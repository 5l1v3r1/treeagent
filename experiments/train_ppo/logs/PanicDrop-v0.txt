2017/08/30 11:14:11 Run with arguments: [-algo mse -env PanicDrop-v0 -step 1 -valstep 0.05 -iters 8 -valiters 8 -discount 0.97 -critic PanicDrop-v0/critic.json -actor PanicDrop-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1 -tuneiters 1 -tunestep 1e3]
2017/08/30 11:14:11 Creating environments...
2017/08/30 11:14:22 Creating new forest for: PanicDrop-v0/actor.json
2017/08/30 11:14:22 Creating new forest for: PanicDrop-v0/critic.json
2017/08/30 11:14:22 Running. Press Ctrl+C to stop.
2017/08/30 11:14:22 Gathering batch of experience...
2017/08/30 11:15:09 batch 0: mean=1.047393 stddev=0.253189 entropy=0.693146 frames=4264 count=211
2017/08/30 11:15:09 Training policy...
2017/08/30 11:15:11 tune 0: objective=0.441168 reg=0.006931 prune=0
2017/08/30 11:15:12 step 0: objective=0.441168 reg=0.006931
2017/08/30 11:15:12 step 1: objective=0.442864 reg=0.006929
2017/08/30 11:15:13 step 2: objective=0.443957 reg=0.006926
2017/08/30 11:15:14 step 3: objective=0.444596 reg=0.006924
2017/08/30 11:15:15 step 4: objective=0.445370 reg=0.006923
2017/08/30 11:15:15 step 5: objective=0.446570 reg=0.006920
2017/08/30 11:15:16 step 6: objective=0.447137 reg=0.006920
2017/08/30 11:15:17 step 7: objective=0.448432 reg=0.006918
2017/08/30 11:15:17 Training value function...
2017/08/30 11:15:19 step 0: mse=0.525169 step=0.050000
2017/08/30 11:15:19 step 1: mse=0.477600 step=0.050000
2017/08/30 11:15:20 step 2: mse=0.434990 step=0.050000
2017/08/30 11:15:21 step 3: mse=0.396818 step=0.050000
2017/08/30 11:15:22 step 4: mse=0.363533 step=0.050000
2017/08/30 11:15:22 step 5: mse=0.332832 step=0.050000
2017/08/30 11:15:23 step 6: mse=0.305249 step=0.050000
2017/08/30 11:15:24 step 7: mse=0.280572 step=0.050000
2017/08/30 11:15:24 Saving...
2017/08/30 11:15:24 Gathering batch of experience...
2017/08/30 11:16:09 batch 1: mean=1.039216 stddev=0.259017 entropy=0.691663 frames=4288 count=204
2017/08/30 11:16:09 Training policy...
2017/08/30 11:16:10 tune 0: objective=0.280680 reg=0.006917 prune=0
2017/08/30 11:16:11 step 0: objective=0.280689 reg=0.006917
2017/08/30 11:16:12 step 1: objective=0.281574 reg=0.006915
2017/08/30 11:16:13 step 2: objective=0.282164 reg=0.006913
2017/08/30 11:16:13 step 3: objective=0.282747 reg=0.006910
2017/08/30 11:16:14 step 4: objective=0.283266 reg=0.006909
2017/08/30 11:16:15 step 5: objective=0.283818 reg=0.006908
2017/08/30 11:16:16 step 6: objective=0.284547 reg=0.006906
2017/08/30 11:16:16 step 7: objective=0.284993 reg=0.006904
2017/08/30 11:16:16 Training value function...
2017/08/30 11:16:18 step 0: mse=0.244780 step=0.050000
2017/08/30 11:16:19 step 1: mse=0.226242 step=0.050000
2017/08/30 11:16:19 step 2: mse=0.209365 step=0.050000
2017/08/30 11:16:20 step 3: mse=0.194289 step=0.050000
2017/08/30 11:16:21 step 4: mse=0.180802 step=0.050000
2017/08/30 11:16:22 step 5: mse=0.168471 step=0.050000
2017/08/30 11:16:22 step 6: mse=0.157475 step=0.050000
2017/08/30 11:16:23 step 7: mse=0.147342 step=0.050000
2017/08/30 11:16:23 Saving...
2017/08/30 11:16:23 Gathering batch of experience...
2017/08/30 11:17:07 batch 2: mean=1.090909 stddev=0.320697 entropy=0.690038 frames=4229 count=198
2017/08/30 11:17:07 Training policy...
2017/08/30 11:17:09 tune 0: objective=0.218492 reg=0.006900 prune=0
2017/08/30 11:17:09 step 0: objective=0.218498 reg=0.006900
2017/08/30 11:17:10 step 1: objective=0.219205 reg=0.006900
2017/08/30 11:17:11 step 2: objective=0.219845 reg=0.006899
2017/08/30 11:17:12 step 3: objective=0.220412 reg=0.006896
2017/08/30 11:17:12 step 4: objective=0.220702 reg=0.006895
2017/08/30 11:17:13 step 5: objective=0.221218 reg=0.006894
2017/08/30 11:17:14 step 6: objective=0.221605 reg=0.006893
2017/08/30 11:17:14 step 7: objective=0.221949 reg=0.006891
2017/08/30 11:17:14 Training value function...
2017/08/30 11:17:16 step 0: mse=0.170528 step=0.050000
2017/08/30 11:17:17 step 1: mse=0.160391 step=0.050000
2017/08/30 11:17:18 step 2: mse=0.151529 step=0.050000
2017/08/30 11:17:18 step 3: mse=0.143090 step=0.050000
2017/08/30 11:17:19 step 4: mse=0.135324 step=0.050000
2017/08/30 11:17:20 step 5: mse=0.128486 step=0.050000
2017/08/30 11:17:20 step 6: mse=0.121978 step=0.050000
2017/08/30 11:17:21 step 7: mse=0.116345 step=0.050000
2017/08/30 11:17:21 Saving...
2017/08/30 11:17:21 Gathering batch of experience...
2017/08/30 11:18:06 batch 3: mean=1.069307 stddev=0.290354 entropy=0.689251 frames=4268 count=202
2017/08/30 11:18:06 Training policy...
2017/08/30 11:18:08 tune 0: objective=0.154121 reg=0.006893 prune=0
2017/08/30 11:18:08 step 0: objective=0.154127 reg=0.006893
2017/08/30 11:18:09 step 1: objective=0.154491 reg=0.006893
2017/08/30 11:18:10 step 2: objective=0.154784 reg=0.006894
2017/08/30 11:18:11 step 3: objective=0.155044 reg=0.006894
2017/08/30 11:18:11 step 4: objective=0.155364 reg=0.006893
2017/08/30 11:18:12 step 5: objective=0.155680 reg=0.006893
2017/08/30 11:18:13 step 6: objective=0.155856 reg=0.006892
2017/08/30 11:18:14 step 7: objective=0.156041 reg=0.006891
2017/08/30 11:18:14 Training value function...
2017/08/30 11:18:15 step 0: mse=0.101386 step=0.050000
2017/08/30 11:18:16 step 1: mse=0.097039 step=0.050000
2017/08/30 11:18:17 step 2: mse=0.093078 step=0.050000
2017/08/30 11:18:17 step 3: mse=0.089502 step=0.050000
2017/08/30 11:18:18 step 4: mse=0.086373 step=0.050000
2017/08/30 11:18:19 step 5: mse=0.083385 step=0.050000
2017/08/30 11:18:20 step 6: mse=0.080555 step=0.050000
2017/08/30 11:18:20 step 7: mse=0.077915 step=0.050000
2017/08/30 11:18:20 Saving...
2017/08/30 11:18:20 Gathering batch of experience...
2017/08/30 11:19:04 batch 4: mean=1.101523 stddev=0.318384 entropy=0.688674 frames=4240 count=197
2017/08/30 11:19:04 Training policy...
2017/08/30 11:19:06 tune 0: objective=0.130600 reg=0.006887 prune=0
2017/08/30 11:19:07 step 0: objective=0.130604 reg=0.006887
2017/08/30 11:19:07 step 1: objective=0.130846 reg=0.006886
2017/08/30 11:19:08 step 2: objective=0.131118 reg=0.006885
2017/08/30 11:19:09 step 3: objective=0.131358 reg=0.006884
2017/08/30 11:19:09 step 4: objective=0.131600 reg=0.006882
2017/08/30 11:19:10 step 5: objective=0.131909 reg=0.006880
2017/08/30 11:19:11 step 6: objective=0.132260 reg=0.006879
2017/08/30 11:19:12 step 7: objective=0.132532 reg=0.006877
2017/08/30 11:19:12 Training value function...
2017/08/30 11:19:13 step 0: mse=0.087687 step=0.050000
2017/08/30 11:19:14 step 1: mse=0.084973 step=0.050000
2017/08/30 11:19:15 step 2: mse=0.082606 step=0.050000
2017/08/30 11:19:15 step 3: mse=0.080188 step=0.050000
2017/08/30 11:19:16 step 4: mse=0.078051 step=0.050000
2017/08/30 11:19:17 step 5: mse=0.076143 step=0.050000
2017/08/30 11:19:18 step 6: mse=0.074365 step=0.050000
2017/08/30 11:19:18 step 7: mse=0.072625 step=0.050000
2017/08/30 11:19:18 Saving...
2017/08/30 11:19:18 Gathering batch of experience...
2017/08/30 11:20:04 batch 5: mean=1.060000 stddev=0.257682 entropy=0.688218 frames=4234 count=200
2017/08/30 11:20:04 Training policy...
2017/08/30 11:20:05 tune 0: objective=0.091976 reg=0.006882 prune=0
2017/08/30 11:20:06 step 0: objective=0.091978 reg=0.006882
2017/08/30 11:20:07 step 1: objective=0.092213 reg=0.006881
2017/08/30 11:20:08 step 2: objective=0.092393 reg=0.006880
2017/08/30 11:20:08 step 3: objective=0.092582 reg=0.006878
2017/08/30 11:20:09 step 4: objective=0.092752 reg=0.006877
2017/08/30 11:20:10 step 5: objective=0.092894 reg=0.006876
2017/08/30 11:20:10 step 6: objective=0.093047 reg=0.006875
2017/08/30 11:20:11 step 7: objective=0.093190 reg=0.006874
2017/08/30 11:20:11 Training value function...
2017/08/30 11:20:13 step 0: mse=0.053442 step=0.050000
2017/08/30 11:20:14 step 1: mse=0.052372 step=0.050000
2017/08/30 11:20:14 step 2: mse=0.051422 step=0.050000
2017/08/30 11:20:15 step 3: mse=0.050535 step=0.050000
2017/08/30 11:20:16 step 4: mse=0.049682 step=0.050000
2017/08/30 11:20:16 step 5: mse=0.048988 step=0.050000
2017/08/30 11:20:17 step 6: mse=0.048208 step=0.050000
2017/08/30 11:20:18 step 7: mse=0.047477 step=0.050000
2017/08/30 11:20:18 Saving...
2017/08/30 11:20:18 Gathering batch of experience...
2017/08/30 11:21:03 batch 6: mean=1.049261 stddev=0.257951 entropy=0.687467 frames=4243 count=203
2017/08/30 11:21:03 Training policy...
2017/08/30 11:21:05 tune 0: objective=0.082449 reg=0.006875 prune=0
2017/08/30 11:21:05 step 0: objective=0.082450 reg=0.006875
2017/08/30 11:21:06 step 1: objective=0.082641 reg=0.006875
2017/08/30 11:21:07 step 2: objective=0.082817 reg=0.006875
2017/08/30 11:21:08 step 3: objective=0.082985 reg=0.006875
2017/08/30 11:21:08 step 4: objective=0.083149 reg=0.006875
2017/08/30 11:21:09 step 5: objective=0.083315 reg=0.006875
2017/08/30 11:21:10 step 6: objective=0.083446 reg=0.006874
2017/08/30 11:21:10 step 7: objective=0.083552 reg=0.006874
2017/08/30 11:21:10 Training value function...
2017/08/30 11:21:12 step 0: mse=0.048047 step=0.050000
2017/08/30 11:21:13 step 1: mse=0.047494 step=0.050000
2017/08/30 11:21:14 step 2: mse=0.046978 step=0.050000
2017/08/30 11:21:14 step 3: mse=0.046369 step=0.050000
2017/08/30 11:21:15 step 4: mse=0.045890 step=0.050000
2017/08/30 11:21:16 step 5: mse=0.045479 step=0.050000
2017/08/30 11:21:16 step 6: mse=0.045079 step=0.050000
2017/08/30 11:21:17 step 7: mse=0.044654 step=0.050000
2017/08/30 11:21:17 Saving...
2017/08/30 11:21:17 Gathering batch of experience...
2017/08/30 11:22:01 batch 7: mean=1.071066 stddev=0.275985 entropy=0.687108 frames=4263 count=197
2017/08/30 11:22:01 Training policy...
2017/08/30 11:22:03 tune 0: objective=0.076889 reg=0.006871 prune=0
2017/08/30 11:22:04 step 0: objective=0.076891 reg=0.006871
2017/08/30 11:22:04 step 1: objective=0.077007 reg=0.006870
2017/08/30 11:22:05 step 2: objective=0.077167 reg=0.006870
2017/08/30 11:22:06 step 3: objective=0.077284 reg=0.006869
2017/08/30 11:22:06 step 4: objective=0.077387 reg=0.006868
2017/08/30 11:22:07 step 5: objective=0.077509 reg=0.006867
2017/08/30 11:22:08 step 6: objective=0.077656 reg=0.006865
2017/08/30 11:22:09 step 7: objective=0.077767 reg=0.006864
2017/08/30 11:22:09 Training value function...
2017/08/30 11:22:10 step 0: mse=0.049716 step=0.050000
2017/08/30 11:22:11 step 1: mse=0.049193 step=0.050000
2017/08/30 11:22:12 step 2: mse=0.048767 step=0.050000
2017/08/30 11:22:13 step 3: mse=0.048287 step=0.050000
2017/08/30 11:22:13 step 4: mse=0.047878 step=0.050000
2017/08/30 11:22:14 step 5: mse=0.047484 step=0.050000
2017/08/30 11:22:15 step 6: mse=0.047123 step=0.050000
2017/08/30 11:22:16 step 7: mse=0.046842 step=0.050000
2017/08/30 11:22:16 Saving...
2017/08/30 11:22:16 Gathering batch of experience...
2017/08/30 11:23:02 batch 8: mean=1.039024 stddev=0.276633 entropy=0.686868 frames=4274 count=205
2017/08/30 11:23:02 Training policy...
2017/08/30 11:23:04 tune 0: objective=0.069273 reg=0.006869 prune=0
2017/08/30 11:23:05 step 0: objective=0.069275 reg=0.006869
2017/08/30 11:23:06 step 1: objective=0.069378 reg=0.006869
2017/08/30 11:23:06 step 2: objective=0.069529 reg=0.006870
2017/08/30 11:23:07 step 3: objective=0.069673 reg=0.006871
2017/08/30 11:23:08 step 4: objective=0.069794 reg=0.006871
2017/08/30 11:23:08 step 5: objective=0.069886 reg=0.006871
2017/08/30 11:23:09 step 6: objective=0.069993 reg=0.006871
2017/08/30 11:23:10 step 7: objective=0.070172 reg=0.006871
2017/08/30 11:23:10 Training value function...
2017/08/30 11:23:12 step 0: mse=0.043885 step=0.050000
2017/08/30 11:23:12 step 1: mse=0.043696 step=0.050000
2017/08/30 11:23:13 step 2: mse=0.043535 step=0.050000
2017/08/30 11:23:14 step 3: mse=0.043291 step=0.050000
2017/08/30 11:23:15 step 4: mse=0.043171 step=0.050000
2017/08/30 11:23:15 step 5: mse=0.043058 step=0.050000
2017/08/30 11:23:16 step 6: mse=0.042963 step=0.050000
2017/08/30 11:23:17 step 7: mse=0.042825 step=0.050000
2017/08/30 11:23:17 Saving...
2017/08/30 11:23:17 Gathering batch of experience...
2017/08/30 11:24:01 batch 9: mean=1.055276 stddev=0.268926 entropy=0.686880 frames=4247 count=199
2017/08/30 11:24:01 Training policy...
2017/08/30 11:24:03 tune 0: objective=0.068228 reg=0.006869 prune=0
2017/08/30 11:24:03 step 0: objective=0.068229 reg=0.006869
2017/08/30 11:24:04 step 1: objective=0.068307 reg=0.006868
2017/08/30 11:24:05 step 2: objective=0.068492 reg=0.006867
2017/08/30 11:24:05 step 3: objective=0.068674 reg=0.006866
2017/08/30 11:24:06 step 4: objective=0.068871 reg=0.006865
2017/08/30 11:24:07 step 5: objective=0.069054 reg=0.006864
2017/08/30 11:24:08 step 6: objective=0.069243 reg=0.006862
2017/08/30 11:24:08 step 7: objective=0.069423 reg=0.006860
2017/08/30 11:24:08 Training value function...
2017/08/30 11:24:10 step 0: mse=0.043314 step=0.050000
2017/08/30 11:24:11 step 1: mse=0.043186 step=0.050000
2017/08/30 11:24:12 step 2: mse=0.043037 step=0.050000
2017/08/30 11:24:12 step 3: mse=0.042887 step=0.050000
2017/08/30 11:24:13 step 4: mse=0.042750 step=0.050000
2017/08/30 11:24:14 step 5: mse=0.042578 step=0.050000
2017/08/30 11:24:14 step 6: mse=0.042447 step=0.050000
2017/08/30 11:24:15 step 7: mse=0.042302 step=0.050000
2017/08/30 11:24:15 Saving...
2017/08/30 11:24:15 Gathering batch of experience...
2017/08/30 11:24:59 batch 10: mean=1.055556 stddev=0.250140 entropy=0.685822 frames=4246 count=198
2017/08/30 11:24:59 Training policy...
2017/08/30 11:25:01 tune 0: objective=0.066566 reg=0.006858 prune=0
2017/08/30 11:25:01 step 0: objective=0.066566 reg=0.006858
2017/08/30 11:25:02 step 1: objective=0.066701 reg=0.006857
2017/08/30 11:25:03 step 2: objective=0.066827 reg=0.006856
2017/08/30 11:25:03 step 3: objective=0.066953 reg=0.006856
2017/08/30 11:25:04 step 4: objective=0.067066 reg=0.006855
2017/08/30 11:25:05 step 5: objective=0.067190 reg=0.006853
2017/08/30 11:25:06 step 6: objective=0.067271 reg=0.006852
2017/08/30 11:25:06 step 7: objective=0.067357 reg=0.006851
2017/08/30 11:25:06 Training value function...
2017/08/30 11:25:08 step 0: mse=0.041382 step=0.050000
2017/08/30 11:25:09 step 1: mse=0.041295 step=0.050000
2017/08/30 11:25:09 step 2: mse=0.041203 step=0.050000
2017/08/30 11:25:10 step 3: mse=0.041070 step=0.050000
2017/08/30 11:25:11 step 4: mse=0.040920 step=0.050000
2017/08/30 11:25:12 step 5: mse=0.040790 step=0.050000
2017/08/30 11:25:12 step 6: mse=0.040660 step=0.050000
2017/08/30 11:25:13 step 7: mse=0.040531 step=0.050000
2017/08/30 11:25:13 Saving...
2017/08/30 11:25:13 Gathering batch of experience...
2017/08/30 11:25:58 batch 11: mean=1.059113 stddev=0.255873 entropy=0.685322 frames=4263 count=203
2017/08/30 11:25:58 Training policy...
2017/08/30 11:26:00 tune 0: objective=0.072246 reg=0.006853 prune=0
2017/08/30 11:26:00 step 0: objective=0.072247 reg=0.006853
2017/08/30 11:26:01 step 1: objective=0.072323 reg=0.006853
2017/08/30 11:26:02 step 2: objective=0.072455 reg=0.006851
2017/08/30 11:26:03 step 3: objective=0.072567 reg=0.006850
2017/08/30 11:26:03 step 4: objective=0.072724 reg=0.006849
2017/08/30 11:26:04 step 5: objective=0.072850 reg=0.006848
2017/08/30 11:26:05 step 6: objective=0.072942 reg=0.006846
2017/08/30 11:26:05 step 7: objective=0.073092 reg=0.006844
2017/08/30 11:26:05 Training value function...
2017/08/30 11:26:07 step 0: mse=0.041519 step=0.050000
2017/08/30 11:26:08 step 1: mse=0.041360 step=0.050000
2017/08/30 11:26:09 step 2: mse=0.041195 step=0.050000
2017/08/30 11:26:09 step 3: mse=0.041046 step=0.050000
2017/08/30 11:26:10 step 4: mse=0.040918 step=0.050000
2017/08/30 11:26:11 step 5: mse=0.040790 step=0.050000
2017/08/30 11:26:12 step 6: mse=0.040667 step=0.050000
2017/08/30 11:26:12 step 7: mse=0.040548 step=0.050000
2017/08/30 11:26:12 Saving...
2017/08/30 11:26:12 Gathering batch of experience...
2017/08/30 11:26:57 batch 12: mean=1.085859 stddev=0.314148 entropy=0.683506 frames=4252 count=198
2017/08/30 11:26:57 Training policy...
2017/08/30 11:26:59 tune 0: objective=0.078846 reg=0.006835 prune=0
2017/08/30 11:27:00 step 0: objective=0.078847 reg=0.006835
2017/08/30 11:27:01 step 1: objective=0.079145 reg=0.006833
2017/08/30 11:27:01 step 2: objective=0.079276 reg=0.006833
2017/08/30 11:27:02 step 3: objective=0.079530 reg=0.006831
2017/08/30 11:27:03 step 4: objective=0.079778 reg=0.006829
2017/08/30 11:27:03 step 5: objective=0.079980 reg=0.006828
2017/08/30 11:27:04 step 6: objective=0.080104 reg=0.006825
2017/08/30 11:27:05 step 7: objective=0.080260 reg=0.006824
2017/08/30 11:27:05 Training value function...
2017/08/30 11:27:07 step 0: mse=0.052937 step=0.050000
2017/08/30 11:27:07 step 1: mse=0.052362 step=0.050000
2017/08/30 11:27:08 step 2: mse=0.051854 step=0.050000
2017/08/30 11:27:09 step 3: mse=0.051099 step=0.050000
2017/08/30 11:27:10 step 4: mse=0.050673 step=0.050000
2017/08/30 11:27:10 step 5: mse=0.050303 step=0.050000
2017/08/30 11:27:11 step 6: mse=0.049998 step=0.050000
2017/08/30 11:27:12 step 7: mse=0.049647 step=0.050000
2017/08/30 11:27:12 Saving...
2017/08/30 11:27:12 Gathering batch of experience...
2017/08/30 11:27:55 batch 13: mean=1.054726 stddev=0.285626 entropy=0.683056 frames=4253 count=201
2017/08/30 11:27:55 Training policy...
2017/08/30 11:27:57 tune 0: objective=0.062803 reg=0.006831 prune=0
2017/08/30 11:27:58 step 0: objective=0.062804 reg=0.006831
2017/08/30 11:27:59 step 1: objective=0.062922 reg=0.006828
2017/08/30 11:27:59 step 2: objective=0.063074 reg=0.006826
2017/08/30 11:28:00 step 3: objective=0.063202 reg=0.006823
2017/08/30 11:28:01 step 4: objective=0.063321 reg=0.006821
2017/08/30 11:28:02 step 5: objective=0.063465 reg=0.006819
2017/08/30 11:28:02 step 6: objective=0.063601 reg=0.006817
2017/08/30 11:28:03 step 7: objective=0.063703 reg=0.006814
2017/08/30 11:28:03 Training value function...
2017/08/30 11:28:05 step 0: mse=0.042317 step=0.050000
2017/08/30 11:28:05 step 1: mse=0.042244 step=0.050000
2017/08/30 11:28:06 step 2: mse=0.042124 step=0.050000
2017/08/30 11:28:07 step 3: mse=0.042010 step=0.050000
2017/08/30 11:28:08 step 4: mse=0.041965 step=0.050000
2017/08/30 11:28:08 step 5: mse=0.041924 step=0.050000
2017/08/30 11:28:09 step 6: mse=0.041869 step=0.050000
2017/08/30 11:28:10 step 7: mse=0.041793 step=0.050000
2017/08/30 11:28:10 Saving...
2017/08/30 11:28:10 Gathering batch of experience...
2017/08/30 11:28:54 batch 14: mean=1.075000 stddev=0.298957 entropy=0.680757 frames=4248 count=200
2017/08/30 11:28:54 Training policy...
2017/08/30 11:28:56 tune 0: objective=0.075556 reg=0.006808 prune=0
2017/08/30 11:28:57 step 0: objective=0.075557 reg=0.006808
2017/08/30 11:28:58 step 1: objective=0.075755 reg=0.006807
2017/08/30 11:28:59 step 2: objective=0.075924 reg=0.006806
2017/08/30 11:28:59 step 3: objective=0.076206 reg=0.006804
2017/08/30 11:29:00 step 4: objective=0.076394 reg=0.006803
2017/08/30 11:29:01 step 5: objective=0.076670 reg=0.006801
2017/08/30 11:29:01 step 6: objective=0.076779 reg=0.006800
2017/08/30 11:29:02 step 7: objective=0.076851 reg=0.006799
2017/08/30 11:29:02 Training value function...
2017/08/30 11:29:04 step 0: mse=0.048515 step=0.050000
2017/08/30 11:29:05 step 1: mse=0.048170 step=0.050000
2017/08/30 11:29:05 step 2: mse=0.047853 step=0.050000
2017/08/30 11:29:06 step 3: mse=0.047626 step=0.050000
2017/08/30 11:29:07 step 4: mse=0.047346 step=0.050000
2017/08/30 11:29:08 step 5: mse=0.047099 step=0.050000
2017/08/30 11:29:08 step 6: mse=0.046914 step=0.050000
2017/08/30 11:29:09 step 7: mse=0.046653 step=0.050000
2017/08/30 11:29:09 Saving...
2017/08/30 11:29:09 Gathering batch of experience...
2017/08/30 11:29:51 batch 15: mean=1.093750 stddev=0.325260 entropy=0.677934 frames=4249 count=192
2017/08/30 11:29:51 Training policy...
2017/08/30 11:29:53 tune 0: objective=0.070268 reg=0.006779 prune=0
2017/08/30 11:29:54 step 0: objective=0.070269 reg=0.006779
2017/08/30 11:29:55 step 1: objective=0.070407 reg=0.006776
2017/08/30 11:29:55 step 2: objective=0.070542 reg=0.006773
2017/08/30 11:29:56 step 3: objective=0.070715 reg=0.006770
2017/08/30 11:29:57 step 4: objective=0.070879 reg=0.006767
2017/08/30 11:29:58 step 5: objective=0.071037 reg=0.006763
2017/08/30 11:29:58 step 6: objective=0.071191 reg=0.006760
2017/08/30 11:29:59 step 7: objective=0.071320 reg=0.006757
2017/08/30 11:29:59 Training value function...
2017/08/30 11:30:01 step 0: mse=0.051824 step=0.050000
2017/08/30 11:30:02 step 1: mse=0.051722 step=0.050000
2017/08/30 11:30:02 step 2: mse=0.051587 step=0.050000
2017/08/30 11:30:03 step 3: mse=0.051443 step=0.050000
2017/08/30 11:30:04 step 4: mse=0.051307 step=0.050000
2017/08/30 11:30:04 step 5: mse=0.051194 step=0.050000
2017/08/30 11:30:05 step 6: mse=0.051046 step=0.050000
2017/08/30 11:30:06 step 7: mse=0.050970 step=0.050000
2017/08/30 11:30:06 Saving...
2017/08/30 11:30:06 Gathering batch of experience...
2017/08/30 11:30:50 batch 16: mean=1.065000 stddev=0.317451 entropy=0.676425 frames=4284 count=200
2017/08/30 11:30:50 Training policy...
2017/08/30 11:30:52 tune 0: objective=0.063759 reg=0.006764 prune=0
2017/08/30 11:30:53 step 0: objective=0.063760 reg=0.006764
2017/08/30 11:30:53 step 1: objective=0.063881 reg=0.006763
2017/08/30 11:30:54 step 2: objective=0.063975 reg=0.006762
2017/08/30 11:30:55 step 3: objective=0.064136 reg=0.006761
2017/08/30 11:30:55 step 4: objective=0.064293 reg=0.006760
2017/08/30 11:30:56 step 5: objective=0.064387 reg=0.006760
2017/08/30 11:30:57 step 6: objective=0.064502 reg=0.006758
2017/08/30 11:30:58 step 7: objective=0.064655 reg=0.006756
2017/08/30 11:30:58 Training value function...
2017/08/30 11:30:59 step 0: mse=0.048132 step=0.050000
2017/08/30 11:31:00 step 1: mse=0.047985 step=0.050000
2017/08/30 11:31:01 step 2: mse=0.047854 step=0.050000
2017/08/30 11:31:02 step 3: mse=0.047745 step=0.050000
2017/08/30 11:31:02 step 4: mse=0.047687 step=0.050000
2017/08/30 11:31:03 step 5: mse=0.047578 step=0.050000
2017/08/30 11:31:04 step 6: mse=0.047492 step=0.050000
2017/08/30 11:31:05 step 7: mse=0.047382 step=0.050000
2017/08/30 11:31:05 Saving...
2017/08/30 11:31:05 Gathering batch of experience...
2017/08/30 11:31:48 batch 17: mean=1.091837 stddev=0.337661 entropy=0.676003 frames=4261 count=196
2017/08/30 11:31:48 Training policy...
2017/08/30 11:31:50 tune 0: objective=0.075190 reg=0.006760 prune=0
2017/08/30 11:31:51 step 0: objective=0.075191 reg=0.006760
2017/08/30 11:31:51 step 1: objective=0.075388 reg=0.006757
2017/08/30 11:31:52 step 2: objective=0.075527 reg=0.006755
2017/08/30 11:31:53 step 3: objective=0.075694 reg=0.006753
2017/08/30 11:31:53 step 4: objective=0.075913 reg=0.006750
2017/08/30 11:31:54 step 5: objective=0.076060 reg=0.006747
2017/08/30 11:31:55 step 6: objective=0.076161 reg=0.006745
2017/08/30 11:31:56 step 7: objective=0.076294 reg=0.006744
2017/08/30 11:31:56 Training value function...
2017/08/30 11:31:57 step 0: mse=0.054665 step=0.050000
2017/08/30 11:31:58 step 1: mse=0.054421 step=0.050000
2017/08/30 11:31:59 step 2: mse=0.054173 step=0.050000
2017/08/30 11:32:00 step 3: mse=0.053943 step=0.050000
2017/08/30 11:32:00 step 4: mse=0.053747 step=0.050000
2017/08/30 11:32:01 step 5: mse=0.053628 step=0.050000
2017/08/30 11:32:02 step 6: mse=0.053416 step=0.050000
2017/08/30 11:32:03 step 7: mse=0.053258 step=0.050000
2017/08/30 11:32:03 Saving...
2017/08/30 11:32:03 Gathering batch of experience...
2017/08/30 11:32:45 batch 18: mean=1.151832 stddev=0.373163 entropy=0.670864 frames=4273 count=191
2017/08/30 11:32:45 Training policy...
2017/08/30 11:32:47 tune 0: objective=0.087930 reg=0.006709 prune=0
2017/08/30 11:32:48 step 0: objective=0.087932 reg=0.006709
2017/08/30 11:32:49 step 1: objective=0.088172 reg=0.006707
2017/08/30 11:32:49 step 2: objective=0.088431 reg=0.006703
2017/08/30 11:32:50 step 3: objective=0.088713 reg=0.006699
2017/08/30 11:32:51 step 4: objective=0.088886 reg=0.006697
2017/08/30 11:32:51 step 5: objective=0.089093 reg=0.006694
2017/08/30 11:32:52 step 6: objective=0.089291 reg=0.006691
2017/08/30 11:32:53 step 7: objective=0.089485 reg=0.006688
2017/08/30 11:32:53 Training value function...
2017/08/30 11:32:55 step 0: mse=0.067418 step=0.050000
2017/08/30 11:32:55 step 1: mse=0.066799 step=0.050000
2017/08/30 11:32:56 step 2: mse=0.065905 step=0.050000
2017/08/30 11:32:57 step 3: mse=0.065248 step=0.050000
2017/08/30 11:32:58 step 4: mse=0.064704 step=0.050000
2017/08/30 11:32:58 step 5: mse=0.064048 step=0.050000
2017/08/30 11:32:59 step 6: mse=0.063444 step=0.050000
2017/08/30 11:33:00 step 7: mse=0.062944 step=0.050000
2017/08/30 11:33:00 Saving...
2017/08/30 11:33:00 Gathering batch of experience...
2017/08/30 11:33:42 batch 19: mean=1.158730 stddev=0.455641 entropy=0.669183 frames=4282 count=189
2017/08/30 11:33:42 Training policy...
2017/08/30 11:33:44 tune 0: objective=0.086254 reg=0.006692 prune=0
2017/08/30 11:33:45 step 0: objective=0.086255 reg=0.006692
2017/08/30 11:33:46 step 1: objective=0.086554 reg=0.006687
2017/08/30 11:33:47 step 2: objective=0.086713 reg=0.006684
2017/08/30 11:33:47 step 3: objective=0.086871 reg=0.006681
2017/08/30 11:33:48 step 4: objective=0.087078 reg=0.006677
2017/08/30 11:33:49 step 5: objective=0.087255 reg=0.006674
2017/08/30 11:33:50 step 6: objective=0.087419 reg=0.006669
2017/08/30 11:33:50 step 7: objective=0.087584 reg=0.006663
2017/08/30 11:33:50 Training value function...
2017/08/30 11:33:52 step 0: mse=0.077044 step=0.050000
2017/08/30 11:33:53 step 1: mse=0.076020 step=0.050000
2017/08/30 11:33:53 step 2: mse=0.075041 step=0.050000
2017/08/30 11:33:54 step 3: mse=0.074154 step=0.050000
2017/08/30 11:33:55 step 4: mse=0.073479 step=0.050000
2017/08/30 11:33:56 step 5: mse=0.072802 step=0.050000
2017/08/30 11:33:56 step 6: mse=0.072045 step=0.050000
2017/08/30 11:33:57 step 7: mse=0.071502 step=0.050000
2017/08/30 11:33:57 Saving...
2017/08/30 11:33:57 Gathering batch of experience...
2017/08/30 11:34:40 batch 20: mean=1.140625 stddev=0.451866 entropy=0.665308 frames=4329 count=192
2017/08/30 11:34:40 Training policy...
2017/08/30 11:34:42 tune 0: objective=0.072787 reg=0.006653 prune=0
2017/08/30 11:34:43 step 0: objective=0.072788 reg=0.006653
2017/08/30 11:34:44 step 1: objective=0.073075 reg=0.006649
2017/08/30 11:34:44 step 2: objective=0.073311 reg=0.006644
2017/08/30 11:34:45 step 3: objective=0.073533 reg=0.006639
2017/08/30 11:34:46 step 4: objective=0.073733 reg=0.006635
2017/08/30 11:34:46 step 5: objective=0.073983 reg=0.006630
2017/08/30 11:34:47 step 6: objective=0.074197 reg=0.006625
2017/08/30 11:34:48 step 7: objective=0.074454 reg=0.006620
2017/08/30 11:34:48 Training value function...
2017/08/30 11:34:50 step 0: mse=0.070011 step=0.050000
2017/08/30 11:34:51 step 1: mse=0.069584 step=0.050000
2017/08/30 11:34:51 step 2: mse=0.069215 step=0.050000
2017/08/30 11:34:52 step 3: mse=0.068923 step=0.050000
2017/08/30 11:34:53 step 4: mse=0.068454 step=0.050000
2017/08/30 11:34:53 step 5: mse=0.068083 step=0.050000
2017/08/30 11:34:54 step 6: mse=0.067766 step=0.050000
2017/08/30 11:34:55 step 7: mse=0.067410 step=0.050000
2017/08/30 11:34:55 Saving...
2017/08/30 11:34:55 Gathering batch of experience...
2017/08/30 11:35:37 batch 21: mean=1.163043 stddev=0.472670 entropy=0.657985 frames=4325 count=184
2017/08/30 11:35:37 Training policy...
2017/08/30 11:35:39 tune 0: objective=0.068258 reg=0.006580 prune=0
2017/08/30 11:35:39 step 0: objective=0.068260 reg=0.006580
2017/08/30 11:35:40 step 1: objective=0.068535 reg=0.006572
2017/08/30 11:35:41 step 2: objective=0.068818 reg=0.006565
2017/08/30 11:35:42 step 3: objective=0.069091 reg=0.006558
2017/08/30 11:35:42 step 4: objective=0.069354 reg=0.006550
2017/08/30 11:35:43 step 5: objective=0.069619 reg=0.006543
2017/08/30 11:35:44 step 6: objective=0.069836 reg=0.006537
2017/08/30 11:35:45 step 7: objective=0.070051 reg=0.006532
2017/08/30 11:35:45 Training value function...
2017/08/30 11:35:46 step 0: mse=0.071969 step=0.050000
2017/08/30 11:35:47 step 1: mse=0.071650 step=0.050000
2017/08/30 11:35:48 step 2: mse=0.071436 step=0.050000
2017/08/30 11:35:49 step 3: mse=0.071214 step=0.050000
2017/08/30 11:35:49 step 4: mse=0.071048 step=0.050000
2017/08/30 11:35:50 step 5: mse=0.070843 step=0.050000
2017/08/30 11:35:51 step 6: mse=0.070666 step=0.050000
2017/08/30 11:35:52 step 7: mse=0.070476 step=0.050000
2017/08/30 11:35:52 Saving...
2017/08/30 11:35:52 Gathering batch of experience...
2017/08/30 11:36:33 batch 22: mean=1.247191 stddev=0.535921 entropy=0.647702 frames=4324 count=178
2017/08/30 11:36:33 Training policy...
2017/08/30 11:36:35 tune 0: objective=0.091393 reg=0.006477 prune=0
2017/08/30 11:36:36 step 0: objective=0.091397 reg=0.006477
2017/08/30 11:36:36 step 1: objective=0.091816 reg=0.006466
2017/08/30 11:36:37 step 2: objective=0.092233 reg=0.006456
2017/08/30 11:36:38 step 3: objective=0.092574 reg=0.006447
2017/08/30 11:36:39 step 4: objective=0.092931 reg=0.006437
2017/08/30 11:36:39 step 5: objective=0.093207 reg=0.006427
2017/08/30 11:36:40 step 6: objective=0.093530 reg=0.006417
2017/08/30 11:36:41 step 7: objective=0.093801 reg=0.006410
2017/08/30 11:36:41 Training value function...
2017/08/30 11:36:43 step 0: mse=0.084848 step=0.050000
2017/08/30 11:36:43 step 1: mse=0.083798 step=0.050000
2017/08/30 11:36:44 step 2: mse=0.082932 step=0.050000
2017/08/30 11:36:45 step 3: mse=0.082249 step=0.050000
2017/08/30 11:36:45 step 4: mse=0.081397 step=0.050000
2017/08/30 11:36:46 step 5: mse=0.080440 step=0.050000
2017/08/30 11:36:47 step 6: mse=0.079691 step=0.050000
2017/08/30 11:36:48 step 7: mse=0.079004 step=0.050000
2017/08/30 11:36:48 Saving...
2017/08/30 11:36:48 Gathering batch of experience...
2017/08/30 11:37:27 batch 23: mean=1.333333 stddev=0.709171 entropy=0.640679 frames=4302 count=171
2017/08/30 11:37:27 Training policy...
2017/08/30 11:37:29 tune 0: objective=0.111410 reg=0.006407 prune=0
2017/08/30 11:37:30 step 0: objective=0.111413 reg=0.006407
2017/08/30 11:37:30 step 1: objective=0.111666 reg=0.006398
2017/08/30 11:37:31 step 2: objective=0.112054 reg=0.006391
2017/08/30 11:37:32 step 3: objective=0.112349 reg=0.006384
2017/08/30 11:37:32 step 4: objective=0.112754 reg=0.006376
2017/08/30 11:37:33 step 5: objective=0.113023 reg=0.006369
2017/08/30 11:37:34 step 6: objective=0.113173 reg=0.006364
2017/08/30 11:37:35 step 7: objective=0.113447 reg=0.006357
2017/08/30 11:37:35 Training value function...
2017/08/30 11:37:36 step 0: mse=0.121885 step=0.050000
2017/08/30 11:37:37 step 1: mse=0.119741 step=0.050000
2017/08/30 11:37:38 step 2: mse=0.117679 step=0.050000
2017/08/30 11:37:39 step 3: mse=0.115794 step=0.050000
2017/08/30 11:37:39 step 4: mse=0.114141 step=0.050000
2017/08/30 11:37:40 step 5: mse=0.112671 step=0.050000
2017/08/30 11:37:41 step 6: mse=0.111353 step=0.050000
2017/08/30 11:37:42 step 7: mse=0.109967 step=0.050000
2017/08/30 11:37:42 Saving...
2017/08/30 11:37:42 Gathering batch of experience...
2017/08/30 11:38:22 batch 24: mean=1.329341 stddev=0.651512 entropy=0.632450 frames=4300 count=167
2017/08/30 11:38:22 Training policy...
2017/08/30 11:38:24 tune 0: objective=0.090961 reg=0.006325 prune=0
2017/08/30 11:38:24 step 0: objective=0.090965 reg=0.006324
2017/08/30 11:38:25 step 1: objective=0.091262 reg=0.006314
2017/08/30 11:38:26 step 2: objective=0.091623 reg=0.006304
2017/08/30 11:38:27 step 3: objective=0.091920 reg=0.006294
2017/08/30 11:38:27 step 4: objective=0.092201 reg=0.006283
2017/08/30 11:38:28 step 5: objective=0.092567 reg=0.006274
2017/08/30 11:38:29 step 6: objective=0.092818 reg=0.006264
2017/08/30 11:38:30 step 7: objective=0.093085 reg=0.006258
2017/08/30 11:38:30 Training value function...
2017/08/30 11:38:31 step 0: mse=0.094711 step=0.050000
2017/08/30 11:38:32 step 1: mse=0.093694 step=0.050000
2017/08/30 11:38:33 step 2: mse=0.092779 step=0.050000
2017/08/30 11:38:34 step 3: mse=0.092039 step=0.050000
2017/08/30 11:38:34 step 4: mse=0.091199 step=0.050000
2017/08/30 11:38:35 step 5: mse=0.090505 step=0.050000
2017/08/30 11:38:36 step 6: mse=0.089795 step=0.050000
2017/08/30 11:38:37 step 7: mse=0.089173 step=0.050000
2017/08/30 11:38:37 Saving...
2017/08/30 11:38:37 Gathering batch of experience...
2017/08/30 11:39:16 batch 25: mean=1.353659 stddev=0.704895 entropy=0.624141 frames=4228 count=164
2017/08/30 11:39:16 Training policy...
2017/08/30 11:39:18 tune 0: objective=0.089743 reg=0.006241 prune=0
2017/08/30 11:39:18 step 0: objective=0.089748 reg=0.006241
2017/08/30 11:39:19 step 1: objective=0.090175 reg=0.006228
2017/08/30 11:39:20 step 2: objective=0.090651 reg=0.006215
2017/08/30 11:39:21 step 3: objective=0.091193 reg=0.006201
2017/08/30 11:39:21 step 4: objective=0.091663 reg=0.006185
2017/08/30 11:39:22 step 5: objective=0.092103 reg=0.006172
2017/08/30 11:39:23 step 6: objective=0.092368 reg=0.006161
2017/08/30 11:39:23 step 7: objective=0.092694 reg=0.006150
2017/08/30 11:39:23 Training value function...
2017/08/30 11:39:25 step 0: mse=0.109979 step=0.050000
2017/08/30 11:39:26 step 1: mse=0.109413 step=0.050000
2017/08/30 11:39:27 step 2: mse=0.108771 step=0.050000
2017/08/30 11:39:27 step 3: mse=0.108105 step=0.050000
2017/08/30 11:39:28 step 4: mse=0.107499 step=0.050000
2017/08/30 11:39:29 step 5: mse=0.106746 step=0.050000
2017/08/30 11:39:30 step 6: mse=0.106137 step=0.050000
2017/08/30 11:39:30 step 7: mse=0.105595 step=0.050000
2017/08/30 11:39:30 Saving...
2017/08/30 11:39:30 Gathering batch of experience...
2017/08/30 11:40:08 batch 26: mean=1.450980 stddev=0.807976 entropy=0.605156 frames=4312 count=153
2017/08/30 11:40:08 Training policy...
2017/08/30 11:40:10 tune 0: objective=0.085533 reg=0.006052 prune=0
2017/08/30 11:40:10 step 0: objective=0.085540 reg=0.006051
2017/08/30 11:40:11 step 1: objective=0.086026 reg=0.006038
2017/08/30 11:40:12 step 2: objective=0.086537 reg=0.006024
2017/08/30 11:40:13 step 3: objective=0.086983 reg=0.006010
2017/08/30 11:40:13 step 4: objective=0.087412 reg=0.005996
2017/08/30 11:40:14 step 5: objective=0.087819 reg=0.005982
2017/08/30 11:40:15 step 6: objective=0.088169 reg=0.005971
2017/08/30 11:40:15 step 7: objective=0.088411 reg=0.005961
2017/08/30 11:40:15 Training value function...
2017/08/30 11:40:17 step 0: mse=0.125753 step=0.050000
2017/08/30 11:40:18 step 1: mse=0.124952 step=0.050000
2017/08/30 11:40:19 step 2: mse=0.124364 step=0.050000
2017/08/30 11:40:20 step 3: mse=0.123612 step=0.050000
2017/08/30 11:40:20 step 4: mse=0.122871 step=0.050000
2017/08/30 11:40:21 step 5: mse=0.122298 step=0.050000
2017/08/30 11:40:22 step 6: mse=0.121568 step=0.050000
2017/08/30 11:40:23 step 7: mse=0.121115 step=0.050000
2017/08/30 11:40:23 Saving...
2017/08/30 11:40:23 Gathering batch of experience...
2017/08/30 11:41:00 batch 27: mean=1.400000 stddev=0.717635 entropy=0.598468 frames=4328 count=160
2017/08/30 11:41:00 Training policy...
2017/08/30 11:41:03 tune 0: objective=0.077865 reg=0.005985 prune=0
2017/08/30 11:41:03 step 0: objective=0.077871 reg=0.005984
2017/08/30 11:41:04 step 1: objective=0.078234 reg=0.005971
2017/08/30 11:41:05 step 2: objective=0.078614 reg=0.005957
2017/08/30 11:41:05 step 3: objective=0.079010 reg=0.005944
2017/08/30 11:41:06 step 4: objective=0.079369 reg=0.005931
2017/08/30 11:41:07 step 5: objective=0.079671 reg=0.005919
2017/08/30 11:41:08 step 6: objective=0.079841 reg=0.005911
2017/08/30 11:41:08 step 7: objective=0.080082 reg=0.005902
2017/08/30 11:41:08 Training value function...
2017/08/30 11:41:10 step 0: mse=0.102548 step=0.050000
2017/08/30 11:41:11 step 1: mse=0.102107 step=0.050000
2017/08/30 11:41:12 step 2: mse=0.101733 step=0.050000
2017/08/30 11:41:13 step 3: mse=0.101307 step=0.050000
2017/08/30 11:41:13 step 4: mse=0.101044 step=0.050000
2017/08/30 11:41:14 step 5: mse=0.100637 step=0.050000
2017/08/30 11:41:15 step 6: mse=0.100425 step=0.050000
2017/08/30 11:41:16 step 7: mse=0.100164 step=0.050000
2017/08/30 11:41:16 Saving...
2017/08/30 11:41:16 Gathering batch of experience...
2017/08/30 11:41:50 batch 28: mean=1.787879 stddev=1.037409 entropy=0.572780 frames=4316 count=132
2017/08/30 11:41:50 Training policy...
2017/08/30 11:41:52 tune 0: objective=0.138867 reg=0.005728 prune=0
2017/08/30 11:41:53 step 0: objective=0.138877 reg=0.005727
2017/08/30 11:41:53 step 1: objective=0.139518 reg=0.005713
2017/08/30 11:41:54 step 2: objective=0.140012 reg=0.005697
2017/08/30 11:41:55 step 3: objective=0.140449 reg=0.005682
2017/08/30 11:41:56 step 4: objective=0.140747 reg=0.005670
2017/08/30 11:41:56 step 5: objective=0.141009 reg=0.005659
2017/08/30 11:41:57 step 6: objective=0.141406 reg=0.005647
2017/08/30 11:41:58 step 7: objective=0.141820 reg=0.005638
2017/08/30 11:41:58 Training value function...
2017/08/30 11:42:00 step 0: mse=0.183649 step=0.050000
2017/08/30 11:42:00 step 1: mse=0.180281 step=0.050000
2017/08/30 11:42:01 step 2: mse=0.176925 step=0.050000
2017/08/30 11:42:02 step 3: mse=0.174005 step=0.050000
2017/08/30 11:42:03 step 4: mse=0.171213 step=0.050000
2017/08/30 11:42:03 step 5: mse=0.168567 step=0.050000
2017/08/30 11:42:04 step 6: mse=0.166528 step=0.050000
2017/08/30 11:42:05 step 7: mse=0.164356 step=0.050000
2017/08/30 11:42:05 Saving...
2017/08/30 11:42:05 Gathering batch of experience...
2017/08/30 11:42:38 batch 29: mean=1.782946 stddev=1.085216 entropy=0.562475 frames=4296 count=129
2017/08/30 11:42:38 Training policy...
2017/08/30 11:42:40 tune 0: objective=0.109183 reg=0.005625 prune=0
2017/08/30 11:42:41 step 0: objective=0.109193 reg=0.005624
2017/08/30 11:42:42 step 1: objective=0.109771 reg=0.005609
2017/08/30 11:42:42 step 2: objective=0.110328 reg=0.005595
2017/08/30 11:42:43 step 3: objective=0.111011 reg=0.005581
2017/08/30 11:42:44 step 4: objective=0.111440 reg=0.005566
2017/08/30 11:42:45 step 5: objective=0.111812 reg=0.005555
2017/08/30 11:42:45 step 6: objective=0.112069 reg=0.005543
2017/08/30 11:42:46 step 7: objective=0.112418 reg=0.005533
2017/08/30 11:42:46 Training value function...
2017/08/30 11:42:48 step 0: mse=0.174583 step=0.050000
2017/08/30 11:42:49 step 1: mse=0.172953 step=0.050000
2017/08/30 11:42:49 step 2: mse=0.171605 step=0.050000
2017/08/30 11:42:50 step 3: mse=0.170125 step=0.050000
2017/08/30 11:42:51 step 4: mse=0.168643 step=0.050000
2017/08/30 11:42:52 step 5: mse=0.167386 step=0.050000
2017/08/30 11:42:52 step 6: mse=0.165744 step=0.050000
2017/08/30 11:42:53 step 7: mse=0.164548 step=0.050000
2017/08/30 11:42:53 Saving...
2017/08/30 11:42:53 Gathering batch of experience...
2017/08/30 11:43:26 batch 30: mean=1.911290 stddev=1.270078 entropy=0.545945 frames=4346 count=124
2017/08/30 11:43:26 Training policy...
2017/08/30 11:43:28 tune 0: objective=0.117605 reg=0.005459 prune=0
2017/08/30 11:43:29 step 0: objective=0.117616 reg=0.005458
2017/08/30 11:43:30 step 1: objective=0.118120 reg=0.005442
2017/08/30 11:43:30 step 2: objective=0.118658 reg=0.005426
2017/08/30 11:43:31 step 3: objective=0.119168 reg=0.005409
2017/08/30 11:43:32 step 4: objective=0.119708 reg=0.005394
2017/08/30 11:43:33 step 5: objective=0.120166 reg=0.005378
2017/08/30 11:43:33 step 6: objective=0.120484 reg=0.005364
2017/08/30 11:43:34 step 7: objective=0.120814 reg=0.005353
2017/08/30 11:43:34 Training value function...
2017/08/30 11:43:36 step 0: mse=0.192649 step=0.050000
2017/08/30 11:43:37 step 1: mse=0.190255 step=0.050000
2017/08/30 11:43:37 step 2: mse=0.188272 step=0.050000
2017/08/30 11:43:38 step 3: mse=0.186161 step=0.050000
2017/08/30 11:43:39 step 4: mse=0.184508 step=0.050000
2017/08/30 11:43:40 step 5: mse=0.182550 step=0.050000
2017/08/30 11:43:40 step 6: mse=0.180920 step=0.050000
2017/08/30 11:43:41 step 7: mse=0.179179 step=0.050000
2017/08/30 11:43:41 Saving...
2017/08/30 11:43:41 Gathering batch of experience...
2017/08/30 11:44:14 batch 31: mean=2.008475 stddev=1.168047 entropy=0.528676 frames=4394 count=118
2017/08/30 11:44:14 Training policy...
2017/08/30 11:44:16 tune 0: objective=0.103166 reg=0.005287 prune=0
2017/08/30 11:44:17 step 0: objective=0.103178 reg=0.005286
2017/08/30 11:44:17 step 1: objective=0.103782 reg=0.005270
2017/08/30 11:44:18 step 2: objective=0.104410 reg=0.005252
2017/08/30 11:44:19 step 3: objective=0.104940 reg=0.005236
2017/08/30 11:44:19 step 4: objective=0.105520 reg=0.005221
2017/08/30 11:44:20 step 5: objective=0.105942 reg=0.005207
2017/08/30 11:44:21 step 6: objective=0.106296 reg=0.005196
2017/08/30 11:44:22 step 7: objective=0.106619 reg=0.005186
2017/08/30 11:44:22 Training value function...
2017/08/30 11:44:24 step 0: mse=0.174889 step=0.050000
2017/08/30 11:44:24 step 1: mse=0.173436 step=0.050000
2017/08/30 11:44:25 step 2: mse=0.172194 step=0.050000
2017/08/30 11:44:26 step 3: mse=0.171110 step=0.050000
2017/08/30 11:44:27 step 4: mse=0.170126 step=0.050000
2017/08/30 11:44:27 step 5: mse=0.169030 step=0.050000
2017/08/30 11:44:28 step 6: mse=0.168194 step=0.050000
2017/08/30 11:44:29 step 7: mse=0.167464 step=0.050000
2017/08/30 11:44:29 Saving...
2017/08/30 11:44:29 Gathering batch of experience...
2017/08/30 11:45:00 batch 32: mean=2.333333 stddev=1.515354 entropy=0.517083 frames=4469 count=108
2017/08/30 11:45:00 Training policy...
2017/08/30 11:45:02 tune 0: objective=0.138849 reg=0.005171 prune=0
2017/08/30 11:45:03 step 0: objective=0.138863 reg=0.005170
2017/08/30 11:45:04 step 1: objective=0.139457 reg=0.005154
2017/08/30 11:45:05 step 2: objective=0.140056 reg=0.005138
2017/08/30 11:45:05 step 3: objective=0.140664 reg=0.005120
2017/08/30 11:45:06 step 4: objective=0.141256 reg=0.005104
2017/08/30 11:45:07 step 5: objective=0.141712 reg=0.005092
2017/08/30 11:45:08 step 6: objective=0.142061 reg=0.005080
2017/08/30 11:45:08 step 7: objective=0.142317 reg=0.005073
2017/08/30 11:45:08 Training value function...
2017/08/30 11:45:10 step 0: mse=0.237044 step=0.050000
2017/08/30 11:45:11 step 1: mse=0.233733 step=0.050000
2017/08/30 11:45:12 step 2: mse=0.230826 step=0.050000
2017/08/30 11:45:13 step 3: mse=0.227772 step=0.050000
2017/08/30 11:45:13 step 4: mse=0.225189 step=0.050000
2017/08/30 11:45:14 step 5: mse=0.222819 step=0.050000
2017/08/30 11:45:15 step 6: mse=0.220756 step=0.050000
2017/08/30 11:45:16 step 7: mse=0.218714 step=0.050000
2017/08/30 11:45:16 Saving...
2017/08/30 11:45:16 Gathering batch of experience...
2017/08/30 11:45:48 batch 33: mean=2.443396 stddev=1.957473 entropy=0.500027 frames=4597 count=106
2017/08/30 11:45:48 Training policy...
2017/08/30 11:45:50 tune 0: objective=0.135633 reg=0.005000 prune=0
2017/08/30 11:45:51 step 0: objective=0.135649 reg=0.004999
2017/08/30 11:45:52 step 1: objective=0.136272 reg=0.004981
2017/08/30 11:45:52 step 2: objective=0.136802 reg=0.004961
2017/08/30 11:45:53 step 3: objective=0.137246 reg=0.004944
2017/08/30 11:45:54 step 4: objective=0.137805 reg=0.004927
2017/08/30 11:45:55 step 5: objective=0.138348 reg=0.004911
2017/08/30 11:45:55 step 6: objective=0.138654 reg=0.004899
2017/08/30 11:45:56 step 7: objective=0.138915 reg=0.004892
2017/08/30 11:45:56 Training value function...
2017/08/30 11:45:58 step 0: mse=0.272802 step=0.050000
2017/08/30 11:45:59 step 1: mse=0.268341 step=0.050000
2017/08/30 11:46:00 step 2: mse=0.264061 step=0.050000
2017/08/30 11:46:01 step 3: mse=0.260690 step=0.050000
2017/08/30 11:46:01 step 4: mse=0.257219 step=0.050000
2017/08/30 11:46:02 step 5: mse=0.254468 step=0.050000
2017/08/30 11:46:03 step 6: mse=0.251756 step=0.050000
2017/08/30 11:46:04 step 7: mse=0.249273 step=0.050000
2017/08/30 11:46:04 Saving...
2017/08/30 11:46:04 Gathering batch of experience...
2017/08/30 11:46:35 batch 34: mean=2.778947 stddev=1.925884 entropy=0.481179 frames=4602 count=95
2017/08/30 11:46:35 Training policy...
2017/08/30 11:46:37 tune 0: objective=0.145680 reg=0.004812 prune=0
2017/08/30 11:46:38 step 0: objective=0.145697 reg=0.004811
2017/08/30 11:46:38 step 1: objective=0.146238 reg=0.004791
2017/08/30 11:46:39 step 2: objective=0.146707 reg=0.004775
2017/08/30 11:46:40 step 3: objective=0.147232 reg=0.004757
2017/08/30 11:46:41 step 4: objective=0.147661 reg=0.004744
2017/08/30 11:46:41 step 5: objective=0.148025 reg=0.004732
2017/08/30 11:46:42 step 6: objective=0.148442 reg=0.004720
2017/08/30 11:46:43 step 7: objective=0.148703 reg=0.004708
2017/08/30 11:46:43 Training value function...
2017/08/30 11:46:45 step 0: mse=0.281559 step=0.050000
2017/08/30 11:46:46 step 1: mse=0.278087 step=0.050000
2017/08/30 11:46:46 step 2: mse=0.274914 step=0.050000
2017/08/30 11:46:47 step 3: mse=0.271841 step=0.050000
2017/08/30 11:46:48 step 4: mse=0.268471 step=0.050000
2017/08/30 11:46:49 step 5: mse=0.265742 step=0.050000
2017/08/30 11:46:50 step 6: mse=0.263140 step=0.050000
2017/08/30 11:46:50 step 7: mse=0.260516 step=0.050000
2017/08/30 11:46:50 Saving...
2017/08/30 11:46:50 Gathering batch of experience...
2017/08/30 11:47:21 batch 35: mean=2.752688 stddev=1.823714 entropy=0.473113 frames=4496 count=93
2017/08/30 11:47:21 Training policy...
2017/08/30 11:47:23 tune 0: objective=0.120161 reg=0.004731 prune=0
2017/08/30 11:47:24 step 0: objective=0.120176 reg=0.004730
2017/08/30 11:47:25 step 1: objective=0.120810 reg=0.004714
2017/08/30 11:47:25 step 2: objective=0.121427 reg=0.004700
2017/08/30 11:47:26 step 3: objective=0.122089 reg=0.004684
2017/08/30 11:47:27 step 4: objective=0.122622 reg=0.004669
2017/08/30 11:47:28 step 5: objective=0.123030 reg=0.004658
2017/08/30 11:47:28 step 6: objective=0.123441 reg=0.004650
2017/08/30 11:47:29 step 7: objective=0.123684 reg=0.004642
2017/08/30 11:47:29 Training value function...
2017/08/30 11:47:31 step 0: mse=0.241213 step=0.050000
2017/08/30 11:47:32 step 1: mse=0.239547 step=0.050000
2017/08/30 11:47:33 step 2: mse=0.237912 step=0.050000
2017/08/30 11:47:33 step 3: mse=0.236244 step=0.050000
2017/08/30 11:47:34 step 4: mse=0.234941 step=0.050000
2017/08/30 11:47:35 step 5: mse=0.233603 step=0.050000
2017/08/30 11:47:36 step 6: mse=0.232348 step=0.050000
2017/08/30 11:47:36 step 7: mse=0.230888 step=0.050000
2017/08/30 11:47:36 Saving...
2017/08/30 11:47:36 Gathering batch of experience...
2017/08/30 11:48:06 batch 36: mean=3.045977 stddev=2.105865 entropy=0.457950 frames=4566 count=87
2017/08/30 11:48:06 Training policy...
2017/08/30 11:48:08 tune 0: objective=0.137801 reg=0.004580 prune=0
2017/08/30 11:48:09 step 0: objective=0.137816 reg=0.004578
2017/08/30 11:48:09 step 1: objective=0.138376 reg=0.004564
2017/08/30 11:48:10 step 2: objective=0.138891 reg=0.004551
2017/08/30 11:48:11 step 3: objective=0.139368 reg=0.004536
2017/08/30 11:48:12 step 4: objective=0.139761 reg=0.004526
2017/08/30 11:48:13 step 5: objective=0.140218 reg=0.004513
2017/08/30 11:48:13 step 6: objective=0.140651 reg=0.004506
2017/08/30 11:48:14 step 7: objective=0.140960 reg=0.004500
2017/08/30 11:48:14 Training value function...
2017/08/30 11:48:16 step 0: mse=0.278462 step=0.050000
2017/08/30 11:48:17 step 1: mse=0.275546 step=0.050000
2017/08/30 11:48:18 step 2: mse=0.272738 step=0.050000
2017/08/30 11:48:18 step 3: mse=0.270059 step=0.050000
2017/08/30 11:48:19 step 4: mse=0.267616 step=0.050000
2017/08/30 11:48:20 step 5: mse=0.264921 step=0.050000
2017/08/30 11:48:21 step 6: mse=0.262726 step=0.050000
2017/08/30 11:48:21 step 7: mse=0.260456 step=0.050000
2017/08/30 11:48:21 Saving...
2017/08/30 11:48:21 Gathering batch of experience...
2017/08/30 11:48:51 batch 37: mean=3.070588 stddev=1.839362 entropy=0.446967 frames=4539 count=85
2017/08/30 11:48:51 Training policy...
2017/08/30 11:48:53 tune 0: objective=0.125272 reg=0.004470 prune=0
2017/08/30 11:48:54 step 0: objective=0.125286 reg=0.004469
2017/08/30 11:48:54 step 1: objective=0.125868 reg=0.004452
2017/08/30 11:48:55 step 2: objective=0.126537 reg=0.004436
2017/08/30 11:48:56 step 3: objective=0.127044 reg=0.004420
2017/08/30 11:48:57 step 4: objective=0.127466 reg=0.004404
2017/08/30 11:48:57 step 5: objective=0.127833 reg=0.004392
2017/08/30 11:48:58 step 6: objective=0.128054 reg=0.004381
2017/08/30 11:48:59 step 7: objective=0.128442 reg=0.004370
2017/08/30 11:48:59 Training value function...
2017/08/30 11:49:01 step 0: mse=0.253061 step=0.050000
2017/08/30 11:49:02 step 1: mse=0.250818 step=0.050000
2017/08/30 11:49:02 step 2: mse=0.248693 step=0.050000
2017/08/30 11:49:03 step 3: mse=0.245724 step=0.050000
2017/08/30 11:49:04 step 4: mse=0.243456 step=0.050000
2017/08/30 11:49:05 step 5: mse=0.241305 step=0.050000
2017/08/30 11:49:05 step 6: mse=0.239510 step=0.050000
2017/08/30 11:49:06 step 7: mse=0.237978 step=0.050000
2017/08/30 11:49:06 Saving...
2017/08/30 11:49:06 Gathering batch of experience...
2017/08/30 11:49:35 batch 38: mean=3.513514 stddev=2.428676 entropy=0.446409 frames=4483 count=74
2017/08/30 11:49:35 Training policy...
2017/08/30 11:49:37 tune 0: objective=0.137080 reg=0.004464 prune=0
2017/08/30 11:49:37 step 0: objective=0.137090 reg=0.004463
2017/08/30 11:49:38 step 1: objective=0.137765 reg=0.004449
2017/08/30 11:49:39 step 2: objective=0.138547 reg=0.004436
2017/08/30 11:49:40 step 3: objective=0.139000 reg=0.004422
2017/08/30 11:49:40 step 4: objective=0.139401 reg=0.004411
2017/08/30 11:49:41 step 5: objective=0.139814 reg=0.004401
2017/08/30 11:49:42 step 6: objective=0.140046 reg=0.004391
2017/08/30 11:49:43 step 7: objective=0.140340 reg=0.004381
2017/08/30 11:49:43 Training value function...
2017/08/30 11:49:44 step 0: mse=0.299330 step=0.050000
2017/08/30 11:49:45 step 1: mse=0.296167 step=0.050000
2017/08/30 11:49:46 step 2: mse=0.293273 step=0.050000
2017/08/30 11:49:47 step 3: mse=0.290316 step=0.050000
2017/08/30 11:49:48 step 4: mse=0.287280 step=0.050000
2017/08/30 11:49:48 step 5: mse=0.284881 step=0.050000
2017/08/30 11:49:49 step 6: mse=0.282188 step=0.050000
2017/08/30 11:49:50 step 7: mse=0.279946 step=0.050000
2017/08/30 11:49:50 Saving...
2017/08/30 11:49:50 Gathering batch of experience...
2017/08/30 11:50:20 batch 39: mean=3.864865 stddev=2.657597 entropy=0.425270 frames=4913 count=74
2017/08/30 11:50:20 Training policy...
2017/08/30 11:50:23 tune 0: objective=0.133559 reg=0.004253 prune=0
2017/08/30 11:50:23 step 0: objective=0.133571 reg=0.004252
2017/08/30 11:50:24 step 1: objective=0.134155 reg=0.004238
2017/08/30 11:50:25 step 2: objective=0.134575 reg=0.004227
2017/08/30 11:50:26 step 3: objective=0.135004 reg=0.004214
2017/08/30 11:50:27 step 4: objective=0.135390 reg=0.004203
2017/08/30 11:50:27 step 5: objective=0.135675 reg=0.004194
2017/08/30 11:50:28 step 6: objective=0.136109 reg=0.004184
2017/08/30 11:50:29 step 7: objective=0.136553 reg=0.004173
2017/08/30 11:50:29 Training value function...
2017/08/30 11:50:31 step 0: mse=0.313743 step=0.050000
2017/08/30 11:50:32 step 1: mse=0.310963 step=0.050000
2017/08/30 11:50:33 step 2: mse=0.308231 step=0.050000
2017/08/30 11:50:34 step 3: mse=0.305808 step=0.050000
2017/08/30 11:50:35 step 4: mse=0.303484 step=0.050000
2017/08/30 11:50:35 step 5: mse=0.301175 step=0.050000
2017/08/30 11:50:36 step 6: mse=0.299240 step=0.050000
2017/08/30 11:50:37 step 7: mse=0.297484 step=0.050000
2017/08/30 11:50:37 Saving...
2017/08/30 11:50:37 Gathering batch of experience...
2017/08/30 11:51:07 batch 40: mean=4.041667 stddev=2.855003 entropy=0.415936 frames=4905 count=72
2017/08/30 11:51:07 Training policy...
2017/08/30 11:51:09 tune 0: objective=0.142141 reg=0.004159 prune=0
2017/08/30 11:51:10 step 0: objective=0.142152 reg=0.004158
2017/08/30 11:51:11 step 1: objective=0.142661 reg=0.004149
2017/08/30 11:51:12 step 2: objective=0.143057 reg=0.004140
2017/08/30 11:51:13 step 3: objective=0.143363 reg=0.004130
2017/08/30 11:51:13 step 4: objective=0.143705 reg=0.004121
2017/08/30 11:51:14 step 5: objective=0.144146 reg=0.004113
2017/08/30 11:51:15 step 6: objective=0.144409 reg=0.004104
2017/08/30 11:51:16 step 7: objective=0.144701 reg=0.004095
2017/08/30 11:51:16 Training value function...
2017/08/30 11:51:18 step 0: mse=0.327675 step=0.050000
2017/08/30 11:51:19 step 1: mse=0.324148 step=0.050000
2017/08/30 11:51:20 step 2: mse=0.321041 step=0.050000
2017/08/30 11:51:20 step 3: mse=0.318284 step=0.050000
2017/08/30 11:51:21 step 4: mse=0.315521 step=0.050000
2017/08/30 11:51:22 step 5: mse=0.312748 step=0.050000
2017/08/30 11:51:23 step 6: mse=0.310324 step=0.050000
2017/08/30 11:51:24 step 7: mse=0.308147 step=0.050000
2017/08/30 11:51:24 Saving...
2017/08/30 11:51:24 Gathering batch of experience...
2017/08/30 11:51:54 batch 41: mean=4.646154 stddev=3.353211 entropy=0.396161 frames=5075 count=65
2017/08/30 11:51:54 Training policy...
2017/08/30 11:51:57 tune 0: objective=0.154123 reg=0.003962 prune=0
2017/08/30 11:51:58 step 0: objective=0.154132 reg=0.003961
2017/08/30 11:51:58 step 1: objective=0.154550 reg=0.003949
2017/08/30 11:51:59 step 2: objective=0.154950 reg=0.003937
2017/08/30 11:52:00 step 3: objective=0.155416 reg=0.003928
2017/08/30 11:52:01 step 4: objective=0.155688 reg=0.003920
2017/08/30 11:52:02 step 5: objective=0.156004 reg=0.003912
2017/08/30 11:52:03 step 6: objective=0.156271 reg=0.003902
2017/08/30 11:52:03 step 7: objective=0.156523 reg=0.003895
2017/08/30 11:52:03 Training value function...
2017/08/30 11:52:06 step 0: mse=0.357718 step=0.050000
2017/08/30 11:52:06 step 1: mse=0.353424 step=0.050000
2017/08/30 11:52:07 step 2: mse=0.348822 step=0.050000
2017/08/30 11:52:08 step 3: mse=0.345083 step=0.050000
2017/08/30 11:52:09 step 4: mse=0.341391 step=0.050000
2017/08/30 11:52:10 step 5: mse=0.337677 step=0.050000
2017/08/30 11:52:11 step 6: mse=0.333993 step=0.050000
2017/08/30 11:52:12 step 7: mse=0.330923 step=0.050000
2017/08/30 11:52:12 Saving...
2017/08/30 11:52:12 Gathering batch of experience...
2017/08/30 11:52:40 batch 42: mean=3.767123 stddev=2.747455 entropy=0.400223 frames=4701 count=73
2017/08/30 11:52:40 Training policy...
2017/08/30 11:52:43 tune 0: objective=0.096530 reg=0.004002 prune=0
2017/08/30 11:52:44 step 0: objective=0.096543 reg=0.004001
2017/08/30 11:52:44 step 1: objective=0.097084 reg=0.003989
2017/08/30 11:52:45 step 2: objective=0.097487 reg=0.003977
2017/08/30 11:52:46 step 3: objective=0.097804 reg=0.003967
2017/08/30 11:52:47 step 4: objective=0.098260 reg=0.003960
2017/08/30 11:52:47 step 5: objective=0.098473 reg=0.003954
2017/08/30 11:52:48 step 6: objective=0.098693 reg=0.003949
2017/08/30 11:52:49 step 7: objective=0.098957 reg=0.003944
2017/08/30 11:52:49 Training value function...
2017/08/30 11:52:51 step 0: mse=0.277369 step=0.050000
2017/08/30 11:52:52 step 1: mse=0.277073 step=0.050000
2017/08/30 11:52:53 step 2: mse=0.276944 step=0.050000
2017/08/30 11:52:53 step 3: mse=0.276409 step=0.050000
2017/08/30 11:52:54 step 4: mse=0.275786 step=0.050000
2017/08/30 11:52:55 step 5: mse=0.275106 step=0.050000
2017/08/30 11:52:56 step 6: mse=0.274940 step=0.050000
2017/08/30 11:52:57 step 7: mse=0.274685 step=0.050000
2017/08/30 11:52:57 Saving...
2017/08/30 11:52:57 Gathering batch of experience...
2017/08/30 11:53:25 batch 43: mean=4.596774 stddev=3.674058 entropy=0.389522 frames=4791 count=62
2017/08/30 11:53:25 Training policy...
2017/08/30 11:53:27 tune 0: objective=0.136876 reg=0.003895 prune=0
2017/08/30 11:53:28 step 0: objective=0.136885 reg=0.003894
2017/08/30 11:53:29 step 1: objective=0.137325 reg=0.003885
2017/08/30 11:53:29 step 2: objective=0.137844 reg=0.003872
2017/08/30 11:53:30 step 3: objective=0.138237 reg=0.003859
2017/08/30 11:53:31 step 4: objective=0.138553 reg=0.003852
2017/08/30 11:53:32 step 5: objective=0.138722 reg=0.003845
2017/08/30 11:53:33 step 6: objective=0.138974 reg=0.003839
2017/08/30 11:53:33 step 7: objective=0.139221 reg=0.003831
2017/08/30 11:53:33 Training value function...
2017/08/30 11:53:35 step 0: mse=0.338190 step=0.050000
2017/08/30 11:53:36 step 1: mse=0.335281 step=0.050000
2017/08/30 11:53:37 step 2: mse=0.332477 step=0.050000
2017/08/30 11:53:38 step 3: mse=0.329895 step=0.050000
2017/08/30 11:53:39 step 4: mse=0.327460 step=0.050000
2017/08/30 11:53:39 step 5: mse=0.325243 step=0.050000
2017/08/30 11:53:40 step 6: mse=0.323061 step=0.050000
2017/08/30 11:53:41 step 7: mse=0.320944 step=0.050000
2017/08/30 11:53:41 Saving...
2017/08/30 11:53:41 Gathering batch of experience...
2017/08/30 11:54:10 batch 44: mean=6.416667 stddev=5.187458 entropy=0.372864 frames=5087 count=48
2017/08/30 11:54:10 Training policy...
2017/08/30 11:54:12 tune 0: objective=0.176339 reg=0.003729 prune=0
2017/08/30 11:54:13 step 0: objective=0.176347 reg=0.003728
2017/08/30 11:54:14 step 1: objective=0.176838 reg=0.003719
2017/08/30 11:54:15 step 2: objective=0.177318 reg=0.003710
2017/08/30 11:54:16 step 3: objective=0.177891 reg=0.003700
2017/08/30 11:54:16 step 4: objective=0.178347 reg=0.003689
2017/08/30 11:54:17 step 5: objective=0.178636 reg=0.003681
2017/08/30 11:54:18 step 6: objective=0.179017 reg=0.003675
2017/08/30 11:54:19 step 7: objective=0.179242 reg=0.003670
2017/08/30 11:54:19 Training value function...
2017/08/30 11:54:21 step 0: mse=0.415697 step=0.050000
2017/08/30 11:54:22 step 1: mse=0.407671 step=0.050000
2017/08/30 11:54:23 step 2: mse=0.400295 step=0.050000
2017/08/30 11:54:24 step 3: mse=0.393643 step=0.050000
2017/08/30 11:54:25 step 4: mse=0.387077 step=0.050000
2017/08/30 11:54:25 step 5: mse=0.381269 step=0.050000
2017/08/30 11:54:26 step 6: mse=0.375827 step=0.050000
2017/08/30 11:54:27 step 7: mse=0.370751 step=0.050000
2017/08/30 11:54:27 Saving...
2017/08/30 11:54:27 Gathering batch of experience...
2017/08/30 11:54:55 batch 45: mean=5.155172 stddev=4.294350 entropy=0.370629 frames=5011 count=58
2017/08/30 11:54:55 Training policy...
2017/08/30 11:54:58 tune 0: objective=0.125755 reg=0.003706 prune=0
2017/08/30 11:54:59 step 0: objective=0.125768 reg=0.003705
2017/08/30 11:54:59 step 1: objective=0.126341 reg=0.003692
2017/08/30 11:55:00 step 2: objective=0.126832 reg=0.003679
2017/08/30 11:55:01 step 3: objective=0.127257 reg=0.003669
2017/08/30 11:55:02 step 4: objective=0.127585 reg=0.003664
2017/08/30 11:55:03 step 5: objective=0.127906 reg=0.003657
2017/08/30 11:55:03 step 6: objective=0.128064 reg=0.003651
2017/08/30 11:55:04 step 7: objective=0.128192 reg=0.003646
2017/08/30 11:55:04 Training value function...
2017/08/30 11:55:06 step 0: mse=0.346528 step=0.050000
2017/08/30 11:55:07 step 1: mse=0.343739 step=0.050000
2017/08/30 11:55:08 step 2: mse=0.341279 step=0.050000
2017/08/30 11:55:09 step 3: mse=0.338796 step=0.050000
2017/08/30 11:55:10 step 4: mse=0.336786 step=0.050000
2017/08/30 11:55:11 step 5: mse=0.334629 step=0.050000
2017/08/30 11:55:11 step 6: mse=0.332829 step=0.050000
2017/08/30 11:55:12 step 7: mse=0.331039 step=0.050000
2017/08/30 11:55:12 Saving...
2017/08/30 11:55:12 Gathering batch of experience...
2017/08/30 11:55:40 batch 46: mean=5.527273 stddev=4.343666 entropy=0.373317 frames=5011 count=55
2017/08/30 11:55:40 Training policy...
2017/08/30 11:55:43 tune 0: objective=0.139313 reg=0.003733 prune=0
2017/08/30 11:55:44 step 0: objective=0.139320 reg=0.003733
2017/08/30 11:55:45 step 1: objective=0.139736 reg=0.003726
2017/08/30 11:55:45 step 2: objective=0.140181 reg=0.003720
2017/08/30 11:55:46 step 3: objective=0.140535 reg=0.003712
2017/08/30 11:55:47 step 4: objective=0.140963 reg=0.003704
2017/08/30 11:55:48 step 5: objective=0.141240 reg=0.003698
2017/08/30 11:55:49 step 6: objective=0.141506 reg=0.003694
2017/08/30 11:55:49 step 7: objective=0.141654 reg=0.003692
2017/08/30 11:55:49 Training value function...
2017/08/30 11:55:51 step 0: mse=0.339564 step=0.050000
2017/08/30 11:55:52 step 1: mse=0.336271 step=0.050000
2017/08/30 11:55:53 step 2: mse=0.333602 step=0.050000
2017/08/30 11:55:54 step 3: mse=0.330853 step=0.050000
2017/08/30 11:55:55 step 4: mse=0.328508 step=0.050000
2017/08/30 11:55:56 step 5: mse=0.326231 step=0.050000
2017/08/30 11:55:57 step 6: mse=0.323996 step=0.050000
2017/08/30 11:55:57 step 7: mse=0.321657 step=0.050000
2017/08/30 11:55:57 Saving...
2017/08/30 11:55:57 Gathering batch of experience...
2017/08/30 11:56:25 batch 47: mean=5.070175 stddev=3.631537 entropy=0.376276 frames=4794 count=57
2017/08/30 11:56:25 Training policy...
2017/08/30 11:56:27 tune 0: objective=0.110782 reg=0.003763 prune=0
2017/08/30 11:56:28 step 0: objective=0.110792 reg=0.003762
2017/08/30 11:56:29 step 1: objective=0.111298 reg=0.003751
2017/08/30 11:56:30 step 2: objective=0.111623 reg=0.003741
2017/08/30 11:56:30 step 3: objective=0.111939 reg=0.003731
2017/08/30 11:56:31 step 4: objective=0.112215 reg=0.003720
2017/08/30 11:56:32 step 5: objective=0.112463 reg=0.003712
2017/08/30 11:56:33 step 6: objective=0.112710 reg=0.003705
2017/08/30 11:56:33 step 7: objective=0.113020 reg=0.003703
2017/08/30 11:56:33 Training value function...
2017/08/30 11:56:35 step 0: mse=0.302151 step=0.050000
2017/08/30 11:56:36 step 1: mse=0.300871 step=0.050000
2017/08/30 11:56:37 step 2: mse=0.299814 step=0.050000
2017/08/30 11:56:38 step 3: mse=0.298874 step=0.050000
2017/08/30 11:56:39 step 4: mse=0.298029 step=0.050000
2017/08/30 11:56:39 step 5: mse=0.297144 step=0.050000
2017/08/30 11:56:40 step 6: mse=0.296465 step=0.050000
2017/08/30 11:56:41 step 7: mse=0.295659 step=0.050000
2017/08/30 11:56:41 Saving...
2017/08/30 11:56:41 Gathering batch of experience...
2017/08/30 11:57:13 batch 48: mean=7.142857 stddev=6.464976 entropy=0.351562 frames=5718 count=49
2017/08/30 11:57:13 Training policy...
2017/08/30 11:57:16 tune 0: objective=0.172705 reg=0.003516 prune=0
2017/08/30 11:57:17 step 0: objective=0.172710 reg=0.003515
2017/08/30 11:57:18 step 1: objective=0.173108 reg=0.003511
2017/08/30 11:57:19 step 2: objective=0.173570 reg=0.003506
2017/08/30 11:57:20 step 3: objective=0.174018 reg=0.003501
2017/08/30 11:57:21 step 4: objective=0.174409 reg=0.003496
2017/08/30 11:57:21 step 5: objective=0.174709 reg=0.003490
2017/08/30 11:57:22 step 6: objective=0.174932 reg=0.003483
2017/08/30 11:57:23 step 7: objective=0.175195 reg=0.003476
2017/08/30 11:57:23 Training value function...
2017/08/30 11:57:26 step 0: mse=0.432612 step=0.050000
2017/08/30 11:57:27 step 1: mse=0.423737 step=0.050000
2017/08/30 11:57:28 step 2: mse=0.415574 step=0.050000
2017/08/30 11:57:29 step 3: mse=0.408011 step=0.050000
2017/08/30 11:57:30 step 4: mse=0.401120 step=0.050000
2017/08/30 11:57:31 step 5: mse=0.394624 step=0.050000
2017/08/30 11:57:32 step 6: mse=0.388322 step=0.050000
2017/08/30 11:57:32 step 7: mse=0.382620 step=0.050000
2017/08/30 11:57:32 Saving...
2017/08/30 11:57:32 Gathering batch of experience...
2017/08/30 11:58:02 batch 49: mean=6.869565 stddev=5.836946 entropy=0.353883 frames=5124 count=46
2017/08/30 11:58:02 Training policy...
2017/08/30 11:58:05 tune 0: objective=0.151765 reg=0.003539 prune=0
2017/08/30 11:58:06 step 0: objective=0.151770 reg=0.003538
2017/08/30 11:58:06 step 1: objective=0.152152 reg=0.003529
2017/08/30 11:58:07 step 2: objective=0.152467 reg=0.003523
2017/08/30 11:58:08 step 3: objective=0.152861 reg=0.003516
2017/08/30 11:58:09 step 4: objective=0.153203 reg=0.003507
2017/08/30 11:58:10 step 5: objective=0.153505 reg=0.003498
2017/08/30 11:58:11 step 6: objective=0.153750 reg=0.003490
2017/08/30 11:58:11 step 7: objective=0.154010 reg=0.003482
2017/08/30 11:58:11 Training value function...
2017/08/30 11:58:14 step 0: mse=0.358362 step=0.050000
2017/08/30 11:58:14 step 1: mse=0.353631 step=0.050000
2017/08/30 11:58:15 step 2: mse=0.349384 step=0.050000
2017/08/30 11:58:16 step 3: mse=0.345380 step=0.050000
2017/08/30 11:58:17 step 4: mse=0.341437 step=0.050000
2017/08/30 11:58:18 step 5: mse=0.337878 step=0.050000
2017/08/30 11:58:19 step 6: mse=0.334549 step=0.050000
2017/08/30 11:58:20 step 7: mse=0.331355 step=0.050000
2017/08/30 11:58:20 Saving...
2017/08/30 11:58:20 Gathering batch of experience...
2017/08/30 11:58:55 batch 50: mean=6.618182 stddev=6.431431 entropy=0.344843 frames=5884 count=55
2017/08/30 11:58:55 Training policy...
2017/08/30 11:58:58 tune 0: objective=0.132449 reg=0.003448 prune=0
2017/08/30 11:58:58 step 0: objective=0.132454 reg=0.003448
2017/08/30 11:58:59 step 1: objective=0.132857 reg=0.003442
2017/08/30 11:59:00 step 2: objective=0.133343 reg=0.003437
2017/08/30 11:59:01 step 3: objective=0.133691 reg=0.003434
2017/08/30 11:59:02 step 4: objective=0.134053 reg=0.003430
2017/08/30 11:59:03 step 5: objective=0.134309 reg=0.003427
2017/08/30 11:59:04 step 6: objective=0.134637 reg=0.003425
2017/08/30 11:59:05 step 7: objective=0.134877 reg=0.003423
2017/08/30 11:59:05 Training value function...
2017/08/30 11:59:08 step 0: mse=0.340985 step=0.050000
2017/08/30 11:59:09 step 1: mse=0.338106 step=0.050000
2017/08/30 11:59:10 step 2: mse=0.335195 step=0.050000
2017/08/30 11:59:11 step 3: mse=0.333017 step=0.050000
2017/08/30 11:59:12 step 4: mse=0.330439 step=0.050000
2017/08/30 11:59:13 step 5: mse=0.328005 step=0.050000
2017/08/30 11:59:14 step 6: mse=0.325910 step=0.050000
2017/08/30 11:59:15 step 7: mse=0.323944 step=0.050000
2017/08/30 11:59:15 Saving...
2017/08/30 11:59:15 Gathering batch of experience...
2017/08/30 11:59:48 batch 51: mean=7.872340 stddev=8.736368 entropy=0.344864 frames=6016 count=47
2017/08/30 11:59:48 Training policy...
2017/08/30 11:59:51 tune 0: objective=0.138697 reg=0.003449 prune=0
2017/08/30 11:59:52 step 0: objective=0.138701 reg=0.003448
2017/08/30 11:59:53 step 1: objective=0.139129 reg=0.003439
2017/08/30 11:59:54 step 2: objective=0.139521 reg=0.003428
2017/08/30 11:59:55 step 3: objective=0.139914 reg=0.003421
2017/08/30 11:59:56 step 4: objective=0.140199 reg=0.003413
2017/08/30 11:59:57 step 5: objective=0.140455 reg=0.003406
2017/08/30 11:59:58 step 6: objective=0.140640 reg=0.003399
2017/08/30 11:59:59 step 7: objective=0.140934 reg=0.003392
2017/08/30 11:59:59 Training value function...
2017/08/30 12:00:01 step 0: mse=0.379177 step=0.050000
2017/08/30 12:00:02 step 1: mse=0.374186 step=0.050000
2017/08/30 12:00:03 step 2: mse=0.370104 step=0.050000
2017/08/30 12:00:04 step 3: mse=0.366286 step=0.050000
2017/08/30 12:00:05 step 4: mse=0.362664 step=0.050000
2017/08/30 12:00:06 step 5: mse=0.359306 step=0.050000
2017/08/30 12:00:07 step 6: mse=0.356202 step=0.050000
2017/08/30 12:00:08 step 7: mse=0.353452 step=0.050000
2017/08/30 12:00:08 Saving...
2017/08/30 12:00:08 Gathering batch of experience...
2017/08/30 12:00:41 batch 52: mean=7.019608 stddev=6.053650 entropy=0.345275 frames=5783 count=51
2017/08/30 12:00:41 Training policy...
2017/08/30 12:00:44 tune 0: objective=0.129581 reg=0.003453 prune=0
2017/08/30 12:00:45 step 0: objective=0.129585 reg=0.003452
2017/08/30 12:00:46 step 1: objective=0.129887 reg=0.003445
2017/08/30 12:00:46 step 2: objective=0.130160 reg=0.003437
2017/08/30 12:00:47 step 3: objective=0.130409 reg=0.003431
2017/08/30 12:00:48 step 4: objective=0.130718 reg=0.003424
2017/08/30 12:00:49 step 5: objective=0.130902 reg=0.003417
2017/08/30 12:00:50 step 6: objective=0.131157 reg=0.003411
2017/08/30 12:00:51 step 7: objective=0.131364 reg=0.003408
2017/08/30 12:00:51 Training value function...
2017/08/30 12:00:54 step 0: mse=0.336299 step=0.050000
2017/08/30 12:00:55 step 1: mse=0.333965 step=0.050000
2017/08/30 12:00:56 step 2: mse=0.331853 step=0.050000
2017/08/30 12:00:57 step 3: mse=0.329898 step=0.050000
2017/08/30 12:00:58 step 4: mse=0.328177 step=0.050000
2017/08/30 12:00:59 step 5: mse=0.326461 step=0.050000
2017/08/30 12:01:00 step 6: mse=0.325089 step=0.050000
2017/08/30 12:01:01 step 7: mse=0.323482 step=0.050000
2017/08/30 12:01:01 Saving...
2017/08/30 12:01:01 Gathering batch of experience...
2017/08/30 12:01:32 batch 53: mean=7.888889 stddev=6.880640 entropy=0.332352 frames=5794 count=45
2017/08/30 12:01:32 Training policy...
2017/08/30 12:01:35 tune 0: objective=0.121101 reg=0.003324 prune=0
2017/08/30 12:01:36 step 0: objective=0.121105 reg=0.003323
2017/08/30 12:01:37 step 1: objective=0.121538 reg=0.003318
2017/08/30 12:01:38 step 2: objective=0.121876 reg=0.003314
2017/08/30 12:01:39 step 3: objective=0.122228 reg=0.003312
2017/08/30 12:01:39 step 4: objective=0.122434 reg=0.003311
2017/08/30 12:01:40 step 5: objective=0.122745 reg=0.003309
2017/08/30 12:01:41 step 6: objective=0.122953 reg=0.003307
2017/08/30 12:01:42 step 7: objective=0.123137 reg=0.003306
2017/08/30 12:01:42 Training value function...
2017/08/30 12:01:45 step 0: mse=0.355924 step=0.050000
2017/08/30 12:01:46 step 1: mse=0.354197 step=0.050000
2017/08/30 12:01:47 step 2: mse=0.352782 step=0.050000
2017/08/30 12:01:48 step 3: mse=0.351339 step=0.050000
2017/08/30 12:01:49 step 4: mse=0.350160 step=0.050000
2017/08/30 12:01:50 step 5: mse=0.349026 step=0.050000
2017/08/30 12:01:51 step 6: mse=0.347712 step=0.050000
2017/08/30 12:01:52 step 7: mse=0.346661 step=0.050000
2017/08/30 12:01:52 Saving...
2017/08/30 12:01:52 Gathering batch of experience...
2017/08/30 12:02:26 batch 54: mean=8.926829 stddev=8.448958 entropy=0.332356 frames=5909 count=41
2017/08/30 12:02:26 Training policy...
2017/08/30 12:02:29 tune 0: objective=0.143831 reg=0.003324 prune=0
2017/08/30 12:02:30 step 0: objective=0.143835 reg=0.003323
2017/08/30 12:02:31 step 1: objective=0.144268 reg=0.003319
2017/08/30 12:02:32 step 2: objective=0.144752 reg=0.003315
2017/08/30 12:02:33 step 3: objective=0.145041 reg=0.003310
2017/08/30 12:02:34 step 4: objective=0.145283 reg=0.003303
2017/08/30 12:02:35 step 5: objective=0.145437 reg=0.003299
2017/08/30 12:02:36 step 6: objective=0.145672 reg=0.003293
2017/08/30 12:02:37 step 7: objective=0.145953 reg=0.003289
2017/08/30 12:02:37 Training value function...
2017/08/30 12:02:39 step 0: mse=0.378771 step=0.050000
2017/08/30 12:02:40 step 1: mse=0.374287 step=0.050000
2017/08/30 12:02:41 step 2: mse=0.370720 step=0.050000
2017/08/30 12:02:42 step 3: mse=0.367592 step=0.050000
2017/08/30 12:02:43 step 4: mse=0.364286 step=0.050000
2017/08/30 12:02:44 step 5: mse=0.361711 step=0.050000
2017/08/30 12:02:45 step 6: mse=0.359364 step=0.050000
2017/08/30 12:02:46 step 7: mse=0.357288 step=0.050000
2017/08/30 12:02:46 Saving...
2017/08/30 12:02:46 Gathering batch of experience...
2017/08/30 12:03:20 batch 55: mean=11.351351 stddev=10.850872 entropy=0.318517 frames=6707 count=37
2017/08/30 12:03:20 Training policy...
2017/08/30 12:03:23 tune 0: objective=0.164466 reg=0.003185 prune=0
2017/08/30 12:03:24 step 0: objective=0.164468 reg=0.003185
2017/08/30 12:03:25 step 1: objective=0.164666 reg=0.003182
2017/08/30 12:03:26 step 2: objective=0.164936 reg=0.003180
2017/08/30 12:03:27 step 3: objective=0.165167 reg=0.003179
2017/08/30 12:03:28 step 4: objective=0.165376 reg=0.003176
2017/08/30 12:03:30 step 5: objective=0.165558 reg=0.003175
2017/08/30 12:03:31 step 6: objective=0.165713 reg=0.003174
2017/08/30 12:03:32 step 7: objective=0.165915 reg=0.003171
2017/08/30 12:03:32 Training value function...
2017/08/30 12:03:34 step 0: mse=0.400558 step=0.050000
2017/08/30 12:03:36 step 1: mse=0.393847 step=0.050000
2017/08/30 12:03:37 step 2: mse=0.387764 step=0.050000
2017/08/30 12:03:38 step 3: mse=0.382045 step=0.050000
2017/08/30 12:03:39 step 4: mse=0.376843 step=0.050000
2017/08/30 12:03:40 step 5: mse=0.371863 step=0.050000
2017/08/30 12:03:41 step 6: mse=0.367340 step=0.050000
2017/08/30 12:03:42 step 7: mse=0.363287 step=0.050000
2017/08/30 12:03:42 Saving...
2017/08/30 12:03:42 Gathering batch of experience...
2017/08/30 12:04:14 batch 56: mean=8.853659 stddev=7.253463 entropy=0.327803 frames=5849 count=41
2017/08/30 12:04:14 Training policy...
2017/08/30 12:04:17 tune 0: objective=0.126005 reg=0.003278 prune=0
2017/08/30 12:04:18 step 0: objective=0.126008 reg=0.003278
2017/08/30 12:04:19 step 1: objective=0.126240 reg=0.003274
2017/08/30 12:04:20 step 2: objective=0.126492 reg=0.003267
2017/08/30 12:04:21 step 3: objective=0.126791 reg=0.003261
2017/08/30 12:04:22 step 4: objective=0.127123 reg=0.003258
2017/08/30 12:04:22 step 5: objective=0.127433 reg=0.003252
2017/08/30 12:04:23 step 6: objective=0.127553 reg=0.003249
2017/08/30 12:04:24 step 7: objective=0.127894 reg=0.003245
2017/08/30 12:04:24 Training value function...
2017/08/30 12:04:27 step 0: mse=0.329733 step=0.050000
2017/08/30 12:04:28 step 1: mse=0.326294 step=0.050000
2017/08/30 12:04:29 step 2: mse=0.323829 step=0.050000
2017/08/30 12:04:30 step 3: mse=0.321891 step=0.050000
2017/08/30 12:04:31 step 4: mse=0.319352 step=0.050000
2017/08/30 12:04:32 step 5: mse=0.317066 step=0.050000
2017/08/30 12:04:33 step 6: mse=0.315418 step=0.050000
2017/08/30 12:04:34 step 7: mse=0.314068 step=0.050000
2017/08/30 12:04:34 Saving...
2017/08/30 12:04:34 Gathering batch of experience...
2017/08/30 12:05:11 batch 57: mean=9.697674 stddev=8.530479 entropy=0.315948 frames=6621 count=43
2017/08/30 12:05:11 Training policy...
2017/08/30 12:05:14 tune 0: objective=0.133847 reg=0.003159 prune=0
2017/08/30 12:05:16 step 0: objective=0.133850 reg=0.003159
2017/08/30 12:05:17 step 1: objective=0.134177 reg=0.003157
2017/08/30 12:05:18 step 2: objective=0.134579 reg=0.003155
2017/08/30 12:05:19 step 3: objective=0.134902 reg=0.003152
2017/08/30 12:05:20 step 4: objective=0.135237 reg=0.003149
2017/08/30 12:05:21 step 5: objective=0.135532 reg=0.003146
2017/08/30 12:05:22 step 6: objective=0.135834 reg=0.003144
2017/08/30 12:05:23 step 7: objective=0.136101 reg=0.003139
2017/08/30 12:05:23 Training value function...
2017/08/30 12:05:26 step 0: mse=0.332839 step=0.050000
2017/08/30 12:05:27 step 1: mse=0.331086 step=0.050000
2017/08/30 12:05:28 step 2: mse=0.329413 step=0.050000
2017/08/30 12:05:29 step 3: mse=0.327442 step=0.050000
2017/08/30 12:05:30 step 4: mse=0.326005 step=0.050000
2017/08/30 12:05:32 step 5: mse=0.324684 step=0.050000
2017/08/30 12:05:33 step 6: mse=0.323189 step=0.050000
2017/08/30 12:05:34 step 7: mse=0.322052 step=0.050000
2017/08/30 12:05:34 Saving...
2017/08/30 12:05:34 Gathering batch of experience...
2017/08/30 12:06:06 batch 58: mean=12.800000 stddev=8.681014 entropy=0.316861 frames=6106 count=30
2017/08/30 12:06:06 Training policy...
2017/08/30 12:06:10 tune 0: objective=0.143064 reg=0.003169 prune=0
2017/08/30 12:06:11 step 0: objective=0.143066 reg=0.003168
2017/08/30 12:06:12 step 1: objective=0.143251 reg=0.003169
2017/08/30 12:06:12 step 2: objective=0.143539 reg=0.003171
2017/08/30 12:06:13 step 3: objective=0.143804 reg=0.003172
2017/08/30 12:06:14 step 4: objective=0.144021 reg=0.003170
2017/08/30 12:06:15 step 5: objective=0.144130 reg=0.003168
2017/08/30 12:06:16 step 6: objective=0.144281 reg=0.003167
2017/08/30 12:06:17 step 7: objective=0.144586 reg=0.003167
2017/08/30 12:06:17 Training value function...
2017/08/30 12:06:20 step 0: mse=0.344359 step=0.050000
2017/08/30 12:06:21 step 1: mse=0.340860 step=0.050000
2017/08/30 12:06:22 step 2: mse=0.337568 step=0.050000
2017/08/30 12:06:23 step 3: mse=0.334462 step=0.050000
2017/08/30 12:06:24 step 4: mse=0.331868 step=0.050000
2017/08/30 12:06:25 step 5: mse=0.329057 step=0.050000
2017/08/30 12:06:26 step 6: mse=0.326529 step=0.050000
2017/08/30 12:06:27 step 7: mse=0.323898 step=0.050000
2017/08/30 12:06:27 Saving...
2017/08/30 12:06:27 Gathering batch of experience...
2017/08/30 12:06:59 batch 59: mean=9.486486 stddev=8.404058 entropy=0.324514 frames=5632 count=37
2017/08/30 12:06:59 Training policy...
2017/08/30 12:07:02 tune 0: objective=0.105875 reg=0.003245 prune=0
2017/08/30 12:07:03 step 0: objective=0.105877 reg=0.003245
2017/08/30 12:07:04 step 1: objective=0.106080 reg=0.003241
2017/08/30 12:07:05 step 2: objective=0.106268 reg=0.003236
2017/08/30 12:07:06 step 3: objective=0.106460 reg=0.003233
2017/08/30 12:07:06 step 4: objective=0.106668 reg=0.003227
2017/08/30 12:07:07 step 5: objective=0.106877 reg=0.003225
2017/08/30 12:07:08 step 6: objective=0.107011 reg=0.003223
2017/08/30 12:07:09 step 7: objective=0.107322 reg=0.003219
2017/08/30 12:07:09 Training value function...
2017/08/30 12:07:12 step 0: mse=0.310457 step=0.050000
2017/08/30 12:07:13 step 1: mse=0.309777 step=0.050000
2017/08/30 12:07:13 step 2: mse=0.309202 step=0.050000
2017/08/30 12:07:14 step 3: mse=0.308772 step=0.050000
2017/08/30 12:07:15 step 4: mse=0.308562 step=0.050000
2017/08/30 12:07:16 step 5: mse=0.308116 step=0.050000
2017/08/30 12:07:17 step 6: mse=0.307913 step=0.050000
2017/08/30 12:07:18 step 7: mse=0.307497 step=0.050000
2017/08/30 12:07:18 Saving...
2017/08/30 12:07:18 Gathering batch of experience...
2017/08/30 12:07:51 batch 60: mean=9.583333 stddev=8.622886 entropy=0.316860 frames=5589 count=36
2017/08/30 12:07:51 Training policy...
2017/08/30 12:07:53 tune 0: objective=0.110877 reg=0.003169 prune=0
2017/08/30 12:07:54 step 0: objective=0.110880 reg=0.003168
2017/08/30 12:07:55 step 1: objective=0.111217 reg=0.003164
2017/08/30 12:07:56 step 2: objective=0.111478 reg=0.003160
2017/08/30 12:07:57 step 3: objective=0.111890 reg=0.003155
2017/08/30 12:07:58 step 4: objective=0.112249 reg=0.003148
2017/08/30 12:07:59 step 5: objective=0.112503 reg=0.003142
2017/08/30 12:08:00 step 6: objective=0.112687 reg=0.003137
2017/08/30 12:08:01 step 7: objective=0.112833 reg=0.003135
2017/08/30 12:08:01 Training value function...
2017/08/30 12:08:03 step 0: mse=0.330358 step=0.050000
2017/08/30 12:08:04 step 1: mse=0.329547 step=0.050000
2017/08/30 12:08:05 step 2: mse=0.328765 step=0.050000
2017/08/30 12:08:06 step 3: mse=0.327322 step=0.050000
2017/08/30 12:08:07 step 4: mse=0.326386 step=0.050000
2017/08/30 12:08:08 step 5: mse=0.325821 step=0.050000
2017/08/30 12:08:09 step 6: mse=0.325018 step=0.050000
2017/08/30 12:08:10 step 7: mse=0.324391 step=0.050000
2017/08/30 12:08:10 Saving...
2017/08/30 12:08:10 Gathering batch of experience...
2017/08/30 12:08:41 batch 61: mean=10.351351 stddev=8.972077 entropy=0.314375 frames=6083 count=37
2017/08/30 12:08:41 Training policy...
2017/08/30 12:08:44 tune 0: objective=0.132923 reg=0.003144 prune=0
2017/08/30 12:08:45 step 0: objective=0.132927 reg=0.003143
2017/08/30 12:08:46 step 1: objective=0.133365 reg=0.003141
2017/08/30 12:08:47 step 2: objective=0.133762 reg=0.003137
2017/08/30 12:08:48 step 3: objective=0.134020 reg=0.003135
2017/08/30 12:08:49 step 4: objective=0.134450 reg=0.003132
2017/08/30 12:08:50 step 5: objective=0.134586 reg=0.003126
2017/08/30 12:08:51 step 6: objective=0.134849 reg=0.003123
2017/08/30 12:08:52 step 7: objective=0.134952 reg=0.003121
2017/08/30 12:08:52 Training value function...
2017/08/30 12:08:54 step 0: mse=0.332773 step=0.050000
2017/08/30 12:08:55 step 1: mse=0.331451 step=0.050000
2017/08/30 12:08:56 step 2: mse=0.329949 step=0.050000
2017/08/30 12:08:57 step 3: mse=0.328033 step=0.050000
2017/08/30 12:08:58 step 4: mse=0.326182 step=0.050000
2017/08/30 12:08:59 step 5: mse=0.324829 step=0.050000
2017/08/30 12:09:00 step 6: mse=0.323608 step=0.050000
2017/08/30 12:09:01 step 7: mse=0.322655 step=0.050000
2017/08/30 12:09:01 Saving...
2017/08/30 12:09:01 Gathering batch of experience...
2017/08/30 12:09:34 batch 62: mean=13.156250 stddev=9.357849 entropy=0.311516 frames=6703 count=32
2017/08/30 12:09:34 Training policy...
2017/08/30 12:09:38 tune 0: objective=0.141827 reg=0.003115 prune=0
2017/08/30 12:09:39 step 0: objective=0.141829 reg=0.003115
2017/08/30 12:09:40 step 1: objective=0.142061 reg=0.003113
2017/08/30 12:09:41 step 2: objective=0.142296 reg=0.003112
2017/08/30 12:09:42 step 3: objective=0.142439 reg=0.003109
2017/08/30 12:09:43 step 4: objective=0.142728 reg=0.003108
2017/08/30 12:09:44 step 5: objective=0.142950 reg=0.003108
2017/08/30 12:09:46 step 6: objective=0.143202 reg=0.003105
2017/08/30 12:09:47 step 7: objective=0.143305 reg=0.003103
2017/08/30 12:09:47 Training value function...
2017/08/30 12:09:49 step 0: mse=0.335037 step=0.050000
2017/08/30 12:09:51 step 1: mse=0.332097 step=0.050000
2017/08/30 12:09:52 step 2: mse=0.329416 step=0.050000
2017/08/30 12:09:53 step 3: mse=0.326770 step=0.050000
2017/08/30 12:09:54 step 4: mse=0.324583 step=0.050000
2017/08/30 12:09:55 step 5: mse=0.322529 step=0.050000
2017/08/30 12:09:56 step 6: mse=0.320727 step=0.050000
2017/08/30 12:09:57 step 7: mse=0.319030 step=0.050000
2017/08/30 12:09:57 Saving...
2017/08/30 12:09:57 Gathering batch of experience...
2017/08/30 12:10:32 batch 63: mean=10.275000 stddev=9.295126 entropy=0.308530 frames=6560 count=40
2017/08/30 12:10:32 Training policy...
2017/08/30 12:10:35 tune 0: objective=0.119728 reg=0.003085 prune=0
2017/08/30 12:10:36 step 0: objective=0.119731 reg=0.003085
2017/08/30 12:10:37 step 1: objective=0.120063 reg=0.003080
2017/08/30 12:10:38 step 2: objective=0.120330 reg=0.003079
2017/08/30 12:10:39 step 3: objective=0.120625 reg=0.003076
2017/08/30 12:10:40 step 4: objective=0.120899 reg=0.003074
2017/08/30 12:10:42 step 5: objective=0.121100 reg=0.003074
2017/08/30 12:10:43 step 6: objective=0.121364 reg=0.003074
2017/08/30 12:10:44 step 7: objective=0.121635 reg=0.003073
2017/08/30 12:10:44 Training value function...
2017/08/30 12:10:46 step 0: mse=0.326055 step=0.050000
2017/08/30 12:10:47 step 1: mse=0.325190 step=0.050000
2017/08/30 12:10:49 step 2: mse=0.324129 step=0.050000
2017/08/30 12:10:50 step 3: mse=0.323576 step=0.050000
2017/08/30 12:10:51 step 4: mse=0.322994 step=0.050000
2017/08/30 12:10:52 step 5: mse=0.322450 step=0.050000
2017/08/30 12:10:53 step 6: mse=0.322023 step=0.050000
2017/08/30 12:10:54 step 7: mse=0.321309 step=0.050000
2017/08/30 12:10:54 Saving...
2017/08/30 12:10:54 Gathering batch of experience...
2017/08/30 12:11:25 batch 64: mean=12.193548 stddev=7.385336 entropy=0.307854 frames=6051 count=31
2017/08/30 12:11:25 Training policy...
2017/08/30 12:11:28 tune 0: objective=0.125957 reg=0.003079 prune=0
2017/08/30 12:11:29 step 0: objective=0.125961 reg=0.003078
2017/08/30 12:11:30 step 1: objective=0.126339 reg=0.003074
2017/08/30 12:11:31 step 2: objective=0.126601 reg=0.003070
2017/08/30 12:11:32 step 3: objective=0.126866 reg=0.003066
2017/08/30 12:11:33 step 4: objective=0.127127 reg=0.003063
2017/08/30 12:11:34 step 5: objective=0.127415 reg=0.003061
2017/08/30 12:11:35 step 6: objective=0.127515 reg=0.003060
2017/08/30 12:11:36 step 7: objective=0.127615 reg=0.003061
2017/08/30 12:11:36 Training value function...
2017/08/30 12:11:38 step 0: mse=0.319086 step=0.050000
2017/08/30 12:11:39 step 1: mse=0.316677 step=0.050000
2017/08/30 12:11:40 step 2: mse=0.314663 step=0.050000
2017/08/30 12:11:41 step 3: mse=0.313055 step=0.050000
2017/08/30 12:11:42 step 4: mse=0.311353 step=0.050000
2017/08/30 12:11:43 step 5: mse=0.309712 step=0.050000
2017/08/30 12:11:44 step 6: mse=0.308423 step=0.050000
2017/08/30 12:11:45 step 7: mse=0.306908 step=0.050000
2017/08/30 12:11:45 Saving...
2017/08/30 12:11:45 Gathering batch of experience...
2017/08/30 12:12:22 batch 65: mean=12.085714 stddev=10.080735 entropy=0.300874 frames=6709 count=35
2017/08/30 12:12:22 Training policy...
2017/08/30 12:12:26 tune 0: objective=0.137762 reg=0.003009 prune=0
2017/08/30 12:12:27 step 0: objective=0.137764 reg=0.003009
2017/08/30 12:12:28 step 1: objective=0.138073 reg=0.003007
2017/08/30 12:12:29 step 2: objective=0.138309 reg=0.003004
2017/08/30 12:12:30 step 3: objective=0.138519 reg=0.003003
2017/08/30 12:12:31 step 4: objective=0.138738 reg=0.003001
2017/08/30 12:12:32 step 5: objective=0.138888 reg=0.003001
2017/08/30 12:12:33 step 6: objective=0.139194 reg=0.002998
2017/08/30 12:12:35 step 7: objective=0.139352 reg=0.002996
2017/08/30 12:12:35 Training value function...
2017/08/30 12:12:37 step 0: mse=0.329214 step=0.050000
2017/08/30 12:12:38 step 1: mse=0.327012 step=0.050000
2017/08/30 12:12:40 step 2: mse=0.324867 step=0.050000
2017/08/30 12:12:41 step 3: mse=0.322387 step=0.050000
2017/08/30 12:12:42 step 4: mse=0.320398 step=0.050000
2017/08/30 12:12:43 step 5: mse=0.318403 step=0.050000
2017/08/30 12:12:44 step 6: mse=0.316864 step=0.050000
2017/08/30 12:12:45 step 7: mse=0.315339 step=0.050000
2017/08/30 12:12:45 Saving...
2017/08/30 12:12:45 Gathering batch of experience...
2017/08/30 12:13:16 batch 66: mean=14.444444 stddev=10.723230 entropy=0.300460 frames=6122 count=27
2017/08/30 12:13:16 Training policy...
2017/08/30 12:13:19 tune 0: objective=0.153867 reg=0.003005 prune=0
2017/08/30 12:13:20 step 0: objective=0.153869 reg=0.003004
2017/08/30 12:13:21 step 1: objective=0.154136 reg=0.003004
2017/08/30 12:13:22 step 2: objective=0.154369 reg=0.003001
2017/08/30 12:13:23 step 3: objective=0.154578 reg=0.003000
2017/08/30 12:13:24 step 4: objective=0.154750 reg=0.002997
2017/08/30 12:13:25 step 5: objective=0.154859 reg=0.002994
2017/08/30 12:13:26 step 6: objective=0.155075 reg=0.002993
2017/08/30 12:13:27 step 7: objective=0.155256 reg=0.002989
2017/08/30 12:13:27 Training value function...
2017/08/30 12:13:30 step 0: mse=0.333744 step=0.050000
2017/08/30 12:13:31 step 1: mse=0.329488 step=0.050000
2017/08/30 12:13:32 step 2: mse=0.325807 step=0.050000
2017/08/30 12:13:33 step 3: mse=0.322340 step=0.050000
2017/08/30 12:13:34 step 4: mse=0.319362 step=0.050000
2017/08/30 12:13:35 step 5: mse=0.316540 step=0.050000
2017/08/30 12:13:36 step 6: mse=0.313718 step=0.050000
2017/08/30 12:13:37 step 7: mse=0.311244 step=0.050000
2017/08/30 12:13:37 Saving...
2017/08/30 12:13:37 Gathering batch of experience...
2017/08/30 12:14:10 batch 67: mean=11.176471 stddev=7.690600 entropy=0.304284 frames=6071 count=34
2017/08/30 12:14:10 Training policy...
2017/08/30 12:14:13 tune 0: objective=0.108554 reg=0.003043 prune=0
2017/08/30 12:14:14 step 0: objective=0.108557 reg=0.003043
2017/08/30 12:14:15 step 1: objective=0.108996 reg=0.003045
2017/08/30 12:14:16 step 2: objective=0.109401 reg=0.003045
2017/08/30 12:14:17 step 3: objective=0.109753 reg=0.003043
2017/08/30 12:14:18 step 4: objective=0.110008 reg=0.003038
2017/08/30 12:14:19 step 5: objective=0.110211 reg=0.003035
2017/08/30 12:14:20 step 6: objective=0.110484 reg=0.003031
2017/08/30 12:14:21 step 7: objective=0.110733 reg=0.003028
2017/08/30 12:14:21 Training value function...
2017/08/30 12:14:23 step 0: mse=0.294251 step=0.050000
2017/08/30 12:14:24 step 1: mse=0.294322 step=0.050000
2017/08/30 12:14:25 step 2: mse=0.294109 step=0.050000
2017/08/30 12:14:26 step 3: mse=0.294146 step=0.050000
2017/08/30 12:14:27 step 4: mse=0.294459 step=0.050000
2017/08/30 12:14:28 step 5: mse=0.293962 step=0.050000
2017/08/30 12:14:29 step 6: mse=0.294329 step=0.050000
2017/08/30 12:14:30 step 7: mse=0.294310 step=0.050000
2017/08/30 12:14:30 Saving...
2017/08/30 12:14:30 Gathering batch of experience...
2017/08/30 12:14:58 batch 68: mean=11.482759 stddev=9.061555 entropy=0.302924 frames=5337 count=29
2017/08/30 12:14:58 Training policy...
2017/08/30 12:15:01 tune 0: objective=0.115808 reg=0.003029 prune=0
2017/08/30 12:15:02 step 0: objective=0.115810 reg=0.003029
2017/08/30 12:15:03 step 1: objective=0.116221 reg=0.003028
2017/08/30 12:15:04 step 2: objective=0.116596 reg=0.003025
2017/08/30 12:15:05 step 3: objective=0.116935 reg=0.003024
2017/08/30 12:15:06 step 4: objective=0.117203 reg=0.003025
2017/08/30 12:15:06 step 5: objective=0.117487 reg=0.003023
2017/08/30 12:15:07 step 6: objective=0.117654 reg=0.003022
2017/08/30 12:15:08 step 7: objective=0.117871 reg=0.003021
2017/08/30 12:15:08 Training value function...
2017/08/30 12:15:10 step 0: mse=0.318436 step=0.050000
2017/08/30 12:15:11 step 1: mse=0.318401 step=0.050000
2017/08/30 12:15:12 step 2: mse=0.318191 step=0.050000
2017/08/30 12:15:13 step 3: mse=0.317918 step=0.050000
2017/08/30 12:15:14 step 4: mse=0.317995 step=0.050000
2017/08/30 12:15:15 step 5: mse=0.317615 step=0.050000
2017/08/30 12:15:16 step 6: mse=0.317826 step=0.050000
2017/08/30 12:15:17 step 7: mse=0.317753 step=0.050000
2017/08/30 12:15:17 Saving...
2017/08/30 12:15:17 Gathering batch of experience...
2017/08/30 12:15:52 batch 69: mean=12.527778 stddev=9.937265 entropy=0.299316 frames=7166 count=36
2017/08/30 12:15:52 Training policy...
2017/08/30 12:15:56 tune 0: objective=0.132330 reg=0.002993 prune=0
2017/08/30 12:15:57 step 0: objective=0.132331 reg=0.002993
2017/08/30 12:15:58 step 1: objective=0.132593 reg=0.002992
2017/08/30 12:15:59 step 2: objective=0.132702 reg=0.002990
2017/08/30 12:16:00 step 3: objective=0.132828 reg=0.002989
2017/08/30 12:16:02 step 4: objective=0.132953 reg=0.002987
2017/08/30 12:16:03 step 5: objective=0.133147 reg=0.002986
2017/08/30 12:16:04 step 6: objective=0.133309 reg=0.002988
2017/08/30 12:16:05 step 7: objective=0.133589 reg=0.002985
2017/08/30 12:16:05 Training value function...
2017/08/30 12:16:08 step 0: mse=0.321667 step=0.050000
2017/08/30 12:16:09 step 1: mse=0.319816 step=0.050000
2017/08/30 12:16:11 step 2: mse=0.318618 step=0.050000
2017/08/30 12:16:12 step 3: mse=0.317297 step=0.050000
2017/08/30 12:16:13 step 4: mse=0.315773 step=0.050000
2017/08/30 12:16:14 step 5: mse=0.314750 step=0.050000
2017/08/30 12:16:16 step 6: mse=0.313453 step=0.050000
2017/08/30 12:16:17 step 7: mse=0.312361 step=0.050000
2017/08/30 12:16:17 Saving...
2017/08/30 12:16:17 Gathering batch of experience...
2017/08/30 12:16:53 batch 70: mean=12.787879 stddev=11.387813 entropy=0.295389 frames=6706 count=33
2017/08/30 12:16:53 Training policy...
2017/08/30 12:16:56 tune 0: objective=0.132817 reg=0.002954 prune=0
2017/08/30 12:16:57 step 0: objective=0.132817 reg=0.002954
2017/08/30 12:16:59 step 1: objective=0.133010 reg=0.002950
2017/08/30 12:17:00 step 2: objective=0.133180 reg=0.002948
2017/08/30 12:17:01 step 3: objective=0.133408 reg=0.002945
2017/08/30 12:17:02 step 4: objective=0.133556 reg=0.002943
2017/08/30 12:17:03 step 5: objective=0.133724 reg=0.002940
2017/08/30 12:17:04 step 6: objective=0.133833 reg=0.002938
2017/08/30 12:17:05 step 7: objective=0.134079 reg=0.002936
2017/08/30 12:17:05 Training value function...
2017/08/30 12:17:08 step 0: mse=0.336176 step=0.050000
2017/08/30 12:17:09 step 1: mse=0.333141 step=0.050000
2017/08/30 12:17:10 step 2: mse=0.330737 step=0.050000
2017/08/30 12:17:11 step 3: mse=0.328451 step=0.050000
2017/08/30 12:17:12 step 4: mse=0.325875 step=0.050000
2017/08/30 12:17:14 step 5: mse=0.323790 step=0.050000
2017/08/30 12:17:15 step 6: mse=0.321830 step=0.050000
2017/08/30 12:17:16 step 7: mse=0.320809 step=0.050000
2017/08/30 12:17:16 Saving...
2017/08/30 12:17:16 Gathering batch of experience...
2017/08/30 12:17:52 batch 71: mean=11.714286 stddev=9.626070 entropy=0.293826 frames=6547 count=35
2017/08/30 12:17:52 Training policy...
2017/08/30 12:17:55 tune 0: objective=0.119091 reg=0.002938 prune=0
2017/08/30 12:17:56 step 0: objective=0.119093 reg=0.002938
2017/08/30 12:17:57 step 1: objective=0.119264 reg=0.002936
2017/08/30 12:17:58 step 2: objective=0.119485 reg=0.002934
2017/08/30 12:17:59 step 3: objective=0.119674 reg=0.002932
2017/08/30 12:18:00 step 4: objective=0.120004 reg=0.002931
2017/08/30 12:18:01 step 5: objective=0.120202 reg=0.002931
2017/08/30 12:18:02 step 6: objective=0.120390 reg=0.002930
2017/08/30 12:18:04 step 7: objective=0.120682 reg=0.002930
2017/08/30 12:18:04 Training value function...
2017/08/30 12:18:06 step 0: mse=0.307124 step=0.050000
2017/08/30 12:18:07 step 1: mse=0.306237 step=0.050000
2017/08/30 12:18:09 step 2: mse=0.305429 step=0.050000
2017/08/30 12:18:10 step 3: mse=0.304718 step=0.050000
2017/08/30 12:18:11 step 4: mse=0.304099 step=0.050000
2017/08/30 12:18:12 step 5: mse=0.303234 step=0.050000
2017/08/30 12:18:13 step 6: mse=0.302285 step=0.050000
2017/08/30 12:18:14 step 7: mse=0.301743 step=0.050000
2017/08/30 12:18:14 Saving...
2017/08/30 12:18:14 Gathering batch of experience...
2017/08/30 12:18:48 batch 72: mean=15.148148 stddev=9.340092 entropy=0.295888 frames=6417 count=27
2017/08/30 12:18:48 Training policy...
2017/08/30 12:18:52 tune 0: objective=0.144493 reg=0.002959 prune=0
2017/08/30 12:18:53 step 0: objective=0.144494 reg=0.002959
2017/08/30 12:18:54 step 1: objective=0.144873 reg=0.002957
2017/08/30 12:18:55 step 2: objective=0.145137 reg=0.002956
2017/08/30 12:18:56 step 3: objective=0.145436 reg=0.002956
2017/08/30 12:18:57 step 4: objective=0.145659 reg=0.002955
2017/08/30 12:18:58 step 5: objective=0.145808 reg=0.002956
2017/08/30 12:18:59 step 6: objective=0.146021 reg=0.002953
2017/08/30 12:19:00 step 7: objective=0.146219 reg=0.002954
2017/08/30 12:19:00 Training value function...
2017/08/30 12:19:03 step 0: mse=0.308260 step=0.050000
2017/08/30 12:19:04 step 1: mse=0.305868 step=0.050000
2017/08/30 12:19:05 step 2: mse=0.303817 step=0.050000
2017/08/30 12:19:06 step 3: mse=0.301089 step=0.050000
2017/08/30 12:19:07 step 4: mse=0.298582 step=0.050000
2017/08/30 12:19:08 step 5: mse=0.296981 step=0.050000
2017/08/30 12:19:09 step 6: mse=0.295765 step=0.050000
2017/08/30 12:19:10 step 7: mse=0.294241 step=0.050000
2017/08/30 12:19:10 Saving...
2017/08/30 12:19:10 Gathering batch of experience...
2017/08/30 12:19:42 batch 73: mean=11.090909 stddev=7.174718 entropy=0.298093 frames=5861 count=33
2017/08/30 12:19:42 Training policy...
2017/08/30 12:19:45 tune 0: objective=0.102278 reg=0.002981 prune=0
2017/08/30 12:19:46 step 0: objective=0.102280 reg=0.002981
2017/08/30 12:19:47 step 1: objective=0.102596 reg=0.002979
2017/08/30 12:19:48 step 2: objective=0.102885 reg=0.002979
2017/08/30 12:19:49 step 3: objective=0.103173 reg=0.002980
2017/08/30 12:19:50 step 4: objective=0.103393 reg=0.002979
2017/08/30 12:19:51 step 5: objective=0.103693 reg=0.002979
2017/08/30 12:19:52 step 6: objective=0.103942 reg=0.002979
2017/08/30 12:19:53 step 7: objective=0.104188 reg=0.002976
2017/08/30 12:19:53 Training value function...
2017/08/30 12:19:55 step 0: mse=0.280464 step=0.050000
2017/08/30 12:19:56 step 1: mse=0.281320 step=0.050000
2017/08/30 12:19:57 step 2: mse=0.281862 step=0.050000
2017/08/30 12:19:58 step 3: mse=0.282513 step=0.050000
2017/08/30 12:19:59 step 4: mse=0.282962 step=0.050000
2017/08/30 12:20:00 step 5: mse=0.283777 step=0.050000
2017/08/30 12:20:01 step 6: mse=0.284209 step=0.050000
2017/08/30 12:20:02 step 7: mse=0.284941 step=0.050000
2017/08/30 12:20:02 Saving...
2017/08/30 12:20:02 Gathering batch of experience...
2017/08/30 12:20:34 batch 74: mean=14.185185 stddev=10.746359 entropy=0.294290 frames=6061 count=27
2017/08/30 12:20:34 Training policy...
2017/08/30 12:20:37 tune 0: objective=0.138836 reg=0.002943 prune=0
2017/08/30 12:20:38 step 0: objective=0.138839 reg=0.002943
2017/08/30 12:20:39 step 1: objective=0.139185 reg=0.002937
2017/08/30 12:20:40 step 2: objective=0.139580 reg=0.002932
2017/08/30 12:20:41 step 3: objective=0.139851 reg=0.002928
2017/08/30 12:20:42 step 4: objective=0.140033 reg=0.002925
2017/08/30 12:20:43 step 5: objective=0.140254 reg=0.002921
2017/08/30 12:20:44 step 6: objective=0.140532 reg=0.002918
2017/08/30 12:20:45 step 7: objective=0.140731 reg=0.002913
2017/08/30 12:20:45 Training value function...
2017/08/30 12:20:48 step 0: mse=0.323988 step=0.050000
2017/08/30 12:20:49 step 1: mse=0.321146 step=0.050000
2017/08/30 12:20:50 step 2: mse=0.319199 step=0.050000
2017/08/30 12:20:51 step 3: mse=0.317177 step=0.050000
2017/08/30 12:20:52 step 4: mse=0.315277 step=0.050000
2017/08/30 12:20:53 step 5: mse=0.313644 step=0.050000
2017/08/30 12:20:54 step 6: mse=0.311942 step=0.050000
2017/08/30 12:20:55 step 7: mse=0.310278 step=0.050000
2017/08/30 12:20:55 Saving...
2017/08/30 12:20:55 Gathering batch of experience...
2017/08/30 12:21:28 batch 75: mean=13.400000 stddev=10.339568 entropy=0.289816 frames=6360 count=30
2017/08/30 12:21:28 Training policy...
2017/08/30 12:21:31 tune 0: objective=0.129850 reg=0.002898 prune=0
2017/08/30 12:21:32 step 0: objective=0.129851 reg=0.002898
2017/08/30 12:21:33 step 1: objective=0.130051 reg=0.002895
2017/08/30 12:21:34 step 2: objective=0.130401 reg=0.002892
2017/08/30 12:21:35 step 3: objective=0.130550 reg=0.002890
2017/08/30 12:21:36 step 4: objective=0.130784 reg=0.002888
2017/08/30 12:21:37 step 5: objective=0.130930 reg=0.002884
2017/08/30 12:21:38 step 6: objective=0.131154 reg=0.002883
2017/08/30 12:21:39 step 7: objective=0.131376 reg=0.002879
2017/08/30 12:21:39 Training value function...
2017/08/30 12:21:42 step 0: mse=0.310325 step=0.050000
2017/08/30 12:21:43 step 1: mse=0.309066 step=0.050000
2017/08/30 12:21:44 step 2: mse=0.307753 step=0.050000
2017/08/30 12:21:45 step 3: mse=0.306487 step=0.050000
2017/08/30 12:21:46 step 4: mse=0.305465 step=0.050000
2017/08/30 12:21:47 step 5: mse=0.303878 step=0.050000
2017/08/30 12:21:48 step 6: mse=0.303106 step=0.050000
2017/08/30 12:21:49 step 7: mse=0.302219 step=0.050000
2017/08/30 12:21:49 Saving...
2017/08/30 12:21:49 Gathering batch of experience...
2017/08/30 12:22:21 batch 76: mean=14.392857 stddev=11.702684 entropy=0.284608 frames=6375 count=28
2017/08/30 12:22:21 Training policy...
2017/08/30 12:22:24 tune 0: objective=0.133056 reg=0.002846 prune=0
2017/08/30 12:22:26 step 0: objective=0.133058 reg=0.002846
2017/08/30 12:22:27 step 1: objective=0.133256 reg=0.002844
2017/08/30 12:22:28 step 2: objective=0.133463 reg=0.002841
2017/08/30 12:22:29 step 3: objective=0.133637 reg=0.002839
2017/08/30 12:22:30 step 4: objective=0.133833 reg=0.002837
2017/08/30 12:22:31 step 5: objective=0.133918 reg=0.002835
2017/08/30 12:22:32 step 6: objective=0.133996 reg=0.002834
2017/08/30 12:22:33 step 7: objective=0.134149 reg=0.002832
2017/08/30 12:22:33 Training value function...
2017/08/30 12:22:35 step 0: mse=0.321949 step=0.050000
2017/08/30 12:22:37 step 1: mse=0.320722 step=0.050000
2017/08/30 12:22:38 step 2: mse=0.319524 step=0.050000
2017/08/30 12:22:39 step 3: mse=0.317925 step=0.050000
2017/08/30 12:22:40 step 4: mse=0.316645 step=0.050000
2017/08/30 12:22:41 step 5: mse=0.315429 step=0.050000
2017/08/30 12:22:42 step 6: mse=0.314492 step=0.050000
2017/08/30 12:22:43 step 7: mse=0.313753 step=0.050000
2017/08/30 12:22:43 Saving...
2017/08/30 12:22:43 Gathering batch of experience...
2017/08/30 12:23:16 batch 77: mean=11.235294 stddev=9.944135 entropy=0.290338 frames=6077 count=34
2017/08/30 12:23:16 Training policy...
2017/08/30 12:23:19 tune 0: objective=0.113948 reg=0.002903 prune=0
2017/08/30 12:23:20 step 0: objective=0.113949 reg=0.002903
2017/08/30 12:23:21 step 1: objective=0.114310 reg=0.002900
2017/08/30 12:23:22 step 2: objective=0.114522 reg=0.002900
2017/08/30 12:23:23 step 3: objective=0.114925 reg=0.002899
2017/08/30 12:23:24 step 4: objective=0.115080 reg=0.002898
2017/08/30 12:23:25 step 5: objective=0.115230 reg=0.002895
2017/08/30 12:23:26 step 6: objective=0.115340 reg=0.002895
2017/08/30 12:23:27 step 7: objective=0.115416 reg=0.002896
2017/08/30 12:23:27 Training value function...
2017/08/30 12:23:30 step 0: mse=0.308340 step=0.050000
2017/08/30 12:23:31 step 1: mse=0.307452 step=0.050000
2017/08/30 12:23:32 step 2: mse=0.306656 step=0.050000
2017/08/30 12:23:33 step 3: mse=0.305732 step=0.050000
2017/08/30 12:23:34 step 4: mse=0.305250 step=0.050000
2017/08/30 12:23:35 step 5: mse=0.304819 step=0.050000
2017/08/30 12:23:36 step 6: mse=0.304178 step=0.050000
2017/08/30 12:23:37 step 7: mse=0.303438 step=0.050000
2017/08/30 12:23:37 Saving...
2017/08/30 12:23:37 Gathering batch of experience...
2017/08/30 12:24:11 batch 78: mean=14.178571 stddev=11.000174 entropy=0.284739 frames=6318 count=28
2017/08/30 12:24:11 Training policy...
2017/08/30 12:24:14 tune 0: objective=0.129588 reg=0.002847 prune=0
2017/08/30 12:24:15 step 0: objective=0.129589 reg=0.002847
2017/08/30 12:24:16 step 1: objective=0.129852 reg=0.002847
2017/08/30 12:24:17 step 2: objective=0.130033 reg=0.002846
2017/08/30 12:24:18 step 3: objective=0.130235 reg=0.002844
2017/08/30 12:24:19 step 4: objective=0.130506 reg=0.002843
2017/08/30 12:24:20 step 5: objective=0.130673 reg=0.002840
2017/08/30 12:24:21 step 6: objective=0.130862 reg=0.002840
2017/08/30 12:24:22 step 7: objective=0.131067 reg=0.002839
2017/08/30 12:24:22 Training value function...
2017/08/30 12:24:25 step 0: mse=0.309941 step=0.050000
2017/08/30 12:24:26 step 1: mse=0.307918 step=0.050000
2017/08/30 12:24:27 step 2: mse=0.306861 step=0.050000
2017/08/30 12:24:28 step 3: mse=0.305474 step=0.050000
2017/08/30 12:24:29 step 4: mse=0.304285 step=0.050000
2017/08/30 12:24:30 step 5: mse=0.303604 step=0.050000
2017/08/30 12:24:31 step 6: mse=0.303029 step=0.050000
2017/08/30 12:24:33 step 7: mse=0.302241 step=0.050000
2017/08/30 12:24:33 Saving...
2017/08/30 12:24:33 Gathering batch of experience...
2017/08/30 12:25:07 batch 79: mean=11.971429 stddev=11.330076 entropy=0.280519 frames=6661 count=35
2017/08/30 12:25:07 Training policy...
2017/08/30 12:25:11 tune 0: objective=0.118967 reg=0.002805 prune=0
2017/08/30 12:25:12 step 0: objective=0.118968 reg=0.002805
2017/08/30 12:25:13 step 1: objective=0.119159 reg=0.002803
2017/08/30 12:25:14 step 2: objective=0.119311 reg=0.002801
2017/08/30 12:25:15 step 3: objective=0.119476 reg=0.002798
2017/08/30 12:25:16 step 4: objective=0.119708 reg=0.002798
2017/08/30 12:25:17 step 5: objective=0.119902 reg=0.002796
2017/08/30 12:25:19 step 6: objective=0.120152 reg=0.002794
2017/08/30 12:25:20 step 7: objective=0.120327 reg=0.002792
2017/08/30 12:25:20 Training value function...
2017/08/30 12:25:22 step 0: mse=0.308297 step=0.050000
2017/08/30 12:25:23 step 1: mse=0.306825 step=0.050000
2017/08/30 12:25:25 step 2: mse=0.305578 step=0.050000
2017/08/30 12:25:26 step 3: mse=0.304275 step=0.050000
2017/08/30 12:25:27 step 4: mse=0.302995 step=0.050000
2017/08/30 12:25:28 step 5: mse=0.302045 step=0.050000
2017/08/30 12:25:29 step 6: mse=0.301204 step=0.050000
2017/08/30 12:25:30 step 7: mse=0.300544 step=0.050000
2017/08/30 12:25:30 Saving...
2017/08/30 12:25:30 Gathering batch of experience...
2017/08/30 12:26:03 batch 80: mean=14.285714 stddev=10.291665 entropy=0.280572 frames=6348 count=28
2017/08/30 12:26:03 Training policy...
2017/08/30 12:26:07 tune 0: objective=0.127827 reg=0.002806 prune=0
2017/08/30 12:26:08 step 0: objective=0.127829 reg=0.002806
2017/08/30 12:26:09 step 1: objective=0.128005 reg=0.002801
2017/08/30 12:26:10 step 2: objective=0.128290 reg=0.002797
2017/08/30 12:26:11 step 3: objective=0.128522 reg=0.002794
2017/08/30 12:26:12 step 4: objective=0.128747 reg=0.002792
2017/08/30 12:26:13 step 5: objective=0.128961 reg=0.002790
2017/08/30 12:26:14 step 6: objective=0.129123 reg=0.002789
2017/08/30 12:26:15 step 7: objective=0.129260 reg=0.002787
2017/08/30 12:26:15 Training value function...
2017/08/30 12:26:18 step 0: mse=0.309267 step=0.050000
2017/08/30 12:26:19 step 1: mse=0.308430 step=0.050000
2017/08/30 12:26:20 step 2: mse=0.307602 step=0.050000
2017/08/30 12:26:21 step 3: mse=0.306803 step=0.050000
2017/08/30 12:26:22 step 4: mse=0.306066 step=0.050000
2017/08/30 12:26:23 step 5: mse=0.305454 step=0.050000
2017/08/30 12:26:24 step 6: mse=0.304752 step=0.050000
2017/08/30 12:26:25 step 7: mse=0.304269 step=0.050000
2017/08/30 12:26:25 Saving...
2017/08/30 12:26:25 Gathering batch of experience...
2017/08/30 12:27:00 batch 81: mean=13.225806 stddev=9.979688 entropy=0.286172 frames=6519 count=31
2017/08/30 12:27:00 Training policy...
2017/08/30 12:27:03 tune 0: objective=0.121034 reg=0.002862 prune=0
2017/08/30 12:27:04 step 0: objective=0.121035 reg=0.002862
2017/08/30 12:27:05 step 1: objective=0.121234 reg=0.002860
2017/08/30 12:27:06 step 2: objective=0.121393 reg=0.002857
2017/08/30 12:27:08 step 3: objective=0.121545 reg=0.002854
2017/08/30 12:27:09 step 4: objective=0.121681 reg=0.002851
2017/08/30 12:27:10 step 5: objective=0.121822 reg=0.002850
2017/08/30 12:27:11 step 6: objective=0.122102 reg=0.002848
2017/08/30 12:27:12 step 7: objective=0.122275 reg=0.002846
2017/08/30 12:27:12 Training value function...
2017/08/30 12:27:15 step 0: mse=0.305247 step=0.050000
2017/08/30 12:27:16 step 1: mse=0.304355 step=0.050000
2017/08/30 12:27:17 step 2: mse=0.303626 step=0.050000
2017/08/30 12:27:18 step 3: mse=0.302847 step=0.050000
2017/08/30 12:27:19 step 4: mse=0.302148 step=0.050000
2017/08/30 12:27:20 step 5: mse=0.301856 step=0.050000
2017/08/30 12:27:21 step 6: mse=0.301273 step=0.050000
2017/08/30 12:27:22 step 7: mse=0.300702 step=0.050000
2017/08/30 12:27:22 Saving...
2017/08/30 12:27:22 Gathering batch of experience...
2017/08/30 12:27:57 batch 82: mean=15.137931 stddev=12.472657 entropy=0.282120 frames=6969 count=29
2017/08/30 12:27:57 Training policy...
2017/08/30 12:28:01 tune 0: objective=0.133654 reg=0.002821 prune=0
2017/08/30 12:28:02 step 0: objective=0.133656 reg=0.002821
2017/08/30 12:28:03 step 1: objective=0.133946 reg=0.002819
2017/08/30 12:28:04 step 2: objective=0.134208 reg=0.002818
2017/08/30 12:28:06 step 3: objective=0.134550 reg=0.002817
2017/08/30 12:28:07 step 4: objective=0.134796 reg=0.002815
2017/08/30 12:28:08 step 5: objective=0.135001 reg=0.002814
2017/08/30 12:28:09 step 6: objective=0.135182 reg=0.002812
2017/08/30 12:28:10 step 7: objective=0.135292 reg=0.002810
2017/08/30 12:28:10 Training value function...
2017/08/30 12:28:13 step 0: mse=0.320279 step=0.050000
2017/08/30 12:28:14 step 1: mse=0.317942 step=0.050000
2017/08/30 12:28:15 step 2: mse=0.315992 step=0.050000
2017/08/30 12:28:17 step 3: mse=0.314447 step=0.050000
2017/08/30 12:28:18 step 4: mse=0.312701 step=0.050000
2017/08/30 12:28:19 step 5: mse=0.311224 step=0.050000
2017/08/30 12:28:20 step 6: mse=0.309395 step=0.050000
2017/08/30 12:28:21 step 7: mse=0.308285 step=0.050000
2017/08/30 12:28:21 Saving...
2017/08/30 12:28:22 Gathering batch of experience...
2017/08/30 12:28:58 batch 83: mean=19.291667 stddev=12.105368 entropy=0.283932 frames=7291 count=24
2017/08/30 12:28:58 Training policy...
2017/08/30 12:29:02 tune 0: objective=0.144734 reg=0.002839 prune=0
2017/08/30 12:29:03 step 0: objective=0.144735 reg=0.002839
2017/08/30 12:29:05 step 1: objective=0.144953 reg=0.002836
2017/08/30 12:29:06 step 2: objective=0.145190 reg=0.002835
2017/08/30 12:29:07 step 3: objective=0.145465 reg=0.002833
2017/08/30 12:29:08 step 4: objective=0.145685 reg=0.002830
2017/08/30 12:29:09 step 5: objective=0.145921 reg=0.002827
2017/08/30 12:29:11 step 6: objective=0.146152 reg=0.002825
2017/08/30 12:29:12 step 7: objective=0.146291 reg=0.002822
2017/08/30 12:29:12 Training value function...
2017/08/30 12:29:15 step 0: mse=0.318848 step=0.050000
2017/08/30 12:29:16 step 1: mse=0.316339 step=0.050000
2017/08/30 12:29:17 step 2: mse=0.313930 step=0.050000
2017/08/30 12:29:19 step 3: mse=0.311106 step=0.050000
2017/08/30 12:29:20 step 4: mse=0.309163 step=0.050000
2017/08/30 12:29:21 step 5: mse=0.307233 step=0.050000
2017/08/30 12:29:22 step 6: mse=0.304811 step=0.050000
2017/08/30 12:29:24 step 7: mse=0.303151 step=0.050000
2017/08/30 12:29:24 Saving...
2017/08/30 12:29:24 Gathering batch of experience...
2017/08/30 12:29:54 batch 84: mean=14.884615 stddev=9.889104 entropy=0.284123 frames=6098 count=26
2017/08/30 12:29:54 Training policy...
2017/08/30 12:29:57 tune 0: objective=0.127899 reg=0.002841 prune=0
2017/08/30 12:29:58 step 0: objective=0.127899 reg=0.002841
2017/08/30 12:29:59 step 1: objective=0.128157 reg=0.002838
2017/08/30 12:30:00 step 2: objective=0.128479 reg=0.002838
2017/08/30 12:30:01 step 3: objective=0.128770 reg=0.002839
2017/08/30 12:30:02 step 4: objective=0.128956 reg=0.002839
2017/08/30 12:30:03 step 5: objective=0.129158 reg=0.002838
2017/08/30 12:30:04 step 6: objective=0.129321 reg=0.002837
2017/08/30 12:30:05 step 7: objective=0.129569 reg=0.002836
2017/08/30 12:30:05 Training value function...
2017/08/30 12:30:08 step 0: mse=0.286261 step=0.050000
2017/08/30 12:30:09 step 1: mse=0.284695 step=0.050000
2017/08/30 12:30:10 step 2: mse=0.283219 step=0.050000
2017/08/30 12:30:11 step 3: mse=0.281977 step=0.050000
2017/08/30 12:30:12 step 4: mse=0.280583 step=0.050000
2017/08/30 12:30:13 step 5: mse=0.279505 step=0.050000
2017/08/30 12:30:14 step 6: mse=0.278529 step=0.050000
2017/08/30 12:30:15 step 7: mse=0.277500 step=0.050000
2017/08/30 12:30:15 Saving...
2017/08/30 12:30:15 Gathering batch of experience...
2017/08/30 12:30:49 batch 85: mean=13.161290 stddev=10.311587 entropy=0.280856 frames=6450 count=31
2017/08/30 12:30:49 Training policy...
2017/08/30 12:30:53 tune 0: objective=0.113600 reg=0.002809 prune=0
2017/08/30 12:30:54 step 0: objective=0.113602 reg=0.002808
2017/08/30 12:30:55 step 1: objective=0.113863 reg=0.002805
2017/08/30 12:30:56 step 2: objective=0.114086 reg=0.002802
2017/08/30 12:30:57 step 3: objective=0.114322 reg=0.002799
2017/08/30 12:30:58 step 4: objective=0.114465 reg=0.002797
2017/08/30 12:30:59 step 5: objective=0.114703 reg=0.002796
2017/08/30 12:31:00 step 6: objective=0.114856 reg=0.002795
2017/08/30 12:31:01 step 7: objective=0.114982 reg=0.002795
2017/08/30 12:31:01 Training value function...
2017/08/30 12:31:04 step 0: mse=0.282296 step=0.050000
2017/08/30 12:31:05 step 1: mse=0.282108 step=0.050000
2017/08/30 12:31:06 step 2: mse=0.281965 step=0.050000
2017/08/30 12:31:07 step 3: mse=0.281630 step=0.050000
2017/08/30 12:31:08 step 4: mse=0.281551 step=0.050000
2017/08/30 12:31:09 step 5: mse=0.281478 step=0.050000
2017/08/30 12:31:11 step 6: mse=0.281674 step=0.050000
2017/08/30 12:31:12 step 7: mse=0.281766 step=0.050000
2017/08/30 12:31:12 Saving...
2017/08/30 12:31:12 Gathering batch of experience...
2017/08/30 12:31:46 batch 86: mean=19.545455 stddev=12.467147 entropy=0.277496 frames=6747 count=22
2017/08/30 12:31:46 Training policy...
2017/08/30 12:31:50 tune 0: objective=0.149262 reg=0.002775 prune=0
2017/08/30 12:31:51 step 0: objective=0.149262 reg=0.002775
2017/08/30 12:31:52 step 1: objective=0.149412 reg=0.002774
2017/08/30 12:31:53 step 2: objective=0.149552 reg=0.002774
2017/08/30 12:31:54 step 3: objective=0.149723 reg=0.002774
2017/08/30 12:31:56 step 4: objective=0.149840 reg=0.002774
2017/08/30 12:31:57 step 5: objective=0.150019 reg=0.002774
2017/08/30 12:31:58 step 6: objective=0.150214 reg=0.002774
2017/08/30 12:31:59 step 7: objective=0.150405 reg=0.002772
2017/08/30 12:31:59 Training value function...
2017/08/30 12:32:02 step 0: mse=0.313029 step=0.050000
2017/08/30 12:32:03 step 1: mse=0.309796 step=0.050000
2017/08/30 12:32:04 step 2: mse=0.306990 step=0.050000
2017/08/30 12:32:05 step 3: mse=0.304244 step=0.050000
2017/08/30 12:32:06 step 4: mse=0.301616 step=0.050000
2017/08/30 12:32:07 step 5: mse=0.299491 step=0.050000
2017/08/30 12:32:09 step 6: mse=0.297540 step=0.050000
2017/08/30 12:32:10 step 7: mse=0.295482 step=0.050000
2017/08/30 12:32:10 Saving...
2017/08/30 12:32:10 Gathering batch of experience...
2017/08/30 12:32:44 batch 87: mean=17.833333 stddev=12.502222 entropy=0.276584 frames=6710 count=24
2017/08/30 12:32:44 Training policy...
2017/08/30 12:32:48 tune 0: objective=0.136335 reg=0.002766 prune=0
2017/08/30 12:32:49 step 0: objective=0.136336 reg=0.002766
2017/08/30 12:32:50 step 1: objective=0.136502 reg=0.002763
2017/08/30 12:32:51 step 2: objective=0.136659 reg=0.002761
2017/08/30 12:32:52 step 3: objective=0.136780 reg=0.002759
2017/08/30 12:32:53 step 4: objective=0.136881 reg=0.002755
2017/08/30 12:32:54 step 5: objective=0.136966 reg=0.002752
2017/08/30 12:32:56 step 6: objective=0.137101 reg=0.002749
2017/08/30 12:32:57 step 7: objective=0.137209 reg=0.002747
2017/08/30 12:32:57 Training value function...
2017/08/30 12:32:59 step 0: mse=0.291144 step=0.050000
2017/08/30 12:33:01 step 1: mse=0.289772 step=0.050000
2017/08/30 12:33:02 step 2: mse=0.288563 step=0.050000
2017/08/30 12:33:03 step 3: mse=0.287534 step=0.050000
2017/08/30 12:33:04 step 4: mse=0.286599 step=0.050000
2017/08/30 12:33:05 step 5: mse=0.285849 step=0.050000
2017/08/30 12:33:06 step 6: mse=0.284759 step=0.050000
2017/08/30 12:33:07 step 7: mse=0.283804 step=0.050000
2017/08/30 12:33:07 Saving...
2017/08/30 12:33:07 Gathering batch of experience...
2017/08/30 12:33:43 batch 88: mean=16.269231 stddev=13.466647 entropy=0.275583 frames=6680 count=26
2017/08/30 12:33:43 Training policy...
2017/08/30 12:33:46 tune 0: objective=0.122078 reg=0.002756 prune=0
2017/08/30 12:33:47 step 0: objective=0.122079 reg=0.002756
2017/08/30 12:33:48 step 1: objective=0.122356 reg=0.002752
2017/08/30 12:33:49 step 2: objective=0.122636 reg=0.002749
2017/08/30 12:33:51 step 3: objective=0.122844 reg=0.002746
2017/08/30 12:33:52 step 4: objective=0.123037 reg=0.002744
2017/08/30 12:33:53 step 5: objective=0.123165 reg=0.002741
2017/08/30 12:33:54 step 6: objective=0.123338 reg=0.002738
2017/08/30 12:33:55 step 7: objective=0.123414 reg=0.002736
2017/08/30 12:33:55 Training value function...
2017/08/30 12:33:58 step 0: mse=0.293429 step=0.050000
2017/08/30 12:33:59 step 1: mse=0.292600 step=0.050000
2017/08/30 12:34:00 step 2: mse=0.291925 step=0.050000
2017/08/30 12:34:01 step 3: mse=0.291033 step=0.050000
2017/08/30 12:34:02 step 4: mse=0.290279 step=0.050000
2017/08/30 12:34:04 step 5: mse=0.289825 step=0.050000
2017/08/30 12:34:05 step 6: mse=0.289237 step=0.050000
2017/08/30 12:34:06 step 7: mse=0.288856 step=0.050000
2017/08/30 12:34:06 Saving...
2017/08/30 12:34:06 Gathering batch of experience...
2017/08/30 12:34:45 batch 89: mean=14.029412 stddev=12.671147 entropy=0.274756 frames=7518 count=34
2017/08/30 12:34:45 Training policy...
2017/08/30 12:34:49 tune 0: objective=0.121657 reg=0.002748 prune=0
2017/08/30 12:34:50 step 0: objective=0.121658 reg=0.002747
2017/08/30 12:34:51 step 1: objective=0.121833 reg=0.002746
2017/08/30 12:34:52 step 2: objective=0.122019 reg=0.002743
2017/08/30 12:34:54 step 3: objective=0.122221 reg=0.002740
2017/08/30 12:34:55 step 4: objective=0.122402 reg=0.002738
2017/08/30 12:34:56 step 5: objective=0.122548 reg=0.002737
2017/08/30 12:34:57 step 6: objective=0.122723 reg=0.002735
2017/08/30 12:34:59 step 7: objective=0.122883 reg=0.002733
2017/08/30 12:34:59 Training value function...
2017/08/30 12:35:02 step 0: mse=0.287450 step=0.050000
2017/08/30 12:35:03 step 1: mse=0.286861 step=0.050000
2017/08/30 12:35:04 step 2: mse=0.286573 step=0.050000
2017/08/30 12:35:06 step 3: mse=0.286091 step=0.050000
2017/08/30 12:35:07 step 4: mse=0.285693 step=0.050000
2017/08/30 12:35:08 step 5: mse=0.285613 step=0.050000
2017/08/30 12:35:10 step 6: mse=0.285412 step=0.050000
2017/08/30 12:35:11 step 7: mse=0.284883 step=0.050000
2017/08/30 12:35:11 Saving...
2017/08/30 12:35:11 Gathering batch of experience...
2017/08/30 12:35:46 batch 90: mean=17.000000 stddev=12.325583 entropy=0.271160 frames=6706 count=25
2017/08/30 12:35:46 Training policy...
2017/08/30 12:35:49 tune 0: objective=0.130684 reg=0.002712 prune=0
2017/08/30 12:35:50 step 0: objective=0.130686 reg=0.002712
2017/08/30 12:35:51 step 1: objective=0.130801 reg=0.002711
2017/08/30 12:35:53 step 2: objective=0.130936 reg=0.002710
2017/08/30 12:35:54 step 3: objective=0.131026 reg=0.002711
2017/08/30 12:35:55 step 4: objective=0.131150 reg=0.002710
2017/08/30 12:35:56 step 5: objective=0.131272 reg=0.002710
2017/08/30 12:35:57 step 6: objective=0.131392 reg=0.002710
2017/08/30 12:35:58 step 7: objective=0.131489 reg=0.002711
2017/08/30 12:35:58 Training value function...
2017/08/30 12:36:01 step 0: mse=0.298799 step=0.050000
2017/08/30 12:36:02 step 1: mse=0.297938 step=0.050000
2017/08/30 12:36:03 step 2: mse=0.296750 step=0.050000
2017/08/30 12:36:04 step 3: mse=0.295739 step=0.050000
2017/08/30 12:36:05 step 4: mse=0.294942 step=0.050000
2017/08/30 12:36:07 step 5: mse=0.294095 step=0.050000
2017/08/30 12:36:08 step 6: mse=0.292952 step=0.050000
2017/08/30 12:36:09 step 7: mse=0.292045 step=0.050000
2017/08/30 12:36:09 Saving...
2017/08/30 12:36:09 Gathering batch of experience...
2017/08/30 12:36:42 batch 91: mean=15.461538 stddev=10.127004 entropy=0.274559 frames=6343 count=26
2017/08/30 12:36:42 Training policy...
2017/08/30 12:36:46 tune 0: objective=0.121577 reg=0.002746 prune=0
2017/08/30 12:36:47 step 0: objective=0.121578 reg=0.002746
2017/08/30 12:36:48 step 1: objective=0.121758 reg=0.002746
2017/08/30 12:36:49 step 2: objective=0.121909 reg=0.002747
2017/08/30 12:36:50 step 3: objective=0.122065 reg=0.002746
2017/08/30 12:36:51 step 4: objective=0.122182 reg=0.002745
2017/08/30 12:36:52 step 5: objective=0.122307 reg=0.002744
2017/08/30 12:36:53 step 6: objective=0.122453 reg=0.002743
2017/08/30 12:36:54 step 7: objective=0.122610 reg=0.002742
2017/08/30 12:36:54 Training value function...
2017/08/30 12:36:57 step 0: mse=0.278869 step=0.050000
2017/08/30 12:36:58 step 1: mse=0.277869 step=0.050000
2017/08/30 12:36:59 step 2: mse=0.277288 step=0.050000
2017/08/30 12:37:00 step 3: mse=0.276728 step=0.050000
2017/08/30 12:37:01 step 4: mse=0.276766 step=0.050000
2017/08/30 12:37:02 step 5: mse=0.276337 step=0.050000
2017/08/30 12:37:03 step 6: mse=0.275874 step=0.050000
2017/08/30 12:37:04 step 7: mse=0.275727 step=0.050000
2017/08/30 12:37:04 Saving...
2017/08/30 12:37:04 Gathering batch of experience...
2017/08/30 12:37:41 batch 92: mean=16.307692 stddev=12.268688 entropy=0.271272 frames=6693 count=26
2017/08/30 12:37:41 Training policy...
2017/08/30 12:37:45 tune 0: objective=0.131094 reg=0.002713 prune=0
2017/08/30 12:37:46 step 0: objective=0.131094 reg=0.002713
2017/08/30 12:37:47 step 1: objective=0.131196 reg=0.002712
2017/08/30 12:37:48 step 2: objective=0.131294 reg=0.002711
2017/08/30 12:37:49 step 3: objective=0.131453 reg=0.002709
2017/08/30 12:37:50 step 4: objective=0.131581 reg=0.002709
2017/08/30 12:37:52 step 5: objective=0.131763 reg=0.002709
2017/08/30 12:37:53 step 6: objective=0.131963 reg=0.002707
2017/08/30 12:37:54 step 7: objective=0.132107 reg=0.002708
2017/08/30 12:37:54 Training value function...
2017/08/30 12:37:57 step 0: mse=0.292386 step=0.050000
2017/08/30 12:37:58 step 1: mse=0.291177 step=0.050000
2017/08/30 12:37:59 step 2: mse=0.290164 step=0.050000
2017/08/30 12:38:00 step 3: mse=0.289047 step=0.050000
2017/08/30 12:38:01 step 4: mse=0.288008 step=0.050000
2017/08/30 12:38:02 step 5: mse=0.287306 step=0.050000
2017/08/30 12:38:03 step 6: mse=0.286518 step=0.050000
2017/08/30 12:38:05 step 7: mse=0.285703 step=0.050000
2017/08/30 12:38:05 Saving...
2017/08/30 12:38:05 Gathering batch of experience...
2017/08/30 12:38:39 batch 93: mean=15.035714 stddev=11.127450 entropy=0.271355 frames=6668 count=28
2017/08/30 12:38:39 Training policy...
2017/08/30 12:38:43 tune 0: objective=0.118768 reg=0.002714 prune=0
2017/08/30 12:38:44 step 0: objective=0.118769 reg=0.002714
2017/08/30 12:38:45 step 1: objective=0.118976 reg=0.002713
2017/08/30 12:38:46 step 2: objective=0.119111 reg=0.002713
2017/08/30 12:38:47 step 3: objective=0.119268 reg=0.002713
2017/08/30 12:38:48 step 4: objective=0.119440 reg=0.002712
2017/08/30 12:38:50 step 5: objective=0.119525 reg=0.002711
2017/08/30 12:38:51 step 6: objective=0.119715 reg=0.002708
2017/08/30 12:38:52 step 7: objective=0.119954 reg=0.002708
2017/08/30 12:38:52 Training value function...
2017/08/30 12:38:54 step 0: mse=0.283489 step=0.050000
2017/08/30 12:38:56 step 1: mse=0.282985 step=0.050000
2017/08/30 12:38:57 step 2: mse=0.282666 step=0.050000
2017/08/30 12:38:58 step 3: mse=0.282484 step=0.050000
2017/08/30 12:38:59 step 4: mse=0.282363 step=0.050000
2017/08/30 12:39:00 step 5: mse=0.282027 step=0.050000
2017/08/30 12:39:01 step 6: mse=0.281823 step=0.050000
2017/08/30 12:39:02 step 7: mse=0.281827 step=0.050000
2017/08/30 12:39:02 Saving...
2017/08/30 12:39:02 Gathering batch of experience...
2017/08/30 12:39:41 batch 94: mean=18.222222 stddev=12.142162 entropy=0.270838 frames=7748 count=27
2017/08/30 12:39:41 Training policy...
2017/08/30 12:39:45 tune 0: objective=0.137897 reg=0.002708 prune=0
2017/08/30 12:39:46 step 0: objective=0.137898 reg=0.002708
2017/08/30 12:39:48 step 1: objective=0.138084 reg=0.002705
2017/08/30 12:39:49 step 2: objective=0.138212 reg=0.002703
2017/08/30 12:39:50 step 3: objective=0.138449 reg=0.002701
2017/08/30 12:39:52 step 4: objective=0.138594 reg=0.002700
2017/08/30 12:39:53 step 5: objective=0.138674 reg=0.002699
2017/08/30 12:39:54 step 6: objective=0.138898 reg=0.002697
2017/08/30 12:39:56 step 7: objective=0.139092 reg=0.002695
2017/08/30 12:39:56 Training value function...
2017/08/30 12:39:59 step 0: mse=0.304382 step=0.050000
2017/08/30 12:40:00 step 1: mse=0.303183 step=0.050000
2017/08/30 12:40:02 step 2: mse=0.301632 step=0.050000
2017/08/30 12:40:03 step 3: mse=0.300230 step=0.050000
2017/08/30 12:40:04 step 4: mse=0.298978 step=0.050000
2017/08/30 12:40:06 step 5: mse=0.297933 step=0.050000
2017/08/30 12:40:07 step 6: mse=0.296997 step=0.050000
2017/08/30 12:40:08 step 7: mse=0.296082 step=0.050000
2017/08/30 12:40:08 Saving...
2017/08/30 12:40:08 Gathering batch of experience...
2017/08/30 12:40:39 batch 95: mean=13.923077 stddev=12.949378 entropy=0.268150 frames=5734 count=26
2017/08/30 12:40:39 Training policy...
2017/08/30 12:40:42 tune 0: objective=0.117040 reg=0.002682 prune=0
2017/08/30 12:40:43 step 0: objective=0.117041 reg=0.002681
2017/08/30 12:40:44 step 1: objective=0.117237 reg=0.002681
2017/08/30 12:40:45 step 2: objective=0.117565 reg=0.002680
2017/08/30 12:40:46 step 3: objective=0.117826 reg=0.002679
2017/08/30 12:40:46 step 4: objective=0.118125 reg=0.002677
2017/08/30 12:40:47 step 5: objective=0.118264 reg=0.002675
2017/08/30 12:40:48 step 6: objective=0.118555 reg=0.002674
2017/08/30 12:40:49 step 7: objective=0.118742 reg=0.002674
2017/08/30 12:40:49 Training value function...
2017/08/30 12:40:52 step 0: mse=0.291362 step=0.050000
2017/08/30 12:40:53 step 1: mse=0.290645 step=0.050000
2017/08/30 12:40:54 step 2: mse=0.290208 step=0.050000
2017/08/30 12:40:55 step 3: mse=0.289998 step=0.050000
2017/08/30 12:40:56 step 4: mse=0.289386 step=0.050000
2017/08/30 12:40:57 step 5: mse=0.288805 step=0.050000
2017/08/30 12:40:57 step 6: mse=0.288307 step=0.050000
2017/08/30 12:40:58 step 7: mse=0.287704 step=0.050000
2017/08/30 12:40:58 Saving...
2017/08/30 12:40:58 Gathering batch of experience...
2017/08/30 12:41:36 batch 96: mean=16.750000 stddev=13.303128 entropy=0.273268 frames=7394 count=28
2017/08/30 12:41:36 Training policy...
2017/08/30 12:41:40 tune 0: objective=0.130475 reg=0.002733 prune=0
2017/08/30 12:41:41 step 0: objective=0.130477 reg=0.002733
2017/08/30 12:41:42 step 1: objective=0.130630 reg=0.002731
2017/08/30 12:41:44 step 2: objective=0.130770 reg=0.002728
2017/08/30 12:41:45 step 3: objective=0.130984 reg=0.002728
2017/08/30 12:41:46 step 4: objective=0.131108 reg=0.002727
2017/08/30 12:41:47 step 5: objective=0.131205 reg=0.002726
2017/08/30 12:41:48 step 6: objective=0.131341 reg=0.002727
2017/08/30 12:41:50 step 7: objective=0.131551 reg=0.002725
2017/08/30 12:41:50 Training value function...
2017/08/30 12:41:53 step 0: mse=0.299737 step=0.050000
2017/08/30 12:41:54 step 1: mse=0.298971 step=0.050000
2017/08/30 12:41:55 step 2: mse=0.298329 step=0.050000
2017/08/30 12:41:57 step 3: mse=0.297330 step=0.050000
2017/08/30 12:41:58 step 4: mse=0.296284 step=0.050000
2017/08/30 12:41:59 step 5: mse=0.295536 step=0.050000
2017/08/30 12:42:00 step 6: mse=0.295048 step=0.050000
2017/08/30 12:42:02 step 7: mse=0.294766 step=0.050000
2017/08/30 12:42:02 Saving...
2017/08/30 12:42:02 Gathering batch of experience...
2017/08/30 12:42:36 batch 97: mean=18.739130 stddev=12.480306 entropy=0.264365 frames=6717 count=23
2017/08/30 12:42:36 Training policy...
2017/08/30 12:42:39 tune 0: objective=0.144620 reg=0.002644 prune=0
2017/08/30 12:42:41 step 0: objective=0.144621 reg=0.002644
2017/08/30 12:42:42 step 1: objective=0.144888 reg=0.002642
2017/08/30 12:42:43 step 2: objective=0.145212 reg=0.002641
2017/08/30 12:42:44 step 3: objective=0.145410 reg=0.002638
2017/08/30 12:42:45 step 4: objective=0.145593 reg=0.002637
2017/08/30 12:42:46 step 5: objective=0.145720 reg=0.002636
2017/08/30 12:42:47 step 6: objective=0.145780 reg=0.002635
2017/08/30 12:42:48 step 7: objective=0.145870 reg=0.002635
2017/08/30 12:42:48 Training value function...
2017/08/30 12:42:51 step 0: mse=0.293367 step=0.050000
2017/08/30 12:42:52 step 1: mse=0.290662 step=0.050000
2017/08/30 12:42:53 step 2: mse=0.288575 step=0.050000
2017/08/30 12:42:55 step 3: mse=0.286601 step=0.050000
2017/08/30 12:42:56 step 4: mse=0.284646 step=0.050000
2017/08/30 12:42:57 step 5: mse=0.282963 step=0.050000
2017/08/30 12:42:58 step 6: mse=0.281450 step=0.050000
2017/08/30 12:42:59 step 7: mse=0.280132 step=0.050000
2017/08/30 12:42:59 Saving...
2017/08/30 12:42:59 Gathering batch of experience...
2017/08/30 12:43:38 batch 98: mean=20.416667 stddev=14.599990 entropy=0.262812 frames=7668 count=24
2017/08/30 12:43:38 Training policy...
2017/08/30 12:43:42 tune 0: objective=0.139857 reg=0.002628 prune=0
2017/08/30 12:43:43 step 0: objective=0.139857 reg=0.002628
2017/08/30 12:43:44 step 1: objective=0.139983 reg=0.002628
2017/08/30 12:43:46 step 2: objective=0.140051 reg=0.002627
2017/08/30 12:43:47 step 3: objective=0.140127 reg=0.002626
2017/08/30 12:43:48 step 4: objective=0.140208 reg=0.002626
2017/08/30 12:43:50 step 5: objective=0.140324 reg=0.002625
2017/08/30 12:43:51 step 6: objective=0.140446 reg=0.002623
2017/08/30 12:43:52 step 7: objective=0.140570 reg=0.002623
2017/08/30 12:43:52 Training value function...
2017/08/30 12:43:55 step 0: mse=0.292799 step=0.050000
2017/08/30 12:43:56 step 1: mse=0.290505 step=0.050000
2017/08/30 12:43:58 step 2: mse=0.288622 step=0.050000
2017/08/30 12:43:59 step 3: mse=0.286741 step=0.050000
2017/08/30 12:44:00 step 4: mse=0.284766 step=0.050000
2017/08/30 12:44:02 step 5: mse=0.283323 step=0.050000
2017/08/30 12:44:03 step 6: mse=0.281646 step=0.050000
2017/08/30 12:44:04 step 7: mse=0.280358 step=0.050000
2017/08/30 12:44:04 Saving...
2017/08/30 12:44:04 Gathering batch of experience...
2017/08/30 12:44:39 batch 99: mean=17.360000 stddev=11.760544 entropy=0.275051 frames=6856 count=25
2017/08/30 12:44:39 Training policy...
2017/08/30 12:44:43 tune 0: objective=0.116890 reg=0.002751 prune=0
2017/08/30 12:44:44 step 0: objective=0.116891 reg=0.002750
2017/08/30 12:44:45 step 1: objective=0.117139 reg=0.002752
2017/08/30 12:44:46 step 2: objective=0.117468 reg=0.002753
2017/08/30 12:44:47 step 3: objective=0.117600 reg=0.002753
2017/08/30 12:44:49 step 4: objective=0.117865 reg=0.002754
2017/08/30 12:44:50 step 5: objective=0.118009 reg=0.002754
2017/08/30 12:44:51 step 6: objective=0.118129 reg=0.002753
2017/08/30 12:44:52 step 7: objective=0.118248 reg=0.002752
2017/08/30 12:44:52 Training value function...
2017/08/30 12:44:55 step 0: mse=0.269720 step=0.050000
2017/08/30 12:44:56 step 1: mse=0.270407 step=0.050000
2017/08/30 12:44:57 step 2: mse=0.270802 step=0.050000
2017/08/30 12:44:58 step 3: mse=0.271041 step=0.050000
2017/08/30 12:44:59 step 4: mse=0.271524 step=0.050000
2017/08/30 12:45:01 step 5: mse=0.271911 step=0.050000
2017/08/30 12:45:02 step 6: mse=0.272123 step=0.050000
2017/08/30 12:45:03 step 7: mse=0.272217 step=0.050000
2017/08/30 12:45:03 Saving...
2017/08/30 12:45:03 Gathering batch of experience...
2017/08/30 12:45:39 batch 100: mean=16.370370 stddev=12.052810 entropy=0.261295 frames=6986 count=27
2017/08/30 12:45:39 Training policy...
2017/08/30 12:45:43 tune 0: objective=0.118396 reg=0.002613 prune=0
2017/08/30 12:45:44 step 0: objective=0.118397 reg=0.002613
2017/08/30 12:45:46 step 1: objective=0.118599 reg=0.002614
2017/08/30 12:45:47 step 2: objective=0.118692 reg=0.002614
2017/08/30 12:45:48 step 3: objective=0.118901 reg=0.002615
2017/08/30 12:45:49 step 4: objective=0.118990 reg=0.002615
2017/08/30 12:45:50 step 5: objective=0.119172 reg=0.002615
2017/08/30 12:45:51 step 6: objective=0.119333 reg=0.002615
2017/08/30 12:45:53 step 7: objective=0.119470 reg=0.002616
2017/08/30 12:45:53 Training value function...
2017/08/30 12:45:55 step 0: mse=0.288546 step=0.050000
2017/08/30 12:45:57 step 1: mse=0.288877 step=0.050000
2017/08/30 12:45:58 step 2: mse=0.289366 step=0.050000
2017/08/30 12:45:59 step 3: mse=0.289574 step=0.050000
2017/08/30 12:46:00 step 4: mse=0.290063 step=0.050000
2017/08/30 12:46:01 step 5: mse=0.290394 step=0.050000
2017/08/30 12:46:03 step 6: mse=0.290735 step=0.050000
2017/08/30 12:46:04 step 7: mse=0.291154 step=0.050000
2017/08/30 12:46:04 Saving...
2017/08/30 12:46:04 Gathering batch of experience...
2017/08/30 12:46:45 batch 101: mean=20.076923 stddev=12.673179 entropy=0.262374 frames=8194 count=26
2017/08/30 12:46:45 Training policy...
2017/08/30 12:46:49 tune 0: objective=0.139566 reg=0.002624 prune=0
2017/08/30 12:46:50 step 0: objective=0.139566 reg=0.002624
2017/08/30 12:46:52 step 1: objective=0.139792 reg=0.002622
2017/08/30 12:46:53 step 2: objective=0.139988 reg=0.002620
2017/08/30 12:46:54 step 3: objective=0.140153 reg=0.002619
2017/08/30 12:46:56 step 4: objective=0.140354 reg=0.002617
2017/08/30 12:46:57 step 5: objective=0.140530 reg=0.002615
2017/08/30 12:46:59 step 6: objective=0.140623 reg=0.002614
2017/08/30 12:47:00 step 7: objective=0.140687 reg=0.002614
2017/08/30 12:47:00 Training value function...
2017/08/30 12:47:03 step 0: mse=0.303221 step=0.050000
2017/08/30 12:47:05 step 1: mse=0.300809 step=0.050000
2017/08/30 12:47:06 step 2: mse=0.299081 step=0.050000
2017/08/30 12:47:08 step 3: mse=0.297179 step=0.050000
2017/08/30 12:47:09 step 4: mse=0.295072 step=0.050000
2017/08/30 12:47:10 step 5: mse=0.293891 step=0.050000
2017/08/30 12:47:12 step 6: mse=0.292921 step=0.050000
2017/08/30 12:47:13 step 7: mse=0.291820 step=0.050000
2017/08/30 12:47:13 Saving...
2017/08/30 12:47:13 Gathering batch of experience...
2017/08/30 12:47:52 batch 102: mean=19.875000 stddev=12.699450 entropy=0.263295 frames=7491 count=24
2017/08/30 12:47:52 Training policy...
2017/08/30 12:47:56 tune 0: objective=0.133335 reg=0.002633 prune=0
2017/08/30 12:47:57 step 0: objective=0.133337 reg=0.002633
2017/08/30 12:47:58 step 1: objective=0.133554 reg=0.002632
2017/08/30 12:48:00 step 2: objective=0.133682 reg=0.002632
2017/08/30 12:48:01 step 3: objective=0.133818 reg=0.002631
2017/08/30 12:48:02 step 4: objective=0.133920 reg=0.002632
2017/08/30 12:48:04 step 5: objective=0.134056 reg=0.002631
2017/08/30 12:48:05 step 6: objective=0.134155 reg=0.002629
2017/08/30 12:48:06 step 7: objective=0.134221 reg=0.002629
2017/08/30 12:48:06 Training value function...
2017/08/30 12:48:09 step 0: mse=0.288598 step=0.050000
2017/08/30 12:48:10 step 1: mse=0.287193 step=0.050000
2017/08/30 12:48:12 step 2: mse=0.286044 step=0.050000
2017/08/30 12:48:13 step 3: mse=0.284294 step=0.050000
2017/08/30 12:48:14 step 4: mse=0.282797 step=0.050000
2017/08/30 12:48:16 step 5: mse=0.281835 step=0.050000
2017/08/30 12:48:17 step 6: mse=0.280794 step=0.050000
2017/08/30 12:48:18 step 7: mse=0.280068 step=0.050000
2017/08/30 12:48:18 Saving...
2017/08/30 12:48:18 Gathering batch of experience...
2017/08/30 12:48:55 batch 103: mean=17.107143 stddev=13.151152 entropy=0.262910 frames=7560 count=28
2017/08/30 12:48:55 Training policy...
2017/08/30 12:48:59 tune 0: objective=0.120913 reg=0.002629 prune=0
2017/08/30 12:49:01 step 0: objective=0.120913 reg=0.002629
2017/08/30 12:49:02 step 1: objective=0.121080 reg=0.002629
2017/08/30 12:49:03 step 2: objective=0.121292 reg=0.002628
2017/08/30 12:49:05 step 3: objective=0.121438 reg=0.002628
2017/08/30 12:49:06 step 4: objective=0.121639 reg=0.002627
2017/08/30 12:49:07 step 5: objective=0.121741 reg=0.002625
2017/08/30 12:49:08 step 6: objective=0.121829 reg=0.002626
2017/08/30 12:49:10 step 7: objective=0.121956 reg=0.002624
2017/08/30 12:49:10 Training value function...
2017/08/30 12:49:13 step 0: mse=0.294179 step=0.050000
2017/08/30 12:49:14 step 1: mse=0.293692 step=0.050000
2017/08/30 12:49:15 step 2: mse=0.292714 step=0.050000
2017/08/30 12:49:17 step 3: mse=0.292145 step=0.050000
2017/08/30 12:49:18 step 4: mse=0.291800 step=0.050000
2017/08/30 12:49:19 step 5: mse=0.291399 step=0.050000
2017/08/30 12:49:21 step 6: mse=0.291042 step=0.050000
2017/08/30 12:49:22 step 7: mse=0.290490 step=0.050000
2017/08/30 12:49:22 Saving...
2017/08/30 12:49:22 Gathering batch of experience...
2017/08/30 12:49:58 batch 104: mean=22.952381 stddev=12.688488 entropy=0.264162 frames=7530 count=21
2017/08/30 12:49:58 Training policy...
2017/08/30 12:50:02 tune 0: objective=0.145007 reg=0.002642 prune=0
2017/08/30 12:50:03 step 0: objective=0.145008 reg=0.002642
2017/08/30 12:50:04 step 1: objective=0.145199 reg=0.002640
2017/08/30 12:50:05 step 2: objective=0.145368 reg=0.002640
2017/08/30 12:50:07 step 3: objective=0.145498 reg=0.002638
2017/08/30 12:50:08 step 4: objective=0.145608 reg=0.002639
2017/08/30 12:50:09 step 5: objective=0.145704 reg=0.002636
2017/08/30 12:50:10 step 6: objective=0.145814 reg=0.002636
2017/08/30 12:50:12 step 7: objective=0.145995 reg=0.002634
2017/08/30 12:50:12 Training value function...
2017/08/30 12:50:15 step 0: mse=0.287911 step=0.050000
2017/08/30 12:50:16 step 1: mse=0.285342 step=0.050000
2017/08/30 12:50:18 step 2: mse=0.282996 step=0.050000
2017/08/30 12:50:19 step 3: mse=0.280758 step=0.050000
2017/08/30 12:50:20 step 4: mse=0.278782 step=0.050000
2017/08/30 12:50:21 step 5: mse=0.276924 step=0.050000
2017/08/30 12:50:23 step 6: mse=0.274995 step=0.050000
2017/08/30 12:50:24 step 7: mse=0.273394 step=0.050000
2017/08/30 12:50:24 Saving...
2017/08/30 12:50:24 Gathering batch of experience...
2017/08/30 12:50:57 batch 105: mean=17.640000 stddev=11.889087 entropy=0.261334 frames=6950 count=25
2017/08/30 12:50:57 Training policy...
2017/08/30 12:51:01 tune 0: objective=0.117791 reg=0.002613 prune=0
2017/08/30 12:51:02 step 0: objective=0.117792 reg=0.002613
2017/08/30 12:51:03 step 1: objective=0.117939 reg=0.002614
2017/08/30 12:51:04 step 2: objective=0.118146 reg=0.002615
2017/08/30 12:51:05 step 3: objective=0.118301 reg=0.002613
2017/08/30 12:51:07 step 4: objective=0.118492 reg=0.002611
2017/08/30 12:51:08 step 5: objective=0.118582 reg=0.002611
2017/08/30 12:51:09 step 6: objective=0.118700 reg=0.002608
2017/08/30 12:51:10 step 7: objective=0.118834 reg=0.002610
2017/08/30 12:51:10 Training value function...
2017/08/30 12:51:13 step 0: mse=0.272268 step=0.050000
2017/08/30 12:51:14 step 1: mse=0.272420 step=0.050000
2017/08/30 12:51:15 step 2: mse=0.272544 step=0.050000
2017/08/30 12:51:16 step 3: mse=0.272647 step=0.050000
2017/08/30 12:51:18 step 4: mse=0.272659 step=0.050000
2017/08/30 12:51:19 step 5: mse=0.272726 step=0.050000
2017/08/30 12:51:20 step 6: mse=0.272922 step=0.050000
2017/08/30 12:51:21 step 7: mse=0.273325 step=0.050000
2017/08/30 12:51:21 Saving...
2017/08/30 12:51:21 Gathering batch of experience...
2017/08/30 12:51:56 batch 106: mean=19.090909 stddev=11.065545 entropy=0.266180 frames=6639 count=22
2017/08/30 12:51:56 Training policy...
2017/08/30 12:51:59 tune 0: objective=0.121493 reg=0.002662 prune=0
2017/08/30 12:52:00 step 0: objective=0.121494 reg=0.002662
2017/08/30 12:52:01 step 1: objective=0.121636 reg=0.002662
2017/08/30 12:52:02 step 2: objective=0.121879 reg=0.002663
2017/08/30 12:52:04 step 3: objective=0.122122 reg=0.002663
2017/08/30 12:52:05 step 4: objective=0.122353 reg=0.002664
2017/08/30 12:52:06 step 5: objective=0.122589 reg=0.002663
2017/08/30 12:52:07 step 6: objective=0.122673 reg=0.002661
2017/08/30 12:52:08 step 7: objective=0.122773 reg=0.002660
2017/08/30 12:52:08 Training value function...
2017/08/30 12:52:11 step 0: mse=0.277030 step=0.050000
2017/08/30 12:52:12 step 1: mse=0.276713 step=0.050000
2017/08/30 12:52:13 step 2: mse=0.276464 step=0.050000
2017/08/30 12:52:14 step 3: mse=0.276164 step=0.050000
2017/08/30 12:52:15 step 4: mse=0.275930 step=0.050000
2017/08/30 12:52:16 step 5: mse=0.275404 step=0.050000
2017/08/30 12:52:17 step 6: mse=0.275608 step=0.050000
2017/08/30 12:52:19 step 7: mse=0.275700 step=0.050000
2017/08/30 12:52:19 Saving...
2017/08/30 12:52:19 Gathering batch of experience...
2017/08/30 12:52:58 batch 107: mean=20.680000 stddev=14.240000 entropy=0.254726 frames=8098 count=25
2017/08/30 12:52:58 Training policy...
2017/08/30 12:53:02 tune 0: objective=0.137702 reg=0.002547 prune=0
2017/08/30 12:53:03 step 0: objective=0.137702 reg=0.002547
2017/08/30 12:53:05 step 1: objective=0.137802 reg=0.002547
2017/08/30 12:53:06 step 2: objective=0.137905 reg=0.002547
2017/08/30 12:53:08 step 3: objective=0.138067 reg=0.002547
2017/08/30 12:53:09 step 4: objective=0.138156 reg=0.002548
2017/08/30 12:53:10 step 5: objective=0.138252 reg=0.002547
2017/08/30 12:53:12 step 6: objective=0.138328 reg=0.002547
2017/08/30 12:53:13 step 7: objective=0.138468 reg=0.002545
2017/08/30 12:53:13 Training value function...
2017/08/30 12:53:16 step 0: mse=0.299170 step=0.050000
2017/08/30 12:53:18 step 1: mse=0.297335 step=0.050000
2017/08/30 12:53:19 step 2: mse=0.295564 step=0.050000
2017/08/30 12:53:21 step 3: mse=0.294193 step=0.050000
2017/08/30 12:53:22 step 4: mse=0.292696 step=0.050000
2017/08/30 12:53:23 step 5: mse=0.291577 step=0.050000
2017/08/30 12:53:25 step 6: mse=0.290067 step=0.050000
2017/08/30 12:53:26 step 7: mse=0.288814 step=0.050000
2017/08/30 12:53:26 Saving...
2017/08/30 12:53:26 Gathering batch of experience...
2017/08/30 12:54:01 batch 108: mean=20.500000 stddev=11.056672 entropy=0.257223 frames=6435 count=20
2017/08/30 12:54:01 Training policy...
2017/08/30 12:54:04 tune 0: objective=0.127913 reg=0.002572 prune=0
2017/08/30 12:54:05 step 0: objective=0.127914 reg=0.002572
2017/08/30 12:54:06 step 1: objective=0.128060 reg=0.002570
2017/08/30 12:54:07 step 2: objective=0.128277 reg=0.002569
2017/08/30 12:54:08 step 3: objective=0.128457 reg=0.002568
2017/08/30 12:54:09 step 4: objective=0.128588 reg=0.002568
2017/08/30 12:54:11 step 5: objective=0.128805 reg=0.002568
2017/08/30 12:54:12 step 6: objective=0.128969 reg=0.002567
2017/08/30 12:54:13 step 7: objective=0.129086 reg=0.002567
2017/08/30 12:54:13 Training value function...
2017/08/30 12:54:15 step 0: mse=0.274752 step=0.050000
2017/08/30 12:54:16 step 1: mse=0.274322 step=0.050000
2017/08/30 12:54:18 step 2: mse=0.274129 step=0.050000
2017/08/30 12:54:19 step 3: mse=0.273874 step=0.050000
2017/08/30 12:54:20 step 4: mse=0.273477 step=0.050000
2017/08/30 12:54:21 step 5: mse=0.273204 step=0.050000
2017/08/30 12:54:22 step 6: mse=0.272823 step=0.050000
2017/08/30 12:54:23 step 7: mse=0.272840 step=0.050000
2017/08/30 12:54:23 Saving...
2017/08/30 12:54:23 Gathering batch of experience...
2017/08/30 12:55:00 batch 109: mean=21.909091 stddev=14.061259 entropy=0.259119 frames=7478 count=22
2017/08/30 12:55:00 Training policy...
2017/08/30 12:55:05 tune 0: objective=0.148210 reg=0.002591 prune=0
2017/08/30 12:55:06 step 0: objective=0.148210 reg=0.002591
2017/08/30 12:55:07 step 1: objective=0.148344 reg=0.002591
2017/08/30 12:55:08 step 2: objective=0.148516 reg=0.002590
2017/08/30 12:55:10 step 3: objective=0.148704 reg=0.002589
2017/08/30 12:55:11 step 4: objective=0.148789 reg=0.002590
2017/08/30 12:55:12 step 5: objective=0.148961 reg=0.002590
2017/08/30 12:55:13 step 6: objective=0.149072 reg=0.002590
2017/08/30 12:55:15 step 7: objective=0.149147 reg=0.002589
2017/08/30 12:55:15 Training value function...
2017/08/30 12:55:18 step 0: mse=0.288514 step=0.050000
2017/08/30 12:55:19 step 1: mse=0.285359 step=0.050000
2017/08/30 12:55:20 step 2: mse=0.282544 step=0.050000
2017/08/30 12:55:21 step 3: mse=0.279123 step=0.050000
2017/08/30 12:55:23 step 4: mse=0.276076 step=0.050000
2017/08/30 12:55:24 step 5: mse=0.273544 step=0.050000
2017/08/30 12:55:25 step 6: mse=0.271429 step=0.050000
2017/08/30 12:55:27 step 7: mse=0.269315 step=0.050000
2017/08/30 12:55:27 Saving...
2017/08/30 12:55:27 Gathering batch of experience...
2017/08/30 12:56:06 batch 110: mean=19.500000 stddev=13.179967 entropy=0.261339 frames=7936 count=26
2017/08/30 12:56:06 Training policy...
2017/08/30 12:56:10 tune 0: objective=0.123364 reg=0.002613 prune=0
2017/08/30 12:56:12 step 0: objective=0.123365 reg=0.002613
2017/08/30 12:56:13 step 1: objective=0.123492 reg=0.002615
2017/08/30 12:56:14 step 2: objective=0.123647 reg=0.002618
2017/08/30 12:56:16 step 3: objective=0.123754 reg=0.002619
2017/08/30 12:56:17 step 4: objective=0.123859 reg=0.002620
2017/08/30 12:56:18 step 5: objective=0.124004 reg=0.002618
2017/08/30 12:56:20 step 6: objective=0.124106 reg=0.002619
2017/08/30 12:56:21 step 7: objective=0.124214 reg=0.002620
2017/08/30 12:56:21 Training value function...
2017/08/30 12:56:24 step 0: mse=0.263654 step=0.050000
2017/08/30 12:56:26 step 1: mse=0.263567 step=0.050000
2017/08/30 12:56:27 step 2: mse=0.263652 step=0.050000
2017/08/30 12:56:29 step 3: mse=0.263584 step=0.050000
2017/08/30 12:56:30 step 4: mse=0.263623 step=0.050000
2017/08/30 12:56:31 step 5: mse=0.263856 step=0.050000
2017/08/30 12:56:33 step 6: mse=0.263987 step=0.050000
2017/08/30 12:56:34 step 7: mse=0.263929 step=0.050000
2017/08/30 12:56:34 Saving...
2017/08/30 12:56:34 Gathering batch of experience...
2017/08/30 12:57:11 batch 111: mean=20.565217 stddev=14.261002 entropy=0.259599 frames=7444 count=23
2017/08/30 12:57:11 Training policy...
2017/08/30 12:57:15 tune 0: objective=0.126749 reg=0.002596 prune=0
2017/08/30 12:57:16 step 0: objective=0.126749 reg=0.002596
2017/08/30 12:57:17 step 1: objective=0.126942 reg=0.002594
2017/08/30 12:57:18 step 2: objective=0.127083 reg=0.002594
2017/08/30 12:57:20 step 3: objective=0.127253 reg=0.002593
2017/08/30 12:57:21 step 4: objective=0.127460 reg=0.002592
2017/08/30 12:57:22 step 5: objective=0.127674 reg=0.002590
2017/08/30 12:57:23 step 6: objective=0.127765 reg=0.002591
2017/08/30 12:57:25 step 7: objective=0.127894 reg=0.002591
2017/08/30 12:57:25 Training value function...
2017/08/30 12:57:28 step 0: mse=0.287464 step=0.050000
2017/08/30 12:57:29 step 1: mse=0.286440 step=0.050000
2017/08/30 12:57:30 step 2: mse=0.285909 step=0.050000
2017/08/30 12:57:32 step 3: mse=0.285123 step=0.050000
2017/08/30 12:57:33 step 4: mse=0.284302 step=0.050000
2017/08/30 12:57:34 step 5: mse=0.284017 step=0.050000
2017/08/30 12:57:35 step 6: mse=0.283648 step=0.050000
2017/08/30 12:57:37 step 7: mse=0.283094 step=0.050000
2017/08/30 12:57:37 Saving...
2017/08/30 12:57:37 Gathering batch of experience...
2017/08/30 12:58:16 batch 112: mean=20.875000 stddev=13.020217 entropy=0.257936 frames=7825 count=24
2017/08/30 12:58:16 Training policy...
2017/08/30 12:58:21 tune 0: objective=0.130610 reg=0.002579 prune=0
2017/08/30 12:58:22 step 0: objective=0.130611 reg=0.002579
2017/08/30 12:58:23 step 1: objective=0.130685 reg=0.002577
2017/08/30 12:58:25 step 2: objective=0.130920 reg=0.002576
2017/08/30 12:58:26 step 3: objective=0.131064 reg=0.002574
2017/08/30 12:58:27 step 4: objective=0.131245 reg=0.002570
2017/08/30 12:58:29 step 5: objective=0.131399 reg=0.002570
2017/08/30 12:58:30 step 6: objective=0.131470 reg=0.002569
2017/08/30 12:58:31 step 7: objective=0.131535 reg=0.002568
2017/08/30 12:58:31 Training value function...
2017/08/30 12:58:34 step 0: mse=0.263781 step=0.050000
2017/08/30 12:58:36 step 1: mse=0.263308 step=0.050000
2017/08/30 12:58:37 step 2: mse=0.262854 step=0.050000
2017/08/30 12:58:39 step 3: mse=0.262399 step=0.050000
2017/08/30 12:58:40 step 4: mse=0.262113 step=0.050000
2017/08/30 12:58:41 step 5: mse=0.261646 step=0.050000
2017/08/30 12:58:43 step 6: mse=0.261459 step=0.050000
2017/08/30 12:58:44 step 7: mse=0.261124 step=0.050000
2017/08/30 12:58:44 Saving...
2017/08/30 12:58:44 Gathering batch of experience...
2017/08/30 12:59:22 batch 113: mean=20.750000 stddev=12.764697 entropy=0.257748 frames=7741 count=24
2017/08/30 12:59:22 Training policy...
2017/08/30 12:59:26 tune 0: objective=0.135641 reg=0.002577 prune=0
2017/08/30 12:59:27 step 0: objective=0.135642 reg=0.002577
2017/08/30 12:59:29 step 1: objective=0.135854 reg=0.002578
2017/08/30 12:59:30 step 2: objective=0.135935 reg=0.002578
2017/08/30 12:59:31 step 3: objective=0.136079 reg=0.002577
2017/08/30 12:59:33 step 4: objective=0.136199 reg=0.002576
2017/08/30 12:59:34 step 5: objective=0.136437 reg=0.002575
2017/08/30 12:59:35 step 6: objective=0.136509 reg=0.002573
2017/08/30 12:59:37 step 7: objective=0.136615 reg=0.002573
2017/08/30 12:59:37 Training value function...
2017/08/30 12:59:40 step 0: mse=0.264842 step=0.050000
2017/08/30 12:59:41 step 1: mse=0.263085 step=0.050000
2017/08/30 12:59:43 step 2: mse=0.261670 step=0.050000
2017/08/30 12:59:44 step 3: mse=0.260375 step=0.050000
2017/08/30 12:59:45 step 4: mse=0.259222 step=0.050000
2017/08/30 12:59:46 step 5: mse=0.258426 step=0.050000
2017/08/30 12:59:48 step 6: mse=0.257311 step=0.050000
2017/08/30 12:59:49 step 7: mse=0.256663 step=0.050000
2017/08/30 12:59:49 Saving...
2017/08/30 12:59:49 Gathering batch of experience...
2017/08/30 13:00:29 batch 114: mean=17.964286 stddev=13.140673 entropy=0.256741 frames=7890 count=28
2017/08/30 13:00:29 Training policy...
2017/08/30 13:00:33 tune 0: objective=0.119109 reg=0.002567 prune=0
2017/08/30 13:00:35 step 0: objective=0.119109 reg=0.002567
2017/08/30 13:00:36 step 1: objective=0.119261 reg=0.002568
2017/08/30 13:00:37 step 2: objective=0.119487 reg=0.002567
2017/08/30 13:00:39 step 3: objective=0.119589 reg=0.002567
2017/08/30 13:00:40 step 4: objective=0.119743 reg=0.002567
2017/08/30 13:00:41 step 5: objective=0.119850 reg=0.002567
2017/08/30 13:00:43 step 6: objective=0.119947 reg=0.002566
2017/08/30 13:00:44 step 7: objective=0.120003 reg=0.002565
2017/08/30 13:00:44 Training value function...
2017/08/30 13:00:47 step 0: mse=0.265401 step=0.050000
2017/08/30 13:00:49 step 1: mse=0.265711 step=0.050000
2017/08/30 13:00:50 step 2: mse=0.266071 step=0.050000
2017/08/30 13:00:51 step 3: mse=0.266451 step=0.050000
2017/08/30 13:00:53 step 4: mse=0.266614 step=0.050000
2017/08/30 13:00:54 step 5: mse=0.266960 step=0.050000
2017/08/30 13:00:55 step 6: mse=0.267269 step=0.050000
2017/08/30 13:00:57 step 7: mse=0.267349 step=0.050000
2017/08/30 13:00:57 Saving...
2017/08/30 13:00:57 Gathering batch of experience...
2017/08/30 13:01:29 batch 115: mean=18.000000 stddev=11.851352 entropy=0.258696 frames=6236 count=22
2017/08/30 13:01:29 Training policy...
2017/08/30 13:01:32 tune 0: objective=0.116105 reg=0.002587 prune=0
2017/08/30 13:01:33 step 0: objective=0.116107 reg=0.002587
2017/08/30 13:01:34 step 1: objective=0.116278 reg=0.002585
2017/08/30 13:01:35 step 2: objective=0.116392 reg=0.002585
2017/08/30 13:01:36 step 3: objective=0.116557 reg=0.002585
2017/08/30 13:01:37 step 4: objective=0.116720 reg=0.002584
2017/08/30 13:01:38 step 5: objective=0.116892 reg=0.002582
2017/08/30 13:01:39 step 6: objective=0.116973 reg=0.002582
2017/08/30 13:01:40 step 7: objective=0.117148 reg=0.002581
2017/08/30 13:01:40 Training value function...
2017/08/30 13:01:43 step 0: mse=0.269993 step=0.050000
2017/08/30 13:01:44 step 1: mse=0.269898 step=0.050000
2017/08/30 13:01:45 step 2: mse=0.270292 step=0.050000
2017/08/30 13:01:46 step 3: mse=0.270254 step=0.050000
2017/08/30 13:01:47 step 4: mse=0.270632 step=0.050000
2017/08/30 13:01:48 step 5: mse=0.270838 step=0.050000
2017/08/30 13:01:49 step 6: mse=0.271152 step=0.050000
2017/08/30 13:01:50 step 7: mse=0.271281 step=0.050000
2017/08/30 13:01:50 Saving...
2017/08/30 13:01:50 Gathering batch of experience...
2017/08/30 13:02:27 batch 116: mean=22.700000 stddev=13.435401 entropy=0.258061 frames=7129 count=20
2017/08/30 13:02:27 Training policy...
2017/08/30 13:02:31 tune 0: objective=0.138381 reg=0.002581 prune=0
2017/08/30 13:02:32 step 0: objective=0.138382 reg=0.002581
2017/08/30 13:02:34 step 1: objective=0.138536 reg=0.002584
2017/08/30 13:02:35 step 2: objective=0.138656 reg=0.002587
2017/08/30 13:02:36 step 3: objective=0.138771 reg=0.002590
2017/08/30 13:02:37 step 4: objective=0.138971 reg=0.002592
2017/08/30 13:02:38 step 5: objective=0.139113 reg=0.002594
2017/08/30 13:02:40 step 6: objective=0.139218 reg=0.002596
2017/08/30 13:02:41 step 7: objective=0.139288 reg=0.002596
2017/08/30 13:02:41 Training value function...
2017/08/30 13:02:44 step 0: mse=0.292931 step=0.050000
2017/08/30 13:02:45 step 1: mse=0.291329 step=0.050000
2017/08/30 13:02:46 step 2: mse=0.289668 step=0.050000
2017/08/30 13:02:47 step 3: mse=0.288245 step=0.050000
2017/08/30 13:02:49 step 4: mse=0.286947 step=0.050000
2017/08/30 13:02:50 step 5: mse=0.285615 step=0.050000
2017/08/30 13:02:51 step 6: mse=0.284440 step=0.050000
2017/08/30 13:02:52 step 7: mse=0.283310 step=0.050000
2017/08/30 13:02:52 Saving...
2017/08/30 13:02:52 Gathering batch of experience...
2017/08/30 13:03:31 batch 117: mean=16.161290 stddev=13.711537 entropy=0.261304 frames=7888 count=31
2017/08/30 13:03:31 Training policy...
2017/08/30 13:03:35 tune 0: objective=0.116156 reg=0.002613 prune=0
2017/08/30 13:03:37 step 0: objective=0.116157 reg=0.002613
2017/08/30 13:03:38 step 1: objective=0.116329 reg=0.002612
2017/08/30 13:03:40 step 2: objective=0.116424 reg=0.002611
2017/08/30 13:03:41 step 3: objective=0.116592 reg=0.002610
2017/08/30 13:03:42 step 4: objective=0.116722 reg=0.002608
2017/08/30 13:03:44 step 5: objective=0.116806 reg=0.002608
2017/08/30 13:03:45 step 6: objective=0.116885 reg=0.002607
2017/08/30 13:03:46 step 7: objective=0.116993 reg=0.002606
2017/08/30 13:03:46 Training value function...
2017/08/30 13:03:50 step 0: mse=0.279190 step=0.050000
2017/08/30 13:03:51 step 1: mse=0.278901 step=0.050000
2017/08/30 13:03:52 step 2: mse=0.278867 step=0.050000
2017/08/30 13:03:54 step 3: mse=0.278811 step=0.050000
2017/08/30 13:03:55 step 4: mse=0.278182 step=0.050000
2017/08/30 13:03:56 step 5: mse=0.278239 step=0.050000
2017/08/30 13:03:58 step 6: mse=0.278154 step=0.050000
2017/08/30 13:03:59 step 7: mse=0.278205 step=0.050000
2017/08/30 13:03:59 Saving...
2017/08/30 13:03:59 Gathering batch of experience...
2017/08/30 13:04:35 batch 118: mean=22.095238 stddev=11.983738 entropy=0.258296 frames=7253 count=21
2017/08/30 13:04:35 Training policy...
2017/08/30 13:04:39 tune 0: objective=0.137979 reg=0.002583 prune=0
2017/08/30 13:04:40 step 0: objective=0.137980 reg=0.002583
2017/08/30 13:04:42 step 1: objective=0.138069 reg=0.002583
2017/08/30 13:04:43 step 2: objective=0.138148 reg=0.002582
2017/08/30 13:04:44 step 3: objective=0.138263 reg=0.002581
2017/08/30 13:04:45 step 4: objective=0.138436 reg=0.002581
2017/08/30 13:04:47 step 5: objective=0.138544 reg=0.002580
2017/08/30 13:04:48 step 6: objective=0.138694 reg=0.002581
2017/08/30 13:04:49 step 7: objective=0.138926 reg=0.002581
2017/08/30 13:04:49 Training value function...
2017/08/30 13:04:52 step 0: mse=0.273345 step=0.050000
2017/08/30 13:04:53 step 1: mse=0.271622 step=0.050000
2017/08/30 13:04:55 step 2: mse=0.269848 step=0.050000
2017/08/30 13:04:56 step 3: mse=0.268605 step=0.050000
2017/08/30 13:04:57 step 4: mse=0.267012 step=0.050000
2017/08/30 13:04:58 step 5: mse=0.265727 step=0.050000
2017/08/30 13:05:00 step 6: mse=0.264351 step=0.050000
2017/08/30 13:05:01 step 7: mse=0.263032 step=0.050000
2017/08/30 13:05:01 Saving...
2017/08/30 13:05:01 Gathering batch of experience...
2017/08/30 13:05:41 batch 119: mean=21.625000 stddev=13.514845 entropy=0.254103 frames=8100 count=24
2017/08/30 13:05:41 Training policy...
2017/08/30 13:05:45 tune 0: objective=0.137763 reg=0.002541 prune=0
2017/08/30 13:05:47 step 0: objective=0.137764 reg=0.002541
2017/08/30 13:05:48 step 1: objective=0.137848 reg=0.002541
2017/08/30 13:05:50 step 2: objective=0.137987 reg=0.002541
2017/08/30 13:05:51 step 3: objective=0.138146 reg=0.002540
2017/08/30 13:05:52 step 4: objective=0.138196 reg=0.002540
2017/08/30 13:05:54 step 5: objective=0.138249 reg=0.002540
2017/08/30 13:05:55 step 6: objective=0.138304 reg=0.002538
2017/08/30 13:05:56 step 7: objective=0.138355 reg=0.002540
2017/08/30 13:05:56 Training value function...
2017/08/30 13:06:00 step 0: mse=0.271112 step=0.050000
2017/08/30 13:06:01 step 1: mse=0.269321 step=0.050000
2017/08/30 13:06:03 step 2: mse=0.267509 step=0.050000
2017/08/30 13:06:04 step 3: mse=0.265503 step=0.050000
2017/08/30 13:06:05 step 4: mse=0.264146 step=0.050000
2017/08/30 13:06:07 step 5: mse=0.262913 step=0.050000
2017/08/30 13:06:08 step 6: mse=0.261802 step=0.050000
2017/08/30 13:06:09 step 7: mse=0.260643 step=0.050000
2017/08/30 13:06:09 Saving...
2017/08/30 13:06:09 Gathering batch of experience...
2017/08/30 13:06:45 batch 120: mean=17.666667 stddev=11.991895 entropy=0.259378 frames=6686 count=24
2017/08/30 13:06:45 Training policy...
2017/08/30 13:06:48 tune 0: objective=0.112677 reg=0.002594 prune=0
2017/08/30 13:06:50 step 0: objective=0.112678 reg=0.002594
2017/08/30 13:06:51 step 1: objective=0.112876 reg=0.002594
2017/08/30 13:06:52 step 2: objective=0.113077 reg=0.002595
2017/08/30 13:06:53 step 3: objective=0.113258 reg=0.002597
2017/08/30 13:06:54 step 4: objective=0.113406 reg=0.002597
2017/08/30 13:06:55 step 5: objective=0.113484 reg=0.002598
2017/08/30 13:06:56 step 6: objective=0.113598 reg=0.002598
2017/08/30 13:06:57 step 7: objective=0.113723 reg=0.002598
2017/08/30 13:06:57 Training value function...
2017/08/30 13:07:00 step 0: mse=0.260527 step=0.050000
2017/08/30 13:07:01 step 1: mse=0.261338 step=0.050000
2017/08/30 13:07:03 step 2: mse=0.262523 step=0.050000
2017/08/30 13:07:04 step 3: mse=0.263301 step=0.050000
2017/08/30 13:07:05 step 4: mse=0.264520 step=0.050000
2017/08/30 13:07:06 step 5: mse=0.265449 step=0.050000
2017/08/30 13:07:07 step 6: mse=0.265758 step=0.050000
2017/08/30 13:07:08 step 7: mse=0.266687 step=0.050000
2017/08/30 13:07:08 Saving...
2017/08/30 13:07:08 Gathering batch of experience...
2017/08/30 13:07:45 batch 121: mean=21.952381 stddev=14.824292 entropy=0.258061 frames=7189 count=21
2017/08/30 13:07:45 Training policy...
2017/08/30 13:07:49 tune 0: objective=0.140619 reg=0.002581 prune=0
2017/08/30 13:07:50 step 0: objective=0.140619 reg=0.002581
2017/08/30 13:07:52 step 1: objective=0.140856 reg=0.002579
2017/08/30 13:07:53 step 2: objective=0.140987 reg=0.002578
2017/08/30 13:07:54 step 3: objective=0.141214 reg=0.002577
2017/08/30 13:07:55 step 4: objective=0.141311 reg=0.002578
2017/08/30 13:07:56 step 5: objective=0.141465 reg=0.002579
2017/08/30 13:07:58 step 6: objective=0.141568 reg=0.002578
2017/08/30 13:07:59 step 7: objective=0.141667 reg=0.002578
2017/08/30 13:07:59 Training value function...
2017/08/30 13:08:02 step 0: mse=0.279184 step=0.050000
2017/08/30 13:08:03 step 1: mse=0.277367 step=0.050000
2017/08/30 13:08:04 step 2: mse=0.275925 step=0.050000
2017/08/30 13:08:06 step 3: mse=0.274049 step=0.050000
2017/08/30 13:08:07 step 4: mse=0.272289 step=0.050000
2017/08/30 13:08:08 step 5: mse=0.270645 step=0.050000
2017/08/30 13:08:09 step 6: mse=0.269050 step=0.050000
2017/08/30 13:08:11 step 7: mse=0.267770 step=0.050000
2017/08/30 13:08:11 Saving...
2017/08/30 13:08:11 Gathering batch of experience...
2017/08/30 13:08:44 batch 122: mean=21.900000 stddev=13.064838 entropy=0.258982 frames=6851 count=20
2017/08/30 13:08:44 Training policy...
2017/08/30 13:08:48 tune 0: objective=0.131967 reg=0.002590 prune=0
2017/08/30 13:08:49 step 0: objective=0.131968 reg=0.002590
2017/08/30 13:08:50 step 1: objective=0.132124 reg=0.002589
2017/08/30 13:08:51 step 2: objective=0.132286 reg=0.002588
2017/08/30 13:08:52 step 3: objective=0.132450 reg=0.002587
2017/08/30 13:08:53 step 4: objective=0.132588 reg=0.002585
2017/08/30 13:08:54 step 5: objective=0.132807 reg=0.002586
2017/08/30 13:08:56 step 6: objective=0.133028 reg=0.002585
2017/08/30 13:08:57 step 7: objective=0.133163 reg=0.002584
2017/08/30 13:08:57 Training value function...
2017/08/30 13:09:00 step 0: mse=0.273003 step=0.050000
2017/08/30 13:09:01 step 1: mse=0.271985 step=0.050000
2017/08/30 13:09:02 step 2: mse=0.271371 step=0.050000
2017/08/30 13:09:03 step 3: mse=0.270792 step=0.050000
2017/08/30 13:09:04 step 4: mse=0.270316 step=0.050000
2017/08/30 13:09:05 step 5: mse=0.269809 step=0.050000
2017/08/30 13:09:07 step 6: mse=0.269172 step=0.050000
2017/08/30 13:09:08 step 7: mse=0.268608 step=0.050000
2017/08/30 13:09:08 Saving...
2017/08/30 13:09:08 Gathering batch of experience...
2017/08/30 13:09:42 batch 123: mean=17.958333 stddev=12.367562 entropy=0.262780 frames=6806 count=24
2017/08/30 13:09:42 Training policy...
2017/08/30 13:09:46 tune 0: objective=0.111600 reg=0.002628 prune=0
2017/08/30 13:09:47 step 0: objective=0.111600 reg=0.002628
2017/08/30 13:09:48 step 1: objective=0.111780 reg=0.002627
2017/08/30 13:09:49 step 2: objective=0.112068 reg=0.002627
2017/08/30 13:09:51 step 3: objective=0.112204 reg=0.002627
2017/08/30 13:09:52 step 4: objective=0.112296 reg=0.002627
2017/08/30 13:09:53 step 5: objective=0.112477 reg=0.002625
2017/08/30 13:09:54 step 6: objective=0.112691 reg=0.002625
2017/08/30 13:09:55 step 7: objective=0.112893 reg=0.002625
2017/08/30 13:09:55 Training value function...
2017/08/30 13:09:58 step 0: mse=0.264215 step=0.050000
2017/08/30 13:09:59 step 1: mse=0.264428 step=0.050000
2017/08/30 13:10:00 step 2: mse=0.264640 step=0.050000
2017/08/30 13:10:02 step 3: mse=0.265210 step=0.050000
2017/08/30 13:10:03 step 4: mse=0.265447 step=0.050000
2017/08/30 13:10:04 step 5: mse=0.266004 step=0.050000
2017/08/30 13:10:05 step 6: mse=0.266494 step=0.050000
2017/08/30 13:10:06 step 7: mse=0.266606 step=0.050000
2017/08/30 13:10:06 Saving...
2017/08/30 13:10:06 Gathering batch of experience...
2017/08/30 13:10:47 batch 124: mean=20.407407 stddev=13.532565 entropy=0.260599 frames=8615 count=27
2017/08/30 13:10:47 Training policy...
2017/08/30 13:10:52 tune 0: objective=0.133514 reg=0.002606 prune=0
2017/08/30 13:10:53 step 0: objective=0.133514 reg=0.002606
2017/08/30 13:10:55 step 1: objective=0.133639 reg=0.002606
2017/08/30 13:10:56 step 2: objective=0.133823 reg=0.002606
2017/08/30 13:10:58 step 3: objective=0.133939 reg=0.002606
2017/08/30 13:10:59 step 4: objective=0.134037 reg=0.002606
2017/08/30 13:11:00 step 5: objective=0.134158 reg=0.002605
2017/08/30 13:11:02 step 6: objective=0.134245 reg=0.002605
2017/08/30 13:11:03 step 7: objective=0.134407 reg=0.002607
2017/08/30 13:11:03 Training value function...
2017/08/30 13:11:07 step 0: mse=0.269670 step=0.050000
2017/08/30 13:11:09 step 1: mse=0.268684 step=0.050000
2017/08/30 13:11:10 step 2: mse=0.267340 step=0.050000
2017/08/30 13:11:12 step 3: mse=0.266406 step=0.050000
2017/08/30 13:11:13 step 4: mse=0.265371 step=0.050000
2017/08/30 13:11:15 step 5: mse=0.264485 step=0.050000
2017/08/30 13:11:16 step 6: mse=0.263524 step=0.050000
2017/08/30 13:11:18 step 7: mse=0.262867 step=0.050000
2017/08/30 13:11:18 Saving...
2017/08/30 13:11:18 Gathering batch of experience...
2017/08/30 13:11:55 batch 125: mean=22.761905 stddev=12.861551 entropy=0.252663 frames=7449 count=21
2017/08/30 13:11:55 Training policy...
2017/08/30 13:11:59 tune 0: objective=0.140005 reg=0.002527 prune=0
2017/08/30 13:12:00 step 0: objective=0.140005 reg=0.002527
2017/08/30 13:12:01 step 1: objective=0.140168 reg=0.002526
2017/08/30 13:12:03 step 2: objective=0.140334 reg=0.002525
2017/08/30 13:12:04 step 3: objective=0.140504 reg=0.002524
2017/08/30 13:12:05 step 4: objective=0.140581 reg=0.002525
2017/08/30 13:12:07 step 5: objective=0.140689 reg=0.002523
2017/08/30 13:12:08 step 6: objective=0.140786 reg=0.002522
2017/08/30 13:12:09 step 7: objective=0.140882 reg=0.002521
2017/08/30 13:12:09 Training value function...
2017/08/30 13:12:12 step 0: mse=0.265862 step=0.050000
2017/08/30 13:12:13 step 1: mse=0.264673 step=0.050000
2017/08/30 13:12:15 step 2: mse=0.263016 step=0.050000
2017/08/30 13:12:16 step 3: mse=0.261844 step=0.050000
2017/08/30 13:12:17 step 4: mse=0.260743 step=0.050000
2017/08/30 13:12:19 step 5: mse=0.259552 step=0.050000
2017/08/30 13:12:20 step 6: mse=0.258721 step=0.050000
2017/08/30 13:12:21 step 7: mse=0.257809 step=0.050000
2017/08/30 13:12:21 Saving...
2017/08/30 13:12:21 Gathering batch of experience...
2017/08/30 13:12:56 batch 126: mean=18.750000 stddev=12.600430 entropy=0.263453 frames=7045 count=24
2017/08/30 13:12:56 Training policy...
2017/08/30 13:13:00 tune 0: objective=0.123084 reg=0.002635 prune=0
2017/08/30 13:13:01 step 0: objective=0.123085 reg=0.002635
2017/08/30 13:13:03 step 1: objective=0.123214 reg=0.002633
2017/08/30 13:13:04 step 2: objective=0.123402 reg=0.002634
2017/08/30 13:13:05 step 3: objective=0.123590 reg=0.002635
2017/08/30 13:13:06 step 4: objective=0.123757 reg=0.002637
2017/08/30 13:13:07 step 5: objective=0.123881 reg=0.002638
2017/08/30 13:13:09 step 6: objective=0.123970 reg=0.002638
2017/08/30 13:13:10 step 7: objective=0.124112 reg=0.002638
2017/08/30 13:13:10 Training value function...
2017/08/30 13:13:13 step 0: mse=0.257446 step=0.050000
2017/08/30 13:13:14 step 1: mse=0.257035 step=0.050000
2017/08/30 13:13:15 step 2: mse=0.256883 step=0.050000
2017/08/30 13:13:16 step 3: mse=0.256820 step=0.050000
2017/08/30 13:13:18 step 4: mse=0.256488 step=0.050000
2017/08/30 13:13:19 step 5: mse=0.256155 step=0.050000
2017/08/30 13:13:20 step 6: mse=0.255980 step=0.050000
2017/08/30 13:13:21 step 7: mse=0.255812 step=0.050000
2017/08/30 13:13:21 Saving...
2017/08/30 13:13:21 Gathering batch of experience...
2017/08/30 13:13:53 batch 127: mean=20.450000 stddev=15.196957 entropy=0.256791 frames=6386 count=20
2017/08/30 13:13:53 Training policy...
2017/08/30 13:13:57 tune 0: objective=0.131870 reg=0.002568 prune=0
2017/08/30 13:13:58 step 0: objective=0.131870 reg=0.002568
2017/08/30 13:13:59 step 1: objective=0.131997 reg=0.002568
2017/08/30 13:14:00 step 2: objective=0.132144 reg=0.002566
2017/08/30 13:14:01 step 3: objective=0.132303 reg=0.002565
2017/08/30 13:14:02 step 4: objective=0.132428 reg=0.002564
2017/08/30 13:14:03 step 5: objective=0.132613 reg=0.002562
2017/08/30 13:14:04 step 6: objective=0.132742 reg=0.002561
2017/08/30 13:14:05 step 7: objective=0.132853 reg=0.002562
2017/08/30 13:14:05 Training value function...
2017/08/30 13:14:08 step 0: mse=0.280174 step=0.050000
2017/08/30 13:14:09 step 1: mse=0.278603 step=0.050000
2017/08/30 13:14:10 step 2: mse=0.276582 step=0.050000
2017/08/30 13:14:11 step 3: mse=0.274846 step=0.050000
2017/08/30 13:14:12 step 4: mse=0.273769 step=0.050000
2017/08/30 13:14:13 step 5: mse=0.272342 step=0.050000
2017/08/30 13:14:15 step 6: mse=0.271015 step=0.050000
2017/08/30 13:14:16 step 7: mse=0.269582 step=0.050000
2017/08/30 13:14:16 Saving...
2017/08/30 13:14:16 Gathering batch of experience...
2017/08/30 13:14:47 batch 128: mean=20.250000 stddev=11.505977 entropy=0.258367 frames=6387 count=20
2017/08/30 13:14:47 Training policy...
2017/08/30 13:14:50 tune 0: objective=0.119404 reg=0.002584 prune=0
2017/08/30 13:14:52 step 0: objective=0.119405 reg=0.002584
2017/08/30 13:14:53 step 1: objective=0.119610 reg=0.002583
2017/08/30 13:14:54 step 2: objective=0.119843 reg=0.002581
2017/08/30 13:14:55 step 3: objective=0.120109 reg=0.002580
2017/08/30 13:14:56 step 4: objective=0.120203 reg=0.002579
2017/08/30 13:14:57 step 5: objective=0.120277 reg=0.002578
2017/08/30 13:14:58 step 6: objective=0.120453 reg=0.002579
2017/08/30 13:14:59 step 7: objective=0.120590 reg=0.002578
2017/08/30 13:14:59 Training value function...
2017/08/30 13:15:02 step 0: mse=0.267721 step=0.050000
2017/08/30 13:15:03 step 1: mse=0.267950 step=0.050000
2017/08/30 13:15:04 step 2: mse=0.267931 step=0.050000
2017/08/30 13:15:05 step 3: mse=0.267880 step=0.050000
2017/08/30 13:15:06 step 4: mse=0.268096 step=0.050000
2017/08/30 13:15:07 step 5: mse=0.268501 step=0.050000
2017/08/30 13:15:08 step 6: mse=0.268882 step=0.050000
2017/08/30 13:15:09 step 7: mse=0.269209 step=0.050000
2017/08/30 13:15:09 Saving...
2017/08/30 13:15:09 Gathering batch of experience...
2017/08/30 13:15:44 batch 129: mean=20.666667 stddev=13.871290 entropy=0.258160 frames=6807 count=21
2017/08/30 13:15:44 Training policy...
2017/08/30 13:15:47 tune 0: objective=0.131665 reg=0.002582 prune=0
2017/08/30 13:15:49 step 0: objective=0.131665 reg=0.002582
2017/08/30 13:15:50 step 1: objective=0.131815 reg=0.002580
2017/08/30 13:15:51 step 2: objective=0.132010 reg=0.002580
2017/08/30 13:15:52 step 3: objective=0.132165 reg=0.002579
2017/08/30 13:15:53 step 4: objective=0.132322 reg=0.002577
2017/08/30 13:15:54 step 5: objective=0.132433 reg=0.002576
2017/08/30 13:15:56 step 6: objective=0.132529 reg=0.002574
2017/08/30 13:15:57 step 7: objective=0.132608 reg=0.002574
2017/08/30 13:15:57 Training value function...
2017/08/30 13:16:00 step 0: mse=0.282007 step=0.050000
2017/08/30 13:16:01 step 1: mse=0.280988 step=0.050000
2017/08/30 13:16:02 step 2: mse=0.280473 step=0.050000
2017/08/30 13:16:03 step 3: mse=0.279657 step=0.050000
2017/08/30 13:16:04 step 4: mse=0.278984 step=0.050000
2017/08/30 13:16:05 step 5: mse=0.277390 step=0.050000
2017/08/30 13:16:07 step 6: mse=0.276872 step=0.050000
2017/08/30 13:16:08 step 7: mse=0.276424 step=0.050000
2017/08/30 13:16:08 Saving...
2017/08/30 13:16:08 Gathering batch of experience...
2017/08/30 13:16:44 batch 130: mean=25.888889 stddev=12.990975 entropy=0.256600 frames=7228 count=18
2017/08/30 13:16:44 Training policy...
2017/08/30 13:16:48 tune 0: objective=0.148472 reg=0.002566 prune=0
2017/08/30 13:16:49 step 0: objective=0.148472 reg=0.002566
2017/08/30 13:16:50 step 1: objective=0.148612 reg=0.002563
2017/08/30 13:16:51 step 2: objective=0.148735 reg=0.002562
2017/08/30 13:16:53 step 3: objective=0.148953 reg=0.002561
2017/08/30 13:16:54 step 4: objective=0.149021 reg=0.002559
2017/08/30 13:16:55 step 5: objective=0.149158 reg=0.002558
2017/08/30 13:16:56 step 6: objective=0.149256 reg=0.002557
2017/08/30 13:16:58 step 7: objective=0.149520 reg=0.002556
2017/08/30 13:16:58 Training value function...
2017/08/30 13:17:01 step 0: mse=0.269594 step=0.050000
2017/08/30 13:17:02 step 1: mse=0.266933 step=0.050000
2017/08/30 13:17:03 step 2: mse=0.264162 step=0.050000
2017/08/30 13:17:04 step 3: mse=0.261866 step=0.050000
2017/08/30 13:17:05 step 4: mse=0.259697 step=0.050000
2017/08/30 13:17:07 step 5: mse=0.257693 step=0.050000
2017/08/30 13:17:08 step 6: mse=0.255727 step=0.050000
2017/08/30 13:17:09 step 7: mse=0.254254 step=0.050000
2017/08/30 13:17:09 Saving...
2017/08/30 13:17:09 Gathering batch of experience...
2017/08/30 13:17:45 batch 131: mean=21.454545 stddev=12.619348 entropy=0.250015 frames=7340 count=22
2017/08/30 13:17:45 Training policy...
2017/08/30 13:17:49 tune 0: objective=0.129307 reg=0.002500 prune=0
2017/08/30 13:17:51 step 0: objective=0.129307 reg=0.002500
2017/08/30 13:17:52 step 1: objective=0.129520 reg=0.002500
2017/08/30 13:17:53 step 2: objective=0.129714 reg=0.002500
2017/08/30 13:17:54 step 3: objective=0.129869 reg=0.002501
2017/08/30 13:17:56 step 4: objective=0.130031 reg=0.002502
2017/08/30 13:17:57 step 5: objective=0.130140 reg=0.002500
2017/08/30 13:17:58 step 6: objective=0.130238 reg=0.002499
2017/08/30 13:17:59 step 7: objective=0.130356 reg=0.002499
2017/08/30 13:17:59 Training value function...
2017/08/30 13:18:03 step 0: mse=0.248852 step=0.050000
2017/08/30 13:18:04 step 1: mse=0.248538 step=0.050000
2017/08/30 13:18:05 step 2: mse=0.248507 step=0.050000
2017/08/30 13:18:06 step 3: mse=0.248255 step=0.050000
2017/08/30 13:18:08 step 4: mse=0.248292 step=0.050000
2017/08/30 13:18:09 step 5: mse=0.248222 step=0.050000
2017/08/30 13:18:10 step 6: mse=0.248228 step=0.050000
2017/08/30 13:18:11 step 7: mse=0.248012 step=0.050000
2017/08/30 13:18:11 Saving...
2017/08/30 13:18:11 Gathering batch of experience...
2017/08/30 13:18:46 batch 132: mean=17.875000 stddev=13.411166 entropy=0.255159 frames=6738 count=24
2017/08/30 13:18:46 Training policy...
2017/08/30 13:18:50 tune 0: objective=0.114376 reg=0.002552 prune=0
2017/08/30 13:18:51 step 0: objective=0.114377 reg=0.002552
2017/08/30 13:18:52 step 1: objective=0.114542 reg=0.002553
2017/08/30 13:18:53 step 2: objective=0.114688 reg=0.002554
2017/08/30 13:18:54 step 3: objective=0.114832 reg=0.002555
2017/08/30 13:18:56 step 4: objective=0.114927 reg=0.002556
2017/08/30 13:18:57 step 5: objective=0.115032 reg=0.002556
2017/08/30 13:18:58 step 6: objective=0.115169 reg=0.002556
2017/08/30 13:18:59 step 7: objective=0.115358 reg=0.002556
2017/08/30 13:18:59 Training value function...
2017/08/30 13:19:02 step 0: mse=0.263759 step=0.050000
2017/08/30 13:19:03 step 1: mse=0.264443 step=0.050000
2017/08/30 13:19:04 step 2: mse=0.265469 step=0.050000
2017/08/30 13:19:05 step 3: mse=0.265972 step=0.050000
2017/08/30 13:19:06 step 4: mse=0.266320 step=0.050000
2017/08/30 13:19:08 step 5: mse=0.266985 step=0.050000
2017/08/30 13:19:09 step 6: mse=0.267618 step=0.050000
2017/08/30 13:19:10 step 7: mse=0.268053 step=0.050000
2017/08/30 13:19:10 Saving...
2017/08/30 13:19:10 Gathering batch of experience...
2017/08/30 13:19:48 batch 133: mean=20.125000 stddev=13.408059 entropy=0.251041 frames=7519 count=24
2017/08/30 13:19:48 Training policy...
2017/08/30 13:19:52 tune 0: objective=0.132551 reg=0.002510 prune=0
2017/08/30 13:19:54 step 0: objective=0.132551 reg=0.002510
2017/08/30 13:19:55 step 1: objective=0.132722 reg=0.002510
2017/08/30 13:19:56 step 2: objective=0.132918 reg=0.002510
2017/08/30 13:19:57 step 3: objective=0.133058 reg=0.002510
2017/08/30 13:19:59 step 4: objective=0.133204 reg=0.002508
2017/08/30 13:20:00 step 5: objective=0.133365 reg=0.002507
2017/08/30 13:20:01 step 6: objective=0.133512 reg=0.002506
2017/08/30 13:20:03 step 7: objective=0.133602 reg=0.002506
2017/08/30 13:20:03 Training value function...
2017/08/30 13:20:06 step 0: mse=0.272191 step=0.050000
2017/08/30 13:20:07 step 1: mse=0.270505 step=0.050000
2017/08/30 13:20:08 step 2: mse=0.269242 step=0.050000
2017/08/30 13:20:10 step 3: mse=0.267887 step=0.050000
2017/08/30 13:20:11 step 4: mse=0.266436 step=0.050000
2017/08/30 13:20:12 step 5: mse=0.264797 step=0.050000
2017/08/30 13:20:13 step 6: mse=0.263608 step=0.050000
2017/08/30 13:20:15 step 7: mse=0.262007 step=0.050000
2017/08/30 13:20:15 Saving...
2017/08/30 13:20:15 Gathering batch of experience...
2017/08/30 13:20:51 batch 134: mean=22.900000 stddev=13.981774 entropy=0.257668 frames=7128 count=20
2017/08/30 13:20:51 Training policy...
2017/08/30 13:20:55 tune 0: objective=0.136508 reg=0.002577 prune=0
2017/08/30 13:20:56 step 0: objective=0.136509 reg=0.002577
2017/08/30 13:20:58 step 1: objective=0.136622 reg=0.002579
2017/08/30 13:20:59 step 2: objective=0.136719 reg=0.002579
2017/08/30 13:21:00 step 3: objective=0.136781 reg=0.002580
2017/08/30 13:21:01 step 4: objective=0.136880 reg=0.002580
2017/08/30 13:21:02 step 5: objective=0.136994 reg=0.002581
2017/08/30 13:21:04 step 6: objective=0.137111 reg=0.002581
2017/08/30 13:21:05 step 7: objective=0.137199 reg=0.002580
2017/08/30 13:21:05 Training value function...
2017/08/30 13:21:08 step 0: mse=0.264458 step=0.050000
2017/08/30 13:21:09 step 1: mse=0.263252 step=0.050000
2017/08/30 13:21:10 step 2: mse=0.262083 step=0.050000
2017/08/30 13:21:11 step 3: mse=0.260720 step=0.050000
2017/08/30 13:21:13 step 4: mse=0.259921 step=0.050000
2017/08/30 13:21:14 step 5: mse=0.259174 step=0.050000
2017/08/30 13:21:15 step 6: mse=0.258335 step=0.050000
2017/08/30 13:21:16 step 7: mse=0.257399 step=0.050000
2017/08/30 13:21:16 Saving...
2017/08/30 13:21:16 Gathering batch of experience...
2017/08/30 13:21:53 batch 135: mean=23.000000 stddev=13.859843 entropy=0.253596 frames=7520 count=21
2017/08/30 13:21:53 Training policy...
2017/08/30 13:21:57 tune 0: objective=0.133223 reg=0.002536 prune=0
2017/08/30 13:21:58 step 0: objective=0.133223 reg=0.002536
2017/08/30 13:22:00 step 1: objective=0.133337 reg=0.002534
2017/08/30 13:22:01 step 2: objective=0.133457 reg=0.002533
2017/08/30 13:22:02 step 3: objective=0.133540 reg=0.002532
2017/08/30 13:22:04 step 4: objective=0.133633 reg=0.002530
2017/08/30 13:22:05 step 5: objective=0.133712 reg=0.002531
2017/08/30 13:22:06 step 6: objective=0.133791 reg=0.002531
2017/08/30 13:22:08 step 7: objective=0.133865 reg=0.002532
2017/08/30 13:22:08 Training value function...
2017/08/30 13:22:11 step 0: mse=0.259154 step=0.050000
2017/08/30 13:22:12 step 1: mse=0.258970 step=0.050000
2017/08/30 13:22:13 step 2: mse=0.258213 step=0.050000
2017/08/30 13:22:15 step 3: mse=0.257445 step=0.050000
2017/08/30 13:22:16 step 4: mse=0.256917 step=0.050000
2017/08/30 13:22:17 step 5: mse=0.256301 step=0.050000
2017/08/30 13:22:18 step 6: mse=0.256057 step=0.050000
2017/08/30 13:22:20 step 7: mse=0.255557 step=0.050000
2017/08/30 13:22:20 Saving...
2017/08/30 13:22:20 Gathering batch of experience...
2017/08/30 13:23:00 batch 136: mean=25.047619 stddev=13.145617 entropy=0.253064 frames=8227 count=21
2017/08/30 13:23:00 Training policy...
2017/08/30 13:23:04 tune 0: objective=0.131824 reg=0.002531 prune=0
2017/08/30 13:23:06 step 0: objective=0.131824 reg=0.002531
2017/08/30 13:23:07 step 1: objective=0.131941 reg=0.002530
2017/08/30 13:23:09 step 2: objective=0.132143 reg=0.002531
2017/08/30 13:23:10 step 3: objective=0.132259 reg=0.002530
2017/08/30 13:23:11 step 4: objective=0.132387 reg=0.002529
2017/08/30 13:23:13 step 5: objective=0.132535 reg=0.002527
2017/08/30 13:23:14 step 6: objective=0.132645 reg=0.002528
2017/08/30 13:23:16 step 7: objective=0.132763 reg=0.002527
2017/08/30 13:23:16 Training value function...
2017/08/30 13:23:19 step 0: mse=0.260569 step=0.050000
2017/08/30 13:23:21 step 1: mse=0.259808 step=0.050000
2017/08/30 13:23:22 step 2: mse=0.259256 step=0.050000
2017/08/30 13:23:23 step 3: mse=0.258588 step=0.050000
2017/08/30 13:23:25 step 4: mse=0.257879 step=0.050000
2017/08/30 13:23:26 step 5: mse=0.257354 step=0.050000
2017/08/30 13:23:28 step 6: mse=0.256969 step=0.050000
2017/08/30 13:23:29 step 7: mse=0.256524 step=0.050000
2017/08/30 13:23:29 Saving...
2017/08/30 13:23:29 Gathering batch of experience...
2017/08/30 13:24:09 batch 137: mean=25.600000 stddev=13.211359 entropy=0.250194 frames=7970 count=20
2017/08/30 13:24:09 Training policy...
2017/08/30 13:24:14 tune 0: objective=0.135251 reg=0.002502 prune=0
2017/08/30 13:24:15 step 0: objective=0.135251 reg=0.002502
2017/08/30 13:24:17 step 1: objective=0.135364 reg=0.002503
2017/08/30 13:24:18 step 2: objective=0.135446 reg=0.002503
2017/08/30 13:24:19 step 3: objective=0.135559 reg=0.002504
2017/08/30 13:24:21 step 4: objective=0.135670 reg=0.002504
2017/08/30 13:24:22 step 5: objective=0.135832 reg=0.002505
2017/08/30 13:24:23 step 6: objective=0.135959 reg=0.002505
2017/08/30 13:24:25 step 7: objective=0.136148 reg=0.002505
2017/08/30 13:24:25 Training value function...
2017/08/30 13:24:28 step 0: mse=0.255668 step=0.050000
2017/08/30 13:24:29 step 1: mse=0.254703 step=0.050000
2017/08/30 13:24:31 step 2: mse=0.254037 step=0.050000
2017/08/30 13:24:32 step 3: mse=0.253655 step=0.050000
2017/08/30 13:24:34 step 4: mse=0.253272 step=0.050000
2017/08/30 13:24:35 step 5: mse=0.252893 step=0.050000
2017/08/30 13:24:36 step 6: mse=0.252466 step=0.050000
2017/08/30 13:24:38 step 7: mse=0.251629 step=0.050000
2017/08/30 13:24:38 Saving...
2017/08/30 13:24:38 Gathering batch of experience...
2017/08/30 13:25:13 batch 138: mean=21.045455 stddev=13.411248 entropy=0.251692 frames=7229 count=22
2017/08/30 13:25:13 Training policy...
2017/08/30 13:25:17 tune 0: objective=0.124032 reg=0.002517 prune=0
2017/08/30 13:25:18 step 0: objective=0.124032 reg=0.002517
2017/08/30 13:25:19 step 1: objective=0.124198 reg=0.002516
2017/08/30 13:25:20 step 2: objective=0.124315 reg=0.002515
2017/08/30 13:25:22 step 3: objective=0.124483 reg=0.002514
2017/08/30 13:25:23 step 4: objective=0.124599 reg=0.002513
2017/08/30 13:25:24 step 5: objective=0.124670 reg=0.002512
2017/08/30 13:25:25 step 6: objective=0.124777 reg=0.002511
2017/08/30 13:25:27 step 7: objective=0.124942 reg=0.002511
2017/08/30 13:25:27 Training value function...
2017/08/30 13:25:30 step 0: mse=0.251462 step=0.050000
2017/08/30 13:25:31 step 1: mse=0.251368 step=0.050000
2017/08/30 13:25:32 step 2: mse=0.251285 step=0.050000
2017/08/30 13:25:33 step 3: mse=0.251366 step=0.050000
2017/08/30 13:25:35 step 4: mse=0.251147 step=0.050000
2017/08/30 13:25:36 step 5: mse=0.251048 step=0.050000
2017/08/30 13:25:37 step 6: mse=0.251357 step=0.050000
2017/08/30 13:25:38 step 7: mse=0.251222 step=0.050000
2017/08/30 13:25:38 Saving...
2017/08/30 13:25:38 Gathering batch of experience...
2017/08/30 13:26:16 batch 139: mean=18.640000 stddev=12.211077 entropy=0.252955 frames=7348 count=25
2017/08/30 13:26:16 Training policy...
2017/08/30 13:26:20 tune 0: objective=0.109057 reg=0.002530 prune=0
2017/08/30 13:26:22 step 0: objective=0.109057 reg=0.002530
2017/08/30 13:26:23 step 1: objective=0.109247 reg=0.002529
2017/08/30 13:26:24 step 2: objective=0.109423 reg=0.002530
2017/08/30 13:26:25 step 3: objective=0.109689 reg=0.002530
2017/08/30 13:26:27 step 4: objective=0.109877 reg=0.002528
2017/08/30 13:26:28 step 5: objective=0.110003 reg=0.002526
2017/08/30 13:26:29 step 6: objective=0.110092 reg=0.002525
2017/08/30 13:26:30 step 7: objective=0.110213 reg=0.002524
2017/08/30 13:26:30 Training value function...
2017/08/30 13:26:33 step 0: mse=0.255017 step=0.050000
2017/08/30 13:26:35 step 1: mse=0.255353 step=0.050000
2017/08/30 13:26:36 step 2: mse=0.256006 step=0.050000
2017/08/30 13:26:37 step 3: mse=0.256715 step=0.050000
2017/08/30 13:26:38 step 4: mse=0.257354 step=0.050000
2017/08/30 13:26:40 step 5: mse=0.257789 step=0.050000
2017/08/30 13:26:41 step 6: mse=0.258425 step=0.050000
2017/08/30 13:26:42 step 7: mse=0.258727 step=0.050000
2017/08/30 13:26:42 Saving...
2017/08/30 13:26:42 Gathering batch of experience...
2017/08/30 13:27:18 batch 140: mean=26.166667 stddev=15.621388 entropy=0.255661 frames=7291 count=18
2017/08/30 13:27:18 Training policy...
2017/08/30 13:27:22 tune 0: objective=0.150356 reg=0.002557 prune=0
2017/08/30 13:27:23 step 0: objective=0.150356 reg=0.002557
2017/08/30 13:27:25 step 1: objective=0.150434 reg=0.002556
2017/08/30 13:27:26 step 2: objective=0.150560 reg=0.002555
2017/08/30 13:27:27 step 3: objective=0.150623 reg=0.002555
2017/08/30 13:27:28 step 4: objective=0.150687 reg=0.002553
2017/08/30 13:27:30 step 5: objective=0.150810 reg=0.002552
2017/08/30 13:27:31 step 6: objective=0.151020 reg=0.002551
2017/08/30 13:27:32 step 7: objective=0.151116 reg=0.002550
2017/08/30 13:27:32 Training value function...
2017/08/30 13:27:35 step 0: mse=0.274607 step=0.050000
2017/08/30 13:27:36 step 1: mse=0.271301 step=0.050000
2017/08/30 13:27:38 step 2: mse=0.268352 step=0.050000
2017/08/30 13:27:39 step 3: mse=0.264827 step=0.050000
2017/08/30 13:27:40 step 4: mse=0.261819 step=0.050000
2017/08/30 13:27:41 step 5: mse=0.258839 step=0.050000
2017/08/30 13:27:43 step 6: mse=0.256440 step=0.050000
2017/08/30 13:27:44 step 7: mse=0.254373 step=0.050000
2017/08/30 13:27:44 Saving...
2017/08/30 13:27:44 Gathering batch of experience...
2017/08/30 13:28:22 batch 141: mean=26.157895 stddev=12.436208 entropy=0.250740 frames=7736 count=19
2017/08/30 13:28:22 Training policy...
2017/08/30 13:28:26 tune 0: objective=0.135154 reg=0.002507 prune=0
2017/08/30 13:28:28 step 0: objective=0.135154 reg=0.002507
2017/08/30 13:28:29 step 1: objective=0.135244 reg=0.002508
2017/08/30 13:28:30 step 2: objective=0.135377 reg=0.002507
2017/08/30 13:28:32 step 3: objective=0.135461 reg=0.002506
2017/08/30 13:28:33 step 4: objective=0.135535 reg=0.002506
2017/08/30 13:28:34 step 5: objective=0.135583 reg=0.002505
2017/08/30 13:28:36 step 6: objective=0.135723 reg=0.002504
2017/08/30 13:28:37 step 7: objective=0.135824 reg=0.002502
2017/08/30 13:28:37 Training value function...
2017/08/30 13:28:40 step 0: mse=0.252088 step=0.050000
2017/08/30 13:28:42 step 1: mse=0.251379 step=0.050000
2017/08/30 13:28:43 step 2: mse=0.250649 step=0.050000
2017/08/30 13:28:44 step 3: mse=0.249794 step=0.050000
2017/08/30 13:28:46 step 4: mse=0.249240 step=0.050000
2017/08/30 13:28:47 step 5: mse=0.248464 step=0.050000
2017/08/30 13:28:48 step 6: mse=0.247845 step=0.050000
2017/08/30 13:28:50 step 7: mse=0.247246 step=0.050000
2017/08/30 13:28:50 Saving...
2017/08/30 13:28:50 Gathering batch of experience...
2017/08/30 13:29:23 batch 142: mean=18.000000 stddev=13.406240 entropy=0.250905 frames=6212 count=22
2017/08/30 13:29:23 Training policy...
2017/08/30 13:29:26 tune 0: objective=0.109171 reg=0.002509 prune=0
2017/08/30 13:29:27 step 0: objective=0.109172 reg=0.002509
2017/08/30 13:29:28 step 1: objective=0.109269 reg=0.002510
2017/08/30 13:29:29 step 2: objective=0.109382 reg=0.002510
2017/08/30 13:29:30 step 3: objective=0.109525 reg=0.002511
2017/08/30 13:29:31 step 4: objective=0.109675 reg=0.002510
2017/08/30 13:29:33 step 5: objective=0.109804 reg=0.002509
2017/08/30 13:29:34 step 6: objective=0.110014 reg=0.002508
2017/08/30 13:29:35 step 7: objective=0.110184 reg=0.002508
2017/08/30 13:29:35 Training value function...
2017/08/30 13:29:37 step 0: mse=0.248718 step=0.050000
2017/08/30 13:29:38 step 1: mse=0.249490 step=0.050000
2017/08/30 13:29:39 step 2: mse=0.250481 step=0.050000
2017/08/30 13:29:40 step 3: mse=0.251445 step=0.050000
2017/08/30 13:29:41 step 4: mse=0.252309 step=0.050000
2017/08/30 13:29:43 step 5: mse=0.253145 step=0.050000
2017/08/30 13:29:44 step 6: mse=0.254036 step=0.050000
2017/08/30 13:29:45 step 7: mse=0.254949 step=0.050000
2017/08/30 13:29:45 Saving...
2017/08/30 13:29:45 Gathering batch of experience...
2017/08/30 13:30:21 batch 143: mean=22.809524 stddev=14.397814 entropy=0.248097 frames=7470 count=21
2017/08/30 13:30:21 Training policy...
2017/08/30 13:30:25 tune 0: objective=0.135546 reg=0.002481 prune=0
2017/08/30 13:30:27 step 0: objective=0.135546 reg=0.002481
2017/08/30 13:30:28 step 1: objective=0.135687 reg=0.002480
2017/08/30 13:30:29 step 2: objective=0.135831 reg=0.002479
2017/08/30 13:30:31 step 3: objective=0.136005 reg=0.002478
2017/08/30 13:30:32 step 4: objective=0.136093 reg=0.002477
2017/08/30 13:30:33 step 5: objective=0.136280 reg=0.002476
2017/08/30 13:30:35 step 6: objective=0.136412 reg=0.002474
2017/08/30 13:30:36 step 7: objective=0.136480 reg=0.002474
2017/08/30 13:30:36 Training value function...
2017/08/30 13:30:39 step 0: mse=0.260808 step=0.050000
2017/08/30 13:30:40 step 1: mse=0.259807 step=0.050000
2017/08/30 13:30:42 step 2: mse=0.258666 step=0.050000
2017/08/30 13:30:43 step 3: mse=0.257872 step=0.050000
2017/08/30 13:30:44 step 4: mse=0.257200 step=0.050000
2017/08/30 13:30:45 step 5: mse=0.256528 step=0.050000
2017/08/30 13:30:47 step 6: mse=0.256063 step=0.050000
2017/08/30 13:30:48 step 7: mse=0.255430 step=0.050000
2017/08/30 13:30:48 Saving...
2017/08/30 13:30:48 Gathering batch of experience...
2017/08/30 13:31:28 batch 144: mean=26.631579 stddev=12.406325 entropy=0.245251 frames=7888 count=19
2017/08/30 13:31:28 Training policy...
2017/08/30 13:31:32 tune 0: objective=0.137161 reg=0.002453 prune=0
2017/08/30 13:31:34 step 0: objective=0.137162 reg=0.002453
2017/08/30 13:31:35 step 1: objective=0.137309 reg=0.002451
2017/08/30 13:31:36 step 2: objective=0.137580 reg=0.002449
2017/08/30 13:31:38 step 3: objective=0.137654 reg=0.002449
2017/08/30 13:31:39 step 4: objective=0.137871 reg=0.002450
2017/08/30 13:31:40 step 5: objective=0.138058 reg=0.002448
2017/08/30 13:31:42 step 6: objective=0.138246 reg=0.002448
2017/08/30 13:31:43 step 7: objective=0.138358 reg=0.002447
2017/08/30 13:31:43 Training value function...
2017/08/30 13:31:46 step 0: mse=0.260088 step=0.050000
2017/08/30 13:31:48 step 1: mse=0.259249 step=0.050000
2017/08/30 13:31:49 step 2: mse=0.258292 step=0.050000
2017/08/30 13:31:51 step 3: mse=0.257172 step=0.050000
2017/08/30 13:31:52 step 4: mse=0.256020 step=0.050000
2017/08/30 13:31:53 step 5: mse=0.255193 step=0.050000
2017/08/30 13:31:55 step 6: mse=0.254659 step=0.050000
2017/08/30 13:31:56 step 7: mse=0.254267 step=0.050000
2017/08/30 13:31:56 Saving...
2017/08/30 13:31:56 Gathering batch of experience...
2017/08/30 13:32:33 batch 145: mean=26.315789 stddev=12.969814 entropy=0.249548 frames=7771 count=19
2017/08/30 13:32:33 Training policy...
2017/08/30 13:32:37 tune 0: objective=0.136318 reg=0.002495 prune=0
2017/08/30 13:32:39 step 0: objective=0.136318 reg=0.002495
2017/08/30 13:32:40 step 1: objective=0.136418 reg=0.002497
2017/08/30 13:32:41 step 2: objective=0.136517 reg=0.002498
2017/08/30 13:32:43 step 3: objective=0.136640 reg=0.002499
2017/08/30 13:32:44 step 4: objective=0.136707 reg=0.002500
2017/08/30 13:32:46 step 5: objective=0.136807 reg=0.002499
2017/08/30 13:32:47 step 6: objective=0.136901 reg=0.002499
2017/08/30 13:32:48 step 7: objective=0.136964 reg=0.002499
2017/08/30 13:32:48 Training value function...
2017/08/30 13:32:51 step 0: mse=0.244965 step=0.050000
2017/08/30 13:32:53 step 1: mse=0.243703 step=0.050000
2017/08/30 13:32:54 step 2: mse=0.242552 step=0.050000
2017/08/30 13:32:55 step 3: mse=0.241667 step=0.050000
2017/08/30 13:32:57 step 4: mse=0.240687 step=0.050000
2017/08/30 13:32:58 step 5: mse=0.240004 step=0.050000
2017/08/30 13:32:59 step 6: mse=0.239396 step=0.050000
2017/08/30 13:33:01 step 7: mse=0.238774 step=0.050000
2017/08/30 13:33:01 Saving...
2017/08/30 13:33:01 Gathering batch of experience...
2017/08/30 13:33:38 batch 146: mean=23.666667 stddev=11.704022 entropy=0.245767 frames=7730 count=21
2017/08/30 13:33:38 Training policy...
2017/08/30 13:33:42 tune 0: objective=0.127229 reg=0.002458 prune=0
2017/08/30 13:33:43 step 0: objective=0.127230 reg=0.002458
2017/08/30 13:33:45 step 1: objective=0.127395 reg=0.002458
2017/08/30 13:33:46 step 2: objective=0.127531 reg=0.002458
2017/08/30 13:33:47 step 3: objective=0.127663 reg=0.002456
2017/08/30 13:33:49 step 4: objective=0.127826 reg=0.002456
2017/08/30 13:33:50 step 5: objective=0.127986 reg=0.002454
2017/08/30 13:33:51 step 6: objective=0.128093 reg=0.002452
2017/08/30 13:33:53 step 7: objective=0.128235 reg=0.002451
2017/08/30 13:33:53 Training value function...
2017/08/30 13:33:56 step 0: mse=0.236697 step=0.050000
2017/08/30 13:33:57 step 1: mse=0.236303 step=0.050000
2017/08/30 13:33:59 step 2: mse=0.235875 step=0.050000
2017/08/30 13:34:00 step 3: mse=0.235102 step=0.050000
2017/08/30 13:34:01 step 4: mse=0.235009 step=0.050000
2017/08/30 13:34:03 step 5: mse=0.234604 step=0.050000
2017/08/30 13:34:04 step 6: mse=0.234411 step=0.050000
2017/08/30 13:34:05 step 7: mse=0.234052 step=0.050000
2017/08/30 13:34:05 Saving...
2017/08/30 13:34:05 Gathering batch of experience...
2017/08/30 13:34:44 batch 147: mean=18.960000 stddev=13.468422 entropy=0.249872 frames=7406 count=25
2017/08/30 13:34:44 Training policy...
2017/08/30 13:34:48 tune 0: objective=0.114841 reg=0.002499 prune=0
2017/08/30 13:34:49 step 0: objective=0.114841 reg=0.002499
2017/08/30 13:34:50 step 1: objective=0.114944 reg=0.002499
2017/08/30 13:34:51 step 2: objective=0.115151 reg=0.002497
2017/08/30 13:34:53 step 3: objective=0.115396 reg=0.002497
2017/08/30 13:34:54 step 4: objective=0.115523 reg=0.002496
2017/08/30 13:34:55 step 5: objective=0.115590 reg=0.002497
2017/08/30 13:34:57 step 6: objective=0.115711 reg=0.002498
2017/08/30 13:34:58 step 7: objective=0.115752 reg=0.002499
2017/08/30 13:34:58 Training value function...
2017/08/30 13:35:01 step 0: mse=0.245968 step=0.050000
2017/08/30 13:35:02 step 1: mse=0.246839 step=0.050000
2017/08/30 13:35:03 step 2: mse=0.247500 step=0.050000
2017/08/30 13:35:05 step 3: mse=0.247950 step=0.050000
2017/08/30 13:35:06 step 4: mse=0.248492 step=0.050000
2017/08/30 13:35:07 step 5: mse=0.249320 step=0.050000
2017/08/30 13:35:09 step 6: mse=0.250120 step=0.050000
2017/08/30 13:35:10 step 7: mse=0.250797 step=0.050000
2017/08/30 13:35:10 Saving...
2017/08/30 13:35:10 Gathering batch of experience...
2017/08/30 13:35:48 batch 148: mean=27.388889 stddev=12.676044 entropy=0.251480 frames=7646 count=18
2017/08/30 13:35:48 Training policy...
2017/08/30 13:35:53 tune 0: objective=0.146124 reg=0.002515 prune=0
2017/08/30 13:35:54 step 0: objective=0.146124 reg=0.002515
2017/08/30 13:35:55 step 1: objective=0.146329 reg=0.002514
2017/08/30 13:35:57 step 2: objective=0.146428 reg=0.002512
2017/08/30 13:35:58 step 3: objective=0.146636 reg=0.002512
2017/08/30 13:35:59 step 4: objective=0.146708 reg=0.002510
2017/08/30 13:36:01 step 5: objective=0.146795 reg=0.002509
2017/08/30 13:36:02 step 6: objective=0.146884 reg=0.002507
2017/08/30 13:36:03 step 7: objective=0.147030 reg=0.002505
2017/08/30 13:36:03 Training value function...
2017/08/30 13:36:06 step 0: mse=0.256884 step=0.050000
2017/08/30 13:36:08 step 1: mse=0.254210 step=0.050000
2017/08/30 13:36:09 step 2: mse=0.251567 step=0.050000
2017/08/30 13:36:10 step 3: mse=0.249896 step=0.050000
2017/08/30 13:36:12 step 4: mse=0.247621 step=0.050000
2017/08/30 13:36:13 step 5: mse=0.245622 step=0.050000
2017/08/30 13:36:14 step 6: mse=0.244153 step=0.050000
2017/08/30 13:36:16 step 7: mse=0.242984 step=0.050000
2017/08/30 13:36:16 Saving...
2017/08/30 13:36:16 Gathering batch of experience...
2017/08/30 13:36:52 batch 149: mean=19.791667 stddev=14.545845 entropy=0.244467 frames=7416 count=24
2017/08/30 13:36:52 Training policy...
2017/08/30 13:36:56 tune 0: objective=0.121008 reg=0.002445 prune=0
2017/08/30 13:36:58 step 0: objective=0.121008 reg=0.002445
2017/08/30 13:36:59 step 1: objective=0.121089 reg=0.002445
2017/08/30 13:37:00 step 2: objective=0.121161 reg=0.002446
2017/08/30 13:37:02 step 3: objective=0.121240 reg=0.002447
2017/08/30 13:37:03 step 4: objective=0.121335 reg=0.002448
2017/08/30 13:37:04 step 5: objective=0.121420 reg=0.002449
2017/08/30 13:37:05 step 6: objective=0.121506 reg=0.002449
2017/08/30 13:37:07 step 7: objective=0.121555 reg=0.002448
2017/08/30 13:37:07 Training value function...
2017/08/30 13:37:10 step 0: mse=0.248580 step=0.050000
2017/08/30 13:37:11 step 1: mse=0.248615 step=0.050000
2017/08/30 13:37:12 step 2: mse=0.248880 step=0.050000
2017/08/30 13:37:14 step 3: mse=0.248952 step=0.050000
2017/08/30 13:37:15 step 4: mse=0.249218 step=0.050000
2017/08/30 13:37:16 step 5: mse=0.249354 step=0.050000
2017/08/30 13:37:17 step 6: mse=0.249935 step=0.050000
2017/08/30 13:37:19 step 7: mse=0.250115 step=0.050000
2017/08/30 13:37:19 Saving...
2017/08/30 13:37:19 Gathering batch of experience...
2017/08/30 13:38:00 batch 150: mean=24.045455 stddev=12.189702 entropy=0.247397 frames=8263 count=22
2017/08/30 13:38:00 Training policy...
2017/08/30 13:38:04 tune 0: objective=0.125985 reg=0.002474 prune=0
2017/08/30 13:38:06 step 0: objective=0.125986 reg=0.002474
2017/08/30 13:38:07 step 1: objective=0.126125 reg=0.002473
2017/08/30 13:38:09 step 2: objective=0.126218 reg=0.002474
2017/08/30 13:38:10 step 3: objective=0.126340 reg=0.002474
2017/08/30 13:38:12 step 4: objective=0.126409 reg=0.002474
2017/08/30 13:38:13 step 5: objective=0.126503 reg=0.002473
2017/08/30 13:38:14 step 6: objective=0.126575 reg=0.002473
2017/08/30 13:38:16 step 7: objective=0.126678 reg=0.002475
2017/08/30 13:38:16 Training value function...
2017/08/30 13:38:19 step 0: mse=0.249502 step=0.050000
2017/08/30 13:38:21 step 1: mse=0.249312 step=0.050000
2017/08/30 13:38:22 step 2: mse=0.248865 step=0.050000
2017/08/30 13:38:24 step 3: mse=0.248704 step=0.050000
2017/08/30 13:38:25 step 4: mse=0.248506 step=0.050000
2017/08/30 13:38:27 step 5: mse=0.248304 step=0.050000
2017/08/30 13:38:28 step 6: mse=0.248288 step=0.050000
2017/08/30 13:38:29 step 7: mse=0.248265 step=0.050000
2017/08/30 13:38:29 Saving...
2017/08/30 13:38:29 Gathering batch of experience...
2017/08/30 13:39:07 batch 151: mean=22.809524 stddev=12.077602 entropy=0.246600 frames=7439 count=21
2017/08/30 13:39:07 Training policy...
2017/08/30 13:39:11 tune 0: objective=0.129856 reg=0.002466 prune=0
2017/08/30 13:39:12 step 0: objective=0.129856 reg=0.002466
2017/08/30 13:39:14 step 1: objective=0.129994 reg=0.002465
2017/08/30 13:39:15 step 2: objective=0.130122 reg=0.002466
2017/08/30 13:39:16 step 3: objective=0.130183 reg=0.002465
2017/08/30 13:39:18 step 4: objective=0.130348 reg=0.002464
2017/08/30 13:39:19 step 5: objective=0.130518 reg=0.002463
2017/08/30 13:39:20 step 6: objective=0.130592 reg=0.002462
2017/08/30 13:39:21 step 7: objective=0.130672 reg=0.002461
2017/08/30 13:39:21 Training value function...
2017/08/30 13:39:24 step 0: mse=0.249405 step=0.050000
2017/08/30 13:39:26 step 1: mse=0.249050 step=0.050000
2017/08/30 13:39:27 step 2: mse=0.248478 step=0.050000
2017/08/30 13:39:28 step 3: mse=0.247866 step=0.050000
2017/08/30 13:39:30 step 4: mse=0.247285 step=0.050000
2017/08/30 13:39:31 step 5: mse=0.246936 step=0.050000
2017/08/30 13:39:32 step 6: mse=0.246039 step=0.050000
2017/08/30 13:39:33 step 7: mse=0.245353 step=0.050000
2017/08/30 13:39:33 Saving...
2017/08/30 13:39:33 Gathering batch of experience...
2017/08/30 13:40:09 batch 152: mean=21.190476 stddev=13.489393 entropy=0.247375 frames=6945 count=21
2017/08/30 13:40:09 Training policy...
2017/08/30 13:40:13 tune 0: objective=0.124457 reg=0.002474 prune=0
2017/08/30 13:40:14 step 0: objective=0.124458 reg=0.002474
2017/08/30 13:40:15 step 1: objective=0.124654 reg=0.002475
2017/08/30 13:40:16 step 2: objective=0.124937 reg=0.002475
2017/08/30 13:40:17 step 3: objective=0.125192 reg=0.002476
2017/08/30 13:40:19 step 4: objective=0.125458 reg=0.002476
2017/08/30 13:40:20 step 5: objective=0.125593 reg=0.002474
2017/08/30 13:40:21 step 6: objective=0.125786 reg=0.002474
2017/08/30 13:40:22 step 7: objective=0.125860 reg=0.002472
2017/08/30 13:40:22 Training value function...
2017/08/30 13:40:25 step 0: mse=0.253638 step=0.050000
2017/08/30 13:40:26 step 1: mse=0.253706 step=0.050000
2017/08/30 13:40:27 step 2: mse=0.253861 step=0.050000
2017/08/30 13:40:29 step 3: mse=0.253723 step=0.050000
2017/08/30 13:40:30 step 4: mse=0.253725 step=0.050000
2017/08/30 13:40:31 step 5: mse=0.254048 step=0.050000
2017/08/30 13:40:32 step 6: mse=0.253965 step=0.050000
2017/08/30 13:40:33 step 7: mse=0.254162 step=0.050000
2017/08/30 13:40:33 Saving...
2017/08/30 13:40:33 Gathering batch of experience...
2017/08/30 13:41:14 batch 153: mean=25.571429 stddev=12.253557 entropy=0.242967 frames=8357 count=21
2017/08/30 13:41:14 Training policy...
2017/08/30 13:41:18 tune 0: objective=0.137721 reg=0.002430 prune=0
2017/08/30 13:41:20 step 0: objective=0.137722 reg=0.002430
2017/08/30 13:41:21 step 1: objective=0.137791 reg=0.002428
2017/08/30 13:41:23 step 2: objective=0.137865 reg=0.002428
2017/08/30 13:41:24 step 3: objective=0.137937 reg=0.002427
2017/08/30 13:41:26 step 4: objective=0.138013 reg=0.002427
2017/08/30 13:41:27 step 5: objective=0.138069 reg=0.002427
2017/08/30 13:41:29 step 6: objective=0.138135 reg=0.002428
2017/08/30 13:41:30 step 7: objective=0.138219 reg=0.002427
2017/08/30 13:41:30 Training value function...
2017/08/30 13:41:33 step 0: mse=0.254131 step=0.050000
2017/08/30 13:41:35 step 1: mse=0.252912 step=0.050000
2017/08/30 13:41:36 step 2: mse=0.251772 step=0.050000
2017/08/30 13:41:38 step 3: mse=0.251011 step=0.050000
2017/08/30 13:41:39 step 4: mse=0.250375 step=0.050000
2017/08/30 13:41:41 step 5: mse=0.249532 step=0.050000
2017/08/30 13:41:42 step 6: mse=0.248632 step=0.050000
2017/08/30 13:41:44 step 7: mse=0.247904 step=0.050000
2017/08/30 13:41:44 Saving...
2017/08/30 13:41:44 Gathering batch of experience...
2017/08/30 13:42:22 batch 154: mean=27.777778 stddev=14.018066 entropy=0.245047 frames=7763 count=18
2017/08/30 13:42:22 Training policy...
2017/08/30 13:42:26 tune 0: objective=0.141277 reg=0.002450 prune=0
2017/08/30 13:42:28 step 0: objective=0.141277 reg=0.002450
2017/08/30 13:42:29 step 1: objective=0.141465 reg=0.002449
2017/08/30 13:42:30 step 2: objective=0.141684 reg=0.002448
2017/08/30 13:42:32 step 3: objective=0.141819 reg=0.002448
2017/08/30 13:42:33 step 4: objective=0.141970 reg=0.002447
2017/08/30 13:42:34 step 5: objective=0.142053 reg=0.002447
2017/08/30 13:42:36 step 6: objective=0.142182 reg=0.002446
2017/08/30 13:42:37 step 7: objective=0.142231 reg=0.002446
2017/08/30 13:42:37 Training value function...
2017/08/30 13:42:40 step 0: mse=0.258414 step=0.050000
2017/08/30 13:42:42 step 1: mse=0.256569 step=0.050000
2017/08/30 13:42:43 step 2: mse=0.254870 step=0.050000
2017/08/30 13:42:44 step 3: mse=0.253682 step=0.050000
2017/08/30 13:42:46 step 4: mse=0.252586 step=0.050000
2017/08/30 13:42:47 step 5: mse=0.251472 step=0.050000
2017/08/30 13:42:48 step 6: mse=0.250137 step=0.050000
2017/08/30 13:42:50 step 7: mse=0.249248 step=0.050000
2017/08/30 13:42:50 Saving...
2017/08/30 13:42:50 Gathering batch of experience...
2017/08/30 13:43:30 batch 155: mean=24.590909 stddev=14.173147 entropy=0.246159 frames=8384 count=22
2017/08/30 13:43:30 Training policy...
2017/08/30 13:43:35 tune 0: objective=0.133990 reg=0.002462 prune=0
2017/08/30 13:43:36 step 0: objective=0.133990 reg=0.002462
2017/08/30 13:43:38 step 1: objective=0.134060 reg=0.002461
2017/08/30 13:43:39 step 2: objective=0.134197 reg=0.002462
2017/08/30 13:43:41 step 3: objective=0.134313 reg=0.002463
2017/08/30 13:43:42 step 4: objective=0.134437 reg=0.002464
2017/08/30 13:43:43 step 5: objective=0.134548 reg=0.002463
2017/08/30 13:43:45 step 6: objective=0.134640 reg=0.002463
2017/08/30 13:43:46 step 7: objective=0.134688 reg=0.002464
2017/08/30 13:43:46 Training value function...
2017/08/30 13:43:50 step 0: mse=0.244331 step=0.050000
2017/08/30 13:43:51 step 1: mse=0.243103 step=0.050000
2017/08/30 13:43:53 step 2: mse=0.242663 step=0.050000
2017/08/30 13:43:54 step 3: mse=0.242214 step=0.050000
2017/08/30 13:43:56 step 4: mse=0.241180 step=0.050000
2017/08/30 13:43:57 step 5: mse=0.240541 step=0.050000
2017/08/30 13:43:59 step 6: mse=0.240264 step=0.050000
2017/08/30 13:44:00 step 7: mse=0.239944 step=0.050000
2017/08/30 13:44:00 Saving...
2017/08/30 13:44:00 Gathering batch of experience...
2017/08/30 13:44:40 batch 156: mean=19.222222 stddev=14.611850 entropy=0.246764 frames=8115 count=27
2017/08/30 13:44:40 Training policy...
2017/08/30 13:44:45 tune 0: objective=0.112821 reg=0.002468 prune=0
2017/08/30 13:44:46 step 0: objective=0.112822 reg=0.002468
2017/08/30 13:44:48 step 1: objective=0.112885 reg=0.002466
2017/08/30 13:44:49 step 2: objective=0.112980 reg=0.002466
2017/08/30 13:44:50 step 3: objective=0.113119 reg=0.002466
2017/08/30 13:44:52 step 4: objective=0.113325 reg=0.002466
2017/08/30 13:44:53 step 5: objective=0.113406 reg=0.002467
2017/08/30 13:44:55 step 6: objective=0.113581 reg=0.002467
2017/08/30 13:44:56 step 7: objective=0.113750 reg=0.002466
2017/08/30 13:44:56 Training value function...
2017/08/30 13:45:00 step 0: mse=0.250116 step=0.050000
2017/08/30 13:45:01 step 1: mse=0.251006 step=0.050000
2017/08/30 13:45:02 step 2: mse=0.251923 step=0.050000
2017/08/30 13:45:04 step 3: mse=0.252799 step=0.050000
2017/08/30 13:45:05 step 4: mse=0.253256 step=0.050000
2017/08/30 13:45:07 step 5: mse=0.254152 step=0.050000
2017/08/30 13:45:08 step 6: mse=0.254774 step=0.050000
2017/08/30 13:45:09 step 7: mse=0.255470 step=0.050000
2017/08/30 13:45:09 Saving...
2017/08/30 13:45:09 Gathering batch of experience...
2017/08/30 13:45:48 batch 157: mean=22.227273 stddev=15.084404 entropy=0.248659 frames=7595 count=22
2017/08/30 13:45:48 Training policy...
2017/08/30 13:45:52 tune 0: objective=0.131786 reg=0.002487 prune=0
2017/08/30 13:45:53 step 0: objective=0.131787 reg=0.002487
2017/08/30 13:45:54 step 1: objective=0.131977 reg=0.002487
2017/08/30 13:45:56 step 2: objective=0.132163 reg=0.002487
2017/08/30 13:45:57 step 3: objective=0.132347 reg=0.002487
2017/08/30 13:45:58 step 4: objective=0.132537 reg=0.002486
2017/08/30 13:46:00 step 5: objective=0.132750 reg=0.002486
2017/08/30 13:46:01 step 6: objective=0.132909 reg=0.002484
2017/08/30 13:46:02 step 7: objective=0.133008 reg=0.002483
2017/08/30 13:46:02 Training value function...
2017/08/30 13:46:06 step 0: mse=0.258429 step=0.050000
2017/08/30 13:46:07 step 1: mse=0.257926 step=0.050000
2017/08/30 13:46:08 step 2: mse=0.257613 step=0.050000
2017/08/30 13:46:09 step 3: mse=0.256289 step=0.050000
2017/08/30 13:46:11 step 4: mse=0.255972 step=0.050000
2017/08/30 13:46:12 step 5: mse=0.254377 step=0.050000
2017/08/30 13:46:13 step 6: mse=0.253356 step=0.050000
2017/08/30 13:46:15 step 7: mse=0.252901 step=0.050000
2017/08/30 13:46:15 Saving...
2017/08/30 13:46:15 Gathering batch of experience...
2017/08/30 13:46:53 batch 158: mean=25.250000 stddev=11.291036 entropy=0.241557 frames=7878 count=20
2017/08/30 13:46:53 Training policy...
2017/08/30 13:46:57 tune 0: objective=0.130147 reg=0.002416 prune=0
2017/08/30 13:46:58 step 0: objective=0.130147 reg=0.002416
2017/08/30 13:47:00 step 1: objective=0.130254 reg=0.002416
2017/08/30 13:47:01 step 2: objective=0.130338 reg=0.002416
2017/08/30 13:47:02 step 3: objective=0.130477 reg=0.002417
2017/08/30 13:47:04 step 4: objective=0.130565 reg=0.002417
2017/08/30 13:47:05 step 5: objective=0.130711 reg=0.002415
2017/08/30 13:47:07 step 6: objective=0.130774 reg=0.002414
2017/08/30 13:47:08 step 7: objective=0.130906 reg=0.002414
2017/08/30 13:47:08 Training value function...
2017/08/30 13:47:11 step 0: mse=0.255804 step=0.050000
2017/08/30 13:47:13 step 1: mse=0.254730 step=0.050000
2017/08/30 13:47:14 step 2: mse=0.254102 step=0.050000
2017/08/30 13:47:15 step 3: mse=0.253654 step=0.050000
2017/08/30 13:47:17 step 4: mse=0.253056 step=0.050000
2017/08/30 13:47:18 step 5: mse=0.252502 step=0.050000
2017/08/30 13:47:19 step 6: mse=0.251820 step=0.050000
2017/08/30 13:47:21 step 7: mse=0.251431 step=0.050000
2017/08/30 13:47:21 Saving...
2017/08/30 13:47:21 Gathering batch of experience...
2017/08/30 13:47:57 batch 159: mean=21.136364 stddev=13.335855 entropy=0.241405 frames=7235 count=22
2017/08/30 13:47:57 Training policy...
2017/08/30 13:48:01 tune 0: objective=0.124150 reg=0.002414 prune=0
2017/08/30 13:48:02 step 0: objective=0.124150 reg=0.002414
2017/08/30 13:48:04 step 1: objective=0.124267 reg=0.002413
2017/08/30 13:48:05 step 2: objective=0.124407 reg=0.002414
2017/08/30 13:48:06 step 3: objective=0.124471 reg=0.002413
2017/08/30 13:48:07 step 4: objective=0.124549 reg=0.002413
2017/08/30 13:48:09 step 5: objective=0.124645 reg=0.002412
2017/08/30 13:48:10 step 6: objective=0.124784 reg=0.002411
2017/08/30 13:48:11 step 7: objective=0.124881 reg=0.002409
2017/08/30 13:48:11 Training value function...
2017/08/30 13:48:14 step 0: mse=0.248254 step=0.050000
2017/08/30 13:48:15 step 1: mse=0.248644 step=0.050000
2017/08/30 13:48:17 step 2: mse=0.248897 step=0.050000
2017/08/30 13:48:18 step 3: mse=0.249456 step=0.050000
2017/08/30 13:48:19 step 4: mse=0.249393 step=0.050000
2017/08/30 13:48:20 step 5: mse=0.249617 step=0.050000
2017/08/30 13:48:21 step 6: mse=0.249984 step=0.050000
2017/08/30 13:48:23 step 7: mse=0.250078 step=0.050000
2017/08/30 13:48:23 Saving...
2017/08/30 13:48:23 Gathering batch of experience...
2017/08/30 13:49:02 batch 160: mean=21.695652 stddev=13.251529 entropy=0.243610 frames=7829 count=23
2017/08/30 13:49:02 Training policy...
2017/08/30 13:49:06 tune 0: objective=0.121007 reg=0.002436 prune=0
2017/08/30 13:49:07 step 0: objective=0.121008 reg=0.002436
2017/08/30 13:49:09 step 1: objective=0.121154 reg=0.002436
2017/08/30 13:49:10 step 2: objective=0.121398 reg=0.002435
2017/08/30 13:49:11 step 3: objective=0.121596 reg=0.002433
2017/08/30 13:49:13 step 4: objective=0.121774 reg=0.002430
2017/08/30 13:49:14 step 5: objective=0.121919 reg=0.002430
2017/08/30 13:49:16 step 6: objective=0.122037 reg=0.002428
2017/08/30 13:49:17 step 7: objective=0.122087 reg=0.002426
2017/08/30 13:49:17 Training value function...
2017/08/30 13:49:20 step 0: mse=0.259167 step=0.050000
2017/08/30 13:49:22 step 1: mse=0.259300 step=0.050000
2017/08/30 13:49:23 step 2: mse=0.259433 step=0.050000
2017/08/30 13:49:24 step 3: mse=0.259806 step=0.050000
2017/08/30 13:49:26 step 4: mse=0.259912 step=0.050000
2017/08/30 13:49:27 step 5: mse=0.259877 step=0.050000
2017/08/30 13:49:28 step 6: mse=0.259857 step=0.050000
2017/08/30 13:49:30 step 7: mse=0.260115 step=0.050000
2017/08/30 13:49:30 Saving...
2017/08/30 13:49:30 Gathering batch of experience...
2017/08/30 13:50:09 batch 161: mean=27.368421 stddev=14.607894 entropy=0.239631 frames=8043 count=19
2017/08/30 13:50:09 Training policy...
2017/08/30 13:50:13 tune 0: objective=0.147816 reg=0.002396 prune=0
2017/08/30 13:50:15 step 0: objective=0.147816 reg=0.002396
2017/08/30 13:50:16 step 1: objective=0.147893 reg=0.002396
2017/08/30 13:50:18 step 2: objective=0.148086 reg=0.002396
2017/08/30 13:50:19 step 3: objective=0.148212 reg=0.002395
2017/08/30 13:50:21 step 4: objective=0.148397 reg=0.002394
2017/08/30 13:50:22 step 5: objective=0.148522 reg=0.002393
2017/08/30 13:50:23 step 6: objective=0.148658 reg=0.002393
2017/08/30 13:50:25 step 7: objective=0.148804 reg=0.002391
2017/08/30 13:50:25 Training value function...
2017/08/30 13:50:28 step 0: mse=0.261608 step=0.050000
2017/08/30 13:50:29 step 1: mse=0.259163 step=0.050000
2017/08/30 13:50:31 step 2: mse=0.256673 step=0.050000
2017/08/30 13:50:32 step 3: mse=0.253590 step=0.050000
2017/08/30 13:50:34 step 4: mse=0.251336 step=0.050000
2017/08/30 13:50:35 step 5: mse=0.248660 step=0.050000
2017/08/30 13:50:36 step 6: mse=0.246666 step=0.050000
2017/08/30 13:50:38 step 7: mse=0.245028 step=0.050000
2017/08/30 13:50:38 Saving...
2017/08/30 13:50:38 Gathering batch of experience...
2017/08/30 13:51:13 batch 162: mean=21.600000 stddev=13.562448 entropy=0.240833 frames=6740 count=20
2017/08/30 13:51:13 Training policy...
2017/08/30 13:51:16 tune 0: objective=0.123424 reg=0.002408 prune=0
2017/08/30 13:51:17 step 0: objective=0.123425 reg=0.002408
2017/08/30 13:51:19 step 1: objective=0.123561 reg=0.002407
2017/08/30 13:51:20 step 2: objective=0.123670 reg=0.002406
2017/08/30 13:51:21 step 3: objective=0.123759 reg=0.002404
2017/08/30 13:51:22 step 4: objective=0.123882 reg=0.002402
2017/08/30 13:51:23 step 5: objective=0.123967 reg=0.002401
2017/08/30 13:51:24 step 6: objective=0.124041 reg=0.002399
2017/08/30 13:51:26 step 7: objective=0.124151 reg=0.002400
2017/08/30 13:51:26 Training value function...
2017/08/30 13:51:28 step 0: mse=0.245903 step=0.050000
2017/08/30 13:51:30 step 1: mse=0.246371 step=0.050000
2017/08/30 13:51:31 step 2: mse=0.246895 step=0.050000
2017/08/30 13:51:32 step 3: mse=0.247301 step=0.050000
2017/08/30 13:51:33 step 4: mse=0.247379 step=0.050000
2017/08/30 13:51:34 step 5: mse=0.247744 step=0.050000
2017/08/30 13:51:35 step 6: mse=0.248248 step=0.050000
2017/08/30 13:51:37 step 7: mse=0.248499 step=0.050000
2017/08/30 13:51:37 Saving...
2017/08/30 13:51:37 Gathering batch of experience...
2017/08/30 13:52:14 batch 163: mean=23.363636 stddev=15.665670 entropy=0.236974 frames=7974 count=22
2017/08/30 13:52:14 Training policy...
2017/08/30 13:52:19 tune 0: objective=0.136157 reg=0.002370 prune=0
2017/08/30 13:52:20 step 0: objective=0.136157 reg=0.002370
2017/08/30 13:52:21 step 1: objective=0.136293 reg=0.002370
2017/08/30 13:52:23 step 2: objective=0.136464 reg=0.002370
2017/08/30 13:52:24 step 3: objective=0.136619 reg=0.002369
2017/08/30 13:52:26 step 4: objective=0.136793 reg=0.002369
2017/08/30 13:52:27 step 5: objective=0.136914 reg=0.002369
2017/08/30 13:52:28 step 6: objective=0.136989 reg=0.002369
2017/08/30 13:52:30 step 7: objective=0.137201 reg=0.002368
2017/08/30 13:52:30 Training value function...
2017/08/30 13:52:33 step 0: mse=0.251245 step=0.050000
2017/08/30 13:52:35 step 1: mse=0.250292 step=0.050000
2017/08/30 13:52:36 step 2: mse=0.249375 step=0.050000
2017/08/30 13:52:37 step 3: mse=0.248132 step=0.050000
2017/08/30 13:52:39 step 4: mse=0.247326 step=0.050000
2017/08/30 13:52:40 step 5: mse=0.246643 step=0.050000
2017/08/30 13:52:41 step 6: mse=0.246094 step=0.050000
2017/08/30 13:52:43 step 7: mse=0.245660 step=0.050000
2017/08/30 13:52:43 Saving...
2017/08/30 13:52:43 Gathering batch of experience...
2017/08/30 13:53:20 batch 164: mean=24.450000 stddev=14.104875 entropy=0.238129 frames=7595 count=20
2017/08/30 13:53:20 Training policy...
2017/08/30 13:53:24 tune 0: objective=0.133577 reg=0.002381 prune=0
2017/08/30 13:53:26 step 0: objective=0.133577 reg=0.002381
2017/08/30 13:53:27 step 1: objective=0.133706 reg=0.002381
2017/08/30 13:53:28 step 2: objective=0.133776 reg=0.002381
2017/08/30 13:53:29 step 3: objective=0.133845 reg=0.002381
2017/08/30 13:53:31 step 4: objective=0.133905 reg=0.002380
2017/08/30 13:53:32 step 5: objective=0.133983 reg=0.002380
2017/08/30 13:53:33 step 6: objective=0.134038 reg=0.002379
2017/08/30 13:53:35 step 7: objective=0.134129 reg=0.002378
2017/08/30 13:53:35 Training value function...
2017/08/30 13:53:38 step 0: mse=0.243515 step=0.050000
2017/08/30 13:53:39 step 1: mse=0.242605 step=0.050000
2017/08/30 13:53:41 step 2: mse=0.241890 step=0.050000
2017/08/30 13:53:42 step 3: mse=0.241140 step=0.050000
2017/08/30 13:53:43 step 4: mse=0.240836 step=0.050000
2017/08/30 13:53:45 step 5: mse=0.240465 step=0.050000
2017/08/30 13:53:46 step 6: mse=0.239934 step=0.050000
2017/08/30 13:53:47 step 7: mse=0.239562 step=0.050000
2017/08/30 13:53:47 Saving...
2017/08/30 13:53:47 Gathering batch of experience...
2017/08/30 13:54:23 batch 165: mean=22.650000 stddev=11.883918 entropy=0.248049 frames=7094 count=20
2017/08/30 13:54:23 Training policy...
2017/08/30 13:54:27 tune 0: objective=0.119445 reg=0.002480 prune=0
2017/08/30 13:54:28 step 0: objective=0.119445 reg=0.002480
2017/08/30 13:54:29 step 1: objective=0.119631 reg=0.002481
2017/08/30 13:54:31 step 2: objective=0.119873 reg=0.002482
2017/08/30 13:54:32 step 3: objective=0.119971 reg=0.002482
2017/08/30 13:54:33 step 4: objective=0.120077 reg=0.002483
2017/08/30 13:54:34 step 5: objective=0.120255 reg=0.002481
2017/08/30 13:54:36 step 6: objective=0.120384 reg=0.002482
2017/08/30 13:54:37 step 7: objective=0.120543 reg=0.002481
2017/08/30 13:54:37 Training value function...
2017/08/30 13:54:40 step 0: mse=0.241554 step=0.050000
2017/08/30 13:54:41 step 1: mse=0.241298 step=0.050000
2017/08/30 13:54:42 step 2: mse=0.241364 step=0.050000
2017/08/30 13:54:43 step 3: mse=0.241287 step=0.050000
2017/08/30 13:54:45 step 4: mse=0.241077 step=0.050000
2017/08/30 13:54:46 step 5: mse=0.240582 step=0.050000
2017/08/30 13:54:47 step 6: mse=0.240616 step=0.050000
2017/08/30 13:54:48 step 7: mse=0.240702 step=0.050000
2017/08/30 13:54:48 Saving...
2017/08/30 13:54:48 Gathering batch of experience...
2017/08/30 13:55:24 batch 166: mean=27.588235 stddev=13.560578 entropy=0.236084 frames=7303 count=17
2017/08/30 13:55:24 Training policy...
2017/08/30 13:55:28 tune 0: objective=0.141639 reg=0.002361 prune=0
2017/08/30 13:55:30 step 0: objective=0.141640 reg=0.002361
2017/08/30 13:55:31 step 1: objective=0.141768 reg=0.002363
2017/08/30 13:55:32 step 2: objective=0.141878 reg=0.002362
2017/08/30 13:55:34 step 3: objective=0.141972 reg=0.002362
2017/08/30 13:55:35 step 4: objective=0.142069 reg=0.002361
2017/08/30 13:55:36 step 5: objective=0.142197 reg=0.002361
2017/08/30 13:55:37 step 6: objective=0.142339 reg=0.002360
2017/08/30 13:55:39 step 7: objective=0.142446 reg=0.002360
2017/08/30 13:55:39 Training value function...
2017/08/30 13:55:42 step 0: mse=0.260100 step=0.050000
2017/08/30 13:55:43 step 1: mse=0.258168 step=0.050000
2017/08/30 13:55:44 step 2: mse=0.256465 step=0.050000
2017/08/30 13:55:45 step 3: mse=0.254966 step=0.050000
2017/08/30 13:55:47 step 4: mse=0.253344 step=0.050000
2017/08/30 13:55:48 step 5: mse=0.252175 step=0.050000
2017/08/30 13:55:49 step 6: mse=0.251053 step=0.050000
2017/08/30 13:55:50 step 7: mse=0.249748 step=0.050000
2017/08/30 13:55:50 Saving...
2017/08/30 13:55:50 Gathering batch of experience...
2017/08/30 13:56:26 batch 167: mean=19.739130 stddev=11.982659 entropy=0.244483 frames=7104 count=23
2017/08/30 13:56:26 Training policy...
2017/08/30 13:56:30 tune 0: objective=0.110615 reg=0.002445 prune=0
2017/08/30 13:56:32 step 0: objective=0.110615 reg=0.002445
2017/08/30 13:56:33 step 1: objective=0.110751 reg=0.002446
2017/08/30 13:56:34 step 2: objective=0.110863 reg=0.002445
2017/08/30 13:56:35 step 3: objective=0.111070 reg=0.002447
2017/08/30 13:56:37 step 4: objective=0.111313 reg=0.002447
2017/08/30 13:56:38 step 5: objective=0.111445 reg=0.002447
2017/08/30 13:56:39 step 6: objective=0.111651 reg=0.002446
2017/08/30 13:56:40 step 7: objective=0.111777 reg=0.002446
2017/08/30 13:56:40 Training value function...
2017/08/30 13:56:43 step 0: mse=0.232477 step=0.050000
2017/08/30 13:56:44 step 1: mse=0.233806 step=0.050000
2017/08/30 13:56:46 step 2: mse=0.235094 step=0.050000
2017/08/30 13:56:47 step 3: mse=0.236193 step=0.050000
2017/08/30 13:56:48 step 4: mse=0.237476 step=0.050000
2017/08/30 13:56:49 step 5: mse=0.238568 step=0.050000
2017/08/30 13:56:51 step 6: mse=0.239520 step=0.050000
2017/08/30 13:56:52 step 7: mse=0.240596 step=0.050000
2017/08/30 13:56:52 Saving...
2017/08/30 13:56:52 Gathering batch of experience...
2017/08/30 13:57:29 batch 168: mean=30.625000 stddev=10.693894 entropy=0.232940 frames=7598 count=16
2017/08/30 13:57:29 Training policy...
2017/08/30 13:57:33 tune 0: objective=0.150663 reg=0.002329 prune=0
2017/08/30 13:57:34 step 0: objective=0.150663 reg=0.002329
2017/08/30 13:57:36 step 1: objective=0.150742 reg=0.002329
2017/08/30 13:57:37 step 2: objective=0.150812 reg=0.002330
2017/08/30 13:57:38 step 3: objective=0.150895 reg=0.002329
2017/08/30 13:57:40 step 4: objective=0.150973 reg=0.002328
2017/08/30 13:57:41 step 5: objective=0.151033 reg=0.002327
2017/08/30 13:57:42 step 6: objective=0.151124 reg=0.002327
2017/08/30 13:57:44 step 7: objective=0.151204 reg=0.002328
2017/08/30 13:57:44 Training value function...
2017/08/30 13:57:47 step 0: mse=0.258050 step=0.050000
2017/08/30 13:57:48 step 1: mse=0.255895 step=0.050000
2017/08/30 13:57:49 step 2: mse=0.253127 step=0.050000
2017/08/30 13:57:51 step 3: mse=0.250245 step=0.050000
2017/08/30 13:57:52 step 4: mse=0.248166 step=0.050000
2017/08/30 13:57:53 step 5: mse=0.246456 step=0.050000
2017/08/30 13:57:55 step 6: mse=0.244032 step=0.050000
2017/08/30 13:57:56 step 7: mse=0.242277 step=0.050000
2017/08/30 13:57:56 Saving...
2017/08/30 13:57:56 Gathering batch of experience...
2017/08/30 13:58:34 batch 169: mean=31.937500 stddev=10.585773 entropy=0.237389 frames=7903 count=16
2017/08/30 13:58:34 Training policy...
2017/08/30 13:58:38 tune 0: objective=0.145072 reg=0.002374 prune=0
2017/08/30 13:58:40 step 0: objective=0.145073 reg=0.002374
2017/08/30 13:58:41 step 1: objective=0.145233 reg=0.002375
2017/08/30 13:58:42 step 2: objective=0.145408 reg=0.002377
2017/08/30 13:58:44 step 3: objective=0.145566 reg=0.002378
2017/08/30 13:58:45 step 4: objective=0.145714 reg=0.002381
2017/08/30 13:58:47 step 5: objective=0.145852 reg=0.002382
2017/08/30 13:58:48 step 6: objective=0.145942 reg=0.002383
2017/08/30 13:58:49 step 7: objective=0.146045 reg=0.002384
2017/08/30 13:58:49 Training value function...
2017/08/30 13:58:53 step 0: mse=0.244203 step=0.050000
2017/08/30 13:58:54 step 1: mse=0.241726 step=0.050000
2017/08/30 13:58:55 step 2: mse=0.239798 step=0.050000
2017/08/30 13:58:57 step 3: mse=0.237652 step=0.050000
2017/08/30 13:58:58 step 4: mse=0.235472 step=0.050000
2017/08/30 13:58:59 step 5: mse=0.233776 step=0.050000
2017/08/30 13:59:01 step 6: mse=0.232021 step=0.050000
2017/08/30 13:59:02 step 7: mse=0.230144 step=0.050000
2017/08/30 13:59:02 Saving...
2017/08/30 13:59:02 Gathering batch of experience...
2017/08/30 13:59:42 batch 170: mean=22.000000 stddev=14.455328 entropy=0.243116 frames=7881 count=23
2017/08/30 13:59:42 Training policy...
2017/08/30 13:59:47 tune 0: objective=0.116848 reg=0.002431 prune=0
2017/08/30 13:59:48 step 0: objective=0.116848 reg=0.002431
2017/08/30 13:59:49 step 1: objective=0.116947 reg=0.002431
2017/08/30 13:59:51 step 2: objective=0.117082 reg=0.002431
2017/08/30 13:59:52 step 3: objective=0.117202 reg=0.002429
2017/08/30 13:59:53 step 4: objective=0.117309 reg=0.002429
2017/08/30 13:59:55 step 5: objective=0.117389 reg=0.002430
2017/08/30 13:59:56 step 6: objective=0.117482 reg=0.002431
2017/08/30 13:59:58 step 7: objective=0.117556 reg=0.002431
2017/08/30 13:59:58 Training value function...
2017/08/30 14:00:01 step 0: mse=0.235478 step=0.050000
2017/08/30 14:00:02 step 1: mse=0.235985 step=0.050000
2017/08/30 14:00:04 step 2: mse=0.236447 step=0.050000
2017/08/30 14:00:05 step 3: mse=0.237191 step=0.050000
2017/08/30 14:00:06 step 4: mse=0.237735 step=0.050000
2017/08/30 14:00:08 step 5: mse=0.238278 step=0.050000
2017/08/30 14:00:09 step 6: mse=0.238758 step=0.050000
2017/08/30 14:00:10 step 7: mse=0.239193 step=0.050000
2017/08/30 14:00:10 Saving...
2017/08/30 14:00:10 Gathering batch of experience...
2017/08/30 14:00:47 batch 171: mean=18.125000 stddev=11.702252 entropy=0.241575 frames=6793 count=24
2017/08/30 14:00:47 Training policy...
2017/08/30 14:00:50 tune 0: objective=0.107044 reg=0.002416 prune=0
2017/08/30 14:00:52 step 0: objective=0.107044 reg=0.002416
2017/08/30 14:00:53 step 1: objective=0.107122 reg=0.002414
2017/08/30 14:00:54 step 2: objective=0.107246 reg=0.002412
2017/08/30 14:00:55 step 3: objective=0.107404 reg=0.002411
2017/08/30 14:00:56 step 4: objective=0.107497 reg=0.002409
2017/08/30 14:00:57 step 5: objective=0.107749 reg=0.002407
2017/08/30 14:00:59 step 6: objective=0.107975 reg=0.002406
2017/08/30 14:01:00 step 7: objective=0.108105 reg=0.002405
2017/08/30 14:01:00 Training value function...
2017/08/30 14:01:03 step 0: mse=0.230262 step=0.050000
2017/08/30 14:01:04 step 1: mse=0.231455 step=0.050000
2017/08/30 14:01:05 step 2: mse=0.232402 step=0.050000
2017/08/30 14:01:06 step 3: mse=0.233720 step=0.050000
2017/08/30 14:01:07 step 4: mse=0.234754 step=0.050000
2017/08/30 14:01:08 step 5: mse=0.235650 step=0.050000
2017/08/30 14:01:10 step 6: mse=0.236370 step=0.050000
2017/08/30 14:01:11 step 7: mse=0.237256 step=0.050000
2017/08/30 14:01:11 Saving...
2017/08/30 14:01:11 Gathering batch of experience...
2017/08/30 14:01:50 batch 172: mean=25.736842 stddev=12.797377 entropy=0.235716 frames=7640 count=19
2017/08/30 14:01:50 Training policy...
2017/08/30 14:01:55 tune 0: objective=0.132245 reg=0.002357 prune=0
2017/08/30 14:01:56 step 0: objective=0.132245 reg=0.002357
2017/08/30 14:01:57 step 1: objective=0.132331 reg=0.002358
2017/08/30 14:01:59 step 2: objective=0.132434 reg=0.002358
2017/08/30 14:02:00 step 3: objective=0.132541 reg=0.002358
2017/08/30 14:02:01 step 4: objective=0.132705 reg=0.002359
2017/08/30 14:02:03 step 5: objective=0.132777 reg=0.002359
2017/08/30 14:02:04 step 6: objective=0.132949 reg=0.002360
2017/08/30 14:02:05 step 7: objective=0.133107 reg=0.002361
2017/08/30 14:02:05 Training value function...
2017/08/30 14:02:08 step 0: mse=0.258003 step=0.050000
2017/08/30 14:02:10 step 1: mse=0.256670 step=0.050000
2017/08/30 14:02:11 step 2: mse=0.255800 step=0.050000
2017/08/30 14:02:12 step 3: mse=0.254887 step=0.050000
2017/08/30 14:02:14 step 4: mse=0.254091 step=0.050000
2017/08/30 14:02:15 step 5: mse=0.253191 step=0.050000
2017/08/30 14:02:16 step 6: mse=0.252269 step=0.050000
2017/08/30 14:02:18 step 7: mse=0.251789 step=0.050000
2017/08/30 14:02:18 Saving...
2017/08/30 14:02:18 Gathering batch of experience...
2017/08/30 14:02:52 batch 173: mean=23.333333 stddev=14.506703 entropy=0.243556 frames=6555 count=18
2017/08/30 14:02:52 Training policy...
2017/08/30 14:02:56 tune 0: objective=0.130217 reg=0.002436 prune=0
2017/08/30 14:02:57 step 0: objective=0.130217 reg=0.002436
2017/08/30 14:02:58 step 1: objective=0.130340 reg=0.002435
2017/08/30 14:03:00 step 2: objective=0.130450 reg=0.002434
2017/08/30 14:03:01 step 3: objective=0.130587 reg=0.002433
2017/08/30 14:03:02 step 4: objective=0.130670 reg=0.002433
2017/08/30 14:03:03 step 5: objective=0.130773 reg=0.002432
2017/08/30 14:03:04 step 6: objective=0.130887 reg=0.002433
2017/08/30 14:03:05 step 7: objective=0.130976 reg=0.002433
2017/08/30 14:03:05 Training value function...
2017/08/30 14:03:08 step 0: mse=0.253845 step=0.050000
2017/08/30 14:03:09 step 1: mse=0.253061 step=0.050000
2017/08/30 14:03:10 step 2: mse=0.252494 step=0.050000
2017/08/30 14:03:11 step 3: mse=0.251894 step=0.050000
2017/08/30 14:03:13 step 4: mse=0.251646 step=0.050000
2017/08/30 14:03:14 step 5: mse=0.251504 step=0.050000
2017/08/30 14:03:15 step 6: mse=0.251053 step=0.050000
2017/08/30 14:03:16 step 7: mse=0.250671 step=0.050000
2017/08/30 14:03:16 Saving...
2017/08/30 14:03:16 Gathering batch of experience...
2017/08/30 14:03:52 batch 174: mean=21.380952 stddev=11.569567 entropy=0.241712 frames=7063 count=21
2017/08/30 14:03:52 Training policy...
2017/08/30 14:03:56 tune 0: objective=0.115059 reg=0.002417 prune=0
2017/08/30 14:03:57 step 0: objective=0.115060 reg=0.002417
2017/08/30 14:03:58 step 1: objective=0.115218 reg=0.002416
2017/08/30 14:04:00 step 2: objective=0.115419 reg=0.002416
2017/08/30 14:04:01 step 3: objective=0.115529 reg=0.002415
2017/08/30 14:04:02 step 4: objective=0.115612 reg=0.002415
2017/08/30 14:04:03 step 5: objective=0.115825 reg=0.002415
2017/08/30 14:04:05 step 6: objective=0.116070 reg=0.002416
2017/08/30 14:04:06 step 7: objective=0.116141 reg=0.002416
2017/08/30 14:04:06 Training value function...
2017/08/30 14:04:09 step 0: mse=0.245749 step=0.050000
2017/08/30 14:04:10 step 1: mse=0.246374 step=0.050000
2017/08/30 14:04:11 step 2: mse=0.246880 step=0.050000
2017/08/30 14:04:13 step 3: mse=0.247559 step=0.050000
2017/08/30 14:04:14 step 4: mse=0.248043 step=0.050000
2017/08/30 14:04:15 step 5: mse=0.248658 step=0.050000
2017/08/30 14:04:16 step 6: mse=0.249241 step=0.050000
2017/08/30 14:04:17 step 7: mse=0.249515 step=0.050000
2017/08/30 14:04:17 Saving...
2017/08/30 14:04:17 Gathering batch of experience...
2017/08/30 14:04:54 batch 175: mean=20.318182 stddev=14.334911 entropy=0.243391 frames=6998 count=22
2017/08/30 14:04:54 Training policy...
2017/08/30 14:04:58 tune 0: objective=0.127245 reg=0.002434 prune=0
2017/08/30 14:04:59 step 0: objective=0.127246 reg=0.002434
2017/08/30 14:05:00 step 1: objective=0.127484 reg=0.002434
2017/08/30 14:05:01 step 2: objective=0.127567 reg=0.002434
2017/08/30 14:05:03 step 3: objective=0.127730 reg=0.002435
2017/08/30 14:05:04 step 4: objective=0.127848 reg=0.002436
2017/08/30 14:05:05 step 5: objective=0.128063 reg=0.002436
2017/08/30 14:05:06 step 6: objective=0.128195 reg=0.002435
2017/08/30 14:05:08 step 7: objective=0.128395 reg=0.002435
2017/08/30 14:05:08 Training value function...
2017/08/30 14:05:10 step 0: mse=0.263008 step=0.050000
2017/08/30 14:05:12 step 1: mse=0.262765 step=0.050000
2017/08/30 14:05:13 step 2: mse=0.262330 step=0.050000
2017/08/30 14:05:14 step 3: mse=0.261881 step=0.050000
2017/08/30 14:05:15 step 4: mse=0.261484 step=0.050000
2017/08/30 14:05:17 step 5: mse=0.261276 step=0.050000
2017/08/30 14:05:18 step 6: mse=0.260982 step=0.050000
2017/08/30 14:05:19 step 7: mse=0.260689 step=0.050000
2017/08/30 14:05:19 Saving...
2017/08/30 14:05:19 Gathering batch of experience...
2017/08/30 14:05:59 batch 176: mean=21.458333 stddev=14.156798 entropy=0.240850 frames=8057 count=24
2017/08/30 14:05:59 Training policy...
2017/08/30 14:06:04 tune 0: objective=0.130602 reg=0.002408 prune=0
2017/08/30 14:06:05 step 0: objective=0.130603 reg=0.002408
2017/08/30 14:06:06 step 1: objective=0.130779 reg=0.002407
2017/08/30 14:06:08 step 2: objective=0.130971 reg=0.002406
2017/08/30 14:06:09 step 3: objective=0.131164 reg=0.002405
2017/08/30 14:06:11 step 4: objective=0.131335 reg=0.002404
2017/08/30 14:06:12 step 5: objective=0.131481 reg=0.002402
2017/08/30 14:06:14 step 6: objective=0.131680 reg=0.002402
2017/08/30 14:06:15 step 7: objective=0.131759 reg=0.002401
2017/08/30 14:06:15 Training value function...
2017/08/30 14:06:18 step 0: mse=0.266806 step=0.050000
2017/08/30 14:06:20 step 1: mse=0.266484 step=0.050000
2017/08/30 14:06:21 step 2: mse=0.266094 step=0.050000
2017/08/30 14:06:23 step 3: mse=0.265651 step=0.050000
2017/08/30 14:06:24 step 4: mse=0.265544 step=0.050000
2017/08/30 14:06:25 step 5: mse=0.265139 step=0.050000
2017/08/30 14:06:27 step 6: mse=0.264657 step=0.050000
2017/08/30 14:06:28 step 7: mse=0.264258 step=0.050000
2017/08/30 14:06:28 Saving...
2017/08/30 14:06:28 Gathering batch of experience...
2017/08/30 14:07:08 batch 177: mean=25.800000 stddev=14.200704 entropy=0.237782 frames=8004 count=20
2017/08/30 14:07:08 Training policy...
2017/08/30 14:07:12 tune 0: objective=0.145528 reg=0.002378 prune=0
2017/08/30 14:07:13 step 0: objective=0.145528 reg=0.002378
2017/08/30 14:07:15 step 1: objective=0.145685 reg=0.002376
2017/08/30 14:07:16 step 2: objective=0.145835 reg=0.002376
2017/08/30 14:07:18 step 3: objective=0.145958 reg=0.002375
2017/08/30 14:07:19 step 4: objective=0.146131 reg=0.002375
2017/08/30 14:07:21 step 5: objective=0.146265 reg=0.002376
2017/08/30 14:07:22 step 6: objective=0.146393 reg=0.002376
2017/08/30 14:07:23 step 7: objective=0.146495 reg=0.002375
2017/08/30 14:07:23 Training value function...
2017/08/30 14:07:27 step 0: mse=0.263055 step=0.050000
2017/08/30 14:07:28 step 1: mse=0.261105 step=0.050000
2017/08/30 14:07:29 step 2: mse=0.259732 step=0.050000
2017/08/30 14:07:31 step 3: mse=0.258544 step=0.050000
2017/08/30 14:07:32 step 4: mse=0.257281 step=0.050000
2017/08/30 14:07:34 step 5: mse=0.256272 step=0.050000
2017/08/30 14:07:35 step 6: mse=0.255223 step=0.050000
2017/08/30 14:07:36 step 7: mse=0.254043 step=0.050000
2017/08/30 14:07:36 Saving...
2017/08/30 14:07:36 Gathering batch of experience...
2017/08/30 14:08:14 batch 178: mean=25.550000 stddev=13.492498 entropy=0.239200 frames=7947 count=20
2017/08/30 14:08:14 Training policy...
2017/08/30 14:08:19 tune 0: objective=0.135059 reg=0.002392 prune=0
2017/08/30 14:08:20 step 0: objective=0.135059 reg=0.002392
2017/08/30 14:08:22 step 1: objective=0.135179 reg=0.002393
2017/08/30 14:08:23 step 2: objective=0.135271 reg=0.002392
2017/08/30 14:08:24 step 3: objective=0.135346 reg=0.002393
2017/08/30 14:08:26 step 4: objective=0.135464 reg=0.002394
2017/08/30 14:08:27 step 5: objective=0.135547 reg=0.002395
2017/08/30 14:08:29 step 6: objective=0.135599 reg=0.002394
2017/08/30 14:08:30 step 7: objective=0.135704 reg=0.002392
2017/08/30 14:08:30 Training value function...
2017/08/30 14:08:33 step 0: mse=0.252697 step=0.050000
2017/08/30 14:08:35 step 1: mse=0.251384 step=0.050000
2017/08/30 14:08:36 step 2: mse=0.250480 step=0.050000
2017/08/30 14:08:37 step 3: mse=0.249696 step=0.050000
2017/08/30 14:08:39 step 4: mse=0.249316 step=0.050000
2017/08/30 14:08:40 step 5: mse=0.248671 step=0.050000
2017/08/30 14:08:42 step 6: mse=0.248143 step=0.050000
2017/08/30 14:08:43 step 7: mse=0.247699 step=0.050000
2017/08/30 14:08:43 Saving...
2017/08/30 14:08:43 Gathering batch of experience...
2017/08/30 14:09:15 batch 179: mean=20.052632 stddev=13.831595 entropy=0.235695 frames=5959 count=19
2017/08/30 14:09:15 Training policy...
2017/08/30 14:09:18 tune 0: objective=0.119397 reg=0.002357 prune=0
2017/08/30 14:09:19 step 0: objective=0.119397 reg=0.002357
2017/08/30 14:09:20 step 1: objective=0.119679 reg=0.002359
2017/08/30 14:09:22 step 2: objective=0.119958 reg=0.002361
2017/08/30 14:09:23 step 3: objective=0.120243 reg=0.002362
2017/08/30 14:09:24 step 4: objective=0.120322 reg=0.002362
2017/08/30 14:09:25 step 5: objective=0.120427 reg=0.002363
2017/08/30 14:09:26 step 6: objective=0.120558 reg=0.002363
2017/08/30 14:09:27 step 7: objective=0.120701 reg=0.002363
2017/08/30 14:09:27 Training value function...
2017/08/30 14:09:29 step 0: mse=0.250804 step=0.050000
2017/08/30 14:09:30 step 1: mse=0.250283 step=0.050000
2017/08/30 14:09:31 step 2: mse=0.250610 step=0.050000
2017/08/30 14:09:32 step 3: mse=0.250994 step=0.050000
2017/08/30 14:09:33 step 4: mse=0.251270 step=0.050000
2017/08/30 14:09:34 step 5: mse=0.251897 step=0.050000
2017/08/30 14:09:35 step 6: mse=0.252002 step=0.050000
2017/08/30 14:09:36 step 7: mse=0.252432 step=0.050000
2017/08/30 14:09:36 Saving...
2017/08/30 14:09:36 Gathering batch of experience...
2017/08/30 14:10:13 batch 180: mean=23.142857 stddev=13.980550 entropy=0.233395 frames=7560 count=21
2017/08/30 14:10:13 Training policy...
2017/08/30 14:10:18 tune 0: objective=0.132322 reg=0.002334 prune=0
2017/08/30 14:10:19 step 0: objective=0.132322 reg=0.002334
2017/08/30 14:10:20 step 1: objective=0.132530 reg=0.002333
2017/08/30 14:10:22 step 2: objective=0.132726 reg=0.002333
2017/08/30 14:10:23 step 3: objective=0.132870 reg=0.002334
2017/08/30 14:10:25 step 4: objective=0.133011 reg=0.002333
2017/08/30 14:10:26 step 5: objective=0.133179 reg=0.002332
2017/08/30 14:10:27 step 6: objective=0.133301 reg=0.002333
2017/08/30 14:10:29 step 7: objective=0.133453 reg=0.002331
2017/08/30 14:10:29 Training value function...
2017/08/30 14:10:32 step 0: mse=0.249820 step=0.050000
2017/08/30 14:10:33 step 1: mse=0.249220 step=0.050000
2017/08/30 14:10:34 step 2: mse=0.248791 step=0.050000
2017/08/30 14:10:36 step 3: mse=0.248553 step=0.050000
2017/08/30 14:10:37 step 4: mse=0.248096 step=0.050000
2017/08/30 14:10:38 step 5: mse=0.247710 step=0.050000
2017/08/30 14:10:40 step 6: mse=0.247269 step=0.050000
2017/08/30 14:10:41 step 7: mse=0.246646 step=0.050000
2017/08/30 14:10:41 Saving...
2017/08/30 14:10:41 Gathering batch of experience...
2017/08/30 14:11:23 batch 181: mean=20.074074 stddev=15.419867 entropy=0.237670 frames=8461 count=27
2017/08/30 14:11:23 Training policy...
2017/08/30 14:11:28 tune 0: objective=0.125786 reg=0.002377 prune=0
2017/08/30 14:11:29 step 0: objective=0.125786 reg=0.002377
2017/08/30 14:11:31 step 1: objective=0.125891 reg=0.002377
2017/08/30 14:11:32 step 2: objective=0.125992 reg=0.002378
2017/08/30 14:11:34 step 3: objective=0.126142 reg=0.002378
2017/08/30 14:11:35 step 4: objective=0.126236 reg=0.002379
2017/08/30 14:11:37 step 5: objective=0.126328 reg=0.002379
2017/08/30 14:11:39 step 6: objective=0.126406 reg=0.002379
2017/08/30 14:11:40 step 7: objective=0.126568 reg=0.002379
2017/08/30 14:11:40 Training value function...
2017/08/30 14:11:44 step 0: mse=0.258617 step=0.050000
2017/08/30 14:11:45 step 1: mse=0.258280 step=0.050000
2017/08/30 14:11:47 step 2: mse=0.257889 step=0.050000
2017/08/30 14:11:48 step 3: mse=0.257580 step=0.050000
2017/08/30 14:11:49 step 4: mse=0.257344 step=0.050000
2017/08/30 14:11:51 step 5: mse=0.257372 step=0.050000
2017/08/30 14:11:52 step 6: mse=0.257279 step=0.050000
2017/08/30 14:11:54 step 7: mse=0.257032 step=0.050000
2017/08/30 14:11:54 Saving...
2017/08/30 14:11:54 Gathering batch of experience...
2017/08/30 14:12:27 batch 182: mean=16.875000 stddev=12.504374 entropy=0.237123 frames=6387 count=24
2017/08/30 14:12:27 Training policy...
2017/08/30 14:12:31 tune 0: objective=0.107105 reg=0.002371 prune=0
2017/08/30 14:12:32 step 0: objective=0.107106 reg=0.002371
2017/08/30 14:12:33 step 1: objective=0.107276 reg=0.002370
2017/08/30 14:12:34 step 2: objective=0.107450 reg=0.002370
2017/08/30 14:12:35 step 3: objective=0.107621 reg=0.002369
2017/08/30 14:12:36 step 4: objective=0.107810 reg=0.002370
2017/08/30 14:12:37 step 5: objective=0.107999 reg=0.002369
2017/08/30 14:12:39 step 6: objective=0.108085 reg=0.002369
2017/08/30 14:12:40 step 7: objective=0.108292 reg=0.002368
2017/08/30 14:12:40 Training value function...
2017/08/30 14:12:42 step 0: mse=0.264028 step=0.050000
2017/08/30 14:12:43 step 1: mse=0.265034 step=0.050000
2017/08/30 14:12:45 step 2: mse=0.265980 step=0.050000
2017/08/30 14:12:46 step 3: mse=0.266843 step=0.050000
2017/08/30 14:12:47 step 4: mse=0.267663 step=0.050000
2017/08/30 14:12:48 step 5: mse=0.268345 step=0.050000
2017/08/30 14:12:49 step 6: mse=0.269255 step=0.050000
2017/08/30 14:12:50 step 7: mse=0.270014 step=0.050000
2017/08/30 14:12:50 Saving...
2017/08/30 14:12:50 Gathering batch of experience...
2017/08/30 14:13:34 batch 183: mean=18.310345 stddev=13.157149 entropy=0.232035 frames=8324 count=29
2017/08/30 14:13:34 Training policy...
2017/08/30 14:13:39 tune 0: objective=0.124181 reg=0.002320 prune=0
2017/08/30 14:13:40 step 0: objective=0.124182 reg=0.002320
2017/08/30 14:13:42 step 1: objective=0.124347 reg=0.002320
2017/08/30 14:13:43 step 2: objective=0.124539 reg=0.002321
2017/08/30 14:13:45 step 3: objective=0.124708 reg=0.002321
2017/08/30 14:13:46 step 4: objective=0.124832 reg=0.002320
2017/08/30 14:13:48 step 5: objective=0.124919 reg=0.002320
2017/08/30 14:13:49 step 6: objective=0.124997 reg=0.002319
2017/08/30 14:13:51 step 7: objective=0.125087 reg=0.002319
2017/08/30 14:13:51 Training value function...
2017/08/30 14:13:54 step 0: mse=0.267696 step=0.050000
2017/08/30 14:13:55 step 1: mse=0.268091 step=0.050000
2017/08/30 14:13:57 step 2: mse=0.268355 step=0.050000
2017/08/30 14:13:58 step 3: mse=0.268477 step=0.050000
2017/08/30 14:14:00 step 4: mse=0.268751 step=0.050000
2017/08/30 14:14:01 step 5: mse=0.269198 step=0.050000
2017/08/30 14:14:03 step 6: mse=0.269542 step=0.050000
2017/08/30 14:14:04 step 7: mse=0.269656 step=0.050000
2017/08/30 14:14:04 Saving...
2017/08/30 14:14:04 Gathering batch of experience...
2017/08/30 14:14:46 batch 184: mean=25.523810 stddev=15.089003 entropy=0.229789 frames=8328 count=21
2017/08/30 14:14:46 Training policy...
2017/08/30 14:14:50 tune 0: objective=0.147803 reg=0.002298 prune=0
2017/08/30 14:14:52 step 0: objective=0.147803 reg=0.002298
2017/08/30 14:14:53 step 1: objective=0.148001 reg=0.002297
2017/08/30 14:14:55 step 2: objective=0.148233 reg=0.002296
2017/08/30 14:14:56 step 3: objective=0.148367 reg=0.002296
2017/08/30 14:14:58 step 4: objective=0.148527 reg=0.002295
2017/08/30 14:14:59 step 5: objective=0.148647 reg=0.002295
2017/08/30 14:15:01 step 6: objective=0.148796 reg=0.002294
2017/08/30 14:15:02 step 7: objective=0.148906 reg=0.002293
2017/08/30 14:15:02 Training value function...
2017/08/30 14:15:06 step 0: mse=0.276394 step=0.050000
2017/08/30 14:15:07 step 1: mse=0.273605 step=0.050000
2017/08/30 14:15:09 step 2: mse=0.271074 step=0.050000
2017/08/30 14:15:10 step 3: mse=0.268795 step=0.050000
2017/08/30 14:15:11 step 4: mse=0.266341 step=0.050000
2017/08/30 14:15:13 step 5: mse=0.263845 step=0.050000
2017/08/30 14:15:14 step 6: mse=0.261472 step=0.050000
2017/08/30 14:15:16 step 7: mse=0.259733 step=0.050000
2017/08/30 14:15:16 Saving...
2017/08/30 14:15:16 Gathering batch of experience...
2017/08/30 14:15:53 batch 185: mean=24.263158 stddev=12.656773 entropy=0.227781 frames=7202 count=19
2017/08/30 14:15:53 Training policy...
2017/08/30 14:15:57 tune 0: objective=0.130689 reg=0.002278 prune=0
2017/08/30 14:15:58 step 0: objective=0.130690 reg=0.002278
2017/08/30 14:15:59 step 1: objective=0.130778 reg=0.002277
2017/08/30 14:16:01 step 2: objective=0.130919 reg=0.002275
2017/08/30 14:16:02 step 3: objective=0.131010 reg=0.002274
2017/08/30 14:16:03 step 4: objective=0.131127 reg=0.002273
2017/08/30 14:16:04 step 5: objective=0.131219 reg=0.002272
2017/08/30 14:16:06 step 6: objective=0.131278 reg=0.002271
2017/08/30 14:16:07 step 7: objective=0.131328 reg=0.002270
2017/08/30 14:16:07 Training value function...
2017/08/30 14:16:10 step 0: mse=0.258683 step=0.050000
2017/08/30 14:16:11 step 1: mse=0.258421 step=0.050000
2017/08/30 14:16:12 step 2: mse=0.257844 step=0.050000
2017/08/30 14:16:14 step 3: mse=0.257376 step=0.050000
2017/08/30 14:16:15 step 4: mse=0.257212 step=0.050000
2017/08/30 14:16:16 step 5: mse=0.256927 step=0.050000
2017/08/30 14:16:17 step 6: mse=0.256601 step=0.050000
2017/08/30 14:16:19 step 7: mse=0.256403 step=0.050000
2017/08/30 14:16:19 Saving...
2017/08/30 14:16:19 Gathering batch of experience...
2017/08/30 14:16:53 batch 186: mean=28.285714 stddev=16.232369 entropy=0.219682 frames=6135 count=14
2017/08/30 14:16:53 Training policy...
2017/08/30 14:16:56 tune 0: objective=0.149496 reg=0.002197 prune=0
2017/08/30 14:16:57 step 0: objective=0.149497 reg=0.002197
2017/08/30 14:16:58 step 1: objective=0.149611 reg=0.002195
2017/08/30 14:16:59 step 2: objective=0.149738 reg=0.002195
2017/08/30 14:17:00 step 3: objective=0.149920 reg=0.002194
2017/08/30 14:17:01 step 4: objective=0.150064 reg=0.002192
2017/08/30 14:17:02 step 5: objective=0.150201 reg=0.002191
2017/08/30 14:17:03 step 6: objective=0.150340 reg=0.002191
2017/08/30 14:17:05 step 7: objective=0.150469 reg=0.002189
2017/08/30 14:17:05 Training value function...
2017/08/30 14:17:07 step 0: mse=0.264180 step=0.050000
2017/08/30 14:17:08 step 1: mse=0.260544 step=0.050000
2017/08/30 14:17:09 step 2: mse=0.257252 step=0.050000
2017/08/30 14:17:10 step 3: mse=0.254580 step=0.050000
2017/08/30 14:17:11 step 4: mse=0.251934 step=0.050000
2017/08/30 14:17:12 step 5: mse=0.249460 step=0.050000
2017/08/30 14:17:13 step 6: mse=0.247302 step=0.050000
2017/08/30 14:17:14 step 7: mse=0.244973 step=0.050000
2017/08/30 14:17:14 Saving...
2017/08/30 14:17:14 Gathering batch of experience...
2017/08/30 14:17:55 batch 187: mean=26.100000 stddev=14.456486 entropy=0.227593 frames=8131 count=20
2017/08/30 14:17:55 Training policy...
2017/08/30 14:17:59 tune 0: objective=0.131905 reg=0.002276 prune=0
2017/08/30 14:18:01 step 0: objective=0.131905 reg=0.002276
2017/08/30 14:18:02 step 1: objective=0.132027 reg=0.002276
2017/08/30 14:18:04 step 2: objective=0.132096 reg=0.002275
2017/08/30 14:18:05 step 3: objective=0.132192 reg=0.002276
2017/08/30 14:18:07 step 4: objective=0.132264 reg=0.002275
2017/08/30 14:18:08 step 5: objective=0.132341 reg=0.002275
2017/08/30 14:18:10 step 6: objective=0.132542 reg=0.002274
2017/08/30 14:18:11 step 7: objective=0.132584 reg=0.002274
2017/08/30 14:18:11 Training value function...
2017/08/30 14:18:15 step 0: mse=0.246996 step=0.050000
2017/08/30 14:18:16 step 1: mse=0.246468 step=0.050000
2017/08/30 14:18:17 step 2: mse=0.245996 step=0.050000
2017/08/30 14:18:19 step 3: mse=0.245694 step=0.050000
2017/08/30 14:18:20 step 4: mse=0.245374 step=0.050000
2017/08/30 14:18:22 step 5: mse=0.244703 step=0.050000
2017/08/30 14:18:23 step 6: mse=0.244331 step=0.050000
2017/08/30 14:18:24 step 7: mse=0.243660 step=0.050000
2017/08/30 14:18:24 Saving...
2017/08/30 14:18:24 Gathering batch of experience...
2017/08/30 14:19:00 batch 188: mean=27.625000 stddev=13.128571 entropy=0.228464 frames=6849 count=16
2017/08/30 14:19:00 Training policy...
2017/08/30 14:19:04 tune 0: objective=0.138144 reg=0.002285 prune=0
2017/08/30 14:19:05 step 0: objective=0.138144 reg=0.002285
2017/08/30 14:19:06 step 1: objective=0.138224 reg=0.002284
2017/08/30 14:19:07 step 2: objective=0.138297 reg=0.002284
2017/08/30 14:19:09 step 3: objective=0.138351 reg=0.002283
2017/08/30 14:19:10 step 4: objective=0.138440 reg=0.002282
2017/08/30 14:19:11 step 5: objective=0.138488 reg=0.002282
2017/08/30 14:19:12 step 6: objective=0.138632 reg=0.002283
2017/08/30 14:19:13 step 7: objective=0.138694 reg=0.002283
2017/08/30 14:19:13 Training value function...
2017/08/30 14:19:16 step 0: mse=0.234940 step=0.050000
2017/08/30 14:19:17 step 1: mse=0.234101 step=0.050000
2017/08/30 14:19:19 step 2: mse=0.233313 step=0.050000
2017/08/30 14:19:20 step 3: mse=0.232393 step=0.050000
2017/08/30 14:19:21 step 4: mse=0.231536 step=0.050000
2017/08/30 14:19:22 step 5: mse=0.230512 step=0.050000
2017/08/30 14:19:23 step 6: mse=0.229590 step=0.050000
2017/08/30 14:19:24 step 7: mse=0.228993 step=0.050000
2017/08/30 14:19:24 Saving...
2017/08/30 14:19:24 Gathering batch of experience...
2017/08/30 14:20:03 batch 189: mean=29.882353 stddev=12.755079 entropy=0.228718 frames=7879 count=17
2017/08/30 14:20:03 Training policy...
2017/08/30 14:20:08 tune 0: objective=0.135740 reg=0.002287 prune=0
2017/08/30 14:20:09 step 0: objective=0.135740 reg=0.002287
2017/08/30 14:20:10 step 1: objective=0.135824 reg=0.002287
2017/08/30 14:20:12 step 2: objective=0.135935 reg=0.002287
2017/08/30 14:20:13 step 3: objective=0.136047 reg=0.002286
2017/08/30 14:20:15 step 4: objective=0.136138 reg=0.002286
2017/08/30 14:20:16 step 5: objective=0.136204 reg=0.002286
2017/08/30 14:20:17 step 6: objective=0.136342 reg=0.002287
2017/08/30 14:20:19 step 7: objective=0.136501 reg=0.002285
2017/08/30 14:20:19 Training value function...
2017/08/30 14:20:22 step 0: mse=0.235732 step=0.050000
2017/08/30 14:20:24 step 1: mse=0.234768 step=0.050000
2017/08/30 14:20:25 step 2: mse=0.233794 step=0.050000
2017/08/30 14:20:26 step 3: mse=0.233014 step=0.050000
2017/08/30 14:20:28 step 4: mse=0.232283 step=0.050000
2017/08/30 14:20:29 step 5: mse=0.231091 step=0.050000
2017/08/30 14:20:30 step 6: mse=0.230505 step=0.050000
2017/08/30 14:20:32 step 7: mse=0.229922 step=0.050000
2017/08/30 14:20:32 Saving...
2017/08/30 14:20:32 Gathering batch of experience...
2017/08/30 14:21:13 batch 190: mean=26.400000 stddev=13.373107 entropy=0.231454 frames=8233 count=20
2017/08/30 14:21:13 Training policy...
2017/08/30 14:21:17 tune 0: objective=0.121846 reg=0.002315 prune=0
2017/08/30 14:21:19 step 0: objective=0.121847 reg=0.002315
2017/08/30 14:21:20 step 1: objective=0.121961 reg=0.002316
2017/08/30 14:21:22 step 2: objective=0.122061 reg=0.002315
2017/08/30 14:21:23 step 3: objective=0.122133 reg=0.002316
2017/08/30 14:21:25 step 4: objective=0.122264 reg=0.002316
2017/08/30 14:21:26 step 5: objective=0.122349 reg=0.002318
2017/08/30 14:21:28 step 6: objective=0.122485 reg=0.002317
2017/08/30 14:21:29 step 7: objective=0.122608 reg=0.002317
2017/08/30 14:21:29 Training value function...
2017/08/30 14:21:33 step 0: mse=0.234902 step=0.050000
2017/08/30 14:21:34 step 1: mse=0.234683 step=0.050000
2017/08/30 14:21:35 step 2: mse=0.234654 step=0.050000
2017/08/30 14:21:37 step 3: mse=0.234504 step=0.050000
2017/08/30 14:21:38 step 4: mse=0.234601 step=0.050000
2017/08/30 14:21:40 step 5: mse=0.234591 step=0.050000
2017/08/30 14:21:41 step 6: mse=0.234636 step=0.050000
2017/08/30 14:21:43 step 7: mse=0.234716 step=0.050000
2017/08/30 14:21:43 Saving...
2017/08/30 14:21:43 Gathering batch of experience...
2017/08/30 14:22:19 batch 191: mean=23.300000 stddev=11.836807 entropy=0.228549 frames=7260 count=20
2017/08/30 14:22:19 Training policy...
2017/08/30 14:22:23 tune 0: objective=0.118224 reg=0.002285 prune=0
2017/08/30 14:22:24 step 0: objective=0.118225 reg=0.002285
2017/08/30 14:22:26 step 1: objective=0.118355 reg=0.002286
2017/08/30 14:22:27 step 2: objective=0.118489 reg=0.002286
2017/08/30 14:22:28 step 3: objective=0.118573 reg=0.002286
2017/08/30 14:22:29 step 4: objective=0.118682 reg=0.002284
2017/08/30 14:22:31 step 5: objective=0.118830 reg=0.002284
2017/08/30 14:22:32 step 6: objective=0.118936 reg=0.002284
2017/08/30 14:22:33 step 7: objective=0.119033 reg=0.002283
2017/08/30 14:22:33 Training value function...
2017/08/30 14:22:36 step 0: mse=0.230551 step=0.050000
2017/08/30 14:22:38 step 1: mse=0.230970 step=0.050000
2017/08/30 14:22:39 step 2: mse=0.231751 step=0.050000
2017/08/30 14:22:40 step 3: mse=0.232213 step=0.050000
2017/08/30 14:22:41 step 4: mse=0.232638 step=0.050000
2017/08/30 14:22:42 step 5: mse=0.233161 step=0.050000
2017/08/30 14:22:44 step 6: mse=0.233694 step=0.050000
2017/08/30 14:22:45 step 7: mse=0.234274 step=0.050000
2017/08/30 14:22:45 Saving...
2017/08/30 14:22:45 Gathering batch of experience...
2017/08/30 14:23:25 batch 192: mean=27.050000 stddev=12.346963 entropy=0.229574 frames=8430 count=20
2017/08/30 14:23:25 Training policy...
2017/08/30 14:23:30 tune 0: objective=0.131617 reg=0.002296 prune=0
2017/08/30 14:23:31 step 0: objective=0.131617 reg=0.002296
2017/08/30 14:23:33 step 1: objective=0.131779 reg=0.002295
2017/08/30 14:23:34 step 2: objective=0.131888 reg=0.002294
2017/08/30 14:23:36 step 3: objective=0.131953 reg=0.002294
2017/08/30 14:23:37 step 4: objective=0.132048 reg=0.002292
2017/08/30 14:23:39 step 5: objective=0.132225 reg=0.002292
2017/08/30 14:23:40 step 6: objective=0.132350 reg=0.002292
2017/08/30 14:23:42 step 7: objective=0.132433 reg=0.002291
2017/08/30 14:23:42 Training value function...
2017/08/30 14:23:45 step 0: mse=0.242967 step=0.050000
2017/08/30 14:23:47 step 1: mse=0.242541 step=0.050000
2017/08/30 14:23:48 step 2: mse=0.242097 step=0.050000
2017/08/30 14:23:49 step 3: mse=0.241957 step=0.050000
2017/08/30 14:23:51 step 4: mse=0.241569 step=0.050000
2017/08/30 14:23:52 step 5: mse=0.240988 step=0.050000
2017/08/30 14:23:54 step 6: mse=0.240748 step=0.050000
2017/08/30 14:23:55 step 7: mse=0.240716 step=0.050000
2017/08/30 14:23:55 Saving...
2017/08/30 14:23:55 Gathering batch of experience...
2017/08/30 14:24:33 batch 193: mean=22.727273 stddev=12.154991 entropy=0.227586 frames=7791 count=22
2017/08/30 14:24:33 Training policy...
2017/08/30 14:24:37 tune 0: objective=0.120143 reg=0.002276 prune=0
2017/08/30 14:24:39 step 0: objective=0.120143 reg=0.002276
2017/08/30 14:24:40 step 1: objective=0.120283 reg=0.002276
2017/08/30 14:24:42 step 2: objective=0.120514 reg=0.002275
2017/08/30 14:24:43 step 3: objective=0.120705 reg=0.002276
2017/08/30 14:24:44 step 4: objective=0.120821 reg=0.002275
2017/08/30 14:24:46 step 5: objective=0.120935 reg=0.002275
2017/08/30 14:24:47 step 6: objective=0.121049 reg=0.002275
2017/08/30 14:24:49 step 7: objective=0.121125 reg=0.002275
2017/08/30 14:24:49 Training value function...
2017/08/30 14:24:52 step 0: mse=0.242831 step=0.050000
2017/08/30 14:24:53 step 1: mse=0.243166 step=0.050000
2017/08/30 14:24:55 step 2: mse=0.243775 step=0.050000
2017/08/30 14:24:56 step 3: mse=0.244245 step=0.050000
2017/08/30 14:24:57 step 4: mse=0.244555 step=0.050000
2017/08/30 14:24:59 step 5: mse=0.245008 step=0.050000
2017/08/30 14:25:00 step 6: mse=0.245297 step=0.050000
2017/08/30 14:25:01 step 7: mse=0.245634 step=0.050000
2017/08/30 14:25:01 Saving...
2017/08/30 14:25:02 Gathering batch of experience...
2017/08/30 14:25:38 batch 194: mean=21.954545 stddev=14.940723 entropy=0.228126 frames=7544 count=22
2017/08/30 14:25:38 Training policy...
2017/08/30 14:25:43 tune 0: objective=0.124558 reg=0.002281 prune=0
2017/08/30 14:25:44 step 0: objective=0.124559 reg=0.002281
2017/08/30 14:25:45 step 1: objective=0.124745 reg=0.002281
2017/08/30 14:25:47 step 2: objective=0.125046 reg=0.002282
2017/08/30 14:25:48 step 3: objective=0.125168 reg=0.002281
2017/08/30 14:25:49 step 4: objective=0.125268 reg=0.002281
2017/08/30 14:25:51 step 5: objective=0.125391 reg=0.002280
2017/08/30 14:25:52 step 6: objective=0.125462 reg=0.002278
2017/08/30 14:25:54 step 7: objective=0.125654 reg=0.002277
2017/08/30 14:25:54 Training value function...
2017/08/30 14:25:57 step 0: mse=0.256975 step=0.050000
2017/08/30 14:25:58 step 1: mse=0.256606 step=0.050000
2017/08/30 14:25:59 step 2: mse=0.256091 step=0.050000
2017/08/30 14:26:01 step 3: mse=0.255581 step=0.050000
2017/08/30 14:26:02 step 4: mse=0.255253 step=0.050000
2017/08/30 14:26:03 step 5: mse=0.254892 step=0.050000
2017/08/30 14:26:05 step 6: mse=0.254799 step=0.050000
2017/08/30 14:26:06 step 7: mse=0.254789 step=0.050000
2017/08/30 14:26:06 Saving...
2017/08/30 14:26:06 Gathering batch of experience...
2017/08/30 14:26:41 batch 195: mean=28.125000 stddev=12.687962 entropy=0.222760 frames=6979 count=16
2017/08/30 14:26:41 Training policy...
2017/08/30 14:26:45 tune 0: objective=0.144179 reg=0.002228 prune=0
2017/08/30 14:26:47 step 0: objective=0.144179 reg=0.002228
2017/08/30 14:26:48 step 1: objective=0.144248 reg=0.002227
2017/08/30 14:26:49 step 2: objective=0.144396 reg=0.002228
2017/08/30 14:26:50 step 3: objective=0.144454 reg=0.002228
2017/08/30 14:26:52 step 4: objective=0.144584 reg=0.002228
2017/08/30 14:26:53 step 5: objective=0.144664 reg=0.002228
2017/08/30 14:26:54 step 6: objective=0.144727 reg=0.002228
2017/08/30 14:26:55 step 7: objective=0.144811 reg=0.002228
2017/08/30 14:26:55 Training value function...
2017/08/30 14:26:58 step 0: mse=0.254092 step=0.050000
2017/08/30 14:26:59 step 1: mse=0.252255 step=0.050000
2017/08/30 14:27:01 step 2: mse=0.250139 step=0.050000
2017/08/30 14:27:02 step 3: mse=0.248613 step=0.050000
2017/08/30 14:27:03 step 4: mse=0.246862 step=0.050000
2017/08/30 14:27:04 step 5: mse=0.245162 step=0.050000
2017/08/30 14:27:05 step 6: mse=0.243424 step=0.050000
2017/08/30 14:27:07 step 7: mse=0.241855 step=0.050000
2017/08/30 14:27:07 Saving...
2017/08/30 14:27:07 Gathering batch of experience...
2017/08/30 14:27:45 batch 196: mean=22.227273 stddev=13.443254 entropy=0.228300 frames=7666 count=22
2017/08/30 14:27:45 Training policy...
2017/08/30 14:27:49 tune 0: objective=0.116317 reg=0.002283 prune=0
2017/08/30 14:27:51 step 0: objective=0.116317 reg=0.002283
2017/08/30 14:27:52 step 1: objective=0.116406 reg=0.002283
2017/08/30 14:27:53 step 2: objective=0.116598 reg=0.002281
2017/08/30 14:27:55 step 3: objective=0.116743 reg=0.002280
2017/08/30 14:27:56 step 4: objective=0.116873 reg=0.002280
2017/08/30 14:27:58 step 5: objective=0.117009 reg=0.002277
2017/08/30 14:27:59 step 6: objective=0.117112 reg=0.002277
2017/08/30 14:28:00 step 7: objective=0.117192 reg=0.002277
2017/08/30 14:28:00 Training value function...
2017/08/30 14:28:03 step 0: mse=0.247918 step=0.050000
2017/08/30 14:28:05 step 1: mse=0.248684 step=0.050000
2017/08/30 14:28:06 step 2: mse=0.249133 step=0.050000
2017/08/30 14:28:07 step 3: mse=0.249760 step=0.050000
2017/08/30 14:28:09 step 4: mse=0.250396 step=0.050000
2017/08/30 14:28:10 step 5: mse=0.251377 step=0.050000
2017/08/30 14:28:11 step 6: mse=0.252075 step=0.050000
2017/08/30 14:28:13 step 7: mse=0.252845 step=0.050000
2017/08/30 14:28:13 Saving...
2017/08/30 14:28:13 Gathering batch of experience...
2017/08/30 14:28:53 batch 197: mean=21.500000 stddev=13.865425 entropy=0.228151 frames=8053 count=24
2017/08/30 14:28:53 Training policy...
2017/08/30 14:28:58 tune 0: objective=0.124239 reg=0.002282 prune=0
2017/08/30 14:28:59 step 0: objective=0.124239 reg=0.002282
2017/08/30 14:29:01 step 1: objective=0.124330 reg=0.002281
2017/08/30 14:29:02 step 2: objective=0.124429 reg=0.002280
2017/08/30 14:29:03 step 3: objective=0.124538 reg=0.002279
2017/08/30 14:29:05 step 4: objective=0.124686 reg=0.002277
2017/08/30 14:29:06 step 5: objective=0.124831 reg=0.002276
2017/08/30 14:29:08 step 6: objective=0.124917 reg=0.002275
2017/08/30 14:29:09 step 7: objective=0.125026 reg=0.002275
2017/08/30 14:29:09 Training value function...
2017/08/30 14:29:12 step 0: mse=0.250225 step=0.050000
2017/08/30 14:29:14 step 1: mse=0.250219 step=0.050000
2017/08/30 14:29:15 step 2: mse=0.250519 step=0.050000
2017/08/30 14:29:17 step 3: mse=0.250296 step=0.050000
2017/08/30 14:29:18 step 4: mse=0.250473 step=0.050000
2017/08/30 14:29:19 step 5: mse=0.250211 step=0.050000
2017/08/30 14:29:21 step 6: mse=0.250402 step=0.050000
2017/08/30 14:29:22 step 7: mse=0.250337 step=0.050000
2017/08/30 14:29:22 Saving...
2017/08/30 14:29:22 Gathering batch of experience...
2017/08/30 14:29:58 batch 198: mean=20.454545 stddev=15.119906 entropy=0.226601 frames=7053 count=22
2017/08/30 14:29:58 Training policy...
2017/08/30 14:30:03 tune 0: objective=0.122374 reg=0.002266 prune=0
2017/08/30 14:30:04 step 0: objective=0.122375 reg=0.002266
2017/08/30 14:30:05 step 1: objective=0.122465 reg=0.002266
2017/08/30 14:30:06 step 2: objective=0.122650 reg=0.002265
2017/08/30 14:30:08 step 3: objective=0.122730 reg=0.002264
2017/08/30 14:30:09 step 4: objective=0.122832 reg=0.002265
2017/08/30 14:30:10 step 5: objective=0.122926 reg=0.002262
2017/08/30 14:30:11 step 6: objective=0.122989 reg=0.002262
2017/08/30 14:30:13 step 7: objective=0.123104 reg=0.002262
2017/08/30 14:30:13 Training value function...
2017/08/30 14:30:16 step 0: mse=0.264087 step=0.050000
2017/08/30 14:30:17 step 1: mse=0.264123 step=0.050000
2017/08/30 14:30:18 step 2: mse=0.263919 step=0.050000
2017/08/30 14:30:19 step 3: mse=0.263956 step=0.050000
2017/08/30 14:30:21 step 4: mse=0.263662 step=0.050000
2017/08/30 14:30:22 step 5: mse=0.263533 step=0.050000
2017/08/30 14:30:23 step 6: mse=0.263437 step=0.050000
2017/08/30 14:30:24 step 7: mse=0.263443 step=0.050000
2017/08/30 14:30:24 Saving...
2017/08/30 14:30:24 Gathering batch of experience...
2017/08/30 14:31:01 batch 199: mean=24.500000 stddev=12.427791 entropy=0.227603 frames=7655 count=20
2017/08/30 14:31:01 Training policy...
2017/08/30 14:31:06 tune 0: objective=0.133417 reg=0.002276 prune=0
2017/08/30 14:31:07 step 0: objective=0.133418 reg=0.002276
2017/08/30 14:31:08 step 1: objective=0.133505 reg=0.002275
2017/08/30 14:31:10 step 2: objective=0.133574 reg=0.002275
2017/08/30 14:31:11 step 3: objective=0.133713 reg=0.002275
2017/08/30 14:31:13 step 4: objective=0.133809 reg=0.002275
2017/08/30 14:31:14 step 5: objective=0.133904 reg=0.002275
2017/08/30 14:31:15 step 6: objective=0.134011 reg=0.002275
2017/08/30 14:31:17 step 7: objective=0.134152 reg=0.002276
2017/08/30 14:31:17 Training value function...
2017/08/30 14:31:20 step 0: mse=0.264104 step=0.050000
2017/08/30 14:31:21 step 1: mse=0.263381 step=0.050000
2017/08/30 14:31:22 step 2: mse=0.262661 step=0.050000
2017/08/30 14:31:24 step 3: mse=0.262439 step=0.050000
2017/08/30 14:31:25 step 4: mse=0.261724 step=0.050000
2017/08/30 14:31:26 step 5: mse=0.261015 step=0.050000
2017/08/30 14:31:28 step 6: mse=0.260616 step=0.050000
2017/08/30 14:31:29 step 7: mse=0.260237 step=0.050000
2017/08/30 14:31:29 Saving...
2017/08/30 14:31:29 Gathering batch of experience...
2017/08/30 14:32:10 batch 200: mean=23.952381 stddev=13.646825 entropy=0.222528 frames=7838 count=21
2017/08/30 14:32:10 Training policy...
2017/08/30 14:32:14 tune 0: objective=0.132489 reg=0.002225 prune=0
2017/08/30 14:32:16 step 0: objective=0.132490 reg=0.002225
2017/08/30 14:32:17 step 1: objective=0.132618 reg=0.002225
2017/08/30 14:32:18 step 2: objective=0.132737 reg=0.002224
2017/08/30 14:32:20 step 3: objective=0.132807 reg=0.002224
2017/08/30 14:32:21 step 4: objective=0.132903 reg=0.002221
2017/08/30 14:32:23 step 5: objective=0.132980 reg=0.002220
2017/08/30 14:32:24 step 6: objective=0.133048 reg=0.002220
2017/08/30 14:32:25 step 7: objective=0.133108 reg=0.002219
2017/08/30 14:32:25 Training value function...
2017/08/30 14:32:29 step 0: mse=0.257427 step=0.050000
2017/08/30 14:32:30 step 1: mse=0.257077 step=0.050000
2017/08/30 14:32:31 step 2: mse=0.256744 step=0.050000
2017/08/30 14:32:33 step 3: mse=0.256406 step=0.050000
2017/08/30 14:32:34 step 4: mse=0.256136 step=0.050000
2017/08/30 14:32:36 step 5: mse=0.255600 step=0.050000
2017/08/30 14:32:37 step 6: mse=0.255580 step=0.050000
2017/08/30 14:32:38 step 7: mse=0.255151 step=0.050000
2017/08/30 14:32:38 Saving...
2017/08/30 14:32:38 Gathering batch of experience...
2017/08/30 14:33:17 batch 201: mean=26.736842 stddev=10.507351 entropy=0.222667 frames=7902 count=19
2017/08/30 14:33:17 Training policy...
2017/08/30 14:33:22 tune 0: objective=0.136722 reg=0.002227 prune=0
2017/08/30 14:33:23 step 0: objective=0.136722 reg=0.002227
2017/08/30 14:33:24 step 1: objective=0.136892 reg=0.002227
2017/08/30 14:33:26 step 2: objective=0.137076 reg=0.002226
2017/08/30 14:33:27 step 3: objective=0.137260 reg=0.002225
2017/08/30 14:33:29 step 4: objective=0.137394 reg=0.002225
2017/08/30 14:33:30 step 5: objective=0.137470 reg=0.002226
2017/08/30 14:33:31 step 6: objective=0.137598 reg=0.002227
2017/08/30 14:33:33 step 7: objective=0.137661 reg=0.002227
2017/08/30 14:33:33 Training value function...
2017/08/30 14:33:36 step 0: mse=0.249826 step=0.050000
2017/08/30 14:33:38 step 1: mse=0.248337 step=0.050000
2017/08/30 14:33:39 step 2: mse=0.247320 step=0.050000
2017/08/30 14:33:40 step 3: mse=0.246087 step=0.050000
2017/08/30 14:33:42 step 4: mse=0.244857 step=0.050000
2017/08/30 14:33:43 step 5: mse=0.243616 step=0.050000
2017/08/30 14:33:44 step 6: mse=0.242809 step=0.050000
2017/08/30 14:33:46 step 7: mse=0.242028 step=0.050000
2017/08/30 14:33:46 Saving...
2017/08/30 14:33:46 Gathering batch of experience...
2017/08/30 14:34:21 batch 202: mean=23.789474 stddev=12.931312 entropy=0.232142 frames=7035 count=19
2017/08/30 14:34:21 Training policy...
2017/08/30 14:34:25 tune 0: objective=0.127722 reg=0.002321 prune=0
2017/08/30 14:34:26 step 0: objective=0.127723 reg=0.002321
2017/08/30 14:34:28 step 1: objective=0.127818 reg=0.002321
2017/08/30 14:34:29 step 2: objective=0.127968 reg=0.002321
2017/08/30 14:34:30 step 3: objective=0.128087 reg=0.002321
2017/08/30 14:34:31 step 4: objective=0.128214 reg=0.002322
2017/08/30 14:34:33 step 5: objective=0.128360 reg=0.002322
2017/08/30 14:34:34 step 6: objective=0.128480 reg=0.002322
2017/08/30 14:34:35 step 7: objective=0.128640 reg=0.002323
2017/08/30 14:34:35 Training value function...
2017/08/30 14:34:38 step 0: mse=0.248300 step=0.050000
2017/08/30 14:34:39 step 1: mse=0.248058 step=0.050000
2017/08/30 14:34:41 step 2: mse=0.247874 step=0.050000
2017/08/30 14:34:42 step 3: mse=0.247855 step=0.050000
2017/08/30 14:34:43 step 4: mse=0.247525 step=0.050000
2017/08/30 14:34:44 step 5: mse=0.247192 step=0.050000
2017/08/30 14:34:45 step 6: mse=0.246744 step=0.050000
2017/08/30 14:34:47 step 7: mse=0.246826 step=0.050000
2017/08/30 14:34:47 Saving...
2017/08/30 14:34:47 Gathering batch of experience...
2017/08/30 14:35:24 batch 203: mean=31.562500 stddev=8.551087 entropy=0.224747 frames=7842 count=16
2017/08/30 14:35:24 Training policy...
2017/08/30 14:35:28 tune 0: objective=0.142851 reg=0.002247 prune=0
2017/08/30 14:35:30 step 0: objective=0.142851 reg=0.002247
2017/08/30 14:35:31 step 1: objective=0.142905 reg=0.002248
2017/08/30 14:35:33 step 2: objective=0.142959 reg=0.002248
2017/08/30 14:35:34 step 3: objective=0.143017 reg=0.002248
2017/08/30 14:35:36 step 4: objective=0.143063 reg=0.002248
2017/08/30 14:35:37 step 5: objective=0.143121 reg=0.002249
2017/08/30 14:35:38 step 6: objective=0.143178 reg=0.002248
2017/08/30 14:35:40 step 7: objective=0.143312 reg=0.002248
2017/08/30 14:35:40 Training value function...
2017/08/30 14:35:43 step 0: mse=0.247025 step=0.050000
2017/08/30 14:35:44 step 1: mse=0.245412 step=0.050000
2017/08/30 14:35:46 step 2: mse=0.243881 step=0.050000
2017/08/30 14:35:47 step 3: mse=0.242497 step=0.050000
2017/08/30 14:35:48 step 4: mse=0.241148 step=0.050000
2017/08/30 14:35:50 step 5: mse=0.239689 step=0.050000
2017/08/30 14:35:51 step 6: mse=0.238223 step=0.050000
2017/08/30 14:35:52 step 7: mse=0.236872 step=0.050000
2017/08/30 14:35:52 Saving...
2017/08/30 14:35:52 Gathering batch of experience...
2017/08/30 14:36:28 batch 204: mean=21.950000 stddev=14.746101 entropy=0.227822 frames=6856 count=20
2017/08/30 14:36:28 Training policy...
2017/08/30 14:36:32 tune 0: objective=0.119370 reg=0.002278 prune=0
2017/08/30 14:36:33 step 0: objective=0.119371 reg=0.002278
2017/08/30 14:36:34 step 1: objective=0.119609 reg=0.002277
2017/08/30 14:36:35 step 2: objective=0.119776 reg=0.002276
2017/08/30 14:36:37 step 3: objective=0.120011 reg=0.002277
2017/08/30 14:36:38 step 4: objective=0.120130 reg=0.002276
2017/08/30 14:36:39 step 5: objective=0.120256 reg=0.002275
2017/08/30 14:36:40 step 6: objective=0.120395 reg=0.002275
2017/08/30 14:36:41 step 7: objective=0.120481 reg=0.002275
2017/08/30 14:36:41 Training value function...
2017/08/30 14:36:44 step 0: mse=0.242402 step=0.050000
2017/08/30 14:36:45 step 1: mse=0.242454 step=0.050000
2017/08/30 14:36:47 step 2: mse=0.242623 step=0.050000
2017/08/30 14:36:48 step 3: mse=0.242679 step=0.050000
2017/08/30 14:36:49 step 4: mse=0.242660 step=0.050000
2017/08/30 14:36:50 step 5: mse=0.242912 step=0.050000
2017/08/30 14:36:51 step 6: mse=0.243150 step=0.050000
2017/08/30 14:36:53 step 7: mse=0.243170 step=0.050000
2017/08/30 14:36:53 Saving...
2017/08/30 14:36:53 Gathering batch of experience...
2017/08/30 14:37:31 batch 205: mean=20.956522 stddev=13.284441 entropy=0.221335 frames=7555 count=23
2017/08/30 14:37:31 Training policy...
2017/08/30 14:37:36 tune 0: objective=0.115712 reg=0.002213 prune=0
2017/08/30 14:37:37 step 0: objective=0.115713 reg=0.002213
2017/08/30 14:37:38 step 1: objective=0.115853 reg=0.002212
2017/08/30 14:37:40 step 2: objective=0.115959 reg=0.002211
2017/08/30 14:37:41 step 3: objective=0.116088 reg=0.002208
2017/08/30 14:37:43 step 4: objective=0.116194 reg=0.002206
2017/08/30 14:37:44 step 5: objective=0.116303 reg=0.002205
2017/08/30 14:37:45 step 6: objective=0.116467 reg=0.002204
2017/08/30 14:37:47 step 7: objective=0.116587 reg=0.002204
2017/08/30 14:37:47 Training value function...
2017/08/30 14:37:50 step 0: mse=0.246228 step=0.050000
2017/08/30 14:37:51 step 1: mse=0.246835 step=0.050000
2017/08/30 14:37:52 step 2: mse=0.247432 step=0.050000
2017/08/30 14:37:54 step 3: mse=0.247722 step=0.050000
2017/08/30 14:37:55 step 4: mse=0.248362 step=0.050000
2017/08/30 14:37:56 step 5: mse=0.248911 step=0.050000
2017/08/30 14:37:58 step 6: mse=0.249440 step=0.050000
2017/08/30 14:37:59 step 7: mse=0.250023 step=0.050000
2017/08/30 14:37:59 Saving...
2017/08/30 14:37:59 Gathering batch of experience...
2017/08/30 14:38:36 batch 206: mean=25.500000 stddev=14.064336 entropy=0.221798 frames=7127 count=18
2017/08/30 14:38:36 Training policy...
2017/08/30 14:38:40 tune 0: objective=0.138876 reg=0.002218 prune=0
2017/08/30 14:38:42 step 0: objective=0.138877 reg=0.002218
2017/08/30 14:38:43 step 1: objective=0.138962 reg=0.002218
2017/08/30 14:38:44 step 2: objective=0.139052 reg=0.002218
2017/08/30 14:38:45 step 3: objective=0.139169 reg=0.002216
2017/08/30 14:38:47 step 4: objective=0.139306 reg=0.002216
2017/08/30 14:38:48 step 5: objective=0.139381 reg=0.002216
2017/08/30 14:38:49 step 6: objective=0.139461 reg=0.002215
2017/08/30 14:38:51 step 7: objective=0.139637 reg=0.002214
2017/08/30 14:38:51 Training value function...
2017/08/30 14:38:53 step 0: mse=0.251067 step=0.050000
2017/08/30 14:38:55 step 1: mse=0.249262 step=0.050000
2017/08/30 14:38:56 step 2: mse=0.248019 step=0.050000
2017/08/30 14:38:57 step 3: mse=0.246424 step=0.050000
2017/08/30 14:38:58 step 4: mse=0.245205 step=0.050000
2017/08/30 14:39:00 step 5: mse=0.243953 step=0.050000
2017/08/30 14:39:01 step 6: mse=0.242904 step=0.050000
2017/08/30 14:39:02 step 7: mse=0.242051 step=0.050000
2017/08/30 14:39:02 Saving...
2017/08/30 14:39:02 Gathering batch of experience...
2017/08/30 14:39:40 batch 207: mean=30.235294 stddev=12.553553 entropy=0.223668 frames=7938 count=17
2017/08/30 14:39:40 Training policy...
2017/08/30 14:39:45 tune 0: objective=0.149733 reg=0.002237 prune=0
2017/08/30 14:39:46 step 0: objective=0.149733 reg=0.002237
2017/08/30 14:39:47 step 1: objective=0.149836 reg=0.002237
2017/08/30 14:39:49 step 2: objective=0.149949 reg=0.002237
2017/08/30 14:39:50 step 3: objective=0.150003 reg=0.002236
2017/08/30 14:39:52 step 4: objective=0.150054 reg=0.002236
2017/08/30 14:39:53 step 5: objective=0.150198 reg=0.002235
2017/08/30 14:39:54 step 6: objective=0.150239 reg=0.002234
2017/08/30 14:39:56 step 7: objective=0.150318 reg=0.002233
2017/08/30 14:39:56 Training value function...
2017/08/30 14:39:59 step 0: mse=0.247654 step=0.050000
2017/08/30 14:40:01 step 1: mse=0.244504 step=0.050000
2017/08/30 14:40:02 step 2: mse=0.242216 step=0.050000
2017/08/30 14:40:03 step 3: mse=0.239727 step=0.050000
2017/08/30 14:40:05 step 4: mse=0.237271 step=0.050000
2017/08/30 14:40:06 step 5: mse=0.235167 step=0.050000
2017/08/30 14:40:07 step 6: mse=0.233474 step=0.050000
2017/08/30 14:40:09 step 7: mse=0.232146 step=0.050000
2017/08/30 14:40:09 Saving...
2017/08/30 14:40:09 Gathering batch of experience...
2017/08/30 14:40:47 batch 208: mean=25.947368 stddev=13.012034 entropy=0.223365 frames=7655 count=19
2017/08/30 14:40:47 Training policy...
2017/08/30 14:40:52 tune 0: objective=0.128101 reg=0.002234 prune=0
2017/08/30 14:40:53 step 0: objective=0.128101 reg=0.002234
2017/08/30 14:40:55 step 1: objective=0.128185 reg=0.002235
2017/08/30 14:40:56 step 2: objective=0.128276 reg=0.002236
2017/08/30 14:40:57 step 3: objective=0.128429 reg=0.002236
2017/08/30 14:40:59 step 4: objective=0.128540 reg=0.002236
2017/08/30 14:41:00 step 5: objective=0.128606 reg=0.002237
2017/08/30 14:41:01 step 6: objective=0.128687 reg=0.002237
2017/08/30 14:41:03 step 7: objective=0.128733 reg=0.002237
2017/08/30 14:41:03 Training value function...
2017/08/30 14:41:06 step 0: mse=0.232424 step=0.050000
2017/08/30 14:41:07 step 1: mse=0.232474 step=0.050000
2017/08/30 14:41:09 step 2: mse=0.232545 step=0.050000
2017/08/30 14:41:10 step 3: mse=0.232523 step=0.050000
2017/08/30 14:41:11 step 4: mse=0.232635 step=0.050000
2017/08/30 14:41:13 step 5: mse=0.232844 step=0.050000
2017/08/30 14:41:14 step 6: mse=0.232877 step=0.050000
2017/08/30 14:41:15 step 7: mse=0.233028 step=0.050000
2017/08/30 14:41:15 Saving...
2017/08/30 14:41:15 Gathering batch of experience...
2017/08/30 14:41:51 batch 209: mean=22.400000 stddev=13.807244 entropy=0.223846 frames=6973 count=20
2017/08/30 14:41:51 Training policy...
2017/08/30 14:41:55 tune 0: objective=0.119745 reg=0.002238 prune=0
2017/08/30 14:41:56 step 0: objective=0.119746 reg=0.002238
2017/08/30 14:41:57 step 1: objective=0.119866 reg=0.002239
2017/08/30 14:41:58 step 2: objective=0.119963 reg=0.002239
2017/08/30 14:42:00 step 3: objective=0.120108 reg=0.002239
2017/08/30 14:42:01 step 4: objective=0.120205 reg=0.002239
2017/08/30 14:42:02 step 5: objective=0.120328 reg=0.002239
2017/08/30 14:42:03 step 6: objective=0.120476 reg=0.002239
2017/08/30 14:42:05 step 7: objective=0.120573 reg=0.002238
2017/08/30 14:42:05 Training value function...
2017/08/30 14:42:08 step 0: mse=0.231483 step=0.050000
2017/08/30 14:42:09 step 1: mse=0.232140 step=0.050000
2017/08/30 14:42:10 step 2: mse=0.232767 step=0.050000
2017/08/30 14:42:11 step 3: mse=0.233120 step=0.050000
2017/08/30 14:42:12 step 4: mse=0.233596 step=0.050000
2017/08/30 14:42:14 step 5: mse=0.234105 step=0.050000
2017/08/30 14:42:15 step 6: mse=0.234626 step=0.050000
2017/08/30 14:42:16 step 7: mse=0.235316 step=0.050000
2017/08/30 14:42:16 Saving...
2017/08/30 14:42:16 Gathering batch of experience...
2017/08/30 14:42:54 batch 210: mean=28.444444 stddev=12.893677 entropy=0.221535 frames=7926 count=18
2017/08/30 14:42:54 Training policy...
2017/08/30 14:42:59 tune 0: objective=0.141529 reg=0.002215 prune=0
2017/08/30 14:43:00 step 0: objective=0.141530 reg=0.002215
2017/08/30 14:43:01 step 1: objective=0.141632 reg=0.002217
2017/08/30 14:43:03 step 2: objective=0.141729 reg=0.002218
2017/08/30 14:43:04 step 3: objective=0.141840 reg=0.002218
2017/08/30 14:43:06 step 4: objective=0.141927 reg=0.002219
2017/08/30 14:43:07 step 5: objective=0.141991 reg=0.002219
2017/08/30 14:43:09 step 6: objective=0.142116 reg=0.002219
2017/08/30 14:43:10 step 7: objective=0.142224 reg=0.002220
2017/08/30 14:43:10 Training value function...
2017/08/30 14:43:13 step 0: mse=0.249915 step=0.050000
2017/08/30 14:43:15 step 1: mse=0.248372 step=0.050000
2017/08/30 14:43:16 step 2: mse=0.246875 step=0.050000
2017/08/30 14:43:17 step 3: mse=0.245550 step=0.050000
2017/08/30 14:43:19 step 4: mse=0.244276 step=0.050000
2017/08/30 14:43:20 step 5: mse=0.243013 step=0.050000
2017/08/30 14:43:21 step 6: mse=0.241341 step=0.050000
2017/08/30 14:43:23 step 7: mse=0.240307 step=0.050000
2017/08/30 14:43:23 Saving...
2017/08/30 14:43:23 Gathering batch of experience...
2017/08/30 14:43:59 batch 211: mean=25.444444 stddev=11.610447 entropy=0.220021 frames=7136 count=18
2017/08/30 14:43:59 Training policy...
2017/08/30 14:44:03 tune 0: objective=0.123068 reg=0.002200 prune=0
2017/08/30 14:44:05 step 0: objective=0.123068 reg=0.002200
2017/08/30 14:44:06 step 1: objective=0.123200 reg=0.002201
2017/08/30 14:44:07 step 2: objective=0.123316 reg=0.002202
2017/08/30 14:44:08 step 3: objective=0.123418 reg=0.002202
2017/08/30 14:44:10 step 4: objective=0.123491 reg=0.002202
2017/08/30 14:44:11 step 5: objective=0.123578 reg=0.002202
2017/08/30 14:44:12 step 6: objective=0.123633 reg=0.002203
2017/08/30 14:44:14 step 7: objective=0.123682 reg=0.002202
2017/08/30 14:44:14 Training value function...
2017/08/30 14:44:17 step 0: mse=0.236785 step=0.050000
2017/08/30 14:44:18 step 1: mse=0.237005 step=0.050000
2017/08/30 14:44:19 step 2: mse=0.237199 step=0.050000
2017/08/30 14:44:20 step 3: mse=0.237367 step=0.050000
2017/08/30 14:44:21 step 4: mse=0.237566 step=0.050000
2017/08/30 14:44:23 step 5: mse=0.237751 step=0.050000
2017/08/30 14:44:24 step 6: mse=0.238132 step=0.050000
2017/08/30 14:44:25 step 7: mse=0.238196 step=0.050000
2017/08/30 14:44:25 Saving...
2017/08/30 14:44:25 Gathering batch of experience...
2017/08/30 14:45:03 batch 212: mean=24.200000 stddev=12.769495 entropy=0.218410 frames=7534 count=20
2017/08/30 14:45:03 Training policy...
2017/08/30 14:45:07 tune 0: objective=0.125266 reg=0.002184 prune=0
2017/08/30 14:45:08 step 0: objective=0.125266 reg=0.002184
2017/08/30 14:45:10 step 1: objective=0.125421 reg=0.002182
2017/08/30 14:45:11 step 2: objective=0.125564 reg=0.002182
2017/08/30 14:45:13 step 3: objective=0.125693 reg=0.002181
2017/08/30 14:45:14 step 4: objective=0.125875 reg=0.002179
2017/08/30 14:45:15 step 5: objective=0.125998 reg=0.002178
2017/08/30 14:45:17 step 6: objective=0.126138 reg=0.002178
2017/08/30 14:45:18 step 7: objective=0.126269 reg=0.002177
2017/08/30 14:45:18 Training value function...
2017/08/30 14:45:21 step 0: mse=0.242544 step=0.050000
2017/08/30 14:45:22 step 1: mse=0.242408 step=0.050000
2017/08/30 14:45:24 step 2: mse=0.242052 step=0.050000
2017/08/30 14:45:25 step 3: mse=0.241909 step=0.050000
2017/08/30 14:45:26 step 4: mse=0.241880 step=0.050000
2017/08/30 14:45:28 step 5: mse=0.241448 step=0.050000
2017/08/30 14:45:29 step 6: mse=0.241565 step=0.050000
2017/08/30 14:45:30 step 7: mse=0.241810 step=0.050000
2017/08/30 14:45:30 Saving...
2017/08/30 14:45:30 Gathering batch of experience...
2017/08/30 14:46:08 batch 213: mean=30.000000 stddev=13.381286 entropy=0.222185 frames=7882 count=17
2017/08/30 14:46:08 Training policy...
2017/08/30 14:46:12 tune 0: objective=0.146479 reg=0.002222 prune=0
2017/08/30 14:46:14 step 0: objective=0.146480 reg=0.002222
2017/08/30 14:46:15 step 1: objective=0.146625 reg=0.002221
2017/08/30 14:46:17 step 2: objective=0.146711 reg=0.002220
2017/08/30 14:46:18 step 3: objective=0.146777 reg=0.002219
2017/08/30 14:46:20 step 4: objective=0.146843 reg=0.002218
2017/08/30 14:46:21 step 5: objective=0.146894 reg=0.002219
2017/08/30 14:46:22 step 6: objective=0.146959 reg=0.002217
2017/08/30 14:46:24 step 7: objective=0.147008 reg=0.002217
2017/08/30 14:46:24 Training value function...
2017/08/30 14:46:27 step 0: mse=0.245781 step=0.050000
2017/08/30 14:46:28 step 1: mse=0.243217 step=0.050000
2017/08/30 14:46:30 step 2: mse=0.240610 step=0.050000
2017/08/30 14:46:31 step 3: mse=0.237902 step=0.050000
2017/08/30 14:46:33 step 4: mse=0.235798 step=0.050000
2017/08/30 14:46:34 step 5: mse=0.233483 step=0.050000
2017/08/30 14:46:35 step 6: mse=0.231479 step=0.050000
2017/08/30 14:46:37 step 7: mse=0.229752 step=0.050000
2017/08/30 14:46:37 Saving...
2017/08/30 14:46:37 Gathering batch of experience...
2017/08/30 14:47:13 batch 214: mean=26.277778 stddev=11.342181 entropy=0.226806 frames=7341 count=18
2017/08/30 14:47:13 Training policy...
2017/08/30 14:47:17 tune 0: objective=0.125833 reg=0.002268 prune=0
2017/08/30 14:47:18 step 0: objective=0.125833 reg=0.002268
2017/08/30 14:47:20 step 1: objective=0.125903 reg=0.002268
2017/08/30 14:47:21 step 2: objective=0.126039 reg=0.002268
2017/08/30 14:47:22 step 3: objective=0.126168 reg=0.002267
2017/08/30 14:47:24 step 4: objective=0.126295 reg=0.002266
2017/08/30 14:47:25 step 5: objective=0.126445 reg=0.002265
2017/08/30 14:47:26 step 6: objective=0.126519 reg=0.002264
2017/08/30 14:47:28 step 7: objective=0.126645 reg=0.002264
2017/08/30 14:47:28 Training value function...
2017/08/30 14:47:31 step 0: mse=0.227185 step=0.050000
2017/08/30 14:47:32 step 1: mse=0.227324 step=0.050000
2017/08/30 14:47:33 step 2: mse=0.227052 step=0.050000
2017/08/30 14:47:34 step 3: mse=0.227101 step=0.050000
2017/08/30 14:47:36 step 4: mse=0.227164 step=0.050000
2017/08/30 14:47:37 step 5: mse=0.227298 step=0.050000
2017/08/30 14:47:38 step 6: mse=0.227530 step=0.050000
2017/08/30 14:47:40 step 7: mse=0.227671 step=0.050000
2017/08/30 14:47:40 Saving...
2017/08/30 14:47:40 Gathering batch of experience...
2017/08/30 14:48:21 batch 215: mean=26.800000 stddev=11.655900 entropy=0.221937 frames=8330 count=20
2017/08/30 14:48:21 Training policy...
2017/08/30 14:48:26 tune 0: objective=0.128689 reg=0.002219 prune=0
2017/08/30 14:48:27 step 0: objective=0.128689 reg=0.002219
2017/08/30 14:48:29 step 1: objective=0.128785 reg=0.002218
2017/08/30 14:48:30 step 2: objective=0.128899 reg=0.002218
2017/08/30 14:48:32 step 3: objective=0.129035 reg=0.002217
2017/08/30 14:48:33 step 4: objective=0.129155 reg=0.002217
2017/08/30 14:48:35 step 5: objective=0.129257 reg=0.002217
2017/08/30 14:48:36 step 6: objective=0.129363 reg=0.002216
2017/08/30 14:48:38 step 7: objective=0.129445 reg=0.002216
2017/08/30 14:48:38 Training value function...
2017/08/30 14:48:41 step 0: mse=0.229117 step=0.050000
2017/08/30 14:48:43 step 1: mse=0.228856 step=0.050000
2017/08/30 14:48:44 step 2: mse=0.228586 step=0.050000
2017/08/30 14:48:46 step 3: mse=0.228612 step=0.050000
2017/08/30 14:48:47 step 4: mse=0.228450 step=0.050000
2017/08/30 14:48:49 step 5: mse=0.228336 step=0.050000
2017/08/30 14:48:50 step 6: mse=0.228232 step=0.050000
2017/08/30 14:48:52 step 7: mse=0.228363 step=0.050000
2017/08/30 14:48:52 Saving...
2017/08/30 14:48:52 Gathering batch of experience...
2017/08/30 14:49:31 batch 216: mean=24.047619 stddev=15.072764 entropy=0.218773 frames=7874 count=21
2017/08/30 14:49:31 Training policy...
2017/08/30 14:49:35 tune 0: objective=0.126327 reg=0.002188 prune=0
2017/08/30 14:49:37 step 0: objective=0.126327 reg=0.002188
2017/08/30 14:49:38 step 1: objective=0.126405 reg=0.002188
2017/08/30 14:49:39 step 2: objective=0.126484 reg=0.002187
2017/08/30 14:49:41 step 3: objective=0.126570 reg=0.002187
2017/08/30 14:49:42 step 4: objective=0.126691 reg=0.002186
2017/08/30 14:49:44 step 5: objective=0.126748 reg=0.002186
2017/08/30 14:49:45 step 6: objective=0.126791 reg=0.002185
2017/08/30 14:49:47 step 7: objective=0.126925 reg=0.002185
2017/08/30 14:49:47 Training value function...
2017/08/30 14:49:50 step 0: mse=0.243285 step=0.050000
2017/08/30 14:49:51 step 1: mse=0.243003 step=0.050000
2017/08/30 14:49:53 step 2: mse=0.242707 step=0.050000
2017/08/30 14:49:54 step 3: mse=0.242640 step=0.050000
2017/08/30 14:49:55 step 4: mse=0.242749 step=0.050000
2017/08/30 14:49:57 step 5: mse=0.242805 step=0.050000
2017/08/30 14:49:58 step 6: mse=0.242922 step=0.050000
2017/08/30 14:50:00 step 7: mse=0.242783 step=0.050000
2017/08/30 14:50:00 Saving...
2017/08/30 14:50:00 Gathering batch of experience...
2017/08/30 14:50:38 batch 217: mean=27.222222 stddev=14.152171 entropy=0.224707 frames=7563 count=18
2017/08/30 14:50:38 Training policy...
2017/08/30 14:50:42 tune 0: objective=0.140808 reg=0.002247 prune=0
2017/08/30 14:50:44 step 0: objective=0.140808 reg=0.002247
2017/08/30 14:50:45 step 1: objective=0.140948 reg=0.002246
2017/08/30 14:50:46 step 2: objective=0.141091 reg=0.002246
2017/08/30 14:50:48 step 3: objective=0.141237 reg=0.002246
2017/08/30 14:50:49 step 4: objective=0.141360 reg=0.002245
2017/08/30 14:50:50 step 5: objective=0.141469 reg=0.002244
2017/08/30 14:50:52 step 6: objective=0.141543 reg=0.002243
2017/08/30 14:50:53 step 7: objective=0.141613 reg=0.002242
2017/08/30 14:50:53 Training value function...
2017/08/30 14:50:56 step 0: mse=0.232773 step=0.050000
2017/08/30 14:50:57 step 1: mse=0.231126 step=0.050000
2017/08/30 14:50:59 step 2: mse=0.229659 step=0.050000
2017/08/30 14:51:00 step 3: mse=0.228321 step=0.050000
2017/08/30 14:51:01 step 4: mse=0.226863 step=0.050000
2017/08/30 14:51:03 step 5: mse=0.225500 step=0.050000
2017/08/30 14:51:04 step 6: mse=0.224938 step=0.050000
2017/08/30 14:51:05 step 7: mse=0.224275 step=0.050000
2017/08/30 14:51:05 Saving...
2017/08/30 14:51:05 Gathering batch of experience...
2017/08/30 14:51:43 batch 218: mean=27.055556 stddev=14.198874 entropy=0.227795 frames=7594 count=18
2017/08/30 14:51:43 Training policy...
2017/08/30 14:51:47 tune 0: objective=0.126675 reg=0.002278 prune=0
2017/08/30 14:51:49 step 0: objective=0.126675 reg=0.002278
2017/08/30 14:51:50 step 1: objective=0.126799 reg=0.002277
2017/08/30 14:51:52 step 2: objective=0.126876 reg=0.002277
2017/08/30 14:51:53 step 3: objective=0.126982 reg=0.002278
2017/08/30 14:51:54 step 4: objective=0.127053 reg=0.002277
2017/08/30 14:51:56 step 5: objective=0.127111 reg=0.002278
2017/08/30 14:51:57 step 6: objective=0.127170 reg=0.002278
2017/08/30 14:51:59 step 7: objective=0.127234 reg=0.002277
2017/08/30 14:51:59 Training value function...
2017/08/30 14:52:02 step 0: mse=0.235485 step=0.050000
2017/08/30 14:52:03 step 1: mse=0.235335 step=0.050000
2017/08/30 14:52:04 step 2: mse=0.235041 step=0.050000
2017/08/30 14:52:06 step 3: mse=0.234978 step=0.050000
2017/08/30 14:52:07 step 4: mse=0.234844 step=0.050000
2017/08/30 14:52:08 step 5: mse=0.234683 step=0.050000
2017/08/30 14:52:10 step 6: mse=0.234260 step=0.050000
2017/08/30 14:52:11 step 7: mse=0.234108 step=0.050000
2017/08/30 14:52:11 Saving...
2017/08/30 14:52:11 Gathering batch of experience...
2017/08/30 14:52:51 batch 219: mean=25.000000 stddev=14.781745 entropy=0.221316 frames=7771 count=20
2017/08/30 14:52:51 Training policy...
2017/08/30 14:52:56 tune 0: objective=0.127919 reg=0.002213 prune=0
2017/08/30 14:52:57 step 0: objective=0.127920 reg=0.002213
2017/08/30 14:52:59 step 1: objective=0.127993 reg=0.002214
2017/08/30 14:53:00 step 2: objective=0.128131 reg=0.002215
2017/08/30 14:53:01 step 3: objective=0.128226 reg=0.002215
2017/08/30 14:53:03 step 4: objective=0.128306 reg=0.002216
2017/08/30 14:53:04 step 5: objective=0.128437 reg=0.002216
2017/08/30 14:53:06 step 6: objective=0.128570 reg=0.002217
2017/08/30 14:53:07 step 7: objective=0.128602 reg=0.002217
2017/08/30 14:53:07 Training value function...
2017/08/30 14:53:10 step 0: mse=0.230689 step=0.050000
2017/08/30 14:53:12 step 1: mse=0.230512 step=0.050000
2017/08/30 14:53:13 step 2: mse=0.229958 step=0.050000
2017/08/30 14:53:14 step 3: mse=0.230172 step=0.050000
2017/08/30 14:53:16 step 4: mse=0.229543 step=0.050000
2017/08/30 14:53:17 step 5: mse=0.229415 step=0.050000
2017/08/30 14:53:18 step 6: mse=0.229385 step=0.050000
2017/08/30 14:53:20 step 7: mse=0.228829 step=0.050000
2017/08/30 14:53:20 Saving...
2017/08/30 14:53:20 Gathering batch of experience...
2017/08/30 14:53:59 batch 220: mean=32.812500 stddev=10.266564 entropy=0.214588 frames=8125 count=16
2017/08/30 14:53:59 Training policy...
2017/08/30 14:54:03 tune 0: objective=0.139771 reg=0.002146 prune=0
2017/08/30 14:54:05 step 0: objective=0.139772 reg=0.002146
2017/08/30 14:54:06 step 1: objective=0.139876 reg=0.002146
2017/08/30 14:54:08 step 2: objective=0.140004 reg=0.002147
2017/08/30 14:54:09 step 3: objective=0.140114 reg=0.002146
2017/08/30 14:54:11 step 4: objective=0.140264 reg=0.002147
2017/08/30 14:54:12 step 5: objective=0.140348 reg=0.002146
2017/08/30 14:54:14 step 6: objective=0.140448 reg=0.002146
2017/08/30 14:54:15 step 7: objective=0.140502 reg=0.002146
2017/08/30 14:54:15 Training value function...
2017/08/30 14:54:18 step 0: mse=0.228835 step=0.050000
2017/08/30 14:54:20 step 1: mse=0.227554 step=0.050000
2017/08/30 14:54:21 step 2: mse=0.226134 step=0.050000
2017/08/30 14:54:23 step 3: mse=0.224962 step=0.050000
2017/08/30 14:54:24 step 4: mse=0.223621 step=0.050000
2017/08/30 14:54:25 step 5: mse=0.222601 step=0.050000
2017/08/30 14:54:27 step 6: mse=0.221669 step=0.050000
2017/08/30 14:54:28 step 7: mse=0.220483 step=0.050000
2017/08/30 14:54:28 Saving...
2017/08/30 14:54:28 Gathering batch of experience...
2017/08/30 14:55:04 batch 221: mean=29.250000 stddev=13.423394 entropy=0.218617 frames=7258 count=16
2017/08/30 14:55:04 Training policy...
2017/08/30 14:55:08 tune 0: objective=0.130191 reg=0.002186 prune=0
2017/08/30 14:55:10 step 0: objective=0.130191 reg=0.002186
2017/08/30 14:55:11 step 1: objective=0.130297 reg=0.002186
2017/08/30 14:55:12 step 2: objective=0.130410 reg=0.002187
2017/08/30 14:55:14 step 3: objective=0.130495 reg=0.002188
2017/08/30 14:55:15 step 4: objective=0.130608 reg=0.002189
2017/08/30 14:55:16 step 5: objective=0.130726 reg=0.002189
2017/08/30 14:55:17 step 6: objective=0.130858 reg=0.002190
2017/08/30 14:55:19 step 7: objective=0.131005 reg=0.002190
2017/08/30 14:55:19 Training value function...
2017/08/30 14:55:22 step 0: mse=0.223000 step=0.050000
2017/08/30 14:55:23 step 1: mse=0.222577 step=0.050000
2017/08/30 14:55:24 step 2: mse=0.222181 step=0.050000
2017/08/30 14:55:26 step 3: mse=0.221798 step=0.050000
2017/08/30 14:55:27 step 4: mse=0.221764 step=0.050000
2017/08/30 14:55:28 step 5: mse=0.221372 step=0.050000
2017/08/30 14:55:29 step 6: mse=0.221116 step=0.050000
2017/08/30 14:55:31 step 7: mse=0.220688 step=0.050000
2017/08/30 14:55:31 Saving...
2017/08/30 14:55:31 Gathering batch of experience...
2017/08/30 14:56:08 batch 222: mean=27.611111 stddev=10.683003 entropy=0.217725 frames=7744 count=18
2017/08/30 14:56:08 Training policy...
2017/08/30 14:56:13 tune 0: objective=0.121250 reg=0.002177 prune=0
2017/08/30 14:56:14 step 0: objective=0.121250 reg=0.002177
2017/08/30 14:56:16 step 1: objective=0.121361 reg=0.002178
2017/08/30 14:56:17 step 2: objective=0.121449 reg=0.002178
2017/08/30 14:56:18 step 3: objective=0.121545 reg=0.002179
2017/08/30 14:56:20 step 4: objective=0.121625 reg=0.002179
2017/08/30 14:56:21 step 5: objective=0.121699 reg=0.002178
2017/08/30 14:56:23 step 6: objective=0.121784 reg=0.002179
2017/08/30 14:56:24 step 7: objective=0.121860 reg=0.002179
2017/08/30 14:56:24 Training value function...
2017/08/30 14:56:27 step 0: mse=0.225912 step=0.050000
2017/08/30 14:56:29 step 1: mse=0.225937 step=0.050000
2017/08/30 14:56:30 step 2: mse=0.225698 step=0.050000
2017/08/30 14:56:31 step 3: mse=0.226062 step=0.050000
2017/08/30 14:56:33 step 4: mse=0.226203 step=0.050000
2017/08/30 14:56:34 step 5: mse=0.226497 step=0.050000
2017/08/30 14:56:36 step 6: mse=0.226705 step=0.050000
2017/08/30 14:56:37 step 7: mse=0.226666 step=0.050000
2017/08/30 14:56:37 Saving...
2017/08/30 14:56:37 Gathering batch of experience...
2017/08/30 14:57:15 batch 223: mean=31.062500 stddev=10.401134 entropy=0.216899 frames=7712 count=16
2017/08/30 14:57:15 Training policy...
2017/08/30 14:57:19 tune 0: objective=0.133382 reg=0.002169 prune=0
2017/08/30 14:57:21 step 0: objective=0.133382 reg=0.002169
2017/08/30 14:57:22 step 1: objective=0.133477 reg=0.002169
2017/08/30 14:57:23 step 2: objective=0.133590 reg=0.002168
2017/08/30 14:57:25 step 3: objective=0.133672 reg=0.002167
2017/08/30 14:57:26 step 4: objective=0.133733 reg=0.002167
2017/08/30 14:57:28 step 5: objective=0.133869 reg=0.002167
2017/08/30 14:57:29 step 6: objective=0.133974 reg=0.002167
2017/08/30 14:57:30 step 7: objective=0.134097 reg=0.002166
2017/08/30 14:57:30 Training value function...
2017/08/30 14:57:34 step 0: mse=0.226183 step=0.050000
2017/08/30 14:57:35 step 1: mse=0.225398 step=0.050000
2017/08/30 14:57:36 step 2: mse=0.225019 step=0.050000
2017/08/30 14:57:38 step 3: mse=0.224688 step=0.050000
2017/08/30 14:57:39 step 4: mse=0.224265 step=0.050000
2017/08/30 14:57:40 step 5: mse=0.223965 step=0.050000
2017/08/30 14:57:41 step 6: mse=0.223691 step=0.050000
2017/08/30 14:57:43 step 7: mse=0.222920 step=0.050000
2017/08/30 14:57:43 Saving...
2017/08/30 14:57:43 Gathering batch of experience...
2017/08/30 14:58:21 batch 224: mean=28.944444 stddev=11.927896 entropy=0.214529 frames=8089 count=18
2017/08/30 14:58:21 Training policy...
2017/08/30 14:58:26 tune 0: objective=0.131703 reg=0.002145 prune=0
2017/08/30 14:58:27 step 0: objective=0.131703 reg=0.002145
2017/08/30 14:58:29 step 1: objective=0.131775 reg=0.002145
2017/08/30 14:58:30 step 2: objective=0.131912 reg=0.002145
2017/08/30 14:58:32 step 3: objective=0.132065 reg=0.002144
2017/08/30 14:58:33 step 4: objective=0.132155 reg=0.002145
2017/08/30 14:58:35 step 5: objective=0.132252 reg=0.002144
2017/08/30 14:58:36 step 6: objective=0.132346 reg=0.002143
2017/08/30 14:58:38 step 7: objective=0.132446 reg=0.002143
2017/08/30 14:58:38 Training value function...
2017/08/30 14:58:41 step 0: mse=0.232839 step=0.050000
2017/08/30 14:58:43 step 1: mse=0.232573 step=0.050000
2017/08/30 14:58:44 step 2: mse=0.232475 step=0.050000
2017/08/30 14:58:45 step 3: mse=0.232408 step=0.050000
2017/08/30 14:58:47 step 4: mse=0.232315 step=0.050000
2017/08/30 14:58:48 step 5: mse=0.231910 step=0.050000
2017/08/30 14:58:50 step 6: mse=0.231865 step=0.050000
2017/08/30 14:58:51 step 7: mse=0.231368 step=0.050000
2017/08/30 14:58:51 Saving...
2017/08/30 14:58:51 Gathering batch of experience...
2017/08/30 14:59:29 batch 225: mean=22.619048 stddev=14.274440 entropy=0.219228 frames=7412 count=21
2017/08/30 14:59:29 Training policy...
2017/08/30 14:59:33 tune 0: objective=0.117885 reg=0.002192 prune=0
2017/08/30 14:59:35 step 0: objective=0.117885 reg=0.002192
2017/08/30 14:59:36 step 1: objective=0.117997 reg=0.002192
2017/08/30 14:59:37 step 2: objective=0.118124 reg=0.002191
2017/08/30 14:59:39 step 3: objective=0.118216 reg=0.002191
2017/08/30 14:59:40 step 4: objective=0.118354 reg=0.002190
2017/08/30 14:59:41 step 5: objective=0.118460 reg=0.002189
2017/08/30 14:59:43 step 6: objective=0.118527 reg=0.002189
2017/08/30 14:59:44 step 7: objective=0.118566 reg=0.002188
2017/08/30 14:59:44 Training value function...
2017/08/30 14:59:47 step 0: mse=0.231155 step=0.050000
2017/08/30 14:59:49 step 1: mse=0.231569 step=0.050000
2017/08/30 14:59:50 step 2: mse=0.232113 step=0.050000
2017/08/30 14:59:51 step 3: mse=0.232425 step=0.050000
2017/08/30 14:59:52 step 4: mse=0.232762 step=0.050000
2017/08/30 14:59:54 step 5: mse=0.233171 step=0.050000
2017/08/30 14:59:55 step 6: mse=0.233755 step=0.050000
2017/08/30 14:59:56 step 7: mse=0.234193 step=0.050000
2017/08/30 14:59:56 Saving...
2017/08/30 14:59:56 Gathering batch of experience...
2017/08/30 15:00:31 batch 226: mean=29.750000 stddev=8.250000 entropy=0.216074 frames=7385 count=16
2017/08/30 15:00:31 Training policy...
2017/08/30 15:00:35 tune 0: objective=0.133470 reg=0.002161 prune=0
2017/08/30 15:00:37 step 0: objective=0.133470 reg=0.002161
2017/08/30 15:00:38 step 1: objective=0.133680 reg=0.002160
2017/08/30 15:00:39 step 2: objective=0.133827 reg=0.002159
2017/08/30 15:00:41 step 3: objective=0.133947 reg=0.002158
2017/08/30 15:00:42 step 4: objective=0.134057 reg=0.002157
2017/08/30 15:00:43 step 5: objective=0.134169 reg=0.002156
2017/08/30 15:00:45 step 6: objective=0.134248 reg=0.002155
2017/08/30 15:00:46 step 7: objective=0.134305 reg=0.002154
2017/08/30 15:00:46 Training value function...
2017/08/30 15:00:49 step 0: mse=0.238115 step=0.050000
2017/08/30 15:00:50 step 1: mse=0.236584 step=0.050000
2017/08/30 15:00:52 step 2: mse=0.235316 step=0.050000
2017/08/30 15:00:53 step 3: mse=0.234289 step=0.050000
2017/08/30 15:00:54 step 4: mse=0.233153 step=0.050000
2017/08/30 15:00:55 step 5: mse=0.232170 step=0.050000
2017/08/30 15:00:57 step 6: mse=0.231281 step=0.050000
2017/08/30 15:00:58 step 7: mse=0.230287 step=0.050000
2017/08/30 15:00:58 Saving...
2017/08/30 15:00:58 Gathering batch of experience...
2017/08/30 15:01:37 batch 227: mean=32.750000 stddev=8.332917 entropy=0.216869 frames=8117 count=16
2017/08/30 15:01:37 Training policy...
2017/08/30 15:01:41 tune 0: objective=0.139221 reg=0.002169 prune=0
2017/08/30 15:01:43 step 0: objective=0.139221 reg=0.002169
2017/08/30 15:01:44 step 1: objective=0.139350 reg=0.002167
2017/08/30 15:01:46 step 2: objective=0.139439 reg=0.002167
2017/08/30 15:01:47 step 3: objective=0.139518 reg=0.002168
2017/08/30 15:01:49 step 4: objective=0.139593 reg=0.002168
2017/08/30 15:01:50 step 5: objective=0.139738 reg=0.002168
2017/08/30 15:01:52 step 6: objective=0.139835 reg=0.002167
2017/08/30 15:01:53 step 7: objective=0.139888 reg=0.002167
2017/08/30 15:01:53 Training value function...
2017/08/30 15:01:56 step 0: mse=0.231336 step=0.050000
2017/08/30 15:01:58 step 1: mse=0.229921 step=0.050000
2017/08/30 15:01:59 step 2: mse=0.228761 step=0.050000
2017/08/30 15:02:01 step 3: mse=0.227777 step=0.050000
2017/08/30 15:02:02 step 4: mse=0.226822 step=0.050000
2017/08/30 15:02:03 step 5: mse=0.225712 step=0.050000
2017/08/30 15:02:05 step 6: mse=0.224216 step=0.050000
2017/08/30 15:02:06 step 7: mse=0.223152 step=0.050000
2017/08/30 15:02:06 Saving...
2017/08/30 15:02:06 Gathering batch of experience...
2017/08/30 15:02:44 batch 228: mean=24.000000 stddev=12.625371 entropy=0.212426 frames=7497 count=20
2017/08/30 15:02:44 Training policy...
2017/08/30 15:02:48 tune 0: objective=0.115234 reg=0.002124 prune=0
2017/08/30 15:02:49 step 0: objective=0.115235 reg=0.002124
2017/08/30 15:02:51 step 1: objective=0.115427 reg=0.002125
2017/08/30 15:02:52 step 2: objective=0.115584 reg=0.002125
2017/08/30 15:02:53 step 3: objective=0.115691 reg=0.002126
2017/08/30 15:02:55 step 4: objective=0.115802 reg=0.002126
2017/08/30 15:02:56 step 5: objective=0.115891 reg=0.002127
2017/08/30 15:02:58 step 6: objective=0.115962 reg=0.002127
2017/08/30 15:02:59 step 7: objective=0.116109 reg=0.002127
2017/08/30 15:02:59 Training value function...
2017/08/30 15:03:02 step 0: mse=0.232933 step=0.050000
2017/08/30 15:03:03 step 1: mse=0.233688 step=0.050000
2017/08/30 15:03:05 step 2: mse=0.234473 step=0.050000
2017/08/30 15:03:06 step 3: mse=0.235171 step=0.050000
2017/08/30 15:03:07 step 4: mse=0.235737 step=0.050000
2017/08/30 15:03:09 step 5: mse=0.236556 step=0.050000
2017/08/30 15:03:10 step 6: mse=0.237259 step=0.050000
2017/08/30 15:03:11 step 7: mse=0.237780 step=0.050000
2017/08/30 15:03:11 Saving...
2017/08/30 15:03:11 Gathering batch of experience...
2017/08/30 15:03:46 batch 229: mean=27.125000 stddev=12.353517 entropy=0.218380 frames=6753 count=16
2017/08/30 15:03:46 Training policy...
2017/08/30 15:03:50 tune 0: objective=0.129065 reg=0.002184 prune=0
2017/08/30 15:03:51 step 0: objective=0.129065 reg=0.002184
2017/08/30 15:03:53 step 1: objective=0.129157 reg=0.002184
2017/08/30 15:03:54 step 2: objective=0.129264 reg=0.002184
2017/08/30 15:03:55 step 3: objective=0.129342 reg=0.002184
2017/08/30 15:03:56 step 4: objective=0.129423 reg=0.002184
2017/08/30 15:03:57 step 5: objective=0.129528 reg=0.002185
2017/08/30 15:03:59 step 6: objective=0.129627 reg=0.002184
2017/08/30 15:04:00 step 7: objective=0.129767 reg=0.002184
2017/08/30 15:04:00 Training value function...
2017/08/30 15:04:03 step 0: mse=0.242627 step=0.050000
2017/08/30 15:04:04 step 1: mse=0.241759 step=0.050000
2017/08/30 15:04:05 step 2: mse=0.240876 step=0.050000
2017/08/30 15:04:06 step 3: mse=0.240026 step=0.050000
2017/08/30 15:04:07 step 4: mse=0.239100 step=0.050000
2017/08/30 15:04:08 step 5: mse=0.238699 step=0.050000
2017/08/30 15:04:10 step 6: mse=0.238471 step=0.050000
2017/08/30 15:04:11 step 7: mse=0.238156 step=0.050000
2017/08/30 15:04:11 Saving...
2017/08/30 15:04:11 Gathering batch of experience...
2017/08/30 15:04:46 batch 230: mean=27.250000 stddev=12.007810 entropy=0.216662 frames=6796 count=16
2017/08/30 15:04:46 Training policy...
2017/08/30 15:04:50 tune 0: objective=0.127854 reg=0.002167 prune=0
2017/08/30 15:04:51 step 0: objective=0.127855 reg=0.002167
2017/08/30 15:04:52 step 1: objective=0.127945 reg=0.002168
2017/08/30 15:04:54 step 2: objective=0.128051 reg=0.002168
2017/08/30 15:04:55 step 3: objective=0.128154 reg=0.002169
2017/08/30 15:04:56 step 4: objective=0.128255 reg=0.002169
2017/08/30 15:04:57 step 5: objective=0.128400 reg=0.002168
2017/08/30 15:04:59 step 6: objective=0.128622 reg=0.002168
2017/08/30 15:05:00 step 7: objective=0.128699 reg=0.002167
2017/08/30 15:05:00 Training value function...
2017/08/30 15:05:03 step 0: mse=0.233627 step=0.050000
2017/08/30 15:05:04 step 1: mse=0.233442 step=0.050000
2017/08/30 15:05:05 step 2: mse=0.233189 step=0.050000
2017/08/30 15:05:06 step 3: mse=0.232896 step=0.050000
2017/08/30 15:05:07 step 4: mse=0.232654 step=0.050000
2017/08/30 15:05:09 step 5: mse=0.232622 step=0.050000
2017/08/30 15:05:10 step 6: mse=0.232462 step=0.050000
2017/08/30 15:05:11 step 7: mse=0.232164 step=0.050000
2017/08/30 15:05:11 Saving...
2017/08/30 15:05:11 Gathering batch of experience...
2017/08/30 15:05:50 batch 231: mean=31.470588 stddev=10.059340 entropy=0.215980 frames=8300 count=17
2017/08/30 15:05:50 Training policy...
2017/08/30 15:05:55 tune 0: objective=0.139003 reg=0.002160 prune=0
2017/08/30 15:05:57 step 0: objective=0.139003 reg=0.002160
2017/08/30 15:05:58 step 1: objective=0.139057 reg=0.002159
2017/08/30 15:06:00 step 2: objective=0.139141 reg=0.002158
2017/08/30 15:06:01 step 3: objective=0.139187 reg=0.002158
2017/08/30 15:06:03 step 4: objective=0.139247 reg=0.002158
2017/08/30 15:06:04 step 5: objective=0.139372 reg=0.002159
2017/08/30 15:06:06 step 6: objective=0.139449 reg=0.002158
2017/08/30 15:06:07 step 7: objective=0.139492 reg=0.002158
2017/08/30 15:06:07 Training value function...
2017/08/30 15:06:11 step 0: mse=0.239275 step=0.050000
2017/08/30 15:06:12 step 1: mse=0.237855 step=0.050000
2017/08/30 15:06:14 step 2: mse=0.236757 step=0.050000
2017/08/30 15:06:15 step 3: mse=0.235705 step=0.050000
2017/08/30 15:06:16 step 4: mse=0.234831 step=0.050000
2017/08/30 15:06:18 step 5: mse=0.233831 step=0.050000
2017/08/30 15:06:19 step 6: mse=0.233161 step=0.050000
2017/08/30 15:06:21 step 7: mse=0.232131 step=0.050000
2017/08/30 15:06:21 Saving...
2017/08/30 15:06:21 Gathering batch of experience...
2017/08/30 15:06:58 batch 232: mean=26.777778 stddev=13.062055 entropy=0.218129 frames=7499 count=18
2017/08/30 15:06:58 Training policy...
2017/08/30 15:07:02 tune 0: objective=0.125356 reg=0.002181 prune=0
2017/08/30 15:07:04 step 0: objective=0.125356 reg=0.002181
2017/08/30 15:07:05 step 1: objective=0.125441 reg=0.002182
2017/08/30 15:07:06 step 2: objective=0.125513 reg=0.002182
2017/08/30 15:07:08 step 3: objective=0.125608 reg=0.002183
2017/08/30 15:07:09 step 4: objective=0.125689 reg=0.002183
2017/08/30 15:07:10 step 5: objective=0.125754 reg=0.002183
2017/08/30 15:07:12 step 6: objective=0.125803 reg=0.002183
2017/08/30 15:07:13 step 7: objective=0.125985 reg=0.002183
2017/08/30 15:07:13 Training value function...
2017/08/30 15:07:16 step 0: mse=0.240573 step=0.050000
2017/08/30 15:07:18 step 1: mse=0.240492 step=0.050000
2017/08/30 15:07:19 step 2: mse=0.240845 step=0.050000
2017/08/30 15:07:20 step 3: mse=0.240778 step=0.050000
2017/08/30 15:07:21 step 4: mse=0.241035 step=0.050000
2017/08/30 15:07:23 step 5: mse=0.241350 step=0.050000
2017/08/30 15:07:24 step 6: mse=0.241298 step=0.050000
2017/08/30 15:07:25 step 7: mse=0.241174 step=0.050000
2017/08/30 15:07:25 Saving...
2017/08/30 15:07:25 Gathering batch of experience...
2017/08/30 15:08:01 batch 233: mean=23.777778 stddev=14.296680 entropy=0.217639 frames=6663 count=18
2017/08/30 15:08:01 Training policy...
2017/08/30 15:08:05 tune 0: objective=0.125348 reg=0.002176 prune=0
2017/08/30 15:08:06 step 0: objective=0.125348 reg=0.002176
2017/08/30 15:08:07 step 1: objective=0.125510 reg=0.002177
2017/08/30 15:08:08 step 2: objective=0.125657 reg=0.002178
2017/08/30 15:08:09 step 3: objective=0.125789 reg=0.002179
2017/08/30 15:08:11 step 4: objective=0.125950 reg=0.002179
2017/08/30 15:08:12 step 5: objective=0.126060 reg=0.002179
2017/08/30 15:08:13 step 6: objective=0.126168 reg=0.002180
2017/08/30 15:08:14 step 7: objective=0.126304 reg=0.002180
2017/08/30 15:08:14 Training value function...
2017/08/30 15:08:17 step 0: mse=0.243705 step=0.050000
2017/08/30 15:08:18 step 1: mse=0.243662 step=0.050000
2017/08/30 15:08:19 step 2: mse=0.243512 step=0.050000
2017/08/30 15:08:20 step 3: mse=0.243276 step=0.050000
2017/08/30 15:08:22 step 4: mse=0.242994 step=0.050000
2017/08/30 15:08:23 step 5: mse=0.242947 step=0.050000
2017/08/30 15:08:24 step 6: mse=0.243018 step=0.050000
2017/08/30 15:08:25 step 7: mse=0.242434 step=0.050000
2017/08/30 15:08:25 Saving...
2017/08/30 15:08:25 Gathering batch of experience...
2017/08/30 15:09:05 batch 234: mean=28.842105 stddev=13.491764 entropy=0.216225 frames=8492 count=19
2017/08/30 15:09:05 Training policy...
2017/08/30 15:09:10 tune 0: objective=0.141283 reg=0.002162 prune=0
2017/08/30 15:09:11 step 0: objective=0.141283 reg=0.002162
2017/08/30 15:09:13 step 1: objective=0.141400 reg=0.002162
2017/08/30 15:09:14 step 2: objective=0.141519 reg=0.002161
2017/08/30 15:09:16 step 3: objective=0.141659 reg=0.002160
2017/08/30 15:09:17 step 4: objective=0.141714 reg=0.002161
2017/08/30 15:09:19 step 5: objective=0.141835 reg=0.002161
2017/08/30 15:09:20 step 6: objective=0.141901 reg=0.002161
2017/08/30 15:09:22 step 7: objective=0.141962 reg=0.002161
2017/08/30 15:09:22 Training value function...
2017/08/30 15:09:26 step 0: mse=0.248045 step=0.050000
2017/08/30 15:09:27 step 1: mse=0.246755 step=0.050000
2017/08/30 15:09:29 step 2: mse=0.245658 step=0.050000
2017/08/30 15:09:30 step 3: mse=0.243962 step=0.050000
2017/08/30 15:09:31 step 4: mse=0.243134 step=0.050000
2017/08/30 15:09:33 step 5: mse=0.242246 step=0.050000
2017/08/30 15:09:34 step 6: mse=0.240576 step=0.050000
2017/08/30 15:09:36 step 7: mse=0.239577 step=0.050000
2017/08/30 15:09:36 Saving...
2017/08/30 15:09:36 Gathering batch of experience...
2017/08/30 15:10:14 batch 235: mean=28.333333 stddev=15.081261 entropy=0.212795 frames=7896 count=18
2017/08/30 15:10:14 Training policy...
2017/08/30 15:10:19 tune 0: objective=0.136965 reg=0.002128 prune=0
2017/08/30 15:10:20 step 0: objective=0.136965 reg=0.002128
2017/08/30 15:10:22 step 1: objective=0.137057 reg=0.002128
2017/08/30 15:10:23 step 2: objective=0.137198 reg=0.002128
2017/08/30 15:10:24 step 3: objective=0.137308 reg=0.002128
2017/08/30 15:10:26 step 4: objective=0.137390 reg=0.002128
2017/08/30 15:10:27 step 5: objective=0.137446 reg=0.002129
2017/08/30 15:10:29 step 6: objective=0.137544 reg=0.002130
2017/08/30 15:10:30 step 7: objective=0.137633 reg=0.002130
2017/08/30 15:10:30 Training value function...
2017/08/30 15:10:34 step 0: mse=0.238248 step=0.050000
2017/08/30 15:10:35 step 1: mse=0.237154 step=0.050000
2017/08/30 15:10:36 step 2: mse=0.235737 step=0.050000
2017/08/30 15:10:38 step 3: mse=0.234129 step=0.050000
2017/08/30 15:10:39 step 4: mse=0.232975 step=0.050000
2017/08/30 15:10:40 step 5: mse=0.231754 step=0.050000
2017/08/30 15:10:42 step 6: mse=0.230631 step=0.050000
2017/08/30 15:10:43 step 7: mse=0.229371 step=0.050000
2017/08/30 15:10:43 Saving...
2017/08/30 15:10:43 Gathering batch of experience...
2017/08/30 15:11:23 batch 236: mean=26.100000 stddev=14.017489 entropy=0.218859 frames=8113 count=20
2017/08/30 15:11:23 Training policy...
2017/08/30 15:11:28 tune 0: objective=0.125305 reg=0.002189 prune=0
2017/08/30 15:11:29 step 0: objective=0.125306 reg=0.002189
2017/08/30 15:11:31 step 1: objective=0.125421 reg=0.002189
2017/08/30 15:11:32 step 2: objective=0.125558 reg=0.002189
2017/08/30 15:11:34 step 3: objective=0.125759 reg=0.002188
2017/08/30 15:11:35 step 4: objective=0.125908 reg=0.002189
2017/08/30 15:11:37 step 5: objective=0.125962 reg=0.002188
2017/08/30 15:11:38 step 6: objective=0.126068 reg=0.002188
2017/08/30 15:11:40 step 7: objective=0.126214 reg=0.002188
2017/08/30 15:11:40 Training value function...
2017/08/30 15:11:43 step 0: mse=0.230673 step=0.050000
2017/08/30 15:11:45 step 1: mse=0.230846 step=0.050000
2017/08/30 15:11:46 step 2: mse=0.231365 step=0.050000
2017/08/30 15:11:48 step 3: mse=0.231344 step=0.050000
2017/08/30 15:11:49 step 4: mse=0.231746 step=0.050000
2017/08/30 15:11:50 step 5: mse=0.231758 step=0.050000
2017/08/30 15:11:52 step 6: mse=0.231780 step=0.050000
2017/08/30 15:11:53 step 7: mse=0.231664 step=0.050000
2017/08/30 15:11:53 Saving...
2017/08/30 15:11:53 Gathering batch of experience...
2017/08/30 15:12:33 batch 237: mean=22.739130 stddev=14.984680 entropy=0.215625 frames=8162 count=23
2017/08/30 15:12:33 Training policy...
2017/08/30 15:12:38 tune 0: objective=0.118680 reg=0.002156 prune=0
2017/08/30 15:12:39 step 0: objective=0.118680 reg=0.002156
2017/08/30 15:12:41 step 1: objective=0.118819 reg=0.002155
2017/08/30 15:12:42 step 2: objective=0.118884 reg=0.002154
2017/08/30 15:12:44 step 3: objective=0.118969 reg=0.002154
2017/08/30 15:12:45 step 4: objective=0.119028 reg=0.002154
2017/08/30 15:12:47 step 5: objective=0.119167 reg=0.002153
2017/08/30 15:12:48 step 6: objective=0.119352 reg=0.002152
2017/08/30 15:12:50 step 7: objective=0.119480 reg=0.002150
2017/08/30 15:12:50 Training value function...
2017/08/30 15:12:53 step 0: mse=0.238997 step=0.050000
2017/08/30 15:12:55 step 1: mse=0.239488 step=0.050000
2017/08/30 15:12:56 step 2: mse=0.240082 step=0.050000
2017/08/30 15:12:58 step 3: mse=0.240397 step=0.050000
2017/08/30 15:12:59 step 4: mse=0.241003 step=0.050000
2017/08/30 15:13:01 step 5: mse=0.241536 step=0.050000
2017/08/30 15:13:02 step 6: mse=0.242146 step=0.050000
2017/08/30 15:13:03 step 7: mse=0.242597 step=0.050000
2017/08/30 15:13:03 Saving...
2017/08/30 15:13:03 Gathering batch of experience...
2017/08/30 15:13:44 batch 238: mean=30.166667 stddev=11.393224 entropy=0.213574 frames=8408 count=18
2017/08/30 15:13:44 Training policy...
2017/08/30 15:13:49 tune 0: objective=0.139344 reg=0.002136 prune=0
2017/08/30 15:13:51 step 0: objective=0.139345 reg=0.002136
2017/08/30 15:13:53 step 1: objective=0.139424 reg=0.002136
2017/08/30 15:13:54 step 2: objective=0.139467 reg=0.002136
2017/08/30 15:13:56 step 3: objective=0.139544 reg=0.002136
2017/08/30 15:13:57 step 4: objective=0.139619 reg=0.002136
2017/08/30 15:13:59 step 5: objective=0.139678 reg=0.002136
2017/08/30 15:14:00 step 6: objective=0.139754 reg=0.002136
2017/08/30 15:14:02 step 7: objective=0.139801 reg=0.002135
2017/08/30 15:14:02 Training value function...
2017/08/30 15:14:05 step 0: mse=0.239553 step=0.050000
2017/08/30 15:14:07 step 1: mse=0.237985 step=0.050000
2017/08/30 15:14:08 step 2: mse=0.236565 step=0.050000
2017/08/30 15:14:10 step 3: mse=0.234896 step=0.050000
2017/08/30 15:14:11 step 4: mse=0.233659 step=0.050000
2017/08/30 15:14:13 step 5: mse=0.232481 step=0.050000
2017/08/30 15:14:14 step 6: mse=0.230939 step=0.050000
2017/08/30 15:14:15 step 7: mse=0.230286 step=0.050000
2017/08/30 15:14:15 Saving...
2017/08/30 15:14:15 Gathering batch of experience...
2017/08/30 15:14:53 batch 239: mean=28.055556 stddev=11.554086 entropy=0.214595 frames=7848 count=18
2017/08/30 15:14:53 Training policy...
2017/08/30 15:14:58 tune 0: objective=0.128364 reg=0.002146 prune=0
2017/08/30 15:15:00 step 0: objective=0.128364 reg=0.002146
2017/08/30 15:15:01 step 1: objective=0.128466 reg=0.002146
2017/08/30 15:15:02 step 2: objective=0.128613 reg=0.002146
2017/08/30 15:15:04 step 3: objective=0.128772 reg=0.002146
2017/08/30 15:15:05 step 4: objective=0.128915 reg=0.002145
2017/08/30 15:15:07 step 5: objective=0.129035 reg=0.002144
2017/08/30 15:15:08 step 6: objective=0.129117 reg=0.002143
2017/08/30 15:15:10 step 7: objective=0.129230 reg=0.002142
2017/08/30 15:15:10 Training value function...
2017/08/30 15:15:13 step 0: mse=0.232284 step=0.050000
2017/08/30 15:15:14 step 1: mse=0.232362 step=0.050000
2017/08/30 15:15:16 step 2: mse=0.232489 step=0.050000
2017/08/30 15:15:17 step 3: mse=0.232426 step=0.050000
2017/08/30 15:15:18 step 4: mse=0.232545 step=0.050000
2017/08/30 15:15:20 step 5: mse=0.232612 step=0.050000
2017/08/30 15:15:21 step 6: mse=0.232308 step=0.050000
2017/08/30 15:15:23 step 7: mse=0.232361 step=0.050000
2017/08/30 15:15:23 Saving...
2017/08/30 15:15:23 Gathering batch of experience...
2017/08/30 15:15:58 batch 240: mean=27.687500 stddev=14.074439 entropy=0.219017 frames=6875 count=16
2017/08/30 15:15:58 Training policy...
2017/08/30 15:16:02 tune 0: objective=0.133925 reg=0.002190 prune=0
2017/08/30 15:16:04 step 0: objective=0.133925 reg=0.002190
2017/08/30 15:16:05 step 1: objective=0.134044 reg=0.002189
2017/08/30 15:16:06 step 2: objective=0.134164 reg=0.002187
2017/08/30 15:16:07 step 3: objective=0.134320 reg=0.002185
2017/08/30 15:16:09 step 4: objective=0.134425 reg=0.002186
2017/08/30 15:16:10 step 5: objective=0.134549 reg=0.002184
2017/08/30 15:16:11 step 6: objective=0.134672 reg=0.002184
2017/08/30 15:16:12 step 7: objective=0.134764 reg=0.002183
2017/08/30 15:16:12 Training value function...
2017/08/30 15:16:15 step 0: mse=0.239005 step=0.050000
2017/08/30 15:16:17 step 1: mse=0.238326 step=0.050000
2017/08/30 15:16:18 step 2: mse=0.237278 step=0.050000
2017/08/30 15:16:19 step 3: mse=0.236413 step=0.050000
2017/08/30 15:16:20 step 4: mse=0.235606 step=0.050000
2017/08/30 15:16:21 step 5: mse=0.234751 step=0.050000
2017/08/30 15:16:22 step 6: mse=0.234087 step=0.050000
2017/08/30 15:16:24 step 7: mse=0.233402 step=0.050000
2017/08/30 15:16:24 Saving...
2017/08/30 15:16:24 Gathering batch of experience...
2017/08/30 15:17:03 batch 241: mean=31.352941 stddev=11.737026 entropy=0.210861 frames=8230 count=17
2017/08/30 15:17:03 Training policy...
2017/08/30 15:17:07 tune 0: objective=0.141080 reg=0.002109 prune=0
2017/08/30 15:17:09 step 0: objective=0.141081 reg=0.002109
2017/08/30 15:17:10 step 1: objective=0.141211 reg=0.002111
2017/08/30 15:17:12 step 2: objective=0.141312 reg=0.002111
2017/08/30 15:17:13 step 3: objective=0.141449 reg=0.002113
2017/08/30 15:17:15 step 4: objective=0.141561 reg=0.002115
2017/08/30 15:17:17 step 5: objective=0.141679 reg=0.002116
2017/08/30 15:17:18 step 6: objective=0.141757 reg=0.002116
2017/08/30 15:17:20 step 7: objective=0.141835 reg=0.002117
2017/08/30 15:17:20 Training value function...
2017/08/30 15:17:23 step 0: mse=0.227897 step=0.050000
2017/08/30 15:17:24 step 1: mse=0.226031 step=0.050000
2017/08/30 15:17:26 step 2: mse=0.224089 step=0.050000
2017/08/30 15:17:27 step 3: mse=0.222317 step=0.050000
2017/08/30 15:17:29 step 4: mse=0.220462 step=0.050000
2017/08/30 15:17:30 step 5: mse=0.219100 step=0.050000
2017/08/30 15:17:31 step 6: mse=0.217730 step=0.050000
2017/08/30 15:17:33 step 7: mse=0.216490 step=0.050000
2017/08/30 15:17:33 Saving...
2017/08/30 15:17:33 Gathering batch of experience...
2017/08/30 15:18:10 batch 242: mean=23.190476 stddev=14.411038 entropy=0.216898 frames=7593 count=21
2017/08/30 15:18:10 Training policy...
2017/08/30 15:18:15 tune 0: objective=0.117412 reg=0.002169 prune=0
2017/08/30 15:18:16 step 0: objective=0.117412 reg=0.002169
2017/08/30 15:18:18 step 1: objective=0.117490 reg=0.002169
2017/08/30 15:18:19 step 2: objective=0.117549 reg=0.002169
2017/08/30 15:18:20 step 3: objective=0.117614 reg=0.002168
2017/08/30 15:18:22 step 4: objective=0.117682 reg=0.002167
2017/08/30 15:18:23 step 5: objective=0.117757 reg=0.002167
2017/08/30 15:18:25 step 6: objective=0.117808 reg=0.002167
2017/08/30 15:18:26 step 7: objective=0.117869 reg=0.002167
2017/08/30 15:18:26 Training value function...
2017/08/30 15:18:29 step 0: mse=0.226185 step=0.050000
2017/08/30 15:18:30 step 1: mse=0.226741 step=0.050000
2017/08/30 15:18:32 step 2: mse=0.227453 step=0.050000
2017/08/30 15:18:33 step 3: mse=0.227733 step=0.050000
2017/08/30 15:18:34 step 4: mse=0.228378 step=0.050000
2017/08/30 15:18:36 step 5: mse=0.228843 step=0.050000
2017/08/30 15:18:37 step 6: mse=0.229023 step=0.050000
2017/08/30 15:18:38 step 7: mse=0.229309 step=0.050000
2017/08/30 15:18:38 Saving...
2017/08/30 15:18:38 Gathering batch of experience...
2017/08/30 15:19:19 batch 243: mean=26.000000 stddev=11.956060 entropy=0.213327 frames=7686 count=19
2017/08/30 15:19:19 Training policy...
2017/08/30 15:19:24 tune 0: objective=0.124089 reg=0.002133 prune=0
2017/08/30 15:19:25 step 0: objective=0.124089 reg=0.002133
2017/08/30 15:19:27 step 1: objective=0.124206 reg=0.002132
2017/08/30 15:19:28 step 2: objective=0.124296 reg=0.002132
2017/08/30 15:19:29 step 3: objective=0.124429 reg=0.002132
2017/08/30 15:19:31 step 4: objective=0.124550 reg=0.002132
2017/08/30 15:19:32 step 5: objective=0.124660 reg=0.002132
2017/08/30 15:19:34 step 6: objective=0.124806 reg=0.002131
2017/08/30 15:19:35 step 7: objective=0.124928 reg=0.002131
2017/08/30 15:19:35 Training value function...
2017/08/30 15:19:38 step 0: mse=0.227601 step=0.050000
2017/08/30 15:19:40 step 1: mse=0.227997 step=0.050000
2017/08/30 15:19:41 step 2: mse=0.228437 step=0.050000
2017/08/30 15:19:42 step 3: mse=0.228658 step=0.050000
2017/08/30 15:19:44 step 4: mse=0.228922 step=0.050000
2017/08/30 15:19:45 step 5: mse=0.229359 step=0.050000
2017/08/30 15:19:46 step 6: mse=0.229672 step=0.050000
2017/08/30 15:19:48 step 7: mse=0.229882 step=0.050000
2017/08/30 15:19:48 Saving...
2017/08/30 15:19:48 Gathering batch of experience...
2017/08/30 15:20:22 batch 244: mean=25.875000 stddev=12.839758 entropy=0.215635 frames=6472 count=16
2017/08/30 15:20:22 Training policy...
2017/08/30 15:20:26 tune 0: objective=0.123837 reg=0.002156 prune=0
2017/08/30 15:20:27 step 0: objective=0.123837 reg=0.002156
2017/08/30 15:20:29 step 1: objective=0.123967 reg=0.002156
2017/08/30 15:20:30 step 2: objective=0.124101 reg=0.002157
2017/08/30 15:20:31 step 3: objective=0.124180 reg=0.002156
2017/08/30 15:20:32 step 4: objective=0.124317 reg=0.002156
2017/08/30 15:20:33 step 5: objective=0.124413 reg=0.002158
2017/08/30 15:20:34 step 6: objective=0.124520 reg=0.002158
2017/08/30 15:20:36 step 7: objective=0.124625 reg=0.002158
2017/08/30 15:20:36 Training value function...
2017/08/30 15:20:38 step 0: mse=0.237472 step=0.050000
2017/08/30 15:20:39 step 1: mse=0.237862 step=0.050000
2017/08/30 15:20:41 step 2: mse=0.238088 step=0.050000
2017/08/30 15:20:42 step 3: mse=0.238451 step=0.050000
2017/08/30 15:20:43 step 4: mse=0.238742 step=0.050000
2017/08/30 15:20:44 step 5: mse=0.239011 step=0.050000
2017/08/30 15:20:45 step 6: mse=0.239230 step=0.050000
2017/08/30 15:20:46 step 7: mse=0.239435 step=0.050000
2017/08/30 15:20:46 Saving...
2017/08/30 15:20:46 Gathering batch of experience...
2017/08/30 15:21:22 batch 245: mean=27.235294 stddev=11.111888 entropy=0.212915 frames=7203 count=17
2017/08/30 15:21:22 Training policy...
2017/08/30 15:21:27 tune 0: objective=0.130672 reg=0.002129 prune=0
2017/08/30 15:21:28 step 0: objective=0.130673 reg=0.002129
2017/08/30 15:21:29 step 1: objective=0.130860 reg=0.002128
2017/08/30 15:21:31 step 2: objective=0.130987 reg=0.002128
2017/08/30 15:21:32 step 3: objective=0.131092 reg=0.002129
2017/08/30 15:21:33 step 4: objective=0.131183 reg=0.002129
2017/08/30 15:21:35 step 5: objective=0.131355 reg=0.002127
2017/08/30 15:21:36 step 6: objective=0.131513 reg=0.002127
2017/08/30 15:21:37 step 7: objective=0.131643 reg=0.002127
2017/08/30 15:21:37 Training value function...
2017/08/30 15:21:40 step 0: mse=0.234864 step=0.050000
2017/08/30 15:21:41 step 1: mse=0.234056 step=0.050000
2017/08/30 15:21:43 step 2: mse=0.233096 step=0.050000
2017/08/30 15:21:44 step 3: mse=0.232305 step=0.050000
2017/08/30 15:21:45 step 4: mse=0.231417 step=0.050000
2017/08/30 15:21:46 step 5: mse=0.230685 step=0.050000
2017/08/30 15:21:48 step 6: mse=0.230079 step=0.050000
2017/08/30 15:21:49 step 7: mse=0.229763 step=0.050000
2017/08/30 15:21:49 Saving...
2017/08/30 15:21:49 Gathering batch of experience...
2017/08/30 15:22:26 batch 246: mean=30.250000 stddev=11.776566 entropy=0.211525 frames=7515 count=16
2017/08/30 15:22:26 Training policy...
2017/08/30 15:22:31 tune 0: objective=0.139235 reg=0.002115 prune=0
2017/08/30 15:22:32 step 0: objective=0.139235 reg=0.002115
2017/08/30 15:22:33 step 1: objective=0.139339 reg=0.002115
2017/08/30 15:22:35 step 2: objective=0.139447 reg=0.002116
2017/08/30 15:22:36 step 3: objective=0.139542 reg=0.002117
2017/08/30 15:22:37 step 4: objective=0.139688 reg=0.002116
2017/08/30 15:22:39 step 5: objective=0.139844 reg=0.002116
2017/08/30 15:22:40 step 6: objective=0.139898 reg=0.002116
2017/08/30 15:22:42 step 7: objective=0.139994 reg=0.002117
2017/08/30 15:22:42 Training value function...
2017/08/30 15:22:45 step 0: mse=0.239272 step=0.050000
2017/08/30 15:22:46 step 1: mse=0.237786 step=0.050000
2017/08/30 15:22:47 step 2: mse=0.236449 step=0.050000
2017/08/30 15:22:49 step 3: mse=0.234863 step=0.050000
2017/08/30 15:22:50 step 4: mse=0.233911 step=0.050000
2017/08/30 15:22:51 step 5: mse=0.232906 step=0.050000
2017/08/30 15:22:52 step 6: mse=0.232056 step=0.050000
2017/08/30 15:22:54 step 7: mse=0.231411 step=0.050000
2017/08/30 15:22:54 Saving...
2017/08/30 15:22:54 Gathering batch of experience...
2017/08/30 15:23:31 batch 247: mean=25.684211 stddev=12.863873 entropy=0.211392 frames=7602 count=19
2017/08/30 15:23:31 Training policy...
2017/08/30 15:23:36 tune 0: objective=0.124674 reg=0.002114 prune=0
2017/08/30 15:23:37 step 0: objective=0.124673 reg=0.002114
2017/08/30 15:23:38 step 1: objective=0.124772 reg=0.002114
2017/08/30 15:23:40 step 2: objective=0.124898 reg=0.002114
2017/08/30 15:23:41 step 3: objective=0.125003 reg=0.002115
2017/08/30 15:23:43 step 4: objective=0.125129 reg=0.002115
2017/08/30 15:23:44 step 5: objective=0.125221 reg=0.002115
2017/08/30 15:23:45 step 6: objective=0.125283 reg=0.002115
2017/08/30 15:23:47 step 7: objective=0.125370 reg=0.002116
2017/08/30 15:23:47 Training value function...
2017/08/30 15:23:50 step 0: mse=0.232438 step=0.050000
2017/08/30 15:23:51 step 1: mse=0.232564 step=0.050000
2017/08/30 15:23:53 step 2: mse=0.232725 step=0.050000
2017/08/30 15:23:54 step 3: mse=0.232977 step=0.050000
2017/08/30 15:23:55 step 4: mse=0.233222 step=0.050000
2017/08/30 15:23:57 step 5: mse=0.233217 step=0.050000
2017/08/30 15:23:58 step 6: mse=0.233462 step=0.050000
2017/08/30 15:23:59 step 7: mse=0.233618 step=0.050000
2017/08/30 15:23:59 Saving...
2017/08/30 15:23:59 Gathering batch of experience...
2017/08/30 15:24:38 batch 248: mean=32.812500 stddev=9.875593 entropy=0.204752 frames=8153 count=16
2017/08/30 15:24:38 Training policy...
2017/08/30 15:24:43 tune 0: objective=0.141242 reg=0.002048 prune=0
2017/08/30 15:24:44 step 0: objective=0.141243 reg=0.002048
2017/08/30 15:24:46 step 1: objective=0.141374 reg=0.002049
2017/08/30 15:24:47 step 2: objective=0.141557 reg=0.002049
2017/08/30 15:24:49 step 3: objective=0.141732 reg=0.002050
2017/08/30 15:24:50 step 4: objective=0.141820 reg=0.002052
2017/08/30 15:24:52 step 5: objective=0.141960 reg=0.002053
2017/08/30 15:24:53 step 6: objective=0.142080 reg=0.002053
2017/08/30 15:24:55 step 7: objective=0.142177 reg=0.002054
2017/08/30 15:24:55 Training value function...
2017/08/30 15:24:58 step 0: mse=0.234211 step=0.050000
2017/08/30 15:25:00 step 1: mse=0.232026 step=0.050000
2017/08/30 15:25:01 step 2: mse=0.230610 step=0.050000
2017/08/30 15:25:03 step 3: mse=0.229431 step=0.050000
2017/08/30 15:25:04 step 4: mse=0.228081 step=0.050000
2017/08/30 15:25:05 step 5: mse=0.226563 step=0.050000
2017/08/30 15:25:07 step 6: mse=0.225898 step=0.050000
2017/08/30 15:25:08 step 7: mse=0.224897 step=0.050000
2017/08/30 15:25:08 Saving...
2017/08/30 15:25:08 Gathering batch of experience...
2017/08/30 15:25:45 batch 249: mean=25.526316 stddev=15.404608 entropy=0.213953 frames=7531 count=19
2017/08/30 15:25:45 Training policy...
2017/08/30 15:25:50 tune 0: objective=0.128448 reg=0.002140 prune=0
2017/08/30 15:25:51 step 0: objective=0.128448 reg=0.002140
2017/08/30 15:25:53 step 1: objective=0.128539 reg=0.002140
2017/08/30 15:25:54 step 2: objective=0.128694 reg=0.002141
2017/08/30 15:25:55 step 3: objective=0.128819 reg=0.002141
2017/08/30 15:25:57 step 4: objective=0.128932 reg=0.002141
2017/08/30 15:25:58 step 5: objective=0.129056 reg=0.002142
2017/08/30 15:26:00 step 6: objective=0.129196 reg=0.002143
2017/08/30 15:26:01 step 7: objective=0.129308 reg=0.002144
2017/08/30 15:26:01 Training value function...
2017/08/30 15:26:04 step 0: mse=0.230548 step=0.050000
2017/08/30 15:26:06 step 1: mse=0.230452 step=0.050000
2017/08/30 15:26:07 step 2: mse=0.230331 step=0.050000
2017/08/30 15:26:08 step 3: mse=0.230155 step=0.050000
2017/08/30 15:26:09 step 4: mse=0.230039 step=0.050000
2017/08/30 15:26:11 step 5: mse=0.229960 step=0.050000
2017/08/30 15:26:12 step 6: mse=0.229886 step=0.050000
2017/08/30 15:26:13 step 7: mse=0.229717 step=0.050000
2017/08/30 15:26:13 Saving...
2017/08/30 15:26:13 Gathering batch of experience...
2017/08/30 15:26:51 batch 250: mean=27.722222 stddev=12.805405 entropy=0.206483 frames=7751 count=18
2017/08/30 15:26:51 Training policy...
2017/08/30 15:26:56 tune 0: objective=0.128891 reg=0.002065 prune=0
2017/08/30 15:26:57 step 0: objective=0.128891 reg=0.002065
2017/08/30 15:26:58 step 1: objective=0.129041 reg=0.002064
2017/08/30 15:27:00 step 2: objective=0.129123 reg=0.002064
2017/08/30 15:27:01 step 3: objective=0.129195 reg=0.002064
2017/08/30 15:27:03 step 4: objective=0.129255 reg=0.002064
2017/08/30 15:27:04 step 5: objective=0.129335 reg=0.002064
2017/08/30 15:27:06 step 6: objective=0.129428 reg=0.002064
2017/08/30 15:27:07 step 7: objective=0.129572 reg=0.002063
2017/08/30 15:27:07 Training value function...
2017/08/30 15:27:10 step 0: mse=0.230726 step=0.050000
2017/08/30 15:27:12 step 1: mse=0.230927 step=0.050000
2017/08/30 15:27:13 step 2: mse=0.230924 step=0.050000
2017/08/30 15:27:14 step 3: mse=0.230989 step=0.050000
2017/08/30 15:27:16 step 4: mse=0.230892 step=0.050000
2017/08/30 15:27:17 step 5: mse=0.231072 step=0.050000
2017/08/30 15:27:18 step 6: mse=0.231139 step=0.050000
2017/08/30 15:27:20 step 7: mse=0.231145 step=0.050000
2017/08/30 15:27:20 Saving...
2017/08/30 15:27:20 Gathering batch of experience...
2017/08/30 15:27:55 batch 251: mean=24.833333 stddev=13.500000 entropy=0.212897 frames=6948 count=18
2017/08/30 15:27:55 Training policy...
2017/08/30 15:28:00 tune 0: objective=0.124359 reg=0.002129 prune=0
2017/08/30 15:28:01 step 0: objective=0.124359 reg=0.002129
2017/08/30 15:28:02 step 1: objective=0.124497 reg=0.002128
2017/08/30 15:28:03 step 2: objective=0.124573 reg=0.002126
2017/08/30 15:28:05 step 3: objective=0.124676 reg=0.002125
2017/08/30 15:28:06 step 4: objective=0.124738 reg=0.002124
2017/08/30 15:28:07 step 5: objective=0.124871 reg=0.002122
2017/08/30 15:28:08 step 6: objective=0.125004 reg=0.002122
2017/08/30 15:28:10 step 7: objective=0.125060 reg=0.002121
2017/08/30 15:28:10 Training value function...
2017/08/30 15:28:13 step 0: mse=0.227437 step=0.050000
2017/08/30 15:28:14 step 1: mse=0.227816 step=0.050000
2017/08/30 15:28:15 step 2: mse=0.228224 step=0.050000
2017/08/30 15:28:16 step 3: mse=0.228573 step=0.050000
2017/08/30 15:28:17 step 4: mse=0.228960 step=0.050000
2017/08/30 15:28:19 step 5: mse=0.228948 step=0.050000
2017/08/30 15:28:20 step 6: mse=0.229283 step=0.050000
2017/08/30 15:28:21 step 7: mse=0.229527 step=0.050000
2017/08/30 15:28:21 Saving...
2017/08/30 15:28:21 Gathering batch of experience...
2017/08/30 15:29:04 batch 252: mean=29.421053 stddev=12.330176 entropy=0.206400 frames=8658 count=19
2017/08/30 15:29:04 Training policy...
2017/08/30 15:29:09 tune 0: objective=0.138769 reg=0.002064 prune=0
2017/08/30 15:29:11 step 0: objective=0.138769 reg=0.002064
2017/08/30 15:29:12 step 1: objective=0.138851 reg=0.002063
2017/08/30 15:29:14 step 2: objective=0.138927 reg=0.002062
2017/08/30 15:29:16 step 3: objective=0.139014 reg=0.002060
2017/08/30 15:29:17 step 4: objective=0.139115 reg=0.002059
2017/08/30 15:29:19 step 5: objective=0.139204 reg=0.002057
2017/08/30 15:29:20 step 6: objective=0.139322 reg=0.002057
2017/08/30 15:29:22 step 7: objective=0.139398 reg=0.002056
2017/08/30 15:29:22 Training value function...
2017/08/30 15:29:26 step 0: mse=0.238908 step=0.050000
2017/08/30 15:29:27 step 1: mse=0.237683 step=0.050000
2017/08/30 15:29:29 step 2: mse=0.236863 step=0.050000
2017/08/30 15:29:30 step 3: mse=0.235869 step=0.050000
2017/08/30 15:29:32 step 4: mse=0.234288 step=0.050000
2017/08/30 15:29:33 step 5: mse=0.232978 step=0.050000
2017/08/30 15:29:35 step 6: mse=0.231898 step=0.050000
2017/08/30 15:29:36 step 7: mse=0.231533 step=0.050000
2017/08/30 15:29:36 Saving...
2017/08/30 15:29:36 Gathering batch of experience...
2017/08/30 15:30:14 batch 253: mean=27.944444 stddev=13.434914 entropy=0.209205 frames=7820 count=18
2017/08/30 15:30:14 Training policy...
2017/08/30 15:30:19 tune 0: objective=0.130101 reg=0.002092 prune=0
2017/08/30 15:30:20 step 0: objective=0.130101 reg=0.002092
2017/08/30 15:30:22 step 1: objective=0.130221 reg=0.002092
2017/08/30 15:30:23 step 2: objective=0.130296 reg=0.002092
2017/08/30 15:30:25 step 3: objective=0.130375 reg=0.002092
2017/08/30 15:30:26 step 4: objective=0.130488 reg=0.002091
2017/08/30 15:30:28 step 5: objective=0.130568 reg=0.002090
2017/08/30 15:30:29 step 6: objective=0.130661 reg=0.002089
2017/08/30 15:30:30 step 7: objective=0.130748 reg=0.002089
2017/08/30 15:30:30 Training value function...
2017/08/30 15:30:34 step 0: mse=0.236669 step=0.050000
2017/08/30 15:30:35 step 1: mse=0.236580 step=0.050000
2017/08/30 15:30:36 step 2: mse=0.236523 step=0.050000
2017/08/30 15:30:38 step 3: mse=0.236465 step=0.050000
2017/08/30 15:30:39 step 4: mse=0.236184 step=0.050000
2017/08/30 15:30:41 step 5: mse=0.235931 step=0.050000
2017/08/30 15:30:42 step 6: mse=0.235510 step=0.050000
2017/08/30 15:30:43 step 7: mse=0.235217 step=0.050000
2017/08/30 15:30:43 Saving...
2017/08/30 15:30:43 Gathering batch of experience...
2017/08/30 15:31:21 batch 254: mean=25.473684 stddev=13.785455 entropy=0.218533 frames=7516 count=19
2017/08/30 15:31:21 Training policy...
2017/08/30 15:31:26 tune 0: objective=0.126805 reg=0.002185 prune=0
2017/08/30 15:31:27 step 0: objective=0.126806 reg=0.002185
2017/08/30 15:31:28 step 1: objective=0.126950 reg=0.002186
2017/08/30 15:31:30 step 2: objective=0.127078 reg=0.002186
2017/08/30 15:31:31 step 3: objective=0.127153 reg=0.002186
2017/08/30 15:31:33 step 4: objective=0.127289 reg=0.002187
2017/08/30 15:31:34 step 5: objective=0.127476 reg=0.002187
2017/08/30 15:31:35 step 6: objective=0.127583 reg=0.002187
2017/08/30 15:31:37 step 7: objective=0.127757 reg=0.002187
2017/08/30 15:31:37 Training value function...
2017/08/30 15:31:40 step 0: mse=0.226649 step=0.050000
2017/08/30 15:31:41 step 1: mse=0.226892 step=0.050000
2017/08/30 15:31:43 step 2: mse=0.227053 step=0.050000
2017/08/30 15:31:44 step 3: mse=0.226996 step=0.050000
2017/08/30 15:31:45 step 4: mse=0.227022 step=0.050000
2017/08/30 15:31:46 step 5: mse=0.227172 step=0.050000
2017/08/30 15:31:48 step 6: mse=0.227030 step=0.050000
2017/08/30 15:31:49 step 7: mse=0.227266 step=0.050000
2017/08/30 15:31:49 Saving...
2017/08/30 15:31:49 Gathering batch of experience...
2017/08/30 15:32:28 batch 255: mean=29.882353 stddev=11.498759 entropy=0.216704 frames=7863 count=17
2017/08/30 15:32:28 Training policy...
2017/08/30 15:32:33 tune 0: objective=0.137406 reg=0.002167 prune=0
2017/08/30 15:32:34 step 0: objective=0.137407 reg=0.002167
2017/08/30 15:32:36 step 1: objective=0.137582 reg=0.002165
2017/08/30 15:32:37 step 2: objective=0.137792 reg=0.002164
2017/08/30 15:32:39 step 3: objective=0.137996 reg=0.002164
2017/08/30 15:32:40 step 4: objective=0.138097 reg=0.002163
2017/08/30 15:32:42 step 5: objective=0.138181 reg=0.002163
2017/08/30 15:32:43 step 6: objective=0.138251 reg=0.002162
2017/08/30 15:32:45 step 7: objective=0.138323 reg=0.002162
2017/08/30 15:32:45 Training value function...
2017/08/30 15:32:48 step 0: mse=0.231872 step=0.050000
2017/08/30 15:32:49 step 1: mse=0.230800 step=0.050000
2017/08/30 15:32:50 step 2: mse=0.229717 step=0.050000
2017/08/30 15:32:52 step 3: mse=0.228355 step=0.050000
2017/08/30 15:32:53 step 4: mse=0.226778 step=0.050000
2017/08/30 15:32:54 step 5: mse=0.226009 step=0.050000
2017/08/30 15:32:56 step 6: mse=0.225298 step=0.050000
2017/08/30 15:32:57 step 7: mse=0.224475 step=0.050000
2017/08/30 15:32:57 Saving...
2017/08/30 15:32:57 Gathering batch of experience...
2017/08/30 15:33:38 batch 256: mean=28.555556 stddev=12.161973 entropy=0.212249 frames=7985 count=18
2017/08/30 15:33:38 Training policy...
2017/08/30 15:33:43 tune 0: objective=0.129164 reg=0.002122 prune=0
2017/08/30 15:33:44 step 0: objective=0.129164 reg=0.002122
2017/08/30 15:33:45 step 1: objective=0.129215 reg=0.002123
2017/08/30 15:33:47 step 2: objective=0.129261 reg=0.002123
2017/08/30 15:33:48 step 3: objective=0.129335 reg=0.002123
2017/08/30 15:33:50 step 4: objective=0.129414 reg=0.002123
2017/08/30 15:33:51 step 5: objective=0.129492 reg=0.002123
2017/08/30 15:33:53 step 6: objective=0.129605 reg=0.002123
2017/08/30 15:33:54 step 7: objective=0.129648 reg=0.002124
2017/08/30 15:33:54 Training value function...
2017/08/30 15:33:58 step 0: mse=0.227902 step=0.050000
2017/08/30 15:33:59 step 1: mse=0.227932 step=0.050000
2017/08/30 15:34:00 step 2: mse=0.228025 step=0.050000
2017/08/30 15:34:02 step 3: mse=0.227878 step=0.050000
2017/08/30 15:34:03 step 4: mse=0.227929 step=0.050000
2017/08/30 15:34:05 step 5: mse=0.227932 step=0.050000
2017/08/30 15:34:06 step 6: mse=0.227866 step=0.050000
2017/08/30 15:34:08 step 7: mse=0.227971 step=0.050000
2017/08/30 15:34:08 Saving...
2017/08/30 15:34:08 Gathering batch of experience...
2017/08/30 15:34:41 batch 257: mean=26.812500 stddev=12.135788 entropy=0.208143 frames=6676 count=16
2017/08/30 15:34:41 Training policy...
2017/08/30 15:34:45 tune 0: objective=0.124489 reg=0.002081 prune=0
2017/08/30 15:34:47 step 0: objective=0.124489 reg=0.002081
2017/08/30 15:34:48 step 1: objective=0.124571 reg=0.002081
2017/08/30 15:34:49 step 2: objective=0.124665 reg=0.002080
2017/08/30 15:34:50 step 3: objective=0.124757 reg=0.002079
2017/08/30 15:34:52 step 4: objective=0.124866 reg=0.002077
2017/08/30 15:34:53 step 5: objective=0.124976 reg=0.002076
2017/08/30 15:34:54 step 6: objective=0.125037 reg=0.002076
2017/08/30 15:34:55 step 7: objective=0.125236 reg=0.002075
2017/08/30 15:34:55 Training value function...
2017/08/30 15:34:58 step 0: mse=0.228825 step=0.050000
2017/08/30 15:34:59 step 1: mse=0.229143 step=0.050000
2017/08/30 15:35:00 step 2: mse=0.229008 step=0.050000
2017/08/30 15:35:01 step 3: mse=0.229194 step=0.050000
2017/08/30 15:35:03 step 4: mse=0.229643 step=0.050000
2017/08/30 15:35:04 step 5: mse=0.229976 step=0.050000
2017/08/30 15:35:05 step 6: mse=0.230236 step=0.050000
2017/08/30 15:35:06 step 7: mse=0.230577 step=0.050000
2017/08/30 15:35:06 Saving...
2017/08/30 15:35:06 Gathering batch of experience...
2017/08/30 15:35:44 batch 258: mean=25.368421 stddev=11.965787 entropy=0.212194 frames=7514 count=19
2017/08/30 15:35:44 Training policy...
2017/08/30 15:35:48 tune 0: objective=0.123385 reg=0.002122 prune=0
2017/08/30 15:35:50 step 0: objective=0.123385 reg=0.002122
2017/08/30 15:35:51 step 1: objective=0.123444 reg=0.002122
2017/08/30 15:35:53 step 2: objective=0.123546 reg=0.002121
2017/08/30 15:35:54 step 3: objective=0.123590 reg=0.002121
2017/08/30 15:35:55 step 4: objective=0.123662 reg=0.002121
2017/08/30 15:35:57 step 5: objective=0.123728 reg=0.002122
2017/08/30 15:35:58 step 6: objective=0.123800 reg=0.002122
2017/08/30 15:36:00 step 7: objective=0.123921 reg=0.002122
2017/08/30 15:36:00 Training value function...
2017/08/30 15:36:03 step 0: mse=0.231504 step=0.050000
2017/08/30 15:36:04 step 1: mse=0.231904 step=0.050000
2017/08/30 15:36:05 step 2: mse=0.232049 step=0.050000
2017/08/30 15:36:07 step 3: mse=0.231646 step=0.050000
2017/08/30 15:36:08 step 4: mse=0.231724 step=0.050000
2017/08/30 15:36:09 step 5: mse=0.231750 step=0.050000
2017/08/30 15:36:11 step 6: mse=0.231935 step=0.050000
2017/08/30 15:36:12 step 7: mse=0.232169 step=0.050000
2017/08/30 15:36:12 Saving...
2017/08/30 15:36:12 Gathering batch of experience...
2017/08/30 15:36:51 batch 259: mean=24.523810 stddev=13.418605 entropy=0.213952 frames=8000 count=21
2017/08/30 15:36:51 Training policy...
2017/08/30 15:36:55 tune 0: objective=0.127546 reg=0.002140 prune=0
2017/08/30 15:36:57 step 0: objective=0.127546 reg=0.002140
2017/08/30 15:36:58 step 1: objective=0.127650 reg=0.002139
2017/08/30 15:37:00 step 2: objective=0.127733 reg=0.002139
2017/08/30 15:37:01 step 3: objective=0.127840 reg=0.002139
2017/08/30 15:37:03 step 4: objective=0.127952 reg=0.002140
2017/08/30 15:37:04 step 5: objective=0.127998 reg=0.002140
2017/08/30 15:37:06 step 6: objective=0.128058 reg=0.002141
2017/08/30 15:37:07 step 7: objective=0.128141 reg=0.002140
2017/08/30 15:37:07 Training value function...
2017/08/30 15:37:11 step 0: mse=0.236881 step=0.050000
2017/08/30 15:37:12 step 1: mse=0.236436 step=0.050000
2017/08/30 15:37:13 step 2: mse=0.236565 step=0.050000
2017/08/30 15:37:15 step 3: mse=0.236441 step=0.050000
2017/08/30 15:37:16 step 4: mse=0.236499 step=0.050000
2017/08/30 15:37:18 step 5: mse=0.236639 step=0.050000
2017/08/30 15:37:19 step 6: mse=0.236697 step=0.050000
2017/08/30 15:37:20 step 7: mse=0.236794 step=0.050000
2017/08/30 15:37:20 Saving...
2017/08/30 15:37:20 Gathering batch of experience...
2017/08/30 15:37:59 batch 260: mean=28.500000 stddev=13.442263 entropy=0.207168 frames=7941 count=18
2017/08/30 15:37:59 Training policy...
2017/08/30 15:38:03 tune 0: objective=0.140178 reg=0.002072 prune=0
2017/08/30 15:38:05 step 0: objective=0.140179 reg=0.002072
2017/08/30 15:38:06 step 1: objective=0.140313 reg=0.002074
2017/08/30 15:38:08 step 2: objective=0.140465 reg=0.002075
2017/08/30 15:38:09 step 3: objective=0.140651 reg=0.002076
2017/08/30 15:38:11 step 4: objective=0.140725 reg=0.002077
2017/08/30 15:38:12 step 5: objective=0.140812 reg=0.002078
2017/08/30 15:38:14 step 6: objective=0.140892 reg=0.002079
2017/08/30 15:38:15 step 7: objective=0.141014 reg=0.002079
2017/08/30 15:38:15 Training value function...
2017/08/30 15:38:18 step 0: mse=0.233016 step=0.050000
2017/08/30 15:38:20 step 1: mse=0.231990 step=0.050000
2017/08/30 15:38:21 step 2: mse=0.230737 step=0.050000
2017/08/30 15:38:23 step 3: mse=0.229174 step=0.050000
2017/08/30 15:38:24 step 4: mse=0.227439 step=0.050000
2017/08/30 15:38:25 step 5: mse=0.226640 step=0.050000
2017/08/30 15:38:27 step 6: mse=0.225587 step=0.050000
2017/08/30 15:38:28 step 7: mse=0.224546 step=0.050000
2017/08/30 15:38:28 Saving...
2017/08/30 15:38:28 Gathering batch of experience...
2017/08/30 15:39:06 batch 261: mean=26.105263 stddev=13.388505 entropy=0.206683 frames=7724 count=19
2017/08/30 15:39:06 Training policy...
2017/08/30 15:39:11 tune 0: objective=0.127468 reg=0.002067 prune=0
2017/08/30 15:39:12 step 0: objective=0.127468 reg=0.002067
2017/08/30 15:39:14 step 1: objective=0.127563 reg=0.002067
2017/08/30 15:39:15 step 2: objective=0.127648 reg=0.002067
2017/08/30 15:39:17 step 3: objective=0.127753 reg=0.002067
2017/08/30 15:39:18 step 4: objective=0.127874 reg=0.002067
2017/08/30 15:39:19 step 5: objective=0.127955 reg=0.002067
2017/08/30 15:39:21 step 6: objective=0.128065 reg=0.002066
2017/08/30 15:39:22 step 7: objective=0.128134 reg=0.002067
2017/08/30 15:39:22 Training value function...
2017/08/30 15:39:26 step 0: mse=0.237057 step=0.050000
2017/08/30 15:39:27 step 1: mse=0.237202 step=0.050000
2017/08/30 15:39:28 step 2: mse=0.237464 step=0.050000
2017/08/30 15:39:30 step 3: mse=0.237670 step=0.050000
2017/08/30 15:39:31 step 4: mse=0.237854 step=0.050000
2017/08/30 15:39:32 step 5: mse=0.238125 step=0.050000
2017/08/30 15:39:34 step 6: mse=0.238295 step=0.050000
2017/08/30 15:39:35 step 7: mse=0.238476 step=0.050000
2017/08/30 15:39:35 Saving...
2017/08/30 15:39:35 Gathering batch of experience...
2017/08/30 15:40:14 batch 262: mean=31.588235 stddev=12.180306 entropy=0.206921 frames=8323 count=17
2017/08/30 15:40:14 Training policy...
2017/08/30 15:40:19 tune 0: objective=0.141809 reg=0.002069 prune=0
2017/08/30 15:40:21 step 0: objective=0.141809 reg=0.002069
2017/08/30 15:40:22 step 1: objective=0.141910 reg=0.002070
2017/08/30 15:40:24 step 2: objective=0.141978 reg=0.002069
2017/08/30 15:40:25 step 3: objective=0.142086 reg=0.002069
2017/08/30 15:40:27 step 4: objective=0.142194 reg=0.002070
2017/08/30 15:40:28 step 5: objective=0.142249 reg=0.002069
2017/08/30 15:40:30 step 6: objective=0.142311 reg=0.002068
2017/08/30 15:40:32 step 7: objective=0.142388 reg=0.002068
2017/08/30 15:40:32 Training value function...
2017/08/30 15:40:35 step 0: mse=0.236837 step=0.050000
2017/08/30 15:40:36 step 1: mse=0.235078 step=0.050000
2017/08/30 15:40:38 step 2: mse=0.233206 step=0.050000
2017/08/30 15:40:39 step 3: mse=0.231750 step=0.050000
2017/08/30 15:40:41 step 4: mse=0.231028 step=0.050000
2017/08/30 15:40:42 step 5: mse=0.229763 step=0.050000
2017/08/30 15:40:44 step 6: mse=0.228751 step=0.050000
2017/08/30 15:40:45 step 7: mse=0.227943 step=0.050000
2017/08/30 15:40:45 Saving...
2017/08/30 15:40:45 Gathering batch of experience...
2017/08/30 15:41:22 batch 263: mean=28.470588 stddev=13.703231 entropy=0.203441 frames=7509 count=17
2017/08/30 15:41:22 Training policy...
2017/08/30 15:41:27 tune 0: objective=0.131895 reg=0.002034 prune=0
2017/08/30 15:41:28 step 0: objective=0.131895 reg=0.002034
2017/08/30 15:41:30 step 1: objective=0.131968 reg=0.002035
2017/08/30 15:41:31 step 2: objective=0.132029 reg=0.002034
2017/08/30 15:41:32 step 3: objective=0.132128 reg=0.002034
2017/08/30 15:41:34 step 4: objective=0.132187 reg=0.002033
2017/08/30 15:41:35 step 5: objective=0.132316 reg=0.002032
2017/08/30 15:41:37 step 6: objective=0.132408 reg=0.002031
2017/08/30 15:41:38 step 7: objective=0.132483 reg=0.002031
2017/08/30 15:41:38 Training value function...
2017/08/30 15:41:41 step 0: mse=0.228643 step=0.050000
2017/08/30 15:41:42 step 1: mse=0.228392 step=0.050000
2017/08/30 15:41:44 step 2: mse=0.227846 step=0.050000
2017/08/30 15:41:45 step 3: mse=0.227634 step=0.050000
2017/08/30 15:41:46 step 4: mse=0.226925 step=0.050000
2017/08/30 15:41:48 step 5: mse=0.226519 step=0.050000
2017/08/30 15:41:49 step 6: mse=0.226212 step=0.050000
2017/08/30 15:41:50 step 7: mse=0.225851 step=0.050000
2017/08/30 15:41:50 Saving...
2017/08/30 15:41:50 Gathering batch of experience...
2017/08/30 15:42:29 batch 264: mean=28.166667 stddev=14.036658 entropy=0.211610 frames=7863 count=18
2017/08/30 15:42:29 Training policy...
2017/08/30 15:42:34 tune 0: objective=0.132264 reg=0.002116 prune=0
2017/08/30 15:42:35 step 0: objective=0.132264 reg=0.002116
2017/08/30 15:42:37 step 1: objective=0.132442 reg=0.002114
2017/08/30 15:42:38 step 2: objective=0.132572 reg=0.002113
2017/08/30 15:42:40 step 3: objective=0.132684 reg=0.002112
2017/08/30 15:42:41 step 4: objective=0.132747 reg=0.002111
2017/08/30 15:42:43 step 5: objective=0.132801 reg=0.002111
2017/08/30 15:42:44 step 6: objective=0.132925 reg=0.002109
2017/08/30 15:42:46 step 7: objective=0.132998 reg=0.002107
2017/08/30 15:42:46 Training value function...
2017/08/30 15:42:49 step 0: mse=0.222240 step=0.050000
2017/08/30 15:42:50 step 1: mse=0.221693 step=0.050000
2017/08/30 15:42:52 step 2: mse=0.221434 step=0.050000
2017/08/30 15:42:53 step 3: mse=0.220790 step=0.050000
2017/08/30 15:42:54 step 4: mse=0.220627 step=0.050000
2017/08/30 15:42:56 step 5: mse=0.220673 step=0.050000
2017/08/30 15:42:57 step 6: mse=0.220420 step=0.050000
2017/08/30 15:42:59 step 7: mse=0.220363 step=0.050000
2017/08/30 15:42:59 Saving...
2017/08/30 15:42:59 Gathering batch of experience...
2017/08/30 15:43:35 batch 265: mean=31.133333 stddev=13.380915 entropy=0.206288 frames=7196 count=15
2017/08/30 15:43:35 Training policy...
2017/08/30 15:43:40 tune 0: objective=0.141486 reg=0.002063 prune=0
2017/08/30 15:43:41 step 0: objective=0.141487 reg=0.002063
2017/08/30 15:43:42 step 1: objective=0.141631 reg=0.002063
2017/08/30 15:43:44 step 2: objective=0.141730 reg=0.002063
2017/08/30 15:43:45 step 3: objective=0.141896 reg=0.002064
2017/08/30 15:43:46 step 4: objective=0.142007 reg=0.002064
2017/08/30 15:43:48 step 5: objective=0.142078 reg=0.002064
2017/08/30 15:43:49 step 6: objective=0.142134 reg=0.002065
2017/08/30 15:43:50 step 7: objective=0.142174 reg=0.002065
2017/08/30 15:43:50 Training value function...
2017/08/30 15:43:53 step 0: mse=0.223308 step=0.050000
2017/08/30 15:43:55 step 1: mse=0.221512 step=0.050000
2017/08/30 15:43:56 step 2: mse=0.220335 step=0.050000
2017/08/30 15:43:57 step 3: mse=0.218960 step=0.050000
2017/08/30 15:43:58 step 4: mse=0.217679 step=0.050000
2017/08/30 15:43:59 step 5: mse=0.216298 step=0.050000
2017/08/30 15:44:01 step 6: mse=0.214751 step=0.050000
2017/08/30 15:44:02 step 7: mse=0.213418 step=0.050000
2017/08/30 15:44:02 Saving...
2017/08/30 15:44:02 Gathering batch of experience...
2017/08/30 15:44:43 batch 266: mean=23.869565 stddev=16.181859 entropy=0.206239 frames=8502 count=23
2017/08/30 15:44:43 Training policy...
2017/08/30 15:44:48 tune 0: objective=0.122395 reg=0.002062 prune=0
2017/08/30 15:44:50 step 0: objective=0.122395 reg=0.002062
2017/08/30 15:44:51 step 1: objective=0.122554 reg=0.002062
2017/08/30 15:44:53 step 2: objective=0.122642 reg=0.002062
2017/08/30 15:44:54 step 3: objective=0.122728 reg=0.002061
2017/08/30 15:44:56 step 4: objective=0.122814 reg=0.002062
2017/08/30 15:44:57 step 5: objective=0.122874 reg=0.002062
2017/08/30 15:44:59 step 6: objective=0.122914 reg=0.002061
2017/08/30 15:45:01 step 7: objective=0.122986 reg=0.002061
2017/08/30 15:45:01 Training value function...
2017/08/30 15:45:04 step 0: mse=0.213020 step=0.050000
2017/08/30 15:45:06 step 1: mse=0.213591 step=0.050000
2017/08/30 15:45:07 step 2: mse=0.214034 step=0.050000
2017/08/30 15:45:09 step 3: mse=0.214336 step=0.050000
2017/08/30 15:45:10 step 4: mse=0.214717 step=0.050000
2017/08/30 15:45:12 step 5: mse=0.215108 step=0.050000
2017/08/30 15:45:13 step 6: mse=0.215570 step=0.050000
2017/08/30 15:45:15 step 7: mse=0.215621 step=0.050000
2017/08/30 15:45:15 Saving...
2017/08/30 15:45:15 Gathering batch of experience...
2017/08/30 15:45:55 batch 267: mean=27.315789 stddev=14.487936 entropy=0.205819 frames=8047 count=19
2017/08/30 15:45:55 Training policy...
2017/08/30 15:45:59 tune 0: objective=0.129487 reg=0.002058 prune=0
2017/08/30 15:46:01 step 0: objective=0.129487 reg=0.002058
2017/08/30 15:46:02 step 1: objective=0.129568 reg=0.002059
2017/08/30 15:46:04 step 2: objective=0.129722 reg=0.002059
2017/08/30 15:46:05 step 3: objective=0.129848 reg=0.002059
2017/08/30 15:46:07 step 4: objective=0.129967 reg=0.002058
2017/08/30 15:46:08 step 5: objective=0.130048 reg=0.002057
2017/08/30 15:46:10 step 6: objective=0.130150 reg=0.002057
2017/08/30 15:46:11 step 7: objective=0.130231 reg=0.002058
2017/08/30 15:46:11 Training value function...
2017/08/30 15:46:15 step 0: mse=0.222554 step=0.050000
2017/08/30 15:46:16 step 1: mse=0.222531 step=0.050000
2017/08/30 15:46:18 step 2: mse=0.222824 step=0.050000
2017/08/30 15:46:19 step 3: mse=0.222671 step=0.050000
2017/08/30 15:46:21 step 4: mse=0.222700 step=0.050000
2017/08/30 15:46:22 step 5: mse=0.223006 step=0.050000
2017/08/30 15:46:23 step 6: mse=0.222912 step=0.050000
2017/08/30 15:46:25 step 7: mse=0.223105 step=0.050000
2017/08/30 15:46:25 Saving...
2017/08/30 15:46:25 Gathering batch of experience...
2017/08/30 15:47:07 batch 268: mean=26.238095 stddev=13.634357 entropy=0.210456 frames=8552 count=21
2017/08/30 15:47:07 Training policy...
2017/08/30 15:47:12 tune 0: objective=0.124752 reg=0.002105 prune=0
2017/08/30 15:47:14 step 0: objective=0.124752 reg=0.002105
2017/08/30 15:47:15 step 1: objective=0.124821 reg=0.002104
2017/08/30 15:47:17 step 2: objective=0.124902 reg=0.002104
2017/08/30 15:47:18 step 3: objective=0.124970 reg=0.002103
2017/08/30 15:47:20 step 4: objective=0.125122 reg=0.002103
2017/08/30 15:47:22 step 5: objective=0.125162 reg=0.002103
2017/08/30 15:47:23 step 6: objective=0.125295 reg=0.002104
2017/08/30 15:47:25 step 7: objective=0.125416 reg=0.002105
2017/08/30 15:47:25 Training value function...
2017/08/30 15:47:28 step 0: mse=0.225124 step=0.050000
2017/08/30 15:47:30 step 1: mse=0.225259 step=0.050000
2017/08/30 15:47:31 step 2: mse=0.225713 step=0.050000
2017/08/30 15:47:33 step 3: mse=0.226036 step=0.050000
2017/08/30 15:47:34 step 4: mse=0.226433 step=0.050000
2017/08/30 15:47:36 step 5: mse=0.226897 step=0.050000
2017/08/30 15:47:37 step 6: mse=0.227224 step=0.050000
2017/08/30 15:47:39 step 7: mse=0.227601 step=0.050000
2017/08/30 15:47:39 Saving...
2017/08/30 15:47:39 Gathering batch of experience...
2017/08/30 15:48:16 batch 269: mean=29.470588 stddev=12.825148 entropy=0.208686 frames=7746 count=17
2017/08/30 15:48:16 Training policy...
2017/08/30 15:48:21 tune 0: objective=0.134409 reg=0.002087 prune=0
2017/08/30 15:48:22 step 0: objective=0.134410 reg=0.002087
2017/08/30 15:48:24 step 1: objective=0.134504 reg=0.002087
2017/08/30 15:48:25 step 2: objective=0.134600 reg=0.002088
2017/08/30 15:48:27 step 3: objective=0.134718 reg=0.002089
2017/08/30 15:48:28 step 4: objective=0.134824 reg=0.002090
2017/08/30 15:48:30 step 5: objective=0.134921 reg=0.002090
2017/08/30 15:48:31 step 6: objective=0.134976 reg=0.002090
2017/08/30 15:48:32 step 7: objective=0.135040 reg=0.002089
2017/08/30 15:48:32 Training value function...
2017/08/30 15:48:36 step 0: mse=0.223417 step=0.050000
2017/08/30 15:48:37 step 1: mse=0.222576 step=0.050000
2017/08/30 15:48:38 step 2: mse=0.221763 step=0.050000
2017/08/30 15:48:40 step 3: mse=0.220895 step=0.050000
2017/08/30 15:48:41 step 4: mse=0.220197 step=0.050000
2017/08/30 15:48:42 step 5: mse=0.219658 step=0.050000
2017/08/30 15:48:44 step 6: mse=0.219218 step=0.050000
2017/08/30 15:48:45 step 7: mse=0.218883 step=0.050000
2017/08/30 15:48:45 Saving...
2017/08/30 15:48:45 Gathering batch of experience...
2017/08/30 15:49:23 batch 270: mean=34.400000 stddev=10.657079 entropy=0.201295 frames=7942 count=15
2017/08/30 15:49:23 Training policy...
2017/08/30 15:49:28 tune 0: objective=0.144028 reg=0.002013 prune=0
2017/08/30 15:49:29 step 0: objective=0.144028 reg=0.002013
2017/08/30 15:49:31 step 1: objective=0.144142 reg=0.002014
2017/08/30 15:49:32 step 2: objective=0.144324 reg=0.002015
2017/08/30 15:49:34 step 3: objective=0.144418 reg=0.002015
2017/08/30 15:49:35 step 4: objective=0.144570 reg=0.002016
2017/08/30 15:49:37 step 5: objective=0.144687 reg=0.002017
2017/08/30 15:49:38 step 6: objective=0.144798 reg=0.002015
2017/08/30 15:49:40 step 7: objective=0.144915 reg=0.002015
2017/08/30 15:49:40 Training value function...
2017/08/30 15:49:43 step 0: mse=0.214487 step=0.050000
2017/08/30 15:49:45 step 1: mse=0.212829 step=0.050000
2017/08/30 15:49:46 step 2: mse=0.211221 step=0.050000
2017/08/30 15:49:47 step 3: mse=0.209148 step=0.050000
2017/08/30 15:49:49 step 4: mse=0.207664 step=0.050000
2017/08/30 15:49:50 step 5: mse=0.206383 step=0.050000
2017/08/30 15:49:51 step 6: mse=0.205055 step=0.050000
2017/08/30 15:49:53 step 7: mse=0.203586 step=0.050000
2017/08/30 15:49:53 Saving...
2017/08/30 15:49:53 Gathering batch of experience...
2017/08/30 15:50:30 batch 271: mean=24.684211 stddev=12.333321 entropy=0.209065 frames=7288 count=19
2017/08/30 15:50:30 Training policy...
2017/08/30 15:50:34 tune 0: objective=0.113153 reg=0.002091 prune=0
2017/08/30 15:50:36 step 0: objective=0.113154 reg=0.002091
2017/08/30 15:50:37 step 1: objective=0.113257 reg=0.002091
2017/08/30 15:50:38 step 2: objective=0.113348 reg=0.002090
2017/08/30 15:50:40 step 3: objective=0.113445 reg=0.002090
2017/08/30 15:50:41 step 4: objective=0.113519 reg=0.002089
2017/08/30 15:50:43 step 5: objective=0.113589 reg=0.002089
2017/08/30 15:50:44 step 6: objective=0.113641 reg=0.002088
2017/08/30 15:50:45 step 7: objective=0.113735 reg=0.002087
2017/08/30 15:50:45 Training value function...
2017/08/30 15:50:48 step 0: mse=0.212291 step=0.050000
2017/08/30 15:50:50 step 1: mse=0.213424 step=0.050000
2017/08/30 15:50:51 step 2: mse=0.214431 step=0.050000
2017/08/30 15:50:52 step 3: mse=0.215178 step=0.050000
2017/08/30 15:50:53 step 4: mse=0.216054 step=0.050000
2017/08/30 15:50:55 step 5: mse=0.217044 step=0.050000
2017/08/30 15:50:56 step 6: mse=0.217988 step=0.050000
2017/08/30 15:50:57 step 7: mse=0.218709 step=0.050000
2017/08/30 15:50:57 Saving...
2017/08/30 15:50:57 Gathering batch of experience...
2017/08/30 15:51:36 batch 272: mean=22.761905 stddev=14.761290 entropy=0.208043 frames=7421 count=21
2017/08/30 15:51:36 Training policy...
2017/08/30 15:51:41 tune 0: objective=0.119606 reg=0.002080 prune=0
2017/08/30 15:51:42 step 0: objective=0.119606 reg=0.002080
2017/08/30 15:51:43 step 1: objective=0.119702 reg=0.002081
2017/08/30 15:51:45 step 2: objective=0.119811 reg=0.002081
2017/08/30 15:51:46 step 3: objective=0.119887 reg=0.002081
2017/08/30 15:51:48 step 4: objective=0.120005 reg=0.002081
2017/08/30 15:51:49 step 5: objective=0.120086 reg=0.002080
2017/08/30 15:51:50 step 6: objective=0.120173 reg=0.002080
2017/08/30 15:51:52 step 7: objective=0.120249 reg=0.002079
2017/08/30 15:51:52 Training value function...
2017/08/30 15:51:55 step 0: mse=0.223924 step=0.050000
2017/08/30 15:51:56 step 1: mse=0.224697 step=0.050000
2017/08/30 15:51:57 step 2: mse=0.225488 step=0.050000
2017/08/30 15:51:59 step 3: mse=0.226256 step=0.050000
2017/08/30 15:52:00 step 4: mse=0.226995 step=0.050000
2017/08/30 15:52:01 step 5: mse=0.227475 step=0.050000
2017/08/30 15:52:03 step 6: mse=0.227874 step=0.050000
2017/08/30 15:52:04 step 7: mse=0.228621 step=0.050000
2017/08/30 15:52:04 Saving...
2017/08/30 15:52:04 Gathering batch of experience...
2017/08/30 15:52:43 batch 273: mean=26.150000 stddev=15.034211 entropy=0.202045 frames=8122 count=20
2017/08/30 15:52:43 Training policy...
2017/08/30 15:52:48 tune 0: objective=0.132302 reg=0.002020 prune=0
2017/08/30 15:52:50 step 0: objective=0.132302 reg=0.002020
2017/08/30 15:52:51 step 1: objective=0.132452 reg=0.002019
2017/08/30 15:52:53 step 2: objective=0.132570 reg=0.002018
2017/08/30 15:52:54 step 3: objective=0.132679 reg=0.002017
2017/08/30 15:52:56 step 4: objective=0.132795 reg=0.002016
2017/08/30 15:52:57 step 5: objective=0.132915 reg=0.002015
2017/08/30 15:52:59 step 6: objective=0.132969 reg=0.002015
2017/08/30 15:53:00 step 7: objective=0.133090 reg=0.002013
2017/08/30 15:53:00 Training value function...
2017/08/30 15:53:04 step 0: mse=0.234557 step=0.050000
2017/08/30 15:53:05 step 1: mse=0.234012 step=0.050000
2017/08/30 15:53:06 step 2: mse=0.233848 step=0.050000
2017/08/30 15:53:08 step 3: mse=0.233481 step=0.050000
2017/08/30 15:53:09 step 4: mse=0.233091 step=0.050000
2017/08/30 15:53:11 step 5: mse=0.232906 step=0.050000
2017/08/30 15:53:12 step 6: mse=0.232635 step=0.050000
2017/08/30 15:53:14 step 7: mse=0.232274 step=0.050000
2017/08/30 15:53:14 Saving...
2017/08/30 15:53:14 Gathering batch of experience...
2017/08/30 15:53:52 batch 274: mean=32.062500 stddev=11.087542 entropy=0.203793 frames=7950 count=16
2017/08/30 15:53:52 Training policy...
2017/08/30 15:53:57 tune 0: objective=0.136926 reg=0.002038 prune=0
2017/08/30 15:53:58 step 0: objective=0.136927 reg=0.002038
2017/08/30 15:54:00 step 1: objective=0.137062 reg=0.002038
2017/08/30 15:54:01 step 2: objective=0.137176 reg=0.002036
2017/08/30 15:54:03 step 3: objective=0.137306 reg=0.002035
2017/08/30 15:54:04 step 4: objective=0.137446 reg=0.002034
2017/08/30 15:54:06 step 5: objective=0.137496 reg=0.002034
2017/08/30 15:54:07 step 6: objective=0.137605 reg=0.002032
2017/08/30 15:54:09 step 7: objective=0.137716 reg=0.002032
2017/08/30 15:54:09 Training value function...
2017/08/30 15:54:12 step 0: mse=0.228670 step=0.050000
2017/08/30 15:54:13 step 1: mse=0.227452 step=0.050000
2017/08/30 15:54:15 step 2: mse=0.226271 step=0.050000
2017/08/30 15:54:16 step 3: mse=0.225063 step=0.050000
2017/08/30 15:54:17 step 4: mse=0.224218 step=0.050000
2017/08/30 15:54:19 step 5: mse=0.223322 step=0.050000
2017/08/30 15:54:20 step 6: mse=0.222226 step=0.050000
2017/08/30 15:54:22 step 7: mse=0.221006 step=0.050000
2017/08/30 15:54:22 Saving...
2017/08/30 15:54:22 Gathering batch of experience...
2017/08/30 15:55:02 batch 275: mean=27.736842 stddev=11.275694 entropy=0.201079 frames=8171 count=19
2017/08/30 15:55:02 Training policy...
2017/08/30 15:55:07 tune 0: objective=0.126231 reg=0.002011 prune=0
2017/08/30 15:55:09 step 0: objective=0.126231 reg=0.002011
2017/08/30 15:55:10 step 1: objective=0.126367 reg=0.002011
2017/08/30 15:55:12 step 2: objective=0.126473 reg=0.002010
2017/08/30 15:55:13 step 3: objective=0.126561 reg=0.002009
2017/08/30 15:55:15 step 4: objective=0.126736 reg=0.002009
2017/08/30 15:55:16 step 5: objective=0.126866 reg=0.002008
2017/08/30 15:55:18 step 6: objective=0.126968 reg=0.002008
2017/08/30 15:55:20 step 7: objective=0.127041 reg=0.002008
2017/08/30 15:55:20 Training value function...
2017/08/30 15:55:23 step 0: mse=0.221797 step=0.050000
2017/08/30 15:55:24 step 1: mse=0.222261 step=0.050000
2017/08/30 15:55:26 step 2: mse=0.222736 step=0.050000
2017/08/30 15:55:27 step 3: mse=0.222822 step=0.050000
2017/08/30 15:55:29 step 4: mse=0.223019 step=0.050000
2017/08/30 15:55:30 step 5: mse=0.223366 step=0.050000
2017/08/30 15:55:32 step 6: mse=0.223459 step=0.050000
2017/08/30 15:55:33 step 7: mse=0.223908 step=0.050000
2017/08/30 15:55:33 Saving...
2017/08/30 15:55:33 Gathering batch of experience...
2017/08/30 15:56:11 batch 276: mean=30.312500 stddev=11.345256 entropy=0.194058 frames=7520 count=16
2017/08/30 15:56:11 Training policy...
2017/08/30 15:56:15 tune 0: objective=0.135857 reg=0.001941 prune=0
2017/08/30 15:56:17 step 0: objective=0.135858 reg=0.001941
2017/08/30 15:56:18 step 1: objective=0.135968 reg=0.001939
2017/08/30 15:56:19 step 2: objective=0.136111 reg=0.001938
2017/08/30 15:56:21 step 3: objective=0.136256 reg=0.001937
2017/08/30 15:56:22 step 4: objective=0.136364 reg=0.001937
2017/08/30 15:56:24 step 5: objective=0.136443 reg=0.001937
2017/08/30 15:56:25 step 6: objective=0.136511 reg=0.001936
2017/08/30 15:56:26 step 7: objective=0.136598 reg=0.001937
2017/08/30 15:56:26 Training value function...
2017/08/30 15:56:29 step 0: mse=0.232537 step=0.050000
2017/08/30 15:56:31 step 1: mse=0.231143 step=0.050000
2017/08/30 15:56:32 step 2: mse=0.230406 step=0.050000
2017/08/30 15:56:33 step 3: mse=0.229883 step=0.050000
2017/08/30 15:56:35 step 4: mse=0.229008 step=0.050000
2017/08/30 15:56:36 step 5: mse=0.228587 step=0.050000
2017/08/30 15:56:37 step 6: mse=0.227890 step=0.050000
2017/08/30 15:56:39 step 7: mse=0.227333 step=0.050000
2017/08/30 15:56:39 Saving...
2017/08/30 15:56:39 Gathering batch of experience...
2017/08/30 15:57:17 batch 277: mean=27.315789 stddev=11.525955 entropy=0.201519 frames=8049 count=19
2017/08/30 15:57:17 Training policy...
2017/08/30 15:57:22 tune 0: objective=0.127916 reg=0.002015 prune=0
2017/08/30 15:57:24 step 0: objective=0.127916 reg=0.002015
2017/08/30 15:57:25 step 1: objective=0.127985 reg=0.002015
2017/08/30 15:57:27 step 2: objective=0.128067 reg=0.002016
2017/08/30 15:57:28 step 3: objective=0.128138 reg=0.002016
2017/08/30 15:57:30 step 4: objective=0.128210 reg=0.002017
2017/08/30 15:57:31 step 5: objective=0.128277 reg=0.002018
2017/08/30 15:57:33 step 6: objective=0.128438 reg=0.002019
2017/08/30 15:57:34 step 7: objective=0.128574 reg=0.002019
2017/08/30 15:57:34 Training value function...
2017/08/30 15:57:38 step 0: mse=0.221906 step=0.050000
2017/08/30 15:57:39 step 1: mse=0.221859 step=0.050000
2017/08/30 15:57:41 step 2: mse=0.221715 step=0.050000
2017/08/30 15:57:42 step 3: mse=0.221717 step=0.050000
2017/08/30 15:57:43 step 4: mse=0.221738 step=0.050000
2017/08/30 15:57:45 step 5: mse=0.221782 step=0.050000
2017/08/30 15:57:46 step 6: mse=0.221847 step=0.050000
2017/08/30 15:57:48 step 7: mse=0.221749 step=0.050000
2017/08/30 15:57:48 Saving...
2017/08/30 15:57:48 Gathering batch of experience...
2017/08/30 15:58:25 batch 278: mean=32.733333 stddev=9.629584 entropy=0.197351 frames=7601 count=15
2017/08/30 15:58:25 Training policy...
2017/08/30 15:58:30 tune 0: objective=0.138775 reg=0.001974 prune=0
2017/08/30 15:58:31 step 0: objective=0.138775 reg=0.001974
2017/08/30 15:58:33 step 1: objective=0.138849 reg=0.001974
2017/08/30 15:58:34 step 2: objective=0.138900 reg=0.001974
2017/08/30 15:58:36 step 3: objective=0.138963 reg=0.001974
2017/08/30 15:58:37 step 4: objective=0.139039 reg=0.001973
2017/08/30 15:58:38 step 5: objective=0.139117 reg=0.001974
2017/08/30 15:58:40 step 6: objective=0.139166 reg=0.001974
2017/08/30 15:58:41 step 7: objective=0.139293 reg=0.001974
2017/08/30 15:58:41 Training value function...
2017/08/30 15:58:44 step 0: mse=0.229236 step=0.050000
2017/08/30 15:58:46 step 1: mse=0.228174 step=0.050000
2017/08/30 15:58:47 step 2: mse=0.227103 step=0.050000
2017/08/30 15:58:48 step 3: mse=0.226048 step=0.050000
2017/08/30 15:58:50 step 4: mse=0.224836 step=0.050000
2017/08/30 15:58:51 step 5: mse=0.224130 step=0.050000
2017/08/30 15:58:52 step 6: mse=0.223290 step=0.050000
2017/08/30 15:58:54 step 7: mse=0.222565 step=0.050000
2017/08/30 15:58:54 Saving...
2017/08/30 15:58:54 Gathering batch of experience...
2017/08/30 15:59:34 batch 279: mean=27.052632 stddev=12.496204 entropy=0.201388 frames=7997 count=19
2017/08/30 15:59:34 Training policy...
2017/08/30 15:59:39 tune 0: objective=0.122222 reg=0.002014 prune=0
2017/08/30 15:59:41 step 0: objective=0.122223 reg=0.002014
2017/08/30 15:59:42 step 1: objective=0.122304 reg=0.002014
2017/08/30 15:59:44 step 2: objective=0.122404 reg=0.002015
2017/08/30 15:59:45 step 3: objective=0.122488 reg=0.002015
2017/08/30 15:59:47 step 4: objective=0.122626 reg=0.002016
2017/08/30 15:59:48 step 5: objective=0.122741 reg=0.002016
2017/08/30 15:59:50 step 6: objective=0.122872 reg=0.002016
2017/08/30 15:59:51 step 7: objective=0.122941 reg=0.002016
2017/08/30 15:59:51 Training value function...
2017/08/30 15:59:55 step 0: mse=0.228045 step=0.050000
2017/08/30 15:59:56 step 1: mse=0.228285 step=0.050000
2017/08/30 15:59:57 step 2: mse=0.228860 step=0.050000
2017/08/30 15:59:59 step 3: mse=0.229701 step=0.050000
2017/08/30 16:00:00 step 4: mse=0.230022 step=0.050000
2017/08/30 16:00:02 step 5: mse=0.230622 step=0.050000
2017/08/30 16:00:03 step 6: mse=0.231181 step=0.050000
2017/08/30 16:00:04 step 7: mse=0.231783 step=0.050000
2017/08/30 16:00:04 Saving...
2017/08/30 16:00:04 Gathering batch of experience...
2017/08/30 16:00:45 batch 280: mean=28.000000 stddev=13.905697 entropy=0.199590 frames=8259 count=19
2017/08/30 16:00:45 Training policy...
2017/08/30 16:00:50 tune 0: objective=0.131615 reg=0.001996 prune=0
2017/08/30 16:00:51 step 0: objective=0.131615 reg=0.001996
2017/08/30 16:00:53 step 1: objective=0.131677 reg=0.001996
2017/08/30 16:00:54 step 2: objective=0.131776 reg=0.001996
2017/08/30 16:00:56 step 3: objective=0.131826 reg=0.001995
2017/08/30 16:00:58 step 4: objective=0.131891 reg=0.001995
2017/08/30 16:00:59 step 5: objective=0.132049 reg=0.001995
2017/08/30 16:01:01 step 6: objective=0.132120 reg=0.001995
2017/08/30 16:01:02 step 7: objective=0.132184 reg=0.001995
2017/08/30 16:01:02 Training value function...
2017/08/30 16:01:06 step 0: mse=0.236816 step=0.050000
2017/08/30 16:01:07 step 1: mse=0.236150 step=0.050000
2017/08/30 16:01:09 step 2: mse=0.234981 step=0.050000
2017/08/30 16:01:10 step 3: mse=0.234400 step=0.050000
2017/08/30 16:01:11 step 4: mse=0.233895 step=0.050000
2017/08/30 16:01:13 step 5: mse=0.233092 step=0.050000
2017/08/30 16:01:14 step 6: mse=0.233045 step=0.050000
2017/08/30 16:01:16 step 7: mse=0.232637 step=0.050000
2017/08/30 16:01:16 Saving...
2017/08/30 16:01:16 Gathering batch of experience...
2017/08/30 16:01:55 batch 281: mean=32.812500 stddev=7.592914 entropy=0.202135 frames=8138 count=16
2017/08/30 16:01:55 Training policy...
2017/08/30 16:02:00 tune 0: objective=0.135233 reg=0.002021 prune=0
2017/08/30 16:02:01 step 0: objective=0.135233 reg=0.002021
2017/08/30 16:02:03 step 1: objective=0.135277 reg=0.002021
2017/08/30 16:02:04 step 2: objective=0.135340 reg=0.002021
2017/08/30 16:02:06 step 3: objective=0.135415 reg=0.002022
2017/08/30 16:02:07 step 4: objective=0.135469 reg=0.002021
2017/08/30 16:02:09 step 5: objective=0.135556 reg=0.002020
2017/08/30 16:02:10 step 6: objective=0.135635 reg=0.002020
2017/08/30 16:02:12 step 7: objective=0.135803 reg=0.002020
2017/08/30 16:02:12 Training value function...
2017/08/30 16:02:15 step 0: mse=0.226540 step=0.050000
2017/08/30 16:02:17 step 1: mse=0.225628 step=0.050000
2017/08/30 16:02:18 step 2: mse=0.224992 step=0.050000
2017/08/30 16:02:19 step 3: mse=0.224225 step=0.050000
2017/08/30 16:02:21 step 4: mse=0.223593 step=0.050000
2017/08/30 16:02:22 step 5: mse=0.222940 step=0.050000
2017/08/30 16:02:24 step 6: mse=0.222420 step=0.050000
2017/08/30 16:02:25 step 7: mse=0.221774 step=0.050000
2017/08/30 16:02:25 Saving...
2017/08/30 16:02:25 Gathering batch of experience...
2017/08/30 16:03:04 batch 282: mean=23.619048 stddev=13.761493 entropy=0.202965 frames=7717 count=21
2017/08/30 16:03:04 Training policy...
2017/08/30 16:03:08 tune 0: objective=0.116925 reg=0.002030 prune=0
2017/08/30 16:03:10 step 0: objective=0.116925 reg=0.002030
2017/08/30 16:03:11 step 1: objective=0.117066 reg=0.002030
2017/08/30 16:03:13 step 2: objective=0.117128 reg=0.002029
2017/08/30 16:03:14 step 3: objective=0.117229 reg=0.002028
2017/08/30 16:03:16 step 4: objective=0.117353 reg=0.002028
2017/08/30 16:03:17 step 5: objective=0.117493 reg=0.002028
2017/08/30 16:03:18 step 6: objective=0.117559 reg=0.002028
2017/08/30 16:03:20 step 7: objective=0.117736 reg=0.002028
2017/08/30 16:03:20 Training value function...
2017/08/30 16:03:23 step 0: mse=0.227326 step=0.050000
2017/08/30 16:03:24 step 1: mse=0.228202 step=0.050000
2017/08/30 16:03:26 step 2: mse=0.228713 step=0.050000
2017/08/30 16:03:27 step 3: mse=0.229047 step=0.050000
2017/08/30 16:03:29 step 4: mse=0.229431 step=0.050000
2017/08/30 16:03:30 step 5: mse=0.230078 step=0.050000
2017/08/30 16:03:31 step 6: mse=0.230509 step=0.050000
2017/08/30 16:03:33 step 7: mse=0.231184 step=0.050000
2017/08/30 16:03:33 Saving...
2017/08/30 16:03:33 Gathering batch of experience...
2017/08/30 16:04:09 batch 283: mean=27.812500 stddev=14.444803 entropy=0.199378 frames=6899 count=16
2017/08/30 16:04:09 Training policy...
2017/08/30 16:04:13 tune 0: objective=0.134566 reg=0.001994 prune=0
2017/08/30 16:04:14 step 0: objective=0.134566 reg=0.001994
2017/08/30 16:04:16 step 1: objective=0.134753 reg=0.001996
2017/08/30 16:04:17 step 2: objective=0.134977 reg=0.001997
2017/08/30 16:04:18 step 3: objective=0.135198 reg=0.001999
2017/08/30 16:04:20 step 4: objective=0.135295 reg=0.001999
2017/08/30 16:04:21 step 5: objective=0.135381 reg=0.001999
2017/08/30 16:04:22 step 6: objective=0.135443 reg=0.001999
2017/08/30 16:04:23 step 7: objective=0.135569 reg=0.002000
2017/08/30 16:04:23 Training value function...
2017/08/30 16:04:26 step 0: mse=0.237586 step=0.050000
2017/08/30 16:04:28 step 1: mse=0.236311 step=0.050000
2017/08/30 16:04:29 step 2: mse=0.235622 step=0.050000
2017/08/30 16:04:30 step 3: mse=0.234962 step=0.050000
2017/08/30 16:04:31 step 4: mse=0.234113 step=0.050000
2017/08/30 16:04:32 step 5: mse=0.233345 step=0.050000
2017/08/30 16:04:33 step 6: mse=0.232725 step=0.050000
2017/08/30 16:04:35 step 7: mse=0.232199 step=0.050000
2017/08/30 16:04:35 Saving...
2017/08/30 16:04:35 Gathering batch of experience...
2017/08/30 16:05:15 batch 284: mean=28.105263 stddev=13.270048 entropy=0.199442 frames=8264 count=19
2017/08/30 16:05:15 Training policy...
2017/08/30 16:05:20 tune 0: objective=0.136109 reg=0.001994 prune=0
2017/08/30 16:05:22 step 0: objective=0.136109 reg=0.001994
2017/08/30 16:05:23 step 1: objective=0.136235 reg=0.001995
2017/08/30 16:05:25 step 2: objective=0.136309 reg=0.001995
2017/08/30 16:05:26 step 3: objective=0.136410 reg=0.001995
2017/08/30 16:05:28 step 4: objective=0.136533 reg=0.001995
2017/08/30 16:05:29 step 5: objective=0.136632 reg=0.001993
2017/08/30 16:05:31 step 6: objective=0.136723 reg=0.001993
2017/08/30 16:05:32 step 7: objective=0.136834 reg=0.001991
2017/08/30 16:05:32 Training value function...
2017/08/30 16:05:36 step 0: mse=0.229881 step=0.050000
2017/08/30 16:05:37 step 1: mse=0.228950 step=0.050000
2017/08/30 16:05:39 step 2: mse=0.228372 step=0.050000
2017/08/30 16:05:40 step 3: mse=0.227885 step=0.050000
2017/08/30 16:05:42 step 4: mse=0.227358 step=0.050000
2017/08/30 16:05:43 step 5: mse=0.226654 step=0.050000
2017/08/30 16:05:45 step 6: mse=0.226323 step=0.050000
2017/08/30 16:05:46 step 7: mse=0.226196 step=0.050000
2017/08/30 16:05:46 Saving...
2017/08/30 16:05:46 Gathering batch of experience...
2017/08/30 16:06:23 batch 285: mean=25.888889 stddev=12.364325 entropy=0.205046 frames=7252 count=18
2017/08/30 16:06:23 Training policy...
2017/08/30 16:06:28 tune 0: objective=0.122624 reg=0.002050 prune=0
2017/08/30 16:06:29 step 0: objective=0.122624 reg=0.002050
2017/08/30 16:06:30 step 1: objective=0.122748 reg=0.002050
2017/08/30 16:06:32 step 2: objective=0.122862 reg=0.002050
2017/08/30 16:06:33 step 3: objective=0.122991 reg=0.002050
2017/08/30 16:06:34 step 4: objective=0.123096 reg=0.002049
2017/08/30 16:06:36 step 5: objective=0.123176 reg=0.002049
2017/08/30 16:06:37 step 6: objective=0.123272 reg=0.002048
2017/08/30 16:06:38 step 7: objective=0.123362 reg=0.002047
2017/08/30 16:06:38 Training value function...
2017/08/30 16:06:41 step 0: mse=0.229207 step=0.050000
2017/08/30 16:06:43 step 1: mse=0.229634 step=0.050000
2017/08/30 16:06:44 step 2: mse=0.230449 step=0.050000
2017/08/30 16:06:45 step 3: mse=0.230890 step=0.050000
2017/08/30 16:06:47 step 4: mse=0.231411 step=0.050000
2017/08/30 16:06:48 step 5: mse=0.231748 step=0.050000
2017/08/30 16:06:49 step 6: mse=0.231798 step=0.050000
2017/08/30 16:06:50 step 7: mse=0.231993 step=0.050000
2017/08/30 16:06:50 Saving...
2017/08/30 16:06:50 Gathering batch of experience...
2017/08/30 16:07:29 batch 286: mean=33.125000 stddev=10.154279 entropy=0.197684 frames=8184 count=16
2017/08/30 16:07:29 Training policy...
2017/08/30 16:07:34 tune 0: objective=0.143691 reg=0.001977 prune=0
2017/08/30 16:07:36 step 0: objective=0.143691 reg=0.001977
2017/08/30 16:07:37 step 1: objective=0.143809 reg=0.001977
2017/08/30 16:07:39 step 2: objective=0.143880 reg=0.001978
2017/08/30 16:07:41 step 3: objective=0.143932 reg=0.001978
2017/08/30 16:07:42 step 4: objective=0.144072 reg=0.001979
2017/08/30 16:07:44 step 5: objective=0.144216 reg=0.001979
2017/08/30 16:07:45 step 6: objective=0.144306 reg=0.001980
2017/08/30 16:07:47 step 7: objective=0.144361 reg=0.001980
2017/08/30 16:07:47 Training value function...
2017/08/30 16:07:50 step 0: mse=0.226317 step=0.050000
2017/08/30 16:07:52 step 1: mse=0.224408 step=0.050000
2017/08/30 16:07:53 step 2: mse=0.222267 step=0.050000
2017/08/30 16:07:54 step 3: mse=0.220579 step=0.050000
2017/08/30 16:07:56 step 4: mse=0.218835 step=0.050000
2017/08/30 16:07:57 step 5: mse=0.217386 step=0.050000
2017/08/30 16:07:59 step 6: mse=0.216389 step=0.050000
2017/08/30 16:08:00 step 7: mse=0.214805 step=0.050000
2017/08/30 16:08:00 Saving...
2017/08/30 16:08:00 Gathering batch of experience...
2017/08/30 16:08:37 batch 287: mean=29.562500 stddev=13.100423 entropy=0.201657 frames=7347 count=16
2017/08/30 16:08:37 Training policy...
2017/08/30 16:08:41 tune 0: objective=0.130575 reg=0.002017 prune=0
2017/08/30 16:08:43 step 0: objective=0.130575 reg=0.002017
2017/08/30 16:08:44 step 1: objective=0.130753 reg=0.002018
2017/08/30 16:08:46 step 2: objective=0.130855 reg=0.002018
2017/08/30 16:08:47 step 3: objective=0.130985 reg=0.002019
2017/08/30 16:08:48 step 4: objective=0.131128 reg=0.002020
2017/08/30 16:08:50 step 5: objective=0.131239 reg=0.002020
2017/08/30 16:08:51 step 6: objective=0.131300 reg=0.002019
2017/08/30 16:08:52 step 7: objective=0.131362 reg=0.002017
2017/08/30 16:08:52 Training value function...
2017/08/30 16:08:56 step 0: mse=0.229275 step=0.050000
2017/08/30 16:08:57 step 1: mse=0.228824 step=0.050000
2017/08/30 16:08:58 step 2: mse=0.228167 step=0.050000
2017/08/30 16:08:59 step 3: mse=0.227827 step=0.050000
2017/08/30 16:09:01 step 4: mse=0.227540 step=0.050000
2017/08/30 16:09:02 step 5: mse=0.227459 step=0.050000
2017/08/30 16:09:03 step 6: mse=0.227358 step=0.050000
2017/08/30 16:09:04 step 7: mse=0.227038 step=0.050000
2017/08/30 16:09:04 Saving...
2017/08/30 16:09:04 Gathering batch of experience...
2017/08/30 16:09:42 batch 288: mean=27.823529 stddev=13.785053 entropy=0.204704 frames=7336 count=17
2017/08/30 16:09:42 Training policy...
2017/08/30 16:09:47 tune 0: objective=0.129254 reg=0.002047 prune=0
2017/08/30 16:09:48 step 0: objective=0.129254 reg=0.002047
2017/08/30 16:09:50 step 1: objective=0.129327 reg=0.002047
2017/08/30 16:09:51 step 2: objective=0.129429 reg=0.002046
2017/08/30 16:09:52 step 3: objective=0.129550 reg=0.002046
2017/08/30 16:09:54 step 4: objective=0.129607 reg=0.002045
2017/08/30 16:09:55 step 5: objective=0.129702 reg=0.002045
2017/08/30 16:09:57 step 6: objective=0.129768 reg=0.002045
2017/08/30 16:09:58 step 7: objective=0.129878 reg=0.002045
2017/08/30 16:09:58 Training value function...
2017/08/30 16:10:01 step 0: mse=0.227038 step=0.050000
2017/08/30 16:10:02 step 1: mse=0.227316 step=0.050000
2017/08/30 16:10:03 step 2: mse=0.227231 step=0.050000
2017/08/30 16:10:05 step 3: mse=0.227202 step=0.050000
2017/08/30 16:10:06 step 4: mse=0.227198 step=0.050000
2017/08/30 16:10:07 step 5: mse=0.227454 step=0.050000
2017/08/30 16:10:08 step 6: mse=0.227673 step=0.050000
2017/08/30 16:10:10 step 7: mse=0.227833 step=0.050000
2017/08/30 16:10:10 Saving...
2017/08/30 16:10:10 Gathering batch of experience...
2017/08/30 16:10:47 batch 289: mean=28.235294 stddev=13.157549 entropy=0.201563 frames=7456 count=17
2017/08/30 16:10:47 Training policy...
2017/08/30 16:10:52 tune 0: objective=0.129748 reg=0.002016 prune=0
2017/08/30 16:10:53 step 0: objective=0.129748 reg=0.002016
2017/08/30 16:10:54 step 1: objective=0.129958 reg=0.002016
2017/08/30 16:10:56 step 2: objective=0.130079 reg=0.002016
2017/08/30 16:10:57 step 3: objective=0.130287 reg=0.002017
2017/08/30 16:10:59 step 4: objective=0.130402 reg=0.002018
2017/08/30 16:11:00 step 5: objective=0.130528 reg=0.002017
2017/08/30 16:11:01 step 6: objective=0.130635 reg=0.002017
2017/08/30 16:11:03 step 7: objective=0.130761 reg=0.002015
2017/08/30 16:11:03 Training value function...
2017/08/30 16:11:06 step 0: mse=0.223719 step=0.050000
2017/08/30 16:11:07 step 1: mse=0.223779 step=0.050000
2017/08/30 16:11:09 step 2: mse=0.223980 step=0.050000
2017/08/30 16:11:10 step 3: mse=0.223869 step=0.050000
2017/08/30 16:11:11 step 4: mse=0.223592 step=0.050000
2017/08/30 16:11:12 step 5: mse=0.223436 step=0.050000
2017/08/30 16:11:14 step 6: mse=0.223408 step=0.050000
2017/08/30 16:11:15 step 7: mse=0.223374 step=0.050000
2017/08/30 16:11:15 Saving...
2017/08/30 16:11:15 Gathering batch of experience...
2017/08/30 16:11:52 batch 290: mean=32.133333 stddev=11.825772 entropy=0.197833 frames=7441 count=15
2017/08/30 16:11:52 Training policy...
2017/08/30 16:11:57 tune 0: objective=0.140664 reg=0.001978 prune=0
2017/08/30 16:11:58 step 0: objective=0.140664 reg=0.001978
2017/08/30 16:12:00 step 1: objective=0.140803 reg=0.001979
2017/08/30 16:12:01 step 2: objective=0.140919 reg=0.001980
2017/08/30 16:12:03 step 3: objective=0.141007 reg=0.001980
2017/08/30 16:12:04 step 4: objective=0.141099 reg=0.001980
2017/08/30 16:12:05 step 5: objective=0.141203 reg=0.001980
2017/08/30 16:12:07 step 6: objective=0.141268 reg=0.001980
2017/08/30 16:12:08 step 7: objective=0.141378 reg=0.001980
2017/08/30 16:12:08 Training value function...
2017/08/30 16:12:11 step 0: mse=0.220555 step=0.050000
2017/08/30 16:12:12 step 1: mse=0.219044 step=0.050000
2017/08/30 16:12:14 step 2: mse=0.216836 step=0.050000
2017/08/30 16:12:15 step 3: mse=0.215779 step=0.050000
2017/08/30 16:12:16 step 4: mse=0.214616 step=0.050000
2017/08/30 16:12:18 step 5: mse=0.213758 step=0.050000
2017/08/30 16:12:19 step 6: mse=0.212267 step=0.050000
2017/08/30 16:12:20 step 7: mse=0.211091 step=0.050000
2017/08/30 16:12:20 Saving...
2017/08/30 16:12:20 Gathering batch of experience...
2017/08/30 16:12:56 batch 291: mean=29.800000 stddev=13.322662 entropy=0.206516 frames=6920 count=15
2017/08/30 16:12:56 Training policy...
2017/08/30 16:13:00 tune 0: objective=0.131101 reg=0.002065 prune=0
2017/08/30 16:13:02 step 0: objective=0.131101 reg=0.002065
2017/08/30 16:13:03 step 1: objective=0.131249 reg=0.002064
2017/08/30 16:13:04 step 2: objective=0.131428 reg=0.002063
2017/08/30 16:13:06 step 3: objective=0.131570 reg=0.002062
2017/08/30 16:13:07 step 4: objective=0.131660 reg=0.002061
2017/08/30 16:13:08 step 5: objective=0.131738 reg=0.002060
2017/08/30 16:13:09 step 6: objective=0.131879 reg=0.002060
2017/08/30 16:13:11 step 7: objective=0.131945 reg=0.002060
2017/08/30 16:13:11 Training value function...
2017/08/30 16:13:14 step 0: mse=0.218424 step=0.050000
2017/08/30 16:13:15 step 1: mse=0.218052 step=0.050000
2017/08/30 16:13:16 step 2: mse=0.217686 step=0.050000
2017/08/30 16:13:17 step 3: mse=0.217462 step=0.050000
2017/08/30 16:13:18 step 4: mse=0.217278 step=0.050000
2017/08/30 16:13:20 step 5: mse=0.217234 step=0.050000
2017/08/30 16:13:21 step 6: mse=0.216887 step=0.050000
2017/08/30 16:13:22 step 7: mse=0.216738 step=0.050000
2017/08/30 16:13:22 Saving...
2017/08/30 16:13:22 Gathering batch of experience...
2017/08/30 16:14:00 batch 292: mean=31.500000 stddev=13.047988 entropy=0.202056 frames=7794 count=16
2017/08/30 16:14:00 Training policy...
2017/08/30 16:14:05 tune 0: objective=0.136747 reg=0.002021 prune=0
2017/08/30 16:14:06 step 0: objective=0.136747 reg=0.002021
2017/08/30 16:14:08 step 1: objective=0.136879 reg=0.002020
2017/08/30 16:14:09 step 2: objective=0.137033 reg=0.002021
2017/08/30 16:14:11 step 3: objective=0.137143 reg=0.002022
2017/08/30 16:14:12 step 4: objective=0.137243 reg=0.002022
2017/08/30 16:14:14 step 5: objective=0.137342 reg=0.002022
2017/08/30 16:14:15 step 6: objective=0.137420 reg=0.002022
2017/08/30 16:14:16 step 7: objective=0.137516 reg=0.002022
2017/08/30 16:14:16 Training value function...
2017/08/30 16:14:20 step 0: mse=0.212266 step=0.050000
2017/08/30 16:14:21 step 1: mse=0.211484 step=0.050000
2017/08/30 16:14:22 step 2: mse=0.210633 step=0.050000
2017/08/30 16:14:24 step 3: mse=0.209793 step=0.050000
2017/08/30 16:14:25 step 4: mse=0.209221 step=0.050000
2017/08/30 16:14:27 step 5: mse=0.208652 step=0.050000
2017/08/30 16:14:28 step 6: mse=0.208123 step=0.050000
2017/08/30 16:14:29 step 7: mse=0.207560 step=0.050000
2017/08/30 16:14:29 Saving...
2017/08/30 16:14:29 Gathering batch of experience...
2017/08/30 16:15:06 batch 293: mean=29.937500 stddev=11.042355 entropy=0.205155 frames=7410 count=16
2017/08/30 16:15:06 Training policy...
2017/08/30 16:15:10 tune 0: objective=0.126045 reg=0.002052 prune=0
2017/08/30 16:15:12 step 0: objective=0.126045 reg=0.002052
2017/08/30 16:15:13 step 1: objective=0.126151 reg=0.002051
2017/08/30 16:15:15 step 2: objective=0.126216 reg=0.002050
2017/08/30 16:15:16 step 3: objective=0.126327 reg=0.002048
2017/08/30 16:15:17 step 4: objective=0.126393 reg=0.002048
2017/08/30 16:15:19 step 5: objective=0.126495 reg=0.002047
2017/08/30 16:15:20 step 6: objective=0.126595 reg=0.002047
2017/08/30 16:15:22 step 7: objective=0.126653 reg=0.002047
2017/08/30 16:15:22 Training value function...
2017/08/30 16:15:25 step 0: mse=0.205135 step=0.050000
2017/08/30 16:15:26 step 1: mse=0.205115 step=0.050000
2017/08/30 16:15:27 step 2: mse=0.205478 step=0.050000
2017/08/30 16:15:29 step 3: mse=0.205742 step=0.050000
2017/08/30 16:15:30 step 4: mse=0.206214 step=0.050000
2017/08/30 16:15:31 step 5: mse=0.206538 step=0.050000
2017/08/30 16:15:32 step 6: mse=0.206962 step=0.050000
2017/08/30 16:15:34 step 7: mse=0.207044 step=0.050000
2017/08/30 16:15:34 Saving...
2017/08/30 16:15:34 Gathering batch of experience...
2017/08/30 16:16:08 batch 294: mean=21.000000 stddev=15.131007 entropy=0.205594 frames=6220 count=19
2017/08/30 16:16:08 Training policy...
2017/08/30 16:16:12 tune 0: objective=0.109475 reg=0.002056 prune=0
2017/08/30 16:16:13 step 0: objective=0.109475 reg=0.002056
2017/08/30 16:16:14 step 1: objective=0.109612 reg=0.002056
2017/08/30 16:16:15 step 2: objective=0.109825 reg=0.002055
2017/08/30 16:16:17 step 3: objective=0.110043 reg=0.002055
2017/08/30 16:16:18 step 4: objective=0.110170 reg=0.002053
2017/08/30 16:16:19 step 5: objective=0.110273 reg=0.002053
2017/08/30 16:16:20 step 6: objective=0.110371 reg=0.002052
2017/08/30 16:16:21 step 7: objective=0.110470 reg=0.002052
2017/08/30 16:16:21 Training value function...
2017/08/30 16:16:24 step 0: mse=0.222407 step=0.050000
2017/08/30 16:16:25 step 1: mse=0.223401 step=0.050000
2017/08/30 16:16:26 step 2: mse=0.224227 step=0.050000
2017/08/30 16:16:27 step 3: mse=0.225178 step=0.050000
2017/08/30 16:16:28 step 4: mse=0.226104 step=0.050000
2017/08/30 16:16:29 step 5: mse=0.226760 step=0.050000
2017/08/30 16:16:30 step 6: mse=0.227785 step=0.050000
2017/08/30 16:16:31 step 7: mse=0.228521 step=0.050000
2017/08/30 16:16:31 Saving...
2017/08/30 16:16:31 Gathering batch of experience...
2017/08/30 16:17:08 batch 295: mean=32.133333 stddev=11.307028 entropy=0.199142 frames=7461 count=15
2017/08/30 16:17:08 Training policy...
2017/08/30 16:17:13 tune 0: objective=0.137648 reg=0.001991 prune=0
2017/08/30 16:17:14 step 0: objective=0.137648 reg=0.001991
2017/08/30 16:17:16 step 1: objective=0.137729 reg=0.001991
2017/08/30 16:17:17 step 2: objective=0.137844 reg=0.001991
2017/08/30 16:17:19 step 3: objective=0.137988 reg=0.001991
2017/08/30 16:17:20 step 4: objective=0.138176 reg=0.001991
2017/08/30 16:17:21 step 5: objective=0.138254 reg=0.001990
2017/08/30 16:17:23 step 6: objective=0.138328 reg=0.001990
2017/08/30 16:17:24 step 7: objective=0.138456 reg=0.001990
2017/08/30 16:17:24 Training value function...
2017/08/30 16:17:27 step 0: mse=0.222236 step=0.050000
2017/08/30 16:17:29 step 1: mse=0.221027 step=0.050000
2017/08/30 16:17:30 step 2: mse=0.220302 step=0.050000
2017/08/30 16:17:31 step 3: mse=0.219467 step=0.050000
2017/08/30 16:17:32 step 4: mse=0.218647 step=0.050000
2017/08/30 16:17:34 step 5: mse=0.217915 step=0.050000
2017/08/30 16:17:35 step 6: mse=0.216909 step=0.050000
2017/08/30 16:17:36 step 7: mse=0.216043 step=0.050000
2017/08/30 16:17:36 Saving...
2017/08/30 16:17:36 Gathering batch of experience...
2017/08/30 16:18:18 batch 296: mean=32.294118 stddev=11.228979 entropy=0.199231 frames=8477 count=17
2017/08/30 16:18:18 Training policy...
2017/08/30 16:18:23 tune 0: objective=0.138793 reg=0.001992 prune=0
2017/08/30 16:18:25 step 0: objective=0.138793 reg=0.001992
2017/08/30 16:18:26 step 1: objective=0.138852 reg=0.001992
2017/08/30 16:18:28 step 2: objective=0.138963 reg=0.001993
2017/08/30 16:18:30 step 3: objective=0.139102 reg=0.001993
2017/08/30 16:18:31 step 4: objective=0.139172 reg=0.001992
2017/08/30 16:18:33 step 5: objective=0.139205 reg=0.001992
2017/08/30 16:18:34 step 6: objective=0.139294 reg=0.001991
2017/08/30 16:18:36 step 7: objective=0.139362 reg=0.001991
2017/08/30 16:18:36 Training value function...
2017/08/30 16:18:40 step 0: mse=0.218029 step=0.050000
2017/08/30 16:18:41 step 1: mse=0.216659 step=0.050000
2017/08/30 16:18:42 step 2: mse=0.215882 step=0.050000
2017/08/30 16:18:44 step 3: mse=0.214709 step=0.050000
2017/08/30 16:18:45 step 4: mse=0.213607 step=0.050000
2017/08/30 16:18:47 step 5: mse=0.212865 step=0.050000
2017/08/30 16:18:48 step 6: mse=0.211974 step=0.050000
2017/08/30 16:18:50 step 7: mse=0.210879 step=0.050000
2017/08/30 16:18:50 Saving...
2017/08/30 16:18:50 Gathering batch of experience...
2017/08/30 16:19:31 batch 297: mean=32.647059 stddev=11.002359 entropy=0.199641 frames=8598 count=17
2017/08/30 16:19:31 Training policy...
2017/08/30 16:19:36 tune 0: objective=0.133822 reg=0.001996 prune=0
2017/08/30 16:19:37 step 0: objective=0.133822 reg=0.001996
2017/08/30 16:19:39 step 1: objective=0.133889 reg=0.001996
2017/08/30 16:19:41 step 2: objective=0.133947 reg=0.001995
2017/08/30 16:19:42 step 3: objective=0.134030 reg=0.001995
2017/08/30 16:19:44 step 4: objective=0.134111 reg=0.001995
2017/08/30 16:19:46 step 5: objective=0.134171 reg=0.001994
2017/08/30 16:19:47 step 6: objective=0.134240 reg=0.001993
2017/08/30 16:19:49 step 7: objective=0.134313 reg=0.001993
2017/08/30 16:19:49 Training value function...
2017/08/30 16:19:53 step 0: mse=0.215584 step=0.050000
2017/08/30 16:19:54 step 1: mse=0.215034 step=0.050000
2017/08/30 16:19:56 step 2: mse=0.214187 step=0.050000
2017/08/30 16:19:57 step 3: mse=0.213899 step=0.050000
2017/08/30 16:19:59 step 4: mse=0.213378 step=0.050000
2017/08/30 16:20:00 step 5: mse=0.213154 step=0.050000
2017/08/30 16:20:02 step 6: mse=0.212853 step=0.050000
2017/08/30 16:20:03 step 7: mse=0.212446 step=0.050000
2017/08/30 16:20:03 Saving...
2017/08/30 16:20:03 Gathering batch of experience...
2017/08/30 16:20:41 batch 298: mean=32.866667 stddev=9.243857 entropy=0.195306 frames=7652 count=15
2017/08/30 16:20:41 Training policy...
2017/08/30 16:20:46 tune 0: objective=0.131665 reg=0.001953 prune=0
2017/08/30 16:20:48 step 0: objective=0.131665 reg=0.001953
2017/08/30 16:20:49 step 1: objective=0.131786 reg=0.001952
2017/08/30 16:20:50 step 2: objective=0.131865 reg=0.001951
2017/08/30 16:20:52 step 3: objective=0.131979 reg=0.001950
2017/08/30 16:20:53 step 4: objective=0.132094 reg=0.001950
2017/08/30 16:20:55 step 5: objective=0.132216 reg=0.001950
2017/08/30 16:20:56 step 6: objective=0.132347 reg=0.001949
2017/08/30 16:20:58 step 7: objective=0.132434 reg=0.001948
2017/08/30 16:20:58 Training value function...
2017/08/30 16:21:01 step 0: mse=0.222182 step=0.050000
2017/08/30 16:21:02 step 1: mse=0.222081 step=0.050000
2017/08/30 16:21:04 step 2: mse=0.221239 step=0.050000
2017/08/30 16:21:05 step 3: mse=0.220979 step=0.050000
2017/08/30 16:21:06 step 4: mse=0.220566 step=0.050000
2017/08/30 16:21:08 step 5: mse=0.220337 step=0.050000
2017/08/30 16:21:09 step 6: mse=0.219628 step=0.050000
2017/08/30 16:21:10 step 7: mse=0.219799 step=0.050000
2017/08/30 16:21:10 Saving...
2017/08/30 16:21:10 Gathering batch of experience...
2017/08/30 16:21:51 batch 299: mean=26.052632 stddev=13.570377 entropy=0.199000 frames=7693 count=19
2017/08/30 16:21:51 Training policy...
2017/08/30 16:21:56 tune 0: objective=0.118682 reg=0.001990 prune=0
2017/08/30 16:21:57 step 0: objective=0.118682 reg=0.001990
2017/08/30 16:21:59 step 1: objective=0.118763 reg=0.001989
2017/08/30 16:22:00 step 2: objective=0.118866 reg=0.001989
2017/08/30 16:22:02 step 3: objective=0.118952 reg=0.001988
2017/08/30 16:22:03 step 4: objective=0.119032 reg=0.001987
2017/08/30 16:22:04 step 5: objective=0.119163 reg=0.001986
2017/08/30 16:22:06 step 6: objective=0.119274 reg=0.001986
2017/08/30 16:22:07 step 7: objective=0.119306 reg=0.001986
2017/08/30 16:22:07 Training value function...
2017/08/30 16:22:11 step 0: mse=0.210890 step=0.050000
2017/08/30 16:22:12 step 1: mse=0.211421 step=0.050000
2017/08/30 16:22:13 step 2: mse=0.212134 step=0.050000
2017/08/30 16:22:15 step 3: mse=0.212820 step=0.050000
2017/08/30 16:22:16 step 4: mse=0.213432 step=0.050000
2017/08/30 16:22:17 step 5: mse=0.213930 step=0.050000
2017/08/30 16:22:19 step 6: mse=0.214510 step=0.050000
2017/08/30 16:22:20 step 7: mse=0.215020 step=0.050000
2017/08/30 16:22:20 Saving...
2017/08/30 16:22:20 Gathering batch of experience...
2017/08/30 16:22:58 batch 300: mean=21.545455 stddev=16.004906 entropy=0.203130 frames=7412 count=22
2017/08/30 16:22:58 Training policy...
2017/08/30 16:23:03 tune 0: objective=0.110592 reg=0.002031 prune=0
2017/08/30 16:23:05 step 0: objective=0.110592 reg=0.002031
2017/08/30 16:23:06 step 1: objective=0.110787 reg=0.002030
2017/08/30 16:23:07 step 2: objective=0.110960 reg=0.002028
2017/08/30 16:23:09 step 3: objective=0.111023 reg=0.002029
2017/08/30 16:23:10 step 4: objective=0.111171 reg=0.002027
2017/08/30 16:23:12 step 5: objective=0.111253 reg=0.002026
2017/08/30 16:23:13 step 6: objective=0.111313 reg=0.002026
2017/08/30 16:23:14 step 7: objective=0.111481 reg=0.002026
2017/08/30 16:23:14 Training value function...
2017/08/30 16:23:18 step 0: mse=0.233057 step=0.050000
2017/08/30 16:23:19 step 1: mse=0.233703 step=0.050000
2017/08/30 16:23:20 step 2: mse=0.234404 step=0.050000
2017/08/30 16:23:21 step 3: mse=0.234703 step=0.050000
2017/08/30 16:23:23 step 4: mse=0.235267 step=0.050000
2017/08/30 16:23:24 step 5: mse=0.235978 step=0.050000
2017/08/30 16:23:25 step 6: mse=0.236427 step=0.050000
2017/08/30 16:23:27 step 7: mse=0.236822 step=0.050000
2017/08/30 16:23:27 Saving...
2017/08/30 16:23:27 Gathering batch of experience...
2017/08/30 16:24:04 batch 301: mean=33.066667 stddev=10.356748 entropy=0.201323 frames=7676 count=15
2017/08/30 16:24:04 Training policy...
2017/08/30 16:24:09 tune 0: objective=0.141148 reg=0.002013 prune=0
2017/08/30 16:24:10 step 0: objective=0.141148 reg=0.002013
2017/08/30 16:24:12 step 1: objective=0.141220 reg=0.002014
2017/08/30 16:24:13 step 2: objective=0.141274 reg=0.002013
2017/08/30 16:24:15 step 3: objective=0.141326 reg=0.002013
2017/08/30 16:24:16 step 4: objective=0.141373 reg=0.002013
2017/08/30 16:24:18 step 5: objective=0.141416 reg=0.002013
2017/08/30 16:24:19 step 6: objective=0.141478 reg=0.002013
2017/08/30 16:24:21 step 7: objective=0.141542 reg=0.002013
2017/08/30 16:24:21 Training value function...
2017/08/30 16:24:24 step 0: mse=0.226002 step=0.050000
2017/08/30 16:24:25 step 1: mse=0.224366 step=0.050000
2017/08/30 16:24:26 step 2: mse=0.223042 step=0.050000
2017/08/30 16:24:28 step 3: mse=0.221887 step=0.050000
2017/08/30 16:24:29 step 4: mse=0.219980 step=0.050000
2017/08/30 16:24:30 step 5: mse=0.218922 step=0.050000
2017/08/30 16:24:32 step 6: mse=0.218023 step=0.050000
2017/08/30 16:24:33 step 7: mse=0.217351 step=0.050000
2017/08/30 16:24:33 Saving...
2017/08/30 16:24:33 Gathering batch of experience...
2017/08/30 16:25:11 batch 302: mean=33.866667 stddev=10.626173 entropy=0.193012 frames=7826 count=15
2017/08/30 16:25:11 Training policy...
2017/08/30 16:25:16 tune 0: objective=0.143937 reg=0.001930 prune=0
2017/08/30 16:25:18 step 0: objective=0.143937 reg=0.001930
2017/08/30 16:25:19 step 1: objective=0.144073 reg=0.001931
2017/08/30 16:25:21 step 2: objective=0.144199 reg=0.001931
2017/08/30 16:25:22 step 3: objective=0.144339 reg=0.001932
2017/08/30 16:25:24 step 4: objective=0.144442 reg=0.001932
2017/08/30 16:25:25 step 5: objective=0.144524 reg=0.001932
2017/08/30 16:25:27 step 6: objective=0.144660 reg=0.001931
2017/08/30 16:25:28 step 7: objective=0.144775 reg=0.001932
2017/08/30 16:25:28 Training value function...
2017/08/30 16:25:31 step 0: mse=0.216225 step=0.050000
2017/08/30 16:25:33 step 1: mse=0.214538 step=0.050000
2017/08/30 16:25:34 step 2: mse=0.212953 step=0.050000
2017/08/30 16:25:35 step 3: mse=0.211885 step=0.050000
2017/08/30 16:25:37 step 4: mse=0.210535 step=0.050000
2017/08/30 16:25:38 step 5: mse=0.209291 step=0.050000
2017/08/30 16:25:39 step 6: mse=0.208183 step=0.050000
2017/08/30 16:25:41 step 7: mse=0.207056 step=0.050000
2017/08/30 16:25:41 Saving...
2017/08/30 16:25:41 Gathering batch of experience...
2017/08/30 16:26:16 batch 303: mean=22.944444 stddev=14.416319 entropy=0.202411 frames=6433 count=18
2017/08/30 16:26:16 Training policy...
2017/08/30 16:26:20 tune 0: objective=0.111824 reg=0.002024 prune=0
2017/08/30 16:26:21 step 0: objective=0.111824 reg=0.002024
2017/08/30 16:26:22 step 1: objective=0.111920 reg=0.002024
2017/08/30 16:26:23 step 2: objective=0.112103 reg=0.002023
2017/08/30 16:26:24 step 3: objective=0.112189 reg=0.002024
2017/08/30 16:26:26 step 4: objective=0.112251 reg=0.002023
2017/08/30 16:26:27 step 5: objective=0.112378 reg=0.002023
2017/08/30 16:26:28 step 6: objective=0.112436 reg=0.002024
2017/08/30 16:26:29 step 7: objective=0.112520 reg=0.002025
2017/08/30 16:26:29 Training value function...
2017/08/30 16:26:32 step 0: mse=0.218642 step=0.050000
2017/08/30 16:26:33 step 1: mse=0.219629 step=0.050000
2017/08/30 16:26:34 step 2: mse=0.220720 step=0.050000
2017/08/30 16:26:35 step 3: mse=0.221648 step=0.050000
2017/08/30 16:26:36 step 4: mse=0.222652 step=0.050000
2017/08/30 16:26:38 step 5: mse=0.223546 step=0.050000
2017/08/30 16:26:39 step 6: mse=0.224578 step=0.050000
2017/08/30 16:26:40 step 7: mse=0.225243 step=0.050000
2017/08/30 16:26:40 Saving...
2017/08/30 16:26:40 Gathering batch of experience...
2017/08/30 16:27:18 batch 304: mean=31.875000 stddev=10.752180 entropy=0.197234 frames=7904 count=16
2017/08/30 16:27:18 Training policy...
2017/08/30 16:27:23 tune 0: objective=0.138129 reg=0.001972 prune=0
2017/08/30 16:27:25 step 0: objective=0.138129 reg=0.001972
2017/08/30 16:27:26 step 1: objective=0.138245 reg=0.001972
2017/08/30 16:27:28 step 2: objective=0.138391 reg=0.001971
2017/08/30 16:27:29 step 3: objective=0.138522 reg=0.001971
2017/08/30 16:27:31 step 4: objective=0.138668 reg=0.001970
2017/08/30 16:27:32 step 5: objective=0.138724 reg=0.001971
2017/08/30 16:27:34 step 6: objective=0.138803 reg=0.001970
2017/08/30 16:27:35 step 7: objective=0.138890 reg=0.001969
2017/08/30 16:27:35 Training value function...
2017/08/30 16:27:38 step 0: mse=0.226373 step=0.050000
2017/08/30 16:27:40 step 1: mse=0.224894 step=0.050000
2017/08/30 16:27:41 step 2: mse=0.223693 step=0.050000
2017/08/30 16:27:43 step 3: mse=0.222803 step=0.050000
2017/08/30 16:27:44 step 4: mse=0.222160 step=0.050000
2017/08/30 16:27:45 step 5: mse=0.221773 step=0.050000
2017/08/30 16:27:47 step 6: mse=0.220998 step=0.050000
2017/08/30 16:27:48 step 7: mse=0.220585 step=0.050000
2017/08/30 16:27:48 Saving...
2017/08/30 16:27:48 Gathering batch of experience...
2017/08/30 16:28:26 batch 305: mean=29.705882 stddev=13.118306 entropy=0.195280 frames=7819 count=17
2017/08/30 16:28:26 Training policy...
2017/08/30 16:28:31 tune 0: objective=0.133445 reg=0.001953 prune=0
2017/08/30 16:28:33 step 0: objective=0.133445 reg=0.001953
2017/08/30 16:28:34 step 1: objective=0.133567 reg=0.001952
2017/08/30 16:28:36 step 2: objective=0.133659 reg=0.001953
2017/08/30 16:28:37 step 3: objective=0.133741 reg=0.001952
2017/08/30 16:28:39 step 4: objective=0.133847 reg=0.001952
2017/08/30 16:28:40 step 5: objective=0.133943 reg=0.001953
2017/08/30 16:28:42 step 6: objective=0.134038 reg=0.001952
2017/08/30 16:28:43 step 7: objective=0.134108 reg=0.001952
2017/08/30 16:28:43 Training value function...
2017/08/30 16:28:46 step 0: mse=0.219530 step=0.050000
2017/08/30 16:28:48 step 1: mse=0.219140 step=0.050000
2017/08/30 16:28:49 step 2: mse=0.218765 step=0.050000
2017/08/30 16:28:50 step 3: mse=0.218123 step=0.050000
2017/08/30 16:28:52 step 4: mse=0.217635 step=0.050000
2017/08/30 16:28:53 step 5: mse=0.217333 step=0.050000
2017/08/30 16:28:55 step 6: mse=0.217099 step=0.050000
2017/08/30 16:28:56 step 7: mse=0.216926 step=0.050000
2017/08/30 16:28:56 Saving...
2017/08/30 16:28:56 Gathering batch of experience...
2017/08/30 16:29:33 batch 306: mean=28.235294 stddev=13.985410 entropy=0.194001 frames=7427 count=17
2017/08/30 16:29:33 Training policy...
2017/08/30 16:29:38 tune 0: objective=0.130921 reg=0.001940 prune=0
2017/08/30 16:29:39 step 0: objective=0.130921 reg=0.001940
2017/08/30 16:29:41 step 1: objective=0.131102 reg=0.001940
2017/08/30 16:29:42 step 2: objective=0.131198 reg=0.001940
2017/08/30 16:29:44 step 3: objective=0.131340 reg=0.001940
2017/08/30 16:29:45 step 4: objective=0.131416 reg=0.001939
2017/08/30 16:29:47 step 5: objective=0.131528 reg=0.001939
2017/08/30 16:29:48 step 6: objective=0.131637 reg=0.001937
2017/08/30 16:29:49 step 7: objective=0.131711 reg=0.001937
2017/08/30 16:29:49 Training value function...
2017/08/30 16:29:53 step 0: mse=0.219960 step=0.050000
2017/08/30 16:29:54 step 1: mse=0.219662 step=0.050000
2017/08/30 16:29:55 step 2: mse=0.219190 step=0.050000
2017/08/30 16:29:56 step 3: mse=0.218831 step=0.050000
2017/08/30 16:29:58 step 4: mse=0.218690 step=0.050000
2017/08/30 16:29:59 step 5: mse=0.218317 step=0.050000
2017/08/30 16:30:00 step 6: mse=0.218389 step=0.050000
2017/08/30 16:30:02 step 7: mse=0.218446 step=0.050000
2017/08/30 16:30:02 Saving...
2017/08/30 16:30:02 Gathering batch of experience...
2017/08/30 16:30:40 batch 307: mean=29.882353 stddev=11.989615 entropy=0.197291 frames=7885 count=17
2017/08/30 16:30:40 Training policy...
2017/08/30 16:30:45 tune 0: objective=0.128610 reg=0.001973 prune=0
2017/08/30 16:30:47 step 0: objective=0.128610 reg=0.001973
2017/08/30 16:30:48 step 1: objective=0.128720 reg=0.001973
2017/08/30 16:30:50 step 2: objective=0.128802 reg=0.001973
2017/08/30 16:30:51 step 3: objective=0.128886 reg=0.001973
2017/08/30 16:30:53 step 4: objective=0.128949 reg=0.001972
2017/08/30 16:30:54 step 5: objective=0.129066 reg=0.001973
2017/08/30 16:30:56 step 6: objective=0.129141 reg=0.001973
2017/08/30 16:30:57 step 7: objective=0.129203 reg=0.001973
2017/08/30 16:30:57 Training value function...
2017/08/30 16:31:00 step 0: mse=0.218173 step=0.050000
2017/08/30 16:31:02 step 1: mse=0.218173 step=0.050000
2017/08/30 16:31:03 step 2: mse=0.217836 step=0.050000
2017/08/30 16:31:04 step 3: mse=0.217645 step=0.050000
2017/08/30 16:31:06 step 4: mse=0.217222 step=0.050000
2017/08/30 16:31:07 step 5: mse=0.217034 step=0.050000
2017/08/30 16:31:09 step 6: mse=0.216919 step=0.050000
2017/08/30 16:31:10 step 7: mse=0.216744 step=0.050000
2017/08/30 16:31:10 Saving...
2017/08/30 16:31:10 Gathering batch of experience...
2017/08/30 16:31:48 batch 308: mean=28.823529 stddev=13.236471 entropy=0.198770 frames=7566 count=17
2017/08/30 16:31:48 Training policy...
2017/08/30 16:31:52 tune 0: objective=0.132892 reg=0.001988 prune=0
2017/08/30 16:31:54 step 0: objective=0.132893 reg=0.001988
2017/08/30 16:31:55 step 1: objective=0.133000 reg=0.001988
2017/08/30 16:31:57 step 2: objective=0.133076 reg=0.001988
2017/08/30 16:31:58 step 3: objective=0.133165 reg=0.001988
2017/08/30 16:32:00 step 4: objective=0.133234 reg=0.001988
2017/08/30 16:32:01 step 5: objective=0.133301 reg=0.001988
2017/08/30 16:32:02 step 6: objective=0.133357 reg=0.001987
2017/08/30 16:32:04 step 7: objective=0.133414 reg=0.001986
2017/08/30 16:32:04 Training value function...
2017/08/30 16:32:07 step 0: mse=0.213367 step=0.050000
2017/08/30 16:32:08 step 1: mse=0.212898 step=0.050000
2017/08/30 16:32:10 step 2: mse=0.212583 step=0.050000
2017/08/30 16:32:11 step 3: mse=0.212283 step=0.050000
2017/08/30 16:32:12 step 4: mse=0.211580 step=0.050000
2017/08/30 16:32:14 step 5: mse=0.211530 step=0.050000
2017/08/30 16:32:15 step 6: mse=0.211033 step=0.050000
2017/08/30 16:32:16 step 7: mse=0.210928 step=0.050000
2017/08/30 16:32:16 Saving...
2017/08/30 16:32:16 Gathering batch of experience...
2017/08/30 16:32:59 batch 309: mean=28.722222 stddev=11.948061 entropy=0.198050 frames=8015 count=18
2017/08/30 16:32:59 Training policy...
2017/08/30 16:33:04 tune 0: objective=0.126340 reg=0.001981 prune=0
2017/08/30 16:33:06 step 0: objective=0.126341 reg=0.001980
2017/08/30 16:33:07 step 1: objective=0.126429 reg=0.001980
2017/08/30 16:33:09 step 2: objective=0.126518 reg=0.001980
2017/08/30 16:33:10 step 3: objective=0.126600 reg=0.001980
2017/08/30 16:33:12 step 4: objective=0.126682 reg=0.001979
2017/08/30 16:33:13 step 5: objective=0.126744 reg=0.001979
2017/08/30 16:33:15 step 6: objective=0.126815 reg=0.001978
2017/08/30 16:33:16 step 7: objective=0.126892 reg=0.001978
2017/08/30 16:33:16 Training value function...
2017/08/30 16:33:20 step 0: mse=0.218769 step=0.050000
2017/08/30 16:33:21 step 1: mse=0.219157 step=0.050000
2017/08/30 16:33:22 step 2: mse=0.219626 step=0.050000
2017/08/30 16:33:24 step 3: mse=0.220088 step=0.050000
2017/08/30 16:33:25 step 4: mse=0.220323 step=0.050000
2017/08/30 16:33:27 step 5: mse=0.220485 step=0.050000
2017/08/30 16:33:28 step 6: mse=0.220990 step=0.050000
2017/08/30 16:33:29 step 7: mse=0.221237 step=0.050000
2017/08/30 16:33:29 Saving...
2017/08/30 16:33:30 Gathering batch of experience...
2017/08/30 16:34:10 batch 310: mean=29.055556 stddev=13.640105 entropy=0.195055 frames=8106 count=18
2017/08/30 16:34:10 Training policy...
2017/08/30 16:34:15 tune 0: objective=0.131673 reg=0.001951 prune=0
2017/08/30 16:34:17 step 0: objective=0.131673 reg=0.001951
2017/08/30 16:34:18 step 1: objective=0.131791 reg=0.001952
2017/08/30 16:34:20 step 2: objective=0.131909 reg=0.001952
2017/08/30 16:34:21 step 3: objective=0.132056 reg=0.001953
2017/08/30 16:34:23 step 4: objective=0.132143 reg=0.001955
2017/08/30 16:34:24 step 5: objective=0.132234 reg=0.001956
2017/08/30 16:34:26 step 6: objective=0.132279 reg=0.001956
2017/08/30 16:34:27 step 7: objective=0.132328 reg=0.001956
2017/08/30 16:34:27 Training value function...
2017/08/30 16:34:31 step 0: mse=0.223698 step=0.050000
2017/08/30 16:34:32 step 1: mse=0.223385 step=0.050000
2017/08/30 16:34:34 step 2: mse=0.223420 step=0.050000
2017/08/30 16:34:35 step 3: mse=0.223481 step=0.050000
2017/08/30 16:34:37 step 4: mse=0.223458 step=0.050000
2017/08/30 16:34:38 step 5: mse=0.223113 step=0.050000
2017/08/30 16:34:39 step 6: mse=0.223192 step=0.050000
2017/08/30 16:34:41 step 7: mse=0.223203 step=0.050000
2017/08/30 16:34:41 Saving...
2017/08/30 16:34:41 Gathering batch of experience...
2017/08/30 16:35:19 batch 311: mean=30.937500 stddev=11.464449 entropy=0.198090 frames=7645 count=16
2017/08/30 16:35:19 Training policy...
2017/08/30 16:35:24 tune 0: objective=0.135525 reg=0.001981 prune=0
2017/08/30 16:35:25 step 0: objective=0.135525 reg=0.001981
2017/08/30 16:35:26 step 1: objective=0.135611 reg=0.001980
2017/08/30 16:35:28 step 2: objective=0.135714 reg=0.001980
2017/08/30 16:35:29 step 3: objective=0.135758 reg=0.001980
2017/08/30 16:35:31 step 4: objective=0.135819 reg=0.001980
2017/08/30 16:35:32 step 5: objective=0.135865 reg=0.001981
2017/08/30 16:35:34 step 6: objective=0.135993 reg=0.001979
2017/08/30 16:35:35 step 7: objective=0.136170 reg=0.001979
2017/08/30 16:35:35 Training value function...
2017/08/30 16:35:38 step 0: mse=0.217147 step=0.050000
2017/08/30 16:35:40 step 1: mse=0.216532 step=0.050000
2017/08/30 16:35:41 step 2: mse=0.215973 step=0.050000
2017/08/30 16:35:42 step 3: mse=0.214725 step=0.050000
2017/08/30 16:35:44 step 4: mse=0.214366 step=0.050000
2017/08/30 16:35:45 step 5: mse=0.213752 step=0.050000
2017/08/30 16:35:46 step 6: mse=0.213280 step=0.050000
2017/08/30 16:35:48 step 7: mse=0.212903 step=0.050000
2017/08/30 16:35:48 Saving...
2017/08/30 16:35:48 Gathering batch of experience...
2017/08/30 16:36:25 batch 312: mean=31.266667 stddev=9.712306 entropy=0.195922 frames=7269 count=15
2017/08/30 16:36:25 Training policy...
2017/08/30 16:36:29 tune 0: objective=0.130383 reg=0.001959 prune=0
2017/08/30 16:36:31 step 0: objective=0.130383 reg=0.001959
2017/08/30 16:36:32 step 1: objective=0.130510 reg=0.001959
2017/08/30 16:36:34 step 2: objective=0.130556 reg=0.001958
2017/08/30 16:36:35 step 3: objective=0.130706 reg=0.001957
2017/08/30 16:36:36 step 4: objective=0.130804 reg=0.001956
2017/08/30 16:36:38 step 5: objective=0.130930 reg=0.001955
2017/08/30 16:36:39 step 6: objective=0.130983 reg=0.001954
2017/08/30 16:36:41 step 7: objective=0.131027 reg=0.001954
2017/08/30 16:36:41 Training value function...
2017/08/30 16:36:44 step 0: mse=0.218140 step=0.050000
2017/08/30 16:36:45 step 1: mse=0.218257 step=0.050000
2017/08/30 16:36:46 step 2: mse=0.217903 step=0.050000
2017/08/30 16:36:47 step 3: mse=0.217473 step=0.050000
2017/08/30 16:36:49 step 4: mse=0.217395 step=0.050000
2017/08/30 16:36:50 step 5: mse=0.217275 step=0.050000
2017/08/30 16:36:51 step 6: mse=0.216699 step=0.050000
2017/08/30 16:36:52 step 7: mse=0.216562 step=0.050000
2017/08/30 16:36:52 Saving...
2017/08/30 16:36:52 Gathering batch of experience...
2017/08/30 16:37:32 batch 313: mean=30.588235 stddev=12.338647 entropy=0.195883 frames=8051 count=17
2017/08/30 16:37:32 Training policy...
2017/08/30 16:37:37 tune 0: objective=0.131782 reg=0.001959 prune=0
2017/08/30 16:37:38 step 0: objective=0.131783 reg=0.001959
2017/08/30 16:37:40 step 1: objective=0.131888 reg=0.001958
2017/08/30 16:37:41 step 2: objective=0.131995 reg=0.001958
2017/08/30 16:37:43 step 3: objective=0.132079 reg=0.001957
2017/08/30 16:37:44 step 4: objective=0.132130 reg=0.001956
2017/08/30 16:37:46 step 5: objective=0.132236 reg=0.001956
2017/08/30 16:37:47 step 6: objective=0.132319 reg=0.001956
2017/08/30 16:37:49 step 7: objective=0.132399 reg=0.001956
2017/08/30 16:37:49 Training value function...
2017/08/30 16:37:52 step 0: mse=0.215820 step=0.050000
2017/08/30 16:37:54 step 1: mse=0.215575 step=0.050000
2017/08/30 16:37:55 step 2: mse=0.215243 step=0.050000
2017/08/30 16:37:56 step 3: mse=0.215113 step=0.050000
2017/08/30 16:37:58 step 4: mse=0.214928 step=0.050000
2017/08/30 16:37:59 step 5: mse=0.214661 step=0.050000
2017/08/30 16:38:01 step 6: mse=0.214706 step=0.050000
2017/08/30 16:38:02 step 7: mse=0.214602 step=0.050000
2017/08/30 16:38:02 Saving...
2017/08/30 16:38:02 Gathering batch of experience...
2017/08/30 16:38:43 batch 314: mean=25.950000 stddev=12.338861 entropy=0.198493 frames=8061 count=20
2017/08/30 16:38:43 Training policy...
2017/08/30 16:38:48 tune 0: objective=0.121165 reg=0.001985 prune=0
2017/08/30 16:38:49 step 0: objective=0.121166 reg=0.001985
2017/08/30 16:38:51 step 1: objective=0.121245 reg=0.001985
2017/08/30 16:38:52 step 2: objective=0.121338 reg=0.001984
2017/08/30 16:38:54 step 3: objective=0.121394 reg=0.001984
2017/08/30 16:38:55 step 4: objective=0.121465 reg=0.001984
2017/08/30 16:38:57 step 5: objective=0.121609 reg=0.001984
2017/08/30 16:38:58 step 6: objective=0.121658 reg=0.001983
2017/08/30 16:39:00 step 7: objective=0.121726 reg=0.001984
2017/08/30 16:39:00 Training value function...
2017/08/30 16:39:03 step 0: mse=0.217574 step=0.050000
2017/08/30 16:39:05 step 1: mse=0.218234 step=0.050000
2017/08/30 16:39:06 step 2: mse=0.218821 step=0.050000
2017/08/30 16:39:08 step 3: mse=0.219449 step=0.050000
2017/08/30 16:39:09 step 4: mse=0.219975 step=0.050000
2017/08/30 16:39:11 step 5: mse=0.220640 step=0.050000
2017/08/30 16:39:12 step 6: mse=0.221065 step=0.050000
2017/08/30 16:39:13 step 7: mse=0.221716 step=0.050000
2017/08/30 16:39:13 Saving...
2017/08/30 16:39:13 Gathering batch of experience...
2017/08/30 16:39:50 batch 315: mean=29.875000 stddev=12.781212 entropy=0.194320 frames=7405 count=16
2017/08/30 16:39:50 Training policy...
2017/08/30 16:39:55 tune 0: objective=0.134020 reg=0.001943 prune=0
2017/08/30 16:39:57 step 0: objective=0.134020 reg=0.001943
2017/08/30 16:39:58 step 1: objective=0.134113 reg=0.001943
2017/08/30 16:39:59 step 2: objective=0.134208 reg=0.001943
2017/08/30 16:40:01 step 3: objective=0.134374 reg=0.001942
2017/08/30 16:40:02 step 4: objective=0.134525 reg=0.001941
2017/08/30 16:40:04 step 5: objective=0.134608 reg=0.001941
2017/08/30 16:40:05 step 6: objective=0.134680 reg=0.001941
2017/08/30 16:40:06 step 7: objective=0.134772 reg=0.001941
2017/08/30 16:40:06 Training value function...
2017/08/30 16:40:10 step 0: mse=0.224432 step=0.050000
2017/08/30 16:40:11 step 1: mse=0.223802 step=0.050000
2017/08/30 16:40:12 step 2: mse=0.223314 step=0.050000
2017/08/30 16:40:13 step 3: mse=0.222494 step=0.050000
2017/08/30 16:40:15 step 4: mse=0.222216 step=0.050000
2017/08/30 16:40:16 step 5: mse=0.221897 step=0.050000
2017/08/30 16:40:17 step 6: mse=0.221571 step=0.050000
2017/08/30 16:40:19 step 7: mse=0.221381 step=0.050000
2017/08/30 16:40:19 Saving...
2017/08/30 16:40:19 Gathering batch of experience...
2017/08/30 16:40:56 batch 316: mean=30.125000 stddev=10.403575 entropy=0.196731 frames=7473 count=16
2017/08/30 16:40:56 Training policy...
2017/08/30 16:41:01 tune 0: objective=0.130725 reg=0.001967 prune=0
2017/08/30 16:41:02 step 0: objective=0.130725 reg=0.001967
2017/08/30 16:41:03 step 1: objective=0.130789 reg=0.001967
2017/08/30 16:41:05 step 2: objective=0.130898 reg=0.001966
2017/08/30 16:41:06 step 3: objective=0.131017 reg=0.001965
2017/08/30 16:41:08 step 4: objective=0.131075 reg=0.001964
2017/08/30 16:41:09 step 5: objective=0.131128 reg=0.001963
2017/08/30 16:41:11 step 6: objective=0.131206 reg=0.001963
2017/08/30 16:41:12 step 7: objective=0.131339 reg=0.001962
2017/08/30 16:41:12 Training value function...
2017/08/30 16:41:15 step 0: mse=0.224968 step=0.050000
2017/08/30 16:41:16 step 1: mse=0.224862 step=0.050000
2017/08/30 16:41:18 step 2: mse=0.224401 step=0.050000
2017/08/30 16:41:19 step 3: mse=0.224372 step=0.050000
2017/08/30 16:41:20 step 4: mse=0.223851 step=0.050000
2017/08/30 16:41:22 step 5: mse=0.223817 step=0.050000
2017/08/30 16:41:23 step 6: mse=0.223888 step=0.050000
2017/08/30 16:41:24 step 7: mse=0.223812 step=0.050000
2017/08/30 16:41:24 Saving...
2017/08/30 16:41:24 Gathering batch of experience...
2017/08/30 16:42:03 batch 317: mean=27.105263 stddev=15.930424 entropy=0.195062 frames=7951 count=19
2017/08/30 16:42:03 Training policy...
2017/08/30 16:42:08 tune 0: objective=0.134819 reg=0.001951 prune=0
2017/08/30 16:42:10 step 0: objective=0.134819 reg=0.001951
2017/08/30 16:42:11 step 1: objective=0.134868 reg=0.001951
2017/08/30 16:42:13 step 2: objective=0.134926 reg=0.001950
2017/08/30 16:42:14 step 3: objective=0.134985 reg=0.001950
2017/08/30 16:42:16 step 4: objective=0.135051 reg=0.001950
2017/08/30 16:42:17 step 5: objective=0.135111 reg=0.001950
2017/08/30 16:42:19 step 6: objective=0.135161 reg=0.001950
2017/08/30 16:42:21 step 7: objective=0.135234 reg=0.001950
2017/08/30 16:42:21 Training value function...
2017/08/30 16:42:24 step 0: mse=0.224270 step=0.050000
2017/08/30 16:42:25 step 1: mse=0.222952 step=0.050000
2017/08/30 16:42:27 step 2: mse=0.221446 step=0.050000
2017/08/30 16:42:28 step 3: mse=0.220366 step=0.050000
2017/08/30 16:42:29 step 4: mse=0.219513 step=0.050000
2017/08/30 16:42:31 step 5: mse=0.218227 step=0.050000
2017/08/30 16:42:32 step 6: mse=0.217517 step=0.050000
2017/08/30 16:42:33 step 7: mse=0.216644 step=0.050000
2017/08/30 16:42:33 Saving...
2017/08/30 16:42:33 Gathering batch of experience...
2017/08/30 16:43:12 batch 318: mean=32.187500 stddev=12.068651 entropy=0.195482 frames=7950 count=16
2017/08/30 16:43:12 Training policy...
2017/08/30 16:43:17 tune 0: objective=0.139478 reg=0.001955 prune=0
2017/08/30 16:43:19 step 0: objective=0.139478 reg=0.001955
2017/08/30 16:43:20 step 1: objective=0.139607 reg=0.001954
2017/08/30 16:43:22 step 2: objective=0.139721 reg=0.001955
2017/08/30 16:43:23 step 3: objective=0.139800 reg=0.001955
2017/08/30 16:43:25 step 4: objective=0.139889 reg=0.001955
2017/08/30 16:43:26 step 5: objective=0.139961 reg=0.001956
2017/08/30 16:43:28 step 6: objective=0.140014 reg=0.001957
2017/08/30 16:43:29 step 7: objective=0.140072 reg=0.001956
2017/08/30 16:43:29 Training value function...
2017/08/30 16:43:33 step 0: mse=0.219040 step=0.050000
2017/08/30 16:43:34 step 1: mse=0.217885 step=0.050000
2017/08/30 16:43:35 step 2: mse=0.216744 step=0.050000
2017/08/30 16:43:37 step 3: mse=0.215836 step=0.050000
2017/08/30 16:43:38 step 4: mse=0.214166 step=0.050000
2017/08/30 16:43:39 step 5: mse=0.213105 step=0.050000
2017/08/30 16:43:41 step 6: mse=0.212085 step=0.050000
2017/08/30 16:43:42 step 7: mse=0.211212 step=0.050000
2017/08/30 16:43:42 Saving...
2017/08/30 16:43:42 Gathering batch of experience...
2017/08/30 16:44:21 batch 319: mean=29.470588 stddev=11.056633 entropy=0.196850 frames=7817 count=17
2017/08/30 16:44:21 Training policy...
2017/08/30 16:44:26 tune 0: objective=0.119158 reg=0.001969 prune=0
2017/08/30 16:44:27 step 0: objective=0.119158 reg=0.001969
2017/08/30 16:44:29 step 1: objective=0.119222 reg=0.001969
2017/08/30 16:44:30 step 2: objective=0.119315 reg=0.001968
2017/08/30 16:44:32 step 3: objective=0.119403 reg=0.001968
2017/08/30 16:44:33 step 4: objective=0.119499 reg=0.001967
2017/08/30 16:44:34 step 5: objective=0.119638 reg=0.001966
2017/08/30 16:44:36 step 6: objective=0.119731 reg=0.001965
2017/08/30 16:44:37 step 7: objective=0.119770 reg=0.001965
2017/08/30 16:44:37 Training value function...
2017/08/30 16:44:41 step 0: mse=0.222883 step=0.050000
2017/08/30 16:44:42 step 1: mse=0.223381 step=0.050000
2017/08/30 16:44:44 step 2: mse=0.223780 step=0.050000
2017/08/30 16:44:45 step 3: mse=0.224090 step=0.050000
2017/08/30 16:44:46 step 4: mse=0.224464 step=0.050000
2017/08/30 16:44:48 step 5: mse=0.224887 step=0.050000
2017/08/30 16:44:49 step 6: mse=0.225181 step=0.050000
2017/08/30 16:44:50 step 7: mse=0.225612 step=0.050000
2017/08/30 16:44:50 Saving...
2017/08/30 16:44:50 Gathering batch of experience...
2017/08/30 16:45:29 batch 320: mean=31.375000 stddev=11.174049 entropy=0.195252 frames=7773 count=16
2017/08/30 16:45:29 Training policy...
2017/08/30 16:45:34 tune 0: objective=0.133042 reg=0.001953 prune=0
2017/08/30 16:45:35 step 0: objective=0.133042 reg=0.001953
2017/08/30 16:45:36 step 1: objective=0.133139 reg=0.001952
2017/08/30 16:45:38 step 2: objective=0.133227 reg=0.001952
2017/08/30 16:45:39 step 3: objective=0.133316 reg=0.001952
2017/08/30 16:45:41 step 4: objective=0.133372 reg=0.001952
2017/08/30 16:45:42 step 5: objective=0.133436 reg=0.001952
2017/08/30 16:45:44 step 6: objective=0.133541 reg=0.001952
2017/08/30 16:45:45 step 7: objective=0.133669 reg=0.001952
2017/08/30 16:45:45 Training value function...
2017/08/30 16:45:49 step 0: mse=0.219681 step=0.050000
2017/08/30 16:45:50 step 1: mse=0.219170 step=0.050000
2017/08/30 16:45:51 step 2: mse=0.218856 step=0.050000
2017/08/30 16:45:53 step 3: mse=0.218685 step=0.050000
2017/08/30 16:45:54 step 4: mse=0.218302 step=0.050000
2017/08/30 16:45:55 step 5: mse=0.217948 step=0.050000
2017/08/30 16:45:57 step 6: mse=0.217867 step=0.050000
2017/08/30 16:45:58 step 7: mse=0.217782 step=0.050000
2017/08/30 16:45:58 Saving...
2017/08/30 16:45:58 Gathering batch of experience...
2017/08/30 16:46:37 batch 321: mean=35.200000 stddev=7.782031 entropy=0.194524 frames=8162 count=15
2017/08/30 16:46:37 Training policy...
2017/08/30 16:46:43 tune 0: objective=0.139643 reg=0.001945 prune=0
2017/08/30 16:46:45 step 0: objective=0.139643 reg=0.001945
2017/08/30 16:46:46 step 1: objective=0.139693 reg=0.001945
2017/08/30 16:46:48 step 2: objective=0.139740 reg=0.001944
2017/08/30 16:46:50 step 3: objective=0.139830 reg=0.001945
2017/08/30 16:46:52 step 4: objective=0.139894 reg=0.001944
2017/08/30 16:46:54 step 5: objective=0.139957 reg=0.001943
2017/08/30 16:46:56 step 6: objective=0.140034 reg=0.001944
2017/08/30 16:46:57 step 7: objective=0.140082 reg=0.001944
2017/08/30 16:46:57 Training value function...
2017/08/30 16:47:01 step 0: mse=0.215339 step=0.050000
2017/08/30 16:47:03 step 1: mse=0.213538 step=0.050000
2017/08/30 16:47:04 step 2: mse=0.212387 step=0.050000
2017/08/30 16:47:06 step 3: mse=0.211091 step=0.050000
2017/08/30 16:47:07 step 4: mse=0.209846 step=0.050000
2017/08/30 16:47:09 step 5: mse=0.208685 step=0.050000
2017/08/30 16:47:11 step 6: mse=0.207544 step=0.050000
2017/08/30 16:47:12 step 7: mse=0.206490 step=0.050000
2017/08/30 16:47:12 Saving...
2017/08/30 16:47:12 Gathering batch of experience...
2017/08/30 16:47:52 batch 322: mean=29.176471 stddev=12.391816 entropy=0.198048 frames=7678 count=17
2017/08/30 16:47:52 Training policy...
2017/08/30 16:47:56 tune 0: objective=0.125445 reg=0.001980 prune=0
2017/08/30 16:47:58 step 0: objective=0.125445 reg=0.001980
2017/08/30 16:47:59 step 1: objective=0.125527 reg=0.001982
2017/08/30 16:48:01 step 2: objective=0.125617 reg=0.001981
2017/08/30 16:48:02 step 3: objective=0.125709 reg=0.001982
2017/08/30 16:48:04 step 4: objective=0.125816 reg=0.001982
2017/08/30 16:48:05 step 5: objective=0.125895 reg=0.001982
2017/08/30 16:48:07 step 6: objective=0.125953 reg=0.001981
2017/08/30 16:48:08 step 7: objective=0.126008 reg=0.001981
2017/08/30 16:48:08 Training value function...
2017/08/30 16:48:11 step 0: mse=0.210269 step=0.050000
2017/08/30 16:48:13 step 1: mse=0.210820 step=0.050000
2017/08/30 16:48:14 step 2: mse=0.211357 step=0.050000
2017/08/30 16:48:15 step 3: mse=0.211895 step=0.050000
2017/08/30 16:48:17 step 4: mse=0.212259 step=0.050000
2017/08/30 16:48:18 step 5: mse=0.212732 step=0.050000
2017/08/30 16:48:20 step 6: mse=0.213082 step=0.050000
2017/08/30 16:48:21 step 7: mse=0.213279 step=0.050000
2017/08/30 16:48:21 Saving...
2017/08/30 16:48:21 Gathering batch of experience...
2017/08/30 16:49:00 batch 323: mean=34.200000 stddev=7.626270 entropy=0.194399 frames=7922 count=15
2017/08/30 16:49:00 Training policy...
2017/08/30 16:49:05 tune 0: objective=0.136567 reg=0.001944 prune=0
2017/08/30 16:49:06 step 0: objective=0.136567 reg=0.001944
2017/08/30 16:49:08 step 1: objective=0.136676 reg=0.001943
2017/08/30 16:49:10 step 2: objective=0.136806 reg=0.001942
2017/08/30 16:49:11 step 3: objective=0.136914 reg=0.001942
2017/08/30 16:49:13 step 4: objective=0.136993 reg=0.001942
2017/08/30 16:49:14 step 5: objective=0.137145 reg=0.001942
2017/08/30 16:49:16 step 6: objective=0.137190 reg=0.001941
2017/08/30 16:49:17 step 7: objective=0.137234 reg=0.001940
2017/08/30 16:49:17 Training value function...
2017/08/30 16:49:20 step 0: mse=0.210724 step=0.050000
2017/08/30 16:49:22 step 1: mse=0.209990 step=0.050000
2017/08/30 16:49:23 step 2: mse=0.209024 step=0.050000
2017/08/30 16:49:25 step 3: mse=0.208076 step=0.050000
2017/08/30 16:49:26 step 4: mse=0.207341 step=0.050000
2017/08/30 16:49:27 step 5: mse=0.206878 step=0.050000
2017/08/30 16:49:29 step 6: mse=0.205989 step=0.050000
2017/08/30 16:49:30 step 7: mse=0.205027 step=0.050000
2017/08/30 16:49:30 Saving...
2017/08/30 16:49:30 Gathering batch of experience...
2017/08/30 16:50:12 batch 324: mean=33.117647 stddev=11.473152 entropy=0.191793 frames=8688 count=17
2017/08/30 16:50:12 Training policy...
2017/08/30 16:50:17 tune 0: objective=0.135532 reg=0.001918 prune=0
2017/08/30 16:50:19 step 0: objective=0.135532 reg=0.001918
2017/08/30 16:50:21 step 1: objective=0.135620 reg=0.001918
2017/08/30 16:50:22 step 2: objective=0.135696 reg=0.001918
2017/08/30 16:50:24 step 3: objective=0.135761 reg=0.001919
2017/08/30 16:50:26 step 4: objective=0.135860 reg=0.001921
2017/08/30 16:50:27 step 5: objective=0.135942 reg=0.001922
2017/08/30 16:50:29 step 6: objective=0.136017 reg=0.001923
2017/08/30 16:50:31 step 7: objective=0.136067 reg=0.001924
2017/08/30 16:50:31 Training value function...
2017/08/30 16:50:34 step 0: mse=0.204412 step=0.050000
2017/08/30 16:50:36 step 1: mse=0.203758 step=0.050000
2017/08/30 16:50:37 step 2: mse=0.203375 step=0.050000
2017/08/30 16:50:39 step 3: mse=0.202860 step=0.050000
2017/08/30 16:50:40 step 4: mse=0.202364 step=0.050000
2017/08/30 16:50:42 step 5: mse=0.201974 step=0.050000
2017/08/30 16:50:43 step 6: mse=0.201658 step=0.050000
2017/08/30 16:50:45 step 7: mse=0.201338 step=0.050000
2017/08/30 16:50:45 Saving...
2017/08/30 16:50:45 Gathering batch of experience...
2017/08/30 16:51:26 batch 325: mean=28.315789 stddev=14.242459 entropy=0.190039 frames=8322 count=19
2017/08/30 16:51:26 Training policy...
2017/08/30 16:51:31 tune 0: objective=0.125122 reg=0.001900 prune=0
2017/08/30 16:51:33 step 0: objective=0.125122 reg=0.001900
2017/08/30 16:51:35 step 1: objective=0.125210 reg=0.001900
2017/08/30 16:51:36 step 2: objective=0.125275 reg=0.001901
2017/08/30 16:51:38 step 3: objective=0.125344 reg=0.001901
2017/08/30 16:51:40 step 4: objective=0.125398 reg=0.001900
2017/08/30 16:51:41 step 5: objective=0.125458 reg=0.001900
2017/08/30 16:51:43 step 6: objective=0.125510 reg=0.001900
2017/08/30 16:51:44 step 7: objective=0.125627 reg=0.001900
2017/08/30 16:51:44 Training value function...
2017/08/30 16:51:48 step 0: mse=0.209002 step=0.050000
2017/08/30 16:51:49 step 1: mse=0.209380 step=0.050000
2017/08/30 16:51:51 step 2: mse=0.209718 step=0.050000
2017/08/30 16:51:52 step 3: mse=0.210391 step=0.050000
2017/08/30 16:51:54 step 4: mse=0.210756 step=0.050000
2017/08/30 16:51:55 step 5: mse=0.211071 step=0.050000
2017/08/30 16:51:57 step 6: mse=0.211454 step=0.050000
2017/08/30 16:51:58 step 7: mse=0.211670 step=0.050000
2017/08/30 16:51:58 Saving...
2017/08/30 16:51:58 Gathering batch of experience...
2017/08/30 16:52:39 batch 326: mean=32.588235 stddev=10.494025 entropy=0.194125 frames=8576 count=17
2017/08/30 16:52:39 Training policy...
2017/08/30 16:52:44 tune 0: objective=0.131132 reg=0.001941 prune=0
2017/08/30 16:52:46 step 0: objective=0.131132 reg=0.001941
2017/08/30 16:52:47 step 1: objective=0.131198 reg=0.001941
2017/08/30 16:52:49 step 2: objective=0.131271 reg=0.001941
2017/08/30 16:52:51 step 3: objective=0.131326 reg=0.001941
2017/08/30 16:52:52 step 4: objective=0.131383 reg=0.001940
2017/08/30 16:52:54 step 5: objective=0.131442 reg=0.001941
2017/08/30 16:52:56 step 6: objective=0.131489 reg=0.001941
2017/08/30 16:52:57 step 7: objective=0.131543 reg=0.001942
2017/08/30 16:52:57 Training value function...
2017/08/30 16:53:01 step 0: mse=0.210753 step=0.050000
2017/08/30 16:53:03 step 1: mse=0.210839 step=0.050000
2017/08/30 16:53:04 step 2: mse=0.210977 step=0.050000
2017/08/30 16:53:06 step 3: mse=0.210804 step=0.050000
2017/08/30 16:53:07 step 4: mse=0.210492 step=0.050000
2017/08/30 16:53:09 step 5: mse=0.210632 step=0.050000
2017/08/30 16:53:10 step 6: mse=0.210642 step=0.050000
2017/08/30 16:53:12 step 7: mse=0.210723 step=0.050000
2017/08/30 16:53:12 Saving...
2017/08/30 16:53:12 Gathering batch of experience...
2017/08/30 16:53:48 batch 327: mean=29.066667 stddev=15.022058 entropy=0.190490 frames=6743 count=15
2017/08/30 16:53:48 Training policy...
2017/08/30 16:53:52 tune 0: objective=0.130634 reg=0.001905 prune=0
2017/08/30 16:53:53 step 0: objective=0.130634 reg=0.001905
2017/08/30 16:53:54 step 1: objective=0.130702 reg=0.001905
2017/08/30 16:53:56 step 2: objective=0.130781 reg=0.001904
2017/08/30 16:53:57 step 3: objective=0.130883 reg=0.001905
2017/08/30 16:53:58 step 4: objective=0.130978 reg=0.001904
2017/08/30 16:54:00 step 5: objective=0.131039 reg=0.001904
2017/08/30 16:54:01 step 6: objective=0.131111 reg=0.001904
2017/08/30 16:54:02 step 7: objective=0.131215 reg=0.001905
2017/08/30 16:54:02 Training value function...
2017/08/30 16:54:05 step 0: mse=0.210734 step=0.050000
2017/08/30 16:54:06 step 1: mse=0.210221 step=0.050000
2017/08/30 16:54:07 step 2: mse=0.210214 step=0.050000
2017/08/30 16:54:08 step 3: mse=0.209623 step=0.050000
2017/08/30 16:54:10 step 4: mse=0.209102 step=0.050000
2017/08/30 16:54:11 step 5: mse=0.208784 step=0.050000
2017/08/30 16:54:12 step 6: mse=0.208686 step=0.050000
2017/08/30 16:54:13 step 7: mse=0.208530 step=0.050000
2017/08/30 16:54:13 Saving...
2017/08/30 16:54:13 Gathering batch of experience...
2017/08/30 16:54:52 batch 328: mean=25.842105 stddev=14.206237 entropy=0.193472 frames=7636 count=19
2017/08/30 16:54:52 Training policy...
2017/08/30 16:54:57 tune 0: objective=0.119683 reg=0.001935 prune=0
2017/08/30 16:54:58 step 0: objective=0.119683 reg=0.001935
2017/08/30 16:55:00 step 1: objective=0.119774 reg=0.001936
2017/08/30 16:55:01 step 2: objective=0.119870 reg=0.001937
2017/08/30 16:55:03 step 3: objective=0.119943 reg=0.001938
2017/08/30 16:55:04 step 4: objective=0.120020 reg=0.001938
2017/08/30 16:55:06 step 5: objective=0.120076 reg=0.001939
2017/08/30 16:55:07 step 6: objective=0.120212 reg=0.001938
2017/08/30 16:55:09 step 7: objective=0.120305 reg=0.001938
2017/08/30 16:55:09 Training value function...
2017/08/30 16:55:12 step 0: mse=0.222210 step=0.050000
2017/08/30 16:55:13 step 1: mse=0.223077 step=0.050000
2017/08/30 16:55:15 step 2: mse=0.223951 step=0.050000
2017/08/30 16:55:16 step 3: mse=0.224588 step=0.050000
2017/08/30 16:55:17 step 4: mse=0.225417 step=0.050000
2017/08/30 16:55:19 step 5: mse=0.226156 step=0.050000
2017/08/30 16:55:20 step 6: mse=0.226747 step=0.050000
2017/08/30 16:55:21 step 7: mse=0.227480 step=0.050000
2017/08/30 16:55:21 Saving...
2017/08/30 16:55:21 Gathering batch of experience...
2017/08/30 16:56:00 batch 329: mean=26.578947 stddev=13.978614 entropy=0.195796 frames=7840 count=19
2017/08/30 16:56:00 Training policy...
2017/08/30 16:56:05 tune 0: objective=0.124515 reg=0.001958 prune=0
2017/08/30 16:56:06 step 0: objective=0.124516 reg=0.001958
2017/08/30 16:56:08 step 1: objective=0.124604 reg=0.001957
2017/08/30 16:56:09 step 2: objective=0.124730 reg=0.001958
2017/08/30 16:56:11 step 3: objective=0.124814 reg=0.001957
2017/08/30 16:56:12 step 4: objective=0.124921 reg=0.001955
2017/08/30 16:56:14 step 5: objective=0.125062 reg=0.001954
2017/08/30 16:56:15 step 6: objective=0.125119 reg=0.001954
2017/08/30 16:56:17 step 7: objective=0.125232 reg=0.001953
2017/08/30 16:56:17 Training value function...
2017/08/30 16:56:20 step 0: mse=0.221838 step=0.050000
2017/08/30 16:56:22 step 1: mse=0.222306 step=0.050000
2017/08/30 16:56:23 step 2: mse=0.222729 step=0.050000
2017/08/30 16:56:24 step 3: mse=0.223400 step=0.050000
2017/08/30 16:56:26 step 4: mse=0.223731 step=0.050000
2017/08/30 16:56:27 step 5: mse=0.223908 step=0.050000
2017/08/30 16:56:29 step 6: mse=0.224431 step=0.050000
2017/08/30 16:56:30 step 7: mse=0.224860 step=0.050000
2017/08/30 16:56:30 Saving...
2017/08/30 16:56:30 Gathering batch of experience...
2017/08/30 16:57:08 batch 330: mean=27.777778 stddev=13.628221 entropy=0.197048 frames=7745 count=18
2017/08/30 16:57:08 Training policy...
2017/08/30 16:57:13 tune 0: objective=0.131305 reg=0.001970 prune=0
2017/08/30 16:57:15 step 0: objective=0.131305 reg=0.001970
2017/08/30 16:57:16 step 1: objective=0.131412 reg=0.001971
2017/08/30 16:57:18 step 2: objective=0.131498 reg=0.001971
2017/08/30 16:57:19 step 3: objective=0.131584 reg=0.001970
2017/08/30 16:57:21 step 4: objective=0.131722 reg=0.001970
2017/08/30 16:57:22 step 5: objective=0.131872 reg=0.001970
2017/08/30 16:57:24 step 6: objective=0.131929 reg=0.001970
2017/08/30 16:57:25 step 7: objective=0.132017 reg=0.001970
2017/08/30 16:57:25 Training value function...
2017/08/30 16:57:29 step 0: mse=0.221518 step=0.050000
2017/08/30 16:57:30 step 1: mse=0.221358 step=0.050000
2017/08/30 16:57:31 step 2: mse=0.220819 step=0.050000
2017/08/30 16:57:32 step 3: mse=0.220154 step=0.050000
2017/08/30 16:57:34 step 4: mse=0.220012 step=0.050000
2017/08/30 16:57:35 step 5: mse=0.219538 step=0.050000
2017/08/30 16:57:37 step 6: mse=0.219575 step=0.050000
2017/08/30 16:57:38 step 7: mse=0.219238 step=0.050000
2017/08/30 16:57:38 Saving...
2017/08/30 16:57:38 Gathering batch of experience...
2017/08/30 16:58:20 batch 331: mean=31.444444 stddev=10.894556 entropy=0.194523 frames=8767 count=18
2017/08/30 16:58:20 Training policy...
2017/08/30 16:58:26 tune 0: objective=0.135912 reg=0.001945 prune=0
2017/08/30 16:58:27 step 0: objective=0.135912 reg=0.001945
2017/08/30 16:58:29 step 1: objective=0.136030 reg=0.001945
2017/08/30 16:58:31 step 2: objective=0.136112 reg=0.001944
2017/08/30 16:58:32 step 3: objective=0.136189 reg=0.001944
2017/08/30 16:58:34 step 4: objective=0.136266 reg=0.001944
2017/08/30 16:58:36 step 5: objective=0.136341 reg=0.001944
2017/08/30 16:58:37 step 6: objective=0.136458 reg=0.001944
2017/08/30 16:58:39 step 7: objective=0.136537 reg=0.001944
2017/08/30 16:58:39 Training value function...
2017/08/30 16:58:43 step 0: mse=0.225193 step=0.050000
2017/08/30 16:58:44 step 1: mse=0.224294 step=0.050000
2017/08/30 16:58:46 step 2: mse=0.223707 step=0.050000
2017/08/30 16:58:47 step 3: mse=0.223027 step=0.050000
2017/08/30 16:58:49 step 4: mse=0.222250 step=0.050000
2017/08/30 16:58:50 step 5: mse=0.221504 step=0.050000
2017/08/30 16:58:52 step 6: mse=0.220918 step=0.050000
2017/08/30 16:58:54 step 7: mse=0.220193 step=0.050000
2017/08/30 16:58:54 Saving...
2017/08/30 16:58:54 Gathering batch of experience...
2017/08/30 16:59:34 batch 332: mean=25.700000 stddev=13.824254 entropy=0.195513 frames=8000 count=20
2017/08/30 16:59:34 Training policy...
2017/08/30 16:59:39 tune 0: objective=0.121389 reg=0.001955 prune=0
2017/08/30 16:59:41 step 0: objective=0.121389 reg=0.001955
2017/08/30 16:59:42 step 1: objective=0.121541 reg=0.001955
2017/08/30 16:59:44 step 2: objective=0.121682 reg=0.001954
2017/08/30 16:59:45 step 3: objective=0.121767 reg=0.001953
2017/08/30 16:59:47 step 4: objective=0.121883 reg=0.001953
2017/08/30 16:59:48 step 5: objective=0.121940 reg=0.001952
2017/08/30 16:59:50 step 6: objective=0.122021 reg=0.001951
2017/08/30 16:59:51 step 7: objective=0.122126 reg=0.001950
2017/08/30 16:59:51 Training value function...
2017/08/30 16:59:55 step 0: mse=0.223937 step=0.050000
2017/08/30 16:59:56 step 1: mse=0.224143 step=0.050000
2017/08/30 16:59:58 step 2: mse=0.224341 step=0.050000
2017/08/30 16:59:59 step 3: mse=0.224839 step=0.050000
2017/08/30 17:00:00 step 4: mse=0.225207 step=0.050000
2017/08/30 17:00:02 step 5: mse=0.225748 step=0.050000
2017/08/30 17:00:03 step 6: mse=0.226059 step=0.050000
2017/08/30 17:00:05 step 7: mse=0.226540 step=0.050000
2017/08/30 17:00:05 Saving...
2017/08/30 17:00:05 Gathering batch of experience...
2017/08/30 17:00:43 batch 333: mean=28.705882 stddev=10.937064 entropy=0.196002 frames=7568 count=17
2017/08/30 17:00:43 Training policy...
2017/08/30 17:00:47 tune 0: objective=0.131164 reg=0.001960 prune=0
2017/08/30 17:00:49 step 0: objective=0.131164 reg=0.001960
2017/08/30 17:00:50 step 1: objective=0.131269 reg=0.001959
2017/08/30 17:00:52 step 2: objective=0.131392 reg=0.001959
2017/08/30 17:00:53 step 3: objective=0.131524 reg=0.001958
2017/08/30 17:00:55 step 4: objective=0.131587 reg=0.001958
2017/08/30 17:00:56 step 5: objective=0.131710 reg=0.001958
2017/08/30 17:00:58 step 6: objective=0.131771 reg=0.001955
2017/08/30 17:00:59 step 7: objective=0.131836 reg=0.001954
2017/08/30 17:00:59 Training value function...
2017/08/30 17:01:02 step 0: mse=0.224216 step=0.050000
2017/08/30 17:01:04 step 1: mse=0.223910 step=0.050000
2017/08/30 17:01:05 step 2: mse=0.223547 step=0.050000
2017/08/30 17:01:06 step 3: mse=0.223362 step=0.050000
2017/08/30 17:01:08 step 4: mse=0.223102 step=0.050000
2017/08/30 17:01:09 step 5: mse=0.222694 step=0.050000
2017/08/30 17:01:10 step 6: mse=0.222591 step=0.050000
2017/08/30 17:01:12 step 7: mse=0.222324 step=0.050000
2017/08/30 17:01:12 Saving...
2017/08/30 17:01:12 Gathering batch of experience...
2017/08/30 17:01:54 batch 334: mean=28.684211 stddev=13.147154 entropy=0.195594 frames=8432 count=19
2017/08/30 17:01:54 Training policy...
2017/08/30 17:01:59 tune 0: objective=0.135024 reg=0.001956 prune=0
2017/08/30 17:02:01 step 0: objective=0.135024 reg=0.001956
2017/08/30 17:02:03 step 1: objective=0.135094 reg=0.001956
2017/08/30 17:02:04 step 2: objective=0.135194 reg=0.001957
2017/08/30 17:02:06 step 3: objective=0.135304 reg=0.001958
2017/08/30 17:02:08 step 4: objective=0.135380 reg=0.001958
2017/08/30 17:02:09 step 5: objective=0.135442 reg=0.001959
2017/08/30 17:02:11 step 6: objective=0.135483 reg=0.001958
2017/08/30 17:02:13 step 7: objective=0.135585 reg=0.001958
2017/08/30 17:02:13 Training value function...
2017/08/30 17:02:16 step 0: mse=0.227099 step=0.050000
2017/08/30 17:02:18 step 1: mse=0.226898 step=0.050000
2017/08/30 17:02:19 step 2: mse=0.226265 step=0.050000
2017/08/30 17:02:21 step 3: mse=0.225530 step=0.050000
2017/08/30 17:02:22 step 4: mse=0.224806 step=0.050000
2017/08/30 17:02:24 step 5: mse=0.224404 step=0.050000
2017/08/30 17:02:25 step 6: mse=0.223746 step=0.050000
2017/08/30 17:02:27 step 7: mse=0.223355 step=0.050000
2017/08/30 17:02:27 Saving...
2017/08/30 17:02:27 Gathering batch of experience...
2017/08/30 17:03:08 batch 335: mean=28.894737 stddev=12.920383 entropy=0.193160 frames=8484 count=19
2017/08/30 17:03:08 Training policy...
2017/08/30 17:03:14 tune 0: objective=0.134683 reg=0.001932 prune=0
2017/08/30 17:03:16 step 0: objective=0.134683 reg=0.001932
2017/08/30 17:03:17 step 1: objective=0.134786 reg=0.001932
2017/08/30 17:03:19 step 2: objective=0.134879 reg=0.001932
2017/08/30 17:03:21 step 3: objective=0.134963 reg=0.001933
2017/08/30 17:03:22 step 4: objective=0.135017 reg=0.001932
2017/08/30 17:03:24 step 5: objective=0.135115 reg=0.001933
2017/08/30 17:03:25 step 6: objective=0.135230 reg=0.001933
2017/08/30 17:03:27 step 7: objective=0.135352 reg=0.001933
2017/08/30 17:03:27 Training value function...
2017/08/30 17:03:31 step 0: mse=0.221906 step=0.050000
2017/08/30 17:03:32 step 1: mse=0.221691 step=0.050000
2017/08/30 17:03:34 step 2: mse=0.221545 step=0.050000
2017/08/30 17:03:35 step 3: mse=0.221370 step=0.050000
2017/08/30 17:03:37 step 4: mse=0.221276 step=0.050000
2017/08/30 17:03:38 step 5: mse=0.221152 step=0.050000
2017/08/30 17:03:40 step 6: mse=0.220519 step=0.050000
2017/08/30 17:03:41 step 7: mse=0.219486 step=0.050000
2017/08/30 17:03:41 Saving...
2017/08/30 17:03:41 Gathering batch of experience...
2017/08/30 17:04:19 batch 336: mean=31.250000 stddev=13.442005 entropy=0.189278 frames=7720 count=16
2017/08/30 17:04:19 Training policy...
2017/08/30 17:04:24 tune 0: objective=0.138136 reg=0.001893 prune=0
2017/08/30 17:04:26 step 0: objective=0.138136 reg=0.001893
2017/08/30 17:04:27 step 1: objective=0.138247 reg=0.001893
2017/08/30 17:04:29 step 2: objective=0.138366 reg=0.001894
2017/08/30 17:04:30 step 3: objective=0.138447 reg=0.001896
2017/08/30 17:04:32 step 4: objective=0.138552 reg=0.001896
2017/08/30 17:04:33 step 5: objective=0.138709 reg=0.001898
2017/08/30 17:04:35 step 6: objective=0.138784 reg=0.001898
2017/08/30 17:04:36 step 7: objective=0.138872 reg=0.001897
2017/08/30 17:04:36 Training value function...
2017/08/30 17:04:39 step 0: mse=0.218786 step=0.050000
2017/08/30 17:04:41 step 1: mse=0.217493 step=0.050000
2017/08/30 17:04:42 step 2: mse=0.216548 step=0.050000
2017/08/30 17:04:43 step 3: mse=0.214799 step=0.050000
2017/08/30 17:04:45 step 4: mse=0.214033 step=0.050000
2017/08/30 17:04:46 step 5: mse=0.213140 step=0.050000
2017/08/30 17:04:47 step 6: mse=0.212040 step=0.050000
2017/08/30 17:04:49 step 7: mse=0.211153 step=0.050000
2017/08/30 17:04:49 Saving...
2017/08/30 17:04:49 Gathering batch of experience...
2017/08/30 17:05:28 batch 337: mean=29.666667 stddev=13.605554 entropy=0.193956 frames=8276 count=18
2017/08/30 17:05:28 Training policy...
2017/08/30 17:05:34 tune 0: objective=0.129276 reg=0.001940 prune=0
2017/08/30 17:05:35 step 0: objective=0.129275 reg=0.001940
2017/08/30 17:05:37 step 1: objective=0.129379 reg=0.001939
2017/08/30 17:05:38 step 2: objective=0.129478 reg=0.001939
2017/08/30 17:05:40 step 3: objective=0.129567 reg=0.001939
2017/08/30 17:05:42 step 4: objective=0.129654 reg=0.001939
2017/08/30 17:05:43 step 5: objective=0.129787 reg=0.001939
2017/08/30 17:05:45 step 6: objective=0.129908 reg=0.001940
2017/08/30 17:05:46 step 7: objective=0.130038 reg=0.001939
2017/08/30 17:05:46 Training value function...
2017/08/30 17:05:50 step 0: mse=0.218204 step=0.050000
2017/08/30 17:05:51 step 1: mse=0.218063 step=0.050000
2017/08/30 17:05:53 step 2: mse=0.218000 step=0.050000
2017/08/30 17:05:54 step 3: mse=0.217836 step=0.050000
2017/08/30 17:05:56 step 4: mse=0.217795 step=0.050000
2017/08/30 17:05:57 step 5: mse=0.217617 step=0.050000
2017/08/30 17:05:59 step 6: mse=0.217263 step=0.050000
2017/08/30 17:06:00 step 7: mse=0.217251 step=0.050000
2017/08/30 17:06:00 Saving...
2017/08/30 17:06:00 Gathering batch of experience...
2017/08/30 17:06:39 batch 338: mean=30.235294 stddev=9.884804 entropy=0.195458 frames=7964 count=17
2017/08/30 17:06:39 Training policy...
2017/08/30 17:06:45 tune 0: objective=0.127440 reg=0.001955 prune=0
2017/08/30 17:06:46 step 0: objective=0.127440 reg=0.001955
2017/08/30 17:06:48 step 1: objective=0.127581 reg=0.001955
2017/08/30 17:06:49 step 2: objective=0.127719 reg=0.001955
2017/08/30 17:06:51 step 3: objective=0.127868 reg=0.001955
2017/08/30 17:06:52 step 4: objective=0.128001 reg=0.001954
2017/08/30 17:06:54 step 5: objective=0.128074 reg=0.001954
2017/08/30 17:06:55 step 6: objective=0.128124 reg=0.001954
2017/08/30 17:06:57 step 7: objective=0.128182 reg=0.001954
2017/08/30 17:06:57 Training value function...
2017/08/30 17:07:00 step 0: mse=0.212909 step=0.050000
2017/08/30 17:07:02 step 1: mse=0.212529 step=0.050000
2017/08/30 17:07:03 step 2: mse=0.212397 step=0.050000
2017/08/30 17:07:05 step 3: mse=0.212340 step=0.050000
2017/08/30 17:07:06 step 4: mse=0.211965 step=0.050000
2017/08/30 17:07:07 step 5: mse=0.211689 step=0.050000
2017/08/30 17:07:09 step 6: mse=0.211562 step=0.050000
2017/08/30 17:07:10 step 7: mse=0.211214 step=0.050000
2017/08/30 17:07:10 Saving...
2017/08/30 17:07:10 Gathering batch of experience...
2017/08/30 17:07:48 batch 339: mean=29.529412 stddev=13.160179 entropy=0.194550 frames=7783 count=17
2017/08/30 17:07:48 Training policy...
2017/08/30 17:07:53 tune 0: objective=0.129548 reg=0.001946 prune=0
2017/08/30 17:07:55 step 0: objective=0.129548 reg=0.001946
2017/08/30 17:07:56 step 1: objective=0.129605 reg=0.001944
2017/08/30 17:07:58 step 2: objective=0.129717 reg=0.001944
2017/08/30 17:07:59 step 3: objective=0.129836 reg=0.001944
2017/08/30 17:08:01 step 4: objective=0.129918 reg=0.001943
2017/08/30 17:08:02 step 5: objective=0.129989 reg=0.001942
2017/08/30 17:08:04 step 6: objective=0.130037 reg=0.001941
2017/08/30 17:08:06 step 7: objective=0.130120 reg=0.001940
2017/08/30 17:08:06 Training value function...
2017/08/30 17:08:09 step 0: mse=0.220779 step=0.050000
2017/08/30 17:08:10 step 1: mse=0.220568 step=0.050000
2017/08/30 17:08:12 step 2: mse=0.220378 step=0.050000
2017/08/30 17:08:13 step 3: mse=0.219938 step=0.050000
2017/08/30 17:08:14 step 4: mse=0.219921 step=0.050000
2017/08/30 17:08:16 step 5: mse=0.219708 step=0.050000
2017/08/30 17:08:17 step 6: mse=0.219569 step=0.050000
2017/08/30 17:08:18 step 7: mse=0.219323 step=0.050000
2017/08/30 17:08:18 Saving...
2017/08/30 17:08:18 Gathering batch of experience...
2017/08/30 17:09:01 batch 340: mean=28.100000 stddev=13.996071 entropy=0.194286 frames=8728 count=20
2017/08/30 17:09:01 Training policy...
2017/08/30 17:09:06 tune 0: objective=0.127175 reg=0.001943 prune=0
2017/08/30 17:09:08 step 0: objective=0.127176 reg=0.001943
2017/08/30 17:09:10 step 1: objective=0.127231 reg=0.001942
2017/08/30 17:09:11 step 2: objective=0.127285 reg=0.001942
2017/08/30 17:09:13 step 3: objective=0.127338 reg=0.001942
2017/08/30 17:09:15 step 4: objective=0.127415 reg=0.001942
2017/08/30 17:09:16 step 5: objective=0.127481 reg=0.001941
2017/08/30 17:09:18 step 6: objective=0.127520 reg=0.001940
2017/08/30 17:09:20 step 7: objective=0.127576 reg=0.001940
2017/08/30 17:09:20 Training value function...
2017/08/30 17:09:23 step 0: mse=0.220359 step=0.050000
2017/08/30 17:09:25 step 1: mse=0.220481 step=0.050000
2017/08/30 17:09:27 step 2: mse=0.220657 step=0.050000
2017/08/30 17:09:28 step 3: mse=0.220645 step=0.050000
2017/08/30 17:09:30 step 4: mse=0.220892 step=0.050000
2017/08/30 17:09:31 step 5: mse=0.220965 step=0.050000
2017/08/30 17:09:33 step 6: mse=0.220983 step=0.050000
2017/08/30 17:09:34 step 7: mse=0.221142 step=0.050000
2017/08/30 17:09:34 Saving...
2017/08/30 17:09:34 Gathering batch of experience...
2017/08/30 17:10:13 batch 341: mean=34.133333 stddev=9.844570 entropy=0.189823 frames=7916 count=15
2017/08/30 17:10:13 Training policy...
2017/08/30 17:10:18 tune 0: objective=0.138550 reg=0.001898 prune=0
2017/08/30 17:10:19 step 0: objective=0.138550 reg=0.001898
2017/08/30 17:10:21 step 1: objective=0.138638 reg=0.001897
2017/08/30 17:10:22 step 2: objective=0.138719 reg=0.001897
2017/08/30 17:10:24 step 3: objective=0.138791 reg=0.001897
2017/08/30 17:10:26 step 4: objective=0.138837 reg=0.001897
2017/08/30 17:10:27 step 5: objective=0.138882 reg=0.001897
2017/08/30 17:10:29 step 6: objective=0.138951 reg=0.001897
2017/08/30 17:10:30 step 7: objective=0.139009 reg=0.001896
2017/08/30 17:10:30 Training value function...
2017/08/30 17:10:34 step 0: mse=0.214982 step=0.050000
2017/08/30 17:10:35 step 1: mse=0.213862 step=0.050000
2017/08/30 17:10:36 step 2: mse=0.212645 step=0.050000
2017/08/30 17:10:38 step 3: mse=0.211620 step=0.050000
2017/08/30 17:10:39 step 4: mse=0.210668 step=0.050000
2017/08/30 17:10:40 step 5: mse=0.209862 step=0.050000
2017/08/30 17:10:42 step 6: mse=0.209368 step=0.050000
2017/08/30 17:10:43 step 7: mse=0.208861 step=0.050000
2017/08/30 17:10:43 Saving...
2017/08/30 17:10:43 Gathering batch of experience...
2017/08/30 17:11:18 batch 342: mean=26.294118 stddev=11.756173 entropy=0.197204 frames=6958 count=17
2017/08/30 17:11:18 Training policy...
2017/08/30 17:11:23 tune 0: objective=0.115516 reg=0.001972 prune=0
2017/08/30 17:11:24 step 0: objective=0.115517 reg=0.001972
2017/08/30 17:11:25 step 1: objective=0.115662 reg=0.001972
2017/08/30 17:11:27 step 2: objective=0.115735 reg=0.001971
2017/08/30 17:11:28 step 3: objective=0.115809 reg=0.001971
2017/08/30 17:11:29 step 4: objective=0.115878 reg=0.001970
2017/08/30 17:11:31 step 5: objective=0.115959 reg=0.001971
2017/08/30 17:11:32 step 6: objective=0.116049 reg=0.001971
2017/08/30 17:11:33 step 7: objective=0.116188 reg=0.001970
2017/08/30 17:11:33 Training value function...
2017/08/30 17:11:36 step 0: mse=0.216632 step=0.050000
2017/08/30 17:11:37 step 1: mse=0.217759 step=0.050000
2017/08/30 17:11:39 step 2: mse=0.218863 step=0.050000
2017/08/30 17:11:40 step 3: mse=0.219964 step=0.050000
2017/08/30 17:11:41 step 4: mse=0.221015 step=0.050000
2017/08/30 17:11:42 step 5: mse=0.222034 step=0.050000
2017/08/30 17:11:43 step 6: mse=0.222864 step=0.050000
2017/08/30 17:11:45 step 7: mse=0.223706 step=0.050000
2017/08/30 17:11:45 Saving...
2017/08/30 17:11:45 Gathering batch of experience...
2017/08/30 17:12:26 batch 343: mean=29.833333 stddev=12.859281 entropy=0.193679 frames=8314 count=18
2017/08/30 17:12:26 Training policy...
2017/08/30 17:12:31 tune 0: objective=0.136261 reg=0.001937 prune=0
2017/08/30 17:12:33 step 0: objective=0.136261 reg=0.001937
2017/08/30 17:12:34 step 1: objective=0.136332 reg=0.001936
2017/08/30 17:12:36 step 2: objective=0.136411 reg=0.001936
2017/08/30 17:12:38 step 3: objective=0.136459 reg=0.001936
2017/08/30 17:12:39 step 4: objective=0.136551 reg=0.001936
2017/08/30 17:12:41 step 5: objective=0.136598 reg=0.001935
2017/08/30 17:12:42 step 6: objective=0.136691 reg=0.001935
2017/08/30 17:12:44 step 7: objective=0.136791 reg=0.001933
2017/08/30 17:12:44 Training value function...
2017/08/30 17:12:48 step 0: mse=0.223200 step=0.050000
2017/08/30 17:12:49 step 1: mse=0.222792 step=0.050000
2017/08/30 17:12:51 step 2: mse=0.221818 step=0.050000
2017/08/30 17:12:52 step 3: mse=0.221166 step=0.050000
2017/08/30 17:12:53 step 4: mse=0.220933 step=0.050000
2017/08/30 17:12:55 step 5: mse=0.219890 step=0.050000
2017/08/30 17:12:56 step 6: mse=0.219160 step=0.050000
2017/08/30 17:12:58 step 7: mse=0.218580 step=0.050000
2017/08/30 17:12:58 Saving...
2017/08/30 17:12:58 Gathering batch of experience...
2017/08/30 17:13:39 batch 344: mean=29.777778 stddev=14.234370 entropy=0.192475 frames=8302 count=18
2017/08/30 17:13:39 Training policy...
2017/08/30 17:13:44 tune 0: objective=0.134788 reg=0.001925 prune=0
2017/08/30 17:13:46 step 0: objective=0.134788 reg=0.001925
2017/08/30 17:13:47 step 1: objective=0.134897 reg=0.001924
2017/08/30 17:13:49 step 2: objective=0.134978 reg=0.001924
2017/08/30 17:13:51 step 3: objective=0.135089 reg=0.001925
2017/08/30 17:13:52 step 4: objective=0.135171 reg=0.001925
2017/08/30 17:13:54 step 5: objective=0.135269 reg=0.001925
2017/08/30 17:13:55 step 6: objective=0.135319 reg=0.001925
2017/08/30 17:13:57 step 7: objective=0.135370 reg=0.001924
2017/08/30 17:13:57 Training value function...
2017/08/30 17:14:01 step 0: mse=0.220420 step=0.050000
2017/08/30 17:14:02 step 1: mse=0.219767 step=0.050000
2017/08/30 17:14:04 step 2: mse=0.219237 step=0.050000
2017/08/30 17:14:05 step 3: mse=0.218650 step=0.050000
2017/08/30 17:14:06 step 4: mse=0.218139 step=0.050000
2017/08/30 17:14:08 step 5: mse=0.217581 step=0.050000
2017/08/30 17:14:09 step 6: mse=0.217258 step=0.050000
2017/08/30 17:14:11 step 7: mse=0.216680 step=0.050000
2017/08/30 17:14:11 Saving...
2017/08/30 17:14:11 Gathering batch of experience...
2017/08/30 17:14:46 batch 345: mean=27.187500 stddev=15.685259 entropy=0.190555 frames=6732 count=16
2017/08/30 17:14:46 Training policy...
2017/08/30 17:14:51 tune 0: objective=0.131414 reg=0.001906 prune=0
2017/08/30 17:14:52 step 0: objective=0.131414 reg=0.001906
2017/08/30 17:14:53 step 1: objective=0.131559 reg=0.001907
2017/08/30 17:14:55 step 2: objective=0.131749 reg=0.001908
2017/08/30 17:14:56 step 3: objective=0.131943 reg=0.001911
2017/08/30 17:14:57 step 4: objective=0.132097 reg=0.001912
2017/08/30 17:14:59 step 5: objective=0.132215 reg=0.001913
2017/08/30 17:15:00 step 6: objective=0.132285 reg=0.001913
2017/08/30 17:15:01 step 7: objective=0.132331 reg=0.001913
2017/08/30 17:15:01 Training value function...
2017/08/30 17:15:04 step 0: mse=0.225431 step=0.050000
2017/08/30 17:15:05 step 1: mse=0.224488 step=0.050000
2017/08/30 17:15:06 step 2: mse=0.223666 step=0.050000
2017/08/30 17:15:07 step 3: mse=0.222780 step=0.050000
2017/08/30 17:15:09 step 4: mse=0.222539 step=0.050000
2017/08/30 17:15:10 step 5: mse=0.222361 step=0.050000
2017/08/30 17:15:11 step 6: mse=0.222045 step=0.050000
2017/08/30 17:15:12 step 7: mse=0.221573 step=0.050000
2017/08/30 17:15:12 Saving...
2017/08/30 17:15:12 Gathering batch of experience...
2017/08/30 17:15:51 batch 346: mean=30.941176 stddev=11.819578 entropy=0.189223 frames=8128 count=17
2017/08/30 17:15:51 Training policy...
2017/08/30 17:15:57 tune 0: objective=0.134990 reg=0.001892 prune=0
2017/08/30 17:15:58 step 0: objective=0.134991 reg=0.001892
2017/08/30 17:16:00 step 1: objective=0.135047 reg=0.001892
2017/08/30 17:16:01 step 2: objective=0.135112 reg=0.001892
2017/08/30 17:16:03 step 3: objective=0.135169 reg=0.001891
2017/08/30 17:16:05 step 4: objective=0.135250 reg=0.001891
2017/08/30 17:16:06 step 5: objective=0.135343 reg=0.001890
2017/08/30 17:16:08 step 6: objective=0.135456 reg=0.001890
2017/08/30 17:16:09 step 7: objective=0.135578 reg=0.001889
2017/08/30 17:16:09 Training value function...
2017/08/30 17:16:13 step 0: mse=0.212656 step=0.050000
2017/08/30 17:16:14 step 1: mse=0.211939 step=0.050000
2017/08/30 17:16:16 step 2: mse=0.211240 step=0.050000
2017/08/30 17:16:17 step 3: mse=0.210594 step=0.050000
2017/08/30 17:16:18 step 4: mse=0.209929 step=0.050000
2017/08/30 17:16:20 step 5: mse=0.209690 step=0.050000
2017/08/30 17:16:21 step 6: mse=0.208958 step=0.050000
2017/08/30 17:16:22 step 7: mse=0.208339 step=0.050000
2017/08/30 17:16:22 Saving...
2017/08/30 17:16:23 Gathering batch of experience...
2017/08/30 17:17:01 batch 347: mean=33.200000 stddev=11.273568 entropy=0.191293 frames=7707 count=15
2017/08/30 17:17:01 Training policy...
2017/08/30 17:17:06 tune 0: objective=0.134779 reg=0.001913 prune=0
2017/08/30 17:17:07 step 0: objective=0.134780 reg=0.001913
2017/08/30 17:17:09 step 1: objective=0.134869 reg=0.001912
2017/08/30 17:17:10 step 2: objective=0.134976 reg=0.001911
2017/08/30 17:17:12 step 3: objective=0.135034 reg=0.001910
2017/08/30 17:17:13 step 4: objective=0.135088 reg=0.001911
2017/08/30 17:17:15 step 5: objective=0.135135 reg=0.001911
2017/08/30 17:17:16 step 6: objective=0.135178 reg=0.001911
2017/08/30 17:17:18 step 7: objective=0.135246 reg=0.001910
2017/08/30 17:17:18 Training value function...
2017/08/30 17:17:21 step 0: mse=0.215200 step=0.050000
2017/08/30 17:17:22 step 1: mse=0.214680 step=0.050000
2017/08/30 17:17:24 step 2: mse=0.214206 step=0.050000
2017/08/30 17:17:25 step 3: mse=0.214006 step=0.050000
2017/08/30 17:17:26 step 4: mse=0.213831 step=0.050000
2017/08/30 17:17:28 step 5: mse=0.212986 step=0.050000
2017/08/30 17:17:29 step 6: mse=0.212253 step=0.050000
2017/08/30 17:17:30 step 7: mse=0.211646 step=0.050000
2017/08/30 17:17:30 Saving...
2017/08/30 17:17:30 Gathering batch of experience...
2017/08/30 17:18:10 batch 348: mean=30.588235 stddev=10.781568 entropy=0.191711 frames=8072 count=17
2017/08/30 17:18:10 Training policy...
2017/08/30 17:18:15 tune 0: objective=0.124494 reg=0.001917 prune=0
2017/08/30 17:18:17 step 0: objective=0.124495 reg=0.001917
2017/08/30 17:18:18 step 1: objective=0.124580 reg=0.001917
2017/08/30 17:18:20 step 2: objective=0.124677 reg=0.001917
2017/08/30 17:18:21 step 3: objective=0.124747 reg=0.001917
2017/08/30 17:18:23 step 4: objective=0.124812 reg=0.001916
2017/08/30 17:18:25 step 5: objective=0.124903 reg=0.001916
2017/08/30 17:18:26 step 6: objective=0.125031 reg=0.001915
2017/08/30 17:18:28 step 7: objective=0.125088 reg=0.001915
2017/08/30 17:18:28 Training value function...
2017/08/30 17:18:31 step 0: mse=0.211316 step=0.050000
2017/08/30 17:18:33 step 1: mse=0.211799 step=0.050000
2017/08/30 17:18:34 step 2: mse=0.212136 step=0.050000
2017/08/30 17:18:35 step 3: mse=0.212493 step=0.050000
2017/08/30 17:18:37 step 4: mse=0.212949 step=0.050000
2017/08/30 17:18:38 step 5: mse=0.213370 step=0.050000
2017/08/30 17:18:40 step 6: mse=0.213842 step=0.050000
2017/08/30 17:18:41 step 7: mse=0.214181 step=0.050000
2017/08/30 17:18:41 Saving...
2017/08/30 17:18:41 Gathering batch of experience...
2017/08/30 17:19:18 batch 349: mean=31.785714 stddev=12.479575 entropy=0.190542 frames=6864 count=14
2017/08/30 17:19:18 Training policy...
2017/08/30 17:19:22 tune 0: objective=0.137838 reg=0.001905 prune=0
2017/08/30 17:19:23 step 0: objective=0.137838 reg=0.001905
2017/08/30 17:19:25 step 1: objective=0.137919 reg=0.001905
2017/08/30 17:19:26 step 2: objective=0.138018 reg=0.001905
2017/08/30 17:19:27 step 3: objective=0.138128 reg=0.001905
2017/08/30 17:19:29 step 4: objective=0.138247 reg=0.001905
2017/08/30 17:19:30 step 5: objective=0.138339 reg=0.001905
2017/08/30 17:19:31 step 6: objective=0.138437 reg=0.001906
2017/08/30 17:19:33 step 7: objective=0.138511 reg=0.001906
2017/08/30 17:19:33 Training value function...
2017/08/30 17:19:36 step 0: mse=0.210955 step=0.050000
2017/08/30 17:19:37 step 1: mse=0.209758 step=0.050000
2017/08/30 17:19:38 step 2: mse=0.208916 step=0.050000
2017/08/30 17:19:39 step 3: mse=0.208041 step=0.050000
2017/08/30 17:19:40 step 4: mse=0.207134 step=0.050000
2017/08/30 17:19:41 step 5: mse=0.206434 step=0.050000
2017/08/30 17:19:43 step 6: mse=0.205109 step=0.050000
2017/08/30 17:19:44 step 7: mse=0.204224 step=0.050000
2017/08/30 17:19:44 Saving...
2017/08/30 17:19:44 Gathering batch of experience...
2017/08/30 17:20:21 batch 350: mean=30.800000 stddev=10.258005 entropy=0.190701 frames=7186 count=15
2017/08/30 17:20:21 Training policy...
2017/08/30 17:20:25 tune 0: objective=0.123231 reg=0.001907 prune=0
2017/08/30 17:20:27 step 0: objective=0.123231 reg=0.001907
2017/08/30 17:20:28 step 1: objective=0.123427 reg=0.001907
2017/08/30 17:20:29 step 2: objective=0.123619 reg=0.001907
2017/08/30 17:20:31 step 3: objective=0.123686 reg=0.001908
2017/08/30 17:20:32 step 4: objective=0.123765 reg=0.001908
2017/08/30 17:20:34 step 5: objective=0.123871 reg=0.001908
2017/08/30 17:20:35 step 6: objective=0.124028 reg=0.001908
2017/08/30 17:20:36 step 7: objective=0.124133 reg=0.001908
2017/08/30 17:20:36 Training value function...
2017/08/30 17:20:39 step 0: mse=0.212952 step=0.050000
2017/08/30 17:20:41 step 1: mse=0.213517 step=0.050000
2017/08/30 17:20:42 step 2: mse=0.214076 step=0.050000
2017/08/30 17:20:43 step 3: mse=0.214324 step=0.050000
2017/08/30 17:20:44 step 4: mse=0.214810 step=0.050000
2017/08/30 17:20:46 step 5: mse=0.215095 step=0.050000
2017/08/30 17:20:47 step 6: mse=0.215500 step=0.050000
2017/08/30 17:20:48 step 7: mse=0.215779 step=0.050000
2017/08/30 17:20:48 Saving...
2017/08/30 17:20:48 Gathering batch of experience...
2017/08/30 17:21:28 batch 351: mean=27.947368 stddev=13.311940 entropy=0.190613 frames=8262 count=19
2017/08/30 17:21:28 Training policy...
2017/08/30 17:21:34 tune 0: objective=0.124620 reg=0.001906 prune=0
2017/08/30 17:21:35 step 0: objective=0.124620 reg=0.001906
2017/08/30 17:21:37 step 1: objective=0.124729 reg=0.001906
2017/08/30 17:21:38 step 2: objective=0.124847 reg=0.001905
2017/08/30 17:21:40 step 3: objective=0.124981 reg=0.001905
2017/08/30 17:21:42 step 4: objective=0.125081 reg=0.001906
2017/08/30 17:21:43 step 5: objective=0.125177 reg=0.001906
2017/08/30 17:21:45 step 6: objective=0.125257 reg=0.001906
2017/08/30 17:21:47 step 7: objective=0.125312 reg=0.001906
2017/08/30 17:21:47 Training value function...
2017/08/30 17:21:50 step 0: mse=0.216100 step=0.050000
2017/08/30 17:21:52 step 1: mse=0.216496 step=0.050000
2017/08/30 17:21:53 step 2: mse=0.216936 step=0.050000
2017/08/30 17:21:55 step 3: mse=0.217223 step=0.050000
2017/08/30 17:21:56 step 4: mse=0.217549 step=0.050000
2017/08/30 17:21:57 step 5: mse=0.217989 step=0.050000
2017/08/30 17:21:59 step 6: mse=0.218404 step=0.050000
2017/08/30 17:22:00 step 7: mse=0.218760 step=0.050000
2017/08/30 17:22:00 Saving...
2017/08/30 17:22:00 Gathering batch of experience...
2017/08/30 17:22:38 batch 352: mean=26.500000 stddev=12.945398 entropy=0.192626 frames=7393 count=18
2017/08/30 17:22:38 Training policy...
2017/08/30 17:22:43 tune 0: objective=0.124777 reg=0.001926 prune=0
2017/08/30 17:22:44 step 0: objective=0.124777 reg=0.001926
2017/08/30 17:22:46 step 1: objective=0.124876 reg=0.001926
2017/08/30 17:22:47 step 2: objective=0.124983 reg=0.001927
2017/08/30 17:22:49 step 3: objective=0.125066 reg=0.001927
2017/08/30 17:22:50 step 4: objective=0.125145 reg=0.001928
2017/08/30 17:22:52 step 5: objective=0.125227 reg=0.001929
2017/08/30 17:22:53 step 6: objective=0.125298 reg=0.001930
2017/08/30 17:22:54 step 7: objective=0.125406 reg=0.001931
2017/08/30 17:22:54 Training value function...
2017/08/30 17:22:58 step 0: mse=0.214736 step=0.050000
2017/08/30 17:22:59 step 1: mse=0.215246 step=0.050000
2017/08/30 17:23:00 step 2: mse=0.215581 step=0.050000
2017/08/30 17:23:01 step 3: mse=0.215885 step=0.050000
2017/08/30 17:23:03 step 4: mse=0.216284 step=0.050000
2017/08/30 17:23:04 step 5: mse=0.216698 step=0.050000
2017/08/30 17:23:05 step 6: mse=0.216816 step=0.050000
2017/08/30 17:23:07 step 7: mse=0.217327 step=0.050000
2017/08/30 17:23:07 Saving...
2017/08/30 17:23:07 Gathering batch of experience...
2017/08/30 17:23:46 batch 353: mean=32.500000 stddev=11.869077 entropy=0.191589 frames=8026 count=16
2017/08/30 17:23:46 Training policy...
2017/08/30 17:23:51 tune 0: objective=0.144027 reg=0.001916 prune=0
2017/08/30 17:23:52 step 0: objective=0.144027 reg=0.001916
2017/08/30 17:23:54 step 1: objective=0.144090 reg=0.001915
2017/08/30 17:23:56 step 2: objective=0.144176 reg=0.001914
2017/08/30 17:23:57 step 3: objective=0.144270 reg=0.001914
2017/08/30 17:23:59 step 4: objective=0.144370 reg=0.001912
2017/08/30 17:24:00 step 5: objective=0.144470 reg=0.001912
2017/08/30 17:24:02 step 6: objective=0.144590 reg=0.001910
2017/08/30 17:24:04 step 7: objective=0.144626 reg=0.001910
2017/08/30 17:24:04 Training value function...
2017/08/30 17:24:07 step 0: mse=0.224676 step=0.050000
2017/08/30 17:24:08 step 1: mse=0.222946 step=0.050000
2017/08/30 17:24:10 step 2: mse=0.221328 step=0.050000
2017/08/30 17:24:11 step 3: mse=0.219707 step=0.050000
2017/08/30 17:24:12 step 4: mse=0.217813 step=0.050000
2017/08/30 17:24:14 step 5: mse=0.216620 step=0.050000
2017/08/30 17:24:15 step 6: mse=0.214933 step=0.050000
2017/08/30 17:24:17 step 7: mse=0.213922 step=0.050000
2017/08/30 17:24:17 Saving...
2017/08/30 17:24:17 Gathering batch of experience...
2017/08/30 17:24:56 batch 354: mean=32.500000 stddev=10.828204 entropy=0.190799 frames=8033 count=16
2017/08/30 17:24:56 Training policy...
2017/08/30 17:25:01 tune 0: objective=0.134870 reg=0.001908 prune=0
2017/08/30 17:25:02 step 0: objective=0.134870 reg=0.001908
2017/08/30 17:25:04 step 1: objective=0.134954 reg=0.001908
2017/08/30 17:25:06 step 2: objective=0.135040 reg=0.001908
2017/08/30 17:25:07 step 3: objective=0.135134 reg=0.001907
2017/08/30 17:25:09 step 4: objective=0.135229 reg=0.001906
2017/08/30 17:25:10 step 5: objective=0.135317 reg=0.001905
2017/08/30 17:25:12 step 6: objective=0.135391 reg=0.001905
2017/08/30 17:25:13 step 7: objective=0.135469 reg=0.001904
2017/08/30 17:25:13 Training value function...
2017/08/30 17:25:17 step 0: mse=0.210734 step=0.050000
2017/08/30 17:25:18 step 1: mse=0.209927 step=0.050000
2017/08/30 17:25:20 step 2: mse=0.209071 step=0.050000
2017/08/30 17:25:21 step 3: mse=0.208267 step=0.050000
2017/08/30 17:25:22 step 4: mse=0.207944 step=0.050000
2017/08/30 17:25:24 step 5: mse=0.207392 step=0.050000
2017/08/30 17:25:25 step 6: mse=0.206629 step=0.050000
2017/08/30 17:25:27 step 7: mse=0.206411 step=0.050000
2017/08/30 17:25:27 Saving...
2017/08/30 17:25:27 Gathering batch of experience...
2017/08/30 17:26:06 batch 355: mean=32.625000 stddev=11.910473 entropy=0.190221 frames=8077 count=16
2017/08/30 17:26:06 Training policy...
2017/08/30 17:26:11 tune 0: objective=0.133244 reg=0.001902 prune=0
2017/08/30 17:26:13 step 0: objective=0.133244 reg=0.001902
2017/08/30 17:26:14 step 1: objective=0.133315 reg=0.001903
2017/08/30 17:26:16 step 2: objective=0.133364 reg=0.001903
2017/08/30 17:26:18 step 3: objective=0.133483 reg=0.001902
2017/08/30 17:26:19 step 4: objective=0.133561 reg=0.001902
2017/08/30 17:26:21 step 5: objective=0.133595 reg=0.001903
2017/08/30 17:26:22 step 6: objective=0.133633 reg=0.001903
2017/08/30 17:26:24 step 7: objective=0.133686 reg=0.001903
2017/08/30 17:26:24 Training value function...
2017/08/30 17:26:27 step 0: mse=0.210642 step=0.050000
2017/08/30 17:26:29 step 1: mse=0.210030 step=0.050000
2017/08/30 17:26:30 step 2: mse=0.209360 step=0.050000
2017/08/30 17:26:31 step 3: mse=0.208733 step=0.050000
2017/08/30 17:26:33 step 4: mse=0.208010 step=0.050000
2017/08/30 17:26:34 step 5: mse=0.207245 step=0.050000
2017/08/30 17:26:36 step 6: mse=0.206625 step=0.050000
2017/08/30 17:26:37 step 7: mse=0.206086 step=0.050000
2017/08/30 17:26:37 Saving...
2017/08/30 17:26:37 Gathering batch of experience...
2017/08/30 17:27:16 batch 356: mean=28.500000 stddev=11.567435 entropy=0.194774 frames=7941 count=18
2017/08/30 17:27:16 Training policy...
2017/08/30 17:27:21 tune 0: objective=0.123563 reg=0.001948 prune=0
2017/08/30 17:27:23 step 0: objective=0.123563 reg=0.001948
2017/08/30 17:27:24 step 1: objective=0.123623 reg=0.001948
2017/08/30 17:27:26 step 2: objective=0.123722 reg=0.001947
2017/08/30 17:27:27 step 3: objective=0.123829 reg=0.001947
2017/08/30 17:27:29 step 4: objective=0.123914 reg=0.001947
2017/08/30 17:27:30 step 5: objective=0.124013 reg=0.001947
2017/08/30 17:27:32 step 6: objective=0.124131 reg=0.001946
2017/08/30 17:27:34 step 7: objective=0.124231 reg=0.001945
2017/08/30 17:27:34 Training value function...
2017/08/30 17:27:37 step 0: mse=0.204485 step=0.050000
2017/08/30 17:27:38 step 1: mse=0.205015 step=0.050000
2017/08/30 17:27:40 step 2: mse=0.205676 step=0.050000
2017/08/30 17:27:41 step 3: mse=0.205805 step=0.050000
2017/08/30 17:27:42 step 4: mse=0.206094 step=0.050000
2017/08/30 17:27:44 step 5: mse=0.206480 step=0.050000
2017/08/30 17:27:45 step 6: mse=0.206992 step=0.050000
2017/08/30 17:27:47 step 7: mse=0.207476 step=0.050000
2017/08/30 17:27:47 Saving...
2017/08/30 17:27:47 Gathering batch of experience...
2017/08/30 17:28:26 batch 357: mean=28.944444 stddev=13.048934 entropy=0.195435 frames=8044 count=18
2017/08/30 17:28:26 Training policy...
2017/08/30 17:28:31 tune 0: objective=0.132763 reg=0.001954 prune=0
2017/08/30 17:28:33 step 0: objective=0.132763 reg=0.001954
2017/08/30 17:28:34 step 1: objective=0.132861 reg=0.001955
2017/08/30 17:28:36 step 2: objective=0.132954 reg=0.001956
2017/08/30 17:28:37 step 3: objective=0.132999 reg=0.001956
2017/08/30 17:28:39 step 4: objective=0.133083 reg=0.001957
2017/08/30 17:28:41 step 5: objective=0.133144 reg=0.001957
2017/08/30 17:28:42 step 6: objective=0.133194 reg=0.001957
2017/08/30 17:28:44 step 7: objective=0.133259 reg=0.001958
2017/08/30 17:28:44 Training value function...
2017/08/30 17:28:47 step 0: mse=0.209346 step=0.050000
2017/08/30 17:28:49 step 1: mse=0.209215 step=0.050000
2017/08/30 17:28:50 step 2: mse=0.209201 step=0.050000
2017/08/30 17:28:51 step 3: mse=0.209124 step=0.050000
2017/08/30 17:28:53 step 4: mse=0.208885 step=0.050000
2017/08/30 17:28:54 step 5: mse=0.208749 step=0.050000
2017/08/30 17:28:56 step 6: mse=0.208748 step=0.050000
2017/08/30 17:28:57 step 7: mse=0.208766 step=0.050000
2017/08/30 17:28:57 Saving...
2017/08/30 17:28:57 Gathering batch of experience...
2017/08/30 17:29:34 batch 358: mean=31.133333 stddev=12.230381 entropy=0.186660 frames=7243 count=15
2017/08/30 17:29:34 Training policy...
2017/08/30 17:29:38 tune 0: objective=0.130616 reg=0.001867 prune=0
2017/08/30 17:29:40 step 0: objective=0.130617 reg=0.001867
2017/08/30 17:29:41 step 1: objective=0.130680 reg=0.001866
2017/08/30 17:29:43 step 2: objective=0.130740 reg=0.001866
2017/08/30 17:29:44 step 3: objective=0.130801 reg=0.001865
2017/08/30 17:29:45 step 4: objective=0.130884 reg=0.001865
2017/08/30 17:29:47 step 5: objective=0.130938 reg=0.001863
2017/08/30 17:29:48 step 6: objective=0.130992 reg=0.001864
2017/08/30 17:29:50 step 7: objective=0.131048 reg=0.001863
2017/08/30 17:29:50 Training value function...
2017/08/30 17:29:53 step 0: mse=0.217735 step=0.050000
2017/08/30 17:29:54 step 1: mse=0.217395 step=0.050000
2017/08/30 17:29:55 step 2: mse=0.217133 step=0.050000
2017/08/30 17:29:56 step 3: mse=0.217127 step=0.050000
2017/08/30 17:29:58 step 4: mse=0.216919 step=0.050000
2017/08/30 17:29:59 step 5: mse=0.216910 step=0.050000
2017/08/30 17:30:00 step 6: mse=0.216840 step=0.050000
2017/08/30 17:30:02 step 7: mse=0.216895 step=0.050000
2017/08/30 17:30:02 Saving...
2017/08/30 17:30:02 Gathering batch of experience...
2017/08/30 17:30:41 batch 359: mean=29.055556 stddev=11.796761 entropy=0.194710 frames=8093 count=18
2017/08/30 17:30:41 Training policy...
2017/08/30 17:30:46 tune 0: objective=0.127550 reg=0.001947 prune=0
2017/08/30 17:30:48 step 0: objective=0.127550 reg=0.001947
2017/08/30 17:30:49 step 1: objective=0.127612 reg=0.001947
2017/08/30 17:30:51 step 2: objective=0.127687 reg=0.001947
2017/08/30 17:30:52 step 3: objective=0.127735 reg=0.001948
2017/08/30 17:30:54 step 4: objective=0.127812 reg=0.001948
2017/08/30 17:30:56 step 5: objective=0.127888 reg=0.001948
2017/08/30 17:30:57 step 6: objective=0.127931 reg=0.001948
2017/08/30 17:30:59 step 7: objective=0.128004 reg=0.001947
2017/08/30 17:30:59 Training value function...
2017/08/30 17:31:02 step 0: mse=0.213977 step=0.050000
2017/08/30 17:31:04 step 1: mse=0.214178 step=0.050000
2017/08/30 17:31:05 step 2: mse=0.214441 step=0.050000
2017/08/30 17:31:06 step 3: mse=0.214422 step=0.050000
2017/08/30 17:31:08 step 4: mse=0.214405 step=0.050000
2017/08/30 17:31:09 step 5: mse=0.214535 step=0.050000
2017/08/30 17:31:11 step 6: mse=0.214707 step=0.050000
2017/08/30 17:31:12 step 7: mse=0.214978 step=0.050000
2017/08/30 17:31:12 Saving...
2017/08/30 17:31:12 Gathering batch of experience...
2017/08/30 17:31:51 batch 360: mean=34.866667 stddev=7.940333 entropy=0.192122 frames=8074 count=15
2017/08/30 17:31:51 Training policy...
2017/08/30 17:31:56 tune 0: objective=0.140391 reg=0.001921 prune=0
2017/08/30 17:31:58 step 0: objective=0.140391 reg=0.001921
2017/08/30 17:32:00 step 1: objective=0.140476 reg=0.001920
2017/08/30 17:32:01 step 2: objective=0.140605 reg=0.001921
2017/08/30 17:32:03 step 3: objective=0.140678 reg=0.001921
2017/08/30 17:32:04 step 4: objective=0.140783 reg=0.001921
2017/08/30 17:32:06 step 5: objective=0.140876 reg=0.001921
2017/08/30 17:32:07 step 6: objective=0.140924 reg=0.001920
2017/08/30 17:32:09 step 7: objective=0.140956 reg=0.001921
2017/08/30 17:32:09 Training value function...
2017/08/30 17:32:12 step 0: mse=0.218063 step=0.050000
2017/08/30 17:32:14 step 1: mse=0.216310 step=0.050000
2017/08/30 17:32:15 step 2: mse=0.214971 step=0.050000
2017/08/30 17:32:17 step 3: mse=0.213621 step=0.050000
2017/08/30 17:32:18 step 4: mse=0.212589 step=0.050000
2017/08/30 17:32:19 step 5: mse=0.211422 step=0.050000
2017/08/30 17:32:21 step 6: mse=0.209837 step=0.050000
2017/08/30 17:32:22 step 7: mse=0.208727 step=0.050000
2017/08/30 17:32:22 Saving...
2017/08/30 17:32:22 Gathering batch of experience...
2017/08/30 17:33:00 batch 361: mean=30.625000 stddev=12.139167 entropy=0.187489 frames=7582 count=16
2017/08/30 17:33:00 Training policy...
2017/08/30 17:33:05 tune 0: objective=0.128528 reg=0.001875 prune=0
2017/08/30 17:33:06 step 0: objective=0.128529 reg=0.001875
2017/08/30 17:33:08 step 1: objective=0.128612 reg=0.001875
2017/08/30 17:33:09 step 2: objective=0.128680 reg=0.001875
2017/08/30 17:33:11 step 3: objective=0.128759 reg=0.001875
2017/08/30 17:33:12 step 4: objective=0.128836 reg=0.001876
2017/08/30 17:33:14 step 5: objective=0.128908 reg=0.001876
2017/08/30 17:33:15 step 6: objective=0.128986 reg=0.001876
2017/08/30 17:33:17 step 7: objective=0.129044 reg=0.001876
2017/08/30 17:33:17 Training value function...
2017/08/30 17:33:20 step 0: mse=0.211835 step=0.050000
2017/08/30 17:33:21 step 1: mse=0.211704 step=0.050000
2017/08/30 17:33:23 step 2: mse=0.211738 step=0.050000
2017/08/30 17:33:24 step 3: mse=0.211913 step=0.050000
2017/08/30 17:33:25 step 4: mse=0.212120 step=0.050000
2017/08/30 17:33:27 step 5: mse=0.212272 step=0.050000
2017/08/30 17:33:28 step 6: mse=0.212307 step=0.050000
2017/08/30 17:33:29 step 7: mse=0.212440 step=0.050000
2017/08/30 17:33:29 Saving...
2017/08/30 17:33:29 Gathering batch of experience...
2017/08/30 17:34:10 batch 362: mean=25.700000 stddev=14.625662 entropy=0.195394 frames=7964 count=20
2017/08/30 17:34:10 Training policy...
2017/08/30 17:34:15 tune 0: objective=0.122980 reg=0.001954 prune=0
2017/08/30 17:34:16 step 0: objective=0.122981 reg=0.001954
2017/08/30 17:34:18 step 1: objective=0.123050 reg=0.001954
2017/08/30 17:34:19 step 2: objective=0.123155 reg=0.001954
2017/08/30 17:34:21 step 3: objective=0.123260 reg=0.001954
2017/08/30 17:34:23 step 4: objective=0.123311 reg=0.001953
2017/08/30 17:34:24 step 5: objective=0.123377 reg=0.001953
2017/08/30 17:34:26 step 6: objective=0.123444 reg=0.001953
2017/08/30 17:34:27 step 7: objective=0.123515 reg=0.001953
2017/08/30 17:34:27 Training value function...
2017/08/30 17:34:31 step 0: mse=0.215980 step=0.050000
2017/08/30 17:34:32 step 1: mse=0.216318 step=0.050000
2017/08/30 17:34:34 step 2: mse=0.216823 step=0.050000
2017/08/30 17:34:35 step 3: mse=0.217381 step=0.050000
2017/08/30 17:34:36 step 4: mse=0.217905 step=0.050000
2017/08/30 17:34:38 step 5: mse=0.218454 step=0.050000
2017/08/30 17:34:39 step 6: mse=0.218883 step=0.050000
2017/08/30 17:34:40 step 7: mse=0.219373 step=0.050000
2017/08/30 17:34:40 Saving...
2017/08/30 17:34:41 Gathering batch of experience...
2017/08/30 17:35:20 batch 363: mean=29.111111 stddev=12.631042 entropy=0.189417 frames=8114 count=18
2017/08/30 17:35:20 Training policy...
2017/08/30 17:35:25 tune 0: objective=0.129228 reg=0.001894 prune=0
2017/08/30 17:35:26 step 0: objective=0.129228 reg=0.001894
2017/08/30 17:35:28 step 1: objective=0.129309 reg=0.001894
2017/08/30 17:35:30 step 2: objective=0.129386 reg=0.001893
2017/08/30 17:35:31 step 3: objective=0.129486 reg=0.001893
2017/08/30 17:35:33 step 4: objective=0.129552 reg=0.001891
2017/08/30 17:35:34 step 5: objective=0.129635 reg=0.001891
2017/08/30 17:35:36 step 6: objective=0.129693 reg=0.001891
2017/08/30 17:35:38 step 7: objective=0.129764 reg=0.001891
2017/08/30 17:35:38 Training value function...
2017/08/30 17:35:41 step 0: mse=0.217024 step=0.050000
2017/08/30 17:35:43 step 1: mse=0.217281 step=0.050000
2017/08/30 17:35:44 step 2: mse=0.217276 step=0.050000
2017/08/30 17:35:45 step 3: mse=0.217125 step=0.050000
2017/08/30 17:35:47 step 4: mse=0.217201 step=0.050000
2017/08/30 17:35:48 step 5: mse=0.217294 step=0.050000
2017/08/30 17:35:50 step 6: mse=0.217449 step=0.050000
2017/08/30 17:35:51 step 7: mse=0.217492 step=0.050000
2017/08/30 17:35:51 Saving...
2017/08/30 17:35:51 Gathering batch of experience...
2017/08/30 17:36:28 batch 364: mean=33.214286 stddev=11.558414 entropy=0.188474 frames=7182 count=14
2017/08/30 17:36:28 Training policy...
2017/08/30 17:36:33 tune 0: objective=0.138383 reg=0.001885 prune=0
2017/08/30 17:36:35 step 0: objective=0.138383 reg=0.001885
2017/08/30 17:36:36 step 1: objective=0.138491 reg=0.001885
2017/08/30 17:36:37 step 2: objective=0.138593 reg=0.001885
2017/08/30 17:36:39 step 3: objective=0.138677 reg=0.001885
2017/08/30 17:36:40 step 4: objective=0.138785 reg=0.001884
2017/08/30 17:36:42 step 5: objective=0.138899 reg=0.001884
2017/08/30 17:36:43 step 6: objective=0.138983 reg=0.001884
2017/08/30 17:36:44 step 7: objective=0.139132 reg=0.001884
2017/08/30 17:36:44 Training value function...
2017/08/30 17:36:47 step 0: mse=0.220341 step=0.050000
2017/08/30 17:36:49 step 1: mse=0.219478 step=0.050000
2017/08/30 17:36:50 step 2: mse=0.218028 step=0.050000
2017/08/30 17:36:51 step 3: mse=0.217141 step=0.050000
2017/08/30 17:36:52 step 4: mse=0.215973 step=0.050000
2017/08/30 17:36:54 step 5: mse=0.215001 step=0.050000
2017/08/30 17:36:55 step 6: mse=0.214088 step=0.050000
2017/08/30 17:36:56 step 7: mse=0.213517 step=0.050000
2017/08/30 17:36:56 Saving...
2017/08/30 17:36:56 Gathering batch of experience...
2017/08/30 17:37:32 batch 365: mean=27.125000 stddev=13.554865 entropy=0.191272 frames=6725 count=16
2017/08/30 17:37:32 Training policy...
2017/08/30 17:37:37 tune 0: objective=0.123224 reg=0.001913 prune=0
2017/08/30 17:37:38 step 0: objective=0.123224 reg=0.001913
2017/08/30 17:37:39 step 1: objective=0.123299 reg=0.001912
2017/08/30 17:37:41 step 2: objective=0.123354 reg=0.001911
2017/08/30 17:37:42 step 3: objective=0.123438 reg=0.001910
2017/08/30 17:37:43 step 4: objective=0.123510 reg=0.001909
2017/08/30 17:37:45 step 5: objective=0.123583 reg=0.001909
2017/08/30 17:37:46 step 6: objective=0.123647 reg=0.001909
2017/08/30 17:37:47 step 7: objective=0.123710 reg=0.001908
2017/08/30 17:37:47 Training value function...
2017/08/30 17:37:50 step 0: mse=0.217764 step=0.050000
2017/08/30 17:37:51 step 1: mse=0.218522 step=0.050000
2017/08/30 17:37:52 step 2: mse=0.218852 step=0.050000
2017/08/30 17:37:54 step 3: mse=0.219243 step=0.050000
2017/08/30 17:37:55 step 4: mse=0.219846 step=0.050000
2017/08/30 17:37:56 step 5: mse=0.220302 step=0.050000
2017/08/30 17:37:57 step 6: mse=0.220541 step=0.050000
2017/08/30 17:37:58 step 7: mse=0.220843 step=0.050000
2017/08/30 17:37:58 Saving...
2017/08/30 17:37:58 Gathering batch of experience...
2017/08/30 17:38:37 batch 366: mean=28.111111 stddev=13.847940 entropy=0.190590 frames=7832 count=18
2017/08/30 17:38:37 Training policy...
2017/08/30 17:38:42 tune 0: objective=0.130502 reg=0.001906 prune=0
2017/08/30 17:38:44 step 0: objective=0.130502 reg=0.001906
2017/08/30 17:38:46 step 1: objective=0.130555 reg=0.001907
2017/08/30 17:38:47 step 2: objective=0.130617 reg=0.001906
2017/08/30 17:38:49 step 3: objective=0.130685 reg=0.001907
2017/08/30 17:38:50 step 4: objective=0.130784 reg=0.001907
2017/08/30 17:38:52 step 5: objective=0.130833 reg=0.001907
2017/08/30 17:38:53 step 6: objective=0.130911 reg=0.001908
2017/08/30 17:38:55 step 7: objective=0.130967 reg=0.001907
2017/08/30 17:38:55 Training value function...
2017/08/30 17:38:58 step 0: mse=0.220180 step=0.050000
2017/08/30 17:38:59 step 1: mse=0.219823 step=0.050000
2017/08/30 17:39:01 step 2: mse=0.219702 step=0.050000
2017/08/30 17:39:02 step 3: mse=0.219235 step=0.050000
2017/08/30 17:39:04 step 4: mse=0.219172 step=0.050000
2017/08/30 17:39:05 step 5: mse=0.219040 step=0.050000
2017/08/30 17:39:06 step 6: mse=0.219063 step=0.050000
2017/08/30 17:39:08 step 7: mse=0.218890 step=0.050000
2017/08/30 17:39:08 Saving...
2017/08/30 17:39:08 Gathering batch of experience...
2017/08/30 17:39:46 batch 367: mean=29.588235 stddev=12.136764 entropy=0.190585 frames=7793 count=17
2017/08/30 17:39:46 Training policy...
2017/08/30 17:39:51 tune 0: objective=0.130818 reg=0.001906 prune=0
2017/08/30 17:39:53 step 0: objective=0.130818 reg=0.001906
2017/08/30 17:39:54 step 1: objective=0.130914 reg=0.001905
2017/08/30 17:39:56 step 2: objective=0.131044 reg=0.001904
2017/08/30 17:39:58 step 3: objective=0.131096 reg=0.001905
2017/08/30 17:39:59 step 4: objective=0.131228 reg=0.001904
2017/08/30 17:40:01 step 5: objective=0.131279 reg=0.001904
2017/08/30 17:40:02 step 6: objective=0.131332 reg=0.001904
2017/08/30 17:40:04 step 7: objective=0.131399 reg=0.001903
2017/08/30 17:40:04 Training value function...
2017/08/30 17:40:07 step 0: mse=0.218421 step=0.050000
2017/08/30 17:40:08 step 1: mse=0.218418 step=0.050000
2017/08/30 17:40:10 step 2: mse=0.218399 step=0.050000
2017/08/30 17:40:11 step 3: mse=0.218281 step=0.050000
2017/08/30 17:40:12 step 4: mse=0.218070 step=0.050000
2017/08/30 17:40:14 step 5: mse=0.218156 step=0.050000
2017/08/30 17:40:15 step 6: mse=0.218018 step=0.050000
2017/08/30 17:40:17 step 7: mse=0.218063 step=0.050000
2017/08/30 17:40:17 Saving...
2017/08/30 17:40:17 Gathering batch of experience...
2017/08/30 17:40:56 batch 368: mean=30.705882 stddev=11.033450 entropy=0.191753 frames=8063 count=17
2017/08/30 17:40:56 Training policy...
2017/08/30 17:41:02 tune 0: objective=0.133955 reg=0.001918 prune=0
2017/08/30 17:41:03 step 0: objective=0.133955 reg=0.001918
2017/08/30 17:41:05 step 1: objective=0.134085 reg=0.001917
2017/08/30 17:41:06 step 2: objective=0.134222 reg=0.001916
2017/08/30 17:41:08 step 3: objective=0.134314 reg=0.001915
2017/08/30 17:41:10 step 4: objective=0.134410 reg=0.001914
2017/08/30 17:41:11 step 5: objective=0.134544 reg=0.001913
2017/08/30 17:41:13 step 6: objective=0.134629 reg=0.001913
2017/08/30 17:41:14 step 7: objective=0.134764 reg=0.001911
2017/08/30 17:41:14 Training value function...
2017/08/30 17:41:18 step 0: mse=0.219105 step=0.050000
2017/08/30 17:41:19 step 1: mse=0.218646 step=0.050000
2017/08/30 17:41:21 step 2: mse=0.217953 step=0.050000
2017/08/30 17:41:22 step 3: mse=0.217578 step=0.050000
2017/08/30 17:41:23 step 4: mse=0.217243 step=0.050000
2017/08/30 17:41:25 step 5: mse=0.216676 step=0.050000
2017/08/30 17:41:26 step 6: mse=0.215618 step=0.050000
2017/08/30 17:41:28 step 7: mse=0.215284 step=0.050000
2017/08/30 17:41:28 Saving...
2017/08/30 17:41:28 Gathering batch of experience...
2017/08/30 17:42:09 batch 369: mean=29.052632 stddev=13.492585 entropy=0.189760 frames=8550 count=19
2017/08/30 17:42:09 Training policy...
2017/08/30 17:42:15 tune 0: objective=0.131307 reg=0.001898 prune=0
2017/08/30 17:42:16 step 0: objective=0.131307 reg=0.001898
2017/08/30 17:42:18 step 1: objective=0.131460 reg=0.001898
2017/08/30 17:42:20 step 2: objective=0.131559 reg=0.001898
2017/08/30 17:42:21 step 3: objective=0.131614 reg=0.001898
2017/08/30 17:42:23 step 4: objective=0.131662 reg=0.001898
2017/08/30 17:42:25 step 5: objective=0.131721 reg=0.001899
2017/08/30 17:42:26 step 6: objective=0.131797 reg=0.001899
2017/08/30 17:42:28 step 7: objective=0.131840 reg=0.001899
2017/08/30 17:42:28 Training value function...
2017/08/30 17:42:32 step 0: mse=0.223442 step=0.050000
2017/08/30 17:42:33 step 1: mse=0.222787 step=0.050000
2017/08/30 17:42:35 step 2: mse=0.222169 step=0.050000
2017/08/30 17:42:36 step 3: mse=0.221811 step=0.050000
2017/08/30 17:42:38 step 4: mse=0.221584 step=0.050000
2017/08/30 17:42:39 step 5: mse=0.221262 step=0.050000
2017/08/30 17:42:41 step 6: mse=0.220778 step=0.050000
2017/08/30 17:42:42 step 7: mse=0.220763 step=0.050000
2017/08/30 17:42:42 Saving...
2017/08/30 17:42:42 Gathering batch of experience...
2017/08/30 17:43:21 batch 370: mean=25.600000 stddev=15.357083 entropy=0.187143 frames=7965 count=20
2017/08/30 17:43:21 Training policy...
2017/08/30 17:43:26 tune 0: objective=0.122812 reg=0.001871 prune=0
2017/08/30 17:43:28 step 0: objective=0.122813 reg=0.001871
2017/08/30 17:43:29 step 1: objective=0.122928 reg=0.001872
2017/08/30 17:43:31 step 2: objective=0.123028 reg=0.001872
2017/08/30 17:43:33 step 3: objective=0.123129 reg=0.001872
2017/08/30 17:43:34 step 4: objective=0.123221 reg=0.001871
2017/08/30 17:43:36 step 5: objective=0.123257 reg=0.001871
2017/08/30 17:43:37 step 6: objective=0.123357 reg=0.001871
2017/08/30 17:43:39 step 7: objective=0.123496 reg=0.001871
2017/08/30 17:43:39 Training value function...
2017/08/30 17:43:42 step 0: mse=0.228490 step=0.050000
2017/08/30 17:43:44 step 1: mse=0.228578 step=0.050000
2017/08/30 17:43:45 step 2: mse=0.228716 step=0.050000
2017/08/30 17:43:47 step 3: mse=0.228849 step=0.050000
2017/08/30 17:43:48 step 4: mse=0.228833 step=0.050000
2017/08/30 17:43:49 step 5: mse=0.228932 step=0.050000
2017/08/30 17:43:51 step 6: mse=0.229164 step=0.050000
2017/08/30 17:43:52 step 7: mse=0.229354 step=0.050000
2017/08/30 17:43:52 Saving...
2017/08/30 17:43:52 Gathering batch of experience...
2017/08/30 17:44:34 batch 371: mean=29.526316 stddev=13.398226 entropy=0.188986 frames=8685 count=19
2017/08/30 17:44:34 Training policy...
2017/08/30 17:44:40 tune 0: objective=0.133268 reg=0.001890 prune=0
2017/08/30 17:44:42 step 0: objective=0.133268 reg=0.001890
2017/08/30 17:44:43 step 1: objective=0.133349 reg=0.001890
2017/08/30 17:44:45 step 2: objective=0.133447 reg=0.001890
2017/08/30 17:44:47 step 3: objective=0.133559 reg=0.001890
2017/08/30 17:44:49 step 4: objective=0.133654 reg=0.001891
2017/08/30 17:44:50 step 5: objective=0.133746 reg=0.001892
2017/08/30 17:44:52 step 6: objective=0.133800 reg=0.001893
2017/08/30 17:44:54 step 7: objective=0.133873 reg=0.001893
2017/08/30 17:44:54 Training value function...
2017/08/30 17:44:57 step 0: mse=0.225664 step=0.050000
2017/08/30 17:44:59 step 1: mse=0.224855 step=0.050000
2017/08/30 17:45:00 step 2: mse=0.224368 step=0.050000
2017/08/30 17:45:02 step 3: mse=0.223460 step=0.050000
2017/08/30 17:45:03 step 4: mse=0.222420 step=0.050000
2017/08/30 17:45:05 step 5: mse=0.221661 step=0.050000
2017/08/30 17:45:06 step 6: mse=0.221415 step=0.050000
2017/08/30 17:45:08 step 7: mse=0.221028 step=0.050000
2017/08/30 17:45:08 Saving...
2017/08/30 17:45:08 Gathering batch of experience...
2017/08/30 17:45:45 batch 372: mean=29.133333 stddev=13.230604 entropy=0.192773 frames=6775 count=15
2017/08/30 17:45:45 Training policy...
2017/08/30 17:45:49 tune 0: objective=0.131338 reg=0.001928 prune=0
2017/08/30 17:45:50 step 0: objective=0.131338 reg=0.001928
2017/08/30 17:45:52 step 1: objective=0.131445 reg=0.001927
2017/08/30 17:45:53 step 2: objective=0.131514 reg=0.001928
2017/08/30 17:45:54 step 3: objective=0.131569 reg=0.001928
2017/08/30 17:45:56 step 4: objective=0.131689 reg=0.001928
2017/08/30 17:45:57 step 5: objective=0.131769 reg=0.001926
2017/08/30 17:45:58 step 6: objective=0.131863 reg=0.001926
2017/08/30 17:46:00 step 7: objective=0.131966 reg=0.001926
2017/08/30 17:46:00 Training value function...
2017/08/30 17:46:03 step 0: mse=0.226167 step=0.050000
2017/08/30 17:46:04 step 1: mse=0.226138 step=0.050000
2017/08/30 17:46:05 step 2: mse=0.225877 step=0.050000
2017/08/30 17:46:06 step 3: mse=0.225978 step=0.050000
2017/08/30 17:46:07 step 4: mse=0.225813 step=0.050000
2017/08/30 17:46:08 step 5: mse=0.225743 step=0.050000
2017/08/30 17:46:10 step 6: mse=0.225387 step=0.050000
2017/08/30 17:46:11 step 7: mse=0.225199 step=0.050000
2017/08/30 17:46:11 Saving...
2017/08/30 17:46:11 Gathering batch of experience...
2017/08/30 17:46:50 batch 373: mean=32.937500 stddev=9.503083 entropy=0.189188 frames=8162 count=16
2017/08/30 17:46:50 Training policy...
2017/08/30 17:46:55 tune 0: objective=0.135448 reg=0.001892 prune=0
2017/08/30 17:46:57 step 0: objective=0.135448 reg=0.001892
2017/08/30 17:46:59 step 1: objective=0.135556 reg=0.001891
2017/08/30 17:47:00 step 2: objective=0.135636 reg=0.001890
2017/08/30 17:47:02 step 3: objective=0.135696 reg=0.001890
2017/08/30 17:47:03 step 4: objective=0.135768 reg=0.001889
2017/08/30 17:47:05 step 5: objective=0.135848 reg=0.001889
2017/08/30 17:47:07 step 6: objective=0.135926 reg=0.001889
2017/08/30 17:47:08 step 7: objective=0.135999 reg=0.001889
2017/08/30 17:47:08 Training value function...
2017/08/30 17:47:12 step 0: mse=0.222352 step=0.050000
2017/08/30 17:47:13 step 1: mse=0.221185 step=0.050000
2017/08/30 17:47:14 step 2: mse=0.220326 step=0.050000
2017/08/30 17:47:16 step 3: mse=0.219298 step=0.050000
2017/08/30 17:47:17 step 4: mse=0.218781 step=0.050000
2017/08/30 17:47:19 step 5: mse=0.217878 step=0.050000
2017/08/30 17:47:20 step 6: mse=0.217207 step=0.050000
2017/08/30 17:47:22 step 7: mse=0.216255 step=0.050000
2017/08/30 17:47:22 Saving...
2017/08/30 17:47:22 Gathering batch of experience...
2017/08/30 17:47:59 batch 374: mean=28.411765 stddev=13.599562 entropy=0.188769 frames=7477 count=17
2017/08/30 17:47:59 Training policy...
2017/08/30 17:48:04 tune 0: objective=0.129949 reg=0.001888 prune=0
2017/08/30 17:48:06 step 0: objective=0.129949 reg=0.001888
2017/08/30 17:48:07 step 1: objective=0.130068 reg=0.001888
2017/08/30 17:48:08 step 2: objective=0.130191 reg=0.001889
2017/08/30 17:48:10 step 3: objective=0.130245 reg=0.001889
2017/08/30 17:48:11 step 4: objective=0.130339 reg=0.001889
2017/08/30 17:48:13 step 5: objective=0.130442 reg=0.001890
2017/08/30 17:48:14 step 6: objective=0.130510 reg=0.001890
2017/08/30 17:48:16 step 7: objective=0.130574 reg=0.001890
2017/08/30 17:48:16 Training value function...
2017/08/30 17:48:19 step 0: mse=0.217206 step=0.050000
2017/08/30 17:48:20 step 1: mse=0.217037 step=0.050000
2017/08/30 17:48:22 step 2: mse=0.216820 step=0.050000
2017/08/30 17:48:23 step 3: mse=0.216822 step=0.050000
2017/08/30 17:48:24 step 4: mse=0.216761 step=0.050000
2017/08/30 17:48:26 step 5: mse=0.216457 step=0.050000
2017/08/30 17:48:27 step 6: mse=0.216549 step=0.050000
2017/08/30 17:48:28 step 7: mse=0.216394 step=0.050000
2017/08/30 17:48:28 Saving...
2017/08/30 17:48:28 Gathering batch of experience...
2017/08/30 17:49:08 batch 375: mean=30.470588 stddev=11.697751 entropy=0.187209 frames=8018 count=17
2017/08/30 17:49:08 Training policy...
2017/08/30 17:49:13 tune 0: objective=0.130957 reg=0.001872 prune=0
2017/08/30 17:49:15 step 0: objective=0.130958 reg=0.001872
2017/08/30 17:49:16 step 1: objective=0.131102 reg=0.001873
2017/08/30 17:49:18 step 2: objective=0.131179 reg=0.001873
2017/08/30 17:49:19 step 3: objective=0.131248 reg=0.001873
2017/08/30 17:49:21 step 4: objective=0.131301 reg=0.001873
2017/08/30 17:49:23 step 5: objective=0.131349 reg=0.001873
2017/08/30 17:49:24 step 6: objective=0.131406 reg=0.001873
2017/08/30 17:49:26 step 7: objective=0.131444 reg=0.001874
2017/08/30 17:49:26 Training value function...
2017/08/30 17:49:29 step 0: mse=0.220796 step=0.050000
2017/08/30 17:49:31 step 1: mse=0.220421 step=0.050000
2017/08/30 17:49:32 step 2: mse=0.220540 step=0.050000
2017/08/30 17:49:33 step 3: mse=0.220511 step=0.050000
2017/08/30 17:49:35 step 4: mse=0.220519 step=0.050000
2017/08/30 17:49:36 step 5: mse=0.219668 step=0.050000
2017/08/30 17:49:38 step 6: mse=0.219489 step=0.050000
2017/08/30 17:49:39 step 7: mse=0.219453 step=0.050000
2017/08/30 17:49:39 Saving...
2017/08/30 17:49:39 Gathering batch of experience...
2017/08/30 17:50:22 batch 376: mean=33.117647 stddev=10.560093 entropy=0.188070 frames=8698 count=17
2017/08/30 17:50:22 Training policy...
2017/08/30 17:50:27 tune 0: objective=0.138748 reg=0.001881 prune=0
2017/08/30 17:50:29 step 0: objective=0.138748 reg=0.001881
2017/08/30 17:50:31 step 1: objective=0.138825 reg=0.001881
2017/08/30 17:50:33 step 2: objective=0.138896 reg=0.001881
2017/08/30 17:50:34 step 3: objective=0.138980 reg=0.001880
2017/08/30 17:50:36 step 4: objective=0.139066 reg=0.001881
2017/08/30 17:50:38 step 5: objective=0.139145 reg=0.001881
2017/08/30 17:50:40 step 6: objective=0.139208 reg=0.001881
2017/08/30 17:50:41 step 7: objective=0.139271 reg=0.001880
2017/08/30 17:50:41 Training value function...
2017/08/30 17:50:45 step 0: mse=0.218375 step=0.050000
2017/08/30 17:50:47 step 1: mse=0.216475 step=0.050000
2017/08/30 17:50:48 step 2: mse=0.215415 step=0.050000
2017/08/30 17:50:50 step 3: mse=0.214093 step=0.050000
2017/08/30 17:50:51 step 4: mse=0.213025 step=0.050000
2017/08/30 17:50:53 step 5: mse=0.211803 step=0.050000
2017/08/30 17:50:54 step 6: mse=0.210904 step=0.050000
2017/08/30 17:50:56 step 7: mse=0.210243 step=0.050000
2017/08/30 17:50:56 Saving...
2017/08/30 17:50:56 Gathering batch of experience...
2017/08/30 17:51:35 batch 377: mean=34.466667 stddev=7.614606 entropy=0.186189 frames=7980 count=15
2017/08/30 17:51:35 Training policy...
2017/08/30 17:51:40 tune 0: objective=0.135116 reg=0.001862 prune=0
2017/08/30 17:51:42 step 0: objective=0.135116 reg=0.001862
2017/08/30 17:51:43 step 1: objective=0.135210 reg=0.001862
2017/08/30 17:51:45 step 2: objective=0.135261 reg=0.001862
2017/08/30 17:51:46 step 3: objective=0.135318 reg=0.001863
2017/08/30 17:51:48 step 4: objective=0.135406 reg=0.001864
2017/08/30 17:51:49 step 5: objective=0.135449 reg=0.001864
2017/08/30 17:51:51 step 6: objective=0.135498 reg=0.001864
2017/08/30 17:51:53 step 7: objective=0.135534 reg=0.001864
2017/08/30 17:51:53 Training value function...
2017/08/30 17:51:56 step 0: mse=0.203997 step=0.050000
2017/08/30 17:51:57 step 1: mse=0.203469 step=0.050000
2017/08/30 17:51:59 step 2: mse=0.202884 step=0.050000
2017/08/30 17:52:00 step 3: mse=0.202081 step=0.050000
2017/08/30 17:52:01 step 4: mse=0.201257 step=0.050000
2017/08/30 17:52:03 step 5: mse=0.200551 step=0.050000
2017/08/30 17:52:04 step 6: mse=0.200012 step=0.050000
2017/08/30 17:52:06 step 7: mse=0.199308 step=0.050000
2017/08/30 17:52:06 Saving...
2017/08/30 17:52:06 Gathering batch of experience...
2017/08/30 17:52:45 batch 378: mean=35.333333 stddev=7.938654 entropy=0.186623 frames=8184 count=15
2017/08/30 17:52:45 Training policy...
2017/08/30 17:52:51 tune 0: objective=0.137245 reg=0.001866 prune=0
2017/08/30 17:52:52 step 0: objective=0.137245 reg=0.001866
2017/08/30 17:52:54 step 1: objective=0.137310 reg=0.001865
2017/08/30 17:52:56 step 2: objective=0.137355 reg=0.001865
2017/08/30 17:52:57 step 3: objective=0.137411 reg=0.001865
2017/08/30 17:52:59 step 4: objective=0.137496 reg=0.001864
2017/08/30 17:53:01 step 5: objective=0.137547 reg=0.001864
2017/08/30 17:53:02 step 6: objective=0.137643 reg=0.001863
2017/08/30 17:53:04 step 7: objective=0.137719 reg=0.001862
2017/08/30 17:53:04 Training value function...
2017/08/30 17:53:07 step 0: mse=0.205400 step=0.050000
2017/08/30 17:53:09 step 1: mse=0.204241 step=0.050000
2017/08/30 17:53:10 step 2: mse=0.203403 step=0.050000
2017/08/30 17:53:12 step 3: mse=0.202545 step=0.050000
2017/08/30 17:53:13 step 4: mse=0.202162 step=0.050000
2017/08/30 17:53:14 step 5: mse=0.201885 step=0.050000
2017/08/30 17:53:16 step 6: mse=0.201008 step=0.050000
2017/08/30 17:53:17 step 7: mse=0.200788 step=0.050000
2017/08/30 17:53:17 Saving...
2017/08/30 17:53:17 Gathering batch of experience...
2017/08/30 17:53:56 batch 379: mean=28.666667 stddev=13.593299 entropy=0.185099 frames=7994 count=18
2017/08/30 17:53:56 Training policy...
2017/08/30 17:54:02 tune 0: objective=0.121623 reg=0.001851 prune=0
2017/08/30 17:54:03 step 0: objective=0.121624 reg=0.001851
2017/08/30 17:54:05 step 1: objective=0.121697 reg=0.001851
2017/08/30 17:54:06 step 2: objective=0.121821 reg=0.001850
2017/08/30 17:54:08 step 3: objective=0.121962 reg=0.001850
2017/08/30 17:54:10 step 4: objective=0.122018 reg=0.001850
2017/08/30 17:54:11 step 5: objective=0.122166 reg=0.001850
2017/08/30 17:54:13 step 6: objective=0.122217 reg=0.001849
2017/08/30 17:54:14 step 7: objective=0.122307 reg=0.001849
2017/08/30 17:54:14 Training value function...
2017/08/30 17:54:18 step 0: mse=0.204707 step=0.050000
2017/08/30 17:54:19 step 1: mse=0.205108 step=0.050000
2017/08/30 17:54:20 step 2: mse=0.205418 step=0.050000
2017/08/30 17:54:22 step 3: mse=0.205781 step=0.050000
2017/08/30 17:54:23 step 4: mse=0.206196 step=0.050000
2017/08/30 17:54:25 step 5: mse=0.206650 step=0.050000
2017/08/30 17:54:26 step 6: mse=0.207229 step=0.050000
2017/08/30 17:54:28 step 7: mse=0.207623 step=0.050000
2017/08/30 17:54:28 Saving...
2017/08/30 17:54:28 Gathering batch of experience...
2017/08/30 17:55:05 batch 380: mean=29.125000 stddev=10.017953 entropy=0.190212 frames=7268 count=16
2017/08/30 17:55:05 Training policy...
2017/08/30 17:55:09 tune 0: objective=0.115133 reg=0.001902 prune=0
2017/08/30 17:55:11 step 0: objective=0.115133 reg=0.001902
2017/08/30 17:55:12 step 1: objective=0.115228 reg=0.001901
2017/08/30 17:55:14 step 2: objective=0.115330 reg=0.001901
2017/08/30 17:55:15 step 3: objective=0.115409 reg=0.001901
2017/08/30 17:55:17 step 4: objective=0.115504 reg=0.001901
2017/08/30 17:55:18 step 5: objective=0.115583 reg=0.001901
2017/08/30 17:55:20 step 6: objective=0.115635 reg=0.001901
2017/08/30 17:55:21 step 7: objective=0.115697 reg=0.001901
2017/08/30 17:55:21 Training value function...
2017/08/30 17:55:24 step 0: mse=0.211629 step=0.050000
2017/08/30 17:55:25 step 1: mse=0.211849 step=0.050000
2017/08/30 17:55:27 step 2: mse=0.212388 step=0.050000
2017/08/30 17:55:28 step 3: mse=0.213149 step=0.050000
2017/08/30 17:55:29 step 4: mse=0.213647 step=0.050000
2017/08/30 17:55:30 step 5: mse=0.214426 step=0.050000
2017/08/30 17:55:32 step 6: mse=0.214622 step=0.050000
2017/08/30 17:55:33 step 7: mse=0.215302 step=0.050000
2017/08/30 17:55:33 Saving...
2017/08/30 17:55:33 Gathering batch of experience...
2017/08/30 17:56:12 batch 381: mean=33.200000 stddev=8.174758 entropy=0.184290 frames=7719 count=15
2017/08/30 17:56:12 Training policy...
2017/08/30 17:56:17 tune 0: objective=0.135673 reg=0.001843 prune=0
2017/08/30 17:56:18 step 0: objective=0.135674 reg=0.001843
2017/08/30 17:56:20 step 1: objective=0.135778 reg=0.001843
2017/08/30 17:56:21 step 2: objective=0.135820 reg=0.001843
2017/08/30 17:56:23 step 3: objective=0.135928 reg=0.001844
2017/08/30 17:56:24 step 4: objective=0.136001 reg=0.001844
2017/08/30 17:56:26 step 5: objective=0.136099 reg=0.001844
2017/08/30 17:56:28 step 6: objective=0.136202 reg=0.001844
2017/08/30 17:56:29 step 7: objective=0.136238 reg=0.001844
2017/08/30 17:56:29 Training value function...
2017/08/30 17:56:32 step 0: mse=0.221676 step=0.050000
2017/08/30 17:56:34 step 1: mse=0.220798 step=0.050000
2017/08/30 17:56:35 step 2: mse=0.219821 step=0.050000
2017/08/30 17:56:36 step 3: mse=0.219220 step=0.050000
2017/08/30 17:56:38 step 4: mse=0.219046 step=0.050000
2017/08/30 17:56:39 step 5: mse=0.218321 step=0.050000
2017/08/30 17:56:40 step 6: mse=0.217646 step=0.050000
2017/08/30 17:56:42 step 7: mse=0.216759 step=0.050000
2017/08/30 17:56:42 Saving...
2017/08/30 17:56:42 Gathering batch of experience...
2017/08/30 17:57:23 batch 382: mean=32.411765 stddev=10.117305 entropy=0.186226 frames=8535 count=17
2017/08/30 17:57:23 Training policy...
2017/08/30 17:57:29 tune 0: objective=0.133964 reg=0.001862 prune=0
2017/08/30 17:57:30 step 0: objective=0.133964 reg=0.001862
2017/08/30 17:57:32 step 1: objective=0.134025 reg=0.001862
2017/08/30 17:57:34 step 2: objective=0.134054 reg=0.001862
2017/08/30 17:57:36 step 3: objective=0.134084 reg=0.001861
2017/08/30 17:57:37 step 4: objective=0.134148 reg=0.001862
2017/08/30 17:57:39 step 5: objective=0.134213 reg=0.001862
2017/08/30 17:57:41 step 6: objective=0.134272 reg=0.001861
2017/08/30 17:57:42 step 7: objective=0.134321 reg=0.001861
2017/08/30 17:57:42 Training value function...
2017/08/30 17:57:46 step 0: mse=0.217884 step=0.050000
2017/08/30 17:57:47 step 1: mse=0.217178 step=0.050000
2017/08/30 17:57:49 step 2: mse=0.216862 step=0.050000
2017/08/30 17:57:50 step 3: mse=0.216417 step=0.050000
2017/08/30 17:57:52 step 4: mse=0.215842 step=0.050000
2017/08/30 17:57:53 step 5: mse=0.215471 step=0.050000
2017/08/30 17:57:55 step 6: mse=0.215208 step=0.050000
2017/08/30 17:57:56 step 7: mse=0.214706 step=0.050000
2017/08/30 17:57:56 Saving...
2017/08/30 17:57:56 Gathering batch of experience...
2017/08/30 17:58:34 batch 383: mean=33.000000 stddev=11.201190 entropy=0.184195 frames=7650 count=15
2017/08/30 17:58:34 Training policy...
2017/08/30 17:58:39 tune 0: objective=0.136767 reg=0.001842 prune=0
2017/08/30 17:58:41 step 0: objective=0.136767 reg=0.001842
2017/08/30 17:58:42 step 1: objective=0.136896 reg=0.001842
2017/08/30 17:58:44 step 2: objective=0.136964 reg=0.001842
2017/08/30 17:58:45 step 3: objective=0.137032 reg=0.001842
2017/08/30 17:58:47 step 4: objective=0.137081 reg=0.001843
2017/08/30 17:58:49 step 5: objective=0.137183 reg=0.001843
2017/08/30 17:58:50 step 6: objective=0.137234 reg=0.001843
2017/08/30 17:58:52 step 7: objective=0.137294 reg=0.001843
2017/08/30 17:58:52 Training value function...
2017/08/30 17:58:55 step 0: mse=0.213839 step=0.050000
2017/08/30 17:58:56 step 1: mse=0.212670 step=0.050000
2017/08/30 17:58:57 step 2: mse=0.211940 step=0.050000
2017/08/30 17:58:59 step 3: mse=0.211104 step=0.050000
2017/08/30 17:59:00 step 4: mse=0.209984 step=0.050000
2017/08/30 17:59:01 step 5: mse=0.209053 step=0.050000
2017/08/30 17:59:03 step 6: mse=0.208440 step=0.050000
2017/08/30 17:59:04 step 7: mse=0.208032 step=0.050000
2017/08/30 17:59:04 Saving...
2017/08/30 17:59:04 Gathering batch of experience...
2017/08/30 17:59:43 batch 384: mean=35.200000 stddev=8.376157 entropy=0.185030 frames=8146 count=15
2017/08/30 17:59:43 Training policy...
2017/08/30 17:59:49 tune 0: objective=0.138380 reg=0.001850 prune=0
2017/08/30 17:59:50 step 0: objective=0.138380 reg=0.001850
2017/08/30 17:59:52 step 1: objective=0.138467 reg=0.001849
2017/08/30 17:59:54 step 2: objective=0.138550 reg=0.001849
2017/08/30 17:59:55 step 3: objective=0.138628 reg=0.001848
2017/08/30 17:59:57 step 4: objective=0.138686 reg=0.001847
2017/08/30 17:59:58 step 5: objective=0.138719 reg=0.001846
2017/08/30 18:00:00 step 6: objective=0.138802 reg=0.001846
2017/08/30 18:00:02 step 7: objective=0.138851 reg=0.001845
2017/08/30 18:00:02 Training value function...
2017/08/30 18:00:05 step 0: mse=0.207252 step=0.050000
2017/08/30 18:00:07 step 1: mse=0.206401 step=0.050000
2017/08/30 18:00:08 step 2: mse=0.204907 step=0.050000
2017/08/30 18:00:09 step 3: mse=0.204464 step=0.050000
2017/08/30 18:00:11 step 4: mse=0.203292 step=0.050000
2017/08/30 18:00:12 step 5: mse=0.202805 step=0.050000
2017/08/30 18:00:13 step 6: mse=0.202331 step=0.050000
2017/08/30 18:00:15 step 7: mse=0.201316 step=0.050000
2017/08/30 18:00:15 Saving...
2017/08/30 18:00:15 Gathering batch of experience...
2017/08/30 18:00:55 batch 385: mean=29.882353 stddev=11.856407 entropy=0.184674 frames=7855 count=17
2017/08/30 18:00:55 Training policy...
2017/08/30 18:01:00 tune 0: objective=0.125061 reg=0.001847 prune=0
2017/08/30 18:01:01 step 0: objective=0.125061 reg=0.001847
2017/08/30 18:01:03 step 1: objective=0.125129 reg=0.001848
2017/08/30 18:01:04 step 2: objective=0.125184 reg=0.001848
2017/08/30 18:01:06 step 3: objective=0.125245 reg=0.001849
2017/08/30 18:01:08 step 4: objective=0.125336 reg=0.001850
2017/08/30 18:01:09 step 5: objective=0.125387 reg=0.001850
2017/08/30 18:01:11 step 6: objective=0.125432 reg=0.001850
2017/08/30 18:01:12 step 7: objective=0.125507 reg=0.001850
2017/08/30 18:01:12 Training value function...
2017/08/30 18:01:16 step 0: mse=0.199842 step=0.050000
2017/08/30 18:01:17 step 1: mse=0.200401 step=0.050000
2017/08/30 18:01:18 step 2: mse=0.201102 step=0.050000
2017/08/30 18:01:20 step 3: mse=0.201373 step=0.050000
2017/08/30 18:01:21 step 4: mse=0.201910 step=0.050000
2017/08/30 18:01:23 step 5: mse=0.202424 step=0.050000
2017/08/30 18:01:24 step 6: mse=0.202915 step=0.050000
2017/08/30 18:01:25 step 7: mse=0.203423 step=0.050000
2017/08/30 18:01:25 Saving...
2017/08/30 18:01:25 Gathering batch of experience...
2017/08/30 18:02:05 batch 386: mean=35.866667 stddev=6.141299 entropy=0.185125 frames=8303 count=15
2017/08/30 18:02:05 Training policy...
2017/08/30 18:02:11 tune 0: objective=0.137744 reg=0.001851 prune=0
2017/08/30 18:02:13 step 0: objective=0.137744 reg=0.001851
2017/08/30 18:02:14 step 1: objective=0.137819 reg=0.001851
2017/08/30 18:02:16 step 2: objective=0.137898 reg=0.001851
2017/08/30 18:02:17 step 3: objective=0.137986 reg=0.001851
2017/08/30 18:02:19 step 4: objective=0.138063 reg=0.001851
2017/08/30 18:02:21 step 5: objective=0.138125 reg=0.001850
2017/08/30 18:02:22 step 6: objective=0.138229 reg=0.001850
2017/08/30 18:02:24 step 7: objective=0.138272 reg=0.001850
2017/08/30 18:02:24 Training value function...
2017/08/30 18:02:28 step 0: mse=0.205659 step=0.050000
2017/08/30 18:02:29 step 1: mse=0.204495 step=0.050000
2017/08/30 18:02:30 step 2: mse=0.203844 step=0.050000
2017/08/30 18:02:32 step 3: mse=0.203070 step=0.050000
2017/08/30 18:02:33 step 4: mse=0.202159 step=0.050000
2017/08/30 18:02:35 step 5: mse=0.201784 step=0.050000
2017/08/30 18:02:36 step 6: mse=0.200885 step=0.050000
2017/08/30 18:02:38 step 7: mse=0.199921 step=0.050000
2017/08/30 18:02:38 Saving...
2017/08/30 18:02:38 Gathering batch of experience...
2017/08/30 18:03:18 batch 387: mean=33.250000 stddev=8.912772 entropy=0.185130 frames=8201 count=16
2017/08/30 18:03:18 Training policy...
2017/08/30 18:03:23 tune 0: objective=0.131988 reg=0.001851 prune=0
2017/08/30 18:03:25 step 0: objective=0.131988 reg=0.001851
2017/08/30 18:03:26 step 1: objective=0.132066 reg=0.001851
2017/08/30 18:03:28 step 2: objective=0.132161 reg=0.001851
2017/08/30 18:03:30 step 3: objective=0.132283 reg=0.001851
2017/08/30 18:03:31 step 4: objective=0.132356 reg=0.001851
2017/08/30 18:03:33 step 5: objective=0.132429 reg=0.001851
2017/08/30 18:03:35 step 6: objective=0.132478 reg=0.001851
2017/08/30 18:03:36 step 7: objective=0.132548 reg=0.001852
2017/08/30 18:03:36 Training value function...
2017/08/30 18:03:40 step 0: mse=0.196106 step=0.050000
2017/08/30 18:03:41 step 1: mse=0.196055 step=0.050000
2017/08/30 18:03:42 step 2: mse=0.195883 step=0.050000
2017/08/30 18:03:44 step 3: mse=0.195825 step=0.050000
2017/08/30 18:03:45 step 4: mse=0.195951 step=0.050000
2017/08/30 18:03:47 step 5: mse=0.195595 step=0.050000
2017/08/30 18:03:48 step 6: mse=0.195340 step=0.050000
2017/08/30 18:03:50 step 7: mse=0.195304 step=0.050000
2017/08/30 18:03:50 Saving...
2017/08/30 18:03:50 Gathering batch of experience...
2017/08/30 18:04:30 batch 388: mean=36.666667 stddev=5.951657 entropy=0.182216 frames=8484 count=15
2017/08/30 18:04:30 Training policy...
2017/08/30 18:04:36 tune 0: objective=0.137264 reg=0.001822 prune=0
2017/08/30 18:04:38 step 0: objective=0.137264 reg=0.001822
2017/08/30 18:04:39 step 1: objective=0.137343 reg=0.001822
2017/08/30 18:04:41 step 2: objective=0.137428 reg=0.001821
2017/08/30 18:04:43 step 3: objective=0.137496 reg=0.001820
2017/08/30 18:04:44 step 4: objective=0.137536 reg=0.001820
2017/08/30 18:04:46 step 5: objective=0.137563 reg=0.001820
2017/08/30 18:04:48 step 6: objective=0.137638 reg=0.001820
2017/08/30 18:04:49 step 7: objective=0.137683 reg=0.001820
2017/08/30 18:04:49 Training value function...
2017/08/30 18:04:53 step 0: mse=0.204550 step=0.050000
2017/08/30 18:04:55 step 1: mse=0.203971 step=0.050000
2017/08/30 18:04:56 step 2: mse=0.203561 step=0.050000
2017/08/30 18:04:57 step 3: mse=0.202199 step=0.050000
2017/08/30 18:04:59 step 4: mse=0.201177 step=0.050000
2017/08/30 18:05:00 step 5: mse=0.200017 step=0.050000
2017/08/30 18:05:02 step 6: mse=0.199588 step=0.050000
2017/08/30 18:05:03 step 7: mse=0.198644 step=0.050000
2017/08/30 18:05:03 Saving...
2017/08/30 18:05:03 Gathering batch of experience...
2017/08/30 18:05:41 batch 389: mean=31.733333 stddev=11.269230 entropy=0.181285 frames=7360 count=15
2017/08/30 18:05:41 Training policy...
2017/08/30 18:05:45 tune 0: objective=0.126215 reg=0.001813 prune=0
2017/08/30 18:05:47 step 0: objective=0.126215 reg=0.001813
2017/08/30 18:05:48 step 1: objective=0.126302 reg=0.001812
2017/08/30 18:05:50 step 2: objective=0.126404 reg=0.001812
2017/08/30 18:05:51 step 3: objective=0.126472 reg=0.001812
2017/08/30 18:05:53 step 4: objective=0.126576 reg=0.001812
2017/08/30 18:05:54 step 5: objective=0.126666 reg=0.001812
2017/08/30 18:05:56 step 6: objective=0.126779 reg=0.001813
2017/08/30 18:05:57 step 7: objective=0.126859 reg=0.001813
2017/08/30 18:05:57 Training value function...
2017/08/30 18:06:00 step 0: mse=0.200150 step=0.050000
2017/08/30 18:06:02 step 1: mse=0.200533 step=0.050000
2017/08/30 18:06:03 step 2: mse=0.201138 step=0.050000
2017/08/30 18:06:04 step 3: mse=0.201525 step=0.050000
2017/08/30 18:06:05 step 4: mse=0.201903 step=0.050000
2017/08/30 18:06:07 step 5: mse=0.202356 step=0.050000
2017/08/30 18:06:08 step 6: mse=0.202901 step=0.050000
2017/08/30 18:06:09 step 7: mse=0.203128 step=0.050000
2017/08/30 18:06:09 Saving...
2017/08/30 18:06:09 Gathering batch of experience...
2017/08/30 18:06:48 batch 390: mean=31.312500 stddev=11.245659 entropy=0.184399 frames=7766 count=16
2017/08/30 18:06:48 Training policy...
2017/08/30 18:06:53 tune 0: objective=0.123426 reg=0.001844 prune=0
2017/08/30 18:06:55 step 0: objective=0.123426 reg=0.001844
2017/08/30 18:06:56 step 1: objective=0.123536 reg=0.001844
2017/08/30 18:06:58 step 2: objective=0.123627 reg=0.001843
2017/08/30 18:06:59 step 3: objective=0.123712 reg=0.001843
2017/08/30 18:07:01 step 4: objective=0.123807 reg=0.001842
2017/08/30 18:07:02 step 5: objective=0.123901 reg=0.001843
2017/08/30 18:07:04 step 6: objective=0.124002 reg=0.001842
2017/08/30 18:07:06 step 7: objective=0.124079 reg=0.001842
2017/08/30 18:07:06 Training value function...
2017/08/30 18:07:09 step 0: mse=0.201182 step=0.050000
2017/08/30 18:07:10 step 1: mse=0.201433 step=0.050000
2017/08/30 18:07:12 step 2: mse=0.201617 step=0.050000
2017/08/30 18:07:13 step 3: mse=0.202026 step=0.050000
2017/08/30 18:07:14 step 4: mse=0.202279 step=0.050000
2017/08/30 18:07:16 step 5: mse=0.202534 step=0.050000
2017/08/30 18:07:17 step 6: mse=0.202760 step=0.050000
2017/08/30 18:07:18 step 7: mse=0.202717 step=0.050000
2017/08/30 18:07:18 Saving...
2017/08/30 18:07:18 Gathering batch of experience...
2017/08/30 18:07:59 batch 391: mean=31.823529 stddev=12.006054 entropy=0.187443 frames=8366 count=17
2017/08/30 18:07:59 Training policy...
2017/08/30 18:08:04 tune 0: objective=0.131303 reg=0.001874 prune=0
2017/08/30 18:08:06 step 0: objective=0.131303 reg=0.001874
2017/08/30 18:08:08 step 1: objective=0.131356 reg=0.001875
2017/08/30 18:08:09 step 2: objective=0.131412 reg=0.001875
2017/08/30 18:08:11 step 3: objective=0.131497 reg=0.001875
2017/08/30 18:08:13 step 4: objective=0.131559 reg=0.001875
2017/08/30 18:08:14 step 5: objective=0.131626 reg=0.001875
2017/08/30 18:08:16 step 6: objective=0.131676 reg=0.001875
2017/08/30 18:08:18 step 7: objective=0.131771 reg=0.001875
2017/08/30 18:08:18 Training value function...
2017/08/30 18:08:21 step 0: mse=0.209879 step=0.050000
2017/08/30 18:08:23 step 1: mse=0.209340 step=0.050000
2017/08/30 18:08:24 step 2: mse=0.209160 step=0.050000
2017/08/30 18:08:26 step 3: mse=0.209382 step=0.050000
2017/08/30 18:08:27 step 4: mse=0.208978 step=0.050000
2017/08/30 18:08:28 step 5: mse=0.209013 step=0.050000
2017/08/30 18:08:30 step 6: mse=0.208959 step=0.050000
2017/08/30 18:08:31 step 7: mse=0.209104 step=0.050000
2017/08/30 18:08:31 Saving...
2017/08/30 18:08:31 Gathering batch of experience...
2017/08/30 18:09:14 batch 392: mean=32.705882 stddev=11.065392 entropy=0.181581 frames=8591 count=17
2017/08/30 18:09:14 Training policy...
2017/08/30 18:09:20 tune 0: objective=0.132140 reg=0.001816 prune=0
2017/08/30 18:09:21 step 0: objective=0.132140 reg=0.001816
2017/08/30 18:09:23 step 1: objective=0.132220 reg=0.001816
2017/08/30 18:09:25 step 2: objective=0.132294 reg=0.001816
2017/08/30 18:09:27 step 3: objective=0.132358 reg=0.001816
2017/08/30 18:09:28 step 4: objective=0.132428 reg=0.001817
2017/08/30 18:09:30 step 5: objective=0.132486 reg=0.001817
2017/08/30 18:09:32 step 6: objective=0.132563 reg=0.001818
2017/08/30 18:09:33 step 7: objective=0.132649 reg=0.001818
2017/08/30 18:09:33 Training value function...
2017/08/30 18:09:37 step 0: mse=0.204871 step=0.050000
2017/08/30 18:09:38 step 1: mse=0.204552 step=0.050000
2017/08/30 18:09:40 step 2: mse=0.204433 step=0.050000
2017/08/30 18:09:41 step 3: mse=0.204251 step=0.050000
2017/08/30 18:09:43 step 4: mse=0.204241 step=0.050000
2017/08/30 18:09:45 step 5: mse=0.204076 step=0.050000
2017/08/30 18:09:46 step 6: mse=0.204009 step=0.050000
2017/08/30 18:09:48 step 7: mse=0.204019 step=0.050000
2017/08/30 18:09:48 Saving...
2017/08/30 18:09:48 Gathering batch of experience...
2017/08/30 18:10:27 batch 393: mean=28.235294 stddev=12.684077 entropy=0.182094 frames=7454 count=17
2017/08/30 18:10:27 Training policy...
2017/08/30 18:10:32 tune 0: objective=0.122155 reg=0.001821 prune=0
2017/08/30 18:10:34 step 0: objective=0.122156 reg=0.001821
2017/08/30 18:10:35 step 1: objective=0.122273 reg=0.001820
2017/08/30 18:10:37 step 2: objective=0.122351 reg=0.001820
2017/08/30 18:10:38 step 3: objective=0.122474 reg=0.001818
2017/08/30 18:10:40 step 4: objective=0.122564 reg=0.001817
2017/08/30 18:10:41 step 5: objective=0.122656 reg=0.001816
2017/08/30 18:10:43 step 6: objective=0.122733 reg=0.001815
2017/08/30 18:10:44 step 7: objective=0.122801 reg=0.001815
2017/08/30 18:10:44 Training value function...
2017/08/30 18:10:47 step 0: mse=0.203188 step=0.050000
2017/08/30 18:10:49 step 1: mse=0.203633 step=0.050000
2017/08/30 18:10:50 step 2: mse=0.204286 step=0.050000
2017/08/30 18:10:51 step 3: mse=0.204742 step=0.050000
2017/08/30 18:10:53 step 4: mse=0.205294 step=0.050000
2017/08/30 18:10:54 step 5: mse=0.205744 step=0.050000
2017/08/30 18:10:55 step 6: mse=0.206098 step=0.050000
2017/08/30 18:10:57 step 7: mse=0.206645 step=0.050000
2017/08/30 18:10:57 Saving...
2017/08/30 18:10:57 Gathering batch of experience...
2017/08/30 18:11:36 batch 394: mean=34.933333 stddev=7.646059 entropy=0.183034 frames=8078 count=15
2017/08/30 18:11:36 Training policy...
2017/08/30 18:11:41 tune 0: objective=0.139916 reg=0.001830 prune=0
2017/08/30 18:11:43 step 0: objective=0.139916 reg=0.001830
2017/08/30 18:11:45 step 1: objective=0.139956 reg=0.001830
2017/08/30 18:11:46 step 2: objective=0.140064 reg=0.001830
2017/08/30 18:11:48 step 3: objective=0.140171 reg=0.001830
2017/08/30 18:11:49 step 4: objective=0.140226 reg=0.001830
2017/08/30 18:11:51 step 5: objective=0.140293 reg=0.001830
2017/08/30 18:11:53 step 6: objective=0.140410 reg=0.001830
2017/08/30 18:11:54 step 7: objective=0.140483 reg=0.001829
2017/08/30 18:11:54 Training value function...
2017/08/30 18:11:58 step 0: mse=0.209851 step=0.050000
2017/08/30 18:11:59 step 1: mse=0.208583 step=0.050000
2017/08/30 18:12:00 step 2: mse=0.207804 step=0.050000
2017/08/30 18:12:02 step 3: mse=0.206747 step=0.050000
2017/08/30 18:12:03 step 4: mse=0.205461 step=0.050000
2017/08/30 18:12:05 step 5: mse=0.204684 step=0.050000
2017/08/30 18:12:06 step 6: mse=0.204052 step=0.050000
2017/08/30 18:12:07 step 7: mse=0.202847 step=0.050000
2017/08/30 18:12:07 Saving...
2017/08/30 18:12:07 Gathering batch of experience...
2017/08/30 18:12:47 batch 395: mean=28.222222 stddev=14.901736 entropy=0.183620 frames=7856 count=18
2017/08/30 18:12:47 Training policy...
2017/08/30 18:12:52 tune 0: objective=0.127288 reg=0.001836 prune=0
2017/08/30 18:12:54 step 0: objective=0.127289 reg=0.001836
2017/08/30 18:12:55 step 1: objective=0.127350 reg=0.001836
2017/08/30 18:12:57 step 2: objective=0.127430 reg=0.001837
2017/08/30 18:12:59 step 3: objective=0.127503 reg=0.001837
2017/08/30 18:13:00 step 4: objective=0.127599 reg=0.001837
2017/08/30 18:13:02 step 5: objective=0.127728 reg=0.001837
2017/08/30 18:13:03 step 6: objective=0.127818 reg=0.001838
2017/08/30 18:13:05 step 7: objective=0.127891 reg=0.001838
2017/08/30 18:13:05 Training value function...
2017/08/30 18:13:08 step 0: mse=0.209537 step=0.050000
2017/08/30 18:13:10 step 1: mse=0.209406 step=0.050000
2017/08/30 18:13:11 step 2: mse=0.209184 step=0.050000
2017/08/30 18:13:12 step 3: mse=0.208927 step=0.050000
2017/08/30 18:13:14 step 4: mse=0.208673 step=0.050000
2017/08/30 18:13:15 step 5: mse=0.208667 step=0.050000
2017/08/30 18:13:16 step 6: mse=0.208708 step=0.050000
2017/08/30 18:13:18 step 7: mse=0.208584 step=0.050000
2017/08/30 18:13:18 Saving...
2017/08/30 18:13:18 Gathering batch of experience...
2017/08/30 18:13:56 batch 396: mean=34.285714 stddev=6.922309 entropy=0.181516 frames=7435 count=14
2017/08/30 18:13:56 Training policy...
2017/08/30 18:14:01 tune 0: objective=0.130174 reg=0.001815 prune=0
2017/08/30 18:14:03 step 0: objective=0.130175 reg=0.001815
2017/08/30 18:14:04 step 1: objective=0.130255 reg=0.001815
2017/08/30 18:14:06 step 2: objective=0.130326 reg=0.001815
2017/08/30 18:14:07 step 3: objective=0.130439 reg=0.001815
2017/08/30 18:14:09 step 4: objective=0.130528 reg=0.001815
2017/08/30 18:14:10 step 5: objective=0.130573 reg=0.001814
2017/08/30 18:14:11 step 6: objective=0.130695 reg=0.001814
2017/08/30 18:14:13 step 7: objective=0.130738 reg=0.001814
2017/08/30 18:14:13 Training value function...
2017/08/30 18:14:16 step 0: mse=0.210581 step=0.050000
2017/08/30 18:14:17 step 1: mse=0.210436 step=0.050000
2017/08/30 18:14:19 step 2: mse=0.210084 step=0.050000
2017/08/30 18:14:20 step 3: mse=0.209931 step=0.050000
2017/08/30 18:14:21 step 4: mse=0.209791 step=0.050000
2017/08/30 18:14:23 step 5: mse=0.209758 step=0.050000
2017/08/30 18:14:24 step 6: mse=0.209661 step=0.050000
2017/08/30 18:14:25 step 7: mse=0.209568 step=0.050000
2017/08/30 18:14:25 Saving...
2017/08/30 18:14:25 Gathering batch of experience...
2017/08/30 18:15:08 batch 397: mean=27.050000 stddev=14.944815 entropy=0.178321 frames=8394 count=20
2017/08/30 18:15:08 Training policy...
2017/08/30 18:15:14 tune 0: objective=0.122503 reg=0.001783 prune=0
2017/08/30 18:15:15 step 0: objective=0.122503 reg=0.001783
2017/08/30 18:15:17 step 1: objective=0.122573 reg=0.001783
2017/08/30 18:15:19 step 2: objective=0.122657 reg=0.001783
2017/08/30 18:15:20 step 3: objective=0.122729 reg=0.001783
2017/08/30 18:15:22 step 4: objective=0.122791 reg=0.001782
2017/08/30 18:15:24 step 5: objective=0.122842 reg=0.001782
2017/08/30 18:15:25 step 6: objective=0.122886 reg=0.001782
2017/08/30 18:15:27 step 7: objective=0.122959 reg=0.001781
2017/08/30 18:15:27 Training value function...
2017/08/30 18:15:31 step 0: mse=0.216901 step=0.050000
2017/08/30 18:15:32 step 1: mse=0.217102 step=0.050000
2017/08/30 18:15:34 step 2: mse=0.217336 step=0.050000
2017/08/30 18:15:35 step 3: mse=0.217681 step=0.050000
2017/08/30 18:15:37 step 4: mse=0.217982 step=0.050000
2017/08/30 18:15:38 step 5: mse=0.218220 step=0.050000
2017/08/30 18:15:39 step 6: mse=0.218551 step=0.050000
2017/08/30 18:15:41 step 7: mse=0.218966 step=0.050000
2017/08/30 18:15:41 Saving...
2017/08/30 18:15:41 Gathering batch of experience...
2017/08/30 18:16:20 batch 398: mean=31.937500 stddev=11.415279 entropy=0.179920 frames=7900 count=16
2017/08/30 18:16:20 Training policy...
2017/08/30 18:16:25 tune 0: objective=0.133533 reg=0.001799 prune=0
2017/08/30 18:16:27 step 0: objective=0.133533 reg=0.001799
2017/08/30 18:16:28 step 1: objective=0.133596 reg=0.001799
2017/08/30 18:16:30 step 2: objective=0.133632 reg=0.001799
2017/08/30 18:16:31 step 3: objective=0.133675 reg=0.001800
2017/08/30 18:16:33 step 4: objective=0.133777 reg=0.001800
2017/08/30 18:16:35 step 5: objective=0.133825 reg=0.001799
2017/08/30 18:16:36 step 6: objective=0.133862 reg=0.001799
2017/08/30 18:16:38 step 7: objective=0.133895 reg=0.001799
2017/08/30 18:16:38 Training value function...
2017/08/30 18:16:41 step 0: mse=0.211851 step=0.050000
2017/08/30 18:16:42 step 1: mse=0.211131 step=0.050000
2017/08/30 18:16:44 step 2: mse=0.210346 step=0.050000
2017/08/30 18:16:45 step 3: mse=0.209679 step=0.050000
2017/08/30 18:16:47 step 4: mse=0.209388 step=0.050000
2017/08/30 18:16:48 step 5: mse=0.208929 step=0.050000
2017/08/30 18:16:49 step 6: mse=0.208472 step=0.050000
2017/08/30 18:16:51 step 7: mse=0.208453 step=0.050000
2017/08/30 18:16:51 Saving...
2017/08/30 18:16:51 Gathering batch of experience...
2017/08/30 18:17:30 batch 399: mean=31.375000 stddev=9.999219 entropy=0.178179 frames=7788 count=16
2017/08/30 18:17:30 Training policy...
2017/08/30 18:17:35 tune 0: objective=0.127484 reg=0.001782 prune=0
2017/08/30 18:17:37 step 0: objective=0.127485 reg=0.001782
2017/08/30 18:17:38 step 1: objective=0.127547 reg=0.001781
2017/08/30 18:17:40 step 2: objective=0.127637 reg=0.001781
2017/08/30 18:17:42 step 3: objective=0.127708 reg=0.001781
2017/08/30 18:17:43 step 4: objective=0.127767 reg=0.001781
2017/08/30 18:17:45 step 5: objective=0.127820 reg=0.001782
2017/08/30 18:17:46 step 6: objective=0.127912 reg=0.001782
2017/08/30 18:17:48 step 7: objective=0.127987 reg=0.001782
2017/08/30 18:17:48 Training value function...
2017/08/30 18:17:51 step 0: mse=0.217035 step=0.050000
2017/08/30 18:17:52 step 1: mse=0.217244 step=0.050000
2017/08/30 18:17:54 step 2: mse=0.217207 step=0.050000
2017/08/30 18:17:55 step 3: mse=0.216955 step=0.050000
2017/08/30 18:17:56 step 4: mse=0.217025 step=0.050000
2017/08/30 18:17:58 step 5: mse=0.216704 step=0.050000
2017/08/30 18:17:59 step 6: mse=0.216255 step=0.050000
2017/08/30 18:18:00 step 7: mse=0.215499 step=0.050000
2017/08/30 18:18:00 Saving...
2017/08/30 18:18:00 Gathering batch of experience...
2017/08/30 18:18:41 batch 400: mean=30.352941 stddev=12.911195 entropy=0.179979 frames=7976 count=17
2017/08/30 18:18:41 Training policy...
2017/08/30 18:18:46 tune 0: objective=0.132165 reg=0.001800 prune=0
2017/08/30 18:18:48 step 0: objective=0.132166 reg=0.001800
2017/08/30 18:18:49 step 1: objective=0.132323 reg=0.001801
2017/08/30 18:18:51 step 2: objective=0.132477 reg=0.001801
2017/08/30 18:18:52 step 3: objective=0.132610 reg=0.001802
2017/08/30 18:18:54 step 4: objective=0.132735 reg=0.001803
2017/08/30 18:18:56 step 5: objective=0.132824 reg=0.001804
2017/08/30 18:18:57 step 6: objective=0.132855 reg=0.001804
2017/08/30 18:18:59 step 7: objective=0.132903 reg=0.001804
2017/08/30 18:18:59 Training value function...
2017/08/30 18:19:02 step 0: mse=0.212792 step=0.050000
2017/08/30 18:19:04 step 1: mse=0.212482 step=0.050000
2017/08/30 18:19:05 step 2: mse=0.212666 step=0.050000
2017/08/30 18:19:06 step 3: mse=0.212092 step=0.050000
2017/08/30 18:19:08 step 4: mse=0.211789 step=0.050000
2017/08/30 18:19:09 step 5: mse=0.211438 step=0.050000
2017/08/30 18:19:11 step 6: mse=0.211030 step=0.050000
2017/08/30 18:19:12 step 7: mse=0.210985 step=0.050000
2017/08/30 18:19:12 Saving...
2017/08/30 18:19:12 Gathering batch of experience...
2017/08/30 18:19:53 batch 401: mean=31.764706 stddev=10.096764 entropy=0.182258 frames=8343 count=17
2017/08/30 18:19:53 Training policy...
2017/08/30 18:19:58 tune 0: objective=0.132308 reg=0.001823 prune=0
2017/08/30 18:20:00 step 0: objective=0.132307 reg=0.001823
2017/08/30 18:20:02 step 1: objective=0.132411 reg=0.001824
2017/08/30 18:20:03 step 2: objective=0.132487 reg=0.001824
2017/08/30 18:20:05 step 3: objective=0.132538 reg=0.001824
2017/08/30 18:20:07 step 4: objective=0.132596 reg=0.001824
2017/08/30 18:20:08 step 5: objective=0.132682 reg=0.001824
2017/08/30 18:20:10 step 6: objective=0.132780 reg=0.001824
2017/08/30 18:20:12 step 7: objective=0.132832 reg=0.001824
2017/08/30 18:20:12 Training value function...
2017/08/30 18:20:15 step 0: mse=0.209476 step=0.050000
2017/08/30 18:20:17 step 1: mse=0.208962 step=0.050000
2017/08/30 18:20:18 step 2: mse=0.208683 step=0.050000
2017/08/30 18:20:19 step 3: mse=0.208462 step=0.050000
2017/08/30 18:20:21 step 4: mse=0.208468 step=0.050000
2017/08/30 18:20:22 step 5: mse=0.208575 step=0.050000
2017/08/30 18:20:24 step 6: mse=0.208177 step=0.050000
2017/08/30 18:20:25 step 7: mse=0.207746 step=0.050000
2017/08/30 18:20:25 Saving...
2017/08/30 18:20:25 Gathering batch of experience...
2017/08/30 18:21:07 batch 402: mean=29.722222 stddev=11.646676 entropy=0.178979 frames=8304 count=18
2017/08/30 18:21:07 Training policy...
2017/08/30 18:21:12 tune 0: objective=0.125253 reg=0.001790 prune=0
2017/08/30 18:21:14 step 0: objective=0.125253 reg=0.001790
2017/08/30 18:21:16 step 1: objective=0.125340 reg=0.001789
2017/08/30 18:21:17 step 2: objective=0.125392 reg=0.001789
2017/08/30 18:21:19 step 3: objective=0.125442 reg=0.001789
2017/08/30 18:21:21 step 4: objective=0.125493 reg=0.001790
2017/08/30 18:21:22 step 5: objective=0.125599 reg=0.001790
2017/08/30 18:21:24 step 6: objective=0.125697 reg=0.001790
2017/08/30 18:21:26 step 7: objective=0.125777 reg=0.001790
2017/08/30 18:21:26 Training value function...
2017/08/30 18:21:29 step 0: mse=0.214782 step=0.050000
2017/08/30 18:21:31 step 1: mse=0.215377 step=0.050000
2017/08/30 18:21:32 step 2: mse=0.215783 step=0.050000
2017/08/30 18:21:34 step 3: mse=0.216268 step=0.050000
2017/08/30 18:21:35 step 4: mse=0.216679 step=0.050000
2017/08/30 18:21:37 step 5: mse=0.217042 step=0.050000
2017/08/30 18:21:38 step 6: mse=0.217434 step=0.050000
2017/08/30 18:21:39 step 7: mse=0.217697 step=0.050000
2017/08/30 18:21:39 Saving...
2017/08/30 18:21:39 Gathering batch of experience...
2017/08/30 18:22:20 batch 403: mean=29.444444 stddev=13.716261 entropy=0.176718 frames=8213 count=18
2017/08/30 18:22:20 Training policy...
2017/08/30 18:22:25 tune 0: objective=0.131222 reg=0.001767 prune=0
2017/08/30 18:22:27 step 0: objective=0.131222 reg=0.001767
2017/08/30 18:22:28 step 1: objective=0.131302 reg=0.001766
2017/08/30 18:22:30 step 2: objective=0.131373 reg=0.001765
2017/08/30 18:22:32 step 3: objective=0.131457 reg=0.001764
2017/08/30 18:22:33 step 4: objective=0.131513 reg=0.001763
2017/08/30 18:22:35 step 5: objective=0.131549 reg=0.001762
2017/08/30 18:22:37 step 6: objective=0.131608 reg=0.001763
2017/08/30 18:22:38 step 7: objective=0.131664 reg=0.001763
2017/08/30 18:22:38 Training value function...
2017/08/30 18:22:42 step 0: mse=0.219946 step=0.050000
2017/08/30 18:22:43 step 1: mse=0.219234 step=0.050000
2017/08/30 18:22:45 step 2: mse=0.218884 step=0.050000
2017/08/30 18:22:46 step 3: mse=0.218545 step=0.050000
2017/08/30 18:22:48 step 4: mse=0.217990 step=0.050000
2017/08/30 18:22:49 step 5: mse=0.217569 step=0.050000
2017/08/30 18:22:50 step 6: mse=0.217196 step=0.050000
2017/08/30 18:22:52 step 7: mse=0.216983 step=0.050000
2017/08/30 18:22:52 Saving...
2017/08/30 18:22:52 Gathering batch of experience...
2017/08/30 18:23:34 batch 404: mean=31.722222 stddev=12.770650 entropy=0.176550 frames=8816 count=18
2017/08/30 18:23:34 Training policy...
2017/08/30 18:23:40 tune 0: objective=0.137892 reg=0.001766 prune=0
2017/08/30 18:23:42 step 0: objective=0.137892 reg=0.001765
2017/08/30 18:23:44 step 1: objective=0.137999 reg=0.001765
2017/08/30 18:23:46 step 2: objective=0.138063 reg=0.001765
2017/08/30 18:23:47 step 3: objective=0.138156 reg=0.001764
2017/08/30 18:23:49 step 4: objective=0.138278 reg=0.001764
2017/08/30 18:23:51 step 5: objective=0.138342 reg=0.001764
2017/08/30 18:23:53 step 6: objective=0.138422 reg=0.001763
2017/08/30 18:23:54 step 7: objective=0.138454 reg=0.001762
2017/08/30 18:23:54 Training value function...
2017/08/30 18:23:58 step 0: mse=0.216955 step=0.050000
2017/08/30 18:24:00 step 1: mse=0.215491 step=0.050000
2017/08/30 18:24:01 step 2: mse=0.214243 step=0.050000
2017/08/30 18:24:03 step 3: mse=0.213272 step=0.050000
2017/08/30 18:24:04 step 4: mse=0.212144 step=0.050000
2017/08/30 18:24:06 step 5: mse=0.211575 step=0.050000
2017/08/30 18:24:07 step 6: mse=0.210471 step=0.050000
2017/08/30 18:24:09 step 7: mse=0.209723 step=0.050000
2017/08/30 18:24:09 Saving...
2017/08/30 18:24:09 Gathering batch of experience...
2017/08/30 18:24:47 batch 405: mean=30.312500 stddev=11.465812 entropy=0.173140 frames=7494 count=16
2017/08/30 18:24:47 Training policy...
2017/08/30 18:24:52 tune 0: objective=0.128692 reg=0.001731 prune=0
2017/08/30 18:24:54 step 0: objective=0.128693 reg=0.001731
2017/08/30 18:24:55 step 1: objective=0.128818 reg=0.001732
2017/08/30 18:24:57 step 2: objective=0.128956 reg=0.001732
2017/08/30 18:24:58 step 3: objective=0.129078 reg=0.001733
2017/08/30 18:25:00 step 4: objective=0.129162 reg=0.001733
2017/08/30 18:25:01 step 5: objective=0.129207 reg=0.001733
2017/08/30 18:25:03 step 6: objective=0.129288 reg=0.001733
2017/08/30 18:25:04 step 7: objective=0.129391 reg=0.001733
2017/08/30 18:25:04 Training value function...
2017/08/30 18:25:07 step 0: mse=0.203081 step=0.050000
2017/08/30 18:25:09 step 1: mse=0.203451 step=0.050000
2017/08/30 18:25:10 step 2: mse=0.203725 step=0.050000
2017/08/30 18:25:11 step 3: mse=0.204041 step=0.050000
2017/08/30 18:25:13 step 4: mse=0.204355 step=0.050000
2017/08/30 18:25:14 step 5: mse=0.204629 step=0.050000
2017/08/30 18:25:15 step 6: mse=0.204768 step=0.050000
2017/08/30 18:25:17 step 7: mse=0.204978 step=0.050000
2017/08/30 18:25:17 Saving...
2017/08/30 18:25:17 Gathering batch of experience...
2017/08/30 18:25:54 batch 406: mean=33.357143 stddev=10.160196 entropy=0.177636 frames=7211 count=14
2017/08/30 18:25:54 Training policy...
2017/08/30 18:25:59 tune 0: objective=0.136132 reg=0.001776 prune=0
2017/08/30 18:26:00 step 0: objective=0.136133 reg=0.001776
2017/08/30 18:26:02 step 1: objective=0.136210 reg=0.001777
2017/08/30 18:26:03 step 2: objective=0.136345 reg=0.001777
2017/08/30 18:26:05 step 3: objective=0.136437 reg=0.001777
2017/08/30 18:26:06 step 4: objective=0.136521 reg=0.001777
2017/08/30 18:26:08 step 5: objective=0.136630 reg=0.001777
2017/08/30 18:26:09 step 6: objective=0.136735 reg=0.001777
2017/08/30 18:26:10 step 7: objective=0.136780 reg=0.001777
2017/08/30 18:26:10 Training value function...
2017/08/30 18:26:13 step 0: mse=0.210120 step=0.050000
2017/08/30 18:26:15 step 1: mse=0.209342 step=0.050000
2017/08/30 18:26:16 step 2: mse=0.208076 step=0.050000
2017/08/30 18:26:17 step 3: mse=0.207157 step=0.050000
2017/08/30 18:26:18 step 4: mse=0.206725 step=0.050000
2017/08/30 18:26:20 step 5: mse=0.205990 step=0.050000
2017/08/30 18:26:21 step 6: mse=0.205494 step=0.050000
2017/08/30 18:26:22 step 7: mse=0.204608 step=0.050000
2017/08/30 18:26:22 Saving...
2017/08/30 18:26:22 Gathering batch of experience...
2017/08/30 18:27:02 batch 407: mean=28.833333 stddev=13.001068 entropy=0.181059 frames=8030 count=18
2017/08/30 18:27:02 Training policy...
2017/08/30 18:27:07 tune 0: objective=0.126073 reg=0.001811 prune=0
2017/08/30 18:27:09 step 0: objective=0.126073 reg=0.001811
2017/08/30 18:27:10 step 1: objective=0.126120 reg=0.001811
2017/08/30 18:27:12 step 2: objective=0.126188 reg=0.001811
2017/08/30 18:27:14 step 3: objective=0.126257 reg=0.001812
2017/08/30 18:27:15 step 4: objective=0.126316 reg=0.001813
2017/08/30 18:27:17 step 5: objective=0.126399 reg=0.001813
2017/08/30 18:27:18 step 6: objective=0.126500 reg=0.001813
2017/08/30 18:27:20 step 7: objective=0.126541 reg=0.001812
2017/08/30 18:27:20 Training value function...
2017/08/30 18:27:23 step 0: mse=0.205055 step=0.050000
2017/08/30 18:27:25 step 1: mse=0.205482 step=0.050000
2017/08/30 18:27:26 step 2: mse=0.205790 step=0.050000
2017/08/30 18:27:28 step 3: mse=0.205972 step=0.050000
2017/08/30 18:27:29 step 4: mse=0.206285 step=0.050000
2017/08/30 18:27:31 step 5: mse=0.206823 step=0.050000
2017/08/30 18:27:32 step 6: mse=0.207023 step=0.050000
2017/08/30 18:27:33 step 7: mse=0.207123 step=0.050000
2017/08/30 18:27:33 Saving...
2017/08/30 18:27:33 Gathering batch of experience...
2017/08/30 18:28:11 batch 408: mean=31.133333 stddev=12.054690 entropy=0.180475 frames=7218 count=15
2017/08/30 18:28:11 Training policy...
2017/08/30 18:28:16 tune 0: objective=0.133087 reg=0.001805 prune=0
2017/08/30 18:28:17 step 0: objective=0.133088 reg=0.001805
2017/08/30 18:28:19 step 1: objective=0.133180 reg=0.001803
2017/08/30 18:28:20 step 2: objective=0.133264 reg=0.001803
2017/08/30 18:28:22 step 3: objective=0.133340 reg=0.001804
2017/08/30 18:28:23 step 4: objective=0.133451 reg=0.001804
2017/08/30 18:28:24 step 5: objective=0.133561 reg=0.001804
2017/08/30 18:28:26 step 6: objective=0.133630 reg=0.001803
2017/08/30 18:28:27 step 7: objective=0.133712 reg=0.001804
2017/08/30 18:28:27 Training value function...
2017/08/30 18:28:30 step 0: mse=0.206448 step=0.050000
2017/08/30 18:28:32 step 1: mse=0.205648 step=0.050000
2017/08/30 18:28:33 step 2: mse=0.205124 step=0.050000
2017/08/30 18:28:34 step 3: mse=0.205012 step=0.050000
2017/08/30 18:28:35 step 4: mse=0.204807 step=0.050000
2017/08/30 18:28:37 step 5: mse=0.204063 step=0.050000
2017/08/30 18:28:38 step 6: mse=0.203384 step=0.050000
2017/08/30 18:28:39 step 7: mse=0.203171 step=0.050000
2017/08/30 18:28:39 Saving...
2017/08/30 18:28:39 Gathering batch of experience...
2017/08/30 18:29:18 batch 409: mean=33.200000 stddev=10.140348 entropy=0.177090 frames=7699 count=15
2017/08/30 18:29:18 Training policy...
2017/08/30 18:29:23 tune 0: objective=0.133824 reg=0.001771 prune=0
2017/08/30 18:29:25 step 0: objective=0.133824 reg=0.001771
2017/08/30 18:29:26 step 1: objective=0.133904 reg=0.001771
2017/08/30 18:29:28 step 2: objective=0.133991 reg=0.001770
2017/08/30 18:29:29 step 3: objective=0.134051 reg=0.001769
2017/08/30 18:29:31 step 4: objective=0.134113 reg=0.001769
2017/08/30 18:29:32 step 5: objective=0.134193 reg=0.001768
2017/08/30 18:29:34 step 6: objective=0.134306 reg=0.001767
2017/08/30 18:29:36 step 7: objective=0.134397 reg=0.001767
2017/08/30 18:29:36 Training value function...
2017/08/30 18:29:39 step 0: mse=0.212569 step=0.050000
2017/08/30 18:29:40 step 1: mse=0.212536 step=0.050000
2017/08/30 18:29:42 step 2: mse=0.212503 step=0.050000
2017/08/30 18:29:43 step 3: mse=0.211694 step=0.050000
2017/08/30 18:29:44 step 4: mse=0.211239 step=0.050000
2017/08/30 18:29:45 step 5: mse=0.210668 step=0.050000
2017/08/30 18:29:47 step 6: mse=0.210120 step=0.050000
2017/08/30 18:29:48 step 7: mse=0.209922 step=0.050000
2017/08/30 18:29:48 Saving...
2017/08/30 18:29:48 Gathering batch of experience...
2017/08/30 18:30:30 batch 410: mean=30.222222 stddev=14.018066 entropy=0.176199 frames=8421 count=18
2017/08/30 18:30:30 Training policy...
2017/08/30 18:30:36 tune 0: objective=0.130595 reg=0.001762 prune=0
2017/08/30 18:30:37 step 0: objective=0.130595 reg=0.001762
2017/08/30 18:30:39 step 1: objective=0.130668 reg=0.001762
2017/08/30 18:30:41 step 2: objective=0.130786 reg=0.001761
2017/08/30 18:30:42 step 3: objective=0.130905 reg=0.001761
2017/08/30 18:30:44 step 4: objective=0.131006 reg=0.001760
2017/08/30 18:30:46 step 5: objective=0.131128 reg=0.001761
2017/08/30 18:30:48 step 6: objective=0.131204 reg=0.001760
2017/08/30 18:30:49 step 7: objective=0.131278 reg=0.001759
2017/08/30 18:30:49 Training value function...
2017/08/30 18:30:53 step 0: mse=0.208583 step=0.050000
2017/08/30 18:30:54 step 1: mse=0.208559 step=0.050000
2017/08/30 18:30:56 step 2: mse=0.208443 step=0.050000
2017/08/30 18:30:57 step 3: mse=0.208371 step=0.050000
2017/08/30 18:30:59 step 4: mse=0.208074 step=0.050000
2017/08/30 18:31:00 step 5: mse=0.207805 step=0.050000
2017/08/30 18:31:02 step 6: mse=0.207982 step=0.050000
2017/08/30 18:31:03 step 7: mse=0.207953 step=0.050000
2017/08/30 18:31:03 Saving...
2017/08/30 18:31:03 Gathering batch of experience...
2017/08/30 18:31:44 batch 411: mean=34.062500 stddev=7.749748 entropy=0.175419 frames=8431 count=16
2017/08/30 18:31:44 Training policy...
2017/08/30 18:31:50 tune 0: objective=0.132134 reg=0.001754 prune=0
2017/08/30 18:31:51 step 0: objective=0.132135 reg=0.001754
2017/08/30 18:31:53 step 1: objective=0.132194 reg=0.001755
2017/08/30 18:31:55 step 2: objective=0.132298 reg=0.001756
2017/08/30 18:31:57 step 3: objective=0.132387 reg=0.001756
2017/08/30 18:31:58 step 4: objective=0.132466 reg=0.001757
2017/08/30 18:32:00 step 5: objective=0.132505 reg=0.001757
2017/08/30 18:32:02 step 6: objective=0.132613 reg=0.001758
2017/08/30 18:32:03 step 7: objective=0.132730 reg=0.001758
2017/08/30 18:32:03 Training value function...
2017/08/30 18:32:07 step 0: mse=0.206260 step=0.050000
2017/08/30 18:32:08 step 1: mse=0.205675 step=0.050000
2017/08/30 18:32:10 step 2: mse=0.205247 step=0.050000
2017/08/30 18:32:11 step 3: mse=0.204675 step=0.050000
2017/08/30 18:32:13 step 4: mse=0.204240 step=0.050000
2017/08/30 18:32:14 step 5: mse=0.203839 step=0.050000
2017/08/30 18:32:16 step 6: mse=0.203605 step=0.050000
2017/08/30 18:32:17 step 7: mse=0.203470 step=0.050000
2017/08/30 18:32:17 Saving...
2017/08/30 18:32:17 Gathering batch of experience...
2017/08/30 18:32:59 batch 412: mean=26.700000 stddev=13.726252 entropy=0.181135 frames=8278 count=20
2017/08/30 18:32:59 Training policy...
2017/08/30 18:33:05 tune 0: objective=0.121393 reg=0.001811 prune=0
2017/08/30 18:33:06 step 0: objective=0.121393 reg=0.001811
2017/08/30 18:33:08 step 1: objective=0.121465 reg=0.001810
2017/08/30 18:33:10 step 2: objective=0.121527 reg=0.001810
2017/08/30 18:33:11 step 3: objective=0.121602 reg=0.001808
2017/08/30 18:33:13 step 4: objective=0.121672 reg=0.001807
2017/08/30 18:33:15 step 5: objective=0.121731 reg=0.001807
2017/08/30 18:33:17 step 6: objective=0.121769 reg=0.001807
2017/08/30 18:33:18 step 7: objective=0.121818 reg=0.001806
2017/08/30 18:33:18 Training value function...
2017/08/30 18:33:22 step 0: mse=0.205078 step=0.050000
2017/08/30 18:33:23 step 1: mse=0.205599 step=0.050000
2017/08/30 18:33:25 step 2: mse=0.206133 step=0.050000
2017/08/30 18:33:26 step 3: mse=0.206669 step=0.050000
2017/08/30 18:33:28 step 4: mse=0.207367 step=0.050000
2017/08/30 18:33:29 step 5: mse=0.207859 step=0.050000
2017/08/30 18:33:31 step 6: mse=0.208450 step=0.050000
2017/08/30 18:33:32 step 7: mse=0.209052 step=0.050000
2017/08/30 18:33:32 Saving...
2017/08/30 18:33:32 Gathering batch of experience...
2017/08/30 18:34:11 batch 413: mean=30.705882 stddev=13.480988 entropy=0.175563 frames=8058 count=17
2017/08/30 18:34:11 Training policy...
2017/08/30 18:34:17 tune 0: objective=0.136516 reg=0.001756 prune=0
2017/08/30 18:34:18 step 0: objective=0.136516 reg=0.001756
2017/08/30 18:34:20 step 1: objective=0.136600 reg=0.001755
2017/08/30 18:34:22 step 2: objective=0.136712 reg=0.001755
2017/08/30 18:34:23 step 3: objective=0.136820 reg=0.001755
2017/08/30 18:34:25 step 4: objective=0.136899 reg=0.001754
2017/08/30 18:34:27 step 5: objective=0.136974 reg=0.001754
2017/08/30 18:34:28 step 6: objective=0.137085 reg=0.001753
2017/08/30 18:34:30 step 7: objective=0.137107 reg=0.001753
2017/08/30 18:34:30 Training value function...
2017/08/30 18:34:33 step 0: mse=0.211854 step=0.050000
2017/08/30 18:34:35 step 1: mse=0.211295 step=0.050000
2017/08/30 18:34:36 step 2: mse=0.211078 step=0.050000
2017/08/30 18:34:37 step 3: mse=0.210863 step=0.050000
2017/08/30 18:34:39 step 4: mse=0.210316 step=0.050000
2017/08/30 18:34:40 step 5: mse=0.209950 step=0.050000
2017/08/30 18:34:42 step 6: mse=0.209387 step=0.050000
2017/08/30 18:34:43 step 7: mse=0.208815 step=0.050000
2017/08/30 18:34:43 Saving...
2017/08/30 18:34:43 Gathering batch of experience...
2017/08/30 18:35:22 batch 414: mean=29.176471 stddev=15.409070 entropy=0.178069 frames=7637 count=17
2017/08/30 18:35:22 Training policy...
2017/08/30 18:35:27 tune 0: objective=0.137727 reg=0.001781 prune=0
2017/08/30 18:35:29 step 0: objective=0.137727 reg=0.001781
2017/08/30 18:35:30 step 1: objective=0.137804 reg=0.001780
2017/08/30 18:35:32 step 2: objective=0.137918 reg=0.001780
2017/08/30 18:35:33 step 3: objective=0.137996 reg=0.001780
2017/08/30 18:35:35 step 4: objective=0.138126 reg=0.001778
2017/08/30 18:35:36 step 5: objective=0.138194 reg=0.001779
2017/08/30 18:35:38 step 6: objective=0.138266 reg=0.001779
2017/08/30 18:35:39 step 7: objective=0.138365 reg=0.001779
2017/08/30 18:35:39 Training value function...
2017/08/30 18:35:43 step 0: mse=0.211201 step=0.050000
2017/08/30 18:35:44 step 1: mse=0.209574 step=0.050000
2017/08/30 18:35:45 step 2: mse=0.207955 step=0.050000
2017/08/30 18:35:47 step 3: mse=0.207271 step=0.050000
2017/08/30 18:35:48 step 4: mse=0.206137 step=0.050000
2017/08/30 18:35:49 step 5: mse=0.205208 step=0.050000
2017/08/30 18:35:50 step 6: mse=0.203844 step=0.050000
2017/08/30 18:35:52 step 7: mse=0.203033 step=0.050000
2017/08/30 18:35:52 Saving...
2017/08/30 18:35:52 Gathering batch of experience...
2017/08/30 18:36:32 batch 415: mean=33.750000 stddev=9.555757 entropy=0.174883 frames=8325 count=16
2017/08/30 18:36:32 Training policy...
2017/08/30 18:36:38 tune 0: objective=0.135021 reg=0.001749 prune=0
2017/08/30 18:36:39 step 0: objective=0.135022 reg=0.001749
2017/08/30 18:36:41 step 1: objective=0.135097 reg=0.001749
2017/08/30 18:36:43 step 2: objective=0.135174 reg=0.001750
2017/08/30 18:36:45 step 3: objective=0.135255 reg=0.001750
2017/08/30 18:36:46 step 4: objective=0.135350 reg=0.001751
2017/08/30 18:36:48 step 5: objective=0.135402 reg=0.001751
2017/08/30 18:36:50 step 6: objective=0.135462 reg=0.001751
2017/08/30 18:36:51 step 7: objective=0.135538 reg=0.001752
2017/08/30 18:36:51 Training value function...
2017/08/30 18:36:55 step 0: mse=0.201478 step=0.050000
2017/08/30 18:36:56 step 1: mse=0.200760 step=0.050000
2017/08/30 18:36:58 step 2: mse=0.199973 step=0.050000
2017/08/30 18:36:59 step 3: mse=0.199875 step=0.050000
2017/08/30 18:37:01 step 4: mse=0.199193 step=0.050000
2017/08/30 18:37:02 step 5: mse=0.198416 step=0.050000
2017/08/30 18:37:03 step 6: mse=0.198367 step=0.050000
2017/08/30 18:37:05 step 7: mse=0.198229 step=0.050000
2017/08/30 18:37:05 Saving...
2017/08/30 18:37:05 Gathering batch of experience...
2017/08/30 18:37:45 batch 416: mean=32.875000 stddev=10.123457 entropy=0.176680 frames=8130 count=16
2017/08/30 18:37:45 Training policy...
2017/08/30 18:37:50 tune 0: objective=0.129016 reg=0.001767 prune=0
2017/08/30 18:37:52 step 0: objective=0.129015 reg=0.001767
2017/08/30 18:37:53 step 1: objective=0.129062 reg=0.001766
2017/08/30 18:37:55 step 2: objective=0.129151 reg=0.001766
2017/08/30 18:37:57 step 3: objective=0.129211 reg=0.001765
2017/08/30 18:37:58 step 4: objective=0.129314 reg=0.001765
2017/08/30 18:38:00 step 5: objective=0.129355 reg=0.001765
2017/08/30 18:38:02 step 6: objective=0.129405 reg=0.001766
2017/08/30 18:38:03 step 7: objective=0.129449 reg=0.001765
2017/08/30 18:38:03 Training value function...
2017/08/30 18:38:07 step 0: mse=0.198350 step=0.050000
2017/08/30 18:38:08 step 1: mse=0.198552 step=0.050000
2017/08/30 18:38:10 step 2: mse=0.198880 step=0.050000
2017/08/30 18:38:11 step 3: mse=0.198869 step=0.050000
2017/08/30 18:38:12 step 4: mse=0.199062 step=0.050000
2017/08/30 18:38:14 step 5: mse=0.199200 step=0.050000
2017/08/30 18:38:15 step 6: mse=0.199503 step=0.050000
2017/08/30 18:38:17 step 7: mse=0.199616 step=0.050000
2017/08/30 18:38:17 Saving...
2017/08/30 18:38:17 Gathering batch of experience...
2017/08/30 18:38:56 batch 417: mean=33.466667 stddev=10.763312 entropy=0.175419 frames=7772 count=15
2017/08/30 18:38:56 Training policy...
2017/08/30 18:39:01 tune 0: objective=0.131025 reg=0.001754 prune=0
2017/08/30 18:39:03 step 0: objective=0.131025 reg=0.001754
2017/08/30 18:39:04 step 1: objective=0.131159 reg=0.001755
2017/08/30 18:39:06 step 2: objective=0.131282 reg=0.001755
2017/08/30 18:39:07 step 3: objective=0.131335 reg=0.001756
2017/08/30 18:39:09 step 4: objective=0.131380 reg=0.001756
2017/08/30 18:39:11 step 5: objective=0.131432 reg=0.001756
2017/08/30 18:39:12 step 6: objective=0.131568 reg=0.001755
2017/08/30 18:39:14 step 7: objective=0.131623 reg=0.001755
2017/08/30 18:39:14 Training value function...
2017/08/30 18:39:17 step 0: mse=0.212315 step=0.050000
2017/08/30 18:39:18 step 1: mse=0.211520 step=0.050000
2017/08/30 18:39:20 step 2: mse=0.211298 step=0.050000
2017/08/30 18:39:21 step 3: mse=0.210863 step=0.050000
2017/08/30 18:39:22 step 4: mse=0.210598 step=0.050000
2017/08/30 18:39:24 step 5: mse=0.209549 step=0.050000
2017/08/30 18:39:25 step 6: mse=0.209539 step=0.050000
2017/08/30 18:39:26 step 7: mse=0.209319 step=0.050000
2017/08/30 18:39:26 Saving...
2017/08/30 18:39:26 Gathering batch of experience...
2017/08/30 18:40:07 batch 418: mean=35.333333 stddev=7.354515 entropy=0.173558 frames=8169 count=15
2017/08/30 18:40:07 Training policy...
2017/08/30 18:40:12 tune 0: objective=0.136916 reg=0.001736 prune=0
2017/08/30 18:40:14 step 0: objective=0.136916 reg=0.001736
2017/08/30 18:40:15 step 1: objective=0.137017 reg=0.001736
2017/08/30 18:40:17 step 2: objective=0.137100 reg=0.001737
2017/08/30 18:40:19 step 3: objective=0.137222 reg=0.001738
2017/08/30 18:40:20 step 4: objective=0.137324 reg=0.001738
2017/08/30 18:40:22 step 5: objective=0.137377 reg=0.001738
2017/08/30 18:40:24 step 6: objective=0.137455 reg=0.001738
2017/08/30 18:40:25 step 7: objective=0.137498 reg=0.001738
2017/08/30 18:40:25 Training value function...
2017/08/30 18:40:29 step 0: mse=0.201187 step=0.050000
2017/08/30 18:40:30 step 1: mse=0.200343 step=0.050000
2017/08/30 18:40:32 step 2: mse=0.199197 step=0.050000
2017/08/30 18:40:33 step 3: mse=0.198402 step=0.050000
2017/08/30 18:40:34 step 4: mse=0.197683 step=0.050000
2017/08/30 18:40:36 step 5: mse=0.196914 step=0.050000
2017/08/30 18:40:37 step 6: mse=0.196199 step=0.050000
2017/08/30 18:40:39 step 7: mse=0.195565 step=0.050000
2017/08/30 18:40:39 Saving...
2017/08/30 18:40:39 Gathering batch of experience...
2017/08/30 18:41:19 batch 419: mean=35.866667 stddev=8.269354 entropy=0.179796 frames=8327 count=15
2017/08/30 18:41:19 Training policy...
2017/08/30 18:41:25 tune 0: objective=0.132346 reg=0.001798 prune=0
2017/08/30 18:41:26 step 0: objective=0.132346 reg=0.001798
2017/08/30 18:41:28 step 1: objective=0.132438 reg=0.001798
2017/08/30 18:41:30 step 2: objective=0.132498 reg=0.001798
2017/08/30 18:41:32 step 3: objective=0.132589 reg=0.001798
2017/08/30 18:41:33 step 4: objective=0.132672 reg=0.001798
2017/08/30 18:41:35 step 5: objective=0.132733 reg=0.001798
2017/08/30 18:41:37 step 6: objective=0.132785 reg=0.001798
2017/08/30 18:41:38 step 7: objective=0.132847 reg=0.001799
2017/08/30 18:41:38 Training value function...
2017/08/30 18:41:42 step 0: mse=0.195995 step=0.050000
2017/08/30 18:41:43 step 1: mse=0.195806 step=0.050000
2017/08/30 18:41:45 step 2: mse=0.195667 step=0.050000
2017/08/30 18:41:46 step 3: mse=0.195292 step=0.050000
2017/08/30 18:41:48 step 4: mse=0.195017 step=0.050000
2017/08/30 18:41:49 step 5: mse=0.194941 step=0.050000
2017/08/30 18:41:51 step 6: mse=0.194772 step=0.050000
2017/08/30 18:41:52 step 7: mse=0.194541 step=0.050000
2017/08/30 18:41:52 Saving...
2017/08/30 18:41:52 Gathering batch of experience...
2017/08/30 18:42:31 batch 420: mean=27.666667 stddev=13.880442 entropy=0.176234 frames=7758 count=18
2017/08/30 18:42:31 Training policy...
2017/08/30 18:42:36 tune 0: objective=0.114270 reg=0.001762 prune=0
2017/08/30 18:42:38 step 0: objective=0.114270 reg=0.001762
2017/08/30 18:42:40 step 1: objective=0.114402 reg=0.001762
2017/08/30 18:42:41 step 2: objective=0.114471 reg=0.001762
2017/08/30 18:42:43 step 3: objective=0.114590 reg=0.001761
2017/08/30 18:42:44 step 4: objective=0.114643 reg=0.001760
2017/08/30 18:42:46 step 5: objective=0.114698 reg=0.001760
2017/08/30 18:42:48 step 6: objective=0.114750 reg=0.001760
2017/08/30 18:42:49 step 7: objective=0.114853 reg=0.001760
2017/08/30 18:42:49 Training value function...
2017/08/30 18:42:52 step 0: mse=0.207558 step=0.050000
2017/08/30 18:42:54 step 1: mse=0.208477 step=0.050000
2017/08/30 18:42:55 step 2: mse=0.209203 step=0.050000
2017/08/30 18:42:56 step 3: mse=0.209874 step=0.050000
2017/08/30 18:42:58 step 4: mse=0.210964 step=0.050000
2017/08/30 18:42:59 step 5: mse=0.211740 step=0.050000
2017/08/30 18:43:01 step 6: mse=0.212437 step=0.050000
2017/08/30 18:43:02 step 7: mse=0.212947 step=0.050000
2017/08/30 18:43:02 Saving...
2017/08/30 18:43:02 Gathering batch of experience...
2017/08/30 18:43:44 batch 421: mean=30.666667 stddev=14.047538 entropy=0.176192 frames=8540 count=18
2017/08/30 18:43:44 Training policy...
2017/08/30 18:43:50 tune 0: objective=0.134024 reg=0.001762 prune=0
2017/08/30 18:43:51 step 0: objective=0.134024 reg=0.001762
2017/08/30 18:43:53 step 1: objective=0.134100 reg=0.001762
2017/08/30 18:43:55 step 2: objective=0.134186 reg=0.001761
2017/08/30 18:43:57 step 3: objective=0.134272 reg=0.001761
2017/08/30 18:43:58 step 4: objective=0.134317 reg=0.001760
2017/08/30 18:44:00 step 5: objective=0.134358 reg=0.001760
2017/08/30 18:44:02 step 6: objective=0.134441 reg=0.001760
2017/08/30 18:44:04 step 7: objective=0.134494 reg=0.001760
2017/08/30 18:44:04 Training value function...
2017/08/30 18:44:07 step 0: mse=0.209872 step=0.050000
2017/08/30 18:44:09 step 1: mse=0.209173 step=0.050000
2017/08/30 18:44:10 step 2: mse=0.208808 step=0.050000
2017/08/30 18:44:12 step 3: mse=0.208492 step=0.050000
2017/08/30 18:44:13 step 4: mse=0.208072 step=0.050000
2017/08/30 18:44:15 step 5: mse=0.207798 step=0.050000
2017/08/30 18:44:16 step 6: mse=0.207507 step=0.050000
2017/08/30 18:44:18 step 7: mse=0.207342 step=0.050000
2017/08/30 18:44:18 Saving...
2017/08/30 18:44:18 Gathering batch of experience...
2017/08/30 18:44:56 batch 422: mean=26.666667 stddev=13.589211 entropy=0.181511 frames=7446 count=18
2017/08/30 18:44:56 Training policy...
2017/08/30 18:45:01 tune 0: objective=0.118615 reg=0.001815 prune=0
2017/08/30 18:45:02 step 0: objective=0.118616 reg=0.001815
2017/08/30 18:45:04 step 1: objective=0.118718 reg=0.001815
2017/08/30 18:45:05 step 2: objective=0.118784 reg=0.001814
2017/08/30 18:45:07 step 3: objective=0.118840 reg=0.001814
2017/08/30 18:45:08 step 4: objective=0.118898 reg=0.001813
2017/08/30 18:45:10 step 5: objective=0.118945 reg=0.001813
2017/08/30 18:45:11 step 6: objective=0.119027 reg=0.001812
2017/08/30 18:45:13 step 7: objective=0.119118 reg=0.001812
2017/08/30 18:45:13 Training value function...
2017/08/30 18:45:16 step 0: mse=0.207534 step=0.050000
2017/08/30 18:45:18 step 1: mse=0.208601 step=0.050000
2017/08/30 18:45:19 step 2: mse=0.209670 step=0.050000
2017/08/30 18:45:20 step 3: mse=0.210710 step=0.050000
2017/08/30 18:45:21 step 4: mse=0.211806 step=0.050000
2017/08/30 18:45:23 step 5: mse=0.212740 step=0.050000
2017/08/30 18:45:24 step 6: mse=0.213624 step=0.050000
2017/08/30 18:45:25 step 7: mse=0.214349 step=0.050000
2017/08/30 18:45:25 Saving...
2017/08/30 18:45:25 Gathering batch of experience...
2017/08/30 18:46:06 batch 423: mean=34.062500 stddev=7.369436 entropy=0.177770 frames=8420 count=16
2017/08/30 18:46:06 Training policy...
2017/08/30 18:46:12 tune 0: objective=0.136651 reg=0.001778 prune=0
2017/08/30 18:46:14 step 0: objective=0.136651 reg=0.001778
2017/08/30 18:46:15 step 1: objective=0.136739 reg=0.001777
2017/08/30 18:46:17 step 2: objective=0.136876 reg=0.001777
2017/08/30 18:46:19 step 3: objective=0.136951 reg=0.001778
2017/08/30 18:46:21 step 4: objective=0.137057 reg=0.001778
2017/08/30 18:46:22 step 5: objective=0.137149 reg=0.001778
2017/08/30 18:46:24 step 6: objective=0.137183 reg=0.001778
2017/08/30 18:46:26 step 7: objective=0.137232 reg=0.001778
2017/08/30 18:46:26 Training value function...
2017/08/30 18:46:29 step 0: mse=0.213899 step=0.050000
2017/08/30 18:46:31 step 1: mse=0.212843 step=0.050000
2017/08/30 18:46:32 step 2: mse=0.212028 step=0.050000
2017/08/30 18:46:34 step 3: mse=0.211290 step=0.050000
2017/08/30 18:46:35 step 4: mse=0.210646 step=0.050000
2017/08/30 18:46:37 step 5: mse=0.209939 step=0.050000
2017/08/30 18:46:38 step 6: mse=0.209443 step=0.050000
2017/08/30 18:46:39 step 7: mse=0.208682 step=0.050000
2017/08/30 18:46:39 Saving...
2017/08/30 18:46:40 Gathering batch of experience...
2017/08/30 18:47:21 batch 424: mean=31.941176 stddev=11.948274 entropy=0.179063 frames=8392 count=17
2017/08/30 18:47:21 Training policy...
2017/08/30 18:47:27 tune 0: objective=0.135000 reg=0.001791 prune=0
2017/08/30 18:47:29 step 0: objective=0.135000 reg=0.001791
2017/08/30 18:47:30 step 1: objective=0.135066 reg=0.001790
2017/08/30 18:47:32 step 2: objective=0.135116 reg=0.001790
2017/08/30 18:47:34 step 3: objective=0.135188 reg=0.001789
2017/08/30 18:47:36 step 4: objective=0.135239 reg=0.001789
2017/08/30 18:47:37 step 5: objective=0.135295 reg=0.001790
2017/08/30 18:47:39 step 6: objective=0.135344 reg=0.001789
2017/08/30 18:47:41 step 7: objective=0.135382 reg=0.001788
2017/08/30 18:47:41 Training value function...
2017/08/30 18:47:44 step 0: mse=0.209143 step=0.050000
2017/08/30 18:47:46 step 1: mse=0.208696 step=0.050000
2017/08/30 18:47:47 step 2: mse=0.208254 step=0.050000
2017/08/30 18:47:49 step 3: mse=0.207896 step=0.050000
2017/08/30 18:47:50 step 4: mse=0.207227 step=0.050000
2017/08/30 18:47:52 step 5: mse=0.206820 step=0.050000
2017/08/30 18:47:53 step 6: mse=0.206343 step=0.050000
2017/08/30 18:47:55 step 7: mse=0.206163 step=0.050000
2017/08/30 18:47:55 Saving...
2017/08/30 18:47:55 Gathering batch of experience...
2017/08/30 18:48:34 batch 425: mean=28.666667 stddev=11.841546 entropy=0.177880 frames=8005 count=18
2017/08/30 18:48:34 Training policy...
2017/08/30 18:48:39 tune 0: objective=0.124808 reg=0.001779 prune=0
2017/08/30 18:48:41 step 0: objective=0.124808 reg=0.001779
2017/08/30 18:48:43 step 1: objective=0.124887 reg=0.001778
2017/08/30 18:48:44 step 2: objective=0.124979 reg=0.001778
2017/08/30 18:48:46 step 3: objective=0.125110 reg=0.001779
2017/08/30 18:48:48 step 4: objective=0.125148 reg=0.001778
2017/08/30 18:48:49 step 5: objective=0.125225 reg=0.001778
2017/08/30 18:48:51 step 6: objective=0.125297 reg=0.001777
2017/08/30 18:48:53 step 7: objective=0.125411 reg=0.001776
2017/08/30 18:48:53 Training value function...
2017/08/30 18:48:56 step 0: mse=0.211077 step=0.050000
2017/08/30 18:48:57 step 1: mse=0.210839 step=0.050000
2017/08/30 18:48:59 step 2: mse=0.210917 step=0.050000
2017/08/30 18:49:00 step 3: mse=0.210993 step=0.050000
2017/08/30 18:49:01 step 4: mse=0.210785 step=0.050000
2017/08/30 18:49:03 step 5: mse=0.210766 step=0.050000
2017/08/30 18:49:04 step 6: mse=0.210971 step=0.050000
2017/08/30 18:49:06 step 7: mse=0.211319 step=0.050000
2017/08/30 18:49:06 Saving...
2017/08/30 18:49:06 Gathering batch of experience...
2017/08/30 18:49:47 batch 426: mean=29.555556 stddev=11.275451 entropy=0.178831 frames=8252 count=18
2017/08/30 18:49:47 Training policy...
2017/08/30 18:49:53 tune 0: objective=0.126666 reg=0.001788 prune=0
2017/08/30 18:49:54 step 0: objective=0.126667 reg=0.001788
2017/08/30 18:49:56 step 1: objective=0.126730 reg=0.001788
2017/08/30 18:49:58 step 2: objective=0.126828 reg=0.001787
2017/08/30 18:49:59 step 3: objective=0.126891 reg=0.001787
2017/08/30 18:50:01 step 4: objective=0.126997 reg=0.001787
2017/08/30 18:50:03 step 5: objective=0.127095 reg=0.001787
2017/08/30 18:50:04 step 6: objective=0.127171 reg=0.001787
2017/08/30 18:50:06 step 7: objective=0.127237 reg=0.001789
2017/08/30 18:50:06 Training value function...
2017/08/30 18:50:10 step 0: mse=0.211515 step=0.050000
2017/08/30 18:50:11 step 1: mse=0.211750 step=0.050000
2017/08/30 18:50:13 step 2: mse=0.212051 step=0.050000
2017/08/30 18:50:14 step 3: mse=0.212408 step=0.050000
2017/08/30 18:50:15 step 4: mse=0.212404 step=0.050000
2017/08/30 18:50:17 step 5: mse=0.212546 step=0.050000
2017/08/30 18:50:18 step 6: mse=0.212741 step=0.050000
2017/08/30 18:50:20 step 7: mse=0.212730 step=0.050000
2017/08/30 18:50:20 Saving...
2017/08/30 18:50:20 Gathering batch of experience...
2017/08/30 18:51:00 batch 427: mean=35.066667 stddev=6.526527 entropy=0.175857 frames=8104 count=15
2017/08/30 18:51:00 Training policy...
2017/08/30 18:51:05 tune 0: objective=0.139916 reg=0.001759 prune=0
2017/08/30 18:51:07 step 0: objective=0.139916 reg=0.001759
2017/08/30 18:51:09 step 1: objective=0.140057 reg=0.001759
2017/08/30 18:51:10 step 2: objective=0.140138 reg=0.001760
2017/08/30 18:51:12 step 3: objective=0.140263 reg=0.001760
2017/08/30 18:51:14 step 4: objective=0.140351 reg=0.001761
2017/08/30 18:51:15 step 5: objective=0.140437 reg=0.001761
2017/08/30 18:51:17 step 6: objective=0.140567 reg=0.001761
2017/08/30 18:51:18 step 7: objective=0.140651 reg=0.001762
2017/08/30 18:51:18 Training value function...
2017/08/30 18:51:22 step 0: mse=0.212086 step=0.050000
2017/08/30 18:51:23 step 1: mse=0.210871 step=0.050000
2017/08/30 18:51:25 step 2: mse=0.209433 step=0.050000
2017/08/30 18:51:26 step 3: mse=0.208302 step=0.050000
2017/08/30 18:51:27 step 4: mse=0.206995 step=0.050000
2017/08/30 18:51:29 step 5: mse=0.205864 step=0.050000
2017/08/30 18:51:30 step 6: mse=0.205155 step=0.050000
2017/08/30 18:51:32 step 7: mse=0.204355 step=0.050000
2017/08/30 18:51:32 Saving...
2017/08/30 18:51:32 Gathering batch of experience...
2017/08/30 18:52:11 batch 428: mean=31.562500 stddev=11.418016 entropy=0.178739 frames=7799 count=16
2017/08/30 18:52:11 Training policy...
2017/08/30 18:52:16 tune 0: objective=0.133373 reg=0.001787 prune=0
2017/08/30 18:52:18 step 0: objective=0.133373 reg=0.001787
2017/08/30 18:52:19 step 1: objective=0.133425 reg=0.001788
2017/08/30 18:52:21 step 2: objective=0.133488 reg=0.001787
2017/08/30 18:52:23 step 3: objective=0.133581 reg=0.001788
2017/08/30 18:52:24 step 4: objective=0.133674 reg=0.001788
2017/08/30 18:52:26 step 5: objective=0.133733 reg=0.001787
2017/08/30 18:52:27 step 6: objective=0.133798 reg=0.001787
2017/08/30 18:52:29 step 7: objective=0.133834 reg=0.001787
2017/08/30 18:52:29 Training value function...
2017/08/30 18:52:32 step 0: mse=0.208993 step=0.050000
2017/08/30 18:52:34 step 1: mse=0.208628 step=0.050000
2017/08/30 18:52:35 step 2: mse=0.208414 step=0.050000
2017/08/30 18:52:36 step 3: mse=0.208335 step=0.050000
2017/08/30 18:52:38 step 4: mse=0.208228 step=0.050000
2017/08/30 18:52:39 step 5: mse=0.208340 step=0.050000
2017/08/30 18:52:40 step 6: mse=0.207610 step=0.050000
2017/08/30 18:52:42 step 7: mse=0.207192 step=0.050000
2017/08/30 18:52:42 Saving...
2017/08/30 18:52:42 Gathering batch of experience...
2017/08/30 18:53:22 batch 429: mean=32.058824 stddev=11.069144 entropy=0.175986 frames=8429 count=17
2017/08/30 18:53:22 Training policy...
2017/08/30 18:53:28 tune 0: objective=0.130290 reg=0.001760 prune=0
2017/08/30 18:53:30 step 0: objective=0.130290 reg=0.001760
2017/08/30 18:53:32 step 1: objective=0.130356 reg=0.001760
2017/08/30 18:53:33 step 2: objective=0.130466 reg=0.001759
2017/08/30 18:53:35 step 3: objective=0.130524 reg=0.001759
2017/08/30 18:53:37 step 4: objective=0.130610 reg=0.001758
2017/08/30 18:53:38 step 5: objective=0.130661 reg=0.001758
2017/08/30 18:53:40 step 6: objective=0.130714 reg=0.001757
2017/08/30 18:53:42 step 7: objective=0.130776 reg=0.001757
2017/08/30 18:53:42 Training value function...
2017/08/30 18:53:46 step 0: mse=0.206671 step=0.050000
2017/08/30 18:53:47 step 1: mse=0.206630 step=0.050000
2017/08/30 18:53:49 step 2: mse=0.206454 step=0.050000
2017/08/30 18:53:50 step 3: mse=0.206268 step=0.050000
2017/08/30 18:53:52 step 4: mse=0.206190 step=0.050000
2017/08/30 18:53:53 step 5: mse=0.206157 step=0.050000
2017/08/30 18:53:54 step 6: mse=0.206297 step=0.050000
2017/08/30 18:53:56 step 7: mse=0.206298 step=0.050000
2017/08/30 18:53:56 Saving...
2017/08/30 18:53:56 Gathering batch of experience...
2017/08/30 18:54:37 batch 430: mean=36.533333 stddev=6.312598 entropy=0.172867 frames=8449 count=15
2017/08/30 18:54:37 Training policy...
2017/08/30 18:54:43 tune 0: objective=0.140061 reg=0.001729 prune=0
2017/08/30 18:54:44 step 0: objective=0.140061 reg=0.001729
2017/08/30 18:54:46 step 1: objective=0.140168 reg=0.001729
2017/08/30 18:54:48 step 2: objective=0.140272 reg=0.001730
2017/08/30 18:54:50 step 3: objective=0.140330 reg=0.001729
2017/08/30 18:54:51 step 4: objective=0.140392 reg=0.001729
2017/08/30 18:54:53 step 5: objective=0.140447 reg=0.001729
2017/08/30 18:54:55 step 6: objective=0.140550 reg=0.001729
2017/08/30 18:54:57 step 7: objective=0.140651 reg=0.001728
2017/08/30 18:54:57 Training value function...
2017/08/30 18:55:00 step 0: mse=0.205906 step=0.050000
2017/08/30 18:55:02 step 1: mse=0.204581 step=0.050000
2017/08/30 18:55:03 step 2: mse=0.203264 step=0.050000
2017/08/30 18:55:04 step 3: mse=0.202191 step=0.050000
2017/08/30 18:55:06 step 4: mse=0.201099 step=0.050000
2017/08/30 18:55:07 step 5: mse=0.200212 step=0.050000
2017/08/30 18:55:09 step 6: mse=0.199357 step=0.050000
2017/08/30 18:55:10 step 7: mse=0.198491 step=0.050000
2017/08/30 18:55:10 Saving...
2017/08/30 18:55:10 Gathering batch of experience...
2017/08/30 18:55:53 batch 431: mean=28.100000 stddev=14.710201 entropy=0.179880 frames=8695 count=20
2017/08/30 18:55:53 Training policy...
2017/08/30 18:55:59 tune 0: objective=0.123991 reg=0.001799 prune=0
2017/08/30 18:56:01 step 0: objective=0.123991 reg=0.001799
2017/08/30 18:56:03 step 1: objective=0.124033 reg=0.001798
2017/08/30 18:56:05 step 2: objective=0.124073 reg=0.001798
2017/08/30 18:56:07 step 3: objective=0.124147 reg=0.001797
2017/08/30 18:56:08 step 4: objective=0.124219 reg=0.001796
2017/08/30 18:56:10 step 5: objective=0.124297 reg=0.001796
2017/08/30 18:56:12 step 6: objective=0.124367 reg=0.001796
2017/08/30 18:56:14 step 7: objective=0.124429 reg=0.001796
2017/08/30 18:56:14 Training value function...
2017/08/30 18:56:17 step 0: mse=0.201797 step=0.050000
2017/08/30 18:56:19 step 1: mse=0.202193 step=0.050000
2017/08/30 18:56:20 step 2: mse=0.202429 step=0.050000
2017/08/30 18:56:22 step 3: mse=0.202725 step=0.050000
2017/08/30 18:56:24 step 4: mse=0.202854 step=0.050000
2017/08/30 18:56:25 step 5: mse=0.203001 step=0.050000
2017/08/30 18:56:27 step 6: mse=0.203194 step=0.050000
2017/08/30 18:56:28 step 7: mse=0.203437 step=0.050000
2017/08/30 18:56:28 Saving...
2017/08/30 18:56:28 Gathering batch of experience...
2017/08/30 18:57:08 batch 432: mean=30.058824 stddev=12.660595 entropy=0.176559 frames=7898 count=17
2017/08/30 18:57:08 Training policy...
2017/08/30 18:57:13 tune 0: objective=0.127461 reg=0.001766 prune=0
2017/08/30 18:57:15 step 0: objective=0.127461 reg=0.001766
2017/08/30 18:57:16 step 1: objective=0.127564 reg=0.001765
2017/08/30 18:57:18 step 2: objective=0.127639 reg=0.001765
2017/08/30 18:57:20 step 3: objective=0.127734 reg=0.001764
2017/08/30 18:57:21 step 4: objective=0.127809 reg=0.001763
2017/08/30 18:57:23 step 5: objective=0.127853 reg=0.001762
2017/08/30 18:57:24 step 6: objective=0.127918 reg=0.001761
2017/08/30 18:57:26 step 7: objective=0.127988 reg=0.001761
2017/08/30 18:57:26 Training value function...
2017/08/30 18:57:29 step 0: mse=0.204478 step=0.050000
2017/08/30 18:57:31 step 1: mse=0.204925 step=0.050000
2017/08/30 18:57:32 step 2: mse=0.205239 step=0.050000
2017/08/30 18:57:33 step 3: mse=0.205564 step=0.050000
2017/08/30 18:57:35 step 4: mse=0.205635 step=0.050000
2017/08/30 18:57:36 step 5: mse=0.205674 step=0.050000
2017/08/30 18:57:38 step 6: mse=0.205886 step=0.050000
2017/08/30 18:57:39 step 7: mse=0.206170 step=0.050000
2017/08/30 18:57:39 Saving...
2017/08/30 18:57:39 Gathering batch of experience...
2017/08/30 18:58:19 batch 433: mean=34.933333 stddev=7.406904 entropy=0.174862 frames=8098 count=15
2017/08/30 18:58:19 Training policy...
2017/08/30 18:58:24 tune 0: objective=0.134666 reg=0.001749 prune=0
2017/08/30 18:58:26 step 0: objective=0.134666 reg=0.001749
2017/08/30 18:58:27 step 1: objective=0.134721 reg=0.001749
2017/08/30 18:58:29 step 2: objective=0.134775 reg=0.001750
2017/08/30 18:58:31 step 3: objective=0.134840 reg=0.001750
2017/08/30 18:58:32 step 4: objective=0.134888 reg=0.001750
2017/08/30 18:58:34 step 5: objective=0.134936 reg=0.001750
2017/08/30 18:58:36 step 6: objective=0.134969 reg=0.001751
2017/08/30 18:58:37 step 7: objective=0.135044 reg=0.001750
2017/08/30 18:58:37 Training value function...
2017/08/30 18:58:41 step 0: mse=0.209293 step=0.050000
2017/08/30 18:58:42 step 1: mse=0.208691 step=0.050000
2017/08/30 18:58:43 step 2: mse=0.208217 step=0.050000
2017/08/30 18:58:45 step 3: mse=0.207285 step=0.050000
2017/08/30 18:58:46 step 4: mse=0.206917 step=0.050000
2017/08/30 18:58:48 step 5: mse=0.206326 step=0.050000
2017/08/30 18:58:49 step 6: mse=0.205681 step=0.050000
2017/08/30 18:58:50 step 7: mse=0.205521 step=0.050000
2017/08/30 18:58:50 Saving...
2017/08/30 18:58:50 Gathering batch of experience...
2017/08/30 18:59:30 batch 434: mean=29.222222 stddev=12.925236 entropy=0.175452 frames=8150 count=18
2017/08/30 18:59:30 Training policy...
2017/08/30 18:59:36 tune 0: objective=0.124976 reg=0.001755 prune=0
2017/08/30 18:59:38 step 0: objective=0.124976 reg=0.001755
2017/08/30 18:59:39 step 1: objective=0.125039 reg=0.001754
2017/08/30 18:59:41 step 2: objective=0.125091 reg=0.001754
2017/08/30 18:59:43 step 3: objective=0.125157 reg=0.001754
2017/08/30 18:59:44 step 4: objective=0.125227 reg=0.001754
2017/08/30 18:59:46 step 5: objective=0.125321 reg=0.001753
2017/08/30 18:59:48 step 6: objective=0.125409 reg=0.001753
2017/08/30 18:59:49 step 7: objective=0.125477 reg=0.001752
2017/08/30 18:59:49 Training value function...
2017/08/30 18:59:53 step 0: mse=0.207400 step=0.050000
2017/08/30 18:59:54 step 1: mse=0.207798 step=0.050000
2017/08/30 18:59:56 step 2: mse=0.208226 step=0.050000
2017/08/30 18:59:57 step 3: mse=0.208462 step=0.050000
2017/08/30 18:59:59 step 4: mse=0.208780 step=0.050000
2017/08/30 19:00:00 step 5: mse=0.209025 step=0.050000
2017/08/30 19:00:01 step 6: mse=0.209389 step=0.050000
2017/08/30 19:00:03 step 7: mse=0.209744 step=0.050000
2017/08/30 19:00:03 Saving...
2017/08/30 19:00:03 Gathering batch of experience...
2017/08/30 19:00:42 batch 435: mean=29.117647 stddev=12.778117 entropy=0.175161 frames=7661 count=17
2017/08/30 19:00:42 Training policy...
2017/08/30 19:00:47 tune 0: objective=0.128084 reg=0.001752 prune=0
2017/08/30 19:00:49 step 0: objective=0.128084 reg=0.001752
2017/08/30 19:00:50 step 1: objective=0.128208 reg=0.001751
2017/08/30 19:00:52 step 2: objective=0.128250 reg=0.001751
2017/08/30 19:00:53 step 3: objective=0.128310 reg=0.001751
2017/08/30 19:00:55 step 4: objective=0.128362 reg=0.001752
2017/08/30 19:00:57 step 5: objective=0.128405 reg=0.001752
2017/08/30 19:00:58 step 6: objective=0.128470 reg=0.001751
2017/08/30 19:01:00 step 7: objective=0.128559 reg=0.001751
2017/08/30 19:01:00 Training value function...
2017/08/30 19:01:03 step 0: mse=0.210449 step=0.050000
2017/08/30 19:01:04 step 1: mse=0.210753 step=0.050000
2017/08/30 19:01:06 step 2: mse=0.210828 step=0.050000
2017/08/30 19:01:07 step 3: mse=0.211321 step=0.050000
2017/08/30 19:01:08 step 4: mse=0.211607 step=0.050000
2017/08/30 19:01:10 step 5: mse=0.211980 step=0.050000
2017/08/30 19:01:11 step 6: mse=0.212260 step=0.050000
2017/08/30 19:01:12 step 7: mse=0.212578 step=0.050000
2017/08/30 19:01:12 Saving...
2017/08/30 19:01:12 Gathering batch of experience...
2017/08/30 19:01:51 batch 436: mean=31.437500 stddev=13.299289 entropy=0.175362 frames=7759 count=16
2017/08/30 19:01:51 Training policy...
2017/08/30 19:01:56 tune 0: objective=0.135803 reg=0.001754 prune=0
2017/08/30 19:01:58 step 0: objective=0.135803 reg=0.001754
2017/08/30 19:02:00 step 1: objective=0.135871 reg=0.001754
2017/08/30 19:02:01 step 2: objective=0.135950 reg=0.001754
2017/08/30 19:02:03 step 3: objective=0.136034 reg=0.001754
2017/08/30 19:02:04 step 4: objective=0.136107 reg=0.001755
2017/08/30 19:02:06 step 5: objective=0.136150 reg=0.001755
2017/08/30 19:02:08 step 6: objective=0.136230 reg=0.001755
2017/08/30 19:02:09 step 7: objective=0.136298 reg=0.001755
2017/08/30 19:02:09 Training value function...
2017/08/30 19:02:12 step 0: mse=0.208470 step=0.050000
2017/08/30 19:02:14 step 1: mse=0.207553 step=0.050000
2017/08/30 19:02:15 step 2: mse=0.207007 step=0.050000
2017/08/30 19:02:16 step 3: mse=0.205870 step=0.050000
2017/08/30 19:02:18 step 4: mse=0.205367 step=0.050000
2017/08/30 19:02:19 step 5: mse=0.204781 step=0.050000
2017/08/30 19:02:20 step 6: mse=0.204175 step=0.050000
2017/08/30 19:02:22 step 7: mse=0.203735 step=0.050000
2017/08/30 19:02:22 Saving...
2017/08/30 19:02:22 Gathering batch of experience...
2017/08/30 19:03:05 batch 437: mean=31.722222 stddev=13.227940 entropy=0.175489 frames=8813 count=18
2017/08/30 19:03:05 Training policy...
2017/08/30 19:03:11 tune 0: objective=0.134274 reg=0.001755 prune=0
2017/08/30 19:03:13 step 0: objective=0.134274 reg=0.001755
2017/08/30 19:03:14 step 1: objective=0.134403 reg=0.001755
2017/08/30 19:03:16 step 2: objective=0.134556 reg=0.001756
2017/08/30 19:03:18 step 3: objective=0.134656 reg=0.001755
2017/08/30 19:03:20 step 4: objective=0.134757 reg=0.001754
2017/08/30 19:03:22 step 5: objective=0.134843 reg=0.001753
2017/08/30 19:03:24 step 6: objective=0.134911 reg=0.001753
2017/08/30 19:03:25 step 7: objective=0.134988 reg=0.001752
2017/08/30 19:03:25 Training value function...
2017/08/30 19:03:29 step 0: mse=0.207186 step=0.050000
2017/08/30 19:03:31 step 1: mse=0.206430 step=0.050000
2017/08/30 19:03:32 step 2: mse=0.205712 step=0.050000
2017/08/30 19:03:34 step 3: mse=0.205359 step=0.050000
2017/08/30 19:03:35 step 4: mse=0.204617 step=0.050000
2017/08/30 19:03:37 step 5: mse=0.204191 step=0.050000
2017/08/30 19:03:38 step 6: mse=0.203796 step=0.050000
2017/08/30 19:03:40 step 7: mse=0.203571 step=0.050000
2017/08/30 19:03:40 Saving...
2017/08/30 19:03:40 Gathering batch of experience...
2017/08/30 19:04:18 batch 438: mean=30.562500 stddev=14.238894 entropy=0.173176 frames=7560 count=16
2017/08/30 19:04:18 Training policy...
2017/08/30 19:04:23 tune 0: objective=0.130335 reg=0.001732 prune=0
2017/08/30 19:04:25 step 0: objective=0.130335 reg=0.001732
2017/08/30 19:04:26 step 1: objective=0.130438 reg=0.001731
2017/08/30 19:04:28 step 2: objective=0.130530 reg=0.001730
2017/08/30 19:04:29 step 3: objective=0.130626 reg=0.001730
2017/08/30 19:04:31 step 4: objective=0.130711 reg=0.001729
2017/08/30 19:04:32 step 5: objective=0.130792 reg=0.001728
2017/08/30 19:04:34 step 6: objective=0.130860 reg=0.001728
2017/08/30 19:04:36 step 7: objective=0.130893 reg=0.001728
2017/08/30 19:04:36 Training value function...
2017/08/30 19:04:39 step 0: mse=0.210812 step=0.050000
2017/08/30 19:04:40 step 1: mse=0.210548 step=0.050000
2017/08/30 19:04:41 step 2: mse=0.210356 step=0.050000
2017/08/30 19:04:43 step 3: mse=0.209889 step=0.050000
2017/08/30 19:04:44 step 4: mse=0.209352 step=0.050000
2017/08/30 19:04:45 step 5: mse=0.208989 step=0.050000
2017/08/30 19:04:46 step 6: mse=0.208467 step=0.050000
2017/08/30 19:04:48 step 7: mse=0.208007 step=0.050000
2017/08/30 19:04:48 Saving...
2017/08/30 19:04:48 Gathering batch of experience...
2017/08/30 19:05:30 batch 439: mean=30.333333 stddev=12.489996 entropy=0.175752 frames=8434 count=18
2017/08/30 19:05:30 Training policy...
2017/08/30 19:05:36 tune 0: objective=0.127362 reg=0.001758 prune=0
2017/08/30 19:05:38 step 0: objective=0.127363 reg=0.001758
2017/08/30 19:05:39 step 1: objective=0.127410 reg=0.001757
2017/08/30 19:05:41 step 2: objective=0.127455 reg=0.001757
2017/08/30 19:05:43 step 3: objective=0.127497 reg=0.001756
2017/08/30 19:05:45 step 4: objective=0.127543 reg=0.001756
2017/08/30 19:05:46 step 5: objective=0.127586 reg=0.001755
2017/08/30 19:05:48 step 6: objective=0.127637 reg=0.001755
2017/08/30 19:05:50 step 7: objective=0.127669 reg=0.001755
2017/08/30 19:05:50 Training value function...
2017/08/30 19:05:53 step 0: mse=0.206144 step=0.050000
2017/08/30 19:05:55 step 1: mse=0.206139 step=0.050000
2017/08/30 19:05:56 step 2: mse=0.206444 step=0.050000
2017/08/30 19:05:58 step 3: mse=0.206632 step=0.050000
2017/08/30 19:05:59 step 4: mse=0.206779 step=0.050000
2017/08/30 19:06:01 step 5: mse=0.206864 step=0.050000
2017/08/30 19:06:02 step 6: mse=0.207027 step=0.050000
2017/08/30 19:06:04 step 7: mse=0.207096 step=0.050000
2017/08/30 19:06:04 Saving...
2017/08/30 19:06:04 Gathering batch of experience...
2017/08/30 19:06:45 batch 440: mean=31.941176 stddev=10.223793 entropy=0.175122 frames=8396 count=17
2017/08/30 19:06:45 Training policy...
2017/08/30 19:06:50 tune 0: objective=0.128886 reg=0.001751 prune=0
2017/08/30 19:06:52 step 0: objective=0.128886 reg=0.001751
2017/08/30 19:06:54 step 1: objective=0.128955 reg=0.001751
2017/08/30 19:06:55 step 2: objective=0.129072 reg=0.001751
2017/08/30 19:06:57 step 3: objective=0.129131 reg=0.001751
2017/08/30 19:06:59 step 4: objective=0.129190 reg=0.001751
2017/08/30 19:07:01 step 5: objective=0.129278 reg=0.001751
2017/08/30 19:07:02 step 6: objective=0.129374 reg=0.001751
2017/08/30 19:07:04 step 7: objective=0.129449 reg=0.001750
2017/08/30 19:07:04 Training value function...
2017/08/30 19:07:08 step 0: mse=0.204498 step=0.050000
2017/08/30 19:07:09 step 1: mse=0.204358 step=0.050000
2017/08/30 19:07:11 step 2: mse=0.204316 step=0.050000
2017/08/30 19:07:12 step 3: mse=0.204624 step=0.050000
2017/08/30 19:07:14 step 4: mse=0.204436 step=0.050000
2017/08/30 19:07:15 step 5: mse=0.204639 step=0.050000
2017/08/30 19:07:16 step 6: mse=0.204877 step=0.050000
2017/08/30 19:07:18 step 7: mse=0.205039 step=0.050000
2017/08/30 19:07:18 Saving...
2017/08/30 19:07:18 Gathering batch of experience...
2017/08/30 19:07:56 batch 441: mean=32.533333 stddev=8.739692 entropy=0.173373 frames=7549 count=15
2017/08/30 19:07:56 Training policy...
2017/08/30 19:08:01 tune 0: objective=0.131371 reg=0.001734 prune=0
2017/08/30 19:08:03 step 0: objective=0.131371 reg=0.001734
2017/08/30 19:08:05 step 1: objective=0.131469 reg=0.001733
2017/08/30 19:08:06 step 2: objective=0.131610 reg=0.001731
2017/08/30 19:08:08 step 3: objective=0.131729 reg=0.001731
2017/08/30 19:08:09 step 4: objective=0.131797 reg=0.001730
2017/08/30 19:08:11 step 5: objective=0.131851 reg=0.001729
2017/08/30 19:08:12 step 6: objective=0.131920 reg=0.001728
2017/08/30 19:08:14 step 7: objective=0.132027 reg=0.001727
2017/08/30 19:08:14 Training value function...
2017/08/30 19:08:17 step 0: mse=0.210416 step=0.050000
2017/08/30 19:08:18 step 1: mse=0.209565 step=0.050000
2017/08/30 19:08:20 step 2: mse=0.209055 step=0.050000
2017/08/30 19:08:21 step 3: mse=0.208734 step=0.050000
2017/08/30 19:08:22 step 4: mse=0.208293 step=0.050000
2017/08/30 19:08:24 step 5: mse=0.207926 step=0.050000
2017/08/30 19:08:25 step 6: mse=0.207578 step=0.050000
2017/08/30 19:08:26 step 7: mse=0.207570 step=0.050000
2017/08/30 19:08:26 Saving...
2017/08/30 19:08:26 Gathering batch of experience...
2017/08/30 19:09:05 batch 442: mean=24.947368 stddev=14.773638 entropy=0.176887 frames=7359 count=19
2017/08/30 19:09:05 Training policy...
2017/08/30 19:09:10 tune 0: objective=0.118772 reg=0.001769 prune=0
2017/08/30 19:09:11 step 0: objective=0.118772 reg=0.001769
2017/08/30 19:09:13 step 1: objective=0.118838 reg=0.001769
2017/08/30 19:09:14 step 2: objective=0.118900 reg=0.001769
2017/08/30 19:09:16 step 3: objective=0.118971 reg=0.001769
2017/08/30 19:09:17 step 4: objective=0.119036 reg=0.001769
2017/08/30 19:09:19 step 5: objective=0.119138 reg=0.001768
2017/08/30 19:09:20 step 6: objective=0.119203 reg=0.001768
2017/08/30 19:09:22 step 7: objective=0.119285 reg=0.001767
2017/08/30 19:09:22 Training value function...
2017/08/30 19:09:25 step 0: mse=0.210071 step=0.050000
2017/08/30 19:09:26 step 1: mse=0.210304 step=0.050000
2017/08/30 19:09:28 step 2: mse=0.210426 step=0.050000
2017/08/30 19:09:29 step 3: mse=0.210603 step=0.050000
2017/08/30 19:09:30 step 4: mse=0.210744 step=0.050000
2017/08/30 19:09:32 step 5: mse=0.211084 step=0.050000
2017/08/30 19:09:33 step 6: mse=0.211437 step=0.050000
2017/08/30 19:09:34 step 7: mse=0.211829 step=0.050000
2017/08/30 19:09:34 Saving...
2017/08/30 19:09:34 Gathering batch of experience...
2017/08/30 19:10:17 batch 443: mean=28.750000 stddev=14.659042 entropy=0.175110 frames=8894 count=20
2017/08/30 19:10:17 Training policy...
2017/08/30 19:10:23 tune 0: objective=0.134037 reg=0.001751 prune=0
2017/08/30 19:10:25 step 0: objective=0.134038 reg=0.001751
2017/08/30 19:10:27 step 1: objective=0.134126 reg=0.001751
2017/08/30 19:10:29 step 2: objective=0.134176 reg=0.001751
2017/08/30 19:10:31 step 3: objective=0.134276 reg=0.001752
2017/08/30 19:10:33 step 4: objective=0.134348 reg=0.001753
2017/08/30 19:10:34 step 5: objective=0.134467 reg=0.001752
2017/08/30 19:10:36 step 6: objective=0.134555 reg=0.001753
2017/08/30 19:10:38 step 7: objective=0.134642 reg=0.001753
2017/08/30 19:10:38 Training value function...
2017/08/30 19:10:42 step 0: mse=0.215960 step=0.050000
2017/08/30 19:10:43 step 1: mse=0.215145 step=0.050000
2017/08/30 19:10:45 step 2: mse=0.214566 step=0.050000
2017/08/30 19:10:47 step 3: mse=0.213960 step=0.050000
2017/08/30 19:10:48 step 4: mse=0.213350 step=0.050000
2017/08/30 19:10:50 step 5: mse=0.212833 step=0.050000
2017/08/30 19:10:51 step 6: mse=0.212201 step=0.050000
2017/08/30 19:10:53 step 7: mse=0.211919 step=0.050000
2017/08/30 19:10:53 Saving...
2017/08/30 19:10:53 Gathering batch of experience...
2017/08/30 19:11:31 batch 444: mean=28.000000 stddev=15.029383 entropy=0.173497 frames=7373 count=17
2017/08/30 19:11:31 Training policy...
2017/08/30 19:11:36 tune 0: objective=0.131533 reg=0.001735 prune=0
2017/08/30 19:11:37 step 0: objective=0.131533 reg=0.001735
2017/08/30 19:11:39 step 1: objective=0.131630 reg=0.001735
2017/08/30 19:11:40 step 2: objective=0.131733 reg=0.001735
2017/08/30 19:11:42 step 3: objective=0.131830 reg=0.001734
2017/08/30 19:11:43 step 4: objective=0.131907 reg=0.001734
2017/08/30 19:11:45 step 5: objective=0.131967 reg=0.001733
2017/08/30 19:11:46 step 6: objective=0.132015 reg=0.001733
2017/08/30 19:11:48 step 7: objective=0.132102 reg=0.001733
2017/08/30 19:11:48 Training value function...
2017/08/30 19:11:51 step 0: mse=0.213378 step=0.050000
2017/08/30 19:11:52 step 1: mse=0.212962 step=0.050000
2017/08/30 19:11:54 step 2: mse=0.212530 step=0.050000
2017/08/30 19:11:55 step 3: mse=0.212025 step=0.050000
2017/08/30 19:11:56 step 4: mse=0.211875 step=0.050000
2017/08/30 19:11:57 step 5: mse=0.211776 step=0.050000
2017/08/30 19:11:59 step 6: mse=0.211419 step=0.050000
2017/08/30 19:12:00 step 7: mse=0.211184 step=0.050000
2017/08/30 19:12:00 Saving...
2017/08/30 19:12:00 Gathering batch of experience...
2017/08/30 19:12:42 batch 445: mean=29.444444 stddev=12.897985 entropy=0.174806 frames=8204 count=18
2017/08/30 19:12:42 Training policy...
2017/08/30 19:12:47 tune 0: objective=0.129510 reg=0.001748 prune=0
2017/08/30 19:12:49 step 0: objective=0.129510 reg=0.001748
2017/08/30 19:12:50 step 1: objective=0.129571 reg=0.001748
2017/08/30 19:12:52 step 2: objective=0.129644 reg=0.001748
2017/08/30 19:12:54 step 3: objective=0.129699 reg=0.001748
2017/08/30 19:12:56 step 4: objective=0.129753 reg=0.001748
2017/08/30 19:12:57 step 5: objective=0.129794 reg=0.001748
2017/08/30 19:12:59 step 6: objective=0.129833 reg=0.001748
2017/08/30 19:13:01 step 7: objective=0.129877 reg=0.001747
2017/08/30 19:13:01 Training value function...
2017/08/30 19:13:04 step 0: mse=0.217215 step=0.050000
2017/08/30 19:13:05 step 1: mse=0.216839 step=0.050000
2017/08/30 19:13:07 step 2: mse=0.216813 step=0.050000
2017/08/30 19:13:08 step 3: mse=0.216989 step=0.050000
2017/08/30 19:13:10 step 4: mse=0.217008 step=0.050000
2017/08/30 19:13:11 step 5: mse=0.216893 step=0.050000
2017/08/30 19:13:13 step 6: mse=0.216767 step=0.050000
2017/08/30 19:13:14 step 7: mse=0.216730 step=0.050000
2017/08/30 19:13:14 Saving...
2017/08/30 19:13:14 Gathering batch of experience...
2017/08/30 19:13:54 batch 446: mean=35.133333 stddev=6.917289 entropy=0.172019 frames=8135 count=15
2017/08/30 19:13:54 Training policy...
2017/08/30 19:14:00 tune 0: objective=0.138520 reg=0.001720 prune=0
2017/08/30 19:14:01 step 0: objective=0.138520 reg=0.001720
2017/08/30 19:14:03 step 1: objective=0.138611 reg=0.001720
2017/08/30 19:14:05 step 2: objective=0.138661 reg=0.001720
2017/08/30 19:14:06 step 3: objective=0.138731 reg=0.001720
2017/08/30 19:14:08 step 4: objective=0.138790 reg=0.001720
2017/08/30 19:14:10 step 5: objective=0.138840 reg=0.001721
2017/08/30 19:14:11 step 6: objective=0.138921 reg=0.001722
2017/08/30 19:14:13 step 7: objective=0.138957 reg=0.001722
2017/08/30 19:14:13 Training value function...
2017/08/30 19:14:17 step 0: mse=0.212543 step=0.050000
2017/08/30 19:14:18 step 1: mse=0.211059 step=0.050000
2017/08/30 19:14:19 step 2: mse=0.209894 step=0.050000
2017/08/30 19:14:21 step 3: mse=0.209048 step=0.050000
2017/08/30 19:14:22 step 4: mse=0.207679 step=0.050000
2017/08/30 19:14:24 step 5: mse=0.206912 step=0.050000
2017/08/30 19:14:25 step 6: mse=0.206043 step=0.050000
2017/08/30 19:14:26 step 7: mse=0.204964 step=0.050000
2017/08/30 19:14:26 Saving...
2017/08/30 19:14:26 Gathering batch of experience...
2017/08/30 19:15:05 batch 447: mean=30.625000 stddev=11.999349 entropy=0.171244 frames=7555 count=16
2017/08/30 19:15:05 Training policy...
2017/08/30 19:15:10 tune 0: objective=0.131499 reg=0.001712 prune=0
2017/08/30 19:15:12 step 0: objective=0.131499 reg=0.001712
2017/08/30 19:15:13 step 1: objective=0.131543 reg=0.001713
2017/08/30 19:15:15 step 2: objective=0.131595 reg=0.001714
2017/08/30 19:15:16 step 3: objective=0.131652 reg=0.001714
2017/08/30 19:15:18 step 4: objective=0.131688 reg=0.001715
2017/08/30 19:15:19 step 5: objective=0.131738 reg=0.001715
2017/08/30 19:15:21 step 6: objective=0.131772 reg=0.001716
2017/08/30 19:15:22 step 7: objective=0.131818 reg=0.001716
2017/08/30 19:15:22 Training value function...
2017/08/30 19:15:26 step 0: mse=0.200781 step=0.050000
2017/08/30 19:15:27 step 1: mse=0.200744 step=0.050000
2017/08/30 19:15:28 step 2: mse=0.200803 step=0.050000
2017/08/30 19:15:30 step 3: mse=0.200841 step=0.050000
2017/08/30 19:15:31 step 4: mse=0.200890 step=0.050000
2017/08/30 19:15:32 step 5: mse=0.200200 step=0.050000
2017/08/30 19:15:33 step 6: mse=0.200468 step=0.050000
2017/08/30 19:15:35 step 7: mse=0.199886 step=0.050000
2017/08/30 19:15:35 Saving...
2017/08/30 19:15:35 Gathering batch of experience...
2017/08/30 19:16:17 batch 448: mean=27.000000 stddev=14.805404 entropy=0.171919 frames=8375 count=20
2017/08/30 19:16:17 Training policy...
2017/08/30 19:16:23 tune 0: objective=0.122658 reg=0.001719 prune=0
2017/08/30 19:16:25 step 0: objective=0.122658 reg=0.001719
2017/08/30 19:16:27 step 1: objective=0.122720 reg=0.001719
2017/08/30 19:16:28 step 2: objective=0.122794 reg=0.001718
2017/08/30 19:16:30 step 3: objective=0.122865 reg=0.001717
2017/08/30 19:16:32 step 4: objective=0.122950 reg=0.001717
2017/08/30 19:16:34 step 5: objective=0.123007 reg=0.001716
2017/08/30 19:16:35 step 6: objective=0.123057 reg=0.001716
2017/08/30 19:16:37 step 7: objective=0.123106 reg=0.001716
2017/08/30 19:16:37 Training value function...
2017/08/30 19:16:41 step 0: mse=0.214911 step=0.050000
2017/08/30 19:16:42 step 1: mse=0.215470 step=0.050000
2017/08/30 19:16:44 step 2: mse=0.215835 step=0.050000
2017/08/30 19:16:45 step 3: mse=0.216250 step=0.050000
2017/08/30 19:16:47 step 4: mse=0.216623 step=0.050000
2017/08/30 19:16:48 step 5: mse=0.217111 step=0.050000
2017/08/30 19:16:50 step 6: mse=0.217291 step=0.050000
2017/08/30 19:16:51 step 7: mse=0.217673 step=0.050000
2017/08/30 19:16:51 Saving...
2017/08/30 19:16:51 Gathering batch of experience...
2017/08/30 19:17:31 batch 449: mean=28.833333 stddev=13.056501 entropy=0.174278 frames=8040 count=18
2017/08/30 19:17:31 Training policy...
2017/08/30 19:17:37 tune 0: objective=0.129043 reg=0.001743 prune=0
2017/08/30 19:17:38 step 0: objective=0.129043 reg=0.001743
2017/08/30 19:17:40 step 1: objective=0.129115 reg=0.001744
2017/08/30 19:17:42 step 2: objective=0.129197 reg=0.001744
2017/08/30 19:17:43 step 3: objective=0.129304 reg=0.001745
2017/08/30 19:17:45 step 4: objective=0.129359 reg=0.001745
2017/08/30 19:17:47 step 5: objective=0.129438 reg=0.001745
2017/08/30 19:17:48 step 6: objective=0.129473 reg=0.001746
2017/08/30 19:17:50 step 7: objective=0.129579 reg=0.001746
2017/08/30 19:17:50 Training value function...
2017/08/30 19:17:53 step 0: mse=0.210208 step=0.050000
2017/08/30 19:17:55 step 1: mse=0.210482 step=0.050000
2017/08/30 19:17:56 step 2: mse=0.210554 step=0.050000
2017/08/30 19:17:58 step 3: mse=0.210636 step=0.050000
2017/08/30 19:17:59 step 4: mse=0.210704 step=0.050000
2017/08/30 19:18:01 step 5: mse=0.210741 step=0.050000
2017/08/30 19:18:02 step 6: mse=0.210893 step=0.050000
2017/08/30 19:18:03 step 7: mse=0.210982 step=0.050000
2017/08/30 19:18:03 Saving...
2017/08/30 19:18:03 Gathering batch of experience...
2017/08/30 19:18:42 batch 450: mean=33.000000 stddev=10.019980 entropy=0.174953 frames=7669 count=15
2017/08/30 19:18:42 Training policy...
2017/08/30 19:18:47 tune 0: objective=0.133519 reg=0.001750 prune=0
2017/08/30 19:18:49 step 0: objective=0.133519 reg=0.001750
2017/08/30 19:18:51 step 1: objective=0.133654 reg=0.001749
2017/08/30 19:18:52 step 2: objective=0.133753 reg=0.001748
2017/08/30 19:18:54 step 3: objective=0.133859 reg=0.001748
2017/08/30 19:18:55 step 4: objective=0.133937 reg=0.001747
2017/08/30 19:18:57 step 5: objective=0.134088 reg=0.001746
2017/08/30 19:18:59 step 6: objective=0.134168 reg=0.001745
2017/08/30 19:19:00 step 7: objective=0.134226 reg=0.001744
2017/08/30 19:19:00 Training value function...
2017/08/30 19:19:03 step 0: mse=0.217239 step=0.050000
2017/08/30 19:19:05 step 1: mse=0.216805 step=0.050000
2017/08/30 19:19:06 step 2: mse=0.216218 step=0.050000
2017/08/30 19:19:07 step 3: mse=0.215755 step=0.050000
2017/08/30 19:19:09 step 4: mse=0.215156 step=0.050000
2017/08/30 19:19:10 step 5: mse=0.214678 step=0.050000
2017/08/30 19:19:11 step 6: mse=0.214351 step=0.050000
2017/08/30 19:19:13 step 7: mse=0.214001 step=0.050000
2017/08/30 19:19:13 Saving...
2017/08/30 19:19:13 Gathering batch of experience...
2017/08/30 19:19:55 batch 451: mean=28.473684 stddev=12.844693 entropy=0.175389 frames=8390 count=19
2017/08/30 19:19:55 Training policy...
2017/08/30 19:20:01 tune 0: objective=0.124771 reg=0.001754 prune=0
2017/08/30 19:20:03 step 0: objective=0.124772 reg=0.001754
2017/08/30 19:20:05 step 1: objective=0.124831 reg=0.001753
2017/08/30 19:20:06 step 2: objective=0.124917 reg=0.001752
2017/08/30 19:20:08 step 3: objective=0.124982 reg=0.001751
2017/08/30 19:20:10 step 4: objective=0.125068 reg=0.001751
2017/08/30 19:20:12 step 5: objective=0.125106 reg=0.001750
2017/08/30 19:20:13 step 6: objective=0.125170 reg=0.001750
2017/08/30 19:20:15 step 7: objective=0.125225 reg=0.001749
2017/08/30 19:20:15 Training value function...
2017/08/30 19:20:19 step 0: mse=0.213682 step=0.050000
2017/08/30 19:20:20 step 1: mse=0.214065 step=0.050000
2017/08/30 19:20:22 step 2: mse=0.214378 step=0.050000
2017/08/30 19:20:23 step 3: mse=0.214807 step=0.050000
2017/08/30 19:20:25 step 4: mse=0.215427 step=0.050000
2017/08/30 19:20:26 step 5: mse=0.215654 step=0.050000
2017/08/30 19:20:28 step 6: mse=0.215721 step=0.050000
2017/08/30 19:20:29 step 7: mse=0.216338 step=0.050000
2017/08/30 19:20:29 Saving...
2017/08/30 19:20:29 Gathering batch of experience...
2017/08/30 19:21:09 batch 452: mean=32.937500 stddev=10.231500 entropy=0.174145 frames=8154 count=16
2017/08/30 19:21:09 Training policy...
2017/08/30 19:21:15 tune 0: objective=0.136777 reg=0.001741 prune=0
2017/08/30 19:21:16 step 0: objective=0.136777 reg=0.001741
2017/08/30 19:21:18 step 1: objective=0.136860 reg=0.001741
2017/08/30 19:21:20 step 2: objective=0.136971 reg=0.001740
2017/08/30 19:21:21 step 3: objective=0.137045 reg=0.001740
2017/08/30 19:21:23 step 4: objective=0.137117 reg=0.001739
2017/08/30 19:21:25 step 5: objective=0.137180 reg=0.001738
2017/08/30 19:21:26 step 6: objective=0.137265 reg=0.001737
2017/08/30 19:21:28 step 7: objective=0.137307 reg=0.001736
2017/08/30 19:21:28 Training value function...
2017/08/30 19:21:31 step 0: mse=0.222603 step=0.050000
2017/08/30 19:21:33 step 1: mse=0.221682 step=0.050000
2017/08/30 19:21:34 step 2: mse=0.221052 step=0.050000
2017/08/30 19:21:36 step 3: mse=0.220135 step=0.050000
2017/08/30 19:21:37 step 4: mse=0.218941 step=0.050000
2017/08/30 19:21:39 step 5: mse=0.218477 step=0.050000
2017/08/30 19:21:40 step 6: mse=0.217578 step=0.050000
2017/08/30 19:21:41 step 7: mse=0.216825 step=0.050000
2017/08/30 19:21:41 Saving...
2017/08/30 19:21:41 Gathering batch of experience...
2017/08/30 19:22:21 batch 453: mean=30.647059 stddev=12.447259 entropy=0.174488 frames=8026 count=17
2017/08/30 19:22:21 Training policy...
2017/08/30 19:22:26 tune 0: objective=0.136220 reg=0.001745 prune=0
2017/08/30 19:22:28 step 0: objective=0.136220 reg=0.001745
2017/08/30 19:22:30 step 1: objective=0.136280 reg=0.001745
2017/08/30 19:22:32 step 2: objective=0.136354 reg=0.001746
2017/08/30 19:22:33 step 3: objective=0.136424 reg=0.001746
2017/08/30 19:22:35 step 4: objective=0.136552 reg=0.001747
2017/08/30 19:22:37 step 5: objective=0.136608 reg=0.001747
2017/08/30 19:22:38 step 6: objective=0.136726 reg=0.001747
2017/08/30 19:22:40 step 7: objective=0.136800 reg=0.001748
2017/08/30 19:22:40 Training value function...
2017/08/30 19:22:43 step 0: mse=0.207377 step=0.050000
2017/08/30 19:22:45 step 1: mse=0.206466 step=0.050000
2017/08/30 19:22:46 step 2: mse=0.205705 step=0.050000
2017/08/30 19:22:47 step 3: mse=0.204883 step=0.050000
2017/08/30 19:22:49 step 4: mse=0.203892 step=0.050000
2017/08/30 19:22:50 step 5: mse=0.203378 step=0.050000
2017/08/30 19:22:51 step 6: mse=0.202396 step=0.050000
2017/08/30 19:22:53 step 7: mse=0.201893 step=0.050000
2017/08/30 19:22:53 Saving...
2017/08/30 19:22:53 Gathering batch of experience...
2017/08/30 19:23:33 batch 454: mean=32.687500 stddev=10.952846 entropy=0.173666 frames=8094 count=16
2017/08/30 19:23:33 Training policy...
2017/08/30 19:23:38 tune 0: objective=0.131479 reg=0.001737 prune=0
2017/08/30 19:23:40 step 0: objective=0.131479 reg=0.001737
2017/08/30 19:23:42 step 1: objective=0.131576 reg=0.001737
2017/08/30 19:23:43 step 2: objective=0.131636 reg=0.001737
2017/08/30 19:23:45 step 3: objective=0.131716 reg=0.001737
2017/08/30 19:23:47 step 4: objective=0.131786 reg=0.001737
2017/08/30 19:23:48 step 5: objective=0.131860 reg=0.001737
2017/08/30 19:23:50 step 6: objective=0.131914 reg=0.001737
2017/08/30 19:23:52 step 7: objective=0.131955 reg=0.001737
2017/08/30 19:23:52 Training value function...
2017/08/30 19:23:55 step 0: mse=0.207796 step=0.050000
2017/08/30 19:23:56 step 1: mse=0.207465 step=0.050000
2017/08/30 19:23:58 step 2: mse=0.207356 step=0.050000
2017/08/30 19:23:59 step 3: mse=0.207252 step=0.050000
2017/08/30 19:24:01 step 4: mse=0.207329 step=0.050000
2017/08/30 19:24:02 step 5: mse=0.207152 step=0.050000
2017/08/30 19:24:04 step 6: mse=0.207151 step=0.050000
2017/08/30 19:24:05 step 7: mse=0.207078 step=0.050000
2017/08/30 19:24:05 Saving...
2017/08/30 19:24:05 Gathering batch of experience...
2017/08/30 19:24:44 batch 455: mean=32.187500 stddev=12.309644 entropy=0.173098 frames=7941 count=16
2017/08/30 19:24:44 Training policy...
2017/08/30 19:24:50 tune 0: objective=0.137444 reg=0.001731 prune=0
2017/08/30 19:24:51 step 0: objective=0.137444 reg=0.001731
2017/08/30 19:24:53 step 1: objective=0.137525 reg=0.001730
2017/08/30 19:24:55 step 2: objective=0.137584 reg=0.001731
2017/08/30 19:24:56 step 3: objective=0.137644 reg=0.001730
2017/08/30 19:24:58 step 4: objective=0.137721 reg=0.001730
2017/08/30 19:25:00 step 5: objective=0.137839 reg=0.001729
2017/08/30 19:25:01 step 6: objective=0.137917 reg=0.001729
2017/08/30 19:25:03 step 7: objective=0.137971 reg=0.001727
2017/08/30 19:25:03 Training value function...
2017/08/30 19:25:06 step 0: mse=0.205729 step=0.050000
2017/08/30 19:25:08 step 1: mse=0.204604 step=0.050000
2017/08/30 19:25:09 step 2: mse=0.203375 step=0.050000
2017/08/30 19:25:10 step 3: mse=0.202291 step=0.050000
2017/08/30 19:25:12 step 4: mse=0.201347 step=0.050000
2017/08/30 19:25:13 step 5: mse=0.200729 step=0.050000
2017/08/30 19:25:14 step 6: mse=0.200003 step=0.050000
2017/08/30 19:25:16 step 7: mse=0.199342 step=0.050000
2017/08/30 19:25:16 Saving...
2017/08/30 19:25:16 Gathering batch of experience...
2017/08/30 19:25:55 batch 456: mean=34.466667 stddev=9.098474 entropy=0.169585 frames=7985 count=15
2017/08/30 19:25:55 Training policy...
2017/08/30 19:26:01 tune 0: objective=0.132726 reg=0.001696 prune=0
2017/08/30 19:26:03 step 0: objective=0.132726 reg=0.001696
2017/08/30 19:26:04 step 1: objective=0.132839 reg=0.001696
2017/08/30 19:26:06 step 2: objective=0.132882 reg=0.001696
2017/08/30 19:26:08 step 3: objective=0.133005 reg=0.001695
2017/08/30 19:26:09 step 4: objective=0.133065 reg=0.001695
2017/08/30 19:26:11 step 5: objective=0.133112 reg=0.001695
2017/08/30 19:26:13 step 6: objective=0.133209 reg=0.001694
2017/08/30 19:26:14 step 7: objective=0.133343 reg=0.001694
2017/08/30 19:26:14 Training value function...
2017/08/30 19:26:18 step 0: mse=0.201190 step=0.050000
2017/08/30 19:26:19 step 1: mse=0.200563 step=0.050000
2017/08/30 19:26:20 step 2: mse=0.200042 step=0.050000
2017/08/30 19:26:22 step 3: mse=0.199853 step=0.050000
2017/08/30 19:26:23 step 4: mse=0.199651 step=0.050000
2017/08/30 19:26:25 step 5: mse=0.199145 step=0.050000
2017/08/30 19:26:26 step 6: mse=0.199127 step=0.050000
2017/08/30 19:26:27 step 7: mse=0.198694 step=0.050000
2017/08/30 19:26:27 Saving...
2017/08/30 19:26:27 Gathering batch of experience...
2017/08/30 19:27:07 batch 457: mean=32.937500 stddev=10.395124 entropy=0.171956 frames=8161 count=16
2017/08/30 19:27:07 Training policy...
2017/08/30 19:27:13 tune 0: objective=0.128481 reg=0.001720 prune=0
2017/08/30 19:27:15 step 0: objective=0.128481 reg=0.001720
2017/08/30 19:27:17 step 1: objective=0.128552 reg=0.001719
2017/08/30 19:27:18 step 2: objective=0.128602 reg=0.001718
2017/08/30 19:27:20 step 3: objective=0.128671 reg=0.001717
2017/08/30 19:27:22 step 4: objective=0.128720 reg=0.001717
2017/08/30 19:27:23 step 5: objective=0.128786 reg=0.001716
2017/08/30 19:27:25 step 6: objective=0.128862 reg=0.001716
2017/08/30 19:27:27 step 7: objective=0.128904 reg=0.001715
2017/08/30 19:27:27 Training value function...
2017/08/30 19:27:30 step 0: mse=0.204896 step=0.050000
2017/08/30 19:27:32 step 1: mse=0.205079 step=0.050000
2017/08/30 19:27:33 step 2: mse=0.205183 step=0.050000
2017/08/30 19:27:34 step 3: mse=0.205596 step=0.050000
2017/08/30 19:27:36 step 4: mse=0.205781 step=0.050000
2017/08/30 19:27:37 step 5: mse=0.205962 step=0.050000
2017/08/30 19:27:39 step 6: mse=0.206233 step=0.050000
2017/08/30 19:27:40 step 7: mse=0.206421 step=0.050000
2017/08/30 19:27:40 Saving...
2017/08/30 19:27:40 Gathering batch of experience...
2017/08/30 19:28:19 batch 458: mean=31.625000 stddev=12.139167 entropy=0.170658 frames=7825 count=16
2017/08/30 19:28:19 Training policy...
2017/08/30 19:28:25 tune 0: objective=0.129018 reg=0.001707 prune=0
2017/08/30 19:28:26 step 0: objective=0.129018 reg=0.001707
2017/08/30 19:28:28 step 1: objective=0.129076 reg=0.001706
2017/08/30 19:28:29 step 2: objective=0.129141 reg=0.001706
2017/08/30 19:28:31 step 3: objective=0.129184 reg=0.001706
2017/08/30 19:28:33 step 4: objective=0.129267 reg=0.001707
2017/08/30 19:28:34 step 5: objective=0.129297 reg=0.001707
2017/08/30 19:28:36 step 6: objective=0.129331 reg=0.001707
2017/08/30 19:28:38 step 7: objective=0.129387 reg=0.001706
2017/08/30 19:28:38 Training value function...
2017/08/30 19:28:41 step 0: mse=0.204068 step=0.050000
2017/08/30 19:28:42 step 1: mse=0.204111 step=0.050000
2017/08/30 19:28:44 step 2: mse=0.204205 step=0.050000
2017/08/30 19:28:45 step 3: mse=0.204207 step=0.050000
2017/08/30 19:28:46 step 4: mse=0.204290 step=0.050000
2017/08/30 19:28:48 step 5: mse=0.204573 step=0.050000
2017/08/30 19:28:49 step 6: mse=0.204501 step=0.050000
2017/08/30 19:28:50 step 7: mse=0.204610 step=0.050000
2017/08/30 19:28:50 Saving...
2017/08/30 19:28:50 Gathering batch of experience...
2017/08/30 19:29:34 batch 459: mean=31.764706 stddev=9.545738 entropy=0.173798 frames=8366 count=17
2017/08/30 19:29:34 Training policy...
2017/08/30 19:29:39 tune 0: objective=0.126242 reg=0.001738 prune=0
2017/08/30 19:29:41 step 0: objective=0.126242 reg=0.001738
2017/08/30 19:29:43 step 1: objective=0.126280 reg=0.001738
2017/08/30 19:29:45 step 2: objective=0.126344 reg=0.001737
2017/08/30 19:29:46 step 3: objective=0.126400 reg=0.001736
2017/08/30 19:29:48 step 4: objective=0.126444 reg=0.001735
2017/08/30 19:29:50 step 5: objective=0.126509 reg=0.001736
2017/08/30 19:29:52 step 6: objective=0.126587 reg=0.001735
2017/08/30 19:29:53 step 7: objective=0.126657 reg=0.001734
2017/08/30 19:29:53 Training value function...
2017/08/30 19:29:57 step 0: mse=0.206138 step=0.050000
2017/08/30 19:29:58 step 1: mse=0.206220 step=0.050000
2017/08/30 19:30:00 step 2: mse=0.206322 step=0.050000
2017/08/30 19:30:01 step 3: mse=0.206087 step=0.050000
2017/08/30 19:30:03 step 4: mse=0.206505 step=0.050000
2017/08/30 19:30:04 step 5: mse=0.206745 step=0.050000
2017/08/30 19:30:06 step 6: mse=0.206790 step=0.050000
2017/08/30 19:30:07 step 7: mse=0.206894 step=0.050000
2017/08/30 19:30:07 Saving...
2017/08/30 19:30:07 Gathering batch of experience...
2017/08/30 19:30:47 batch 460: mean=34.733333 stddev=7.066038 entropy=0.167613 frames=8063 count=15
2017/08/30 19:30:47 Training policy...
2017/08/30 19:30:53 tune 0: objective=0.133904 reg=0.001676 prune=0
2017/08/30 19:30:55 step 0: objective=0.133904 reg=0.001676
2017/08/30 19:30:56 step 1: objective=0.133993 reg=0.001676
2017/08/30 19:30:58 step 2: objective=0.134043 reg=0.001676
2017/08/30 19:31:00 step 3: objective=0.134100 reg=0.001676
2017/08/30 19:31:01 step 4: objective=0.134158 reg=0.001676
2017/08/30 19:31:03 step 5: objective=0.134228 reg=0.001675
2017/08/30 19:31:05 step 6: objective=0.134293 reg=0.001674
2017/08/30 19:31:06 step 7: objective=0.134375 reg=0.001674
2017/08/30 19:31:06 Training value function...
2017/08/30 19:31:10 step 0: mse=0.204500 step=0.050000
2017/08/30 19:31:11 step 1: mse=0.204176 step=0.050000
2017/08/30 19:31:12 step 2: mse=0.203392 step=0.050000
2017/08/30 19:31:14 step 3: mse=0.203090 step=0.050000
2017/08/30 19:31:15 step 4: mse=0.202642 step=0.050000
2017/08/30 19:31:17 step 5: mse=0.202404 step=0.050000
2017/08/30 19:31:18 step 6: mse=0.202102 step=0.050000
2017/08/30 19:31:20 step 7: mse=0.201797 step=0.050000
2017/08/30 19:31:20 Saving...
2017/08/30 19:31:20 Gathering batch of experience...
2017/08/30 19:31:59 batch 461: mean=27.444444 stddev=13.454542 entropy=0.175085 frames=7665 count=18
2017/08/30 19:31:59 Training policy...
2017/08/30 19:32:04 tune 0: objective=0.121375 reg=0.001751 prune=0
2017/08/30 19:32:05 step 0: objective=0.121375 reg=0.001751
2017/08/30 19:32:07 step 1: objective=0.121467 reg=0.001750
2017/08/30 19:32:09 step 2: objective=0.121526 reg=0.001750
2017/08/30 19:32:10 step 3: objective=0.121641 reg=0.001749
2017/08/30 19:32:12 step 4: objective=0.121679 reg=0.001748
2017/08/30 19:32:13 step 5: objective=0.121799 reg=0.001747
2017/08/30 19:32:15 step 6: objective=0.121860 reg=0.001746
2017/08/30 19:32:17 step 7: objective=0.121891 reg=0.001746
2017/08/30 19:32:17 Training value function...
2017/08/30 19:32:20 step 0: mse=0.208373 step=0.050000
2017/08/30 19:32:21 step 1: mse=0.209100 step=0.050000
2017/08/30 19:32:22 step 2: mse=0.209797 step=0.050000
2017/08/30 19:32:24 step 3: mse=0.210183 step=0.050000
2017/08/30 19:32:25 step 4: mse=0.210808 step=0.050000
2017/08/30 19:32:26 step 5: mse=0.211223 step=0.050000
2017/08/30 19:32:28 step 6: mse=0.211882 step=0.050000
2017/08/30 19:32:29 step 7: mse=0.212510 step=0.050000
2017/08/30 19:32:29 Saving...
2017/08/30 19:32:29 Gathering batch of experience...
2017/08/30 19:33:10 batch 462: mean=33.812500 stddev=9.761011 entropy=0.168125 frames=8357 count=16
2017/08/30 19:33:10 Training policy...
2017/08/30 19:33:16 tune 0: objective=0.136297 reg=0.001681 prune=0
2017/08/30 19:33:17 step 0: objective=0.136297 reg=0.001681
2017/08/30 19:33:19 step 1: objective=0.136392 reg=0.001681
2017/08/30 19:33:21 step 2: objective=0.136470 reg=0.001681
2017/08/30 19:33:23 step 3: objective=0.136548 reg=0.001681
2017/08/30 19:33:24 step 4: objective=0.136589 reg=0.001680
2017/08/30 19:33:26 step 5: objective=0.136708 reg=0.001680
2017/08/30 19:33:28 step 6: objective=0.136761 reg=0.001681
2017/08/30 19:33:30 step 7: objective=0.136852 reg=0.001679
2017/08/30 19:33:30 Training value function...
2017/08/30 19:33:33 step 0: mse=0.206958 step=0.050000
2017/08/30 19:33:35 step 1: mse=0.206088 step=0.050000
2017/08/30 19:33:36 step 2: mse=0.205222 step=0.050000
2017/08/30 19:33:38 step 3: mse=0.204221 step=0.050000
2017/08/30 19:33:39 step 4: mse=0.203255 step=0.050000
2017/08/30 19:33:40 step 5: mse=0.202679 step=0.050000
2017/08/30 19:33:42 step 6: mse=0.201880 step=0.050000
2017/08/30 19:33:43 step 7: mse=0.201162 step=0.050000
2017/08/30 19:33:43 Saving...
2017/08/30 19:33:43 Gathering batch of experience...
2017/08/30 19:34:20 batch 463: mean=29.266667 stddev=14.626308 entropy=0.164214 frames=6788 count=15
2017/08/30 19:34:20 Training policy...
2017/08/30 19:34:25 tune 0: objective=0.132660 reg=0.001642 prune=0
2017/08/30 19:34:26 step 0: objective=0.132660 reg=0.001642
2017/08/30 19:34:28 step 1: objective=0.132732 reg=0.001641
2017/08/30 19:34:29 step 2: objective=0.132830 reg=0.001641
2017/08/30 19:34:31 step 3: objective=0.132892 reg=0.001641
2017/08/30 19:34:32 step 4: objective=0.132957 reg=0.001641
2017/08/30 19:34:33 step 5: objective=0.133020 reg=0.001641
2017/08/30 19:34:35 step 6: objective=0.133054 reg=0.001641
2017/08/30 19:34:36 step 7: objective=0.133095 reg=0.001640
2017/08/30 19:34:36 Training value function...
2017/08/30 19:34:39 step 0: mse=0.210465 step=0.050000
2017/08/30 19:34:40 step 1: mse=0.210259 step=0.050000
2017/08/30 19:34:41 step 2: mse=0.210266 step=0.050000
2017/08/30 19:34:43 step 3: mse=0.210270 step=0.050000
2017/08/30 19:34:44 step 4: mse=0.210351 step=0.050000
2017/08/30 19:34:45 step 5: mse=0.210474 step=0.050000
2017/08/30 19:34:46 step 6: mse=0.210309 step=0.050000
2017/08/30 19:34:47 step 7: mse=0.210456 step=0.050000
2017/08/30 19:34:47 Saving...
2017/08/30 19:34:47 Gathering batch of experience...
2017/08/30 19:35:30 batch 464: mean=28.526316 stddev=12.019144 entropy=0.169089 frames=8424 count=19
2017/08/30 19:35:30 Training policy...
2017/08/30 19:35:36 tune 0: objective=0.119270 reg=0.001691 prune=0
2017/08/30 19:35:38 step 0: objective=0.119269 reg=0.001691
2017/08/30 19:35:40 step 1: objective=0.119373 reg=0.001691
2017/08/30 19:35:41 step 2: objective=0.119455 reg=0.001691
2017/08/30 19:35:43 step 3: objective=0.119555 reg=0.001692
2017/08/30 19:35:45 step 4: objective=0.119617 reg=0.001692
2017/08/30 19:35:47 step 5: objective=0.119667 reg=0.001692
2017/08/30 19:35:48 step 6: objective=0.119714 reg=0.001691
2017/08/30 19:35:50 step 7: objective=0.119762 reg=0.001691
2017/08/30 19:35:50 Training value function...
2017/08/30 19:35:54 step 0: mse=0.212608 step=0.050000
2017/08/30 19:35:55 step 1: mse=0.213412 step=0.050000
2017/08/30 19:35:57 step 2: mse=0.214289 step=0.050000
2017/08/30 19:35:58 step 3: mse=0.214879 step=0.050000
2017/08/30 19:36:00 step 4: mse=0.215533 step=0.050000
2017/08/30 19:36:01 step 5: mse=0.216290 step=0.050000
2017/08/30 19:36:03 step 6: mse=0.216934 step=0.050000
2017/08/30 19:36:04 step 7: mse=0.217692 step=0.050000
2017/08/30 19:36:04 Saving...
2017/08/30 19:36:04 Gathering batch of experience...
2017/08/30 19:36:43 batch 465: mean=33.857143 stddev=9.280218 entropy=0.169346 frames=7321 count=14
2017/08/30 19:36:43 Training policy...
2017/08/30 19:36:48 tune 0: objective=0.139180 reg=0.001693 prune=0
2017/08/30 19:36:49 step 0: objective=0.139181 reg=0.001693
2017/08/30 19:36:51 step 1: objective=0.139344 reg=0.001693
2017/08/30 19:36:52 step 2: objective=0.139457 reg=0.001693
2017/08/30 19:36:54 step 3: objective=0.139600 reg=0.001693
2017/08/30 19:36:55 step 4: objective=0.139729 reg=0.001693
2017/08/30 19:36:57 step 5: objective=0.139817 reg=0.001694
2017/08/30 19:36:58 step 6: objective=0.139856 reg=0.001693
2017/08/30 19:37:00 step 7: objective=0.139932 reg=0.001693
2017/08/30 19:37:00 Training value function...
2017/08/30 19:37:03 step 0: mse=0.214665 step=0.050000
2017/08/30 19:37:04 step 1: mse=0.213433 step=0.050000
2017/08/30 19:37:05 step 2: mse=0.211933 step=0.050000
2017/08/30 19:37:07 step 3: mse=0.210918 step=0.050000
2017/08/30 19:37:08 step 4: mse=0.210320 step=0.050000
2017/08/30 19:37:09 step 5: mse=0.209407 step=0.050000
2017/08/30 19:37:10 step 6: mse=0.208528 step=0.050000
2017/08/30 19:37:12 step 7: mse=0.207606 step=0.050000
2017/08/30 19:37:12 Saving...
2017/08/30 19:37:12 Gathering batch of experience...
2017/08/30 19:37:51 batch 466: mean=33.533333 stddev=10.111819 entropy=0.167899 frames=7746 count=15
2017/08/30 19:37:51 Training policy...
2017/08/30 19:37:56 tune 0: objective=0.136970 reg=0.001679 prune=0
2017/08/30 19:37:58 step 0: objective=0.136970 reg=0.001679
2017/08/30 19:37:59 step 1: objective=0.137042 reg=0.001679
2017/08/30 19:38:01 step 2: objective=0.137136 reg=0.001680
2017/08/30 19:38:03 step 3: objective=0.137265 reg=0.001680
2017/08/30 19:38:04 step 4: objective=0.137328 reg=0.001680
2017/08/30 19:38:06 step 5: objective=0.137408 reg=0.001681
2017/08/30 19:38:07 step 6: objective=0.137497 reg=0.001681
2017/08/30 19:38:09 step 7: objective=0.137573 reg=0.001682
2017/08/30 19:38:09 Training value function...
2017/08/30 19:38:12 step 0: mse=0.204621 step=0.050000
2017/08/30 19:38:14 step 1: mse=0.203539 step=0.050000
2017/08/30 19:38:15 step 2: mse=0.202736 step=0.050000
2017/08/30 19:38:16 step 3: mse=0.201927 step=0.050000
2017/08/30 19:38:18 step 4: mse=0.201434 step=0.050000
2017/08/30 19:38:19 step 5: mse=0.200923 step=0.050000
2017/08/30 19:38:20 step 6: mse=0.200257 step=0.050000
2017/08/30 19:38:22 step 7: mse=0.199509 step=0.050000
2017/08/30 19:38:22 Saving...
2017/08/30 19:38:22 Gathering batch of experience...
2017/08/30 19:39:02 batch 467: mean=30.470588 stddev=11.576435 entropy=0.167606 frames=8022 count=17
2017/08/30 19:39:02 Training policy...
2017/08/30 19:39:07 tune 0: objective=0.127032 reg=0.001676 prune=0
2017/08/30 19:39:09 step 0: objective=0.127032 reg=0.001676
2017/08/30 19:39:10 step 1: objective=0.127097 reg=0.001675
2017/08/30 19:39:12 step 2: objective=0.127161 reg=0.001675
2017/08/30 19:39:14 step 3: objective=0.127221 reg=0.001675
2017/08/30 19:39:16 step 4: objective=0.127278 reg=0.001674
2017/08/30 19:39:17 step 5: objective=0.127326 reg=0.001674
2017/08/30 19:39:19 step 6: objective=0.127389 reg=0.001674
2017/08/30 19:39:21 step 7: objective=0.127475 reg=0.001674
2017/08/30 19:39:21 Training value function...
2017/08/30 19:39:24 step 0: mse=0.209862 step=0.050000
2017/08/30 19:39:25 step 1: mse=0.210185 step=0.050000
2017/08/30 19:39:27 step 2: mse=0.210731 step=0.050000
2017/08/30 19:39:28 step 3: mse=0.211064 step=0.050000
2017/08/30 19:39:30 step 4: mse=0.211467 step=0.050000
2017/08/30 19:39:31 step 5: mse=0.211806 step=0.050000
2017/08/30 19:39:33 step 6: mse=0.211992 step=0.050000
2017/08/30 19:39:34 step 7: mse=0.212253 step=0.050000
2017/08/30 19:39:34 Saving...
2017/08/30 19:39:34 Gathering batch of experience...
2017/08/30 19:40:14 batch 468: mean=33.375000 stddev=11.585956 entropy=0.168559 frames=8233 count=16
2017/08/30 19:40:14 Training policy...
2017/08/30 19:40:20 tune 0: objective=0.138749 reg=0.001686 prune=0
2017/08/30 19:40:22 step 0: objective=0.138749 reg=0.001686
2017/08/30 19:40:24 step 1: objective=0.138818 reg=0.001685
2017/08/30 19:40:25 step 2: objective=0.138874 reg=0.001684
2017/08/30 19:40:27 step 3: objective=0.138937 reg=0.001684
2017/08/30 19:40:29 step 4: objective=0.138982 reg=0.001683
2017/08/30 19:40:30 step 5: objective=0.139037 reg=0.001683
2017/08/30 19:40:32 step 6: objective=0.139086 reg=0.001683
2017/08/30 19:40:34 step 7: objective=0.139137 reg=0.001682
2017/08/30 19:40:34 Training value function...
2017/08/30 19:40:37 step 0: mse=0.208380 step=0.050000
2017/08/30 19:40:39 step 1: mse=0.206916 step=0.050000
2017/08/30 19:40:40 step 2: mse=0.205559 step=0.050000
2017/08/30 19:40:42 step 3: mse=0.204090 step=0.050000
2017/08/30 19:40:43 step 4: mse=0.202913 step=0.050000
2017/08/30 19:40:44 step 5: mse=0.202020 step=0.050000
2017/08/30 19:40:46 step 6: mse=0.200625 step=0.050000
2017/08/30 19:40:47 step 7: mse=0.199686 step=0.050000
2017/08/30 19:40:47 Saving...
2017/08/30 19:40:47 Gathering batch of experience...
2017/08/30 19:41:31 batch 469: mean=31.333333 stddev=12.596296 entropy=0.167576 frames=8691 count=18
2017/08/30 19:41:31 Training policy...
2017/08/30 19:41:37 tune 0: objective=0.132994 reg=0.001676 prune=0
2017/08/30 19:41:39 step 0: objective=0.132994 reg=0.001676
2017/08/30 19:41:41 step 1: objective=0.133095 reg=0.001676
2017/08/30 19:41:42 step 2: objective=0.133199 reg=0.001676
2017/08/30 19:41:44 step 3: objective=0.133276 reg=0.001677
2017/08/30 19:41:46 step 4: objective=0.133350 reg=0.001677
2017/08/30 19:41:48 step 5: objective=0.133403 reg=0.001677
2017/08/30 19:41:50 step 6: objective=0.133486 reg=0.001677
2017/08/30 19:41:52 step 7: objective=0.133508 reg=0.001677
2017/08/30 19:41:52 Training value function...
2017/08/30 19:41:55 step 0: mse=0.197377 step=0.050000
2017/08/30 19:41:57 step 1: mse=0.197095 step=0.050000
2017/08/30 19:41:58 step 2: mse=0.196479 step=0.050000
2017/08/30 19:42:00 step 3: mse=0.196243 step=0.050000
2017/08/30 19:42:01 step 4: mse=0.195874 step=0.050000
2017/08/30 19:42:03 step 5: mse=0.195187 step=0.050000
2017/08/30 19:42:04 step 6: mse=0.194759 step=0.050000
2017/08/30 19:42:06 step 7: mse=0.194465 step=0.050000
2017/08/30 19:42:06 Saving...
2017/08/30 19:42:06 Gathering batch of experience...
2017/08/30 19:42:46 batch 470: mean=37.285714 stddev=6.180945 entropy=0.165359 frames=8038 count=14
2017/08/30 19:42:46 Training policy...
2017/08/30 19:42:51 tune 0: objective=0.139597 reg=0.001654 prune=0
2017/08/30 19:42:53 step 0: objective=0.139597 reg=0.001654
2017/08/30 19:42:55 step 1: objective=0.139687 reg=0.001654
2017/08/30 19:42:56 step 2: objective=0.139763 reg=0.001654
2017/08/30 19:42:58 step 3: objective=0.139820 reg=0.001654
2017/08/30 19:43:00 step 4: objective=0.139915 reg=0.001654
2017/08/30 19:43:01 step 5: objective=0.140004 reg=0.001654
2017/08/30 19:43:03 step 6: objective=0.140049 reg=0.001655
2017/08/30 19:43:05 step 7: objective=0.140095 reg=0.001654
2017/08/30 19:43:05 Training value function...
2017/08/30 19:43:08 step 0: mse=0.194544 step=0.050000
2017/08/30 19:43:10 step 1: mse=0.193424 step=0.050000
2017/08/30 19:43:11 step 2: mse=0.192482 step=0.050000
2017/08/30 19:43:12 step 3: mse=0.191116 step=0.050000
2017/08/30 19:43:14 step 4: mse=0.189940 step=0.050000
2017/08/30 19:43:15 step 5: mse=0.189076 step=0.050000
2017/08/30 19:43:16 step 6: mse=0.188213 step=0.050000
2017/08/30 19:43:18 step 7: mse=0.187150 step=0.050000
2017/08/30 19:43:18 Saving...
2017/08/30 19:43:18 Gathering batch of experience...
2017/08/30 19:43:57 batch 471: mean=31.000000 stddev=12.908331 entropy=0.170381 frames=7675 count=16
2017/08/30 19:43:57 Training policy...
2017/08/30 19:44:02 tune 0: objective=0.124770 reg=0.001704 prune=0
2017/08/30 19:44:03 step 0: objective=0.124770 reg=0.001704
2017/08/30 19:44:05 step 1: objective=0.124827 reg=0.001704
2017/08/30 19:44:07 step 2: objective=0.124871 reg=0.001704
2017/08/30 19:44:08 step 3: objective=0.124916 reg=0.001703
2017/08/30 19:44:10 step 4: objective=0.124972 reg=0.001704
2017/08/30 19:44:11 step 5: objective=0.125009 reg=0.001704
2017/08/30 19:44:13 step 6: objective=0.125038 reg=0.001705
2017/08/30 19:44:15 step 7: objective=0.125079 reg=0.001705
2017/08/30 19:44:15 Training value function...
2017/08/30 19:44:18 step 0: mse=0.197548 step=0.050000
2017/08/30 19:44:19 step 1: mse=0.198067 step=0.050000
2017/08/30 19:44:21 step 2: mse=0.198186 step=0.050000
2017/08/30 19:44:22 step 3: mse=0.198399 step=0.050000
2017/08/30 19:44:23 step 4: mse=0.198883 step=0.050000
2017/08/30 19:44:25 step 5: mse=0.199428 step=0.050000
2017/08/30 19:44:26 step 6: mse=0.200066 step=0.050000
2017/08/30 19:44:27 step 7: mse=0.200280 step=0.050000
2017/08/30 19:44:27 Saving...
2017/08/30 19:44:27 Gathering batch of experience...
2017/08/30 19:45:08 batch 472: mean=31.705882 stddev=12.294258 entropy=0.169135 frames=8325 count=17
2017/08/30 19:45:08 Training policy...
2017/08/30 19:45:14 tune 0: objective=0.128085 reg=0.001691 prune=0
2017/08/30 19:45:15 step 0: objective=0.128085 reg=0.001691
2017/08/30 19:45:17 step 1: objective=0.128142 reg=0.001691
2017/08/30 19:45:19 step 2: objective=0.128195 reg=0.001691
2017/08/30 19:45:21 step 3: objective=0.128248 reg=0.001691
2017/08/30 19:45:22 step 4: objective=0.128310 reg=0.001690
2017/08/30 19:45:24 step 5: objective=0.128371 reg=0.001690
2017/08/30 19:45:26 step 6: objective=0.128473 reg=0.001690
2017/08/30 19:45:28 step 7: objective=0.128552 reg=0.001690
2017/08/30 19:45:28 Training value function...
2017/08/30 19:45:31 step 0: mse=0.197339 step=0.050000
2017/08/30 19:45:33 step 1: mse=0.197492 step=0.050000
2017/08/30 19:45:34 step 2: mse=0.197985 step=0.050000
2017/08/30 19:45:36 step 3: mse=0.198114 step=0.050000
2017/08/30 19:45:37 step 4: mse=0.198201 step=0.050000
2017/08/30 19:45:39 step 5: mse=0.198656 step=0.050000
2017/08/30 19:45:40 step 6: mse=0.198885 step=0.050000
2017/08/30 19:45:42 step 7: mse=0.199188 step=0.050000
2017/08/30 19:45:42 Saving...
2017/08/30 19:45:42 Gathering batch of experience...
2017/08/30 19:46:22 batch 473: mean=33.687500 stddev=11.251215 entropy=0.165833 frames=8304 count=16
2017/08/30 19:46:22 Training policy...
2017/08/30 19:46:28 tune 0: objective=0.135825 reg=0.001658 prune=0
2017/08/30 19:46:30 step 0: objective=0.135825 reg=0.001658
2017/08/30 19:46:32 step 1: objective=0.135861 reg=0.001659
2017/08/30 19:46:34 step 2: objective=0.135886 reg=0.001659
2017/08/30 19:46:35 step 3: objective=0.135937 reg=0.001661
2017/08/30 19:46:37 step 4: objective=0.136015 reg=0.001661
2017/08/30 19:46:39 step 5: objective=0.136053 reg=0.001661
2017/08/30 19:46:40 step 6: objective=0.136089 reg=0.001661
2017/08/30 19:46:42 step 7: objective=0.136133 reg=0.001660
2017/08/30 19:46:42 Training value function...
2017/08/30 19:46:46 step 0: mse=0.198602 step=0.050000
2017/08/30 19:46:47 step 1: mse=0.197655 step=0.050000
2017/08/30 19:46:49 step 2: mse=0.196826 step=0.050000
2017/08/30 19:46:50 step 3: mse=0.196124 step=0.050000
2017/08/30 19:46:51 step 4: mse=0.195430 step=0.050000
2017/08/30 19:46:53 step 5: mse=0.194563 step=0.050000
2017/08/30 19:46:54 step 6: mse=0.194027 step=0.050000
2017/08/30 19:46:56 step 7: mse=0.193508 step=0.050000
2017/08/30 19:46:56 Saving...
2017/08/30 19:46:56 Gathering batch of experience...
2017/08/30 19:47:35 batch 474: mean=33.333333 stddev=11.498792 entropy=0.166076 frames=7705 count=15
2017/08/30 19:47:35 Training policy...
2017/08/30 19:47:40 tune 0: objective=0.132792 reg=0.001661 prune=0
2017/08/30 19:47:42 step 0: objective=0.132792 reg=0.001661
2017/08/30 19:47:43 step 1: objective=0.132841 reg=0.001661
2017/08/30 19:47:45 step 2: objective=0.132889 reg=0.001661
2017/08/30 19:47:46 step 3: objective=0.132942 reg=0.001661
2017/08/30 19:47:48 step 4: objective=0.132989 reg=0.001660
2017/08/30 19:47:50 step 5: objective=0.133045 reg=0.001660
2017/08/30 19:47:51 step 6: objective=0.133098 reg=0.001660
2017/08/30 19:47:53 step 7: objective=0.133143 reg=0.001660
2017/08/30 19:47:53 Training value function...
2017/08/30 19:47:56 step 0: mse=0.193654 step=0.050000
2017/08/30 19:47:57 step 1: mse=0.193186 step=0.050000
2017/08/30 19:47:59 step 2: mse=0.192966 step=0.050000
2017/08/30 19:48:00 step 3: mse=0.192589 step=0.050000
2017/08/30 19:48:01 step 4: mse=0.192489 step=0.050000
2017/08/30 19:48:03 step 5: mse=0.192390 step=0.050000
2017/08/30 19:48:04 step 6: mse=0.191849 step=0.050000
2017/08/30 19:48:05 step 7: mse=0.191671 step=0.050000
2017/08/30 19:48:05 Saving...
2017/08/30 19:48:05 Gathering batch of experience...
2017/08/30 19:48:46 batch 475: mean=31.764706 stddev=13.054318 entropy=0.168565 frames=8335 count=17
2017/08/30 19:48:46 Training policy...
2017/08/30 19:48:52 tune 0: objective=0.130371 reg=0.001686 prune=0
2017/08/30 19:48:54 step 0: objective=0.130371 reg=0.001686
2017/08/30 19:48:56 step 1: objective=0.130456 reg=0.001686
2017/08/30 19:48:57 step 2: objective=0.130498 reg=0.001685
2017/08/30 19:48:59 step 3: objective=0.130581 reg=0.001686
2017/08/30 19:49:01 step 4: objective=0.130665 reg=0.001686
2017/08/30 19:49:03 step 5: objective=0.130739 reg=0.001687
2017/08/30 19:49:04 step 6: objective=0.130777 reg=0.001687
2017/08/30 19:49:06 step 7: objective=0.130843 reg=0.001688
2017/08/30 19:49:06 Training value function...
2017/08/30 19:49:10 step 0: mse=0.194506 step=0.050000
2017/08/30 19:49:11 step 1: mse=0.194502 step=0.050000
2017/08/30 19:49:13 step 2: mse=0.194620 step=0.050000
2017/08/30 19:49:14 step 3: mse=0.194721 step=0.050000
2017/08/30 19:49:16 step 4: mse=0.194565 step=0.050000
2017/08/30 19:49:17 step 5: mse=0.194674 step=0.050000
2017/08/30 19:49:19 step 6: mse=0.195046 step=0.050000
2017/08/30 19:49:20 step 7: mse=0.194994 step=0.050000
2017/08/30 19:49:20 Saving...
2017/08/30 19:49:20 Gathering batch of experience...
2017/08/30 19:50:02 batch 476: mean=37.066667 stddev=3.395422 entropy=0.167456 frames=8597 count=15
2017/08/30 19:50:02 Training policy...
2017/08/30 19:50:07 tune 0: objective=0.130061 reg=0.001675 prune=0
2017/08/30 19:50:09 step 0: objective=0.130062 reg=0.001675
2017/08/30 19:50:11 step 1: objective=0.130124 reg=0.001675
2017/08/30 19:50:13 step 2: objective=0.130179 reg=0.001675
2017/08/30 19:50:15 step 3: objective=0.130246 reg=0.001675
2017/08/30 19:50:17 step 4: objective=0.130308 reg=0.001676
2017/08/30 19:50:18 step 5: objective=0.130380 reg=0.001676
2017/08/30 19:50:20 step 6: objective=0.130442 reg=0.001676
2017/08/30 19:50:22 step 7: objective=0.130496 reg=0.001676
2017/08/30 19:50:22 Training value function...
2017/08/30 19:50:26 step 0: mse=0.196803 step=0.050000
2017/08/30 19:50:27 step 1: mse=0.196504 step=0.050000
2017/08/30 19:50:29 step 2: mse=0.196138 step=0.050000
2017/08/30 19:50:30 step 3: mse=0.195755 step=0.050000
2017/08/30 19:50:32 step 4: mse=0.195594 step=0.050000
2017/08/30 19:50:33 step 5: mse=0.195577 step=0.050000
2017/08/30 19:50:34 step 6: mse=0.195499 step=0.050000
2017/08/30 19:50:36 step 7: mse=0.195279 step=0.050000
2017/08/30 19:50:36 Saving...
2017/08/30 19:50:36 Gathering batch of experience...
2017/08/30 19:51:16 batch 477: mean=32.937500 stddev=10.280253 entropy=0.165788 frames=8148 count=16
2017/08/30 19:51:16 Training policy...
2017/08/30 19:51:22 tune 0: objective=0.128149 reg=0.001658 prune=0
2017/08/30 19:51:24 step 0: objective=0.128149 reg=0.001658
2017/08/30 19:51:25 step 1: objective=0.128236 reg=0.001657
2017/08/30 19:51:27 step 2: objective=0.128300 reg=0.001657
2017/08/30 19:51:29 step 3: objective=0.128347 reg=0.001657
2017/08/30 19:51:31 step 4: objective=0.128390 reg=0.001657
2017/08/30 19:51:32 step 5: objective=0.128475 reg=0.001656
2017/08/30 19:51:34 step 6: objective=0.128540 reg=0.001656
2017/08/30 19:51:36 step 7: objective=0.128595 reg=0.001656
2017/08/30 19:51:36 Training value function...
2017/08/30 19:51:39 step 0: mse=0.201755 step=0.050000
2017/08/30 19:51:41 step 1: mse=0.201959 step=0.050000
2017/08/30 19:51:42 step 2: mse=0.202192 step=0.050000
2017/08/30 19:51:44 step 3: mse=0.202551 step=0.050000
2017/08/30 19:51:45 step 4: mse=0.202896 step=0.050000
2017/08/30 19:51:46 step 5: mse=0.203054 step=0.050000
2017/08/30 19:51:48 step 6: mse=0.203112 step=0.050000
2017/08/30 19:51:49 step 7: mse=0.203418 step=0.050000
2017/08/30 19:51:49 Saving...
2017/08/30 19:51:49 Gathering batch of experience...
2017/08/30 19:52:31 batch 478: mean=36.866667 stddev=6.984427 entropy=0.165983 frames=8522 count=15
2017/08/30 19:52:31 Training policy...
2017/08/30 19:52:37 tune 0: objective=0.137704 reg=0.001660 prune=0
2017/08/30 19:52:38 step 0: objective=0.137704 reg=0.001660
2017/08/30 19:52:40 step 1: objective=0.137806 reg=0.001659
2017/08/30 19:52:42 step 2: objective=0.137914 reg=0.001660
2017/08/30 19:52:44 step 3: objective=0.137994 reg=0.001661
2017/08/30 19:52:46 step 4: objective=0.138098 reg=0.001661
2017/08/30 19:52:47 step 5: objective=0.138204 reg=0.001661
2017/08/30 19:52:49 step 6: objective=0.138252 reg=0.001661
2017/08/30 19:52:51 step 7: objective=0.138314 reg=0.001661
2017/08/30 19:52:51 Training value function...
2017/08/30 19:52:55 step 0: mse=0.195990 step=0.050000
2017/08/30 19:52:56 step 1: mse=0.195200 step=0.050000
2017/08/30 19:52:58 step 2: mse=0.194618 step=0.050000
2017/08/30 19:52:59 step 3: mse=0.193560 step=0.050000
2017/08/30 19:53:00 step 4: mse=0.192745 step=0.050000
2017/08/30 19:53:02 step 5: mse=0.191935 step=0.050000
2017/08/30 19:53:03 step 6: mse=0.191267 step=0.050000
2017/08/30 19:53:05 step 7: mse=0.190313 step=0.050000
2017/08/30 19:53:05 Saving...
2017/08/30 19:53:05 Gathering batch of experience...
2017/08/30 19:53:45 batch 479: mean=33.750000 stddev=10.213349 entropy=0.166148 frames=8351 count=16
2017/08/30 19:53:45 Training policy...
2017/08/30 19:53:51 tune 0: objective=0.127307 reg=0.001661 prune=0
2017/08/30 19:53:53 step 0: objective=0.127307 reg=0.001661
2017/08/30 19:53:55 step 1: objective=0.127388 reg=0.001662
2017/08/30 19:53:57 step 2: objective=0.127453 reg=0.001663
2017/08/30 19:53:58 step 3: objective=0.127520 reg=0.001664
2017/08/30 19:54:00 step 4: objective=0.127608 reg=0.001665
2017/08/30 19:54:02 step 5: objective=0.127651 reg=0.001666
2017/08/30 19:54:04 step 6: objective=0.127722 reg=0.001666
2017/08/30 19:54:05 step 7: objective=0.127764 reg=0.001665
2017/08/30 19:54:05 Training value function...
2017/08/30 19:54:09 step 0: mse=0.192739 step=0.050000
2017/08/30 19:54:10 step 1: mse=0.193023 step=0.050000
2017/08/30 19:54:12 step 2: mse=0.193332 step=0.050000
2017/08/30 19:54:13 step 3: mse=0.193628 step=0.050000
2017/08/30 19:54:15 step 4: mse=0.193724 step=0.050000
2017/08/30 19:54:16 step 5: mse=0.194151 step=0.050000
2017/08/30 19:54:18 step 6: mse=0.194546 step=0.050000
2017/08/30 19:54:19 step 7: mse=0.194829 step=0.050000
2017/08/30 19:54:19 Saving...
2017/08/30 19:54:19 Gathering batch of experience...
2017/08/30 19:54:58 batch 480: mean=31.250000 stddev=10.991474 entropy=0.167635 frames=7747 count=16
2017/08/30 19:54:58 Training policy...
2017/08/30 19:55:04 tune 0: objective=0.121532 reg=0.001676 prune=0
2017/08/30 19:55:05 step 0: objective=0.121532 reg=0.001676
2017/08/30 19:55:07 step 1: objective=0.121703 reg=0.001674
2017/08/30 19:55:09 step 2: objective=0.121803 reg=0.001673
2017/08/30 19:55:10 step 3: objective=0.121901 reg=0.001671
2017/08/30 19:55:12 step 4: objective=0.122004 reg=0.001670
2017/08/30 19:55:14 step 5: objective=0.122069 reg=0.001670
2017/08/30 19:55:15 step 6: objective=0.122117 reg=0.001669
2017/08/30 19:55:17 step 7: objective=0.122183 reg=0.001668
2017/08/30 19:55:17 Training value function...
2017/08/30 19:55:20 step 0: mse=0.199802 step=0.050000
2017/08/30 19:55:22 step 1: mse=0.200278 step=0.050000
2017/08/30 19:55:23 step 2: mse=0.200803 step=0.050000
2017/08/30 19:55:24 step 3: mse=0.201355 step=0.050000
2017/08/30 19:55:26 step 4: mse=0.201924 step=0.050000
2017/08/30 19:55:27 step 5: mse=0.202431 step=0.050000
2017/08/30 19:55:28 step 6: mse=0.202847 step=0.050000
2017/08/30 19:55:30 step 7: mse=0.203354 step=0.050000
2017/08/30 19:55:30 Saving...
2017/08/30 19:55:30 Gathering batch of experience...
2017/08/30 19:56:08 batch 481: mean=29.812500 stddev=12.851161 entropy=0.169211 frames=7376 count=16
2017/08/30 19:56:08 Training policy...
2017/08/30 19:56:13 tune 0: objective=0.128390 reg=0.001692 prune=0
2017/08/30 19:56:15 step 0: objective=0.128390 reg=0.001692
2017/08/30 19:56:16 step 1: objective=0.128456 reg=0.001692
2017/08/30 19:56:18 step 2: objective=0.128523 reg=0.001691
2017/08/30 19:56:19 step 3: objective=0.128587 reg=0.001691
2017/08/30 19:56:21 step 4: objective=0.128668 reg=0.001690
2017/08/30 19:56:23 step 5: objective=0.128731 reg=0.001688
2017/08/30 19:56:24 step 6: objective=0.128771 reg=0.001689
2017/08/30 19:56:26 step 7: objective=0.128819 reg=0.001688
2017/08/30 19:56:26 Training value function...
2017/08/30 19:56:29 step 0: mse=0.206651 step=0.050000
2017/08/30 19:56:30 step 1: mse=0.206664 step=0.050000
2017/08/30 19:56:31 step 2: mse=0.206754 step=0.050000
2017/08/30 19:56:33 step 3: mse=0.207007 step=0.050000
2017/08/30 19:56:34 step 4: mse=0.207018 step=0.050000
2017/08/30 19:56:35 step 5: mse=0.207248 step=0.050000
2017/08/30 19:56:37 step 6: mse=0.207183 step=0.050000
2017/08/30 19:56:38 step 7: mse=0.207442 step=0.050000
2017/08/30 19:56:38 Saving...
2017/08/30 19:56:38 Gathering batch of experience...
2017/08/30 19:57:16 batch 482: mean=28.411765 stddev=13.668594 entropy=0.166551 frames=7476 count=17
2017/08/30 19:57:16 Training policy...
2017/08/30 19:57:21 tune 0: objective=0.125475 reg=0.001666 prune=0
2017/08/30 19:57:23 step 0: objective=0.125475 reg=0.001666
2017/08/30 19:57:24 step 1: objective=0.125550 reg=0.001666
2017/08/30 19:57:26 step 2: objective=0.125639 reg=0.001667
2017/08/30 19:57:28 step 3: objective=0.125706 reg=0.001666
2017/08/30 19:57:29 step 4: objective=0.125777 reg=0.001665
2017/08/30 19:57:31 step 5: objective=0.125839 reg=0.001666
2017/08/30 19:57:32 step 6: objective=0.125869 reg=0.001666
2017/08/30 19:57:34 step 7: objective=0.125914 reg=0.001666
2017/08/30 19:57:34 Training value function...
2017/08/30 19:57:37 step 0: mse=0.210373 step=0.050000
2017/08/30 19:57:38 step 1: mse=0.210454 step=0.050000
2017/08/30 19:57:40 step 2: mse=0.210872 step=0.050000
2017/08/30 19:57:41 step 3: mse=0.211229 step=0.050000
2017/08/30 19:57:42 step 4: mse=0.211236 step=0.050000
2017/08/30 19:57:44 step 5: mse=0.211391 step=0.050000
2017/08/30 19:57:45 step 6: mse=0.211685 step=0.050000
2017/08/30 19:57:46 step 7: mse=0.211467 step=0.050000
2017/08/30 19:57:46 Saving...
2017/08/30 19:57:46 Gathering batch of experience...
2017/08/30 19:58:29 batch 483: mean=26.190476 stddev=14.344798 entropy=0.170322 frames=8546 count=21
2017/08/30 19:58:29 Training policy...
2017/08/30 19:58:35 tune 0: objective=0.122022 reg=0.001703 prune=0
2017/08/30 19:58:37 step 0: objective=0.122022 reg=0.001703
2017/08/30 19:58:39 step 1: objective=0.122109 reg=0.001703
2017/08/30 19:58:41 step 2: objective=0.122213 reg=0.001703
2017/08/30 19:58:42 step 3: objective=0.122331 reg=0.001703
2017/08/30 19:58:44 step 4: objective=0.122435 reg=0.001703
2017/08/30 19:58:46 step 5: objective=0.122503 reg=0.001703
2017/08/30 19:58:48 step 6: objective=0.122600 reg=0.001702
2017/08/30 19:58:50 step 7: objective=0.122659 reg=0.001701
2017/08/30 19:58:50 Training value function...
2017/08/30 19:58:53 step 0: mse=0.218894 step=0.050000
2017/08/30 19:58:55 step 1: mse=0.219315 step=0.050000
2017/08/30 19:58:56 step 2: mse=0.219822 step=0.050000
2017/08/30 19:58:58 step 3: mse=0.220265 step=0.050000
2017/08/30 19:58:59 step 4: mse=0.220822 step=0.050000
2017/08/30 19:59:01 step 5: mse=0.221390 step=0.050000
2017/08/30 19:59:02 step 6: mse=0.221663 step=0.050000
2017/08/30 19:59:04 step 7: mse=0.221997 step=0.050000
2017/08/30 19:59:04 Saving...
2017/08/30 19:59:04 Gathering batch of experience...
2017/08/30 19:59:45 batch 484: mean=33.625000 stddev=9.379999 entropy=0.164230 frames=8324 count=16
2017/08/30 19:59:45 Training policy...
2017/08/30 19:59:50 tune 0: objective=0.137089 reg=0.001642 prune=0
2017/08/30 19:59:52 step 0: objective=0.137089 reg=0.001642
2017/08/30 19:59:54 step 1: objective=0.137186 reg=0.001642
2017/08/30 19:59:56 step 2: objective=0.137250 reg=0.001643
2017/08/30 19:59:57 step 3: objective=0.137321 reg=0.001643
2017/08/30 19:59:59 step 4: objective=0.137362 reg=0.001643
2017/08/30 20:00:01 step 5: objective=0.137410 reg=0.001643
2017/08/30 20:00:03 step 6: objective=0.137462 reg=0.001642
2017/08/30 20:00:05 step 7: objective=0.137538 reg=0.001642
2017/08/30 20:00:05 Training value function...
2017/08/30 20:00:08 step 0: mse=0.217542 step=0.050000
2017/08/30 20:00:09 step 1: mse=0.216627 step=0.050000
2017/08/30 20:00:11 step 2: mse=0.215559 step=0.050000
2017/08/30 20:00:12 step 3: mse=0.214681 step=0.050000
2017/08/30 20:00:14 step 4: mse=0.213819 step=0.050000
2017/08/30 20:00:15 step 5: mse=0.213083 step=0.050000
2017/08/30 20:00:17 step 6: mse=0.212326 step=0.050000
2017/08/30 20:00:18 step 7: mse=0.211737 step=0.050000
2017/08/30 20:00:18 Saving...
2017/08/30 20:00:18 Gathering batch of experience...
2017/08/30 20:01:00 batch 485: mean=35.250000 stddev=7.445636 entropy=0.160760 frames=8708 count=16
2017/08/30 20:01:00 Training policy...
2017/08/30 20:01:06 tune 0: objective=0.138806 reg=0.001608 prune=0
2017/08/30 20:01:08 step 0: objective=0.138806 reg=0.001608
2017/08/30 20:01:10 step 1: objective=0.138882 reg=0.001607
2017/08/30 20:01:12 step 2: objective=0.138946 reg=0.001607
2017/08/30 20:01:13 step 3: objective=0.139036 reg=0.001607
2017/08/30 20:01:15 step 4: objective=0.139096 reg=0.001607
2017/08/30 20:01:17 step 5: objective=0.139139 reg=0.001607
2017/08/30 20:01:19 step 6: objective=0.139224 reg=0.001606
2017/08/30 20:01:21 step 7: objective=0.139287 reg=0.001605
2017/08/30 20:01:21 Training value function...
2017/08/30 20:01:25 step 0: mse=0.213245 step=0.050000
2017/08/30 20:01:26 step 1: mse=0.212346 step=0.050000
2017/08/30 20:01:28 step 2: mse=0.211250 step=0.050000
2017/08/30 20:01:29 step 3: mse=0.210144 step=0.050000
2017/08/30 20:01:31 step 4: mse=0.208900 step=0.050000
2017/08/30 20:01:32 step 5: mse=0.207997 step=0.050000
2017/08/30 20:01:34 step 6: mse=0.207140 step=0.050000
2017/08/30 20:01:35 step 7: mse=0.206175 step=0.050000
2017/08/30 20:01:35 Saving...
2017/08/30 20:01:35 Gathering batch of experience...
2017/08/30 20:02:14 batch 486: mean=33.133333 stddev=9.098474 entropy=0.165726 frames=7688 count=15
2017/08/30 20:02:14 Training policy...
2017/08/30 20:02:20 tune 0: objective=0.129904 reg=0.001657 prune=0
2017/08/30 20:02:21 step 0: objective=0.129904 reg=0.001657
2017/08/30 20:02:23 step 1: objective=0.129969 reg=0.001658
2017/08/30 20:02:25 step 2: objective=0.130046 reg=0.001659
2017/08/30 20:02:26 step 3: objective=0.130160 reg=0.001660
2017/08/30 20:02:28 step 4: objective=0.130245 reg=0.001661
2017/08/30 20:02:30 step 5: objective=0.130318 reg=0.001662
2017/08/30 20:02:31 step 6: objective=0.130380 reg=0.001662
2017/08/30 20:02:33 step 7: objective=0.130415 reg=0.001662
2017/08/30 20:02:33 Training value function...
2017/08/30 20:02:36 step 0: mse=0.202811 step=0.050000
2017/08/30 20:02:37 step 1: mse=0.202691 step=0.050000
2017/08/30 20:02:39 step 2: mse=0.202972 step=0.050000
2017/08/30 20:02:40 step 3: mse=0.203098 step=0.050000
2017/08/30 20:02:41 step 4: mse=0.202755 step=0.050000
2017/08/30 20:02:43 step 5: mse=0.202797 step=0.050000
2017/08/30 20:02:44 step 6: mse=0.202953 step=0.050000
2017/08/30 20:02:46 step 7: mse=0.202833 step=0.050000
2017/08/30 20:02:46 Saving...
2017/08/30 20:02:46 Gathering batch of experience...
2017/08/30 20:03:27 batch 487: mean=34.000000 stddev=9.956154 entropy=0.163115 frames=8399 count=16
2017/08/30 20:03:27 Training policy...
2017/08/30 20:03:32 tune 0: objective=0.136016 reg=0.001631 prune=0
2017/08/30 20:03:34 step 0: objective=0.136016 reg=0.001631
2017/08/30 20:03:36 step 1: objective=0.136092 reg=0.001631
2017/08/30 20:03:38 step 2: objective=0.136203 reg=0.001633
2017/08/30 20:03:40 step 3: objective=0.136270 reg=0.001633
2017/08/30 20:03:41 step 4: objective=0.136348 reg=0.001633
2017/08/30 20:03:43 step 5: objective=0.136404 reg=0.001633
2017/08/30 20:03:45 step 6: objective=0.136429 reg=0.001633
2017/08/30 20:03:47 step 7: objective=0.136460 reg=0.001633
2017/08/30 20:03:47 Training value function...
2017/08/30 20:03:50 step 0: mse=0.210082 step=0.050000
2017/08/30 20:03:52 step 1: mse=0.209491 step=0.050000
2017/08/30 20:03:53 step 2: mse=0.208391 step=0.050000
2017/08/30 20:03:55 step 3: mse=0.207392 step=0.050000
2017/08/30 20:03:56 step 4: mse=0.206997 step=0.050000
2017/08/30 20:03:58 step 5: mse=0.206551 step=0.050000
2017/08/30 20:03:59 step 6: mse=0.206229 step=0.050000
2017/08/30 20:04:00 step 7: mse=0.205517 step=0.050000
2017/08/30 20:04:00 Saving...
2017/08/30 20:04:00 Gathering batch of experience...
2017/08/30 20:04:40 batch 488: mean=31.500000 stddev=9.893179 entropy=0.165104 frames=7802 count=16
2017/08/30 20:04:40 Training policy...
2017/08/30 20:04:46 tune 0: objective=0.127311 reg=0.001651 prune=0
2017/08/30 20:04:47 step 0: objective=0.127312 reg=0.001651
2017/08/30 20:04:49 step 1: objective=0.127372 reg=0.001651
2017/08/30 20:04:51 step 2: objective=0.127455 reg=0.001650
2017/08/30 20:04:52 step 3: objective=0.127509 reg=0.001650
2017/08/30 20:04:54 step 4: objective=0.127562 reg=0.001649
2017/08/30 20:04:56 step 5: objective=0.127610 reg=0.001649
2017/08/30 20:04:57 step 6: objective=0.127677 reg=0.001650
2017/08/30 20:04:59 step 7: objective=0.127730 reg=0.001649
2017/08/30 20:04:59 Training value function...
2017/08/30 20:05:02 step 0: mse=0.207783 step=0.050000
2017/08/30 20:05:04 step 1: mse=0.207694 step=0.050000
2017/08/30 20:05:05 step 2: mse=0.207785 step=0.050000
2017/08/30 20:05:06 step 3: mse=0.207904 step=0.050000
2017/08/30 20:05:08 step 4: mse=0.207931 step=0.050000
2017/08/30 20:05:09 step 5: mse=0.208292 step=0.050000
2017/08/30 20:05:10 step 6: mse=0.208561 step=0.050000
2017/08/30 20:05:12 step 7: mse=0.208821 step=0.050000
2017/08/30 20:05:12 Saving...
2017/08/30 20:05:12 Gathering batch of experience...
2017/08/30 20:05:51 batch 489: mean=28.500000 stddev=12.906717 entropy=0.166552 frames=7921 count=18
2017/08/30 20:05:51 Training policy...
2017/08/30 20:05:57 tune 0: objective=0.126766 reg=0.001666 prune=0
2017/08/30 20:05:59 step 0: objective=0.126766 reg=0.001666
2017/08/30 20:06:00 step 1: objective=0.126860 reg=0.001665
2017/08/30 20:06:02 step 2: objective=0.126965 reg=0.001664
2017/08/30 20:06:04 step 3: objective=0.127051 reg=0.001664
2017/08/30 20:06:05 step 4: objective=0.127109 reg=0.001663
2017/08/30 20:06:07 step 5: objective=0.127231 reg=0.001662
2017/08/30 20:06:09 step 6: objective=0.127325 reg=0.001661
2017/08/30 20:06:10 step 7: objective=0.127418 reg=0.001661
2017/08/30 20:06:10 Training value function...
2017/08/30 20:06:14 step 0: mse=0.205631 step=0.050000
2017/08/30 20:06:15 step 1: mse=0.205871 step=0.050000
2017/08/30 20:06:17 step 2: mse=0.206274 step=0.050000
2017/08/30 20:06:18 step 3: mse=0.206832 step=0.050000
2017/08/30 20:06:19 step 4: mse=0.207103 step=0.050000
2017/08/30 20:06:21 step 5: mse=0.207723 step=0.050000
2017/08/30 20:06:22 step 6: mse=0.207868 step=0.050000
2017/08/30 20:06:24 step 7: mse=0.208337 step=0.050000
2017/08/30 20:06:24 Saving...
2017/08/30 20:06:24 Gathering batch of experience...
2017/08/30 20:07:03 batch 490: mean=32.437500 stddev=13.783907 entropy=0.162222 frames=8003 count=16
2017/08/30 20:07:03 Training policy...
2017/08/30 20:07:09 tune 0: objective=0.139484 reg=0.001622 prune=0
2017/08/30 20:07:11 step 0: objective=0.139484 reg=0.001622
2017/08/30 20:07:12 step 1: objective=0.139559 reg=0.001623
2017/08/30 20:07:14 step 2: objective=0.139705 reg=0.001623
2017/08/30 20:07:16 step 3: objective=0.139814 reg=0.001623
2017/08/30 20:07:18 step 4: objective=0.139865 reg=0.001624
2017/08/30 20:07:19 step 5: objective=0.139939 reg=0.001624
2017/08/30 20:07:21 step 6: objective=0.139988 reg=0.001624
2017/08/30 20:07:23 step 7: objective=0.140053 reg=0.001624
2017/08/30 20:07:23 Training value function...
2017/08/30 20:07:26 step 0: mse=0.213551 step=0.050000
2017/08/30 20:07:27 step 1: mse=0.211499 step=0.050000
2017/08/30 20:07:29 step 2: mse=0.209966 step=0.050000
2017/08/30 20:07:30 step 3: mse=0.208444 step=0.050000
2017/08/30 20:07:31 step 4: mse=0.206801 step=0.050000
2017/08/30 20:07:33 step 5: mse=0.205890 step=0.050000
2017/08/30 20:07:34 step 6: mse=0.204489 step=0.050000
2017/08/30 20:07:36 step 7: mse=0.203138 step=0.050000
2017/08/30 20:07:36 Saving...
2017/08/30 20:07:36 Gathering batch of experience...
2017/08/30 20:08:15 batch 491: mean=31.187500 stddev=11.609364 entropy=0.165243 frames=7721 count=16
2017/08/30 20:08:15 Training policy...
2017/08/30 20:08:20 tune 0: objective=0.124905 reg=0.001652 prune=0
2017/08/30 20:08:22 step 0: objective=0.124905 reg=0.001652
2017/08/30 20:08:23 step 1: objective=0.124989 reg=0.001652
2017/08/30 20:08:25 step 2: objective=0.125058 reg=0.001652
2017/08/30 20:08:27 step 3: objective=0.125163 reg=0.001651
2017/08/30 20:08:28 step 4: objective=0.125268 reg=0.001652
2017/08/30 20:08:30 step 5: objective=0.125404 reg=0.001651
2017/08/30 20:08:31 step 6: objective=0.125443 reg=0.001651
2017/08/30 20:08:33 step 7: objective=0.125518 reg=0.001651
2017/08/30 20:08:33 Training value function...
2017/08/30 20:08:36 step 0: mse=0.202788 step=0.050000
2017/08/30 20:08:38 step 1: mse=0.203223 step=0.050000
2017/08/30 20:08:39 step 2: mse=0.203467 step=0.050000
2017/08/30 20:08:40 step 3: mse=0.203685 step=0.050000
2017/08/30 20:08:42 step 4: mse=0.204053 step=0.050000
2017/08/30 20:08:43 step 5: mse=0.204349 step=0.050000
2017/08/30 20:08:44 step 6: mse=0.204615 step=0.050000
2017/08/30 20:08:46 step 7: mse=0.204943 step=0.050000
2017/08/30 20:08:46 Saving...
2017/08/30 20:08:46 Gathering batch of experience...
2017/08/30 20:09:27 batch 492: mean=34.312500 stddev=10.838120 entropy=0.162269 frames=8475 count=16
2017/08/30 20:09:27 Training policy...
2017/08/30 20:09:33 tune 0: objective=0.136638 reg=0.001623 prune=0
2017/08/30 20:09:35 step 0: objective=0.136638 reg=0.001623
2017/08/30 20:09:36 step 1: objective=0.136715 reg=0.001623
2017/08/30 20:09:38 step 2: objective=0.136777 reg=0.001623
2017/08/30 20:09:40 step 3: objective=0.136820 reg=0.001623
2017/08/30 20:09:42 step 4: objective=0.136860 reg=0.001623
2017/08/30 20:09:44 step 5: objective=0.136912 reg=0.001623
2017/08/30 20:09:45 step 6: objective=0.136990 reg=0.001623
2017/08/30 20:09:47 step 7: objective=0.137046 reg=0.001623
2017/08/30 20:09:47 Training value function...
2017/08/30 20:09:51 step 0: mse=0.206274 step=0.050000
2017/08/30 20:09:52 step 1: mse=0.205470 step=0.050000
2017/08/30 20:09:54 step 2: mse=0.205030 step=0.050000
2017/08/30 20:09:55 step 3: mse=0.204182 step=0.050000
2017/08/30 20:09:57 step 4: mse=0.203502 step=0.050000
2017/08/30 20:09:58 step 5: mse=0.202835 step=0.050000
2017/08/30 20:10:00 step 6: mse=0.202086 step=0.050000
2017/08/30 20:10:01 step 7: mse=0.201660 step=0.050000
2017/08/30 20:10:01 Saving...
2017/08/30 20:10:01 Gathering batch of experience...
2017/08/30 20:10:44 batch 493: mean=33.470588 stddev=12.151580 entropy=0.161893 frames=8772 count=17
2017/08/30 20:10:44 Training policy...
2017/08/30 20:10:50 tune 0: objective=0.136650 reg=0.001619 prune=0
2017/08/30 20:10:52 step 0: objective=0.136650 reg=0.001619
2017/08/30 20:10:54 step 1: objective=0.136708 reg=0.001618
2017/08/30 20:10:56 step 2: objective=0.136765 reg=0.001618
2017/08/30 20:10:58 step 3: objective=0.136820 reg=0.001618
2017/08/30 20:11:00 step 4: objective=0.136877 reg=0.001618
2017/08/30 20:11:01 step 5: objective=0.136926 reg=0.001618
2017/08/30 20:11:03 step 6: objective=0.136996 reg=0.001618
2017/08/30 20:11:05 step 7: objective=0.137051 reg=0.001617
2017/08/30 20:11:05 Training value function...
2017/08/30 20:11:09 step 0: mse=0.200651 step=0.050000
2017/08/30 20:11:10 step 1: mse=0.200145 step=0.050000
2017/08/30 20:11:12 step 2: mse=0.199514 step=0.050000
2017/08/30 20:11:13 step 3: mse=0.198949 step=0.050000
2017/08/30 20:11:15 step 4: mse=0.198176 step=0.050000
2017/08/30 20:11:16 step 5: mse=0.197728 step=0.050000
2017/08/30 20:11:18 step 6: mse=0.197445 step=0.050000
2017/08/30 20:11:20 step 7: mse=0.196943 step=0.050000
2017/08/30 20:11:20 Saving...
2017/08/30 20:11:20 Gathering batch of experience...
2017/08/30 20:11:58 batch 494: mean=29.812500 stddev=11.775073 entropy=0.164347 frames=7417 count=16
2017/08/30 20:11:58 Training policy...
2017/08/30 20:12:04 tune 0: objective=0.118370 reg=0.001643 prune=0
2017/08/30 20:12:05 step 0: objective=0.118370 reg=0.001643
2017/08/30 20:12:07 step 1: objective=0.118441 reg=0.001644
2017/08/30 20:12:08 step 2: objective=0.118512 reg=0.001645
2017/08/30 20:12:10 step 3: objective=0.118583 reg=0.001646
2017/08/30 20:12:11 step 4: objective=0.118647 reg=0.001645
2017/08/30 20:12:13 step 5: objective=0.118735 reg=0.001645
2017/08/30 20:12:15 step 6: objective=0.118796 reg=0.001644
2017/08/30 20:12:16 step 7: objective=0.118845 reg=0.001644
2017/08/30 20:12:16 Training value function...
2017/08/30 20:12:19 step 0: mse=0.211230 step=0.050000
2017/08/30 20:12:21 step 1: mse=0.212084 step=0.050000
2017/08/30 20:12:22 step 2: mse=0.212824 step=0.050000
2017/08/30 20:12:23 step 3: mse=0.213733 step=0.050000
2017/08/30 20:12:25 step 4: mse=0.214345 step=0.050000
2017/08/30 20:12:26 step 5: mse=0.215055 step=0.050000
2017/08/30 20:12:27 step 6: mse=0.215914 step=0.050000
2017/08/30 20:12:28 step 7: mse=0.216593 step=0.050000
2017/08/30 20:12:28 Saving...
2017/08/30 20:12:28 Gathering batch of experience...
2017/08/30 20:13:10 batch 495: mean=39.000000 stddev=0.000000 entropy=0.163609 frames=8400 count=14
2017/08/30 20:13:10 Training policy...
2017/08/30 20:13:16 tune 0: objective=0.145547 reg=0.001636 prune=0
2017/08/30 20:13:17 step 0: objective=0.145547 reg=0.001636
2017/08/30 20:13:19 step 1: objective=0.145618 reg=0.001636
2017/08/30 20:13:21 step 2: objective=0.145693 reg=0.001637
2017/08/30 20:13:23 step 3: objective=0.145770 reg=0.001637
2017/08/30 20:13:25 step 4: objective=0.145867 reg=0.001637
2017/08/30 20:13:26 step 5: objective=0.145958 reg=0.001638
2017/08/30 20:13:28 step 6: objective=0.146017 reg=0.001638
2017/08/30 20:13:30 step 7: objective=0.146048 reg=0.001638
2017/08/30 20:13:30 Training value function...
2017/08/30 20:13:34 step 0: mse=0.208193 step=0.050000
2017/08/30 20:13:35 step 1: mse=0.206556 step=0.050000
2017/08/30 20:13:36 step 2: mse=0.204879 step=0.050000
2017/08/30 20:13:38 step 3: mse=0.202936 step=0.050000
2017/08/30 20:13:39 step 4: mse=0.201270 step=0.050000
2017/08/30 20:13:41 step 5: mse=0.199959 step=0.050000
2017/08/30 20:13:42 step 6: mse=0.198202 step=0.050000
2017/08/30 20:13:44 step 7: mse=0.196669 step=0.050000
2017/08/30 20:13:44 Saving...
2017/08/30 20:13:44 Gathering batch of experience...
2017/08/30 20:14:24 batch 496: mean=30.588235 stddev=11.024352 entropy=0.165609 frames=8057 count=17
2017/08/30 20:14:24 Training policy...
2017/08/30 20:14:29 tune 0: objective=0.121525 reg=0.001656 prune=0
2017/08/30 20:14:31 step 0: objective=0.121525 reg=0.001656
2017/08/30 20:14:33 step 1: objective=0.121605 reg=0.001656
2017/08/30 20:14:35 step 2: objective=0.121672 reg=0.001656
2017/08/30 20:14:36 step 3: objective=0.121729 reg=0.001656
2017/08/30 20:14:38 step 4: objective=0.121775 reg=0.001656
2017/08/30 20:14:40 step 5: objective=0.121817 reg=0.001655
2017/08/30 20:14:42 step 6: objective=0.121903 reg=0.001655
2017/08/30 20:14:43 step 7: objective=0.121938 reg=0.001655
2017/08/30 20:14:43 Training value function...
2017/08/30 20:14:47 step 0: mse=0.205626 step=0.050000
2017/08/30 20:14:48 step 1: mse=0.206485 step=0.050000
2017/08/30 20:14:49 step 2: mse=0.207304 step=0.050000
2017/08/30 20:14:51 step 3: mse=0.208160 step=0.050000
2017/08/30 20:14:52 step 4: mse=0.208795 step=0.050000
2017/08/30 20:14:54 step 5: mse=0.209268 step=0.050000
2017/08/30 20:14:55 step 6: mse=0.209998 step=0.050000
2017/08/30 20:14:57 step 7: mse=0.210326 step=0.050000
2017/08/30 20:14:57 Saving...
2017/08/30 20:14:57 Gathering batch of experience...
2017/08/30 20:15:36 batch 497: mean=33.666667 stddev=9.008638 entropy=0.162737 frames=7804 count=15
2017/08/30 20:15:36 Training policy...
2017/08/30 20:15:41 tune 0: objective=0.131669 reg=0.001627 prune=0
2017/08/30 20:15:43 step 0: objective=0.131670 reg=0.001627
2017/08/30 20:15:45 step 1: objective=0.131788 reg=0.001627
2017/08/30 20:15:47 step 2: objective=0.131887 reg=0.001627
2017/08/30 20:15:48 step 3: objective=0.131992 reg=0.001627
2017/08/30 20:15:50 step 4: objective=0.132090 reg=0.001627
2017/08/30 20:15:52 step 5: objective=0.132216 reg=0.001627
2017/08/30 20:15:53 step 6: objective=0.132275 reg=0.001627
2017/08/30 20:15:55 step 7: objective=0.132353 reg=0.001627
2017/08/30 20:15:55 Training value function...
2017/08/30 20:15:58 step 0: mse=0.204754 step=0.050000
2017/08/30 20:15:59 step 1: mse=0.204535 step=0.050000
2017/08/30 20:16:01 step 2: mse=0.204267 step=0.050000
2017/08/30 20:16:02 step 3: mse=0.204149 step=0.050000
2017/08/30 20:16:04 step 4: mse=0.203914 step=0.050000
2017/08/30 20:16:05 step 5: mse=0.203788 step=0.050000
2017/08/30 20:16:06 step 6: mse=0.203502 step=0.050000
2017/08/30 20:16:08 step 7: mse=0.203475 step=0.050000
2017/08/30 20:16:08 Saving...
2017/08/30 20:16:08 Gathering batch of experience...
2017/08/30 20:16:47 batch 498: mean=30.437500 stddev=11.984202 entropy=0.165265 frames=7553 count=16
2017/08/30 20:16:47 Training policy...
2017/08/30 20:16:52 tune 0: objective=0.124043 reg=0.001653 prune=0
2017/08/30 20:16:54 step 0: objective=0.124043 reg=0.001653
2017/08/30 20:16:55 step 1: objective=0.124147 reg=0.001654
2017/08/30 20:16:57 step 2: objective=0.124202 reg=0.001654
2017/08/30 20:16:58 step 3: objective=0.124338 reg=0.001655
2017/08/30 20:17:00 step 4: objective=0.124386 reg=0.001655
2017/08/30 20:17:02 step 5: objective=0.124491 reg=0.001656
2017/08/30 20:17:03 step 6: objective=0.124588 reg=0.001656
2017/08/30 20:17:05 step 7: objective=0.124669 reg=0.001657
2017/08/30 20:17:05 Training value function...
2017/08/30 20:17:08 step 0: mse=0.213079 step=0.050000
2017/08/30 20:17:09 step 1: mse=0.213669 step=0.050000
2017/08/30 20:17:11 step 2: mse=0.214093 step=0.050000
2017/08/30 20:17:12 step 3: mse=0.214729 step=0.050000
2017/08/30 20:17:13 step 4: mse=0.215165 step=0.050000
2017/08/30 20:17:15 step 5: mse=0.215504 step=0.050000
2017/08/30 20:17:16 step 6: mse=0.215964 step=0.050000
2017/08/30 20:17:17 step 7: mse=0.216303 step=0.050000
2017/08/30 20:17:17 Saving...
2017/08/30 20:17:17 Gathering batch of experience...
2017/08/30 20:17:59 batch 499: mean=34.500000 stddev=10.031201 entropy=0.167406 frames=8511 count=16
2017/08/30 20:17:59 Training policy...
2017/08/30 20:18:05 tune 0: objective=0.139351 reg=0.001674 prune=0
2017/08/30 20:18:07 step 0: objective=0.139351 reg=0.001674
2017/08/30 20:18:08 step 1: objective=0.139408 reg=0.001673
2017/08/30 20:18:10 step 2: objective=0.139494 reg=0.001674
2017/08/30 20:18:12 step 3: objective=0.139552 reg=0.001674
2017/08/30 20:18:14 step 4: objective=0.139618 reg=0.001673
2017/08/30 20:18:16 step 5: objective=0.139675 reg=0.001673
2017/08/30 20:18:17 step 6: objective=0.139798 reg=0.001673
2017/08/30 20:18:19 step 7: objective=0.139873 reg=0.001672
2017/08/30 20:18:19 Training value function...
2017/08/30 20:18:23 step 0: mse=0.212308 step=0.050000
2017/08/30 20:18:24 step 1: mse=0.211131 step=0.050000
2017/08/30 20:18:26 step 2: mse=0.210126 step=0.050000
2017/08/30 20:18:27 step 3: mse=0.209109 step=0.050000
2017/08/30 20:18:29 step 4: mse=0.207798 step=0.050000
2017/08/30 20:18:30 step 5: mse=0.206591 step=0.050000
2017/08/30 20:18:32 step 6: mse=0.205574 step=0.050000
2017/08/30 20:18:33 step 7: mse=0.204834 step=0.050000
2017/08/30 20:18:33 Saving...
2017/08/30 20:18:33 Gathering batch of experience...
2017/08/30 20:19:14 batch 500: mean=36.200000 stddev=6.685307 entropy=0.164718 frames=8372 count=15
2017/08/30 20:19:14 Training policy...
2017/08/30 20:19:20 tune 0: objective=0.135669 reg=0.001647 prune=0
2017/08/30 20:19:22 step 0: objective=0.135669 reg=0.001647
2017/08/30 20:19:24 step 1: objective=0.135709 reg=0.001647
2017/08/30 20:19:26 step 2: objective=0.135747 reg=0.001648
2017/08/30 20:19:27 step 3: objective=0.135828 reg=0.001648
2017/08/30 20:19:29 step 4: objective=0.135878 reg=0.001647
2017/08/30 20:19:31 step 5: objective=0.135924 reg=0.001647
2017/08/30 20:19:33 step 6: objective=0.136007 reg=0.001647
2017/08/30 20:19:35 step 7: objective=0.136091 reg=0.001647
2017/08/30 20:19:35 Training value function...
2017/08/30 20:19:38 step 0: mse=0.200806 step=0.050000
2017/08/30 20:19:39 step 1: mse=0.199965 step=0.050000
2017/08/30 20:19:41 step 2: mse=0.198986 step=0.050000
2017/08/30 20:19:42 step 3: mse=0.198136 step=0.050000
2017/08/30 20:19:44 step 4: mse=0.197799 step=0.050000
2017/08/30 20:19:45 step 5: mse=0.197143 step=0.050000
2017/08/30 20:19:47 step 6: mse=0.196539 step=0.050000
2017/08/30 20:19:48 step 7: mse=0.195751 step=0.050000
2017/08/30 20:19:48 Saving...
2017/08/30 20:19:48 Gathering batch of experience...
2017/08/30 20:20:30 batch 501: mean=37.133333 stddev=4.787019 entropy=0.162897 frames=8580 count=15
2017/08/30 20:20:30 Training policy...
2017/08/30 20:20:36 tune 0: objective=0.135545 reg=0.001629 prune=0
2017/08/30 20:20:38 step 0: objective=0.135545 reg=0.001629
2017/08/30 20:20:39 step 1: objective=0.135613 reg=0.001630
2017/08/30 20:20:41 step 2: objective=0.135743 reg=0.001630
2017/08/30 20:20:43 step 3: objective=0.135875 reg=0.001631
2017/08/30 20:20:45 step 4: objective=0.135930 reg=0.001631
2017/08/30 20:20:47 step 5: objective=0.136028 reg=0.001632
2017/08/30 20:20:49 step 6: objective=0.136059 reg=0.001632
2017/08/30 20:20:50 step 7: objective=0.136101 reg=0.001632
2017/08/30 20:20:50 Training value function...
2017/08/30 20:20:54 step 0: mse=0.193896 step=0.050000
2017/08/30 20:20:56 step 1: mse=0.193237 step=0.050000
2017/08/30 20:20:57 step 2: mse=0.192375 step=0.050000
2017/08/30 20:20:59 step 3: mse=0.191691 step=0.050000
2017/08/30 20:21:00 step 4: mse=0.191202 step=0.050000
2017/08/30 20:21:02 step 5: mse=0.190513 step=0.050000
2017/08/30 20:21:03 step 6: mse=0.189924 step=0.050000
2017/08/30 20:21:04 step 7: mse=0.189189 step=0.050000
2017/08/30 20:21:04 Saving...
2017/08/30 20:21:05 Gathering batch of experience...
2017/08/30 20:21:44 batch 502: mean=29.176471 stddev=12.948928 entropy=0.167854 frames=7681 count=17
2017/08/30 20:21:44 Training policy...
2017/08/30 20:21:49 tune 0: objective=0.118788 reg=0.001679 prune=0
2017/08/30 20:21:51 step 0: objective=0.118788 reg=0.001679
2017/08/30 20:21:52 step 1: objective=0.118932 reg=0.001678
2017/08/30 20:21:54 step 2: objective=0.119073 reg=0.001678
2017/08/30 20:21:56 step 3: objective=0.119117 reg=0.001678
2017/08/30 20:21:57 step 4: objective=0.119183 reg=0.001677
2017/08/30 20:21:59 step 5: objective=0.119247 reg=0.001677
2017/08/30 20:22:01 step 6: objective=0.119294 reg=0.001676
2017/08/30 20:22:02 step 7: objective=0.119338 reg=0.001676
2017/08/30 20:22:02 Training value function...
2017/08/30 20:22:05 step 0: mse=0.200472 step=0.050000
2017/08/30 20:22:07 step 1: mse=0.201295 step=0.050000
2017/08/30 20:22:08 step 2: mse=0.202104 step=0.050000
2017/08/30 20:22:10 step 3: mse=0.202886 step=0.050000
2017/08/30 20:22:11 step 4: mse=0.203708 step=0.050000
2017/08/30 20:22:12 step 5: mse=0.204550 step=0.050000
2017/08/30 20:22:14 step 6: mse=0.205268 step=0.050000
2017/08/30 20:22:15 step 7: mse=0.205784 step=0.050000
2017/08/30 20:22:15 Saving...
2017/08/30 20:22:15 Gathering batch of experience...
2017/08/30 20:22:55 batch 503: mean=31.375000 stddev=10.445543 entropy=0.168651 frames=7768 count=16
2017/08/30 20:22:55 Training policy...
2017/08/30 20:23:00 tune 0: objective=0.127104 reg=0.001687 prune=0
2017/08/30 20:23:02 step 0: objective=0.127104 reg=0.001687
2017/08/30 20:23:03 step 1: objective=0.127148 reg=0.001686
2017/08/30 20:23:05 step 2: objective=0.127255 reg=0.001686
2017/08/30 20:23:07 step 3: objective=0.127380 reg=0.001685
2017/08/30 20:23:08 step 4: objective=0.127444 reg=0.001684
2017/08/30 20:23:10 step 5: objective=0.127482 reg=0.001684
2017/08/30 20:23:12 step 6: objective=0.127569 reg=0.001683
2017/08/30 20:23:13 step 7: objective=0.127638 reg=0.001683
2017/08/30 20:23:13 Training value function...
2017/08/30 20:23:17 step 0: mse=0.203829 step=0.050000
2017/08/30 20:23:18 step 1: mse=0.204074 step=0.050000
2017/08/30 20:23:19 step 2: mse=0.204388 step=0.050000
2017/08/30 20:23:21 step 3: mse=0.204737 step=0.050000
2017/08/30 20:23:22 step 4: mse=0.205143 step=0.050000
2017/08/30 20:23:24 step 5: mse=0.205193 step=0.050000
2017/08/30 20:23:25 step 6: mse=0.205538 step=0.050000
2017/08/30 20:23:26 step 7: mse=0.205824 step=0.050000
2017/08/30 20:23:26 Saving...
2017/08/30 20:23:26 Gathering batch of experience...
2017/08/30 20:24:07 batch 504: mean=36.000000 stddev=8.555700 entropy=0.162196 frames=8319 count=15
2017/08/30 20:24:07 Training policy...
2017/08/30 20:24:13 tune 0: objective=0.140051 reg=0.001622 prune=0
2017/08/30 20:24:15 step 0: objective=0.140051 reg=0.001622
2017/08/30 20:24:17 step 1: objective=0.140089 reg=0.001622
2017/08/30 20:24:19 step 2: objective=0.140143 reg=0.001622
2017/08/30 20:24:20 step 3: objective=0.140218 reg=0.001623
2017/08/30 20:24:22 step 4: objective=0.140325 reg=0.001623
2017/08/30 20:24:24 step 5: objective=0.140406 reg=0.001623
2017/08/30 20:24:26 step 6: objective=0.140483 reg=0.001624
2017/08/30 20:24:27 step 7: objective=0.140526 reg=0.001624
2017/08/30 20:24:27 Training value function...
2017/08/30 20:24:31 step 0: mse=0.203724 step=0.050000
2017/08/30 20:24:32 step 1: mse=0.202462 step=0.050000
2017/08/30 20:24:34 step 2: mse=0.201055 step=0.050000
2017/08/30 20:24:35 step 3: mse=0.199588 step=0.050000
2017/08/30 20:24:37 step 4: mse=0.198275 step=0.050000
2017/08/30 20:24:38 step 5: mse=0.197131 step=0.050000
2017/08/30 20:24:40 step 6: mse=0.196093 step=0.050000
2017/08/30 20:24:41 step 7: mse=0.195281 step=0.050000
2017/08/30 20:24:41 Saving...
2017/08/30 20:24:41 Gathering batch of experience...
2017/08/30 20:25:20 batch 505: mean=22.095238 stddev=13.890404 entropy=0.170313 frames=7232 count=21
2017/08/30 20:25:20 Training policy...
2017/08/30 20:25:25 tune 0: objective=0.102807 reg=0.001703 prune=0
2017/08/30 20:25:26 step 0: objective=0.102807 reg=0.001703
2017/08/30 20:25:28 step 1: objective=0.102885 reg=0.001703
2017/08/30 20:25:29 step 2: objective=0.102952 reg=0.001702
2017/08/30 20:25:31 step 3: objective=0.103018 reg=0.001702
2017/08/30 20:25:32 step 4: objective=0.103084 reg=0.001702
2017/08/30 20:25:34 step 5: objective=0.103192 reg=0.001702
2017/08/30 20:25:35 step 6: objective=0.103272 reg=0.001701
2017/08/30 20:25:37 step 7: objective=0.103334 reg=0.001701
2017/08/30 20:25:37 Training value function...
2017/08/30 20:25:40 step 0: mse=0.215128 step=0.050000
2017/08/30 20:25:41 step 1: mse=0.216197 step=0.050000
2017/08/30 20:25:43 step 2: mse=0.217558 step=0.050000
2017/08/30 20:25:44 step 3: mse=0.218799 step=0.050000
2017/08/30 20:25:45 step 4: mse=0.219974 step=0.050000
2017/08/30 20:25:46 step 5: mse=0.220912 step=0.050000
2017/08/30 20:25:48 step 6: mse=0.222105 step=0.050000
2017/08/30 20:25:49 step 7: mse=0.223454 step=0.050000
2017/08/30 20:25:49 Saving...
2017/08/30 20:25:49 Gathering batch of experience...
2017/08/30 20:26:30 batch 506: mean=29.555556 stddev=13.136980 entropy=0.162330 frames=8237 count=18
2017/08/30 20:26:30 Training policy...
2017/08/30 20:26:36 tune 0: objective=0.131841 reg=0.001623 prune=0
2017/08/30 20:26:38 step 0: objective=0.131842 reg=0.001623
2017/08/30 20:26:40 step 1: objective=0.131916 reg=0.001624
2017/08/30 20:26:42 step 2: objective=0.131999 reg=0.001624
2017/08/30 20:26:43 step 3: objective=0.132047 reg=0.001624
2017/08/30 20:26:45 step 4: objective=0.132122 reg=0.001624
2017/08/30 20:26:47 step 5: objective=0.132189 reg=0.001624
2017/08/30 20:26:49 step 6: objective=0.132276 reg=0.001625
2017/08/30 20:26:50 step 7: objective=0.132366 reg=0.001626
2017/08/30 20:26:50 Training value function...
2017/08/30 20:26:54 step 0: mse=0.220798 step=0.050000
2017/08/30 20:26:55 step 1: mse=0.220373 step=0.050000
2017/08/30 20:26:57 step 2: mse=0.220056 step=0.050000
2017/08/30 20:26:58 step 3: mse=0.220045 step=0.050000
2017/08/30 20:27:00 step 4: mse=0.220037 step=0.050000
2017/08/30 20:27:01 step 5: mse=0.219979 step=0.050000
2017/08/30 20:27:03 step 6: mse=0.219731 step=0.050000
2017/08/30 20:27:04 step 7: mse=0.219865 step=0.050000
2017/08/30 20:27:04 Saving...
2017/08/30 20:27:04 Gathering batch of experience...
2017/08/30 20:27:46 batch 507: mean=32.588235 stddev=10.655343 entropy=0.161327 frames=8546 count=17
2017/08/30 20:27:46 Training policy...
2017/08/30 20:27:52 tune 0: objective=0.139611 reg=0.001613 prune=0
2017/08/30 20:27:54 step 0: objective=0.139611 reg=0.001613
2017/08/30 20:27:56 step 1: objective=0.139732 reg=0.001613
2017/08/30 20:27:57 step 2: objective=0.139862 reg=0.001613
2017/08/30 20:27:59 step 3: objective=0.139937 reg=0.001613
2017/08/30 20:28:01 step 4: objective=0.140052 reg=0.001613
2017/08/30 20:28:03 step 5: objective=0.140104 reg=0.001613
2017/08/30 20:28:05 step 6: objective=0.140192 reg=0.001614
2017/08/30 20:28:07 step 7: objective=0.140276 reg=0.001613
2017/08/30 20:28:07 Training value function...
2017/08/30 20:28:10 step 0: mse=0.214106 step=0.050000
2017/08/30 20:28:12 step 1: mse=0.213077 step=0.050000
2017/08/30 20:28:13 step 2: mse=0.211855 step=0.050000
2017/08/30 20:28:15 step 3: mse=0.210895 step=0.050000
2017/08/30 20:28:16 step 4: mse=0.209651 step=0.050000
2017/08/30 20:28:18 step 5: mse=0.208567 step=0.050000
2017/08/30 20:28:19 step 6: mse=0.207730 step=0.050000
2017/08/30 20:28:21 step 7: mse=0.206787 step=0.050000
2017/08/30 20:28:21 Saving...
2017/08/30 20:28:21 Gathering batch of experience...
2017/08/30 20:29:00 batch 508: mean=31.437500 stddev=12.589523 entropy=0.160462 frames=7780 count=16
2017/08/30 20:29:00 Training policy...
2017/08/30 20:29:06 tune 0: objective=0.133158 reg=0.001605 prune=0
2017/08/30 20:29:07 step 0: objective=0.133158 reg=0.001605
2017/08/30 20:29:09 step 1: objective=0.133242 reg=0.001605
2017/08/30 20:29:11 step 2: objective=0.133310 reg=0.001605
2017/08/30 20:29:12 step 3: objective=0.133369 reg=0.001605
2017/08/30 20:29:14 step 4: objective=0.133435 reg=0.001606
2017/08/30 20:29:16 step 5: objective=0.133464 reg=0.001606
2017/08/30 20:29:17 step 6: objective=0.133489 reg=0.001606
2017/08/30 20:29:19 step 7: objective=0.133531 reg=0.001606
2017/08/30 20:29:19 Training value function...
2017/08/30 20:29:22 step 0: mse=0.211611 step=0.050000
2017/08/30 20:29:24 step 1: mse=0.211109 step=0.050000
2017/08/30 20:29:25 step 2: mse=0.211053 step=0.050000
2017/08/30 20:29:26 step 3: mse=0.210467 step=0.050000
2017/08/30 20:29:28 step 4: mse=0.209618 step=0.050000
2017/08/30 20:29:29 step 5: mse=0.209136 step=0.050000
2017/08/30 20:29:30 step 6: mse=0.208917 step=0.050000
2017/08/30 20:29:32 step 7: mse=0.208617 step=0.050000
2017/08/30 20:29:32 Saving...
2017/08/30 20:29:32 Gathering batch of experience...
2017/08/30 20:30:14 batch 509: mean=33.294118 stddev=11.441744 entropy=0.163345 frames=8745 count=17
2017/08/30 20:30:14 Training policy...
2017/08/30 20:30:20 tune 0: objective=0.136327 reg=0.001633 prune=0
2017/08/30 20:30:22 step 0: objective=0.136328 reg=0.001633
2017/08/30 20:30:24 step 1: objective=0.136395 reg=0.001633
2017/08/30 20:30:26 step 2: objective=0.136471 reg=0.001633
2017/08/30 20:30:28 step 3: objective=0.136519 reg=0.001633
2017/08/30 20:30:30 step 4: objective=0.136601 reg=0.001633
2017/08/30 20:30:32 step 5: objective=0.136641 reg=0.001634
2017/08/30 20:30:33 step 6: objective=0.136737 reg=0.001634
2017/08/30 20:30:35 step 7: objective=0.136784 reg=0.001634
2017/08/30 20:30:35 Training value function...
2017/08/30 20:30:39 step 0: mse=0.204717 step=0.050000
2017/08/30 20:30:41 step 1: mse=0.203925 step=0.050000
2017/08/30 20:30:42 step 2: mse=0.203326 step=0.050000
2017/08/30 20:30:44 step 3: mse=0.202931 step=0.050000
2017/08/30 20:30:45 step 4: mse=0.202522 step=0.050000
2017/08/30 20:30:47 step 5: mse=0.201935 step=0.050000
2017/08/30 20:30:48 step 6: mse=0.201610 step=0.050000
2017/08/30 20:30:50 step 7: mse=0.200998 step=0.050000
2017/08/30 20:30:50 Saving...
2017/08/30 20:30:50 Gathering batch of experience...
2017/08/30 20:31:31 batch 510: mean=33.687500 stddev=9.291924 entropy=0.162495 frames=8314 count=16
2017/08/30 20:31:31 Training policy...
2017/08/30 20:31:37 tune 0: objective=0.134416 reg=0.001625 prune=0
2017/08/30 20:31:38 step 0: objective=0.134417 reg=0.001625
2017/08/30 20:31:40 step 1: objective=0.134453 reg=0.001625
2017/08/30 20:31:42 step 2: objective=0.134490 reg=0.001625
2017/08/30 20:31:44 step 3: objective=0.134519 reg=0.001625
2017/08/30 20:31:46 step 4: objective=0.134552 reg=0.001626
2017/08/30 20:31:47 step 5: objective=0.134585 reg=0.001626
2017/08/30 20:31:49 step 6: objective=0.134611 reg=0.001626
2017/08/30 20:31:51 step 7: objective=0.134660 reg=0.001626
2017/08/30 20:31:51 Training value function...
2017/08/30 20:31:54 step 0: mse=0.203882 step=0.050000
2017/08/30 20:31:56 step 1: mse=0.203026 step=0.050000
2017/08/30 20:31:57 step 2: mse=0.202469 step=0.050000
2017/08/30 20:31:59 step 3: mse=0.201564 step=0.050000
2017/08/30 20:32:00 step 4: mse=0.200963 step=0.050000
2017/08/30 20:32:02 step 5: mse=0.200533 step=0.050000
2017/08/30 20:32:03 step 6: mse=0.200232 step=0.050000
2017/08/30 20:32:04 step 7: mse=0.199836 step=0.050000
2017/08/30 20:32:04 Saving...
2017/08/30 20:32:04 Gathering batch of experience...
2017/08/30 20:32:44 batch 511: mean=33.266667 stddev=10.188010 entropy=0.164947 frames=7731 count=15
2017/08/30 20:32:44 Training policy...
2017/08/30 20:32:49 tune 0: objective=0.129522 reg=0.001649 prune=0
2017/08/30 20:32:51 step 0: objective=0.129522 reg=0.001649
2017/08/30 20:32:52 step 1: objective=0.129633 reg=0.001648
2017/08/30 20:32:54 step 2: objective=0.129748 reg=0.001647
2017/08/30 20:32:56 step 3: objective=0.129882 reg=0.001646
2017/08/30 20:32:57 step 4: objective=0.130003 reg=0.001646
2017/08/30 20:32:59 step 5: objective=0.130108 reg=0.001645
2017/08/30 20:33:01 step 6: objective=0.130178 reg=0.001646
2017/08/30 20:33:02 step 7: objective=0.130249 reg=0.001645
2017/08/30 20:33:02 Training value function...
2017/08/30 20:33:06 step 0: mse=0.207115 step=0.050000
2017/08/30 20:33:07 step 1: mse=0.206961 step=0.050000
2017/08/30 20:33:08 step 2: mse=0.207110 step=0.050000
2017/08/30 20:33:10 step 3: mse=0.207342 step=0.050000
2017/08/30 20:33:11 step 4: mse=0.207396 step=0.050000
2017/08/30 20:33:12 step 5: mse=0.207082 step=0.050000
2017/08/30 20:33:14 step 6: mse=0.206668 step=0.050000
2017/08/30 20:33:15 step 7: mse=0.206609 step=0.050000
2017/08/30 20:33:15 Saving...
2017/08/30 20:33:15 Gathering batch of experience...
2017/08/30 20:33:55 batch 512: mean=37.285714 stddev=6.180945 entropy=0.159227 frames=8039 count=14
2017/08/30 20:33:55 Training policy...
2017/08/30 20:34:01 tune 0: objective=0.141955 reg=0.001592 prune=0
2017/08/30 20:34:03 step 0: objective=0.141955 reg=0.001592
2017/08/30 20:34:05 step 1: objective=0.142021 reg=0.001592
2017/08/30 20:34:06 step 2: objective=0.142112 reg=0.001592
2017/08/30 20:34:08 step 3: objective=0.142159 reg=0.001593
2017/08/30 20:34:10 step 4: objective=0.142223 reg=0.001593
2017/08/30 20:34:12 step 5: objective=0.142302 reg=0.001593
2017/08/30 20:34:13 step 6: objective=0.142376 reg=0.001594
2017/08/30 20:34:15 step 7: objective=0.142434 reg=0.001594
2017/08/30 20:34:15 Training value function...
2017/08/30 20:34:19 step 0: mse=0.202549 step=0.050000
2017/08/30 20:34:20 step 1: mse=0.200942 step=0.050000
2017/08/30 20:34:21 step 2: mse=0.199666 step=0.050000
2017/08/30 20:34:23 step 3: mse=0.198433 step=0.050000
2017/08/30 20:34:24 step 4: mse=0.197237 step=0.050000
2017/08/30 20:34:25 step 5: mse=0.196066 step=0.050000
2017/08/30 20:34:27 step 6: mse=0.195017 step=0.050000
2017/08/30 20:34:28 step 7: mse=0.193733 step=0.050000
2017/08/30 20:34:28 Saving...
2017/08/30 20:34:28 Gathering batch of experience...
2017/08/30 20:35:10 batch 513: mean=35.125000 stddev=9.157476 entropy=0.161101 frames=8672 count=16
2017/08/30 20:35:10 Training policy...
2017/08/30 20:35:16 tune 0: objective=0.131117 reg=0.001611 prune=0
2017/08/30 20:35:18 step 0: objective=0.131118 reg=0.001611
2017/08/30 20:35:20 step 1: objective=0.131181 reg=0.001611
2017/08/30 20:35:22 step 2: objective=0.131261 reg=0.001611
2017/08/30 20:35:24 step 3: objective=0.131307 reg=0.001611
2017/08/30 20:35:26 step 4: objective=0.131384 reg=0.001611
2017/08/30 20:35:28 step 5: objective=0.131436 reg=0.001611
2017/08/30 20:35:29 step 6: objective=0.131521 reg=0.001612
2017/08/30 20:35:31 step 7: objective=0.131556 reg=0.001612
2017/08/30 20:35:31 Training value function...
2017/08/30 20:35:35 step 0: mse=0.194680 step=0.050000
2017/08/30 20:35:36 step 1: mse=0.194371 step=0.050000
2017/08/30 20:35:38 step 2: mse=0.194084 step=0.050000
2017/08/30 20:35:39 step 3: mse=0.194045 step=0.050000
2017/08/30 20:35:41 step 4: mse=0.193932 step=0.050000
2017/08/30 20:35:42 step 5: mse=0.193633 step=0.050000
2017/08/30 20:35:44 step 6: mse=0.193297 step=0.050000
2017/08/30 20:35:45 step 7: mse=0.192948 step=0.050000
2017/08/30 20:35:45 Saving...
2017/08/30 20:35:45 Gathering batch of experience...
2017/08/30 20:36:25 batch 514: mean=31.812500 stddev=12.319795 entropy=0.162046 frames=7878 count=16
2017/08/30 20:36:25 Training policy...
2017/08/30 20:36:31 tune 0: objective=0.125429 reg=0.001620 prune=0
2017/08/30 20:36:33 step 0: objective=0.125429 reg=0.001620
2017/08/30 20:36:34 step 1: objective=0.125499 reg=0.001620
2017/08/30 20:36:36 step 2: objective=0.125574 reg=0.001620
2017/08/30 20:36:38 step 3: objective=0.125711 reg=0.001619
2017/08/30 20:36:39 step 4: objective=0.125784 reg=0.001618
2017/08/30 20:36:41 step 5: objective=0.125862 reg=0.001617
2017/08/30 20:36:43 step 6: objective=0.125982 reg=0.001616
2017/08/30 20:36:44 step 7: objective=0.126065 reg=0.001615
2017/08/30 20:36:44 Training value function...
2017/08/30 20:36:48 step 0: mse=0.201626 step=0.050000
2017/08/30 20:36:49 step 1: mse=0.202066 step=0.050000
2017/08/30 20:36:51 step 2: mse=0.202454 step=0.050000
2017/08/30 20:36:52 step 3: mse=0.202995 step=0.050000
2017/08/30 20:36:53 step 4: mse=0.203500 step=0.050000
2017/08/30 20:36:55 step 5: mse=0.203976 step=0.050000
2017/08/30 20:36:56 step 6: mse=0.204512 step=0.050000
2017/08/30 20:36:58 step 7: mse=0.204849 step=0.050000
2017/08/30 20:36:58 Saving...
2017/08/30 20:36:58 Gathering batch of experience...
2017/08/30 20:37:42 batch 515: mean=29.894737 stddev=12.859135 entropy=0.161358 frames=8816 count=19
2017/08/30 20:37:42 Training policy...
2017/08/30 20:37:48 tune 0: objective=0.122020 reg=0.001614 prune=0
2017/08/30 20:37:50 step 0: objective=0.122020 reg=0.001614
2017/08/30 20:37:52 step 1: objective=0.122146 reg=0.001614
2017/08/30 20:37:54 step 2: objective=0.122226 reg=0.001614
2017/08/30 20:37:56 step 3: objective=0.122337 reg=0.001614
2017/08/30 20:37:58 step 4: objective=0.122442 reg=0.001613
2017/08/30 20:38:00 step 5: objective=0.122476 reg=0.001613
2017/08/30 20:38:01 step 6: objective=0.122517 reg=0.001612
2017/08/30 20:38:03 step 7: objective=0.122543 reg=0.001612
2017/08/30 20:38:03 Training value function...
2017/08/30 20:38:07 step 0: mse=0.207868 step=0.050000
2017/08/30 20:38:09 step 1: mse=0.208471 step=0.050000
2017/08/30 20:38:10 step 2: mse=0.209307 step=0.050000
2017/08/30 20:38:12 step 3: mse=0.209964 step=0.050000
2017/08/30 20:38:13 step 4: mse=0.210500 step=0.050000
2017/08/30 20:38:15 step 5: mse=0.211061 step=0.050000
2017/08/30 20:38:17 step 6: mse=0.211464 step=0.050000
2017/08/30 20:38:18 step 7: mse=0.211924 step=0.050000
2017/08/30 20:38:18 Saving...
2017/08/30 20:38:18 Gathering batch of experience...
2017/08/30 20:39:00 batch 516: mean=31.882353 stddev=10.057963 entropy=0.167485 frames=8382 count=17
2017/08/30 20:39:00 Training policy...
2017/08/30 20:39:06 tune 0: objective=0.129208 reg=0.001675 prune=0
2017/08/30 20:39:07 step 0: objective=0.129208 reg=0.001675
2017/08/30 20:39:09 step 1: objective=0.129287 reg=0.001675
2017/08/30 20:39:11 step 2: objective=0.129393 reg=0.001674
2017/08/30 20:39:13 step 3: objective=0.129500 reg=0.001674
2017/08/30 20:39:15 step 4: objective=0.129569 reg=0.001672
2017/08/30 20:39:16 step 5: objective=0.129643 reg=0.001671
2017/08/30 20:39:18 step 6: objective=0.129702 reg=0.001670
2017/08/30 20:39:20 step 7: objective=0.129782 reg=0.001670
2017/08/30 20:39:20 Training value function...
2017/08/30 20:39:24 step 0: mse=0.207880 step=0.050000
2017/08/30 20:39:25 step 1: mse=0.208126 step=0.050000
2017/08/30 20:39:27 step 2: mse=0.208115 step=0.050000
2017/08/30 20:39:28 step 3: mse=0.208277 step=0.050000
2017/08/30 20:39:30 step 4: mse=0.208613 step=0.050000
2017/08/30 20:39:31 step 5: mse=0.209003 step=0.050000
2017/08/30 20:39:33 step 6: mse=0.209153 step=0.050000
2017/08/30 20:39:34 step 7: mse=0.209371 step=0.050000
2017/08/30 20:39:34 Saving...
2017/08/30 20:39:34 Gathering batch of experience...
2017/08/30 20:40:14 batch 517: mean=33.666667 stddev=10.169672 entropy=0.161740 frames=7803 count=15
2017/08/30 20:40:14 Training policy...
2017/08/30 20:40:19 tune 0: objective=0.135498 reg=0.001617 prune=0
2017/08/30 20:40:21 step 0: objective=0.135498 reg=0.001617
2017/08/30 20:40:23 step 1: objective=0.135564 reg=0.001617
2017/08/30 20:40:24 step 2: objective=0.135630 reg=0.001617
2017/08/30 20:40:26 step 3: objective=0.135697 reg=0.001617
2017/08/30 20:40:28 step 4: objective=0.135729 reg=0.001617
2017/08/30 20:40:29 step 5: objective=0.135773 reg=0.001616
2017/08/30 20:40:31 step 6: objective=0.135825 reg=0.001615
2017/08/30 20:40:33 step 7: objective=0.135860 reg=0.001615
2017/08/30 20:40:33 Training value function...
2017/08/30 20:40:36 step 0: mse=0.211840 step=0.050000
2017/08/30 20:40:37 step 1: mse=0.211027 step=0.050000
2017/08/30 20:40:39 step 2: mse=0.210299 step=0.050000
2017/08/30 20:40:40 step 3: mse=0.209811 step=0.050000
2017/08/30 20:40:41 step 4: mse=0.209141 step=0.050000
2017/08/30 20:40:43 step 5: mse=0.208685 step=0.050000
2017/08/30 20:40:44 step 6: mse=0.208154 step=0.050000
2017/08/30 20:40:45 step 7: mse=0.207297 step=0.050000
2017/08/30 20:40:45 Saving...
2017/08/30 20:40:45 Gathering batch of experience...
2017/08/30 20:41:28 batch 518: mean=35.750000 stddev=8.714213 entropy=0.161277 frames=8810 count=16
2017/08/30 20:41:28 Training policy...
2017/08/30 20:41:34 tune 0: objective=0.140312 reg=0.001613 prune=0
2017/08/30 20:41:36 step 0: objective=0.140312 reg=0.001613
2017/08/30 20:41:38 step 1: objective=0.140421 reg=0.001612
2017/08/30 20:41:40 step 2: objective=0.140483 reg=0.001612
2017/08/30 20:41:42 step 3: objective=0.140536 reg=0.001613
2017/08/30 20:41:44 step 4: objective=0.140588 reg=0.001612
2017/08/30 20:41:46 step 5: objective=0.140641 reg=0.001612
2017/08/30 20:41:48 step 6: objective=0.140730 reg=0.001612
2017/08/30 20:41:50 step 7: objective=0.140794 reg=0.001613
2017/08/30 20:41:50 Training value function...
2017/08/30 20:41:53 step 0: mse=0.203218 step=0.050000
2017/08/30 20:41:55 step 1: mse=0.202089 step=0.050000
2017/08/30 20:41:56 step 2: mse=0.201035 step=0.050000
2017/08/30 20:41:58 step 3: mse=0.199998 step=0.050000
2017/08/30 20:41:59 step 4: mse=0.198924 step=0.050000
2017/08/30 20:42:01 step 5: mse=0.197714 step=0.050000
2017/08/30 20:42:02 step 6: mse=0.196552 step=0.050000
2017/08/30 20:42:04 step 7: mse=0.195670 step=0.050000
2017/08/30 20:42:04 Saving...
2017/08/30 20:42:04 Gathering batch of experience...
2017/08/30 20:42:44 batch 519: mean=34.000000 stddev=9.667816 entropy=0.159715 frames=7885 count=15
2017/08/30 20:42:44 Training policy...
2017/08/30 20:42:49 tune 0: objective=0.128376 reg=0.001597 prune=0
2017/08/30 20:42:51 step 0: objective=0.128376 reg=0.001597
2017/08/30 20:42:53 step 1: objective=0.128434 reg=0.001598
2017/08/30 20:42:54 step 2: objective=0.128506 reg=0.001598
2017/08/30 20:42:56 step 3: objective=0.128584 reg=0.001597
2017/08/30 20:42:58 step 4: objective=0.128625 reg=0.001597
2017/08/30 20:42:59 step 5: objective=0.128652 reg=0.001597
2017/08/30 20:43:01 step 6: objective=0.128694 reg=0.001597
2017/08/30 20:43:03 step 7: objective=0.128730 reg=0.001597
2017/08/30 20:43:03 Training value function...
2017/08/30 20:43:06 step 0: mse=0.200878 step=0.050000
2017/08/30 20:43:07 step 1: mse=0.200670 step=0.050000
2017/08/30 20:43:09 step 2: mse=0.200608 step=0.050000
2017/08/30 20:43:10 step 3: mse=0.200838 step=0.050000
2017/08/30 20:43:12 step 4: mse=0.200843 step=0.050000
2017/08/30 20:43:13 step 5: mse=0.200875 step=0.050000
2017/08/30 20:43:14 step 6: mse=0.201042 step=0.050000
2017/08/30 20:43:16 step 7: mse=0.201030 step=0.050000
2017/08/30 20:43:16 Saving...
2017/08/30 20:43:16 Gathering batch of experience...
2017/08/30 20:43:59 batch 520: mean=32.764706 stddev=10.641370 entropy=0.161830 frames=8602 count=17
2017/08/30 20:43:59 Training policy...
2017/08/30 20:44:05 tune 0: objective=0.129870 reg=0.001618 prune=0
2017/08/30 20:44:07 step 0: objective=0.129870 reg=0.001618
2017/08/30 20:44:09 step 1: objective=0.130012 reg=0.001618
2017/08/30 20:44:11 step 2: objective=0.130171 reg=0.001618
2017/08/30 20:44:13 step 3: objective=0.130261 reg=0.001619
2017/08/30 20:44:15 step 4: objective=0.130309 reg=0.001619
2017/08/30 20:44:17 step 5: objective=0.130360 reg=0.001620
2017/08/30 20:44:19 step 6: objective=0.130461 reg=0.001620
2017/08/30 20:44:20 step 7: objective=0.130532 reg=0.001620
2017/08/30 20:44:20 Training value function...
2017/08/30 20:44:24 step 0: mse=0.201090 step=0.050000
2017/08/30 20:44:26 step 1: mse=0.201200 step=0.050000
2017/08/30 20:44:27 step 2: mse=0.201178 step=0.050000
2017/08/30 20:44:29 step 3: mse=0.201371 step=0.050000
2017/08/30 20:44:30 step 4: mse=0.201394 step=0.050000
2017/08/30 20:44:32 step 5: mse=0.201523 step=0.050000
2017/08/30 20:44:33 step 6: mse=0.201691 step=0.050000
2017/08/30 20:44:35 step 7: mse=0.201804 step=0.050000
2017/08/30 20:44:35 Saving...
2017/08/30 20:44:35 Gathering batch of experience...
2017/08/30 20:45:16 batch 521: mean=34.125000 stddev=10.717247 entropy=0.159651 frames=8444 count=16
2017/08/30 20:45:16 Training policy...
2017/08/30 20:45:22 tune 0: objective=0.133389 reg=0.001597 prune=0
2017/08/30 20:45:24 step 0: objective=0.133389 reg=0.001597
2017/08/30 20:45:26 step 1: objective=0.133447 reg=0.001597
2017/08/30 20:45:28 step 2: objective=0.133527 reg=0.001596
2017/08/30 20:45:30 step 3: objective=0.133599 reg=0.001597
2017/08/30 20:45:32 step 4: objective=0.133651 reg=0.001597
2017/08/30 20:45:33 step 5: objective=0.133719 reg=0.001597
2017/08/30 20:45:35 step 6: objective=0.133748 reg=0.001597
2017/08/30 20:45:37 step 7: objective=0.133817 reg=0.001598
2017/08/30 20:45:37 Training value function...
2017/08/30 20:45:41 step 0: mse=0.202541 step=0.050000
2017/08/30 20:45:42 step 1: mse=0.202064 step=0.050000
2017/08/30 20:45:44 step 2: mse=0.201827 step=0.050000
2017/08/30 20:45:45 step 3: mse=0.201241 step=0.050000
2017/08/30 20:45:47 step 4: mse=0.201183 step=0.050000
2017/08/30 20:45:48 step 5: mse=0.200959 step=0.050000
2017/08/30 20:45:50 step 6: mse=0.200410 step=0.050000
2017/08/30 20:45:51 step 7: mse=0.200059 step=0.050000
2017/08/30 20:45:51 Saving...
2017/08/30 20:45:51 Gathering batch of experience...
2017/08/30 20:46:32 batch 522: mean=33.750000 stddev=10.526752 entropy=0.165864 frames=8342 count=16
2017/08/30 20:46:32 Training policy...
2017/08/30 20:46:38 tune 0: objective=0.132464 reg=0.001659 prune=0
2017/08/30 20:46:40 step 0: objective=0.132464 reg=0.001659
2017/08/30 20:46:42 step 1: objective=0.132534 reg=0.001659
2017/08/30 20:46:44 step 2: objective=0.132620 reg=0.001658
2017/08/30 20:46:46 step 3: objective=0.132717 reg=0.001659
2017/08/30 20:46:47 step 4: objective=0.132793 reg=0.001658
2017/08/30 20:46:49 step 5: objective=0.132869 reg=0.001659
2017/08/30 20:46:51 step 6: objective=0.132898 reg=0.001659
2017/08/30 20:46:53 step 7: objective=0.132958 reg=0.001659
2017/08/30 20:46:53 Training value function...
2017/08/30 20:46:56 step 0: mse=0.204117 step=0.050000
2017/08/30 20:46:58 step 1: mse=0.204165 step=0.050000
2017/08/30 20:46:59 step 2: mse=0.204137 step=0.050000
2017/08/30 20:47:01 step 3: mse=0.203712 step=0.050000
2017/08/30 20:47:02 step 4: mse=0.203605 step=0.050000
2017/08/30 20:47:04 step 5: mse=0.203381 step=0.050000
2017/08/30 20:47:05 step 6: mse=0.203163 step=0.050000
2017/08/30 20:47:07 step 7: mse=0.202951 step=0.050000
2017/08/30 20:47:07 Saving...
2017/08/30 20:47:07 Gathering batch of experience...
2017/08/30 20:47:49 batch 523: mean=29.421053 stddev=14.564975 entropy=0.163403 frames=8623 count=19
2017/08/30 20:47:49 Training policy...
2017/08/30 20:47:55 tune 0: objective=0.129684 reg=0.001634 prune=0
2017/08/30 20:47:57 step 0: objective=0.129685 reg=0.001634
2017/08/30 20:47:59 step 1: objective=0.129750 reg=0.001634
2017/08/30 20:48:01 step 2: objective=0.129817 reg=0.001635
2017/08/30 20:48:03 step 3: objective=0.129901 reg=0.001635
2017/08/30 20:48:05 step 4: objective=0.129991 reg=0.001635
2017/08/30 20:48:06 step 5: objective=0.130064 reg=0.001635
2017/08/30 20:48:08 step 6: objective=0.130140 reg=0.001636
2017/08/30 20:48:10 step 7: objective=0.130224 reg=0.001635
2017/08/30 20:48:10 Training value function...
2017/08/30 20:48:14 step 0: mse=0.202305 step=0.050000
2017/08/30 20:48:15 step 1: mse=0.202096 step=0.050000
2017/08/30 20:48:17 step 2: mse=0.202253 step=0.050000
2017/08/30 20:48:18 step 3: mse=0.202122 step=0.050000
2017/08/30 20:48:20 step 4: mse=0.201923 step=0.050000
2017/08/30 20:48:22 step 5: mse=0.201772 step=0.050000
2017/08/30 20:48:23 step 6: mse=0.201878 step=0.050000
2017/08/30 20:48:25 step 7: mse=0.201731 step=0.050000
2017/08/30 20:48:25 Saving...
2017/08/30 20:48:25 Gathering batch of experience...
2017/08/30 20:49:06 batch 524: mean=38.714286 stddev=1.030158 entropy=0.162726 frames=8339 count=14
2017/08/30 20:49:06 Training policy...
2017/08/30 20:49:12 tune 0: objective=0.139018 reg=0.001627 prune=0
2017/08/30 20:49:14 step 0: objective=0.139018 reg=0.001627
2017/08/30 20:49:16 step 1: objective=0.139095 reg=0.001627
2017/08/30 20:49:17 step 2: objective=0.139137 reg=0.001627
2017/08/30 20:49:19 step 3: objective=0.139212 reg=0.001627
2017/08/30 20:49:21 step 4: objective=0.139265 reg=0.001628
2017/08/30 20:49:23 step 5: objective=0.139311 reg=0.001627
2017/08/30 20:49:25 step 6: objective=0.139357 reg=0.001627
2017/08/30 20:49:26 step 7: objective=0.139393 reg=0.001627
2017/08/30 20:49:26 Training value function...
2017/08/30 20:49:30 step 0: mse=0.194586 step=0.050000
2017/08/30 20:49:31 step 1: mse=0.193746 step=0.050000
2017/08/30 20:49:33 step 2: mse=0.192772 step=0.050000
2017/08/30 20:49:34 step 3: mse=0.191605 step=0.050000
2017/08/30 20:49:36 step 4: mse=0.190758 step=0.050000
2017/08/30 20:49:37 step 5: mse=0.190096 step=0.050000
2017/08/30 20:49:39 step 6: mse=0.189139 step=0.050000
2017/08/30 20:49:40 step 7: mse=0.188553 step=0.050000
2017/08/30 20:49:40 Saving...
2017/08/30 20:49:40 Gathering batch of experience...
2017/08/30 20:50:22 batch 525: mean=27.210526 stddev=13.983370 entropy=0.161057 frames=8047 count=19
2017/08/30 20:50:22 Training policy...
2017/08/30 20:50:28 tune 0: objective=0.111112 reg=0.001611 prune=0
2017/08/30 20:50:30 step 0: objective=0.111113 reg=0.001611
2017/08/30 20:50:32 step 1: objective=0.111233 reg=0.001612
2017/08/30 20:50:33 step 2: objective=0.111324 reg=0.001612
2017/08/30 20:50:35 step 3: objective=0.111428 reg=0.001613
2017/08/30 20:50:37 step 4: objective=0.111513 reg=0.001614
2017/08/30 20:50:39 step 5: objective=0.111586 reg=0.001614
2017/08/30 20:50:40 step 6: objective=0.111641 reg=0.001613
2017/08/30 20:50:42 step 7: objective=0.111705 reg=0.001613
2017/08/30 20:50:42 Training value function...
2017/08/30 20:50:46 step 0: mse=0.212998 step=0.050000
2017/08/30 20:50:47 step 1: mse=0.213853 step=0.050000
2017/08/30 20:50:48 step 2: mse=0.214517 step=0.050000
2017/08/30 20:50:50 step 3: mse=0.215317 step=0.050000
2017/08/30 20:50:51 step 4: mse=0.215962 step=0.050000
2017/08/30 20:50:53 step 5: mse=0.216864 step=0.050000
2017/08/30 20:50:54 step 6: mse=0.217533 step=0.050000
2017/08/30 20:50:55 step 7: mse=0.218068 step=0.050000
2017/08/30 20:50:55 Saving...
2017/08/30 20:50:56 Gathering batch of experience...
2017/08/30 20:51:37 batch 526: mean=30.764706 stddev=12.891080 entropy=0.161777 frames=8085 count=17
2017/08/30 20:51:37 Training policy...
2017/08/30 20:51:43 tune 0: objective=0.132413 reg=0.001618 prune=0
2017/08/30 20:51:45 step 0: objective=0.132413 reg=0.001618
2017/08/30 20:51:47 step 1: objective=0.132478 reg=0.001618
2017/08/30 20:51:48 step 2: objective=0.132519 reg=0.001617
2017/08/30 20:51:50 step 3: objective=0.132656 reg=0.001618
2017/08/30 20:51:52 step 4: objective=0.132722 reg=0.001618
2017/08/30 20:51:54 step 5: objective=0.132801 reg=0.001618
2017/08/30 20:51:55 step 6: objective=0.132861 reg=0.001618
2017/08/30 20:51:57 step 7: objective=0.132961 reg=0.001619
2017/08/30 20:51:57 Training value function...
2017/08/30 20:52:00 step 0: mse=0.212351 step=0.050000
2017/08/30 20:52:02 step 1: mse=0.212153 step=0.050000
2017/08/30 20:52:03 step 2: mse=0.212189 step=0.050000
2017/08/30 20:52:05 step 3: mse=0.212136 step=0.050000
2017/08/30 20:52:06 step 4: mse=0.211866 step=0.050000
2017/08/30 20:52:08 step 5: mse=0.211732 step=0.050000
2017/08/30 20:52:09 step 6: mse=0.211832 step=0.050000
2017/08/30 20:52:10 step 7: mse=0.211888 step=0.050000
2017/08/30 20:52:10 Saving...
2017/08/30 20:52:10 Gathering batch of experience...
2017/08/30 20:52:51 batch 527: mean=34.466667 stddev=8.365538 entropy=0.161735 frames=8014 count=15
2017/08/30 20:52:51 Training policy...
2017/08/30 20:52:56 tune 0: objective=0.130517 reg=0.001617 prune=0
2017/08/30 20:52:58 step 0: objective=0.130517 reg=0.001617
2017/08/30 20:53:00 step 1: objective=0.130648 reg=0.001618
2017/08/30 20:53:02 step 2: objective=0.130802 reg=0.001617
2017/08/30 20:53:03 step 3: objective=0.130893 reg=0.001617
2017/08/30 20:53:05 step 4: objective=0.130966 reg=0.001616
2017/08/30 20:53:07 step 5: objective=0.131050 reg=0.001617
2017/08/30 20:53:09 step 6: objective=0.131126 reg=0.001617
2017/08/30 20:53:10 step 7: objective=0.131200 reg=0.001617
2017/08/30 20:53:10 Training value function...
2017/08/30 20:53:14 step 0: mse=0.210160 step=0.050000
2017/08/30 20:53:15 step 1: mse=0.209910 step=0.050000
2017/08/30 20:53:17 step 2: mse=0.209774 step=0.050000
2017/08/30 20:53:18 step 3: mse=0.209552 step=0.050000
2017/08/30 20:53:19 step 4: mse=0.209238 step=0.050000
2017/08/30 20:53:21 step 5: mse=0.209306 step=0.050000
2017/08/30 20:53:22 step 6: mse=0.209222 step=0.050000
2017/08/30 20:53:24 step 7: mse=0.209150 step=0.050000
2017/08/30 20:53:24 Saving...
2017/08/30 20:53:24 Gathering batch of experience...
2017/08/30 20:54:04 batch 528: mean=32.375000 stddev=10.902265 entropy=0.164747 frames=8032 count=16
2017/08/30 20:54:04 Training policy...
2017/08/30 20:54:09 tune 0: objective=0.129290 reg=0.001647 prune=0
2017/08/30 20:54:11 step 0: objective=0.129290 reg=0.001647
2017/08/30 20:54:13 step 1: objective=0.129340 reg=0.001647
2017/08/30 20:54:15 step 2: objective=0.129410 reg=0.001647
2017/08/30 20:54:16 step 3: objective=0.129544 reg=0.001647
2017/08/30 20:54:18 step 4: objective=0.129639 reg=0.001647
2017/08/30 20:54:20 step 5: objective=0.129679 reg=0.001648
2017/08/30 20:54:22 step 6: objective=0.129710 reg=0.001648
2017/08/30 20:54:23 step 7: objective=0.129782 reg=0.001647
2017/08/30 20:54:23 Training value function...
2017/08/30 20:54:27 step 0: mse=0.211643 step=0.050000
2017/08/30 20:54:28 step 1: mse=0.211772 step=0.050000
2017/08/30 20:54:30 step 2: mse=0.211800 step=0.050000
2017/08/30 20:54:31 step 3: mse=0.211989 step=0.050000
2017/08/30 20:54:32 step 4: mse=0.212032 step=0.050000
2017/08/30 20:54:34 step 5: mse=0.212215 step=0.050000
2017/08/30 20:54:35 step 6: mse=0.212166 step=0.050000
2017/08/30 20:54:37 step 7: mse=0.212438 step=0.050000
2017/08/30 20:54:37 Saving...
2017/08/30 20:54:37 Gathering batch of experience...
2017/08/30 20:55:18 batch 529: mean=33.562500 stddev=10.234554 entropy=0.164879 frames=8289 count=16
2017/08/30 20:55:18 Training policy...
2017/08/30 20:55:24 tune 0: objective=0.135928 reg=0.001649 prune=0
2017/08/30 20:55:26 step 0: objective=0.135929 reg=0.001649
2017/08/30 20:55:28 step 1: objective=0.135998 reg=0.001650
2017/08/30 20:55:29 step 2: objective=0.136078 reg=0.001650
2017/08/30 20:55:31 step 3: objective=0.136162 reg=0.001651
2017/08/30 20:55:33 step 4: objective=0.136242 reg=0.001651
2017/08/30 20:55:35 step 5: objective=0.136292 reg=0.001651
2017/08/30 20:55:37 step 6: objective=0.136389 reg=0.001650
2017/08/30 20:55:38 step 7: objective=0.136485 reg=0.001650
2017/08/30 20:55:38 Training value function...
2017/08/30 20:55:42 step 0: mse=0.207240 step=0.050000
2017/08/30 20:55:43 step 1: mse=0.206183 step=0.050000
2017/08/30 20:55:45 step 2: mse=0.205617 step=0.050000
2017/08/30 20:55:46 step 3: mse=0.204962 step=0.050000
2017/08/30 20:55:48 step 4: mse=0.204348 step=0.050000
2017/08/30 20:55:49 step 5: mse=0.203948 step=0.050000
2017/08/30 20:55:50 step 6: mse=0.203219 step=0.050000
2017/08/30 20:55:52 step 7: mse=0.202760 step=0.050000
2017/08/30 20:55:52 Saving...
2017/08/30 20:55:52 Gathering batch of experience...
2017/08/30 20:56:34 batch 530: mean=34.875000 stddev=10.385537 entropy=0.160286 frames=8613 count=16
2017/08/30 20:56:34 Training policy...
2017/08/30 20:56:40 tune 0: objective=0.136888 reg=0.001603 prune=0
2017/08/30 20:56:42 step 0: objective=0.136888 reg=0.001603
2017/08/30 20:56:44 step 1: objective=0.136990 reg=0.001602
2017/08/30 20:56:46 step 2: objective=0.137064 reg=0.001601
2017/08/30 20:56:48 step 3: objective=0.137174 reg=0.001601
2017/08/30 20:56:49 step 4: objective=0.137235 reg=0.001601
2017/08/30 20:56:51 step 5: objective=0.137289 reg=0.001601
2017/08/30 20:56:53 step 6: objective=0.137345 reg=0.001600
2017/08/30 20:56:55 step 7: objective=0.137401 reg=0.001600
2017/08/30 20:56:55 Training value function...
2017/08/30 20:56:59 step 0: mse=0.207281 step=0.050000
2017/08/30 20:57:00 step 1: mse=0.206618 step=0.050000
2017/08/30 20:57:02 step 2: mse=0.205554 step=0.050000
2017/08/30 20:57:03 step 3: mse=0.204881 step=0.050000
2017/08/30 20:57:05 step 4: mse=0.203799 step=0.050000
2017/08/30 20:57:06 step 5: mse=0.203051 step=0.050000
2017/08/30 20:57:08 step 6: mse=0.202286 step=0.050000
2017/08/30 20:57:09 step 7: mse=0.201523 step=0.050000
2017/08/30 20:57:09 Saving...
2017/08/30 20:57:09 Gathering batch of experience...
2017/08/30 20:57:51 batch 531: mean=34.000000 stddev=10.356158 entropy=0.162217 frames=8403 count=16
2017/08/30 20:57:51 Training policy...
2017/08/30 20:57:57 tune 0: objective=0.132600 reg=0.001622 prune=0
2017/08/30 20:57:59 step 0: objective=0.132600 reg=0.001622
2017/08/30 20:58:00 step 1: objective=0.132678 reg=0.001623
2017/08/30 20:58:02 step 2: objective=0.132729 reg=0.001624
2017/08/30 20:58:04 step 3: objective=0.132790 reg=0.001625
2017/08/30 20:58:06 step 4: objective=0.132849 reg=0.001626
2017/08/30 20:58:08 step 5: objective=0.132889 reg=0.001626
2017/08/30 20:58:09 step 6: objective=0.132936 reg=0.001626
2017/08/30 20:58:11 step 7: objective=0.132990 reg=0.001625
2017/08/30 20:58:11 Training value function...
2017/08/30 20:58:15 step 0: mse=0.203275 step=0.050000
2017/08/30 20:58:16 step 1: mse=0.202484 step=0.050000
2017/08/30 20:58:18 step 2: mse=0.202266 step=0.050000
2017/08/30 20:58:19 step 3: mse=0.201770 step=0.050000
2017/08/30 20:58:21 step 4: mse=0.201636 step=0.050000
2017/08/30 20:58:22 step 5: mse=0.201167 step=0.050000
2017/08/30 20:58:24 step 6: mse=0.200896 step=0.050000
2017/08/30 20:58:25 step 7: mse=0.200532 step=0.050000
2017/08/30 20:58:25 Saving...
2017/08/30 20:58:25 Gathering batch of experience...
2017/08/30 20:59:06 batch 532: mean=35.466667 stddev=8.808077 entropy=0.161030 frames=8215 count=15
2017/08/30 20:59:06 Training policy...
2017/08/30 20:59:12 tune 0: objective=0.132797 reg=0.001610 prune=0
2017/08/30 20:59:14 step 0: objective=0.132797 reg=0.001610
2017/08/30 20:59:16 step 1: objective=0.132849 reg=0.001610
2017/08/30 20:59:17 step 2: objective=0.132904 reg=0.001610
2017/08/30 20:59:19 step 3: objective=0.132963 reg=0.001610
2017/08/30 20:59:21 step 4: objective=0.133025 reg=0.001610
2017/08/30 20:59:23 step 5: objective=0.133060 reg=0.001610
2017/08/30 20:59:25 step 6: objective=0.133125 reg=0.001609
2017/08/30 20:59:26 step 7: objective=0.133170 reg=0.001609
2017/08/30 20:59:26 Training value function...
2017/08/30 20:59:30 step 0: mse=0.198604 step=0.050000
2017/08/30 20:59:31 step 1: mse=0.197874 step=0.050000
2017/08/30 20:59:33 step 2: mse=0.197597 step=0.050000
2017/08/30 20:59:34 step 3: mse=0.197314 step=0.050000
2017/08/30 20:59:35 step 4: mse=0.196778 step=0.050000
2017/08/30 20:59:37 step 5: mse=0.196752 step=0.050000
2017/08/30 20:59:38 step 6: mse=0.196635 step=0.050000
2017/08/30 20:59:40 step 7: mse=0.196468 step=0.050000
2017/08/30 20:59:40 Saving...
2017/08/30 20:59:40 Gathering batch of experience...
2017/08/30 21:00:20 batch 533: mean=33.933333 stddev=9.976417 entropy=0.165469 frames=7873 count=15
2017/08/30 21:00:20 Training policy...
2017/08/30 21:00:25 tune 0: objective=0.129734 reg=0.001655 prune=0
2017/08/30 21:00:27 step 0: objective=0.129735 reg=0.001655
2017/08/30 21:00:29 step 1: objective=0.129827 reg=0.001656
2017/08/30 21:00:30 step 2: objective=0.129900 reg=0.001657
2017/08/30 21:00:32 step 3: objective=0.129999 reg=0.001657
2017/08/30 21:00:34 step 4: objective=0.130073 reg=0.001658
2017/08/30 21:00:36 step 5: objective=0.130139 reg=0.001658
2017/08/30 21:00:37 step 6: objective=0.130226 reg=0.001659
2017/08/30 21:00:39 step 7: objective=0.130291 reg=0.001659
2017/08/30 21:00:39 Training value function...
2017/08/30 21:00:42 step 0: mse=0.197418 step=0.050000
2017/08/30 21:00:44 step 1: mse=0.197150 step=0.050000
2017/08/30 21:00:45 step 2: mse=0.197366 step=0.050000
2017/08/30 21:00:46 step 3: mse=0.196727 step=0.050000
2017/08/30 21:00:48 step 4: mse=0.196977 step=0.050000
2017/08/30 21:00:49 step 5: mse=0.197048 step=0.050000
2017/08/30 21:00:51 step 6: mse=0.196989 step=0.050000
2017/08/30 21:00:52 step 7: mse=0.197155 step=0.050000
2017/08/30 21:00:52 Saving...
2017/08/30 21:00:52 Gathering batch of experience...
2017/08/30 21:01:32 batch 534: mean=36.785714 stddev=7.983721 entropy=0.162958 frames=7935 count=14
2017/08/30 21:01:32 Training policy...
2017/08/30 21:01:38 tune 0: objective=0.138270 reg=0.001630 prune=0
2017/08/30 21:01:40 step 0: objective=0.138270 reg=0.001630
2017/08/30 21:01:41 step 1: objective=0.138337 reg=0.001630
2017/08/30 21:01:43 step 2: objective=0.138405 reg=0.001631
2017/08/30 21:01:45 step 3: objective=0.138493 reg=0.001632
2017/08/30 21:01:47 step 4: objective=0.138521 reg=0.001632
2017/08/30 21:01:48 step 5: objective=0.138565 reg=0.001632
2017/08/30 21:01:50 step 6: objective=0.138602 reg=0.001633
2017/08/30 21:01:52 step 7: objective=0.138705 reg=0.001633
2017/08/30 21:01:52 Training value function...
2017/08/30 21:01:55 step 0: mse=0.197603 step=0.050000
2017/08/30 21:01:56 step 1: mse=0.196565 step=0.050000
2017/08/30 21:01:58 step 2: mse=0.195799 step=0.050000
2017/08/30 21:01:59 step 3: mse=0.194866 step=0.050000
2017/08/30 21:02:01 step 4: mse=0.194141 step=0.050000
2017/08/30 21:02:02 step 5: mse=0.193525 step=0.050000
2017/08/30 21:02:03 step 6: mse=0.192505 step=0.050000
2017/08/30 21:02:05 step 7: mse=0.191699 step=0.050000
2017/08/30 21:02:05 Saving...
2017/08/30 21:02:05 Gathering batch of experience...
2017/08/30 21:02:47 batch 535: mean=34.625000 stddev=8.462232 entropy=0.161450 frames=8546 count=16
2017/08/30 21:02:47 Training policy...
2017/08/30 21:02:53 tune 0: objective=0.129771 reg=0.001614 prune=0
2017/08/30 21:02:55 step 0: objective=0.129772 reg=0.001614
2017/08/30 21:02:56 step 1: objective=0.129854 reg=0.001615
2017/08/30 21:02:58 step 2: objective=0.129950 reg=0.001615
2017/08/30 21:03:00 step 3: objective=0.130029 reg=0.001616
2017/08/30 21:03:02 step 4: objective=0.130134 reg=0.001617
2017/08/30 21:03:04 step 5: objective=0.130231 reg=0.001616
2017/08/30 21:03:06 step 6: objective=0.130288 reg=0.001617
2017/08/30 21:03:08 step 7: objective=0.130354 reg=0.001616
2017/08/30 21:03:08 Training value function...
2017/08/30 21:03:11 step 0: mse=0.192651 step=0.050000
2017/08/30 21:03:13 step 1: mse=0.192562 step=0.050000
2017/08/30 21:03:14 step 2: mse=0.192471 step=0.050000
2017/08/30 21:03:16 step 3: mse=0.192714 step=0.050000
2017/08/30 21:03:17 step 4: mse=0.192432 step=0.050000
2017/08/30 21:03:18 step 5: mse=0.192290 step=0.050000
2017/08/30 21:03:20 step 6: mse=0.192075 step=0.050000
2017/08/30 21:03:21 step 7: mse=0.192144 step=0.050000
2017/08/30 21:03:21 Saving...
2017/08/30 21:03:21 Gathering batch of experience...
2017/08/30 21:04:02 batch 536: mean=34.400000 stddev=8.623998 entropy=0.166065 frames=7964 count=15
2017/08/30 21:04:02 Training policy...
2017/08/30 21:04:07 tune 0: objective=0.128634 reg=0.001661 prune=0
2017/08/30 21:04:09 step 0: objective=0.128634 reg=0.001661
2017/08/30 21:04:11 step 1: objective=0.128710 reg=0.001661
2017/08/30 21:04:13 step 2: objective=0.128760 reg=0.001661
2017/08/30 21:04:14 step 3: objective=0.128825 reg=0.001662
2017/08/30 21:04:16 step 4: objective=0.128903 reg=0.001662
2017/08/30 21:04:18 step 5: objective=0.128957 reg=0.001662
2017/08/30 21:04:20 step 6: objective=0.128998 reg=0.001662
2017/08/30 21:04:21 step 7: objective=0.129044 reg=0.001663
2017/08/30 21:04:21 Training value function...
2017/08/30 21:04:25 step 0: mse=0.192824 step=0.050000
2017/08/30 21:04:26 step 1: mse=0.193064 step=0.050000
2017/08/30 21:04:28 step 2: mse=0.193082 step=0.050000
2017/08/30 21:04:29 step 3: mse=0.193524 step=0.050000
2017/08/30 21:04:30 step 4: mse=0.193620 step=0.050000
2017/08/30 21:04:32 step 5: mse=0.193683 step=0.050000
2017/08/30 21:04:33 step 6: mse=0.193948 step=0.050000
2017/08/30 21:04:35 step 7: mse=0.194319 step=0.050000
2017/08/30 21:04:35 Saving...
2017/08/30 21:04:35 Gathering batch of experience...
2017/08/30 21:05:17 batch 537: mean=27.368421 stddev=15.228818 entropy=0.166250 frames=8046 count=19
2017/08/30 21:05:17 Training policy...
2017/08/30 21:05:23 tune 0: objective=0.120607 reg=0.001662 prune=0
2017/08/30 21:05:25 step 0: objective=0.120608 reg=0.001663
2017/08/30 21:05:26 step 1: objective=0.120677 reg=0.001663
2017/08/30 21:05:28 step 2: objective=0.120752 reg=0.001664
2017/08/30 21:05:30 step 3: objective=0.120842 reg=0.001664
2017/08/30 21:05:32 step 4: objective=0.120907 reg=0.001665
2017/08/30 21:05:33 step 5: objective=0.121009 reg=0.001665
2017/08/30 21:05:35 step 6: objective=0.121068 reg=0.001665
2017/08/30 21:05:37 step 7: objective=0.121107 reg=0.001665
2017/08/30 21:05:37 Training value function...
2017/08/30 21:05:40 step 0: mse=0.199898 step=0.050000
2017/08/30 21:05:42 step 1: mse=0.200312 step=0.050000
2017/08/30 21:05:43 step 2: mse=0.200613 step=0.050000
2017/08/30 21:05:45 step 3: mse=0.201141 step=0.050000
2017/08/30 21:05:46 step 4: mse=0.201674 step=0.050000
2017/08/30 21:05:47 step 5: mse=0.202187 step=0.050000
2017/08/30 21:05:49 step 6: mse=0.202639 step=0.050000
2017/08/30 21:05:50 step 7: mse=0.202929 step=0.050000
2017/08/30 21:05:50 Saving...
2017/08/30 21:05:50 Gathering batch of experience...
2017/08/30 21:06:31 batch 538: mean=37.357143 stddev=4.922356 entropy=0.157790 frames=8062 count=14
2017/08/30 21:06:31 Training policy...
2017/08/30 21:06:37 tune 0: objective=0.138916 reg=0.001578 prune=0
2017/08/30 21:06:38 step 0: objective=0.138916 reg=0.001578
2017/08/30 21:06:40 step 1: objective=0.138991 reg=0.001578
2017/08/30 21:06:42 step 2: objective=0.139079 reg=0.001578
2017/08/30 21:06:44 step 3: objective=0.139156 reg=0.001578
2017/08/30 21:06:45 step 4: objective=0.139239 reg=0.001579
2017/08/30 21:06:47 step 5: objective=0.139300 reg=0.001579
2017/08/30 21:06:49 step 6: objective=0.139397 reg=0.001579
2017/08/30 21:06:51 step 7: objective=0.139482 reg=0.001579
2017/08/30 21:06:51 Training value function...
2017/08/30 21:06:54 step 0: mse=0.199511 step=0.050000
2017/08/30 21:06:56 step 1: mse=0.198138 step=0.050000
2017/08/30 21:06:57 step 2: mse=0.196552 step=0.050000
2017/08/30 21:06:58 step 3: mse=0.195606 step=0.050000
2017/08/30 21:07:00 step 4: mse=0.194383 step=0.050000
2017/08/30 21:07:01 step 5: mse=0.193293 step=0.050000
2017/08/30 21:07:02 step 6: mse=0.192341 step=0.050000
2017/08/30 21:07:04 step 7: mse=0.191407 step=0.050000
2017/08/30 21:07:04 Saving...
2017/08/30 21:07:04 Gathering batch of experience...
2017/08/30 21:07:45 batch 539: mean=33.250000 stddev=10.158125 entropy=0.161774 frames=8233 count=16
2017/08/30 21:07:45 Training policy...
2017/08/30 21:07:51 tune 0: objective=0.127020 reg=0.001618 prune=0
2017/08/30 21:07:53 step 0: objective=0.127020 reg=0.001618
2017/08/30 21:07:54 step 1: objective=0.127079 reg=0.001616
2017/08/30 21:07:56 step 2: objective=0.127191 reg=0.001615
2017/08/30 21:07:58 step 3: objective=0.127268 reg=0.001616
2017/08/30 21:08:00 step 4: objective=0.127327 reg=0.001614
2017/08/30 21:08:02 step 5: objective=0.127503 reg=0.001615
2017/08/30 21:08:03 step 6: objective=0.127580 reg=0.001614
2017/08/30 21:08:05 step 7: objective=0.127654 reg=0.001614
2017/08/30 21:08:05 Training value function...
2017/08/30 21:08:09 step 0: mse=0.203196 step=0.050000
2017/08/30 21:08:10 step 1: mse=0.202862 step=0.050000
2017/08/30 21:08:11 step 2: mse=0.203281 step=0.050000
2017/08/30 21:08:13 step 3: mse=0.203224 step=0.050000
2017/08/30 21:08:14 step 4: mse=0.203401 step=0.050000
2017/08/30 21:08:16 step 5: mse=0.203082 step=0.050000
2017/08/30 21:08:17 step 6: mse=0.203370 step=0.050000
2017/08/30 21:08:19 step 7: mse=0.203270 step=0.050000
2017/08/30 21:08:19 Saving...
2017/08/30 21:08:19 Gathering batch of experience...
2017/08/30 21:09:03 batch 540: mean=29.166667 stddev=12.623831 entropy=0.163106 frames=8129 count=18
2017/08/30 21:09:03 Training policy...
2017/08/30 21:09:09 tune 0: objective=0.122820 reg=0.001631 prune=0
2017/08/30 21:09:10 step 0: objective=0.122820 reg=0.001631
2017/08/30 21:09:12 step 1: objective=0.122893 reg=0.001630
2017/08/30 21:09:14 step 2: objective=0.122954 reg=0.001631
2017/08/30 21:09:16 step 3: objective=0.123008 reg=0.001632
2017/08/30 21:09:18 step 4: objective=0.123060 reg=0.001632
2017/08/30 21:09:19 step 5: objective=0.123111 reg=0.001632
2017/08/30 21:09:21 step 6: objective=0.123195 reg=0.001632
2017/08/30 21:09:23 step 7: objective=0.123264 reg=0.001631
2017/08/30 21:09:23 Training value function...
2017/08/30 21:09:26 step 0: mse=0.201092 step=0.050000
2017/08/30 21:09:28 step 1: mse=0.201829 step=0.050000
2017/08/30 21:09:29 step 2: mse=0.202563 step=0.050000
2017/08/30 21:09:31 step 3: mse=0.203170 step=0.050000
2017/08/30 21:09:32 step 4: mse=0.203726 step=0.050000
2017/08/30 21:09:34 step 5: mse=0.204397 step=0.050000
2017/08/30 21:09:35 step 6: mse=0.204959 step=0.050000
2017/08/30 21:09:36 step 7: mse=0.205555 step=0.050000
2017/08/30 21:09:36 Saving...
2017/08/30 21:09:36 Gathering batch of experience...
2017/08/30 21:10:18 batch 541: mean=35.866667 stddev=6.781019 entropy=0.161874 frames=8303 count=15
2017/08/30 21:10:18 Training policy...
2017/08/30 21:10:24 tune 0: objective=0.137457 reg=0.001619 prune=0
2017/08/30 21:10:26 step 0: objective=0.137457 reg=0.001619
2017/08/30 21:10:27 step 1: objective=0.137538 reg=0.001620
2017/08/30 21:10:29 step 2: objective=0.137625 reg=0.001620
2017/08/30 21:10:31 step 3: objective=0.137660 reg=0.001620
2017/08/30 21:10:33 step 4: objective=0.137737 reg=0.001621
2017/08/30 21:10:35 step 5: objective=0.137802 reg=0.001621
2017/08/30 21:10:37 step 6: objective=0.137865 reg=0.001621
2017/08/30 21:10:38 step 7: objective=0.137907 reg=0.001621
2017/08/30 21:10:38 Training value function...
2017/08/30 21:10:42 step 0: mse=0.206238 step=0.050000
2017/08/30 21:10:43 step 1: mse=0.205399 step=0.050000
2017/08/30 21:10:45 step 2: mse=0.204308 step=0.050000
2017/08/30 21:10:46 step 3: mse=0.203466 step=0.050000
2017/08/30 21:10:48 step 4: mse=0.202402 step=0.050000
2017/08/30 21:10:49 step 5: mse=0.201605 step=0.050000
2017/08/30 21:10:50 step 6: mse=0.200710 step=0.050000
2017/08/30 21:10:52 step 7: mse=0.200197 step=0.050000
2017/08/30 21:10:52 Saving...
2017/08/30 21:10:52 Gathering batch of experience...
2017/08/30 21:11:32 batch 542: mean=31.500000 stddev=10.810874 entropy=0.166829 frames=7839 count=16
2017/08/30 21:11:32 Training policy...
2017/08/30 21:11:37 tune 0: objective=0.119749 reg=0.001668 prune=0
2017/08/30 21:11:39 step 0: objective=0.119749 reg=0.001668
2017/08/30 21:11:41 step 1: objective=0.119830 reg=0.001669
2017/08/30 21:11:42 step 2: objective=0.119923 reg=0.001669
2017/08/30 21:11:44 step 3: objective=0.119993 reg=0.001669
2017/08/30 21:11:46 step 4: objective=0.120066 reg=0.001670
2017/08/30 21:11:48 step 5: objective=0.120107 reg=0.001670
2017/08/30 21:11:49 step 6: objective=0.120163 reg=0.001669
2017/08/30 21:11:51 step 7: objective=0.120218 reg=0.001669
2017/08/30 21:11:51 Training value function...
2017/08/30 21:11:54 step 0: mse=0.207116 step=0.050000
2017/08/30 21:11:56 step 1: mse=0.207209 step=0.050000
2017/08/30 21:11:57 step 2: mse=0.207682 step=0.050000
2017/08/30 21:11:59 step 3: mse=0.207825 step=0.050000
2017/08/30 21:12:00 step 4: mse=0.208083 step=0.050000
2017/08/30 21:12:01 step 5: mse=0.208348 step=0.050000
2017/08/30 21:12:03 step 6: mse=0.208793 step=0.050000
2017/08/30 21:12:04 step 7: mse=0.209040 step=0.050000
2017/08/30 21:12:04 Saving...
2017/08/30 21:12:04 Gathering batch of experience...
2017/08/30 21:12:46 batch 543: mean=33.750000 stddev=9.845684 entropy=0.165789 frames=8368 count=16
2017/08/30 21:12:46 Training policy...
2017/08/30 21:12:52 tune 0: objective=0.134085 reg=0.001658 prune=0
2017/08/30 21:12:53 step 0: objective=0.134085 reg=0.001658
2017/08/30 21:12:55 step 1: objective=0.134140 reg=0.001658
2017/08/30 21:12:57 step 2: objective=0.134183 reg=0.001657
2017/08/30 21:12:59 step 3: objective=0.134263 reg=0.001657
2017/08/30 21:13:01 step 4: objective=0.134336 reg=0.001656
2017/08/30 21:13:03 step 5: objective=0.134427 reg=0.001656
2017/08/30 21:13:04 step 6: objective=0.134468 reg=0.001655
2017/08/30 21:13:06 step 7: objective=0.134554 reg=0.001655
2017/08/30 21:13:06 Training value function...
2017/08/30 21:13:10 step 0: mse=0.210020 step=0.050000
2017/08/30 21:13:11 step 1: mse=0.209705 step=0.050000
2017/08/30 21:13:13 step 2: mse=0.209386 step=0.050000
2017/08/30 21:13:14 step 3: mse=0.209172 step=0.050000
2017/08/30 21:13:16 step 4: mse=0.208655 step=0.050000
2017/08/30 21:13:17 step 5: mse=0.208433 step=0.050000
2017/08/30 21:13:18 step 6: mse=0.208058 step=0.050000
2017/08/30 21:13:20 step 7: mse=0.208007 step=0.050000
2017/08/30 21:13:20 Saving...
2017/08/30 21:13:20 Gathering batch of experience...
2017/08/30 21:14:02 batch 544: mean=30.055556 stddev=12.743069 entropy=0.162110 frames=8369 count=18
2017/08/30 21:14:02 Training policy...
2017/08/30 21:14:08 tune 0: objective=0.130764 reg=0.001621 prune=0
2017/08/30 21:14:09 step 0: objective=0.130764 reg=0.001621
2017/08/30 21:14:11 step 1: objective=0.130834 reg=0.001621
2017/08/30 21:14:13 step 2: objective=0.130983 reg=0.001620
2017/08/30 21:14:15 step 3: objective=0.131098 reg=0.001621
2017/08/30 21:14:17 step 4: objective=0.131263 reg=0.001622
2017/08/30 21:14:19 step 5: objective=0.131307 reg=0.001622
2017/08/30 21:14:21 step 6: objective=0.131362 reg=0.001622
2017/08/30 21:14:22 step 7: objective=0.131403 reg=0.001622
2017/08/30 21:14:22 Training value function...
2017/08/30 21:14:26 step 0: mse=0.206146 step=0.050000
2017/08/30 21:14:27 step 1: mse=0.206125 step=0.050000
2017/08/30 21:14:29 step 2: mse=0.206122 step=0.050000
2017/08/30 21:14:30 step 3: mse=0.206142 step=0.050000
2017/08/30 21:14:32 step 4: mse=0.205964 step=0.050000
2017/08/30 21:14:33 step 5: mse=0.206080 step=0.050000
2017/08/30 21:14:35 step 6: mse=0.205988 step=0.050000
2017/08/30 21:14:36 step 7: mse=0.206066 step=0.050000
2017/08/30 21:14:36 Saving...
2017/08/30 21:14:36 Gathering batch of experience...
2017/08/30 21:15:15 batch 545: mean=32.733333 stddev=12.693655 entropy=0.157447 frames=7563 count=15
2017/08/30 21:15:15 Training policy...
2017/08/30 21:15:21 tune 0: objective=0.138064 reg=0.001574 prune=0
2017/08/30 21:15:22 step 0: objective=0.138064 reg=0.001574
2017/08/30 21:15:24 step 1: objective=0.138117 reg=0.001575
2017/08/30 21:15:26 step 2: objective=0.138156 reg=0.001575
2017/08/30 21:15:27 step 3: objective=0.138233 reg=0.001574
2017/08/30 21:15:29 step 4: objective=0.138288 reg=0.001575
2017/08/30 21:15:31 step 5: objective=0.138338 reg=0.001575
2017/08/30 21:15:32 step 6: objective=0.138371 reg=0.001575
2017/08/30 21:15:34 step 7: objective=0.138427 reg=0.001575
2017/08/30 21:15:34 Training value function...
2017/08/30 21:15:37 step 0: mse=0.204661 step=0.050000
2017/08/30 21:15:38 step 1: mse=0.203595 step=0.050000
2017/08/30 21:15:40 step 2: mse=0.202240 step=0.050000
2017/08/30 21:15:41 step 3: mse=0.201315 step=0.050000
2017/08/30 21:15:42 step 4: mse=0.200712 step=0.050000
2017/08/30 21:15:44 step 5: mse=0.199962 step=0.050000
2017/08/30 21:15:45 step 6: mse=0.199145 step=0.050000
2017/08/30 21:15:46 step 7: mse=0.198727 step=0.050000
2017/08/30 21:15:46 Saving...
2017/08/30 21:15:46 Gathering batch of experience...
2017/08/30 21:16:28 batch 546: mean=36.066667 stddev=7.523002 entropy=0.162033 frames=8359 count=15
2017/08/30 21:16:28 Training policy...
2017/08/30 21:16:34 tune 0: objective=0.135058 reg=0.001620 prune=0
2017/08/30 21:16:35 step 0: objective=0.135058 reg=0.001620
2017/08/30 21:16:37 step 1: objective=0.135131 reg=0.001621
2017/08/30 21:16:39 step 2: objective=0.135207 reg=0.001621
2017/08/30 21:16:41 step 3: objective=0.135253 reg=0.001621
2017/08/30 21:16:43 step 4: objective=0.135329 reg=0.001621
2017/08/30 21:16:45 step 5: objective=0.135388 reg=0.001621
2017/08/30 21:16:47 step 6: objective=0.135453 reg=0.001621
2017/08/30 21:16:48 step 7: objective=0.135563 reg=0.001621
2017/08/30 21:16:48 Training value function...
2017/08/30 21:16:52 step 0: mse=0.204110 step=0.050000
2017/08/30 21:16:53 step 1: mse=0.203154 step=0.050000
2017/08/30 21:16:55 step 2: mse=0.202484 step=0.050000
2017/08/30 21:16:56 step 3: mse=0.201865 step=0.050000
2017/08/30 21:16:58 step 4: mse=0.201126 step=0.050000
2017/08/30 21:16:59 step 5: mse=0.200579 step=0.050000
2017/08/30 21:17:01 step 6: mse=0.200111 step=0.050000
2017/08/30 21:17:02 step 7: mse=0.199184 step=0.050000
2017/08/30 21:17:02 Saving...
2017/08/30 21:17:02 Gathering batch of experience...
2017/08/30 21:17:43 batch 547: mean=33.250000 stddev=11.934718 entropy=0.161537 frames=8208 count=16
2017/08/30 21:17:43 Training policy...
2017/08/30 21:17:49 tune 0: objective=0.133438 reg=0.001615 prune=0
2017/08/30 21:17:51 step 0: objective=0.133438 reg=0.001615
2017/08/30 21:17:53 step 1: objective=0.133481 reg=0.001615
2017/08/30 21:17:54 step 2: objective=0.133541 reg=0.001615
2017/08/30 21:17:56 step 3: objective=0.133629 reg=0.001615
2017/08/30 21:17:58 step 4: objective=0.133676 reg=0.001615
2017/08/30 21:18:00 step 5: objective=0.133710 reg=0.001615
2017/08/30 21:18:02 step 6: objective=0.133766 reg=0.001614
2017/08/30 21:18:03 step 7: objective=0.133815 reg=0.001615
2017/08/30 21:18:03 Training value function...
2017/08/30 21:18:07 step 0: mse=0.197214 step=0.050000
2017/08/30 21:18:08 step 1: mse=0.196599 step=0.050000
2017/08/30 21:18:10 step 2: mse=0.196084 step=0.050000
2017/08/30 21:18:11 step 3: mse=0.195460 step=0.050000
2017/08/30 21:18:13 step 4: mse=0.194805 step=0.050000
2017/08/30 21:18:14 step 5: mse=0.194448 step=0.050000
2017/08/30 21:18:16 step 6: mse=0.194363 step=0.050000
2017/08/30 21:18:17 step 7: mse=0.194296 step=0.050000
2017/08/30 21:18:17 Saving...
2017/08/30 21:18:17 Gathering batch of experience...
2017/08/30 21:18:57 batch 548: mean=31.750000 stddev=11.404495 entropy=0.164639 frames=7871 count=16
2017/08/30 21:18:57 Training policy...
2017/08/30 21:19:02 tune 0: objective=0.124338 reg=0.001646 prune=0
2017/08/30 21:19:04 step 0: objective=0.124338 reg=0.001646
2017/08/30 21:19:06 step 1: objective=0.124443 reg=0.001646
2017/08/30 21:19:08 step 2: objective=0.124530 reg=0.001648
2017/08/30 21:19:09 step 3: objective=0.124586 reg=0.001648
2017/08/30 21:19:11 step 4: objective=0.124642 reg=0.001648
2017/08/30 21:19:13 step 5: objective=0.124705 reg=0.001648
2017/08/30 21:19:15 step 6: objective=0.124759 reg=0.001648
2017/08/30 21:19:16 step 7: objective=0.124802 reg=0.001648
2017/08/30 21:19:16 Training value function...
2017/08/30 21:19:20 step 0: mse=0.200252 step=0.050000
2017/08/30 21:19:21 step 1: mse=0.200769 step=0.050000
2017/08/30 21:19:22 step 2: mse=0.201435 step=0.050000
2017/08/30 21:19:24 step 3: mse=0.202008 step=0.050000
2017/08/30 21:19:25 step 4: mse=0.202517 step=0.050000
2017/08/30 21:19:27 step 5: mse=0.203142 step=0.050000
2017/08/30 21:19:28 step 6: mse=0.203531 step=0.050000
2017/08/30 21:19:29 step 7: mse=0.203958 step=0.050000
2017/08/30 21:19:29 Saving...
2017/08/30 21:19:29 Gathering batch of experience...
2017/08/30 21:20:11 batch 549: mean=37.266667 stddev=3.549022 entropy=0.162135 frames=8615 count=15
2017/08/30 21:20:11 Training policy...
2017/08/30 21:20:18 tune 0: objective=0.137662 reg=0.001621 prune=0
2017/08/30 21:20:20 step 0: objective=0.137662 reg=0.001621
2017/08/30 21:20:22 step 1: objective=0.137715 reg=0.001621
2017/08/30 21:20:23 step 2: objective=0.137777 reg=0.001621
2017/08/30 21:20:25 step 3: objective=0.137831 reg=0.001620
2017/08/30 21:20:27 step 4: objective=0.137906 reg=0.001620
2017/08/30 21:20:29 step 5: objective=0.137952 reg=0.001619
2017/08/30 21:20:31 step 6: objective=0.137996 reg=0.001620
2017/08/30 21:20:33 step 7: objective=0.138025 reg=0.001620
2017/08/30 21:20:33 Training value function...
2017/08/30 21:20:37 step 0: mse=0.197159 step=0.050000
2017/08/30 21:20:38 step 1: mse=0.196532 step=0.050000
2017/08/30 21:20:40 step 2: mse=0.196123 step=0.050000
2017/08/30 21:20:41 step 3: mse=0.195630 step=0.050000
2017/08/30 21:20:43 step 4: mse=0.194648 step=0.050000
2017/08/30 21:20:44 step 5: mse=0.193842 step=0.050000
2017/08/30 21:20:46 step 6: mse=0.192993 step=0.050000
2017/08/30 21:20:47 step 7: mse=0.192321 step=0.050000
2017/08/30 21:20:47 Saving...
2017/08/30 21:20:47 Gathering batch of experience...
2017/08/30 21:21:28 batch 550: mean=30.529412 stddev=11.469231 entropy=0.166748 frames=8027 count=17
2017/08/30 21:21:28 Training policy...
2017/08/30 21:21:34 tune 0: objective=0.122855 reg=0.001667 prune=0
2017/08/30 21:21:36 step 0: objective=0.122855 reg=0.001667
2017/08/30 21:21:37 step 1: objective=0.122935 reg=0.001667
2017/08/30 21:21:39 step 2: objective=0.123033 reg=0.001667
2017/08/30 21:21:41 step 3: objective=0.123095 reg=0.001667
2017/08/30 21:21:43 step 4: objective=0.123137 reg=0.001667
2017/08/30 21:21:44 step 5: objective=0.123203 reg=0.001667
2017/08/30 21:21:46 step 6: objective=0.123274 reg=0.001666
2017/08/30 21:21:48 step 7: objective=0.123313 reg=0.001666
2017/08/30 21:21:48 Training value function...
2017/08/30 21:21:51 step 0: mse=0.196249 step=0.050000
2017/08/30 21:21:53 step 1: mse=0.197005 step=0.050000
2017/08/30 21:21:54 step 2: mse=0.197355 step=0.050000
2017/08/30 21:21:56 step 3: mse=0.197749 step=0.050000
2017/08/30 21:21:57 step 4: mse=0.198265 step=0.050000
2017/08/30 21:21:58 step 5: mse=0.198939 step=0.050000
2017/08/30 21:22:00 step 6: mse=0.199477 step=0.050000
2017/08/30 21:22:01 step 7: mse=0.199732 step=0.050000
2017/08/30 21:22:01 Saving...
2017/08/30 21:22:01 Gathering batch of experience...
2017/08/30 21:22:43 batch 551: mean=33.875000 stddev=11.483004 entropy=0.160529 frames=8383 count=16
2017/08/30 21:22:43 Training policy...
2017/08/30 21:22:49 tune 0: objective=0.133390 reg=0.001605 prune=0
2017/08/30 21:22:51 step 0: objective=0.133390 reg=0.001605
2017/08/30 21:22:53 step 1: objective=0.133463 reg=0.001605
2017/08/30 21:22:54 step 2: objective=0.133548 reg=0.001605
2017/08/30 21:22:56 step 3: objective=0.133642 reg=0.001604
2017/08/30 21:22:58 step 4: objective=0.133716 reg=0.001604
2017/08/30 21:23:00 step 5: objective=0.133799 reg=0.001605
2017/08/30 21:23:02 step 6: objective=0.133837 reg=0.001605
2017/08/30 21:23:04 step 7: objective=0.133895 reg=0.001604
2017/08/30 21:23:04 Training value function...
2017/08/30 21:23:07 step 0: mse=0.205803 step=0.050000
2017/08/30 21:23:09 step 1: mse=0.205321 step=0.050000
2017/08/30 21:23:10 step 2: mse=0.204473 step=0.050000
2017/08/30 21:23:12 step 3: mse=0.203628 step=0.050000
2017/08/30 21:23:13 step 4: mse=0.203101 step=0.050000
2017/08/30 21:23:14 step 5: mse=0.202719 step=0.050000
2017/08/30 21:23:16 step 6: mse=0.202380 step=0.050000
2017/08/30 21:23:17 step 7: mse=0.202158 step=0.050000
2017/08/30 21:23:17 Saving...
2017/08/30 21:23:17 Gathering batch of experience...
2017/08/30 21:23:59 batch 552: mean=32.117647 stddev=12.280460 entropy=0.161850 frames=8417 count=17
2017/08/30 21:23:59 Training policy...
2017/08/30 21:24:05 tune 0: objective=0.132615 reg=0.001619 prune=0
2017/08/30 21:24:07 step 0: objective=0.132616 reg=0.001619
2017/08/30 21:24:09 step 1: objective=0.132711 reg=0.001618
2017/08/30 21:24:11 step 2: objective=0.132772 reg=0.001618
2017/08/30 21:24:13 step 3: objective=0.132847 reg=0.001618
2017/08/30 21:24:15 step 4: objective=0.132953 reg=0.001618
2017/08/30 21:24:17 step 5: objective=0.133021 reg=0.001617
2017/08/30 21:24:18 step 6: objective=0.133092 reg=0.001617
2017/08/30 21:24:20 step 7: objective=0.133150 reg=0.001617
2017/08/30 21:24:20 Training value function...
2017/08/30 21:24:24 step 0: mse=0.195587 step=0.050000
2017/08/30 21:24:25 step 1: mse=0.195452 step=0.050000
2017/08/30 21:24:27 step 2: mse=0.195467 step=0.050000
2017/08/30 21:24:28 step 3: mse=0.195432 step=0.050000
2017/08/30 21:24:30 step 4: mse=0.195463 step=0.050000
2017/08/30 21:24:31 step 5: mse=0.195111 step=0.050000
2017/08/30 21:24:33 step 6: mse=0.195158 step=0.050000
2017/08/30 21:24:34 step 7: mse=0.194914 step=0.050000
2017/08/30 21:24:34 Saving...
2017/08/30 21:24:34 Gathering batch of experience...
2017/08/30 21:25:16 batch 553: mean=36.666667 stddev=6.289321 entropy=0.160638 frames=8486 count=15
2017/08/30 21:25:16 Training policy...
2017/08/30 21:25:22 tune 0: objective=0.135198 reg=0.001606 prune=0
2017/08/30 21:25:24 step 0: objective=0.135199 reg=0.001606
2017/08/30 21:25:26 step 1: objective=0.135269 reg=0.001606
2017/08/30 21:25:28 step 2: objective=0.135314 reg=0.001607
2017/08/30 21:25:30 step 3: objective=0.135405 reg=0.001607
2017/08/30 21:25:32 step 4: objective=0.135531 reg=0.001607
2017/08/30 21:25:33 step 5: objective=0.135624 reg=0.001606
2017/08/30 21:25:35 step 6: objective=0.135676 reg=0.001606
2017/08/30 21:25:37 step 7: objective=0.135727 reg=0.001605
2017/08/30 21:25:37 Training value function...
2017/08/30 21:25:41 step 0: mse=0.194512 step=0.050000
2017/08/30 21:25:42 step 1: mse=0.193846 step=0.050000
2017/08/30 21:25:44 step 2: mse=0.193305 step=0.050000
2017/08/30 21:25:45 step 3: mse=0.192775 step=0.050000
2017/08/30 21:25:47 step 4: mse=0.192315 step=0.050000
2017/08/30 21:25:48 step 5: mse=0.192083 step=0.050000
2017/08/30 21:25:50 step 6: mse=0.191458 step=0.050000
2017/08/30 21:25:51 step 7: mse=0.191091 step=0.050000
2017/08/30 21:25:51 Saving...
2017/08/30 21:25:51 Gathering batch of experience...
2017/08/30 21:26:32 batch 554: mean=33.125000 stddev=11.395586 entropy=0.165100 frames=8189 count=16
2017/08/30 21:26:32 Training policy...
2017/08/30 21:26:38 tune 0: objective=0.130396 reg=0.001651 prune=0
2017/08/30 21:26:40 step 0: objective=0.130395 reg=0.001651
2017/08/30 21:26:41 step 1: objective=0.130492 reg=0.001651
2017/08/30 21:26:43 step 2: objective=0.130586 reg=0.001651
2017/08/30 21:26:45 step 3: objective=0.130678 reg=0.001651
2017/08/30 21:26:47 step 4: objective=0.130754 reg=0.001650
2017/08/30 21:26:49 step 5: objective=0.130816 reg=0.001649
2017/08/30 21:26:50 step 6: objective=0.130904 reg=0.001648
2017/08/30 21:26:52 step 7: objective=0.130961 reg=0.001647
2017/08/30 21:26:52 Training value function...
2017/08/30 21:26:56 step 0: mse=0.197524 step=0.050000
2017/08/30 21:26:57 step 1: mse=0.197756 step=0.050000
2017/08/30 21:26:59 step 2: mse=0.197839 step=0.050000
2017/08/30 21:27:00 step 3: mse=0.198172 step=0.050000
2017/08/30 21:27:01 step 4: mse=0.198329 step=0.050000
2017/08/30 21:27:03 step 5: mse=0.198324 step=0.050000
2017/08/30 21:27:04 step 6: mse=0.198172 step=0.050000
2017/08/30 21:27:06 step 7: mse=0.198444 step=0.050000
2017/08/30 21:27:06 Saving...
2017/08/30 21:27:06 Gathering batch of experience...
2017/08/30 21:27:46 batch 555: mean=34.866667 stddev=8.301539 entropy=0.162095 frames=8060 count=15
2017/08/30 21:27:46 Training policy...
2017/08/30 21:27:52 tune 0: objective=0.133251 reg=0.001621 prune=0
2017/08/30 21:27:54 step 0: objective=0.133251 reg=0.001621
2017/08/30 21:27:56 step 1: objective=0.133322 reg=0.001621
2017/08/30 21:27:57 step 2: objective=0.133366 reg=0.001621
2017/08/30 21:27:59 step 3: objective=0.133432 reg=0.001621
2017/08/30 21:28:01 step 4: objective=0.133519 reg=0.001621
2017/08/30 21:28:03 step 5: objective=0.133621 reg=0.001621
2017/08/30 21:28:04 step 6: objective=0.133749 reg=0.001621
2017/08/30 21:28:06 step 7: objective=0.133806 reg=0.001621
2017/08/30 21:28:06 Training value function...
2017/08/30 21:28:10 step 0: mse=0.194054 step=0.050000
2017/08/30 21:28:11 step 1: mse=0.193307 step=0.050000
2017/08/30 21:28:12 step 2: mse=0.192779 step=0.050000
2017/08/30 21:28:14 step 3: mse=0.192363 step=0.050000
2017/08/30 21:28:15 step 4: mse=0.191863 step=0.050000
2017/08/30 21:28:17 step 5: mse=0.191404 step=0.050000
2017/08/30 21:28:18 step 6: mse=0.190881 step=0.050000
2017/08/30 21:28:19 step 7: mse=0.190817 step=0.050000
2017/08/30 21:28:19 Saving...
2017/08/30 21:28:19 Gathering batch of experience...
2017/08/30 21:29:00 batch 556: mean=30.117647 stddev=12.569255 entropy=0.165999 frames=7925 count=17
2017/08/30 21:29:00 Training policy...
2017/08/30 21:29:05 tune 0: objective=0.121408 reg=0.001660 prune=0
2017/08/30 21:29:07 step 0: objective=0.121407 reg=0.001660
2017/08/30 21:29:09 step 1: objective=0.121453 reg=0.001660
2017/08/30 21:29:11 step 2: objective=0.121521 reg=0.001660
2017/08/30 21:29:12 step 3: objective=0.121610 reg=0.001660
2017/08/30 21:29:14 step 4: objective=0.121688 reg=0.001660
2017/08/30 21:29:16 step 5: objective=0.121752 reg=0.001659
2017/08/30 21:29:18 step 6: objective=0.121816 reg=0.001660
2017/08/30 21:29:19 step 7: objective=0.121860 reg=0.001659
2017/08/30 21:29:19 Training value function...
2017/08/30 21:29:23 step 0: mse=0.198045 step=0.050000
2017/08/30 21:29:24 step 1: mse=0.198750 step=0.050000
2017/08/30 21:29:26 step 2: mse=0.199258 step=0.050000
2017/08/30 21:29:27 step 3: mse=0.200014 step=0.050000
2017/08/30 21:29:28 step 4: mse=0.200720 step=0.050000
2017/08/30 21:29:30 step 5: mse=0.201047 step=0.050000
2017/08/30 21:29:31 step 6: mse=0.201563 step=0.050000
2017/08/30 21:29:33 step 7: mse=0.201923 step=0.050000
2017/08/30 21:29:33 Saving...
2017/08/30 21:29:33 Gathering batch of experience...
2017/08/30 21:30:13 batch 557: mean=35.200000 stddev=7.185170 entropy=0.157952 frames=8150 count=15
2017/08/30 21:30:13 Training policy...
2017/08/30 21:30:19 tune 0: objective=0.134298 reg=0.001580 prune=0
2017/08/30 21:30:21 step 0: objective=0.134297 reg=0.001580
2017/08/30 21:30:23 step 1: objective=0.134384 reg=0.001580
2017/08/30 21:30:25 step 2: objective=0.134446 reg=0.001580
2017/08/30 21:30:27 step 3: objective=0.134502 reg=0.001580
2017/08/30 21:30:28 step 4: objective=0.134597 reg=0.001579
2017/08/30 21:30:30 step 5: objective=0.134646 reg=0.001580
2017/08/30 21:30:32 step 6: objective=0.134762 reg=0.001580
2017/08/30 21:30:34 step 7: objective=0.134805 reg=0.001580
2017/08/30 21:30:34 Training value function...
2017/08/30 21:30:37 step 0: mse=0.201638 step=0.050000
2017/08/30 21:30:39 step 1: mse=0.201023 step=0.050000
2017/08/30 21:30:40 step 2: mse=0.200500 step=0.050000
2017/08/30 21:30:41 step 3: mse=0.200093 step=0.050000
2017/08/30 21:30:43 step 4: mse=0.199382 step=0.050000
2017/08/30 21:30:44 step 5: mse=0.198631 step=0.050000
2017/08/30 21:30:46 step 6: mse=0.198195 step=0.050000
2017/08/30 21:30:47 step 7: mse=0.198109 step=0.050000
2017/08/30 21:30:47 Saving...
2017/08/30 21:30:47 Gathering batch of experience...
2017/08/30 21:31:29 batch 558: mean=39.000000 stddev=0.000000 entropy=0.159235 frames=8400 count=14
2017/08/30 21:31:29 Training policy...
2017/08/30 21:31:35 tune 0: objective=0.143012 reg=0.001592 prune=0
2017/08/30 21:31:37 step 0: objective=0.143012 reg=0.001592
2017/08/30 21:31:39 step 1: objective=0.143072 reg=0.001594
2017/08/30 21:31:41 step 2: objective=0.143148 reg=0.001594
2017/08/30 21:31:43 step 3: objective=0.143207 reg=0.001595
2017/08/30 21:31:44 step 4: objective=0.143268 reg=0.001596
2017/08/30 21:31:46 step 5: objective=0.143332 reg=0.001596
2017/08/30 21:31:48 step 6: objective=0.143383 reg=0.001596
2017/08/30 21:31:50 step 7: objective=0.143407 reg=0.001596
2017/08/30 21:31:50 Training value function...
2017/08/30 21:31:54 step 0: mse=0.196798 step=0.050000
2017/08/30 21:31:55 step 1: mse=0.195015 step=0.050000
2017/08/30 21:31:57 step 2: mse=0.193669 step=0.050000
2017/08/30 21:31:58 step 3: mse=0.192472 step=0.050000
2017/08/30 21:31:59 step 4: mse=0.191641 step=0.050000
2017/08/30 21:32:01 step 5: mse=0.190445 step=0.050000
2017/08/30 21:32:02 step 6: mse=0.189376 step=0.050000
2017/08/30 21:32:04 step 7: mse=0.188379 step=0.050000
2017/08/30 21:32:04 Saving...
2017/08/30 21:32:04 Gathering batch of experience...
2017/08/30 21:32:44 batch 559: mean=31.125000 stddev=10.850547 entropy=0.164082 frames=7710 count=16
2017/08/30 21:32:44 Training policy...
2017/08/30 21:32:49 tune 0: objective=0.119605 reg=0.001641 prune=0
2017/08/30 21:32:51 step 0: objective=0.119605 reg=0.001641
2017/08/30 21:32:53 step 1: objective=0.119673 reg=0.001640
2017/08/30 21:32:54 step 2: objective=0.119801 reg=0.001639
2017/08/30 21:32:56 step 3: objective=0.119906 reg=0.001639
2017/08/30 21:32:58 step 4: objective=0.119963 reg=0.001638
2017/08/30 21:32:59 step 5: objective=0.120037 reg=0.001637
2017/08/30 21:33:01 step 6: objective=0.120086 reg=0.001637
2017/08/30 21:33:03 step 7: objective=0.120205 reg=0.001638
2017/08/30 21:33:03 Training value function...
2017/08/30 21:33:06 step 0: mse=0.196594 step=0.050000
2017/08/30 21:33:08 step 1: mse=0.197353 step=0.050000
2017/08/30 21:33:09 step 2: mse=0.198055 step=0.050000
2017/08/30 21:33:10 step 3: mse=0.198826 step=0.050000
2017/08/30 21:33:12 step 4: mse=0.199485 step=0.050000
2017/08/30 21:33:13 step 5: mse=0.200079 step=0.050000
2017/08/30 21:33:14 step 6: mse=0.200829 step=0.050000
2017/08/30 21:33:16 step 7: mse=0.201519 step=0.050000
2017/08/30 21:33:16 Saving...
2017/08/30 21:33:16 Gathering batch of experience...
2017/08/30 21:33:55 batch 560: mean=33.666667 stddev=11.446494 entropy=0.163269 frames=7783 count=15
2017/08/30 21:33:55 Training policy...
2017/08/30 21:34:01 tune 0: objective=0.135339 reg=0.001633 prune=0
2017/08/30 21:34:03 step 0: objective=0.135339 reg=0.001633
2017/08/30 21:34:05 step 1: objective=0.135386 reg=0.001632
2017/08/30 21:34:06 step 2: objective=0.135454 reg=0.001632
2017/08/30 21:34:08 step 3: objective=0.135512 reg=0.001632
2017/08/30 21:34:10 step 4: objective=0.135573 reg=0.001632
2017/08/30 21:34:11 step 5: objective=0.135633 reg=0.001632
2017/08/30 21:34:13 step 6: objective=0.135671 reg=0.001632
2017/08/30 21:34:15 step 7: objective=0.135715 reg=0.001632
2017/08/30 21:34:15 Training value function...
2017/08/30 21:34:18 step 0: mse=0.200209 step=0.050000
2017/08/30 21:34:20 step 1: mse=0.199341 step=0.050000
2017/08/30 21:34:21 step 2: mse=0.198310 step=0.050000
2017/08/30 21:34:22 step 3: mse=0.197662 step=0.050000
2017/08/30 21:34:24 step 4: mse=0.196902 step=0.050000
2017/08/30 21:34:25 step 5: mse=0.196189 step=0.050000
2017/08/30 21:34:26 step 6: mse=0.195369 step=0.050000
2017/08/30 21:34:28 step 7: mse=0.194718 step=0.050000
2017/08/30 21:34:28 Saving...
2017/08/30 21:34:28 Gathering batch of experience...
2017/08/30 21:35:08 batch 561: mean=34.666667 stddev=10.149986 entropy=0.158931 frames=8035 count=15
2017/08/30 21:35:08 Training policy...
2017/08/30 21:35:14 tune 0: objective=0.132527 reg=0.001589 prune=0
2017/08/30 21:35:16 step 0: objective=0.132527 reg=0.001589
2017/08/30 21:35:17 step 1: objective=0.132609 reg=0.001590
2017/08/30 21:35:19 step 2: objective=0.132677 reg=0.001590
2017/08/30 21:35:21 step 3: objective=0.132742 reg=0.001591
2017/08/30 21:35:23 step 4: objective=0.132807 reg=0.001591
2017/08/30 21:35:25 step 5: objective=0.132880 reg=0.001591
2017/08/30 21:35:26 step 6: objective=0.132987 reg=0.001591
2017/08/30 21:35:28 step 7: objective=0.133013 reg=0.001591
2017/08/30 21:35:28 Training value function...
2017/08/30 21:35:32 step 0: mse=0.199533 step=0.050000
2017/08/30 21:35:33 step 1: mse=0.198954 step=0.050000
2017/08/30 21:35:34 step 2: mse=0.198664 step=0.050000
2017/08/30 21:35:36 step 3: mse=0.198169 step=0.050000
2017/08/30 21:35:37 step 4: mse=0.198125 step=0.050000
2017/08/30 21:35:39 step 5: mse=0.197717 step=0.050000
2017/08/30 21:35:40 step 6: mse=0.197724 step=0.050000
2017/08/30 21:35:41 step 7: mse=0.197620 step=0.050000
2017/08/30 21:35:41 Saving...
2017/08/30 21:35:41 Gathering batch of experience...
2017/08/30 21:36:24 batch 562: mean=27.894737 stddev=13.684008 entropy=0.165835 frames=8238 count=19
2017/08/30 21:36:24 Training policy...
2017/08/30 21:36:30 tune 0: objective=0.115185 reg=0.001658 prune=0
2017/08/30 21:36:32 step 0: objective=0.115185 reg=0.001658
2017/08/30 21:36:34 step 1: objective=0.115289 reg=0.001659
2017/08/30 21:36:36 step 2: objective=0.115395 reg=0.001658
2017/08/30 21:36:37 step 3: objective=0.115498 reg=0.001658
2017/08/30 21:36:39 step 4: objective=0.115565 reg=0.001658
2017/08/30 21:36:41 step 5: objective=0.115627 reg=0.001658
2017/08/30 21:36:43 step 6: objective=0.115689 reg=0.001657
2017/08/30 21:36:45 step 7: objective=0.115770 reg=0.001657
2017/08/30 21:36:45 Training value function...
2017/08/30 21:36:48 step 0: mse=0.207861 step=0.050000
2017/08/30 21:36:50 step 1: mse=0.208686 step=0.050000
2017/08/30 21:36:51 step 2: mse=0.209755 step=0.050000
2017/08/30 21:36:53 step 3: mse=0.210715 step=0.050000
2017/08/30 21:36:54 step 4: mse=0.211648 step=0.050000
2017/08/30 21:36:55 step 5: mse=0.212532 step=0.050000
2017/08/30 21:36:57 step 6: mse=0.213398 step=0.050000
2017/08/30 21:36:58 step 7: mse=0.214177 step=0.050000
2017/08/30 21:36:58 Saving...
2017/08/30 21:36:58 Gathering batch of experience...
2017/08/30 21:37:43 batch 563: mean=33.294118 stddev=10.213974 entropy=0.158924 frames=8749 count=17
2017/08/30 21:37:43 Training policy...
2017/08/30 21:37:49 tune 0: objective=0.133817 reg=0.001589 prune=0
2017/08/30 21:37:51 step 0: objective=0.133817 reg=0.001589
2017/08/30 21:37:53 step 1: objective=0.133900 reg=0.001589
2017/08/30 21:37:55 step 2: objective=0.133985 reg=0.001589
2017/08/30 21:37:57 step 3: objective=0.134044 reg=0.001589
2017/08/30 21:37:59 step 4: objective=0.134108 reg=0.001589
2017/08/30 21:38:01 step 5: objective=0.134150 reg=0.001589
2017/08/30 21:38:03 step 6: objective=0.134242 reg=0.001588
2017/08/30 21:38:05 step 7: objective=0.134293 reg=0.001588
2017/08/30 21:38:05 Training value function...
2017/08/30 21:38:09 step 0: mse=0.206221 step=0.050000
2017/08/30 21:38:10 step 1: mse=0.205993 step=0.050000
2017/08/30 21:38:12 step 2: mse=0.205804 step=0.050000
2017/08/30 21:38:13 step 3: mse=0.205544 step=0.050000
2017/08/30 21:38:15 step 4: mse=0.205102 step=0.050000
2017/08/30 21:38:16 step 5: mse=0.205070 step=0.050000
2017/08/30 21:38:18 step 6: mse=0.204715 step=0.050000
2017/08/30 21:38:19 step 7: mse=0.204657 step=0.050000
2017/08/30 21:38:19 Saving...
2017/08/30 21:38:19 Gathering batch of experience...
2017/08/30 21:39:01 batch 564: mean=30.722222 stddev=12.917712 entropy=0.167887 frames=8551 count=18
2017/08/30 21:39:01 Training policy...
2017/08/30 21:39:08 tune 0: objective=0.130206 reg=0.001679 prune=0
2017/08/30 21:39:10 step 0: objective=0.130206 reg=0.001679
2017/08/30 21:39:11 step 1: objective=0.130280 reg=0.001679
2017/08/30 21:39:13 step 2: objective=0.130316 reg=0.001679
2017/08/30 21:39:15 step 3: objective=0.130359 reg=0.001679
2017/08/30 21:39:17 step 4: objective=0.130404 reg=0.001679
2017/08/30 21:39:19 step 5: objective=0.130439 reg=0.001679
2017/08/30 21:39:21 step 6: objective=0.130476 reg=0.001679
2017/08/30 21:39:23 step 7: objective=0.130518 reg=0.001679
2017/08/30 21:39:23 Training value function...
2017/08/30 21:39:27 step 0: mse=0.205922 step=0.050000
2017/08/30 21:39:28 step 1: mse=0.205947 step=0.050000
2017/08/30 21:39:30 step 2: mse=0.205866 step=0.050000
2017/08/30 21:39:31 step 3: mse=0.205884 step=0.050000
2017/08/30 21:39:33 step 4: mse=0.205745 step=0.050000
2017/08/30 21:39:34 step 5: mse=0.205641 step=0.050000
2017/08/30 21:39:36 step 6: mse=0.205749 step=0.050000
2017/08/30 21:39:37 step 7: mse=0.205566 step=0.050000
2017/08/30 21:39:37 Saving...
2017/08/30 21:39:37 Gathering batch of experience...
2017/08/30 21:40:19 batch 565: mean=34.500000 stddev=8.753571 entropy=0.158859 frames=8523 count=16
2017/08/30 21:40:19 Training policy...
2017/08/30 21:40:25 tune 0: objective=0.134950 reg=0.001589 prune=0
2017/08/30 21:40:27 step 0: objective=0.134951 reg=0.001589
2017/08/30 21:40:29 step 1: objective=0.134987 reg=0.001589
2017/08/30 21:40:31 step 2: objective=0.135055 reg=0.001590
2017/08/30 21:40:33 step 3: objective=0.135089 reg=0.001590
2017/08/30 21:40:35 step 4: objective=0.135152 reg=0.001590
2017/08/30 21:40:36 step 5: objective=0.135201 reg=0.001590
2017/08/30 21:40:38 step 6: objective=0.135256 reg=0.001590
2017/08/30 21:40:40 step 7: objective=0.135303 reg=0.001590
2017/08/30 21:40:40 Training value function...
2017/08/30 21:40:44 step 0: mse=0.205779 step=0.050000
2017/08/30 21:40:45 step 1: mse=0.204756 step=0.050000
2017/08/30 21:40:47 step 2: mse=0.204343 step=0.050000
2017/08/30 21:40:48 step 3: mse=0.203945 step=0.050000
2017/08/30 21:40:50 step 4: mse=0.202991 step=0.050000
2017/08/30 21:40:51 step 5: mse=0.202307 step=0.050000
2017/08/30 21:40:53 step 6: mse=0.201484 step=0.050000
2017/08/30 21:40:54 step 7: mse=0.201092 step=0.050000
2017/08/30 21:40:54 Saving...
2017/08/30 21:40:54 Gathering batch of experience...
2017/08/30 21:41:35 batch 566: mean=35.600000 stddev=7.144228 entropy=0.163179 frames=8238 count=15
2017/08/30 21:41:35 Training policy...
2017/08/30 21:41:41 tune 0: objective=0.135908 reg=0.001632 prune=0
2017/08/30 21:41:43 step 0: objective=0.135908 reg=0.001632
2017/08/30 21:41:45 step 1: objective=0.135990 reg=0.001633
2017/08/30 21:41:47 step 2: objective=0.136066 reg=0.001633
2017/08/30 21:41:49 step 3: objective=0.136119 reg=0.001634
2017/08/30 21:41:51 step 4: objective=0.136175 reg=0.001634
2017/08/30 21:41:52 step 5: objective=0.136226 reg=0.001635
2017/08/30 21:41:54 step 6: objective=0.136279 reg=0.001636
2017/08/30 21:41:56 step 7: objective=0.136338 reg=0.001636
2017/08/30 21:41:56 Training value function...
2017/08/30 21:41:59 step 0: mse=0.198644 step=0.050000
2017/08/30 21:42:01 step 1: mse=0.197741 step=0.050000
2017/08/30 21:42:02 step 2: mse=0.196837 step=0.050000
2017/08/30 21:42:04 step 3: mse=0.196077 step=0.050000
2017/08/30 21:42:05 step 4: mse=0.195289 step=0.050000
2017/08/30 21:42:07 step 5: mse=0.194442 step=0.050000
2017/08/30 21:42:08 step 6: mse=0.193686 step=0.050000
2017/08/30 21:42:09 step 7: mse=0.193240 step=0.050000
2017/08/30 21:42:09 Saving...
2017/08/30 21:42:10 Gathering batch of experience...
2017/08/30 21:42:51 batch 567: mean=36.600000 stddev=8.212186 entropy=0.159992 frames=8458 count=15
2017/08/30 21:42:51 Training policy...
2017/08/30 21:42:57 tune 0: objective=0.137092 reg=0.001600 prune=0
2017/08/30 21:42:59 step 0: objective=0.137092 reg=0.001600
2017/08/30 21:43:01 step 1: objective=0.137164 reg=0.001600
2017/08/30 21:43:03 step 2: objective=0.137238 reg=0.001600
2017/08/30 21:43:05 step 3: objective=0.137299 reg=0.001600
2017/08/30 21:43:07 step 4: objective=0.137348 reg=0.001600
2017/08/30 21:43:09 step 5: objective=0.137384 reg=0.001600
2017/08/30 21:43:11 step 6: objective=0.137436 reg=0.001600
2017/08/30 21:43:13 step 7: objective=0.137501 reg=0.001600
2017/08/30 21:43:13 Training value function...
2017/08/30 21:43:16 step 0: mse=0.190876 step=0.050000
2017/08/30 21:43:18 step 1: mse=0.189732 step=0.050000
2017/08/30 21:43:19 step 2: mse=0.188985 step=0.050000
2017/08/30 21:43:21 step 3: mse=0.188173 step=0.050000
2017/08/30 21:43:22 step 4: mse=0.187239 step=0.050000
2017/08/30 21:43:23 step 5: mse=0.186328 step=0.050000
2017/08/30 21:43:25 step 6: mse=0.185568 step=0.050000
2017/08/30 21:43:26 step 7: mse=0.184895 step=0.050000
2017/08/30 21:43:26 Saving...
2017/08/30 21:43:26 Gathering batch of experience...
2017/08/30 21:44:06 batch 568: mean=28.470588 stddev=12.170928 entropy=0.165674 frames=7483 count=17
2017/08/30 21:44:06 Training policy...
2017/08/30 21:44:11 tune 0: objective=0.117593 reg=0.001657 prune=0
2017/08/30 21:44:13 step 0: objective=0.117593 reg=0.001657
2017/08/30 21:44:15 step 1: objective=0.117651 reg=0.001657
2017/08/30 21:44:16 step 2: objective=0.117723 reg=0.001657
2017/08/30 21:44:18 step 3: objective=0.117769 reg=0.001657
2017/08/30 21:44:20 step 4: objective=0.117855 reg=0.001657
2017/08/30 21:44:21 step 5: objective=0.117939 reg=0.001658
2017/08/30 21:44:23 step 6: objective=0.118000 reg=0.001659
2017/08/30 21:44:25 step 7: objective=0.118022 reg=0.001659
2017/08/30 21:44:25 Training value function...
2017/08/30 21:44:28 step 0: mse=0.186714 step=0.050000
2017/08/30 21:44:29 step 1: mse=0.187682 step=0.050000
2017/08/30 21:44:31 step 2: mse=0.188611 step=0.050000
2017/08/30 21:44:32 step 3: mse=0.189511 step=0.050000
2017/08/30 21:44:33 step 4: mse=0.190531 step=0.050000
2017/08/30 21:44:34 step 5: mse=0.191401 step=0.050000
2017/08/30 21:44:36 step 6: mse=0.192250 step=0.050000
2017/08/30 21:44:37 step 7: mse=0.193027 step=0.050000
2017/08/30 21:44:37 Saving...
2017/08/30 21:44:37 Gathering batch of experience...
2017/08/30 21:45:20 batch 569: mean=35.250000 stddev=9.871044 entropy=0.161209 frames=8694 count=16
2017/08/30 21:45:20 Training policy...
2017/08/30 21:45:26 tune 0: objective=0.138546 reg=0.001612 prune=0
2017/08/30 21:45:28 step 0: objective=0.138546 reg=0.001612
2017/08/30 21:45:30 step 1: objective=0.138633 reg=0.001612
2017/08/30 21:45:32 step 2: objective=0.138734 reg=0.001613
2017/08/30 21:45:34 step 3: objective=0.138843 reg=0.001614
2017/08/30 21:45:36 step 4: objective=0.138899 reg=0.001614
2017/08/30 21:45:38 step 5: objective=0.138932 reg=0.001614
2017/08/30 21:45:40 step 6: objective=0.138987 reg=0.001614
2017/08/30 21:45:42 step 7: objective=0.139071 reg=0.001614
2017/08/30 21:45:42 Training value function...
2017/08/30 21:45:45 step 0: mse=0.196752 step=0.050000
2017/08/30 21:45:47 step 1: mse=0.195766 step=0.050000
2017/08/30 21:45:48 step 2: mse=0.194829 step=0.050000
2017/08/30 21:45:50 step 3: mse=0.193813 step=0.050000
2017/08/30 21:45:51 step 4: mse=0.192988 step=0.050000
2017/08/30 21:45:53 step 5: mse=0.192289 step=0.050000
2017/08/30 21:45:54 step 6: mse=0.191545 step=0.050000
2017/08/30 21:45:56 step 7: mse=0.191027 step=0.050000
2017/08/30 21:45:56 Saving...
2017/08/30 21:45:56 Gathering batch of experience...
2017/08/30 21:46:37 batch 570: mean=35.400000 stddev=8.830251 entropy=0.162547 frames=8181 count=15
2017/08/30 21:46:37 Training policy...
2017/08/30 21:46:43 tune 0: objective=0.134609 reg=0.001625 prune=0
2017/08/30 21:46:44 step 0: objective=0.134610 reg=0.001625
2017/08/30 21:46:46 step 1: objective=0.134657 reg=0.001626
2017/08/30 21:46:48 step 2: objective=0.134696 reg=0.001626
2017/08/30 21:46:50 step 3: objective=0.134747 reg=0.001626
2017/08/30 21:46:52 step 4: objective=0.134785 reg=0.001626
2017/08/30 21:46:53 step 5: objective=0.134824 reg=0.001626
2017/08/30 21:46:55 step 6: objective=0.134879 reg=0.001626
2017/08/30 21:46:57 step 7: objective=0.134926 reg=0.001627
2017/08/30 21:46:57 Training value function...
2017/08/30 21:47:01 step 0: mse=0.190234 step=0.050000
2017/08/30 21:47:02 step 1: mse=0.189472 step=0.050000
2017/08/30 21:47:03 step 2: mse=0.189030 step=0.050000
2017/08/30 21:47:05 step 3: mse=0.188483 step=0.050000
2017/08/30 21:47:06 step 4: mse=0.187968 step=0.050000
2017/08/30 21:47:08 step 5: mse=0.187517 step=0.050000
2017/08/30 21:47:09 step 6: mse=0.187127 step=0.050000
2017/08/30 21:47:10 step 7: mse=0.187021 step=0.050000
2017/08/30 21:47:10 Saving...
2017/08/30 21:47:11 Gathering batch of experience...
2017/08/30 21:47:52 batch 571: mean=36.000000 stddev=8.725442 entropy=0.162402 frames=8325 count=15
2017/08/30 21:47:52 Training policy...
2017/08/30 21:47:58 tune 0: objective=0.134848 reg=0.001624 prune=0
2017/08/30 21:48:00 step 0: objective=0.134848 reg=0.001624
2017/08/30 21:48:02 step 1: objective=0.134943 reg=0.001624
2017/08/30 21:48:04 step 2: objective=0.135030 reg=0.001625
2017/08/30 21:48:05 step 3: objective=0.135126 reg=0.001626
2017/08/30 21:48:07 step 4: objective=0.135224 reg=0.001628
2017/08/30 21:48:09 step 5: objective=0.135281 reg=0.001629
2017/08/30 21:48:11 step 6: objective=0.135374 reg=0.001628
2017/08/30 21:48:13 step 7: objective=0.135405 reg=0.001628
2017/08/30 21:48:13 Training value function...
2017/08/30 21:48:16 step 0: mse=0.190558 step=0.050000
2017/08/30 21:48:18 step 1: mse=0.189932 step=0.050000
2017/08/30 21:48:19 step 2: mse=0.189436 step=0.050000
2017/08/30 21:48:21 step 3: mse=0.189177 step=0.050000
2017/08/30 21:48:22 step 4: mse=0.188728 step=0.050000
2017/08/30 21:48:24 step 5: mse=0.188457 step=0.050000
2017/08/30 21:48:25 step 6: mse=0.187774 step=0.050000
2017/08/30 21:48:26 step 7: mse=0.187537 step=0.050000
2017/08/30 21:48:26 Saving...
2017/08/30 21:48:27 Gathering batch of experience...
2017/08/30 21:49:07 batch 572: mean=34.466667 stddev=9.010118 entropy=0.158533 frames=7979 count=15
2017/08/30 21:49:07 Training policy...
2017/08/30 21:49:13 tune 0: objective=0.129042 reg=0.001585 prune=0
2017/08/30 21:49:15 step 0: objective=0.129043 reg=0.001585
2017/08/30 21:49:16 step 1: objective=0.129089 reg=0.001585
2017/08/30 21:49:18 step 2: objective=0.129152 reg=0.001586
2017/08/30 21:49:20 step 3: objective=0.129201 reg=0.001586
2017/08/30 21:49:22 step 4: objective=0.129257 reg=0.001586
2017/08/30 21:49:23 step 5: objective=0.129294 reg=0.001586
2017/08/30 21:49:25 step 6: objective=0.129331 reg=0.001585
2017/08/30 21:49:27 step 7: objective=0.129360 reg=0.001585
2017/08/30 21:49:27 Training value function...
2017/08/30 21:49:30 step 0: mse=0.188067 step=0.050000
2017/08/30 21:49:32 step 1: mse=0.188299 step=0.050000
2017/08/30 21:49:33 step 2: mse=0.188494 step=0.050000
2017/08/30 21:49:35 step 3: mse=0.188831 step=0.050000
2017/08/30 21:49:36 step 4: mse=0.188996 step=0.050000
2017/08/30 21:49:37 step 5: mse=0.189225 step=0.050000
2017/08/30 21:49:39 step 6: mse=0.189491 step=0.050000
2017/08/30 21:49:40 step 7: mse=0.189532 step=0.050000
2017/08/30 21:49:40 Saving...
2017/08/30 21:49:40 Gathering batch of experience...
2017/08/30 21:50:20 batch 573: mean=31.562500 stddev=11.202504 entropy=0.165727 frames=7811 count=16
2017/08/30 21:50:20 Training policy...
2017/08/30 21:50:26 tune 0: objective=0.124985 reg=0.001657 prune=0
2017/08/30 21:50:28 step 0: objective=0.124985 reg=0.001657
2017/08/30 21:50:30 step 1: objective=0.125096 reg=0.001658
2017/08/30 21:50:31 step 2: objective=0.125171 reg=0.001658
2017/08/30 21:50:33 step 3: objective=0.125226 reg=0.001659
2017/08/30 21:50:35 step 4: objective=0.125304 reg=0.001658
2017/08/30 21:50:36 step 5: objective=0.125342 reg=0.001658
2017/08/30 21:50:38 step 6: objective=0.125421 reg=0.001658
2017/08/30 21:50:40 step 7: objective=0.125487 reg=0.001658
2017/08/30 21:50:40 Training value function...
2017/08/30 21:50:43 step 0: mse=0.195805 step=0.050000
2017/08/30 21:50:45 step 1: mse=0.196373 step=0.050000
2017/08/30 21:50:46 step 2: mse=0.196803 step=0.050000
2017/08/30 21:50:47 step 3: mse=0.197436 step=0.050000
2017/08/30 21:50:49 step 4: mse=0.198132 step=0.050000
2017/08/30 21:50:50 step 5: mse=0.198420 step=0.050000
2017/08/30 21:50:52 step 6: mse=0.198914 step=0.050000
2017/08/30 21:50:53 step 7: mse=0.199297 step=0.050000
2017/08/30 21:50:53 Saving...
2017/08/30 21:50:53 Gathering batch of experience...
2017/08/30 21:51:35 batch 574: mean=34.562500 stddev=9.246410 entropy=0.162760 frames=8521 count=16
2017/08/30 21:51:35 Training policy...
2017/08/30 21:51:41 tune 0: objective=0.134488 reg=0.001628 prune=0
2017/08/30 21:51:43 step 0: objective=0.134488 reg=0.001628
2017/08/30 21:51:45 step 1: objective=0.134581 reg=0.001628
2017/08/30 21:51:47 step 2: objective=0.134633 reg=0.001628
2017/08/30 21:51:49 step 3: objective=0.134720 reg=0.001628
2017/08/30 21:51:51 step 4: objective=0.134798 reg=0.001628
2017/08/30 21:51:53 step 5: objective=0.134845 reg=0.001629
2017/08/30 21:51:55 step 6: objective=0.134888 reg=0.001628
2017/08/30 21:51:56 step 7: objective=0.134983 reg=0.001628
2017/08/30 21:51:56 Training value function...
2017/08/30 21:52:00 step 0: mse=0.193558 step=0.050000
2017/08/30 21:52:02 step 1: mse=0.192679 step=0.050000
2017/08/30 21:52:03 step 2: mse=0.192081 step=0.050000
2017/08/30 21:52:04 step 3: mse=0.191637 step=0.050000
2017/08/30 21:52:06 step 4: mse=0.191482 step=0.050000
2017/08/30 21:52:07 step 5: mse=0.191309 step=0.050000
2017/08/30 21:52:09 step 6: mse=0.191192 step=0.050000
2017/08/30 21:52:10 step 7: mse=0.190837 step=0.050000
2017/08/30 21:52:10 Saving...
2017/08/30 21:52:10 Gathering batch of experience...
2017/08/30 21:52:49 batch 575: mean=29.875000 stddev=11.439378 entropy=0.164519 frames=7396 count=16
2017/08/30 21:52:49 Training policy...
2017/08/30 21:52:54 tune 0: objective=0.121558 reg=0.001645 prune=0
2017/08/30 21:52:56 step 0: objective=0.121558 reg=0.001645
2017/08/30 21:52:58 step 1: objective=0.121667 reg=0.001646
2017/08/30 21:52:59 step 2: objective=0.121741 reg=0.001646
2017/08/30 21:53:01 step 3: objective=0.121829 reg=0.001645
2017/08/30 21:53:03 step 4: objective=0.121937 reg=0.001645
2017/08/30 21:53:04 step 5: objective=0.122011 reg=0.001646
2017/08/30 21:53:06 step 6: objective=0.122116 reg=0.001646
2017/08/30 21:53:08 step 7: objective=0.122220 reg=0.001646
2017/08/30 21:53:08 Training value function...
2017/08/30 21:53:11 step 0: mse=0.195566 step=0.050000
2017/08/30 21:53:12 step 1: mse=0.196408 step=0.050000
2017/08/30 21:53:13 step 2: mse=0.196834 step=0.050000
2017/08/30 21:53:15 step 3: mse=0.197294 step=0.050000
2017/08/30 21:53:16 step 4: mse=0.197777 step=0.050000
2017/08/30 21:53:17 step 5: mse=0.198318 step=0.050000
2017/08/30 21:53:19 step 6: mse=0.198854 step=0.050000
2017/08/30 21:53:20 step 7: mse=0.199446 step=0.050000
2017/08/30 21:53:20 Saving...
2017/08/30 21:53:20 Gathering batch of experience...
2017/08/30 21:54:02 batch 576: mean=36.733333 stddev=6.647974 entropy=0.161338 frames=8492 count=15
2017/08/30 21:54:02 Training policy...
2017/08/30 21:54:08 tune 0: objective=0.138666 reg=0.001613 prune=0
2017/08/30 21:54:10 step 0: objective=0.138667 reg=0.001613
2017/08/30 21:54:12 step 1: objective=0.138747 reg=0.001613
2017/08/30 21:54:14 step 2: objective=0.138848 reg=0.001612
2017/08/30 21:54:16 step 3: objective=0.138907 reg=0.001611
2017/08/30 21:54:18 step 4: objective=0.138976 reg=0.001611
2017/08/30 21:54:19 step 5: objective=0.139036 reg=0.001610
2017/08/30 21:54:21 step 6: objective=0.139072 reg=0.001609
2017/08/30 21:54:23 step 7: objective=0.139128 reg=0.001609
2017/08/30 21:54:23 Training value function...
2017/08/30 21:54:27 step 0: mse=0.200757 step=0.050000
2017/08/30 21:54:28 step 1: mse=0.199488 step=0.050000
2017/08/30 21:54:30 step 2: mse=0.198321 step=0.050000
2017/08/30 21:54:31 step 3: mse=0.197232 step=0.050000
2017/08/30 21:54:33 step 4: mse=0.196374 step=0.050000
2017/08/30 21:54:34 step 5: mse=0.195467 step=0.050000
2017/08/30 21:54:36 step 6: mse=0.194746 step=0.050000
2017/08/30 21:54:37 step 7: mse=0.194286 step=0.050000
2017/08/30 21:54:37 Saving...
2017/08/30 21:54:37 Gathering batch of experience...
2017/08/30 21:55:19 batch 577: mean=35.933333 stddev=7.852530 entropy=0.162877 frames=8314 count=15
2017/08/30 21:55:19 Training policy...
2017/08/30 21:55:25 tune 0: objective=0.134927 reg=0.001629 prune=0
2017/08/30 21:55:27 step 0: objective=0.134928 reg=0.001629
2017/08/30 21:55:29 step 1: objective=0.134971 reg=0.001628
2017/08/30 21:55:31 step 2: objective=0.135017 reg=0.001628
2017/08/30 21:55:32 step 3: objective=0.135092 reg=0.001629
2017/08/30 21:55:34 step 4: objective=0.135121 reg=0.001628
2017/08/30 21:55:36 step 5: objective=0.135170 reg=0.001628
2017/08/30 21:55:38 step 6: objective=0.135233 reg=0.001629
2017/08/30 21:55:40 step 7: objective=0.135279 reg=0.001628
2017/08/30 21:55:40 Training value function...
2017/08/30 21:55:43 step 0: mse=0.193738 step=0.050000
2017/08/30 21:55:45 step 1: mse=0.193114 step=0.050000
2017/08/30 21:55:46 step 2: mse=0.192279 step=0.050000
2017/08/30 21:55:48 step 3: mse=0.191459 step=0.050000
2017/08/30 21:55:49 step 4: mse=0.191023 step=0.050000
2017/08/30 21:55:51 step 5: mse=0.190924 step=0.050000
2017/08/30 21:55:52 step 6: mse=0.190636 step=0.050000
2017/08/30 21:55:53 step 7: mse=0.190387 step=0.050000
2017/08/30 21:55:53 Saving...
2017/08/30 21:55:54 Gathering batch of experience...
2017/08/30 21:56:34 batch 578: mean=37.500000 stddev=5.408327 entropy=0.161192 frames=8076 count=14
2017/08/30 21:56:34 Training policy...
2017/08/30 21:56:40 tune 0: objective=0.138829 reg=0.001612 prune=0
2017/08/30 21:56:42 step 0: objective=0.138829 reg=0.001612
2017/08/30 21:56:44 step 1: objective=0.138890 reg=0.001613
2017/08/30 21:56:46 step 2: objective=0.138930 reg=0.001613
2017/08/30 21:56:48 step 3: objective=0.138979 reg=0.001614
2017/08/30 21:56:49 step 4: objective=0.139037 reg=0.001614
2017/08/30 21:56:51 step 5: objective=0.139083 reg=0.001615
2017/08/30 21:56:53 step 6: objective=0.139111 reg=0.001615
2017/08/30 21:56:55 step 7: objective=0.139140 reg=0.001615
2017/08/30 21:56:55 Training value function...
2017/08/30 21:56:58 step 0: mse=0.190367 step=0.050000
2017/08/30 21:57:00 step 1: mse=0.189275 step=0.050000
2017/08/30 21:57:01 step 2: mse=0.188454 step=0.050000
2017/08/30 21:57:02 step 3: mse=0.187390 step=0.050000
2017/08/30 21:57:04 step 4: mse=0.186353 step=0.050000
2017/08/30 21:57:05 step 5: mse=0.185363 step=0.050000
2017/08/30 21:57:07 step 6: mse=0.184927 step=0.050000
2017/08/30 21:57:08 step 7: mse=0.184241 step=0.050000
2017/08/30 21:57:08 Saving...
2017/08/30 21:57:08 Gathering batch of experience...
2017/08/30 21:57:49 batch 579: mean=35.333333 stddev=6.992059 entropy=0.165021 frames=8187 count=15
2017/08/30 21:57:49 Training policy...
2017/08/30 21:57:55 tune 0: objective=0.126082 reg=0.001650 prune=0
2017/08/30 21:57:57 step 0: objective=0.126083 reg=0.001650
2017/08/30 21:57:59 step 1: objective=0.126134 reg=0.001650
2017/08/30 21:58:01 step 2: objective=0.126224 reg=0.001650
2017/08/30 21:58:03 step 3: objective=0.126301 reg=0.001650
2017/08/30 21:58:05 step 4: objective=0.126407 reg=0.001650
2017/08/30 21:58:06 step 5: objective=0.126476 reg=0.001650
2017/08/30 21:58:08 step 6: objective=0.126573 reg=0.001649
2017/08/30 21:58:10 step 7: objective=0.126631 reg=0.001649
2017/08/30 21:58:10 Training value function...
2017/08/30 21:58:14 step 0: mse=0.188567 step=0.050000
2017/08/30 21:58:15 step 1: mse=0.188924 step=0.050000
2017/08/30 21:58:16 step 2: mse=0.189347 step=0.050000
2017/08/30 21:58:18 step 3: mse=0.189835 step=0.050000
2017/08/30 21:58:19 step 4: mse=0.190402 step=0.050000
2017/08/30 21:58:21 step 5: mse=0.190930 step=0.050000
2017/08/30 21:58:22 step 6: mse=0.191000 step=0.050000
2017/08/30 21:58:24 step 7: mse=0.191185 step=0.050000
2017/08/30 21:58:24 Saving...
2017/08/30 21:58:24 Gathering batch of experience...
2017/08/30 21:59:06 batch 580: mean=35.312500 stddev=7.847920 entropy=0.163839 frames=8741 count=16
2017/08/30 21:59:06 Training policy...
2017/08/30 21:59:13 tune 0: objective=0.128362 reg=0.001638 prune=0
2017/08/30 21:59:15 step 0: objective=0.128363 reg=0.001638
2017/08/30 21:59:17 step 1: objective=0.128410 reg=0.001639
2017/08/30 21:59:19 step 2: objective=0.128449 reg=0.001639
2017/08/30 21:59:21 step 3: objective=0.128478 reg=0.001639
2017/08/30 21:59:23 step 4: objective=0.128537 reg=0.001639
2017/08/30 21:59:24 step 5: objective=0.128565 reg=0.001639
2017/08/30 21:59:26 step 6: objective=0.128662 reg=0.001639
2017/08/30 21:59:28 step 7: objective=0.128686 reg=0.001639
2017/08/30 21:59:28 Training value function...
2017/08/30 21:59:32 step 0: mse=0.191906 step=0.050000
2017/08/30 21:59:34 step 1: mse=0.192228 step=0.050000
2017/08/30 21:59:35 step 2: mse=0.192476 step=0.050000
2017/08/30 21:59:37 step 3: mse=0.192491 step=0.050000
2017/08/30 21:59:38 step 4: mse=0.192447 step=0.050000
2017/08/30 21:59:40 step 5: mse=0.192648 step=0.050000
2017/08/30 21:59:41 step 6: mse=0.192946 step=0.050000
2017/08/30 21:59:43 step 7: mse=0.193042 step=0.050000
2017/08/30 21:59:43 Saving...
2017/08/30 21:59:43 Gathering batch of experience...
2017/08/30 22:00:24 batch 581: mean=35.866667 stddev=7.365385 entropy=0.161888 frames=8300 count=15
2017/08/30 22:00:24 Training policy...
2017/08/30 22:00:30 tune 0: objective=0.132548 reg=0.001619 prune=0
2017/08/30 22:00:32 step 0: objective=0.132549 reg=0.001619
2017/08/30 22:00:34 step 1: objective=0.132605 reg=0.001618
2017/08/30 22:00:36 step 2: objective=0.132691 reg=0.001618
2017/08/30 22:00:38 step 3: objective=0.132749 reg=0.001618
2017/08/30 22:00:40 step 4: objective=0.132818 reg=0.001617
2017/08/30 22:00:42 step 5: objective=0.132895 reg=0.001617
2017/08/30 22:00:44 step 6: objective=0.133004 reg=0.001616
2017/08/30 22:00:45 step 7: objective=0.133083 reg=0.001616
2017/08/30 22:00:45 Training value function...
2017/08/30 22:00:49 step 0: mse=0.193972 step=0.050000
2017/08/30 22:00:50 step 1: mse=0.193566 step=0.050000
2017/08/30 22:00:52 step 2: mse=0.193543 step=0.050000
2017/08/30 22:00:53 step 3: mse=0.193457 step=0.050000
2017/08/30 22:00:55 step 4: mse=0.193461 step=0.050000
2017/08/30 22:00:56 step 5: mse=0.193127 step=0.050000
2017/08/30 22:00:58 step 6: mse=0.192933 step=0.050000
2017/08/30 22:00:59 step 7: mse=0.193080 step=0.050000
2017/08/30 22:00:59 Saving...
2017/08/30 22:00:59 Gathering batch of experience...
2017/08/30 22:01:40 batch 582: mean=33.375000 stddev=10.282722 entropy=0.164136 frames=8246 count=16
2017/08/30 22:01:40 Training policy...
2017/08/30 22:01:46 tune 0: objective=0.129187 reg=0.001641 prune=0
2017/08/30 22:01:48 step 0: objective=0.129187 reg=0.001641
2017/08/30 22:01:50 step 1: objective=0.129308 reg=0.001641
2017/08/30 22:01:52 step 2: objective=0.129350 reg=0.001641
2017/08/30 22:01:54 step 3: objective=0.129450 reg=0.001641
2017/08/30 22:01:56 step 4: objective=0.129484 reg=0.001641
2017/08/30 22:01:57 step 5: objective=0.129534 reg=0.001641
2017/08/30 22:01:59 step 6: objective=0.129589 reg=0.001641
2017/08/30 22:02:01 step 7: objective=0.129659 reg=0.001641
2017/08/30 22:02:01 Training value function...
2017/08/30 22:02:05 step 0: mse=0.193782 step=0.050000
2017/08/30 22:02:06 step 1: mse=0.194178 step=0.050000
2017/08/30 22:02:08 step 2: mse=0.194554 step=0.050000
2017/08/30 22:02:09 step 3: mse=0.194781 step=0.050000
2017/08/30 22:02:10 step 4: mse=0.195096 step=0.050000
2017/08/30 22:02:12 step 5: mse=0.195426 step=0.050000
2017/08/30 22:02:13 step 6: mse=0.195655 step=0.050000
2017/08/30 22:02:15 step 7: mse=0.195752 step=0.050000
2017/08/30 22:02:15 Saving...
2017/08/30 22:02:15 Gathering batch of experience...
2017/08/30 22:02:55 batch 583: mean=36.142857 stddev=7.962924 entropy=0.159714 frames=7808 count=14
2017/08/30 22:02:55 Training policy...
2017/08/30 22:03:01 tune 0: objective=0.133972 reg=0.001597 prune=0
2017/08/30 22:03:03 step 0: objective=0.133972 reg=0.001597
2017/08/30 22:03:05 step 1: objective=0.134025 reg=0.001597
2017/08/30 22:03:06 step 2: objective=0.134068 reg=0.001597
2017/08/30 22:03:08 step 3: objective=0.134145 reg=0.001596
2017/08/30 22:03:10 step 4: objective=0.134209 reg=0.001596
2017/08/30 22:03:11 step 5: objective=0.134261 reg=0.001596
2017/08/30 22:03:13 step 6: objective=0.134298 reg=0.001596
2017/08/30 22:03:15 step 7: objective=0.134333 reg=0.001597
2017/08/30 22:03:15 Training value function...
2017/08/30 22:03:18 step 0: mse=0.194665 step=0.050000
2017/08/30 22:03:20 step 1: mse=0.194298 step=0.050000
2017/08/30 22:03:21 step 2: mse=0.193721 step=0.050000
2017/08/30 22:03:22 step 3: mse=0.193364 step=0.050000
2017/08/30 22:03:24 step 4: mse=0.192768 step=0.050000
2017/08/30 22:03:25 step 5: mse=0.191810 step=0.050000
2017/08/30 22:03:26 step 6: mse=0.191036 step=0.050000
2017/08/30 22:03:28 step 7: mse=0.190637 step=0.050000
2017/08/30 22:03:28 Saving...
2017/08/30 22:03:28 Gathering batch of experience...
2017/08/30 22:04:08 batch 584: mean=32.750000 stddev=9.927865 entropy=0.163452 frames=8108 count=16
2017/08/30 22:04:08 Training policy...
2017/08/30 22:04:14 tune 0: objective=0.124805 reg=0.001635 prune=0
2017/08/30 22:04:16 step 0: objective=0.124805 reg=0.001635
2017/08/30 22:04:18 step 1: objective=0.124913 reg=0.001634
2017/08/30 22:04:20 step 2: objective=0.125023 reg=0.001633
2017/08/30 22:04:22 step 3: objective=0.125133 reg=0.001633
2017/08/30 22:04:24 step 4: objective=0.125260 reg=0.001632
2017/08/30 22:04:25 step 5: objective=0.125353 reg=0.001631
2017/08/30 22:04:27 step 6: objective=0.125389 reg=0.001631
2017/08/30 22:04:29 step 7: objective=0.125444 reg=0.001630
2017/08/30 22:04:29 Training value function...
2017/08/30 22:04:32 step 0: mse=0.198858 step=0.050000
2017/08/30 22:04:34 step 1: mse=0.199189 step=0.050000
2017/08/30 22:04:35 step 2: mse=0.199301 step=0.050000
2017/08/30 22:04:37 step 3: mse=0.199493 step=0.050000
2017/08/30 22:04:38 step 4: mse=0.199759 step=0.050000
2017/08/30 22:04:40 step 5: mse=0.200013 step=0.050000
2017/08/30 22:04:41 step 6: mse=0.200340 step=0.050000
2017/08/30 22:04:42 step 7: mse=0.200784 step=0.050000
2017/08/30 22:04:42 Saving...
2017/08/30 22:04:43 Gathering batch of experience...
2017/08/30 22:05:25 batch 585: mean=35.062500 stddev=9.443707 entropy=0.163047 frames=8650 count=16
2017/08/30 22:05:25 Training policy...
2017/08/30 22:05:31 tune 0: objective=0.135304 reg=0.001630 prune=0
2017/08/30 22:05:33 step 0: objective=0.135304 reg=0.001630
2017/08/30 22:05:35 step 1: objective=0.135347 reg=0.001631
2017/08/30 22:05:37 step 2: objective=0.135382 reg=0.001631
2017/08/30 22:05:39 step 3: objective=0.135419 reg=0.001631
2017/08/30 22:05:41 step 4: objective=0.135448 reg=0.001631
2017/08/30 22:05:43 step 5: objective=0.135482 reg=0.001631
2017/08/30 22:05:45 step 6: objective=0.135525 reg=0.001631
2017/08/30 22:05:47 step 7: objective=0.135572 reg=0.001631
2017/08/30 22:05:47 Training value function...
2017/08/30 22:05:51 step 0: mse=0.198418 step=0.050000
2017/08/30 22:05:52 step 1: mse=0.197481 step=0.050000
2017/08/30 22:05:54 step 2: mse=0.196578 step=0.050000
2017/08/30 22:05:55 step 3: mse=0.195894 step=0.050000
2017/08/30 22:05:57 step 4: mse=0.195318 step=0.050000
2017/08/30 22:05:58 step 5: mse=0.194358 step=0.050000
2017/08/30 22:06:00 step 6: mse=0.193866 step=0.050000
2017/08/30 22:06:01 step 7: mse=0.193196 step=0.050000
2017/08/30 22:06:01 Saving...
2017/08/30 22:06:01 Gathering batch of experience...
2017/08/30 22:06:42 batch 586: mean=31.058824 stddev=12.041451 entropy=0.160521 frames=8173 count=17
2017/08/30 22:06:42 Training policy...
2017/08/30 22:06:49 tune 0: objective=0.123855 reg=0.001605 prune=0
2017/08/30 22:06:50 step 0: objective=0.123855 reg=0.001605
2017/08/30 22:06:52 step 1: objective=0.123937 reg=0.001605
2017/08/30 22:06:54 step 2: objective=0.124011 reg=0.001605
2017/08/30 22:06:56 step 3: objective=0.124110 reg=0.001605
2017/08/30 22:06:58 step 4: objective=0.124187 reg=0.001605
2017/08/30 22:07:00 step 5: objective=0.124264 reg=0.001605
2017/08/30 22:07:01 step 6: objective=0.124355 reg=0.001605
2017/08/30 22:07:03 step 7: objective=0.124417 reg=0.001605
2017/08/30 22:07:03 Training value function...
2017/08/30 22:07:07 step 0: mse=0.198899 step=0.050000
2017/08/30 22:07:08 step 1: mse=0.199615 step=0.050000
2017/08/30 22:07:10 step 2: mse=0.200090 step=0.050000
2017/08/30 22:07:11 step 3: mse=0.200609 step=0.050000
2017/08/30 22:07:12 step 4: mse=0.201213 step=0.050000
2017/08/30 22:07:14 step 5: mse=0.201747 step=0.050000
2017/08/30 22:07:15 step 6: mse=0.202314 step=0.050000
2017/08/30 22:07:17 step 7: mse=0.202749 step=0.050000
2017/08/30 22:07:17 Saving...
2017/08/30 22:07:17 Gathering batch of experience...
2017/08/30 22:08:02 batch 587: mean=30.105263 stddev=13.637775 entropy=0.160258 frames=8850 count=19
2017/08/30 22:08:02 Training policy...
2017/08/30 22:08:09 tune 0: objective=0.129216 reg=0.001603 prune=0
2017/08/30 22:08:11 step 0: objective=0.129216 reg=0.001603
2017/08/30 22:08:13 step 1: objective=0.129356 reg=0.001602
2017/08/30 22:08:15 step 2: objective=0.129414 reg=0.001602
2017/08/30 22:08:17 step 3: objective=0.129534 reg=0.001601
2017/08/30 22:08:19 step 4: objective=0.129594 reg=0.001601
2017/08/30 22:08:21 step 5: objective=0.129715 reg=0.001602
2017/08/30 22:08:23 step 6: objective=0.129823 reg=0.001601
2017/08/30 22:08:25 step 7: objective=0.129909 reg=0.001601
2017/08/30 22:08:25 Training value function...
2017/08/30 22:08:29 step 0: mse=0.208412 step=0.050000
2017/08/30 22:08:30 step 1: mse=0.208593 step=0.050000
2017/08/30 22:08:32 step 2: mse=0.208853 step=0.050000
2017/08/30 22:08:33 step 3: mse=0.208719 step=0.050000
2017/08/30 22:08:35 step 4: mse=0.208753 step=0.050000
2017/08/30 22:08:37 step 5: mse=0.208600 step=0.050000
2017/08/30 22:08:38 step 6: mse=0.208761 step=0.050000
2017/08/30 22:08:40 step 7: mse=0.208663 step=0.050000
2017/08/30 22:08:40 Saving...
2017/08/30 22:08:40 Gathering batch of experience...
2017/08/30 22:09:22 batch 588: mean=29.777778 stddev=13.595569 entropy=0.163257 frames=8298 count=18
2017/08/30 22:09:22 Training policy...
2017/08/30 22:09:28 tune 0: objective=0.129428 reg=0.001633 prune=0
2017/08/30 22:09:30 step 0: objective=0.129428 reg=0.001633
2017/08/30 22:09:32 step 1: objective=0.129508 reg=0.001633
2017/08/30 22:09:34 step 2: objective=0.129556 reg=0.001633
2017/08/30 22:09:35 step 3: objective=0.129610 reg=0.001633
2017/08/30 22:09:37 step 4: objective=0.129653 reg=0.001633
2017/08/30 22:09:39 step 5: objective=0.129711 reg=0.001633
2017/08/30 22:09:41 step 6: objective=0.129766 reg=0.001633
2017/08/30 22:09:43 step 7: objective=0.129821 reg=0.001633
2017/08/30 22:09:43 Training value function...
2017/08/30 22:09:46 step 0: mse=0.208470 step=0.050000
2017/08/30 22:09:48 step 1: mse=0.208656 step=0.050000
2017/08/30 22:09:49 step 2: mse=0.208854 step=0.050000
2017/08/30 22:09:51 step 3: mse=0.208933 step=0.050000
2017/08/30 22:09:52 step 4: mse=0.209091 step=0.050000
2017/08/30 22:09:54 step 5: mse=0.209266 step=0.050000
2017/08/30 22:09:55 step 6: mse=0.209398 step=0.050000
2017/08/30 22:09:57 step 7: mse=0.209412 step=0.050000
2017/08/30 22:09:57 Saving...
2017/08/30 22:09:57 Gathering batch of experience...
2017/08/30 22:10:39 batch 589: mean=34.375000 stddev=11.285361 entropy=0.160796 frames=8490 count=16
2017/08/30 22:10:39 Training policy...
2017/08/30 22:10:45 tune 0: objective=0.138839 reg=0.001608 prune=0
2017/08/30 22:10:47 step 0: objective=0.138839 reg=0.001608
2017/08/30 22:10:49 step 1: objective=0.138911 reg=0.001608
2017/08/30 22:10:51 step 2: objective=0.138998 reg=0.001609
2017/08/30 22:10:53 step 3: objective=0.139049 reg=0.001609
2017/08/30 22:10:55 step 4: objective=0.139102 reg=0.001609
2017/08/30 22:10:57 step 5: objective=0.139171 reg=0.001610
2017/08/30 22:10:59 step 6: objective=0.139201 reg=0.001609
2017/08/30 22:11:00 step 7: objective=0.139273 reg=0.001609
2017/08/30 22:11:00 Training value function...
2017/08/30 22:11:04 step 0: mse=0.206179 step=0.050000
2017/08/30 22:11:06 step 1: mse=0.204833 step=0.050000
2017/08/30 22:11:07 step 2: mse=0.203456 step=0.050000
2017/08/30 22:11:08 step 3: mse=0.202526 step=0.050000
2017/08/30 22:11:10 step 4: mse=0.201452 step=0.050000
2017/08/30 22:11:11 step 5: mse=0.200265 step=0.050000
2017/08/30 22:11:13 step 6: mse=0.199189 step=0.050000
2017/08/30 22:11:14 step 7: mse=0.198390 step=0.050000
2017/08/30 22:11:14 Saving...
2017/08/30 22:11:14 Gathering batch of experience...
2017/08/30 22:11:59 batch 590: mean=28.368421 stddev=12.239756 entropy=0.164769 frames=8357 count=19
2017/08/30 22:11:59 Training policy...
2017/08/30 22:12:05 tune 0: objective=0.118858 reg=0.001648 prune=0
2017/08/30 22:12:07 step 0: objective=0.118859 reg=0.001648
2017/08/30 22:12:09 step 1: objective=0.118960 reg=0.001648
2017/08/30 22:12:11 step 2: objective=0.119021 reg=0.001647
2017/08/30 22:12:13 step 3: objective=0.119091 reg=0.001647
2017/08/30 22:12:14 step 4: objective=0.119143 reg=0.001647
2017/08/30 22:12:16 step 5: objective=0.119189 reg=0.001646
2017/08/30 22:12:18 step 6: objective=0.119239 reg=0.001646
2017/08/30 22:12:20 step 7: objective=0.119275 reg=0.001646
2017/08/30 22:12:20 Training value function...
2017/08/30 22:12:24 step 0: mse=0.201705 step=0.050000
2017/08/30 22:12:25 step 1: mse=0.202281 step=0.050000
2017/08/30 22:12:27 step 2: mse=0.202967 step=0.050000
2017/08/30 22:12:28 step 3: mse=0.203585 step=0.050000
2017/08/30 22:12:30 step 4: mse=0.204160 step=0.050000
2017/08/30 22:12:31 step 5: mse=0.204540 step=0.050000
2017/08/30 22:12:33 step 6: mse=0.205011 step=0.050000
2017/08/30 22:12:34 step 7: mse=0.205608 step=0.050000
2017/08/30 22:12:34 Saving...
2017/08/30 22:12:34 Gathering batch of experience...
2017/08/30 22:13:14 batch 591: mean=32.933333 stddev=11.263313 entropy=0.164997 frames=7629 count=15
2017/08/30 22:13:14 Training policy...
2017/08/30 22:13:19 tune 0: objective=0.134415 reg=0.001650 prune=0
2017/08/30 22:13:21 step 0: objective=0.134415 reg=0.001650
2017/08/30 22:13:23 step 1: objective=0.134448 reg=0.001650
2017/08/30 22:13:25 step 2: objective=0.134497 reg=0.001650
2017/08/30 22:13:26 step 3: objective=0.134569 reg=0.001649
2017/08/30 22:13:28 step 4: objective=0.134605 reg=0.001649
2017/08/30 22:13:30 step 5: objective=0.134651 reg=0.001649
2017/08/30 22:13:31 step 6: objective=0.134685 reg=0.001649
2017/08/30 22:13:33 step 7: objective=0.134735 reg=0.001649
2017/08/30 22:13:33 Training value function...
2017/08/30 22:13:36 step 0: mse=0.203790 step=0.050000
2017/08/30 22:13:38 step 1: mse=0.202704 step=0.050000
2017/08/30 22:13:39 step 2: mse=0.202073 step=0.050000
2017/08/30 22:13:40 step 3: mse=0.201586 step=0.050000
2017/08/30 22:13:42 step 4: mse=0.201112 step=0.050000
2017/08/30 22:13:43 step 5: mse=0.200821 step=0.050000
2017/08/30 22:13:44 step 6: mse=0.200526 step=0.050000
2017/08/30 22:13:45 step 7: mse=0.200052 step=0.050000
2017/08/30 22:13:45 Saving...
2017/08/30 22:13:45 Gathering batch of experience...
2017/08/30 22:14:25 batch 592: mean=33.666667 stddev=8.638415 entropy=0.161003 frames=7807 count=15
2017/08/30 22:14:25 Training policy...
2017/08/30 22:14:31 tune 0: objective=0.132940 reg=0.001610 prune=0
2017/08/30 22:14:33 step 0: objective=0.132940 reg=0.001610
2017/08/30 22:14:35 step 1: objective=0.132995 reg=0.001611
2017/08/30 22:14:37 step 2: objective=0.133059 reg=0.001611
2017/08/30 22:14:38 step 3: objective=0.133116 reg=0.001611
2017/08/30 22:14:40 step 4: objective=0.133179 reg=0.001611
2017/08/30 22:14:42 step 5: objective=0.133227 reg=0.001611
2017/08/30 22:14:44 step 6: objective=0.133255 reg=0.001612
2017/08/30 22:14:45 step 7: objective=0.133314 reg=0.001611
2017/08/30 22:14:45 Training value function...
2017/08/30 22:14:49 step 0: mse=0.203667 step=0.050000
2017/08/30 22:14:50 step 1: mse=0.203312 step=0.050000
2017/08/30 22:14:51 step 2: mse=0.202851 step=0.050000
2017/08/30 22:14:53 step 3: mse=0.202634 step=0.050000
2017/08/30 22:14:54 step 4: mse=0.202282 step=0.050000
2017/08/30 22:14:56 step 5: mse=0.201842 step=0.050000
2017/08/30 22:14:57 step 6: mse=0.201476 step=0.050000
2017/08/30 22:14:58 step 7: mse=0.200816 step=0.050000
2017/08/30 22:14:58 Saving...
2017/08/30 22:14:58 Gathering batch of experience...
2017/08/30 22:15:40 batch 593: mean=28.500000 stddev=13.438130 entropy=0.163789 frames=7965 count=18
2017/08/30 22:15:40 Training policy...
2017/08/30 22:15:46 tune 0: objective=0.121281 reg=0.001638 prune=0
2017/08/30 22:15:48 step 0: objective=0.121281 reg=0.001638
2017/08/30 22:15:49 step 1: objective=0.121406 reg=0.001637
2017/08/30 22:15:51 step 2: objective=0.121482 reg=0.001636
2017/08/30 22:15:53 step 3: objective=0.121558 reg=0.001635
2017/08/30 22:15:55 step 4: objective=0.121666 reg=0.001634
2017/08/30 22:15:57 step 5: objective=0.121784 reg=0.001633
2017/08/30 22:15:58 step 6: objective=0.121863 reg=0.001633
2017/08/30 22:16:00 step 7: objective=0.121914 reg=0.001633
2017/08/30 22:16:00 Training value function...
2017/08/30 22:16:04 step 0: mse=0.210782 step=0.050000
2017/08/30 22:16:05 step 1: mse=0.211151 step=0.050000
2017/08/30 22:16:07 step 2: mse=0.211584 step=0.050000
2017/08/30 22:16:08 step 3: mse=0.212086 step=0.050000
2017/08/30 22:16:09 step 4: mse=0.212230 step=0.050000
2017/08/30 22:16:11 step 5: mse=0.212665 step=0.050000
2017/08/30 22:16:12 step 6: mse=0.213095 step=0.050000
2017/08/30 22:16:14 step 7: mse=0.213520 step=0.050000
2017/08/30 22:16:14 Saving...
2017/08/30 22:16:14 Gathering batch of experience...
2017/08/30 22:16:53 batch 594: mean=32.933333 stddev=11.245542 entropy=0.158110 frames=7630 count=15
2017/08/30 22:16:53 Training policy...
2017/08/30 22:16:59 tune 0: objective=0.136156 reg=0.001581 prune=0
2017/08/30 22:17:00 step 0: objective=0.136156 reg=0.001581
2017/08/30 22:17:02 step 1: objective=0.136247 reg=0.001582
2017/08/30 22:17:04 step 2: objective=0.136286 reg=0.001582
2017/08/30 22:17:06 step 3: objective=0.136389 reg=0.001583
2017/08/30 22:17:07 step 4: objective=0.136430 reg=0.001583
2017/08/30 22:17:09 step 5: objective=0.136487 reg=0.001583
2017/08/30 22:17:11 step 6: objective=0.136543 reg=0.001583
2017/08/30 22:17:13 step 7: objective=0.136571 reg=0.001583
2017/08/30 22:17:13 Training value function...
2017/08/30 22:17:16 step 0: mse=0.210680 step=0.050000
2017/08/30 22:17:17 step 1: mse=0.209555 step=0.050000
2017/08/30 22:17:18 step 2: mse=0.208428 step=0.050000
2017/08/30 22:17:20 step 3: mse=0.207683 step=0.050000
2017/08/30 22:17:21 step 4: mse=0.206634 step=0.050000
2017/08/30 22:17:22 step 5: mse=0.206166 step=0.050000
2017/08/30 22:17:24 step 6: mse=0.205440 step=0.050000
2017/08/30 22:17:25 step 7: mse=0.204694 step=0.050000
2017/08/30 22:17:25 Saving...
2017/08/30 22:17:25 Gathering batch of experience...
2017/08/30 22:18:04 batch 595: mean=28.529412 stddev=13.651622 entropy=0.162041 frames=7505 count=17
2017/08/30 22:18:04 Training policy...
2017/08/30 22:18:10 tune 0: objective=0.124785 reg=0.001620 prune=0
2017/08/30 22:18:11 step 0: objective=0.124785 reg=0.001620
2017/08/30 22:18:13 step 1: objective=0.124921 reg=0.001621
2017/08/30 22:18:15 step 2: objective=0.125085 reg=0.001622
2017/08/30 22:18:16 step 3: objective=0.125237 reg=0.001622
2017/08/30 22:18:18 step 4: objective=0.125361 reg=0.001622
2017/08/30 22:18:20 step 5: objective=0.125399 reg=0.001622
2017/08/30 22:18:22 step 6: objective=0.125449 reg=0.001622
2017/08/30 22:18:23 step 7: objective=0.125507 reg=0.001621
2017/08/30 22:18:23 Training value function...
2017/08/30 22:18:26 step 0: mse=0.201841 step=0.050000
2017/08/30 22:18:28 step 1: mse=0.201800 step=0.050000
2017/08/30 22:18:29 step 2: mse=0.202233 step=0.050000
2017/08/30 22:18:30 step 3: mse=0.202638 step=0.050000
2017/08/30 22:18:32 step 4: mse=0.202598 step=0.050000
2017/08/30 22:18:33 step 5: mse=0.202902 step=0.050000
2017/08/30 22:18:34 step 6: mse=0.203158 step=0.050000
2017/08/30 22:18:36 step 7: mse=0.203552 step=0.050000
2017/08/30 22:18:36 Saving...
2017/08/30 22:18:36 Gathering batch of experience...
2017/08/30 22:19:15 batch 596: mean=33.333333 stddev=11.085526 entropy=0.159921 frames=7723 count=15
2017/08/30 22:19:15 Training policy...
2017/08/30 22:19:21 tune 0: objective=0.136610 reg=0.001599 prune=0
2017/08/30 22:19:23 step 0: objective=0.136610 reg=0.001599
2017/08/30 22:19:25 step 1: objective=0.136668 reg=0.001599
2017/08/30 22:19:26 step 2: objective=0.136708 reg=0.001599
2017/08/30 22:19:28 step 3: objective=0.136743 reg=0.001599
2017/08/30 22:19:30 step 4: objective=0.136817 reg=0.001599
2017/08/30 22:19:32 step 5: objective=0.136882 reg=0.001598
2017/08/30 22:19:33 step 6: objective=0.136997 reg=0.001598
2017/08/30 22:19:35 step 7: objective=0.137046 reg=0.001598
2017/08/30 22:19:35 Training value function...
2017/08/30 22:19:38 step 0: mse=0.206515 step=0.050000
2017/08/30 22:19:40 step 1: mse=0.205589 step=0.050000
2017/08/30 22:19:41 step 2: mse=0.204869 step=0.050000
2017/08/30 22:19:42 step 3: mse=0.203974 step=0.050000
2017/08/30 22:19:44 step 4: mse=0.203178 step=0.050000
2017/08/30 22:19:45 step 5: mse=0.202783 step=0.050000
2017/08/30 22:19:46 step 6: mse=0.202169 step=0.050000
2017/08/30 22:19:48 step 7: mse=0.201410 step=0.050000
2017/08/30 22:19:48 Saving...
2017/08/30 22:19:48 Gathering batch of experience...
2017/08/30 22:20:28 batch 597: mean=34.533333 stddev=10.019093 entropy=0.158134 frames=8015 count=15
2017/08/30 22:20:28 Training policy...
2017/08/30 22:20:34 tune 0: objective=0.134143 reg=0.001581 prune=0
2017/08/30 22:20:36 step 0: objective=0.134143 reg=0.001581
2017/08/30 22:20:38 step 1: objective=0.134232 reg=0.001581
2017/08/30 22:20:40 step 2: objective=0.134345 reg=0.001580
2017/08/30 22:20:41 step 3: objective=0.134447 reg=0.001580
2017/08/30 22:20:43 step 4: objective=0.134582 reg=0.001579
2017/08/30 22:20:45 step 5: objective=0.134625 reg=0.001579
2017/08/30 22:20:47 step 6: objective=0.134687 reg=0.001579
2017/08/30 22:20:49 step 7: objective=0.134764 reg=0.001579
2017/08/30 22:20:49 Training value function...
2017/08/30 22:20:52 step 0: mse=0.204267 step=0.050000
2017/08/30 22:20:54 step 1: mse=0.203748 step=0.050000
2017/08/30 22:20:55 step 2: mse=0.203108 step=0.050000
2017/08/30 22:20:56 step 3: mse=0.202347 step=0.050000
2017/08/30 22:20:58 step 4: mse=0.201487 step=0.050000
2017/08/30 22:20:59 step 5: mse=0.201246 step=0.050000
2017/08/30 22:21:01 step 6: mse=0.200806 step=0.050000
2017/08/30 22:21:02 step 7: mse=0.200399 step=0.050000
2017/08/30 22:21:02 Saving...
2017/08/30 22:21:02 Gathering batch of experience...
2017/08/30 22:21:41 batch 598: mean=30.625000 stddev=12.633660 entropy=0.156132 frames=7575 count=16
2017/08/30 22:21:41 Training policy...
2017/08/30 22:21:47 tune 0: objective=0.129561 reg=0.001561 prune=0
2017/08/30 22:21:49 step 0: objective=0.129562 reg=0.001561
2017/08/30 22:21:51 step 1: objective=0.129660 reg=0.001562
2017/08/30 22:21:52 step 2: objective=0.129713 reg=0.001563
2017/08/30 22:21:54 step 3: objective=0.129789 reg=0.001564
2017/08/30 22:21:56 step 4: objective=0.129867 reg=0.001565
2017/08/30 22:21:57 step 5: objective=0.129974 reg=0.001565
2017/08/30 22:21:59 step 6: objective=0.130033 reg=0.001565
2017/08/30 22:22:01 step 7: objective=0.130084 reg=0.001565
2017/08/30 22:22:01 Training value function...
2017/08/30 22:22:04 step 0: mse=0.200434 step=0.050000
2017/08/30 22:22:05 step 1: mse=0.200629 step=0.050000
2017/08/30 22:22:07 step 2: mse=0.200775 step=0.050000
2017/08/30 22:22:08 step 3: mse=0.200892 step=0.050000
2017/08/30 22:22:09 step 4: mse=0.200927 step=0.050000
2017/08/30 22:22:11 step 5: mse=0.201209 step=0.050000
2017/08/30 22:22:12 step 6: mse=0.201402 step=0.050000
2017/08/30 22:22:13 step 7: mse=0.201757 step=0.050000
2017/08/30 22:22:13 Saving...
2017/08/30 22:22:13 Gathering batch of experience...
2017/08/30 22:22:54 batch 599: mean=35.133333 stddev=7.906678 entropy=0.157612 frames=8139 count=15
2017/08/30 22:22:54 Training policy...
2017/08/30 22:23:01 tune 0: objective=0.135713 reg=0.001576 prune=0
2017/08/30 22:23:02 step 0: objective=0.135713 reg=0.001576
2017/08/30 22:23:04 step 1: objective=0.135815 reg=0.001577
2017/08/30 22:23:06 step 2: objective=0.135864 reg=0.001577
2017/08/30 22:23:08 step 3: objective=0.135946 reg=0.001577
2017/08/30 22:23:10 step 4: objective=0.136011 reg=0.001578
2017/08/30 22:23:12 step 5: objective=0.136069 reg=0.001577
2017/08/30 22:23:13 step 6: objective=0.136139 reg=0.001578
2017/08/30 22:23:15 step 7: objective=0.136179 reg=0.001578
2017/08/30 22:23:15 Training value function...
2017/08/30 22:23:19 step 0: mse=0.202952 step=0.050000
2017/08/30 22:23:20 step 1: mse=0.202485 step=0.050000
2017/08/30 22:23:21 step 2: mse=0.201680 step=0.050000
2017/08/30 22:23:23 step 3: mse=0.201156 step=0.050000
2017/08/30 22:23:24 step 4: mse=0.200476 step=0.050000
2017/08/30 22:23:26 step 5: mse=0.199922 step=0.050000
2017/08/30 22:23:27 step 6: mse=0.199260 step=0.050000
2017/08/30 22:23:28 step 7: mse=0.198564 step=0.050000
2017/08/30 22:23:28 Saving...
2017/08/30 22:23:29 Gathering batch of experience...
2017/08/30 22:24:10 batch 600: mean=35.466667 stddev=9.527971 entropy=0.159614 frames=8190 count=15
2017/08/30 22:24:10 Training policy...
2017/08/30 22:24:16 tune 0: objective=0.137793 reg=0.001596 prune=0
2017/08/30 22:24:18 step 0: objective=0.137792 reg=0.001596
2017/08/30 22:24:20 step 1: objective=0.137920 reg=0.001596
2017/08/30 22:24:21 step 2: objective=0.137982 reg=0.001595
2017/08/30 22:24:23 step 3: objective=0.138061 reg=0.001595
2017/08/30 22:24:25 step 4: objective=0.138161 reg=0.001595
2017/08/30 22:24:27 step 5: objective=0.138205 reg=0.001594
2017/08/30 22:24:29 step 6: objective=0.138291 reg=0.001594
2017/08/30 22:24:31 step 7: objective=0.138325 reg=0.001594
2017/08/30 22:24:31 Training value function...
2017/08/30 22:24:34 step 0: mse=0.193103 step=0.050000
2017/08/30 22:24:36 step 1: mse=0.192103 step=0.050000
2017/08/30 22:24:37 step 2: mse=0.191510 step=0.050000
2017/08/30 22:24:38 step 3: mse=0.190794 step=0.050000
2017/08/30 22:24:40 step 4: mse=0.189816 step=0.050000
2017/08/30 22:24:41 step 5: mse=0.188821 step=0.050000
2017/08/30 22:24:43 step 6: mse=0.187840 step=0.050000
2017/08/30 22:24:44 step 7: mse=0.187250 step=0.050000
2017/08/30 22:24:44 Saving...
2017/08/30 22:24:44 Gathering batch of experience...
2017/08/30 22:25:25 batch 601: mean=31.352941 stddev=11.360101 entropy=0.159409 frames=8254 count=17
2017/08/30 22:25:25 Training policy...
2017/08/30 22:25:32 tune 0: objective=0.122152 reg=0.001594 prune=0
2017/08/30 22:25:34 step 0: objective=0.122152 reg=0.001594
2017/08/30 22:25:35 step 1: objective=0.122214 reg=0.001593
2017/08/30 22:25:37 step 2: objective=0.122269 reg=0.001594
2017/08/30 22:25:39 step 3: objective=0.122309 reg=0.001593
2017/08/30 22:25:41 step 4: objective=0.122369 reg=0.001593
2017/08/30 22:25:43 step 5: objective=0.122401 reg=0.001593
2017/08/30 22:25:45 step 6: objective=0.122437 reg=0.001592
2017/08/30 22:25:47 step 7: objective=0.122466 reg=0.001591
2017/08/30 22:25:47 Training value function...
2017/08/30 22:25:50 step 0: mse=0.194974 step=0.050000
2017/08/30 22:25:52 step 1: mse=0.195566 step=0.050000
2017/08/30 22:25:53 step 2: mse=0.196105 step=0.050000
2017/08/30 22:25:55 step 3: mse=0.196606 step=0.050000
2017/08/30 22:25:56 step 4: mse=0.197337 step=0.050000
2017/08/30 22:25:58 step 5: mse=0.197829 step=0.050000
2017/08/30 22:25:59 step 6: mse=0.198388 step=0.050000
2017/08/30 22:26:00 step 7: mse=0.198690 step=0.050000
2017/08/30 22:26:00 Saving...
2017/08/30 22:26:01 Gathering batch of experience...
2017/08/30 22:26:43 batch 602: mean=32.588235 stddev=11.104100 entropy=0.159993 frames=8563 count=17
2017/08/30 22:26:43 Training policy...
2017/08/30 22:26:49 tune 0: objective=0.130661 reg=0.001600 prune=0
2017/08/30 22:26:51 step 0: objective=0.130661 reg=0.001600
2017/08/30 22:26:53 step 1: objective=0.130744 reg=0.001600
2017/08/30 22:26:55 step 2: objective=0.130793 reg=0.001600
2017/08/30 22:26:57 step 3: objective=0.130838 reg=0.001601
2017/08/30 22:26:59 step 4: objective=0.130902 reg=0.001602
2017/08/30 22:27:01 step 5: objective=0.130953 reg=0.001602
2017/08/30 22:27:03 step 6: objective=0.130998 reg=0.001602
2017/08/30 22:27:05 step 7: objective=0.131045 reg=0.001602
2017/08/30 22:27:05 Training value function...
2017/08/30 22:27:08 step 0: mse=0.200242 step=0.050000
2017/08/30 22:27:10 step 1: mse=0.200409 step=0.050000
2017/08/30 22:27:11 step 2: mse=0.200572 step=0.050000
2017/08/30 22:27:13 step 3: mse=0.200910 step=0.050000
2017/08/30 22:27:14 step 4: mse=0.200858 step=0.050000
2017/08/30 22:27:16 step 5: mse=0.200782 step=0.050000
2017/08/30 22:27:18 step 6: mse=0.200911 step=0.050000
2017/08/30 22:27:19 step 7: mse=0.201101 step=0.050000
2017/08/30 22:27:19 Saving...
2017/08/30 22:27:19 Gathering batch of experience...
2017/08/30 22:28:01 batch 603: mean=34.000000 stddev=9.861541 entropy=0.156365 frames=8404 count=16
2017/08/30 22:28:01 Training policy...
2017/08/30 22:28:07 tune 0: objective=0.132386 reg=0.001564 prune=0
2017/08/30 22:28:09 step 0: objective=0.132386 reg=0.001564
2017/08/30 22:28:11 step 1: objective=0.132449 reg=0.001563
2017/08/30 22:28:13 step 2: objective=0.132503 reg=0.001563
2017/08/30 22:28:15 step 3: objective=0.132541 reg=0.001563
2017/08/30 22:28:17 step 4: objective=0.132581 reg=0.001563
2017/08/30 22:28:19 step 5: objective=0.132672 reg=0.001562
2017/08/30 22:28:21 step 6: objective=0.132712 reg=0.001561
2017/08/30 22:28:23 step 7: objective=0.132746 reg=0.001560
2017/08/30 22:28:23 Training value function...
2017/08/30 22:28:26 step 0: mse=0.199932 step=0.050000
2017/08/30 22:28:28 step 1: mse=0.199805 step=0.050000
2017/08/30 22:28:29 step 2: mse=0.199658 step=0.050000
2017/08/30 22:28:30 step 3: mse=0.199062 step=0.050000
2017/08/30 22:28:32 step 4: mse=0.198515 step=0.050000
2017/08/30 22:28:33 step 5: mse=0.198085 step=0.050000
2017/08/30 22:28:35 step 6: mse=0.197625 step=0.050000
2017/08/30 22:28:36 step 7: mse=0.197366 step=0.050000
2017/08/30 22:28:36 Saving...
2017/08/30 22:28:36 Gathering batch of experience...
2017/08/30 22:29:20 batch 604: mean=29.611111 stddev=12.932040 entropy=0.160349 frames=8247 count=18
2017/08/30 22:29:20 Training policy...
2017/08/30 22:29:26 tune 0: objective=0.124758 reg=0.001603 prune=0
2017/08/30 22:29:28 step 0: objective=0.124758 reg=0.001603
2017/08/30 22:29:30 step 1: objective=0.124813 reg=0.001604
2017/08/30 22:29:32 step 2: objective=0.124860 reg=0.001604
2017/08/30 22:29:34 step 3: objective=0.124918 reg=0.001603
2017/08/30 22:29:35 step 4: objective=0.124984 reg=0.001602
2017/08/30 22:29:37 step 5: objective=0.125030 reg=0.001601
2017/08/30 22:29:39 step 6: objective=0.125107 reg=0.001601
2017/08/30 22:29:41 step 7: objective=0.125176 reg=0.001601
2017/08/30 22:29:41 Training value function...
2017/08/30 22:29:45 step 0: mse=0.197848 step=0.050000
2017/08/30 22:29:46 step 1: mse=0.198380 step=0.050000
2017/08/30 22:29:48 step 2: mse=0.198876 step=0.050000
2017/08/30 22:29:49 step 3: mse=0.199244 step=0.050000
2017/08/30 22:29:50 step 4: mse=0.199474 step=0.050000
2017/08/30 22:29:52 step 5: mse=0.199987 step=0.050000
2017/08/30 22:29:53 step 6: mse=0.200390 step=0.050000
2017/08/30 22:29:55 step 7: mse=0.200860 step=0.050000
2017/08/30 22:29:55 Saving...
2017/08/30 22:29:55 Gathering batch of experience...
2017/08/30 22:30:35 batch 605: mean=34.133333 stddev=10.429872 entropy=0.156777 frames=7915 count=15
2017/08/30 22:30:35 Training policy...
2017/08/30 22:30:41 tune 0: objective=0.135974 reg=0.001568 prune=0
2017/08/30 22:30:43 step 0: objective=0.135974 reg=0.001568
2017/08/30 22:30:45 step 1: objective=0.136038 reg=0.001567
2017/08/30 22:30:47 step 2: objective=0.136125 reg=0.001566
2017/08/30 22:30:48 step 3: objective=0.136166 reg=0.001566
2017/08/30 22:30:50 step 4: objective=0.136223 reg=0.001566
2017/08/30 22:30:52 step 5: objective=0.136297 reg=0.001566
2017/08/30 22:30:54 step 6: objective=0.136350 reg=0.001567
2017/08/30 22:30:56 step 7: objective=0.136394 reg=0.001567
2017/08/30 22:30:56 Training value function...
2017/08/30 22:30:59 step 0: mse=0.210124 step=0.050000
2017/08/30 22:31:00 step 1: mse=0.209044 step=0.050000
2017/08/30 22:31:02 step 2: mse=0.208411 step=0.050000
2017/08/30 22:31:03 step 3: mse=0.207448 step=0.050000
2017/08/30 22:31:05 step 4: mse=0.207068 step=0.050000
2017/08/30 22:31:06 step 5: mse=0.206235 step=0.050000
2017/08/30 22:31:07 step 6: mse=0.206067 step=0.050000
2017/08/30 22:31:09 step 7: mse=0.205328 step=0.050000
2017/08/30 22:31:09 Saving...
2017/08/30 22:31:09 Gathering batch of experience...
2017/08/30 22:31:49 batch 606: mean=32.875000 stddev=12.180286 entropy=0.162246 frames=8127 count=16
2017/08/30 22:31:49 Training policy...
2017/08/30 22:31:56 tune 0: objective=0.132229 reg=0.001622 prune=0
2017/08/30 22:31:57 step 0: objective=0.132229 reg=0.001622
2017/08/30 22:31:59 step 1: objective=0.132274 reg=0.001623
2017/08/30 22:32:01 step 2: objective=0.132356 reg=0.001624
2017/08/30 22:32:03 step 3: objective=0.132419 reg=0.001625
2017/08/30 22:32:05 step 4: objective=0.132467 reg=0.001626
2017/08/30 22:32:07 step 5: objective=0.132529 reg=0.001626
2017/08/30 22:32:09 step 6: objective=0.132623 reg=0.001626
2017/08/30 22:32:10 step 7: objective=0.132705 reg=0.001627
2017/08/30 22:32:10 Training value function...
2017/08/30 22:32:14 step 0: mse=0.197780 step=0.050000
2017/08/30 22:32:15 step 1: mse=0.197503 step=0.050000
2017/08/30 22:32:17 step 2: mse=0.197246 step=0.050000
2017/08/30 22:32:18 step 3: mse=0.197154 step=0.050000
2017/08/30 22:32:20 step 4: mse=0.197043 step=0.050000
2017/08/30 22:32:21 step 5: mse=0.196920 step=0.050000
2017/08/30 22:32:22 step 6: mse=0.196782 step=0.050000
2017/08/30 22:32:24 step 7: mse=0.196611 step=0.050000
2017/08/30 22:32:24 Saving...
2017/08/30 22:32:24 Gathering batch of experience...
2017/08/30 22:33:05 batch 607: mean=28.944444 stddev=12.920579 entropy=0.158198 frames=8070 count=18
2017/08/30 22:33:05 Training policy...
2017/08/30 22:33:11 tune 0: objective=0.122812 reg=0.001582 prune=0
2017/08/30 22:33:13 step 0: objective=0.122811 reg=0.001582
2017/08/30 22:33:15 step 1: objective=0.122856 reg=0.001582
2017/08/30 22:33:16 step 2: objective=0.122906 reg=0.001583
2017/08/30 22:33:18 step 3: objective=0.122956 reg=0.001583
2017/08/30 22:33:20 step 4: objective=0.123003 reg=0.001583
2017/08/30 22:33:22 step 5: objective=0.123081 reg=0.001584
2017/08/30 22:33:24 step 6: objective=0.123115 reg=0.001583
2017/08/30 22:33:26 step 7: objective=0.123157 reg=0.001583
2017/08/30 22:33:26 Training value function...
2017/08/30 22:33:29 step 0: mse=0.205154 step=0.050000
2017/08/30 22:33:31 step 1: mse=0.206035 step=0.050000
2017/08/30 22:33:32 step 2: mse=0.206973 step=0.050000
2017/08/30 22:33:33 step 3: mse=0.207584 step=0.050000
2017/08/30 22:33:35 step 4: mse=0.208333 step=0.050000
2017/08/30 22:33:36 step 5: mse=0.209226 step=0.050000
2017/08/30 22:33:38 step 6: mse=0.209766 step=0.050000
2017/08/30 22:33:39 step 7: mse=0.210538 step=0.050000
2017/08/30 22:33:39 Saving...
2017/08/30 22:33:39 Gathering batch of experience...
2017/08/30 22:34:20 batch 608: mean=34.666667 stddev=11.169403 entropy=0.158357 frames=8008 count=15
2017/08/30 22:34:20 Training policy...
2017/08/30 22:34:26 tune 0: objective=0.140728 reg=0.001584 prune=0
2017/08/30 22:34:28 step 0: objective=0.140728 reg=0.001584
2017/08/30 22:34:30 step 1: objective=0.140797 reg=0.001584
2017/08/30 22:34:31 step 2: objective=0.140830 reg=0.001583
2017/08/30 22:34:33 step 3: objective=0.140891 reg=0.001583
2017/08/30 22:34:35 step 4: objective=0.140959 reg=0.001584
2017/08/30 22:34:37 step 5: objective=0.141024 reg=0.001584
2017/08/30 22:34:39 step 6: objective=0.141078 reg=0.001583
2017/08/30 22:34:41 step 7: objective=0.141142 reg=0.001584
2017/08/30 22:34:41 Training value function...
2017/08/30 22:34:44 step 0: mse=0.203007 step=0.050000
2017/08/30 22:34:45 step 1: mse=0.201282 step=0.050000
2017/08/30 22:34:47 step 2: mse=0.199774 step=0.050000
2017/08/30 22:34:48 step 3: mse=0.198368 step=0.050000
2017/08/30 22:34:50 step 4: mse=0.197413 step=0.050000
2017/08/30 22:34:51 step 5: mse=0.196620 step=0.050000
2017/08/30 22:34:52 step 6: mse=0.195773 step=0.050000
2017/08/30 22:34:54 step 7: mse=0.194795 step=0.050000
2017/08/30 22:34:54 Saving...
2017/08/30 22:34:54 Gathering batch of experience...
2017/08/30 22:35:37 batch 609: mean=29.833333 stddev=13.973189 entropy=0.158455 frames=8304 count=18
2017/08/30 22:35:37 Training policy...
2017/08/30 22:35:43 tune 0: objective=0.127001 reg=0.001585 prune=0
2017/08/30 22:35:45 step 0: objective=0.127001 reg=0.001585
2017/08/30 22:35:47 step 1: objective=0.127051 reg=0.001584
2017/08/30 22:35:49 step 2: objective=0.127116 reg=0.001585
2017/08/30 22:35:51 step 3: objective=0.127163 reg=0.001584
2017/08/30 22:35:52 step 4: objective=0.127214 reg=0.001584
2017/08/30 22:35:54 step 5: objective=0.127256 reg=0.001584
2017/08/30 22:35:56 step 6: objective=0.127290 reg=0.001584
2017/08/30 22:35:58 step 7: objective=0.127320 reg=0.001585
2017/08/30 22:35:58 Training value function...
2017/08/30 22:36:02 step 0: mse=0.197859 step=0.050000
2017/08/30 22:36:03 step 1: mse=0.198148 step=0.050000
2017/08/30 22:36:05 step 2: mse=0.198252 step=0.050000
2017/08/30 22:36:06 step 3: mse=0.198394 step=0.050000
2017/08/30 22:36:08 step 4: mse=0.198659 step=0.050000
2017/08/30 22:36:09 step 5: mse=0.198704 step=0.050000
2017/08/30 22:36:11 step 6: mse=0.198916 step=0.050000
2017/08/30 22:36:12 step 7: mse=0.199169 step=0.050000
2017/08/30 22:36:12 Saving...
2017/08/30 22:36:12 Gathering batch of experience...
2017/08/30 22:36:54 batch 610: mean=34.562500 stddev=9.387284 entropy=0.160520 frames=8516 count=16
2017/08/30 22:36:54 Training policy...
2017/08/30 22:37:01 tune 0: objective=0.136529 reg=0.001605 prune=0
2017/08/30 22:37:03 step 0: objective=0.136529 reg=0.001605
2017/08/30 22:37:05 step 1: objective=0.136570 reg=0.001605
2017/08/30 22:37:07 step 2: objective=0.136594 reg=0.001605
2017/08/30 22:37:09 step 3: objective=0.136639 reg=0.001605
2017/08/30 22:37:11 step 4: objective=0.136682 reg=0.001605
2017/08/30 22:37:13 step 5: objective=0.136730 reg=0.001604
2017/08/30 22:37:15 step 6: objective=0.136763 reg=0.001604
2017/08/30 22:37:16 step 7: objective=0.136807 reg=0.001604
2017/08/30 22:37:16 Training value function...
2017/08/30 22:37:20 step 0: mse=0.197965 step=0.050000
2017/08/30 22:37:22 step 1: mse=0.197182 step=0.050000
2017/08/30 22:37:23 step 2: mse=0.196502 step=0.050000
2017/08/30 22:37:25 step 3: mse=0.195932 step=0.050000
2017/08/30 22:37:26 step 4: mse=0.195713 step=0.050000
2017/08/30 22:37:27 step 5: mse=0.195306 step=0.050000
2017/08/30 22:37:29 step 6: mse=0.194518 step=0.050000
2017/08/30 22:37:30 step 7: mse=0.194266 step=0.050000
2017/08/30 22:37:30 Saving...
2017/08/30 22:37:30 Gathering batch of experience...
2017/08/30 22:38:13 batch 611: mean=37.733333 stddev=4.739433 entropy=0.156823 frames=8720 count=15
2017/08/30 22:38:13 Training policy...
2017/08/30 22:38:20 tune 0: objective=0.139477 reg=0.001568 prune=0
2017/08/30 22:38:22 step 0: objective=0.139477 reg=0.001568
2017/08/30 22:38:24 step 1: objective=0.139566 reg=0.001568
2017/08/30 22:38:26 step 2: objective=0.139643 reg=0.001568
2017/08/30 22:38:28 step 3: objective=0.139758 reg=0.001568
2017/08/30 22:38:30 step 4: objective=0.139818 reg=0.001568
2017/08/30 22:38:32 step 5: objective=0.139901 reg=0.001567
2017/08/30 22:38:34 step 6: objective=0.139980 reg=0.001567
2017/08/30 22:38:36 step 7: objective=0.140052 reg=0.001567
2017/08/30 22:38:36 Training value function...
2017/08/30 22:38:40 step 0: mse=0.197666 step=0.050000
2017/08/30 22:38:41 step 1: mse=0.196461 step=0.050000
2017/08/30 22:38:43 step 2: mse=0.195492 step=0.050000
2017/08/30 22:38:44 step 3: mse=0.194085 step=0.050000
2017/08/30 22:38:46 step 4: mse=0.193461 step=0.050000
2017/08/30 22:38:47 step 5: mse=0.192477 step=0.050000
2017/08/30 22:38:49 step 6: mse=0.191300 step=0.050000
2017/08/30 22:38:50 step 7: mse=0.190523 step=0.050000
2017/08/30 22:38:50 Saving...
2017/08/30 22:38:50 Gathering batch of experience...
2017/08/30 22:39:32 batch 612: mean=30.941176 stddev=12.021895 entropy=0.160374 frames=8121 count=17
2017/08/30 22:39:32 Training policy...
2017/08/30 22:39:38 tune 0: objective=0.124358 reg=0.001604 prune=0
2017/08/30 22:39:39 step 0: objective=0.124358 reg=0.001604
2017/08/30 22:39:41 step 1: objective=0.124405 reg=0.001603
2017/08/30 22:39:43 step 2: objective=0.124495 reg=0.001603
2017/08/30 22:39:45 step 3: objective=0.124556 reg=0.001603
2017/08/30 22:39:47 step 4: objective=0.124622 reg=0.001602
2017/08/30 22:39:49 step 5: objective=0.124679 reg=0.001602
2017/08/30 22:39:51 step 6: objective=0.124744 reg=0.001602
2017/08/30 22:39:53 step 7: objective=0.124793 reg=0.001602
2017/08/30 22:39:53 Training value function...
2017/08/30 22:39:56 step 0: mse=0.190397 step=0.050000
2017/08/30 22:39:57 step 1: mse=0.191081 step=0.050000
2017/08/30 22:39:59 step 2: mse=0.191611 step=0.050000
2017/08/30 22:40:00 step 3: mse=0.192100 step=0.050000
2017/08/30 22:40:02 step 4: mse=0.192323 step=0.050000
2017/08/30 22:40:03 step 5: mse=0.192805 step=0.050000
2017/08/30 22:40:05 step 6: mse=0.192972 step=0.050000
2017/08/30 22:40:06 step 7: mse=0.193287 step=0.050000
2017/08/30 22:40:06 Saving...
2017/08/30 22:40:06 Gathering batch of experience...
2017/08/30 22:40:46 batch 613: mean=34.000000 stddev=8.148620 entropy=0.159478 frames=7888 count=15
2017/08/30 22:40:46 Training policy...
2017/08/30 22:40:52 tune 0: objective=0.126786 reg=0.001595 prune=0
2017/08/30 22:40:54 step 0: objective=0.126786 reg=0.001595
2017/08/30 22:40:56 step 1: objective=0.126847 reg=0.001595
2017/08/30 22:40:58 step 2: objective=0.126918 reg=0.001594
2017/08/30 22:41:00 step 3: objective=0.126968 reg=0.001594
2017/08/30 22:41:01 step 4: objective=0.127007 reg=0.001594
2017/08/30 22:41:03 step 5: objective=0.127075 reg=0.001594
2017/08/30 22:41:05 step 6: objective=0.127113 reg=0.001594
2017/08/30 22:41:07 step 7: objective=0.127248 reg=0.001594
2017/08/30 22:41:07 Training value function...
2017/08/30 22:41:10 step 0: mse=0.195488 step=0.050000
2017/08/30 22:41:12 step 1: mse=0.195587 step=0.050000
2017/08/30 22:41:13 step 2: mse=0.195742 step=0.050000
2017/08/30 22:41:14 step 3: mse=0.195937 step=0.050000
2017/08/30 22:41:16 step 4: mse=0.196201 step=0.050000
2017/08/30 22:41:17 step 5: mse=0.196578 step=0.050000
2017/08/30 22:41:19 step 6: mse=0.196951 step=0.050000
2017/08/30 22:41:20 step 7: mse=0.197231 step=0.050000
2017/08/30 22:41:20 Saving...
2017/08/30 22:41:20 Gathering batch of experience...
2017/08/30 22:42:01 batch 614: mean=28.611111 stddev=12.715428 entropy=0.162725 frames=7983 count=18
2017/08/30 22:42:01 Training policy...
2017/08/30 22:42:07 tune 0: objective=0.120671 reg=0.001627 prune=0
2017/08/30 22:42:09 step 0: objective=0.120671 reg=0.001627
2017/08/30 22:42:11 step 1: objective=0.120734 reg=0.001627
2017/08/30 22:42:12 step 2: objective=0.120790 reg=0.001627
2017/08/30 22:42:14 step 3: objective=0.120845 reg=0.001627
2017/08/30 22:42:16 step 4: objective=0.120939 reg=0.001626
2017/08/30 22:42:18 step 5: objective=0.120970 reg=0.001626
2017/08/30 22:42:20 step 6: objective=0.120999 reg=0.001626
2017/08/30 22:42:22 step 7: objective=0.121046 reg=0.001626
2017/08/30 22:42:22 Training value function...
2017/08/30 22:42:25 step 0: mse=0.202272 step=0.050000
2017/08/30 22:42:26 step 1: mse=0.203125 step=0.050000
2017/08/30 22:42:28 step 2: mse=0.203884 step=0.050000
2017/08/30 22:42:29 step 3: mse=0.204462 step=0.050000
2017/08/30 22:42:31 step 4: mse=0.205334 step=0.050000
2017/08/30 22:42:32 step 5: mse=0.205999 step=0.050000
2017/08/30 22:42:34 step 6: mse=0.206610 step=0.050000
2017/08/30 22:42:35 step 7: mse=0.207065 step=0.050000
2017/08/30 22:42:35 Saving...
2017/08/30 22:42:35 Gathering batch of experience...
2017/08/30 22:43:21 batch 615: mean=28.473684 stddev=13.311524 entropy=0.157866 frames=8363 count=19
2017/08/30 22:43:21 Training policy...
2017/08/30 22:43:27 tune 0: objective=0.127264 reg=0.001579 prune=0
2017/08/30 22:43:29 step 0: objective=0.127265 reg=0.001579
2017/08/30 22:43:31 step 1: objective=0.127303 reg=0.001579
2017/08/30 22:43:33 step 2: objective=0.127347 reg=0.001579
2017/08/30 22:43:35 step 3: objective=0.127420 reg=0.001580
2017/08/30 22:43:37 step 4: objective=0.127522 reg=0.001582
2017/08/30 22:43:39 step 5: objective=0.127568 reg=0.001581
2017/08/30 22:43:40 step 6: objective=0.127631 reg=0.001582
2017/08/30 22:43:42 step 7: objective=0.127710 reg=0.001581
2017/08/30 22:43:42 Training value function...
2017/08/30 22:43:46 step 0: mse=0.206759 step=0.050000
2017/08/30 22:43:47 step 1: mse=0.207051 step=0.050000
2017/08/30 22:43:49 step 2: mse=0.207450 step=0.050000
2017/08/30 22:43:50 step 3: mse=0.207808 step=0.050000
2017/08/30 22:43:52 step 4: mse=0.208379 step=0.050000
2017/08/30 22:43:53 step 5: mse=0.208781 step=0.050000
2017/08/30 22:43:55 step 6: mse=0.209268 step=0.050000
2017/08/30 22:43:56 step 7: mse=0.209203 step=0.050000
2017/08/30 22:43:56 Saving...
2017/08/30 22:43:56 Gathering batch of experience...
2017/08/30 22:44:39 batch 616: mean=32.294118 stddev=11.374712 entropy=0.160517 frames=8487 count=17
2017/08/30 22:44:39 Training policy...
2017/08/30 22:44:45 tune 0: objective=0.135296 reg=0.001605 prune=0
2017/08/30 22:44:47 step 0: objective=0.135296 reg=0.001605
2017/08/30 22:44:49 step 1: objective=0.135351 reg=0.001605
2017/08/30 22:44:51 step 2: objective=0.135428 reg=0.001605
2017/08/30 22:44:53 step 3: objective=0.135517 reg=0.001605
2017/08/30 22:44:55 step 4: objective=0.135589 reg=0.001605
2017/08/30 22:44:57 step 5: objective=0.135639 reg=0.001605
2017/08/30 22:44:59 step 6: objective=0.135691 reg=0.001605
2017/08/30 22:45:01 step 7: objective=0.135757 reg=0.001605
2017/08/30 22:45:01 Training value function...
2017/08/30 22:45:04 step 0: mse=0.214630 step=0.050000
2017/08/30 22:45:06 step 1: mse=0.213980 step=0.050000
2017/08/30 22:45:07 step 2: mse=0.213799 step=0.050000
2017/08/30 22:45:09 step 3: mse=0.213487 step=0.050000
2017/08/30 22:45:10 step 4: mse=0.212879 step=0.050000
2017/08/30 22:45:12 step 5: mse=0.212541 step=0.050000
2017/08/30 22:45:13 step 6: mse=0.211923 step=0.050000
2017/08/30 22:45:15 step 7: mse=0.211654 step=0.050000
2017/08/30 22:45:15 Saving...
2017/08/30 22:45:15 Gathering batch of experience...
2017/08/30 22:45:55 batch 617: mean=36.571429 stddev=7.480587 entropy=0.155638 frames=7892 count=14
2017/08/30 22:45:55 Training policy...
2017/08/30 22:46:01 tune 0: objective=0.140736 reg=0.001556 prune=0
2017/08/30 22:46:03 step 0: objective=0.140736 reg=0.001556
2017/08/30 22:46:05 step 1: objective=0.140821 reg=0.001557
2017/08/30 22:46:06 step 2: objective=0.140884 reg=0.001557
2017/08/30 22:46:08 step 3: objective=0.140955 reg=0.001558
2017/08/30 22:46:10 step 4: objective=0.141040 reg=0.001559
2017/08/30 22:46:12 step 5: objective=0.141139 reg=0.001559
2017/08/30 22:46:14 step 6: objective=0.141172 reg=0.001559
2017/08/30 22:46:16 step 7: objective=0.141222 reg=0.001560
2017/08/30 22:46:16 Training value function...
2017/08/30 22:46:19 step 0: mse=0.204733 step=0.050000
2017/08/30 22:46:20 step 1: mse=0.203690 step=0.050000
2017/08/30 22:46:22 step 2: mse=0.202146 step=0.050000
2017/08/30 22:46:23 step 3: mse=0.200576 step=0.050000
2017/08/30 22:46:24 step 4: mse=0.199188 step=0.050000
2017/08/30 22:46:26 step 5: mse=0.197828 step=0.050000
2017/08/30 22:46:27 step 6: mse=0.196424 step=0.050000
2017/08/30 22:46:29 step 7: mse=0.194907 step=0.050000
2017/08/30 22:46:29 Saving...
2017/08/30 22:46:29 Gathering batch of experience...
2017/08/30 22:47:13 batch 618: mean=33.117647 stddev=11.559983 entropy=0.160622 frames=8693 count=17
2017/08/30 22:47:13 Training policy...
2017/08/30 22:47:20 tune 0: objective=0.132478 reg=0.001606 prune=0
2017/08/30 22:47:22 step 0: objective=0.132477 reg=0.001606
2017/08/30 22:47:24 step 1: objective=0.132542 reg=0.001606
2017/08/30 22:47:26 step 2: objective=0.132596 reg=0.001606
2017/08/30 22:47:28 step 3: objective=0.132672 reg=0.001605
2017/08/30 22:47:30 step 4: objective=0.132768 reg=0.001605
2017/08/30 22:47:32 step 5: objective=0.132807 reg=0.001605
2017/08/30 22:47:34 step 6: objective=0.132860 reg=0.001604
2017/08/30 22:47:36 step 7: objective=0.132913 reg=0.001604
2017/08/30 22:47:36 Training value function...
2017/08/30 22:47:40 step 0: mse=0.200079 step=0.050000
2017/08/30 22:47:41 step 1: mse=0.199615 step=0.050000
2017/08/30 22:47:43 step 2: mse=0.199199 step=0.050000
2017/08/30 22:47:44 step 3: mse=0.198766 step=0.050000
2017/08/30 22:47:46 step 4: mse=0.198411 step=0.050000
2017/08/30 22:47:47 step 5: mse=0.198296 step=0.050000
2017/08/30 22:47:49 step 6: mse=0.198180 step=0.050000
2017/08/30 22:47:50 step 7: mse=0.198159 step=0.050000
2017/08/30 22:47:50 Saving...
2017/08/30 22:47:50 Gathering batch of experience...
2017/08/30 22:48:30 batch 619: mean=30.625000 stddev=13.765332 entropy=0.160964 frames=7574 count=16
2017/08/30 22:48:30 Training policy...
2017/08/30 22:48:36 tune 0: objective=0.127578 reg=0.001610 prune=0
2017/08/30 22:48:37 step 0: objective=0.127578 reg=0.001610
2017/08/30 22:48:39 step 1: objective=0.127637 reg=0.001609
2017/08/30 22:48:41 step 2: objective=0.127741 reg=0.001609
2017/08/30 22:48:43 step 3: objective=0.127801 reg=0.001609
2017/08/30 22:48:44 step 4: objective=0.127857 reg=0.001610
2017/08/30 22:48:46 step 5: objective=0.127917 reg=0.001610
2017/08/30 22:48:48 step 6: objective=0.127986 reg=0.001609
2017/08/30 22:48:50 step 7: objective=0.128051 reg=0.001610
2017/08/30 22:48:50 Training value function...
2017/08/30 22:48:53 step 0: mse=0.195905 step=0.050000
2017/08/30 22:48:54 step 1: mse=0.196223 step=0.050000
2017/08/30 22:48:56 step 2: mse=0.196443 step=0.050000
2017/08/30 22:48:57 step 3: mse=0.196569 step=0.050000
2017/08/30 22:48:58 step 4: mse=0.196739 step=0.050000
2017/08/30 22:49:00 step 5: mse=0.196927 step=0.050000
2017/08/30 22:49:01 step 6: mse=0.197024 step=0.050000
2017/08/30 22:49:02 step 7: mse=0.197156 step=0.050000
2017/08/30 22:49:02 Saving...
2017/08/30 22:49:02 Gathering batch of experience...
2017/08/30 22:49:43 batch 620: mean=29.294118 stddev=14.082800 entropy=0.159510 frames=7695 count=17
2017/08/30 22:49:43 Training policy...
2017/08/30 22:49:48 tune 0: objective=0.127349 reg=0.001595 prune=0
2017/08/30 22:49:50 step 0: objective=0.127349 reg=0.001595
2017/08/30 22:49:52 step 1: objective=0.127399 reg=0.001595
2017/08/30 22:49:54 step 2: objective=0.127454 reg=0.001596
2017/08/30 22:49:56 step 3: objective=0.127516 reg=0.001596
2017/08/30 22:49:57 step 4: objective=0.127611 reg=0.001596
2017/08/30 22:49:59 step 5: objective=0.127649 reg=0.001596
2017/08/30 22:50:01 step 6: objective=0.127713 reg=0.001595
2017/08/30 22:50:03 step 7: objective=0.127750 reg=0.001595
2017/08/30 22:50:03 Training value function...
2017/08/30 22:50:06 step 0: mse=0.200998 step=0.050000
2017/08/30 22:50:07 step 1: mse=0.201476 step=0.050000
2017/08/30 22:50:09 step 2: mse=0.201992 step=0.050000
2017/08/30 22:50:10 step 3: mse=0.202075 step=0.050000
2017/08/30 22:50:11 step 4: mse=0.202348 step=0.050000
2017/08/30 22:50:13 step 5: mse=0.202713 step=0.050000
2017/08/30 22:50:14 step 6: mse=0.202977 step=0.050000
2017/08/30 22:50:15 step 7: mse=0.203353 step=0.050000
2017/08/30 22:50:15 Saving...
2017/08/30 22:50:15 Gathering batch of experience...
2017/08/30 22:50:56 batch 621: mean=28.833333 stddev=14.419316 entropy=0.159468 frames=8012 count=18
2017/08/30 22:50:56 Training policy...
2017/08/30 22:51:02 tune 0: objective=0.130269 reg=0.001595 prune=0
2017/08/30 22:51:04 step 0: objective=0.130269 reg=0.001595
2017/08/30 22:51:06 step 1: objective=0.130312 reg=0.001595
2017/08/30 22:51:08 step 2: objective=0.130357 reg=0.001595
2017/08/30 22:51:10 step 3: objective=0.130396 reg=0.001595
2017/08/30 22:51:12 step 4: objective=0.130427 reg=0.001596
2017/08/30 22:51:13 step 5: objective=0.130511 reg=0.001597
2017/08/30 22:51:15 step 6: objective=0.130548 reg=0.001597
2017/08/30 22:51:17 step 7: objective=0.130578 reg=0.001597
2017/08/30 22:51:17 Training value function...
2017/08/30 22:51:21 step 0: mse=0.198954 step=0.050000
2017/08/30 22:51:22 step 1: mse=0.198949 step=0.050000
2017/08/30 22:51:23 step 2: mse=0.198987 step=0.050000
2017/08/30 22:51:25 step 3: mse=0.199048 step=0.050000
2017/08/30 22:51:26 step 4: mse=0.198946 step=0.050000
2017/08/30 22:51:28 step 5: mse=0.198921 step=0.050000
2017/08/30 22:51:29 step 6: mse=0.198987 step=0.050000
2017/08/30 22:51:30 step 7: mse=0.199097 step=0.050000
2017/08/30 22:51:30 Saving...
2017/08/30 22:51:30 Gathering batch of experience...
2017/08/30 22:52:12 batch 622: mean=29.944444 stddev=12.967790 entropy=0.159802 frames=8342 count=18
2017/08/30 22:52:12 Training policy...
2017/08/30 22:52:18 tune 0: objective=0.125748 reg=0.001598 prune=0
2017/08/30 22:52:20 step 0: objective=0.125748 reg=0.001598
2017/08/30 22:52:22 step 1: objective=0.125820 reg=0.001599
2017/08/30 22:52:24 step 2: objective=0.125881 reg=0.001598
2017/08/30 22:52:26 step 3: objective=0.125947 reg=0.001599
2017/08/30 22:52:28 step 4: objective=0.126008 reg=0.001600
2017/08/30 22:52:30 step 5: objective=0.126141 reg=0.001600
2017/08/30 22:52:32 step 6: objective=0.126187 reg=0.001600
2017/08/30 22:52:34 step 7: objective=0.126277 reg=0.001601
2017/08/30 22:52:34 Training value function...
2017/08/30 22:52:37 step 0: mse=0.206237 step=0.050000
2017/08/30 22:52:39 step 1: mse=0.206544 step=0.050000
2017/08/30 22:52:40 step 2: mse=0.206799 step=0.050000
2017/08/30 22:52:42 step 3: mse=0.206879 step=0.050000
2017/08/30 22:52:43 step 4: mse=0.207041 step=0.050000
2017/08/30 22:52:45 step 5: mse=0.207351 step=0.050000
2017/08/30 22:52:46 step 6: mse=0.207469 step=0.050000
2017/08/30 22:52:48 step 7: mse=0.207579 step=0.050000
2017/08/30 22:52:48 Saving...
2017/08/30 22:52:48 Gathering batch of experience...
2017/08/30 22:53:30 batch 623: mean=34.125000 stddev=8.781194 entropy=0.163548 frames=8439 count=16
2017/08/30 22:53:30 Training policy...
2017/08/30 22:53:36 tune 0: objective=0.134367 reg=0.001635 prune=0
2017/08/30 22:53:38 step 0: objective=0.134367 reg=0.001635
2017/08/30 22:53:40 step 1: objective=0.134423 reg=0.001635
2017/08/30 22:53:42 step 2: objective=0.134495 reg=0.001636
2017/08/30 22:53:44 step 3: objective=0.134565 reg=0.001636
2017/08/30 22:53:46 step 4: objective=0.134615 reg=0.001636
2017/08/30 22:53:48 step 5: objective=0.134685 reg=0.001636
2017/08/30 22:53:50 step 6: objective=0.134730 reg=0.001637
2017/08/30 22:53:52 step 7: objective=0.134775 reg=0.001637
2017/08/30 22:53:52 Training value function...
2017/08/30 22:53:56 step 0: mse=0.208979 step=0.050000
2017/08/30 22:53:57 step 1: mse=0.208120 step=0.050000
2017/08/30 22:53:59 step 2: mse=0.207412 step=0.050000
2017/08/30 22:54:00 step 3: mse=0.206812 step=0.050000
2017/08/30 22:54:01 step 4: mse=0.206484 step=0.050000
2017/08/30 22:54:03 step 5: mse=0.205840 step=0.050000
2017/08/30 22:54:04 step 6: mse=0.205454 step=0.050000
2017/08/30 22:54:06 step 7: mse=0.205174 step=0.050000
2017/08/30 22:54:06 Saving...
2017/08/30 22:54:06 Gathering batch of experience...
2017/08/30 22:54:46 batch 624: mean=29.437500 stddev=11.757810 entropy=0.164055 frames=7295 count=16
2017/08/30 22:54:46 Training policy...
2017/08/30 22:54:51 tune 0: objective=0.124705 reg=0.001641 prune=0
2017/08/30 22:54:53 step 0: objective=0.124705 reg=0.001641
2017/08/30 22:54:54 step 1: objective=0.124761 reg=0.001640
2017/08/30 22:54:56 step 2: objective=0.124830 reg=0.001639
2017/08/30 22:54:58 step 3: objective=0.124939 reg=0.001639
2017/08/30 22:55:00 step 4: objective=0.125014 reg=0.001639
2017/08/30 22:55:01 step 5: objective=0.125070 reg=0.001640
2017/08/30 22:55:03 step 6: objective=0.125121 reg=0.001640
2017/08/30 22:55:05 step 7: objective=0.125163 reg=0.001640
2017/08/30 22:55:05 Training value function...
2017/08/30 22:55:08 step 0: mse=0.207636 step=0.050000
2017/08/30 22:55:09 step 1: mse=0.208149 step=0.050000
2017/08/30 22:55:10 step 2: mse=0.208709 step=0.050000
2017/08/30 22:55:11 step 3: mse=0.209427 step=0.050000
2017/08/30 22:55:13 step 4: mse=0.210030 step=0.050000
2017/08/30 22:55:14 step 5: mse=0.210844 step=0.050000
2017/08/30 22:55:15 step 6: mse=0.211539 step=0.050000
2017/08/30 22:55:17 step 7: mse=0.211686 step=0.050000
2017/08/30 22:55:17 Saving...
2017/08/30 22:55:17 Gathering batch of experience...
2017/08/30 22:55:56 batch 625: mean=33.000000 stddev=12.312595 entropy=0.160433 frames=7637 count=15
2017/08/30 22:55:56 Training policy...
2017/08/30 22:56:02 tune 0: objective=0.138543 reg=0.001604 prune=0
2017/08/30 22:56:04 step 0: objective=0.138543 reg=0.001604
2017/08/30 22:56:06 step 1: objective=0.138690 reg=0.001604
2017/08/30 22:56:08 step 2: objective=0.138739 reg=0.001604
2017/08/30 22:56:09 step 3: objective=0.138784 reg=0.001604
2017/08/30 22:56:11 step 4: objective=0.138894 reg=0.001604
2017/08/30 22:56:13 step 5: objective=0.138980 reg=0.001604
2017/08/30 22:56:15 step 6: objective=0.139012 reg=0.001604
2017/08/30 22:56:16 step 7: objective=0.139106 reg=0.001604
2017/08/30 22:56:16 Training value function...
2017/08/30 22:56:20 step 0: mse=0.211064 step=0.050000
2017/08/30 22:56:21 step 1: mse=0.209741 step=0.050000
2017/08/30 22:56:22 step 2: mse=0.208437 step=0.050000
2017/08/30 22:56:24 step 3: mse=0.206938 step=0.050000
2017/08/30 22:56:25 step 4: mse=0.205753 step=0.050000
2017/08/30 22:56:26 step 5: mse=0.204557 step=0.050000
2017/08/30 22:56:27 step 6: mse=0.203558 step=0.050000
2017/08/30 22:56:29 step 7: mse=0.202300 step=0.050000
2017/08/30 22:56:29 Saving...
2017/08/30 22:56:29 Gathering batch of experience...
2017/08/30 22:57:12 batch 626: mean=37.733333 stddev=4.739433 entropy=0.160391 frames=8720 count=15
2017/08/30 22:57:12 Training policy...
2017/08/30 22:57:18 tune 0: objective=0.141689 reg=0.001604 prune=0
2017/08/30 22:57:20 step 0: objective=0.141689 reg=0.001604
2017/08/30 22:57:22 step 1: objective=0.141739 reg=0.001604
2017/08/30 22:57:24 step 2: objective=0.141797 reg=0.001605
2017/08/30 22:57:26 step 3: objective=0.141854 reg=0.001605
2017/08/30 22:57:29 step 4: objective=0.141904 reg=0.001605
2017/08/30 22:57:31 step 5: objective=0.141961 reg=0.001605
2017/08/30 22:57:33 step 6: objective=0.142030 reg=0.001605
2017/08/30 22:57:35 step 7: objective=0.142083 reg=0.001605
2017/08/30 22:57:35 Training value function...
2017/08/30 22:57:38 step 0: mse=0.203575 step=0.050000
2017/08/30 22:57:40 step 1: mse=0.201605 step=0.050000
2017/08/30 22:57:41 step 2: mse=0.200194 step=0.050000
2017/08/30 22:57:43 step 3: mse=0.198789 step=0.050000
2017/08/30 22:57:44 step 4: mse=0.197394 step=0.050000
2017/08/30 22:57:46 step 5: mse=0.195858 step=0.050000
2017/08/30 22:57:47 step 6: mse=0.194714 step=0.050000
2017/08/30 22:57:49 step 7: mse=0.193570 step=0.050000
2017/08/30 22:57:49 Saving...
2017/08/30 22:57:49 Gathering batch of experience...
2017/08/30 22:58:30 batch 627: mean=34.600000 stddev=9.031796 entropy=0.157557 frames=8014 count=15
2017/08/30 22:58:30 Training policy...
2017/08/30 22:58:36 tune 0: objective=0.130928 reg=0.001576 prune=0
2017/08/30 22:58:38 step 0: objective=0.130928 reg=0.001576
2017/08/30 22:58:40 step 1: objective=0.130965 reg=0.001576
2017/08/30 22:58:41 step 2: objective=0.131041 reg=0.001575
2017/08/30 22:58:43 step 3: objective=0.131136 reg=0.001575
2017/08/30 22:58:45 step 4: objective=0.131196 reg=0.001575
2017/08/30 22:58:47 step 5: objective=0.131267 reg=0.001574
2017/08/30 22:58:49 step 6: objective=0.131302 reg=0.001574
2017/08/30 22:58:51 step 7: objective=0.131338 reg=0.001573
2017/08/30 22:58:51 Training value function...
2017/08/30 22:58:54 step 0: mse=0.191587 step=0.050000
2017/08/30 22:58:56 step 1: mse=0.191275 step=0.050000
2017/08/30 22:58:57 step 2: mse=0.191290 step=0.050000
2017/08/30 22:58:58 step 3: mse=0.191330 step=0.050000
2017/08/30 22:59:00 step 4: mse=0.191201 step=0.050000
2017/08/30 22:59:01 step 5: mse=0.191104 step=0.050000
2017/08/30 22:59:03 step 6: mse=0.191355 step=0.050000
2017/08/30 22:59:04 step 7: mse=0.190818 step=0.050000
2017/08/30 22:59:04 Saving...
2017/08/30 22:59:04 Gathering batch of experience...
2017/08/30 22:59:45 batch 628: mean=33.187500 stddev=10.800571 entropy=0.159596 frames=8200 count=16
2017/08/30 22:59:45 Training policy...
2017/08/30 22:59:51 tune 0: objective=0.129331 reg=0.001596 prune=0
2017/08/30 22:59:53 step 0: objective=0.129331 reg=0.001596
2017/08/30 22:59:55 step 1: objective=0.129402 reg=0.001595
2017/08/30 22:59:57 step 2: objective=0.129449 reg=0.001594
2017/08/30 22:59:59 step 3: objective=0.129486 reg=0.001593
2017/08/30 23:00:01 step 4: objective=0.129583 reg=0.001592
2017/08/30 23:00:03 step 5: objective=0.129642 reg=0.001592
2017/08/30 23:00:05 step 6: objective=0.129701 reg=0.001591
2017/08/30 23:00:07 step 7: objective=0.129807 reg=0.001591
2017/08/30 23:00:07 Training value function...
2017/08/30 23:00:10 step 0: mse=0.192396 step=0.050000
2017/08/30 23:00:12 step 1: mse=0.192519 step=0.050000
2017/08/30 23:00:13 step 2: mse=0.192692 step=0.050000
2017/08/30 23:00:14 step 3: mse=0.192694 step=0.050000
2017/08/30 23:00:16 step 4: mse=0.192601 step=0.050000
2017/08/30 23:00:17 step 5: mse=0.192196 step=0.050000
2017/08/30 23:00:19 step 6: mse=0.192432 step=0.050000
2017/08/30 23:00:20 step 7: mse=0.192298 step=0.050000
2017/08/30 23:00:20 Saving...
2017/08/30 23:00:20 Gathering batch of experience...
2017/08/30 23:01:05 batch 629: mean=33.823529 stddev=10.939595 entropy=0.158440 frames=8875 count=17
2017/08/30 23:01:05 Training policy...
2017/08/30 23:01:12 tune 0: objective=0.132201 reg=0.001584 prune=0
2017/08/30 23:01:14 step 0: objective=0.132201 reg=0.001584
2017/08/30 23:01:16 step 1: objective=0.132343 reg=0.001585
2017/08/30 23:01:18 step 2: objective=0.132479 reg=0.001585
2017/08/30 23:01:21 step 3: objective=0.132567 reg=0.001584
2017/08/30 23:01:23 step 4: objective=0.132619 reg=0.001584
2017/08/30 23:01:25 step 5: objective=0.132706 reg=0.001584
2017/08/30 23:01:27 step 6: objective=0.132749 reg=0.001584
2017/08/30 23:01:29 step 7: objective=0.132775 reg=0.001584
2017/08/30 23:01:29 Training value function...
2017/08/30 23:01:33 step 0: mse=0.192837 step=0.050000
2017/08/30 23:01:34 step 1: mse=0.192325 step=0.050000
2017/08/30 23:01:36 step 2: mse=0.192293 step=0.050000
2017/08/30 23:01:37 step 3: mse=0.191849 step=0.050000
2017/08/30 23:01:39 step 4: mse=0.191338 step=0.050000
2017/08/30 23:01:40 step 5: mse=0.190753 step=0.050000
2017/08/30 23:01:42 step 6: mse=0.190361 step=0.050000
2017/08/30 23:01:43 step 7: mse=0.190421 step=0.050000
2017/08/30 23:01:43 Saving...
2017/08/30 23:01:44 Gathering batch of experience...
2017/08/30 23:02:25 batch 630: mean=35.333333 stddev=6.257440 entropy=0.160160 frames=8198 count=15
2017/08/30 23:02:25 Training policy...
2017/08/30 23:02:31 tune 0: objective=0.127467 reg=0.001602 prune=0
2017/08/30 23:02:33 step 0: objective=0.127468 reg=0.001602
2017/08/30 23:02:35 step 1: objective=0.127533 reg=0.001603
2017/08/30 23:02:37 step 2: objective=0.127602 reg=0.001604
2017/08/30 23:02:39 step 3: objective=0.127659 reg=0.001605
2017/08/30 23:02:41 step 4: objective=0.127698 reg=0.001606
2017/08/30 23:02:43 step 5: objective=0.127736 reg=0.001607
2017/08/30 23:02:45 step 6: objective=0.127769 reg=0.001607
2017/08/30 23:02:47 step 7: objective=0.127807 reg=0.001607
2017/08/30 23:02:47 Training value function...
2017/08/30 23:02:50 step 0: mse=0.197653 step=0.050000
2017/08/30 23:02:51 step 1: mse=0.197739 step=0.050000
2017/08/30 23:02:53 step 2: mse=0.197629 step=0.050000
2017/08/30 23:02:54 step 3: mse=0.197630 step=0.050000
2017/08/30 23:02:56 step 4: mse=0.197995 step=0.050000
2017/08/30 23:02:57 step 5: mse=0.198094 step=0.050000
2017/08/30 23:02:59 step 6: mse=0.198028 step=0.050000
2017/08/30 23:03:00 step 7: mse=0.198107 step=0.050000
2017/08/30 23:03:00 Saving...
2017/08/30 23:03:00 Gathering batch of experience...
2017/08/30 23:03:43 batch 631: mean=23.434783 stddev=15.310769 entropy=0.164014 frames=8370 count=23
2017/08/30 23:03:43 Training policy...
2017/08/30 23:03:49 tune 0: objective=0.108668 reg=0.001640 prune=0
2017/08/30 23:03:51 step 0: objective=0.108668 reg=0.001640
2017/08/30 23:03:53 step 1: objective=0.108785 reg=0.001640
2017/08/30 23:03:55 step 2: objective=0.108874 reg=0.001640
2017/08/30 23:03:57 step 3: objective=0.108992 reg=0.001640
2017/08/30 23:03:59 step 4: objective=0.109080 reg=0.001640
2017/08/30 23:04:01 step 5: objective=0.109135 reg=0.001640
2017/08/30 23:04:03 step 6: objective=0.109205 reg=0.001640
2017/08/30 23:04:05 step 7: objective=0.109267 reg=0.001640
2017/08/30 23:04:05 Training value function...
2017/08/30 23:04:09 step 0: mse=0.206284 step=0.050000
2017/08/30 23:04:10 step 1: mse=0.207076 step=0.050000
2017/08/30 23:04:11 step 2: mse=0.207817 step=0.050000
2017/08/30 23:04:13 step 3: mse=0.208382 step=0.050000
2017/08/30 23:04:14 step 4: mse=0.208978 step=0.050000
2017/08/30 23:04:16 step 5: mse=0.209801 step=0.050000
2017/08/30 23:04:17 step 6: mse=0.210518 step=0.050000
2017/08/30 23:04:19 step 7: mse=0.211245 step=0.050000
2017/08/30 23:04:19 Saving...
2017/08/30 23:04:19 Gathering batch of experience...
2017/08/30 23:04:59 batch 632: mean=33.533333 stddev=10.984029 entropy=0.162093 frames=7769 count=15
2017/08/30 23:04:59 Training policy...
2017/08/30 23:05:05 tune 0: objective=0.139226 reg=0.001621 prune=0
2017/08/30 23:05:07 step 0: objective=0.139226 reg=0.001621
2017/08/30 23:05:09 step 1: objective=0.139278 reg=0.001620
2017/08/30 23:05:11 step 2: objective=0.139359 reg=0.001620
2017/08/30 23:05:12 step 3: objective=0.139455 reg=0.001618
2017/08/30 23:05:14 step 4: objective=0.139534 reg=0.001617
2017/08/30 23:05:16 step 5: objective=0.139592 reg=0.001617
2017/08/30 23:05:18 step 6: objective=0.139637 reg=0.001616
2017/08/30 23:05:20 step 7: objective=0.139673 reg=0.001616
2017/08/30 23:05:20 Training value function...
2017/08/30 23:05:23 step 0: mse=0.209445 step=0.050000
2017/08/30 23:05:24 step 1: mse=0.208360 step=0.050000
2017/08/30 23:05:26 step 2: mse=0.207669 step=0.050000
2017/08/30 23:05:27 step 3: mse=0.206949 step=0.050000
2017/08/30 23:05:28 step 4: mse=0.205775 step=0.050000
2017/08/30 23:05:30 step 5: mse=0.204692 step=0.050000
2017/08/30 23:05:31 step 6: mse=0.204018 step=0.050000
2017/08/30 23:05:32 step 7: mse=0.203707 step=0.050000
2017/08/30 23:05:32 Saving...
2017/08/30 23:05:32 Gathering batch of experience...
2017/08/30 23:06:13 batch 633: mean=27.052632 stddev=13.323796 entropy=0.158777 frames=7956 count=19
2017/08/30 23:06:13 Training policy...
2017/08/30 23:06:19 tune 0: objective=0.124565 reg=0.001588 prune=0
2017/08/30 23:06:21 step 0: objective=0.124565 reg=0.001588
2017/08/30 23:06:23 step 1: objective=0.124645 reg=0.001588
2017/08/30 23:06:25 step 2: objective=0.124681 reg=0.001588
2017/08/30 23:06:27 step 3: objective=0.124796 reg=0.001588
2017/08/30 23:06:28 step 4: objective=0.124829 reg=0.001588
2017/08/30 23:06:30 step 5: objective=0.124875 reg=0.001589
2017/08/30 23:06:32 step 6: objective=0.124918 reg=0.001589
2017/08/30 23:06:34 step 7: objective=0.124952 reg=0.001589
2017/08/30 23:06:34 Training value function...
2017/08/30 23:06:37 step 0: mse=0.206008 step=0.050000
2017/08/30 23:06:39 step 1: mse=0.206292 step=0.050000
2017/08/30 23:06:40 step 2: mse=0.206758 step=0.050000
2017/08/30 23:06:42 step 3: mse=0.206927 step=0.050000
2017/08/30 23:06:43 step 4: mse=0.207375 step=0.050000
2017/08/30 23:06:44 step 5: mse=0.207789 step=0.050000
2017/08/30 23:06:46 step 6: mse=0.208216 step=0.050000
2017/08/30 23:06:47 step 7: mse=0.208619 step=0.050000
2017/08/30 23:06:47 Saving...
2017/08/30 23:06:47 Gathering batch of experience...
2017/08/30 23:07:29 batch 634: mean=29.722222 stddev=14.050724 entropy=0.160884 frames=8269 count=18
2017/08/30 23:07:29 Training policy...
2017/08/30 23:07:35 tune 0: objective=0.132551 reg=0.001609 prune=0
2017/08/30 23:07:37 step 0: objective=0.132551 reg=0.001609
2017/08/30 23:07:39 step 1: objective=0.132632 reg=0.001609
2017/08/30 23:07:41 step 2: objective=0.132664 reg=0.001609
2017/08/30 23:07:43 step 3: objective=0.132730 reg=0.001609
2017/08/30 23:07:45 step 4: objective=0.132767 reg=0.001608
2017/08/30 23:07:47 step 5: objective=0.132807 reg=0.001608
2017/08/30 23:07:49 step 6: objective=0.132840 reg=0.001607
2017/08/30 23:07:51 step 7: objective=0.132914 reg=0.001607
2017/08/30 23:07:51 Training value function...
2017/08/30 23:07:54 step 0: mse=0.205970 step=0.050000
2017/08/30 23:07:56 step 1: mse=0.205507 step=0.050000
2017/08/30 23:07:57 step 2: mse=0.205038 step=0.050000
2017/08/30 23:07:59 step 3: mse=0.204553 step=0.050000
2017/08/30 23:08:00 step 4: mse=0.204407 step=0.050000
2017/08/30 23:08:02 step 5: mse=0.203793 step=0.050000
2017/08/30 23:08:03 step 6: mse=0.203374 step=0.050000
2017/08/30 23:08:05 step 7: mse=0.202962 step=0.050000
2017/08/30 23:08:05 Saving...
2017/08/30 23:08:05 Gathering batch of experience...
2017/08/30 23:08:46 batch 635: mean=32.875000 stddev=10.821709 entropy=0.161087 frames=8116 count=16
2017/08/30 23:08:46 Training policy...
2017/08/30 23:08:52 tune 0: objective=0.135984 reg=0.001611 prune=0
2017/08/30 23:08:54 step 0: objective=0.135984 reg=0.001611
2017/08/30 23:08:56 step 1: objective=0.136028 reg=0.001611
2017/08/30 23:08:58 step 2: objective=0.136134 reg=0.001611
2017/08/30 23:09:00 step 3: objective=0.136252 reg=0.001611
2017/08/30 23:09:01 step 4: objective=0.136288 reg=0.001611
2017/08/30 23:09:03 step 5: objective=0.136360 reg=0.001611
2017/08/30 23:09:05 step 6: objective=0.136454 reg=0.001611
2017/08/30 23:09:07 step 7: objective=0.136495 reg=0.001611
2017/08/30 23:09:07 Training value function...
2017/08/30 23:09:10 step 0: mse=0.203933 step=0.050000
2017/08/30 23:09:12 step 1: mse=0.203227 step=0.050000
2017/08/30 23:09:13 step 2: mse=0.202551 step=0.050000
2017/08/30 23:09:15 step 3: mse=0.202277 step=0.050000
2017/08/30 23:09:16 step 4: mse=0.201579 step=0.050000
2017/08/30 23:09:18 step 5: mse=0.200936 step=0.050000
2017/08/30 23:09:19 step 6: mse=0.199943 step=0.050000
2017/08/30 23:09:20 step 7: mse=0.199537 step=0.050000
2017/08/30 23:09:20 Saving...
2017/08/30 23:09:20 Gathering batch of experience...
2017/08/30 23:10:00 batch 636: mean=26.611111 stddev=15.326589 entropy=0.161720 frames=7418 count=18
2017/08/30 23:10:00 Training policy...
2017/08/30 23:10:06 tune 0: objective=0.124036 reg=0.001617 prune=0
2017/08/30 23:10:07 step 0: objective=0.124036 reg=0.001617
2017/08/30 23:10:09 step 1: objective=0.124117 reg=0.001617
2017/08/30 23:10:11 step 2: objective=0.124279 reg=0.001617
2017/08/30 23:10:13 step 3: objective=0.124363 reg=0.001617
2017/08/30 23:10:14 step 4: objective=0.124471 reg=0.001616
2017/08/30 23:10:16 step 5: objective=0.124527 reg=0.001616
2017/08/30 23:10:18 step 6: objective=0.124611 reg=0.001616
2017/08/30 23:10:19 step 7: objective=0.124701 reg=0.001616
2017/08/30 23:10:19 Training value function...
2017/08/30 23:10:23 step 0: mse=0.206755 step=0.050000
2017/08/30 23:10:24 step 1: mse=0.207023 step=0.050000
2017/08/30 23:10:25 step 2: mse=0.207255 step=0.050000
2017/08/30 23:10:27 step 3: mse=0.207737 step=0.050000
2017/08/30 23:10:28 step 4: mse=0.207719 step=0.050000
2017/08/30 23:10:29 step 5: mse=0.207876 step=0.050000
2017/08/30 23:10:30 step 6: mse=0.208213 step=0.050000
2017/08/30 23:10:32 step 7: mse=0.208336 step=0.050000
2017/08/30 23:10:32 Saving...
2017/08/30 23:10:32 Gathering batch of experience...
2017/08/30 23:11:12 batch 637: mean=34.333333 stddev=10.299946 entropy=0.156155 frames=7946 count=15
2017/08/30 23:11:12 Training policy...
2017/08/30 23:11:19 tune 0: objective=0.138245 reg=0.001562 prune=0
2017/08/30 23:11:20 step 0: objective=0.138245 reg=0.001562
2017/08/30 23:11:22 step 1: objective=0.138310 reg=0.001563
2017/08/30 23:11:24 step 2: objective=0.138418 reg=0.001564
2017/08/30 23:11:26 step 3: objective=0.138517 reg=0.001564
2017/08/30 23:11:28 step 4: objective=0.138590 reg=0.001565
2017/08/30 23:11:30 step 5: objective=0.138699 reg=0.001566
2017/08/30 23:11:32 step 6: objective=0.138754 reg=0.001567
2017/08/30 23:11:33 step 7: objective=0.138814 reg=0.001567
2017/08/30 23:11:33 Training value function...
2017/08/30 23:11:37 step 0: mse=0.208912 step=0.050000
2017/08/30 23:11:38 step 1: mse=0.207710 step=0.050000
2017/08/30 23:11:40 step 2: mse=0.206938 step=0.050000
2017/08/30 23:11:41 step 3: mse=0.206236 step=0.050000
2017/08/30 23:11:42 step 4: mse=0.205453 step=0.050000
2017/08/30 23:11:44 step 5: mse=0.204290 step=0.050000
2017/08/30 23:11:45 step 6: mse=0.203835 step=0.050000
2017/08/30 23:11:46 step 7: mse=0.202765 step=0.050000
2017/08/30 23:11:46 Saving...
2017/08/30 23:11:46 Gathering batch of experience...
2017/08/30 23:12:29 batch 638: mean=28.388889 stddev=13.454198 entropy=0.160896 frames=7928 count=18
2017/08/30 23:12:29 Training policy...
2017/08/30 23:12:35 tune 0: objective=0.119382 reg=0.001609 prune=0
2017/08/30 23:12:37 step 0: objective=0.119382 reg=0.001609
2017/08/30 23:12:39 step 1: objective=0.119422 reg=0.001609
2017/08/30 23:12:41 step 2: objective=0.119486 reg=0.001609
2017/08/30 23:12:43 step 3: objective=0.119541 reg=0.001609
2017/08/30 23:12:44 step 4: objective=0.119587 reg=0.001609
2017/08/30 23:12:46 step 5: objective=0.119646 reg=0.001608
2017/08/30 23:12:48 step 6: objective=0.119718 reg=0.001607
2017/08/30 23:12:50 step 7: objective=0.119800 reg=0.001607
2017/08/30 23:12:50 Training value function...
2017/08/30 23:12:53 step 0: mse=0.205016 step=0.050000
2017/08/30 23:12:55 step 1: mse=0.205836 step=0.050000
2017/08/30 23:12:56 step 2: mse=0.206644 step=0.050000
2017/08/30 23:12:58 step 3: mse=0.207330 step=0.050000
2017/08/30 23:12:59 step 4: mse=0.207948 step=0.050000
2017/08/30 23:13:00 step 5: mse=0.208842 step=0.050000
2017/08/30 23:13:02 step 6: mse=0.209320 step=0.050000
2017/08/30 23:13:03 step 7: mse=0.209752 step=0.050000
2017/08/30 23:13:03 Saving...
2017/08/30 23:13:03 Gathering batch of experience...
2017/08/30 23:13:44 batch 639: mean=27.210526 stddev=14.915830 entropy=0.161714 frames=8002 count=19
2017/08/30 23:13:44 Training policy...
2017/08/30 23:13:50 tune 0: objective=0.127606 reg=0.001617 prune=0
2017/08/30 23:13:52 step 0: objective=0.127606 reg=0.001617
2017/08/30 23:13:54 step 1: objective=0.127687 reg=0.001617
2017/08/30 23:13:56 step 2: objective=0.127752 reg=0.001617
2017/08/30 23:13:58 step 3: objective=0.127807 reg=0.001617
2017/08/30 23:14:00 step 4: objective=0.127891 reg=0.001616
2017/08/30 23:14:02 step 5: objective=0.127983 reg=0.001616
2017/08/30 23:14:04 step 6: objective=0.128027 reg=0.001616
2017/08/30 23:14:06 step 7: objective=0.128098 reg=0.001616
2017/08/30 23:14:06 Training value function...
2017/08/30 23:14:09 step 0: mse=0.211467 step=0.050000
2017/08/30 23:14:10 step 1: mse=0.211849 step=0.050000
2017/08/30 23:14:12 step 2: mse=0.212157 step=0.050000
2017/08/30 23:14:13 step 3: mse=0.212289 step=0.050000
2017/08/30 23:14:15 step 4: mse=0.212644 step=0.050000
2017/08/30 23:14:16 step 5: mse=0.213091 step=0.050000
2017/08/30 23:14:17 step 6: mse=0.213281 step=0.050000
2017/08/30 23:14:19 step 7: mse=0.213720 step=0.050000
2017/08/30 23:14:19 Saving...
2017/08/30 23:14:19 Gathering batch of experience...
2017/08/30 23:15:01 batch 640: mean=33.750000 stddev=9.236477 entropy=0.161537 frames=8347 count=16
2017/08/30 23:15:01 Training policy...
2017/08/30 23:15:07 tune 0: objective=0.136166 reg=0.001615 prune=0
2017/08/30 23:15:09 step 0: objective=0.136166 reg=0.001615
2017/08/30 23:15:11 step 1: objective=0.136244 reg=0.001615
2017/08/30 23:15:13 step 2: objective=0.136290 reg=0.001615
2017/08/30 23:15:15 step 3: objective=0.136382 reg=0.001615
2017/08/30 23:15:17 step 4: objective=0.136420 reg=0.001615
2017/08/30 23:15:19 step 5: objective=0.136510 reg=0.001614
2017/08/30 23:15:21 step 6: objective=0.136557 reg=0.001614
2017/08/30 23:15:23 step 7: objective=0.136607 reg=0.001614
2017/08/30 23:15:23 Training value function...
2017/08/30 23:15:26 step 0: mse=0.211603 step=0.050000
2017/08/30 23:15:28 step 1: mse=0.210758 step=0.050000
2017/08/30 23:15:29 step 2: mse=0.210186 step=0.050000
2017/08/30 23:15:31 step 3: mse=0.209636 step=0.050000
2017/08/30 23:15:32 step 4: mse=0.208789 step=0.050000
2017/08/30 23:15:34 step 5: mse=0.208476 step=0.050000
2017/08/30 23:15:35 step 6: mse=0.207954 step=0.050000
2017/08/30 23:15:36 step 7: mse=0.207263 step=0.050000
2017/08/30 23:15:36 Saving...
2017/08/30 23:15:36 Gathering batch of experience...
2017/08/30 23:16:18 batch 641: mean=35.200000 stddev=7.678542 entropy=0.160391 frames=8142 count=15
2017/08/30 23:16:18 Training policy...
2017/08/30 23:16:24 tune 0: objective=0.138064 reg=0.001604 prune=0
2017/08/30 23:16:26 step 0: objective=0.138064 reg=0.001604
2017/08/30 23:16:28 step 1: objective=0.138116 reg=0.001604
2017/08/30 23:16:30 step 2: objective=0.138190 reg=0.001604
2017/08/30 23:16:32 step 3: objective=0.138276 reg=0.001604
2017/08/30 23:16:33 step 4: objective=0.138335 reg=0.001605
2017/08/30 23:16:35 step 5: objective=0.138409 reg=0.001605
2017/08/30 23:16:37 step 6: objective=0.138483 reg=0.001605
2017/08/30 23:16:39 step 7: objective=0.138523 reg=0.001606
2017/08/30 23:16:39 Training value function...
2017/08/30 23:16:43 step 0: mse=0.207767 step=0.050000
2017/08/30 23:16:44 step 1: mse=0.206301 step=0.050000
2017/08/30 23:16:45 step 2: mse=0.205239 step=0.050000
2017/08/30 23:16:47 step 3: mse=0.204086 step=0.050000
2017/08/30 23:16:48 step 4: mse=0.203191 step=0.050000
2017/08/30 23:16:50 step 5: mse=0.202287 step=0.050000
2017/08/30 23:16:51 step 6: mse=0.201166 step=0.050000
2017/08/30 23:16:52 step 7: mse=0.200417 step=0.050000
2017/08/30 23:16:52 Saving...
2017/08/30 23:16:52 Gathering batch of experience...
2017/08/30 23:17:34 batch 642: mean=31.764706 stddev=11.874488 entropy=0.165095 frames=8327 count=17
2017/08/30 23:17:34 Training policy...
2017/08/30 23:17:41 tune 0: objective=0.132413 reg=0.001651 prune=0
2017/08/30 23:17:43 step 0: objective=0.132413 reg=0.001651
2017/08/30 23:17:44 step 1: objective=0.132465 reg=0.001652
2017/08/30 23:17:46 step 2: objective=0.132560 reg=0.001652
2017/08/30 23:17:48 step 3: objective=0.132611 reg=0.001653
2017/08/30 23:17:50 step 4: objective=0.132668 reg=0.001652
2017/08/30 23:17:52 step 5: objective=0.132752 reg=0.001652
2017/08/30 23:17:54 step 6: objective=0.132801 reg=0.001651
2017/08/30 23:17:56 step 7: objective=0.132881 reg=0.001651
2017/08/30 23:17:56 Training value function...
2017/08/30 23:18:00 step 0: mse=0.200757 step=0.050000
2017/08/30 23:18:01 step 1: mse=0.200360 step=0.050000
2017/08/30 23:18:03 step 2: mse=0.200302 step=0.050000
2017/08/30 23:18:04 step 3: mse=0.200487 step=0.050000
2017/08/30 23:18:06 step 4: mse=0.200402 step=0.050000
2017/08/30 23:18:07 step 5: mse=0.199992 step=0.050000
2017/08/30 23:18:09 step 6: mse=0.199512 step=0.050000
2017/08/30 23:18:10 step 7: mse=0.199547 step=0.050000
2017/08/30 23:18:10 Saving...
2017/08/30 23:18:10 Gathering batch of experience...
2017/08/30 23:18:53 batch 643: mean=37.466667 stddev=5.226429 entropy=0.161855 frames=8662 count=15
2017/08/30 23:18:53 Training policy...
2017/08/30 23:19:00 tune 0: objective=0.139682 reg=0.001619 prune=0
2017/08/30 23:19:02 step 0: objective=0.139683 reg=0.001619
2017/08/30 23:19:04 step 1: objective=0.139709 reg=0.001619
2017/08/30 23:19:06 step 2: objective=0.139766 reg=0.001619
2017/08/30 23:19:08 step 3: objective=0.139820 reg=0.001618
2017/08/30 23:19:10 step 4: objective=0.139877 reg=0.001618
2017/08/30 23:19:12 step 5: objective=0.139937 reg=0.001618
2017/08/30 23:19:14 step 6: objective=0.140031 reg=0.001618
2017/08/30 23:19:16 step 7: objective=0.140070 reg=0.001617
2017/08/30 23:19:16 Training value function...
2017/08/30 23:19:20 step 0: mse=0.199186 step=0.050000
2017/08/30 23:19:21 step 1: mse=0.198187 step=0.050000
2017/08/30 23:19:23 step 2: mse=0.196717 step=0.050000
2017/08/30 23:19:24 step 3: mse=0.195246 step=0.050000
2017/08/30 23:19:26 step 4: mse=0.193978 step=0.050000
2017/08/30 23:19:27 step 5: mse=0.192976 step=0.050000
2017/08/30 23:19:29 step 6: mse=0.191731 step=0.050000
2017/08/30 23:19:30 step 7: mse=0.190326 step=0.050000
2017/08/30 23:19:30 Saving...
2017/08/30 23:19:30 Gathering batch of experience...
2017/08/30 23:20:10 batch 644: mean=31.687500 stddev=13.696344 entropy=0.163139 frames=7825 count=16
2017/08/30 23:20:10 Training policy...
2017/08/30 23:20:16 tune 0: objective=0.129205 reg=0.001631 prune=0
2017/08/30 23:20:18 step 0: objective=0.129205 reg=0.001631
2017/08/30 23:20:20 step 1: objective=0.129260 reg=0.001631
2017/08/30 23:20:22 step 2: objective=0.129314 reg=0.001631
2017/08/30 23:20:24 step 3: objective=0.129363 reg=0.001631
2017/08/30 23:20:26 step 4: objective=0.129406 reg=0.001632
2017/08/30 23:20:27 step 5: objective=0.129478 reg=0.001631
2017/08/30 23:20:29 step 6: objective=0.129514 reg=0.001631
2017/08/30 23:20:31 step 7: objective=0.129593 reg=0.001630
2017/08/30 23:20:31 Training value function...
2017/08/30 23:20:34 step 0: mse=0.196218 step=0.050000
2017/08/30 23:20:36 step 1: mse=0.195803 step=0.050000
2017/08/30 23:20:37 step 2: mse=0.195715 step=0.050000
2017/08/30 23:20:38 step 3: mse=0.195677 step=0.050000
2017/08/30 23:20:40 step 4: mse=0.195628 step=0.050000
2017/08/30 23:20:41 step 5: mse=0.195709 step=0.050000
2017/08/30 23:20:42 step 6: mse=0.195878 step=0.050000
2017/08/30 23:20:44 step 7: mse=0.195892 step=0.050000
2017/08/30 23:20:44 Saving...
2017/08/30 23:20:44 Gathering batch of experience...
2017/08/30 23:21:27 batch 645: mean=35.250000 stddev=8.158584 entropy=0.159137 frames=8720 count=16
2017/08/30 23:21:27 Training policy...
2017/08/30 23:21:33 tune 0: objective=0.130416 reg=0.001591 prune=0
2017/08/30 23:21:35 step 0: objective=0.130415 reg=0.001591
2017/08/30 23:21:38 step 1: objective=0.130454 reg=0.001592
2017/08/30 23:21:40 step 2: objective=0.130480 reg=0.001592
2017/08/30 23:21:42 step 3: objective=0.130523 reg=0.001593
2017/08/30 23:21:44 step 4: objective=0.130563 reg=0.001593
2017/08/30 23:21:46 step 5: objective=0.130607 reg=0.001592
2017/08/30 23:21:48 step 6: objective=0.130647 reg=0.001593
2017/08/30 23:21:50 step 7: objective=0.130690 reg=0.001593
2017/08/30 23:21:50 Training value function...
2017/08/30 23:21:54 step 0: mse=0.199154 step=0.050000
2017/08/30 23:21:55 step 1: mse=0.198796 step=0.050000
2017/08/30 23:21:57 step 2: mse=0.198738 step=0.050000
2017/08/30 23:21:58 step 3: mse=0.198662 step=0.050000
2017/08/30 23:22:00 step 4: mse=0.198734 step=0.050000
2017/08/30 23:22:01 step 5: mse=0.198584 step=0.050000
2017/08/30 23:22:03 step 6: mse=0.198176 step=0.050000
2017/08/30 23:22:04 step 7: mse=0.197920 step=0.050000
2017/08/30 23:22:04 Saving...
2017/08/30 23:22:04 Gathering batch of experience...
2017/08/30 23:22:46 batch 646: mean=33.687500 stddev=8.636541 entropy=0.161891 frames=8317 count=16
2017/08/30 23:22:46 Training policy...
2017/08/30 23:22:53 tune 0: objective=0.128690 reg=0.001619 prune=0
2017/08/30 23:22:55 step 0: objective=0.128690 reg=0.001619
2017/08/30 23:22:57 step 1: objective=0.128763 reg=0.001619
2017/08/30 23:22:59 step 2: objective=0.128815 reg=0.001619
2017/08/30 23:23:00 step 3: objective=0.128862 reg=0.001619
2017/08/30 23:23:02 step 4: objective=0.128904 reg=0.001619
2017/08/30 23:23:04 step 5: objective=0.128939 reg=0.001619
2017/08/30 23:23:06 step 6: objective=0.128983 reg=0.001619
2017/08/30 23:23:08 step 7: objective=0.129059 reg=0.001618
2017/08/30 23:23:08 Training value function...
2017/08/30 23:23:12 step 0: mse=0.192168 step=0.050000
2017/08/30 23:23:13 step 1: mse=0.192533 step=0.050000
2017/08/30 23:23:15 step 2: mse=0.192719 step=0.050000
2017/08/30 23:23:16 step 3: mse=0.192935 step=0.050000
2017/08/30 23:23:18 step 4: mse=0.193073 step=0.050000
2017/08/30 23:23:19 step 5: mse=0.193269 step=0.050000
2017/08/30 23:23:21 step 6: mse=0.193492 step=0.050000
2017/08/30 23:23:22 step 7: mse=0.193731 step=0.050000
2017/08/30 23:23:22 Saving...
2017/08/30 23:23:22 Gathering batch of experience...
2017/08/30 23:24:04 batch 647: mean=38.928571 stddev=0.257539 entropy=0.159982 frames=8391 count=14
2017/08/30 23:24:04 Training policy...
2017/08/30 23:24:11 tune 0: objective=0.140735 reg=0.001600 prune=0
2017/08/30 23:24:13 step 0: objective=0.140735 reg=0.001600
2017/08/30 23:24:15 step 1: objective=0.140816 reg=0.001601
2017/08/30 23:24:17 step 2: objective=0.140860 reg=0.001601
2017/08/30 23:24:19 step 3: objective=0.140934 reg=0.001602
2017/08/30 23:24:21 step 4: objective=0.140998 reg=0.001602
2017/08/30 23:24:23 step 5: objective=0.141031 reg=0.001603
2017/08/30 23:24:25 step 6: objective=0.141086 reg=0.001603
2017/08/30 23:24:27 step 7: objective=0.141117 reg=0.001603
2017/08/30 23:24:27 Training value function...
2017/08/30 23:24:30 step 0: mse=0.194689 step=0.050000
2017/08/30 23:24:32 step 1: mse=0.193422 step=0.050000
2017/08/30 23:24:33 step 2: mse=0.191908 step=0.050000
2017/08/30 23:24:35 step 3: mse=0.190689 step=0.050000
2017/08/30 23:24:36 step 4: mse=0.189241 step=0.050000
2017/08/30 23:24:38 step 5: mse=0.188015 step=0.050000
2017/08/30 23:24:39 step 6: mse=0.186951 step=0.050000
2017/08/30 23:24:41 step 7: mse=0.186198 step=0.050000
2017/08/30 23:24:41 Saving...
2017/08/30 23:24:41 Gathering batch of experience...
2017/08/30 23:25:23 batch 648: mean=34.062500 stddev=10.365018 entropy=0.157617 frames=8411 count=16
2017/08/30 23:25:23 Training policy...
2017/08/30 23:25:29 tune 0: objective=0.129211 reg=0.001576 prune=0
2017/08/30 23:25:31 step 0: objective=0.129211 reg=0.001576
2017/08/30 23:25:33 step 1: objective=0.129277 reg=0.001576
2017/08/30 23:25:35 step 2: objective=0.129330 reg=0.001576
2017/08/30 23:25:37 step 3: objective=0.129389 reg=0.001575
2017/08/30 23:25:39 step 4: objective=0.129453 reg=0.001575
2017/08/30 23:25:41 step 5: objective=0.129493 reg=0.001575
2017/08/30 23:25:43 step 6: objective=0.129577 reg=0.001575
2017/08/30 23:25:45 step 7: objective=0.129639 reg=0.001574
2017/08/30 23:25:45 Training value function...
2017/08/30 23:25:49 step 0: mse=0.192811 step=0.050000
2017/08/30 23:25:50 step 1: mse=0.192781 step=0.050000
2017/08/30 23:25:52 step 2: mse=0.192993 step=0.050000
2017/08/30 23:25:53 step 3: mse=0.193200 step=0.050000
2017/08/30 23:25:54 step 4: mse=0.193338 step=0.050000
2017/08/30 23:25:56 step 5: mse=0.193716 step=0.050000
2017/08/30 23:25:57 step 6: mse=0.193890 step=0.050000
2017/08/30 23:25:59 step 7: mse=0.193911 step=0.050000
2017/08/30 23:25:59 Saving...
2017/08/30 23:25:59 Gathering batch of experience...
2017/08/30 23:26:40 batch 649: mean=35.666667 stddev=7.105553 entropy=0.161552 frames=8277 count=15
2017/08/30 23:26:40 Training policy...
2017/08/30 23:26:47 tune 0: objective=0.127206 reg=0.001616 prune=0
2017/08/30 23:26:49 step 0: objective=0.127206 reg=0.001616
2017/08/30 23:26:51 step 1: objective=0.127260 reg=0.001616
2017/08/30 23:26:53 step 2: objective=0.127378 reg=0.001616
2017/08/30 23:26:55 step 3: objective=0.127503 reg=0.001616
2017/08/30 23:26:57 step 4: objective=0.127614 reg=0.001616
2017/08/30 23:26:59 step 5: objective=0.127659 reg=0.001616
2017/08/30 23:27:01 step 6: objective=0.127701 reg=0.001617
2017/08/30 23:27:02 step 7: objective=0.127727 reg=0.001617
2017/08/30 23:27:02 Training value function...
2017/08/30 23:27:06 step 0: mse=0.195904 step=0.050000
2017/08/30 23:27:07 step 1: mse=0.196141 step=0.050000
2017/08/30 23:27:09 step 2: mse=0.196338 step=0.050000
2017/08/30 23:27:10 step 3: mse=0.196628 step=0.050000
2017/08/30 23:27:12 step 4: mse=0.196797 step=0.050000
2017/08/30 23:27:13 step 5: mse=0.196881 step=0.050000
2017/08/30 23:27:15 step 6: mse=0.197072 step=0.050000
2017/08/30 23:27:16 step 7: mse=0.197405 step=0.050000
2017/08/30 23:27:16 Saving...
2017/08/30 23:27:16 Gathering batch of experience...
2017/08/30 23:27:58 batch 650: mean=35.933333 stddev=7.886416 entropy=0.161448 frames=8315 count=15
2017/08/30 23:27:58 Training policy...
2017/08/30 23:28:04 tune 0: objective=0.135019 reg=0.001614 prune=0
2017/08/30 23:28:06 step 0: objective=0.135019 reg=0.001614
2017/08/30 23:28:08 step 1: objective=0.135074 reg=0.001614
2017/08/30 23:28:10 step 2: objective=0.135137 reg=0.001614
2017/08/30 23:28:12 step 3: objective=0.135203 reg=0.001615
2017/08/30 23:28:14 step 4: objective=0.135271 reg=0.001615
2017/08/30 23:28:16 step 5: objective=0.135311 reg=0.001615
2017/08/30 23:28:18 step 6: objective=0.135369 reg=0.001615
2017/08/30 23:28:20 step 7: objective=0.135431 reg=0.001614
2017/08/30 23:28:20 Training value function...
2017/08/30 23:28:24 step 0: mse=0.195923 step=0.050000
2017/08/30 23:28:25 step 1: mse=0.195864 step=0.050000
2017/08/30 23:28:27 step 2: mse=0.195068 step=0.050000
2017/08/30 23:28:28 step 3: mse=0.194838 step=0.050000
2017/08/30 23:28:29 step 4: mse=0.193746 step=0.050000
2017/08/30 23:28:31 step 5: mse=0.193687 step=0.050000
2017/08/30 23:28:32 step 6: mse=0.193735 step=0.050000
2017/08/30 23:28:34 step 7: mse=0.193106 step=0.050000
2017/08/30 23:28:34 Saving...
2017/08/30 23:28:34 Gathering batch of experience...
2017/08/30 23:29:13 batch 651: mean=32.466667 stddev=12.590296 entropy=0.159754 frames=7533 count=15
2017/08/30 23:29:13 Training policy...
2017/08/30 23:29:19 tune 0: objective=0.126425 reg=0.001598 prune=0
2017/08/30 23:29:21 step 0: objective=0.126425 reg=0.001598
2017/08/30 23:29:23 step 1: objective=0.126463 reg=0.001598
2017/08/30 23:29:25 step 2: objective=0.126509 reg=0.001597
2017/08/30 23:29:26 step 3: objective=0.126578 reg=0.001597
2017/08/30 23:29:28 step 4: objective=0.126664 reg=0.001598
2017/08/30 23:29:30 step 5: objective=0.126759 reg=0.001598
2017/08/30 23:29:32 step 6: objective=0.126869 reg=0.001598
2017/08/30 23:29:34 step 7: objective=0.126917 reg=0.001599
2017/08/30 23:29:34 Training value function...
2017/08/30 23:29:37 step 0: mse=0.198917 step=0.050000
2017/08/30 23:29:38 step 1: mse=0.199342 step=0.050000
2017/08/30 23:29:39 step 2: mse=0.199698 step=0.050000
2017/08/30 23:29:41 step 3: mse=0.200142 step=0.050000
2017/08/30 23:29:42 step 4: mse=0.200501 step=0.050000
2017/08/30 23:29:43 step 5: mse=0.200761 step=0.050000
2017/08/30 23:29:45 step 6: mse=0.200974 step=0.050000
2017/08/30 23:29:46 step 7: mse=0.201169 step=0.050000
2017/08/30 23:29:46 Saving...
2017/08/30 23:29:46 Gathering batch of experience...
2017/08/30 23:30:34 batch 652: mean=26.181818 stddev=15.896359 entropy=0.157302 frames=8893 count=22
2017/08/30 23:30:34 Training policy...
2017/08/30 23:30:41 tune 0: objective=0.122859 reg=0.001573 prune=0
2017/08/30 23:30:43 step 0: objective=0.122859 reg=0.001573
2017/08/30 23:30:45 step 1: objective=0.122959 reg=0.001574
2017/08/30 23:30:47 step 2: objective=0.123053 reg=0.001573
2017/08/30 23:30:49 step 3: objective=0.123206 reg=0.001574
2017/08/30 23:30:52 step 4: objective=0.123282 reg=0.001573
2017/08/30 23:30:54 step 5: objective=0.123335 reg=0.001574
2017/08/30 23:30:56 step 6: objective=0.123373 reg=0.001573
2017/08/30 23:30:58 step 7: objective=0.123430 reg=0.001573
2017/08/30 23:30:58 Training value function...
2017/08/30 23:31:02 step 0: mse=0.198602 step=0.050000
2017/08/30 23:31:03 step 1: mse=0.199065 step=0.050000
2017/08/30 23:31:05 step 2: mse=0.199333 step=0.050000
2017/08/30 23:31:07 step 3: mse=0.199632 step=0.050000
2017/08/30 23:31:08 step 4: mse=0.199983 step=0.050000
2017/08/30 23:31:10 step 5: mse=0.200464 step=0.050000
2017/08/30 23:31:11 step 6: mse=0.200919 step=0.050000
2017/08/30 23:31:13 step 7: mse=0.201282 step=0.050000
2017/08/30 23:31:13 Saving...
2017/08/30 23:31:13 Gathering batch of experience...
2017/08/30 23:31:54 batch 653: mean=34.466667 stddev=10.996161 entropy=0.157637 frames=7984 count=15
2017/08/30 23:31:54 Training policy...
2017/08/30 23:32:00 tune 0: objective=0.135566 reg=0.001576 prune=0
2017/08/30 23:32:02 step 0: objective=0.135566 reg=0.001576
2017/08/30 23:32:04 step 1: objective=0.135636 reg=0.001576
2017/08/30 23:32:06 step 2: objective=0.135729 reg=0.001576
2017/08/30 23:32:08 step 3: objective=0.135800 reg=0.001577
2017/08/30 23:32:09 step 4: objective=0.135859 reg=0.001578
2017/08/30 23:32:11 step 5: objective=0.135919 reg=0.001578
2017/08/30 23:32:13 step 6: objective=0.135968 reg=0.001577
2017/08/30 23:32:15 step 7: objective=0.136024 reg=0.001577
2017/08/30 23:32:15 Training value function...
2017/08/30 23:32:18 step 0: mse=0.205850 step=0.050000
2017/08/30 23:32:20 step 1: mse=0.204632 step=0.050000
2017/08/30 23:32:21 step 2: mse=0.204106 step=0.050000
2017/08/30 23:32:23 step 3: mse=0.203359 step=0.050000
2017/08/30 23:32:24 step 4: mse=0.202522 step=0.050000
2017/08/30 23:32:25 step 5: mse=0.201693 step=0.050000
2017/08/30 23:32:27 step 6: mse=0.201399 step=0.050000
2017/08/30 23:32:28 step 7: mse=0.200578 step=0.050000
2017/08/30 23:32:28 Saving...
2017/08/30 23:32:28 Gathering batch of experience...
2017/08/30 23:33:11 batch 654: mean=34.812500 stddev=8.903783 entropy=0.157844 frames=8611 count=16
2017/08/30 23:33:11 Training policy...
2017/08/30 23:33:17 tune 0: objective=0.132904 reg=0.001578 prune=0
2017/08/30 23:33:19 step 0: objective=0.132904 reg=0.001578
2017/08/30 23:33:22 step 1: objective=0.132963 reg=0.001578
2017/08/30 23:33:24 step 2: objective=0.133095 reg=0.001578
2017/08/30 23:33:26 step 3: objective=0.133141 reg=0.001577
2017/08/30 23:33:28 step 4: objective=0.133214 reg=0.001576
2017/08/30 23:33:30 step 5: objective=0.133284 reg=0.001577
2017/08/30 23:33:32 step 6: objective=0.133352 reg=0.001576
2017/08/30 23:33:34 step 7: objective=0.133401 reg=0.001576
2017/08/30 23:33:34 Training value function...
2017/08/30 23:33:37 step 0: mse=0.202108 step=0.050000
2017/08/30 23:33:39 step 1: mse=0.202055 step=0.050000
2017/08/30 23:33:40 step 2: mse=0.201682 step=0.050000
2017/08/30 23:33:42 step 3: mse=0.201567 step=0.050000
2017/08/30 23:33:43 step 4: mse=0.200752 step=0.050000
2017/08/30 23:33:45 step 5: mse=0.200109 step=0.050000
2017/08/30 23:33:46 step 6: mse=0.199750 step=0.050000
2017/08/30 23:33:48 step 7: mse=0.199738 step=0.050000
2017/08/30 23:33:48 Saving...
2017/08/30 23:33:48 Gathering batch of experience...
2017/08/30 23:34:30 batch 655: mean=35.933333 stddev=6.971051 entropy=0.162433 frames=8322 count=15
2017/08/30 23:34:30 Training policy...
2017/08/30 23:34:36 tune 0: objective=0.132445 reg=0.001624 prune=0
2017/08/30 23:34:38 step 0: objective=0.132445 reg=0.001624
2017/08/30 23:34:40 step 1: objective=0.132478 reg=0.001624
2017/08/30 23:34:42 step 2: objective=0.132513 reg=0.001625
2017/08/30 23:34:44 step 3: objective=0.132545 reg=0.001624
2017/08/30 23:34:46 step 4: objective=0.132588 reg=0.001624
2017/08/30 23:34:48 step 5: objective=0.132639 reg=0.001624
2017/08/30 23:34:50 step 6: objective=0.132669 reg=0.001624
2017/08/30 23:34:52 step 7: objective=0.132698 reg=0.001624
2017/08/30 23:34:52 Training value function...
2017/08/30 23:34:55 step 0: mse=0.197071 step=0.050000
2017/08/30 23:34:57 step 1: mse=0.196695 step=0.050000
2017/08/30 23:34:58 step 2: mse=0.196433 step=0.050000
2017/08/30 23:35:00 step 3: mse=0.195796 step=0.050000
2017/08/30 23:35:01 step 4: mse=0.195457 step=0.050000
2017/08/30 23:35:03 step 5: mse=0.195215 step=0.050000
2017/08/30 23:35:04 step 6: mse=0.195259 step=0.050000
2017/08/30 23:35:06 step 7: mse=0.194802 step=0.050000
2017/08/30 23:35:06 Saving...
2017/08/30 23:35:06 Gathering batch of experience...
2017/08/30 23:35:44 batch 656: mean=33.214286 stddev=12.450924 entropy=0.158488 frames=7170 count=14
2017/08/30 23:35:44 Training policy...
2017/08/30 23:35:50 tune 0: objective=0.131112 reg=0.001585 prune=0
2017/08/30 23:35:51 step 0: objective=0.131112 reg=0.001585
2017/08/30 23:35:53 step 1: objective=0.131169 reg=0.001585
2017/08/30 23:35:55 step 2: objective=0.131203 reg=0.001585
2017/08/30 23:35:57 step 3: objective=0.131238 reg=0.001585
2017/08/30 23:35:58 step 4: objective=0.131307 reg=0.001585
2017/08/30 23:36:00 step 5: objective=0.131349 reg=0.001585
2017/08/30 23:36:02 step 6: objective=0.131412 reg=0.001585
2017/08/30 23:36:03 step 7: objective=0.131444 reg=0.001585
2017/08/30 23:36:03 Training value function...
2017/08/30 23:36:06 step 0: mse=0.193431 step=0.050000
2017/08/30 23:36:08 step 1: mse=0.193065 step=0.050000
2017/08/30 23:36:09 step 2: mse=0.192793 step=0.050000
2017/08/30 23:36:10 step 3: mse=0.192253 step=0.050000
2017/08/30 23:36:11 step 4: mse=0.191957 step=0.050000
2017/08/30 23:36:12 step 5: mse=0.191712 step=0.050000
2017/08/30 23:36:14 step 6: mse=0.191434 step=0.050000
2017/08/30 23:36:15 step 7: mse=0.190760 step=0.050000
2017/08/30 23:36:15 Saving...
2017/08/30 23:36:15 Gathering batch of experience...
2017/08/30 23:36:55 batch 657: mean=32.600000 stddev=12.805207 entropy=0.158657 frames=7552 count=15
2017/08/30 23:36:55 Training policy...
2017/08/30 23:37:00 tune 0: objective=0.131259 reg=0.001587 prune=0
2017/08/30 23:37:02 step 0: objective=0.131260 reg=0.001587
2017/08/30 23:37:04 step 1: objective=0.131367 reg=0.001587
2017/08/30 23:37:06 step 2: objective=0.131434 reg=0.001586
2017/08/30 23:37:08 step 3: objective=0.131472 reg=0.001586
2017/08/30 23:37:09 step 4: objective=0.131527 reg=0.001586
2017/08/30 23:37:11 step 5: objective=0.131580 reg=0.001586
2017/08/30 23:37:13 step 6: objective=0.131648 reg=0.001586
2017/08/30 23:37:15 step 7: objective=0.131699 reg=0.001586
2017/08/30 23:37:15 Training value function...
2017/08/30 23:37:18 step 0: mse=0.196918 step=0.050000
2017/08/30 23:37:19 step 1: mse=0.197191 step=0.050000
2017/08/30 23:37:21 step 2: mse=0.197334 step=0.050000
2017/08/30 23:37:22 step 3: mse=0.197196 step=0.050000
2017/08/30 23:37:23 step 4: mse=0.197098 step=0.050000
2017/08/30 23:37:25 step 5: mse=0.197193 step=0.050000
2017/08/30 23:37:26 step 6: mse=0.197185 step=0.050000
2017/08/30 23:37:27 step 7: mse=0.196977 step=0.050000
2017/08/30 23:37:27 Saving...
2017/08/30 23:37:27 Gathering batch of experience...
2017/08/30 23:38:08 batch 658: mean=33.600000 stddev=11.277115 entropy=0.157712 frames=7783 count=15
2017/08/30 23:38:08 Training policy...
2017/08/30 23:38:14 tune 0: objective=0.133049 reg=0.001577 prune=0
2017/08/30 23:38:16 step 0: objective=0.133049 reg=0.001577
2017/08/30 23:38:18 step 1: objective=0.133109 reg=0.001577
2017/08/30 23:38:19 step 2: objective=0.133140 reg=0.001577
2017/08/30 23:38:21 step 3: objective=0.133199 reg=0.001578
2017/08/30 23:38:23 step 4: objective=0.133258 reg=0.001578
2017/08/30 23:38:25 step 5: objective=0.133347 reg=0.001578
2017/08/30 23:38:27 step 6: objective=0.133375 reg=0.001577
2017/08/30 23:38:29 step 7: objective=0.133407 reg=0.001578
2017/08/30 23:38:29 Training value function...
2017/08/30 23:38:32 step 0: mse=0.195628 step=0.050000
2017/08/30 23:38:33 step 1: mse=0.195458 step=0.050000
2017/08/30 23:38:35 step 2: mse=0.195138 step=0.050000
2017/08/30 23:38:36 step 3: mse=0.195088 step=0.050000
2017/08/30 23:38:37 step 4: mse=0.194900 step=0.050000
2017/08/30 23:38:39 step 5: mse=0.194841 step=0.050000
2017/08/30 23:38:40 step 6: mse=0.194475 step=0.050000
2017/08/30 23:38:42 step 7: mse=0.194032 step=0.050000
2017/08/30 23:38:42 Saving...
2017/08/30 23:38:42 Gathering batch of experience...
2017/08/30 23:39:22 batch 659: mean=31.062500 stddev=12.497343 entropy=0.164417 frames=7679 count=16
2017/08/30 23:39:22 Training policy...
2017/08/30 23:39:28 tune 0: objective=0.126418 reg=0.001644 prune=0
2017/08/30 23:39:29 step 0: objective=0.126418 reg=0.001644
2017/08/30 23:39:31 step 1: objective=0.126468 reg=0.001644
2017/08/30 23:39:33 step 2: objective=0.126553 reg=0.001644
2017/08/30 23:39:35 step 3: objective=0.126672 reg=0.001644
2017/08/30 23:39:37 step 4: objective=0.126720 reg=0.001644
2017/08/30 23:39:39 step 5: objective=0.126785 reg=0.001644
2017/08/30 23:39:40 step 6: objective=0.126835 reg=0.001644
2017/08/30 23:39:42 step 7: objective=0.126920 reg=0.001643
2017/08/30 23:39:42 Training value function...
2017/08/30 23:39:46 step 0: mse=0.192214 step=0.050000
2017/08/30 23:39:47 step 1: mse=0.192628 step=0.050000
2017/08/30 23:39:48 step 2: mse=0.193105 step=0.050000
2017/08/30 23:39:50 step 3: mse=0.192868 step=0.050000
2017/08/30 23:39:51 step 4: mse=0.193370 step=0.050000
2017/08/30 23:39:52 step 5: mse=0.193632 step=0.050000
2017/08/30 23:39:54 step 6: mse=0.193708 step=0.050000
2017/08/30 23:39:55 step 7: mse=0.194062 step=0.050000
2017/08/30 23:39:55 Saving...
2017/08/30 23:39:55 Gathering batch of experience...
2017/08/30 23:40:36 batch 660: mean=35.133333 stddev=10.184083 entropy=0.158031 frames=8127 count=15
2017/08/30 23:40:36 Training policy...
2017/08/30 23:40:43 tune 0: objective=0.136630 reg=0.001580 prune=0
2017/08/30 23:40:45 step 0: objective=0.136630 reg=0.001580
2017/08/30 23:40:47 step 1: objective=0.136665 reg=0.001580
2017/08/30 23:40:49 step 2: objective=0.136732 reg=0.001581
2017/08/30 23:40:51 step 3: objective=0.136795 reg=0.001581
2017/08/30 23:40:52 step 4: objective=0.136855 reg=0.001581
2017/08/30 23:40:54 step 5: objective=0.136906 reg=0.001580
2017/08/30 23:40:56 step 6: objective=0.136940 reg=0.001580
2017/08/30 23:40:58 step 7: objective=0.137027 reg=0.001580
2017/08/30 23:40:58 Training value function...
2017/08/30 23:41:02 step 0: mse=0.197062 step=0.050000
2017/08/30 23:41:03 step 1: mse=0.196186 step=0.050000
2017/08/30 23:41:05 step 2: mse=0.195560 step=0.050000
2017/08/30 23:41:06 step 3: mse=0.194902 step=0.050000
2017/08/30 23:41:07 step 4: mse=0.194160 step=0.050000
2017/08/30 23:41:09 step 5: mse=0.193353 step=0.050000
2017/08/30 23:41:10 step 6: mse=0.192480 step=0.050000
2017/08/30 23:41:12 step 7: mse=0.191994 step=0.050000
2017/08/30 23:41:12 Saving...
2017/08/30 23:41:12 Gathering batch of experience...
2017/08/30 23:41:55 batch 661: mean=27.050000 stddev=14.776586 entropy=0.158092 frames=8360 count=20
2017/08/30 23:41:55 Training policy...
2017/08/30 23:42:02 tune 0: objective=0.120298 reg=0.001581 prune=0
2017/08/30 23:42:04 step 0: objective=0.120299 reg=0.001581
2017/08/30 23:42:06 step 1: objective=0.120348 reg=0.001581
2017/08/30 23:42:08 step 2: objective=0.120401 reg=0.001581
2017/08/30 23:42:10 step 3: objective=0.120475 reg=0.001581
2017/08/30 23:42:12 step 4: objective=0.120560 reg=0.001581
2017/08/30 23:42:14 step 5: objective=0.120623 reg=0.001581
2017/08/30 23:42:16 step 6: objective=0.120685 reg=0.001580
2017/08/30 23:42:18 step 7: objective=0.120751 reg=0.001580
2017/08/30 23:42:18 Training value function...
2017/08/30 23:42:21 step 0: mse=0.194443 step=0.050000
2017/08/30 23:42:23 step 1: mse=0.194894 step=0.050000
2017/08/30 23:42:24 step 2: mse=0.195515 step=0.050000
2017/08/30 23:42:26 step 3: mse=0.196272 step=0.050000
2017/08/30 23:42:27 step 4: mse=0.196969 step=0.050000
2017/08/30 23:42:29 step 5: mse=0.197545 step=0.050000
2017/08/30 23:42:30 step 6: mse=0.198063 step=0.050000
2017/08/30 23:42:32 step 7: mse=0.198564 step=0.050000
2017/08/30 23:42:32 Saving...
2017/08/30 23:42:32 Gathering batch of experience...
2017/08/30 23:43:13 batch 662: mean=31.562500 stddev=11.763124 entropy=0.161820 frames=7817 count=16
2017/08/30 23:43:13 Training policy...
2017/08/30 23:43:19 tune 0: objective=0.127245 reg=0.001618 prune=0
2017/08/30 23:43:21 step 0: objective=0.127245 reg=0.001618
2017/08/30 23:43:22 step 1: objective=0.127378 reg=0.001618
2017/08/30 23:43:24 step 2: objective=0.127526 reg=0.001618
2017/08/30 23:43:26 step 3: objective=0.127634 reg=0.001617
2017/08/30 23:43:28 step 4: objective=0.127745 reg=0.001618
2017/08/30 23:43:30 step 5: objective=0.127786 reg=0.001617
2017/08/30 23:43:32 step 6: objective=0.127877 reg=0.001616
2017/08/30 23:43:34 step 7: objective=0.127950 reg=0.001616
2017/08/30 23:43:34 Training value function...
2017/08/30 23:43:37 step 0: mse=0.202901 step=0.050000
2017/08/30 23:43:38 step 1: mse=0.203099 step=0.050000
2017/08/30 23:43:40 step 2: mse=0.203367 step=0.050000
2017/08/30 23:43:41 step 3: mse=0.203570 step=0.050000
2017/08/30 23:43:43 step 4: mse=0.203971 step=0.050000
2017/08/30 23:43:44 step 5: mse=0.204135 step=0.050000
2017/08/30 23:43:45 step 6: mse=0.204477 step=0.050000
2017/08/30 23:43:47 step 7: mse=0.204596 step=0.050000
2017/08/30 23:43:47 Saving...
2017/08/30 23:43:47 Gathering batch of experience...
