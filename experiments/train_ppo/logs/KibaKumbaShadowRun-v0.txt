2017/08/29 19:51:18 Run with arguments: [-algo mse -env KibaKumbaShadowRun-v0 -step 0.001 -valstep 0.05 -iters 8 -valiters 8 -discount 0.97 -critic Kiba-v0/critic.json -actor Kiba-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1 -tuneiters 1 -tunestep 0.001]
2017/08/29 19:51:18 Creating environments...
2017/08/29 19:51:29 Creating new forest for: Kiba-v0/actor.json
2017/08/29 19:51:29 Creating new forest for: Kiba-v0/critic.json
2017/08/29 19:51:29 Running. Press Ctrl+C to stop.
2017/08/29 19:51:29 Gathering batch of experience...
2017/08/29 19:51:52 batch 0: mean=573.869048 stddev=320.229969 entropy=0.693146 frames=4616 count=84
2017/08/29 19:51:52 Training policy...
2017/08/29 19:51:54 tune 0: objective=107.347521 reg=0.006931 prune=0
2017/08/29 19:51:55 step 0: objective=107.347710 reg=0.006931
2017/08/29 19:51:56 step 1: objective=107.376043 reg=0.006931
2017/08/29 19:51:56 step 2: objective=107.409757 reg=0.006931
2017/08/29 19:51:57 step 3: objective=107.455880 reg=0.006931
2017/08/29 19:51:58 step 4: objective=107.502214 reg=0.006931
2017/08/29 19:51:58 step 5: objective=107.545216 reg=0.006931
2017/08/29 19:51:59 step 6: objective=107.588652 reg=0.006931
2017/08/29 19:52:00 step 7: objective=107.633361 reg=0.006930
2017/08/29 19:52:00 Training value function...
2017/08/29 19:52:01 step 0: mse=50985.447759 step=0.050000
2017/08/29 19:52:02 step 1: mse=47030.249634 step=0.050000
2017/08/29 19:52:03 step 2: mse=43489.532668 step=0.050000
2017/08/29 19:52:03 step 3: mse=40323.780755 step=0.050000
2017/08/29 19:52:04 step 4: mse=37486.696076 step=0.050000
2017/08/29 19:52:05 step 5: mse=34944.684709 step=0.050000
2017/08/29 19:52:06 step 6: mse=32665.762031 step=0.050000
2017/08/29 19:52:06 step 7: mse=30622.389860 step=0.050000
2017/08/29 19:52:06 Saving...
2017/08/29 19:52:06 Gathering batch of experience...
2017/08/29 19:52:28 batch 1: mean=611.772152 stddev=338.509426 entropy=0.692975 frames=4559 count=79
2017/08/29 19:52:28 Training policy...
2017/08/29 19:52:30 tune 0: objective=75.846581 reg=0.006930 prune=0
2017/08/29 19:52:31 step 0: objective=75.875932 reg=0.006927
2017/08/29 19:52:32 step 1: objective=75.907751 reg=0.006927
2017/08/29 19:52:32 step 2: objective=75.951442 reg=0.006927
2017/08/29 19:52:33 step 3: objective=76.000521 reg=0.006927
2017/08/29 19:52:34 step 4: objective=76.036741 reg=0.006927
2017/08/29 19:52:34 step 5: objective=76.072199 reg=0.006926
2017/08/29 19:52:35 step 6: objective=76.111394 reg=0.006926
2017/08/29 19:52:36 step 7: objective=76.151760 reg=0.006925
2017/08/29 19:52:36 Training value function...
2017/08/29 19:52:37 step 0: mse=32200.667994 step=0.050000
2017/08/29 19:52:38 step 1: mse=30330.696709 step=0.050000
2017/08/29 19:52:39 step 2: mse=28652.884040 step=0.050000
2017/08/29 19:52:39 step 3: mse=27139.027483 step=0.050000
2017/08/29 19:52:40 step 4: mse=25777.231439 step=0.050000
2017/08/29 19:52:41 step 5: mse=24552.758412 step=0.050000
2017/08/29 19:52:41 step 6: mse=23442.451086 step=0.050000
2017/08/29 19:52:42 step 7: mse=22443.891880 step=0.050000
2017/08/29 19:52:42 Saving...
2017/08/29 19:52:42 Gathering batch of experience...
2017/08/29 19:53:04 batch 2: mean=605.769231 stddev=285.918534 entropy=0.692505 frames=4516 count=78
2017/08/29 19:53:04 Training policy...
2017/08/29 19:53:06 tune 0: objective=51.275631 reg=0.006925 prune=0
2017/08/29 19:53:07 step 0: objective=51.291356 reg=0.006923
2017/08/29 19:53:08 step 1: objective=51.318742 reg=0.006923
2017/08/29 19:53:08 step 2: objective=51.345947 reg=0.006923
2017/08/29 19:53:09 step 3: objective=51.369755 reg=0.006922
2017/08/29 19:53:10 step 4: objective=51.395386 reg=0.006922
2017/08/29 19:53:10 step 5: objective=51.423051 reg=0.006922
2017/08/29 19:53:11 step 6: objective=51.447862 reg=0.006921
2017/08/29 19:53:12 step 7: objective=51.473801 reg=0.006921
2017/08/29 19:53:12 Training value function...
2017/08/29 19:53:13 step 0: mse=18961.420443 step=0.050000
2017/08/29 19:53:14 step 1: mse=18218.341796 step=0.050000
2017/08/29 19:53:15 step 2: mse=17546.454602 step=0.050000
2017/08/29 19:53:15 step 3: mse=16938.491761 step=0.050000
2017/08/29 19:53:16 step 4: mse=16371.196243 step=0.050000
2017/08/29 19:53:16 step 5: mse=15862.678258 step=0.050000
2017/08/29 19:53:17 step 6: mse=15404.981922 step=0.050000
2017/08/29 19:53:18 step 7: mse=14991.322722 step=0.050000
2017/08/29 19:53:18 Saving...
2017/08/29 19:53:18 Gathering batch of experience...
2017/08/29 19:53:40 batch 3: mean=602.500000 stddev=319.276777 entropy=0.692045 frames=4468 count=78
2017/08/29 19:53:40 Training policy...
2017/08/29 19:53:42 tune 0: objective=38.817969 reg=0.006920 prune=0
2017/08/29 19:53:42 step 0: objective=38.836829 reg=0.006920
2017/08/29 19:53:43 step 1: objective=38.857591 reg=0.006920
2017/08/29 19:53:44 step 2: objective=38.879291 reg=0.006920
2017/08/29 19:53:44 step 3: objective=38.898312 reg=0.006920
2017/08/29 19:53:45 step 4: objective=38.914800 reg=0.006919
2017/08/29 19:53:46 step 5: objective=38.937622 reg=0.006919
2017/08/29 19:53:46 step 6: objective=38.955038 reg=0.006919
2017/08/29 19:53:47 step 7: objective=38.976185 reg=0.006919
2017/08/29 19:53:47 Training value function...
2017/08/29 19:53:49 step 0: mse=15939.495797 step=0.050000
2017/08/29 19:53:49 step 1: mse=15562.266475 step=0.050000
2017/08/29 19:53:50 step 2: mse=15219.494071 step=0.050000
2017/08/29 19:53:51 step 3: mse=14910.445859 step=0.050000
2017/08/29 19:53:51 step 4: mse=14621.986363 step=0.050000
2017/08/29 19:53:52 step 5: mse=14358.553397 step=0.050000
2017/08/29 19:53:53 step 6: mse=14118.648560 step=0.050000
2017/08/29 19:53:53 step 7: mse=13897.889458 step=0.050000
2017/08/29 19:53:53 Saving...
2017/08/29 19:53:53 Gathering batch of experience...
2017/08/29 19:54:17 batch 4: mean=547.176471 stddev=314.181895 entropy=0.691907 frames=4498 count=85
2017/08/29 19:54:17 Training policy...
2017/08/29 19:54:18 tune 0: objective=24.821183 reg=0.006919 prune=0
2017/08/29 19:54:19 step 0: objective=24.826477 reg=0.006919
2017/08/29 19:54:20 step 1: objective=24.842015 reg=0.006919
2017/08/29 19:54:20 step 2: objective=24.862189 reg=0.006919
2017/08/29 19:54:21 step 3: objective=24.881444 reg=0.006918
2017/08/29 19:54:22 step 4: objective=24.899287 reg=0.006918
2017/08/29 19:54:22 step 5: objective=24.915813 reg=0.006918
2017/08/29 19:54:23 step 6: objective=24.930782 reg=0.006918
2017/08/29 19:54:24 step 7: objective=24.946247 reg=0.006918
2017/08/29 19:54:24 Training value function...
2017/08/29 19:54:25 step 0: mse=12254.487172 step=0.050000
2017/08/29 19:54:26 step 1: mse=12150.313730 step=0.050000
2017/08/29 19:54:27 step 2: mse=12052.189316 step=0.050000
2017/08/29 19:54:27 step 3: mse=11961.243824 step=0.050000
2017/08/29 19:54:28 step 4: mse=11878.459545 step=0.050000
2017/08/29 19:54:29 step 5: mse=11803.935612 step=0.050000
2017/08/29 19:54:29 step 6: mse=11733.271083 step=0.050000
2017/08/29 19:54:30 step 7: mse=11664.315260 step=0.050000
2017/08/29 19:54:30 Saving...
2017/08/29 19:54:30 Gathering batch of experience...
2017/08/29 19:54:53 batch 5: mean=627.937500 stddev=350.986729 entropy=0.691637 frames=4712 count=80
2017/08/29 19:54:53 Training policy...
2017/08/29 19:54:55 tune 0: objective=30.925682 reg=0.006916 prune=0
2017/08/29 19:54:56 step 0: objective=30.934118 reg=0.006915
2017/08/29 19:54:56 step 1: objective=30.964572 reg=0.006915
2017/08/29 19:54:57 step 2: objective=30.996134 reg=0.006915
2017/08/29 19:54:58 step 3: objective=31.018699 reg=0.006915
2017/08/29 19:54:58 step 4: objective=31.036900 reg=0.006915
2017/08/29 19:54:59 step 5: objective=31.060444 reg=0.006915
2017/08/29 19:55:00 step 6: objective=31.085702 reg=0.006914
2017/08/29 19:55:01 step 7: objective=31.106676 reg=0.006914
2017/08/29 19:55:01 Training value function...
2017/08/29 19:55:02 step 0: mse=14553.401375 step=0.050000
2017/08/29 19:55:03 step 1: mse=14343.431267 step=0.050000
2017/08/29 19:55:04 step 2: mse=14148.647308 step=0.050000
2017/08/29 19:55:04 step 3: mse=13967.401175 step=0.050000
2017/08/29 19:55:05 step 4: mse=13800.942058 step=0.050000
2017/08/29 19:55:06 step 5: mse=13651.367046 step=0.050000
2017/08/29 19:55:07 step 6: mse=13509.946547 step=0.050000
2017/08/29 19:55:07 step 7: mse=13376.411309 step=0.050000
2017/08/29 19:55:07 Saving...
2017/08/29 19:55:07 Gathering batch of experience...
2017/08/29 19:55:30 batch 6: mean=580.864198 stddev=272.634371 entropy=0.691500 frames=4556 count=81
2017/08/29 19:55:30 Training policy...
2017/08/29 19:55:32 tune 0: objective=17.848531 reg=0.006915 prune=0
2017/08/29 19:55:32 step 0: objective=17.861541 reg=0.006915
2017/08/29 19:55:33 step 1: objective=17.873158 reg=0.006915
2017/08/29 19:55:34 step 2: objective=17.891767 reg=0.006915
2017/08/29 19:55:34 step 3: objective=17.907029 reg=0.006915
2017/08/29 19:55:35 step 4: objective=17.920714 reg=0.006915
2017/08/29 19:55:36 step 5: objective=17.940136 reg=0.006915
2017/08/29 19:55:36 step 6: objective=17.954730 reg=0.006915
2017/08/29 19:55:37 step 7: objective=17.965305 reg=0.006915
2017/08/29 19:55:37 Training value function...
2017/08/29 19:55:39 step 0: mse=9691.304193 step=0.050000
2017/08/29 19:55:39 step 1: mse=9658.236742 step=0.050000
2017/08/29 19:55:40 step 2: mse=9617.364782 step=0.050000
2017/08/29 19:55:41 step 3: mse=9590.263055 step=0.050000
2017/08/29 19:55:41 step 4: mse=9565.916692 step=0.050000
2017/08/29 19:55:42 step 5: mse=9541.600854 step=0.050000
2017/08/29 19:55:43 step 6: mse=9517.811421 step=0.050000
2017/08/29 19:55:43 step 7: mse=9496.721776 step=0.050000
2017/08/29 19:55:43 Saving...
2017/08/29 19:55:43 Gathering batch of experience...
2017/08/29 19:56:05 batch 7: mean=637.565789 stddev=324.284124 entropy=0.691369 frames=4496 count=76
2017/08/29 19:56:05 Training policy...
2017/08/29 19:56:07 tune 0: objective=26.566829 reg=0.006914 prune=0
2017/08/29 19:56:08 step 0: objective=26.581903 reg=0.006913
2017/08/29 19:56:09 step 1: objective=26.608784 reg=0.006912
2017/08/29 19:56:09 step 2: objective=26.635833 reg=0.006912
2017/08/29 19:56:10 step 3: objective=26.669765 reg=0.006912
2017/08/29 19:56:11 step 4: objective=26.699671 reg=0.006911
2017/08/29 19:56:11 step 5: objective=26.728121 reg=0.006911
2017/08/29 19:56:12 step 6: objective=26.753651 reg=0.006910
2017/08/29 19:56:12 step 7: objective=26.783601 reg=0.006909
2017/08/29 19:56:12 Training value function...
2017/08/29 19:56:14 step 0: mse=12962.420086 step=0.050000
2017/08/29 19:56:15 step 1: mse=12804.486005 step=0.050000
2017/08/29 19:56:16 step 2: mse=12645.708990 step=0.050000
2017/08/29 19:56:16 step 3: mse=12510.422387 step=0.050000
2017/08/29 19:56:17 step 4: mse=12373.149559 step=0.050000
2017/08/29 19:56:18 step 5: mse=12259.211072 step=0.050000
2017/08/29 19:56:18 step 6: mse=12140.431136 step=0.050000
2017/08/29 19:56:19 step 7: mse=12041.041675 step=0.050000
2017/08/29 19:56:19 Saving...
2017/08/29 19:56:19 Gathering batch of experience...
2017/08/29 19:56:41 batch 8: mean=673.466667 stddev=364.259041 entropy=0.690903 frames=4633 count=75
2017/08/29 19:56:41 Training policy...
2017/08/29 19:56:43 tune 0: objective=27.827122 reg=0.006909 prune=0
2017/08/29 19:56:44 step 0: objective=27.835180 reg=0.006909
2017/08/29 19:56:44 step 1: objective=27.862736 reg=0.006909
2017/08/29 19:56:45 step 2: objective=27.889812 reg=0.006909
2017/08/29 19:56:46 step 3: objective=27.909803 reg=0.006909
2017/08/29 19:56:46 step 4: objective=27.936659 reg=0.006909
2017/08/29 19:56:47 step 5: objective=27.963934 reg=0.006909
2017/08/29 19:56:48 step 6: objective=27.994144 reg=0.006909
2017/08/29 19:56:48 step 7: objective=28.023964 reg=0.006909
2017/08/29 19:56:48 Training value function...
2017/08/29 19:56:50 step 0: mse=15066.215949 step=0.050000
2017/08/29 19:56:51 step 1: mse=14903.923131 step=0.050000
2017/08/29 19:56:51 step 2: mse=14752.783317 step=0.050000
2017/08/29 19:56:52 step 3: mse=14612.055379 step=0.050000
2017/08/29 19:56:53 step 4: mse=14481.625331 step=0.050000
2017/08/29 19:56:54 step 5: mse=14362.047931 step=0.050000
2017/08/29 19:56:54 step 6: mse=14255.049935 step=0.050000
2017/08/29 19:56:55 step 7: mse=14153.483672 step=0.050000
2017/08/29 19:56:55 Saving...
2017/08/29 19:56:55 Gathering batch of experience...
2017/08/29 19:57:18 batch 9: mean=667.500000 stddev=322.909776 entropy=0.690801 frames=4715 count=76
2017/08/29 19:57:18 Training policy...
2017/08/29 19:57:20 tune 0: objective=21.283321 reg=0.006908 prune=0
2017/08/29 19:57:21 step 0: objective=21.293381 reg=0.006908
2017/08/29 19:57:22 step 1: objective=21.309885 reg=0.006908
2017/08/29 19:57:22 step 2: objective=21.326389 reg=0.006907
2017/08/29 19:57:23 step 3: objective=21.342184 reg=0.006907
2017/08/29 19:57:24 step 4: objective=21.362169 reg=0.006907
2017/08/29 19:57:25 step 5: objective=21.379840 reg=0.006907
2017/08/29 19:57:25 step 6: objective=21.397453 reg=0.006907
2017/08/29 19:57:26 step 7: objective=21.412074 reg=0.006907
2017/08/29 19:57:26 Training value function...
2017/08/29 19:57:28 step 0: mse=11734.385340 step=0.050000
2017/08/29 19:57:28 step 1: mse=11690.714701 step=0.050000
2017/08/29 19:57:29 step 2: mse=11647.990405 step=0.050000
2017/08/29 19:57:30 step 3: mse=11607.290960 step=0.050000
2017/08/29 19:57:31 step 4: mse=11571.268571 step=0.050000
2017/08/29 19:57:31 step 5: mse=11536.779688 step=0.050000
2017/08/29 19:57:32 step 6: mse=11504.775490 step=0.050000
2017/08/29 19:57:33 step 7: mse=11475.760751 step=0.050000
2017/08/29 19:57:33 Saving...
2017/08/29 19:57:33 Gathering batch of experience...
2017/08/29 19:57:55 batch 10: mean=595.740741 stddev=291.762536 entropy=0.690772 frames=4593 count=81
2017/08/29 19:57:55 Training policy...
2017/08/29 19:57:57 tune 0: objective=12.208462 reg=0.006908 prune=0
2017/08/29 19:57:58 step 0: objective=12.226710 reg=0.006907
2017/08/29 19:57:59 step 1: objective=12.246303 reg=0.006907
2017/08/29 19:57:59 step 2: objective=12.259538 reg=0.006907
2017/08/29 19:58:00 step 3: objective=12.279768 reg=0.006906
2017/08/29 19:58:01 step 4: objective=12.304153 reg=0.006906
2017/08/29 19:58:02 step 5: objective=12.321494 reg=0.006906
2017/08/29 19:58:02 step 6: objective=12.343554 reg=0.006905
2017/08/29 19:58:03 step 7: objective=12.369462 reg=0.006905
2017/08/29 19:58:03 Training value function...
2017/08/29 19:58:05 step 0: mse=10085.616107 step=0.050000
2017/08/29 19:58:05 step 1: mse=10095.672638 step=0.050000
2017/08/29 19:58:06 step 2: mse=10108.562964 step=0.050000
2017/08/29 19:58:07 step 3: mse=10119.281842 step=0.050000
2017/08/29 19:58:07 step 4: mse=10131.712904 step=0.050000
2017/08/29 19:58:08 step 5: mse=10141.364130 step=0.050000
2017/08/29 19:58:09 step 6: mse=10151.883240 step=0.050000
2017/08/29 19:58:09 step 7: mse=10162.108136 step=0.050000
2017/08/29 19:58:09 Saving...
2017/08/29 19:58:09 Gathering batch of experience...
2017/08/29 19:58:33 batch 11: mean=535.434783 stddev=293.919033 entropy=0.690639 frames=4674 count=92
2017/08/29 19:58:33 Training policy...
2017/08/29 19:58:35 tune 0: objective=9.036478 reg=0.006906 prune=0
2017/08/29 19:58:36 step 0: objective=9.048616 reg=0.006905
2017/08/29 19:58:37 step 1: objective=9.062757 reg=0.006905
2017/08/29 19:58:37 step 2: objective=9.077597 reg=0.006905
2017/08/29 19:58:38 step 3: objective=9.095508 reg=0.006904
2017/08/29 19:58:39 step 4: objective=9.116399 reg=0.006904
2017/08/29 19:58:39 step 5: objective=9.132624 reg=0.006903
2017/08/29 19:58:40 step 6: objective=9.146140 reg=0.006903
2017/08/29 19:58:41 step 7: objective=9.163982 reg=0.006902
2017/08/29 19:58:41 Training value function...
2017/08/29 19:58:43 step 0: mse=9919.582351 step=0.050000
2017/08/29 19:58:43 step 1: mse=9917.205827 step=0.050000
2017/08/29 19:58:44 step 2: mse=9915.829036 step=0.050000
2017/08/29 19:58:45 step 3: mse=9916.823890 step=0.050000
2017/08/29 19:58:45 step 4: mse=9914.801485 step=0.050000
2017/08/29 19:58:46 step 5: mse=9918.151632 step=0.050000
2017/08/29 19:58:47 step 6: mse=9918.273447 step=0.050000
2017/08/29 19:58:47 step 7: mse=9925.797959 step=0.050000
2017/08/29 19:58:47 Saving...
2017/08/29 19:58:47 Gathering batch of experience...
2017/08/29 19:59:09 batch 12: mean=628.223684 stddev=329.872088 entropy=0.689887 frames=4490 count=76
2017/08/29 19:59:09 Training policy...
2017/08/29 19:59:11 tune 0: objective=21.188645 reg=0.006899 prune=0
2017/08/29 19:59:12 step 0: objective=21.209697 reg=0.006897
2017/08/29 19:59:13 step 1: objective=21.229948 reg=0.006897
2017/08/29 19:59:13 step 2: objective=21.246242 reg=0.006896
2017/08/29 19:59:14 step 3: objective=21.264745 reg=0.006896
2017/08/29 19:59:15 step 4: objective=21.284928 reg=0.006895
2017/08/29 19:59:15 step 5: objective=21.301331 reg=0.006895
2017/08/29 19:59:16 step 6: objective=21.313166 reg=0.006894
2017/08/29 19:59:17 step 7: objective=21.338370 reg=0.006893
2017/08/29 19:59:17 Training value function...
2017/08/29 19:59:18 step 0: mse=12534.436193 step=0.050000
2017/08/29 19:59:19 step 1: mse=12481.047628 step=0.050000
2017/08/29 19:59:20 step 2: mse=12427.551801 step=0.050000
2017/08/29 19:59:20 step 3: mse=12383.799697 step=0.050000
2017/08/29 19:59:21 step 4: mse=12343.960884 step=0.050000
2017/08/29 19:59:22 step 5: mse=12302.819527 step=0.050000
2017/08/29 19:59:22 step 6: mse=12267.151275 step=0.050000
2017/08/29 19:59:23 step 7: mse=12229.959481 step=0.050000
2017/08/29 19:59:23 Saving...
2017/08/29 19:59:23 Gathering batch of experience...
2017/08/29 19:59:45 batch 13: mean=645.526316 stddev=355.405235 entropy=0.689202 frames=4573 count=76
2017/08/29 19:59:45 Training policy...
2017/08/29 19:59:47 tune 0: objective=22.771030 reg=0.006892 prune=0
2017/08/29 19:59:48 step 0: objective=22.784329 reg=0.006892
2017/08/29 19:59:49 step 1: objective=22.809919 reg=0.006891
2017/08/29 19:59:49 step 2: objective=22.832170 reg=0.006891
2017/08/29 19:59:50 step 3: objective=22.856360 reg=0.006891
2017/08/29 19:59:51 step 4: objective=22.874879 reg=0.006890
2017/08/29 19:59:51 step 5: objective=22.902134 reg=0.006890
2017/08/29 19:59:52 step 6: objective=22.924544 reg=0.006890
2017/08/29 19:59:53 step 7: objective=22.950004 reg=0.006889
2017/08/29 19:59:53 Training value function...
2017/08/29 19:59:54 step 0: mse=13660.073106 step=0.050000
2017/08/29 19:59:55 step 1: mse=13582.842748 step=0.050000
2017/08/29 19:59:56 step 2: mse=13514.275700 step=0.050000
2017/08/29 19:59:56 step 3: mse=13452.519746 step=0.050000
2017/08/29 19:59:57 step 4: mse=13394.425737 step=0.050000
2017/08/29 19:59:58 step 5: mse=13340.854933 step=0.050000
2017/08/29 19:59:58 step 6: mse=13287.843781 step=0.050000
2017/08/29 19:59:59 step 7: mse=13239.602382 step=0.050000
2017/08/29 19:59:59 Saving...
2017/08/29 19:59:59 Gathering batch of experience...
2017/08/29 20:00:21 batch 14: mean=634.605263 stddev=346.824659 entropy=0.688909 frames=4508 count=76
2017/08/29 20:00:21 Training policy...
2017/08/29 20:00:23 tune 0: objective=19.738207 reg=0.006889 prune=0
2017/08/29 20:00:24 step 0: objective=19.749614 reg=0.006888
2017/08/29 20:00:25 step 1: objective=19.769788 reg=0.006887
2017/08/29 20:00:25 step 2: objective=19.792639 reg=0.006887
2017/08/29 20:00:26 step 3: objective=19.815893 reg=0.006886
2017/08/29 20:00:27 step 4: objective=19.842046 reg=0.006886
2017/08/29 20:00:27 step 5: objective=19.868506 reg=0.006885
2017/08/29 20:00:28 step 6: objective=19.892043 reg=0.006884
2017/08/29 20:00:29 step 7: objective=19.914471 reg=0.006883
2017/08/29 20:00:29 Training value function...
2017/08/29 20:00:30 step 0: mse=12392.169458 step=0.050000
2017/08/29 20:00:31 step 1: mse=12359.532719 step=0.050000
2017/08/29 20:00:32 step 2: mse=12328.610041 step=0.050000
2017/08/29 20:00:32 step 3: mse=12300.449125 step=0.050000
2017/08/29 20:00:33 step 4: mse=12270.866922 step=0.050000
2017/08/29 20:00:34 step 5: mse=12243.324551 step=0.050000
2017/08/29 20:00:34 step 6: mse=12219.344546 step=0.050000
2017/08/29 20:00:35 step 7: mse=12198.755881 step=0.050000
2017/08/29 20:00:35 Saving...
2017/08/29 20:00:35 Gathering batch of experience...
2017/08/29 20:00:58 batch 15: mean=612.716049 stddev=331.986213 entropy=0.688475 frames=4719 count=81
2017/08/29 20:00:58 Training policy...
2017/08/29 20:01:00 tune 0: objective=15.445296 reg=0.006885 prune=0
2017/08/29 20:01:01 step 0: objective=15.459284 reg=0.006883
2017/08/29 20:01:02 step 1: objective=15.478158 reg=0.006883
2017/08/29 20:01:02 step 2: objective=15.499877 reg=0.006882
2017/08/29 20:01:03 step 3: objective=15.513072 reg=0.006881
2017/08/29 20:01:04 step 4: objective=15.532861 reg=0.006881
2017/08/29 20:01:05 step 5: objective=15.547784 reg=0.006880
2017/08/29 20:01:05 step 6: objective=15.570659 reg=0.006880
2017/08/29 20:01:06 step 7: objective=15.590762 reg=0.006879
2017/08/29 20:01:06 Training value function...
2017/08/29 20:01:08 step 0: mse=11508.945296 step=0.050000
2017/08/29 20:01:08 step 1: mse=11503.835719 step=0.050000
2017/08/29 20:01:09 step 2: mse=11503.123055 step=0.050000
2017/08/29 20:01:10 step 3: mse=11502.304275 step=0.050000
2017/08/29 20:01:11 step 4: mse=11497.769351 step=0.050000
2017/08/29 20:01:11 step 5: mse=11494.777946 step=0.050000
2017/08/29 20:01:12 step 6: mse=11491.764546 step=0.050000
2017/08/29 20:01:13 step 7: mse=11490.806119 step=0.050000
2017/08/29 20:01:13 Saving...
2017/08/29 20:01:13 Gathering batch of experience...
2017/08/29 20:01:35 batch 16: mean=591.062500 stddev=312.695633 entropy=0.687792 frames=4488 count=80
2017/08/29 20:01:35 Training policy...
2017/08/29 20:01:37 tune 0: objective=14.104263 reg=0.006878 prune=0
2017/08/29 20:01:38 step 0: objective=14.115547 reg=0.006877
2017/08/29 20:01:38 step 1: objective=14.127715 reg=0.006876
2017/08/29 20:01:39 step 2: objective=14.141360 reg=0.006876
2017/08/29 20:01:40 step 3: objective=14.155032 reg=0.006875
2017/08/29 20:01:40 step 4: objective=14.174806 reg=0.006874
2017/08/29 20:01:41 step 5: objective=14.195482 reg=0.006874
2017/08/29 20:01:42 step 6: objective=14.211555 reg=0.006873
2017/08/29 20:01:42 step 7: objective=14.227503 reg=0.006873
2017/08/29 20:01:42 Training value function...
2017/08/29 20:01:44 step 0: mse=10849.623274 step=0.050000
2017/08/29 20:01:45 step 1: mse=10853.694282 step=0.050000
2017/08/29 20:01:45 step 2: mse=10859.933772 step=0.050000
2017/08/29 20:01:46 step 3: mse=10865.131984 step=0.050000
2017/08/29 20:01:47 step 4: mse=10869.082966 step=0.050000
2017/08/29 20:01:48 step 5: mse=10875.001689 step=0.050000
2017/08/29 20:01:48 step 6: mse=10881.820204 step=0.050000
2017/08/29 20:01:49 step 7: mse=10886.554446 step=0.050000
2017/08/29 20:01:49 Saving...
2017/08/29 20:01:49 Gathering batch of experience...
2017/08/29 20:02:11 batch 17: mean=606.428571 stddev=290.409314 entropy=0.686926 frames=4499 count=77
2017/08/29 20:02:11 Training policy...
2017/08/29 20:02:13 tune 0: objective=14.864920 reg=0.006869 prune=0
2017/08/29 20:02:14 step 0: objective=14.883186 reg=0.006867
2017/08/29 20:02:14 step 1: objective=14.903032 reg=0.006867
2017/08/29 20:02:15 step 2: objective=14.926336 reg=0.006866
2017/08/29 20:02:16 step 3: objective=14.950197 reg=0.006865
2017/08/29 20:02:16 step 4: objective=14.972270 reg=0.006864
2017/08/29 20:02:17 step 5: objective=14.990496 reg=0.006864
2017/08/29 20:02:18 step 6: objective=15.010945 reg=0.006864
2017/08/29 20:02:18 step 7: objective=15.034160 reg=0.006863
2017/08/29 20:02:18 Training value function...
2017/08/29 20:02:20 step 0: mse=10513.433713 step=0.050000
2017/08/29 20:02:21 step 1: mse=10492.712552 step=0.050000
2017/08/29 20:02:21 step 2: mse=10473.086025 step=0.050000
2017/08/29 20:02:22 step 3: mse=10459.008926 step=0.050000
2017/08/29 20:02:23 step 4: mse=10447.691846 step=0.050000
2017/08/29 20:02:23 step 5: mse=10437.682802 step=0.050000
2017/08/29 20:02:24 step 6: mse=10428.750357 step=0.050000
2017/08/29 20:02:25 step 7: mse=10423.371573 step=0.050000
2017/08/29 20:02:25 Saving...
2017/08/29 20:02:25 Gathering batch of experience...
2017/08/29 20:02:47 batch 18: mean=729.275362 stddev=370.390780 entropy=0.685094 frames=4635 count=69
2017/08/29 20:02:47 Training policy...
2017/08/29 20:02:49 tune 0: objective=30.035157 reg=0.006851 prune=0
2017/08/29 20:02:50 step 0: objective=30.054339 reg=0.006848
2017/08/29 20:02:50 step 1: objective=30.074161 reg=0.006847
2017/08/29 20:02:51 step 2: objective=30.093197 reg=0.006847
2017/08/29 20:02:52 step 3: objective=30.108485 reg=0.006846
2017/08/29 20:02:52 step 4: objective=30.132022 reg=0.006845
2017/08/29 20:02:53 step 5: objective=30.148146 reg=0.006844
2017/08/29 20:02:54 step 6: objective=30.171036 reg=0.006843
2017/08/29 20:02:54 step 7: objective=30.193045 reg=0.006842
2017/08/29 20:02:54 Training value function...
2017/08/29 20:02:56 step 0: mse=14988.564586 step=0.050000
2017/08/29 20:02:57 step 1: mse=14792.949419 step=0.050000
2017/08/29 20:02:58 step 2: mse=14608.534720 step=0.050000
2017/08/29 20:02:58 step 3: mse=14438.639078 step=0.050000
2017/08/29 20:02:59 step 4: mse=14285.492436 step=0.050000
2017/08/29 20:03:00 step 5: mse=14145.887758 step=0.050000
2017/08/29 20:03:00 step 6: mse=14013.410592 step=0.050000
2017/08/29 20:03:01 step 7: mse=13894.106473 step=0.050000
2017/08/29 20:03:01 Saving...
2017/08/29 20:03:01 Gathering batch of experience...
2017/08/29 20:03:24 batch 19: mean=616.419753 stddev=351.741027 entropy=0.685552 frames=4668 count=81
2017/08/29 20:03:24 Training policy...
2017/08/29 20:03:26 tune 0: objective=16.038895 reg=0.006856 prune=0
2017/08/29 20:03:27 step 0: objective=16.057854 reg=0.006854
2017/08/29 20:03:28 step 1: objective=16.081273 reg=0.006853
2017/08/29 20:03:28 step 2: objective=16.097134 reg=0.006853
2017/08/29 20:03:29 step 3: objective=16.118583 reg=0.006852
2017/08/29 20:03:30 step 4: objective=16.140955 reg=0.006852
2017/08/29 20:03:30 step 5: objective=16.158441 reg=0.006852
2017/08/29 20:03:31 step 6: objective=16.190151 reg=0.006851
2017/08/29 20:03:32 step 7: objective=16.213697 reg=0.006850
2017/08/29 20:03:32 Training value function...
2017/08/29 20:03:34 step 0: mse=12415.196940 step=0.050000
2017/08/29 20:03:34 step 1: mse=12385.827320 step=0.050000
2017/08/29 20:03:35 step 2: mse=12362.162669 step=0.050000
2017/08/29 20:03:36 step 3: mse=12340.549245 step=0.050000
2017/08/29 20:03:36 step 4: mse=12321.444243 step=0.050000
2017/08/29 20:03:37 step 5: mse=12305.831298 step=0.050000
2017/08/29 20:03:38 step 6: mse=12289.795779 step=0.050000
2017/08/29 20:03:38 step 7: mse=12276.568089 step=0.050000
2017/08/29 20:03:38 Saving...
2017/08/29 20:03:38 Gathering batch of experience...
2017/08/29 20:04:01 batch 20: mean=607.125000 stddev=344.523924 entropy=0.685066 frames=4575 count=80
2017/08/29 20:04:01 Training policy...
2017/08/29 20:04:03 tune 0: objective=15.052896 reg=0.006851 prune=0
2017/08/29 20:04:04 step 0: objective=15.068564 reg=0.006849
2017/08/29 20:04:05 step 1: objective=15.085227 reg=0.006848
2017/08/29 20:04:05 step 2: objective=15.102705 reg=0.006848
2017/08/29 20:04:06 step 3: objective=15.130196 reg=0.006847
2017/08/29 20:04:07 step 4: objective=15.151936 reg=0.006847
2017/08/29 20:04:07 step 5: objective=15.168714 reg=0.006846
2017/08/29 20:04:08 step 6: objective=15.186755 reg=0.006846
2017/08/29 20:04:09 step 7: objective=15.205055 reg=0.006846
2017/08/29 20:04:09 Training value function...
2017/08/29 20:04:10 step 0: mse=11755.839593 step=0.050000
2017/08/29 20:04:11 step 1: mse=11743.992785 step=0.050000
2017/08/29 20:04:12 step 2: mse=11737.156899 step=0.050000
2017/08/29 20:04:13 step 3: mse=11742.742751 step=0.050000
2017/08/29 20:04:13 step 4: mse=11740.409901 step=0.050000
2017/08/29 20:04:14 step 5: mse=11734.329569 step=0.050000
2017/08/29 20:04:15 step 6: mse=11730.987627 step=0.050000
2017/08/29 20:04:15 step 7: mse=11726.617987 step=0.050000
2017/08/29 20:04:15 Saving...
2017/08/29 20:04:15 Gathering batch of experience...
2017/08/29 20:04:38 batch 21: mean=645.844156 stddev=319.207015 entropy=0.683785 frames=4598 count=77
2017/08/29 20:04:38 Training policy...
2017/08/29 20:04:40 tune 0: objective=19.634357 reg=0.006838 prune=0
2017/08/29 20:04:41 step 0: objective=19.646507 reg=0.006837
2017/08/29 20:04:41 step 1: objective=19.662978 reg=0.006837
2017/08/29 20:04:42 step 2: objective=19.684499 reg=0.006837
2017/08/29 20:04:43 step 3: objective=19.702746 reg=0.006837
2017/08/29 20:04:43 step 4: objective=19.718227 reg=0.006838
2017/08/29 20:04:44 step 5: objective=19.737432 reg=0.006837
2017/08/29 20:04:45 step 6: objective=19.754229 reg=0.006837
2017/08/29 20:04:45 step 7: objective=19.773813 reg=0.006837
2017/08/29 20:04:45 Training value function...
2017/08/29 20:04:47 step 0: mse=11923.474818 step=0.050000
2017/08/29 20:04:48 step 1: mse=11879.433746 step=0.050000
2017/08/29 20:04:48 step 2: mse=11843.197319 step=0.050000
2017/08/29 20:04:49 step 3: mse=11806.541798 step=0.050000
2017/08/29 20:04:50 step 4: mse=11776.191614 step=0.050000
2017/08/29 20:04:51 step 5: mse=11746.641118 step=0.050000
2017/08/29 20:04:51 step 6: mse=11715.219419 step=0.050000
2017/08/29 20:04:52 step 7: mse=11685.940234 step=0.050000
2017/08/29 20:04:52 Saving...
2017/08/29 20:04:52 Gathering batch of experience...
2017/08/29 20:05:14 batch 22: mean=609.102564 stddev=326.148605 entropy=0.684751 frames=4433 count=78
2017/08/29 20:05:14 Training policy...
2017/08/29 20:05:16 tune 0: objective=15.726118 reg=0.006848 prune=0
2017/08/29 20:05:16 step 0: objective=15.736832 reg=0.006846
2017/08/29 20:05:17 step 1: objective=15.750795 reg=0.006845
2017/08/29 20:05:18 step 2: objective=15.763852 reg=0.006845
2017/08/29 20:05:18 step 3: objective=15.778166 reg=0.006844
2017/08/29 20:05:19 step 4: objective=15.793697 reg=0.006843
2017/08/29 20:05:20 step 5: objective=15.815366 reg=0.006842
2017/08/29 20:05:20 step 6: objective=15.834147 reg=0.006842
2017/08/29 20:05:21 step 7: objective=15.851409 reg=0.006841
2017/08/29 20:05:21 Training value function...
2017/08/29 20:05:23 step 0: mse=11783.278847 step=0.050000
2017/08/29 20:05:23 step 1: mse=11769.047128 step=0.050000
2017/08/29 20:05:24 step 2: mse=11759.683562 step=0.050000
2017/08/29 20:05:25 step 3: mse=11749.590450 step=0.050000
2017/08/29 20:05:25 step 4: mse=11742.551783 step=0.050000
2017/08/29 20:05:26 step 5: mse=11733.848073 step=0.050000
2017/08/29 20:05:27 step 6: mse=11725.838254 step=0.050000
2017/08/29 20:05:27 step 7: mse=11720.773436 step=0.050000
2017/08/29 20:05:27 Saving...
2017/08/29 20:05:27 Gathering batch of experience...
2017/08/29 20:05:50 batch 23: mean=660.533333 stddev=350.266159 entropy=0.682334 frames=4582 count=75
2017/08/29 20:05:50 Training policy...
2017/08/29 20:05:52 tune 0: objective=21.642816 reg=0.006823 prune=0
2017/08/29 20:05:53 step 0: objective=21.655906 reg=0.006821
2017/08/29 20:05:53 step 1: objective=21.668826 reg=0.006820
2017/08/29 20:05:54 step 2: objective=21.681969 reg=0.006820
2017/08/29 20:05:55 step 3: objective=21.703207 reg=0.006819
2017/08/29 20:05:56 step 4: objective=21.713294 reg=0.006819
2017/08/29 20:05:56 step 5: objective=21.736702 reg=0.006818
2017/08/29 20:05:57 step 6: objective=21.747971 reg=0.006817
2017/08/29 20:05:58 step 7: objective=21.759870 reg=0.006817
2017/08/29 20:05:58 Training value function...
2017/08/29 20:05:59 step 0: mse=12855.933053 step=0.050000
2017/08/29 20:06:00 step 1: mse=12795.584530 step=0.050000
2017/08/29 20:06:01 step 2: mse=12750.043258 step=0.050000
2017/08/29 20:06:01 step 3: mse=12702.345615 step=0.050000
2017/08/29 20:06:02 step 4: mse=12657.122865 step=0.050000
2017/08/29 20:06:03 step 5: mse=12614.396373 step=0.050000
2017/08/29 20:06:04 step 6: mse=12575.808774 step=0.050000
2017/08/29 20:06:04 step 7: mse=12536.535383 step=0.050000
2017/08/29 20:06:04 Saving...
2017/08/29 20:06:04 Gathering batch of experience...
2017/08/29 20:06:27 batch 24: mean=650.259740 stddev=335.535912 entropy=0.682180 frames=4628 count=77
2017/08/29 20:06:27 Training policy...
2017/08/29 20:06:29 tune 0: objective=19.302292 reg=0.006822 prune=0
2017/08/29 20:06:30 step 0: objective=19.309875 reg=0.006821
2017/08/29 20:06:31 step 1: objective=19.320878 reg=0.006821
2017/08/29 20:06:31 step 2: objective=19.335348 reg=0.006821
2017/08/29 20:06:32 step 3: objective=19.348490 reg=0.006821
2017/08/29 20:06:33 step 4: objective=19.357960 reg=0.006820
2017/08/29 20:06:33 step 5: objective=19.370545 reg=0.006820
2017/08/29 20:06:34 step 6: objective=19.384776 reg=0.006820
2017/08/29 20:06:35 step 7: objective=19.401206 reg=0.006820
2017/08/29 20:06:35 Training value function...
2017/08/29 20:06:37 step 0: mse=12008.171409 step=0.050000
2017/08/29 20:06:37 step 1: mse=11957.494789 step=0.050000
2017/08/29 20:06:38 step 2: mse=11906.626104 step=0.050000
2017/08/29 20:06:39 step 3: mse=11863.346778 step=0.050000
2017/08/29 20:06:39 step 4: mse=11823.317960 step=0.050000
2017/08/29 20:06:40 step 5: mse=11786.014009 step=0.050000
2017/08/29 20:06:41 step 6: mse=11757.022170 step=0.050000
2017/08/29 20:06:41 step 7: mse=11727.906811 step=0.050000
2017/08/29 20:06:41 Saving...
2017/08/29 20:06:41 Gathering batch of experience...
2017/08/29 20:07:05 batch 25: mean=616.750000 stddev=325.467068 entropy=0.682180 frames=4627 count=80
2017/08/29 20:07:05 Training policy...
2017/08/29 20:07:07 tune 0: objective=14.665489 reg=0.006822 prune=0
2017/08/29 20:07:07 step 0: objective=14.674445 reg=0.006821
2017/08/29 20:07:08 step 1: objective=14.688755 reg=0.006821
2017/08/29 20:07:09 step 2: objective=14.706838 reg=0.006821
2017/08/29 20:07:10 step 3: objective=14.717524 reg=0.006821
2017/08/29 20:07:10 step 4: objective=14.732747 reg=0.006821
2017/08/29 20:07:11 step 5: objective=14.753831 reg=0.006820
2017/08/29 20:07:12 step 6: objective=14.771357 reg=0.006820
2017/08/29 20:07:12 step 7: objective=14.793010 reg=0.006820
2017/08/29 20:07:12 Training value function...
2017/08/29 20:07:14 step 0: mse=10941.879917 step=0.050000
2017/08/29 20:07:15 step 1: mse=10940.536217 step=0.050000
2017/08/29 20:07:15 step 2: mse=10944.607629 step=0.050000
2017/08/29 20:07:16 step 3: mse=10952.414125 step=0.050000
2017/08/29 20:07:17 step 4: mse=10958.745765 step=0.050000
2017/08/29 20:07:18 step 5: mse=10960.724597 step=0.050000
2017/08/29 20:07:18 step 6: mse=10964.351813 step=0.050000
2017/08/29 20:07:19 step 7: mse=10963.937207 step=0.050000
2017/08/29 20:07:19 Saving...
2017/08/29 20:07:19 Gathering batch of experience...
2017/08/29 20:07:42 batch 26: mean=627.215190 stddev=326.417790 entropy=0.682583 frames=4687 count=79
2017/08/29 20:07:42 Training policy...
2017/08/29 20:07:44 tune 0: objective=16.647207 reg=0.006826 prune=0
2017/08/29 20:07:45 step 0: objective=16.657907 reg=0.006825
2017/08/29 20:07:46 step 1: objective=16.676662 reg=0.006824
2017/08/29 20:07:46 step 2: objective=16.694232 reg=0.006823
2017/08/29 20:07:47 step 3: objective=16.714923 reg=0.006823
2017/08/29 20:07:48 step 4: objective=16.737680 reg=0.006822
2017/08/29 20:07:48 step 5: objective=16.760834 reg=0.006821
2017/08/29 20:07:49 step 6: objective=16.783659 reg=0.006821
2017/08/29 20:07:50 step 7: objective=16.804701 reg=0.006820
2017/08/29 20:07:50 Training value function...
2017/08/29 20:07:52 step 0: mse=10799.556750 step=0.050000
2017/08/29 20:07:52 step 1: mse=10787.396160 step=0.050000
2017/08/29 20:07:53 step 2: mse=10778.166334 step=0.050000
2017/08/29 20:07:54 step 3: mse=10773.390984 step=0.050000
2017/08/29 20:07:54 step 4: mse=10760.482190 step=0.050000
2017/08/29 20:07:55 step 5: mse=10750.780713 step=0.050000
2017/08/29 20:07:56 step 6: mse=10741.709673 step=0.050000
2017/08/29 20:07:57 step 7: mse=10733.703436 step=0.050000
2017/08/29 20:07:57 Saving...
2017/08/29 20:07:57 Gathering batch of experience...
2017/08/29 20:08:19 batch 27: mean=663.513514 stddev=361.697135 entropy=0.680813 frames=4554 count=74
2017/08/29 20:08:19 Training policy...
2017/08/29 20:08:21 tune 0: objective=22.107630 reg=0.006808 prune=0
2017/08/29 20:08:21 step 0: objective=22.115348 reg=0.006807
2017/08/29 20:08:22 step 1: objective=22.129500 reg=0.006806
2017/08/29 20:08:23 step 2: objective=22.150206 reg=0.006806
2017/08/29 20:08:23 step 3: objective=22.171467 reg=0.006805
2017/08/29 20:08:24 step 4: objective=22.196807 reg=0.006804
2017/08/29 20:08:25 step 5: objective=22.213804 reg=0.006803
2017/08/29 20:08:25 step 6: objective=22.228983 reg=0.006803
2017/08/29 20:08:26 step 7: objective=22.245625 reg=0.006802
2017/08/29 20:08:26 Training value function...
2017/08/29 20:08:28 step 0: mse=13298.425508 step=0.050000
2017/08/29 20:08:29 step 1: mse=13233.165076 step=0.050000
2017/08/29 20:08:29 step 2: mse=13172.757165 step=0.050000
2017/08/29 20:08:30 step 3: mse=13116.222059 step=0.050000
2017/08/29 20:08:31 step 4: mse=13058.469707 step=0.050000
2017/08/29 20:08:31 step 5: mse=13008.576645 step=0.050000
2017/08/29 20:08:32 step 6: mse=12961.982967 step=0.050000
2017/08/29 20:08:33 step 7: mse=12922.027921 step=0.050000
2017/08/29 20:08:33 Saving...
2017/08/29 20:08:33 Gathering batch of experience...
2017/08/29 20:08:55 batch 28: mean=676.891892 stddev=324.131587 entropy=0.679725 frames=4662 count=74
2017/08/29 20:08:55 Training policy...
2017/08/29 20:08:57 tune 0: objective=20.462233 reg=0.006797 prune=0
2017/08/29 20:08:58 step 0: objective=20.468411 reg=0.006797
2017/08/29 20:08:59 step 1: objective=20.476376 reg=0.006798
2017/08/29 20:08:59 step 2: objective=20.495893 reg=0.006798
2017/08/29 20:09:00 step 3: objective=20.513874 reg=0.006798
2017/08/29 20:09:01 step 4: objective=20.522502 reg=0.006798
2017/08/29 20:09:01 step 5: objective=20.536535 reg=0.006798
2017/08/29 20:09:02 step 6: objective=20.547850 reg=0.006798
2017/08/29 20:09:03 step 7: objective=20.556303 reg=0.006798
2017/08/29 20:09:03 Training value function...
2017/08/29 20:09:04 step 0: mse=11741.031312 step=0.050000
2017/08/29 20:09:05 step 1: mse=11703.674620 step=0.050000
2017/08/29 20:09:06 step 2: mse=11668.041989 step=0.050000
2017/08/29 20:09:07 step 3: mse=11636.244185 step=0.050000
2017/08/29 20:09:07 step 4: mse=11606.161646 step=0.050000
2017/08/29 20:09:08 step 5: mse=11578.186060 step=0.050000
2017/08/29 20:09:09 step 6: mse=11552.218100 step=0.050000
2017/08/29 20:09:09 step 7: mse=11529.873281 step=0.050000
2017/08/29 20:09:09 Saving...
2017/08/29 20:09:09 Gathering batch of experience...
2017/08/29 20:09:33 batch 29: mean=565.892857 stddev=337.611675 entropy=0.682271 frames=4552 count=84
2017/08/29 20:09:33 Training policy...
2017/08/29 20:09:35 tune 0: objective=8.415974 reg=0.006823 prune=0
2017/08/29 20:09:35 step 0: objective=8.429892 reg=0.006821
2017/08/29 20:09:36 step 1: objective=8.447433 reg=0.006820
2017/08/29 20:09:37 step 2: objective=8.470050 reg=0.006820
2017/08/29 20:09:37 step 3: objective=8.485458 reg=0.006819
2017/08/29 20:09:38 step 4: objective=8.503723 reg=0.006819
2017/08/29 20:09:39 step 5: objective=8.528882 reg=0.006818
2017/08/29 20:09:39 step 6: objective=8.550683 reg=0.006817
2017/08/29 20:09:40 step 7: objective=8.570433 reg=0.006817
2017/08/29 20:09:40 Training value function...
2017/08/29 20:09:42 step 0: mse=10973.097617 step=0.050000
2017/08/29 20:09:43 step 1: mse=10954.038489 step=0.050000
2017/08/29 20:09:43 step 2: mse=10939.265017 step=0.050000
2017/08/29 20:09:44 step 3: mse=10926.762730 step=0.050000
2017/08/29 20:09:45 step 4: mse=10920.626972 step=0.050000
2017/08/29 20:09:45 step 5: mse=10915.511842 step=0.050000
2017/08/29 20:09:46 step 6: mse=10910.336360 step=0.050000
2017/08/29 20:09:47 step 7: mse=10911.638782 step=0.050000
2017/08/29 20:09:47 Saving...
2017/08/29 20:09:47 Gathering batch of experience...
2017/08/29 20:10:10 batch 30: mean=623.797468 stddev=324.630477 entropy=0.679861 frames=4551 count=79
2017/08/29 20:10:10 Training policy...
2017/08/29 20:10:12 tune 0: objective=18.646283 reg=0.006799 prune=0
2017/08/29 20:10:13 step 0: objective=18.660004 reg=0.006798
2017/08/29 20:10:13 step 1: objective=18.676144 reg=0.006798
2017/08/29 20:10:14 step 2: objective=18.694555 reg=0.006798
2017/08/29 20:10:15 step 3: objective=18.711664 reg=0.006797
2017/08/29 20:10:15 step 4: objective=18.726339 reg=0.006797
2017/08/29 20:10:16 step 5: objective=18.746151 reg=0.006796
2017/08/29 20:10:17 step 6: objective=18.762722 reg=0.006796
2017/08/29 20:10:17 step 7: objective=18.779097 reg=0.006795
2017/08/29 20:10:17 Training value function...
2017/08/29 20:10:19 step 0: mse=12031.431763 step=0.050000
2017/08/29 20:10:20 step 1: mse=11996.939479 step=0.050000
2017/08/29 20:10:20 step 2: mse=11962.228567 step=0.050000
2017/08/29 20:10:21 step 3: mse=11931.749621 step=0.050000
2017/08/29 20:10:22 step 4: mse=11905.879308 step=0.050000
2017/08/29 20:10:22 step 5: mse=11883.731445 step=0.050000
2017/08/29 20:10:23 step 6: mse=11861.793566 step=0.050000
2017/08/29 20:10:24 step 7: mse=11842.390759 step=0.050000
2017/08/29 20:10:24 Saving...
2017/08/29 20:10:24 Gathering batch of experience...
2017/08/29 20:10:47 batch 31: mean=653.441558 stddev=373.937681 entropy=0.679984 frames=4683 count=77
2017/08/29 20:10:47 Training policy...
2017/08/29 20:10:49 tune 0: objective=21.334329 reg=0.006800 prune=0
2017/08/29 20:10:50 step 0: objective=21.343622 reg=0.006799
2017/08/29 20:10:50 step 1: objective=21.361312 reg=0.006799
2017/08/29 20:10:51 step 2: objective=21.380077 reg=0.006800
2017/08/29 20:10:52 step 3: objective=21.403124 reg=0.006800
2017/08/29 20:10:53 step 4: objective=21.426920 reg=0.006800
2017/08/29 20:10:53 step 5: objective=21.446065 reg=0.006800
2017/08/29 20:10:54 step 6: objective=21.467969 reg=0.006800
2017/08/29 20:10:55 step 7: objective=21.485316 reg=0.006800
2017/08/29 20:10:55 Training value function...
2017/08/29 20:10:57 step 0: mse=14007.682541 step=0.050000
2017/08/29 20:10:57 step 1: mse=13899.955814 step=0.050000
2017/08/29 20:10:58 step 2: mse=13829.254410 step=0.050000
2017/08/29 20:10:59 step 3: mse=13745.088283 step=0.050000
2017/08/29 20:10:59 step 4: mse=13666.549582 step=0.050000
2017/08/29 20:11:00 step 5: mse=13610.154813 step=0.050000
2017/08/29 20:11:01 step 6: mse=13544.918318 step=0.050000
2017/08/29 20:11:02 step 7: mse=13484.971657 step=0.050000
2017/08/29 20:11:02 Saving...
2017/08/29 20:11:02 Gathering batch of experience...
2017/08/29 20:11:26 batch 32: mean=622.439024 stddev=330.248653 entropy=0.679583 frames=4779 count=82
2017/08/29 20:11:26 Training policy...
2017/08/29 20:11:28 tune 0: objective=16.090147 reg=0.006796 prune=0
2017/08/29 20:11:29 step 0: objective=16.096814 reg=0.006795
2017/08/29 20:11:29 step 1: objective=16.108726 reg=0.006795
2017/08/29 20:11:30 step 2: objective=16.121981 reg=0.006795
2017/08/29 20:11:31 step 3: objective=16.136821 reg=0.006795
2017/08/29 20:11:32 step 4: objective=16.149284 reg=0.006795
2017/08/29 20:11:32 step 5: objective=16.160015 reg=0.006794
2017/08/29 20:11:33 step 6: objective=16.171146 reg=0.006794
2017/08/29 20:11:34 step 7: objective=16.185102 reg=0.006794
2017/08/29 20:11:34 Training value function...
2017/08/29 20:11:35 step 0: mse=11502.257803 step=0.050000
2017/08/29 20:11:36 step 1: mse=11502.199180 step=0.050000
2017/08/29 20:11:37 step 2: mse=11499.383718 step=0.050000
2017/08/29 20:11:38 step 3: mse=11501.557825 step=0.050000
2017/08/29 20:11:38 step 4: mse=11504.625802 step=0.050000
2017/08/29 20:11:39 step 5: mse=11500.010134 step=0.050000
2017/08/29 20:11:40 step 6: mse=11491.736307 step=0.050000
2017/08/29 20:11:41 step 7: mse=11490.328541 step=0.050000
2017/08/29 20:11:41 Saving...
2017/08/29 20:11:41 Gathering batch of experience...
2017/08/29 20:12:03 batch 33: mean=602.716049 stddev=309.712182 entropy=0.680578 frames=4624 count=81
2017/08/29 20:12:03 Training policy...
2017/08/29 20:12:06 tune 0: objective=14.686787 reg=0.006806 prune=0
2017/08/29 20:12:06 step 0: objective=14.699577 reg=0.006804
2017/08/29 20:12:07 step 1: objective=14.721043 reg=0.006803
2017/08/29 20:12:08 step 2: objective=14.734557 reg=0.006803
2017/08/29 20:12:08 step 3: objective=14.760534 reg=0.006801
2017/08/29 20:12:09 step 4: objective=14.784183 reg=0.006800
2017/08/29 20:12:10 step 5: objective=14.799962 reg=0.006799
2017/08/29 20:12:10 step 6: objective=14.815634 reg=0.006798
2017/08/29 20:12:11 step 7: objective=14.830850 reg=0.006798
2017/08/29 20:12:11 Training value function...
2017/08/29 20:12:13 step 0: mse=10705.233931 step=0.050000
2017/08/29 20:12:14 step 1: mse=10713.115004 step=0.050000
2017/08/29 20:12:14 step 2: mse=10719.595786 step=0.050000
2017/08/29 20:12:15 step 3: mse=10726.639401 step=0.050000
2017/08/29 20:12:16 step 4: mse=10731.998642 step=0.050000
2017/08/29 20:12:16 step 5: mse=10738.486799 step=0.050000
2017/08/29 20:12:17 step 6: mse=10743.084366 step=0.050000
2017/08/29 20:12:18 step 7: mse=10745.180003 step=0.050000
2017/08/29 20:12:18 Saving...
2017/08/29 20:12:18 Gathering batch of experience...
2017/08/29 20:12:41 batch 34: mean=624.102564 stddev=334.816965 entropy=0.678620 frames=4623 count=78
2017/08/29 20:12:41 Training policy...
2017/08/29 20:12:43 tune 0: objective=17.498449 reg=0.006786 prune=0
2017/08/29 20:12:44 step 0: objective=17.508333 reg=0.006785
2017/08/29 20:12:45 step 1: objective=17.524374 reg=0.006786
2017/08/29 20:12:45 step 2: objective=17.543749 reg=0.006785
2017/08/29 20:12:46 step 3: objective=17.557287 reg=0.006785
2017/08/29 20:12:47 step 4: objective=17.575908 reg=0.006785
2017/08/29 20:12:47 step 5: objective=17.590668 reg=0.006785
2017/08/29 20:12:48 step 6: objective=17.607114 reg=0.006784
2017/08/29 20:12:49 step 7: objective=17.632596 reg=0.006784
2017/08/29 20:12:49 Training value function...
2017/08/29 20:12:51 step 0: mse=11396.010750 step=0.050000
2017/08/29 20:12:51 step 1: mse=11379.851112 step=0.050000
2017/08/29 20:12:52 step 2: mse=11366.785016 step=0.050000
2017/08/29 20:12:53 step 3: mse=11349.157290 step=0.050000
2017/08/29 20:12:53 step 4: mse=11334.899513 step=0.050000
2017/08/29 20:12:54 step 5: mse=11322.064916 step=0.050000
2017/08/29 20:12:55 step 6: mse=11315.382258 step=0.050000
2017/08/29 20:12:55 step 7: mse=11302.702721 step=0.050000
2017/08/29 20:12:55 Saving...
2017/08/29 20:12:55 Gathering batch of experience...
2017/08/29 20:13:19 batch 35: mean=693.716216 stddev=383.522138 entropy=0.677391 frames=4642 count=74
2017/08/29 20:13:19 Training policy...
2017/08/29 20:13:21 tune 0: objective=27.847845 reg=0.006774 prune=0
2017/08/29 20:13:21 step 0: objective=27.856305 reg=0.006773
2017/08/29 20:13:22 step 1: objective=27.873723 reg=0.006772
2017/08/29 20:13:23 step 2: objective=27.895430 reg=0.006772
2017/08/29 20:13:24 step 3: objective=27.911228 reg=0.006772
2017/08/29 20:13:24 step 4: objective=27.928001 reg=0.006771
2017/08/29 20:13:25 step 5: objective=27.943032 reg=0.006771
2017/08/29 20:13:26 step 6: objective=27.961787 reg=0.006771
2017/08/29 20:13:26 step 7: objective=27.980014 reg=0.006771
2017/08/29 20:13:26 Training value function...
2017/08/29 20:13:28 step 0: mse=15296.298518 step=0.050000
2017/08/29 20:13:29 step 1: mse=15109.931824 step=0.050000
2017/08/29 20:13:30 step 2: mse=14944.387644 step=0.050000
2017/08/29 20:13:30 step 3: mse=14782.917144 step=0.050000
2017/08/29 20:13:31 step 4: mse=14634.435684 step=0.050000
2017/08/29 20:13:32 step 5: mse=14498.443234 step=0.050000
2017/08/29 20:13:32 step 6: mse=14371.181142 step=0.050000
2017/08/29 20:13:33 step 7: mse=14255.680663 step=0.050000
2017/08/29 20:13:33 Saving...
2017/08/29 20:13:33 Gathering batch of experience...
2017/08/29 20:13:56 batch 36: mean=621.687500 stddev=355.822940 entropy=0.678065 frames=4600 count=80
2017/08/29 20:13:56 Training policy...
2017/08/29 20:13:58 tune 0: objective=16.372500 reg=0.006781 prune=0
2017/08/29 20:13:59 step 0: objective=16.383843 reg=0.006779
2017/08/29 20:14:00 step 1: objective=16.398672 reg=0.006779
2017/08/29 20:14:00 step 2: objective=16.420924 reg=0.006778
2017/08/29 20:14:01 step 3: objective=16.437536 reg=0.006778
2017/08/29 20:14:02 step 4: objective=16.457668 reg=0.006777
2017/08/29 20:14:02 step 5: objective=16.476303 reg=0.006776
2017/08/29 20:14:03 step 6: objective=16.494531 reg=0.006775
2017/08/29 20:14:04 step 7: objective=16.511926 reg=0.006774
2017/08/29 20:14:04 Training value function...
2017/08/29 20:14:06 step 0: mse=12662.560495 step=0.050000
2017/08/29 20:14:06 step 1: mse=12650.978522 step=0.050000
2017/08/29 20:14:07 step 2: mse=12640.532587 step=0.050000
2017/08/29 20:14:08 step 3: mse=12633.530617 step=0.050000
2017/08/29 20:14:08 step 4: mse=12624.979705 step=0.050000
2017/08/29 20:14:09 step 5: mse=12619.355275 step=0.050000
2017/08/29 20:14:10 step 6: mse=12615.850636 step=0.050000
2017/08/29 20:14:11 step 7: mse=12607.341198 step=0.050000
2017/08/29 20:14:11 Saving...
2017/08/29 20:14:11 Gathering batch of experience...
2017/08/29 20:14:34 batch 37: mean=656.818182 stddev=358.281349 entropy=0.675683 frames=4650 count=77
2017/08/29 20:14:34 Training policy...
2017/08/29 20:14:36 tune 0: objective=19.578935 reg=0.006757 prune=0
2017/08/29 20:14:36 step 0: objective=19.588812 reg=0.006756
2017/08/29 20:14:37 step 1: objective=19.608473 reg=0.006755
2017/08/29 20:14:38 step 2: objective=19.625901 reg=0.006754
2017/08/29 20:14:38 step 3: objective=19.643093 reg=0.006754
2017/08/29 20:14:39 step 4: objective=19.663301 reg=0.006753
2017/08/29 20:14:40 step 5: objective=19.679926 reg=0.006753
2017/08/29 20:14:41 step 6: objective=19.705716 reg=0.006752
2017/08/29 20:14:41 step 7: objective=19.720064 reg=0.006752
2017/08/29 20:14:41 Training value function...
2017/08/29 20:14:43 step 0: mse=13134.541834 step=0.050000
2017/08/29 20:14:44 step 1: mse=13107.497202 step=0.050000
2017/08/29 20:14:44 step 2: mse=13082.244307 step=0.050000
2017/08/29 20:14:45 step 3: mse=13059.539126 step=0.050000
2017/08/29 20:14:46 step 4: mse=13033.289208 step=0.050000
2017/08/29 20:14:47 step 5: mse=13006.720252 step=0.050000
2017/08/29 20:14:47 step 6: mse=12987.418952 step=0.050000
2017/08/29 20:14:48 step 7: mse=12969.313214 step=0.050000
2017/08/29 20:14:48 Saving...
2017/08/29 20:14:48 Gathering batch of experience...
2017/08/29 20:15:12 batch 38: mean=616.812500 stddev=318.029326 entropy=0.676244 frames=4621 count=80
2017/08/29 20:15:12 Training policy...
2017/08/29 20:15:14 tune 0: objective=14.245374 reg=0.006762 prune=0
2017/08/29 20:15:15 step 0: objective=14.251336 reg=0.006762
2017/08/29 20:15:15 step 1: objective=14.265498 reg=0.006762
2017/08/29 20:15:16 step 2: objective=14.276144 reg=0.006762
2017/08/29 20:15:17 step 3: objective=14.291746 reg=0.006762
2017/08/29 20:15:17 step 4: objective=14.302231 reg=0.006762
2017/08/29 20:15:18 step 5: objective=14.314241 reg=0.006762
2017/08/29 20:15:19 step 6: objective=14.325667 reg=0.006762
2017/08/29 20:15:19 step 7: objective=14.340239 reg=0.006762
2017/08/29 20:15:19 Training value function...
2017/08/29 20:15:21 step 0: mse=10980.329611 step=0.050000
2017/08/29 20:15:22 step 1: mse=10982.112861 step=0.050000
2017/08/29 20:15:23 step 2: mse=10990.311056 step=0.050000
2017/08/29 20:15:23 step 3: mse=10993.674722 step=0.050000
2017/08/29 20:15:24 step 4: mse=11003.457704 step=0.050000
2017/08/29 20:15:25 step 5: mse=11008.063680 step=0.050000
2017/08/29 20:15:26 step 6: mse=11016.803275 step=0.050000
2017/08/29 20:15:26 step 7: mse=11020.380894 step=0.050000
2017/08/29 20:15:26 Saving...
2017/08/29 20:15:26 Gathering batch of experience...
2017/08/29 20:15:48 batch 39: mean=692.569444 stddev=369.068829 entropy=0.675110 frames=4657 count=72
2017/08/29 20:15:48 Training policy...
2017/08/29 20:15:51 tune 0: objective=22.347395 reg=0.006751 prune=0
2017/08/29 20:15:51 step 0: objective=22.359009 reg=0.006749
2017/08/29 20:15:52 step 1: objective=22.378209 reg=0.006749
2017/08/29 20:15:53 step 2: objective=22.398193 reg=0.006748
2017/08/29 20:15:53 step 3: objective=22.419466 reg=0.006748
2017/08/29 20:15:54 step 4: objective=22.438746 reg=0.006748
2017/08/29 20:15:55 step 5: objective=22.459050 reg=0.006747
2017/08/29 20:15:56 step 6: objective=22.484635 reg=0.006747
2017/08/29 20:15:56 step 7: objective=22.500067 reg=0.006746
2017/08/29 20:15:56 Training value function...
2017/08/29 20:15:58 step 0: mse=13697.546413 step=0.050000
2017/08/29 20:15:59 step 1: mse=13634.354827 step=0.050000
2017/08/29 20:16:00 step 2: mse=13573.406037 step=0.050000
2017/08/29 20:16:00 step 3: mse=13517.053533 step=0.050000
2017/08/29 20:16:01 step 4: mse=13464.115416 step=0.050000
2017/08/29 20:16:02 step 5: mse=13420.548215 step=0.050000
2017/08/29 20:16:02 step 6: mse=13361.433199 step=0.050000
2017/08/29 20:16:03 step 7: mse=13316.732419 step=0.050000
2017/08/29 20:16:03 Saving...
2017/08/29 20:16:03 Gathering batch of experience...
2017/08/29 20:16:26 batch 40: mean=718.098592 stddev=366.540129 entropy=0.673948 frames=4589 count=71
2017/08/29 20:16:26 Training policy...
2017/08/29 20:16:28 tune 0: objective=25.084780 reg=0.006739 prune=0
2017/08/29 20:16:29 step 0: objective=25.100982 reg=0.006737
2017/08/29 20:16:29 step 1: objective=25.121265 reg=0.006737
2017/08/29 20:16:30 step 2: objective=25.142246 reg=0.006736
2017/08/29 20:16:31 step 3: objective=25.162988 reg=0.006735
2017/08/29 20:16:31 step 4: objective=25.184953 reg=0.006734
2017/08/29 20:16:32 step 5: objective=25.214075 reg=0.006733
2017/08/29 20:16:33 step 6: objective=25.230630 reg=0.006733
2017/08/29 20:16:33 step 7: objective=25.248109 reg=0.006732
2017/08/29 20:16:33 Training value function...
2017/08/29 20:16:35 step 0: mse=14706.734458 step=0.050000
2017/08/29 20:16:36 step 1: mse=14591.936832 step=0.050000
2017/08/29 20:16:37 step 2: mse=14481.577244 step=0.050000
2017/08/29 20:16:37 step 3: mse=14378.462558 step=0.050000
2017/08/29 20:16:38 step 4: mse=14285.185933 step=0.050000
2017/08/29 20:16:39 step 5: mse=14200.715876 step=0.050000
2017/08/29 20:16:39 step 6: mse=14124.028684 step=0.050000
2017/08/29 20:16:40 step 7: mse=14046.389337 step=0.050000
2017/08/29 20:16:40 Saving...
2017/08/29 20:16:40 Gathering batch of experience...
2017/08/29 20:17:03 batch 41: mean=644.480519 stddev=368.002315 entropy=0.675853 frames=4546 count=77
2017/08/29 20:17:03 Training policy...
2017/08/29 20:17:05 tune 0: objective=16.308118 reg=0.006759 prune=0
2017/08/29 20:17:06 step 0: objective=16.316798 reg=0.006758
2017/08/29 20:17:07 step 1: objective=16.333590 reg=0.006758
2017/08/29 20:17:07 step 2: objective=16.353128 reg=0.006758
2017/08/29 20:17:08 step 3: objective=16.371035 reg=0.006757
2017/08/29 20:17:09 step 4: objective=16.390408 reg=0.006757
2017/08/29 20:17:09 step 5: objective=16.408281 reg=0.006757
2017/08/29 20:17:10 step 6: objective=16.427190 reg=0.006756
2017/08/29 20:17:11 step 7: objective=16.447509 reg=0.006756
2017/08/29 20:17:11 Training value function...
2017/08/29 20:17:12 step 0: mse=13805.883937 step=0.050000
2017/08/29 20:17:13 step 1: mse=13781.769390 step=0.050000
2017/08/29 20:17:14 step 2: mse=13759.350687 step=0.050000
2017/08/29 20:17:15 step 3: mse=13738.644713 step=0.050000
2017/08/29 20:17:15 step 4: mse=13720.942453 step=0.050000
2017/08/29 20:17:16 step 5: mse=13705.649108 step=0.050000
2017/08/29 20:17:17 step 6: mse=13695.842687 step=0.050000
2017/08/29 20:17:17 step 7: mse=13685.669112 step=0.050000
2017/08/29 20:17:17 Saving...
2017/08/29 20:17:17 Gathering batch of experience...
2017/08/29 20:17:40 batch 42: mean=688.219178 stddev=367.535638 entropy=0.673098 frames=4541 count=73
2017/08/29 20:17:40 Training policy...
2017/08/29 20:17:42 tune 0: objective=21.452120 reg=0.006731 prune=0
2017/08/29 20:17:43 step 0: objective=21.461689 reg=0.006730
2017/08/29 20:17:43 step 1: objective=21.474785 reg=0.006729
2017/08/29 20:17:44 step 2: objective=21.492504 reg=0.006730
2017/08/29 20:17:45 step 3: objective=21.510335 reg=0.006729
2017/08/29 20:17:45 step 4: objective=21.523923 reg=0.006729
2017/08/29 20:17:46 step 5: objective=21.538230 reg=0.006729
2017/08/29 20:17:47 step 6: objective=21.552547 reg=0.006729
2017/08/29 20:17:47 step 7: objective=21.571925 reg=0.006729
2017/08/29 20:17:47 Training value function...
2017/08/29 20:17:49 step 0: mse=13426.983495 step=0.050000
2017/08/29 20:17:50 step 1: mse=13371.973934 step=0.050000
2017/08/29 20:17:51 step 2: mse=13306.985807 step=0.050000
2017/08/29 20:17:51 step 3: mse=13259.620557 step=0.050000
2017/08/29 20:17:52 step 4: mse=13198.707555 step=0.050000
2017/08/29 20:17:53 step 5: mse=13143.897383 step=0.050000
2017/08/29 20:17:53 step 6: mse=13100.166818 step=0.050000
2017/08/29 20:17:54 step 7: mse=13051.639861 step=0.050000
2017/08/29 20:17:54 Saving...
2017/08/29 20:17:54 Gathering batch of experience...
2017/08/29 20:18:16 batch 43: mean=702.876712 stddev=391.699771 entropy=0.673180 frames=4662 count=73
2017/08/29 20:18:16 Training policy...
2017/08/29 20:18:19 tune 0: objective=21.720917 reg=0.006732 prune=0
2017/08/29 20:18:19 step 0: objective=21.726137 reg=0.006731
2017/08/29 20:18:20 step 1: objective=21.737410 reg=0.006731
2017/08/29 20:18:21 step 2: objective=21.749419 reg=0.006731
2017/08/29 20:18:22 step 3: objective=21.768888 reg=0.006731
2017/08/29 20:18:22 step 4: objective=21.779898 reg=0.006731
2017/08/29 20:18:23 step 5: objective=21.790985 reg=0.006731
2017/08/29 20:18:24 step 6: objective=21.808187 reg=0.006730
2017/08/29 20:18:24 step 7: objective=21.821936 reg=0.006730
2017/08/29 20:18:24 Training value function...
2017/08/29 20:18:26 step 0: mse=14071.601166 step=0.050000
2017/08/29 20:18:27 step 1: mse=14011.372988 step=0.050000
2017/08/29 20:18:28 step 2: mse=13955.227230 step=0.050000
2017/08/29 20:18:28 step 3: mse=13905.984659 step=0.050000
2017/08/29 20:18:29 step 4: mse=13858.499530 step=0.050000
2017/08/29 20:18:30 step 5: mse=13816.804620 step=0.050000
2017/08/29 20:18:30 step 6: mse=13778.395262 step=0.050000
2017/08/29 20:18:31 step 7: mse=13742.429641 step=0.050000
2017/08/29 20:18:31 Saving...
2017/08/29 20:18:31 Gathering batch of experience...
2017/08/29 20:18:54 batch 44: mean=618.291139 stddev=360.096582 entropy=0.675578 frames=4528 count=79
2017/08/29 20:18:54 Training policy...
2017/08/29 20:18:56 tune 0: objective=12.363866 reg=0.006756 prune=0
2017/08/29 20:18:57 step 0: objective=12.378540 reg=0.006753
2017/08/29 20:18:58 step 1: objective=12.397284 reg=0.006751
2017/08/29 20:18:58 step 2: objective=12.415931 reg=0.006750
2017/08/29 20:18:59 step 3: objective=12.433840 reg=0.006748
2017/08/29 20:19:00 step 4: objective=12.449329 reg=0.006746
2017/08/29 20:19:00 step 5: objective=12.468939 reg=0.006745
2017/08/29 20:19:01 step 6: objective=12.483795 reg=0.006744
2017/08/29 20:19:02 step 7: objective=12.504472 reg=0.006742
2017/08/29 20:19:02 Training value function...
2017/08/29 20:19:03 step 0: mse=12038.717710 step=0.050000
2017/08/29 20:19:04 step 1: mse=12036.217011 step=0.050000
2017/08/29 20:19:05 step 2: mse=12036.074885 step=0.050000
2017/08/29 20:19:05 step 3: mse=12038.867639 step=0.050000
2017/08/29 20:19:06 step 4: mse=12043.270806 step=0.050000
2017/08/29 20:19:07 step 5: mse=12047.594492 step=0.050000
2017/08/29 20:19:07 step 6: mse=12051.476033 step=0.050000
2017/08/29 20:19:08 step 7: mse=12056.833025 step=0.050000
2017/08/29 20:19:08 Saving...
2017/08/29 20:19:08 Gathering batch of experience...
2017/08/29 20:19:31 batch 45: mean=704.726027 stddev=374.647680 entropy=0.671272 frames=4666 count=73
2017/08/29 20:19:31 Training policy...
2017/08/29 20:19:33 tune 0: objective=22.724786 reg=0.006713 prune=0
2017/08/29 20:19:34 step 0: objective=22.733565 reg=0.006713
2017/08/29 20:19:35 step 1: objective=22.750174 reg=0.006713
2017/08/29 20:19:35 step 2: objective=22.765049 reg=0.006713
2017/08/29 20:19:36 step 3: objective=22.781203 reg=0.006713
2017/08/29 20:19:37 step 4: objective=22.798867 reg=0.006714
2017/08/29 20:19:37 step 5: objective=22.816957 reg=0.006714
2017/08/29 20:19:38 step 6: objective=22.837192 reg=0.006714
2017/08/29 20:19:39 step 7: objective=22.850859 reg=0.006714
2017/08/29 20:19:39 Training value function...
2017/08/29 20:19:41 step 0: mse=13725.281923 step=0.050000
2017/08/29 20:19:41 step 1: mse=13666.571091 step=0.050000
2017/08/29 20:19:42 step 2: mse=13611.368692 step=0.050000
2017/08/29 20:19:43 step 3: mse=13554.732841 step=0.050000
2017/08/29 20:19:44 step 4: mse=13507.159080 step=0.050000
2017/08/29 20:19:44 step 5: mse=13459.664796 step=0.050000
2017/08/29 20:19:45 step 6: mse=13420.827407 step=0.050000
2017/08/29 20:19:46 step 7: mse=13381.808344 step=0.050000
2017/08/29 20:19:46 Saving...
2017/08/29 20:19:46 Gathering batch of experience...
2017/08/29 20:20:09 batch 46: mean=697.708333 stddev=343.205819 entropy=0.670912 frames=4638 count=72
2017/08/29 20:20:09 Training policy...
2017/08/29 20:20:11 tune 0: objective=18.339315 reg=0.006709 prune=0
2017/08/29 20:20:12 step 0: objective=18.354350 reg=0.006706
2017/08/29 20:20:12 step 1: objective=18.377101 reg=0.006705
2017/08/29 20:20:13 step 2: objective=18.398668 reg=0.006704
2017/08/29 20:20:14 step 3: objective=18.419458 reg=0.006702
2017/08/29 20:20:14 step 4: objective=18.438669 reg=0.006700
2017/08/29 20:20:15 step 5: objective=18.461473 reg=0.006698
2017/08/29 20:20:16 step 6: objective=18.482237 reg=0.006697
2017/08/29 20:20:16 step 7: objective=18.503477 reg=0.006696
2017/08/29 20:20:16 Training value function...
2017/08/29 20:20:18 step 0: mse=11928.987962 step=0.050000
2017/08/29 20:20:19 step 1: mse=11901.620677 step=0.050000
2017/08/29 20:20:20 step 2: mse=11880.240630 step=0.050000
2017/08/29 20:20:20 step 3: mse=11859.535947 step=0.050000
2017/08/29 20:20:21 step 4: mse=11839.159925 step=0.050000
2017/08/29 20:20:22 step 5: mse=11820.781917 step=0.050000
2017/08/29 20:20:22 step 6: mse=11800.474400 step=0.050000
2017/08/29 20:20:23 step 7: mse=11788.811368 step=0.050000
2017/08/29 20:20:23 Saving...
2017/08/29 20:20:23 Gathering batch of experience...
2017/08/29 20:20:47 batch 47: mean=653.687500 stddev=382.828081 entropy=0.670672 frames=4750 count=80
2017/08/29 20:20:47 Training policy...
2017/08/29 20:20:49 tune 0: objective=17.199178 reg=0.006707 prune=0
2017/08/29 20:20:50 step 0: objective=17.216100 reg=0.006705
2017/08/29 20:20:50 step 1: objective=17.234495 reg=0.006704
2017/08/29 20:20:51 step 2: objective=17.262097 reg=0.006703
2017/08/29 20:20:52 step 3: objective=17.284977 reg=0.006702
2017/08/29 20:20:53 step 4: objective=17.313893 reg=0.006700
2017/08/29 20:20:53 step 5: objective=17.338400 reg=0.006699
2017/08/29 20:20:54 step 6: objective=17.368556 reg=0.006698
2017/08/29 20:20:55 step 7: objective=17.390735 reg=0.006697
2017/08/29 20:20:55 Training value function...
2017/08/29 20:20:57 step 0: mse=13877.510119 step=0.050000
2017/08/29 20:20:57 step 1: mse=13867.259308 step=0.050000
2017/08/29 20:20:58 step 2: mse=13857.389642 step=0.050000
2017/08/29 20:20:59 step 3: mse=13844.074043 step=0.050000
2017/08/29 20:20:59 step 4: mse=13825.050279 step=0.050000
2017/08/29 20:21:00 step 5: mse=13815.770530 step=0.050000
2017/08/29 20:21:01 step 6: mse=13807.355548 step=0.050000
2017/08/29 20:21:02 step 7: mse=13794.103192 step=0.050000
2017/08/29 20:21:02 Saving...
2017/08/29 20:21:02 Gathering batch of experience...
2017/08/29 20:21:24 batch 48: mean=672.297297 stddev=348.531852 entropy=0.668403 frames=4552 count=74
2017/08/29 20:21:24 Training policy...
2017/08/29 20:21:26 tune 0: objective=17.448628 reg=0.006684 prune=0
2017/08/29 20:21:27 step 0: objective=17.457297 reg=0.006683
2017/08/29 20:21:28 step 1: objective=17.473566 reg=0.006682
2017/08/29 20:21:28 step 2: objective=17.493401 reg=0.006682
2017/08/29 20:21:29 step 3: objective=17.515203 reg=0.006681
2017/08/29 20:21:30 step 4: objective=17.534902 reg=0.006682
2017/08/29 20:21:30 step 5: objective=17.561077 reg=0.006682
2017/08/29 20:21:31 step 6: objective=17.584504 reg=0.006681
2017/08/29 20:21:32 step 7: objective=17.603761 reg=0.006681
2017/08/29 20:21:32 Training value function...
2017/08/29 20:21:33 step 0: mse=12702.326106 step=0.050000
2017/08/29 20:21:34 step 1: mse=12694.000718 step=0.050000
2017/08/29 20:21:35 step 2: mse=12686.115915 step=0.050000
2017/08/29 20:21:35 step 3: mse=12679.039950 step=0.050000
2017/08/29 20:21:36 step 4: mse=12673.952873 step=0.050000
2017/08/29 20:21:37 step 5: mse=12667.832688 step=0.050000
2017/08/29 20:21:38 step 6: mse=12663.482204 step=0.050000
2017/08/29 20:21:38 step 7: mse=12661.228278 step=0.050000
2017/08/29 20:21:38 Saving...
2017/08/29 20:21:38 Gathering batch of experience...
2017/08/29 20:22:01 batch 49: mean=673.733333 stddev=374.519330 entropy=0.670141 frames=4611 count=75
2017/08/29 20:22:01 Training policy...
2017/08/29 20:22:04 tune 0: objective=18.998084 reg=0.006701 prune=0
2017/08/29 20:22:04 step 0: objective=19.011142 reg=0.006700
2017/08/29 20:22:05 step 1: objective=19.038671 reg=0.006700
2017/08/29 20:22:06 step 2: objective=19.062563 reg=0.006699
2017/08/29 20:22:06 step 3: objective=19.084567 reg=0.006698
2017/08/29 20:22:07 step 4: objective=19.108170 reg=0.006697
2017/08/29 20:22:08 step 5: objective=19.129204 reg=0.006696
2017/08/29 20:22:08 step 6: objective=19.156879 reg=0.006696
2017/08/29 20:22:09 step 7: objective=19.178127 reg=0.006695
2017/08/29 20:22:09 Training value function...
2017/08/29 20:22:11 step 0: mse=13686.964403 step=0.050000
2017/08/29 20:22:11 step 1: mse=13638.949006 step=0.050000
2017/08/29 20:22:12 step 2: mse=13593.002510 step=0.050000
2017/08/29 20:22:13 step 3: mse=13540.705172 step=0.050000
2017/08/29 20:22:13 step 4: mse=13491.437820 step=0.050000
2017/08/29 20:22:14 step 5: mse=13455.396699 step=0.050000
2017/08/29 20:22:15 step 6: mse=13420.734821 step=0.050000
2017/08/29 20:22:16 step 7: mse=13382.821870 step=0.050000
2017/08/29 20:22:16 Saving...
2017/08/29 20:22:16 Gathering batch of experience...
2017/08/29 20:22:38 batch 50: mean=600.696203 stddev=361.597838 entropy=0.670556 frames=4388 count=79
2017/08/29 20:22:38 Training policy...
2017/08/29 20:22:40 tune 0: objective=12.223543 reg=0.006706 prune=0
2017/08/29 20:22:40 step 0: objective=12.229109 reg=0.006705
2017/08/29 20:22:41 step 1: objective=12.238822 reg=0.006705
2017/08/29 20:22:42 step 2: objective=12.247415 reg=0.006705
2017/08/29 20:22:42 step 3: objective=12.259426 reg=0.006705
2017/08/29 20:22:43 step 4: objective=12.268802 reg=0.006705
2017/08/29 20:22:44 step 5: objective=12.279153 reg=0.006705
2017/08/29 20:22:44 step 6: objective=12.289391 reg=0.006704
2017/08/29 20:22:45 step 7: objective=12.298515 reg=0.006704
2017/08/29 20:22:45 Training value function...
2017/08/29 20:22:46 step 0: mse=12310.596305 step=0.050000
2017/08/29 20:22:47 step 1: mse=12308.869747 step=0.050000
2017/08/29 20:22:48 step 2: mse=12314.506757 step=0.050000
2017/08/29 20:22:48 step 3: mse=12307.263711 step=0.050000
2017/08/29 20:22:49 step 4: mse=12307.408335 step=0.050000
2017/08/29 20:22:50 step 5: mse=12313.553346 step=0.050000
2017/08/29 20:22:50 step 6: mse=12314.817259 step=0.050000
2017/08/29 20:22:51 step 7: mse=12315.434411 step=0.050000
2017/08/29 20:22:51 Saving...
2017/08/29 20:22:51 Gathering batch of experience...
2017/08/29 20:23:14 batch 51: mean=654.807692 stddev=384.951248 entropy=0.668296 frames=4619 count=78
2017/08/29 20:23:14 Training policy...
2017/08/29 20:23:16 tune 0: objective=20.688063 reg=0.006683 prune=0
2017/08/29 20:23:17 step 0: objective=20.700661 reg=0.006681
2017/08/29 20:23:18 step 1: objective=20.718205 reg=0.006680
2017/08/29 20:23:18 step 2: objective=20.737208 reg=0.006680
2017/08/29 20:23:19 step 3: objective=20.754178 reg=0.006679
2017/08/29 20:23:20 step 4: objective=20.767041 reg=0.006679
2017/08/29 20:23:20 step 5: objective=20.782517 reg=0.006679
2017/08/29 20:23:21 step 6: objective=20.796848 reg=0.006678
2017/08/29 20:23:22 step 7: objective=20.819489 reg=0.006676
2017/08/29 20:23:22 Training value function...
2017/08/29 20:23:24 step 0: mse=14529.058042 step=0.050000
2017/08/29 20:23:24 step 1: mse=14461.808265 step=0.050000
2017/08/29 20:23:25 step 2: mse=14388.557693 step=0.050000
2017/08/29 20:23:26 step 3: mse=14311.167331 step=0.050000
2017/08/29 20:23:26 step 4: mse=14242.338499 step=0.050000
2017/08/29 20:23:27 step 5: mse=14190.101699 step=0.050000
2017/08/29 20:23:28 step 6: mse=14131.030763 step=0.050000
2017/08/29 20:23:28 step 7: mse=14077.303614 step=0.050000
2017/08/29 20:23:28 Saving...
2017/08/29 20:23:28 Gathering batch of experience...
2017/08/29 20:23:50 batch 52: mean=699.166667 stddev=384.140455 entropy=0.666971 frames=4579 count=72
2017/08/29 20:23:50 Training policy...
2017/08/29 20:23:53 tune 0: objective=22.607058 reg=0.006670 prune=0
2017/08/29 20:23:53 step 0: objective=22.618221 reg=0.006668
2017/08/29 20:23:54 step 1: objective=22.641413 reg=0.006667
2017/08/29 20:23:55 step 2: objective=22.671143 reg=0.006667
2017/08/29 20:23:55 step 3: objective=22.697735 reg=0.006666
2017/08/29 20:23:56 step 4: objective=22.717547 reg=0.006666
2017/08/29 20:23:57 step 5: objective=22.743822 reg=0.006665
2017/08/29 20:23:57 step 6: objective=22.772537 reg=0.006663
2017/08/29 20:23:58 step 7: objective=22.795498 reg=0.006663
2017/08/29 20:23:58 Training value function...
2017/08/29 20:24:00 step 0: mse=13793.764809 step=0.050000
2017/08/29 20:24:01 step 1: mse=13736.033427 step=0.050000
2017/08/29 20:24:01 step 2: mse=13684.674201 step=0.050000
2017/08/29 20:24:02 step 3: mse=13634.547361 step=0.050000
2017/08/29 20:24:03 step 4: mse=13588.529987 step=0.050000
2017/08/29 20:24:03 step 5: mse=13545.370921 step=0.050000
2017/08/29 20:24:04 step 6: mse=13506.008954 step=0.050000
2017/08/29 20:24:05 step 7: mse=13468.757397 step=0.050000
2017/08/29 20:24:05 Saving...
2017/08/29 20:24:05 Gathering batch of experience...
2017/08/29 20:24:27 batch 53: mean=667.500000 stddev=363.057819 entropy=0.667790 frames=4498 count=74
2017/08/29 20:24:27 Training policy...
2017/08/29 20:24:29 tune 0: objective=17.925003 reg=0.006678 prune=0
2017/08/29 20:24:30 step 0: objective=17.938247 reg=0.006677
2017/08/29 20:24:31 step 1: objective=17.951447 reg=0.006676
2017/08/29 20:24:31 step 2: objective=17.974798 reg=0.006676
2017/08/29 20:24:32 step 3: objective=17.995844 reg=0.006675
2017/08/29 20:24:33 step 4: objective=18.020101 reg=0.006674
2017/08/29 20:24:33 step 5: objective=18.035361 reg=0.006674
2017/08/29 20:24:34 step 6: objective=18.051825 reg=0.006674
2017/08/29 20:24:35 step 7: objective=18.071829 reg=0.006673
2017/08/29 20:24:35 Training value function...
2017/08/29 20:24:36 step 0: mse=12984.284324 step=0.050000
2017/08/29 20:24:37 step 1: mse=12963.718599 step=0.050000
2017/08/29 20:24:38 step 2: mse=12939.213388 step=0.050000
2017/08/29 20:24:38 step 3: mse=12921.573021 step=0.050000
2017/08/29 20:24:39 step 4: mse=12912.874487 step=0.050000
2017/08/29 20:24:40 step 5: mse=12905.604880 step=0.050000
2017/08/29 20:24:40 step 6: mse=12895.891590 step=0.050000
2017/08/29 20:24:41 step 7: mse=12878.814550 step=0.050000
2017/08/29 20:24:41 Saving...
2017/08/29 20:24:41 Gathering batch of experience...
2017/08/29 20:25:04 batch 54: mean=752.816901 stddev=413.821704 entropy=0.662944 frames=4756 count=71
2017/08/29 20:25:04 Training policy...
2017/08/29 20:25:06 tune 0: objective=26.180271 reg=0.006629 prune=0
2017/08/29 20:25:07 step 0: objective=26.188334 reg=0.006629
2017/08/29 20:25:08 step 1: objective=26.207189 reg=0.006628
2017/08/29 20:25:08 step 2: objective=26.218123 reg=0.006628
2017/08/29 20:25:09 step 3: objective=26.231973 reg=0.006627
2017/08/29 20:25:10 step 4: objective=26.244913 reg=0.006626
2017/08/29 20:25:10 step 5: objective=26.260056 reg=0.006626
2017/08/29 20:25:11 step 6: objective=26.283970 reg=0.006626
2017/08/29 20:25:12 step 7: objective=26.297521 reg=0.006625
2017/08/29 20:25:12 Training value function...
2017/08/29 20:25:14 step 0: mse=16086.931635 step=0.050000
2017/08/29 20:25:14 step 1: mse=15966.597699 step=0.050000
2017/08/29 20:25:15 step 2: mse=15854.739184 step=0.050000
2017/08/29 20:25:16 step 3: mse=15754.384827 step=0.050000
2017/08/29 20:25:16 step 4: mse=15657.680201 step=0.050000
2017/08/29 20:25:17 step 5: mse=15571.144341 step=0.050000
2017/08/29 20:25:18 step 6: mse=15489.904833 step=0.050000
2017/08/29 20:25:19 step 7: mse=15415.572984 step=0.050000
2017/08/29 20:25:19 Saving...
2017/08/29 20:25:19 Gathering batch of experience...
2017/08/29 20:25:41 batch 55: mean=745.072464 stddev=411.411931 entropy=0.664898 frames=4549 count=69
2017/08/29 20:25:41 Training policy...
2017/08/29 20:25:43 tune 0: objective=23.810283 reg=0.006649 prune=0
2017/08/29 20:25:44 step 0: objective=23.819407 reg=0.006648
2017/08/29 20:25:45 step 1: objective=23.840897 reg=0.006647
2017/08/29 20:25:45 step 2: objective=23.863387 reg=0.006647
2017/08/29 20:25:46 step 3: objective=23.885689 reg=0.006646
2017/08/29 20:25:47 step 4: objective=23.911215 reg=0.006646
2017/08/29 20:25:47 step 5: objective=23.930560 reg=0.006645
2017/08/29 20:25:48 step 6: objective=23.957042 reg=0.006644
2017/08/29 20:25:49 step 7: objective=23.977047 reg=0.006643
2017/08/29 20:25:49 Training value function...
2017/08/29 20:25:50 step 0: mse=15613.414908 step=0.050000
2017/08/29 20:25:51 step 1: mse=15507.471820 step=0.050000
2017/08/29 20:25:52 step 2: mse=15409.753362 step=0.050000
2017/08/29 20:25:53 step 3: mse=15319.079129 step=0.050000
2017/08/29 20:25:53 step 4: mse=15236.326110 step=0.050000
2017/08/29 20:25:54 step 5: mse=15160.022750 step=0.050000
2017/08/29 20:25:55 step 6: mse=15091.142241 step=0.050000
2017/08/29 20:25:55 step 7: mse=15025.866325 step=0.050000
2017/08/29 20:25:55 Saving...
2017/08/29 20:25:55 Gathering batch of experience...
2017/08/29 20:26:18 batch 56: mean=710.205479 stddev=403.620972 entropy=0.663491 frames=4578 count=73
2017/08/29 20:26:18 Training policy...
2017/08/29 20:26:20 tune 0: objective=20.546810 reg=0.006635 prune=0
2017/08/29 20:26:20 step 0: objective=20.557447 reg=0.006633
2017/08/29 20:26:21 step 1: objective=20.574166 reg=0.006631
2017/08/29 20:26:22 step 2: objective=20.593871 reg=0.006630
2017/08/29 20:26:22 step 3: objective=20.608032 reg=0.006629
2017/08/29 20:26:23 step 4: objective=20.620083 reg=0.006629
2017/08/29 20:26:24 step 5: objective=20.630459 reg=0.006628
2017/08/29 20:26:25 step 6: objective=20.646446 reg=0.006628
2017/08/29 20:26:25 step 7: objective=20.659842 reg=0.006627
2017/08/29 20:26:25 Training value function...
2017/08/29 20:26:27 step 0: mse=13575.945110 step=0.050000
2017/08/29 20:26:28 step 1: mse=13501.039316 step=0.050000
2017/08/29 20:26:28 step 2: mse=13428.090530 step=0.050000
2017/08/29 20:26:29 step 3: mse=13368.780664 step=0.050000
2017/08/29 20:26:30 step 4: mse=13311.147140 step=0.050000
2017/08/29 20:26:30 step 5: mse=13253.775841 step=0.050000
2017/08/29 20:26:31 step 6: mse=13203.166576 step=0.050000
2017/08/29 20:26:32 step 7: mse=13158.054075 step=0.050000
2017/08/29 20:26:32 Saving...
2017/08/29 20:26:32 Gathering batch of experience...
2017/08/29 20:26:54 batch 57: mean=742.971014 stddev=413.588326 entropy=0.661925 frames=4618 count=69
2017/08/29 20:26:54 Training policy...
2017/08/29 20:26:56 tune 0: objective=19.399828 reg=0.006619 prune=0
2017/08/29 20:26:57 step 0: objective=19.422513 reg=0.006617
2017/08/29 20:26:58 step 1: objective=19.456453 reg=0.006616
2017/08/29 20:26:58 step 2: objective=19.484343 reg=0.006615
2017/08/29 20:26:59 step 3: objective=19.513380 reg=0.006614
2017/08/29 20:27:00 step 4: objective=19.543471 reg=0.006613
2017/08/29 20:27:00 step 5: objective=19.571827 reg=0.006612
2017/08/29 20:27:01 step 6: objective=19.598242 reg=0.006611
2017/08/29 20:27:02 step 7: objective=19.622271 reg=0.006610
2017/08/29 20:27:02 Training value function...
2017/08/29 20:27:03 step 0: mse=15020.540733 step=0.050000
2017/08/29 20:27:04 step 1: mse=14967.181045 step=0.050000
2017/08/29 20:27:05 step 2: mse=14905.526363 step=0.050000
2017/08/29 20:27:05 step 3: mse=14865.895340 step=0.050000
2017/08/29 20:27:06 step 4: mse=14829.874138 step=0.050000
2017/08/29 20:27:07 step 5: mse=14794.657077 step=0.050000
2017/08/29 20:27:08 step 6: mse=14750.997798 step=0.050000
2017/08/29 20:27:08 step 7: mse=14716.980932 step=0.050000
2017/08/29 20:27:08 Saving...
2017/08/29 20:27:08 Gathering batch of experience...
2017/08/29 20:27:31 batch 58: mean=737.635135 stddev=423.986250 entropy=0.661462 frames=4828 count=74
2017/08/29 20:27:31 Training policy...
2017/08/29 20:27:34 tune 0: objective=21.943100 reg=0.006615 prune=0
2017/08/29 20:27:35 step 0: objective=21.955850 reg=0.006612
2017/08/29 20:27:35 step 1: objective=21.981951 reg=0.006611
2017/08/29 20:27:36 step 2: objective=22.002500 reg=0.006610
2017/08/29 20:27:37 step 3: objective=22.027690 reg=0.006608
2017/08/29 20:27:37 step 4: objective=22.051729 reg=0.006607
2017/08/29 20:27:38 step 5: objective=22.076572 reg=0.006606
2017/08/29 20:27:39 step 6: objective=22.105977 reg=0.006604
2017/08/29 20:27:39 step 7: objective=22.131241 reg=0.006602
2017/08/29 20:27:39 Training value function...
2017/08/29 20:27:41 step 0: mse=14498.744432 step=0.050000
2017/08/29 20:27:42 step 1: mse=14414.623987 step=0.050000
2017/08/29 20:27:43 step 2: mse=14337.080492 step=0.050000
2017/08/29 20:27:44 step 3: mse=14265.057999 step=0.050000
2017/08/29 20:27:44 step 4: mse=14200.589546 step=0.050000
2017/08/29 20:27:45 step 5: mse=14139.262009 step=0.050000
2017/08/29 20:27:46 step 6: mse=14072.360094 step=0.050000
2017/08/29 20:27:46 step 7: mse=14017.934041 step=0.050000
2017/08/29 20:27:46 Saving...
2017/08/29 20:27:47 Gathering batch of experience...
2017/08/29 20:28:09 batch 59: mean=635.454545 stddev=341.129885 entropy=0.663525 frames=4572 count=77
2017/08/29 20:28:09 Training policy...
2017/08/29 20:28:12 tune 0: objective=6.710298 reg=0.006635 prune=0
2017/08/29 20:28:12 step 0: objective=6.720171 reg=0.006635
2017/08/29 20:28:13 step 1: objective=6.738608 reg=0.006635
2017/08/29 20:28:14 step 2: objective=6.760356 reg=0.006634
2017/08/29 20:28:14 step 3: objective=6.775120 reg=0.006635
2017/08/29 20:28:15 step 4: objective=6.799232 reg=0.006635
2017/08/29 20:28:16 step 5: objective=6.825966 reg=0.006635
2017/08/29 20:28:16 step 6: objective=6.842263 reg=0.006635
2017/08/29 20:28:17 step 7: objective=6.865060 reg=0.006635
2017/08/29 20:28:17 Training value function...
2017/08/29 20:28:19 step 0: mse=11511.144849 step=0.050000
2017/08/29 20:28:19 step 1: mse=11497.205593 step=0.050000
2017/08/29 20:28:20 step 2: mse=11490.409711 step=0.050000
2017/08/29 20:28:21 step 3: mse=11490.043914 step=0.050000
2017/08/29 20:28:21 step 4: mse=11497.416919 step=0.050000
2017/08/29 20:28:22 step 5: mse=11509.672725 step=0.050000
2017/08/29 20:28:23 step 6: mse=11517.978107 step=0.050000
2017/08/29 20:28:24 step 7: mse=11531.747517 step=0.050000
2017/08/29 20:28:24 Saving...
2017/08/29 20:28:24 Gathering batch of experience...
2017/08/29 20:28:46 batch 60: mean=648.205128 stddev=370.617100 entropy=0.663031 frames=4596 count=78
2017/08/29 20:28:46 Training policy...
2017/08/29 20:28:49 tune 0: objective=15.007090 reg=0.006630 prune=0
2017/08/29 20:28:49 step 0: objective=15.013663 reg=0.006629
2017/08/29 20:28:50 step 1: objective=15.022193 reg=0.006629
2017/08/29 20:28:51 step 2: objective=15.028428 reg=0.006629
2017/08/29 20:28:51 step 3: objective=15.039979 reg=0.006628
2017/08/29 20:28:52 step 4: objective=15.051971 reg=0.006628
2017/08/29 20:28:53 step 5: objective=15.064062 reg=0.006627
2017/08/29 20:28:53 step 6: objective=15.079864 reg=0.006627
2017/08/29 20:28:54 step 7: objective=15.089183 reg=0.006626
2017/08/29 20:28:54 Training value function...
2017/08/29 20:28:56 step 0: mse=12922.847214 step=0.050000
2017/08/29 20:28:57 step 1: mse=12927.788321 step=0.050000
2017/08/29 20:28:57 step 2: mse=12936.437696 step=0.050000
2017/08/29 20:28:58 step 3: mse=12944.699991 step=0.050000
2017/08/29 20:28:59 step 4: mse=12951.127419 step=0.050000
2017/08/29 20:28:59 step 5: mse=12959.159057 step=0.050000
2017/08/29 20:29:00 step 6: mse=12966.615496 step=0.050000
2017/08/29 20:29:01 step 7: mse=12973.258839 step=0.050000
2017/08/29 20:29:01 Saving...
2017/08/29 20:29:01 Gathering batch of experience...
2017/08/29 20:29:24 batch 61: mean=636.772152 stddev=355.274041 entropy=0.661528 frames=4596 count=79
2017/08/29 20:29:24 Training policy...
2017/08/29 20:29:26 tune 0: objective=14.547188 reg=0.006615 prune=0
2017/08/29 20:29:27 step 0: objective=14.556692 reg=0.006613
2017/08/29 20:29:27 step 1: objective=14.573078 reg=0.006612
2017/08/29 20:29:28 step 2: objective=14.593809 reg=0.006611
2017/08/29 20:29:29 step 3: objective=14.609411 reg=0.006610
2017/08/29 20:29:29 step 4: objective=14.624094 reg=0.006609
2017/08/29 20:29:30 step 5: objective=14.638317 reg=0.006608
2017/08/29 20:29:31 step 6: objective=14.653444 reg=0.006607
2017/08/29 20:29:31 step 7: objective=14.669383 reg=0.006606
2017/08/29 20:29:31 Training value function...
2017/08/29 20:29:33 step 0: mse=12409.457128 step=0.050000
2017/08/29 20:29:34 step 1: mse=12421.819039 step=0.050000
2017/08/29 20:29:34 step 2: mse=12437.528003 step=0.050000
2017/08/29 20:29:35 step 3: mse=12451.771502 step=0.050000
2017/08/29 20:29:36 step 4: mse=12465.835143 step=0.050000
2017/08/29 20:29:37 step 5: mse=12480.812198 step=0.050000
2017/08/29 20:29:37 step 6: mse=12488.243569 step=0.050000
2017/08/29 20:29:38 step 7: mse=12502.469325 step=0.050000
2017/08/29 20:29:38 Saving...
2017/08/29 20:29:38 Gathering batch of experience...
2017/08/29 20:30:01 batch 62: mean=720.070423 stddev=418.082050 entropy=0.659601 frames=4666 count=71
2017/08/29 20:30:01 Training policy...
2017/08/29 20:30:03 tune 0: objective=22.975437 reg=0.006596 prune=0
2017/08/29 20:30:04 step 0: objective=22.989197 reg=0.006594
2017/08/29 20:30:05 step 1: objective=23.013736 reg=0.006593
2017/08/29 20:30:05 step 2: objective=23.034148 reg=0.006591
2017/08/29 20:30:06 step 3: objective=23.060404 reg=0.006590
2017/08/29 20:30:07 step 4: objective=23.086776 reg=0.006589
2017/08/29 20:30:07 step 5: objective=23.110492 reg=0.006587
2017/08/29 20:30:08 step 6: objective=23.126281 reg=0.006586
2017/08/29 20:30:09 step 7: objective=23.151890 reg=0.006585
2017/08/29 20:30:09 Training value function...
2017/08/29 20:30:11 step 0: mse=15544.546928 step=0.050000
2017/08/29 20:30:11 step 1: mse=15439.288639 step=0.050000
2017/08/29 20:30:12 step 2: mse=15344.252887 step=0.050000
2017/08/29 20:30:13 step 3: mse=15257.288989 step=0.050000
2017/08/29 20:30:13 step 4: mse=15180.604982 step=0.050000
2017/08/29 20:30:14 step 5: mse=15114.046193 step=0.050000
2017/08/29 20:30:15 step 6: mse=15047.061887 step=0.050000
2017/08/29 20:30:16 step 7: mse=14981.551241 step=0.050000
2017/08/29 20:30:16 Saving...
2017/08/29 20:30:16 Gathering batch of experience...
2017/08/29 20:30:38 batch 63: mean=700.479452 stddev=382.458848 entropy=0.658227 frames=4537 count=73
2017/08/29 20:30:38 Training policy...
2017/08/29 20:30:40 tune 0: objective=22.431050 reg=0.006582 prune=0
2017/08/29 20:30:41 step 0: objective=22.437545 reg=0.006581
2017/08/29 20:30:41 step 1: objective=22.449993 reg=0.006581
2017/08/29 20:30:42 step 2: objective=22.468461 reg=0.006581
2017/08/29 20:30:43 step 3: objective=22.486236 reg=0.006581
2017/08/29 20:30:43 step 4: objective=22.498619 reg=0.006581
2017/08/29 20:30:44 step 5: objective=22.511850 reg=0.006581
2017/08/29 20:30:45 step 6: objective=22.524512 reg=0.006581
2017/08/29 20:30:45 step 7: objective=22.541284 reg=0.006580
2017/08/29 20:30:45 Training value function...
2017/08/29 20:30:47 step 0: mse=14271.902090 step=0.050000
2017/08/29 20:30:48 step 1: mse=14164.888446 step=0.050000
2017/08/29 20:30:48 step 2: mse=14067.104095 step=0.050000
2017/08/29 20:30:49 step 3: mse=13976.425805 step=0.050000
2017/08/29 20:30:50 step 4: mse=13892.473390 step=0.050000
2017/08/29 20:30:50 step 5: mse=13815.917988 step=0.050000
2017/08/29 20:30:51 step 6: mse=13744.645801 step=0.050000
2017/08/29 20:30:52 step 7: mse=13678.251903 step=0.050000
2017/08/29 20:30:52 Saving...
2017/08/29 20:30:52 Gathering batch of experience...
2017/08/29 20:31:14 batch 64: mean=733.695652 stddev=378.014121 entropy=0.658101 frames=4598 count=69
2017/08/29 20:31:14 Training policy...
2017/08/29 20:31:16 tune 0: objective=22.012947 reg=0.006581 prune=0
2017/08/29 20:31:17 step 0: objective=22.023262 reg=0.006580
2017/08/29 20:31:18 step 1: objective=22.051959 reg=0.006579
2017/08/29 20:31:18 step 2: objective=22.080196 reg=0.006578
2017/08/29 20:31:19 step 3: objective=22.105498 reg=0.006577
2017/08/29 20:31:20 step 4: objective=22.123450 reg=0.006577
2017/08/29 20:31:20 step 5: objective=22.143857 reg=0.006577
2017/08/29 20:31:21 step 6: objective=22.166805 reg=0.006577
2017/08/29 20:31:22 step 7: objective=22.186139 reg=0.006577
2017/08/29 20:31:22 Training value function...
2017/08/29 20:31:23 step 0: mse=13965.371257 step=0.050000
2017/08/29 20:31:24 step 1: mse=13912.084503 step=0.050000
2017/08/29 20:31:25 step 2: mse=13863.271355 step=0.050000
2017/08/29 20:31:26 step 3: mse=13819.089107 step=0.050000
2017/08/29 20:31:26 step 4: mse=13769.656134 step=0.050000
2017/08/29 20:31:27 step 5: mse=13730.725652 step=0.050000
2017/08/29 20:31:28 step 6: mse=13691.393935 step=0.050000
2017/08/29 20:31:28 step 7: mse=13659.966796 step=0.050000
2017/08/29 20:31:28 Saving...
2017/08/29 20:31:28 Gathering batch of experience...
2017/08/29 20:31:51 batch 65: mean=573.597561 stddev=289.057841 entropy=0.662123 frames=4514 count=82
2017/08/29 20:31:51 Training policy...
2017/08/29 20:31:54 tune 0: objective=1.883177 reg=0.006621 prune=0
2017/08/29 20:31:54 step 0: objective=1.894991 reg=0.006620
2017/08/29 20:31:55 step 1: objective=1.909387 reg=0.006620
2017/08/29 20:31:56 step 2: objective=1.932821 reg=0.006619
2017/08/29 20:31:56 step 3: objective=1.947027 reg=0.006618
2017/08/29 20:31:57 step 4: objective=1.962703 reg=0.006617
2017/08/29 20:31:58 step 5: objective=1.989252 reg=0.006617
2017/08/29 20:31:58 step 6: objective=2.002439 reg=0.006617
2017/08/29 20:31:59 step 7: objective=2.016185 reg=0.006616
2017/08/29 20:31:59 Training value function...
2017/08/29 20:32:01 step 0: mse=10196.476851 step=0.050000
2017/08/29 20:32:01 step 1: mse=10138.187588 step=0.050000
2017/08/29 20:32:02 step 2: mse=10093.454822 step=0.050000
2017/08/29 20:32:03 step 3: mse=10059.682732 step=0.050000
2017/08/29 20:32:03 step 4: mse=10036.186110 step=0.050000
2017/08/29 20:32:04 step 5: mse=10018.673568 step=0.050000
2017/08/29 20:32:05 step 6: mse=10004.736751 step=0.050000
2017/08/29 20:32:06 step 7: mse=10003.048432 step=0.050000
2017/08/29 20:32:06 Saving...
2017/08/29 20:32:06 Gathering batch of experience...
2017/08/29 20:32:28 batch 66: mean=693.851351 stddev=373.461300 entropy=0.658369 frames=4668 count=74
2017/08/29 20:32:28 Training policy...
2017/08/29 20:32:31 tune 0: objective=23.665818 reg=0.006584 prune=0
2017/08/29 20:32:31 step 0: objective=23.682789 reg=0.006582
2017/08/29 20:32:32 step 1: objective=23.708291 reg=0.006581
2017/08/29 20:32:33 step 2: objective=23.724566 reg=0.006581
2017/08/29 20:32:33 step 3: objective=23.744003 reg=0.006581
2017/08/29 20:32:34 step 4: objective=23.763503 reg=0.006580
2017/08/29 20:32:35 step 5: objective=23.783257 reg=0.006579
2017/08/29 20:32:35 step 6: objective=23.798689 reg=0.006578
2017/08/29 20:32:36 step 7: objective=23.817151 reg=0.006579
2017/08/29 20:32:36 Training value function...
2017/08/29 20:32:38 step 0: mse=14502.246700 step=0.050000
2017/08/29 20:32:39 step 1: mse=14421.277725 step=0.050000
2017/08/29 20:32:39 step 2: mse=14347.408680 step=0.050000
2017/08/29 20:32:40 step 3: mse=14280.438764 step=0.050000
2017/08/29 20:32:41 step 4: mse=14214.238440 step=0.050000
2017/08/29 20:32:42 step 5: mse=14155.244079 step=0.050000
2017/08/29 20:32:42 step 6: mse=14097.997068 step=0.050000
2017/08/29 20:32:43 step 7: mse=14044.079254 step=0.050000
2017/08/29 20:32:43 Saving...
2017/08/29 20:32:43 Gathering batch of experience...
2017/08/29 20:33:09 batch 67: mean=941.486486 stddev=2224.083584 entropy=0.657507 frames=5036 count=74
2017/08/29 20:33:09 Training policy...
2017/08/29 20:33:12 tune 0: objective=61.868056 reg=0.006575 prune=0
2017/08/29 20:33:12 step 0: objective=61.932772 reg=0.006574
2017/08/29 20:33:13 step 1: objective=62.213686 reg=0.006572
2017/08/29 20:33:14 step 2: objective=62.468613 reg=0.006571
2017/08/29 20:33:15 step 3: objective=62.744694 reg=0.006568
2017/08/29 20:33:15 step 4: objective=62.964493 reg=0.006564
2017/08/29 20:33:16 step 5: objective=63.080030 reg=0.006563
2017/08/29 20:33:17 step 6: objective=63.237267 reg=0.006561
2017/08/29 20:33:18 step 7: objective=63.301486 reg=0.006560
2017/08/29 20:33:18 Training value function...
2017/08/29 20:33:20 step 0: mse=289437.714967 step=0.050000
2017/08/29 20:33:20 step 1: mse=281208.740749 step=0.050000
2017/08/29 20:33:21 step 2: mse=270239.576386 step=0.050000
2017/08/29 20:33:22 step 3: mse=264717.397767 step=0.050000
2017/08/29 20:33:23 step 4: mse=255078.114900 step=0.050000
2017/08/29 20:33:23 step 5: mse=250578.034653 step=0.050000
2017/08/29 20:33:24 step 6: mse=243609.907612 step=0.050000
2017/08/29 20:33:25 step 7: mse=239561.069582 step=0.050000
2017/08/29 20:33:25 Saving...
2017/08/29 20:33:25 Gathering batch of experience...
2017/08/29 20:33:48 batch 68: mean=801.594203 stddev=422.667935 entropy=0.652776 frames=4828 count=69
2017/08/29 20:33:48 Training policy...
2017/08/29 20:33:51 tune 0: objective=24.275601 reg=0.006528 prune=0
2017/08/29 20:33:51 step 0: objective=24.284252 reg=0.006527
2017/08/29 20:33:52 step 1: objective=24.296470 reg=0.006527
2017/08/29 20:33:53 step 2: objective=24.310497 reg=0.006527
2017/08/29 20:33:53 step 3: objective=24.327829 reg=0.006527
2017/08/29 20:33:54 step 4: objective=24.344362 reg=0.006526
2017/08/29 20:33:55 step 5: objective=24.363155 reg=0.006525
2017/08/29 20:33:56 step 6: objective=24.379884 reg=0.006525
2017/08/29 20:33:56 step 7: objective=24.396213 reg=0.006525
2017/08/29 20:33:56 Training value function...
2017/08/29 20:33:58 step 0: mse=16659.664429 step=0.050000
2017/08/29 20:33:59 step 1: mse=16483.473713 step=0.050000
2017/08/29 20:34:00 step 2: mse=16310.718678 step=0.050000
2017/08/29 20:34:00 step 3: mse=16151.619642 step=0.050000
2017/08/29 20:34:01 step 4: mse=16013.006281 step=0.050000
2017/08/29 20:34:02 step 5: mse=15877.142173 step=0.050000
2017/08/29 20:34:03 step 6: mse=15759.538175 step=0.050000
2017/08/29 20:34:03 step 7: mse=15638.514581 step=0.050000
2017/08/29 20:34:03 Saving...
2017/08/29 20:34:03 Gathering batch of experience...
2017/08/29 20:34:26 batch 69: mean=756.304348 stddev=381.722500 entropy=0.652092 frames=4633 count=69
2017/08/29 20:34:26 Training policy...
2017/08/29 20:34:28 tune 0: objective=17.585309 reg=0.006521 prune=0
2017/08/29 20:34:29 step 0: objective=17.596010 reg=0.006519
2017/08/29 20:34:30 step 1: objective=17.614908 reg=0.006518
2017/08/29 20:34:30 step 2: objective=17.634040 reg=0.006518
2017/08/29 20:34:31 step 3: objective=17.648584 reg=0.006516
2017/08/29 20:34:32 step 4: objective=17.668963 reg=0.006516
2017/08/29 20:34:33 step 5: objective=17.691051 reg=0.006515
2017/08/29 20:34:33 step 6: objective=17.710352 reg=0.006515
2017/08/29 20:34:34 step 7: objective=17.728466 reg=0.006515
2017/08/29 20:34:34 Training value function...
2017/08/29 20:34:36 step 0: mse=14789.471953 step=0.050000
2017/08/29 20:34:36 step 1: mse=14772.587924 step=0.050000
2017/08/29 20:34:37 step 2: mse=14760.139403 step=0.050000
2017/08/29 20:34:38 step 3: mse=14750.451905 step=0.050000
2017/08/29 20:34:39 step 4: mse=14741.353859 step=0.050000
2017/08/29 20:34:39 step 5: mse=14730.725995 step=0.050000
2017/08/29 20:34:40 step 6: mse=14720.463976 step=0.050000
2017/08/29 20:34:41 step 7: mse=14714.855649 step=0.050000
2017/08/29 20:34:41 Saving...
2017/08/29 20:34:41 Gathering batch of experience...
2017/08/29 20:35:03 batch 70: mean=670.789474 stddev=391.564887 entropy=0.654810 frames=4634 count=76
2017/08/29 20:35:03 Training policy...
2017/08/29 20:35:06 tune 0: objective=10.931597 reg=0.006548 prune=0
2017/08/29 20:35:06 step 0: objective=10.944242 reg=0.006547
2017/08/29 20:35:07 step 1: objective=10.967050 reg=0.006546
2017/08/29 20:35:08 step 2: objective=10.979304 reg=0.006547
2017/08/29 20:35:08 step 3: objective=11.008284 reg=0.006547
2017/08/29 20:35:09 step 4: objective=11.038536 reg=0.006547
2017/08/29 20:35:10 step 5: objective=11.057494 reg=0.006546
2017/08/29 20:35:10 step 6: objective=11.081930 reg=0.006545
2017/08/29 20:35:11 step 7: objective=11.103024 reg=0.006544
2017/08/29 20:35:11 Training value function...
2017/08/29 20:35:13 step 0: mse=13873.555476 step=0.050000
2017/08/29 20:35:14 step 1: mse=13889.627640 step=0.050000
2017/08/29 20:35:14 step 2: mse=13907.858701 step=0.050000
2017/08/29 20:35:15 step 3: mse=13924.291914 step=0.050000
2017/08/29 20:35:16 step 4: mse=13938.051095 step=0.050000
2017/08/29 20:35:16 step 5: mse=13954.939477 step=0.050000
2017/08/29 20:35:17 step 6: mse=13969.201469 step=0.050000
2017/08/29 20:35:18 step 7: mse=13986.440045 step=0.050000
2017/08/29 20:35:18 Saving...
2017/08/29 20:35:18 Gathering batch of experience...
2017/08/29 20:35:41 batch 71: mean=703.287671 stddev=425.102904 entropy=0.654385 frames=4596 count=73
2017/08/29 20:35:41 Training policy...
2017/08/29 20:35:43 tune 0: objective=18.619215 reg=0.006544 prune=0
2017/08/29 20:35:44 step 0: objective=18.635571 reg=0.006541
2017/08/29 20:35:44 step 1: objective=18.664929 reg=0.006539
2017/08/29 20:35:45 step 2: objective=18.690162 reg=0.006537
2017/08/29 20:35:46 step 3: objective=18.709119 reg=0.006536
2017/08/29 20:35:46 step 4: objective=18.726576 reg=0.006535
2017/08/29 20:35:47 step 5: objective=18.745533 reg=0.006534
2017/08/29 20:35:48 step 6: objective=18.769978 reg=0.006532
2017/08/29 20:35:48 step 7: objective=18.797004 reg=0.006530
2017/08/29 20:35:48 Training value function...
2017/08/29 20:35:50 step 0: mse=15532.382848 step=0.050000
2017/08/29 20:35:51 step 1: mse=15492.125840 step=0.050000
2017/08/29 20:35:52 step 2: mse=15449.231192 step=0.050000
2017/08/29 20:35:52 step 3: mse=15408.588884 step=0.050000
2017/08/29 20:35:53 step 4: mse=15369.955056 step=0.050000
2017/08/29 20:35:54 step 5: mse=15331.771425 step=0.050000
2017/08/29 20:35:55 step 6: mse=15298.641512 step=0.050000
2017/08/29 20:35:55 step 7: mse=15262.460860 step=0.050000
2017/08/29 20:35:55 Saving...
2017/08/29 20:35:55 Gathering batch of experience...
2017/08/29 20:36:18 batch 72: mean=763.913043 stddev=436.849616 entropy=0.650720 frames=4600 count=69
2017/08/29 20:36:18 Training policy...
2017/08/29 20:36:20 tune 0: objective=25.466963 reg=0.006507 prune=0
2017/08/29 20:36:21 step 0: objective=25.481133 reg=0.006505
2017/08/29 20:36:21 step 1: objective=25.498505 reg=0.006504
2017/08/29 20:36:22 step 2: objective=25.522385 reg=0.006502
2017/08/29 20:36:23 step 3: objective=25.542210 reg=0.006501
2017/08/29 20:36:23 step 4: objective=25.564383 reg=0.006501
2017/08/29 20:36:24 step 5: objective=25.589474 reg=0.006499
2017/08/29 20:36:25 step 6: objective=25.609034 reg=0.006498
2017/08/29 20:36:25 step 7: objective=25.626245 reg=0.006496
2017/08/29 20:36:25 Training value function...
2017/08/29 20:36:27 step 0: mse=16102.536794 step=0.050000
2017/08/29 20:36:28 step 1: mse=15931.121156 step=0.050000
2017/08/29 20:36:29 step 2: mse=15773.271282 step=0.050000
2017/08/29 20:36:29 step 3: mse=15627.684302 step=0.050000
2017/08/29 20:36:30 step 4: mse=15492.049128 step=0.050000
2017/08/29 20:36:31 step 5: mse=15369.749132 step=0.050000
2017/08/29 20:36:31 step 6: mse=15249.824463 step=0.050000
2017/08/29 20:36:32 step 7: mse=15143.405141 step=0.050000
2017/08/29 20:36:32 Saving...
2017/08/29 20:36:32 Gathering batch of experience...
2017/08/29 20:36:55 batch 73: mean=765.357143 stddev=434.718564 entropy=0.650725 frames=4716 count=70
2017/08/29 20:36:55 Training policy...
2017/08/29 20:36:57 tune 0: objective=22.254012 reg=0.006507 prune=0
2017/08/29 20:36:58 step 0: objective=22.270215 reg=0.006505
2017/08/29 20:36:59 step 1: objective=22.289336 reg=0.006504
2017/08/29 20:36:59 step 2: objective=22.307116 reg=0.006503
2017/08/29 20:37:00 step 3: objective=22.326854 reg=0.006501
2017/08/29 20:37:01 step 4: objective=22.340516 reg=0.006500
2017/08/29 20:37:01 step 5: objective=22.355944 reg=0.006500
2017/08/29 20:37:02 step 6: objective=22.370507 reg=0.006499
2017/08/29 20:37:03 step 7: objective=22.387287 reg=0.006498
2017/08/29 20:37:03 Training value function...
2017/08/29 20:37:05 step 0: mse=15375.094685 step=0.050000
2017/08/29 20:37:05 step 1: mse=15325.252719 step=0.050000
2017/08/29 20:37:06 step 2: mse=15278.756214 step=0.050000
2017/08/29 20:37:07 step 3: mse=15232.890846 step=0.050000
2017/08/29 20:37:08 step 4: mse=15187.752425 step=0.050000
2017/08/29 20:37:08 step 5: mse=15146.010651 step=0.050000
2017/08/29 20:37:09 step 6: mse=15102.412851 step=0.050000
2017/08/29 20:37:10 step 7: mse=15066.383215 step=0.050000
2017/08/29 20:37:10 Saving...
2017/08/29 20:37:10 Gathering batch of experience...
2017/08/29 20:37:32 batch 74: mean=756.811594 stddev=391.032608 entropy=0.647760 frames=4571 count=69
2017/08/29 20:37:32 Training policy...
2017/08/29 20:37:34 tune 0: objective=20.054248 reg=0.006478 prune=0
2017/08/29 20:37:35 step 0: objective=20.063563 reg=0.006476
2017/08/29 20:37:35 step 1: objective=20.081605 reg=0.006476
2017/08/29 20:37:36 step 2: objective=20.100578 reg=0.006475
2017/08/29 20:37:37 step 3: objective=20.117230 reg=0.006475
2017/08/29 20:37:37 step 4: objective=20.132286 reg=0.006474
2017/08/29 20:37:38 step 5: objective=20.147393 reg=0.006474
2017/08/29 20:37:39 step 6: objective=20.161600 reg=0.006473
2017/08/29 20:37:39 step 7: objective=20.173533 reg=0.006473
2017/08/29 20:37:39 Training value function...
2017/08/29 20:37:41 step 0: mse=14026.206950 step=0.050000
2017/08/29 20:37:42 step 1: mse=14012.375056 step=0.050000
2017/08/29 20:37:43 step 2: mse=14000.627772 step=0.050000
2017/08/29 20:37:43 step 3: mse=13987.630132 step=0.050000
2017/08/29 20:37:44 step 4: mse=13977.018364 step=0.050000
2017/08/29 20:37:45 step 5: mse=13967.348716 step=0.050000
2017/08/29 20:37:45 step 6: mse=13958.314561 step=0.050000
2017/08/29 20:37:46 step 7: mse=13948.279092 step=0.050000
2017/08/29 20:37:46 Saving...
2017/08/29 20:37:46 Gathering batch of experience...
2017/08/29 20:38:09 batch 75: mean=719.931507 stddev=397.305560 entropy=0.650177 frames=4712 count=73
2017/08/29 20:38:09 Training policy...
2017/08/29 20:38:12 tune 0: objective=15.349480 reg=0.006502 prune=0
2017/08/29 20:38:13 step 0: objective=15.356803 reg=0.006502
2017/08/29 20:38:13 step 1: objective=15.379888 reg=0.006502
2017/08/29 20:38:14 step 2: objective=15.403491 reg=0.006502
2017/08/29 20:38:15 step 3: objective=15.426814 reg=0.006501
2017/08/29 20:38:15 step 4: objective=15.446851 reg=0.006501
2017/08/29 20:38:16 step 5: objective=15.469738 reg=0.006500
2017/08/29 20:38:17 step 6: objective=15.494446 reg=0.006500
2017/08/29 20:38:17 step 7: objective=15.516414 reg=0.006500
2017/08/29 20:38:17 Training value function...
2017/08/29 20:38:19 step 0: mse=14385.747110 step=0.050000
2017/08/29 20:38:20 step 1: mse=14392.304118 step=0.050000
2017/08/29 20:38:21 step 2: mse=14401.398362 step=0.050000
2017/08/29 20:38:21 step 3: mse=14406.616817 step=0.050000
2017/08/29 20:38:22 step 4: mse=14412.614196 step=0.050000
2017/08/29 20:38:23 step 5: mse=14412.496354 step=0.050000
2017/08/29 20:38:24 step 6: mse=14418.730511 step=0.050000
2017/08/29 20:38:24 step 7: mse=14422.525361 step=0.050000
2017/08/29 20:38:24 Saving...
2017/08/29 20:38:24 Gathering batch of experience...
2017/08/29 20:38:47 batch 76: mean=706.319444 stddev=395.624500 entropy=0.648504 frames=4534 count=72
2017/08/29 20:38:47 Training policy...
2017/08/29 20:38:49 tune 0: objective=17.303505 reg=0.006485 prune=0
2017/08/29 20:38:50 step 0: objective=17.316672 reg=0.006483
2017/08/29 20:38:50 step 1: objective=17.342260 reg=0.006483
2017/08/29 20:38:51 step 2: objective=17.360399 reg=0.006482
2017/08/29 20:38:52 step 3: objective=17.381008 reg=0.006481
2017/08/29 20:38:52 step 4: objective=17.403162 reg=0.006480
2017/08/29 20:38:53 step 5: objective=17.427239 reg=0.006479
2017/08/29 20:38:54 step 6: objective=17.449107 reg=0.006479
2017/08/29 20:38:54 step 7: objective=17.472799 reg=0.006478
2017/08/29 20:38:54 Training value function...
2017/08/29 20:38:56 step 0: mse=13373.223644 step=0.050000
2017/08/29 20:38:57 step 1: mse=13368.201713 step=0.050000
2017/08/29 20:38:58 step 2: mse=13367.238063 step=0.050000
2017/08/29 20:38:58 step 3: mse=13364.460896 step=0.050000
2017/08/29 20:38:59 step 4: mse=13362.039843 step=0.050000
2017/08/29 20:39:00 step 5: mse=13363.306083 step=0.050000
2017/08/29 20:39:00 step 6: mse=13362.636930 step=0.050000
2017/08/29 20:39:01 step 7: mse=13361.448987 step=0.050000
2017/08/29 20:39:01 Saving...
2017/08/29 20:39:01 Gathering batch of experience...
2017/08/29 20:39:24 batch 77: mean=692.533333 stddev=396.617678 entropy=0.649690 frames=4692 count=75
2017/08/29 20:39:24 Training policy...
2017/08/29 20:39:27 tune 0: objective=15.537372 reg=0.006497 prune=0
2017/08/29 20:39:27 step 0: objective=15.547106 reg=0.006496
2017/08/29 20:39:28 step 1: objective=15.570845 reg=0.006495
2017/08/29 20:39:29 step 2: objective=15.590550 reg=0.006494
2017/08/29 20:39:30 step 3: objective=15.606876 reg=0.006494
2017/08/29 20:39:30 step 4: objective=15.620278 reg=0.006494
2017/08/29 20:39:31 step 5: objective=15.638938 reg=0.006494
2017/08/29 20:39:32 step 6: objective=15.660940 reg=0.006493
2017/08/29 20:39:32 step 7: objective=15.684616 reg=0.006492
2017/08/29 20:39:32 Training value function...
2017/08/29 20:39:34 step 0: mse=13310.237152 step=0.050000
2017/08/29 20:39:35 step 1: mse=13312.827214 step=0.050000
2017/08/29 20:39:36 step 2: mse=13318.618003 step=0.050000
2017/08/29 20:39:36 step 3: mse=13327.978603 step=0.050000
2017/08/29 20:39:37 step 4: mse=13337.634429 step=0.050000
2017/08/29 20:39:38 step 5: mse=13341.140342 step=0.050000
2017/08/29 20:39:38 step 6: mse=13343.357276 step=0.050000
2017/08/29 20:39:39 step 7: mse=13349.969214 step=0.050000
2017/08/29 20:39:39 Saving...
2017/08/29 20:39:39 Gathering batch of experience...
2017/08/29 20:40:02 batch 78: mean=743.768116 stddev=412.765861 entropy=0.645798 frames=4586 count=69
2017/08/29 20:40:02 Training policy...
2017/08/29 20:40:04 tune 0: objective=20.765652 reg=0.006458 prune=0
2017/08/29 20:40:05 step 0: objective=20.778967 reg=0.006456
2017/08/29 20:40:05 step 1: objective=20.796505 reg=0.006455
2017/08/29 20:40:06 step 2: objective=20.818498 reg=0.006454
2017/08/29 20:40:07 step 3: objective=20.834742 reg=0.006454
2017/08/29 20:40:07 step 4: objective=20.859428 reg=0.006453
2017/08/29 20:40:08 step 5: objective=20.882988 reg=0.006452
2017/08/29 20:40:09 step 6: objective=20.908327 reg=0.006451
2017/08/29 20:40:09 step 7: objective=20.929543 reg=0.006450
2017/08/29 20:40:09 Training value function...
2017/08/29 20:40:11 step 0: mse=15923.760691 step=0.050000
2017/08/29 20:40:12 step 1: mse=15874.957026 step=0.050000
2017/08/29 20:40:13 step 2: mse=15827.215075 step=0.050000
2017/08/29 20:40:13 step 3: mse=15784.833189 step=0.050000
2017/08/29 20:40:14 step 4: mse=15748.875376 step=0.050000
2017/08/29 20:40:15 step 5: mse=15707.219991 step=0.050000
2017/08/29 20:40:15 step 6: mse=15671.081268 step=0.050000
2017/08/29 20:40:16 step 7: mse=15643.430794 step=0.050000
2017/08/29 20:40:16 Saving...
2017/08/29 20:40:16 Gathering batch of experience...
2017/08/29 20:40:40 batch 79: mean=748.013699 stddev=441.529673 entropy=0.647703 frames=4855 count=73
2017/08/29 20:40:40 Training policy...
2017/08/29 20:40:42 tune 0: objective=21.916623 reg=0.006477 prune=0
2017/08/29 20:40:43 step 0: objective=21.926773 reg=0.006475
2017/08/29 20:40:43 step 1: objective=21.955680 reg=0.006474
2017/08/29 20:40:44 step 2: objective=21.984446 reg=0.006473
2017/08/29 20:40:45 step 3: objective=22.011039 reg=0.006471
2017/08/29 20:40:46 step 4: objective=22.038076 reg=0.006471
2017/08/29 20:40:46 step 5: objective=22.071616 reg=0.006469
2017/08/29 20:40:47 step 6: objective=22.092260 reg=0.006468
2017/08/29 20:40:48 step 7: objective=22.111193 reg=0.006467
2017/08/29 20:40:48 Training value function...
2017/08/29 20:40:50 step 0: mse=16315.423183 step=0.050000
2017/08/29 20:40:50 step 1: mse=16255.008666 step=0.050000
2017/08/29 20:40:51 step 2: mse=16199.601364 step=0.050000
2017/08/29 20:40:52 step 3: mse=16148.203163 step=0.050000
2017/08/29 20:40:53 step 4: mse=16102.778123 step=0.050000
2017/08/29 20:40:53 step 5: mse=16057.983472 step=0.050000
2017/08/29 20:40:54 step 6: mse=16017.422919 step=0.050000
2017/08/29 20:40:55 step 7: mse=15975.544714 step=0.050000
2017/08/29 20:40:55 Saving...
2017/08/29 20:40:55 Gathering batch of experience...
2017/08/29 20:41:18 batch 80: mean=720.202703 stddev=389.485488 entropy=0.644889 frames=4745 count=74
2017/08/29 20:41:18 Training policy...
2017/08/29 20:41:20 tune 0: objective=18.409778 reg=0.006449 prune=0
2017/08/29 20:41:21 step 0: objective=18.420810 reg=0.006448
2017/08/29 20:41:22 step 1: objective=18.433379 reg=0.006448
2017/08/29 20:41:23 step 2: objective=18.455962 reg=0.006447
2017/08/29 20:41:23 step 3: objective=18.475680 reg=0.006447
2017/08/29 20:41:24 step 4: objective=18.493281 reg=0.006447
2017/08/29 20:41:25 step 5: objective=18.512105 reg=0.006446
2017/08/29 20:41:25 step 6: objective=18.528081 reg=0.006447
2017/08/29 20:41:26 step 7: objective=18.548843 reg=0.006446
2017/08/29 20:41:26 Training value function...
2017/08/29 20:41:28 step 0: mse=14317.904907 step=0.050000
2017/08/29 20:41:29 step 1: mse=14299.270861 step=0.050000
2017/08/29 20:41:29 step 2: mse=14277.956625 step=0.050000
2017/08/29 20:41:30 step 3: mse=14262.652095 step=0.050000
2017/08/29 20:41:31 step 4: mse=14247.712052 step=0.050000
2017/08/29 20:41:32 step 5: mse=14231.784994 step=0.050000
2017/08/29 20:41:32 step 6: mse=14216.182520 step=0.050000
2017/08/29 20:41:33 step 7: mse=14206.230117 step=0.050000
2017/08/29 20:41:33 Saving...
2017/08/29 20:41:33 Gathering batch of experience...
2017/08/29 20:41:55 batch 81: mean=746.376812 stddev=400.610842 entropy=0.645678 frames=4602 count=69
2017/08/29 20:41:55 Training policy...
2017/08/29 20:41:58 tune 0: objective=20.545076 reg=0.006457 prune=0
2017/08/29 20:41:58 step 0: objective=20.557835 reg=0.006455
2017/08/29 20:41:59 step 1: objective=20.573224 reg=0.006454
2017/08/29 20:42:00 step 2: objective=20.593667 reg=0.006454
2017/08/29 20:42:00 step 3: objective=20.616512 reg=0.006453
2017/08/29 20:42:01 step 4: objective=20.635306 reg=0.006452
2017/08/29 20:42:02 step 5: objective=20.652121 reg=0.006451
2017/08/29 20:42:02 step 6: objective=20.673321 reg=0.006450
2017/08/29 20:42:03 step 7: objective=20.694036 reg=0.006449
2017/08/29 20:42:03 Training value function...
2017/08/29 20:42:05 step 0: mse=14262.517904 step=0.050000
2017/08/29 20:42:06 step 1: mse=14232.953277 step=0.050000
2017/08/29 20:42:06 step 2: mse=14203.323529 step=0.050000
2017/08/29 20:42:07 step 3: mse=14173.859259 step=0.050000
2017/08/29 20:42:08 step 4: mse=14142.108339 step=0.050000
2017/08/29 20:42:08 step 5: mse=14118.611169 step=0.050000
2017/08/29 20:42:09 step 6: mse=14081.895765 step=0.050000
2017/08/29 20:42:10 step 7: mse=14060.100113 step=0.050000
2017/08/29 20:42:10 Saving...
2017/08/29 20:42:10 Gathering batch of experience...
2017/08/29 20:42:32 batch 82: mean=796.307692 stddev=448.886894 entropy=0.643914 frames=4510 count=65
2017/08/29 20:42:32 Training policy...
2017/08/29 20:42:34 tune 0: objective=26.036752 reg=0.006439 prune=0
2017/08/29 20:42:35 step 0: objective=26.051330 reg=0.006437
2017/08/29 20:42:35 step 1: objective=26.078979 reg=0.006436
2017/08/29 20:42:36 step 2: objective=26.101039 reg=0.006435
2017/08/29 20:42:37 step 3: objective=26.116734 reg=0.006434
2017/08/29 20:42:37 step 4: objective=26.142986 reg=0.006433
2017/08/29 20:42:38 step 5: objective=26.162711 reg=0.006433
2017/08/29 20:42:39 step 6: objective=26.185115 reg=0.006432
2017/08/29 20:42:39 step 7: objective=26.206053 reg=0.006430
2017/08/29 20:42:39 Training value function...
2017/08/29 20:42:41 step 0: mse=16837.692595 step=0.050000
2017/08/29 20:42:42 step 1: mse=16716.413052 step=0.050000
2017/08/29 20:42:43 step 2: mse=16612.441253 step=0.050000
2017/08/29 20:42:43 step 3: mse=16514.309204 step=0.050000
2017/08/29 20:42:44 step 4: mse=16422.110524 step=0.050000
2017/08/29 20:42:45 step 5: mse=16329.047025 step=0.050000
2017/08/29 20:42:45 step 6: mse=16246.312494 step=0.050000
2017/08/29 20:42:46 step 7: mse=16170.353156 step=0.050000
2017/08/29 20:42:46 Saving...
2017/08/29 20:42:46 Gathering batch of experience...
2017/08/29 20:43:08 batch 83: mean=806.461538 stddev=414.856530 entropy=0.640349 frames=4591 count=65
2017/08/29 20:43:08 Training policy...
2017/08/29 20:43:11 tune 0: objective=23.270160 reg=0.006403 prune=0
2017/08/29 20:43:12 step 0: objective=23.280399 reg=0.006402
2017/08/29 20:43:12 step 1: objective=23.302647 reg=0.006401
2017/08/29 20:43:13 step 2: objective=23.326462 reg=0.006400
2017/08/29 20:43:14 step 3: objective=23.343748 reg=0.006400
2017/08/29 20:43:14 step 4: objective=23.364909 reg=0.006399
2017/08/29 20:43:15 step 5: objective=23.382093 reg=0.006398
2017/08/29 20:43:16 step 6: objective=23.396802 reg=0.006397
2017/08/29 20:43:16 step 7: objective=23.414983 reg=0.006397
2017/08/29 20:43:16 Training value function...
2017/08/29 20:43:18 step 0: mse=14544.134901 step=0.050000
2017/08/29 20:43:19 step 1: mse=14485.645580 step=0.050000
2017/08/29 20:43:20 step 2: mse=14429.261609 step=0.050000
2017/08/29 20:43:20 step 3: mse=14375.100804 step=0.050000
2017/08/29 20:43:21 step 4: mse=14328.464981 step=0.050000
2017/08/29 20:43:22 step 5: mse=14282.597831 step=0.050000
2017/08/29 20:43:22 step 6: mse=14237.212226 step=0.050000
2017/08/29 20:43:23 step 7: mse=14196.599993 step=0.050000
2017/08/29 20:43:23 Saving...
2017/08/29 20:43:23 Gathering batch of experience...
2017/08/29 20:43:46 batch 84: mean=725.270270 stddev=392.980548 entropy=0.642094 frames=4755 count=74
2017/08/29 20:43:46 Training policy...
2017/08/29 20:43:49 tune 0: objective=15.590129 reg=0.006421 prune=0
2017/08/29 20:43:50 step 0: objective=15.599271 reg=0.006421
2017/08/29 20:43:50 step 1: objective=15.622680 reg=0.006421
2017/08/29 20:43:51 step 2: objective=15.647008 reg=0.006422
2017/08/29 20:43:52 step 3: objective=15.672701 reg=0.006421
2017/08/29 20:43:52 step 4: objective=15.694399 reg=0.006422
2017/08/29 20:43:53 step 5: objective=15.712991 reg=0.006422
2017/08/29 20:43:54 step 6: objective=15.731184 reg=0.006421
2017/08/29 20:43:55 step 7: objective=15.747468 reg=0.006422
2017/08/29 20:43:55 Training value function...
2017/08/29 20:43:56 step 0: mse=13899.612410 step=0.050000
2017/08/29 20:43:57 step 1: mse=13911.997815 step=0.050000
2017/08/29 20:43:58 step 2: mse=13927.769266 step=0.050000
2017/08/29 20:43:59 step 3: mse=13939.366821 step=0.050000
2017/08/29 20:43:59 step 4: mse=13951.455423 step=0.050000
2017/08/29 20:44:00 step 5: mse=13960.422851 step=0.050000
2017/08/29 20:44:01 step 6: mse=13968.206453 step=0.050000
2017/08/29 20:44:02 step 7: mse=13980.381067 step=0.050000
2017/08/29 20:44:02 Saving...
2017/08/29 20:44:02 Gathering batch of experience...
2017/08/29 20:44:25 batch 85: mean=742.394366 stddev=391.505634 entropy=0.640130 frames=4732 count=71
2017/08/29 20:44:25 Training policy...
2017/08/29 20:44:27 tune 0: objective=16.606258 reg=0.006401 prune=0
2017/08/29 20:44:28 step 0: objective=16.622732 reg=0.006398
2017/08/29 20:44:28 step 1: objective=16.651139 reg=0.006396
2017/08/29 20:44:29 step 2: objective=16.675502 reg=0.006394
2017/08/29 20:44:30 step 3: objective=16.700323 reg=0.006392
2017/08/29 20:44:31 step 4: objective=16.718687 reg=0.006390
2017/08/29 20:44:31 step 5: objective=16.743997 reg=0.006387
2017/08/29 20:44:32 step 6: objective=16.770923 reg=0.006385
2017/08/29 20:44:33 step 7: objective=16.799754 reg=0.006383
2017/08/29 20:44:33 Training value function...
2017/08/29 20:44:35 step 0: mse=13101.513365 step=0.050000
2017/08/29 20:44:35 step 1: mse=13100.861761 step=0.050000
2017/08/29 20:44:36 step 2: mse=13097.979490 step=0.050000
2017/08/29 20:44:37 step 3: mse=13100.940995 step=0.050000
2017/08/29 20:44:37 step 4: mse=13100.830780 step=0.050000
2017/08/29 20:44:38 step 5: mse=13104.711812 step=0.050000
2017/08/29 20:44:39 step 6: mse=13103.769477 step=0.050000
2017/08/29 20:44:40 step 7: mse=13101.448863 step=0.050000
2017/08/29 20:44:40 Saving...
2017/08/29 20:44:40 Gathering batch of experience...
2017/08/29 20:45:02 batch 86: mean=842.692308 stddev=486.903937 entropy=0.638465 frames=4724 count=65
2017/08/29 20:45:02 Training policy...
2017/08/29 20:45:04 tune 0: objective=29.335508 reg=0.006385 prune=0
2017/08/29 20:45:05 step 0: objective=29.350501 reg=0.006382
2017/08/29 20:45:06 step 1: objective=29.373813 reg=0.006381
2017/08/29 20:45:06 step 2: objective=29.394141 reg=0.006381
2017/08/29 20:45:07 step 3: objective=29.412991 reg=0.006381
2017/08/29 20:45:08 step 4: objective=29.432105 reg=0.006380
2017/08/29 20:45:09 step 5: objective=29.452589 reg=0.006379
2017/08/29 20:45:09 step 6: objective=29.470268 reg=0.006379
2017/08/29 20:45:10 step 7: objective=29.491926 reg=0.006378
2017/08/29 20:45:10 Training value function...
2017/08/29 20:45:12 step 0: mse=18222.556625 step=0.050000
2017/08/29 20:45:13 step 1: mse=18020.194956 step=0.050000
2017/08/29 20:45:13 step 2: mse=17833.204673 step=0.050000
2017/08/29 20:45:14 step 3: mse=17650.378779 step=0.050000
2017/08/29 20:45:15 step 4: mse=17489.419798 step=0.050000
2017/08/29 20:45:15 step 5: mse=17341.198622 step=0.050000
2017/08/29 20:45:16 step 6: mse=17197.148112 step=0.050000
2017/08/29 20:45:17 step 7: mse=17066.317656 step=0.050000
2017/08/29 20:45:17 Saving...
2017/08/29 20:45:17 Gathering batch of experience...
2017/08/29 20:45:40 batch 87: mean=802.753623 stddev=468.887472 entropy=0.636886 frames=4787 count=69
2017/08/29 20:45:40 Training policy...
2017/08/29 20:45:43 tune 0: objective=23.523906 reg=0.006369 prune=0
2017/08/29 20:45:44 step 0: objective=23.533603 reg=0.006367
2017/08/29 20:45:44 step 1: objective=23.552693 reg=0.006366
2017/08/29 20:45:45 step 2: objective=23.566306 reg=0.006365
2017/08/29 20:45:46 step 3: objective=23.581374 reg=0.006365
2017/08/29 20:45:46 step 4: objective=23.599917 reg=0.006364
2017/08/29 20:45:47 step 5: objective=23.614903 reg=0.006363
2017/08/29 20:45:48 step 6: objective=23.634476 reg=0.006362
2017/08/29 20:45:49 step 7: objective=23.652612 reg=0.006362
2017/08/29 20:45:49 Training value function...
2017/08/29 20:45:50 step 0: mse=15686.916967 step=0.050000
2017/08/29 20:45:51 step 1: mse=15565.049577 step=0.050000
2017/08/29 20:45:52 step 2: mse=15448.400722 step=0.050000
2017/08/29 20:45:53 step 3: mse=15342.292023 step=0.050000
2017/08/29 20:45:53 step 4: mse=15251.832206 step=0.050000
2017/08/29 20:45:54 step 5: mse=15158.654818 step=0.050000
2017/08/29 20:45:55 step 6: mse=15084.630161 step=0.050000
2017/08/29 20:45:56 step 7: mse=15001.896012 step=0.050000
2017/08/29 20:45:56 Saving...
2017/08/29 20:45:56 Gathering batch of experience...
2017/08/29 20:46:18 batch 88: mean=822.835821 stddev=437.209796 entropy=0.636341 frames=4822 count=67
2017/08/29 20:46:18 Training policy...
2017/08/29 20:46:21 tune 0: objective=20.952189 reg=0.006363 prune=0
2017/08/29 20:46:22 step 0: objective=20.959991 reg=0.006363
2017/08/29 20:46:22 step 1: objective=20.979019 reg=0.006363
2017/08/29 20:46:23 step 2: objective=20.993351 reg=0.006363
2017/08/29 20:46:24 step 3: objective=21.011129 reg=0.006363
2017/08/29 20:46:25 step 4: objective=21.027010 reg=0.006362
2017/08/29 20:46:25 step 5: objective=21.045475 reg=0.006362
2017/08/29 20:46:26 step 6: objective=21.065224 reg=0.006361
2017/08/29 20:46:27 step 7: objective=21.086080 reg=0.006361
2017/08/29 20:46:27 Training value function...
2017/08/29 20:46:29 step 0: mse=15545.654049 step=0.050000
2017/08/29 20:46:30 step 1: mse=15484.223222 step=0.050000
2017/08/29 20:46:30 step 2: mse=15428.491621 step=0.050000
2017/08/29 20:46:31 step 3: mse=15371.330932 step=0.050000
2017/08/29 20:46:32 step 4: mse=15323.368157 step=0.050000
2017/08/29 20:46:33 step 5: mse=15288.853627 step=0.050000
2017/08/29 20:46:33 step 6: mse=15245.460653 step=0.050000
2017/08/29 20:46:34 step 7: mse=15203.420389 step=0.050000
2017/08/29 20:46:34 Saving...
2017/08/29 20:46:34 Gathering batch of experience...
2017/08/29 20:46:57 batch 89: mean=750.138889 stddev=424.034829 entropy=0.639615 frames=4786 count=72
2017/08/29 20:46:57 Training policy...
2017/08/29 20:47:00 tune 0: objective=15.119159 reg=0.006396 prune=0
2017/08/29 20:47:00 step 0: objective=15.127587 reg=0.006395
2017/08/29 20:47:01 step 1: objective=15.152554 reg=0.006395
2017/08/29 20:47:02 step 2: objective=15.170274 reg=0.006395
2017/08/29 20:47:03 step 3: objective=15.191519 reg=0.006394
2017/08/29 20:47:03 step 4: objective=15.212984 reg=0.006395
2017/08/29 20:47:04 step 5: objective=15.233866 reg=0.006395
2017/08/29 20:47:05 step 6: objective=15.252271 reg=0.006394
2017/08/29 20:47:05 step 7: objective=15.272740 reg=0.006394
2017/08/29 20:47:05 Training value function...
2017/08/29 20:47:07 step 0: mse=14946.692695 step=0.050000
2017/08/29 20:47:08 step 1: mse=14956.049264 step=0.050000
2017/08/29 20:47:09 step 2: mse=14964.286343 step=0.050000
2017/08/29 20:47:10 step 3: mse=14965.388258 step=0.050000
2017/08/29 20:47:10 step 4: mse=14965.631116 step=0.050000
2017/08/29 20:47:11 step 5: mse=14974.796372 step=0.050000
2017/08/29 20:47:12 step 6: mse=14980.416483 step=0.050000
2017/08/29 20:47:12 step 7: mse=14981.971914 step=0.050000
2017/08/29 20:47:12 Saving...
2017/08/29 20:47:13 Gathering batch of experience...
2017/08/29 20:47:35 batch 90: mean=752.720588 stddev=409.692706 entropy=0.637981 frames=4601 count=68
2017/08/29 20:47:35 Training policy...
2017/08/29 20:47:37 tune 0: objective=16.050626 reg=0.006380 prune=0
2017/08/29 20:47:38 step 0: objective=16.065825 reg=0.006378
2017/08/29 20:47:39 step 1: objective=16.086651 reg=0.006378
2017/08/29 20:47:39 step 2: objective=16.106935 reg=0.006377
2017/08/29 20:47:40 step 3: objective=16.128890 reg=0.006376
2017/08/29 20:47:41 step 4: objective=16.151548 reg=0.006375
2017/08/29 20:47:41 step 5: objective=16.171926 reg=0.006374
2017/08/29 20:47:42 step 6: objective=16.196664 reg=0.006372
2017/08/29 20:47:43 step 7: objective=16.220555 reg=0.006371
2017/08/29 20:47:43 Training value function...
2017/08/29 20:47:45 step 0: mse=13249.873318 step=0.050000
2017/08/29 20:47:45 step 1: mse=13259.129984 step=0.050000
2017/08/29 20:47:46 step 2: mse=13275.604784 step=0.050000
2017/08/29 20:47:47 step 3: mse=13282.788365 step=0.050000
2017/08/29 20:47:47 step 4: mse=13289.072446 step=0.050000
2017/08/29 20:47:48 step 5: mse=13300.431527 step=0.050000
2017/08/29 20:47:49 step 6: mse=13310.844137 step=0.050000
2017/08/29 20:47:50 step 7: mse=13322.096458 step=0.050000
2017/08/29 20:47:50 Saving...
2017/08/29 20:47:50 Gathering batch of experience...
2017/08/29 20:48:12 batch 91: mean=782.238806 stddev=406.285764 entropy=0.632633 frames=4636 count=67
2017/08/29 20:48:12 Training policy...
2017/08/29 20:48:14 tune 0: objective=20.044121 reg=0.006326 prune=0
2017/08/29 20:48:15 step 0: objective=20.052780 reg=0.006325
2017/08/29 20:48:16 step 1: objective=20.064025 reg=0.006324
2017/08/29 20:48:17 step 2: objective=20.078558 reg=0.006324
2017/08/29 20:48:17 step 3: objective=20.091359 reg=0.006323
2017/08/29 20:48:18 step 4: objective=20.108696 reg=0.006322
2017/08/29 20:48:19 step 5: objective=20.124301 reg=0.006322
2017/08/29 20:48:19 step 6: objective=20.134702 reg=0.006321
2017/08/29 20:48:20 step 7: objective=20.147528 reg=0.006321
2017/08/29 20:48:20 Training value function...
2017/08/29 20:48:22 step 0: mse=13892.772303 step=0.050000
2017/08/29 20:48:23 step 1: mse=13865.385137 step=0.050000
2017/08/29 20:48:23 step 2: mse=13836.801789 step=0.050000
2017/08/29 20:48:24 step 3: mse=13812.778734 step=0.050000
2017/08/29 20:48:25 step 4: mse=13790.507059 step=0.050000
2017/08/29 20:48:25 step 5: mse=13768.003728 step=0.050000
2017/08/29 20:48:26 step 6: mse=13748.588390 step=0.050000
2017/08/29 20:48:27 step 7: mse=13732.101756 step=0.050000
2017/08/29 20:48:27 Saving...
2017/08/29 20:48:27 Gathering batch of experience...
2017/08/29 20:48:49 batch 92: mean=859.921875 stddev=423.531924 entropy=0.630694 frames=4725 count=64
2017/08/29 20:48:49 Training policy...
2017/08/29 20:48:52 tune 0: objective=27.507138 reg=0.006307 prune=0
2017/08/29 20:48:52 step 0: objective=27.512006 reg=0.006307
2017/08/29 20:48:53 step 1: objective=27.522842 reg=0.006306
2017/08/29 20:48:54 step 2: objective=27.539076 reg=0.006306
2017/08/29 20:48:55 step 3: objective=27.548775 reg=0.006306
2017/08/29 20:48:55 step 4: objective=27.563497 reg=0.006305
2017/08/29 20:48:56 step 5: objective=27.574714 reg=0.006305
2017/08/29 20:48:57 step 6: objective=27.588158 reg=0.006305
2017/08/29 20:48:57 step 7: objective=27.601182 reg=0.006305
2017/08/29 20:48:57 Training value function...
2017/08/29 20:48:59 step 0: mse=15235.721332 step=0.050000
2017/08/29 20:49:00 step 1: mse=15088.449263 step=0.050000
2017/08/29 20:49:01 step 2: mse=14943.494465 step=0.050000
2017/08/29 20:49:01 step 3: mse=14817.508596 step=0.050000
2017/08/29 20:49:02 step 4: mse=14699.252166 step=0.050000
2017/08/29 20:49:03 step 5: mse=14589.864306 step=0.050000
2017/08/29 20:49:04 step 6: mse=14477.105446 step=0.050000
2017/08/29 20:49:04 step 7: mse=14386.280468 step=0.050000
2017/08/29 20:49:04 Saving...
2017/08/29 20:49:04 Gathering batch of experience...
2017/08/29 20:49:27 batch 93: mean=867.187500 stddev=541.955282 entropy=0.637020 frames=4764 count=64
2017/08/29 20:49:27 Training policy...
2017/08/29 20:49:29 tune 0: objective=27.382716 reg=0.006370 prune=0
2017/08/29 20:49:30 step 0: objective=27.392896 reg=0.006369
2017/08/29 20:49:31 step 1: objective=27.407819 reg=0.006369
2017/08/29 20:49:31 step 2: objective=27.422792 reg=0.006369
2017/08/29 20:49:32 step 3: objective=27.440695 reg=0.006370
2017/08/29 20:49:33 step 4: objective=27.458374 reg=0.006370
2017/08/29 20:49:34 step 5: objective=27.474796 reg=0.006369
2017/08/29 20:49:34 step 6: objective=27.489523 reg=0.006369
2017/08/29 20:49:35 step 7: objective=27.506120 reg=0.006369
2017/08/29 20:49:35 Training value function...
2017/08/29 20:49:37 step 0: mse=19190.412860 step=0.050000
2017/08/29 20:49:38 step 1: mse=18994.866359 step=0.050000
2017/08/29 20:49:38 step 2: mse=18806.225010 step=0.050000
2017/08/29 20:49:39 step 3: mse=18640.561405 step=0.050000
2017/08/29 20:49:40 step 4: mse=18490.486639 step=0.050000
2017/08/29 20:49:41 step 5: mse=18354.271257 step=0.050000
2017/08/29 20:49:41 step 6: mse=18232.138572 step=0.050000
2017/08/29 20:49:42 step 7: mse=18112.878936 step=0.050000
2017/08/29 20:49:42 Saving...
2017/08/29 20:49:42 Gathering batch of experience...
2017/08/29 20:50:05 batch 94: mean=796.838235 stddev=446.585003 entropy=0.634512 frames=4708 count=68
2017/08/29 20:50:05 Training policy...
2017/08/29 20:50:07 tune 0: objective=18.794144 reg=0.006345 prune=0
2017/08/29 20:50:08 step 0: objective=18.803206 reg=0.006343
2017/08/29 20:50:09 step 1: objective=18.821673 reg=0.006342
2017/08/29 20:50:09 step 2: objective=18.839019 reg=0.006341
2017/08/29 20:50:10 step 3: objective=18.854017 reg=0.006340
2017/08/29 20:50:11 step 4: objective=18.872074 reg=0.006339
2017/08/29 20:50:12 step 5: objective=18.893630 reg=0.006337
2017/08/29 20:50:12 step 6: objective=18.912747 reg=0.006336
2017/08/29 20:50:13 step 7: objective=18.929800 reg=0.006335
2017/08/29 20:50:13 Training value function...
2017/08/29 20:50:15 step 0: mse=13468.697847 step=0.050000
2017/08/29 20:50:16 step 1: mse=13437.003559 step=0.050000
2017/08/29 20:50:16 step 2: mse=13401.205063 step=0.050000
2017/08/29 20:50:17 step 3: mse=13371.436360 step=0.050000
2017/08/29 20:50:18 step 4: mse=13344.303092 step=0.050000
2017/08/29 20:50:18 step 5: mse=13314.199683 step=0.050000
2017/08/29 20:50:19 step 6: mse=13293.586367 step=0.050000
2017/08/29 20:50:20 step 7: mse=13266.773773 step=0.050000
2017/08/29 20:50:20 Saving...
2017/08/29 20:50:20 Gathering batch of experience...
2017/08/29 20:50:43 batch 95: mean=706.315789 stddev=426.428997 entropy=0.636728 frames=4731 count=76
2017/08/29 20:50:43 Training policy...
2017/08/29 20:50:45 tune 0: objective=12.152662 reg=0.006367 prune=0
2017/08/29 20:50:46 step 0: objective=12.164347 reg=0.006365
2017/08/29 20:50:47 step 1: objective=12.180512 reg=0.006365
2017/08/29 20:50:48 step 2: objective=12.197997 reg=0.006365
2017/08/29 20:50:48 step 3: objective=12.215211 reg=0.006364
2017/08/29 20:50:49 step 4: objective=12.225790 reg=0.006363
2017/08/29 20:50:50 step 5: objective=12.241036 reg=0.006363
2017/08/29 20:50:50 step 6: objective=12.257273 reg=0.006361
2017/08/29 20:50:51 step 7: objective=12.270089 reg=0.006360
2017/08/29 20:50:51 Training value function...
2017/08/29 20:50:53 step 0: mse=13963.940408 step=0.050000
2017/08/29 20:50:54 step 1: mse=13974.466935 step=0.050000
2017/08/29 20:50:54 step 2: mse=13989.415404 step=0.050000
2017/08/29 20:50:55 step 3: mse=13984.314950 step=0.050000
2017/08/29 20:50:56 step 4: mse=13985.389817 step=0.050000
2017/08/29 20:50:57 step 5: mse=13989.381017 step=0.050000
2017/08/29 20:50:57 step 6: mse=14007.032928 step=0.050000
2017/08/29 20:50:58 step 7: mse=14017.443074 step=0.050000
2017/08/29 20:50:58 Saving...
2017/08/29 20:50:58 Gathering batch of experience...
2017/08/29 20:51:20 batch 96: mean=873.629032 stddev=422.436452 entropy=0.628426 frames=4600 count=62
2017/08/29 20:51:20 Training policy...
2017/08/29 20:51:22 tune 0: objective=26.871912 reg=0.006284 prune=0
2017/08/29 20:51:23 step 0: objective=26.881313 reg=0.006283
2017/08/29 20:51:24 step 1: objective=26.899905 reg=0.006282
2017/08/29 20:51:24 step 2: objective=26.918755 reg=0.006282
2017/08/29 20:51:25 step 3: objective=26.930119 reg=0.006282
2017/08/29 20:51:26 step 4: objective=26.945289 reg=0.006281
2017/08/29 20:51:27 step 5: objective=26.959927 reg=0.006281
2017/08/29 20:51:27 step 6: objective=26.973414 reg=0.006281
2017/08/29 20:51:28 step 7: objective=26.987738 reg=0.006280
2017/08/29 20:51:28 Training value function...
2017/08/29 20:51:30 step 0: mse=15392.656497 step=0.050000
2017/08/29 20:51:30 step 1: mse=15282.905973 step=0.050000
2017/08/29 20:51:31 step 2: mse=15183.903250 step=0.050000
2017/08/29 20:51:32 step 3: mse=15088.546163 step=0.050000
2017/08/29 20:51:33 step 4: mse=15005.113616 step=0.050000
2017/08/29 20:51:33 step 5: mse=14926.374538 step=0.050000
2017/08/29 20:51:34 step 6: mse=14855.466095 step=0.050000
2017/08/29 20:51:35 step 7: mse=14791.276851 step=0.050000
2017/08/29 20:51:35 Saving...
2017/08/29 20:51:35 Gathering batch of experience...
2017/08/29 20:51:58 batch 97: mean=782.352941 stddev=423.292826 entropy=0.631591 frames=4725 count=68
2017/08/29 20:51:58 Training policy...
2017/08/29 20:52:00 tune 0: objective=15.965655 reg=0.006316 prune=0
2017/08/29 20:52:01 step 0: objective=15.975506 reg=0.006315
2017/08/29 20:52:02 step 1: objective=15.992705 reg=0.006315
2017/08/29 20:52:02 step 2: objective=16.014489 reg=0.006315
2017/08/29 20:52:03 step 3: objective=16.028039 reg=0.006314
2017/08/29 20:52:04 step 4: objective=16.050021 reg=0.006314
2017/08/29 20:52:04 step 5: objective=16.072536 reg=0.006314
2017/08/29 20:52:05 step 6: objective=16.092044 reg=0.006313
2017/08/29 20:52:06 step 7: objective=16.103438 reg=0.006313
2017/08/29 20:52:06 Training value function...
2017/08/29 20:52:08 step 0: mse=13284.931770 step=0.050000
2017/08/29 20:52:09 step 1: mse=13301.709038 step=0.050000
2017/08/29 20:52:09 step 2: mse=13317.518877 step=0.050000
2017/08/29 20:52:10 step 3: mse=13334.757845 step=0.050000
2017/08/29 20:52:11 step 4: mse=13351.132094 step=0.050000
2017/08/29 20:52:11 step 5: mse=13360.585750 step=0.050000
2017/08/29 20:52:12 step 6: mse=13369.458791 step=0.050000
2017/08/29 20:52:13 step 7: mse=13377.319217 step=0.050000
2017/08/29 20:52:13 Saving...
2017/08/29 20:52:13 Gathering batch of experience...
2017/08/29 20:52:35 batch 98: mean=834.923077 stddev=444.052572 entropy=0.629419 frames=4661 count=65
2017/08/29 20:52:35 Training policy...
2017/08/29 20:52:38 tune 0: objective=24.070785 reg=0.006294 prune=0
2017/08/29 20:52:38 step 0: objective=24.081658 reg=0.006293
2017/08/29 20:52:39 step 1: objective=24.097241 reg=0.006292
2017/08/29 20:52:40 step 2: objective=24.119675 reg=0.006291
2017/08/29 20:52:40 step 3: objective=24.138503 reg=0.006291
2017/08/29 20:52:41 step 4: objective=24.155011 reg=0.006290
2017/08/29 20:52:42 step 5: objective=24.184118 reg=0.006288
2017/08/29 20:52:43 step 6: objective=24.207366 reg=0.006288
2017/08/29 20:52:43 step 7: objective=24.227620 reg=0.006286
2017/08/29 20:52:43 Training value function...
2017/08/29 20:52:45 step 0: mse=15836.035866 step=0.050000
2017/08/29 20:52:46 step 1: mse=15764.525920 step=0.050000
2017/08/29 20:52:47 step 2: mse=15693.571745 step=0.050000
2017/08/29 20:52:47 step 3: mse=15630.618748 step=0.050000
2017/08/29 20:52:48 step 4: mse=15569.724513 step=0.050000
2017/08/29 20:52:49 step 5: mse=15511.890351 step=0.050000
2017/08/29 20:52:49 step 6: mse=15461.985857 step=0.050000
2017/08/29 20:52:50 step 7: mse=15417.842199 step=0.050000
2017/08/29 20:52:50 Saving...
2017/08/29 20:52:50 Gathering batch of experience...
2017/08/29 20:53:13 batch 99: mean=730.281690 stddev=429.951592 entropy=0.633161 frames=4601 count=71
2017/08/29 20:53:13 Training policy...
2017/08/29 20:53:15 tune 0: objective=13.383300 reg=0.006332 prune=0
2017/08/29 20:53:16 step 0: objective=13.391753 reg=0.006331
2017/08/29 20:53:17 step 1: objective=13.404902 reg=0.006331
2017/08/29 20:53:17 step 2: objective=13.421996 reg=0.006331
2017/08/29 20:53:18 step 3: objective=13.444519 reg=0.006330
2017/08/29 20:53:19 step 4: objective=13.458688 reg=0.006329
2017/08/29 20:53:19 step 5: objective=13.473212 reg=0.006328
2017/08/29 20:53:20 step 6: objective=13.493599 reg=0.006328
2017/08/29 20:53:21 step 7: objective=13.503534 reg=0.006327
2017/08/29 20:53:21 Training value function...
2017/08/29 20:53:23 step 0: mse=13868.808939 step=0.050000
2017/08/29 20:53:23 step 1: mse=13886.651657 step=0.050000
2017/08/29 20:53:24 step 2: mse=13913.627321 step=0.050000
2017/08/29 20:53:25 step 3: mse=13938.294968 step=0.050000
2017/08/29 20:53:25 step 4: mse=13961.009852 step=0.050000
2017/08/29 20:53:26 step 5: mse=13982.300747 step=0.050000
2017/08/29 20:53:27 step 6: mse=14002.000169 step=0.050000
2017/08/29 20:53:28 step 7: mse=14012.715008 step=0.050000
2017/08/29 20:53:28 Saving...
2017/08/29 20:53:28 Gathering batch of experience...
2017/08/29 20:53:50 batch 100: mean=757.101449 stddev=392.732351 entropy=0.628494 frames=4529 count=69
2017/08/29 20:53:50 Training policy...
2017/08/29 20:53:52 tune 0: objective=18.370398 reg=0.006285 prune=0
2017/08/29 20:53:53 step 0: objective=18.377553 reg=0.006284
2017/08/29 20:53:54 step 1: objective=18.399709 reg=0.006284
2017/08/29 20:53:54 step 2: objective=18.419129 reg=0.006284
2017/08/29 20:53:55 step 3: objective=18.439910 reg=0.006285
2017/08/29 20:53:56 step 4: objective=18.458778 reg=0.006285
2017/08/29 20:53:56 step 5: objective=18.479526 reg=0.006284
2017/08/29 20:53:57 step 6: objective=18.499741 reg=0.006284
2017/08/29 20:53:58 step 7: objective=18.520740 reg=0.006284
2017/08/29 20:53:58 Training value function...
2017/08/29 20:53:59 step 0: mse=12970.850990 step=0.050000
2017/08/29 20:54:00 step 1: mse=12958.862367 step=0.050000
2017/08/29 20:54:01 step 2: mse=12951.094365 step=0.050000
2017/08/29 20:54:02 step 3: mse=12943.221197 step=0.050000
2017/08/29 20:54:02 step 4: mse=12935.038456 step=0.050000
2017/08/29 20:54:03 step 5: mse=12926.238843 step=0.050000
2017/08/29 20:54:04 step 6: mse=12921.692394 step=0.050000
2017/08/29 20:54:04 step 7: mse=12909.218035 step=0.050000
2017/08/29 20:54:04 Saving...
2017/08/29 20:54:04 Gathering batch of experience...
2017/08/29 20:54:26 batch 101: mean=754.782609 stddev=454.773741 entropy=0.633330 frames=4556 count=69
2017/08/29 20:54:26 Training policy...
2017/08/29 20:54:29 tune 0: objective=19.380570 reg=0.006333 prune=0
2017/08/29 20:54:29 step 0: objective=19.396333 reg=0.006333
2017/08/29 20:54:30 step 1: objective=19.426273 reg=0.006333
2017/08/29 20:54:31 step 2: objective=19.461229 reg=0.006333
2017/08/29 20:54:31 step 3: objective=19.490593 reg=0.006333
2017/08/29 20:54:32 step 4: objective=19.521159 reg=0.006333
2017/08/29 20:54:33 step 5: objective=19.545724 reg=0.006333
2017/08/29 20:54:34 step 6: objective=19.574203 reg=0.006332
2017/08/29 20:54:34 step 7: objective=19.598226 reg=0.006333
2017/08/29 20:54:34 Training value function...
2017/08/29 20:54:36 step 0: mse=15800.770794 step=0.050000
2017/08/29 20:54:37 step 1: mse=15767.329704 step=0.050000
2017/08/29 20:54:37 step 2: mse=15738.467356 step=0.050000
2017/08/29 20:54:38 step 3: mse=15710.937686 step=0.050000
2017/08/29 20:54:39 step 4: mse=15686.204256 step=0.050000
2017/08/29 20:54:40 step 5: mse=15667.355494 step=0.050000
2017/08/29 20:54:40 step 6: mse=15649.490395 step=0.050000
2017/08/29 20:54:41 step 7: mse=15630.044960 step=0.050000
2017/08/29 20:54:41 Saving...
2017/08/29 20:54:41 Gathering batch of experience...
2017/08/29 20:55:03 batch 102: mean=893.253968 stddev=456.602497 entropy=0.627662 frames=4782 count=63
2017/08/29 20:55:03 Training policy...
2017/08/29 20:55:06 tune 0: objective=29.738267 reg=0.006277 prune=0
2017/08/29 20:55:06 step 0: objective=29.746311 reg=0.006275
2017/08/29 20:55:07 step 1: objective=29.760100 reg=0.006275
2017/08/29 20:55:08 step 2: objective=29.772428 reg=0.006274
2017/08/29 20:55:09 step 3: objective=29.785988 reg=0.006273
2017/08/29 20:55:09 step 4: objective=29.795143 reg=0.006272
2017/08/29 20:55:10 step 5: objective=29.804678 reg=0.006272
2017/08/29 20:55:11 step 6: objective=29.821015 reg=0.006271
2017/08/29 20:55:12 step 7: objective=29.832964 reg=0.006270
2017/08/29 20:55:12 Training value function...
2017/08/29 20:55:13 step 0: mse=16195.404939 step=0.050000
2017/08/29 20:55:14 step 1: mse=16036.244320 step=0.050000
2017/08/29 20:55:15 step 2: mse=15898.076103 step=0.050000
2017/08/29 20:55:16 step 3: mse=15765.596040 step=0.050000
2017/08/29 20:55:16 step 4: mse=15645.075208 step=0.050000
2017/08/29 20:55:17 step 5: mse=15527.886606 step=0.050000
2017/08/29 20:55:18 step 6: mse=15423.758073 step=0.050000
2017/08/29 20:55:19 step 7: mse=15323.519311 step=0.050000
2017/08/29 20:55:19 Saving...
2017/08/29 20:55:19 Gathering batch of experience...
2017/08/29 20:55:41 batch 103: mean=836.406250 stddev=416.783132 entropy=0.627102 frames=4690 count=64
2017/08/29 20:55:41 Training policy...
2017/08/29 20:55:43 tune 0: objective=19.414341 reg=0.006271 prune=0
2017/08/29 20:55:44 step 0: objective=19.422110 reg=0.006270
2017/08/29 20:55:45 step 1: objective=19.433286 reg=0.006269
2017/08/29 20:55:46 step 2: objective=19.446823 reg=0.006268
2017/08/29 20:55:46 step 3: objective=19.459398 reg=0.006267
2017/08/29 20:55:47 step 4: objective=19.480687 reg=0.006266
2017/08/29 20:55:48 step 5: objective=19.496738 reg=0.006265
2017/08/29 20:55:48 step 6: objective=19.513046 reg=0.006263
2017/08/29 20:55:49 step 7: objective=19.532369 reg=0.006262
2017/08/29 20:55:49 Training value function...
2017/08/29 20:55:51 step 0: mse=14155.625983 step=0.050000
2017/08/29 20:55:52 step 1: mse=14146.390558 step=0.050000
2017/08/29 20:55:52 step 2: mse=14139.676366 step=0.050000
2017/08/29 20:55:53 step 3: mse=14130.468504 step=0.050000
2017/08/29 20:55:54 step 4: mse=14119.137276 step=0.050000
2017/08/29 20:55:55 step 5: mse=14111.420272 step=0.050000
2017/08/29 20:55:55 step 6: mse=14093.316568 step=0.050000
2017/08/29 20:55:56 step 7: mse=14076.391567 step=0.050000
2017/08/29 20:55:56 Saving...
2017/08/29 20:55:56 Gathering batch of experience...
2017/08/29 20:56:19 batch 104: mean=771.250000 stddev=451.119828 entropy=0.630874 frames=4644 count=68
2017/08/29 20:56:19 Training policy...
2017/08/29 20:56:21 tune 0: objective=16.675100 reg=0.006309 prune=0
2017/08/29 20:56:22 step 0: objective=16.684586 reg=0.006307
2017/08/29 20:56:22 step 1: objective=16.708838 reg=0.006306
2017/08/29 20:56:23 step 2: objective=16.734166 reg=0.006305
2017/08/29 20:56:24 step 3: objective=16.751842 reg=0.006303
2017/08/29 20:56:25 step 4: objective=16.769284 reg=0.006302
2017/08/29 20:56:25 step 5: objective=16.793051 reg=0.006301
2017/08/29 20:56:26 step 6: objective=16.813595 reg=0.006300
2017/08/29 20:56:27 step 7: objective=16.839208 reg=0.006298
2017/08/29 20:56:27 Training value function...
2017/08/29 20:56:28 step 0: mse=13833.368396 step=0.050000
2017/08/29 20:56:29 step 1: mse=13812.822592 step=0.050000
2017/08/29 20:56:30 step 2: mse=13790.905748 step=0.050000
2017/08/29 20:56:31 step 3: mse=13774.689916 step=0.050000
2017/08/29 20:56:31 step 4: mse=13760.338079 step=0.050000
2017/08/29 20:56:32 step 5: mse=13749.002628 step=0.050000
2017/08/29 20:56:33 step 6: mse=13737.298856 step=0.050000
2017/08/29 20:56:33 step 7: mse=13715.472743 step=0.050000
2017/08/29 20:56:33 Saving...
2017/08/29 20:56:33 Gathering batch of experience...
2017/08/29 20:56:56 batch 105: mean=807.941176 stddev=439.706817 entropy=0.626217 frames=4765 count=68
2017/08/29 20:56:56 Training policy...
2017/08/29 20:56:59 tune 0: objective=20.301135 reg=0.006262 prune=0
2017/08/29 20:56:59 step 0: objective=20.310485 reg=0.006260
2017/08/29 20:57:00 step 1: objective=20.324475 reg=0.006260
2017/08/29 20:57:01 step 2: objective=20.344204 reg=0.006258
2017/08/29 20:57:01 step 3: objective=20.354133 reg=0.006258
2017/08/29 20:57:02 step 4: objective=20.368247 reg=0.006257
2017/08/29 20:57:03 step 5: objective=20.386538 reg=0.006256
2017/08/29 20:57:04 step 6: objective=20.405565 reg=0.006254
2017/08/29 20:57:04 step 7: objective=20.421491 reg=0.006253
2017/08/29 20:57:04 Training value function...
2017/08/29 20:57:06 step 0: mse=15430.383137 step=0.050000
2017/08/29 20:57:07 step 1: mse=15409.942380 step=0.050000
2017/08/29 20:57:08 step 2: mse=15392.159393 step=0.050000
2017/08/29 20:57:08 step 3: mse=15368.977589 step=0.050000
2017/08/29 20:57:09 step 4: mse=15357.038878 step=0.050000
2017/08/29 20:57:10 step 5: mse=15339.224386 step=0.050000
2017/08/29 20:57:11 step 6: mse=15328.350487 step=0.050000
2017/08/29 20:57:11 step 7: mse=15317.557274 step=0.050000
2017/08/29 20:57:11 Saving...
2017/08/29 20:57:11 Gathering batch of experience...
2017/08/29 20:57:34 batch 106: mean=709.864865 stddev=412.336760 entropy=0.629118 frames=4616 count=74
2017/08/29 20:57:34 Training policy...
2017/08/29 20:57:36 tune 0: objective=12.613446 reg=0.006291 prune=0
2017/08/29 20:57:37 step 0: objective=12.620930 reg=0.006290
2017/08/29 20:57:38 step 1: objective=12.637662 reg=0.006289
2017/08/29 20:57:39 step 2: objective=12.655387 reg=0.006289
2017/08/29 20:57:39 step 3: objective=12.671195 reg=0.006288
2017/08/29 20:57:40 step 4: objective=12.686056 reg=0.006287
2017/08/29 20:57:41 step 5: objective=12.701857 reg=0.006286
2017/08/29 20:57:41 step 6: objective=12.717298 reg=0.006285
2017/08/29 20:57:42 step 7: objective=12.731535 reg=0.006285
2017/08/29 20:57:42 Training value function...
2017/08/29 20:57:44 step 0: mse=13474.020524 step=0.050000
2017/08/29 20:57:44 step 1: mse=13484.700334 step=0.050000
2017/08/29 20:57:45 step 2: mse=13498.821891 step=0.050000
2017/08/29 20:57:46 step 3: mse=13508.069423 step=0.050000
2017/08/29 20:57:47 step 4: mse=13520.499516 step=0.050000
2017/08/29 20:57:47 step 5: mse=13529.783543 step=0.050000
2017/08/29 20:57:48 step 6: mse=13543.899254 step=0.050000
2017/08/29 20:57:49 step 7: mse=13559.533811 step=0.050000
2017/08/29 20:57:49 Saving...
2017/08/29 20:57:49 Gathering batch of experience...
2017/08/29 20:58:12 batch 107: mean=788.840580 stddev=470.367683 entropy=0.628280 frames=4749 count=69
2017/08/29 20:58:12 Training policy...
2017/08/29 20:58:14 tune 0: objective=22.503435 reg=0.006283 prune=0
2017/08/29 20:58:15 step 0: objective=22.509933 reg=0.006282
2017/08/29 20:58:16 step 1: objective=22.529496 reg=0.006282
2017/08/29 20:58:17 step 2: objective=22.549818 reg=0.006281
2017/08/29 20:58:17 step 3: objective=22.571762 reg=0.006279
2017/08/29 20:58:18 step 4: objective=22.590595 reg=0.006279
2017/08/29 20:58:19 step 5: objective=22.606698 reg=0.006278
2017/08/29 20:58:20 step 6: objective=22.626176 reg=0.006277
2017/08/29 20:58:20 step 7: objective=22.645587 reg=0.006275
2017/08/29 20:58:20 Training value function...
2017/08/29 20:58:22 step 0: mse=15718.759531 step=0.050000
2017/08/29 20:58:23 step 1: mse=15655.976602 step=0.050000
2017/08/29 20:58:24 step 2: mse=15599.244523 step=0.050000
2017/08/29 20:58:24 step 3: mse=15550.478047 step=0.050000
2017/08/29 20:58:25 step 4: mse=15502.477278 step=0.050000
2017/08/29 20:58:26 step 5: mse=15460.078560 step=0.050000
2017/08/29 20:58:27 step 6: mse=15418.050181 step=0.050000
2017/08/29 20:58:27 step 7: mse=15381.966077 step=0.050000
2017/08/29 20:58:27 Saving...
2017/08/29 20:58:27 Gathering batch of experience...
2017/08/29 20:58:50 batch 108: mean=853.359375 stddev=432.812437 entropy=0.620789 frames=4710 count=64
2017/08/29 20:58:50 Training policy...
2017/08/29 20:58:52 tune 0: objective=24.287699 reg=0.006208 prune=0
2017/08/29 20:58:53 step 0: objective=24.304842 reg=0.006205
2017/08/29 20:58:54 step 1: objective=24.327627 reg=0.006203
2017/08/29 20:58:54 step 2: objective=24.344787 reg=0.006202
2017/08/29 20:58:55 step 3: objective=24.366650 reg=0.006200
2017/08/29 20:58:56 step 4: objective=24.389849 reg=0.006198
2017/08/29 20:58:57 step 5: objective=24.409664 reg=0.006197
2017/08/29 20:58:57 step 6: objective=24.436362 reg=0.006194
2017/08/29 20:58:58 step 7: objective=24.460301 reg=0.006192
2017/08/29 20:58:58 Training value function...
2017/08/29 20:59:00 step 0: mse=15513.146427 step=0.050000
2017/08/29 20:59:01 step 1: mse=15447.056567 step=0.050000
2017/08/29 20:59:01 step 2: mse=15383.610512 step=0.050000
2017/08/29 20:59:02 step 3: mse=15327.313305 step=0.050000
2017/08/29 20:59:03 step 4: mse=15271.801581 step=0.050000
2017/08/29 20:59:03 step 5: mse=15214.919951 step=0.050000
2017/08/29 20:59:04 step 6: mse=15163.923354 step=0.050000
2017/08/29 20:59:05 step 7: mse=15115.087421 step=0.050000
2017/08/29 20:59:05 Saving...
2017/08/29 20:59:05 Gathering batch of experience...
2017/08/29 20:59:28 batch 109: mean=858.923077 stddev=426.697959 entropy=0.618658 frames=4772 count=65
2017/08/29 20:59:28 Training policy...
2017/08/29 20:59:30 tune 0: objective=24.026995 reg=0.006187 prune=0
2017/08/29 20:59:31 step 0: objective=24.038265 reg=0.006185
2017/08/29 20:59:32 step 1: objective=24.057363 reg=0.006184
2017/08/29 20:59:33 step 2: objective=24.071295 reg=0.006183
2017/08/29 20:59:33 step 3: objective=24.091733 reg=0.006181
2017/08/29 20:59:34 step 4: objective=24.110596 reg=0.006180
2017/08/29 20:59:35 step 5: objective=24.128392 reg=0.006178
2017/08/29 20:59:35 step 6: objective=24.142531 reg=0.006177
2017/08/29 20:59:36 step 7: objective=24.164331 reg=0.006176
2017/08/29 20:59:36 Training value function...
2017/08/29 20:59:38 step 0: mse=15225.912350 step=0.050000
2017/08/29 20:59:39 step 1: mse=15168.760129 step=0.050000
2017/08/29 20:59:40 step 2: mse=15116.573840 step=0.050000
2017/08/29 20:59:40 step 3: mse=15064.308078 step=0.050000
2017/08/29 20:59:41 step 4: mse=15016.186000 step=0.050000
2017/08/29 20:59:42 step 5: mse=14967.799189 step=0.050000
2017/08/29 20:59:43 step 6: mse=14929.139618 step=0.050000
2017/08/29 20:59:43 step 7: mse=14887.966217 step=0.050000
2017/08/29 20:59:43 Saving...
2017/08/29 20:59:43 Gathering batch of experience...
2017/08/29 21:00:06 batch 110: mean=782.058824 stddev=422.680726 entropy=0.622273 frames=4627 count=68
2017/08/29 21:00:06 Training policy...
2017/08/29 21:00:08 tune 0: objective=17.347358 reg=0.006223 prune=0
2017/08/29 21:00:09 step 0: objective=17.354688 reg=0.006222
2017/08/29 21:00:10 step 1: objective=17.368064 reg=0.006222
2017/08/29 21:00:10 step 2: objective=17.382014 reg=0.006222
2017/08/29 21:00:11 step 3: objective=17.395110 reg=0.006221
2017/08/29 21:00:12 step 4: objective=17.410046 reg=0.006221
2017/08/29 21:00:12 step 5: objective=17.423148 reg=0.006221
2017/08/29 21:00:13 step 6: objective=17.433721 reg=0.006220
2017/08/29 21:00:14 step 7: objective=17.448806 reg=0.006220
2017/08/29 21:00:14 Training value function...
2017/08/29 21:00:16 step 0: mse=13719.230862 step=0.050000
2017/08/29 21:00:16 step 1: mse=13715.594829 step=0.050000
2017/08/29 21:00:17 step 2: mse=13710.811081 step=0.050000
2017/08/29 21:00:18 step 3: mse=13709.882964 step=0.050000
2017/08/29 21:00:19 step 4: mse=13710.050003 step=0.050000
2017/08/29 21:00:19 step 5: mse=13708.237008 step=0.050000
2017/08/29 21:00:20 step 6: mse=13710.715006 step=0.050000
2017/08/29 21:00:21 step 7: mse=13709.172277 step=0.050000
2017/08/29 21:00:21 Saving...
2017/08/29 21:00:21 Gathering batch of experience...
2017/08/29 21:00:43 batch 111: mean=830.461538 stddev=449.711637 entropy=0.619745 frames=4640 count=65
2017/08/29 21:00:43 Training policy...
2017/08/29 21:00:46 tune 0: objective=22.618508 reg=0.006197 prune=0
2017/08/29 21:00:46 step 0: objective=22.628928 reg=0.006195
2017/08/29 21:00:47 step 1: objective=22.646693 reg=0.006194
2017/08/29 21:00:48 step 2: objective=22.661281 reg=0.006192
2017/08/29 21:00:48 step 3: objective=22.681498 reg=0.006190
2017/08/29 21:00:49 step 4: objective=22.697197 reg=0.006189
2017/08/29 21:00:50 step 5: objective=22.711172 reg=0.006188
2017/08/29 21:00:51 step 6: objective=22.725445 reg=0.006187
2017/08/29 21:00:51 step 7: objective=22.738783 reg=0.006185
2017/08/29 21:00:51 Training value function...
2017/08/29 21:00:53 step 0: mse=14983.307480 step=0.050000
2017/08/29 21:00:54 step 1: mse=14938.682194 step=0.050000
2017/08/29 21:00:55 step 2: mse=14895.967560 step=0.050000
2017/08/29 21:00:55 step 3: mse=14856.574149 step=0.050000
2017/08/29 21:00:56 step 4: mse=14819.583602 step=0.050000
2017/08/29 21:00:57 step 5: mse=14782.193042 step=0.050000
2017/08/29 21:00:57 step 6: mse=14753.735946 step=0.050000
2017/08/29 21:00:58 step 7: mse=14721.617561 step=0.050000
2017/08/29 21:00:58 Saving...
2017/08/29 21:00:58 Gathering batch of experience...
2017/08/29 21:01:20 batch 112: mean=781.567164 stddev=449.663397 entropy=0.621588 frames=4620 count=67
2017/08/29 21:01:20 Training policy...
2017/08/29 21:01:23 tune 0: objective=16.969396 reg=0.006216 prune=0
2017/08/29 21:01:23 step 0: objective=16.976764 reg=0.006214
2017/08/29 21:01:24 step 1: objective=16.993735 reg=0.006214
2017/08/29 21:01:25 step 2: objective=17.006962 reg=0.006213
2017/08/29 21:01:26 step 3: objective=17.024523 reg=0.006212
2017/08/29 21:01:26 step 4: objective=17.035352 reg=0.006211
2017/08/29 21:01:27 step 5: objective=17.047771 reg=0.006210
2017/08/29 21:01:28 step 6: objective=17.062848 reg=0.006209
2017/08/29 21:01:28 step 7: objective=17.078440 reg=0.006208
2017/08/29 21:01:28 Training value function...
2017/08/29 21:01:30 step 0: mse=14093.388206 step=0.050000
2017/08/29 21:01:31 step 1: mse=14093.533226 step=0.050000
2017/08/29 21:01:32 step 2: mse=14093.034672 step=0.050000
2017/08/29 21:01:32 step 3: mse=14101.071296 step=0.050000
2017/08/29 21:01:33 step 4: mse=14109.880356 step=0.050000
2017/08/29 21:01:34 step 5: mse=14119.249612 step=0.050000
2017/08/29 21:01:34 step 6: mse=14121.618633 step=0.050000
2017/08/29 21:01:35 step 7: mse=14121.328533 step=0.050000
2017/08/29 21:01:35 Saving...
2017/08/29 21:01:35 Gathering batch of experience...
2017/08/29 21:01:58 batch 113: mean=779.029851 stddev=421.485680 entropy=0.618556 frames=4612 count=67
2017/08/29 21:01:58 Training policy...
2017/08/29 21:02:00 tune 0: objective=16.737951 reg=0.006186 prune=0
2017/08/29 21:02:01 step 0: objective=16.745311 reg=0.006184
2017/08/29 21:02:02 step 1: objective=16.761089 reg=0.006183
2017/08/29 21:02:02 step 2: objective=16.772829 reg=0.006183
2017/08/29 21:02:03 step 3: objective=16.784828 reg=0.006182
2017/08/29 21:02:04 step 4: objective=16.801760 reg=0.006181
2017/08/29 21:02:04 step 5: objective=16.815300 reg=0.006180
2017/08/29 21:02:05 step 6: objective=16.829233 reg=0.006179
2017/08/29 21:02:06 step 7: objective=16.844461 reg=0.006178
2017/08/29 21:02:06 Training value function...
2017/08/29 21:02:08 step 0: mse=14225.395929 step=0.050000
2017/08/29 21:02:08 step 1: mse=14234.063054 step=0.050000
2017/08/29 21:02:09 step 2: mse=14244.629199 step=0.050000
2017/08/29 21:02:10 step 3: mse=14250.529862 step=0.050000
2017/08/29 21:02:10 step 4: mse=14255.824013 step=0.050000
2017/08/29 21:02:11 step 5: mse=14266.064312 step=0.050000
2017/08/29 21:02:12 step 6: mse=14273.206496 step=0.050000
2017/08/29 21:02:13 step 7: mse=14286.700601 step=0.050000
2017/08/29 21:02:13 Saving...
2017/08/29 21:02:13 Gathering batch of experience...
2017/08/29 21:02:36 batch 114: mean=810.434783 stddev=477.308835 entropy=0.619210 frames=4806 count=69
2017/08/29 21:02:36 Training policy...
2017/08/29 21:02:38 tune 0: objective=24.650047 reg=0.006192 prune=0
2017/08/29 21:02:39 step 0: objective=24.656938 reg=0.006191
2017/08/29 21:02:40 step 1: objective=24.669289 reg=0.006192
2017/08/29 21:02:41 step 2: objective=24.685694 reg=0.006191
2017/08/29 21:02:41 step 3: objective=24.696849 reg=0.006191
2017/08/29 21:02:42 step 4: objective=24.715935 reg=0.006191
2017/08/29 21:02:43 step 5: objective=24.728440 reg=0.006191
2017/08/29 21:02:44 step 6: objective=24.739652 reg=0.006190
2017/08/29 21:02:44 step 7: objective=24.753612 reg=0.006190
2017/08/29 21:02:44 Training value function...
2017/08/29 21:02:46 step 0: mse=16380.054002 step=0.050000
2017/08/29 21:02:47 step 1: mse=16261.820969 step=0.050000
2017/08/29 21:02:48 step 2: mse=16142.631947 step=0.050000
2017/08/29 21:02:48 step 3: mse=16042.217323 step=0.050000
2017/08/29 21:02:49 step 4: mse=15943.498359 step=0.050000
2017/08/29 21:02:50 step 5: mse=15857.449800 step=0.050000
2017/08/29 21:02:51 step 6: mse=15776.197976 step=0.050000
2017/08/29 21:02:51 step 7: mse=15696.295119 step=0.050000
2017/08/29 21:02:51 Saving...
2017/08/29 21:02:51 Gathering batch of experience...
2017/08/29 21:03:15 batch 115: mean=867.230769 stddev=466.392894 entropy=0.616361 frames=4841 count=65
2017/08/29 21:03:15 Training policy...
2017/08/29 21:03:17 tune 0: objective=24.658143 reg=0.006164 prune=0
2017/08/29 21:03:18 step 0: objective=24.669763 reg=0.006161
2017/08/29 21:03:19 step 1: objective=24.691417 reg=0.006161
2017/08/29 21:03:20 step 2: objective=24.708948 reg=0.006159
2017/08/29 21:03:20 step 3: objective=24.726729 reg=0.006159
2017/08/29 21:03:21 step 4: objective=24.745744 reg=0.006157
2017/08/29 21:03:22 step 5: objective=24.766095 reg=0.006156
2017/08/29 21:03:23 step 6: objective=24.789282 reg=0.006155
2017/08/29 21:03:23 step 7: objective=24.805156 reg=0.006154
2017/08/29 21:03:23 Training value function...
2017/08/29 21:03:25 step 0: mse=15932.388530 step=0.050000
2017/08/29 21:03:26 step 1: mse=15857.414843 step=0.050000
2017/08/29 21:03:27 step 2: mse=15776.755963 step=0.050000
2017/08/29 21:03:27 step 3: mse=15681.565576 step=0.050000
2017/08/29 21:03:28 step 4: mse=15614.646222 step=0.050000
2017/08/29 21:03:29 step 5: mse=15552.906516 step=0.050000
2017/08/29 21:03:30 step 6: mse=15496.759273 step=0.050000
2017/08/29 21:03:30 step 7: mse=15446.055587 step=0.050000
2017/08/29 21:03:30 Saving...
2017/08/29 21:03:30 Gathering batch of experience...
2017/08/29 21:03:53 batch 116: mean=797.348485 stddev=432.286223 entropy=0.615461 frames=4572 count=66
2017/08/29 21:03:53 Training policy...
2017/08/29 21:03:55 tune 0: objective=17.693257 reg=0.006155 prune=0
2017/08/29 21:03:56 step 0: objective=17.705604 reg=0.006153
2017/08/29 21:03:56 step 1: objective=17.727270 reg=0.006152
2017/08/29 21:03:57 step 2: objective=17.747965 reg=0.006151
2017/08/29 21:03:58 step 3: objective=17.774762 reg=0.006151
2017/08/29 21:03:58 step 4: objective=17.801359 reg=0.006149
2017/08/29 21:03:59 step 5: objective=17.820376 reg=0.006149
2017/08/29 21:04:00 step 6: objective=17.842450 reg=0.006148
2017/08/29 21:04:01 step 7: objective=17.868795 reg=0.006147
2017/08/29 21:04:01 Training value function...
2017/08/29 21:04:02 step 0: mse=14396.780411 step=0.050000
2017/08/29 21:04:03 step 1: mse=14408.050882 step=0.050000
2017/08/29 21:04:04 step 2: mse=14414.582282 step=0.050000
2017/08/29 21:04:04 step 3: mse=14424.548591 step=0.050000
2017/08/29 21:04:05 step 4: mse=14430.893051 step=0.050000
2017/08/29 21:04:06 step 5: mse=14439.765125 step=0.050000
2017/08/29 21:04:07 step 6: mse=14444.606721 step=0.050000
2017/08/29 21:04:07 step 7: mse=14453.087220 step=0.050000
2017/08/29 21:04:07 Saving...
2017/08/29 21:04:07 Gathering batch of experience...
2017/08/29 21:04:30 batch 117: mean=796.590909 stddev=437.598611 entropy=0.614560 frames=4554 count=66
2017/08/29 21:04:30 Training policy...
2017/08/29 21:04:32 tune 0: objective=18.943058 reg=0.006146 prune=0
2017/08/29 21:04:33 step 0: objective=18.951013 reg=0.006144
2017/08/29 21:04:33 step 1: objective=18.964993 reg=0.006144
2017/08/29 21:04:34 step 2: objective=18.976369 reg=0.006143
2017/08/29 21:04:35 step 3: objective=18.989472 reg=0.006142
2017/08/29 21:04:36 step 4: objective=19.005454 reg=0.006141
2017/08/29 21:04:36 step 5: objective=19.024167 reg=0.006141
2017/08/29 21:04:37 step 6: objective=19.039188 reg=0.006141
2017/08/29 21:04:38 step 7: objective=19.061568 reg=0.006140
2017/08/29 21:04:38 Training value function...
2017/08/29 21:04:39 step 0: mse=14271.735301 step=0.050000
2017/08/29 21:04:40 step 1: mse=14252.687998 step=0.050000
2017/08/29 21:04:41 step 2: mse=14249.945583 step=0.050000
2017/08/29 21:04:42 step 3: mse=14229.441065 step=0.050000
2017/08/29 21:04:42 step 4: mse=14218.077065 step=0.050000
2017/08/29 21:04:43 step 5: mse=14216.744726 step=0.050000
2017/08/29 21:04:44 step 6: mse=14212.326907 step=0.050000
2017/08/29 21:04:44 step 7: mse=14212.915809 step=0.050000
2017/08/29 21:04:44 Saving...
2017/08/29 21:04:44 Gathering batch of experience...
2017/08/29 21:05:06 batch 118: mean=850.317460 stddev=469.366233 entropy=0.615185 frames=4616 count=63
2017/08/29 21:05:06 Training policy...
2017/08/29 21:05:09 tune 0: objective=24.403738 reg=0.006152 prune=0
2017/08/29 21:05:10 step 0: objective=24.413040 reg=0.006152
2017/08/29 21:05:10 step 1: objective=24.426936 reg=0.006152
2017/08/29 21:05:11 step 2: objective=24.442408 reg=0.006152
2017/08/29 21:05:12 step 3: objective=24.461389 reg=0.006152
2017/08/29 21:05:12 step 4: objective=24.480227 reg=0.006152
2017/08/29 21:05:13 step 5: objective=24.499206 reg=0.006152
2017/08/29 21:05:14 step 6: objective=24.515921 reg=0.006152
2017/08/29 21:05:15 step 7: objective=24.533283 reg=0.006153
2017/08/29 21:05:15 Training value function...
2017/08/29 21:05:16 step 0: mse=15206.890029 step=0.050000
2017/08/29 21:05:17 step 1: mse=15136.104202 step=0.050000
2017/08/29 21:05:18 step 2: mse=15068.860861 step=0.050000
2017/08/29 21:05:19 step 3: mse=15007.522936 step=0.050000
2017/08/29 21:05:19 step 4: mse=14948.905814 step=0.050000
2017/08/29 21:05:20 step 5: mse=14892.987191 step=0.050000
2017/08/29 21:05:21 step 6: mse=14839.451756 step=0.050000
2017/08/29 21:05:21 step 7: mse=14789.553042 step=0.050000
2017/08/29 21:05:21 Saving...
2017/08/29 21:05:21 Gathering batch of experience...
2017/08/29 21:05:43 batch 119: mean=801.742424 stddev=419.573640 entropy=0.614481 frames=4615 count=66
2017/08/29 21:05:43 Training policy...
2017/08/29 21:05:46 tune 0: objective=17.267680 reg=0.006145 prune=0
2017/08/29 21:05:47 step 0: objective=17.279105 reg=0.006142
2017/08/29 21:05:47 step 1: objective=17.296872 reg=0.006141
2017/08/29 21:05:48 step 2: objective=17.319385 reg=0.006140
2017/08/29 21:05:49 step 3: objective=17.334478 reg=0.006138
2017/08/29 21:05:49 step 4: objective=17.354955 reg=0.006136
2017/08/29 21:05:50 step 5: objective=17.371623 reg=0.006135
2017/08/29 21:05:51 step 6: objective=17.392105 reg=0.006133
2017/08/29 21:05:52 step 7: objective=17.407877 reg=0.006132
2017/08/29 21:05:52 Training value function...
2017/08/29 21:05:53 step 0: mse=14193.717577 step=0.050000
2017/08/29 21:05:54 step 1: mse=14208.266370 step=0.050000
2017/08/29 21:05:55 step 2: mse=14223.671382 step=0.050000
2017/08/29 21:05:56 step 3: mse=14230.089170 step=0.050000
2017/08/29 21:05:56 step 4: mse=14234.829553 step=0.050000
2017/08/29 21:05:57 step 5: mse=14242.488103 step=0.050000
2017/08/29 21:05:58 step 6: mse=14254.437909 step=0.050000
2017/08/29 21:05:58 step 7: mse=14266.829996 step=0.050000
2017/08/29 21:05:58 Saving...
2017/08/29 21:05:58 Gathering batch of experience...
2017/08/29 21:06:21 batch 120: mean=859.140625 stddev=480.150981 entropy=0.614268 frames=4715 count=64
2017/08/29 21:06:21 Training policy...
2017/08/29 21:06:24 tune 0: objective=24.946443 reg=0.006143 prune=0
2017/08/29 21:06:24 step 0: objective=24.956911 reg=0.006141
2017/08/29 21:06:25 step 1: objective=24.977885 reg=0.006139
2017/08/29 21:06:26 step 2: objective=24.998046 reg=0.006137
2017/08/29 21:06:26 step 3: objective=25.019736 reg=0.006136
2017/08/29 21:06:27 step 4: objective=25.039454 reg=0.006135
2017/08/29 21:06:28 step 5: objective=25.064116 reg=0.006133
2017/08/29 21:06:29 step 6: objective=25.078312 reg=0.006132
2017/08/29 21:06:29 step 7: objective=25.094698 reg=0.006130
2017/08/29 21:06:29 Training value function...
2017/08/29 21:06:31 step 0: mse=16248.863719 step=0.050000
2017/08/29 21:06:32 step 1: mse=16115.015236 step=0.050000
2017/08/29 21:06:33 step 2: mse=15976.565654 step=0.050000
2017/08/29 21:06:33 step 3: mse=15865.331167 step=0.050000
2017/08/29 21:06:34 step 4: mse=15764.496647 step=0.050000
2017/08/29 21:06:35 step 5: mse=15667.493137 step=0.050000
2017/08/29 21:06:36 step 6: mse=15576.556057 step=0.050000
2017/08/29 21:06:36 step 7: mse=15508.404565 step=0.050000
2017/08/29 21:06:36 Saving...
2017/08/29 21:06:36 Gathering batch of experience...
2017/08/29 21:06:59 batch 121: mean=850.149254 stddev=481.425875 entropy=0.613645 frames=4890 count=67
2017/08/29 21:06:59 Training policy...
2017/08/29 21:07:02 tune 0: objective=23.649510 reg=0.006136 prune=0
2017/08/29 21:07:03 step 0: objective=23.656945 reg=0.006135
2017/08/29 21:07:04 step 1: objective=23.676545 reg=0.006134
2017/08/29 21:07:04 step 2: objective=23.689333 reg=0.006133
2017/08/29 21:07:05 step 3: objective=23.699543 reg=0.006133
2017/08/29 21:07:06 step 4: objective=23.714579 reg=0.006132
2017/08/29 21:07:07 step 5: objective=23.725689 reg=0.006132
2017/08/29 21:07:07 step 6: objective=23.745667 reg=0.006131
2017/08/29 21:07:08 step 7: objective=23.761572 reg=0.006130
2017/08/29 21:07:08 Training value function...
2017/08/29 21:07:10 step 0: mse=15443.439068 step=0.050000
2017/08/29 21:07:11 step 1: mse=15375.651640 step=0.050000
2017/08/29 21:07:12 step 2: mse=15308.497148 step=0.050000
2017/08/29 21:07:12 step 3: mse=15244.686122 step=0.050000
2017/08/29 21:07:13 step 4: mse=15185.629536 step=0.050000
2017/08/29 21:07:14 step 5: mse=15129.089570 step=0.050000
2017/08/29 21:07:15 step 6: mse=15075.574541 step=0.050000
2017/08/29 21:07:15 step 7: mse=15026.519325 step=0.050000
2017/08/29 21:07:15 Saving...
2017/08/29 21:07:15 Gathering batch of experience...
2017/08/29 21:07:38 batch 122: mean=735.000000 stddev=467.402924 entropy=0.619381 frames=4610 count=71
2017/08/29 21:07:38 Training policy...
2017/08/29 21:07:41 tune 0: objective=12.131082 reg=0.006194 prune=0
2017/08/29 21:07:41 step 0: objective=12.148039 reg=0.006193
2017/08/29 21:07:42 step 1: objective=12.176077 reg=0.006193
2017/08/29 21:07:43 step 2: objective=12.212857 reg=0.006193
2017/08/29 21:07:43 step 3: objective=12.244580 reg=0.006192
2017/08/29 21:07:44 step 4: objective=12.280781 reg=0.006191
2017/08/29 21:07:45 step 5: objective=12.317239 reg=0.006191
2017/08/29 21:07:46 step 6: objective=12.353463 reg=0.006189
2017/08/29 21:07:46 step 7: objective=12.378946 reg=0.006189
2017/08/29 21:07:46 Training value function...
2017/08/29 21:07:48 step 0: mse=15549.120428 step=0.050000
2017/08/29 21:07:49 step 1: mse=15528.069586 step=0.050000
2017/08/29 21:07:49 step 2: mse=15506.627221 step=0.050000
2017/08/29 21:07:50 step 3: mse=15489.711966 step=0.050000
2017/08/29 21:07:51 step 4: mse=15486.337813 step=0.050000
2017/08/29 21:07:52 step 5: mse=15485.713065 step=0.050000
2017/08/29 21:07:52 step 6: mse=15482.395866 step=0.050000
2017/08/29 21:07:53 step 7: mse=15481.620893 step=0.050000
2017/08/29 21:07:53 Saving...
2017/08/29 21:07:53 Gathering batch of experience...
2017/08/29 21:08:16 batch 123: mean=934.672131 stddev=502.173855 entropy=0.610004 frames=4820 count=61
2017/08/29 21:08:16 Training policy...
2017/08/29 21:08:18 tune 0: objective=29.775759 reg=0.006100 prune=0
2017/08/29 21:08:19 step 0: objective=29.781704 reg=0.006099
2017/08/29 21:08:20 step 1: objective=29.795831 reg=0.006099
2017/08/29 21:08:20 step 2: objective=29.811492 reg=0.006099
2017/08/29 21:08:21 step 3: objective=29.821927 reg=0.006099
2017/08/29 21:08:22 step 4: objective=29.832145 reg=0.006098
2017/08/29 21:08:23 step 5: objective=29.846172 reg=0.006098
2017/08/29 21:08:23 step 6: objective=29.861061 reg=0.006097
2017/08/29 21:08:24 step 7: objective=29.874413 reg=0.006097
2017/08/29 21:08:24 Training value function...
2017/08/29 21:08:26 step 0: mse=17175.913390 step=0.050000
2017/08/29 21:08:27 step 1: mse=17007.445798 step=0.050000
2017/08/29 21:08:27 step 2: mse=16854.737757 step=0.050000
2017/08/29 21:08:28 step 3: mse=16703.755901 step=0.050000
2017/08/29 21:08:29 step 4: mse=16572.721133 step=0.050000
2017/08/29 21:08:30 step 5: mse=16456.482277 step=0.050000
2017/08/29 21:08:30 step 6: mse=16343.305320 step=0.050000
2017/08/29 21:08:31 step 7: mse=16238.038898 step=0.050000
2017/08/29 21:08:31 Saving...
2017/08/29 21:08:31 Gathering batch of experience...
2017/08/29 21:08:54 batch 124: mean=805.671642 stddev=500.598817 entropy=0.616315 frames=4662 count=67
2017/08/29 21:08:54 Training policy...
2017/08/29 21:08:57 tune 0: objective=18.487510 reg=0.006163 prune=0
2017/08/29 21:08:57 step 0: objective=18.497057 reg=0.006161
2017/08/29 21:08:58 step 1: objective=18.525861 reg=0.006160
2017/08/29 21:08:59 step 2: objective=18.547011 reg=0.006159
2017/08/29 21:08:59 step 3: objective=18.574597 reg=0.006157
2017/08/29 21:09:00 step 4: objective=18.603696 reg=0.006156
2017/08/29 21:09:01 step 5: objective=18.629262 reg=0.006155
2017/08/29 21:09:02 step 6: objective=18.654603 reg=0.006153
2017/08/29 21:09:02 step 7: objective=18.677656 reg=0.006151
2017/08/29 21:09:02 Training value function...
2017/08/29 21:09:04 step 0: mse=15687.675746 step=0.050000
2017/08/29 21:09:05 step 1: mse=15674.940685 step=0.050000
2017/08/29 21:09:06 step 2: mse=15658.528098 step=0.050000
2017/08/29 21:09:06 step 3: mse=15645.604505 step=0.050000
2017/08/29 21:09:07 step 4: mse=15632.078266 step=0.050000
2017/08/29 21:09:08 step 5: mse=15621.055731 step=0.050000
2017/08/29 21:09:09 step 6: mse=15612.487729 step=0.050000
2017/08/29 21:09:09 step 7: mse=15603.779884 step=0.050000
2017/08/29 21:09:09 Saving...
2017/08/29 21:09:09 Gathering batch of experience...
2017/08/29 21:09:32 batch 125: mean=847.230769 stddev=485.133630 entropy=0.611251 frames=4808 count=65
2017/08/29 21:09:32 Training policy...
2017/08/29 21:09:35 tune 0: objective=19.419982 reg=0.006113 prune=0
2017/08/29 21:09:36 step 0: objective=19.427863 reg=0.006111
2017/08/29 21:09:36 step 1: objective=19.445730 reg=0.006110
2017/08/29 21:09:37 step 2: objective=19.461053 reg=0.006110
2017/08/29 21:09:38 step 3: objective=19.477723 reg=0.006110
2017/08/29 21:09:39 step 4: objective=19.493876 reg=0.006109
2017/08/29 21:09:39 step 5: objective=19.514699 reg=0.006108
2017/08/29 21:09:40 step 6: objective=19.542389 reg=0.006107
2017/08/29 21:09:41 step 7: objective=19.562232 reg=0.006105
2017/08/29 21:09:41 Training value function...
2017/08/29 21:09:43 step 0: mse=15300.721029 step=0.050000
2017/08/29 21:09:44 step 1: mse=15292.067575 step=0.050000
2017/08/29 21:09:44 step 2: mse=15283.841557 step=0.050000
2017/08/29 21:09:45 step 3: mse=15276.806901 step=0.050000
2017/08/29 21:09:46 step 4: mse=15272.012257 step=0.050000
2017/08/29 21:09:47 step 5: mse=15262.723264 step=0.050000
2017/08/29 21:09:47 step 6: mse=15254.548984 step=0.050000
2017/08/29 21:09:48 step 7: mse=15250.123771 step=0.050000
2017/08/29 21:09:48 Saving...
2017/08/29 21:09:48 Gathering batch of experience...
2017/08/29 21:10:11 batch 126: mean=766.142857 stddev=408.750860 entropy=0.609444 frames=4727 count=70
2017/08/29 21:10:11 Training policy...
2017/08/29 21:10:13 tune 0: objective=13.184495 reg=0.006094 prune=0
2017/08/29 21:10:14 step 0: objective=13.192083 reg=0.006093
2017/08/29 21:10:15 step 1: objective=13.211783 reg=0.006093
2017/08/29 21:10:16 step 2: objective=13.227486 reg=0.006093
2017/08/29 21:10:16 step 3: objective=13.248896 reg=0.006092
2017/08/29 21:10:17 step 4: objective=13.269462 reg=0.006091
2017/08/29 21:10:18 step 5: objective=13.287531 reg=0.006090
2017/08/29 21:10:18 step 6: objective=13.297160 reg=0.006090
2017/08/29 21:10:19 step 7: objective=13.313930 reg=0.006090
2017/08/29 21:10:19 Training value function...
2017/08/29 21:10:21 step 0: mse=13509.763015 step=0.050000
2017/08/29 21:10:22 step 1: mse=13514.819493 step=0.050000
2017/08/29 21:10:23 step 2: mse=13523.756404 step=0.050000
2017/08/29 21:10:23 step 3: mse=13536.242479 step=0.050000
2017/08/29 21:10:24 step 4: mse=13549.050273 step=0.050000
2017/08/29 21:10:25 step 5: mse=13559.499217 step=0.050000
2017/08/29 21:10:25 step 6: mse=13570.701595 step=0.050000
2017/08/29 21:10:26 step 7: mse=13581.846376 step=0.050000
2017/08/29 21:10:26 Saving...
2017/08/29 21:10:26 Gathering batch of experience...
2017/08/29 21:10:49 batch 127: mean=843.863636 stddev=469.273936 entropy=0.608388 frames=4755 count=66
2017/08/29 21:10:49 Training policy...
2017/08/29 21:10:51 tune 0: objective=24.675785 reg=0.006084 prune=0
2017/08/29 21:10:52 step 0: objective=24.681868 reg=0.006083
2017/08/29 21:10:53 step 1: objective=24.702032 reg=0.006084
2017/08/29 21:10:54 step 2: objective=24.717455 reg=0.006084
2017/08/29 21:10:54 step 3: objective=24.732234 reg=0.006083
2017/08/29 21:10:55 step 4: objective=24.744430 reg=0.006083
2017/08/29 21:10:56 step 5: objective=24.760873 reg=0.006083
2017/08/29 21:10:57 step 6: objective=24.782559 reg=0.006083
2017/08/29 21:10:57 step 7: objective=24.800429 reg=0.006084
2017/08/29 21:10:57 Training value function...
2017/08/29 21:10:59 step 0: mse=15549.113067 step=0.050000
2017/08/29 21:11:00 step 1: mse=15447.150463 step=0.050000
2017/08/29 21:11:01 step 2: mse=15347.919279 step=0.050000
2017/08/29 21:11:01 step 3: mse=15263.022321 step=0.050000
2017/08/29 21:11:02 step 4: mse=15164.750715 step=0.050000
2017/08/29 21:11:03 step 5: mse=15093.953393 step=0.050000
2017/08/29 21:11:04 step 6: mse=15020.277685 step=0.050000
2017/08/29 21:11:04 step 7: mse=14947.712203 step=0.050000
2017/08/29 21:11:04 Saving...
2017/08/29 21:11:04 Gathering batch of experience...
2017/08/29 21:11:26 batch 128: mean=906.500000 stddev=471.791179 entropy=0.604968 frames=4647 count=60
2017/08/29 21:11:26 Training policy...
2017/08/29 21:11:29 tune 0: objective=25.512261 reg=0.006050 prune=0
2017/08/29 21:11:29 step 0: objective=25.519625 reg=0.006049
2017/08/29 21:11:30 step 1: objective=25.531761 reg=0.006049
2017/08/29 21:11:31 step 2: objective=25.543032 reg=0.006048
2017/08/29 21:11:32 step 3: objective=25.560298 reg=0.006048
2017/08/29 21:11:32 step 4: objective=25.572135 reg=0.006046
2017/08/29 21:11:33 step 5: objective=25.586433 reg=0.006046
2017/08/29 21:11:34 step 6: objective=25.599364 reg=0.006046
2017/08/29 21:11:34 step 7: objective=25.614007 reg=0.006046
2017/08/29 21:11:34 Training value function...
2017/08/29 21:11:36 step 0: mse=16208.124361 step=0.050000
2017/08/29 21:11:37 step 1: mse=16129.396903 step=0.050000
2017/08/29 21:11:38 step 2: mse=16053.094877 step=0.050000
2017/08/29 21:11:38 step 3: mse=15987.788584 step=0.050000
2017/08/29 21:11:39 step 4: mse=15927.159326 step=0.050000
2017/08/29 21:11:40 step 5: mse=15874.016418 step=0.050000
2017/08/29 21:11:41 step 6: mse=15820.491607 step=0.050000
2017/08/29 21:11:41 step 7: mse=15772.034897 step=0.050000
2017/08/29 21:11:41 Saving...
2017/08/29 21:11:41 Gathering batch of experience...
2017/08/29 21:12:04 batch 129: mean=892.786885 stddev=458.312590 entropy=0.604903 frames=4666 count=61
2017/08/29 21:12:04 Training policy...
2017/08/29 21:12:06 tune 0: objective=22.000509 reg=0.006049 prune=0
2017/08/29 21:12:07 step 0: objective=22.009418 reg=0.006047
2017/08/29 21:12:08 step 1: objective=22.031145 reg=0.006046
2017/08/29 21:12:08 step 2: objective=22.052132 reg=0.006045
2017/08/29 21:12:09 step 3: objective=22.078286 reg=0.006043
2017/08/29 21:12:10 step 4: objective=22.100538 reg=0.006042
2017/08/29 21:12:11 step 5: objective=22.125306 reg=0.006041
2017/08/29 21:12:11 step 6: objective=22.137496 reg=0.006041
2017/08/29 21:12:12 step 7: objective=22.162040 reg=0.006039
2017/08/29 21:12:12 Training value function...
2017/08/29 21:12:14 step 0: mse=16283.029490 step=0.050000
2017/08/29 21:12:15 step 1: mse=16252.511826 step=0.050000
2017/08/29 21:12:15 step 2: mse=16223.008269 step=0.050000
2017/08/29 21:12:16 step 3: mse=16193.536117 step=0.050000
2017/08/29 21:12:17 step 4: mse=16158.512792 step=0.050000
2017/08/29 21:12:18 step 5: mse=16135.216932 step=0.050000
2017/08/29 21:12:18 step 6: mse=16111.615604 step=0.050000
2017/08/29 21:12:19 step 7: mse=16088.688855 step=0.050000
2017/08/29 21:12:19 Saving...
2017/08/29 21:12:19 Gathering batch of experience...
2017/08/29 21:12:41 batch 130: mean=993.421053 stddev=535.202174 entropy=0.607045 frames=4757 count=57
2017/08/29 21:12:41 Training policy...
2017/08/29 21:12:44 tune 0: objective=30.346923 reg=0.006070 prune=0
2017/08/29 21:12:44 step 0: objective=30.354583 reg=0.006069
2017/08/29 21:12:45 step 1: objective=30.369107 reg=0.006069
2017/08/29 21:12:46 step 2: objective=30.383740 reg=0.006068
2017/08/29 21:12:47 step 3: objective=30.399119 reg=0.006067
2017/08/29 21:12:47 step 4: objective=30.413683 reg=0.006066
2017/08/29 21:12:48 step 5: objective=30.434327 reg=0.006066
2017/08/29 21:12:49 step 6: objective=30.458479 reg=0.006064
2017/08/29 21:12:49 step 7: objective=30.472199 reg=0.006063
2017/08/29 21:12:49 Training value function...
2017/08/29 21:12:51 step 0: mse=18768.523201 step=0.050000
2017/08/29 21:12:52 step 1: mse=18579.953465 step=0.050000
2017/08/29 21:12:53 step 2: mse=18404.927998 step=0.050000
2017/08/29 21:12:54 step 3: mse=18241.927427 step=0.050000
2017/08/29 21:12:54 step 4: mse=18092.534750 step=0.050000
2017/08/29 21:12:55 step 5: mse=17954.346482 step=0.050000
2017/08/29 21:12:56 step 6: mse=17829.518915 step=0.050000
2017/08/29 21:12:56 step 7: mse=17712.398151 step=0.050000
2017/08/29 21:12:56 Saving...
2017/08/29 21:12:57 Gathering batch of experience...
2017/08/29 21:13:19 batch 131: mean=866.250000 stddev=460.179143 entropy=0.604465 frames=4789 count=64
2017/08/29 21:13:19 Training policy...
2017/08/29 21:13:22 tune 0: objective=16.279677 reg=0.006045 prune=0
2017/08/29 21:13:23 step 0: objective=16.289152 reg=0.006043
2017/08/29 21:13:23 step 1: objective=16.313595 reg=0.006042
2017/08/29 21:13:24 step 2: objective=16.330078 reg=0.006041
2017/08/29 21:13:25 step 3: objective=16.347972 reg=0.006040
2017/08/29 21:13:25 step 4: objective=16.369966 reg=0.006039
2017/08/29 21:13:26 step 5: objective=16.392263 reg=0.006038
2017/08/29 21:13:27 step 6: objective=16.411536 reg=0.006037
2017/08/29 21:13:28 step 7: objective=16.429612 reg=0.006037
2017/08/29 21:13:28 Training value function...
2017/08/29 21:13:30 step 0: mse=14748.706737 step=0.050000
2017/08/29 21:13:30 step 1: mse=14740.465769 step=0.050000
2017/08/29 21:13:31 step 2: mse=14734.741176 step=0.050000
2017/08/29 21:13:32 step 3: mse=14727.459237 step=0.050000
2017/08/29 21:13:33 step 4: mse=14721.998885 step=0.050000
2017/08/29 21:13:33 step 5: mse=14723.950274 step=0.050000
2017/08/29 21:13:34 step 6: mse=14722.948118 step=0.050000
2017/08/29 21:13:35 step 7: mse=14726.620554 step=0.050000
2017/08/29 21:13:35 Saving...
2017/08/29 21:13:35 Gathering batch of experience...
2017/08/29 21:13:57 batch 132: mean=838.333333 stddev=463.722858 entropy=0.605333 frames=4562 count=63
2017/08/29 21:13:57 Training policy...
2017/08/29 21:13:59 tune 0: objective=17.580449 reg=0.006053 prune=0
2017/08/29 21:14:00 step 0: objective=17.586337 reg=0.006053
2017/08/29 21:14:00 step 1: objective=17.601720 reg=0.006052
2017/08/29 21:14:01 step 2: objective=17.617009 reg=0.006052
2017/08/29 21:14:02 step 3: objective=17.630156 reg=0.006052
2017/08/29 21:14:03 step 4: objective=17.648300 reg=0.006052
2017/08/29 21:14:03 step 5: objective=17.661858 reg=0.006052
2017/08/29 21:14:04 step 6: objective=17.678686 reg=0.006051
2017/08/29 21:14:05 step 7: objective=17.694549 reg=0.006051
2017/08/29 21:14:05 Training value function...
2017/08/29 21:14:06 step 0: mse=14393.225018 step=0.050000
2017/08/29 21:14:07 step 1: mse=14389.224392 step=0.050000
2017/08/29 21:14:08 step 2: mse=14379.646464 step=0.050000
2017/08/29 21:14:09 step 3: mse=14367.240425 step=0.050000
2017/08/29 21:14:09 step 4: mse=14363.883440 step=0.050000
2017/08/29 21:14:10 step 5: mse=14361.583509 step=0.050000
2017/08/29 21:14:11 step 6: mse=14363.643069 step=0.050000
2017/08/29 21:14:11 step 7: mse=14361.701657 step=0.050000
2017/08/29 21:14:11 Saving...
2017/08/29 21:14:11 Gathering batch of experience...
2017/08/29 21:14:34 batch 133: mean=968.000000 stddev=463.860791 entropy=0.601654 frames=4915 count=60
2017/08/29 21:14:34 Training policy...
2017/08/29 21:14:37 tune 0: objective=27.206317 reg=0.006017 prune=0
2017/08/29 21:14:38 step 0: objective=27.213476 reg=0.006016
2017/08/29 21:14:38 step 1: objective=27.230385 reg=0.006015
2017/08/29 21:14:39 step 2: objective=27.249628 reg=0.006014
2017/08/29 21:14:40 step 3: objective=27.268009 reg=0.006013
2017/08/29 21:14:41 step 4: objective=27.288705 reg=0.006011
2017/08/29 21:14:41 step 5: objective=27.304069 reg=0.006011
2017/08/29 21:14:42 step 6: objective=27.320562 reg=0.006010
2017/08/29 21:14:43 step 7: objective=27.337840 reg=0.006009
2017/08/29 21:14:43 Training value function...
2017/08/29 21:14:45 step 0: mse=14913.099212 step=0.050000
2017/08/29 21:14:46 step 1: mse=14804.122153 step=0.050000
2017/08/29 21:14:47 step 2: mse=14703.470682 step=0.050000
2017/08/29 21:14:47 step 3: mse=14613.018875 step=0.050000
2017/08/29 21:14:48 step 4: mse=14529.573724 step=0.050000
2017/08/29 21:14:49 step 5: mse=14453.107188 step=0.050000
2017/08/29 21:14:50 step 6: mse=14381.570994 step=0.050000
2017/08/29 21:14:50 step 7: mse=14313.561985 step=0.050000
2017/08/29 21:14:50 Saving...
2017/08/29 21:14:50 Gathering batch of experience...
2017/08/29 21:15:13 batch 134: mean=908.951613 stddev=499.508740 entropy=0.603743 frames=4765 count=62
2017/08/29 21:15:13 Training policy...
2017/08/29 21:15:15 tune 0: objective=22.837928 reg=0.006037 prune=0
2017/08/29 21:15:16 step 0: objective=22.846870 reg=0.006036
2017/08/29 21:15:17 step 1: objective=22.865748 reg=0.006034
2017/08/29 21:15:18 step 2: objective=22.881770 reg=0.006032
2017/08/29 21:15:18 step 3: objective=22.897106 reg=0.006031
2017/08/29 21:15:19 step 4: objective=22.910977 reg=0.006031
2017/08/29 21:15:20 step 5: objective=22.932371 reg=0.006029
2017/08/29 21:15:20 step 6: objective=22.948554 reg=0.006028
2017/08/29 21:15:21 step 7: objective=22.969637 reg=0.006027
2017/08/29 21:15:21 Training value function...
2017/08/29 21:15:23 step 0: mse=14888.461736 step=0.050000
2017/08/29 21:15:24 step 1: mse=14819.287523 step=0.050000
2017/08/29 21:15:25 step 2: mse=14757.563862 step=0.050000
2017/08/29 21:15:25 step 3: mse=14701.628650 step=0.050000
2017/08/29 21:15:26 step 4: mse=14649.282377 step=0.050000
2017/08/29 21:15:27 step 5: mse=14604.881206 step=0.050000
2017/08/29 21:15:28 step 6: mse=14559.718608 step=0.050000
2017/08/29 21:15:28 step 7: mse=14516.597701 step=0.050000
2017/08/29 21:15:28 Saving...
2017/08/29 21:15:28 Gathering batch of experience...
2017/08/29 21:15:52 batch 135: mean=920.000000 stddev=500.088702 entropy=0.601318 frames=4798 count=62
2017/08/29 21:15:52 Training policy...
2017/08/29 21:15:54 tune 0: objective=22.152875 reg=0.006013 prune=0
2017/08/29 21:15:55 step 0: objective=22.161718 reg=0.006012
2017/08/29 21:15:56 step 1: objective=22.189379 reg=0.006012
2017/08/29 21:15:57 step 2: objective=22.219777 reg=0.006011
2017/08/29 21:15:57 step 3: objective=22.246465 reg=0.006010
2017/08/29 21:15:58 step 4: objective=22.272045 reg=0.006009
2017/08/29 21:15:59 step 5: objective=22.302255 reg=0.006009
2017/08/29 21:16:00 step 6: objective=22.327855 reg=0.006008
2017/08/29 21:16:00 step 7: objective=22.357574 reg=0.006007
2017/08/29 21:16:00 Training value function...
2017/08/29 21:16:02 step 0: mse=16243.915655 step=0.050000
2017/08/29 21:16:03 step 1: mse=16221.054038 step=0.050000
2017/08/29 21:16:04 step 2: mse=16196.856133 step=0.050000
2017/08/29 21:16:04 step 3: mse=16176.141533 step=0.050000
2017/08/29 21:16:05 step 4: mse=16146.796066 step=0.050000
2017/08/29 21:16:06 step 5: mse=16115.990918 step=0.050000
2017/08/29 21:16:07 step 6: mse=16096.891505 step=0.050000
2017/08/29 21:16:07 step 7: mse=16075.397081 step=0.050000
2017/08/29 21:16:07 Saving...
2017/08/29 21:16:07 Gathering batch of experience...
2017/08/29 21:16:31 batch 136: mean=817.898551 stddev=458.412830 entropy=0.602887 frames=4889 count=69
2017/08/29 21:16:31 Training policy...
2017/08/29 21:16:33 tune 0: objective=12.662678 reg=0.006029 prune=0
2017/08/29 21:16:34 step 0: objective=12.670100 reg=0.006028
2017/08/29 21:16:35 step 1: objective=12.685725 reg=0.006026
2017/08/29 21:16:36 step 2: objective=12.704181 reg=0.006025
2017/08/29 21:16:36 step 3: objective=12.721921 reg=0.006024
2017/08/29 21:16:37 step 4: objective=12.738261 reg=0.006023
2017/08/29 21:16:38 step 5: objective=12.758429 reg=0.006022
2017/08/29 21:16:39 step 6: objective=12.776212 reg=0.006022
2017/08/29 21:16:40 step 7: objective=12.795056 reg=0.006020
2017/08/29 21:16:40 Training value function...
2017/08/29 21:16:41 step 0: mse=14135.360670 step=0.050000
2017/08/29 21:16:42 step 1: mse=14147.455784 step=0.050000
2017/08/29 21:16:43 step 2: mse=14165.764830 step=0.050000
2017/08/29 21:16:44 step 3: mse=14177.090849 step=0.050000
2017/08/29 21:16:45 step 4: mse=14199.521649 step=0.050000
2017/08/29 21:16:45 step 5: mse=14222.070381 step=0.050000
2017/08/29 21:16:46 step 6: mse=14243.134549 step=0.050000
2017/08/29 21:16:47 step 7: mse=14254.205620 step=0.050000
2017/08/29 21:16:47 Saving...
2017/08/29 21:16:47 Gathering batch of experience...
2017/08/29 21:17:09 batch 137: mean=902.000000 stddev=445.609321 entropy=0.599227 frames=4603 count=60
2017/08/29 21:17:09 Training policy...
2017/08/29 21:17:11 tune 0: objective=22.550006 reg=0.005992 prune=0
2017/08/29 21:17:12 step 0: objective=22.554951 reg=0.005991
2017/08/29 21:17:13 step 1: objective=22.568223 reg=0.005991
2017/08/29 21:17:13 step 2: objective=22.580932 reg=0.005990
2017/08/29 21:17:14 step 3: objective=22.592781 reg=0.005990
2017/08/29 21:17:15 step 4: objective=22.604144 reg=0.005989
2017/08/29 21:17:16 step 5: objective=22.614759 reg=0.005989
2017/08/29 21:17:16 step 6: objective=22.627060 reg=0.005988
2017/08/29 21:17:17 step 7: objective=22.638261 reg=0.005987
2017/08/29 21:17:17 Training value function...
2017/08/29 21:17:19 step 0: mse=14653.077550 step=0.050000
2017/08/29 21:17:20 step 1: mse=14586.429500 step=0.050000
2017/08/29 21:17:20 step 2: mse=14516.131934 step=0.050000
2017/08/29 21:17:21 step 3: mse=14438.174256 step=0.050000
2017/08/29 21:17:22 step 4: mse=14393.351848 step=0.050000
2017/08/29 21:17:22 step 5: mse=14337.001764 step=0.050000
2017/08/29 21:17:23 step 6: mse=14279.913187 step=0.050000
2017/08/29 21:17:24 step 7: mse=14223.141497 step=0.050000
2017/08/29 21:17:24 Saving...
2017/08/29 21:17:24 Gathering batch of experience...
2017/08/29 21:17:46 batch 138: mean=858.750000 stddev=489.604432 entropy=0.601757 frames=4678 count=64
2017/08/29 21:17:46 Training policy...
2017/08/29 21:17:49 tune 0: objective=20.950622 reg=0.006018 prune=0
2017/08/29 21:17:49 step 0: objective=20.955944 reg=0.006017
2017/08/29 21:17:50 step 1: objective=20.972027 reg=0.006017
2017/08/29 21:17:51 step 2: objective=20.987702 reg=0.006017
2017/08/29 21:17:52 step 3: objective=21.008708 reg=0.006016
2017/08/29 21:17:52 step 4: objective=21.029555 reg=0.006017
2017/08/29 21:17:53 step 5: objective=21.048881 reg=0.006017
2017/08/29 21:17:54 step 6: objective=21.066830 reg=0.006017
2017/08/29 21:17:55 step 7: objective=21.086422 reg=0.006016
2017/08/29 21:17:55 Training value function...
2017/08/29 21:17:56 step 0: mse=14946.785033 step=0.050000
2017/08/29 21:17:57 step 1: mse=14882.917608 step=0.050000
2017/08/29 21:17:58 step 2: mse=14824.998419 step=0.050000
2017/08/29 21:17:59 step 3: mse=14775.470803 step=0.050000
2017/08/29 21:17:59 step 4: mse=14723.077899 step=0.050000
2017/08/29 21:18:00 step 5: mse=14672.425545 step=0.050000
2017/08/29 21:18:01 step 6: mse=14629.906241 step=0.050000
2017/08/29 21:18:01 step 7: mse=14591.446047 step=0.050000
2017/08/29 21:18:01 Saving...
2017/08/29 21:18:01 Gathering batch of experience...
2017/08/29 21:18:24 batch 139: mean=922.583333 stddev=471.018835 entropy=0.598478 frames=4682 count=60
2017/08/29 21:18:24 Training policy...
2017/08/29 21:18:26 tune 0: objective=23.295617 reg=0.005985 prune=0
2017/08/29 21:18:27 step 0: objective=23.301707 reg=0.005983
2017/08/29 21:18:28 step 1: objective=23.322303 reg=0.005982
2017/08/29 21:18:29 step 2: objective=23.332899 reg=0.005982
2017/08/29 21:18:29 step 3: objective=23.346623 reg=0.005981
2017/08/29 21:18:30 step 4: objective=23.359844 reg=0.005980
2017/08/29 21:18:31 step 5: objective=23.376317 reg=0.005979
2017/08/29 21:18:32 step 6: objective=23.393397 reg=0.005978
2017/08/29 21:18:32 step 7: objective=23.406120 reg=0.005977
2017/08/29 21:18:32 Training value function...
2017/08/29 21:18:34 step 0: mse=14905.137184 step=0.050000
2017/08/29 21:18:35 step 1: mse=14847.845747 step=0.050000
2017/08/29 21:18:36 step 2: mse=14765.694505 step=0.050000
2017/08/29 21:18:36 step 3: mse=14690.901592 step=0.050000
2017/08/29 21:18:37 step 4: mse=14611.111999 step=0.050000
2017/08/29 21:18:38 step 5: mse=14551.639303 step=0.050000
2017/08/29 21:18:39 step 6: mse=14484.362885 step=0.050000
2017/08/29 21:18:39 step 7: mse=14419.733739 step=0.050000
2017/08/29 21:18:39 Saving...
2017/08/29 21:18:39 Gathering batch of experience...
2017/08/29 21:19:02 batch 140: mean=916.129032 stddev=496.415717 entropy=0.595897 frames=4742 count=62
2017/08/29 21:19:02 Training policy...
2017/08/29 21:19:04 tune 0: objective=24.590394 reg=0.005959 prune=0
2017/08/29 21:19:05 step 0: objective=24.595208 reg=0.005959
2017/08/29 21:19:06 step 1: objective=24.604091 reg=0.005958
2017/08/29 21:19:07 step 2: objective=24.620562 reg=0.005958
2017/08/29 21:19:07 step 3: objective=24.634404 reg=0.005958
2017/08/29 21:19:08 step 4: objective=24.648591 reg=0.005958
2017/08/29 21:19:09 step 5: objective=24.664156 reg=0.005958
2017/08/29 21:19:10 step 6: objective=24.672099 reg=0.005959
2017/08/29 21:19:10 step 7: objective=24.690719 reg=0.005959
2017/08/29 21:19:10 Training value function...
2017/08/29 21:19:12 step 0: mse=15348.019351 step=0.050000
2017/08/29 21:19:13 step 1: mse=15259.860668 step=0.050000
2017/08/29 21:19:14 step 2: mse=15179.873049 step=0.050000
2017/08/29 21:19:14 step 3: mse=15108.578926 step=0.050000
2017/08/29 21:19:15 step 4: mse=15042.236055 step=0.050000
2017/08/29 21:19:16 step 5: mse=14980.375019 step=0.050000
2017/08/29 21:19:17 step 6: mse=14923.105801 step=0.050000
2017/08/29 21:19:17 step 7: mse=14867.538191 step=0.050000
2017/08/29 21:19:17 Saving...
2017/08/29 21:19:17 Gathering batch of experience...
2017/08/29 21:19:41 batch 141: mean=981.333333 stddev=458.918899 entropy=0.594998 frames=4936 count=60
2017/08/29 21:19:41 Training policy...
2017/08/29 21:19:43 tune 0: objective=25.232669 reg=0.005950 prune=0
2017/08/29 21:19:44 step 0: objective=25.239840 reg=0.005948
2017/08/29 21:19:45 step 1: objective=25.251341 reg=0.005947
2017/08/29 21:19:46 step 2: objective=25.268781 reg=0.005945
2017/08/29 21:19:46 step 3: objective=25.281736 reg=0.005944
2017/08/29 21:19:47 step 4: objective=25.294871 reg=0.005944
2017/08/29 21:19:48 step 5: objective=25.310056 reg=0.005942
2017/08/29 21:19:49 step 6: objective=25.325048 reg=0.005940
2017/08/29 21:19:49 step 7: objective=25.343748 reg=0.005939
2017/08/29 21:19:49 Training value function...
2017/08/29 21:19:51 step 0: mse=14212.662808 step=0.050000
2017/08/29 21:19:52 step 1: mse=14140.613950 step=0.050000
2017/08/29 21:19:53 step 2: mse=14072.402543 step=0.050000
2017/08/29 21:19:54 step 3: mse=14011.136371 step=0.050000
2017/08/29 21:19:54 step 4: mse=13959.737794 step=0.050000
2017/08/29 21:19:55 step 5: mse=13913.149956 step=0.050000
2017/08/29 21:19:56 step 6: mse=13859.591487 step=0.050000
2017/08/29 21:19:57 step 7: mse=13812.111859 step=0.050000
2017/08/29 21:19:57 Saving...
2017/08/29 21:19:57 Gathering batch of experience...
2017/08/29 21:20:20 batch 142: mean=916.250000 stddev=491.507566 entropy=0.595341 frames=4829 count=64
2017/08/29 21:20:20 Training policy...
2017/08/29 21:20:23 tune 0: objective=23.213288 reg=0.005953 prune=0
2017/08/29 21:20:23 step 0: objective=23.220314 reg=0.005952
2017/08/29 21:20:24 step 1: objective=23.232327 reg=0.005951
2017/08/29 21:20:25 step 2: objective=23.245600 reg=0.005950
2017/08/29 21:20:26 step 3: objective=23.263363 reg=0.005949
2017/08/29 21:20:26 step 4: objective=23.276599 reg=0.005948
2017/08/29 21:20:27 step 5: objective=23.285710 reg=0.005947
2017/08/29 21:20:28 step 6: objective=23.303178 reg=0.005947
2017/08/29 21:20:29 step 7: objective=23.312935 reg=0.005946
2017/08/29 21:20:29 Training value function...
2017/08/29 21:20:30 step 0: mse=14838.033247 step=0.050000
2017/08/29 21:20:31 step 1: mse=14772.293490 step=0.050000
2017/08/29 21:20:32 step 2: mse=14708.747296 step=0.050000
2017/08/29 21:20:33 step 3: mse=14650.850164 step=0.050000
2017/08/29 21:20:33 step 4: mse=14597.628010 step=0.050000
2017/08/29 21:20:34 step 5: mse=14547.790057 step=0.050000
2017/08/29 21:20:35 step 6: mse=14497.736687 step=0.050000
2017/08/29 21:20:36 step 7: mse=14453.264192 step=0.050000
2017/08/29 21:20:36 Saving...
2017/08/29 21:20:36 Gathering batch of experience...
2017/08/29 21:20:58 batch 143: mean=883.225806 stddev=516.021612 entropy=0.599634 frames=4715 count=62
2017/08/29 21:20:58 Training policy...
2017/08/29 21:21:00 tune 0: objective=16.916226 reg=0.005996 prune=0
2017/08/29 21:21:01 step 0: objective=16.924995 reg=0.005995
2017/08/29 21:21:02 step 1: objective=16.938970 reg=0.005994
2017/08/29 21:21:03 step 2: objective=16.962159 reg=0.005994
2017/08/29 21:21:03 step 3: objective=16.980163 reg=0.005993
2017/08/29 21:21:04 step 4: objective=17.000146 reg=0.005993
2017/08/29 21:21:05 step 5: objective=17.019693 reg=0.005992
2017/08/29 21:21:06 step 6: objective=17.038536 reg=0.005992
2017/08/29 21:21:06 step 7: objective=17.056557 reg=0.005992
2017/08/29 21:21:06 Training value function...
2017/08/29 21:21:08 step 0: mse=16566.852474 step=0.050000
2017/08/29 21:21:09 step 1: mse=16547.765675 step=0.050000
2017/08/29 21:21:10 step 2: mse=16533.972503 step=0.050000
2017/08/29 21:21:10 step 3: mse=16523.521597 step=0.050000
2017/08/29 21:21:11 step 4: mse=16517.901485 step=0.050000
2017/08/29 21:21:12 step 5: mse=16506.170752 step=0.050000
2017/08/29 21:21:13 step 6: mse=16495.983655 step=0.050000
2017/08/29 21:21:13 step 7: mse=16496.292108 step=0.050000
2017/08/29 21:21:13 Saving...
2017/08/29 21:21:13 Gathering batch of experience...
2017/08/29 21:21:36 batch 144: mean=868.015873 stddev=475.858072 entropy=0.597638 frames=4663 count=63
2017/08/29 21:21:36 Training policy...
2017/08/29 21:21:38 tune 0: objective=17.543112 reg=0.005976 prune=0
2017/08/29 21:21:39 step 0: objective=17.551834 reg=0.005975
2017/08/29 21:21:40 step 1: objective=17.577383 reg=0.005976
2017/08/29 21:21:40 step 2: objective=17.597473 reg=0.005975
2017/08/29 21:21:41 step 3: objective=17.619962 reg=0.005975
2017/08/29 21:21:42 step 4: objective=17.643024 reg=0.005974
2017/08/29 21:21:43 step 5: objective=17.669447 reg=0.005973
2017/08/29 21:21:43 step 6: objective=17.686384 reg=0.005972
2017/08/29 21:21:44 step 7: objective=17.706536 reg=0.005972
2017/08/29 21:21:44 Training value function...
2017/08/29 21:21:46 step 0: mse=15082.573650 step=0.050000
2017/08/29 21:21:47 step 1: mse=15074.862854 step=0.050000
2017/08/29 21:21:47 step 2: mse=15069.579779 step=0.050000
2017/08/29 21:21:48 step 3: mse=15074.883117 step=0.050000
2017/08/29 21:21:49 step 4: mse=15073.375067 step=0.050000
2017/08/29 21:21:49 step 5: mse=15074.096891 step=0.050000
2017/08/29 21:21:50 step 6: mse=15069.963545 step=0.050000
2017/08/29 21:21:51 step 7: mse=15075.121247 step=0.050000
2017/08/29 21:21:51 Saving...
2017/08/29 21:21:51 Gathering batch of experience...
2017/08/29 21:22:13 batch 145: mean=932.177419 stddev=440.789816 entropy=0.588339 frames=4787 count=62
2017/08/29 21:22:13 Training policy...
2017/08/29 21:22:16 tune 0: objective=23.580713 reg=0.005883 prune=0
2017/08/29 21:22:17 step 0: objective=23.585874 reg=0.005882
2017/08/29 21:22:18 step 1: objective=23.601742 reg=0.005881
2017/08/29 21:22:18 step 2: objective=23.617633 reg=0.005881
2017/08/29 21:22:19 step 3: objective=23.629496 reg=0.005880
2017/08/29 21:22:20 step 4: objective=23.644504 reg=0.005880
2017/08/29 21:22:21 step 5: objective=23.658259 reg=0.005879
2017/08/29 21:22:21 step 6: objective=23.674948 reg=0.005878
2017/08/29 21:22:22 step 7: objective=23.693605 reg=0.005877
2017/08/29 21:22:22 Training value function...
2017/08/29 21:22:24 step 0: mse=13385.695674 step=0.050000
2017/08/29 21:22:25 step 1: mse=13291.283976 step=0.050000
2017/08/29 21:22:25 step 2: mse=13211.728020 step=0.050000
2017/08/29 21:22:26 step 3: mse=13131.490389 step=0.050000
2017/08/29 21:22:27 step 4: mse=13059.553148 step=0.050000
2017/08/29 21:22:28 step 5: mse=12998.146527 step=0.050000
2017/08/29 21:22:28 step 6: mse=12940.959386 step=0.050000
2017/08/29 21:22:29 step 7: mse=12887.142490 step=0.050000
2017/08/29 21:22:29 Saving...
2017/08/29 21:22:29 Gathering batch of experience...
2017/08/29 21:22:52 batch 146: mean=944.583333 stddev=443.424450 entropy=0.590246 frames=4782 count=60
2017/08/29 21:22:52 Training policy...
2017/08/29 21:22:55 tune 0: objective=22.286909 reg=0.005902 prune=0
2017/08/29 21:22:56 step 0: objective=22.294916 reg=0.005901
2017/08/29 21:22:56 step 1: objective=22.309894 reg=0.005900
2017/08/29 21:22:57 step 2: objective=22.328370 reg=0.005899
2017/08/29 21:22:58 step 3: objective=22.342896 reg=0.005898
2017/08/29 21:22:59 step 4: objective=22.360019 reg=0.005897
2017/08/29 21:22:59 step 5: objective=22.376691 reg=0.005896
2017/08/29 21:23:00 step 6: objective=22.393507 reg=0.005895
2017/08/29 21:23:01 step 7: objective=22.406797 reg=0.005894
2017/08/29 21:23:01 Training value function...
2017/08/29 21:23:03 step 0: mse=14670.195607 step=0.050000
2017/08/29 21:23:04 step 1: mse=14653.576737 step=0.050000
2017/08/29 21:23:04 step 2: mse=14631.193207 step=0.050000
2017/08/29 21:23:05 step 3: mse=14613.936791 step=0.050000
2017/08/29 21:23:06 step 4: mse=14601.047473 step=0.050000
2017/08/29 21:23:06 step 5: mse=14584.018826 step=0.050000
2017/08/29 21:23:07 step 6: mse=14570.628080 step=0.050000
2017/08/29 21:23:08 step 7: mse=14555.132629 step=0.050000
2017/08/29 21:23:08 Saving...
2017/08/29 21:23:08 Gathering batch of experience...
2017/08/29 21:23:30 batch 147: mean=971.694915 stddev=512.962161 entropy=0.592007 frames=4795 count=59
2017/08/29 21:23:30 Training policy...
2017/08/29 21:23:33 tune 0: objective=25.828159 reg=0.005920 prune=0
2017/08/29 21:23:34 step 0: objective=25.834960 reg=0.005919
2017/08/29 21:23:35 step 1: objective=25.857070 reg=0.005918
2017/08/29 21:23:35 step 2: objective=25.877042 reg=0.005918
2017/08/29 21:23:36 step 3: objective=25.894886 reg=0.005917
2017/08/29 21:23:37 step 4: objective=25.911403 reg=0.005917
2017/08/29 21:23:38 step 5: objective=25.926533 reg=0.005917
2017/08/29 21:23:38 step 6: objective=25.940705 reg=0.005917
2017/08/29 21:23:39 step 7: objective=25.956680 reg=0.005917
2017/08/29 21:23:39 Training value function...
2017/08/29 21:23:41 step 0: mse=16304.828304 step=0.050000
2017/08/29 21:23:42 step 1: mse=16188.485794 step=0.050000
2017/08/29 21:23:43 step 2: mse=16089.351855 step=0.050000
2017/08/29 21:23:43 step 3: mse=15998.126310 step=0.050000
2017/08/29 21:23:44 step 4: mse=15912.859383 step=0.050000
2017/08/29 21:23:45 step 5: mse=15825.036743 step=0.050000
2017/08/29 21:23:46 step 6: mse=15754.546496 step=0.050000
2017/08/29 21:23:46 step 7: mse=15678.306331 step=0.050000
2017/08/29 21:23:46 Saving...
2017/08/29 21:23:46 Gathering batch of experience...
2017/08/29 21:24:08 batch 148: mean=915.916667 stddev=509.771592 entropy=0.592870 frames=4579 count=60
2017/08/29 21:24:08 Training policy...
2017/08/29 21:24:11 tune 0: objective=21.897764 reg=0.005929 prune=0
2017/08/29 21:24:12 step 0: objective=21.903764 reg=0.005927
2017/08/29 21:24:12 step 1: objective=21.918266 reg=0.005926
2017/08/29 21:24:13 step 2: objective=21.933069 reg=0.005925
2017/08/29 21:24:14 step 3: objective=21.951328 reg=0.005923
2017/08/29 21:24:14 step 4: objective=21.970035 reg=0.005922
2017/08/29 21:24:15 step 5: objective=21.989055 reg=0.005920
2017/08/29 21:24:16 step 6: objective=22.007125 reg=0.005918
2017/08/29 21:24:17 step 7: objective=22.023489 reg=0.005916
2017/08/29 21:24:17 Training value function...
2017/08/29 21:24:18 step 0: mse=15083.321141 step=0.050000
2017/08/29 21:24:19 step 1: mse=15008.733056 step=0.050000
2017/08/29 21:24:20 step 2: mse=14950.799268 step=0.050000
2017/08/29 21:24:20 step 3: mse=14892.824855 step=0.050000
2017/08/29 21:24:21 step 4: mse=14837.180885 step=0.050000
2017/08/29 21:24:22 step 5: mse=14780.762261 step=0.050000
2017/08/29 21:24:23 step 6: mse=14732.384424 step=0.050000
2017/08/29 21:24:23 step 7: mse=14685.825533 step=0.050000
2017/08/29 21:24:23 Saving...
2017/08/29 21:24:23 Gathering batch of experience...
2017/08/29 21:24:46 batch 149: mean=883.174603 stddev=504.886677 entropy=0.594041 frames=4720 count=63
2017/08/29 21:24:46 Training policy...
2017/08/29 21:24:48 tune 0: objective=17.744584 reg=0.005940 prune=0
2017/08/29 21:24:49 step 0: objective=17.749730 reg=0.005940
2017/08/29 21:24:50 step 1: objective=17.763723 reg=0.005938
2017/08/29 21:24:50 step 2: objective=17.775642 reg=0.005938
2017/08/29 21:24:51 step 3: objective=17.794000 reg=0.005936
2017/08/29 21:24:52 step 4: objective=17.808873 reg=0.005936
2017/08/29 21:24:53 step 5: objective=17.823924 reg=0.005935
2017/08/29 21:24:53 step 6: objective=17.834312 reg=0.005934
2017/08/29 21:24:54 step 7: objective=17.845834 reg=0.005933
2017/08/29 21:24:54 Training value function...
2017/08/29 21:24:56 step 0: mse=15706.210169 step=0.050000
2017/08/29 21:24:57 step 1: mse=15695.880232 step=0.050000
2017/08/29 21:24:57 step 2: mse=15686.036841 step=0.050000
2017/08/29 21:24:58 step 3: mse=15676.249528 step=0.050000
2017/08/29 21:24:59 step 4: mse=15669.245045 step=0.050000
2017/08/29 21:25:00 step 5: mse=15670.165200 step=0.050000
2017/08/29 21:25:00 step 6: mse=15669.478907 step=0.050000
2017/08/29 21:25:01 step 7: mse=15670.829831 step=0.050000
2017/08/29 21:25:01 Saving...
2017/08/29 21:25:01 Gathering batch of experience...
2017/08/29 21:25:24 batch 150: mean=950.403226 stddev=465.000259 entropy=0.587801 frames=4916 count=62
2017/08/29 21:25:24 Training policy...
2017/08/29 21:25:27 tune 0: objective=22.789112 reg=0.005878 prune=0
2017/08/29 21:25:28 step 0: objective=22.796511 reg=0.005877
2017/08/29 21:25:29 step 1: objective=22.815383 reg=0.005875
2017/08/29 21:25:29 step 2: objective=22.832867 reg=0.005875
2017/08/29 21:25:30 step 3: objective=22.848079 reg=0.005874
2017/08/29 21:25:31 step 4: objective=22.863960 reg=0.005873
2017/08/29 21:25:32 step 5: objective=22.879148 reg=0.005873
2017/08/29 21:25:32 step 6: objective=22.896701 reg=0.005872
2017/08/29 21:25:33 step 7: objective=22.912724 reg=0.005870
2017/08/29 21:25:33 Training value function...
2017/08/29 21:25:35 step 0: mse=14188.942799 step=0.050000
2017/08/29 21:25:36 step 1: mse=14146.572744 step=0.050000
2017/08/29 21:25:37 step 2: mse=14106.382024 step=0.050000
2017/08/29 21:25:37 step 3: mse=14074.351605 step=0.050000
2017/08/29 21:25:38 step 4: mse=14041.740972 step=0.050000
2017/08/29 21:25:39 step 5: mse=14008.910242 step=0.050000
2017/08/29 21:25:40 step 6: mse=13974.207716 step=0.050000
2017/08/29 21:25:41 step 7: mse=13945.615009 step=0.050000
2017/08/29 21:25:41 Saving...
2017/08/29 21:25:41 Gathering batch of experience...
2017/08/29 21:26:02 batch 151: mean=906.186441 stddev=540.367373 entropy=0.592508 frames=4477 count=59
2017/08/29 21:26:02 Training policy...
2017/08/29 21:26:04 tune 0: objective=22.082374 reg=0.005925 prune=0
2017/08/29 21:26:05 step 0: objective=22.088916 reg=0.005924
2017/08/29 21:26:06 step 1: objective=22.107590 reg=0.005923
2017/08/29 21:26:06 step 2: objective=22.121407 reg=0.005922
2017/08/29 21:26:07 step 3: objective=22.136123 reg=0.005921
2017/08/29 21:26:08 step 4: objective=22.153245 reg=0.005921
2017/08/29 21:26:09 step 5: objective=22.168149 reg=0.005920
2017/08/29 21:26:09 step 6: objective=22.180654 reg=0.005919
2017/08/29 21:26:10 step 7: objective=22.195642 reg=0.005918
2017/08/29 21:26:10 Training value function...
2017/08/29 21:26:12 step 0: mse=15746.149593 step=0.050000
2017/08/29 21:26:12 step 1: mse=15658.351799 step=0.050000
2017/08/29 21:26:13 step 2: mse=15600.223955 step=0.050000
2017/08/29 21:26:14 step 3: mse=15529.023840 step=0.050000
2017/08/29 21:26:15 step 4: mse=15456.512559 step=0.050000
2017/08/29 21:26:15 step 5: mse=15403.878443 step=0.050000
2017/08/29 21:26:16 step 6: mse=15338.927558 step=0.050000
2017/08/29 21:26:17 step 7: mse=15287.443963 step=0.050000
2017/08/29 21:26:17 Saving...
2017/08/29 21:26:17 Gathering batch of experience...
2017/08/29 21:26:39 batch 152: mean=1000.862069 stddev=511.912521 entropy=0.588492 frames=4845 count=58
2017/08/29 21:26:39 Training policy...
2017/08/29 21:26:42 tune 0: objective=25.806116 reg=0.005885 prune=0
2017/08/29 21:26:43 step 0: objective=25.814628 reg=0.005883
2017/08/29 21:26:44 step 1: objective=25.829718 reg=0.005882
2017/08/29 21:26:44 step 2: objective=25.844277 reg=0.005881
2017/08/29 21:26:45 step 3: objective=25.855642 reg=0.005880
2017/08/29 21:26:46 step 4: objective=25.879816 reg=0.005878
2017/08/29 21:26:47 step 5: objective=25.895845 reg=0.005876
2017/08/29 21:26:47 step 6: objective=25.918950 reg=0.005874
2017/08/29 21:26:48 step 7: objective=25.940952 reg=0.005873
2017/08/29 21:26:48 Training value function...
2017/08/29 21:26:50 step 0: mse=15643.549877 step=0.050000
2017/08/29 21:26:51 step 1: mse=15565.759431 step=0.050000
2017/08/29 21:26:52 step 2: mse=15488.894492 step=0.050000
2017/08/29 21:26:52 step 3: mse=15423.691143 step=0.050000
2017/08/29 21:26:53 step 4: mse=15362.828836 step=0.050000
2017/08/29 21:26:54 step 5: mse=15304.564606 step=0.050000
2017/08/29 21:26:55 step 6: mse=15256.331704 step=0.050000
2017/08/29 21:26:55 step 7: mse=15202.183640 step=0.050000
2017/08/29 21:26:55 Saving...
2017/08/29 21:26:55 Gathering batch of experience...
2017/08/29 21:27:18 batch 153: mean=1043.125000 stddev=501.506269 entropy=0.586367 frames=4893 count=56
2017/08/29 21:27:18 Training policy...
2017/08/29 21:27:21 tune 0: objective=25.341045 reg=0.005864 prune=0
2017/08/29 21:27:21 step 0: objective=25.349615 reg=0.005862
2017/08/29 21:27:22 step 1: objective=25.360162 reg=0.005862
2017/08/29 21:27:23 step 2: objective=25.375560 reg=0.005861
2017/08/29 21:27:24 step 3: objective=25.387741 reg=0.005860
2017/08/29 21:27:25 step 4: objective=25.400215 reg=0.005860
2017/08/29 21:27:25 step 5: objective=25.412892 reg=0.005859
2017/08/29 21:27:26 step 6: objective=25.425707 reg=0.005858
2017/08/29 21:27:27 step 7: objective=25.444348 reg=0.005857
2017/08/29 21:27:27 Training value function...
2017/08/29 21:27:29 step 0: mse=15029.639327 step=0.050000
2017/08/29 21:27:30 step 1: mse=14948.904336 step=0.050000
2017/08/29 21:27:30 step 2: mse=14877.148003 step=0.050000
2017/08/29 21:27:31 step 3: mse=14811.341238 step=0.050000
2017/08/29 21:27:32 step 4: mse=14750.935002 step=0.050000
2017/08/29 21:27:33 step 5: mse=14691.646316 step=0.050000
2017/08/29 21:27:33 step 6: mse=14637.860680 step=0.050000
2017/08/29 21:27:34 step 7: mse=14587.945322 step=0.050000
2017/08/29 21:27:34 Saving...
2017/08/29 21:27:34 Gathering batch of experience...
2017/08/29 21:27:57 batch 154: mean=871.953125 stddev=474.871378 entropy=0.589385 frames=4763 count=64
2017/08/29 21:27:57 Training policy...
2017/08/29 21:28:00 tune 0: objective=11.865798 reg=0.005894 prune=0
2017/08/29 21:28:00 step 0: objective=11.874232 reg=0.005892
2017/08/29 21:28:01 step 1: objective=11.888931 reg=0.005890
2017/08/29 21:28:02 step 2: objective=11.901847 reg=0.005889
2017/08/29 21:28:03 step 3: objective=11.918740 reg=0.005887
2017/08/29 21:28:03 step 4: objective=11.932352 reg=0.005886
2017/08/29 21:28:04 step 5: objective=11.948195 reg=0.005885
2017/08/29 21:28:05 step 6: objective=11.962946 reg=0.005884
2017/08/29 21:28:06 step 7: objective=11.978428 reg=0.005883
2017/08/29 21:28:06 Training value function...
2017/08/29 21:28:08 step 0: mse=13592.048052 step=0.050000
2017/08/29 21:28:08 step 1: mse=13623.116106 step=0.050000
2017/08/29 21:28:09 step 2: mse=13661.696597 step=0.050000
2017/08/29 21:28:10 step 3: mse=13707.860328 step=0.050000
2017/08/29 21:28:11 step 4: mse=13747.543279 step=0.050000
2017/08/29 21:28:11 step 5: mse=13791.977543 step=0.050000
2017/08/29 21:28:12 step 6: mse=13835.896068 step=0.050000
2017/08/29 21:28:13 step 7: mse=13875.585269 step=0.050000
2017/08/29 21:28:13 Saving...
2017/08/29 21:28:13 Gathering batch of experience...
2017/08/29 21:28:36 batch 155: mean=986.166667 stddev=502.021220 entropy=0.582776 frames=4873 count=60
2017/08/29 21:28:36 Training policy...
2017/08/29 21:28:39 tune 0: objective=25.231302 reg=0.005828 prune=0
2017/08/29 21:28:39 step 0: objective=25.238917 reg=0.005827
2017/08/29 21:28:40 step 1: objective=25.255355 reg=0.005827
2017/08/29 21:28:41 step 2: objective=25.275732 reg=0.005825
2017/08/29 21:28:42 step 3: objective=25.292070 reg=0.005825
2017/08/29 21:28:42 step 4: objective=25.307270 reg=0.005825
2017/08/29 21:28:43 step 5: objective=25.327852 reg=0.005824
2017/08/29 21:28:44 step 6: objective=25.344720 reg=0.005823
2017/08/29 21:28:45 step 7: objective=25.359306 reg=0.005823
2017/08/29 21:28:45 Training value function...
2017/08/29 21:28:47 step 0: mse=14785.532219 step=0.050000
2017/08/29 21:28:47 step 1: mse=14678.194150 step=0.050000
2017/08/29 21:28:48 step 2: mse=14588.301187 step=0.050000
2017/08/29 21:28:49 step 3: mse=14502.061282 step=0.050000
2017/08/29 21:28:50 step 4: mse=14416.955684 step=0.050000
2017/08/29 21:28:50 step 5: mse=14328.090365 step=0.050000
2017/08/29 21:28:51 step 6: mse=14258.246414 step=0.050000
2017/08/29 21:28:52 step 7: mse=14175.525926 step=0.050000
2017/08/29 21:28:52 Saving...
2017/08/29 21:28:52 Gathering batch of experience...
2017/08/29 21:29:15 batch 156: mean=1028.534483 stddev=539.568800 entropy=0.586528 frames=4964 count=58
2017/08/29 21:29:15 Training policy...
2017/08/29 21:29:18 tune 0: objective=26.575132 reg=0.005865 prune=0
2017/08/29 21:29:19 step 0: objective=26.581301 reg=0.005864
2017/08/29 21:29:20 step 1: objective=26.593319 reg=0.005863
2017/08/29 21:29:20 step 2: objective=26.610496 reg=0.005861
2017/08/29 21:29:21 step 3: objective=26.620571 reg=0.005860
2017/08/29 21:29:22 step 4: objective=26.634950 reg=0.005858
2017/08/29 21:29:23 step 5: objective=26.650301 reg=0.005857
2017/08/29 21:29:23 step 6: objective=26.665281 reg=0.005855
2017/08/29 21:29:24 step 7: objective=26.678218 reg=0.005854
2017/08/29 21:29:24 Training value function...
2017/08/29 21:29:26 step 0: mse=15480.810008 step=0.050000
2017/08/29 21:29:27 step 1: mse=15375.192701 step=0.050000
2017/08/29 21:29:28 step 2: mse=15274.939902 step=0.050000
2017/08/29 21:29:29 step 3: mse=15189.124593 step=0.050000
2017/08/29 21:29:29 step 4: mse=15104.077552 step=0.050000
2017/08/29 21:29:30 step 5: mse=15024.066892 step=0.050000
2017/08/29 21:29:31 step 6: mse=14953.572995 step=0.050000
2017/08/29 21:29:32 step 7: mse=14885.329661 step=0.050000
2017/08/29 21:29:32 Saving...
2017/08/29 21:29:32 Gathering batch of experience...
2017/08/29 21:29:55 batch 157: mean=934.112903 stddev=531.393879 entropy=0.588531 frames=4872 count=62
2017/08/29 21:29:55 Training policy...
2017/08/29 21:29:57 tune 0: objective=19.119711 reg=0.005885 prune=0
2017/08/29 21:29:58 step 0: objective=19.127000 reg=0.005884
2017/08/29 21:29:59 step 1: objective=19.139902 reg=0.005883
2017/08/29 21:30:00 step 2: objective=19.153995 reg=0.005883
2017/08/29 21:30:00 step 3: objective=19.165791 reg=0.005882
2017/08/29 21:30:01 step 4: objective=19.176581 reg=0.005882
2017/08/29 21:30:02 step 5: objective=19.191074 reg=0.005881
2017/08/29 21:30:03 step 6: objective=19.205088 reg=0.005880
2017/08/29 21:30:04 step 7: objective=19.219468 reg=0.005879
2017/08/29 21:30:04 Training value function...
2017/08/29 21:30:05 step 0: mse=14828.796698 step=0.050000
2017/08/29 21:30:06 step 1: mse=14797.620526 step=0.050000
2017/08/29 21:30:07 step 2: mse=14771.579157 step=0.050000
2017/08/29 21:30:08 step 3: mse=14747.949509 step=0.050000
2017/08/29 21:30:08 step 4: mse=14724.259873 step=0.050000
2017/08/29 21:30:09 step 5: mse=14706.242718 step=0.050000
2017/08/29 21:30:10 step 6: mse=14689.550482 step=0.050000
2017/08/29 21:30:11 step 7: mse=14678.186947 step=0.050000
2017/08/29 21:30:11 Saving...
2017/08/29 21:30:11 Gathering batch of experience...
2017/08/29 21:30:33 batch 158: mean=945.666667 stddev=500.477661 entropy=0.584552 frames=4743 count=60
2017/08/29 21:30:33 Training policy...
2017/08/29 21:30:36 tune 0: objective=19.675021 reg=0.005846 prune=0
2017/08/29 21:30:36 step 0: objective=19.682568 reg=0.005844
2017/08/29 21:30:37 step 1: objective=19.701045 reg=0.005843
2017/08/29 21:30:38 step 2: objective=19.718953 reg=0.005842
2017/08/29 21:30:39 step 3: objective=19.734111 reg=0.005841
2017/08/29 21:30:39 step 4: objective=19.747696 reg=0.005839
2017/08/29 21:30:40 step 5: objective=19.765385 reg=0.005839
2017/08/29 21:30:41 step 6: objective=19.779904 reg=0.005837
2017/08/29 21:30:42 step 7: objective=19.794014 reg=0.005836
2017/08/29 21:30:42 Training value function...
2017/08/29 21:30:44 step 0: mse=14305.963971 step=0.050000
2017/08/29 21:30:44 step 1: mse=14309.329413 step=0.050000
2017/08/29 21:30:45 step 2: mse=14307.726914 step=0.050000
2017/08/29 21:30:46 step 3: mse=14311.780739 step=0.050000
2017/08/29 21:30:46 step 4: mse=14311.766063 step=0.050000
2017/08/29 21:30:47 step 5: mse=14309.067672 step=0.050000
2017/08/29 21:30:48 step 6: mse=14314.103677 step=0.050000
2017/08/29 21:30:49 step 7: mse=14316.845917 step=0.050000
2017/08/29 21:30:49 Saving...
2017/08/29 21:30:49 Gathering batch of experience...
2017/08/29 21:31:11 batch 159: mean=964.827586 stddev=530.038194 entropy=0.584676 frames=4731 count=58
2017/08/29 21:31:11 Training policy...
2017/08/29 21:31:13 tune 0: objective=21.838778 reg=0.005847 prune=0
2017/08/29 21:31:14 step 0: objective=21.847335 reg=0.005846
2017/08/29 21:31:15 step 1: objective=21.864015 reg=0.005845
2017/08/29 21:31:16 step 2: objective=21.886928 reg=0.005845
2017/08/29 21:31:16 step 3: objective=21.905616 reg=0.005845
2017/08/29 21:31:17 step 4: objective=21.921437 reg=0.005845
2017/08/29 21:31:18 step 5: objective=21.940641 reg=0.005844
2017/08/29 21:31:19 step 6: objective=21.961241 reg=0.005844
2017/08/29 21:31:19 step 7: objective=21.976592 reg=0.005843
2017/08/29 21:31:19 Training value function...
2017/08/29 21:31:21 step 0: mse=14366.208096 step=0.050000
2017/08/29 21:31:22 step 1: mse=14337.126364 step=0.050000
2017/08/29 21:31:23 step 2: mse=14298.953708 step=0.050000
2017/08/29 21:31:24 step 3: mse=14272.608607 step=0.050000
2017/08/29 21:31:24 step 4: mse=14248.825224 step=0.050000
2017/08/29 21:31:25 step 5: mse=14233.182796 step=0.050000
2017/08/29 21:31:26 step 6: mse=14206.692228 step=0.050000
2017/08/29 21:31:26 step 7: mse=14191.585646 step=0.050000
2017/08/29 21:31:26 Saving...
2017/08/29 21:31:26 Gathering batch of experience...
2017/08/29 21:31:48 batch 160: mean=1015.545455 stddev=499.996066 entropy=0.579340 frames=4624 count=55
2017/08/29 21:31:48 Training policy...
2017/08/29 21:31:51 tune 0: objective=25.206219 reg=0.005793 prune=0
2017/08/29 21:31:52 step 0: objective=25.215117 reg=0.005792
2017/08/29 21:31:52 step 1: objective=25.240800 reg=0.005791
2017/08/29 21:31:53 step 2: objective=25.261540 reg=0.005789
2017/08/29 21:31:54 step 3: objective=25.285117 reg=0.005788
2017/08/29 21:31:55 step 4: objective=25.304902 reg=0.005787
2017/08/29 21:31:55 step 5: objective=25.320858 reg=0.005786
2017/08/29 21:31:56 step 6: objective=25.341893 reg=0.005785
2017/08/29 21:31:57 step 7: objective=25.361761 reg=0.005784
2017/08/29 21:31:57 Training value function...
2017/08/29 21:31:59 step 0: mse=15263.679795 step=0.050000
2017/08/29 21:31:59 step 1: mse=15192.362136 step=0.050000
2017/08/29 21:32:00 step 2: mse=15116.226923 step=0.050000
2017/08/29 21:32:01 step 3: mse=15054.270145 step=0.050000
2017/08/29 21:32:01 step 4: mse=14995.703956 step=0.050000
2017/08/29 21:32:02 step 5: mse=14939.439014 step=0.050000
2017/08/29 21:32:03 step 6: mse=14891.269221 step=0.050000
2017/08/29 21:32:04 step 7: mse=14845.214035 step=0.050000
2017/08/29 21:32:04 Saving...
2017/08/29 21:32:04 Gathering batch of experience...
2017/08/29 21:32:26 batch 161: mean=1081.759259 stddev=548.359639 entropy=0.582520 frames=4809 count=54
2017/08/29 21:32:26 Training policy...
2017/08/29 21:32:29 tune 0: objective=28.571000 reg=0.005825 prune=0
2017/08/29 21:32:29 step 0: objective=28.578421 reg=0.005824
2017/08/29 21:32:30 step 1: objective=28.595430 reg=0.005822
2017/08/29 21:32:31 step 2: objective=28.608218 reg=0.005821
2017/08/29 21:32:32 step 3: objective=28.629636 reg=0.005819
2017/08/29 21:32:32 step 4: objective=28.641596 reg=0.005818
2017/08/29 21:32:33 step 5: objective=28.654599 reg=0.005817
2017/08/29 21:32:34 step 6: objective=28.671254 reg=0.005816
2017/08/29 21:32:35 step 7: objective=28.686535 reg=0.005815
2017/08/29 21:32:35 Training value function...
2017/08/29 21:32:37 step 0: mse=16505.786667 step=0.050000
2017/08/29 21:32:37 step 1: mse=16377.458429 step=0.050000
2017/08/29 21:32:38 step 2: mse=16253.762081 step=0.050000
2017/08/29 21:32:39 step 3: mse=16143.067142 step=0.050000
2017/08/29 21:32:40 step 4: mse=16039.180337 step=0.050000
2017/08/29 21:32:40 step 5: mse=15941.599130 step=0.050000
2017/08/29 21:32:41 step 6: mse=15844.619000 step=0.050000
2017/08/29 21:32:42 step 7: mse=15753.289692 step=0.050000
2017/08/29 21:32:42 Saving...
2017/08/29 21:32:42 Gathering batch of experience...
2017/08/29 21:33:04 batch 162: mean=884.836066 stddev=500.122909 entropy=0.583709 frames=4638 count=61
2017/08/29 21:33:04 Training policy...
2017/08/29 21:33:07 tune 0: objective=10.759830 reg=0.005837 prune=0
2017/08/29 21:33:08 step 0: objective=10.765252 reg=0.005837
2017/08/29 21:33:08 step 1: objective=10.780627 reg=0.005837
2017/08/29 21:33:09 step 2: objective=10.797987 reg=0.005837
2017/08/29 21:33:10 step 3: objective=10.816887 reg=0.005837
2017/08/29 21:33:11 step 4: objective=10.832778 reg=0.005837
2017/08/29 21:33:11 step 5: objective=10.851584 reg=0.005838
2017/08/29 21:33:12 step 6: objective=10.870484 reg=0.005838
2017/08/29 21:33:13 step 7: objective=10.886777 reg=0.005838
2017/08/29 21:33:13 Training value function...
2017/08/29 21:33:15 step 0: mse=14508.790562 step=0.050000
2017/08/29 21:33:15 step 1: mse=14528.155733 step=0.050000
2017/08/29 21:33:16 step 2: mse=14560.705926 step=0.050000
2017/08/29 21:33:17 step 3: mse=14572.772973 step=0.050000
2017/08/29 21:33:18 step 4: mse=14607.141440 step=0.050000
2017/08/29 21:33:18 step 5: mse=14631.191814 step=0.050000
2017/08/29 21:33:19 step 6: mse=14652.327284 step=0.050000
2017/08/29 21:33:20 step 7: mse=14675.027601 step=0.050000
2017/08/29 21:33:20 Saving...
2017/08/29 21:33:20 Gathering batch of experience...
2017/08/29 21:33:43 batch 163: mean=971.083333 stddev=541.884898 entropy=0.583797 frames=4873 count=60
2017/08/29 21:33:43 Training policy...
2017/08/29 21:33:45 tune 0: objective=22.884943 reg=0.005838 prune=0
2017/08/29 21:33:46 step 0: objective=22.894643 reg=0.005837
2017/08/29 21:33:47 step 1: objective=22.909881 reg=0.005836
2017/08/29 21:33:48 step 2: objective=22.929817 reg=0.005835
2017/08/29 21:33:49 step 3: objective=22.944702 reg=0.005834
2017/08/29 21:33:49 step 4: objective=22.966937 reg=0.005833
2017/08/29 21:33:50 step 5: objective=22.984245 reg=0.005832
2017/08/29 21:33:51 step 6: objective=23.005722 reg=0.005830
2017/08/29 21:33:52 step 7: objective=23.030357 reg=0.005829
2017/08/29 21:33:52 Training value function...
2017/08/29 21:33:54 step 0: mse=16860.824856 step=0.050000
2017/08/29 21:33:54 step 1: mse=16799.448525 step=0.050000
2017/08/29 21:33:55 step 2: mse=16752.296025 step=0.050000
2017/08/29 21:33:56 step 3: mse=16701.601075 step=0.050000
2017/08/29 21:33:57 step 4: mse=16656.391639 step=0.050000
2017/08/29 21:33:57 step 5: mse=16613.397145 step=0.050000
2017/08/29 21:33:58 step 6: mse=16571.358429 step=0.050000
2017/08/29 21:33:59 step 7: mse=16536.715038 step=0.050000
2017/08/29 21:33:59 Saving...
2017/08/29 21:33:59 Gathering batch of experience...
2017/08/29 21:34:22 batch 164: mean=877.031250 stddev=493.325544 entropy=0.578082 frames=4709 count=64
2017/08/29 21:34:22 Training policy...
2017/08/29 21:34:24 tune 0: objective=15.785164 reg=0.005781 prune=0
2017/08/29 21:34:25 step 0: objective=15.792678 reg=0.005780
2017/08/29 21:34:26 step 1: objective=15.816810 reg=0.005779
2017/08/29 21:34:26 step 2: objective=15.827505 reg=0.005778
2017/08/29 21:34:27 step 3: objective=15.841386 reg=0.005777
2017/08/29 21:34:28 step 4: objective=15.861718 reg=0.005778
2017/08/29 21:34:29 step 5: objective=15.875141 reg=0.005777
2017/08/29 21:34:29 step 6: objective=15.890945 reg=0.005777
2017/08/29 21:34:30 step 7: objective=15.910457 reg=0.005776
2017/08/29 21:34:30 Training value function...
2017/08/29 21:34:32 step 0: mse=14746.032797 step=0.050000
2017/08/29 21:34:33 step 1: mse=14745.636420 step=0.050000
2017/08/29 21:34:34 step 2: mse=14751.312590 step=0.050000
2017/08/29 21:34:34 step 3: mse=14759.162380 step=0.050000
2017/08/29 21:34:35 step 4: mse=14761.878884 step=0.050000
2017/08/29 21:34:36 step 5: mse=14772.511616 step=0.050000
2017/08/29 21:34:36 step 6: mse=14783.215169 step=0.050000
2017/08/29 21:34:37 step 7: mse=14793.078906 step=0.050000
2017/08/29 21:34:37 Saving...
2017/08/29 21:34:37 Gathering batch of experience...
2017/08/29 21:35:00 batch 165: mean=839.538462 stddev=491.802589 entropy=0.581492 frames=4667 count=65
2017/08/29 21:35:00 Training policy...
2017/08/29 21:35:02 tune 0: objective=14.895597 reg=0.005815 prune=0
2017/08/29 21:35:03 step 0: objective=14.901933 reg=0.005813
2017/08/29 21:35:04 step 1: objective=14.913107 reg=0.005812
2017/08/29 21:35:05 step 2: objective=14.930535 reg=0.005811
2017/08/29 21:35:05 step 3: objective=14.941405 reg=0.005811
2017/08/29 21:35:06 step 4: objective=14.949799 reg=0.005810
2017/08/29 21:35:07 step 5: objective=14.965970 reg=0.005810
2017/08/29 21:35:07 step 6: objective=14.975183 reg=0.005809
2017/08/29 21:35:08 step 7: objective=14.991024 reg=0.005808
2017/08/29 21:35:08 Training value function...
2017/08/29 21:35:10 step 0: mse=14369.195544 step=0.050000
2017/08/29 21:35:11 step 1: mse=14386.907885 step=0.050000
2017/08/29 21:35:12 step 2: mse=14407.221545 step=0.050000
2017/08/29 21:35:12 step 3: mse=14430.202511 step=0.050000
2017/08/29 21:35:13 step 4: mse=14451.579927 step=0.050000
2017/08/29 21:35:14 step 5: mse=14472.038897 step=0.050000
2017/08/29 21:35:14 step 6: mse=14494.161519 step=0.050000
2017/08/29 21:35:15 step 7: mse=14512.604431 step=0.050000
2017/08/29 21:35:15 Saving...
2017/08/29 21:35:15 Gathering batch of experience...
2017/08/29 21:35:38 batch 166: mean=887.031250 stddev=499.632458 entropy=0.579616 frames=4833 count=64
2017/08/29 21:35:38 Training policy...
2017/08/29 21:35:41 tune 0: objective=19.393968 reg=0.005796 prune=0
2017/08/29 21:35:42 step 0: objective=19.400400 reg=0.005795
2017/08/29 21:35:43 step 1: objective=19.425405 reg=0.005794
2017/08/29 21:35:43 step 2: objective=19.441837 reg=0.005794
2017/08/29 21:35:44 step 3: objective=19.462496 reg=0.005793
2017/08/29 21:35:45 step 4: objective=19.483885 reg=0.005792
2017/08/29 21:35:46 step 5: objective=19.501649 reg=0.005792
2017/08/29 21:35:47 step 6: objective=19.519509 reg=0.005791
2017/08/29 21:35:47 step 7: objective=19.532912 reg=0.005790
2017/08/29 21:35:47 Training value function...
2017/08/29 21:35:49 step 0: mse=15422.058389 step=0.050000
2017/08/29 21:35:50 step 1: mse=15414.820770 step=0.050000
2017/08/29 21:35:51 step 2: mse=15414.684626 step=0.050000
2017/08/29 21:35:51 step 3: mse=15411.824963 step=0.050000
2017/08/29 21:35:52 step 4: mse=15409.244877 step=0.050000
2017/08/29 21:35:53 step 5: mse=15405.263386 step=0.050000
2017/08/29 21:35:54 step 6: mse=15404.694460 step=0.050000
2017/08/29 21:35:54 step 7: mse=15405.204343 step=0.050000
2017/08/29 21:35:54 Saving...
2017/08/29 21:35:55 Gathering batch of experience...
2017/08/29 21:36:17 batch 167: mean=849.846154 stddev=495.341350 entropy=0.580657 frames=4736 count=65
2017/08/29 21:36:17 Training policy...
2017/08/29 21:36:20 tune 0: objective=17.042527 reg=0.005807 prune=0
2017/08/29 21:36:21 step 0: objective=17.051524 reg=0.005805
2017/08/29 21:36:21 step 1: objective=17.070720 reg=0.005803
2017/08/29 21:36:22 step 2: objective=17.090426 reg=0.005801
2017/08/29 21:36:23 step 3: objective=17.109984 reg=0.005800
2017/08/29 21:36:24 step 4: objective=17.123766 reg=0.005799
2017/08/29 21:36:24 step 5: objective=17.145257 reg=0.005797
2017/08/29 21:36:25 step 6: objective=17.167212 reg=0.005795
2017/08/29 21:36:26 step 7: objective=17.187599 reg=0.005793
2017/08/29 21:36:26 Training value function...
2017/08/29 21:36:28 step 0: mse=15515.142256 step=0.050000
2017/08/29 21:36:29 step 1: mse=15530.099902 step=0.050000
2017/08/29 21:36:29 step 2: mse=15530.892240 step=0.050000
2017/08/29 21:36:30 step 3: mse=15521.745563 step=0.050000
2017/08/29 21:36:31 step 4: mse=15522.036248 step=0.050000
2017/08/29 21:36:31 step 5: mse=15516.296081 step=0.050000
2017/08/29 21:36:32 step 6: mse=15516.286537 step=0.050000
2017/08/29 21:36:33 step 7: mse=15520.621677 step=0.050000
2017/08/29 21:36:33 Saving...
2017/08/29 21:36:33 Gathering batch of experience...
2017/08/29 21:36:56 batch 168: mean=962.622951 stddev=480.326568 entropy=0.573325 frames=4884 count=61
2017/08/29 21:36:56 Training policy...
2017/08/29 21:36:59 tune 0: objective=27.357590 reg=0.005733 prune=0
2017/08/29 21:37:00 step 0: objective=27.363265 reg=0.005732
2017/08/29 21:37:00 step 1: objective=27.386328 reg=0.005731
2017/08/29 21:37:01 step 2: objective=27.402113 reg=0.005730
2017/08/29 21:37:02 step 3: objective=27.423411 reg=0.005730
2017/08/29 21:37:03 step 4: objective=27.435628 reg=0.005728
2017/08/29 21:37:03 step 5: objective=27.448633 reg=0.005728
2017/08/29 21:37:04 step 6: objective=27.464709 reg=0.005727
2017/08/29 21:37:05 step 7: objective=27.481384 reg=0.005726
2017/08/29 21:37:05 Training value function...
2017/08/29 21:37:07 step 0: mse=15346.402706 step=0.050000
2017/08/29 21:37:08 step 1: mse=15222.732309 step=0.050000
2017/08/29 21:37:08 step 2: mse=15100.426918 step=0.050000
2017/08/29 21:37:09 step 3: mse=14997.491041 step=0.050000
2017/08/29 21:37:10 step 4: mse=14898.526802 step=0.050000
2017/08/29 21:37:11 step 5: mse=14814.058432 step=0.050000
2017/08/29 21:37:11 step 6: mse=14726.267307 step=0.050000
2017/08/29 21:37:12 step 7: mse=14648.067922 step=0.050000
2017/08/29 21:37:12 Saving...
2017/08/29 21:37:12 Gathering batch of experience...
2017/08/29 21:37:35 batch 169: mean=962.457627 stddev=510.427183 entropy=0.574168 frames=4742 count=59
2017/08/29 21:37:35 Training policy...
2017/08/29 21:37:37 tune 0: objective=24.553608 reg=0.005742 prune=0
2017/08/29 21:37:38 step 0: objective=24.563068 reg=0.005740
2017/08/29 21:37:39 step 1: objective=24.583320 reg=0.005740
2017/08/29 21:37:40 step 2: objective=24.599108 reg=0.005740
2017/08/29 21:37:41 step 3: objective=24.615619 reg=0.005738
2017/08/29 21:37:41 step 4: objective=24.634816 reg=0.005738
2017/08/29 21:37:42 step 5: objective=24.652798 reg=0.005737
2017/08/29 21:37:43 step 6: objective=24.667498 reg=0.005737
2017/08/29 21:37:44 step 7: objective=24.686782 reg=0.005736
2017/08/29 21:37:44 Training value function...
2017/08/29 21:37:45 step 0: mse=16484.702647 step=0.050000
2017/08/29 21:37:46 step 1: mse=16428.849084 step=0.050000
2017/08/29 21:37:47 step 2: mse=16376.581196 step=0.050000
2017/08/29 21:37:48 step 3: mse=16320.215973 step=0.050000
2017/08/29 21:37:48 step 4: mse=16278.677812 step=0.050000
2017/08/29 21:37:49 step 5: mse=16236.686918 step=0.050000
2017/08/29 21:37:50 step 6: mse=16184.691572 step=0.050000
2017/08/29 21:37:51 step 7: mse=16141.453699 step=0.050000
2017/08/29 21:37:51 Saving...
2017/08/29 21:37:51 Gathering batch of experience...
2017/08/29 21:38:13 batch 170: mean=1127.924528 stddev=510.568897 entropy=0.570171 frames=4832 count=53
2017/08/29 21:38:13 Training policy...
2017/08/29 21:38:15 tune 0: objective=34.741308 reg=0.005702 prune=0
2017/08/29 21:38:16 step 0: objective=34.750000 reg=0.005701
2017/08/29 21:38:17 step 1: objective=34.766960 reg=0.005701
2017/08/29 21:38:18 step 2: objective=34.787873 reg=0.005701
2017/08/29 21:38:19 step 3: objective=34.802482 reg=0.005701
2017/08/29 21:38:19 step 4: objective=34.816558 reg=0.005701
2017/08/29 21:38:20 step 5: objective=34.837887 reg=0.005700
2017/08/29 21:38:21 step 6: objective=34.855194 reg=0.005700
2017/08/29 21:38:22 step 7: objective=34.873128 reg=0.005701
2017/08/29 21:38:22 Training value function...
2017/08/29 21:38:24 step 0: mse=18452.871713 step=0.050000
2017/08/29 21:38:24 step 1: mse=18179.108963 step=0.050000
2017/08/29 21:38:25 step 2: mse=17922.522514 step=0.050000
2017/08/29 21:38:26 step 3: mse=17686.786118 step=0.050000
2017/08/29 21:38:27 step 4: mse=17472.404037 step=0.050000
2017/08/29 21:38:27 step 5: mse=17270.640998 step=0.050000
2017/08/29 21:38:28 step 6: mse=17081.291008 step=0.050000
2017/08/29 21:38:29 step 7: mse=16907.716535 step=0.050000
2017/08/29 21:38:29 Saving...
2017/08/29 21:38:29 Gathering batch of experience...
2017/08/29 21:38:51 batch 171: mean=968.620690 stddev=540.153070 entropy=0.575685 frames=4676 count=58
2017/08/29 21:38:51 Training policy...
2017/08/29 21:38:54 tune 0: objective=20.066632 reg=0.005757 prune=0
2017/08/29 21:38:54 step 0: objective=20.073388 reg=0.005756
2017/08/29 21:38:55 step 1: objective=20.089607 reg=0.005755
2017/08/29 21:38:56 step 2: objective=20.106620 reg=0.005754
2017/08/29 21:38:57 step 3: objective=20.125306 reg=0.005753
2017/08/29 21:38:57 step 4: objective=20.141866 reg=0.005752
2017/08/29 21:38:58 step 5: objective=20.157618 reg=0.005751
2017/08/29 21:38:59 step 6: objective=20.174919 reg=0.005750
2017/08/29 21:39:00 step 7: objective=20.197725 reg=0.005748
2017/08/29 21:39:00 Training value function...
2017/08/29 21:39:02 step 0: mse=15753.605395 step=0.050000
2017/08/29 21:39:02 step 1: mse=15752.294668 step=0.050000
2017/08/29 21:39:03 step 2: mse=15744.221878 step=0.050000
2017/08/29 21:39:04 step 3: mse=15741.591199 step=0.050000
2017/08/29 21:39:04 step 4: mse=15740.055483 step=0.050000
2017/08/29 21:39:05 step 5: mse=15740.579403 step=0.050000
2017/08/29 21:39:06 step 6: mse=15740.746070 step=0.050000
2017/08/29 21:39:07 step 7: mse=15743.449713 step=0.050000
2017/08/29 21:39:07 Saving...
2017/08/29 21:39:07 Gathering batch of experience...
2017/08/29 21:39:30 batch 172: mean=821.029412 stddev=480.010385 entropy=0.580280 frames=4844 count=68
2017/08/29 21:39:30 Training policy...
2017/08/29 21:39:33 tune 0: objective=7.951840 reg=0.005803 prune=0
2017/08/29 21:39:34 step 0: objective=7.958316 reg=0.005803
2017/08/29 21:39:35 step 1: objective=7.973141 reg=0.005803
2017/08/29 21:39:35 step 2: objective=7.991375 reg=0.005803
2017/08/29 21:39:36 step 3: objective=8.007132 reg=0.005804
2017/08/29 21:39:37 step 4: objective=8.023375 reg=0.005805
2017/08/29 21:39:38 step 5: objective=8.042338 reg=0.005806
2017/08/29 21:39:38 step 6: objective=8.056824 reg=0.005806
2017/08/29 21:39:39 step 7: objective=8.072777 reg=0.005806
2017/08/29 21:39:39 Training value function...
2017/08/29 21:39:41 step 0: mse=14176.341698 step=0.050000
2017/08/29 21:39:42 step 1: mse=14192.880838 step=0.050000
2017/08/29 21:39:43 step 2: mse=14215.085470 step=0.050000
2017/08/29 21:39:43 step 3: mse=14245.033888 step=0.050000
2017/08/29 21:39:44 step 4: mse=14269.467624 step=0.050000
2017/08/29 21:39:45 step 5: mse=14299.449252 step=0.050000
2017/08/29 21:39:46 step 6: mse=14319.180861 step=0.050000
2017/08/29 21:39:46 step 7: mse=14350.061076 step=0.050000
2017/08/29 21:39:46 Saving...
2017/08/29 21:39:46 Gathering batch of experience...
2017/08/29 21:40:09 batch 173: mean=1045.909091 stddev=530.506697 entropy=0.573531 frames=4756 count=55
2017/08/29 21:40:09 Training policy...
2017/08/29 21:40:11 tune 0: objective=29.281398 reg=0.005735 prune=0
2017/08/29 21:40:12 step 0: objective=29.289427 reg=0.005734
2017/08/29 21:40:13 step 1: objective=29.301251 reg=0.005734
2017/08/29 21:40:14 step 2: objective=29.316787 reg=0.005733
2017/08/29 21:40:14 step 3: objective=29.330566 reg=0.005732
2017/08/29 21:40:15 step 4: objective=29.351963 reg=0.005731
2017/08/29 21:40:16 step 5: objective=29.370962 reg=0.005730
2017/08/29 21:40:17 step 6: objective=29.390011 reg=0.005729
2017/08/29 21:40:17 step 7: objective=29.409568 reg=0.005727
2017/08/29 21:40:17 Training value function...
2017/08/29 21:40:19 step 0: mse=17380.509416 step=0.050000
2017/08/29 21:40:20 step 1: mse=17242.879112 step=0.050000
2017/08/29 21:40:21 step 2: mse=17108.247031 step=0.050000
2017/08/29 21:40:21 step 3: mse=16988.160682 step=0.050000
2017/08/29 21:40:22 step 4: mse=16876.092461 step=0.050000
2017/08/29 21:40:23 step 5: mse=16773.019293 step=0.050000
2017/08/29 21:40:24 step 6: mse=16673.702962 step=0.050000
2017/08/29 21:40:24 step 7: mse=16580.323540 step=0.050000
2017/08/29 21:40:24 Saving...
2017/08/29 21:40:24 Gathering batch of experience...
2017/08/29 21:40:47 batch 174: mean=890.564516 stddev=487.592096 entropy=0.573069 frames=4689 count=62
2017/08/29 21:40:47 Training policy...
2017/08/29 21:40:49 tune 0: objective=16.185377 reg=0.005731 prune=0
2017/08/29 21:40:50 step 0: objective=16.191829 reg=0.005730
2017/08/29 21:40:51 step 1: objective=16.211299 reg=0.005729
2017/08/29 21:40:52 step 2: objective=16.230941 reg=0.005729
2017/08/29 21:40:52 step 3: objective=16.248955 reg=0.005728
2017/08/29 21:40:53 step 4: objective=16.265055 reg=0.005727
2017/08/29 21:40:54 step 5: objective=16.285300 reg=0.005727
2017/08/29 21:40:55 step 6: objective=16.302650 reg=0.005726
2017/08/29 21:40:55 step 7: objective=16.321580 reg=0.005725
2017/08/29 21:40:55 Training value function...
2017/08/29 21:40:57 step 0: mse=14173.834875 step=0.050000
2017/08/29 21:40:58 step 1: mse=14189.813029 step=0.050000
2017/08/29 21:40:59 step 2: mse=14200.886492 step=0.050000
2017/08/29 21:40:59 step 3: mse=14215.592003 step=0.050000
2017/08/29 21:41:00 step 4: mse=14227.854396 step=0.050000
2017/08/29 21:41:01 step 5: mse=14242.687390 step=0.050000
2017/08/29 21:41:02 step 6: mse=14253.560743 step=0.050000
2017/08/29 21:41:02 step 7: mse=14264.166872 step=0.050000
2017/08/29 21:41:02 Saving...
2017/08/29 21:41:02 Gathering batch of experience...
2017/08/29 21:41:26 batch 175: mean=1013.666667 stddev=531.563626 entropy=0.572763 frames=5041 count=60
2017/08/29 21:41:26 Training policy...
2017/08/29 21:41:29 tune 0: objective=27.722150 reg=0.005728 prune=0
2017/08/29 21:41:30 step 0: objective=27.727565 reg=0.005727
2017/08/29 21:41:30 step 1: objective=27.740363 reg=0.005726
2017/08/29 21:41:31 step 2: objective=27.750329 reg=0.005725
2017/08/29 21:41:32 step 3: objective=27.760399 reg=0.005725
2017/08/29 21:41:33 step 4: objective=27.771121 reg=0.005724
2017/08/29 21:41:34 step 5: objective=27.784343 reg=0.005723
2017/08/29 21:41:34 step 6: objective=27.794535 reg=0.005723
2017/08/29 21:41:35 step 7: objective=27.805083 reg=0.005722
2017/08/29 21:41:35 Training value function...
2017/08/29 21:41:37 step 0: mse=16427.971149 step=0.050000
2017/08/29 21:41:38 step 1: mse=16289.349943 step=0.050000
2017/08/29 21:41:39 step 2: mse=16155.255327 step=0.050000
2017/08/29 21:41:40 step 3: mse=16033.711713 step=0.050000
2017/08/29 21:41:40 step 4: mse=15922.954543 step=0.050000
2017/08/29 21:41:41 step 5: mse=15820.953132 step=0.050000
2017/08/29 21:41:42 step 6: mse=15725.869266 step=0.050000
2017/08/29 21:41:43 step 7: mse=15636.790567 step=0.050000
2017/08/29 21:41:43 Saving...
2017/08/29 21:41:43 Gathering batch of experience...
2017/08/29 21:42:05 batch 176: mean=1055.277778 stddev=474.913654 entropy=0.566537 frames=4684 count=54
2017/08/29 21:42:05 Training policy...
2017/08/29 21:42:07 tune 0: objective=25.953312 reg=0.005665 prune=0
2017/08/29 21:42:08 step 0: objective=25.959605 reg=0.005665
2017/08/29 21:42:09 step 1: objective=25.974891 reg=0.005664
2017/08/29 21:42:10 step 2: objective=25.988793 reg=0.005664
2017/08/29 21:42:11 step 3: objective=26.001301 reg=0.005664
2017/08/29 21:42:11 step 4: objective=26.015575 reg=0.005663
2017/08/29 21:42:12 step 5: objective=26.028688 reg=0.005663
2017/08/29 21:42:13 step 6: objective=26.043336 reg=0.005663
2017/08/29 21:42:14 step 7: objective=26.055491 reg=0.005662
2017/08/29 21:42:14 Training value function...
2017/08/29 21:42:15 step 0: mse=14756.404288 step=0.050000
2017/08/29 21:42:16 step 1: mse=14692.780445 step=0.050000
2017/08/29 21:42:17 step 2: mse=14627.715773 step=0.050000
2017/08/29 21:42:18 step 3: mse=14572.239315 step=0.050000
2017/08/29 21:42:18 step 4: mse=14521.448986 step=0.050000
2017/08/29 21:42:19 step 5: mse=14471.642722 step=0.050000
2017/08/29 21:42:20 step 6: mse=14422.946020 step=0.050000
2017/08/29 21:42:20 step 7: mse=14377.468461 step=0.050000
2017/08/29 21:42:20 Saving...
2017/08/29 21:42:20 Gathering batch of experience...
2017/08/29 21:42:43 batch 177: mean=1018.620690 stddev=510.246554 entropy=0.569760 frames=4918 count=58
2017/08/29 21:42:43 Training policy...
2017/08/29 21:42:46 tune 0: objective=22.477338 reg=0.005698 prune=0
2017/08/29 21:42:47 step 0: objective=22.483694 reg=0.005697
2017/08/29 21:42:48 step 1: objective=22.499733 reg=0.005697
2017/08/29 21:42:48 step 2: objective=22.513606 reg=0.005697
2017/08/29 21:42:49 step 3: objective=22.527059 reg=0.005697
2017/08/29 21:42:50 step 4: objective=22.536943 reg=0.005697
2017/08/29 21:42:51 step 5: objective=22.550275 reg=0.005698
2017/08/29 21:42:52 step 6: objective=22.562336 reg=0.005698
2017/08/29 21:42:52 step 7: objective=22.574972 reg=0.005698
2017/08/29 21:42:52 Training value function...
2017/08/29 21:42:54 step 0: mse=15650.078396 step=0.050000
2017/08/29 21:42:55 step 1: mse=15630.673489 step=0.050000
2017/08/29 21:42:56 step 2: mse=15614.233004 step=0.050000
2017/08/29 21:42:57 step 3: mse=15595.102205 step=0.050000
2017/08/29 21:42:57 step 4: mse=15577.997626 step=0.050000
2017/08/29 21:42:58 step 5: mse=15563.778448 step=0.050000
2017/08/29 21:42:59 step 6: mse=15549.367453 step=0.050000
2017/08/29 21:43:00 step 7: mse=15536.830685 step=0.050000
2017/08/29 21:43:00 Saving...
2017/08/29 21:43:00 Gathering batch of experience...
2017/08/29 21:43:23 batch 178: mean=924.666667 stddev=566.161687 entropy=0.574608 frames=4658 count=60
2017/08/29 21:43:23 Training policy...
2017/08/29 21:43:25 tune 0: objective=18.343228 reg=0.005746 prune=0
2017/08/29 21:43:26 step 0: objective=18.349768 reg=0.005745
2017/08/29 21:43:27 step 1: objective=18.369453 reg=0.005744
2017/08/29 21:43:27 step 2: objective=18.395670 reg=0.005743
2017/08/29 21:43:28 step 3: objective=18.416582 reg=0.005743
2017/08/29 21:43:29 step 4: objective=18.434947 reg=0.005742
2017/08/29 21:43:30 step 5: objective=18.451787 reg=0.005741
2017/08/29 21:43:30 step 6: objective=18.470446 reg=0.005740
2017/08/29 21:43:31 step 7: objective=18.491429 reg=0.005739
2017/08/29 21:43:31 Training value function...
2017/08/29 21:43:33 step 0: mse=17449.558200 step=0.050000
2017/08/29 21:43:34 step 1: mse=17439.587344 step=0.050000
2017/08/29 21:43:35 step 2: mse=17432.371486 step=0.050000
2017/08/29 21:43:35 step 3: mse=17427.364828 step=0.050000
2017/08/29 21:43:36 step 4: mse=17419.659188 step=0.050000
2017/08/29 21:43:37 step 5: mse=17410.482062 step=0.050000
2017/08/29 21:43:37 step 6: mse=17405.775448 step=0.050000
2017/08/29 21:43:38 step 7: mse=17404.748687 step=0.050000
2017/08/29 21:43:38 Saving...
2017/08/29 21:43:38 Gathering batch of experience...
2017/08/29 21:44:01 batch 179: mean=915.806452 stddev=525.034710 entropy=0.571877 frames=4791 count=62
2017/08/29 21:44:01 Training policy...
2017/08/29 21:44:04 tune 0: objective=17.371515 reg=0.005719 prune=0
2017/08/29 21:44:04 step 0: objective=17.377562 reg=0.005718
2017/08/29 21:44:05 step 1: objective=17.389756 reg=0.005717
2017/08/29 21:44:06 step 2: objective=17.405893 reg=0.005716
2017/08/29 21:44:07 step 3: objective=17.418811 reg=0.005716
2017/08/29 21:44:07 step 4: objective=17.438002 reg=0.005715
2017/08/29 21:44:08 step 5: objective=17.454637 reg=0.005714
2017/08/29 21:44:09 step 6: objective=17.465502 reg=0.005714
2017/08/29 21:44:10 step 7: objective=17.477898 reg=0.005713
2017/08/29 21:44:10 Training value function...
2017/08/29 21:44:12 step 0: mse=15554.358488 step=0.050000
2017/08/29 21:44:12 step 1: mse=15567.709111 step=0.050000
2017/08/29 21:44:13 step 2: mse=15583.114241 step=0.050000
2017/08/29 21:44:14 step 3: mse=15594.828394 step=0.050000
2017/08/29 21:44:15 step 4: mse=15607.006072 step=0.050000
2017/08/29 21:44:15 step 5: mse=15616.029213 step=0.050000
2017/08/29 21:44:16 step 6: mse=15630.762371 step=0.050000
2017/08/29 21:44:17 step 7: mse=15646.574643 step=0.050000
2017/08/29 21:44:17 Saving...
2017/08/29 21:44:17 Gathering batch of experience...
2017/08/29 21:44:40 batch 180: mean=1030.789474 stddev=509.672056 entropy=0.569800 frames=4920 count=57
2017/08/29 21:44:40 Training policy...
2017/08/29 21:44:43 tune 0: objective=25.098109 reg=0.005698 prune=0
2017/08/29 21:44:43 step 0: objective=25.103701 reg=0.005697
2017/08/29 21:44:44 step 1: objective=25.117746 reg=0.005696
2017/08/29 21:44:45 step 2: objective=25.127533 reg=0.005696
2017/08/29 21:44:46 step 3: objective=25.141052 reg=0.005696
2017/08/29 21:44:47 step 4: objective=25.153127 reg=0.005695
2017/08/29 21:44:47 step 5: objective=25.165654 reg=0.005694
2017/08/29 21:44:48 step 6: objective=25.180739 reg=0.005693
2017/08/29 21:44:49 step 7: objective=25.190581 reg=0.005692
2017/08/29 21:44:49 Training value function...
2017/08/29 21:44:51 step 0: mse=15289.062761 step=0.050000
2017/08/29 21:44:52 step 1: mse=15205.797038 step=0.050000
2017/08/29 21:44:53 step 2: mse=15130.131277 step=0.050000
2017/08/29 21:44:53 step 3: mse=15060.157721 step=0.050000
2017/08/29 21:44:54 step 4: mse=14995.053967 step=0.050000
2017/08/29 21:44:55 step 5: mse=14934.228975 step=0.050000
2017/08/29 21:44:56 step 6: mse=14880.929081 step=0.050000
2017/08/29 21:44:56 step 7: mse=14829.519412 step=0.050000
2017/08/29 21:44:56 Saving...
2017/08/29 21:44:56 Gathering batch of experience...
2017/08/29 21:45:19 batch 181: mean=1046.071429 stddev=488.686938 entropy=0.565560 frames=4811 count=56
2017/08/29 21:45:19 Training policy...
2017/08/29 21:45:22 tune 0: objective=25.426961 reg=0.005656 prune=0
2017/08/29 21:45:23 step 0: objective=25.432141 reg=0.005655
2017/08/29 21:45:23 step 1: objective=25.440446 reg=0.005654
2017/08/29 21:45:24 step 2: objective=25.451287 reg=0.005653
2017/08/29 21:45:25 step 3: objective=25.459734 reg=0.005653
2017/08/29 21:45:26 step 4: objective=25.470902 reg=0.005652
2017/08/29 21:45:26 step 5: objective=25.479867 reg=0.005652
2017/08/29 21:45:27 step 6: objective=25.490932 reg=0.005651
2017/08/29 21:45:28 step 7: objective=25.502876 reg=0.005650
2017/08/29 21:45:28 Training value function...
2017/08/29 21:45:30 step 0: mse=14233.845336 step=0.050000
2017/08/29 21:45:31 step 1: mse=14150.086773 step=0.050000
2017/08/29 21:45:31 step 2: mse=14070.355722 step=0.050000
2017/08/29 21:45:32 step 3: mse=13998.108654 step=0.050000
2017/08/29 21:45:33 step 4: mse=13930.616411 step=0.050000
2017/08/29 21:45:34 step 5: mse=13868.168412 step=0.050000
2017/08/29 21:45:34 step 6: mse=13806.207663 step=0.050000
2017/08/29 21:45:35 step 7: mse=13748.082649 step=0.050000
2017/08/29 21:45:35 Saving...
2017/08/29 21:45:35 Gathering batch of experience...
2017/08/29 21:45:57 batch 182: mean=1416.960784 stddev=2561.414491 entropy=0.572495 frames=4881 count=51
2017/08/29 21:45:57 Training policy...
2017/08/29 21:46:00 tune 0: objective=64.359782 reg=0.005725 prune=0
2017/08/29 21:46:01 step 0: objective=64.411346 reg=0.005723
2017/08/29 21:46:02 step 1: objective=64.644662 reg=0.005725
2017/08/29 21:46:02 step 2: objective=64.811156 reg=0.005725
2017/08/29 21:46:03 step 3: objective=65.063377 reg=0.005725
2017/08/29 21:46:04 step 4: objective=65.351100 reg=0.005726
2017/08/29 21:46:05 step 5: objective=65.498912 reg=0.005723
2017/08/29 21:46:06 step 6: objective=65.622996 reg=0.005724
2017/08/29 21:46:06 step 7: objective=65.698038 reg=0.005723
2017/08/29 21:46:06 Training value function...
2017/08/29 21:46:08 step 0: mse=266870.179212 step=0.050000
2017/08/29 21:46:09 step 1: mse=260482.534033 step=0.050000
2017/08/29 21:46:10 step 2: mse=247593.238953 step=0.050000
2017/08/29 21:46:11 step 3: mse=240118.265789 step=0.050000
2017/08/29 21:46:11 step 4: mse=235026.174410 step=0.050000
2017/08/29 21:46:12 step 5: mse=225946.526533 step=0.050000
2017/08/29 21:46:13 step 6: mse=221958.301870 step=0.050000
2017/08/29 21:46:14 step 7: mse=219069.777689 step=0.050000
2017/08/29 21:46:14 Saving...
2017/08/29 21:46:14 Gathering batch of experience...
2017/08/29 21:46:36 batch 183: mean=1033.245614 stddev=478.660862 entropy=0.564577 frames=4811 count=57
2017/08/29 21:46:36 Training policy...
2017/08/29 21:46:39 tune 0: objective=16.309663 reg=0.005646 prune=0
2017/08/29 21:46:40 step 0: objective=16.315665 reg=0.005646
2017/08/29 21:46:41 step 1: objective=16.327326 reg=0.005647
2017/08/29 21:46:41 step 2: objective=16.337548 reg=0.005647
2017/08/29 21:46:42 step 3: objective=16.346002 reg=0.005648
2017/08/29 21:46:43 step 4: objective=16.356670 reg=0.005648
2017/08/29 21:46:44 step 5: objective=16.369920 reg=0.005649
2017/08/29 21:46:44 step 6: objective=16.378998 reg=0.005649
2017/08/29 21:46:45 step 7: objective=16.388090 reg=0.005649
2017/08/29 21:46:45 Training value function...
2017/08/29 21:46:47 step 0: mse=13097.510148 step=0.050000
2017/08/29 21:46:48 step 1: mse=13118.028892 step=0.050000
2017/08/29 21:46:49 step 2: mse=13129.932554 step=0.050000
2017/08/29 21:46:49 step 3: mse=13147.723476 step=0.050000
2017/08/29 21:46:50 step 4: mse=13165.712599 step=0.050000
2017/08/29 21:46:51 step 5: mse=13185.310433 step=0.050000
2017/08/29 21:46:52 step 6: mse=13196.706041 step=0.050000
2017/08/29 21:46:52 step 7: mse=13213.667603 step=0.050000
2017/08/29 21:46:52 Saving...
2017/08/29 21:46:52 Gathering batch of experience...
2017/08/29 21:47:15 batch 184: mean=1061.071429 stddev=659.588423 entropy=0.572498 frames=4819 count=56
2017/08/29 21:47:15 Training policy...
2017/08/29 21:47:18 tune 0: objective=19.370018 reg=0.005725 prune=0
2017/08/29 21:47:18 step 0: objective=19.380930 reg=0.005724
2017/08/29 21:47:19 step 1: objective=19.397476 reg=0.005723
2017/08/29 21:47:20 step 2: objective=19.418845 reg=0.005722
2017/08/29 21:47:21 step 3: objective=19.437589 reg=0.005721
2017/08/29 21:47:21 step 4: objective=19.454218 reg=0.005720
2017/08/29 21:47:22 step 5: objective=19.470914 reg=0.005719
2017/08/29 21:47:23 step 6: objective=19.495162 reg=0.005719
2017/08/29 21:47:24 step 7: objective=19.514882 reg=0.005718
2017/08/29 21:47:24 Training value function...
2017/08/29 21:47:26 step 0: mse=19389.726856 step=0.050000
2017/08/29 21:47:27 step 1: mse=19297.064616 step=0.050000
2017/08/29 21:47:27 step 2: mse=19227.375585 step=0.050000
2017/08/29 21:47:28 step 3: mse=19161.660859 step=0.050000
2017/08/29 21:47:29 step 4: mse=19105.801703 step=0.050000
2017/08/29 21:47:30 step 5: mse=19057.003144 step=0.050000
2017/08/29 21:47:30 step 6: mse=19017.447816 step=0.050000
2017/08/29 21:47:31 step 7: mse=18971.555763 step=0.050000
2017/08/29 21:47:31 Saving...
2017/08/29 21:47:31 Gathering batch of experience...
2017/08/29 21:47:54 batch 185: mean=981.982759 stddev=516.993080 entropy=0.568296 frames=4762 count=58
2017/08/29 21:47:54 Training policy...
2017/08/29 21:47:56 tune 0: objective=15.144646 reg=0.005683 prune=0
2017/08/29 21:47:57 step 0: objective=15.158168 reg=0.005681
2017/08/29 21:47:58 step 1: objective=15.179955 reg=0.005681
2017/08/29 21:47:59 step 2: objective=15.204921 reg=0.005678
2017/08/29 21:48:00 step 3: objective=15.231765 reg=0.005676
2017/08/29 21:48:00 step 4: objective=15.254961 reg=0.005675
2017/08/29 21:48:01 step 5: objective=15.276983 reg=0.005674
2017/08/29 21:48:02 step 6: objective=15.296188 reg=0.005673
2017/08/29 21:48:03 step 7: objective=15.321896 reg=0.005671
2017/08/29 21:48:03 Training value function...
2017/08/29 21:48:05 step 0: mse=15308.449081 step=0.050000
2017/08/29 21:48:05 step 1: mse=15325.997346 step=0.050000
2017/08/29 21:48:06 step 2: mse=15344.564508 step=0.050000
2017/08/29 21:48:07 step 3: mse=15364.959283 step=0.050000
2017/08/29 21:48:07 step 4: mse=15385.151175 step=0.050000
2017/08/29 21:48:08 step 5: mse=15405.909082 step=0.050000
2017/08/29 21:48:09 step 6: mse=15427.342253 step=0.050000
2017/08/29 21:48:10 step 7: mse=15448.233032 step=0.050000
2017/08/29 21:48:10 Saving...
2017/08/29 21:48:10 Gathering batch of experience...
2017/08/29 21:48:32 batch 186: mean=1033.859649 stddev=499.890354 entropy=0.564464 frames=4913 count=57
2017/08/29 21:48:32 Training policy...
2017/08/29 21:48:35 tune 0: objective=19.305192 reg=0.005645 prune=0
2017/08/29 21:48:36 step 0: objective=19.311967 reg=0.005644
2017/08/29 21:48:37 step 1: objective=19.329367 reg=0.005645
2017/08/29 21:48:38 step 2: objective=19.348220 reg=0.005645
2017/08/29 21:48:38 step 3: objective=19.362667 reg=0.005645
2017/08/29 21:48:39 step 4: objective=19.377999 reg=0.005645
2017/08/29 21:48:40 step 5: objective=19.397677 reg=0.005645
2017/08/29 21:48:41 step 6: objective=19.417596 reg=0.005645
2017/08/29 21:48:42 step 7: objective=19.444416 reg=0.005646
2017/08/29 21:48:42 Training value function...
2017/08/29 21:48:43 step 0: mse=15738.798918 step=0.050000
2017/08/29 21:48:44 step 1: mse=15736.840055 step=0.050000
2017/08/29 21:48:45 step 2: mse=15734.861392 step=0.050000
2017/08/29 21:48:46 step 3: mse=15734.665376 step=0.050000
2017/08/29 21:48:47 step 4: mse=15733.035435 step=0.050000
2017/08/29 21:48:47 step 5: mse=15731.515882 step=0.050000
2017/08/29 21:48:48 step 6: mse=15735.487921 step=0.050000
2017/08/29 21:48:49 step 7: mse=15738.140253 step=0.050000
2017/08/29 21:48:49 Saving...
2017/08/29 21:48:49 Gathering batch of experience...
2017/08/29 21:49:11 batch 187: mean=1040.370370 stddev=557.407900 entropy=0.569752 frames=4696 count=54
2017/08/29 21:49:11 Training policy...
2017/08/29 21:49:14 tune 0: objective=22.557002 reg=0.005698 prune=0
2017/08/29 21:49:14 step 0: objective=22.563849 reg=0.005697
2017/08/29 21:49:15 step 1: objective=22.580750 reg=0.005696
2017/08/29 21:49:16 step 2: objective=22.598302 reg=0.005697
2017/08/29 21:49:17 step 3: objective=22.616238 reg=0.005697
2017/08/29 21:49:17 step 4: objective=22.633099 reg=0.005696
2017/08/29 21:49:18 step 5: objective=22.649823 reg=0.005696
2017/08/29 21:49:19 step 6: objective=22.666125 reg=0.005696
2017/08/29 21:49:20 step 7: objective=22.684371 reg=0.005695
2017/08/29 21:49:20 Training value function...
2017/08/29 21:49:22 step 0: mse=16670.621960 step=0.050000
2017/08/29 21:49:22 step 1: mse=16553.412983 step=0.050000
2017/08/29 21:49:23 step 2: mse=16446.098964 step=0.050000
2017/08/29 21:49:24 step 3: mse=16336.195351 step=0.050000
2017/08/29 21:49:24 step 4: mse=16259.650838 step=0.050000
2017/08/29 21:49:25 step 5: mse=16172.110695 step=0.050000
2017/08/29 21:49:26 step 6: mse=16103.121755 step=0.050000
2017/08/29 21:49:27 step 7: mse=16025.284784 step=0.050000
2017/08/29 21:49:27 Saving...
2017/08/29 21:49:27 Gathering batch of experience...
2017/08/29 21:49:50 batch 188: mean=984.333333 stddev=502.095166 entropy=0.566261 frames=4941 count=60
2017/08/29 21:49:50 Training policy...
2017/08/29 21:49:52 tune 0: objective=17.989449 reg=0.005663 prune=0
2017/08/29 21:49:53 step 0: objective=17.993497 reg=0.005662
2017/08/29 21:49:54 step 1: objective=18.002207 reg=0.005662
2017/08/29 21:49:55 step 2: objective=18.013951 reg=0.005662
2017/08/29 21:49:56 step 3: objective=18.023996 reg=0.005663
2017/08/29 21:49:56 step 4: objective=18.033239 reg=0.005664
2017/08/29 21:49:57 step 5: objective=18.043931 reg=0.005664
2017/08/29 21:49:58 step 6: objective=18.053940 reg=0.005664
2017/08/29 21:49:59 step 7: objective=18.063121 reg=0.005665
2017/08/29 21:49:59 Training value function...
2017/08/29 21:50:01 step 0: mse=13997.729073 step=0.050000
2017/08/29 21:50:02 step 1: mse=14006.656652 step=0.050000
2017/08/29 21:50:02 step 2: mse=14014.280399 step=0.050000
2017/08/29 21:50:03 step 3: mse=14023.604982 step=0.050000
2017/08/29 21:50:04 step 4: mse=14032.434801 step=0.050000
2017/08/29 21:50:05 step 5: mse=14039.921856 step=0.050000
2017/08/29 21:50:05 step 6: mse=14044.405167 step=0.050000
2017/08/29 21:50:06 step 7: mse=14051.201730 step=0.050000
2017/08/29 21:50:06 Saving...
2017/08/29 21:50:06 Gathering batch of experience...
2017/08/29 21:50:29 batch 189: mean=1013.389831 stddev=568.488511 entropy=0.569154 frames=4944 count=59
2017/08/29 21:50:29 Training policy...
2017/08/29 21:50:32 tune 0: objective=24.232926 reg=0.005692 prune=0
2017/08/29 21:50:33 step 0: objective=24.241974 reg=0.005691
2017/08/29 21:50:34 step 1: objective=24.261945 reg=0.005691
2017/08/29 21:50:35 step 2: objective=24.282844 reg=0.005690
2017/08/29 21:50:35 step 3: objective=24.301672 reg=0.005689
2017/08/29 21:50:36 step 4: objective=24.319684 reg=0.005688
2017/08/29 21:50:37 step 5: objective=24.333939 reg=0.005688
2017/08/29 21:50:38 step 6: objective=24.351562 reg=0.005688
2017/08/29 21:50:39 step 7: objective=24.370613 reg=0.005687
2017/08/29 21:50:39 Training value function...
2017/08/29 21:50:41 step 0: mse=16499.458534 step=0.050000
2017/08/29 21:50:41 step 1: mse=16431.753443 step=0.050000
2017/08/29 21:50:42 step 2: mse=16365.767158 step=0.050000
2017/08/29 21:50:43 step 3: mse=16301.664134 step=0.050000
2017/08/29 21:50:44 step 4: mse=16241.227748 step=0.050000
2017/08/29 21:50:44 step 5: mse=16185.656026 step=0.050000
2017/08/29 21:50:45 step 6: mse=16138.819974 step=0.050000
2017/08/29 21:50:46 step 7: mse=16091.481850 step=0.050000
2017/08/29 21:50:46 Saving...
2017/08/29 21:50:46 Gathering batch of experience...
2017/08/29 21:51:09 batch 190: mean=922.049180 stddev=523.879270 entropy=0.568708 frames=4717 count=61
2017/08/29 21:51:09 Training policy...
2017/08/29 21:51:11 tune 0: objective=15.662047 reg=0.005687 prune=0
2017/08/29 21:51:12 step 0: objective=15.670760 reg=0.005687
2017/08/29 21:51:13 step 1: objective=15.681099 reg=0.005686
2017/08/29 21:51:14 step 2: objective=15.689945 reg=0.005686
2017/08/29 21:51:14 step 3: objective=15.709223 reg=0.005685
2017/08/29 21:51:15 step 4: objective=15.720837 reg=0.005685
2017/08/29 21:51:16 step 5: objective=15.731965 reg=0.005684
2017/08/29 21:51:17 step 6: objective=15.745492 reg=0.005684
2017/08/29 21:51:17 step 7: objective=15.758477 reg=0.005684
2017/08/29 21:51:17 Training value function...
2017/08/29 21:51:19 step 0: mse=15229.347326 step=0.050000
2017/08/29 21:51:20 step 1: mse=15257.332151 step=0.050000
2017/08/29 21:51:21 step 2: mse=15268.604854 step=0.050000
2017/08/29 21:51:21 step 3: mse=15280.417052 step=0.050000
2017/08/29 21:51:22 step 4: mse=15298.404437 step=0.050000
2017/08/29 21:51:23 step 5: mse=15314.203347 step=0.050000
2017/08/29 21:51:24 step 6: mse=15322.143730 step=0.050000
2017/08/29 21:51:24 step 7: mse=15333.386195 step=0.050000
2017/08/29 21:51:24 Saving...
2017/08/29 21:51:24 Gathering batch of experience...
2017/08/29 21:51:46 batch 191: mean=1139.509804 stddev=520.009667 entropy=0.565888 frames=4790 count=51
2017/08/29 21:51:46 Training policy...
2017/08/29 21:51:49 tune 0: objective=29.789858 reg=0.005659 prune=0
2017/08/29 21:51:50 step 0: objective=29.799935 reg=0.005657
2017/08/29 21:51:51 step 1: objective=29.819970 reg=0.005655
2017/08/29 21:51:51 step 2: objective=29.836870 reg=0.005654
2017/08/29 21:51:52 step 3: objective=29.849341 reg=0.005653
2017/08/29 21:51:53 step 4: objective=29.868173 reg=0.005652
2017/08/29 21:51:54 step 5: objective=29.887617 reg=0.005650
2017/08/29 21:51:55 step 6: objective=29.908530 reg=0.005649
2017/08/29 21:51:55 step 7: objective=29.933103 reg=0.005647
2017/08/29 21:51:55 Training value function...
2017/08/29 21:51:57 step 0: mse=16591.069819 step=0.050000
2017/08/29 21:51:58 step 1: mse=16431.097970 step=0.050000
2017/08/29 21:51:59 step 2: mse=16282.764568 step=0.050000
2017/08/29 21:52:00 step 3: mse=16146.146285 step=0.050000
2017/08/29 21:52:00 step 4: mse=16019.559657 step=0.050000
2017/08/29 21:52:01 step 5: mse=15903.001539 step=0.050000
2017/08/29 21:52:02 step 6: mse=15789.389294 step=0.050000
2017/08/29 21:52:03 step 7: mse=15685.009476 step=0.050000
2017/08/29 21:52:03 Saving...
2017/08/29 21:52:03 Gathering batch of experience...
2017/08/29 21:52:25 batch 192: mean=1002.192982 stddev=537.670428 entropy=0.566512 frames=4736 count=57
2017/08/29 21:52:25 Training policy...
2017/08/29 21:52:27 tune 0: objective=20.809732 reg=0.005665 prune=0
2017/08/29 21:52:28 step 0: objective=20.816355 reg=0.005664
2017/08/29 21:52:29 step 1: objective=20.831320 reg=0.005663
2017/08/29 21:52:30 step 2: objective=20.845604 reg=0.005663
2017/08/29 21:52:30 step 3: objective=20.857485 reg=0.005662
2017/08/29 21:52:31 step 4: objective=20.876257 reg=0.005661
2017/08/29 21:52:32 step 5: objective=20.895768 reg=0.005661
2017/08/29 21:52:33 step 6: objective=20.909802 reg=0.005660
2017/08/29 21:52:33 step 7: objective=20.922660 reg=0.005660
2017/08/29 21:52:33 Training value function...
2017/08/29 21:52:35 step 0: mse=14904.935694 step=0.050000
2017/08/29 21:52:36 step 1: mse=14876.647955 step=0.050000
2017/08/29 21:52:37 step 2: mse=14851.195478 step=0.050000
2017/08/29 21:52:38 step 3: mse=14828.410253 step=0.050000
2017/08/29 21:52:38 step 4: mse=14811.787165 step=0.050000
2017/08/29 21:52:39 step 5: mse=14795.123568 step=0.050000
2017/08/29 21:52:40 step 6: mse=14771.200476 step=0.050000
2017/08/29 21:52:40 step 7: mse=14755.517495 step=0.050000
2017/08/29 21:52:40 Saving...
2017/08/29 21:52:40 Gathering batch of experience...
2017/08/29 21:53:03 batch 193: mean=1243.469388 stddev=455.247414 entropy=0.557947 frames=4864 count=49
2017/08/29 21:53:03 Training policy...
2017/08/29 21:53:06 tune 0: objective=33.208335 reg=0.005579 prune=0
2017/08/29 21:53:07 step 0: objective=33.217574 reg=0.005578
2017/08/29 21:53:07 step 1: objective=33.235355 reg=0.005577
2017/08/29 21:53:08 step 2: objective=33.248493 reg=0.005577
2017/08/29 21:53:09 step 3: objective=33.264841 reg=0.005576
2017/08/29 21:53:10 step 4: objective=33.280106 reg=0.005574
2017/08/29 21:53:11 step 5: objective=33.296021 reg=0.005574
2017/08/29 21:53:11 step 6: objective=33.309737 reg=0.005573
2017/08/29 21:53:12 step 7: objective=33.323210 reg=0.005573
2017/08/29 21:53:12 Training value function...
2017/08/29 21:53:14 step 0: mse=15384.113354 step=0.050000
2017/08/29 21:53:15 step 1: mse=15156.520534 step=0.050000
2017/08/29 21:53:16 step 2: mse=14942.078123 step=0.050000
2017/08/29 21:53:16 step 3: mse=14743.763303 step=0.050000
2017/08/29 21:53:17 step 4: mse=14563.841323 step=0.050000
2017/08/29 21:53:18 step 5: mse=14393.497373 step=0.050000
2017/08/29 21:53:19 step 6: mse=14236.124570 step=0.050000
2017/08/29 21:53:19 step 7: mse=14094.195191 step=0.050000
2017/08/29 21:53:19 Saving...
2017/08/29 21:53:19 Gathering batch of experience...
2017/08/29 21:53:43 batch 194: mean=946.129032 stddev=578.375380 entropy=0.570003 frames=4935 count=62
2017/08/29 21:53:43 Training policy...
2017/08/29 21:53:45 tune 0: objective=13.421106 reg=0.005700 prune=0
2017/08/29 21:53:46 step 0: objective=13.429763 reg=0.005699
2017/08/29 21:53:47 step 1: objective=13.447526 reg=0.005698
2017/08/29 21:53:48 step 2: objective=13.463071 reg=0.005698
2017/08/29 21:53:49 step 3: objective=13.474748 reg=0.005697
2017/08/29 21:53:49 step 4: objective=13.487649 reg=0.005697
2017/08/29 21:53:50 step 5: objective=13.501403 reg=0.005695
2017/08/29 21:53:51 step 6: objective=13.516980 reg=0.005694
2017/08/29 21:53:52 step 7: objective=13.531372 reg=0.005693
2017/08/29 21:53:52 Training value function...
2017/08/29 21:53:54 step 0: mse=16530.336631 step=0.050000
2017/08/29 21:53:55 step 1: mse=16518.258093 step=0.050000
2017/08/29 21:53:55 step 2: mse=16506.060669 step=0.050000
2017/08/29 21:53:56 step 3: mse=16506.509444 step=0.050000
2017/08/29 21:53:57 step 4: mse=16504.262447 step=0.050000
2017/08/29 21:53:58 step 5: mse=16509.107242 step=0.050000
2017/08/29 21:53:58 step 6: mse=16515.966407 step=0.050000
2017/08/29 21:53:59 step 7: mse=16522.002810 step=0.050000
2017/08/29 21:53:59 Saving...
2017/08/29 21:53:59 Gathering batch of experience...
2017/08/29 21:54:22 batch 195: mean=1038.421053 stddev=544.271731 entropy=0.564259 frames=4927 count=57
2017/08/29 21:54:22 Training policy...
2017/08/29 21:54:25 tune 0: objective=21.119674 reg=0.005643 prune=0
2017/08/29 21:54:26 step 0: objective=21.128888 reg=0.005641
2017/08/29 21:54:27 step 1: objective=21.149221 reg=0.005641
2017/08/29 21:54:28 step 2: objective=21.166419 reg=0.005640
2017/08/29 21:54:28 step 3: objective=21.176892 reg=0.005640
2017/08/29 21:54:29 step 4: objective=21.191310 reg=0.005640
2017/08/29 21:54:30 step 5: objective=21.203196 reg=0.005639
2017/08/29 21:54:31 step 6: objective=21.214646 reg=0.005639
2017/08/29 21:54:32 step 7: objective=21.225234 reg=0.005639
2017/08/29 21:54:32 Training value function...
2017/08/29 21:54:34 step 0: mse=15847.667890 step=0.050000
2017/08/29 21:54:34 step 1: mse=15816.616222 step=0.050000
2017/08/29 21:54:35 step 2: mse=15797.917445 step=0.050000
2017/08/29 21:54:36 step 3: mse=15788.211222 step=0.050000
2017/08/29 21:54:37 step 4: mse=15773.860246 step=0.050000
2017/08/29 21:54:37 step 5: mse=15768.750092 step=0.050000
2017/08/29 21:54:38 step 6: mse=15753.712665 step=0.050000
2017/08/29 21:54:39 step 7: mse=15743.651355 step=0.050000
2017/08/29 21:54:39 Saving...
2017/08/29 21:54:39 Gathering batch of experience...
2017/08/29 21:55:02 batch 196: mean=941.349206 stddev=511.146553 entropy=0.561184 frames=4932 count=63
2017/08/29 21:55:02 Training policy...
2017/08/29 21:55:05 tune 0: objective=15.762590 reg=0.005612 prune=0
2017/08/29 21:55:06 step 0: objective=15.767841 reg=0.005611
2017/08/29 21:55:07 step 1: objective=15.782712 reg=0.005610
2017/08/29 21:55:08 step 2: objective=15.797680 reg=0.005608
2017/08/29 21:55:08 step 3: objective=15.816432 reg=0.005607
2017/08/29 21:55:09 step 4: objective=15.833826 reg=0.005605
2017/08/29 21:55:10 step 5: objective=15.850732 reg=0.005604
2017/08/29 21:55:11 step 6: objective=15.867127 reg=0.005602
2017/08/29 21:55:12 step 7: objective=15.879286 reg=0.005601
2017/08/29 21:55:12 Training value function...
2017/08/29 21:55:14 step 0: mse=14372.933622 step=0.050000
2017/08/29 21:55:14 step 1: mse=14376.526831 step=0.050000
2017/08/29 21:55:15 step 2: mse=14386.844774 step=0.050000
2017/08/29 21:55:16 step 3: mse=14395.293156 step=0.050000
2017/08/29 21:55:17 step 4: mse=14405.386711 step=0.050000
2017/08/29 21:55:17 step 5: mse=14414.659151 step=0.050000
2017/08/29 21:55:18 step 6: mse=14428.187867 step=0.050000
2017/08/29 21:55:19 step 7: mse=14437.699969 step=0.050000
2017/08/29 21:55:19 Saving...
2017/08/29 21:55:19 Gathering batch of experience...
2017/08/29 21:55:42 batch 197: mean=992.500000 stddev=573.980618 entropy=0.565522 frames=4941 count=60
2017/08/29 21:55:42 Training policy...
2017/08/29 21:55:45 tune 0: objective=22.632950 reg=0.005655 prune=0
2017/08/29 21:55:46 step 0: objective=22.640260 reg=0.005654
2017/08/29 21:55:47 step 1: objective=22.652507 reg=0.005653
2017/08/29 21:55:48 step 2: objective=22.666096 reg=0.005653
2017/08/29 21:55:48 step 3: objective=22.679227 reg=0.005653
2017/08/29 21:55:49 step 4: objective=22.689606 reg=0.005652
2017/08/29 21:55:50 step 5: objective=22.702437 reg=0.005652
2017/08/29 21:55:51 step 6: objective=22.710506 reg=0.005651
2017/08/29 21:55:52 step 7: objective=22.721326 reg=0.005651
2017/08/29 21:55:52 Training value function...
2017/08/29 21:55:54 step 0: mse=16388.446732 step=0.050000
2017/08/29 21:55:54 step 1: mse=16320.037130 step=0.050000
2017/08/29 21:55:55 step 2: mse=16256.681142 step=0.050000
2017/08/29 21:55:56 step 3: mse=16196.205645 step=0.050000
2017/08/29 21:55:57 step 4: mse=16129.880215 step=0.050000
2017/08/29 21:55:57 step 5: mse=16067.557884 step=0.050000
2017/08/29 21:55:58 step 6: mse=16024.626381 step=0.050000
2017/08/29 21:55:59 step 7: mse=15983.373518 step=0.050000
2017/08/29 21:55:59 Saving...
2017/08/29 21:55:59 Gathering batch of experience...
2017/08/29 21:56:22 batch 198: mean=986.525424 stddev=539.411366 entropy=0.562491 frames=4854 count=59
2017/08/29 21:56:22 Training policy...
2017/08/29 21:56:25 tune 0: objective=20.326459 reg=0.005625 prune=0
2017/08/29 21:56:25 step 0: objective=20.330990 reg=0.005624
2017/08/29 21:56:26 step 1: objective=20.346649 reg=0.005623
2017/08/29 21:56:27 step 2: objective=20.364075 reg=0.005622
2017/08/29 21:56:28 step 3: objective=20.381610 reg=0.005621
2017/08/29 21:56:29 step 4: objective=20.398512 reg=0.005620
2017/08/29 21:56:29 step 5: objective=20.419002 reg=0.005619
2017/08/29 21:56:30 step 6: objective=20.438625 reg=0.005618
2017/08/29 21:56:31 step 7: objective=20.457450 reg=0.005617
2017/08/29 21:56:31 Training value function...
2017/08/29 21:56:33 step 0: mse=16606.155819 step=0.050000
2017/08/29 21:56:34 step 1: mse=16596.699303 step=0.050000
2017/08/29 21:56:34 step 2: mse=16578.185646 step=0.050000
2017/08/29 21:56:35 step 3: mse=16565.632824 step=0.050000
2017/08/29 21:56:36 step 4: mse=16551.522264 step=0.050000
2017/08/29 21:56:37 step 5: mse=16548.446635 step=0.050000
2017/08/29 21:56:38 step 6: mse=16545.953002 step=0.050000
2017/08/29 21:56:38 step 7: mse=16540.387388 step=0.050000
2017/08/29 21:56:38 Saving...
2017/08/29 21:56:38 Gathering batch of experience...
2017/08/29 21:57:01 batch 199: mean=941.750000 stddev=546.497046 entropy=0.566090 frames=4784 count=60
2017/08/29 21:57:01 Training policy...
2017/08/29 21:57:04 tune 0: objective=17.763156 reg=0.005661 prune=0
2017/08/29 21:57:05 step 0: objective=17.769366 reg=0.005660
2017/08/29 21:57:06 step 1: objective=17.779676 reg=0.005660
2017/08/29 21:57:07 step 2: objective=17.791613 reg=0.005660
2017/08/29 21:57:07 step 3: objective=17.804274 reg=0.005660
2017/08/29 21:57:08 step 4: objective=17.818593 reg=0.005659
2017/08/29 21:57:09 step 5: objective=17.830259 reg=0.005658
2017/08/29 21:57:10 step 6: objective=17.839055 reg=0.005658
2017/08/29 21:57:10 step 7: objective=17.853104 reg=0.005658
2017/08/29 21:57:10 Training value function...
2017/08/29 21:57:12 step 0: mse=15459.976847 step=0.050000
2017/08/29 21:57:13 step 1: mse=15454.522571 step=0.050000
2017/08/29 21:57:14 step 2: mse=15447.801716 step=0.050000
2017/08/29 21:57:15 step 3: mse=15446.676684 step=0.050000
2017/08/29 21:57:15 step 4: mse=15447.282476 step=0.050000
2017/08/29 21:57:16 step 5: mse=15440.509843 step=0.050000
2017/08/29 21:57:17 step 6: mse=15440.811357 step=0.050000
2017/08/29 21:57:18 step 7: mse=15439.139919 step=0.050000
2017/08/29 21:57:18 Saving...
2017/08/29 21:57:18 Gathering batch of experience...
2017/08/29 21:57:40 batch 200: mean=1075.754717 stddev=551.215977 entropy=0.559658 frames=4679 count=53
2017/08/29 21:57:40 Training policy...
2017/08/29 21:57:42 tune 0: objective=27.991859 reg=0.005597 prune=0
2017/08/29 21:57:43 step 0: objective=27.999833 reg=0.005596
2017/08/29 21:57:44 step 1: objective=28.014814 reg=0.005595
2017/08/29 21:57:45 step 2: objective=28.031928 reg=0.005595
2017/08/29 21:57:45 step 3: objective=28.049774 reg=0.005595
2017/08/29 21:57:46 step 4: objective=28.064671 reg=0.005595
2017/08/29 21:57:47 step 5: objective=28.087325 reg=0.005594
2017/08/29 21:57:48 step 6: objective=28.104176 reg=0.005593
2017/08/29 21:57:48 step 7: objective=28.121711 reg=0.005592
2017/08/29 21:57:48 Training value function...
2017/08/29 21:57:50 step 0: mse=17082.627123 step=0.050000
2017/08/29 21:57:51 step 1: mse=16970.756981 step=0.050000
2017/08/29 21:57:52 step 2: mse=16871.600039 step=0.050000
2017/08/29 21:57:52 step 3: mse=16779.941798 step=0.050000
2017/08/29 21:57:53 step 4: mse=16693.553247 step=0.050000
2017/08/29 21:57:54 step 5: mse=16607.422750 step=0.050000
2017/08/29 21:57:55 step 6: mse=16530.289020 step=0.050000
2017/08/29 21:57:55 step 7: mse=16460.143205 step=0.050000
2017/08/29 21:57:55 Saving...
2017/08/29 21:57:55 Gathering batch of experience...
2017/08/29 21:58:17 batch 201: mean=1143.627451 stddev=521.630248 entropy=0.558268 frames=4719 count=51
2017/08/29 21:58:17 Training policy...
2017/08/29 21:58:20 tune 0: objective=29.352140 reg=0.005583 prune=0
2017/08/29 21:58:21 step 0: objective=29.358690 reg=0.005581
2017/08/29 21:58:22 step 1: objective=29.374517 reg=0.005580
2017/08/29 21:58:23 step 2: objective=29.386721 reg=0.005578
2017/08/29 21:58:23 step 3: objective=29.400062 reg=0.005577
2017/08/29 21:58:24 step 4: objective=29.416018 reg=0.005576
2017/08/29 21:58:25 step 5: objective=29.433219 reg=0.005575
2017/08/29 21:58:26 step 6: objective=29.442460 reg=0.005573
2017/08/29 21:58:26 step 7: objective=29.455221 reg=0.005572
2017/08/29 21:58:26 Training value function...
2017/08/29 21:58:28 step 0: mse=15700.902151 step=0.050000
2017/08/29 21:58:29 step 1: mse=15562.512545 step=0.050000
2017/08/29 21:58:30 step 2: mse=15436.943826 step=0.050000
2017/08/29 21:58:31 step 3: mse=15323.676314 step=0.050000
2017/08/29 21:58:31 step 4: mse=15212.891169 step=0.050000
2017/08/29 21:58:32 step 5: mse=15113.967361 step=0.050000
2017/08/29 21:58:33 step 6: mse=15018.645819 step=0.050000
2017/08/29 21:58:33 step 7: mse=14931.036418 step=0.050000
2017/08/29 21:58:33 Saving...
2017/08/29 21:58:34 Gathering batch of experience...
2017/08/29 21:58:56 batch 202: mean=1142.264151 stddev=598.427630 entropy=0.556726 frames=4883 count=53
2017/08/29 21:58:56 Training policy...
2017/08/29 21:58:59 tune 0: objective=26.938217 reg=0.005567 prune=0
2017/08/29 21:59:00 step 0: objective=26.945135 reg=0.005566
2017/08/29 21:59:00 step 1: objective=26.957826 reg=0.005565
2017/08/29 21:59:01 step 2: objective=26.969153 reg=0.005565
2017/08/29 21:59:02 step 3: objective=26.981735 reg=0.005564
2017/08/29 21:59:03 step 4: objective=26.996320 reg=0.005564
2017/08/29 21:59:04 step 5: objective=27.011843 reg=0.005563
2017/08/29 21:59:04 step 6: objective=27.026313 reg=0.005561
2017/08/29 21:59:05 step 7: objective=27.044728 reg=0.005560
2017/08/29 21:59:05 Training value function...
2017/08/29 21:59:07 step 0: mse=16588.611942 step=0.050000
2017/08/29 21:59:08 step 1: mse=16470.242142 step=0.050000
2017/08/29 21:59:09 step 2: mse=16353.445193 step=0.050000
2017/08/29 21:59:09 step 3: mse=16253.141125 step=0.050000
2017/08/29 21:59:10 step 4: mse=16152.535596 step=0.050000
2017/08/29 21:59:11 step 5: mse=16060.111053 step=0.050000
2017/08/29 21:59:12 step 6: mse=15974.413260 step=0.050000
2017/08/29 21:59:12 step 7: mse=15892.342100 step=0.050000
2017/08/29 21:59:12 Saving...
2017/08/29 21:59:12 Gathering batch of experience...
2017/08/29 21:59:35 batch 203: mean=918.750000 stddev=509.272868 entropy=0.558824 frames=4696 count=60
2017/08/29 21:59:35 Training policy...
2017/08/29 21:59:38 tune 0: objective=8.823402 reg=0.005588 prune=0
2017/08/29 21:59:38 step 0: objective=8.832510 reg=0.005587
2017/08/29 21:59:39 step 1: objective=8.849594 reg=0.005587
2017/08/29 21:59:40 step 2: objective=8.867296 reg=0.005586
2017/08/29 21:59:41 step 3: objective=8.884488 reg=0.005586
2017/08/29 21:59:41 step 4: objective=8.902571 reg=0.005585
2017/08/29 21:59:42 step 5: objective=8.920022 reg=0.005585
2017/08/29 21:59:43 step 6: objective=8.936051 reg=0.005584
2017/08/29 21:59:44 step 7: objective=8.952643 reg=0.005583
2017/08/29 21:59:44 Training value function...
2017/08/29 21:59:46 step 0: mse=15187.970543 step=0.050000
2017/08/29 21:59:46 step 1: mse=15197.827823 step=0.050000
2017/08/29 21:59:47 step 2: mse=15205.093468 step=0.050000
2017/08/29 21:59:48 step 3: mse=15204.428621 step=0.050000
2017/08/29 21:59:48 step 4: mse=15220.701170 step=0.050000
2017/08/29 21:59:49 step 5: mse=15242.039840 step=0.050000
2017/08/29 21:59:50 step 6: mse=15238.578431 step=0.050000
2017/08/29 21:59:51 step 7: mse=15271.734138 step=0.050000
2017/08/29 21:59:51 Saving...
2017/08/29 21:59:51 Gathering batch of experience...
2017/08/29 22:00:13 batch 204: mean=1110.673077 stddev=528.241849 entropy=0.556868 frames=4770 count=52
2017/08/29 22:00:13 Training policy...
2017/08/29 22:00:15 tune 0: objective=26.444862 reg=0.005569 prune=0
2017/08/29 22:00:16 step 0: objective=26.450961 reg=0.005567
2017/08/29 22:00:17 step 1: objective=26.471343 reg=0.005566
2017/08/29 22:00:18 step 2: objective=26.491744 reg=0.005564
2017/08/29 22:00:19 step 3: objective=26.505770 reg=0.005563
2017/08/29 22:00:19 step 4: objective=26.518917 reg=0.005561
2017/08/29 22:00:20 step 5: objective=26.537131 reg=0.005560
2017/08/29 22:00:21 step 6: objective=26.553559 reg=0.005559
2017/08/29 22:00:22 step 7: objective=26.570073 reg=0.005557
2017/08/29 22:00:22 Training value function...
2017/08/29 22:00:24 step 0: mse=15929.024450 step=0.050000
2017/08/29 22:00:24 step 1: mse=15831.133196 step=0.050000
2017/08/29 22:00:25 step 2: mse=15734.632683 step=0.050000
2017/08/29 22:00:26 step 3: mse=15642.357733 step=0.050000
2017/08/29 22:00:27 step 4: mse=15562.402872 step=0.050000
2017/08/29 22:00:27 step 5: mse=15482.615332 step=0.050000
2017/08/29 22:00:28 step 6: mse=15408.600541 step=0.050000
2017/08/29 22:00:29 step 7: mse=15344.142550 step=0.050000
2017/08/29 22:00:29 Saving...
2017/08/29 22:00:29 Gathering batch of experience...
2017/08/29 22:00:52 batch 205: mean=1074.545455 stddev=498.125826 entropy=0.551100 frames=4881 count=55
2017/08/29 22:00:52 Training policy...
2017/08/29 22:00:54 tune 0: objective=22.291015 reg=0.005511 prune=0
2017/08/29 22:00:55 step 0: objective=22.296696 reg=0.005510
2017/08/29 22:00:56 step 1: objective=22.309929 reg=0.005508
2017/08/29 22:00:57 step 2: objective=22.323768 reg=0.005507
2017/08/29 22:00:58 step 3: objective=22.341221 reg=0.005505
2017/08/29 22:00:58 step 4: objective=22.354749 reg=0.005504
2017/08/29 22:00:59 step 5: objective=22.370840 reg=0.005502
2017/08/29 22:01:00 step 6: objective=22.387654 reg=0.005500
2017/08/29 22:01:01 step 7: objective=22.403422 reg=0.005499
2017/08/29 22:01:01 Training value function...
2017/08/29 22:01:03 step 0: mse=13688.445654 step=0.050000
2017/08/29 22:01:04 step 1: mse=13661.260192 step=0.050000
2017/08/29 22:01:04 step 2: mse=13634.975219 step=0.050000
2017/08/29 22:01:05 step 3: mse=13611.664618 step=0.050000
2017/08/29 22:01:06 step 4: mse=13591.718550 step=0.050000
2017/08/29 22:01:07 step 5: mse=13572.391579 step=0.050000
2017/08/29 22:01:07 step 6: mse=13554.689631 step=0.050000
2017/08/29 22:01:08 step 7: mse=13539.302169 step=0.050000
2017/08/29 22:01:08 Saving...
2017/08/29 22:01:08 Gathering batch of experience...
2017/08/29 22:01:31 batch 206: mean=1162.075472 stddev=550.696329 entropy=0.553288 frames=4950 count=53
2017/08/29 22:01:31 Training policy...
2017/08/29 22:01:34 tune 0: objective=30.430846 reg=0.005533 prune=0
2017/08/29 22:01:35 step 0: objective=30.435521 reg=0.005532
2017/08/29 22:01:36 step 1: objective=30.446193 reg=0.005532
2017/08/29 22:01:36 step 2: objective=30.461234 reg=0.005532
2017/08/29 22:01:37 step 3: objective=30.476111 reg=0.005530
2017/08/29 22:01:38 step 4: objective=30.488819 reg=0.005530
2017/08/29 22:01:39 step 5: objective=30.503703 reg=0.005529
2017/08/29 22:01:40 step 6: objective=30.514479 reg=0.005528
2017/08/29 22:01:41 step 7: objective=30.526607 reg=0.005528
2017/08/29 22:01:41 Training value function...
2017/08/29 22:01:43 step 0: mse=16368.971962 step=0.050000
2017/08/29 22:01:43 step 1: mse=16185.107618 step=0.050000
2017/08/29 22:01:44 step 2: mse=16012.698531 step=0.050000
2017/08/29 22:01:45 step 3: mse=15860.082096 step=0.050000
2017/08/29 22:01:46 step 4: mse=15719.515719 step=0.050000
2017/08/29 22:01:46 step 5: mse=15582.385424 step=0.050000
2017/08/29 22:01:47 step 6: mse=15458.045392 step=0.050000
2017/08/29 22:01:48 step 7: mse=15344.080540 step=0.050000
2017/08/29 22:01:48 Saving...
2017/08/29 22:01:48 Gathering batch of experience...
2017/08/29 22:02:10 batch 207: mean=1082.685185 stddev=583.025088 entropy=0.557136 frames=4787 count=54
2017/08/29 22:02:10 Training policy...
2017/08/29 22:02:13 tune 0: objective=23.084193 reg=0.005571 prune=0
2017/08/29 22:02:14 step 0: objective=23.092643 reg=0.005571
2017/08/29 22:02:15 step 1: objective=23.115131 reg=0.005570
2017/08/29 22:02:16 step 2: objective=23.131631 reg=0.005570
2017/08/29 22:02:16 step 3: objective=23.150845 reg=0.005570
2017/08/29 22:02:17 step 4: objective=23.173141 reg=0.005569
2017/08/29 22:02:18 step 5: objective=23.190464 reg=0.005569
2017/08/29 22:02:19 step 6: objective=23.202813 reg=0.005569
2017/08/29 22:02:20 step 7: objective=23.220005 reg=0.005568
2017/08/29 22:02:20 Training value function...
2017/08/29 22:02:21 step 0: mse=16212.071068 step=0.050000
2017/08/29 22:02:22 step 1: mse=16154.906305 step=0.050000
2017/08/29 22:02:23 step 2: mse=16098.321046 step=0.050000
2017/08/29 22:02:24 step 3: mse=16046.948737 step=0.050000
2017/08/29 22:02:24 step 4: mse=16006.596482 step=0.050000
2017/08/29 22:02:25 step 5: mse=15966.518054 step=0.050000
2017/08/29 22:02:26 step 6: mse=15921.126700 step=0.050000
2017/08/29 22:02:27 step 7: mse=15884.346736 step=0.050000
2017/08/29 22:02:27 Saving...
2017/08/29 22:02:27 Gathering batch of experience...
2017/08/29 22:02:50 batch 208: mean=1153.867925 stddev=553.533795 entropy=0.555577 frames=4985 count=53
2017/08/29 22:02:50 Training policy...
2017/08/29 22:02:52 tune 0: objective=25.579272 reg=0.005556 prune=0
2017/08/29 22:02:53 step 0: objective=25.584171 reg=0.005556
2017/08/29 22:02:54 step 1: objective=25.596526 reg=0.005556
2017/08/29 22:02:55 step 2: objective=25.608648 reg=0.005556
2017/08/29 22:02:56 step 3: objective=25.621632 reg=0.005556
2017/08/29 22:02:57 step 4: objective=25.635988 reg=0.005556
2017/08/29 22:02:57 step 5: objective=25.645018 reg=0.005557
2017/08/29 22:02:58 step 6: objective=25.655277 reg=0.005557
2017/08/29 22:02:59 step 7: objective=25.669712 reg=0.005557
2017/08/29 22:02:59 Training value function...
2017/08/29 22:03:01 step 0: mse=15666.174457 step=0.050000
2017/08/29 22:03:02 step 1: mse=15587.499073 step=0.050000
2017/08/29 22:03:03 step 2: mse=15530.458253 step=0.050000
2017/08/29 22:03:03 step 3: mse=15461.573398 step=0.050000
2017/08/29 22:03:04 step 4: mse=15397.649215 step=0.050000
2017/08/29 22:03:05 step 5: mse=15344.923597 step=0.050000
2017/08/29 22:03:06 step 6: mse=15299.616156 step=0.050000
2017/08/29 22:03:06 step 7: mse=15245.104454 step=0.050000
2017/08/29 22:03:06 Saving...
2017/08/29 22:03:06 Gathering batch of experience...
2017/08/29 22:03:29 batch 209: mean=1056.964286 stddev=560.007716 entropy=0.554892 frames=4871 count=56
2017/08/29 22:03:29 Training policy...
2017/08/29 22:03:32 tune 0: objective=19.173715 reg=0.005549 prune=0
2017/08/29 22:03:33 step 0: objective=19.182089 reg=0.005548
2017/08/29 22:03:34 step 1: objective=19.197356 reg=0.005547
2017/08/29 22:03:35 step 2: objective=19.209946 reg=0.005546
2017/08/29 22:03:35 step 3: objective=19.224572 reg=0.005545
2017/08/29 22:03:36 step 4: objective=19.240168 reg=0.005544
2017/08/29 22:03:37 step 5: objective=19.253163 reg=0.005544
2017/08/29 22:03:38 step 6: objective=19.271927 reg=0.005543
2017/08/29 22:03:39 step 7: objective=19.283239 reg=0.005542
2017/08/29 22:03:39 Training value function...
2017/08/29 22:03:41 step 0: mse=14773.299663 step=0.050000
2017/08/29 22:03:41 step 1: mse=14797.049159 step=0.050000
2017/08/29 22:03:42 step 2: mse=14819.926293 step=0.050000
2017/08/29 22:03:43 step 3: mse=14838.154253 step=0.050000
2017/08/29 22:03:44 step 4: mse=14860.985500 step=0.050000
2017/08/29 22:03:44 step 5: mse=14883.333718 step=0.050000
2017/08/29 22:03:45 step 6: mse=14896.600547 step=0.050000
2017/08/29 22:03:46 step 7: mse=14916.500008 step=0.050000
2017/08/29 22:03:46 Saving...
2017/08/29 22:03:46 Gathering batch of experience...
2017/08/29 22:04:08 batch 210: mean=1103.962264 stddev=538.083916 entropy=0.552477 frames=4771 count=53
2017/08/29 22:04:08 Training policy...
2017/08/29 22:04:11 tune 0: objective=22.575446 reg=0.005525 prune=0
2017/08/29 22:04:11 step 0: objective=22.582207 reg=0.005524
2017/08/29 22:04:12 step 1: objective=22.598296 reg=0.005524
2017/08/29 22:04:13 step 2: objective=22.613978 reg=0.005523
2017/08/29 22:04:14 step 3: objective=22.632395 reg=0.005522
2017/08/29 22:04:15 step 4: objective=22.651179 reg=0.005522
2017/08/29 22:04:15 step 5: objective=22.660409 reg=0.005521
2017/08/29 22:04:16 step 6: objective=22.675913 reg=0.005520
2017/08/29 22:04:17 step 7: objective=22.685433 reg=0.005520
2017/08/29 22:04:17 Training value function...
2017/08/29 22:04:19 step 0: mse=15539.268327 step=0.050000
2017/08/29 22:04:20 step 1: mse=15494.941648 step=0.050000
2017/08/29 22:04:20 step 2: mse=15477.681485 step=0.050000
2017/08/29 22:04:21 step 3: mse=15455.553768 step=0.050000
2017/08/29 22:04:22 step 4: mse=15425.518966 step=0.050000
2017/08/29 22:04:23 step 5: mse=15400.652324 step=0.050000
2017/08/29 22:04:23 step 6: mse=15380.797144 step=0.050000
2017/08/29 22:04:24 step 7: mse=15356.916969 step=0.050000
2017/08/29 22:04:24 Saving...
2017/08/29 22:04:24 Gathering batch of experience...
2017/08/29 22:04:51 batch 211: mean=1508.867925 stddev=2707.865664 entropy=0.555458 frames=5318 count=53
2017/08/29 22:04:51 Training policy...
2017/08/29 22:04:54 tune 0: objective=62.681894 reg=0.005555 prune=0
2017/08/29 22:04:55 step 0: objective=62.733570 reg=0.005554
2017/08/29 22:04:56 step 1: objective=62.902901 reg=0.005553
2017/08/29 22:04:57 step 2: objective=63.045659 reg=0.005551
2017/08/29 22:04:57 step 3: objective=63.175036 reg=0.005550
2017/08/29 22:04:58 step 4: objective=63.355867 reg=0.005551
2017/08/29 22:04:59 step 5: objective=63.466934 reg=0.005550
2017/08/29 22:05:00 step 6: objective=63.572736 reg=0.005551
2017/08/29 22:05:01 step 7: objective=63.762511 reg=0.005550
2017/08/29 22:05:01 Training value function...
2017/08/29 22:05:03 step 0: mse=269795.985734 step=0.050000
2017/08/29 22:05:04 step 1: mse=258347.740135 step=0.050000
2017/08/29 22:05:05 step 2: mse=248989.166474 step=0.050000
2017/08/29 22:05:06 step 3: mse=239353.017615 step=0.050000
2017/08/29 22:05:06 step 4: mse=229836.563145 step=0.050000
2017/08/29 22:05:07 step 5: mse=221349.076183 step=0.050000
2017/08/29 22:05:08 step 6: mse=213700.361167 step=0.050000
2017/08/29 22:05:09 step 7: mse=210463.708216 step=0.050000
2017/08/29 22:05:09 Saving...
2017/08/29 22:05:09 Gathering batch of experience...
2017/08/29 22:05:32 batch 212: mean=1039.732143 stddev=582.330922 entropy=0.557048 frames=4831 count=56
2017/08/29 22:05:32 Training policy...
2017/08/29 22:05:35 tune 0: objective=12.150685 reg=0.005570 prune=0
2017/08/29 22:05:35 step 0: objective=12.156320 reg=0.005570
2017/08/29 22:05:36 step 1: objective=12.166681 reg=0.005570
2017/08/29 22:05:37 step 2: objective=12.180986 reg=0.005569
2017/08/29 22:05:38 step 3: objective=12.190040 reg=0.005569
2017/08/29 22:05:39 step 4: objective=12.199659 reg=0.005569
2017/08/29 22:05:39 step 5: objective=12.208644 reg=0.005569
2017/08/29 22:05:40 step 6: objective=12.223987 reg=0.005569
2017/08/29 22:05:41 step 7: objective=12.231610 reg=0.005569
2017/08/29 22:05:41 Training value function...
2017/08/29 22:05:43 step 0: mse=15787.549382 step=0.050000
2017/08/29 22:05:44 step 1: mse=15775.357767 step=0.050000
2017/08/29 22:05:44 step 2: mse=15768.818893 step=0.050000
2017/08/29 22:05:45 step 3: mse=15772.769517 step=0.050000
2017/08/29 22:05:46 step 4: mse=15774.266443 step=0.050000
2017/08/29 22:05:47 step 5: mse=15780.105151 step=0.050000
2017/08/29 22:05:47 step 6: mse=15786.951262 step=0.050000
2017/08/29 22:05:48 step 7: mse=15797.693089 step=0.050000
2017/08/29 22:05:48 Saving...
2017/08/29 22:05:48 Gathering batch of experience...
2017/08/29 22:06:11 batch 213: mean=1069.727273 stddev=482.088655 entropy=0.546684 frames=4824 count=55
2017/08/29 22:06:11 Training policy...
2017/08/29 22:06:13 tune 0: objective=15.968209 reg=0.005467 prune=0
2017/08/29 22:06:14 step 0: objective=15.975764 reg=0.005466
2017/08/29 22:06:15 step 1: objective=15.990774 reg=0.005466
2017/08/29 22:06:16 step 2: objective=16.005469 reg=0.005466
2017/08/29 22:06:17 step 3: objective=16.021078 reg=0.005465
2017/08/29 22:06:17 step 4: objective=16.035381 reg=0.005464
2017/08/29 22:06:18 step 5: objective=16.049384 reg=0.005464
2017/08/29 22:06:19 step 6: objective=16.065067 reg=0.005463
2017/08/29 22:06:20 step 7: objective=16.078758 reg=0.005462
2017/08/29 22:06:20 Training value function...
2017/08/29 22:06:22 step 0: mse=12674.050787 step=0.050000
2017/08/29 22:06:23 step 1: mse=12645.179503 step=0.050000
2017/08/29 22:06:23 step 2: mse=12616.007390 step=0.050000
2017/08/29 22:06:24 step 3: mse=12594.230478 step=0.050000
2017/08/29 22:06:25 step 4: mse=12580.575769 step=0.050000
2017/08/29 22:06:25 step 5: mse=12565.297340 step=0.050000
2017/08/29 22:06:26 step 6: mse=12558.042120 step=0.050000
2017/08/29 22:06:27 step 7: mse=12554.422923 step=0.050000
2017/08/29 22:06:27 Saving...
2017/08/29 22:06:27 Gathering batch of experience...
2017/08/29 22:06:50 batch 214: mean=1118.888889 stddev=536.905284 entropy=0.548265 frames=4881 count=54
2017/08/29 22:06:50 Training policy...
2017/08/29 22:06:52 tune 0: objective=22.907988 reg=0.005483 prune=0
2017/08/29 22:06:53 step 0: objective=22.916166 reg=0.005482
2017/08/29 22:06:54 step 1: objective=22.935237 reg=0.005482
2017/08/29 22:06:55 step 2: objective=22.959551 reg=0.005481
2017/08/29 22:06:56 step 3: objective=22.973316 reg=0.005480
2017/08/29 22:06:56 step 4: objective=22.988865 reg=0.005479
2017/08/29 22:06:57 step 5: objective=23.003541 reg=0.005478
2017/08/29 22:06:58 step 6: objective=23.021954 reg=0.005477
2017/08/29 22:06:59 step 7: objective=23.045463 reg=0.005476
2017/08/29 22:06:59 Training value function...
2017/08/29 22:07:01 step 0: mse=15152.307546 step=0.050000
2017/08/29 22:07:02 step 1: mse=15105.437702 step=0.050000
2017/08/29 22:07:02 step 2: mse=15067.063657 step=0.050000
2017/08/29 22:07:03 step 3: mse=15025.192290 step=0.050000
2017/08/29 22:07:04 step 4: mse=14988.460463 step=0.050000
2017/08/29 22:07:05 step 5: mse=14952.840075 step=0.050000
2017/08/29 22:07:05 step 6: mse=14913.346279 step=0.050000
2017/08/29 22:07:06 step 7: mse=14875.328299 step=0.050000
2017/08/29 22:07:06 Saving...
2017/08/29 22:07:06 Gathering batch of experience...
2017/08/29 22:07:29 batch 215: mean=1034.913793 stddev=553.591325 entropy=0.551345 frames=4883 count=58
2017/08/29 22:07:29 Training policy...
2017/08/29 22:07:32 tune 0: objective=18.966956 reg=0.005513 prune=0
2017/08/29 22:07:33 step 0: objective=18.975031 reg=0.005512
2017/08/29 22:07:34 step 1: objective=18.996029 reg=0.005511
2017/08/29 22:07:34 step 2: objective=19.014793 reg=0.005511
2017/08/29 22:07:35 step 3: objective=19.029157 reg=0.005510
2017/08/29 22:07:36 step 4: objective=19.046787 reg=0.005508
2017/08/29 22:07:37 step 5: objective=19.064294 reg=0.005507
2017/08/29 22:07:38 step 6: objective=19.083048 reg=0.005506
2017/08/29 22:07:38 step 7: objective=19.097988 reg=0.005505
2017/08/29 22:07:38 Training value function...
2017/08/29 22:07:40 step 0: mse=15362.051956 step=0.050000
2017/08/29 22:07:41 step 1: mse=15337.979665 step=0.050000
2017/08/29 22:07:42 step 2: mse=15322.105123 step=0.050000
2017/08/29 22:07:43 step 3: mse=15303.201090 step=0.050000
2017/08/29 22:07:43 step 4: mse=15292.616239 step=0.050000
2017/08/29 22:07:44 step 5: mse=15279.318445 step=0.050000
2017/08/29 22:07:45 step 6: mse=15274.679556 step=0.050000
2017/08/29 22:07:46 step 7: mse=15267.858456 step=0.050000
2017/08/29 22:07:46 Saving...
2017/08/29 22:07:46 Gathering batch of experience...
2017/08/29 22:08:08 batch 216: mean=1142.211538 stddev=550.152438 entropy=0.549280 frames=4799 count=52
2017/08/29 22:08:08 Training policy...
2017/08/29 22:08:11 tune 0: objective=25.222216 reg=0.005493 prune=0
2017/08/29 22:08:11 step 0: objective=25.228195 reg=0.005492
2017/08/29 22:08:12 step 1: objective=25.246720 reg=0.005492
2017/08/29 22:08:13 step 2: objective=25.265527 reg=0.005492
2017/08/29 22:08:14 step 3: objective=25.284465 reg=0.005491
2017/08/29 22:08:15 step 4: objective=25.294759 reg=0.005492
2017/08/29 22:08:15 step 5: objective=25.307392 reg=0.005492
2017/08/29 22:08:16 step 6: objective=25.317540 reg=0.005491
2017/08/29 22:08:17 step 7: objective=25.332081 reg=0.005492
2017/08/29 22:08:17 Training value function...
2017/08/29 22:08:19 step 0: mse=15651.910492 step=0.050000
2017/08/29 22:08:20 step 1: mse=15585.452704 step=0.050000
2017/08/29 22:08:20 step 2: mse=15524.728450 step=0.050000
2017/08/29 22:08:21 step 3: mse=15471.133970 step=0.050000
2017/08/29 22:08:22 step 4: mse=15416.641929 step=0.050000
2017/08/29 22:08:23 step 5: mse=15367.815117 step=0.050000
2017/08/29 22:08:23 step 6: mse=15318.152007 step=0.050000
2017/08/29 22:08:24 step 7: mse=15271.693532 step=0.050000
2017/08/29 22:08:24 Saving...
2017/08/29 22:08:24 Gathering batch of experience...
2017/08/29 22:08:48 batch 217: mean=1132.727273 stddev=525.926730 entropy=0.542655 frames=5012 count=55
2017/08/29 22:08:48 Training policy...
2017/08/29 22:08:50 tune 0: objective=23.570716 reg=0.005427 prune=0
2017/08/29 22:08:51 step 0: objective=23.580767 reg=0.005425
2017/08/29 22:08:52 step 1: objective=23.600409 reg=0.005424
2017/08/29 22:08:53 step 2: objective=23.618450 reg=0.005424
2017/08/29 22:08:54 step 3: objective=23.639980 reg=0.005423
2017/08/29 22:08:55 step 4: objective=23.659636 reg=0.005422
2017/08/29 22:08:55 step 5: objective=23.678285 reg=0.005420
2017/08/29 22:08:56 step 6: objective=23.700103 reg=0.005419
2017/08/29 22:08:57 step 7: objective=23.721551 reg=0.005418
2017/08/29 22:08:57 Training value function...
2017/08/29 22:08:59 step 0: mse=15687.827500 step=0.050000
2017/08/29 22:09:00 step 1: mse=15654.194192 step=0.050000
2017/08/29 22:09:01 step 2: mse=15612.428898 step=0.050000
2017/08/29 22:09:01 step 3: mse=15583.530877 step=0.050000
2017/08/29 22:09:02 step 4: mse=15552.202334 step=0.050000
2017/08/29 22:09:03 step 5: mse=15527.082255 step=0.050000
2017/08/29 22:09:04 step 6: mse=15495.787283 step=0.050000
2017/08/29 22:09:05 step 7: mse=15469.753392 step=0.050000
2017/08/29 22:09:05 Saving...
2017/08/29 22:09:05 Gathering batch of experience...
2017/08/29 22:09:28 batch 218: mean=1138.796296 stddev=631.004443 entropy=0.553869 frames=4989 count=54
2017/08/29 22:09:28 Training policy...
2017/08/29 22:09:31 tune 0: objective=25.092533 reg=0.005539 prune=0
2017/08/29 22:09:31 step 0: objective=25.099268 reg=0.005538
2017/08/29 22:09:32 step 1: objective=25.109640 reg=0.005537
2017/08/29 22:09:33 step 2: objective=25.124883 reg=0.005536
2017/08/29 22:09:34 step 3: objective=25.134421 reg=0.005536
2017/08/29 22:09:35 step 4: objective=25.151176 reg=0.005535
2017/08/29 22:09:36 step 5: objective=25.163688 reg=0.005535
2017/08/29 22:09:36 step 6: objective=25.181408 reg=0.005534
2017/08/29 22:09:37 step 7: objective=25.197400 reg=0.005533
2017/08/29 22:09:37 Training value function...
2017/08/29 22:09:39 step 0: mse=16796.364309 step=0.050000
2017/08/29 22:09:40 step 1: mse=16696.870961 step=0.050000
2017/08/29 22:09:41 step 2: mse=16606.952796 step=0.050000
2017/08/29 22:09:42 step 3: mse=16521.900235 step=0.050000
2017/08/29 22:09:42 step 4: mse=16446.990417 step=0.050000
2017/08/29 22:09:43 step 5: mse=16373.018219 step=0.050000
2017/08/29 22:09:44 step 6: mse=16306.155432 step=0.050000
2017/08/29 22:09:45 step 7: mse=16250.104013 step=0.050000
2017/08/29 22:09:45 Saving...
2017/08/29 22:09:45 Gathering batch of experience...
2017/08/29 22:10:08 batch 219: mean=1060.803571 stddev=534.282544 entropy=0.543896 frames=4872 count=56
2017/08/29 22:10:08 Training policy...
2017/08/29 22:10:11 tune 0: objective=17.400820 reg=0.005439 prune=0
2017/08/29 22:10:11 step 0: objective=17.406673 reg=0.005438
2017/08/29 22:10:12 step 1: objective=17.417823 reg=0.005437
2017/08/29 22:10:13 step 2: objective=17.431907 reg=0.005436
2017/08/29 22:10:14 step 3: objective=17.441190 reg=0.005435
2017/08/29 22:10:15 step 4: objective=17.460059 reg=0.005434
2017/08/29 22:10:15 step 5: objective=17.474826 reg=0.005433
2017/08/29 22:10:16 step 6: objective=17.486530 reg=0.005432
2017/08/29 22:10:17 step 7: objective=17.495587 reg=0.005432
2017/08/29 22:10:17 Training value function...
2017/08/29 22:10:19 step 0: mse=15037.528266 step=0.050000
2017/08/29 22:10:20 step 1: mse=15060.788179 step=0.050000
2017/08/29 22:10:20 step 2: mse=15089.964746 step=0.050000
2017/08/29 22:10:21 step 3: mse=15111.784364 step=0.050000
2017/08/29 22:10:22 step 4: mse=15135.789952 step=0.050000
2017/08/29 22:10:23 step 5: mse=15157.393096 step=0.050000
2017/08/29 22:10:23 step 6: mse=15177.589767 step=0.050000
2017/08/29 22:10:24 step 7: mse=15197.730775 step=0.050000
2017/08/29 22:10:24 Saving...
2017/08/29 22:10:24 Gathering batch of experience...
2017/08/29 22:10:47 batch 220: mean=1035.789474 stddev=551.640130 entropy=0.548352 frames=4881 count=57
2017/08/29 22:10:47 Training policy...
2017/08/29 22:10:50 tune 0: objective=18.193400 reg=0.005484 prune=0
2017/08/29 22:10:51 step 0: objective=18.201465 reg=0.005483
2017/08/29 22:10:52 step 1: objective=18.216336 reg=0.005482
2017/08/29 22:10:52 step 2: objective=18.234932 reg=0.005481
2017/08/29 22:10:53 step 3: objective=18.252505 reg=0.005480
2017/08/29 22:10:54 step 4: objective=18.270724 reg=0.005480
2017/08/29 22:10:55 step 5: objective=18.289162 reg=0.005479
2017/08/29 22:10:56 step 6: objective=18.306227 reg=0.005478
2017/08/29 22:10:57 step 7: objective=18.324913 reg=0.005477
2017/08/29 22:10:57 Training value function...
2017/08/29 22:10:58 step 0: mse=14473.687845 step=0.050000
2017/08/29 22:10:59 step 1: mse=14488.787698 step=0.050000
2017/08/29 22:11:00 step 2: mse=14502.171144 step=0.050000
2017/08/29 22:11:01 step 3: mse=14516.082711 step=0.050000
2017/08/29 22:11:02 step 4: mse=14527.380503 step=0.050000
2017/08/29 22:11:02 step 5: mse=14539.344212 step=0.050000
2017/08/29 22:11:03 step 6: mse=14552.374490 step=0.050000
2017/08/29 22:11:04 step 7: mse=14559.578828 step=0.050000
2017/08/29 22:11:04 Saving...
2017/08/29 22:11:04 Gathering batch of experience...
2017/08/29 22:11:27 batch 221: mean=1167.547170 stddev=573.329915 entropy=0.546007 frames=4987 count=53
2017/08/29 22:11:27 Training policy...
2017/08/29 22:11:30 tune 0: objective=28.582627 reg=0.005460 prune=0
2017/08/29 22:11:30 step 0: objective=28.586459 reg=0.005460
2017/08/29 22:11:31 step 1: objective=28.592772 reg=0.005460
2017/08/29 22:11:32 step 2: objective=28.602047 reg=0.005459
2017/08/29 22:11:33 step 3: objective=28.609240 reg=0.005459
2017/08/29 22:11:34 step 4: objective=28.615695 reg=0.005459
2017/08/29 22:11:35 step 5: objective=28.622935 reg=0.005459
2017/08/29 22:11:35 step 6: objective=28.631862 reg=0.005459
2017/08/29 22:11:36 step 7: objective=28.643686 reg=0.005458
2017/08/29 22:11:36 Training value function...
2017/08/29 22:11:38 step 0: mse=15796.613133 step=0.050000
2017/08/29 22:11:39 step 1: mse=15663.258515 step=0.050000
2017/08/29 22:11:40 step 2: mse=15544.837638 step=0.050000
2017/08/29 22:11:41 step 3: mse=15435.723380 step=0.050000
2017/08/29 22:11:41 step 4: mse=15337.097776 step=0.050000
2017/08/29 22:11:42 step 5: mse=15239.890620 step=0.050000
2017/08/29 22:11:43 step 6: mse=15152.136758 step=0.050000
2017/08/29 22:11:44 step 7: mse=15071.815959 step=0.050000
2017/08/29 22:11:44 Saving...
2017/08/29 22:11:44 Gathering batch of experience...
2017/08/29 22:12:07 batch 222: mean=1065.446429 stddev=484.437521 entropy=0.540672 frames=4862 count=56
2017/08/29 22:12:07 Training policy...
2017/08/29 22:12:09 tune 0: objective=17.657484 reg=0.005407 prune=0
2017/08/29 22:12:10 step 0: objective=17.662915 reg=0.005406
2017/08/29 22:12:11 step 1: objective=17.676289 reg=0.005405
2017/08/29 22:12:12 step 2: objective=17.685226 reg=0.005404
2017/08/29 22:12:13 step 3: objective=17.694597 reg=0.005404
2017/08/29 22:12:13 step 4: objective=17.709617 reg=0.005402
2017/08/29 22:12:14 step 5: objective=17.723643 reg=0.005401
2017/08/29 22:12:15 step 6: objective=17.735768 reg=0.005400
2017/08/29 22:12:16 step 7: objective=17.747791 reg=0.005398
2017/08/29 22:12:16 Training value function...
2017/08/29 22:12:18 step 0: mse=13866.417415 step=0.050000
2017/08/29 22:12:18 step 1: mse=13883.004826 step=0.050000
2017/08/29 22:12:19 step 2: mse=13902.904693 step=0.050000
2017/08/29 22:12:20 step 3: mse=13922.984643 step=0.050000
2017/08/29 22:12:21 step 4: mse=13946.469424 step=0.050000
2017/08/29 22:12:21 step 5: mse=13969.012073 step=0.050000
2017/08/29 22:12:22 step 6: mse=13994.352907 step=0.050000
2017/08/29 22:12:23 step 7: mse=14015.687583 step=0.050000
2017/08/29 22:12:23 Saving...
2017/08/29 22:12:23 Gathering batch of experience...
2017/08/29 22:12:46 batch 223: mean=1023.620690 stddev=594.233636 entropy=0.548803 frames=4899 count=58
2017/08/29 22:12:46 Training policy...
2017/08/29 22:12:49 tune 0: objective=19.619511 reg=0.005488 prune=0
2017/08/29 22:12:50 step 0: objective=19.628213 reg=0.005487
2017/08/29 22:12:51 step 1: objective=19.644980 reg=0.005486
2017/08/29 22:12:51 step 2: objective=19.661828 reg=0.005485
2017/08/29 22:12:52 step 3: objective=19.685695 reg=0.005484
2017/08/29 22:12:53 step 4: objective=19.700285 reg=0.005483
2017/08/29 22:12:54 step 5: objective=19.717536 reg=0.005482
2017/08/29 22:12:55 step 6: objective=19.730699 reg=0.005482
2017/08/29 22:12:55 step 7: objective=19.746107 reg=0.005481
2017/08/29 22:12:55 Training value function...
2017/08/29 22:12:57 step 0: mse=16665.585169 step=0.050000
2017/08/29 22:12:58 step 1: mse=16648.526220 step=0.050000
2017/08/29 22:12:59 step 2: mse=16630.158205 step=0.050000
2017/08/29 22:13:00 step 3: mse=16611.268923 step=0.050000
2017/08/29 22:13:00 step 4: mse=16599.359108 step=0.050000
2017/08/29 22:13:01 step 5: mse=16588.524682 step=0.050000
2017/08/29 22:13:02 step 6: mse=16576.544732 step=0.050000
2017/08/29 22:13:03 step 7: mse=16565.740820 step=0.050000
2017/08/29 22:13:03 Saving...
2017/08/29 22:13:03 Gathering batch of experience...
2017/08/29 22:13:25 batch 224: mean=1156.634615 stddev=511.445652 entropy=0.541032 frames=4876 count=52
2017/08/29 22:13:25 Training policy...
2017/08/29 22:13:28 tune 0: objective=25.970179 reg=0.005410 prune=0
2017/08/29 22:13:29 step 0: objective=25.976795 reg=0.005409
2017/08/29 22:13:30 step 1: objective=25.990361 reg=0.005409
2017/08/29 22:13:31 step 2: objective=26.001754 reg=0.005409
2017/08/29 22:13:31 step 3: objective=26.016308 reg=0.005408
2017/08/29 22:13:32 step 4: objective=26.025852 reg=0.005408
2017/08/29 22:13:33 step 5: objective=26.041874 reg=0.005407
2017/08/29 22:13:34 step 6: objective=26.055400 reg=0.005406
2017/08/29 22:13:35 step 7: objective=26.072003 reg=0.005405
2017/08/29 22:13:35 Training value function...
2017/08/29 22:13:37 step 0: mse=15331.551454 step=0.050000
2017/08/29 22:13:37 step 1: mse=15237.165542 step=0.050000
2017/08/29 22:13:38 step 2: mse=15151.893074 step=0.050000
2017/08/29 22:13:39 step 3: mse=15083.835142 step=0.050000
2017/08/29 22:13:40 step 4: mse=15013.575480 step=0.050000
2017/08/29 22:13:40 step 5: mse=14959.640879 step=0.050000
2017/08/29 22:13:41 step 6: mse=14908.706259 step=0.050000
2017/08/29 22:13:42 step 7: mse=14849.963963 step=0.050000
2017/08/29 22:13:42 Saving...
2017/08/29 22:13:42 Gathering batch of experience...
2017/08/29 22:14:04 batch 225: mean=1237.653061 stddev=576.606984 entropy=0.546778 frames=4855 count=49
2017/08/29 22:14:04 Training policy...
2017/08/29 22:14:07 tune 0: objective=31.512111 reg=0.005468 prune=0
2017/08/29 22:14:08 step 0: objective=31.517717 reg=0.005467
2017/08/29 22:14:09 step 1: objective=31.530732 reg=0.005466
2017/08/29 22:14:09 step 2: objective=31.546453 reg=0.005464
2017/08/29 22:14:10 step 3: objective=31.561116 reg=0.005463
2017/08/29 22:14:11 step 4: objective=31.573803 reg=0.005462
2017/08/29 22:14:12 step 5: objective=31.587082 reg=0.005461
2017/08/29 22:14:13 step 6: objective=31.597538 reg=0.005460
2017/08/29 22:14:14 step 7: objective=31.607109 reg=0.005458
2017/08/29 22:14:14 Training value function...
2017/08/29 22:14:16 step 0: mse=16781.467140 step=0.050000
2017/08/29 22:14:16 step 1: mse=16547.585453 step=0.050000
2017/08/29 22:14:17 step 2: mse=16335.357180 step=0.050000
2017/08/29 22:14:18 step 3: mse=16153.653652 step=0.050000
2017/08/29 22:14:19 step 4: mse=15967.765323 step=0.050000
2017/08/29 22:14:19 step 5: mse=15797.090756 step=0.050000
2017/08/29 22:14:20 step 6: mse=15649.368640 step=0.050000
2017/08/29 22:14:21 step 7: mse=15506.002823 step=0.050000
2017/08/29 22:14:21 Saving...
2017/08/29 22:14:21 Gathering batch of experience...
2017/08/29 22:14:43 batch 226: mean=1121.037736 stddev=555.866109 entropy=0.543426 frames=4861 count=53
2017/08/29 22:14:43 Training policy...
2017/08/29 22:14:46 tune 0: objective=20.501303 reg=0.005434 prune=0
2017/08/29 22:14:47 step 0: objective=20.506615 reg=0.005434
2017/08/29 22:14:48 step 1: objective=20.521411 reg=0.005433
2017/08/29 22:14:49 step 2: objective=20.533156 reg=0.005433
2017/08/29 22:14:49 step 3: objective=20.544326 reg=0.005433
2017/08/29 22:14:50 step 4: objective=20.558979 reg=0.005433
2017/08/29 22:14:51 step 5: objective=20.569244 reg=0.005432
2017/08/29 22:14:52 step 6: objective=20.581264 reg=0.005432
2017/08/29 22:14:53 step 7: objective=20.594669 reg=0.005432
2017/08/29 22:14:53 Training value function...
2017/08/29 22:14:55 step 0: mse=14371.187256 step=0.050000
2017/08/29 22:14:55 step 1: mse=14371.181381 step=0.050000
2017/08/29 22:14:56 step 2: mse=14372.270728 step=0.050000
2017/08/29 22:14:57 step 3: mse=14370.979524 step=0.050000
2017/08/29 22:14:58 step 4: mse=14352.501552 step=0.050000
2017/08/29 22:14:58 step 5: mse=14339.168996 step=0.050000
2017/08/29 22:14:59 step 6: mse=14320.190705 step=0.050000
2017/08/29 22:15:00 step 7: mse=14311.237331 step=0.050000
2017/08/29 22:15:00 Saving...
2017/08/29 22:15:00 Gathering batch of experience...
2017/08/29 22:15:23 batch 227: mean=1100.000000 stddev=550.339121 entropy=0.544049 frames=4866 count=54
2017/08/29 22:15:23 Training policy...
2017/08/29 22:15:26 tune 0: objective=20.694389 reg=0.005440 prune=0
2017/08/29 22:15:26 step 0: objective=20.698554 reg=0.005440
2017/08/29 22:15:27 step 1: objective=20.712419 reg=0.005439
2017/08/29 22:15:28 step 2: objective=20.722380 reg=0.005438
2017/08/29 22:15:29 step 3: objective=20.737143 reg=0.005437
2017/08/29 22:15:30 step 4: objective=20.747940 reg=0.005437
2017/08/29 22:15:30 step 5: objective=20.758108 reg=0.005436
2017/08/29 22:15:31 step 6: objective=20.766344 reg=0.005435
2017/08/29 22:15:32 step 7: objective=20.775196 reg=0.005434
2017/08/29 22:15:32 Training value function...
2017/08/29 22:15:34 step 0: mse=13373.491675 step=0.050000
2017/08/29 22:15:35 step 1: mse=13369.042403 step=0.050000
2017/08/29 22:15:36 step 2: mse=13366.412210 step=0.050000
2017/08/29 22:15:36 step 3: mse=13363.517738 step=0.050000
2017/08/29 22:15:37 step 4: mse=13356.660701 step=0.050000
2017/08/29 22:15:38 step 5: mse=13354.384459 step=0.050000
2017/08/29 22:15:39 step 6: mse=13353.320891 step=0.050000
2017/08/29 22:15:39 step 7: mse=13351.417033 step=0.050000
2017/08/29 22:15:39 Saving...
2017/08/29 22:15:39 Gathering batch of experience...
2017/08/29 22:16:02 batch 228: mean=968.620690 stddev=536.212607 entropy=0.543009 frames=4670 count=58
2017/08/29 22:16:02 Training policy...
2017/08/29 22:16:05 tune 0: objective=13.018249 reg=0.005430 prune=0
2017/08/29 22:16:05 step 0: objective=13.028383 reg=0.005428
2017/08/29 22:16:06 step 1: objective=13.044425 reg=0.005428
2017/08/29 22:16:07 step 2: objective=13.066333 reg=0.005426
2017/08/29 22:16:08 step 3: objective=13.082586 reg=0.005425
2017/08/29 22:16:08 step 4: objective=13.103849 reg=0.005423
2017/08/29 22:16:09 step 5: objective=13.118789 reg=0.005422
2017/08/29 22:16:10 step 6: objective=13.133436 reg=0.005422
2017/08/29 22:16:11 step 7: objective=13.159797 reg=0.005419
2017/08/29 22:16:11 Training value function...
2017/08/29 22:16:13 step 0: mse=13508.477408 step=0.050000
2017/08/29 22:16:13 step 1: mse=13554.035168 step=0.050000
2017/08/29 22:16:14 step 2: mse=13595.987214 step=0.050000
2017/08/29 22:16:15 step 3: mse=13637.230522 step=0.050000
2017/08/29 22:16:16 step 4: mse=13676.970811 step=0.050000
2017/08/29 22:16:16 step 5: mse=13719.744181 step=0.050000
2017/08/29 22:16:17 step 6: mse=13761.518951 step=0.050000
2017/08/29 22:16:18 step 7: mse=13803.993536 step=0.050000
2017/08/29 22:16:18 Saving...
2017/08/29 22:16:18 Gathering batch of experience...
2017/08/29 22:16:42 batch 229: mean=1149.464286 stddev=757.318860 entropy=0.545245 frames=5124 count=56
2017/08/29 22:16:42 Training policy...
2017/08/29 22:16:45 tune 0: objective=30.396041 reg=0.005452 prune=0
2017/08/29 22:16:46 step 0: objective=30.405213 reg=0.005451
2017/08/29 22:16:46 step 1: objective=30.434298 reg=0.005450
2017/08/29 22:16:47 step 2: objective=30.466497 reg=0.005448
2017/08/29 22:16:48 step 3: objective=30.494331 reg=0.005447
2017/08/29 22:16:49 step 4: objective=30.524233 reg=0.005445
2017/08/29 22:16:50 step 5: objective=30.551638 reg=0.005443
2017/08/29 22:16:51 step 6: objective=30.580351 reg=0.005441
2017/08/29 22:16:52 step 7: objective=30.603639 reg=0.005440
2017/08/29 22:16:52 Training value function...
2017/08/29 22:16:54 step 0: mse=24472.403937 step=0.050000
2017/08/29 22:16:54 step 1: mse=24104.469944 step=0.050000
2017/08/29 22:16:55 step 2: mse=23767.579289 step=0.050000
2017/08/29 22:16:56 step 3: mse=23434.132304 step=0.050000
2017/08/29 22:16:57 step 4: mse=23167.701754 step=0.050000
2017/08/29 22:16:58 step 5: mse=22884.710139 step=0.050000
2017/08/29 22:16:59 step 6: mse=22673.639710 step=0.050000
2017/08/29 22:16:59 step 7: mse=22439.318248 step=0.050000
2017/08/29 22:16:59 Saving...
2017/08/29 22:16:59 Gathering batch of experience...
2017/08/29 22:17:22 batch 230: mean=1161.568627 stddev=559.209430 entropy=0.539418 frames=4823 count=51
2017/08/29 22:17:22 Training policy...
2017/08/29 22:17:25 tune 0: objective=24.371466 reg=0.005394 prune=0
2017/08/29 22:17:25 step 0: objective=24.377632 reg=0.005394
2017/08/29 22:17:26 step 1: objective=24.391837 reg=0.005393
2017/08/29 22:17:27 step 2: objective=24.405923 reg=0.005393
2017/08/29 22:17:28 step 3: objective=24.421540 reg=0.005393
2017/08/29 22:17:29 step 4: objective=24.436248 reg=0.005393
2017/08/29 22:17:29 step 5: objective=24.445978 reg=0.005392
2017/08/29 22:17:30 step 6: objective=24.461318 reg=0.005392
2017/08/29 22:17:31 step 7: objective=24.477209 reg=0.005392
2017/08/29 22:17:31 Training value function...
2017/08/29 22:17:33 step 0: mse=16720.611799 step=0.050000
2017/08/29 22:17:34 step 1: mse=16668.884208 step=0.050000
2017/08/29 22:17:34 step 2: mse=16617.189902 step=0.050000
2017/08/29 22:17:35 step 3: mse=16572.536453 step=0.050000
2017/08/29 22:17:36 step 4: mse=16531.848092 step=0.050000
2017/08/29 22:17:37 step 5: mse=16495.325625 step=0.050000
2017/08/29 22:17:37 step 6: mse=16464.643049 step=0.050000
2017/08/29 22:17:38 step 7: mse=16435.720698 step=0.050000
2017/08/29 22:17:38 Saving...
2017/08/29 22:17:38 Gathering batch of experience...
2017/08/29 22:18:00 batch 231: mean=1078.396226 stddev=555.515037 entropy=0.539355 frames=4657 count=53
2017/08/29 22:18:00 Training policy...
2017/08/29 22:18:03 tune 0: objective=20.643992 reg=0.005394 prune=0
2017/08/29 22:18:04 step 0: objective=20.650997 reg=0.005392
2017/08/29 22:18:05 step 1: objective=20.660258 reg=0.005391
2017/08/29 22:18:05 step 2: objective=20.680934 reg=0.005390
2017/08/29 22:18:06 step 3: objective=20.700052 reg=0.005389
2017/08/29 22:18:07 step 4: objective=20.718748 reg=0.005389
2017/08/29 22:18:08 step 5: objective=20.729096 reg=0.005388
2017/08/29 22:18:09 step 6: objective=20.742669 reg=0.005388
2017/08/29 22:18:09 step 7: objective=20.762543 reg=0.005387
2017/08/29 22:18:09 Training value function...
2017/08/29 22:18:11 step 0: mse=15272.634206 step=0.050000
2017/08/29 22:18:12 step 1: mse=15284.120005 step=0.050000
2017/08/29 22:18:13 step 2: mse=15281.613634 step=0.050000
2017/08/29 22:18:13 step 3: mse=15277.550178 step=0.050000
2017/08/29 22:18:14 step 4: mse=15277.898010 step=0.050000
2017/08/29 22:18:15 step 5: mse=15284.472495 step=0.050000
2017/08/29 22:18:16 step 6: mse=15285.886236 step=0.050000
2017/08/29 22:18:16 step 7: mse=15279.314683 step=0.050000
2017/08/29 22:18:16 Saving...
2017/08/29 22:18:16 Gathering batch of experience...
2017/08/29 22:18:39 batch 232: mean=1108.148148 stddev=537.199784 entropy=0.537142 frames=4895 count=54
2017/08/29 22:18:39 Training policy...
2017/08/29 22:18:42 tune 0: objective=22.502570 reg=0.005371 prune=0
2017/08/29 22:18:43 step 0: objective=22.507915 reg=0.005370
2017/08/29 22:18:44 step 1: objective=22.524287 reg=0.005370
2017/08/29 22:18:45 step 2: objective=22.533486 reg=0.005369
2017/08/29 22:18:45 step 3: objective=22.546106 reg=0.005368
2017/08/29 22:18:46 step 4: objective=22.561858 reg=0.005367
2017/08/29 22:18:47 step 5: objective=22.574555 reg=0.005366
2017/08/29 22:18:48 step 6: objective=22.585163 reg=0.005366
2017/08/29 22:18:49 step 7: objective=22.603213 reg=0.005365
2017/08/29 22:18:49 Training value function...
2017/08/29 22:18:51 step 0: mse=15421.291958 step=0.050000
2017/08/29 22:18:51 step 1: mse=15414.969755 step=0.050000
2017/08/29 22:18:52 step 2: mse=15400.580388 step=0.050000
2017/08/29 22:18:53 step 3: mse=15393.551153 step=0.050000
2017/08/29 22:18:54 step 4: mse=15385.446133 step=0.050000
2017/08/29 22:18:54 step 5: mse=15377.863059 step=0.050000
2017/08/29 22:18:55 step 6: mse=15366.355673 step=0.050000
2017/08/29 22:18:56 step 7: mse=15360.574686 step=0.050000
2017/08/29 22:18:56 Saving...
2017/08/29 22:18:56 Gathering batch of experience...
2017/08/29 22:19:19 batch 233: mean=1097.454545 stddev=524.754378 entropy=0.536145 frames=4900 count=55
2017/08/29 22:19:19 Training policy...
2017/08/29 22:19:22 tune 0: objective=22.007943 reg=0.005361 prune=0
2017/08/29 22:19:23 step 0: objective=22.013119 reg=0.005360
2017/08/29 22:19:24 step 1: objective=22.024442 reg=0.005359
2017/08/29 22:19:25 step 2: objective=22.037825 reg=0.005358
2017/08/29 22:19:25 step 3: objective=22.048747 reg=0.005358
2017/08/29 22:19:26 step 4: objective=22.062498 reg=0.005356
2017/08/29 22:19:27 step 5: objective=22.073760 reg=0.005356
2017/08/29 22:19:28 step 6: objective=22.088605 reg=0.005355
2017/08/29 22:19:29 step 7: objective=22.103560 reg=0.005354
2017/08/29 22:19:29 Training value function...
2017/08/29 22:19:31 step 0: mse=14276.449230 step=0.050000
2017/08/29 22:19:31 step 1: mse=14246.508934 step=0.050000
2017/08/29 22:19:32 step 2: mse=14198.152622 step=0.050000
2017/08/29 22:19:33 step 3: mse=14150.210773 step=0.050000
2017/08/29 22:19:34 step 4: mse=14107.440384 step=0.050000
2017/08/29 22:19:34 step 5: mse=14070.829774 step=0.050000
2017/08/29 22:19:35 step 6: mse=14043.306604 step=0.050000
2017/08/29 22:19:36 step 7: mse=14018.167184 step=0.050000
2017/08/29 22:19:36 Saving...
2017/08/29 22:19:36 Gathering batch of experience...
2017/08/29 22:19:59 batch 234: mean=1083.454545 stddev=559.571973 entropy=0.537492 frames=4901 count=55
2017/08/29 22:19:59 Training policy...
2017/08/29 22:20:02 tune 0: objective=21.134289 reg=0.005375 prune=0
2017/08/29 22:20:03 step 0: objective=21.139619 reg=0.005375
2017/08/29 22:20:03 step 1: objective=21.151579 reg=0.005375
2017/08/29 22:20:04 step 2: objective=21.164096 reg=0.005375
2017/08/29 22:20:05 step 3: objective=21.179778 reg=0.005375
2017/08/29 22:20:06 step 4: objective=21.192678 reg=0.005375
2017/08/29 22:20:07 step 5: objective=21.207048 reg=0.005374
2017/08/29 22:20:07 step 6: objective=21.221352 reg=0.005374
2017/08/29 22:20:08 step 7: objective=21.235365 reg=0.005374
2017/08/29 22:20:08 Training value function...
2017/08/29 22:20:10 step 0: mse=15491.700126 step=0.050000
2017/08/29 22:20:11 step 1: mse=15486.076640 step=0.050000
2017/08/29 22:20:12 step 2: mse=15479.738905 step=0.050000
2017/08/29 22:20:13 step 3: mse=15476.257700 step=0.050000
2017/08/29 22:20:13 step 4: mse=15470.842097 step=0.050000
2017/08/29 22:20:14 step 5: mse=15467.628040 step=0.050000
2017/08/29 22:20:15 step 6: mse=15462.614992 step=0.050000
2017/08/29 22:20:16 step 7: mse=15458.799804 step=0.050000
2017/08/29 22:20:16 Saving...
2017/08/29 22:20:16 Gathering batch of experience...
2017/08/29 22:20:37 batch 235: mean=1077.075472 stddev=547.414535 entropy=0.537656 frames=4713 count=53
2017/08/29 22:20:37 Training policy...
2017/08/29 22:20:40 tune 0: objective=21.137107 reg=0.005377 prune=0
2017/08/29 22:20:41 step 0: objective=21.143693 reg=0.005376
2017/08/29 22:20:42 step 1: objective=21.158559 reg=0.005375
2017/08/29 22:20:43 step 2: objective=21.172931 reg=0.005373
2017/08/29 22:20:43 step 3: objective=21.184291 reg=0.005373
2017/08/29 22:20:44 step 4: objective=21.194673 reg=0.005373
2017/08/29 22:20:45 step 5: objective=21.206361 reg=0.005372
2017/08/29 22:20:46 step 6: objective=21.218228 reg=0.005372
2017/08/29 22:20:46 step 7: objective=21.229215 reg=0.005371
2017/08/29 22:20:46 Training value function...
2017/08/29 22:20:48 step 0: mse=14715.774554 step=0.050000
2017/08/29 22:20:49 step 1: mse=14694.757110 step=0.050000
2017/08/29 22:20:50 step 2: mse=14669.960425 step=0.050000
2017/08/29 22:20:51 step 3: mse=14644.552814 step=0.050000
2017/08/29 22:20:51 step 4: mse=14627.201051 step=0.050000
2017/08/29 22:20:52 step 5: mse=14611.941596 step=0.050000
2017/08/29 22:20:53 step 6: mse=14597.829066 step=0.050000
2017/08/29 22:20:53 step 7: mse=14583.675392 step=0.050000
2017/08/29 22:20:53 Saving...
2017/08/29 22:20:54 Gathering batch of experience...
2017/08/29 22:21:16 batch 236: mean=1369.150943 stddev=2502.971392 entropy=0.541837 frames=4899 count=53
2017/08/29 22:21:16 Training policy...
2017/08/29 22:21:19 tune 0: objective=56.531122 reg=0.005418 prune=0
2017/08/29 22:21:20 step 0: objective=56.619891 reg=0.005419
2017/08/29 22:21:21 step 1: objective=57.036883 reg=0.005421
2017/08/29 22:21:21 step 2: objective=57.360105 reg=0.005423
2017/08/29 22:21:22 step 3: objective=57.498954 reg=0.005421
2017/08/29 22:21:23 step 4: objective=57.628483 reg=0.005422
2017/08/29 22:21:24 step 5: objective=57.729256 reg=0.005420
2017/08/29 22:21:25 step 6: objective=57.832874 reg=0.005418
2017/08/29 22:21:26 step 7: objective=57.933577 reg=0.005415
2017/08/29 22:21:26 Training value function...
2017/08/29 22:21:27 step 0: mse=259909.974096 step=0.050000
2017/08/29 22:21:28 step 1: mse=254223.659928 step=0.050000
2017/08/29 22:21:29 step 2: mse=249286.986081 step=0.050000
2017/08/29 22:21:30 step 3: mse=245260.181789 step=0.050000
2017/08/29 22:21:31 step 4: mse=240941.555050 step=0.050000
2017/08/29 22:21:31 step 5: mse=237184.293649 step=0.050000
2017/08/29 22:21:32 step 6: mse=233667.183920 step=0.050000
2017/08/29 22:21:33 step 7: mse=230555.129985 step=0.050000
2017/08/29 22:21:33 Saving...
2017/08/29 22:21:33 Gathering batch of experience...
2017/08/29 22:21:56 batch 237: mean=1148.584906 stddev=539.832589 entropy=0.533148 frames=4896 count=53
2017/08/29 22:21:56 Training policy...
2017/08/29 22:21:59 tune 0: objective=20.373061 reg=0.005331 prune=0
2017/08/29 22:22:00 step 0: objective=20.380148 reg=0.005330
2017/08/29 22:22:00 step 1: objective=20.392792 reg=0.005329
2017/08/29 22:22:01 step 2: objective=20.405253 reg=0.005328
2017/08/29 22:22:02 step 3: objective=20.423123 reg=0.005328
2017/08/29 22:22:03 step 4: objective=20.439325 reg=0.005328
2017/08/29 22:22:04 step 5: objective=20.451360 reg=0.005326
2017/08/29 22:22:04 step 6: objective=20.467703 reg=0.005326
2017/08/29 22:22:05 step 7: objective=20.480687 reg=0.005325
2017/08/29 22:22:05 Training value function...
2017/08/29 22:22:07 step 0: mse=14205.513456 step=0.050000
2017/08/29 22:22:08 step 1: mse=14090.374335 step=0.050000
2017/08/29 22:22:09 step 2: mse=13983.673130 step=0.050000
2017/08/29 22:22:10 step 3: mse=13891.690770 step=0.050000
2017/08/29 22:22:10 step 4: mse=13811.072902 step=0.050000
2017/08/29 22:22:11 step 5: mse=13735.849941 step=0.050000
2017/08/29 22:22:12 step 6: mse=13668.925397 step=0.050000
2017/08/29 22:22:13 step 7: mse=13615.001681 step=0.050000
2017/08/29 22:22:13 Saving...
2017/08/29 22:22:13 Gathering batch of experience...
2017/08/29 22:22:35 batch 238: mean=1079.727273 stddev=546.563993 entropy=0.535183 frames=4893 count=55
2017/08/29 22:22:35 Training policy...
2017/08/29 22:22:38 tune 0: objective=15.816465 reg=0.005352 prune=0
2017/08/29 22:22:39 step 0: objective=15.824129 reg=0.005350
2017/08/29 22:22:40 step 1: objective=15.841181 reg=0.005349
2017/08/29 22:22:41 step 2: objective=15.856986 reg=0.005348
2017/08/29 22:22:41 step 3: objective=15.866629 reg=0.005347
2017/08/29 22:22:42 step 4: objective=15.879313 reg=0.005345
2017/08/29 22:22:43 step 5: objective=15.891043 reg=0.005345
2017/08/29 22:22:44 step 6: objective=15.904439 reg=0.005344
2017/08/29 22:22:45 step 7: objective=15.920232 reg=0.005343
2017/08/29 22:22:45 Training value function...
2017/08/29 22:22:47 step 0: mse=15062.293525 step=0.050000
2017/08/29 22:22:48 step 1: mse=15078.082882 step=0.050000
2017/08/29 22:22:48 step 2: mse=15104.263543 step=0.050000
2017/08/29 22:22:49 step 3: mse=15116.566391 step=0.050000
2017/08/29 22:22:50 step 4: mse=15137.792585 step=0.050000
2017/08/29 22:22:51 step 5: mse=15162.495310 step=0.050000
2017/08/29 22:22:51 step 6: mse=15180.956434 step=0.050000
2017/08/29 22:22:52 step 7: mse=15198.557878 step=0.050000
2017/08/29 22:22:52 Saving...
2017/08/29 22:22:52 Gathering batch of experience...
2017/08/29 22:23:14 batch 239: mean=1050.363636 stddev=530.223670 entropy=0.532530 frames=4715 count=55
2017/08/29 22:23:14 Training policy...
2017/08/29 22:23:17 tune 0: objective=16.751695 reg=0.005325 prune=0
2017/08/29 22:23:18 step 0: objective=16.756919 reg=0.005325
2017/08/29 22:23:19 step 1: objective=16.767434 reg=0.005324
2017/08/29 22:23:20 step 2: objective=16.780322 reg=0.005323
2017/08/29 22:23:20 step 3: objective=16.789775 reg=0.005322
2017/08/29 22:23:21 step 4: objective=16.802306 reg=0.005322
2017/08/29 22:23:22 step 5: objective=16.811836 reg=0.005320
2017/08/29 22:23:23 step 6: objective=16.821262 reg=0.005319
2017/08/29 22:23:23 step 7: objective=16.833099 reg=0.005318
2017/08/29 22:23:23 Training value function...
2017/08/29 22:23:25 step 0: mse=14120.420185 step=0.050000
2017/08/29 22:23:26 step 1: mse=14136.940827 step=0.050000
2017/08/29 22:23:27 step 2: mse=14158.339604 step=0.050000
2017/08/29 22:23:28 step 3: mse=14181.377404 step=0.050000
2017/08/29 22:23:28 step 4: mse=14209.297195 step=0.050000
2017/08/29 22:23:29 step 5: mse=14234.833560 step=0.050000
2017/08/29 22:23:30 step 6: mse=14251.503939 step=0.050000
2017/08/29 22:23:31 step 7: mse=14267.914986 step=0.050000
2017/08/29 22:23:31 Saving...
2017/08/29 22:23:31 Gathering batch of experience...
2017/08/29 22:23:53 batch 240: mean=1133.301887 stddev=516.233587 entropy=0.529571 frames=4851 count=53
2017/08/29 22:23:53 Training policy...
2017/08/29 22:23:56 tune 0: objective=24.276947 reg=0.005296 prune=0
2017/08/29 22:23:57 step 0: objective=24.281184 reg=0.005295
2017/08/29 22:23:58 step 1: objective=24.296021 reg=0.005294
2017/08/29 22:23:59 step 2: objective=24.307432 reg=0.005294
2017/08/29 22:23:59 step 3: objective=24.320863 reg=0.005293
2017/08/29 22:24:00 step 4: objective=24.332560 reg=0.005293
2017/08/29 22:24:01 step 5: objective=24.344526 reg=0.005293
2017/08/29 22:24:02 step 6: objective=24.357326 reg=0.005292
2017/08/29 22:24:03 step 7: objective=24.369312 reg=0.005292
2017/08/29 22:24:03 Training value function...
2017/08/29 22:24:05 step 0: mse=13819.797719 step=0.050000
2017/08/29 22:24:05 step 1: mse=13764.600093 step=0.050000
2017/08/29 22:24:06 step 2: mse=13715.361075 step=0.050000
2017/08/29 22:24:07 step 3: mse=13666.032429 step=0.050000
2017/08/29 22:24:08 step 4: mse=13622.162369 step=0.050000
2017/08/29 22:24:08 step 5: mse=13580.284061 step=0.050000
2017/08/29 22:24:09 step 6: mse=13540.392701 step=0.050000
2017/08/29 22:24:10 step 7: mse=13505.172506 step=0.050000
2017/08/29 22:24:10 Saving...
2017/08/29 22:24:10 Gathering batch of experience...
2017/08/29 22:24:33 batch 241: mean=1280.937500 stddev=537.890998 entropy=0.531489 frames=4923 count=48
2017/08/29 22:24:33 Training policy...
2017/08/29 22:24:35 tune 0: objective=31.150289 reg=0.005315 prune=0
2017/08/29 22:24:36 step 0: objective=31.155768 reg=0.005314
2017/08/29 22:24:37 step 1: objective=31.170767 reg=0.005314
2017/08/29 22:24:38 step 2: objective=31.191074 reg=0.005313
2017/08/29 22:24:39 step 3: objective=31.205505 reg=0.005312
2017/08/29 22:24:40 step 4: objective=31.220251 reg=0.005311
2017/08/29 22:24:40 step 5: objective=31.238812 reg=0.005311
2017/08/29 22:24:41 step 6: objective=31.257446 reg=0.005310
2017/08/29 22:24:42 step 7: objective=31.272674 reg=0.005308
2017/08/29 22:24:42 Training value function...
2017/08/29 22:24:44 step 0: mse=16551.748492 step=0.050000
2017/08/29 22:24:45 step 1: mse=16345.160244 step=0.050000
2017/08/29 22:24:46 step 2: mse=16150.347516 step=0.050000
2017/08/29 22:24:46 step 3: mse=15972.602376 step=0.050000
2017/08/29 22:24:47 step 4: mse=15813.132744 step=0.050000
2017/08/29 22:24:48 step 5: mse=15658.351505 step=0.050000
2017/08/29 22:24:49 step 6: mse=15515.361193 step=0.050000
2017/08/29 22:24:49 step 7: mse=15385.902920 step=0.050000
2017/08/29 22:24:49 Saving...
2017/08/29 22:24:49 Gathering batch of experience...
2017/08/29 22:25:12 batch 242: mean=1294.375000 stddev=484.132197 entropy=0.526397 frames=4870 count=48
2017/08/29 22:25:12 Training policy...
2017/08/29 22:25:14 tune 0: objective=29.726367 reg=0.005264 prune=0
2017/08/29 22:25:15 step 0: objective=29.730900 reg=0.005263
2017/08/29 22:25:16 step 1: objective=29.744841 reg=0.005262
2017/08/29 22:25:17 step 2: objective=29.754601 reg=0.005261
2017/08/29 22:25:18 step 3: objective=29.766912 reg=0.005260
2017/08/29 22:25:19 step 4: objective=29.780666 reg=0.005259
2017/08/29 22:25:19 step 5: objective=29.794135 reg=0.005257
2017/08/29 22:25:20 step 6: objective=29.806446 reg=0.005256
2017/08/29 22:25:21 step 7: objective=29.818686 reg=0.005255
2017/08/29 22:25:21 Training value function...
2017/08/29 22:25:23 step 0: mse=13688.222011 step=0.050000
2017/08/29 22:25:24 step 1: mse=13554.820250 step=0.050000
2017/08/29 22:25:24 step 2: mse=13434.193536 step=0.050000
2017/08/29 22:25:25 step 3: mse=13321.355920 step=0.050000
2017/08/29 22:25:26 step 4: mse=13219.404546 step=0.050000
2017/08/29 22:25:27 step 5: mse=13126.251717 step=0.050000
2017/08/29 22:25:28 step 6: mse=13038.288411 step=0.050000
2017/08/29 22:25:28 step 7: mse=12953.069498 step=0.050000
2017/08/29 22:25:28 Saving...
2017/08/29 22:25:28 Gathering batch of experience...
2017/08/29 22:25:51 batch 243: mean=1088.396226 stddev=580.267321 entropy=0.533282 frames=4701 count=53
2017/08/29 22:25:51 Training policy...
2017/08/29 22:25:53 tune 0: objective=17.251655 reg=0.005333 prune=0
2017/08/29 22:25:54 step 0: objective=17.257678 reg=0.005332
2017/08/29 22:25:55 step 1: objective=17.272615 reg=0.005331
2017/08/29 22:25:56 step 2: objective=17.285799 reg=0.005331
2017/08/29 22:25:57 step 3: objective=17.296556 reg=0.005330
2017/08/29 22:25:57 step 4: objective=17.309934 reg=0.005329
2017/08/29 22:25:58 step 5: objective=17.322445 reg=0.005328
2017/08/29 22:25:59 step 6: objective=17.337892 reg=0.005328
2017/08/29 22:26:00 step 7: objective=17.351042 reg=0.005327
2017/08/29 22:26:00 Training value function...
2017/08/29 22:26:02 step 0: mse=13452.165734 step=0.050000
2017/08/29 22:26:02 step 1: mse=13470.467460 step=0.050000
2017/08/29 22:26:03 step 2: mse=13485.752243 step=0.050000
2017/08/29 22:26:04 step 3: mse=13501.832516 step=0.050000
2017/08/29 22:26:05 step 4: mse=13518.034258 step=0.050000
2017/08/29 22:26:05 step 5: mse=13538.464433 step=0.050000
2017/08/29 22:26:06 step 6: mse=13557.692298 step=0.050000
2017/08/29 22:26:07 step 7: mse=13573.588586 step=0.050000
2017/08/29 22:26:07 Saving...
2017/08/29 22:26:07 Gathering batch of experience...
2017/08/29 22:26:29 batch 244: mean=1357.282609 stddev=575.534446 entropy=0.534133 frames=4925 count=46
2017/08/29 22:26:29 Training policy...
2017/08/29 22:26:32 tune 0: objective=33.815152 reg=0.005341 prune=0
2017/08/29 22:26:33 step 0: objective=33.823442 reg=0.005341
2017/08/29 22:26:34 step 1: objective=33.836945 reg=0.005340
2017/08/29 22:26:35 step 2: objective=33.849375 reg=0.005339
2017/08/29 22:26:36 step 3: objective=33.862157 reg=0.005339
2017/08/29 22:26:36 step 4: objective=33.873420 reg=0.005338
2017/08/29 22:26:37 step 5: objective=33.886380 reg=0.005337
2017/08/29 22:26:38 step 6: objective=33.901196 reg=0.005336
2017/08/29 22:26:39 step 7: objective=33.914115 reg=0.005335
2017/08/29 22:26:39 Training value function...
2017/08/29 22:26:41 step 0: mse=15831.727599 step=0.050000
2017/08/29 22:26:42 step 1: mse=15537.137557 step=0.050000
2017/08/29 22:26:42 step 2: mse=15271.256418 step=0.050000
2017/08/29 22:26:43 step 3: mse=15022.354983 step=0.050000
2017/08/29 22:26:44 step 4: mse=14794.764813 step=0.050000
2017/08/29 22:26:45 step 5: mse=14582.753910 step=0.050000
2017/08/29 22:26:45 step 6: mse=14388.031259 step=0.050000
2017/08/29 22:26:46 step 7: mse=14207.515188 step=0.050000
2017/08/29 22:26:46 Saving...
2017/08/29 22:26:46 Gathering batch of experience...
2017/08/29 22:27:10 batch 245: mean=1072.767857 stddev=593.713284 entropy=0.535469 frames=4907 count=56
2017/08/29 22:27:10 Training policy...
2017/08/29 22:27:12 tune 0: objective=14.361499 reg=0.005355 prune=0
2017/08/29 22:27:13 step 0: objective=14.366723 reg=0.005354
2017/08/29 22:27:14 step 1: objective=14.378511 reg=0.005352
2017/08/29 22:27:15 step 2: objective=14.388156 reg=0.005351
2017/08/29 22:27:16 step 3: objective=14.401362 reg=0.005350
2017/08/29 22:27:17 step 4: objective=14.416561 reg=0.005349
2017/08/29 22:27:17 step 5: objective=14.424838 reg=0.005348
2017/08/29 22:27:18 step 6: objective=14.438030 reg=0.005348
2017/08/29 22:27:19 step 7: objective=14.451047 reg=0.005347
2017/08/29 22:27:19 Training value function...
2017/08/29 22:27:21 step 0: mse=14350.953919 step=0.050000
2017/08/29 22:27:22 step 1: mse=14385.585545 step=0.050000
2017/08/29 22:27:23 step 2: mse=14422.678543 step=0.050000
2017/08/29 22:27:23 step 3: mse=14458.248464 step=0.050000
2017/08/29 22:27:24 step 4: mse=14492.700453 step=0.050000
2017/08/29 22:27:25 step 5: mse=14525.373497 step=0.050000
2017/08/29 22:27:26 step 6: mse=14554.964409 step=0.050000
2017/08/29 22:27:26 step 7: mse=14586.679316 step=0.050000
2017/08/29 22:27:26 Saving...
2017/08/29 22:27:26 Gathering batch of experience...
2017/08/29 22:27:49 batch 246: mean=1223.300000 stddev=531.576533 entropy=0.525880 frames=4852 count=50
2017/08/29 22:27:49 Training policy...
2017/08/29 22:27:52 tune 0: objective=24.829263 reg=0.005259 prune=0
2017/08/29 22:27:53 step 0: objective=24.832981 reg=0.005258
2017/08/29 22:27:53 step 1: objective=24.842600 reg=0.005258
2017/08/29 22:27:54 step 2: objective=24.853066 reg=0.005257
2017/08/29 22:27:55 step 3: objective=24.864758 reg=0.005256
2017/08/29 22:27:56 step 4: objective=24.876510 reg=0.005256
2017/08/29 22:27:57 step 5: objective=24.885025 reg=0.005256
2017/08/29 22:27:58 step 6: objective=24.893288 reg=0.005255
2017/08/29 22:27:58 step 7: objective=24.906037 reg=0.005255
2017/08/29 22:27:58 Training value function...
2017/08/29 22:28:00 step 0: mse=13000.672453 step=0.050000
2017/08/29 22:28:01 step 1: mse=12949.259987 step=0.050000
2017/08/29 22:28:02 step 2: mse=12897.358843 step=0.050000
2017/08/29 22:28:03 step 3: mse=12852.088290 step=0.050000
2017/08/29 22:28:03 step 4: mse=12809.657528 step=0.050000
2017/08/29 22:28:04 step 5: mse=12771.459476 step=0.050000
2017/08/29 22:28:05 step 6: mse=12736.056114 step=0.050000
2017/08/29 22:28:06 step 7: mse=12700.624071 step=0.050000
2017/08/29 22:28:06 Saving...
2017/08/29 22:28:06 Gathering batch of experience...
2017/08/29 22:28:28 batch 247: mean=1134.117647 stddev=580.038628 entropy=0.531668 frames=4712 count=51
2017/08/29 22:28:28 Training policy...
2017/08/29 22:28:31 tune 0: objective=18.529653 reg=0.005317 prune=0
2017/08/29 22:28:32 step 0: objective=18.537051 reg=0.005316
2017/08/29 22:28:33 step 1: objective=18.548884 reg=0.005315
2017/08/29 22:28:34 step 2: objective=18.567127 reg=0.005315
2017/08/29 22:28:34 step 3: objective=18.578155 reg=0.005314
2017/08/29 22:28:35 step 4: objective=18.589724 reg=0.005313
2017/08/29 22:28:36 step 5: objective=18.603093 reg=0.005313
2017/08/29 22:28:37 step 6: objective=18.615055 reg=0.005312
2017/08/29 22:28:38 step 7: objective=18.630314 reg=0.005311
2017/08/29 22:28:38 Training value function...
2017/08/29 22:28:39 step 0: mse=14917.733838 step=0.050000
2017/08/29 22:28:40 step 1: mse=14926.798944 step=0.050000
2017/08/29 22:28:41 step 2: mse=14938.532783 step=0.050000
2017/08/29 22:28:42 step 3: mse=14947.523542 step=0.050000
2017/08/29 22:28:42 step 4: mse=14963.704980 step=0.050000
2017/08/29 22:28:43 step 5: mse=14981.855308 step=0.050000
2017/08/29 22:28:44 step 6: mse=14988.769418 step=0.050000
2017/08/29 22:28:45 step 7: mse=15003.279140 step=0.050000
2017/08/29 22:28:45 Saving...
2017/08/29 22:28:45 Gathering batch of experience...
2017/08/29 22:29:06 batch 248: mean=1119.117647 stddev=550.537799 entropy=0.526354 frames=4622 count=51
2017/08/29 22:29:06 Training policy...
2017/08/29 22:29:09 tune 0: objective=19.850029 reg=0.005264 prune=0
2017/08/29 22:29:10 step 0: objective=19.858415 reg=0.005262
2017/08/29 22:29:11 step 1: objective=19.879645 reg=0.005261
2017/08/29 22:29:12 step 2: objective=19.899538 reg=0.005259
2017/08/29 22:29:12 step 3: objective=19.922734 reg=0.005257
2017/08/29 22:29:13 step 4: objective=19.939929 reg=0.005255
2017/08/29 22:29:14 step 5: objective=19.960067 reg=0.005253
2017/08/29 22:29:15 step 6: objective=19.981481 reg=0.005251
2017/08/29 22:29:15 step 7: objective=20.001146 reg=0.005249
2017/08/29 22:29:15 Training value function...
2017/08/29 22:29:17 step 0: mse=14921.317190 step=0.050000
2017/08/29 22:29:18 step 1: mse=14936.257169 step=0.050000
2017/08/29 22:29:19 step 2: mse=14953.955479 step=0.050000
2017/08/29 22:29:19 step 3: mse=14968.127050 step=0.050000
2017/08/29 22:29:20 step 4: mse=14980.541077 step=0.050000
2017/08/29 22:29:21 step 5: mse=14990.609113 step=0.050000
2017/08/29 22:29:22 step 6: mse=15001.666222 step=0.050000
2017/08/29 22:29:22 step 7: mse=15015.668935 step=0.050000
2017/08/29 22:29:22 Saving...
2017/08/29 22:29:22 Gathering batch of experience...
2017/08/29 22:29:44 batch 249: mean=1156.764706 stddev=566.504438 entropy=0.525866 frames=4768 count=51
2017/08/29 22:29:44 Training policy...
2017/08/29 22:29:47 tune 0: objective=23.114802 reg=0.005259 prune=0
2017/08/29 22:29:48 step 0: objective=23.121661 reg=0.005258
2017/08/29 22:29:49 step 1: objective=23.137164 reg=0.005256
2017/08/29 22:29:50 step 2: objective=23.153335 reg=0.005255
2017/08/29 22:29:51 step 3: objective=23.166543 reg=0.005254
2017/08/29 22:29:51 step 4: objective=23.178665 reg=0.005253
2017/08/29 22:29:52 step 5: objective=23.192347 reg=0.005252
2017/08/29 22:29:53 step 6: objective=23.206102 reg=0.005250
2017/08/29 22:29:54 step 7: objective=23.217521 reg=0.005249
2017/08/29 22:29:54 Training value function...
2017/08/29 22:29:56 step 0: mse=14883.756806 step=0.050000
2017/08/29 22:29:56 step 1: mse=14859.380989 step=0.050000
2017/08/29 22:29:57 step 2: mse=14834.006227 step=0.050000
2017/08/29 22:29:58 step 3: mse=14814.322828 step=0.050000
2017/08/29 22:29:59 step 4: mse=14794.838975 step=0.050000
2017/08/29 22:29:59 step 5: mse=14783.300574 step=0.050000
2017/08/29 22:30:00 step 6: mse=14767.230493 step=0.050000
2017/08/29 22:30:01 step 7: mse=14751.568844 step=0.050000
2017/08/29 22:30:01 Saving...
2017/08/29 22:30:01 Gathering batch of experience...
2017/08/29 22:30:24 batch 250: mean=1704.555556 stddev=2890.604093 entropy=0.529913 frames=5029 count=45
2017/08/29 22:30:24 Training policy...
2017/08/29 22:30:27 tune 0: objective=64.718508 reg=0.005299 prune=0
2017/08/29 22:30:28 step 0: objective=64.779467 reg=0.005297
2017/08/29 22:30:28 step 1: objective=64.956459 reg=0.005298
2017/08/29 22:30:29 step 2: objective=65.185201 reg=0.005294
2017/08/29 22:30:30 step 3: objective=65.266051 reg=0.005294
2017/08/29 22:30:31 step 4: objective=65.453054 reg=0.005292
2017/08/29 22:30:32 step 5: objective=65.634893 reg=0.005290
2017/08/29 22:30:33 step 6: objective=65.802067 reg=0.005289
2017/08/29 22:30:33 step 7: objective=65.932423 reg=0.005286
2017/08/29 22:30:33 Training value function...
2017/08/29 22:30:35 step 0: mse=273045.804033 step=0.050000
2017/08/29 22:30:36 step 1: mse=266231.650899 step=0.050000
2017/08/29 22:30:37 step 2: mse=258034.239008 step=0.050000
2017/08/29 22:30:38 step 3: mse=253025.281669 step=0.050000
2017/08/29 22:30:39 step 4: mse=246860.425548 step=0.050000
2017/08/29 22:30:39 step 5: mse=241014.948706 step=0.050000
2017/08/29 22:30:40 step 6: mse=237430.290794 step=0.050000
2017/08/29 22:30:41 step 7: mse=232289.063473 step=0.050000
2017/08/29 22:30:41 Saving...
2017/08/29 22:30:41 Gathering batch of experience...
2017/08/29 22:31:03 batch 251: mean=1155.673077 stddev=558.578234 entropy=0.525091 frames=4863 count=52
2017/08/29 22:31:03 Training policy...
2017/08/29 22:31:06 tune 0: objective=12.180351 reg=0.005251 prune=0
2017/08/29 22:31:07 step 0: objective=12.185020 reg=0.005250
2017/08/29 22:31:08 step 1: objective=12.196619 reg=0.005250
2017/08/29 22:31:09 step 2: objective=12.208127 reg=0.005249
2017/08/29 22:31:10 step 3: objective=12.218953 reg=0.005249
2017/08/29 22:31:10 step 4: objective=12.230074 reg=0.005248
2017/08/29 22:31:11 step 5: objective=12.241264 reg=0.005247
2017/08/29 22:31:12 step 6: objective=12.251726 reg=0.005247
2017/08/29 22:31:13 step 7: objective=12.264786 reg=0.005246
2017/08/29 22:31:13 Training value function...
2017/08/29 22:31:15 step 0: mse=13957.101195 step=0.050000
2017/08/29 22:31:16 step 1: mse=13932.645843 step=0.050000
2017/08/29 22:31:16 step 2: mse=13912.897940 step=0.050000
2017/08/29 22:31:17 step 3: mse=13900.673548 step=0.050000
2017/08/29 22:31:18 step 4: mse=13893.855859 step=0.050000
2017/08/29 22:31:19 step 5: mse=13882.193362 step=0.050000
2017/08/29 22:31:19 step 6: mse=13878.020846 step=0.050000
2017/08/29 22:31:20 step 7: mse=13874.381120 step=0.050000
2017/08/29 22:31:20 Saving...
2017/08/29 22:31:20 Gathering batch of experience...
2017/08/29 22:31:43 batch 252: mean=1134.056604 stddev=589.613766 entropy=0.527151 frames=4892 count=53
2017/08/29 22:31:43 Training policy...
2017/08/29 22:31:46 tune 0: objective=16.362537 reg=0.005272 prune=0
2017/08/29 22:31:47 step 0: objective=16.367112 reg=0.005271
2017/08/29 22:31:48 step 1: objective=16.382333 reg=0.005271
2017/08/29 22:31:48 step 2: objective=16.391570 reg=0.005271
2017/08/29 22:31:49 step 3: objective=16.401108 reg=0.005270
2017/08/29 22:31:50 step 4: objective=16.412189 reg=0.005270
2017/08/29 22:31:51 step 5: objective=16.423258 reg=0.005270
2017/08/29 22:31:52 step 6: objective=16.432339 reg=0.005270
2017/08/29 22:31:52 step 7: objective=16.441694 reg=0.005269
2017/08/29 22:31:52 Training value function...
2017/08/29 22:31:54 step 0: mse=13698.203030 step=0.050000
2017/08/29 22:31:55 step 1: mse=13689.520701 step=0.050000
2017/08/29 22:31:56 step 2: mse=13676.822923 step=0.050000
2017/08/29 22:31:57 step 3: mse=13659.214113 step=0.050000
2017/08/29 22:31:57 step 4: mse=13656.272670 step=0.050000
2017/08/29 22:31:58 step 5: mse=13651.041022 step=0.050000
2017/08/29 22:31:59 step 6: mse=13651.622441 step=0.050000
2017/08/29 22:32:00 step 7: mse=13653.403350 step=0.050000
2017/08/29 22:32:00 Saving...
2017/08/29 22:32:00 Gathering batch of experience...
2017/08/29 22:32:23 batch 253: mean=1180.192308 stddev=571.347060 entropy=0.525296 frames=4944 count=52
2017/08/29 22:32:23 Training policy...
2017/08/29 22:32:26 tune 0: objective=20.647079 reg=0.005253 prune=0
2017/08/29 22:32:27 step 0: objective=20.652971 reg=0.005252
2017/08/29 22:32:27 step 1: objective=20.665513 reg=0.005250
2017/08/29 22:32:28 step 2: objective=20.681272 reg=0.005249
2017/08/29 22:32:29 step 3: objective=20.690528 reg=0.005249
2017/08/29 22:32:30 step 4: objective=20.699541 reg=0.005248
2017/08/29 22:32:31 step 5: objective=20.708502 reg=0.005247
2017/08/29 22:32:32 step 6: objective=20.723404 reg=0.005246
2017/08/29 22:32:32 step 7: objective=20.733300 reg=0.005245
2017/08/29 22:32:32 Training value function...
2017/08/29 22:32:34 step 0: mse=14156.919100 step=0.050000
2017/08/29 22:32:35 step 1: mse=14150.291403 step=0.050000
2017/08/29 22:32:36 step 2: mse=14145.322321 step=0.050000
2017/08/29 22:32:37 step 3: mse=14140.174047 step=0.050000
2017/08/29 22:32:38 step 4: mse=14137.016465 step=0.050000
2017/08/29 22:32:38 step 5: mse=14133.948517 step=0.050000
2017/08/29 22:32:39 step 6: mse=14130.522335 step=0.050000
2017/08/29 22:32:40 step 7: mse=14127.061486 step=0.050000
2017/08/29 22:32:40 Saving...
2017/08/29 22:32:40 Gathering batch of experience...
2017/08/29 22:33:03 batch 254: mean=1272.755102 stddev=546.114346 entropy=0.519711 frames=4934 count=49
2017/08/29 22:33:03 Training policy...
2017/08/29 22:33:06 tune 0: objective=26.928975 reg=0.005197 prune=0
2017/08/29 22:33:07 step 0: objective=26.933355 reg=0.005196
2017/08/29 22:33:07 step 1: objective=26.947751 reg=0.005195
2017/08/29 22:33:08 step 2: objective=26.959759 reg=0.005194
2017/08/29 22:33:09 step 3: objective=26.970001 reg=0.005193
2017/08/29 22:33:10 step 4: objective=26.981534 reg=0.005192
2017/08/29 22:33:11 step 5: objective=26.999050 reg=0.005191
2017/08/29 22:33:12 step 6: objective=27.010856 reg=0.005189
2017/08/29 22:33:12 step 7: objective=27.021987 reg=0.005188
2017/08/29 22:33:12 Training value function...
2017/08/29 22:33:14 step 0: mse=13526.754487 step=0.050000
2017/08/29 22:33:15 step 1: mse=13411.728163 step=0.050000
2017/08/29 22:33:16 step 2: mse=13310.810014 step=0.050000
2017/08/29 22:33:17 step 3: mse=13214.824967 step=0.050000
2017/08/29 22:33:17 step 4: mse=13124.397627 step=0.050000
2017/08/29 22:33:18 step 5: mse=13037.120673 step=0.050000
2017/08/29 22:33:19 step 6: mse=12956.125393 step=0.050000
2017/08/29 22:33:20 step 7: mse=12872.320046 step=0.050000
2017/08/29 22:33:20 Saving...
2017/08/29 22:33:20 Gathering batch of experience...
2017/08/29 22:33:42 batch 255: mean=1237.340426 stddev=552.421026 entropy=0.520162 frames=4654 count=47
2017/08/29 22:33:42 Training policy...
2017/08/29 22:33:45 tune 0: objective=22.728552 reg=0.005202 prune=0
2017/08/29 22:33:45 step 0: objective=22.733232 reg=0.005201
2017/08/29 22:33:46 step 1: objective=22.743774 reg=0.005200
2017/08/29 22:33:47 step 2: objective=22.757782 reg=0.005199
2017/08/29 22:33:48 step 3: objective=22.770658 reg=0.005198
2017/08/29 22:33:49 step 4: objective=22.782158 reg=0.005198
2017/08/29 22:33:49 step 5: objective=22.789890 reg=0.005197
2017/08/29 22:33:50 step 6: objective=22.802089 reg=0.005196
2017/08/29 22:33:51 step 7: objective=22.812391 reg=0.005196
2017/08/29 22:33:51 Training value function...
2017/08/29 22:33:53 step 0: mse=14264.000638 step=0.050000
2017/08/29 22:33:54 step 1: mse=14263.680732 step=0.050000
2017/08/29 22:33:54 step 2: mse=14264.915753 step=0.050000
2017/08/29 22:33:55 step 3: mse=14263.627045 step=0.050000
2017/08/29 22:33:56 step 4: mse=14265.910029 step=0.050000
2017/08/29 22:33:56 step 5: mse=14266.324125 step=0.050000
2017/08/29 22:33:57 step 6: mse=14265.935294 step=0.050000
2017/08/29 22:33:58 step 7: mse=14268.852855 step=0.050000
2017/08/29 22:33:58 Saving...
2017/08/29 22:33:58 Gathering batch of experience...
2017/08/29 22:34:21 batch 256: mean=1273.600000 stddev=546.090688 entropy=0.520305 frames=5084 count=50
2017/08/29 22:34:21 Training policy...
2017/08/29 22:34:24 tune 0: objective=24.336435 reg=0.005203 prune=0
2017/08/29 22:34:25 step 0: objective=24.342653 reg=0.005202
2017/08/29 22:34:26 step 1: objective=24.354917 reg=0.005202
2017/08/29 22:34:27 step 2: objective=24.363337 reg=0.005202
2017/08/29 22:34:28 step 3: objective=24.372827 reg=0.005202
2017/08/29 22:34:29 step 4: objective=24.383152 reg=0.005201
2017/08/29 22:34:29 step 5: objective=24.394808 reg=0.005201
2017/08/29 22:34:30 step 6: objective=24.403084 reg=0.005200
2017/08/29 22:34:31 step 7: objective=24.411602 reg=0.005200
2017/08/29 22:34:31 Training value function...
2017/08/29 22:34:33 step 0: mse=14553.867101 step=0.050000
2017/08/29 22:34:34 step 1: mse=14494.124852 step=0.050000
2017/08/29 22:34:35 step 2: mse=14444.965163 step=0.050000
2017/08/29 22:34:36 step 3: mse=14397.998380 step=0.050000
2017/08/29 22:34:36 step 4: mse=14345.156625 step=0.050000
2017/08/29 22:34:37 step 5: mse=14298.626635 step=0.050000
2017/08/29 22:34:38 step 6: mse=14257.739171 step=0.050000
2017/08/29 22:34:39 step 7: mse=14215.654063 step=0.050000
2017/08/29 22:34:39 Saving...
2017/08/29 22:34:39 Gathering batch of experience...
2017/08/29 22:35:02 batch 257: mean=1064.285714 stddev=595.359607 entropy=0.527136 frames=4922 count=56
2017/08/29 22:35:02 Training policy...
2017/08/29 22:35:05 tune 0: objective=13.119283 reg=0.005271 prune=0
2017/08/29 22:35:06 step 0: objective=13.124907 reg=0.005270
2017/08/29 22:35:07 step 1: objective=13.138132 reg=0.005269
2017/08/29 22:35:07 step 2: objective=13.154960 reg=0.005268
2017/08/29 22:35:08 step 3: objective=13.171496 reg=0.005266
2017/08/29 22:35:09 step 4: objective=13.186875 reg=0.005265
2017/08/29 22:35:10 step 5: objective=13.203046 reg=0.005264
2017/08/29 22:35:11 step 6: objective=13.218211 reg=0.005263
2017/08/29 22:35:12 step 7: objective=13.233223 reg=0.005262
2017/08/29 22:35:12 Training value function...
2017/08/29 22:35:14 step 0: mse=14751.561343 step=0.050000
2017/08/29 22:35:14 step 1: mse=14785.910066 step=0.050000
2017/08/29 22:35:15 step 2: mse=14826.140303 step=0.050000
2017/08/29 22:35:16 step 3: mse=14867.049262 step=0.050000
2017/08/29 22:35:17 step 4: mse=14897.889545 step=0.050000
2017/08/29 22:35:17 step 5: mse=14934.904510 step=0.050000
2017/08/29 22:35:18 step 6: mse=14970.696185 step=0.050000
2017/08/29 22:35:19 step 7: mse=15005.798710 step=0.050000
2017/08/29 22:35:19 Saving...
2017/08/29 22:35:19 Gathering batch of experience...
2017/08/29 22:35:42 batch 258: mean=1247.653061 stddev=576.591942 entropy=0.520793 frames=4885 count=49
2017/08/29 22:35:42 Training policy...
2017/08/29 22:35:45 tune 0: objective=27.163655 reg=0.005208 prune=0
2017/08/29 22:35:46 step 0: objective=27.170951 reg=0.005207
2017/08/29 22:35:46 step 1: objective=27.190305 reg=0.005205
2017/08/29 22:35:47 step 2: objective=27.208124 reg=0.005204
2017/08/29 22:35:48 step 3: objective=27.228787 reg=0.005202
2017/08/29 22:35:49 step 4: objective=27.248426 reg=0.005201
2017/08/29 22:35:50 step 5: objective=27.267573 reg=0.005199
2017/08/29 22:35:51 step 6: objective=27.284826 reg=0.005198
2017/08/29 22:35:51 step 7: objective=27.305543 reg=0.005196
2017/08/29 22:35:51 Training value function...
2017/08/29 22:35:53 step 0: mse=15716.124181 step=0.050000
2017/08/29 22:35:54 step 1: mse=15631.528925 step=0.050000
2017/08/29 22:35:55 step 2: mse=15554.708612 step=0.050000
2017/08/29 22:35:56 step 3: mse=15483.298612 step=0.050000
2017/08/29 22:35:56 step 4: mse=15416.521756 step=0.050000
2017/08/29 22:35:57 step 5: mse=15349.283182 step=0.050000
2017/08/29 22:35:58 step 6: mse=15290.855445 step=0.050000
2017/08/29 22:35:59 step 7: mse=15232.035867 step=0.050000
2017/08/29 22:35:59 Saving...
2017/08/29 22:35:59 Gathering batch of experience...
2017/08/29 22:36:22 batch 259: mean=1130.192308 stddev=543.655683 entropy=0.517753 frames=4800 count=52
2017/08/29 22:36:22 Training policy...
2017/08/29 22:36:25 tune 0: objective=16.867002 reg=0.005178 prune=0
2017/08/29 22:36:26 step 0: objective=16.873372 reg=0.005177
2017/08/29 22:36:26 step 1: objective=16.882790 reg=0.005176
2017/08/29 22:36:27 step 2: objective=16.895272 reg=0.005175
2017/08/29 22:36:28 step 3: objective=16.905189 reg=0.005175
2017/08/29 22:36:29 step 4: objective=16.914635 reg=0.005174
2017/08/29 22:36:30 step 5: objective=16.927046 reg=0.005174
2017/08/29 22:36:30 step 6: objective=16.936291 reg=0.005173
2017/08/29 22:36:31 step 7: objective=16.953656 reg=0.005171
2017/08/29 22:36:31 Training value function...
2017/08/29 22:36:33 step 0: mse=15339.737575 step=0.050000
2017/08/29 22:36:34 step 1: mse=15369.513348 step=0.050000
2017/08/29 22:36:35 step 2: mse=15388.502944 step=0.050000
2017/08/29 22:36:35 step 3: mse=15411.939590 step=0.050000
2017/08/29 22:36:36 step 4: mse=15436.600354 step=0.050000
2017/08/29 22:36:37 step 5: mse=15467.537194 step=0.050000
2017/08/29 22:36:38 step 6: mse=15487.110597 step=0.050000
2017/08/29 22:36:38 step 7: mse=15515.237281 step=0.050000
2017/08/29 22:36:38 Saving...
2017/08/29 22:36:38 Gathering batch of experience...
2017/08/29 22:37:01 batch 260: mean=1222.800000 stddev=555.048791 entropy=0.515542 frames=4820 count=50
2017/08/29 22:37:01 Training policy...
2017/08/29 22:37:03 tune 0: objective=27.433733 reg=0.005155 prune=0
2017/08/29 22:37:04 step 0: objective=27.438862 reg=0.005155
2017/08/29 22:37:05 step 1: objective=27.453054 reg=0.005154
2017/08/29 22:37:06 step 2: objective=27.463868 reg=0.005154
2017/08/29 22:37:07 step 3: objective=27.479153 reg=0.005153
2017/08/29 22:37:08 step 4: objective=27.493124 reg=0.005153
2017/08/29 22:37:08 step 5: objective=27.507141 reg=0.005152
2017/08/29 22:37:09 step 6: objective=27.519988 reg=0.005151
2017/08/29 22:37:10 step 7: objective=27.535727 reg=0.005150
2017/08/29 22:37:10 Training value function...
2017/08/29 22:37:12 step 0: mse=15687.910833 step=0.050000
2017/08/29 22:37:13 step 1: mse=15568.280510 step=0.050000
2017/08/29 22:37:13 step 2: mse=15453.921956 step=0.050000
2017/08/29 22:37:14 step 3: mse=15347.891149 step=0.050000
2017/08/29 22:37:15 step 4: mse=15242.721163 step=0.050000
2017/08/29 22:37:16 step 5: mse=15151.438574 step=0.050000
2017/08/29 22:37:16 step 6: mse=15068.668196 step=0.050000
2017/08/29 22:37:17 step 7: mse=14989.858767 step=0.050000
2017/08/29 22:37:17 Saving...
2017/08/29 22:37:17 Gathering batch of experience...
2017/08/29 22:37:40 batch 261: mean=1344.574468 stddev=556.882307 entropy=0.516361 frames=4968 count=47
2017/08/29 22:37:40 Training policy...
2017/08/29 22:37:43 tune 0: objective=31.236809 reg=0.005164 prune=0
2017/08/29 22:37:44 step 0: objective=31.241820 reg=0.005162
2017/08/29 22:37:45 step 1: objective=31.257869 reg=0.005161
2017/08/29 22:37:46 step 2: objective=31.269560 reg=0.005159
2017/08/29 22:37:47 step 3: objective=31.277753 reg=0.005159
2017/08/29 22:37:47 step 4: objective=31.284279 reg=0.005158
2017/08/29 22:37:48 step 5: objective=31.294982 reg=0.005157
2017/08/29 22:37:49 step 6: objective=31.307877 reg=0.005155
2017/08/29 22:37:50 step 7: objective=31.315513 reg=0.005154
2017/08/29 22:37:50 Training value function...
2017/08/29 22:37:52 step 0: mse=15635.459597 step=0.050000
2017/08/29 22:37:53 step 1: mse=15446.190416 step=0.050000
2017/08/29 22:37:53 step 2: mse=15273.352327 step=0.050000
2017/08/29 22:37:54 step 3: mse=15111.947151 step=0.050000
2017/08/29 22:37:55 step 4: mse=14961.779286 step=0.050000
2017/08/29 22:37:56 step 5: mse=14818.498646 step=0.050000
2017/08/29 22:37:57 step 6: mse=14688.678761 step=0.050000
2017/08/29 22:37:57 step 7: mse=14567.936813 step=0.050000
2017/08/29 22:37:57 Saving...
2017/08/29 22:37:57 Gathering batch of experience...
2017/08/29 22:38:21 batch 262: mean=1241.800000 stddev=559.527265 entropy=0.514002 frames=4932 count=50
2017/08/29 22:38:21 Training policy...
2017/08/29 22:38:23 tune 0: objective=22.846124 reg=0.005140 prune=0
2017/08/29 22:38:24 step 0: objective=22.850873 reg=0.005139
2017/08/29 22:38:25 step 1: objective=22.866045 reg=0.005138
2017/08/29 22:38:26 step 2: objective=22.880508 reg=0.005137
2017/08/29 22:38:27 step 3: objective=22.889196 reg=0.005136
2017/08/29 22:38:28 step 4: objective=22.901276 reg=0.005135
2017/08/29 22:38:28 step 5: objective=22.913901 reg=0.005134
2017/08/29 22:38:29 step 6: objective=22.925067 reg=0.005133
2017/08/29 22:38:30 step 7: objective=22.938333 reg=0.005132
2017/08/29 22:38:30 Training value function...
2017/08/29 22:38:32 step 0: mse=14342.255566 step=0.050000
2017/08/29 22:38:33 step 1: mse=14291.225708 step=0.050000
2017/08/29 22:38:34 step 2: mse=14260.766851 step=0.050000
2017/08/29 22:38:34 step 3: mse=14234.807320 step=0.050000
2017/08/29 22:38:35 step 4: mse=14207.968927 step=0.050000
2017/08/29 22:38:36 step 5: mse=14179.371705 step=0.050000
2017/08/29 22:38:37 step 6: mse=14156.383224 step=0.050000
2017/08/29 22:38:38 step 7: mse=14119.139209 step=0.050000
2017/08/29 22:38:38 Saving...
2017/08/29 22:38:38 Gathering batch of experience...
2017/08/29 22:39:01 batch 263: mean=1322.604167 stddev=630.233083 entropy=0.520172 frames=5012 count=48
2017/08/29 22:39:01 Training policy...
2017/08/29 22:39:04 tune 0: objective=27.768920 reg=0.005202 prune=0
2017/08/29 22:39:05 step 0: objective=27.775311 reg=0.005201
2017/08/29 22:39:05 step 1: objective=27.794612 reg=0.005200
2017/08/29 22:39:06 step 2: objective=27.806614 reg=0.005200
2017/08/29 22:39:07 step 3: objective=27.817254 reg=0.005200
2017/08/29 22:39:08 step 4: objective=27.836761 reg=0.005199
2017/08/29 22:39:09 step 5: objective=27.845973 reg=0.005198
2017/08/29 22:39:10 step 6: objective=27.856787 reg=0.005198
2017/08/29 22:39:10 step 7: objective=27.865797 reg=0.005198
2017/08/29 22:39:10 Training value function...
2017/08/29 22:39:12 step 0: mse=16881.480543 step=0.050000
2017/08/29 22:39:13 step 1: mse=16769.386787 step=0.050000
2017/08/29 22:39:14 step 2: mse=16663.626673 step=0.050000
2017/08/29 22:39:15 step 3: mse=16567.718165 step=0.050000
2017/08/29 22:39:16 step 4: mse=16476.910939 step=0.050000
2017/08/29 22:39:16 step 5: mse=16396.544704 step=0.050000
2017/08/29 22:39:17 step 6: mse=16319.994006 step=0.050000
2017/08/29 22:39:18 step 7: mse=16250.795886 step=0.050000
2017/08/29 22:39:18 Saving...
2017/08/29 22:39:18 Gathering batch of experience...
2017/08/29 22:39:40 batch 264: mean=1345.000000 stddev=562.835407 entropy=0.518248 frames=4921 count=46
2017/08/29 22:39:40 Training policy...
2017/08/29 22:39:43 tune 0: objective=26.238661 reg=0.005182 prune=0
2017/08/29 22:39:44 step 0: objective=26.242877 reg=0.005182
2017/08/29 22:39:45 step 1: objective=26.253196 reg=0.005180
2017/08/29 22:39:46 step 2: objective=26.263947 reg=0.005179
2017/08/29 22:39:47 step 3: objective=26.277318 reg=0.005178
2017/08/29 22:39:48 step 4: objective=26.289834 reg=0.005177
2017/08/29 22:39:48 step 5: objective=26.300506 reg=0.005176
2017/08/29 22:39:49 step 6: objective=26.311452 reg=0.005175
2017/08/29 22:39:50 step 7: objective=26.319857 reg=0.005175
2017/08/29 22:39:50 Training value function...
2017/08/29 22:39:52 step 0: mse=13350.849021 step=0.050000
2017/08/29 22:39:53 step 1: mse=13267.348937 step=0.050000
2017/08/29 22:39:54 step 2: mse=13183.089334 step=0.050000
2017/08/29 22:39:54 step 3: mse=13111.471296 step=0.050000
2017/08/29 22:39:55 step 4: mse=13039.718263 step=0.050000
2017/08/29 22:39:56 step 5: mse=12978.351814 step=0.050000
2017/08/29 22:39:57 step 6: mse=12914.028503 step=0.050000
2017/08/29 22:39:57 step 7: mse=12858.264806 step=0.050000
2017/08/29 22:39:57 Saving...
2017/08/29 22:39:57 Gathering batch of experience...
2017/08/29 22:40:20 batch 265: mean=1359.893617 stddev=553.515351 entropy=0.514568 frames=4993 count=47
2017/08/29 22:40:20 Training policy...
2017/08/29 22:40:23 tune 0: objective=27.061896 reg=0.005146 prune=0
2017/08/29 22:40:24 step 0: objective=27.065852 reg=0.005145
2017/08/29 22:40:25 step 1: objective=27.074342 reg=0.005144
2017/08/29 22:40:26 step 2: objective=27.084453 reg=0.005143
2017/08/29 22:40:27 step 3: objective=27.091816 reg=0.005143
2017/08/29 22:40:28 step 4: objective=27.102265 reg=0.005142
2017/08/29 22:40:28 step 5: objective=27.110642 reg=0.005142
2017/08/29 22:40:29 step 6: objective=27.122935 reg=0.005140
2017/08/29 22:40:30 step 7: objective=27.131869 reg=0.005140
2017/08/29 22:40:30 Training value function...
2017/08/29 22:40:32 step 0: mse=13784.395446 step=0.050000
2017/08/29 22:40:33 step 1: mse=13712.286104 step=0.050000
2017/08/29 22:40:34 step 2: mse=13645.677505 step=0.050000
2017/08/29 22:40:34 step 3: mse=13582.703468 step=0.050000
2017/08/29 22:40:35 step 4: mse=13521.337280 step=0.050000
2017/08/29 22:40:36 step 5: mse=13464.615041 step=0.050000
2017/08/29 22:40:37 step 6: mse=13413.001267 step=0.050000
2017/08/29 22:40:38 step 7: mse=13362.875879 step=0.050000
2017/08/29 22:40:38 Saving...
2017/08/29 22:40:38 Gathering batch of experience...
2017/08/29 22:41:01 batch 266: mean=1171.037736 stddev=591.227025 entropy=0.515431 frames=4995 count=53
2017/08/29 22:41:01 Training policy...
2017/08/29 22:41:04 tune 0: objective=15.284869 reg=0.005154 prune=0
2017/08/29 22:41:05 step 0: objective=15.291438 reg=0.005153
2017/08/29 22:41:06 step 1: objective=15.310043 reg=0.005152
2017/08/29 22:41:07 step 2: objective=15.319343 reg=0.005152
2017/08/29 22:41:08 step 3: objective=15.335639 reg=0.005151
2017/08/29 22:41:08 step 4: objective=15.350561 reg=0.005150
2017/08/29 22:41:09 step 5: objective=15.359896 reg=0.005150
2017/08/29 22:41:10 step 6: objective=15.377945 reg=0.005148
2017/08/29 22:41:11 step 7: objective=15.390537 reg=0.005147
2017/08/29 22:41:11 Training value function...
2017/08/29 22:41:13 step 0: mse=13847.226323 step=0.050000
2017/08/29 22:41:14 step 1: mse=13900.816321 step=0.050000
2017/08/29 22:41:15 step 2: mse=13955.723377 step=0.050000
2017/08/29 22:41:15 step 3: mse=14008.185418 step=0.050000
2017/08/29 22:41:16 step 4: mse=14061.407643 step=0.050000
2017/08/29 22:41:17 step 5: mse=14114.768995 step=0.050000
2017/08/29 22:41:18 step 6: mse=14160.357895 step=0.050000
2017/08/29 22:41:18 step 7: mse=14208.831802 step=0.050000
2017/08/29 22:41:18 Saving...
2017/08/29 22:41:19 Gathering batch of experience...
2017/08/29 22:41:41 batch 267: mean=1293.061224 stddev=529.092230 entropy=0.510379 frames=4936 count=49
2017/08/29 22:41:41 Training policy...
2017/08/29 22:41:44 tune 0: objective=25.878846 reg=0.005104 prune=0
2017/08/29 22:41:45 step 0: objective=25.883146 reg=0.005103
2017/08/29 22:41:46 step 1: objective=25.896399 reg=0.005102
2017/08/29 22:41:47 step 2: objective=25.905125 reg=0.005101
2017/08/29 22:41:48 step 3: objective=25.920398 reg=0.005100
2017/08/29 22:41:48 step 4: objective=25.934442 reg=0.005098
2017/08/29 22:41:49 step 5: objective=25.945939 reg=0.005097
2017/08/29 22:41:50 step 6: objective=25.961829 reg=0.005096
2017/08/29 22:41:51 step 7: objective=25.976783 reg=0.005094
2017/08/29 22:41:51 Training value function...
2017/08/29 22:41:53 step 0: mse=12757.450956 step=0.050000
2017/08/29 22:41:54 step 1: mse=12681.818866 step=0.050000
2017/08/29 22:41:54 step 2: mse=12613.854810 step=0.050000
2017/08/29 22:41:55 step 3: mse=12549.179154 step=0.050000
2017/08/29 22:41:56 step 4: mse=12489.088916 step=0.050000
2017/08/29 22:41:57 step 5: mse=12436.417431 step=0.050000
2017/08/29 22:41:58 step 6: mse=12380.870350 step=0.050000
2017/08/29 22:41:58 step 7: mse=12333.540342 step=0.050000
2017/08/29 22:41:58 Saving...
2017/08/29 22:41:58 Gathering batch of experience...
2017/08/29 22:42:21 batch 268: mean=1245.816327 stddev=536.713684 entropy=0.507652 frames=4865 count=49
2017/08/29 22:42:21 Training policy...
2017/08/29 22:42:24 tune 0: objective=20.089559 reg=0.005077 prune=0
2017/08/29 22:42:25 step 0: objective=20.095744 reg=0.005076
2017/08/29 22:42:26 step 1: objective=20.105584 reg=0.005076
2017/08/29 22:42:26 step 2: objective=20.115541 reg=0.005075
2017/08/29 22:42:27 step 3: objective=20.125960 reg=0.005074
2017/08/29 22:42:28 step 4: objective=20.136583 reg=0.005073
2017/08/29 22:42:29 step 5: objective=20.145926 reg=0.005073
2017/08/29 22:42:30 step 6: objective=20.159255 reg=0.005072
2017/08/29 22:42:30 step 7: objective=20.170555 reg=0.005071
2017/08/29 22:42:30 Training value function...
2017/08/29 22:42:32 step 0: mse=13123.218594 step=0.050000
2017/08/29 22:42:33 step 1: mse=13130.711918 step=0.050000
2017/08/29 22:42:34 step 2: mse=13145.214333 step=0.050000
2017/08/29 22:42:35 step 3: mse=13161.638432 step=0.050000
2017/08/29 22:42:36 step 4: mse=13180.105903 step=0.050000
2017/08/29 22:42:36 step 5: mse=13194.550960 step=0.050000
2017/08/29 22:42:37 step 6: mse=13208.498747 step=0.050000
2017/08/29 22:42:38 step 7: mse=13227.256123 step=0.050000
2017/08/29 22:42:38 Saving...
2017/08/29 22:42:38 Gathering batch of experience...
2017/08/29 22:43:01 batch 269: mean=1340.625000 stddev=560.281389 entropy=0.510084 frames=5074 count=48
2017/08/29 22:43:01 Training policy...
2017/08/29 22:43:04 tune 0: objective=27.236167 reg=0.005101 prune=0
2017/08/29 22:43:05 step 0: objective=27.240574 reg=0.005100
2017/08/29 22:43:06 step 1: objective=27.249344 reg=0.005099
2017/08/29 22:43:07 step 2: objective=27.255780 reg=0.005099
2017/08/29 22:43:08 step 3: objective=27.264889 reg=0.005098
2017/08/29 22:43:09 step 4: objective=27.271975 reg=0.005097
2017/08/29 22:43:10 step 5: objective=27.286251 reg=0.005096
2017/08/29 22:43:10 step 6: objective=27.296967 reg=0.005095
2017/08/29 22:43:11 step 7: objective=27.309559 reg=0.005093
2017/08/29 22:43:11 Training value function...
2017/08/29 22:43:13 step 0: mse=13833.066077 step=0.050000
2017/08/29 22:43:14 step 1: mse=13745.689163 step=0.050000
2017/08/29 22:43:15 step 2: mse=13666.788879 step=0.050000
2017/08/29 22:43:16 step 3: mse=13589.906167 step=0.050000
2017/08/29 22:43:17 step 4: mse=13519.200174 step=0.050000
2017/08/29 22:43:17 step 5: mse=13450.887108 step=0.050000
2017/08/29 22:43:18 step 6: mse=13387.108206 step=0.050000
2017/08/29 22:43:19 step 7: mse=13328.975996 step=0.050000
2017/08/29 22:43:19 Saving...
2017/08/29 22:43:19 Gathering batch of experience...
2017/08/29 22:43:42 batch 270: mean=1226.400000 stddev=505.834993 entropy=0.505815 frames=4964 count=50
2017/08/29 22:43:42 Training policy...
2017/08/29 22:43:45 tune 0: objective=16.208677 reg=0.005058 prune=0
2017/08/29 22:43:46 step 0: objective=16.214510 reg=0.005057
2017/08/29 22:43:46 step 1: objective=16.232288 reg=0.005056
2017/08/29 22:43:47 step 2: objective=16.247606 reg=0.005055
2017/08/29 22:43:48 step 3: objective=16.265823 reg=0.005054
2017/08/29 22:43:49 step 4: objective=16.281058 reg=0.005054
2017/08/29 22:43:50 step 5: objective=16.298668 reg=0.005052
2017/08/29 22:43:51 step 6: objective=16.314875 reg=0.005052
2017/08/29 22:43:52 step 7: objective=16.330124 reg=0.005051
2017/08/29 22:43:52 Training value function...
2017/08/29 22:43:54 step 0: mse=13443.629417 step=0.050000
2017/08/29 22:43:54 step 1: mse=13470.274194 step=0.050000
2017/08/29 22:43:55 step 2: mse=13507.525192 step=0.050000
2017/08/29 22:43:56 step 3: mse=13546.221094 step=0.050000
2017/08/29 22:43:57 step 4: mse=13585.371149 step=0.050000
2017/08/29 22:43:57 step 5: mse=13627.492320 step=0.050000
2017/08/29 22:43:58 step 6: mse=13662.888527 step=0.050000
2017/08/29 22:43:59 step 7: mse=13695.228354 step=0.050000
2017/08/29 22:43:59 Saving...
2017/08/29 22:43:59 Gathering batch of experience...
2017/08/29 22:44:21 batch 271: mean=1226.666667 stddev=532.407399 entropy=0.508145 frames=4705 count=48
2017/08/29 22:44:21 Training policy...
2017/08/29 22:44:24 tune 0: objective=21.519605 reg=0.005081 prune=0
2017/08/29 22:44:25 step 0: objective=21.523227 reg=0.005081
2017/08/29 22:44:26 step 1: objective=21.535964 reg=0.005080
2017/08/29 22:44:26 step 2: objective=21.544687 reg=0.005079
2017/08/29 22:44:27 step 3: objective=21.556896 reg=0.005078
2017/08/29 22:44:28 step 4: objective=21.563534 reg=0.005078
2017/08/29 22:44:29 step 5: objective=21.574821 reg=0.005078
2017/08/29 22:44:30 step 6: objective=21.585830 reg=0.005078
2017/08/29 22:44:31 step 7: objective=21.600146 reg=0.005078
2017/08/29 22:44:31 Training value function...
2017/08/29 22:44:32 step 0: mse=12872.296253 step=0.050000
2017/08/29 22:44:33 step 1: mse=12864.751710 step=0.050000
2017/08/29 22:44:34 step 2: mse=12856.204599 step=0.050000
2017/08/29 22:44:35 step 3: mse=12850.286565 step=0.050000
2017/08/29 22:44:35 step 4: mse=12842.308102 step=0.050000
2017/08/29 22:44:36 step 5: mse=12833.084825 step=0.050000
2017/08/29 22:44:37 step 6: mse=12824.955998 step=0.050000
2017/08/29 22:44:38 step 7: mse=12821.637806 step=0.050000
2017/08/29 22:44:38 Saving...
2017/08/29 22:44:38 Gathering batch of experience...
2017/08/29 22:44:59 batch 272: mean=1315.217391 stddev=497.451064 entropy=0.504143 frames=4747 count=46
2017/08/29 22:44:59 Training policy...
2017/08/29 22:45:02 tune 0: objective=26.444105 reg=0.005041 prune=0
2017/08/29 22:45:03 step 0: objective=26.448020 reg=0.005041
2017/08/29 22:45:04 step 1: objective=26.456064 reg=0.005041
2017/08/29 22:45:05 step 2: objective=26.463640 reg=0.005041
2017/08/29 22:45:06 step 3: objective=26.471365 reg=0.005040
2017/08/29 22:45:06 step 4: objective=26.479347 reg=0.005040
2017/08/29 22:45:07 step 5: objective=26.486403 reg=0.005039
2017/08/29 22:45:08 step 6: objective=26.494628 reg=0.005039
2017/08/29 22:45:09 step 7: objective=26.502841 reg=0.005038
2017/08/29 22:45:09 Training value function...
2017/08/29 22:45:11 step 0: mse=13780.060953 step=0.050000
2017/08/29 22:45:11 step 1: mse=13719.008059 step=0.050000
2017/08/29 22:45:12 step 2: mse=13674.061540 step=0.050000
2017/08/29 22:45:13 step 3: mse=13621.707285 step=0.050000
2017/08/29 22:45:14 step 4: mse=13584.208565 step=0.050000
2017/08/29 22:45:14 step 5: mse=13537.554625 step=0.050000
2017/08/29 22:45:15 step 6: mse=13500.527503 step=0.050000
2017/08/29 22:45:16 step 7: mse=13464.103402 step=0.050000
2017/08/29 22:45:16 Saving...
2017/08/29 22:45:16 Gathering batch of experience...
2017/08/29 22:45:39 batch 273: mean=1253.367347 stddev=543.770273 entropy=0.505831 frames=4904 count=49
2017/08/29 22:45:39 Training policy...
2017/08/29 22:45:41 tune 0: objective=22.343224 reg=0.005058 prune=0
2017/08/29 22:45:42 step 0: objective=22.348317 reg=0.005057
2017/08/29 22:45:43 step 1: objective=22.359096 reg=0.005056
2017/08/29 22:45:44 step 2: objective=22.374893 reg=0.005055
2017/08/29 22:45:45 step 3: objective=22.388253 reg=0.005053
2017/08/29 22:45:46 step 4: objective=22.401530 reg=0.005052
2017/08/29 22:45:47 step 5: objective=22.412850 reg=0.005051
2017/08/29 22:45:47 step 6: objective=22.423307 reg=0.005050
2017/08/29 22:45:48 step 7: objective=22.434414 reg=0.005049
2017/08/29 22:45:48 Training value function...
2017/08/29 22:45:50 step 0: mse=13622.300603 step=0.050000
2017/08/29 22:45:51 step 1: mse=13627.143868 step=0.050000
2017/08/29 22:45:52 step 2: mse=13630.101140 step=0.050000
2017/08/29 22:45:52 step 3: mse=13636.862627 step=0.050000
2017/08/29 22:45:53 step 4: mse=13641.334173 step=0.050000
2017/08/29 22:45:54 step 5: mse=13644.570793 step=0.050000
2017/08/29 22:45:55 step 6: mse=13645.910113 step=0.050000
2017/08/29 22:45:55 step 7: mse=13649.694520 step=0.050000
2017/08/29 22:45:55 Saving...
2017/08/29 22:45:56 Gathering batch of experience...
2017/08/29 22:46:18 batch 274: mean=1395.000000 stddev=574.968598 entropy=0.510226 frames=4910 count=45
2017/08/29 22:46:18 Training policy...
2017/08/29 22:46:21 tune 0: objective=31.760482 reg=0.005102 prune=0
2017/08/29 22:46:22 step 0: objective=31.765590 reg=0.005102
2017/08/29 22:46:23 step 1: objective=31.774386 reg=0.005101
2017/08/29 22:46:24 step 2: objective=31.787010 reg=0.005100
2017/08/29 22:46:24 step 3: objective=31.795612 reg=0.005100
2017/08/29 22:46:25 step 4: objective=31.807001 reg=0.005099
2017/08/29 22:46:26 step 5: objective=31.814893 reg=0.005099
2017/08/29 22:46:27 step 6: objective=31.822276 reg=0.005099
2017/08/29 22:46:28 step 7: objective=31.830957 reg=0.005099
2017/08/29 22:46:28 Training value function...
2017/08/29 22:46:30 step 0: mse=16139.253689 step=0.050000
2017/08/29 22:46:30 step 1: mse=15945.750210 step=0.050000
2017/08/29 22:46:31 step 2: mse=15771.229534 step=0.050000
2017/08/29 22:46:32 step 3: mse=15608.423682 step=0.050000
2017/08/29 22:46:33 step 4: mse=15452.743386 step=0.050000
2017/08/29 22:46:34 step 5: mse=15308.832759 step=0.050000
2017/08/29 22:46:34 step 6: mse=15176.511099 step=0.050000
2017/08/29 22:46:35 step 7: mse=15051.666333 step=0.050000
2017/08/29 22:46:35 Saving...
2017/08/29 22:46:35 Gathering batch of experience...
2017/08/29 22:46:58 batch 275: mean=1312.959184 stddev=619.671505 entropy=0.510325 frames=5081 count=49
2017/08/29 22:46:58 Training policy...
2017/08/29 22:47:01 tune 0: objective=24.610150 reg=0.005103 prune=0
2017/08/29 22:47:02 step 0: objective=24.617003 reg=0.005103
2017/08/29 22:47:03 step 1: objective=24.625829 reg=0.005102
2017/08/29 22:47:04 step 2: objective=24.649100 reg=0.005101
2017/08/29 22:47:05 step 3: objective=24.657992 reg=0.005101
2017/08/29 22:47:06 step 4: objective=24.676978 reg=0.005100
2017/08/29 22:47:07 step 5: objective=24.685198 reg=0.005100
2017/08/29 22:47:08 step 6: objective=24.696217 reg=0.005099
2017/08/29 22:47:08 step 7: objective=24.710668 reg=0.005098
2017/08/29 22:47:08 Training value function...
2017/08/29 22:47:10 step 0: mse=16335.577265 step=0.050000
2017/08/29 22:47:11 step 1: mse=16260.574579 step=0.050000
2017/08/29 22:47:12 step 2: mse=16177.107127 step=0.050000
2017/08/29 22:47:13 step 3: mse=16106.339284 step=0.050000
2017/08/29 22:47:14 step 4: mse=16036.887380 step=0.050000
2017/08/29 22:47:14 step 5: mse=15984.986731 step=0.050000
2017/08/29 22:47:15 step 6: mse=15938.700747 step=0.050000
2017/08/29 22:47:16 step 7: mse=15882.565664 step=0.050000
2017/08/29 22:47:16 Saving...
2017/08/29 22:47:16 Gathering batch of experience...
2017/08/29 22:47:39 batch 276: mean=1525.681818 stddev=1014.928116 entropy=0.510273 frames=4920 count=44
2017/08/29 22:47:39 Training policy...
2017/08/29 22:47:42 tune 0: objective=40.005621 reg=0.005103 prune=0
2017/08/29 22:47:42 step 0: objective=40.021364 reg=0.005102
2017/08/29 22:47:43 step 1: objective=40.061731 reg=0.005102
2017/08/29 22:47:44 step 2: objective=40.103535 reg=0.005100
2017/08/29 22:47:45 step 3: objective=40.130050 reg=0.005099
2017/08/29 22:47:46 step 4: objective=40.183155 reg=0.005100
2017/08/29 22:47:47 step 5: objective=40.238558 reg=0.005101
2017/08/29 22:47:47 step 6: objective=40.271624 reg=0.005100
2017/08/29 22:47:48 step 7: objective=40.297256 reg=0.005100
2017/08/29 22:47:48 Training value function...
2017/08/29 22:47:50 step 0: mse=41212.384144 step=0.050000
2017/08/29 22:47:51 step 1: mse=39311.946978 step=0.050000
2017/08/29 22:47:52 step 2: mse=37608.897777 step=0.050000
2017/08/29 22:47:53 step 3: mse=36151.276027 step=0.050000
2017/08/29 22:47:53 step 4: mse=34766.457474 step=0.050000
2017/08/29 22:47:54 step 5: mse=33497.459674 step=0.050000
2017/08/29 22:47:55 step 6: mse=32404.780043 step=0.050000
2017/08/29 22:47:56 step 7: mse=31355.059375 step=0.050000
2017/08/29 22:47:56 Saving...
2017/08/29 22:47:56 Gathering batch of experience...
2017/08/29 22:48:18 batch 277: mean=1295.104167 stddev=569.589115 entropy=0.505901 frames=4924 count=48
2017/08/29 22:48:18 Training policy...
2017/08/29 22:48:21 tune 0: objective=18.034060 reg=0.005059 prune=0
2017/08/29 22:48:22 step 0: objective=18.043814 reg=0.005058
2017/08/29 22:48:23 step 1: objective=18.070860 reg=0.005057
2017/08/29 22:48:24 step 2: objective=18.099135 reg=0.005057
2017/08/29 22:48:25 step 3: objective=18.127339 reg=0.005056
2017/08/29 22:48:26 step 4: objective=18.156204 reg=0.005055
2017/08/29 22:48:26 step 5: objective=18.182812 reg=0.005054
2017/08/29 22:48:27 step 6: objective=18.214254 reg=0.005053
2017/08/29 22:48:28 step 7: objective=18.236033 reg=0.005052
2017/08/29 22:48:28 Training value function...
2017/08/29 22:48:30 step 0: mse=14751.493655 step=0.050000
2017/08/29 22:48:31 step 1: mse=14746.053308 step=0.050000
2017/08/29 22:48:32 step 2: mse=14741.066530 step=0.050000
2017/08/29 22:48:32 step 3: mse=14743.544075 step=0.050000
2017/08/29 22:48:33 step 4: mse=14745.423017 step=0.050000
2017/08/29 22:48:34 step 5: mse=14749.501263 step=0.050000
2017/08/29 22:48:35 step 6: mse=14752.784597 step=0.050000
2017/08/29 22:48:35 step 7: mse=14756.470031 step=0.050000
2017/08/29 22:48:35 Saving...
2017/08/29 22:48:35 Gathering batch of experience...
2017/08/29 22:48:58 batch 278: mean=1344.787234 stddev=570.253730 entropy=0.505367 frames=4951 count=47
2017/08/29 22:48:58 Training policy...
2017/08/29 22:49:01 tune 0: objective=24.577338 reg=0.005054 prune=0
2017/08/29 22:49:02 step 0: objective=24.582259 reg=0.005053
2017/08/29 22:49:03 step 1: objective=24.592945 reg=0.005052
2017/08/29 22:49:04 step 2: objective=24.605365 reg=0.005051
2017/08/29 22:49:05 step 3: objective=24.620432 reg=0.005050
2017/08/29 22:49:06 step 4: objective=24.629079 reg=0.005050
2017/08/29 22:49:07 step 5: objective=24.639426 reg=0.005049
2017/08/29 22:49:07 step 6: objective=24.648793 reg=0.005048
2017/08/29 22:49:08 step 7: objective=24.666844 reg=0.005047
2017/08/29 22:49:08 Training value function...
2017/08/29 22:49:10 step 0: mse=13575.086341 step=0.050000
2017/08/29 22:49:11 step 1: mse=13501.926113 step=0.050000
2017/08/29 22:49:12 step 2: mse=13432.169510 step=0.050000
2017/08/29 22:49:13 step 3: mse=13369.615510 step=0.050000
2017/08/29 22:49:13 step 4: mse=13310.466572 step=0.050000
2017/08/29 22:49:14 step 5: mse=13259.301261 step=0.050000
2017/08/29 22:49:15 step 6: mse=13210.945119 step=0.050000
2017/08/29 22:49:16 step 7: mse=13162.922493 step=0.050000
2017/08/29 22:49:16 Saving...
2017/08/29 22:49:16 Gathering batch of experience...
2017/08/29 22:49:40 batch 279: mean=1473.888889 stddev=865.556911 entropy=0.504285 frames=4958 count=45
2017/08/29 22:49:40 Training policy...
2017/08/29 22:49:43 tune 0: objective=32.387051 reg=0.005043 prune=0
2017/08/29 22:49:44 step 0: objective=32.397826 reg=0.005042
2017/08/29 22:49:44 step 1: objective=32.418556 reg=0.005042
2017/08/29 22:49:45 step 2: objective=32.449860 reg=0.005041
2017/08/29 22:49:46 step 3: objective=32.478416 reg=0.005042
2017/08/29 22:49:47 step 4: objective=32.500306 reg=0.005041
2017/08/29 22:49:48 step 5: objective=32.523280 reg=0.005041
2017/08/29 22:49:49 step 6: objective=32.544174 reg=0.005041
2017/08/29 22:49:50 step 7: objective=32.568863 reg=0.005041
2017/08/29 22:49:50 Training value function...
2017/08/29 22:49:51 step 0: mse=26969.983079 step=0.050000
2017/08/29 22:49:52 step 1: mse=26374.165728 step=0.050000
2017/08/29 22:49:53 step 2: mse=25888.563408 step=0.050000
2017/08/29 22:49:54 step 3: mse=25383.828511 step=0.050000
2017/08/29 22:49:55 step 4: mse=24919.305246 step=0.050000
2017/08/29 22:49:55 step 5: mse=24509.587109 step=0.050000
2017/08/29 22:49:56 step 6: mse=24099.163588 step=0.050000
2017/08/29 22:49:57 step 7: mse=23779.202188 step=0.050000
2017/08/29 22:49:57 Saving...
2017/08/29 22:49:57 Gathering batch of experience...
2017/08/29 22:50:22 batch 280: mean=1522.941176 stddev=2600.028879 entropy=0.514026 frames=5150 count=51
2017/08/29 22:50:22 Training policy...
2017/08/29 22:50:25 tune 0: objective=46.114860 reg=0.005140 prune=0
2017/08/29 22:50:26 step 0: objective=46.180552 reg=0.005138
2017/08/29 22:50:27 step 1: objective=46.333083 reg=0.005137
2017/08/29 22:50:27 step 2: objective=46.464481 reg=0.005138
2017/08/29 22:50:28 step 3: objective=46.629939 reg=0.005136
2017/08/29 22:50:29 step 4: objective=46.747175 reg=0.005133
2017/08/29 22:50:30 step 5: objective=46.875789 reg=0.005130
2017/08/29 22:50:31 step 6: objective=47.024293 reg=0.005125
2017/08/29 22:50:32 step 7: objective=47.137315 reg=0.005121
2017/08/29 22:50:32 Training value function...
2017/08/29 22:50:34 step 0: mse=254027.807449 step=0.050000
2017/08/29 22:50:35 step 1: mse=249542.922114 step=0.050000
2017/08/29 22:50:36 step 2: mse=245643.378696 step=0.050000
2017/08/29 22:50:36 step 3: mse=240809.635007 step=0.050000
2017/08/29 22:50:37 step 4: mse=234615.508723 step=0.050000
2017/08/29 22:50:38 step 5: mse=231496.459952 step=0.050000
2017/08/29 22:50:39 step 6: mse=228940.185735 step=0.050000
2017/08/29 22:50:40 step 7: mse=225467.103352 step=0.050000
2017/08/29 22:50:40 Saving...
2017/08/29 22:50:40 Gathering batch of experience...
2017/08/29 22:51:04 batch 281: mean=1393.333333 stddev=901.544007 entropy=0.506038 frames=5107 count=48
2017/08/29 22:51:04 Training policy...
2017/08/29 22:51:07 tune 0: objective=19.764699 reg=0.005060 prune=0
2017/08/29 22:51:08 step 0: objective=19.774729 reg=0.005059
2017/08/29 22:51:08 step 1: objective=19.801400 reg=0.005059
2017/08/29 22:51:09 step 2: objective=19.823043 reg=0.005058
2017/08/29 22:51:10 step 3: objective=19.851148 reg=0.005057
2017/08/29 22:51:11 step 4: objective=19.879315 reg=0.005056
2017/08/29 22:51:12 step 5: objective=19.902205 reg=0.005056
2017/08/29 22:51:13 step 6: objective=19.925505 reg=0.005054
2017/08/29 22:51:14 step 7: objective=19.951378 reg=0.005053
2017/08/29 22:51:14 Training value function...
2017/08/29 22:51:16 step 0: mse=22205.047717 step=0.050000
2017/08/29 22:51:17 step 1: mse=22153.194548 step=0.050000
2017/08/29 22:51:17 step 2: mse=22100.183338 step=0.050000
2017/08/29 22:51:18 step 3: mse=22057.096770 step=0.050000
2017/08/29 22:51:19 step 4: mse=22026.673238 step=0.050000
2017/08/29 22:51:20 step 5: mse=21983.323544 step=0.050000
2017/08/29 22:51:21 step 6: mse=21950.019379 step=0.050000
2017/08/29 22:51:21 step 7: mse=21917.932768 step=0.050000
2017/08/29 22:51:21 Saving...
2017/08/29 22:51:21 Gathering batch of experience...
2017/08/29 22:51:44 batch 282: mean=1232.000000 stddev=559.081389 entropy=0.500767 frames=4913 count=50
2017/08/29 22:51:44 Training policy...
2017/08/29 22:51:47 tune 0: objective=13.273011 reg=0.005008 prune=0
2017/08/29 22:51:48 step 0: objective=13.280457 reg=0.005006
2017/08/29 22:51:49 step 1: objective=13.291623 reg=0.005006
2017/08/29 22:51:50 step 2: objective=13.310198 reg=0.005006
2017/08/29 22:51:51 step 3: objective=13.328003 reg=0.005005
2017/08/29 22:51:52 step 4: objective=13.340482 reg=0.005004
2017/08/29 22:51:52 step 5: objective=13.360156 reg=0.005003
2017/08/29 22:51:53 step 6: objective=13.372926 reg=0.005002
2017/08/29 22:51:54 step 7: objective=13.382730 reg=0.005002
2017/08/29 22:51:54 Training value function...
2017/08/29 22:51:56 step 0: mse=13862.281333 step=0.050000
2017/08/29 22:51:57 step 1: mse=13846.549532 step=0.050000
2017/08/29 22:51:58 step 2: mse=13835.243851 step=0.050000
2017/08/29 22:51:58 step 3: mse=13834.852613 step=0.050000
2017/08/29 22:51:59 step 4: mse=13833.922745 step=0.050000
2017/08/29 22:52:00 step 5: mse=13839.976539 step=0.050000
2017/08/29 22:52:01 step 6: mse=13842.737098 step=0.050000
2017/08/29 22:52:02 step 7: mse=13852.396528 step=0.050000
2017/08/29 22:52:02 Saving...
2017/08/29 22:52:02 Gathering batch of experience...
2017/08/29 22:52:26 batch 283: mean=1639.693878 stddev=2625.901285 entropy=0.507473 frames=5272 count=49
2017/08/29 22:52:26 Training policy...
2017/08/29 22:52:29 tune 0: objective=49.686063 reg=0.005075 prune=0
2017/08/29 22:52:30 step 0: objective=49.720602 reg=0.005073
2017/08/29 22:52:31 step 1: objective=49.793965 reg=0.005072
2017/08/29 22:52:32 step 2: objective=49.903476 reg=0.005069
2017/08/29 22:52:33 step 3: objective=50.023248 reg=0.005068
2017/08/29 22:52:34 step 4: objective=50.183280 reg=0.005066
2017/08/29 22:52:34 step 5: objective=50.307942 reg=0.005063
2017/08/29 22:52:35 step 6: objective=50.388894 reg=0.005063
2017/08/29 22:52:36 step 7: objective=50.519478 reg=0.005062
2017/08/29 22:52:36 Training value function...
2017/08/29 22:52:38 step 0: mse=211329.765432 step=0.050000
2017/08/29 22:52:39 step 1: mse=208369.630077 step=0.050000
2017/08/29 22:52:40 step 2: mse=205196.793968 step=0.050000
2017/08/29 22:52:41 step 3: mse=201501.006150 step=0.050000
2017/08/29 22:52:42 step 4: mse=198817.023892 step=0.050000
2017/08/29 22:52:43 step 5: mse=196475.633640 step=0.050000
2017/08/29 22:52:43 step 6: mse=193563.656808 step=0.050000
2017/08/29 22:52:44 step 7: mse=191795.946424 step=0.050000
2017/08/29 22:52:44 Saving...
2017/08/29 22:52:44 Gathering batch of experience...
2017/08/29 22:53:07 batch 284: mean=1257.500000 stddev=611.253834 entropy=0.503378 frames=4783 count=48
2017/08/29 22:53:07 Training policy...
2017/08/29 22:53:10 tune 0: objective=14.857846 reg=0.005034 prune=0
2017/08/29 22:53:11 step 0: objective=14.866444 reg=0.005032
2017/08/29 22:53:11 step 1: objective=14.887071 reg=0.005031
2017/08/29 22:53:12 step 2: objective=14.907632 reg=0.005029
2017/08/29 22:53:13 step 3: objective=14.921055 reg=0.005029
2017/08/29 22:53:14 step 4: objective=14.935094 reg=0.005028
2017/08/29 22:53:15 step 5: objective=14.949994 reg=0.005027
2017/08/29 22:53:16 step 6: objective=14.967171 reg=0.005026
2017/08/29 22:53:16 step 7: objective=14.980510 reg=0.005026
2017/08/29 22:53:16 Training value function...
2017/08/29 22:53:18 step 0: mse=13467.757465 step=0.050000
2017/08/29 22:53:19 step 1: mse=13369.537918 step=0.050000
2017/08/29 22:53:20 step 2: mse=13292.364222 step=0.050000
2017/08/29 22:53:21 step 3: mse=13223.733758 step=0.050000
2017/08/29 22:53:21 step 4: mse=13159.913049 step=0.050000
2017/08/29 22:53:22 step 5: mse=13101.600480 step=0.050000
2017/08/29 22:53:23 step 6: mse=13057.375932 step=0.050000
2017/08/29 22:53:24 step 7: mse=13013.480626 step=0.050000
2017/08/29 22:53:24 Saving...
2017/08/29 22:53:24 Gathering batch of experience...
2017/08/29 22:53:46 batch 285: mean=1683.000000 stddev=2910.253597 entropy=0.506750 frames=4963 count=45
2017/08/29 22:53:46 Training policy...
2017/08/29 22:53:49 tune 0: objective=43.359986 reg=0.005068 prune=0
2017/08/29 22:53:50 step 0: objective=43.432475 reg=0.005067
2017/08/29 22:53:51 step 1: objective=43.636180 reg=0.005066
2017/08/29 22:53:52 step 2: objective=43.784165 reg=0.005063
2017/08/29 22:53:52 step 3: objective=43.870967 reg=0.005063
2017/08/29 22:53:53 step 4: objective=44.020070 reg=0.005062
2017/08/29 22:53:54 step 5: objective=44.084525 reg=0.005061
2017/08/29 22:53:55 step 6: objective=44.188306 reg=0.005059
2017/08/29 22:53:56 step 7: objective=44.296582 reg=0.005059
2017/08/29 22:53:56 Training value function...
2017/08/29 22:53:58 step 0: mse=221642.831884 step=0.050000
2017/08/29 22:53:59 step 1: mse=219163.441846 step=0.050000
2017/08/29 22:53:59 step 2: mse=216367.841384 step=0.050000
2017/08/29 22:54:00 step 3: mse=214060.953039 step=0.050000
2017/08/29 22:54:01 step 4: mse=209419.751792 step=0.050000
2017/08/29 22:54:02 step 5: mse=207664.341463 step=0.050000
2017/08/29 22:54:02 step 6: mse=205903.885051 step=0.050000
2017/08/29 22:54:03 step 7: mse=201976.213358 step=0.050000
2017/08/29 22:54:03 Saving...
2017/08/29 22:54:03 Gathering batch of experience...
2017/08/29 22:54:26 batch 286: mean=1390.000000 stddev=553.747837 entropy=0.499201 frames=4929 count=45
2017/08/29 22:54:26 Training policy...
2017/08/29 22:54:29 tune 0: objective=18.675647 reg=0.004992 prune=0
2017/08/29 22:54:30 step 0: objective=18.682193 reg=0.004991
2017/08/29 22:54:31 step 1: objective=18.694946 reg=0.004990
2017/08/29 22:54:32 step 2: objective=18.705428 reg=0.004990
2017/08/29 22:54:33 step 3: objective=18.714917 reg=0.004990
2017/08/29 22:54:34 step 4: objective=18.726754 reg=0.004989
2017/08/29 22:54:35 step 5: objective=18.741454 reg=0.004989
2017/08/29 22:54:35 step 6: objective=18.751208 reg=0.004988
2017/08/29 22:54:36 step 7: objective=18.766739 reg=0.004988
2017/08/29 22:54:36 Training value function...
2017/08/29 22:54:38 step 0: mse=13675.049578 step=0.050000
2017/08/29 22:54:39 step 1: mse=13590.914139 step=0.050000
2017/08/29 22:54:40 step 2: mse=13518.567497 step=0.050000
2017/08/29 22:54:41 step 3: mse=13453.878611 step=0.050000
2017/08/29 22:54:41 step 4: mse=13397.420151 step=0.050000
2017/08/29 22:54:42 step 5: mse=13342.556331 step=0.050000
2017/08/29 22:54:43 step 6: mse=13296.600151 step=0.050000
2017/08/29 22:54:44 step 7: mse=13253.372854 step=0.050000
2017/08/29 22:54:44 Saving...
2017/08/29 22:54:44 Gathering batch of experience...
2017/08/29 22:55:06 batch 287: mean=1572.380952 stddev=785.640653 entropy=0.499642 frames=4926 count=42
2017/08/29 22:55:06 Training policy...
2017/08/29 22:55:09 tune 0: objective=28.615465 reg=0.004996 prune=0
2017/08/29 22:55:10 step 0: objective=28.624867 reg=0.004996
2017/08/29 22:55:10 step 1: objective=28.640739 reg=0.004997
2017/08/29 22:55:11 step 2: objective=28.658061 reg=0.004996
2017/08/29 22:55:12 step 3: objective=28.682400 reg=0.004996
2017/08/29 22:55:13 step 4: objective=28.698386 reg=0.004996
2017/08/29 22:55:14 step 5: objective=28.713145 reg=0.004996
2017/08/29 22:55:15 step 6: objective=28.729931 reg=0.004996
2017/08/29 22:55:16 step 7: objective=28.753064 reg=0.004996
2017/08/29 22:55:16 Training value function...
2017/08/29 22:55:18 step 0: mse=16861.753875 step=0.050000
2017/08/29 22:55:18 step 1: mse=16739.315869 step=0.050000
2017/08/29 22:55:19 step 2: mse=16620.731599 step=0.050000
2017/08/29 22:55:20 step 3: mse=16515.560262 step=0.050000
2017/08/29 22:55:21 step 4: mse=16422.720830 step=0.050000
2017/08/29 22:55:21 step 5: mse=16333.824297 step=0.050000
2017/08/29 22:55:22 step 6: mse=16250.726109 step=0.050000
2017/08/29 22:55:23 step 7: mse=16177.254787 step=0.050000
2017/08/29 22:55:23 Saving...
2017/08/29 22:55:23 Gathering batch of experience...
2017/08/29 22:55:47 batch 288: mean=1230.784314 stddev=541.464402 entropy=0.495574 frames=5020 count=51
2017/08/29 22:55:47 Training policy...
2017/08/29 22:55:50 tune 0: objective=10.026585 reg=0.004956 prune=0
2017/08/29 22:55:51 step 0: objective=10.031431 reg=0.004955
2017/08/29 22:55:51 step 1: objective=10.039754 reg=0.004954
2017/08/29 22:55:52 step 2: objective=10.047531 reg=0.004954
2017/08/29 22:55:53 step 3: objective=10.056527 reg=0.004952
2017/08/29 22:55:54 step 4: objective=10.063120 reg=0.004952
2017/08/29 22:55:55 step 5: objective=10.070902 reg=0.004952
2017/08/29 22:55:56 step 6: objective=10.076962 reg=0.004952
2017/08/29 22:55:57 step 7: objective=10.083486 reg=0.004951
2017/08/29 22:55:57 Training value function...
2017/08/29 22:55:59 step 0: mse=12735.215845 step=0.050000
2017/08/29 22:56:00 step 1: mse=12775.624985 step=0.050000
2017/08/29 22:56:00 step 2: mse=12822.306393 step=0.050000
2017/08/29 22:56:01 step 3: mse=12875.680055 step=0.050000
2017/08/29 22:56:02 step 4: mse=12926.367898 step=0.050000
2017/08/29 22:56:03 step 5: mse=12981.068162 step=0.050000
2017/08/29 22:56:03 step 6: mse=13034.310910 step=0.050000
2017/08/29 22:56:04 step 7: mse=13086.906701 step=0.050000
2017/08/29 22:56:04 Saving...
2017/08/29 22:56:04 Gathering batch of experience...
2017/08/29 22:56:27 batch 289: mean=1232.352941 stddev=653.478890 entropy=0.504938 frames=4964 count=51
2017/08/29 22:56:27 Training policy...
2017/08/29 22:56:30 tune 0: objective=19.288875 reg=0.005049 prune=0
2017/08/29 22:56:31 step 0: objective=19.297925 reg=0.005048
2017/08/29 22:56:32 step 1: objective=19.318041 reg=0.005046
2017/08/29 22:56:33 step 2: objective=19.336768 reg=0.005046
2017/08/29 22:56:34 step 3: objective=19.352855 reg=0.005044
2017/08/29 22:56:35 step 4: objective=19.371209 reg=0.005043
2017/08/29 22:56:36 step 5: objective=19.387621 reg=0.005042
2017/08/29 22:56:36 step 6: objective=19.408910 reg=0.005041
2017/08/29 22:56:37 step 7: objective=19.427015 reg=0.005039
2017/08/29 22:56:37 Training value function...
2017/08/29 22:56:39 step 0: mse=16805.747578 step=0.050000
2017/08/29 22:56:40 step 1: mse=16721.545657 step=0.050000
2017/08/29 22:56:41 step 2: mse=16648.476284 step=0.050000
2017/08/29 22:56:42 step 3: mse=16574.488559 step=0.050000
2017/08/29 22:56:42 step 4: mse=16512.712244 step=0.050000
2017/08/29 22:56:43 step 5: mse=16457.034738 step=0.050000
2017/08/29 22:56:44 step 6: mse=16409.877663 step=0.050000
2017/08/29 22:56:45 step 7: mse=16365.795184 step=0.050000
2017/08/29 22:56:45 Saving...
2017/08/29 22:56:45 Gathering batch of experience...
2017/08/29 22:57:08 batch 290: mean=1441.489362 stddev=799.779168 entropy=0.500812 frames=5153 count=47
2017/08/29 22:57:08 Training policy...
2017/08/29 22:57:11 tune 0: objective=28.963404 reg=0.005008 prune=0
2017/08/29 22:57:12 step 0: objective=28.971764 reg=0.005007
2017/08/29 22:57:13 step 1: objective=28.986716 reg=0.005007
2017/08/29 22:57:14 step 2: objective=29.002286 reg=0.005006
2017/08/29 22:57:15 step 3: objective=29.019955 reg=0.005006
2017/08/29 22:57:16 step 4: objective=29.034225 reg=0.005006
2017/08/29 22:57:17 step 5: objective=29.051445 reg=0.005005
2017/08/29 22:57:17 step 6: objective=29.065187 reg=0.005005
2017/08/29 22:57:18 step 7: objective=29.078747 reg=0.005005
2017/08/29 22:57:18 Training value function...
2017/08/29 22:57:20 step 0: mse=18916.346697 step=0.050000
2017/08/29 22:57:21 step 1: mse=18785.722435 step=0.050000
2017/08/29 22:57:22 step 2: mse=18682.448223 step=0.050000
2017/08/29 22:57:23 step 3: mse=18562.719862 step=0.050000
2017/08/29 22:57:24 step 4: mse=18476.370071 step=0.050000
2017/08/29 22:57:24 step 5: mse=18403.606735 step=0.050000
2017/08/29 22:57:25 step 6: mse=18316.843948 step=0.050000
2017/08/29 22:57:26 step 7: mse=18244.518226 step=0.050000
2017/08/29 22:57:26 Saving...
2017/08/29 22:57:26 Gathering batch of experience...
2017/08/29 22:57:49 batch 291: mean=1224.019608 stddev=663.701016 entropy=0.503127 frames=4889 count=51
2017/08/29 22:57:49 Training policy...
2017/08/29 22:57:52 tune 0: objective=20.681281 reg=0.005031 prune=0
2017/08/29 22:57:53 step 0: objective=20.686677 reg=0.005030
2017/08/29 22:57:54 step 1: objective=20.703775 reg=0.005029
2017/08/29 22:57:55 step 2: objective=20.722361 reg=0.005028
2017/08/29 22:57:56 step 3: objective=20.740615 reg=0.005026
2017/08/29 22:57:56 step 4: objective=20.758458 reg=0.005024
2017/08/29 22:57:57 step 5: objective=20.774936 reg=0.005023
2017/08/29 22:57:58 step 6: objective=20.791827 reg=0.005022
2017/08/29 22:57:59 step 7: objective=20.807781 reg=0.005021
2017/08/29 22:57:59 Training value function...
2017/08/29 22:58:01 step 0: mse=14345.987061 step=0.050000
2017/08/29 22:58:02 step 1: mse=14279.609157 step=0.050000
2017/08/29 22:58:02 step 2: mse=14220.797906 step=0.050000
2017/08/29 22:58:03 step 3: mse=14171.805804 step=0.050000
2017/08/29 22:58:04 step 4: mse=14122.140700 step=0.050000
2017/08/29 22:58:05 step 5: mse=14085.771809 step=0.050000
2017/08/29 22:58:06 step 6: mse=14043.912257 step=0.050000
2017/08/29 22:58:06 step 7: mse=14007.112576 step=0.050000
2017/08/29 22:58:06 Saving...
2017/08/29 22:58:06 Gathering batch of experience...
2017/08/29 22:58:30 batch 292: mean=1292.500000 stddev=606.390345 entropy=0.497511 frames=5113 count=50
2017/08/29 22:58:30 Training policy...
2017/08/29 22:58:33 tune 0: objective=19.384284 reg=0.004975 prune=0
2017/08/29 22:58:34 step 0: objective=19.392920 reg=0.004974
2017/08/29 22:58:35 step 1: objective=19.413138 reg=0.004973
2017/08/29 22:58:35 step 2: objective=19.432161 reg=0.004971
2017/08/29 22:58:36 step 3: objective=19.445381 reg=0.004970
2017/08/29 22:58:37 step 4: objective=19.466493 reg=0.004969
2017/08/29 22:58:38 step 5: objective=19.485943 reg=0.004968
2017/08/29 22:58:39 step 6: objective=19.508946 reg=0.004966
2017/08/29 22:58:40 step 7: objective=19.527158 reg=0.004964
2017/08/29 22:58:40 Training value function...
2017/08/29 22:58:42 step 0: mse=16440.715603 step=0.050000
2017/08/29 22:58:43 step 1: mse=16420.363432 step=0.050000
2017/08/29 22:58:44 step 2: mse=16414.870373 step=0.050000
2017/08/29 22:58:44 step 3: mse=16398.500249 step=0.050000
2017/08/29 22:58:45 step 4: mse=16377.437463 step=0.050000
2017/08/29 22:58:46 step 5: mse=16370.954621 step=0.050000
2017/08/29 22:58:47 step 6: mse=16356.744380 step=0.050000
2017/08/29 22:58:48 step 7: mse=16340.186417 step=0.050000
2017/08/29 22:58:48 Saving...
2017/08/29 22:58:48 Gathering batch of experience...
2017/08/29 22:59:10 batch 293: mean=1265.312500 stddev=644.619887 entropy=0.500035 frames=4843 count=48
2017/08/29 22:59:10 Training policy...
2017/08/29 22:59:13 tune 0: objective=21.162970 reg=0.005000 prune=0
2017/08/29 22:59:14 step 0: objective=21.172765 reg=0.004999
2017/08/29 22:59:15 step 1: objective=21.189595 reg=0.004998
2017/08/29 22:59:15 step 2: objective=21.205072 reg=0.004997
2017/08/29 22:59:16 step 3: objective=21.225846 reg=0.004995
2017/08/29 22:59:17 step 4: objective=21.242079 reg=0.004994
2017/08/29 22:59:18 step 5: objective=21.260710 reg=0.004992
2017/08/29 22:59:19 step 6: objective=21.272195 reg=0.004991
2017/08/29 22:59:20 step 7: objective=21.287377 reg=0.004989
2017/08/29 22:59:20 Training value function...
2017/08/29 22:59:22 step 0: mse=16541.534599 step=0.050000
2017/08/29 22:59:22 step 1: mse=16491.896038 step=0.050000
2017/08/29 22:59:23 step 2: mse=16446.358162 step=0.050000
2017/08/29 22:59:24 step 3: mse=16406.030433 step=0.050000
2017/08/29 22:59:25 step 4: mse=16368.182525 step=0.050000
2017/08/29 22:59:25 step 5: mse=16334.628617 step=0.050000
2017/08/29 22:59:26 step 6: mse=16303.983042 step=0.050000
2017/08/29 22:59:27 step 7: mse=16275.223974 step=0.050000
2017/08/29 22:59:27 Saving...
2017/08/29 22:59:27 Gathering batch of experience...
2017/08/29 22:59:51 batch 294: mean=1141.851852 stddev=548.994279 entropy=0.491672 frames=4963 count=54
2017/08/29 22:59:51 Training policy...
2017/08/29 22:59:54 tune 0: objective=13.669755 reg=0.004917 prune=0
2017/08/29 22:59:54 step 0: objective=13.676794 reg=0.004916
2017/08/29 22:59:55 step 1: objective=13.695391 reg=0.004915
2017/08/29 22:59:56 step 2: objective=13.715400 reg=0.004913
2017/08/29 22:59:57 step 3: objective=13.735302 reg=0.004912
2017/08/29 22:59:58 step 4: objective=13.741898 reg=0.004912
2017/08/29 22:59:59 step 5: objective=13.755302 reg=0.004911
2017/08/29 23:00:00 step 6: objective=13.766425 reg=0.004910
2017/08/29 23:00:01 step 7: objective=13.780978 reg=0.004909
2017/08/29 23:00:01 Training value function...
2017/08/29 23:00:03 step 0: mse=13852.440328 step=0.050000
2017/08/29 23:00:03 step 1: mse=13902.586381 step=0.050000
2017/08/29 23:00:04 step 2: mse=13952.729298 step=0.050000
2017/08/29 23:00:05 step 3: mse=14001.294607 step=0.050000
2017/08/29 23:00:06 step 4: mse=14054.446398 step=0.050000
2017/08/29 23:00:06 step 5: mse=14107.604323 step=0.050000
2017/08/29 23:00:07 step 6: mse=14158.121204 step=0.050000
2017/08/29 23:00:08 step 7: mse=14203.112720 step=0.050000
2017/08/29 23:00:08 Saving...
2017/08/29 23:00:08 Gathering batch of experience...
2017/08/29 23:00:31 batch 295: mean=1256.428571 stddev=574.637419 entropy=0.492083 frames=4891 count=49
2017/08/29 23:00:31 Training policy...
2017/08/29 23:00:34 tune 0: objective=23.153514 reg=0.004921 prune=0
2017/08/29 23:00:35 step 0: objective=23.158344 reg=0.004920
2017/08/29 23:00:35 step 1: objective=23.171885 reg=0.004919
2017/08/29 23:00:36 step 2: objective=23.183475 reg=0.004919
2017/08/29 23:00:37 step 3: objective=23.194889 reg=0.004918
2017/08/29 23:00:38 step 4: objective=23.203253 reg=0.004918
2017/08/29 23:00:39 step 5: objective=23.215971 reg=0.004917
2017/08/29 23:00:40 step 6: objective=23.223874 reg=0.004917
2017/08/29 23:00:41 step 7: objective=23.235381 reg=0.004916
2017/08/29 23:00:41 Training value function...
2017/08/29 23:00:42 step 0: mse=15068.416941 step=0.050000
2017/08/29 23:00:43 step 1: mse=14986.510525 step=0.050000
2017/08/29 23:00:44 step 2: mse=14913.548143 step=0.050000
2017/08/29 23:00:45 step 3: mse=14847.320679 step=0.050000
2017/08/29 23:00:46 step 4: mse=14791.439743 step=0.050000
2017/08/29 23:00:46 step 5: mse=14738.456273 step=0.050000
2017/08/29 23:00:47 step 6: mse=14691.010863 step=0.050000
2017/08/29 23:00:48 step 7: mse=14646.390244 step=0.050000
2017/08/29 23:00:48 Saving...
2017/08/29 23:00:48 Gathering batch of experience...
2017/08/29 23:01:11 batch 296: mean=1429.111111 stddev=589.233296 entropy=0.492939 frames=4981 count=45
2017/08/29 23:01:11 Training policy...
2017/08/29 23:01:14 tune 0: objective=32.233139 reg=0.004929 prune=0
2017/08/29 23:01:15 step 0: objective=32.239589 reg=0.004929
2017/08/29 23:01:16 step 1: objective=32.256788 reg=0.004929
2017/08/29 23:01:16 step 2: objective=32.273367 reg=0.004929
2017/08/29 23:01:17 step 3: objective=32.288722 reg=0.004929
2017/08/29 23:01:18 step 4: objective=32.303130 reg=0.004929
2017/08/29 23:01:19 step 5: objective=32.318912 reg=0.004928
2017/08/29 23:01:20 step 6: objective=32.336140 reg=0.004927
2017/08/29 23:01:21 step 7: objective=32.349732 reg=0.004927
2017/08/29 23:01:21 Training value function...
2017/08/29 23:01:23 step 0: mse=16610.862539 step=0.050000
2017/08/29 23:01:24 step 1: mse=16416.209615 step=0.050000
2017/08/29 23:01:24 step 2: mse=16238.637740 step=0.050000
2017/08/29 23:01:25 step 3: mse=16079.660931 step=0.050000
2017/08/29 23:01:26 step 4: mse=15917.119838 step=0.050000
2017/08/29 23:01:27 step 5: mse=15773.684088 step=0.050000
2017/08/29 23:01:27 step 6: mse=15638.837175 step=0.050000
2017/08/29 23:01:28 step 7: mse=15518.126486 step=0.050000
2017/08/29 23:01:28 Saving...
2017/08/29 23:01:28 Gathering batch of experience...
2017/08/29 23:01:51 batch 297: mean=1259.693878 stddev=631.327891 entropy=0.494311 frames=4870 count=49
2017/08/29 23:01:51 Training policy...
2017/08/29 23:01:54 tune 0: objective=23.012267 reg=0.004943 prune=0
2017/08/29 23:01:55 step 0: objective=23.017069 reg=0.004942
2017/08/29 23:01:55 step 1: objective=23.026819 reg=0.004941
2017/08/29 23:01:56 step 2: objective=23.037461 reg=0.004941
2017/08/29 23:01:57 step 3: objective=23.047124 reg=0.004940
2017/08/29 23:01:58 step 4: objective=23.060110 reg=0.004939
2017/08/29 23:01:59 step 5: objective=23.066677 reg=0.004940
2017/08/29 23:02:00 step 6: objective=23.078035 reg=0.004939
2017/08/29 23:02:01 step 7: objective=23.086818 reg=0.004938
2017/08/29 23:02:01 Training value function...
2017/08/29 23:02:03 step 0: mse=15990.864130 step=0.050000
2017/08/29 23:02:03 step 1: mse=15951.428982 step=0.050000
2017/08/29 23:02:04 step 2: mse=15884.259084 step=0.050000
2017/08/29 23:02:05 step 3: mse=15820.579592 step=0.050000
2017/08/29 23:02:06 step 4: mse=15767.324835 step=0.050000
2017/08/29 23:02:06 step 5: mse=15720.581986 step=0.050000
2017/08/29 23:02:07 step 6: mse=15676.553651 step=0.050000
2017/08/29 23:02:08 step 7: mse=15639.162984 step=0.050000
2017/08/29 23:02:08 Saving...
2017/08/29 23:02:08 Gathering batch of experience...
2017/08/29 23:02:30 batch 298: mean=1359.565217 stddev=564.895937 entropy=0.491485 frames=4887 count=46
2017/08/29 23:02:30 Training policy...
2017/08/29 23:02:33 tune 0: objective=26.682912 reg=0.004915 prune=0
2017/08/29 23:02:34 step 0: objective=26.686769 reg=0.004914
2017/08/29 23:02:35 step 1: objective=26.701405 reg=0.004914
2017/08/29 23:02:36 step 2: objective=26.716720 reg=0.004913
2017/08/29 23:02:37 step 3: objective=26.730292 reg=0.004913
2017/08/29 23:02:38 step 4: objective=26.743895 reg=0.004912
2017/08/29 23:02:38 step 5: objective=26.757255 reg=0.004911
2017/08/29 23:02:39 step 6: objective=26.771171 reg=0.004910
2017/08/29 23:02:40 step 7: objective=26.778774 reg=0.004911
2017/08/29 23:02:40 Training value function...
2017/08/29 23:02:42 step 0: mse=13577.247648 step=0.050000
2017/08/29 23:02:43 step 1: mse=13504.197009 step=0.050000
2017/08/29 23:02:44 step 2: mse=13438.852705 step=0.050000
2017/08/29 23:02:44 step 3: mse=13372.556000 step=0.050000
2017/08/29 23:02:45 step 4: mse=13310.032899 step=0.050000
2017/08/29 23:02:46 step 5: mse=13251.962844 step=0.050000
2017/08/29 23:02:47 step 6: mse=13198.746144 step=0.050000
2017/08/29 23:02:47 step 7: mse=13148.956753 step=0.050000
2017/08/29 23:02:47 Saving...
2017/08/29 23:02:47 Gathering batch of experience...
2017/08/29 23:03:10 batch 299: mean=1367.717391 stddev=652.085039 entropy=0.495381 frames=4852 count=46
2017/08/29 23:03:10 Training policy...
2017/08/29 23:03:13 tune 0: objective=29.000789 reg=0.004954 prune=0
2017/08/29 23:03:14 step 0: objective=29.007397 reg=0.004953
2017/08/29 23:03:15 step 1: objective=29.022471 reg=0.004952
2017/08/29 23:03:15 step 2: objective=29.035424 reg=0.004952
2017/08/29 23:03:16 step 3: objective=29.050028 reg=0.004951
2017/08/29 23:03:17 step 4: objective=29.062004 reg=0.004950
2017/08/29 23:03:18 step 5: objective=29.077574 reg=0.004950
2017/08/29 23:03:19 step 6: objective=29.094114 reg=0.004949
2017/08/29 23:03:20 step 7: objective=29.108528 reg=0.004948
2017/08/29 23:03:20 Training value function...
2017/08/29 23:03:22 step 0: mse=16489.822248 step=0.050000
2017/08/29 23:03:22 step 1: mse=16355.506914 step=0.050000
2017/08/29 23:03:23 step 2: mse=16234.345086 step=0.050000
2017/08/29 23:03:24 step 3: mse=16120.264030 step=0.050000
2017/08/29 23:03:25 step 4: mse=16015.088751 step=0.050000
2017/08/29 23:03:25 step 5: mse=15914.031256 step=0.050000
2017/08/29 23:03:26 step 6: mse=15823.299202 step=0.050000
2017/08/29 23:03:27 step 7: mse=15740.107302 step=0.050000
2017/08/29 23:03:27 Saving...
2017/08/29 23:03:27 Gathering batch of experience...
2017/08/29 23:03:49 batch 300: mean=1272.872340 stddev=555.724316 entropy=0.487750 frames=4764 count=47
2017/08/29 23:03:49 Training policy...
2017/08/29 23:03:52 tune 0: objective=17.091246 reg=0.004878 prune=0
2017/08/29 23:03:53 step 0: objective=17.098253 reg=0.004877
2017/08/29 23:03:54 step 1: objective=17.112645 reg=0.004876
2017/08/29 23:03:55 step 2: objective=17.124229 reg=0.004875
2017/08/29 23:03:56 step 3: objective=17.134457 reg=0.004875
2017/08/29 23:03:56 step 4: objective=17.147723 reg=0.004875
2017/08/29 23:03:57 step 5: objective=17.168543 reg=0.004873
2017/08/29 23:03:58 step 6: objective=17.176086 reg=0.004873
2017/08/29 23:03:59 step 7: objective=17.184150 reg=0.004873
2017/08/29 23:03:59 Training value function...
2017/08/29 23:04:01 step 0: mse=13716.468665 step=0.050000
2017/08/29 23:04:02 step 1: mse=13732.348844 step=0.050000
2017/08/29 23:04:02 step 2: mse=13754.794423 step=0.050000
2017/08/29 23:04:03 step 3: mse=13780.369119 step=0.050000
2017/08/29 23:04:04 step 4: mse=13803.410257 step=0.050000
2017/08/29 23:04:05 step 5: mse=13828.922315 step=0.050000
2017/08/29 23:04:05 step 6: mse=13847.618872 step=0.050000
2017/08/29 23:04:06 step 7: mse=13861.567404 step=0.050000
2017/08/29 23:04:06 Saving...
2017/08/29 23:04:06 Gathering batch of experience...
2017/08/29 23:04:29 batch 301: mean=1466.590909 stddev=504.125900 entropy=0.488167 frames=5008 count=44
2017/08/29 23:04:29 Training policy...
2017/08/29 23:04:32 tune 0: objective=29.844917 reg=0.004882 prune=0
2017/08/29 23:04:33 step 0: objective=29.848109 reg=0.004881
2017/08/29 23:04:34 step 1: objective=29.854795 reg=0.004881
2017/08/29 23:04:35 step 2: objective=29.867621 reg=0.004880
2017/08/29 23:04:35 step 3: objective=29.874916 reg=0.004879
2017/08/29 23:04:36 step 4: objective=29.882656 reg=0.004879
2017/08/29 23:04:37 step 5: objective=29.892931 reg=0.004878
2017/08/29 23:04:38 step 6: objective=29.900946 reg=0.004878
2017/08/29 23:04:39 step 7: objective=29.908091 reg=0.004877
2017/08/29 23:04:39 Training value function...
2017/08/29 23:04:41 step 0: mse=13716.117597 step=0.050000
2017/08/29 23:04:42 step 1: mse=13589.983933 step=0.050000
2017/08/29 23:04:43 step 2: mse=13471.728139 step=0.050000
2017/08/29 23:04:43 step 3: mse=13364.896775 step=0.050000
2017/08/29 23:04:44 step 4: mse=13263.401087 step=0.050000
2017/08/29 23:04:45 step 5: mse=13171.213236 step=0.050000
2017/08/29 23:04:46 step 6: mse=13086.610448 step=0.050000
2017/08/29 23:04:46 step 7: mse=13005.699594 step=0.050000
2017/08/29 23:04:46 Saving...
2017/08/29 23:04:46 Gathering batch of experience...
2017/08/29 23:05:09 batch 302: mean=1382.222222 stddev=531.459788 entropy=0.485048 frames=4868 count=45
2017/08/29 23:05:09 Training policy...
2017/08/29 23:05:12 tune 0: objective=22.784211 reg=0.004850 prune=0
2017/08/29 23:05:13 step 0: objective=22.790836 reg=0.004849
2017/08/29 23:05:14 step 1: objective=22.802391 reg=0.004850
2017/08/29 23:05:15 step 2: objective=22.815666 reg=0.004849
2017/08/29 23:05:16 step 3: objective=22.827751 reg=0.004848
2017/08/29 23:05:17 step 4: objective=22.838160 reg=0.004847
2017/08/29 23:05:17 step 5: objective=22.851911 reg=0.004847
2017/08/29 23:05:18 step 6: objective=22.860851 reg=0.004847
2017/08/29 23:05:19 step 7: objective=22.875061 reg=0.004846
2017/08/29 23:05:19 Training value function...
2017/08/29 23:05:21 step 0: mse=13264.915790 step=0.050000
2017/08/29 23:05:22 step 1: mse=13239.137936 step=0.050000
2017/08/29 23:05:23 step 2: mse=13211.816552 step=0.050000
2017/08/29 23:05:23 step 3: mse=13187.889610 step=0.050000
2017/08/29 23:05:24 step 4: mse=13163.733430 step=0.050000
2017/08/29 23:05:25 step 5: mse=13149.332044 step=0.050000
2017/08/29 23:05:26 step 6: mse=13127.165019 step=0.050000
2017/08/29 23:05:26 step 7: mse=13105.592288 step=0.050000
2017/08/29 23:05:26 Saving...
2017/08/29 23:05:26 Gathering batch of experience...
2017/08/29 23:05:49 batch 303: mean=1239.795918 stddev=623.580804 entropy=0.493476 frames=4839 count=49
2017/08/29 23:05:49 Training policy...
2017/08/29 23:05:52 tune 0: objective=19.085984 reg=0.004935 prune=0
2017/08/29 23:05:53 step 0: objective=19.090100 reg=0.004934
2017/08/29 23:05:54 step 1: objective=19.099649 reg=0.004934
2017/08/29 23:05:54 step 2: objective=19.111304 reg=0.004934
2017/08/29 23:05:55 step 3: objective=19.125741 reg=0.004933
2017/08/29 23:05:56 step 4: objective=19.134383 reg=0.004933
2017/08/29 23:05:57 step 5: objective=19.143076 reg=0.004932
2017/08/29 23:05:58 step 6: objective=19.155486 reg=0.004932
2017/08/29 23:05:59 step 7: objective=19.165624 reg=0.004932
2017/08/29 23:05:59 Training value function...
2017/08/29 23:06:01 step 0: mse=14342.865936 step=0.050000
2017/08/29 23:06:01 step 1: mse=14310.783718 step=0.050000
2017/08/29 23:06:02 step 2: mse=14297.191812 step=0.050000
2017/08/29 23:06:03 step 3: mse=14276.866834 step=0.050000
2017/08/29 23:06:04 step 4: mse=14274.758789 step=0.050000
2017/08/29 23:06:04 step 5: mse=14272.280228 step=0.050000
2017/08/29 23:06:05 step 6: mse=14246.391757 step=0.050000
2017/08/29 23:06:06 step 7: mse=14237.582454 step=0.050000
2017/08/29 23:06:06 Saving...
2017/08/29 23:06:06 Gathering batch of experience...
2017/08/29 23:06:29 batch 304: mean=1433.333333 stddev=437.381095 entropy=0.481570 frames=5020 count=45
2017/08/29 23:06:29 Training policy...
2017/08/29 23:06:32 tune 0: objective=26.244388 reg=0.004816 prune=0
2017/08/29 23:06:33 step 0: objective=26.248584 reg=0.004815
2017/08/29 23:06:34 step 1: objective=26.258161 reg=0.004815
2017/08/29 23:06:35 step 2: objective=26.266599 reg=0.004815
2017/08/29 23:06:36 step 3: objective=26.276348 reg=0.004815
2017/08/29 23:06:36 step 4: objective=26.283893 reg=0.004815
2017/08/29 23:06:37 step 5: objective=26.293071 reg=0.004815
2017/08/29 23:06:38 step 6: objective=26.301198 reg=0.004815
2017/08/29 23:06:39 step 7: objective=26.309879 reg=0.004815
2017/08/29 23:06:39 Training value function...
2017/08/29 23:06:41 step 0: mse=12198.690931 step=0.050000
2017/08/29 23:06:42 step 1: mse=12108.572007 step=0.050000
2017/08/29 23:06:43 step 2: mse=12022.260219 step=0.050000
2017/08/29 23:06:44 step 3: mse=11947.114637 step=0.050000
2017/08/29 23:06:44 step 4: mse=11879.472115 step=0.050000
2017/08/29 23:06:45 step 5: mse=11818.742733 step=0.050000
2017/08/29 23:06:46 step 6: mse=11749.068655 step=0.050000
2017/08/29 23:06:47 step 7: mse=11690.999677 step=0.050000
2017/08/29 23:06:47 Saving...
2017/08/29 23:06:47 Gathering batch of experience...
2017/08/29 23:07:09 batch 305: mean=1408.369565 stddev=827.563248 entropy=0.490416 frames=4930 count=46
2017/08/29 23:07:09 Training policy...
2017/08/29 23:07:12 tune 0: objective=29.257375 reg=0.004904 prune=0
2017/08/29 23:07:13 step 0: objective=29.267742 reg=0.004903
2017/08/29 23:07:14 step 1: objective=29.284591 reg=0.004903
2017/08/29 23:07:15 step 2: objective=29.301049 reg=0.004903
2017/08/29 23:07:16 step 3: objective=29.317907 reg=0.004901
2017/08/29 23:07:17 step 4: objective=29.333751 reg=0.004901
2017/08/29 23:07:18 step 5: objective=29.352466 reg=0.004900
2017/08/29 23:07:18 step 6: objective=29.376987 reg=0.004899
2017/08/29 23:07:19 step 7: objective=29.392986 reg=0.004899
2017/08/29 23:07:19 Training value function...
2017/08/29 23:07:21 step 0: mse=24761.435449 step=0.050000
2017/08/29 23:07:22 step 1: mse=24347.640366 step=0.050000
2017/08/29 23:07:23 step 2: mse=23985.136654 step=0.050000
2017/08/29 23:07:24 step 3: mse=23664.077109 step=0.050000
2017/08/29 23:07:24 step 4: mse=23355.300260 step=0.050000
2017/08/29 23:07:25 step 5: mse=23074.349577 step=0.050000
2017/08/29 23:07:26 step 6: mse=22842.527232 step=0.050000
2017/08/29 23:07:27 step 7: mse=22610.710158 step=0.050000
2017/08/29 23:07:27 Saving...
2017/08/29 23:07:27 Gathering batch of experience...
2017/08/29 23:07:50 batch 306: mean=1339.375000 stddev=598.420338 entropy=0.489841 frames=5054 count=48
2017/08/29 23:07:50 Training policy...
2017/08/29 23:07:53 tune 0: objective=22.176613 reg=0.004898 prune=0
2017/08/29 23:07:54 step 0: objective=22.184441 reg=0.004897
2017/08/29 23:07:55 step 1: objective=22.196648 reg=0.004896
2017/08/29 23:07:56 step 2: objective=22.214453 reg=0.004895
2017/08/29 23:07:57 step 3: objective=22.235374 reg=0.004893
2017/08/29 23:07:57 step 4: objective=22.256503 reg=0.004892
2017/08/29 23:07:58 step 5: objective=22.270598 reg=0.004890
2017/08/29 23:07:59 step 6: objective=22.285690 reg=0.004889
2017/08/29 23:08:00 step 7: objective=22.309823 reg=0.004887
2017/08/29 23:08:00 Training value function...
2017/08/29 23:08:02 step 0: mse=15557.321648 step=0.050000
2017/08/29 23:08:03 step 1: mse=15499.475417 step=0.050000
2017/08/29 23:08:04 step 2: mse=15446.911671 step=0.050000
2017/08/29 23:08:04 step 3: mse=15399.274960 step=0.050000
2017/08/29 23:08:05 step 4: mse=15360.083037 step=0.050000
2017/08/29 23:08:06 step 5: mse=15333.221820 step=0.050000
2017/08/29 23:08:07 step 6: mse=15304.872709 step=0.050000
2017/08/29 23:08:08 step 7: mse=15282.657370 step=0.050000
2017/08/29 23:08:08 Saving...
2017/08/29 23:08:08 Gathering batch of experience...
2017/08/29 23:08:30 batch 307: mean=1474.883721 stddev=524.285215 entropy=0.488115 frames=4916 count=43
2017/08/29 23:08:30 Training policy...
2017/08/29 23:08:33 tune 0: objective=28.487658 reg=0.004881 prune=0
2017/08/29 23:08:34 step 0: objective=28.491863 reg=0.004881
2017/08/29 23:08:35 step 1: objective=28.499422 reg=0.004880
2017/08/29 23:08:36 step 2: objective=28.507263 reg=0.004879
2017/08/29 23:08:37 step 3: objective=28.515104 reg=0.004879
2017/08/29 23:08:37 step 4: objective=28.523380 reg=0.004878
2017/08/29 23:08:38 step 5: objective=28.531472 reg=0.004877
2017/08/29 23:08:39 step 6: objective=28.540159 reg=0.004877
2017/08/29 23:08:40 step 7: objective=28.548445 reg=0.004876
2017/08/29 23:08:40 Training value function...
2017/08/29 23:08:42 step 0: mse=13692.116330 step=0.050000
2017/08/29 23:08:43 step 1: mse=13563.872302 step=0.050000
2017/08/29 23:08:43 step 2: mse=13446.952889 step=0.050000
2017/08/29 23:08:44 step 3: mse=13339.662173 step=0.050000
2017/08/29 23:08:45 step 4: mse=13235.381030 step=0.050000
2017/08/29 23:08:46 step 5: mse=13139.738453 step=0.050000
2017/08/29 23:08:47 step 6: mse=13050.667873 step=0.050000
2017/08/29 23:08:47 step 7: mse=12968.087248 step=0.050000
2017/08/29 23:08:47 Saving...
2017/08/29 23:08:47 Gathering batch of experience...
2017/08/29 23:09:10 batch 308: mean=1296.224490 stddev=565.969937 entropy=0.487213 frames=5015 count=49
2017/08/29 23:09:10 Training policy...
2017/08/29 23:09:14 tune 0: objective=18.378921 reg=0.004872 prune=0
2017/08/29 23:09:14 step 0: objective=18.384271 reg=0.004872
2017/08/29 23:09:15 step 1: objective=18.396492 reg=0.004871
2017/08/29 23:09:16 step 2: objective=18.406086 reg=0.004871
2017/08/29 23:09:17 step 3: objective=18.417105 reg=0.004870
2017/08/29 23:09:18 step 4: objective=18.427826 reg=0.004870
2017/08/29 23:09:19 step 5: objective=18.436660 reg=0.004870
2017/08/29 23:09:20 step 6: objective=18.452427 reg=0.004870
2017/08/29 23:09:21 step 7: objective=18.472274 reg=0.004869
2017/08/29 23:09:21 Training value function...
2017/08/29 23:09:23 step 0: mse=13360.136995 step=0.050000
2017/08/29 23:09:23 step 1: mse=13400.833488 step=0.050000
2017/08/29 23:09:24 step 2: mse=13434.866063 step=0.050000
2017/08/29 23:09:25 step 3: mse=13470.429654 step=0.050000
2017/08/29 23:09:26 step 4: mse=13508.310716 step=0.050000
2017/08/29 23:09:26 step 5: mse=13547.345860 step=0.050000
2017/08/29 23:09:27 step 6: mse=13579.001196 step=0.050000
2017/08/29 23:09:28 step 7: mse=13614.381701 step=0.050000
2017/08/29 23:09:28 Saving...
2017/08/29 23:09:28 Gathering batch of experience...
2017/08/29 23:09:51 batch 309: mean=1408.913043 stddev=528.705261 entropy=0.482795 frames=5091 count=46
2017/08/29 23:09:51 Training policy...
2017/08/29 23:09:54 tune 0: objective=24.461757 reg=0.004828 prune=0
2017/08/29 23:09:55 step 0: objective=24.465738 reg=0.004828
2017/08/29 23:09:56 step 1: objective=24.471930 reg=0.004828
2017/08/29 23:09:57 step 2: objective=24.478841 reg=0.004828
2017/08/29 23:09:58 step 3: objective=24.486332 reg=0.004828
2017/08/29 23:09:59 step 4: objective=24.496173 reg=0.004827
2017/08/29 23:10:00 step 5: objective=24.504796 reg=0.004827
2017/08/29 23:10:01 step 6: objective=24.511406 reg=0.004827
2017/08/29 23:10:02 step 7: objective=24.518966 reg=0.004827
2017/08/29 23:10:02 Training value function...
2017/08/29 23:10:04 step 0: mse=13727.769423 step=0.050000
2017/08/29 23:10:04 step 1: mse=13709.637800 step=0.050000
2017/08/29 23:10:05 step 2: mse=13693.125023 step=0.050000
2017/08/29 23:10:06 step 3: mse=13670.270208 step=0.050000
2017/08/29 23:10:07 step 4: mse=13654.694935 step=0.050000
2017/08/29 23:10:08 step 5: mse=13642.393873 step=0.050000
2017/08/29 23:10:08 step 6: mse=13628.727232 step=0.050000
2017/08/29 23:10:09 step 7: mse=13613.913862 step=0.050000
2017/08/29 23:10:09 Saving...
2017/08/29 23:10:09 Gathering batch of experience...
2017/08/29 23:10:32 batch 310: mean=1221.666667 stddev=623.990296 entropy=0.488053 frames=4656 count=48
2017/08/29 23:10:32 Training policy...
2017/08/29 23:10:35 tune 0: objective=17.355660 reg=0.004881 prune=0
2017/08/29 23:10:36 step 0: objective=17.360994 reg=0.004880
2017/08/29 23:10:36 step 1: objective=17.369891 reg=0.004880
2017/08/29 23:10:37 step 2: objective=17.384803 reg=0.004880
2017/08/29 23:10:38 step 3: objective=17.398015 reg=0.004880
2017/08/29 23:10:39 step 4: objective=17.410238 reg=0.004880
2017/08/29 23:10:40 step 5: objective=17.423394 reg=0.004879
2017/08/29 23:10:41 step 6: objective=17.440893 reg=0.004879
2017/08/29 23:10:41 step 7: objective=17.455446 reg=0.004878
2017/08/29 23:10:41 Training value function...
2017/08/29 23:10:43 step 0: mse=15387.685936 step=0.050000
2017/08/29 23:10:44 step 1: mse=15386.916435 step=0.050000
2017/08/29 23:10:45 step 2: mse=15395.742379 step=0.050000
2017/08/29 23:10:45 step 3: mse=15403.355450 step=0.050000
2017/08/29 23:10:46 step 4: mse=15408.805855 step=0.050000
2017/08/29 23:10:47 step 5: mse=15418.244666 step=0.050000
2017/08/29 23:10:48 step 6: mse=15424.552546 step=0.050000
2017/08/29 23:10:48 step 7: mse=15432.407632 step=0.050000
2017/08/29 23:10:48 Saving...
2017/08/29 23:10:48 Gathering batch of experience...
2017/08/29 23:11:11 batch 311: mean=1550.581395 stddev=686.403849 entropy=0.486788 frames=5027 count=43
2017/08/29 23:11:11 Training policy...
2017/08/29 23:11:15 tune 0: objective=36.303197 reg=0.004868 prune=0
2017/08/29 23:11:15 step 0: objective=36.314940 reg=0.004867
2017/08/29 23:11:16 step 1: objective=36.335153 reg=0.004868
2017/08/29 23:11:17 step 2: objective=36.355558 reg=0.004868
2017/08/29 23:11:18 step 3: objective=36.370111 reg=0.004868
2017/08/29 23:11:19 step 4: objective=36.392561 reg=0.004867
2017/08/29 23:11:20 step 5: objective=36.408870 reg=0.004867
2017/08/29 23:11:21 step 6: objective=36.426935 reg=0.004867
2017/08/29 23:11:22 step 7: objective=36.440173 reg=0.004866
2017/08/29 23:11:22 Training value function...
2017/08/29 23:11:24 step 0: mse=19999.660286 step=0.050000
2017/08/29 23:11:24 step 1: mse=19629.878343 step=0.050000
2017/08/29 23:11:25 step 2: mse=19296.603129 step=0.050000
2017/08/29 23:11:26 step 3: mse=18972.835545 step=0.050000
2017/08/29 23:11:27 step 4: mse=18686.700647 step=0.050000
2017/08/29 23:11:28 step 5: mse=18422.863507 step=0.050000
2017/08/29 23:11:28 step 6: mse=18166.437904 step=0.050000
2017/08/29 23:11:29 step 7: mse=17939.518018 step=0.050000
2017/08/29 23:11:29 Saving...
2017/08/29 23:11:29 Gathering batch of experience...
2017/08/29 23:11:52 batch 312: mean=1902.073171 stddev=2662.339879 entropy=0.496371 frames=5004 count=41
2017/08/29 23:11:52 Training policy...
2017/08/29 23:11:55 tune 0: objective=62.275917 reg=0.004964 prune=0
2017/08/29 23:11:56 step 0: objective=62.337967 reg=0.004964
2017/08/29 23:11:57 step 1: objective=62.573310 reg=0.004964
2017/08/29 23:11:58 step 2: objective=62.734019 reg=0.004962
2017/08/29 23:11:59 step 3: objective=62.865595 reg=0.004964
2017/08/29 23:12:00 step 4: objective=63.030245 reg=0.004962
2017/08/29 23:12:01 step 5: objective=63.143954 reg=0.004959
2017/08/29 23:12:02 step 6: objective=63.228005 reg=0.004959
2017/08/29 23:12:03 step 7: objective=63.360661 reg=0.004956
2017/08/29 23:12:03 Training value function...
2017/08/29 23:12:05 step 0: mse=257729.680023 step=0.050000
2017/08/29 23:12:05 step 1: mse=252486.166716 step=0.050000
2017/08/29 23:12:06 step 2: mse=244959.291035 step=0.050000
2017/08/29 23:12:07 step 3: mse=240383.466430 step=0.050000
2017/08/29 23:12:08 step 4: mse=233720.992617 step=0.050000
2017/08/29 23:12:08 step 5: mse=227820.498628 step=0.050000
2017/08/29 23:12:09 step 6: mse=224765.415719 step=0.050000
2017/08/29 23:12:10 step 7: mse=220589.458945 step=0.050000
2017/08/29 23:12:10 Saving...
2017/08/29 23:12:10 Gathering batch of experience...
2017/08/29 23:12:33 batch 313: mean=1427.000000 stddev=557.633292 entropy=0.485118 frames=5010 count=45
2017/08/29 23:12:33 Training policy...
2017/08/29 23:12:36 tune 0: objective=18.106351 reg=0.004851 prune=0
2017/08/29 23:12:37 step 0: objective=18.114106 reg=0.004851
2017/08/29 23:12:38 step 1: objective=18.124841 reg=0.004850
2017/08/29 23:12:39 step 2: objective=18.140787 reg=0.004850
2017/08/29 23:12:40 step 3: objective=18.152921 reg=0.004849
2017/08/29 23:12:41 step 4: objective=18.165648 reg=0.004848
2017/08/29 23:12:42 step 5: objective=18.178282 reg=0.004848
2017/08/29 23:12:43 step 6: objective=18.196091 reg=0.004848
2017/08/29 23:12:44 step 7: objective=18.212031 reg=0.004847
2017/08/29 23:12:44 Training value function...
2017/08/29 23:12:46 step 0: mse=12052.298280 step=0.050000
2017/08/29 23:12:46 step 1: mse=12031.035024 step=0.050000
2017/08/29 23:12:47 step 2: mse=12005.564951 step=0.050000
2017/08/29 23:12:48 step 3: mse=11990.442124 step=0.050000
2017/08/29 23:12:49 step 4: mse=11984.685584 step=0.050000
2017/08/29 23:12:49 step 5: mse=11977.545480 step=0.050000
2017/08/29 23:12:50 step 6: mse=11978.997643 step=0.050000
2017/08/29 23:12:51 step 7: mse=11974.228780 step=0.050000
2017/08/29 23:12:51 Saving...
2017/08/29 23:12:51 Gathering batch of experience...
2017/08/29 23:13:19 batch 314: mean=2025.568182 stddev=2871.045544 entropy=0.489485 frames=5590 count=44
2017/08/29 23:13:19 Training policy...
2017/08/29 23:13:22 tune 0: objective=56.704249 reg=0.004895 prune=0
2017/08/29 23:13:23 step 0: objective=56.765832 reg=0.004894
2017/08/29 23:13:24 step 1: objective=56.882687 reg=0.004894
2017/08/29 23:13:25 step 2: objective=57.100034 reg=0.004894
2017/08/29 23:13:26 step 3: objective=57.195807 reg=0.004894
2017/08/29 23:13:27 step 4: objective=57.312064 reg=0.004890
2017/08/29 23:13:28 step 5: objective=57.383358 reg=0.004888
2017/08/29 23:13:29 step 6: objective=57.459800 reg=0.004888
2017/08/29 23:13:30 step 7: objective=57.561175 reg=0.004887
2017/08/29 23:13:30 Training value function...
2017/08/29 23:13:32 step 0: mse=207370.782732 step=0.050000
2017/08/29 23:13:33 step 1: mse=202258.985449 step=0.050000
2017/08/29 23:13:34 step 2: mse=198183.970190 step=0.050000
2017/08/29 23:13:35 step 3: mse=194123.349016 step=0.050000
2017/08/29 23:13:36 step 4: mse=188025.050791 step=0.050000
2017/08/29 23:13:37 step 5: mse=184567.460354 step=0.050000
2017/08/29 23:13:38 step 6: mse=181815.769040 step=0.050000
2017/08/29 23:13:39 step 7: mse=178925.605821 step=0.050000
2017/08/29 23:13:39 Saving...
2017/08/29 23:13:39 Gathering batch of experience...
2017/08/29 23:14:01 batch 315: mean=1726.477273 stddev=2722.857076 entropy=0.489371 frames=4880 count=44
2017/08/29 23:14:01 Training policy...
2017/08/29 23:14:04 tune 0: objective=39.781228 reg=0.004894 prune=0
2017/08/29 23:14:05 step 0: objective=39.840996 reg=0.004894
2017/08/29 23:14:06 step 1: objective=40.077529 reg=0.004896
2017/08/29 23:14:07 step 2: objective=40.406778 reg=0.004892
2017/08/29 23:14:08 step 3: objective=40.535672 reg=0.004889
2017/08/29 23:14:09 step 4: objective=40.692761 reg=0.004889
2017/08/29 23:14:09 step 5: objective=40.752565 reg=0.004886
2017/08/29 23:14:10 step 6: objective=40.798550 reg=0.004886
2017/08/29 23:14:11 step 7: objective=40.857752 reg=0.004885
2017/08/29 23:14:11 Training value function...
2017/08/29 23:14:13 step 0: mse=195676.615166 step=0.050000
2017/08/29 23:14:14 step 1: mse=194331.679949 step=0.050000
2017/08/29 23:14:15 step 2: mse=193064.808706 step=0.050000
2017/08/29 23:14:15 step 3: mse=191973.163394 step=0.050000
2017/08/29 23:14:16 step 4: mse=189634.810348 step=0.050000
2017/08/29 23:14:17 step 5: mse=185314.428951 step=0.050000
2017/08/29 23:14:18 step 6: mse=184157.550961 step=0.050000
2017/08/29 23:14:18 step 7: mse=183186.458110 step=0.050000
2017/08/29 23:14:18 Saving...
2017/08/29 23:14:18 Gathering batch of experience...
2017/08/29 23:14:42 batch 316: mean=1655.952381 stddev=650.631779 entropy=0.483418 frames=5234 count=42
2017/08/29 23:14:42 Training policy...
2017/08/29 23:14:45 tune 0: objective=19.635577 reg=0.004834 prune=0
2017/08/29 23:14:46 step 0: objective=19.644930 reg=0.004834
2017/08/29 23:14:47 step 1: objective=19.671099 reg=0.004833
2017/08/29 23:14:48 step 2: objective=19.694489 reg=0.004833
2017/08/29 23:14:49 step 3: objective=19.717971 reg=0.004833
2017/08/29 23:14:50 step 4: objective=19.743088 reg=0.004833
2017/08/29 23:14:51 step 5: objective=19.768363 reg=0.004833
2017/08/29 23:14:52 step 6: objective=19.788725 reg=0.004832
2017/08/29 23:14:53 step 7: objective=19.811155 reg=0.004832
2017/08/29 23:14:53 Training value function...
2017/08/29 23:14:55 step 0: mse=16687.585129 step=0.050000
2017/08/29 23:14:56 step 1: mse=16443.424200 step=0.050000
2017/08/29 23:14:57 step 2: mse=16229.293299 step=0.050000
2017/08/29 23:14:57 step 3: mse=16036.671236 step=0.050000
2017/08/29 23:14:58 step 4: mse=15865.385034 step=0.050000
2017/08/29 23:14:59 step 5: mse=15720.102225 step=0.050000
2017/08/29 23:15:00 step 6: mse=15594.851322 step=0.050000
2017/08/29 23:15:01 step 7: mse=15468.445828 step=0.050000
2017/08/29 23:15:01 Saving...
2017/08/29 23:15:01 Gathering batch of experience...
2017/08/29 23:15:23 batch 317: mean=1382.555556 stddev=542.180395 entropy=0.480923 frames=4861 count=45
2017/08/29 23:15:23 Training policy...
2017/08/29 23:15:26 tune 0: objective=12.620772 reg=0.004809 prune=0
2017/08/29 23:15:27 step 0: objective=12.626037 reg=0.004808
2017/08/29 23:15:28 step 1: objective=12.638765 reg=0.004807
2017/08/29 23:15:29 step 2: objective=12.647392 reg=0.004807
2017/08/29 23:15:30 step 3: objective=12.659893 reg=0.004806
2017/08/29 23:15:31 step 4: objective=12.672607 reg=0.004805
2017/08/29 23:15:32 step 5: objective=12.680037 reg=0.004804
2017/08/29 23:15:32 step 6: objective=12.695952 reg=0.004804
2017/08/29 23:15:33 step 7: objective=12.708893 reg=0.004803
2017/08/29 23:15:33 Training value function...
2017/08/29 23:15:35 step 0: mse=11671.419977 step=0.050000
2017/08/29 23:15:36 step 1: mse=11683.878193 step=0.050000
2017/08/29 23:15:37 step 2: mse=11703.102095 step=0.050000
2017/08/29 23:15:37 step 3: mse=11729.230856 step=0.050000
2017/08/29 23:15:38 step 4: mse=11757.601890 step=0.050000
2017/08/29 23:15:39 step 5: mse=11783.020211 step=0.050000
2017/08/29 23:15:40 step 6: mse=11813.273694 step=0.050000
2017/08/29 23:15:40 step 7: mse=11844.567392 step=0.050000
2017/08/29 23:15:40 Saving...
2017/08/29 23:15:40 Gathering batch of experience...
2017/08/29 23:16:04 batch 318: mean=1599.523810 stddev=530.960282 entropy=0.479005 frames=5109 count=42
2017/08/29 23:16:04 Training policy...
2017/08/29 23:16:07 tune 0: objective=23.029369 reg=0.004790 prune=0
2017/08/29 23:16:08 step 0: objective=23.041833 reg=0.004789
2017/08/29 23:16:09 step 1: objective=23.059740 reg=0.004789
2017/08/29 23:16:10 step 2: objective=23.076756 reg=0.004788
2017/08/29 23:16:11 step 3: objective=23.096519 reg=0.004787
2017/08/29 23:16:12 step 4: objective=23.119669 reg=0.004786
2017/08/29 23:16:12 step 5: objective=23.137837 reg=0.004785
2017/08/29 23:16:13 step 6: objective=23.158093 reg=0.004784
2017/08/29 23:16:14 step 7: objective=23.175632 reg=0.004784
2017/08/29 23:16:14 Training value function...
2017/08/29 23:16:16 step 0: mse=16024.583290 step=0.050000
2017/08/29 23:16:17 step 1: mse=15868.029244 step=0.050000
2017/08/29 23:16:18 step 2: mse=15711.259637 step=0.050000
2017/08/29 23:16:19 step 3: mse=15570.536401 step=0.050000
2017/08/29 23:16:20 step 4: mse=15447.536899 step=0.050000
2017/08/29 23:16:20 step 5: mse=15328.677989 step=0.050000
2017/08/29 23:16:21 step 6: mse=15222.459334 step=0.050000
2017/08/29 23:16:22 step 7: mse=15126.941449 step=0.050000
2017/08/29 23:16:22 Saving...
2017/08/29 23:16:22 Gathering batch of experience...
2017/08/29 23:16:45 batch 319: mean=1331.326531 stddev=691.125801 entropy=0.482734 frames=5053 count=49
2017/08/29 23:16:45 Training policy...
2017/08/29 23:16:49 tune 0: objective=13.968294 reg=0.004827 prune=0
2017/08/29 23:16:49 step 0: objective=13.976029 reg=0.004826
2017/08/29 23:16:50 step 1: objective=13.997880 reg=0.004825
2017/08/29 23:16:51 step 2: objective=14.022354 reg=0.004824
2017/08/29 23:16:52 step 3: objective=14.046219 reg=0.004824
2017/08/29 23:16:53 step 4: objective=14.067534 reg=0.004823
2017/08/29 23:16:54 step 5: objective=14.091650 reg=0.004822
2017/08/29 23:16:55 step 6: objective=14.110031 reg=0.004821
2017/08/29 23:16:56 step 7: objective=14.125617 reg=0.004820
2017/08/29 23:16:56 Training value function...
2017/08/29 23:16:58 step 0: mse=15280.308667 step=0.050000
2017/08/29 23:16:59 step 1: mse=15266.545495 step=0.050000
2017/08/29 23:16:59 step 2: mse=15268.494644 step=0.050000
2017/08/29 23:17:00 step 3: mse=15268.116919 step=0.050000
2017/08/29 23:17:01 step 4: mse=15260.467515 step=0.050000
2017/08/29 23:17:02 step 5: mse=15271.274556 step=0.050000
2017/08/29 23:17:02 step 6: mse=15271.567153 step=0.050000
2017/08/29 23:17:03 step 7: mse=15283.181588 step=0.050000
2017/08/29 23:17:03 Saving...
2017/08/29 23:17:03 Gathering batch of experience...
2017/08/29 23:17:27 batch 320: mean=1430.111111 stddev=566.045237 entropy=0.480269 frames=4982 count=45
2017/08/29 23:17:27 Training policy...
2017/08/29 23:17:30 tune 0: objective=23.709313 reg=0.004803 prune=0
2017/08/29 23:17:31 step 0: objective=23.712749 reg=0.004802
2017/08/29 23:17:32 step 1: objective=23.720591 reg=0.004802
2017/08/29 23:17:32 step 2: objective=23.729837 reg=0.004802
2017/08/29 23:17:33 step 3: objective=23.735148 reg=0.004802
2017/08/29 23:17:34 step 4: objective=23.741392 reg=0.004801
2017/08/29 23:17:35 step 5: objective=23.752663 reg=0.004801
2017/08/29 23:17:36 step 6: objective=23.761256 reg=0.004800
2017/08/29 23:17:37 step 7: objective=23.767544 reg=0.004800
2017/08/29 23:17:37 Training value function...
2017/08/29 23:17:39 step 0: mse=13981.545809 step=0.050000
2017/08/29 23:17:40 step 1: mse=13959.096881 step=0.050000
2017/08/29 23:17:40 step 2: mse=13940.136996 step=0.050000
2017/08/29 23:17:41 step 3: mse=13919.342645 step=0.050000
2017/08/29 23:17:42 step 4: mse=13900.592057 step=0.050000
2017/08/29 23:17:43 step 5: mse=13879.991820 step=0.050000
2017/08/29 23:17:43 step 6: mse=13861.100370 step=0.050000
2017/08/29 23:17:44 step 7: mse=13847.387895 step=0.050000
2017/08/29 23:17:44 Saving...
2017/08/29 23:17:44 Gathering batch of experience...
2017/08/29 23:18:08 batch 321: mean=1377.065217 stddev=518.331957 entropy=0.476283 frames=4968 count=46
2017/08/29 23:18:08 Training policy...
2017/08/29 23:18:11 tune 0: objective=19.424055 reg=0.004763 prune=0
2017/08/29 23:18:11 step 0: objective=19.428255 reg=0.004762
2017/08/29 23:18:12 step 1: objective=19.436162 reg=0.004761
2017/08/29 23:18:13 step 2: objective=19.446857 reg=0.004760
2017/08/29 23:18:14 step 3: objective=19.455805 reg=0.004760
2017/08/29 23:18:15 step 4: objective=19.467767 reg=0.004759
2017/08/29 23:18:16 step 5: objective=19.478898 reg=0.004758
2017/08/29 23:18:17 step 6: objective=19.491799 reg=0.004757
2017/08/29 23:18:18 step 7: objective=19.500401 reg=0.004756
2017/08/29 23:18:18 Training value function...
2017/08/29 23:18:20 step 0: mse=12104.191280 step=0.050000
2017/08/29 23:18:20 step 1: mse=12084.182892 step=0.050000
2017/08/29 23:18:21 step 2: mse=12087.180265 step=0.050000
2017/08/29 23:18:22 step 3: mse=12074.448710 step=0.050000
2017/08/29 23:18:23 step 4: mse=12060.991385 step=0.050000
2017/08/29 23:18:24 step 5: mse=12066.125697 step=0.050000
2017/08/29 23:18:24 step 6: mse=12058.778168 step=0.050000
2017/08/29 23:18:25 step 7: mse=12052.318518 step=0.050000
2017/08/29 23:18:25 Saving...
2017/08/29 23:18:25 Gathering batch of experience...
2017/08/29 23:18:47 batch 322: mean=1222.340426 stddev=687.215977 entropy=0.487690 frames=4612 count=47
2017/08/29 23:18:47 Training policy...
2017/08/29 23:18:50 tune 0: objective=16.212316 reg=0.004877 prune=0
2017/08/29 23:18:51 step 0: objective=16.219421 reg=0.004876
2017/08/29 23:18:52 step 1: objective=16.228633 reg=0.004876
2017/08/29 23:18:53 step 2: objective=16.238280 reg=0.004875
2017/08/29 23:18:53 step 3: objective=16.248901 reg=0.004875
2017/08/29 23:18:54 step 4: objective=16.257797 reg=0.004875
2017/08/29 23:18:55 step 5: objective=16.266892 reg=0.004874
2017/08/29 23:18:56 step 6: objective=16.278445 reg=0.004873
2017/08/29 23:18:57 step 7: objective=16.288061 reg=0.004873
2017/08/29 23:18:57 Training value function...
2017/08/29 23:18:58 step 0: mse=15875.364288 step=0.050000
2017/08/29 23:18:59 step 1: mse=15832.382192 step=0.050000
2017/08/29 23:19:00 step 2: mse=15797.800965 step=0.050000
2017/08/29 23:19:01 step 3: mse=15767.778013 step=0.050000
2017/08/29 23:19:01 step 4: mse=15748.286606 step=0.050000
2017/08/29 23:19:02 step 5: mse=15729.910223 step=0.050000
2017/08/29 23:19:03 step 6: mse=15707.132501 step=0.050000
2017/08/29 23:19:04 step 7: mse=15700.940213 step=0.050000
2017/08/29 23:19:04 Saving...
2017/08/29 23:19:04 Gathering batch of experience...
2017/08/29 23:19:27 batch 323: mean=1338.854167 stddev=615.193262 entropy=0.480095 frames=4959 count=48
2017/08/29 23:19:27 Training policy...
2017/08/29 23:19:30 tune 0: objective=25.466409 reg=0.004801 prune=0
2017/08/29 23:19:31 step 0: objective=25.473894 reg=0.004800
2017/08/29 23:19:32 step 1: objective=25.490833 reg=0.004799
2017/08/29 23:19:33 step 2: objective=25.502034 reg=0.004798
2017/08/29 23:19:34 step 3: objective=25.516696 reg=0.004798
2017/08/29 23:19:35 step 4: objective=25.531839 reg=0.004797
2017/08/29 23:19:36 step 5: objective=25.548239 reg=0.004797
2017/08/29 23:19:37 step 6: objective=25.566038 reg=0.004796
2017/08/29 23:19:37 step 7: objective=25.581744 reg=0.004795
2017/08/29 23:19:37 Training value function...
2017/08/29 23:19:39 step 0: mse=16099.205090 step=0.050000
2017/08/29 23:19:40 step 1: mse=16033.183503 step=0.050000
2017/08/29 23:19:41 step 2: mse=15975.616023 step=0.050000
2017/08/29 23:19:42 step 3: mse=15920.448976 step=0.050000
2017/08/29 23:19:43 step 4: mse=15873.869382 step=0.050000
2017/08/29 23:19:43 step 5: mse=15824.218096 step=0.050000
2017/08/29 23:19:44 step 6: mse=15784.439327 step=0.050000
2017/08/29 23:19:45 step 7: mse=15750.062865 step=0.050000
2017/08/29 23:19:45 Saving...
2017/08/29 23:19:45 Gathering batch of experience...
2017/08/29 23:20:08 batch 324: mean=1580.731707 stddev=537.136219 entropy=0.480444 frames=4963 count=41
2017/08/29 23:20:08 Training policy...
2017/08/29 23:20:11 tune 0: objective=33.639325 reg=0.004804 prune=0
2017/08/29 23:20:12 step 0: objective=33.643679 reg=0.004804
2017/08/29 23:20:13 step 1: objective=33.653681 reg=0.004804
2017/08/29 23:20:13 step 2: objective=33.669319 reg=0.004803
2017/08/29 23:20:14 step 3: objective=33.676440 reg=0.004802
2017/08/29 23:20:15 step 4: objective=33.685085 reg=0.004802
2017/08/29 23:20:16 step 5: objective=33.693233 reg=0.004802
2017/08/29 23:20:17 step 6: objective=33.704173 reg=0.004802
2017/08/29 23:20:18 step 7: objective=33.713439 reg=0.004801
2017/08/29 23:20:18 Training value function...
2017/08/29 23:20:20 step 0: mse=15003.375410 step=0.050000
2017/08/29 23:20:21 step 1: mse=14766.471935 step=0.050000
2017/08/29 23:20:21 step 2: mse=14549.312252 step=0.050000
2017/08/29 23:20:22 step 3: mse=14346.033385 step=0.050000
2017/08/29 23:20:23 step 4: mse=14157.622353 step=0.050000
2017/08/29 23:20:24 step 5: mse=13979.757384 step=0.050000
2017/08/29 23:20:25 step 6: mse=13817.459667 step=0.050000
2017/08/29 23:20:25 step 7: mse=13665.652685 step=0.050000
2017/08/29 23:20:25 Saving...
2017/08/29 23:20:25 Gathering batch of experience...
2017/08/29 23:20:48 batch 325: mean=1277.040816 stddev=633.882528 entropy=0.482550 frames=4984 count=49
2017/08/29 23:20:48 Training policy...
2017/08/29 23:20:52 tune 0: objective=15.666030 reg=0.004826 prune=0
2017/08/29 23:20:52 step 0: objective=15.672319 reg=0.004825
2017/08/29 23:20:53 step 1: objective=15.689771 reg=0.004824
2017/08/29 23:20:54 step 2: objective=15.701716 reg=0.004824
2017/08/29 23:20:55 step 3: objective=15.712828 reg=0.004823
2017/08/29 23:20:56 step 4: objective=15.730922 reg=0.004822
2017/08/29 23:20:57 step 5: objective=15.744407 reg=0.004822
2017/08/29 23:20:58 step 6: objective=15.759004 reg=0.004822
2017/08/29 23:20:59 step 7: objective=15.772665 reg=0.004821
2017/08/29 23:20:59 Training value function...
2017/08/29 23:21:01 step 0: mse=15272.948004 step=0.050000
2017/08/29 23:21:01 step 1: mse=15310.772963 step=0.050000
2017/08/29 23:21:02 step 2: mse=15349.778171 step=0.050000
2017/08/29 23:21:03 step 3: mse=15391.213323 step=0.050000
2017/08/29 23:21:04 step 4: mse=15436.888694 step=0.050000
2017/08/29 23:21:04 step 5: mse=15471.666656 step=0.050000
2017/08/29 23:21:05 step 6: mse=15511.413973 step=0.050000
2017/08/29 23:21:06 step 7: mse=15545.212061 step=0.050000
2017/08/29 23:21:06 Saving...
2017/08/29 23:21:06 Gathering batch of experience...
2017/08/29 23:21:32 batch 326: mean=1925.348837 stddev=2774.789201 entropy=0.482142 frames=5289 count=43
2017/08/29 23:21:32 Training policy...
2017/08/29 23:21:36 tune 0: objective=60.381210 reg=0.004821 prune=0
2017/08/29 23:21:36 step 0: objective=60.447621 reg=0.004821
2017/08/29 23:21:37 step 1: objective=60.552840 reg=0.004820
2017/08/29 23:21:38 step 2: objective=60.663712 reg=0.004819
2017/08/29 23:21:39 step 3: objective=60.758815 reg=0.004819
2017/08/29 23:21:40 step 4: objective=60.825280 reg=0.004818
2017/08/29 23:21:41 step 5: objective=60.901464 reg=0.004817
2017/08/29 23:21:42 step 6: objective=61.032839 reg=0.004815
2017/08/29 23:21:43 step 7: objective=61.114199 reg=0.004816
2017/08/29 23:21:43 Training value function...
2017/08/29 23:21:45 step 0: mse=234935.891899 step=0.050000
2017/08/29 23:21:46 step 1: mse=230979.383719 step=0.050000
2017/08/29 23:21:47 step 2: mse=227082.391898 step=0.050000
2017/08/29 23:21:48 step 3: mse=223087.065025 step=0.050000
2017/08/29 23:21:49 step 4: mse=219518.989978 step=0.050000
2017/08/29 23:21:49 step 5: mse=215267.573019 step=0.050000
2017/08/29 23:21:50 step 6: mse=212723.374458 step=0.050000
2017/08/29 23:21:51 step 7: mse=210003.988448 step=0.050000
2017/08/29 23:21:51 Saving...
2017/08/29 23:21:51 Gathering batch of experience...
2017/08/29 23:22:15 batch 327: mean=1379.583333 stddev=586.361337 entropy=0.476382 frames=5147 count=48
2017/08/29 23:22:15 Training policy...
2017/08/29 23:22:18 tune 0: objective=15.876563 reg=0.004764 prune=0
2017/08/29 23:22:19 step 0: objective=15.881323 reg=0.004763
2017/08/29 23:22:20 step 1: objective=15.891153 reg=0.004763
2017/08/29 23:22:21 step 2: objective=15.900494 reg=0.004762
2017/08/29 23:22:22 step 3: objective=15.914415 reg=0.004763
2017/08/29 23:22:23 step 4: objective=15.924974 reg=0.004762
2017/08/29 23:22:24 step 5: objective=15.933490 reg=0.004762
2017/08/29 23:22:25 step 6: objective=15.943326 reg=0.004762
2017/08/29 23:22:26 step 7: objective=15.953383 reg=0.004761
2017/08/29 23:22:26 Training value function...
2017/08/29 23:22:28 step 0: mse=13823.484536 step=0.050000
2017/08/29 23:22:28 step 1: mse=13829.437746 step=0.050000
2017/08/29 23:22:29 step 2: mse=13840.077557 step=0.050000
2017/08/29 23:22:30 step 3: mse=13849.423699 step=0.050000
2017/08/29 23:22:31 step 4: mse=13864.958550 step=0.050000
2017/08/29 23:22:32 step 5: mse=13878.794546 step=0.050000
2017/08/29 23:22:32 step 6: mse=13895.157277 step=0.050000
2017/08/29 23:22:33 step 7: mse=13914.421455 step=0.050000
2017/08/29 23:22:33 Saving...
2017/08/29 23:22:33 Gathering batch of experience...
2017/08/29 23:22:57 batch 328: mean=1570.813953 stddev=700.243255 entropy=0.481055 frames=5141 count=43
2017/08/29 23:22:57 Training policy...
2017/08/29 23:23:00 tune 0: objective=25.985986 reg=0.004811 prune=0
2017/08/29 23:23:01 step 0: objective=25.993703 reg=0.004810
2017/08/29 23:23:02 step 1: objective=26.015239 reg=0.004810
2017/08/29 23:23:03 step 2: objective=26.034399 reg=0.004809
2017/08/29 23:23:04 step 3: objective=26.049334 reg=0.004809
2017/08/29 23:23:04 step 4: objective=26.072065 reg=0.004808
2017/08/29 23:23:05 step 5: objective=26.094358 reg=0.004807
2017/08/29 23:23:06 step 6: objective=26.108329 reg=0.004807
2017/08/29 23:23:07 step 7: objective=26.120471 reg=0.004807
2017/08/29 23:23:07 Training value function...
2017/08/29 23:23:09 step 0: mse=17721.975946 step=0.050000
2017/08/29 23:23:10 step 1: mse=17622.573049 step=0.050000
2017/08/29 23:23:11 step 2: mse=17521.214878 step=0.050000
2017/08/29 23:23:12 step 3: mse=17424.958227 step=0.050000
2017/08/29 23:23:12 step 4: mse=17337.439086 step=0.050000
2017/08/29 23:23:13 step 5: mse=17259.898733 step=0.050000
2017/08/29 23:23:14 step 6: mse=17181.676049 step=0.050000
2017/08/29 23:23:15 step 7: mse=17107.528172 step=0.050000
2017/08/29 23:23:15 Saving...
2017/08/29 23:23:15 Gathering batch of experience...
2017/08/29 23:23:38 batch 329: mean=1403.404255 stddev=558.370641 entropy=0.474695 frames=5088 count=47
2017/08/29 23:23:38 Training policy...
2017/08/29 23:23:42 tune 0: objective=20.340889 reg=0.004747 prune=0
2017/08/29 23:23:43 step 0: objective=20.344292 reg=0.004747
2017/08/29 23:23:43 step 1: objective=20.357549 reg=0.004747
2017/08/29 23:23:44 step 2: objective=20.366438 reg=0.004747
2017/08/29 23:23:45 step 3: objective=20.378470 reg=0.004748
2017/08/29 23:23:46 step 4: objective=20.385710 reg=0.004748
2017/08/29 23:23:47 step 5: objective=20.393237 reg=0.004748
2017/08/29 23:23:48 step 6: objective=20.400274 reg=0.004747
2017/08/29 23:23:49 step 7: objective=20.409011 reg=0.004748
2017/08/29 23:23:49 Training value function...
2017/08/29 23:23:51 step 0: mse=11722.156002 step=0.050000
2017/08/29 23:23:52 step 1: mse=11708.672257 step=0.050000
2017/08/29 23:23:53 step 2: mse=11692.807590 step=0.050000
2017/08/29 23:23:53 step 3: mse=11684.888601 step=0.050000
2017/08/29 23:23:54 step 4: mse=11679.206355 step=0.050000
2017/08/29 23:23:55 step 5: mse=11674.923682 step=0.050000
2017/08/29 23:23:56 step 6: mse=11672.182384 step=0.050000
2017/08/29 23:23:57 step 7: mse=11668.399400 step=0.050000
2017/08/29 23:23:57 Saving...
2017/08/29 23:23:57 Gathering batch of experience...
2017/08/29 23:24:21 batch 330: mean=1528.888889 stddev=692.972574 entropy=0.475012 frames=5161 count=45
2017/08/29 23:24:21 Training policy...
2017/08/29 23:24:24 tune 0: objective=27.434179 reg=0.004750 prune=0
2017/08/29 23:24:25 step 0: objective=27.439017 reg=0.004750
2017/08/29 23:24:26 step 1: objective=27.447209 reg=0.004749
2017/08/29 23:24:27 step 2: objective=27.456204 reg=0.004749
2017/08/29 23:24:27 step 3: objective=27.468532 reg=0.004749
2017/08/29 23:24:28 step 4: objective=27.476552 reg=0.004749
2017/08/29 23:24:29 step 5: objective=27.485314 reg=0.004748
2017/08/29 23:24:30 step 6: objective=27.494714 reg=0.004748
2017/08/29 23:24:31 step 7: objective=27.503612 reg=0.004748
2017/08/29 23:24:31 Training value function...
2017/08/29 23:24:33 step 0: mse=16107.572970 step=0.050000
2017/08/29 23:24:34 step 1: mse=16002.581621 step=0.050000
2017/08/29 23:24:35 step 2: mse=15900.043503 step=0.050000
2017/08/29 23:24:36 step 3: mse=15806.855278 step=0.050000
2017/08/29 23:24:37 step 4: mse=15706.597332 step=0.050000
2017/08/29 23:24:37 step 5: mse=15626.062044 step=0.050000
2017/08/29 23:24:38 step 6: mse=15543.583960 step=0.050000
2017/08/29 23:24:39 step 7: mse=15467.884077 step=0.050000
2017/08/29 23:24:39 Saving...
2017/08/29 23:24:39 Gathering batch of experience...
2017/08/29 23:25:02 batch 331: mean=1355.957447 stddev=621.901373 entropy=0.476405 frames=4931 count=47
2017/08/29 23:25:02 Training policy...
2017/08/29 23:25:05 tune 0: objective=18.537294 reg=0.004764 prune=0
2017/08/29 23:25:06 step 0: objective=18.543530 reg=0.004763
2017/08/29 23:25:07 step 1: objective=18.556086 reg=0.004762
2017/08/29 23:25:08 step 2: objective=18.568036 reg=0.004761
2017/08/29 23:25:09 step 3: objective=18.577399 reg=0.004760
2017/08/29 23:25:10 step 4: objective=18.588968 reg=0.004759
2017/08/29 23:25:11 step 5: objective=18.602199 reg=0.004758
2017/08/29 23:25:11 step 6: objective=18.611983 reg=0.004757
2017/08/29 23:25:12 step 7: objective=18.625003 reg=0.004756
2017/08/29 23:25:12 Training value function...
2017/08/29 23:25:14 step 0: mse=14412.513745 step=0.050000
2017/08/29 23:25:15 step 1: mse=14446.248430 step=0.050000
2017/08/29 23:25:16 step 2: mse=14478.860000 step=0.050000
2017/08/29 23:25:17 step 3: mse=14508.205146 step=0.050000
2017/08/29 23:25:17 step 4: mse=14535.663138 step=0.050000
2017/08/29 23:25:18 step 5: mse=14566.887971 step=0.050000
2017/08/29 23:25:19 step 6: mse=14594.933673 step=0.050000
2017/08/29 23:25:20 step 7: mse=14619.986999 step=0.050000
2017/08/29 23:25:20 Saving...
2017/08/29 23:25:20 Gathering batch of experience...
2017/08/29 23:25:44 batch 332: mean=1922.325581 stddev=2739.090485 entropy=0.479755 frames=5319 count=43
2017/08/29 23:25:44 Training policy...
2017/08/29 23:25:47 tune 0: objective=56.367956 reg=0.004798 prune=0
2017/08/29 23:25:48 step 0: objective=56.414939 reg=0.004796
2017/08/29 23:25:49 step 1: objective=56.578310 reg=0.004795
2017/08/29 23:25:50 step 2: objective=56.807759 reg=0.004794
2017/08/29 23:25:51 step 3: objective=56.922783 reg=0.004793
2017/08/29 23:25:52 step 4: objective=56.986546 reg=0.004793
2017/08/29 23:25:53 step 5: objective=57.100900 reg=0.004791
2017/08/29 23:25:54 step 6: objective=57.165016 reg=0.004791
2017/08/29 23:25:55 step 7: objective=57.217828 reg=0.004789
2017/08/29 23:25:55 Training value function...
2017/08/29 23:25:57 step 0: mse=226717.689785 step=0.050000
2017/08/29 23:25:58 step 1: mse=221496.306791 step=0.050000
2017/08/29 23:25:58 step 2: mse=218268.359793 step=0.050000
2017/08/29 23:25:59 step 3: mse=215286.033367 step=0.050000
2017/08/29 23:26:00 step 4: mse=211890.806114 step=0.050000
2017/08/29 23:26:01 step 5: mse=209380.775337 step=0.050000
2017/08/29 23:26:02 step 6: mse=207305.978832 step=0.050000
2017/08/29 23:26:03 step 7: mse=205474.447904 step=0.050000
2017/08/29 23:26:03 Saving...
2017/08/29 23:26:03 Gathering batch of experience...
2017/08/29 23:26:27 batch 333: mean=1808.555556 stddev=2735.427982 entropy=0.481064 frames=5274 count=45
2017/08/29 23:26:27 Training policy...
2017/08/29 23:26:30 tune 0: objective=38.778154 reg=0.004811 prune=0
2017/08/29 23:26:31 step 0: objective=38.814989 reg=0.004809
2017/08/29 23:26:32 step 1: objective=38.921611 reg=0.004808
2017/08/29 23:26:33 step 2: objective=39.041646 reg=0.004806
2017/08/29 23:26:34 step 3: objective=39.115419 reg=0.004805
2017/08/29 23:26:35 step 4: objective=39.201309 reg=0.004804
2017/08/29 23:26:36 step 5: objective=39.289688 reg=0.004802
2017/08/29 23:26:37 step 6: objective=39.384054 reg=0.004802
2017/08/29 23:26:38 step 7: objective=39.433527 reg=0.004801
2017/08/29 23:26:38 Training value function...
2017/08/29 23:26:40 step 0: mse=187657.055982 step=0.050000
2017/08/29 23:26:41 step 1: mse=185050.773419 step=0.050000
2017/08/29 23:26:42 step 2: mse=182013.947482 step=0.050000
2017/08/29 23:26:42 step 3: mse=180838.821380 step=0.050000
2017/08/29 23:26:43 step 4: mse=176839.572755 step=0.050000
2017/08/29 23:26:44 step 5: mse=175878.484080 step=0.050000
2017/08/29 23:26:45 step 6: mse=174959.564844 step=0.050000
2017/08/29 23:26:46 step 7: mse=174031.362286 step=0.050000
2017/08/29 23:26:46 Saving...
2017/08/29 23:26:46 Gathering batch of experience...
2017/08/29 23:27:13 batch 334: mean=1967.500000 stddev=3073.420901 entropy=0.487026 frames=5499 count=46
2017/08/29 23:27:13 Training policy...
2017/08/29 23:27:17 tune 0: objective=44.364069 reg=0.004870 prune=0
2017/08/29 23:27:18 step 0: objective=44.438128 reg=0.004869
2017/08/29 23:27:19 step 1: objective=44.677993 reg=0.004870
2017/08/29 23:27:19 step 2: objective=44.835544 reg=0.004867
2017/08/29 23:27:20 step 3: objective=44.942055 reg=0.004866
2017/08/29 23:27:21 step 4: objective=45.043374 reg=0.004865
2017/08/29 23:27:22 step 5: objective=45.115919 reg=0.004865
2017/08/29 23:27:23 step 6: objective=45.182348 reg=0.004865
2017/08/29 23:27:24 step 7: objective=45.241368 reg=0.004864
2017/08/29 23:27:24 Training value function...
2017/08/29 23:27:27 step 0: mse=195652.893475 step=0.050000
2017/08/29 23:27:28 step 1: mse=193951.916852 step=0.050000
2017/08/29 23:27:28 step 2: mse=192294.747148 step=0.050000
2017/08/29 23:27:29 step 3: mse=190549.228006 step=0.050000
2017/08/29 23:27:30 step 4: mse=187166.102282 step=0.050000
2017/08/29 23:27:31 step 5: mse=183695.078809 step=0.050000
2017/08/29 23:27:32 step 6: mse=182592.974975 step=0.050000
2017/08/29 23:27:33 step 7: mse=181633.792125 step=0.050000
2017/08/29 23:27:33 Saving...
2017/08/29 23:27:33 Gathering batch of experience...
2017/08/29 23:27:55 batch 335: mean=1384.456522 stddev=608.066455 entropy=0.473243 frames=4914 count=46
2017/08/29 23:27:55 Training policy...
2017/08/29 23:27:59 tune 0: objective=11.207536 reg=0.004732 prune=0
2017/08/29 23:27:59 step 0: objective=11.212541 reg=0.004732
2017/08/29 23:28:00 step 1: objective=11.229253 reg=0.004731
2017/08/29 23:28:01 step 2: objective=11.249736 reg=0.004731
2017/08/29 23:28:02 step 3: objective=11.266080 reg=0.004731
2017/08/29 23:28:03 step 4: objective=11.282822 reg=0.004730
2017/08/29 23:28:04 step 5: objective=11.293491 reg=0.004730
2017/08/29 23:28:05 step 6: objective=11.306858 reg=0.004730
2017/08/29 23:28:06 step 7: objective=11.316749 reg=0.004729
2017/08/29 23:28:06 Training value function...
2017/08/29 23:28:08 step 0: mse=12618.546154 step=0.050000
2017/08/29 23:28:08 step 1: mse=12532.613362 step=0.050000
2017/08/29 23:28:09 step 2: mse=12465.072684 step=0.050000
2017/08/29 23:28:10 step 3: mse=12406.161288 step=0.050000
2017/08/29 23:28:11 step 4: mse=12366.100445 step=0.050000
2017/08/29 23:28:11 step 5: mse=12334.453134 step=0.050000
2017/08/29 23:28:12 step 6: mse=12309.680145 step=0.050000
2017/08/29 23:28:13 step 7: mse=12292.156101 step=0.050000
2017/08/29 23:28:13 Saving...
2017/08/29 23:28:13 Gathering batch of experience...
2017/08/29 23:28:37 batch 336: mean=1452.021277 stddev=879.552993 entropy=0.480984 frames=5136 count=47
2017/08/29 23:28:37 Training policy...
2017/08/29 23:28:40 tune 0: objective=17.784403 reg=0.004810 prune=0
2017/08/29 23:28:41 step 0: objective=17.797245 reg=0.004809
2017/08/29 23:28:42 step 1: objective=17.823388 reg=0.004809
2017/08/29 23:28:43 step 2: objective=17.841033 reg=0.004809
2017/08/29 23:28:44 step 3: objective=17.870913 reg=0.004809
2017/08/29 23:28:44 step 4: objective=17.894119 reg=0.004809
2017/08/29 23:28:45 step 5: objective=17.923004 reg=0.004808
2017/08/29 23:28:46 step 6: objective=17.942600 reg=0.004808
2017/08/29 23:28:47 step 7: objective=17.959848 reg=0.004807
2017/08/29 23:28:47 Training value function...
2017/08/29 23:28:49 step 0: mse=18646.170599 step=0.050000
2017/08/29 23:28:50 step 1: mse=18578.500744 step=0.050000
2017/08/29 23:28:51 step 2: mse=18500.266237 step=0.050000
2017/08/29 23:28:52 step 3: mse=18452.697830 step=0.050000
2017/08/29 23:28:53 step 4: mse=18399.985443 step=0.050000
2017/08/29 23:28:53 step 5: mse=18356.312237 step=0.050000
2017/08/29 23:28:54 step 6: mse=18319.361224 step=0.050000
2017/08/29 23:28:55 step 7: mse=18278.074510 step=0.050000
2017/08/29 23:28:55 Saving...
2017/08/29 23:28:55 Gathering batch of experience...
2017/08/29 23:29:17 batch 337: mean=1296.489362 stddev=607.239056 entropy=0.472167 frames=4781 count=47
2017/08/29 23:29:17 Training policy...
2017/08/29 23:29:20 tune 0: objective=12.543810 reg=0.004722 prune=0
2017/08/29 23:29:21 step 0: objective=12.549391 reg=0.004721
2017/08/29 23:29:22 step 1: objective=12.563302 reg=0.004721
2017/08/29 23:29:23 step 2: objective=12.573901 reg=0.004720
2017/08/29 23:29:24 step 3: objective=12.585116 reg=0.004721
2017/08/29 23:29:25 step 4: objective=12.596698 reg=0.004721
2017/08/29 23:29:26 step 5: objective=12.606231 reg=0.004721
2017/08/29 23:29:26 step 6: objective=12.616793 reg=0.004721
2017/08/29 23:29:27 step 7: objective=12.625881 reg=0.004722
2017/08/29 23:29:27 Training value function...
2017/08/29 23:29:29 step 0: mse=13395.365576 step=0.050000
2017/08/29 23:29:30 step 1: mse=13401.662767 step=0.050000
2017/08/29 23:29:31 step 2: mse=13405.062843 step=0.050000
2017/08/29 23:29:31 step 3: mse=13419.177398 step=0.050000
2017/08/29 23:29:32 step 4: mse=13438.658659 step=0.050000
2017/08/29 23:29:33 step 5: mse=13463.390241 step=0.050000
2017/08/29 23:29:34 step 6: mse=13492.287947 step=0.050000
2017/08/29 23:29:34 step 7: mse=13520.645086 step=0.050000
2017/08/29 23:29:34 Saving...
2017/08/29 23:29:34 Gathering batch of experience...
2017/08/29 23:29:57 batch 338: mean=1517.380952 stddev=800.842739 entropy=0.475724 frames=4779 count=42
2017/08/29 23:29:57 Training policy...
2017/08/29 23:30:00 tune 0: objective=26.339755 reg=0.004757 prune=0
2017/08/29 23:30:00 step 0: objective=26.349110 reg=0.004757
2017/08/29 23:30:01 step 1: objective=26.363598 reg=0.004756
2017/08/29 23:30:02 step 2: objective=26.381832 reg=0.004754
2017/08/29 23:30:03 step 3: objective=26.399886 reg=0.004754
2017/08/29 23:30:04 step 4: objective=26.413330 reg=0.004754
2017/08/29 23:30:05 step 5: objective=26.425914 reg=0.004753
2017/08/29 23:30:06 step 6: objective=26.440595 reg=0.004752
2017/08/29 23:30:06 step 7: objective=26.452646 reg=0.004752
2017/08/29 23:30:06 Training value function...
2017/08/29 23:30:08 step 0: mse=17163.119946 step=0.050000
2017/08/29 23:30:09 step 1: mse=17121.411914 step=0.050000
2017/08/29 23:30:10 step 2: mse=17084.283910 step=0.050000
2017/08/29 23:30:11 step 3: mse=17048.203433 step=0.050000
2017/08/29 23:30:11 step 4: mse=17016.282574 step=0.050000
2017/08/29 23:30:12 step 5: mse=16985.960182 step=0.050000
2017/08/29 23:30:13 step 6: mse=16953.137331 step=0.050000
2017/08/29 23:30:14 step 7: mse=16926.459363 step=0.050000
2017/08/29 23:30:14 Saving...
2017/08/29 23:30:14 Gathering batch of experience...
2017/08/29 23:30:38 batch 339: mean=2151.704545 stddev=3809.749297 entropy=0.481180 frames=5317 count=44
2017/08/29 23:30:38 Training policy...
2017/08/29 23:30:42 tune 0: objective=70.201218 reg=0.004812 prune=0
2017/08/29 23:30:43 step 0: objective=70.292599 reg=0.004810
2017/08/29 23:30:44 step 1: objective=70.466669 reg=0.004809
2017/08/29 23:30:45 step 2: objective=70.625717 reg=0.004808
2017/08/29 23:30:46 step 3: objective=70.833512 reg=0.004807
2017/08/29 23:30:47 step 4: objective=70.962185 reg=0.004804
2017/08/29 23:30:48 step 5: objective=71.150367 reg=0.004801
2017/08/29 23:30:48 step 6: objective=71.254855 reg=0.004797
2017/08/29 23:30:49 step 7: objective=71.324901 reg=0.004797
2017/08/29 23:30:49 Training value function...
2017/08/29 23:30:52 step 0: mse=374973.535567 step=0.050000
2017/08/29 23:30:52 step 1: mse=365087.252587 step=0.050000
2017/08/29 23:30:53 step 2: mse=357155.240866 step=0.050000
2017/08/29 23:30:54 step 3: mse=347428.932340 step=0.050000
2017/08/29 23:30:55 step 4: mse=335401.228288 step=0.050000
2017/08/29 23:30:56 step 5: mse=324486.594399 step=0.050000
2017/08/29 23:30:57 step 6: mse=318535.666831 step=0.050000
2017/08/29 23:30:57 step 7: mse=313603.041258 step=0.050000
2017/08/29 23:30:57 Saving...
2017/08/29 23:30:57 Gathering batch of experience...
2017/08/29 23:31:20 batch 340: mean=1505.238095 stddev=517.325945 entropy=0.470569 frames=4877 count=42
2017/08/29 23:31:20 Training policy...
2017/08/29 23:31:23 tune 0: objective=19.204842 reg=0.004706 prune=0
2017/08/29 23:31:24 step 0: objective=19.212048 reg=0.004705
2017/08/29 23:31:25 step 1: objective=19.228185 reg=0.004704
2017/08/29 23:31:26 step 2: objective=19.243884 reg=0.004703
2017/08/29 23:31:26 step 3: objective=19.263520 reg=0.004702
2017/08/29 23:31:27 step 4: objective=19.279682 reg=0.004701
2017/08/29 23:31:28 step 5: objective=19.293468 reg=0.004700
2017/08/29 23:31:29 step 6: objective=19.305785 reg=0.004699
2017/08/29 23:31:30 step 7: objective=19.317807 reg=0.004699
2017/08/29 23:31:30 Training value function...
2017/08/29 23:31:32 step 0: mse=12634.958629 step=0.050000
2017/08/29 23:31:33 step 1: mse=12551.885752 step=0.050000
2017/08/29 23:31:33 step 2: mse=12483.492792 step=0.050000
2017/08/29 23:31:34 step 3: mse=12415.486850 step=0.050000
2017/08/29 23:31:35 step 4: mse=12365.131087 step=0.050000
2017/08/29 23:31:36 step 5: mse=12319.970607 step=0.050000
2017/08/29 23:31:36 step 6: mse=12274.551102 step=0.050000
2017/08/29 23:31:37 step 7: mse=12233.286758 step=0.050000
2017/08/29 23:31:37 Saving...
2017/08/29 23:31:37 Gathering batch of experience...
2017/08/29 23:32:01 batch 341: mean=1438.152174 stddev=611.625026 entropy=0.473082 frames=5065 count=46
2017/08/29 23:32:01 Training policy...
2017/08/29 23:32:04 tune 0: objective=20.603020 reg=0.004731 prune=0
2017/08/29 23:32:05 step 0: objective=20.609028 reg=0.004730
2017/08/29 23:32:06 step 1: objective=20.622804 reg=0.004730
2017/08/29 23:32:07 step 2: objective=20.634503 reg=0.004730
2017/08/29 23:32:08 step 3: objective=20.646374 reg=0.004730
2017/08/29 23:32:09 step 4: objective=20.658701 reg=0.004730
2017/08/29 23:32:10 step 5: objective=20.669231 reg=0.004730
2017/08/29 23:32:10 step 6: objective=20.683971 reg=0.004729
2017/08/29 23:32:11 step 7: objective=20.701273 reg=0.004728
2017/08/29 23:32:11 Training value function...
2017/08/29 23:32:13 step 0: mse=14532.523587 step=0.050000
2017/08/29 23:32:14 step 1: mse=14420.199964 step=0.050000
2017/08/29 23:32:15 step 2: mse=14312.305539 step=0.050000
2017/08/29 23:32:16 step 3: mse=14222.770245 step=0.050000
2017/08/29 23:32:17 step 4: mse=14141.631481 step=0.050000
2017/08/29 23:32:17 step 5: mse=14068.899185 step=0.050000
2017/08/29 23:32:18 step 6: mse=14005.184382 step=0.050000
2017/08/29 23:32:19 step 7: mse=13951.056725 step=0.050000
2017/08/29 23:32:19 Saving...
2017/08/29 23:32:19 Gathering batch of experience...
2017/08/29 23:32:44 batch 342: mean=1782.500000 stddev=2721.757095 entropy=0.479858 frames=5313 count=46
2017/08/29 23:32:44 Training policy...
2017/08/29 23:32:47 tune 0: objective=39.052224 reg=0.004799 prune=0
2017/08/29 23:32:48 step 0: objective=39.093059 reg=0.004797
2017/08/29 23:32:49 step 1: objective=39.205145 reg=0.004797
2017/08/29 23:32:50 step 2: objective=39.299637 reg=0.004796
2017/08/29 23:32:51 step 3: objective=39.393260 reg=0.004795
2017/08/29 23:32:52 step 4: objective=39.489845 reg=0.004793
2017/08/29 23:32:53 step 5: objective=39.561015 reg=0.004793
2017/08/29 23:32:54 step 6: objective=39.612913 reg=0.004792
2017/08/29 23:32:55 step 7: objective=39.708974 reg=0.004790
2017/08/29 23:32:55 Training value function...
2017/08/29 23:32:57 step 0: mse=164992.000932 step=0.050000
2017/08/29 23:32:58 step 1: mse=164046.043196 step=0.050000
2017/08/29 23:32:59 step 2: mse=163003.663789 step=0.050000
2017/08/29 23:33:00 step 3: mse=162390.464044 step=0.050000
2017/08/29 23:33:01 step 4: mse=161901.173987 step=0.050000
2017/08/29 23:33:01 step 5: mse=161279.164805 step=0.050000
2017/08/29 23:33:02 step 6: mse=157679.526069 step=0.050000
2017/08/29 23:33:03 step 7: mse=155902.166137 step=0.050000
2017/08/29 23:33:03 Saving...
2017/08/29 23:33:03 Gathering batch of experience...
2017/08/29 23:33:26 batch 343: mean=1539.767442 stddev=738.699323 entropy=0.472123 frames=4986 count=43
2017/08/29 23:33:26 Training policy...
2017/08/29 23:33:29 tune 0: objective=20.823840 reg=0.004721 prune=0
2017/08/29 23:33:30 step 0: objective=20.838506 reg=0.004721
2017/08/29 23:33:31 step 1: objective=20.858800 reg=0.004721
2017/08/29 23:33:32 step 2: objective=20.880363 reg=0.004721
2017/08/29 23:33:33 step 3: objective=20.905932 reg=0.004722
2017/08/29 23:33:34 step 4: objective=20.936880 reg=0.004722
2017/08/29 23:33:35 step 5: objective=20.960579 reg=0.004722
2017/08/29 23:33:35 step 6: objective=20.990003 reg=0.004722
2017/08/29 23:33:36 step 7: objective=21.011675 reg=0.004722
2017/08/29 23:33:36 Training value function...
2017/08/29 23:33:38 step 0: mse=19184.542865 step=0.050000
2017/08/29 23:33:39 step 1: mse=19054.197675 step=0.050000
2017/08/29 23:33:40 step 2: mse=18945.057811 step=0.050000
2017/08/29 23:33:41 step 3: mse=18841.401025 step=0.050000
2017/08/29 23:33:41 step 4: mse=18756.062849 step=0.050000
2017/08/29 23:33:42 step 5: mse=18683.957499 step=0.050000
2017/08/29 23:33:43 step 6: mse=18619.256233 step=0.050000
2017/08/29 23:33:44 step 7: mse=18551.704699 step=0.050000
2017/08/29 23:33:44 Saving...
2017/08/29 23:33:44 Gathering batch of experience...
2017/08/29 23:34:07 batch 344: mean=1597.738095 stddev=704.764569 entropy=0.473756 frames=5080 count=42
2017/08/29 23:34:07 Training policy...
2017/08/29 23:34:10 tune 0: objective=22.131979 reg=0.004738 prune=0
2017/08/29 23:34:11 step 0: objective=22.142204 reg=0.004737
2017/08/29 23:34:12 step 1: objective=22.165933 reg=0.004737
2017/08/29 23:34:13 step 2: objective=22.184933 reg=0.004737
2017/08/29 23:34:14 step 3: objective=22.212225 reg=0.004737
2017/08/29 23:34:15 step 4: objective=22.235758 reg=0.004736
2017/08/29 23:34:16 step 5: objective=22.258509 reg=0.004736
2017/08/29 23:34:17 step 6: objective=22.281857 reg=0.004735
2017/08/29 23:34:17 step 7: objective=22.301787 reg=0.004735
2017/08/29 23:34:17 Training value function...
2017/08/29 23:34:20 step 0: mse=19652.025432 step=0.050000
2017/08/29 23:34:20 step 1: mse=19406.799460 step=0.050000
2017/08/29 23:34:21 step 2: mse=19195.713623 step=0.050000
2017/08/29 23:34:22 step 3: mse=18980.550312 step=0.050000
2017/08/29 23:34:23 step 4: mse=18793.824159 step=0.050000
2017/08/29 23:34:23 step 5: mse=18616.168529 step=0.050000
2017/08/29 23:34:24 step 6: mse=18464.495824 step=0.050000
2017/08/29 23:34:25 step 7: mse=18321.612732 step=0.050000
2017/08/29 23:34:25 Saving...
2017/08/29 23:34:25 Gathering batch of experience...
2017/08/29 23:34:49 batch 345: mean=1800.333333 stddev=2677.792084 entropy=0.478898 frames=5222 count=45
2017/08/29 23:34:49 Training policy...
2017/08/29 23:34:53 tune 0: objective=44.270670 reg=0.004789 prune=0
2017/08/29 23:34:54 step 0: objective=44.344357 reg=0.004788
2017/08/29 23:34:55 step 1: objective=44.550702 reg=0.004787
2017/08/29 23:34:55 step 2: objective=44.635844 reg=0.004787
2017/08/29 23:34:56 step 3: objective=44.769605 reg=0.004786
2017/08/29 23:34:57 step 4: objective=44.833622 reg=0.004785
2017/08/29 23:34:58 step 5: objective=44.898653 reg=0.004785
2017/08/29 23:34:59 step 6: objective=44.977466 reg=0.004782
2017/08/29 23:35:00 step 7: objective=45.039688 reg=0.004780
2017/08/29 23:35:00 Training value function...
2017/08/29 23:35:02 step 0: mse=185446.539666 step=0.050000
2017/08/29 23:35:03 step 1: mse=180922.226204 step=0.050000
2017/08/29 23:35:04 step 2: mse=179510.177045 step=0.050000
2017/08/29 23:35:05 step 3: mse=177916.115780 step=0.050000
2017/08/29 23:35:06 step 4: mse=176690.566847 step=0.050000
2017/08/29 23:35:06 step 5: mse=172890.932591 step=0.050000
2017/08/29 23:35:07 step 6: mse=171932.506910 step=0.050000
2017/08/29 23:35:08 step 7: mse=168628.246394 step=0.050000
2017/08/29 23:35:08 Saving...
2017/08/29 23:35:08 Gathering batch of experience...
2017/08/29 23:35:35 batch 346: mean=1804.565217 stddev=2799.237828 entropy=0.472824 frames=5491 count=46
2017/08/29 23:35:35 Training policy...
2017/08/29 23:35:39 tune 0: objective=32.444483 reg=0.004728 prune=0
2017/08/29 23:35:40 step 0: objective=32.495857 reg=0.004728
2017/08/29 23:35:41 step 1: objective=32.621213 reg=0.004726
2017/08/29 23:35:42 step 2: objective=32.707456 reg=0.004725
2017/08/29 23:35:43 step 3: objective=32.776987 reg=0.004725
2017/08/29 23:35:44 step 4: objective=32.904676 reg=0.004723
2017/08/29 23:35:45 step 5: objective=32.972279 reg=0.004723
2017/08/29 23:35:46 step 6: objective=33.069696 reg=0.004721
2017/08/29 23:35:47 step 7: objective=33.154045 reg=0.004721
2017/08/29 23:35:47 Training value function...
2017/08/29 23:35:49 step 0: mse=169942.905352 step=0.050000
2017/08/29 23:35:50 step 1: mse=168515.295212 step=0.050000
2017/08/29 23:35:51 step 2: mse=167135.973166 step=0.050000
2017/08/29 23:35:52 step 3: mse=165527.306720 step=0.050000
2017/08/29 23:35:52 step 4: mse=164177.701895 step=0.050000
2017/08/29 23:35:53 step 5: mse=162810.927325 step=0.050000
2017/08/29 23:35:54 step 6: mse=161453.093771 step=0.050000
2017/08/29 23:35:55 step 7: mse=160172.963170 step=0.050000
2017/08/29 23:35:55 Saving...
2017/08/29 23:35:55 Gathering batch of experience...
2017/08/29 23:36:17 batch 347: mean=1330.108696 stddev=557.866169 entropy=0.465581 frames=4766 count=46
2017/08/29 23:36:17 Training policy...
2017/08/29 23:36:20 tune 0: objective=8.921921 reg=0.004656 prune=0
2017/08/29 23:36:21 step 0: objective=8.929884 reg=0.004654
2017/08/29 23:36:22 step 1: objective=8.940920 reg=0.004653
2017/08/29 23:36:23 step 2: objective=8.951005 reg=0.004653
2017/08/29 23:36:24 step 3: objective=8.962701 reg=0.004652
2017/08/29 23:36:25 step 4: objective=8.975813 reg=0.004651
2017/08/29 23:36:25 step 5: objective=8.985215 reg=0.004650
2017/08/29 23:36:26 step 6: objective=9.000384 reg=0.004649
2017/08/29 23:36:27 step 7: objective=9.010752 reg=0.004647
2017/08/29 23:36:27 Training value function...
2017/08/29 23:36:29 step 0: mse=12258.149783 step=0.050000
2017/08/29 23:36:30 step 1: mse=12178.180418 step=0.050000
2017/08/29 23:36:31 step 2: mse=12132.248486 step=0.050000
2017/08/29 23:36:31 step 3: mse=12082.732030 step=0.050000
2017/08/29 23:36:32 step 4: mse=12044.565445 step=0.050000
2017/08/29 23:36:33 step 5: mse=12027.727771 step=0.050000
2017/08/29 23:36:34 step 6: mse=12010.432826 step=0.050000
2017/08/29 23:36:34 step 7: mse=12004.996406 step=0.050000
2017/08/29 23:36:34 Saving...
2017/08/29 23:36:34 Gathering batch of experience...
2017/08/29 23:36:57 batch 348: mean=1554.418605 stddev=763.387653 entropy=0.467876 frames=4993 count=43
2017/08/29 23:36:57 Training policy...
2017/08/29 23:37:00 tune 0: objective=23.992452 reg=0.004679 prune=0
2017/08/29 23:37:01 step 0: objective=24.000469 reg=0.004678
2017/08/29 23:37:02 step 1: objective=24.015362 reg=0.004678
2017/08/29 23:37:03 step 2: objective=24.026838 reg=0.004678
2017/08/29 23:37:04 step 3: objective=24.042226 reg=0.004678
2017/08/29 23:37:05 step 4: objective=24.054586 reg=0.004678
2017/08/29 23:37:06 step 5: objective=24.069755 reg=0.004677
2017/08/29 23:37:07 step 6: objective=24.081437 reg=0.004677
2017/08/29 23:37:08 step 7: objective=24.092705 reg=0.004676
2017/08/29 23:37:08 Training value function...
2017/08/29 23:37:10 step 0: mse=16875.837806 step=0.050000
2017/08/29 23:37:10 step 1: mse=16792.753754 step=0.050000
2017/08/29 23:37:11 step 2: mse=16704.657302 step=0.050000
2017/08/29 23:37:12 step 3: mse=16621.190258 step=0.050000
2017/08/29 23:37:13 step 4: mse=16554.808646 step=0.050000
2017/08/29 23:37:13 step 5: mse=16489.778872 step=0.050000
2017/08/29 23:37:14 step 6: mse=16436.476908 step=0.050000
2017/08/29 23:37:15 step 7: mse=16388.453459 step=0.050000
2017/08/29 23:37:15 Saving...
2017/08/29 23:37:15 Gathering batch of experience...
2017/08/29 23:37:40 batch 349: mean=1881.333333 stddev=2803.455883 entropy=0.472544 frames=5490 count=45
2017/08/29 23:37:40 Training policy...
2017/08/29 23:37:43 tune 0: objective=42.409899 reg=0.004725 prune=0
2017/08/29 23:37:44 step 0: objective=42.469388 reg=0.004726
2017/08/29 23:37:45 step 1: objective=42.617623 reg=0.004726
2017/08/29 23:37:46 step 2: objective=42.744405 reg=0.004725
2017/08/29 23:37:47 step 3: objective=42.801901 reg=0.004726
2017/08/29 23:37:48 step 4: objective=42.855419 reg=0.004725
2017/08/29 23:37:49 step 5: objective=42.973301 reg=0.004725
2017/08/29 23:37:50 step 6: objective=43.015591 reg=0.004726
2017/08/29 23:37:51 step 7: objective=43.084896 reg=0.004725
2017/08/29 23:37:51 Training value function...
2017/08/29 23:37:54 step 0: mse=170366.867963 step=0.050000
2017/08/29 23:37:54 step 1: mse=168461.871762 step=0.050000
2017/08/29 23:37:55 step 2: mse=166905.753207 step=0.050000
2017/08/29 23:37:56 step 3: mse=165629.382116 step=0.050000
2017/08/29 23:37:57 step 4: mse=164361.414733 step=0.050000
2017/08/29 23:37:58 step 5: mse=163202.471322 step=0.050000
2017/08/29 23:37:59 step 6: mse=162046.704760 step=0.050000
2017/08/29 23:38:00 step 7: mse=160848.637035 step=0.050000
2017/08/29 23:38:00 Saving...
2017/08/29 23:38:00 Gathering batch of experience...
2017/08/29 23:38:22 batch 350: mean=1683.536585 stddev=1097.701725 entropy=0.472487 frames=4945 count=41
2017/08/29 23:38:22 Training policy...
2017/08/29 23:38:25 tune 0: objective=24.787500 reg=0.004725 prune=0
2017/08/29 23:38:26 step 0: objective=24.805918 reg=0.004723
2017/08/29 23:38:27 step 1: objective=24.852542 reg=0.004722
2017/08/29 23:38:28 step 2: objective=24.899453 reg=0.004720
2017/08/29 23:38:29 step 3: objective=24.935881 reg=0.004718
2017/08/29 23:38:30 step 4: objective=24.981868 reg=0.004717
2017/08/29 23:38:31 step 5: objective=25.009103 reg=0.004715
2017/08/29 23:38:32 step 6: objective=25.047910 reg=0.004713
2017/08/29 23:38:32 step 7: objective=25.083553 reg=0.004713
2017/08/29 23:38:32 Training value function...
2017/08/29 23:38:34 step 0: mse=26687.251873 step=0.050000
2017/08/29 23:38:35 step 1: mse=26542.802078 step=0.050000
2017/08/29 23:38:36 step 2: mse=26430.191538 step=0.050000
2017/08/29 23:38:37 step 3: mse=26320.235802 step=0.050000
2017/08/29 23:38:38 step 4: mse=26218.739440 step=0.050000
2017/08/29 23:38:38 step 5: mse=26132.428268 step=0.050000
2017/08/29 23:38:39 step 6: mse=26053.262039 step=0.050000
2017/08/29 23:38:40 step 7: mse=25970.510672 step=0.050000
2017/08/29 23:38:40 Saving...
2017/08/29 23:38:40 Gathering batch of experience...
2017/08/29 23:39:04 batch 351: mean=1432.608696 stddev=616.050481 entropy=0.467834 frames=5135 count=46
2017/08/29 23:39:04 Training policy...
2017/08/29 23:39:07 tune 0: objective=16.988273 reg=0.004678 prune=0
2017/08/29 23:39:08 step 0: objective=16.994272 reg=0.004678
2017/08/29 23:39:09 step 1: objective=17.007193 reg=0.004676
2017/08/29 23:39:10 step 2: objective=17.015528 reg=0.004676
2017/08/29 23:39:11 step 3: objective=17.026915 reg=0.004675
2017/08/29 23:39:12 step 4: objective=17.035364 reg=0.004674
2017/08/29 23:39:13 step 5: objective=17.046361 reg=0.004673
2017/08/29 23:39:14 step 6: objective=17.056694 reg=0.004673
2017/08/29 23:39:15 step 7: objective=17.065738 reg=0.004672
2017/08/29 23:39:15 Training value function...
2017/08/29 23:39:17 step 0: mse=13930.132194 step=0.050000
2017/08/29 23:39:17 step 1: mse=13887.263256 step=0.050000
2017/08/29 23:39:18 step 2: mse=13841.163965 step=0.050000
2017/08/29 23:39:19 step 3: mse=13800.546724 step=0.050000
2017/08/29 23:39:20 step 4: mse=13774.314865 step=0.050000
2017/08/29 23:39:21 step 5: mse=13749.379054 step=0.050000
2017/08/29 23:39:21 step 6: mse=13728.464227 step=0.050000
2017/08/29 23:39:22 step 7: mse=13711.456569 step=0.050000
2017/08/29 23:39:22 Saving...
2017/08/29 23:39:22 Gathering batch of experience...
2017/08/29 23:39:46 batch 352: mean=1438.777778 stddev=630.556329 entropy=0.467296 frames=5009 count=45
2017/08/29 23:39:46 Training policy...
2017/08/29 23:39:49 tune 0: objective=20.844160 reg=0.004673 prune=0
2017/08/29 23:39:50 step 0: objective=20.850145 reg=0.004672
2017/08/29 23:39:51 step 1: objective=20.863674 reg=0.004672
2017/08/29 23:39:52 step 2: objective=20.871703 reg=0.004671
2017/08/29 23:39:52 step 3: objective=20.880524 reg=0.004671
2017/08/29 23:39:53 step 4: objective=20.889516 reg=0.004670
2017/08/29 23:39:54 step 5: objective=20.904683 reg=0.004670
2017/08/29 23:39:55 step 6: objective=20.918932 reg=0.004670
2017/08/29 23:39:56 step 7: objective=20.926676 reg=0.004669
2017/08/29 23:39:56 Training value function...
2017/08/29 23:39:58 step 0: mse=14952.278774 step=0.050000
2017/08/29 23:39:59 step 1: mse=14918.366452 step=0.050000
2017/08/29 23:40:00 step 2: mse=14889.706492 step=0.050000
2017/08/29 23:40:00 step 3: mse=14863.844737 step=0.050000
2017/08/29 23:40:01 step 4: mse=14836.440707 step=0.050000
2017/08/29 23:40:02 step 5: mse=14818.211076 step=0.050000
2017/08/29 23:40:03 step 6: mse=14799.873634 step=0.050000
2017/08/29 23:40:04 step 7: mse=14783.159544 step=0.050000
2017/08/29 23:40:04 Saving...
2017/08/29 23:40:04 Gathering batch of experience...
2017/08/29 23:40:27 batch 353: mean=1416.521739 stddev=585.283162 entropy=0.460141 frames=5010 count=46
2017/08/29 23:40:27 Training policy...
2017/08/29 23:40:30 tune 0: objective=21.261761 reg=0.004601 prune=0
2017/08/29 23:40:31 step 0: objective=21.265965 reg=0.004601
2017/08/29 23:40:32 step 1: objective=21.274601 reg=0.004600
2017/08/29 23:40:33 step 2: objective=21.284366 reg=0.004600
2017/08/29 23:40:34 step 3: objective=21.293786 reg=0.004599
2017/08/29 23:40:35 step 4: objective=21.303945 reg=0.004598
2017/08/29 23:40:36 step 5: objective=21.312609 reg=0.004597
2017/08/29 23:40:36 step 6: objective=21.319525 reg=0.004596
2017/08/29 23:40:37 step 7: objective=21.329452 reg=0.004596
2017/08/29 23:40:37 Training value function...
2017/08/29 23:40:39 step 0: mse=12685.679576 step=0.050000
2017/08/29 23:40:40 step 1: mse=12674.621211 step=0.050000
2017/08/29 23:40:41 step 2: mse=12666.693713 step=0.050000
2017/08/29 23:40:42 step 3: mse=12662.228289 step=0.050000
2017/08/29 23:40:43 step 4: mse=12658.282035 step=0.050000
2017/08/29 23:40:43 step 5: mse=12656.402007 step=0.050000
2017/08/29 23:40:44 step 6: mse=12646.286973 step=0.050000
2017/08/29 23:40:45 step 7: mse=12646.591157 step=0.050000
2017/08/29 23:40:45 Saving...
2017/08/29 23:40:45 Gathering batch of experience...
2017/08/29 23:41:11 batch 354: mean=2387.804878 stddev=3954.807055 entropy=0.474185 frames=5484 count=41
2017/08/29 23:41:11 Training policy...
2017/08/29 23:41:14 tune 0: objective=74.310893 reg=0.004742 prune=0
2017/08/29 23:41:15 step 0: objective=74.430673 reg=0.004742
2017/08/29 23:41:16 step 1: objective=74.732438 reg=0.004746
2017/08/29 23:41:17 step 2: objective=74.954219 reg=0.004747
2017/08/29 23:41:18 step 3: objective=75.131473 reg=0.004749
2017/08/29 23:41:19 step 4: objective=75.288350 reg=0.004746
2017/08/29 23:41:20 step 5: objective=75.395725 reg=0.004746
2017/08/29 23:41:21 step 6: objective=75.456094 reg=0.004745
2017/08/29 23:41:22 step 7: objective=75.526235 reg=0.004742
2017/08/29 23:41:22 Training value function...
2017/08/29 23:41:24 step 0: mse=368038.127664 step=0.050000
2017/08/29 23:41:25 step 1: mse=358310.705088 step=0.050000
2017/08/29 23:41:26 step 2: mse=350039.138158 step=0.050000
2017/08/29 23:41:27 step 3: mse=342415.200396 step=0.050000
2017/08/29 23:41:28 step 4: mse=335008.645710 step=0.050000
2017/08/29 23:41:29 step 5: mse=329461.881726 step=0.050000
2017/08/29 23:41:29 step 6: mse=324179.489878 step=0.050000
2017/08/29 23:41:30 step 7: mse=312837.140405 step=0.050000
2017/08/29 23:41:30 Saving...
2017/08/29 23:41:30 Gathering batch of experience...
2017/08/29 23:41:54 batch 355: mean=1625.000000 stddev=991.736790 entropy=0.468915 frames=5118 count=43
2017/08/29 23:41:54 Training policy...
2017/08/29 23:41:58 tune 0: objective=18.145789 reg=0.004689 prune=0
2017/08/29 23:41:59 step 0: objective=18.162904 reg=0.004688
2017/08/29 23:41:59 step 1: objective=18.188283 reg=0.004689
2017/08/29 23:42:00 step 2: objective=18.209498 reg=0.004689
2017/08/29 23:42:01 step 3: objective=18.243859 reg=0.004689
2017/08/29 23:42:02 step 4: objective=18.279777 reg=0.004689
2017/08/29 23:42:03 step 5: objective=18.305269 reg=0.004689
2017/08/29 23:42:04 step 6: objective=18.326328 reg=0.004688
2017/08/29 23:42:05 step 7: objective=18.345681 reg=0.004688
2017/08/29 23:42:05 Training value function...
2017/08/29 23:42:07 step 0: mse=25528.981899 step=0.050000
2017/08/29 23:42:08 step 1: mse=25213.189595 step=0.050000
2017/08/29 23:42:09 step 2: mse=24955.433879 step=0.050000
2017/08/29 23:42:10 step 3: mse=24701.981856 step=0.050000
2017/08/29 23:42:10 step 4: mse=24498.028013 step=0.050000
2017/08/29 23:42:11 step 5: mse=24354.204746 step=0.050000
2017/08/29 23:42:12 step 6: mse=24176.470640 step=0.050000
2017/08/29 23:42:13 step 7: mse=24071.144428 step=0.050000
2017/08/29 23:42:13 Saving...
2017/08/29 23:42:13 Gathering batch of experience...
2017/08/29 23:42:36 batch 356: mean=1472.444444 stddev=739.688089 entropy=0.463168 frames=5033 count=45
2017/08/29 23:42:36 Training policy...
2017/08/29 23:42:39 tune 0: objective=14.732464 reg=0.004632 prune=0
2017/08/29 23:42:40 step 0: objective=14.749278 reg=0.004631
2017/08/29 23:42:41 step 1: objective=14.784850 reg=0.004630
2017/08/29 23:42:42 step 2: objective=14.802971 reg=0.004629
2017/08/29 23:42:43 step 3: objective=14.829981 reg=0.004628
2017/08/29 23:42:44 step 4: objective=14.864238 reg=0.004627
2017/08/29 23:42:45 step 5: objective=14.896941 reg=0.004625
2017/08/29 23:42:45 step 6: objective=14.916939 reg=0.004625
2017/08/29 23:42:46 step 7: objective=14.939563 reg=0.004623
2017/08/29 23:42:46 Training value function...
2017/08/29 23:42:48 step 0: mse=18026.013479 step=0.050000
2017/08/29 23:42:49 step 1: mse=17948.462420 step=0.050000
2017/08/29 23:42:50 step 2: mse=17882.408925 step=0.050000
2017/08/29 23:42:51 step 3: mse=17814.138710 step=0.050000
2017/08/29 23:42:52 step 4: mse=17762.172080 step=0.050000
2017/08/29 23:42:52 step 5: mse=17712.018889 step=0.050000
2017/08/29 23:42:53 step 6: mse=17662.060499 step=0.050000
2017/08/29 23:42:54 step 7: mse=17613.540148 step=0.050000
2017/08/29 23:42:54 Saving...
2017/08/29 23:42:54 Gathering batch of experience...
2017/08/29 23:43:17 batch 357: mean=1469.888889 stddev=545.291450 entropy=0.461661 frames=5105 count=45
2017/08/29 23:43:17 Training policy...
2017/08/29 23:43:21 tune 0: objective=19.491624 reg=0.004617 prune=0
2017/08/29 23:43:22 step 0: objective=19.496838 reg=0.004616
2017/08/29 23:43:23 step 1: objective=19.506337 reg=0.004615
2017/08/29 23:43:23 step 2: objective=19.519180 reg=0.004614
2017/08/29 23:43:24 step 3: objective=19.527745 reg=0.004614
2017/08/29 23:43:25 step 4: objective=19.535656 reg=0.004614
2017/08/29 23:43:26 step 5: objective=19.548675 reg=0.004613
2017/08/29 23:43:27 step 6: objective=19.555557 reg=0.004613
2017/08/29 23:43:28 step 7: objective=19.572369 reg=0.004612
2017/08/29 23:43:28 Training value function...
2017/08/29 23:43:30 step 0: mse=13016.201102 step=0.050000
2017/08/29 23:43:31 step 1: mse=12996.300272 step=0.050000
2017/08/29 23:43:32 step 2: mse=12987.494512 step=0.050000
2017/08/29 23:43:33 step 3: mse=12979.768550 step=0.050000
2017/08/29 23:43:33 step 4: mse=12974.629587 step=0.050000
2017/08/29 23:43:34 step 5: mse=12962.332426 step=0.050000
2017/08/29 23:43:35 step 6: mse=12959.189149 step=0.050000
2017/08/29 23:43:36 step 7: mse=12955.017747 step=0.050000
2017/08/29 23:43:36 Saving...
2017/08/29 23:43:36 Gathering batch of experience...
2017/08/29 23:44:02 batch 358: mean=2371.931818 stddev=3967.712905 entropy=0.472956 frames=5879 count=44
2017/08/29 23:44:02 Training policy...
2017/08/29 23:44:06 tune 0: objective=69.556260 reg=0.004730 prune=0
2017/08/29 23:44:07 step 0: objective=69.655612 reg=0.004729
2017/08/29 23:44:08 step 1: objective=70.039569 reg=0.004731
2017/08/29 23:44:09 step 2: objective=70.227159 reg=0.004729
2017/08/29 23:44:10 step 3: objective=70.363157 reg=0.004729
2017/08/29 23:44:11 step 4: objective=70.504295 reg=0.004730
2017/08/29 23:44:13 step 5: objective=70.578489 reg=0.004731
2017/08/29 23:44:14 step 6: objective=70.694910 reg=0.004734
2017/08/29 23:44:15 step 7: objective=70.754853 reg=0.004732
2017/08/29 23:44:15 Training value function...
2017/08/29 23:44:17 step 0: mse=330493.106899 step=0.050000
2017/08/29 23:44:18 step 1: mse=323968.135446 step=0.050000
2017/08/29 23:44:19 step 2: mse=318439.508159 step=0.050000
2017/08/29 23:44:20 step 3: mse=313581.656473 step=0.050000
2017/08/29 23:44:21 step 4: mse=308420.051954 step=0.050000
2017/08/29 23:44:22 step 5: mse=304383.464517 step=0.050000
2017/08/29 23:44:23 step 6: mse=300229.371947 step=0.050000
2017/08/29 23:44:24 step 7: mse=294402.339320 step=0.050000
2017/08/29 23:44:24 Saving...
2017/08/29 23:44:24 Gathering batch of experience...
2017/08/29 23:44:46 batch 359: mean=1502.325581 stddev=508.653431 entropy=0.459558 frames=4974 count=43
2017/08/29 23:44:46 Training policy...
2017/08/29 23:44:49 tune 0: objective=15.980238 reg=0.004596 prune=0
2017/08/29 23:44:50 step 0: objective=15.984072 reg=0.004595
2017/08/29 23:44:51 step 1: objective=15.995467 reg=0.004593
2017/08/29 23:44:52 step 2: objective=16.008538 reg=0.004592
2017/08/29 23:44:53 step 3: objective=16.018969 reg=0.004591
2017/08/29 23:44:54 step 4: objective=16.031256 reg=0.004590
2017/08/29 23:44:55 step 5: objective=16.045377 reg=0.004588
2017/08/29 23:44:56 step 6: objective=16.052539 reg=0.004587
2017/08/29 23:44:57 step 7: objective=16.060976 reg=0.004586
2017/08/29 23:44:57 Training value function...
2017/08/29 23:44:59 step 0: mse=11202.855985 step=0.050000
2017/08/29 23:45:00 step 1: mse=11150.758852 step=0.050000
2017/08/29 23:45:00 step 2: mse=11102.199616 step=0.050000
2017/08/29 23:45:01 step 3: mse=11064.033802 step=0.050000
2017/08/29 23:45:02 step 4: mse=11024.675777 step=0.050000
2017/08/29 23:45:03 step 5: mse=11002.112528 step=0.050000
2017/08/29 23:45:03 step 6: mse=10981.389684 step=0.050000
2017/08/29 23:45:04 step 7: mse=10965.183450 step=0.050000
2017/08/29 23:45:04 Saving...
2017/08/29 23:45:04 Gathering batch of experience...
2017/08/29 23:45:32 batch 360: mean=1980.000000 stddev=3024.122901 entropy=0.467494 frames=5454 count=44
2017/08/29 23:45:32 Training policy...
2017/08/29 23:45:35 tune 0: objective=40.948235 reg=0.004675 prune=0
2017/08/29 23:45:36 step 0: objective=41.004260 reg=0.004674
2017/08/29 23:45:37 step 1: objective=41.092157 reg=0.004672
2017/08/29 23:45:38 step 2: objective=41.220466 reg=0.004672
2017/08/29 23:45:39 step 3: objective=41.291065 reg=0.004673
2017/08/29 23:45:40 step 4: objective=41.367400 reg=0.004672
2017/08/29 23:45:41 step 5: objective=41.448982 reg=0.004672
2017/08/29 23:45:42 step 6: objective=41.528758 reg=0.004670
2017/08/29 23:45:43 step 7: objective=41.615486 reg=0.004670
2017/08/29 23:45:43 Training value function...
2017/08/29 23:45:45 step 0: mse=173452.170686 step=0.050000
2017/08/29 23:45:46 step 1: mse=170793.754349 step=0.050000
2017/08/29 23:45:47 step 2: mse=168771.647390 step=0.050000
2017/08/29 23:45:48 step 3: mse=167933.072688 step=0.050000
2017/08/29 23:45:49 step 4: mse=167030.661329 step=0.050000
2017/08/29 23:45:50 step 5: mse=165522.756417 step=0.050000
2017/08/29 23:45:51 step 6: mse=163490.430968 step=0.050000
2017/08/29 23:45:52 step 7: mse=162850.136596 step=0.050000
2017/08/29 23:45:52 Saving...
2017/08/29 23:45:52 Gathering batch of experience...
2017/08/29 23:46:15 batch 361: mean=1634.047619 stddev=781.332225 entropy=0.460004 frames=5121 count=42
2017/08/29 23:46:15 Training policy...
2017/08/29 23:46:19 tune 0: objective=21.092269 reg=0.004600 prune=0
2017/08/29 23:46:19 step 0: objective=21.103009 reg=0.004599
2017/08/29 23:46:20 step 1: objective=21.117581 reg=0.004599
2017/08/29 23:46:21 step 2: objective=21.131978 reg=0.004598
2017/08/29 23:46:22 step 3: objective=21.144880 reg=0.004598
2017/08/29 23:46:23 step 4: objective=21.157922 reg=0.004597
2017/08/29 23:46:24 step 5: objective=21.181199 reg=0.004597
2017/08/29 23:46:25 step 6: objective=21.195380 reg=0.004596
2017/08/29 23:46:26 step 7: objective=21.207253 reg=0.004596
2017/08/29 23:46:26 Training value function...
2017/08/29 23:46:28 step 0: mse=15803.920001 step=0.050000
2017/08/29 23:46:29 step 1: mse=15748.873233 step=0.050000
2017/08/29 23:46:30 step 2: mse=15704.404536 step=0.050000
2017/08/29 23:46:30 step 3: mse=15666.022975 step=0.050000
2017/08/29 23:46:31 step 4: mse=15638.729300 step=0.050000
2017/08/29 23:46:32 step 5: mse=15612.427077 step=0.050000
2017/08/29 23:46:33 step 6: mse=15585.227920 step=0.050000
2017/08/29 23:46:34 step 7: mse=15561.767304 step=0.050000
2017/08/29 23:46:34 Saving...
2017/08/29 23:46:34 Gathering batch of experience...
2017/08/29 23:46:57 batch 362: mean=1964.523810 stddev=2845.828570 entropy=0.472982 frames=5024 count=42
2017/08/29 23:46:57 Training policy...
2017/08/29 23:47:00 tune 0: objective=39.724398 reg=0.004730 prune=0
2017/08/29 23:47:01 step 0: objective=39.829549 reg=0.004731
2017/08/29 23:47:02 step 1: objective=39.948503 reg=0.004731
2017/08/29 23:47:03 step 2: objective=40.047883 reg=0.004730
2017/08/29 23:47:04 step 3: objective=40.163167 reg=0.004731
2017/08/29 23:47:05 step 4: objective=40.265659 reg=0.004731
2017/08/29 23:47:06 step 5: objective=40.388140 reg=0.004730
2017/08/29 23:47:07 step 6: objective=40.502311 reg=0.004730
2017/08/29 23:47:08 step 7: objective=40.588671 reg=0.004730
2017/08/29 23:47:08 Training value function...
2017/08/29 23:47:10 step 0: mse=179051.274070 step=0.050000
2017/08/29 23:47:11 step 1: mse=174304.556808 step=0.050000
2017/08/29 23:47:11 step 2: mse=173683.363007 step=0.050000
2017/08/29 23:47:12 step 3: mse=173015.716395 step=0.050000
2017/08/29 23:47:13 step 4: mse=168920.412315 step=0.050000
2017/08/29 23:47:14 step 5: mse=167857.699135 step=0.050000
2017/08/29 23:47:15 step 6: mse=167464.133379 step=0.050000
2017/08/29 23:47:15 step 7: mse=163884.065284 step=0.050000
2017/08/29 23:47:15 Saving...
2017/08/29 23:47:15 Gathering batch of experience...
2017/08/29 23:47:39 batch 363: mean=1410.111111 stddev=549.267683 entropy=0.456989 frames=4958 count=45
2017/08/29 23:47:39 Training policy...
2017/08/29 23:47:42 tune 0: objective=11.676733 reg=0.004570 prune=0
2017/08/29 23:47:43 step 0: objective=11.683799 reg=0.004569
2017/08/29 23:47:44 step 1: objective=11.696214 reg=0.004568
2017/08/29 23:47:45 step 2: objective=11.709236 reg=0.004568
2017/08/29 23:47:46 step 3: objective=11.722117 reg=0.004568
2017/08/29 23:47:47 step 4: objective=11.735768 reg=0.004567
2017/08/29 23:47:47 step 5: objective=11.749779 reg=0.004567
2017/08/29 23:47:48 step 6: objective=11.761593 reg=0.004566
2017/08/29 23:47:49 step 7: objective=11.774659 reg=0.004566
2017/08/29 23:47:49 Training value function...
2017/08/29 23:47:51 step 0: mse=14734.613849 step=0.050000
2017/08/29 23:47:52 step 1: mse=14656.688130 step=0.050000
2017/08/29 23:47:53 step 2: mse=14591.332248 step=0.050000
2017/08/29 23:47:54 step 3: mse=14538.488492 step=0.050000
2017/08/29 23:47:54 step 4: mse=14485.691208 step=0.050000
2017/08/29 23:47:55 step 5: mse=14463.345377 step=0.050000
2017/08/29 23:47:56 step 6: mse=14432.630811 step=0.050000
2017/08/29 23:47:57 step 7: mse=14407.640901 step=0.050000
2017/08/29 23:47:57 Saving...
2017/08/29 23:47:57 Gathering batch of experience...
2017/08/29 23:48:20 batch 364: mean=1571.395349 stddev=970.873094 entropy=0.468747 frames=4985 count=43
2017/08/29 23:48:20 Training policy...
2017/08/29 23:48:23 tune 0: objective=25.390998 reg=0.004687 prune=0
2017/08/29 23:48:24 step 0: objective=25.401332 reg=0.004687
2017/08/29 23:48:25 step 1: objective=25.416736 reg=0.004687
2017/08/29 23:48:26 step 2: objective=25.434458 reg=0.004686
2017/08/29 23:48:27 step 3: objective=25.446551 reg=0.004686
2017/08/29 23:48:28 step 4: objective=25.463950 reg=0.004685
2017/08/29 23:48:29 step 5: objective=25.476581 reg=0.004685
2017/08/29 23:48:30 step 6: objective=25.499030 reg=0.004685
2017/08/29 23:48:30 step 7: objective=25.517792 reg=0.004685
2017/08/29 23:48:30 Training value function...
2017/08/29 23:48:32 step 0: mse=23571.275148 step=0.050000
2017/08/29 23:48:33 step 1: mse=23382.627774 step=0.050000
2017/08/29 23:48:34 step 2: mse=23217.581349 step=0.050000
2017/08/29 23:48:35 step 3: mse=23058.749935 step=0.050000
2017/08/29 23:48:36 step 4: mse=22914.921315 step=0.050000
2017/08/29 23:48:36 step 5: mse=22786.212611 step=0.050000
2017/08/29 23:48:37 step 6: mse=22659.314381 step=0.050000
2017/08/29 23:48:38 step 7: mse=22549.581993 step=0.050000
2017/08/29 23:48:38 Saving...
2017/08/29 23:48:38 Gathering batch of experience...
2017/08/29 23:49:01 batch 365: mean=1660.975610 stddev=659.714664 entropy=0.461981 frames=5107 count=41
2017/08/29 23:49:01 Training policy...
2017/08/29 23:49:05 tune 0: objective=26.890631 reg=0.004620 prune=0
2017/08/29 23:49:06 step 0: objective=26.899920 reg=0.004619
2017/08/29 23:49:07 step 1: objective=26.916502 reg=0.004620
2017/08/29 23:49:07 step 2: objective=26.929016 reg=0.004619
2017/08/29 23:49:08 step 3: objective=26.943243 reg=0.004619
2017/08/29 23:49:09 step 4: objective=26.959801 reg=0.004618
2017/08/29 23:49:10 step 5: objective=26.974193 reg=0.004618
2017/08/29 23:49:11 step 6: objective=26.987119 reg=0.004618
2017/08/29 23:49:12 step 7: objective=27.002588 reg=0.004618
2017/08/29 23:49:12 Training value function...
2017/08/29 23:49:14 step 0: mse=16905.126392 step=0.050000
2017/08/29 23:49:15 step 1: mse=16774.028692 step=0.050000
2017/08/29 23:49:16 step 2: mse=16656.652850 step=0.050000
2017/08/29 23:49:17 step 3: mse=16551.928214 step=0.050000
2017/08/29 23:49:17 step 4: mse=16445.027920 step=0.050000
2017/08/29 23:49:18 step 5: mse=16345.363714 step=0.050000
2017/08/29 23:49:19 step 6: mse=16260.400988 step=0.050000
2017/08/29 23:49:20 step 7: mse=16174.736933 step=0.050000
2017/08/29 23:49:20 Saving...
2017/08/29 23:49:20 Gathering batch of experience...
2017/08/29 23:49:44 batch 366: mean=1957.386364 stddev=2702.558234 entropy=0.466891 frames=5445 count=44
2017/08/29 23:49:44 Training policy...
2017/08/29 23:49:48 tune 0: objective=47.401639 reg=0.004669 prune=0
2017/08/29 23:49:49 step 0: objective=47.459389 reg=0.004669
2017/08/29 23:49:50 step 1: objective=47.554675 reg=0.004671
2017/08/29 23:49:51 step 2: objective=47.635244 reg=0.004670
2017/08/29 23:49:52 step 3: objective=47.793859 reg=0.004672
2017/08/29 23:49:53 step 4: objective=47.904709 reg=0.004672
2017/08/29 23:49:54 step 5: objective=47.971975 reg=0.004674
2017/08/29 23:49:55 step 6: objective=48.005607 reg=0.004674
2017/08/29 23:49:56 step 7: objective=48.044694 reg=0.004674
2017/08/29 23:49:56 Training value function...
2017/08/29 23:49:58 step 0: mse=164986.826271 step=0.050000
2017/08/29 23:49:59 step 1: mse=163299.839553 step=0.050000
2017/08/29 23:50:00 step 2: mse=160076.051937 step=0.050000
2017/08/29 23:50:01 step 3: mse=156918.957223 step=0.050000
2017/08/29 23:50:01 step 4: mse=155756.032081 step=0.050000
2017/08/29 23:50:02 step 5: mse=153223.270100 step=0.050000
2017/08/29 23:50:03 step 6: mse=150572.819281 step=0.050000
2017/08/29 23:50:04 step 7: mse=148357.622848 step=0.050000
2017/08/29 23:50:04 Saving...
2017/08/29 23:50:04 Gathering batch of experience...
2017/08/29 23:50:32 batch 367: mean=1998.837209 stddev=2924.932485 entropy=0.470478 frames=5481 count=43
2017/08/29 23:50:32 Training policy...
2017/08/29 23:50:35 tune 0: objective=44.780264 reg=0.004705 prune=0
2017/08/29 23:50:36 step 0: objective=44.842878 reg=0.004705
2017/08/29 23:50:37 step 1: objective=44.943943 reg=0.004704
2017/08/29 23:50:38 step 2: objective=45.140890 reg=0.004703
2017/08/29 23:50:39 step 3: objective=45.235330 reg=0.004702
2017/08/29 23:50:40 step 4: objective=45.309031 reg=0.004700
2017/08/29 23:50:41 step 5: objective=45.426140 reg=0.004700
2017/08/29 23:50:42 step 6: objective=45.457076 reg=0.004699
2017/08/29 23:50:43 step 7: objective=45.525332 reg=0.004698
2017/08/29 23:50:43 Training value function...
2017/08/29 23:50:45 step 0: mse=169217.923946 step=0.050000
2017/08/29 23:50:46 step 1: mse=168058.273208 step=0.050000
2017/08/29 23:50:47 step 2: mse=167206.115201 step=0.050000
2017/08/29 23:50:48 step 3: mse=166190.709997 step=0.050000
2017/08/29 23:50:49 step 4: mse=164251.970676 step=0.050000
2017/08/29 23:50:50 step 5: mse=160972.346449 step=0.050000
2017/08/29 23:50:51 step 6: mse=159935.536922 step=0.050000
2017/08/29 23:50:51 step 7: mse=158858.338574 step=0.050000
2017/08/29 23:50:51 Saving...
2017/08/29 23:50:51 Gathering batch of experience...
2017/08/29 23:51:16 batch 368: mean=2459.625000 stddev=4212.219336 entropy=0.472725 frames=5284 count=40
2017/08/29 23:51:16 Training policy...
2017/08/29 23:51:19 tune 0: objective=54.060572 reg=0.004727 prune=0
2017/08/29 23:51:20 step 0: objective=54.155741 reg=0.004725
2017/08/29 23:51:21 step 1: objective=54.350119 reg=0.004724
2017/08/29 23:51:22 step 2: objective=54.510811 reg=0.004724
2017/08/29 23:51:23 step 3: objective=54.715675 reg=0.004723
2017/08/29 23:51:24 step 4: objective=54.826037 reg=0.004722
2017/08/29 23:51:25 step 5: objective=54.935176 reg=0.004720
2017/08/29 23:51:26 step 6: objective=55.009445 reg=0.004719
2017/08/29 23:51:27 step 7: objective=55.090060 reg=0.004719
2017/08/29 23:51:27 Training value function...
2017/08/29 23:51:29 step 0: mse=296766.116074 step=0.050000
2017/08/29 23:51:29 step 1: mse=294162.246472 step=0.050000
2017/08/29 23:51:30 step 2: mse=289681.342636 step=0.050000
2017/08/29 23:51:31 step 3: mse=285400.062774 step=0.050000
2017/08/29 23:51:32 step 4: mse=282845.658176 step=0.050000
2017/08/29 23:51:33 step 5: mse=279074.975375 step=0.050000
2017/08/29 23:51:34 step 6: mse=274232.326365 step=0.050000
2017/08/29 23:51:34 step 7: mse=269181.267185 step=0.050000
2017/08/29 23:51:34 Saving...
2017/08/29 23:51:35 Gathering batch of experience...
2017/08/29 23:51:59 batch 369: mean=1944.302326 stddev=2879.662363 entropy=0.461504 frames=5286 count=43
2017/08/29 23:51:59 Training policy...
2017/08/29 23:52:02 tune 0: objective=32.530765 reg=0.004615 prune=0
2017/08/29 23:52:03 step 0: objective=32.572964 reg=0.004614
2017/08/29 23:52:04 step 1: objective=32.621453 reg=0.004612
2017/08/29 23:52:05 step 2: objective=32.710521 reg=0.004611
2017/08/29 23:52:06 step 3: objective=32.755468 reg=0.004611
2017/08/29 23:52:07 step 4: objective=32.804147 reg=0.004610
2017/08/29 23:52:08 step 5: objective=32.870708 reg=0.004611
2017/08/29 23:52:09 step 6: objective=32.941916 reg=0.004610
2017/08/29 23:52:10 step 7: objective=32.985761 reg=0.004610
2017/08/29 23:52:10 Training value function...
2017/08/29 23:52:12 step 0: mse=151151.741925 step=0.050000
2017/08/29 23:52:13 step 1: mse=150315.563178 step=0.050000
2017/08/29 23:52:14 step 2: mse=149497.913889 step=0.050000
2017/08/29 23:52:14 step 3: mse=149117.664033 step=0.050000
2017/08/29 23:52:15 step 4: mse=148830.667936 step=0.050000
2017/08/29 23:52:16 step 5: mse=148466.895321 step=0.050000
2017/08/29 23:52:17 step 6: mse=148372.339374 step=0.050000
2017/08/29 23:52:18 step 7: mse=148256.023132 step=0.050000
2017/08/29 23:52:18 Saving...
2017/08/29 23:52:18 Gathering batch of experience...
2017/08/29 23:52:43 batch 370: mean=2074.186047 stddev=2941.733576 entropy=0.461830 frames=5597 count=43
2017/08/29 23:52:43 Training policy...
2017/08/29 23:52:47 tune 0: objective=28.137875 reg=0.004618 prune=0
2017/08/29 23:52:48 step 0: objective=28.199602 reg=0.004618
2017/08/29 23:52:49 step 1: objective=28.291803 reg=0.004617
2017/08/29 23:52:50 step 2: objective=28.374777 reg=0.004617
2017/08/29 23:52:51 step 3: objective=28.474238 reg=0.004617
2017/08/29 23:52:52 step 4: objective=28.541272 reg=0.004618
2017/08/29 23:52:53 step 5: objective=28.604777 reg=0.004618
2017/08/29 23:52:54 step 6: objective=28.671459 reg=0.004618
2017/08/29 23:52:55 step 7: objective=28.742719 reg=0.004619
2017/08/29 23:52:55 Training value function...
2017/08/29 23:52:57 step 0: mse=138375.283442 step=0.050000
2017/08/29 23:52:58 step 1: mse=138153.696740 step=0.050000
2017/08/29 23:52:59 step 2: mse=137697.656909 step=0.050000
2017/08/29 23:53:00 step 3: mse=136741.132919 step=0.050000
2017/08/29 23:53:01 step 4: mse=136038.290109 step=0.050000
2017/08/29 23:53:02 step 5: mse=135770.811306 step=0.050000
2017/08/29 23:53:03 step 6: mse=135508.827325 step=0.050000
2017/08/29 23:53:04 step 7: mse=135241.045327 step=0.050000
2017/08/29 23:53:04 Saving...
2017/08/29 23:53:04 Gathering batch of experience...
2017/08/29 23:53:27 batch 371: mean=1670.875000 stddev=525.159366 entropy=0.455468 frames=5019 count=40
2017/08/29 23:53:27 Training policy...
2017/08/29 23:53:30 tune 0: objective=12.067338 reg=0.004555 prune=0
2017/08/29 23:53:31 step 0: objective=12.079496 reg=0.004554
2017/08/29 23:53:32 step 1: objective=12.094266 reg=0.004554
2017/08/29 23:53:33 step 2: objective=12.108939 reg=0.004554
2017/08/29 23:53:33 step 3: objective=12.124813 reg=0.004553
2017/08/29 23:53:34 step 4: objective=12.141865 reg=0.004553
2017/08/29 23:53:35 step 5: objective=12.156137 reg=0.004553
2017/08/29 23:53:36 step 6: objective=12.171126 reg=0.004553
2017/08/29 23:53:37 step 7: objective=12.185542 reg=0.004553
2017/08/29 23:53:37 Training value function...
2017/08/29 23:53:39 step 0: mse=16498.110485 step=0.050000
2017/08/29 23:53:40 step 1: mse=16108.273111 step=0.050000
2017/08/29 23:53:41 step 2: mse=15734.982101 step=0.050000
2017/08/29 23:53:41 step 3: mse=15431.738756 step=0.050000
2017/08/29 23:53:42 step 4: mse=15160.159590 step=0.050000
2017/08/29 23:53:43 step 5: mse=14914.252322 step=0.050000
2017/08/29 23:53:44 step 6: mse=14699.229714 step=0.050000
2017/08/29 23:53:45 step 7: mse=14504.119268 step=0.050000
2017/08/29 23:53:45 Saving...
2017/08/29 23:53:45 Gathering batch of experience...
2017/08/29 23:54:07 batch 372: mean=1355.434783 stddev=651.255331 entropy=0.463215 frames=4852 count=46
2017/08/29 23:54:07 Training policy...
2017/08/29 23:54:10 tune 0: objective=7.401179 reg=0.004632 prune=0
2017/08/29 23:54:11 step 0: objective=7.408745 reg=0.004631
2017/08/29 23:54:12 step 1: objective=7.421679 reg=0.004631
2017/08/29 23:54:13 step 2: objective=7.434243 reg=0.004631
2017/08/29 23:54:14 step 3: objective=7.445940 reg=0.004630
2017/08/29 23:54:15 step 4: objective=7.461169 reg=0.004629
2017/08/29 23:54:16 step 5: objective=7.475918 reg=0.004629
2017/08/29 23:54:17 step 6: objective=7.489205 reg=0.004629
2017/08/29 23:54:18 step 7: objective=7.503609 reg=0.004628
2017/08/29 23:54:18 Training value function...
2017/08/29 23:54:20 step 0: mse=13637.773716 step=0.050000
2017/08/29 23:54:20 step 1: mse=13608.800283 step=0.050000
2017/08/29 23:54:21 step 2: mse=13590.431304 step=0.050000
2017/08/29 23:54:22 step 3: mse=13581.264589 step=0.050000
2017/08/29 23:54:23 step 4: mse=13585.955947 step=0.050000
2017/08/29 23:54:23 step 5: mse=13594.319042 step=0.050000
2017/08/29 23:54:24 step 6: mse=13609.787816 step=0.050000
2017/08/29 23:54:25 step 7: mse=13632.172405 step=0.050000
2017/08/29 23:54:25 Saving...
2017/08/29 23:54:25 Gathering batch of experience...
2017/08/29 23:54:51 batch 373: mean=2259.883721 stddev=3939.669666 entropy=0.464394 frames=5360 count=43
2017/08/29 23:54:51 Training policy...
2017/08/29 23:54:54 tune 0: objective=59.285879 reg=0.004644 prune=0
2017/08/29 23:54:55 step 0: objective=59.381635 reg=0.004643
2017/08/29 23:54:56 step 1: objective=59.496531 reg=0.004642
2017/08/29 23:54:57 step 2: objective=59.630515 reg=0.004641
2017/08/29 23:54:58 step 3: objective=59.765188 reg=0.004640
2017/08/29 23:54:59 step 4: objective=59.875017 reg=0.004639
2017/08/29 23:55:00 step 5: objective=59.947837 reg=0.004637
2017/08/29 23:55:01 step 6: objective=60.047656 reg=0.004637
2017/08/29 23:55:02 step 7: objective=60.150373 reg=0.004635
2017/08/29 23:55:02 Training value function...
2017/08/29 23:55:04 step 0: mse=296754.472212 step=0.050000
2017/08/29 23:55:05 step 1: mse=290833.296130 step=0.050000
2017/08/29 23:55:06 step 2: mse=286880.322630 step=0.050000
2017/08/29 23:55:07 step 3: mse=281757.736442 step=0.050000
2017/08/29 23:55:07 step 4: mse=277823.908552 step=0.050000
2017/08/29 23:55:08 step 5: mse=275144.098177 step=0.050000
2017/08/29 23:55:09 step 6: mse=272573.751950 step=0.050000
2017/08/29 23:55:10 step 7: mse=267985.406499 step=0.050000
2017/08/29 23:55:10 Saving...
2017/08/29 23:55:10 Gathering batch of experience...
2017/08/29 23:55:34 batch 374: mean=1355.312500 stddev=667.012467 entropy=0.461403 frames=5034 count=48
2017/08/29 23:55:34 Training policy...
2017/08/29 23:55:37 tune 0: objective=10.431896 reg=0.004614 prune=0
2017/08/29 23:55:38 step 0: objective=10.439573 reg=0.004613
2017/08/29 23:55:39 step 1: objective=10.457565 reg=0.004612
2017/08/29 23:55:40 step 2: objective=10.471688 reg=0.004611
2017/08/29 23:55:40 step 3: objective=10.484906 reg=0.004610
2017/08/29 23:55:41 step 4: objective=10.498845 reg=0.004610
2017/08/29 23:55:42 step 5: objective=10.512381 reg=0.004609
2017/08/29 23:55:43 step 6: objective=10.527318 reg=0.004609
2017/08/29 23:55:44 step 7: objective=10.542668 reg=0.004609
2017/08/29 23:55:44 Training value function...
2017/08/29 23:55:46 step 0: mse=15224.587565 step=0.050000
2017/08/29 23:55:47 step 1: mse=15068.463059 step=0.050000
2017/08/29 23:55:48 step 2: mse=14938.094437 step=0.050000
2017/08/29 23:55:49 step 3: mse=14831.414479 step=0.050000
2017/08/29 23:55:49 step 4: mse=14743.617565 step=0.050000
2017/08/29 23:55:50 step 5: mse=14668.018502 step=0.050000
2017/08/29 23:55:51 step 6: mse=14603.610011 step=0.050000
2017/08/29 23:55:52 step 7: mse=14551.299059 step=0.050000
2017/08/29 23:55:52 Saving...
2017/08/29 23:55:52 Gathering batch of experience...
2017/08/29 23:56:16 batch 375: mean=1978.953488 stddev=2850.463356 entropy=0.459112 frames=5425 count=43
2017/08/29 23:56:16 Training policy...
2017/08/29 23:56:20 tune 0: objective=37.978684 reg=0.004591 prune=0
2017/08/29 23:56:21 step 0: objective=38.041233 reg=0.004591
2017/08/29 23:56:22 step 1: objective=38.208505 reg=0.004592
2017/08/29 23:56:23 step 2: objective=38.321132 reg=0.004592
2017/08/29 23:56:24 step 3: objective=38.406898 reg=0.004591
2017/08/29 23:56:25 step 4: objective=38.449294 reg=0.004591
2017/08/29 23:56:26 step 5: objective=38.535979 reg=0.004591
2017/08/29 23:56:27 step 6: objective=38.583214 reg=0.004590
2017/08/29 23:56:28 step 7: objective=38.680204 reg=0.004588
2017/08/29 23:56:28 Training value function...
2017/08/29 23:56:30 step 0: mse=162233.682167 step=0.050000
2017/08/29 23:56:31 step 1: mse=160269.415125 step=0.050000
2017/08/29 23:56:32 step 2: mse=159721.619411 step=0.050000
2017/08/29 23:56:33 step 3: mse=158259.121665 step=0.050000
2017/08/29 23:56:34 step 4: mse=157481.180569 step=0.050000
2017/08/29 23:56:34 step 5: mse=156218.505685 step=0.050000
2017/08/29 23:56:35 step 6: mse=155934.979011 step=0.050000
2017/08/29 23:56:36 step 7: mse=155745.359459 step=0.050000
2017/08/29 23:56:36 Saving...
2017/08/29 23:56:36 Gathering batch of experience...
2017/08/29 23:57:03 batch 376: mean=3095.394737 stddev=5007.138638 entropy=0.464871 frames=5818 count=38
2017/08/29 23:57:03 Training policy...
2017/08/29 23:57:06 tune 0: objective=74.958394 reg=0.004649 prune=0
2017/08/29 23:57:07 step 0: objective=75.137032 reg=0.004652
2017/08/29 23:57:09 step 1: objective=75.569021 reg=0.004656
2017/08/29 23:57:10 step 2: objective=75.720114 reg=0.004660
2017/08/29 23:57:11 step 3: objective=75.800834 reg=0.004661
2017/08/29 23:57:12 step 4: objective=75.903887 reg=0.004662
2017/08/29 23:57:13 step 5: objective=76.043223 reg=0.004661
2017/08/29 23:57:14 step 6: objective=76.195885 reg=0.004659
2017/08/29 23:57:15 step 7: objective=76.345034 reg=0.004658
2017/08/29 23:57:15 Training value function...
2017/08/29 23:57:17 step 0: mse=376858.649570 step=0.050000
2017/08/29 23:57:18 step 1: mse=367532.400752 step=0.050000
2017/08/29 23:57:19 step 2: mse=362340.520350 step=0.050000
2017/08/29 23:57:20 step 3: mse=351875.058005 step=0.050000
2017/08/29 23:57:21 step 4: mse=339024.243555 step=0.050000
2017/08/29 23:57:22 step 5: mse=332485.221103 step=0.050000
2017/08/29 23:57:23 step 6: mse=324200.394583 step=0.050000
2017/08/29 23:57:24 step 7: mse=315800.397946 step=0.050000
2017/08/29 23:57:24 Saving...
2017/08/29 23:57:24 Gathering batch of experience...
2017/08/29 23:57:48 batch 377: mean=1599.318182 stddev=932.012480 entropy=0.460347 frames=5220 count=44
2017/08/29 23:57:48 Training policy...
2017/08/29 23:57:51 tune 0: objective=8.617122 reg=0.004603 prune=0
2017/08/29 23:57:52 step 0: objective=8.628251 reg=0.004603
2017/08/29 23:57:53 step 1: objective=8.647433 reg=0.004602
2017/08/29 23:57:54 step 2: objective=8.669108 reg=0.004602
2017/08/29 23:57:55 step 3: objective=8.693263 reg=0.004601
2017/08/29 23:57:56 step 4: objective=8.723875 reg=0.004600
2017/08/29 23:57:57 step 5: objective=8.742807 reg=0.004600
2017/08/29 23:57:58 step 6: objective=8.758114 reg=0.004599
2017/08/29 23:57:59 step 7: objective=8.781052 reg=0.004599
2017/08/29 23:57:59 Training value function...
2017/08/29 23:58:01 step 0: mse=20135.772563 step=0.050000
2017/08/29 23:58:02 step 1: mse=19793.389193 step=0.050000
2017/08/29 23:58:03 step 2: mse=19512.624710 step=0.050000
2017/08/29 23:58:04 step 3: mse=19269.803679 step=0.050000
2017/08/29 23:58:05 step 4: mse=19061.084071 step=0.050000
2017/08/29 23:58:05 step 5: mse=18898.272295 step=0.050000
2017/08/29 23:58:06 step 6: mse=18751.052739 step=0.050000
2017/08/29 23:58:07 step 7: mse=18617.583227 step=0.050000
2017/08/29 23:58:07 Saving...
2017/08/29 23:58:07 Gathering batch of experience...
2017/08/29 23:58:30 batch 378: mean=2158.421053 stddev=2766.302183 entropy=0.464133 frames=5126 count=38
2017/08/29 23:58:30 Training policy...
2017/08/29 23:58:33 tune 0: objective=28.425591 reg=0.004641 prune=0
2017/08/29 23:58:34 step 0: objective=28.484338 reg=0.004641
2017/08/29 23:58:35 step 1: objective=28.582886 reg=0.004639
2017/08/29 23:58:36 step 2: objective=28.787026 reg=0.004639
2017/08/29 23:58:37 step 3: objective=28.940460 reg=0.004639
2017/08/29 23:58:38 step 4: objective=29.004097 reg=0.004638
2017/08/29 23:58:39 step 5: objective=29.071934 reg=0.004637
2017/08/29 23:58:40 step 6: objective=29.122702 reg=0.004636
2017/08/29 23:58:41 step 7: objective=29.186805 reg=0.004635
2017/08/29 23:58:41 Training value function...
2017/08/29 23:58:43 step 0: mse=146162.089132 step=0.050000
2017/08/29 23:58:44 step 1: mse=143220.425110 step=0.050000
2017/08/29 23:58:45 step 2: mse=142810.178846 step=0.050000
2017/08/29 23:58:45 step 3: mse=142689.864502 step=0.050000
2017/08/29 23:58:46 step 4: mse=141804.959648 step=0.050000
2017/08/29 23:58:47 step 5: mse=140701.180946 step=0.050000
2017/08/29 23:58:48 step 6: mse=140250.890907 step=0.050000
2017/08/29 23:58:49 step 7: mse=139218.483196 step=0.050000
2017/08/29 23:58:49 Saving...
2017/08/29 23:58:49 Gathering batch of experience...
2017/08/29 23:59:17 batch 379: mean=2387.441860 stddev=3894.385400 entropy=0.467033 frames=5639 count=43
2017/08/29 23:59:17 Training policy...
2017/08/29 23:59:20 tune 0: objective=46.575994 reg=0.004670 prune=0
2017/08/29 23:59:21 step 0: objective=46.653762 reg=0.004669
2017/08/29 23:59:22 step 1: objective=46.765140 reg=0.004669
2017/08/29 23:59:24 step 2: objective=46.835476 reg=0.004668
2017/08/29 23:59:25 step 3: objective=46.909342 reg=0.004668
2017/08/29 23:59:26 step 4: objective=47.058975 reg=0.004666
2017/08/29 23:59:27 step 5: objective=47.184469 reg=0.004664
2017/08/29 23:59:28 step 6: objective=47.241787 reg=0.004664
2017/08/29 23:59:29 step 7: objective=47.348122 reg=0.004661
2017/08/29 23:59:29 Training value function...
2017/08/29 23:59:31 step 0: mse=245334.742690 step=0.050000
2017/08/29 23:59:32 step 1: mse=242224.205463 step=0.050000
2017/08/29 23:59:33 step 2: mse=239911.902983 step=0.050000
2017/08/29 23:59:34 step 3: mse=236685.840633 step=0.050000
2017/08/29 23:59:35 step 4: mse=234459.107581 step=0.050000
2017/08/29 23:59:35 step 5: mse=228351.868172 step=0.050000
2017/08/29 23:59:36 step 6: mse=225551.211363 step=0.050000
2017/08/29 23:59:37 step 7: mse=224299.485001 step=0.050000
2017/08/29 23:59:37 Saving...
2017/08/29 23:59:37 Gathering batch of experience...
2017/08/30 00:00:04 batch 380: mean=2043.902439 stddev=2836.676283 entropy=0.459921 frames=5371 count=41
2017/08/30 00:00:04 Training policy...
2017/08/30 00:00:07 tune 0: objective=31.237598 reg=0.004599 prune=0
2017/08/30 00:00:08 step 0: objective=31.274896 reg=0.004598
2017/08/30 00:00:09 step 1: objective=31.322857 reg=0.004597
2017/08/30 00:00:10 step 2: objective=31.359727 reg=0.004597
2017/08/30 00:00:11 step 3: objective=31.410701 reg=0.004597
2017/08/30 00:00:12 step 4: objective=31.448299 reg=0.004597
2017/08/30 00:00:13 step 5: objective=31.502732 reg=0.004597
2017/08/30 00:00:14 step 6: objective=31.552914 reg=0.004596
2017/08/30 00:00:15 step 7: objective=31.597593 reg=0.004596
2017/08/30 00:00:15 Training value function...
2017/08/30 00:00:17 step 0: mse=123826.595937 step=0.050000
2017/08/30 00:00:18 step 1: mse=123667.368739 step=0.050000
2017/08/30 00:00:19 step 2: mse=123513.870807 step=0.050000
2017/08/30 00:00:20 step 3: mse=123627.008584 step=0.050000
2017/08/30 00:00:21 step 4: mse=123756.478656 step=0.050000
2017/08/30 00:00:21 step 5: mse=123752.389180 step=0.050000
2017/08/30 00:00:22 step 6: mse=123628.802883 step=0.050000
2017/08/30 00:00:23 step 7: mse=122027.789070 step=0.050000
2017/08/30 00:00:23 Saving...
2017/08/30 00:00:23 Gathering batch of experience...
2017/08/30 00:00:51 batch 381: mean=1946.022727 stddev=2785.512353 entropy=0.456359 frames=5515 count=44
2017/08/30 00:00:51 Training policy...
2017/08/30 00:00:55 tune 0: objective=29.580984 reg=0.004564 prune=0
2017/08/30 00:00:56 step 0: objective=29.616812 reg=0.004563
2017/08/30 00:00:57 step 1: objective=29.646753 reg=0.004562
2017/08/30 00:00:58 step 2: objective=29.696864 reg=0.004561
2017/08/30 00:00:59 step 3: objective=29.727445 reg=0.004561
2017/08/30 00:01:00 step 4: objective=29.767886 reg=0.004561
2017/08/30 00:01:01 step 5: objective=29.801689 reg=0.004561
2017/08/30 00:01:02 step 6: objective=29.838874 reg=0.004560
2017/08/30 00:01:03 step 7: objective=29.871090 reg=0.004560
2017/08/30 00:01:03 Training value function...
2017/08/30 00:01:05 step 0: mse=113012.162859 step=0.050000
2017/08/30 00:01:06 step 1: mse=112675.277709 step=0.050000
2017/08/30 00:01:07 step 2: mse=112109.524752 step=0.050000
2017/08/30 00:01:08 step 3: mse=111827.819265 step=0.050000
2017/08/30 00:01:09 step 4: mse=111624.036305 step=0.050000
2017/08/30 00:01:10 step 5: mse=111089.035054 step=0.050000
2017/08/30 00:01:10 step 6: mse=111144.547937 step=0.050000
2017/08/30 00:01:11 step 7: mse=110561.484584 step=0.050000
2017/08/30 00:01:11 Saving...
2017/08/30 00:01:11 Gathering batch of experience...
2017/08/30 00:01:35 batch 382: mean=1992.682927 stddev=2936.946958 entropy=0.457181 frames=5134 count=41
2017/08/30 00:01:35 Training policy...
2017/08/30 00:01:38 tune 0: objective=33.264618 reg=0.004572 prune=0
2017/08/30 00:01:39 step 0: objective=33.329668 reg=0.004572
2017/08/30 00:01:40 step 1: objective=33.432281 reg=0.004572
2017/08/30 00:01:41 step 2: objective=33.506988 reg=0.004573
2017/08/30 00:01:42 step 3: objective=33.598619 reg=0.004571
2017/08/30 00:01:43 step 4: objective=33.648900 reg=0.004571
2017/08/30 00:01:44 step 5: objective=33.699391 reg=0.004571
2017/08/30 00:01:45 step 6: objective=33.753351 reg=0.004569
2017/08/30 00:01:46 step 7: objective=33.804971 reg=0.004568
2017/08/30 00:01:46 Training value function...
2017/08/30 00:01:48 step 0: mse=137823.417210 step=0.050000
2017/08/30 00:01:49 step 1: mse=136739.716663 step=0.050000
2017/08/30 00:01:49 step 2: mse=136590.364168 step=0.050000
2017/08/30 00:01:50 step 3: mse=136660.852045 step=0.050000
2017/08/30 00:01:51 step 4: mse=136452.300706 step=0.050000
2017/08/30 00:01:52 step 5: mse=135265.281900 step=0.050000
2017/08/30 00:01:53 step 6: mse=134293.891651 step=0.050000
2017/08/30 00:01:53 step 7: mse=134400.193533 step=0.050000
2017/08/30 00:01:53 Saving...
2017/08/30 00:01:53 Gathering batch of experience...
2017/08/30 00:02:20 batch 383: mean=2239.642857 stddev=3799.946960 entropy=0.462350 frames=5199 count=42
2017/08/30 00:02:20 Training policy...
2017/08/30 00:02:23 tune 0: objective=42.891307 reg=0.004624 prune=0
2017/08/30 00:02:24 step 0: objective=42.990419 reg=0.004622
2017/08/30 00:02:25 step 1: objective=43.105098 reg=0.004620
2017/08/30 00:02:26 step 2: objective=43.245501 reg=0.004620
2017/08/30 00:02:27 step 3: objective=43.378480 reg=0.004620
2017/08/30 00:02:28 step 4: objective=43.573524 reg=0.004614
2017/08/30 00:02:29 step 5: objective=43.668088 reg=0.004611
2017/08/30 00:02:30 step 6: objective=43.770422 reg=0.004608
2017/08/30 00:02:31 step 7: objective=43.878982 reg=0.004604
2017/08/30 00:02:31 Training value function...
2017/08/30 00:02:33 step 0: mse=249778.038135 step=0.050000
2017/08/30 00:02:34 step 1: mse=248063.652057 step=0.050000
2017/08/30 00:02:34 step 2: mse=246843.167650 step=0.050000
2017/08/30 00:02:35 step 3: mse=244977.696927 step=0.050000
2017/08/30 00:02:36 step 4: mse=243567.307641 step=0.050000
2017/08/30 00:02:37 step 5: mse=241934.811699 step=0.050000
2017/08/30 00:02:38 step 6: mse=241077.576562 step=0.050000
2017/08/30 00:02:39 step 7: mse=237526.212788 step=0.050000
2017/08/30 00:02:39 Saving...
2017/08/30 00:02:39 Gathering batch of experience...
2017/08/30 00:03:03 batch 384: mean=1602.558140 stddev=615.288146 entropy=0.450715 frames=5195 count=43
2017/08/30 00:03:03 Training policy...
2017/08/30 00:03:06 tune 0: objective=7.383782 reg=0.004507 prune=0
2017/08/30 00:03:07 step 0: objective=7.403472 reg=0.004507
2017/08/30 00:03:08 step 1: objective=7.433905 reg=0.004506
2017/08/30 00:03:09 step 2: objective=7.468872 reg=0.004505
2017/08/30 00:03:10 step 3: objective=7.498139 reg=0.004505
2017/08/30 00:03:11 step 4: objective=7.530422 reg=0.004505
2017/08/30 00:03:12 step 5: objective=7.564027 reg=0.004504
2017/08/30 00:03:13 step 6: objective=7.594554 reg=0.004504
2017/08/30 00:03:14 step 7: objective=7.612605 reg=0.004503
2017/08/30 00:03:14 Training value function...
2017/08/30 00:03:16 step 0: mse=21042.590341 step=0.050000
2017/08/30 00:03:17 step 1: mse=20496.407257 step=0.050000
2017/08/30 00:03:17 step 2: mse=19945.806229 step=0.050000
2017/08/30 00:03:18 step 3: mse=19436.990317 step=0.050000
2017/08/30 00:03:19 step 4: mse=19070.037780 step=0.050000
2017/08/30 00:03:20 step 5: mse=18691.852944 step=0.050000
2017/08/30 00:03:21 step 6: mse=18387.355324 step=0.050000
2017/08/30 00:03:21 step 7: mse=18049.133348 step=0.050000
2017/08/30 00:03:21 Saving...
2017/08/30 00:03:21 Gathering batch of experience...
2017/08/30 00:03:46 batch 385: mean=2082.317073 stddev=2935.650943 entropy=0.451258 frames=5395 count=41
2017/08/30 00:03:46 Training policy...
2017/08/30 00:03:49 tune 0: objective=36.569248 reg=0.004513 prune=0
2017/08/30 00:03:50 step 0: objective=36.588378 reg=0.004511
2017/08/30 00:03:51 step 1: objective=36.622981 reg=0.004511
2017/08/30 00:03:52 step 2: objective=36.657941 reg=0.004511
2017/08/30 00:03:53 step 3: objective=36.701657 reg=0.004510
2017/08/30 00:03:54 step 4: objective=36.731899 reg=0.004509
2017/08/30 00:03:55 step 5: objective=36.761611 reg=0.004509
2017/08/30 00:03:56 step 6: objective=36.787248 reg=0.004509
2017/08/30 00:03:57 step 7: objective=36.816256 reg=0.004508
2017/08/30 00:03:57 Training value function...
2017/08/30 00:03:59 step 0: mse=120335.569904 step=0.050000
2017/08/30 00:04:00 step 1: mse=119978.193661 step=0.050000
2017/08/30 00:04:01 step 2: mse=119621.389525 step=0.050000
2017/08/30 00:04:02 step 3: mse=119235.311311 step=0.050000
2017/08/30 00:04:03 step 4: mse=118987.714504 step=0.050000
2017/08/30 00:04:04 step 5: mse=118802.352066 step=0.050000
2017/08/30 00:04:04 step 6: mse=118724.378591 step=0.050000
2017/08/30 00:04:05 step 7: mse=118508.863133 step=0.050000
2017/08/30 00:04:05 Saving...
2017/08/30 00:04:05 Gathering batch of experience...
2017/08/30 00:04:29 batch 386: mean=1485.568182 stddev=587.085653 entropy=0.450721 frames=5020 count=44
2017/08/30 00:04:29 Training policy...
2017/08/30 00:04:32 tune 0: objective=9.738698 reg=0.004507 prune=0
2017/08/30 00:04:33 step 0: objective=9.745519 reg=0.004507
2017/08/30 00:04:34 step 1: objective=9.756350 reg=0.004506
2017/08/30 00:04:35 step 2: objective=9.765834 reg=0.004506
2017/08/30 00:04:36 step 3: objective=9.776668 reg=0.004505
2017/08/30 00:04:37 step 4: objective=9.789118 reg=0.004505
2017/08/30 00:04:37 step 5: objective=9.800700 reg=0.004504
2017/08/30 00:04:38 step 6: objective=9.809080 reg=0.004504
2017/08/30 00:04:39 step 7: objective=9.820804 reg=0.004503
2017/08/30 00:04:39 Training value function...
2017/08/30 00:04:41 step 0: mse=12237.885428 step=0.050000
2017/08/30 00:04:42 step 1: mse=12164.252432 step=0.050000
2017/08/30 00:04:43 step 2: mse=12126.316678 step=0.050000
2017/08/30 00:04:44 step 3: mse=12085.983596 step=0.050000
2017/08/30 00:04:44 step 4: mse=12060.466112 step=0.050000
2017/08/30 00:04:45 step 5: mse=12038.549452 step=0.050000
2017/08/30 00:04:46 step 6: mse=12022.939904 step=0.050000
2017/08/30 00:04:47 step 7: mse=12020.242269 step=0.050000
2017/08/30 00:04:47 Saving...
2017/08/30 00:04:47 Gathering batch of experience...
2017/08/30 00:05:11 batch 387: mean=1846.538462 stddev=780.918389 entropy=0.455696 frames=5232 count=39
2017/08/30 00:05:11 Training policy...
2017/08/30 00:05:14 tune 0: objective=22.202231 reg=0.004557 prune=0
2017/08/30 00:05:15 step 0: objective=22.241057 reg=0.004556
2017/08/30 00:05:16 step 1: objective=22.313078 reg=0.004556
2017/08/30 00:05:17 step 2: objective=22.389545 reg=0.004555
2017/08/30 00:05:18 step 3: objective=22.422557 reg=0.004555
2017/08/30 00:05:19 step 4: objective=22.463731 reg=0.004556
2017/08/30 00:05:20 step 5: objective=22.510469 reg=0.004555
2017/08/30 00:05:21 step 6: objective=22.530723 reg=0.004556
2017/08/30 00:05:22 step 7: objective=22.552609 reg=0.004556
2017/08/30 00:05:22 Training value function...
2017/08/30 00:05:24 step 0: mse=29232.852950 step=0.050000
2017/08/30 00:05:25 step 1: mse=27835.444473 step=0.050000
2017/08/30 00:05:26 step 2: mse=26648.557782 step=0.050000
2017/08/30 00:05:26 step 3: mse=25719.857580 step=0.050000
2017/08/30 00:05:27 step 4: mse=24644.572373 step=0.050000
2017/08/30 00:05:28 step 5: mse=23782.380176 step=0.050000
2017/08/30 00:05:29 step 6: mse=23012.428540 step=0.050000
2017/08/30 00:05:30 step 7: mse=22322.648764 step=0.050000
2017/08/30 00:05:30 Saving...
2017/08/30 00:05:30 Gathering batch of experience...
2017/08/30 00:05:53 batch 388: mean=2063.205128 stddev=3041.050233 entropy=0.450869 frames=5082 count=39
2017/08/30 00:05:53 Training policy...
2017/08/30 00:05:56 tune 0: objective=40.248663 reg=0.004509 prune=0
2017/08/30 00:05:57 step 0: objective=40.308540 reg=0.004509
2017/08/30 00:05:58 step 1: objective=40.367492 reg=0.004508
2017/08/30 00:05:59 step 2: objective=40.478478 reg=0.004506
2017/08/30 00:06:00 step 3: objective=40.539016 reg=0.004504
2017/08/30 00:06:01 step 4: objective=40.574128 reg=0.004504
2017/08/30 00:06:02 step 5: objective=40.629716 reg=0.004504
2017/08/30 00:06:03 step 6: objective=40.660478 reg=0.004504
2017/08/30 00:06:04 step 7: objective=40.695780 reg=0.004504
2017/08/30 00:06:04 Training value function...
2017/08/30 00:06:06 step 0: mse=155291.830547 step=0.050000
2017/08/30 00:06:06 step 1: mse=154111.307844 step=0.050000
2017/08/30 00:06:07 step 2: mse=152992.795213 step=0.050000
2017/08/30 00:06:08 step 3: mse=151996.107853 step=0.050000
2017/08/30 00:06:09 step 4: mse=151035.337001 step=0.050000
2017/08/30 00:06:10 step 5: mse=150285.543814 step=0.050000
2017/08/30 00:06:10 step 6: mse=149536.000617 step=0.050000
2017/08/30 00:06:11 step 7: mse=148793.383192 step=0.050000
2017/08/30 00:06:11 Saving...
2017/08/30 00:06:11 Gathering batch of experience...
2017/08/30 00:06:35 batch 389: mean=1684.634146 stddev=547.642832 entropy=0.449012 frames=5198 count=41
2017/08/30 00:06:35 Training policy...
2017/08/30 00:06:38 tune 0: objective=17.252678 reg=0.004490 prune=0
2017/08/30 00:06:39 step 0: objective=17.259804 reg=0.004490
2017/08/30 00:06:40 step 1: objective=17.268000 reg=0.004490
2017/08/30 00:06:41 step 2: objective=17.279095 reg=0.004490
2017/08/30 00:06:42 step 3: objective=17.288825 reg=0.004490
2017/08/30 00:06:43 step 4: objective=17.297897 reg=0.004490
2017/08/30 00:06:44 step 5: objective=17.317056 reg=0.004490
2017/08/30 00:06:45 step 6: objective=17.326559 reg=0.004490
2017/08/30 00:06:46 step 7: objective=17.335365 reg=0.004490
2017/08/30 00:06:46 Training value function...
2017/08/30 00:06:48 step 0: mse=14308.249447 step=0.050000
2017/08/30 00:06:49 step 1: mse=14087.731721 step=0.050000
2017/08/30 00:06:49 step 2: mse=13902.340416 step=0.050000
2017/08/30 00:06:50 step 3: mse=13718.313917 step=0.050000
2017/08/30 00:06:51 step 4: mse=13515.045999 step=0.050000
2017/08/30 00:06:52 step 5: mse=13331.535639 step=0.050000
2017/08/30 00:06:53 step 6: mse=13178.329150 step=0.050000
2017/08/30 00:06:53 step 7: mse=13053.399603 step=0.050000
2017/08/30 00:06:53 Saving...
2017/08/30 00:06:54 Gathering batch of experience...
2017/08/30 00:07:18 batch 390: mean=2020.357143 stddev=2773.737249 entropy=0.448697 frames=5403 count=42
2017/08/30 00:07:18 Training policy...
2017/08/30 00:07:22 tune 0: objective=38.417962 reg=0.004487 prune=0
2017/08/30 00:07:23 step 0: objective=38.447055 reg=0.004486
2017/08/30 00:07:24 step 1: objective=38.476607 reg=0.004486
2017/08/30 00:07:25 step 2: objective=38.522444 reg=0.004485
2017/08/30 00:07:26 step 3: objective=38.554385 reg=0.004485
2017/08/30 00:07:27 step 4: objective=38.587049 reg=0.004484
2017/08/30 00:07:28 step 5: objective=38.614537 reg=0.004484
2017/08/30 00:07:29 step 6: objective=38.663575 reg=0.004483
2017/08/30 00:07:30 step 7: objective=38.699299 reg=0.004483
2017/08/30 00:07:30 Training value function...
2017/08/30 00:07:32 step 0: mse=133124.805270 step=0.050000
2017/08/30 00:07:33 step 1: mse=132300.251756 step=0.050000
2017/08/30 00:07:33 step 2: mse=131723.332665 step=0.050000
2017/08/30 00:07:34 step 3: mse=130738.526194 step=0.050000
2017/08/30 00:07:35 step 4: mse=129709.541529 step=0.050000
2017/08/30 00:07:36 step 5: mse=129068.852406 step=0.050000
2017/08/30 00:07:37 step 6: mse=128742.145520 step=0.050000
2017/08/30 00:07:38 step 7: mse=128307.925681 step=0.050000
2017/08/30 00:07:38 Saving...
2017/08/30 00:07:38 Gathering batch of experience...
2017/08/30 00:08:06 batch 391: mean=2254.431818 stddev=3616.712504 entropy=0.460523 frames=5666 count=44
2017/08/30 00:08:06 Training policy...
2017/08/30 00:08:09 tune 0: objective=47.717923 reg=0.004605 prune=0
2017/08/30 00:08:10 step 0: objective=47.814044 reg=0.004605
2017/08/30 00:08:11 step 1: objective=47.936160 reg=0.004604
2017/08/30 00:08:12 step 2: objective=48.062379 reg=0.004604
2017/08/30 00:08:13 step 3: objective=48.163652 reg=0.004603
2017/08/30 00:08:15 step 4: objective=48.239306 reg=0.004602
2017/08/30 00:08:16 step 5: objective=48.305948 reg=0.004600
2017/08/30 00:08:17 step 6: objective=48.387636 reg=0.004598
2017/08/30 00:08:18 step 7: objective=48.464658 reg=0.004597
2017/08/30 00:08:18 Training value function...
2017/08/30 00:08:20 step 0: mse=250056.945612 step=0.050000
2017/08/30 00:08:21 step 1: mse=244079.170267 step=0.050000
2017/08/30 00:08:22 step 2: mse=237573.547156 step=0.050000
2017/08/30 00:08:23 step 3: mse=235188.538284 step=0.050000
2017/08/30 00:08:24 step 4: mse=233240.090437 step=0.050000
2017/08/30 00:08:24 step 5: mse=231397.351383 step=0.050000
2017/08/30 00:08:25 step 6: mse=227623.574041 step=0.050000
2017/08/30 00:08:26 step 7: mse=224193.336584 step=0.050000
2017/08/30 00:08:26 Saving...
2017/08/30 00:08:26 Gathering batch of experience...
2017/08/30 00:08:49 batch 392: mean=1526.627907 stddev=494.402059 entropy=0.443673 frames=4991 count=43
2017/08/30 00:08:49 Training policy...
2017/08/30 00:08:52 tune 0: objective=8.239934 reg=0.004437 prune=0
2017/08/30 00:08:53 step 0: objective=8.247045 reg=0.004436
2017/08/30 00:08:54 step 1: objective=8.257834 reg=0.004436
2017/08/30 00:08:55 step 2: objective=8.268680 reg=0.004436
2017/08/30 00:08:56 step 3: objective=8.282721 reg=0.004436
2017/08/30 00:08:57 step 4: objective=8.294100 reg=0.004436
2017/08/30 00:08:58 step 5: objective=8.306384 reg=0.004436
2017/08/30 00:08:59 step 6: objective=8.318660 reg=0.004436
2017/08/30 00:09:00 step 7: objective=8.332419 reg=0.004436
2017/08/30 00:09:00 Training value function...
2017/08/30 00:09:02 step 0: mse=10910.435615 step=0.050000
2017/08/30 00:09:03 step 1: mse=10856.537551 step=0.050000
2017/08/30 00:09:03 step 2: mse=10814.296354 step=0.050000
2017/08/30 00:09:04 step 3: mse=10798.232324 step=0.050000
2017/08/30 00:09:05 step 4: mse=10790.947017 step=0.050000
2017/08/30 00:09:06 step 5: mse=10793.692960 step=0.050000
2017/08/30 00:09:06 step 6: mse=10803.240115 step=0.050000
2017/08/30 00:09:07 step 7: mse=10828.511346 step=0.050000
2017/08/30 00:09:07 Saving...
2017/08/30 00:09:07 Gathering batch of experience...
2017/08/30 00:09:33 batch 393: mean=2411.447368 stddev=3039.338334 entropy=0.454902 frames=5597 count=38
2017/08/30 00:09:33 Training policy...
2017/08/30 00:09:37 tune 0: objective=39.877984 reg=0.004549 prune=0
2017/08/30 00:09:38 step 0: objective=39.935635 reg=0.004547
2017/08/30 00:09:39 step 1: objective=40.000045 reg=0.004546
2017/08/30 00:09:40 step 2: objective=40.079713 reg=0.004547
2017/08/30 00:09:41 step 3: objective=40.157797 reg=0.004546
2017/08/30 00:09:42 step 4: objective=40.213100 reg=0.004545
2017/08/30 00:09:43 step 5: objective=40.258020 reg=0.004544
2017/08/30 00:09:44 step 6: objective=40.300013 reg=0.004544
2017/08/30 00:09:45 step 7: objective=40.345492 reg=0.004545
2017/08/30 00:09:45 Training value function...
2017/08/30 00:09:47 step 0: mse=134993.658617 step=0.050000
2017/08/30 00:09:48 step 1: mse=133277.803169 step=0.050000
2017/08/30 00:09:49 step 2: mse=132942.387639 step=0.050000
2017/08/30 00:09:50 step 3: mse=131497.594680 step=0.050000
2017/08/30 00:09:51 step 4: mse=130387.175796 step=0.050000
2017/08/30 00:09:52 step 5: mse=128843.215492 step=0.050000
2017/08/30 00:09:53 step 6: mse=127424.237209 step=0.050000
2017/08/30 00:09:53 step 7: mse=125639.383177 step=0.050000
2017/08/30 00:09:53 Saving...
2017/08/30 00:09:54 Gathering batch of experience...
2017/08/30 00:10:17 batch 394: mean=1582.500000 stddev=650.585130 entropy=0.454194 frames=5079 count=42
2017/08/30 00:10:17 Training policy...
2017/08/30 00:10:20 tune 0: objective=13.340215 reg=0.004542 prune=0
2017/08/30 00:10:21 step 0: objective=13.362488 reg=0.004542
2017/08/30 00:10:22 step 1: objective=13.382819 reg=0.004542
2017/08/30 00:10:23 step 2: objective=13.405738 reg=0.004541
2017/08/30 00:10:24 step 3: objective=13.425179 reg=0.004541
2017/08/30 00:10:25 step 4: objective=13.446709 reg=0.004540
2017/08/30 00:10:26 step 5: objective=13.472006 reg=0.004540
2017/08/30 00:10:27 step 6: objective=13.488876 reg=0.004540
2017/08/30 00:10:28 step 7: objective=13.503341 reg=0.004539
2017/08/30 00:10:28 Training value function...
2017/08/30 00:10:30 step 0: mse=15458.187214 step=0.050000
2017/08/30 00:10:31 step 1: mse=15141.129527 step=0.050000
2017/08/30 00:10:31 step 2: mse=14853.916040 step=0.050000
2017/08/30 00:10:32 step 3: mse=14600.194197 step=0.050000
2017/08/30 00:10:33 step 4: mse=14374.969264 step=0.050000
2017/08/30 00:10:34 step 5: mse=14190.944557 step=0.050000
2017/08/30 00:10:35 step 6: mse=14020.676251 step=0.050000
2017/08/30 00:10:35 step 7: mse=13871.440984 step=0.050000
2017/08/30 00:10:35 Saving...
2017/08/30 00:10:35 Gathering batch of experience...
2017/08/30 00:10:58 batch 395: mean=1519.166667 stddev=517.018601 entropy=0.446110 frames=4889 count=42
2017/08/30 00:10:58 Training policy...
2017/08/30 00:11:01 tune 0: objective=13.709472 reg=0.004461 prune=0
2017/08/30 00:11:02 step 0: objective=13.719218 reg=0.004460
2017/08/30 00:11:03 step 1: objective=13.737975 reg=0.004460
2017/08/30 00:11:04 step 2: objective=13.753851 reg=0.004459
2017/08/30 00:11:05 step 3: objective=13.771459 reg=0.004458
2017/08/30 00:11:06 step 4: objective=13.793842 reg=0.004457
2017/08/30 00:11:07 step 5: objective=13.811364 reg=0.004457
2017/08/30 00:11:08 step 6: objective=13.831495 reg=0.004456
2017/08/30 00:11:09 step 7: objective=13.853416 reg=0.004455
2017/08/30 00:11:09 Training value function...
2017/08/30 00:11:11 step 0: mse=11061.618490 step=0.050000
2017/08/30 00:11:11 step 1: mse=11058.841995 step=0.050000
2017/08/30 00:11:12 step 2: mse=11064.404207 step=0.050000
2017/08/30 00:11:13 step 3: mse=11076.460419 step=0.050000
2017/08/30 00:11:14 step 4: mse=11093.794437 step=0.050000
2017/08/30 00:11:14 step 5: mse=11113.822188 step=0.050000
2017/08/30 00:11:15 step 6: mse=11137.121894 step=0.050000
2017/08/30 00:11:16 step 7: mse=11161.294685 step=0.050000
2017/08/30 00:11:16 Saving...
2017/08/30 00:11:16 Gathering batch of experience...
2017/08/30 00:11:39 batch 396: mean=1747.500000 stddev=803.962841 entropy=0.451004 frames=5126 count=40
2017/08/30 00:11:39 Training policy...
2017/08/30 00:11:43 tune 0: objective=28.215196 reg=0.004510 prune=0
2017/08/30 00:11:44 step 0: objective=28.224581 reg=0.004510
2017/08/30 00:11:44 step 1: objective=28.237249 reg=0.004509
2017/08/30 00:11:45 step 2: objective=28.251893 reg=0.004508
2017/08/30 00:11:46 step 3: objective=28.264418 reg=0.004508
2017/08/30 00:11:47 step 4: objective=28.279714 reg=0.004507
2017/08/30 00:11:48 step 5: objective=28.293449 reg=0.004507
2017/08/30 00:11:49 step 6: objective=28.310400 reg=0.004506
2017/08/30 00:11:50 step 7: objective=28.323772 reg=0.004505
2017/08/30 00:11:50 Training value function...
2017/08/30 00:11:52 step 0: mse=18675.371202 step=0.050000
2017/08/30 00:11:53 step 1: mse=18536.427307 step=0.050000
2017/08/30 00:11:54 step 2: mse=18424.672839 step=0.050000
2017/08/30 00:11:55 step 3: mse=18320.519355 step=0.050000
2017/08/30 00:11:56 step 4: mse=18217.193925 step=0.050000
2017/08/30 00:11:56 step 5: mse=18100.781508 step=0.050000
2017/08/30 00:11:57 step 6: mse=17996.406294 step=0.050000
2017/08/30 00:11:58 step 7: mse=17893.078539 step=0.050000
2017/08/30 00:11:58 Saving...
2017/08/30 00:11:58 Gathering batch of experience...
2017/08/30 00:12:26 batch 397: mean=2764.047619 stddev=4765.989409 entropy=0.457631 frames=5776 count=42
2017/08/30 00:12:26 Training policy...
2017/08/30 00:12:30 tune 0: objective=79.431013 reg=0.004576 prune=0
2017/08/30 00:12:31 step 0: objective=79.543223 reg=0.004575
2017/08/30 00:12:32 step 1: objective=79.722397 reg=0.004572
2017/08/30 00:12:33 step 2: objective=79.861361 reg=0.004572
2017/08/30 00:12:34 step 3: objective=79.959774 reg=0.004572
2017/08/30 00:12:35 step 4: objective=80.051647 reg=0.004570
2017/08/30 00:12:36 step 5: objective=80.168277 reg=0.004570
2017/08/30 00:12:37 step 6: objective=80.277744 reg=0.004570
2017/08/30 00:12:38 step 7: objective=80.390474 reg=0.004568
2017/08/30 00:12:38 Training value function...
2017/08/30 00:12:41 step 0: mse=423375.174015 step=0.050000
2017/08/30 00:12:42 step 1: mse=406505.618861 step=0.050000
2017/08/30 00:12:42 step 2: mse=396065.186177 step=0.050000
2017/08/30 00:12:43 step 3: mse=385444.791607 step=0.050000
2017/08/30 00:12:44 step 4: mse=378962.541692 step=0.050000
2017/08/30 00:12:45 step 5: mse=373612.777436 step=0.050000
2017/08/30 00:12:46 step 6: mse=358365.768517 step=0.050000
2017/08/30 00:12:47 step 7: mse=353822.434622 step=0.050000
2017/08/30 00:12:47 Saving...
2017/08/30 00:12:47 Gathering batch of experience...
2017/08/30 00:13:13 batch 398: mean=2081.341463 stddev=2696.561502 entropy=0.450161 frames=5441 count=41
2017/08/30 00:13:13 Training policy...
2017/08/30 00:13:16 tune 0: objective=37.023608 reg=0.004502 prune=0
2017/08/30 00:13:17 step 0: objective=37.066753 reg=0.004501
2017/08/30 00:13:18 step 1: objective=37.119446 reg=0.004502
2017/08/30 00:13:19 step 2: objective=37.172309 reg=0.004503
2017/08/30 00:13:20 step 3: objective=37.221909 reg=0.004502
2017/08/30 00:13:21 step 4: objective=37.265493 reg=0.004503
2017/08/30 00:13:22 step 5: objective=37.319404 reg=0.004501
2017/08/30 00:13:23 step 6: objective=37.353103 reg=0.004501
2017/08/30 00:13:24 step 7: objective=37.403628 reg=0.004500
2017/08/30 00:13:24 Training value function...
2017/08/30 00:13:27 step 0: mse=128178.773981 step=0.050000
2017/08/30 00:13:27 step 1: mse=127882.963782 step=0.050000
2017/08/30 00:13:28 step 2: mse=126918.385606 step=0.050000
2017/08/30 00:13:29 step 3: mse=126323.073081 step=0.050000
2017/08/30 00:13:30 step 4: mse=125784.253535 step=0.050000
2017/08/30 00:13:31 step 5: mse=125646.762620 step=0.050000
2017/08/30 00:13:32 step 6: mse=125393.825107 step=0.050000
2017/08/30 00:13:33 step 7: mse=124419.791665 step=0.050000
2017/08/30 00:13:33 Saving...
2017/08/30 00:13:33 Gathering batch of experience...
2017/08/30 00:14:01 batch 399: mean=3148.717949 stddev=5261.426968 entropy=0.461351 frames=5972 count=39
2017/08/30 00:14:01 Training policy...
2017/08/30 00:14:05 tune 0: objective=73.396753 reg=0.004614 prune=0
2017/08/30 00:14:06 step 0: objective=73.503506 reg=0.004613
2017/08/30 00:14:07 step 1: objective=73.618710 reg=0.004614
2017/08/30 00:14:08 step 2: objective=73.719289 reg=0.004615
2017/08/30 00:14:09 step 3: objective=73.831076 reg=0.004616
2017/08/30 00:14:11 step 4: objective=73.958431 reg=0.004617
2017/08/30 00:14:12 step 5: objective=74.026331 reg=0.004617
2017/08/30 00:14:13 step 6: objective=74.154298 reg=0.004617
2017/08/30 00:14:14 step 7: objective=74.212408 reg=0.004617
2017/08/30 00:14:14 Training value function...
2017/08/30 00:14:16 step 0: mse=351222.363265 step=0.050000
2017/08/30 00:14:17 step 1: mse=345236.170224 step=0.050000
2017/08/30 00:14:18 step 2: mse=339649.242616 step=0.050000
2017/08/30 00:14:19 step 3: mse=333570.912691 step=0.050000
2017/08/30 00:14:20 step 4: mse=327300.609773 step=0.050000
2017/08/30 00:14:21 step 5: mse=317715.826069 step=0.050000
2017/08/30 00:14:22 step 6: mse=313272.439328 step=0.050000
2017/08/30 00:14:23 step 7: mse=302696.144852 step=0.050000
2017/08/30 00:14:23 Saving...
2017/08/30 00:14:23 Gathering batch of experience...
2017/08/30 00:14:49 batch 400: mean=3158.472222 stddev=4973.308453 entropy=0.456408 frames=5577 count=36
2017/08/30 00:14:49 Training policy...
2017/08/30 00:14:53 tune 0: objective=56.292311 reg=0.004564 prune=0
2017/08/30 00:14:54 step 0: objective=56.431712 reg=0.004566
2017/08/30 00:14:55 step 1: objective=56.675363 reg=0.004567
2017/08/30 00:14:56 step 2: objective=56.769937 reg=0.004567
2017/08/30 00:14:57 step 3: objective=56.931387 reg=0.004566
2017/08/30 00:14:58 step 4: objective=57.116175 reg=0.004567
2017/08/30 00:14:59 step 5: objective=57.287318 reg=0.004565
2017/08/30 00:15:00 step 6: objective=57.385170 reg=0.004563
2017/08/30 00:15:01 step 7: objective=57.469417 reg=0.004563
2017/08/30 00:15:01 Training value function...
2017/08/30 00:15:04 step 0: mse=306947.452310 step=0.050000
2017/08/30 00:15:04 step 1: mse=303329.740049 step=0.050000
2017/08/30 00:15:05 step 2: mse=295041.795385 step=0.050000
2017/08/30 00:15:06 step 3: mse=292287.412501 step=0.050000
2017/08/30 00:15:07 step 4: mse=290686.084200 step=0.050000
2017/08/30 00:15:08 step 5: mse=288980.671934 step=0.050000
2017/08/30 00:15:09 step 6: mse=279149.507158 step=0.050000
2017/08/30 00:15:10 step 7: mse=273279.721968 step=0.050000
2017/08/30 00:15:10 Saving...
2017/08/30 00:15:10 Gathering batch of experience...
2017/08/30 00:15:33 batch 401: mean=1971.829268 stddev=2847.518979 entropy=0.453726 frames=5178 count=41
2017/08/30 00:15:33 Training policy...
2017/08/30 00:15:37 tune 0: objective=10.578326 reg=0.004537 prune=0
2017/08/30 00:15:38 step 0: objective=10.646786 reg=0.004536
2017/08/30 00:15:39 step 1: objective=10.746092 reg=0.004536
2017/08/30 00:15:40 step 2: objective=10.825238 reg=0.004535
2017/08/30 00:15:41 step 3: objective=10.909811 reg=0.004535
2017/08/30 00:15:42 step 4: objective=10.968924 reg=0.004535
2017/08/30 00:15:43 step 5: objective=11.048026 reg=0.004536
2017/08/30 00:15:44 step 6: objective=11.088889 reg=0.004534
2017/08/30 00:15:44 step 7: objective=11.143040 reg=0.004533
2017/08/30 00:15:44 Training value function...
2017/08/30 00:15:47 step 0: mse=123678.026446 step=0.050000
2017/08/30 00:15:47 step 1: mse=120946.081967 step=0.050000
2017/08/30 00:15:48 step 2: mse=119324.563405 step=0.050000
2017/08/30 00:15:49 step 3: mse=117358.497506 step=0.050000
2017/08/30 00:15:50 step 4: mse=116044.215083 step=0.050000
2017/08/30 00:15:51 step 5: mse=113840.489686 step=0.050000
2017/08/30 00:15:51 step 6: mse=114003.669464 step=0.050000
2017/08/30 00:15:52 step 7: mse=111832.394536 step=0.050000
2017/08/30 00:15:52 Saving...
2017/08/30 00:15:52 Gathering batch of experience...
2017/08/30 00:16:18 batch 402: mean=1874.651163 stddev=2834.294423 entropy=0.451067 frames=5136 count=43
2017/08/30 00:16:18 Training policy...
2017/08/30 00:16:22 tune 0: objective=16.774178 reg=0.004511 prune=0
2017/08/30 00:16:23 step 0: objective=16.818741 reg=0.004509
2017/08/30 00:16:24 step 1: objective=16.893914 reg=0.004509
2017/08/30 00:16:25 step 2: objective=16.953505 reg=0.004508
2017/08/30 00:16:26 step 3: objective=17.039755 reg=0.004505
2017/08/30 00:16:27 step 4: objective=17.103767 reg=0.004505
2017/08/30 00:16:28 step 5: objective=17.147885 reg=0.004505
2017/08/30 00:16:28 step 6: objective=17.202138 reg=0.004504
2017/08/30 00:16:29 step 7: objective=17.247594 reg=0.004504
2017/08/30 00:16:29 Training value function...
2017/08/30 00:16:31 step 0: mse=113000.251906 step=0.050000
2017/08/30 00:16:32 step 1: mse=112825.263939 step=0.050000
2017/08/30 00:16:33 step 2: mse=113217.017577 step=0.050000
2017/08/30 00:16:34 step 3: mse=113446.015831 step=0.050000
2017/08/30 00:16:35 step 4: mse=113654.582562 step=0.050000
2017/08/30 00:16:36 step 5: mse=113841.358377 step=0.050000
2017/08/30 00:16:36 step 6: mse=114043.008868 step=0.050000
2017/08/30 00:16:37 step 7: mse=113118.218478 step=0.050000
2017/08/30 00:16:37 Saving...
2017/08/30 00:16:37 Gathering batch of experience...
2017/08/30 00:17:01 batch 403: mean=1539.534884 stddev=584.715011 entropy=0.444941 frames=5031 count=43
2017/08/30 00:17:01 Training policy...
2017/08/30 00:17:04 tune 0: objective=10.360120 reg=0.004449 prune=0
2017/08/30 00:17:05 step 0: objective=10.367733 reg=0.004449
2017/08/30 00:17:06 step 1: objective=10.388015 reg=0.004448
2017/08/30 00:17:07 step 2: objective=10.401214 reg=0.004448
2017/08/30 00:17:08 step 3: objective=10.412548 reg=0.004449
2017/08/30 00:17:09 step 4: objective=10.426544 reg=0.004448
2017/08/30 00:17:10 step 5: objective=10.443932 reg=0.004448
2017/08/30 00:17:11 step 6: objective=10.459764 reg=0.004447
2017/08/30 00:17:11 step 7: objective=10.472163 reg=0.004447
2017/08/30 00:17:11 Training value function...
2017/08/30 00:17:14 step 0: mse=13668.197625 step=0.050000
2017/08/30 00:17:14 step 1: mse=13564.710245 step=0.050000
2017/08/30 00:17:15 step 2: mse=13482.672158 step=0.050000
2017/08/30 00:17:16 step 3: mse=13415.519392 step=0.050000
2017/08/30 00:17:17 step 4: mse=13363.402109 step=0.050000
2017/08/30 00:17:17 step 5: mse=13327.639988 step=0.050000
2017/08/30 00:17:18 step 6: mse=13301.219809 step=0.050000
2017/08/30 00:17:19 step 7: mse=13282.352659 step=0.050000
2017/08/30 00:17:19 Saving...
2017/08/30 00:17:19 Gathering batch of experience...
2017/08/30 00:17:46 batch 404: mean=2439.880952 stddev=3924.151332 entropy=0.452372 frames=5742 count=42
2017/08/30 00:17:46 Training policy...
2017/08/30 00:17:50 tune 0: objective=49.680441 reg=0.004524 prune=0
2017/08/30 00:17:51 step 0: objective=49.739491 reg=0.004524
2017/08/30 00:17:52 step 1: objective=49.818927 reg=0.004524
2017/08/30 00:17:53 step 2: objective=49.877220 reg=0.004523
2017/08/30 00:17:54 step 3: objective=49.965757 reg=0.004522
2017/08/30 00:17:55 step 4: objective=50.023734 reg=0.004522
2017/08/30 00:17:56 step 5: objective=50.086087 reg=0.004521
2017/08/30 00:17:57 step 6: objective=50.145425 reg=0.004520
2017/08/30 00:17:58 step 7: objective=50.178150 reg=0.004519
2017/08/30 00:17:58 Training value function...
2017/08/30 00:18:01 step 0: mse=199664.951223 step=0.050000
2017/08/30 00:18:02 step 1: mse=198143.020723 step=0.050000
2017/08/30 00:18:02 step 2: mse=195803.717690 step=0.050000
2017/08/30 00:18:03 step 3: mse=192636.044969 step=0.050000
2017/08/30 00:18:04 step 4: mse=191074.821575 step=0.050000
2017/08/30 00:18:05 step 5: mse=188812.947529 step=0.050000
2017/08/30 00:18:06 step 6: mse=185050.343844 step=0.050000
2017/08/30 00:18:07 step 7: mse=182951.258655 step=0.050000
2017/08/30 00:18:07 Saving...
2017/08/30 00:18:07 Gathering batch of experience...
2017/08/30 00:18:35 batch 405: mean=4168.333333 stddev=6219.022098 entropy=0.463877 frames=5781 count=33
2017/08/30 00:18:35 Training policy...
2017/08/30 00:18:38 tune 0: objective=79.369135 reg=0.004639 prune=0
2017/08/30 00:18:39 step 0: objective=79.501449 reg=0.004638
2017/08/30 00:18:40 step 1: objective=79.613340 reg=0.004636
2017/08/30 00:18:42 step 2: objective=79.834085 reg=0.004634
2017/08/30 00:18:43 step 3: objective=79.966285 reg=0.004632
2017/08/30 00:18:44 step 4: objective=80.066549 reg=0.004631
2017/08/30 00:18:45 step 5: objective=80.218318 reg=0.004630
2017/08/30 00:18:46 step 6: objective=80.288785 reg=0.004630
2017/08/30 00:18:47 step 7: objective=80.462036 reg=0.004628
2017/08/30 00:18:47 Training value function...
2017/08/30 00:18:49 step 0: mse=388654.446820 step=0.050000
2017/08/30 00:18:50 step 1: mse=374641.535078 step=0.050000
2017/08/30 00:18:51 step 2: mse=366587.513293 step=0.050000
2017/08/30 00:18:52 step 3: mse=358690.887097 step=0.050000
2017/08/30 00:18:53 step 4: mse=353250.374486 step=0.050000
2017/08/30 00:18:54 step 5: mse=340714.420131 step=0.050000
2017/08/30 00:18:55 step 6: mse=331286.441216 step=0.050000
2017/08/30 00:18:56 step 7: mse=317958.818009 step=0.050000
2017/08/30 00:18:56 Saving...
2017/08/30 00:18:56 Gathering batch of experience...
2017/08/30 00:19:22 batch 406: mean=2203.375000 stddev=3185.747634 entropy=0.448690 frames=5405 count=40
2017/08/30 00:19:22 Training policy...
2017/08/30 00:19:26 tune 0: objective=23.597580 reg=0.004487 prune=0
2017/08/30 00:19:27 step 0: objective=23.650308 reg=0.004486
2017/08/30 00:19:28 step 1: objective=23.697800 reg=0.004486
2017/08/30 00:19:29 step 2: objective=23.755662 reg=0.004485
2017/08/30 00:19:30 step 3: objective=23.846032 reg=0.004485
2017/08/30 00:19:31 step 4: objective=23.884534 reg=0.004484
2017/08/30 00:19:32 step 5: objective=23.953479 reg=0.004485
2017/08/30 00:19:33 step 6: objective=23.990255 reg=0.004483
2017/08/30 00:19:34 step 7: objective=24.037331 reg=0.004484
2017/08/30 00:19:34 Training value function...
2017/08/30 00:19:36 step 0: mse=97204.681911 step=0.050000
2017/08/30 00:19:37 step 1: mse=97577.330886 step=0.050000
2017/08/30 00:19:38 step 2: mse=98017.212909 step=0.050000
2017/08/30 00:19:38 step 3: mse=98442.226078 step=0.050000
2017/08/30 00:19:39 step 4: mse=98883.480260 step=0.050000
2017/08/30 00:19:40 step 5: mse=99391.139005 step=0.050000
2017/08/30 00:19:41 step 6: mse=99118.886595 step=0.050000
2017/08/30 00:19:42 step 7: mse=99595.354651 step=0.050000
2017/08/30 00:19:42 Saving...
2017/08/30 00:19:42 Gathering batch of experience...
2017/08/30 00:20:08 batch 407: mean=2034.390244 stddev=2819.094344 entropy=0.453844 frames=5344 count=41
2017/08/30 00:20:08 Training policy...
2017/08/30 00:20:12 tune 0: objective=24.790796 reg=0.004538 prune=0
2017/08/30 00:20:13 step 0: objective=24.863582 reg=0.004538
2017/08/30 00:20:14 step 1: objective=24.924398 reg=0.004536
2017/08/30 00:20:15 step 2: objective=24.997819 reg=0.004536
2017/08/30 00:20:16 step 3: objective=25.067892 reg=0.004535
2017/08/30 00:20:17 step 4: objective=25.143616 reg=0.004534
2017/08/30 00:20:18 step 5: objective=25.213858 reg=0.004533
2017/08/30 00:20:19 step 6: objective=25.253357 reg=0.004532
2017/08/30 00:20:20 step 7: objective=25.294659 reg=0.004532
2017/08/30 00:20:20 Training value function...
2017/08/30 00:20:22 step 0: mse=100579.829931 step=0.050000
2017/08/30 00:20:23 step 1: mse=100253.531118 step=0.050000
2017/08/30 00:20:24 step 2: mse=100297.839639 step=0.050000
2017/08/30 00:20:24 step 3: mse=99709.145031 step=0.050000
2017/08/30 00:20:25 step 4: mse=99974.095587 step=0.050000
2017/08/30 00:20:26 step 5: mse=100190.116237 step=0.050000
2017/08/30 00:20:27 step 6: mse=100160.238122 step=0.050000
2017/08/30 00:20:28 step 7: mse=100464.358833 step=0.050000
2017/08/30 00:20:28 Saving...
2017/08/30 00:20:28 Gathering batch of experience...
2017/08/30 00:20:54 batch 408: mean=2098.658537 stddev=2998.940875 entropy=0.445672 frames=5425 count=41
2017/08/30 00:20:54 Training policy...
2017/08/30 00:20:58 tune 0: objective=28.897543 reg=0.004457 prune=0
2017/08/30 00:20:59 step 0: objective=28.945432 reg=0.004457
2017/08/30 00:21:00 step 1: objective=28.988546 reg=0.004457
2017/08/30 00:21:01 step 2: objective=29.037238 reg=0.004456
2017/08/30 00:21:02 step 3: objective=29.078036 reg=0.004455
2017/08/30 00:21:03 step 4: objective=29.132756 reg=0.004454
2017/08/30 00:21:04 step 5: objective=29.164755 reg=0.004454
2017/08/30 00:21:05 step 6: objective=29.224487 reg=0.004453
2017/08/30 00:21:06 step 7: objective=29.266820 reg=0.004453
2017/08/30 00:21:06 Training value function...
2017/08/30 00:21:08 step 0: mse=104839.140084 step=0.050000
2017/08/30 00:21:09 step 1: mse=104252.358459 step=0.050000
2017/08/30 00:21:10 step 2: mse=102562.854459 step=0.050000
2017/08/30 00:21:11 step 3: mse=102623.245644 step=0.050000
2017/08/30 00:21:12 step 4: mse=102430.637067 step=0.050000
2017/08/30 00:21:12 step 5: mse=101616.195194 step=0.050000
2017/08/30 00:21:13 step 6: mse=101633.622414 step=0.050000
2017/08/30 00:21:14 step 7: mse=101765.785143 step=0.050000
2017/08/30 00:21:14 Saving...
2017/08/30 00:21:14 Gathering batch of experience...
2017/08/30 00:21:40 batch 409: mean=2353.536585 stddev=3791.977611 entropy=0.454289 frames=5429 count=41
2017/08/30 00:21:40 Training policy...
2017/08/30 00:21:44 tune 0: objective=36.680072 reg=0.004543 prune=0
2017/08/30 00:21:45 step 0: objective=36.755747 reg=0.004543
2017/08/30 00:21:46 step 1: objective=36.884348 reg=0.004542
2017/08/30 00:21:47 step 2: objective=36.984220 reg=0.004541
2017/08/30 00:21:48 step 3: objective=37.046345 reg=0.004540
2017/08/30 00:21:49 step 4: objective=37.162337 reg=0.004540
2017/08/30 00:21:50 step 5: objective=37.253077 reg=0.004541
2017/08/30 00:21:51 step 6: objective=37.320913 reg=0.004541
2017/08/30 00:21:52 step 7: objective=37.402097 reg=0.004540
2017/08/30 00:21:52 Training value function...
2017/08/30 00:21:54 step 0: mse=173726.121566 step=0.050000
2017/08/30 00:21:55 step 1: mse=173746.940648 step=0.050000
2017/08/30 00:21:56 step 2: mse=171431.000677 step=0.050000
2017/08/30 00:21:57 step 3: mse=170403.967790 step=0.050000
2017/08/30 00:21:58 step 4: mse=170347.056979 step=0.050000
2017/08/30 00:21:58 step 5: mse=169849.661216 step=0.050000
2017/08/30 00:21:59 step 6: mse=169917.524895 step=0.050000
2017/08/30 00:22:00 step 7: mse=169439.543982 step=0.050000
2017/08/30 00:22:00 Saving...
2017/08/30 00:22:00 Gathering batch of experience...
2017/08/30 00:22:23 batch 410: mean=2067.692308 stddev=2724.709076 entropy=0.447171 frames=5187 count=39
2017/08/30 00:22:23 Training policy...
2017/08/30 00:22:27 tune 0: objective=25.006419 reg=0.004472 prune=0
2017/08/30 00:22:28 step 0: objective=25.049289 reg=0.004471
2017/08/30 00:22:29 step 1: objective=25.099678 reg=0.004470
2017/08/30 00:22:30 step 2: objective=25.165367 reg=0.004471
2017/08/30 00:22:31 step 3: objective=25.221262 reg=0.004471
2017/08/30 00:22:32 step 4: objective=25.263123 reg=0.004470
2017/08/30 00:22:33 step 5: objective=25.284410 reg=0.004470
2017/08/30 00:22:34 step 6: objective=25.316784 reg=0.004470
2017/08/30 00:22:35 step 7: objective=25.343545 reg=0.004470
2017/08/30 00:22:35 Training value function...
2017/08/30 00:22:37 step 0: mse=100232.092522 step=0.050000
2017/08/30 00:22:37 step 1: mse=100598.833261 step=0.050000
2017/08/30 00:22:38 step 2: mse=100393.792272 step=0.050000
2017/08/30 00:22:39 step 3: mse=100896.771855 step=0.050000
2017/08/30 00:22:40 step 4: mse=101309.369461 step=0.050000
2017/08/30 00:22:41 step 5: mse=100494.643295 step=0.050000
2017/08/30 00:22:42 step 6: mse=99110.327315 step=0.050000
2017/08/30 00:22:42 step 7: mse=98024.065499 step=0.050000
2017/08/30 00:22:42 Saving...
2017/08/30 00:22:42 Gathering batch of experience...
2017/08/30 00:23:12 batch 411: mean=3906.911765 stddev=5694.109574 entropy=0.460470 frames=6041 count=34
2017/08/30 00:23:12 Training policy...
2017/08/30 00:23:16 tune 0: objective=68.315086 reg=0.004605 prune=0
2017/08/30 00:23:17 step 0: objective=68.436145 reg=0.004605
2017/08/30 00:23:18 step 1: objective=68.618198 reg=0.004604
2017/08/30 00:23:19 step 2: objective=68.723783 reg=0.004603
2017/08/30 00:23:20 step 3: objective=68.832457 reg=0.004601
2017/08/30 00:23:21 step 4: objective=68.910409 reg=0.004601
2017/08/30 00:23:22 step 5: objective=68.969785 reg=0.004600
2017/08/30 00:23:24 step 6: objective=69.067047 reg=0.004596
2017/08/30 00:23:25 step 7: objective=69.157285 reg=0.004594
2017/08/30 00:23:25 Training value function...
2017/08/30 00:23:27 step 0: mse=313989.123072 step=0.050000
2017/08/30 00:23:28 step 1: mse=310802.400412 step=0.050000
2017/08/30 00:23:29 step 2: mse=301725.828854 step=0.050000
2017/08/30 00:23:30 step 3: mse=296314.537038 step=0.050000
2017/08/30 00:23:31 step 4: mse=289441.315049 step=0.050000
2017/08/30 00:23:32 step 5: mse=283809.717906 step=0.050000
2017/08/30 00:23:33 step 6: mse=276671.134781 step=0.050000
2017/08/30 00:23:34 step 7: mse=269391.644985 step=0.050000
2017/08/30 00:23:34 Saving...
2017/08/30 00:23:34 Gathering batch of experience...
2017/08/30 00:23:59 batch 412: mean=2276.097561 stddev=3256.125468 entropy=0.452249 frames=5562 count=41
2017/08/30 00:23:59 Training policy...
2017/08/30 00:24:03 tune 0: objective=14.775800 reg=0.004522 prune=0
2017/08/30 00:24:04 step 0: objective=14.909500 reg=0.004522
2017/08/30 00:24:05 step 1: objective=15.072844 reg=0.004520
2017/08/30 00:24:06 step 2: objective=15.156760 reg=0.004523
2017/08/30 00:24:07 step 3: objective=15.219708 reg=0.004523
2017/08/30 00:24:08 step 4: objective=15.289634 reg=0.004525
2017/08/30 00:24:09 step 5: objective=15.344393 reg=0.004525
2017/08/30 00:24:10 step 6: objective=15.386983 reg=0.004525
2017/08/30 00:24:11 step 7: objective=15.445276 reg=0.004525
2017/08/30 00:24:11 Training value function...
2017/08/30 00:24:13 step 0: mse=127957.548381 step=0.050000
2017/08/30 00:24:14 step 1: mse=126644.229213 step=0.050000
2017/08/30 00:24:15 step 2: mse=125182.338396 step=0.050000
2017/08/30 00:24:16 step 3: mse=123101.099194 step=0.050000
2017/08/30 00:24:17 step 4: mse=122411.193100 step=0.050000
2017/08/30 00:24:18 step 5: mse=121921.271447 step=0.050000
2017/08/30 00:24:19 step 6: mse=120741.458031 step=0.050000
2017/08/30 00:24:19 step 7: mse=120136.430903 step=0.050000
2017/08/30 00:24:19 Saving...
2017/08/30 00:24:19 Gathering batch of experience...
2017/08/30 00:24:47 batch 413: mean=1926.931818 stddev=2837.899595 entropy=0.445429 frames=5469 count=44
2017/08/30 00:24:47 Training policy...
2017/08/30 00:24:51 tune 0: objective=17.240532 reg=0.004454 prune=0
2017/08/30 00:24:52 step 0: objective=17.289321 reg=0.004454
2017/08/30 00:24:53 step 1: objective=17.346050 reg=0.004454
2017/08/30 00:24:54 step 2: objective=17.391591 reg=0.004454
2017/08/30 00:24:55 step 3: objective=17.426979 reg=0.004453
2017/08/30 00:24:56 step 4: objective=17.453615 reg=0.004452
2017/08/30 00:24:57 step 5: objective=17.469169 reg=0.004450
2017/08/30 00:24:58 step 6: objective=17.519166 reg=0.004450
2017/08/30 00:24:59 step 7: objective=17.545191 reg=0.004450
2017/08/30 00:24:59 Training value function...
2017/08/30 00:25:01 step 0: mse=85461.329448 step=0.050000
2017/08/30 00:25:02 step 1: mse=85761.545666 step=0.050000
2017/08/30 00:25:03 step 2: mse=85597.819171 step=0.050000
2017/08/30 00:25:04 step 3: mse=85520.616495 step=0.050000
2017/08/30 00:25:04 step 4: mse=85903.797368 step=0.050000
2017/08/30 00:25:05 step 5: mse=86424.327826 step=0.050000
2017/08/30 00:25:06 step 6: mse=86671.958321 step=0.050000
2017/08/30 00:25:07 step 7: mse=87134.303962 step=0.050000
2017/08/30 00:25:07 Saving...
2017/08/30 00:25:07 Gathering batch of experience...
2017/08/30 00:25:31 batch 414: mean=1574.431818 stddev=891.659724 entropy=0.442932 frames=5123 count=44
2017/08/30 00:25:31 Training policy...
2017/08/30 00:25:34 tune 0: objective=6.635753 reg=0.004429 prune=0
2017/08/30 00:25:35 step 0: objective=6.649019 reg=0.004429
2017/08/30 00:25:36 step 1: objective=6.670076 reg=0.004428
2017/08/30 00:25:37 step 2: objective=6.690006 reg=0.004428
2017/08/30 00:25:38 step 3: objective=6.711429 reg=0.004428
2017/08/30 00:25:39 step 4: objective=6.725346 reg=0.004428
2017/08/30 00:25:40 step 5: objective=6.744547 reg=0.004428
2017/08/30 00:25:41 step 6: objective=6.761004 reg=0.004428
2017/08/30 00:25:42 step 7: objective=6.781231 reg=0.004428
2017/08/30 00:25:42 Training value function...
2017/08/30 00:25:44 step 0: mse=19835.281288 step=0.050000
2017/08/30 00:25:45 step 1: mse=19629.964281 step=0.050000
2017/08/30 00:25:46 step 2: mse=19453.297584 step=0.050000
2017/08/30 00:25:47 step 3: mse=19267.564104 step=0.050000
2017/08/30 00:25:47 step 4: mse=19105.423516 step=0.050000
2017/08/30 00:25:48 step 5: mse=18968.333818 step=0.050000
2017/08/30 00:25:49 step 6: mse=18870.004480 step=0.050000
2017/08/30 00:25:50 step 7: mse=18768.625348 step=0.050000
2017/08/30 00:25:50 Saving...
2017/08/30 00:25:50 Gathering batch of experience...
2017/08/30 00:26:13 batch 415: mean=1636.219512 stddev=522.270816 entropy=0.442045 frames=5134 count=41
2017/08/30 00:26:13 Training policy...
2017/08/30 00:26:17 tune 0: objective=16.970721 reg=0.004420 prune=0
2017/08/30 00:26:18 step 0: objective=16.979233 reg=0.004419
2017/08/30 00:26:19 step 1: objective=16.995869 reg=0.004418
2017/08/30 00:26:20 step 2: objective=17.010771 reg=0.004417
2017/08/30 00:26:21 step 3: objective=17.026425 reg=0.004415
2017/08/30 00:26:22 step 4: objective=17.043212 reg=0.004414
2017/08/30 00:26:23 step 5: objective=17.055019 reg=0.004413
2017/08/30 00:26:24 step 6: objective=17.070509 reg=0.004412
2017/08/30 00:26:25 step 7: objective=17.085752 reg=0.004411
2017/08/30 00:26:25 Training value function...
2017/08/30 00:26:27 step 0: mse=12857.517632 step=0.050000
2017/08/30 00:26:27 step 1: mse=12772.233253 step=0.050000
2017/08/30 00:26:28 step 2: mse=12699.199961 step=0.050000
2017/08/30 00:26:29 step 3: mse=12638.544592 step=0.050000
2017/08/30 00:26:30 step 4: mse=12588.658496 step=0.050000
2017/08/30 00:26:31 step 5: mse=12547.478104 step=0.050000
2017/08/30 00:26:31 step 6: mse=12514.855916 step=0.050000
2017/08/30 00:26:32 step 7: mse=12489.772446 step=0.050000
2017/08/30 00:26:32 Saving...
2017/08/30 00:26:32 Gathering batch of experience...
2017/08/30 00:26:58 batch 416: mean=1603.000000 stddev=866.301462 entropy=0.441092 frames=5299 count=45
2017/08/30 00:26:58 Training policy...
2017/08/30 00:27:01 tune 0: objective=19.992552 reg=0.004411 prune=0
2017/08/30 00:27:02 step 0: objective=20.007739 reg=0.004410
2017/08/30 00:27:03 step 1: objective=20.024978 reg=0.004409
2017/08/30 00:27:04 step 2: objective=20.045846 reg=0.004408
2017/08/30 00:27:05 step 3: objective=20.075598 reg=0.004407
2017/08/30 00:27:06 step 4: objective=20.092270 reg=0.004407
2017/08/30 00:27:07 step 5: objective=20.107327 reg=0.004407
2017/08/30 00:27:08 step 6: objective=20.124388 reg=0.004407
2017/08/30 00:27:09 step 7: objective=20.144545 reg=0.004406
2017/08/30 00:27:09 Training value function...
2017/08/30 00:27:11 step 0: mse=18370.572025 step=0.050000
2017/08/30 00:27:12 step 1: mse=18282.471368 step=0.050000
2017/08/30 00:27:13 step 2: mse=18205.086770 step=0.050000
2017/08/30 00:27:14 step 3: mse=18127.465852 step=0.050000
2017/08/30 00:27:15 step 4: mse=18097.587160 step=0.050000
2017/08/30 00:27:16 step 5: mse=18084.166120 step=0.050000
2017/08/30 00:27:16 step 6: mse=18042.613079 step=0.050000
2017/08/30 00:27:17 step 7: mse=18000.568982 step=0.050000
2017/08/30 00:27:17 Saving...
2017/08/30 00:27:17 Gathering batch of experience...
2017/08/30 00:27:44 batch 417: mean=2244.634146 stddev=2848.016295 entropy=0.447510 frames=5597 count=41
2017/08/30 00:27:44 Training policy...
2017/08/30 00:27:48 tune 0: objective=47.354665 reg=0.004475 prune=0
2017/08/30 00:27:49 step 0: objective=47.397065 reg=0.004474
2017/08/30 00:27:50 step 1: objective=47.454903 reg=0.004473
2017/08/30 00:27:51 step 2: objective=47.512434 reg=0.004474
2017/08/30 00:27:52 step 3: objective=47.572723 reg=0.004474
2017/08/30 00:27:53 step 4: objective=47.637049 reg=0.004474
2017/08/30 00:27:54 step 5: objective=47.694931 reg=0.004472
2017/08/30 00:27:56 step 6: objective=47.741926 reg=0.004472
2017/08/30 00:27:57 step 7: objective=47.796749 reg=0.004473
2017/08/30 00:27:57 Training value function...
2017/08/30 00:27:59 step 0: mse=141475.069253 step=0.050000
2017/08/30 00:28:00 step 1: mse=139295.958949 step=0.050000
2017/08/30 00:28:01 step 2: mse=137796.361035 step=0.050000
2017/08/30 00:28:02 step 3: mse=136566.339723 step=0.050000
2017/08/30 00:28:02 step 4: mse=134998.507300 step=0.050000
2017/08/30 00:28:03 step 5: mse=134695.143370 step=0.050000
2017/08/30 00:28:04 step 6: mse=133797.871446 step=0.050000
2017/08/30 00:28:05 step 7: mse=132351.897298 step=0.050000
2017/08/30 00:28:05 Saving...
2017/08/30 00:28:05 Gathering batch of experience...
2017/08/30 00:28:31 batch 418: mean=1995.714286 stddev=2675.975695 entropy=0.442689 frames=5351 count=42
2017/08/30 00:28:31 Training policy...
2017/08/30 00:28:34 tune 0: objective=36.407964 reg=0.004427 prune=0
2017/08/30 00:28:35 step 0: objective=36.464639 reg=0.004427
2017/08/30 00:28:36 step 1: objective=36.563046 reg=0.004426
2017/08/30 00:28:37 step 2: objective=36.624194 reg=0.004427
2017/08/30 00:28:38 step 3: objective=36.667977 reg=0.004427
2017/08/30 00:28:39 step 4: objective=36.701808 reg=0.004427
2017/08/30 00:28:41 step 5: objective=36.741695 reg=0.004426
2017/08/30 00:28:42 step 6: objective=36.778318 reg=0.004425
2017/08/30 00:28:43 step 7: objective=36.824130 reg=0.004423
2017/08/30 00:28:43 Training value function...
2017/08/30 00:28:45 step 0: mse=126797.633422 step=0.050000
2017/08/30 00:28:45 step 1: mse=126015.690141 step=0.050000
2017/08/30 00:28:46 step 2: mse=125202.702790 step=0.050000
2017/08/30 00:28:47 step 3: mse=125053.226444 step=0.050000
2017/08/30 00:28:48 step 4: mse=124899.023061 step=0.050000
2017/08/30 00:28:49 step 5: mse=124565.913552 step=0.050000
2017/08/30 00:28:50 step 6: mse=124695.720959 step=0.050000
2017/08/30 00:28:51 step 7: mse=124058.843354 step=0.050000
2017/08/30 00:28:51 Saving...
2017/08/30 00:28:51 Gathering batch of experience...
2017/08/30 00:29:16 batch 419: mean=2002.738095 stddev=2791.959374 entropy=0.445512 frames=5340 count=42
2017/08/30 00:29:16 Training policy...
2017/08/30 00:29:20 tune 0: objective=34.972800 reg=0.004455 prune=0
2017/08/30 00:29:21 step 0: objective=35.020125 reg=0.004454
2017/08/30 00:29:22 step 1: objective=35.059018 reg=0.004453
2017/08/30 00:29:23 step 2: objective=35.107491 reg=0.004453
2017/08/30 00:29:24 step 3: objective=35.133386 reg=0.004452
2017/08/30 00:29:25 step 4: objective=35.173824 reg=0.004452
2017/08/30 00:29:26 step 5: objective=35.217386 reg=0.004451
2017/08/30 00:29:27 step 6: objective=35.273698 reg=0.004450
2017/08/30 00:29:28 step 7: objective=35.309989 reg=0.004450
2017/08/30 00:29:28 Training value function...
2017/08/30 00:29:30 step 0: mse=133349.631648 step=0.050000
2017/08/30 00:29:31 step 1: mse=133201.718495 step=0.050000
2017/08/30 00:29:32 step 2: mse=133107.373817 step=0.050000
2017/08/30 00:29:32 step 3: mse=132254.328645 step=0.050000
2017/08/30 00:29:33 step 4: mse=132033.336752 step=0.050000
2017/08/30 00:29:34 step 5: mse=130810.888934 step=0.050000
2017/08/30 00:29:35 step 6: mse=130261.891950 step=0.050000
2017/08/30 00:29:36 step 7: mse=128740.987059 step=0.050000
2017/08/30 00:29:36 Saving...
2017/08/30 00:29:36 Gathering batch of experience...
2017/08/30 00:29:59 batch 420: mean=2094.605263 stddev=2853.912223 entropy=0.446533 frames=5053 count=38
2017/08/30 00:29:59 Training policy...
2017/08/30 00:30:03 tune 0: objective=30.172673 reg=0.004465 prune=0
2017/08/30 00:30:04 step 0: objective=30.219984 reg=0.004464
2017/08/30 00:30:05 step 1: objective=30.266964 reg=0.004465
2017/08/30 00:30:05 step 2: objective=30.334566 reg=0.004465
2017/08/30 00:30:06 step 3: objective=30.390752 reg=0.004464
2017/08/30 00:30:07 step 4: objective=30.459081 reg=0.004464
2017/08/30 00:30:08 step 5: objective=30.509493 reg=0.004464
2017/08/30 00:30:09 step 6: objective=30.537697 reg=0.004463
2017/08/30 00:30:10 step 7: objective=30.581740 reg=0.004463
2017/08/30 00:30:10 Training value function...
2017/08/30 00:30:12 step 0: mse=133341.134978 step=0.050000
2017/08/30 00:30:13 step 1: mse=133347.337243 step=0.050000
2017/08/30 00:30:14 step 2: mse=133447.117842 step=0.050000
2017/08/30 00:30:15 step 3: mse=133145.489157 step=0.050000
2017/08/30 00:30:15 step 4: mse=133315.011860 step=0.050000
2017/08/30 00:30:16 step 5: mse=133649.516192 step=0.050000
2017/08/30 00:30:17 step 6: mse=131996.989228 step=0.050000
2017/08/30 00:30:18 step 7: mse=131531.510284 step=0.050000
2017/08/30 00:30:18 Saving...
2017/08/30 00:30:18 Gathering batch of experience...
2017/08/30 00:30:45 batch 421: mean=2000.116279 stddev=2692.232472 entropy=0.444633 frames=5502 count=43
2017/08/30 00:30:45 Training policy...
2017/08/30 00:30:49 tune 0: objective=25.566340 reg=0.004446 prune=0
2017/08/30 00:30:50 step 0: objective=25.609631 reg=0.004445
2017/08/30 00:30:51 step 1: objective=25.667397 reg=0.004445
2017/08/30 00:30:52 step 2: objective=25.713763 reg=0.004444
2017/08/30 00:30:53 step 3: objective=25.778856 reg=0.004443
2017/08/30 00:30:54 step 4: objective=25.848044 reg=0.004442
2017/08/30 00:30:55 step 5: objective=25.882736 reg=0.004442
2017/08/30 00:30:56 step 6: objective=25.923877 reg=0.004440
2017/08/30 00:30:57 step 7: objective=25.967429 reg=0.004440
2017/08/30 00:30:57 Training value function...
2017/08/30 00:30:59 step 0: mse=114320.284299 step=0.050000
2017/08/30 00:31:00 step 1: mse=114420.218537 step=0.050000
2017/08/30 00:31:01 step 2: mse=112317.175935 step=0.050000
2017/08/30 00:31:02 step 3: mse=112344.972221 step=0.050000
2017/08/30 00:31:03 step 4: mse=111498.769938 step=0.050000
2017/08/30 00:31:04 step 5: mse=111175.539588 step=0.050000
2017/08/30 00:31:05 step 6: mse=111276.129458 step=0.050000
2017/08/30 00:31:06 step 7: mse=111257.821348 step=0.050000
2017/08/30 00:31:06 Saving...
2017/08/30 00:31:06 Gathering batch of experience...
2017/08/30 00:31:33 batch 422: mean=2638.026316 stddev=4053.424079 entropy=0.445879 frames=5461 count=38
2017/08/30 00:31:33 Training policy...
2017/08/30 00:31:36 tune 0: objective=50.931577 reg=0.004459 prune=0
2017/08/30 00:31:37 step 0: objective=51.026014 reg=0.004459
2017/08/30 00:31:38 step 1: objective=51.177932 reg=0.004457
2017/08/30 00:31:39 step 2: objective=51.322262 reg=0.004459
2017/08/30 00:31:40 step 3: objective=51.449111 reg=0.004459
2017/08/30 00:31:41 step 4: objective=51.536950 reg=0.004460
2017/08/30 00:31:42 step 5: objective=51.613864 reg=0.004460
2017/08/30 00:31:43 step 6: objective=51.685457 reg=0.004460
2017/08/30 00:31:44 step 7: objective=51.785404 reg=0.004458
2017/08/30 00:31:44 Training value function...
2017/08/30 00:31:47 step 0: mse=234715.331842 step=0.050000
2017/08/30 00:31:47 step 1: mse=230001.615663 step=0.050000
2017/08/30 00:31:48 step 2: mse=225862.720298 step=0.050000
2017/08/30 00:31:49 step 3: mse=222252.169164 step=0.050000
2017/08/30 00:31:50 step 4: mse=221045.630650 step=0.050000
2017/08/30 00:31:51 step 5: mse=219780.951394 step=0.050000
2017/08/30 00:31:52 step 6: mse=218784.382978 step=0.050000
2017/08/30 00:31:53 step 7: mse=217308.929478 step=0.050000
2017/08/30 00:31:53 Saving...
2017/08/30 00:31:53 Gathering batch of experience...
2017/08/30 00:32:19 batch 423: mean=2525.476190 stddev=3910.099531 entropy=0.445457 frames=5932 count=42
2017/08/30 00:32:19 Training policy...
2017/08/30 00:32:23 tune 0: objective=39.139608 reg=0.004455 prune=0
2017/08/30 00:32:24 step 0: objective=39.209842 reg=0.004454
2017/08/30 00:32:26 step 1: objective=39.301005 reg=0.004453
2017/08/30 00:32:27 step 2: objective=39.401335 reg=0.004453
2017/08/30 00:32:28 step 3: objective=39.463327 reg=0.004453
2017/08/30 00:32:29 step 4: objective=39.545316 reg=0.004452
2017/08/30 00:32:30 step 5: objective=39.595952 reg=0.004452
2017/08/30 00:32:31 step 6: objective=39.633308 reg=0.004452
2017/08/30 00:32:32 step 7: objective=39.687576 reg=0.004452
2017/08/30 00:32:32 Training value function...
2017/08/30 00:32:35 step 0: mse=191602.160156 step=0.050000
2017/08/30 00:32:36 step 1: mse=190527.963077 step=0.050000
2017/08/30 00:32:37 step 2: mse=189772.939342 step=0.050000
2017/08/30 00:32:37 step 3: mse=185532.896073 step=0.050000
2017/08/30 00:32:38 step 4: mse=184697.465278 step=0.050000
2017/08/30 00:32:39 step 5: mse=180831.457216 step=0.050000
2017/08/30 00:32:40 step 6: mse=177495.515238 step=0.050000
2017/08/30 00:32:41 step 7: mse=174375.463210 step=0.050000
2017/08/30 00:32:41 Saving...
2017/08/30 00:32:41 Gathering batch of experience...
2017/08/30 00:33:06 batch 424: mean=1549.418605 stddev=575.571717 entropy=0.437878 frames=5092 count=43
2017/08/30 00:33:06 Training policy...
2017/08/30 00:33:09 tune 0: objective=6.732486 reg=0.004379 prune=0
2017/08/30 00:33:10 step 0: objective=6.743739 reg=0.004378
2017/08/30 00:33:11 step 1: objective=6.761779 reg=0.004378
2017/08/30 00:33:12 step 2: objective=6.786488 reg=0.004378
2017/08/30 00:33:13 step 3: objective=6.812459 reg=0.004378
2017/08/30 00:33:14 step 4: objective=6.830956 reg=0.004378
2017/08/30 00:33:15 step 5: objective=6.849454 reg=0.004378
2017/08/30 00:33:16 step 6: objective=6.878199 reg=0.004378
2017/08/30 00:33:17 step 7: objective=6.897808 reg=0.004378
2017/08/30 00:33:17 Training value function...
2017/08/30 00:33:19 step 0: mse=14247.805161 step=0.050000
2017/08/30 00:33:20 step 1: mse=14066.415219 step=0.050000
2017/08/30 00:33:20 step 2: mse=13922.836643 step=0.050000
2017/08/30 00:33:21 step 3: mse=13805.773783 step=0.050000
2017/08/30 00:33:22 step 4: mse=13713.197514 step=0.050000
2017/08/30 00:33:23 step 5: mse=13631.917135 step=0.050000
2017/08/30 00:33:24 step 6: mse=13558.955655 step=0.050000
2017/08/30 00:33:24 step 7: mse=13510.189020 step=0.050000
2017/08/30 00:33:24 Saving...
2017/08/30 00:33:24 Gathering batch of experience...
2017/08/30 00:33:51 batch 425: mean=2080.348837 stddev=3083.467430 entropy=0.441897 frames=5517 count=43
2017/08/30 00:33:51 Training policy...
2017/08/30 00:33:55 tune 0: objective=36.426559 reg=0.004419 prune=0
2017/08/30 00:33:56 step 0: objective=36.488895 reg=0.004419
2017/08/30 00:33:57 step 1: objective=36.607942 reg=0.004419
2017/08/30 00:33:58 step 2: objective=36.691029 reg=0.004419
2017/08/30 00:33:59 step 3: objective=36.743407 reg=0.004419
2017/08/30 00:34:00 step 4: objective=36.776971 reg=0.004418
2017/08/30 00:34:01 step 5: objective=36.857764 reg=0.004418
2017/08/30 00:34:02 step 6: objective=36.897162 reg=0.004418
2017/08/30 00:34:03 step 7: objective=36.930833 reg=0.004419
2017/08/30 00:34:03 Training value function...
2017/08/30 00:34:05 step 0: mse=124947.007016 step=0.050000
2017/08/30 00:34:06 step 1: mse=124057.940918 step=0.050000
2017/08/30 00:34:07 step 2: mse=123271.682586 step=0.050000
2017/08/30 00:34:08 step 3: mse=123078.327295 step=0.050000
2017/08/30 00:34:09 step 4: mse=122536.969857 step=0.050000
2017/08/30 00:34:10 step 5: mse=122429.580386 step=0.050000
2017/08/30 00:34:11 step 6: mse=122325.642470 step=0.050000
2017/08/30 00:34:11 step 7: mse=122083.944411 step=0.050000
2017/08/30 00:34:11 Saving...
2017/08/30 00:34:11 Gathering batch of experience...
2017/08/30 00:34:36 batch 426: mean=2688.513514 stddev=4190.091250 entropy=0.444663 frames=5426 count=37
2017/08/30 00:34:36 Training policy...
2017/08/30 00:34:39 tune 0: objective=53.789319 reg=0.004447 prune=0
2017/08/30 00:34:40 step 0: objective=53.862387 reg=0.004446
2017/08/30 00:34:41 step 1: objective=53.994621 reg=0.004446
2017/08/30 00:34:42 step 2: objective=54.150352 reg=0.004444
2017/08/30 00:34:43 step 3: objective=54.267439 reg=0.004443
2017/08/30 00:34:45 step 4: objective=54.341677 reg=0.004441
2017/08/30 00:34:46 step 5: objective=54.393885 reg=0.004440
2017/08/30 00:34:47 step 6: objective=54.438692 reg=0.004439
2017/08/30 00:34:48 step 7: objective=54.486414 reg=0.004439
2017/08/30 00:34:48 Training value function...
2017/08/30 00:34:50 step 0: mse=223079.709740 step=0.050000
2017/08/30 00:34:51 step 1: mse=219847.522416 step=0.050000
2017/08/30 00:34:51 step 2: mse=216452.542286 step=0.050000
2017/08/30 00:34:52 step 3: mse=211256.921045 step=0.050000
2017/08/30 00:34:53 step 4: mse=207438.717275 step=0.050000
2017/08/30 00:34:54 step 5: mse=201052.378247 step=0.050000
2017/08/30 00:34:55 step 6: mse=200119.624175 step=0.050000
2017/08/30 00:34:56 step 7: mse=195129.989088 step=0.050000
2017/08/30 00:34:56 Saving...
2017/08/30 00:34:56 Gathering batch of experience...
2017/08/30 00:35:22 batch 427: mean=4109.696970 stddev=5679.945708 entropy=0.451199 frames=5785 count=33
2017/08/30 00:35:22 Training policy...
2017/08/30 00:35:26 tune 0: objective=62.804813 reg=0.004512 prune=0
2017/08/30 00:35:27 step 0: objective=62.955829 reg=0.004512
2017/08/30 00:35:28 step 1: objective=63.077550 reg=0.004511
2017/08/30 00:35:29 step 2: objective=63.250475 reg=0.004511
2017/08/30 00:35:30 step 3: objective=63.461441 reg=0.004510
2017/08/30 00:35:31 step 4: objective=63.597153 reg=0.004509
2017/08/30 00:35:32 step 5: objective=63.683097 reg=0.004506
2017/08/30 00:35:33 step 6: objective=63.779343 reg=0.004504
2017/08/30 00:35:35 step 7: objective=63.870992 reg=0.004503
2017/08/30 00:35:35 Training value function...
2017/08/30 00:35:37 step 0: mse=358413.813439 step=0.050000
2017/08/30 00:35:38 step 1: mse=350621.254854 step=0.050000
2017/08/30 00:35:39 step 2: mse=341201.156435 step=0.050000
2017/08/30 00:35:40 step 3: mse=335228.886246 step=0.050000
2017/08/30 00:35:41 step 4: mse=326667.681794 step=0.050000
2017/08/30 00:35:41 step 5: mse=323530.905869 step=0.050000
2017/08/30 00:35:42 step 6: mse=316872.452331 step=0.050000
2017/08/30 00:35:43 step 7: mse=309433.085258 step=0.050000
2017/08/30 00:35:43 Saving...
2017/08/30 00:35:43 Gathering batch of experience...
2017/08/30 00:36:07 batch 428: mean=1709.404762 stddev=1032.223791 entropy=0.440906 frames=5168 count=42
2017/08/30 00:36:07 Training policy...
2017/08/30 00:36:11 tune 0: objective=0.942883 reg=0.004409 prune=0
2017/08/30 00:36:12 step 0: objective=0.989299 reg=0.004408
2017/08/30 00:36:13 step 1: objective=1.054666 reg=0.004406
2017/08/30 00:36:14 step 2: objective=1.109608 reg=0.004405
2017/08/30 00:36:15 step 3: objective=1.188402 reg=0.004404
2017/08/30 00:36:16 step 4: objective=1.241094 reg=0.004403
2017/08/30 00:36:17 step 5: objective=1.274799 reg=0.004403
2017/08/30 00:36:18 step 6: objective=1.298337 reg=0.004402
2017/08/30 00:36:19 step 7: objective=1.325623 reg=0.004402
2017/08/30 00:36:19 Training value function...
2017/08/30 00:36:21 step 0: mse=29731.440841 step=0.050000
2017/08/30 00:36:22 step 1: mse=28757.859050 step=0.050000
2017/08/30 00:36:22 step 2: mse=27977.195480 step=0.050000
2017/08/30 00:36:23 step 3: mse=27251.475256 step=0.050000
2017/08/30 00:36:24 step 4: mse=26606.868120 step=0.050000
2017/08/30 00:36:25 step 5: mse=25988.098843 step=0.050000
2017/08/30 00:36:26 step 6: mse=25461.498152 step=0.050000
2017/08/30 00:36:26 step 7: mse=25103.759338 step=0.050000
2017/08/30 00:36:26 Saving...
2017/08/30 00:36:27 Gathering batch of experience...
2017/08/30 00:36:51 batch 429: mean=2491.923077 stddev=4081.044615 entropy=0.445162 frames=5328 count=39
2017/08/30 00:36:51 Training policy...
2017/08/30 00:36:54 tune 0: objective=46.151496 reg=0.004452 prune=0
2017/08/30 00:36:55 step 0: objective=46.231788 reg=0.004452
2017/08/30 00:36:56 step 1: objective=46.303828 reg=0.004452
2017/08/30 00:36:57 step 2: objective=46.398259 reg=0.004452
2017/08/30 00:36:58 step 3: objective=46.553793 reg=0.004454
2017/08/30 00:36:59 step 4: objective=46.610789 reg=0.004455
2017/08/30 00:37:00 step 5: objective=46.695506 reg=0.004457
2017/08/30 00:37:01 step 6: objective=46.776490 reg=0.004457
2017/08/30 00:37:02 step 7: objective=46.816802 reg=0.004457
2017/08/30 00:37:02 Training value function...
2017/08/30 00:37:04 step 0: mse=201860.004616 step=0.050000
2017/08/30 00:37:05 step 1: mse=200811.355655 step=0.050000
2017/08/30 00:37:06 step 2: mse=199243.878934 step=0.050000
2017/08/30 00:37:07 step 3: mse=198587.591842 step=0.050000
2017/08/30 00:37:08 step 4: mse=198026.788628 step=0.050000
2017/08/30 00:37:09 step 5: mse=193440.259109 step=0.050000
2017/08/30 00:37:10 step 6: mse=191847.202279 step=0.050000
2017/08/30 00:37:10 step 7: mse=191429.964639 step=0.050000
2017/08/30 00:37:10 Saving...
2017/08/30 00:37:10 Gathering batch of experience...
2017/08/30 00:37:38 batch 430: mean=2535.250000 stddev=4125.052113 entropy=0.444075 frames=5434 count=40
2017/08/30 00:37:38 Training policy...
2017/08/30 00:37:41 tune 0: objective=41.028073 reg=0.004441 prune=0
2017/08/30 00:37:42 step 0: objective=41.088321 reg=0.004440
2017/08/30 00:37:43 step 1: objective=41.197394 reg=0.004438
2017/08/30 00:37:44 step 2: objective=41.280405 reg=0.004437
2017/08/30 00:37:45 step 3: objective=41.374666 reg=0.004437
2017/08/30 00:37:46 step 4: objective=41.436750 reg=0.004436
2017/08/30 00:37:47 step 5: objective=41.496440 reg=0.004436
2017/08/30 00:37:48 step 6: objective=41.573358 reg=0.004435
2017/08/30 00:37:49 step 7: objective=41.616653 reg=0.004434
2017/08/30 00:37:49 Training value function...
2017/08/30 00:37:51 step 0: mse=180046.609364 step=0.050000
2017/08/30 00:37:52 step 1: mse=178579.780096 step=0.050000
2017/08/30 00:37:53 step 2: mse=174442.786981 step=0.050000
2017/08/30 00:37:54 step 3: mse=171589.738948 step=0.050000
2017/08/30 00:37:55 step 4: mse=170254.010865 step=0.050000
2017/08/30 00:37:56 step 5: mse=169559.526396 step=0.050000
2017/08/30 00:37:57 step 6: mse=168269.852752 step=0.050000
2017/08/30 00:37:57 step 7: mse=168856.581051 step=0.050000
2017/08/30 00:37:57 Saving...
2017/08/30 00:37:58 Gathering batch of experience...
2017/08/30 00:38:25 batch 431: mean=2527.682927 stddev=3959.740552 entropy=0.441218 frames=5851 count=41
2017/08/30 00:38:25 Training policy...
2017/08/30 00:38:29 tune 0: objective=39.124391 reg=0.004412 prune=0
2017/08/30 00:38:30 step 0: objective=39.224419 reg=0.004413
2017/08/30 00:38:31 step 1: objective=39.353086 reg=0.004415
2017/08/30 00:38:33 step 2: objective=39.502809 reg=0.004417
2017/08/30 00:38:34 step 3: objective=39.569903 reg=0.004416
2017/08/30 00:38:35 step 4: objective=39.631476 reg=0.004417
2017/08/30 00:38:36 step 5: objective=39.689893 reg=0.004416
2017/08/30 00:38:37 step 6: objective=39.734383 reg=0.004415
2017/08/30 00:38:38 step 7: objective=39.770621 reg=0.004415
2017/08/30 00:38:38 Training value function...
2017/08/30 00:38:41 step 0: mse=186798.626782 step=0.050000
2017/08/30 00:38:41 step 1: mse=185765.449422 step=0.050000
2017/08/30 00:38:42 step 2: mse=184153.128938 step=0.050000
2017/08/30 00:38:43 step 3: mse=183697.481112 step=0.050000
2017/08/30 00:38:44 step 4: mse=181892.364286 step=0.050000
2017/08/30 00:38:45 step 5: mse=181672.134748 step=0.050000
2017/08/30 00:38:46 step 6: mse=178403.894890 step=0.050000
2017/08/30 00:38:47 step 7: mse=174963.052486 step=0.050000
2017/08/30 00:38:47 Saving...
2017/08/30 00:38:47 Gathering batch of experience...
2017/08/30 00:39:10 batch 432: mean=2942.272727 stddev=4154.941215 entropy=0.444117 frames=5153 count=33
2017/08/30 00:39:10 Training policy...
2017/08/30 00:39:13 tune 0: objective=39.661150 reg=0.004441 prune=0
2017/08/30 00:39:14 step 0: objective=39.813992 reg=0.004442
2017/08/30 00:39:15 step 1: objective=39.935899 reg=0.004441
2017/08/30 00:39:16 step 2: objective=40.104963 reg=0.004440
2017/08/30 00:39:17 step 3: objective=40.194465 reg=0.004439
2017/08/30 00:39:18 step 4: objective=40.252022 reg=0.004440
2017/08/30 00:39:19 step 5: objective=40.331930 reg=0.004439
2017/08/30 00:39:20 step 6: objective=40.431226 reg=0.004441
2017/08/30 00:39:21 step 7: objective=40.497871 reg=0.004440
2017/08/30 00:39:21 Training value function...
2017/08/30 00:39:23 step 0: mse=184819.775698 step=0.050000
2017/08/30 00:39:24 step 1: mse=180712.432533 step=0.050000
2017/08/30 00:39:25 step 2: mse=177374.306804 step=0.050000
2017/08/30 00:39:26 step 3: mse=176506.772340 step=0.050000
2017/08/30 00:39:27 step 4: mse=173426.696743 step=0.050000
2017/08/30 00:39:27 step 5: mse=173133.408039 step=0.050000
2017/08/30 00:39:28 step 6: mse=170463.618921 step=0.050000
2017/08/30 00:39:29 step 7: mse=167317.471834 step=0.050000
2017/08/30 00:39:29 Saving...
2017/08/30 00:39:29 Gathering batch of experience...
2017/08/30 00:39:58 batch 433: mean=2607.804878 stddev=4145.057011 entropy=0.443042 frames=5927 count=41
2017/08/30 00:39:58 Training policy...
2017/08/30 00:40:01 tune 0: objective=35.250266 reg=0.004430 prune=0
2017/08/30 00:40:03 step 0: objective=35.373716 reg=0.004432
2017/08/30 00:40:04 step 1: objective=35.447789 reg=0.004433
2017/08/30 00:40:05 step 2: objective=35.521512 reg=0.004433
2017/08/30 00:40:06 step 3: objective=35.626642 reg=0.004434
2017/08/30 00:40:07 step 4: objective=35.732432 reg=0.004433
2017/08/30 00:40:08 step 5: objective=35.801198 reg=0.004433
2017/08/30 00:40:09 step 6: objective=35.851160 reg=0.004434
2017/08/30 00:40:11 step 7: objective=35.899717 reg=0.004433
2017/08/30 00:40:11 Training value function...
2017/08/30 00:40:13 step 0: mse=163753.099312 step=0.050000
2017/08/30 00:40:14 step 1: mse=163335.952517 step=0.050000
2017/08/30 00:40:15 step 2: mse=163153.185089 step=0.050000
2017/08/30 00:40:16 step 3: mse=162455.880239 step=0.050000
2017/08/30 00:40:17 step 4: mse=161476.596791 step=0.050000
2017/08/30 00:40:18 step 5: mse=160540.225537 step=0.050000
2017/08/30 00:40:19 step 6: mse=159634.140130 step=0.050000
2017/08/30 00:40:20 step 7: mse=159872.231741 step=0.050000
2017/08/30 00:40:20 Saving...
2017/08/30 00:40:20 Gathering batch of experience...
2017/08/30 00:40:42 batch 434: mean=1934.375000 stddev=3152.043025 entropy=0.440889 frames=4839 count=40
2017/08/30 00:40:42 Training policy...
2017/08/30 00:40:45 tune 0: objective=18.892709 reg=0.004409 prune=0
2017/08/30 00:40:46 step 0: objective=18.936912 reg=0.004408
2017/08/30 00:40:47 step 1: objective=18.990368 reg=0.004408
2017/08/30 00:40:48 step 2: objective=19.024377 reg=0.004407
2017/08/30 00:40:49 step 3: objective=19.058060 reg=0.004406
2017/08/30 00:40:50 step 4: objective=19.101776 reg=0.004405
2017/08/30 00:40:51 step 5: objective=19.127444 reg=0.004405
2017/08/30 00:40:52 step 6: objective=19.162969 reg=0.004403
2017/08/30 00:40:53 step 7: objective=19.197570 reg=0.004402
2017/08/30 00:40:53 Training value function...
2017/08/30 00:40:54 step 0: mse=92886.815778 step=0.050000
2017/08/30 00:40:55 step 1: mse=93517.494462 step=0.050000
2017/08/30 00:40:56 step 2: mse=94208.158835 step=0.050000
2017/08/30 00:40:57 step 3: mse=94900.499924 step=0.050000
2017/08/30 00:40:58 step 4: mse=94659.626617 step=0.050000
2017/08/30 00:40:58 step 5: mse=95335.546257 step=0.050000
2017/08/30 00:40:59 step 6: mse=95821.132519 step=0.050000
2017/08/30 00:41:00 step 7: mse=96280.857912 step=0.050000
2017/08/30 00:41:00 Saving...
2017/08/30 00:41:00 Gathering batch of experience...
2017/08/30 00:41:27 batch 435: mean=2017.857143 stddev=2767.472877 entropy=0.439558 frames=5390 count=42
2017/08/30 00:41:27 Training policy...
2017/08/30 00:41:30 tune 0: objective=21.501081 reg=0.004396 prune=0
2017/08/30 00:41:31 step 0: objective=21.540199 reg=0.004395
2017/08/30 00:41:32 step 1: objective=21.589286 reg=0.004396
2017/08/30 00:41:34 step 2: objective=21.640699 reg=0.004397
2017/08/30 00:41:35 step 3: objective=21.693495 reg=0.004399
2017/08/30 00:41:36 step 4: objective=21.747427 reg=0.004399
2017/08/30 00:41:37 step 5: objective=21.807379 reg=0.004400
2017/08/30 00:41:38 step 6: objective=21.854967 reg=0.004400
2017/08/30 00:41:39 step 7: objective=21.893996 reg=0.004399
2017/08/30 00:41:39 Training value function...
2017/08/30 00:41:41 step 0: mse=111617.690295 step=0.050000
2017/08/30 00:41:42 step 1: mse=111439.192225 step=0.050000
2017/08/30 00:41:43 step 2: mse=111346.356261 step=0.050000
2017/08/30 00:41:43 step 3: mse=109374.208672 step=0.050000
2017/08/30 00:41:44 step 4: mse=109643.825189 step=0.050000
2017/08/30 00:41:45 step 5: mse=109842.657110 step=0.050000
2017/08/30 00:41:46 step 6: mse=109837.450801 step=0.050000
2017/08/30 00:41:47 step 7: mse=110166.566067 step=0.050000
2017/08/30 00:41:47 Saving...
2017/08/30 00:41:47 Gathering batch of experience...
2017/08/30 00:42:10 batch 436: mean=2214.230769 stddev=3241.835215 entropy=0.443667 frames=5136 count=39
2017/08/30 00:42:10 Training policy...
2017/08/30 00:42:14 tune 0: objective=27.238272 reg=0.004437 prune=0
2017/08/30 00:42:15 step 0: objective=27.347294 reg=0.004437
2017/08/30 00:42:16 step 1: objective=27.472732 reg=0.004434
2017/08/30 00:42:17 step 2: objective=27.553294 reg=0.004432
2017/08/30 00:42:18 step 3: objective=27.643646 reg=0.004432
2017/08/30 00:42:19 step 4: objective=27.708768 reg=0.004433
2017/08/30 00:42:20 step 5: objective=27.758856 reg=0.004432
2017/08/30 00:42:21 step 6: objective=27.797344 reg=0.004431
2017/08/30 00:42:22 step 7: objective=27.836607 reg=0.004433
2017/08/30 00:42:22 Training value function...
2017/08/30 00:42:24 step 0: mse=144086.421500 step=0.050000
2017/08/30 00:42:24 step 1: mse=142757.292696 step=0.050000
2017/08/30 00:42:25 step 2: mse=142422.818657 step=0.050000
2017/08/30 00:42:26 step 3: mse=142518.299682 step=0.050000
2017/08/30 00:42:27 step 4: mse=141454.197114 step=0.050000
2017/08/30 00:42:28 step 5: mse=140561.392898 step=0.050000
2017/08/30 00:42:29 step 6: mse=140482.747774 step=0.050000
2017/08/30 00:42:29 step 7: mse=139592.884970 step=0.050000
2017/08/30 00:42:29 Saving...
2017/08/30 00:42:29 Gathering batch of experience...
2017/08/30 00:42:55 batch 437: mean=2706.500000 stddev=4099.269173 entropy=0.443726 frames=5880 count=40
2017/08/30 00:42:55 Training policy...
2017/08/30 00:42:59 tune 0: objective=44.656128 reg=0.004437 prune=0
2017/08/30 00:43:00 step 0: objective=44.723230 reg=0.004437
2017/08/30 00:43:01 step 1: objective=44.808084 reg=0.004436
2017/08/30 00:43:03 step 2: objective=44.871285 reg=0.004437
2017/08/30 00:43:04 step 3: objective=44.931659 reg=0.004437
2017/08/30 00:43:05 step 4: objective=45.013037 reg=0.004437
2017/08/30 00:43:06 step 5: objective=45.105846 reg=0.004435
2017/08/30 00:43:07 step 6: objective=45.174617 reg=0.004435
2017/08/30 00:43:08 step 7: objective=45.246455 reg=0.004436
2017/08/30 00:43:08 Training value function...
2017/08/30 00:43:11 step 0: mse=191252.250847 step=0.050000
2017/08/30 00:43:12 step 1: mse=188750.216145 step=0.050000
2017/08/30 00:43:12 step 2: mse=185368.407364 step=0.050000
2017/08/30 00:43:13 step 3: mse=183901.587155 step=0.050000
2017/08/30 00:43:14 step 4: mse=183078.619518 step=0.050000
2017/08/30 00:43:15 step 5: mse=180135.096718 step=0.050000
2017/08/30 00:43:16 step 6: mse=179707.917563 step=0.050000
2017/08/30 00:43:17 step 7: mse=178563.330352 step=0.050000
2017/08/30 00:43:17 Saving...
2017/08/30 00:43:17 Gathering batch of experience...
2017/08/30 00:43:45 batch 438: mean=1922.954545 stddev=2839.613914 entropy=0.436456 frames=5420 count=44
2017/08/30 00:43:45 Training policy...
2017/08/30 00:43:49 tune 0: objective=21.316630 reg=0.004365 prune=0
2017/08/30 00:43:50 step 0: objective=21.343094 reg=0.004364
2017/08/30 00:43:51 step 1: objective=21.359985 reg=0.004364
2017/08/30 00:43:52 step 2: objective=21.396120 reg=0.004365
2017/08/30 00:43:53 step 3: objective=21.415315 reg=0.004364
2017/08/30 00:43:54 step 4: objective=21.434111 reg=0.004365
2017/08/30 00:43:55 step 5: objective=21.462653 reg=0.004365
2017/08/30 00:43:56 step 6: objective=21.487278 reg=0.004365
2017/08/30 00:43:57 step 7: objective=21.529510 reg=0.004364
2017/08/30 00:43:57 Training value function...
2017/08/30 00:43:59 step 0: mse=82110.338292 step=0.050000
2017/08/30 00:44:00 step 1: mse=82650.113449 step=0.050000
2017/08/30 00:44:01 step 2: mse=81501.904365 step=0.050000
2017/08/30 00:44:02 step 3: mse=81966.850324 step=0.050000
2017/08/30 00:44:03 step 4: mse=82472.731704 step=0.050000
2017/08/30 00:44:04 step 5: mse=82624.004951 step=0.050000
2017/08/30 00:44:05 step 6: mse=83152.911247 step=0.050000
2017/08/30 00:44:05 step 7: mse=83606.850930 step=0.050000
2017/08/30 00:44:05 Saving...
2017/08/30 00:44:05 Gathering batch of experience...
2017/08/30 00:44:31 batch 439: mean=1840.731707 stddev=1002.915604 entropy=0.441587 frames=5391 count=41
2017/08/30 00:44:31 Training policy...
2017/08/30 00:44:34 tune 0: objective=16.237579 reg=0.004416 prune=0
2017/08/30 00:44:35 step 0: objective=16.262973 reg=0.004415
2017/08/30 00:44:36 step 1: objective=16.295384 reg=0.004415
2017/08/30 00:44:37 step 2: objective=16.326296 reg=0.004415
2017/08/30 00:44:38 step 3: objective=16.364575 reg=0.004415
2017/08/30 00:44:39 step 4: objective=16.399193 reg=0.004415
2017/08/30 00:44:40 step 5: objective=16.431287 reg=0.004415
2017/08/30 00:44:41 step 6: objective=16.462613 reg=0.004415
2017/08/30 00:44:42 step 7: objective=16.496384 reg=0.004414
2017/08/30 00:44:42 Training value function...
2017/08/30 00:44:45 step 0: mse=27536.677487 step=0.050000
2017/08/30 00:44:45 step 1: mse=26723.841527 step=0.050000
2017/08/30 00:44:46 step 2: mse=25982.459425 step=0.050000
2017/08/30 00:44:47 step 3: mse=25336.945357 step=0.050000
2017/08/30 00:44:48 step 4: mse=24764.683826 step=0.050000
2017/08/30 00:44:49 step 5: mse=24246.287140 step=0.050000
2017/08/30 00:44:50 step 6: mse=23789.725053 step=0.050000
2017/08/30 00:44:51 step 7: mse=23379.128521 step=0.050000
2017/08/30 00:44:51 Saving...
2017/08/30 00:44:51 Gathering batch of experience...
2017/08/30 00:45:18 batch 440: mean=2584.404762 stddev=4072.677282 entropy=0.444979 frames=5964 count=42
2017/08/30 00:45:18 Training policy...
2017/08/30 00:45:22 tune 0: objective=47.314030 reg=0.004450 prune=0
2017/08/30 00:45:23 step 0: objective=47.372370 reg=0.004450
2017/08/30 00:45:25 step 1: objective=47.438946 reg=0.004449
2017/08/30 00:45:26 step 2: objective=47.551004 reg=0.004449
2017/08/30 00:45:27 step 3: objective=47.648935 reg=0.004448
2017/08/30 00:45:28 step 4: objective=47.711168 reg=0.004449
2017/08/30 00:45:29 step 5: objective=47.783356 reg=0.004449
2017/08/30 00:45:30 step 6: objective=47.863520 reg=0.004449
2017/08/30 00:45:31 step 7: objective=47.928697 reg=0.004448
2017/08/30 00:45:31 Training value function...
2017/08/30 00:45:34 step 0: mse=188367.877836 step=0.050000
2017/08/30 00:45:35 step 1: mse=185288.661508 step=0.050000
2017/08/30 00:45:36 step 2: mse=183000.583953 step=0.050000
2017/08/30 00:45:37 step 3: mse=180043.512318 step=0.050000
2017/08/30 00:45:38 step 4: mse=180061.790921 step=0.050000
2017/08/30 00:45:39 step 5: mse=180002.567823 step=0.050000
2017/08/30 00:45:40 step 6: mse=178746.948032 step=0.050000
2017/08/30 00:45:40 step 7: mse=177604.306622 step=0.050000
2017/08/30 00:45:40 Saving...
2017/08/30 00:45:41 Gathering batch of experience...
2017/08/30 00:46:04 batch 441: mean=1995.875000 stddev=2777.984631 entropy=0.434796 frames=5102 count=40
2017/08/30 00:46:04 Training policy...
2017/08/30 00:46:07 tune 0: objective=25.627216 reg=0.004348 prune=0
2017/08/30 00:46:08 step 0: objective=25.699704 reg=0.004348
2017/08/30 00:46:09 step 1: objective=25.762348 reg=0.004349
2017/08/30 00:46:10 step 2: objective=25.817302 reg=0.004348
2017/08/30 00:46:11 step 3: objective=25.860425 reg=0.004349
2017/08/30 00:46:12 step 4: objective=25.899169 reg=0.004349
2017/08/30 00:46:13 step 5: objective=25.928196 reg=0.004349
2017/08/30 00:46:14 step 6: objective=25.959412 reg=0.004348
2017/08/30 00:46:15 step 7: objective=25.985184 reg=0.004348
2017/08/30 00:46:15 Training value function...
2017/08/30 00:46:17 step 0: mse=94441.636406 step=0.050000
2017/08/30 00:46:18 step 1: mse=94599.350297 step=0.050000
2017/08/30 00:46:19 step 2: mse=94837.918653 step=0.050000
2017/08/30 00:46:20 step 3: mse=94971.115258 step=0.050000
2017/08/30 00:46:20 step 4: mse=95201.002875 step=0.050000
2017/08/30 00:46:21 step 5: mse=95316.735425 step=0.050000
2017/08/30 00:46:22 step 6: mse=95634.009271 step=0.050000
2017/08/30 00:46:23 step 7: mse=95987.805416 step=0.050000
2017/08/30 00:46:23 Saving...
2017/08/30 00:46:23 Gathering batch of experience...
2017/08/30 00:46:48 batch 442: mean=2144.634146 stddev=2997.004478 entropy=0.441505 frames=5542 count=41
2017/08/30 00:46:48 Training policy...
2017/08/30 00:46:52 tune 0: objective=29.748607 reg=0.004415 prune=0
2017/08/30 00:46:53 step 0: objective=29.844173 reg=0.004416
2017/08/30 00:46:54 step 1: objective=29.926956 reg=0.004414
2017/08/30 00:46:55 step 2: objective=30.030602 reg=0.004414
2017/08/30 00:46:56 step 3: objective=30.107661 reg=0.004414
2017/08/30 00:46:57 step 4: objective=30.181830 reg=0.004413
2017/08/30 00:46:58 step 5: objective=30.228195 reg=0.004413
2017/08/30 00:46:59 step 6: objective=30.273770 reg=0.004412
2017/08/30 00:47:01 step 7: objective=30.307631 reg=0.004412
2017/08/30 00:47:01 Training value function...
2017/08/30 00:47:03 step 0: mse=102867.910649 step=0.050000
2017/08/30 00:47:04 step 1: mse=102645.639017 step=0.050000
2017/08/30 00:47:05 step 2: mse=102572.476220 step=0.050000
2017/08/30 00:47:05 step 3: mse=102814.110207 step=0.050000
2017/08/30 00:47:06 step 4: mse=103229.413198 step=0.050000
2017/08/30 00:47:07 step 5: mse=103135.889779 step=0.050000
2017/08/30 00:47:08 step 6: mse=103461.092497 step=0.050000
2017/08/30 00:47:09 step 7: mse=103810.893092 step=0.050000
2017/08/30 00:47:09 Saving...
2017/08/30 00:47:09 Gathering batch of experience...
2017/08/30 00:47:38 batch 443: mean=2378.139535 stddev=3950.436688 entropy=0.444081 frames=5754 count=43
2017/08/30 00:47:38 Training policy...
2017/08/30 00:47:42 tune 0: objective=40.804869 reg=0.004441 prune=0
2017/08/30 00:47:43 step 0: objective=40.884246 reg=0.004440
2017/08/30 00:47:44 step 1: objective=40.953326 reg=0.004439
2017/08/30 00:47:45 step 2: objective=41.061099 reg=0.004438
2017/08/30 00:47:46 step 3: objective=41.168434 reg=0.004437
2017/08/30 00:47:47 step 4: objective=41.318336 reg=0.004433
2017/08/30 00:47:48 step 5: objective=41.458056 reg=0.004431
2017/08/30 00:47:49 step 6: objective=41.515590 reg=0.004430
2017/08/30 00:47:51 step 7: objective=41.571890 reg=0.004429
2017/08/30 00:47:51 Training value function...
2017/08/30 00:47:53 step 0: mse=185472.888034 step=0.050000
2017/08/30 00:47:54 step 1: mse=184680.189143 step=0.050000
2017/08/30 00:47:55 step 2: mse=180842.142775 step=0.050000
2017/08/30 00:47:56 step 3: mse=177662.969120 step=0.050000
2017/08/30 00:47:57 step 4: mse=177160.618857 step=0.050000
2017/08/30 00:47:57 step 5: mse=175871.326748 step=0.050000
2017/08/30 00:47:58 step 6: mse=173885.663117 step=0.050000
2017/08/30 00:47:59 step 7: mse=173101.377379 step=0.050000
2017/08/30 00:47:59 Saving...
2017/08/30 00:47:59 Gathering batch of experience...
2017/08/30 00:48:27 batch 444: mean=3211.944444 stddev=5368.540211 entropy=0.443972 frames=5512 count=36
2017/08/30 00:48:27 Training policy...
2017/08/30 00:48:31 tune 0: objective=60.663484 reg=0.004440 prune=0
2017/08/30 00:48:32 step 0: objective=60.803690 reg=0.004442
2017/08/30 00:48:33 step 1: objective=60.999246 reg=0.004444
2017/08/30 00:48:34 step 2: objective=61.115798 reg=0.004445
2017/08/30 00:48:35 step 3: objective=61.189649 reg=0.004444
2017/08/30 00:48:36 step 4: objective=61.276624 reg=0.004445
2017/08/30 00:48:37 step 5: objective=61.361926 reg=0.004444
2017/08/30 00:48:38 step 6: objective=61.446361 reg=0.004445
2017/08/30 00:48:39 step 7: objective=61.515591 reg=0.004445
2017/08/30 00:48:39 Training value function...
2017/08/30 00:48:41 step 0: mse=275779.783292 step=0.050000
2017/08/30 00:48:42 step 1: mse=273024.989660 step=0.050000
2017/08/30 00:48:43 step 2: mse=270593.979785 step=0.050000
2017/08/30 00:48:44 step 3: mse=263588.582008 step=0.050000
2017/08/30 00:48:45 step 4: mse=259214.375414 step=0.050000
2017/08/30 00:48:46 step 5: mse=257253.563591 step=0.050000
2017/08/30 00:48:47 step 6: mse=255425.973088 step=0.050000
2017/08/30 00:48:47 step 7: mse=249903.650446 step=0.050000
2017/08/30 00:48:47 Saving...
2017/08/30 00:48:48 Gathering batch of experience...
2017/08/30 00:49:12 batch 445: mean=1652.380952 stddev=654.187280 entropy=0.435405 frames=5187 count=42
2017/08/30 00:49:12 Training policy...
2017/08/30 00:49:15 tune 0: objective=6.049050 reg=0.004354 prune=0
2017/08/30 00:49:16 step 0: objective=6.075303 reg=0.004354
2017/08/30 00:49:17 step 1: objective=6.106089 reg=0.004354
2017/08/30 00:49:18 step 2: objective=6.135276 reg=0.004354
2017/08/30 00:49:19 step 3: objective=6.179433 reg=0.004355
2017/08/30 00:49:20 step 4: objective=6.223436 reg=0.004355
2017/08/30 00:49:21 step 5: objective=6.252819 reg=0.004355
2017/08/30 00:49:22 step 6: objective=6.288753 reg=0.004355
2017/08/30 00:49:23 step 7: objective=6.311993 reg=0.004355
2017/08/30 00:49:23 Training value function...
2017/08/30 00:49:25 step 0: mse=23968.208713 step=0.050000
2017/08/30 00:49:26 step 1: mse=23237.598888 step=0.050000
2017/08/30 00:49:27 step 2: mse=22563.986016 step=0.050000
2017/08/30 00:49:28 step 3: mse=21984.067240 step=0.050000
2017/08/30 00:49:29 step 4: mse=21438.973535 step=0.050000
2017/08/30 00:49:29 step 5: mse=20962.311015 step=0.050000
2017/08/30 00:49:30 step 6: mse=20540.536350 step=0.050000
2017/08/30 00:49:31 step 7: mse=20141.820616 step=0.050000
2017/08/30 00:49:31 Saving...
2017/08/30 00:49:31 Gathering batch of experience...
2017/08/30 00:49:55 batch 446: mean=1694.875000 stddev=459.394285 entropy=0.430702 frames=5107 count=40
2017/08/30 00:49:55 Training policy...
2017/08/30 00:49:58 tune 0: objective=16.007712 reg=0.004307 prune=0
2017/08/30 00:49:59 step 0: objective=16.015230 reg=0.004306
2017/08/30 00:50:00 step 1: objective=16.025876 reg=0.004306
2017/08/30 00:50:01 step 2: objective=16.039788 reg=0.004305
2017/08/30 00:50:02 step 3: objective=16.055137 reg=0.004304
2017/08/30 00:50:03 step 4: objective=16.064553 reg=0.004304
2017/08/30 00:50:04 step 5: objective=16.074010 reg=0.004303
2017/08/30 00:50:05 step 6: objective=16.081050 reg=0.004303
2017/08/30 00:50:06 step 7: objective=16.091417 reg=0.004303
2017/08/30 00:50:06 Training value function...
2017/08/30 00:50:08 step 0: mse=11454.480364 step=0.050000
2017/08/30 00:50:09 step 1: mse=11414.019645 step=0.050000
2017/08/30 00:50:10 step 2: mse=11380.641655 step=0.050000
2017/08/30 00:50:10 step 3: mse=11359.921316 step=0.050000
2017/08/30 00:50:11 step 4: mse=11346.608487 step=0.050000
2017/08/30 00:50:12 step 5: mse=11336.619949 step=0.050000
2017/08/30 00:50:13 step 6: mse=11330.605149 step=0.050000
2017/08/30 00:50:14 step 7: mse=11332.575248 step=0.050000
2017/08/30 00:50:14 Saving...
2017/08/30 00:50:14 Gathering batch of experience...
2017/08/30 00:50:38 batch 447: mean=1794.000000 stddev=909.698576 entropy=0.435647 frames=5205 count=40
2017/08/30 00:50:38 Training policy...
2017/08/30 00:50:41 tune 0: objective=19.323883 reg=0.004356 prune=0
2017/08/30 00:50:42 step 0: objective=19.347693 reg=0.004356
2017/08/30 00:50:43 step 1: objective=19.371231 reg=0.004356
2017/08/30 00:50:44 step 2: objective=19.396123 reg=0.004355
2017/08/30 00:50:45 step 3: objective=19.430939 reg=0.004354
2017/08/30 00:50:46 step 4: objective=19.457278 reg=0.004354
2017/08/30 00:50:47 step 5: objective=19.501980 reg=0.004354
2017/08/30 00:50:48 step 6: objective=19.542707 reg=0.004353
2017/08/30 00:50:49 step 7: objective=19.570066 reg=0.004352
2017/08/30 00:50:49 Training value function...
2017/08/30 00:50:51 step 0: mse=23777.281594 step=0.050000
2017/08/30 00:50:52 step 1: mse=23386.552980 step=0.050000
2017/08/30 00:50:53 step 2: mse=23075.027052 step=0.050000
2017/08/30 00:50:53 step 3: mse=22816.843217 step=0.050000
2017/08/30 00:50:54 step 4: mse=22542.801333 step=0.050000
2017/08/30 00:50:55 step 5: mse=22311.699244 step=0.050000
2017/08/30 00:50:56 step 6: mse=22102.156959 step=0.050000
2017/08/30 00:50:57 step 7: mse=21897.109320 step=0.050000
2017/08/30 00:50:57 Saving...
2017/08/30 00:50:57 Gathering batch of experience...
2017/08/30 00:51:26 batch 448: mean=3901.666667 stddev=6003.842867 entropy=0.450488 frames=6165 count=36
2017/08/30 00:51:26 Training policy...
2017/08/30 00:51:30 tune 0: objective=94.741636 reg=0.004505 prune=0
2017/08/30 00:51:31 step 0: objective=94.865247 reg=0.004503
2017/08/30 00:51:33 step 1: objective=95.007938 reg=0.004502
2017/08/30 00:51:34 step 2: objective=95.131154 reg=0.004501
2017/08/30 00:51:35 step 3: objective=95.219394 reg=0.004501
2017/08/30 00:51:36 step 4: objective=95.350923 reg=0.004501
2017/08/30 00:51:37 step 5: objective=95.430829 reg=0.004500
2017/08/30 00:51:39 step 6: objective=95.529542 reg=0.004497
2017/08/30 00:51:40 step 7: objective=95.600223 reg=0.004498
2017/08/30 00:51:40 Training value function...
2017/08/30 00:51:42 step 0: mse=385924.836898 step=0.050000
2017/08/30 00:51:43 step 1: mse=377227.182463 step=0.050000
2017/08/30 00:51:44 step 2: mse=363568.642593 step=0.050000
2017/08/30 00:51:45 step 3: mse=348547.953367 step=0.050000
2017/08/30 00:51:46 step 4: mse=335992.309249 step=0.050000
2017/08/30 00:51:47 step 5: mse=321227.498583 step=0.050000
2017/08/30 00:51:48 step 6: mse=309016.508218 step=0.050000
2017/08/30 00:51:49 step 7: mse=304499.154371 step=0.050000
2017/08/30 00:51:49 Saving...
2017/08/30 00:51:49 Gathering batch of experience...
2017/08/30 00:52:13 batch 449: mean=2328.611111 stddev=2945.949576 entropy=0.436638 frames=5172 count=36
2017/08/30 00:52:13 Training policy...
2017/08/30 00:52:17 tune 0: objective=29.438983 reg=0.004366 prune=0
2017/08/30 00:52:18 step 0: objective=29.513160 reg=0.004366
2017/08/30 00:52:19 step 1: objective=29.570122 reg=0.004364
2017/08/30 00:52:20 step 2: objective=29.611390 reg=0.004364
2017/08/30 00:52:21 step 3: objective=29.647072 reg=0.004364
2017/08/30 00:52:22 step 4: objective=29.697041 reg=0.004363
2017/08/30 00:52:23 step 5: objective=29.729871 reg=0.004362
2017/08/30 00:52:24 step 6: objective=29.777963 reg=0.004361
2017/08/30 00:52:25 step 7: objective=29.841309 reg=0.004360
2017/08/30 00:52:25 Training value function...
2017/08/30 00:52:27 step 0: mse=103411.793289 step=0.050000
2017/08/30 00:52:28 step 1: mse=102311.605345 step=0.050000
2017/08/30 00:52:28 step 2: mse=102216.710336 step=0.050000
2017/08/30 00:52:29 step 3: mse=102553.704210 step=0.050000
2017/08/30 00:52:30 step 4: mse=102886.233115 step=0.050000
2017/08/30 00:52:31 step 5: mse=103055.784040 step=0.050000
2017/08/30 00:52:32 step 6: mse=103475.560842 step=0.050000
2017/08/30 00:52:33 step 7: mse=103875.219488 step=0.050000
2017/08/30 00:52:33 Saving...
2017/08/30 00:52:33 Gathering batch of experience...
2017/08/30 00:52:59 batch 450: mean=2712.894737 stddev=4538.149059 entropy=0.443469 frames=5386 count=38
2017/08/30 00:52:59 Training policy...
2017/08/30 00:53:02 tune 0: objective=47.293153 reg=0.004435 prune=0
2017/08/30 00:53:04 step 0: objective=47.405507 reg=0.004435
2017/08/30 00:53:05 step 1: objective=47.555091 reg=0.004433
2017/08/30 00:53:06 step 2: objective=47.643506 reg=0.004430
2017/08/30 00:53:07 step 3: objective=47.721813 reg=0.004429
2017/08/30 00:53:08 step 4: objective=47.791111 reg=0.004429
2017/08/30 00:53:09 step 5: objective=47.872012 reg=0.004427
2017/08/30 00:53:10 step 6: objective=47.962347 reg=0.004427
2017/08/30 00:53:11 step 7: objective=48.015103 reg=0.004426
2017/08/30 00:53:11 Training value function...
2017/08/30 00:53:13 step 0: mse=188999.380568 step=0.050000
2017/08/30 00:53:14 step 1: mse=187674.968022 step=0.050000
2017/08/30 00:53:15 step 2: mse=184708.806299 step=0.050000
2017/08/30 00:53:16 step 3: mse=183176.484214 step=0.050000
2017/08/30 00:53:16 step 4: mse=181903.374680 step=0.050000
2017/08/30 00:53:17 step 5: mse=178438.049952 step=0.050000
2017/08/30 00:53:18 step 6: mse=176787.953011 step=0.050000
2017/08/30 00:53:19 step 7: mse=174525.618943 step=0.050000
2017/08/30 00:53:19 Saving...
2017/08/30 00:53:19 Gathering batch of experience...
2017/08/30 00:53:44 batch 451: mean=2247.564103 stddev=2956.827577 entropy=0.434454 frames=5492 count=39
2017/08/30 00:53:44 Training policy...
2017/08/30 00:53:47 tune 0: objective=20.376178 reg=0.004345 prune=0
2017/08/30 00:53:48 step 0: objective=20.429909 reg=0.004344
2017/08/30 00:53:49 step 1: objective=20.479886 reg=0.004343
2017/08/30 00:53:50 step 2: objective=20.529637 reg=0.004343
2017/08/30 00:53:51 step 3: objective=20.585511 reg=0.004341
2017/08/30 00:53:53 step 4: objective=20.629186 reg=0.004340
2017/08/30 00:53:54 step 5: objective=20.672165 reg=0.004340
2017/08/30 00:53:55 step 6: objective=20.706728 reg=0.004339
2017/08/30 00:53:56 step 7: objective=20.737109 reg=0.004339
2017/08/30 00:53:56 Training value function...
2017/08/30 00:53:58 step 0: mse=87398.245911 step=0.050000
2017/08/30 00:53:59 step 1: mse=87807.806813 step=0.050000
2017/08/30 00:54:00 step 2: mse=88069.765247 step=0.050000
2017/08/30 00:54:01 step 3: mse=88370.723654 step=0.050000
2017/08/30 00:54:01 step 4: mse=88880.225921 step=0.050000
2017/08/30 00:54:02 step 5: mse=88892.950136 step=0.050000
2017/08/30 00:54:03 step 6: mse=88334.594988 step=0.050000
2017/08/30 00:54:04 step 7: mse=87846.070589 step=0.050000
2017/08/30 00:54:04 Saving...
2017/08/30 00:54:04 Gathering batch of experience...
2017/08/30 00:54:33 batch 452: mean=4262.142857 stddev=6619.019164 entropy=0.446065 frames=6124 count=35
2017/08/30 00:54:33 Training policy...
2017/08/30 00:54:37 tune 0: objective=77.932188 reg=0.004461 prune=0
2017/08/30 00:54:38 step 0: objective=78.035220 reg=0.004460
2017/08/30 00:54:40 step 1: objective=78.272060 reg=0.004462
2017/08/30 00:54:41 step 2: objective=78.459376 reg=0.004462
2017/08/30 00:54:42 step 3: objective=78.599435 reg=0.004462
2017/08/30 00:54:43 step 4: objective=78.658745 reg=0.004461
2017/08/30 00:54:44 step 5: objective=78.749673 reg=0.004460
2017/08/30 00:54:45 step 6: objective=78.819838 reg=0.004459
2017/08/30 00:54:47 step 7: objective=78.869208 reg=0.004459
2017/08/30 00:54:47 Training value function...
2017/08/30 00:54:49 step 0: mse=316170.070278 step=0.050000
2017/08/30 00:54:50 step 1: mse=306002.407830 step=0.050000
2017/08/30 00:54:51 step 2: mse=292414.303142 step=0.050000
2017/08/30 00:54:52 step 3: mse=288124.120955 step=0.050000
2017/08/30 00:54:53 step 4: mse=280801.765519 step=0.050000
2017/08/30 00:54:54 step 5: mse=269900.979472 step=0.050000
2017/08/30 00:54:55 step 6: mse=267251.764420 step=0.050000
2017/08/30 00:54:56 step 7: mse=259444.684924 step=0.050000
2017/08/30 00:54:56 Saving...
2017/08/30 00:54:56 Gathering batch of experience...
2017/08/30 00:55:21 batch 453: mean=2754.054054 stddev=4314.422832 entropy=0.440276 frames=5522 count=37
2017/08/30 00:55:21 Training policy...
2017/08/30 00:55:25 tune 0: objective=46.397410 reg=0.004403 prune=0
2017/08/30 00:55:26 step 0: objective=46.494711 reg=0.004402
2017/08/30 00:55:27 step 1: objective=46.609341 reg=0.004401
2017/08/30 00:55:28 step 2: objective=46.766397 reg=0.004401
2017/08/30 00:55:29 step 3: objective=46.850425 reg=0.004401
2017/08/30 00:55:30 step 4: objective=46.928819 reg=0.004400
2017/08/30 00:55:31 step 5: objective=46.997139 reg=0.004399
2017/08/30 00:55:32 step 6: objective=47.057857 reg=0.004397
2017/08/30 00:55:33 step 7: objective=47.113486 reg=0.004395
2017/08/30 00:55:33 Training value function...
2017/08/30 00:55:36 step 0: mse=228029.218718 step=0.050000
2017/08/30 00:55:37 step 1: mse=226521.067830 step=0.050000
2017/08/30 00:55:37 step 2: mse=225045.052219 step=0.050000
2017/08/30 00:55:38 step 3: mse=222643.034519 step=0.050000
2017/08/30 00:55:39 step 4: mse=221684.963755 step=0.050000
2017/08/30 00:55:40 step 5: mse=219971.731638 step=0.050000
2017/08/30 00:55:41 step 6: mse=218682.007451 step=0.050000
2017/08/30 00:55:42 step 7: mse=213582.049575 step=0.050000
2017/08/30 00:55:42 Saving...
2017/08/30 00:55:42 Gathering batch of experience...
2017/08/30 00:56:07 batch 454: mean=2325.769231 stddev=3054.731626 entropy=0.431047 frames=5460 count=39
2017/08/30 00:56:07 Training policy...
2017/08/30 00:56:10 tune 0: objective=11.969836 reg=0.004310 prune=0
2017/08/30 00:56:11 step 0: objective=12.059570 reg=0.004310
2017/08/30 00:56:12 step 1: objective=12.170501 reg=0.004310
2017/08/30 00:56:13 step 2: objective=12.270185 reg=0.004309
2017/08/30 00:56:14 step 3: objective=12.329698 reg=0.004308
2017/08/30 00:56:15 step 4: objective=12.389253 reg=0.004309
2017/08/30 00:56:16 step 5: objective=12.468666 reg=0.004309
2017/08/30 00:56:18 step 6: objective=12.527644 reg=0.004310
2017/08/30 00:56:19 step 7: objective=12.590267 reg=0.004311
2017/08/30 00:56:19 Training value function...
2017/08/30 00:56:21 step 0: mse=102961.831732 step=0.050000
2017/08/30 00:56:22 step 1: mse=101503.151787 step=0.050000
2017/08/30 00:56:23 step 2: mse=101247.350925 step=0.050000
2017/08/30 00:56:23 step 3: mse=101009.732866 step=0.050000
2017/08/30 00:56:24 step 4: mse=100872.366443 step=0.050000
2017/08/30 00:56:25 step 5: mse=100522.433872 step=0.050000
2017/08/30 00:56:26 step 6: mse=99621.199080 step=0.050000
2017/08/30 00:56:27 step 7: mse=99210.989467 step=0.050000
2017/08/30 00:56:27 Saving...
2017/08/30 00:56:27 Gathering batch of experience...
2017/08/30 00:56:51 batch 455: mean=1796.875000 stddev=905.081963 entropy=0.425865 frames=5179 count=40
2017/08/30 00:56:51 Training policy...
2017/08/30 00:56:55 tune 0: objective=7.918449 reg=0.004259 prune=0
2017/08/30 00:56:56 step 0: objective=7.945079 reg=0.004258
2017/08/30 00:56:57 step 1: objective=7.969211 reg=0.004258
2017/08/30 00:56:58 step 2: objective=7.994544 reg=0.004258
2017/08/30 00:56:59 step 3: objective=8.021363 reg=0.004258
2017/08/30 00:57:00 step 4: objective=8.053601 reg=0.004257
2017/08/30 00:57:01 step 5: objective=8.083490 reg=0.004257
2017/08/30 00:57:02 step 6: objective=8.101894 reg=0.004257
2017/08/30 00:57:03 step 7: objective=8.128528 reg=0.004258
2017/08/30 00:57:03 Training value function...
2017/08/30 00:57:05 step 0: mse=22037.144874 step=0.050000
2017/08/30 00:57:06 step 1: mse=21596.921038 step=0.050000
2017/08/30 00:57:06 step 2: mse=21219.588021 step=0.050000
2017/08/30 00:57:07 step 3: mse=20875.887661 step=0.050000
2017/08/30 00:57:08 step 4: mse=20592.584868 step=0.050000
2017/08/30 00:57:09 step 5: mse=20330.169849 step=0.050000
2017/08/30 00:57:10 step 6: mse=20071.019262 step=0.050000
2017/08/30 00:57:10 step 7: mse=19870.435426 step=0.050000
2017/08/30 00:57:10 Saving...
2017/08/30 00:57:10 Gathering batch of experience...
2017/08/30 00:57:34 batch 456: mean=1795.000000 stddev=659.150021 entropy=0.426141 frames=5268 count=40
2017/08/30 00:57:34 Training policy...
2017/08/30 00:57:38 tune 0: objective=15.744342 reg=0.004261 prune=0
2017/08/30 00:57:39 step 0: objective=15.774820 reg=0.004261
2017/08/30 00:57:40 step 1: objective=15.806012 reg=0.004261
2017/08/30 00:57:41 step 2: objective=15.831322 reg=0.004261
2017/08/30 00:57:42 step 3: objective=15.863895 reg=0.004261
2017/08/30 00:57:43 step 4: objective=15.888310 reg=0.004261
2017/08/30 00:57:44 step 5: objective=15.899771 reg=0.004261
2017/08/30 00:57:45 step 6: objective=15.916100 reg=0.004260
2017/08/30 00:57:46 step 7: objective=15.928747 reg=0.004260
2017/08/30 00:57:46 Training value function...
2017/08/30 00:57:48 step 0: mse=23728.545683 step=0.050000
2017/08/30 00:57:49 step 1: mse=23067.198990 step=0.050000
2017/08/30 00:57:50 step 2: mse=22482.613552 step=0.050000
2017/08/30 00:57:51 step 3: mse=21937.558812 step=0.050000
2017/08/30 00:57:51 step 4: mse=21466.508423 step=0.050000
2017/08/30 00:57:52 step 5: mse=21003.962568 step=0.050000
2017/08/30 00:57:53 step 6: mse=20622.905980 step=0.050000
2017/08/30 00:57:54 step 7: mse=20280.547324 step=0.050000
2017/08/30 00:57:54 Saving...
2017/08/30 00:57:54 Gathering batch of experience...
2017/08/30 00:58:20 batch 457: mean=4838.870968 stddev=6963.803733 entropy=0.444502 frames=5826 count=31
2017/08/30 00:58:20 Training policy...
2017/08/30 00:58:24 tune 0: objective=112.514761 reg=0.004445 prune=0
2017/08/30 00:58:25 step 0: objective=112.697960 reg=0.004445
2017/08/30 00:58:26 step 1: objective=112.946189 reg=0.004444
2017/08/30 00:58:27 step 2: objective=113.175925 reg=0.004442
2017/08/30 00:58:28 step 3: objective=113.301708 reg=0.004441
2017/08/30 00:58:30 step 4: objective=113.449279 reg=0.004439
2017/08/30 00:58:31 step 5: objective=113.549637 reg=0.004439
2017/08/30 00:58:32 step 6: objective=113.643269 reg=0.004438
2017/08/30 00:58:33 step 7: objective=113.701596 reg=0.004437
2017/08/30 00:58:33 Training value function...
2017/08/30 00:58:35 step 0: mse=472190.198138 step=0.050000
2017/08/30 00:58:36 step 1: mse=458740.290385 step=0.050000
2017/08/30 00:58:37 step 2: mse=440335.404008 step=0.050000
2017/08/30 00:58:38 step 3: mse=426460.267199 step=0.050000
2017/08/30 00:58:39 step 4: mse=413929.360400 step=0.050000
2017/08/30 00:58:40 step 5: mse=399405.983343 step=0.050000
2017/08/30 00:58:41 step 6: mse=387453.351200 step=0.050000
2017/08/30 00:58:42 step 7: mse=374396.037494 step=0.050000
2017/08/30 00:58:42 Saving...
2017/08/30 00:58:42 Gathering batch of experience...
2017/08/30 00:59:11 batch 458: mean=5271.093750 stddev=7299.234949 entropy=0.449980 frames=6402 count=32
2017/08/30 00:59:11 Training policy...
2017/08/30 00:59:15 tune 0: objective=100.623418 reg=0.004500 prune=0
2017/08/30 00:59:17 step 0: objective=100.812256 reg=0.004500
2017/08/30 00:59:18 step 1: objective=101.029415 reg=0.004501
2017/08/30 00:59:19 step 2: objective=101.222196 reg=0.004501
2017/08/30 00:59:20 step 3: objective=101.487543 reg=0.004504
2017/08/30 00:59:22 step 4: objective=101.618518 reg=0.004503
2017/08/30 00:59:23 step 5: objective=101.697399 reg=0.004503
2017/08/30 00:59:24 step 6: objective=101.812041 reg=0.004502
2017/08/30 00:59:25 step 7: objective=101.857564 reg=0.004502
2017/08/30 00:59:25 Training value function...
2017/08/30 00:59:28 step 0: mse=485314.308614 step=0.050000
2017/08/30 00:59:29 step 1: mse=463666.941041 step=0.050000
2017/08/30 00:59:30 step 2: mse=452323.518774 step=0.050000
2017/08/30 00:59:31 step 3: mse=437540.709517 step=0.050000
2017/08/30 00:59:32 step 4: mse=427681.461158 step=0.050000
2017/08/30 00:59:33 step 5: mse=419386.427863 step=0.050000
2017/08/30 00:59:34 step 6: mse=406138.241573 step=0.050000
2017/08/30 00:59:35 step 7: mse=386510.637228 step=0.050000
2017/08/30 00:59:35 Saving...
2017/08/30 00:59:35 Gathering batch of experience...
2017/08/30 01:00:06 batch 459: mean=3314.500000 stddev=4908.207896 entropy=0.442821 frames=6502 count=40
2017/08/30 01:00:06 Training policy...
2017/08/30 01:00:11 tune 0: objective=30.935460 reg=0.004428 prune=0
2017/08/30 01:00:12 step 0: objective=31.074508 reg=0.004428
2017/08/30 01:00:13 step 1: objective=31.328171 reg=0.004427
2017/08/30 01:00:14 step 2: objective=31.489900 reg=0.004426
2017/08/30 01:00:16 step 3: objective=31.613061 reg=0.004425
2017/08/30 01:00:17 step 4: objective=31.699826 reg=0.004426
2017/08/30 01:00:18 step 5: objective=31.768338 reg=0.004426
2017/08/30 01:00:20 step 6: objective=31.819813 reg=0.004427
2017/08/30 01:00:21 step 7: objective=31.876098 reg=0.004426
2017/08/30 01:00:21 Training value function...
2017/08/30 01:00:23 step 0: mse=241239.372572 step=0.050000
2017/08/30 01:00:24 step 1: mse=233731.080556 step=0.050000
2017/08/30 01:00:25 step 2: mse=230991.732180 step=0.050000
2017/08/30 01:00:27 step 3: mse=224805.021324 step=0.050000
2017/08/30 01:00:28 step 4: mse=220411.321059 step=0.050000
2017/08/30 01:00:29 step 5: mse=217794.655655 step=0.050000
2017/08/30 01:00:30 step 6: mse=212988.840868 step=0.050000
2017/08/30 01:00:31 step 7: mse=210584.352040 step=0.050000
2017/08/30 01:00:31 Saving...
2017/08/30 01:00:31 Gathering batch of experience...
2017/08/30 01:01:00 batch 460: mean=4964.285714 stddev=7030.716702 entropy=0.449534 frames=6574 count=35
2017/08/30 01:01:00 Training policy...
2017/08/30 01:01:05 tune 0: objective=73.934192 reg=0.004495 prune=0
2017/08/30 01:01:06 step 0: objective=74.069645 reg=0.004496
2017/08/30 01:01:07 step 1: objective=74.246596 reg=0.004495
2017/08/30 01:01:08 step 2: objective=74.428929 reg=0.004495
2017/08/30 01:01:10 step 3: objective=74.594416 reg=0.004494
2017/08/30 01:01:11 step 4: objective=74.687562 reg=0.004494
2017/08/30 01:01:12 step 5: objective=74.808483 reg=0.004493
2017/08/30 01:01:14 step 6: objective=74.868141 reg=0.004493
2017/08/30 01:01:15 step 7: objective=74.926676 reg=0.004493
2017/08/30 01:01:15 Training value function...
2017/08/30 01:01:17 step 0: mse=323990.932118 step=0.050000
2017/08/30 01:01:19 step 1: mse=318009.513688 step=0.050000
2017/08/30 01:01:20 step 2: mse=313846.995816 step=0.050000
2017/08/30 01:01:21 step 3: mse=309470.051492 step=0.050000
2017/08/30 01:01:22 step 4: mse=300746.395842 step=0.050000
2017/08/30 01:01:23 step 5: mse=290081.524987 step=0.050000
2017/08/30 01:01:24 step 6: mse=280294.221810 step=0.050000
2017/08/30 01:01:25 step 7: mse=275021.386915 step=0.050000
2017/08/30 01:01:25 Saving...
2017/08/30 01:01:25 Gathering batch of experience...
2017/08/30 01:01:53 batch 461: mean=3670.675676 stddev=5696.293148 entropy=0.439147 frames=6061 count=37
2017/08/30 01:01:53 Training policy...
2017/08/30 01:01:57 tune 0: objective=45.347808 reg=0.004391 prune=0
2017/08/30 01:01:58 step 0: objective=45.449642 reg=0.004392
2017/08/30 01:01:59 step 1: objective=45.616823 reg=0.004391
2017/08/30 01:02:00 step 2: objective=45.746551 reg=0.004391
2017/08/30 01:02:01 step 3: objective=45.849251 reg=0.004389
2017/08/30 01:02:03 step 4: objective=45.946317 reg=0.004390
2017/08/30 01:02:04 step 5: objective=45.988214 reg=0.004390
2017/08/30 01:02:05 step 6: objective=46.059829 reg=0.004389
2017/08/30 01:02:06 step 7: objective=46.117637 reg=0.004389
2017/08/30 01:02:06 Training value function...
2017/08/30 01:02:09 step 0: mse=239837.510327 step=0.050000
2017/08/30 01:02:10 step 1: mse=237690.559934 step=0.050000
2017/08/30 01:02:10 step 2: mse=233901.995090 step=0.050000
2017/08/30 01:02:11 step 3: mse=229167.390682 step=0.050000
2017/08/30 01:02:12 step 4: mse=223647.656598 step=0.050000
2017/08/30 01:02:13 step 5: mse=222923.760580 step=0.050000
2017/08/30 01:02:14 step 6: mse=221224.340184 step=0.050000
2017/08/30 01:02:15 step 7: mse=217626.044779 step=0.050000
2017/08/30 01:02:15 Saving...
2017/08/30 01:02:15 Gathering batch of experience...
2017/08/30 01:02:43 batch 462: mean=3350.731707 stddev=5691.310188 entropy=0.440893 frames=6109 count=41
2017/08/30 01:02:43 Training policy...
2017/08/30 01:02:47 tune 0: objective=46.566705 reg=0.004409 prune=0
2017/08/30 01:02:48 step 0: objective=46.629097 reg=0.004408
2017/08/30 01:02:49 step 1: objective=46.692498 reg=0.004407
2017/08/30 01:02:51 step 2: objective=46.778263 reg=0.004406
2017/08/30 01:02:52 step 3: objective=46.872171 reg=0.004406
2017/08/30 01:02:53 step 4: objective=46.940682 reg=0.004404
2017/08/30 01:02:54 step 5: objective=46.981544 reg=0.004403
2017/08/30 01:02:55 step 6: objective=47.092159 reg=0.004403
2017/08/30 01:02:57 step 7: objective=47.151216 reg=0.004402
2017/08/30 01:02:57 Training value function...
2017/08/30 01:02:59 step 0: mse=180125.564285 step=0.050000
2017/08/30 01:03:00 step 1: mse=174598.106957 step=0.050000
2017/08/30 01:03:01 step 2: mse=170002.668368 step=0.050000
2017/08/30 01:03:02 step 3: mse=164741.217486 step=0.050000
2017/08/30 01:03:03 step 4: mse=160093.883581 step=0.050000
2017/08/30 01:03:04 step 5: mse=156019.180911 step=0.050000
2017/08/30 01:03:05 step 6: mse=152783.917170 step=0.050000
2017/08/30 01:03:06 step 7: mse=147605.304664 step=0.050000
2017/08/30 01:03:06 Saving...
2017/08/30 01:03:06 Gathering batch of experience...
2017/08/30 01:03:29 batch 463: mean=2449.285714 stddev=3167.633444 entropy=0.431782 frames=5198 count=35
2017/08/30 01:03:29 Training policy...
2017/08/30 01:03:33 tune 0: objective=18.133127 reg=0.004318 prune=0
2017/08/30 01:03:34 step 0: objective=18.178285 reg=0.004317
2017/08/30 01:03:35 step 1: objective=18.254575 reg=0.004317
2017/08/30 01:03:36 step 2: objective=18.337897 reg=0.004317
2017/08/30 01:03:37 step 3: objective=18.404325 reg=0.004317
2017/08/30 01:03:38 step 4: objective=18.452031 reg=0.004317
2017/08/30 01:03:39 step 5: objective=18.490363 reg=0.004316
2017/08/30 01:03:40 step 6: objective=18.534095 reg=0.004316
2017/08/30 01:03:41 step 7: objective=18.578271 reg=0.004316
2017/08/30 01:03:41 Training value function...
2017/08/30 01:03:43 step 0: mse=68371.065710 step=0.050000
2017/08/30 01:03:44 step 1: mse=68600.777232 step=0.050000
2017/08/30 01:03:45 step 2: mse=68554.386361 step=0.050000
2017/08/30 01:03:46 step 3: mse=68522.407713 step=0.050000
2017/08/30 01:03:46 step 4: mse=68847.288958 step=0.050000
2017/08/30 01:03:47 step 5: mse=69054.932506 step=0.050000
2017/08/30 01:03:48 step 6: mse=69425.489133 step=0.050000
2017/08/30 01:03:49 step 7: mse=69877.095473 step=0.050000
2017/08/30 01:03:49 Saving...
2017/08/30 01:03:49 Gathering batch of experience...
2017/08/30 01:04:12 batch 464: mean=1711.875000 stddev=761.470360 entropy=0.431378 frames=5094 count=40
2017/08/30 01:04:12 Training policy...
2017/08/30 01:04:16 tune 0: objective=4.105659 reg=0.004314 prune=0
2017/08/30 01:04:17 step 0: objective=4.166942 reg=0.004314
2017/08/30 01:04:18 step 1: objective=4.225963 reg=0.004313
2017/08/30 01:04:19 step 2: objective=4.272583 reg=0.004313
2017/08/30 01:04:20 step 3: objective=4.300442 reg=0.004313
2017/08/30 01:04:21 step 4: objective=4.349725 reg=0.004313
2017/08/30 01:04:22 step 5: objective=4.383608 reg=0.004312
2017/08/30 01:04:23 step 6: objective=4.403867 reg=0.004312
2017/08/30 01:04:24 step 7: objective=4.434985 reg=0.004312
2017/08/30 01:04:24 Training value function...
2017/08/30 01:04:26 step 0: mse=28064.285282 step=0.050000
2017/08/30 01:04:27 step 1: mse=27129.631158 step=0.050000
2017/08/30 01:04:27 step 2: mse=26283.192418 step=0.050000
2017/08/30 01:04:28 step 3: mse=25525.756391 step=0.050000
2017/08/30 01:04:29 step 4: mse=24804.158907 step=0.050000
2017/08/30 01:04:30 step 5: mse=24160.949921 step=0.050000
2017/08/30 01:04:31 step 6: mse=23631.314537 step=0.050000
2017/08/30 01:04:31 step 7: mse=23154.347949 step=0.050000
2017/08/30 01:04:31 Saving...
2017/08/30 01:04:31 Gathering batch of experience...
2017/08/30 01:04:56 batch 465: mean=1731.625000 stddev=624.388088 entropy=0.428934 frames=5205 count=40
2017/08/30 01:04:56 Training policy...
2017/08/30 01:04:59 tune 0: objective=15.467410 reg=0.004289 prune=0
2017/08/30 01:05:00 step 0: objective=15.478841 reg=0.004289
2017/08/30 01:05:01 step 1: objective=15.496819 reg=0.004288
2017/08/30 01:05:02 step 2: objective=15.516188 reg=0.004287
2017/08/30 01:05:03 step 3: objective=15.537625 reg=0.004287
2017/08/30 01:05:04 step 4: objective=15.555870 reg=0.004286
2017/08/30 01:05:05 step 5: objective=15.571983 reg=0.004285
2017/08/30 01:05:06 step 6: objective=15.594508 reg=0.004284
2017/08/30 01:05:07 step 7: objective=15.607608 reg=0.004284
2017/08/30 01:05:07 Training value function...
2017/08/30 01:05:09 step 0: mse=15708.824286 step=0.050000
2017/08/30 01:05:10 step 1: mse=15537.509823 step=0.050000
2017/08/30 01:05:11 step 2: mse=15377.252273 step=0.050000
2017/08/30 01:05:12 step 3: mse=15249.327628 step=0.050000
2017/08/30 01:05:13 step 4: mse=15134.088564 step=0.050000
2017/08/30 01:05:14 step 5: mse=15040.176939 step=0.050000
2017/08/30 01:05:14 step 6: mse=14959.801121 step=0.050000
2017/08/30 01:05:15 step 7: mse=14891.889884 step=0.050000
2017/08/30 01:05:15 Saving...
2017/08/30 01:05:15 Gathering batch of experience...
2017/08/30 01:05:45 batch 466: mean=3195.263158 stddev=5106.526261 entropy=0.435133 frames=5901 count=38
2017/08/30 01:05:45 Training policy...
2017/08/30 01:05:49 tune 0: objective=66.157770 reg=0.004351 prune=0
2017/08/30 01:05:50 step 0: objective=66.258023 reg=0.004352
2017/08/30 01:05:51 step 1: objective=66.351799 reg=0.004351
2017/08/30 01:05:52 step 2: objective=66.465869 reg=0.004351
2017/08/30 01:05:53 step 3: objective=66.564745 reg=0.004351
2017/08/30 01:05:55 step 4: objective=66.678005 reg=0.004350
2017/08/30 01:05:56 step 5: objective=66.730702 reg=0.004352
2017/08/30 01:05:57 step 6: objective=66.802295 reg=0.004351
2017/08/30 01:05:58 step 7: objective=66.870758 reg=0.004350
2017/08/30 01:05:58 Training value function...
2017/08/30 01:06:00 step 0: mse=252425.009109 step=0.050000
2017/08/30 01:06:01 step 1: mse=245183.980046 step=0.050000
2017/08/30 01:06:02 step 2: mse=242458.857503 step=0.050000
2017/08/30 01:06:03 step 3: mse=235190.438726 step=0.050000
2017/08/30 01:06:04 step 4: mse=230171.111185 step=0.050000
2017/08/30 01:06:05 step 5: mse=228651.798697 step=0.050000
2017/08/30 01:06:06 step 6: mse=224264.201932 step=0.050000
2017/08/30 01:06:07 step 7: mse=219255.764461 step=0.050000
2017/08/30 01:06:07 Saving...
2017/08/30 01:06:07 Gathering batch of experience...
2017/08/30 01:06:35 batch 467: mean=4036.911765 stddev=5960.471262 entropy=0.441691 frames=5932 count=34
2017/08/30 01:06:35 Training policy...
2017/08/30 01:06:39 tune 0: objective=65.335737 reg=0.004417 prune=0
2017/08/30 01:06:40 step 0: objective=65.421749 reg=0.004416
2017/08/30 01:06:41 step 1: objective=65.490270 reg=0.004417
2017/08/30 01:06:42 step 2: objective=65.558623 reg=0.004417
2017/08/30 01:06:44 step 3: objective=65.674746 reg=0.004416
2017/08/30 01:06:45 step 4: objective=65.760626 reg=0.004418
2017/08/30 01:06:46 step 5: objective=65.821635 reg=0.004416
2017/08/30 01:06:47 step 6: objective=65.887991 reg=0.004416
2017/08/30 01:06:48 step 7: objective=65.948163 reg=0.004414
2017/08/30 01:06:48 Training value function...
2017/08/30 01:06:51 step 0: mse=253412.743088 step=0.050000
2017/08/30 01:06:52 step 1: mse=247994.820328 step=0.050000
2017/08/30 01:06:53 step 2: mse=242785.403357 step=0.050000
2017/08/30 01:06:53 step 3: mse=237808.546200 step=0.050000
2017/08/30 01:06:54 step 4: mse=235342.691582 step=0.050000
2017/08/30 01:06:55 step 5: mse=229293.061852 step=0.050000
2017/08/30 01:06:56 step 6: mse=225074.897120 step=0.050000
2017/08/30 01:06:57 step 7: mse=222317.170038 step=0.050000
2017/08/30 01:06:57 Saving...
2017/08/30 01:06:57 Gathering batch of experience...
2017/08/30 01:07:23 batch 468: mean=2819.054054 stddev=4287.071992 entropy=0.435959 frames=5729 count=37
2017/08/30 01:07:23 Training policy...
2017/08/30 01:07:27 tune 0: objective=36.362111 reg=0.004360 prune=0
2017/08/30 01:07:28 step 0: objective=36.425876 reg=0.004359
2017/08/30 01:07:29 step 1: objective=36.484110 reg=0.004360
2017/08/30 01:07:31 step 2: objective=36.543619 reg=0.004360
2017/08/30 01:07:32 step 3: objective=36.633280 reg=0.004360
2017/08/30 01:07:33 step 4: objective=36.706551 reg=0.004360
2017/08/30 01:07:34 step 5: objective=36.816335 reg=0.004359
2017/08/30 01:07:35 step 6: objective=36.857979 reg=0.004358
2017/08/30 01:07:36 step 7: objective=36.903913 reg=0.004357
2017/08/30 01:07:36 Training value function...
2017/08/30 01:07:38 step 0: mse=118536.594749 step=0.050000
2017/08/30 01:07:39 step 1: mse=118601.860717 step=0.050000
2017/08/30 01:07:40 step 2: mse=118916.687882 step=0.050000
2017/08/30 01:07:41 step 3: mse=119042.392642 step=0.050000
2017/08/30 01:07:42 step 4: mse=118008.086285 step=0.050000
2017/08/30 01:07:43 step 5: mse=117999.253800 step=0.050000
2017/08/30 01:07:44 step 6: mse=117744.909740 step=0.050000
2017/08/30 01:07:45 step 7: mse=117878.100557 step=0.050000
2017/08/30 01:07:45 Saving...
2017/08/30 01:07:45 Gathering batch of experience...
2017/08/30 01:08:13 batch 469: mean=3108.552632 stddev=5056.591569 entropy=0.438974 frames=5652 count=38
2017/08/30 01:08:13 Training policy...
2017/08/30 01:08:17 tune 0: objective=49.250503 reg=0.004390 prune=0
2017/08/30 01:08:18 step 0: objective=49.344646 reg=0.004389
2017/08/30 01:08:19 step 1: objective=49.461883 reg=0.004387
2017/08/30 01:08:20 step 2: objective=49.569925 reg=0.004388
2017/08/30 01:08:21 step 3: objective=49.705408 reg=0.004388
2017/08/30 01:08:22 step 4: objective=49.769700 reg=0.004386
2017/08/30 01:08:23 step 5: objective=49.852525 reg=0.004386
2017/08/30 01:08:24 step 6: objective=49.906659 reg=0.004385
2017/08/30 01:08:25 step 7: objective=49.976308 reg=0.004385
2017/08/30 01:08:25 Training value function...
2017/08/30 01:08:28 step 0: mse=177163.758840 step=0.050000
2017/08/30 01:08:28 step 1: mse=176917.539783 step=0.050000
2017/08/30 01:08:29 step 2: mse=173677.018464 step=0.050000
2017/08/30 01:08:30 step 3: mse=170834.373332 step=0.050000
2017/08/30 01:08:31 step 4: mse=167122.318781 step=0.050000
2017/08/30 01:08:32 step 5: mse=164742.819748 step=0.050000
2017/08/30 01:08:33 step 6: mse=162628.598899 step=0.050000
2017/08/30 01:08:34 step 7: mse=160702.725363 step=0.050000
2017/08/30 01:08:34 Saving...
2017/08/30 01:08:34 Gathering batch of experience...
2017/08/30 01:09:00 batch 470: mean=2250.500000 stddev=3136.874798 entropy=0.431234 frames=5543 count=40
2017/08/30 01:09:00 Training policy...
2017/08/30 01:09:03 tune 0: objective=20.631693 reg=0.004312 prune=0
2017/08/30 01:09:04 step 0: objective=20.705658 reg=0.004311
2017/08/30 01:09:06 step 1: objective=20.780920 reg=0.004312
2017/08/30 01:09:07 step 2: objective=20.856009 reg=0.004311
2017/08/30 01:09:08 step 3: objective=20.940615 reg=0.004310
2017/08/30 01:09:09 step 4: objective=21.039284 reg=0.004310
2017/08/30 01:09:10 step 5: objective=21.091010 reg=0.004310
2017/08/30 01:09:11 step 6: objective=21.123561 reg=0.004311
2017/08/30 01:09:12 step 7: objective=21.176866 reg=0.004311
2017/08/30 01:09:12 Training value function...
2017/08/30 01:09:14 step 0: mse=109788.867618 step=0.050000
2017/08/30 01:09:15 step 1: mse=108755.969856 step=0.050000
2017/08/30 01:09:16 step 2: mse=107569.100486 step=0.050000
2017/08/30 01:09:17 step 3: mse=107541.515738 step=0.050000
2017/08/30 01:09:18 step 4: mse=107402.233287 step=0.050000
2017/08/30 01:09:19 step 5: mse=107588.436974 step=0.050000
2017/08/30 01:09:20 step 6: mse=107630.550974 step=0.050000
2017/08/30 01:09:20 step 7: mse=107570.681854 step=0.050000
2017/08/30 01:09:20 Saving...
2017/08/30 01:09:21 Gathering batch of experience...
2017/08/30 01:09:48 batch 471: mean=3655.571429 stddev=5276.627815 entropy=0.438659 frames=5929 count=35
2017/08/30 01:09:48 Training policy...
2017/08/30 01:09:52 tune 0: objective=50.177559 reg=0.004387 prune=0
2017/08/30 01:09:54 step 0: objective=50.296804 reg=0.004385
2017/08/30 01:09:55 step 1: objective=50.452975 reg=0.004385
2017/08/30 01:09:56 step 2: objective=50.569579 reg=0.004385
2017/08/30 01:09:57 step 3: objective=50.658432 reg=0.004383
2017/08/30 01:09:58 step 4: objective=50.742015 reg=0.004383
2017/08/30 01:09:59 step 5: objective=50.808099 reg=0.004383
2017/08/30 01:10:01 step 6: objective=50.852378 reg=0.004381
2017/08/30 01:10:02 step 7: objective=50.904664 reg=0.004382
2017/08/30 01:10:02 Training value function...
2017/08/30 01:10:04 step 0: mse=179147.688591 step=0.050000
2017/08/30 01:10:05 step 1: mse=179410.425311 step=0.050000
2017/08/30 01:10:06 step 2: mse=177508.457472 step=0.050000
2017/08/30 01:10:07 step 3: mse=174564.708684 step=0.050000
2017/08/30 01:10:08 step 4: mse=171905.041298 step=0.050000
2017/08/30 01:10:09 step 5: mse=172063.654583 step=0.050000
2017/08/30 01:10:10 step 6: mse=168658.517053 step=0.050000
2017/08/30 01:10:11 step 7: mse=168636.437147 step=0.050000
2017/08/30 01:10:11 Saving...
2017/08/30 01:10:11 Gathering batch of experience...
2017/08/30 01:10:37 batch 472: mean=2205.125000 stddev=2883.822656 entropy=0.430990 frames=5501 count=40
2017/08/30 01:10:37 Training policy...
2017/08/30 01:10:41 tune 0: objective=21.376748 reg=0.004310 prune=0
2017/08/30 01:10:42 step 0: objective=21.423663 reg=0.004310
2017/08/30 01:10:43 step 1: objective=21.473109 reg=0.004310
2017/08/30 01:10:44 step 2: objective=21.524724 reg=0.004310
2017/08/30 01:10:45 step 3: objective=21.565975 reg=0.004309
2017/08/30 01:10:46 step 4: objective=21.618042 reg=0.004309
2017/08/30 01:10:47 step 5: objective=21.658278 reg=0.004308
2017/08/30 01:10:48 step 6: objective=21.692188 reg=0.004309
2017/08/30 01:10:49 step 7: objective=21.726572 reg=0.004309
2017/08/30 01:10:49 Training value function...
2017/08/30 01:10:51 step 0: mse=75242.549271 step=0.050000
2017/08/30 01:10:52 step 1: mse=75744.215147 step=0.050000
2017/08/30 01:10:53 step 2: mse=76082.462566 step=0.050000
2017/08/30 01:10:54 step 3: mse=76560.197689 step=0.050000
2017/08/30 01:10:55 step 4: mse=76979.739486 step=0.050000
2017/08/30 01:10:56 step 5: mse=77459.082480 step=0.050000
2017/08/30 01:10:57 step 6: mse=77991.143631 step=0.050000
2017/08/30 01:10:57 step 7: mse=78533.881023 step=0.050000
2017/08/30 01:10:57 Saving...
2017/08/30 01:10:57 Gathering batch of experience...
2017/08/30 01:11:29 batch 473: mean=4181.710526 stddev=6407.747395 entropy=0.440731 frames=6604 count=38
2017/08/30 01:11:29 Training policy...
2017/08/30 01:11:33 tune 0: objective=71.394988 reg=0.004407 prune=0
2017/08/30 01:11:34 step 0: objective=71.457654 reg=0.004407
2017/08/30 01:11:36 step 1: objective=71.570573 reg=0.004407
2017/08/30 01:11:37 step 2: objective=71.645395 reg=0.004408
2017/08/30 01:11:38 step 3: objective=71.712603 reg=0.004409
2017/08/30 01:11:40 step 4: objective=71.803926 reg=0.004410
2017/08/30 01:11:41 step 5: objective=71.889082 reg=0.004409
2017/08/30 01:11:42 step 6: objective=71.968253 reg=0.004410
2017/08/30 01:11:43 step 7: objective=72.049274 reg=0.004409
2017/08/30 01:11:43 Training value function...
2017/08/30 01:11:46 step 0: mse=227227.293369 step=0.050000
2017/08/30 01:11:47 step 1: mse=218951.030723 step=0.050000
2017/08/30 01:11:48 step 2: mse=212859.835438 step=0.050000
2017/08/30 01:11:49 step 3: mse=210962.968225 step=0.050000
2017/08/30 01:11:50 step 4: mse=203018.745231 step=0.050000
2017/08/30 01:11:51 step 5: mse=196901.558426 step=0.050000
2017/08/30 01:11:52 step 6: mse=195844.047183 step=0.050000
2017/08/30 01:11:53 step 7: mse=194852.346090 step=0.050000
2017/08/30 01:11:53 Saving...
2017/08/30 01:11:54 Gathering batch of experience...
2017/08/30 01:12:23 batch 474: mean=4414.736842 stddev=6844.442035 entropy=0.444507 frames=6430 count=38
2017/08/30 01:12:23 Training policy...
2017/08/30 01:12:28 tune 0: objective=73.742793 reg=0.004445 prune=0
2017/08/30 01:12:29 step 0: objective=73.844299 reg=0.004446
2017/08/30 01:12:30 step 1: objective=73.920475 reg=0.004446
2017/08/30 01:12:31 step 2: objective=74.083602 reg=0.004447
2017/08/30 01:12:33 step 3: objective=74.244124 reg=0.004450
2017/08/30 01:12:34 step 4: objective=74.333933 reg=0.004451
2017/08/30 01:12:35 step 5: objective=74.440542 reg=0.004450
2017/08/30 01:12:36 step 6: objective=74.490382 reg=0.004450
2017/08/30 01:12:38 step 7: objective=74.546340 reg=0.004451
2017/08/30 01:12:38 Training value function...
2017/08/30 01:12:40 step 0: mse=285278.882181 step=0.050000
2017/08/30 01:12:41 step 1: mse=283100.815789 step=0.050000
2017/08/30 01:12:42 step 2: mse=277081.089908 step=0.050000
2017/08/30 01:12:43 step 3: mse=270195.407238 step=0.050000
2017/08/30 01:12:44 step 4: mse=265729.210232 step=0.050000
2017/08/30 01:12:45 step 5: mse=261889.143020 step=0.050000
2017/08/30 01:12:46 step 6: mse=260334.444535 step=0.050000
2017/08/30 01:12:47 step 7: mse=256083.118118 step=0.050000
2017/08/30 01:12:47 Saving...
2017/08/30 01:12:47 Gathering batch of experience...
2017/08/30 01:13:16 batch 475: mean=3901.666667 stddev=5786.013548 entropy=0.443023 frames=6246 count=36
2017/08/30 01:13:16 Training policy...
2017/08/30 01:13:20 tune 0: objective=44.721046 reg=0.004430 prune=0
2017/08/30 01:13:21 step 0: objective=44.841779 reg=0.004429
2017/08/30 01:13:23 step 1: objective=44.984065 reg=0.004431
2017/08/30 01:13:24 step 2: objective=45.138118 reg=0.004429
2017/08/30 01:13:25 step 3: objective=45.240539 reg=0.004428
2017/08/30 01:13:26 step 4: objective=45.316703 reg=0.004427
2017/08/30 01:13:28 step 5: objective=45.408286 reg=0.004426
2017/08/30 01:13:29 step 6: objective=45.458699 reg=0.004425
2017/08/30 01:13:30 step 7: objective=45.510427 reg=0.004425
2017/08/30 01:13:30 Training value function...
2017/08/30 01:13:33 step 0: mse=178187.293595 step=0.050000
2017/08/30 01:13:34 step 1: mse=178780.887487 step=0.050000
2017/08/30 01:13:35 step 2: mse=174799.202039 step=0.050000
2017/08/30 01:13:36 step 3: mse=172527.081827 step=0.050000
2017/08/30 01:13:37 step 4: mse=169627.389561 step=0.050000
2017/08/30 01:13:38 step 5: mse=169136.757473 step=0.050000
2017/08/30 01:13:39 step 6: mse=168815.269313 step=0.050000
2017/08/30 01:13:40 step 7: mse=169217.781926 step=0.050000
2017/08/30 01:13:40 Saving...
2017/08/30 01:13:40 Gathering batch of experience...
2017/08/30 01:14:05 batch 476: mean=3673.125000 stddev=5629.486787 entropy=0.436094 frames=5456 count=32
2017/08/30 01:14:05 Training policy...
2017/08/30 01:14:08 tune 0: objective=45.292788 reg=0.004361 prune=0
2017/08/30 01:14:09 step 0: objective=45.376211 reg=0.004361
2017/08/30 01:14:11 step 1: objective=45.566684 reg=0.004360
2017/08/30 01:14:12 step 2: objective=45.683723 reg=0.004359
2017/08/30 01:14:13 step 3: objective=45.758586 reg=0.004360
2017/08/30 01:14:14 step 4: objective=45.868319 reg=0.004361
2017/08/30 01:14:15 step 5: objective=45.940292 reg=0.004359
2017/08/30 01:14:16 step 6: objective=46.024377 reg=0.004359
2017/08/30 01:14:17 step 7: objective=46.145107 reg=0.004359
2017/08/30 01:14:17 Training value function...
2017/08/30 01:14:19 step 0: mse=198835.396406 step=0.050000
2017/08/30 01:14:20 step 1: mse=195054.489582 step=0.050000
2017/08/30 01:14:21 step 2: mse=192562.164337 step=0.050000
2017/08/30 01:14:22 step 3: mse=189132.159570 step=0.050000
2017/08/30 01:14:23 step 4: mse=188447.664343 step=0.050000
2017/08/30 01:14:23 step 5: mse=185956.029244 step=0.050000
2017/08/30 01:14:24 step 6: mse=181242.244574 step=0.050000
2017/08/30 01:14:25 step 7: mse=179001.556070 step=0.050000
2017/08/30 01:14:25 Saving...
2017/08/30 01:14:25 Gathering batch of experience...
2017/08/30 01:14:53 batch 477: mean=2198.536585 stddev=2912.020555 entropy=0.428105 frames=5463 count=41
2017/08/30 01:14:53 Training policy...
2017/08/30 01:14:56 tune 0: objective=9.532235 reg=0.004281 prune=0
2017/08/30 01:14:57 step 0: objective=9.605825 reg=0.004280
2017/08/30 01:14:58 step 1: objective=9.662422 reg=0.004281
2017/08/30 01:14:59 step 2: objective=9.723664 reg=0.004280
2017/08/30 01:15:00 step 3: objective=9.792745 reg=0.004280
2017/08/30 01:15:02 step 4: objective=9.838593 reg=0.004280
2017/08/30 01:15:03 step 5: objective=9.883119 reg=0.004281
2017/08/30 01:15:04 step 6: objective=9.926318 reg=0.004280
2017/08/30 01:15:05 step 7: objective=9.955252 reg=0.004280
2017/08/30 01:15:05 Training value function...
2017/08/30 01:15:07 step 0: mse=72023.346765 step=0.050000
2017/08/30 01:15:08 step 1: mse=72242.818634 step=0.050000
2017/08/30 01:15:09 step 2: mse=71991.439778 step=0.050000
2017/08/30 01:15:10 step 3: mse=72521.032986 step=0.050000
2017/08/30 01:15:10 step 4: mse=72947.479758 step=0.050000
2017/08/30 01:15:11 step 5: mse=73455.771573 step=0.050000
2017/08/30 01:15:12 step 6: mse=74040.750959 step=0.050000
2017/08/30 01:15:13 step 7: mse=73941.170650 step=0.050000
2017/08/30 01:15:13 Saving...
2017/08/30 01:15:13 Gathering batch of experience...
2017/08/30 01:15:41 batch 478: mean=3416.527778 stddev=4984.129510 entropy=0.436362 frames=5944 count=36
2017/08/30 01:15:41 Training policy...
2017/08/30 01:15:45 tune 0: objective=34.247037 reg=0.004364 prune=0
2017/08/30 01:15:46 step 0: objective=34.340159 reg=0.004366
2017/08/30 01:15:47 step 1: objective=34.457476 reg=0.004367
2017/08/30 01:15:48 step 2: objective=34.575622 reg=0.004369
2017/08/30 01:15:49 step 3: objective=34.668739 reg=0.004369
2017/08/30 01:15:50 step 4: objective=34.772299 reg=0.004371
2017/08/30 01:15:52 step 5: objective=34.845180 reg=0.004372
2017/08/30 01:15:53 step 6: objective=34.882660 reg=0.004373
2017/08/30 01:15:54 step 7: objective=34.944574 reg=0.004375
2017/08/30 01:15:54 Training value function...
2017/08/30 01:15:56 step 0: mse=160879.555662 step=0.050000
2017/08/30 01:15:57 step 1: mse=158881.066200 step=0.050000
2017/08/30 01:15:58 step 2: mse=159057.543725 step=0.050000
2017/08/30 01:15:59 step 3: mse=159765.253386 step=0.050000
2017/08/30 01:16:00 step 4: mse=159724.868872 step=0.050000
2017/08/30 01:16:01 step 5: mse=157956.433131 step=0.050000
2017/08/30 01:16:02 step 6: mse=157471.443107 step=0.050000
2017/08/30 01:16:03 step 7: mse=156805.572667 step=0.050000
2017/08/30 01:16:03 Saving...
2017/08/30 01:16:03 Gathering batch of experience...
2017/08/30 01:16:34 batch 479: mean=3303.333333 stddev=5110.184569 entropy=0.437650 frames=6036 count=39
2017/08/30 01:16:34 Training policy...
2017/08/30 01:16:38 tune 0: objective=39.059267 reg=0.004376 prune=0
2017/08/30 01:16:39 step 0: objective=39.135039 reg=0.004375
2017/08/30 01:16:40 step 1: objective=39.214657 reg=0.004373
2017/08/30 01:16:41 step 2: objective=39.293150 reg=0.004372
2017/08/30 01:16:42 step 3: objective=39.379025 reg=0.004370
2017/08/30 01:16:44 step 4: objective=39.475315 reg=0.004369
2017/08/30 01:16:45 step 5: objective=39.540820 reg=0.004367
2017/08/30 01:16:46 step 6: objective=39.615445 reg=0.004367
2017/08/30 01:16:47 step 7: objective=39.658228 reg=0.004367
2017/08/30 01:16:47 Training value function...
2017/08/30 01:16:50 step 0: mse=153443.802353 step=0.050000
2017/08/30 01:16:51 step 1: mse=151477.934329 step=0.050000
2017/08/30 01:16:52 step 2: mse=151109.980470 step=0.050000
2017/08/30 01:16:53 step 3: mse=149708.671263 step=0.050000
2017/08/30 01:16:53 step 4: mse=147674.417307 step=0.050000
2017/08/30 01:16:54 step 5: mse=147366.415155 step=0.050000
2017/08/30 01:16:55 step 6: mse=145260.041496 step=0.050000
2017/08/30 01:16:56 step 7: mse=143485.996013 step=0.050000
2017/08/30 01:16:56 Saving...
2017/08/30 01:16:56 Gathering batch of experience...
2017/08/30 01:17:25 batch 480: mean=3691.973684 stddev=5931.709785 entropy=0.440232 frames=6159 count=38
2017/08/30 01:17:25 Training policy...
2017/08/30 01:17:29 tune 0: objective=58.463392 reg=0.004402 prune=0
2017/08/30 01:17:30 step 0: objective=58.564190 reg=0.004401
2017/08/30 01:17:31 step 1: objective=58.700230 reg=0.004402
2017/08/30 01:17:32 step 2: objective=58.803311 reg=0.004403
2017/08/30 01:17:34 step 3: objective=58.893773 reg=0.004403
2017/08/30 01:17:35 step 4: objective=59.001319 reg=0.004401
2017/08/30 01:17:36 step 5: objective=59.075854 reg=0.004400
2017/08/30 01:17:37 step 6: objective=59.138354 reg=0.004398
2017/08/30 01:17:39 step 7: objective=59.206486 reg=0.004397
2017/08/30 01:17:39 Training value function...
2017/08/30 01:17:41 step 0: mse=210165.848085 step=0.050000
2017/08/30 01:17:42 step 1: mse=208568.611314 step=0.050000
2017/08/30 01:17:43 step 2: mse=205260.211418 step=0.050000
2017/08/30 01:17:44 step 3: mse=203673.578805 step=0.050000
2017/08/30 01:17:45 step 4: mse=201965.130594 step=0.050000
2017/08/30 01:17:46 step 5: mse=198277.286282 step=0.050000
2017/08/30 01:17:47 step 6: mse=196396.504880 step=0.050000
2017/08/30 01:17:48 step 7: mse=193047.865015 step=0.050000
2017/08/30 01:17:48 Saving...
2017/08/30 01:17:48 Gathering batch of experience...
2017/08/30 01:18:16 batch 481: mean=3915.285714 stddev=6193.974139 entropy=0.440583 frames=5945 count=35
2017/08/30 01:18:16 Training policy...
2017/08/30 01:18:20 tune 0: objective=56.175615 reg=0.004406 prune=0
2017/08/30 01:18:22 step 0: objective=56.326719 reg=0.004403
2017/08/30 01:18:23 step 1: objective=56.548465 reg=0.004401
2017/08/30 01:18:24 step 2: objective=56.658437 reg=0.004399
2017/08/30 01:18:25 step 3: objective=56.764356 reg=0.004399
2017/08/30 01:18:26 step 4: objective=56.830688 reg=0.004397
2017/08/30 01:18:27 step 5: objective=56.904868 reg=0.004395
2017/08/30 01:18:29 step 6: objective=56.985261 reg=0.004395
2017/08/30 01:18:30 step 7: objective=57.028601 reg=0.004394
2017/08/30 01:18:30 Training value function...
2017/08/30 01:18:32 step 0: mse=171489.621842 step=0.050000
2017/08/30 01:18:33 step 1: mse=169311.140501 step=0.050000
2017/08/30 01:18:34 step 2: mse=167363.023861 step=0.050000
2017/08/30 01:18:35 step 3: mse=166527.497359 step=0.050000
2017/08/30 01:18:36 step 4: mse=164182.497336 step=0.050000
2017/08/30 01:18:37 step 5: mse=161305.191579 step=0.050000
2017/08/30 01:18:38 step 6: mse=159805.748078 step=0.050000
2017/08/30 01:18:39 step 7: mse=159002.505092 step=0.050000
2017/08/30 01:18:39 Saving...
2017/08/30 01:18:39 Gathering batch of experience...
2017/08/30 01:19:01 batch 482: mean=2627.361111 stddev=4511.170778 entropy=0.433099 frames=4784 count=36
2017/08/30 01:19:01 Training policy...
2017/08/30 01:19:04 tune 0: objective=24.553747 reg=0.004331 prune=0
2017/08/30 01:19:05 step 0: objective=24.650012 reg=0.004330
2017/08/30 01:19:06 step 1: objective=24.756978 reg=0.004329
2017/08/30 01:19:07 step 2: objective=24.889613 reg=0.004328
2017/08/30 01:19:08 step 3: objective=24.983676 reg=0.004327
2017/08/30 01:19:09 step 4: objective=25.051305 reg=0.004328
2017/08/30 01:19:10 step 5: objective=25.134302 reg=0.004327
2017/08/30 01:19:11 step 6: objective=25.204258 reg=0.004328
2017/08/30 01:19:12 step 7: objective=25.258288 reg=0.004328
2017/08/30 01:19:12 Training value function...
2017/08/30 01:19:14 step 0: mse=126217.169791 step=0.050000
2017/08/30 01:19:14 step 1: mse=127563.500188 step=0.050000
2017/08/30 01:19:15 step 2: mse=128531.470227 step=0.050000
2017/08/30 01:19:16 step 3: mse=129024.290400 step=0.050000
2017/08/30 01:19:17 step 4: mse=129066.184276 step=0.050000
2017/08/30 01:19:17 step 5: mse=129781.469099 step=0.050000
2017/08/30 01:19:18 step 6: mse=130816.363952 step=0.050000
2017/08/30 01:19:19 step 7: mse=131424.430718 step=0.050000
2017/08/30 01:19:19 Saving...
2017/08/30 01:19:19 Gathering batch of experience...
2017/08/30 01:19:50 batch 483: mean=4673.857143 stddev=6489.089314 entropy=0.439148 frames=6544 count=35
2017/08/30 01:19:50 Training policy...
2017/08/30 01:19:55 tune 0: objective=54.200661 reg=0.004391 prune=0
2017/08/30 01:19:56 step 0: objective=54.346649 reg=0.004388
2017/08/30 01:19:57 step 1: objective=54.519479 reg=0.004387
2017/08/30 01:19:58 step 2: objective=54.616872 reg=0.004387
2017/08/30 01:20:00 step 3: objective=54.722857 reg=0.004385
2017/08/30 01:20:01 step 4: objective=54.876055 reg=0.004384
2017/08/30 01:20:02 step 5: objective=54.977198 reg=0.004386
2017/08/30 01:20:04 step 6: objective=55.039683 reg=0.004386
2017/08/30 01:20:05 step 7: objective=55.102307 reg=0.004386
2017/08/30 01:20:05 Training value function...
2017/08/30 01:20:08 step 0: mse=203104.440332 step=0.050000
2017/08/30 01:20:09 step 1: mse=199725.507952 step=0.050000
2017/08/30 01:20:10 step 2: mse=197512.934494 step=0.050000
2017/08/30 01:20:11 step 3: mse=194635.795120 step=0.050000
2017/08/30 01:20:12 step 4: mse=192965.526264 step=0.050000
2017/08/30 01:20:13 step 5: mse=193590.943308 step=0.050000
2017/08/30 01:20:14 step 6: mse=194060.578766 step=0.050000
2017/08/30 01:20:15 step 7: mse=194306.590787 step=0.050000
2017/08/30 01:20:15 Saving...
2017/08/30 01:20:15 Gathering batch of experience...
2017/08/30 01:20:44 batch 484: mean=2392.613636 stddev=4008.537407 entropy=0.435119 frames=5786 count=44
2017/08/30 01:20:44 Training policy...
2017/08/30 01:20:48 tune 0: objective=23.318927 reg=0.004351 prune=0
2017/08/30 01:20:49 step 0: objective=23.384711 reg=0.004351
2017/08/30 01:20:51 step 1: objective=23.514942 reg=0.004351
2017/08/30 01:20:52 step 2: objective=23.569618 reg=0.004351
2017/08/30 01:20:53 step 3: objective=23.634922 reg=0.004351
2017/08/30 01:20:54 step 4: objective=23.673749 reg=0.004351
2017/08/30 01:20:55 step 5: objective=23.715407 reg=0.004351
2017/08/30 01:20:56 step 6: objective=23.768504 reg=0.004351
2017/08/30 01:20:57 step 7: objective=23.810169 reg=0.004350
2017/08/30 01:20:57 Training value function...
2017/08/30 01:21:00 step 0: mse=106855.896265 step=0.050000
2017/08/30 01:21:01 step 1: mse=107482.011353 step=0.050000
2017/08/30 01:21:02 step 2: mse=108272.125046 step=0.050000
2017/08/30 01:21:02 step 3: mse=108856.737244 step=0.050000
2017/08/30 01:21:03 step 4: mse=109757.919023 step=0.050000
2017/08/30 01:21:04 step 5: mse=109560.842664 step=0.050000
2017/08/30 01:21:05 step 6: mse=110094.091614 step=0.050000
2017/08/30 01:21:06 step 7: mse=110848.154342 step=0.050000
2017/08/30 01:21:06 Saving...
2017/08/30 01:21:06 Gathering batch of experience...
2017/08/30 01:21:31 batch 485: mean=3129.411765 stddev=4493.391514 entropy=0.437761 frames=5631 count=34
2017/08/30 01:21:31 Training policy...
2017/08/30 01:21:35 tune 0: objective=32.178079 reg=0.004378 prune=0
2017/08/30 01:21:36 step 0: objective=32.298903 reg=0.004376
2017/08/30 01:21:37 step 1: objective=32.392895 reg=0.004374
2017/08/30 01:21:38 step 2: objective=32.468434 reg=0.004373
2017/08/30 01:21:40 step 3: objective=32.514851 reg=0.004374
2017/08/30 01:21:41 step 4: objective=32.558199 reg=0.004374
2017/08/30 01:21:42 step 5: objective=32.603171 reg=0.004374
2017/08/30 01:21:43 step 6: objective=32.645700 reg=0.004374
2017/08/30 01:21:44 step 7: objective=32.680541 reg=0.004373
2017/08/30 01:21:44 Training value function...
2017/08/30 01:21:46 step 0: mse=112326.132010 step=0.050000
2017/08/30 01:21:47 step 1: mse=112259.389088 step=0.050000
2017/08/30 01:21:48 step 2: mse=112581.156084 step=0.050000
2017/08/30 01:21:49 step 3: mse=112892.179001 step=0.050000
2017/08/30 01:21:50 step 4: mse=112947.288118 step=0.050000
2017/08/30 01:21:51 step 5: mse=113205.899194 step=0.050000
2017/08/30 01:21:52 step 6: mse=113957.730267 step=0.050000
2017/08/30 01:21:53 step 7: mse=113985.755096 step=0.050000
2017/08/30 01:21:53 Saving...
2017/08/30 01:21:53 Gathering batch of experience...
2017/08/30 01:22:21 batch 486: mean=4252.714286 stddev=6462.058976 entropy=0.440641 frames=6087 count=35
2017/08/30 01:22:21 Training policy...
2017/08/30 01:22:25 tune 0: objective=64.715870 reg=0.004406 prune=0
2017/08/30 01:22:26 step 0: objective=64.821012 reg=0.004407
2017/08/30 01:22:28 step 1: objective=64.923253 reg=0.004406
2017/08/30 01:22:29 step 2: objective=65.077168 reg=0.004406
2017/08/30 01:22:30 step 3: objective=65.181683 reg=0.004406
2017/08/30 01:22:31 step 4: objective=65.367381 reg=0.004405
2017/08/30 01:22:32 step 5: objective=65.424619 reg=0.004405
2017/08/30 01:22:34 step 6: objective=65.530465 reg=0.004405
2017/08/30 01:22:35 step 7: objective=65.630606 reg=0.004406
2017/08/30 01:22:35 Training value function...
2017/08/30 01:22:37 step 0: mse=250424.323826 step=0.050000
2017/08/30 01:22:38 step 1: mse=246217.808352 step=0.050000
2017/08/30 01:22:39 step 2: mse=241529.162115 step=0.050000
2017/08/30 01:22:40 step 3: mse=240265.087926 step=0.050000
2017/08/30 01:22:41 step 4: mse=236683.752520 step=0.050000
2017/08/30 01:22:42 step 5: mse=233179.072212 step=0.050000
2017/08/30 01:22:43 step 6: mse=225024.172566 step=0.050000
2017/08/30 01:22:44 step 7: mse=223766.435842 step=0.050000
2017/08/30 01:22:44 Saving...
2017/08/30 01:22:44 Gathering batch of experience...
2017/08/30 01:23:10 batch 487: mean=3543.823529 stddev=5535.377273 entropy=0.432466 frames=5618 count=34
2017/08/30 01:23:10 Training policy...
2017/08/30 01:23:14 tune 0: objective=45.427234 reg=0.004325 prune=0
2017/08/30 01:23:15 step 0: objective=45.525537 reg=0.004325
2017/08/30 01:23:16 step 1: objective=45.626246 reg=0.004326
2017/08/30 01:23:17 step 2: objective=45.725200 reg=0.004326
2017/08/30 01:23:18 step 3: objective=45.807488 reg=0.004326
2017/08/30 01:23:19 step 4: objective=45.861909 reg=0.004327
2017/08/30 01:23:21 step 5: objective=45.897144 reg=0.004327
2017/08/30 01:23:22 step 6: objective=45.943466 reg=0.004327
2017/08/30 01:23:23 step 7: objective=46.002231 reg=0.004327
2017/08/30 01:23:23 Training value function...
2017/08/30 01:23:25 step 0: mse=174876.291759 step=0.050000
2017/08/30 01:23:26 step 1: mse=172259.223898 step=0.050000
2017/08/30 01:23:27 step 2: mse=170666.827881 step=0.050000
2017/08/30 01:23:28 step 3: mse=170551.819753 step=0.050000
2017/08/30 01:23:29 step 4: mse=169210.114192 step=0.050000
2017/08/30 01:23:30 step 5: mse=168437.155701 step=0.050000
2017/08/30 01:23:30 step 6: mse=166336.979616 step=0.050000
2017/08/30 01:23:31 step 7: mse=163889.500144 step=0.050000
2017/08/30 01:23:31 Saving...
2017/08/30 01:23:31 Gathering batch of experience...
2017/08/30 01:23:55 batch 488: mean=3475.151515 stddev=5585.226791 entropy=0.430110 frames=5262 count=33
2017/08/30 01:23:55 Training policy...
2017/08/30 01:23:59 tune 0: objective=36.978790 reg=0.004301 prune=0
2017/08/30 01:24:00 step 0: objective=37.140405 reg=0.004302
2017/08/30 01:24:01 step 1: objective=37.259974 reg=0.004299
2017/08/30 01:24:02 step 2: objective=37.347741 reg=0.004299
2017/08/30 01:24:03 step 3: objective=37.423152 reg=0.004297
2017/08/30 01:24:04 step 4: objective=37.494703 reg=0.004298
2017/08/30 01:24:05 step 5: objective=37.552146 reg=0.004297
2017/08/30 01:24:06 step 6: objective=37.589557 reg=0.004296
2017/08/30 01:24:07 step 7: objective=37.630119 reg=0.004297
2017/08/30 01:24:07 Training value function...
2017/08/30 01:24:09 step 0: mse=149347.500029 step=0.050000
2017/08/30 01:24:10 step 1: mse=150064.465639 step=0.050000
2017/08/30 01:24:11 step 2: mse=148619.180805 step=0.050000
2017/08/30 01:24:12 step 3: mse=147669.008752 step=0.050000
2017/08/30 01:24:12 step 4: mse=146955.033764 step=0.050000
2017/08/30 01:24:13 step 5: mse=146191.236635 step=0.050000
2017/08/30 01:24:14 step 6: mse=146276.370510 step=0.050000
2017/08/30 01:24:15 step 7: mse=146679.263918 step=0.050000
2017/08/30 01:24:15 Saving...
2017/08/30 01:24:15 Gathering batch of experience...
2017/08/30 01:24:40 batch 489: mean=2599.871795 stddev=4299.374505 entropy=0.433053 frames=5582 count=39
2017/08/30 01:24:40 Training policy...
2017/08/30 01:24:44 tune 0: objective=22.461084 reg=0.004331 prune=0
2017/08/30 01:24:45 step 0: objective=22.499267 reg=0.004330
2017/08/30 01:24:46 step 1: objective=22.529050 reg=0.004330
2017/08/30 01:24:47 step 2: objective=22.585315 reg=0.004330
2017/08/30 01:24:49 step 3: objective=22.636853 reg=0.004331
2017/08/30 01:24:50 step 4: objective=22.678726 reg=0.004330
2017/08/30 01:24:51 step 5: objective=22.713990 reg=0.004330
2017/08/30 01:24:52 step 6: objective=22.743220 reg=0.004329
2017/08/30 01:24:53 step 7: objective=22.775046 reg=0.004328
2017/08/30 01:24:53 Training value function...
2017/08/30 01:24:55 step 0: mse=79479.489465 step=0.050000
2017/08/30 01:24:56 step 1: mse=80295.281054 step=0.050000
2017/08/30 01:24:57 step 2: mse=79969.679550 step=0.050000
2017/08/30 01:24:58 step 3: mse=80794.176003 step=0.050000
2017/08/30 01:24:59 step 4: mse=81337.177551 step=0.050000
2017/08/30 01:25:00 step 5: mse=82503.807194 step=0.050000
2017/08/30 01:25:00 step 6: mse=83595.722565 step=0.050000
2017/08/30 01:25:01 step 7: mse=84040.769789 step=0.050000
2017/08/30 01:25:01 Saving...
2017/08/30 01:25:01 Gathering batch of experience...
2017/08/30 01:25:29 batch 490: mean=2417.826087 stddev=3966.434256 entropy=0.434141 frames=6076 count=46
2017/08/30 01:25:29 Training policy...
2017/08/30 01:25:33 tune 0: objective=22.534655 reg=0.004341 prune=0
2017/08/30 01:25:35 step 0: objective=22.590091 reg=0.004341
2017/08/30 01:25:36 step 1: objective=22.669987 reg=0.004340
2017/08/30 01:25:37 step 2: objective=22.734545 reg=0.004339
2017/08/30 01:25:38 step 3: objective=22.789726 reg=0.004338
2017/08/30 01:25:40 step 4: objective=22.849595 reg=0.004337
2017/08/30 01:25:41 step 5: objective=22.887022 reg=0.004336
2017/08/30 01:25:42 step 6: objective=22.926607 reg=0.004336
2017/08/30 01:25:43 step 7: objective=22.956496 reg=0.004336
2017/08/30 01:25:43 Training value function...
2017/08/30 01:25:46 step 0: mse=97596.882358 step=0.050000
2017/08/30 01:25:47 step 1: mse=97296.619991 step=0.050000
2017/08/30 01:25:48 step 2: mse=97282.473192 step=0.050000
2017/08/30 01:25:49 step 3: mse=97703.646409 step=0.050000
2017/08/30 01:25:49 step 4: mse=98104.014779 step=0.050000
2017/08/30 01:25:50 step 5: mse=98318.361510 step=0.050000
2017/08/30 01:25:51 step 6: mse=98962.597623 step=0.050000
2017/08/30 01:25:52 step 7: mse=99848.974935 step=0.050000
2017/08/30 01:25:52 Saving...
2017/08/30 01:25:52 Gathering batch of experience...
2017/08/30 01:26:25 batch 491: mean=8095.517241 stddev=9162.312645 entropy=0.446409 frames=7094 count=29
2017/08/30 01:26:25 Training policy...
2017/08/30 01:26:30 tune 0: objective=109.620868 reg=0.004464 prune=0
2017/08/30 01:26:31 step 0: objective=109.737243 reg=0.004463
2017/08/30 01:26:33 step 1: objective=109.908911 reg=0.004461
2017/08/30 01:26:34 step 2: objective=110.047734 reg=0.004460
2017/08/30 01:26:36 step 3: objective=110.160902 reg=0.004460
2017/08/30 01:26:37 step 4: objective=110.250996 reg=0.004459
2017/08/30 01:26:38 step 5: objective=110.343503 reg=0.004458
2017/08/30 01:26:40 step 6: objective=110.443931 reg=0.004458
2017/08/30 01:26:41 step 7: objective=110.520519 reg=0.004458
2017/08/30 01:26:41 Training value function...
2017/08/30 01:26:44 step 0: mse=338378.773207 step=0.050000
2017/08/30 01:26:45 step 1: mse=324481.256305 step=0.050000
2017/08/30 01:26:46 step 2: mse=313315.176328 step=0.050000
2017/08/30 01:26:47 step 3: mse=302443.521489 step=0.050000
2017/08/30 01:26:49 step 4: mse=291738.904685 step=0.050000
2017/08/30 01:26:50 step 5: mse=285683.853647 step=0.050000
2017/08/30 01:26:51 step 6: mse=277024.317833 step=0.050000
2017/08/30 01:26:52 step 7: mse=269715.521889 step=0.050000
2017/08/30 01:26:52 Saving...
2017/08/30 01:26:52 Gathering batch of experience...
2017/08/30 01:27:20 batch 492: mean=3070.125000 stddev=5218.958527 entropy=0.434130 frames=5900 count=40
2017/08/30 01:27:20 Training policy...
2017/08/30 01:27:24 tune 0: objective=29.342609 reg=0.004341 prune=0
2017/08/30 01:27:26 step 0: objective=29.395644 reg=0.004341
2017/08/30 01:27:27 step 1: objective=29.446510 reg=0.004341
2017/08/30 01:27:28 step 2: objective=29.494944 reg=0.004342
2017/08/30 01:27:29 step 3: objective=29.561814 reg=0.004343
2017/08/30 01:27:30 step 4: objective=29.611785 reg=0.004343
2017/08/30 01:27:31 step 5: objective=29.666070 reg=0.004343
2017/08/30 01:27:33 step 6: objective=29.706118 reg=0.004342
2017/08/30 01:27:34 step 7: objective=29.751586 reg=0.004341
2017/08/30 01:27:34 Training value function...
2017/08/30 01:27:36 step 0: mse=112332.034357 step=0.050000
2017/08/30 01:27:37 step 1: mse=111694.128505 step=0.050000
2017/08/30 01:27:38 step 2: mse=111397.513034 step=0.050000
2017/08/30 01:27:39 step 3: mse=111758.703682 step=0.050000
2017/08/30 01:27:40 step 4: mse=110919.088182 step=0.050000
2017/08/30 01:27:41 step 5: mse=110528.191074 step=0.050000
2017/08/30 01:27:42 step 6: mse=109564.766740 step=0.050000
2017/08/30 01:27:43 step 7: mse=109749.591443 step=0.050000
2017/08/30 01:27:43 Saving...
2017/08/30 01:27:43 Gathering batch of experience...
2017/08/30 01:28:07 batch 493: mean=5148.888889 stddev=6916.851849 entropy=0.432714 frames=5537 count=27
2017/08/30 01:28:07 Training policy...
2017/08/30 01:28:11 tune 0: objective=58.425287 reg=0.004327 prune=0
2017/08/30 01:28:12 step 0: objective=58.601290 reg=0.004326
2017/08/30 01:28:13 step 1: objective=58.718095 reg=0.004325
2017/08/30 01:28:15 step 2: objective=58.807426 reg=0.004325
2017/08/30 01:28:16 step 3: objective=58.958822 reg=0.004325
2017/08/30 01:28:17 step 4: objective=59.100201 reg=0.004324
2017/08/30 01:28:18 step 5: objective=59.239706 reg=0.004324
2017/08/30 01:28:19 step 6: objective=59.308758 reg=0.004325
2017/08/30 01:28:20 step 7: objective=59.362482 reg=0.004325
2017/08/30 01:28:20 Training value function...
2017/08/30 01:28:22 step 0: mse=229503.778261 step=0.050000
2017/08/30 01:28:23 step 1: mse=228823.564931 step=0.050000
2017/08/30 01:28:24 step 2: mse=227709.863720 step=0.050000
2017/08/30 01:28:25 step 3: mse=225791.977457 step=0.050000
2017/08/30 01:28:26 step 4: mse=224661.951688 step=0.050000
2017/08/30 01:28:27 step 5: mse=224276.245176 step=0.050000
2017/08/30 01:28:28 step 6: mse=223566.988635 step=0.050000
2017/08/30 01:28:28 step 7: mse=220152.825202 step=0.050000
2017/08/30 01:28:28 Saving...
2017/08/30 01:28:29 Gathering batch of experience...
2017/08/30 01:28:57 batch 494: mean=4259.729730 stddev=6594.202403 entropy=0.439763 frames=6292 count=37
2017/08/30 01:28:57 Training policy...
2017/08/30 01:29:02 tune 0: objective=48.178664 reg=0.004398 prune=0
2017/08/30 01:29:03 step 0: objective=48.247268 reg=0.004397
2017/08/30 01:29:04 step 1: objective=48.363040 reg=0.004397
2017/08/30 01:29:05 step 2: objective=48.455057 reg=0.004398
2017/08/30 01:29:07 step 3: objective=48.562123 reg=0.004398
2017/08/30 01:29:08 step 4: objective=48.655644 reg=0.004397
2017/08/30 01:29:09 step 5: objective=48.748296 reg=0.004396
2017/08/30 01:29:10 step 6: objective=48.814551 reg=0.004397
2017/08/30 01:29:12 step 7: objective=48.890451 reg=0.004396
2017/08/30 01:29:12 Training value function...
2017/08/30 01:29:14 step 0: mse=163927.673469 step=0.050000
2017/08/30 01:29:15 step 1: mse=161727.162213 step=0.050000
2017/08/30 01:29:16 step 2: mse=160172.269955 step=0.050000
2017/08/30 01:29:17 step 3: mse=159129.917310 step=0.050000
2017/08/30 01:29:18 step 4: mse=157303.940463 step=0.050000
2017/08/30 01:29:19 step 5: mse=155882.480433 step=0.050000
2017/08/30 01:29:20 step 6: mse=156868.219452 step=0.050000
2017/08/30 01:29:21 step 7: mse=155526.977822 step=0.050000
2017/08/30 01:29:21 Saving...
2017/08/30 01:29:21 Gathering batch of experience...
2017/08/30 01:29:46 batch 495: mean=1588.152174 stddev=1103.763502 entropy=0.430272 frames=5288 count=46
2017/08/30 01:29:46 Training policy...
2017/08/30 01:29:50 tune 0: objective=-14.475892 reg=0.004303 prune=0
2017/08/30 01:29:51 step 0: objective=-14.397724 reg=0.004302
2017/08/30 01:29:52 step 1: objective=-14.295117 reg=0.004302
2017/08/30 01:29:53 step 2: objective=-14.243313 reg=0.004302
2017/08/30 01:29:54 step 3: objective=-14.188367 reg=0.004301
2017/08/30 01:29:55 step 4: objective=-14.128465 reg=0.004301
2017/08/30 01:29:56 step 5: objective=-14.092109 reg=0.004302
2017/08/30 01:29:57 step 6: objective=-14.066433 reg=0.004302
2017/08/30 01:29:58 step 7: objective=-14.035564 reg=0.004302
2017/08/30 01:29:58 Training value function...
2017/08/30 01:30:00 step 0: mse=49038.883691 step=0.050000
2017/08/30 01:30:01 step 1: mse=46164.374019 step=0.050000
2017/08/30 01:30:02 step 2: mse=43572.522195 step=0.050000
2017/08/30 01:30:03 step 3: mse=41282.122794 step=0.050000
2017/08/30 01:30:03 step 4: mse=39286.679945 step=0.050000
2017/08/30 01:30:04 step 5: mse=37558.775057 step=0.050000
2017/08/30 01:30:05 step 6: mse=36088.076314 step=0.050000
2017/08/30 01:30:06 step 7: mse=34780.711858 step=0.050000
2017/08/30 01:30:06 Saving...
2017/08/30 01:30:06 Gathering batch of experience...
2017/08/30 01:30:33 batch 496: mean=3052.000000 stddev=4307.577576 entropy=0.427845 frames=5501 count=35
2017/08/30 01:30:33 Training policy...
2017/08/30 01:30:36 tune 0: objective=39.953844 reg=0.004278 prune=0
2017/08/30 01:30:38 step 0: objective=40.039104 reg=0.004277
2017/08/30 01:30:39 step 1: objective=40.124688 reg=0.004275
2017/08/30 01:30:40 step 2: objective=40.233276 reg=0.004273
2017/08/30 01:30:41 step 3: objective=40.331394 reg=0.004272
2017/08/30 01:30:42 step 4: objective=40.428186 reg=0.004270
2017/08/30 01:30:43 step 5: objective=40.490715 reg=0.004271
2017/08/30 01:30:44 step 6: objective=40.597440 reg=0.004271
2017/08/30 01:30:45 step 7: objective=40.666950 reg=0.004270
2017/08/30 01:30:45 Training value function...
2017/08/30 01:30:47 step 0: mse=147113.845350 step=0.050000
2017/08/30 01:30:48 step 1: mse=144961.450238 step=0.050000
2017/08/30 01:30:49 step 2: mse=143985.685259 step=0.050000
2017/08/30 01:30:50 step 3: mse=143375.047169 step=0.050000
2017/08/30 01:30:51 step 4: mse=143890.918008 step=0.050000
2017/08/30 01:30:52 step 5: mse=143886.681615 step=0.050000
2017/08/30 01:30:53 step 6: mse=143014.997370 step=0.050000
2017/08/30 01:30:53 step 7: mse=142412.830361 step=0.050000
2017/08/30 01:30:53 Saving...
2017/08/30 01:30:54 Gathering batch of experience...
2017/08/30 01:31:24 batch 497: mean=4502.428571 stddev=6759.352502 entropy=0.434520 frames=6301 count=35
2017/08/30 01:31:24 Training policy...
2017/08/30 01:31:29 tune 0: objective=76.906493 reg=0.004345 prune=0
2017/08/30 01:31:30 step 0: objective=77.032897 reg=0.004345
2017/08/30 01:31:31 step 1: objective=77.176336 reg=0.004346
2017/08/30 01:31:33 step 2: objective=77.247357 reg=0.004346
2017/08/30 01:31:34 step 3: objective=77.364342 reg=0.004346
2017/08/30 01:31:35 step 4: objective=77.458638 reg=0.004346
2017/08/30 01:31:36 step 5: objective=77.530129 reg=0.004346
2017/08/30 01:31:38 step 6: objective=77.663555 reg=0.004345
2017/08/30 01:31:39 step 7: objective=77.744862 reg=0.004344
2017/08/30 01:31:39 Training value function...
2017/08/30 01:31:41 step 0: mse=228166.202391 step=0.050000
2017/08/30 01:31:42 step 1: mse=225956.538473 step=0.050000
2017/08/30 01:31:43 step 2: mse=220327.178158 step=0.050000
2017/08/30 01:31:44 step 3: mse=217545.191827 step=0.050000
2017/08/30 01:31:45 step 4: mse=211618.935911 step=0.050000
2017/08/30 01:31:46 step 5: mse=207093.678895 step=0.050000
2017/08/30 01:31:47 step 6: mse=205940.094504 step=0.050000
2017/08/30 01:31:48 step 7: mse=203732.198511 step=0.050000
2017/08/30 01:31:48 Saving...
2017/08/30 01:31:48 Gathering batch of experience...
2017/08/30 01:32:16 batch 498: mean=5169.218750 stddev=7439.841135 entropy=0.440853 frames=6020 count=32
2017/08/30 01:32:16 Training policy...
2017/08/30 01:32:20 tune 0: objective=71.766087 reg=0.004409 prune=0
2017/08/30 01:32:21 step 0: objective=71.859853 reg=0.004408
2017/08/30 01:32:22 step 1: objective=71.963424 reg=0.004409
2017/08/30 01:32:23 step 2: objective=72.032688 reg=0.004409
2017/08/30 01:32:25 step 3: objective=72.122103 reg=0.004409
2017/08/30 01:32:26 step 4: objective=72.217675 reg=0.004408
2017/08/30 01:32:27 step 5: objective=72.316020 reg=0.004407
2017/08/30 01:32:28 step 6: objective=72.360844 reg=0.004406
2017/08/30 01:32:29 step 7: objective=72.410060 reg=0.004405
2017/08/30 01:32:29 Training value function...
2017/08/30 01:32:32 step 0: mse=240528.240977 step=0.050000
2017/08/30 01:32:33 step 1: mse=233276.514248 step=0.050000
2017/08/30 01:32:34 step 2: mse=226644.979969 step=0.050000
2017/08/30 01:32:35 step 3: mse=223148.776930 step=0.050000
2017/08/30 01:32:36 step 4: mse=219766.381887 step=0.050000
2017/08/30 01:32:37 step 5: mse=218761.462281 step=0.050000
2017/08/30 01:32:38 step 6: mse=214857.520963 step=0.050000
2017/08/30 01:32:39 step 7: mse=210577.061085 step=0.050000
2017/08/30 01:32:39 Saving...
2017/08/30 01:32:39 Gathering batch of experience...
2017/08/30 01:33:04 batch 499: mean=4220.806452 stddev=6220.766872 entropy=0.431545 frames=5589 count=31
2017/08/30 01:33:04 Training policy...
2017/08/30 01:33:07 tune 0: objective=51.913754 reg=0.004315 prune=0
2017/08/30 01:33:09 step 0: objective=52.020090 reg=0.004315
2017/08/30 01:33:10 step 1: objective=52.089529 reg=0.004313
2017/08/30 01:33:11 step 2: objective=52.166068 reg=0.004312
2017/08/30 01:33:12 step 3: objective=52.240210 reg=0.004310
2017/08/30 01:33:13 step 4: objective=52.300713 reg=0.004309
2017/08/30 01:33:14 step 5: objective=52.354457 reg=0.004309
2017/08/30 01:33:15 step 6: objective=52.440536 reg=0.004307
2017/08/30 01:33:16 step 7: objective=52.596082 reg=0.004306
2017/08/30 01:33:16 Training value function...
2017/08/30 01:33:19 step 0: mse=194803.835094 step=0.050000
2017/08/30 01:33:20 step 1: mse=193291.998631 step=0.050000
2017/08/30 01:33:20 step 2: mse=193133.215424 step=0.050000
2017/08/30 01:33:21 step 3: mse=191829.865514 step=0.050000
2017/08/30 01:33:22 step 4: mse=189736.223084 step=0.050000
2017/08/30 01:33:23 step 5: mse=188956.545541 step=0.050000
2017/08/30 01:33:24 step 6: mse=187044.755255 step=0.050000
2017/08/30 01:33:25 step 7: mse=184917.987346 step=0.050000
2017/08/30 01:33:25 Saving...
2017/08/30 01:33:25 Gathering batch of experience...
2017/08/30 01:33:48 batch 500: mean=4448.571429 stddev=6546.298007 entropy=0.434787 frames=5106 count=28
2017/08/30 01:33:48 Training policy...
2017/08/30 01:33:51 tune 0: objective=51.416000 reg=0.004348 prune=0
2017/08/30 01:33:52 step 0: objective=51.534977 reg=0.004347
2017/08/30 01:33:53 step 1: objective=51.623335 reg=0.004349
2017/08/30 01:33:54 step 2: objective=51.704588 reg=0.004348
2017/08/30 01:33:55 step 3: objective=51.838536 reg=0.004346
2017/08/30 01:33:56 step 4: objective=51.909426 reg=0.004344
2017/08/30 01:33:57 step 5: objective=51.962673 reg=0.004343
2017/08/30 01:33:58 step 6: objective=52.055554 reg=0.004342
2017/08/30 01:33:59 step 7: objective=52.149701 reg=0.004342
2017/08/30 01:33:59 Training value function...
2017/08/30 01:34:02 step 0: mse=168162.088026 step=0.050000
2017/08/30 01:34:02 step 1: mse=167204.499913 step=0.050000
2017/08/30 01:34:03 step 2: mse=167683.397821 step=0.050000
2017/08/30 01:34:04 step 3: mse=165670.195881 step=0.050000
2017/08/30 01:34:05 step 4: mse=163779.263788 step=0.050000
2017/08/30 01:34:06 step 5: mse=163049.337814 step=0.050000
2017/08/30 01:34:06 step 6: mse=162183.917842 step=0.050000
2017/08/30 01:34:07 step 7: mse=161751.516049 step=0.050000
2017/08/30 01:34:07 Saving...
2017/08/30 01:34:07 Gathering batch of experience...
2017/08/30 01:34:36 batch 501: mean=5290.000000 stddev=7194.650031 entropy=0.434869 frames=6315 count=32
2017/08/30 01:34:36 Training policy...
2017/08/30 01:34:41 tune 0: objective=58.962480 reg=0.004349 prune=0
2017/08/30 01:34:42 step 0: objective=59.102445 reg=0.004348
2017/08/30 01:34:43 step 1: objective=59.291068 reg=0.004347
2017/08/30 01:34:44 step 2: objective=59.483675 reg=0.004346
2017/08/30 01:34:46 step 3: objective=59.600539 reg=0.004345
2017/08/30 01:34:47 step 4: objective=59.695136 reg=0.004345
2017/08/30 01:34:48 step 5: objective=59.802039 reg=0.004343
2017/08/30 01:34:50 step 6: objective=59.875901 reg=0.004343
2017/08/30 01:34:51 step 7: objective=59.953098 reg=0.004343
2017/08/30 01:34:51 Training value function...
2017/08/30 01:34:53 step 0: mse=231832.618072 step=0.050000
2017/08/30 01:34:54 step 1: mse=229839.520227 step=0.050000
2017/08/30 01:34:55 step 2: mse=230230.293558 step=0.050000
2017/08/30 01:34:56 step 3: mse=229445.806612 step=0.050000
2017/08/30 01:34:57 step 4: mse=226399.197506 step=0.050000
2017/08/30 01:34:58 step 5: mse=226546.310812 step=0.050000
2017/08/30 01:34:59 step 6: mse=226500.171699 step=0.050000
2017/08/30 01:35:00 step 7: mse=226819.826634 step=0.050000
2017/08/30 01:35:00 Saving...
2017/08/30 01:35:00 Gathering batch of experience...
2017/08/30 01:35:28 batch 502: mean=3431.756757 stddev=5303.456957 entropy=0.429762 frames=5982 count=37
2017/08/30 01:35:28 Training policy...
2017/08/30 01:35:32 tune 0: objective=28.096012 reg=0.004298 prune=0
2017/08/30 01:35:33 step 0: objective=28.213907 reg=0.004297
2017/08/30 01:35:35 step 1: objective=28.356481 reg=0.004298
2017/08/30 01:35:36 step 2: objective=28.461436 reg=0.004299
2017/08/30 01:35:37 step 3: objective=28.559478 reg=0.004299
2017/08/30 01:35:38 step 4: objective=28.630595 reg=0.004298
2017/08/30 01:35:39 step 5: objective=28.702678 reg=0.004297
2017/08/30 01:35:41 step 6: objective=28.762877 reg=0.004297
2017/08/30 01:35:42 step 7: objective=28.824975 reg=0.004297
2017/08/30 01:35:42 Training value function...
2017/08/30 01:35:44 step 0: mse=129916.235698 step=0.050000
2017/08/30 01:35:45 step 1: mse=130069.462970 step=0.050000
2017/08/30 01:35:46 step 2: mse=129949.791893 step=0.050000
2017/08/30 01:35:47 step 3: mse=130048.670199 step=0.050000
2017/08/30 01:35:48 step 4: mse=129476.721193 step=0.050000
2017/08/30 01:35:49 step 5: mse=128962.590463 step=0.050000
2017/08/30 01:35:50 step 6: mse=129619.997042 step=0.050000
2017/08/30 01:35:51 step 7: mse=130303.259237 step=0.050000
2017/08/30 01:35:51 Saving...
2017/08/30 01:35:51 Gathering batch of experience...
2017/08/30 01:36:18 batch 503: mean=3397.000000 stddev=5372.121581 entropy=0.429191 frames=5744 count=35
2017/08/30 01:36:18 Training policy...
2017/08/30 01:36:22 tune 0: objective=40.254665 reg=0.004292 prune=0
2017/08/30 01:36:23 step 0: objective=40.337129 reg=0.004292
2017/08/30 01:36:24 step 1: objective=40.434709 reg=0.004291
2017/08/30 01:36:25 step 2: objective=40.527991 reg=0.004291
2017/08/30 01:36:26 step 3: objective=40.604903 reg=0.004291
2017/08/30 01:36:28 step 4: objective=40.682060 reg=0.004290
2017/08/30 01:36:29 step 5: objective=40.761069 reg=0.004290
2017/08/30 01:36:30 step 6: objective=40.810035 reg=0.004290
2017/08/30 01:36:31 step 7: objective=40.862498 reg=0.004289
2017/08/30 01:36:31 Training value function...
2017/08/30 01:36:33 step 0: mse=163758.362460 step=0.050000
2017/08/30 01:36:34 step 1: mse=163170.301407 step=0.050000
2017/08/30 01:36:35 step 2: mse=162195.849398 step=0.050000
2017/08/30 01:36:36 step 3: mse=161298.158201 step=0.050000
2017/08/30 01:36:37 step 4: mse=161041.281134 step=0.050000
2017/08/30 01:36:38 step 5: mse=158115.301939 step=0.050000
2017/08/30 01:36:39 step 6: mse=157484.396346 step=0.050000
2017/08/30 01:36:40 step 7: mse=156580.951375 step=0.050000
2017/08/30 01:36:40 Saving...
2017/08/30 01:36:40 Gathering batch of experience...
2017/08/30 01:37:07 batch 504: mean=4548.125000 stddev=6214.773572 entropy=0.428898 frames=5996 count=32
2017/08/30 01:37:07 Training policy...
2017/08/30 01:37:11 tune 0: objective=43.299348 reg=0.004289 prune=0
2017/08/30 01:37:12 step 0: objective=43.431165 reg=0.004290
2017/08/30 01:37:14 step 1: objective=43.622475 reg=0.004291
2017/08/30 01:37:15 step 2: objective=43.771718 reg=0.004293
2017/08/30 01:37:16 step 3: objective=43.905656 reg=0.004295
2017/08/30 01:37:17 step 4: objective=44.022468 reg=0.004296
2017/08/30 01:37:18 step 5: objective=44.142256 reg=0.004296
2017/08/30 01:37:20 step 6: objective=44.255613 reg=0.004296
2017/08/30 01:37:21 step 7: objective=44.347826 reg=0.004295
2017/08/30 01:37:21 Training value function...
2017/08/30 01:37:23 step 0: mse=187602.946945 step=0.050000
2017/08/30 01:37:24 step 1: mse=186992.218137 step=0.050000
2017/08/30 01:37:25 step 2: mse=186759.105856 step=0.050000
2017/08/30 01:37:26 step 3: mse=185043.536773 step=0.050000
2017/08/30 01:37:27 step 4: mse=185228.629375 step=0.050000
2017/08/30 01:37:28 step 5: mse=183005.095390 step=0.050000
2017/08/30 01:37:29 step 6: mse=182943.577085 step=0.050000
2017/08/30 01:37:30 step 7: mse=181671.315146 step=0.050000
2017/08/30 01:37:30 Saving...
2017/08/30 01:37:30 Gathering batch of experience...
2017/08/30 01:37:54 batch 505: mean=2754.857143 stddev=4406.036847 entropy=0.429435 frames=5214 count=35
2017/08/30 01:37:54 Training policy...
2017/08/30 01:37:57 tune 0: objective=24.753227 reg=0.004294 prune=0
2017/08/30 01:37:58 step 0: objective=24.822972 reg=0.004294
2017/08/30 01:37:59 step 1: objective=24.916431 reg=0.004295
2017/08/30 01:38:00 step 2: objective=24.978316 reg=0.004295
2017/08/30 01:38:01 step 3: objective=25.057951 reg=0.004296
2017/08/30 01:38:02 step 4: objective=25.122351 reg=0.004297
2017/08/30 01:38:03 step 5: objective=25.158297 reg=0.004296
2017/08/30 01:38:05 step 6: objective=25.207935 reg=0.004296
2017/08/30 01:38:06 step 7: objective=25.271331 reg=0.004296
2017/08/30 01:38:06 Training value function...
2017/08/30 01:38:08 step 0: mse=121055.507501 step=0.050000
2017/08/30 01:38:09 step 1: mse=121378.105296 step=0.050000
2017/08/30 01:38:09 step 2: mse=122164.401381 step=0.050000
2017/08/30 01:38:10 step 3: mse=122645.884148 step=0.050000
2017/08/30 01:38:11 step 4: mse=123172.850511 step=0.050000
2017/08/30 01:38:12 step 5: mse=123701.637968 step=0.050000
2017/08/30 01:38:13 step 6: mse=124310.902835 step=0.050000
2017/08/30 01:38:13 step 7: mse=124766.094326 step=0.050000
2017/08/30 01:38:13 Saving...
2017/08/30 01:38:14 Gathering batch of experience...
2017/08/30 01:38:38 batch 506: mean=2979.428571 stddev=4377.463351 entropy=0.425421 frames=5400 count=35
2017/08/30 01:38:38 Training policy...
2017/08/30 01:38:42 tune 0: objective=23.901949 reg=0.004254 prune=0
2017/08/30 01:38:43 step 0: objective=24.004087 reg=0.004255
2017/08/30 01:38:44 step 1: objective=24.119418 reg=0.004254
2017/08/30 01:38:45 step 2: objective=24.244333 reg=0.004255
2017/08/30 01:38:46 step 3: objective=24.328628 reg=0.004256
2017/08/30 01:38:47 step 4: objective=24.389682 reg=0.004257
2017/08/30 01:38:48 step 5: objective=24.446481 reg=0.004257
2017/08/30 01:38:50 step 6: objective=24.514100 reg=0.004256
2017/08/30 01:38:51 step 7: objective=24.562665 reg=0.004256
2017/08/30 01:38:51 Training value function...
2017/08/30 01:38:53 step 0: mse=106196.888033 step=0.050000
2017/08/30 01:38:54 step 1: mse=106555.272219 step=0.050000
2017/08/30 01:38:54 step 2: mse=107203.000749 step=0.050000
2017/08/30 01:38:55 step 3: mse=107987.159534 step=0.050000
2017/08/30 01:38:56 step 4: mse=108771.741379 step=0.050000
2017/08/30 01:38:57 step 5: mse=109628.328623 step=0.050000
2017/08/30 01:38:58 step 6: mse=109963.136809 step=0.050000
2017/08/30 01:38:59 step 7: mse=110563.330990 step=0.050000
2017/08/30 01:38:59 Saving...
2017/08/30 01:38:59 Gathering batch of experience...
2017/08/30 01:39:28 batch 507: mean=3494.000000 stddev=5690.675948 entropy=0.430498 frames=6238 count=40
2017/08/30 01:39:28 Training policy...
2017/08/30 01:39:33 tune 0: objective=51.079392 reg=0.004305 prune=0
2017/08/30 01:39:34 step 0: objective=51.127079 reg=0.004304
2017/08/30 01:39:35 step 1: objective=51.193096 reg=0.004303
2017/08/30 01:39:36 step 2: objective=51.232521 reg=0.004303
2017/08/30 01:39:38 step 3: objective=51.278875 reg=0.004303
2017/08/30 01:39:39 step 4: objective=51.311909 reg=0.004303
2017/08/30 01:39:40 step 5: objective=51.366859 reg=0.004302
2017/08/30 01:39:41 step 6: objective=51.409682 reg=0.004302
2017/08/30 01:39:43 step 7: objective=51.442725 reg=0.004301
2017/08/30 01:39:43 Training value function...
2017/08/30 01:39:45 step 0: mse=204792.714064 step=0.050000
2017/08/30 01:39:46 step 1: mse=201921.873722 step=0.050000
2017/08/30 01:39:47 step 2: mse=199170.667305 step=0.050000
2017/08/30 01:39:48 step 3: mse=199158.600695 step=0.050000
2017/08/30 01:39:49 step 4: mse=199700.179212 step=0.050000
2017/08/30 01:39:50 step 5: mse=197828.385714 step=0.050000
2017/08/30 01:39:51 step 6: mse=198112.451336 step=0.050000
2017/08/30 01:39:52 step 7: mse=196927.751930 step=0.050000
2017/08/30 01:39:52 Saving...
2017/08/30 01:39:52 Gathering batch of experience...
2017/08/30 01:40:23 batch 508: mean=4406.805556 stddev=6600.647186 entropy=0.433721 frames=6559 count=36
2017/08/30 01:40:23 Training policy...
2017/08/30 01:40:27 tune 0: objective=62.120088 reg=0.004337 prune=0
2017/08/30 01:40:29 step 0: objective=62.196281 reg=0.004337
2017/08/30 01:40:30 step 1: objective=62.269082 reg=0.004336
2017/08/30 01:40:31 step 2: objective=62.366495 reg=0.004335
2017/08/30 01:40:33 step 3: objective=62.465139 reg=0.004336
2017/08/30 01:40:34 step 4: objective=62.527033 reg=0.004336
2017/08/30 01:40:35 step 5: objective=62.576903 reg=0.004336
2017/08/30 01:40:37 step 6: objective=62.623704 reg=0.004335
2017/08/30 01:40:38 step 7: objective=62.667842 reg=0.004334
2017/08/30 01:40:38 Training value function...
2017/08/30 01:40:41 step 0: mse=185024.014177 step=0.050000
2017/08/30 01:40:42 step 1: mse=180878.755995 step=0.050000
2017/08/30 01:40:43 step 2: mse=176773.014743 step=0.050000
2017/08/30 01:40:44 step 3: mse=174135.119598 step=0.050000
2017/08/30 01:40:45 step 4: mse=169946.313440 step=0.050000
2017/08/30 01:40:46 step 5: mse=167486.476307 step=0.050000
2017/08/30 01:40:47 step 6: mse=166851.638175 step=0.050000
2017/08/30 01:40:48 step 7: mse=162879.317026 step=0.050000
2017/08/30 01:40:48 Saving...
2017/08/30 01:40:48 Gathering batch of experience...
2017/08/30 01:41:15 batch 509: mean=5922.857143 stddev=7328.878718 entropy=0.433519 frames=6003 count=28
2017/08/30 01:41:15 Training policy...
2017/08/30 01:41:19 tune 0: objective=59.260182 reg=0.004335 prune=0
2017/08/30 01:41:21 step 0: objective=59.406448 reg=0.004335
2017/08/30 01:41:22 step 1: objective=59.559965 reg=0.004336
2017/08/30 01:41:23 step 2: objective=59.737470 reg=0.004338
2017/08/30 01:41:24 step 3: objective=59.927541 reg=0.004335
2017/08/30 01:41:25 step 4: objective=60.047711 reg=0.004335
2017/08/30 01:41:27 step 5: objective=60.179712 reg=0.004336
2017/08/30 01:41:28 step 6: objective=60.278652 reg=0.004335
2017/08/30 01:41:29 step 7: objective=60.360617 reg=0.004336
2017/08/30 01:41:29 Training value function...
2017/08/30 01:41:31 step 0: mse=255574.577354 step=0.050000
2017/08/30 01:41:32 step 1: mse=251998.376377 step=0.050000
2017/08/30 01:41:33 step 2: mse=250898.580801 step=0.050000
2017/08/30 01:41:34 step 3: mse=247834.908378 step=0.050000
2017/08/30 01:41:35 step 4: mse=244863.499926 step=0.050000
2017/08/30 01:41:36 step 5: mse=242242.420200 step=0.050000
2017/08/30 01:41:37 step 6: mse=242180.020442 step=0.050000
2017/08/30 01:41:38 step 7: mse=237622.690434 step=0.050000
2017/08/30 01:41:38 Saving...
2017/08/30 01:41:38 Gathering batch of experience...
2017/08/30 01:42:07 batch 510: mean=2601.341463 stddev=4150.425195 entropy=0.424970 frames=5900 count=41
2017/08/30 01:42:07 Training policy...
2017/08/30 01:42:11 tune 0: objective=20.429178 reg=0.004250 prune=0
2017/08/30 01:42:12 step 0: objective=20.474890 reg=0.004249
2017/08/30 01:42:13 step 1: objective=20.534809 reg=0.004248
2017/08/30 01:42:14 step 2: objective=20.606373 reg=0.004247
2017/08/30 01:42:15 step 3: objective=20.657459 reg=0.004247
2017/08/30 01:42:17 step 4: objective=20.706888 reg=0.004247
2017/08/30 01:42:18 step 5: objective=20.750418 reg=0.004246
2017/08/30 01:42:19 step 6: objective=20.807219 reg=0.004245
2017/08/30 01:42:20 step 7: objective=20.842789 reg=0.004245
2017/08/30 01:42:20 Training value function...
2017/08/30 01:42:23 step 0: mse=86162.398912 step=0.050000
2017/08/30 01:42:23 step 1: mse=86743.142892 step=0.050000
2017/08/30 01:42:24 step 2: mse=87041.413986 step=0.050000
2017/08/30 01:42:25 step 3: mse=87760.531132 step=0.050000
2017/08/30 01:42:26 step 4: mse=88279.670077 step=0.050000
2017/08/30 01:42:27 step 5: mse=88587.329166 step=0.050000
2017/08/30 01:42:28 step 6: mse=89041.641715 step=0.050000
2017/08/30 01:42:29 step 7: mse=89781.950824 step=0.050000
2017/08/30 01:42:29 Saving...
2017/08/30 01:42:29 Gathering batch of experience...
2017/08/30 01:42:55 batch 511: mean=5025.344828 stddev=7144.272113 entropy=0.431699 frames=5512 count=29
2017/08/30 01:42:55 Training policy...
2017/08/30 01:42:59 tune 0: objective=55.930379 reg=0.004317 prune=0
2017/08/30 01:43:00 step 0: objective=56.051428 reg=0.004317
2017/08/30 01:43:01 step 1: objective=56.180861 reg=0.004318
2017/08/30 01:43:02 step 2: objective=56.273364 reg=0.004319
2017/08/30 01:43:03 step 3: objective=56.342939 reg=0.004321
2017/08/30 01:43:04 step 4: objective=56.421563 reg=0.004323
2017/08/30 01:43:05 step 5: objective=56.483502 reg=0.004323
2017/08/30 01:43:06 step 6: objective=56.542578 reg=0.004323
2017/08/30 01:43:08 step 7: objective=56.607612 reg=0.004324
2017/08/30 01:43:08 Training value function...
2017/08/30 01:43:10 step 0: mse=185705.435911 step=0.050000
2017/08/30 01:43:11 step 1: mse=180665.972939 step=0.050000
2017/08/30 01:43:12 step 2: mse=178809.065240 step=0.050000
2017/08/30 01:43:12 step 3: mse=178665.974552 step=0.050000
2017/08/30 01:43:13 step 4: mse=175165.160029 step=0.050000
2017/08/30 01:43:14 step 5: mse=174910.736923 step=0.050000
2017/08/30 01:43:15 step 6: mse=171953.428572 step=0.050000
2017/08/30 01:43:16 step 7: mse=170635.732938 step=0.050000
2017/08/30 01:43:16 Saving...
2017/08/30 01:43:16 Gathering batch of experience...
2017/08/30 01:43:45 batch 512: mean=3436.111111 stddev=5166.140176 entropy=0.424816 frames=5907 count=36
2017/08/30 01:43:45 Training policy...
2017/08/30 01:43:49 tune 0: objective=30.096326 reg=0.004248 prune=0
2017/08/30 01:43:51 step 0: objective=30.200559 reg=0.004246
2017/08/30 01:43:52 step 1: objective=30.284369 reg=0.004244
2017/08/30 01:43:53 step 2: objective=30.386382 reg=0.004242
2017/08/30 01:43:54 step 3: objective=30.479846 reg=0.004239
2017/08/30 01:43:55 step 4: objective=30.548465 reg=0.004238
2017/08/30 01:43:56 step 5: objective=30.611436 reg=0.004238
2017/08/30 01:43:58 step 6: objective=30.682614 reg=0.004238
2017/08/30 01:43:59 step 7: objective=30.754404 reg=0.004237
2017/08/30 01:43:59 Training value function...
2017/08/30 01:44:01 step 0: mse=109001.177550 step=0.050000
2017/08/30 01:44:02 step 1: mse=109259.570671 step=0.050000
2017/08/30 01:44:03 step 2: mse=109656.737444 step=0.050000
2017/08/30 01:44:04 step 3: mse=109471.187437 step=0.050000
2017/08/30 01:44:05 step 4: mse=109868.605516 step=0.050000
2017/08/30 01:44:06 step 5: mse=110202.705940 step=0.050000
2017/08/30 01:44:07 step 6: mse=110678.997067 step=0.050000
2017/08/30 01:44:08 step 7: mse=111732.998765 step=0.050000
2017/08/30 01:44:08 Saving...
2017/08/30 01:44:08 Gathering batch of experience...
2017/08/30 01:44:31 batch 513: mean=3426.406250 stddev=5241.435013 entropy=0.430709 frames=5050 count=32
2017/08/30 01:44:31 Training policy...
2017/08/30 01:44:34 tune 0: objective=37.102302 reg=0.004307 prune=0
2017/08/30 01:44:35 step 0: objective=37.204542 reg=0.004306
2017/08/30 01:44:36 step 1: objective=37.285900 reg=0.004307
2017/08/30 01:44:37 step 2: objective=37.407853 reg=0.004308
2017/08/30 01:44:38 step 3: objective=37.533199 reg=0.004311
2017/08/30 01:44:39 step 4: objective=37.630835 reg=0.004312
2017/08/30 01:44:40 step 5: objective=37.708772 reg=0.004312
2017/08/30 01:44:41 step 6: objective=37.793812 reg=0.004311
2017/08/30 01:44:43 step 7: objective=37.884245 reg=0.004311
2017/08/30 01:44:43 Training value function...
2017/08/30 01:44:45 step 0: mse=209578.370749 step=0.050000
2017/08/30 01:44:45 step 1: mse=208449.631780 step=0.050000
2017/08/30 01:44:46 step 2: mse=207323.844403 step=0.050000
2017/08/30 01:44:47 step 3: mse=208177.713119 step=0.050000
2017/08/30 01:44:48 step 4: mse=206594.187423 step=0.050000
2017/08/30 01:44:49 step 5: mse=205536.016548 step=0.050000
2017/08/30 01:44:49 step 6: mse=204171.290737 step=0.050000
2017/08/30 01:44:50 step 7: mse=204707.532539 step=0.050000
2017/08/30 01:44:50 Saving...
2017/08/30 01:44:50 Gathering batch of experience...
2017/08/30 01:45:20 batch 514: mean=5871.724138 stddev=7654.887134 entropy=0.434657 frames=6310 count=29
2017/08/30 01:45:20 Training policy...
2017/08/30 01:45:24 tune 0: objective=68.708652 reg=0.004347 prune=0
2017/08/30 01:45:26 step 0: objective=68.834316 reg=0.004346
2017/08/30 01:45:27 step 1: objective=68.968096 reg=0.004346
2017/08/30 01:45:28 step 2: objective=69.080765 reg=0.004346
2017/08/30 01:45:29 step 3: objective=69.150698 reg=0.004346
2017/08/30 01:45:31 step 4: objective=69.211311 reg=0.004344
2017/08/30 01:45:32 step 5: objective=69.286737 reg=0.004342
2017/08/30 01:45:33 step 6: objective=69.372851 reg=0.004340
2017/08/30 01:45:34 step 7: objective=69.458355 reg=0.004339
2017/08/30 01:45:34 Training value function...
2017/08/30 01:45:37 step 0: mse=201752.296741 step=0.050000
2017/08/30 01:45:38 step 1: mse=199566.441736 step=0.050000
2017/08/30 01:45:39 step 2: mse=197421.191563 step=0.050000
2017/08/30 01:45:40 step 3: mse=191729.855428 step=0.050000
2017/08/30 01:45:41 step 4: mse=188304.930498 step=0.050000
2017/08/30 01:45:42 step 5: mse=186679.876585 step=0.050000
2017/08/30 01:45:43 step 6: mse=186896.597411 step=0.050000
2017/08/30 01:45:44 step 7: mse=185013.672745 step=0.050000
2017/08/30 01:45:44 Saving...
2017/08/30 01:45:44 Gathering batch of experience...
2017/08/30 01:46:11 batch 515: mean=2561.351351 stddev=3369.997724 entropy=0.416482 frames=5409 count=37
2017/08/30 01:46:11 Training policy...
2017/08/30 01:46:15 tune 0: objective=6.625218 reg=0.004165 prune=0
2017/08/30 01:46:16 step 0: objective=6.738048 reg=0.004164
2017/08/30 01:46:17 step 1: objective=6.844359 reg=0.004164
2017/08/30 01:46:18 step 2: objective=6.945580 reg=0.004162
2017/08/30 01:46:20 step 3: objective=7.054269 reg=0.004162
2017/08/30 01:46:21 step 4: objective=7.121947 reg=0.004162
2017/08/30 01:46:22 step 5: objective=7.170852 reg=0.004162
2017/08/30 01:46:23 step 6: objective=7.223113 reg=0.004163
2017/08/30 01:46:24 step 7: objective=7.266305 reg=0.004162
2017/08/30 01:46:24 Training value function...
2017/08/30 01:46:26 step 0: mse=83529.452297 step=0.050000
2017/08/30 01:46:27 step 1: mse=82629.018296 step=0.050000
2017/08/30 01:46:28 step 2: mse=82153.692984 step=0.050000
2017/08/30 01:46:29 step 3: mse=81758.905564 step=0.050000
2017/08/30 01:46:30 step 4: mse=81523.870205 step=0.050000
2017/08/30 01:46:30 step 5: mse=81060.353541 step=0.050000
2017/08/30 01:46:31 step 6: mse=80686.932394 step=0.050000
2017/08/30 01:46:32 step 7: mse=80556.809330 step=0.050000
2017/08/30 01:46:32 Saving...
2017/08/30 01:46:32 Gathering batch of experience...
2017/08/30 01:46:59 batch 516: mean=3098.513514 stddev=4478.358300 entropy=0.422540 frames=5898 count=37
2017/08/30 01:46:59 Training policy...
2017/08/30 01:47:03 tune 0: objective=25.048605 reg=0.004225 prune=0
2017/08/30 01:47:04 step 0: objective=25.164712 reg=0.004224
2017/08/30 01:47:06 step 1: objective=25.252896 reg=0.004223
2017/08/30 01:47:07 step 2: objective=25.331603 reg=0.004222
2017/08/30 01:47:08 step 3: objective=25.392209 reg=0.004223
2017/08/30 01:47:09 step 4: objective=25.447509 reg=0.004222
2017/08/30 01:47:10 step 5: objective=25.498940 reg=0.004222
2017/08/30 01:47:12 step 6: objective=25.551471 reg=0.004222
2017/08/30 01:47:13 step 7: objective=25.593917 reg=0.004223
2017/08/30 01:47:13 Training value function...
2017/08/30 01:47:15 step 0: mse=120931.728412 step=0.050000
2017/08/30 01:47:16 step 1: mse=120423.614420 step=0.050000
2017/08/30 01:47:17 step 2: mse=120973.688948 step=0.050000
2017/08/30 01:47:18 step 3: mse=121242.976544 step=0.050000
2017/08/30 01:47:19 step 4: mse=121345.591463 step=0.050000
2017/08/30 01:47:20 step 5: mse=121277.308931 step=0.050000
2017/08/30 01:47:21 step 6: mse=121655.523679 step=0.050000
2017/08/30 01:47:22 step 7: mse=121765.913474 step=0.050000
2017/08/30 01:47:22 Saving...
2017/08/30 01:47:22 Gathering batch of experience...
2017/08/30 01:47:52 batch 517: mean=4431.060606 stddev=6034.954088 entropy=0.426476 frames=6313 count=33
2017/08/30 01:47:52 Training policy...
2017/08/30 01:47:56 tune 0: objective=56.983051 reg=0.004265 prune=0
2017/08/30 01:47:57 step 0: objective=57.097542 reg=0.004264
2017/08/30 01:47:59 step 1: objective=57.189827 reg=0.004263
2017/08/30 01:48:00 step 2: objective=57.270454 reg=0.004262
2017/08/30 01:48:01 step 3: objective=57.345062 reg=0.004261
2017/08/30 01:48:02 step 4: objective=57.446153 reg=0.004261
2017/08/30 01:48:04 step 5: objective=57.513415 reg=0.004261
2017/08/30 01:48:05 step 6: objective=57.567544 reg=0.004261
2017/08/30 01:48:06 step 7: objective=57.651577 reg=0.004260
2017/08/30 01:48:06 Training value function...
2017/08/30 01:48:09 step 0: mse=185054.532369 step=0.050000
2017/08/30 01:48:10 step 1: mse=184138.783547 step=0.050000
2017/08/30 01:48:11 step 2: mse=184169.551409 step=0.050000
2017/08/30 01:48:12 step 3: mse=180479.626203 step=0.050000
2017/08/30 01:48:13 step 4: mse=178044.097969 step=0.050000
2017/08/30 01:48:14 step 5: mse=174838.425051 step=0.050000
2017/08/30 01:48:15 step 6: mse=171960.956736 step=0.050000
2017/08/30 01:48:16 step 7: mse=172266.876544 step=0.050000
2017/08/30 01:48:16 Saving...
2017/08/30 01:48:16 Gathering batch of experience...
2017/08/30 01:48:43 batch 518: mean=5127.500000 stddev=6983.725934 entropy=0.426651 frames=6058 count=30
2017/08/30 01:48:43 Training policy...
2017/08/30 01:48:48 tune 0: objective=64.216614 reg=0.004267 prune=0
2017/08/30 01:48:49 step 0: objective=64.340258 reg=0.004265
2017/08/30 01:48:50 step 1: objective=64.409319 reg=0.004265
2017/08/30 01:48:51 step 2: objective=64.530781 reg=0.004264
2017/08/30 01:48:52 step 3: objective=64.593626 reg=0.004265
2017/08/30 01:48:54 step 4: objective=64.701650 reg=0.004265
2017/08/30 01:48:55 step 5: objective=64.794564 reg=0.004264
2017/08/30 01:48:56 step 6: objective=64.830570 reg=0.004265
2017/08/30 01:48:57 step 7: objective=64.892410 reg=0.004264
2017/08/30 01:48:57 Training value function...
2017/08/30 01:49:00 step 0: mse=225074.602698 step=0.050000
2017/08/30 01:49:01 step 1: mse=219671.967370 step=0.050000
2017/08/30 01:49:02 step 2: mse=215713.625912 step=0.050000
2017/08/30 01:49:03 step 3: mse=213714.562341 step=0.050000
2017/08/30 01:49:04 step 4: mse=211157.844177 step=0.050000
2017/08/30 01:49:05 step 5: mse=208476.901708 step=0.050000
2017/08/30 01:49:06 step 6: mse=205060.533629 step=0.050000
2017/08/30 01:49:07 step 7: mse=203775.997471 step=0.050000
2017/08/30 01:49:07 Saving...
2017/08/30 01:49:07 Gathering batch of experience...
2017/08/30 01:49:33 batch 519: mean=2820.540541 stddev=4464.278154 entropy=0.422160 frames=5461 count=37
2017/08/30 01:49:33 Training policy...
2017/08/30 01:49:37 tune 0: objective=24.183380 reg=0.004222 prune=0
2017/08/30 01:49:38 step 0: objective=24.238218 reg=0.004221
2017/08/30 01:49:39 step 1: objective=24.283774 reg=0.004221
2017/08/30 01:49:40 step 2: objective=24.334102 reg=0.004222
2017/08/30 01:49:41 step 3: objective=24.371861 reg=0.004222
2017/08/30 01:49:42 step 4: objective=24.417400 reg=0.004222
2017/08/30 01:49:43 step 5: objective=24.460158 reg=0.004221
2017/08/30 01:49:44 step 6: objective=24.495333 reg=0.004221
2017/08/30 01:49:45 step 7: objective=24.529502 reg=0.004221
2017/08/30 01:49:45 Training value function...
2017/08/30 01:49:47 step 0: mse=94702.984842 step=0.050000
2017/08/30 01:49:48 step 1: mse=95165.935879 step=0.050000
2017/08/30 01:49:49 step 2: mse=95457.162110 step=0.050000
2017/08/30 01:49:50 step 3: mse=96303.329881 step=0.050000
2017/08/30 01:49:51 step 4: mse=97329.955259 step=0.050000
2017/08/30 01:49:52 step 5: mse=97806.294665 step=0.050000
2017/08/30 01:49:53 step 6: mse=98531.997421 step=0.050000
2017/08/30 01:49:54 step 7: mse=99313.374798 step=0.050000
2017/08/30 01:49:54 Saving...
2017/08/30 01:49:54 Gathering batch of experience...
2017/08/30 01:50:17 batch 520: mean=2930.000000 stddev=4567.381718 entropy=0.421834 frames=4999 count=33
2017/08/30 01:50:17 Training policy...
2017/08/30 01:50:20 tune 0: objective=29.446914 reg=0.004218 prune=0
2017/08/30 01:50:21 step 0: objective=29.512402 reg=0.004218
2017/08/30 01:50:22 step 1: objective=29.579256 reg=0.004218
2017/08/30 01:50:23 step 2: objective=29.629273 reg=0.004218
2017/08/30 01:50:24 step 3: objective=29.675504 reg=0.004218
2017/08/30 01:50:25 step 4: objective=29.736760 reg=0.004219
2017/08/30 01:50:26 step 5: objective=29.786598 reg=0.004220
2017/08/30 01:50:27 step 6: objective=29.833545 reg=0.004220
2017/08/30 01:50:28 step 7: objective=29.860556 reg=0.004220
2017/08/30 01:50:28 Training value function...
2017/08/30 01:50:30 step 0: mse=107897.148892 step=0.050000
2017/08/30 01:50:31 step 1: mse=108734.276318 step=0.050000
2017/08/30 01:50:32 step 2: mse=109724.787464 step=0.050000
2017/08/30 01:50:32 step 3: mse=110582.852553 step=0.050000
2017/08/30 01:50:33 step 4: mse=111136.980555 step=0.050000
2017/08/30 01:50:34 step 5: mse=112133.249306 step=0.050000
2017/08/30 01:50:35 step 6: mse=113246.722948 step=0.050000
2017/08/30 01:50:36 step 7: mse=113709.290973 step=0.050000
2017/08/30 01:50:36 Saving...
2017/08/30 01:50:36 Gathering batch of experience...
2017/08/30 01:51:03 batch 521: mean=2031.363636 stddev=3098.636680 entropy=0.422212 frames=5518 count=44
2017/08/30 01:51:03 Training policy...
2017/08/30 01:51:07 tune 0: objective=13.102384 reg=0.004222 prune=0
2017/08/30 01:51:08 step 0: objective=13.144796 reg=0.004221
2017/08/30 01:51:09 step 1: objective=13.206471 reg=0.004221
2017/08/30 01:51:11 step 2: objective=13.249027 reg=0.004220
2017/08/30 01:51:12 step 3: objective=13.286551 reg=0.004220
2017/08/30 01:51:13 step 4: objective=13.325006 reg=0.004220
2017/08/30 01:51:14 step 5: objective=13.377339 reg=0.004219
2017/08/30 01:51:15 step 6: objective=13.413248 reg=0.004218
2017/08/30 01:51:16 step 7: objective=13.444241 reg=0.004217
2017/08/30 01:51:16 Training value function...
2017/08/30 01:51:18 step 0: mse=67097.093002 step=0.050000
2017/08/30 01:51:19 step 1: mse=67628.797833 step=0.050000
2017/08/30 01:51:20 step 2: mse=67756.739453 step=0.050000
2017/08/30 01:51:21 step 3: mse=68429.912341 step=0.050000
2017/08/30 01:51:22 step 4: mse=68994.294514 step=0.050000
2017/08/30 01:51:23 step 5: mse=69147.855463 step=0.050000
2017/08/30 01:51:24 step 6: mse=69731.197743 step=0.050000
2017/08/30 01:51:25 step 7: mse=70428.828230 step=0.050000
2017/08/30 01:51:25 Saving...
2017/08/30 01:51:25 Gathering batch of experience...
2017/08/30 01:51:52 batch 522: mean=3655.394737 stddev=5845.083222 entropy=0.426143 frames=6041 count=38
2017/08/30 01:51:52 Training policy...
2017/08/30 01:51:56 tune 0: objective=59.302987 reg=0.004261 prune=0
2017/08/30 01:51:57 step 0: objective=59.438333 reg=0.004260
2017/08/30 01:51:58 step 1: objective=59.551828 reg=0.004261
2017/08/30 01:52:00 step 2: objective=59.679368 reg=0.004260
2017/08/30 01:52:01 step 3: objective=59.756885 reg=0.004261
2017/08/30 01:52:02 step 4: objective=59.811765 reg=0.004260
2017/08/30 01:52:03 step 5: objective=59.856455 reg=0.004260
2017/08/30 01:52:04 step 6: objective=59.947267 reg=0.004259
2017/08/30 01:52:06 step 7: objective=59.999374 reg=0.004257
2017/08/30 01:52:06 Training value function...
2017/08/30 01:52:08 step 0: mse=201237.777182 step=0.050000
2017/08/30 01:52:09 step 1: mse=196960.577498 step=0.050000
2017/08/30 01:52:10 step 2: mse=192374.817776 step=0.050000
2017/08/30 01:52:11 step 3: mse=188920.077664 step=0.050000
2017/08/30 01:52:12 step 4: mse=185557.502254 step=0.050000
2017/08/30 01:52:13 step 5: mse=182020.721329 step=0.050000
2017/08/30 01:52:14 step 6: mse=182469.737005 step=0.050000
2017/08/30 01:52:15 step 7: mse=179889.351078 step=0.050000
2017/08/30 01:52:15 Saving...
2017/08/30 01:52:15 Gathering batch of experience...
2017/08/30 01:52:42 batch 523: mean=5900.000000 stddev=7625.872784 entropy=0.431909 frames=5931 count=28
2017/08/30 01:52:42 Training policy...
2017/08/30 01:52:46 tune 0: objective=78.641239 reg=0.004319 prune=0
2017/08/30 01:52:47 step 0: objective=78.829793 reg=0.004318
2017/08/30 01:52:48 step 1: objective=79.063332 reg=0.004318
2017/08/30 01:52:50 step 2: objective=79.300418 reg=0.004319
2017/08/30 01:52:51 step 3: objective=79.466216 reg=0.004318
2017/08/30 01:52:52 step 4: objective=79.567669 reg=0.004318
2017/08/30 01:52:53 step 5: objective=79.674560 reg=0.004317
2017/08/30 01:52:54 step 6: objective=79.805239 reg=0.004316
2017/08/30 01:52:56 step 7: objective=79.913974 reg=0.004315
2017/08/30 01:52:56 Training value function...
2017/08/30 01:52:58 step 0: mse=337129.570699 step=0.050000
2017/08/30 01:52:59 step 1: mse=324611.027240 step=0.050000
2017/08/30 01:53:00 step 2: mse=314656.181535 step=0.050000
2017/08/30 01:53:01 step 3: mse=312032.394815 step=0.050000
2017/08/30 01:53:02 step 4: mse=304189.127661 step=0.050000
2017/08/30 01:53:03 step 5: mse=298516.242611 step=0.050000
2017/08/30 01:53:04 step 6: mse=291749.016172 step=0.050000
2017/08/30 01:53:05 step 7: mse=288489.341945 step=0.050000
2017/08/30 01:53:05 Saving...
2017/08/30 01:53:05 Gathering batch of experience...
2017/08/30 01:53:35 batch 524: mean=4752.352941 stddev=6589.589855 entropy=0.425488 frames=6495 count=34
2017/08/30 01:53:35 Training policy...
2017/08/30 01:53:40 tune 0: objective=54.372926 reg=0.004255 prune=0
2017/08/30 01:53:41 step 0: objective=54.461475 reg=0.004254
2017/08/30 01:53:42 step 1: objective=54.539314 reg=0.004253
2017/08/30 01:53:44 step 2: objective=54.652959 reg=0.004252
2017/08/30 01:53:45 step 3: objective=54.743211 reg=0.004250
2017/08/30 01:53:46 step 4: objective=54.853719 reg=0.004250
2017/08/30 01:53:48 step 5: objective=54.931495 reg=0.004249
2017/08/30 01:53:49 step 6: objective=54.988530 reg=0.004249
2017/08/30 01:53:50 step 7: objective=55.039627 reg=0.004248
2017/08/30 01:53:50 Training value function...
2017/08/30 01:53:53 step 0: mse=205239.210616 step=0.050000
2017/08/30 01:53:54 step 1: mse=204230.575024 step=0.050000
2017/08/30 01:53:55 step 2: mse=201757.091206 step=0.050000
2017/08/30 01:53:56 step 3: mse=201672.505615 step=0.050000
2017/08/30 01:53:57 step 4: mse=201084.134195 step=0.050000
2017/08/30 01:53:58 step 5: mse=201404.931669 step=0.050000
2017/08/30 01:53:59 step 6: mse=200561.403484 step=0.050000
2017/08/30 01:54:00 step 7: mse=199630.311956 step=0.050000
2017/08/30 01:54:00 Saving...
2017/08/30 01:54:00 Gathering batch of experience...
2017/08/30 01:54:31 batch 525: mean=5317.500000 stddev=6660.273080 entropy=0.427187 frames=6551 count=32
2017/08/30 01:54:31 Training policy...
2017/08/30 01:54:35 tune 0: objective=49.739634 reg=0.004272 prune=0
2017/08/30 01:54:36 step 0: objective=49.945858 reg=0.004272
2017/08/30 01:54:38 step 1: objective=50.209677 reg=0.004272
2017/08/30 01:54:39 step 2: objective=50.373388 reg=0.004271
2017/08/30 01:54:40 step 3: objective=50.480666 reg=0.004272
2017/08/30 01:54:42 step 4: objective=50.540199 reg=0.004273
2017/08/30 01:54:43 step 5: objective=50.590578 reg=0.004274
2017/08/30 01:54:44 step 6: objective=50.637116 reg=0.004274
2017/08/30 01:54:46 step 7: objective=50.735608 reg=0.004275
2017/08/30 01:54:46 Training value function...
2017/08/30 01:54:48 step 0: mse=207153.625756 step=0.050000
2017/08/30 01:54:49 step 1: mse=202955.075853 step=0.050000
2017/08/30 01:54:51 step 2: mse=199884.187559 step=0.050000
2017/08/30 01:54:52 step 3: mse=198682.701205 step=0.050000
2017/08/30 01:54:53 step 4: mse=198249.159399 step=0.050000
2017/08/30 01:54:54 step 5: mse=197461.841964 step=0.050000
2017/08/30 01:54:55 step 6: mse=196280.505383 step=0.050000
2017/08/30 01:54:56 step 7: mse=194442.802707 step=0.050000
2017/08/30 01:54:56 Saving...
2017/08/30 01:54:56 Gathering batch of experience...
2017/08/30 01:55:23 batch 526: mean=4990.666667 stddev=7076.309388 entropy=0.428255 frames=5764 count=30
2017/08/30 01:55:23 Training policy...
2017/08/30 01:55:27 tune 0: objective=56.764655 reg=0.004283 prune=0
2017/08/30 01:55:29 step 0: objective=56.885903 reg=0.004283
2017/08/30 01:55:30 step 1: objective=56.998948 reg=0.004284
2017/08/30 01:55:31 step 2: objective=57.094037 reg=0.004285
2017/08/30 01:55:32 step 3: objective=57.194472 reg=0.004286
2017/08/30 01:55:33 step 4: objective=57.241851 reg=0.004287
2017/08/30 01:55:34 step 5: objective=57.306802 reg=0.004287
2017/08/30 01:55:36 step 6: objective=57.368391 reg=0.004287
2017/08/30 01:55:37 step 7: objective=57.420590 reg=0.004286
2017/08/30 01:55:37 Training value function...
2017/08/30 01:55:39 step 0: mse=186791.560277 step=0.050000
2017/08/30 01:55:40 step 1: mse=185192.144375 step=0.050000
2017/08/30 01:55:41 step 2: mse=183772.751162 step=0.050000
2017/08/30 01:55:42 step 3: mse=183424.454329 step=0.050000
2017/08/30 01:55:43 step 4: mse=182228.459368 step=0.050000
2017/08/30 01:55:44 step 5: mse=181122.008710 step=0.050000
2017/08/30 01:55:45 step 6: mse=178519.455672 step=0.050000
2017/08/30 01:55:45 step 7: mse=177443.847146 step=0.050000
2017/08/30 01:55:45 Saving...
2017/08/30 01:55:45 Gathering batch of experience...
2017/08/30 01:56:14 batch 527: mean=5640.000000 stddev=7292.510298 entropy=0.431254 frames=6293 count=31
2017/08/30 01:56:14 Training policy...
2017/08/30 01:56:19 tune 0: objective=57.396909 reg=0.004313 prune=0
2017/08/30 01:56:20 step 0: objective=57.496469 reg=0.004311
2017/08/30 01:56:21 step 1: objective=57.621688 reg=0.004310
2017/08/30 01:56:23 step 2: objective=57.736076 reg=0.004310
2017/08/30 01:56:24 step 3: objective=57.851432 reg=0.004309
2017/08/30 01:56:25 step 4: objective=57.932033 reg=0.004308
2017/08/30 01:56:26 step 5: objective=58.010840 reg=0.004307
2017/08/30 01:56:28 step 6: objective=58.067938 reg=0.004307
2017/08/30 01:56:29 step 7: objective=58.119160 reg=0.004305
2017/08/30 01:56:29 Training value function...
2017/08/30 01:56:32 step 0: mse=234019.743273 step=0.050000
2017/08/30 01:56:33 step 1: mse=233112.502394 step=0.050000
2017/08/30 01:56:34 step 2: mse=232946.628700 step=0.050000
2017/08/30 01:56:35 step 3: mse=231710.013000 step=0.050000
2017/08/30 01:56:36 step 4: mse=227326.882483 step=0.050000
2017/08/30 01:56:37 step 5: mse=226127.597723 step=0.050000
2017/08/30 01:56:38 step 6: mse=226800.538493 step=0.050000
2017/08/30 01:56:39 step 7: mse=226462.585093 step=0.050000
2017/08/30 01:56:39 Saving...
2017/08/30 01:56:39 Gathering batch of experience...
2017/08/30 01:57:08 batch 528: mean=2694.634146 stddev=4302.554600 entropy=0.423018 frames=5964 count=41
2017/08/30 01:57:08 Training policy...
2017/08/30 01:57:12 tune 0: objective=8.863753 reg=0.004230 prune=0
2017/08/30 01:57:13 step 0: objective=9.007747 reg=0.004228
2017/08/30 01:57:14 step 1: objective=9.138881 reg=0.004226
2017/08/30 01:57:15 step 2: objective=9.193840 reg=0.004227
2017/08/30 01:57:17 step 3: objective=9.261611 reg=0.004226
2017/08/30 01:57:18 step 4: objective=9.322538 reg=0.004227
2017/08/30 01:57:19 step 5: objective=9.368192 reg=0.004226
2017/08/30 01:57:20 step 6: objective=9.406295 reg=0.004227
2017/08/30 01:57:21 step 7: objective=9.433224 reg=0.004226
2017/08/30 01:57:21 Training value function...
2017/08/30 01:57:24 step 0: mse=99033.833302 step=0.050000
2017/08/30 01:57:25 step 1: mse=98571.221783 step=0.050000
2017/08/30 01:57:26 step 2: mse=98483.440266 step=0.050000
2017/08/30 01:57:27 step 3: mse=98218.816324 step=0.050000
2017/08/30 01:57:28 step 4: mse=98706.174289 step=0.050000
2017/08/30 01:57:29 step 5: mse=99112.833699 step=0.050000
2017/08/30 01:57:30 step 6: mse=99054.659163 step=0.050000
2017/08/30 01:57:30 step 7: mse=99556.133967 step=0.050000
2017/08/30 01:57:30 Saving...
2017/08/30 01:57:30 Gathering batch of experience...
2017/08/30 01:58:01 batch 529: mean=7406.538462 stddev=8370.084179 entropy=0.431997 frames=6360 count=26
2017/08/30 01:58:01 Training policy...
2017/08/30 01:58:05 tune 0: objective=81.251828 reg=0.004320 prune=0
2017/08/30 01:58:06 step 0: objective=81.395995 reg=0.004315
2017/08/30 01:58:08 step 1: objective=81.528837 reg=0.004315
2017/08/30 01:58:09 step 2: objective=81.645819 reg=0.004314
2017/08/30 01:58:10 step 3: objective=81.757871 reg=0.004312
2017/08/30 01:58:12 step 4: objective=81.904791 reg=0.004308
2017/08/30 01:58:13 step 5: objective=81.989849 reg=0.004307
2017/08/30 01:58:14 step 6: objective=82.063964 reg=0.004306
2017/08/30 01:58:15 step 7: objective=82.141814 reg=0.004304
2017/08/30 01:58:15 Training value function...
2017/08/30 01:58:18 step 0: mse=235392.524605 step=0.050000
2017/08/30 01:58:19 step 1: mse=231198.329533 step=0.050000
2017/08/30 01:58:20 step 2: mse=227357.110528 step=0.050000
2017/08/30 01:58:21 step 3: mse=223604.605328 step=0.050000
2017/08/30 01:58:22 step 4: mse=220749.334547 step=0.050000
2017/08/30 01:58:23 step 5: mse=217580.650878 step=0.050000
2017/08/30 01:58:24 step 6: mse=217599.386849 step=0.050000
2017/08/30 01:58:25 step 7: mse=215507.155624 step=0.050000
2017/08/30 01:58:25 Saving...
2017/08/30 01:58:25 Gathering batch of experience...
2017/08/30 01:58:56 batch 530: mean=4083.108108 stddev=6000.460270 entropy=0.422851 frames=6504 count=37
2017/08/30 01:58:56 Training policy...
2017/08/30 01:59:00 tune 0: objective=32.114420 reg=0.004229 prune=0
2017/08/30 01:59:02 step 0: objective=32.214171 reg=0.004226
2017/08/30 01:59:03 step 1: objective=32.355320 reg=0.004225
2017/08/30 01:59:04 step 2: objective=32.449798 reg=0.004224
2017/08/30 01:59:06 step 3: objective=32.538082 reg=0.004224
2017/08/30 01:59:07 step 4: objective=32.598694 reg=0.004224
2017/08/30 01:59:08 step 5: objective=32.666434 reg=0.004223
2017/08/30 01:59:09 step 6: objective=32.751088 reg=0.004222
2017/08/30 01:59:11 step 7: objective=32.812077 reg=0.004222
2017/08/30 01:59:11 Training value function...
2017/08/30 01:59:13 step 0: mse=184688.850475 step=0.050000
2017/08/30 01:59:14 step 1: mse=184916.892846 step=0.050000
2017/08/30 01:59:16 step 2: mse=185250.560804 step=0.050000
2017/08/30 01:59:17 step 3: mse=184118.062941 step=0.050000
2017/08/30 01:59:18 step 4: mse=182921.898212 step=0.050000
2017/08/30 01:59:19 step 5: mse=181824.975990 step=0.050000
2017/08/30 01:59:20 step 6: mse=180673.712024 step=0.050000
2017/08/30 01:59:21 step 7: mse=181053.021005 step=0.050000
2017/08/30 01:59:21 Saving...
2017/08/30 01:59:21 Gathering batch of experience...
2017/08/30 01:59:45 batch 531: mean=2736.805556 stddev=4392.888848 entropy=0.422495 frames=5143 count=36
2017/08/30 01:59:45 Training policy...
2017/08/30 01:59:49 tune 0: objective=16.438741 reg=0.004225 prune=0
2017/08/30 01:59:50 step 0: objective=16.501656 reg=0.004224
2017/08/30 01:59:51 step 1: objective=16.560932 reg=0.004223
2017/08/30 01:59:52 step 2: objective=16.635494 reg=0.004221
2017/08/30 01:59:53 step 3: objective=16.715654 reg=0.004220
2017/08/30 01:59:54 step 4: objective=16.771762 reg=0.004219
2017/08/30 01:59:55 step 5: objective=16.811311 reg=0.004218
2017/08/30 01:59:56 step 6: objective=16.842078 reg=0.004218
2017/08/30 01:59:57 step 7: objective=16.882149 reg=0.004219
2017/08/30 01:59:57 Training value function...
2017/08/30 01:59:59 step 0: mse=92702.110456 step=0.050000
2017/08/30 02:00:00 step 1: mse=92229.270107 step=0.050000
2017/08/30 02:00:01 step 2: mse=93403.225765 step=0.050000
2017/08/30 02:00:02 step 3: mse=94027.560875 step=0.050000
2017/08/30 02:00:02 step 4: mse=94151.413373 step=0.050000
2017/08/30 02:00:03 step 5: mse=93990.171007 step=0.050000
2017/08/30 02:00:04 step 6: mse=93418.591093 step=0.050000
2017/08/30 02:00:05 step 7: mse=92803.827784 step=0.050000
2017/08/30 02:00:05 Saving...
2017/08/30 02:00:05 Gathering batch of experience...
2017/08/30 02:00:33 batch 532: mean=3003.461538 stddev=5104.546133 entropy=0.421215 frames=5743 count=39
2017/08/30 02:00:33 Training policy...
2017/08/30 02:00:37 tune 0: objective=35.288623 reg=0.004212 prune=0
2017/08/30 02:00:39 step 0: objective=35.367978 reg=0.004212
2017/08/30 02:00:40 step 1: objective=35.467686 reg=0.004212
2017/08/30 02:00:41 step 2: objective=35.590210 reg=0.004211
2017/08/30 02:00:42 step 3: objective=35.654188 reg=0.004210
2017/08/30 02:00:43 step 4: objective=35.698990 reg=0.004211
2017/08/30 02:00:44 step 5: objective=35.724836 reg=0.004211
2017/08/30 02:00:46 step 6: objective=35.751420 reg=0.004210
2017/08/30 02:00:47 step 7: objective=35.798788 reg=0.004210
2017/08/30 02:00:47 Training value function...
2017/08/30 02:00:49 step 0: mse=143880.519285 step=0.050000
2017/08/30 02:00:50 step 1: mse=144119.500623 step=0.050000
2017/08/30 02:00:51 step 2: mse=142804.781085 step=0.050000
2017/08/30 02:00:52 step 3: mse=142594.257248 step=0.050000
2017/08/30 02:00:53 step 4: mse=141259.649640 step=0.050000
2017/08/30 02:00:54 step 5: mse=141618.338849 step=0.050000
2017/08/30 02:00:55 step 6: mse=140506.989428 step=0.050000
2017/08/30 02:00:55 step 7: mse=140015.508680 step=0.050000
2017/08/30 02:00:55 Saving...
2017/08/30 02:00:55 Gathering batch of experience...
2017/08/30 02:01:19 batch 533: mean=2540.571429 stddev=3139.665763 entropy=0.414809 frames=5194 count=35
2017/08/30 02:01:19 Training policy...
2017/08/30 02:01:23 tune 0: objective=13.425279 reg=0.004148 prune=0
2017/08/30 02:01:24 step 0: objective=13.599672 reg=0.004147
2017/08/30 02:01:25 step 1: objective=13.670075 reg=0.004147
2017/08/30 02:01:26 step 2: objective=13.741222 reg=0.004147
2017/08/30 02:01:27 step 3: objective=13.804558 reg=0.004147
2017/08/30 02:01:28 step 4: objective=13.836070 reg=0.004149
2017/08/30 02:01:29 step 5: objective=13.890148 reg=0.004148
2017/08/30 02:01:30 step 6: objective=13.938156 reg=0.004149
2017/08/30 02:01:31 step 7: objective=13.989340 reg=0.004149
2017/08/30 02:01:31 Training value function...
2017/08/30 02:01:33 step 0: mse=71203.633291 step=0.050000
2017/08/30 02:01:34 step 1: mse=70748.508473 step=0.050000
2017/08/30 02:01:35 step 2: mse=70611.886999 step=0.050000
2017/08/30 02:01:36 step 3: mse=70694.317805 step=0.050000
2017/08/30 02:01:37 step 4: mse=70645.805253 step=0.050000
2017/08/30 02:01:37 step 5: mse=70720.711191 step=0.050000
2017/08/30 02:01:38 step 6: mse=70536.037780 step=0.050000
2017/08/30 02:01:39 step 7: mse=70791.210499 step=0.050000
2017/08/30 02:01:39 Saving...
2017/08/30 02:01:39 Gathering batch of experience...
2017/08/30 02:02:10 batch 534: mean=5154.285714 stddev=7286.108323 entropy=0.428667 frames=6775 count=35
2017/08/30 02:02:10 Training policy...
2017/08/30 02:02:15 tune 0: objective=82.212205 reg=0.004287 prune=0
2017/08/30 02:02:16 step 0: objective=82.347039 reg=0.004287
2017/08/30 02:02:18 step 1: objective=82.493570 reg=0.004288
2017/08/30 02:02:19 step 2: objective=82.663755 reg=0.004286
2017/08/30 02:02:20 step 3: objective=82.836273 reg=0.004286
2017/08/30 02:02:22 step 4: objective=82.956089 reg=0.004287
2017/08/30 02:02:23 step 5: objective=83.071799 reg=0.004288
2017/08/30 02:02:25 step 6: objective=83.176439 reg=0.004287
2017/08/30 02:02:26 step 7: objective=83.255304 reg=0.004287
2017/08/30 02:02:26 Training value function...
2017/08/30 02:02:29 step 0: mse=288071.837805 step=0.050000
2017/08/30 02:02:30 step 1: mse=285473.111355 step=0.050000
2017/08/30 02:02:31 step 2: mse=277447.468544 step=0.050000
2017/08/30 02:02:32 step 3: mse=274208.550763 step=0.050000
2017/08/30 02:02:33 step 4: mse=269760.249138 step=0.050000
2017/08/30 02:02:34 step 5: mse=265333.496440 step=0.050000
2017/08/30 02:02:35 step 6: mse=263861.858930 step=0.050000
2017/08/30 02:02:36 step 7: mse=260697.068528 step=0.050000
2017/08/30 02:02:36 Saving...
2017/08/30 02:02:36 Gathering batch of experience...
2017/08/30 02:03:06 batch 535: mean=6021.612903 stddev=8115.977510 entropy=0.428117 frames=6317 count=31
2017/08/30 02:03:06 Training policy...
2017/08/30 02:03:10 tune 0: objective=84.237435 reg=0.004281 prune=0
2017/08/30 02:03:12 step 0: objective=84.347841 reg=0.004281
2017/08/30 02:03:13 step 1: objective=84.460850 reg=0.004282
2017/08/30 02:03:14 step 2: objective=84.571197 reg=0.004281
2017/08/30 02:03:15 step 3: objective=84.692259 reg=0.004281
2017/08/30 02:03:17 step 4: objective=84.802566 reg=0.004280
2017/08/30 02:03:18 step 5: objective=84.862138 reg=0.004280
2017/08/30 02:03:19 step 6: objective=84.943545 reg=0.004279
2017/08/30 02:03:21 step 7: objective=85.010982 reg=0.004278
2017/08/30 02:03:21 Training value function...
2017/08/30 02:03:23 step 0: mse=254032.238020 step=0.050000
2017/08/30 02:03:24 step 1: mse=247545.968449 step=0.050000
2017/08/30 02:03:25 step 2: mse=241769.311988 step=0.050000
2017/08/30 02:03:26 step 3: mse=236134.658311 step=0.050000
2017/08/30 02:03:27 step 4: mse=234107.295570 step=0.050000
2017/08/30 02:03:28 step 5: mse=229285.970530 step=0.050000
2017/08/30 02:03:29 step 6: mse=224892.043249 step=0.050000
2017/08/30 02:03:30 step 7: mse=221086.913158 step=0.050000
2017/08/30 02:03:30 Saving...
2017/08/30 02:03:30 Gathering batch of experience...
2017/08/30 02:03:55 batch 536: mean=4187.656250 stddev=6364.445182 entropy=0.422655 frames=5532 count=32
2017/08/30 02:03:55 Training policy...
2017/08/30 02:03:59 tune 0: objective=40.626175 reg=0.004227 prune=0
2017/08/30 02:04:00 step 0: objective=40.797999 reg=0.004225
2017/08/30 02:04:01 step 1: objective=40.900946 reg=0.004224
2017/08/30 02:04:02 step 2: objective=40.970775 reg=0.004223
2017/08/30 02:04:04 step 3: objective=41.053264 reg=0.004223
2017/08/30 02:04:05 step 4: objective=41.127051 reg=0.004222
2017/08/30 02:04:06 step 5: objective=41.185382 reg=0.004222
2017/08/30 02:04:07 step 6: objective=41.221145 reg=0.004222
2017/08/30 02:04:08 step 7: objective=41.272116 reg=0.004222
2017/08/30 02:04:08 Training value function...
2017/08/30 02:04:10 step 0: mse=145801.422582 step=0.050000
2017/08/30 02:04:11 step 1: mse=147662.401060 step=0.050000
2017/08/30 02:04:12 step 2: mse=147538.901950 step=0.050000
2017/08/30 02:04:13 step 3: mse=145785.689927 step=0.050000
2017/08/30 02:04:14 step 4: mse=144431.393336 step=0.050000
2017/08/30 02:04:15 step 5: mse=143170.783445 step=0.050000
2017/08/30 02:04:16 step 6: mse=141758.265014 step=0.050000
2017/08/30 02:04:16 step 7: mse=141105.484655 step=0.050000
2017/08/30 02:04:16 Saving...
2017/08/30 02:04:17 Gathering batch of experience...
2017/08/30 02:04:46 batch 537: mean=4649.558824 stddev=6729.910559 entropy=0.425212 frames=6215 count=34
2017/08/30 02:04:46 Training policy...
2017/08/30 02:04:50 tune 0: objective=53.346812 reg=0.004252 prune=0
2017/08/30 02:04:51 step 0: objective=53.500201 reg=0.004254
2017/08/30 02:04:53 step 1: objective=53.712289 reg=0.004256
2017/08/30 02:04:54 step 2: objective=53.838330 reg=0.004256
2017/08/30 02:04:55 step 3: objective=53.951830 reg=0.004254
2017/08/30 02:04:56 step 4: objective=54.041226 reg=0.004255
2017/08/30 02:04:58 step 5: objective=54.117935 reg=0.004254
2017/08/30 02:04:59 step 6: objective=54.161856 reg=0.004254
2017/08/30 02:05:00 step 7: objective=54.236283 reg=0.004253
2017/08/30 02:05:00 Training value function...
2017/08/30 02:05:03 step 0: mse=207879.750688 step=0.050000
2017/08/30 02:05:04 step 1: mse=205178.311643 step=0.050000
2017/08/30 02:05:05 step 2: mse=204468.681251 step=0.050000
2017/08/30 02:05:06 step 3: mse=204752.325942 step=0.050000
2017/08/30 02:05:07 step 4: mse=204050.375885 step=0.050000
2017/08/30 02:05:08 step 5: mse=203345.050738 step=0.050000
2017/08/30 02:05:09 step 6: mse=202208.037399 step=0.050000
2017/08/30 02:05:10 step 7: mse=201044.485306 step=0.050000
2017/08/30 02:05:10 Saving...
2017/08/30 02:05:10 Gathering batch of experience...
2017/08/30 02:05:39 batch 538: mean=4180.000000 stddev=6656.240620 entropy=0.422913 frames=6210 count=37
2017/08/30 02:05:39 Training policy...
2017/08/30 02:05:43 tune 0: objective=48.703231 reg=0.004229 prune=0
2017/08/30 02:05:45 step 0: objective=48.787787 reg=0.004228
2017/08/30 02:05:46 step 1: objective=48.852969 reg=0.004228
2017/08/30 02:05:47 step 2: objective=48.954489 reg=0.004227
2017/08/30 02:05:48 step 3: objective=49.024336 reg=0.004229
2017/08/30 02:05:50 step 4: objective=49.075493 reg=0.004229
2017/08/30 02:05:51 step 5: objective=49.167879 reg=0.004228
2017/08/30 02:05:52 step 6: objective=49.212510 reg=0.004228
2017/08/30 02:05:54 step 7: objective=49.260356 reg=0.004229
2017/08/30 02:05:54 Training value function...
2017/08/30 02:05:56 step 0: mse=172384.975728 step=0.050000
2017/08/30 02:05:57 step 1: mse=171756.960552 step=0.050000
2017/08/30 02:05:58 step 2: mse=170131.748663 step=0.050000
2017/08/30 02:05:59 step 3: mse=168838.053023 step=0.050000
2017/08/30 02:06:00 step 4: mse=168636.288792 step=0.050000
2017/08/30 02:06:01 step 5: mse=168057.208812 step=0.050000
2017/08/30 02:06:02 step 6: mse=166291.990036 step=0.050000
2017/08/30 02:06:03 step 7: mse=166207.862865 step=0.050000
2017/08/30 02:06:03 Saving...
2017/08/30 02:06:03 Gathering batch of experience...
2017/08/30 02:06:32 batch 539: mean=5912.758621 stddev=7695.319624 entropy=0.424963 frames=6206 count=29
2017/08/30 02:06:32 Training policy...
2017/08/30 02:06:37 tune 0: objective=66.661849 reg=0.004250 prune=0
2017/08/30 02:06:38 step 0: objective=66.749265 reg=0.004250
2017/08/30 02:06:39 step 1: objective=66.831786 reg=0.004249
2017/08/30 02:06:41 step 2: objective=66.924755 reg=0.004249
2017/08/30 02:06:42 step 3: objective=66.987673 reg=0.004248
2017/08/30 02:06:43 step 4: objective=67.115755 reg=0.004248
2017/08/30 02:06:44 step 5: objective=67.210789 reg=0.004248
2017/08/30 02:06:46 step 6: objective=67.274699 reg=0.004248
2017/08/30 02:06:47 step 7: objective=67.339112 reg=0.004247
2017/08/30 02:06:47 Training value function...
2017/08/30 02:06:50 step 0: mse=181666.135689 step=0.050000
2017/08/30 02:06:51 step 1: mse=180962.493637 step=0.050000
2017/08/30 02:06:52 step 2: mse=179402.499942 step=0.050000
2017/08/30 02:06:53 step 3: mse=177071.663676 step=0.050000
2017/08/30 02:06:54 step 4: mse=175396.538116 step=0.050000
2017/08/30 02:06:55 step 5: mse=174786.695318 step=0.050000
2017/08/30 02:06:56 step 6: mse=172795.947353 step=0.050000
2017/08/30 02:06:57 step 7: mse=172601.059616 step=0.050000
2017/08/30 02:06:57 Saving...
2017/08/30 02:06:57 Gathering batch of experience...
2017/08/30 02:07:28 batch 540: mean=5125.285714 stddev=7249.795065 entropy=0.423365 frames=6739 count=35
2017/08/30 02:07:28 Training policy...
2017/08/30 02:07:33 tune 0: objective=49.177150 reg=0.004234 prune=0
2017/08/30 02:07:34 step 0: objective=49.269226 reg=0.004232
2017/08/30 02:07:35 step 1: objective=49.348392 reg=0.004232
2017/08/30 02:07:37 step 2: objective=49.496633 reg=0.004231
2017/08/30 02:07:38 step 3: objective=49.587253 reg=0.004230
2017/08/30 02:07:40 step 4: objective=49.664453 reg=0.004229
2017/08/30 02:07:41 step 5: objective=49.721351 reg=0.004229
2017/08/30 02:07:42 step 6: objective=49.784362 reg=0.004228
2017/08/30 02:07:44 step 7: objective=49.833785 reg=0.004228
2017/08/30 02:07:44 Training value function...
2017/08/30 02:07:46 step 0: mse=158329.847301 step=0.050000
2017/08/30 02:07:48 step 1: mse=158541.030523 step=0.050000
2017/08/30 02:07:49 step 2: mse=159144.537686 step=0.050000
2017/08/30 02:07:50 step 3: mse=158662.873892 step=0.050000
2017/08/30 02:07:51 step 4: mse=159515.001426 step=0.050000
2017/08/30 02:07:52 step 5: mse=159102.285725 step=0.050000
2017/08/30 02:07:53 step 6: mse=158937.752208 step=0.050000
2017/08/30 02:07:54 step 7: mse=158078.854150 step=0.050000
2017/08/30 02:07:54 Saving...
2017/08/30 02:07:54 Gathering batch of experience...
2017/08/30 02:08:20 batch 541: mean=4629.500000 stddev=6205.624109 entropy=0.421390 frames=5533 count=30
2017/08/30 02:08:20 Training policy...
2017/08/30 02:08:24 tune 0: objective=30.937701 reg=0.004214 prune=0
2017/08/30 02:08:25 step 0: objective=31.175696 reg=0.004211
2017/08/30 02:08:26 step 1: objective=31.351691 reg=0.004210
2017/08/30 02:08:27 step 2: objective=31.472111 reg=0.004213
2017/08/30 02:08:28 step 3: objective=31.669161 reg=0.004214
2017/08/30 02:08:29 step 4: objective=31.798013 reg=0.004213
2017/08/30 02:08:30 step 5: objective=31.886389 reg=0.004213
2017/08/30 02:08:32 step 6: objective=31.933064 reg=0.004212
2017/08/30 02:08:33 step 7: objective=32.006074 reg=0.004212
2017/08/30 02:08:33 Training value function...
2017/08/30 02:08:35 step 0: mse=193767.675433 step=0.050000
2017/08/30 02:08:36 step 1: mse=192925.586652 step=0.050000
2017/08/30 02:08:37 step 2: mse=191077.998312 step=0.050000
2017/08/30 02:08:38 step 3: mse=187662.734219 step=0.050000
2017/08/30 02:08:39 step 4: mse=187906.979335 step=0.050000
2017/08/30 02:08:39 step 5: mse=188643.771199 step=0.050000
2017/08/30 02:08:40 step 6: mse=188717.285085 step=0.050000
2017/08/30 02:08:41 step 7: mse=185127.083914 step=0.050000
2017/08/30 02:08:41 Saving...
2017/08/30 02:08:41 Gathering batch of experience...
2017/08/30 02:09:13 batch 542: mean=4170.000000 stddev=6071.431737 entropy=0.421681 frames=6525 count=36
2017/08/30 02:09:13 Training policy...
2017/08/30 02:09:17 tune 0: objective=37.435558 reg=0.004217 prune=0
2017/08/30 02:09:19 step 0: objective=37.586312 reg=0.004216
2017/08/30 02:09:20 step 1: objective=37.756906 reg=0.004216
2017/08/30 02:09:21 step 2: objective=37.899025 reg=0.004215
2017/08/30 02:09:23 step 3: objective=38.009713 reg=0.004214
2017/08/30 02:09:24 step 4: objective=38.077486 reg=0.004214
2017/08/30 02:09:25 step 5: objective=38.124207 reg=0.004214
2017/08/30 02:09:27 step 6: objective=38.157323 reg=0.004215
2017/08/30 02:09:28 step 7: objective=38.211518 reg=0.004214
2017/08/30 02:09:28 Training value function...
2017/08/30 02:09:30 step 0: mse=169861.751067 step=0.050000
2017/08/30 02:09:31 step 1: mse=169928.624342 step=0.050000
2017/08/30 02:09:33 step 2: mse=170539.074120 step=0.050000
2017/08/30 02:09:34 step 3: mse=170561.270165 step=0.050000
2017/08/30 02:09:35 step 4: mse=171412.139997 step=0.050000
2017/08/30 02:09:36 step 5: mse=171326.234985 step=0.050000
2017/08/30 02:09:37 step 6: mse=171679.561714 step=0.050000
2017/08/30 02:09:38 step 7: mse=171550.070734 step=0.050000
2017/08/30 02:09:38 Saving...
2017/08/30 02:09:38 Gathering batch of experience...
2017/08/30 02:10:11 batch 543: mean=5691.428571 stddev=7565.596811 entropy=0.423210 frames=7113 count=35
2017/08/30 02:10:11 Training policy...
2017/08/30 02:10:16 tune 0: objective=64.721768 reg=0.004232 prune=0
2017/08/30 02:10:18 step 0: objective=64.840538 reg=0.004232
2017/08/30 02:10:19 step 1: objective=64.968196 reg=0.004233
2017/08/30 02:10:21 step 2: objective=65.097643 reg=0.004232
2017/08/30 02:10:22 step 3: objective=65.208083 reg=0.004232
2017/08/30 02:10:23 step 4: objective=65.318598 reg=0.004231
2017/08/30 02:10:25 step 5: objective=65.387908 reg=0.004230
2017/08/30 02:10:26 step 6: objective=65.449419 reg=0.004229
2017/08/30 02:10:28 step 7: objective=65.517516 reg=0.004229
2017/08/30 02:10:28 Training value function...
2017/08/30 02:10:31 step 0: mse=201032.254850 step=0.050000
2017/08/30 02:10:32 step 1: mse=199498.176739 step=0.050000
2017/08/30 02:10:33 step 2: mse=197292.818630 step=0.050000
2017/08/30 02:10:34 step 3: mse=197290.701652 step=0.050000
2017/08/30 02:10:35 step 4: mse=195041.968393 step=0.050000
2017/08/30 02:10:37 step 5: mse=195828.231429 step=0.050000
2017/08/30 02:10:38 step 6: mse=195325.817747 step=0.050000
2017/08/30 02:10:39 step 7: mse=193570.166942 step=0.050000
2017/08/30 02:10:39 Saving...
2017/08/30 02:10:39 Gathering batch of experience...
2017/08/30 02:11:11 batch 544: mean=5660.735294 stddev=7625.221128 entropy=0.424493 frames=6901 count=34
2017/08/30 02:11:11 Training policy...
2017/08/30 02:11:16 tune 0: objective=63.920519 reg=0.004245 prune=0
2017/08/30 02:11:17 step 0: objective=64.058610 reg=0.004246
2017/08/30 02:11:19 step 1: objective=64.220620 reg=0.004245
2017/08/30 02:11:20 step 2: objective=64.400725 reg=0.004246
2017/08/30 02:11:21 step 3: objective=64.507925 reg=0.004244
2017/08/30 02:11:23 step 4: objective=64.573699 reg=0.004244
2017/08/30 02:11:24 step 5: objective=64.649426 reg=0.004244
2017/08/30 02:11:26 step 6: objective=64.692291 reg=0.004242
2017/08/30 02:11:27 step 7: objective=64.746894 reg=0.004241
2017/08/30 02:11:27 Training value function...
2017/08/30 02:11:30 step 0: mse=225991.210037 step=0.050000
2017/08/30 02:11:31 step 1: mse=226057.650163 step=0.050000
2017/08/30 02:11:32 step 2: mse=223865.113507 step=0.050000
2017/08/30 02:11:33 step 3: mse=218447.985573 step=0.050000
2017/08/30 02:11:34 step 4: mse=217712.314266 step=0.050000
2017/08/30 02:11:35 step 5: mse=217592.479304 step=0.050000
2017/08/30 02:11:37 step 6: mse=215957.523291 step=0.050000
2017/08/30 02:11:38 step 7: mse=214958.796647 step=0.050000
2017/08/30 02:11:38 Saving...
2017/08/30 02:11:38 Gathering batch of experience...
2017/08/30 02:12:06 batch 545: mean=3585.142857 stddev=5291.367564 entropy=0.416412 frames=5919 count=35
2017/08/30 02:12:06 Training policy...
2017/08/30 02:12:10 tune 0: objective=25.051220 reg=0.004164 prune=0
2017/08/30 02:12:12 step 0: objective=25.149724 reg=0.004164
2017/08/30 02:12:13 step 1: objective=25.213486 reg=0.004165
2017/08/30 02:12:14 step 2: objective=25.268518 reg=0.004164
2017/08/30 02:12:15 step 3: objective=25.345722 reg=0.004164
2017/08/30 02:12:17 step 4: objective=25.396889 reg=0.004165
2017/08/30 02:12:18 step 5: objective=25.467694 reg=0.004167
2017/08/30 02:12:19 step 6: objective=25.504448 reg=0.004167
2017/08/30 02:12:20 step 7: objective=25.556914 reg=0.004168
2017/08/30 02:12:20 Training value function...
2017/08/30 02:12:23 step 0: mse=162147.034356 step=0.050000
2017/08/30 02:12:24 step 1: mse=160835.167111 step=0.050000
2017/08/30 02:12:24 step 2: mse=161627.033448 step=0.050000
2017/08/30 02:12:25 step 3: mse=161304.685105 step=0.050000
2017/08/30 02:12:26 step 4: mse=160596.895900 step=0.050000
2017/08/30 02:12:27 step 5: mse=160988.520654 step=0.050000
2017/08/30 02:12:28 step 6: mse=160221.861012 step=0.050000
2017/08/30 02:12:29 step 7: mse=160284.223732 step=0.050000
2017/08/30 02:12:29 Saving...
2017/08/30 02:12:29 Gathering batch of experience...
2017/08/30 02:12:57 batch 546: mean=5881.379310 stddev=7522.894126 entropy=0.427363 frames=5956 count=29
2017/08/30 02:12:57 Training policy...
2017/08/30 02:13:01 tune 0: objective=62.178098 reg=0.004274 prune=0
2017/08/30 02:13:03 step 0: objective=62.402766 reg=0.004275
2017/08/30 02:13:04 step 1: objective=62.581488 reg=0.004275
2017/08/30 02:13:05 step 2: objective=62.696546 reg=0.004274
2017/08/30 02:13:06 step 3: objective=62.801602 reg=0.004274
2017/08/30 02:13:07 step 4: objective=62.917588 reg=0.004273
2017/08/30 02:13:09 step 5: objective=63.081966 reg=0.004273
2017/08/30 02:13:10 step 6: objective=63.127340 reg=0.004272
2017/08/30 02:13:11 step 7: objective=63.164367 reg=0.004272
2017/08/30 02:13:11 Training value function...
2017/08/30 02:13:14 step 0: mse=247567.981225 step=0.050000
2017/08/30 02:13:15 step 1: mse=246804.643263 step=0.050000
2017/08/30 02:13:15 step 2: mse=245578.113833 step=0.050000
2017/08/30 02:13:16 step 3: mse=245612.080224 step=0.050000
2017/08/30 02:13:17 step 4: mse=244679.905619 step=0.050000
2017/08/30 02:13:18 step 5: mse=242933.662111 step=0.050000
2017/08/30 02:13:19 step 6: mse=239764.180130 step=0.050000
2017/08/30 02:13:20 step 7: mse=237228.805397 step=0.050000
2017/08/30 02:13:20 Saving...
2017/08/30 02:13:20 Gathering batch of experience...
2017/08/30 02:13:49 batch 547: mean=3320.131579 stddev=5248.445946 entropy=0.418357 frames=5943 count=38
2017/08/30 02:13:49 Training policy...
2017/08/30 02:13:53 tune 0: objective=26.388553 reg=0.004184 prune=0
2017/08/30 02:13:54 step 0: objective=26.458333 reg=0.004183
2017/08/30 02:13:56 step 1: objective=26.511290 reg=0.004183
2017/08/30 02:13:57 step 2: objective=26.568544 reg=0.004184
2017/08/30 02:13:58 step 3: objective=26.615622 reg=0.004185
2017/08/30 02:13:59 step 4: objective=26.667245 reg=0.004185
2017/08/30 02:14:00 step 5: objective=26.724823 reg=0.004185
2017/08/30 02:14:02 step 6: objective=26.757398 reg=0.004185
2017/08/30 02:14:03 step 7: objective=26.787281 reg=0.004184
2017/08/30 02:14:03 Training value function...
2017/08/30 02:14:05 step 0: mse=113387.619537 step=0.050000
2017/08/30 02:14:06 step 1: mse=113486.593797 step=0.050000
2017/08/30 02:14:07 step 2: mse=113511.572690 step=0.050000
2017/08/30 02:14:08 step 3: mse=112498.124696 step=0.050000
2017/08/30 02:14:09 step 4: mse=113525.572571 step=0.050000
2017/08/30 02:14:10 step 5: mse=113226.271402 step=0.050000
2017/08/30 02:14:11 step 6: mse=113297.650179 step=0.050000
2017/08/30 02:14:12 step 7: mse=114076.415501 step=0.050000
2017/08/30 02:14:12 Saving...
2017/08/30 02:14:12 Gathering batch of experience...
2017/08/30 02:14:41 batch 548: mean=4816.285714 stddev=7329.344771 entropy=0.427625 frames=6214 count=35
2017/08/30 02:14:41 Training policy...
2017/08/30 02:14:46 tune 0: objective=58.043204 reg=0.004276 prune=0
2017/08/30 02:14:47 step 0: objective=58.153741 reg=0.004274
2017/08/30 02:14:48 step 1: objective=58.243472 reg=0.004273
2017/08/30 02:14:49 step 2: objective=58.337670 reg=0.004272
2017/08/30 02:14:51 step 3: objective=58.402906 reg=0.004271
2017/08/30 02:14:52 step 4: objective=58.483621 reg=0.004271
2017/08/30 02:14:53 step 5: objective=58.540357 reg=0.004271
2017/08/30 02:14:54 step 6: objective=58.601837 reg=0.004270
2017/08/30 02:14:56 step 7: objective=58.642828 reg=0.004270
2017/08/30 02:14:56 Training value function...
2017/08/30 02:14:58 step 0: mse=196936.603491 step=0.050000
2017/08/30 02:14:59 step 1: mse=195630.755327 step=0.050000
2017/08/30 02:15:00 step 2: mse=193502.859175 step=0.050000
2017/08/30 02:15:01 step 3: mse=190159.848386 step=0.050000
2017/08/30 02:15:02 step 4: mse=189993.769120 step=0.050000
2017/08/30 02:15:03 step 5: mse=191025.309088 step=0.050000
2017/08/30 02:15:04 step 6: mse=187908.989750 step=0.050000
2017/08/30 02:15:05 step 7: mse=185137.586253 step=0.050000
2017/08/30 02:15:05 Saving...
2017/08/30 02:15:05 Gathering batch of experience...
2017/08/30 02:15:37 batch 549: mean=5143.484848 stddev=6804.653653 entropy=0.420902 frames=6683 count=33
2017/08/30 02:15:37 Training policy...
2017/08/30 02:15:41 tune 0: objective=47.982409 reg=0.004209 prune=0
2017/08/30 02:15:43 step 0: objective=48.135746 reg=0.004208
2017/08/30 02:15:44 step 1: objective=48.231296 reg=0.004207
2017/08/30 02:15:45 step 2: objective=48.335562 reg=0.004206
2017/08/30 02:15:47 step 3: objective=48.432361 reg=0.004205
2017/08/30 02:15:48 step 4: objective=48.515730 reg=0.004204
2017/08/30 02:15:50 step 5: objective=48.595017 reg=0.004204
2017/08/30 02:15:51 step 6: objective=48.683268 reg=0.004202
2017/08/30 02:15:52 step 7: objective=48.751216 reg=0.004201
2017/08/30 02:15:52 Training value function...
2017/08/30 02:15:55 step 0: mse=183262.457998 step=0.050000
2017/08/30 02:15:56 step 1: mse=182855.461101 step=0.050000
2017/08/30 02:15:57 step 2: mse=182583.246390 step=0.050000
2017/08/30 02:15:58 step 3: mse=182465.355335 step=0.050000
2017/08/30 02:15:59 step 4: mse=183130.652040 step=0.050000
2017/08/30 02:16:00 step 5: mse=183130.866709 step=0.050000
2017/08/30 02:16:01 step 6: mse=183522.931765 step=0.050000
2017/08/30 02:16:03 step 7: mse=184196.220163 step=0.050000
2017/08/30 02:16:03 Saving...
2017/08/30 02:16:03 Gathering batch of experience...
2017/08/30 02:16:31 batch 550: mean=2937.972973 stddev=4459.067812 entropy=0.413992 frames=5442 count=37
2017/08/30 02:16:31 Training policy...
2017/08/30 02:16:35 tune 0: objective=15.473957 reg=0.004140 prune=0
2017/08/30 02:16:36 step 0: objective=15.581074 reg=0.004139
2017/08/30 02:16:37 step 1: objective=15.690767 reg=0.004139
2017/08/30 02:16:38 step 2: objective=15.785346 reg=0.004139
2017/08/30 02:16:39 step 3: objective=15.861910 reg=0.004139
2017/08/30 02:16:40 step 4: objective=15.930990 reg=0.004139
2017/08/30 02:16:41 step 5: objective=15.984999 reg=0.004139
2017/08/30 02:16:42 step 6: objective=16.046134 reg=0.004138
2017/08/30 02:16:43 step 7: objective=16.074809 reg=0.004138
2017/08/30 02:16:43 Training value function...
2017/08/30 02:16:46 step 0: mse=121208.925495 step=0.050000
2017/08/30 02:16:47 step 1: mse=121930.483873 step=0.050000
2017/08/30 02:16:47 step 2: mse=121948.413811 step=0.050000
2017/08/30 02:16:48 step 3: mse=121972.190733 step=0.050000
2017/08/30 02:16:49 step 4: mse=122278.757786 step=0.050000
2017/08/30 02:16:50 step 5: mse=123174.677115 step=0.050000
2017/08/30 02:16:51 step 6: mse=124074.197051 step=0.050000
2017/08/30 02:16:52 step 7: mse=124963.068031 step=0.050000
2017/08/30 02:16:52 Saving...
2017/08/30 02:16:52 Gathering batch of experience...
2017/08/30 02:17:21 batch 551: mean=5356.969697 stddev=7489.738226 entropy=0.422618 frames=6267 count=33
2017/08/30 02:17:21 Training policy...
2017/08/30 02:17:25 tune 0: objective=72.219672 reg=0.004226 prune=0
2017/08/30 02:17:27 step 0: objective=72.347420 reg=0.004228
2017/08/30 02:17:28 step 1: objective=72.457565 reg=0.004228
2017/08/30 02:17:29 step 2: objective=72.544678 reg=0.004229
2017/08/30 02:17:31 step 3: objective=72.632460 reg=0.004229
2017/08/30 02:17:32 step 4: objective=72.697837 reg=0.004228
2017/08/30 02:17:33 step 5: objective=72.814300 reg=0.004228
2017/08/30 02:17:34 step 6: objective=72.859936 reg=0.004228
2017/08/30 02:17:36 step 7: objective=72.906080 reg=0.004228
2017/08/30 02:17:36 Training value function...
2017/08/30 02:17:38 step 0: mse=222807.794356 step=0.050000
2017/08/30 02:17:39 step 1: mse=219748.517113 step=0.050000
2017/08/30 02:17:40 step 2: mse=217445.568466 step=0.050000
2017/08/30 02:17:41 step 3: mse=215970.374957 step=0.050000
2017/08/30 02:17:42 step 4: mse=212807.996673 step=0.050000
2017/08/30 02:17:43 step 5: mse=212805.204834 step=0.050000
2017/08/30 02:17:44 step 6: mse=209213.130445 step=0.050000
2017/08/30 02:17:45 step 7: mse=206862.597763 step=0.050000
2017/08/30 02:17:45 Saving...
2017/08/30 02:17:45 Gathering batch of experience...
2017/08/30 02:18:13 batch 552: mean=4644.843750 stddev=6921.703354 entropy=0.422173 frames=5946 count=32
2017/08/30 02:18:13 Training policy...
2017/08/30 02:18:17 tune 0: objective=55.087900 reg=0.004222 prune=0
2017/08/30 02:18:19 step 0: objective=55.198616 reg=0.004222
2017/08/30 02:18:20 step 1: objective=55.259839 reg=0.004223
2017/08/30 02:18:21 step 2: objective=55.412709 reg=0.004224
2017/08/30 02:18:22 step 3: objective=55.552556 reg=0.004223
2017/08/30 02:18:24 step 4: objective=55.610326 reg=0.004223
2017/08/30 02:18:25 step 5: objective=55.669358 reg=0.004224
2017/08/30 02:18:26 step 6: objective=55.725635 reg=0.004223
2017/08/30 02:18:27 step 7: objective=55.782375 reg=0.004223
2017/08/30 02:18:27 Training value function...
2017/08/30 02:18:30 step 0: mse=223004.587102 step=0.050000
2017/08/30 02:18:31 step 1: mse=219222.941964 step=0.050000
2017/08/30 02:18:31 step 2: mse=217994.007812 step=0.050000
2017/08/30 02:18:32 step 3: mse=216836.855804 step=0.050000
2017/08/30 02:18:33 step 4: mse=215566.662305 step=0.050000
2017/08/30 02:18:34 step 5: mse=211168.690583 step=0.050000
2017/08/30 02:18:35 step 6: mse=207025.559625 step=0.050000
2017/08/30 02:18:36 step 7: mse=205465.685122 step=0.050000
2017/08/30 02:18:36 Saving...
2017/08/30 02:18:36 Gathering batch of experience...
2017/08/30 02:19:05 batch 553: mean=5575.357143 stddev=7271.899306 entropy=0.423980 frames=5980 count=28
2017/08/30 02:19:05 Training policy...
2017/08/30 02:19:09 tune 0: objective=49.589528 reg=0.004240 prune=0
2017/08/30 02:19:10 step 0: objective=49.709631 reg=0.004240
2017/08/30 02:19:11 step 1: objective=49.831198 reg=0.004240
2017/08/30 02:19:13 step 2: objective=49.943551 reg=0.004240
2017/08/30 02:19:14 step 3: objective=50.037202 reg=0.004239
2017/08/30 02:19:15 step 4: objective=50.124023 reg=0.004239
2017/08/30 02:19:16 step 5: objective=50.192736 reg=0.004239
2017/08/30 02:19:18 step 6: objective=50.256517 reg=0.004240
2017/08/30 02:19:19 step 7: objective=50.310290 reg=0.004241
2017/08/30 02:19:19 Training value function...
2017/08/30 02:19:21 step 0: mse=178929.351598 step=0.050000
2017/08/30 02:19:22 step 1: mse=177860.121021 step=0.050000
2017/08/30 02:19:23 step 2: mse=176985.931759 step=0.050000
2017/08/30 02:19:24 step 3: mse=176439.436864 step=0.050000
2017/08/30 02:19:25 step 4: mse=176779.272189 step=0.050000
2017/08/30 02:19:26 step 5: mse=176124.397747 step=0.050000
2017/08/30 02:19:27 step 6: mse=174552.821354 step=0.050000
2017/08/30 02:19:28 step 7: mse=173036.898306 step=0.050000
2017/08/30 02:19:28 Saving...
2017/08/30 02:19:28 Gathering batch of experience...
2017/08/30 02:19:58 batch 554: mean=5051.875000 stddev=6992.436176 entropy=0.421800 frames=6310 count=32
2017/08/30 02:19:58 Training policy...
2017/08/30 02:20:02 tune 0: objective=49.500030 reg=0.004218 prune=0
2017/08/30 02:20:03 step 0: objective=49.668171 reg=0.004217
2017/08/30 02:20:05 step 1: objective=49.798836 reg=0.004217
2017/08/30 02:20:06 step 2: objective=49.966972 reg=0.004217
2017/08/30 02:20:07 step 3: objective=50.117467 reg=0.004217
2017/08/30 02:20:09 step 4: objective=50.183508 reg=0.004217
2017/08/30 02:20:10 step 5: objective=50.288500 reg=0.004217
2017/08/30 02:20:11 step 6: objective=50.347291 reg=0.004217
2017/08/30 02:20:13 step 7: objective=50.445072 reg=0.004217
2017/08/30 02:20:13 Training value function...
2017/08/30 02:20:15 step 0: mse=206586.555364 step=0.050000
2017/08/30 02:20:16 step 1: mse=206225.217851 step=0.050000
2017/08/30 02:20:17 step 2: mse=206318.241097 step=0.050000
2017/08/30 02:20:18 step 3: mse=206346.477905 step=0.050000
2017/08/30 02:20:19 step 4: mse=206906.364721 step=0.050000
2017/08/30 02:20:20 step 5: mse=206870.065334 step=0.050000
2017/08/30 02:20:21 step 6: mse=207612.714842 step=0.050000
2017/08/30 02:20:22 step 7: mse=207503.697303 step=0.050000
2017/08/30 02:20:22 Saving...
2017/08/30 02:20:22 Gathering batch of experience...
2017/08/30 02:20:48 batch 555: mean=4312.031250 stddev=6345.111044 entropy=0.418685 frames=5855 count=32
2017/08/30 02:20:48 Training policy...
2017/08/30 02:20:52 tune 0: objective=38.176524 reg=0.004187 prune=0
2017/08/30 02:20:54 step 0: objective=38.322289 reg=0.004186
2017/08/30 02:20:55 step 1: objective=38.428165 reg=0.004187
2017/08/30 02:20:56 step 2: objective=38.539320 reg=0.004187
2017/08/30 02:20:57 step 3: objective=38.609991 reg=0.004188
2017/08/30 02:20:59 step 4: objective=38.694831 reg=0.004188
2017/08/30 02:21:00 step 5: objective=38.733396 reg=0.004188
2017/08/30 02:21:01 step 6: objective=38.775918 reg=0.004188
2017/08/30 02:21:02 step 7: objective=38.817837 reg=0.004188
2017/08/30 02:21:02 Training value function...
2017/08/30 02:21:04 step 0: mse=142010.314876 step=0.050000
2017/08/30 02:21:05 step 1: mse=143392.146283 step=0.050000
2017/08/30 02:21:06 step 2: mse=142794.113896 step=0.050000
2017/08/30 02:21:07 step 3: mse=142912.407221 step=0.050000
2017/08/30 02:21:08 step 4: mse=141535.525901 step=0.050000
2017/08/30 02:21:09 step 5: mse=140469.231244 step=0.050000
2017/08/30 02:21:10 step 6: mse=141064.230306 step=0.050000
2017/08/30 02:21:11 step 7: mse=140755.219607 step=0.050000
2017/08/30 02:21:11 Saving...
2017/08/30 02:21:11 Gathering batch of experience...
2017/08/30 02:21:41 batch 556: mean=3814.714286 stddev=5481.751147 entropy=0.417399 frames=6042 count=35
2017/08/30 02:21:41 Training policy...
2017/08/30 02:21:45 tune 0: objective=26.685129 reg=0.004174 prune=0
2017/08/30 02:21:46 step 0: objective=26.846176 reg=0.004172
2017/08/30 02:21:47 step 1: objective=26.959086 reg=0.004171
2017/08/30 02:21:49 step 2: objective=27.056061 reg=0.004171
2017/08/30 02:21:50 step 3: objective=27.102111 reg=0.004172
2017/08/30 02:21:51 step 4: objective=27.190161 reg=0.004171
2017/08/30 02:21:52 step 5: objective=27.239056 reg=0.004172
2017/08/30 02:21:54 step 6: objective=27.319746 reg=0.004173
2017/08/30 02:21:55 step 7: objective=27.380658 reg=0.004173
2017/08/30 02:21:55 Training value function...
2017/08/30 02:21:57 step 0: mse=127905.195140 step=0.050000
2017/08/30 02:21:58 step 1: mse=128188.343986 step=0.050000
2017/08/30 02:21:59 step 2: mse=127815.799802 step=0.050000
2017/08/30 02:22:00 step 3: mse=127736.075562 step=0.050000
2017/08/30 02:22:01 step 4: mse=128633.994976 step=0.050000
2017/08/30 02:22:02 step 5: mse=129335.193070 step=0.050000
2017/08/30 02:22:03 step 6: mse=129718.839440 step=0.050000
2017/08/30 02:22:04 step 7: mse=129364.775787 step=0.050000
2017/08/30 02:22:04 Saving...
2017/08/30 02:22:04 Gathering batch of experience...
2017/08/30 02:22:34 batch 557: mean=5922.031250 stddev=7869.511665 entropy=0.426969 frames=6476 count=32
2017/08/30 02:22:34 Training policy...
2017/08/30 02:22:39 tune 0: objective=74.434711 reg=0.004270 prune=0
2017/08/30 02:22:40 step 0: objective=74.600901 reg=0.004269
2017/08/30 02:22:42 step 1: objective=74.782225 reg=0.004269
2017/08/30 02:22:43 step 2: objective=74.882079 reg=0.004270
2017/08/30 02:22:44 step 3: objective=75.008498 reg=0.004269
2017/08/30 02:22:46 step 4: objective=75.140736 reg=0.004270
2017/08/30 02:22:47 step 5: objective=75.212790 reg=0.004269
2017/08/30 02:22:48 step 6: objective=75.294699 reg=0.004269
2017/08/30 02:22:50 step 7: objective=75.373253 reg=0.004268
2017/08/30 02:22:50 Training value function...
2017/08/30 02:22:52 step 0: mse=266818.330525 step=0.050000
2017/08/30 02:22:53 step 1: mse=264918.493653 step=0.050000
2017/08/30 02:22:55 step 2: mse=261553.314719 step=0.050000
2017/08/30 02:22:56 step 3: mse=259706.132692 step=0.050000
2017/08/30 02:22:57 step 4: mse=256599.251322 step=0.050000
2017/08/30 02:22:58 step 5: mse=255199.243319 step=0.050000
2017/08/30 02:22:59 step 6: mse=253951.469421 step=0.050000
2017/08/30 02:23:00 step 7: mse=251741.358031 step=0.050000
2017/08/30 02:23:00 Saving...
2017/08/30 02:23:00 Gathering batch of experience...
2017/08/30 02:23:29 batch 558: mean=3919.166667 stddev=6110.142240 entropy=0.419339 frames=5954 count=36
2017/08/30 02:23:29 Training policy...
2017/08/30 02:23:33 tune 0: objective=41.367859 reg=0.004193 prune=0
2017/08/30 02:23:34 step 0: objective=41.539986 reg=0.004193
2017/08/30 02:23:35 step 1: objective=41.644428 reg=0.004192
2017/08/30 02:23:36 step 2: objective=41.804223 reg=0.004192
2017/08/30 02:23:38 step 3: objective=41.896209 reg=0.004191
2017/08/30 02:23:39 step 4: objective=41.966819 reg=0.004192
2017/08/30 02:23:40 step 5: objective=42.058495 reg=0.004193
2017/08/30 02:23:41 step 6: objective=42.140260 reg=0.004192
2017/08/30 02:23:43 step 7: objective=42.170035 reg=0.004193
2017/08/30 02:23:43 Training value function...
2017/08/30 02:23:45 step 0: mse=148388.863711 step=0.050000
2017/08/30 02:23:46 step 1: mse=147501.892813 step=0.050000
2017/08/30 02:23:47 step 2: mse=148482.519154 step=0.050000
2017/08/30 02:23:48 step 3: mse=149978.616977 step=0.050000
2017/08/30 02:23:49 step 4: mse=148771.830481 step=0.050000
2017/08/30 02:23:50 step 5: mse=148160.864268 step=0.050000
2017/08/30 02:23:51 step 6: mse=147656.693938 step=0.050000
2017/08/30 02:23:52 step 7: mse=146867.798371 step=0.050000
2017/08/30 02:23:52 Saving...
2017/08/30 02:23:52 Gathering batch of experience...
2017/08/30 02:24:18 batch 559: mean=4264.242424 stddev=6373.791284 entropy=0.421891 frames=5856 count=33
2017/08/30 02:24:18 Training policy...
2017/08/30 02:24:23 tune 0: objective=43.519833 reg=0.004219 prune=0
2017/08/30 02:24:24 step 0: objective=43.638971 reg=0.004218
2017/08/30 02:24:25 step 1: objective=43.746016 reg=0.004218
2017/08/30 02:24:26 step 2: objective=43.795650 reg=0.004218
2017/08/30 02:24:27 step 3: objective=43.867823 reg=0.004218
2017/08/30 02:24:29 step 4: objective=43.921024 reg=0.004218
2017/08/30 02:24:30 step 5: objective=43.967872 reg=0.004218
2017/08/30 02:24:31 step 6: objective=44.013093 reg=0.004218
2017/08/30 02:24:32 step 7: objective=44.054479 reg=0.004217
2017/08/30 02:24:32 Training value function...
2017/08/30 02:24:35 step 0: mse=139718.745957 step=0.050000
2017/08/30 02:24:35 step 1: mse=140982.784308 step=0.050000
2017/08/30 02:24:36 step 2: mse=141761.949979 step=0.050000
2017/08/30 02:24:37 step 3: mse=140315.937147 step=0.050000
2017/08/30 02:24:38 step 4: mse=140332.246499 step=0.050000
2017/08/30 02:24:39 step 5: mse=139239.725254 step=0.050000
2017/08/30 02:24:40 step 6: mse=139161.249685 step=0.050000
2017/08/30 02:24:41 step 7: mse=138106.280866 step=0.050000
2017/08/30 02:24:41 Saving...
2017/08/30 02:24:41 Gathering batch of experience...
2017/08/30 02:25:13 batch 560: mean=7125.344828 stddev=8463.888090 entropy=0.426194 frames=6696 count=29
2017/08/30 02:25:13 Training policy...
2017/08/30 02:25:17 tune 0: objective=78.050842 reg=0.004262 prune=0
2017/08/30 02:25:19 step 0: objective=78.156423 reg=0.004261
2017/08/30 02:25:20 step 1: objective=78.274716 reg=0.004262
2017/08/30 02:25:22 step 2: objective=78.367524 reg=0.004262
2017/08/30 02:25:23 step 3: objective=78.429295 reg=0.004262
2017/08/30 02:25:24 step 4: objective=78.497349 reg=0.004260
2017/08/30 02:25:26 step 5: objective=78.564348 reg=0.004258
2017/08/30 02:25:27 step 6: objective=78.623889 reg=0.004256
2017/08/30 02:25:29 step 7: objective=78.664492 reg=0.004255
2017/08/30 02:25:29 Training value function...
2017/08/30 02:25:31 step 0: mse=224008.228523 step=0.050000
2017/08/30 02:25:32 step 1: mse=220751.040222 step=0.050000
2017/08/30 02:25:33 step 2: mse=217203.527491 step=0.050000
2017/08/30 02:25:35 step 3: mse=213868.635929 step=0.050000
2017/08/30 02:25:36 step 4: mse=211987.984860 step=0.050000
2017/08/30 02:25:37 step 5: mse=208546.664433 step=0.050000
2017/08/30 02:25:38 step 6: mse=205223.843547 step=0.050000
2017/08/30 02:25:39 step 7: mse=202369.068719 step=0.050000
2017/08/30 02:25:39 Saving...
2017/08/30 02:25:39 Gathering batch of experience...
2017/08/30 02:26:06 batch 561: mean=3401.515152 stddev=4613.003768 entropy=0.413224 frames=5450 count=33
2017/08/30 02:26:06 Training policy...
2017/08/30 02:26:10 tune 0: objective=11.515793 reg=0.004132 prune=0
2017/08/30 02:26:11 step 0: objective=11.772803 reg=0.004128
2017/08/30 02:26:12 step 1: objective=11.841107 reg=0.004128
2017/08/30 02:26:13 step 2: objective=11.929960 reg=0.004127
2017/08/30 02:26:14 step 3: objective=11.996762 reg=0.004127
2017/08/30 02:26:15 step 4: objective=12.049564 reg=0.004127
2017/08/30 02:26:17 step 5: objective=12.092906 reg=0.004126
2017/08/30 02:26:18 step 6: objective=12.132087 reg=0.004125
2017/08/30 02:26:19 step 7: objective=12.206358 reg=0.004125
2017/08/30 02:26:19 Training value function...
2017/08/30 02:26:21 step 0: mse=110139.716635 step=0.050000
2017/08/30 02:26:22 step 1: mse=110097.039923 step=0.050000
2017/08/30 02:26:23 step 2: mse=109732.423487 step=0.050000
2017/08/30 02:26:24 step 3: mse=110045.213487 step=0.050000
2017/08/30 02:26:24 step 4: mse=109966.791253 step=0.050000
2017/08/30 02:26:25 step 5: mse=109827.838040 step=0.050000
2017/08/30 02:26:26 step 6: mse=110042.716822 step=0.050000
2017/08/30 02:26:27 step 7: mse=110634.043528 step=0.050000
2017/08/30 02:26:27 Saving...
2017/08/30 02:26:27 Gathering batch of experience...
2017/08/30 02:26:57 batch 562: mean=4480.312500 stddev=6129.067137 entropy=0.416515 frames=6046 count=32
2017/08/30 02:26:57 Training policy...
2017/08/30 02:27:01 tune 0: objective=48.578275 reg=0.004165 prune=0
2017/08/30 02:27:02 step 0: objective=48.722823 reg=0.004163
2017/08/30 02:27:04 step 1: objective=48.823783 reg=0.004163
2017/08/30 02:27:05 step 2: objective=48.919839 reg=0.004163
2017/08/30 02:27:06 step 3: objective=49.020261 reg=0.004164
2017/08/30 02:27:07 step 4: objective=49.138842 reg=0.004164
2017/08/30 02:27:09 step 5: objective=49.192400 reg=0.004165
2017/08/30 02:27:10 step 6: objective=49.249840 reg=0.004164
2017/08/30 02:27:11 step 7: objective=49.302519 reg=0.004164
2017/08/30 02:27:11 Training value function...
2017/08/30 02:27:14 step 0: mse=214921.194959 step=0.050000
2017/08/30 02:27:15 step 1: mse=214564.473595 step=0.050000
2017/08/30 02:27:16 step 2: mse=213896.047826 step=0.050000
2017/08/30 02:27:17 step 3: mse=212850.377619 step=0.050000
2017/08/30 02:27:18 step 4: mse=210906.215719 step=0.050000
2017/08/30 02:27:19 step 5: mse=209888.827036 step=0.050000
2017/08/30 02:27:19 step 6: mse=209189.170895 step=0.050000
2017/08/30 02:27:20 step 7: mse=208799.913246 step=0.050000
2017/08/30 02:27:20 Saving...
2017/08/30 02:27:20 Gathering batch of experience...
2017/08/30 02:27:51 batch 563: mean=7163.620690 stddev=8428.471852 entropy=0.422259 frames=6937 count=29
2017/08/30 02:27:51 Training policy...
2017/08/30 02:27:56 tune 0: objective=84.615801 reg=0.004223 prune=0
2017/08/30 02:27:57 step 0: objective=84.733206 reg=0.004222
2017/08/30 02:27:59 step 1: objective=84.834484 reg=0.004222
2017/08/30 02:28:00 step 2: objective=84.965169 reg=0.004221
2017/08/30 02:28:02 step 3: objective=85.044246 reg=0.004221
2017/08/30 02:28:03 step 4: objective=85.121450 reg=0.004220
2017/08/30 02:28:05 step 5: objective=85.210682 reg=0.004220
2017/08/30 02:28:06 step 6: objective=85.285651 reg=0.004219
2017/08/30 02:28:08 step 7: objective=85.349304 reg=0.004218
2017/08/30 02:28:08 Training value function...
2017/08/30 02:28:10 step 0: mse=266783.027958 step=0.050000
2017/08/30 02:28:11 step 1: mse=262003.722441 step=0.050000
2017/08/30 02:28:13 step 2: mse=258289.264477 step=0.050000
2017/08/30 02:28:14 step 3: mse=254280.890469 step=0.050000
2017/08/30 02:28:15 step 4: mse=250814.450497 step=0.050000
2017/08/30 02:28:16 step 5: mse=246899.109116 step=0.050000
2017/08/30 02:28:17 step 6: mse=242039.289037 step=0.050000
2017/08/30 02:28:18 step 7: mse=238611.459620 step=0.050000
2017/08/30 02:28:18 Saving...
2017/08/30 02:28:18 Gathering batch of experience...
2017/08/30 02:28:45 batch 564: mean=4444.705882 stddev=6683.217781 entropy=0.415051 frames=5877 count=34
2017/08/30 02:28:45 Training policy...
2017/08/30 02:28:50 tune 0: objective=44.581714 reg=0.004151 prune=0
2017/08/30 02:28:51 step 0: objective=44.677961 reg=0.004148
2017/08/30 02:28:52 step 1: objective=44.770945 reg=0.004148
2017/08/30 02:28:53 step 2: objective=44.830930 reg=0.004148
2017/08/30 02:28:55 step 3: objective=44.897439 reg=0.004147
2017/08/30 02:28:56 step 4: objective=44.967048 reg=0.004146
2017/08/30 02:28:57 step 5: objective=45.060283 reg=0.004145
2017/08/30 02:28:58 step 6: objective=45.114956 reg=0.004143
2017/08/30 02:28:59 step 7: objective=45.184038 reg=0.004143
2017/08/30 02:28:59 Training value function...
2017/08/30 02:29:02 step 0: mse=154251.975542 step=0.050000
2017/08/30 02:29:03 step 1: mse=153576.805803 step=0.050000
2017/08/30 02:29:04 step 2: mse=153186.835077 step=0.050000
2017/08/30 02:29:05 step 3: mse=152437.299393 step=0.050000
2017/08/30 02:29:06 step 4: mse=153804.598426 step=0.050000
2017/08/30 02:29:06 step 5: mse=152914.580939 step=0.050000
2017/08/30 02:29:07 step 6: mse=152581.699408 step=0.050000
2017/08/30 02:29:08 step 7: mse=150661.438540 step=0.050000
2017/08/30 02:29:08 Saving...
2017/08/30 02:29:08 Gathering batch of experience...
2017/08/30 02:29:38 batch 565: mean=7363.333333 stddev=8846.121665 entropy=0.425034 frames=6318 count=27
2017/08/30 02:29:38 Training policy...
2017/08/30 02:29:43 tune 0: objective=79.442600 reg=0.004250 prune=0
2017/08/30 02:29:44 step 0: objective=79.578372 reg=0.004250
2017/08/30 02:29:45 step 1: objective=79.795005 reg=0.004249
2017/08/30 02:29:47 step 2: objective=79.926569 reg=0.004248
2017/08/30 02:29:48 step 3: objective=80.027382 reg=0.004247
2017/08/30 02:29:49 step 4: objective=80.118135 reg=0.004244
2017/08/30 02:29:51 step 5: objective=80.211553 reg=0.004243
2017/08/30 02:29:52 step 6: objective=80.293497 reg=0.004241
2017/08/30 02:29:53 step 7: objective=80.368733 reg=0.004240
2017/08/30 02:29:53 Training value function...
2017/08/30 02:29:56 step 0: mse=218322.852931 step=0.050000
2017/08/30 02:29:57 step 1: mse=215092.624882 step=0.050000
2017/08/30 02:29:58 step 2: mse=211899.663462 step=0.050000
2017/08/30 02:29:59 step 3: mse=209595.182728 step=0.050000
2017/08/30 02:30:00 step 4: mse=206517.316033 step=0.050000
2017/08/30 02:30:01 step 5: mse=204153.448801 step=0.050000
2017/08/30 02:30:02 step 6: mse=202234.513214 step=0.050000
2017/08/30 02:30:03 step 7: mse=199259.180971 step=0.050000
2017/08/30 02:30:03 Saving...
2017/08/30 02:30:03 Gathering batch of experience...
2017/08/30 02:30:35 batch 566: mean=6930.862069 stddev=8056.935015 entropy=0.420685 frames=6848 count=29
2017/08/30 02:30:35 Training policy...
2017/08/30 02:30:40 tune 0: objective=60.282820 reg=0.004207 prune=0
2017/08/30 02:30:41 step 0: objective=60.393473 reg=0.004206
2017/08/30 02:30:43 step 1: objective=60.495738 reg=0.004207
2017/08/30 02:30:44 step 2: objective=60.625817 reg=0.004207
2017/08/30 02:30:45 step 3: objective=60.764763 reg=0.004207
2017/08/30 02:30:47 step 4: objective=60.855793 reg=0.004206
2017/08/30 02:30:48 step 5: objective=60.946672 reg=0.004206
2017/08/30 02:30:50 step 6: objective=61.021535 reg=0.004205
2017/08/30 02:30:51 step 7: objective=61.066132 reg=0.004206
2017/08/30 02:30:51 Training value function...
2017/08/30 02:30:54 step 0: mse=204074.807510 step=0.050000
2017/08/30 02:30:55 step 1: mse=205025.135462 step=0.050000
2017/08/30 02:30:56 step 2: mse=204637.009919 step=0.050000
2017/08/30 02:30:57 step 3: mse=204057.008661 step=0.050000
2017/08/30 02:30:58 step 4: mse=203646.879823 step=0.050000
2017/08/30 02:31:00 step 5: mse=204002.959430 step=0.050000
2017/08/30 02:31:01 step 6: mse=203697.245146 step=0.050000
2017/08/30 02:31:02 step 7: mse=204106.641298 step=0.050000
2017/08/30 02:31:02 Saving...
2017/08/30 02:31:02 Gathering batch of experience...
2017/08/30 02:31:35 batch 567: mean=6589.090909 stddev=7861.042268 entropy=0.421297 frames=7360 count=33
2017/08/30 02:31:35 Training policy...
2017/08/30 02:31:41 tune 0: objective=49.743372 reg=0.004213 prune=0
2017/08/30 02:31:42 step 0: objective=49.937029 reg=0.004212
2017/08/30 02:31:44 step 1: objective=50.128834 reg=0.004212
2017/08/30 02:31:45 step 2: objective=50.217243 reg=0.004212
2017/08/30 02:31:47 step 3: objective=50.296115 reg=0.004212
2017/08/30 02:31:48 step 4: objective=50.359774 reg=0.004212
2017/08/30 02:31:50 step 5: objective=50.434689 reg=0.004213
2017/08/30 02:31:51 step 6: objective=50.496077 reg=0.004213
2017/08/30 02:31:53 step 7: objective=50.578104 reg=0.004212
2017/08/30 02:31:53 Training value function...
2017/08/30 02:31:56 step 0: mse=182129.133442 step=0.050000
2017/08/30 02:31:57 step 1: mse=183913.640181 step=0.050000
2017/08/30 02:31:58 step 2: mse=182236.544742 step=0.050000
2017/08/30 02:32:00 step 3: mse=180308.445431 step=0.050000
2017/08/30 02:32:01 step 4: mse=180109.014595 step=0.050000
2017/08/30 02:32:02 step 5: mse=179695.144110 step=0.050000
2017/08/30 02:32:03 step 6: mse=181404.499586 step=0.050000
2017/08/30 02:32:04 step 7: mse=181334.396525 step=0.050000
2017/08/30 02:32:04 Saving...
2017/08/30 02:32:04 Gathering batch of experience...
2017/08/30 02:32:32 batch 568: mean=5330.806452 stddev=7041.562223 entropy=0.414977 frames=6053 count=31
2017/08/30 02:32:32 Training policy...
2017/08/30 02:32:37 tune 0: objective=43.150284 reg=0.004150 prune=0
2017/08/30 02:32:38 step 0: objective=43.251239 reg=0.004148
2017/08/30 02:32:39 step 1: objective=43.353136 reg=0.004147
2017/08/30 02:32:41 step 2: objective=43.439162 reg=0.004146
2017/08/30 02:32:42 step 3: objective=43.508880 reg=0.004146
2017/08/30 02:32:43 step 4: objective=43.603089 reg=0.004145
2017/08/30 02:32:44 step 5: objective=43.661485 reg=0.004144
2017/08/30 02:32:46 step 6: objective=43.721445 reg=0.004144
2017/08/30 02:32:47 step 7: objective=43.779861 reg=0.004143
2017/08/30 02:32:47 Training value function...
2017/08/30 02:32:49 step 0: mse=167968.449341 step=0.050000
2017/08/30 02:32:50 step 1: mse=166428.383341 step=0.050000
2017/08/30 02:32:51 step 2: mse=166799.857378 step=0.050000
2017/08/30 02:32:52 step 3: mse=167014.898859 step=0.050000
2017/08/30 02:32:53 step 4: mse=167459.943052 step=0.050000
2017/08/30 02:32:54 step 5: mse=167971.441804 step=0.050000
2017/08/30 02:32:55 step 6: mse=169457.371772 step=0.050000
2017/08/30 02:32:56 step 7: mse=169222.856632 step=0.050000
2017/08/30 02:32:56 Saving...
2017/08/30 02:32:56 Gathering batch of experience...
2017/08/30 02:33:25 batch 569: mean=5488.166667 stddev=7620.293792 entropy=0.418777 frames=6055 count=30
2017/08/30 02:33:25 Training policy...
2017/08/30 02:33:29 tune 0: objective=51.650965 reg=0.004188 prune=0
2017/08/30 02:33:31 step 0: objective=51.783913 reg=0.004187
2017/08/30 02:33:32 step 1: objective=51.902890 reg=0.004187
2017/08/30 02:33:33 step 2: objective=51.973013 reg=0.004186
2017/08/30 02:33:35 step 3: objective=52.130543 reg=0.004186
2017/08/30 02:33:36 step 4: objective=52.243611 reg=0.004186
2017/08/30 02:33:37 step 5: objective=52.332065 reg=0.004185
2017/08/30 02:33:38 step 6: objective=52.429516 reg=0.004184
2017/08/30 02:33:40 step 7: objective=52.473767 reg=0.004184
2017/08/30 02:33:40 Training value function...
2017/08/30 02:33:42 step 0: mse=193858.008569 step=0.050000
2017/08/30 02:33:43 step 1: mse=191236.886334 step=0.050000
2017/08/30 02:33:44 step 2: mse=188945.016288 step=0.050000
2017/08/30 02:33:45 step 3: mse=188654.771887 step=0.050000
2017/08/30 02:33:46 step 4: mse=186986.246298 step=0.050000
2017/08/30 02:33:47 step 5: mse=185378.199352 step=0.050000
2017/08/30 02:33:48 step 6: mse=183705.206240 step=0.050000
2017/08/30 02:33:49 step 7: mse=180726.368279 step=0.050000
2017/08/30 02:33:49 Saving...
2017/08/30 02:33:49 Gathering batch of experience...
2017/08/30 02:34:19 batch 570: mean=4084.857143 stddev=6047.738596 entropy=0.413252 frames=6282 count=35
2017/08/30 02:34:19 Training policy...
2017/08/30 02:34:24 tune 0: objective=34.197673 reg=0.004133 prune=0
2017/08/30 02:34:25 step 0: objective=34.292958 reg=0.004132
2017/08/30 02:34:26 step 1: objective=34.392115 reg=0.004130
2017/08/30 02:34:28 step 2: objective=34.482316 reg=0.004131
2017/08/30 02:34:29 step 3: objective=34.608619 reg=0.004131
2017/08/30 02:34:30 step 4: objective=34.678257 reg=0.004131
2017/08/30 02:34:32 step 5: objective=34.743232 reg=0.004130
2017/08/30 02:34:33 step 6: objective=34.806846 reg=0.004130
2017/08/30 02:34:34 step 7: objective=34.868468 reg=0.004130
2017/08/30 02:34:34 Training value function...
2017/08/30 02:34:37 step 0: mse=138973.168580 step=0.050000
2017/08/30 02:34:38 step 1: mse=139440.371628 step=0.050000
2017/08/30 02:34:39 step 2: mse=139185.008207 step=0.050000
2017/08/30 02:34:40 step 3: mse=139024.793427 step=0.050000
2017/08/30 02:34:41 step 4: mse=138599.295664 step=0.050000
2017/08/30 02:34:42 step 5: mse=138637.841265 step=0.050000
2017/08/30 02:34:43 step 6: mse=138560.231890 step=0.050000
2017/08/30 02:34:44 step 7: mse=138878.159839 step=0.050000
2017/08/30 02:34:44 Saving...
2017/08/30 02:34:44 Gathering batch of experience...
2017/08/30 02:35:14 batch 571: mean=4921.969697 stddev=6875.046439 entropy=0.414802 frames=6411 count=33
2017/08/30 02:35:14 Training policy...
2017/08/30 02:35:18 tune 0: objective=51.666277 reg=0.004148 prune=0
2017/08/30 02:35:20 step 0: objective=51.798033 reg=0.004147
2017/08/30 02:35:21 step 1: objective=51.898071 reg=0.004146
2017/08/30 02:35:22 step 2: objective=52.017441 reg=0.004145
2017/08/30 02:35:24 step 3: objective=52.084898 reg=0.004145
2017/08/30 02:35:25 step 4: objective=52.175582 reg=0.004145
2017/08/30 02:35:26 step 5: objective=52.224614 reg=0.004145
2017/08/30 02:35:28 step 6: objective=52.277726 reg=0.004145
2017/08/30 02:35:29 step 7: objective=52.313743 reg=0.004145
2017/08/30 02:35:29 Training value function...
2017/08/30 02:35:31 step 0: mse=179528.362109 step=0.050000
2017/08/30 02:35:32 step 1: mse=178106.747138 step=0.050000
2017/08/30 02:35:33 step 2: mse=177083.980074 step=0.050000
2017/08/30 02:35:35 step 3: mse=176593.268456 step=0.050000
2017/08/30 02:35:36 step 4: mse=175771.349083 step=0.050000
2017/08/30 02:35:37 step 5: mse=174718.914110 step=0.050000
2017/08/30 02:35:38 step 6: mse=174494.253520 step=0.050000
2017/08/30 02:35:39 step 7: mse=174700.443642 step=0.050000
2017/08/30 02:35:39 Saving...
2017/08/30 02:35:39 Gathering batch of experience...
2017/08/30 02:36:06 batch 572: mean=4708.387097 stddev=6250.647371 entropy=0.414084 frames=5862 count=31
2017/08/30 02:36:06 Training policy...
2017/08/30 02:36:10 tune 0: objective=35.655091 reg=0.004141 prune=0
2017/08/30 02:36:12 step 0: objective=35.814648 reg=0.004138
2017/08/30 02:36:13 step 1: objective=35.982059 reg=0.004137
2017/08/30 02:36:14 step 2: objective=36.124952 reg=0.004136
2017/08/30 02:36:15 step 3: objective=36.228090 reg=0.004138
2017/08/30 02:36:16 step 4: objective=36.321232 reg=0.004137
2017/08/30 02:36:18 step 5: objective=36.373441 reg=0.004138
2017/08/30 02:36:19 step 6: objective=36.443319 reg=0.004138
2017/08/30 02:36:20 step 7: objective=36.502759 reg=0.004138
2017/08/30 02:36:20 Training value function...
2017/08/30 02:36:22 step 0: mse=188008.751587 step=0.050000
2017/08/30 02:36:23 step 1: mse=188426.729221 step=0.050000
2017/08/30 02:36:24 step 2: mse=188854.133244 step=0.050000
2017/08/30 02:36:25 step 3: mse=189430.253827 step=0.050000
2017/08/30 02:36:26 step 4: mse=189844.330324 step=0.050000
2017/08/30 02:36:27 step 5: mse=190331.767186 step=0.050000
2017/08/30 02:36:28 step 6: mse=189805.558360 step=0.050000
2017/08/30 02:36:29 step 7: mse=188727.254427 step=0.050000
2017/08/30 02:36:29 Saving...
2017/08/30 02:36:29 Gathering batch of experience...
2017/08/30 02:37:01 batch 573: mean=5893.437500 stddev=7349.946050 entropy=0.413090 frames=6958 count=32
2017/08/30 02:37:01 Training policy...
2017/08/30 02:37:06 tune 0: objective=58.116161 reg=0.004131 prune=0
2017/08/30 02:37:08 step 0: objective=58.240811 reg=0.004130
2017/08/30 02:37:09 step 1: objective=58.398453 reg=0.004131
2017/08/30 02:37:10 step 2: objective=58.526108 reg=0.004133
2017/08/30 02:37:12 step 3: objective=58.598367 reg=0.004133
2017/08/30 02:37:13 step 4: objective=58.693837 reg=0.004133
2017/08/30 02:37:15 step 5: objective=58.765526 reg=0.004133
2017/08/30 02:37:16 step 6: objective=58.814948 reg=0.004134
2017/08/30 02:37:18 step 7: objective=58.886884 reg=0.004133
2017/08/30 02:37:18 Training value function...
2017/08/30 02:37:21 step 0: mse=231302.291910 step=0.050000
2017/08/30 02:37:22 step 1: mse=230640.995075 step=0.050000
2017/08/30 02:37:23 step 2: mse=229326.318259 step=0.050000
2017/08/30 02:37:24 step 3: mse=228313.528206 step=0.050000
2017/08/30 02:37:25 step 4: mse=228098.962972 step=0.050000
2017/08/30 02:37:26 step 5: mse=227398.326848 step=0.050000
2017/08/30 02:37:27 step 6: mse=227742.429191 step=0.050000
2017/08/30 02:37:29 step 7: mse=227814.821187 step=0.050000
2017/08/30 02:37:29 Saving...
2017/08/30 02:37:29 Gathering batch of experience...
2017/08/30 02:37:54 batch 574: mean=5458.571429 stddev=7548.310461 entropy=0.418845 frames=5599 count=28
2017/08/30 02:37:54 Training policy...
2017/08/30 02:37:58 tune 0: objective=59.920717 reg=0.004188 prune=0
2017/08/30 02:37:59 step 0: objective=60.098695 reg=0.004188
2017/08/30 02:38:00 step 1: objective=60.241701 reg=0.004189
2017/08/30 02:38:01 step 2: objective=60.339268 reg=0.004189
2017/08/30 02:38:02 step 3: objective=60.402204 reg=0.004188
2017/08/30 02:38:04 step 4: objective=60.478400 reg=0.004188
2017/08/30 02:38:05 step 5: objective=60.539231 reg=0.004187
2017/08/30 02:38:06 step 6: objective=60.596809 reg=0.004186
2017/08/30 02:38:07 step 7: objective=60.637703 reg=0.004187
2017/08/30 02:38:07 Training value function...
2017/08/30 02:38:09 step 0: mse=202366.222414 step=0.050000
2017/08/30 02:38:10 step 1: mse=202897.987787 step=0.050000
2017/08/30 02:38:11 step 2: mse=200630.957847 step=0.050000
2017/08/30 02:38:12 step 3: mse=200335.061270 step=0.050000
2017/08/30 02:38:13 step 4: mse=200469.136271 step=0.050000
2017/08/30 02:38:14 step 5: mse=201059.946656 step=0.050000
2017/08/30 02:38:15 step 6: mse=201495.543533 step=0.050000
2017/08/30 02:38:16 step 7: mse=200950.892353 step=0.050000
2017/08/30 02:38:16 Saving...
2017/08/30 02:38:16 Gathering batch of experience...
2017/08/30 02:38:45 batch 575: mean=6390.344828 stddev=8337.033493 entropy=0.417515 frames=6218 count=29
2017/08/30 02:38:45 Training policy...
2017/08/30 02:38:50 tune 0: objective=68.808696 reg=0.004175 prune=0
2017/08/30 02:38:51 step 0: objective=68.987602 reg=0.004172
2017/08/30 02:38:52 step 1: objective=69.108495 reg=0.004170
2017/08/30 02:38:54 step 2: objective=69.174579 reg=0.004169
2017/08/30 02:38:55 step 3: objective=69.236451 reg=0.004169
2017/08/30 02:38:56 step 4: objective=69.304087 reg=0.004168
2017/08/30 02:38:58 step 5: objective=69.378025 reg=0.004167
2017/08/30 02:38:59 step 6: objective=69.439887 reg=0.004167
2017/08/30 02:39:00 step 7: objective=69.506895 reg=0.004165
2017/08/30 02:39:00 Training value function...
2017/08/30 02:39:03 step 0: mse=209178.494108 step=0.050000
2017/08/30 02:39:04 step 1: mse=205443.193370 step=0.050000
2017/08/30 02:39:05 step 2: mse=202021.854191 step=0.050000
2017/08/30 02:39:06 step 3: mse=197579.162741 step=0.050000
2017/08/30 02:39:07 step 4: mse=194665.020815 step=0.050000
2017/08/30 02:39:08 step 5: mse=191883.400137 step=0.050000
2017/08/30 02:39:09 step 6: mse=189372.843414 step=0.050000
2017/08/30 02:39:10 step 7: mse=186925.514901 step=0.050000
2017/08/30 02:39:10 Saving...
2017/08/30 02:39:10 Gathering batch of experience...
2017/08/30 02:39:40 batch 576: mean=5028.750000 stddev=6941.492545 entropy=0.411544 frames=6178 count=32
2017/08/30 02:39:40 Training policy...
2017/08/30 02:39:44 tune 0: objective=46.854651 reg=0.004115 prune=0
2017/08/30 02:39:46 step 0: objective=47.015741 reg=0.004114
2017/08/30 02:39:47 step 1: objective=47.142112 reg=0.004114
2017/08/30 02:39:48 step 2: objective=47.222013 reg=0.004113
2017/08/30 02:39:50 step 3: objective=47.328181 reg=0.004112
2017/08/30 02:39:51 step 4: objective=47.403084 reg=0.004112
2017/08/30 02:39:52 step 5: objective=47.481335 reg=0.004112
2017/08/30 02:39:53 step 6: objective=47.540684 reg=0.004110
2017/08/30 02:39:55 step 7: objective=47.635693 reg=0.004110
2017/08/30 02:39:55 Training value function...
2017/08/30 02:39:57 step 0: mse=207082.652497 step=0.050000
2017/08/30 02:39:58 step 1: mse=205835.600876 step=0.050000
2017/08/30 02:39:59 step 2: mse=206100.788577 step=0.050000
2017/08/30 02:40:00 step 3: mse=207390.710474 step=0.050000
2017/08/30 02:40:01 step 4: mse=206994.848892 step=0.050000
2017/08/30 02:40:02 step 5: mse=206623.825437 step=0.050000
2017/08/30 02:40:03 step 6: mse=206915.110826 step=0.050000
2017/08/30 02:40:04 step 7: mse=207232.220674 step=0.050000
2017/08/30 02:40:04 Saving...
2017/08/30 02:40:04 Gathering batch of experience...
2017/08/30 02:40:33 batch 577: mean=5059.531250 stddev=6807.320320 entropy=0.411739 frames=6241 count=32
2017/08/30 02:40:33 Training policy...
2017/08/30 02:40:37 tune 0: objective=38.548938 reg=0.004117 prune=0
2017/08/30 02:40:38 step 0: objective=38.687377 reg=0.004117
2017/08/30 02:40:40 step 1: objective=38.847613 reg=0.004117
2017/08/30 02:40:41 step 2: objective=38.969827 reg=0.004117
2017/08/30 02:40:42 step 3: objective=39.038152 reg=0.004117
2017/08/30 02:40:43 step 4: objective=39.118453 reg=0.004116
2017/08/30 02:40:45 step 5: objective=39.191543 reg=0.004116
2017/08/30 02:40:46 step 6: objective=39.246157 reg=0.004116
2017/08/30 02:40:47 step 7: objective=39.285716 reg=0.004117
2017/08/30 02:40:47 Training value function...
2017/08/30 02:40:50 step 0: mse=177240.321553 step=0.050000
2017/08/30 02:40:51 step 1: mse=177627.792469 step=0.050000
2017/08/30 02:40:52 step 2: mse=178140.576689 step=0.050000
2017/08/30 02:40:53 step 3: mse=178553.114053 step=0.050000
2017/08/30 02:40:54 step 4: mse=177817.211603 step=0.050000
2017/08/30 02:40:55 step 5: mse=178246.311630 step=0.050000
2017/08/30 02:40:56 step 6: mse=177350.472208 step=0.050000
2017/08/30 02:40:57 step 7: mse=177884.154930 step=0.050000
2017/08/30 02:40:57 Saving...
2017/08/30 02:40:57 Gathering batch of experience...
2017/08/30 02:41:26 batch 578: mean=4922.878788 stddev=6779.034864 entropy=0.413989 frames=6246 count=33
2017/08/30 02:41:26 Training policy...
2017/08/30 02:41:31 tune 0: objective=47.810489 reg=0.004140 prune=0
2017/08/30 02:41:32 step 0: objective=47.967954 reg=0.004140
2017/08/30 02:41:34 step 1: objective=48.110166 reg=0.004141
2017/08/30 02:41:35 step 2: objective=48.243621 reg=0.004142
2017/08/30 02:41:36 step 3: objective=48.338617 reg=0.004142
2017/08/30 02:41:37 step 4: objective=48.401572 reg=0.004141
2017/08/30 02:41:39 step 5: objective=48.436975 reg=0.004142
2017/08/30 02:41:40 step 6: objective=48.523750 reg=0.004142
2017/08/30 02:41:41 step 7: objective=48.561019 reg=0.004142
2017/08/30 02:41:41 Training value function...
2017/08/30 02:41:44 step 0: mse=174237.376007 step=0.050000
2017/08/30 02:41:45 step 1: mse=173874.506858 step=0.050000
2017/08/30 02:41:46 step 2: mse=173181.013324 step=0.050000
2017/08/30 02:41:47 step 3: mse=172564.002910 step=0.050000
2017/08/30 02:41:48 step 4: mse=172139.084042 step=0.050000
2017/08/30 02:41:49 step 5: mse=171743.245995 step=0.050000
2017/08/30 02:41:50 step 6: mse=171238.552482 step=0.050000
2017/08/30 02:41:51 step 7: mse=171020.865314 step=0.050000
2017/08/30 02:41:51 Saving...
2017/08/30 02:41:51 Gathering batch of experience...
2017/08/30 02:42:21 batch 579: mean=5117.878788 stddev=6844.917383 entropy=0.410700 frames=6728 count=33
2017/08/30 02:42:21 Training policy...
2017/08/30 02:42:26 tune 0: objective=49.414778 reg=0.004107 prune=0
2017/08/30 02:42:27 step 0: objective=49.558208 reg=0.004107
2017/08/30 02:42:29 step 1: objective=49.686004 reg=0.004108
2017/08/30 02:42:30 step 2: objective=49.846365 reg=0.004109
2017/08/30 02:42:31 step 3: objective=49.951290 reg=0.004110
2017/08/30 02:42:33 step 4: objective=50.046146 reg=0.004109
2017/08/30 02:42:34 step 5: objective=50.104944 reg=0.004110
2017/08/30 02:42:36 step 6: objective=50.165549 reg=0.004110
2017/08/30 02:42:37 step 7: objective=50.224510 reg=0.004109
2017/08/30 02:42:37 Training value function...
2017/08/30 02:42:40 step 0: mse=195284.716299 step=0.050000
2017/08/30 02:42:41 step 1: mse=193428.661137 step=0.050000
2017/08/30 02:42:42 step 2: mse=192687.528639 step=0.050000
2017/08/30 02:42:43 step 3: mse=192515.260588 step=0.050000
2017/08/30 02:42:44 step 4: mse=190073.766885 step=0.050000
2017/08/30 02:42:45 step 5: mse=190328.135385 step=0.050000
2017/08/30 02:42:46 step 6: mse=190435.086305 step=0.050000
2017/08/30 02:42:47 step 7: mse=187401.450323 step=0.050000
2017/08/30 02:42:47 Saving...
2017/08/30 02:42:47 Gathering batch of experience...
2017/08/30 02:43:15 batch 580: mean=5403.333333 stddev=8100.850186 entropy=0.420770 frames=5926 count=33
2017/08/30 02:43:15 Training policy...
2017/08/30 02:43:19 tune 0: objective=72.107946 reg=0.004208 prune=0
2017/08/30 02:43:21 step 0: objective=72.242812 reg=0.004208
2017/08/30 02:43:22 step 1: objective=72.324724 reg=0.004208
2017/08/30 02:43:23 step 2: objective=72.404515 reg=0.004208
2017/08/30 02:43:24 step 3: objective=72.482318 reg=0.004208
2017/08/30 02:43:26 step 4: objective=72.555112 reg=0.004208
2017/08/30 02:43:27 step 5: objective=72.610424 reg=0.004207
2017/08/30 02:43:28 step 6: objective=72.654162 reg=0.004206
2017/08/30 02:43:29 step 7: objective=72.701216 reg=0.004206
2017/08/30 02:43:29 Training value function...
2017/08/30 02:43:32 step 0: mse=242754.553111 step=0.050000
2017/08/30 02:43:33 step 1: mse=237781.065808 step=0.050000
2017/08/30 02:43:34 step 2: mse=236879.158147 step=0.050000
2017/08/30 02:43:35 step 3: mse=232395.141867 step=0.050000
2017/08/30 02:43:36 step 4: mse=230573.309959 step=0.050000
2017/08/30 02:43:37 step 5: mse=228733.640782 step=0.050000
2017/08/30 02:43:38 step 6: mse=228730.945639 step=0.050000
2017/08/30 02:43:38 step 7: mse=226149.082470 step=0.050000
2017/08/30 02:43:38 Saving...
2017/08/30 02:43:39 Gathering batch of experience...
2017/08/30 02:44:07 batch 581: mean=4543.636364 stddev=6925.324658 entropy=0.412587 frames=5813 count=33
2017/08/30 02:44:07 Training policy...
2017/08/30 02:44:11 tune 0: objective=40.183562 reg=0.004126 prune=0
2017/08/30 02:44:13 step 0: objective=40.286631 reg=0.004124
2017/08/30 02:44:14 step 1: objective=40.341167 reg=0.004123
2017/08/30 02:44:15 step 2: objective=40.426294 reg=0.004122
2017/08/30 02:44:16 step 3: objective=40.525992 reg=0.004122
2017/08/30 02:44:17 step 4: objective=40.591436 reg=0.004123
2017/08/30 02:44:19 step 5: objective=40.660258 reg=0.004122
2017/08/30 02:44:20 step 6: objective=40.713207 reg=0.004121
2017/08/30 02:44:21 step 7: objective=40.751976 reg=0.004120
2017/08/30 02:44:21 Training value function...
2017/08/30 02:44:23 step 0: mse=141340.008090 step=0.050000
2017/08/30 02:44:24 step 1: mse=142235.796206 step=0.050000
2017/08/30 02:44:25 step 2: mse=144170.801627 step=0.050000
2017/08/30 02:44:26 step 3: mse=143596.974136 step=0.050000
2017/08/30 02:44:27 step 4: mse=143692.603617 step=0.050000
2017/08/30 02:44:28 step 5: mse=143481.484035 step=0.050000
2017/08/30 02:44:29 step 6: mse=142906.750439 step=0.050000
2017/08/30 02:44:30 step 7: mse=142389.586836 step=0.050000
2017/08/30 02:44:30 Saving...
2017/08/30 02:44:30 Gathering batch of experience...
2017/08/30 02:44:59 batch 582: mean=4429.857143 stddev=6725.041953 entropy=0.414931 frames=6153 count=35
2017/08/30 02:44:59 Training policy...
2017/08/30 02:45:03 tune 0: objective=40.987631 reg=0.004149 prune=0
2017/08/30 02:45:05 step 0: objective=41.035841 reg=0.004149
2017/08/30 02:45:06 step 1: objective=41.091911 reg=0.004149
2017/08/30 02:45:07 step 2: objective=41.139256 reg=0.004149
2017/08/30 02:45:09 step 3: objective=41.173632 reg=0.004149
2017/08/30 02:45:10 step 4: objective=41.232953 reg=0.004149
2017/08/30 02:45:11 step 5: objective=41.277804 reg=0.004149
2017/08/30 02:45:12 step 6: objective=41.311652 reg=0.004149
2017/08/30 02:45:14 step 7: objective=41.355215 reg=0.004149
2017/08/30 02:45:14 Training value function...
2017/08/30 02:45:16 step 0: mse=125587.820774 step=0.050000
2017/08/30 02:45:17 step 1: mse=127294.743376 step=0.050000
2017/08/30 02:45:18 step 2: mse=125977.574401 step=0.050000
2017/08/30 02:45:19 step 3: mse=125066.098826 step=0.050000
2017/08/30 02:45:20 step 4: mse=125941.610811 step=0.050000
2017/08/30 02:45:21 step 5: mse=127036.206906 step=0.050000
2017/08/30 02:45:22 step 6: mse=128274.508644 step=0.050000
2017/08/30 02:45:23 step 7: mse=129345.125531 step=0.050000
2017/08/30 02:45:23 Saving...
2017/08/30 02:45:23 Gathering batch of experience...
2017/08/30 02:45:57 batch 583: mean=8569.464286 stddev=9152.008205 entropy=0.420617 frames=7317 count=28
2017/08/30 02:45:57 Training policy...
2017/08/30 02:46:02 tune 0: objective=88.733942 reg=0.004206 prune=0
2017/08/30 02:46:04 step 0: objective=88.808169 reg=0.004204
2017/08/30 02:46:05 step 1: objective=88.888769 reg=0.004203
2017/08/30 02:46:07 step 2: objective=88.956582 reg=0.004201
2017/08/30 02:46:08 step 3: objective=89.025019 reg=0.004200
2017/08/30 02:46:10 step 4: objective=89.101476 reg=0.004199
2017/08/30 02:46:12 step 5: objective=89.155383 reg=0.004198
2017/08/30 02:46:13 step 6: objective=89.189610 reg=0.004197
2017/08/30 02:46:15 step 7: objective=89.249428 reg=0.004196
2017/08/30 02:46:15 Training value function...
2017/08/30 02:46:18 step 0: mse=253437.438488 step=0.050000
2017/08/30 02:46:19 step 1: mse=248250.037816 step=0.050000
2017/08/30 02:46:20 step 2: mse=244094.185242 step=0.050000
2017/08/30 02:46:21 step 3: mse=241541.254254 step=0.050000
2017/08/30 02:46:22 step 4: mse=236023.431995 step=0.050000
2017/08/30 02:46:24 step 5: mse=231881.818271 step=0.050000
2017/08/30 02:46:25 step 6: mse=229918.881212 step=0.050000
2017/08/30 02:46:26 step 7: mse=226831.816430 step=0.050000
2017/08/30 02:46:26 Saving...
2017/08/30 02:46:26 Gathering batch of experience...
2017/08/30 02:46:55 batch 584: mean=4622.702703 stddev=7233.415476 entropy=0.413986 frames=6433 count=37
2017/08/30 02:46:55 Training policy...
2017/08/30 02:47:00 tune 0: objective=48.579682 reg=0.004140 prune=0
2017/08/30 02:47:01 step 0: objective=48.647113 reg=0.004139
2017/08/30 02:47:03 step 1: objective=48.709341 reg=0.004139
2017/08/30 02:47:04 step 2: objective=48.766929 reg=0.004140
2017/08/30 02:47:05 step 3: objective=48.815084 reg=0.004140
2017/08/30 02:47:07 step 4: objective=48.864862 reg=0.004139
2017/08/30 02:47:08 step 5: objective=48.915966 reg=0.004139
2017/08/30 02:47:09 step 6: objective=48.967565 reg=0.004139
2017/08/30 02:47:11 step 7: objective=49.025634 reg=0.004139
2017/08/30 02:47:11 Training value function...
2017/08/30 02:47:13 step 0: mse=186722.448493 step=0.050000
2017/08/30 02:47:14 step 1: mse=185856.485083 step=0.050000
2017/08/30 02:47:15 step 2: mse=184801.126452 step=0.050000
2017/08/30 02:47:16 step 3: mse=184216.349211 step=0.050000
2017/08/30 02:47:17 step 4: mse=183770.253944 step=0.050000
2017/08/30 02:47:18 step 5: mse=182960.688878 step=0.050000
2017/08/30 02:47:20 step 6: mse=181334.559108 step=0.050000
2017/08/30 02:47:21 step 7: mse=182043.006912 step=0.050000
2017/08/30 02:47:21 Saving...
2017/08/30 02:47:21 Gathering batch of experience...
2017/08/30 02:47:51 batch 585: mean=4906.428571 stddev=7157.434154 entropy=0.413038 frames=6502 count=35
2017/08/30 02:47:51 Training policy...
2017/08/30 02:47:55 tune 0: objective=49.853665 reg=0.004130 prune=0
2017/08/30 02:47:57 step 0: objective=49.989325 reg=0.004130
2017/08/30 02:47:58 step 1: objective=50.131022 reg=0.004130
2017/08/30 02:48:00 step 2: objective=50.347028 reg=0.004128
2017/08/30 02:48:01 step 3: objective=50.533783 reg=0.004129
2017/08/30 02:48:02 step 4: objective=50.674422 reg=0.004126
2017/08/30 02:48:04 step 5: objective=50.764356 reg=0.004125
2017/08/30 02:48:05 step 6: objective=50.828534 reg=0.004125
2017/08/30 02:48:06 step 7: objective=50.900223 reg=0.004124
2017/08/30 02:48:06 Training value function...
2017/08/30 02:48:09 step 0: mse=256142.243917 step=0.050000
2017/08/30 02:48:10 step 1: mse=255810.577509 step=0.050000
2017/08/30 02:48:11 step 2: mse=254090.732730 step=0.050000
2017/08/30 02:48:12 step 3: mse=253023.661558 step=0.050000
2017/08/30 02:48:13 step 4: mse=251227.363669 step=0.050000
2017/08/30 02:48:14 step 5: mse=250188.021220 step=0.050000
2017/08/30 02:48:15 step 6: mse=250223.927510 step=0.050000
2017/08/30 02:48:16 step 7: mse=250720.260437 step=0.050000
2017/08/30 02:48:16 Saving...
2017/08/30 02:48:16 Gathering batch of experience...
2017/08/30 02:48:47 batch 586: mean=6750.172414 stddev=7975.921359 entropy=0.413053 frames=6611 count=29
2017/08/30 02:48:47 Training policy...
2017/08/30 02:48:52 tune 0: objective=47.537877 reg=0.004131 prune=0
2017/08/30 02:48:53 step 0: objective=47.712293 reg=0.004129
2017/08/30 02:48:55 step 1: objective=47.862492 reg=0.004129
2017/08/30 02:48:56 step 2: objective=48.010442 reg=0.004128
2017/08/30 02:48:58 step 3: objective=48.145014 reg=0.004128
2017/08/30 02:48:59 step 4: objective=48.236018 reg=0.004129
2017/08/30 02:49:00 step 5: objective=48.310070 reg=0.004129
2017/08/30 02:49:02 step 6: objective=48.364610 reg=0.004129
2017/08/30 02:49:03 step 7: objective=48.416110 reg=0.004130
2017/08/30 02:49:03 Training value function...
2017/08/30 02:49:06 step 0: mse=191948.237022 step=0.050000
2017/08/30 02:49:07 step 1: mse=191274.375826 step=0.050000
2017/08/30 02:49:08 step 2: mse=190285.789059 step=0.050000
2017/08/30 02:49:09 step 3: mse=189547.923469 step=0.050000
2017/08/30 02:49:10 step 4: mse=188810.482238 step=0.050000
2017/08/30 02:49:11 step 5: mse=187846.272261 step=0.050000
2017/08/30 02:49:12 step 6: mse=187205.192964 step=0.050000
2017/08/30 02:49:13 step 7: mse=189197.291345 step=0.050000
2017/08/30 02:49:13 Saving...
2017/08/30 02:49:13 Gathering batch of experience...
2017/08/30 02:49:43 batch 587: mean=4428.000000 stddev=6780.070080 entropy=0.412484 frames=6168 count=35
2017/08/30 02:49:43 Training policy...
2017/08/30 02:49:47 tune 0: objective=40.472682 reg=0.004125 prune=0
2017/08/30 02:49:49 step 0: objective=40.582794 reg=0.004124
2017/08/30 02:49:50 step 1: objective=40.669423 reg=0.004124
2017/08/30 02:49:51 step 2: objective=40.745453 reg=0.004123
2017/08/30 02:49:53 step 3: objective=40.828140 reg=0.004123
2017/08/30 02:49:54 step 4: objective=40.917852 reg=0.004123
2017/08/30 02:49:55 step 5: objective=40.995901 reg=0.004122
2017/08/30 02:49:56 step 6: objective=41.060332 reg=0.004122
2017/08/30 02:49:58 step 7: objective=41.118854 reg=0.004122
2017/08/30 02:49:58 Training value function...
2017/08/30 02:50:00 step 0: mse=171503.989431 step=0.050000
2017/08/30 02:50:01 step 1: mse=171302.176057 step=0.050000
2017/08/30 02:50:02 step 2: mse=168543.160685 step=0.050000
2017/08/30 02:50:03 step 3: mse=167874.548217 step=0.050000
2017/08/30 02:50:04 step 4: mse=168510.535977 step=0.050000
2017/08/30 02:50:05 step 5: mse=167147.835166 step=0.050000
2017/08/30 02:50:06 step 6: mse=165426.785684 step=0.050000
2017/08/30 02:50:07 step 7: mse=163641.842375 step=0.050000
2017/08/30 02:50:07 Saving...
2017/08/30 02:50:07 Gathering batch of experience...
2017/08/30 02:50:35 batch 588: mean=4208.676471 stddev=6195.137361 entropy=0.407056 frames=6050 count=34
2017/08/30 02:50:35 Training policy...
2017/08/30 02:50:39 tune 0: objective=32.433412 reg=0.004071 prune=0
2017/08/30 02:50:41 step 0: objective=32.602275 reg=0.004068
2017/08/30 02:50:42 step 1: objective=32.692552 reg=0.004068
2017/08/30 02:50:43 step 2: objective=32.749375 reg=0.004069
2017/08/30 02:50:44 step 3: objective=32.818042 reg=0.004067
2017/08/30 02:50:46 step 4: objective=32.891710 reg=0.004067
2017/08/30 02:50:47 step 5: objective=32.922665 reg=0.004067
2017/08/30 02:50:48 step 6: objective=32.978110 reg=0.004067
2017/08/30 02:50:49 step 7: objective=33.019016 reg=0.004066
2017/08/30 02:50:49 Training value function...
2017/08/30 02:50:52 step 0: mse=123481.353813 step=0.050000
2017/08/30 02:50:53 step 1: mse=123338.325078 step=0.050000
2017/08/30 02:50:54 step 2: mse=123051.686842 step=0.050000
2017/08/30 02:50:55 step 3: mse=124784.505097 step=0.050000
2017/08/30 02:50:56 step 4: mse=125070.457058 step=0.050000
2017/08/30 02:50:57 step 5: mse=125156.449594 step=0.050000
2017/08/30 02:50:58 step 6: mse=124169.343454 step=0.050000
2017/08/30 02:50:59 step 7: mse=123768.941435 step=0.050000
2017/08/30 02:50:59 Saving...
2017/08/30 02:50:59 Gathering batch of experience...
2017/08/30 02:51:27 batch 589: mean=7996.600000 stddev=8859.016279 entropy=0.417425 frames=6335 count=25
2017/08/30 02:51:27 Training policy...
2017/08/30 02:51:32 tune 0: objective=82.157942 reg=0.004174 prune=0
2017/08/30 02:51:33 step 0: objective=82.248140 reg=0.004173
2017/08/30 02:51:35 step 1: objective=82.327614 reg=0.004173
2017/08/30 02:51:36 step 2: objective=82.415889 reg=0.004173
2017/08/30 02:51:37 step 3: objective=82.484057 reg=0.004172
2017/08/30 02:51:39 step 4: objective=82.544189 reg=0.004172
2017/08/30 02:51:40 step 5: objective=82.610833 reg=0.004172
2017/08/30 02:51:41 step 6: objective=82.703369 reg=0.004172
2017/08/30 02:51:43 step 7: objective=82.773865 reg=0.004172
2017/08/30 02:51:43 Training value function...
2017/08/30 02:51:45 step 0: mse=275861.398043 step=0.050000
2017/08/30 02:51:46 step 1: mse=271865.867971 step=0.050000
2017/08/30 02:51:47 step 2: mse=268529.503832 step=0.050000
2017/08/30 02:51:48 step 3: mse=263278.527191 step=0.050000
2017/08/30 02:51:49 step 4: mse=261670.182382 step=0.050000
2017/08/30 02:51:50 step 5: mse=261194.860066 step=0.050000
2017/08/30 02:51:51 step 6: mse=260568.247582 step=0.050000
2017/08/30 02:51:52 step 7: mse=256603.179031 step=0.050000
2017/08/30 02:51:52 Saving...
2017/08/30 02:51:52 Gathering batch of experience...
2017/08/30 02:52:21 batch 590: mean=3849.264706 stddev=5534.079860 entropy=0.405269 frames=5979 count=34
2017/08/30 02:52:21 Training policy...
2017/08/30 02:52:26 tune 0: objective=24.229344 reg=0.004053 prune=0
2017/08/30 02:52:27 step 0: objective=24.371577 reg=0.004051
2017/08/30 02:52:28 step 1: objective=24.512826 reg=0.004049
2017/08/30 02:52:30 step 2: objective=24.569710 reg=0.004049
2017/08/30 02:52:31 step 3: objective=24.610311 reg=0.004049
2017/08/30 02:52:32 step 4: objective=24.670145 reg=0.004048
2017/08/30 02:52:33 step 5: objective=24.702647 reg=0.004049
2017/08/30 02:52:35 step 6: objective=24.733361 reg=0.004049
2017/08/30 02:52:36 step 7: objective=24.765732 reg=0.004049
2017/08/30 02:52:36 Training value function...
2017/08/30 02:52:38 step 0: mse=118473.024640 step=0.050000
2017/08/30 02:52:39 step 1: mse=118851.723579 step=0.050000
2017/08/30 02:52:40 step 2: mse=118557.820205 step=0.050000
2017/08/30 02:52:41 step 3: mse=118958.605711 step=0.050000
2017/08/30 02:52:42 step 4: mse=118588.706692 step=0.050000
2017/08/30 02:52:43 step 5: mse=119056.384247 step=0.050000
2017/08/30 02:52:44 step 6: mse=119565.973666 step=0.050000
2017/08/30 02:52:45 step 7: mse=119206.950418 step=0.050000
2017/08/30 02:52:45 Saving...
2017/08/30 02:52:45 Gathering batch of experience...
2017/08/30 02:53:14 batch 591: mean=3811.470588 stddev=5608.917602 entropy=0.402748 frames=5898 count=34
2017/08/30 02:53:14 Training policy...
2017/08/30 02:53:18 tune 0: objective=33.343946 reg=0.004027 prune=0
2017/08/30 02:53:19 step 0: objective=33.451885 reg=0.004026
2017/08/30 02:53:20 step 1: objective=33.581958 reg=0.004026
2017/08/30 02:53:22 step 2: objective=33.643987 reg=0.004024
2017/08/30 02:53:23 step 3: objective=33.732184 reg=0.004024
2017/08/30 02:53:24 step 4: objective=33.779478 reg=0.004024
2017/08/30 02:53:25 step 5: objective=33.819184 reg=0.004025
2017/08/30 02:53:27 step 6: objective=33.852466 reg=0.004025
2017/08/30 02:53:28 step 7: objective=33.892246 reg=0.004025
2017/08/30 02:53:28 Training value function...
2017/08/30 02:53:30 step 0: mse=119012.755157 step=0.050000
2017/08/30 02:53:31 step 1: mse=119523.353543 step=0.050000
2017/08/30 02:53:32 step 2: mse=119744.765591 step=0.050000
2017/08/30 02:53:33 step 3: mse=119936.657477 step=0.050000
2017/08/30 02:53:34 step 4: mse=121031.385059 step=0.050000
2017/08/30 02:53:35 step 5: mse=121343.346622 step=0.050000
2017/08/30 02:53:36 step 6: mse=121558.793421 step=0.050000
2017/08/30 02:53:37 step 7: mse=122139.549408 step=0.050000
2017/08/30 02:53:37 Saving...
2017/08/30 02:53:37 Gathering batch of experience...
2017/08/30 02:54:08 batch 592: mean=6589.500000 stddev=7931.098216 entropy=0.413337 frames=6524 count=30
2017/08/30 02:54:08 Training policy...
2017/08/30 02:54:13 tune 0: objective=67.814464 reg=0.004133 prune=0
2017/08/30 02:54:14 step 0: objective=68.015117 reg=0.004129
2017/08/30 02:54:15 step 1: objective=68.155393 reg=0.004128
2017/08/30 02:54:17 step 2: objective=68.252414 reg=0.004129
2017/08/30 02:54:18 step 3: objective=68.337216 reg=0.004129
2017/08/30 02:54:20 step 4: objective=68.400119 reg=0.004129
2017/08/30 02:54:21 step 5: objective=68.445633 reg=0.004128
2017/08/30 02:54:22 step 6: objective=68.484346 reg=0.004128
2017/08/30 02:54:24 step 7: objective=68.546664 reg=0.004128
2017/08/30 02:54:24 Training value function...
2017/08/30 02:54:26 step 0: mse=266762.139104 step=0.050000
2017/08/30 02:54:27 step 1: mse=265063.824947 step=0.050000
2017/08/30 02:54:29 step 2: mse=263893.411787 step=0.050000
2017/08/30 02:54:30 step 3: mse=262308.187837 step=0.050000
2017/08/30 02:54:31 step 4: mse=262002.722576 step=0.050000
2017/08/30 02:54:32 step 5: mse=261224.081119 step=0.050000
2017/08/30 02:54:33 step 6: mse=259364.935199 step=0.050000
2017/08/30 02:54:34 step 7: mse=257985.696143 step=0.050000
2017/08/30 02:54:34 Saving...
2017/08/30 02:54:34 Gathering batch of experience...
2017/08/30 02:55:04 batch 593: mean=5925.645161 stddev=8010.662425 entropy=0.414040 frames=6322 count=31
2017/08/30 02:55:04 Training policy...
2017/08/30 02:55:09 tune 0: objective=62.899873 reg=0.004140 prune=0
2017/08/30 02:55:10 step 0: objective=63.028650 reg=0.004142
2017/08/30 02:55:11 step 1: objective=63.117699 reg=0.004141
2017/08/30 02:55:13 step 2: objective=63.201059 reg=0.004141
2017/08/30 02:55:14 step 3: objective=63.298417 reg=0.004142
2017/08/30 02:55:15 step 4: objective=63.370245 reg=0.004143
2017/08/30 02:55:17 step 5: objective=63.462457 reg=0.004143
2017/08/30 02:55:18 step 6: objective=63.545565 reg=0.004143
2017/08/30 02:55:19 step 7: objective=63.624407 reg=0.004142
2017/08/30 02:55:19 Training value function...
2017/08/30 02:55:22 step 0: mse=231040.187473 step=0.050000
2017/08/30 02:55:23 step 1: mse=227986.948358 step=0.050000
2017/08/30 02:55:24 step 2: mse=225294.020888 step=0.050000
2017/08/30 02:55:25 step 3: mse=222866.525759 step=0.050000
2017/08/30 02:55:26 step 4: mse=220590.017071 step=0.050000
2017/08/30 02:55:27 step 5: mse=218290.633794 step=0.050000
2017/08/30 02:55:28 step 6: mse=218732.645682 step=0.050000
2017/08/30 02:55:29 step 7: mse=216648.802242 step=0.050000
2017/08/30 02:55:29 Saving...
2017/08/30 02:55:29 Gathering batch of experience...
2017/08/30 02:55:58 batch 594: mean=5339.193548 stddev=7665.462351 entropy=0.412062 frames=6082 count=31
2017/08/30 02:55:58 Training policy...
2017/08/30 02:56:02 tune 0: objective=51.635795 reg=0.004121 prune=0
2017/08/30 02:56:03 step 0: objective=51.712194 reg=0.004120
2017/08/30 02:56:04 step 1: objective=51.768184 reg=0.004119
2017/08/30 02:56:06 step 2: objective=51.824235 reg=0.004119
2017/08/30 02:56:07 step 3: objective=51.869749 reg=0.004119
2017/08/30 02:56:08 step 4: objective=51.924197 reg=0.004119
2017/08/30 02:56:10 step 5: objective=51.978985 reg=0.004118
2017/08/30 02:56:11 step 6: objective=52.026549 reg=0.004118
2017/08/30 02:56:12 step 7: objective=52.060974 reg=0.004118
2017/08/30 02:56:12 Training value function...
2017/08/30 02:56:15 step 0: mse=145317.239952 step=0.050000
2017/08/30 02:56:16 step 1: mse=143679.802664 step=0.050000
2017/08/30 02:56:17 step 2: mse=144751.651980 step=0.050000
2017/08/30 02:56:18 step 3: mse=144050.015701 step=0.050000
2017/08/30 02:56:19 step 4: mse=142628.724819 step=0.050000
2017/08/30 02:56:20 step 5: mse=141168.463361 step=0.050000
2017/08/30 02:56:21 step 6: mse=141860.974096 step=0.050000
2017/08/30 02:56:22 step 7: mse=143217.966946 step=0.050000
2017/08/30 02:56:22 Saving...
2017/08/30 02:56:22 Gathering batch of experience...
2017/08/30 02:56:52 batch 595: mean=5214.843750 stddev=7546.221683 entropy=0.413594 frames=6151 count=32
2017/08/30 02:56:52 Training policy...
2017/08/30 02:56:57 tune 0: objective=54.698123 reg=0.004136 prune=0
2017/08/30 02:56:58 step 0: objective=54.748456 reg=0.004136
2017/08/30 02:56:59 step 1: objective=54.785812 reg=0.004135
2017/08/30 02:57:00 step 2: objective=54.827960 reg=0.004135
2017/08/30 02:57:02 step 3: objective=54.868827 reg=0.004134
2017/08/30 02:57:03 step 4: objective=54.909522 reg=0.004134
2017/08/30 02:57:04 step 5: objective=54.959001 reg=0.004134
2017/08/30 02:57:06 step 6: objective=54.994381 reg=0.004134
2017/08/30 02:57:07 step 7: objective=55.023924 reg=0.004134
2017/08/30 02:57:07 Training value function...
2017/08/30 02:57:09 step 0: mse=148175.556197 step=0.050000
2017/08/30 02:57:10 step 1: mse=146887.666574 step=0.050000
2017/08/30 02:57:11 step 2: mse=148232.674150 step=0.050000
2017/08/30 02:57:12 step 3: mse=146866.992850 step=0.050000
2017/08/30 02:57:13 step 4: mse=145884.518936 step=0.050000
2017/08/30 02:57:14 step 5: mse=144877.505197 step=0.050000
2017/08/30 02:57:15 step 6: mse=143493.214771 step=0.050000
2017/08/30 02:57:16 step 7: mse=141741.915003 step=0.050000
2017/08/30 02:57:16 Saving...
2017/08/30 02:57:16 Gathering batch of experience...
2017/08/30 02:57:52 batch 596: mean=6960.588235 stddev=8447.360949 entropy=0.413461 frames=7788 count=34
2017/08/30 02:57:52 Training policy...
2017/08/30 02:57:58 tune 0: objective=68.134101 reg=0.004135 prune=0
2017/08/30 02:57:59 step 0: objective=68.274589 reg=0.004133
2017/08/30 02:58:01 step 1: objective=68.470756 reg=0.004134
2017/08/30 02:58:03 step 2: objective=68.540054 reg=0.004134
2017/08/30 02:58:04 step 3: objective=68.614383 reg=0.004134
2017/08/30 02:58:06 step 4: objective=68.721053 reg=0.004134
2017/08/30 02:58:08 step 5: objective=68.815068 reg=0.004134
2017/08/30 02:58:09 step 6: objective=68.909171 reg=0.004133
2017/08/30 02:58:11 step 7: objective=68.953149 reg=0.004133
2017/08/30 02:58:11 Training value function...
2017/08/30 02:58:14 step 0: mse=224834.137218 step=0.050000
2017/08/30 02:58:15 step 1: mse=222735.944903 step=0.050000
2017/08/30 02:58:17 step 2: mse=221733.275797 step=0.050000
2017/08/30 02:58:18 step 3: mse=220024.787055 step=0.050000
2017/08/30 02:58:19 step 4: mse=218017.814924 step=0.050000
2017/08/30 02:58:21 step 5: mse=218794.526400 step=0.050000
2017/08/30 02:58:22 step 6: mse=217548.344970 step=0.050000
2017/08/30 02:58:23 step 7: mse=216210.151285 step=0.050000
2017/08/30 02:58:23 Saving...
2017/08/30 02:58:23 Gathering batch of experience...
2017/08/30 02:58:52 batch 597: mean=7150.925926 stddev=8457.169656 entropy=0.410666 frames=6250 count=27
2017/08/30 02:58:52 Training policy...
2017/08/30 02:58:56 tune 0: objective=63.150520 reg=0.004107 prune=0
2017/08/30 02:58:58 step 0: objective=63.257520 reg=0.004107
2017/08/30 02:58:59 step 1: objective=63.366705 reg=0.004106
2017/08/30 02:59:00 step 2: objective=63.498275 reg=0.004106
2017/08/30 02:59:02 step 3: objective=63.610680 reg=0.004106
2017/08/30 02:59:03 step 4: objective=63.711615 reg=0.004107
2017/08/30 02:59:04 step 5: objective=63.778460 reg=0.004107
2017/08/30 02:59:06 step 6: objective=63.858755 reg=0.004106
2017/08/30 02:59:07 step 7: objective=63.900660 reg=0.004105
2017/08/30 02:59:07 Training value function...
2017/08/30 02:59:09 step 0: mse=197179.847317 step=0.050000
2017/08/30 02:59:11 step 1: mse=196398.575258 step=0.050000
2017/08/30 02:59:12 step 2: mse=196097.368192 step=0.050000
2017/08/30 02:59:13 step 3: mse=195206.538310 step=0.050000
2017/08/30 02:59:14 step 4: mse=194706.325386 step=0.050000
2017/08/30 02:59:15 step 5: mse=195574.193945 step=0.050000
2017/08/30 02:59:16 step 6: mse=194955.394772 step=0.050000
2017/08/30 02:59:17 step 7: mse=193495.462882 step=0.050000
2017/08/30 02:59:17 Saving...
2017/08/30 02:59:17 Gathering batch of experience...
2017/08/30 02:59:44 batch 598: mean=7586.250000 stddev=8539.253267 entropy=0.410711 frames=5763 count=24
2017/08/30 02:59:44 Training policy...
2017/08/30 02:59:48 tune 0: objective=63.694533 reg=0.004107 prune=0
2017/08/30 02:59:50 step 0: objective=63.886778 reg=0.004104
2017/08/30 02:59:51 step 1: objective=64.048212 reg=0.004103
2017/08/30 02:59:52 step 2: objective=64.157790 reg=0.004103
2017/08/30 02:59:53 step 3: objective=64.241497 reg=0.004103
2017/08/30 02:59:55 step 4: objective=64.350300 reg=0.004102
2017/08/30 02:59:56 step 5: objective=64.417984 reg=0.004102
2017/08/30 02:59:57 step 6: objective=64.481390 reg=0.004101
2017/08/30 02:59:58 step 7: objective=64.538299 reg=0.004102
2017/08/30 02:59:58 Training value function...
2017/08/30 03:00:01 step 0: mse=185043.328600 step=0.050000
2017/08/30 03:00:02 step 1: mse=184347.851161 step=0.050000
2017/08/30 03:00:02 step 2: mse=183745.212580 step=0.050000
2017/08/30 03:00:03 step 3: mse=184117.704859 step=0.050000
2017/08/30 03:00:04 step 4: mse=185005.020326 step=0.050000
2017/08/30 03:00:05 step 5: mse=185282.067875 step=0.050000
2017/08/30 03:00:06 step 6: mse=184377.221549 step=0.050000
2017/08/30 03:00:07 step 7: mse=184228.105389 step=0.050000
2017/08/30 03:00:07 Saving...
2017/08/30 03:00:07 Gathering batch of experience...
2017/08/30 03:00:38 batch 599: mean=5641.093750 stddev=8021.327015 entropy=0.411703 frames=6130 count=32
2017/08/30 03:00:38 Training policy...
2017/08/30 03:00:42 tune 0: objective=51.366267 reg=0.004117 prune=0
2017/08/30 03:00:43 step 0: objective=51.419020 reg=0.004116
2017/08/30 03:00:45 step 1: objective=51.466741 reg=0.004115
2017/08/30 03:00:46 step 2: objective=51.525122 reg=0.004115
2017/08/30 03:00:47 step 3: objective=51.582688 reg=0.004114
2017/08/30 03:00:49 step 4: objective=51.636659 reg=0.004114
2017/08/30 03:00:50 step 5: objective=51.660762 reg=0.004114
2017/08/30 03:00:51 step 6: objective=51.712393 reg=0.004114
2017/08/30 03:00:52 step 7: objective=51.760920 reg=0.004113
2017/08/30 03:00:52 Training value function...
2017/08/30 03:00:55 step 0: mse=150936.144580 step=0.050000
2017/08/30 03:00:56 step 1: mse=149321.624580 step=0.050000
2017/08/30 03:00:57 step 2: mse=148903.505973 step=0.050000
2017/08/30 03:00:58 step 3: mse=150190.027500 step=0.050000
2017/08/30 03:00:59 step 4: mse=149367.517032 step=0.050000
2017/08/30 03:01:00 step 5: mse=150795.297111 step=0.050000
2017/08/30 03:01:01 step 6: mse=150298.652958 step=0.050000
2017/08/30 03:01:02 step 7: mse=149225.017772 step=0.050000
2017/08/30 03:01:02 Saving...
2017/08/30 03:01:02 Gathering batch of experience...
2017/08/30 03:01:32 batch 600: mean=7887.678571 stddev=9185.391496 entropy=0.413437 frames=6809 count=28
2017/08/30 03:01:32 Training policy...
2017/08/30 03:01:37 tune 0: objective=75.137474 reg=0.004134 prune=0
2017/08/30 03:01:39 step 0: objective=75.215198 reg=0.004134
2017/08/30 03:01:40 step 1: objective=75.307846 reg=0.004133
2017/08/30 03:01:41 step 2: objective=75.389540 reg=0.004133
2017/08/30 03:01:43 step 3: objective=75.470329 reg=0.004132
2017/08/30 03:01:44 step 4: objective=75.545349 reg=0.004131
2017/08/30 03:01:46 step 5: objective=75.606858 reg=0.004130
2017/08/30 03:01:47 step 6: objective=75.652803 reg=0.004129
2017/08/30 03:01:49 step 7: objective=75.712426 reg=0.004129
2017/08/30 03:01:49 Training value function...
2017/08/30 03:01:52 step 0: mse=187850.738283 step=0.050000
2017/08/30 03:01:53 step 1: mse=186121.283144 step=0.050000
2017/08/30 03:01:54 step 2: mse=184531.694274 step=0.050000
2017/08/30 03:01:55 step 3: mse=180177.200042 step=0.050000
2017/08/30 03:01:56 step 4: mse=177548.328890 step=0.050000
2017/08/30 03:01:57 step 5: mse=175306.838098 step=0.050000
2017/08/30 03:01:58 step 6: mse=171950.596901 step=0.050000
2017/08/30 03:01:59 step 7: mse=169947.406297 step=0.050000
2017/08/30 03:01:59 Saving...
2017/08/30 03:01:59 Gathering batch of experience...
2017/08/30 03:02:31 batch 601: mean=10491.304348 stddev=9181.789422 entropy=0.411296 frames=6996 count=23
2017/08/30 03:02:31 Training policy...
2017/08/30 03:02:36 tune 0: objective=73.504132 reg=0.004113 prune=0
2017/08/30 03:02:38 step 0: objective=73.630132 reg=0.004111
2017/08/30 03:02:39 step 1: objective=73.786583 reg=0.004110
2017/08/30 03:02:40 step 2: objective=73.891970 reg=0.004110
2017/08/30 03:02:42 step 3: objective=73.955349 reg=0.004111
2017/08/30 03:02:43 step 4: objective=74.047630 reg=0.004111
2017/08/30 03:02:45 step 5: objective=74.097140 reg=0.004110
2017/08/30 03:02:46 step 6: objective=74.157318 reg=0.004109
2017/08/30 03:02:48 step 7: objective=74.208400 reg=0.004108
2017/08/30 03:02:48 Training value function...
2017/08/30 03:02:51 step 0: mse=191678.463485 step=0.050000
2017/08/30 03:02:52 step 1: mse=190908.316978 step=0.050000
2017/08/30 03:02:53 step 2: mse=189575.894323 step=0.050000
2017/08/30 03:02:54 step 3: mse=188356.835517 step=0.050000
2017/08/30 03:02:55 step 4: mse=186743.023791 step=0.050000
2017/08/30 03:02:57 step 5: mse=188296.206384 step=0.050000
2017/08/30 03:02:58 step 6: mse=188192.589772 step=0.050000
2017/08/30 03:02:59 step 7: mse=187617.652108 step=0.050000
2017/08/30 03:02:59 Saving...
2017/08/30 03:02:59 Gathering batch of experience...
2017/08/30 03:03:31 batch 602: mean=7722.758621 stddev=8684.588469 entropy=0.410797 frames=7004 count=29
2017/08/30 03:03:31 Training policy...
2017/08/30 03:03:36 tune 0: objective=54.687728 reg=0.004108 prune=0
2017/08/30 03:03:38 step 0: objective=54.804924 reg=0.004107
2017/08/30 03:03:39 step 1: objective=54.878462 reg=0.004108
2017/08/30 03:03:41 step 2: objective=55.019319 reg=0.004107
2017/08/30 03:03:42 step 3: objective=55.084238 reg=0.004107
2017/08/30 03:03:44 step 4: objective=55.149334 reg=0.004107
2017/08/30 03:03:45 step 5: objective=55.190766 reg=0.004106
2017/08/30 03:03:47 step 6: objective=55.220503 reg=0.004106
2017/08/30 03:03:48 step 7: objective=55.280884 reg=0.004105
2017/08/30 03:03:48 Training value function...
2017/08/30 03:03:51 step 0: mse=159675.073345 step=0.050000
2017/08/30 03:03:52 step 1: mse=159821.728081 step=0.050000
2017/08/30 03:03:53 step 2: mse=159415.370428 step=0.050000
2017/08/30 03:03:54 step 3: mse=158285.732446 step=0.050000
2017/08/30 03:03:56 step 4: mse=158016.174553 step=0.050000
2017/08/30 03:03:57 step 5: mse=157590.883276 step=0.050000
2017/08/30 03:03:58 step 6: mse=157894.415869 step=0.050000
2017/08/30 03:03:59 step 7: mse=157718.444796 step=0.050000
2017/08/30 03:03:59 Saving...
2017/08/30 03:03:59 Gathering batch of experience...
2017/08/30 03:04:29 batch 603: mean=6437.500000 stddev=8357.799448 entropy=0.410467 frames=6048 count=28
2017/08/30 03:04:29 Training policy...
2017/08/30 03:04:33 tune 0: objective=64.923141 reg=0.004105 prune=0
2017/08/30 03:04:35 step 0: objective=65.044354 reg=0.004105
2017/08/30 03:04:36 step 1: objective=65.132725 reg=0.004105
2017/08/30 03:04:37 step 2: objective=65.240989 reg=0.004105
2017/08/30 03:04:39 step 3: objective=65.377403 reg=0.004104
2017/08/30 03:04:40 step 4: objective=65.474356 reg=0.004103
2017/08/30 03:04:41 step 5: objective=65.562634 reg=0.004103
2017/08/30 03:04:43 step 6: objective=65.657578 reg=0.004102
2017/08/30 03:04:44 step 7: objective=65.712023 reg=0.004101
2017/08/30 03:04:44 Training value function...
2017/08/30 03:04:46 step 0: mse=237263.264018 step=0.050000
2017/08/30 03:04:47 step 1: mse=235075.688401 step=0.050000
2017/08/30 03:04:48 step 2: mse=234144.254009 step=0.050000
2017/08/30 03:04:49 step 3: mse=232692.220018 step=0.050000
2017/08/30 03:04:50 step 4: mse=230401.673052 step=0.050000
2017/08/30 03:04:51 step 5: mse=223870.713335 step=0.050000
2017/08/30 03:04:52 step 6: mse=222818.569347 step=0.050000
2017/08/30 03:04:53 step 7: mse=219675.886815 step=0.050000
2017/08/30 03:04:53 Saving...
2017/08/30 03:04:53 Gathering batch of experience...
2017/08/30 03:05:25 batch 604: mean=7363.333333 stddev=8754.554941 entropy=0.410706 frames=6903 count=30
2017/08/30 03:05:25 Training policy...
2017/08/30 03:05:30 tune 0: objective=59.128907 reg=0.004107 prune=0
2017/08/30 03:05:31 step 0: objective=59.187197 reg=0.004106
2017/08/30 03:05:33 step 1: objective=59.227460 reg=0.004106
2017/08/30 03:05:34 step 2: objective=59.297158 reg=0.004105
2017/08/30 03:05:36 step 3: objective=59.341663 reg=0.004105
2017/08/30 03:05:37 step 4: objective=59.394878 reg=0.004105
2017/08/30 03:05:39 step 5: objective=59.448374 reg=0.004105
2017/08/30 03:05:40 step 6: objective=59.496913 reg=0.004104
2017/08/30 03:05:41 step 7: objective=59.539598 reg=0.004104
2017/08/30 03:05:41 Training value function...
2017/08/30 03:05:44 step 0: mse=185954.026135 step=0.050000
2017/08/30 03:05:45 step 1: mse=187311.828903 step=0.050000
2017/08/30 03:05:47 step 2: mse=188052.258403 step=0.050000
2017/08/30 03:05:48 step 3: mse=188624.984053 step=0.050000
2017/08/30 03:05:49 step 4: mse=188324.901813 step=0.050000
2017/08/30 03:05:50 step 5: mse=187590.647849 step=0.050000
2017/08/30 03:05:51 step 6: mse=187561.895909 step=0.050000
2017/08/30 03:05:52 step 7: mse=187280.701745 step=0.050000
2017/08/30 03:05:52 Saving...
2017/08/30 03:05:52 Gathering batch of experience...
2017/08/30 03:06:20 batch 605: mean=6818.461538 stddev=8125.000919 entropy=0.405685 frames=6025 count=26
2017/08/30 03:06:20 Training policy...
2017/08/30 03:06:24 tune 0: objective=44.006141 reg=0.004057 prune=0
2017/08/30 03:06:25 step 0: objective=44.169212 reg=0.004058
2017/08/30 03:06:27 step 1: objective=44.331686 reg=0.004059
2017/08/30 03:06:28 step 2: objective=44.443169 reg=0.004061
2017/08/30 03:06:29 step 3: objective=44.506317 reg=0.004061
2017/08/30 03:06:30 step 4: objective=44.555529 reg=0.004061
2017/08/30 03:06:32 step 5: objective=44.596872 reg=0.004060
2017/08/30 03:06:33 step 6: objective=44.639979 reg=0.004060
2017/08/30 03:06:34 step 7: objective=44.693729 reg=0.004061
2017/08/30 03:06:34 Training value function...
2017/08/30 03:06:37 step 0: mse=147471.272516 step=0.050000
2017/08/30 03:06:38 step 1: mse=147301.636177 step=0.050000
2017/08/30 03:06:39 step 2: mse=146465.281768 step=0.050000
2017/08/30 03:06:40 step 3: mse=146554.274792 step=0.050000
2017/08/30 03:06:41 step 4: mse=147513.751919 step=0.050000
2017/08/30 03:06:42 step 5: mse=147631.165146 step=0.050000
2017/08/30 03:06:43 step 6: mse=147516.945554 step=0.050000
2017/08/30 03:06:44 step 7: mse=147213.376258 step=0.050000
2017/08/30 03:06:44 Saving...
2017/08/30 03:06:44 Gathering batch of experience...
2017/08/30 03:07:13 batch 606: mean=6458.620690 stddev=7586.483545 entropy=0.404840 frames=6534 count=29
2017/08/30 03:07:13 Training policy...
2017/08/30 03:07:18 tune 0: objective=44.443206 reg=0.004048 prune=0
2017/08/30 03:07:20 step 0: objective=44.568431 reg=0.004047
2017/08/30 03:07:21 step 1: objective=44.705043 reg=0.004047
2017/08/30 03:07:22 step 2: objective=44.811940 reg=0.004045
2017/08/30 03:07:24 step 3: objective=44.893404 reg=0.004045
2017/08/30 03:07:25 step 4: objective=44.989172 reg=0.004045
2017/08/30 03:07:27 step 5: objective=45.042848 reg=0.004045
2017/08/30 03:07:28 step 6: objective=45.110021 reg=0.004046
2017/08/30 03:07:29 step 7: objective=45.162726 reg=0.004046
2017/08/30 03:07:29 Training value function...
2017/08/30 03:07:32 step 0: mse=167764.428026 step=0.050000
2017/08/30 03:07:33 step 1: mse=168196.142315 step=0.050000
2017/08/30 03:07:34 step 2: mse=167509.394398 step=0.050000
2017/08/30 03:07:35 step 3: mse=167525.934065 step=0.050000
2017/08/30 03:07:36 step 4: mse=167595.333520 step=0.050000
2017/08/30 03:07:37 step 5: mse=166504.857631 step=0.050000
2017/08/30 03:07:38 step 6: mse=165357.448911 step=0.050000
2017/08/30 03:07:39 step 7: mse=165911.137013 step=0.050000
2017/08/30 03:07:39 Saving...
2017/08/30 03:07:39 Gathering batch of experience...
2017/08/30 03:08:08 batch 607: mean=6672.857143 stddev=8175.007255 entropy=0.407810 frames=6340 count=28
2017/08/30 03:08:08 Training policy...
2017/08/30 03:08:13 tune 0: objective=60.163412 reg=0.004078 prune=0
2017/08/30 03:08:14 step 0: objective=60.269258 reg=0.004077
2017/08/30 03:08:15 step 1: objective=60.376203 reg=0.004077
2017/08/30 03:08:17 step 2: objective=60.461923 reg=0.004077
2017/08/30 03:08:18 step 3: objective=60.556861 reg=0.004076
2017/08/30 03:08:19 step 4: objective=60.624788 reg=0.004076
2017/08/30 03:08:21 step 5: objective=60.675187 reg=0.004075
2017/08/30 03:08:22 step 6: objective=60.726853 reg=0.004074
2017/08/30 03:08:23 step 7: objective=60.761928 reg=0.004073
2017/08/30 03:08:23 Training value function...
2017/08/30 03:08:26 step 0: mse=211785.519130 step=0.050000
2017/08/30 03:08:27 step 1: mse=211931.221806 step=0.050000
2017/08/30 03:08:28 step 2: mse=207481.074689 step=0.050000
2017/08/30 03:08:29 step 3: mse=207599.121697 step=0.050000
2017/08/30 03:08:30 step 4: mse=207503.806500 step=0.050000
2017/08/30 03:08:31 step 5: mse=208145.148133 step=0.050000
2017/08/30 03:08:32 step 6: mse=208575.660393 step=0.050000
2017/08/30 03:08:33 step 7: mse=208992.109973 step=0.050000
2017/08/30 03:08:33 Saving...
2017/08/30 03:08:33 Gathering batch of experience...
2017/08/30 03:09:05 batch 608: mean=7599.107143 stddev=8627.900863 entropy=0.408547 frames=7082 count=28
2017/08/30 03:09:05 Training policy...
2017/08/30 03:09:11 tune 0: objective=63.259836 reg=0.004085 prune=0
2017/08/30 03:09:12 step 0: objective=63.369489 reg=0.004085
2017/08/30 03:09:14 step 1: objective=63.457185 reg=0.004086
2017/08/30 03:09:15 step 2: objective=63.543433 reg=0.004086
2017/08/30 03:09:17 step 3: objective=63.607495 reg=0.004086
2017/08/30 03:09:18 step 4: objective=63.676111 reg=0.004086
2017/08/30 03:09:20 step 5: objective=63.721605 reg=0.004086
2017/08/30 03:09:21 step 6: objective=63.767024 reg=0.004086
2017/08/30 03:09:23 step 7: objective=63.823456 reg=0.004086
2017/08/30 03:09:23 Training value function...
2017/08/30 03:09:26 step 0: mse=167920.867912 step=0.050000
2017/08/30 03:09:27 step 1: mse=167220.078887 step=0.050000
2017/08/30 03:09:28 step 2: mse=166090.571315 step=0.050000
2017/08/30 03:09:29 step 3: mse=165167.146976 step=0.050000
2017/08/30 03:09:30 step 4: mse=164569.018959 step=0.050000
2017/08/30 03:09:31 step 5: mse=163804.927847 step=0.050000
2017/08/30 03:09:32 step 6: mse=163467.029432 step=0.050000
2017/08/30 03:09:34 step 7: mse=162341.679914 step=0.050000
2017/08/30 03:09:34 Saving...
2017/08/30 03:09:34 Gathering batch of experience...
2017/08/30 03:09:59 batch 609: mean=4843.275862 stddev=6788.424640 entropy=0.404920 frames=5625 count=29
2017/08/30 03:09:59 Training policy...
2017/08/30 03:10:03 tune 0: objective=35.690475 reg=0.004049 prune=0
2017/08/30 03:10:04 step 0: objective=35.905922 reg=0.004047
2017/08/30 03:10:06 step 1: objective=35.971731 reg=0.004047
2017/08/30 03:10:07 step 2: objective=36.028428 reg=0.004047
2017/08/30 03:10:08 step 3: objective=36.068058 reg=0.004047
2017/08/30 03:10:09 step 4: objective=36.103728 reg=0.004047
2017/08/30 03:10:10 step 5: objective=36.175489 reg=0.004048
2017/08/30 03:10:12 step 6: objective=36.212583 reg=0.004048
2017/08/30 03:10:13 step 7: objective=36.241764 reg=0.004048
2017/08/30 03:10:13 Training value function...
2017/08/30 03:10:15 step 0: mse=128988.777535 step=0.050000
2017/08/30 03:10:16 step 1: mse=128777.928622 step=0.050000
2017/08/30 03:10:17 step 2: mse=129480.365288 step=0.050000
2017/08/30 03:10:18 step 3: mse=129167.158687 step=0.050000
2017/08/30 03:10:19 step 4: mse=128355.324478 step=0.050000
2017/08/30 03:10:20 step 5: mse=129285.054147 step=0.050000
2017/08/30 03:10:20 step 6: mse=129452.849582 step=0.050000
2017/08/30 03:10:21 step 7: mse=128632.569287 step=0.050000
2017/08/30 03:10:21 Saving...
2017/08/30 03:10:21 Gathering batch of experience...
2017/08/30 03:10:49 batch 610: mean=5205.892857 stddev=7224.089915 entropy=0.404212 frames=5460 count=28
2017/08/30 03:10:49 Training policy...
2017/08/30 03:10:53 tune 0: objective=47.488373 reg=0.004042 prune=0
2017/08/30 03:10:54 step 0: objective=47.604456 reg=0.004041
2017/08/30 03:10:55 step 1: objective=47.692185 reg=0.004041
2017/08/30 03:10:56 step 2: objective=47.788058 reg=0.004040
2017/08/30 03:10:57 step 3: objective=47.862036 reg=0.004040
2017/08/30 03:10:59 step 4: objective=47.960786 reg=0.004039
2017/08/30 03:11:00 step 5: objective=48.072316 reg=0.004040
2017/08/30 03:11:01 step 6: objective=48.108717 reg=0.004040
2017/08/30 03:11:02 step 7: objective=48.147619 reg=0.004040
2017/08/30 03:11:02 Training value function...
2017/08/30 03:11:04 step 0: mse=182075.053598 step=0.050000
2017/08/30 03:11:05 step 1: mse=182045.111210 step=0.050000
2017/08/30 03:11:06 step 2: mse=182022.736161 step=0.050000
2017/08/30 03:11:07 step 3: mse=182458.545304 step=0.050000
2017/08/30 03:11:08 step 4: mse=182477.076957 step=0.050000
2017/08/30 03:11:09 step 5: mse=180522.421975 step=0.050000
2017/08/30 03:11:10 step 6: mse=180597.970977 step=0.050000
2017/08/30 03:11:10 step 7: mse=180690.633322 step=0.050000
2017/08/30 03:11:10 Saving...
2017/08/30 03:11:10 Gathering batch of experience...
2017/08/30 03:11:42 batch 611: mean=7027.931034 stddev=8293.414662 entropy=0.409632 frames=6777 count=29
2017/08/30 03:11:42 Training policy...
2017/08/30 03:11:47 tune 0: objective=54.363541 reg=0.004096 prune=0
2017/08/30 03:11:48 step 0: objective=54.468875 reg=0.004096
2017/08/30 03:11:50 step 1: objective=54.577971 reg=0.004095
2017/08/30 03:11:51 step 2: objective=54.672025 reg=0.004095
2017/08/30 03:11:53 step 3: objective=54.711022 reg=0.004095
2017/08/30 03:11:54 step 4: objective=54.777704 reg=0.004095
2017/08/30 03:11:55 step 5: objective=54.834514 reg=0.004095
2017/08/30 03:11:57 step 6: objective=54.878435 reg=0.004094
2017/08/30 03:11:58 step 7: objective=54.925889 reg=0.004094
2017/08/30 03:11:58 Training value function...
2017/08/30 03:12:01 step 0: mse=155702.466056 step=0.050000
2017/08/30 03:12:02 step 1: mse=154733.590835 step=0.050000
2017/08/30 03:12:03 step 2: mse=152648.688114 step=0.050000
2017/08/30 03:12:04 step 3: mse=151741.424400 step=0.050000
2017/08/30 03:12:05 step 4: mse=153698.105224 step=0.050000
2017/08/30 03:12:07 step 5: mse=155322.549070 step=0.050000
2017/08/30 03:12:08 step 6: mse=154896.968025 step=0.050000
2017/08/30 03:12:09 step 7: mse=154212.418031 step=0.050000
2017/08/30 03:12:09 Saving...
2017/08/30 03:12:09 Gathering batch of experience...
2017/08/30 03:12:39 batch 612: mean=6020.322581 stddev=8066.873813 entropy=0.408361 frames=6518 count=31
2017/08/30 03:12:39 Training policy...
2017/08/30 03:12:44 tune 0: objective=61.315319 reg=0.004084 prune=0
2017/08/30 03:12:45 step 0: objective=61.397352 reg=0.004084
2017/08/30 03:12:46 step 1: objective=61.530190 reg=0.004086
2017/08/30 03:12:48 step 2: objective=61.614447 reg=0.004086
2017/08/30 03:12:49 step 3: objective=61.736135 reg=0.004086
2017/08/30 03:12:51 step 4: objective=61.822237 reg=0.004087
2017/08/30 03:12:52 step 5: objective=61.908105 reg=0.004088
2017/08/30 03:12:54 step 6: objective=61.992842 reg=0.004090
2017/08/30 03:12:55 step 7: objective=62.037061 reg=0.004090
2017/08/30 03:12:55 Training value function...
2017/08/30 03:12:58 step 0: mse=177100.646414 step=0.050000
2017/08/30 03:12:59 step 1: mse=175970.456463 step=0.050000
2017/08/30 03:13:00 step 2: mse=172419.698525 step=0.050000
2017/08/30 03:13:01 step 3: mse=172283.742065 step=0.050000
2017/08/30 03:13:02 step 4: mse=171088.821730 step=0.050000
2017/08/30 03:13:03 step 5: mse=170478.941988 step=0.050000
2017/08/30 03:13:04 step 6: mse=168999.260525 step=0.050000
2017/08/30 03:13:05 step 7: mse=167534.929113 step=0.050000
2017/08/30 03:13:05 Saving...
2017/08/30 03:13:05 Gathering batch of experience...
2017/08/30 03:13:36 batch 613: mean=6725.322581 stddev=8364.219777 entropy=0.407223 frames=6935 count=31
2017/08/30 03:13:36 Training policy...
2017/08/30 03:13:42 tune 0: objective=68.064631 reg=0.004072 prune=0
2017/08/30 03:13:43 step 0: objective=68.135864 reg=0.004071
2017/08/30 03:13:45 step 1: objective=68.235017 reg=0.004071
2017/08/30 03:13:46 step 2: objective=68.321864 reg=0.004071
2017/08/30 03:13:48 step 3: objective=68.411491 reg=0.004070
2017/08/30 03:13:49 step 4: objective=68.512013 reg=0.004068
2017/08/30 03:13:50 step 5: objective=68.574500 reg=0.004068
2017/08/30 03:13:52 step 6: objective=68.618836 reg=0.004068
2017/08/30 03:13:53 step 7: objective=68.676374 reg=0.004067
2017/08/30 03:13:53 Training value function...
2017/08/30 03:13:56 step 0: mse=243088.681884 step=0.050000
2017/08/30 03:13:57 step 1: mse=241159.504146 step=0.050000
2017/08/30 03:13:59 step 2: mse=238871.725375 step=0.050000
2017/08/30 03:14:00 step 3: mse=236706.353141 step=0.050000
2017/08/30 03:14:01 step 4: mse=235466.542899 step=0.050000
2017/08/30 03:14:02 step 5: mse=234748.189275 step=0.050000
2017/08/30 03:14:03 step 6: mse=232973.693175 step=0.050000
2017/08/30 03:14:04 step 7: mse=227599.990362 step=0.050000
2017/08/30 03:14:04 Saving...
2017/08/30 03:14:04 Gathering batch of experience...
2017/08/30 03:14:34 batch 614: mean=8930.625000 stddev=9418.928229 entropy=0.410853 frames=6374 count=24
2017/08/30 03:14:34 Training policy...
2017/08/30 03:14:39 tune 0: objective=76.065344 reg=0.004109 prune=0
2017/08/30 03:14:40 step 0: objective=76.128476 reg=0.004107
2017/08/30 03:14:41 step 1: objective=76.174768 reg=0.004106
2017/08/30 03:14:43 step 2: objective=76.222824 reg=0.004106
2017/08/30 03:14:44 step 3: objective=76.278034 reg=0.004106
2017/08/30 03:14:45 step 4: objective=76.323413 reg=0.004105
2017/08/30 03:14:47 step 5: objective=76.365979 reg=0.004105
2017/08/30 03:14:48 step 6: objective=76.402568 reg=0.004104
2017/08/30 03:14:50 step 7: objective=76.443025 reg=0.004103
2017/08/30 03:14:50 Training value function...
2017/08/30 03:14:52 step 0: mse=163321.786736 step=0.050000
2017/08/30 03:14:53 step 1: mse=161889.588483 step=0.050000
2017/08/30 03:14:54 step 2: mse=159984.376892 step=0.050000
2017/08/30 03:14:55 step 3: mse=159370.819701 step=0.050000
2017/08/30 03:14:56 step 4: mse=157558.713662 step=0.050000
2017/08/30 03:14:57 step 5: mse=156810.899281 step=0.050000
2017/08/30 03:14:58 step 6: mse=154933.793055 step=0.050000
2017/08/30 03:14:59 step 7: mse=154067.737749 step=0.050000
2017/08/30 03:14:59 Saving...
2017/08/30 03:14:59 Gathering batch of experience...
2017/08/30 03:15:29 batch 615: mean=8977.291667 stddev=9434.727515 entropy=0.412949 frames=6447 count=24
2017/08/30 03:15:29 Training policy...
2017/08/30 03:15:34 tune 0: objective=70.350371 reg=0.004130 prune=0
2017/08/30 03:15:35 step 0: objective=70.408300 reg=0.004130
2017/08/30 03:15:36 step 1: objective=70.446235 reg=0.004131
2017/08/30 03:15:38 step 2: objective=70.488672 reg=0.004132
2017/08/30 03:15:39 step 3: objective=70.531163 reg=0.004132
2017/08/30 03:15:41 step 4: objective=70.581608 reg=0.004133
2017/08/30 03:15:42 step 5: objective=70.631844 reg=0.004133
2017/08/30 03:15:43 step 6: objective=70.673467 reg=0.004133
2017/08/30 03:15:45 step 7: objective=70.712434 reg=0.004133
2017/08/30 03:15:45 Training value function...
2017/08/30 03:15:47 step 0: mse=179301.884583 step=0.050000
2017/08/30 03:15:48 step 1: mse=178504.723365 step=0.050000
2017/08/30 03:15:49 step 2: mse=178375.861055 step=0.050000
2017/08/30 03:15:50 step 3: mse=177181.815635 step=0.050000
2017/08/30 03:15:52 step 4: mse=175995.178802 step=0.050000
2017/08/30 03:15:53 step 5: mse=176473.617554 step=0.050000
2017/08/30 03:15:54 step 6: mse=177166.274979 step=0.050000
2017/08/30 03:15:55 step 7: mse=176407.241475 step=0.050000
2017/08/30 03:15:55 Saving...
2017/08/30 03:15:55 Gathering batch of experience...
2017/08/30 03:16:25 batch 616: mean=8077.115385 stddev=8725.746295 entropy=0.408367 frames=6481 count=26
2017/08/30 03:16:25 Training policy...
2017/08/30 03:16:29 tune 0: objective=63.729729 reg=0.004084 prune=0
2017/08/30 03:16:31 step 0: objective=63.873028 reg=0.004083
2017/08/30 03:16:32 step 1: objective=64.016114 reg=0.004083
2017/08/30 03:16:34 step 2: objective=64.139123 reg=0.004083
2017/08/30 03:16:35 step 3: objective=64.241301 reg=0.004083
2017/08/30 03:16:36 step 4: objective=64.323952 reg=0.004084
2017/08/30 03:16:38 step 5: objective=64.388337 reg=0.004083
2017/08/30 03:16:39 step 6: objective=64.466575 reg=0.004084
2017/08/30 03:16:41 step 7: objective=64.518448 reg=0.004084
2017/08/30 03:16:41 Training value function...
2017/08/30 03:16:43 step 0: mse=258639.862191 step=0.050000
2017/08/30 03:16:44 step 1: mse=254732.522200 step=0.050000
2017/08/30 03:16:45 step 2: mse=253359.640249 step=0.050000
2017/08/30 03:16:46 step 3: mse=250213.561395 step=0.050000
2017/08/30 03:16:47 step 4: mse=249160.765673 step=0.050000
2017/08/30 03:16:49 step 5: mse=249286.767680 step=0.050000
2017/08/30 03:16:50 step 6: mse=248394.204197 step=0.050000
2017/08/30 03:16:51 step 7: mse=248591.041572 step=0.050000
2017/08/30 03:16:51 Saving...
2017/08/30 03:16:51 Gathering batch of experience...
2017/08/30 03:17:21 batch 617: mean=8462.692308 stddev=9333.100238 entropy=0.408843 frames=6545 count=26
2017/08/30 03:17:21 Training policy...
2017/08/30 03:17:25 tune 0: objective=67.694199 reg=0.004088 prune=0
2017/08/30 03:17:27 step 0: objective=67.796128 reg=0.004088
2017/08/30 03:17:28 step 1: objective=67.869820 reg=0.004088
2017/08/30 03:17:30 step 2: objective=67.982491 reg=0.004088
2017/08/30 03:17:31 step 3: objective=68.075731 reg=0.004089
2017/08/30 03:17:32 step 4: objective=68.165102 reg=0.004088
2017/08/30 03:17:34 step 5: objective=68.244352 reg=0.004087
2017/08/30 03:17:35 step 6: objective=68.300544 reg=0.004087
2017/08/30 03:17:37 step 7: objective=68.335394 reg=0.004086
2017/08/30 03:17:37 Training value function...
2017/08/30 03:17:39 step 0: mse=174405.638932 step=0.050000
2017/08/30 03:17:40 step 1: mse=173869.830469 step=0.050000
2017/08/30 03:17:41 step 2: mse=173345.132857 step=0.050000
2017/08/30 03:17:43 step 3: mse=173020.382819 step=0.050000
2017/08/30 03:17:44 step 4: mse=170933.113826 step=0.050000
2017/08/30 03:17:45 step 5: mse=170817.565234 step=0.050000
2017/08/30 03:17:46 step 6: mse=170325.152514 step=0.050000
2017/08/30 03:17:47 step 7: mse=171680.441561 step=0.050000
2017/08/30 03:17:47 Saving...
2017/08/30 03:17:47 Gathering batch of experience...
2017/08/30 03:18:22 batch 618: mean=8226.833333 stddev=9134.319121 entropy=0.408956 frames=7567 count=30
2017/08/30 03:18:22 Training policy...
2017/08/30 03:18:28 tune 0: objective=56.404862 reg=0.004090 prune=0
2017/08/30 03:18:29 step 0: objective=56.470439 reg=0.004089
2017/08/30 03:18:31 step 1: objective=56.520579 reg=0.004088
2017/08/30 03:18:33 step 2: objective=56.592329 reg=0.004087
2017/08/30 03:18:34 step 3: objective=56.645839 reg=0.004087
2017/08/30 03:18:36 step 4: objective=56.693472 reg=0.004087
2017/08/30 03:18:38 step 5: objective=56.733836 reg=0.004087
2017/08/30 03:18:39 step 6: objective=56.773845 reg=0.004086
2017/08/30 03:18:41 step 7: objective=56.812186 reg=0.004086
2017/08/30 03:18:41 Training value function...
2017/08/30 03:18:44 step 0: mse=155784.723191 step=0.050000
2017/08/30 03:18:45 step 1: mse=156405.886096 step=0.050000
2017/08/30 03:18:46 step 2: mse=156886.083154 step=0.050000
2017/08/30 03:18:48 step 3: mse=157305.336713 step=0.050000
2017/08/30 03:18:49 step 4: mse=157857.982076 step=0.050000
2017/08/30 03:18:50 step 5: mse=158358.032682 step=0.050000
2017/08/30 03:18:51 step 6: mse=157984.747316 step=0.050000
2017/08/30 03:18:53 step 7: mse=158448.465823 step=0.050000
2017/08/30 03:18:53 Saving...
2017/08/30 03:18:53 Gathering batch of experience...
2017/08/30 03:19:23 batch 619: mean=5752.096774 stddev=7295.888676 entropy=0.405909 frames=6549 count=31
2017/08/30 03:19:23 Training policy...
2017/08/30 03:19:28 tune 0: objective=33.217734 reg=0.004059 prune=0
2017/08/30 03:19:30 step 0: objective=33.419587 reg=0.004056
2017/08/30 03:19:31 step 1: objective=33.525894 reg=0.004055
2017/08/30 03:19:33 step 2: objective=33.613536 reg=0.004055
2017/08/30 03:19:34 step 3: objective=33.703741 reg=0.004055
2017/08/30 03:19:35 step 4: objective=33.780739 reg=0.004054
2017/08/30 03:19:37 step 5: objective=33.833329 reg=0.004054
2017/08/30 03:19:38 step 6: objective=33.906198 reg=0.004053
2017/08/30 03:19:40 step 7: objective=33.950374 reg=0.004053
2017/08/30 03:19:40 Training value function...
2017/08/30 03:19:42 step 0: mse=242290.359972 step=0.050000
2017/08/30 03:19:43 step 1: mse=241134.703320 step=0.050000
2017/08/30 03:19:44 step 2: mse=238569.453042 step=0.050000
2017/08/30 03:19:45 step 3: mse=237007.139907 step=0.050000
2017/08/30 03:19:46 step 4: mse=234325.374278 step=0.050000
2017/08/30 03:19:48 step 5: mse=234294.874742 step=0.050000
2017/08/30 03:19:49 step 6: mse=234120.018935 step=0.050000
2017/08/30 03:19:50 step 7: mse=233099.603519 step=0.050000
2017/08/30 03:19:50 Saving...
2017/08/30 03:19:50 Gathering batch of experience...
2017/08/30 03:20:19 batch 620: mean=8223.000000 stddev=8822.470176 entropy=0.405634 frames=6473 count=25
2017/08/30 03:20:19 Training policy...
2017/08/30 03:20:24 tune 0: objective=63.523772 reg=0.004056 prune=0
2017/08/30 03:20:25 step 0: objective=63.646189 reg=0.004055
2017/08/30 03:20:27 step 1: objective=63.734271 reg=0.004056
2017/08/30 03:20:28 step 2: objective=63.815068 reg=0.004056
2017/08/30 03:20:29 step 3: objective=63.900626 reg=0.004056
2017/08/30 03:20:31 step 4: objective=63.981080 reg=0.004055
2017/08/30 03:20:32 step 5: objective=64.027021 reg=0.004057
2017/08/30 03:20:34 step 6: objective=64.086185 reg=0.004057
2017/08/30 03:20:35 step 7: objective=64.165973 reg=0.004057
2017/08/30 03:20:35 Training value function...
2017/08/30 03:20:38 step 0: mse=187983.864877 step=0.050000
2017/08/30 03:20:39 step 1: mse=187739.309050 step=0.050000
2017/08/30 03:20:40 step 2: mse=187120.134981 step=0.050000
2017/08/30 03:20:41 step 3: mse=187089.250873 step=0.050000
2017/08/30 03:20:42 step 4: mse=187595.946845 step=0.050000
2017/08/30 03:20:43 step 5: mse=188120.782958 step=0.050000
2017/08/30 03:20:44 step 6: mse=187288.644625 step=0.050000
2017/08/30 03:20:45 step 7: mse=186845.994218 step=0.050000
2017/08/30 03:20:45 Saving...
2017/08/30 03:20:45 Gathering batch of experience...
2017/08/30 03:21:17 batch 621: mean=7861.296296 stddev=8502.539010 entropy=0.405976 frames=6776 count=27
2017/08/30 03:21:17 Training policy...
2017/08/30 03:21:22 tune 0: objective=58.068043 reg=0.004060 prune=0
2017/08/30 03:21:23 step 0: objective=58.172673 reg=0.004058
2017/08/30 03:21:25 step 1: objective=58.261359 reg=0.004057
2017/08/30 03:21:26 step 2: objective=58.347998 reg=0.004057
2017/08/30 03:21:28 step 3: objective=58.422691 reg=0.004056
2017/08/30 03:21:29 step 4: objective=58.506826 reg=0.004055
2017/08/30 03:21:31 step 5: objective=58.589189 reg=0.004056
2017/08/30 03:21:32 step 6: objective=58.642839 reg=0.004056
2017/08/30 03:21:33 step 7: objective=58.696996 reg=0.004056
2017/08/30 03:21:33 Training value function...
2017/08/30 03:21:36 step 0: mse=174841.227033 step=0.050000
2017/08/30 03:21:37 step 1: mse=174647.158891 step=0.050000
2017/08/30 03:21:38 step 2: mse=174466.370063 step=0.050000
2017/08/30 03:21:40 step 3: mse=174973.068314 step=0.050000
2017/08/30 03:21:41 step 4: mse=174884.686720 step=0.050000
2017/08/30 03:21:42 step 5: mse=174743.588770 step=0.050000
2017/08/30 03:21:43 step 6: mse=175417.885570 step=0.050000
2017/08/30 03:21:44 step 7: mse=174150.144113 step=0.050000
2017/08/30 03:21:44 Saving...
2017/08/30 03:21:44 Gathering batch of experience...
2017/08/30 03:22:15 batch 622: mean=8115.740741 stddev=9113.963209 entropy=0.406796 frames=6627 count=27
2017/08/30 03:22:15 Training policy...
2017/08/30 03:22:20 tune 0: objective=77.366969 reg=0.004068 prune=0
2017/08/30 03:22:21 step 0: objective=77.516269 reg=0.004069
2017/08/30 03:22:23 step 1: objective=77.722838 reg=0.004068
2017/08/30 03:22:24 step 2: objective=77.917912 reg=0.004068
2017/08/30 03:22:26 step 3: objective=78.046538 reg=0.004068
2017/08/30 03:22:27 step 4: objective=78.175480 reg=0.004068
2017/08/30 03:22:28 step 5: objective=78.251726 reg=0.004067
2017/08/30 03:22:30 step 6: objective=78.335866 reg=0.004066
2017/08/30 03:22:31 step 7: objective=78.394376 reg=0.004065
2017/08/30 03:22:31 Training value function...
2017/08/30 03:22:34 step 0: mse=263105.928614 step=0.050000
2017/08/30 03:22:35 step 1: mse=261699.358702 step=0.050000
2017/08/30 03:22:36 step 2: mse=259464.741157 step=0.050000
2017/08/30 03:22:37 step 3: mse=258644.940994 step=0.050000
2017/08/30 03:22:38 step 4: mse=257496.506346 step=0.050000
2017/08/30 03:22:39 step 5: mse=256876.226070 step=0.050000
2017/08/30 03:22:40 step 6: mse=255040.088715 step=0.050000
2017/08/30 03:22:42 step 7: mse=254161.451426 step=0.050000
2017/08/30 03:22:42 Saving...
2017/08/30 03:22:42 Gathering batch of experience...
2017/08/30 03:23:14 batch 623: mean=6410.483871 stddev=8267.076692 entropy=0.408561 frames=6964 count=31
2017/08/30 03:23:14 Training policy...
2017/08/30 03:23:19 tune 0: objective=49.866339 reg=0.004086 prune=0
2017/08/30 03:23:20 step 0: objective=50.010720 reg=0.004083
2017/08/30 03:23:22 step 1: objective=50.071228 reg=0.004082
2017/08/30 03:23:23 step 2: objective=50.162523 reg=0.004082
2017/08/30 03:23:25 step 3: objective=50.208644 reg=0.004082
2017/08/30 03:23:26 step 4: objective=50.245486 reg=0.004082
2017/08/30 03:23:28 step 5: objective=50.311966 reg=0.004082
2017/08/30 03:23:29 step 6: objective=50.374574 reg=0.004082
2017/08/30 03:23:31 step 7: objective=50.422885 reg=0.004082
2017/08/30 03:23:31 Training value function...
2017/08/30 03:23:34 step 0: mse=197759.895835 step=0.050000
2017/08/30 03:23:35 step 1: mse=194830.105350 step=0.050000
2017/08/30 03:23:36 step 2: mse=194448.062579 step=0.050000
2017/08/30 03:23:37 step 3: mse=192116.760970 step=0.050000
2017/08/30 03:23:38 step 4: mse=189149.932013 step=0.050000
2017/08/30 03:23:39 step 5: mse=188167.300813 step=0.050000
2017/08/30 03:23:41 step 6: mse=186883.645932 step=0.050000
2017/08/30 03:23:42 step 7: mse=186465.958529 step=0.050000
2017/08/30 03:23:42 Saving...
2017/08/30 03:23:42 Gathering batch of experience...
2017/08/30 03:24:14 batch 624: mean=8225.862069 stddev=9082.120278 entropy=0.409205 frames=7268 count=29
2017/08/30 03:24:14 Training policy...
2017/08/30 03:24:19 tune 0: objective=64.038633 reg=0.004092 prune=0
2017/08/30 03:24:21 step 0: objective=64.152449 reg=0.004091
2017/08/30 03:24:22 step 1: objective=64.266489 reg=0.004090
2017/08/30 03:24:24 step 2: objective=64.369101 reg=0.004090
2017/08/30 03:24:25 step 3: objective=64.429911 reg=0.004089
2017/08/30 03:24:27 step 4: objective=64.514206 reg=0.004089
2017/08/30 03:24:29 step 5: objective=64.593784 reg=0.004089
2017/08/30 03:24:30 step 6: objective=64.674863 reg=0.004088
2017/08/30 03:24:32 step 7: objective=64.730058 reg=0.004088
2017/08/30 03:24:32 Training value function...
2017/08/30 03:24:35 step 0: mse=195101.910605 step=0.050000
2017/08/30 03:24:36 step 1: mse=194111.929653 step=0.050000
2017/08/30 03:24:37 step 2: mse=190984.089749 step=0.050000
2017/08/30 03:24:38 step 3: mse=188562.553787 step=0.050000
2017/08/30 03:24:39 step 4: mse=189755.676409 step=0.050000
2017/08/30 03:24:41 step 5: mse=190320.112109 step=0.050000
2017/08/30 03:24:42 step 6: mse=189418.911651 step=0.050000
2017/08/30 03:24:43 step 7: mse=189477.075260 step=0.050000
2017/08/30 03:24:43 Saving...
2017/08/30 03:24:43 Gathering batch of experience...
2017/08/30 03:25:13 batch 625: mean=5884.166667 stddev=7719.684912 entropy=0.406534 frames=6327 count=30
2017/08/30 03:25:13 Training policy...
2017/08/30 03:25:18 tune 0: objective=46.509305 reg=0.004065 prune=0
2017/08/30 03:25:19 step 0: objective=46.648199 reg=0.004063
2017/08/30 03:25:21 step 1: objective=46.734047 reg=0.004062
2017/08/30 03:25:22 step 2: objective=46.849519 reg=0.004062
2017/08/30 03:25:23 step 3: objective=46.901187 reg=0.004062
2017/08/30 03:25:25 step 4: objective=46.969120 reg=0.004061
2017/08/30 03:25:26 step 5: objective=47.053595 reg=0.004060
2017/08/30 03:25:28 step 6: objective=47.114154 reg=0.004060
2017/08/30 03:25:29 step 7: objective=47.182561 reg=0.004060
2017/08/30 03:25:29 Training value function...
2017/08/30 03:25:32 step 0: mse=220675.678237 step=0.050000
2017/08/30 03:25:33 step 1: mse=219074.881468 step=0.050000
2017/08/30 03:25:34 step 2: mse=218349.468470 step=0.050000
2017/08/30 03:25:35 step 3: mse=218554.014331 step=0.050000
2017/08/30 03:25:36 step 4: mse=217548.225720 step=0.050000
2017/08/30 03:25:37 step 5: mse=217309.812445 step=0.050000
2017/08/30 03:25:38 step 6: mse=216420.592127 step=0.050000
2017/08/30 03:25:39 step 7: mse=215520.152476 step=0.050000
2017/08/30 03:25:39 Saving...
2017/08/30 03:25:39 Gathering batch of experience...
2017/08/30 03:26:08 batch 626: mean=8315.384615 stddev=9352.064449 entropy=0.410608 frames=6461 count=26
2017/08/30 03:26:08 Training policy...
2017/08/30 03:26:13 tune 0: objective=80.469002 reg=0.004106 prune=0
2017/08/30 03:26:14 step 0: objective=80.578708 reg=0.004106
2017/08/30 03:26:16 step 1: objective=80.688090 reg=0.004106
2017/08/30 03:26:17 step 2: objective=80.785308 reg=0.004106
2017/08/30 03:26:18 step 3: objective=80.849728 reg=0.004106
2017/08/30 03:26:20 step 4: objective=80.900286 reg=0.004106
2017/08/30 03:26:21 step 5: objective=80.967014 reg=0.004105
2017/08/30 03:26:22 step 6: objective=81.014791 reg=0.004105
2017/08/30 03:26:24 step 7: objective=81.090887 reg=0.004105
2017/08/30 03:26:24 Training value function...
2017/08/30 03:26:27 step 0: mse=215638.938642 step=0.050000
2017/08/30 03:26:28 step 1: mse=213023.136253 step=0.050000
2017/08/30 03:26:29 step 2: mse=211109.112154 step=0.050000
2017/08/30 03:26:30 step 3: mse=208895.299434 step=0.050000
2017/08/30 03:26:31 step 4: mse=206141.158927 step=0.050000
2017/08/30 03:26:32 step 5: mse=204270.354769 step=0.050000
2017/08/30 03:26:33 step 6: mse=202569.473840 step=0.050000
2017/08/30 03:26:34 step 7: mse=199660.205078 step=0.050000
2017/08/30 03:26:34 Saving...
2017/08/30 03:26:34 Gathering batch of experience...
2017/08/30 03:27:01 batch 627: mean=4219.545455 stddev=6191.298924 entropy=0.401695 frames=5877 count=33
2017/08/30 03:27:01 Training policy...
2017/08/30 03:27:06 tune 0: objective=23.077936 reg=0.004017 prune=0
2017/08/30 03:27:07 step 0: objective=23.186487 reg=0.004017
2017/08/30 03:27:08 step 1: objective=23.281327 reg=0.004017
2017/08/30 03:27:09 step 2: objective=23.355632 reg=0.004018
2017/08/30 03:27:11 step 3: objective=23.403187 reg=0.004019
2017/08/30 03:27:12 step 4: objective=23.457464 reg=0.004019
2017/08/30 03:27:13 step 5: objective=23.502276 reg=0.004019
2017/08/30 03:27:14 step 6: objective=23.561221 reg=0.004018
2017/08/30 03:27:16 step 7: objective=23.592540 reg=0.004019
2017/08/30 03:27:16 Training value function...
2017/08/30 03:27:18 step 0: mse=98529.989732 step=0.050000
2017/08/30 03:27:19 step 1: mse=98857.138967 step=0.050000
2017/08/30 03:27:20 step 2: mse=99867.776062 step=0.050000
2017/08/30 03:27:21 step 3: mse=100076.938875 step=0.050000
2017/08/30 03:27:22 step 4: mse=100805.486537 step=0.050000
2017/08/30 03:27:23 step 5: mse=101367.417319 step=0.050000
2017/08/30 03:27:24 step 6: mse=101189.719134 step=0.050000
2017/08/30 03:27:25 step 7: mse=101444.487327 step=0.050000
2017/08/30 03:27:25 Saving...
2017/08/30 03:27:25 Gathering batch of experience...
2017/08/30 03:27:55 batch 628: mean=7652.962963 stddev=8635.952762 entropy=0.407585 frames=6610 count=27
2017/08/30 03:27:55 Training policy...
2017/08/30 03:28:00 tune 0: objective=61.843731 reg=0.004076 prune=0
2017/08/30 03:28:02 step 0: objective=61.935354 reg=0.004075
2017/08/30 03:28:03 step 1: objective=62.021393 reg=0.004075
2017/08/30 03:28:05 step 2: objective=62.098563 reg=0.004075
2017/08/30 03:28:06 step 3: objective=62.160524 reg=0.004075
2017/08/30 03:28:08 step 4: objective=62.231349 reg=0.004074
2017/08/30 03:28:09 step 5: objective=62.300856 reg=0.004074
2017/08/30 03:28:10 step 6: objective=62.351886 reg=0.004073
2017/08/30 03:28:12 step 7: objective=62.397603 reg=0.004074
2017/08/30 03:28:12 Training value function...
2017/08/30 03:28:15 step 0: mse=162464.197417 step=0.050000
2017/08/30 03:28:16 step 1: mse=161971.772791 step=0.050000
2017/08/30 03:28:17 step 2: mse=161560.805859 step=0.050000
2017/08/30 03:28:18 step 3: mse=161756.144357 step=0.050000
2017/08/30 03:28:19 step 4: mse=161470.898994 step=0.050000
2017/08/30 03:28:20 step 5: mse=161628.216552 step=0.050000
2017/08/30 03:28:21 step 6: mse=161507.615569 step=0.050000
2017/08/30 03:28:22 step 7: mse=161400.435289 step=0.050000
2017/08/30 03:28:22 Saving...
2017/08/30 03:28:22 Gathering batch of experience...
2017/08/30 03:28:55 batch 629: mean=6905.645161 stddev=8454.901016 entropy=0.404335 frames=6975 count=31
2017/08/30 03:28:55 Training policy...
2017/08/30 03:29:00 tune 0: objective=59.489323 reg=0.004043 prune=0
2017/08/30 03:29:02 step 0: objective=59.618015 reg=0.004041
2017/08/30 03:29:03 step 1: objective=59.702616 reg=0.004041
2017/08/30 03:29:05 step 2: objective=59.779727 reg=0.004040
2017/08/30 03:29:06 step 3: objective=59.841210 reg=0.004040
2017/08/30 03:29:08 step 4: objective=59.881259 reg=0.004039
2017/08/30 03:29:09 step 5: objective=59.915797 reg=0.004039
2017/08/30 03:29:11 step 6: objective=59.959651 reg=0.004038
2017/08/30 03:29:13 step 7: objective=59.995824 reg=0.004038
2017/08/30 03:29:13 Training value function...
2017/08/30 03:29:15 step 0: mse=170223.695250 step=0.050000
2017/08/30 03:29:16 step 1: mse=169973.916317 step=0.050000
2017/08/30 03:29:18 step 2: mse=169692.481151 step=0.050000
2017/08/30 03:29:19 step 3: mse=169548.072050 step=0.050000
2017/08/30 03:29:20 step 4: mse=168030.865035 step=0.050000
2017/08/30 03:29:21 step 5: mse=169695.650471 step=0.050000
2017/08/30 03:29:22 step 6: mse=169510.273550 step=0.050000
2017/08/30 03:29:23 step 7: mse=169474.381928 step=0.050000
2017/08/30 03:29:23 Saving...
2017/08/30 03:29:23 Gathering batch of experience...
2017/08/30 03:29:54 batch 630: mean=9209.583333 stddev=9468.593691 entropy=0.407715 frames=6439 count=24
2017/08/30 03:29:54 Training policy...
2017/08/30 03:29:59 tune 0: objective=82.563364 reg=0.004077 prune=0
2017/08/30 03:30:00 step 0: objective=82.714115 reg=0.004076
2017/08/30 03:30:01 step 1: objective=82.858227 reg=0.004076
2017/08/30 03:30:03 step 2: objective=82.928657 reg=0.004075
2017/08/30 03:30:04 step 3: objective=83.023431 reg=0.004075
2017/08/30 03:30:06 step 4: objective=83.082049 reg=0.004075
2017/08/30 03:30:07 step 5: objective=83.122816 reg=0.004074
2017/08/30 03:30:08 step 6: objective=83.164146 reg=0.004074
2017/08/30 03:30:10 step 7: objective=83.198643 reg=0.004074
2017/08/30 03:30:10 Training value function...
2017/08/30 03:30:12 step 0: mse=203827.081864 step=0.050000
2017/08/30 03:30:13 step 1: mse=201957.951746 step=0.050000
2017/08/30 03:30:14 step 2: mse=200515.101942 step=0.050000
2017/08/30 03:30:16 step 3: mse=198954.165793 step=0.050000
2017/08/30 03:30:17 step 4: mse=197761.902725 step=0.050000
2017/08/30 03:30:18 step 5: mse=196406.415435 step=0.050000
2017/08/30 03:30:19 step 6: mse=194783.314586 step=0.050000
2017/08/30 03:30:20 step 7: mse=193002.763072 step=0.050000
2017/08/30 03:30:20 Saving...
2017/08/30 03:30:20 Gathering batch of experience...
2017/08/30 03:30:51 batch 631: mean=5099.411765 stddev=7236.349092 entropy=0.403258 frames=6421 count=34
2017/08/30 03:30:51 Training policy...
2017/08/30 03:30:56 tune 0: objective=33.231214 reg=0.004033 prune=0
2017/08/30 03:30:57 step 0: objective=33.376112 reg=0.004033
2017/08/30 03:30:58 step 1: objective=33.496350 reg=0.004033
2017/08/30 03:31:00 step 2: objective=33.560047 reg=0.004034
2017/08/30 03:31:01 step 3: objective=33.610324 reg=0.004034
2017/08/30 03:31:03 step 4: objective=33.668600 reg=0.004034
2017/08/30 03:31:04 step 5: objective=33.717830 reg=0.004033
2017/08/30 03:31:05 step 6: objective=33.761610 reg=0.004032
2017/08/30 03:31:07 step 7: objective=33.835381 reg=0.004033
2017/08/30 03:31:07 Training value function...
2017/08/30 03:31:09 step 0: mse=171787.143388 step=0.050000
2017/08/30 03:31:10 step 1: mse=171828.791943 step=0.050000
2017/08/30 03:31:11 step 2: mse=172198.730049 step=0.050000
2017/08/30 03:31:13 step 3: mse=172169.689907 step=0.050000
2017/08/30 03:31:14 step 4: mse=173664.438248 step=0.050000
2017/08/30 03:31:15 step 5: mse=174336.057482 step=0.050000
2017/08/30 03:31:16 step 6: mse=174562.837566 step=0.050000
2017/08/30 03:31:17 step 7: mse=174960.063401 step=0.050000
2017/08/30 03:31:17 Saving...
2017/08/30 03:31:17 Gathering batch of experience...
2017/08/30 03:31:45 batch 632: mean=7383.846154 stddev=8437.024210 entropy=0.401699 frames=6267 count=26
2017/08/30 03:31:45 Training policy...
2017/08/30 03:31:50 tune 0: objective=63.649653 reg=0.004017 prune=0
2017/08/30 03:31:51 step 0: objective=63.826073 reg=0.004014
2017/08/30 03:31:52 step 1: objective=63.937445 reg=0.004014
2017/08/30 03:31:54 step 2: objective=64.024937 reg=0.004014
2017/08/30 03:31:55 step 3: objective=64.087382 reg=0.004015
2017/08/30 03:31:56 step 4: objective=64.145948 reg=0.004014
2017/08/30 03:31:58 step 5: objective=64.179352 reg=0.004015
2017/08/30 03:31:59 step 6: objective=64.229361 reg=0.004015
2017/08/30 03:32:00 step 7: objective=64.298772 reg=0.004015
2017/08/30 03:32:00 Training value function...
2017/08/30 03:32:03 step 0: mse=159873.572811 step=0.050000
2017/08/30 03:32:04 step 1: mse=159156.090188 step=0.050000
2017/08/30 03:32:05 step 2: mse=159069.208308 step=0.050000
2017/08/30 03:32:06 step 3: mse=158676.085001 step=0.050000
2017/08/30 03:32:07 step 4: mse=158129.952124 step=0.050000
2017/08/30 03:32:08 step 5: mse=157230.193377 step=0.050000
2017/08/30 03:32:09 step 6: mse=157201.835344 step=0.050000
2017/08/30 03:32:10 step 7: mse=156035.072214 step=0.050000
2017/08/30 03:32:10 Saving...
2017/08/30 03:32:10 Gathering batch of experience...
2017/08/30 03:32:41 batch 633: mean=9275.208333 stddev=8908.804923 entropy=0.402840 frames=6772 count=24
2017/08/30 03:32:41 Training policy...
2017/08/30 03:32:46 tune 0: objective=66.026686 reg=0.004028 prune=0
2017/08/30 03:32:47 step 0: objective=66.108849 reg=0.004030
2017/08/30 03:32:49 step 1: objective=66.188718 reg=0.004031
2017/08/30 03:32:50 step 2: objective=66.267452 reg=0.004032
2017/08/30 03:32:52 step 3: objective=66.325799 reg=0.004034
2017/08/30 03:32:53 step 4: objective=66.377035 reg=0.004034
2017/08/30 03:32:55 step 5: objective=66.424750 reg=0.004035
2017/08/30 03:32:56 step 6: objective=66.474910 reg=0.004035
2017/08/30 03:32:58 step 7: objective=66.523290 reg=0.004035
2017/08/30 03:32:58 Training value function...
2017/08/30 03:33:00 step 0: mse=172385.357578 step=0.050000
2017/08/30 03:33:02 step 1: mse=173080.124410 step=0.050000
2017/08/30 03:33:03 step 2: mse=172510.123740 step=0.050000
2017/08/30 03:33:04 step 3: mse=171949.082603 step=0.050000
2017/08/30 03:33:05 step 4: mse=171427.331617 step=0.050000
2017/08/30 03:33:06 step 5: mse=170844.745650 step=0.050000
2017/08/30 03:33:07 step 6: mse=170228.686270 step=0.050000
2017/08/30 03:33:08 step 7: mse=170805.090026 step=0.050000
2017/08/30 03:33:08 Saving...
2017/08/30 03:33:08 Gathering batch of experience...
2017/08/30 03:33:37 batch 634: mean=5958.500000 stddev=7907.765924 entropy=0.401172 frames=6252 count=30
2017/08/30 03:33:37 Training policy...
2017/08/30 03:33:42 tune 0: objective=48.831979 reg=0.004012 prune=0
2017/08/30 03:33:43 step 0: objective=49.029531 reg=0.004010
2017/08/30 03:33:44 step 1: objective=49.095659 reg=0.004010
2017/08/30 03:33:46 step 2: objective=49.215111 reg=0.004009
2017/08/30 03:33:47 step 3: objective=49.289227 reg=0.004009
2017/08/30 03:33:48 step 4: objective=49.375460 reg=0.004009
2017/08/30 03:33:50 step 5: objective=49.446977 reg=0.004008
2017/08/30 03:33:51 step 6: objective=49.500780 reg=0.004006
2017/08/30 03:33:52 step 7: objective=49.557142 reg=0.004005
2017/08/30 03:33:52 Training value function...
2017/08/30 03:33:55 step 0: mse=163512.925340 step=0.050000
2017/08/30 03:33:56 step 1: mse=162777.062110 step=0.050000
2017/08/30 03:33:57 step 2: mse=162002.958369 step=0.050000
2017/08/30 03:33:58 step 3: mse=162612.865505 step=0.050000
2017/08/30 03:33:59 step 4: mse=162572.237235 step=0.050000
2017/08/30 03:34:00 step 5: mse=161735.785092 step=0.050000
2017/08/30 03:34:01 step 6: mse=162308.065105 step=0.050000
2017/08/30 03:34:02 step 7: mse=163223.752835 step=0.050000
2017/08/30 03:34:02 Saving...
2017/08/30 03:34:02 Gathering batch of experience...
2017/08/30 03:34:33 batch 635: mean=8020.925926 stddev=9292.827186 entropy=0.405745 frames=6554 count=27
2017/08/30 03:34:33 Training policy...
2017/08/30 03:34:38 tune 0: objective=74.259498 reg=0.004057 prune=0
2017/08/30 03:34:39 step 0: objective=74.304962 reg=0.004057
2017/08/30 03:34:41 step 1: objective=74.339373 reg=0.004056
2017/08/30 03:34:42 step 2: objective=74.374132 reg=0.004056
2017/08/30 03:34:43 step 3: objective=74.414208 reg=0.004055
2017/08/30 03:34:45 step 4: objective=74.446383 reg=0.004055
2017/08/30 03:34:46 step 5: objective=74.488485 reg=0.004054
2017/08/30 03:34:48 step 6: objective=74.523235 reg=0.004054
2017/08/30 03:34:49 step 7: objective=74.565852 reg=0.004053
2017/08/30 03:34:49 Training value function...
2017/08/30 03:34:52 step 0: mse=171218.621522 step=0.050000
2017/08/30 03:34:53 step 1: mse=170445.950859 step=0.050000
2017/08/30 03:34:54 step 2: mse=167700.799523 step=0.050000
2017/08/30 03:34:55 step 3: mse=165536.944376 step=0.050000
2017/08/30 03:34:56 step 4: mse=164447.769992 step=0.050000
2017/08/30 03:34:57 step 5: mse=162121.241662 step=0.050000
2017/08/30 03:34:58 step 6: mse=159392.697038 step=0.050000
2017/08/30 03:34:59 step 7: mse=156449.381510 step=0.050000
2017/08/30 03:34:59 Saving...
2017/08/30 03:34:59 Gathering batch of experience...
2017/08/30 03:35:32 batch 636: mean=6570.312500 stddev=8275.444280 entropy=0.403306 frames=7008 count=32
2017/08/30 03:35:32 Training policy...
2017/08/30 03:35:37 tune 0: objective=55.630570 reg=0.004033 prune=0
2017/08/30 03:35:39 step 0: objective=55.729394 reg=0.004032
2017/08/30 03:35:40 step 1: objective=55.836691 reg=0.004032
2017/08/30 03:35:42 step 2: objective=55.943841 reg=0.004032
2017/08/30 03:35:43 step 3: objective=55.997258 reg=0.004033
2017/08/30 03:35:45 step 4: objective=56.075271 reg=0.004032
2017/08/30 03:35:46 step 5: objective=56.127234 reg=0.004031
2017/08/30 03:35:48 step 6: objective=56.174328 reg=0.004031
2017/08/30 03:35:49 step 7: objective=56.213372 reg=0.004031
2017/08/30 03:35:49 Training value function...
2017/08/30 03:35:52 step 0: mse=170462.640708 step=0.050000
2017/08/30 03:35:53 step 1: mse=171758.111173 step=0.050000
2017/08/30 03:35:54 step 2: mse=172520.705266 step=0.050000
2017/08/30 03:35:56 step 3: mse=174251.792781 step=0.050000
2017/08/30 03:35:57 step 4: mse=174773.789561 step=0.050000
2017/08/30 03:35:58 step 5: mse=174161.938408 step=0.050000
2017/08/30 03:35:59 step 6: mse=173221.571899 step=0.050000
2017/08/30 03:36:00 step 7: mse=172412.872002 step=0.050000
2017/08/30 03:36:00 Saving...
2017/08/30 03:36:00 Gathering batch of experience...
2017/08/30 03:36:33 batch 637: mean=8760.714286 stddev=8991.332703 entropy=0.403283 frames=7314 count=28
2017/08/30 03:36:33 Training policy...
2017/08/30 03:36:39 tune 0: objective=69.595673 reg=0.004033 prune=0
2017/08/30 03:36:40 step 0: objective=69.759229 reg=0.004032
2017/08/30 03:36:42 step 1: objective=69.882058 reg=0.004033
2017/08/30 03:36:44 step 2: objective=69.966686 reg=0.004033
2017/08/30 03:36:45 step 3: objective=70.058065 reg=0.004032
2017/08/30 03:36:47 step 4: objective=70.131020 reg=0.004032
2017/08/30 03:36:48 step 5: objective=70.210645 reg=0.004031
2017/08/30 03:36:50 step 6: objective=70.266813 reg=0.004030
2017/08/30 03:36:51 step 7: objective=70.308753 reg=0.004029
2017/08/30 03:36:51 Training value function...
2017/08/30 03:36:54 step 0: mse=244914.858940 step=0.050000
2017/08/30 03:36:56 step 1: mse=243996.740348 step=0.050000
2017/08/30 03:36:57 step 2: mse=243177.525565 step=0.050000
2017/08/30 03:36:58 step 3: mse=239728.991522 step=0.050000
2017/08/30 03:36:59 step 4: mse=239875.635416 step=0.050000
2017/08/30 03:37:01 step 5: mse=237451.652378 step=0.050000
2017/08/30 03:37:02 step 6: mse=237992.982777 step=0.050000
2017/08/30 03:37:03 step 7: mse=235728.052153 step=0.050000
2017/08/30 03:37:03 Saving...
2017/08/30 03:37:03 Gathering batch of experience...
2017/08/30 03:37:35 batch 638: mean=6920.833333 stddev=8510.240996 entropy=0.402885 frames=6914 count=30
2017/08/30 03:37:35 Training policy...
2017/08/30 03:37:40 tune 0: objective=53.328817 reg=0.004029 prune=0
2017/08/30 03:37:41 step 0: objective=53.392460 reg=0.004028
2017/08/30 03:37:43 step 1: objective=53.434268 reg=0.004028
2017/08/30 03:37:44 step 2: objective=53.506147 reg=0.004029
2017/08/30 03:37:46 step 3: objective=53.555431 reg=0.004029
2017/08/30 03:37:47 step 4: objective=53.624277 reg=0.004029
2017/08/30 03:37:49 step 5: objective=53.666352 reg=0.004029
2017/08/30 03:37:50 step 6: objective=53.719446 reg=0.004029
2017/08/30 03:37:52 step 7: objective=53.742836 reg=0.004029
2017/08/30 03:37:52 Training value function...
2017/08/30 03:37:55 step 0: mse=142289.075617 step=0.050000
2017/08/30 03:37:56 step 1: mse=141306.004022 step=0.050000
2017/08/30 03:37:57 step 2: mse=141345.797885 step=0.050000
2017/08/30 03:37:58 step 3: mse=140478.699093 step=0.050000
2017/08/30 03:37:59 step 4: mse=139491.251382 step=0.050000
2017/08/30 03:38:00 step 5: mse=138693.940603 step=0.050000
2017/08/30 03:38:01 step 6: mse=138101.898296 step=0.050000
2017/08/30 03:38:03 step 7: mse=137291.621216 step=0.050000
2017/08/30 03:38:03 Saving...
2017/08/30 03:38:03 Gathering batch of experience...
2017/08/30 03:38:33 batch 639: mean=7697.222222 stddev=8849.504834 entropy=0.404707 frames=6408 count=27
2017/08/30 03:38:33 Training policy...
2017/08/30 03:38:38 tune 0: objective=67.404470 reg=0.004047 prune=0
2017/08/30 03:38:39 step 0: objective=67.587542 reg=0.004047
2017/08/30 03:38:41 step 1: objective=67.692143 reg=0.004046
2017/08/30 03:38:42 step 2: objective=67.804653 reg=0.004045
2017/08/30 03:38:43 step 3: objective=67.906640 reg=0.004045
2017/08/30 03:38:45 step 4: objective=68.022199 reg=0.004045
2017/08/30 03:38:46 step 5: objective=68.074570 reg=0.004045
2017/08/30 03:38:48 step 6: objective=68.163516 reg=0.004045
2017/08/30 03:38:49 step 7: objective=68.248893 reg=0.004045
2017/08/30 03:38:49 Training value function...
2017/08/30 03:38:52 step 0: mse=240327.633875 step=0.050000
2017/08/30 03:38:53 step 1: mse=241631.799628 step=0.050000
2017/08/30 03:38:54 step 2: mse=241271.398454 step=0.050000
2017/08/30 03:38:55 step 3: mse=240920.430815 step=0.050000
2017/08/30 03:38:56 step 4: mse=240733.220467 step=0.050000
2017/08/30 03:38:57 step 5: mse=239204.949365 step=0.050000
2017/08/30 03:38:58 step 6: mse=237994.997303 step=0.050000
2017/08/30 03:38:59 step 7: mse=237863.431968 step=0.050000
2017/08/30 03:38:59 Saving...
2017/08/30 03:38:59 Gathering batch of experience...
2017/08/30 03:39:30 batch 640: mean=5490.000000 stddev=7972.859767 entropy=0.402891 frames=6621 count=35
2017/08/30 03:39:30 Training policy...
2017/08/30 03:39:35 tune 0: objective=48.469699 reg=0.004029 prune=0
2017/08/30 03:39:37 step 0: objective=48.516949 reg=0.004029
2017/08/30 03:39:38 step 1: objective=48.566441 reg=0.004028
2017/08/30 03:39:40 step 2: objective=48.605469 reg=0.004027
2017/08/30 03:39:41 step 3: objective=48.666398 reg=0.004028
2017/08/30 03:39:42 step 4: objective=48.702245 reg=0.004027
2017/08/30 03:39:44 step 5: objective=48.740697 reg=0.004027
2017/08/30 03:39:45 step 6: objective=48.780079 reg=0.004027
2017/08/30 03:39:47 step 7: objective=48.826895 reg=0.004026
2017/08/30 03:39:47 Training value function...
2017/08/30 03:39:50 step 0: mse=143355.842304 step=0.050000
2017/08/30 03:39:51 step 1: mse=145317.399989 step=0.050000
2017/08/30 03:39:52 step 2: mse=144348.574145 step=0.050000
2017/08/30 03:39:53 step 3: mse=143711.847092 step=0.050000
2017/08/30 03:39:54 step 4: mse=144835.766502 step=0.050000
2017/08/30 03:39:55 step 5: mse=146119.337878 step=0.050000
2017/08/30 03:39:56 step 6: mse=145509.638296 step=0.050000
2017/08/30 03:39:57 step 7: mse=144783.724671 step=0.050000
2017/08/30 03:39:57 Saving...
2017/08/30 03:39:57 Gathering batch of experience...
2017/08/30 03:40:28 batch 641: mean=7900.000000 stddev=8817.035849 entropy=0.401680 frames=6594 count=26
2017/08/30 03:40:28 Training policy...
2017/08/30 03:40:33 tune 0: objective=62.767113 reg=0.004017 prune=0
2017/08/30 03:40:35 step 0: objective=62.861062 reg=0.004016
2017/08/30 03:40:36 step 1: objective=62.936391 reg=0.004016
2017/08/30 03:40:37 step 2: objective=63.006014 reg=0.004015
2017/08/30 03:40:39 step 3: objective=63.082978 reg=0.004014
2017/08/30 03:40:40 step 4: objective=63.134388 reg=0.004014
2017/08/30 03:40:42 step 5: objective=63.188410 reg=0.004013
2017/08/30 03:40:43 step 6: objective=63.234010 reg=0.004014
2017/08/30 03:40:45 step 7: objective=63.283918 reg=0.004014
2017/08/30 03:40:45 Training value function...
2017/08/30 03:40:47 step 0: mse=159979.122534 step=0.050000
2017/08/30 03:40:48 step 1: mse=159619.515226 step=0.050000
2017/08/30 03:40:49 step 2: mse=160007.816078 step=0.050000
2017/08/30 03:40:51 step 3: mse=158860.720934 step=0.050000
2017/08/30 03:40:52 step 4: mse=158388.258948 step=0.050000
2017/08/30 03:40:53 step 5: mse=158525.790235 step=0.050000
2017/08/30 03:40:54 step 6: mse=158725.621107 step=0.050000
2017/08/30 03:40:55 step 7: mse=158117.075736 step=0.050000
2017/08/30 03:40:55 Saving...
2017/08/30 03:40:55 Gathering batch of experience...
2017/08/30 03:41:25 batch 642: mean=6094.666667 stddev=8167.687242 entropy=0.400898 frames=6150 count=30
2017/08/30 03:41:25 Training policy...
2017/08/30 03:41:30 tune 0: objective=51.840884 reg=0.004009 prune=0
2017/08/30 03:41:31 step 0: objective=51.926550 reg=0.004009
2017/08/30 03:41:33 step 1: objective=52.023836 reg=0.004008
2017/08/30 03:41:34 step 2: objective=52.105183 reg=0.004007
2017/08/30 03:41:35 step 3: objective=52.183699 reg=0.004007
2017/08/30 03:41:37 step 4: objective=52.253526 reg=0.004007
2017/08/30 03:41:38 step 5: objective=52.292840 reg=0.004006
2017/08/30 03:41:39 step 6: objective=52.358181 reg=0.004005
2017/08/30 03:41:41 step 7: objective=52.399522 reg=0.004005
2017/08/30 03:41:41 Training value function...
2017/08/30 03:41:43 step 0: mse=176332.302985 step=0.050000
2017/08/30 03:41:44 step 1: mse=175597.004142 step=0.050000
2017/08/30 03:41:45 step 2: mse=175798.659772 step=0.050000
2017/08/30 03:41:46 step 3: mse=176548.736956 step=0.050000
2017/08/30 03:41:47 step 4: mse=177434.671621 step=0.050000
2017/08/30 03:41:48 step 5: mse=177647.682478 step=0.050000
2017/08/30 03:41:49 step 6: mse=176175.209118 step=0.050000
2017/08/30 03:41:50 step 7: mse=176866.825172 step=0.050000
2017/08/30 03:41:50 Saving...
2017/08/30 03:41:50 Gathering batch of experience...
2017/08/30 03:42:20 batch 643: mean=7316.538462 stddev=8445.330727 entropy=0.398436 frames=6347 count=26
2017/08/30 03:42:20 Training policy...
2017/08/30 03:42:25 tune 0: objective=54.239237 reg=0.003984 prune=0
2017/08/30 03:42:26 step 0: objective=54.347699 reg=0.003983
2017/08/30 03:42:28 step 1: objective=54.446343 reg=0.003983
2017/08/30 03:42:29 step 2: objective=54.515435 reg=0.003984
2017/08/30 03:42:31 step 3: objective=54.583435 reg=0.003985
2017/08/30 03:42:32 step 4: objective=54.639786 reg=0.003984
2017/08/30 03:42:33 step 5: objective=54.690833 reg=0.003984
2017/08/30 03:42:35 step 6: objective=54.742171 reg=0.003984
2017/08/30 03:42:36 step 7: objective=54.783943 reg=0.003984
2017/08/30 03:42:36 Training value function...
2017/08/30 03:42:39 step 0: mse=144029.025059 step=0.050000
2017/08/30 03:42:40 step 1: mse=143736.467737 step=0.050000
2017/08/30 03:42:41 step 2: mse=142938.629682 step=0.050000
2017/08/30 03:42:42 step 3: mse=142922.093556 step=0.050000
2017/08/30 03:42:43 step 4: mse=142554.516406 step=0.050000
2017/08/30 03:42:44 step 5: mse=142517.291751 step=0.050000
2017/08/30 03:42:45 step 6: mse=143418.841569 step=0.050000
2017/08/30 03:42:46 step 7: mse=143360.996911 step=0.050000
2017/08/30 03:42:46 Saving...
2017/08/30 03:42:46 Gathering batch of experience...
2017/08/30 03:43:15 batch 644: mean=5120.156250 stddev=7413.243901 entropy=0.398161 frames=5804 count=32
2017/08/30 03:43:15 Training policy...
2017/08/30 03:43:19 tune 0: objective=44.053037 reg=0.003982 prune=0
2017/08/30 03:43:20 step 0: objective=44.211091 reg=0.003980
2017/08/30 03:43:22 step 1: objective=44.314446 reg=0.003978
2017/08/30 03:43:23 step 2: objective=44.392520 reg=0.003977
2017/08/30 03:43:24 step 3: objective=44.449243 reg=0.003977
2017/08/30 03:43:25 step 4: objective=44.518508 reg=0.003975
2017/08/30 03:43:27 step 5: objective=44.581035 reg=0.003975
2017/08/30 03:43:28 step 6: objective=44.610786 reg=0.003974
2017/08/30 03:43:29 step 7: objective=44.678850 reg=0.003973
2017/08/30 03:43:29 Training value function...
2017/08/30 03:43:32 step 0: mse=219760.028635 step=0.050000
2017/08/30 03:43:32 step 1: mse=219651.665323 step=0.050000
2017/08/30 03:43:33 step 2: mse=217054.427097 step=0.050000
2017/08/30 03:43:34 step 3: mse=213667.955787 step=0.050000
2017/08/30 03:43:35 step 4: mse=211302.916707 step=0.050000
2017/08/30 03:43:36 step 5: mse=209911.277939 step=0.050000
2017/08/30 03:43:37 step 6: mse=207417.130719 step=0.050000
2017/08/30 03:43:38 step 7: mse=203330.371122 step=0.050000
2017/08/30 03:43:38 Saving...
2017/08/30 03:43:38 Gathering batch of experience...
2017/08/30 03:44:11 batch 645: mean=7269.482759 stddev=8857.775986 entropy=0.401478 frames=6928 count=29
2017/08/30 03:44:11 Training policy...
2017/08/30 03:44:16 tune 0: objective=69.073497 reg=0.004015 prune=0
2017/08/30 03:44:18 step 0: objective=69.253839 reg=0.004012
2017/08/30 03:44:19 step 1: objective=69.341071 reg=0.004011
2017/08/30 03:44:21 step 2: objective=69.442281 reg=0.004010
2017/08/30 03:44:22 step 3: objective=69.530664 reg=0.004011
2017/08/30 03:44:24 step 4: objective=69.596285 reg=0.004010
2017/08/30 03:44:25 step 5: objective=69.638361 reg=0.004010
2017/08/30 03:44:27 step 6: objective=69.672479 reg=0.004010
2017/08/30 03:44:28 step 7: objective=69.700008 reg=0.004010
2017/08/30 03:44:28 Training value function...
2017/08/30 03:44:31 step 0: mse=161052.275372 step=0.050000
2017/08/30 03:44:32 step 1: mse=159759.115948 step=0.050000
2017/08/30 03:44:33 step 2: mse=159019.723360 step=0.050000
2017/08/30 03:44:35 step 3: mse=157867.482815 step=0.050000
2017/08/30 03:44:36 step 4: mse=156197.844509 step=0.050000
2017/08/30 03:44:37 step 5: mse=155240.950507 step=0.050000
2017/08/30 03:44:38 step 6: mse=153060.318376 step=0.050000
2017/08/30 03:44:39 step 7: mse=152764.538019 step=0.050000
2017/08/30 03:44:39 Saving...
2017/08/30 03:44:39 Gathering batch of experience...
2017/08/30 03:45:08 batch 646: mean=5132.121212 stddev=7717.461805 entropy=0.396246 frames=6031 count=33
2017/08/30 03:45:08 Training policy...
2017/08/30 03:45:13 tune 0: objective=55.066858 reg=0.003962 prune=0
2017/08/30 03:45:14 step 0: objective=55.155742 reg=0.003962
2017/08/30 03:45:15 step 1: objective=55.259125 reg=0.003961
2017/08/30 03:45:17 step 2: objective=55.349201 reg=0.003960
2017/08/30 03:45:18 step 3: objective=55.404955 reg=0.003960
2017/08/30 03:45:19 step 4: objective=55.456174 reg=0.003960
2017/08/30 03:45:21 step 5: objective=55.493041 reg=0.003959
2017/08/30 03:45:22 step 6: objective=55.535670 reg=0.003960
2017/08/30 03:45:23 step 7: objective=55.586802 reg=0.003959
2017/08/30 03:45:23 Training value function...
2017/08/30 03:45:26 step 0: mse=202317.902527 step=0.050000
2017/08/30 03:45:27 step 1: mse=200376.140648 step=0.050000
2017/08/30 03:45:28 step 2: mse=197320.796016 step=0.050000
2017/08/30 03:45:29 step 3: mse=195530.075237 step=0.050000
2017/08/30 03:45:30 step 4: mse=196125.581435 step=0.050000
2017/08/30 03:45:30 step 5: mse=193978.395381 step=0.050000
2017/08/30 03:45:31 step 6: mse=189537.022763 step=0.050000
2017/08/30 03:45:32 step 7: mse=189252.931903 step=0.050000
2017/08/30 03:45:32 Saving...
2017/08/30 03:45:32 Gathering batch of experience...
2017/08/30 03:46:03 batch 647: mean=8054.107143 stddev=9016.314088 entropy=0.399786 frames=6930 count=28
2017/08/30 03:46:03 Training policy...
2017/08/30 03:46:09 tune 0: objective=68.489610 reg=0.003998 prune=0
2017/08/30 03:46:10 step 0: objective=68.593592 reg=0.003998
2017/08/30 03:46:12 step 1: objective=68.680605 reg=0.003999
2017/08/30 03:46:13 step 2: objective=68.736526 reg=0.004000
2017/08/30 03:46:15 step 3: objective=68.802688 reg=0.003999
2017/08/30 03:46:16 step 4: objective=68.854582 reg=0.003999
2017/08/30 03:46:18 step 5: objective=68.907711 reg=0.003998
2017/08/30 03:46:19 step 6: objective=68.948801 reg=0.003997
2017/08/30 03:46:21 step 7: objective=68.980596 reg=0.003997
2017/08/30 03:46:21 Training value function...
2017/08/30 03:46:24 step 0: mse=191289.094075 step=0.050000
2017/08/30 03:46:25 step 1: mse=190369.601626 step=0.050000
2017/08/30 03:46:26 step 2: mse=190056.865914 step=0.050000
2017/08/30 03:46:27 step 3: mse=190327.597133 step=0.050000
2017/08/30 03:46:28 step 4: mse=189901.621042 step=0.050000
2017/08/30 03:46:29 step 5: mse=189084.215682 step=0.050000
2017/08/30 03:46:30 step 6: mse=187714.207083 step=0.050000
2017/08/30 03:46:31 step 7: mse=187784.461814 step=0.050000
2017/08/30 03:46:31 Saving...
2017/08/30 03:46:32 Gathering batch of experience...
2017/08/30 03:47:02 batch 648: mean=10532.954545 stddev=9637.766817 entropy=0.402815 frames=6458 count=22
2017/08/30 03:47:02 Training policy...
2017/08/30 03:47:07 tune 0: objective=77.852441 reg=0.004028 prune=0
2017/08/30 03:47:09 step 0: objective=77.981970 reg=0.004027
2017/08/30 03:47:10 step 1: objective=78.079741 reg=0.004028
2017/08/30 03:47:11 step 2: objective=78.142198 reg=0.004028
2017/08/30 03:47:13 step 3: objective=78.233698 reg=0.004028
2017/08/30 03:47:14 step 4: objective=78.295089 reg=0.004028
2017/08/30 03:47:16 step 5: objective=78.349141 reg=0.004027
2017/08/30 03:47:17 step 6: objective=78.412192 reg=0.004027
2017/08/30 03:47:18 step 7: objective=78.463495 reg=0.004027
2017/08/30 03:47:18 Training value function...
2017/08/30 03:47:21 step 0: mse=174640.172885 step=0.050000
2017/08/30 03:47:22 step 1: mse=175422.409625 step=0.050000
2017/08/30 03:47:23 step 2: mse=174639.254253 step=0.050000
2017/08/30 03:47:24 step 3: mse=172735.995569 step=0.050000
2017/08/30 03:47:25 step 4: mse=170643.563973 step=0.050000
2017/08/30 03:47:26 step 5: mse=169497.720724 step=0.050000
2017/08/30 03:47:27 step 6: mse=168856.677905 step=0.050000
2017/08/30 03:47:28 step 7: mse=168426.925891 step=0.050000
2017/08/30 03:47:28 Saving...
2017/08/30 03:47:29 Gathering batch of experience...
2017/08/30 03:48:00 batch 649: mean=6362.833333 stddev=8221.360662 entropy=0.396233 frames=6681 count=30
2017/08/30 03:48:00 Training policy...
2017/08/30 03:48:05 tune 0: objective=45.400408 reg=0.003962 prune=0
2017/08/30 03:48:06 step 0: objective=45.454788 reg=0.003962
2017/08/30 03:48:08 step 1: objective=45.496155 reg=0.003962
2017/08/30 03:48:09 step 2: objective=45.535198 reg=0.003960
2017/08/30 03:48:11 step 3: objective=45.594325 reg=0.003959
2017/08/30 03:48:12 step 4: objective=45.637840 reg=0.003959
2017/08/30 03:48:14 step 5: objective=45.682214 reg=0.003958
2017/08/30 03:48:15 step 6: objective=45.719919 reg=0.003957
2017/08/30 03:48:17 step 7: objective=45.760183 reg=0.003956
2017/08/30 03:48:17 Training value function...
2017/08/30 03:48:19 step 0: mse=136586.178521 step=0.050000
2017/08/30 03:48:20 step 1: mse=136128.738297 step=0.050000
2017/08/30 03:48:22 step 2: mse=135926.680716 step=0.050000
2017/08/30 03:48:23 step 3: mse=136396.250480 step=0.050000
2017/08/30 03:48:24 step 4: mse=136385.448064 step=0.050000
2017/08/30 03:48:25 step 5: mse=136084.320693 step=0.050000
2017/08/30 03:48:26 step 6: mse=136237.463276 step=0.050000
2017/08/30 03:48:27 step 7: mse=137335.103672 step=0.050000
2017/08/30 03:48:27 Saving...
2017/08/30 03:48:27 Gathering batch of experience...
2017/08/30 03:48:57 batch 650: mean=7715.961538 stddev=8849.048517 entropy=0.401533 frames=6234 count=26
2017/08/30 03:48:57 Training policy...
2017/08/30 03:49:01 tune 0: objective=64.486861 reg=0.004015 prune=0
2017/08/30 03:49:03 step 0: objective=64.561934 reg=0.004014
2017/08/30 03:49:04 step 1: objective=64.663283 reg=0.004013
2017/08/30 03:49:06 step 2: objective=64.733092 reg=0.004013
2017/08/30 03:49:07 step 3: objective=64.811307 reg=0.004014
2017/08/30 03:49:08 step 4: objective=64.862984 reg=0.004012
2017/08/30 03:49:10 step 5: objective=64.934873 reg=0.004011
2017/08/30 03:49:11 step 6: objective=64.982119 reg=0.004010
2017/08/30 03:49:12 step 7: objective=65.039626 reg=0.004009
2017/08/30 03:49:12 Training value function...
2017/08/30 03:49:15 step 0: mse=171272.319760 step=0.050000
2017/08/30 03:49:16 step 1: mse=171838.328452 step=0.050000
2017/08/30 03:49:17 step 2: mse=170475.833508 step=0.050000
2017/08/30 03:49:18 step 3: mse=169875.572638 step=0.050000
2017/08/30 03:49:19 step 4: mse=170400.727960 step=0.050000
2017/08/30 03:49:20 step 5: mse=170174.063374 step=0.050000
2017/08/30 03:49:21 step 6: mse=169489.994973 step=0.050000
2017/08/30 03:49:22 step 7: mse=169773.151212 step=0.050000
2017/08/30 03:49:22 Saving...
2017/08/30 03:49:22 Gathering batch of experience...
2017/08/30 03:49:52 batch 651: mean=6147.000000 stddev=8262.646025 entropy=0.397547 frames=6239 count=30
2017/08/30 03:49:52 Training policy...
2017/08/30 03:49:57 tune 0: objective=55.454290 reg=0.003975 prune=0
2017/08/30 03:49:58 step 0: objective=55.536980 reg=0.003976
2017/08/30 03:50:00 step 1: objective=55.599981 reg=0.003976
2017/08/30 03:50:01 step 2: objective=55.677918 reg=0.003976
2017/08/30 03:50:02 step 3: objective=55.729163 reg=0.003977
2017/08/30 03:50:04 step 4: objective=55.764285 reg=0.003977
2017/08/30 03:50:05 step 5: objective=55.805122 reg=0.003977
2017/08/30 03:50:07 step 6: objective=55.851258 reg=0.003977
2017/08/30 03:50:08 step 7: objective=55.900370 reg=0.003977
2017/08/30 03:50:08 Training value function...
2017/08/30 03:50:11 step 0: mse=163482.964137 step=0.050000
2017/08/30 03:50:12 step 1: mse=163310.898771 step=0.050000
2017/08/30 03:50:13 step 2: mse=164069.946812 step=0.050000
2017/08/30 03:50:14 step 3: mse=163582.274866 step=0.050000
2017/08/30 03:50:15 step 4: mse=162268.034735 step=0.050000
2017/08/30 03:50:16 step 5: mse=161703.879736 step=0.050000
2017/08/30 03:50:17 step 6: mse=161745.004945 step=0.050000
2017/08/30 03:50:18 step 7: mse=161521.472646 step=0.050000
2017/08/30 03:50:18 Saving...
2017/08/30 03:50:18 Gathering batch of experience...
2017/08/30 03:50:49 batch 652: mean=10644.375000 stddev=9637.206255 entropy=0.401882 frames=6972 count=24
2017/08/30 03:50:49 Training policy...
2017/08/30 03:50:55 tune 0: objective=78.217764 reg=0.004019 prune=0
2017/08/30 03:50:56 step 0: objective=78.327049 reg=0.004018
2017/08/30 03:50:58 step 1: objective=78.415582 reg=0.004018
2017/08/30 03:50:59 step 2: objective=78.494953 reg=0.004017
2017/08/30 03:51:01 step 3: objective=78.545494 reg=0.004016
2017/08/30 03:51:02 step 4: objective=78.590057 reg=0.004016
2017/08/30 03:51:04 step 5: objective=78.649858 reg=0.004016
2017/08/30 03:51:06 step 6: objective=78.685169 reg=0.004017
2017/08/30 03:51:07 step 7: objective=78.719844 reg=0.004016
2017/08/30 03:51:07 Training value function...
2017/08/30 03:51:10 step 0: mse=216562.080104 step=0.050000
2017/08/30 03:51:11 step 1: mse=214750.310902 step=0.050000
2017/08/30 03:51:12 step 2: mse=215090.444292 step=0.050000
2017/08/30 03:51:13 step 3: mse=214549.631763 step=0.050000
2017/08/30 03:51:15 step 4: mse=214012.045161 step=0.050000
2017/08/30 03:51:16 step 5: mse=212019.585639 step=0.050000
2017/08/30 03:51:17 step 6: mse=211740.965025 step=0.050000
2017/08/30 03:51:18 step 7: mse=211182.531082 step=0.050000
2017/08/30 03:51:18 Saving...
2017/08/30 03:51:18 Gathering batch of experience...
2017/08/30 03:51:50 batch 653: mean=9715.192308 stddev=9581.863425 entropy=0.401454 frames=7023 count=26
2017/08/30 03:51:50 Training policy...
2017/08/30 03:51:55 tune 0: objective=81.967250 reg=0.004015 prune=0
2017/08/30 03:51:57 step 0: objective=82.054117 reg=0.004014
2017/08/30 03:51:58 step 1: objective=82.126059 reg=0.004014
2017/08/30 03:52:00 step 2: objective=82.206785 reg=0.004014
2017/08/30 03:52:01 step 3: objective=82.247375 reg=0.004015
2017/08/30 03:52:03 step 4: objective=82.300584 reg=0.004015
2017/08/30 03:52:04 step 5: objective=82.353499 reg=0.004016
2017/08/30 03:52:06 step 6: objective=82.401235 reg=0.004018
2017/08/30 03:52:07 step 7: objective=82.431867 reg=0.004017
2017/08/30 03:52:07 Training value function...
2017/08/30 03:52:10 step 0: mse=190945.119115 step=0.050000
2017/08/30 03:52:11 step 1: mse=190524.647638 step=0.050000
2017/08/30 03:52:13 step 2: mse=189023.134110 step=0.050000
2017/08/30 03:52:14 step 3: mse=187161.984136 step=0.050000
2017/08/30 03:52:15 step 4: mse=185635.872732 step=0.050000
2017/08/30 03:52:16 step 5: mse=182968.474207 step=0.050000
2017/08/30 03:52:17 step 6: mse=183222.609794 step=0.050000
2017/08/30 03:52:18 step 7: mse=181904.091913 step=0.050000
2017/08/30 03:52:18 Saving...
2017/08/30 03:52:18 Gathering batch of experience...
2017/08/30 03:52:50 batch 654: mean=8449.800000 stddev=8668.716569 entropy=0.398104 frames=6583 count=25
2017/08/30 03:52:50 Training policy...
2017/08/30 03:52:54 tune 0: objective=50.186878 reg=0.003981 prune=0
2017/08/30 03:52:56 step 0: objective=50.320969 reg=0.003980
2017/08/30 03:52:57 step 1: objective=50.439726 reg=0.003981
2017/08/30 03:52:59 step 2: objective=50.540597 reg=0.003980
2017/08/30 03:53:00 step 3: objective=50.644197 reg=0.003979
2017/08/30 03:53:02 step 4: objective=50.746596 reg=0.003979
2017/08/30 03:53:03 step 5: objective=50.823371 reg=0.003979
2017/08/30 03:53:05 step 6: objective=50.874929 reg=0.003978
2017/08/30 03:53:06 step 7: objective=50.961487 reg=0.003977
2017/08/30 03:53:06 Training value function...
2017/08/30 03:53:09 step 0: mse=196948.920333 step=0.050000
2017/08/30 03:53:10 step 1: mse=197276.326014 step=0.050000
2017/08/30 03:53:11 step 2: mse=197368.809704 step=0.050000
2017/08/30 03:53:12 step 3: mse=197887.845048 step=0.050000
2017/08/30 03:53:13 step 4: mse=198351.826764 step=0.050000
2017/08/30 03:53:14 step 5: mse=200312.786573 step=0.050000
2017/08/30 03:53:15 step 6: mse=200454.736212 step=0.050000
2017/08/30 03:53:16 step 7: mse=200837.237647 step=0.050000
2017/08/30 03:53:16 Saving...
2017/08/30 03:53:16 Gathering batch of experience...
2017/08/30 03:53:48 batch 655: mean=8803.461538 stddev=8973.505422 entropy=0.395427 frames=6971 count=26
2017/08/30 03:53:48 Training policy...
2017/08/30 03:53:54 tune 0: objective=70.887938 reg=0.003954 prune=0
2017/08/30 03:53:55 step 0: objective=71.030533 reg=0.003956
2017/08/30 03:53:57 step 1: objective=71.200675 reg=0.003957
2017/08/30 03:53:58 step 2: objective=71.302651 reg=0.003958
2017/08/30 03:54:00 step 3: objective=71.380240 reg=0.003958
2017/08/30 03:54:01 step 4: objective=71.457996 reg=0.003959
2017/08/30 03:54:03 step 5: objective=71.517084 reg=0.003959
2017/08/30 03:54:05 step 6: objective=71.565463 reg=0.003960
2017/08/30 03:54:06 step 7: objective=71.608391 reg=0.003960
2017/08/30 03:54:06 Training value function...
2017/08/30 03:54:09 step 0: mse=265806.347729 step=0.050000
2017/08/30 03:54:10 step 1: mse=265505.728454 step=0.050000
2017/08/30 03:54:11 step 2: mse=264544.673826 step=0.050000
2017/08/30 03:54:12 step 3: mse=264732.835650 step=0.050000
2017/08/30 03:54:14 step 4: mse=264269.825482 step=0.050000
2017/08/30 03:54:15 step 5: mse=258057.059431 step=0.050000
2017/08/30 03:54:16 step 6: mse=257588.541596 step=0.050000
2017/08/30 03:54:17 step 7: mse=257231.787552 step=0.050000
2017/08/30 03:54:17 Saving...
2017/08/30 03:54:17 Gathering batch of experience...
2017/08/30 03:54:49 batch 656: mean=7870.000000 stddev=8548.510592 entropy=0.396632 frames=6664 count=27
2017/08/30 03:54:49 Training policy...
2017/08/30 03:54:54 tune 0: objective=46.927061 reg=0.003966 prune=0
2017/08/30 03:54:55 step 0: objective=47.052090 reg=0.003966
2017/08/30 03:54:57 step 1: objective=47.170149 reg=0.003965
2017/08/30 03:54:58 step 2: objective=47.256181 reg=0.003964
2017/08/30 03:55:00 step 3: objective=47.309114 reg=0.003965
2017/08/30 03:55:01 step 4: objective=47.371746 reg=0.003965
2017/08/30 03:55:03 step 5: objective=47.416482 reg=0.003964
2017/08/30 03:55:04 step 6: objective=47.476427 reg=0.003965
2017/08/30 03:55:06 step 7: objective=47.513036 reg=0.003965
2017/08/30 03:55:06 Training value function...
2017/08/30 03:55:08 step 0: mse=165089.025612 step=0.050000
2017/08/30 03:55:09 step 1: mse=164574.578553 step=0.050000
2017/08/30 03:55:11 step 2: mse=166289.594348 step=0.050000
2017/08/30 03:55:12 step 3: mse=166094.342079 step=0.050000
2017/08/30 03:55:13 step 4: mse=166577.193435 step=0.050000
2017/08/30 03:55:14 step 5: mse=166034.412364 step=0.050000
2017/08/30 03:55:15 step 6: mse=167243.477124 step=0.050000
2017/08/30 03:55:16 step 7: mse=169106.552144 step=0.050000
2017/08/30 03:55:16 Saving...
2017/08/30 03:55:16 Gathering batch of experience...
2017/08/30 03:55:46 batch 657: mean=13231.750000 stddev=9455.197417 entropy=0.405260 frames=6894 count=20
2017/08/30 03:55:46 Training policy...
2017/08/30 03:55:51 tune 0: objective=94.518150 reg=0.004053 prune=0
2017/08/30 03:55:53 step 0: objective=94.592544 reg=0.004051
2017/08/30 03:55:55 step 1: objective=94.657401 reg=0.004051
2017/08/30 03:55:56 step 2: objective=94.732594 reg=0.004050
2017/08/30 03:55:58 step 3: objective=94.811358 reg=0.004050
2017/08/30 03:55:59 step 4: objective=94.872416 reg=0.004049
2017/08/30 03:56:01 step 5: objective=94.950092 reg=0.004048
2017/08/30 03:56:02 step 6: objective=95.016989 reg=0.004047
2017/08/30 03:56:04 step 7: objective=95.073823 reg=0.004047
2017/08/30 03:56:04 Training value function...
2017/08/30 03:56:07 step 0: mse=219660.184906 step=0.050000
2017/08/30 03:56:08 step 1: mse=216279.308319 step=0.050000
2017/08/30 03:56:09 step 2: mse=214026.397128 step=0.050000
2017/08/30 03:56:10 step 3: mse=211145.518171 step=0.050000
2017/08/30 03:56:11 step 4: mse=208657.941212 step=0.050000
2017/08/30 03:56:12 step 5: mse=204411.493630 step=0.050000
2017/08/30 03:56:13 step 6: mse=201821.968875 step=0.050000
2017/08/30 03:56:14 step 7: mse=199975.574063 step=0.050000
2017/08/30 03:56:14 Saving...
2017/08/30 03:56:14 Gathering batch of experience...
2017/08/30 03:56:47 batch 658: mean=7575.178571 stddev=8805.161482 entropy=0.396424 frames=6800 count=28
2017/08/30 03:56:47 Training policy...
2017/08/30 03:56:52 tune 0: objective=56.145386 reg=0.003964 prune=0
2017/08/30 03:56:53 step 0: objective=56.319223 reg=0.003962
2017/08/30 03:56:55 step 1: objective=56.459439 reg=0.003961
2017/08/30 03:56:57 step 2: objective=56.540271 reg=0.003959
2017/08/30 03:56:58 step 3: objective=56.621631 reg=0.003959
2017/08/30 03:57:00 step 4: objective=56.704596 reg=0.003960
2017/08/30 03:57:01 step 5: objective=56.764903 reg=0.003961
2017/08/30 03:57:03 step 6: objective=56.838640 reg=0.003961
2017/08/30 03:57:04 step 7: objective=56.875308 reg=0.003962
2017/08/30 03:57:04 Training value function...
2017/08/30 03:57:07 step 0: mse=217345.828664 step=0.050000
2017/08/30 03:57:08 step 1: mse=216175.784851 step=0.050000
2017/08/30 03:57:09 step 2: mse=215931.956174 step=0.050000
2017/08/30 03:57:10 step 3: mse=216224.830406 step=0.050000
2017/08/30 03:57:11 step 4: mse=214137.136581 step=0.050000
2017/08/30 03:57:13 step 5: mse=212046.784757 step=0.050000
2017/08/30 03:57:14 step 6: mse=212453.971720 step=0.050000
2017/08/30 03:57:15 step 7: mse=210772.993558 step=0.050000
2017/08/30 03:57:15 Saving...
2017/08/30 03:57:15 Gathering batch of experience...
2017/08/30 03:57:47 batch 659: mean=9003.148148 stddev=9303.827682 entropy=0.400945 frames=7194 count=27
2017/08/30 03:57:47 Training policy...
2017/08/30 03:57:52 tune 0: objective=60.129696 reg=0.004009 prune=0
2017/08/30 03:57:54 step 0: objective=60.216439 reg=0.004009
2017/08/30 03:57:56 step 1: objective=60.262515 reg=0.004008
2017/08/30 03:57:57 step 2: objective=60.338789 reg=0.004008
2017/08/30 03:57:59 step 3: objective=60.411150 reg=0.004008
2017/08/30 03:58:00 step 4: objective=60.454628 reg=0.004008
2017/08/30 03:58:02 step 5: objective=60.498445 reg=0.004008
2017/08/30 03:58:04 step 6: objective=60.537197 reg=0.004007
2017/08/30 03:58:05 step 7: objective=60.583047 reg=0.004006
2017/08/30 03:58:05 Training value function...
2017/08/30 03:58:08 step 0: mse=163165.825980 step=0.050000
2017/08/30 03:58:09 step 1: mse=162789.279979 step=0.050000
2017/08/30 03:58:11 step 2: mse=163476.423757 step=0.050000
2017/08/30 03:58:12 step 3: mse=165305.128465 step=0.050000
2017/08/30 03:58:13 step 4: mse=165007.037852 step=0.050000
2017/08/30 03:58:14 step 5: mse=164971.750975 step=0.050000
2017/08/30 03:58:15 step 6: mse=165040.750390 step=0.050000
2017/08/30 03:58:16 step 7: mse=165532.284567 step=0.050000
2017/08/30 03:58:16 Saving...
2017/08/30 03:58:17 Gathering batch of experience...
2017/08/30 03:58:45 batch 660: mean=5966.607143 stddev=8172.386547 entropy=0.394281 frames=5923 count=28
2017/08/30 03:58:45 Training policy...
2017/08/30 03:58:50 tune 0: objective=47.342299 reg=0.003943 prune=0
2017/08/30 03:58:51 step 0: objective=47.386317 reg=0.003942
2017/08/30 03:58:52 step 1: objective=47.425434 reg=0.003942
2017/08/30 03:58:54 step 2: objective=47.459739 reg=0.003942
2017/08/30 03:58:55 step 3: objective=47.494344 reg=0.003942
2017/08/30 03:58:56 step 4: objective=47.524681 reg=0.003942
2017/08/30 03:58:58 step 5: objective=47.562278 reg=0.003942
2017/08/30 03:58:59 step 6: objective=47.601722 reg=0.003942
2017/08/30 03:59:00 step 7: objective=47.638654 reg=0.003941
2017/08/30 03:59:00 Training value function...
2017/08/30 03:59:03 step 0: mse=119045.099267 step=0.050000
2017/08/30 03:59:04 step 1: mse=117845.923173 step=0.050000
2017/08/30 03:59:05 step 2: mse=118542.556775 step=0.050000
2017/08/30 03:59:05 step 3: mse=117685.104798 step=0.050000
2017/08/30 03:59:06 step 4: mse=116173.970009 step=0.050000
2017/08/30 03:59:07 step 5: mse=115106.286125 step=0.050000
2017/08/30 03:59:08 step 6: mse=114109.953703 step=0.050000
2017/08/30 03:59:09 step 7: mse=113346.636863 step=0.050000
2017/08/30 03:59:09 Saving...
2017/08/30 03:59:09 Gathering batch of experience...
2017/08/30 03:59:37 batch 661: mean=6947.115385 stddev=8797.194611 entropy=0.396081 frames=5733 count=26
2017/08/30 03:59:37 Training policy...
2017/08/30 03:59:41 tune 0: objective=59.289137 reg=0.003961 prune=0
2017/08/30 03:59:43 step 0: objective=59.461789 reg=0.003960
2017/08/30 03:59:44 step 1: objective=59.578095 reg=0.003960
2017/08/30 03:59:45 step 2: objective=59.714024 reg=0.003959
2017/08/30 03:59:46 step 3: objective=59.779397 reg=0.003959
2017/08/30 03:59:48 step 4: objective=59.830210 reg=0.003957
2017/08/30 03:59:49 step 5: objective=59.887477 reg=0.003957
2017/08/30 03:59:50 step 6: objective=59.928168 reg=0.003955
2017/08/30 03:59:51 step 7: objective=59.981543 reg=0.003954
2017/08/30 03:59:51 Training value function...
2017/08/30 03:59:54 step 0: mse=186009.253299 step=0.050000
2017/08/30 03:59:55 step 1: mse=185320.770024 step=0.050000
2017/08/30 03:59:56 step 2: mse=184280.535984 step=0.050000
2017/08/30 03:59:57 step 3: mse=184315.807416 step=0.050000
2017/08/30 03:59:58 step 4: mse=184898.827844 step=0.050000
2017/08/30 03:59:58 step 5: mse=184718.831938 step=0.050000
2017/08/30 03:59:59 step 6: mse=184341.918493 step=0.050000
2017/08/30 04:00:00 step 7: mse=184027.552146 step=0.050000
2017/08/30 04:00:00 Saving...
2017/08/30 04:00:00 Gathering batch of experience...
2017/08/30 04:00:31 batch 662: mean=7025.862069 stddev=8577.556728 entropy=0.397533 frames=6576 count=29
2017/08/30 04:00:31 Training policy...
2017/08/30 04:00:36 tune 0: objective=51.949889 reg=0.003975 prune=0
2017/08/30 04:00:37 step 0: objective=52.008269 reg=0.003975
2017/08/30 04:00:39 step 1: objective=52.093113 reg=0.003975
2017/08/30 04:00:40 step 2: objective=52.162775 reg=0.003976
2017/08/30 04:00:42 step 3: objective=52.214435 reg=0.003976
2017/08/30 04:00:43 step 4: objective=52.275357 reg=0.003976
2017/08/30 04:00:45 step 5: objective=52.312191 reg=0.003977
2017/08/30 04:00:46 step 6: objective=52.350717 reg=0.003977
2017/08/30 04:00:48 step 7: objective=52.380232 reg=0.003977
2017/08/30 04:00:48 Training value function...
2017/08/30 04:00:50 step 0: mse=147626.663052 step=0.050000
2017/08/30 04:00:51 step 1: mse=146093.225879 step=0.050000
2017/08/30 04:00:52 step 2: mse=146313.980032 step=0.050000
2017/08/30 04:00:54 step 3: mse=146487.368242 step=0.050000
2017/08/30 04:00:55 step 4: mse=146943.640550 step=0.050000
2017/08/30 04:00:56 step 5: mse=147678.831435 step=0.050000
2017/08/30 04:00:57 step 6: mse=148021.771554 step=0.050000
2017/08/30 04:00:58 step 7: mse=148334.931910 step=0.050000
2017/08/30 04:00:58 Saving...
2017/08/30 04:00:58 Gathering batch of experience...
2017/08/30 04:01:30 batch 663: mean=10158.541667 stddev=9367.144651 entropy=0.396206 frames=7097 count=24
2017/08/30 04:01:30 Training policy...
2017/08/30 04:01:35 tune 0: objective=75.938108 reg=0.003962 prune=0
2017/08/30 04:01:37 step 0: objective=76.018608 reg=0.003960
2017/08/30 04:01:38 step 1: objective=76.096194 reg=0.003959
2017/08/30 04:01:40 step 2: objective=76.156589 reg=0.003958
2017/08/30 04:01:41 step 3: objective=76.232774 reg=0.003957
2017/08/30 04:01:43 step 4: objective=76.296851 reg=0.003956
2017/08/30 04:01:45 step 5: objective=76.334076 reg=0.003955
2017/08/30 04:01:46 step 6: objective=76.369690 reg=0.003955
2017/08/30 04:01:48 step 7: objective=76.430120 reg=0.003954
2017/08/30 04:01:48 Training value function...
2017/08/30 04:01:51 step 0: mse=169385.969848 step=0.050000
2017/08/30 04:01:52 step 1: mse=168397.714274 step=0.050000
2017/08/30 04:01:53 step 2: mse=167775.336285 step=0.050000
2017/08/30 04:01:54 step 3: mse=167324.339659 step=0.050000
2017/08/30 04:01:55 step 4: mse=167506.851803 step=0.050000
2017/08/30 04:01:56 step 5: mse=168277.646754 step=0.050000
2017/08/30 04:01:58 step 6: mse=169311.341061 step=0.050000
2017/08/30 04:01:59 step 7: mse=168851.913828 step=0.050000
2017/08/30 04:01:59 Saving...
2017/08/30 04:01:59 Gathering batch of experience...
2017/08/30 04:02:32 batch 664: mean=7111.406250 stddev=8873.843607 entropy=0.398788 frames=7224 count=32
2017/08/30 04:02:32 Training policy...
2017/08/30 04:02:37 tune 0: objective=60.338849 reg=0.003988 prune=0
2017/08/30 04:02:39 step 0: objective=60.433364 reg=0.003987
2017/08/30 04:02:40 step 1: objective=60.500489 reg=0.003987
2017/08/30 04:02:42 step 2: objective=60.564732 reg=0.003987
2017/08/30 04:02:43 step 3: objective=60.650198 reg=0.003987
2017/08/30 04:02:45 step 4: objective=60.690636 reg=0.003987
2017/08/30 04:02:47 step 5: objective=60.729245 reg=0.003987
2017/08/30 04:02:48 step 6: objective=60.776016 reg=0.003987
2017/08/30 04:02:50 step 7: objective=60.818465 reg=0.003987
2017/08/30 04:02:50 Training value function...
2017/08/30 04:02:53 step 0: mse=190281.327867 step=0.050000
2017/08/30 04:02:54 step 1: mse=187136.231904 step=0.050000
2017/08/30 04:02:55 step 2: mse=186110.289656 step=0.050000
2017/08/30 04:02:57 step 3: mse=185349.868981 step=0.050000
2017/08/30 04:02:58 step 4: mse=184508.758364 step=0.050000
2017/08/30 04:02:59 step 5: mse=184151.633791 step=0.050000
2017/08/30 04:03:00 step 6: mse=184276.130294 step=0.050000
2017/08/30 04:03:01 step 7: mse=185646.455532 step=0.050000
2017/08/30 04:03:01 Saving...
2017/08/30 04:03:01 Gathering batch of experience...
2017/08/30 04:03:35 batch 665: mean=5777.432432 stddev=8133.270728 entropy=0.395776 frames=7238 count=37
2017/08/30 04:03:35 Training policy...
2017/08/30 04:03:40 tune 0: objective=46.954714 reg=0.003958 prune=0
2017/08/30 04:03:42 step 0: objective=47.007698 reg=0.003957
2017/08/30 04:03:44 step 1: objective=47.066066 reg=0.003957
2017/08/30 04:03:45 step 2: objective=47.128083 reg=0.003957
2017/08/30 04:03:47 step 3: objective=47.181671 reg=0.003956
2017/08/30 04:03:48 step 4: objective=47.222960 reg=0.003956
2017/08/30 04:03:50 step 5: objective=47.257983 reg=0.003955
2017/08/30 04:03:52 step 6: objective=47.303157 reg=0.003955
2017/08/30 04:03:53 step 7: objective=47.341289 reg=0.003953
2017/08/30 04:03:53 Training value function...
2017/08/30 04:03:56 step 0: mse=163776.624132 step=0.050000
2017/08/30 04:03:57 step 1: mse=163416.107525 step=0.050000
2017/08/30 04:03:59 step 2: mse=163766.274153 step=0.050000
2017/08/30 04:04:00 step 3: mse=163944.007691 step=0.050000
2017/08/30 04:04:01 step 4: mse=163775.813412 step=0.050000
2017/08/30 04:04:02 step 5: mse=165793.615213 step=0.050000
2017/08/30 04:04:03 step 6: mse=166461.812481 step=0.050000
2017/08/30 04:04:05 step 7: mse=166512.604000 step=0.050000
2017/08/30 04:04:05 Saving...
2017/08/30 04:04:05 Gathering batch of experience...
2017/08/30 04:04:33 batch 666: mean=6890.384615 stddev=8586.135506 entropy=0.394084 frames=5766 count=26
2017/08/30 04:04:33 Training policy...
2017/08/30 04:04:38 tune 0: objective=62.383162 reg=0.003941 prune=0
2017/08/30 04:04:39 step 0: objective=62.482332 reg=0.003941
2017/08/30 04:04:40 step 1: objective=62.559395 reg=0.003941
2017/08/30 04:04:41 step 2: objective=62.658488 reg=0.003941
2017/08/30 04:04:43 step 3: objective=62.766817 reg=0.003942
2017/08/30 04:04:44 step 4: objective=62.859359 reg=0.003943
2017/08/30 04:04:45 step 5: objective=62.937392 reg=0.003942
2017/08/30 04:04:47 step 6: objective=63.009089 reg=0.003942
2017/08/30 04:04:48 step 7: objective=63.081014 reg=0.003941
2017/08/30 04:04:48 Training value function...
2017/08/30 04:04:50 step 0: mse=201778.137209 step=0.050000
2017/08/30 04:04:51 step 1: mse=201412.910554 step=0.050000
2017/08/30 04:04:52 step 2: mse=202647.044431 step=0.050000
2017/08/30 04:04:53 step 3: mse=202268.756196 step=0.050000
2017/08/30 04:04:54 step 4: mse=201228.860906 step=0.050000
2017/08/30 04:04:55 step 5: mse=201252.267436 step=0.050000
2017/08/30 04:04:56 step 6: mse=200191.813006 step=0.050000
2017/08/30 04:04:57 step 7: mse=201698.240794 step=0.050000
2017/08/30 04:04:57 Saving...
2017/08/30 04:04:57 Gathering batch of experience...
2017/08/30 04:05:28 batch 667: mean=9185.400000 stddev=9189.750478 entropy=0.391723 frames=6769 count=25
2017/08/30 04:05:28 Training policy...
2017/08/30 04:05:33 tune 0: objective=77.405945 reg=0.003917 prune=0
2017/08/30 04:05:34 step 0: objective=77.602803 reg=0.003916
2017/08/30 04:05:36 step 1: objective=77.755808 reg=0.003915
2017/08/30 04:05:37 step 2: objective=77.885120 reg=0.003916
2017/08/30 04:05:39 step 3: objective=77.973556 reg=0.003917
2017/08/30 04:05:40 step 4: objective=78.017451 reg=0.003916
2017/08/30 04:05:42 step 5: objective=78.050958 reg=0.003915
2017/08/30 04:05:43 step 6: objective=78.081539 reg=0.003914
2017/08/30 04:05:45 step 7: objective=78.116875 reg=0.003914
2017/08/30 04:05:45 Training value function...
2017/08/30 04:05:48 step 0: mse=286890.510708 step=0.050000
2017/08/30 04:05:49 step 1: mse=284482.037390 step=0.050000
2017/08/30 04:05:50 step 2: mse=277667.123523 step=0.050000
2017/08/30 04:05:51 step 3: mse=272434.665220 step=0.050000
2017/08/30 04:05:52 step 4: mse=269202.735752 step=0.050000
2017/08/30 04:05:53 step 5: mse=267466.317753 step=0.050000
2017/08/30 04:05:54 step 6: mse=266953.353290 step=0.050000
2017/08/30 04:05:55 step 7: mse=265182.948893 step=0.050000
2017/08/30 04:05:55 Saving...
2017/08/30 04:05:55 Gathering batch of experience...
2017/08/30 04:06:27 batch 668: mean=10905.227273 stddev=9525.672307 entropy=0.396719 frames=6842 count=22
2017/08/30 04:06:27 Training policy...
2017/08/30 04:06:32 tune 0: objective=70.217713 reg=0.003967 prune=0
2017/08/30 04:06:34 step 0: objective=70.316177 reg=0.003967
2017/08/30 04:06:35 step 1: objective=70.387496 reg=0.003967
2017/08/30 04:06:37 step 2: objective=70.463086 reg=0.003967
2017/08/30 04:06:39 step 3: objective=70.507326 reg=0.003967
2017/08/30 04:06:40 step 4: objective=70.563304 reg=0.003968
2017/08/30 04:06:42 step 5: objective=70.612257 reg=0.003968
2017/08/30 04:06:43 step 6: objective=70.644594 reg=0.003969
2017/08/30 04:06:45 step 7: objective=70.700604 reg=0.003968
2017/08/30 04:06:45 Training value function...
2017/08/30 04:06:47 step 0: mse=197569.829961 step=0.050000
2017/08/30 04:06:49 step 1: mse=197801.344378 step=0.050000
2017/08/30 04:06:50 step 2: mse=197450.070694 step=0.050000
2017/08/30 04:06:51 step 3: mse=195341.118313 step=0.050000
2017/08/30 04:06:52 step 4: mse=194509.056479 step=0.050000
2017/08/30 04:06:53 step 5: mse=193687.159193 step=0.050000
2017/08/30 04:06:54 step 6: mse=192356.504014 step=0.050000
2017/08/30 04:06:55 step 7: mse=191797.141341 step=0.050000
2017/08/30 04:06:55 Saving...
2017/08/30 04:06:55 Gathering batch of experience...
2017/08/30 04:07:27 batch 669: mean=9436.800000 stddev=9787.596322 entropy=0.399783 frames=6626 count=25
2017/08/30 04:07:27 Training policy...
2017/08/30 04:07:32 tune 0: objective=74.928360 reg=0.003998 prune=0
2017/08/30 04:07:33 step 0: objective=75.003438 reg=0.003998
2017/08/30 04:07:35 step 1: objective=75.072432 reg=0.003997
2017/08/30 04:07:36 step 2: objective=75.135946 reg=0.003997
2017/08/30 04:07:38 step 3: objective=75.185420 reg=0.003997
2017/08/30 04:07:39 step 4: objective=75.241959 reg=0.003997
2017/08/30 04:07:41 step 5: objective=75.285108 reg=0.003996
2017/08/30 04:07:42 step 6: objective=75.316485 reg=0.003995
2017/08/30 04:07:44 step 7: objective=75.360856 reg=0.003995
2017/08/30 04:07:44 Training value function...
2017/08/30 04:07:46 step 0: mse=176769.055377 step=0.050000
2017/08/30 04:07:47 step 1: mse=175535.165190 step=0.050000
2017/08/30 04:07:48 step 2: mse=176621.010824 step=0.050000
2017/08/30 04:07:50 step 3: mse=175924.961107 step=0.050000
2017/08/30 04:07:51 step 4: mse=174051.396987 step=0.050000
2017/08/30 04:07:52 step 5: mse=173736.878149 step=0.050000
2017/08/30 04:07:53 step 6: mse=172588.607079 step=0.050000
2017/08/30 04:07:54 step 7: mse=170982.199036 step=0.050000
2017/08/30 04:07:54 Saving...
2017/08/30 04:07:54 Gathering batch of experience...
2017/08/30 04:08:25 batch 670: mean=8172.407407 stddev=9324.206189 entropy=0.395579 frames=6669 count=27
2017/08/30 04:08:25 Training policy...
2017/08/30 04:08:30 tune 0: objective=63.494115 reg=0.003956 prune=0
2017/08/30 04:08:32 step 0: objective=63.569121 reg=0.003956
2017/08/30 04:08:33 step 1: objective=63.625178 reg=0.003955
2017/08/30 04:08:35 step 2: objective=63.670514 reg=0.003955
2017/08/30 04:08:36 step 3: objective=63.713253 reg=0.003955
2017/08/30 04:08:38 step 4: objective=63.758833 reg=0.003955
2017/08/30 04:08:39 step 5: objective=63.791817 reg=0.003955
2017/08/30 04:08:41 step 6: objective=63.852691 reg=0.003955
2017/08/30 04:08:42 step 7: objective=63.901484 reg=0.003955
2017/08/30 04:08:42 Training value function...
2017/08/30 04:08:45 step 0: mse=150732.720914 step=0.050000
2017/08/30 04:08:46 step 1: mse=148664.400859 step=0.050000
2017/08/30 04:08:47 step 2: mse=147205.998802 step=0.050000
2017/08/30 04:08:48 step 3: mse=146553.267527 step=0.050000
2017/08/30 04:08:49 step 4: mse=148081.973894 step=0.050000
2017/08/30 04:08:50 step 5: mse=147226.402840 step=0.050000
2017/08/30 04:08:52 step 6: mse=145961.193246 step=0.050000
2017/08/30 04:08:53 step 7: mse=146726.618168 step=0.050000
2017/08/30 04:08:53 Saving...
2017/08/30 04:08:53 Gathering batch of experience...
2017/08/30 04:09:25 batch 671: mean=6571.562500 stddev=8339.213602 entropy=0.396007 frames=6824 count=32
2017/08/30 04:09:25 Training policy...
2017/08/30 04:09:30 tune 0: objective=46.001644 reg=0.003960 prune=0
2017/08/30 04:09:32 step 0: objective=46.118451 reg=0.003959
2017/08/30 04:09:33 step 1: objective=46.282006 reg=0.003960
2017/08/30 04:09:35 step 2: objective=46.335205 reg=0.003960
2017/08/30 04:09:37 step 3: objective=46.397169 reg=0.003961
2017/08/30 04:09:38 step 4: objective=46.468329 reg=0.003962
2017/08/30 04:09:40 step 5: objective=46.526121 reg=0.003961
2017/08/30 04:09:41 step 6: objective=46.597455 reg=0.003961
2017/08/30 04:09:43 step 7: objective=46.640927 reg=0.003960
2017/08/30 04:09:43 Training value function...
2017/08/30 04:09:45 step 0: mse=188835.980781 step=0.050000
2017/08/30 04:09:47 step 1: mse=189459.850952 step=0.050000
2017/08/30 04:09:48 step 2: mse=190143.259096 step=0.050000
2017/08/30 04:09:49 step 3: mse=190722.536050 step=0.050000
2017/08/30 04:09:50 step 4: mse=192857.339802 step=0.050000
2017/08/30 04:09:51 step 5: mse=193971.747449 step=0.050000
2017/08/30 04:09:52 step 6: mse=194429.454887 step=0.050000
2017/08/30 04:09:53 step 7: mse=194984.697090 step=0.050000
2017/08/30 04:09:53 Saving...
2017/08/30 04:09:53 Gathering batch of experience...
2017/08/30 04:10:24 batch 672: mean=6548.965517 stddev=8145.127947 entropy=0.393980 frames=6520 count=29
2017/08/30 04:10:24 Training policy...
2017/08/30 04:10:29 tune 0: objective=45.580061 reg=0.003940 prune=0
2017/08/30 04:10:30 step 0: objective=45.651797 reg=0.003939
2017/08/30 04:10:32 step 1: objective=45.712490 reg=0.003939
2017/08/30 04:10:33 step 2: objective=45.766814 reg=0.003939
2017/08/30 04:10:35 step 3: objective=45.824832 reg=0.003940
2017/08/30 04:10:36 step 4: objective=45.888880 reg=0.003940
2017/08/30 04:10:38 step 5: objective=45.940323 reg=0.003941
2017/08/30 04:10:39 step 6: objective=45.975992 reg=0.003942
2017/08/30 04:10:41 step 7: objective=46.001093 reg=0.003941
2017/08/30 04:10:41 Training value function...
2017/08/30 04:10:43 step 0: mse=126161.475630 step=0.050000
2017/08/30 04:10:44 step 1: mse=127447.191806 step=0.050000
2017/08/30 04:10:45 step 2: mse=128204.504549 step=0.050000
2017/08/30 04:10:46 step 3: mse=129250.461698 step=0.050000
2017/08/30 04:10:48 step 4: mse=129007.249585 step=0.050000
2017/08/30 04:10:49 step 5: mse=128316.967861 step=0.050000
2017/08/30 04:10:50 step 6: mse=128546.483207 step=0.050000
2017/08/30 04:10:51 step 7: mse=127746.276613 step=0.050000
2017/08/30 04:10:51 Saving...
2017/08/30 04:10:51 Gathering batch of experience...
2017/08/30 04:11:23 batch 673: mean=7926.551724 stddev=9214.435929 entropy=0.396355 frames=7083 count=29
2017/08/30 04:11:23 Training policy...
2017/08/30 04:11:29 tune 0: objective=74.038490 reg=0.003964 prune=0
2017/08/30 04:11:31 step 0: objective=74.195468 reg=0.003964
2017/08/30 04:11:32 step 1: objective=74.333845 reg=0.003965
2017/08/30 04:11:34 step 2: objective=74.433873 reg=0.003965
2017/08/30 04:11:35 step 3: objective=74.512230 reg=0.003965
2017/08/30 04:11:37 step 4: objective=74.561238 reg=0.003965
2017/08/30 04:11:38 step 5: objective=74.597213 reg=0.003965
2017/08/30 04:11:40 step 6: objective=74.638024 reg=0.003965
2017/08/30 04:11:42 step 7: objective=74.689415 reg=0.003965
2017/08/30 04:11:42 Training value function...
2017/08/30 04:11:45 step 0: mse=228173.065987 step=0.050000
2017/08/30 04:11:46 step 1: mse=224506.047968 step=0.050000
2017/08/30 04:11:47 step 2: mse=220903.732776 step=0.050000
2017/08/30 04:11:48 step 3: mse=217861.500995 step=0.050000
2017/08/30 04:11:49 step 4: mse=217353.190645 step=0.050000
2017/08/30 04:11:50 step 5: mse=216872.119327 step=0.050000
2017/08/30 04:11:52 step 6: mse=217078.773032 step=0.050000
2017/08/30 04:11:53 step 7: mse=216426.191665 step=0.050000
2017/08/30 04:11:53 Saving...
2017/08/30 04:11:53 Gathering batch of experience...
2017/08/30 04:12:24 batch 674: mean=5514.531250 stddev=7499.810764 entropy=0.392965 frames=6521 count=32
2017/08/30 04:12:24 Training policy...
2017/08/30 04:12:29 tune 0: objective=37.475064 reg=0.003930 prune=0
2017/08/30 04:12:30 step 0: objective=37.571557 reg=0.003929
2017/08/30 04:12:32 step 1: objective=37.628398 reg=0.003929
2017/08/30 04:12:33 step 2: objective=37.701187 reg=0.003929
2017/08/30 04:12:35 step 3: objective=37.780689 reg=0.003929
2017/08/30 04:12:36 step 4: objective=37.823141 reg=0.003929
2017/08/30 04:12:38 step 5: objective=37.860755 reg=0.003929
2017/08/30 04:12:39 step 6: objective=37.926842 reg=0.003929
2017/08/30 04:12:41 step 7: objective=37.953726 reg=0.003929
2017/08/30 04:12:41 Training value function...
2017/08/30 04:12:43 step 0: mse=149102.138924 step=0.050000
2017/08/30 04:12:44 step 1: mse=149666.751200 step=0.050000
2017/08/30 04:12:46 step 2: mse=150259.673690 step=0.050000
2017/08/30 04:12:47 step 3: mse=151434.243734 step=0.050000
2017/08/30 04:12:48 step 4: mse=151793.880310 step=0.050000
2017/08/30 04:12:49 step 5: mse=152709.192325 step=0.050000
2017/08/30 04:12:50 step 6: mse=153374.829444 step=0.050000
2017/08/30 04:12:51 step 7: mse=153216.662076 step=0.050000
2017/08/30 04:12:51 Saving...
2017/08/30 04:12:51 Gathering batch of experience...
2017/08/30 04:13:22 batch 675: mean=9348.800000 stddev=9530.653102 entropy=0.398722 frames=6584 count=25
2017/08/30 04:13:22 Training policy...
2017/08/30 04:13:27 tune 0: objective=76.785512 reg=0.003987 prune=0
2017/08/30 04:13:28 step 0: objective=76.889818 reg=0.003987
2017/08/30 04:13:30 step 1: objective=76.977469 reg=0.003987
2017/08/30 04:13:31 step 2: objective=77.042342 reg=0.003986
2017/08/30 04:13:33 step 3: objective=77.089364 reg=0.003986
2017/08/30 04:13:34 step 4: objective=77.150806 reg=0.003986
2017/08/30 04:13:36 step 5: objective=77.202593 reg=0.003985
2017/08/30 04:13:37 step 6: objective=77.262867 reg=0.003985
2017/08/30 04:13:39 step 7: objective=77.286974 reg=0.003985
2017/08/30 04:13:39 Training value function...
2017/08/30 04:13:41 step 0: mse=189599.949721 step=0.050000
2017/08/30 04:13:42 step 1: mse=187658.208925 step=0.050000
2017/08/30 04:13:43 step 2: mse=187477.116078 step=0.050000
2017/08/30 04:13:44 step 3: mse=186394.191170 step=0.050000
2017/08/30 04:13:46 step 4: mse=185964.413766 step=0.050000
2017/08/30 04:13:47 step 5: mse=184681.113148 step=0.050000
2017/08/30 04:13:48 step 6: mse=183560.385034 step=0.050000
2017/08/30 04:13:49 step 7: mse=182614.683757 step=0.050000
2017/08/30 04:13:49 Saving...
2017/08/30 04:13:49 Gathering batch of experience...
2017/08/30 04:14:21 batch 676: mean=9639.400000 stddev=9709.575204 entropy=0.398319 frames=7023 count=25
2017/08/30 04:14:21 Training policy...
2017/08/30 04:14:26 tune 0: objective=75.076436 reg=0.003983 prune=0
2017/08/30 04:14:28 step 0: objective=75.124404 reg=0.003983
2017/08/30 04:14:29 step 1: objective=75.166257 reg=0.003984
2017/08/30 04:14:31 step 2: objective=75.206349 reg=0.003983
2017/08/30 04:14:32 step 3: objective=75.253195 reg=0.003984
2017/08/30 04:14:34 step 4: objective=75.288054 reg=0.003983
2017/08/30 04:14:36 step 5: objective=75.322369 reg=0.003983
2017/08/30 04:14:37 step 6: objective=75.373950 reg=0.003984
2017/08/30 04:14:39 step 7: objective=75.408978 reg=0.003984
2017/08/30 04:14:39 Training value function...
2017/08/30 04:14:42 step 0: mse=171256.316351 step=0.050000
2017/08/30 04:14:43 step 1: mse=169260.332504 step=0.050000
2017/08/30 04:14:44 step 2: mse=168228.176928 step=0.050000
2017/08/30 04:14:45 step 3: mse=166443.209652 step=0.050000
2017/08/30 04:14:46 step 4: mse=163100.122145 step=0.050000
2017/08/30 04:14:47 step 5: mse=162789.925338 step=0.050000
2017/08/30 04:14:49 step 6: mse=162332.081629 step=0.050000
2017/08/30 04:14:50 step 7: mse=161133.961353 step=0.050000
2017/08/30 04:14:50 Saving...
2017/08/30 04:14:50 Gathering batch of experience...
2017/08/30 04:15:24 batch 677: mean=8936.428571 stddev=9534.304965 entropy=0.392512 frames=7279 count=28
2017/08/30 04:15:24 Training policy...
2017/08/30 04:15:30 tune 0: objective=66.067437 reg=0.003925 prune=0
2017/08/30 04:15:32 step 0: objective=66.200667 reg=0.003924
2017/08/30 04:15:33 step 1: objective=66.248922 reg=0.003924
2017/08/30 04:15:35 step 2: objective=66.291562 reg=0.003924
2017/08/30 04:15:36 step 3: objective=66.338697 reg=0.003924
2017/08/30 04:15:38 step 4: objective=66.380766 reg=0.003924
2017/08/30 04:15:40 step 5: objective=66.405606 reg=0.003924
2017/08/30 04:15:41 step 6: objective=66.454024 reg=0.003924
2017/08/30 04:15:43 step 7: objective=66.499493 reg=0.003924
2017/08/30 04:15:43 Training value function...
2017/08/30 04:15:46 step 0: mse=190353.097864 step=0.050000
2017/08/30 04:15:47 step 1: mse=188205.176774 step=0.050000
2017/08/30 04:15:48 step 2: mse=187775.136270 step=0.050000
2017/08/30 04:15:50 step 3: mse=187540.538442 step=0.050000
2017/08/30 04:15:51 step 4: mse=188811.483851 step=0.050000
2017/08/30 04:15:52 step 5: mse=188012.125800 step=0.050000
2017/08/30 04:15:53 step 6: mse=190300.069050 step=0.050000
2017/08/30 04:15:54 step 7: mse=190102.777638 step=0.050000
2017/08/30 04:15:54 Saving...
2017/08/30 04:15:54 Gathering batch of experience...
2017/08/30 04:16:27 batch 678: mean=8083.166667 stddev=9390.589038 entropy=0.392398 frames=7229 count=30
2017/08/30 04:16:27 Training policy...
2017/08/30 04:16:33 tune 0: objective=72.446241 reg=0.003924 prune=0
2017/08/30 04:16:34 step 0: objective=72.510033 reg=0.003924
2017/08/30 04:16:36 step 1: objective=72.554529 reg=0.003924
2017/08/30 04:16:37 step 2: objective=72.619787 reg=0.003924
2017/08/30 04:16:39 step 3: objective=72.666110 reg=0.003924
2017/08/30 04:16:41 step 4: objective=72.695169 reg=0.003925
2017/08/30 04:16:42 step 5: objective=72.734758 reg=0.003924
2017/08/30 04:16:44 step 6: objective=72.796540 reg=0.003924
2017/08/30 04:16:46 step 7: objective=72.829446 reg=0.003925
2017/08/30 04:16:46 Training value function...
2017/08/30 04:16:49 step 0: mse=225744.447287 step=0.050000
2017/08/30 04:16:50 step 1: mse=223376.869635 step=0.050000
2017/08/30 04:16:51 step 2: mse=221540.526165 step=0.050000
2017/08/30 04:16:52 step 3: mse=219145.727428 step=0.050000
2017/08/30 04:16:53 step 4: mse=217308.346211 step=0.050000
2017/08/30 04:16:55 step 5: mse=216698.360815 step=0.050000
2017/08/30 04:16:56 step 6: mse=215190.669880 step=0.050000
2017/08/30 04:16:57 step 7: mse=213624.009015 step=0.050000
2017/08/30 04:16:57 Saving...
2017/08/30 04:16:57 Gathering batch of experience...
2017/08/30 04:17:28 batch 679: mean=8111.346154 stddev=8962.514195 entropy=0.392572 frames=6653 count=26
2017/08/30 04:17:28 Training policy...
2017/08/30 04:17:33 tune 0: objective=55.553792 reg=0.003926 prune=0
2017/08/30 04:17:35 step 0: objective=55.729431 reg=0.003923
2017/08/30 04:17:36 step 1: objective=55.874690 reg=0.003921
2017/08/30 04:17:38 step 2: objective=55.967468 reg=0.003921
2017/08/30 04:17:39 step 3: objective=56.042904 reg=0.003921
2017/08/30 04:17:41 step 4: objective=56.079212 reg=0.003921
2017/08/30 04:17:42 step 5: objective=56.130265 reg=0.003920
2017/08/30 04:17:44 step 6: objective=56.170651 reg=0.003921
2017/08/30 04:17:45 step 7: objective=56.207618 reg=0.003921
2017/08/30 04:17:45 Training value function...
2017/08/30 04:17:48 step 0: mse=168944.574817 step=0.050000
2017/08/30 04:17:49 step 1: mse=169404.121335 step=0.050000
2017/08/30 04:17:50 step 2: mse=168087.639659 step=0.050000
2017/08/30 04:17:51 step 3: mse=168413.763113 step=0.050000
2017/08/30 04:17:52 step 4: mse=169959.316828 step=0.050000
2017/08/30 04:17:53 step 5: mse=170229.110309 step=0.050000
2017/08/30 04:17:55 step 6: mse=169733.218040 step=0.050000
2017/08/30 04:17:56 step 7: mse=169835.448415 step=0.050000
2017/08/30 04:17:56 Saving...
2017/08/30 04:17:56 Gathering batch of experience...
2017/08/30 04:18:27 batch 680: mean=7283.666667 stddev=8934.611532 entropy=0.395838 frames=6793 count=30
2017/08/30 04:18:27 Training policy...
2017/08/30 04:18:32 tune 0: objective=56.366577 reg=0.003958 prune=0
2017/08/30 04:18:34 step 0: objective=56.478443 reg=0.003958
2017/08/30 04:18:35 step 1: objective=56.562321 reg=0.003959
2017/08/30 04:18:37 step 2: objective=56.649906 reg=0.003958
2017/08/30 04:18:38 step 3: objective=56.710120 reg=0.003958
2017/08/30 04:18:40 step 4: objective=56.774014 reg=0.003957
2017/08/30 04:18:41 step 5: objective=56.847527 reg=0.003956
2017/08/30 04:18:43 step 6: objective=56.911545 reg=0.003956
2017/08/30 04:18:45 step 7: objective=56.960916 reg=0.003955
2017/08/30 04:18:45 Training value function...
2017/08/30 04:18:47 step 0: mse=181749.048204 step=0.050000
2017/08/30 04:18:48 step 1: mse=180494.312192 step=0.050000
2017/08/30 04:18:49 step 2: mse=179502.816047 step=0.050000
2017/08/30 04:18:51 step 3: mse=178089.816342 step=0.050000
2017/08/30 04:18:52 step 4: mse=177910.402302 step=0.050000
2017/08/30 04:18:53 step 5: mse=177530.236880 step=0.050000
2017/08/30 04:18:54 step 6: mse=177339.559680 step=0.050000
2017/08/30 04:18:55 step 7: mse=177380.059327 step=0.050000
2017/08/30 04:18:55 Saving...
2017/08/30 04:18:55 Gathering batch of experience...
2017/08/30 04:19:30 batch 681: mean=10326.538462 stddev=9704.950042 entropy=0.393353 frames=7696 count=26
2017/08/30 04:19:30 Training policy...
2017/08/30 04:19:36 tune 0: objective=76.036951 reg=0.003934 prune=0
2017/08/30 04:19:37 step 0: objective=76.112185 reg=0.003934
2017/08/30 04:19:39 step 1: objective=76.160505 reg=0.003934
2017/08/30 04:19:41 step 2: objective=76.245022 reg=0.003934
2017/08/30 04:19:43 step 3: objective=76.309739 reg=0.003933
2017/08/30 04:19:44 step 4: objective=76.356939 reg=0.003933
2017/08/30 04:19:46 step 5: objective=76.396407 reg=0.003932
2017/08/30 04:19:48 step 6: objective=76.420706 reg=0.003932
2017/08/30 04:19:50 step 7: objective=76.461725 reg=0.003931
2017/08/30 04:19:50 Training value function...
2017/08/30 04:19:53 step 0: mse=164599.440010 step=0.050000
2017/08/30 04:19:54 step 1: mse=163737.250642 step=0.050000
2017/08/30 04:19:55 step 2: mse=164074.221589 step=0.050000
2017/08/30 04:19:57 step 3: mse=163150.100939 step=0.050000
2017/08/30 04:19:58 step 4: mse=161351.312031 step=0.050000
2017/08/30 04:19:59 step 5: mse=159819.956162 step=0.050000
2017/08/30 04:20:00 step 6: mse=158399.018377 step=0.050000
2017/08/30 04:20:02 step 7: mse=157799.623034 step=0.050000
2017/08/30 04:20:02 Saving...
2017/08/30 04:20:02 Gathering batch of experience...
2017/08/30 04:20:31 batch 682: mean=7993.269231 stddev=9098.064877 entropy=0.395215 frames=6515 count=26
2017/08/30 04:20:31 Training policy...
2017/08/30 04:20:36 tune 0: objective=61.919004 reg=0.003952 prune=0
2017/08/30 04:20:38 step 0: objective=62.068870 reg=0.003952
2017/08/30 04:20:39 step 1: objective=62.246657 reg=0.003952
2017/08/30 04:20:41 step 2: objective=62.354902 reg=0.003952
2017/08/30 04:20:42 step 3: objective=62.451851 reg=0.003952
2017/08/30 04:20:44 step 4: objective=62.532037 reg=0.003952
2017/08/30 04:20:45 step 5: objective=62.594263 reg=0.003952
2017/08/30 04:20:47 step 6: objective=62.635749 reg=0.003953
2017/08/30 04:20:48 step 7: objective=62.707660 reg=0.003953
2017/08/30 04:20:48 Training value function...
2017/08/30 04:20:51 step 0: mse=203790.544988 step=0.050000
2017/08/30 04:20:52 step 1: mse=203694.058292 step=0.050000
2017/08/30 04:20:53 step 2: mse=201413.839371 step=0.050000
2017/08/30 04:20:54 step 3: mse=201546.704719 step=0.050000
2017/08/30 04:20:55 step 4: mse=201515.028163 step=0.050000
2017/08/30 04:20:56 step 5: mse=202074.033986 step=0.050000
2017/08/30 04:20:57 step 6: mse=202163.511357 step=0.050000
2017/08/30 04:20:58 step 7: mse=202106.552840 step=0.050000
2017/08/30 04:20:58 Saving...
2017/08/30 04:20:58 Gathering batch of experience...
2017/08/30 04:21:30 batch 683: mean=8407.916667 stddev=9127.521788 entropy=0.396361 frames=6226 count=24
2017/08/30 04:21:30 Training policy...
2017/08/30 04:21:34 tune 0: objective=53.394625 reg=0.003964 prune=0
2017/08/30 04:21:36 step 0: objective=53.478141 reg=0.003963
2017/08/30 04:21:37 step 1: objective=53.530693 reg=0.003963
2017/08/30 04:21:39 step 2: objective=53.585177 reg=0.003962
2017/08/30 04:21:40 step 3: objective=53.647210 reg=0.003962
2017/08/30 04:21:41 step 4: objective=53.692585 reg=0.003962
2017/08/30 04:21:43 step 5: objective=53.752475 reg=0.003962
2017/08/30 04:21:44 step 6: objective=53.805839 reg=0.003961
2017/08/30 04:21:46 step 7: objective=53.871637 reg=0.003961
2017/08/30 04:21:46 Training value function...
2017/08/30 04:21:48 step 0: mse=143323.497924 step=0.050000
2017/08/30 04:21:49 step 1: mse=143138.933752 step=0.050000
2017/08/30 04:21:50 step 2: mse=145422.162090 step=0.050000
2017/08/30 04:21:51 step 3: mse=145191.917116 step=0.050000
2017/08/30 04:21:52 step 4: mse=145782.904082 step=0.050000
2017/08/30 04:21:53 step 5: mse=146682.209317 step=0.050000
2017/08/30 04:21:54 step 6: mse=146307.404791 step=0.050000
2017/08/30 04:21:55 step 7: mse=145914.544764 step=0.050000
2017/08/30 04:21:55 Saving...
2017/08/30 04:21:55 Gathering batch of experience...
2017/08/30 04:22:28 batch 684: mean=8412.241379 stddev=9514.870266 entropy=0.395717 frames=7229 count=29
2017/08/30 04:22:28 Training policy...
2017/08/30 04:22:34 tune 0: objective=74.277018 reg=0.003957 prune=0
2017/08/30 04:22:36 step 0: objective=74.336846 reg=0.003957
2017/08/30 04:22:37 step 1: objective=74.376184 reg=0.003956
2017/08/30 04:22:39 step 2: objective=74.422430 reg=0.003955
2017/08/30 04:22:40 step 3: objective=74.483902 reg=0.003955
2017/08/30 04:22:42 step 4: objective=74.523655 reg=0.003954
2017/08/30 04:22:44 step 5: objective=74.588688 reg=0.003953
2017/08/30 04:22:45 step 6: objective=74.622181 reg=0.003953
2017/08/30 04:22:47 step 7: objective=74.659410 reg=0.003952
2017/08/30 04:22:47 Training value function...
2017/08/30 04:22:50 step 0: mse=202289.131075 step=0.050000
2017/08/30 04:22:51 step 1: mse=198506.564211 step=0.050000
2017/08/30 04:22:52 step 2: mse=197121.133457 step=0.050000
2017/08/30 04:22:54 step 3: mse=196158.793069 step=0.050000
2017/08/30 04:22:55 step 4: mse=193996.232154 step=0.050000
2017/08/30 04:22:56 step 5: mse=192082.348667 step=0.050000
2017/08/30 04:22:57 step 6: mse=190723.852248 step=0.050000
2017/08/30 04:22:58 step 7: mse=190154.776581 step=0.050000
2017/08/30 04:22:58 Saving...
2017/08/30 04:22:58 Gathering batch of experience...
2017/08/30 04:23:31 batch 685: mean=6459.393939 stddev=8510.047961 entropy=0.393480 frames=7007 count=33
2017/08/30 04:23:31 Training policy...
2017/08/30 04:23:36 tune 0: objective=42.152562 reg=0.003935 prune=0
2017/08/30 04:23:38 step 0: objective=42.219339 reg=0.003935
2017/08/30 04:23:39 step 1: objective=42.269610 reg=0.003934
2017/08/30 04:23:41 step 2: objective=42.353307 reg=0.003935
2017/08/30 04:23:43 step 3: objective=42.422100 reg=0.003935
2017/08/30 04:23:44 step 4: objective=42.479801 reg=0.003935
2017/08/30 04:23:46 step 5: objective=42.519035 reg=0.003935
2017/08/30 04:23:47 step 6: objective=42.545731 reg=0.003935
2017/08/30 04:23:49 step 7: objective=42.578636 reg=0.003935
2017/08/30 04:23:49 Training value function...
2017/08/30 04:23:52 step 0: mse=130703.121255 step=0.050000
2017/08/30 04:23:53 step 1: mse=132464.298270 step=0.050000
2017/08/30 04:23:54 step 2: mse=134345.772269 step=0.050000
2017/08/30 04:23:55 step 3: mse=135056.260160 step=0.050000
2017/08/30 04:23:57 step 4: mse=134591.127738 step=0.050000
2017/08/30 04:23:58 step 5: mse=135404.346256 step=0.050000
2017/08/30 04:23:59 step 6: mse=136943.002564 step=0.050000
2017/08/30 04:24:00 step 7: mse=136548.252033 step=0.050000
2017/08/30 04:24:00 Saving...
2017/08/30 04:24:00 Gathering batch of experience...
2017/08/30 04:24:31 batch 686: mean=10304.347826 stddev=9629.744376 entropy=0.393700 frames=6622 count=23
2017/08/30 04:24:31 Training policy...
2017/08/30 04:24:36 tune 0: objective=77.855236 reg=0.003937 prune=0
2017/08/30 04:24:37 step 0: objective=77.952554 reg=0.003936
2017/08/30 04:24:39 step 1: objective=78.067063 reg=0.003936
2017/08/30 04:24:40 step 2: objective=78.131102 reg=0.003935
2017/08/30 04:24:42 step 3: objective=78.209269 reg=0.003934
2017/08/30 04:24:43 step 4: objective=78.255460 reg=0.003935
2017/08/30 04:24:45 step 5: objective=78.307875 reg=0.003935
2017/08/30 04:24:46 step 6: objective=78.357218 reg=0.003934
2017/08/30 04:24:48 step 7: objective=78.387105 reg=0.003934
2017/08/30 04:24:48 Training value function...
2017/08/30 04:24:51 step 0: mse=231442.318091 step=0.050000
2017/08/30 04:24:52 step 1: mse=230517.590905 step=0.050000
2017/08/30 04:24:53 step 2: mse=229950.690981 step=0.050000
2017/08/30 04:24:54 step 3: mse=229219.462969 step=0.050000
2017/08/30 04:24:55 step 4: mse=228484.833669 step=0.050000
2017/08/30 04:24:56 step 5: mse=228452.379950 step=0.050000
2017/08/30 04:24:57 step 6: mse=227784.353983 step=0.050000
2017/08/30 04:24:58 step 7: mse=228143.177610 step=0.050000
2017/08/30 04:24:58 Saving...
2017/08/30 04:24:58 Gathering batch of experience...
2017/08/30 04:25:30 batch 687: mean=5396.470588 stddev=7559.952491 entropy=0.389945 frames=6646 count=34
2017/08/30 04:25:30 Training policy...
2017/08/30 04:25:35 tune 0: objective=35.075640 reg=0.003899 prune=0
2017/08/30 04:25:36 step 0: objective=35.181919 reg=0.003899
2017/08/30 04:25:38 step 1: objective=35.283639 reg=0.003899
2017/08/30 04:25:39 step 2: objective=35.354680 reg=0.003899
2017/08/30 04:25:41 step 3: objective=35.421602 reg=0.003899
2017/08/30 04:25:42 step 4: objective=35.465176 reg=0.003900
2017/08/30 04:25:44 step 5: objective=35.525678 reg=0.003900
2017/08/30 04:25:45 step 6: objective=35.567016 reg=0.003900
2017/08/30 04:25:47 step 7: objective=35.617834 reg=0.003900
2017/08/30 04:25:47 Training value function...
2017/08/30 04:25:50 step 0: mse=138444.328546 step=0.050000
2017/08/30 04:25:51 step 1: mse=137736.089881 step=0.050000
2017/08/30 04:25:52 step 2: mse=137259.822945 step=0.050000
2017/08/30 04:25:53 step 3: mse=137049.264002 step=0.050000
2017/08/30 04:25:54 step 4: mse=137863.512540 step=0.050000
2017/08/30 04:25:55 step 5: mse=137050.465369 step=0.050000
2017/08/30 04:25:56 step 6: mse=136781.565296 step=0.050000
2017/08/30 04:25:57 step 7: mse=136212.940807 step=0.050000
2017/08/30 04:25:57 Saving...
2017/08/30 04:25:57 Gathering batch of experience...
2017/08/30 04:26:27 batch 688: mean=10012.173913 stddev=9804.851819 entropy=0.392443 frames=6422 count=23
2017/08/30 04:26:27 Training policy...
2017/08/30 04:26:32 tune 0: objective=84.039814 reg=0.003924 prune=0
2017/08/30 04:26:34 step 0: objective=84.166128 reg=0.003925
2017/08/30 04:26:35 step 1: objective=84.281727 reg=0.003925
2017/08/30 04:26:37 step 2: objective=84.443612 reg=0.003926
2017/08/30 04:26:38 step 3: objective=84.482025 reg=0.003925
2017/08/30 04:26:40 step 4: objective=84.548291 reg=0.003924
2017/08/30 04:26:41 step 5: objective=84.594324 reg=0.003923
2017/08/30 04:26:43 step 6: objective=84.625934 reg=0.003921
2017/08/30 04:26:44 step 7: objective=84.678936 reg=0.003921
2017/08/30 04:26:44 Training value function...
2017/08/30 04:26:47 step 0: mse=246960.418500 step=0.050000
2017/08/30 04:26:48 step 1: mse=246750.194440 step=0.050000
2017/08/30 04:26:49 step 2: mse=245454.525800 step=0.050000
2017/08/30 04:26:50 step 3: mse=244063.309157 step=0.050000
2017/08/30 04:26:51 step 4: mse=242930.348416 step=0.050000
2017/08/30 04:26:52 step 5: mse=242305.923946 step=0.050000
2017/08/30 04:26:53 step 6: mse=241987.411226 step=0.050000
2017/08/30 04:26:54 step 7: mse=240953.817031 step=0.050000
2017/08/30 04:26:54 Saving...
2017/08/30 04:26:54 Gathering batch of experience...
2017/08/30 04:27:24 batch 689: mean=9450.217391 stddev=9558.213458 entropy=0.396139 frames=6319 count=23
2017/08/30 04:27:24 Training policy...
2017/08/30 04:27:29 tune 0: objective=66.393659 reg=0.003961 prune=0
2017/08/30 04:27:30 step 0: objective=66.497804 reg=0.003961
2017/08/30 04:27:32 step 1: objective=66.593483 reg=0.003960
2017/08/30 04:27:33 step 2: objective=66.678954 reg=0.003961
2017/08/30 04:27:35 step 3: objective=66.751825 reg=0.003962
2017/08/30 04:27:36 step 4: objective=66.827262 reg=0.003962
2017/08/30 04:27:38 step 5: objective=66.896839 reg=0.003962
2017/08/30 04:27:39 step 6: objective=66.956955 reg=0.003961
2017/08/30 04:27:40 step 7: objective=67.009218 reg=0.003960
2017/08/30 04:27:40 Training value function...
2017/08/30 04:27:43 step 0: mse=179446.238849 step=0.050000
2017/08/30 04:27:44 step 1: mse=179058.270358 step=0.050000
2017/08/30 04:27:45 step 2: mse=178931.021333 step=0.050000
2017/08/30 04:27:46 step 3: mse=178805.830269 step=0.050000
2017/08/30 04:27:47 step 4: mse=179524.677843 step=0.050000
2017/08/30 04:27:48 step 5: mse=179782.565499 step=0.050000
2017/08/30 04:27:49 step 6: mse=178364.906289 step=0.050000
2017/08/30 04:27:50 step 7: mse=179654.642787 step=0.050000
2017/08/30 04:27:50 Saving...
2017/08/30 04:27:50 Gathering batch of experience...
2017/08/30 04:28:23 batch 690: mean=7449.137931 stddev=8707.174516 entropy=0.390766 frames=6983 count=29
2017/08/30 04:28:23 Training policy...
2017/08/30 04:28:28 tune 0: objective=54.169765 reg=0.003908 prune=0
2017/08/30 04:28:30 step 0: objective=54.398606 reg=0.003905
2017/08/30 04:28:32 step 1: objective=54.456220 reg=0.003905
2017/08/30 04:28:33 step 2: objective=54.504444 reg=0.003905
2017/08/30 04:28:35 step 3: objective=54.596713 reg=0.003905
2017/08/30 04:28:36 step 4: objective=54.649560 reg=0.003904
2017/08/30 04:28:38 step 5: objective=54.737112 reg=0.003903
2017/08/30 04:28:40 step 6: objective=54.773123 reg=0.003903
2017/08/30 04:28:41 step 7: objective=54.812276 reg=0.003903
2017/08/30 04:28:41 Training value function...
2017/08/30 04:28:44 step 0: mse=190513.052422 step=0.050000
2017/08/30 04:28:45 step 1: mse=190658.832628 step=0.050000
2017/08/30 04:28:46 step 2: mse=191164.089996 step=0.050000
2017/08/30 04:28:48 step 3: mse=191933.032216 step=0.050000
2017/08/30 04:28:49 step 4: mse=192171.310291 step=0.050000
2017/08/30 04:28:50 step 5: mse=193662.930759 step=0.050000
2017/08/30 04:28:51 step 6: mse=194033.503094 step=0.050000
2017/08/30 04:28:52 step 7: mse=193740.880143 step=0.050000
2017/08/30 04:28:52 Saving...
2017/08/30 04:28:52 Gathering batch of experience...
2017/08/30 04:29:25 batch 691: mean=8743.035714 stddev=9409.021254 entropy=0.396046 frames=7194 count=28
2017/08/30 04:29:25 Training policy...
2017/08/30 04:29:30 tune 0: objective=66.922548 reg=0.003960 prune=0
2017/08/30 04:29:32 step 0: objective=67.002046 reg=0.003960
2017/08/30 04:29:33 step 1: objective=67.068820 reg=0.003960
2017/08/30 04:29:35 step 2: objective=67.116286 reg=0.003959
2017/08/30 04:29:37 step 3: objective=67.145386 reg=0.003959
2017/08/30 04:29:38 step 4: objective=67.174525 reg=0.003960
2017/08/30 04:29:40 step 5: objective=67.222777 reg=0.003960
2017/08/30 04:29:42 step 6: objective=67.248280 reg=0.003960
2017/08/30 04:29:43 step 7: objective=67.271268 reg=0.003960
2017/08/30 04:29:43 Training value function...
2017/08/30 04:29:46 step 0: mse=172343.839599 step=0.050000
2017/08/30 04:29:47 step 1: mse=170130.803194 step=0.050000
2017/08/30 04:29:49 step 2: mse=168815.385046 step=0.050000
2017/08/30 04:29:50 step 3: mse=167508.380383 step=0.050000
2017/08/30 04:29:51 step 4: mse=167051.770916 step=0.050000
2017/08/30 04:29:52 step 5: mse=167271.320815 step=0.050000
2017/08/30 04:29:53 step 6: mse=166098.969040 step=0.050000
2017/08/30 04:29:55 step 7: mse=165358.328025 step=0.050000
2017/08/30 04:29:55 Saving...
2017/08/30 04:29:55 Gathering batch of experience...
2017/08/30 04:30:23 batch 692: mean=6021.724138 stddev=7983.398645 entropy=0.388978 frames=6064 count=29
2017/08/30 04:30:23 Training policy...
2017/08/30 04:30:27 tune 0: objective=40.032131 reg=0.003890 prune=0
2017/08/30 04:30:29 step 0: objective=40.183529 reg=0.003888
2017/08/30 04:30:30 step 1: objective=40.266898 reg=0.003889
2017/08/30 04:30:31 step 2: objective=40.312874 reg=0.003887
2017/08/30 04:30:33 step 3: objective=40.361274 reg=0.003887
2017/08/30 04:30:34 step 4: objective=40.403957 reg=0.003887
2017/08/30 04:30:36 step 5: objective=40.451002 reg=0.003887
2017/08/30 04:30:37 step 6: objective=40.492994 reg=0.003887
2017/08/30 04:30:38 step 7: objective=40.520096 reg=0.003887
2017/08/30 04:30:38 Training value function...
2017/08/30 04:30:41 step 0: mse=128924.608078 step=0.050000
2017/08/30 04:30:42 step 1: mse=128469.423922 step=0.050000
2017/08/30 04:30:43 step 2: mse=129306.061131 step=0.050000
2017/08/30 04:30:44 step 3: mse=128947.504968 step=0.050000
2017/08/30 04:30:45 step 4: mse=128803.832231 step=0.050000
2017/08/30 04:30:46 step 5: mse=130120.831379 step=0.050000
2017/08/30 04:30:47 step 6: mse=131602.074963 step=0.050000
2017/08/30 04:30:48 step 7: mse=130744.384359 step=0.050000
2017/08/30 04:30:48 Saving...
2017/08/30 04:30:48 Gathering batch of experience...
2017/08/30 04:31:19 batch 693: mean=10685.217391 stddev=9678.904277 entropy=0.394335 frames=6793 count=23
2017/08/30 04:31:19 Training policy...
2017/08/30 04:31:24 tune 0: objective=78.032690 reg=0.003943 prune=0
2017/08/30 04:31:25 step 0: objective=78.148084 reg=0.003943
2017/08/30 04:31:27 step 1: objective=78.197179 reg=0.003942
2017/08/30 04:31:28 step 2: objective=78.256440 reg=0.003943
2017/08/30 04:31:30 step 3: objective=78.321001 reg=0.003944
2017/08/30 04:31:32 step 4: objective=78.362358 reg=0.003944
2017/08/30 04:31:33 step 5: objective=78.415290 reg=0.003944
2017/08/30 04:31:35 step 6: objective=78.469500 reg=0.003944
2017/08/30 04:31:36 step 7: objective=78.496311 reg=0.003943
2017/08/30 04:31:36 Training value function...
2017/08/30 04:31:39 step 0: mse=196455.473119 step=0.050000
2017/08/30 04:31:40 step 1: mse=197683.805264 step=0.050000
2017/08/30 04:31:41 step 2: mse=196527.289621 step=0.050000
2017/08/30 04:31:42 step 3: mse=195585.046797 step=0.050000
2017/08/30 04:31:43 step 4: mse=195476.998727 step=0.050000
2017/08/30 04:31:45 step 5: mse=194636.748856 step=0.050000
2017/08/30 04:31:46 step 6: mse=193782.817393 step=0.050000
2017/08/30 04:31:47 step 7: mse=191855.851726 step=0.050000
2017/08/30 04:31:47 Saving...
2017/08/30 04:31:47 Gathering batch of experience...
2017/08/30 04:32:22 batch 694: mean=13612.500000 stddev=9407.658721 entropy=0.389529 frames=7848 count=22
2017/08/30 04:32:22 Training policy...
2017/08/30 04:32:28 tune 0: objective=92.576604 reg=0.003895 prune=0
2017/08/30 04:32:30 step 0: objective=92.688137 reg=0.003895
2017/08/30 04:32:32 step 1: objective=92.778781 reg=0.003895
2017/08/30 04:32:34 step 2: objective=92.917630 reg=0.003895
2017/08/30 04:32:35 step 3: objective=92.984741 reg=0.003895
2017/08/30 04:32:37 step 4: objective=93.043435 reg=0.003895
2017/08/30 04:32:39 step 5: objective=93.123981 reg=0.003895
2017/08/30 04:32:41 step 6: objective=93.166308 reg=0.003894
2017/08/30 04:32:43 step 7: objective=93.235466 reg=0.003892
2017/08/30 04:32:43 Training value function...
2017/08/30 04:32:46 step 0: mse=260345.901022 step=0.050000
2017/08/30 04:32:47 step 1: mse=258510.226093 step=0.050000
2017/08/30 04:32:48 step 2: mse=255101.290409 step=0.050000
2017/08/30 04:32:50 step 3: mse=253588.308857 step=0.050000
2017/08/30 04:32:51 step 4: mse=247483.888322 step=0.050000
2017/08/30 04:32:52 step 5: mse=246596.705037 step=0.050000
2017/08/30 04:32:54 step 6: mse=244249.980150 step=0.050000
2017/08/30 04:32:55 step 7: mse=242749.181636 step=0.050000
2017/08/30 04:32:55 Saving...
2017/08/30 04:32:55 Gathering batch of experience...
2017/08/30 04:33:25 batch 695: mean=9710.909091 stddev=9727.841211 entropy=0.389450 frames=6067 count=22
2017/08/30 04:33:25 Training policy...
2017/08/30 04:33:29 tune 0: objective=66.959252 reg=0.003895 prune=0
2017/08/30 04:33:31 step 0: objective=67.041438 reg=0.003894
2017/08/30 04:33:32 step 1: objective=67.120194 reg=0.003894
2017/08/30 04:33:34 step 2: objective=67.180330 reg=0.003894
2017/08/30 04:33:35 step 3: objective=67.238333 reg=0.003894
2017/08/30 04:33:36 step 4: objective=67.297743 reg=0.003894
2017/08/30 04:33:38 step 5: objective=67.340541 reg=0.003894
2017/08/30 04:33:39 step 6: objective=67.379620 reg=0.003893
2017/08/30 04:33:40 step 7: objective=67.416933 reg=0.003893
2017/08/30 04:33:40 Training value function...
2017/08/30 04:33:43 step 0: mse=202857.545484 step=0.050000
2017/08/30 04:33:44 step 1: mse=202613.249529 step=0.050000
2017/08/30 04:33:45 step 2: mse=202334.807774 step=0.050000
2017/08/30 04:33:46 step 3: mse=203391.019097 step=0.050000
2017/08/30 04:33:47 step 4: mse=200972.811538 step=0.050000
2017/08/30 04:33:48 step 5: mse=201115.242329 step=0.050000
2017/08/30 04:33:49 step 6: mse=200648.681514 step=0.050000
2017/08/30 04:33:50 step 7: mse=199810.823676 step=0.050000
2017/08/30 04:33:50 Saving...
2017/08/30 04:33:50 Gathering batch of experience...
2017/08/30 04:34:20 batch 696: mean=8035.769231 stddev=8998.101583 entropy=0.387060 frames=6466 count=26
2017/08/30 04:34:20 Training policy...
2017/08/30 04:34:25 tune 0: objective=49.459809 reg=0.003871 prune=0
2017/08/30 04:34:26 step 0: objective=49.512097 reg=0.003870
2017/08/30 04:34:28 step 1: objective=49.563486 reg=0.003869
2017/08/30 04:34:29 step 2: objective=49.640422 reg=0.003870
2017/08/30 04:34:31 step 3: objective=49.702874 reg=0.003870
2017/08/30 04:34:32 step 4: objective=49.746738 reg=0.003869
2017/08/30 04:34:33 step 5: objective=49.795933 reg=0.003869
2017/08/30 04:34:35 step 6: objective=49.826351 reg=0.003868
2017/08/30 04:34:36 step 7: objective=49.868273 reg=0.003868
2017/08/30 04:34:36 Training value function...
2017/08/30 04:34:39 step 0: mse=146951.887032 step=0.050000
2017/08/30 04:34:40 step 1: mse=147516.465949 step=0.050000
2017/08/30 04:34:41 step 2: mse=147861.073822 step=0.050000
2017/08/30 04:34:42 step 3: mse=148280.451564 step=0.050000
2017/08/30 04:34:43 step 4: mse=148684.653700 step=0.050000
2017/08/30 04:34:44 step 5: mse=149053.578119 step=0.050000
2017/08/30 04:34:45 step 6: mse=149747.767691 step=0.050000
2017/08/30 04:34:46 step 7: mse=150595.615314 step=0.050000
2017/08/30 04:34:46 Saving...
2017/08/30 04:34:47 Gathering batch of experience...
2017/08/30 04:35:20 batch 697: mean=8253.928571 stddev=9157.818026 entropy=0.389345 frames=6965 count=28
2017/08/30 04:35:20 Training policy...
2017/08/30 04:35:26 tune 0: objective=61.180564 reg=0.003893 prune=0
2017/08/30 04:35:27 step 0: objective=61.287253 reg=0.003894
2017/08/30 04:35:29 step 1: objective=61.425844 reg=0.003894
2017/08/30 04:35:30 step 2: objective=61.523771 reg=0.003895
2017/08/30 04:35:32 step 3: objective=61.577423 reg=0.003895
2017/08/30 04:35:34 step 4: objective=61.645105 reg=0.003896
2017/08/30 04:35:35 step 5: objective=61.694934 reg=0.003895
2017/08/30 04:35:37 step 6: objective=61.759696 reg=0.003895
2017/08/30 04:35:38 step 7: objective=61.802966 reg=0.003895
2017/08/30 04:35:38 Training value function...
2017/08/30 04:35:41 step 0: mse=166216.601243 step=0.050000
2017/08/30 04:35:42 step 1: mse=165905.851176 step=0.050000
2017/08/30 04:35:43 step 2: mse=166058.612813 step=0.050000
2017/08/30 04:35:45 step 3: mse=166684.635900 step=0.050000
2017/08/30 04:35:46 step 4: mse=166478.423464 step=0.050000
2017/08/30 04:35:47 step 5: mse=166214.979903 step=0.050000
2017/08/30 04:35:48 step 6: mse=166016.444362 step=0.050000
2017/08/30 04:35:49 step 7: mse=165065.382952 step=0.050000
2017/08/30 04:35:49 Saving...
2017/08/30 04:35:49 Gathering batch of experience...
2017/08/30 04:36:22 batch 698: mean=9640.200000 stddev=9641.714316 entropy=0.390360 frames=6866 count=25
2017/08/30 04:36:22 Training policy...
2017/08/30 04:36:27 tune 0: objective=72.485190 reg=0.003904 prune=0
2017/08/30 04:36:29 step 0: objective=72.551968 reg=0.003904
2017/08/30 04:36:30 step 1: objective=72.609066 reg=0.003903
2017/08/30 04:36:32 step 2: objective=72.668102 reg=0.003902
2017/08/30 04:36:33 step 3: objective=72.718604 reg=0.003902
2017/08/30 04:36:35 step 4: objective=72.755703 reg=0.003902
2017/08/30 04:36:36 step 5: objective=72.799792 reg=0.003902
2017/08/30 04:36:38 step 6: objective=72.837505 reg=0.003902
2017/08/30 04:36:40 step 7: objective=72.870044 reg=0.003901
2017/08/30 04:36:40 Training value function...
2017/08/30 04:36:42 step 0: mse=185126.176785 step=0.050000
2017/08/30 04:36:44 step 1: mse=183784.368144 step=0.050000
2017/08/30 04:36:45 step 2: mse=182734.829387 step=0.050000
2017/08/30 04:36:46 step 3: mse=181608.760153 step=0.050000
2017/08/30 04:36:47 step 4: mse=180680.384595 step=0.050000
2017/08/30 04:36:48 step 5: mse=180822.792046 step=0.050000
2017/08/30 04:36:49 step 6: mse=179500.599257 step=0.050000
2017/08/30 04:36:50 step 7: mse=177095.590999 step=0.050000
2017/08/30 04:36:50 Saving...
2017/08/30 04:36:50 Gathering batch of experience...
2017/08/30 04:37:21 batch 699: mean=7746.296296 stddev=9011.731818 entropy=0.391172 frames=6576 count=27
2017/08/30 04:37:21 Training policy...
2017/08/30 04:37:27 tune 0: objective=64.371750 reg=0.003912 prune=0
2017/08/30 04:37:28 step 0: objective=64.467272 reg=0.003911
2017/08/30 04:37:30 step 1: objective=64.542954 reg=0.003910
2017/08/30 04:37:31 step 2: objective=64.623707 reg=0.003911
2017/08/30 04:37:33 step 3: objective=64.690095 reg=0.003910
2017/08/30 04:37:34 step 4: objective=64.776237 reg=0.003911
2017/08/30 04:37:36 step 5: objective=64.835334 reg=0.003911
2017/08/30 04:37:37 step 6: objective=64.881064 reg=0.003911
2017/08/30 04:37:39 step 7: objective=64.942361 reg=0.003911
2017/08/30 04:37:39 Training value function...
2017/08/30 04:37:41 step 0: mse=234493.190044 step=0.050000
2017/08/30 04:37:42 step 1: mse=232419.688232 step=0.050000
2017/08/30 04:37:43 step 2: mse=231366.693229 step=0.050000
2017/08/30 04:37:45 step 3: mse=227898.548283 step=0.050000
2017/08/30 04:37:46 step 4: mse=228206.248860 step=0.050000
2017/08/30 04:37:47 step 5: mse=227938.645300 step=0.050000
2017/08/30 04:37:48 step 6: mse=227097.270205 step=0.050000
2017/08/30 04:37:49 step 7: mse=222147.614460 step=0.050000
2017/08/30 04:37:49 Saving...
2017/08/30 04:37:49 Gathering batch of experience...
2017/08/30 04:38:20 batch 700: mean=8119.400000 stddev=8994.844892 entropy=0.391207 frames=6347 count=25
2017/08/30 04:38:20 Training policy...
2017/08/30 04:38:25 tune 0: objective=53.106724 reg=0.003912 prune=0
2017/08/30 04:38:26 step 0: objective=53.178012 reg=0.003911
2017/08/30 04:38:28 step 1: objective=53.249291 reg=0.003910
2017/08/30 04:38:29 step 2: objective=53.301397 reg=0.003910
2017/08/30 04:38:31 step 3: objective=53.361037 reg=0.003910
2017/08/30 04:38:32 step 4: objective=53.393429 reg=0.003909
2017/08/30 04:38:34 step 5: objective=53.429494 reg=0.003909
2017/08/30 04:38:35 step 6: objective=53.476180 reg=0.003908
2017/08/30 04:38:37 step 7: objective=53.522949 reg=0.003908
2017/08/30 04:38:37 Training value function...
2017/08/30 04:38:39 step 0: mse=149711.373180 step=0.050000
2017/08/30 04:38:40 step 1: mse=149993.453239 step=0.050000
2017/08/30 04:38:41 step 2: mse=149770.387636 step=0.050000
2017/08/30 04:38:42 step 3: mse=150443.408471 step=0.050000
2017/08/30 04:38:43 step 4: mse=152470.628330 step=0.050000
2017/08/30 04:38:44 step 5: mse=153019.336511 step=0.050000
2017/08/30 04:38:45 step 6: mse=153623.770105 step=0.050000
2017/08/30 04:38:46 step 7: mse=153430.409446 step=0.050000
2017/08/30 04:38:46 Saving...
2017/08/30 04:38:47 Gathering batch of experience...
2017/08/30 04:39:20 batch 701: mean=9350.925926 stddev=9774.369359 entropy=0.394172 frames=7078 count=27
2017/08/30 04:39:20 Training policy...
2017/08/30 04:39:25 tune 0: objective=72.584417 reg=0.003942 prune=0
2017/08/30 04:39:27 step 0: objective=72.670175 reg=0.003941
2017/08/30 04:39:29 step 1: objective=72.727629 reg=0.003941
2017/08/30 04:39:30 step 2: objective=72.794848 reg=0.003941
2017/08/30 04:39:32 step 3: objective=72.873349 reg=0.003940
2017/08/30 04:39:33 step 4: objective=72.935778 reg=0.003941
2017/08/30 04:39:35 step 5: objective=72.994212 reg=0.003940
2017/08/30 04:39:37 step 6: objective=73.060085 reg=0.003941
2017/08/30 04:39:38 step 7: objective=73.128894 reg=0.003940
2017/08/30 04:39:38 Training value function...
2017/08/30 04:39:41 step 0: mse=185340.848408 step=0.050000
2017/08/30 04:39:42 step 1: mse=183849.932161 step=0.050000
2017/08/30 04:39:44 step 2: mse=183124.958673 step=0.050000
2017/08/30 04:39:45 step 3: mse=181935.676012 step=0.050000
2017/08/30 04:39:46 step 4: mse=178920.750764 step=0.050000
2017/08/30 04:39:47 step 5: mse=177079.296280 step=0.050000
2017/08/30 04:39:48 step 6: mse=177350.953439 step=0.050000
2017/08/30 04:39:49 step 7: mse=174259.675155 step=0.050000
2017/08/30 04:39:49 Saving...
2017/08/30 04:39:49 Gathering batch of experience...
2017/08/30 04:40:18 batch 702: mean=11143.250000 stddev=9347.446613 entropy=0.386861 frames=6335 count=20
2017/08/30 04:40:18 Training policy...
2017/08/30 04:40:23 tune 0: objective=73.256028 reg=0.003869 prune=0
2017/08/30 04:40:25 step 0: objective=73.394574 reg=0.003868
2017/08/30 04:40:26 step 1: objective=73.518010 reg=0.003868
2017/08/30 04:40:28 step 2: objective=73.629607 reg=0.003868
2017/08/30 04:40:29 step 3: objective=73.693553 reg=0.003867
2017/08/30 04:40:31 step 4: objective=73.779104 reg=0.003866
2017/08/30 04:40:32 step 5: objective=73.813210 reg=0.003865
2017/08/30 04:40:34 step 6: objective=73.875390 reg=0.003864
2017/08/30 04:40:35 step 7: objective=73.943785 reg=0.003862
2017/08/30 04:40:35 Training value function...
2017/08/30 04:40:38 step 0: mse=247680.290737 step=0.050000
2017/08/30 04:40:39 step 1: mse=247082.844133 step=0.050000
2017/08/30 04:40:40 step 2: mse=244181.222962 step=0.050000
2017/08/30 04:40:41 step 3: mse=244961.040039 step=0.050000
2017/08/30 04:40:42 step 4: mse=244221.940476 step=0.050000
2017/08/30 04:40:43 step 5: mse=244162.728878 step=0.050000
2017/08/30 04:40:44 step 6: mse=244177.868864 step=0.050000
2017/08/30 04:40:45 step 7: mse=242071.267011 step=0.050000
2017/08/30 04:40:45 Saving...
2017/08/30 04:40:45 Gathering batch of experience...
2017/08/30 04:41:16 batch 703: mean=7428.392857 stddev=8892.852071 entropy=0.391341 frames=6612 count=28
2017/08/30 04:41:16 Training policy...
2017/08/30 04:41:21 tune 0: objective=55.672159 reg=0.003913 prune=0
2017/08/30 04:41:23 step 0: objective=55.781987 reg=0.003913
2017/08/30 04:41:24 step 1: objective=55.878252 reg=0.003913
2017/08/30 04:41:26 step 2: objective=55.947364 reg=0.003913
2017/08/30 04:41:28 step 3: objective=56.031997 reg=0.003913
2017/08/30 04:41:29 step 4: objective=56.104852 reg=0.003913
2017/08/30 04:41:31 step 5: objective=56.234134 reg=0.003912
2017/08/30 04:41:32 step 6: objective=56.278334 reg=0.003911
2017/08/30 04:41:34 step 7: objective=56.333173 reg=0.003909
2017/08/30 04:41:34 Training value function...
2017/08/30 04:41:36 step 0: mse=174273.278449 step=0.050000
2017/08/30 04:41:37 step 1: mse=173534.784785 step=0.050000
2017/08/30 04:41:39 step 2: mse=172265.996129 step=0.050000
2017/08/30 04:41:40 step 3: mse=171244.849883 step=0.050000
2017/08/30 04:41:41 step 4: mse=171770.488331 step=0.050000
2017/08/30 04:41:42 step 5: mse=172577.970266 step=0.050000
2017/08/30 04:41:43 step 6: mse=172432.785265 step=0.050000
2017/08/30 04:41:44 step 7: mse=172471.222463 step=0.050000
2017/08/30 04:41:44 Saving...
2017/08/30 04:41:44 Gathering batch of experience...
2017/08/30 04:42:14 batch 704: mean=12636.750000 stddev=9668.832178 entropy=0.389428 frames=6648 count=20
2017/08/30 04:42:14 Training policy...
2017/08/30 04:42:20 tune 0: objective=87.395316 reg=0.003894 prune=0
2017/08/30 04:42:21 step 0: objective=87.519668 reg=0.003894
2017/08/30 04:42:23 step 1: objective=87.634730 reg=0.003894
2017/08/30 04:42:24 step 2: objective=87.742733 reg=0.003892
2017/08/30 04:42:26 step 3: objective=87.814380 reg=0.003892
2017/08/30 04:42:27 step 4: objective=87.870581 reg=0.003892
2017/08/30 04:42:29 step 5: objective=87.916676 reg=0.003892
2017/08/30 04:42:30 step 6: objective=87.963354 reg=0.003891
2017/08/30 04:42:32 step 7: objective=88.003779 reg=0.003891
2017/08/30 04:42:32 Training value function...
2017/08/30 04:42:34 step 0: mse=240287.325770 step=0.050000
2017/08/30 04:42:36 step 1: mse=239316.048273 step=0.050000
2017/08/30 04:42:37 step 2: mse=239035.531084 step=0.050000
2017/08/30 04:42:38 step 3: mse=238469.008599 step=0.050000
2017/08/30 04:42:39 step 4: mse=237759.958142 step=0.050000
2017/08/30 04:42:40 step 5: mse=237427.962743 step=0.050000
2017/08/30 04:42:41 step 6: mse=235289.403896 step=0.050000
2017/08/30 04:42:42 step 7: mse=234524.544160 step=0.050000
2017/08/30 04:42:42 Saving...
2017/08/30 04:42:42 Gathering batch of experience...
2017/08/30 04:43:10 batch 705: mean=6670.740741 stddev=8708.597891 entropy=0.386099 frames=5818 count=27
2017/08/30 04:43:10 Training policy...
2017/08/30 04:43:14 tune 0: objective=46.992566 reg=0.003861 prune=0
2017/08/30 04:43:16 step 0: objective=47.042143 reg=0.003861
2017/08/30 04:43:17 step 1: objective=47.080542 reg=0.003861
2017/08/30 04:43:18 step 2: objective=47.112560 reg=0.003860
2017/08/30 04:43:20 step 3: objective=47.149681 reg=0.003860
2017/08/30 04:43:21 step 4: objective=47.170269 reg=0.003860
2017/08/30 04:43:22 step 5: objective=47.224325 reg=0.003858
2017/08/30 04:43:24 step 6: objective=47.267231 reg=0.003857
2017/08/30 04:43:25 step 7: objective=47.305834 reg=0.003857
2017/08/30 04:43:25 Training value function...
2017/08/30 04:43:27 step 0: mse=139492.214338 step=0.050000
2017/08/30 04:43:28 step 1: mse=139377.883345 step=0.050000
2017/08/30 04:43:29 step 2: mse=138134.277354 step=0.050000
2017/08/30 04:43:30 step 3: mse=136570.366206 step=0.050000
2017/08/30 04:43:31 step 4: mse=138414.644659 step=0.050000
2017/08/30 04:43:32 step 5: mse=137796.441013 step=0.050000
2017/08/30 04:43:33 step 6: mse=138037.781413 step=0.050000
2017/08/30 04:43:34 step 7: mse=137653.992369 step=0.050000
2017/08/30 04:43:34 Saving...
2017/08/30 04:43:34 Gathering batch of experience...
2017/08/30 04:44:05 batch 706: mean=7820.555556 stddev=8577.570593 entropy=0.384531 frames=6581 count=27
2017/08/30 04:44:05 Training policy...
2017/08/30 04:44:10 tune 0: objective=46.221499 reg=0.003845 prune=0
2017/08/30 04:44:11 step 0: objective=46.353105 reg=0.003843
2017/08/30 04:44:13 step 1: objective=46.473783 reg=0.003842
2017/08/30 04:44:14 step 2: objective=46.567567 reg=0.003842
2017/08/30 04:44:16 step 3: objective=46.601172 reg=0.003842
2017/08/30 04:44:17 step 4: objective=46.644383 reg=0.003842
2017/08/30 04:44:19 step 5: objective=46.681588 reg=0.003842
2017/08/30 04:44:20 step 6: objective=46.722658 reg=0.003842
2017/08/30 04:44:22 step 7: objective=46.792513 reg=0.003841
2017/08/30 04:44:22 Training value function...
2017/08/30 04:44:25 step 0: mse=206164.017140 step=0.050000
2017/08/30 04:44:26 step 1: mse=205692.832239 step=0.050000
2017/08/30 04:44:27 step 2: mse=205817.580430 step=0.050000
2017/08/30 04:44:28 step 3: mse=206116.703093 step=0.050000
2017/08/30 04:44:29 step 4: mse=208526.474567 step=0.050000
2017/08/30 04:44:30 step 5: mse=209014.644093 step=0.050000
2017/08/30 04:44:31 step 6: mse=210278.948121 step=0.050000
2017/08/30 04:44:32 step 7: mse=211858.083030 step=0.050000
2017/08/30 04:44:32 Saving...
2017/08/30 04:44:32 Gathering batch of experience...
2017/08/30 04:45:04 batch 707: mean=12478.636364 stddev=9787.679661 entropy=0.386825 frames=7313 count=22
2017/08/30 04:45:04 Training policy...
2017/08/30 04:45:10 tune 0: objective=89.322166 reg=0.003868 prune=0
2017/08/30 04:45:11 step 0: objective=89.388862 reg=0.003868
2017/08/30 04:45:13 step 1: objective=89.458815 reg=0.003868
2017/08/30 04:45:15 step 2: objective=89.517204 reg=0.003868
2017/08/30 04:45:16 step 3: objective=89.545458 reg=0.003868
2017/08/30 04:45:18 step 4: objective=89.578448 reg=0.003868
2017/08/30 04:45:20 step 5: objective=89.609351 reg=0.003867
2017/08/30 04:45:22 step 6: objective=89.669014 reg=0.003867
2017/08/30 04:45:23 step 7: objective=89.696747 reg=0.003867
2017/08/30 04:45:23 Training value function...
2017/08/30 04:45:26 step 0: mse=186974.577461 step=0.050000
2017/08/30 04:45:27 step 1: mse=184174.802260 step=0.050000
2017/08/30 04:45:29 step 2: mse=181570.432383 step=0.050000
2017/08/30 04:45:30 step 3: mse=179929.945582 step=0.050000
2017/08/30 04:45:31 step 4: mse=177835.754358 step=0.050000
2017/08/30 04:45:32 step 5: mse=174523.442550 step=0.050000
2017/08/30 04:45:33 step 6: mse=172509.673797 step=0.050000
2017/08/30 04:45:35 step 7: mse=171020.607071 step=0.050000
2017/08/30 04:45:35 Saving...
2017/08/30 04:45:35 Gathering batch of experience...
2017/08/30 04:46:02 batch 708: mean=5633.500000 stddev=7890.819259 entropy=0.386185 frames=5771 count=30
2017/08/30 04:46:02 Training policy...
2017/08/30 04:46:07 tune 0: objective=33.955589 reg=0.003862 prune=0
2017/08/30 04:46:08 step 0: objective=34.121559 reg=0.003862
2017/08/30 04:46:10 step 1: objective=34.250260 reg=0.003863
2017/08/30 04:46:11 step 2: objective=34.353299 reg=0.003863
2017/08/30 04:46:12 step 3: objective=34.415298 reg=0.003863
2017/08/30 04:46:14 step 4: objective=34.470786 reg=0.003863
2017/08/30 04:46:15 step 5: objective=34.525559 reg=0.003862
2017/08/30 04:46:16 step 6: objective=34.581924 reg=0.003862
2017/08/30 04:46:18 step 7: objective=34.621283 reg=0.003861
2017/08/30 04:46:18 Training value function...
2017/08/30 04:46:20 step 0: mse=161123.995156 step=0.050000
2017/08/30 04:46:21 step 1: mse=161272.282894 step=0.050000
2017/08/30 04:46:22 step 2: mse=161309.540697 step=0.050000
2017/08/30 04:46:23 step 3: mse=162267.462826 step=0.050000
2017/08/30 04:46:24 step 4: mse=163925.948102 step=0.050000
2017/08/30 04:46:25 step 5: mse=164374.978440 step=0.050000
2017/08/30 04:46:25 step 6: mse=164558.952277 step=0.050000
2017/08/30 04:46:26 step 7: mse=167068.914398 step=0.050000
2017/08/30 04:46:26 Saving...
2017/08/30 04:46:26 Gathering batch of experience...
2017/08/30 04:47:00 batch 709: mean=9620.000000 stddev=9265.187739 entropy=0.388048 frames=7301 count=26
2017/08/30 04:47:00 Training policy...
2017/08/30 04:47:06 tune 0: objective=66.479455 reg=0.003880 prune=0
2017/08/30 04:47:07 step 0: objective=66.582382 reg=0.003880
2017/08/30 04:47:09 step 1: objective=66.640730 reg=0.003880
2017/08/30 04:47:11 step 2: objective=66.695162 reg=0.003880
2017/08/30 04:47:12 step 3: objective=66.745497 reg=0.003880
2017/08/30 04:47:14 step 4: objective=66.811644 reg=0.003881
2017/08/30 04:47:16 step 5: objective=66.868896 reg=0.003881
2017/08/30 04:47:18 step 6: objective=66.901876 reg=0.003882
2017/08/30 04:47:19 step 7: objective=66.935202 reg=0.003882
2017/08/30 04:47:19 Training value function...
2017/08/30 04:47:22 step 0: mse=183686.706717 step=0.050000
2017/08/30 04:47:23 step 1: mse=185467.240496 step=0.050000
2017/08/30 04:47:25 step 2: mse=184948.080608 step=0.050000
2017/08/30 04:47:26 step 3: mse=184781.894550 step=0.050000
2017/08/30 04:47:27 step 4: mse=184345.724379 step=0.050000
2017/08/30 04:47:28 step 5: mse=184172.450039 step=0.050000
2017/08/30 04:47:29 step 6: mse=182649.054499 step=0.050000
2017/08/30 04:47:31 step 7: mse=182254.010190 step=0.050000
2017/08/30 04:47:31 Saving...
2017/08/30 04:47:31 Gathering batch of experience...
2017/08/30 04:48:03 batch 710: mean=9964.791667 stddev=9525.651714 entropy=0.389501 frames=6807 count=24
2017/08/30 04:48:03 Training policy...
2017/08/30 04:48:08 tune 0: objective=72.211680 reg=0.003895 prune=0
2017/08/30 04:48:09 step 0: objective=72.302662 reg=0.003896
2017/08/30 04:48:11 step 1: objective=72.393969 reg=0.003896
2017/08/30 04:48:13 step 2: objective=72.454468 reg=0.003896
2017/08/30 04:48:14 step 3: objective=72.508640 reg=0.003896
2017/08/30 04:48:16 step 4: objective=72.561871 reg=0.003896
2017/08/30 04:48:17 step 5: objective=72.666387 reg=0.003896
2017/08/30 04:48:19 step 6: objective=72.725489 reg=0.003896
2017/08/30 04:48:21 step 7: objective=72.760302 reg=0.003896
2017/08/30 04:48:21 Training value function...
2017/08/30 04:48:23 step 0: mse=185445.187891 step=0.050000
2017/08/30 04:48:24 step 1: mse=184198.499753 step=0.050000
2017/08/30 04:48:26 step 2: mse=183294.437607 step=0.050000
2017/08/30 04:48:27 step 3: mse=183249.522597 step=0.050000
2017/08/30 04:48:28 step 4: mse=184809.310554 step=0.050000
2017/08/30 04:48:29 step 5: mse=186081.966273 step=0.050000
2017/08/30 04:48:30 step 6: mse=184896.602552 step=0.050000
2017/08/30 04:48:31 step 7: mse=183758.274220 step=0.050000
2017/08/30 04:48:31 Saving...
2017/08/30 04:48:31 Gathering batch of experience...
2017/08/30 04:49:01 batch 711: mean=11000.000000 stddev=10159.076519 entropy=0.386592 frames=6161 count=21
2017/08/30 04:49:01 Training policy...
2017/08/30 04:49:05 tune 0: objective=94.907919 reg=0.003866 prune=0
2017/08/30 04:49:07 step 0: objective=94.983485 reg=0.003866
2017/08/30 04:49:08 step 1: objective=95.046127 reg=0.003867
2017/08/30 04:49:10 step 2: objective=95.104924 reg=0.003867
2017/08/30 04:49:11 step 3: objective=95.161510 reg=0.003867
2017/08/30 04:49:13 step 4: objective=95.227053 reg=0.003867
2017/08/30 04:49:14 step 5: objective=95.319865 reg=0.003867
2017/08/30 04:49:15 step 6: objective=95.377982 reg=0.003867
2017/08/30 04:49:17 step 7: objective=95.433260 reg=0.003867
2017/08/30 04:49:17 Training value function...
2017/08/30 04:49:19 step 0: mse=265773.486372 step=0.050000
2017/08/30 04:49:20 step 1: mse=264239.932787 step=0.050000
2017/08/30 04:49:21 step 2: mse=259430.374358 step=0.050000
2017/08/30 04:49:22 step 3: mse=256337.224851 step=0.050000
2017/08/30 04:49:23 step 4: mse=252913.740227 step=0.050000
2017/08/30 04:49:24 step 5: mse=247832.681650 step=0.050000
2017/08/30 04:49:25 step 6: mse=244578.624719 step=0.050000
2017/08/30 04:49:26 step 7: mse=242096.655426 step=0.050000
2017/08/30 04:49:26 Saving...
2017/08/30 04:49:26 Gathering batch of experience...
2017/08/30 04:49:57 batch 712: mean=10220.833333 stddev=9631.996988 entropy=0.388225 frames=6862 count=24
2017/08/30 04:49:57 Training policy...
2017/08/30 04:50:02 tune 0: objective=71.303465 reg=0.003882 prune=0
2017/08/30 04:50:04 step 0: objective=71.444645 reg=0.003881
2017/08/30 04:50:05 step 1: objective=71.551247 reg=0.003880
2017/08/30 04:50:07 step 2: objective=71.624681 reg=0.003879
2017/08/30 04:50:09 step 3: objective=71.719055 reg=0.003879
2017/08/30 04:50:10 step 4: objective=71.800404 reg=0.003878
2017/08/30 04:50:12 step 5: objective=71.875560 reg=0.003878
2017/08/30 04:50:13 step 6: objective=71.935505 reg=0.003877
2017/08/30 04:50:15 step 7: objective=71.987508 reg=0.003876
2017/08/30 04:50:15 Training value function...
2017/08/30 04:50:18 step 0: mse=241637.424505 step=0.050000
2017/08/30 04:50:19 step 1: mse=241148.104221 step=0.050000
2017/08/30 04:50:20 step 2: mse=239680.777541 step=0.050000
2017/08/30 04:50:21 step 3: mse=239735.361800 step=0.050000
2017/08/30 04:50:22 step 4: mse=240604.359505 step=0.050000
2017/08/30 04:50:23 step 5: mse=241456.172365 step=0.050000
2017/08/30 04:50:24 step 6: mse=242493.055716 step=0.050000
2017/08/30 04:50:26 step 7: mse=243017.553219 step=0.050000
2017/08/30 04:50:26 Saving...
2017/08/30 04:50:26 Gathering batch of experience...
2017/08/30 04:50:57 batch 713: mean=8496.153846 stddev=9551.995996 entropy=0.389082 frames=6555 count=26
2017/08/30 04:50:57 Training policy...
2017/08/30 04:51:02 tune 0: objective=63.311933 reg=0.003891 prune=0
2017/08/30 04:51:04 step 0: objective=63.364607 reg=0.003891
2017/08/30 04:51:05 step 1: objective=63.392491 reg=0.003891
2017/08/30 04:51:07 step 2: objective=63.423575 reg=0.003891
2017/08/30 04:51:08 step 3: objective=63.453351 reg=0.003891
2017/08/30 04:51:10 step 4: objective=63.482661 reg=0.003891
2017/08/30 04:51:11 step 5: objective=63.509730 reg=0.003891
2017/08/30 04:51:13 step 6: objective=63.534806 reg=0.003891
2017/08/30 04:51:15 step 7: objective=63.551278 reg=0.003891
2017/08/30 04:51:15 Training value function...
2017/08/30 04:51:17 step 0: mse=181338.871345 step=0.050000
2017/08/30 04:51:18 step 1: mse=179341.774870 step=0.050000
2017/08/30 04:51:19 step 2: mse=178297.150675 step=0.050000
2017/08/30 04:51:20 step 3: mse=177573.997856 step=0.050000
2017/08/30 04:51:22 step 4: mse=178622.816117 step=0.050000
2017/08/30 04:51:23 step 5: mse=179539.509907 step=0.050000
2017/08/30 04:51:24 step 6: mse=178680.015693 step=0.050000
2017/08/30 04:51:25 step 7: mse=177839.075620 step=0.050000
2017/08/30 04:51:25 Saving...
2017/08/30 04:51:25 Gathering batch of experience...
2017/08/30 04:51:56 batch 714: mean=6177.096774 stddev=8385.232389 entropy=0.388445 frames=6532 count=31
2017/08/30 04:51:56 Training policy...
2017/08/30 04:52:01 tune 0: objective=33.867176 reg=0.003884 prune=0
2017/08/30 04:52:02 step 0: objective=34.001612 reg=0.003883
2017/08/30 04:52:04 step 1: objective=34.105325 reg=0.003882
2017/08/30 04:52:05 step 2: objective=34.185541 reg=0.003882
2017/08/30 04:52:07 step 3: objective=34.245135 reg=0.003882
2017/08/30 04:52:08 step 4: objective=34.297320 reg=0.003883
2017/08/30 04:52:10 step 5: objective=34.341267 reg=0.003883
2017/08/30 04:52:11 step 6: objective=34.369355 reg=0.003883
2017/08/30 04:52:13 step 7: objective=34.409673 reg=0.003883
2017/08/30 04:52:13 Training value function...
2017/08/30 04:52:16 step 0: mse=168798.247859 step=0.050000
2017/08/30 04:52:17 step 1: mse=169412.434951 step=0.050000
2017/08/30 04:52:18 step 2: mse=171878.134622 step=0.050000
2017/08/30 04:52:19 step 3: mse=172171.484505 step=0.050000
2017/08/30 04:52:20 step 4: mse=173505.110607 step=0.050000
2017/08/30 04:52:21 step 5: mse=172263.646768 step=0.050000
2017/08/30 04:52:22 step 6: mse=173330.192880 step=0.050000
2017/08/30 04:52:23 step 7: mse=174055.121722 step=0.050000
2017/08/30 04:52:23 Saving...
2017/08/30 04:52:23 Gathering batch of experience...
2017/08/30 04:52:56 batch 715: mean=11290.000000 stddev=9871.505766 entropy=0.385708 frames=7022 count=23
2017/08/30 04:52:56 Training policy...
2017/08/30 04:53:02 tune 0: objective=90.471180 reg=0.003857 prune=0
2017/08/30 04:53:04 step 0: objective=90.601618 reg=0.003855
2017/08/30 04:53:05 step 1: objective=90.650055 reg=0.003854
2017/08/30 04:53:07 step 2: objective=90.689592 reg=0.003853
2017/08/30 04:53:09 step 3: objective=90.758981 reg=0.003853
2017/08/30 04:53:10 step 4: objective=90.816950 reg=0.003853
2017/08/30 04:53:12 step 5: objective=90.846251 reg=0.003853
2017/08/30 04:53:13 step 6: objective=90.896904 reg=0.003853
2017/08/30 04:53:15 step 7: objective=90.947976 reg=0.003854
2017/08/30 04:53:15 Training value function...
2017/08/30 04:53:18 step 0: mse=285512.310998 step=0.050000
2017/08/30 04:53:19 step 1: mse=278587.193143 step=0.050000
2017/08/30 04:53:20 step 2: mse=274204.246438 step=0.050000
2017/08/30 04:53:21 step 3: mse=273623.561818 step=0.050000
2017/08/30 04:53:23 step 4: mse=264732.827247 step=0.050000
2017/08/30 04:53:24 step 5: mse=263330.038214 step=0.050000
2017/08/30 04:53:25 step 6: mse=261926.204565 step=0.050000
2017/08/30 04:53:26 step 7: mse=261147.552817 step=0.050000
2017/08/30 04:53:26 Saving...
2017/08/30 04:53:26 Gathering batch of experience...
2017/08/30 04:53:59 batch 716: mean=9882.000000 stddev=9437.318475 entropy=0.386525 frames=7103 count=25
2017/08/30 04:53:59 Training policy...
2017/08/30 04:54:05 tune 0: objective=64.649950 reg=0.003865 prune=0
2017/08/30 04:54:07 step 0: objective=64.738962 reg=0.003864
2017/08/30 04:54:08 step 1: objective=64.815448 reg=0.003863
2017/08/30 04:54:10 step 2: objective=64.883694 reg=0.003862
2017/08/30 04:54:11 step 3: objective=64.948701 reg=0.003861
2017/08/30 04:54:13 step 4: objective=65.024066 reg=0.003861
2017/08/30 04:54:15 step 5: objective=65.087582 reg=0.003860
2017/08/30 04:54:16 step 6: objective=65.165867 reg=0.003860
2017/08/30 04:54:18 step 7: objective=65.216832 reg=0.003859
2017/08/30 04:54:18 Training value function...
2017/08/30 04:54:21 step 0: mse=258655.840154 step=0.050000
2017/08/30 04:54:22 step 1: mse=257536.255958 step=0.050000
2017/08/30 04:54:23 step 2: mse=257680.857056 step=0.050000
2017/08/30 04:54:24 step 3: mse=254454.775213 step=0.050000
2017/08/30 04:54:26 step 4: mse=254888.821838 step=0.050000
2017/08/30 04:54:27 step 5: mse=253969.547620 step=0.050000
2017/08/30 04:54:28 step 6: mse=254038.325662 step=0.050000
2017/08/30 04:54:29 step 7: mse=254165.441292 step=0.050000
2017/08/30 04:54:29 Saving...
2017/08/30 04:54:29 Gathering batch of experience...
2017/08/30 04:55:01 batch 717: mean=11780.952381 stddev=9181.920592 entropy=0.383973 frames=6827 count=21
2017/08/30 04:55:01 Training policy...
2017/08/30 04:55:07 tune 0: objective=70.865062 reg=0.003840 prune=0
2017/08/30 04:55:08 step 0: objective=70.990465 reg=0.003840
2017/08/30 04:55:10 step 1: objective=71.107295 reg=0.003840
2017/08/30 04:55:12 step 2: objective=71.191899 reg=0.003840
2017/08/30 04:55:13 step 3: objective=71.266914 reg=0.003840
2017/08/30 04:55:15 step 4: objective=71.318927 reg=0.003841
2017/08/30 04:55:16 step 5: objective=71.394875 reg=0.003842
2017/08/30 04:55:18 step 6: objective=71.445176 reg=0.003841
2017/08/30 04:55:19 step 7: objective=71.490909 reg=0.003841
2017/08/30 04:55:19 Training value function...
2017/08/30 04:55:22 step 0: mse=221486.422355 step=0.050000
2017/08/30 04:55:23 step 1: mse=221034.084682 step=0.050000
2017/08/30 04:55:25 step 2: mse=220442.859784 step=0.050000
2017/08/30 04:55:26 step 3: mse=220530.992949 step=0.050000
2017/08/30 04:55:27 step 4: mse=221270.650676 step=0.050000
2017/08/30 04:55:28 step 5: mse=220998.861441 step=0.050000
2017/08/30 04:55:29 step 6: mse=219780.773583 step=0.050000
2017/08/30 04:55:30 step 7: mse=219664.668934 step=0.050000
2017/08/30 04:55:30 Saving...
2017/08/30 04:55:30 Gathering batch of experience...
2017/08/30 04:56:00 batch 718: mean=7639.629630 stddev=8978.254690 entropy=0.385113 frames=6363 count=27
2017/08/30 04:56:00 Training policy...
2017/08/30 04:56:05 tune 0: objective=50.763103 reg=0.003851 prune=0
2017/08/30 04:56:07 step 0: objective=50.857634 reg=0.003851
2017/08/30 04:56:08 step 1: objective=50.934809 reg=0.003851
2017/08/30 04:56:10 step 2: objective=50.995261 reg=0.003851
2017/08/30 04:56:11 step 3: objective=51.072327 reg=0.003851
2017/08/30 04:56:13 step 4: objective=51.165046 reg=0.003850
2017/08/30 04:56:14 step 5: objective=51.229614 reg=0.003851
2017/08/30 04:56:16 step 6: objective=51.297634 reg=0.003850
2017/08/30 04:56:17 step 7: objective=51.334856 reg=0.003850
2017/08/30 04:56:17 Training value function...
2017/08/30 04:56:20 step 0: mse=217510.200340 step=0.050000
2017/08/30 04:56:21 step 1: mse=217705.426596 step=0.050000
2017/08/30 04:56:22 step 2: mse=218461.822963 step=0.050000
2017/08/30 04:56:23 step 3: mse=218649.263569 step=0.050000
2017/08/30 04:56:24 step 4: mse=218998.342395 step=0.050000
2017/08/30 04:56:25 step 5: mse=219491.473735 step=0.050000
2017/08/30 04:56:26 step 6: mse=221586.111272 step=0.050000
2017/08/30 04:56:27 step 7: mse=222550.579300 step=0.050000
2017/08/30 04:56:27 Saving...
2017/08/30 04:56:27 Gathering batch of experience...
2017/08/30 04:57:00 batch 719: mean=7308.333333 stddev=8755.293193 entropy=0.382661 frames=6970 count=30
2017/08/30 04:57:00 Training policy...
2017/08/30 04:57:05 tune 0: objective=55.061357 reg=0.003827 prune=0
2017/08/30 04:57:07 step 0: objective=55.167611 reg=0.003826
2017/08/30 04:57:09 step 1: objective=55.246489 reg=0.003825
2017/08/30 04:57:10 step 2: objective=55.307739 reg=0.003825
2017/08/30 04:57:12 step 3: objective=55.363630 reg=0.003825
2017/08/30 04:57:14 step 4: objective=55.428156 reg=0.003825
2017/08/30 04:57:15 step 5: objective=55.466428 reg=0.003825
2017/08/30 04:57:17 step 6: objective=55.499825 reg=0.003824
2017/08/30 04:57:18 step 7: objective=55.565576 reg=0.003824
2017/08/30 04:57:18 Training value function...
2017/08/30 04:57:21 step 0: mse=253361.308521 step=0.050000
2017/08/30 04:57:23 step 1: mse=247673.428317 step=0.050000
2017/08/30 04:57:24 step 2: mse=243032.476903 step=0.050000
2017/08/30 04:57:25 step 3: mse=243857.724938 step=0.050000
2017/08/30 04:57:26 step 4: mse=238686.647030 step=0.050000
2017/08/30 04:57:27 step 5: mse=238345.720955 step=0.050000
2017/08/30 04:57:28 step 6: mse=236677.911604 step=0.050000
2017/08/30 04:57:29 step 7: mse=235170.226838 step=0.050000
2017/08/30 04:57:29 Saving...
2017/08/30 04:57:29 Gathering batch of experience...
2017/08/30 04:58:04 batch 720: mean=10175.384615 stddev=9789.024066 entropy=0.388977 frames=7378 count=26
2017/08/30 04:58:04 Training policy...
2017/08/30 04:58:09 tune 0: objective=75.505515 reg=0.003890 prune=0
2017/08/30 04:58:11 step 0: objective=75.591590 reg=0.003889
2017/08/30 04:58:13 step 1: objective=75.679241 reg=0.003889
2017/08/30 04:58:15 step 2: objective=75.772753 reg=0.003888
2017/08/30 04:58:16 step 3: objective=75.830882 reg=0.003889
2017/08/30 04:58:18 step 4: objective=75.870036 reg=0.003889
2017/08/30 04:58:20 step 5: objective=75.909317 reg=0.003889
2017/08/30 04:58:21 step 6: objective=75.952452 reg=0.003888
2017/08/30 04:58:23 step 7: objective=75.979178 reg=0.003888
2017/08/30 04:58:23 Training value function...
2017/08/30 04:58:26 step 0: mse=199307.369078 step=0.050000
2017/08/30 04:58:28 step 1: mse=197528.568219 step=0.050000
2017/08/30 04:58:29 step 2: mse=196881.563779 step=0.050000
2017/08/30 04:58:30 step 3: mse=195082.315367 step=0.050000
2017/08/30 04:58:31 step 4: mse=193767.954095 step=0.050000
2017/08/30 04:58:32 step 5: mse=193304.155019 step=0.050000
2017/08/30 04:58:34 step 6: mse=192576.729362 step=0.050000
2017/08/30 04:58:35 step 7: mse=192070.131387 step=0.050000
2017/08/30 04:58:35 Saving...
2017/08/30 04:58:35 Gathering batch of experience...
2017/08/30 04:59:06 batch 721: mean=8861.200000 stddev=9336.184261 entropy=0.385203 frames=6469 count=25
2017/08/30 04:59:06 Training policy...
2017/08/30 04:59:11 tune 0: objective=60.104097 reg=0.003852 prune=0
2017/08/30 04:59:12 step 0: objective=60.226296 reg=0.003852
2017/08/30 04:59:14 step 1: objective=60.317007 reg=0.003852
2017/08/30 04:59:15 step 2: objective=60.402323 reg=0.003852
2017/08/30 04:59:17 step 3: objective=60.474851 reg=0.003852
2017/08/30 04:59:18 step 4: objective=60.563490 reg=0.003852
2017/08/30 04:59:20 step 5: objective=60.642854 reg=0.003851
2017/08/30 04:59:21 step 6: objective=60.694389 reg=0.003851
2017/08/30 04:59:23 step 7: objective=60.754198 reg=0.003850
2017/08/30 04:59:23 Training value function...
2017/08/30 04:59:26 step 0: mse=198337.178666 step=0.050000
2017/08/30 04:59:27 step 1: mse=199372.076944 step=0.050000
2017/08/30 04:59:28 step 2: mse=199866.531829 step=0.050000
2017/08/30 04:59:29 step 3: mse=200258.254893 step=0.050000
2017/08/30 04:59:30 step 4: mse=202217.088704 step=0.050000
2017/08/30 04:59:31 step 5: mse=201582.505780 step=0.050000
2017/08/30 04:59:32 step 6: mse=202506.526657 step=0.050000
2017/08/30 04:59:33 step 7: mse=201622.560522 step=0.050000
2017/08/30 04:59:33 Saving...
2017/08/30 04:59:33 Gathering batch of experience...
2017/08/30 05:00:01 batch 722: mean=8891.136364 stddev=9224.386889 entropy=0.382107 frames=5829 count=22
2017/08/30 05:00:01 Training policy...
2017/08/30 05:00:05 tune 0: objective=54.762170 reg=0.003821 prune=0
2017/08/30 05:00:07 step 0: objective=54.856971 reg=0.003821
2017/08/30 05:00:08 step 1: objective=54.930643 reg=0.003821
2017/08/30 05:00:10 step 2: objective=54.985734 reg=0.003821
2017/08/30 05:00:11 step 3: objective=55.043661 reg=0.003821
2017/08/30 05:00:12 step 4: objective=55.097540 reg=0.003821
2017/08/30 05:00:14 step 5: objective=55.154760 reg=0.003821
2017/08/30 05:00:15 step 6: objective=55.205824 reg=0.003821
2017/08/30 05:00:16 step 7: objective=55.265333 reg=0.003822
2017/08/30 05:00:16 Training value function...
2017/08/30 05:00:19 step 0: mse=189355.892650 step=0.050000
2017/08/30 05:00:20 step 1: mse=189327.921293 step=0.050000
2017/08/30 05:00:21 step 2: mse=189833.785008 step=0.050000
2017/08/30 05:00:22 step 3: mse=189617.835043 step=0.050000
2017/08/30 05:00:23 step 4: mse=189960.200340 step=0.050000
2017/08/30 05:00:23 step 5: mse=190532.137408 step=0.050000
2017/08/30 05:00:24 step 6: mse=190927.355530 step=0.050000
2017/08/30 05:00:25 step 7: mse=191020.088198 step=0.050000
2017/08/30 05:00:25 Saving...
2017/08/30 05:00:25 Gathering batch of experience...
2017/08/30 05:00:52 batch 723: mean=6494.629630 stddev=8227.877064 entropy=0.379705 frames=5810 count=27
2017/08/30 05:00:52 Training policy...
2017/08/30 05:00:57 tune 0: objective=41.895165 reg=0.003797 prune=0
2017/08/30 05:00:58 step 0: objective=42.034464 reg=0.003797
2017/08/30 05:00:59 step 1: objective=42.127523 reg=0.003797
2017/08/30 05:01:01 step 2: objective=42.180744 reg=0.003797
2017/08/30 05:01:02 step 3: objective=42.233399 reg=0.003797
2017/08/30 05:01:03 step 4: objective=42.294562 reg=0.003796
2017/08/30 05:01:05 step 5: objective=42.341870 reg=0.003797
2017/08/30 05:01:06 step 6: objective=42.391776 reg=0.003796
2017/08/30 05:01:08 step 7: objective=42.432853 reg=0.003796
2017/08/30 05:01:08 Training value function...
2017/08/30 05:01:10 step 0: mse=193511.640204 step=0.050000
2017/08/30 05:01:11 step 1: mse=192699.645367 step=0.050000
2017/08/30 05:01:12 step 2: mse=192599.097639 step=0.050000
2017/08/30 05:01:13 step 3: mse=193569.301728 step=0.050000
2017/08/30 05:01:14 step 4: mse=193378.586041 step=0.050000
2017/08/30 05:01:15 step 5: mse=193712.230714 step=0.050000
2017/08/30 05:01:16 step 6: mse=193964.156914 step=0.050000
2017/08/30 05:01:16 step 7: mse=194071.614300 step=0.050000
2017/08/30 05:01:16 Saving...
2017/08/30 05:01:16 Gathering batch of experience...
2017/08/30 05:01:49 batch 724: mean=13008.333333 stddev=9685.919989 entropy=0.385841 frames=7171 count=21
2017/08/30 05:01:49 Training policy...
2017/08/30 05:01:55 tune 0: objective=94.035612 reg=0.003858 prune=0
2017/08/30 05:01:56 step 0: objective=94.103228 reg=0.003857
2017/08/30 05:01:58 step 1: objective=94.161684 reg=0.003857
2017/08/30 05:02:00 step 2: objective=94.211233 reg=0.003857
2017/08/30 05:02:02 step 3: objective=94.284322 reg=0.003856
2017/08/30 05:02:03 step 4: objective=94.344513 reg=0.003857
2017/08/30 05:02:05 step 5: objective=94.410046 reg=0.003856
2017/08/30 05:02:07 step 6: objective=94.455254 reg=0.003856
2017/08/30 05:02:08 step 7: objective=94.488818 reg=0.003856
2017/08/30 05:02:08 Training value function...
2017/08/30 05:02:11 step 0: mse=206939.486519 step=0.050000
2017/08/30 05:02:12 step 1: mse=204335.784128 step=0.050000
2017/08/30 05:02:14 step 2: mse=201450.372913 step=0.050000
2017/08/30 05:02:15 step 3: mse=200164.837616 step=0.050000
2017/08/30 05:02:16 step 4: mse=196753.949122 step=0.050000
2017/08/30 05:02:17 step 5: mse=194974.238548 step=0.050000
2017/08/30 05:02:18 step 6: mse=191975.335590 step=0.050000
2017/08/30 05:02:19 step 7: mse=190208.473261 step=0.050000
2017/08/30 05:02:19 Saving...
2017/08/30 05:02:19 Gathering batch of experience...
2017/08/30 05:02:51 batch 725: mean=11015.652174 stddev=10106.145602 entropy=0.386740 frames=6780 count=23
2017/08/30 05:02:51 Training policy...
2017/08/30 05:02:57 tune 0: objective=89.299935 reg=0.003867 prune=0
2017/08/30 05:02:58 step 0: objective=89.408048 reg=0.003867
2017/08/30 05:03:00 step 1: objective=89.520289 reg=0.003867
2017/08/30 05:03:01 step 2: objective=89.599926 reg=0.003866
2017/08/30 05:03:03 step 3: objective=89.667764 reg=0.003867
2017/08/30 05:03:05 step 4: objective=89.709440 reg=0.003866
2017/08/30 05:03:06 step 5: objective=89.761348 reg=0.003866
2017/08/30 05:03:08 step 6: objective=89.811126 reg=0.003865
2017/08/30 05:03:09 step 7: objective=89.847004 reg=0.003865
2017/08/30 05:03:09 Training value function...
2017/08/30 05:03:12 step 0: mse=260027.580183 step=0.050000
2017/08/30 05:03:13 step 1: mse=256843.976161 step=0.050000
2017/08/30 05:03:14 step 2: mse=252452.436474 step=0.050000
2017/08/30 05:03:16 step 3: mse=250984.327091 step=0.050000
2017/08/30 05:03:17 step 4: mse=249726.417595 step=0.050000
2017/08/30 05:03:18 step 5: mse=247586.056268 step=0.050000
2017/08/30 05:03:19 step 6: mse=241589.864430 step=0.050000
2017/08/30 05:03:20 step 7: mse=239482.817708 step=0.050000
2017/08/30 05:03:20 Saving...
2017/08/30 05:03:20 Gathering batch of experience...
2017/08/30 05:03:46 batch 726: mean=7771.600000 stddev=9421.128353 entropy=0.382740 frames=5698 count=25
2017/08/30 05:03:46 Training policy...
2017/08/30 05:03:50 tune 0: objective=59.262148 reg=0.003827 prune=0
2017/08/30 05:03:52 step 0: objective=59.332441 reg=0.003827
2017/08/30 05:03:53 step 1: objective=59.394612 reg=0.003827
2017/08/30 05:03:54 step 2: objective=59.432520 reg=0.003827
2017/08/30 05:03:56 step 3: objective=59.472496 reg=0.003827
2017/08/30 05:03:57 step 4: objective=59.508841 reg=0.003828
2017/08/30 05:03:58 step 5: objective=59.541221 reg=0.003827
2017/08/30 05:04:00 step 6: objective=59.571440 reg=0.003827
2017/08/30 05:04:01 step 7: objective=59.598044 reg=0.003828
2017/08/30 05:04:01 Training value function...
2017/08/30 05:04:03 step 0: mse=163017.725610 step=0.050000
2017/08/30 05:04:04 step 1: mse=163185.430399 step=0.050000
2017/08/30 05:04:05 step 2: mse=163009.584372 step=0.050000
2017/08/30 05:04:06 step 3: mse=162441.143963 step=0.050000
2017/08/30 05:04:07 step 4: mse=161483.779231 step=0.050000
2017/08/30 05:04:08 step 5: mse=161162.825740 step=0.050000
2017/08/30 05:04:09 step 6: mse=162109.380440 step=0.050000
2017/08/30 05:04:10 step 7: mse=160499.967442 step=0.050000
2017/08/30 05:04:10 Saving...
2017/08/30 05:04:10 Gathering batch of experience...
2017/08/30 05:04:40 batch 727: mean=8263.461538 stddev=9573.281405 entropy=0.385269 frames=6250 count=26
2017/08/30 05:04:40 Training policy...
2017/08/30 05:04:45 tune 0: objective=63.296720 reg=0.003853 prune=0
2017/08/30 05:04:46 step 0: objective=63.359140 reg=0.003853
2017/08/30 05:04:48 step 1: objective=63.390855 reg=0.003853
2017/08/30 05:04:49 step 2: objective=63.437745 reg=0.003853
2017/08/30 05:04:51 step 3: objective=63.520870 reg=0.003852
2017/08/30 05:04:52 step 4: objective=63.554420 reg=0.003852
2017/08/30 05:04:54 step 5: objective=63.596240 reg=0.003851
2017/08/30 05:04:55 step 6: objective=63.626220 reg=0.003850
2017/08/30 05:04:57 step 7: objective=63.669820 reg=0.003850
2017/08/30 05:04:57 Training value function...
2017/08/30 05:04:59 step 0: mse=179309.826848 step=0.050000
2017/08/30 05:05:00 step 1: mse=179788.037506 step=0.050000
2017/08/30 05:05:01 step 2: mse=180406.696524 step=0.050000
2017/08/30 05:05:02 step 3: mse=180496.720934 step=0.050000
2017/08/30 05:05:03 step 4: mse=181001.916854 step=0.050000
2017/08/30 05:05:04 step 5: mse=181056.771646 step=0.050000
2017/08/30 05:05:05 step 6: mse=181808.799272 step=0.050000
2017/08/30 05:05:06 step 7: mse=182718.191821 step=0.050000
2017/08/30 05:05:06 Saving...
2017/08/30 05:05:06 Gathering batch of experience...
2017/08/30 05:05:37 batch 728: mean=7520.892857 stddev=8843.436433 entropy=0.382462 frames=6703 count=28
2017/08/30 05:05:37 Training policy...
2017/08/30 05:05:43 tune 0: objective=43.937206 reg=0.003825 prune=0
2017/08/30 05:05:44 step 0: objective=44.023945 reg=0.003823
2017/08/30 05:05:46 step 1: objective=44.079489 reg=0.003823
2017/08/30 05:05:47 step 2: objective=44.167369 reg=0.003822
2017/08/30 05:05:49 step 3: objective=44.216419 reg=0.003822
2017/08/30 05:05:51 step 4: objective=44.265138 reg=0.003822
2017/08/30 05:05:52 step 5: objective=44.311432 reg=0.003821
2017/08/30 05:05:54 step 6: objective=44.372893 reg=0.003821
2017/08/30 05:05:55 step 7: objective=44.392930 reg=0.003821
2017/08/30 05:05:55 Training value function...
2017/08/30 05:05:58 step 0: mse=153197.156058 step=0.050000
2017/08/30 05:05:59 step 1: mse=153569.771117 step=0.050000
2017/08/30 05:06:00 step 2: mse=153470.682010 step=0.050000
2017/08/30 05:06:01 step 3: mse=153618.036156 step=0.050000
2017/08/30 05:06:02 step 4: mse=154046.778233 step=0.050000
2017/08/30 05:06:03 step 5: mse=154529.470569 step=0.050000
2017/08/30 05:06:05 step 6: mse=153858.303623 step=0.050000
2017/08/30 05:06:06 step 7: mse=153649.640466 step=0.050000
2017/08/30 05:06:06 Saving...
2017/08/30 05:06:06 Gathering batch of experience...
2017/08/30 05:06:38 batch 729: mean=12533.571429 stddev=9685.090056 entropy=0.382763 frames=7025 count=21
2017/08/30 05:06:38 Training policy...
2017/08/30 05:06:43 tune 0: objective=89.330480 reg=0.003828 prune=0
2017/08/30 05:06:45 step 0: objective=89.440516 reg=0.003828
2017/08/30 05:06:47 step 1: objective=89.554804 reg=0.003827
2017/08/30 05:06:48 step 2: objective=89.651628 reg=0.003828
2017/08/30 05:06:50 step 3: objective=89.734075 reg=0.003828
2017/08/30 05:06:52 step 4: objective=89.778052 reg=0.003827
2017/08/30 05:06:53 step 5: objective=89.809893 reg=0.003827
2017/08/30 05:06:55 step 6: objective=89.837456 reg=0.003827
2017/08/30 05:06:57 step 7: objective=89.879564 reg=0.003828
2017/08/30 05:06:57 Training value function...
2017/08/30 05:06:59 step 0: mse=265491.672555 step=0.050000
2017/08/30 05:07:01 step 1: mse=262275.404243 step=0.050000
2017/08/30 05:07:02 step 2: mse=261931.227892 step=0.050000
2017/08/30 05:07:03 step 3: mse=260465.005159 step=0.050000
2017/08/30 05:07:04 step 4: mse=259284.282516 step=0.050000
2017/08/30 05:07:05 step 5: mse=255696.318446 step=0.050000
2017/08/30 05:07:06 step 6: mse=251158.689233 step=0.050000
2017/08/30 05:07:08 step 7: mse=250061.879516 step=0.050000
2017/08/30 05:07:08 Saving...
2017/08/30 05:07:08 Gathering batch of experience...
2017/08/30 05:07:41 batch 730: mean=9610.000000 stddev=9264.913342 entropy=0.378131 frames=7247 count=26
2017/08/30 05:07:41 Training policy...
2017/08/30 05:07:46 tune 0: objective=59.437315 reg=0.003781 prune=0
2017/08/30 05:07:48 step 0: objective=59.506395 reg=0.003781
2017/08/30 05:07:50 step 1: objective=59.574738 reg=0.003781
2017/08/30 05:07:52 step 2: objective=59.648044 reg=0.003781
2017/08/30 05:07:53 step 3: objective=59.709660 reg=0.003780
2017/08/30 05:07:55 step 4: objective=59.777641 reg=0.003780
2017/08/30 05:07:57 step 5: objective=59.817312 reg=0.003780
2017/08/30 05:07:58 step 6: objective=59.858006 reg=0.003780
2017/08/30 05:08:00 step 7: objective=59.904025 reg=0.003779
2017/08/30 05:08:00 Training value function...
2017/08/30 05:08:03 step 0: mse=199409.562668 step=0.050000
2017/08/30 05:08:04 step 1: mse=199794.009490 step=0.050000
2017/08/30 05:08:05 step 2: mse=200581.153252 step=0.050000
2017/08/30 05:08:07 step 3: mse=201188.253743 step=0.050000
2017/08/30 05:08:08 step 4: mse=202322.765370 step=0.050000
2017/08/30 05:08:09 step 5: mse=203080.413586 step=0.050000
2017/08/30 05:08:10 step 6: mse=203856.470996 step=0.050000
2017/08/30 05:08:11 step 7: mse=204923.461249 step=0.050000
2017/08/30 05:08:11 Saving...
2017/08/30 05:08:11 Gathering batch of experience...
2017/08/30 05:08:44 batch 731: mean=13779.750000 stddev=9509.321279 entropy=0.384018 frames=7136 count=20
2017/08/30 05:08:44 Training policy...
2017/08/30 05:08:50 tune 0: objective=87.805502 reg=0.003840 prune=0
2017/08/30 05:08:51 step 0: objective=87.880255 reg=0.003841
2017/08/30 05:08:53 step 1: objective=87.939909 reg=0.003841
2017/08/30 05:08:55 step 2: objective=87.999212 reg=0.003841
2017/08/30 05:08:56 step 3: objective=88.029227 reg=0.003842
2017/08/30 05:08:58 step 4: objective=88.056641 reg=0.003842
2017/08/30 05:09:00 step 5: objective=88.104873 reg=0.003842
2017/08/30 05:09:01 step 6: objective=88.152353 reg=0.003841
2017/08/30 05:09:03 step 7: objective=88.186405 reg=0.003841
2017/08/30 05:09:03 Training value function...
2017/08/30 05:09:06 step 0: mse=218376.917963 step=0.050000
2017/08/30 05:09:07 step 1: mse=217362.769940 step=0.050000
2017/08/30 05:09:08 step 2: mse=216289.375653 step=0.050000
2017/08/30 05:09:09 step 3: mse=215567.045276 step=0.050000
2017/08/30 05:09:11 step 4: mse=214893.531167 step=0.050000
2017/08/30 05:09:12 step 5: mse=213856.465976 step=0.050000
2017/08/30 05:09:13 step 6: mse=213319.491601 step=0.050000
2017/08/30 05:09:14 step 7: mse=211398.430264 step=0.050000
2017/08/30 05:09:14 Saving...
2017/08/30 05:09:14 Gathering batch of experience...
2017/08/30 05:09:49 batch 732: mean=13741.363636 stddev=9102.552237 entropy=0.379884 frames=7900 count=22
2017/08/30 05:09:49 Training policy...
2017/08/30 05:09:56 tune 0: objective=73.638940 reg=0.003799 prune=0
2017/08/30 05:09:58 step 0: objective=73.725309 reg=0.003798
2017/08/30 05:09:59 step 1: objective=73.802951 reg=0.003798
2017/08/30 05:10:01 step 2: objective=73.872896 reg=0.003798
2017/08/30 05:10:03 step 3: objective=73.926701 reg=0.003797
2017/08/30 05:10:05 step 4: objective=73.968734 reg=0.003798
2017/08/30 05:10:07 step 5: objective=73.999786 reg=0.003797
2017/08/30 05:10:09 step 6: objective=74.034304 reg=0.003797
2017/08/30 05:10:11 step 7: objective=74.055522 reg=0.003797
2017/08/30 05:10:11 Training value function...
2017/08/30 05:10:14 step 0: mse=208328.762311 step=0.050000
2017/08/30 05:10:15 step 1: mse=208267.938598 step=0.050000
2017/08/30 05:10:17 step 2: mse=208349.098946 step=0.050000
2017/08/30 05:10:18 step 3: mse=207633.921034 step=0.050000
2017/08/30 05:10:19 step 4: mse=206618.158016 step=0.050000
2017/08/30 05:10:20 step 5: mse=206342.160029 step=0.050000
2017/08/30 05:10:22 step 6: mse=206610.013509 step=0.050000
2017/08/30 05:10:23 step 7: mse=207083.952553 step=0.050000
2017/08/30 05:10:23 Saving...
2017/08/30 05:10:23 Gathering batch of experience...
2017/08/30 05:10:54 batch 733: mean=8949.200000 stddev=9468.541459 entropy=0.382029 frames=6606 count=25
2017/08/30 05:10:54 Training policy...
2017/08/30 05:10:59 tune 0: objective=60.854469 reg=0.003820 prune=0
2017/08/30 05:11:01 step 0: objective=60.971825 reg=0.003820
2017/08/30 05:11:02 step 1: objective=61.049756 reg=0.003821
2017/08/30 05:11:04 step 2: objective=61.119063 reg=0.003822
2017/08/30 05:11:05 step 3: objective=61.162135 reg=0.003822
2017/08/30 05:11:07 step 4: objective=61.195126 reg=0.003822
2017/08/30 05:11:09 step 5: objective=61.227189 reg=0.003822
2017/08/30 05:11:10 step 6: objective=61.262929 reg=0.003822
2017/08/30 05:11:12 step 7: objective=61.278345 reg=0.003822
2017/08/30 05:11:12 Training value function...
2017/08/30 05:11:14 step 0: mse=203134.767317 step=0.050000
2017/08/30 05:11:15 step 1: mse=202844.049055 step=0.050000
2017/08/30 05:11:17 step 2: mse=202567.740774 step=0.050000
2017/08/30 05:11:18 step 3: mse=201848.577437 step=0.050000
2017/08/30 05:11:19 step 4: mse=201235.657707 step=0.050000
2017/08/30 05:11:20 step 5: mse=201084.886795 step=0.050000
2017/08/30 05:11:21 step 6: mse=201167.356202 step=0.050000
2017/08/30 05:11:22 step 7: mse=201975.871485 step=0.050000
2017/08/30 05:11:22 Saving...
2017/08/30 05:11:22 Gathering batch of experience...
2017/08/30 05:11:54 batch 734: mean=7531.333333 stddev=9204.415148 entropy=0.381989 frames=6980 count=30
2017/08/30 05:11:54 Training policy...
2017/08/30 05:11:59 tune 0: objective=54.941225 reg=0.003820 prune=0
2017/08/30 05:12:01 step 0: objective=54.980023 reg=0.003820
2017/08/30 05:12:02 step 1: objective=55.013006 reg=0.003820
2017/08/30 05:12:04 step 2: objective=55.046754 reg=0.003820
2017/08/30 05:12:06 step 3: objective=55.087930 reg=0.003820
2017/08/30 05:12:07 step 4: objective=55.120715 reg=0.003820
2017/08/30 05:12:09 step 5: objective=55.149906 reg=0.003820
2017/08/30 05:12:11 step 6: objective=55.168916 reg=0.003820
2017/08/30 05:12:12 step 7: objective=55.195263 reg=0.003819
2017/08/30 05:12:12 Training value function...
2017/08/30 05:12:15 step 0: mse=151819.972441 step=0.050000
2017/08/30 05:12:16 step 1: mse=150830.223270 step=0.050000
2017/08/30 05:12:18 step 2: mse=150250.693745 step=0.050000
2017/08/30 05:12:19 step 3: mse=148761.415751 step=0.050000
2017/08/30 05:12:20 step 4: mse=148294.693028 step=0.050000
2017/08/30 05:12:21 step 5: mse=147994.854254 step=0.050000
2017/08/30 05:12:22 step 6: mse=146932.033304 step=0.050000
2017/08/30 05:12:23 step 7: mse=146321.254662 step=0.050000
2017/08/30 05:12:23 Saving...
2017/08/30 05:12:23 Gathering batch of experience...
2017/08/30 05:12:54 batch 735: mean=13992.105263 stddev=9770.765514 entropy=0.385755 frames=6606 count=19
2017/08/30 05:12:54 Training policy...
2017/08/30 05:12:59 tune 0: objective=97.756348 reg=0.003858 prune=0
2017/08/30 05:13:01 step 0: objective=97.834885 reg=0.003856
2017/08/30 05:13:02 step 1: objective=97.894026 reg=0.003856
2017/08/30 05:13:04 step 2: objective=97.947065 reg=0.003854
2017/08/30 05:13:05 step 3: objective=97.982033 reg=0.003854
2017/08/30 05:13:07 step 4: objective=98.012914 reg=0.003853
2017/08/30 05:13:09 step 5: objective=98.047362 reg=0.003852
2017/08/30 05:13:10 step 6: objective=98.094015 reg=0.003850
2017/08/30 05:13:12 step 7: objective=98.132342 reg=0.003849
2017/08/30 05:13:12 Training value function...
2017/08/30 05:13:14 step 0: mse=246660.014576 step=0.050000
2017/08/30 05:13:16 step 1: mse=245068.618559 step=0.050000
2017/08/30 05:13:17 step 2: mse=243187.834834 step=0.050000
2017/08/30 05:13:18 step 3: mse=240406.148008 step=0.050000
2017/08/30 05:13:19 step 4: mse=238978.597428 step=0.050000
2017/08/30 05:13:20 step 5: mse=236602.209395 step=0.050000
2017/08/30 05:13:21 step 6: mse=235685.008917 step=0.050000
2017/08/30 05:13:22 step 7: mse=233020.239750 step=0.050000
2017/08/30 05:13:22 Saving...
2017/08/30 05:13:22 Gathering batch of experience...
2017/08/30 05:13:53 batch 736: mean=7529.642857 stddev=8896.658575 entropy=0.382660 frames=6666 count=28
2017/08/30 05:13:53 Training policy...
2017/08/30 05:13:58 tune 0: objective=38.948828 reg=0.003827 prune=0
2017/08/30 05:14:00 step 0: objective=39.031175 reg=0.003827
2017/08/30 05:14:01 step 1: objective=39.098068 reg=0.003826
2017/08/30 05:14:03 step 2: objective=39.160500 reg=0.003826
2017/08/30 05:14:05 step 3: objective=39.221900 reg=0.003826
2017/08/30 05:14:06 step 4: objective=39.259695 reg=0.003826
2017/08/30 05:14:08 step 5: objective=39.302756 reg=0.003826
2017/08/30 05:14:09 step 6: objective=39.333291 reg=0.003825
2017/08/30 05:14:11 step 7: objective=39.387981 reg=0.003826
2017/08/30 05:14:11 Training value function...
2017/08/30 05:14:14 step 0: mse=160796.417152 step=0.050000
2017/08/30 05:14:15 step 1: mse=162111.073986 step=0.050000
2017/08/30 05:14:16 step 2: mse=163040.435192 step=0.050000
2017/08/30 05:14:17 step 3: mse=163981.182692 step=0.050000
2017/08/30 05:14:18 step 4: mse=164601.126941 step=0.050000
2017/08/30 05:14:19 step 5: mse=165331.442731 step=0.050000
2017/08/30 05:14:20 step 6: mse=167974.692937 step=0.050000
2017/08/30 05:14:21 step 7: mse=168578.593891 step=0.050000
2017/08/30 05:14:21 Saving...
2017/08/30 05:14:21 Gathering batch of experience...
2017/08/30 05:14:54 batch 737: mean=14347.894737 stddev=9577.555907 entropy=0.383241 frames=7010 count=19
2017/08/30 05:14:54 Training policy...
2017/08/30 05:14:59 tune 0: objective=92.024911 reg=0.003832 prune=0
2017/08/30 05:15:01 step 0: objective=92.078825 reg=0.003832
2017/08/30 05:15:03 step 1: objective=92.141583 reg=0.003832
2017/08/30 05:15:04 step 2: objective=92.215808 reg=0.003832
2017/08/30 05:15:06 step 3: objective=92.258301 reg=0.003831
2017/08/30 05:15:08 step 4: objective=92.296853 reg=0.003831
2017/08/30 05:15:09 step 5: objective=92.343830 reg=0.003830
2017/08/30 05:15:11 step 6: objective=92.389203 reg=0.003829
2017/08/30 05:15:13 step 7: objective=92.442002 reg=0.003829
2017/08/30 05:15:13 Training value function...
2017/08/30 05:15:15 step 0: mse=209688.091812 step=0.050000
2017/08/30 05:15:17 step 1: mse=208704.967826 step=0.050000
2017/08/30 05:15:18 step 2: mse=207518.417641 step=0.050000
2017/08/30 05:15:19 step 3: mse=204965.057149 step=0.050000
2017/08/30 05:15:20 step 4: mse=203366.044559 step=0.050000
2017/08/30 05:15:21 step 5: mse=201918.491531 step=0.050000
2017/08/30 05:15:22 step 6: mse=200395.841334 step=0.050000
2017/08/30 05:15:24 step 7: mse=197273.940022 step=0.050000
2017/08/30 05:15:24 Saving...
2017/08/30 05:15:24 Gathering batch of experience...
2017/08/30 05:15:59 batch 738: mean=10979.615385 stddev=10070.481323 entropy=0.382844 frames=7697 count=26
2017/08/30 05:15:59 Training policy...
2017/08/30 05:16:05 tune 0: objective=76.698218 reg=0.003828 prune=0
2017/08/30 05:16:07 step 0: objective=76.782074 reg=0.003828
2017/08/30 05:16:09 step 1: objective=76.865459 reg=0.003827
2017/08/30 05:16:11 step 2: objective=76.912011 reg=0.003827
2017/08/30 05:16:12 step 3: objective=76.961608 reg=0.003827
2017/08/30 05:16:14 step 4: objective=77.009484 reg=0.003828
2017/08/30 05:16:16 step 5: objective=77.061737 reg=0.003828
2017/08/30 05:16:18 step 6: objective=77.123335 reg=0.003828
2017/08/30 05:16:20 step 7: objective=77.176838 reg=0.003827
2017/08/30 05:16:20 Training value function...
2017/08/30 05:16:23 step 0: mse=245505.313933 step=0.050000
2017/08/30 05:16:24 step 1: mse=245677.061323 step=0.050000
2017/08/30 05:16:25 step 2: mse=245752.765683 step=0.050000
2017/08/30 05:16:27 step 3: mse=243067.296480 step=0.050000
2017/08/30 05:16:28 step 4: mse=242534.173549 step=0.050000
2017/08/30 05:16:29 step 5: mse=240826.351662 step=0.050000
2017/08/30 05:16:30 step 6: mse=237952.960702 step=0.050000
2017/08/30 05:16:32 step 7: mse=234378.083741 step=0.050000
2017/08/30 05:16:32 Saving...
2017/08/30 05:16:32 Gathering batch of experience...
2017/08/30 05:17:02 batch 739: mean=9653.043478 stddev=9545.159682 entropy=0.379560 frames=6425 count=23
2017/08/30 05:17:02 Training policy...
2017/08/30 05:17:07 tune 0: objective=62.271206 reg=0.003796 prune=0
2017/08/30 05:17:08 step 0: objective=62.377087 reg=0.003794
2017/08/30 05:17:10 step 1: objective=62.487067 reg=0.003793
2017/08/30 05:17:11 step 2: objective=62.587709 reg=0.003792
2017/08/30 05:17:13 step 3: objective=62.690948 reg=0.003791
2017/08/30 05:17:15 step 4: objective=62.770015 reg=0.003789
2017/08/30 05:17:16 step 5: objective=62.860593 reg=0.003787
2017/08/30 05:17:18 step 6: objective=62.940496 reg=0.003785
2017/08/30 05:17:19 step 7: objective=63.019596 reg=0.003783
2017/08/30 05:17:19 Training value function...
2017/08/30 05:17:22 step 0: mse=236730.220980 step=0.050000
2017/08/30 05:17:23 step 1: mse=235894.114964 step=0.050000
2017/08/30 05:17:24 step 2: mse=236782.275029 step=0.050000
2017/08/30 05:17:25 step 3: mse=236976.503784 step=0.050000
2017/08/30 05:17:26 step 4: mse=237142.491539 step=0.050000
2017/08/30 05:17:27 step 5: mse=235552.617493 step=0.050000
2017/08/30 05:17:28 step 6: mse=236048.888601 step=0.050000
2017/08/30 05:17:29 step 7: mse=236581.087298 step=0.050000
2017/08/30 05:17:29 Saving...
2017/08/30 05:17:29 Gathering batch of experience...
2017/08/30 05:18:05 batch 740: mean=9543.392857 stddev=9632.981112 entropy=0.377730 frames=7586 count=28
2017/08/30 05:18:05 Training policy...
2017/08/30 05:18:11 tune 0: objective=65.440062 reg=0.003777 prune=0
2017/08/30 05:18:13 step 0: objective=65.504919 reg=0.003778
2017/08/30 05:18:14 step 1: objective=65.588452 reg=0.003777
2017/08/30 05:18:16 step 2: objective=65.649815 reg=0.003776
2017/08/30 05:18:18 step 3: objective=65.711347 reg=0.003777
2017/08/30 05:18:20 step 4: objective=65.772546 reg=0.003777
2017/08/30 05:18:22 step 5: objective=65.825695 reg=0.003777
2017/08/30 05:18:24 step 6: objective=65.874728 reg=0.003777
2017/08/30 05:18:25 step 7: objective=65.914477 reg=0.003777
2017/08/30 05:18:25 Training value function...
2017/08/30 05:18:29 step 0: mse=201960.273538 step=0.050000
2017/08/30 05:18:30 step 1: mse=198717.633426 step=0.050000
2017/08/30 05:18:31 step 2: mse=199278.918334 step=0.050000
2017/08/30 05:18:32 step 3: mse=199892.983359 step=0.050000
2017/08/30 05:18:34 step 4: mse=198544.199751 step=0.050000
2017/08/30 05:18:35 step 5: mse=199031.739700 step=0.050000
2017/08/30 05:18:36 step 6: mse=200319.235572 step=0.050000
2017/08/30 05:18:37 step 7: mse=200854.203839 step=0.050000
2017/08/30 05:18:37 Saving...
2017/08/30 05:18:37 Gathering batch of experience...
2017/08/30 05:19:06 batch 741: mean=9543.181818 stddev=8896.946175 entropy=0.379997 frames=6391 count=22
2017/08/30 05:19:06 Training policy...
2017/08/30 05:19:11 tune 0: objective=40.178569 reg=0.003800 prune=0
2017/08/30 05:19:13 step 0: objective=40.400358 reg=0.003797
2017/08/30 05:19:14 step 1: objective=40.532744 reg=0.003797
2017/08/30 05:19:16 step 2: objective=40.626875 reg=0.003796
2017/08/30 05:19:17 step 3: objective=40.706098 reg=0.003795
2017/08/30 05:19:19 step 4: objective=40.775725 reg=0.003795
2017/08/30 05:19:20 step 5: objective=40.830807 reg=0.003795
2017/08/30 05:19:22 step 6: objective=40.888104 reg=0.003794
2017/08/30 05:19:23 step 7: objective=40.939351 reg=0.003792
2017/08/30 05:19:23 Training value function...
2017/08/30 05:19:26 step 0: mse=198584.651989 step=0.050000
2017/08/30 05:19:27 step 1: mse=197204.195207 step=0.050000
2017/08/30 05:19:28 step 2: mse=196261.691559 step=0.050000
2017/08/30 05:19:29 step 3: mse=197008.652626 step=0.050000
2017/08/30 05:19:30 step 4: mse=195529.415300 step=0.050000
2017/08/30 05:19:31 step 5: mse=196715.183857 step=0.050000
2017/08/30 05:19:32 step 6: mse=197251.823529 step=0.050000
2017/08/30 05:19:33 step 7: mse=198369.579162 step=0.050000
2017/08/30 05:19:33 Saving...
2017/08/30 05:19:33 Gathering batch of experience...
2017/08/30 05:20:04 batch 742: mean=8635.600000 stddev=9722.541059 entropy=0.381868 frames=6250 count=25
2017/08/30 05:20:04 Training policy...
2017/08/30 05:20:09 tune 0: objective=73.380090 reg=0.003819 prune=0
2017/08/30 05:20:11 step 0: objective=73.449990 reg=0.003818
2017/08/30 05:20:12 step 1: objective=73.508720 reg=0.003817
2017/08/30 05:20:14 step 2: objective=73.585900 reg=0.003817
2017/08/30 05:20:15 step 3: objective=73.635770 reg=0.003817
2017/08/30 05:20:17 step 4: objective=73.720685 reg=0.003818
2017/08/30 05:20:18 step 5: objective=73.764120 reg=0.003817
2017/08/30 05:20:20 step 6: objective=73.840020 reg=0.003817
2017/08/30 05:20:21 step 7: objective=73.877570 reg=0.003816
2017/08/30 05:20:21 Training value function...
2017/08/30 05:20:24 step 0: mse=235740.958017 step=0.050000
2017/08/30 05:20:25 step 1: mse=233194.546417 step=0.050000
2017/08/30 05:20:26 step 2: mse=231649.120397 step=0.050000
2017/08/30 05:20:27 step 3: mse=230426.668554 step=0.050000
2017/08/30 05:20:28 step 4: mse=227144.357551 step=0.050000
2017/08/30 05:20:29 step 5: mse=225825.885755 step=0.050000
2017/08/30 05:20:30 step 6: mse=225331.781240 step=0.050000
2017/08/30 05:20:31 step 7: mse=224410.876449 step=0.050000
2017/08/30 05:20:31 Saving...
2017/08/30 05:20:31 Gathering batch of experience...
2017/08/30 05:21:04 batch 743: mean=10030.192308 stddev=9855.865052 entropy=0.386916 frames=7158 count=26
2017/08/30 05:21:04 Training policy...
2017/08/30 05:21:10 tune 0: objective=78.281503 reg=0.003869 prune=0
2017/08/30 05:21:12 step 0: objective=78.367692 reg=0.003869
2017/08/30 05:21:14 step 1: objective=78.459320 reg=0.003869
2017/08/30 05:21:15 step 2: objective=78.520763 reg=0.003868
2017/08/30 05:21:17 step 3: objective=78.569415 reg=0.003867
2017/08/30 05:21:19 step 4: objective=78.605581 reg=0.003866
2017/08/30 05:21:20 step 5: objective=78.657743 reg=0.003866
2017/08/30 05:21:22 step 6: objective=78.722749 reg=0.003865
2017/08/30 05:21:24 step 7: objective=78.769375 reg=0.003864
2017/08/30 05:21:24 Training value function...
2017/08/30 05:21:27 step 0: mse=236175.365626 step=0.050000
2017/08/30 05:21:28 step 1: mse=233605.098688 step=0.050000
2017/08/30 05:21:29 step 2: mse=229453.919251 step=0.050000
2017/08/30 05:21:30 step 3: mse=224709.385375 step=0.050000
2017/08/30 05:21:32 step 4: mse=220554.584053 step=0.050000
2017/08/30 05:21:33 step 5: mse=219775.488170 step=0.050000
2017/08/30 05:21:34 step 6: mse=218509.848321 step=0.050000
2017/08/30 05:21:35 step 7: mse=217224.385656 step=0.050000
2017/08/30 05:21:35 Saving...
2017/08/30 05:21:35 Gathering batch of experience...
2017/08/30 05:22:06 batch 744: mean=11016.956522 stddev=9913.842950 entropy=0.378584 frames=6804 count=23
2017/08/30 05:22:06 Training policy...
2017/08/30 05:22:11 tune 0: objective=78.084647 reg=0.003786 prune=0
2017/08/30 05:22:13 step 0: objective=78.146467 reg=0.003785
2017/08/30 05:22:14 step 1: objective=78.195280 reg=0.003784
2017/08/30 05:22:16 step 2: objective=78.270843 reg=0.003784
2017/08/30 05:22:18 step 3: objective=78.340021 reg=0.003784
2017/08/30 05:22:19 step 4: objective=78.386445 reg=0.003783
2017/08/30 05:22:21 step 5: objective=78.428314 reg=0.003783
2017/08/30 05:22:23 step 6: objective=78.463137 reg=0.003783
2017/08/30 05:22:24 step 7: objective=78.509783 reg=0.003782
2017/08/30 05:22:24 Training value function...
2017/08/30 05:22:27 step 0: mse=226528.643386 step=0.050000
2017/08/30 05:22:28 step 1: mse=223623.048176 step=0.050000
2017/08/30 05:22:29 step 2: mse=223477.965414 step=0.050000
2017/08/30 05:22:30 step 3: mse=222900.943173 step=0.050000
2017/08/30 05:22:31 step 4: mse=222468.033889 step=0.050000
2017/08/30 05:22:33 step 5: mse=222727.521694 step=0.050000
2017/08/30 05:22:34 step 6: mse=222247.311088 step=0.050000
2017/08/30 05:22:35 step 7: mse=222180.289571 step=0.050000
2017/08/30 05:22:35 Saving...
2017/08/30 05:22:35 Gathering batch of experience...
2017/08/30 05:23:09 batch 745: mean=10910.769231 stddev=9982.758569 entropy=0.378996 frames=7637 count=26
2017/08/30 05:23:09 Training policy...
2017/08/30 05:23:16 tune 0: objective=71.265705 reg=0.003790 prune=0
2017/08/30 05:23:17 step 0: objective=71.381613 reg=0.003789
2017/08/30 05:23:19 step 1: objective=71.471357 reg=0.003788
2017/08/30 05:23:21 step 2: objective=71.513593 reg=0.003787
2017/08/30 05:23:23 step 3: objective=71.538112 reg=0.003787
2017/08/30 05:23:25 step 4: objective=71.569882 reg=0.003787
2017/08/30 05:23:27 step 5: objective=71.605383 reg=0.003787
2017/08/30 05:23:28 step 6: objective=71.640549 reg=0.003787
2017/08/30 05:23:30 step 7: objective=71.663603 reg=0.003786
2017/08/30 05:23:30 Training value function...
2017/08/30 05:23:33 step 0: mse=195111.694461 step=0.050000
2017/08/30 05:23:35 step 1: mse=195070.484988 step=0.050000
2017/08/30 05:23:36 step 2: mse=195702.940225 step=0.050000
2017/08/30 05:23:37 step 3: mse=194655.955286 step=0.050000
2017/08/30 05:23:38 step 4: mse=193277.852594 step=0.050000
2017/08/30 05:23:40 step 5: mse=193706.923267 step=0.050000
2017/08/30 05:23:41 step 6: mse=193536.184174 step=0.050000
2017/08/30 05:23:42 step 7: mse=192965.574811 step=0.050000
2017/08/30 05:23:42 Saving...
2017/08/30 05:23:42 Gathering batch of experience...
2017/08/30 05:24:16 batch 746: mean=12468.863636 stddev=9744.707996 entropy=0.380922 frames=7326 count=22
2017/08/30 05:24:16 Training policy...
2017/08/30 05:24:22 tune 0: objective=74.450135 reg=0.003809 prune=0
2017/08/30 05:24:23 step 0: objective=74.503285 reg=0.003809
2017/08/30 05:24:25 step 1: objective=74.564266 reg=0.003809
2017/08/30 05:24:27 step 2: objective=74.618943 reg=0.003808
2017/08/30 05:24:29 step 3: objective=74.665643 reg=0.003808
2017/08/30 05:24:30 step 4: objective=74.714237 reg=0.003807
2017/08/30 05:24:32 step 5: objective=74.750887 reg=0.003807
2017/08/30 05:24:34 step 6: objective=74.794269 reg=0.003808
2017/08/30 05:24:36 step 7: objective=74.839135 reg=0.003808
2017/08/30 05:24:36 Training value function...
2017/08/30 05:24:39 step 0: mse=208825.496322 step=0.050000
2017/08/30 05:24:40 step 1: mse=208663.767766 step=0.050000
2017/08/30 05:24:41 step 2: mse=209073.812061 step=0.050000
2017/08/30 05:24:42 step 3: mse=209258.088772 step=0.050000
2017/08/30 05:24:44 step 4: mse=209300.609844 step=0.050000
2017/08/30 05:24:45 step 5: mse=208839.650783 step=0.050000
2017/08/30 05:24:46 step 6: mse=208461.824913 step=0.050000
2017/08/30 05:24:47 step 7: mse=208139.962625 step=0.050000
2017/08/30 05:24:47 Saving...
2017/08/30 05:24:47 Gathering batch of experience...
2017/08/30 05:25:20 batch 747: mean=8260.000000 stddev=9432.841376 entropy=0.378059 frames=6941 count=28
2017/08/30 05:25:20 Training policy...
2017/08/30 05:25:26 tune 0: objective=56.692876 reg=0.003781 prune=0
2017/08/30 05:25:28 step 0: objective=56.759338 reg=0.003780
2017/08/30 05:25:29 step 1: objective=56.819884 reg=0.003779
2017/08/30 05:25:31 step 2: objective=56.872078 reg=0.003779
2017/08/30 05:25:33 step 3: objective=56.930292 reg=0.003779
2017/08/30 05:25:34 step 4: objective=56.975269 reg=0.003779
2017/08/30 05:25:36 step 5: objective=57.031025 reg=0.003778
2017/08/30 05:25:38 step 6: objective=57.066543 reg=0.003778
2017/08/30 05:25:39 step 7: objective=57.097302 reg=0.003777
2017/08/30 05:25:39 Training value function...
2017/08/30 05:25:42 step 0: mse=161138.894442 step=0.050000
2017/08/30 05:25:43 step 1: mse=160514.864907 step=0.050000
2017/08/30 05:25:44 step 2: mse=159580.187722 step=0.050000
2017/08/30 05:25:46 step 3: mse=159219.406979 step=0.050000
2017/08/30 05:25:47 step 4: mse=159866.225384 step=0.050000
2017/08/30 05:25:48 step 5: mse=160062.711749 step=0.050000
2017/08/30 05:25:49 step 6: mse=159570.073319 step=0.050000
2017/08/30 05:25:50 step 7: mse=158685.801198 step=0.050000
2017/08/30 05:25:50 Saving...
2017/08/30 05:25:50 Gathering batch of experience...
2017/08/30 05:26:22 batch 748: mean=10251.250000 stddev=9794.598347 entropy=0.379302 frames=6871 count=24
2017/08/30 05:26:22 Training policy...
2017/08/30 05:26:28 tune 0: objective=67.908128 reg=0.003793 prune=0
2017/08/30 05:26:29 step 0: objective=68.014417 reg=0.003793
2017/08/30 05:26:31 step 1: objective=68.132609 reg=0.003792
2017/08/30 05:26:33 step 2: objective=68.232731 reg=0.003792
2017/08/30 05:26:34 step 3: objective=68.299201 reg=0.003792
2017/08/30 05:26:36 step 4: objective=68.342235 reg=0.003792
2017/08/30 05:26:38 step 5: objective=68.377583 reg=0.003792
2017/08/30 05:26:39 step 6: objective=68.415264 reg=0.003792
2017/08/30 05:26:41 step 7: objective=68.463506 reg=0.003791
2017/08/30 05:26:41 Training value function...
2017/08/30 05:26:44 step 0: mse=203295.422717 step=0.050000
2017/08/30 05:26:45 step 1: mse=202239.959053 step=0.050000
2017/08/30 05:26:46 step 2: mse=201677.017619 step=0.050000
2017/08/30 05:26:47 step 3: mse=202687.503195 step=0.050000
2017/08/30 05:26:48 step 4: mse=203990.977315 step=0.050000
2017/08/30 05:26:49 step 5: mse=204395.353125 step=0.050000
2017/08/30 05:26:50 step 6: mse=205158.324381 step=0.050000
2017/08/30 05:26:51 step 7: mse=205578.416695 step=0.050000
2017/08/30 05:26:51 Saving...
2017/08/30 05:26:52 Gathering batch of experience...
2017/08/30 05:27:24 batch 749: mean=9652.800000 stddev=9569.445656 entropy=0.381101 frames=6881 count=25
2017/08/30 05:27:24 Training policy...
2017/08/30 05:27:30 tune 0: objective=67.568054 reg=0.003811 prune=0
2017/08/30 05:27:31 step 0: objective=67.640691 reg=0.003810
2017/08/30 05:27:33 step 1: objective=67.779683 reg=0.003810
2017/08/30 05:27:35 step 2: objective=67.876412 reg=0.003810
2017/08/30 05:27:36 step 3: objective=67.974985 reg=0.003809
2017/08/30 05:27:38 step 4: objective=68.041028 reg=0.003809
2017/08/30 05:27:40 step 5: objective=68.095857 reg=0.003808
2017/08/30 05:27:41 step 6: objective=68.162731 reg=0.003805
2017/08/30 05:27:43 step 7: objective=68.219018 reg=0.003803
2017/08/30 05:27:43 Training value function...
2017/08/30 05:27:46 step 0: mse=260425.218716 step=0.050000
2017/08/30 05:27:47 step 1: mse=261153.120971 step=0.050000
2017/08/30 05:27:48 step 2: mse=261398.923933 step=0.050000
2017/08/30 05:27:49 step 3: mse=256823.285064 step=0.050000
2017/08/30 05:27:50 step 4: mse=255421.241032 step=0.050000
2017/08/30 05:27:52 step 5: mse=255350.324382 step=0.050000
2017/08/30 05:27:53 step 6: mse=255284.378616 step=0.050000
2017/08/30 05:27:54 step 7: mse=255677.033836 step=0.050000
2017/08/30 05:27:54 Saving...
2017/08/30 05:27:54 Gathering batch of experience...
2017/08/30 05:28:26 batch 750: mean=9693.600000 stddev=9872.437948 entropy=0.376707 frames=6933 count=25
2017/08/30 05:28:26 Training policy...
2017/08/30 05:28:32 tune 0: objective=67.986419 reg=0.003767 prune=0
2017/08/30 05:28:33 step 0: objective=68.049798 reg=0.003766
2017/08/30 05:28:35 step 1: objective=68.103937 reg=0.003766
2017/08/30 05:28:37 step 2: objective=68.144130 reg=0.003766
2017/08/30 05:28:38 step 3: objective=68.182767 reg=0.003766
2017/08/30 05:28:40 step 4: objective=68.220242 reg=0.003766
2017/08/30 05:28:42 step 5: objective=68.254715 reg=0.003765
2017/08/30 05:28:43 step 6: objective=68.298342 reg=0.003766
2017/08/30 05:28:45 step 7: objective=68.327104 reg=0.003765
2017/08/30 05:28:45 Training value function...
2017/08/30 05:28:48 step 0: mse=184248.965097 step=0.050000
2017/08/30 05:28:49 step 1: mse=182965.343842 step=0.050000
2017/08/30 05:28:50 step 2: mse=182293.784354 step=0.050000
2017/08/30 05:28:51 step 3: mse=182374.545935 step=0.050000
2017/08/30 05:28:52 step 4: mse=181970.043701 step=0.050000
2017/08/30 05:28:54 step 5: mse=182756.418243 step=0.050000
2017/08/30 05:28:55 step 6: mse=181554.756135 step=0.050000
2017/08/30 05:28:56 step 7: mse=181494.935833 step=0.050000
2017/08/30 05:28:56 Saving...
2017/08/30 05:28:56 Gathering batch of experience...
2017/08/30 05:29:28 batch 751: mean=13606.250000 stddev=10080.277510 entropy=0.374972 frames=6845 count=20
2017/08/30 05:29:28 Training policy...
2017/08/30 05:29:33 tune 0: objective=99.404830 reg=0.003750 prune=0
2017/08/30 05:29:35 step 0: objective=99.468106 reg=0.003750
2017/08/30 05:29:37 step 1: objective=99.503944 reg=0.003750
2017/08/30 05:29:38 step 2: objective=99.558501 reg=0.003749
2017/08/30 05:29:40 step 3: objective=99.623484 reg=0.003749
2017/08/30 05:29:41 step 4: objective=99.668380 reg=0.003749
2017/08/30 05:29:43 step 5: objective=99.709341 reg=0.003749
2017/08/30 05:29:45 step 6: objective=99.748055 reg=0.003749
2017/08/30 05:29:46 step 7: objective=99.769147 reg=0.003749
2017/08/30 05:29:46 Training value function...
2017/08/30 05:29:49 step 0: mse=293130.340943 step=0.050000
2017/08/30 05:29:50 step 1: mse=288452.318119 step=0.050000
2017/08/30 05:29:51 step 2: mse=281967.352796 step=0.050000
2017/08/30 05:29:53 step 3: mse=274056.939093 step=0.050000
2017/08/30 05:29:54 step 4: mse=272424.596972 step=0.050000
2017/08/30 05:29:55 step 5: mse=266881.968259 step=0.050000
2017/08/30 05:29:56 step 6: mse=265308.722456 step=0.050000
2017/08/30 05:29:57 step 7: mse=261566.788539 step=0.050000
2017/08/30 05:29:57 Saving...
2017/08/30 05:29:57 Gathering batch of experience...
2017/08/30 05:30:28 batch 752: mean=11228.636364 stddev=9764.099617 entropy=0.374229 frames=6737 count=22
2017/08/30 05:30:28 Training policy...
2017/08/30 05:30:33 tune 0: objective=68.233742 reg=0.003742 prune=0
2017/08/30 05:30:35 step 0: objective=68.317482 reg=0.003743
2017/08/30 05:30:37 step 1: objective=68.414887 reg=0.003744
2017/08/30 05:30:38 step 2: objective=68.483380 reg=0.003744
2017/08/30 05:30:40 step 3: objective=68.570316 reg=0.003744
2017/08/30 05:30:42 step 4: objective=68.630307 reg=0.003745
2017/08/30 05:30:43 step 5: objective=68.680074 reg=0.003744
2017/08/30 05:30:45 step 6: objective=68.744304 reg=0.003745
2017/08/30 05:30:46 step 7: objective=68.802782 reg=0.003745
2017/08/30 05:30:46 Training value function...
2017/08/30 05:30:49 step 0: mse=240363.290386 step=0.050000
2017/08/30 05:30:50 step 1: mse=236035.772167 step=0.050000
2017/08/30 05:30:51 step 2: mse=237030.229767 step=0.050000
2017/08/30 05:30:52 step 3: mse=237717.248260 step=0.050000
2017/08/30 05:30:54 step 4: mse=238606.954876 step=0.050000
2017/08/30 05:30:55 step 5: mse=237544.230256 step=0.050000
2017/08/30 05:30:56 step 6: mse=238264.696501 step=0.050000
2017/08/30 05:30:57 step 7: mse=239725.248798 step=0.050000
2017/08/30 05:30:57 Saving...
2017/08/30 05:30:57 Gathering batch of experience...
2017/08/30 05:31:28 batch 753: mean=10124.000000 stddev=9826.731298 entropy=0.382638 frames=6958 count=25
2017/08/30 05:31:28 Training policy...
2017/08/30 05:31:34 tune 0: objective=59.874838 reg=0.003826 prune=0
2017/08/30 05:31:35 step 0: objective=59.940599 reg=0.003826
2017/08/30 05:31:37 step 1: objective=60.020372 reg=0.003825
2017/08/30 05:31:39 step 2: objective=60.091248 reg=0.003824
2017/08/30 05:31:40 step 3: objective=60.126909 reg=0.003824
2017/08/30 05:31:42 step 4: objective=60.191080 reg=0.003823
2017/08/30 05:31:44 step 5: objective=60.216967 reg=0.003823
2017/08/30 05:31:45 step 6: objective=60.261201 reg=0.003822
2017/08/30 05:31:47 step 7: objective=60.292321 reg=0.003821
2017/08/30 05:31:47 Training value function...
2017/08/30 05:31:50 step 0: mse=182630.586270 step=0.050000
2017/08/30 05:31:51 step 1: mse=182044.152243 step=0.050000
2017/08/30 05:31:52 step 2: mse=181629.619029 step=0.050000
2017/08/30 05:31:53 step 3: mse=183987.766413 step=0.050000
2017/08/30 05:31:55 step 4: mse=185969.787943 step=0.050000
2017/08/30 05:31:56 step 5: mse=185871.341250 step=0.050000
2017/08/30 05:31:57 step 6: mse=188192.052845 step=0.050000
2017/08/30 05:31:58 step 7: mse=190670.170393 step=0.050000
2017/08/30 05:31:58 Saving...
2017/08/30 05:31:58 Gathering batch of experience...
2017/08/30 05:32:28 batch 754: mean=12807.250000 stddev=9915.726962 entropy=0.376151 frames=6623 count=20
2017/08/30 05:32:28 Training policy...
2017/08/30 05:32:34 tune 0: objective=84.276093 reg=0.003762 prune=0
2017/08/30 05:32:35 step 0: objective=84.359778 reg=0.003761
2017/08/30 05:32:37 step 1: objective=84.438708 reg=0.003761
2017/08/30 05:32:39 step 2: objective=84.514089 reg=0.003762
2017/08/30 05:32:40 step 3: objective=84.608202 reg=0.003763
2017/08/30 05:32:42 step 4: objective=84.673458 reg=0.003762
2017/08/30 05:32:43 step 5: objective=84.731192 reg=0.003762
2017/08/30 05:32:45 step 6: objective=84.781226 reg=0.003763
2017/08/30 05:32:47 step 7: objective=84.833478 reg=0.003762
2017/08/30 05:32:47 Training value function...
2017/08/30 05:32:49 step 0: mse=280595.217642 step=0.050000
2017/08/30 05:32:50 step 1: mse=278977.900425 step=0.050000
2017/08/30 05:32:51 step 2: mse=278079.131651 step=0.050000
2017/08/30 05:32:53 step 3: mse=276830.068114 step=0.050000
2017/08/30 05:32:54 step 4: mse=276392.588416 step=0.050000
2017/08/30 05:32:55 step 5: mse=274753.567039 step=0.050000
2017/08/30 05:32:56 step 6: mse=274410.426184 step=0.050000
2017/08/30 05:32:57 step 7: mse=273279.911419 step=0.050000
2017/08/30 05:32:57 Saving...
2017/08/30 05:32:57 Gathering batch of experience...
2017/08/30 05:33:29 batch 755: mean=8787.115385 stddev=9565.307222 entropy=0.376166 frames=6757 count=26
2017/08/30 05:33:29 Training policy...
2017/08/30 05:33:35 tune 0: objective=53.103402 reg=0.003762 prune=0
2017/08/30 05:33:37 step 0: objective=53.187921 reg=0.003761
2017/08/30 05:33:38 step 1: objective=53.248095 reg=0.003760
2017/08/30 05:33:40 step 2: objective=53.304763 reg=0.003760
2017/08/30 05:33:41 step 3: objective=53.355599 reg=0.003761
2017/08/30 05:33:43 step 4: objective=53.397676 reg=0.003761
2017/08/30 05:33:45 step 5: objective=53.439595 reg=0.003761
2017/08/30 05:33:46 step 6: objective=53.486528 reg=0.003761
2017/08/30 05:33:48 step 7: objective=53.535861 reg=0.003760
2017/08/30 05:33:48 Training value function...
2017/08/30 05:33:51 step 0: mse=174957.112043 step=0.050000
2017/08/30 05:33:52 step 1: mse=175476.808582 step=0.050000
2017/08/30 05:33:53 step 2: mse=175575.786278 step=0.050000
2017/08/30 05:33:54 step 3: mse=177008.224977 step=0.050000
2017/08/30 05:33:55 step 4: mse=175936.913150 step=0.050000
2017/08/30 05:33:56 step 5: mse=175516.874002 step=0.050000
2017/08/30 05:33:57 step 6: mse=175522.109906 step=0.050000
2017/08/30 05:33:58 step 7: mse=174736.703880 step=0.050000
2017/08/30 05:33:58 Saving...
2017/08/30 05:33:59 Gathering batch of experience...
2017/08/30 05:34:30 batch 756: mean=11718.250000 stddev=9891.513822 entropy=0.375946 frames=6429 count=20
2017/08/30 05:34:30 Training policy...
2017/08/30 05:34:35 tune 0: objective=70.643155 reg=0.003759 prune=0
2017/08/30 05:34:36 step 0: objective=70.697815 reg=0.003760
2017/08/30 05:34:38 step 1: objective=70.742641 reg=0.003761
2017/08/30 05:34:39 step 2: objective=70.785834 reg=0.003760
2017/08/30 05:34:41 step 3: objective=70.830932 reg=0.003761
2017/08/30 05:34:42 step 4: objective=70.867130 reg=0.003761
2017/08/30 05:34:44 step 5: objective=70.895075 reg=0.003761
2017/08/30 05:34:46 step 6: objective=70.936892 reg=0.003761
2017/08/30 05:34:47 step 7: objective=70.973480 reg=0.003761
2017/08/30 05:34:47 Training value function...
2017/08/30 05:34:50 step 0: mse=161076.901551 step=0.050000
2017/08/30 05:34:51 step 1: mse=162679.451447 step=0.050000
2017/08/30 05:34:52 step 2: mse=161423.631807 step=0.050000
2017/08/30 05:34:53 step 3: mse=159638.232427 step=0.050000
2017/08/30 05:34:54 step 4: mse=158346.848403 step=0.050000
2017/08/30 05:34:55 step 5: mse=159805.252379 step=0.050000
2017/08/30 05:34:56 step 6: mse=159536.044290 step=0.050000
2017/08/30 05:34:57 step 7: mse=158690.219146 step=0.050000
2017/08/30 05:34:57 Saving...
2017/08/30 05:34:57 Gathering batch of experience...
2017/08/30 05:35:30 batch 757: mean=8481.724138 stddev=9412.450144 entropy=0.377676 frames=7262 count=29
2017/08/30 05:35:30 Training policy...
2017/08/30 05:35:36 tune 0: objective=55.172697 reg=0.003777 prune=0
2017/08/30 05:35:38 step 0: objective=55.219800 reg=0.003776
2017/08/30 05:35:40 step 1: objective=55.268405 reg=0.003776
2017/08/30 05:35:41 step 2: objective=55.311786 reg=0.003776
2017/08/30 05:35:43 step 3: objective=55.354104 reg=0.003777
2017/08/30 05:35:45 step 4: objective=55.389149 reg=0.003776
2017/08/30 05:35:47 step 5: objective=55.422146 reg=0.003776
2017/08/30 05:35:48 step 6: objective=55.455776 reg=0.003775
2017/08/30 05:35:50 step 7: objective=55.485709 reg=0.003774
2017/08/30 05:35:50 Training value function...
2017/08/30 05:35:53 step 0: mse=170688.122243 step=0.050000
2017/08/30 05:35:54 step 1: mse=169082.758580 step=0.050000
2017/08/30 05:35:55 step 2: mse=168439.209927 step=0.050000
2017/08/30 05:35:57 step 3: mse=166697.153182 step=0.050000
2017/08/30 05:35:58 step 4: mse=165539.518354 step=0.050000
2017/08/30 05:35:59 step 5: mse=167782.525147 step=0.050000
2017/08/30 05:36:00 step 6: mse=166760.584552 step=0.050000
2017/08/30 05:36:01 step 7: mse=166229.205619 step=0.050000
2017/08/30 05:36:01 Saving...
2017/08/30 05:36:01 Gathering batch of experience...
2017/08/30 05:36:32 batch 758: mean=5484.687500 stddev=7251.735130 entropy=0.373969 frames=6528 count=32
2017/08/30 05:36:32 Training policy...
2017/08/30 05:36:38 tune 0: objective=24.562591 reg=0.003740 prune=0
2017/08/30 05:36:39 step 0: objective=24.672689 reg=0.003739
2017/08/30 05:36:41 step 1: objective=24.799489 reg=0.003739
2017/08/30 05:36:42 step 2: objective=24.923244 reg=0.003740
2017/08/30 05:36:44 step 3: objective=25.014780 reg=0.003739
2017/08/30 05:36:45 step 4: objective=25.066236 reg=0.003739
2017/08/30 05:36:47 step 5: objective=25.110715 reg=0.003740
2017/08/30 05:36:49 step 6: objective=25.159213 reg=0.003740
2017/08/30 05:36:50 step 7: objective=25.190044 reg=0.003739
2017/08/30 05:36:50 Training value function...
2017/08/30 05:36:53 step 0: mse=208361.505951 step=0.050000
2017/08/30 05:36:54 step 1: mse=207207.242863 step=0.050000
2017/08/30 05:36:55 step 2: mse=206972.347074 step=0.050000
2017/08/30 05:36:56 step 3: mse=206237.719317 step=0.050000
2017/08/30 05:36:57 step 4: mse=203494.770857 step=0.050000
2017/08/30 05:36:58 step 5: mse=200041.926214 step=0.050000
2017/08/30 05:36:59 step 6: mse=198884.369881 step=0.050000
2017/08/30 05:37:00 step 7: mse=198847.664798 step=0.050000
2017/08/30 05:37:00 Saving...
2017/08/30 05:37:00 Gathering batch of experience...
2017/08/30 05:37:31 batch 759: mean=9152.916667 stddev=9762.031457 entropy=0.375369 frames=6236 count=24
2017/08/30 05:37:31 Training policy...
2017/08/30 05:37:36 tune 0: objective=69.609054 reg=0.003754 prune=0
2017/08/30 05:37:37 step 0: objective=69.678084 reg=0.003753
2017/08/30 05:37:39 step 1: objective=69.759757 reg=0.003753
2017/08/30 05:37:40 step 2: objective=69.811102 reg=0.003753
2017/08/30 05:37:42 step 3: objective=69.860568 reg=0.003751
2017/08/30 05:37:43 step 4: objective=69.888721 reg=0.003750
2017/08/30 05:37:45 step 5: objective=69.947452 reg=0.003749
2017/08/30 05:37:46 step 6: objective=69.991311 reg=0.003748
2017/08/30 05:37:48 step 7: objective=70.025437 reg=0.003748
2017/08/30 05:37:48 Training value function...
2017/08/30 05:37:50 step 0: mse=178687.148387 step=0.050000
2017/08/30 05:37:51 step 1: mse=177667.050284 step=0.050000
2017/08/30 05:37:52 step 2: mse=176601.931601 step=0.050000
2017/08/30 05:37:53 step 3: mse=176560.344091 step=0.050000
2017/08/30 05:37:54 step 4: mse=175561.511340 step=0.050000
2017/08/30 05:37:55 step 5: mse=174524.657486 step=0.050000
2017/08/30 05:37:56 step 6: mse=173690.526707 step=0.050000
2017/08/30 05:37:58 step 7: mse=172773.949753 step=0.050000
2017/08/30 05:37:58 Saving...
2017/08/30 05:37:58 Gathering batch of experience...
2017/08/30 05:38:27 batch 760: mean=7863.076923 stddev=9232.985711 entropy=0.380032 frames=6257 count=26
2017/08/30 05:38:27 Training policy...
2017/08/30 05:38:32 tune 0: objective=58.548031 reg=0.003800 prune=0
2017/08/30 05:38:33 step 0: objective=58.621414 reg=0.003800
2017/08/30 05:38:35 step 1: objective=58.706629 reg=0.003799
2017/08/30 05:38:37 step 2: objective=58.772460 reg=0.003798
2017/08/30 05:38:38 step 3: objective=58.829651 reg=0.003797
2017/08/30 05:38:40 step 4: objective=58.885478 reg=0.003796
2017/08/30 05:38:41 step 5: objective=58.924070 reg=0.003796
2017/08/30 05:38:43 step 6: objective=58.972011 reg=0.003796
2017/08/30 05:38:44 step 7: objective=59.001114 reg=0.003796
2017/08/30 05:38:44 Training value function...
2017/08/30 05:38:47 step 0: mse=149748.379779 step=0.050000
2017/08/30 05:38:48 step 1: mse=149881.640975 step=0.050000
2017/08/30 05:38:49 step 2: mse=149933.060679 step=0.050000
2017/08/30 05:38:50 step 3: mse=151963.815214 step=0.050000
2017/08/30 05:38:51 step 4: mse=151069.566440 step=0.050000
2017/08/30 05:38:52 step 5: mse=150075.315801 step=0.050000
2017/08/30 05:38:53 step 6: mse=149478.838384 step=0.050000
2017/08/30 05:38:54 step 7: mse=150002.011658 step=0.050000
2017/08/30 05:38:54 Saving...
2017/08/30 05:38:54 Gathering batch of experience...
2017/08/30 05:39:27 batch 761: mean=10822.916667 stddev=10108.774954 entropy=0.379546 frames=7130 count=24
2017/08/30 05:39:27 Training policy...
2017/08/30 05:39:33 tune 0: objective=84.093452 reg=0.003795 prune=0
2017/08/30 05:39:34 step 0: objective=84.184870 reg=0.003794
2017/08/30 05:39:36 step 1: objective=84.247195 reg=0.003794
2017/08/30 05:39:38 step 2: objective=84.330549 reg=0.003794
2017/08/30 05:39:39 step 3: objective=84.393250 reg=0.003794
2017/08/30 05:39:41 step 4: objective=84.445538 reg=0.003793
2017/08/30 05:39:43 step 5: objective=84.508661 reg=0.003794
2017/08/30 05:39:45 step 6: objective=84.557004 reg=0.003794
2017/08/30 05:39:46 step 7: objective=84.595065 reg=0.003793
2017/08/30 05:39:46 Training value function...
2017/08/30 05:39:49 step 0: mse=212643.792899 step=0.050000
2017/08/30 05:39:51 step 1: mse=211946.386949 step=0.050000
2017/08/30 05:39:52 step 2: mse=209981.744435 step=0.050000
2017/08/30 05:39:53 step 3: mse=209167.401717 step=0.050000
2017/08/30 05:39:54 step 4: mse=208226.803233 step=0.050000
2017/08/30 05:39:55 step 5: mse=207138.733606 step=0.050000
2017/08/30 05:39:56 step 6: mse=204763.364706 step=0.050000
2017/08/30 05:39:58 step 7: mse=204649.384708 step=0.050000
2017/08/30 05:39:58 Saving...
2017/08/30 05:39:58 Gathering batch of experience...
2017/08/30 05:40:29 batch 762: mean=6780.645161 stddev=8774.574683 entropy=0.376774 frames=6829 count=31
2017/08/30 05:40:29 Training policy...
2017/08/30 05:40:35 tune 0: objective=56.351525 reg=0.003768 prune=0
2017/08/30 05:40:36 step 0: objective=56.392622 reg=0.003767
2017/08/30 05:40:38 step 1: objective=56.414171 reg=0.003767
2017/08/30 05:40:40 step 2: objective=56.440255 reg=0.003766
2017/08/30 05:40:41 step 3: objective=56.468022 reg=0.003766
2017/08/30 05:40:43 step 4: objective=56.499643 reg=0.003765
2017/08/30 05:40:45 step 5: objective=56.533881 reg=0.003764
2017/08/30 05:40:46 step 6: objective=56.568014 reg=0.003764
2017/08/30 05:40:48 step 7: objective=56.600815 reg=0.003764
2017/08/30 05:40:48 Training value function...
2017/08/30 05:40:51 step 0: mse=168647.743475 step=0.050000
2017/08/30 05:40:52 step 1: mse=165828.331678 step=0.050000
2017/08/30 05:40:53 step 2: mse=163829.271142 step=0.050000
2017/08/30 05:40:54 step 3: mse=160575.362920 step=0.050000
2017/08/30 05:40:55 step 4: mse=159753.977224 step=0.050000
2017/08/30 05:40:56 step 5: mse=159100.962031 step=0.050000
2017/08/30 05:40:57 step 6: mse=158621.438924 step=0.050000
2017/08/30 05:40:58 step 7: mse=158434.049168 step=0.050000
2017/08/30 05:40:58 Saving...
2017/08/30 05:40:59 Gathering batch of experience...
2017/08/30 05:41:28 batch 763: mean=8538.076923 stddev=9502.660162 entropy=0.373656 frames=6591 count=26
2017/08/30 05:41:28 Training policy...
2017/08/30 05:41:34 tune 0: objective=69.479148 reg=0.003737 prune=0
2017/08/30 05:41:35 step 0: objective=69.523379 reg=0.003736
2017/08/30 05:41:37 step 1: objective=69.560575 reg=0.003735
2017/08/30 05:41:39 step 2: objective=69.598150 reg=0.003735
2017/08/30 05:41:40 step 3: objective=69.627081 reg=0.003735
2017/08/30 05:41:42 step 4: objective=69.657293 reg=0.003735
2017/08/30 05:41:43 step 5: objective=69.688851 reg=0.003735
2017/08/30 05:41:45 step 6: objective=69.712136 reg=0.003735
2017/08/30 05:41:47 step 7: objective=69.738227 reg=0.003734
2017/08/30 05:41:47 Training value function...
2017/08/30 05:41:49 step 0: mse=187840.720764 step=0.050000
2017/08/30 05:41:50 step 1: mse=187928.474006 step=0.050000
2017/08/30 05:41:51 step 2: mse=185651.869282 step=0.050000
2017/08/30 05:41:53 step 3: mse=185432.553009 step=0.050000
2017/08/30 05:41:54 step 4: mse=185677.705331 step=0.050000
2017/08/30 05:41:55 step 5: mse=185641.752416 step=0.050000
2017/08/30 05:41:56 step 6: mse=184809.894034 step=0.050000
2017/08/30 05:41:57 step 7: mse=184222.262025 step=0.050000
2017/08/30 05:41:57 Saving...
2017/08/30 05:41:57 Gathering batch of experience...
2017/08/30 05:42:27 batch 764: mean=9267.400000 stddev=9388.271526 entropy=0.369297 frames=6599 count=25
2017/08/30 05:42:27 Training policy...
2017/08/30 05:42:33 tune 0: objective=64.399265 reg=0.003693 prune=0
2017/08/30 05:42:34 step 0: objective=64.614942 reg=0.003691
2017/08/30 05:42:36 step 1: objective=64.726081 reg=0.003691
2017/08/30 05:42:37 step 2: objective=64.826934 reg=0.003690
2017/08/30 05:42:39 step 3: objective=64.902850 reg=0.003691
2017/08/30 05:42:41 step 4: objective=64.962712 reg=0.003690
2017/08/30 05:42:42 step 5: objective=65.022437 reg=0.003689
2017/08/30 05:42:44 step 6: objective=65.060885 reg=0.003690
2017/08/30 05:42:45 step 7: objective=65.089687 reg=0.003689
2017/08/30 05:42:45 Training value function...
2017/08/30 05:42:48 step 0: mse=247853.541047 step=0.050000
2017/08/30 05:42:49 step 1: mse=246695.405594 step=0.050000
2017/08/30 05:42:50 step 2: mse=244136.505698 step=0.050000
2017/08/30 05:42:51 step 3: mse=244864.938470 step=0.050000
2017/08/30 05:42:52 step 4: mse=245508.980680 step=0.050000
2017/08/30 05:42:54 step 5: mse=246225.568640 step=0.050000
2017/08/30 05:42:55 step 6: mse=245103.128175 step=0.050000
2017/08/30 05:42:56 step 7: mse=245500.752656 step=0.050000
2017/08/30 05:42:56 Saving...
2017/08/30 05:42:56 Gathering batch of experience...
2017/08/30 05:43:26 batch 765: mean=9431.458333 stddev=9409.210744 entropy=0.368360 frames=6506 count=24
2017/08/30 05:43:26 Training policy...
2017/08/30 05:43:32 tune 0: objective=69.295136 reg=0.003684 prune=0
2017/08/30 05:43:33 step 0: objective=69.393209 reg=0.003683
2017/08/30 05:43:35 step 1: objective=69.461502 reg=0.003683
2017/08/30 05:43:36 step 2: objective=69.523257 reg=0.003683
2017/08/30 05:43:38 step 3: objective=69.599802 reg=0.003684
2017/08/30 05:43:40 step 4: objective=69.641648 reg=0.003685
2017/08/30 05:43:41 step 5: objective=69.674027 reg=0.003684
2017/08/30 05:43:43 step 6: objective=69.727444 reg=0.003685
2017/08/30 05:43:44 step 7: objective=69.783527 reg=0.003685
2017/08/30 05:43:44 Training value function...
2017/08/30 05:43:47 step 0: mse=247148.506158 step=0.050000
2017/08/30 05:43:48 step 1: mse=247572.797573 step=0.050000
2017/08/30 05:43:49 step 2: mse=246912.911759 step=0.050000
2017/08/30 05:43:50 step 3: mse=246794.047454 step=0.050000
2017/08/30 05:43:51 step 4: mse=246332.008219 step=0.050000
2017/08/30 05:43:52 step 5: mse=245783.731490 step=0.050000
2017/08/30 05:43:53 step 6: mse=245435.419221 step=0.050000
2017/08/30 05:43:54 step 7: mse=245837.945773 step=0.050000
2017/08/30 05:43:54 Saving...
2017/08/30 05:43:54 Gathering batch of experience...
2017/08/30 05:44:29 batch 766: mean=7947.258065 stddev=9385.754291 entropy=0.377541 frames=7362 count=31
2017/08/30 05:44:29 Training policy...
2017/08/30 05:44:35 tune 0: objective=65.756308 reg=0.003775 prune=0
2017/08/30 05:44:37 step 0: objective=65.817207 reg=0.003775
2017/08/30 05:44:39 step 1: objective=65.851344 reg=0.003775
2017/08/30 05:44:40 step 2: objective=65.919854 reg=0.003774
2017/08/30 05:44:42 step 3: objective=65.979659 reg=0.003774
2017/08/30 05:44:44 step 4: objective=66.025507 reg=0.003775
2017/08/30 05:44:46 step 5: objective=66.063179 reg=0.003775
2017/08/30 05:44:48 step 6: objective=66.095028 reg=0.003774
2017/08/30 05:44:49 step 7: objective=66.123761 reg=0.003775
2017/08/30 05:44:49 Training value function...
2017/08/30 05:44:52 step 0: mse=232766.040830 step=0.050000
2017/08/30 05:44:54 step 1: mse=232148.590700 step=0.050000
2017/08/30 05:44:55 step 2: mse=226763.735230 step=0.050000
2017/08/30 05:44:56 step 3: mse=223005.172710 step=0.050000
2017/08/30 05:44:57 step 4: mse=222681.810007 step=0.050000
2017/08/30 05:44:58 step 5: mse=219654.175471 step=0.050000
2017/08/30 05:45:00 step 6: mse=219680.621694 step=0.050000
2017/08/30 05:45:01 step 7: mse=215878.311967 step=0.050000
2017/08/30 05:45:01 Saving...
2017/08/30 05:45:01 Gathering batch of experience...
2017/08/30 05:45:34 batch 767: mean=9528.076923 stddev=9750.792480 entropy=0.372792 frames=6983 count=26
2017/08/30 05:45:34 Training policy...
2017/08/30 05:45:39 tune 0: objective=68.259174 reg=0.003728 prune=0
2017/08/30 05:45:41 step 0: objective=68.330083 reg=0.003728
2017/08/30 05:45:43 step 1: objective=68.392176 reg=0.003728
2017/08/30 05:45:44 step 2: objective=68.466714 reg=0.003729
2017/08/30 05:45:46 step 3: objective=68.510637 reg=0.003729
2017/08/30 05:45:48 step 4: objective=68.563610 reg=0.003730
2017/08/30 05:45:50 step 5: objective=68.606880 reg=0.003729
2017/08/30 05:45:51 step 6: objective=68.645988 reg=0.003729
2017/08/30 05:45:53 step 7: objective=68.689447 reg=0.003729
2017/08/30 05:45:53 Training value function...
2017/08/30 05:45:56 step 0: mse=204189.965127 step=0.050000
2017/08/30 05:45:57 step 1: mse=204555.316356 step=0.050000
2017/08/30 05:45:58 step 2: mse=204003.911556 step=0.050000
2017/08/30 05:45:59 step 3: mse=204858.009778 step=0.050000
2017/08/30 05:46:00 step 4: mse=205500.862358 step=0.050000
2017/08/30 05:46:02 step 5: mse=206148.572833 step=0.050000
2017/08/30 05:46:03 step 6: mse=206776.174007 step=0.050000
2017/08/30 05:46:04 step 7: mse=207220.672244 step=0.050000
2017/08/30 05:46:04 Saving...
2017/08/30 05:46:04 Gathering batch of experience...
2017/08/30 05:46:34 batch 768: mean=7486.250000 stddev=9022.850419 entropy=0.378719 frames=6634 count=28
2017/08/30 05:46:34 Training policy...
2017/08/30 05:46:40 tune 0: objective=47.109535 reg=0.003787 prune=0
2017/08/30 05:46:41 step 0: objective=47.182398 reg=0.003786
2017/08/30 05:46:43 step 1: objective=47.261254 reg=0.003786
2017/08/30 05:46:45 step 2: objective=47.335978 reg=0.003785
2017/08/30 05:46:46 step 3: objective=47.404776 reg=0.003783
2017/08/30 05:46:48 step 4: objective=47.465424 reg=0.003783
2017/08/30 05:46:49 step 5: objective=47.511791 reg=0.003782
2017/08/30 05:46:51 step 6: objective=47.560969 reg=0.003781
2017/08/30 05:46:53 step 7: objective=47.616629 reg=0.003781
2017/08/30 05:46:53 Training value function...
2017/08/30 05:46:55 step 0: mse=192528.064933 step=0.050000
2017/08/30 05:46:57 step 1: mse=191727.702727 step=0.050000
2017/08/30 05:46:58 step 2: mse=192782.707888 step=0.050000
2017/08/30 05:46:59 step 3: mse=193645.337096 step=0.050000
2017/08/30 05:47:00 step 4: mse=192666.244466 step=0.050000
2017/08/30 05:47:01 step 5: mse=192459.091253 step=0.050000
2017/08/30 05:47:02 step 6: mse=193337.181250 step=0.050000
2017/08/30 05:47:03 step 7: mse=193939.946147 step=0.050000
2017/08/30 05:47:03 Saving...
2017/08/30 05:47:03 Gathering batch of experience...
2017/08/30 05:47:37 batch 769: mean=11848.913043 stddev=9785.709074 entropy=0.372954 frames=7409 count=23
2017/08/30 05:47:37 Training policy...
2017/08/30 05:47:43 tune 0: objective=84.931789 reg=0.003730 prune=0
2017/08/30 05:47:45 step 0: objective=85.012274 reg=0.003728
2017/08/30 05:47:47 step 1: objective=85.102915 reg=0.003728
2017/08/30 05:47:48 step 2: objective=85.193380 reg=0.003727
2017/08/30 05:47:50 step 3: objective=85.239177 reg=0.003727
2017/08/30 05:47:52 step 4: objective=85.298488 reg=0.003726
2017/08/30 05:47:54 step 5: objective=85.332585 reg=0.003726
2017/08/30 05:47:56 step 6: objective=85.375287 reg=0.003725
2017/08/30 05:47:58 step 7: objective=85.402450 reg=0.003725
2017/08/30 05:47:58 Training value function...
2017/08/30 05:48:01 step 0: mse=243499.325142 step=0.050000
2017/08/30 05:48:02 step 1: mse=242285.689146 step=0.050000
2017/08/30 05:48:03 step 2: mse=240725.824496 step=0.050000
2017/08/30 05:48:04 step 3: mse=239554.423811 step=0.050000
2017/08/30 05:48:06 step 4: mse=235464.317297 step=0.050000
2017/08/30 05:48:07 step 5: mse=234757.229818 step=0.050000
2017/08/30 05:48:08 step 6: mse=233479.829937 step=0.050000
2017/08/30 05:48:09 step 7: mse=233195.311669 step=0.050000
2017/08/30 05:48:09 Saving...
2017/08/30 05:48:09 Gathering batch of experience...
2017/08/30 05:48:42 batch 770: mean=11428.043478 stddev=10044.767699 entropy=0.369518 frames=7085 count=23
2017/08/30 05:48:42 Training policy...
2017/08/30 05:48:48 tune 0: objective=84.907542 reg=0.003695 prune=0
2017/08/30 05:48:50 step 0: objective=84.984148 reg=0.003695
2017/08/30 05:48:52 step 1: objective=85.036882 reg=0.003695
2017/08/30 05:48:53 step 2: objective=85.154146 reg=0.003695
2017/08/30 05:48:55 step 3: objective=85.230072 reg=0.003695
2017/08/30 05:48:57 step 4: objective=85.279076 reg=0.003695
2017/08/30 05:48:59 step 5: objective=85.314573 reg=0.003694
2017/08/30 05:49:00 step 6: objective=85.359915 reg=0.003692
2017/08/30 05:49:02 step 7: objective=85.408398 reg=0.003691
2017/08/30 05:49:02 Training value function...
2017/08/30 05:49:05 step 0: mse=296251.429830 step=0.050000
2017/08/30 05:49:06 step 1: mse=294393.152095 step=0.050000
2017/08/30 05:49:07 step 2: mse=285363.573355 step=0.050000
2017/08/30 05:49:09 step 3: mse=277775.124150 step=0.050000
2017/08/30 05:49:10 step 4: mse=275681.462261 step=0.050000
2017/08/30 05:49:11 step 5: mse=273366.602877 step=0.050000
2017/08/30 05:49:12 step 6: mse=267445.593475 step=0.050000
2017/08/30 05:49:13 step 7: mse=261667.207401 step=0.050000
2017/08/30 05:49:13 Saving...
2017/08/30 05:49:13 Gathering batch of experience...
2017/08/30 05:49:48 batch 771: mean=11578.750000 stddev=9889.415875 entropy=0.372763 frames=7496 count=24
2017/08/30 05:49:48 Training policy...
2017/08/30 05:49:54 tune 0: objective=76.333053 reg=0.003728 prune=0
2017/08/30 05:49:56 step 0: objective=76.392268 reg=0.003727
2017/08/30 05:49:58 step 1: objective=76.457302 reg=0.003726
2017/08/30 05:49:59 step 2: objective=76.518710 reg=0.003725
2017/08/30 05:50:01 step 3: objective=76.573172 reg=0.003725
2017/08/30 05:50:03 step 4: objective=76.607716 reg=0.003725
2017/08/30 05:50:05 step 5: objective=76.655450 reg=0.003724
2017/08/30 05:50:07 step 6: objective=76.704409 reg=0.003723
2017/08/30 05:50:09 step 7: objective=76.728063 reg=0.003723
2017/08/30 05:50:09 Training value function...
2017/08/30 05:50:12 step 0: mse=234311.810764 step=0.050000
2017/08/30 05:50:13 step 1: mse=234057.149719 step=0.050000
2017/08/30 05:50:14 step 2: mse=233524.134211 step=0.050000
2017/08/30 05:50:15 step 3: mse=233862.655644 step=0.050000
2017/08/30 05:50:17 step 4: mse=232308.565035 step=0.050000
2017/08/30 05:50:18 step 5: mse=231912.068185 step=0.050000
2017/08/30 05:50:19 step 6: mse=230006.018677 step=0.050000
2017/08/30 05:50:20 step 7: mse=230400.877568 step=0.050000
2017/08/30 05:50:20 Saving...
2017/08/30 05:50:20 Gathering batch of experience...
2017/08/30 05:50:51 batch 772: mean=12842.500000 stddev=9885.631429 entropy=0.369946 frames=6766 count=20
2017/08/30 05:50:51 Training policy...
2017/08/30 05:50:57 tune 0: objective=76.576093 reg=0.003699 prune=0
2017/08/30 05:50:58 step 0: objective=76.646953 reg=0.003699
2017/08/30 05:51:00 step 1: objective=76.715489 reg=0.003698
2017/08/30 05:51:02 step 2: objective=76.778470 reg=0.003697
2017/08/30 05:51:03 step 3: objective=76.843533 reg=0.003696
2017/08/30 05:51:05 step 4: objective=76.891424 reg=0.003696
2017/08/30 05:51:07 step 5: objective=76.939366 reg=0.003695
2017/08/30 05:51:08 step 6: objective=76.961406 reg=0.003695
2017/08/30 05:51:10 step 7: objective=76.999607 reg=0.003694
2017/08/30 05:51:10 Training value function...
2017/08/30 05:51:13 step 0: mse=190923.118827 step=0.050000
2017/08/30 05:51:14 step 1: mse=190144.392425 step=0.050000
2017/08/30 05:51:15 step 2: mse=189126.796017 step=0.050000
2017/08/30 05:51:16 step 3: mse=188956.995823 step=0.050000
2017/08/30 05:51:17 step 4: mse=188748.504488 step=0.050000
2017/08/30 05:51:18 step 5: mse=189759.721864 step=0.050000
2017/08/30 05:51:19 step 6: mse=187204.073106 step=0.050000
2017/08/30 05:51:20 step 7: mse=187026.326725 step=0.050000
2017/08/30 05:51:20 Saving...
2017/08/30 05:51:20 Gathering batch of experience...
2017/08/30 05:51:56 batch 773: mean=11599.200000 stddev=9839.410925 entropy=0.372066 frames=7834 count=25
2017/08/30 05:51:56 Training policy...
2017/08/30 05:52:03 tune 0: objective=65.639249 reg=0.003721 prune=0
2017/08/30 05:52:04 step 0: objective=65.729010 reg=0.003720
2017/08/30 05:52:06 step 1: objective=65.793524 reg=0.003720
2017/08/30 05:52:08 step 2: objective=65.885615 reg=0.003721
2017/08/30 05:52:10 step 3: objective=65.950037 reg=0.003721
2017/08/30 05:52:12 step 4: objective=65.994611 reg=0.003722
2017/08/30 05:52:14 step 5: objective=66.029670 reg=0.003721
2017/08/30 05:52:16 step 6: objective=66.077120 reg=0.003722
2017/08/30 05:52:18 step 7: objective=66.113571 reg=0.003721
2017/08/30 05:52:18 Training value function...
2017/08/30 05:52:21 step 0: mse=205659.582809 step=0.050000
2017/08/30 05:52:22 step 1: mse=206221.542877 step=0.050000
2017/08/30 05:52:24 step 2: mse=206144.159330 step=0.050000
2017/08/30 05:52:25 step 3: mse=206986.503951 step=0.050000
2017/08/30 05:52:26 step 4: mse=209640.982737 step=0.050000
2017/08/30 05:52:28 step 5: mse=210272.153081 step=0.050000
2017/08/30 05:52:29 step 6: mse=211415.679329 step=0.050000
2017/08/30 05:52:30 step 7: mse=212130.276274 step=0.050000
2017/08/30 05:52:30 Saving...
2017/08/30 05:52:30 Gathering batch of experience...
2017/08/30 05:53:01 batch 774: mean=11357.142857 stddev=9737.331033 entropy=0.369822 frames=6587 count=21
2017/08/30 05:53:01 Training policy...
2017/08/30 05:53:06 tune 0: objective=65.958166 reg=0.003698 prune=0
2017/08/30 05:53:08 step 0: objective=66.034656 reg=0.003697
2017/08/30 05:53:09 step 1: objective=66.071486 reg=0.003696
2017/08/30 05:53:11 step 2: objective=66.132515 reg=0.003695
2017/08/30 05:53:13 step 3: objective=66.164211 reg=0.003695
2017/08/30 05:53:14 step 4: objective=66.194612 reg=0.003694
2017/08/30 05:53:16 step 5: objective=66.228969 reg=0.003694
2017/08/30 05:53:17 step 6: objective=66.279542 reg=0.003694
2017/08/30 05:53:19 step 7: objective=66.316234 reg=0.003694
2017/08/30 05:53:19 Training value function...
2017/08/30 05:53:22 step 0: mse=181779.497494 step=0.050000
2017/08/30 05:53:23 step 1: mse=181162.333026 step=0.050000
2017/08/30 05:53:24 step 2: mse=180179.558672 step=0.050000
2017/08/30 05:53:25 step 3: mse=179946.585621 step=0.050000
2017/08/30 05:53:26 step 4: mse=179139.906360 step=0.050000
2017/08/30 05:53:27 step 5: mse=177996.710582 step=0.050000
2017/08/30 05:53:28 step 6: mse=177930.362345 step=0.050000
2017/08/30 05:53:29 step 7: mse=178308.110791 step=0.050000
2017/08/30 05:53:29 Saving...
2017/08/30 05:53:29 Gathering batch of experience...
2017/08/30 05:54:03 batch 775: mean=8663.750000 stddev=9601.231936 entropy=0.372146 frames=7033 count=28
2017/08/30 05:54:03 Training policy...
2017/08/30 05:54:09 tune 0: objective=54.427631 reg=0.003721 prune=0
2017/08/30 05:54:11 step 0: objective=54.478565 reg=0.003722
2017/08/30 05:54:12 step 1: objective=54.530286 reg=0.003722
2017/08/30 05:54:14 step 2: objective=54.581740 reg=0.003722
2017/08/30 05:54:16 step 3: objective=54.622952 reg=0.003721
2017/08/30 05:54:17 step 4: objective=54.651140 reg=0.003721
2017/08/30 05:54:19 step 5: objective=54.674126 reg=0.003721
2017/08/30 05:54:21 step 6: objective=54.701634 reg=0.003721
2017/08/30 05:54:23 step 7: objective=54.730805 reg=0.003721
2017/08/30 05:54:23 Training value function...
2017/08/30 05:54:25 step 0: mse=151612.826571 step=0.050000
2017/08/30 05:54:27 step 1: mse=150819.587377 step=0.050000
2017/08/30 05:54:28 step 2: mse=153032.115679 step=0.050000
2017/08/30 05:54:29 step 3: mse=151813.217127 step=0.050000
2017/08/30 05:54:30 step 4: mse=150922.097383 step=0.050000
2017/08/30 05:54:31 step 5: mse=153435.309163 step=0.050000
2017/08/30 05:54:32 step 6: mse=153519.355506 step=0.050000
2017/08/30 05:54:33 step 7: mse=152606.573832 step=0.050000
2017/08/30 05:54:33 Saving...
2017/08/30 05:54:34 Gathering batch of experience...
2017/08/30 05:55:06 batch 776: mean=8091.166667 stddev=9651.333991 entropy=0.373719 frames=6974 count=30
2017/08/30 05:55:06 Training policy...
2017/08/30 05:55:12 tune 0: objective=71.746993 reg=0.003737 prune=0
2017/08/30 05:55:14 step 0: objective=71.813020 reg=0.003737
2017/08/30 05:55:15 step 1: objective=71.884701 reg=0.003736
2017/08/30 05:55:17 step 2: objective=71.955052 reg=0.003735
2017/08/30 05:55:19 step 3: objective=71.997002 reg=0.003734
2017/08/30 05:55:21 step 4: objective=72.022190 reg=0.003733
2017/08/30 05:55:22 step 5: objective=72.050747 reg=0.003732
2017/08/30 05:55:24 step 6: objective=72.082646 reg=0.003732
2017/08/30 05:55:26 step 7: objective=72.121886 reg=0.003732
2017/08/30 05:55:26 Training value function...
2017/08/30 05:55:29 step 0: mse=216957.383062 step=0.050000
2017/08/30 05:55:30 step 1: mse=215772.892695 step=0.050000
2017/08/30 05:55:31 step 2: mse=214340.078392 step=0.050000
2017/08/30 05:55:32 step 3: mse=211562.786244 step=0.050000
2017/08/30 05:55:33 step 4: mse=210285.287931 step=0.050000
2017/08/30 05:55:34 step 5: mse=204784.440329 step=0.050000
2017/08/30 05:55:35 step 6: mse=203607.920205 step=0.050000
2017/08/30 05:55:37 step 7: mse=198731.717761 step=0.050000
2017/08/30 05:55:37 Saving...
2017/08/30 05:55:37 Gathering batch of experience...
2017/08/30 05:56:07 batch 777: mean=8686.666667 stddev=9256.763031 entropy=0.369894 frames=6241 count=24
2017/08/30 05:56:07 Training policy...
2017/08/30 05:56:12 tune 0: objective=55.073896 reg=0.003699 prune=0
2017/08/30 05:56:13 step 0: objective=55.159840 reg=0.003699
2017/08/30 05:56:15 step 1: objective=55.226716 reg=0.003698
2017/08/30 05:56:16 step 2: objective=55.296131 reg=0.003697
2017/08/30 05:56:18 step 3: objective=55.352152 reg=0.003696
2017/08/30 05:56:19 step 4: objective=55.395730 reg=0.003696
2017/08/30 05:56:21 step 5: objective=55.423845 reg=0.003696
2017/08/30 05:56:22 step 6: objective=55.453313 reg=0.003695
2017/08/30 05:56:24 step 7: objective=55.491473 reg=0.003695
2017/08/30 05:56:24 Training value function...
2017/08/30 05:56:27 step 0: mse=191692.206399 step=0.050000
2017/08/30 05:56:28 step 1: mse=192365.358969 step=0.050000
2017/08/30 05:56:29 step 2: mse=191760.053974 step=0.050000
2017/08/30 05:56:30 step 3: mse=191537.409804 step=0.050000
2017/08/30 05:56:31 step 4: mse=192330.763196 step=0.050000
2017/08/30 05:56:32 step 5: mse=192500.504529 step=0.050000
2017/08/30 05:56:33 step 6: mse=193062.095283 step=0.050000
2017/08/30 05:56:34 step 7: mse=192868.386055 step=0.050000
2017/08/30 05:56:34 Saving...
2017/08/30 05:56:34 Gathering batch of experience...
2017/08/30 05:57:08 batch 778: mean=10545.800000 stddev=9951.216476 entropy=0.371352 frames=7156 count=25
2017/08/30 05:57:08 Training policy...
2017/08/30 05:57:14 tune 0: objective=83.976602 reg=0.003714 prune=0
2017/08/30 05:57:16 step 0: objective=84.056980 reg=0.003714
2017/08/30 05:57:18 step 1: objective=84.118083 reg=0.003714
2017/08/30 05:57:20 step 2: objective=84.184356 reg=0.003713
2017/08/30 05:57:21 step 3: objective=84.232034 reg=0.003713
2017/08/30 05:57:23 step 4: objective=84.277416 reg=0.003713
2017/08/30 05:57:25 step 5: objective=84.316561 reg=0.003713
2017/08/30 05:57:27 step 6: objective=84.355392 reg=0.003713
2017/08/30 05:57:28 step 7: objective=84.378467 reg=0.003712
2017/08/30 05:57:28 Training value function...
2017/08/30 05:57:31 step 0: mse=235514.359156 step=0.050000
2017/08/30 05:57:33 step 1: mse=234540.865193 step=0.050000
2017/08/30 05:57:34 step 2: mse=229188.140802 step=0.050000
2017/08/30 05:57:35 step 3: mse=229480.779941 step=0.050000
2017/08/30 05:57:36 step 4: mse=226416.182866 step=0.050000
2017/08/30 05:57:37 step 5: mse=227091.700009 step=0.050000
2017/08/30 05:57:38 step 6: mse=226490.861815 step=0.050000
2017/08/30 05:57:40 step 7: mse=225465.692934 step=0.050000
2017/08/30 05:57:40 Saving...
2017/08/30 05:57:40 Gathering batch of experience...
2017/08/30 05:58:13 batch 779: mean=9698.518519 stddev=9742.971713 entropy=0.369873 frames=7184 count=27
2017/08/30 05:58:13 Training policy...
2017/08/30 05:58:19 tune 0: objective=70.081857 reg=0.003699 prune=0
2017/08/30 05:58:20 step 0: objective=70.138828 reg=0.003699
2017/08/30 05:58:22 step 1: objective=70.181754 reg=0.003699
2017/08/30 05:58:24 step 2: objective=70.218263 reg=0.003698
2017/08/30 05:58:26 step 3: objective=70.260675 reg=0.003698
2017/08/30 05:58:27 step 4: objective=70.297841 reg=0.003698
2017/08/30 05:58:29 step 5: objective=70.333845 reg=0.003698
2017/08/30 05:58:31 step 6: objective=70.362859 reg=0.003698
2017/08/30 05:58:33 step 7: objective=70.390682 reg=0.003698
2017/08/30 05:58:33 Training value function...
2017/08/30 05:58:36 step 0: mse=200623.366166 step=0.050000
2017/08/30 05:58:37 step 1: mse=202721.894018 step=0.050000
2017/08/30 05:58:38 step 2: mse=202483.530104 step=0.050000
2017/08/30 05:58:39 step 3: mse=202642.021782 step=0.050000
2017/08/30 05:58:40 step 4: mse=202494.649569 step=0.050000
2017/08/30 05:58:42 step 5: mse=202380.473330 step=0.050000
2017/08/30 05:58:43 step 6: mse=200856.888521 step=0.050000
2017/08/30 05:58:44 step 7: mse=202504.287445 step=0.050000
2017/08/30 05:58:44 Saving...
2017/08/30 05:58:44 Gathering batch of experience...
2017/08/30 05:59:17 batch 780: mean=10953.541667 stddev=10119.644106 entropy=0.368581 frames=7126 count=24
2017/08/30 05:59:17 Training policy...
2017/08/30 05:59:23 tune 0: objective=77.208594 reg=0.003686 prune=0
2017/08/30 05:59:25 step 0: objective=77.261998 reg=0.003686
2017/08/30 05:59:26 step 1: objective=77.306974 reg=0.003686
2017/08/30 05:59:28 step 2: objective=77.355248 reg=0.003686
2017/08/30 05:59:30 step 3: objective=77.404829 reg=0.003686
2017/08/30 05:59:32 step 4: objective=77.453717 reg=0.003685
2017/08/30 05:59:33 step 5: objective=77.500044 reg=0.003685
2017/08/30 05:59:35 step 6: objective=77.546415 reg=0.003685
2017/08/30 05:59:37 step 7: objective=77.568631 reg=0.003684
2017/08/30 05:59:37 Training value function...
2017/08/30 05:59:40 step 0: mse=221858.787950 step=0.050000
2017/08/30 05:59:41 step 1: mse=218825.574015 step=0.050000
2017/08/30 05:59:42 step 2: mse=217678.096013 step=0.050000
2017/08/30 05:59:43 step 3: mse=215252.237920 step=0.050000
2017/08/30 05:59:44 step 4: mse=213973.329122 step=0.050000
2017/08/30 05:59:46 step 5: mse=215560.498239 step=0.050000
2017/08/30 05:59:47 step 6: mse=214895.677452 step=0.050000
2017/08/30 05:59:48 step 7: mse=215183.603129 step=0.050000
2017/08/30 05:59:48 Saving...
2017/08/30 05:59:48 Gathering batch of experience...
2017/08/30 06:00:17 batch 781: mean=7141.250000 stddev=9083.477310 entropy=0.371544 frames=6169 count=28
2017/08/30 06:00:17 Training policy...
2017/08/30 06:00:22 tune 0: objective=51.738131 reg=0.003715 prune=0
2017/08/30 06:00:24 step 0: objective=51.774877 reg=0.003715
2017/08/30 06:00:25 step 1: objective=51.825397 reg=0.003714
2017/08/30 06:00:27 step 2: objective=51.863126 reg=0.003712
2017/08/30 06:00:29 step 3: objective=51.912769 reg=0.003711
2017/08/30 06:00:30 step 4: objective=51.950134 reg=0.003711
2017/08/30 06:00:32 step 5: objective=51.985755 reg=0.003710
2017/08/30 06:00:33 step 6: objective=52.010385 reg=0.003709
2017/08/30 06:00:35 step 7: objective=52.050297 reg=0.003709
2017/08/30 06:00:35 Training value function...
2017/08/30 06:00:37 step 0: mse=167428.356370 step=0.050000
2017/08/30 06:00:38 step 1: mse=167377.002972 step=0.050000
2017/08/30 06:00:39 step 2: mse=167107.210307 step=0.050000
2017/08/30 06:00:40 step 3: mse=167750.198932 step=0.050000
2017/08/30 06:00:41 step 4: mse=167766.585271 step=0.050000
2017/08/30 06:00:42 step 5: mse=168094.837470 step=0.050000
2017/08/30 06:00:43 step 6: mse=167519.010971 step=0.050000
2017/08/30 06:00:44 step 7: mse=167919.786720 step=0.050000
2017/08/30 06:00:44 Saving...
2017/08/30 06:00:44 Gathering batch of experience...
2017/08/30 06:01:16 batch 782: mean=8363.333333 stddev=9438.904225 entropy=0.371821 frames=6636 count=27
2017/08/30 06:01:16 Training policy...
2017/08/30 06:01:22 tune 0: objective=58.749854 reg=0.003718 prune=0
2017/08/30 06:01:23 step 0: objective=58.848445 reg=0.003717
2017/08/30 06:01:25 step 1: objective=58.927893 reg=0.003717
2017/08/30 06:01:27 step 2: objective=58.994443 reg=0.003717
2017/08/30 06:01:28 step 3: objective=59.054471 reg=0.003717
2017/08/30 06:01:30 step 4: objective=59.111230 reg=0.003716
2017/08/30 06:01:32 step 5: objective=59.153264 reg=0.003716
2017/08/30 06:01:33 step 6: objective=59.187900 reg=0.003715
2017/08/30 06:01:35 step 7: objective=59.216466 reg=0.003716
2017/08/30 06:01:35 Training value function...
2017/08/30 06:01:38 step 0: mse=171317.351028 step=0.050000
2017/08/30 06:01:39 step 1: mse=171854.095830 step=0.050000
2017/08/30 06:01:40 step 2: mse=172578.728459 step=0.050000
2017/08/30 06:01:41 step 3: mse=173100.693991 step=0.050000
2017/08/30 06:01:42 step 4: mse=175563.568596 step=0.050000
2017/08/30 06:01:43 step 5: mse=175858.833596 step=0.050000
2017/08/30 06:01:44 step 6: mse=175953.844632 step=0.050000
2017/08/30 06:01:45 step 7: mse=175176.577944 step=0.050000
2017/08/30 06:01:45 Saving...
2017/08/30 06:01:45 Gathering batch of experience...
2017/08/30 06:02:13 batch 783: mean=8530.217391 stddev=9336.676217 entropy=0.369154 frames=5635 count=23
2017/08/30 06:02:13 Training policy...
2017/08/30 06:02:18 tune 0: objective=69.791948 reg=0.003692 prune=0
2017/08/30 06:02:19 step 0: objective=69.958086 reg=0.003691
2017/08/30 06:02:20 step 1: objective=70.091820 reg=0.003691
2017/08/30 06:02:22 step 2: objective=70.172138 reg=0.003690
2017/08/30 06:02:23 step 3: objective=70.280607 reg=0.003690
2017/08/30 06:02:25 step 4: objective=70.336945 reg=0.003689
2017/08/30 06:02:26 step 5: objective=70.421551 reg=0.003690
2017/08/30 06:02:27 step 6: objective=70.496584 reg=0.003691
2017/08/30 06:02:29 step 7: objective=70.575671 reg=0.003690
2017/08/30 06:02:29 Training value function...
2017/08/30 06:02:31 step 0: mse=256775.640085 step=0.050000
2017/08/30 06:02:32 step 1: mse=256518.941283 step=0.050000
2017/08/30 06:02:33 step 2: mse=256122.225876 step=0.050000
2017/08/30 06:02:34 step 3: mse=251424.599888 step=0.050000
2017/08/30 06:02:35 step 4: mse=251679.576234 step=0.050000
2017/08/30 06:02:36 step 5: mse=247426.155328 step=0.050000
2017/08/30 06:02:37 step 6: mse=241562.323122 step=0.050000
2017/08/30 06:02:37 step 7: mse=237375.229628 step=0.050000
2017/08/30 06:02:37 Saving...
2017/08/30 06:02:38 Gathering batch of experience...
2017/08/30 06:03:12 batch 784: mean=8615.000000 stddev=9648.321097 entropy=0.367613 frames=7367 count=29
2017/08/30 06:03:12 Training policy...
2017/08/30 06:03:18 tune 0: objective=71.580486 reg=0.003676 prune=0
2017/08/30 06:03:20 step 0: objective=71.611782 reg=0.003676
2017/08/30 06:03:22 step 1: objective=71.635410 reg=0.003676
2017/08/30 06:03:23 step 2: objective=71.684616 reg=0.003675
2017/08/30 06:03:25 step 3: objective=71.708234 reg=0.003675
2017/08/30 06:03:27 step 4: objective=71.749126 reg=0.003676
2017/08/30 06:03:29 step 5: objective=71.777216 reg=0.003676
2017/08/30 06:03:31 step 6: objective=71.812059 reg=0.003676
2017/08/30 06:03:33 step 7: objective=71.845196 reg=0.003675
2017/08/30 06:03:33 Training value function...
2017/08/30 06:03:36 step 0: mse=179896.963319 step=0.050000
2017/08/30 06:03:37 step 1: mse=177723.343482 step=0.050000
2017/08/30 06:03:38 step 2: mse=176626.767764 step=0.050000
2017/08/30 06:03:39 step 3: mse=176342.244225 step=0.050000
2017/08/30 06:03:41 step 4: mse=175867.002472 step=0.050000
2017/08/30 06:03:42 step 5: mse=176243.647212 step=0.050000
2017/08/30 06:03:43 step 6: mse=176003.469333 step=0.050000
2017/08/30 06:03:44 step 7: mse=175584.758940 step=0.050000
2017/08/30 06:03:44 Saving...
2017/08/30 06:03:44 Gathering batch of experience...
2017/08/30 06:04:14 batch 785: mean=7997.321429 stddev=9636.913173 entropy=0.368033 frames=6568 count=28
2017/08/30 06:04:14 Training policy...
2017/08/30 06:04:20 tune 0: objective=68.621560 reg=0.003680 prune=0
2017/08/30 06:04:22 step 0: objective=68.659062 reg=0.003680
2017/08/30 06:04:23 step 1: objective=68.684564 reg=0.003680
2017/08/30 06:04:25 step 2: objective=68.732800 reg=0.003680
2017/08/30 06:04:26 step 3: objective=68.754020 reg=0.003680
2017/08/30 06:04:28 step 4: objective=68.784895 reg=0.003680
2017/08/30 06:04:30 step 5: objective=68.819351 reg=0.003680
2017/08/30 06:04:31 step 6: objective=68.842746 reg=0.003680
2017/08/30 06:04:33 step 7: objective=68.865094 reg=0.003681
2017/08/30 06:04:33 Training value function...
2017/08/30 06:04:36 step 0: mse=200310.558428 step=0.050000
2017/08/30 06:04:37 step 1: mse=199317.764642 step=0.050000
2017/08/30 06:04:38 step 2: mse=199159.221610 step=0.050000
2017/08/30 06:04:39 step 3: mse=198495.388389 step=0.050000
2017/08/30 06:04:40 step 4: mse=198150.285065 step=0.050000
2017/08/30 06:04:41 step 5: mse=198125.966518 step=0.050000
2017/08/30 06:04:42 step 6: mse=196616.147548 step=0.050000
2017/08/30 06:04:43 step 7: mse=196914.794962 step=0.050000
2017/08/30 06:04:43 Saving...
2017/08/30 06:04:43 Gathering batch of experience...
2017/08/30 06:05:16 batch 786: mean=12067.391304 stddev=10172.203907 entropy=0.366982 frames=7259 count=23
2017/08/30 06:05:16 Training policy...
2017/08/30 06:05:22 tune 0: objective=82.728905 reg=0.003670 prune=0
2017/08/30 06:05:24 step 0: objective=82.780419 reg=0.003670
2017/08/30 06:05:26 step 1: objective=82.835437 reg=0.003669
2017/08/30 06:05:28 step 2: objective=82.883231 reg=0.003670
2017/08/30 06:05:30 step 3: objective=82.920280 reg=0.003670
2017/08/30 06:05:31 step 4: objective=82.944698 reg=0.003669
2017/08/30 06:05:33 step 5: objective=83.000801 reg=0.003670
2017/08/30 06:05:35 step 6: objective=83.037936 reg=0.003670
2017/08/30 06:05:37 step 7: objective=83.073994 reg=0.003669
2017/08/30 06:05:37 Training value function...
2017/08/30 06:05:40 step 0: mse=214529.839855 step=0.050000
2017/08/30 06:05:41 step 1: mse=214258.156282 step=0.050000
2017/08/30 06:05:42 step 2: mse=213027.794414 step=0.050000
2017/08/30 06:05:43 step 3: mse=212001.047938 step=0.050000
2017/08/30 06:05:45 step 4: mse=212183.079973 step=0.050000
2017/08/30 06:05:46 step 5: mse=212500.271990 step=0.050000
2017/08/30 06:05:47 step 6: mse=212579.859202 step=0.050000
2017/08/30 06:05:48 step 7: mse=210161.116170 step=0.050000
2017/08/30 06:05:48 Saving...
2017/08/30 06:05:48 Gathering batch of experience...
2017/08/30 06:06:24 batch 787: mean=8305.666667 stddev=9300.324254 entropy=0.372256 frames=7468 count=30
2017/08/30 06:06:24 Training policy...
2017/08/30 06:06:30 tune 0: objective=44.179700 reg=0.003723 prune=0
2017/08/30 06:06:32 step 0: objective=44.303553 reg=0.003720
2017/08/30 06:06:33 step 1: objective=44.375167 reg=0.003720
2017/08/30 06:06:35 step 2: objective=44.438864 reg=0.003720
2017/08/30 06:06:37 step 3: objective=44.475010 reg=0.003719
2017/08/30 06:06:39 step 4: objective=44.513821 reg=0.003719
2017/08/30 06:06:41 step 5: objective=44.570928 reg=0.003718
2017/08/30 06:06:43 step 6: objective=44.609425 reg=0.003718
2017/08/30 06:06:45 step 7: objective=44.644115 reg=0.003718
2017/08/30 06:06:45 Training value function...
2017/08/30 06:06:48 step 0: mse=193982.436443 step=0.050000
2017/08/30 06:06:49 step 1: mse=195067.152935 step=0.050000
2017/08/30 06:06:50 step 2: mse=195766.384983 step=0.050000
2017/08/30 06:06:51 step 3: mse=196864.629956 step=0.050000
2017/08/30 06:06:53 step 4: mse=197818.241365 step=0.050000
2017/08/30 06:06:54 step 5: mse=198614.837758 step=0.050000
2017/08/30 06:06:55 step 6: mse=201125.877407 step=0.050000
2017/08/30 06:06:56 step 7: mse=203654.560869 step=0.050000
2017/08/30 06:06:56 Saving...
2017/08/30 06:06:56 Gathering batch of experience...
2017/08/30 06:07:26 batch 788: mean=8172.600000 stddev=9263.126375 entropy=0.369263 frames=6163 count=25
2017/08/30 06:07:26 Training policy...
2017/08/30 06:07:31 tune 0: objective=48.631429 reg=0.003693 prune=0
2017/08/30 06:07:32 step 0: objective=48.759913 reg=0.003692
2017/08/30 06:07:34 step 1: objective=48.850418 reg=0.003692
2017/08/30 06:07:35 step 2: objective=48.929347 reg=0.003692
2017/08/30 06:07:37 step 3: objective=48.989240 reg=0.003692
2017/08/30 06:07:38 step 4: objective=49.064660 reg=0.003692
2017/08/30 06:07:40 step 5: objective=49.110823 reg=0.003693
2017/08/30 06:07:41 step 6: objective=49.177764 reg=0.003692
2017/08/30 06:07:43 step 7: objective=49.235696 reg=0.003692
2017/08/30 06:07:43 Training value function...
2017/08/30 06:07:45 step 0: mse=194160.063505 step=0.050000
2017/08/30 06:07:46 step 1: mse=195769.653060 step=0.050000
2017/08/30 06:07:47 step 2: mse=197234.367021 step=0.050000
2017/08/30 06:07:48 step 3: mse=197416.243606 step=0.050000
2017/08/30 06:07:49 step 4: mse=198096.379760 step=0.050000
2017/08/30 06:07:50 step 5: mse=198928.102005 step=0.050000
2017/08/30 06:07:51 step 6: mse=199576.268864 step=0.050000
2017/08/30 06:07:52 step 7: mse=199113.499608 step=0.050000
2017/08/30 06:07:52 Saving...
2017/08/30 06:07:53 Gathering batch of experience...
2017/08/30 06:08:24 batch 789: mean=8537.692308 stddev=9695.612532 entropy=0.365841 frames=6387 count=26
2017/08/30 06:08:24 Training policy...
2017/08/30 06:08:29 tune 0: objective=72.684354 reg=0.003658 prune=0
2017/08/30 06:08:30 step 0: objective=72.765079 reg=0.003658
2017/08/30 06:08:32 step 1: objective=72.828382 reg=0.003658
2017/08/30 06:08:34 step 2: objective=72.884012 reg=0.003657
2017/08/30 06:08:35 step 3: objective=72.939922 reg=0.003655
2017/08/30 06:08:37 step 4: objective=72.991580 reg=0.003656
2017/08/30 06:08:38 step 5: objective=73.048326 reg=0.003656
2017/08/30 06:08:40 step 6: objective=73.097468 reg=0.003655
2017/08/30 06:08:42 step 7: objective=73.139566 reg=0.003654
2017/08/30 06:08:42 Training value function...
2017/08/30 06:08:44 step 0: mse=231342.114437 step=0.050000
2017/08/30 06:08:45 step 1: mse=230640.089019 step=0.050000
2017/08/30 06:08:46 step 2: mse=228291.690789 step=0.050000
2017/08/30 06:08:47 step 3: mse=228162.920394 step=0.050000
2017/08/30 06:08:48 step 4: mse=224811.862344 step=0.050000
2017/08/30 06:08:49 step 5: mse=224881.262207 step=0.050000
2017/08/30 06:08:50 step 6: mse=221823.308076 step=0.050000
2017/08/30 06:08:52 step 7: mse=221686.468209 step=0.050000
2017/08/30 06:08:52 Saving...
2017/08/30 06:08:52 Gathering batch of experience...
2017/08/30 06:09:24 batch 790: mean=9262.115385 stddev=9904.649857 entropy=0.370713 frames=6818 count=26
2017/08/30 06:09:24 Training policy...
2017/08/30 06:09:30 tune 0: objective=76.725680 reg=0.003707 prune=0
2017/08/30 06:09:32 step 0: objective=76.804539 reg=0.003707
2017/08/30 06:09:34 step 1: objective=76.858816 reg=0.003708
2017/08/30 06:09:35 step 2: objective=76.910375 reg=0.003708
2017/08/30 06:09:37 step 3: objective=76.965679 reg=0.003708
2017/08/30 06:09:39 step 4: objective=77.014337 reg=0.003707
2017/08/30 06:09:40 step 5: objective=77.059227 reg=0.003706
2017/08/30 06:09:42 step 6: objective=77.091660 reg=0.003706
2017/08/30 06:09:44 step 7: objective=77.128749 reg=0.003706
2017/08/30 06:09:44 Training value function...
2017/08/30 06:09:47 step 0: mse=216621.949549 step=0.050000
2017/08/30 06:09:48 step 1: mse=212301.715451 step=0.050000
2017/08/30 06:09:49 step 2: mse=211133.691226 step=0.050000
2017/08/30 06:09:50 step 3: mse=210134.804161 step=0.050000
2017/08/30 06:09:51 step 4: mse=205117.384750 step=0.050000
2017/08/30 06:09:52 step 5: mse=203490.306073 step=0.050000
2017/08/30 06:09:53 step 6: mse=200707.417389 step=0.050000
2017/08/30 06:09:54 step 7: mse=200849.903016 step=0.050000
2017/08/30 06:09:54 Saving...
2017/08/30 06:09:54 Gathering batch of experience...
2017/08/30 06:10:31 batch 791: mean=9700.689655 stddev=9924.750125 entropy=0.372261 frames=7883 count=29
2017/08/30 06:10:31 Training policy...
2017/08/30 06:10:37 tune 0: objective=67.677574 reg=0.003723 prune=0
2017/08/30 06:10:39 step 0: objective=67.727515 reg=0.003722
2017/08/30 06:10:41 step 1: objective=67.773817 reg=0.003722
2017/08/30 06:10:43 step 2: objective=67.823917 reg=0.003721
2017/08/30 06:10:45 step 3: objective=67.893679 reg=0.003721
2017/08/30 06:10:47 step 4: objective=67.933528 reg=0.003720
2017/08/30 06:10:49 step 5: objective=67.980417 reg=0.003720
2017/08/30 06:10:51 step 6: objective=68.034370 reg=0.003719
2017/08/30 06:10:53 step 7: objective=68.066956 reg=0.003719
2017/08/30 06:10:53 Training value function...
2017/08/30 06:10:56 step 0: mse=211352.280854 step=0.050000
2017/08/30 06:10:57 step 1: mse=208031.186787 step=0.050000
2017/08/30 06:10:59 step 2: mse=208857.738161 step=0.050000
2017/08/30 06:11:00 step 3: mse=208314.916284 step=0.050000
2017/08/30 06:11:01 step 4: mse=209944.943389 step=0.050000
2017/08/30 06:11:02 step 5: mse=207806.308493 step=0.050000
2017/08/30 06:11:04 step 6: mse=204859.639127 step=0.050000
2017/08/30 06:11:05 step 7: mse=204659.948362 step=0.050000
2017/08/30 06:11:05 Saving...
2017/08/30 06:11:05 Gathering batch of experience...
2017/08/30 06:11:40 batch 792: mean=9453.750000 stddev=9872.762099 entropy=0.365266 frames=7314 count=28
2017/08/30 06:11:40 Training policy...
2017/08/30 06:11:46 tune 0: objective=71.376624 reg=0.003653 prune=0
2017/08/30 06:11:48 step 0: objective=71.462486 reg=0.003653
2017/08/30 06:11:49 step 1: objective=71.522226 reg=0.003654
2017/08/30 06:11:51 step 2: objective=71.575036 reg=0.003654
2017/08/30 06:11:53 step 3: objective=71.626906 reg=0.003655
2017/08/30 06:11:55 step 4: objective=71.677647 reg=0.003655
2017/08/30 06:11:57 step 5: objective=71.712162 reg=0.003655
2017/08/30 06:11:58 step 6: objective=71.746838 reg=0.003655
2017/08/30 06:12:00 step 7: objective=71.786822 reg=0.003655
2017/08/30 06:12:00 Training value function...
2017/08/30 06:12:03 step 0: mse=209418.156649 step=0.050000
2017/08/30 06:12:05 step 1: mse=209510.674920 step=0.050000
2017/08/30 06:12:06 step 2: mse=209951.987020 step=0.050000
2017/08/30 06:12:07 step 3: mse=210970.688753 step=0.050000
2017/08/30 06:12:08 step 4: mse=211966.208851 step=0.050000
2017/08/30 06:12:09 step 5: mse=212901.787301 step=0.050000
2017/08/30 06:12:11 step 6: mse=213140.315951 step=0.050000
2017/08/30 06:12:12 step 7: mse=213406.055828 step=0.050000
2017/08/30 06:12:12 Saving...
2017/08/30 06:12:12 Gathering batch of experience...
2017/08/30 06:12:43 batch 793: mean=9069.800000 stddev=9491.703375 entropy=0.370361 frames=6652 count=25
2017/08/30 06:12:43 Training policy...
2017/08/30 06:12:49 tune 0: objective=53.769599 reg=0.003704 prune=0
2017/08/30 06:12:50 step 0: objective=53.872698 reg=0.003703
2017/08/30 06:12:52 step 1: objective=53.953914 reg=0.003703
2017/08/30 06:12:54 step 2: objective=54.027647 reg=0.003703
2017/08/30 06:12:55 step 3: objective=54.075471 reg=0.003703
2017/08/30 06:12:57 step 4: objective=54.134118 reg=0.003704
2017/08/30 06:12:59 step 5: objective=54.179720 reg=0.003704
2017/08/30 06:13:00 step 6: objective=54.222753 reg=0.003704
2017/08/30 06:13:02 step 7: objective=54.256873 reg=0.003704
2017/08/30 06:13:02 Training value function...
2017/08/30 06:13:05 step 0: mse=171187.677706 step=0.050000
2017/08/30 06:13:06 step 1: mse=171285.934868 step=0.050000
2017/08/30 06:13:07 step 2: mse=172427.829131 step=0.050000
2017/08/30 06:13:08 step 3: mse=172499.837113 step=0.050000
2017/08/30 06:13:09 step 4: mse=173000.422853 step=0.050000
2017/08/30 06:13:10 step 5: mse=172090.038093 step=0.050000
2017/08/30 06:13:11 step 6: mse=172193.733879 step=0.050000
2017/08/30 06:13:12 step 7: mse=172803.367479 step=0.050000
2017/08/30 06:13:12 Saving...
2017/08/30 06:13:12 Gathering batch of experience...
2017/08/30 06:13:44 batch 794: mean=10845.454545 stddev=10127.414741 entropy=0.368004 frames=6348 count=22
2017/08/30 06:13:44 Training policy...
2017/08/30 06:13:49 tune 0: objective=82.273280 reg=0.003680 prune=0
2017/08/30 06:13:51 step 0: objective=82.329710 reg=0.003680
2017/08/30 06:13:52 step 1: objective=82.401435 reg=0.003680
2017/08/30 06:13:54 step 2: objective=82.438509 reg=0.003679
2017/08/30 06:13:56 step 3: objective=82.490533 reg=0.003679
2017/08/30 06:13:57 step 4: objective=82.564356 reg=0.003678
2017/08/30 06:13:59 step 5: objective=82.606864 reg=0.003676
2017/08/30 06:14:00 step 6: objective=82.644967 reg=0.003676
2017/08/30 06:14:02 step 7: objective=82.688209 reg=0.003675
2017/08/30 06:14:02 Training value function...
2017/08/30 06:14:04 step 0: mse=208443.160111 step=0.050000
2017/08/30 06:14:06 step 1: mse=208677.272823 step=0.050000
2017/08/30 06:14:07 step 2: mse=209268.605785 step=0.050000
2017/08/30 06:14:08 step 3: mse=208435.759257 step=0.050000
2017/08/30 06:14:09 step 4: mse=207983.279971 step=0.050000
2017/08/30 06:14:10 step 5: mse=208438.471499 step=0.050000
2017/08/30 06:14:11 step 6: mse=208002.655041 step=0.050000
2017/08/30 06:14:12 step 7: mse=207877.210808 step=0.050000
2017/08/30 06:14:12 Saving...
2017/08/30 06:14:12 Gathering batch of experience...
2017/08/30 06:14:45 batch 795: mean=7047.031250 stddev=9072.720173 entropy=0.370805 frames=6907 count=32
2017/08/30 06:14:45 Training policy...
2017/08/30 06:14:51 tune 0: objective=52.419547 reg=0.003708 prune=0
2017/08/30 06:14:53 step 0: objective=52.516849 reg=0.003706
2017/08/30 06:14:54 step 1: objective=52.588352 reg=0.003705
2017/08/30 06:14:56 step 2: objective=52.659965 reg=0.003704
2017/08/30 06:14:58 step 3: objective=52.687559 reg=0.003704
2017/08/30 06:15:00 step 4: objective=52.719786 reg=0.003704
2017/08/30 06:15:01 step 5: objective=52.753307 reg=0.003704
2017/08/30 06:15:03 step 6: objective=52.779603 reg=0.003703
2017/08/30 06:15:05 step 7: objective=52.801700 reg=0.003703
2017/08/30 06:15:05 Training value function...
2017/08/30 06:15:08 step 0: mse=166224.562056 step=0.050000
2017/08/30 06:15:09 step 1: mse=165108.560932 step=0.050000
2017/08/30 06:15:10 step 2: mse=163641.324264 step=0.050000
2017/08/30 06:15:11 step 3: mse=163894.085586 step=0.050000
2017/08/30 06:15:12 step 4: mse=166044.344726 step=0.050000
2017/08/30 06:15:13 step 5: mse=165209.141237 step=0.050000
2017/08/30 06:15:14 step 6: mse=163755.040547 step=0.050000
2017/08/30 06:15:15 step 7: mse=164006.108221 step=0.050000
2017/08/30 06:15:15 Saving...
2017/08/30 06:15:16 Gathering batch of experience...
2017/08/30 06:15:48 batch 796: mean=13788.250000 stddev=10018.892313 entropy=0.367492 frames=7027 count=20
2017/08/30 06:15:48 Training policy...
2017/08/30 06:15:54 tune 0: objective=96.443637 reg=0.003675 prune=0
2017/08/30 06:15:56 step 0: objective=96.493783 reg=0.003675
2017/08/30 06:15:57 step 1: objective=96.568948 reg=0.003674
2017/08/30 06:15:59 step 2: objective=96.634801 reg=0.003675
2017/08/30 06:16:01 step 3: objective=96.678250 reg=0.003676
2017/08/30 06:16:03 step 4: objective=96.705208 reg=0.003676
2017/08/30 06:16:04 step 5: objective=96.728983 reg=0.003676
2017/08/30 06:16:06 step 6: objective=96.757711 reg=0.003676
2017/08/30 06:16:08 step 7: objective=96.790487 reg=0.003675
2017/08/30 06:16:08 Training value function...
2017/08/30 06:16:11 step 0: mse=233113.925537 step=0.050000
2017/08/30 06:16:12 step 1: mse=228170.071837 step=0.050000
2017/08/30 06:16:13 step 2: mse=226202.961340 step=0.050000
2017/08/30 06:16:14 step 3: mse=224633.174599 step=0.050000
2017/08/30 06:16:15 step 4: mse=224021.541659 step=0.050000
2017/08/30 06:16:17 step 5: mse=223267.876016 step=0.050000
2017/08/30 06:16:18 step 6: mse=222746.433769 step=0.050000
2017/08/30 06:16:19 step 7: mse=222930.172486 step=0.050000
2017/08/30 06:16:19 Saving...
2017/08/30 06:16:19 Gathering batch of experience...
2017/08/30 06:16:50 batch 797: mean=9665.909091 stddev=9116.586238 entropy=0.358476 frames=6100 count=22
2017/08/30 06:16:50 Training policy...
2017/08/30 06:16:55 tune 0: objective=54.832833 reg=0.003585 prune=0
2017/08/30 06:16:56 step 0: objective=55.093847 reg=0.003581
2017/08/30 06:16:58 step 1: objective=55.202597 reg=0.003580
2017/08/30 06:16:59 step 2: objective=55.284887 reg=0.003579
2017/08/30 06:17:01 step 3: objective=55.348443 reg=0.003577
2017/08/30 06:17:02 step 4: objective=55.397418 reg=0.003577
2017/08/30 06:17:04 step 5: objective=55.432741 reg=0.003577
2017/08/30 06:17:05 step 6: objective=55.483120 reg=0.003576
2017/08/30 06:17:07 step 7: objective=55.536537 reg=0.003576
2017/08/30 06:17:07 Training value function...
2017/08/30 06:17:10 step 0: mse=265405.918102 step=0.050000
2017/08/30 06:17:11 step 1: mse=259607.356535 step=0.050000
2017/08/30 06:17:11 step 2: mse=259412.822680 step=0.050000
2017/08/30 06:17:12 step 3: mse=258123.338810 step=0.050000
2017/08/30 06:17:13 step 4: mse=256173.989350 step=0.050000
2017/08/30 06:17:14 step 5: mse=253164.740782 step=0.050000
2017/08/30 06:17:15 step 6: mse=249285.317154 step=0.050000
2017/08/30 06:17:16 step 7: mse=251411.724866 step=0.050000
2017/08/30 06:17:16 Saving...
2017/08/30 06:17:16 Gathering batch of experience...
2017/08/30 06:17:52 batch 798: mean=6966.406250 stddev=8485.715777 entropy=0.364404 frames=7268 count=32
2017/08/30 06:17:52 Training policy...
2017/08/30 06:17:57 tune 0: objective=45.346033 reg=0.003644 prune=0
2017/08/30 06:17:59 step 0: objective=45.405786 reg=0.003644
2017/08/30 06:18:01 step 1: objective=45.473063 reg=0.003644
2017/08/30 06:18:03 step 2: objective=45.542838 reg=0.003644
2017/08/30 06:18:05 step 3: objective=45.637048 reg=0.003645
2017/08/30 06:18:07 step 4: objective=45.678359 reg=0.003645
2017/08/30 06:18:08 step 5: objective=45.719808 reg=0.003644
2017/08/30 06:18:10 step 6: objective=45.761661 reg=0.003645
2017/08/30 06:18:12 step 7: objective=45.806081 reg=0.003645
2017/08/30 06:18:12 Training value function...
2017/08/30 06:18:15 step 0: mse=201111.835847 step=0.050000
2017/08/30 06:18:16 step 1: mse=202222.217879 step=0.050000
2017/08/30 06:18:18 step 2: mse=201127.295028 step=0.050000
2017/08/30 06:18:19 step 3: mse=202223.219941 step=0.050000
2017/08/30 06:18:20 step 4: mse=202888.977610 step=0.050000
2017/08/30 06:18:21 step 5: mse=203413.359627 step=0.050000
2017/08/30 06:18:22 step 6: mse=203256.919930 step=0.050000
2017/08/30 06:18:23 step 7: mse=202396.186740 step=0.050000
2017/08/30 06:18:23 Saving...
2017/08/30 06:18:24 Gathering batch of experience...
2017/08/30 06:18:55 batch 799: mean=8159.285714 stddev=9527.113443 entropy=0.364855 frames=6674 count=28
2017/08/30 06:18:55 Training policy...
2017/08/30 06:19:01 tune 0: objective=72.011814 reg=0.003649 prune=0
2017/08/30 06:19:02 step 0: objective=72.124963 reg=0.003647
2017/08/30 06:19:04 step 1: objective=72.218937 reg=0.003647
2017/08/30 06:19:06 step 2: objective=72.291134 reg=0.003647
2017/08/30 06:19:07 step 3: objective=72.357769 reg=0.003647
2017/08/30 06:19:09 step 4: objective=72.419272 reg=0.003646
2017/08/30 06:19:11 step 5: objective=72.463688 reg=0.003646
2017/08/30 06:19:12 step 6: objective=72.508850 reg=0.003646
2017/08/30 06:19:14 step 7: objective=72.541565 reg=0.003646
2017/08/30 06:19:14 Training value function...
2017/08/30 06:19:17 step 0: mse=263192.329483 step=0.050000
2017/08/30 06:19:18 step 1: mse=260819.880187 step=0.050000
2017/08/30 06:19:19 step 2: mse=256165.110018 step=0.050000
2017/08/30 06:19:20 step 3: mse=251226.865352 step=0.050000
2017/08/30 06:19:21 step 4: mse=247845.474588 step=0.050000
2017/08/30 06:19:22 step 5: mse=243806.730598 step=0.050000
2017/08/30 06:19:23 step 6: mse=243944.273228 step=0.050000
2017/08/30 06:19:24 step 7: mse=239801.967852 step=0.050000
2017/08/30 06:19:24 Saving...
2017/08/30 06:19:25 Gathering batch of experience...
2017/08/30 06:19:57 batch 800: mean=8585.925926 stddev=9353.734948 entropy=0.363366 frames=6898 count=27
2017/08/30 06:19:57 Training policy...
2017/08/30 06:20:03 tune 0: objective=57.228436 reg=0.003634 prune=0
2017/08/30 06:20:05 step 0: objective=57.300989 reg=0.003633
2017/08/30 06:20:07 step 1: objective=57.365545 reg=0.003634
2017/08/30 06:20:08 step 2: objective=57.417938 reg=0.003634
2017/08/30 06:20:10 step 3: objective=57.452128 reg=0.003634
2017/08/30 06:20:12 step 4: objective=57.497449 reg=0.003635
2017/08/30 06:20:14 step 5: objective=57.525592 reg=0.003635
2017/08/30 06:20:15 step 6: objective=57.581595 reg=0.003635
2017/08/30 06:20:17 step 7: objective=57.619958 reg=0.003634
2017/08/30 06:20:17 Training value function...
2017/08/30 06:20:20 step 0: mse=191389.693321 step=0.050000
2017/08/30 06:20:21 step 1: mse=191678.451123 step=0.050000
2017/08/30 06:20:22 step 2: mse=193012.109187 step=0.050000
2017/08/30 06:20:23 step 3: mse=193152.210171 step=0.050000
2017/08/30 06:20:24 step 4: mse=194716.890493 step=0.050000
2017/08/30 06:20:26 step 5: mse=195769.082771 step=0.050000
2017/08/30 06:20:27 step 6: mse=196928.408275 step=0.050000
2017/08/30 06:20:28 step 7: mse=196685.228658 step=0.050000
2017/08/30 06:20:28 Saving...
2017/08/30 06:20:28 Gathering batch of experience...
2017/08/30 06:21:00 batch 801: mean=9324.038462 stddev=9879.736646 entropy=0.364892 frames=6846 count=26
2017/08/30 06:21:00 Training policy...
2017/08/30 06:21:06 tune 0: objective=75.832092 reg=0.003649 prune=0
2017/08/30 06:21:08 step 0: objective=75.885846 reg=0.003650
2017/08/30 06:21:09 step 1: objective=75.925956 reg=0.003650
2017/08/30 06:21:11 step 2: objective=75.970795 reg=0.003650
2017/08/30 06:21:13 step 3: objective=76.007723 reg=0.003650
2017/08/30 06:21:14 step 4: objective=76.050595 reg=0.003651
2017/08/30 06:21:16 step 5: objective=76.080280 reg=0.003651
2017/08/30 06:21:18 step 6: objective=76.105080 reg=0.003651
2017/08/30 06:21:20 step 7: objective=76.142547 reg=0.003651
2017/08/30 06:21:20 Training value function...
2017/08/30 06:21:22 step 0: mse=188642.752561 step=0.050000
2017/08/30 06:21:24 step 1: mse=185767.586204 step=0.050000
2017/08/30 06:21:25 step 2: mse=184700.864520 step=0.050000
2017/08/30 06:21:26 step 3: mse=183570.698603 step=0.050000
2017/08/30 06:21:27 step 4: mse=182588.356622 step=0.050000
2017/08/30 06:21:28 step 5: mse=181959.097793 step=0.050000
2017/08/30 06:21:29 step 6: mse=181632.937989 step=0.050000
2017/08/30 06:21:30 step 7: mse=180845.191780 step=0.050000
2017/08/30 06:21:30 Saving...
2017/08/30 06:21:30 Gathering batch of experience...
2017/08/30 06:22:03 batch 802: mean=7887.962963 stddev=9239.741184 entropy=0.366097 frames=6638 count=27
2017/08/30 06:22:03 Training policy...
2017/08/30 06:22:08 tune 0: objective=57.777404 reg=0.003661 prune=0
2017/08/30 06:22:10 step 0: objective=57.858000 reg=0.003661
2017/08/30 06:22:12 step 1: objective=57.923207 reg=0.003661
2017/08/30 06:22:13 step 2: objective=57.993861 reg=0.003661
2017/08/30 06:22:15 step 3: objective=58.055462 reg=0.003661
2017/08/30 06:22:17 step 4: objective=58.117049 reg=0.003661
2017/08/30 06:22:18 step 5: objective=58.173697 reg=0.003660
2017/08/30 06:22:20 step 6: objective=58.213920 reg=0.003660
2017/08/30 06:22:22 step 7: objective=58.257947 reg=0.003659
2017/08/30 06:22:22 Training value function...
2017/08/30 06:22:24 step 0: mse=171098.989907 step=0.050000
2017/08/30 06:22:25 step 1: mse=170905.068602 step=0.050000
2017/08/30 06:22:27 step 2: mse=171634.734453 step=0.050000
2017/08/30 06:22:28 step 3: mse=170971.605253 step=0.050000
2017/08/30 06:22:29 step 4: mse=172489.255018 step=0.050000
2017/08/30 06:22:30 step 5: mse=173314.194483 step=0.050000
2017/08/30 06:22:31 step 6: mse=173101.701265 step=0.050000
2017/08/30 06:22:32 step 7: mse=172325.968697 step=0.050000
2017/08/30 06:22:32 Saving...
2017/08/30 06:22:32 Gathering batch of experience...
2017/08/30 06:23:07 batch 803: mean=10812.884615 stddev=10124.535238 entropy=0.369048 frames=7643 count=26
2017/08/30 06:23:07 Training policy...
2017/08/30 06:23:14 tune 0: objective=77.061756 reg=0.003690 prune=0
2017/08/30 06:23:16 step 0: objective=77.102880 reg=0.003690
2017/08/30 06:23:18 step 1: objective=77.151789 reg=0.003690
2017/08/30 06:23:20 step 2: objective=77.185006 reg=0.003690
2017/08/30 06:23:21 step 3: objective=77.241888 reg=0.003691
2017/08/30 06:23:23 step 4: objective=77.267107 reg=0.003691
2017/08/30 06:23:25 step 5: objective=77.305214 reg=0.003691
2017/08/30 06:23:27 step 6: objective=77.336762 reg=0.003691
2017/08/30 06:23:29 step 7: objective=77.387217 reg=0.003691
2017/08/30 06:23:29 Training value function...
2017/08/30 06:23:32 step 0: mse=208180.390965 step=0.050000
2017/08/30 06:23:34 step 1: mse=208023.226663 step=0.050000
2017/08/30 06:23:35 step 2: mse=207573.936776 step=0.050000
2017/08/30 06:23:36 step 3: mse=207242.627528 step=0.050000
2017/08/30 06:23:37 step 4: mse=205837.542035 step=0.050000
2017/08/30 06:23:39 step 5: mse=205828.567727 step=0.050000
2017/08/30 06:23:40 step 6: mse=206301.992370 step=0.050000
2017/08/30 06:23:41 step 7: mse=206153.245328 step=0.050000
2017/08/30 06:23:41 Saving...
2017/08/30 06:23:41 Gathering batch of experience...
2017/08/30 06:24:14 batch 804: mean=11890.681818 stddev=9900.924578 entropy=0.363319 frames=6996 count=22
2017/08/30 06:24:14 Training policy...
2017/08/30 06:24:20 tune 0: objective=75.145574 reg=0.003633 prune=0
2017/08/30 06:24:21 step 0: objective=75.195683 reg=0.003633
2017/08/30 06:24:23 step 1: objective=75.232937 reg=0.003633
2017/08/30 06:24:25 step 2: objective=75.261918 reg=0.003633
2017/08/30 06:24:27 step 3: objective=75.291122 reg=0.003633
2017/08/30 06:24:28 step 4: objective=75.324203 reg=0.003633
2017/08/30 06:24:30 step 5: objective=75.350557 reg=0.003633
2017/08/30 06:24:32 step 6: objective=75.369416 reg=0.003633
2017/08/30 06:24:34 step 7: objective=75.397441 reg=0.003632
2017/08/30 06:24:34 Training value function...
2017/08/30 06:24:37 step 0: mse=180156.459875 step=0.050000
2017/08/30 06:24:38 step 1: mse=179635.452396 step=0.050000
2017/08/30 06:24:39 step 2: mse=179366.451759 step=0.050000
2017/08/30 06:24:40 step 3: mse=180659.978725 step=0.050000
2017/08/30 06:24:41 step 4: mse=180810.239838 step=0.050000
2017/08/30 06:24:42 step 5: mse=181191.320033 step=0.050000
2017/08/30 06:24:44 step 6: mse=180848.008185 step=0.050000
2017/08/30 06:24:45 step 7: mse=180500.503786 step=0.050000
2017/08/30 06:24:45 Saving...
2017/08/30 06:24:45 Gathering batch of experience...
2017/08/30 06:25:18 batch 805: mean=10349.423077 stddev=9886.894621 entropy=0.367702 frames=7291 count=26
2017/08/30 06:25:18 Training policy...
2017/08/30 06:25:25 tune 0: objective=68.497175 reg=0.003677 prune=0
2017/08/30 06:25:27 step 0: objective=68.574818 reg=0.003676
2017/08/30 06:25:28 step 1: objective=68.641141 reg=0.003676
2017/08/30 06:25:30 step 2: objective=68.683947 reg=0.003675
2017/08/30 06:25:32 step 3: objective=68.721665 reg=0.003675
2017/08/30 06:25:34 step 4: objective=68.772541 reg=0.003675
2017/08/30 06:25:36 step 5: objective=68.807605 reg=0.003675
2017/08/30 06:25:38 step 6: objective=68.849498 reg=0.003675
2017/08/30 06:25:39 step 7: objective=68.885162 reg=0.003674
2017/08/30 06:25:39 Training value function...
2017/08/30 06:25:42 step 0: mse=213633.247159 step=0.050000
2017/08/30 06:25:44 step 1: mse=214098.339305 step=0.050000
2017/08/30 06:25:45 step 2: mse=212336.145585 step=0.050000
2017/08/30 06:25:46 step 3: mse=214616.367172 step=0.050000
2017/08/30 06:25:47 step 4: mse=216421.388910 step=0.050000
2017/08/30 06:25:48 step 5: mse=217175.383294 step=0.050000
2017/08/30 06:25:50 step 6: mse=217459.343602 step=0.050000
2017/08/30 06:25:51 step 7: mse=216298.802442 step=0.050000
2017/08/30 06:25:51 Saving...
2017/08/30 06:25:51 Gathering batch of experience...
2017/08/30 06:26:26 batch 806: mean=12905.652174 stddev=9733.215241 entropy=0.363430 frames=7780 count=23
2017/08/30 06:26:26 Training policy...
2017/08/30 06:26:32 tune 0: objective=81.708708 reg=0.003634 prune=0
2017/08/30 06:26:34 step 0: objective=81.773932 reg=0.003634
2017/08/30 06:26:36 step 1: objective=81.814749 reg=0.003634
2017/08/30 06:26:38 step 2: objective=81.857447 reg=0.003635
2017/08/30 06:26:40 step 3: objective=81.903398 reg=0.003634
2017/08/30 06:26:42 step 4: objective=81.951342 reg=0.003634
2017/08/30 06:26:44 step 5: objective=81.980029 reg=0.003633
2017/08/30 06:26:46 step 6: objective=82.027844 reg=0.003632
2017/08/30 06:26:48 step 7: objective=82.064524 reg=0.003632
2017/08/30 06:26:48 Training value function...
2017/08/30 06:26:51 step 0: mse=216428.173875 step=0.050000
2017/08/30 06:26:52 step 1: mse=215796.247793 step=0.050000
2017/08/30 06:26:54 step 2: mse=214613.124601 step=0.050000
2017/08/30 06:26:55 step 3: mse=212416.813047 step=0.050000
2017/08/30 06:26:56 step 4: mse=212164.639253 step=0.050000
2017/08/30 06:26:57 step 5: mse=211647.167818 step=0.050000
2017/08/30 06:26:59 step 6: mse=211170.442476 step=0.050000
2017/08/30 06:27:00 step 7: mse=210475.126925 step=0.050000
2017/08/30 06:27:00 Saving...
2017/08/30 06:27:00 Gathering batch of experience...
2017/08/30 06:27:31 batch 807: mean=9898.478261 stddev=9466.102159 entropy=0.363380 frames=6511 count=23
2017/08/30 06:27:31 Training policy...
2017/08/30 06:27:36 tune 0: objective=58.497567 reg=0.003634 prune=0
2017/08/30 06:27:38 step 0: objective=58.579169 reg=0.003634
2017/08/30 06:27:40 step 1: objective=58.650913 reg=0.003634
2017/08/30 06:27:41 step 2: objective=58.721035 reg=0.003635
2017/08/30 06:27:43 step 3: objective=58.776038 reg=0.003635
2017/08/30 06:27:45 step 4: objective=58.840520 reg=0.003635
2017/08/30 06:27:46 step 5: objective=58.874213 reg=0.003635
2017/08/30 06:27:48 step 6: objective=58.913968 reg=0.003635
2017/08/30 06:27:49 step 7: objective=58.935676 reg=0.003635
2017/08/30 06:27:49 Training value function...
2017/08/30 06:27:52 step 0: mse=208858.898922 step=0.050000
2017/08/30 06:27:53 step 1: mse=210037.955582 step=0.050000
2017/08/30 06:27:54 step 2: mse=212272.726304 step=0.050000
2017/08/30 06:27:55 step 3: mse=211891.045476 step=0.050000
2017/08/30 06:27:56 step 4: mse=210387.088864 step=0.050000
2017/08/30 06:27:58 step 5: mse=210941.977520 step=0.050000
2017/08/30 06:27:59 step 6: mse=211249.017257 step=0.050000
2017/08/30 06:28:00 step 7: mse=212795.691497 step=0.050000
2017/08/30 06:28:00 Saving...
2017/08/30 06:28:00 Gathering batch of experience...
2017/08/30 06:28:33 batch 808: mean=9937.200000 stddev=9715.161047 entropy=0.363176 frames=7096 count=25
2017/08/30 06:28:33 Training policy...
2017/08/30 06:28:39 tune 0: objective=64.165428 reg=0.003632 prune=0
2017/08/30 06:28:41 step 0: objective=64.248895 reg=0.003630
2017/08/30 06:28:42 step 1: objective=64.304547 reg=0.003630
2017/08/30 06:28:44 step 2: objective=64.353152 reg=0.003629
2017/08/30 06:28:46 step 3: objective=64.399653 reg=0.003629
2017/08/30 06:28:48 step 4: objective=64.439046 reg=0.003628
2017/08/30 06:28:50 step 5: objective=64.460841 reg=0.003628
2017/08/30 06:28:51 step 6: objective=64.501779 reg=0.003627
2017/08/30 06:28:53 step 7: objective=64.545378 reg=0.003627
2017/08/30 06:28:53 Training value function...
2017/08/30 06:28:56 step 0: mse=183712.364355 step=0.050000
2017/08/30 06:28:57 step 1: mse=185121.292829 step=0.050000
2017/08/30 06:28:58 step 2: mse=185006.829937 step=0.050000
2017/08/30 06:29:00 step 3: mse=184393.328001 step=0.050000
2017/08/30 06:29:01 step 4: mse=183826.934787 step=0.050000
2017/08/30 06:29:02 step 5: mse=184427.583061 step=0.050000
2017/08/30 06:29:03 step 6: mse=184830.637298 step=0.050000
2017/08/30 06:29:04 step 7: mse=184830.726640 step=0.050000
2017/08/30 06:29:04 Saving...
2017/08/30 06:29:04 Gathering batch of experience...
2017/08/30 06:29:40 batch 809: mean=11324.400000 stddev=10019.248008 entropy=0.364614 frames=7673 count=25
2017/08/30 06:29:40 Training policy...
2017/08/30 06:29:46 tune 0: objective=78.921331 reg=0.003646 prune=0
2017/08/30 06:29:48 step 0: objective=78.972884 reg=0.003646
2017/08/30 06:29:50 step 1: objective=79.046062 reg=0.003646
2017/08/30 06:29:52 step 2: objective=79.111177 reg=0.003646
2017/08/30 06:29:54 step 3: objective=79.152532 reg=0.003647
2017/08/30 06:29:56 step 4: objective=79.207530 reg=0.003647
2017/08/30 06:29:58 step 5: objective=79.249780 reg=0.003647
2017/08/30 06:30:00 step 6: objective=79.279470 reg=0.003647
2017/08/30 06:30:02 step 7: objective=79.317738 reg=0.003646
2017/08/30 06:30:02 Training value function...
2017/08/30 06:30:05 step 0: mse=191636.756746 step=0.050000
2017/08/30 06:30:06 step 1: mse=190308.451768 step=0.050000
2017/08/30 06:30:08 step 2: mse=187504.749854 step=0.050000
2017/08/30 06:30:09 step 3: mse=186224.727504 step=0.050000
2017/08/30 06:30:10 step 4: mse=185321.673991 step=0.050000
2017/08/30 06:30:11 step 5: mse=184438.794783 step=0.050000
2017/08/30 06:30:13 step 6: mse=183584.806379 step=0.050000
2017/08/30 06:30:14 step 7: mse=182103.800693 step=0.050000
2017/08/30 06:30:14 Saving...
2017/08/30 06:30:14 Gathering batch of experience...
2017/08/30 06:30:46 batch 810: mean=11741.190476 stddev=9809.520267 entropy=0.363154 frames=6735 count=21
2017/08/30 06:30:46 Training policy...
2017/08/30 06:30:51 tune 0: objective=75.782368 reg=0.003632 prune=0
2017/08/30 06:30:53 step 0: objective=75.916574 reg=0.003630
2017/08/30 06:30:55 step 1: objective=76.002190 reg=0.003630
2017/08/30 06:30:56 step 2: objective=76.067831 reg=0.003630
2017/08/30 06:30:58 step 3: objective=76.118300 reg=0.003629
2017/08/30 06:31:00 step 4: objective=76.170249 reg=0.003629
2017/08/30 06:31:02 step 5: objective=76.202287 reg=0.003630
2017/08/30 06:31:03 step 6: objective=76.246664 reg=0.003630
2017/08/30 06:31:05 step 7: objective=76.290873 reg=0.003629
2017/08/30 06:31:05 Training value function...
2017/08/30 06:31:08 step 0: mse=272129.104656 step=0.050000
2017/08/30 06:31:09 step 1: mse=266713.475373 step=0.050000
2017/08/30 06:31:10 step 2: mse=262547.056510 step=0.050000
2017/08/30 06:31:11 step 3: mse=259076.341207 step=0.050000
2017/08/30 06:31:12 step 4: mse=258709.390333 step=0.050000
2017/08/30 06:31:13 step 5: mse=259118.182193 step=0.050000
2017/08/30 06:31:14 step 6: mse=255411.294434 step=0.050000
2017/08/30 06:31:15 step 7: mse=250211.862326 step=0.050000
2017/08/30 06:31:15 Saving...
2017/08/30 06:31:16 Gathering batch of experience...
2017/08/30 06:31:47 batch 811: mean=13300.500000 stddev=9659.842895 entropy=0.365073 frames=6962 count=20
2017/08/30 06:31:47 Training policy...
2017/08/30 06:31:52 tune 0: objective=72.458269 reg=0.003651 prune=0
2017/08/30 06:31:54 step 0: objective=72.526425 reg=0.003650
2017/08/30 06:31:56 step 1: objective=72.562033 reg=0.003650
2017/08/30 06:31:58 step 2: objective=72.616687 reg=0.003650
2017/08/30 06:32:00 step 3: objective=72.676907 reg=0.003650
2017/08/30 06:32:01 step 4: objective=72.725321 reg=0.003649
2017/08/30 06:32:03 step 5: objective=72.763654 reg=0.003648
2017/08/30 06:32:05 step 6: objective=72.818160 reg=0.003649
2017/08/30 06:32:07 step 7: objective=72.867392 reg=0.003649
2017/08/30 06:32:07 Training value function...
2017/08/30 06:32:10 step 0: mse=198537.408051 step=0.050000
2017/08/30 06:32:11 step 1: mse=197820.593535 step=0.050000
2017/08/30 06:32:12 step 2: mse=198383.223514 step=0.050000
2017/08/30 06:32:13 step 3: mse=198693.279145 step=0.050000
2017/08/30 06:32:14 step 4: mse=199108.684916 step=0.050000
2017/08/30 06:32:15 step 5: mse=199032.376833 step=0.050000
2017/08/30 06:32:16 step 6: mse=199322.653847 step=0.050000
2017/08/30 06:32:17 step 7: mse=199125.551858 step=0.050000
2017/08/30 06:32:17 Saving...
2017/08/30 06:32:18 Gathering batch of experience...
2017/08/30 06:32:48 batch 812: mean=9574.583333 stddev=9501.280716 entropy=0.359425 frames=6602 count=24
2017/08/30 06:32:48 Training policy...
2017/08/30 06:32:54 tune 0: objective=56.961096 reg=0.003594 prune=0
2017/08/30 06:32:55 step 0: objective=57.071441 reg=0.003593
2017/08/30 06:32:57 step 1: objective=57.150082 reg=0.003593
2017/08/30 06:32:59 step 2: objective=57.264730 reg=0.003592
2017/08/30 06:33:01 step 3: objective=57.311127 reg=0.003591
2017/08/30 06:33:02 step 4: objective=57.335528 reg=0.003591
2017/08/30 06:33:04 step 5: objective=57.383691 reg=0.003591
2017/08/30 06:33:06 step 6: objective=57.427015 reg=0.003591
2017/08/30 06:33:07 step 7: objective=57.465408 reg=0.003591
2017/08/30 06:33:07 Training value function...
2017/08/30 06:33:10 step 0: mse=242433.803685 step=0.050000
2017/08/30 06:33:11 step 1: mse=243843.759993 step=0.050000
2017/08/30 06:33:12 step 2: mse=241456.636815 step=0.050000
2017/08/30 06:33:13 step 3: mse=242546.638403 step=0.050000
2017/08/30 06:33:14 step 4: mse=240278.296032 step=0.050000
2017/08/30 06:33:15 step 5: mse=241365.730716 step=0.050000
2017/08/30 06:33:17 step 6: mse=241398.352296 step=0.050000
2017/08/30 06:33:18 step 7: mse=242149.551462 step=0.050000
2017/08/30 06:33:18 Saving...
2017/08/30 06:33:18 Gathering batch of experience...
2017/08/30 06:33:49 batch 813: mean=9365.192308 stddev=9678.535876 entropy=0.365176 frames=6890 count=26
2017/08/30 06:33:49 Training policy...
2017/08/30 06:33:55 tune 0: objective=65.741292 reg=0.003652 prune=0
2017/08/30 06:33:57 step 0: objective=65.814559 reg=0.003651
2017/08/30 06:33:59 step 1: objective=65.857275 reg=0.003651
2017/08/30 06:34:00 step 2: objective=65.903470 reg=0.003651
2017/08/30 06:34:02 step 3: objective=65.956667 reg=0.003650
2017/08/30 06:34:04 step 4: objective=66.008495 reg=0.003650
2017/08/30 06:34:06 step 5: objective=66.056078 reg=0.003650
2017/08/30 06:34:07 step 6: objective=66.092317 reg=0.003650
2017/08/30 06:34:09 step 7: objective=66.140575 reg=0.003649
2017/08/30 06:34:09 Training value function...
2017/08/30 06:34:12 step 0: mse=194502.604420 step=0.050000
2017/08/30 06:34:13 step 1: mse=194848.896658 step=0.050000
2017/08/30 06:34:14 step 2: mse=193299.936746 step=0.050000
2017/08/30 06:34:15 step 3: mse=193435.886669 step=0.050000
2017/08/30 06:34:17 step 4: mse=193961.211533 step=0.050000
2017/08/30 06:34:18 step 5: mse=194477.959216 step=0.050000
2017/08/30 06:34:19 step 6: mse=194872.510830 step=0.050000
2017/08/30 06:34:20 step 7: mse=194462.665996 step=0.050000
2017/08/30 06:34:20 Saving...
2017/08/30 06:34:20 Gathering batch of experience...
2017/08/30 06:34:50 batch 814: mean=7266.346154 stddev=8786.181081 entropy=0.365742 frames=5873 count=26
2017/08/30 06:34:50 Training policy...
2017/08/30 06:34:55 tune 0: objective=45.506257 reg=0.003657 prune=0
2017/08/30 06:34:56 step 0: objective=45.572775 reg=0.003658
2017/08/30 06:34:58 step 1: objective=45.625229 reg=0.003657
2017/08/30 06:34:59 step 2: objective=45.683472 reg=0.003657
2017/08/30 06:35:01 step 3: objective=45.741066 reg=0.003656
2017/08/30 06:35:02 step 4: objective=45.796968 reg=0.003655
2017/08/30 06:35:04 step 5: objective=45.840020 reg=0.003655
2017/08/30 06:35:05 step 6: objective=45.871185 reg=0.003655
2017/08/30 06:35:07 step 7: objective=45.923602 reg=0.003654
2017/08/30 06:35:07 Training value function...
2017/08/30 06:35:09 step 0: mse=151469.936774 step=0.050000
2017/08/30 06:35:10 step 1: mse=151126.108808 step=0.050000
2017/08/30 06:35:11 step 2: mse=152943.904873 step=0.050000
2017/08/30 06:35:12 step 3: mse=154754.174848 step=0.050000
2017/08/30 06:35:13 step 4: mse=154730.719773 step=0.050000
2017/08/30 06:35:14 step 5: mse=155461.439095 step=0.050000
2017/08/30 06:35:15 step 6: mse=154945.426099 step=0.050000
2017/08/30 06:35:16 step 7: mse=155256.693462 step=0.050000
2017/08/30 06:35:16 Saving...
2017/08/30 06:35:16 Gathering batch of experience...
2017/08/30 06:35:50 batch 815: mean=9430.925926 stddev=9462.242221 entropy=0.363131 frames=7320 count=27
2017/08/30 06:35:50 Training policy...
2017/08/30 06:35:56 tune 0: objective=68.301405 reg=0.003631 prune=0
2017/08/30 06:35:58 step 0: objective=68.366581 reg=0.003630
2017/08/30 06:36:00 step 1: objective=68.434127 reg=0.003629
2017/08/30 06:36:02 step 2: objective=68.500837 reg=0.003628
2017/08/30 06:36:04 step 3: objective=68.561966 reg=0.003628
2017/08/30 06:36:06 step 4: objective=68.613298 reg=0.003628
2017/08/30 06:36:07 step 5: objective=68.665100 reg=0.003627
2017/08/30 06:36:09 step 6: objective=68.705225 reg=0.003625
2017/08/30 06:36:11 step 7: objective=68.745949 reg=0.003623
2017/08/30 06:36:11 Training value function...
2017/08/30 06:36:14 step 0: mse=242254.630151 step=0.050000
2017/08/30 06:36:15 step 1: mse=243659.650643 step=0.050000
2017/08/30 06:36:17 step 2: mse=241423.577296 step=0.050000
2017/08/30 06:36:18 step 3: mse=241906.125030 step=0.050000
2017/08/30 06:36:19 step 4: mse=240792.204408 step=0.050000
2017/08/30 06:36:20 step 5: mse=239255.462281 step=0.050000
2017/08/30 06:36:21 step 6: mse=239268.403642 step=0.050000
2017/08/30 06:36:23 step 7: mse=239712.247184 step=0.050000
2017/08/30 06:36:23 Saving...
2017/08/30 06:36:23 Gathering batch of experience...
2017/08/30 06:36:53 batch 816: mean=14894.705882 stddev=9745.561051 entropy=0.363473 frames=6389 count=17
2017/08/30 06:36:53 Training policy...
2017/08/30 06:36:58 tune 0: objective=98.830118 reg=0.003635 prune=0
2017/08/30 06:37:00 step 0: objective=98.911625 reg=0.003635
2017/08/30 06:37:01 step 1: objective=98.980474 reg=0.003635
2017/08/30 06:37:03 step 2: objective=99.034962 reg=0.003635
2017/08/30 06:37:05 step 3: objective=99.079727 reg=0.003635
2017/08/30 06:37:06 step 4: objective=99.116127 reg=0.003635
2017/08/30 06:37:08 step 5: objective=99.161498 reg=0.003635
2017/08/30 06:37:09 step 6: objective=99.212905 reg=0.003635
2017/08/30 06:37:11 step 7: objective=99.258413 reg=0.003634
2017/08/30 06:37:11 Training value function...
2017/08/30 06:37:14 step 0: mse=208631.865666 step=0.050000
2017/08/30 06:37:15 step 1: mse=205164.091499 step=0.050000
2017/08/30 06:37:16 step 2: mse=202714.914891 step=0.050000
2017/08/30 06:37:17 step 3: mse=200560.172140 step=0.050000
2017/08/30 06:37:18 step 4: mse=198435.484031 step=0.050000
2017/08/30 06:37:19 step 5: mse=196311.469932 step=0.050000
2017/08/30 06:37:20 step 6: mse=194683.418366 step=0.050000
2017/08/30 06:37:21 step 7: mse=193644.018313 step=0.050000
2017/08/30 06:37:21 Saving...
2017/08/30 06:37:21 Gathering batch of experience...
2017/08/30 06:37:56 batch 817: mean=9543.392857 stddev=9878.981842 entropy=0.364898 frames=7654 count=28
2017/08/30 06:37:56 Training policy...
2017/08/30 06:38:03 tune 0: objective=65.350327 reg=0.003649 prune=0
2017/08/30 06:38:05 step 0: objective=65.424280 reg=0.003647
2017/08/30 06:38:07 step 1: objective=65.486367 reg=0.003647
2017/08/30 06:38:09 step 2: objective=65.565056 reg=0.003646
2017/08/30 06:38:11 step 3: objective=65.616691 reg=0.003646
2017/08/30 06:38:13 step 4: objective=65.648680 reg=0.003646
2017/08/30 06:38:14 step 5: objective=65.682833 reg=0.003645
2017/08/30 06:38:16 step 6: objective=65.721330 reg=0.003645
2017/08/30 06:38:18 step 7: objective=65.758950 reg=0.003645
2017/08/30 06:38:18 Training value function...
2017/08/30 06:38:22 step 0: mse=197462.225469 step=0.050000
2017/08/30 06:38:23 step 1: mse=196761.517569 step=0.050000
2017/08/30 06:38:24 step 2: mse=195456.100140 step=0.050000
2017/08/30 06:38:25 step 3: mse=195537.012851 step=0.050000
2017/08/30 06:38:27 step 4: mse=195712.965117 step=0.050000
2017/08/30 06:38:28 step 5: mse=194372.953510 step=0.050000
2017/08/30 06:38:29 step 6: mse=195475.154612 step=0.050000
2017/08/30 06:38:30 step 7: mse=195811.102934 step=0.050000
2017/08/30 06:38:30 Saving...
2017/08/30 06:38:30 Gathering batch of experience...
2017/08/30 06:39:03 batch 818: mean=13072.750000 stddev=9664.894137 entropy=0.356549 frames=6944 count=20
2017/08/30 06:39:03 Training policy...
2017/08/30 06:39:09 tune 0: objective=78.205492 reg=0.003565 prune=0
2017/08/30 06:39:11 step 0: objective=78.265580 reg=0.003565
2017/08/30 06:39:12 step 1: objective=78.313292 reg=0.003564
2017/08/30 06:39:14 step 2: objective=78.350563 reg=0.003564
2017/08/30 06:39:16 step 3: objective=78.401957 reg=0.003564
2017/08/30 06:39:18 step 4: objective=78.448652 reg=0.003564
2017/08/30 06:39:20 step 5: objective=78.497795 reg=0.003563
2017/08/30 06:39:21 step 6: objective=78.514914 reg=0.003563
2017/08/30 06:39:23 step 7: objective=78.538009 reg=0.003562
2017/08/30 06:39:23 Training value function...
2017/08/30 06:39:26 step 0: mse=192272.630729 step=0.050000
2017/08/30 06:39:27 step 1: mse=192358.189980 step=0.050000
2017/08/30 06:39:28 step 2: mse=192187.997945 step=0.050000
2017/08/30 06:39:29 step 3: mse=192029.443482 step=0.050000
2017/08/30 06:39:30 step 4: mse=192140.317458 step=0.050000
2017/08/30 06:39:32 step 5: mse=191499.872908 step=0.050000
2017/08/30 06:39:33 step 6: mse=190352.501197 step=0.050000
2017/08/30 06:39:34 step 7: mse=188683.057992 step=0.050000
2017/08/30 06:39:34 Saving...
2017/08/30 06:39:34 Gathering batch of experience...
2017/08/30 06:40:06 batch 819: mean=9855.833333 stddev=10053.176909 entropy=0.362166 frames=6478 count=24
2017/08/30 06:40:06 Training policy...
2017/08/30 06:40:11 tune 0: objective=72.820720 reg=0.003622 prune=0
2017/08/30 06:40:13 step 0: objective=72.891344 reg=0.003622
2017/08/30 06:40:15 step 1: objective=72.981669 reg=0.003623
2017/08/30 06:40:16 step 2: objective=73.020603 reg=0.003622
2017/08/30 06:40:18 step 3: objective=73.052871 reg=0.003622
2017/08/30 06:40:20 step 4: objective=73.085028 reg=0.003622
2017/08/30 06:40:21 step 5: objective=73.122738 reg=0.003622
2017/08/30 06:40:23 step 6: objective=73.161600 reg=0.003621
2017/08/30 06:40:25 step 7: objective=73.224428 reg=0.003621
2017/08/30 06:40:25 Training value function...
2017/08/30 06:40:27 step 0: mse=219773.064601 step=0.050000
2017/08/30 06:40:28 step 1: mse=217544.366559 step=0.050000
2017/08/30 06:40:29 step 2: mse=215340.173752 step=0.050000
2017/08/30 06:40:30 step 3: mse=215901.679149 step=0.050000
2017/08/30 06:40:31 step 4: mse=213789.449989 step=0.050000
2017/08/30 06:40:32 step 5: mse=213878.800017 step=0.050000
2017/08/30 06:40:34 step 6: mse=212890.854203 step=0.050000
2017/08/30 06:40:35 step 7: mse=212968.166214 step=0.050000
2017/08/30 06:40:35 Saving...
2017/08/30 06:40:35 Gathering batch of experience...
2017/08/30 06:41:07 batch 820: mean=10259.565217 stddev=9934.982212 entropy=0.364678 frames=6546 count=23
2017/08/30 06:41:07 Training policy...
2017/08/30 06:41:12 tune 0: objective=62.431943 reg=0.003647 prune=0
2017/08/30 06:41:14 step 0: objective=62.475529 reg=0.003647
2017/08/30 06:41:16 step 1: objective=62.500936 reg=0.003646
2017/08/30 06:41:17 step 2: objective=62.536964 reg=0.003646
2017/08/30 06:41:19 step 3: objective=62.571131 reg=0.003646
2017/08/30 06:41:21 step 4: objective=62.607647 reg=0.003646
2017/08/30 06:41:22 step 5: objective=62.640959 reg=0.003646
2017/08/30 06:41:24 step 6: objective=62.669044 reg=0.003645
2017/08/30 06:41:26 step 7: objective=62.699082 reg=0.003645
2017/08/30 06:41:26 Training value function...
2017/08/30 06:41:28 step 0: mse=150696.835640 step=0.050000
2017/08/30 06:41:29 step 1: mse=150572.419700 step=0.050000
2017/08/30 06:41:30 step 2: mse=151287.918633 step=0.050000
2017/08/30 06:41:32 step 3: mse=152804.309650 step=0.050000
2017/08/30 06:41:33 step 4: mse=152481.232325 step=0.050000
2017/08/30 06:41:34 step 5: mse=152826.846786 step=0.050000
2017/08/30 06:41:35 step 6: mse=152658.175247 step=0.050000
2017/08/30 06:41:36 step 7: mse=152355.539086 step=0.050000
2017/08/30 06:41:36 Saving...
2017/08/30 06:41:36 Gathering batch of experience...
2017/08/30 06:42:09 batch 821: mean=7413.333333 stddev=9158.670148 entropy=0.363749 frames=6784 count=30
2017/08/30 06:42:09 Training policy...
2017/08/30 06:42:15 tune 0: objective=50.701292 reg=0.003637 prune=0
2017/08/30 06:42:17 step 0: objective=50.740792 reg=0.003637
2017/08/30 06:42:19 step 1: objective=50.774165 reg=0.003638
2017/08/30 06:42:20 step 2: objective=50.801670 reg=0.003637
2017/08/30 06:42:22 step 3: objective=50.848426 reg=0.003637
2017/08/30 06:42:24 step 4: objective=50.878377 reg=0.003637
2017/08/30 06:42:26 step 5: objective=50.903491 reg=0.003636
2017/08/30 06:42:27 step 6: objective=50.945888 reg=0.003636
2017/08/30 06:42:29 step 7: objective=50.969750 reg=0.003636
2017/08/30 06:42:29 Training value function...
2017/08/30 06:42:32 step 0: mse=181919.215401 step=0.050000
2017/08/30 06:42:33 step 1: mse=182198.504043 step=0.050000
2017/08/30 06:42:34 step 2: mse=182124.300650 step=0.050000
2017/08/30 06:42:35 step 3: mse=182341.215113 step=0.050000
2017/08/30 06:42:36 step 4: mse=182330.162644 step=0.050000
2017/08/30 06:42:37 step 5: mse=183130.252877 step=0.050000
2017/08/30 06:42:38 step 6: mse=183409.120002 step=0.050000
2017/08/30 06:42:40 step 7: mse=184154.552828 step=0.050000
2017/08/30 06:42:40 Saving...
2017/08/30 06:42:40 Gathering batch of experience...
2017/08/30 06:43:15 batch 822: mean=10806.923077 stddev=10220.821139 entropy=0.361611 frames=7533 count=26
2017/08/30 06:43:15 Training policy...
2017/08/30 06:43:21 tune 0: objective=79.415547 reg=0.003616 prune=0
2017/08/30 06:43:23 step 0: objective=79.468107 reg=0.003616
2017/08/30 06:43:25 step 1: objective=79.523862 reg=0.003615
2017/08/30 06:43:27 step 2: objective=79.556725 reg=0.003615
2017/08/30 06:43:29 step 3: objective=79.607884 reg=0.003614
2017/08/30 06:43:31 step 4: objective=79.646066 reg=0.003614
2017/08/30 06:43:33 step 5: objective=79.682821 reg=0.003613
2017/08/30 06:43:35 step 6: objective=79.723649 reg=0.003613
2017/08/30 06:43:37 step 7: objective=79.755368 reg=0.003613
2017/08/30 06:43:37 Training value function...
2017/08/30 06:43:40 step 0: mse=191528.945893 step=0.050000
2017/08/30 06:43:41 step 1: mse=189724.465289 step=0.050000
2017/08/30 06:43:42 step 2: mse=189196.828179 step=0.050000
2017/08/30 06:43:43 step 3: mse=188859.775376 step=0.050000
2017/08/30 06:43:45 step 4: mse=184909.061928 step=0.050000
2017/08/30 06:43:46 step 5: mse=184305.677587 step=0.050000
2017/08/30 06:43:47 step 6: mse=185315.536013 step=0.050000
2017/08/30 06:43:48 step 7: mse=185629.552292 step=0.050000
2017/08/30 06:43:48 Saving...
2017/08/30 06:43:48 Gathering batch of experience...
2017/08/30 06:44:21 batch 823: mean=9750.800000 stddev=9915.588604 entropy=0.361208 frames=6956 count=25
2017/08/30 06:44:21 Training policy...
2017/08/30 06:44:27 tune 0: objective=66.128657 reg=0.003612 prune=0
2017/08/30 06:44:29 step 0: objective=66.167535 reg=0.003612
2017/08/30 06:44:31 step 1: objective=66.209549 reg=0.003611
2017/08/30 06:44:33 step 2: objective=66.253347 reg=0.003611
2017/08/30 06:44:34 step 3: objective=66.306431 reg=0.003611
2017/08/30 06:44:36 step 4: objective=66.375858 reg=0.003611
2017/08/30 06:44:38 step 5: objective=66.410046 reg=0.003610
2017/08/30 06:44:40 step 6: objective=66.445272 reg=0.003609
2017/08/30 06:44:41 step 7: objective=66.483059 reg=0.003609
2017/08/30 06:44:41 Training value function...
2017/08/30 06:44:44 step 0: mse=160352.076921 step=0.050000
2017/08/30 06:44:45 step 1: mse=159893.178378 step=0.050000
2017/08/30 06:44:47 step 2: mse=160571.152296 step=0.050000
2017/08/30 06:44:48 step 3: mse=161816.609553 step=0.050000
2017/08/30 06:44:49 step 4: mse=160560.182814 step=0.050000
2017/08/30 06:44:50 step 5: mse=160292.151870 step=0.050000
2017/08/30 06:44:51 step 6: mse=160667.136410 step=0.050000
2017/08/30 06:44:52 step 7: mse=161086.519678 step=0.050000
2017/08/30 06:44:52 Saving...
2017/08/30 06:44:52 Gathering batch of experience...
2017/08/30 06:45:26 batch 824: mean=9795.384615 stddev=9795.365459 entropy=0.365032 frames=6991 count=26
2017/08/30 06:45:26 Training policy...
2017/08/30 06:45:32 tune 0: objective=73.367705 reg=0.003650 prune=0
2017/08/30 06:45:34 step 0: objective=73.412285 reg=0.003650
2017/08/30 06:45:36 step 1: objective=73.472666 reg=0.003650
2017/08/30 06:45:38 step 2: objective=73.532287 reg=0.003650
2017/08/30 06:45:39 step 3: objective=73.583643 reg=0.003650
2017/08/30 06:45:41 step 4: objective=73.642451 reg=0.003650
2017/08/30 06:45:43 step 5: objective=73.691559 reg=0.003649
2017/08/30 06:45:45 step 6: objective=73.728660 reg=0.003650
2017/08/30 06:45:47 step 7: objective=73.755033 reg=0.003649
2017/08/30 06:45:47 Training value function...
2017/08/30 06:45:50 step 0: mse=241804.741749 step=0.050000
2017/08/30 06:45:51 step 1: mse=240725.812069 step=0.050000
2017/08/30 06:45:52 step 2: mse=240310.785700 step=0.050000
2017/08/30 06:45:53 step 3: mse=240210.471243 step=0.050000
2017/08/30 06:45:54 step 4: mse=236159.423099 step=0.050000
2017/08/30 06:45:55 step 5: mse=237253.331426 step=0.050000
2017/08/30 06:45:56 step 6: mse=232322.744653 step=0.050000
2017/08/30 06:45:58 step 7: mse=231764.813062 step=0.050000
2017/08/30 06:45:58 Saving...
2017/08/30 06:45:58 Gathering batch of experience...
2017/08/30 06:46:31 batch 825: mean=12073.913043 stddev=10162.903980 entropy=0.356508 frames=7234 count=23
2017/08/30 06:46:31 Training policy...
2017/08/30 06:46:38 tune 0: objective=84.012433 reg=0.003565 prune=0
2017/08/30 06:46:39 step 0: objective=84.058837 reg=0.003565
2017/08/30 06:46:41 step 1: objective=84.083555 reg=0.003565
2017/08/30 06:46:43 step 2: objective=84.109664 reg=0.003564
2017/08/30 06:46:45 step 3: objective=84.142660 reg=0.003563
2017/08/30 06:46:47 step 4: objective=84.179275 reg=0.003562
2017/08/30 06:46:49 step 5: objective=84.211052 reg=0.003562
2017/08/30 06:46:51 step 6: objective=84.230923 reg=0.003561
2017/08/30 06:46:52 step 7: objective=84.267383 reg=0.003561
2017/08/30 06:46:52 Training value function...
2017/08/30 06:46:55 step 0: mse=233953.404281 step=0.050000
2017/08/30 06:46:57 step 1: mse=232178.879910 step=0.050000
2017/08/30 06:46:58 step 2: mse=229412.490497 step=0.050000
2017/08/30 06:46:59 step 3: mse=229074.351680 step=0.050000
2017/08/30 06:47:00 step 4: mse=226970.812938 step=0.050000
2017/08/30 06:47:01 step 5: mse=225709.284977 step=0.050000
2017/08/30 06:47:03 step 6: mse=224101.588538 step=0.050000
2017/08/30 06:47:04 step 7: mse=223130.237578 step=0.050000
2017/08/30 06:47:04 Saving...
2017/08/30 06:47:04 Gathering batch of experience...
2017/08/30 06:47:38 batch 826: mean=9177.777778 stddev=9706.356864 entropy=0.360883 frames=7257 count=27
2017/08/30 06:47:38 Training policy...
2017/08/30 06:47:44 tune 0: objective=60.721579 reg=0.003609 prune=0
2017/08/30 06:47:46 step 0: objective=60.778356 reg=0.003609
2017/08/30 06:47:48 step 1: objective=60.816785 reg=0.003608
2017/08/30 06:47:50 step 2: objective=60.858611 reg=0.003608
2017/08/30 06:47:51 step 3: objective=60.906332 reg=0.003609
2017/08/30 06:47:53 step 4: objective=60.936376 reg=0.003609
2017/08/30 06:47:55 step 5: objective=60.969555 reg=0.003609
2017/08/30 06:47:57 step 6: objective=60.996030 reg=0.003609
2017/08/30 06:47:59 step 7: objective=61.029932 reg=0.003608
2017/08/30 06:47:59 Training value function...
2017/08/30 06:48:02 step 0: mse=174273.167753 step=0.050000
2017/08/30 06:48:03 step 1: mse=174241.086157 step=0.050000
2017/08/30 06:48:04 step 2: mse=172712.142945 step=0.050000
2017/08/30 06:48:05 step 3: mse=173072.884658 step=0.050000
2017/08/30 06:48:07 step 4: mse=172772.012421 step=0.050000
2017/08/30 06:48:08 step 5: mse=173328.819377 step=0.050000
2017/08/30 06:48:09 step 6: mse=173930.257295 step=0.050000
2017/08/30 06:48:10 step 7: mse=173334.939918 step=0.050000
2017/08/30 06:48:10 Saving...
2017/08/30 06:48:10 Gathering batch of experience...
2017/08/30 06:48:45 batch 827: mean=9559.423077 stddev=9946.876136 entropy=0.361689 frames=7022 count=26
2017/08/30 06:48:45 Training policy...
2017/08/30 06:48:51 tune 0: objective=63.369646 reg=0.003617 prune=0
2017/08/30 06:48:53 step 0: objective=63.451122 reg=0.003616
2017/08/30 06:48:54 step 1: objective=63.533448 reg=0.003616
2017/08/30 06:48:56 step 2: objective=63.602953 reg=0.003616
2017/08/30 06:48:58 step 3: objective=63.674964 reg=0.003615
2017/08/30 06:49:00 step 4: objective=63.721215 reg=0.003615
2017/08/30 06:49:02 step 5: objective=63.767641 reg=0.003615
2017/08/30 06:49:04 step 6: objective=63.788820 reg=0.003615
2017/08/30 06:49:05 step 7: objective=63.816176 reg=0.003615
2017/08/30 06:49:05 Training value function...
2017/08/30 06:49:08 step 0: mse=193920.650039 step=0.050000
2017/08/30 06:49:09 step 1: mse=193088.002918 step=0.050000
2017/08/30 06:49:11 step 2: mse=194313.254166 step=0.050000
2017/08/30 06:49:12 step 3: mse=194279.187075 step=0.050000
2017/08/30 06:49:13 step 4: mse=195054.167150 step=0.050000
2017/08/30 06:49:14 step 5: mse=194990.850649 step=0.050000
2017/08/30 06:49:15 step 6: mse=192602.576920 step=0.050000
2017/08/30 06:49:16 step 7: mse=191379.594023 step=0.050000
2017/08/30 06:49:16 Saving...
2017/08/30 06:49:16 Gathering batch of experience...
2017/08/30 06:49:48 batch 828: mean=12343.181818 stddev=10200.713383 entropy=0.362942 frames=7011 count=22
2017/08/30 06:49:48 Training policy...
2017/08/30 06:49:54 tune 0: objective=74.028192 reg=0.003629 prune=0
2017/08/30 06:49:56 step 0: objective=74.109587 reg=0.003629
2017/08/30 06:49:58 step 1: objective=74.180636 reg=0.003629
2017/08/30 06:50:00 step 2: objective=74.257216 reg=0.003629
2017/08/30 06:50:01 step 3: objective=74.306746 reg=0.003628
2017/08/30 06:50:03 step 4: objective=74.344049 reg=0.003628
2017/08/30 06:50:05 step 5: objective=74.398298 reg=0.003628
2017/08/30 06:50:07 step 6: objective=74.451795 reg=0.003627
2017/08/30 06:50:09 step 7: objective=74.487069 reg=0.003627
2017/08/30 06:50:09 Training value function...
2017/08/30 06:50:12 step 0: mse=185832.013534 step=0.050000
2017/08/30 06:50:13 step 1: mse=184505.748741 step=0.050000
2017/08/30 06:50:14 step 2: mse=183992.933653 step=0.050000
2017/08/30 06:50:15 step 3: mse=185070.640990 step=0.050000
2017/08/30 06:50:16 step 4: mse=185168.600225 step=0.050000
2017/08/30 06:50:17 step 5: mse=185110.345229 step=0.050000
2017/08/30 06:50:18 step 6: mse=184372.936300 step=0.050000
2017/08/30 06:50:20 step 7: mse=184362.394869 step=0.050000
2017/08/30 06:50:20 Saving...
2017/08/30 06:50:20 Gathering batch of experience...
2017/08/30 06:50:56 batch 829: mean=9827.586207 stddev=9937.299000 entropy=0.361743 frames=7972 count=29
2017/08/30 06:50:56 Training policy...
2017/08/30 06:51:03 tune 0: objective=66.563801 reg=0.003617 prune=0
2017/08/30 06:51:05 step 0: objective=66.606435 reg=0.003617
2017/08/30 06:51:07 step 1: objective=66.647273 reg=0.003617
2017/08/30 06:51:09 step 2: objective=66.702098 reg=0.003617
2017/08/30 06:51:11 step 3: objective=66.743022 reg=0.003618
2017/08/30 06:51:14 step 4: objective=66.775417 reg=0.003618
2017/08/30 06:51:16 step 5: objective=66.806385 reg=0.003618
2017/08/30 06:51:18 step 6: objective=66.842433 reg=0.003617
2017/08/30 06:51:20 step 7: objective=66.861649 reg=0.003617
2017/08/30 06:51:20 Training value function...
2017/08/30 06:51:23 step 0: mse=193976.717782 step=0.050000
2017/08/30 06:51:25 step 1: mse=191915.862004 step=0.050000
2017/08/30 06:51:26 step 2: mse=192159.647876 step=0.050000
2017/08/30 06:51:27 step 3: mse=192973.762140 step=0.050000
2017/08/30 06:51:29 step 4: mse=192698.497433 step=0.050000
2017/08/30 06:51:30 step 5: mse=193667.275380 step=0.050000
2017/08/30 06:51:31 step 6: mse=193320.801105 step=0.050000
2017/08/30 06:51:33 step 7: mse=192432.511522 step=0.050000
2017/08/30 06:51:33 Saving...
2017/08/30 06:51:33 Gathering batch of experience...
2017/08/30 06:52:03 batch 830: mean=13272.631579 stddev=9870.993707 entropy=0.359291 frames=6524 count=19
2017/08/30 06:52:03 Training policy...
2017/08/30 06:52:09 tune 0: objective=81.511783 reg=0.003593 prune=0
2017/08/30 06:52:10 step 0: objective=81.599872 reg=0.003592
2017/08/30 06:52:12 step 1: objective=81.662937 reg=0.003593
2017/08/30 06:52:14 step 2: objective=81.735036 reg=0.003593
2017/08/30 06:52:15 step 3: objective=81.779075 reg=0.003593
2017/08/30 06:52:17 step 4: objective=81.811906 reg=0.003593
2017/08/30 06:52:19 step 5: objective=81.856539 reg=0.003594
2017/08/30 06:52:20 step 6: objective=81.899726 reg=0.003595
2017/08/30 06:52:22 step 7: objective=81.930507 reg=0.003595
2017/08/30 06:52:22 Training value function...
2017/08/30 06:52:25 step 0: mse=200510.968111 step=0.050000
2017/08/30 06:52:26 step 1: mse=200463.195655 step=0.050000
2017/08/30 06:52:27 step 2: mse=200691.696175 step=0.050000
2017/08/30 06:52:28 step 3: mse=200931.871241 step=0.050000
2017/08/30 06:52:29 step 4: mse=200090.234120 step=0.050000
2017/08/30 06:52:30 step 5: mse=198964.860425 step=0.050000
2017/08/30 06:52:31 step 6: mse=199587.744688 step=0.050000
2017/08/30 06:52:32 step 7: mse=200550.089412 step=0.050000
2017/08/30 06:52:32 Saving...
2017/08/30 06:52:32 Gathering batch of experience...
2017/08/30 06:53:04 batch 831: mean=10475.217391 stddev=9895.522206 entropy=0.354072 frames=6615 count=23
2017/08/30 06:53:04 Training policy...
2017/08/30 06:53:10 tune 0: objective=66.053562 reg=0.003541 prune=0
2017/08/30 06:53:12 step 0: objective=66.150123 reg=0.003540
2017/08/30 06:53:13 step 1: objective=66.223342 reg=0.003539
2017/08/30 06:53:15 step 2: objective=66.285190 reg=0.003539
2017/08/30 06:53:17 step 3: objective=66.335780 reg=0.003539
2017/08/30 06:53:18 step 4: objective=66.389966 reg=0.003538
2017/08/30 06:53:20 step 5: objective=66.431231 reg=0.003537
2017/08/30 06:53:22 step 6: objective=66.463530 reg=0.003536
2017/08/30 06:53:24 step 7: objective=66.481278 reg=0.003536
2017/08/30 06:53:24 Training value function...
2017/08/30 06:53:26 step 0: mse=205306.431777 step=0.050000
2017/08/30 06:53:27 step 1: mse=205815.881283 step=0.050000
2017/08/30 06:53:28 step 2: mse=203568.421325 step=0.050000
2017/08/30 06:53:30 step 3: mse=203185.141914 step=0.050000
2017/08/30 06:53:31 step 4: mse=203676.668138 step=0.050000
2017/08/30 06:53:32 step 5: mse=203424.779202 step=0.050000
2017/08/30 06:53:33 step 6: mse=204539.998995 step=0.050000
2017/08/30 06:53:34 step 7: mse=205823.290885 step=0.050000
2017/08/30 06:53:34 Saving...
2017/08/30 06:53:34 Gathering batch of experience...
2017/08/30 06:54:04 batch 832: mean=8520.208333 stddev=9555.632881 entropy=0.363282 frames=6253 count=24
2017/08/30 06:54:04 Training policy...
2017/08/30 06:54:09 tune 0: objective=55.089307 reg=0.003633 prune=0
2017/08/30 06:54:11 step 0: objective=55.137354 reg=0.003633
2017/08/30 06:54:13 step 1: objective=55.190214 reg=0.003633
2017/08/30 06:54:14 step 2: objective=55.247361 reg=0.003632
2017/08/30 06:54:16 step 3: objective=55.287927 reg=0.003632
2017/08/30 06:54:17 step 4: objective=55.337153 reg=0.003632
2017/08/30 06:54:19 step 5: objective=55.371117 reg=0.003632
2017/08/30 06:54:21 step 6: objective=55.403521 reg=0.003631
2017/08/30 06:54:22 step 7: objective=55.431933 reg=0.003630
2017/08/30 06:54:22 Training value function...
2017/08/30 06:54:25 step 0: mse=150015.049048 step=0.050000
2017/08/30 06:54:26 step 1: mse=149776.733650 step=0.050000
2017/08/30 06:54:27 step 2: mse=148925.184206 step=0.050000
2017/08/30 06:54:28 step 3: mse=149208.885812 step=0.050000
2017/08/30 06:54:29 step 4: mse=150011.842072 step=0.050000
2017/08/30 06:54:30 step 5: mse=149468.025825 step=0.050000
2017/08/30 06:54:31 step 6: mse=149021.749768 step=0.050000
2017/08/30 06:54:32 step 7: mse=148797.041731 step=0.050000
2017/08/30 06:54:32 Saving...
2017/08/30 06:54:32 Gathering batch of experience...
2017/08/30 06:55:02 batch 833: mean=9028.750000 stddev=9725.855602 entropy=0.360983 frames=6096 count=24
2017/08/30 06:55:02 Training policy...
2017/08/30 06:55:07 tune 0: objective=57.600573 reg=0.003610 prune=0
2017/08/30 06:55:08 step 0: objective=57.672121 reg=0.003609
2017/08/30 06:55:10 step 1: objective=57.721595 reg=0.003609
2017/08/30 06:55:11 step 2: objective=57.754983 reg=0.003609
2017/08/30 06:55:13 step 3: objective=57.788283 reg=0.003609
2017/08/30 06:55:15 step 4: objective=57.818980 reg=0.003609
2017/08/30 06:55:16 step 5: objective=57.848102 reg=0.003609
2017/08/30 06:55:18 step 6: objective=57.881285 reg=0.003608
2017/08/30 06:55:19 step 7: objective=57.921716 reg=0.003607
2017/08/30 06:55:19 Training value function...
2017/08/30 06:55:22 step 0: mse=173015.774497 step=0.050000
2017/08/30 06:55:23 step 1: mse=175130.207510 step=0.050000
2017/08/30 06:55:24 step 2: mse=175593.639191 step=0.050000
2017/08/30 06:55:25 step 3: mse=175821.069973 step=0.050000
2017/08/30 06:55:26 step 4: mse=176124.391797 step=0.050000
2017/08/30 06:55:27 step 5: mse=176120.946984 step=0.050000
2017/08/30 06:55:28 step 6: mse=176362.640520 step=0.050000
2017/08/30 06:55:29 step 7: mse=176700.469479 step=0.050000
2017/08/30 06:55:29 Saving...
2017/08/30 06:55:29 Gathering batch of experience...
2017/08/30 06:56:02 batch 834: mean=11632.500000 stddev=10062.277976 entropy=0.357707 frames=6867 count=22
2017/08/30 06:56:02 Training policy...
2017/08/30 06:56:08 tune 0: objective=84.027359 reg=0.003577 prune=0
2017/08/30 06:56:10 step 0: objective=84.083570 reg=0.003576
2017/08/30 06:56:11 step 1: objective=84.120859 reg=0.003575
2017/08/30 06:56:13 step 2: objective=84.172828 reg=0.003574
2017/08/30 06:56:15 step 3: objective=84.235055 reg=0.003573
2017/08/30 06:56:17 step 4: objective=84.314075 reg=0.003572
2017/08/30 06:56:18 step 5: objective=84.371978 reg=0.003571
2017/08/30 06:56:20 step 6: objective=84.426615 reg=0.003569
2017/08/30 06:56:22 step 7: objective=84.464941 reg=0.003568
2017/08/30 06:56:22 Training value function...
2017/08/30 06:56:25 step 0: mse=257971.769809 step=0.050000
2017/08/30 06:56:26 step 1: mse=257027.797110 step=0.050000
2017/08/30 06:56:27 step 2: mse=253197.767148 step=0.050000
2017/08/30 06:56:28 step 3: mse=249614.561458 step=0.050000
2017/08/30 06:56:29 step 4: mse=247953.195492 step=0.050000
2017/08/30 06:56:30 step 5: mse=244618.210755 step=0.050000
2017/08/30 06:56:32 step 6: mse=242280.214879 step=0.050000
2017/08/30 06:56:33 step 7: mse=241893.216122 step=0.050000
2017/08/30 06:56:33 Saving...
2017/08/30 06:56:33 Gathering batch of experience...
2017/08/30 06:57:04 batch 835: mean=11765.909091 stddev=10056.563849 entropy=0.357197 frames=6752 count=22
2017/08/30 06:57:04 Training policy...
2017/08/30 06:57:10 tune 0: objective=78.230913 reg=0.003572 prune=0
2017/08/30 06:57:12 step 0: objective=78.296570 reg=0.003572
2017/08/30 06:57:13 step 1: objective=78.344629 reg=0.003572
2017/08/30 06:57:15 step 2: objective=78.413914 reg=0.003572
2017/08/30 06:57:17 step 3: objective=78.486032 reg=0.003573
2017/08/30 06:57:19 step 4: objective=78.542265 reg=0.003572
2017/08/30 06:57:20 step 5: objective=78.594648 reg=0.003571
2017/08/30 06:57:22 step 6: objective=78.630554 reg=0.003571
2017/08/30 06:57:24 step 7: objective=78.673097 reg=0.003570
2017/08/30 06:57:24 Training value function...
2017/08/30 06:57:27 step 0: mse=190166.661364 step=0.050000
2017/08/30 06:57:28 step 1: mse=189312.081851 step=0.050000
2017/08/30 06:57:29 step 2: mse=188438.337238 step=0.050000
2017/08/30 06:57:30 step 3: mse=189223.678176 step=0.050000
2017/08/30 06:57:31 step 4: mse=187181.214352 step=0.050000
2017/08/30 06:57:32 step 5: mse=186745.775337 step=0.050000
2017/08/30 06:57:33 step 6: mse=186288.482537 step=0.050000
2017/08/30 06:57:34 step 7: mse=186507.661209 step=0.050000
2017/08/30 06:57:34 Saving...
2017/08/30 06:57:34 Gathering batch of experience...
2017/08/30 06:58:09 batch 836: mean=10815.800000 stddev=10095.969857 entropy=0.353648 frames=7430 count=25
2017/08/30 06:58:09 Training policy...
2017/08/30 06:58:16 tune 0: objective=73.284320 reg=0.003536 prune=0
2017/08/30 06:58:18 step 0: objective=73.337121 reg=0.003536
2017/08/30 06:58:19 step 1: objective=73.386819 reg=0.003535
2017/08/30 06:58:21 step 2: objective=73.434934 reg=0.003535
2017/08/30 06:58:23 step 3: objective=73.480156 reg=0.003535
2017/08/30 06:58:25 step 4: objective=73.528970 reg=0.003535
2017/08/30 06:58:27 step 5: objective=73.565915 reg=0.003535
2017/08/30 06:58:29 step 6: objective=73.604551 reg=0.003534
2017/08/30 06:58:31 step 7: objective=73.631528 reg=0.003534
2017/08/30 06:58:31 Training value function...
2017/08/30 06:58:34 step 0: mse=204562.655470 step=0.050000
2017/08/30 06:58:35 step 1: mse=204135.566197 step=0.050000
2017/08/30 06:58:37 step 2: mse=203200.375361 step=0.050000
2017/08/30 06:58:38 step 3: mse=201901.456809 step=0.050000
2017/08/30 06:58:39 step 4: mse=199633.971178 step=0.050000
2017/08/30 06:58:40 step 5: mse=197860.503985 step=0.050000
2017/08/30 06:58:42 step 6: mse=197208.615492 step=0.050000
2017/08/30 06:58:43 step 7: mse=195792.143640 step=0.050000
2017/08/30 06:58:43 Saving...
2017/08/30 06:58:43 Gathering batch of experience...
2017/08/30 06:59:15 batch 837: mean=14013.750000 stddev=9406.253355 entropy=0.354106 frames=7071 count=20
2017/08/30 06:59:15 Training policy...
2017/08/30 06:59:21 tune 0: objective=77.806437 reg=0.003541 prune=0
2017/08/30 06:59:23 step 0: objective=77.885023 reg=0.003541
2017/08/30 06:59:25 step 1: objective=77.964662 reg=0.003541
2017/08/30 06:59:27 step 2: objective=78.019057 reg=0.003541
2017/08/30 06:59:29 step 3: objective=78.080744 reg=0.003541
2017/08/30 06:59:30 step 4: objective=78.116135 reg=0.003541
2017/08/30 06:59:32 step 5: objective=78.165597 reg=0.003540
2017/08/30 06:59:34 step 6: objective=78.218092 reg=0.003541
2017/08/30 06:59:36 step 7: objective=78.264885 reg=0.003540
2017/08/30 06:59:36 Training value function...
2017/08/30 06:59:39 step 0: mse=215482.819476 step=0.050000
2017/08/30 06:59:40 step 1: mse=214459.625189 step=0.050000
2017/08/30 06:59:41 step 2: mse=215441.919330 step=0.050000
2017/08/30 06:59:42 step 3: mse=217540.341180 step=0.050000
2017/08/30 06:59:44 step 4: mse=215730.607617 step=0.050000
2017/08/30 06:59:45 step 5: mse=216193.518747 step=0.050000
2017/08/30 06:59:46 step 6: mse=216687.172685 step=0.050000
2017/08/30 06:59:47 step 7: mse=215998.422273 step=0.050000
2017/08/30 06:59:47 Saving...
2017/08/30 06:59:47 Gathering batch of experience...
2017/08/30 07:00:23 batch 838: mean=11024.230769 stddev=9842.795461 entropy=0.354674 frames=7796 count=26
2017/08/30 07:00:23 Training policy...
2017/08/30 07:00:30 tune 0: objective=66.492396 reg=0.003547 prune=0
2017/08/30 07:00:32 step 0: objective=66.559582 reg=0.003546
2017/08/30 07:00:34 step 1: objective=66.640505 reg=0.003547
2017/08/30 07:00:36 step 2: objective=66.694395 reg=0.003546
2017/08/30 07:00:38 step 3: objective=66.727517 reg=0.003546
2017/08/30 07:00:40 step 4: objective=66.779703 reg=0.003545
2017/08/30 07:00:42 step 5: objective=66.821884 reg=0.003544
2017/08/30 07:00:44 step 6: objective=66.867817 reg=0.003544
2017/08/30 07:00:46 step 7: objective=66.913790 reg=0.003544
2017/08/30 07:00:46 Training value function...
2017/08/30 07:00:49 step 0: mse=181744.335456 step=0.050000
2017/08/30 07:00:50 step 1: mse=181367.043217 step=0.050000
2017/08/30 07:00:52 step 2: mse=181816.339753 step=0.050000
2017/08/30 07:00:53 step 3: mse=182719.985120 step=0.050000
2017/08/30 07:00:54 step 4: mse=184773.191234 step=0.050000
2017/08/30 07:00:56 step 5: mse=185103.124603 step=0.050000
2017/08/30 07:00:57 step 6: mse=186853.878464 step=0.050000
2017/08/30 07:00:58 step 7: mse=186886.452137 step=0.050000
2017/08/30 07:00:58 Saving...
2017/08/30 07:00:58 Gathering batch of experience...
2017/08/30 07:01:32 batch 839: mean=10582.000000 stddev=9945.382144 entropy=0.356729 frames=7286 count=25
2017/08/30 07:01:32 Training policy...
2017/08/30 07:01:38 tune 0: objective=68.588779 reg=0.003567 prune=0
2017/08/30 07:01:40 step 0: objective=68.657833 reg=0.003566
2017/08/30 07:01:42 step 1: objective=68.701997 reg=0.003566
2017/08/30 07:01:44 step 2: objective=68.736228 reg=0.003565
2017/08/30 07:01:46 step 3: objective=68.766097 reg=0.003564
2017/08/30 07:01:48 step 4: objective=68.799384 reg=0.003564
2017/08/30 07:01:50 step 5: objective=68.831724 reg=0.003564
2017/08/30 07:01:52 step 6: objective=68.857188 reg=0.003563
2017/08/30 07:01:53 step 7: objective=68.881760 reg=0.003563
2017/08/30 07:01:53 Training value function...
2017/08/30 07:01:56 step 0: mse=198448.890961 step=0.050000
2017/08/30 07:01:58 step 1: mse=198404.581154 step=0.050000
2017/08/30 07:01:59 step 2: mse=200070.557588 step=0.050000
2017/08/30 07:02:00 step 3: mse=200182.966429 step=0.050000
2017/08/30 07:02:01 step 4: mse=196545.258784 step=0.050000
2017/08/30 07:02:02 step 5: mse=194498.002096 step=0.050000
2017/08/30 07:02:04 step 6: mse=194425.886088 step=0.050000
2017/08/30 07:02:05 step 7: mse=194147.352214 step=0.050000
2017/08/30 07:02:05 Saving...
2017/08/30 07:02:05 Gathering batch of experience...
2017/08/30 07:02:40 batch 840: mean=7712.096774 stddev=9366.582223 entropy=0.355857 frames=7341 count=31
2017/08/30 07:02:40 Training policy...
2017/08/30 07:02:46 tune 0: objective=51.986361 reg=0.003559 prune=0
2017/08/30 07:02:48 step 0: objective=52.101025 reg=0.003557
2017/08/30 07:02:50 step 1: objective=52.210602 reg=0.003557
2017/08/30 07:02:52 step 2: objective=52.272600 reg=0.003557
2017/08/30 07:02:54 step 3: objective=52.312270 reg=0.003557
2017/08/30 07:02:55 step 4: objective=52.342320 reg=0.003556
2017/08/30 07:02:57 step 5: objective=52.379538 reg=0.003556
2017/08/30 07:02:59 step 6: objective=52.410609 reg=0.003555
2017/08/30 07:03:01 step 7: objective=52.448483 reg=0.003555
2017/08/30 07:03:01 Training value function...
2017/08/30 07:03:04 step 0: mse=214100.267035 step=0.050000
2017/08/30 07:03:05 step 1: mse=210650.741810 step=0.050000
2017/08/30 07:03:07 step 2: mse=208670.950865 step=0.050000
2017/08/30 07:03:08 step 3: mse=205316.483718 step=0.050000
2017/08/30 07:03:09 step 4: mse=206830.363092 step=0.050000
2017/08/30 07:03:10 step 5: mse=207229.689834 step=0.050000
2017/08/30 07:03:11 step 6: mse=206799.057304 step=0.050000
2017/08/30 07:03:13 step 7: mse=204040.547174 step=0.050000
2017/08/30 07:03:13 Saving...
2017/08/30 07:03:13 Gathering batch of experience...
2017/08/30 07:03:44 batch 841: mean=13636.750000 stddev=9780.418610 entropy=0.355168 frames=6916 count=20
2017/08/30 07:03:44 Training policy...
2017/08/30 07:03:50 tune 0: objective=83.189985 reg=0.003552 prune=0
2017/08/30 07:03:52 step 0: objective=83.246457 reg=0.003551
2017/08/30 07:03:54 step 1: objective=83.285913 reg=0.003551
2017/08/30 07:03:56 step 2: objective=83.330384 reg=0.003551
2017/08/30 07:03:58 step 3: objective=83.382998 reg=0.003551
2017/08/30 07:03:59 step 4: objective=83.431138 reg=0.003551
2017/08/30 07:04:01 step 5: objective=83.476395 reg=0.003551
2017/08/30 07:04:03 step 6: objective=83.514902 reg=0.003552
2017/08/30 07:04:05 step 7: objective=83.556671 reg=0.003551
2017/08/30 07:04:05 Training value function...
2017/08/30 07:04:08 step 0: mse=220387.120649 step=0.050000
2017/08/30 07:04:09 step 1: mse=220908.536701 step=0.050000
2017/08/30 07:04:10 step 2: mse=220541.530356 step=0.050000
2017/08/30 07:04:11 step 3: mse=221221.155836 step=0.050000
2017/08/30 07:04:12 step 4: mse=217189.672091 step=0.050000
2017/08/30 07:04:13 step 5: mse=216760.068579 step=0.050000
2017/08/30 07:04:14 step 6: mse=217249.546711 step=0.050000
2017/08/30 07:04:16 step 7: mse=213424.131851 step=0.050000
2017/08/30 07:04:16 Saving...
2017/08/30 07:04:16 Gathering batch of experience...
2017/08/30 07:04:50 batch 842: mean=12730.000000 stddev=9922.515947 entropy=0.354582 frames=7228 count=22
2017/08/30 07:04:50 Training policy...
2017/08/30 07:04:56 tune 0: objective=85.960985 reg=0.003546 prune=0
2017/08/30 07:04:58 step 0: objective=86.007229 reg=0.003546
2017/08/30 07:04:59 step 1: objective=86.048570 reg=0.003546
2017/08/30 07:05:01 step 2: objective=86.092937 reg=0.003546
2017/08/30 07:05:03 step 3: objective=86.136085 reg=0.003547
2017/08/30 07:05:05 step 4: objective=86.174875 reg=0.003547
2017/08/30 07:05:07 step 5: objective=86.212887 reg=0.003547
2017/08/30 07:05:09 step 6: objective=86.231937 reg=0.003547
2017/08/30 07:05:11 step 7: objective=86.269265 reg=0.003548
2017/08/30 07:05:11 Training value function...
2017/08/30 07:05:14 step 0: mse=228769.733703 step=0.050000
2017/08/30 07:05:15 step 1: mse=228558.540975 step=0.050000
2017/08/30 07:05:16 step 2: mse=226251.188091 step=0.050000
2017/08/30 07:05:17 step 3: mse=226141.453987 step=0.050000
2017/08/30 07:05:19 step 4: mse=225376.472081 step=0.050000
2017/08/30 07:05:20 step 5: mse=224957.482654 step=0.050000
2017/08/30 07:05:21 step 6: mse=223081.961750 step=0.050000
2017/08/30 07:05:22 step 7: mse=223512.399194 step=0.050000
2017/08/30 07:05:22 Saving...
2017/08/30 07:05:22 Gathering batch of experience...
2017/08/30 07:05:55 batch 843: mean=10469.166667 stddev=9799.974561 entropy=0.354235 frames=7014 count=24
2017/08/30 07:05:55 Training policy...
2017/08/30 07:06:01 tune 0: objective=63.424989 reg=0.003542 prune=0
2017/08/30 07:06:03 step 0: objective=63.513402 reg=0.003542
2017/08/30 07:06:05 step 1: objective=63.600135 reg=0.003543
2017/08/30 07:06:06 step 2: objective=63.670480 reg=0.003543
2017/08/30 07:06:08 step 3: objective=63.719017 reg=0.003542
2017/08/30 07:06:10 step 4: objective=63.765981 reg=0.003542
2017/08/30 07:06:12 step 5: objective=63.800805 reg=0.003541
2017/08/30 07:06:14 step 6: objective=63.822649 reg=0.003541
2017/08/30 07:06:15 step 7: objective=63.849413 reg=0.003540
2017/08/30 07:06:15 Training value function...
2017/08/30 07:06:18 step 0: mse=197051.114809 step=0.050000
2017/08/30 07:06:20 step 1: mse=198097.383157 step=0.050000
2017/08/30 07:06:21 step 2: mse=199393.856328 step=0.050000
2017/08/30 07:06:22 step 3: mse=200106.801095 step=0.050000
2017/08/30 07:06:23 step 4: mse=200651.086506 step=0.050000
2017/08/30 07:06:24 step 5: mse=199184.927058 step=0.050000
2017/08/30 07:06:25 step 6: mse=197538.959548 step=0.050000
2017/08/30 07:06:26 step 7: mse=198782.709955 step=0.050000
2017/08/30 07:06:26 Saving...
2017/08/30 07:06:26 Gathering batch of experience...
2017/08/30 07:06:58 batch 844: mean=10648.636364 stddev=9730.031321 entropy=0.348862 frames=6501 count=22
2017/08/30 07:06:58 Training policy...
2017/08/30 07:07:03 tune 0: objective=72.908990 reg=0.003489 prune=0
2017/08/30 07:07:05 step 0: objective=72.964635 reg=0.003488
2017/08/30 07:07:07 step 1: objective=73.019843 reg=0.003488
2017/08/30 07:07:08 step 2: objective=73.072796 reg=0.003488
2017/08/30 07:07:10 step 3: objective=73.130922 reg=0.003486
2017/08/30 07:07:12 step 4: objective=73.184996 reg=0.003486
2017/08/30 07:07:13 step 5: objective=73.235065 reg=0.003486
2017/08/30 07:07:15 step 6: objective=73.280923 reg=0.003487
2017/08/30 07:07:17 step 7: objective=73.331204 reg=0.003485
2017/08/30 07:07:17 Training value function...
2017/08/30 07:07:20 step 0: mse=268078.248985 step=0.050000
2017/08/30 07:07:21 step 1: mse=265915.977338 step=0.050000
2017/08/30 07:07:22 step 2: mse=260572.808430 step=0.050000
2017/08/30 07:07:23 step 3: mse=255590.693426 step=0.050000
2017/08/30 07:07:24 step 4: mse=254617.508036 step=0.050000
2017/08/30 07:07:25 step 5: mse=249894.026413 step=0.050000
2017/08/30 07:07:26 step 6: mse=246242.418884 step=0.050000
2017/08/30 07:07:27 step 7: mse=242346.255595 step=0.050000
2017/08/30 07:07:27 Saving...
2017/08/30 07:07:27 Gathering batch of experience...
2017/08/30 07:07:57 batch 845: mean=9881.086957 stddev=9721.145370 entropy=0.357626 frames=6417 count=23
2017/08/30 07:07:57 Training policy...
2017/08/30 07:08:03 tune 0: objective=63.499055 reg=0.003576 prune=0
2017/08/30 07:08:05 step 0: objective=63.661164 reg=0.003575
2017/08/30 07:08:06 step 1: objective=63.725621 reg=0.003576
2017/08/30 07:08:08 step 2: objective=63.797194 reg=0.003577
2017/08/30 07:08:10 step 3: objective=63.876091 reg=0.003578
2017/08/30 07:08:11 step 4: objective=63.952329 reg=0.003579
2017/08/30 07:08:13 step 5: objective=63.997507 reg=0.003579
2017/08/30 07:08:15 step 6: objective=64.040191 reg=0.003579
2017/08/30 07:08:16 step 7: objective=64.078897 reg=0.003578
2017/08/30 07:08:16 Training value function...
2017/08/30 07:08:19 step 0: mse=194635.411465 step=0.050000
2017/08/30 07:08:20 step 1: mse=194157.976893 step=0.050000
2017/08/30 07:08:21 step 2: mse=193494.753055 step=0.050000
2017/08/30 07:08:22 step 3: mse=192775.929862 step=0.050000
2017/08/30 07:08:23 step 4: mse=193323.860202 step=0.050000
2017/08/30 07:08:24 step 5: mse=194454.850875 step=0.050000
2017/08/30 07:08:25 step 6: mse=194087.648846 step=0.050000
2017/08/30 07:08:26 step 7: mse=194464.608790 step=0.050000
2017/08/30 07:08:26 Saving...
2017/08/30 07:08:27 Gathering batch of experience...
2017/08/30 07:09:01 batch 846: mean=12811.956522 stddev=9926.174855 entropy=0.357904 frames=7549 count=23
2017/08/30 07:09:01 Training policy...
2017/08/30 07:09:07 tune 0: objective=80.590451 reg=0.003579 prune=0
2017/08/30 07:09:09 step 0: objective=80.638744 reg=0.003579
2017/08/30 07:09:11 step 1: objective=80.680214 reg=0.003579
2017/08/30 07:09:13 step 2: objective=80.712512 reg=0.003579
2017/08/30 07:09:15 step 3: objective=80.745322 reg=0.003579
2017/08/30 07:09:17 step 4: objective=80.776386 reg=0.003579
2017/08/30 07:09:19 step 5: objective=80.818337 reg=0.003580
2017/08/30 07:09:21 step 6: objective=80.879189 reg=0.003579
2017/08/30 07:09:23 step 7: objective=80.924353 reg=0.003580
2017/08/30 07:09:23 Training value function...
2017/08/30 07:09:26 step 0: mse=198988.367178 step=0.050000
2017/08/30 07:09:27 step 1: mse=197597.124371 step=0.050000
2017/08/30 07:09:29 step 2: mse=196990.822021 step=0.050000
2017/08/30 07:09:30 step 3: mse=195849.565588 step=0.050000
2017/08/30 07:09:31 step 4: mse=192845.120275 step=0.050000
2017/08/30 07:09:32 step 5: mse=192255.738632 step=0.050000
2017/08/30 07:09:34 step 6: mse=191098.435522 step=0.050000
2017/08/30 07:09:35 step 7: mse=190230.781230 step=0.050000
2017/08/30 07:09:35 Saving...
2017/08/30 07:09:35 Gathering batch of experience...
2017/08/30 07:10:09 batch 847: mean=8922.500000 stddev=9518.556497 entropy=0.351242 frames=6825 count=26
2017/08/30 07:10:09 Training policy...
2017/08/30 07:10:14 tune 0: objective=53.280114 reg=0.003512 prune=0
2017/08/30 07:10:16 step 0: objective=53.390801 reg=0.003511
2017/08/30 07:10:18 step 1: objective=53.470092 reg=0.003509
2017/08/30 07:10:20 step 2: objective=53.539533 reg=0.003508
2017/08/30 07:10:22 step 3: objective=53.603228 reg=0.003508
2017/08/30 07:10:23 step 4: objective=53.645220 reg=0.003507
2017/08/30 07:10:25 step 5: objective=53.693942 reg=0.003505
2017/08/30 07:10:27 step 6: objective=53.737669 reg=0.003505
2017/08/30 07:10:29 step 7: objective=53.765815 reg=0.003505
2017/08/30 07:10:29 Training value function...
2017/08/30 07:10:32 step 0: mse=178772.255662 step=0.050000
2017/08/30 07:10:33 step 1: mse=178849.999807 step=0.050000
2017/08/30 07:10:34 step 2: mse=180335.829188 step=0.050000
2017/08/30 07:10:35 step 3: mse=180570.798034 step=0.050000
2017/08/30 07:10:36 step 4: mse=182256.463016 step=0.050000
2017/08/30 07:10:37 step 5: mse=181091.180461 step=0.050000
2017/08/30 07:10:38 step 6: mse=182529.356562 step=0.050000
2017/08/30 07:10:39 step 7: mse=184273.990894 step=0.050000
2017/08/30 07:10:39 Saving...
2017/08/30 07:10:39 Gathering batch of experience...
2017/08/30 07:11:12 batch 848: mean=13608.333333 stddev=9864.070846 entropy=0.352719 frames=7391 count=21
2017/08/30 07:11:12 Training policy...
2017/08/30 07:11:19 tune 0: objective=95.522384 reg=0.003527 prune=0
2017/08/30 07:11:21 step 0: objective=95.595378 reg=0.003527
2017/08/30 07:11:23 step 1: objective=95.670520 reg=0.003527
2017/08/30 07:11:24 step 2: objective=95.740893 reg=0.003527
2017/08/30 07:11:26 step 3: objective=95.811096 reg=0.003528
2017/08/30 07:11:28 step 4: objective=95.848380 reg=0.003527
2017/08/30 07:11:30 step 5: objective=95.904242 reg=0.003527
2017/08/30 07:11:32 step 6: objective=95.936798 reg=0.003527
2017/08/30 07:11:34 step 7: objective=95.969617 reg=0.003527
2017/08/30 07:11:34 Training value function...
2017/08/30 07:11:37 step 0: mse=269681.688083 step=0.050000
2017/08/30 07:11:38 step 1: mse=265348.626540 step=0.050000
2017/08/30 07:11:40 step 2: mse=258753.389341 step=0.050000
2017/08/30 07:11:41 step 3: mse=255683.415146 step=0.050000
2017/08/30 07:11:42 step 4: mse=253361.101816 step=0.050000
2017/08/30 07:11:43 step 5: mse=248439.505078 step=0.050000
2017/08/30 07:11:45 step 6: mse=243207.829833 step=0.050000
2017/08/30 07:11:46 step 7: mse=239694.910167 step=0.050000
2017/08/30 07:11:46 Saving...
2017/08/30 07:11:46 Gathering batch of experience...
2017/08/30 07:12:17 batch 849: mean=9261.400000 stddev=9400.528977 entropy=0.348453 frames=6688 count=25
2017/08/30 07:12:17 Training policy...
2017/08/30 07:12:22 tune 0: objective=50.750388 reg=0.003485 prune=0
2017/08/30 07:12:24 step 0: objective=50.830882 reg=0.003483
2017/08/30 07:12:26 step 1: objective=50.898933 reg=0.003482
2017/08/30 07:12:28 step 2: objective=50.942406 reg=0.003481
2017/08/30 07:12:29 step 3: objective=50.976988 reg=0.003481
2017/08/30 07:12:31 step 4: objective=50.999196 reg=0.003481
2017/08/30 07:12:33 step 5: objective=51.038464 reg=0.003480
2017/08/30 07:12:35 step 6: objective=51.074518 reg=0.003479
2017/08/30 07:12:36 step 7: objective=51.104324 reg=0.003478
2017/08/30 07:12:36 Training value function...
2017/08/30 07:12:39 step 0: mse=180320.885827 step=0.050000
2017/08/30 07:12:40 step 1: mse=180273.383041 step=0.050000
2017/08/30 07:12:41 step 2: mse=181058.174973 step=0.050000
2017/08/30 07:12:42 step 3: mse=181998.100312 step=0.050000
2017/08/30 07:12:44 step 4: mse=182658.871364 step=0.050000
2017/08/30 07:12:45 step 5: mse=183693.159851 step=0.050000
2017/08/30 07:12:46 step 6: mse=184031.391922 step=0.050000
2017/08/30 07:12:47 step 7: mse=184741.366064 step=0.050000
2017/08/30 07:12:47 Saving...
2017/08/30 07:12:47 Gathering batch of experience...
2017/08/30 07:13:18 batch 850: mean=10566.956522 stddev=10226.837534 entropy=0.351165 frames=6691 count=23
2017/08/30 07:13:18 Training policy...
2017/08/30 07:13:24 tune 0: objective=81.699578 reg=0.003512 prune=0
2017/08/30 07:13:26 step 0: objective=81.763563 reg=0.003511
2017/08/30 07:13:28 step 1: objective=81.801244 reg=0.003511
2017/08/30 07:13:29 step 2: objective=81.842391 reg=0.003511
2017/08/30 07:13:31 step 3: objective=81.882585 reg=0.003511
2017/08/30 07:13:33 step 4: objective=81.912653 reg=0.003511
2017/08/30 07:13:35 step 5: objective=81.937388 reg=0.003511
2017/08/30 07:13:36 step 6: objective=81.971071 reg=0.003511
2017/08/30 07:13:38 step 7: objective=82.004082 reg=0.003511
2017/08/30 07:13:38 Training value function...
2017/08/30 07:13:41 step 0: mse=213316.643442 step=0.050000
2017/08/30 07:13:42 step 1: mse=210594.025306 step=0.050000
2017/08/30 07:13:43 step 2: mse=209071.496460 step=0.050000
2017/08/30 07:13:44 step 3: mse=207311.985983 step=0.050000
2017/08/30 07:13:45 step 4: mse=204118.942430 step=0.050000
2017/08/30 07:13:46 step 5: mse=203850.668058 step=0.050000
2017/08/30 07:13:47 step 6: mse=202158.542444 step=0.050000
2017/08/30 07:13:49 step 7: mse=201568.864061 step=0.050000
2017/08/30 07:13:49 Saving...
2017/08/30 07:13:49 Gathering batch of experience...
2017/08/30 07:14:19 batch 851: mean=10232.500000 stddev=9951.642481 entropy=0.348117 frames=6299 count=22
2017/08/30 07:14:19 Training policy...
2017/08/30 07:14:24 tune 0: objective=68.527906 reg=0.003481 prune=0
2017/08/30 07:14:26 step 0: objective=68.592594 reg=0.003481
2017/08/30 07:14:27 step 1: objective=68.653189 reg=0.003481
2017/08/30 07:14:29 step 2: objective=68.702463 reg=0.003480
2017/08/30 07:14:31 step 3: objective=68.741536 reg=0.003480
2017/08/30 07:14:32 step 4: objective=68.800320 reg=0.003480
2017/08/30 07:14:34 step 5: objective=68.838888 reg=0.003480
2017/08/30 07:14:36 step 6: objective=68.870828 reg=0.003479
2017/08/30 07:14:37 step 7: objective=68.901527 reg=0.003479
2017/08/30 07:14:37 Training value function...
2017/08/30 07:14:40 step 0: mse=173866.668115 step=0.050000
2017/08/30 07:14:41 step 1: mse=174009.083646 step=0.050000
2017/08/30 07:14:42 step 2: mse=174919.487849 step=0.050000
2017/08/30 07:14:43 step 3: mse=175026.263891 step=0.050000
2017/08/30 07:14:44 step 4: mse=174898.835720 step=0.050000
2017/08/30 07:14:45 step 5: mse=175845.437397 step=0.050000
2017/08/30 07:14:46 step 6: mse=176031.032070 step=0.050000
2017/08/30 07:14:47 step 7: mse=175943.813890 step=0.050000
2017/08/30 07:14:47 Saving...
2017/08/30 07:14:47 Gathering batch of experience...
2017/08/30 07:15:23 batch 852: mean=10278.269231 stddev=9823.142312 entropy=0.355005 frames=7525 count=26
2017/08/30 07:15:23 Training policy...
2017/08/30 07:15:29 tune 0: objective=57.508738 reg=0.003550 prune=0
2017/08/30 07:15:31 step 0: objective=57.574983 reg=0.003550
2017/08/30 07:15:33 step 1: objective=57.634581 reg=0.003550
2017/08/30 07:15:35 step 2: objective=57.689236 reg=0.003550
2017/08/30 07:15:37 step 3: objective=57.762056 reg=0.003550
2017/08/30 07:15:39 step 4: objective=57.789967 reg=0.003550
2017/08/30 07:15:41 step 5: objective=57.836794 reg=0.003549
2017/08/30 07:15:43 step 6: objective=57.870299 reg=0.003549
2017/08/30 07:15:45 step 7: objective=57.886744 reg=0.003549
2017/08/30 07:15:45 Training value function...
2017/08/30 07:15:48 step 0: mse=184003.164040 step=0.050000
2017/08/30 07:15:50 step 1: mse=186110.724197 step=0.050000
2017/08/30 07:15:51 step 2: mse=187274.186964 step=0.050000
2017/08/30 07:15:52 step 3: mse=188012.206932 step=0.050000
2017/08/30 07:15:53 step 4: mse=188374.535728 step=0.050000
2017/08/30 07:15:55 step 5: mse=189582.561737 step=0.050000
2017/08/30 07:15:56 step 6: mse=190131.798686 step=0.050000
2017/08/30 07:15:57 step 7: mse=190492.249589 step=0.050000
2017/08/30 07:15:57 Saving...
2017/08/30 07:15:57 Gathering batch of experience...
2017/08/30 07:16:28 batch 853: mean=9975.000000 stddev=9726.520000 entropy=0.354394 frames=6521 count=23
2017/08/30 07:16:28 Training policy...
2017/08/30 07:16:34 tune 0: objective=58.683360 reg=0.003544 prune=0
2017/08/30 07:16:36 step 0: objective=58.817072 reg=0.003544
2017/08/30 07:16:37 step 1: objective=58.953204 reg=0.003545
2017/08/30 07:16:39 step 2: objective=59.055312 reg=0.003544
2017/08/30 07:16:41 step 3: objective=59.128719 reg=0.003545
2017/08/30 07:16:43 step 4: objective=59.176099 reg=0.003545
2017/08/30 07:16:44 step 5: objective=59.220638 reg=0.003546
2017/08/30 07:16:46 step 6: objective=59.246377 reg=0.003547
2017/08/30 07:16:48 step 7: objective=59.296374 reg=0.003547
2017/08/30 07:16:48 Training value function...
2017/08/30 07:16:51 step 0: mse=195397.934846 step=0.050000
2017/08/30 07:16:52 step 1: mse=195969.996711 step=0.050000
2017/08/30 07:16:53 step 2: mse=196641.024761 step=0.050000
2017/08/30 07:16:54 step 3: mse=196836.735290 step=0.050000
2017/08/30 07:16:55 step 4: mse=198821.539764 step=0.050000
2017/08/30 07:16:56 step 5: mse=199522.724757 step=0.050000
2017/08/30 07:16:57 step 6: mse=199334.075570 step=0.050000
2017/08/30 07:16:58 step 7: mse=199942.433649 step=0.050000
2017/08/30 07:16:58 Saving...
2017/08/30 07:16:58 Gathering batch of experience...
2017/08/30 07:17:29 batch 854: mean=12174.761905 stddev=10342.751255 entropy=0.352248 frames=6620 count=21
2017/08/30 07:17:29 Training policy...
2017/08/30 07:17:35 tune 0: objective=89.153597 reg=0.003522 prune=0
2017/08/30 07:17:36 step 0: objective=89.200463 reg=0.003523
2017/08/30 07:17:38 step 1: objective=89.243750 reg=0.003522
2017/08/30 07:17:40 step 2: objective=89.286225 reg=0.003522
2017/08/30 07:17:42 step 3: objective=89.326256 reg=0.003522
2017/08/30 07:17:43 step 4: objective=89.365587 reg=0.003522
2017/08/30 07:17:45 step 5: objective=89.394911 reg=0.003522
2017/08/30 07:17:47 step 6: objective=89.427020 reg=0.003522
2017/08/30 07:17:49 step 7: objective=89.461254 reg=0.003522
2017/08/30 07:17:49 Training value function...
2017/08/30 07:17:51 step 0: mse=195670.716527 step=0.050000
2017/08/30 07:17:52 step 1: mse=193832.550542 step=0.050000
2017/08/30 07:17:53 step 2: mse=191611.509054 step=0.050000
2017/08/30 07:17:55 step 3: mse=190052.696542 step=0.050000
2017/08/30 07:17:56 step 4: mse=189070.408091 step=0.050000
2017/08/30 07:17:57 step 5: mse=189645.202133 step=0.050000
2017/08/30 07:17:58 step 6: mse=187983.663111 step=0.050000
2017/08/30 07:17:59 step 7: mse=185678.479918 step=0.050000
2017/08/30 07:17:59 Saving...
2017/08/30 07:17:59 Gathering batch of experience...
2017/08/30 07:18:28 batch 855: mean=10034.761905 stddev=9673.979025 entropy=0.350624 frames=6079 count=21
2017/08/30 07:18:28 Training policy...
2017/08/30 07:18:33 tune 0: objective=61.022079 reg=0.003506 prune=0
2017/08/30 07:18:35 step 0: objective=61.153053 reg=0.003505
2017/08/30 07:18:36 step 1: objective=61.236758 reg=0.003504
2017/08/30 07:18:38 step 2: objective=61.276649 reg=0.003504
2017/08/30 07:18:40 step 3: objective=61.308156 reg=0.003504
2017/08/30 07:18:41 step 4: objective=61.339067 reg=0.003504
2017/08/30 07:18:43 step 5: objective=61.384788 reg=0.003504
2017/08/30 07:18:45 step 6: objective=61.422073 reg=0.003505
2017/08/30 07:18:46 step 7: objective=61.463142 reg=0.003505
2017/08/30 07:18:46 Training value function...
2017/08/30 07:18:49 step 0: mse=214379.995620 step=0.050000
2017/08/30 07:18:50 step 1: mse=214761.880703 step=0.050000
2017/08/30 07:18:51 step 2: mse=215323.702256 step=0.050000
2017/08/30 07:18:52 step 3: mse=216820.424556 step=0.050000
2017/08/30 07:18:53 step 4: mse=213595.560157 step=0.050000
2017/08/30 07:18:54 step 5: mse=210832.624987 step=0.050000
2017/08/30 07:18:55 step 6: mse=211771.863997 step=0.050000
2017/08/30 07:18:56 step 7: mse=212897.555693 step=0.050000
2017/08/30 07:18:56 Saving...
2017/08/30 07:18:56 Gathering batch of experience...
2017/08/30 07:19:31 batch 856: mean=12826.666667 stddev=10051.157444 entropy=0.351172 frames=7826 count=24
2017/08/30 07:19:31 Training policy...
2017/08/30 07:19:38 tune 0: objective=87.684274 reg=0.003512 prune=0
2017/08/30 07:19:40 step 0: objective=87.765940 reg=0.003511
2017/08/30 07:19:42 step 1: objective=87.826540 reg=0.003512
2017/08/30 07:19:44 step 2: objective=87.892538 reg=0.003512
2017/08/30 07:19:46 step 3: objective=88.002604 reg=0.003512
2017/08/30 07:19:48 step 4: objective=88.035954 reg=0.003512
2017/08/30 07:19:50 step 5: objective=88.085987 reg=0.003512
2017/08/30 07:19:52 step 6: objective=88.139160 reg=0.003511
2017/08/30 07:19:54 step 7: objective=88.161010 reg=0.003511
2017/08/30 07:19:54 Training value function...
2017/08/30 07:19:58 step 0: mse=263007.575353 step=0.050000
2017/08/30 07:19:59 step 1: mse=258716.874743 step=0.050000
2017/08/30 07:20:00 step 2: mse=259333.253442 step=0.050000
2017/08/30 07:20:01 step 3: mse=257943.558267 step=0.050000
2017/08/30 07:20:03 step 4: mse=255601.533407 step=0.050000
2017/08/30 07:20:04 step 5: mse=255852.733724 step=0.050000
2017/08/30 07:20:05 step 6: mse=256885.775754 step=0.050000
2017/08/30 07:20:07 step 7: mse=255153.426178 step=0.050000
2017/08/30 07:20:07 Saving...
2017/08/30 07:20:07 Gathering batch of experience...
2017/08/30 07:20:41 batch 857: mean=10423.461538 stddev=9797.346459 entropy=0.350186 frames=7460 count=26
2017/08/30 07:20:41 Training policy...
2017/08/30 07:20:47 tune 0: objective=65.732758 reg=0.003502 prune=0
2017/08/30 07:20:49 step 0: objective=65.810477 reg=0.003502
2017/08/30 07:20:51 step 1: objective=65.861197 reg=0.003502
2017/08/30 07:20:53 step 2: objective=65.912684 reg=0.003502
2017/08/30 07:20:55 step 3: objective=65.984538 reg=0.003502
2017/08/30 07:20:57 step 4: objective=66.028314 reg=0.003502
2017/08/30 07:20:59 step 5: objective=66.067862 reg=0.003502
2017/08/30 07:21:01 step 6: objective=66.119651 reg=0.003502
2017/08/30 07:21:03 step 7: objective=66.139699 reg=0.003501
2017/08/30 07:21:03 Training value function...
2017/08/30 07:21:06 step 0: mse=203297.617340 step=0.050000
2017/08/30 07:21:08 step 1: mse=203101.904905 step=0.050000
2017/08/30 07:21:09 step 2: mse=202992.055762 step=0.050000
2017/08/30 07:21:10 step 3: mse=202839.423075 step=0.050000
2017/08/30 07:21:11 step 4: mse=203852.329056 step=0.050000
2017/08/30 07:21:12 step 5: mse=204147.780127 step=0.050000
2017/08/30 07:21:14 step 6: mse=204851.091425 step=0.050000
2017/08/30 07:21:15 step 7: mse=204691.128555 step=0.050000
2017/08/30 07:21:15 Saving...
2017/08/30 07:21:15 Gathering batch of experience...
2017/08/30 07:21:48 batch 858: mean=11667.083333 stddev=10303.259690 entropy=0.356983 frames=7372 count=24
2017/08/30 07:21:48 Training policy...
2017/08/30 07:21:55 tune 0: objective=78.855874 reg=0.003570 prune=0
2017/08/30 07:21:57 step 0: objective=78.921527 reg=0.003570
2017/08/30 07:21:59 step 1: objective=78.997160 reg=0.003570
2017/08/30 07:22:01 step 2: objective=79.056794 reg=0.003569
2017/08/30 07:22:03 step 3: objective=79.136047 reg=0.003569
2017/08/30 07:22:05 step 4: objective=79.165686 reg=0.003569
2017/08/30 07:22:07 step 5: objective=79.219555 reg=0.003569
2017/08/30 07:22:09 step 6: objective=79.270424 reg=0.003568
2017/08/30 07:22:11 step 7: objective=79.307430 reg=0.003568
2017/08/30 07:22:11 Training value function...
2017/08/30 07:22:14 step 0: mse=218739.920751 step=0.050000
2017/08/30 07:22:15 step 1: mse=216791.777767 step=0.050000
2017/08/30 07:22:16 step 2: mse=216004.443586 step=0.050000
2017/08/30 07:22:17 step 3: mse=216040.977078 step=0.050000
2017/08/30 07:22:18 step 4: mse=215808.180811 step=0.050000
2017/08/30 07:22:20 step 5: mse=211836.653228 step=0.050000
2017/08/30 07:22:21 step 6: mse=211913.457533 step=0.050000
2017/08/30 07:22:22 step 7: mse=211713.387537 step=0.050000
2017/08/30 07:22:22 Saving...
2017/08/30 07:22:22 Gathering batch of experience...
2017/08/30 07:22:54 batch 859: mean=10832.083333 stddev=10224.423875 entropy=0.350511 frames=6815 count=24
2017/08/30 07:22:54 Training policy...
2017/08/30 07:23:00 tune 0: objective=73.672771 reg=0.003505 prune=0
2017/08/30 07:23:02 step 0: objective=73.735189 reg=0.003505
2017/08/30 07:23:04 step 1: objective=73.800527 reg=0.003504
2017/08/30 07:23:05 step 2: objective=73.857172 reg=0.003503
2017/08/30 07:23:07 step 3: objective=73.888243 reg=0.003502
2017/08/30 07:23:09 step 4: objective=73.923840 reg=0.003502
2017/08/30 07:23:11 step 5: objective=73.954150 reg=0.003502
2017/08/30 07:23:13 step 6: objective=73.998533 reg=0.003502
2017/08/30 07:23:14 step 7: objective=74.037876 reg=0.003502
2017/08/30 07:23:14 Training value function...
2017/08/30 07:23:17 step 0: mse=222009.322577 step=0.050000
2017/08/30 07:23:18 step 1: mse=221690.460467 step=0.050000
2017/08/30 07:23:19 step 2: mse=220962.524876 step=0.050000
2017/08/30 07:23:21 step 3: mse=219774.315728 step=0.050000
2017/08/30 07:23:22 step 4: mse=220099.181756 step=0.050000
2017/08/30 07:23:23 step 5: mse=218063.460292 step=0.050000
2017/08/30 07:23:24 step 6: mse=218418.482428 step=0.050000
2017/08/30 07:23:25 step 7: mse=218462.237064 step=0.050000
2017/08/30 07:23:25 Saving...
2017/08/30 07:23:25 Gathering batch of experience...
2017/08/30 07:23:59 batch 860: mean=14961.750000 stddev=9871.536389 entropy=0.350799 frames=7419 count=20
2017/08/30 07:23:59 Training policy...
2017/08/30 07:24:05 tune 0: objective=90.599508 reg=0.003508 prune=0
2017/08/30 07:24:07 step 0: objective=90.645875 reg=0.003508
2017/08/30 07:24:09 step 1: objective=90.681224 reg=0.003508
2017/08/30 07:24:11 step 2: objective=90.708409 reg=0.003508
2017/08/30 07:24:13 step 3: objective=90.739739 reg=0.003508
2017/08/30 07:24:15 step 4: objective=90.760488 reg=0.003508
2017/08/30 07:24:17 step 5: objective=90.782442 reg=0.003508
2017/08/30 07:24:19 step 6: objective=90.798482 reg=0.003508
2017/08/30 07:24:21 step 7: objective=90.820815 reg=0.003508
2017/08/30 07:24:21 Training value function...
2017/08/30 07:24:24 step 0: mse=191480.514666 step=0.050000
2017/08/30 07:24:25 step 1: mse=190761.638065 step=0.050000
2017/08/30 07:24:26 step 2: mse=190773.907796 step=0.050000
2017/08/30 07:24:27 step 3: mse=190385.987474 step=0.050000
2017/08/30 07:24:29 step 4: mse=189295.065885 step=0.050000
2017/08/30 07:24:30 step 5: mse=187969.098257 step=0.050000
2017/08/30 07:24:31 step 6: mse=188154.496250 step=0.050000
2017/08/30 07:24:32 step 7: mse=187482.197154 step=0.050000
2017/08/30 07:24:32 Saving...
2017/08/30 07:24:32 Gathering batch of experience...
2017/08/30 07:25:10 batch 861: mean=12327.800000 stddev=10101.833208 entropy=0.351683 frames=8118 count=25
2017/08/30 07:25:10 Training policy...
2017/08/30 07:25:17 tune 0: objective=68.564286 reg=0.003517 prune=0
2017/08/30 07:25:19 step 0: objective=68.627502 reg=0.003516
2017/08/30 07:25:21 step 1: objective=68.678785 reg=0.003515
2017/08/30 07:25:24 step 2: objective=68.716186 reg=0.003515
2017/08/30 07:25:26 step 3: objective=68.755274 reg=0.003514
2017/08/30 07:25:28 step 4: objective=68.783152 reg=0.003514
2017/08/30 07:25:30 step 5: objective=68.803916 reg=0.003514
2017/08/30 07:25:32 step 6: objective=68.837845 reg=0.003514
2017/08/30 07:25:34 step 7: objective=68.852750 reg=0.003514
2017/08/30 07:25:34 Training value function...
2017/08/30 07:25:38 step 0: mse=188218.760954 step=0.050000
2017/08/30 07:25:39 step 1: mse=186139.357775 step=0.050000
2017/08/30 07:25:40 step 2: mse=185782.367219 step=0.050000
2017/08/30 07:25:42 step 3: mse=184657.322581 step=0.050000
2017/08/30 07:25:43 step 4: mse=186840.392088 step=0.050000
2017/08/30 07:25:45 step 5: mse=185823.941615 step=0.050000
2017/08/30 07:25:46 step 6: mse=186296.660635 step=0.050000
2017/08/30 07:25:47 step 7: mse=186910.566536 step=0.050000
2017/08/30 07:25:47 Saving...
2017/08/30 07:25:47 Gathering batch of experience...
2017/08/30 07:26:20 batch 862: mean=13193.571429 stddev=10223.235107 entropy=0.349533 frames=7032 count=21
2017/08/30 07:26:20 Training policy...
2017/08/30 07:26:26 tune 0: objective=80.458938 reg=0.003495 prune=0
2017/08/30 07:26:28 step 0: objective=80.512123 reg=0.003495
2017/08/30 07:26:30 step 1: objective=80.542227 reg=0.003495
2017/08/30 07:26:32 step 2: objective=80.589306 reg=0.003495
2017/08/30 07:26:33 step 3: objective=80.629426 reg=0.003496
2017/08/30 07:26:35 step 4: objective=80.670337 reg=0.003497
2017/08/30 07:26:37 step 5: objective=80.712360 reg=0.003496
2017/08/30 07:26:39 step 6: objective=80.736135 reg=0.003496
2017/08/30 07:26:41 step 7: objective=80.760194 reg=0.003496
2017/08/30 07:26:41 Training value function...
2017/08/30 07:26:44 step 0: mse=188466.182890 step=0.050000
2017/08/30 07:26:45 step 1: mse=187918.559511 step=0.050000
2017/08/30 07:26:46 step 2: mse=188454.264848 step=0.050000
2017/08/30 07:26:47 step 3: mse=185243.392790 step=0.050000
2017/08/30 07:26:48 step 4: mse=184087.958888 step=0.050000
2017/08/30 07:26:50 step 5: mse=182694.344498 step=0.050000
2017/08/30 07:26:51 step 6: mse=182239.877965 step=0.050000
2017/08/30 07:26:52 step 7: mse=181924.287312 step=0.050000
2017/08/30 07:26:52 Saving...
2017/08/30 07:26:52 Gathering batch of experience...
2017/08/30 07:27:23 batch 863: mean=11075.909091 stddev=10072.298379 entropy=0.353346 frames=6604 count=22
2017/08/30 07:27:23 Training policy...
2017/08/30 07:27:28 tune 0: objective=66.053258 reg=0.003533 prune=0
2017/08/30 07:27:30 step 0: objective=66.115380 reg=0.003533
2017/08/30 07:27:32 step 1: objective=66.190817 reg=0.003533
2017/08/30 07:27:34 step 2: objective=66.264527 reg=0.003533
2017/08/30 07:27:35 step 3: objective=66.318571 reg=0.003533
2017/08/30 07:27:37 step 4: objective=66.364471 reg=0.003534
2017/08/30 07:27:39 step 5: objective=66.415496 reg=0.003533
2017/08/30 07:27:41 step 6: objective=66.450338 reg=0.003533
2017/08/30 07:27:42 step 7: objective=66.480007 reg=0.003533
2017/08/30 07:27:42 Training value function...
2017/08/30 07:27:45 step 0: mse=196897.442682 step=0.050000
2017/08/30 07:27:46 step 1: mse=195225.491173 step=0.050000
2017/08/30 07:27:47 step 2: mse=195108.729934 step=0.050000
2017/08/30 07:27:48 step 3: mse=195336.708996 step=0.050000
2017/08/30 07:27:49 step 4: mse=196588.935308 step=0.050000
2017/08/30 07:27:51 step 5: mse=194061.224139 step=0.050000
2017/08/30 07:27:52 step 6: mse=195107.059673 step=0.050000
2017/08/30 07:27:53 step 7: mse=194102.638706 step=0.050000
2017/08/30 07:27:53 Saving...
2017/08/30 07:27:53 Gathering batch of experience...
2017/08/30 07:28:25 batch 864: mean=14481.315789 stddev=9973.218063 entropy=0.349168 frames=6807 count=19
2017/08/30 07:28:25 Training policy...
2017/08/30 07:28:31 tune 0: objective=90.695194 reg=0.003492 prune=0
2017/08/30 07:28:32 step 0: objective=90.763020 reg=0.003491
2017/08/30 07:28:34 step 1: objective=90.829110 reg=0.003491
2017/08/30 07:28:36 step 2: objective=90.868711 reg=0.003491
2017/08/30 07:28:38 step 3: objective=90.911204 reg=0.003491
2017/08/30 07:28:40 step 4: objective=90.952631 reg=0.003490
2017/08/30 07:28:41 step 5: objective=90.992076 reg=0.003490
2017/08/30 07:28:43 step 6: objective=91.032457 reg=0.003490
2017/08/30 07:28:45 step 7: objective=91.073004 reg=0.003489
2017/08/30 07:28:45 Training value function...
2017/08/30 07:28:48 step 0: mse=238149.756678 step=0.050000
2017/08/30 07:28:49 step 1: mse=234738.698622 step=0.050000
2017/08/30 07:28:50 step 2: mse=231855.264285 step=0.050000
2017/08/30 07:28:51 step 3: mse=229099.146973 step=0.050000
2017/08/30 07:28:52 step 4: mse=229499.994501 step=0.050000
2017/08/30 07:28:53 step 5: mse=229943.639790 step=0.050000
2017/08/30 07:28:55 step 6: mse=229518.938345 step=0.050000
2017/08/30 07:28:56 step 7: mse=229781.363351 step=0.050000
2017/08/30 07:28:56 Saving...
2017/08/30 07:28:56 Gathering batch of experience...
2017/08/30 07:29:30 batch 865: mean=11305.200000 stddev=10276.264251 entropy=0.350466 frames=7531 count=25
2017/08/30 07:29:30 Training policy...
2017/08/30 07:29:37 tune 0: objective=66.234419 reg=0.003505 prune=0
2017/08/30 07:29:39 step 0: objective=66.264353 reg=0.003505
2017/08/30 07:29:41 step 1: objective=66.287607 reg=0.003504
2017/08/30 07:29:43 step 2: objective=66.303471 reg=0.003505
2017/08/30 07:29:45 step 3: objective=66.329169 reg=0.003505
2017/08/30 07:29:47 step 4: objective=66.346310 reg=0.003505
2017/08/30 07:29:49 step 5: objective=66.361045 reg=0.003505
2017/08/30 07:29:51 step 6: objective=66.384515 reg=0.003505
2017/08/30 07:29:53 step 7: objective=66.402847 reg=0.003505
2017/08/30 07:29:53 Training value function...
2017/08/30 07:29:56 step 0: mse=178823.885421 step=0.050000
2017/08/30 07:29:57 step 1: mse=178532.968202 step=0.050000
2017/08/30 07:29:58 step 2: mse=179916.445784 step=0.050000
2017/08/30 07:30:00 step 3: mse=180817.591213 step=0.050000
2017/08/30 07:30:01 step 4: mse=182450.551153 step=0.050000
2017/08/30 07:30:02 step 5: mse=182348.189473 step=0.050000
2017/08/30 07:30:03 step 6: mse=182506.496469 step=0.050000
2017/08/30 07:30:04 step 7: mse=180765.372403 step=0.050000
2017/08/30 07:30:04 Saving...
2017/08/30 07:30:05 Gathering batch of experience...
2017/08/30 07:30:39 batch 866: mean=6901.666667 stddev=8472.062356 entropy=0.350486 frames=6764 count=30
2017/08/30 07:30:39 Training policy...
2017/08/30 07:30:45 tune 0: objective=22.764622 reg=0.003505 prune=0
2017/08/30 07:30:46 step 0: objective=22.946574 reg=0.003503
2017/08/30 07:30:48 step 1: objective=23.023049 reg=0.003502
2017/08/30 07:30:50 step 2: objective=23.070781 reg=0.003502
2017/08/30 07:30:52 step 3: objective=23.124226 reg=0.003502
2017/08/30 07:30:54 step 4: objective=23.190207 reg=0.003502
2017/08/30 07:30:55 step 5: objective=23.237239 reg=0.003501
2017/08/30 07:30:57 step 6: objective=23.274484 reg=0.003501
2017/08/30 07:30:59 step 7: objective=23.313297 reg=0.003501
2017/08/30 07:30:59 Training value function...
2017/08/30 07:31:02 step 0: mse=186589.526797 step=0.050000
2017/08/30 07:31:03 step 1: mse=185787.123393 step=0.050000
2017/08/30 07:31:04 step 2: mse=185894.390219 step=0.050000
2017/08/30 07:31:05 step 3: mse=184530.513850 step=0.050000
2017/08/30 07:31:06 step 4: mse=185356.690488 step=0.050000
2017/08/30 07:31:07 step 5: mse=186412.841800 step=0.050000
2017/08/30 07:31:08 step 6: mse=186820.106776 step=0.050000
2017/08/30 07:31:10 step 7: mse=187185.245874 step=0.050000
2017/08/30 07:31:10 Saving...
2017/08/30 07:31:10 Gathering batch of experience...
2017/08/30 07:31:43 batch 867: mean=12241.521739 stddev=10334.262077 entropy=0.352402 frames=7302 count=23
2017/08/30 07:31:43 Training policy...
2017/08/30 07:31:50 tune 0: objective=86.742862 reg=0.003524 prune=0
2017/08/30 07:31:52 step 0: objective=86.774112 reg=0.003523
2017/08/30 07:31:54 step 1: objective=86.808392 reg=0.003523
2017/08/30 07:31:56 step 2: objective=86.847396 reg=0.003523
2017/08/30 07:31:57 step 3: objective=86.872304 reg=0.003523
2017/08/30 07:31:59 step 4: objective=86.912447 reg=0.003522
2017/08/30 07:32:01 step 5: objective=86.962947 reg=0.003522
2017/08/30 07:32:03 step 6: objective=87.007352 reg=0.003522
2017/08/30 07:32:05 step 7: objective=87.039150 reg=0.003521
2017/08/30 07:32:05 Training value function...
2017/08/30 07:32:08 step 0: mse=203963.307648 step=0.050000
2017/08/30 07:32:10 step 1: mse=202877.705405 step=0.050000
2017/08/30 07:32:11 step 2: mse=201721.713088 step=0.050000
2017/08/30 07:32:12 step 3: mse=200196.090773 step=0.050000
2017/08/30 07:32:13 step 4: mse=200065.011994 step=0.050000
2017/08/30 07:32:14 step 5: mse=199073.462206 step=0.050000
2017/08/30 07:32:15 step 6: mse=197281.608346 step=0.050000
2017/08/30 07:32:17 step 7: mse=197263.649180 step=0.050000
2017/08/30 07:32:17 Saving...
2017/08/30 07:32:17 Gathering batch of experience...
2017/08/30 07:32:48 batch 868: mean=10593.913043 stddev=10201.497221 entropy=0.345799 frames=6593 count=23
2017/08/30 07:32:48 Training policy...
2017/08/30 07:32:53 tune 0: objective=76.370872 reg=0.003458 prune=0
2017/08/30 07:32:55 step 0: objective=76.440145 reg=0.003458
2017/08/30 07:32:57 step 1: objective=76.494535 reg=0.003458
2017/08/30 07:32:59 step 2: objective=76.544209 reg=0.003459
2017/08/30 07:33:00 step 3: objective=76.575397 reg=0.003458
2017/08/30 07:33:02 step 4: objective=76.617857 reg=0.003459
2017/08/30 07:33:04 step 5: objective=76.657084 reg=0.003459
2017/08/30 07:33:06 step 6: objective=76.686059 reg=0.003459
2017/08/30 07:33:07 step 7: objective=76.704971 reg=0.003459
2017/08/30 07:33:07 Training value function...
2017/08/30 07:33:10 step 0: mse=240593.753451 step=0.050000
2017/08/30 07:33:11 step 1: mse=235539.376134 step=0.050000
2017/08/30 07:33:12 step 2: mse=236386.961629 step=0.050000
2017/08/30 07:33:13 step 3: mse=237279.979206 step=0.050000
2017/08/30 07:33:15 step 4: mse=236814.396932 step=0.050000
2017/08/30 07:33:16 step 5: mse=235302.803608 step=0.050000
2017/08/30 07:33:17 step 6: mse=235912.146911 step=0.050000
2017/08/30 07:33:18 step 7: mse=236720.283330 step=0.050000
2017/08/30 07:33:18 Saving...
2017/08/30 07:33:18 Gathering batch of experience...
2017/08/30 07:33:46 batch 869: mean=13249.375000 stddev=9953.031868 entropy=0.346379 frames=5417 count=16
2017/08/30 07:33:46 Training policy...
2017/08/30 07:33:50 tune 0: objective=76.094731 reg=0.003464 prune=0
2017/08/30 07:33:52 step 0: objective=76.153129 reg=0.003464
2017/08/30 07:33:53 step 1: objective=76.224905 reg=0.003465
2017/08/30 07:33:55 step 2: objective=76.303460 reg=0.003466
2017/08/30 07:33:56 step 3: objective=76.361253 reg=0.003466
2017/08/30 07:33:58 step 4: objective=76.409481 reg=0.003466
2017/08/30 07:33:59 step 5: objective=76.486034 reg=0.003467
2017/08/30 07:34:00 step 6: objective=76.542205 reg=0.003467
2017/08/30 07:34:02 step 7: objective=76.570473 reg=0.003467
2017/08/30 07:34:02 Training value function...
2017/08/30 07:34:04 step 0: mse=199469.691541 step=0.050000
2017/08/30 07:34:05 step 1: mse=199195.389094 step=0.050000
2017/08/30 07:34:06 step 2: mse=199696.801171 step=0.050000
2017/08/30 07:34:07 step 3: mse=197862.039881 step=0.050000
2017/08/30 07:34:08 step 4: mse=196797.170596 step=0.050000
2017/08/30 07:34:09 step 5: mse=196634.242733 step=0.050000
2017/08/30 07:34:09 step 6: mse=197026.212828 step=0.050000
2017/08/30 07:34:10 step 7: mse=198851.319689 step=0.050000
2017/08/30 07:34:10 Saving...
2017/08/30 07:34:10 Gathering batch of experience...
2017/08/30 07:34:44 batch 870: mean=14931.000000 stddev=9944.062751 entropy=0.349823 frames=7375 count=20
2017/08/30 07:34:44 Training policy...
2017/08/30 07:34:50 tune 0: objective=92.774864 reg=0.003498 prune=0
2017/08/30 07:34:52 step 0: objective=92.813085 reg=0.003497
2017/08/30 07:34:54 step 1: objective=92.834153 reg=0.003497
2017/08/30 07:34:56 step 2: objective=92.868593 reg=0.003496
2017/08/30 07:34:58 step 3: objective=92.908805 reg=0.003496
2017/08/30 07:35:00 step 4: objective=92.937822 reg=0.003495
2017/08/30 07:35:02 step 5: objective=92.972881 reg=0.003495
2017/08/30 07:35:04 step 6: objective=92.998161 reg=0.003495
2017/08/30 07:35:06 step 7: objective=93.013737 reg=0.003494
2017/08/30 07:35:06 Training value function...
2017/08/30 07:35:09 step 0: mse=227670.240583 step=0.050000
2017/08/30 07:35:10 step 1: mse=226297.985596 step=0.050000
2017/08/30 07:35:12 step 2: mse=224425.723366 step=0.050000
2017/08/30 07:35:13 step 3: mse=222592.207731 step=0.050000
2017/08/30 07:35:14 step 4: mse=220915.112617 step=0.050000
2017/08/30 07:35:15 step 5: mse=219342.051124 step=0.050000
2017/08/30 07:35:16 step 6: mse=217618.834726 step=0.050000
2017/08/30 07:35:18 step 7: mse=214438.017980 step=0.050000
2017/08/30 07:35:18 Saving...
2017/08/30 07:35:18 Gathering batch of experience...
2017/08/30 07:35:53 batch 871: mean=14251.666667 stddev=9755.941942 entropy=0.352450 frames=7627 count=21
2017/08/30 07:35:53 Training policy...
2017/08/30 07:35:59 tune 0: objective=77.237159 reg=0.003524 prune=0
2017/08/30 07:36:01 step 0: objective=77.287039 reg=0.003524
2017/08/30 07:36:04 step 1: objective=77.346073 reg=0.003524
2017/08/30 07:36:06 step 2: objective=77.416669 reg=0.003524
2017/08/30 07:36:08 step 3: objective=77.491691 reg=0.003523
2017/08/30 07:36:10 step 4: objective=77.511841 reg=0.003523
2017/08/30 07:36:12 step 5: objective=77.544341 reg=0.003523
2017/08/30 07:36:14 step 6: objective=77.586297 reg=0.003522
2017/08/30 07:36:16 step 7: objective=77.646970 reg=0.003522
2017/08/30 07:36:16 Training value function...
2017/08/30 07:36:19 step 0: mse=206859.040599 step=0.050000
2017/08/30 07:36:20 step 1: mse=206529.891482 step=0.050000
2017/08/30 07:36:22 step 2: mse=206407.707909 step=0.050000
2017/08/30 07:36:23 step 3: mse=206737.315096 step=0.050000
2017/08/30 07:36:24 step 4: mse=206726.965592 step=0.050000
2017/08/30 07:36:26 step 5: mse=205551.948583 step=0.050000
2017/08/30 07:36:27 step 6: mse=205390.960542 step=0.050000
2017/08/30 07:36:28 step 7: mse=204938.158399 step=0.050000
2017/08/30 07:36:28 Saving...
2017/08/30 07:36:28 Gathering batch of experience...
2017/08/30 07:37:03 batch 872: mean=11372.000000 stddev=10586.531821 entropy=0.351673 frames=7427 count=25
2017/08/30 07:37:03 Training policy...
2017/08/30 07:37:09 tune 0: objective=70.790233 reg=0.003517 prune=0
2017/08/30 07:37:11 step 0: objective=70.851269 reg=0.003517
2017/08/30 07:37:13 step 1: objective=70.907340 reg=0.003517
2017/08/30 07:37:15 step 2: objective=70.971960 reg=0.003517
2017/08/30 07:37:17 step 3: objective=71.010225 reg=0.003517
2017/08/30 07:37:19 step 4: objective=71.052553 reg=0.003517
2017/08/30 07:37:21 step 5: objective=71.091979 reg=0.003517
2017/08/30 07:37:23 step 6: objective=71.136478 reg=0.003516
2017/08/30 07:37:25 step 7: objective=71.164695 reg=0.003516
2017/08/30 07:37:25 Training value function...
2017/08/30 07:37:29 step 0: mse=224353.590495 step=0.050000
2017/08/30 07:37:30 step 1: mse=222065.414906 step=0.050000
2017/08/30 07:37:31 step 2: mse=219076.913886 step=0.050000
2017/08/30 07:37:32 step 3: mse=219300.381206 step=0.050000
2017/08/30 07:37:33 step 4: mse=220103.114545 step=0.050000
2017/08/30 07:37:35 step 5: mse=219368.413042 step=0.050000
2017/08/30 07:37:36 step 6: mse=219527.596217 step=0.050000
2017/08/30 07:37:37 step 7: mse=218423.119039 step=0.050000
2017/08/30 07:37:37 Saving...
2017/08/30 07:37:37 Gathering batch of experience...
2017/08/30 07:38:08 batch 873: mean=12990.500000 stddev=10109.562911 entropy=0.347235 frames=6682 count=20
2017/08/30 07:38:08 Training policy...
2017/08/30 07:38:14 tune 0: objective=68.374224 reg=0.003472 prune=0
2017/08/30 07:38:16 step 0: objective=68.455370 reg=0.003472
2017/08/30 07:38:18 step 1: objective=68.514470 reg=0.003471
2017/08/30 07:38:20 step 2: objective=68.561120 reg=0.003471
2017/08/30 07:38:21 step 3: objective=68.596074 reg=0.003471
2017/08/30 07:38:23 step 4: objective=68.639199 reg=0.003470
2017/08/30 07:38:25 step 5: objective=68.667287 reg=0.003470
2017/08/30 07:38:27 step 6: objective=68.712362 reg=0.003469
2017/08/30 07:38:29 step 7: objective=68.752264 reg=0.003469
2017/08/30 07:38:29 Training value function...
2017/08/30 07:38:31 step 0: mse=178774.236255 step=0.050000
2017/08/30 07:38:32 step 1: mse=180115.220115 step=0.050000
2017/08/30 07:38:34 step 2: mse=181668.162135 step=0.050000
2017/08/30 07:38:35 step 3: mse=180845.104779 step=0.050000
2017/08/30 07:38:36 step 4: mse=181589.392402 step=0.050000
2017/08/30 07:38:37 step 5: mse=183785.602294 step=0.050000
2017/08/30 07:38:38 step 6: mse=184546.069635 step=0.050000
2017/08/30 07:38:39 step 7: mse=185540.586596 step=0.050000
2017/08/30 07:38:39 Saving...
2017/08/30 07:38:39 Gathering batch of experience...
2017/08/30 07:39:11 batch 874: mean=11724.090909 stddev=10313.786849 entropy=0.350561 frames=6721 count=22
2017/08/30 07:39:11 Training policy...
2017/08/30 07:39:17 tune 0: objective=76.673398 reg=0.003506 prune=0
2017/08/30 07:39:19 step 0: objective=76.719703 reg=0.003505
2017/08/30 07:39:21 step 1: objective=76.750488 reg=0.003505
2017/08/30 07:39:23 step 2: objective=76.786123 reg=0.003505
2017/08/30 07:39:24 step 3: objective=76.824896 reg=0.003505
2017/08/30 07:39:26 step 4: objective=76.875005 reg=0.003504
2017/08/30 07:39:28 step 5: objective=76.916502 reg=0.003504
2017/08/30 07:39:30 step 6: objective=76.951054 reg=0.003503
2017/08/30 07:39:32 step 7: objective=76.983545 reg=0.003504
2017/08/30 07:39:32 Training value function...
2017/08/30 07:39:34 step 0: mse=218594.790202 step=0.050000
2017/08/30 07:39:36 step 1: mse=214742.639036 step=0.050000
2017/08/30 07:39:37 step 2: mse=215123.292520 step=0.050000
2017/08/30 07:39:38 step 3: mse=210673.033045 step=0.050000
2017/08/30 07:39:39 step 4: mse=207977.823291 step=0.050000
2017/08/30 07:39:40 step 5: mse=208393.120508 step=0.050000
2017/08/30 07:39:41 step 6: mse=207236.911770 step=0.050000
2017/08/30 07:39:42 step 7: mse=205961.505248 step=0.050000
2017/08/30 07:39:42 Saving...
2017/08/30 07:39:42 Gathering batch of experience...
2017/08/30 07:40:17 batch 875: mean=11719.166667 stddev=10308.508689 entropy=0.349732 frames=7418 count=24
2017/08/30 07:40:17 Training policy...
2017/08/30 07:40:24 tune 0: objective=70.894033 reg=0.003497 prune=0
2017/08/30 07:40:26 step 0: objective=70.919882 reg=0.003497
2017/08/30 07:40:28 step 1: objective=70.943187 reg=0.003496
2017/08/30 07:40:30 step 2: objective=70.956946 reg=0.003496
2017/08/30 07:40:32 step 3: objective=70.980276 reg=0.003496
2017/08/30 07:40:34 step 4: objective=71.006808 reg=0.003496
2017/08/30 07:40:36 step 5: objective=71.028925 reg=0.003495
2017/08/30 07:40:38 step 6: objective=71.049592 reg=0.003495
2017/08/30 07:40:40 step 7: objective=71.064800 reg=0.003495
2017/08/30 07:40:40 Training value function...
2017/08/30 07:40:43 step 0: mse=187578.890893 step=0.050000
2017/08/30 07:40:44 step 1: mse=186019.561425 step=0.050000
2017/08/30 07:40:45 step 2: mse=187129.093882 step=0.050000
2017/08/30 07:40:47 step 3: mse=187882.516064 step=0.050000
2017/08/30 07:40:48 step 4: mse=188403.200835 step=0.050000
2017/08/30 07:40:49 step 5: mse=187799.126956 step=0.050000
2017/08/30 07:40:50 step 6: mse=187648.244229 step=0.050000
2017/08/30 07:40:51 step 7: mse=185246.120863 step=0.050000
2017/08/30 07:40:51 Saving...
2017/08/30 07:40:52 Gathering batch of experience...
2017/08/30 07:41:24 batch 876: mean=10054.166667 stddev=10008.674744 entropy=0.350824 frames=6683 count=24
2017/08/30 07:41:24 Training policy...
2017/08/30 07:41:30 tune 0: objective=56.592721 reg=0.003508 prune=0
2017/08/30 07:41:31 step 0: objective=56.648123 reg=0.003509
2017/08/30 07:41:33 step 1: objective=56.694205 reg=0.003509
2017/08/30 07:41:35 step 2: objective=56.744384 reg=0.003509
2017/08/30 07:41:37 step 3: objective=56.794343 reg=0.003509
2017/08/30 07:41:39 step 4: objective=56.824246 reg=0.003510
2017/08/30 07:41:40 step 5: objective=56.863586 reg=0.003510
2017/08/30 07:41:42 step 6: objective=56.891824 reg=0.003510
2017/08/30 07:41:44 step 7: objective=56.910169 reg=0.003510
2017/08/30 07:41:44 Training value function...
2017/08/30 07:41:47 step 0: mse=185252.982430 step=0.050000
2017/08/30 07:41:48 step 1: mse=185464.181879 step=0.050000
2017/08/30 07:41:49 step 2: mse=186372.713425 step=0.050000
2017/08/30 07:41:50 step 3: mse=184386.244141 step=0.050000
2017/08/30 07:41:51 step 4: mse=184458.141320 step=0.050000
2017/08/30 07:41:52 step 5: mse=186503.320778 step=0.050000
2017/08/30 07:41:53 step 6: mse=187383.210924 step=0.050000
2017/08/30 07:41:55 step 7: mse=190202.545626 step=0.050000
2017/08/30 07:41:55 Saving...
2017/08/30 07:41:55 Gathering batch of experience...
2017/08/30 07:42:26 batch 877: mean=9413.269231 stddev=9738.796615 entropy=0.348914 frames=6862 count=26
2017/08/30 07:42:26 Training policy...
2017/08/30 07:42:32 tune 0: objective=62.734329 reg=0.003489 prune=0
2017/08/30 07:42:34 step 0: objective=62.823070 reg=0.003490
2017/08/30 07:42:36 step 1: objective=62.874558 reg=0.003490
2017/08/30 07:42:38 step 2: objective=62.918478 reg=0.003491
2017/08/30 07:42:40 step 3: objective=62.953899 reg=0.003491
2017/08/30 07:42:41 step 4: objective=62.998984 reg=0.003491
2017/08/30 07:42:43 step 5: objective=63.024428 reg=0.003492
2017/08/30 07:42:45 step 6: objective=63.059358 reg=0.003492
2017/08/30 07:42:47 step 7: objective=63.090189 reg=0.003492
2017/08/30 07:42:47 Training value function...
2017/08/30 07:42:50 step 0: mse=220130.020740 step=0.050000
2017/08/30 07:42:51 step 1: mse=219955.960577 step=0.050000
2017/08/30 07:42:52 step 2: mse=219950.945687 step=0.050000
2017/08/30 07:42:53 step 3: mse=215804.452945 step=0.050000
2017/08/30 07:42:54 step 4: mse=210916.624121 step=0.050000
2017/08/30 07:42:56 step 5: mse=211271.748334 step=0.050000
2017/08/30 07:42:57 step 6: mse=210264.107238 step=0.050000
2017/08/30 07:42:58 step 7: mse=208684.061943 step=0.050000
2017/08/30 07:42:58 Saving...
2017/08/30 07:42:58 Gathering batch of experience...
2017/08/30 07:43:34 batch 878: mean=12628.333333 stddev=10488.547590 entropy=0.353579 frames=7718 count=24
2017/08/30 07:43:34 Training policy...
2017/08/30 07:43:41 tune 0: objective=90.000178 reg=0.003536 prune=0
2017/08/30 07:43:43 step 0: objective=90.047972 reg=0.003535
2017/08/30 07:43:45 step 1: objective=90.087830 reg=0.003535
2017/08/30 07:43:47 step 2: objective=90.124385 reg=0.003535
2017/08/30 07:43:49 step 3: objective=90.178503 reg=0.003534
2017/08/30 07:43:51 step 4: objective=90.230686 reg=0.003533
2017/08/30 07:43:53 step 5: objective=90.259313 reg=0.003533
2017/08/30 07:43:55 step 6: objective=90.293486 reg=0.003533
2017/08/30 07:43:57 step 7: objective=90.332761 reg=0.003533
2017/08/30 07:43:57 Training value function...
2017/08/30 07:44:01 step 0: mse=254651.351813 step=0.050000
2017/08/30 07:44:02 step 1: mse=253807.272423 step=0.050000
2017/08/30 07:44:03 step 2: mse=247959.334300 step=0.050000
2017/08/30 07:44:04 step 3: mse=242718.920095 step=0.050000
2017/08/30 07:44:06 step 4: mse=240208.577838 step=0.050000
2017/08/30 07:44:07 step 5: mse=234434.774150 step=0.050000
2017/08/30 07:44:08 step 6: mse=231497.346581 step=0.050000
2017/08/30 07:44:10 step 7: mse=231099.652979 step=0.050000
2017/08/30 07:44:10 Saving...
2017/08/30 07:44:10 Gathering batch of experience...
2017/08/30 07:44:44 batch 879: mean=13515.714286 stddev=9907.008136 entropy=0.346289 frames=7320 count=21
2017/08/30 07:44:44 Training policy...
2017/08/30 07:44:50 tune 0: objective=73.329534 reg=0.003463 prune=0
2017/08/30 07:44:52 step 0: objective=73.390676 reg=0.003463
2017/08/30 07:44:54 step 1: objective=73.432172 reg=0.003463
2017/08/30 07:44:56 step 2: objective=73.471064 reg=0.003463
2017/08/30 07:44:58 step 3: objective=73.529389 reg=0.003464
2017/08/30 07:45:00 step 4: objective=73.573386 reg=0.003464
2017/08/30 07:45:02 step 5: objective=73.613806 reg=0.003464
2017/08/30 07:45:04 step 6: objective=73.628637 reg=0.003464
2017/08/30 07:45:06 step 7: objective=73.646730 reg=0.003465
2017/08/30 07:45:06 Training value function...
2017/08/30 07:45:09 step 0: mse=160559.251123 step=0.050000
2017/08/30 07:45:10 step 1: mse=161512.411582 step=0.050000
2017/08/30 07:45:11 step 2: mse=162126.423006 step=0.050000
2017/08/30 07:45:13 step 3: mse=162473.642394 step=0.050000
2017/08/30 07:45:14 step 4: mse=163188.511667 step=0.050000
2017/08/30 07:45:15 step 5: mse=163280.701552 step=0.050000
2017/08/30 07:45:16 step 6: mse=164748.791086 step=0.050000
2017/08/30 07:45:17 step 7: mse=164440.414844 step=0.050000
2017/08/30 07:45:17 Saving...
2017/08/30 07:45:17 Gathering batch of experience...
2017/08/30 07:45:51 batch 880: mean=17085.555556 stddev=8515.432052 entropy=0.348633 frames=7558 count=18
2017/08/30 07:45:51 Training policy...
2017/08/30 07:45:57 tune 0: objective=89.905845 reg=0.003486 prune=0
2017/08/30 07:45:59 step 0: objective=90.011098 reg=0.003486
2017/08/30 07:46:01 step 1: objective=90.091360 reg=0.003486
2017/08/30 07:46:03 step 2: objective=90.138628 reg=0.003487
2017/08/30 07:46:05 step 3: objective=90.190154 reg=0.003488
2017/08/30 07:46:08 step 4: objective=90.234536 reg=0.003488
2017/08/30 07:46:10 step 5: objective=90.254532 reg=0.003488
2017/08/30 07:46:12 step 6: objective=90.282978 reg=0.003488
2017/08/30 07:46:14 step 7: objective=90.305248 reg=0.003488
2017/08/30 07:46:14 Training value function...
2017/08/30 07:46:17 step 0: mse=212077.753869 step=0.050000
2017/08/30 07:46:18 step 1: mse=208846.953648 step=0.050000
2017/08/30 07:46:19 step 2: mse=207305.982222 step=0.050000
2017/08/30 07:46:21 step 3: mse=204418.021979 step=0.050000
2017/08/30 07:46:22 step 4: mse=203436.455368 step=0.050000
2017/08/30 07:46:23 step 5: mse=204434.034945 step=0.050000
2017/08/30 07:46:24 step 6: mse=205247.110304 step=0.050000
2017/08/30 07:46:26 step 7: mse=205770.245779 step=0.050000
2017/08/30 07:46:26 Saving...
2017/08/30 07:46:26 Gathering batch of experience...
2017/08/30 07:46:58 batch 881: mean=16376.176471 stddev=8763.787378 entropy=0.349242 frames=6809 count=17
2017/08/30 07:46:58 Training policy...
2017/08/30 07:47:04 tune 0: objective=81.953472 reg=0.003492 prune=0
2017/08/30 07:47:05 step 0: objective=82.021929 reg=0.003492
2017/08/30 07:47:07 step 1: objective=82.063271 reg=0.003492
2017/08/30 07:47:09 step 2: objective=82.098665 reg=0.003492
2017/08/30 07:47:11 step 3: objective=82.130764 reg=0.003492
2017/08/30 07:47:13 step 4: objective=82.173217 reg=0.003491
2017/08/30 07:47:15 step 5: objective=82.250294 reg=0.003489
2017/08/30 07:47:16 step 6: objective=82.281374 reg=0.003489
2017/08/30 07:47:18 step 7: objective=82.304992 reg=0.003489
2017/08/30 07:47:18 Training value function...
2017/08/30 07:47:21 step 0: mse=239250.593266 step=0.050000
2017/08/30 07:47:22 step 1: mse=240307.632473 step=0.050000
2017/08/30 07:47:23 step 2: mse=241469.750875 step=0.050000
2017/08/30 07:47:24 step 3: mse=242679.002246 step=0.050000
2017/08/30 07:47:26 step 4: mse=243906.130094 step=0.050000
2017/08/30 07:47:27 step 5: mse=243559.089836 step=0.050000
2017/08/30 07:47:28 step 6: mse=243004.139412 step=0.050000
2017/08/30 07:47:29 step 7: mse=244036.782653 step=0.050000
2017/08/30 07:47:29 Saving...
2017/08/30 07:47:29 Gathering batch of experience...
2017/08/30 07:48:04 batch 882: mean=13037.608696 stddev=10249.555544 entropy=0.351650 frames=7640 count=23
2017/08/30 07:48:04 Training policy...
2017/08/30 07:48:10 tune 0: objective=71.992826 reg=0.003517 prune=0
2017/08/30 07:48:13 step 0: objective=72.037868 reg=0.003517
2017/08/30 07:48:15 step 1: objective=72.071711 reg=0.003516
2017/08/30 07:48:17 step 2: objective=72.117261 reg=0.003516
2017/08/30 07:48:19 step 3: objective=72.148986 reg=0.003516
2017/08/30 07:48:21 step 4: objective=72.178927 reg=0.003515
2017/08/30 07:48:23 step 5: objective=72.216558 reg=0.003515
2017/08/30 07:48:25 step 6: objective=72.264872 reg=0.003515
2017/08/30 07:48:27 step 7: objective=72.301211 reg=0.003514
2017/08/30 07:48:27 Training value function...
2017/08/30 07:48:30 step 0: mse=194513.063026 step=0.050000
2017/08/30 07:48:32 step 1: mse=194171.273575 step=0.050000
2017/08/30 07:48:33 step 2: mse=191838.529893 step=0.050000
2017/08/30 07:48:34 step 3: mse=193405.914129 step=0.050000
2017/08/30 07:48:35 step 4: mse=193160.277247 step=0.050000
2017/08/30 07:48:37 step 5: mse=194395.400086 step=0.050000
2017/08/30 07:48:38 step 6: mse=193853.649222 step=0.050000
2017/08/30 07:48:39 step 7: mse=194090.664533 step=0.050000
2017/08/30 07:48:39 Saving...
2017/08/30 07:48:39 Gathering batch of experience...
2017/08/30 07:49:11 batch 883: mean=9259.807692 stddev=10106.065627 entropy=0.353384 frames=6670 count=26
2017/08/30 07:49:11 Training policy...
2017/08/30 07:49:17 tune 0: objective=57.144888 reg=0.003534 prune=0
2017/08/30 07:49:19 step 0: objective=57.193286 reg=0.003534
2017/08/30 07:49:21 step 1: objective=57.239758 reg=0.003533
2017/08/30 07:49:22 step 2: objective=57.279512 reg=0.003533
2017/08/30 07:49:24 step 3: objective=57.319256 reg=0.003532
2017/08/30 07:49:26 step 4: objective=57.351982 reg=0.003532
2017/08/30 07:49:28 step 5: objective=57.390934 reg=0.003531
2017/08/30 07:49:30 step 6: objective=57.440569 reg=0.003531
2017/08/30 07:49:31 step 7: objective=57.485743 reg=0.003531
2017/08/30 07:49:31 Training value function...
2017/08/30 07:49:34 step 0: mse=209126.411556 step=0.050000
2017/08/30 07:49:35 step 1: mse=209060.613913 step=0.050000
2017/08/30 07:49:37 step 2: mse=208804.815871 step=0.050000
2017/08/30 07:49:38 step 3: mse=209518.519540 step=0.050000
2017/08/30 07:49:39 step 4: mse=208449.631511 step=0.050000
2017/08/30 07:49:40 step 5: mse=208207.801786 step=0.050000
2017/08/30 07:49:41 step 6: mse=209543.036899 step=0.050000
2017/08/30 07:49:42 step 7: mse=210218.095406 step=0.050000
2017/08/30 07:49:42 Saving...
2017/08/30 07:49:42 Gathering batch of experience...
2017/08/30 07:50:17 batch 884: mean=12634.130435 stddev=10224.302214 entropy=0.350211 frames=7590 count=23
2017/08/30 07:50:17 Training policy...
2017/08/30 07:50:23 tune 0: objective=77.629035 reg=0.003502 prune=0
2017/08/30 07:50:25 step 0: objective=77.667861 reg=0.003502
2017/08/30 07:50:27 step 1: objective=77.700387 reg=0.003502
2017/08/30 07:50:29 step 2: objective=77.738842 reg=0.003502
2017/08/30 07:50:32 step 3: objective=77.777075 reg=0.003501
2017/08/30 07:50:34 step 4: objective=77.814929 reg=0.003501
2017/08/30 07:50:36 step 5: objective=77.849218 reg=0.003500
2017/08/30 07:50:38 step 6: objective=77.889592 reg=0.003501
2017/08/30 07:50:40 step 7: objective=77.928450 reg=0.003500
2017/08/30 07:50:40 Training value function...
2017/08/30 07:50:43 step 0: mse=224336.847572 step=0.050000
2017/08/30 07:50:44 step 1: mse=224201.244480 step=0.050000
2017/08/30 07:50:45 step 2: mse=222065.255399 step=0.050000
2017/08/30 07:50:47 step 3: mse=220857.719810 step=0.050000
2017/08/30 07:50:48 step 4: mse=220566.945981 step=0.050000
2017/08/30 07:50:49 step 5: mse=220350.786708 step=0.050000
2017/08/30 07:50:50 step 6: mse=219248.516950 step=0.050000
2017/08/30 07:50:52 step 7: mse=219106.172241 step=0.050000
2017/08/30 07:50:52 Saving...
2017/08/30 07:50:52 Gathering batch of experience...
2017/08/30 07:51:25 batch 885: mean=15049.250000 stddev=9633.746841 entropy=0.346120 frames=7392 count=20
2017/08/30 07:51:25 Training policy...
2017/08/30 07:51:31 tune 0: objective=83.525298 reg=0.003461 prune=0
2017/08/30 07:51:33 step 0: objective=83.575842 reg=0.003460
2017/08/30 07:51:35 step 1: objective=83.621212 reg=0.003460
2017/08/30 07:51:37 step 2: objective=83.665052 reg=0.003459
2017/08/30 07:51:39 step 3: objective=83.719680 reg=0.003459
2017/08/30 07:51:41 step 4: objective=83.757694 reg=0.003458
2017/08/30 07:51:43 step 5: objective=83.798059 reg=0.003458
2017/08/30 07:51:45 step 6: objective=83.832158 reg=0.003457
2017/08/30 07:51:47 step 7: objective=83.872937 reg=0.003457
2017/08/30 07:51:47 Training value function...
2017/08/30 07:51:51 step 0: mse=219306.199214 step=0.050000
2017/08/30 07:51:52 step 1: mse=219665.178166 step=0.050000
2017/08/30 07:51:53 step 2: mse=216785.023599 step=0.050000
2017/08/30 07:51:54 step 3: mse=217602.088351 step=0.050000
2017/08/30 07:51:55 step 4: mse=218070.419790 step=0.050000
2017/08/30 07:51:57 step 5: mse=215847.543712 step=0.050000
2017/08/30 07:51:58 step 6: mse=212616.958476 step=0.050000
2017/08/30 07:51:59 step 7: mse=212413.971129 step=0.050000
2017/08/30 07:51:59 Saving...
2017/08/30 07:51:59 Gathering batch of experience...
2017/08/30 07:52:33 batch 886: mean=12704.523810 stddev=10040.155793 entropy=0.345165 frames=7083 count=21
2017/08/30 07:52:33 Training policy...
2017/08/30 07:52:39 tune 0: objective=68.617261 reg=0.003452 prune=0
2017/08/30 07:52:41 step 0: objective=68.694193 reg=0.003452
2017/08/30 07:52:43 step 1: objective=68.793886 reg=0.003451
2017/08/30 07:52:45 step 2: objective=68.834595 reg=0.003451
2017/08/30 07:52:47 step 3: objective=68.877219 reg=0.003451
2017/08/30 07:52:49 step 4: objective=68.907578 reg=0.003450
2017/08/30 07:52:51 step 5: objective=68.938766 reg=0.003450
2017/08/30 07:52:53 step 6: objective=68.978708 reg=0.003450
2017/08/30 07:52:54 step 7: objective=69.015773 reg=0.003450
2017/08/30 07:52:54 Training value function...
2017/08/30 07:52:57 step 0: mse=187316.662823 step=0.050000
2017/08/30 07:52:59 step 1: mse=186394.822014 step=0.050000
2017/08/30 07:53:00 step 2: mse=187126.561822 step=0.050000
2017/08/30 07:53:01 step 3: mse=188532.324832 step=0.050000
2017/08/30 07:53:02 step 4: mse=186523.866639 step=0.050000
2017/08/30 07:53:03 step 5: mse=186706.716379 step=0.050000
2017/08/30 07:53:04 step 6: mse=186601.201237 step=0.050000
2017/08/30 07:53:06 step 7: mse=187537.607475 step=0.050000
2017/08/30 07:53:06 Saving...
2017/08/30 07:53:06 Gathering batch of experience...
2017/08/30 07:53:43 batch 887: mean=11896.730769 stddev=10487.566534 entropy=0.347720 frames=7989 count=26
2017/08/30 07:53:43 Training policy...
2017/08/30 07:53:50 tune 0: objective=77.195660 reg=0.003477 prune=0
2017/08/30 07:53:52 step 0: objective=77.240933 reg=0.003476
2017/08/30 07:53:54 step 1: objective=77.273830 reg=0.003476
2017/08/30 07:53:56 step 2: objective=77.320480 reg=0.003476
2017/08/30 07:53:58 step 3: objective=77.357969 reg=0.003475
2017/08/30 07:54:00 step 4: objective=77.398986 reg=0.003475
2017/08/30 07:54:03 step 5: objective=77.426923 reg=0.003474
2017/08/30 07:54:05 step 6: objective=77.462980 reg=0.003474
2017/08/30 07:54:07 step 7: objective=77.497184 reg=0.003474
2017/08/30 07:54:07 Training value function...
2017/08/30 07:54:10 step 0: mse=237735.536246 step=0.050000
2017/08/30 07:54:12 step 1: mse=233800.542257 step=0.050000
2017/08/30 07:54:13 step 2: mse=233438.513128 step=0.050000
2017/08/30 07:54:14 step 3: mse=227154.352168 step=0.050000
2017/08/30 07:54:16 step 4: mse=225358.841750 step=0.050000
2017/08/30 07:54:17 step 5: mse=224765.398985 step=0.050000
2017/08/30 07:54:18 step 6: mse=224516.048572 step=0.050000
2017/08/30 07:54:20 step 7: mse=219069.472438 step=0.050000
2017/08/30 07:54:20 Saving...
2017/08/30 07:54:20 Gathering batch of experience...
2017/08/30 07:54:56 batch 888: mean=11001.153846 stddev=10075.604420 entropy=0.348765 frames=7670 count=26
2017/08/30 07:54:56 Training policy...
2017/08/30 07:55:03 tune 0: objective=58.351446 reg=0.003488 prune=0
2017/08/30 07:55:05 step 0: objective=58.405533 reg=0.003487
2017/08/30 07:55:07 step 1: objective=58.451760 reg=0.003487
2017/08/30 07:55:09 step 2: objective=58.475318 reg=0.003487
2017/08/30 07:55:11 step 3: objective=58.506132 reg=0.003486
2017/08/30 07:55:13 step 4: objective=58.546741 reg=0.003487
2017/08/30 07:55:15 step 5: objective=58.569288 reg=0.003487
2017/08/30 07:55:17 step 6: objective=58.598570 reg=0.003487
2017/08/30 07:55:19 step 7: objective=58.637329 reg=0.003487
2017/08/30 07:55:19 Training value function...
2017/08/30 07:55:23 step 0: mse=168432.003499 step=0.050000
2017/08/30 07:55:24 step 1: mse=169540.341001 step=0.050000
2017/08/30 07:55:25 step 2: mse=168371.696527 step=0.050000
2017/08/30 07:55:26 step 3: mse=168787.762542 step=0.050000
2017/08/30 07:55:28 step 4: mse=169956.129910 step=0.050000
2017/08/30 07:55:29 step 5: mse=170033.238794 step=0.050000
2017/08/30 07:55:30 step 6: mse=170536.426703 step=0.050000
2017/08/30 07:55:32 step 7: mse=171619.616891 step=0.050000
2017/08/30 07:55:32 Saving...
2017/08/30 07:55:32 Gathering batch of experience...
2017/08/30 07:56:07 batch 889: mean=11702.291667 stddev=10371.798500 entropy=0.347014 frames=7298 count=24
2017/08/30 07:56:07 Training policy...
2017/08/30 07:56:13 tune 0: objective=77.715299 reg=0.003470 prune=0
2017/08/30 07:56:15 step 0: objective=77.751636 reg=0.003470
2017/08/30 07:56:17 step 1: objective=77.782149 reg=0.003470
2017/08/30 07:56:19 step 2: objective=77.824918 reg=0.003469
2017/08/30 07:56:21 step 3: objective=77.850267 reg=0.003469
2017/08/30 07:56:23 step 4: objective=77.890621 reg=0.003468
2017/08/30 07:56:25 step 5: objective=77.914026 reg=0.003468
2017/08/30 07:56:27 step 6: objective=77.941140 reg=0.003468
2017/08/30 07:56:29 step 7: objective=77.973323 reg=0.003468
2017/08/30 07:56:29 Training value function...
2017/08/30 07:56:32 step 0: mse=206314.306836 step=0.050000
2017/08/30 07:56:33 step 1: mse=205869.835776 step=0.050000
2017/08/30 07:56:35 step 2: mse=205592.306095 step=0.050000
2017/08/30 07:56:36 step 3: mse=203431.653328 step=0.050000
2017/08/30 07:56:37 step 4: mse=201531.771998 step=0.050000
2017/08/30 07:56:38 step 5: mse=198242.332522 step=0.050000
2017/08/30 07:56:40 step 6: mse=195991.636490 step=0.050000
2017/08/30 07:56:41 step 7: mse=196795.321379 step=0.050000
2017/08/30 07:56:41 Saving...
2017/08/30 07:56:41 Gathering batch of experience...
2017/08/30 07:57:13 batch 890: mean=12188.409091 stddev=9998.930669 entropy=0.346508 frames=7202 count=22
2017/08/30 07:57:13 Training policy...
2017/08/30 07:57:20 tune 0: objective=67.345989 reg=0.003465 prune=0
2017/08/30 07:57:22 step 0: objective=67.397129 reg=0.003465
2017/08/30 07:57:24 step 1: objective=67.446838 reg=0.003464
2017/08/30 07:57:26 step 2: objective=67.495309 reg=0.003464
2017/08/30 07:57:28 step 3: objective=67.535012 reg=0.003463
2017/08/30 07:57:30 step 4: objective=67.567021 reg=0.003463
2017/08/30 07:57:32 step 5: objective=67.583610 reg=0.003463
2017/08/30 07:57:34 step 6: objective=67.604715 reg=0.003463
2017/08/30 07:57:36 step 7: objective=67.632064 reg=0.003463
2017/08/30 07:57:36 Training value function...
2017/08/30 07:57:39 step 0: mse=163499.503392 step=0.050000
2017/08/30 07:57:40 step 1: mse=163927.983663 step=0.050000
2017/08/30 07:57:41 step 2: mse=163593.393779 step=0.050000
2017/08/30 07:57:42 step 3: mse=165143.246704 step=0.050000
2017/08/30 07:57:43 step 4: mse=166233.806336 step=0.050000
2017/08/30 07:57:45 step 5: mse=166604.978100 step=0.050000
2017/08/30 07:57:46 step 6: mse=166959.630427 step=0.050000
2017/08/30 07:57:47 step 7: mse=167943.843498 step=0.050000
2017/08/30 07:57:47 Saving...
2017/08/30 07:57:47 Gathering batch of experience...
2017/08/30 07:58:16 batch 891: mean=10232.500000 stddev=9695.496571 entropy=0.345739 frames=5824 count=20
2017/08/30 07:58:16 Training policy...
2017/08/30 07:58:21 tune 0: objective=51.778996 reg=0.003457 prune=0
2017/08/30 07:58:23 step 0: objective=51.892573 reg=0.003457
2017/08/30 07:58:24 step 1: objective=51.982089 reg=0.003457
2017/08/30 07:58:26 step 2: objective=52.049697 reg=0.003457
2017/08/30 07:58:27 step 3: objective=52.121008 reg=0.003457
2017/08/30 07:58:29 step 4: objective=52.156288 reg=0.003456
2017/08/30 07:58:31 step 5: objective=52.192817 reg=0.003456
2017/08/30 07:58:32 step 6: objective=52.236333 reg=0.003455
2017/08/30 07:58:34 step 7: objective=52.282586 reg=0.003455
2017/08/30 07:58:34 Training value function...
2017/08/30 07:58:36 step 0: mse=183824.147869 step=0.050000
2017/08/30 07:58:37 step 1: mse=185135.964540 step=0.050000
2017/08/30 07:58:38 step 2: mse=185690.775483 step=0.050000
2017/08/30 07:58:39 step 3: mse=186000.875519 step=0.050000
2017/08/30 07:58:40 step 4: mse=187008.620979 step=0.050000
2017/08/30 07:58:41 step 5: mse=186966.712702 step=0.050000
2017/08/30 07:58:42 step 6: mse=188842.700970 step=0.050000
2017/08/30 07:58:43 step 7: mse=190269.055409 step=0.050000
2017/08/30 07:58:43 Saving...
2017/08/30 07:58:43 Gathering batch of experience...
2017/08/30 07:59:15 batch 892: mean=12289.090909 stddev=9947.928592 entropy=0.346933 frames=7177 count=22
2017/08/30 07:59:15 Training policy...
2017/08/30 07:59:22 tune 0: objective=72.300017 reg=0.003469 prune=0
2017/08/30 07:59:24 step 0: objective=72.423950 reg=0.003469
2017/08/30 07:59:26 step 1: objective=72.535770 reg=0.003468
2017/08/30 07:59:28 step 2: objective=72.624229 reg=0.003468
2017/08/30 07:59:30 step 3: objective=72.681443 reg=0.003468
2017/08/30 07:59:32 step 4: objective=72.741200 reg=0.003469
2017/08/30 07:59:34 step 5: objective=72.777980 reg=0.003469
2017/08/30 07:59:35 step 6: objective=72.812165 reg=0.003469
2017/08/30 07:59:37 step 7: objective=72.852694 reg=0.003469
2017/08/30 07:59:37 Training value function...
2017/08/30 07:59:41 step 0: mse=189990.152316 step=0.050000
2017/08/30 07:59:42 step 1: mse=188800.650245 step=0.050000
2017/08/30 07:59:43 step 2: mse=188894.895674 step=0.050000
2017/08/30 07:59:44 step 3: mse=189124.389717 step=0.050000
2017/08/30 07:59:45 step 4: mse=189398.028869 step=0.050000
2017/08/30 07:59:46 step 5: mse=189256.479780 step=0.050000
2017/08/30 07:59:48 step 6: mse=191445.811626 step=0.050000
2017/08/30 07:59:49 step 7: mse=190653.176996 step=0.050000
2017/08/30 07:59:49 Saving...
2017/08/30 07:59:49 Gathering batch of experience...
2017/08/30 08:00:23 batch 893: mean=15032.500000 stddev=9544.582953 entropy=0.343864 frames=7466 count=20
2017/08/30 08:00:23 Training policy...
2017/08/30 08:00:30 tune 0: objective=92.586316 reg=0.003439 prune=0
2017/08/30 08:00:32 step 0: objective=92.632266 reg=0.003438
2017/08/30 08:00:34 step 1: objective=92.662076 reg=0.003437
2017/08/30 08:00:36 step 2: objective=92.715703 reg=0.003437
2017/08/30 08:00:38 step 3: objective=92.745990 reg=0.003437
2017/08/30 08:00:40 step 4: objective=92.797725 reg=0.003437
2017/08/30 08:00:42 step 5: objective=92.847333 reg=0.003437
2017/08/30 08:00:44 step 6: objective=92.879437 reg=0.003436
2017/08/30 08:00:46 step 7: objective=92.912545 reg=0.003436
2017/08/30 08:00:46 Training value function...
2017/08/30 08:00:49 step 0: mse=235166.448858 step=0.050000
2017/08/30 08:00:50 step 1: mse=232783.231629 step=0.050000
2017/08/30 08:00:52 step 2: mse=232047.323493 step=0.050000
2017/08/30 08:00:53 step 3: mse=231776.476291 step=0.050000
2017/08/30 08:00:54 step 4: mse=231253.886938 step=0.050000
2017/08/30 08:00:55 step 5: mse=228477.624828 step=0.050000
2017/08/30 08:00:57 step 6: mse=224623.905769 step=0.050000
2017/08/30 08:00:58 step 7: mse=222101.495345 step=0.050000
2017/08/30 08:00:58 Saving...
2017/08/30 08:00:58 Gathering batch of experience...
2017/08/30 08:01:33 batch 894: mean=9778.888889 stddev=10135.578090 entropy=0.347649 frames=7268 count=27
2017/08/30 08:01:33 Training policy...
2017/08/30 08:01:40 tune 0: objective=65.277870 reg=0.003476 prune=0
2017/08/30 08:01:42 step 0: objective=65.325236 reg=0.003476
2017/08/30 08:01:44 step 1: objective=65.374428 reg=0.003476
2017/08/30 08:01:46 step 2: objective=65.421101 reg=0.003476
2017/08/30 08:01:48 step 3: objective=65.473101 reg=0.003476
2017/08/30 08:01:50 step 4: objective=65.512989 reg=0.003476
2017/08/30 08:01:52 step 5: objective=65.543078 reg=0.003475
2017/08/30 08:01:54 step 6: objective=65.575829 reg=0.003475
2017/08/30 08:01:56 step 7: objective=65.603244 reg=0.003475
2017/08/30 08:01:56 Training value function...
2017/08/30 08:01:59 step 0: mse=197705.647691 step=0.050000
2017/08/30 08:02:00 step 1: mse=196288.190287 step=0.050000
2017/08/30 08:02:01 step 2: mse=196954.592830 step=0.050000
2017/08/30 08:02:02 step 3: mse=196807.400231 step=0.050000
2017/08/30 08:02:04 step 4: mse=197368.180936 step=0.050000
2017/08/30 08:02:05 step 5: mse=195131.722994 step=0.050000
2017/08/30 08:02:06 step 6: mse=194064.438348 step=0.050000
2017/08/30 08:02:07 step 7: mse=192938.956657 step=0.050000
2017/08/30 08:02:07 Saving...
2017/08/30 08:02:07 Gathering batch of experience...
2017/08/30 08:02:39 batch 895: mean=13904.210526 stddev=9806.027183 entropy=0.342658 frames=6675 count=19
2017/08/30 08:02:39 Training policy...
2017/08/30 08:02:45 tune 0: objective=75.424743 reg=0.003427 prune=0
2017/08/30 08:02:47 step 0: objective=75.490023 reg=0.003426
2017/08/30 08:02:49 step 1: objective=75.547233 reg=0.003426
2017/08/30 08:02:51 step 2: objective=75.584953 reg=0.003425
2017/08/30 08:02:52 step 3: objective=75.617917 reg=0.003425
2017/08/30 08:02:54 step 4: objective=75.651124 reg=0.003426
2017/08/30 08:02:56 step 5: objective=75.697907 reg=0.003426
2017/08/30 08:02:58 step 6: objective=75.724007 reg=0.003426
2017/08/30 08:03:00 step 7: objective=75.771419 reg=0.003425
2017/08/30 08:03:00 Training value function...
2017/08/30 08:03:03 step 0: mse=189499.781856 step=0.050000
2017/08/30 08:03:04 step 1: mse=189686.155588 step=0.050000
2017/08/30 08:03:05 step 2: mse=190023.432261 step=0.050000
2017/08/30 08:03:06 step 3: mse=189683.117920 step=0.050000
2017/08/30 08:03:07 step 4: mse=190080.588438 step=0.050000
2017/08/30 08:03:08 step 5: mse=190667.936827 step=0.050000
2017/08/30 08:03:09 step 6: mse=191110.530828 step=0.050000
2017/08/30 08:03:10 step 7: mse=192463.581495 step=0.050000
2017/08/30 08:03:10 Saving...
2017/08/30 08:03:10 Gathering batch of experience...
2017/08/30 08:03:40 batch 896: mean=8421.000000 stddev=9541.917522 entropy=0.348485 frames=6213 count=25
2017/08/30 08:03:40 Training policy...
2017/08/30 08:03:46 tune 0: objective=48.706638 reg=0.003485 prune=0
2017/08/30 08:03:47 step 0: objective=48.768510 reg=0.003484
2017/08/30 08:03:49 step 1: objective=48.822539 reg=0.003484
2017/08/30 08:03:51 step 2: objective=48.893997 reg=0.003484
2017/08/30 08:03:53 step 3: objective=48.943365 reg=0.003484
2017/08/30 08:03:54 step 4: objective=48.989805 reg=0.003484
2017/08/30 08:03:56 step 5: objective=49.047310 reg=0.003484
2017/08/30 08:03:58 step 6: objective=49.088675 reg=0.003484
2017/08/30 08:03:59 step 7: objective=49.148565 reg=0.003485
2017/08/30 08:03:59 Training value function...
2017/08/30 08:04:02 step 0: mse=186433.551655 step=0.050000
2017/08/30 08:04:03 step 1: mse=187248.951022 step=0.050000
2017/08/30 08:04:04 step 2: mse=188299.301584 step=0.050000
2017/08/30 08:04:05 step 3: mse=185910.403846 step=0.050000
2017/08/30 08:04:06 step 4: mse=185743.012421 step=0.050000
2017/08/30 08:04:07 step 5: mse=185462.666768 step=0.050000
2017/08/30 08:04:08 step 6: mse=185150.542291 step=0.050000
2017/08/30 08:04:09 step 7: mse=183255.496592 step=0.050000
2017/08/30 08:04:09 Saving...
2017/08/30 08:04:09 Gathering batch of experience...
2017/08/30 08:04:42 batch 897: mean=10372.400000 stddev=10268.126034 entropy=0.345753 frames=6906 count=25
2017/08/30 08:04:42 Training policy...
2017/08/30 08:04:48 tune 0: objective=84.180296 reg=0.003458 prune=0
2017/08/30 08:04:50 step 0: objective=84.246851 reg=0.003458
2017/08/30 08:04:52 step 1: objective=84.293821 reg=0.003457
2017/08/30 08:04:54 step 2: objective=84.335569 reg=0.003457
2017/08/30 08:04:55 step 3: objective=84.389299 reg=0.003457
2017/08/30 08:04:57 step 4: objective=84.450233 reg=0.003457
2017/08/30 08:04:59 step 5: objective=84.483058 reg=0.003457
2017/08/30 08:05:01 step 6: objective=84.530345 reg=0.003458
2017/08/30 08:05:03 step 7: objective=84.578301 reg=0.003457
2017/08/30 08:05:03 Training value function...
2017/08/30 08:05:06 step 0: mse=294900.788404 step=0.050000
2017/08/30 08:05:07 step 1: mse=292917.629388 step=0.050000
2017/08/30 08:05:08 step 2: mse=292520.311290 step=0.050000
2017/08/30 08:05:09 step 3: mse=292258.042667 step=0.050000
2017/08/30 08:05:10 step 4: mse=286192.133251 step=0.050000
2017/08/30 08:05:12 step 5: mse=285889.101827 step=0.050000
2017/08/30 08:05:13 step 6: mse=285606.390010 step=0.050000
2017/08/30 08:05:14 step 7: mse=280862.923366 step=0.050000
2017/08/30 08:05:14 Saving...
2017/08/30 08:05:14 Gathering batch of experience...
2017/08/30 08:05:46 batch 898: mean=10377.291667 stddev=9964.363583 entropy=0.344006 frames=6905 count=24
2017/08/30 08:05:46 Training policy...
2017/08/30 08:05:52 tune 0: objective=70.209843 reg=0.003440 prune=0
2017/08/30 08:05:54 step 0: objective=70.270393 reg=0.003440
2017/08/30 08:05:56 step 1: objective=70.325276 reg=0.003440
2017/08/30 08:05:58 step 2: objective=70.361007 reg=0.003439
2017/08/30 08:06:00 step 3: objective=70.395918 reg=0.003439
2017/08/30 08:06:02 step 4: objective=70.435762 reg=0.003440
2017/08/30 08:06:04 step 5: objective=70.470302 reg=0.003439
2017/08/30 08:06:06 step 6: objective=70.513690 reg=0.003439
2017/08/30 08:06:08 step 7: objective=70.529490 reg=0.003439
2017/08/30 08:06:08 Training value function...
2017/08/30 08:06:11 step 0: mse=195904.782071 step=0.050000
2017/08/30 08:06:12 step 1: mse=196358.335658 step=0.050000
2017/08/30 08:06:13 step 2: mse=195648.105889 step=0.050000
2017/08/30 08:06:14 step 3: mse=193102.142678 step=0.050000
2017/08/30 08:06:15 step 4: mse=192715.991392 step=0.050000
2017/08/30 08:06:16 step 5: mse=193430.026267 step=0.050000
2017/08/30 08:06:17 step 6: mse=193529.525243 step=0.050000
2017/08/30 08:06:19 step 7: mse=191384.280267 step=0.050000
2017/08/30 08:06:19 Saving...
2017/08/30 08:06:19 Gathering batch of experience...
2017/08/30 08:06:52 batch 899: mean=14879.750000 stddev=9892.938198 entropy=0.347651 frames=7338 count=20
2017/08/30 08:06:52 Training policy...
2017/08/30 08:06:59 tune 0: objective=94.107437 reg=0.003477 prune=0
2017/08/30 08:07:01 step 0: objective=94.158413 reg=0.003478
2017/08/30 08:07:03 step 1: objective=94.218759 reg=0.003478
2017/08/30 08:07:05 step 2: objective=94.253288 reg=0.003478
2017/08/30 08:07:07 step 3: objective=94.282093 reg=0.003479
2017/08/30 08:07:09 step 4: objective=94.346654 reg=0.003480
2017/08/30 08:07:11 step 5: objective=94.402170 reg=0.003481
2017/08/30 08:07:13 step 6: objective=94.445847 reg=0.003481
2017/08/30 08:07:15 step 7: objective=94.483425 reg=0.003482
2017/08/30 08:07:15 Training value function...
2017/08/30 08:07:18 step 0: mse=221119.006589 step=0.050000
2017/08/30 08:07:19 step 1: mse=217824.090232 step=0.050000
2017/08/30 08:07:21 step 2: mse=216332.526780 step=0.050000
2017/08/30 08:07:22 step 3: mse=213164.666428 step=0.050000
2017/08/30 08:07:23 step 4: mse=213703.614984 step=0.050000
2017/08/30 08:07:24 step 5: mse=213926.601930 step=0.050000
2017/08/30 08:07:26 step 6: mse=214496.415901 step=0.050000
2017/08/30 08:07:27 step 7: mse=214421.424780 step=0.050000
2017/08/30 08:07:27 Saving...
2017/08/30 08:07:27 Gathering batch of experience...
2017/08/30 08:08:00 batch 900: mean=10052.608696 stddev=9670.479493 entropy=0.353321 frames=6687 count=23
2017/08/30 08:08:00 Training policy...
2017/08/30 08:08:06 tune 0: objective=52.085796 reg=0.003533 prune=0
2017/08/30 08:08:07 step 0: objective=52.180579 reg=0.003532
2017/08/30 08:08:09 step 1: objective=52.262379 reg=0.003532
2017/08/30 08:08:11 step 2: objective=52.309860 reg=0.003531
2017/08/30 08:08:13 step 3: objective=52.371430 reg=0.003531
2017/08/30 08:08:15 step 4: objective=52.421466 reg=0.003530
2017/08/30 08:08:17 step 5: objective=52.459969 reg=0.003529
2017/08/30 08:08:19 step 6: objective=52.511562 reg=0.003529
2017/08/30 08:08:20 step 7: objective=52.545929 reg=0.003528
2017/08/30 08:08:20 Training value function...
2017/08/30 08:08:23 step 0: mse=196301.291383 step=0.050000
2017/08/30 08:08:24 step 1: mse=198155.992169 step=0.050000
2017/08/30 08:08:25 step 2: mse=199601.678169 step=0.050000
2017/08/30 08:08:27 step 3: mse=200431.848389 step=0.050000
2017/08/30 08:08:28 step 4: mse=200531.062095 step=0.050000
2017/08/30 08:08:29 step 5: mse=199690.241748 step=0.050000
2017/08/30 08:08:30 step 6: mse=200984.034923 step=0.050000
2017/08/30 08:08:31 step 7: mse=199594.709579 step=0.050000
2017/08/30 08:08:31 Saving...
2017/08/30 08:08:31 Gathering batch of experience...
2017/08/30 08:09:08 batch 901: mean=10651.851852 stddev=10114.394413 entropy=0.347877 frames=7705 count=27
2017/08/30 08:09:08 Training policy...
2017/08/30 08:09:14 tune 0: objective=69.769671 reg=0.003479 prune=0
2017/08/30 08:09:17 step 0: objective=69.825235 reg=0.003479
2017/08/30 08:09:19 step 1: objective=69.866961 reg=0.003479
2017/08/30 08:09:21 step 2: objective=69.895798 reg=0.003479
2017/08/30 08:09:23 step 3: objective=69.926338 reg=0.003479
2017/08/30 08:09:25 step 4: objective=69.950965 reg=0.003478
2017/08/30 08:09:27 step 5: objective=69.987386 reg=0.003478
2017/08/30 08:09:30 step 6: objective=70.010918 reg=0.003478
2017/08/30 08:09:32 step 7: objective=70.044111 reg=0.003478
2017/08/30 08:09:32 Training value function...
2017/08/30 08:09:35 step 0: mse=207653.415609 step=0.050000
2017/08/30 08:09:36 step 1: mse=207373.173589 step=0.050000
2017/08/30 08:09:38 step 2: mse=203140.329786 step=0.050000
2017/08/30 08:09:39 step 3: mse=201678.356423 step=0.050000
2017/08/30 08:09:40 step 4: mse=199652.314097 step=0.050000
2017/08/30 08:09:42 step 5: mse=197854.870257 step=0.050000
2017/08/30 08:09:43 step 6: mse=195996.057508 step=0.050000
2017/08/30 08:09:44 step 7: mse=195665.930974 step=0.050000
2017/08/30 08:09:44 Saving...
2017/08/30 08:09:44 Gathering batch of experience...
2017/08/30 08:10:13 batch 902: mean=10527.142857 stddev=10329.487906 entropy=0.345658 frames=5864 count=21
2017/08/30 08:10:13 Training policy...
2017/08/30 08:10:19 tune 0: objective=74.724308 reg=0.003457 prune=0
2017/08/30 08:10:20 step 0: objective=74.789174 reg=0.003456
2017/08/30 08:10:22 step 1: objective=74.851674 reg=0.003455
2017/08/30 08:10:24 step 2: objective=74.904667 reg=0.003454
2017/08/30 08:10:25 step 3: objective=74.957164 reg=0.003453
2017/08/30 08:10:27 step 4: objective=74.999472 reg=0.003453
2017/08/30 08:10:29 step 5: objective=75.030605 reg=0.003452
2017/08/30 08:10:30 step 6: objective=75.095626 reg=0.003451
2017/08/30 08:10:32 step 7: objective=75.133639 reg=0.003451
2017/08/30 08:10:32 Training value function...
2017/08/30 08:10:34 step 0: mse=189942.265597 step=0.050000
2017/08/30 08:10:35 step 1: mse=188030.810813 step=0.050000
2017/08/30 08:10:36 step 2: mse=187824.764493 step=0.050000
2017/08/30 08:10:37 step 3: mse=187614.344217 step=0.050000
2017/08/30 08:10:38 step 4: mse=187733.394523 step=0.050000
2017/08/30 08:10:39 step 5: mse=188081.947603 step=0.050000
2017/08/30 08:10:40 step 6: mse=187983.847936 step=0.050000
2017/08/30 08:10:41 step 7: mse=187935.990232 step=0.050000
2017/08/30 08:10:41 Saving...
2017/08/30 08:10:41 Gathering batch of experience...
2017/08/30 08:11:14 batch 903: mean=11659.782609 stddev=9819.358927 entropy=0.342642 frames=7169 count=23
2017/08/30 08:11:14 Training policy...
2017/08/30 08:11:20 tune 0: objective=66.868409 reg=0.003426 prune=0
2017/08/30 08:11:22 step 0: objective=66.927688 reg=0.003427
2017/08/30 08:11:24 step 1: objective=66.994159 reg=0.003426
2017/08/30 08:11:26 step 2: objective=67.038822 reg=0.003426
2017/08/30 08:11:28 step 3: objective=67.083070 reg=0.003426
2017/08/30 08:11:30 step 4: objective=67.135584 reg=0.003425
2017/08/30 08:11:32 step 5: objective=67.163238 reg=0.003424
2017/08/30 08:11:34 step 6: objective=67.215363 reg=0.003424
2017/08/30 08:11:36 step 7: objective=67.253025 reg=0.003424
2017/08/30 08:11:36 Training value function...
2017/08/30 08:11:39 step 0: mse=181946.418165 step=0.050000
2017/08/30 08:11:40 step 1: mse=183037.347041 step=0.050000
2017/08/30 08:11:42 step 2: mse=184708.739991 step=0.050000
2017/08/30 08:11:43 step 3: mse=187314.142397 step=0.050000
2017/08/30 08:11:44 step 4: mse=188754.018495 step=0.050000
2017/08/30 08:11:45 step 5: mse=189694.184934 step=0.050000
2017/08/30 08:11:46 step 6: mse=189880.125577 step=0.050000
2017/08/30 08:11:47 step 7: mse=190002.438994 step=0.050000
2017/08/30 08:11:47 Saving...
2017/08/30 08:11:48 Gathering batch of experience...
2017/08/30 08:12:23 batch 904: mean=14513.095238 stddev=9762.089145 entropy=0.345914 frames=7719 count=21
2017/08/30 08:12:23 Training policy...
2017/08/30 08:12:30 tune 0: objective=84.840515 reg=0.003459 prune=0
2017/08/30 08:12:32 step 0: objective=84.894109 reg=0.003459
2017/08/30 08:12:34 step 1: objective=84.937370 reg=0.003459
2017/08/30 08:12:36 step 2: objective=84.973968 reg=0.003459
2017/08/30 08:12:38 step 3: objective=84.998024 reg=0.003459
2017/08/30 08:12:41 step 4: objective=85.018663 reg=0.003460
2017/08/30 08:12:43 step 5: objective=85.043205 reg=0.003460
2017/08/30 08:12:45 step 6: objective=85.073123 reg=0.003460
2017/08/30 08:12:47 step 7: objective=85.097163 reg=0.003460
2017/08/30 08:12:47 Training value function...
2017/08/30 08:12:50 step 0: mse=194695.541647 step=0.050000
2017/08/30 08:12:52 step 1: mse=192947.778803 step=0.050000
2017/08/30 08:12:53 step 2: mse=192937.837387 step=0.050000
2017/08/30 08:12:54 step 3: mse=192640.100107 step=0.050000
2017/08/30 08:12:55 step 4: mse=192505.441368 step=0.050000
2017/08/30 08:12:57 step 5: mse=193173.988981 step=0.050000
2017/08/30 08:12:58 step 6: mse=192247.793338 step=0.050000
2017/08/30 08:12:59 step 7: mse=192629.847941 step=0.050000
2017/08/30 08:12:59 Saving...
2017/08/30 08:12:59 Gathering batch of experience...
2017/08/30 08:13:33 batch 905: mean=14911.578947 stddev=9178.938858 entropy=0.345862 frames=7166 count=19
2017/08/30 08:13:33 Training policy...
2017/08/30 08:13:39 tune 0: objective=74.022615 reg=0.003459 prune=0
2017/08/30 08:13:41 step 0: objective=74.073952 reg=0.003458
2017/08/30 08:13:43 step 1: objective=74.101948 reg=0.003458
2017/08/30 08:13:45 step 2: objective=74.140525 reg=0.003458
2017/08/30 08:13:47 step 3: objective=74.168530 reg=0.003459
2017/08/30 08:13:49 step 4: objective=74.201987 reg=0.003459
2017/08/30 08:13:51 step 5: objective=74.238644 reg=0.003458
2017/08/30 08:13:53 step 6: objective=74.276662 reg=0.003458
2017/08/30 08:13:55 step 7: objective=74.297246 reg=0.003458
2017/08/30 08:13:55 Training value function...
2017/08/30 08:13:58 step 0: mse=209717.254527 step=0.050000
2017/08/30 08:13:59 step 1: mse=209995.745468 step=0.050000
2017/08/30 08:14:01 step 2: mse=210415.837624 step=0.050000
2017/08/30 08:14:02 step 3: mse=209744.439748 step=0.050000
2017/08/30 08:14:03 step 4: mse=210758.283794 step=0.050000
2017/08/30 08:14:04 step 5: mse=211146.608254 step=0.050000
2017/08/30 08:14:05 step 6: mse=211634.059136 step=0.050000
2017/08/30 08:14:06 step 7: mse=212258.758879 step=0.050000
2017/08/30 08:14:06 Saving...
2017/08/30 08:14:06 Gathering batch of experience...
2017/08/30 08:14:39 batch 906: mean=11188.260870 stddev=10369.094402 entropy=0.346846 frames=6775 count=23
2017/08/30 08:14:39 Training policy...
2017/08/30 08:14:45 tune 0: objective=78.252601 reg=0.003468 prune=0
2017/08/30 08:14:47 step 0: objective=78.300295 reg=0.003467
2017/08/30 08:14:48 step 1: objective=78.351476 reg=0.003466
2017/08/30 08:14:50 step 2: objective=78.403884 reg=0.003465
2017/08/30 08:14:52 step 3: objective=78.456882 reg=0.003464
2017/08/30 08:14:54 step 4: objective=78.507980 reg=0.003463
2017/08/30 08:14:56 step 5: objective=78.564945 reg=0.003463
2017/08/30 08:14:58 step 6: objective=78.613210 reg=0.003462
2017/08/30 08:15:00 step 7: objective=78.669382 reg=0.003461
2017/08/30 08:15:00 Training value function...
2017/08/30 08:15:03 step 0: mse=261211.287426 step=0.050000
2017/08/30 08:15:04 step 1: mse=254939.950137 step=0.050000
2017/08/30 08:15:05 step 2: mse=248991.051996 step=0.050000
2017/08/30 08:15:06 step 3: mse=244882.633478 step=0.050000
2017/08/30 08:15:07 step 4: mse=243546.200448 step=0.050000
2017/08/30 08:15:08 step 5: mse=240394.939447 step=0.050000
2017/08/30 08:15:09 step 6: mse=233669.794590 step=0.050000
2017/08/30 08:15:10 step 7: mse=233734.199581 step=0.050000
2017/08/30 08:15:10 Saving...
2017/08/30 08:15:10 Gathering batch of experience...
2017/08/30 08:15:43 batch 907: mean=15685.789474 stddev=9553.892327 entropy=0.345319 frames=7359 count=19
2017/08/30 08:15:43 Training policy...
2017/08/30 08:15:50 tune 0: objective=88.058746 reg=0.003453 prune=0
2017/08/30 08:15:52 step 0: objective=88.105033 reg=0.003452
2017/08/30 08:15:54 step 1: objective=88.159125 reg=0.003451
2017/08/30 08:15:56 step 2: objective=88.190600 reg=0.003451
2017/08/30 08:15:58 step 3: objective=88.217981 reg=0.003451
2017/08/30 08:16:00 step 4: objective=88.244938 reg=0.003451
2017/08/30 08:16:02 step 5: objective=88.273874 reg=0.003451
2017/08/30 08:16:04 step 6: objective=88.309247 reg=0.003451
2017/08/30 08:16:06 step 7: objective=88.328790 reg=0.003451
2017/08/30 08:16:06 Training value function...
2017/08/30 08:16:09 step 0: mse=189459.366061 step=0.050000
2017/08/30 08:16:11 step 1: mse=189139.531253 step=0.050000
2017/08/30 08:16:12 step 2: mse=189508.646086 step=0.050000
2017/08/30 08:16:13 step 3: mse=188668.527093 step=0.050000
2017/08/30 08:16:14 step 4: mse=187616.792122 step=0.050000
2017/08/30 08:16:15 step 5: mse=187466.241630 step=0.050000
2017/08/30 08:16:17 step 6: mse=186515.548988 step=0.050000
2017/08/30 08:16:18 step 7: mse=185907.047618 step=0.050000
2017/08/30 08:16:18 Saving...
2017/08/30 08:16:18 Gathering batch of experience...
2017/08/30 08:16:48 batch 908: mean=10888.250000 stddev=10218.781027 entropy=0.346795 frames=5920 count=20
2017/08/30 08:16:48 Training policy...
2017/08/30 08:16:53 tune 0: objective=66.452924 reg=0.003468 prune=0
2017/08/30 08:16:55 step 0: objective=66.483963 reg=0.003467
2017/08/30 08:16:56 step 1: objective=66.518977 reg=0.003467
2017/08/30 08:16:58 step 2: objective=66.559813 reg=0.003466
2017/08/30 08:17:00 step 3: objective=66.590050 reg=0.003466
2017/08/30 08:17:01 step 4: objective=66.627687 reg=0.003466
2017/08/30 08:17:03 step 5: objective=66.658805 reg=0.003465
2017/08/30 08:17:05 step 6: objective=66.685621 reg=0.003465
2017/08/30 08:17:06 step 7: objective=66.729751 reg=0.003465
2017/08/30 08:17:06 Training value function...
2017/08/30 08:17:09 step 0: mse=189020.329132 step=0.050000
2017/08/30 08:17:10 step 1: mse=188237.626732 step=0.050000
2017/08/30 08:17:11 step 2: mse=186319.406959 step=0.050000
2017/08/30 08:17:12 step 3: mse=185193.376751 step=0.050000
2017/08/30 08:17:13 step 4: mse=185207.737658 step=0.050000
2017/08/30 08:17:14 step 5: mse=185864.269513 step=0.050000
2017/08/30 08:17:15 step 6: mse=185390.603302 step=0.050000
2017/08/30 08:17:16 step 7: mse=184188.510503 step=0.050000
2017/08/30 08:17:16 Saving...
2017/08/30 08:17:16 Gathering batch of experience...
2017/08/30 08:17:50 batch 909: mean=10290.000000 stddev=10228.700760 entropy=0.343914 frames=7339 count=26
2017/08/30 08:17:50 Training policy...
2017/08/30 08:17:56 tune 0: objective=64.179755 reg=0.003439 prune=0
2017/08/30 08:17:58 step 0: objective=64.249872 reg=0.003438
2017/08/30 08:18:00 step 1: objective=64.290907 reg=0.003438
2017/08/30 08:18:03 step 2: objective=64.334148 reg=0.003437
2017/08/30 08:18:05 step 3: objective=64.378739 reg=0.003437
2017/08/30 08:18:07 step 4: objective=64.407561 reg=0.003437
2017/08/30 08:18:09 step 5: objective=64.437777 reg=0.003437
2017/08/30 08:18:11 step 6: objective=64.461473 reg=0.003437
2017/08/30 08:18:13 step 7: objective=64.477841 reg=0.003436
2017/08/30 08:18:13 Training value function...
2017/08/30 08:18:16 step 0: mse=181842.510811 step=0.050000
2017/08/30 08:18:17 step 1: mse=183127.208296 step=0.050000
2017/08/30 08:18:18 step 2: mse=183692.758857 step=0.050000
2017/08/30 08:18:20 step 3: mse=183051.211428 step=0.050000
2017/08/30 08:18:21 step 4: mse=183918.033733 step=0.050000
2017/08/30 08:18:22 step 5: mse=184932.682043 step=0.050000
2017/08/30 08:18:23 step 6: mse=186206.349419 step=0.050000
2017/08/30 08:18:24 step 7: mse=187629.400167 step=0.050000
2017/08/30 08:18:24 Saving...
2017/08/30 08:18:25 Gathering batch of experience...
2017/08/30 08:18:57 batch 910: mean=11242.608696 stddev=10191.667192 entropy=0.348153 frames=6943 count=23
2017/08/30 08:18:57 Training policy...
2017/08/30 08:19:03 tune 0: objective=66.495315 reg=0.003482 prune=0
2017/08/30 08:19:05 step 0: objective=66.534234 reg=0.003482
2017/08/30 08:19:07 step 1: objective=66.586958 reg=0.003482
2017/08/30 08:19:09 step 2: objective=66.638377 reg=0.003482
2017/08/30 08:19:11 step 3: objective=66.675780 reg=0.003482
2017/08/30 08:19:13 step 4: objective=66.729624 reg=0.003482
2017/08/30 08:19:15 step 5: objective=66.778122 reg=0.003482
2017/08/30 08:19:17 step 6: objective=66.809156 reg=0.003482
2017/08/30 08:19:19 step 7: objective=66.844839 reg=0.003482
2017/08/30 08:19:19 Training value function...
2017/08/30 08:19:22 step 0: mse=212424.024934 step=0.050000
2017/08/30 08:19:23 step 1: mse=214228.909988 step=0.050000
2017/08/30 08:19:24 step 2: mse=215433.171352 step=0.050000
2017/08/30 08:19:25 step 3: mse=216596.454639 step=0.050000
2017/08/30 08:19:26 step 4: mse=217728.020459 step=0.050000
2017/08/30 08:19:27 step 5: mse=218296.762688 step=0.050000
2017/08/30 08:19:29 step 6: mse=219497.378455 step=0.050000
2017/08/30 08:19:30 step 7: mse=216382.279279 step=0.050000
2017/08/30 08:19:30 Saving...
2017/08/30 08:19:30 Gathering batch of experience...
2017/08/30 08:20:02 batch 911: mean=12182.619048 stddev=10414.819983 entropy=0.342634 frames=6520 count=21
2017/08/30 08:20:02 Training policy...
2017/08/30 08:20:08 tune 0: objective=80.851678 reg=0.003426 prune=0
2017/08/30 08:20:10 step 0: objective=80.911609 reg=0.003427
2017/08/30 08:20:12 step 1: objective=80.957132 reg=0.003427
2017/08/30 08:20:14 step 2: objective=81.008819 reg=0.003427
2017/08/30 08:20:16 step 3: objective=81.059854 reg=0.003428
2017/08/30 08:20:17 step 4: objective=81.095744 reg=0.003428
2017/08/30 08:20:19 step 5: objective=81.122546 reg=0.003428
2017/08/30 08:20:21 step 6: objective=81.152559 reg=0.003427
2017/08/30 08:20:23 step 7: objective=81.198255 reg=0.003426
2017/08/30 08:20:23 Training value function...
2017/08/30 08:20:26 step 0: mse=201431.976682 step=0.050000
2017/08/30 08:20:27 step 1: mse=198161.774708 step=0.050000
2017/08/30 08:20:28 step 2: mse=197207.576533 step=0.050000
2017/08/30 08:20:29 step 3: mse=197295.307797 step=0.050000
2017/08/30 08:20:30 step 4: mse=194987.893539 step=0.050000
2017/08/30 08:20:31 step 5: mse=194919.582125 step=0.050000
2017/08/30 08:20:32 step 6: mse=193394.454953 step=0.050000
2017/08/30 08:20:33 step 7: mse=192934.137307 step=0.050000
2017/08/30 08:20:33 Saving...
2017/08/30 08:20:33 Gathering batch of experience...
2017/08/30 08:21:07 batch 912: mean=12615.238095 stddev=9878.051846 entropy=0.344395 frames=7146 count=21
2017/08/30 08:21:07 Training policy...
2017/08/30 08:21:14 tune 0: objective=64.609441 reg=0.003444 prune=0
2017/08/30 08:21:16 step 0: objective=64.672185 reg=0.003443
2017/08/30 08:21:18 step 1: objective=64.732591 reg=0.003442
2017/08/30 08:21:20 step 2: objective=64.789506 reg=0.003442
2017/08/30 08:21:22 step 3: objective=64.839609 reg=0.003442
2017/08/30 08:21:24 step 4: objective=64.895912 reg=0.003442
2017/08/30 08:21:26 step 5: objective=64.939818 reg=0.003441
2017/08/30 08:21:28 step 6: objective=64.982643 reg=0.003441
2017/08/30 08:21:30 step 7: objective=65.017129 reg=0.003441
2017/08/30 08:21:30 Training value function...
2017/08/30 08:21:33 step 0: mse=212096.753476 step=0.050000
2017/08/30 08:21:34 step 1: mse=212150.738979 step=0.050000
2017/08/30 08:21:35 step 2: mse=208520.095095 step=0.050000
2017/08/30 08:21:36 step 3: mse=209011.595012 step=0.050000
2017/08/30 08:21:37 step 4: mse=208698.144099 step=0.050000
2017/08/30 08:21:39 step 5: mse=208905.185514 step=0.050000
2017/08/30 08:21:40 step 6: mse=206804.934930 step=0.050000
2017/08/30 08:21:41 step 7: mse=207962.848007 step=0.050000
2017/08/30 08:21:41 Saving...
2017/08/30 08:21:41 Gathering batch of experience...
2017/08/30 08:22:13 batch 913: mean=11784.523810 stddev=9841.699416 entropy=0.342196 frames=6641 count=21
2017/08/30 08:22:13 Training policy...
2017/08/30 08:22:19 tune 0: objective=66.577026 reg=0.003422 prune=0
2017/08/30 08:22:21 step 0: objective=66.666598 reg=0.003422
2017/08/30 08:22:23 step 1: objective=66.721475 reg=0.003422
2017/08/30 08:22:25 step 2: objective=66.803578 reg=0.003422
2017/08/30 08:22:27 step 3: objective=66.856036 reg=0.003422
2017/08/30 08:22:29 step 4: objective=66.887032 reg=0.003422
2017/08/30 08:22:30 step 5: objective=66.923487 reg=0.003423
2017/08/30 08:22:32 step 6: objective=66.955899 reg=0.003423
2017/08/30 08:22:34 step 7: objective=66.987728 reg=0.003423
2017/08/30 08:22:34 Training value function...
2017/08/30 08:22:37 step 0: mse=197976.392144 step=0.050000
2017/08/30 08:22:38 step 1: mse=197055.844115 step=0.050000
2017/08/30 08:22:39 step 2: mse=197398.163426 step=0.050000
2017/08/30 08:22:40 step 3: mse=196360.500298 step=0.050000
2017/08/30 08:22:41 step 4: mse=196462.911827 step=0.050000
2017/08/30 08:22:42 step 5: mse=197652.370755 step=0.050000
2017/08/30 08:22:43 step 6: mse=198081.911722 step=0.050000
2017/08/30 08:22:45 step 7: mse=199425.333774 step=0.050000
2017/08/30 08:22:45 Saving...
2017/08/30 08:22:45 Gathering batch of experience...
2017/08/30 08:23:18 batch 914: mean=11710.625000 stddev=10363.532750 entropy=0.344217 frames=7366 count=24
2017/08/30 08:23:18 Training policy...
2017/08/30 08:23:25 tune 0: objective=74.237714 reg=0.003442 prune=0
2017/08/30 08:23:27 step 0: objective=74.268658 reg=0.003442
2017/08/30 08:23:29 step 1: objective=74.293613 reg=0.003442
2017/08/30 08:23:31 step 2: objective=74.316793 reg=0.003441
2017/08/30 08:23:33 step 3: objective=74.343512 reg=0.003442
2017/08/30 08:23:35 step 4: objective=74.385419 reg=0.003441
2017/08/30 08:23:37 step 5: objective=74.420437 reg=0.003440
2017/08/30 08:23:39 step 6: objective=74.441725 reg=0.003441
2017/08/30 08:23:41 step 7: objective=74.457321 reg=0.003441
2017/08/30 08:23:41 Training value function...
2017/08/30 08:23:44 step 0: mse=165380.302828 step=0.050000
2017/08/30 08:23:46 step 1: mse=166438.393361 step=0.050000
2017/08/30 08:23:47 step 2: mse=165300.458477 step=0.050000
2017/08/30 08:23:48 step 3: mse=167009.861736 step=0.050000
2017/08/30 08:23:49 step 4: mse=165895.922306 step=0.050000
2017/08/30 08:23:50 step 5: mse=165146.627072 step=0.050000
2017/08/30 08:23:52 step 6: mse=164648.301723 step=0.050000
2017/08/30 08:23:53 step 7: mse=164333.777805 step=0.050000
2017/08/30 08:23:53 Saving...
2017/08/30 08:23:53 Gathering batch of experience...
2017/08/30 08:24:29 batch 915: mean=10690.185185 stddev=10099.726205 entropy=0.344829 frames=7749 count=27
2017/08/30 08:24:29 Training policy...
2017/08/30 08:24:36 tune 0: objective=68.207253 reg=0.003448 prune=0
2017/08/30 08:24:39 step 0: objective=68.248661 reg=0.003448
2017/08/30 08:24:41 step 1: objective=68.274189 reg=0.003447
2017/08/30 08:24:43 step 2: objective=68.302668 reg=0.003447
2017/08/30 08:24:45 step 3: objective=68.335818 reg=0.003447
2017/08/30 08:24:47 step 4: objective=68.381202 reg=0.003446
2017/08/30 08:24:50 step 5: objective=68.417957 reg=0.003446
2017/08/30 08:24:52 step 6: objective=68.444840 reg=0.003446
2017/08/30 08:24:54 step 7: objective=68.488144 reg=0.003445
2017/08/30 08:24:54 Training value function...
2017/08/30 08:24:57 step 0: mse=204535.681467 step=0.050000
2017/08/30 08:24:58 step 1: mse=203720.146631 step=0.050000
2017/08/30 08:25:00 step 2: mse=203897.250602 step=0.050000
2017/08/30 08:25:01 step 3: mse=202790.684999 step=0.050000
2017/08/30 08:25:02 step 4: mse=204039.029088 step=0.050000
2017/08/30 08:25:04 step 5: mse=204202.570513 step=0.050000
2017/08/30 08:25:05 step 6: mse=204087.226090 step=0.050000
2017/08/30 08:25:06 step 7: mse=202533.820575 step=0.050000
2017/08/30 08:25:06 Saving...
2017/08/30 08:25:06 Gathering batch of experience...
2017/08/30 08:25:37 batch 916: mean=12128.000000 stddev=9839.449349 entropy=0.342967 frames=6611 count=20
2017/08/30 08:25:37 Training policy...
2017/08/30 08:25:43 tune 0: objective=66.043512 reg=0.003430 prune=0
2017/08/30 08:25:45 step 0: objective=66.113840 reg=0.003430
2017/08/30 08:25:47 step 1: objective=66.165676 reg=0.003429
2017/08/30 08:25:49 step 2: objective=66.217691 reg=0.003429
2017/08/30 08:25:51 step 3: objective=66.261822 reg=0.003429
2017/08/30 08:25:52 step 4: objective=66.301737 reg=0.003430
2017/08/30 08:25:54 step 5: objective=66.331214 reg=0.003430
2017/08/30 08:25:56 step 6: objective=66.364005 reg=0.003430
2017/08/30 08:25:58 step 7: objective=66.387347 reg=0.003430
2017/08/30 08:25:58 Training value function...
2017/08/30 08:26:01 step 0: mse=195215.177151 step=0.050000
2017/08/30 08:26:02 step 1: mse=196006.593294 step=0.050000
2017/08/30 08:26:03 step 2: mse=196849.182038 step=0.050000
2017/08/30 08:26:04 step 3: mse=197815.042309 step=0.050000
2017/08/30 08:26:05 step 4: mse=199285.614212 step=0.050000
2017/08/30 08:26:06 step 5: mse=199601.915244 step=0.050000
2017/08/30 08:26:07 step 6: mse=200992.979485 step=0.050000
2017/08/30 08:26:08 step 7: mse=199558.862498 step=0.050000
2017/08/30 08:26:08 Saving...
2017/08/30 08:26:08 Gathering batch of experience...
2017/08/30 08:26:41 batch 917: mean=12793.500000 stddev=10185.161032 entropy=0.341726 frames=6590 count=20
2017/08/30 08:26:41 Training policy...
2017/08/30 08:26:47 tune 0: objective=81.278433 reg=0.003417 prune=0
2017/08/30 08:26:49 step 0: objective=81.327950 reg=0.003417
2017/08/30 08:26:51 step 1: objective=81.359617 reg=0.003417
2017/08/30 08:26:53 step 2: objective=81.411485 reg=0.003418
2017/08/30 08:26:54 step 3: objective=81.469423 reg=0.003418
2017/08/30 08:26:56 step 4: objective=81.496586 reg=0.003419
2017/08/30 08:26:58 step 5: objective=81.534228 reg=0.003419
2017/08/30 08:27:00 step 6: objective=81.554941 reg=0.003419
2017/08/30 08:27:02 step 7: objective=81.578519 reg=0.003419
2017/08/30 08:27:02 Training value function...
2017/08/30 08:27:05 step 0: mse=190785.753629 step=0.050000
2017/08/30 08:27:06 step 1: mse=188754.795253 step=0.050000
2017/08/30 08:27:07 step 2: mse=188040.646716 step=0.050000
2017/08/30 08:27:08 step 3: mse=187710.908842 step=0.050000
2017/08/30 08:27:09 step 4: mse=187466.731576 step=0.050000
2017/08/30 08:27:10 step 5: mse=186880.445202 step=0.050000
2017/08/30 08:27:11 step 6: mse=186780.370395 step=0.050000
2017/08/30 08:27:12 step 7: mse=185494.815631 step=0.050000
2017/08/30 08:27:12 Saving...
2017/08/30 08:27:12 Gathering batch of experience...
2017/08/30 08:27:48 batch 918: mean=11982.708333 stddev=10161.147714 entropy=0.344768 frames=7622 count=24
2017/08/30 08:27:48 Training policy...
2017/08/30 08:27:55 tune 0: objective=73.173371 reg=0.003448 prune=0
2017/08/30 08:27:57 step 0: objective=73.204269 reg=0.003448
2017/08/30 08:27:59 step 1: objective=73.226909 reg=0.003447
2017/08/30 08:28:02 step 2: objective=73.254395 reg=0.003447
2017/08/30 08:28:04 step 3: objective=73.287925 reg=0.003447
2017/08/30 08:28:06 step 4: objective=73.311770 reg=0.003447
2017/08/30 08:28:08 step 5: objective=73.336099 reg=0.003447
2017/08/30 08:28:10 step 6: objective=73.357592 reg=0.003446
2017/08/30 08:28:12 step 7: objective=73.374688 reg=0.003445
2017/08/30 08:28:12 Training value function...
2017/08/30 08:28:16 step 0: mse=193157.569602 step=0.050000
2017/08/30 08:28:17 step 1: mse=190493.900990 step=0.050000
2017/08/30 08:28:18 step 2: mse=190445.498315 step=0.050000
2017/08/30 08:28:19 step 3: mse=190456.158787 step=0.050000
2017/08/30 08:28:21 step 4: mse=188018.412146 step=0.050000
2017/08/30 08:28:22 step 5: mse=188163.737794 step=0.050000
2017/08/30 08:28:23 step 6: mse=187365.123746 step=0.050000
2017/08/30 08:28:24 step 7: mse=188674.852684 step=0.050000
2017/08/30 08:28:24 Saving...
2017/08/30 08:28:24 Gathering batch of experience...
2017/08/30 08:28:57 batch 919: mean=10618.695652 stddev=10073.571127 entropy=0.344664 frames=6738 count=23
2017/08/30 08:28:57 Training policy...
2017/08/30 08:29:03 tune 0: objective=60.966663 reg=0.003447 prune=0
2017/08/30 08:29:05 step 0: objective=61.024901 reg=0.003446
2017/08/30 08:29:07 step 1: objective=61.081543 reg=0.003446
2017/08/30 08:29:09 step 2: objective=61.157382 reg=0.003446
2017/08/30 08:29:11 step 3: objective=61.222061 reg=0.003446
2017/08/30 08:29:13 step 4: objective=61.284135 reg=0.003446
2017/08/30 08:29:15 step 5: objective=61.336070 reg=0.003446
2017/08/30 08:29:17 step 6: objective=61.358206 reg=0.003446
2017/08/30 08:29:19 step 7: objective=61.386817 reg=0.003446
2017/08/30 08:29:19 Training value function...
2017/08/30 08:29:21 step 0: mse=224542.918497 step=0.050000
2017/08/30 08:29:23 step 1: mse=225366.224728 step=0.050000
2017/08/30 08:29:24 step 2: mse=226842.362636 step=0.050000
2017/08/30 08:29:25 step 3: mse=229102.169534 step=0.050000
2017/08/30 08:29:26 step 4: mse=230703.912285 step=0.050000
2017/08/30 08:29:27 step 5: mse=227357.178129 step=0.050000
2017/08/30 08:29:28 step 6: mse=228572.562642 step=0.050000
2017/08/30 08:29:29 step 7: mse=225053.782840 step=0.050000
2017/08/30 08:29:29 Saving...
2017/08/30 08:29:29 Gathering batch of experience...
2017/08/30 08:30:01 batch 920: mean=12427.142857 stddev=10096.164709 entropy=0.342616 frames=6829 count=21
2017/08/30 08:30:01 Training policy...
2017/08/30 08:30:07 tune 0: objective=76.444424 reg=0.003426 prune=0
2017/08/30 08:30:09 step 0: objective=76.544717 reg=0.003426
2017/08/30 08:30:11 step 1: objective=76.606407 reg=0.003425
2017/08/30 08:30:13 step 2: objective=76.653125 reg=0.003425
2017/08/30 08:30:15 step 3: objective=76.703484 reg=0.003425
2017/08/30 08:30:16 step 4: objective=76.741420 reg=0.003424
2017/08/30 08:30:18 step 5: objective=76.765902 reg=0.003424
2017/08/30 08:30:20 step 6: objective=76.793619 reg=0.003424
2017/08/30 08:30:22 step 7: objective=76.817881 reg=0.003423
2017/08/30 08:30:22 Training value function...
2017/08/30 08:30:25 step 0: mse=198939.581090 step=0.050000
2017/08/30 08:30:26 step 1: mse=198667.873446 step=0.050000
2017/08/30 08:30:27 step 2: mse=199803.612935 step=0.050000
2017/08/30 08:30:29 step 3: mse=199584.944987 step=0.050000
2017/08/30 08:30:30 step 4: mse=200066.603196 step=0.050000
2017/08/30 08:30:31 step 5: mse=200235.601710 step=0.050000
2017/08/30 08:30:32 step 6: mse=201990.191000 step=0.050000
2017/08/30 08:30:33 step 7: mse=201650.388664 step=0.050000
2017/08/30 08:30:33 Saving...
2017/08/30 08:30:33 Gathering batch of experience...
2017/08/30 08:31:08 batch 921: mean=11498.541667 stddev=9959.319283 entropy=0.339818 frames=7470 count=24
2017/08/30 08:31:08 Training policy...
2017/08/30 08:31:15 tune 0: objective=70.563161 reg=0.003398 prune=0
2017/08/30 08:31:17 step 0: objective=70.626941 reg=0.003398
2017/08/30 08:31:19 step 1: objective=70.692997 reg=0.003398
2017/08/30 08:31:21 step 2: objective=70.746954 reg=0.003398
2017/08/30 08:31:23 step 3: objective=70.826606 reg=0.003399
2017/08/30 08:31:25 step 4: objective=70.865872 reg=0.003398
2017/08/30 08:31:28 step 5: objective=70.904970 reg=0.003398
2017/08/30 08:31:30 step 6: objective=70.950996 reg=0.003397
2017/08/30 08:31:32 step 7: objective=70.989500 reg=0.003397
2017/08/30 08:31:32 Training value function...
2017/08/30 08:31:35 step 0: mse=211589.776277 step=0.050000
2017/08/30 08:31:36 step 1: mse=209883.142810 step=0.050000
2017/08/30 08:31:37 step 2: mse=210456.804067 step=0.050000
2017/08/30 08:31:39 step 3: mse=210425.307040 step=0.050000
2017/08/30 08:31:40 step 4: mse=209029.919494 step=0.050000
2017/08/30 08:31:41 step 5: mse=208680.455411 step=0.050000
2017/08/30 08:31:42 step 6: mse=208618.253570 step=0.050000
2017/08/30 08:31:44 step 7: mse=208780.841313 step=0.050000
2017/08/30 08:31:44 Saving...
2017/08/30 08:31:44 Gathering batch of experience...
2017/08/30 08:32:15 batch 922: mean=12520.250000 stddev=9762.576949 entropy=0.336369 frames=6683 count=20
2017/08/30 08:32:15 Training policy...
2017/08/30 08:32:21 tune 0: objective=63.331700 reg=0.003364 prune=0
2017/08/30 08:32:23 step 0: objective=63.433076 reg=0.003363
2017/08/30 08:32:25 step 1: objective=63.529632 reg=0.003362
2017/08/30 08:32:27 step 2: objective=63.632725 reg=0.003362
2017/08/30 08:32:28 step 3: objective=63.687140 reg=0.003362
2017/08/30 08:32:30 step 4: objective=63.745675 reg=0.003361
2017/08/30 08:32:32 step 5: objective=63.786604 reg=0.003362
2017/08/30 08:32:34 step 6: objective=63.827865 reg=0.003362
2017/08/30 08:32:36 step 7: objective=63.862010 reg=0.003362
2017/08/30 08:32:36 Training value function...
2017/08/30 08:32:39 step 0: mse=201035.542719 step=0.050000
2017/08/30 08:32:40 step 1: mse=201161.567984 step=0.050000
2017/08/30 08:32:41 step 2: mse=201767.985771 step=0.050000
2017/08/30 08:32:42 step 3: mse=204342.720086 step=0.050000
2017/08/30 08:32:43 step 4: mse=203062.335664 step=0.050000
2017/08/30 08:32:44 step 5: mse=203529.769024 step=0.050000
2017/08/30 08:32:45 step 6: mse=204093.965804 step=0.050000
2017/08/30 08:32:46 step 7: mse=204042.007237 step=0.050000
2017/08/30 08:32:46 Saving...
2017/08/30 08:32:47 Gathering batch of experience...
2017/08/30 08:33:19 batch 923: mean=15575.000000 stddev=9945.506655 entropy=0.341373 frames=7073 count=19
2017/08/30 08:33:19 Training policy...
2017/08/30 08:33:25 tune 0: objective=104.436501 reg=0.003414 prune=0
2017/08/30 08:33:27 step 0: objective=104.494672 reg=0.003414
2017/08/30 08:33:29 step 1: objective=104.565230 reg=0.003415
2017/08/30 08:33:31 step 2: objective=104.638043 reg=0.003416
2017/08/30 08:33:33 step 3: objective=104.695797 reg=0.003416
2017/08/30 08:33:35 step 4: objective=104.754975 reg=0.003416
2017/08/30 08:33:37 step 5: objective=104.802824 reg=0.003416
2017/08/30 08:33:39 step 6: objective=104.837162 reg=0.003416
2017/08/30 08:33:41 step 7: objective=104.886558 reg=0.003416
2017/08/30 08:33:41 Training value function...
2017/08/30 08:33:44 step 0: mse=259542.780666 step=0.050000
2017/08/30 08:33:45 step 1: mse=257116.079366 step=0.050000
2017/08/30 08:33:46 step 2: mse=251998.730930 step=0.050000
2017/08/30 08:33:47 step 3: mse=248780.140558 step=0.050000
2017/08/30 08:33:49 step 4: mse=244714.258097 step=0.050000
2017/08/30 08:33:50 step 5: mse=241436.728159 step=0.050000
2017/08/30 08:33:51 step 6: mse=239251.566509 step=0.050000
2017/08/30 08:33:52 step 7: mse=237979.304432 step=0.050000
2017/08/30 08:33:52 Saving...
2017/08/30 08:33:52 Gathering batch of experience...
2017/08/30 08:34:28 batch 924: mean=11572.800000 stddev=10136.382696 entropy=0.340226 frames=7801 count=25
2017/08/30 08:34:28 Training policy...
2017/08/30 08:34:35 tune 0: objective=72.319775 reg=0.003402 prune=0
2017/08/30 08:34:38 step 0: objective=72.353504 reg=0.003402
2017/08/30 08:34:40 step 1: objective=72.385912 reg=0.003402
2017/08/30 08:34:42 step 2: objective=72.408978 reg=0.003402
2017/08/30 08:34:44 step 3: objective=72.458058 reg=0.003402
2017/08/30 08:34:47 step 4: objective=72.505376 reg=0.003402
2017/08/30 08:34:49 step 5: objective=72.539466 reg=0.003401
2017/08/30 08:34:51 step 6: objective=72.571249 reg=0.003401
2017/08/30 08:34:53 step 7: objective=72.591206 reg=0.003401
2017/08/30 08:34:53 Training value function...
2017/08/30 08:34:56 step 0: mse=222407.280703 step=0.050000
2017/08/30 08:34:58 step 1: mse=221825.221887 step=0.050000
2017/08/30 08:34:59 step 2: mse=217636.797644 step=0.050000
2017/08/30 08:35:00 step 3: mse=217284.831268 step=0.050000
2017/08/30 08:35:02 step 4: mse=216340.715781 step=0.050000
2017/08/30 08:35:03 step 5: mse=215469.621092 step=0.050000
2017/08/30 08:35:04 step 6: mse=210191.271688 step=0.050000
2017/08/30 08:35:05 step 7: mse=208102.891876 step=0.050000
2017/08/30 08:35:05 Saving...
2017/08/30 08:35:06 Gathering batch of experience...
2017/08/30 08:35:39 batch 925: mean=12996.818182 stddev=9693.336927 entropy=0.341820 frames=7452 count=22
2017/08/30 08:35:39 Training policy...
2017/08/30 08:35:46 tune 0: objective=62.011591 reg=0.003418 prune=0
2017/08/30 08:35:48 step 0: objective=62.079412 reg=0.003417
2017/08/30 08:35:51 step 1: objective=62.165392 reg=0.003415
2017/08/30 08:35:53 step 2: objective=62.216989 reg=0.003415
2017/08/30 08:35:55 step 3: objective=62.260756 reg=0.003414
2017/08/30 08:35:57 step 4: objective=62.300410 reg=0.003414
2017/08/30 08:35:59 step 5: objective=62.338231 reg=0.003413
2017/08/30 08:36:01 step 6: objective=62.387790 reg=0.003413
2017/08/30 08:36:03 step 7: objective=62.426609 reg=0.003412
2017/08/30 08:36:03 Training value function...
2017/08/30 08:36:06 step 0: mse=231223.561011 step=0.050000
2017/08/30 08:36:08 step 1: mse=232729.105429 step=0.050000
2017/08/30 08:36:09 step 2: mse=234286.951114 step=0.050000
2017/08/30 08:36:10 step 3: mse=234730.144978 step=0.050000
2017/08/30 08:36:11 step 4: mse=235295.288811 step=0.050000
2017/08/30 08:36:13 step 5: mse=235053.452272 step=0.050000
2017/08/30 08:36:14 step 6: mse=236369.615382 step=0.050000
2017/08/30 08:36:15 step 7: mse=237555.533680 step=0.050000
2017/08/30 08:36:15 Saving...
2017/08/30 08:36:15 Gathering batch of experience...
2017/08/30 08:36:50 batch 926: mean=13879.318182 stddev=10031.161935 entropy=0.338392 frames=7627 count=22
2017/08/30 08:36:50 Training policy...
2017/08/30 08:36:57 tune 0: objective=87.317966 reg=0.003384 prune=0
2017/08/30 08:36:59 step 0: objective=87.393372 reg=0.003384
2017/08/30 08:37:01 step 1: objective=87.423282 reg=0.003384
2017/08/30 08:37:04 step 2: objective=87.457257 reg=0.003383
2017/08/30 08:37:06 step 3: objective=87.480603 reg=0.003383
2017/08/30 08:37:08 step 4: objective=87.521396 reg=0.003384
2017/08/30 08:37:10 step 5: objective=87.554428 reg=0.003384
2017/08/30 08:37:12 step 6: objective=87.579332 reg=0.003384
2017/08/30 08:37:14 step 7: objective=87.599163 reg=0.003384
2017/08/30 08:37:14 Training value function...
2017/08/30 08:37:18 step 0: mse=249810.541043 step=0.050000
2017/08/30 08:37:19 step 1: mse=244241.024065 step=0.050000
2017/08/30 08:37:20 step 2: mse=241892.843929 step=0.050000
2017/08/30 08:37:21 step 3: mse=237775.938953 step=0.050000
2017/08/30 08:37:23 step 4: mse=231777.530648 step=0.050000
2017/08/30 08:37:24 step 5: mse=229968.457553 step=0.050000
2017/08/30 08:37:25 step 6: mse=228164.762805 step=0.050000
2017/08/30 08:37:27 step 7: mse=223621.298419 step=0.050000
2017/08/30 08:37:27 Saving...
2017/08/30 08:37:27 Gathering batch of experience...
2017/08/30 08:38:02 batch 927: mean=11097.500000 stddev=10300.622297 entropy=0.339780 frames=7747 count=26
2017/08/30 08:38:02 Training policy...
2017/08/30 08:38:09 tune 0: objective=71.028656 reg=0.003398 prune=0
2017/08/30 08:38:11 step 0: objective=71.071996 reg=0.003398
2017/08/30 08:38:14 step 1: objective=71.117287 reg=0.003397
2017/08/30 08:38:16 step 2: objective=71.170437 reg=0.003396
2017/08/30 08:38:18 step 3: objective=71.208403 reg=0.003396
2017/08/30 08:38:20 step 4: objective=71.249371 reg=0.003396
2017/08/30 08:38:23 step 5: objective=71.274187 reg=0.003396
2017/08/30 08:38:25 step 6: objective=71.296744 reg=0.003396
2017/08/30 08:38:27 step 7: objective=71.328369 reg=0.003395
2017/08/30 08:38:27 Training value function...
2017/08/30 08:38:30 step 0: mse=195371.888118 step=0.050000
2017/08/30 08:38:31 step 1: mse=195760.907021 step=0.050000
2017/08/30 08:38:33 step 2: mse=192964.005382 step=0.050000
2017/08/30 08:38:34 step 3: mse=192232.324629 step=0.050000
2017/08/30 08:38:35 step 4: mse=191738.678468 step=0.050000
2017/08/30 08:38:37 step 5: mse=191253.030289 step=0.050000
2017/08/30 08:38:38 step 6: mse=187495.081588 step=0.050000
2017/08/30 08:38:39 step 7: mse=186562.101046 step=0.050000
2017/08/30 08:38:39 Saving...
2017/08/30 08:38:39 Gathering batch of experience...
2017/08/30 08:39:09 batch 928: mean=12578.000000 stddev=10059.762472 entropy=0.342425 frames=6509 count=20
2017/08/30 08:39:09 Training policy...
2017/08/30 08:39:15 tune 0: objective=67.553023 reg=0.003424 prune=0
2017/08/30 08:39:17 step 0: objective=67.598076 reg=0.003424
2017/08/30 08:39:19 step 1: objective=67.632211 reg=0.003423
2017/08/30 08:39:21 step 2: objective=67.681475 reg=0.003423
2017/08/30 08:39:23 step 3: objective=67.717204 reg=0.003423
2017/08/30 08:39:25 step 4: objective=67.754350 reg=0.003423
2017/08/30 08:39:27 step 5: objective=67.799100 reg=0.003422
2017/08/30 08:39:28 step 6: objective=67.862493 reg=0.003421
2017/08/30 08:39:30 step 7: objective=67.895654 reg=0.003420
2017/08/30 08:39:30 Training value function...
2017/08/30 08:39:33 step 0: mse=179980.207251 step=0.050000
2017/08/30 08:39:34 step 1: mse=181732.559173 step=0.050000
2017/08/30 08:39:35 step 2: mse=182645.366360 step=0.050000
2017/08/30 08:39:36 step 3: mse=182036.210695 step=0.050000
2017/08/30 08:39:37 step 4: mse=182607.264029 step=0.050000
2017/08/30 08:39:38 step 5: mse=183505.551212 step=0.050000
2017/08/30 08:39:39 step 6: mse=184070.367082 step=0.050000
2017/08/30 08:39:40 step 7: mse=183182.931797 step=0.050000
2017/08/30 08:39:40 Saving...
2017/08/30 08:39:41 Gathering batch of experience...
2017/08/30 08:40:14 batch 929: mean=15955.526316 stddev=9531.001617 entropy=0.339021 frames=7358 count=19
2017/08/30 08:40:14 Training policy...
2017/08/30 08:40:21 tune 0: objective=89.392744 reg=0.003390 prune=0
2017/08/30 08:40:23 step 0: objective=89.452067 reg=0.003390
2017/08/30 08:40:25 step 1: objective=89.493553 reg=0.003390
2017/08/30 08:40:27 step 2: objective=89.524548 reg=0.003389
2017/08/30 08:40:29 step 3: objective=89.581000 reg=0.003389
2017/08/30 08:40:32 step 4: objective=89.636042 reg=0.003389
2017/08/30 08:40:34 step 5: objective=89.658509 reg=0.003389
2017/08/30 08:40:36 step 6: objective=89.692809 reg=0.003388
2017/08/30 08:40:38 step 7: objective=89.734668 reg=0.003387
2017/08/30 08:40:38 Training value function...
2017/08/30 08:40:41 step 0: mse=224754.734133 step=0.050000
2017/08/30 08:40:42 step 1: mse=221679.597681 step=0.050000
2017/08/30 08:40:43 step 2: mse=218120.692612 step=0.050000
2017/08/30 08:40:45 step 3: mse=215702.746441 step=0.050000
2017/08/30 08:40:46 step 4: mse=216308.719042 step=0.050000
2017/08/30 08:40:47 step 5: mse=214952.917587 step=0.050000
2017/08/30 08:40:48 step 6: mse=215582.180952 step=0.050000
2017/08/30 08:40:50 step 7: mse=216370.025010 step=0.050000
2017/08/30 08:40:50 Saving...
2017/08/30 08:40:50 Gathering batch of experience...
2017/08/30 08:41:26 batch 930: mean=9837.758621 stddev=10107.018267 entropy=0.341941 frames=7656 count=29
2017/08/30 08:41:26 Training policy...
2017/08/30 08:41:33 tune 0: objective=57.789495 reg=0.003419 prune=0
2017/08/30 08:41:35 step 0: objective=57.835174 reg=0.003419
2017/08/30 08:41:37 step 1: objective=57.872347 reg=0.003419
2017/08/30 08:41:40 step 2: objective=57.910671 reg=0.003419
2017/08/30 08:41:42 step 3: objective=57.950941 reg=0.003419
2017/08/30 08:41:44 step 4: objective=57.981852 reg=0.003419
2017/08/30 08:41:46 step 5: objective=58.026940 reg=0.003419
2017/08/30 08:41:48 step 6: objective=58.057381 reg=0.003420
2017/08/30 08:41:51 step 7: objective=58.097926 reg=0.003420
2017/08/30 08:41:51 Training value function...
2017/08/30 08:41:54 step 0: mse=193830.821238 step=0.050000
2017/08/30 08:41:55 step 1: mse=195258.269279 step=0.050000
2017/08/30 08:41:56 step 2: mse=196968.762096 step=0.050000
2017/08/30 08:41:58 step 3: mse=198243.399759 step=0.050000
2017/08/30 08:41:59 step 4: mse=197067.572330 step=0.050000
2017/08/30 08:42:00 step 5: mse=198226.361354 step=0.050000
2017/08/30 08:42:01 step 6: mse=200238.168488 step=0.050000
2017/08/30 08:42:03 step 7: mse=198732.017147 step=0.050000
2017/08/30 08:42:03 Saving...
2017/08/30 08:42:03 Gathering batch of experience...
2017/08/30 08:42:33 batch 931: mean=13347.894737 stddev=10224.619195 entropy=0.339788 frames=6428 count=19
2017/08/30 08:42:33 Training policy...
2017/08/30 08:42:39 tune 0: objective=81.525052 reg=0.003398 prune=0
2017/08/30 08:42:41 step 0: objective=81.597464 reg=0.003399
2017/08/30 08:42:43 step 1: objective=81.658185 reg=0.003399
2017/08/30 08:42:44 step 2: objective=81.696805 reg=0.003400
2017/08/30 08:42:46 step 3: objective=81.735425 reg=0.003400
2017/08/30 08:42:48 step 4: objective=81.771099 reg=0.003400
2017/08/30 08:42:50 step 5: objective=81.803137 reg=0.003401
2017/08/30 08:42:52 step 6: objective=81.845238 reg=0.003400
2017/08/30 08:42:54 step 7: objective=81.873678 reg=0.003400
2017/08/30 08:42:54 Training value function...
2017/08/30 08:42:56 step 0: mse=207005.616014 step=0.050000
2017/08/30 08:42:57 step 1: mse=205442.259406 step=0.050000
2017/08/30 08:42:58 step 2: mse=204516.439698 step=0.050000
2017/08/30 08:42:59 step 3: mse=205172.475675 step=0.050000
2017/08/30 08:43:01 step 4: mse=203016.423696 step=0.050000
2017/08/30 08:43:02 step 5: mse=203774.795498 step=0.050000
2017/08/30 08:43:03 step 6: mse=201609.109019 step=0.050000
2017/08/30 08:43:04 step 7: mse=200726.702804 step=0.050000
2017/08/30 08:43:04 Saving...
2017/08/30 08:43:04 Gathering batch of experience...
2017/08/30 08:43:38 batch 932: mean=11860.833333 stddev=10465.684170 entropy=0.343281 frames=7404 count=24
2017/08/30 08:43:38 Training policy...
2017/08/30 08:43:45 tune 0: objective=75.766005 reg=0.003433 prune=0
2017/08/30 08:43:47 step 0: objective=75.800750 reg=0.003433
2017/08/30 08:43:49 step 1: objective=75.839200 reg=0.003432
2017/08/30 08:43:51 step 2: objective=75.886261 reg=0.003432
2017/08/30 08:43:53 step 3: objective=75.930418 reg=0.003432
2017/08/30 08:43:56 step 4: objective=75.948803 reg=0.003432
2017/08/30 08:43:58 step 5: objective=75.972490 reg=0.003432
2017/08/30 08:44:00 step 6: objective=75.996691 reg=0.003432
2017/08/30 08:44:02 step 7: objective=76.024843 reg=0.003432
2017/08/30 08:44:02 Training value function...
2017/08/30 08:44:05 step 0: mse=184165.801774 step=0.050000
2017/08/30 08:44:06 step 1: mse=182606.762241 step=0.050000
2017/08/30 08:44:07 step 2: mse=183204.706160 step=0.050000
2017/08/30 08:44:09 step 3: mse=184355.306275 step=0.050000
2017/08/30 08:44:10 step 4: mse=185178.372399 step=0.050000
2017/08/30 08:44:11 step 5: mse=185685.252572 step=0.050000
2017/08/30 08:44:12 step 6: mse=187238.969283 step=0.050000
2017/08/30 08:44:14 step 7: mse=187340.194390 step=0.050000
2017/08/30 08:44:14 Saving...
2017/08/30 08:44:14 Gathering batch of experience...
2017/08/30 08:44:48 batch 933: mean=10796.800000 stddev=10081.850513 entropy=0.340347 frames=7397 count=25
2017/08/30 08:44:48 Training policy...
2017/08/30 08:44:55 tune 0: objective=64.661831 reg=0.003403 prune=0
2017/08/30 08:44:57 step 0: objective=64.695582 reg=0.003403
2017/08/30 08:44:59 step 1: objective=64.741246 reg=0.003402
2017/08/30 08:45:01 step 2: objective=64.773924 reg=0.003402
2017/08/30 08:45:03 step 3: objective=64.811148 reg=0.003401
2017/08/30 08:45:06 step 4: objective=64.830962 reg=0.003402
2017/08/30 08:45:08 step 5: objective=64.852913 reg=0.003401
2017/08/30 08:45:10 step 6: objective=64.874996 reg=0.003401
2017/08/30 08:45:12 step 7: objective=64.895460 reg=0.003401
2017/08/30 08:45:12 Training value function...
2017/08/30 08:45:15 step 0: mse=190671.828362 step=0.050000
2017/08/30 08:45:16 step 1: mse=190288.026630 step=0.050000
2017/08/30 08:45:17 step 2: mse=189267.462772 step=0.050000
2017/08/30 08:45:19 step 3: mse=187589.600493 step=0.050000
2017/08/30 08:45:20 step 4: mse=188987.182128 step=0.050000
2017/08/30 08:45:21 step 5: mse=189521.184367 step=0.050000
2017/08/30 08:45:22 step 6: mse=190536.176605 step=0.050000
2017/08/30 08:45:24 step 7: mse=192455.038705 step=0.050000
2017/08/30 08:45:24 Saving...
2017/08/30 08:45:24 Gathering batch of experience...
2017/08/30 08:45:56 batch 934: mean=13527.368421 stddev=9954.593011 entropy=0.339770 frames=6657 count=19
2017/08/30 08:45:56 Training policy...
2017/08/30 08:46:02 tune 0: objective=77.351768 reg=0.003398 prune=0
2017/08/30 08:46:04 step 0: objective=77.416695 reg=0.003398
2017/08/30 08:46:06 step 1: objective=77.471454 reg=0.003398
2017/08/30 08:46:08 step 2: objective=77.519510 reg=0.003398
2017/08/30 08:46:10 step 3: objective=77.567894 reg=0.003399
2017/08/30 08:46:12 step 4: objective=77.614532 reg=0.003399
2017/08/30 08:46:14 step 5: objective=77.653255 reg=0.003398
2017/08/30 08:46:16 step 6: objective=77.683688 reg=0.003398
2017/08/30 08:46:18 step 7: objective=77.720933 reg=0.003398
2017/08/30 08:46:18 Training value function...
2017/08/30 08:46:20 step 0: mse=192472.728760 step=0.050000
2017/08/30 08:46:21 step 1: mse=191970.837099 step=0.050000
2017/08/30 08:46:23 step 2: mse=191817.239854 step=0.050000
2017/08/30 08:46:24 step 3: mse=191564.761828 step=0.050000
2017/08/30 08:46:25 step 4: mse=192014.650983 step=0.050000
2017/08/30 08:46:26 step 5: mse=191647.997095 step=0.050000
2017/08/30 08:46:27 step 6: mse=190122.066343 step=0.050000
2017/08/30 08:46:28 step 7: mse=190503.506213 step=0.050000
2017/08/30 08:46:28 Saving...
2017/08/30 08:46:28 Gathering batch of experience...
2017/08/30 08:47:03 batch 935: mean=16170.750000 stddev=9482.951054 entropy=0.335570 frames=7734 count=20
2017/08/30 08:47:03 Training policy...
2017/08/30 08:47:10 tune 0: objective=92.407495 reg=0.003356 prune=0
2017/08/30 08:47:12 step 0: objective=92.473655 reg=0.003355
2017/08/30 08:47:15 step 1: objective=92.511823 reg=0.003355
2017/08/30 08:47:17 step 2: objective=92.581903 reg=0.003355
2017/08/30 08:47:19 step 3: objective=92.619327 reg=0.003354
2017/08/30 08:47:21 step 4: objective=92.642706 reg=0.003354
2017/08/30 08:47:24 step 5: objective=92.671418 reg=0.003354
2017/08/30 08:47:26 step 6: objective=92.705529 reg=0.003354
2017/08/30 08:47:28 step 7: objective=92.726734 reg=0.003353
2017/08/30 08:47:28 Training value function...
2017/08/30 08:47:31 step 0: mse=213891.081785 step=0.050000
2017/08/30 08:47:33 step 1: mse=212614.217650 step=0.050000
2017/08/30 08:47:34 step 2: mse=212755.184853 step=0.050000
2017/08/30 08:47:35 step 3: mse=213282.817866 step=0.050000
2017/08/30 08:47:36 step 4: mse=210292.640374 step=0.050000
2017/08/30 08:47:38 step 5: mse=210568.230909 step=0.050000
2017/08/30 08:47:39 step 6: mse=209673.678065 step=0.050000
2017/08/30 08:47:40 step 7: mse=208959.197317 step=0.050000
2017/08/30 08:47:40 Saving...
2017/08/30 08:47:40 Gathering batch of experience...
2017/08/30 08:48:15 batch 936: mean=15950.000000 stddev=8979.205070 entropy=0.336754 frames=7493 count=19
2017/08/30 08:48:15 Training policy...
2017/08/30 08:48:22 tune 0: objective=79.408873 reg=0.003368 prune=0
2017/08/30 08:48:24 step 0: objective=79.454491 reg=0.003368
2017/08/30 08:48:26 step 1: objective=79.488698 reg=0.003368
2017/08/30 08:48:28 step 2: objective=79.519710 reg=0.003368
2017/08/30 08:48:31 step 3: objective=79.553225 reg=0.003368
2017/08/30 08:48:33 step 4: objective=79.587540 reg=0.003368
2017/08/30 08:48:35 step 5: objective=79.615416 reg=0.003367
2017/08/30 08:48:37 step 6: objective=79.645386 reg=0.003367
2017/08/30 08:48:39 step 7: objective=79.681753 reg=0.003367
2017/08/30 08:48:39 Training value function...
2017/08/30 08:48:42 step 0: mse=233980.991084 step=0.050000
2017/08/30 08:48:44 step 1: mse=232801.093382 step=0.050000
2017/08/30 08:48:45 step 2: mse=232294.995084 step=0.050000
2017/08/30 08:48:46 step 3: mse=232281.151697 step=0.050000
2017/08/30 08:48:47 step 4: mse=228782.545799 step=0.050000
2017/08/30 08:48:49 step 5: mse=225552.637464 step=0.050000
2017/08/30 08:48:50 step 6: mse=225251.306860 step=0.050000
2017/08/30 08:48:51 step 7: mse=226340.450263 step=0.050000
2017/08/30 08:48:51 Saving...
2017/08/30 08:48:51 Gathering batch of experience...
2017/08/30 08:49:24 batch 937: mean=15845.000000 stddev=9444.287662 entropy=0.335685 frames=6935 count=18
2017/08/30 08:49:24 Training policy...
2017/08/30 08:49:30 tune 0: objective=85.968484 reg=0.003357 prune=0
2017/08/30 08:49:32 step 0: objective=86.046999 reg=0.003356
2017/08/30 08:49:34 step 1: objective=86.079335 reg=0.003356
2017/08/30 08:49:36 step 2: objective=86.150135 reg=0.003355
2017/08/30 08:49:38 step 3: objective=86.190240 reg=0.003355
2017/08/30 08:49:40 step 4: objective=86.218836 reg=0.003354
2017/08/30 08:49:42 step 5: objective=86.249441 reg=0.003354
2017/08/30 08:49:44 step 6: objective=86.275982 reg=0.003354
2017/08/30 08:49:46 step 7: objective=86.298053 reg=0.003354
2017/08/30 08:49:46 Training value function...
2017/08/30 08:49:49 step 0: mse=237293.393255 step=0.050000
2017/08/30 08:49:50 step 1: mse=237387.877231 step=0.050000
2017/08/30 08:49:51 step 2: mse=238923.246915 step=0.050000
2017/08/30 08:49:52 step 3: mse=239765.532836 step=0.050000
2017/08/30 08:49:53 step 4: mse=240732.278782 step=0.050000
2017/08/30 08:49:55 step 5: mse=236162.538123 step=0.050000
2017/08/30 08:49:56 step 6: mse=234074.586491 step=0.050000
2017/08/30 08:49:57 step 7: mse=231488.218618 step=0.050000
2017/08/30 08:49:57 Saving...
2017/08/30 08:49:57 Gathering batch of experience...
2017/08/30 08:50:32 batch 938: mean=14124.000000 stddev=10113.932297 entropy=0.339381 frames=7263 count=20
2017/08/30 08:50:32 Training policy...
2017/08/30 08:50:38 tune 0: objective=67.426081 reg=0.003394 prune=0
2017/08/30 08:50:40 step 0: objective=67.469512 reg=0.003394
2017/08/30 08:50:42 step 1: objective=67.510017 reg=0.003394
2017/08/30 08:50:45 step 2: objective=67.551640 reg=0.003393
2017/08/30 08:50:47 step 3: objective=67.600514 reg=0.003394
2017/08/30 08:50:49 step 4: objective=67.644512 reg=0.003393
2017/08/30 08:50:51 step 5: objective=67.696505 reg=0.003393
2017/08/30 08:50:53 step 6: objective=67.718505 reg=0.003393
2017/08/30 08:50:55 step 7: objective=67.755426 reg=0.003394
2017/08/30 08:50:55 Training value function...
2017/08/30 08:50:58 step 0: mse=182359.129146 step=0.050000
2017/08/30 08:50:59 step 1: mse=182330.069504 step=0.050000
2017/08/30 08:51:00 step 2: mse=183629.629725 step=0.050000
2017/08/30 08:51:02 step 3: mse=183452.781054 step=0.050000
2017/08/30 08:51:03 step 4: mse=184184.994171 step=0.050000
2017/08/30 08:51:04 step 5: mse=184527.214965 step=0.050000
2017/08/30 08:51:05 step 6: mse=183488.143672 step=0.050000
2017/08/30 08:51:07 step 7: mse=183130.667734 step=0.050000
2017/08/30 08:51:07 Saving...
2017/08/30 08:51:07 Gathering batch of experience...
2017/08/30 08:51:41 batch 939: mean=14690.000000 stddev=9789.506755 entropy=0.336351 frames=7243 count=20
2017/08/30 08:51:41 Training policy...
2017/08/30 08:51:47 tune 0: objective=76.763133 reg=0.003364 prune=0
2017/08/30 08:51:49 step 0: objective=76.813294 reg=0.003363
2017/08/30 08:51:51 step 1: objective=76.872964 reg=0.003363
2017/08/30 08:51:54 step 2: objective=76.939364 reg=0.003362
2017/08/30 08:51:56 step 3: objective=76.982190 reg=0.003362
2017/08/30 08:51:58 step 4: objective=77.032195 reg=0.003362
2017/08/30 08:52:00 step 5: objective=77.059687 reg=0.003361
2017/08/30 08:52:02 step 6: objective=77.092935 reg=0.003361
2017/08/30 08:52:04 step 7: objective=77.123162 reg=0.003360
2017/08/30 08:52:04 Training value function...
2017/08/30 08:52:07 step 0: mse=199347.759650 step=0.050000
2017/08/30 08:52:08 step 1: mse=199172.627031 step=0.050000
2017/08/30 08:52:09 step 2: mse=197271.941859 step=0.050000
2017/08/30 08:52:11 step 3: mse=197217.176780 step=0.050000
2017/08/30 08:52:12 step 4: mse=195586.300897 step=0.050000
2017/08/30 08:52:13 step 5: mse=196041.395414 step=0.050000
2017/08/30 08:52:14 step 6: mse=197280.671184 step=0.050000
2017/08/30 08:52:15 step 7: mse=196396.439481 step=0.050000
2017/08/30 08:52:15 Saving...
2017/08/30 08:52:15 Gathering batch of experience...
2017/08/30 08:52:52 batch 940: mean=10114.629630 stddev=10133.381024 entropy=0.337654 frames=7558 count=27
2017/08/30 08:52:52 Training policy...
2017/08/30 08:52:59 tune 0: objective=54.110806 reg=0.003377 prune=0
2017/08/30 08:53:01 step 0: objective=54.156407 reg=0.003377
2017/08/30 08:53:03 step 1: objective=54.193723 reg=0.003377
2017/08/30 08:53:06 step 2: objective=54.232787 reg=0.003377
2017/08/30 08:53:08 step 3: objective=54.258356 reg=0.003377
2017/08/30 08:53:10 step 4: objective=54.290644 reg=0.003378
2017/08/30 08:53:12 step 5: objective=54.322973 reg=0.003378
2017/08/30 08:53:14 step 6: objective=54.359611 reg=0.003377
2017/08/30 08:53:17 step 7: objective=54.390919 reg=0.003377
2017/08/30 08:53:17 Training value function...
2017/08/30 08:53:20 step 0: mse=176870.005240 step=0.050000
2017/08/30 08:53:21 step 1: mse=176885.520228 step=0.050000
2017/08/30 08:53:22 step 2: mse=177996.878787 step=0.050000
2017/08/30 08:53:24 step 3: mse=179501.021564 step=0.050000
2017/08/30 08:53:25 step 4: mse=180560.486915 step=0.050000
2017/08/30 08:53:26 step 5: mse=181465.078256 step=0.050000
2017/08/30 08:53:27 step 6: mse=181671.865637 step=0.050000
2017/08/30 08:53:28 step 7: mse=180402.745839 step=0.050000
2017/08/30 08:53:28 Saving...
2017/08/30 08:53:29 Gathering batch of experience...
2017/08/30 08:54:03 batch 941: mean=13040.000000 stddev=9623.128018 entropy=0.336743 frames=7171 count=21
2017/08/30 08:54:03 Training policy...
2017/08/30 08:54:09 tune 0: objective=69.630948 reg=0.003367 prune=0
2017/08/30 08:54:11 step 0: objective=69.723805 reg=0.003367
2017/08/30 08:54:13 step 1: objective=69.778008 reg=0.003367
2017/08/30 08:54:16 step 2: objective=69.830790 reg=0.003367
2017/08/30 08:54:18 step 3: objective=69.912364 reg=0.003366
2017/08/30 08:54:20 step 4: objective=69.950251 reg=0.003365
2017/08/30 08:54:22 step 5: objective=69.973130 reg=0.003365
2017/08/30 08:54:24 step 6: objective=70.021122 reg=0.003363
2017/08/30 08:54:26 step 7: objective=70.058247 reg=0.003364
2017/08/30 08:54:26 Training value function...
2017/08/30 08:54:29 step 0: mse=222842.136088 step=0.050000
2017/08/30 08:54:30 step 1: mse=223967.303894 step=0.050000
2017/08/30 08:54:31 step 2: mse=222829.411788 step=0.050000
2017/08/30 08:54:33 step 3: mse=221992.226237 step=0.050000
2017/08/30 08:54:34 step 4: mse=220209.206017 step=0.050000
2017/08/30 08:54:35 step 5: mse=221381.278106 step=0.050000
2017/08/30 08:54:36 step 6: mse=222771.760476 step=0.050000
2017/08/30 08:54:37 step 7: mse=223069.881797 step=0.050000
2017/08/30 08:54:37 Saving...
2017/08/30 08:54:37 Gathering batch of experience...
2017/08/30 08:55:11 batch 942: mean=12614.047619 stddev=10020.617391 entropy=0.337458 frames=6892 count=21
2017/08/30 08:55:11 Training policy...
2017/08/30 08:55:17 tune 0: objective=70.228517 reg=0.003375 prune=0
2017/08/30 08:55:19 step 0: objective=70.297918 reg=0.003375
2017/08/30 08:55:21 step 1: objective=70.352555 reg=0.003376
2017/08/30 08:55:23 step 2: objective=70.403026 reg=0.003377
2017/08/30 08:55:25 step 3: objective=70.459935 reg=0.003378
2017/08/30 08:55:27 step 4: objective=70.497007 reg=0.003378
2017/08/30 08:55:29 step 5: objective=70.529971 reg=0.003379
2017/08/30 08:55:31 step 6: objective=70.578769 reg=0.003379
2017/08/30 08:55:33 step 7: objective=70.619205 reg=0.003379
2017/08/30 08:55:33 Training value function...
2017/08/30 08:55:36 step 0: mse=194825.463878 step=0.050000
2017/08/30 08:55:37 step 1: mse=196070.358488 step=0.050000
2017/08/30 08:55:38 step 2: mse=197377.616863 step=0.050000
2017/08/30 08:55:39 step 3: mse=197408.745352 step=0.050000
2017/08/30 08:55:40 step 4: mse=196722.026719 step=0.050000
2017/08/30 08:55:42 step 5: mse=197090.350545 step=0.050000
2017/08/30 08:55:43 step 6: mse=197411.016180 step=0.050000
2017/08/30 08:55:44 step 7: mse=198806.651183 step=0.050000
2017/08/30 08:55:44 Saving...
2017/08/30 08:55:44 Gathering batch of experience...
2017/08/30 08:56:19 batch 943: mean=12594.782609 stddev=10161.011427 entropy=0.336419 frames=7441 count=23
2017/08/30 08:56:19 Training policy...
2017/08/30 08:56:25 tune 0: objective=83.389413 reg=0.003364 prune=0
2017/08/30 08:56:28 step 0: objective=83.459288 reg=0.003364
2017/08/30 08:56:30 step 1: objective=83.539057 reg=0.003365
2017/08/30 08:56:32 step 2: objective=83.628175 reg=0.003366
2017/08/30 08:56:34 step 3: objective=83.668492 reg=0.003366
2017/08/30 08:56:36 step 4: objective=83.730026 reg=0.003366
2017/08/30 08:56:39 step 5: objective=83.760130 reg=0.003367
2017/08/30 08:56:41 step 6: objective=83.796088 reg=0.003367
2017/08/30 08:56:43 step 7: objective=83.825082 reg=0.003366
2017/08/30 08:56:43 Training value function...
2017/08/30 08:56:46 step 0: mse=245863.653134 step=0.050000
2017/08/30 08:56:47 step 1: mse=244766.804949 step=0.050000
2017/08/30 08:56:48 step 2: mse=244138.310954 step=0.050000
2017/08/30 08:56:50 step 3: mse=239321.576661 step=0.050000
2017/08/30 08:56:51 step 4: mse=239675.211184 step=0.050000
2017/08/30 08:56:52 step 5: mse=239131.536594 step=0.050000
2017/08/30 08:56:53 step 6: mse=235045.344098 step=0.050000
2017/08/30 08:56:55 step 7: mse=231632.476431 step=0.050000
2017/08/30 08:56:55 Saving...
2017/08/30 08:56:55 Gathering batch of experience...
2017/08/30 08:57:28 batch 944: mean=14428.684211 stddev=9919.220688 entropy=0.337476 frames=6912 count=19
2017/08/30 08:57:28 Training policy...
2017/08/30 08:57:34 tune 0: objective=78.501465 reg=0.003375 prune=0
2017/08/30 08:57:36 step 0: objective=78.558883 reg=0.003375
2017/08/30 08:57:38 step 1: objective=78.612006 reg=0.003374
2017/08/30 08:57:40 step 2: objective=78.654921 reg=0.003374
2017/08/30 08:57:42 step 3: objective=78.692401 reg=0.003373
2017/08/30 08:57:44 step 4: objective=78.739809 reg=0.003373
2017/08/30 08:57:46 step 5: objective=78.785455 reg=0.003372
2017/08/30 08:57:48 step 6: objective=78.836959 reg=0.003372
2017/08/30 08:57:50 step 7: objective=78.872486 reg=0.003372
2017/08/30 08:57:50 Training value function...
2017/08/30 08:57:53 step 0: mse=232996.698676 step=0.050000
2017/08/30 08:57:54 step 1: mse=230828.997727 step=0.050000
2017/08/30 08:57:55 step 2: mse=230944.172350 step=0.050000
2017/08/30 08:57:57 step 3: mse=226645.406196 step=0.050000
2017/08/30 08:57:58 step 4: mse=226628.179766 step=0.050000
2017/08/30 08:57:59 step 5: mse=224962.028185 step=0.050000
2017/08/30 08:58:00 step 6: mse=225409.824834 step=0.050000
2017/08/30 08:58:01 step 7: mse=223391.711152 step=0.050000
2017/08/30 08:58:01 Saving...
2017/08/30 08:58:01 Gathering batch of experience...
2017/08/30 08:58:38 batch 945: mean=12516.458333 stddev=10339.503079 entropy=0.338345 frames=7605 count=24
2017/08/30 08:58:38 Training policy...
2017/08/30 08:58:45 tune 0: objective=81.884772 reg=0.003383 prune=0
2017/08/30 08:58:47 step 0: objective=81.925131 reg=0.003384
2017/08/30 08:58:49 step 1: objective=81.952687 reg=0.003384
2017/08/30 08:58:51 step 2: objective=81.982766 reg=0.003384
2017/08/30 08:58:54 step 3: objective=82.012196 reg=0.003384
2017/08/30 08:58:56 step 4: objective=82.048685 reg=0.003385
2017/08/30 08:58:58 step 5: objective=82.070398 reg=0.003385
2017/08/30 08:59:00 step 6: objective=82.103821 reg=0.003386
2017/08/30 08:59:03 step 7: objective=82.127556 reg=0.003385
2017/08/30 08:59:03 Training value function...
2017/08/30 08:59:06 step 0: mse=229077.141000 step=0.050000
2017/08/30 08:59:07 step 1: mse=229511.011753 step=0.050000
2017/08/30 08:59:08 step 2: mse=225124.288147 step=0.050000
2017/08/30 08:59:09 step 3: mse=219148.031020 step=0.050000
2017/08/30 08:59:11 step 4: mse=217533.487110 step=0.050000
2017/08/30 08:59:12 step 5: mse=212514.464034 step=0.050000
2017/08/30 08:59:13 step 6: mse=208437.022102 step=0.050000
2017/08/30 08:59:14 step 7: mse=207665.937301 step=0.050000
2017/08/30 08:59:14 Saving...
2017/08/30 08:59:14 Gathering batch of experience...
2017/08/30 08:59:46 batch 946: mean=11850.952381 stddev=10039.720355 entropy=0.339831 frames=6676 count=21
2017/08/30 08:59:46 Training policy...
2017/08/30 08:59:52 tune 0: objective=66.152744 reg=0.003398 prune=0
2017/08/30 08:59:54 step 0: objective=66.240835 reg=0.003399
2017/08/30 08:59:56 step 1: objective=66.306125 reg=0.003400
2017/08/30 08:59:58 step 2: objective=66.359881 reg=0.003400
2017/08/30 09:00:00 step 3: objective=66.409059 reg=0.003400
2017/08/30 09:00:02 step 4: objective=66.467856 reg=0.003401
2017/08/30 09:00:04 step 5: objective=66.509512 reg=0.003401
2017/08/30 09:00:06 step 6: objective=66.559130 reg=0.003402
2017/08/30 09:00:08 step 7: objective=66.614061 reg=0.003402
2017/08/30 09:00:08 Training value function...
2017/08/30 09:00:11 step 0: mse=200853.407843 step=0.050000
2017/08/30 09:00:12 step 1: mse=201469.354590 step=0.050000
2017/08/30 09:00:13 step 2: mse=198737.401960 step=0.050000
2017/08/30 09:00:14 step 3: mse=200073.089931 step=0.050000
2017/08/30 09:00:15 step 4: mse=200063.399878 step=0.050000
2017/08/30 09:00:16 step 5: mse=199676.328908 step=0.050000
2017/08/30 09:00:17 step 6: mse=199556.084048 step=0.050000
2017/08/30 09:00:18 step 7: mse=200613.675082 step=0.050000
2017/08/30 09:00:18 Saving...
2017/08/30 09:00:18 Gathering batch of experience...
2017/08/30 09:00:56 batch 947: mean=14259.565217 stddev=10123.305539 entropy=0.335295 frames=8068 count=23
2017/08/30 09:00:56 Training policy...
2017/08/30 09:01:03 tune 0: objective=88.539043 reg=0.003353 prune=0
2017/08/30 09:01:05 step 0: objective=88.585825 reg=0.003353
2017/08/30 09:01:08 step 1: objective=88.627742 reg=0.003353
2017/08/30 09:01:10 step 2: objective=88.661347 reg=0.003354
2017/08/30 09:01:13 step 3: objective=88.715101 reg=0.003355
2017/08/30 09:01:15 step 4: objective=88.755578 reg=0.003354
2017/08/30 09:01:17 step 5: objective=88.806001 reg=0.003354
2017/08/30 09:01:20 step 6: objective=88.845106 reg=0.003355
2017/08/30 09:01:22 step 7: objective=88.879075 reg=0.003354
2017/08/30 09:01:22 Training value function...
2017/08/30 09:01:25 step 0: mse=217315.389732 step=0.050000
2017/08/30 09:01:27 step 1: mse=214702.810277 step=0.050000
2017/08/30 09:01:28 step 2: mse=213023.305604 step=0.050000
2017/08/30 09:01:29 step 3: mse=212975.717369 step=0.050000
2017/08/30 09:01:31 step 4: mse=213138.262832 step=0.050000
2017/08/30 09:01:32 step 5: mse=213853.129115 step=0.050000
2017/08/30 09:01:33 step 6: mse=213971.902992 step=0.050000
2017/08/30 09:01:35 step 7: mse=210975.507752 step=0.050000
2017/08/30 09:01:35 Saving...
2017/08/30 09:01:35 Gathering batch of experience...
2017/08/30 09:02:10 batch 948: mean=13347.391304 stddev=10353.863894 entropy=0.336905 frames=7764 count=23
2017/08/30 09:02:10 Training policy...
2017/08/30 09:02:17 tune 0: objective=83.441211 reg=0.003369 prune=0
2017/08/30 09:02:20 step 0: objective=83.475745 reg=0.003369
2017/08/30 09:02:22 step 1: objective=83.505096 reg=0.003369
2017/08/30 09:02:24 step 2: objective=83.540451 reg=0.003369
2017/08/30 09:02:26 step 3: objective=83.568167 reg=0.003368
2017/08/30 09:02:29 step 4: objective=83.603957 reg=0.003367
2017/08/30 09:02:31 step 5: objective=83.633992 reg=0.003367
2017/08/30 09:02:33 step 6: objective=83.669500 reg=0.003367
2017/08/30 09:02:36 step 7: objective=83.687717 reg=0.003366
2017/08/30 09:02:36 Training value function...
2017/08/30 09:02:39 step 0: mse=195836.355857 step=0.050000
2017/08/30 09:02:40 step 1: mse=196242.014181 step=0.050000
2017/08/30 09:02:41 step 2: mse=193200.737786 step=0.050000
2017/08/30 09:02:43 step 3: mse=192667.343405 step=0.050000
2017/08/30 09:02:44 step 4: mse=192593.852312 step=0.050000
2017/08/30 09:02:45 step 5: mse=192149.303105 step=0.050000
2017/08/30 09:02:46 step 6: mse=188480.783864 step=0.050000
2017/08/30 09:02:48 step 7: mse=188952.978823 step=0.050000
2017/08/30 09:02:48 Saving...
2017/08/30 09:02:48 Gathering batch of experience...
2017/08/30 09:03:22 batch 949: mean=8299.642857 stddev=9451.403234 entropy=0.343150 frames=6987 count=28
2017/08/30 09:03:22 Training policy...
2017/08/30 09:03:29 tune 0: objective=35.483964 reg=0.003432 prune=0
2017/08/30 09:03:31 step 0: objective=35.547304 reg=0.003431
2017/08/30 09:03:33 step 1: objective=35.606877 reg=0.003431
2017/08/30 09:03:35 step 2: objective=35.671718 reg=0.003431
2017/08/30 09:03:37 step 3: objective=35.725689 reg=0.003431
2017/08/30 09:03:39 step 4: objective=35.781259 reg=0.003430
2017/08/30 09:03:41 step 5: objective=35.826694 reg=0.003431
2017/08/30 09:03:43 step 6: objective=35.871491 reg=0.003431
2017/08/30 09:03:45 step 7: objective=35.914535 reg=0.003430
2017/08/30 09:03:45 Training value function...
2017/08/30 09:03:48 step 0: mse=149247.327386 step=0.050000
2017/08/30 09:03:49 step 1: mse=150286.573839 step=0.050000
2017/08/30 09:03:50 step 2: mse=151474.762582 step=0.050000
2017/08/30 09:03:51 step 3: mse=152485.902572 step=0.050000
2017/08/30 09:03:53 step 4: mse=153745.019041 step=0.050000
2017/08/30 09:03:54 step 5: mse=155041.280451 step=0.050000
2017/08/30 09:03:55 step 6: mse=156458.967196 step=0.050000
2017/08/30 09:03:56 step 7: mse=157411.778830 step=0.050000
2017/08/30 09:03:56 Saving...
2017/08/30 09:03:56 Gathering batch of experience...
2017/08/30 09:04:30 batch 950: mean=12914.090909 stddev=10277.226770 entropy=0.341548 frames=7347 count=22
2017/08/30 09:04:30 Training policy...
2017/08/30 09:04:37 tune 0: objective=72.604873 reg=0.003415 prune=0
2017/08/30 09:04:39 step 0: objective=72.678202 reg=0.003416
2017/08/30 09:04:41 step 1: objective=72.770280 reg=0.003416
2017/08/30 09:04:43 step 2: objective=72.831224 reg=0.003416
2017/08/30 09:04:45 step 3: objective=72.868050 reg=0.003416
2017/08/30 09:04:48 step 4: objective=72.899951 reg=0.003416
2017/08/30 09:04:50 step 5: objective=72.934012 reg=0.003417
2017/08/30 09:04:52 step 6: objective=72.988533 reg=0.003417
2017/08/30 09:04:54 step 7: objective=73.040212 reg=0.003418
2017/08/30 09:04:54 Training value function...
2017/08/30 09:04:57 step 0: mse=200158.705528 step=0.050000
2017/08/30 09:04:58 step 1: mse=199839.377310 step=0.050000
2017/08/30 09:04:59 step 2: mse=199123.760429 step=0.050000
2017/08/30 09:05:01 step 3: mse=198776.904324 step=0.050000
2017/08/30 09:05:02 step 4: mse=200699.246879 step=0.050000
2017/08/30 09:05:03 step 5: mse=200169.081814 step=0.050000
2017/08/30 09:05:04 step 6: mse=200332.241777 step=0.050000
2017/08/30 09:05:06 step 7: mse=201663.619165 step=0.050000
2017/08/30 09:05:06 Saving...
2017/08/30 09:05:06 Gathering batch of experience...
2017/08/30 09:05:38 batch 951: mean=9447.800000 stddev=10140.767533 entropy=0.341476 frames=6450 count=25
2017/08/30 09:05:38 Training policy...
2017/08/30 09:05:44 tune 0: objective=60.353580 reg=0.003415 prune=0
2017/08/30 09:05:46 step 0: objective=60.386657 reg=0.003414
2017/08/30 09:05:47 step 1: objective=60.441856 reg=0.003414
2017/08/30 09:05:49 step 2: objective=60.495756 reg=0.003414
2017/08/30 09:05:51 step 3: objective=60.548551 reg=0.003413
2017/08/30 09:05:53 step 4: objective=60.588808 reg=0.003412
2017/08/30 09:05:55 step 5: objective=60.617844 reg=0.003412
2017/08/30 09:05:57 step 6: objective=60.669472 reg=0.003410
2017/08/30 09:05:59 step 7: objective=60.715368 reg=0.003410
2017/08/30 09:05:59 Training value function...
2017/08/30 09:06:01 step 0: mse=165478.471702 step=0.050000
2017/08/30 09:06:03 step 1: mse=164515.481578 step=0.050000
2017/08/30 09:06:04 step 2: mse=162971.325253 step=0.050000
2017/08/30 09:06:05 step 3: mse=160912.552867 step=0.050000
2017/08/30 09:06:06 step 4: mse=160329.672131 step=0.050000
2017/08/30 09:06:07 step 5: mse=159478.607062 step=0.050000
2017/08/30 09:06:08 step 6: mse=159051.030932 step=0.050000
2017/08/30 09:06:09 step 7: mse=157855.100538 step=0.050000
2017/08/30 09:06:09 Saving...
2017/08/30 09:06:09 Gathering batch of experience...
2017/08/30 09:06:42 batch 952: mean=16757.500000 stddev=8963.913495 entropy=0.336558 frames=7330 count=18
2017/08/30 09:06:42 Training policy...
2017/08/30 09:06:49 tune 0: objective=99.995481 reg=0.003366 prune=0
2017/08/30 09:06:51 step 0: objective=100.051475 reg=0.003365
2017/08/30 09:06:53 step 1: objective=100.083757 reg=0.003364
2017/08/30 09:06:55 step 2: objective=100.108637 reg=0.003364
2017/08/30 09:06:58 step 3: objective=100.152080 reg=0.003363
2017/08/30 09:07:00 step 4: objective=100.189649 reg=0.003363
2017/08/30 09:07:02 step 5: objective=100.211767 reg=0.003363
2017/08/30 09:07:04 step 6: objective=100.238762 reg=0.003362
2017/08/30 09:07:06 step 7: objective=100.265553 reg=0.003362
2017/08/30 09:07:06 Training value function...
2017/08/30 09:07:09 step 0: mse=253359.147937 step=0.050000
2017/08/30 09:07:10 step 1: mse=247930.239292 step=0.050000
2017/08/30 09:07:12 step 2: mse=245000.538952 step=0.050000
2017/08/30 09:07:13 step 3: mse=242765.347218 step=0.050000
2017/08/30 09:07:14 step 4: mse=241084.858549 step=0.050000
2017/08/30 09:07:15 step 5: mse=239894.596518 step=0.050000
2017/08/30 09:07:16 step 6: mse=235866.227676 step=0.050000
2017/08/30 09:07:18 step 7: mse=232057.828086 step=0.050000
2017/08/30 09:07:18 Saving...
2017/08/30 09:07:18 Gathering batch of experience...
2017/08/30 09:07:53 batch 953: mean=13192.826087 stddev=10397.812356 entropy=0.340919 frames=7648 count=23
2017/08/30 09:07:53 Training policy...
2017/08/30 09:08:00 tune 0: objective=84.692697 reg=0.003409 prune=0
2017/08/30 09:08:02 step 0: objective=84.729079 reg=0.003409
2017/08/30 09:08:05 step 1: objective=84.754151 reg=0.003409
2017/08/30 09:08:07 step 2: objective=84.782541 reg=0.003409
2017/08/30 09:08:09 step 3: objective=84.824521 reg=0.003408
2017/08/30 09:08:12 step 4: objective=84.871968 reg=0.003408
2017/08/30 09:08:14 step 5: objective=84.898135 reg=0.003408
2017/08/30 09:08:16 step 6: objective=84.917152 reg=0.003408
2017/08/30 09:08:18 step 7: objective=84.963307 reg=0.003408
2017/08/30 09:08:18 Training value function...
2017/08/30 09:08:21 step 0: mse=208658.455111 step=0.050000
2017/08/30 09:08:23 step 1: mse=207303.844249 step=0.050000
2017/08/30 09:08:24 step 2: mse=207356.051571 step=0.050000
2017/08/30 09:08:25 step 3: mse=208330.523964 step=0.050000
2017/08/30 09:08:27 step 4: mse=206034.463125 step=0.050000
2017/08/30 09:08:28 step 5: mse=203251.014596 step=0.050000
2017/08/30 09:08:29 step 6: mse=202306.949619 step=0.050000
2017/08/30 09:08:30 step 7: mse=200941.715209 step=0.050000
2017/08/30 09:08:30 Saving...
2017/08/30 09:08:30 Gathering batch of experience...
2017/08/30 09:09:01 batch 954: mean=12156.666667 stddev=10346.445253 entropy=0.339169 frames=6569 count=21
2017/08/30 09:09:01 Training policy...
2017/08/30 09:09:07 tune 0: objective=73.312234 reg=0.003392 prune=0
2017/08/30 09:09:09 step 0: objective=73.346590 reg=0.003392
2017/08/30 09:09:11 step 1: objective=73.387735 reg=0.003392
2017/08/30 09:09:13 step 2: objective=73.431406 reg=0.003392
2017/08/30 09:09:15 step 3: objective=73.475234 reg=0.003392
2017/08/30 09:09:17 step 4: objective=73.524404 reg=0.003392
2017/08/30 09:09:19 step 5: objective=73.552638 reg=0.003392
2017/08/30 09:09:21 step 6: objective=73.579973 reg=0.003392
2017/08/30 09:09:23 step 7: objective=73.598455 reg=0.003392
2017/08/30 09:09:23 Training value function...
2017/08/30 09:09:26 step 0: mse=201885.369359 step=0.050000
2017/08/30 09:09:27 step 1: mse=199571.665046 step=0.050000
2017/08/30 09:09:28 step 2: mse=198943.023488 step=0.050000
2017/08/30 09:09:29 step 3: mse=200141.001005 step=0.050000
2017/08/30 09:09:30 step 4: mse=196239.488470 step=0.050000
2017/08/30 09:09:31 step 5: mse=197788.860216 step=0.050000
2017/08/30 09:09:32 step 6: mse=198197.042651 step=0.050000
2017/08/30 09:09:33 step 7: mse=197397.323319 step=0.050000
2017/08/30 09:09:33 Saving...
2017/08/30 09:09:33 Gathering batch of experience...
2017/08/30 09:10:06 batch 955: mean=11946.590909 stddev=10143.941697 entropy=0.339813 frames=6849 count=22
2017/08/30 09:10:06 Training policy...
2017/08/30 09:10:12 tune 0: objective=69.544496 reg=0.003398 prune=0
2017/08/30 09:10:14 step 0: objective=69.614862 reg=0.003398
2017/08/30 09:10:16 step 1: objective=69.645094 reg=0.003398
2017/08/30 09:10:18 step 2: objective=69.677216 reg=0.003398
2017/08/30 09:10:20 step 3: objective=69.717171 reg=0.003397
2017/08/30 09:10:22 step 4: objective=69.757141 reg=0.003397
2017/08/30 09:10:24 step 5: objective=69.790987 reg=0.003397
2017/08/30 09:10:26 step 6: objective=69.826033 reg=0.003398
2017/08/30 09:10:28 step 7: objective=69.864921 reg=0.003398
2017/08/30 09:10:28 Training value function...
2017/08/30 09:10:31 step 0: mse=183771.137507 step=0.050000
2017/08/30 09:10:32 step 1: mse=185140.207250 step=0.050000
2017/08/30 09:10:33 step 2: mse=185936.292420 step=0.050000
2017/08/30 09:10:35 step 3: mse=187275.090189 step=0.050000
2017/08/30 09:10:36 step 4: mse=188174.089963 step=0.050000
2017/08/30 09:10:37 step 5: mse=189069.411061 step=0.050000
2017/08/30 09:10:38 step 6: mse=188501.739566 step=0.050000
2017/08/30 09:10:39 step 7: mse=189433.041649 step=0.050000
2017/08/30 09:10:39 Saving...
2017/08/30 09:10:39 Gathering batch of experience...
2017/08/30 09:11:16 batch 956: mean=13662.173913 stddev=10080.098432 entropy=0.335727 frames=7896 count=23
2017/08/30 09:11:16 Training policy...
2017/08/30 09:11:24 tune 0: objective=81.734312 reg=0.003357 prune=0
2017/08/30 09:11:26 step 0: objective=81.795276 reg=0.003357
2017/08/30 09:11:28 step 1: objective=81.840489 reg=0.003356
2017/08/30 09:11:31 step 2: objective=81.885409 reg=0.003356
2017/08/30 09:11:33 step 3: objective=81.927986 reg=0.003356
2017/08/30 09:11:35 step 4: objective=81.973594 reg=0.003355
2017/08/30 09:11:38 step 5: objective=82.039917 reg=0.003355
2017/08/30 09:11:40 step 6: objective=82.089943 reg=0.003355
2017/08/30 09:11:42 step 7: objective=82.142113 reg=0.003355
2017/08/30 09:11:42 Training value function...
2017/08/30 09:11:46 step 0: mse=223608.133860 step=0.050000
2017/08/30 09:11:47 step 1: mse=223787.113495 step=0.050000
2017/08/30 09:11:48 step 2: mse=225012.172177 step=0.050000
2017/08/30 09:11:50 step 3: mse=225081.071616 step=0.050000
2017/08/30 09:11:51 step 4: mse=222430.797587 step=0.050000
2017/08/30 09:11:52 step 5: mse=219450.869738 step=0.050000
2017/08/30 09:11:53 step 6: mse=217754.727984 step=0.050000
2017/08/30 09:11:55 step 7: mse=216165.375737 step=0.050000
2017/08/30 09:11:55 Saving...
2017/08/30 09:11:55 Gathering batch of experience...
2017/08/30 09:12:28 batch 957: mean=15617.894737 stddev=9598.989025 entropy=0.337430 frames=7206 count=19
2017/08/30 09:12:28 Training policy...
2017/08/30 09:12:35 tune 0: objective=88.473859 reg=0.003374 prune=0
2017/08/30 09:12:37 step 0: objective=88.510807 reg=0.003374
2017/08/30 09:12:39 step 1: objective=88.540418 reg=0.003375
2017/08/30 09:12:41 step 2: objective=88.571121 reg=0.003374
2017/08/30 09:12:43 step 3: objective=88.608208 reg=0.003373
2017/08/30 09:12:45 step 4: objective=88.636197 reg=0.003373
2017/08/30 09:12:48 step 5: objective=88.677404 reg=0.003374
2017/08/30 09:12:50 step 6: objective=88.700467 reg=0.003374
2017/08/30 09:12:52 step 7: objective=88.725376 reg=0.003374
2017/08/30 09:12:52 Training value function...
2017/08/30 09:12:55 step 0: mse=205757.218117 step=0.050000
2017/08/30 09:12:56 step 1: mse=205669.647937 step=0.050000
2017/08/30 09:12:57 step 2: mse=205711.827607 step=0.050000
2017/08/30 09:12:58 step 3: mse=203920.665982 step=0.050000
2017/08/30 09:13:00 step 4: mse=202747.965342 step=0.050000
2017/08/30 09:13:01 step 5: mse=202380.715987 step=0.050000
2017/08/30 09:13:02 step 6: mse=202492.942158 step=0.050000
2017/08/30 09:13:03 step 7: mse=203064.466821 step=0.050000
2017/08/30 09:13:03 Saving...
2017/08/30 09:13:03 Gathering batch of experience...
2017/08/30 09:13:38 batch 958: mean=11776.875000 stddev=10297.409850 entropy=0.338709 frames=7381 count=24
2017/08/30 09:13:38 Training policy...
2017/08/30 09:13:45 tune 0: objective=67.943762 reg=0.003387 prune=0
2017/08/30 09:13:47 step 0: objective=67.996190 reg=0.003387
2017/08/30 09:13:49 step 1: objective=68.071594 reg=0.003385
2017/08/30 09:13:52 step 2: objective=68.158333 reg=0.003384
2017/08/30 09:13:54 step 3: objective=68.221375 reg=0.003383
2017/08/30 09:13:56 step 4: objective=68.279197 reg=0.003383
2017/08/30 09:13:58 step 5: objective=68.349843 reg=0.003382
2017/08/30 09:14:00 step 6: objective=68.380043 reg=0.003382
2017/08/30 09:14:03 step 7: objective=68.414955 reg=0.003382
2017/08/30 09:14:03 Training value function...
2017/08/30 09:14:06 step 0: mse=200377.667066 step=0.050000
2017/08/30 09:14:07 step 1: mse=199761.677331 step=0.050000
2017/08/30 09:14:08 step 2: mse=199992.362759 step=0.050000
2017/08/30 09:14:09 step 3: mse=199320.529652 step=0.050000
2017/08/30 09:14:10 step 4: mse=196769.929563 step=0.050000
2017/08/30 09:14:12 step 5: mse=197069.465780 step=0.050000
2017/08/30 09:14:13 step 6: mse=197673.300057 step=0.050000
2017/08/30 09:14:14 step 7: mse=198025.939224 step=0.050000
2017/08/30 09:14:14 Saving...
2017/08/30 09:14:14 Gathering batch of experience...
2017/08/30 09:14:51 batch 959: mean=14898.863636 stddev=9820.481141 entropy=0.335102 frames=8105 count=22
2017/08/30 09:14:51 Training policy...
2017/08/30 09:14:59 tune 0: objective=83.504018 reg=0.003351 prune=0
2017/08/30 09:15:01 step 0: objective=83.544078 reg=0.003350
2017/08/30 09:15:03 step 1: objective=83.581956 reg=0.003349
2017/08/30 09:15:06 step 2: objective=83.607064 reg=0.003350
2017/08/30 09:15:08 step 3: objective=83.660734 reg=0.003349
2017/08/30 09:15:11 step 4: objective=83.675725 reg=0.003349
2017/08/30 09:15:13 step 5: objective=83.704203 reg=0.003349
2017/08/30 09:15:16 step 6: objective=83.745404 reg=0.003348
2017/08/30 09:15:18 step 7: objective=83.769016 reg=0.003348
2017/08/30 09:15:18 Training value function...
2017/08/30 09:15:21 step 0: mse=229776.379365 step=0.050000
2017/08/30 09:15:23 step 1: mse=230179.253233 step=0.050000
2017/08/30 09:15:24 step 2: mse=230666.120351 step=0.050000
2017/08/30 09:15:25 step 3: mse=231693.816179 step=0.050000
2017/08/30 09:15:27 step 4: mse=226896.988090 step=0.050000
2017/08/30 09:15:28 step 5: mse=226073.351424 step=0.050000
2017/08/30 09:15:29 step 6: mse=224967.301963 step=0.050000
2017/08/30 09:15:31 step 7: mse=223807.038943 step=0.050000
2017/08/30 09:15:31 Saving...
2017/08/30 09:15:31 Gathering batch of experience...
2017/08/30 09:16:07 batch 960: mean=12611.875000 stddev=10466.811618 entropy=0.335205 frames=7650 count=24
2017/08/30 09:16:07 Training policy...
2017/08/30 09:16:14 tune 0: objective=74.699208 reg=0.003352 prune=0
2017/08/30 09:16:17 step 0: objective=74.730572 reg=0.003352
2017/08/30 09:16:19 step 1: objective=74.756511 reg=0.003352
2017/08/30 09:16:21 step 2: objective=74.781789 reg=0.003352
2017/08/30 09:16:23 step 3: objective=74.800474 reg=0.003352
2017/08/30 09:16:26 step 4: objective=74.827794 reg=0.003352
2017/08/30 09:16:28 step 5: objective=74.857990 reg=0.003351
2017/08/30 09:16:30 step 6: objective=74.874044 reg=0.003351
2017/08/30 09:16:33 step 7: objective=74.894330 reg=0.003351
2017/08/30 09:16:33 Training value function...
2017/08/30 09:16:36 step 0: mse=191661.129665 step=0.050000
2017/08/30 09:16:37 step 1: mse=189455.382289 step=0.050000
2017/08/30 09:16:38 step 2: mse=190684.509377 step=0.050000
2017/08/30 09:16:40 step 3: mse=187681.618972 step=0.050000
2017/08/30 09:16:41 step 4: mse=187828.599359 step=0.050000
2017/08/30 09:16:42 step 5: mse=188561.945744 step=0.050000
2017/08/30 09:16:43 step 6: mse=188392.781554 step=0.050000
2017/08/30 09:16:45 step 7: mse=187694.185875 step=0.050000
2017/08/30 09:16:45 Saving...
2017/08/30 09:16:45 Gathering batch of experience...
2017/08/30 09:17:20 batch 961: mean=11990.416667 stddev=10312.161400 entropy=0.338466 frames=7474 count=24
2017/08/30 09:17:20 Training policy...
2017/08/30 09:17:27 tune 0: objective=70.420976 reg=0.003385 prune=0
2017/08/30 09:17:29 step 0: objective=70.474453 reg=0.003385
2017/08/30 09:17:32 step 1: objective=70.515153 reg=0.003385
2017/08/30 09:17:34 step 2: objective=70.556705 reg=0.003386
2017/08/30 09:17:36 step 3: objective=70.606762 reg=0.003387
2017/08/30 09:17:38 step 4: objective=70.673543 reg=0.003387
2017/08/30 09:17:41 step 5: objective=70.708364 reg=0.003386
2017/08/30 09:17:43 step 6: objective=70.749632 reg=0.003386
2017/08/30 09:17:45 step 7: objective=70.790323 reg=0.003386
2017/08/30 09:17:45 Training value function...
2017/08/30 09:17:48 step 0: mse=190231.974605 step=0.050000
2017/08/30 09:17:49 step 1: mse=188232.719507 step=0.050000
2017/08/30 09:17:51 step 2: mse=189147.481351 step=0.050000
2017/08/30 09:17:52 step 3: mse=190110.941999 step=0.050000
2017/08/30 09:17:53 step 4: mse=191059.849842 step=0.050000
2017/08/30 09:17:54 step 5: mse=192025.141338 step=0.050000
2017/08/30 09:17:56 step 6: mse=193200.944470 step=0.050000
2017/08/30 09:17:57 step 7: mse=191919.581384 step=0.050000
2017/08/30 09:17:57 Saving...
2017/08/30 09:17:57 Gathering batch of experience...
2017/08/30 09:18:29 batch 962: mean=7981.730769 stddev=9315.908947 entropy=0.339817 frames=6275 count=26
2017/08/30 09:18:29 Training policy...
2017/08/30 09:18:35 tune 0: objective=36.273451 reg=0.003398 prune=0
2017/08/30 09:18:37 step 0: objective=36.357430 reg=0.003398
2017/08/30 09:18:39 step 1: objective=36.449756 reg=0.003398
2017/08/30 09:18:40 step 2: objective=36.513690 reg=0.003399
2017/08/30 09:18:42 step 3: objective=36.550356 reg=0.003398
2017/08/30 09:18:44 step 4: objective=36.585349 reg=0.003397
2017/08/30 09:18:46 step 5: objective=36.612054 reg=0.003397
2017/08/30 09:18:48 step 6: objective=36.656183 reg=0.003396
2017/08/30 09:18:50 step 7: objective=36.685667 reg=0.003395
2017/08/30 09:18:50 Training value function...
2017/08/30 09:18:52 step 0: mse=169178.185331 step=0.050000
2017/08/30 09:18:53 step 1: mse=170085.160615 step=0.050000
2017/08/30 09:18:54 step 2: mse=170999.368271 step=0.050000
2017/08/30 09:18:55 step 3: mse=170325.977893 step=0.050000
2017/08/30 09:18:56 step 4: mse=169860.705003 step=0.050000
2017/08/30 09:18:57 step 5: mse=171095.347161 step=0.050000
2017/08/30 09:18:58 step 6: mse=171012.208853 step=0.050000
2017/08/30 09:18:59 step 7: mse=171346.230696 step=0.050000
2017/08/30 09:18:59 Saving...
2017/08/30 09:19:00 Gathering batch of experience...
2017/08/30 09:19:33 batch 963: mean=13275.714286 stddev=10389.738331 entropy=0.336821 frames=6962 count=21
2017/08/30 09:19:33 Training policy...
2017/08/30 09:19:39 tune 0: objective=93.332367 reg=0.003368 prune=0
2017/08/30 09:19:41 step 0: objective=93.372504 reg=0.003368
2017/08/30 09:19:43 step 1: objective=93.421350 reg=0.003369
2017/08/30 09:19:45 step 2: objective=93.476120 reg=0.003370
2017/08/30 09:19:47 step 3: objective=93.524634 reg=0.003370
2017/08/30 09:19:49 step 4: objective=93.567850 reg=0.003371
2017/08/30 09:19:52 step 5: objective=93.614111 reg=0.003371
2017/08/30 09:19:54 step 6: objective=93.652641 reg=0.003372
2017/08/30 09:19:56 step 7: objective=93.695194 reg=0.003372
2017/08/30 09:19:56 Training value function...
2017/08/30 09:19:59 step 0: mse=234017.971868 step=0.050000
2017/08/30 09:20:00 step 1: mse=233890.191357 step=0.050000
2017/08/30 09:20:01 step 2: mse=227847.570872 step=0.050000
2017/08/30 09:20:02 step 3: mse=225073.660184 step=0.050000
2017/08/30 09:20:03 step 4: mse=221144.296050 step=0.050000
2017/08/30 09:20:04 step 5: mse=221053.996859 step=0.050000
2017/08/30 09:20:06 step 6: mse=219982.378796 step=0.050000
2017/08/30 09:20:07 step 7: mse=215830.170215 step=0.050000
2017/08/30 09:20:07 Saving...
2017/08/30 09:20:07 Gathering batch of experience...
2017/08/30 09:20:39 batch 964: mean=11801.428571 stddev=10078.861560 entropy=0.336150 frames=6679 count=21
2017/08/30 09:20:39 Training policy...
2017/08/30 09:20:45 tune 0: objective=68.490956 reg=0.003362 prune=0
2017/08/30 09:20:47 step 0: objective=68.539391 reg=0.003361
2017/08/30 09:20:49 step 1: objective=68.586549 reg=0.003360
2017/08/30 09:20:51 step 2: objective=68.631709 reg=0.003360
2017/08/30 09:20:53 step 3: objective=68.677384 reg=0.003360
2017/08/30 09:20:55 step 4: objective=68.711942 reg=0.003360
2017/08/30 09:20:57 step 5: objective=68.744844 reg=0.003359
2017/08/30 09:20:59 step 6: objective=68.784642 reg=0.003359
2017/08/30 09:21:01 step 7: objective=68.815223 reg=0.003359
2017/08/30 09:21:01 Training value function...
2017/08/30 09:21:04 step 0: mse=184516.238567 step=0.050000
2017/08/30 09:21:05 step 1: mse=182908.853972 step=0.050000
2017/08/30 09:21:06 step 2: mse=184123.564991 step=0.050000
2017/08/30 09:21:07 step 3: mse=185643.437979 step=0.050000
2017/08/30 09:21:08 step 4: mse=185616.985268 step=0.050000
2017/08/30 09:21:10 step 5: mse=185578.855885 step=0.050000
2017/08/30 09:21:11 step 6: mse=187010.771660 step=0.050000
2017/08/30 09:21:12 step 7: mse=187590.983104 step=0.050000
2017/08/30 09:21:12 Saving...
2017/08/30 09:21:12 Gathering batch of experience...
2017/08/30 09:21:42 batch 965: mean=11409.047619 stddev=10350.946888 entropy=0.334136 frames=6385 count=21
2017/08/30 09:21:42 Training policy...
2017/08/30 09:21:48 tune 0: objective=71.396603 reg=0.003341 prune=0
2017/08/30 09:21:50 step 0: objective=71.435165 reg=0.003341
2017/08/30 09:21:52 step 1: objective=71.484647 reg=0.003341
2017/08/30 09:21:54 step 2: objective=71.521143 reg=0.003340
2017/08/30 09:21:56 step 3: objective=71.547793 reg=0.003340
2017/08/30 09:21:58 step 4: objective=71.581084 reg=0.003340
2017/08/30 09:22:00 step 5: objective=71.610625 reg=0.003340
2017/08/30 09:22:02 step 6: objective=71.640084 reg=0.003340
2017/08/30 09:22:04 step 7: objective=71.670580 reg=0.003340
2017/08/30 09:22:04 Training value function...
2017/08/30 09:22:06 step 0: mse=169975.201327 step=0.050000
2017/08/30 09:22:07 step 1: mse=170572.302317 step=0.050000
2017/08/30 09:22:08 step 2: mse=170622.347895 step=0.050000
2017/08/30 09:22:09 step 3: mse=170316.293475 step=0.050000
2017/08/30 09:22:10 step 4: mse=170020.169165 step=0.050000
2017/08/30 09:22:12 step 5: mse=169646.173189 step=0.050000
2017/08/30 09:22:13 step 6: mse=170174.317692 step=0.050000
2017/08/30 09:22:14 step 7: mse=171372.532817 step=0.050000
2017/08/30 09:22:14 Saving...
2017/08/30 09:22:14 Gathering batch of experience...
2017/08/30 09:22:45 batch 966: mean=14322.894737 stddev=9802.945089 entropy=0.337927 frames=6747 count=19
2017/08/30 09:22:45 Training policy...
2017/08/30 09:22:51 tune 0: objective=84.760403 reg=0.003379 prune=0
2017/08/30 09:22:53 step 0: objective=84.802097 reg=0.003379
2017/08/30 09:22:55 step 1: objective=84.840448 reg=0.003379
2017/08/30 09:22:57 step 2: objective=84.884087 reg=0.003378
2017/08/30 09:22:59 step 3: objective=84.922114 reg=0.003378
2017/08/30 09:23:01 step 4: objective=84.965800 reg=0.003377
2017/08/30 09:23:03 step 5: objective=85.013376 reg=0.003377
2017/08/30 09:23:06 step 6: objective=85.066845 reg=0.003377
2017/08/30 09:23:08 step 7: objective=85.096867 reg=0.003378
2017/08/30 09:23:08 Training value function...
2017/08/30 09:23:10 step 0: mse=206473.506938 step=0.050000
2017/08/30 09:23:11 step 1: mse=206717.721638 step=0.050000
2017/08/30 09:23:13 step 2: mse=204137.782701 step=0.050000
2017/08/30 09:23:14 step 3: mse=204619.959755 step=0.050000
2017/08/30 09:23:15 step 4: mse=205391.659980 step=0.050000
2017/08/30 09:23:16 step 5: mse=204087.743772 step=0.050000
2017/08/30 09:23:17 step 6: mse=205163.907745 step=0.050000
2017/08/30 09:23:18 step 7: mse=202709.815466 step=0.050000
2017/08/30 09:23:18 Saving...
2017/08/30 09:23:18 Gathering batch of experience...
2017/08/30 09:23:50 batch 967: mean=10940.909091 stddev=10507.498365 entropy=0.336877 frames=6332 count=22
2017/08/30 09:23:50 Training policy...
2017/08/30 09:23:56 tune 0: objective=72.706185 reg=0.003369 prune=0
2017/08/30 09:23:58 step 0: objective=72.738950 reg=0.003368
2017/08/30 09:23:59 step 1: objective=72.770225 reg=0.003367
2017/08/30 09:24:01 step 2: objective=72.797245 reg=0.003367
2017/08/30 09:24:03 step 3: objective=72.829290 reg=0.003366
2017/08/30 09:24:05 step 4: objective=72.857811 reg=0.003366
2017/08/30 09:24:07 step 5: objective=72.893142 reg=0.003365
2017/08/30 09:24:09 step 6: objective=72.917014 reg=0.003364
2017/08/30 09:24:11 step 7: objective=72.933369 reg=0.003364
2017/08/30 09:24:11 Training value function...
2017/08/30 09:24:13 step 0: mse=172230.656345 step=0.050000
2017/08/30 09:24:14 step 1: mse=173298.655598 step=0.050000
2017/08/30 09:24:15 step 2: mse=173344.236381 step=0.050000
2017/08/30 09:24:16 step 3: mse=172888.769147 step=0.050000
2017/08/30 09:24:17 step 4: mse=173010.286768 step=0.050000
2017/08/30 09:24:19 step 5: mse=172917.356167 step=0.050000
2017/08/30 09:24:20 step 6: mse=173952.603721 step=0.050000
2017/08/30 09:24:21 step 7: mse=173967.654131 step=0.050000
2017/08/30 09:24:21 Saving...
2017/08/30 09:24:21 Gathering batch of experience...
2017/08/30 09:24:52 batch 968: mean=11852.750000 stddev=10395.086036 entropy=0.334860 frames=6211 count=20
2017/08/30 09:24:52 Training policy...
2017/08/30 09:24:58 tune 0: objective=74.273381 reg=0.003349 prune=0
2017/08/30 09:24:59 step 0: objective=74.339946 reg=0.003348
2017/08/30 09:25:01 step 1: objective=74.419795 reg=0.003346
2017/08/30 09:25:03 step 2: objective=74.484126 reg=0.003345
2017/08/30 09:25:05 step 3: objective=74.527733 reg=0.003345
2017/08/30 09:25:07 step 4: objective=74.573801 reg=0.003344
2017/08/30 09:25:09 step 5: objective=74.627023 reg=0.003343
2017/08/30 09:25:11 step 6: objective=74.652728 reg=0.003342
2017/08/30 09:25:12 step 7: objective=74.687772 reg=0.003341
2017/08/30 09:25:12 Training value function...
2017/08/30 09:25:15 step 0: mse=196361.847207 step=0.050000
2017/08/30 09:25:16 step 1: mse=196787.286964 step=0.050000
2017/08/30 09:25:17 step 2: mse=193327.691696 step=0.050000
2017/08/30 09:25:18 step 3: mse=194107.766421 step=0.050000
2017/08/30 09:25:19 step 4: mse=192963.202046 step=0.050000
2017/08/30 09:25:20 step 5: mse=193052.193973 step=0.050000
2017/08/30 09:25:21 step 6: mse=193847.332677 step=0.050000
2017/08/30 09:25:22 step 7: mse=194810.756999 step=0.050000
2017/08/30 09:25:22 Saving...
2017/08/30 09:25:22 Gathering batch of experience...
2017/08/30 09:25:55 batch 969: mean=14660.263158 stddev=10067.117587 entropy=0.333231 frames=6895 count=19
2017/08/30 09:25:55 Training policy...
2017/08/30 09:26:02 tune 0: objective=85.224084 reg=0.003332 prune=0
2017/08/30 09:26:04 step 0: objective=85.250308 reg=0.003332
2017/08/30 09:26:06 step 1: objective=85.276922 reg=0.003332
2017/08/30 09:26:08 step 2: objective=85.295903 reg=0.003332
2017/08/30 09:26:10 step 3: objective=85.312618 reg=0.003331
2017/08/30 09:26:12 step 4: objective=85.340509 reg=0.003331
2017/08/30 09:26:14 step 5: objective=85.358684 reg=0.003331
2017/08/30 09:26:16 step 6: objective=85.397435 reg=0.003331
2017/08/30 09:26:18 step 7: objective=85.419045 reg=0.003331
2017/08/30 09:26:18 Training value function...
2017/08/30 09:26:21 step 0: mse=183191.778393 step=0.050000
2017/08/30 09:26:22 step 1: mse=182820.545241 step=0.050000
2017/08/30 09:26:24 step 2: mse=182521.769368 step=0.050000
2017/08/30 09:26:25 step 3: mse=182082.586966 step=0.050000
2017/08/30 09:26:26 step 4: mse=182590.935148 step=0.050000
2017/08/30 09:26:27 step 5: mse=179755.180057 step=0.050000
2017/08/30 09:26:28 step 6: mse=178794.521280 step=0.050000
2017/08/30 09:26:29 step 7: mse=177860.127055 step=0.050000
2017/08/30 09:26:29 Saving...
2017/08/30 09:26:29 Gathering batch of experience...
2017/08/30 09:27:05 batch 970: mean=13263.695652 stddev=10128.909896 entropy=0.334619 frames=7598 count=23
2017/08/30 09:27:05 Training policy...
2017/08/30 09:27:12 tune 0: objective=73.443192 reg=0.003346 prune=0
2017/08/30 09:27:14 step 0: objective=73.516912 reg=0.003346
2017/08/30 09:27:16 step 1: objective=73.576903 reg=0.003347
2017/08/30 09:27:19 step 2: objective=73.626365 reg=0.003347
2017/08/30 09:27:21 step 3: objective=73.661375 reg=0.003347
2017/08/30 09:27:23 step 4: objective=73.737554 reg=0.003347
2017/08/30 09:27:26 step 5: objective=73.799429 reg=0.003347
2017/08/30 09:27:28 step 6: objective=73.842640 reg=0.003346
2017/08/30 09:27:30 step 7: objective=73.902589 reg=0.003346
2017/08/30 09:27:30 Training value function...
2017/08/30 09:27:33 step 0: mse=235869.369694 step=0.050000
2017/08/30 09:27:35 step 1: mse=235503.111423 step=0.050000
2017/08/30 09:27:36 step 2: mse=232015.687054 step=0.050000
2017/08/30 09:27:37 step 3: mse=233271.371523 step=0.050000
2017/08/30 09:27:38 step 4: mse=232510.417924 step=0.050000
2017/08/30 09:27:40 step 5: mse=228976.498100 step=0.050000
2017/08/30 09:27:41 step 6: mse=230453.738471 step=0.050000
2017/08/30 09:27:42 step 7: mse=231158.280914 step=0.050000
2017/08/30 09:27:42 Saving...
2017/08/30 09:27:42 Gathering batch of experience...
2017/08/30 09:28:14 batch 971: mean=8744.038462 stddev=10002.772214 entropy=0.337788 frames=6436 count=26
2017/08/30 09:28:14 Training policy...
2017/08/30 09:28:20 tune 0: objective=58.671491 reg=0.003378 prune=0
2017/08/30 09:28:22 step 0: objective=58.755317 reg=0.003378
2017/08/30 09:28:24 step 1: objective=58.858831 reg=0.003378
2017/08/30 09:28:26 step 2: objective=58.942535 reg=0.003377
2017/08/30 09:28:28 step 3: objective=59.012547 reg=0.003377
2017/08/30 09:28:30 step 4: objective=59.069254 reg=0.003376
2017/08/30 09:28:32 step 5: objective=59.150603 reg=0.003375
2017/08/30 09:28:34 step 6: objective=59.185019 reg=0.003375
2017/08/30 09:28:36 step 7: objective=59.236244 reg=0.003374
2017/08/30 09:28:36 Training value function...
2017/08/30 09:28:38 step 0: mse=223508.430190 step=0.050000
2017/08/30 09:28:40 step 1: mse=218238.103697 step=0.050000
2017/08/30 09:28:41 step 2: mse=213842.428298 step=0.050000
2017/08/30 09:28:42 step 3: mse=215464.766541 step=0.050000
2017/08/30 09:28:43 step 4: mse=215154.002210 step=0.050000
2017/08/30 09:28:44 step 5: mse=211033.464145 step=0.050000
2017/08/30 09:28:45 step 6: mse=207037.626469 step=0.050000
2017/08/30 09:28:46 step 7: mse=202979.194682 step=0.050000
2017/08/30 09:28:46 Saving...
2017/08/30 09:28:46 Gathering batch of experience...
2017/08/30 09:29:19 batch 972: mean=12957.500000 stddev=10220.673840 entropy=0.335221 frames=6728 count=20
2017/08/30 09:29:19 Training policy...
2017/08/30 09:29:25 tune 0: objective=76.127778 reg=0.003352 prune=0
2017/08/30 09:29:27 step 0: objective=76.154322 reg=0.003351
2017/08/30 09:29:29 step 1: objective=76.181857 reg=0.003350
2017/08/30 09:29:31 step 2: objective=76.210752 reg=0.003350
2017/08/30 09:29:33 step 3: objective=76.240710 reg=0.003349
2017/08/30 09:29:35 step 4: objective=76.268505 reg=0.003348
2017/08/30 09:29:37 step 5: objective=76.311720 reg=0.003347
2017/08/30 09:29:39 step 6: objective=76.335807 reg=0.003347
2017/08/30 09:29:41 step 7: objective=76.362770 reg=0.003346
2017/08/30 09:29:41 Training value function...
2017/08/30 09:29:44 step 0: mse=195965.364284 step=0.050000
2017/08/30 09:29:45 step 1: mse=196419.261967 step=0.050000
2017/08/30 09:29:46 step 2: mse=196422.807725 step=0.050000
2017/08/30 09:29:47 step 3: mse=194539.049224 step=0.050000
2017/08/30 09:29:48 step 4: mse=194273.871219 step=0.050000
2017/08/30 09:29:50 step 5: mse=194426.815609 step=0.050000
2017/08/30 09:29:51 step 6: mse=193549.900846 step=0.050000
2017/08/30 09:29:52 step 7: mse=193914.900372 step=0.050000
2017/08/30 09:29:52 Saving...
2017/08/30 09:29:52 Gathering batch of experience...
2017/08/30 09:30:26 batch 973: mean=14145.000000 stddev=10419.221300 entropy=0.334550 frames=7081 count=20
2017/08/30 09:30:26 Training policy...
2017/08/30 09:30:32 tune 0: objective=86.394401 reg=0.003346 prune=0
2017/08/30 09:30:35 step 0: objective=86.456106 reg=0.003346
2017/08/30 09:30:37 step 1: objective=86.517582 reg=0.003345
2017/08/30 09:30:39 step 2: objective=86.548157 reg=0.003346
2017/08/30 09:30:41 step 3: objective=86.594487 reg=0.003346
2017/08/30 09:30:43 step 4: objective=86.644709 reg=0.003347
2017/08/30 09:30:45 step 5: objective=86.676564 reg=0.003348
2017/08/30 09:30:47 step 6: objective=86.697845 reg=0.003348
2017/08/30 09:30:49 step 7: objective=86.722170 reg=0.003348
2017/08/30 09:30:49 Training value function...
2017/08/30 09:30:52 step 0: mse=201716.114102 step=0.050000
2017/08/30 09:30:53 step 1: mse=202027.898813 step=0.050000
2017/08/30 09:30:55 step 2: mse=200269.605680 step=0.050000
2017/08/30 09:30:56 step 3: mse=199824.575001 step=0.050000
2017/08/30 09:30:57 step 4: mse=200953.855809 step=0.050000
2017/08/30 09:30:58 step 5: mse=201518.252556 step=0.050000
2017/08/30 09:30:59 step 6: mse=201844.814447 step=0.050000
2017/08/30 09:31:00 step 7: mse=202374.162232 step=0.050000
2017/08/30 09:31:00 Saving...
2017/08/30 09:31:01 Gathering batch of experience...
2017/08/30 09:31:33 batch 974: mean=16406.388889 stddev=9116.908102 entropy=0.333169 frames=7071 count=18
2017/08/30 09:31:33 Training policy...
2017/08/30 09:31:39 tune 0: objective=83.033137 reg=0.003332 prune=0
2017/08/30 09:31:42 step 0: objective=83.082573 reg=0.003331
2017/08/30 09:31:44 step 1: objective=83.127873 reg=0.003331
2017/08/30 09:31:46 step 2: objective=83.168028 reg=0.003331
2017/08/30 09:31:48 step 3: objective=83.187801 reg=0.003331
2017/08/30 09:31:50 step 4: objective=83.223209 reg=0.003330
2017/08/30 09:31:52 step 5: objective=83.244838 reg=0.003330
2017/08/30 09:31:54 step 6: objective=83.272893 reg=0.003330
2017/08/30 09:31:56 step 7: objective=83.322453 reg=0.003330
2017/08/30 09:31:56 Training value function...
2017/08/30 09:31:59 step 0: mse=211063.467778 step=0.050000
2017/08/30 09:32:01 step 1: mse=210232.230409 step=0.050000
2017/08/30 09:32:02 step 2: mse=209022.114907 step=0.050000
2017/08/30 09:32:03 step 3: mse=209610.190580 step=0.050000
2017/08/30 09:32:04 step 4: mse=211177.351273 step=0.050000
2017/08/30 09:32:05 step 5: mse=208940.173657 step=0.050000
2017/08/30 09:32:06 step 6: mse=207989.237284 step=0.050000
2017/08/30 09:32:08 step 7: mse=208134.977771 step=0.050000
2017/08/30 09:32:08 Saving...
2017/08/30 09:32:08 Gathering batch of experience...
2017/08/30 09:32:43 batch 975: mean=11657.200000 stddev=10436.147285 entropy=0.331104 frames=7530 count=25
2017/08/30 09:32:43 Training policy...
2017/08/30 09:32:50 tune 0: objective=71.050149 reg=0.003311 prune=0
2017/08/30 09:32:52 step 0: objective=71.095759 reg=0.003310
2017/08/30 09:32:54 step 1: objective=71.131275 reg=0.003310
2017/08/30 09:32:56 step 2: objective=71.173274 reg=0.003310
2017/08/30 09:32:59 step 3: objective=71.204034 reg=0.003310
2017/08/30 09:33:01 step 4: objective=71.224842 reg=0.003310
2017/08/30 09:33:03 step 5: objective=71.253519 reg=0.003310
2017/08/30 09:33:06 step 6: objective=71.272219 reg=0.003310
2017/08/30 09:33:08 step 7: objective=71.292497 reg=0.003310
2017/08/30 09:33:08 Training value function...
2017/08/30 09:33:11 step 0: mse=199878.821680 step=0.050000
2017/08/30 09:33:12 step 1: mse=201162.369258 step=0.050000
2017/08/30 09:33:14 step 2: mse=199913.504488 step=0.050000
2017/08/30 09:33:15 step 3: mse=196318.307550 step=0.050000
2017/08/30 09:33:16 step 4: mse=195628.067096 step=0.050000
2017/08/30 09:33:17 step 5: mse=194600.829952 step=0.050000
2017/08/30 09:33:19 step 6: mse=194366.915802 step=0.050000
2017/08/30 09:33:20 step 7: mse=194095.839273 step=0.050000
2017/08/30 09:33:20 Saving...
2017/08/30 09:33:20 Gathering batch of experience...
2017/08/30 09:33:55 batch 976: mean=16688.947368 stddev=9275.127688 entropy=0.331581 frames=7585 count=19
2017/08/30 09:33:55 Training policy...
2017/08/30 09:34:02 tune 0: objective=85.595328 reg=0.003316 prune=0
2017/08/30 09:34:04 step 0: objective=85.626879 reg=0.003316
2017/08/30 09:34:07 step 1: objective=85.651426 reg=0.003316
2017/08/30 09:34:09 step 2: objective=85.675717 reg=0.003316
2017/08/30 09:34:11 step 3: objective=85.689758 reg=0.003316
2017/08/30 09:34:13 step 4: objective=85.715038 reg=0.003316
2017/08/30 09:34:16 step 5: objective=85.745633 reg=0.003317
2017/08/30 09:34:18 step 6: objective=85.775503 reg=0.003317
2017/08/30 09:34:20 step 7: objective=85.798706 reg=0.003317
2017/08/30 09:34:20 Training value function...
2017/08/30 09:34:23 step 0: mse=189159.966840 step=0.050000
2017/08/30 09:34:25 step 1: mse=188504.620874 step=0.050000
2017/08/30 09:34:26 step 2: mse=188872.309499 step=0.050000
2017/08/30 09:34:27 step 3: mse=188006.164479 step=0.050000
2017/08/30 09:34:28 step 4: mse=188406.923642 step=0.050000
2017/08/30 09:34:30 step 5: mse=188949.714679 step=0.050000
2017/08/30 09:34:31 step 6: mse=186528.527612 step=0.050000
2017/08/30 09:34:32 step 7: mse=186604.413268 step=0.050000
2017/08/30 09:34:32 Saving...
2017/08/30 09:34:32 Gathering batch of experience...
2017/08/30 09:35:08 batch 977: mean=13192.272727 stddev=10279.108969 entropy=0.336251 frames=7488 count=22
2017/08/30 09:35:08 Training policy...
2017/08/30 09:35:15 tune 0: objective=70.240318 reg=0.003363 prune=0
2017/08/30 09:35:17 step 0: objective=70.302784 reg=0.003362
2017/08/30 09:35:19 step 1: objective=70.386844 reg=0.003362
2017/08/30 09:35:21 step 2: objective=70.443610 reg=0.003363
2017/08/30 09:35:24 step 3: objective=70.479784 reg=0.003363
2017/08/30 09:35:26 step 4: objective=70.530591 reg=0.003363
2017/08/30 09:35:28 step 5: objective=70.584393 reg=0.003363
2017/08/30 09:35:31 step 6: objective=70.630183 reg=0.003363
2017/08/30 09:35:33 step 7: objective=70.695613 reg=0.003363
2017/08/30 09:35:33 Training value function...
2017/08/30 09:35:36 step 0: mse=187200.244903 step=0.050000
2017/08/30 09:35:37 step 1: mse=188771.182963 step=0.050000
2017/08/30 09:35:38 step 2: mse=190176.361515 step=0.050000
2017/08/30 09:35:40 step 3: mse=191447.122221 step=0.050000
2017/08/30 09:35:41 step 4: mse=192335.281706 step=0.050000
2017/08/30 09:35:42 step 5: mse=192458.406031 step=0.050000
2017/08/30 09:35:43 step 6: mse=193735.181026 step=0.050000
2017/08/30 09:35:44 step 7: mse=193361.668159 step=0.050000
2017/08/30 09:35:44 Saving...
2017/08/30 09:35:45 Gathering batch of experience...
2017/08/30 09:36:15 batch 978: mean=10062.272727 stddev=10073.418523 entropy=0.334332 frames=6193 count=22
2017/08/30 09:36:15 Training policy...
2017/08/30 09:36:21 tune 0: objective=52.081922 reg=0.003343 prune=0
2017/08/30 09:36:23 step 0: objective=52.184906 reg=0.003341
2017/08/30 09:36:24 step 1: objective=52.256651 reg=0.003340
2017/08/30 09:36:26 step 2: objective=52.314201 reg=0.003338
2017/08/30 09:36:28 step 3: objective=52.378229 reg=0.003337
2017/08/30 09:36:30 step 4: objective=52.414818 reg=0.003336
2017/08/30 09:36:32 step 5: objective=52.455701 reg=0.003335
2017/08/30 09:36:34 step 6: objective=52.537588 reg=0.003334
2017/08/30 09:36:36 step 7: objective=52.585303 reg=0.003333
2017/08/30 09:36:36 Training value function...
2017/08/30 09:36:38 step 0: mse=232620.227765 step=0.050000
2017/08/30 09:36:39 step 1: mse=233084.688526 step=0.050000
2017/08/30 09:36:40 step 2: mse=234473.895661 step=0.050000
2017/08/30 09:36:41 step 3: mse=236147.111455 step=0.050000
2017/08/30 09:36:42 step 4: mse=237167.151651 step=0.050000
2017/08/30 09:36:43 step 5: mse=237061.069393 step=0.050000
2017/08/30 09:36:44 step 6: mse=235974.872452 step=0.050000
2017/08/30 09:36:45 step 7: mse=236629.673877 step=0.050000
2017/08/30 09:36:45 Saving...
2017/08/30 09:36:45 Gathering batch of experience...
2017/08/30 09:37:19 batch 979: mean=12293.863636 stddev=9887.549785 entropy=0.332775 frames=7141 count=22
2017/08/30 09:37:19 Training policy...
2017/08/30 09:37:26 tune 0: objective=64.536103 reg=0.003328 prune=0
2017/08/30 09:37:28 step 0: objective=64.591781 reg=0.003327
2017/08/30 09:37:31 step 1: objective=64.627455 reg=0.003327
2017/08/30 09:37:33 step 2: objective=64.675768 reg=0.003327
2017/08/30 09:37:35 step 3: objective=64.701876 reg=0.003327
2017/08/30 09:37:37 step 4: objective=64.738268 reg=0.003327
2017/08/30 09:37:39 step 5: objective=64.779718 reg=0.003327
2017/08/30 09:37:41 step 6: objective=64.836407 reg=0.003327
2017/08/30 09:37:44 step 7: objective=64.878190 reg=0.003327
2017/08/30 09:37:44 Training value function...
2017/08/30 09:37:46 step 0: mse=204624.579799 step=0.050000
2017/08/30 09:37:48 step 1: mse=205543.373410 step=0.050000
2017/08/30 09:37:49 step 2: mse=206655.025717 step=0.050000
2017/08/30 09:37:50 step 3: mse=206373.011907 step=0.050000
2017/08/30 09:37:51 step 4: mse=206443.708389 step=0.050000
2017/08/30 09:37:52 step 5: mse=206678.982203 step=0.050000
2017/08/30 09:37:54 step 6: mse=206671.144785 step=0.050000
2017/08/30 09:37:55 step 7: mse=205905.531157 step=0.050000
2017/08/30 09:37:55 Saving...
2017/08/30 09:37:55 Gathering batch of experience...
2017/08/30 09:38:28 batch 980: mean=13117.380952 stddev=10288.090621 entropy=0.332586 frames=6960 count=21
2017/08/30 09:38:28 Training policy...
2017/08/30 09:38:34 tune 0: objective=75.890876 reg=0.003326 prune=0
2017/08/30 09:38:36 step 0: objective=75.945788 reg=0.003326
2017/08/30 09:38:38 step 1: objective=75.980594 reg=0.003326
2017/08/30 09:38:41 step 2: objective=76.018552 reg=0.003325
2017/08/30 09:38:43 step 3: objective=76.065544 reg=0.003325
2017/08/30 09:38:45 step 4: objective=76.110695 reg=0.003325
2017/08/30 09:38:47 step 5: objective=76.149192 reg=0.003325
2017/08/30 09:38:49 step 6: objective=76.183324 reg=0.003325
2017/08/30 09:38:51 step 7: objective=76.220788 reg=0.003325
2017/08/30 09:38:51 Training value function...
2017/08/30 09:38:54 step 0: mse=184900.770993 step=0.050000
2017/08/30 09:38:55 step 1: mse=185051.032870 step=0.050000
2017/08/30 09:38:56 step 2: mse=184702.319172 step=0.050000
2017/08/30 09:38:58 step 3: mse=184234.581372 step=0.050000
2017/08/30 09:38:59 step 4: mse=183997.525387 step=0.050000
2017/08/30 09:39:00 step 5: mse=181326.025025 step=0.050000
2017/08/30 09:39:01 step 6: mse=181846.546636 step=0.050000
2017/08/30 09:39:02 step 7: mse=182395.968415 step=0.050000
2017/08/30 09:39:02 Saving...
2017/08/30 09:39:02 Gathering batch of experience...
2017/08/30 09:39:36 batch 981: mean=11496.086957 stddev=10184.885429 entropy=0.330213 frames=6884 count=23
2017/08/30 09:39:36 Training policy...
2017/08/30 09:39:42 tune 0: objective=76.269193 reg=0.003302 prune=0
2017/08/30 09:39:45 step 0: objective=76.317984 reg=0.003301
2017/08/30 09:39:47 step 1: objective=76.375318 reg=0.003300
2017/08/30 09:39:49 step 2: objective=76.439951 reg=0.003299
2017/08/30 09:39:51 step 3: objective=76.483213 reg=0.003298
2017/08/30 09:39:53 step 4: objective=76.511058 reg=0.003297
2017/08/30 09:39:55 step 5: objective=76.535771 reg=0.003296
2017/08/30 09:39:57 step 6: objective=76.556717 reg=0.003296
2017/08/30 09:39:59 step 7: objective=76.580422 reg=0.003295
2017/08/30 09:39:59 Training value function...
2017/08/30 09:40:02 step 0: mse=221546.104650 step=0.050000
2017/08/30 09:40:03 step 1: mse=220183.662273 step=0.050000
2017/08/30 09:40:04 step 2: mse=220728.136239 step=0.050000
2017/08/30 09:40:06 step 3: mse=218205.873892 step=0.050000
2017/08/30 09:40:07 step 4: mse=215300.198423 step=0.050000
2017/08/30 09:40:08 step 5: mse=213737.152846 step=0.050000
2017/08/30 09:40:09 step 6: mse=211243.994827 step=0.050000
2017/08/30 09:40:10 step 7: mse=212544.426575 step=0.050000
2017/08/30 09:40:10 Saving...
2017/08/30 09:40:10 Gathering batch of experience...
2017/08/30 09:40:42 batch 982: mean=13703.250000 stddev=10119.274835 entropy=0.336889 frames=6850 count=20
2017/08/30 09:40:42 Training policy...
2017/08/30 09:40:49 tune 0: objective=79.917701 reg=0.003369 prune=0
2017/08/30 09:40:51 step 0: objective=79.953349 reg=0.003369
2017/08/30 09:40:53 step 1: objective=80.000675 reg=0.003368
2017/08/30 09:40:55 step 2: objective=80.050009 reg=0.003368
2017/08/30 09:40:57 step 3: objective=80.101104 reg=0.003368
2017/08/30 09:40:59 step 4: objective=80.145438 reg=0.003368
2017/08/30 09:41:01 step 5: objective=80.183805 reg=0.003367
2017/08/30 09:41:03 step 6: objective=80.229115 reg=0.003367
2017/08/30 09:41:05 step 7: objective=80.262765 reg=0.003366
2017/08/30 09:41:05 Training value function...
2017/08/30 09:41:08 step 0: mse=183397.071182 step=0.050000
2017/08/30 09:41:09 step 1: mse=183082.011804 step=0.050000
2017/08/30 09:41:10 step 2: mse=182834.066886 step=0.050000
2017/08/30 09:41:11 step 3: mse=183597.596158 step=0.050000
2017/08/30 09:41:13 step 4: mse=183216.809198 step=0.050000
2017/08/30 09:41:14 step 5: mse=184254.497739 step=0.050000
2017/08/30 09:41:15 step 6: mse=185867.023991 step=0.050000
2017/08/30 09:41:16 step 7: mse=186236.250625 step=0.050000
2017/08/30 09:41:16 Saving...
2017/08/30 09:41:16 Gathering batch of experience...
2017/08/30 09:41:53 batch 983: mean=17945.263158 stddev=8408.004249 entropy=0.329789 frames=8206 count=19
2017/08/30 09:41:53 Training policy...
2017/08/30 09:42:01 tune 0: objective=91.322576 reg=0.003298 prune=0
2017/08/30 09:42:04 step 0: objective=91.348937 reg=0.003297
2017/08/30 09:42:06 step 1: objective=91.373279 reg=0.003297
2017/08/30 09:42:09 step 2: objective=91.387080 reg=0.003297
2017/08/30 09:42:11 step 3: objective=91.434613 reg=0.003297
2017/08/30 09:42:14 step 4: objective=91.454584 reg=0.003297
2017/08/30 09:42:16 step 5: objective=91.473655 reg=0.003297
2017/08/30 09:42:19 step 6: objective=91.496154 reg=0.003296
2017/08/30 09:42:21 step 7: objective=91.531448 reg=0.003296
2017/08/30 09:42:21 Training value function...
2017/08/30 09:42:25 step 0: mse=206980.337188 step=0.050000
2017/08/30 09:42:26 step 1: mse=204365.028986 step=0.050000
2017/08/30 09:42:27 step 2: mse=203163.398559 step=0.050000
2017/08/30 09:42:29 step 3: mse=202962.413719 step=0.050000
2017/08/30 09:42:30 step 4: mse=203483.887886 step=0.050000
2017/08/30 09:42:31 step 5: mse=202815.329615 step=0.050000
2017/08/30 09:42:33 step 6: mse=202582.872894 step=0.050000
2017/08/30 09:42:34 step 7: mse=201702.358304 step=0.050000
2017/08/30 09:42:34 Saving...
2017/08/30 09:42:34 Gathering batch of experience...
2017/08/30 09:43:06 batch 984: mean=15556.111111 stddev=9385.839446 entropy=0.329631 frames=6961 count=18
2017/08/30 09:43:06 Training policy...
2017/08/30 09:43:13 tune 0: objective=71.262184 reg=0.003296 prune=0
2017/08/30 09:43:15 step 0: objective=71.321384 reg=0.003296
2017/08/30 09:43:17 step 1: objective=71.381334 reg=0.003297
2017/08/30 09:43:19 step 2: objective=71.412647 reg=0.003297
2017/08/30 09:43:21 step 3: objective=71.455677 reg=0.003298
2017/08/30 09:43:23 step 4: objective=71.518931 reg=0.003299
2017/08/30 09:43:25 step 5: objective=71.557598 reg=0.003299
2017/08/30 09:43:27 step 6: objective=71.606940 reg=0.003299
2017/08/30 09:43:30 step 7: objective=71.647563 reg=0.003299
2017/08/30 09:43:30 Training value function...
2017/08/30 09:43:32 step 0: mse=180472.775291 step=0.050000
2017/08/30 09:43:34 step 1: mse=180854.180246 step=0.050000
2017/08/30 09:43:35 step 2: mse=180306.407782 step=0.050000
2017/08/30 09:43:36 step 3: mse=181041.614747 step=0.050000
2017/08/30 09:43:37 step 4: mse=181502.972316 step=0.050000
2017/08/30 09:43:38 step 5: mse=183618.531147 step=0.050000
2017/08/30 09:43:39 step 6: mse=184283.606979 step=0.050000
2017/08/30 09:43:40 step 7: mse=185179.104941 step=0.050000
2017/08/30 09:43:40 Saving...
2017/08/30 09:43:40 Gathering batch of experience...
2017/08/30 09:44:13 batch 985: mean=12024.545455 stddev=10267.888925 entropy=0.329263 frames=7030 count=22
2017/08/30 09:44:13 Training policy...
2017/08/30 09:44:20 tune 0: objective=69.208135 reg=0.003293 prune=0
2017/08/30 09:44:22 step 0: objective=69.251934 reg=0.003292
2017/08/30 09:44:24 step 1: objective=69.281019 reg=0.003293
2017/08/30 09:44:26 step 2: objective=69.306312 reg=0.003293
2017/08/30 09:44:29 step 3: objective=69.352503 reg=0.003293
2017/08/30 09:44:31 step 4: objective=69.378978 reg=0.003292
2017/08/30 09:44:33 step 5: objective=69.402560 reg=0.003292
2017/08/30 09:44:35 step 6: objective=69.424218 reg=0.003292
2017/08/30 09:44:37 step 7: objective=69.447822 reg=0.003291
2017/08/30 09:44:37 Training value function...
2017/08/30 09:44:40 step 0: mse=178875.604132 step=0.050000
2017/08/30 09:44:41 step 1: mse=179166.267518 step=0.050000
2017/08/30 09:44:42 step 2: mse=179209.111604 step=0.050000
2017/08/30 09:44:44 step 3: mse=178148.098075 step=0.050000
2017/08/30 09:44:45 step 4: mse=177973.687035 step=0.050000
2017/08/30 09:44:46 step 5: mse=174923.765110 step=0.050000
2017/08/30 09:44:47 step 6: mse=175544.880111 step=0.050000
2017/08/30 09:44:48 step 7: mse=175756.470972 step=0.050000
2017/08/30 09:44:48 Saving...
2017/08/30 09:44:48 Gathering batch of experience...
2017/08/30 09:45:23 batch 986: mean=15837.631579 stddev=9695.375100 entropy=0.330205 frames=7384 count=19
2017/08/30 09:45:23 Training policy...
2017/08/30 09:45:30 tune 0: objective=88.446345 reg=0.003302 prune=0
2017/08/30 09:45:32 step 0: objective=88.492204 reg=0.003302
2017/08/30 09:45:34 step 1: objective=88.517191 reg=0.003302
2017/08/30 09:45:36 step 2: objective=88.551353 reg=0.003302
2017/08/30 09:45:39 step 3: objective=88.599514 reg=0.003302
2017/08/30 09:45:41 step 4: objective=88.625965 reg=0.003301
2017/08/30 09:45:43 step 5: objective=88.650393 reg=0.003301
2017/08/30 09:45:45 step 6: objective=88.683141 reg=0.003301
2017/08/30 09:45:48 step 7: objective=88.705173 reg=0.003300
2017/08/30 09:45:48 Training value function...
2017/08/30 09:45:51 step 0: mse=208175.809748 step=0.050000
2017/08/30 09:45:52 step 1: mse=206791.663500 step=0.050000
2017/08/30 09:45:53 step 2: mse=206683.704778 step=0.050000
2017/08/30 09:45:54 step 3: mse=206523.466765 step=0.050000
2017/08/30 09:45:56 step 4: mse=205058.416870 step=0.050000
2017/08/30 09:45:57 step 5: mse=200986.870449 step=0.050000
2017/08/30 09:45:58 step 6: mse=199942.890309 step=0.050000
2017/08/30 09:45:59 step 7: mse=197281.842068 step=0.050000
2017/08/30 09:45:59 Saving...
2017/08/30 09:45:59 Gathering batch of experience...
2017/08/30 09:46:33 batch 987: mean=12897.954545 stddev=10041.708210 entropy=0.330975 frames=7241 count=22
2017/08/30 09:46:33 Training policy...
2017/08/30 09:46:40 tune 0: objective=70.551107 reg=0.003310 prune=0
2017/08/30 09:46:43 step 0: objective=70.599753 reg=0.003309
2017/08/30 09:46:45 step 1: objective=70.661312 reg=0.003309
2017/08/30 09:46:47 step 2: objective=70.713092 reg=0.003308
2017/08/30 09:46:49 step 3: objective=70.757060 reg=0.003307
2017/08/30 09:46:51 step 4: objective=70.798219 reg=0.003307
2017/08/30 09:46:54 step 5: objective=70.842770 reg=0.003306
2017/08/30 09:46:56 step 6: objective=70.873364 reg=0.003306
2017/08/30 09:46:58 step 7: objective=70.900186 reg=0.003306
2017/08/30 09:46:58 Training value function...
2017/08/30 09:47:01 step 0: mse=218558.799207 step=0.050000
2017/08/30 09:47:02 step 1: mse=219749.676254 step=0.050000
2017/08/30 09:47:03 step 2: mse=219186.481531 step=0.050000
2017/08/30 09:47:05 step 3: mse=216231.582630 step=0.050000
2017/08/30 09:47:06 step 4: mse=216267.132716 step=0.050000
2017/08/30 09:47:07 step 5: mse=216754.129050 step=0.050000
2017/08/30 09:47:08 step 6: mse=217703.410154 step=0.050000
2017/08/30 09:47:09 step 7: mse=218636.830107 step=0.050000
2017/08/30 09:47:09 Saving...
2017/08/30 09:47:09 Gathering batch of experience...
2017/08/30 09:47:43 batch 988: mean=10907.916667 stddev=10484.594842 entropy=0.334120 frames=6930 count=24
2017/08/30 09:47:43 Training policy...
2017/08/30 09:47:50 tune 0: objective=64.973661 reg=0.003341 prune=0
2017/08/30 09:47:52 step 0: objective=65.012793 reg=0.003341
2017/08/30 09:47:54 step 1: objective=65.045391 reg=0.003341
2017/08/30 09:47:56 step 2: objective=65.085015 reg=0.003340
2017/08/30 09:47:58 step 3: objective=65.121870 reg=0.003340
2017/08/30 09:48:01 step 4: objective=65.158022 reg=0.003339
2017/08/30 09:48:03 step 5: objective=65.193953 reg=0.003339
2017/08/30 09:48:05 step 6: objective=65.240278 reg=0.003338
2017/08/30 09:48:07 step 7: objective=65.278265 reg=0.003338
2017/08/30 09:48:07 Training value function...
2017/08/30 09:48:10 step 0: mse=181692.856845 step=0.050000
2017/08/30 09:48:11 step 1: mse=181998.087409 step=0.050000
2017/08/30 09:48:12 step 2: mse=182178.460989 step=0.050000
2017/08/30 09:48:13 step 3: mse=181881.893975 step=0.050000
2017/08/30 09:48:14 step 4: mse=182512.754584 step=0.050000
2017/08/30 09:48:16 step 5: mse=182085.629106 step=0.050000
2017/08/30 09:48:17 step 6: mse=182592.431595 step=0.050000
2017/08/30 09:48:18 step 7: mse=181845.841068 step=0.050000
2017/08/30 09:48:18 Saving...
2017/08/30 09:48:18 Gathering batch of experience...
2017/08/30 09:48:53 batch 989: mean=12306.739130 stddev=10197.115386 entropy=0.329775 frames=7251 count=23
2017/08/30 09:48:53 Training policy...
2017/08/30 09:49:00 tune 0: objective=71.413758 reg=0.003298 prune=0
2017/08/30 09:49:02 step 0: objective=71.486545 reg=0.003297
2017/08/30 09:49:04 step 1: objective=71.517528 reg=0.003297
2017/08/30 09:49:07 step 2: objective=71.548709 reg=0.003297
2017/08/30 09:49:09 step 3: objective=71.598986 reg=0.003297
2017/08/30 09:49:11 step 4: objective=71.651945 reg=0.003297
2017/08/30 09:49:13 step 5: objective=71.676777 reg=0.003296
2017/08/30 09:49:15 step 6: objective=71.729231 reg=0.003297
2017/08/30 09:49:18 step 7: objective=71.755103 reg=0.003297
2017/08/30 09:49:18 Training value function...
2017/08/30 09:49:21 step 0: mse=204298.647718 step=0.050000
2017/08/30 09:49:22 step 1: mse=205960.629923 step=0.050000
2017/08/30 09:49:23 step 2: mse=208110.988653 step=0.050000
2017/08/30 09:49:24 step 3: mse=209034.271143 step=0.050000
2017/08/30 09:49:25 step 4: mse=209982.531430 step=0.050000
2017/08/30 09:49:27 step 5: mse=208134.392980 step=0.050000
2017/08/30 09:49:28 step 6: mse=207524.806921 step=0.050000
2017/08/30 09:49:29 step 7: mse=205466.051903 step=0.050000
2017/08/30 09:49:29 Saving...
2017/08/30 09:49:29 Gathering batch of experience...
2017/08/30 09:50:03 batch 990: mean=11740.416667 stddev=10629.767060 entropy=0.332096 frames=7155 count=24
2017/08/30 09:50:03 Training policy...
2017/08/30 09:50:10 tune 0: objective=83.676983 reg=0.003321 prune=0
2017/08/30 09:50:12 step 0: objective=83.709705 reg=0.003321
2017/08/30 09:50:14 step 1: objective=83.741649 reg=0.003320
2017/08/30 09:50:16 step 2: objective=83.765348 reg=0.003320
2017/08/30 09:50:18 step 3: objective=83.801223 reg=0.003320
2017/08/30 09:50:21 step 4: objective=83.834923 reg=0.003320
2017/08/30 09:50:23 step 5: objective=83.869706 reg=0.003319
2017/08/30 09:50:25 step 6: objective=83.900952 reg=0.003319
2017/08/30 09:50:27 step 7: objective=83.949869 reg=0.003319
2017/08/30 09:50:27 Training value function...
2017/08/30 09:50:30 step 0: mse=250746.336206 step=0.050000
2017/08/30 09:50:31 step 1: mse=247266.483046 step=0.050000
2017/08/30 09:50:33 step 2: mse=244574.975343 step=0.050000
2017/08/30 09:50:34 step 3: mse=242416.624355 step=0.050000
2017/08/30 09:50:35 step 4: mse=240281.149439 step=0.050000
2017/08/30 09:50:36 step 5: mse=239740.908039 step=0.050000
2017/08/30 09:50:37 step 6: mse=233521.529307 step=0.050000
2017/08/30 09:50:38 step 7: mse=227602.752597 step=0.050000
2017/08/30 09:50:38 Saving...
2017/08/30 09:50:39 Gathering batch of experience...
2017/08/30 09:51:12 batch 991: mean=12452.727273 stddev=10288.860120 entropy=0.329879 frames=6951 count=22
2017/08/30 09:51:12 Training policy...
2017/08/30 09:51:18 tune 0: objective=68.506600 reg=0.003299 prune=0
2017/08/30 09:51:20 step 0: objective=68.536146 reg=0.003298
2017/08/30 09:51:23 step 1: objective=68.557442 reg=0.003298
2017/08/30 09:51:25 step 2: objective=68.596528 reg=0.003297
2017/08/30 09:51:27 step 3: objective=68.645802 reg=0.003296
2017/08/30 09:51:29 step 4: objective=68.671594 reg=0.003295
2017/08/30 09:51:31 step 5: objective=68.696267 reg=0.003295
2017/08/30 09:51:33 step 6: objective=68.721137 reg=0.003294
2017/08/30 09:51:35 step 7: objective=68.754370 reg=0.003293
2017/08/30 09:51:35 Training value function...
2017/08/30 09:51:38 step 0: mse=177504.784545 step=0.050000
2017/08/30 09:51:39 step 1: mse=179926.856890 step=0.050000
2017/08/30 09:51:41 step 2: mse=180363.900985 step=0.050000
2017/08/30 09:51:42 step 3: mse=180157.170023 step=0.050000
2017/08/30 09:51:43 step 4: mse=181038.248143 step=0.050000
2017/08/30 09:51:44 step 5: mse=181923.308904 step=0.050000
2017/08/30 09:51:45 step 6: mse=180737.759342 step=0.050000
2017/08/30 09:51:46 step 7: mse=182514.841700 step=0.050000
2017/08/30 09:51:46 Saving...
2017/08/30 09:51:46 Gathering batch of experience...
2017/08/30 09:52:17 batch 992: mean=13521.052632 stddev=10036.130070 entropy=0.328542 frames=6585 count=19
2017/08/30 09:52:17 Training policy...
2017/08/30 09:52:24 tune 0: objective=80.151158 reg=0.003285 prune=0
2017/08/30 09:52:26 step 0: objective=80.223481 reg=0.003286
2017/08/30 09:52:28 step 1: objective=80.285013 reg=0.003286
2017/08/30 09:52:30 step 2: objective=80.354214 reg=0.003287
2017/08/30 09:52:32 step 3: objective=80.400380 reg=0.003287
2017/08/30 09:52:34 step 4: objective=80.436503 reg=0.003287
2017/08/30 09:52:36 step 5: objective=80.470349 reg=0.003286
2017/08/30 09:52:38 step 6: objective=80.504584 reg=0.003287
2017/08/30 09:52:40 step 7: objective=80.536560 reg=0.003286
2017/08/30 09:52:40 Training value function...
2017/08/30 09:52:43 step 0: mse=231972.939943 step=0.050000
2017/08/30 09:52:44 step 1: mse=228634.535372 step=0.050000
2017/08/30 09:52:45 step 2: mse=225553.762001 step=0.050000
2017/08/30 09:52:46 step 3: mse=224521.621754 step=0.050000
2017/08/30 09:52:47 step 4: mse=223865.858277 step=0.050000
2017/08/30 09:52:48 step 5: mse=222605.221958 step=0.050000
2017/08/30 09:52:49 step 6: mse=217372.858453 step=0.050000
2017/08/30 09:52:50 step 7: mse=217988.728436 step=0.050000
2017/08/30 09:52:50 Saving...
2017/08/30 09:52:50 Gathering batch of experience...
2017/08/30 09:53:23 batch 993: mean=11475.652174 stddev=10211.329418 entropy=0.330328 frames=6893 count=23
2017/08/30 09:53:23 Training policy...
2017/08/30 09:53:30 tune 0: objective=71.555523 reg=0.003303 prune=0
2017/08/30 09:53:32 step 0: objective=71.605963 reg=0.003303
2017/08/30 09:53:34 step 1: objective=71.650098 reg=0.003303
2017/08/30 09:53:36 step 2: objective=71.691680 reg=0.003302
2017/08/30 09:53:38 step 3: objective=71.724925 reg=0.003302
2017/08/30 09:53:40 step 4: objective=71.764245 reg=0.003302
2017/08/30 09:53:42 step 5: objective=71.790177 reg=0.003301
2017/08/30 09:53:45 step 6: objective=71.806751 reg=0.003301
2017/08/30 09:53:47 step 7: objective=71.824487 reg=0.003301
2017/08/30 09:53:47 Training value function...
2017/08/30 09:53:50 step 0: mse=221981.989602 step=0.050000
2017/08/30 09:53:51 step 1: mse=222802.719664 step=0.050000
2017/08/30 09:53:52 step 2: mse=221701.686238 step=0.050000
2017/08/30 09:53:53 step 3: mse=219979.423912 step=0.050000
2017/08/30 09:53:54 step 4: mse=221239.834425 step=0.050000
2017/08/30 09:53:55 step 5: mse=221092.833448 step=0.050000
2017/08/30 09:53:56 step 6: mse=221936.142035 step=0.050000
2017/08/30 09:53:58 step 7: mse=220927.552255 step=0.050000
2017/08/30 09:53:58 Saving...
2017/08/30 09:53:58 Gathering batch of experience...
2017/08/30 09:54:31 batch 994: mean=14279.500000 stddev=9915.371640 entropy=0.326745 frames=7111 count=20
2017/08/30 09:54:31 Training policy...
2017/08/30 09:54:38 tune 0: objective=84.784243 reg=0.003267 prune=0
2017/08/30 09:54:40 step 0: objective=84.849116 reg=0.003266
2017/08/30 09:54:42 step 1: objective=84.907863 reg=0.003265
2017/08/30 09:54:44 step 2: objective=84.957715 reg=0.003265
2017/08/30 09:54:46 step 3: objective=85.002065 reg=0.003265
2017/08/30 09:54:48 step 4: objective=85.040817 reg=0.003266
2017/08/30 09:54:51 step 5: objective=85.070437 reg=0.003266
2017/08/30 09:54:53 step 6: objective=85.094378 reg=0.003266
2017/08/30 09:54:55 step 7: objective=85.120184 reg=0.003266
2017/08/30 09:54:55 Training value function...
2017/08/30 09:54:58 step 0: mse=249408.078352 step=0.050000
2017/08/30 09:54:59 step 1: mse=243154.556662 step=0.050000
2017/08/30 09:55:00 step 2: mse=240260.237280 step=0.050000
2017/08/30 09:55:02 step 3: mse=237302.622764 step=0.050000
2017/08/30 09:55:03 step 4: mse=236322.917901 step=0.050000
2017/08/30 09:55:04 step 5: mse=231202.868940 step=0.050000
2017/08/30 09:55:05 step 6: mse=228313.789000 step=0.050000
2017/08/30 09:55:06 step 7: mse=228819.839135 step=0.050000
2017/08/30 09:55:06 Saving...
2017/08/30 09:55:06 Gathering batch of experience...
2017/08/30 09:55:41 batch 995: mean=15738.500000 stddev=9694.992148 entropy=0.327149 frames=7499 count=20
2017/08/30 09:55:41 Training policy...
2017/08/30 09:55:48 tune 0: objective=87.893461 reg=0.003271 prune=0
2017/08/30 09:55:50 step 0: objective=87.926940 reg=0.003272
2017/08/30 09:55:52 step 1: objective=87.956669 reg=0.003272
2017/08/30 09:55:55 step 2: objective=87.985898 reg=0.003272
2017/08/30 09:55:57 step 3: objective=88.018736 reg=0.003273
2017/08/30 09:55:59 step 4: objective=88.048423 reg=0.003272
2017/08/30 09:56:02 step 5: objective=88.079436 reg=0.003272
2017/08/30 09:56:04 step 6: objective=88.109556 reg=0.003273
2017/08/30 09:56:06 step 7: objective=88.138368 reg=0.003273
2017/08/30 09:56:06 Training value function...
2017/08/30 09:56:09 step 0: mse=203396.711929 step=0.050000
2017/08/30 09:56:11 step 1: mse=201149.703076 step=0.050000
2017/08/30 09:56:12 step 2: mse=202611.330370 step=0.050000
2017/08/30 09:56:13 step 3: mse=201965.196989 step=0.050000
2017/08/30 09:56:14 step 4: mse=200812.558470 step=0.050000
2017/08/30 09:56:16 step 5: mse=201167.804343 step=0.050000
2017/08/30 09:56:17 step 6: mse=199274.977021 step=0.050000
2017/08/30 09:56:18 step 7: mse=199930.771402 step=0.050000
2017/08/30 09:56:18 Saving...
2017/08/30 09:56:18 Gathering batch of experience...
2017/08/30 09:56:54 batch 996: mean=18737.777778 stddev=8013.876719 entropy=0.326560 frames=7772 count=18
2017/08/30 09:56:54 Training policy...
2017/08/30 09:57:01 tune 0: objective=97.706318 reg=0.003266 prune=0
2017/08/30 09:57:03 step 0: objective=97.744942 reg=0.003265
2017/08/30 09:57:06 step 1: objective=97.799947 reg=0.003264
2017/08/30 09:57:08 step 2: objective=97.836979 reg=0.003263
2017/08/30 09:57:11 step 3: objective=97.868004 reg=0.003263
2017/08/30 09:57:13 step 4: objective=97.902808 reg=0.003262
2017/08/30 09:57:15 step 5: objective=97.942003 reg=0.003261
2017/08/30 09:57:18 step 6: objective=97.961529 reg=0.003261
2017/08/30 09:57:20 step 7: objective=97.985831 reg=0.003260
2017/08/30 09:57:20 Training value function...
2017/08/30 09:57:23 step 0: mse=226976.004541 step=0.050000
2017/08/30 09:57:25 step 1: mse=224544.151427 step=0.050000
2017/08/30 09:57:26 step 2: mse=225342.717217 step=0.050000
2017/08/30 09:57:27 step 3: mse=222562.140451 step=0.050000
2017/08/30 09:57:29 step 4: mse=219897.824760 step=0.050000
2017/08/30 09:57:30 step 5: mse=220543.037679 step=0.050000
2017/08/30 09:57:31 step 6: mse=219643.112213 step=0.050000
2017/08/30 09:57:32 step 7: mse=219208.165706 step=0.050000
2017/08/30 09:57:32 Saving...
2017/08/30 09:57:32 Gathering batch of experience...
2017/08/30 09:58:10 batch 997: mean=15321.363636 stddev=9784.641047 entropy=0.326391 frames=8075 count=22
2017/08/30 09:58:10 Training policy...
2017/08/30 09:58:18 tune 0: objective=79.342732 reg=0.003264 prune=0
2017/08/30 09:58:20 step 0: objective=79.378506 reg=0.003264
2017/08/30 09:58:23 step 1: objective=79.419211 reg=0.003264
2017/08/30 09:58:25 step 2: objective=79.458096 reg=0.003264
2017/08/30 09:58:28 step 3: objective=79.495054 reg=0.003264
2017/08/30 09:58:30 step 4: objective=79.520797 reg=0.003264
2017/08/30 09:58:33 step 5: objective=79.541161 reg=0.003264
2017/08/30 09:58:35 step 6: objective=79.563050 reg=0.003263
2017/08/30 09:58:38 step 7: objective=79.589358 reg=0.003263
2017/08/30 09:58:38 Training value function...
2017/08/30 09:58:41 step 0: mse=208473.617295 step=0.050000
2017/08/30 09:58:43 step 1: mse=203761.164103 step=0.050000
2017/08/30 09:58:44 step 2: mse=201694.427973 step=0.050000
2017/08/30 09:58:45 step 3: mse=202666.782242 step=0.050000
2017/08/30 09:58:47 step 4: mse=200925.946429 step=0.050000
2017/08/30 09:58:48 step 5: mse=202017.583290 step=0.050000
2017/08/30 09:58:49 step 6: mse=198197.454534 step=0.050000
2017/08/30 09:58:51 step 7: mse=195169.493691 step=0.050000
2017/08/30 09:58:51 Saving...
2017/08/30 09:58:51 Gathering batch of experience...
2017/08/30 09:59:25 batch 998: mean=12106.590909 stddev=10254.016440 entropy=0.326661 frames=7044 count=22
2017/08/30 09:59:25 Training policy...
2017/08/30 09:59:32 tune 0: objective=60.561564 reg=0.003267 prune=0
2017/08/30 09:59:34 step 0: objective=60.608071 reg=0.003265
2017/08/30 09:59:36 step 1: objective=60.640314 reg=0.003265
2017/08/30 09:59:38 step 2: objective=60.680459 reg=0.003265
2017/08/30 09:59:40 step 3: objective=60.704540 reg=0.003265
2017/08/30 09:59:42 step 4: objective=60.732574 reg=0.003264
2017/08/30 09:59:45 step 5: objective=60.754015 reg=0.003264
2017/08/30 09:59:47 step 6: objective=60.779546 reg=0.003265
2017/08/30 09:59:49 step 7: objective=60.803024 reg=0.003265
2017/08/30 09:59:49 Training value function...
2017/08/30 09:59:52 step 0: mse=171885.654915 step=0.050000
2017/08/30 09:59:53 step 1: mse=170413.641461 step=0.050000
2017/08/30 09:59:54 step 2: mse=171805.105147 step=0.050000
2017/08/30 09:59:55 step 3: mse=171377.557004 step=0.050000
2017/08/30 09:59:57 step 4: mse=172730.845593 step=0.050000
2017/08/30 09:59:58 step 5: mse=173417.886788 step=0.050000
2017/08/30 09:59:59 step 6: mse=173906.696052 step=0.050000
2017/08/30 10:00:00 step 7: mse=174094.284131 step=0.050000
2017/08/30 10:00:00 Saving...
2017/08/30 10:00:00 Gathering batch of experience...
2017/08/30 10:00:35 batch 999: mean=15029.000000 stddev=10160.933840 entropy=0.326335 frames=7327 count=20
2017/08/30 10:00:35 Training policy...
2017/08/30 10:00:42 tune 0: objective=86.556981 reg=0.003263 prune=0
2017/08/30 10:00:44 step 0: objective=86.595964 reg=0.003263
2017/08/30 10:00:46 step 1: objective=86.643928 reg=0.003262
2017/08/30 10:00:49 step 2: objective=86.687244 reg=0.003262
2017/08/30 10:00:51 step 3: objective=86.741641 reg=0.003261
2017/08/30 10:00:53 step 4: objective=86.776273 reg=0.003261
2017/08/30 10:00:55 step 5: objective=86.809045 reg=0.003261
2017/08/30 10:00:58 step 6: objective=86.841963 reg=0.003261
2017/08/30 10:01:00 step 7: objective=86.891693 reg=0.003260
2017/08/30 10:01:00 Training value function...
2017/08/30 10:01:03 step 0: mse=200427.701140 step=0.050000
2017/08/30 10:01:04 step 1: mse=197675.259554 step=0.050000
2017/08/30 10:01:05 step 2: mse=193904.311495 step=0.050000
2017/08/30 10:01:07 step 3: mse=193712.705077 step=0.050000
2017/08/30 10:01:08 step 4: mse=192247.230806 step=0.050000
2017/08/30 10:01:09 step 5: mse=192330.296676 step=0.050000
2017/08/30 10:01:10 step 6: mse=192892.885107 step=0.050000
2017/08/30 10:01:11 step 7: mse=195057.438655 step=0.050000
2017/08/30 10:01:11 Saving...
2017/08/30 10:01:11 Gathering batch of experience...
2017/08/30 10:01:46 batch 1000: mean=16104.473684 stddev=9197.452149 entropy=0.322777 frames=7359 count=19
2017/08/30 10:01:46 Training policy...
2017/08/30 10:01:53 tune 0: objective=80.379535 reg=0.003228 prune=0
2017/08/30 10:01:55 step 0: objective=80.451471 reg=0.003228
2017/08/30 10:01:57 step 1: objective=80.491465 reg=0.003227
2017/08/30 10:02:00 step 2: objective=80.524655 reg=0.003227
2017/08/30 10:02:02 step 3: objective=80.565787 reg=0.003226
2017/08/30 10:02:04 step 4: objective=80.623794 reg=0.003226
2017/08/30 10:02:06 step 5: objective=80.651736 reg=0.003226
2017/08/30 10:02:09 step 6: objective=80.672799 reg=0.003226
2017/08/30 10:02:11 step 7: objective=80.697284 reg=0.003225
2017/08/30 10:02:11 Training value function...
2017/08/30 10:02:14 step 0: mse=200169.775322 step=0.050000
2017/08/30 10:02:15 step 1: mse=201068.992494 step=0.050000
2017/08/30 10:02:16 step 2: mse=201939.710137 step=0.050000
2017/08/30 10:02:18 step 3: mse=200452.752716 step=0.050000
2017/08/30 10:02:19 step 4: mse=201323.430018 step=0.050000
2017/08/30 10:02:20 step 5: mse=198313.471709 step=0.050000
2017/08/30 10:02:21 step 6: mse=196733.806893 step=0.050000
2017/08/30 10:02:23 step 7: mse=197997.568063 step=0.050000
2017/08/30 10:02:23 Saving...
2017/08/30 10:02:23 Gathering batch of experience...
2017/08/30 10:02:54 batch 1001: mean=10343.409091 stddev=9690.756536 entropy=0.325195 frames=6264 count=22
2017/08/30 10:02:54 Training policy...
2017/08/30 10:03:00 tune 0: objective=42.859545 reg=0.003252 prune=0
2017/08/30 10:03:02 step 0: objective=43.007887 reg=0.003252
2017/08/30 10:03:04 step 1: objective=43.111470 reg=0.003253
2017/08/30 10:03:06 step 2: objective=43.213656 reg=0.003254
2017/08/30 10:03:08 step 3: objective=43.297568 reg=0.003256
2017/08/30 10:03:10 step 4: objective=43.331892 reg=0.003256
2017/08/30 10:03:11 step 5: objective=43.365721 reg=0.003256
2017/08/30 10:03:13 step 6: objective=43.387287 reg=0.003256
2017/08/30 10:03:15 step 7: objective=43.415045 reg=0.003257
2017/08/30 10:03:15 Training value function...
2017/08/30 10:03:18 step 0: mse=181803.452245 step=0.050000
2017/08/30 10:03:19 step 1: mse=182919.645548 step=0.050000
2017/08/30 10:03:20 step 2: mse=183746.957725 step=0.050000
2017/08/30 10:03:21 step 3: mse=184991.670700 step=0.050000
2017/08/30 10:03:22 step 4: mse=187148.189449 step=0.050000
2017/08/30 10:03:23 step 5: mse=189376.544294 step=0.050000
2017/08/30 10:03:24 step 6: mse=190662.560602 step=0.050000
2017/08/30 10:03:25 step 7: mse=192791.363953 step=0.050000
2017/08/30 10:03:25 Saving...
2017/08/30 10:03:25 Gathering batch of experience...
2017/08/30 10:03:56 batch 1002: mean=12738.250000 stddev=10195.781637 entropy=0.328308 frames=6507 count=20
2017/08/30 10:03:56 Training policy...
2017/08/30 10:04:03 tune 0: objective=77.253943 reg=0.003283 prune=0
2017/08/30 10:04:05 step 0: objective=77.302602 reg=0.003282
2017/08/30 10:04:07 step 1: objective=77.365731 reg=0.003281
2017/08/30 10:04:09 step 2: objective=77.409847 reg=0.003281
2017/08/30 10:04:11 step 3: objective=77.465350 reg=0.003281
2017/08/30 10:04:13 step 4: objective=77.502589 reg=0.003280
2017/08/30 10:04:15 step 5: objective=77.546733 reg=0.003279
2017/08/30 10:04:17 step 6: objective=77.584726 reg=0.003279
2017/08/30 10:04:19 step 7: objective=77.632578 reg=0.003278
2017/08/30 10:04:19 Training value function...
2017/08/30 10:04:22 step 0: mse=202472.022155 step=0.050000
2017/08/30 10:04:23 step 1: mse=202120.441096 step=0.050000
2017/08/30 10:04:24 step 2: mse=201235.461698 step=0.050000
2017/08/30 10:04:25 step 3: mse=200683.763321 step=0.050000
2017/08/30 10:04:26 step 4: mse=200183.858071 step=0.050000
2017/08/30 10:04:27 step 5: mse=199839.676892 step=0.050000
2017/08/30 10:04:28 step 6: mse=200209.129917 step=0.050000
2017/08/30 10:04:29 step 7: mse=200498.988925 step=0.050000
2017/08/30 10:04:29 Saving...
2017/08/30 10:04:29 Gathering batch of experience...
2017/08/30 10:05:00 batch 1003: mean=9955.000000 stddev=10448.596198 entropy=0.331006 frames=6290 count=24
2017/08/30 10:05:00 Training policy...
2017/08/30 10:05:06 tune 0: objective=71.487674 reg=0.003310 prune=0
2017/08/30 10:05:08 step 0: objective=71.518308 reg=0.003310
2017/08/30 10:05:10 step 1: objective=71.550144 reg=0.003310
2017/08/30 10:05:12 step 2: objective=71.585453 reg=0.003310
2017/08/30 10:05:14 step 3: objective=71.630977 reg=0.003309
2017/08/30 10:05:16 step 4: objective=71.665550 reg=0.003310
2017/08/30 10:05:18 step 5: objective=71.693099 reg=0.003309
2017/08/30 10:05:20 step 6: objective=71.718969 reg=0.003308
2017/08/30 10:05:22 step 7: objective=71.743556 reg=0.003309
2017/08/30 10:05:22 Training value function...
2017/08/30 10:05:24 step 0: mse=185010.426702 step=0.050000
2017/08/30 10:05:25 step 1: mse=186650.516158 step=0.050000
2017/08/30 10:05:26 step 2: mse=186546.802545 step=0.050000
2017/08/30 10:05:27 step 3: mse=185083.076156 step=0.050000
2017/08/30 10:05:28 step 4: mse=182970.686526 step=0.050000
2017/08/30 10:05:29 step 5: mse=181836.705367 step=0.050000
2017/08/30 10:05:30 step 6: mse=180312.371310 step=0.050000
2017/08/30 10:05:31 step 7: mse=179082.221712 step=0.050000
2017/08/30 10:05:31 Saving...
2017/08/30 10:05:32 Gathering batch of experience...
