2017/08/28 07:53:01 Run with arguments: [-algo mse -env PenguinSkip-v0 -step 0.03 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic PenguinSkip-v0/critic.json -actor PenguinSkip-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1]
2017/08/28 07:53:01 Creating environments...
2017/08/28 07:53:12 Creating new forest for: PenguinSkip-v0/actor.json
2017/08/28 07:53:12 Creating new forest for: PenguinSkip-v0/critic.json
2017/08/28 07:53:12 Running. Press Ctrl+C to stop.
2017/08/28 07:53:12 Gathering batch of experience...
2017/08/28 07:55:00 batch 0: mean=7.947170 stddev=10.745646 entropy=1.098614 frames=4201 count=265
2017/08/28 07:55:00 Training policy...
2017/08/28 07:55:02 step 0: objective=4.23288
2017/08/28 07:55:03 step 1: objective=4.244571
2017/08/28 07:55:03 step 2: objective=4.2602096
2017/08/28 07:55:04 step 3: objective=4.278128
2017/08/28 07:55:05 step 4: objective=4.2919807
2017/08/28 07:55:06 step 5: objective=4.3082676
2017/08/28 07:55:06 step 6: objective=4.3224792
2017/08/28 07:55:07 step 7: objective=4.3318267
2017/08/28 07:55:07 Training value function...
2017/08/28 07:55:09 step 0: mse=94.443111 step=0.100000
2017/08/28 07:55:09 step 1: mse=85.549845 step=0.100000
2017/08/28 07:55:10 step 2: mse=78.448592 step=0.100000
2017/08/28 07:55:11 step 3: mse=72.811123 step=0.100000
2017/08/28 07:55:11 step 4: mse=67.762312 step=0.100000
2017/08/28 07:55:12 step 5: mse=63.471464 step=0.100000
2017/08/28 07:55:13 step 6: mse=60.108188 step=0.100000
2017/08/28 07:55:14 step 7: mse=57.143131 step=0.100000
2017/08/28 07:55:14 Saving...
2017/08/28 07:55:14 Gathering batch of experience...
2017/08/28 07:57:00 batch 1: mean=7.969466 stddev=9.017319 entropy=1.097517 frames=4199 count=262
2017/08/28 07:57:00 Training policy...
2017/08/28 07:57:02 step 0: objective=1.6385766
2017/08/28 07:57:03 step 1: objective=1.6493332
2017/08/28 07:57:03 step 2: objective=1.6606052
2017/08/28 07:57:04 step 3: objective=1.6713383
2017/08/28 07:57:05 step 4: objective=1.6833192
2017/08/28 07:57:06 step 5: objective=1.6935939
2017/08/28 07:57:06 step 6: objective=1.701506
2017/08/28 07:57:07 step 7: objective=1.7111627
2017/08/28 07:57:07 Training value function...
2017/08/28 07:57:09 step 0: mse=41.458529 step=0.100000
2017/08/28 07:57:09 step 1: mse=39.960283 step=0.100000
2017/08/28 07:57:10 step 2: mse=38.645827 step=0.100000
2017/08/28 07:57:11 step 3: mse=37.405460 step=0.100000
2017/08/28 07:57:12 step 4: mse=36.399816 step=0.100000
2017/08/28 07:57:12 step 5: mse=35.627964 step=0.100000
2017/08/28 07:57:13 step 6: mse=34.931577 step=0.100000
2017/08/28 07:57:14 step 7: mse=34.424541 step=0.100000
2017/08/28 07:57:14 Saving...
2017/08/28 07:57:14 Gathering batch of experience...
2017/08/28 07:59:02 batch 2: mean=8.266160 stddev=9.307050 entropy=1.096046 frames=4219 count=263
2017/08/28 07:59:02 Training policy...
2017/08/28 07:59:04 step 0: objective=1.0246475
2017/08/28 07:59:05 step 1: objective=1.0340503
2017/08/28 07:59:05 step 2: objective=1.0443687
2017/08/28 07:59:06 step 3: objective=1.0526513
2017/08/28 07:59:07 step 4: objective=1.0617986
2017/08/28 07:59:07 step 5: objective=1.0711247
2017/08/28 07:59:08 step 6: objective=1.0785837
2017/08/28 07:59:09 step 7: objective=1.0863007
2017/08/28 07:59:09 Training value function...
2017/08/28 07:59:11 step 0: mse=38.694157 step=0.100000
2017/08/28 07:59:11 step 1: mse=38.140431 step=0.100000
2017/08/28 07:59:12 step 2: mse=37.473791 step=0.100000
2017/08/28 07:59:13 step 3: mse=37.036733 step=0.100000
2017/08/28 07:59:13 step 4: mse=36.489728 step=0.100000
2017/08/28 07:59:14 step 5: mse=35.851773 step=0.100000
2017/08/28 07:59:15 step 6: mse=35.522431 step=0.100000
2017/08/28 07:59:16 step 7: mse=34.947951 step=0.100000
2017/08/28 07:59:16 Saving...
2017/08/28 07:59:16 Gathering batch of experience...
2017/08/28 08:01:05 batch 3: mean=8.154135 stddev=9.723369 entropy=1.094918 frames=4231 count=266
2017/08/28 08:01:05 Training policy...
2017/08/28 08:01:07 step 0: objective=0.64831877
2017/08/28 08:01:08 step 1: objective=0.6592022
2017/08/28 08:01:08 step 2: objective=0.67150974
2017/08/28 08:01:09 step 3: objective=0.6791241
2017/08/28 08:01:10 step 4: objective=0.69134295
2017/08/28 08:01:11 step 5: objective=0.6998358
2017/08/28 08:01:11 step 6: objective=0.7090797
2017/08/28 08:01:12 step 7: objective=0.7178064
2017/08/28 08:01:12 Training value function...
2017/08/28 08:01:14 step 0: mse=41.659131 step=0.100000
2017/08/28 08:01:14 step 1: mse=40.909326 step=0.100000
2017/08/28 08:01:15 step 2: mse=40.181560 step=0.100000
2017/08/28 08:01:16 step 3: mse=39.738436 step=0.100000
2017/08/28 08:01:17 step 4: mse=39.250097 step=0.100000
2017/08/28 08:01:17 step 5: mse=38.627464 step=0.100000
2017/08/28 08:01:18 step 6: mse=38.084037 step=0.100000
2017/08/28 08:01:19 step 7: mse=37.669501 step=0.100000
2017/08/28 08:01:19 Saving...
2017/08/28 08:01:19 Gathering batch of experience...
2017/08/28 08:03:05 batch 4: mean=7.660156 stddev=8.746748 entropy=1.092910 frames=4186 count=256
2017/08/28 08:03:05 Training policy...
2017/08/28 08:03:07 step 0: objective=0.18534932
2017/08/28 08:03:08 step 1: objective=0.19505817
2017/08/28 08:03:09 step 2: objective=0.20498684
2017/08/28 08:03:10 step 3: objective=0.21401036
2017/08/28 08:03:10 step 4: objective=0.22311912
2017/08/28 08:03:11 step 5: objective=0.23263122
2017/08/28 08:03:12 step 6: objective=0.24070553
2017/08/28 08:03:12 step 7: objective=0.24820076
2017/08/28 08:03:12 Training value function...
2017/08/28 08:03:14 step 0: mse=31.977547 step=0.100000
2017/08/28 08:03:15 step 1: mse=31.429226 step=0.100000
2017/08/28 08:03:16 step 2: mse=30.910349 step=0.100000
2017/08/28 08:03:16 step 3: mse=30.370170 step=0.100000
2017/08/28 08:03:17 step 4: mse=29.948882 step=0.100000
2017/08/28 08:03:18 step 5: mse=29.701835 step=0.100000
2017/08/28 08:03:18 step 6: mse=29.336681 step=0.100000
2017/08/28 08:03:19 step 7: mse=29.173783 step=0.100000
2017/08/28 08:03:19 Saving...
2017/08/28 08:03:19 Gathering batch of experience...
2017/08/28 08:05:08 batch 5: mean=7.870722 stddev=9.689398 entropy=1.090768 frames=4208 count=263
2017/08/28 08:05:08 Training policy...
2017/08/28 08:05:10 step 0: objective=0.4209462
2017/08/28 08:05:11 step 1: objective=0.43129572
2017/08/28 08:05:11 step 2: objective=0.4438759
2017/08/28 08:05:12 step 3: objective=0.4569711
2017/08/28 08:05:13 step 4: objective=0.4655636
2017/08/28 08:05:14 step 5: objective=0.47557187
2017/08/28 08:05:14 step 6: objective=0.48300704
2017/08/28 08:05:15 step 7: objective=0.4895769
2017/08/28 08:05:15 Training value function...
2017/08/28 08:05:17 step 0: mse=37.532084 step=0.100000
2017/08/28 08:05:17 step 1: mse=36.933613 step=0.100000
2017/08/28 08:05:18 step 2: mse=36.389317 step=0.100000
2017/08/28 08:05:19 step 3: mse=35.935054 step=0.100000
2017/08/28 08:05:20 step 4: mse=35.319095 step=0.100000
2017/08/28 08:05:20 step 5: mse=34.787303 step=0.100000
2017/08/28 08:05:21 step 6: mse=34.308733 step=0.100000
2017/08/28 08:05:22 step 7: mse=33.950995 step=0.100000
2017/08/28 08:05:22 Saving...
2017/08/28 08:05:22 Gathering batch of experience...
2017/08/28 08:07:03 batch 6: mean=9.118367 stddev=9.630641 entropy=1.088817 frames=4213 count=245
2017/08/28 08:07:03 Training policy...
2017/08/28 08:07:05 step 0: objective=0.85697466
2017/08/28 08:07:06 step 1: objective=0.86900294
2017/08/28 08:07:06 step 2: objective=0.879454
2017/08/28 08:07:07 step 3: objective=0.89039856
2017/08/28 08:07:08 step 4: objective=0.9030726
2017/08/28 08:07:09 step 5: objective=0.9116722
2017/08/28 08:07:09 step 6: objective=0.9217708
2017/08/28 08:07:10 step 7: objective=0.9302399
2017/08/28 08:07:10 Training value function...
2017/08/28 08:07:12 step 0: mse=39.266086 step=0.100000
2017/08/28 08:07:13 step 1: mse=38.436651 step=0.100000
2017/08/28 08:07:13 step 2: mse=38.119922 step=0.100000
2017/08/28 08:07:14 step 3: mse=37.653482 step=0.100000
2017/08/28 08:07:15 step 4: mse=37.125020 step=0.100000
2017/08/28 08:07:16 step 5: mse=36.794471 step=0.100000
2017/08/28 08:07:16 step 6: mse=36.239819 step=0.100000
2017/08/28 08:07:17 step 7: mse=35.964173 step=0.100000
2017/08/28 08:07:17 Saving...
2017/08/28 08:07:17 Gathering batch of experience...
2017/08/28 08:09:05 batch 7: mean=8.469466 stddev=10.206878 entropy=1.085294 frames=4195 count=262
2017/08/28 08:09:05 Training policy...
2017/08/28 08:09:08 step 0: objective=0.3457736
2017/08/28 08:09:08 step 1: objective=0.35579842
2017/08/28 08:09:09 step 2: objective=0.36306095
2017/08/28 08:09:10 step 3: objective=0.371011
2017/08/28 08:09:11 step 4: objective=0.3794404
2017/08/28 08:09:11 step 5: objective=0.38615113
2017/08/28 08:09:12 step 6: objective=0.39341393
2017/08/28 08:09:13 step 7: objective=0.40138283
2017/08/28 08:09:13 Training value function...
2017/08/28 08:09:14 step 0: mse=43.239112 step=0.100000
2017/08/28 08:09:15 step 1: mse=42.440192 step=0.100000
2017/08/28 08:09:16 step 2: mse=41.666605 step=0.100000
2017/08/28 08:09:17 step 3: mse=41.005743 step=0.100000
2017/08/28 08:09:17 step 4: mse=40.240736 step=0.100000
2017/08/28 08:09:18 step 5: mse=39.639027 step=0.100000
2017/08/28 08:09:19 step 6: mse=39.364985 step=0.100000
2017/08/28 08:09:20 step 7: mse=38.904920 step=0.100000
2017/08/28 08:09:20 Saving...
2017/08/28 08:09:20 Gathering batch of experience...
2017/08/28 08:11:04 batch 8: mean=8.623529 stddev=9.957135 entropy=1.083808 frames=4233 count=255
2017/08/28 08:11:04 Training policy...
2017/08/28 08:11:07 step 0: objective=0.47551528
2017/08/28 08:11:07 step 1: objective=0.48576635
2017/08/28 08:11:08 step 2: objective=0.4933249
2017/08/28 08:11:09 step 3: objective=0.50132793
2017/08/28 08:11:10 step 4: objective=0.50854975
2017/08/28 08:11:10 step 5: objective=0.5191125
2017/08/28 08:11:11 step 6: objective=0.5285684
2017/08/28 08:11:12 step 7: objective=0.53479654
2017/08/28 08:11:12 Training value function...
2017/08/28 08:11:13 step 0: mse=42.150260 step=0.100000
2017/08/28 08:11:14 step 1: mse=41.499809 step=0.100000
2017/08/28 08:11:15 step 2: mse=41.076275 step=0.100000
2017/08/28 08:11:16 step 3: mse=40.520171 step=0.100000
2017/08/28 08:11:16 step 4: mse=40.141795 step=0.100000
2017/08/28 08:11:17 step 5: mse=39.914462 step=0.100000
2017/08/28 08:11:18 step 6: mse=39.692430 step=0.100000
2017/08/28 08:11:19 step 7: mse=39.200405 step=0.100000
2017/08/28 08:11:19 Saving...
2017/08/28 08:11:19 Gathering batch of experience...
2017/08/28 08:13:00 batch 9: mean=9.481328 stddev=11.404332 entropy=1.082061 frames=4218 count=241
2017/08/28 08:13:00 Training policy...
2017/08/28 08:13:02 step 0: objective=0.8560063
2017/08/28 08:13:03 step 1: objective=0.8657204
2017/08/28 08:13:04 step 2: objective=0.87443155
2017/08/28 08:13:04 step 3: objective=0.88156736
2017/08/28 08:13:05 step 4: objective=0.89053446
2017/08/28 08:13:06 step 5: objective=0.9009792
2017/08/28 08:13:07 step 6: objective=0.90943575
2017/08/28 08:13:07 step 7: objective=0.91805387
2017/08/28 08:13:07 Training value function...
2017/08/28 08:13:09 step 0: mse=46.944153 step=0.100000
2017/08/28 08:13:10 step 1: mse=46.011456 step=0.100000
2017/08/28 08:13:10 step 2: mse=45.453812 step=0.100000
2017/08/28 08:13:11 step 3: mse=44.653280 step=0.100000
2017/08/28 08:13:12 step 4: mse=44.007600 step=0.100000
2017/08/28 08:13:13 step 5: mse=43.354685 step=0.100000
2017/08/28 08:13:13 step 6: mse=42.911861 step=0.100000
2017/08/28 08:13:14 step 7: mse=42.395713 step=0.100000
2017/08/28 08:13:14 Saving...
2017/08/28 08:13:14 Gathering batch of experience...
2017/08/28 08:15:00 batch 10: mean=8.286822 stddev=9.643405 entropy=1.080651 frames=4248 count=258
2017/08/28 08:15:00 Training policy...
2017/08/28 08:15:03 step 0: objective=-0.088809535
2017/08/28 08:15:03 step 1: objective=-0.0801794
2017/08/28 08:15:04 step 2: objective=-0.073647656
2017/08/28 08:15:05 step 3: objective=-0.06764394
2017/08/28 08:15:06 step 4: objective=-0.058763765
2017/08/28 08:15:06 step 5: objective=-0.05075239
2017/08/28 08:15:07 step 6: objective=-0.042104546
2017/08/28 08:15:08 step 7: objective=-0.03726237
2017/08/28 08:15:08 Training value function...
2017/08/28 08:15:10 step 0: mse=35.443456 step=0.100000
2017/08/28 08:15:10 step 1: mse=34.829189 step=0.100000
2017/08/28 08:15:11 step 2: mse=34.524453 step=0.100000
2017/08/28 08:15:12 step 3: mse=34.226883 step=0.100000
2017/08/28 08:15:13 step 4: mse=33.916219 step=0.100000
2017/08/28 08:15:13 step 5: mse=33.553741 step=0.100000
2017/08/28 08:15:14 step 6: mse=33.270433 step=0.100000
2017/08/28 08:15:15 step 7: mse=33.004859 step=0.100000
2017/08/28 08:15:15 Saving...
2017/08/28 08:15:15 Gathering batch of experience...
2017/08/28 08:16:51 batch 11: mean=9.450644 stddev=10.654883 entropy=1.078434 frames=4193 count=233
2017/08/28 08:16:51 Training policy...
2017/08/28 08:16:53 step 0: objective=0.7777805
2017/08/28 08:16:54 step 1: objective=0.7871265
2017/08/28 08:16:55 step 2: objective=0.79591227
2017/08/28 08:16:56 step 3: objective=0.8069908
2017/08/28 08:16:56 step 4: objective=0.8207511
2017/08/28 08:16:57 step 5: objective=0.8283419
2017/08/28 08:16:58 step 6: objective=0.840506
2017/08/28 08:16:59 step 7: objective=0.8505005
2017/08/28 08:16:59 Training value function...
2017/08/28 08:17:00 step 0: mse=47.904622 step=0.100000
2017/08/28 08:17:01 step 1: mse=47.039566 step=0.100000
2017/08/28 08:17:02 step 2: mse=46.329875 step=0.100000
2017/08/28 08:17:02 step 3: mse=45.772734 step=0.100000
2017/08/28 08:17:03 step 4: mse=45.244612 step=0.100000
2017/08/28 08:17:04 step 5: mse=44.755811 step=0.100000
2017/08/28 08:17:05 step 6: mse=44.454863 step=0.100000
2017/08/28 08:17:06 step 7: mse=43.998338 step=0.100000
2017/08/28 08:17:06 Saving...
2017/08/28 08:17:06 Gathering batch of experience...
2017/08/28 08:18:48 batch 12: mean=9.881633 stddev=12.514737 entropy=1.074922 frames=4264 count=245
2017/08/28 08:18:48 Training policy...
2017/08/28 08:18:50 step 0: objective=0.79882914
2017/08/28 08:18:51 step 1: objective=0.81002825
2017/08/28 08:18:52 step 2: objective=0.82033783
2017/08/28 08:18:52 step 3: objective=0.8307245
2017/08/28 08:18:53 step 4: objective=0.8423033
2017/08/28 08:18:54 step 5: objective=0.8506873
2017/08/28 08:18:55 step 6: objective=0.8581532
2017/08/28 08:18:55 step 7: objective=0.8652362
2017/08/28 08:18:55 Training value function...
2017/08/28 08:18:57 step 0: mse=59.202420 step=0.100000
2017/08/28 08:18:58 step 1: mse=57.474545 step=0.100000
2017/08/28 08:18:59 step 2: mse=56.283611 step=0.100000
2017/08/28 08:18:59 step 3: mse=55.130320 step=0.100000
2017/08/28 08:19:00 step 4: mse=53.837910 step=0.100000
2017/08/28 08:19:01 step 5: mse=53.147841 step=0.100000
2017/08/28 08:19:02 step 6: mse=52.261254 step=0.100000
2017/08/28 08:19:03 step 7: mse=51.297893 step=0.100000
2017/08/28 08:19:03 Saving...
2017/08/28 08:19:03 Gathering batch of experience...
2017/08/28 08:20:43 batch 13: mean=10.192623 stddev=10.534476 entropy=1.072075 frames=4248 count=244
2017/08/28 08:20:43 Training policy...
2017/08/28 08:20:46 step 0: objective=0.46163678
2017/08/28 08:20:47 step 1: objective=0.47181353
2017/08/28 08:20:47 step 2: objective=0.48266906
2017/08/28 08:20:48 step 3: objective=0.4897393
2017/08/28 08:20:49 step 4: objective=0.4981424
2017/08/28 08:20:50 step 5: objective=0.5068715
2017/08/28 08:20:50 step 6: objective=0.51480436
2017/08/28 08:20:51 step 7: objective=0.51991475
2017/08/28 08:20:51 Training value function...
2017/08/28 08:20:53 step 0: mse=41.630755 step=0.100000
2017/08/28 08:20:54 step 1: mse=41.035534 step=0.100000
2017/08/28 08:20:54 step 2: mse=40.493037 step=0.100000
2017/08/28 08:20:55 step 3: mse=40.176052 step=0.100000
2017/08/28 08:20:56 step 4: mse=39.765664 step=0.100000
2017/08/28 08:20:57 step 5: mse=39.342194 step=0.100000
2017/08/28 08:20:57 step 6: mse=39.008627 step=0.100000
2017/08/28 08:20:58 step 7: mse=38.724143 step=0.100000
2017/08/28 08:20:58 Saving...
2017/08/28 08:20:58 Gathering batch of experience...
2017/08/28 08:22:40 batch 14: mean=10.467213 stddev=11.078841 entropy=1.069296 frames=4262 count=244
2017/08/28 08:22:40 Training policy...
2017/08/28 08:22:42 step 0: objective=0.47821844
2017/08/28 08:22:43 step 1: objective=0.49011305
2017/08/28 08:22:44 step 2: objective=0.49867952
2017/08/28 08:22:45 step 3: objective=0.5096995
2017/08/28 08:22:45 step 4: objective=0.51620096
2017/08/28 08:22:46 step 5: objective=0.5228164
2017/08/28 08:22:47 step 6: objective=0.5329763
2017/08/28 08:22:48 step 7: objective=0.5386283
2017/08/28 08:22:48 Training value function...
2017/08/28 08:22:49 step 0: mse=46.626465 step=0.100000
2017/08/28 08:22:50 step 1: mse=46.102720 step=0.100000
2017/08/28 08:22:51 step 2: mse=45.623379 step=0.100000
2017/08/28 08:22:52 step 3: mse=45.209401 step=0.100000
2017/08/28 08:22:53 step 4: mse=44.955490 step=0.100000
2017/08/28 08:22:53 step 5: mse=44.648281 step=0.100000
2017/08/28 08:22:54 step 6: mse=44.376278 step=0.100000
2017/08/28 08:22:55 step 7: mse=44.155021 step=0.100000
2017/08/28 08:22:55 Saving...
2017/08/28 08:22:55 Gathering batch of experience...
2017/08/28 08:24:31 batch 15: mean=10.108696 stddev=12.596460 entropy=1.067441 frames=4207 count=230
2017/08/28 08:24:31 Training policy...
2017/08/28 08:24:33 step 0: objective=0.6102118
2017/08/28 08:24:34 step 1: objective=0.6176966
2017/08/28 08:24:35 step 2: objective=0.62550855
2017/08/28 08:24:35 step 3: objective=0.63286626
2017/08/28 08:24:36 step 4: objective=0.64244914
2017/08/28 08:24:37 step 5: objective=0.65447396
2017/08/28 08:24:38 step 6: objective=0.6634633
2017/08/28 08:24:38 step 7: objective=0.6734358
2017/08/28 08:24:38 Training value function...
2017/08/28 08:24:40 step 0: mse=59.341077 step=0.100000
2017/08/28 08:24:41 step 1: mse=58.595675 step=0.100000
2017/08/28 08:24:42 step 2: mse=57.994420 step=0.100000
2017/08/28 08:24:42 step 3: mse=57.277833 step=0.100000
2017/08/28 08:24:43 step 4: mse=56.792100 step=0.100000
2017/08/28 08:24:44 step 5: mse=56.435005 step=0.100000
2017/08/28 08:24:45 step 6: mse=55.912192 step=0.100000
2017/08/28 08:24:45 step 7: mse=55.471695 step=0.100000
2017/08/28 08:24:45 Saving...
2017/08/28 08:24:45 Gathering batch of experience...
2017/08/28 08:26:20 batch 16: mean=12.635135 stddev=13.398845 entropy=1.064961 frames=4267 count=222
2017/08/28 08:26:20 Training policy...
2017/08/28 08:26:22 step 0: objective=1.3085008
2017/08/28 08:26:23 step 1: objective=1.3346877
2017/08/28 08:26:24 step 2: objective=1.3477341
2017/08/28 08:26:24 step 3: objective=1.3667247
2017/08/28 08:26:25 step 4: objective=1.3807492
2017/08/28 08:26:26 step 5: objective=1.3938949
2017/08/28 08:26:27 step 6: objective=1.4021996
2017/08/28 08:26:27 step 7: objective=1.4107068
2017/08/28 08:26:27 Training value function...
2017/08/28 08:26:29 step 0: mse=72.405682 step=0.100000
2017/08/28 08:26:30 step 1: mse=71.222173 step=0.100000
2017/08/28 08:26:31 step 2: mse=69.952138 step=0.100000
2017/08/28 08:26:32 step 3: mse=68.727909 step=0.100000
2017/08/28 08:26:32 step 4: mse=67.957572 step=0.100000
2017/08/28 08:26:33 step 5: mse=67.173461 step=0.100000
2017/08/28 08:26:34 step 6: mse=66.408985 step=0.100000
2017/08/28 08:26:35 step 7: mse=65.737911 step=0.100000
2017/08/28 08:26:35 Saving...
2017/08/28 08:26:35 Gathering batch of experience...
2017/08/28 08:28:10 batch 17: mean=11.231111 stddev=12.174652 entropy=1.061072 frames=4263 count=225
2017/08/28 08:28:10 Training policy...
2017/08/28 08:28:12 step 0: objective=0.22518113
2017/08/28 08:28:13 step 1: objective=0.23527381
2017/08/28 08:28:14 step 2: objective=0.24792755
2017/08/28 08:28:15 step 3: objective=0.26324442
2017/08/28 08:28:16 step 4: objective=0.27562952
2017/08/28 08:28:16 step 5: objective=0.28296217
2017/08/28 08:28:17 step 6: objective=0.28977457
2017/08/28 08:28:18 step 7: objective=0.30071858
2017/08/28 08:28:18 Training value function...
2017/08/28 08:28:20 step 0: mse=51.138452 step=0.100000
2017/08/28 08:28:20 step 1: mse=50.331510 step=0.100000
2017/08/28 08:28:21 step 2: mse=49.727495 step=0.100000
2017/08/28 08:28:22 step 3: mse=49.057823 step=0.100000
2017/08/28 08:28:23 step 4: mse=48.344543 step=0.100000
2017/08/28 08:28:23 step 5: mse=47.888745 step=0.100000
2017/08/28 08:28:24 step 6: mse=47.233528 step=0.100000
2017/08/28 08:28:25 step 7: mse=46.677811 step=0.100000
2017/08/28 08:28:25 Saving...
2017/08/28 08:28:25 Gathering batch of experience...
2017/08/28 08:30:03 batch 18: mean=10.231760 stddev=11.789550 entropy=1.059134 frames=4207 count=233
2017/08/28 08:30:03 Training policy...
2017/08/28 08:30:05 step 0: objective=-0.054181017
2017/08/28 08:30:06 step 1: objective=-0.043045945
2017/08/28 08:30:07 step 2: objective=-0.03179199
2017/08/28 08:30:08 step 3: objective=-0.022580372
2017/08/28 08:30:08 step 4: objective=-0.01450751
2017/08/28 08:30:09 step 5: objective=-0.00845814
2017/08/28 08:30:10 step 6: objective=0.0003387057
2017/08/28 08:30:11 step 7: objective=0.007915033
2017/08/28 08:30:11 Training value function...
2017/08/28 08:30:12 step 0: mse=49.113765 step=0.100000
2017/08/28 08:30:13 step 1: mse=48.537958 step=0.100000
2017/08/28 08:30:14 step 2: mse=48.111592 step=0.100000
2017/08/28 08:30:15 step 3: mse=47.495226 step=0.100000
2017/08/28 08:30:15 step 4: mse=47.035968 step=0.100000
2017/08/28 08:30:16 step 5: mse=46.624018 step=0.100000
2017/08/28 08:30:17 step 6: mse=46.193979 step=0.100000
2017/08/28 08:30:18 step 7: mse=45.623041 step=0.100000
2017/08/28 08:30:18 Saving...
2017/08/28 08:30:18 Gathering batch of experience...
2017/08/28 08:31:55 batch 19: mean=10.910638 stddev=12.677526 entropy=1.055978 frames=4212 count=235
2017/08/28 08:31:55 Training policy...
2017/08/28 08:31:57 step 0: objective=0.50101495
2017/08/28 08:31:58 step 1: objective=0.5105761
2017/08/28 08:31:59 step 2: objective=0.521041
2017/08/28 08:31:59 step 3: objective=0.5339231
2017/08/28 08:32:00 step 4: objective=0.53965974
2017/08/28 08:32:01 step 5: objective=0.54801834
2017/08/28 08:32:02 step 6: objective=0.5545805
2017/08/28 08:32:02 step 7: objective=0.5620122
2017/08/28 08:32:02 Training value function...
2017/08/28 08:32:04 step 0: mse=53.791793 step=0.100000
2017/08/28 08:32:05 step 1: mse=52.967617 step=0.100000
2017/08/28 08:32:06 step 2: mse=52.127451 step=0.100000
2017/08/28 08:32:06 step 3: mse=51.521584 step=0.100000
2017/08/28 08:32:07 step 4: mse=51.023994 step=0.100000
2017/08/28 08:32:08 step 5: mse=50.550274 step=0.100000
2017/08/28 08:32:09 step 6: mse=50.082606 step=0.100000
2017/08/28 08:32:10 step 7: mse=49.571002 step=0.100000
2017/08/28 08:32:10 Saving...
2017/08/28 08:32:10 Gathering batch of experience...
2017/08/28 08:33:43 batch 20: mean=12.248869 stddev=15.033795 entropy=1.052318 frames=4186 count=221
2017/08/28 08:33:43 Training policy...
2017/08/28 08:33:45 step 0: objective=1.0792527
2017/08/28 08:33:46 step 1: objective=1.092011
2017/08/28 08:33:47 step 2: objective=1.1074976
2017/08/28 08:33:48 step 3: objective=1.1225426
2017/08/28 08:33:48 step 4: objective=1.1325653
2017/08/28 08:33:49 step 5: objective=1.1420572
2017/08/28 08:33:50 step 6: objective=1.1495876
2017/08/28 08:33:51 step 7: objective=1.1583829
2017/08/28 08:33:51 Training value function...
2017/08/28 08:33:52 step 0: mse=70.646358 step=0.100000
2017/08/28 08:33:53 step 1: mse=67.595430 step=0.100000
2017/08/28 08:33:54 step 2: mse=65.499864 step=0.100000
2017/08/28 08:33:55 step 3: mse=63.226931 step=0.100000
2017/08/28 08:33:56 step 4: mse=61.407263 step=0.100000
2017/08/28 08:33:56 step 5: mse=59.705580 step=0.100000
2017/08/28 08:33:57 step 6: mse=58.669009 step=0.100000
2017/08/28 08:33:58 step 7: mse=57.432044 step=0.100000
2017/08/28 08:33:58 Saving...
2017/08/28 08:33:58 Gathering batch of experience...
2017/08/28 08:35:37 batch 21: mean=11.970085 stddev=13.082380 entropy=1.047165 frames=4235 count=234
2017/08/28 08:35:37 Training policy...
2017/08/28 08:35:39 step 0: objective=0.6180067
2017/08/28 08:35:40 step 1: objective=0.62658393
2017/08/28 08:35:41 step 2: objective=0.6369199
2017/08/28 08:35:41 step 3: objective=0.648682
2017/08/28 08:35:42 step 4: objective=0.6559995
2017/08/28 08:35:43 step 5: objective=0.66504574
2017/08/28 08:35:44 step 6: objective=0.6766415
2017/08/28 08:35:45 step 7: objective=0.6837516
2017/08/28 08:35:45 Training value function...
2017/08/28 08:35:46 step 0: mse=64.812738 step=0.100000
2017/08/28 08:35:47 step 1: mse=63.942382 step=0.100000
2017/08/28 08:35:48 step 2: mse=63.039464 step=0.100000
2017/08/28 08:35:49 step 3: mse=62.540831 step=0.100000
2017/08/28 08:35:49 step 4: mse=62.154664 step=0.100000
2017/08/28 08:35:50 step 5: mse=61.724064 step=0.100000
2017/08/28 08:35:51 step 6: mse=61.160861 step=0.100000
2017/08/28 08:35:52 step 7: mse=60.698452 step=0.100000
2017/08/28 08:35:52 Saving...
2017/08/28 08:35:52 Gathering batch of experience...
2017/08/28 08:37:29 batch 22: mean=12.113043 stddev=12.432961 entropy=1.043351 frames=4265 count=230
2017/08/28 08:37:29 Training policy...
2017/08/28 08:37:31 step 0: objective=0.47401237
2017/08/28 08:37:32 step 1: objective=0.48778513
2017/08/28 08:37:33 step 2: objective=0.50150603
2017/08/28 08:37:34 step 3: objective=0.50935066
2017/08/28 08:37:34 step 4: objective=0.5187926
2017/08/28 08:37:35 step 5: objective=0.5296577
2017/08/28 08:37:36 step 6: objective=0.5378685
2017/08/28 08:37:37 step 7: objective=0.54711145
2017/08/28 08:37:37 Training value function...
2017/08/28 08:37:38 step 0: mse=57.143055 step=0.100000
2017/08/28 08:37:39 step 1: mse=56.583590 step=0.100000
2017/08/28 08:37:40 step 2: mse=55.777613 step=0.100000
2017/08/28 08:37:41 step 3: mse=55.196646 step=0.100000
2017/08/28 08:37:42 step 4: mse=54.567600 step=0.100000
2017/08/28 08:37:42 step 5: mse=54.022362 step=0.100000
2017/08/28 08:37:43 step 6: mse=53.648339 step=0.100000
2017/08/28 08:37:44 step 7: mse=53.141029 step=0.100000
2017/08/28 08:37:44 Saving...
2017/08/28 08:37:44 Gathering batch of experience...
2017/08/28 08:39:18 batch 23: mean=12.218750 stddev=13.683652 entropy=1.043385 frames=4243 count=224
2017/08/28 08:39:18 Training policy...
2017/08/28 08:39:20 step 0: objective=0.49308765
2017/08/28 08:39:21 step 1: objective=0.50455666
2017/08/28 08:39:22 step 2: objective=0.51806724
2017/08/28 08:39:23 step 3: objective=0.5321521
2017/08/28 08:39:24 step 4: objective=0.5433443
2017/08/28 08:39:24 step 5: objective=0.55129284
2017/08/28 08:39:25 step 6: objective=0.56095093
2017/08/28 08:39:26 step 7: objective=0.5703952
2017/08/28 08:39:26 Training value function...
2017/08/28 08:39:28 step 0: mse=68.936561 step=0.100000
2017/08/28 08:39:28 step 1: mse=68.489407 step=0.100000
2017/08/28 08:39:29 step 2: mse=68.051001 step=0.100000
2017/08/28 08:39:30 step 3: mse=67.532873 step=0.100000
2017/08/28 08:39:31 step 4: mse=67.207392 step=0.100000
2017/08/28 08:39:31 step 5: mse=66.599504 step=0.100000
2017/08/28 08:39:32 step 6: mse=66.280661 step=0.100000
2017/08/28 08:39:33 step 7: mse=65.846746 step=0.100000
2017/08/28 08:39:33 Saving...
2017/08/28 08:39:33 Gathering batch of experience...
2017/08/28 08:41:09 batch 24: mean=12.105727 stddev=13.880462 entropy=1.039791 frames=4298 count=227
2017/08/28 08:41:09 Training policy...
2017/08/28 08:41:12 step 0: objective=0.5262636
2017/08/28 08:41:13 step 1: objective=0.53665674
2017/08/28 08:41:13 step 2: objective=0.54958826
2017/08/28 08:41:14 step 3: objective=0.5607809
2017/08/28 08:41:15 step 4: objective=0.57209015
2017/08/28 08:41:16 step 5: objective=0.5785771
2017/08/28 08:41:16 step 6: objective=0.5857683
2017/08/28 08:41:17 step 7: objective=0.59392047
2017/08/28 08:41:17 Training value function...
2017/08/28 08:41:19 step 0: mse=72.584328 step=0.100000
2017/08/28 08:41:20 step 1: mse=71.970954 step=0.100000
2017/08/28 08:41:21 step 2: mse=71.446665 step=0.100000
2017/08/28 08:41:21 step 3: mse=70.692500 step=0.100000
2017/08/28 08:41:22 step 4: mse=70.365479 step=0.100000
2017/08/28 08:41:23 step 5: mse=69.820830 step=0.100000
2017/08/28 08:41:24 step 6: mse=69.396205 step=0.100000
2017/08/28 08:41:25 step 7: mse=68.855732 step=0.100000
2017/08/28 08:41:25 Saving...
2017/08/28 08:41:25 Gathering batch of experience...
2017/08/28 08:43:00 batch 25: mean=12.493392 stddev=12.450207 entropy=1.037428 frames=4329 count=227
2017/08/28 08:43:00 Training policy...
2017/08/28 08:43:02 step 0: objective=0.43468073
2017/08/28 08:43:03 step 1: objective=0.44593757
2017/08/28 08:43:04 step 2: objective=0.4545956
2017/08/28 08:43:05 step 3: objective=0.46519715
2017/08/28 08:43:05 step 4: objective=0.47623006
2017/08/28 08:43:06 step 5: objective=0.4838091
2017/08/28 08:43:07 step 6: objective=0.49190816
2017/08/28 08:43:08 step 7: objective=0.50035274
2017/08/28 08:43:08 Training value function...
2017/08/28 08:43:10 step 0: mse=56.468324 step=0.100000
2017/08/28 08:43:10 step 1: mse=55.656444 step=0.100000
2017/08/28 08:43:11 step 2: mse=55.052350 step=0.100000
2017/08/28 08:43:12 step 3: mse=54.341068 step=0.100000
2017/08/28 08:43:13 step 4: mse=53.877678 step=0.100000
2017/08/28 08:43:14 step 5: mse=53.641623 step=0.100000
2017/08/28 08:43:14 step 6: mse=53.390451 step=0.100000
2017/08/28 08:43:15 step 7: mse=52.878104 step=0.100000
2017/08/28 08:43:15 Saving...
2017/08/28 08:43:15 Gathering batch of experience...
2017/08/28 08:44:52 batch 26: mean=11.581197 stddev=13.051338 entropy=1.035462 frames=4241 count=234
2017/08/28 08:44:52 Training policy...
2017/08/28 08:44:54 step 0: objective=0.33982107
2017/08/28 08:44:55 step 1: objective=0.3495054
2017/08/28 08:44:56 step 2: objective=0.3597765
2017/08/28 08:44:57 step 3: objective=0.36777705
2017/08/28 08:44:57 step 4: objective=0.3794837
2017/08/28 08:44:58 step 5: objective=0.38789144
2017/08/28 08:44:59 step 6: objective=0.3959738
2017/08/28 08:45:00 step 7: objective=0.40691516
2017/08/28 08:45:00 Training value function...
2017/08/28 08:45:01 step 0: mse=61.949558 step=0.100000
2017/08/28 08:45:02 step 1: mse=61.082614 step=0.100000
2017/08/28 08:45:03 step 2: mse=60.755936 step=0.100000
2017/08/28 08:45:04 step 3: mse=60.150196 step=0.100000
2017/08/28 08:45:05 step 4: mse=59.733395 step=0.100000
2017/08/28 08:45:05 step 5: mse=58.913133 step=0.100000
2017/08/28 08:45:06 step 6: mse=58.467976 step=0.100000
2017/08/28 08:45:07 step 7: mse=57.795073 step=0.100000
2017/08/28 08:45:07 Saving...
2017/08/28 08:45:07 Gathering batch of experience...
2017/08/28 08:46:36 batch 27: mean=13.884615 stddev=13.336840 entropy=1.033329 frames=4263 count=208
2017/08/28 08:46:36 Training policy...
2017/08/28 08:46:39 step 0: objective=0.94781643
2017/08/28 08:46:40 step 1: objective=0.9581937
2017/08/28 08:46:41 step 2: objective=0.972236
2017/08/28 08:46:41 step 3: objective=0.9825239
2017/08/28 08:46:42 step 4: objective=0.9909797
2017/08/28 08:46:43 step 5: objective=1.0016314
2017/08/28 08:46:44 step 6: objective=1.0090141
2017/08/28 08:46:44 step 7: objective=1.0151002
2017/08/28 08:46:44 Training value function...
2017/08/28 08:46:46 step 0: mse=58.819676 step=0.100000
2017/08/28 08:46:47 step 1: mse=57.882575 step=0.100000
2017/08/28 08:46:48 step 2: mse=57.267241 step=0.100000
2017/08/28 08:46:48 step 3: mse=56.630844 step=0.100000
2017/08/28 08:46:49 step 4: mse=55.903928 step=0.100000
2017/08/28 08:46:50 step 5: mse=55.297561 step=0.100000
2017/08/28 08:46:51 step 6: mse=54.634447 step=0.100000
2017/08/28 08:46:52 step 7: mse=54.117215 step=0.100000
2017/08/28 08:46:52 Saving...
2017/08/28 08:46:52 Gathering batch of experience...
2017/08/28 08:48:27 batch 28: mean=11.640693 stddev=13.689693 entropy=1.028032 frames=4247 count=231
2017/08/28 08:48:27 Training policy...
2017/08/28 08:48:30 step 0: objective=0.17008464
2017/08/28 08:48:30 step 1: objective=0.18025933
2017/08/28 08:48:31 step 2: objective=0.19518912
2017/08/28 08:48:32 step 3: objective=0.20570822
2017/08/28 08:48:33 step 4: objective=0.21232547
2017/08/28 08:48:33 step 5: objective=0.22751309
2017/08/28 08:48:34 step 6: objective=0.23873964
2017/08/28 08:48:35 step 7: objective=0.24519052
2017/08/28 08:48:35 Training value function...
2017/08/28 08:48:37 step 0: mse=70.872797 step=0.100000
2017/08/28 08:48:37 step 1: mse=70.010166 step=0.100000
2017/08/28 08:48:38 step 2: mse=68.848698 step=0.100000
2017/08/28 08:48:39 step 3: mse=67.846434 step=0.100000
2017/08/28 08:48:40 step 4: mse=67.143620 step=0.100000
2017/08/28 08:48:41 step 5: mse=66.632217 step=0.100000
2017/08/28 08:48:41 step 6: mse=65.693792 step=0.100000
2017/08/28 08:48:42 step 7: mse=65.078880 step=0.100000
2017/08/28 08:48:42 Saving...
2017/08/28 08:48:42 Gathering batch of experience...
2017/08/28 08:50:19 batch 29: mean=12.021834 stddev=13.012069 entropy=1.026399 frames=4301 count=229
2017/08/28 08:50:19 Training policy...
2017/08/28 08:50:21 step 0: objective=0.47711015
2017/08/28 08:50:22 step 1: objective=0.49383122
2017/08/28 08:50:23 step 2: objective=0.51011837
2017/08/28 08:50:24 step 3: objective=0.5194092
2017/08/28 08:50:24 step 4: objective=0.5342748
2017/08/28 08:50:25 step 5: objective=0.5451058
2017/08/28 08:50:26 step 6: objective=0.55534357
2017/08/28 08:50:27 step 7: objective=0.56477135
2017/08/28 08:50:27 Training value function...
2017/08/28 08:50:28 step 0: mse=61.295088 step=0.100000
2017/08/28 08:50:29 step 1: mse=60.637323 step=0.100000
2017/08/28 08:50:30 step 2: mse=59.934294 step=0.100000
2017/08/28 08:50:31 step 3: mse=59.333523 step=0.100000
2017/08/28 08:50:32 step 4: mse=59.021720 step=0.100000
2017/08/28 08:50:32 step 5: mse=58.307995 step=0.100000
2017/08/28 08:50:33 step 6: mse=57.792433 step=0.100000
2017/08/28 08:50:34 step 7: mse=57.257191 step=0.100000
2017/08/28 08:50:34 Saving...
2017/08/28 08:50:34 Gathering batch of experience...
2017/08/28 08:52:08 batch 30: mean=12.917808 stddev=13.714060 entropy=1.020976 frames=4249 count=219
2017/08/28 08:52:08 Training policy...
2017/08/28 08:52:11 step 0: objective=0.67185843
2017/08/28 08:52:11 step 1: objective=0.6840281
2017/08/28 08:52:12 step 2: objective=0.6963904
2017/08/28 08:52:13 step 3: objective=0.7030396
2017/08/28 08:52:14 step 4: objective=0.71169305
2017/08/28 08:52:15 step 5: objective=0.7206499
2017/08/28 08:52:15 step 6: objective=0.73159176
2017/08/28 08:52:16 step 7: objective=0.7438021
2017/08/28 08:52:16 Training value function...
2017/08/28 08:52:18 step 0: mse=63.255405 step=0.100000
2017/08/28 08:52:19 step 1: mse=62.154319 step=0.100000
2017/08/28 08:52:19 step 2: mse=61.214788 step=0.100000
2017/08/28 08:52:20 step 3: mse=60.084045 step=0.100000
2017/08/28 08:52:21 step 4: mse=59.332177 step=0.100000
2017/08/28 08:52:22 step 5: mse=58.633983 step=0.100000
2017/08/28 08:52:22 step 6: mse=57.922631 step=0.100000
2017/08/28 08:52:23 step 7: mse=57.162872 step=0.100000
2017/08/28 08:52:23 Saving...
2017/08/28 08:52:23 Gathering batch of experience...
2017/08/28 08:53:58 batch 31: mean=14.048889 stddev=15.036912 entropy=1.016300 frames=4261 count=225
2017/08/28 08:53:58 Training policy...
2017/08/28 08:54:01 step 0: objective=1.1581264
2017/08/28 08:54:01 step 1: objective=1.1665195
2017/08/28 08:54:02 step 2: objective=1.1848149
2017/08/28 08:54:03 step 3: objective=1.2005501
2017/08/28 08:54:04 step 4: objective=1.2115039
2017/08/28 08:54:05 step 5: objective=1.2182218
2017/08/28 08:54:05 step 6: objective=1.2262452
2017/08/28 08:54:06 step 7: objective=1.2324854
2017/08/28 08:54:06 Training value function...
2017/08/28 08:54:08 step 0: mse=83.651880 step=0.100000
2017/08/28 08:54:09 step 1: mse=82.741482 step=0.100000
2017/08/28 08:54:09 step 2: mse=81.903966 step=0.100000
2017/08/28 08:54:10 step 3: mse=81.077714 step=0.100000
2017/08/28 08:54:11 step 4: mse=80.291148 step=0.100000
2017/08/28 08:54:12 step 5: mse=79.789056 step=0.100000
2017/08/28 08:54:13 step 6: mse=78.851762 step=0.100000
2017/08/28 08:54:13 step 7: mse=78.396744 step=0.100000
2017/08/28 08:54:13 Saving...
2017/08/28 08:54:13 Gathering batch of experience...
2017/08/28 08:55:43 batch 32: mean=13.581731 stddev=13.332402 entropy=1.014125 frames=4239 count=208
2017/08/28 08:55:43 Training policy...
2017/08/28 08:55:45 step 0: objective=0.21197832
2017/08/28 08:55:46 step 1: objective=0.22114381
2017/08/28 08:55:47 step 2: objective=0.23470742
2017/08/28 08:55:48 step 3: objective=0.245924
2017/08/28 08:55:48 step 4: objective=0.25278407
2017/08/28 08:55:49 step 5: objective=0.26124093
2017/08/28 08:55:50 step 6: objective=0.268877
2017/08/28 08:55:51 step 7: objective=0.27816665
2017/08/28 08:55:51 Training value function...
2017/08/28 08:55:52 step 0: mse=58.952774 step=0.100000
2017/08/28 08:55:53 step 1: mse=58.516850 step=0.100000
2017/08/28 08:55:54 step 2: mse=58.204819 step=0.100000
2017/08/28 08:55:55 step 3: mse=57.723283 step=0.100000
2017/08/28 08:55:56 step 4: mse=57.224786 step=0.100000
2017/08/28 08:55:56 step 5: mse=56.866862 step=0.100000
2017/08/28 08:55:57 step 6: mse=56.617535 step=0.100000
2017/08/28 08:55:58 step 7: mse=56.223118 step=0.100000
2017/08/28 08:55:58 Saving...
2017/08/28 08:55:58 Gathering batch of experience...
2017/08/28 08:57:33 batch 33: mean=13.622807 stddev=15.622122 entropy=1.009694 frames=4263 count=228
2017/08/28 08:57:33 Training policy...
2017/08/28 08:57:36 step 0: objective=0.80593115
2017/08/28 08:57:37 step 1: objective=0.822003
2017/08/28 08:57:37 step 2: objective=0.83691674
2017/08/28 08:57:38 step 3: objective=0.847956
2017/08/28 08:57:39 step 4: objective=0.85660636
2017/08/28 08:57:40 step 5: objective=0.86660045
2017/08/28 08:57:40 step 6: objective=0.87521875
2017/08/28 08:57:41 step 7: objective=0.8817985
2017/08/28 08:57:41 Training value function...
2017/08/28 08:57:43 step 0: mse=79.531922 step=0.100000
2017/08/28 08:57:44 step 1: mse=77.810783 step=0.100000
2017/08/28 08:57:45 step 2: mse=76.214684 step=0.100000
2017/08/28 08:57:45 step 3: mse=74.946618 step=0.100000
2017/08/28 08:57:46 step 4: mse=73.635108 step=0.100000
2017/08/28 08:57:47 step 5: mse=72.609415 step=0.100000
2017/08/28 08:57:48 step 6: mse=71.625831 step=0.100000
2017/08/28 08:57:49 step 7: mse=70.573098 step=0.100000
2017/08/28 08:57:49 Saving...
2017/08/28 08:57:49 Gathering batch of experience...
2017/08/28 08:59:20 batch 34: mean=12.799065 stddev=12.902648 entropy=1.008797 frames=4264 count=214
2017/08/28 08:59:20 Training policy...
2017/08/28 08:59:23 step 0: objective=0.23066674
2017/08/28 08:59:23 step 1: objective=0.23965767
2017/08/28 08:59:24 step 2: objective=0.25024518
2017/08/28 08:59:25 step 3: objective=0.26260358
2017/08/28 08:59:26 step 4: objective=0.26832035
2017/08/28 08:59:27 step 5: objective=0.28055957
2017/08/28 08:59:27 step 6: objective=0.28792232
2017/08/28 08:59:28 step 7: objective=0.29546574
2017/08/28 08:59:28 Training value function...
2017/08/28 08:59:30 step 0: mse=52.305810 step=0.100000
2017/08/28 08:59:31 step 1: mse=51.745288 step=0.100000
2017/08/28 08:59:31 step 2: mse=51.162297 step=0.100000
2017/08/28 08:59:32 step 3: mse=50.598480 step=0.100000
2017/08/28 08:59:33 step 4: mse=50.125455 step=0.100000
2017/08/28 08:59:34 step 5: mse=49.576842 step=0.100000
2017/08/28 08:59:35 step 6: mse=48.953939 step=0.100000
2017/08/28 08:59:35 step 7: mse=48.562203 step=0.100000
2017/08/28 08:59:35 Saving...
2017/08/28 08:59:35 Gathering batch of experience...
2017/08/28 09:01:10 batch 35: mean=12.972973 stddev=13.138870 entropy=1.005028 frames=4278 count=222
2017/08/28 09:01:10 Training policy...
2017/08/28 09:01:12 step 0: objective=0.43111962
2017/08/28 09:01:13 step 1: objective=0.43917686
2017/08/28 09:01:14 step 2: objective=0.44840115
2017/08/28 09:01:15 step 3: objective=0.45677775
2017/08/28 09:01:15 step 4: objective=0.46244547
2017/08/28 09:01:16 step 5: objective=0.47165993
2017/08/28 09:01:17 step 6: objective=0.4796085
2017/08/28 09:01:18 step 7: objective=0.48569906
2017/08/28 09:01:18 Training value function...
2017/08/28 09:01:19 step 0: mse=60.822087 step=0.100000
2017/08/28 09:01:20 step 1: mse=59.669613 step=0.100000
2017/08/28 09:01:21 step 2: mse=59.368547 step=0.100000
2017/08/28 09:01:22 step 3: mse=58.660549 step=0.100000
2017/08/28 09:01:23 step 4: mse=58.384963 step=0.100000
2017/08/28 09:01:23 step 5: mse=58.115476 step=0.100000
2017/08/28 09:01:24 step 6: mse=57.579918 step=0.100000
2017/08/28 09:01:25 step 7: mse=57.281165 step=0.100000
2017/08/28 09:01:25 Saving...
2017/08/28 09:01:25 Gathering batch of experience...
2017/08/28 09:03:03 batch 36: mean=11.218341 stddev=11.779837 entropy=0.999473 frames=4217 count=229
2017/08/28 09:03:03 Training policy...
2017/08/28 09:03:05 step 0: objective=-0.104110554
2017/08/28 09:03:06 step 1: objective=-0.09490739
2017/08/28 09:03:07 step 2: objective=-0.08327705
2017/08/28 09:03:08 step 3: objective=-0.07443762
2017/08/28 09:03:08 step 4: objective=-0.06747835
2017/08/28 09:03:09 step 5: objective=-0.05765698
2017/08/28 09:03:10 step 6: objective=-0.04714398
2017/08/28 09:03:11 step 7: objective=-0.039441876
2017/08/28 09:03:11 Training value function...
2017/08/28 09:03:12 step 0: mse=49.868985 step=0.100000
2017/08/28 09:03:13 step 1: mse=49.199270 step=0.100000
2017/08/28 09:03:14 step 2: mse=48.887745 step=0.100000
2017/08/28 09:03:15 step 3: mse=48.419371 step=0.100000
2017/08/28 09:03:15 step 4: mse=48.167652 step=0.100000
2017/08/28 09:03:16 step 5: mse=47.880890 step=0.100000
2017/08/28 09:03:17 step 6: mse=47.260661 step=0.100000
2017/08/28 09:03:18 step 7: mse=46.804922 step=0.100000
2017/08/28 09:03:18 Saving...
2017/08/28 09:03:18 Gathering batch of experience...
2017/08/28 09:04:48 batch 37: mean=14.953052 stddev=16.102595 entropy=1.001882 frames=4305 count=213
2017/08/28 09:04:48 Training policy...
2017/08/28 09:04:50 step 0: objective=1.6796478
2017/08/28 09:04:51 step 1: objective=1.7000493
2017/08/28 09:04:52 step 2: objective=1.7160912
2017/08/28 09:04:53 step 3: objective=1.7295203
2017/08/28 09:04:53 step 4: objective=1.7431555
2017/08/28 09:04:54 step 5: objective=1.7542491
2017/08/28 09:04:55 step 6: objective=1.7636868
2017/08/28 09:04:56 step 7: objective=1.7790775
2017/08/28 09:04:56 Training value function...
2017/08/28 09:04:58 step 0: mse=92.246817 step=0.100000
2017/08/28 09:04:58 step 1: mse=90.063988 step=0.100000
2017/08/28 09:04:59 step 2: mse=88.156371 step=0.100000
2017/08/28 09:05:00 step 3: mse=86.501540 step=0.100000
2017/08/28 09:05:01 step 4: mse=85.131276 step=0.100000
2017/08/28 09:05:02 step 5: mse=83.749407 step=0.100000
2017/08/28 09:05:02 step 6: mse=82.285452 step=0.100000
2017/08/28 09:05:03 step 7: mse=81.219668 step=0.100000
2017/08/28 09:05:03 Saving...
2017/08/28 09:05:03 Gathering batch of experience...
2017/08/28 09:06:33 batch 38: mean=14.253589 stddev=15.743391 entropy=0.996897 frames=4279 count=209
2017/08/28 09:06:33 Training policy...
2017/08/28 09:06:36 step 0: objective=0.5960963
2017/08/28 09:06:36 step 1: objective=0.60875416
2017/08/28 09:06:37 step 2: objective=0.62102
2017/08/28 09:06:38 step 3: objective=0.6303086
2017/08/28 09:06:39 step 4: objective=0.6416821
2017/08/28 09:06:40 step 5: objective=0.65418893
2017/08/28 09:06:40 step 6: objective=0.6616531
2017/08/28 09:06:41 step 7: objective=0.6736769
2017/08/28 09:06:41 Training value function...
2017/08/28 09:06:43 step 0: mse=75.503631 step=0.100000
2017/08/28 09:06:44 step 1: mse=74.645527 step=0.100000
2017/08/28 09:06:45 step 2: mse=73.754307 step=0.100000
2017/08/28 09:06:45 step 3: mse=72.605380 step=0.100000
2017/08/28 09:06:46 step 4: mse=72.015427 step=0.100000
2017/08/28 09:06:47 step 5: mse=71.146241 step=0.100000
2017/08/28 09:06:48 step 6: mse=70.571456 step=0.100000
2017/08/28 09:06:49 step 7: mse=70.104739 step=0.100000
2017/08/28 09:06:49 Saving...
2017/08/28 09:06:49 Gathering batch of experience...
2017/08/28 09:08:21 batch 39: mean=14.131818 stddev=14.649104 entropy=0.991035 frames=4244 count=220
2017/08/28 09:08:21 Training policy...
2017/08/28 09:08:24 step 0: objective=0.70075554
2017/08/28 09:08:25 step 1: objective=0.7168835
2017/08/28 09:08:25 step 2: objective=0.729677
2017/08/28 09:08:26 step 3: objective=0.74325734
2017/08/28 09:08:27 step 4: objective=0.75448817
2017/08/28 09:08:28 step 5: objective=0.76544964
2017/08/28 09:08:28 step 6: objective=0.7759944
2017/08/28 09:08:29 step 7: objective=0.78833693
2017/08/28 09:08:29 Training value function...
2017/08/28 09:08:31 step 0: mse=72.061212 step=0.100000
2017/08/28 09:08:32 step 1: mse=70.910311 step=0.100000
2017/08/28 09:08:33 step 2: mse=69.913919 step=0.100000
2017/08/28 09:08:33 step 3: mse=68.912347 step=0.100000
2017/08/28 09:08:34 step 4: mse=68.013344 step=0.100000
2017/08/28 09:08:35 step 5: mse=67.284731 step=0.100000
2017/08/28 09:08:36 step 6: mse=66.232051 step=0.100000
2017/08/28 09:08:36 step 7: mse=65.565857 step=0.100000
2017/08/28 09:08:36 Saving...
2017/08/28 09:08:36 Gathering batch of experience...
2017/08/28 09:10:04 batch 40: mean=15.341463 stddev=16.162905 entropy=0.989457 frames=4284 count=205
2017/08/28 09:10:04 Training policy...
2017/08/28 09:10:07 step 0: objective=0.78000015
2017/08/28 09:10:08 step 1: objective=0.7913398
2017/08/28 09:10:09 step 2: objective=0.8009998
2017/08/28 09:10:09 step 3: objective=0.8081452
2017/08/28 09:10:10 step 4: objective=0.8161625
2017/08/28 09:10:11 step 5: objective=0.82448524
2017/08/28 09:10:12 step 6: objective=0.8314885
2017/08/28 09:10:13 step 7: objective=0.8464166
2017/08/28 09:10:13 Training value function...
2017/08/28 09:10:14 step 0: mse=79.123422 step=0.100000
2017/08/28 09:10:15 step 1: mse=78.636193 step=0.100000
2017/08/28 09:10:16 step 2: mse=78.078075 step=0.100000
2017/08/28 09:10:17 step 3: mse=77.371263 step=0.100000
2017/08/28 09:10:18 step 4: mse=76.775996 step=0.100000
2017/08/28 09:10:18 step 5: mse=76.426949 step=0.100000
2017/08/28 09:10:19 step 6: mse=76.241786 step=0.100000
2017/08/28 09:10:20 step 7: mse=75.813814 step=0.100000
2017/08/28 09:10:20 Saving...
2017/08/28 09:10:20 Gathering batch of experience...
2017/08/28 09:11:51 batch 41: mean=14.426540 stddev=14.165175 entropy=0.987027 frames=4308 count=211
2017/08/28 09:11:51 Training policy...
2017/08/28 09:11:54 step 0: objective=0.3751386
2017/08/28 09:11:54 step 1: objective=0.3823312
2017/08/28 09:11:55 step 2: objective=0.39676508
2017/08/28 09:11:56 step 3: objective=0.41016057
2017/08/28 09:11:57 step 4: objective=0.42276037
2017/08/28 09:11:58 step 5: objective=0.43428558
2017/08/28 09:11:58 step 6: objective=0.44168714
2017/08/28 09:11:59 step 7: objective=0.4519493
2017/08/28 09:11:59 Training value function...
2017/08/28 09:12:01 step 0: mse=62.416110 step=0.100000
2017/08/28 09:12:02 step 1: mse=61.900752 step=0.100000
2017/08/28 09:12:03 step 2: mse=61.447008 step=0.100000
2017/08/28 09:12:03 step 3: mse=60.937798 step=0.100000
2017/08/28 09:12:04 step 4: mse=60.564480 step=0.100000
2017/08/28 09:12:05 step 5: mse=60.251560 step=0.100000
2017/08/28 09:12:06 step 6: mse=59.898899 step=0.100000
2017/08/28 09:12:07 step 7: mse=59.620862 step=0.100000
2017/08/28 09:12:07 Saving...
2017/08/28 09:12:07 Gathering batch of experience...
2017/08/28 09:13:34 batch 42: mean=15.564356 stddev=17.993077 entropy=0.985068 frames=4273 count=202
2017/08/28 09:13:34 Training policy...
2017/08/28 09:13:36 step 0: objective=1.0972207
2017/08/28 09:13:37 step 1: objective=1.1166875
2017/08/28 09:13:38 step 2: objective=1.1339446
2017/08/28 09:13:39 step 3: objective=1.1467428
2017/08/28 09:13:40 step 4: objective=1.1573913
2017/08/28 09:13:40 step 5: objective=1.1644354
2017/08/28 09:13:41 step 6: objective=1.1740227
2017/08/28 09:13:42 step 7: objective=1.1804751
2017/08/28 09:13:42 Training value function...
2017/08/28 09:13:44 step 0: mse=95.437298 step=0.100000
2017/08/28 09:13:45 step 1: mse=93.535504 step=0.100000
2017/08/28 09:13:45 step 2: mse=91.922177 step=0.100000
2017/08/28 09:13:46 step 3: mse=90.600181 step=0.100000
2017/08/28 09:13:47 step 4: mse=89.010492 step=0.100000
2017/08/28 09:13:48 step 5: mse=88.190877 step=0.100000
2017/08/28 09:13:49 step 6: mse=87.243961 step=0.100000
2017/08/28 09:13:50 step 7: mse=86.206763 step=0.100000
2017/08/28 09:13:50 Saving...
2017/08/28 09:13:50 Gathering batch of experience...
2017/08/28 09:15:16 batch 43: mean=16.716418 stddev=17.954175 entropy=0.978349 frames=4250 count=201
2017/08/28 09:15:16 Training policy...
2017/08/28 09:15:19 step 0: objective=1.083466
2017/08/28 09:15:20 step 1: objective=1.1070633
2017/08/28 09:15:21 step 2: objective=1.1243796
2017/08/28 09:15:21 step 3: objective=1.1384336
2017/08/28 09:15:22 step 4: objective=1.1498274
2017/08/28 09:15:23 step 5: objective=1.1652863
2017/08/28 09:15:24 step 6: objective=1.1716324
2017/08/28 09:15:25 step 7: objective=1.1814861
2017/08/28 09:15:25 Training value function...
2017/08/28 09:15:26 step 0: mse=92.350993 step=0.100000
2017/08/28 09:15:27 step 1: mse=90.683426 step=0.100000
2017/08/28 09:15:28 step 2: mse=89.660391 step=0.100000
2017/08/28 09:15:29 step 3: mse=88.411743 step=0.100000
2017/08/28 09:15:30 step 4: mse=87.562570 step=0.100000
2017/08/28 09:15:30 step 5: mse=86.680402 step=0.100000
2017/08/28 09:15:31 step 6: mse=86.021142 step=0.100000
2017/08/28 09:15:32 step 7: mse=84.990270 step=0.100000
2017/08/28 09:15:32 Saving...
2017/08/28 09:15:32 Gathering batch of experience...
2017/08/28 09:16:54 batch 44: mean=16.792553 stddev=17.355009 entropy=0.975802 frames=4301 count=188
2017/08/28 09:16:54 Training policy...
2017/08/28 09:16:57 step 0: objective=0.6765027
2017/08/28 09:16:58 step 1: objective=0.6881453
2017/08/28 09:16:58 step 2: objective=0.70676917
2017/08/28 09:16:59 step 3: objective=0.7162124
2017/08/28 09:17:00 step 4: objective=0.7310901
2017/08/28 09:17:01 step 5: objective=0.7414869
2017/08/28 09:17:02 step 6: objective=0.75064015
2017/08/28 09:17:02 step 7: objective=0.76004225
2017/08/28 09:17:02 Training value function...
2017/08/28 09:17:04 step 0: mse=79.995218 step=0.100000
2017/08/28 09:17:05 step 1: mse=78.473448 step=0.100000
2017/08/28 09:17:06 step 2: mse=77.444749 step=0.100000
2017/08/28 09:17:07 step 3: mse=76.126432 step=0.100000
2017/08/28 09:17:08 step 4: mse=75.285910 step=0.100000
2017/08/28 09:17:08 step 5: mse=74.264146 step=0.100000
2017/08/28 09:17:09 step 6: mse=73.446066 step=0.100000
2017/08/28 09:17:10 step 7: mse=72.664220 step=0.100000
2017/08/28 09:17:10 Saving...
2017/08/28 09:17:10 Gathering batch of experience...
2017/08/28 09:18:36 batch 45: mean=15.696078 stddev=18.497371 entropy=0.970939 frames=4211 count=204
2017/08/28 09:18:36 Training policy...
2017/08/28 09:18:39 step 0: objective=0.37362006
2017/08/28 09:18:39 step 1: objective=0.38927653
2017/08/28 09:18:40 step 2: objective=0.40914518
2017/08/28 09:18:41 step 3: objective=0.42437634
2017/08/28 09:18:42 step 4: objective=0.43505794
2017/08/28 09:18:42 step 5: objective=0.44499153
2017/08/28 09:18:43 step 6: objective=0.46209398
2017/08/28 09:18:44 step 7: objective=0.46912307
2017/08/28 09:18:44 Training value function...
2017/08/28 09:18:46 step 0: mse=93.564642 step=0.100000
2017/08/28 09:18:47 step 1: mse=92.354023 step=0.100000
2017/08/28 09:18:47 step 2: mse=91.288225 step=0.100000
2017/08/28 09:18:48 step 3: mse=90.050872 step=0.100000
2017/08/28 09:18:49 step 4: mse=88.956613 step=0.100000
2017/08/28 09:18:50 step 5: mse=87.976308 step=0.100000
2017/08/28 09:18:51 step 6: mse=86.678661 step=0.100000
2017/08/28 09:18:51 step 7: mse=85.978872 step=0.100000
2017/08/28 09:18:51 Saving...
2017/08/28 09:18:51 Gathering batch of experience...
2017/08/28 09:20:20 batch 46: mean=15.487805 stddev=16.843790 entropy=0.963924 frames=4300 count=205
2017/08/28 09:20:20 Training policy...
2017/08/28 09:20:22 step 0: objective=0.39259747
2017/08/28 09:20:23 step 1: objective=0.40284547
2017/08/28 09:20:24 step 2: objective=0.41037086
2017/08/28 09:20:25 step 3: objective=0.420933
2017/08/28 09:20:26 step 4: objective=0.43721405
2017/08/28 09:20:26 step 5: objective=0.4500216
2017/08/28 09:20:27 step 6: objective=0.45676062
2017/08/28 09:20:28 step 7: objective=0.4647824
2017/08/28 09:20:28 Training value function...
2017/08/28 09:20:30 step 0: mse=88.410761 step=0.100000
2017/08/28 09:20:30 step 1: mse=86.934007 step=0.100000
2017/08/28 09:20:31 step 2: mse=85.653186 step=0.100000
2017/08/28 09:20:32 step 3: mse=84.694024 step=0.100000
2017/08/28 09:20:33 step 4: mse=83.769576 step=0.100000
2017/08/28 09:20:34 step 5: mse=82.860754 step=0.100000
2017/08/28 09:20:35 step 6: mse=82.076130 step=0.100000
2017/08/28 09:20:35 step 7: mse=81.227421 step=0.100000
2017/08/28 09:20:35 Saving...
2017/08/28 09:20:35 Gathering batch of experience...
2017/08/28 09:22:03 batch 47: mean=15.590244 stddev=15.081499 entropy=0.959703 frames=4278 count=205
2017/08/28 09:22:03 Training policy...
2017/08/28 09:22:06 step 0: objective=0.377375
2017/08/28 09:22:06 step 1: objective=0.39786455
2017/08/28 09:22:07 step 2: objective=0.40600508
2017/08/28 09:22:08 step 3: objective=0.42125246
2017/08/28 09:22:09 step 4: objective=0.43672597
2017/08/28 09:22:10 step 5: objective=0.44690332
2017/08/28 09:22:10 step 6: objective=0.45245695
2017/08/28 09:22:11 step 7: objective=0.45834312
2017/08/28 09:22:11 Training value function...
2017/08/28 09:22:13 step 0: mse=71.528480 step=0.100000
2017/08/28 09:22:14 step 1: mse=70.773916 step=0.100000
2017/08/28 09:22:14 step 2: mse=70.342253 step=0.100000
2017/08/28 09:22:15 step 3: mse=69.474050 step=0.100000
2017/08/28 09:22:16 step 4: mse=68.862170 step=0.100000
2017/08/28 09:22:17 step 5: mse=68.472090 step=0.100000
2017/08/28 09:22:18 step 6: mse=68.043314 step=0.100000
2017/08/28 09:22:19 step 7: mse=67.501503 step=0.100000
2017/08/28 09:22:19 Saving...
2017/08/28 09:22:19 Gathering batch of experience...
2017/08/28 09:23:48 batch 48: mean=13.894231 stddev=13.562830 entropy=0.960564 frames=4244 count=208
2017/08/28 09:23:48 Training policy...
2017/08/28 09:23:50 step 0: objective=-0.096964255
2017/08/28 09:23:51 step 1: objective=-0.08962512
2017/08/28 09:23:52 step 2: objective=-0.07384459
2017/08/28 09:23:53 step 3: objective=-0.06692452
2017/08/28 09:23:53 step 4: objective=-0.056050524
2017/08/28 09:23:54 step 5: objective=-0.04295659
2017/08/28 09:23:55 step 6: objective=-0.031460725
2017/08/28 09:23:56 step 7: objective=-0.022666749
2017/08/28 09:23:56 Training value function...
2017/08/28 09:23:58 step 0: mse=59.447959 step=0.100000
2017/08/28 09:23:58 step 1: mse=58.747294 step=0.100000
2017/08/28 09:23:59 step 2: mse=58.207328 step=0.100000
2017/08/28 09:24:00 step 3: mse=57.830578 step=0.100000
2017/08/28 09:24:01 step 4: mse=57.367294 step=0.100000
2017/08/28 09:24:02 step 5: mse=57.010925 step=0.100000
2017/08/28 09:24:02 step 6: mse=56.608537 step=0.100000
2017/08/28 09:24:03 step 7: mse=56.305777 step=0.100000
2017/08/28 09:24:03 Saving...
2017/08/28 09:24:03 Gathering batch of experience...
2017/08/28 09:25:28 batch 49: mean=16.045918 stddev=16.395710 entropy=0.954213 frames=4292 count=196
2017/08/28 09:25:28 Training policy...
2017/08/28 09:25:31 step 0: objective=1.1755548
2017/08/28 09:25:32 step 1: objective=1.1875658
2017/08/28 09:25:33 step 2: objective=1.1992459
2017/08/28 09:25:33 step 3: objective=1.2103
2017/08/28 09:25:34 step 4: objective=1.2226179
2017/08/28 09:25:35 step 5: objective=1.2364913
2017/08/28 09:25:36 step 6: objective=1.2446628
2017/08/28 09:25:37 step 7: objective=1.2571375
2017/08/28 09:25:37 Training value function...
2017/08/28 09:25:38 step 0: mse=89.401213 step=0.100000
2017/08/28 09:25:39 step 1: mse=88.361296 step=0.100000
2017/08/28 09:25:40 step 2: mse=87.422699 step=0.100000
2017/08/28 09:25:41 step 3: mse=86.473076 step=0.100000
2017/08/28 09:25:42 step 4: mse=85.681662 step=0.100000
2017/08/28 09:25:43 step 5: mse=84.879440 step=0.100000
2017/08/28 09:25:43 step 6: mse=84.350980 step=0.100000
2017/08/28 09:25:44 step 7: mse=83.235809 step=0.100000
2017/08/28 09:25:44 Saving...
2017/08/28 09:25:44 Gathering batch of experience...
2017/08/28 09:27:09 batch 50: mean=17.603093 stddev=20.182216 entropy=0.953425 frames=4350 count=194
2017/08/28 09:27:09 Training policy...
2017/08/28 09:27:12 step 0: objective=1.3124521
2017/08/28 09:27:12 step 1: objective=1.3240552
2017/08/28 09:27:13 step 2: objective=1.3398261
2017/08/28 09:27:14 step 3: objective=1.3537037
2017/08/28 09:27:15 step 4: objective=1.3675959
2017/08/28 09:27:16 step 5: objective=1.3735538
2017/08/28 09:27:17 step 6: objective=1.3824309
2017/08/28 09:27:17 step 7: objective=1.387652
2017/08/28 09:27:17 Training value function...
2017/08/28 09:27:19 step 0: mse=108.323964 step=0.100000
2017/08/28 09:27:20 step 1: mse=105.899436 step=0.100000
2017/08/28 09:27:21 step 2: mse=104.111023 step=0.100000
2017/08/28 09:27:22 step 3: mse=102.176069 step=0.100000
2017/08/28 09:27:23 step 4: mse=101.053438 step=0.100000
2017/08/28 09:27:23 step 5: mse=99.325390 step=0.100000
2017/08/28 09:27:24 step 6: mse=98.101749 step=0.100000
2017/08/28 09:27:25 step 7: mse=96.917210 step=0.100000
2017/08/28 09:27:25 Saving...
2017/08/28 09:27:25 Gathering batch of experience...
2017/08/28 09:28:56 batch 51: mean=16.333333 stddev=16.041311 entropy=0.948371 frames=4301 count=207
2017/08/28 09:28:56 Training policy...
2017/08/28 09:28:59 step 0: objective=0.2335575
2017/08/28 09:28:59 step 1: objective=0.24309699
2017/08/28 09:29:00 step 2: objective=0.2558543
2017/08/28 09:29:01 step 3: objective=0.2644196
2017/08/28 09:29:02 step 4: objective=0.27534577
2017/08/28 09:29:03 step 5: objective=0.28250277
2017/08/28 09:29:03 step 6: objective=0.29374146
2017/08/28 09:29:04 step 7: objective=0.3004743
2017/08/28 09:29:04 Training value function...
2017/08/28 09:29:06 step 0: mse=87.149664 step=0.100000
2017/08/28 09:29:07 step 1: mse=86.232490 step=0.100000
2017/08/28 09:29:08 step 2: mse=85.433566 step=0.100000
2017/08/28 09:29:08 step 3: mse=84.625372 step=0.100000
2017/08/28 09:29:09 step 4: mse=84.030594 step=0.100000
2017/08/28 09:29:10 step 5: mse=83.420923 step=0.100000
2017/08/28 09:29:11 step 6: mse=83.022303 step=0.100000
2017/08/28 09:29:12 step 7: mse=82.453521 step=0.100000
2017/08/28 09:29:12 Saving...
2017/08/28 09:29:12 Gathering batch of experience...
2017/08/28 09:30:42 batch 52: mean=15.951456 stddev=14.607073 entropy=0.942202 frames=4365 count=206
2017/08/28 09:30:42 Training policy...
2017/08/28 09:30:45 step 0: objective=0.4852606
2017/08/28 09:30:46 step 1: objective=0.4975945
2017/08/28 09:30:47 step 2: objective=0.50741965
2017/08/28 09:30:48 step 3: objective=0.51624036
2017/08/28 09:30:48 step 4: objective=0.52507406
2017/08/28 09:30:49 step 5: objective=0.531204
2017/08/28 09:30:50 step 6: objective=0.5431279
2017/08/28 09:30:51 step 7: objective=0.5491862
2017/08/28 09:30:51 Training value function...
2017/08/28 09:30:53 step 0: mse=70.556308 step=0.100000
2017/08/28 09:30:53 step 1: mse=69.616991 step=0.100000
2017/08/28 09:30:54 step 2: mse=68.869277 step=0.100000
2017/08/28 09:30:55 step 3: mse=68.043473 step=0.100000
2017/08/28 09:30:56 step 4: mse=67.378788 step=0.100000
2017/08/28 09:30:57 step 5: mse=66.564274 step=0.100000
2017/08/28 09:30:58 step 6: mse=65.987470 step=0.100000
2017/08/28 09:30:58 step 7: mse=65.588861 step=0.100000
2017/08/28 09:30:58 Saving...
2017/08/28 09:30:58 Gathering batch of experience...
2017/08/28 09:32:22 batch 53: mean=17.078534 stddev=18.464034 entropy=0.942565 frames=4273 count=191
2017/08/28 09:32:22 Training policy...
2017/08/28 09:32:24 step 0: objective=0.9998935
2017/08/28 09:32:25 step 1: objective=1.012364
2017/08/28 09:32:26 step 2: objective=1.0304834
2017/08/28 09:32:27 step 3: objective=1.0460321
2017/08/28 09:32:28 step 4: objective=1.060822
2017/08/28 09:32:28 step 5: objective=1.0689801
2017/08/28 09:32:29 step 6: objective=1.0832613
2017/08/28 09:32:30 step 7: objective=1.0949628
2017/08/28 09:32:30 Training value function...
2017/08/28 09:32:32 step 0: mse=101.070170 step=0.100000
2017/08/28 09:32:33 step 1: mse=99.361120 step=0.100000
2017/08/28 09:32:33 step 2: mse=97.965548 step=0.100000
2017/08/28 09:32:34 step 3: mse=96.624703 step=0.100000
2017/08/28 09:32:35 step 4: mse=95.285659 step=0.100000
2017/08/28 09:32:36 step 5: mse=94.117828 step=0.100000
2017/08/28 09:32:37 step 6: mse=92.984145 step=0.100000
2017/08/28 09:32:37 step 7: mse=91.880649 step=0.100000
2017/08/28 09:32:37 Saving...
2017/08/28 09:32:37 Gathering batch of experience...
2017/08/28 09:34:02 batch 54: mean=17.112821 stddev=16.880199 entropy=0.937386 frames=4249 count=195
2017/08/28 09:34:02 Training policy...
2017/08/28 09:34:05 step 0: objective=0.40685046
2017/08/28 09:34:06 step 1: objective=0.41683128
2017/08/28 09:34:07 step 2: objective=0.43683589
2017/08/28 09:34:07 step 3: objective=0.44822618
2017/08/28 09:34:08 step 4: objective=0.46156368
2017/08/28 09:34:09 step 5: objective=0.47964633
2017/08/28 09:34:10 step 6: objective=0.49090692
2017/08/28 09:34:11 step 7: objective=0.49741134
2017/08/28 09:34:11 Training value function...
2017/08/28 09:34:12 step 0: mse=83.479014 step=0.100000
2017/08/28 09:34:13 step 1: mse=82.209104 step=0.100000
2017/08/28 09:34:14 step 2: mse=81.522278 step=0.100000
2017/08/28 09:34:15 step 3: mse=80.897268 step=0.100000
2017/08/28 09:34:16 step 4: mse=80.074216 step=0.100000
2017/08/28 09:34:16 step 5: mse=79.745461 step=0.100000
2017/08/28 09:34:17 step 6: mse=78.795823 step=0.100000
2017/08/28 09:34:18 step 7: mse=78.138708 step=0.100000
2017/08/28 09:34:18 Saving...
2017/08/28 09:34:18 Gathering batch of experience...
2017/08/28 09:35:38 batch 55: mean=16.852459 stddev=17.495826 entropy=0.936206 frames=4208 count=183
2017/08/28 09:35:38 Training policy...
2017/08/28 09:35:41 step 0: objective=0.73599213
2017/08/28 09:35:42 step 1: objective=0.7451133
2017/08/28 09:35:43 step 2: objective=0.75699735
2017/08/28 09:35:43 step 3: objective=0.7664089
2017/08/28 09:35:44 step 4: objective=0.7814282
2017/08/28 09:35:45 step 5: objective=0.7944938
2017/08/28 09:35:46 step 6: objective=0.80484843
2017/08/28 09:35:47 step 7: objective=0.81534547
2017/08/28 09:35:47 Training value function...
2017/08/28 09:35:48 step 0: mse=87.971015 step=0.100000
2017/08/28 09:35:49 step 1: mse=87.255987 step=0.100000
2017/08/28 09:35:50 step 2: mse=86.681324 step=0.100000
2017/08/28 09:35:51 step 3: mse=86.119380 step=0.100000
2017/08/28 09:35:52 step 4: mse=85.631927 step=0.100000
2017/08/28 09:35:52 step 5: mse=85.182648 step=0.100000
2017/08/28 09:35:53 step 6: mse=84.360023 step=0.100000
2017/08/28 09:35:54 step 7: mse=83.875630 step=0.100000
2017/08/28 09:35:54 Saving...
2017/08/28 09:35:54 Gathering batch of experience...
2017/08/28 09:37:19 batch 56: mean=16.142857 stddev=16.567118 entropy=0.930633 frames=4199 count=196
2017/08/28 09:37:19 Training policy...
2017/08/28 09:37:21 step 0: objective=0.33968624
2017/08/28 09:37:22 step 1: objective=0.35446668
2017/08/28 09:37:23 step 2: objective=0.36399156
2017/08/28 09:37:24 step 3: objective=0.37451154
2017/08/28 09:37:25 step 4: objective=0.38293463
2017/08/28 09:37:25 step 5: objective=0.39546463
2017/08/28 09:37:26 step 6: objective=0.40217218
2017/08/28 09:37:27 step 7: objective=0.40766358
2017/08/28 09:37:27 Training value function...
2017/08/28 09:37:29 step 0: mse=74.049799 step=0.100000
2017/08/28 09:37:29 step 1: mse=72.673713 step=0.100000
2017/08/28 09:37:30 step 2: mse=71.514461 step=0.100000
2017/08/28 09:37:31 step 3: mse=70.390444 step=0.100000
2017/08/28 09:37:32 step 4: mse=69.485945 step=0.100000
2017/08/28 09:37:33 step 5: mse=68.522461 step=0.100000
2017/08/28 09:37:33 step 6: mse=67.810080 step=0.100000
2017/08/28 09:37:34 step 7: mse=67.025041 step=0.100000
2017/08/28 09:37:34 Saving...
2017/08/28 09:37:34 Gathering batch of experience...
2017/08/28 09:38:59 batch 57: mean=17.015464 stddev=18.815840 entropy=0.925810 frames=4337 count=194
2017/08/28 09:38:59 Training policy...
2017/08/28 09:39:01 step 0: objective=0.9528737
2017/08/28 09:39:02 step 1: objective=0.9660475
2017/08/28 09:39:03 step 2: objective=0.9768951
2017/08/28 09:39:04 step 3: objective=0.988568
2017/08/28 09:39:05 step 4: objective=0.9964475
2017/08/28 09:39:05 step 5: objective=1.0145514
2017/08/28 09:39:06 step 6: objective=1.0227292
2017/08/28 09:39:07 step 7: objective=1.0322915
2017/08/28 09:39:07 Training value function...
2017/08/28 09:39:09 step 0: mse=97.802268 step=0.100000
2017/08/28 09:39:10 step 1: mse=95.678854 step=0.100000
2017/08/28 09:39:11 step 2: mse=94.033156 step=0.100000
2017/08/28 09:39:11 step 3: mse=92.609321 step=0.100000
2017/08/28 09:39:12 step 4: mse=91.234331 step=0.100000
2017/08/28 09:39:13 step 5: mse=90.128982 step=0.100000
2017/08/28 09:39:14 step 6: mse=88.987581 step=0.100000
2017/08/28 09:39:15 step 7: mse=88.088427 step=0.100000
2017/08/28 09:39:15 Saving...
2017/08/28 09:39:15 Gathering batch of experience...
2017/08/28 09:40:44 batch 58: mean=15.485577 stddev=15.299252 entropy=0.918886 frames=4297 count=208
2017/08/28 09:40:44 Training policy...
2017/08/28 09:40:46 step 0: objective=-0.017441934
2017/08/28 09:40:47 step 1: objective=-0.0005910737
2017/08/28 09:40:48 step 2: objective=0.011471671
2017/08/28 09:40:49 step 3: objective=0.019965904
2017/08/28 09:40:49 step 4: objective=0.03243927
2017/08/28 09:40:50 step 5: objective=0.044138968
2017/08/28 09:40:51 step 6: objective=0.053982735
2017/08/28 09:40:52 step 7: objective=0.059732985
2017/08/28 09:40:52 Training value function...
2017/08/28 09:40:54 step 0: mse=75.472264 step=0.100000
2017/08/28 09:40:54 step 1: mse=74.414424 step=0.100000
2017/08/28 09:40:55 step 2: mse=73.399332 step=0.100000
2017/08/28 09:40:56 step 3: mse=72.640865 step=0.100000
2017/08/28 09:40:57 step 4: mse=71.917046 step=0.100000
2017/08/28 09:40:58 step 5: mse=71.073197 step=0.100000
2017/08/28 09:40:59 step 6: mse=70.316892 step=0.100000
2017/08/28 09:40:59 step 7: mse=69.543226 step=0.100000
2017/08/28 09:40:59 Saving...
2017/08/28 09:40:59 Gathering batch of experience...
2017/08/28 09:42:23 batch 59: mean=16.520619 stddev=15.655837 entropy=0.920328 frames=4246 count=194
2017/08/28 09:42:23 Training policy...
2017/08/28 09:42:26 step 0: objective=0.85149264
2017/08/28 09:42:26 step 1: objective=0.86195767
2017/08/28 09:42:27 step 2: objective=0.87457514
2017/08/28 09:42:28 step 3: objective=0.8833245
2017/08/28 09:42:29 step 4: objective=0.89086163
2017/08/28 09:42:30 step 5: objective=0.8997451
2017/08/28 09:42:31 step 6: objective=0.90570605
2017/08/28 09:42:31 step 7: objective=0.9118986
2017/08/28 09:42:31 Training value function...
2017/08/28 09:42:33 step 0: mse=76.343101 step=0.100000
2017/08/28 09:42:34 step 1: mse=75.598375 step=0.100000
2017/08/28 09:42:35 step 2: mse=74.551224 step=0.100000
2017/08/28 09:42:36 step 3: mse=73.912938 step=0.100000
2017/08/28 09:42:36 step 4: mse=73.364616 step=0.100000
2017/08/28 09:42:37 step 5: mse=72.352773 step=0.100000
2017/08/28 09:42:38 step 6: mse=71.523172 step=0.100000
2017/08/28 09:42:39 step 7: mse=70.886724 step=0.100000
2017/08/28 09:42:39 Saving...
2017/08/28 09:42:39 Gathering batch of experience...
2017/08/28 09:44:05 batch 60: mean=16.308458 stddev=17.553738 entropy=0.913072 frames=4270 count=201
2017/08/28 09:44:05 Training policy...
2017/08/28 09:44:08 step 0: objective=0.8415607
2017/08/28 09:44:09 step 1: objective=0.85117173
2017/08/28 09:44:09 step 2: objective=0.8607159
2017/08/28 09:44:10 step 3: objective=0.870168
2017/08/28 09:44:11 step 4: objective=0.88517773
2017/08/28 09:44:12 step 5: objective=0.892655
2017/08/28 09:44:13 step 6: objective=0.901975
2017/08/28 09:44:13 step 7: objective=0.9094918
2017/08/28 09:44:13 Training value function...
2017/08/28 09:44:15 step 0: mse=88.370376 step=0.100000
2017/08/28 09:44:16 step 1: mse=87.595998 step=0.100000
2017/08/28 09:44:17 step 2: mse=86.807674 step=0.100000
2017/08/28 09:44:18 step 3: mse=85.825770 step=0.100000
2017/08/28 09:44:19 step 4: mse=85.448263 step=0.100000
2017/08/28 09:44:19 step 5: mse=85.053016 step=0.100000
2017/08/28 09:44:20 step 6: mse=84.632971 step=0.100000
2017/08/28 09:44:21 step 7: mse=84.037590 step=0.100000
2017/08/28 09:44:21 Saving...
2017/08/28 09:44:21 Gathering batch of experience...
2017/08/28 09:45:42 batch 61: mean=18.191257 stddev=19.484659 entropy=0.917071 frames=4302 count=183
2017/08/28 09:45:42 Training policy...
2017/08/28 09:45:44 step 0: objective=1.0039208
2017/08/28 09:45:45 step 1: objective=1.017841
2017/08/28 09:45:46 step 2: objective=1.0290915
2017/08/28 09:45:47 step 3: objective=1.0456853
2017/08/28 09:45:48 step 4: objective=1.0530728
2017/08/28 09:45:48 step 5: objective=1.0649517
2017/08/28 09:45:49 step 6: objective=1.0763398
2017/08/28 09:45:50 step 7: objective=1.0838224
2017/08/28 09:45:50 Training value function...
2017/08/28 09:45:52 step 0: mse=105.945640 step=0.100000
2017/08/28 09:45:53 step 1: mse=105.184826 step=0.100000
2017/08/28 09:45:53 step 2: mse=104.307160 step=0.100000
2017/08/28 09:45:54 step 3: mse=103.737047 step=0.100000
2017/08/28 09:45:55 step 4: mse=103.178789 step=0.100000
2017/08/28 09:45:56 step 5: mse=102.724638 step=0.100000
2017/08/28 09:45:57 step 6: mse=101.873854 step=0.100000
2017/08/28 09:45:58 step 7: mse=101.090226 step=0.100000
2017/08/28 09:45:58 Saving...
2017/08/28 09:45:58 Gathering batch of experience...
2017/08/28 09:47:16 batch 62: mean=19.983240 stddev=19.559528 entropy=0.917385 frames=4273 count=179
2017/08/28 09:47:16 Training policy...
2017/08/28 09:47:19 step 0: objective=1.3331361
2017/08/28 09:47:20 step 1: objective=1.3435608
2017/08/28 09:47:21 step 2: objective=1.359324
2017/08/28 09:47:21 step 3: objective=1.372276
2017/08/28 09:47:22 step 4: objective=1.3873537
2017/08/28 09:47:23 step 5: objective=1.3966492
2017/08/28 09:47:24 step 6: objective=1.4074973
2017/08/28 09:47:25 step 7: objective=1.4218568
2017/08/28 09:47:25 Training value function...
2017/08/28 09:47:26 step 0: mse=97.930981 step=0.100000
2017/08/28 09:47:27 step 1: mse=96.403087 step=0.100000
2017/08/28 09:47:28 step 2: mse=95.123720 step=0.100000
2017/08/28 09:47:29 step 3: mse=93.887032 step=0.100000
2017/08/28 09:47:30 step 4: mse=92.774106 step=0.100000
2017/08/28 09:47:31 step 5: mse=91.713054 step=0.100000
2017/08/28 09:47:32 step 6: mse=91.034980 step=0.100000
2017/08/28 09:47:32 step 7: mse=90.017645 step=0.100000
2017/08/28 09:47:32 Saving...
2017/08/28 09:47:32 Gathering batch of experience...
2017/08/28 09:48:52 batch 63: mean=19.505495 stddev=20.587724 entropy=0.910225 frames=4236 count=182
2017/08/28 09:48:52 Training policy...
2017/08/28 09:48:55 step 0: objective=0.9134003
2017/08/28 09:48:56 step 1: objective=0.93485355
2017/08/28 09:48:56 step 2: objective=0.95216435
2017/08/28 09:48:57 step 3: objective=0.9663704
2017/08/28 09:48:58 step 4: objective=0.9803183
2017/08/28 09:48:59 step 5: objective=0.9934249
2017/08/28 09:49:00 step 6: objective=1.0044249
2017/08/28 09:49:00 step 7: objective=1.0186524
2017/08/28 09:49:00 Training value function...
2017/08/28 09:49:02 step 0: mse=113.245472 step=0.100000
2017/08/28 09:49:03 step 1: mse=111.965370 step=0.100000
2017/08/28 09:49:04 step 2: mse=110.736203 step=0.100000
2017/08/28 09:49:05 step 3: mse=109.552190 step=0.100000
2017/08/28 09:49:06 step 4: mse=108.411054 step=0.100000
2017/08/28 09:49:06 step 5: mse=107.525264 step=0.100000
2017/08/28 09:49:07 step 6: mse=106.701059 step=0.100000
2017/08/28 09:49:08 step 7: mse=106.095051 step=0.100000
2017/08/28 09:49:08 Saving...
2017/08/28 09:49:08 Gathering batch of experience...
2017/08/28 09:50:29 batch 64: mean=18.886486 stddev=17.995287 entropy=0.898796 frames=4245 count=185
2017/08/28 09:50:29 Training policy...
2017/08/28 09:50:32 step 0: objective=0.46527115
2017/08/28 09:50:33 step 1: objective=0.47807413
2017/08/28 09:50:34 step 2: objective=0.4992161
2017/08/28 09:50:34 step 3: objective=0.5142592
2017/08/28 09:50:35 step 4: objective=0.52825314
2017/08/28 09:50:36 step 5: objective=0.53703827
2017/08/28 09:50:37 step 6: objective=0.546676
2017/08/28 09:50:38 step 7: objective=0.55583173
2017/08/28 09:50:38 Training value function...
2017/08/28 09:50:39 step 0: mse=94.652897 step=0.100000
2017/08/28 09:50:40 step 1: mse=93.277701 step=0.100000
2017/08/28 09:50:41 step 2: mse=92.000075 step=0.100000
2017/08/28 09:50:42 step 3: mse=90.911071 step=0.100000
2017/08/28 09:50:43 step 4: mse=90.203374 step=0.100000
2017/08/28 09:50:44 step 5: mse=89.490228 step=0.100000
2017/08/28 09:50:44 step 6: mse=88.862322 step=0.100000
2017/08/28 09:50:45 step 7: mse=88.308697 step=0.100000
2017/08/28 09:50:45 Saving...
2017/08/28 09:50:45 Gathering batch of experience...
2017/08/28 09:52:09 batch 65: mean=18.494737 stddev=18.533255 entropy=0.894982 frames=4310 count=190
2017/08/28 09:52:09 Training policy...
2017/08/28 09:52:11 step 0: objective=0.50055355
2017/08/28 09:52:12 step 1: objective=0.511717
2017/08/28 09:52:13 step 2: objective=0.5208961
2017/08/28 09:52:14 step 3: objective=0.53626263
2017/08/28 09:52:15 step 4: objective=0.5454696
2017/08/28 09:52:16 step 5: objective=0.5554337
2017/08/28 09:52:16 step 6: objective=0.56582075
2017/08/28 09:52:17 step 7: objective=0.5755112
2017/08/28 09:52:17 Training value function...
2017/08/28 09:52:19 step 0: mse=97.182619 step=0.100000
2017/08/28 09:52:20 step 1: mse=96.448828 step=0.100000
2017/08/28 09:52:21 step 2: mse=95.974291 step=0.100000
2017/08/28 09:52:21 step 3: mse=95.467062 step=0.100000
2017/08/28 09:52:22 step 4: mse=95.111427 step=0.100000
2017/08/28 09:52:23 step 5: mse=94.486175 step=0.100000
2017/08/28 09:52:24 step 6: mse=94.265110 step=0.100000
2017/08/28 09:52:25 step 7: mse=93.674858 step=0.100000
2017/08/28 09:52:25 Saving...
2017/08/28 09:52:25 Gathering batch of experience...
2017/08/28 09:53:51 batch 66: mean=16.543147 stddev=15.185634 entropy=0.894990 frames=4314 count=197
2017/08/28 09:53:51 Training policy...
2017/08/28 09:53:54 step 0: objective=-0.2785998
2017/08/28 09:53:54 step 1: objective=-0.26834863
2017/08/28 09:53:55 step 2: objective=-0.25768203
2017/08/28 09:53:56 step 3: objective=-0.24900043
2017/08/28 09:53:57 step 4: objective=-0.24009927
2017/08/28 09:53:58 step 5: objective=-0.22705483
2017/08/28 09:53:58 step 6: objective=-0.22069548
2017/08/28 09:53:59 step 7: objective=-0.21559244
2017/08/28 09:53:59 Training value function...
2017/08/28 09:54:01 step 0: mse=70.870208 step=0.100000
2017/08/28 09:54:02 step 1: mse=69.600397 step=0.100000
2017/08/28 09:54:03 step 2: mse=68.403117 step=0.100000
2017/08/28 09:54:04 step 3: mse=67.520051 step=0.100000
2017/08/28 09:54:04 step 4: mse=66.853446 step=0.100000
2017/08/28 09:54:05 step 5: mse=66.312327 step=0.100000
2017/08/28 09:54:06 step 6: mse=65.520559 step=0.100000
2017/08/28 09:54:07 step 7: mse=64.850712 step=0.100000
2017/08/28 09:54:07 Saving...
2017/08/28 09:54:07 Gathering batch of experience...
2017/08/28 09:55:33 batch 67: mean=18.309645 stddev=18.047050 entropy=0.891610 frames=4340 count=197
2017/08/28 09:55:33 Training policy...
2017/08/28 09:55:36 step 0: objective=0.93535864
2017/08/28 09:55:37 step 1: objective=0.9561073
2017/08/28 09:55:37 step 2: objective=0.9710979
2017/08/28 09:55:38 step 3: objective=0.987175
2017/08/28 09:55:39 step 4: objective=1.0013244
2017/08/28 09:55:40 step 5: objective=1.0159154
2017/08/28 09:55:41 step 6: objective=1.0257257
2017/08/28 09:55:41 step 7: objective=1.0341046
2017/08/28 09:55:41 Training value function...
2017/08/28 09:55:43 step 0: mse=96.311042 step=0.100000
2017/08/28 09:55:44 step 1: mse=95.444158 step=0.100000
2017/08/28 09:55:45 step 2: mse=94.663001 step=0.100000
2017/08/28 09:55:46 step 3: mse=93.845750 step=0.100000
2017/08/28 09:55:47 step 4: mse=92.775814 step=0.100000
2017/08/28 09:55:48 step 5: mse=92.282386 step=0.100000
2017/08/28 09:55:48 step 6: mse=91.633304 step=0.100000
2017/08/28 09:55:49 step 7: mse=90.934621 step=0.100000
2017/08/28 09:55:49 Saving...
2017/08/28 09:55:49 Gathering batch of experience...
2017/08/28 09:57:16 batch 68: mean=17.050251 stddev=16.921263 entropy=0.880901 frames=4234 count=199
2017/08/28 09:57:16 Training policy...
2017/08/28 09:57:18 step 0: objective=0.54771876
2017/08/28 09:57:19 step 1: objective=0.5632416
2017/08/28 09:57:20 step 2: objective=0.5762531
2017/08/28 09:57:21 step 3: objective=0.5854168
2017/08/28 09:57:22 step 4: objective=0.6011369
2017/08/28 09:57:22 step 5: objective=0.6112564
2017/08/28 09:57:23 step 6: objective=0.6215463
2017/08/28 09:57:24 step 7: objective=0.6279188
2017/08/28 09:57:24 Training value function...
2017/08/28 09:57:26 step 0: mse=87.693214 step=0.100000
2017/08/28 09:57:27 step 1: mse=86.714247 step=0.100000
2017/08/28 09:57:27 step 2: mse=85.585822 step=0.100000
2017/08/28 09:57:28 step 3: mse=84.601087 step=0.100000
2017/08/28 09:57:29 step 4: mse=83.771019 step=0.100000
2017/08/28 09:57:30 step 5: mse=83.028594 step=0.100000
2017/08/28 09:57:31 step 6: mse=82.189972 step=0.100000
2017/08/28 09:57:31 step 7: mse=81.712018 step=0.100000
2017/08/28 09:57:31 Saving...
2017/08/28 09:57:32 Gathering batch of experience...
2017/08/28 09:58:57 batch 69: mean=17.922280 stddev=18.695797 entropy=0.879064 frames=4378 count=193
2017/08/28 09:58:57 Training policy...
2017/08/28 09:58:59 step 0: objective=0.5551048
2017/08/28 09:59:00 step 1: objective=0.5696774
2017/08/28 09:59:01 step 2: objective=0.5855034
2017/08/28 09:59:02 step 3: objective=0.6023483
2017/08/28 09:59:03 step 4: objective=0.61740994
2017/08/28 09:59:04 step 5: objective=0.62674725
2017/08/28 09:59:04 step 6: objective=0.636347
2017/08/28 09:59:05 step 7: objective=0.64314693
2017/08/28 09:59:05 Training value function...
2017/08/28 09:59:07 step 0: mse=95.412701 step=0.100000
2017/08/28 09:59:08 step 1: mse=94.536759 step=0.100000
2017/08/28 09:59:09 step 2: mse=93.666069 step=0.100000
2017/08/28 09:59:10 step 3: mse=92.478622 step=0.100000
2017/08/28 09:59:11 step 4: mse=91.239161 step=0.100000
2017/08/28 09:59:11 step 5: mse=90.194891 step=0.100000
2017/08/28 09:59:12 step 6: mse=89.927087 step=0.100000
2017/08/28 09:59:13 step 7: mse=89.233945 step=0.100000
2017/08/28 09:59:13 Saving...
2017/08/28 09:59:13 Gathering batch of experience...
2017/08/28 10:00:35 batch 70: mean=17.550265 stddev=17.909941 entropy=0.886243 frames=4266 count=189
2017/08/28 10:00:35 Training policy...
2017/08/28 10:00:38 step 0: objective=0.61500823
2017/08/28 10:00:39 step 1: objective=0.62805235
2017/08/28 10:00:40 step 2: objective=0.641372
2017/08/28 10:00:40 step 3: objective=0.65479344
2017/08/28 10:00:41 step 4: objective=0.66686416
2017/08/28 10:00:42 step 5: objective=0.6801721
2017/08/28 10:00:43 step 6: objective=0.69247735
2017/08/28 10:00:44 step 7: objective=0.6995493
2017/08/28 10:00:44 Training value function...
2017/08/28 10:00:45 step 0: mse=89.055366 step=0.100000
2017/08/28 10:00:46 step 1: mse=88.179361 step=0.100000
2017/08/28 10:00:47 step 2: mse=87.257358 step=0.100000
2017/08/28 10:00:48 step 3: mse=86.440949 step=0.100000
2017/08/28 10:00:49 step 4: mse=85.492432 step=0.100000
2017/08/28 10:00:50 step 5: mse=85.019472 step=0.100000
2017/08/28 10:00:50 step 6: mse=84.127827 step=0.100000
2017/08/28 10:00:51 step 7: mse=83.489207 step=0.100000
2017/08/28 10:00:51 Saving...
2017/08/28 10:00:51 Gathering batch of experience...
2017/08/28 10:02:13 batch 71: mean=18.513369 stddev=18.081029 entropy=0.882360 frames=4256 count=187
2017/08/28 10:02:13 Training policy...
2017/08/28 10:02:16 step 0: objective=0.89181936
2017/08/28 10:02:16 step 1: objective=0.90219593
2017/08/28 10:02:17 step 2: objective=0.91347337
2017/08/28 10:02:18 step 3: objective=0.9289048
2017/08/28 10:02:19 step 4: objective=0.93717337
2017/08/28 10:02:20 step 5: objective=0.95047224
2017/08/28 10:02:21 step 6: objective=0.9654088
2017/08/28 10:02:21 step 7: objective=0.9717081
2017/08/28 10:02:21 Training value function...
2017/08/28 10:02:23 step 0: mse=95.652146 step=0.100000
2017/08/28 10:02:24 step 1: mse=94.594029 step=0.100000
2017/08/28 10:02:25 step 2: mse=93.936450 step=0.100000
2017/08/28 10:02:26 step 3: mse=92.867039 step=0.100000
2017/08/28 10:02:27 step 4: mse=92.472818 step=0.100000
2017/08/28 10:02:27 step 5: mse=91.965524 step=0.100000
2017/08/28 10:02:28 step 6: mse=91.403559 step=0.100000
2017/08/28 10:02:29 step 7: mse=91.050194 step=0.100000
2017/08/28 10:02:29 Saving...
2017/08/28 10:02:29 Gathering batch of experience...
2017/08/28 10:03:48 batch 72: mean=18.719101 stddev=18.836666 entropy=0.877424 frames=4253 count=178
2017/08/28 10:03:48 Training policy...
2017/08/28 10:03:51 step 0: objective=0.66097116
2017/08/28 10:03:51 step 1: objective=0.67259175
2017/08/28 10:03:52 step 2: objective=0.6805178
2017/08/28 10:03:53 step 3: objective=0.69211847
2017/08/28 10:03:54 step 4: objective=0.7011087
2017/08/28 10:03:55 step 5: objective=0.70822614
2017/08/28 10:03:55 step 6: objective=0.7136332
2017/08/28 10:03:56 step 7: objective=0.7232244
2017/08/28 10:03:56 Training value function...
2017/08/28 10:03:58 step 0: mse=91.850781 step=0.100000
2017/08/28 10:03:59 step 1: mse=91.045535 step=0.100000
2017/08/28 10:04:00 step 2: mse=90.383743 step=0.100000
2017/08/28 10:04:01 step 3: mse=89.474720 step=0.100000
2017/08/28 10:04:01 step 4: mse=88.692190 step=0.100000
2017/08/28 10:04:02 step 5: mse=87.883129 step=0.100000
2017/08/28 10:04:03 step 6: mse=87.248765 step=0.100000
2017/08/28 10:04:04 step 7: mse=86.363178 step=0.100000
2017/08/28 10:04:04 Saving...
2017/08/28 10:04:04 Gathering batch of experience...
2017/08/28 10:05:23 batch 73: mean=19.121547 stddev=18.727078 entropy=0.870889 frames=4265 count=181
2017/08/28 10:05:23 Training policy...
2017/08/28 10:05:25 step 0: objective=1.022041
2017/08/28 10:05:26 step 1: objective=1.0390146
2017/08/28 10:05:27 step 2: objective=1.0528485
2017/08/28 10:05:28 step 3: objective=1.0669142
2017/08/28 10:05:29 step 4: objective=1.0828263
2017/08/28 10:05:29 step 5: objective=1.0962372
2017/08/28 10:05:30 step 6: objective=1.1023403
2017/08/28 10:05:31 step 7: objective=1.1177045
2017/08/28 10:05:31 Training value function...
2017/08/28 10:05:33 step 0: mse=100.576777 step=0.100000
2017/08/28 10:05:34 step 1: mse=98.857335 step=0.100000
2017/08/28 10:05:35 step 2: mse=97.367771 step=0.100000
2017/08/28 10:05:35 step 3: mse=95.767523 step=0.100000
2017/08/28 10:05:36 step 4: mse=94.311808 step=0.100000
2017/08/28 10:05:37 step 5: mse=93.178985 step=0.100000
2017/08/28 10:05:38 step 6: mse=92.253575 step=0.100000
2017/08/28 10:05:39 step 7: mse=90.918537 step=0.100000
2017/08/28 10:05:39 Saving...
2017/08/28 10:05:39 Gathering batch of experience...
2017/08/28 10:06:54 batch 74: mean=20.579882 stddev=19.154182 entropy=0.868873 frames=4237 count=169
2017/08/28 10:06:54 Training policy...
2017/08/28 10:06:57 step 0: objective=0.9038306
2017/08/28 10:06:58 step 1: objective=0.91576016
2017/08/28 10:06:59 step 2: objective=0.9260216
2017/08/28 10:06:59 step 3: objective=0.9399978
2017/08/28 10:07:00 step 4: objective=0.95440686
2017/08/28 10:07:01 step 5: objective=0.9679358
2017/08/28 10:07:02 step 6: objective=0.97449404
2017/08/28 10:07:03 step 7: objective=0.9817506
2017/08/28 10:07:03 Training value function...
2017/08/28 10:07:04 step 0: mse=100.615533 step=0.100000
2017/08/28 10:07:05 step 1: mse=100.095564 step=0.100000
2017/08/28 10:07:06 step 2: mse=99.055156 step=0.100000
2017/08/28 10:07:07 step 3: mse=98.122005 step=0.100000
2017/08/28 10:07:08 step 4: mse=97.261767 step=0.100000
2017/08/28 10:07:09 step 5: mse=96.718782 step=0.100000
2017/08/28 10:07:09 step 6: mse=95.962115 step=0.100000
2017/08/28 10:07:10 step 7: mse=95.332358 step=0.100000
2017/08/28 10:07:10 Saving...
2017/08/28 10:07:10 Gathering batch of experience...
2017/08/28 10:08:31 batch 75: mean=18.825843 stddev=17.834067 entropy=0.856389 frames=4292 count=178
2017/08/28 10:08:31 Training policy...
2017/08/28 10:08:33 step 0: objective=0.16700149
2017/08/28 10:08:34 step 1: objective=0.17840649
2017/08/28 10:08:35 step 2: objective=0.19119608
2017/08/28 10:08:36 step 3: objective=0.19975396
2017/08/28 10:08:36 step 4: objective=0.21585049
2017/08/28 10:08:37 step 5: objective=0.2220518
2017/08/28 10:08:38 step 6: objective=0.22955751
2017/08/28 10:08:39 step 7: objective=0.2344712
2017/08/28 10:08:39 Training value function...
2017/08/28 10:08:41 step 0: mse=89.045583 step=0.100000
2017/08/28 10:08:42 step 1: mse=87.985878 step=0.100000
2017/08/28 10:08:42 step 2: mse=87.505716 step=0.100000
2017/08/28 10:08:43 step 3: mse=86.957220 step=0.100000
2017/08/28 10:08:44 step 4: mse=85.965673 step=0.100000
2017/08/28 10:08:45 step 5: mse=85.388044 step=0.100000
2017/08/28 10:08:46 step 6: mse=85.028574 step=0.100000
2017/08/28 10:08:47 step 7: mse=84.854132 step=0.100000
2017/08/28 10:08:47 Saving...
2017/08/28 10:08:47 Gathering batch of experience...
2017/08/28 10:10:09 batch 76: mean=18.455026 stddev=20.313270 entropy=0.864895 frames=4261 count=189
2017/08/28 10:10:09 Training policy...
2017/08/28 10:10:11 step 0: objective=0.7122076
2017/08/28 10:10:12 step 1: objective=0.71964526
2017/08/28 10:10:13 step 2: objective=0.73378104
2017/08/28 10:10:14 step 3: objective=0.7426784
2017/08/28 10:10:15 step 4: objective=0.7512507
2017/08/28 10:10:16 step 5: objective=0.7617687
2017/08/28 10:10:16 step 6: objective=0.77483374
2017/08/28 10:10:17 step 7: objective=0.7818305
2017/08/28 10:10:17 Training value function...
2017/08/28 10:10:19 step 0: mse=104.643063 step=0.100000
2017/08/28 10:10:20 step 1: mse=103.344154 step=0.100000
2017/08/28 10:10:21 step 2: mse=101.798810 step=0.100000
2017/08/28 10:10:21 step 3: mse=100.568064 step=0.100000
2017/08/28 10:10:22 step 4: mse=99.229983 step=0.100000
2017/08/28 10:10:23 step 5: mse=98.195404 step=0.100000
2017/08/28 10:10:24 step 6: mse=97.291282 step=0.100000
2017/08/28 10:10:25 step 7: mse=96.296070 step=0.100000
2017/08/28 10:10:25 Saving...
2017/08/28 10:10:25 Gathering batch of experience...
2017/08/28 10:11:46 batch 77: mean=19.215470 stddev=19.338593 entropy=0.850920 frames=4255 count=181
2017/08/28 10:11:46 Training policy...
2017/08/28 10:11:48 step 0: objective=0.61509275
2017/08/28 10:11:49 step 1: objective=0.6289569
2017/08/28 10:11:50 step 2: objective=0.6392998
2017/08/28 10:11:51 step 3: objective=0.6511537
2017/08/28 10:11:52 step 4: objective=0.6631592
2017/08/28 10:11:52 step 5: objective=0.67535955
2017/08/28 10:11:53 step 6: objective=0.6818359
2017/08/28 10:11:54 step 7: objective=0.6901517
2017/08/28 10:11:54 Training value function...
2017/08/28 10:11:56 step 0: mse=98.522544 step=0.100000
2017/08/28 10:11:57 step 1: mse=97.568465 step=0.100000
2017/08/28 10:11:58 step 2: mse=96.472353 step=0.100000
2017/08/28 10:11:58 step 3: mse=95.173989 step=0.100000
2017/08/28 10:11:59 step 4: mse=94.235929 step=0.100000
2017/08/28 10:12:00 step 5: mse=93.372332 step=0.100000
2017/08/28 10:12:01 step 6: mse=92.686617 step=0.100000
2017/08/28 10:12:02 step 7: mse=92.147611 step=0.100000
2017/08/28 10:12:02 Saving...
2017/08/28 10:12:02 Gathering batch of experience...
2017/08/28 10:13:14 batch 78: mean=22.081250 stddev=22.360672 entropy=0.856794 frames=4212 count=160
2017/08/28 10:13:14 Training policy...
2017/08/28 10:13:17 step 0: objective=1.2910877
2017/08/28 10:13:18 step 1: objective=1.302148
2017/08/28 10:13:19 step 2: objective=1.3207073
2017/08/28 10:13:19 step 3: objective=1.3391362
2017/08/28 10:13:20 step 4: objective=1.351334
2017/08/28 10:13:21 step 5: objective=1.3648869
2017/08/28 10:13:22 step 6: objective=1.3749907
2017/08/28 10:13:23 step 7: objective=1.3827826
2017/08/28 10:13:23 Training value function...
2017/08/28 10:13:24 step 0: mse=109.109654 step=0.100000
2017/08/28 10:13:25 step 1: mse=107.574529 step=0.100000
2017/08/28 10:13:26 step 2: mse=106.117769 step=0.100000
2017/08/28 10:13:27 step 3: mse=104.518745 step=0.100000
2017/08/28 10:13:28 step 4: mse=103.610434 step=0.100000
2017/08/28 10:13:29 step 5: mse=102.558509 step=0.100000
2017/08/28 10:13:29 step 6: mse=101.781413 step=0.100000
2017/08/28 10:13:30 step 7: mse=100.788052 step=0.100000
2017/08/28 10:13:30 Saving...
2017/08/28 10:13:30 Gathering batch of experience...
2017/08/28 10:14:50 batch 79: mean=19.710227 stddev=17.598460 entropy=0.851346 frames=4434 count=176
2017/08/28 10:14:50 Training policy...
2017/08/28 10:14:53 step 0: objective=0.16471381
2017/08/28 10:14:54 step 1: objective=0.1793203
2017/08/28 10:14:55 step 2: objective=0.19945341
2017/08/28 10:14:55 step 3: objective=0.2201565
2017/08/28 10:14:56 step 4: objective=0.23101237
2017/08/28 10:14:57 step 5: objective=0.236781
2017/08/28 10:14:58 step 6: objective=0.24783021
2017/08/28 10:14:59 step 7: objective=0.25426686
2017/08/28 10:14:59 Training value function...
2017/08/28 10:15:01 step 0: mse=87.264720 step=0.100000
2017/08/28 10:15:02 step 1: mse=86.449602 step=0.100000
2017/08/28 10:15:02 step 2: mse=85.743257 step=0.100000
2017/08/28 10:15:03 step 3: mse=85.040748 step=0.100000
2017/08/28 10:15:04 step 4: mse=84.412030 step=0.100000
2017/08/28 10:15:05 step 5: mse=83.904936 step=0.100000
2017/08/28 10:15:06 step 6: mse=83.451811 step=0.100000
2017/08/28 10:15:07 step 7: mse=82.879877 step=0.100000
2017/08/28 10:15:07 Saving...
2017/08/28 10:15:07 Gathering batch of experience...
2017/08/28 10:16:21 batch 80: mean=20.230303 stddev=19.328617 entropy=0.847694 frames=4258 count=165
2017/08/28 10:16:21 Training policy...
2017/08/28 10:16:24 step 0: objective=0.70334756
2017/08/28 10:16:25 step 1: objective=0.7181169
2017/08/28 10:16:26 step 2: objective=0.7311913
2017/08/28 10:16:26 step 3: objective=0.74693704
2017/08/28 10:16:27 step 4: objective=0.757629
2017/08/28 10:16:28 step 5: objective=0.76588655
2017/08/28 10:16:29 step 6: objective=0.77266276
2017/08/28 10:16:30 step 7: objective=0.77907443
2017/08/28 10:16:30 Training value function...
2017/08/28 10:16:31 step 0: mse=96.817278 step=0.100000
2017/08/28 10:16:32 step 1: mse=95.144504 step=0.100000
2017/08/28 10:16:33 step 2: mse=93.746341 step=0.100000
2017/08/28 10:16:34 step 3: mse=92.657587 step=0.100000
2017/08/28 10:16:35 step 4: mse=91.800344 step=0.100000
2017/08/28 10:16:36 step 5: mse=90.821871 step=0.100000
2017/08/28 10:16:37 step 6: mse=90.244442 step=0.100000
2017/08/28 10:16:37 step 7: mse=89.376665 step=0.100000
2017/08/28 10:16:37 Saving...
2017/08/28 10:16:37 Gathering batch of experience...
2017/08/28 10:17:56 batch 81: mean=20.240000 stddev=18.543835 entropy=0.843562 frames=4270 count=175
2017/08/28 10:17:56 Training policy...
2017/08/28 10:17:58 step 0: objective=0.75918204
2017/08/28 10:17:59 step 1: objective=0.767896
2017/08/28 10:18:00 step 2: objective=0.78137994
2017/08/28 10:18:01 step 3: objective=0.7978798
2017/08/28 10:18:02 step 4: objective=0.80770934
2017/08/28 10:18:02 step 5: objective=0.81315124
2017/08/28 10:18:03 step 6: objective=0.8205448
2017/08/28 10:18:04 step 7: objective=0.82829064
2017/08/28 10:18:04 Training value function...
2017/08/28 10:18:06 step 0: mse=86.937847 step=0.100000
2017/08/28 10:18:07 step 1: mse=86.226538 step=0.100000
2017/08/28 10:18:08 step 2: mse=85.375950 step=0.100000
2017/08/28 10:18:08 step 3: mse=84.668040 step=0.100000
2017/08/28 10:18:09 step 4: mse=84.076901 step=0.100000
2017/08/28 10:18:10 step 5: mse=83.392215 step=0.100000
2017/08/28 10:18:11 step 6: mse=82.699899 step=0.100000
2017/08/28 10:18:12 step 7: mse=82.156939 step=0.100000
2017/08/28 10:18:12 Saving...
2017/08/28 10:18:12 Gathering batch of experience...
2017/08/28 10:19:28 batch 82: mean=21.356725 stddev=19.961548 entropy=0.845630 frames=4310 count=171
2017/08/28 10:19:28 Training policy...
2017/08/28 10:19:31 step 0: objective=0.9881853
2017/08/28 10:19:32 step 1: objective=1.0040007
2017/08/28 10:19:33 step 2: objective=1.0204595
2017/08/28 10:19:34 step 3: objective=1.0373541
2017/08/28 10:19:34 step 4: objective=1.0448846
2017/08/28 10:19:35 step 5: objective=1.0539659
2017/08/28 10:19:36 step 6: objective=1.0606893
2017/08/28 10:19:37 step 7: objective=1.0664502
2017/08/28 10:19:37 Training value function...
2017/08/28 10:19:39 step 0: mse=103.920329 step=0.100000
2017/08/28 10:19:40 step 1: mse=103.054448 step=0.100000
2017/08/28 10:19:40 step 2: mse=102.290503 step=0.100000
2017/08/28 10:19:41 step 3: mse=101.047005 step=0.100000
2017/08/28 10:19:42 step 4: mse=100.081099 step=0.100000
2017/08/28 10:19:43 step 5: mse=99.196150 step=0.100000
2017/08/28 10:19:44 step 6: mse=98.225107 step=0.100000
2017/08/28 10:19:45 step 7: mse=97.335104 step=0.100000
2017/08/28 10:19:45 Saving...
2017/08/28 10:19:45 Gathering batch of experience...
2017/08/28 10:21:02 batch 83: mean=19.488506 stddev=21.840261 entropy=0.841028 frames=4251 count=174
2017/08/28 10:21:02 Training policy...
2017/08/28 10:21:04 step 0: objective=0.43785608
2017/08/28 10:21:05 step 1: objective=0.450066
2017/08/28 10:21:06 step 2: objective=0.46240407
2017/08/28 10:21:07 step 3: objective=0.46982563
2017/08/28 10:21:08 step 4: objective=0.48126152
2017/08/28 10:21:09 step 5: objective=0.49172333
2017/08/28 10:21:09 step 6: objective=0.5004282
2017/08/28 10:21:10 step 7: objective=0.51091367
2017/08/28 10:21:10 Training value function...
2017/08/28 10:21:12 step 0: mse=113.002601 step=0.100000
2017/08/28 10:21:13 step 1: mse=111.484692 step=0.100000
2017/08/28 10:21:14 step 2: mse=110.077497 step=0.100000
2017/08/28 10:21:15 step 3: mse=108.830488 step=0.100000
2017/08/28 10:21:15 step 4: mse=107.959328 step=0.100000
2017/08/28 10:21:16 step 5: mse=106.619638 step=0.100000
2017/08/28 10:21:17 step 6: mse=105.422235 step=0.100000
2017/08/28 10:21:18 step 7: mse=104.269977 step=0.100000
2017/08/28 10:21:18 Saving...
2017/08/28 10:21:18 Gathering batch of experience...
2017/08/28 10:22:33 batch 84: mean=23.036364 stddev=22.503842 entropy=0.846311 frames=4258 count=165
2017/08/28 10:22:33 Training policy...
2017/08/28 10:22:36 step 0: objective=1.2540015
2017/08/28 10:22:36 step 1: objective=1.2669281
2017/08/28 10:22:37 step 2: objective=1.287036
2017/08/28 10:22:38 step 3: objective=1.3038664
2017/08/28 10:22:39 step 4: objective=1.3229785
2017/08/28 10:22:40 step 5: objective=1.3335154
2017/08/28 10:22:41 step 6: objective=1.3437662
2017/08/28 10:22:41 step 7: objective=1.3530358
2017/08/28 10:22:41 Training value function...
2017/08/28 10:22:43 step 0: mse=114.930939 step=0.100000
2017/08/28 10:22:44 step 1: mse=113.381006 step=0.100000
2017/08/28 10:22:45 step 2: mse=112.026152 step=0.100000
2017/08/28 10:22:46 step 3: mse=110.277067 step=0.100000
2017/08/28 10:22:46 step 4: mse=108.865764 step=0.100000
2017/08/28 10:22:47 step 5: mse=107.466511 step=0.100000
2017/08/28 10:22:48 step 6: mse=105.947751 step=0.100000
2017/08/28 10:22:49 step 7: mse=104.755983 step=0.100000
2017/08/28 10:22:49 Saving...
2017/08/28 10:22:49 Gathering batch of experience...
2017/08/28 10:24:04 batch 85: mean=22.835366 stddev=26.161617 entropy=0.830064 frames=4298 count=164
2017/08/28 10:24:04 Training policy...
2017/08/28 10:24:07 step 0: objective=0.8892372
2017/08/28 10:24:08 step 1: objective=0.9045337
2017/08/28 10:24:09 step 2: objective=0.92353076
2017/08/28 10:24:10 step 3: objective=0.9352359
2017/08/28 10:24:10 step 4: objective=0.94557595
2017/08/28 10:24:11 step 5: objective=0.9551585
2017/08/28 10:24:12 step 6: objective=0.96296936
2017/08/28 10:24:13 step 7: objective=0.97012043
2017/08/28 10:24:13 Training value function...
2017/08/28 10:24:15 step 0: mse=128.422921 step=0.100000
2017/08/28 10:24:16 step 1: mse=124.814978 step=0.100000
2017/08/28 10:24:16 step 2: mse=122.386242 step=0.100000
2017/08/28 10:24:17 step 3: mse=119.986245 step=0.100000
2017/08/28 10:24:18 step 4: mse=117.760957 step=0.100000
2017/08/28 10:24:19 step 5: mse=116.135776 step=0.100000
2017/08/28 10:24:20 step 6: mse=115.056683 step=0.100000
2017/08/28 10:24:21 step 7: mse=113.878629 step=0.100000
2017/08/28 10:24:21 Saving...
2017/08/28 10:24:21 Gathering batch of experience...
2017/08/28 10:25:40 batch 86: mean=21.545455 stddev=20.160385 entropy=0.826505 frames=4275 count=176
2017/08/28 10:25:40 Training policy...
2017/08/28 10:25:43 step 0: objective=0.8794214
2017/08/28 10:25:43 step 1: objective=0.8923042
2017/08/28 10:25:44 step 2: objective=0.9041914
2017/08/28 10:25:45 step 3: objective=0.91327083
2017/08/28 10:25:46 step 4: objective=0.9239967
2017/08/28 10:25:47 step 5: objective=0.9336867
2017/08/28 10:25:48 step 6: objective=0.9410258
2017/08/28 10:25:48 step 7: objective=0.9539685
2017/08/28 10:25:48 Training value function...
2017/08/28 10:25:50 step 0: mse=106.943904 step=0.100000
2017/08/28 10:25:51 step 1: mse=106.224511 step=0.100000
2017/08/28 10:25:52 step 2: mse=105.306803 step=0.100000
2017/08/28 10:25:53 step 3: mse=104.317909 step=0.100000
2017/08/28 10:25:54 step 4: mse=103.827457 step=0.100000
2017/08/28 10:25:54 step 5: mse=103.143351 step=0.100000
2017/08/28 10:25:55 step 6: mse=102.370232 step=0.100000
2017/08/28 10:25:56 step 7: mse=101.908527 step=0.100000
2017/08/28 10:25:56 Saving...
2017/08/28 10:25:56 Gathering batch of experience...
2017/08/28 10:27:12 batch 87: mean=22.568047 stddev=23.963911 entropy=0.831219 frames=4303 count=169
2017/08/28 10:27:12 Training policy...
2017/08/28 10:27:15 step 0: objective=0.88437766
2017/08/28 10:27:16 step 1: objective=0.9001439
2017/08/28 10:27:16 step 2: objective=0.91668636
2017/08/28 10:27:17 step 3: objective=0.92688173
2017/08/28 10:27:18 step 4: objective=0.9464844
2017/08/28 10:27:19 step 5: objective=0.95617926
2017/08/28 10:27:20 step 6: objective=0.96339244
2017/08/28 10:27:21 step 7: objective=0.9701403
2017/08/28 10:27:21 Training value function...
2017/08/28 10:27:22 step 0: mse=123.075973 step=0.100000
2017/08/28 10:27:23 step 1: mse=121.577348 step=0.100000
2017/08/28 10:27:24 step 2: mse=120.189503 step=0.100000
2017/08/28 10:27:25 step 3: mse=118.874477 step=0.100000
2017/08/28 10:27:26 step 4: mse=118.042629 step=0.100000
2017/08/28 10:27:27 step 5: mse=116.947739 step=0.100000
2017/08/28 10:27:28 step 6: mse=116.052586 step=0.100000
2017/08/28 10:27:28 step 7: mse=114.896657 step=0.100000
2017/08/28 10:27:28 Saving...
2017/08/28 10:27:28 Gathering batch of experience...
2017/08/28 10:28:46 batch 88: mean=21.433526 stddev=19.422960 entropy=0.821901 frames=4270 count=173
2017/08/28 10:28:46 Training policy...
2017/08/28 10:28:49 step 0: objective=0.5275928
2017/08/28 10:28:50 step 1: objective=0.5438818
2017/08/28 10:28:51 step 2: objective=0.55299646
2017/08/28 10:28:51 step 3: objective=0.56167847
2017/08/28 10:28:52 step 4: objective=0.5737486
2017/08/28 10:28:53 step 5: objective=0.5847084
2017/08/28 10:28:54 step 6: objective=0.5986061
2017/08/28 10:28:55 step 7: objective=0.60766184
2017/08/28 10:28:55 Training value function...
2017/08/28 10:28:56 step 0: mse=92.118554 step=0.100000
2017/08/28 10:28:57 step 1: mse=91.256525 step=0.100000
2017/08/28 10:28:58 step 2: mse=90.526543 step=0.100000
2017/08/28 10:28:59 step 3: mse=89.761637 step=0.100000
2017/08/28 10:29:00 step 4: mse=88.984954 step=0.100000
2017/08/28 10:29:01 step 5: mse=88.328173 step=0.100000
2017/08/28 10:29:01 step 6: mse=87.923376 step=0.100000
2017/08/28 10:29:02 step 7: mse=87.372584 step=0.100000
2017/08/28 10:29:02 Saving...
2017/08/28 10:29:02 Gathering batch of experience...
2017/08/28 10:30:19 batch 89: mean=20.550296 stddev=21.022927 entropy=0.817516 frames=4288 count=169
2017/08/28 10:30:19 Training policy...
2017/08/28 10:30:22 step 0: objective=0.4729874
2017/08/28 10:30:23 step 1: objective=0.4803585
2017/08/28 10:30:24 step 2: objective=0.48955318
2017/08/28 10:30:25 step 3: objective=0.49865454
2017/08/28 10:30:25 step 4: objective=0.5113001
2017/08/28 10:30:26 step 5: objective=0.52272785
2017/08/28 10:30:27 step 6: objective=0.53056115
2017/08/28 10:30:28 step 7: objective=0.5417712
2017/08/28 10:30:28 Training value function...
2017/08/28 10:30:30 step 0: mse=104.126532 step=0.100000
2017/08/28 10:30:31 step 1: mse=103.350262 step=0.100000
2017/08/28 10:30:31 step 2: mse=102.819419 step=0.100000
2017/08/28 10:30:32 step 3: mse=102.057730 step=0.100000
2017/08/28 10:30:33 step 4: mse=101.561106 step=0.100000
2017/08/28 10:30:34 step 5: mse=101.175692 step=0.100000
2017/08/28 10:30:35 step 6: mse=100.665500 step=0.100000
2017/08/28 10:30:36 step 7: mse=100.400981 step=0.100000
2017/08/28 10:30:36 Saving...
2017/08/28 10:30:36 Gathering batch of experience...
2017/08/28 10:31:49 batch 90: mean=21.335366 stddev=20.554590 entropy=0.811720 frames=4267 count=164
2017/08/28 10:31:49 Training policy...
2017/08/28 10:31:52 step 0: objective=0.56593734
2017/08/28 10:31:53 step 1: objective=0.57590103
2017/08/28 10:31:54 step 2: objective=0.588992
2017/08/28 10:31:55 step 3: objective=0.59756756
2017/08/28 10:31:55 step 4: objective=0.60946304
2017/08/28 10:31:56 step 5: objective=0.61739665
2017/08/28 10:31:57 step 6: objective=0.62511444
2017/08/28 10:31:58 step 7: objective=0.63247544
2017/08/28 10:31:58 Training value function...
2017/08/28 10:32:00 step 0: mse=90.414151 step=0.100000
2017/08/28 10:32:01 step 1: mse=89.586260 step=0.100000
2017/08/28 10:32:01 step 2: mse=89.067979 step=0.100000
2017/08/28 10:32:02 step 3: mse=88.338980 step=0.100000
2017/08/28 10:32:03 step 4: mse=87.935438 step=0.100000
2017/08/28 10:32:04 step 5: mse=87.386860 step=0.100000
2017/08/28 10:32:05 step 6: mse=86.851584 step=0.100000
2017/08/28 10:32:06 step 7: mse=86.444711 step=0.100000
2017/08/28 10:32:06 Saving...
2017/08/28 10:32:06 Gathering batch of experience...
2017/08/28 10:33:22 batch 91: mean=20.862275 stddev=17.201837 entropy=0.811702 frames=4330 count=167
2017/08/28 10:33:22 Training policy...
2017/08/28 10:33:25 step 0: objective=0.2729357
2017/08/28 10:33:26 step 1: objective=0.28285378
2017/08/28 10:33:26 step 2: objective=0.2919501
2017/08/28 10:33:27 step 3: objective=0.30457824
2017/08/28 10:33:28 step 4: objective=0.3158748
2017/08/28 10:33:29 step 5: objective=0.32891282
2017/08/28 10:33:30 step 6: objective=0.34123522
2017/08/28 10:33:31 step 7: objective=0.34940737
2017/08/28 10:33:31 Training value function...
2017/08/28 10:33:33 step 0: mse=76.247634 step=0.100000
2017/08/28 10:33:33 step 1: mse=75.394843 step=0.100000
2017/08/28 10:33:34 step 2: mse=74.687846 step=0.100000
2017/08/28 10:33:35 step 3: mse=74.027205 step=0.100000
2017/08/28 10:33:36 step 4: mse=73.595279 step=0.100000
2017/08/28 10:33:37 step 5: mse=73.102303 step=0.100000
2017/08/28 10:33:38 step 6: mse=72.511945 step=0.100000
2017/08/28 10:33:39 step 7: mse=72.037055 step=0.100000
2017/08/28 10:33:39 Saving...
2017/08/28 10:33:39 Gathering batch of experience...
2017/08/28 10:34:47 batch 92: mean=23.649007 stddev=23.922391 entropy=0.807207 frames=4308 count=151
2017/08/28 10:34:47 Training policy...
2017/08/28 10:34:50 step 0: objective=1.4914906
2017/08/28 10:34:51 step 1: objective=1.501436
2017/08/28 10:34:52 step 2: objective=1.5113889
2017/08/28 10:34:52 step 3: objective=1.5224031
2017/08/28 10:34:53 step 4: objective=1.5296298
2017/08/28 10:34:54 step 5: objective=1.5375304
2017/08/28 10:34:55 step 6: objective=1.5507365
2017/08/28 10:34:56 step 7: objective=1.5553712
2017/08/28 10:34:56 Training value function...
2017/08/28 10:34:58 step 0: mse=113.793223 step=0.100000
2017/08/28 10:34:59 step 1: mse=111.815038 step=0.100000
2017/08/28 10:34:59 step 2: mse=110.017184 step=0.100000
2017/08/28 10:35:00 step 3: mse=108.720720 step=0.100000
2017/08/28 10:35:01 step 4: mse=107.469691 step=0.100000
2017/08/28 10:35:02 step 5: mse=106.518449 step=0.100000
2017/08/28 10:35:03 step 6: mse=105.851792 step=0.100000
2017/08/28 10:35:04 step 7: mse=104.498612 step=0.100000
2017/08/28 10:35:04 Saving...
2017/08/28 10:35:04 Gathering batch of experience...
2017/08/28 10:36:21 batch 93: mean=22.865497 stddev=22.472063 entropy=0.806798 frames=4410 count=171
2017/08/28 10:36:21 Training policy...
2017/08/28 10:36:23 step 0: objective=0.98810977
2017/08/28 10:36:24 step 1: objective=1.0087494
2017/08/28 10:36:25 step 2: objective=1.0193284
2017/08/28 10:36:26 step 3: objective=1.0360185
2017/08/28 10:36:27 step 4: objective=1.0476556
2017/08/28 10:36:28 step 5: objective=1.0626318
2017/08/28 10:36:29 step 6: objective=1.0718889
2017/08/28 10:36:30 step 7: objective=1.0784917
2017/08/28 10:36:30 Training value function...
2017/08/28 10:36:31 step 0: mse=124.799567 step=0.100000
2017/08/28 10:36:32 step 1: mse=124.010168 step=0.100000
2017/08/28 10:36:33 step 2: mse=123.068802 step=0.100000
2017/08/28 10:36:34 step 3: mse=121.997523 step=0.100000
2017/08/28 10:36:35 step 4: mse=120.786530 step=0.100000
2017/08/28 10:36:36 step 5: mse=120.136734 step=0.100000
2017/08/28 10:36:37 step 6: mse=119.742531 step=0.100000
2017/08/28 10:36:37 step 7: mse=118.810157 step=0.100000
2017/08/28 10:36:37 Saving...
2017/08/28 10:36:37 Gathering batch of experience...
2017/08/28 10:37:54 batch 94: mean=20.511628 stddev=20.258357 entropy=0.800439 frames=4276 count=172
2017/08/28 10:37:54 Training policy...
2017/08/28 10:37:57 step 0: objective=0.22189572
2017/08/28 10:37:58 step 1: objective=0.238453
2017/08/28 10:37:58 step 2: objective=0.25064725
2017/08/28 10:37:59 step 3: objective=0.2594492
2017/08/28 10:38:00 step 4: objective=0.26961163
2017/08/28 10:38:01 step 5: objective=0.28210294
2017/08/28 10:38:02 step 6: objective=0.28960446
2017/08/28 10:38:03 step 7: objective=0.2959334
2017/08/28 10:38:03 Training value function...
2017/08/28 10:38:04 step 0: mse=100.604489 step=0.100000
2017/08/28 10:38:05 step 1: mse=100.084269 step=0.100000
2017/08/28 10:38:06 step 2: mse=98.761463 step=0.100000
2017/08/28 10:38:07 step 3: mse=97.777083 step=0.100000
2017/08/28 10:38:08 step 4: mse=97.036508 step=0.100000
2017/08/28 10:38:09 step 5: mse=96.078998 step=0.100000
2017/08/28 10:38:09 step 6: mse=95.136999 step=0.100000
2017/08/28 10:38:10 step 7: mse=94.344539 step=0.100000
2017/08/28 10:38:10 Saving...
2017/08/28 10:38:10 Gathering batch of experience...
2017/08/28 10:39:23 batch 95: mean=23.183544 stddev=21.403844 entropy=0.799351 frames=4252 count=158
2017/08/28 10:39:23 Training policy...
2017/08/28 10:39:25 step 0: objective=1.0624255
2017/08/28 10:39:26 step 1: objective=1.0776135
2017/08/28 10:39:27 step 2: objective=1.0912809
2017/08/28 10:39:28 step 3: objective=1.1031555
2017/08/28 10:39:29 step 4: objective=1.1128575
2017/08/28 10:39:30 step 5: objective=1.1239796
2017/08/28 10:39:30 step 6: objective=1.1314979
2017/08/28 10:39:31 step 7: objective=1.1413044
2017/08/28 10:39:31 Training value function...
2017/08/28 10:39:33 step 0: mse=115.834258 step=0.100000
2017/08/28 10:39:34 step 1: mse=114.299119 step=0.100000
2017/08/28 10:39:35 step 2: mse=113.329237 step=0.100000
2017/08/28 10:39:36 step 3: mse=112.134447 step=0.100000
2017/08/28 10:39:36 step 4: mse=110.764698 step=0.100000
2017/08/28 10:39:37 step 5: mse=109.726338 step=0.100000
2017/08/28 10:39:38 step 6: mse=108.717647 step=0.100000
2017/08/28 10:39:39 step 7: mse=107.895167 step=0.100000
2017/08/28 10:39:39 Saving...
2017/08/28 10:39:39 Gathering batch of experience...
2017/08/28 10:40:51 batch 96: mean=24.490446 stddev=24.755523 entropy=0.797875 frames=4274 count=157
2017/08/28 10:40:51 Training policy...
2017/08/28 10:40:54 step 0: objective=1.2938617
2017/08/28 10:40:54 step 1: objective=1.3051189
2017/08/28 10:40:55 step 2: objective=1.320342
2017/08/28 10:40:56 step 3: objective=1.3347068
2017/08/28 10:40:57 step 4: objective=1.3463926
2017/08/28 10:40:58 step 5: objective=1.3622707
2017/08/28 10:40:59 step 6: objective=1.370128
2017/08/28 10:40:59 step 7: objective=1.3782818
2017/08/28 10:40:59 Training value function...
2017/08/28 10:41:01 step 0: mse=133.833260 step=0.100000
2017/08/28 10:41:02 step 1: mse=132.471071 step=0.100000
2017/08/28 10:41:03 step 2: mse=131.075070 step=0.100000
2017/08/28 10:41:04 step 3: mse=129.822081 step=0.100000
2017/08/28 10:41:05 step 4: mse=128.610927 step=0.100000
2017/08/28 10:41:06 step 5: mse=127.303049 step=0.100000
2017/08/28 10:41:06 step 6: mse=126.170581 step=0.100000
2017/08/28 10:41:07 step 7: mse=125.366722 step=0.100000
2017/08/28 10:41:07 Saving...
2017/08/28 10:41:07 Gathering batch of experience...
2017/08/28 10:42:26 batch 97: mean=19.728814 stddev=18.417473 entropy=0.789803 frames=4307 count=177
2017/08/28 10:42:26 Training policy...
2017/08/28 10:42:28 step 0: objective=-0.519623
2017/08/28 10:42:29 step 1: objective=-0.5033159
2017/08/28 10:42:30 step 2: objective=-0.49123362
2017/08/28 10:42:31 step 3: objective=-0.4769961
2017/08/28 10:42:32 step 4: objective=-0.46271268
2017/08/28 10:42:33 step 5: objective=-0.4497605
2017/08/28 10:42:33 step 6: objective=-0.44341725
2017/08/28 10:42:34 step 7: objective=-0.43778458
2017/08/28 10:42:34 Training value function...
2017/08/28 10:42:36 step 0: mse=91.777269 step=0.100000
2017/08/28 10:42:37 step 1: mse=90.704607 step=0.100000
2017/08/28 10:42:38 step 2: mse=89.860967 step=0.100000
2017/08/28 10:42:39 step 3: mse=89.081795 step=0.100000
2017/08/28 10:42:39 step 4: mse=88.534985 step=0.100000
2017/08/28 10:42:40 step 5: mse=87.884040 step=0.100000
2017/08/28 10:42:41 step 6: mse=87.173406 step=0.100000
2017/08/28 10:42:42 step 7: mse=86.232057 step=0.100000
2017/08/28 10:42:42 Saving...
2017/08/28 10:42:42 Gathering batch of experience...
2017/08/28 10:43:57 batch 98: mean=22.090361 stddev=21.571350 entropy=0.790104 frames=4372 count=166
2017/08/28 10:43:57 Training policy...
2017/08/28 10:44:00 step 0: objective=0.79380053
2017/08/28 10:44:01 step 1: objective=0.80456996
2017/08/28 10:44:02 step 2: objective=0.81542337
2017/08/28 10:44:02 step 3: objective=0.82598674
2017/08/28 10:44:03 step 4: objective=0.8385027
2017/08/28 10:44:04 step 5: objective=0.849632
2017/08/28 10:44:05 step 6: objective=0.86164856
2017/08/28 10:44:06 step 7: objective=0.8738913
2017/08/28 10:44:06 Training value function...
2017/08/28 10:44:08 step 0: mse=108.095014 step=0.100000
2017/08/28 10:44:09 step 1: mse=106.454691 step=0.100000
2017/08/28 10:44:09 step 2: mse=105.063715 step=0.100000
2017/08/28 10:44:10 step 3: mse=103.902831 step=0.100000
2017/08/28 10:44:11 step 4: mse=102.310528 step=0.100000
2017/08/28 10:44:12 step 5: mse=101.093727 step=0.100000
2017/08/28 10:44:13 step 6: mse=100.061294 step=0.100000
2017/08/28 10:44:14 step 7: mse=98.959971 step=0.100000
2017/08/28 10:44:14 Saving...
2017/08/28 10:44:14 Gathering batch of experience...
2017/08/28 10:45:25 batch 99: mean=25.353333 stddev=24.693086 entropy=0.792203 frames=4322 count=150
2017/08/28 10:45:25 Training policy...
2017/08/28 10:45:28 step 0: objective=1.740544
2017/08/28 10:45:29 step 1: objective=1.7568262
2017/08/28 10:45:30 step 2: objective=1.7744403
2017/08/28 10:45:31 step 3: objective=1.7943101
2017/08/28 10:45:32 step 4: objective=1.8019714
2017/08/28 10:45:33 step 5: objective=1.8150711
2017/08/28 10:45:33 step 6: objective=1.8261341
2017/08/28 10:45:34 step 7: objective=1.8372862
2017/08/28 10:45:34 Training value function...
2017/08/28 10:45:36 step 0: mse=124.980928 step=0.100000
2017/08/28 10:45:37 step 1: mse=122.946117 step=0.100000
2017/08/28 10:45:38 step 2: mse=120.895130 step=0.100000
2017/08/28 10:45:39 step 3: mse=119.099564 step=0.100000
2017/08/28 10:45:39 step 4: mse=117.472799 step=0.100000
2017/08/28 10:45:40 step 5: mse=115.931010 step=0.100000
2017/08/28 10:45:41 step 6: mse=114.608465 step=0.100000
2017/08/28 10:45:42 step 7: mse=113.676344 step=0.100000
2017/08/28 10:45:42 Saving...
2017/08/28 10:45:42 Gathering batch of experience...
2017/08/28 10:46:52 batch 100: mean=24.533784 stddev=23.579198 entropy=0.790570 frames=4419 count=148
2017/08/28 10:46:52 Training policy...
2017/08/28 10:46:55 step 0: objective=0.6507106
2017/08/28 10:46:55 step 1: objective=0.6613397
2017/08/28 10:46:56 step 2: objective=0.6733111
2017/08/28 10:46:57 step 3: objective=0.68668705
2017/08/28 10:46:58 step 4: objective=0.697697
2017/08/28 10:46:59 step 5: objective=0.7039168
2017/08/28 10:47:00 step 6: objective=0.71758133
2017/08/28 10:47:01 step 7: objective=0.7232916
2017/08/28 10:47:01 Training value function...
2017/08/28 10:47:03 step 0: mse=96.854983 step=0.100000
2017/08/28 10:47:04 step 1: mse=95.955453 step=0.100000
2017/08/28 10:47:04 step 2: mse=94.919137 step=0.100000
2017/08/28 10:47:05 step 3: mse=94.220056 step=0.100000
2017/08/28 10:47:06 step 4: mse=93.556883 step=0.100000
2017/08/28 10:47:07 step 5: mse=92.974196 step=0.100000
2017/08/28 10:47:08 step 6: mse=92.175040 step=0.100000
2017/08/28 10:47:09 step 7: mse=91.428565 step=0.100000
2017/08/28 10:47:09 Saving...
2017/08/28 10:47:09 Gathering batch of experience...
2017/08/28 10:48:30 batch 101: mean=19.918919 stddev=18.741165 entropy=0.775438 frames=4352 count=185
2017/08/28 10:48:30 Training policy...
2017/08/28 10:48:33 step 0: objective=-0.10663254
2017/08/28 10:48:34 step 1: objective=-0.09100824
2017/08/28 10:48:35 step 2: objective=-0.0718349
2017/08/28 10:48:36 step 3: objective=-0.0546063
2017/08/28 10:48:37 step 4: objective=-0.0437501
2017/08/28 10:48:37 step 5: objective=-0.03360314
2017/08/28 10:48:38 step 6: objective=-0.02307603
2017/08/28 10:48:39 step 7: objective=-0.016765248
2017/08/28 10:48:39 Training value function...
2017/08/28 10:48:41 step 0: mse=89.654639 step=0.100000
2017/08/28 10:48:42 step 1: mse=88.448195 step=0.100000
2017/08/28 10:48:43 step 2: mse=87.417981 step=0.100000
2017/08/28 10:48:43 step 3: mse=86.498147 step=0.100000
2017/08/28 10:48:44 step 4: mse=85.676763 step=0.100000
2017/08/28 10:48:45 step 5: mse=85.022838 step=0.100000
2017/08/28 10:48:46 step 6: mse=84.455491 step=0.100000
2017/08/28 10:48:47 step 7: mse=83.928772 step=0.100000
2017/08/28 10:48:47 Saving...
2017/08/28 10:48:47 Gathering batch of experience...
2017/08/28 10:49:58 batch 102: mean=25.486667 stddev=24.551100 entropy=0.778231 frames=4359 count=150
2017/08/28 10:49:58 Training policy...
2017/08/28 10:50:01 step 0: objective=1.4341413
2017/08/28 10:50:01 step 1: objective=1.4431834
2017/08/28 10:50:02 step 2: objective=1.4537673
2017/08/28 10:50:03 step 3: objective=1.4636213
2017/08/28 10:50:04 step 4: objective=1.4710345
2017/08/28 10:50:05 step 5: objective=1.4796126
2017/08/28 10:50:06 step 6: objective=1.4921559
2017/08/28 10:50:07 step 7: objective=1.4985657
2017/08/28 10:50:07 Training value function...
2017/08/28 10:50:08 step 0: mse=128.909318 step=0.100000
2017/08/28 10:50:09 step 1: mse=126.778186 step=0.100000
2017/08/28 10:50:10 step 2: mse=124.893920 step=0.100000
2017/08/28 10:50:11 step 3: mse=123.339007 step=0.100000
2017/08/28 10:50:12 step 4: mse=121.791489 step=0.100000
2017/08/28 10:50:13 step 5: mse=120.713130 step=0.100000
2017/08/28 10:50:14 step 6: mse=119.059413 step=0.100000
2017/08/28 10:50:14 step 7: mse=117.902462 step=0.100000
2017/08/28 10:50:14 Saving...
2017/08/28 10:50:15 Gathering batch of experience...
2017/08/28 10:51:26 batch 103: mean=24.218543 stddev=23.129607 entropy=0.776529 frames=4381 count=151
2017/08/28 10:51:26 Training policy...
2017/08/28 10:51:29 step 0: objective=0.69232595
2017/08/28 10:51:30 step 1: objective=0.7092683
2017/08/28 10:51:30 step 2: objective=0.7201346
2017/08/28 10:51:31 step 3: objective=0.73085177
2017/08/28 10:51:32 step 4: objective=0.7386612
2017/08/28 10:51:33 step 5: objective=0.7498325
2017/08/28 10:51:34 step 6: objective=0.7589162
2017/08/28 10:51:35 step 7: objective=0.76628536
2017/08/28 10:51:35 Training value function...
2017/08/28 10:51:37 step 0: mse=97.970313 step=0.100000
2017/08/28 10:51:37 step 1: mse=96.993031 step=0.100000
2017/08/28 10:51:38 step 2: mse=96.303955 step=0.100000
2017/08/28 10:51:39 step 3: mse=95.787594 step=0.100000
2017/08/28 10:51:40 step 4: mse=95.223657 step=0.100000
2017/08/28 10:51:41 step 5: mse=94.457786 step=0.100000
2017/08/28 10:51:42 step 6: mse=94.026724 step=0.100000
2017/08/28 10:51:43 step 7: mse=93.760575 step=0.100000
2017/08/28 10:51:43 Saving...
2017/08/28 10:51:43 Gathering batch of experience...
2017/08/28 10:52:50 batch 104: mean=26.156463 stddev=25.085893 entropy=0.773490 frames=4282 count=147
2017/08/28 10:52:50 Training policy...
2017/08/28 10:52:53 step 0: objective=1.3441896
2017/08/28 10:52:54 step 1: objective=1.3628883
2017/08/28 10:52:55 step 2: objective=1.3798503
2017/08/28 10:52:55 step 3: objective=1.3888333
2017/08/28 10:52:56 step 4: objective=1.400707
2017/08/28 10:52:57 step 5: objective=1.412825
2017/08/28 10:52:58 step 6: objective=1.4217825
2017/08/28 10:52:59 step 7: objective=1.430134
2017/08/28 10:52:59 Training value function...
2017/08/28 10:53:01 step 0: mse=132.090391 step=0.100000
2017/08/28 10:53:01 step 1: mse=130.506811 step=0.100000
2017/08/28 10:53:02 step 2: mse=128.778055 step=0.100000
2017/08/28 10:53:03 step 3: mse=127.530872 step=0.100000
2017/08/28 10:53:04 step 4: mse=126.486667 step=0.100000
2017/08/28 10:53:05 step 5: mse=125.611936 step=0.100000
2017/08/28 10:53:06 step 6: mse=124.763691 step=0.100000
2017/08/28 10:53:07 step 7: mse=123.937092 step=0.100000
2017/08/28 10:53:07 Saving...
2017/08/28 10:53:07 Gathering batch of experience...
2017/08/28 10:54:20 batch 105: mean=22.932099 stddev=23.542482 entropy=0.761308 frames=4309 count=162
2017/08/28 10:54:20 Training policy...
2017/08/28 10:54:23 step 0: objective=0.24612305
2017/08/28 10:54:24 step 1: objective=0.257869
2017/08/28 10:54:25 step 2: objective=0.2734511
2017/08/28 10:54:26 step 3: objective=0.28486726
2017/08/28 10:54:27 step 4: objective=0.2929346
2017/08/28 10:54:27 step 5: objective=0.30578402
2017/08/28 10:54:28 step 6: objective=0.3143803
2017/08/28 10:54:29 step 7: objective=0.32517606
2017/08/28 10:54:29 Training value function...
2017/08/28 10:54:31 step 0: mse=111.447835 step=0.100000
2017/08/28 10:54:32 step 1: mse=110.495739 step=0.100000
2017/08/28 10:54:33 step 2: mse=108.897687 step=0.100000
2017/08/28 10:54:33 step 3: mse=107.524183 step=0.100000
2017/08/28 10:54:34 step 4: mse=106.782983 step=0.100000
2017/08/28 10:54:35 step 5: mse=105.739838 step=0.100000
2017/08/28 10:54:36 step 6: mse=104.818248 step=0.100000
2017/08/28 10:54:37 step 7: mse=104.350596 step=0.100000
2017/08/28 10:54:37 Saving...
2017/08/28 10:54:37 Gathering batch of experience...
2017/08/28 10:55:48 batch 106: mean=25.286667 stddev=24.784225 entropy=0.753928 frames=4302 count=150
2017/08/28 10:55:48 Training policy...
2017/08/28 10:55:50 step 0: objective=1.2844044
2017/08/28 10:55:51 step 1: objective=1.2982473
2017/08/28 10:55:52 step 2: objective=1.309051
2017/08/28 10:55:53 step 3: objective=1.3238094
2017/08/28 10:55:54 step 4: objective=1.3389255
2017/08/28 10:55:55 step 5: objective=1.3477118
2017/08/28 10:55:55 step 6: objective=1.3547045
2017/08/28 10:55:56 step 7: objective=1.3642162
2017/08/28 10:55:56 Training value function...
2017/08/28 10:55:58 step 0: mse=128.742695 step=0.100000
2017/08/28 10:55:59 step 1: mse=127.165607 step=0.100000
2017/08/28 10:56:00 step 2: mse=125.658495 step=0.100000
2017/08/28 10:56:01 step 3: mse=124.265749 step=0.100000
2017/08/28 10:56:02 step 4: mse=122.691759 step=0.100000
2017/08/28 10:56:02 step 5: mse=121.622613 step=0.100000
2017/08/28 10:56:03 step 6: mse=120.544308 step=0.100000
2017/08/28 10:56:04 step 7: mse=119.197414 step=0.100000
2017/08/28 10:56:04 Saving...
2017/08/28 10:56:04 Gathering batch of experience...
2017/08/28 10:57:19 batch 107: mean=20.718750 stddev=19.970657 entropy=0.760539 frames=4395 count=160
2017/08/28 10:57:19 Training policy...
2017/08/28 10:57:22 step 0: objective=-0.49640715
2017/08/28 10:57:24 step 1: objective=-0.4826147
2017/08/28 10:57:25 step 2: objective=-0.46739614
2017/08/28 10:57:26 step 3: objective=-0.45764786
2017/08/28 10:57:27 step 4: objective=-0.4477128
2017/08/28 10:57:28 step 5: objective=-0.43774393
2017/08/28 10:57:29 step 6: objective=-0.42756328
2017/08/28 10:57:29 step 7: objective=-0.4195696
2017/08/28 10:57:29 Training value function...
2017/08/28 10:57:32 step 0: mse=87.158008 step=0.100000
2017/08/28 10:57:33 step 1: mse=86.286469 step=0.100000
2017/08/28 10:57:33 step 2: mse=85.450618 step=0.100000
2017/08/28 10:57:34 step 3: mse=84.809408 step=0.100000
2017/08/28 10:57:35 step 4: mse=83.878359 step=0.100000
2017/08/28 10:57:36 step 5: mse=83.387085 step=0.100000
2017/08/28 10:57:37 step 6: mse=82.799654 step=0.100000
2017/08/28 10:57:38 step 7: mse=82.321977 step=0.100000
2017/08/28 10:57:38 Saving...
2017/08/28 10:57:38 Gathering batch of experience...
2017/08/28 10:58:56 batch 108: mean=24.401316 stddev=23.158567 entropy=0.749095 frames=4337 count=152
2017/08/28 10:58:56 Training policy...
2017/08/28 10:59:03 step 0: objective=1.165439
2017/08/28 10:59:04 step 1: objective=1.1800998
2017/08/28 10:59:05 step 2: objective=1.192015
2017/08/28 10:59:06 step 3: objective=1.2070652
2017/08/28 10:59:07 step 4: objective=1.2171223
2017/08/28 10:59:08 step 5: objective=1.2308205
2017/08/28 10:59:09 step 6: objective=1.2392181
2017/08/28 10:59:09 step 7: objective=1.2496738
2017/08/28 10:59:09 Training value function...
2017/08/28 10:59:11 step 0: mse=116.700122 step=0.100000
2017/08/28 10:59:12 step 1: mse=115.781513 step=0.100000
2017/08/28 10:59:13 step 2: mse=114.715615 step=0.100000
2017/08/28 10:59:14 step 3: mse=113.801874 step=0.100000
2017/08/28 10:59:15 step 4: mse=113.289141 step=0.100000
2017/08/28 10:59:16 step 5: mse=112.364086 step=0.100000
2017/08/28 10:59:17 step 6: mse=111.427324 step=0.100000
2017/08/28 10:59:18 step 7: mse=110.458051 step=0.100000
2017/08/28 10:59:18 Saving...
2017/08/28 10:59:18 Gathering batch of experience...
2017/08/28 11:00:33 batch 109: mean=22.761006 stddev=20.870809 entropy=0.740467 frames=4256 count=159
2017/08/28 11:00:33 Training policy...
2017/08/28 11:00:36 step 0: objective=0.5924253
2017/08/28 11:00:37 step 1: objective=0.6063218
2017/08/28 11:00:38 step 2: objective=0.61419755
2017/08/28 11:00:39 step 3: objective=0.62630194
2017/08/28 11:00:39 step 4: objective=0.6351982
2017/08/28 11:00:40 step 5: objective=0.6457549
2017/08/28 11:00:41 step 6: objective=0.6553256
2017/08/28 11:00:42 step 7: objective=0.6611424
2017/08/28 11:00:42 Training value function...
2017/08/28 11:00:44 step 0: mse=103.428909 step=0.100000
2017/08/28 11:00:44 step 1: mse=102.185128 step=0.100000
2017/08/28 11:00:45 step 2: mse=101.180397 step=0.100000
2017/08/28 11:00:46 step 3: mse=100.334514 step=0.100000
2017/08/28 11:00:47 step 4: mse=99.559388 step=0.100000
2017/08/28 11:00:48 step 5: mse=98.856939 step=0.100000
2017/08/28 11:00:49 step 6: mse=98.067951 step=0.100000
2017/08/28 11:00:50 step 7: mse=97.134708 step=0.100000
2017/08/28 11:00:50 Saving...
2017/08/28 11:00:50 Gathering batch of experience...
2017/08/28 11:01:59 batch 110: mean=25.493243 stddev=27.373912 entropy=0.747511 frames=4256 count=148
2017/08/28 11:01:59 Training policy...
2017/08/28 11:02:02 step 0: objective=1.5163101
2017/08/28 11:02:03 step 1: objective=1.526437
2017/08/28 11:02:04 step 2: objective=1.5366015
2017/08/28 11:02:04 step 3: objective=1.5504153
2017/08/28 11:02:05 step 4: objective=1.561103
2017/08/28 11:02:06 step 5: objective=1.5713384
2017/08/28 11:02:07 step 6: objective=1.5821704
2017/08/28 11:02:08 step 7: objective=1.5923404
2017/08/28 11:02:08 Training value function...
2017/08/28 11:02:10 step 0: mse=139.804340 step=0.100000
2017/08/28 11:02:10 step 1: mse=136.841577 step=0.100000
2017/08/28 11:02:11 step 2: mse=134.173904 step=0.100000
2017/08/28 11:02:12 step 3: mse=132.149321 step=0.100000
2017/08/28 11:02:13 step 4: mse=130.101264 step=0.100000
2017/08/28 11:02:14 step 5: mse=128.511862 step=0.100000
2017/08/28 11:02:15 step 6: mse=127.017895 step=0.100000
2017/08/28 11:02:15 step 7: mse=125.361350 step=0.100000
2017/08/28 11:02:15 Saving...
2017/08/28 11:02:15 Gathering batch of experience...
2017/08/28 11:03:30 batch 111: mean=23.930380 stddev=21.991114 entropy=0.735905 frames=4316 count=158
2017/08/28 11:03:30 Training policy...
2017/08/28 11:03:33 step 0: objective=0.35762513
2017/08/28 11:03:34 step 1: objective=0.3736209
2017/08/28 11:03:35 step 2: objective=0.38913134
2017/08/28 11:03:36 step 3: objective=0.40619567
2017/08/28 11:03:36 step 4: objective=0.41994065
2017/08/28 11:03:37 step 5: objective=0.43445724
2017/08/28 11:03:38 step 6: objective=0.44696423
2017/08/28 11:03:39 step 7: objective=0.4519385
2017/08/28 11:03:39 Training value function...
2017/08/28 11:03:41 step 0: mse=109.007242 step=0.100000
2017/08/28 11:03:42 step 1: mse=107.642875 step=0.100000
2017/08/28 11:03:42 step 2: mse=106.122750 step=0.100000
2017/08/28 11:03:43 step 3: mse=104.900978 step=0.100000
2017/08/28 11:03:44 step 4: mse=104.099819 step=0.100000
2017/08/28 11:03:45 step 5: mse=103.247764 step=0.100000
2017/08/28 11:03:46 step 6: mse=102.557574 step=0.100000
2017/08/28 11:03:47 step 7: mse=101.628638 step=0.100000
2017/08/28 11:03:47 Saving...
2017/08/28 11:03:47 Gathering batch of experience...
2017/08/28 11:04:57 batch 112: mean=28.795775 stddev=27.216539 entropy=0.740876 frames=4362 count=142
2017/08/28 11:04:57 Training policy...
2017/08/28 11:04:59 step 0: objective=1.878782
2017/08/28 11:05:00 step 1: objective=1.8882239
2017/08/28 11:05:01 step 2: objective=1.906295
2017/08/28 11:05:02 step 3: objective=1.9199994
2017/08/28 11:05:03 step 4: objective=1.9270097
2017/08/28 11:05:04 step 5: objective=1.9348365
2017/08/28 11:05:05 step 6: objective=1.9407456
2017/08/28 11:05:05 step 7: objective=1.9536215
2017/08/28 11:05:05 Training value function...
2017/08/28 11:05:07 step 0: mse=152.384236 step=0.100000
2017/08/28 11:05:08 step 1: mse=150.517252 step=0.100000
2017/08/28 11:05:09 step 2: mse=148.402394 step=0.100000
2017/08/28 11:05:10 step 3: mse=146.687513 step=0.100000
2017/08/28 11:05:11 step 4: mse=145.313909 step=0.100000
2017/08/28 11:05:12 step 5: mse=143.522849 step=0.100000
2017/08/28 11:05:12 step 6: mse=142.487249 step=0.100000
2017/08/28 11:05:13 step 7: mse=141.430781 step=0.100000
2017/08/28 11:05:13 Saving...
2017/08/28 11:05:13 Gathering batch of experience...
2017/08/28 11:06:25 batch 113: mean=24.445860 stddev=20.957158 entropy=0.726254 frames=4297 count=157
2017/08/28 11:06:25 Training policy...
2017/08/28 11:06:28 step 0: objective=0.18540151
2017/08/28 11:06:29 step 1: objective=0.1960655
2017/08/28 11:06:30 step 2: objective=0.20928736
2017/08/28 11:06:31 step 3: objective=0.21970192
2017/08/28 11:06:32 step 4: objective=0.23365809
2017/08/28 11:06:32 step 5: objective=0.23791148
2017/08/28 11:06:33 step 6: objective=0.2465711
2017/08/28 11:06:34 step 7: objective=0.25155315
2017/08/28 11:06:34 Training value function...
2017/08/28 11:06:36 step 0: mse=94.392973 step=0.100000
2017/08/28 11:06:37 step 1: mse=93.410885 step=0.100000
2017/08/28 11:06:38 step 2: mse=92.335464 step=0.100000
2017/08/28 11:06:38 step 3: mse=90.990446 step=0.100000
2017/08/28 11:06:39 step 4: mse=89.956101 step=0.100000
2017/08/28 11:06:40 step 5: mse=89.278914 step=0.100000
2017/08/28 11:06:41 step 6: mse=88.342739 step=0.100000
2017/08/28 11:06:42 step 7: mse=87.729102 step=0.100000
2017/08/28 11:06:42 Saving...
2017/08/28 11:06:42 Gathering batch of experience...
2017/08/28 11:07:53 batch 114: mean=24.552632 stddev=23.648130 entropy=0.727927 frames=4345 count=152
2017/08/28 11:07:53 Training policy...
2017/08/28 11:07:56 step 0: objective=0.5726532
2017/08/28 11:07:57 step 1: objective=0.5874908
2017/08/28 11:07:58 step 2: objective=0.604453
2017/08/28 11:07:59 step 3: objective=0.61827445
2017/08/28 11:07:59 step 4: objective=0.6275705
2017/08/28 11:08:00 step 5: objective=0.6347152
2017/08/28 11:08:01 step 6: objective=0.64380383
2017/08/28 11:08:02 step 7: objective=0.6522905
2017/08/28 11:08:02 Training value function...
2017/08/28 11:08:04 step 0: mse=108.950436 step=0.100000
2017/08/28 11:08:05 step 1: mse=107.779199 step=0.100000
2017/08/28 11:08:06 step 2: mse=106.931755 step=0.100000
2017/08/28 11:08:06 step 3: mse=105.853529 step=0.100000
2017/08/28 11:08:07 step 4: mse=105.234649 step=0.100000
2017/08/28 11:08:08 step 5: mse=104.433412 step=0.100000
2017/08/28 11:08:09 step 6: mse=103.944330 step=0.100000
2017/08/28 11:08:10 step 7: mse=103.189767 step=0.100000
2017/08/28 11:08:10 Saving...
2017/08/28 11:08:10 Gathering batch of experience...
2017/08/28 11:09:26 batch 115: mean=23.577640 stddev=21.405183 entropy=0.723042 frames=4268 count=161
2017/08/28 11:09:26 Training policy...
2017/08/28 11:09:28 step 0: objective=0.47539464
2017/08/28 11:09:29 step 1: objective=0.48701072
2017/08/28 11:09:30 step 2: objective=0.5020695
2017/08/28 11:09:31 step 3: objective=0.51281
2017/08/28 11:09:32 step 4: objective=0.52087826
2017/08/28 11:09:32 step 5: objective=0.5267061
2017/08/28 11:09:33 step 6: objective=0.5364073
2017/08/28 11:09:34 step 7: objective=0.5427427
2017/08/28 11:09:34 Training value function...
2017/08/28 11:09:36 step 0: mse=102.975952 step=0.100000
2017/08/28 11:09:37 step 1: mse=101.920225 step=0.100000
2017/08/28 11:09:38 step 2: mse=100.867472 step=0.100000
2017/08/28 11:09:38 step 3: mse=99.941485 step=0.100000
2017/08/28 11:09:39 step 4: mse=99.162758 step=0.100000
2017/08/28 11:09:40 step 5: mse=98.261968 step=0.100000
2017/08/28 11:09:41 step 6: mse=97.233691 step=0.100000
2017/08/28 11:09:42 step 7: mse=96.682723 step=0.100000
2017/08/28 11:09:42 Saving...
2017/08/28 11:09:42 Gathering batch of experience...
2017/08/28 11:10:52 batch 116: mean=24.734694 stddev=23.894703 entropy=0.724821 frames=4432 count=147
2017/08/28 11:10:52 Training policy...
2017/08/28 11:10:55 step 0: objective=0.7634863
2017/08/28 11:10:56 step 1: objective=0.77542317
2017/08/28 11:10:57 step 2: objective=0.7849651
2017/08/28 11:10:58 step 3: objective=0.79441583
2017/08/28 11:10:59 step 4: objective=0.80175626
2017/08/28 11:11:00 step 5: objective=0.8137575
2017/08/28 11:11:00 step 6: objective=0.82345974
2017/08/28 11:11:01 step 7: objective=0.8328487
2017/08/28 11:11:01 Training value function...
2017/08/28 11:11:03 step 0: mse=114.489619 step=0.100000
2017/08/28 11:11:04 step 1: mse=113.153723 step=0.100000
2017/08/28 11:11:05 step 2: mse=112.430451 step=0.100000
2017/08/28 11:11:06 step 3: mse=111.850355 step=0.100000
2017/08/28 11:11:07 step 4: mse=111.240221 step=0.100000
2017/08/28 11:11:08 step 5: mse=109.878847 step=0.100000
2017/08/28 11:11:08 step 6: mse=109.504935 step=0.100000
2017/08/28 11:11:09 step 7: mse=109.199453 step=0.100000
2017/08/28 11:11:09 Saving...
2017/08/28 11:11:09 Gathering batch of experience...
2017/08/28 11:12:19 batch 117: mean=26.319444 stddev=24.381987 entropy=0.715175 frames=4224 count=144
2017/08/28 11:12:19 Training policy...
2017/08/28 11:12:22 step 0: objective=1.351254
2017/08/28 11:12:23 step 1: objective=1.3690811
2017/08/28 11:12:23 step 2: objective=1.3825662
2017/08/28 11:12:24 step 3: objective=1.3942323
2017/08/28 11:12:25 step 4: objective=1.4006059
2017/08/28 11:12:26 step 5: objective=1.4141165
2017/08/28 11:12:27 step 6: objective=1.4206448
2017/08/28 11:12:28 step 7: objective=1.428953
2017/08/28 11:12:28 Training value function...
2017/08/28 11:12:29 step 0: mse=121.089627 step=0.100000
2017/08/28 11:12:30 step 1: mse=119.022427 step=0.100000
2017/08/28 11:12:31 step 2: mse=117.172814 step=0.100000
2017/08/28 11:12:32 step 3: mse=115.763303 step=0.100000
2017/08/28 11:12:33 step 4: mse=114.495348 step=0.100000
2017/08/28 11:12:33 step 5: mse=113.188417 step=0.100000
2017/08/28 11:12:34 step 6: mse=111.878892 step=0.100000
2017/08/28 11:12:35 step 7: mse=110.543797 step=0.100000
2017/08/28 11:12:35 Saving...
2017/08/28 11:12:35 Gathering batch of experience...
2017/08/28 11:13:48 batch 118: mean=22.426752 stddev=21.316602 entropy=0.726453 frames=4328 count=157
2017/08/28 11:13:48 Training policy...
2017/08/28 11:13:51 step 0: objective=0.0073558465
2017/08/28 11:13:52 step 1: objective=0.01744003
2017/08/28 11:13:52 step 2: objective=0.031115431
2017/08/28 11:13:53 step 3: objective=0.0451183
2017/08/28 11:13:54 step 4: objective=0.053808484
2017/08/28 11:13:55 step 5: objective=0.062180616
2017/08/28 11:13:56 step 6: objective=0.069339044
2017/08/28 11:13:57 step 7: objective=0.07687163
2017/08/28 11:13:57 Training value function...
2017/08/28 11:13:59 step 0: mse=103.269264 step=0.100000
2017/08/28 11:13:59 step 1: mse=102.832643 step=0.100000
2017/08/28 11:14:00 step 2: mse=102.081894 step=0.100000
2017/08/28 11:14:01 step 3: mse=101.739738 step=0.100000
2017/08/28 11:14:02 step 4: mse=101.398285 step=0.100000
2017/08/28 11:14:03 step 5: mse=100.634420 step=0.100000
2017/08/28 11:14:04 step 6: mse=100.447196 step=0.100000
2017/08/28 11:14:05 step 7: mse=99.773151 step=0.100000
2017/08/28 11:14:05 Saving...
2017/08/28 11:14:05 Gathering batch of experience...
2017/08/28 11:15:17 batch 119: mean=25.551282 stddev=21.875608 entropy=0.726191 frames=4406 count=156
2017/08/28 11:15:17 Training policy...
2017/08/28 11:15:20 step 0: objective=1.2079915
2017/08/28 11:15:21 step 1: objective=1.2204106
2017/08/28 11:15:22 step 2: objective=1.2321483
2017/08/28 11:15:22 step 3: objective=1.2391424
2017/08/28 11:15:23 step 4: objective=1.2449667
2017/08/28 11:15:24 step 5: objective=1.251613
2017/08/28 11:15:25 step 6: objective=1.2585047
2017/08/28 11:15:26 step 7: objective=1.2659279
2017/08/28 11:15:26 Training value function...
2017/08/28 11:15:28 step 0: mse=115.657344 step=0.100000
2017/08/28 11:15:29 step 1: mse=114.206284 step=0.100000
2017/08/28 11:15:30 step 2: mse=112.450827 step=0.100000
2017/08/28 11:15:30 step 3: mse=111.476934 step=0.100000
2017/08/28 11:15:31 step 4: mse=110.134959 step=0.100000
2017/08/28 11:15:32 step 5: mse=109.068061 step=0.100000
2017/08/28 11:15:33 step 6: mse=107.890189 step=0.100000
2017/08/28 11:15:34 step 7: mse=106.635751 step=0.100000
2017/08/28 11:15:34 Saving...
2017/08/28 11:15:34 Gathering batch of experience...
2017/08/28 11:16:43 batch 120: mean=24.531469 stddev=24.838444 entropy=0.719279 frames=4438 count=143
2017/08/28 11:16:43 Training policy...
2017/08/28 11:16:46 step 0: objective=0.30060047
2017/08/28 11:16:47 step 1: objective=0.3077551
2017/08/28 11:16:48 step 2: objective=0.31993437
2017/08/28 11:16:49 step 3: objective=0.33192453
2017/08/28 11:16:50 step 4: objective=0.34290117
2017/08/28 11:16:51 step 5: objective=0.35224903
2017/08/28 11:16:51 step 6: objective=0.36342236
2017/08/28 11:16:52 step 7: objective=0.37047735
2017/08/28 11:16:52 Training value function...
2017/08/28 11:16:54 step 0: mse=103.037084 step=0.100000
2017/08/28 11:16:55 step 1: mse=101.322885 step=0.100000
2017/08/28 11:16:56 step 2: mse=99.971186 step=0.100000
2017/08/28 11:16:57 step 3: mse=98.885505 step=0.100000
2017/08/28 11:16:58 step 4: mse=97.835642 step=0.100000
2017/08/28 11:16:59 step 5: mse=96.891358 step=0.100000
2017/08/28 11:17:00 step 6: mse=96.071597 step=0.100000
2017/08/28 11:17:00 step 7: mse=95.394359 step=0.100000
2017/08/28 11:17:00 Saving...
2017/08/28 11:17:01 Gathering batch of experience...
2017/08/28 11:18:13 batch 121: mean=27.361842 stddev=27.199930 entropy=0.713429 frames=4428 count=152
2017/08/28 11:18:13 Training policy...
2017/08/28 11:18:15 step 0: objective=1.6332586
2017/08/28 11:18:16 step 1: objective=1.646444
2017/08/28 11:18:17 step 2: objective=1.6646663
2017/08/28 11:18:18 step 3: objective=1.6756053
2017/08/28 11:18:19 step 4: objective=1.6906638
2017/08/28 11:18:20 step 5: objective=1.7053497
2017/08/28 11:18:21 step 6: objective=1.7153034
2017/08/28 11:18:22 step 7: objective=1.7211487
2017/08/28 11:18:22 Training value function...
2017/08/28 11:18:24 step 0: mse=156.172840 step=0.100000
2017/08/28 11:18:24 step 1: mse=153.723661 step=0.100000
2017/08/28 11:18:25 step 2: mse=151.419174 step=0.100000
2017/08/28 11:18:26 step 3: mse=149.582234 step=0.100000
2017/08/28 11:18:27 step 4: mse=148.144542 step=0.100000
2017/08/28 11:18:28 step 5: mse=146.485190 step=0.100000
2017/08/28 11:18:29 step 6: mse=144.669663 step=0.100000
2017/08/28 11:18:30 step 7: mse=142.996801 step=0.100000
2017/08/28 11:18:30 Saving...
2017/08/28 11:18:30 Gathering batch of experience...
2017/08/28 11:19:39 batch 122: mean=26.244755 stddev=25.571295 entropy=0.713150 frames=4382 count=143
2017/08/28 11:19:39 Training policy...
2017/08/28 11:19:41 step 0: objective=0.80662644
2017/08/28 11:19:42 step 1: objective=0.82281995
2017/08/28 11:19:43 step 2: objective=0.8332774
2017/08/28 11:19:44 step 3: objective=0.8471384
2017/08/28 11:19:45 step 4: objective=0.8586248
2017/08/28 11:19:46 step 5: objective=0.8652988
2017/08/28 11:19:47 step 6: objective=0.8789331
2017/08/28 11:19:48 step 7: objective=0.88596547
2017/08/28 11:19:48 Training value function...
2017/08/28 11:19:49 step 0: mse=113.580715 step=0.100000
2017/08/28 11:19:50 step 1: mse=112.666202 step=0.100000
2017/08/28 11:19:51 step 2: mse=111.676715 step=0.100000
2017/08/28 11:19:52 step 3: mse=110.721561 step=0.100000
2017/08/28 11:19:53 step 4: mse=109.776763 step=0.100000
2017/08/28 11:19:54 step 5: mse=109.124286 step=0.100000
2017/08/28 11:19:55 step 6: mse=108.524805 step=0.100000
2017/08/28 11:19:55 step 7: mse=108.113637 step=0.100000
2017/08/28 11:19:55 Saving...
2017/08/28 11:19:55 Gathering batch of experience...
2017/08/28 11:21:09 batch 123: mean=24.905063 stddev=23.556232 entropy=0.705770 frames=4357 count=158
2017/08/28 11:21:09 Training policy...
2017/08/28 11:21:11 step 0: objective=0.56729347
2017/08/28 11:21:12 step 1: objective=0.5832315
2017/08/28 11:21:13 step 2: objective=0.6011474
2017/08/28 11:21:14 step 3: objective=0.6154422
2017/08/28 11:21:15 step 4: objective=0.6332479
2017/08/28 11:21:16 step 5: objective=0.6441996
2017/08/28 11:21:17 step 6: objective=0.6524966
2017/08/28 11:21:18 step 7: objective=0.66120744
2017/08/28 11:21:18 Training value function...
2017/08/28 11:21:19 step 0: mse=120.538632 step=0.100000
2017/08/28 11:21:20 step 1: mse=119.791337 step=0.100000
2017/08/28 11:21:21 step 2: mse=119.116004 step=0.100000
2017/08/28 11:21:22 step 3: mse=118.377408 step=0.100000
2017/08/28 11:21:23 step 4: mse=117.755267 step=0.100000
2017/08/28 11:21:24 step 5: mse=117.035843 step=0.100000
2017/08/28 11:21:24 step 6: mse=115.958161 step=0.100000
2017/08/28 11:21:25 step 7: mse=115.336049 step=0.100000
2017/08/28 11:21:25 Saving...
2017/08/28 11:21:25 Gathering batch of experience...
2017/08/28 11:22:38 batch 124: mean=25.392157 stddev=29.320460 entropy=0.697710 frames=4428 count=153
2017/08/28 11:22:38 Training policy...
2017/08/28 11:22:41 step 0: objective=0.9139442
2017/08/28 11:22:42 step 1: objective=0.9306041
2017/08/28 11:22:43 step 2: objective=0.9374141
2017/08/28 11:22:44 step 3: objective=0.9501839
2017/08/28 11:22:45 step 4: objective=0.95767236
2017/08/28 11:22:45 step 5: objective=0.967582
2017/08/28 11:22:46 step 6: objective=0.977417
2017/08/28 11:22:47 step 7: objective=0.98196304
2017/08/28 11:22:47 Training value function...
2017/08/28 11:22:49 step 0: mse=145.477910 step=0.100000
2017/08/28 11:22:50 step 1: mse=142.181130 step=0.100000
2017/08/28 11:22:51 step 2: mse=140.009262 step=0.100000
2017/08/28 11:22:52 step 3: mse=137.641526 step=0.100000
2017/08/28 11:22:53 step 4: mse=135.310667 step=0.100000
2017/08/28 11:22:54 step 5: mse=133.505535 step=0.100000
2017/08/28 11:22:54 step 6: mse=131.711848 step=0.100000
2017/08/28 11:22:55 step 7: mse=130.160130 step=0.100000
2017/08/28 11:22:55 Saving...
2017/08/28 11:22:55 Gathering batch of experience...
2017/08/28 11:24:04 batch 125: mean=26.850340 stddev=27.357386 entropy=0.688050 frames=4330 count=147
2017/08/28 11:24:04 Training policy...
2017/08/28 11:24:07 step 0: objective=1.027321
2017/08/28 11:24:08 step 1: objective=1.0406544
2017/08/28 11:24:09 step 2: objective=1.0505155
2017/08/28 11:24:10 step 3: objective=1.0659232
2017/08/28 11:24:11 step 4: objective=1.0742236
2017/08/28 11:24:12 step 5: objective=1.0852476
2017/08/28 11:24:13 step 6: objective=1.0921701
2017/08/28 11:24:13 step 7: objective=1.1031802
2017/08/28 11:24:13 Training value function...
2017/08/28 11:24:15 step 0: mse=148.895079 step=0.100000
2017/08/28 11:24:16 step 1: mse=147.291562 step=0.100000
2017/08/28 11:24:17 step 2: mse=146.008154 step=0.100000
2017/08/28 11:24:18 step 3: mse=144.356561 step=0.100000
2017/08/28 11:24:19 step 4: mse=143.273857 step=0.100000
2017/08/28 11:24:19 step 5: mse=141.639821 step=0.100000
2017/08/28 11:24:20 step 6: mse=140.366322 step=0.100000
2017/08/28 11:24:21 step 7: mse=139.565427 step=0.100000
2017/08/28 11:24:21 Saving...
2017/08/28 11:24:21 Gathering batch of experience...
2017/08/28 11:25:25 batch 126: mean=31.255814 stddev=25.142780 entropy=0.701270 frames=4405 count=129
2017/08/28 11:25:25 Training policy...
2017/08/28 11:25:28 step 0: objective=1.5459865
2017/08/28 11:25:29 step 1: objective=1.5596834
2017/08/28 11:25:29 step 2: objective=1.5683738
2017/08/28 11:25:30 step 3: objective=1.5784116
2017/08/28 11:25:31 step 4: objective=1.586271
2017/08/28 11:25:32 step 5: objective=1.593165
2017/08/28 11:25:33 step 6: objective=1.6010365
2017/08/28 11:25:34 step 7: objective=1.6059393
2017/08/28 11:25:34 Training value function...
2017/08/28 11:25:36 step 0: mse=113.501728 step=0.100000
2017/08/28 11:25:37 step 1: mse=111.954418 step=0.100000
2017/08/28 11:25:38 step 2: mse=110.449924 step=0.100000
2017/08/28 11:25:38 step 3: mse=109.357075 step=0.100000
2017/08/28 11:25:39 step 4: mse=108.185470 step=0.100000
2017/08/28 11:25:40 step 5: mse=107.180842 step=0.100000
2017/08/28 11:25:41 step 6: mse=106.519215 step=0.100000
2017/08/28 11:25:42 step 7: mse=105.392417 step=0.100000
2017/08/28 11:25:42 Saving...
2017/08/28 11:25:42 Gathering batch of experience...
2017/08/28 11:26:51 batch 127: mean=28.543478 stddev=32.713761 entropy=0.695574 frames=4450 count=138
2017/08/28 11:26:51 Training policy...
2017/08/28 11:26:54 step 0: objective=0.57243186
2017/08/28 11:26:54 step 1: objective=0.5843627
2017/08/28 11:26:55 step 2: objective=0.59407747
2017/08/28 11:26:56 step 3: objective=0.6043259
2017/08/28 11:26:57 step 4: objective=0.6150522
2017/08/28 11:26:58 step 5: objective=0.6215036
2017/08/28 11:26:59 step 6: objective=0.62687564
2017/08/28 11:27:00 step 7: objective=0.64129794
2017/08/28 11:27:00 Training value function...
2017/08/28 11:27:02 step 0: mse=128.723190 step=0.100000
2017/08/28 11:27:03 step 1: mse=125.447127 step=0.100000
2017/08/28 11:27:04 step 2: mse=122.496799 step=0.100000
2017/08/28 11:27:05 step 3: mse=120.009779 step=0.100000
2017/08/28 11:27:05 step 4: mse=118.278292 step=0.100000
2017/08/28 11:27:06 step 5: mse=116.201901 step=0.100000
2017/08/28 11:27:07 step 6: mse=114.823872 step=0.100000
2017/08/28 11:27:08 step 7: mse=113.539961 step=0.100000
2017/08/28 11:27:08 Saving...
2017/08/28 11:27:08 Gathering batch of experience...
2017/08/28 11:28:18 batch 128: mean=26.993197 stddev=25.461855 entropy=0.692830 frames=4302 count=147
2017/08/28 11:28:18 Training policy...
2017/08/28 11:28:21 step 0: objective=0.75610465
2017/08/28 11:28:22 step 1: objective=0.7728873
2017/08/28 11:28:22 step 2: objective=0.78593796
2017/08/28 11:28:23 step 3: objective=0.79940605
2017/08/28 11:28:24 step 4: objective=0.8103807
2017/08/28 11:28:25 step 5: objective=0.8181346
2017/08/28 11:28:26 step 6: objective=0.8233902
2017/08/28 11:28:27 step 7: objective=0.833477
2017/08/28 11:28:27 Training value function...
2017/08/28 11:28:29 step 0: mse=133.528113 step=0.100000
2017/08/28 11:28:29 step 1: mse=131.940715 step=0.100000
2017/08/28 11:28:30 step 2: mse=130.588172 step=0.100000
2017/08/28 11:28:31 step 3: mse=129.579148 step=0.100000
2017/08/28 11:28:32 step 4: mse=128.853968 step=0.100000
2017/08/28 11:28:33 step 5: mse=128.092866 step=0.100000
2017/08/28 11:28:34 step 6: mse=127.098222 step=0.100000
2017/08/28 11:28:35 step 7: mse=125.990328 step=0.100000
2017/08/28 11:28:35 Saving...
2017/08/28 11:28:35 Gathering batch of experience...
2017/08/28 11:29:39 batch 129: mean=30.914729 stddev=32.515955 entropy=0.687129 frames=4345 count=129
2017/08/28 11:29:39 Training policy...
2017/08/28 11:29:41 step 0: objective=1.3881222
2017/08/28 11:29:42 step 1: objective=1.4008081
2017/08/28 11:29:43 step 2: objective=1.4128721
2017/08/28 11:29:44 step 3: objective=1.4225742
2017/08/28 11:29:45 step 4: objective=1.4309764
2017/08/28 11:29:46 step 5: objective=1.4419955
2017/08/28 11:29:47 step 6: objective=1.449814
2017/08/28 11:29:48 step 7: objective=1.460517
2017/08/28 11:29:48 Training value function...
2017/08/28 11:29:49 step 0: mse=162.951689 step=0.100000
2017/08/28 11:29:50 step 1: mse=160.567194 step=0.100000
2017/08/28 11:29:51 step 2: mse=158.780423 step=0.100000
2017/08/28 11:29:52 step 3: mse=156.808379 step=0.100000
2017/08/28 11:29:53 step 4: mse=154.788250 step=0.100000
2017/08/28 11:29:54 step 5: mse=153.145715 step=0.100000
2017/08/28 11:29:55 step 6: mse=151.311171 step=0.100000
2017/08/28 11:29:56 step 7: mse=149.787634 step=0.100000
2017/08/28 11:29:56 Saving...
2017/08/28 11:29:56 Gathering batch of experience...
2017/08/28 11:31:01 batch 130: mean=27.902256 stddev=24.023129 entropy=0.689355 frames=4247 count=133
2017/08/28 11:31:01 Training policy...
2017/08/28 11:31:04 step 0: objective=0.19912203
2017/08/28 11:31:05 step 1: objective=0.21720868
2017/08/28 11:31:05 step 2: objective=0.23304544
2017/08/28 11:31:06 step 3: objective=0.24587761
2017/08/28 11:31:07 step 4: objective=0.25870755
2017/08/28 11:31:08 step 5: objective=0.27264637
2017/08/28 11:31:09 step 6: objective=0.2804418
2017/08/28 11:31:10 step 7: objective=0.28670362
2017/08/28 11:31:10 Training value function...
2017/08/28 11:31:12 step 0: mse=108.674355 step=0.100000
2017/08/28 11:31:12 step 1: mse=107.582112 step=0.100000
2017/08/28 11:31:13 step 2: mse=106.439996 step=0.100000
2017/08/28 11:31:14 step 3: mse=105.190086 step=0.100000
2017/08/28 11:31:15 step 4: mse=104.482260 step=0.100000
2017/08/28 11:31:16 step 5: mse=103.693776 step=0.100000
2017/08/28 11:31:17 step 6: mse=103.267509 step=0.100000
2017/08/28 11:31:17 step 7: mse=102.460003 step=0.100000
2017/08/28 11:31:17 Saving...
2017/08/28 11:31:18 Gathering batch of experience...
2017/08/28 11:32:24 batch 131: mean=29.277372 stddev=25.832625 entropy=0.678218 frames=4364 count=137
2017/08/28 11:32:24 Training policy...
2017/08/28 11:32:27 step 0: objective=0.9840162
2017/08/28 11:32:28 step 1: objective=1.0025659
2017/08/28 11:32:29 step 2: objective=1.0173886
2017/08/28 11:32:30 step 3: objective=1.0285448
2017/08/28 11:32:31 step 4: objective=1.0359306
2017/08/28 11:32:32 step 5: objective=1.0458257
2017/08/28 11:32:33 step 6: objective=1.054036
2017/08/28 11:32:33 step 7: objective=1.0660326
2017/08/28 11:32:33 Training value function...
2017/08/28 11:32:35 step 0: mse=124.755477 step=0.100000
2017/08/28 11:32:36 step 1: mse=123.653877 step=0.100000
2017/08/28 11:32:37 step 2: mse=122.705089 step=0.100000
2017/08/28 11:32:38 step 3: mse=121.872466 step=0.100000
2017/08/28 11:32:39 step 4: mse=120.656978 step=0.100000
2017/08/28 11:32:40 step 5: mse=120.071075 step=0.100000
2017/08/28 11:32:41 step 6: mse=119.647309 step=0.100000
2017/08/28 11:32:41 step 7: mse=118.624049 step=0.100000
2017/08/28 11:32:41 Saving...
2017/08/28 11:32:41 Gathering batch of experience...
2017/08/28 11:33:46 batch 132: mean=30.751938 stddev=33.241664 entropy=0.678397 frames=4419 count=129
2017/08/28 11:33:46 Training policy...
2017/08/28 11:33:49 step 0: objective=1.4073026
2017/08/28 11:33:50 step 1: objective=1.4167541
2017/08/28 11:33:51 step 2: objective=1.4358969
2017/08/28 11:33:51 step 3: objective=1.450894
2017/08/28 11:33:52 step 4: objective=1.4617199
2017/08/28 11:33:53 step 5: objective=1.4716064
2017/08/28 11:33:54 step 6: objective=1.4808295
2017/08/28 11:33:55 step 7: objective=1.4903228
2017/08/28 11:33:55 Training value function...
2017/08/28 11:33:57 step 0: mse=162.913061 step=0.100000
2017/08/28 11:33:58 step 1: mse=160.109547 step=0.100000
2017/08/28 11:33:59 step 2: mse=157.641181 step=0.100000
2017/08/28 11:34:00 step 3: mse=155.071436 step=0.100000
2017/08/28 11:34:00 step 4: mse=152.863051 step=0.100000
2017/08/28 11:34:01 step 5: mse=151.226442 step=0.100000
2017/08/28 11:34:02 step 6: mse=149.446070 step=0.100000
2017/08/28 11:34:03 step 7: mse=147.868470 step=0.100000
2017/08/28 11:34:03 Saving...
2017/08/28 11:34:03 Gathering batch of experience...
2017/08/28 11:35:10 batch 133: mean=28.420290 stddev=28.536986 entropy=0.682425 frames=4307 count=138
2017/08/28 11:35:10 Training policy...
2017/08/28 11:35:13 step 0: objective=0.45395935
2017/08/28 11:35:14 step 1: objective=0.46156386
2017/08/28 11:35:15 step 2: objective=0.4733645
2017/08/28 11:35:15 step 3: objective=0.4856583
2017/08/28 11:35:16 step 4: objective=0.49446616
2017/08/28 11:35:17 step 5: objective=0.50800914
2017/08/28 11:35:18 step 6: objective=0.52045894
2017/08/28 11:35:19 step 7: objective=0.53098303
2017/08/28 11:35:19 Training value function...
2017/08/28 11:35:21 step 0: mse=128.317228 step=0.100000
2017/08/28 11:35:22 step 1: mse=126.532492 step=0.100000
2017/08/28 11:35:22 step 2: mse=125.114930 step=0.100000
2017/08/28 11:35:23 step 3: mse=123.535289 step=0.100000
2017/08/28 11:35:24 step 4: mse=122.935865 step=0.100000
2017/08/28 11:35:25 step 5: mse=121.776539 step=0.100000
2017/08/28 11:35:26 step 6: mse=120.327974 step=0.100000
2017/08/28 11:35:27 step 7: mse=119.773279 step=0.100000
2017/08/28 11:35:27 Saving...
2017/08/28 11:35:27 Gathering batch of experience...
2017/08/28 11:36:33 batch 134: mean=28.865672 stddev=25.245893 entropy=0.672235 frames=4254 count=134
2017/08/28 11:36:33 Training policy...
2017/08/28 11:36:36 step 0: objective=0.6752134
2017/08/28 11:36:36 step 1: objective=0.6930635
2017/08/28 11:36:37 step 2: objective=0.71619016
2017/08/28 11:36:38 step 3: objective=0.727907
2017/08/28 11:36:39 step 4: objective=0.739923
2017/08/28 11:36:40 step 5: objective=0.75228304
2017/08/28 11:36:41 step 6: objective=0.7603432
2017/08/28 11:36:42 step 7: objective=0.76669353
2017/08/28 11:36:42 Training value function...
2017/08/28 11:36:43 step 0: mse=123.945826 step=0.100000
2017/08/28 11:36:44 step 1: mse=122.648587 step=0.100000
2017/08/28 11:36:45 step 2: mse=121.577958 step=0.100000
2017/08/28 11:36:46 step 3: mse=120.615638 step=0.100000
2017/08/28 11:36:47 step 4: mse=119.493729 step=0.100000
2017/08/28 11:36:48 step 5: mse=118.406131 step=0.100000
2017/08/28 11:36:48 step 6: mse=117.614116 step=0.100000
2017/08/28 11:36:49 step 7: mse=116.799123 step=0.100000
2017/08/28 11:36:49 Saving...
2017/08/28 11:36:49 Gathering batch of experience...
2017/08/28 11:37:56 batch 135: mean=29.920290 stddev=30.777382 entropy=0.678787 frames=4358 count=138
2017/08/28 11:37:56 Training policy...
2017/08/28 11:37:59 step 0: objective=1.0185095
2017/08/28 11:38:00 step 1: objective=1.0321683
2017/08/28 11:38:01 step 2: objective=1.0521742
2017/08/28 11:38:02 step 3: objective=1.0610687
2017/08/28 11:38:02 step 4: objective=1.0731537
2017/08/28 11:38:03 step 5: objective=1.0847387
2017/08/28 11:38:04 step 6: objective=1.0923896
2017/08/28 11:38:05 step 7: objective=1.0998827
2017/08/28 11:38:05 Training value function...
2017/08/28 11:38:07 step 0: mse=151.653675 step=0.100000
2017/08/28 11:38:08 step 1: mse=150.504439 step=0.100000
2017/08/28 11:38:09 step 2: mse=149.576750 step=0.100000
2017/08/28 11:38:10 step 3: mse=148.267854 step=0.100000
2017/08/28 11:38:10 step 4: mse=147.344716 step=0.100000
2017/08/28 11:38:11 step 5: mse=146.249920 step=0.100000
2017/08/28 11:38:12 step 6: mse=145.235366 step=0.100000
2017/08/28 11:38:13 step 7: mse=144.078740 step=0.100000
2017/08/28 11:38:13 Saving...
2017/08/28 11:38:13 Gathering batch of experience...
2017/08/28 11:39:24 batch 136: mean=26.898649 stddev=25.040707 entropy=0.672598 frames=4344 count=148
2017/08/28 11:39:24 Training policy...
2017/08/28 11:39:27 step 0: objective=0.07424962
2017/08/28 11:39:28 step 1: objective=0.08782363
2017/08/28 11:39:29 step 2: objective=0.099281654
2017/08/28 11:39:30 step 3: objective=0.10572453
2017/08/28 11:39:31 step 4: objective=0.117823265
2017/08/28 11:39:31 step 5: objective=0.12751116
2017/08/28 11:39:32 step 6: objective=0.13723762
2017/08/28 11:39:33 step 7: objective=0.1495771
2017/08/28 11:39:33 Training value function...
2017/08/28 11:39:35 step 0: mse=123.689152 step=0.100000
2017/08/28 11:39:36 step 1: mse=122.140232 step=0.100000
2017/08/28 11:39:37 step 2: mse=121.016205 step=0.100000
2017/08/28 11:39:38 step 3: mse=120.050699 step=0.100000
2017/08/28 11:39:38 step 4: mse=119.555902 step=0.100000
2017/08/28 11:39:39 step 5: mse=118.689198 step=0.100000
2017/08/28 11:39:40 step 6: mse=117.876294 step=0.100000
2017/08/28 11:39:41 step 7: mse=117.211605 step=0.100000
2017/08/28 11:39:41 Saving...
2017/08/28 11:39:41 Gathering batch of experience...
2017/08/28 11:40:46 batch 137: mean=32.908397 stddev=30.425093 entropy=0.671401 frames=4572 count=131
2017/08/28 11:40:46 Training policy...
2017/08/28 11:40:49 step 0: objective=1.8130903
2017/08/28 11:40:50 step 1: objective=1.821531
2017/08/28 11:40:51 step 2: objective=1.829837
2017/08/28 11:40:52 step 3: objective=1.839666
2017/08/28 11:40:52 step 4: objective=1.8523135
2017/08/28 11:40:53 step 5: objective=1.8667861
2017/08/28 11:40:54 step 6: objective=1.8729044
2017/08/28 11:40:55 step 7: objective=1.8868628
2017/08/28 11:40:55 Training value function...
2017/08/28 11:40:57 step 0: mse=142.354099 step=0.100000
2017/08/28 11:40:58 step 1: mse=140.072776 step=0.100000
2017/08/28 11:40:59 step 2: mse=137.771840 step=0.100000
2017/08/28 11:41:00 step 3: mse=136.016839 step=0.100000
2017/08/28 11:41:01 step 4: mse=133.968432 step=0.100000
2017/08/28 11:41:02 step 5: mse=132.495793 step=0.100000
2017/08/28 11:41:03 step 6: mse=130.965927 step=0.100000
2017/08/28 11:41:04 step 7: mse=129.625417 step=0.100000
2017/08/28 11:41:04 Saving...
2017/08/28 11:41:04 Gathering batch of experience...
2017/08/28 11:42:09 batch 138: mean=28.492537 stddev=24.416396 entropy=0.670662 frames=4308 count=134
2017/08/28 11:42:09 Training policy...
2017/08/28 11:42:12 step 0: objective=-0.052224033
2017/08/28 11:42:12 step 1: objective=-0.040827166
2017/08/28 11:42:13 step 2: objective=-0.02609037
2017/08/28 11:42:14 step 3: objective=-0.017389001
2017/08/28 11:42:15 step 4: objective=-0.004230302
2017/08/28 11:42:16 step 5: objective=0.0031227234
2017/08/28 11:42:17 step 6: objective=0.01061616
2017/08/28 11:42:18 step 7: objective=0.021160066
2017/08/28 11:42:18 Training value function...
2017/08/28 11:42:19 step 0: mse=111.476420 step=0.100000
2017/08/28 11:42:20 step 1: mse=109.785288 step=0.100000
2017/08/28 11:42:21 step 2: mse=108.146680 step=0.100000
2017/08/28 11:42:22 step 3: mse=107.155713 step=0.100000
2017/08/28 11:42:23 step 4: mse=106.053677 step=0.100000
2017/08/28 11:42:24 step 5: mse=104.961309 step=0.100000
2017/08/28 11:42:25 step 6: mse=104.115841 step=0.100000
2017/08/28 11:42:25 step 7: mse=103.407902 step=0.100000
2017/08/28 11:42:25 Saving...
2017/08/28 11:42:25 Gathering batch of experience...
2017/08/28 11:43:31 batch 139: mean=30.715385 stddev=25.096808 entropy=0.672008 frames=4411 count=130
2017/08/28 11:43:31 Training policy...
2017/08/28 11:43:33 step 0: objective=0.81767803
2017/08/28 11:43:34 step 1: objective=0.82554317
2017/08/28 11:43:35 step 2: objective=0.83451396
2017/08/28 11:43:36 step 3: objective=0.8470961
2017/08/28 11:43:37 step 4: objective=0.85680103
2017/08/28 11:43:38 step 5: objective=0.8677277
2017/08/28 11:43:39 step 6: objective=0.8793015
2017/08/28 11:43:40 step 7: objective=0.8856517
2017/08/28 11:43:40 Training value function...
2017/08/28 11:43:42 step 0: mse=114.157239 step=0.100000
2017/08/28 11:43:42 step 1: mse=113.086630 step=0.100000
2017/08/28 11:43:43 step 2: mse=112.661084 step=0.100000
2017/08/28 11:43:44 step 3: mse=111.945471 step=0.100000
2017/08/28 11:43:45 step 4: mse=111.336401 step=0.100000
2017/08/28 11:43:46 step 5: mse=110.539981 step=0.100000
2017/08/28 11:43:47 step 6: mse=109.973303 step=0.100000
2017/08/28 11:43:48 step 7: mse=109.575666 step=0.100000
2017/08/28 11:43:48 Saving...
2017/08/28 11:43:48 Gathering batch of experience...
2017/08/28 11:44:54 batch 140: mean=31.223077 stddev=32.463297 entropy=0.670821 frames=4559 count=130
2017/08/28 11:44:54 Training policy...
2017/08/28 11:44:57 step 0: objective=1.2347518
2017/08/28 11:44:58 step 1: objective=1.2446257
2017/08/28 11:44:59 step 2: objective=1.259789
2017/08/28 11:45:00 step 3: objective=1.2713498
2017/08/28 11:45:01 step 4: objective=1.2839503
2017/08/28 11:45:02 step 5: objective=1.2906097
2017/08/28 11:45:03 step 6: objective=1.2955488
2017/08/28 11:45:03 step 7: objective=1.3055733
2017/08/28 11:45:03 Training value function...
2017/08/28 11:45:05 step 0: mse=151.804583 step=0.100000
2017/08/28 11:45:06 step 1: mse=148.788592 step=0.100000
2017/08/28 11:45:07 step 2: mse=145.887557 step=0.100000
2017/08/28 11:45:08 step 3: mse=143.121919 step=0.100000
2017/08/28 11:45:09 step 4: mse=141.352660 step=0.100000
2017/08/28 11:45:10 step 5: mse=139.486344 step=0.100000
2017/08/28 11:45:11 step 6: mse=137.633659 step=0.100000
2017/08/28 11:45:12 step 7: mse=136.363738 step=0.100000
2017/08/28 11:45:12 Saving...
2017/08/28 11:45:12 Gathering batch of experience...
2017/08/28 11:46:14 batch 141: mean=31.549180 stddev=32.666748 entropy=0.672825 frames=4353 count=122
2017/08/28 11:46:14 Training policy...
2017/08/28 11:46:16 step 0: objective=0.9826998
2017/08/28 11:46:17 step 1: objective=0.9942086
2017/08/28 11:46:18 step 2: objective=1.0052972
2017/08/28 11:46:19 step 3: objective=1.0124325
2017/08/28 11:46:20 step 4: objective=1.0238392
2017/08/28 11:46:21 step 5: objective=1.032299
2017/08/28 11:46:22 step 6: objective=1.0426188
2017/08/28 11:46:23 step 7: objective=1.0519811
2017/08/28 11:46:23 Training value function...
2017/08/28 11:46:25 step 0: mse=134.630284 step=0.100000
2017/08/28 11:46:25 step 1: mse=133.284189 step=0.100000
2017/08/28 11:46:26 step 2: mse=131.873016 step=0.100000
2017/08/28 11:46:27 step 3: mse=130.546087 step=0.100000
2017/08/28 11:46:28 step 4: mse=129.322809 step=0.100000
2017/08/28 11:46:29 step 5: mse=128.305138 step=0.100000
2017/08/28 11:46:30 step 6: mse=127.150743 step=0.100000
2017/08/28 11:46:31 step 7: mse=126.414962 step=0.100000
2017/08/28 11:46:31 Saving...
2017/08/28 11:46:31 Gathering batch of experience...
2017/08/28 11:47:35 batch 142: mean=30.480620 stddev=28.595576 entropy=0.675865 frames=4439 count=129
2017/08/28 11:47:35 Training policy...
2017/08/28 11:47:38 step 0: objective=0.7003962
2017/08/28 11:47:39 step 1: objective=0.71188015
2017/08/28 11:47:40 step 2: objective=0.7207777
2017/08/28 11:47:41 step 3: objective=0.7352536
2017/08/28 11:47:42 step 4: objective=0.7452362
2017/08/28 11:47:43 step 5: objective=0.75303394
2017/08/28 11:47:44 step 6: objective=0.7618223
2017/08/28 11:47:45 step 7: objective=0.7685975
2017/08/28 11:47:45 Training value function...
2017/08/28 11:47:46 step 0: mse=127.739339 step=0.100000
2017/08/28 11:47:47 step 1: mse=126.612623 step=0.100000
2017/08/28 11:47:48 step 2: mse=125.666780 step=0.100000
2017/08/28 11:47:49 step 3: mse=124.547199 step=0.100000
2017/08/28 11:47:50 step 4: mse=123.767157 step=0.100000
2017/08/28 11:47:51 step 5: mse=123.053850 step=0.100000
2017/08/28 11:47:52 step 6: mse=122.071482 step=0.100000
2017/08/28 11:47:53 step 7: mse=121.169483 step=0.100000
2017/08/28 11:47:53 Saving...
2017/08/28 11:47:53 Gathering batch of experience...
2017/08/28 11:48:53 batch 143: mean=37.112069 stddev=38.358736 entropy=0.668359 frames=4639 count=116
2017/08/28 11:48:53 Training policy...
2017/08/28 11:48:56 step 0: objective=1.7181095
2017/08/28 11:48:57 step 1: objective=1.731308
2017/08/28 11:48:58 step 2: objective=1.7459129
2017/08/28 11:48:59 step 3: objective=1.7567618
2017/08/28 11:49:00 step 4: objective=1.7666559
2017/08/28 11:49:01 step 5: objective=1.7806627
2017/08/28 11:49:02 step 6: objective=1.7908211
2017/08/28 11:49:03 step 7: objective=1.7953899
2017/08/28 11:49:03 Training value function...
2017/08/28 11:49:05 step 0: mse=170.168100 step=0.100000
2017/08/28 11:49:06 step 1: mse=165.623695 step=0.100000
2017/08/28 11:49:07 step 2: mse=162.078874 step=0.100000
2017/08/28 11:49:08 step 3: mse=158.496969 step=0.100000
2017/08/28 11:49:09 step 4: mse=155.208346 step=0.100000
2017/08/28 11:49:10 step 5: mse=152.376400 step=0.100000
2017/08/28 11:49:11 step 6: mse=150.190494 step=0.100000
2017/08/28 11:49:12 step 7: mse=148.243932 step=0.100000
2017/08/28 11:49:12 Saving...
2017/08/28 11:49:12 Gathering batch of experience...
2017/08/28 11:50:11 batch 144: mean=34.104348 stddev=31.204619 entropy=0.655781 frames=4245 count=115
2017/08/28 11:50:11 Training policy...
2017/08/28 11:50:13 step 0: objective=0.62900025
2017/08/28 11:50:14 step 1: objective=0.64206433
2017/08/28 11:50:15 step 2: objective=0.65223104
2017/08/28 11:50:16 step 3: objective=0.6648084
2017/08/28 11:50:17 step 4: objective=0.6769192
2017/08/28 11:50:18 step 5: objective=0.6928792
2017/08/28 11:50:19 step 6: objective=0.7004697
2017/08/28 11:50:20 step 7: objective=0.7069392
2017/08/28 11:50:20 Training value function...
2017/08/28 11:50:21 step 0: mse=136.380609 step=0.100000
2017/08/28 11:50:22 step 1: mse=134.134682 step=0.100000
2017/08/28 11:50:23 step 2: mse=132.346725 step=0.100000
2017/08/28 11:50:24 step 3: mse=130.815474 step=0.100000
2017/08/28 11:50:25 step 4: mse=129.511974 step=0.100000
2017/08/28 11:50:26 step 5: mse=128.933191 step=0.100000
2017/08/28 11:50:26 step 6: mse=127.984184 step=0.100000
2017/08/28 11:50:27 step 7: mse=127.302410 step=0.100000
2017/08/28 11:50:27 Saving...
2017/08/28 11:50:27 Gathering batch of experience...
2017/08/28 11:51:28 batch 145: mean=35.152542 stddev=34.469743 entropy=0.658371 frames=4396 count=118
2017/08/28 11:51:28 Training policy...
2017/08/28 11:51:31 step 0: objective=1.2032188
2017/08/28 11:51:32 step 1: objective=1.2184911
2017/08/28 11:51:32 step 2: objective=1.233635
2017/08/28 11:51:33 step 3: objective=1.2450042
2017/08/28 11:51:34 step 4: objective=1.2586231
2017/08/28 11:51:35 step 5: objective=1.2666523
2017/08/28 11:51:36 step 6: objective=1.2848275
2017/08/28 11:51:37 step 7: objective=1.2892523
2017/08/28 11:51:37 Training value function...
2017/08/28 11:51:39 step 0: mse=164.862899 step=0.100000
2017/08/28 11:51:40 step 1: mse=162.497588 step=0.100000
2017/08/28 11:51:41 step 2: mse=160.574803 step=0.100000
2017/08/28 11:51:42 step 3: mse=158.883044 step=0.100000
2017/08/28 11:51:42 step 4: mse=157.363271 step=0.100000
2017/08/28 11:51:43 step 5: mse=156.249204 step=0.100000
2017/08/28 11:51:44 step 6: mse=154.376503 step=0.100000
2017/08/28 11:51:45 step 7: mse=152.755344 step=0.100000
2017/08/28 11:51:45 Saving...
2017/08/28 11:51:45 Gathering batch of experience...
2017/08/28 11:52:51 batch 146: mean=29.082090 stddev=29.276359 entropy=0.660031 frames=4360 count=134
2017/08/28 11:52:51 Training policy...
2017/08/28 11:52:54 step 0: objective=-0.24170925
2017/08/28 11:52:55 step 1: objective=-0.22318769
2017/08/28 11:52:56 step 2: objective=-0.20751525
2017/08/28 11:52:57 step 3: objective=-0.19054402
2017/08/28 11:52:57 step 4: objective=-0.18239972
2017/08/28 11:52:58 step 5: objective=-0.17315684
2017/08/28 11:52:59 step 6: objective=-0.16253851
2017/08/28 11:53:00 step 7: objective=-0.15377058
2017/08/28 11:53:00 Training value function...
2017/08/28 11:53:02 step 0: mse=142.292738 step=0.100000
2017/08/28 11:53:03 step 1: mse=140.507285 step=0.100000
2017/08/28 11:53:04 step 2: mse=139.321851 step=0.100000
2017/08/28 11:53:05 step 3: mse=138.359471 step=0.100000
2017/08/28 11:53:05 step 4: mse=137.270849 step=0.100000
2017/08/28 11:53:06 step 5: mse=136.672555 step=0.100000
2017/08/28 11:53:07 step 6: mse=135.967847 step=0.100000
2017/08/28 11:53:08 step 7: mse=135.370861 step=0.100000
2017/08/28 11:53:08 Saving...
2017/08/28 11:53:08 Gathering batch of experience...
2017/08/28 11:54:05 batch 147: mean=40.150943 stddev=35.509178 entropy=0.661895 frames=4490 count=106
2017/08/28 11:54:05 Training policy...
2017/08/28 11:54:08 step 0: objective=1.8559623
2017/08/28 11:54:09 step 1: objective=1.8665502
2017/08/28 11:54:10 step 2: objective=1.8829072
2017/08/28 11:54:11 step 3: objective=1.8963549
2017/08/28 11:54:12 step 4: objective=1.9136249
2017/08/28 11:54:13 step 5: objective=1.9210755
2017/08/28 11:54:14 step 6: objective=1.9274534
2017/08/28 11:54:15 step 7: objective=1.9343743
2017/08/28 11:54:15 Training value function...
2017/08/28 11:54:17 step 0: mse=164.025310 step=0.100000
2017/08/28 11:54:18 step 1: mse=161.227785 step=0.100000
2017/08/28 11:54:18 step 2: mse=159.011337 step=0.100000
2017/08/28 11:54:19 step 3: mse=156.734213 step=0.100000
2017/08/28 11:54:20 step 4: mse=155.109620 step=0.100000
2017/08/28 11:54:21 step 5: mse=153.495434 step=0.100000
2017/08/28 11:54:22 step 6: mse=151.637287 step=0.100000
2017/08/28 11:54:23 step 7: mse=149.826615 step=0.100000
2017/08/28 11:54:23 Saving...
2017/08/28 11:54:23 Gathering batch of experience...
2017/08/28 11:55:26 batch 148: mean=31.889764 stddev=28.536543 entropy=0.654562 frames=4366 count=127
2017/08/28 11:55:26 Training policy...
2017/08/28 11:55:28 step 0: objective=0.26060206
2017/08/28 11:55:29 step 1: objective=0.27354917
2017/08/28 11:55:30 step 2: objective=0.28794634
2017/08/28 11:55:31 step 3: objective=0.29839376
2017/08/28 11:55:32 step 4: objective=0.3057671
2017/08/28 11:55:33 step 5: objective=0.3181169
2017/08/28 11:55:34 step 6: objective=0.32553354
2017/08/28 11:55:35 step 7: objective=0.3324643
2017/08/28 11:55:35 Training value function...
2017/08/28 11:55:36 step 0: mse=125.124516 step=0.100000
2017/08/28 11:55:37 step 1: mse=123.967749 step=0.100000
2017/08/28 11:55:38 step 2: mse=123.242812 step=0.100000
2017/08/28 11:55:39 step 3: mse=122.511734 step=0.100000
2017/08/28 11:55:40 step 4: mse=121.677886 step=0.100000
2017/08/28 11:55:41 step 5: mse=121.157305 step=0.100000
2017/08/28 11:55:42 step 6: mse=120.153277 step=0.100000
2017/08/28 11:55:43 step 7: mse=119.323492 step=0.100000
2017/08/28 11:55:43 Saving...
2017/08/28 11:55:43 Gathering batch of experience...
2017/08/28 11:56:49 batch 149: mean=29.022222 stddev=27.605546 entropy=0.648966 frames=4359 count=135
2017/08/28 11:56:49 Training policy...
2017/08/28 11:56:52 step 0: objective=-0.11392868
2017/08/28 11:56:53 step 1: objective=-0.10310085
2017/08/28 11:56:54 step 2: objective=-0.09164718
2017/08/28 11:56:55 step 3: objective=-0.076398216
2017/08/28 11:56:56 step 4: objective=-0.0667133
2017/08/28 11:56:57 step 5: objective=-0.052370243
2017/08/28 11:56:58 step 6: objective=-0.045228664
2017/08/28 11:56:58 step 7: objective=-0.038364314
2017/08/28 11:56:58 Training value function...
2017/08/28 11:57:00 step 0: mse=123.023395 step=0.100000
2017/08/28 11:57:01 step 1: mse=121.438483 step=0.100000
2017/08/28 11:57:02 step 2: mse=120.151067 step=0.100000
2017/08/28 11:57:03 step 3: mse=118.846789 step=0.100000
2017/08/28 11:57:04 step 4: mse=117.841675 step=0.100000
2017/08/28 11:57:05 step 5: mse=116.682483 step=0.100000
2017/08/28 11:57:05 step 6: mse=115.867985 step=0.100000
2017/08/28 11:57:06 step 7: mse=115.046563 step=0.100000
2017/08/28 11:57:06 Saving...
2017/08/28 11:57:06 Gathering batch of experience...
2017/08/28 11:58:10 batch 150: mean=35.252033 stddev=34.858971 entropy=0.652058 frames=4504 count=123
2017/08/28 11:58:10 Training policy...
2017/08/28 11:58:13 step 0: objective=1.8043237
2017/08/28 11:58:14 step 1: objective=1.8204042
2017/08/28 11:58:15 step 2: objective=1.8352814
2017/08/28 11:58:16 step 3: objective=1.8491876
2017/08/28 11:58:16 step 4: objective=1.8654462
2017/08/28 11:58:17 step 5: objective=1.8787156
2017/08/28 11:58:18 step 6: objective=1.8869764
2017/08/28 11:58:19 step 7: objective=1.8916122
2017/08/28 11:58:19 Training value function...
2017/08/28 11:58:21 step 0: mse=165.682946 step=0.100000
2017/08/28 11:58:22 step 1: mse=162.215734 step=0.100000
2017/08/28 11:58:23 step 2: mse=159.349538 step=0.100000
2017/08/28 11:58:24 step 3: mse=157.157359 step=0.100000
2017/08/28 11:58:25 step 4: mse=154.847883 step=0.100000
2017/08/28 11:58:26 step 5: mse=152.786782 step=0.100000
2017/08/28 11:58:27 step 6: mse=151.548374 step=0.100000
2017/08/28 11:58:27 step 7: mse=150.660392 step=0.100000
2017/08/28 11:58:27 Saving...
2017/08/28 11:58:27 Gathering batch of experience...
2017/08/28 11:59:38 batch 151: mean=26.400000 stddev=22.715755 entropy=0.649983 frames=4391 count=145
2017/08/28 11:59:38 Training policy...
2017/08/28 11:59:41 step 0: objective=-0.7709741
2017/08/28 11:59:41 step 1: objective=-0.7611064
2017/08/28 11:59:42 step 2: objective=-0.7510915
2017/08/28 11:59:43 step 3: objective=-0.74095494
2017/08/28 11:59:44 step 4: objective=-0.7279057
2017/08/28 11:59:45 step 5: objective=-0.72028226
2017/08/28 11:59:46 step 6: objective=-0.7100615
2017/08/28 11:59:47 step 7: objective=-0.70348
2017/08/28 11:59:47 Training value function...
2017/08/28 11:59:49 step 0: mse=114.013059 step=0.100000
2017/08/28 11:59:50 step 1: mse=111.344707 step=0.100000
2017/08/28 11:59:50 step 2: mse=109.110148 step=0.100000
2017/08/28 11:59:51 step 3: mse=107.350426 step=0.100000
2017/08/28 11:59:52 step 4: mse=105.693866 step=0.100000
2017/08/28 11:59:53 step 5: mse=104.503162 step=0.100000
2017/08/28 11:59:54 step 6: mse=103.073229 step=0.100000
2017/08/28 11:59:55 step 7: mse=101.786576 step=0.100000
2017/08/28 11:59:55 Saving...
2017/08/28 11:59:55 Gathering batch of experience...
2017/08/28 12:00:58 batch 152: mean=35.371901 stddev=33.246172 entropy=0.645481 frames=4493 count=121
2017/08/28 12:00:58 Training policy...
2017/08/28 12:01:01 step 0: objective=1.8864869
2017/08/28 12:01:01 step 1: objective=1.8963603
2017/08/28 12:01:02 step 2: objective=1.9089284
2017/08/28 12:01:03 step 3: objective=1.9165933
2017/08/28 12:01:04 step 4: objective=1.9244871
2017/08/28 12:01:05 step 5: objective=1.9337509
2017/08/28 12:01:06 step 6: objective=1.9393018
2017/08/28 12:01:07 step 7: objective=1.9472393
2017/08/28 12:01:07 Training value function...
2017/08/28 12:01:09 step 0: mse=157.913490 step=0.100000
2017/08/28 12:01:10 step 1: mse=154.203764 step=0.100000
2017/08/28 12:01:11 step 2: mse=151.261626 step=0.100000
2017/08/28 12:01:12 step 3: mse=148.466172 step=0.100000
2017/08/28 12:01:12 step 4: mse=146.452896 step=0.100000
2017/08/28 12:01:13 step 5: mse=144.505094 step=0.100000
2017/08/28 12:01:14 step 6: mse=143.164270 step=0.100000
2017/08/28 12:01:15 step 7: mse=141.830339 step=0.100000
2017/08/28 12:01:15 Saving...
2017/08/28 12:01:15 Gathering batch of experience...
2017/08/28 12:02:15 batch 153: mean=33.547009 stddev=30.263655 entropy=0.651221 frames=4379 count=117
2017/08/28 12:02:15 Training policy...
2017/08/28 12:02:18 step 0: objective=0.8418415
2017/08/28 12:02:19 step 1: objective=0.8532497
2017/08/28 12:02:20 step 2: objective=0.8641519
2017/08/28 12:02:21 step 3: objective=0.87391347
2017/08/28 12:02:21 step 4: objective=0.88396865
2017/08/28 12:02:22 step 5: objective=0.89429873
2017/08/28 12:02:23 step 6: objective=0.9001922
2017/08/28 12:02:24 step 7: objective=0.9073919
2017/08/28 12:02:24 Training value function...
2017/08/28 12:02:26 step 0: mse=137.899702 step=0.100000
2017/08/28 12:02:27 step 1: mse=136.783947 step=0.100000
2017/08/28 12:02:28 step 2: mse=135.765616 step=0.100000
2017/08/28 12:02:29 step 3: mse=135.161633 step=0.100000
2017/08/28 12:02:29 step 4: mse=133.817159 step=0.100000
2017/08/28 12:02:30 step 5: mse=133.270267 step=0.100000
2017/08/28 12:02:31 step 6: mse=132.674214 step=0.100000
2017/08/28 12:02:32 step 7: mse=131.386859 step=0.100000
2017/08/28 12:02:32 Saving...
2017/08/28 12:02:32 Gathering batch of experience...
2017/08/28 12:03:34 batch 154: mean=33.308943 stddev=32.182440 entropy=0.645243 frames=4321 count=123
2017/08/28 12:03:34 Training policy...
2017/08/28 12:03:37 step 0: objective=1.1045167
2017/08/28 12:03:38 step 1: objective=1.1201847
2017/08/28 12:03:38 step 2: objective=1.1274396
2017/08/28 12:03:39 step 3: objective=1.1432875
2017/08/28 12:03:40 step 4: objective=1.1504749
2017/08/28 12:03:41 step 5: objective=1.1560783
2017/08/28 12:03:42 step 6: objective=1.1678824
2017/08/28 12:03:43 step 7: objective=1.1785924
2017/08/28 12:03:43 Training value function...
2017/08/28 12:03:45 step 0: mse=146.876520 step=0.100000
2017/08/28 12:03:46 step 1: mse=144.826741 step=0.100000
2017/08/28 12:03:46 step 2: mse=143.016898 step=0.100000
2017/08/28 12:03:47 step 3: mse=141.504146 step=0.100000
2017/08/28 12:03:48 step 4: mse=140.180163 step=0.100000
2017/08/28 12:03:49 step 5: mse=138.901322 step=0.100000
2017/08/28 12:03:50 step 6: mse=137.731809 step=0.100000
2017/08/28 12:03:51 step 7: mse=137.008686 step=0.100000
2017/08/28 12:03:51 Saving...
2017/08/28 12:03:51 Gathering batch of experience...
2017/08/28 12:04:52 batch 155: mean=35.033333 stddev=35.057318 entropy=0.647267 frames=4443 count=120
2017/08/28 12:04:52 Training policy...
2017/08/28 12:04:55 step 0: objective=1.0105839
2017/08/28 12:04:56 step 1: objective=1.0247059
2017/08/28 12:04:56 step 2: objective=1.0349754
2017/08/28 12:04:57 step 3: objective=1.044434
2017/08/28 12:04:58 step 4: objective=1.0536016
2017/08/28 12:04:59 step 5: objective=1.0693101
2017/08/28 12:05:00 step 6: objective=1.077931
2017/08/28 12:05:01 step 7: objective=1.0848686
2017/08/28 12:05:01 Training value function...
2017/08/28 12:05:03 step 0: mse=160.608649 step=0.100000
2017/08/28 12:05:04 step 1: mse=158.663892 step=0.100000
2017/08/28 12:05:05 step 2: mse=157.013181 step=0.100000
2017/08/28 12:05:06 step 3: mse=155.667617 step=0.100000
2017/08/28 12:05:07 step 4: mse=154.528942 step=0.100000
2017/08/28 12:05:07 step 5: mse=153.277516 step=0.100000
2017/08/28 12:05:08 step 6: mse=152.508592 step=0.100000
2017/08/28 12:05:09 step 7: mse=151.746436 step=0.100000
2017/08/28 12:05:09 Saving...
2017/08/28 12:05:09 Gathering batch of experience...
2017/08/28 12:06:08 batch 156: mean=35.707965 stddev=40.933722 entropy=0.643307 frames=4383 count=113
2017/08/28 12:06:08 Training policy...
2017/08/28 12:06:11 step 0: objective=1.2359189
2017/08/28 12:06:12 step 1: objective=1.2475568
2017/08/28 12:06:13 step 2: objective=1.2603806
2017/08/28 12:06:13 step 3: objective=1.2688396
2017/08/28 12:06:14 step 4: objective=1.2809694
2017/08/28 12:06:15 step 5: objective=1.2935514
2017/08/28 12:06:16 step 6: objective=1.303198
2017/08/28 12:06:17 step 7: objective=1.3087447
2017/08/28 12:06:17 Training value function...
2017/08/28 12:06:19 step 0: mse=183.293263 step=0.100000
2017/08/28 12:06:20 step 1: mse=180.426249 step=0.100000
2017/08/28 12:06:21 step 2: mse=178.058869 step=0.100000
2017/08/28 12:06:22 step 3: mse=175.988615 step=0.100000
2017/08/28 12:06:23 step 4: mse=173.459938 step=0.100000
2017/08/28 12:06:23 step 5: mse=171.254291 step=0.100000
2017/08/28 12:06:24 step 6: mse=169.278484 step=0.100000
2017/08/28 12:06:25 step 7: mse=167.131857 step=0.100000
2017/08/28 12:06:25 Saving...
2017/08/28 12:06:25 Gathering batch of experience...
2017/08/28 12:07:23 batch 157: mean=40.027273 stddev=40.905092 entropy=0.635302 frames=4559 count=110
2017/08/28 12:07:23 Training policy...
2017/08/28 12:07:26 step 0: objective=1.5212408
2017/08/28 12:07:27 step 1: objective=1.5343584
2017/08/28 12:07:28 step 2: objective=1.5503737
2017/08/28 12:07:29 step 3: objective=1.5643067
2017/08/28 12:07:30 step 4: objective=1.5727744
2017/08/28 12:07:31 step 5: objective=1.5824652
2017/08/28 12:07:32 step 6: objective=1.587946
2017/08/28 12:07:33 step 7: objective=1.5928819
2017/08/28 12:07:33 Training value function...
2017/08/28 12:07:34 step 0: mse=182.196998 step=0.100000
2017/08/28 12:07:35 step 1: mse=179.241953 step=0.100000
2017/08/28 12:07:36 step 2: mse=177.020655 step=0.100000
2017/08/28 12:07:37 step 3: mse=175.272869 step=0.100000
2017/08/28 12:07:38 step 4: mse=173.296806 step=0.100000
2017/08/28 12:07:39 step 5: mse=171.650905 step=0.100000
2017/08/28 12:07:40 step 6: mse=169.982311 step=0.100000
2017/08/28 12:07:41 step 7: mse=168.869426 step=0.100000
2017/08/28 12:07:41 Saving...
2017/08/28 12:07:41 Gathering batch of experience...
2017/08/28 12:08:42 batch 158: mean=32.595041 stddev=30.976285 entropy=0.634842 frames=4346 count=121
2017/08/28 12:08:42 Training policy...
2017/08/28 12:08:45 step 0: objective=-0.3458244
2017/08/28 12:08:46 step 1: objective=-0.32993743
2017/08/28 12:08:47 step 2: objective=-0.31554553
2017/08/28 12:08:48 step 3: objective=-0.30531454
2017/08/28 12:08:48 step 4: objective=-0.29760078
2017/08/28 12:08:49 step 5: objective=-0.28616786
2017/08/28 12:08:50 step 6: objective=-0.27478844
2017/08/28 12:08:51 step 7: objective=-0.26922843
2017/08/28 12:08:51 Training value function...
2017/08/28 12:08:53 step 0: mse=117.714683 step=0.100000
2017/08/28 12:08:54 step 1: mse=115.791365 step=0.100000
2017/08/28 12:08:55 step 2: mse=114.125722 step=0.100000
2017/08/28 12:08:56 step 3: mse=112.961862 step=0.100000
2017/08/28 12:08:56 step 4: mse=112.069499 step=0.100000
2017/08/28 12:08:57 step 5: mse=110.965975 step=0.100000
2017/08/28 12:08:58 step 6: mse=110.176412 step=0.100000
2017/08/28 12:08:59 step 7: mse=109.499196 step=0.100000
2017/08/28 12:08:59 Saving...
2017/08/28 12:08:59 Gathering batch of experience...
2017/08/28 12:10:00 batch 159: mean=35.016529 stddev=33.396932 entropy=0.639566 frames=4437 count=121
2017/08/28 12:10:00 Training policy...
2017/08/28 12:10:03 step 0: objective=0.9838806
2017/08/28 12:10:04 step 1: objective=0.9955433
2017/08/28 12:10:05 step 2: objective=1.0037484
2017/08/28 12:10:05 step 3: objective=1.0224622
2017/08/28 12:10:06 step 4: objective=1.0330626
2017/08/28 12:10:07 step 5: objective=1.0438262
2017/08/28 12:10:08 step 6: objective=1.0543776
2017/08/28 12:10:09 step 7: objective=1.0636874
2017/08/28 12:10:09 Training value function...
2017/08/28 12:10:11 step 0: mse=147.004941 step=0.100000
2017/08/28 12:10:12 step 1: mse=145.117794 step=0.100000
2017/08/28 12:10:13 step 2: mse=143.803250 step=0.100000
2017/08/28 12:10:14 step 3: mse=142.005117 step=0.100000
2017/08/28 12:10:15 step 4: mse=140.373565 step=0.100000
2017/08/28 12:10:15 step 5: mse=139.023268 step=0.100000
2017/08/28 12:10:16 step 6: mse=137.666775 step=0.100000
2017/08/28 12:10:17 step 7: mse=136.295153 step=0.100000
2017/08/28 12:10:17 Saving...
2017/08/28 12:10:17 Gathering batch of experience...
2017/08/28 12:11:20 batch 160: mean=32.549180 stddev=34.824879 entropy=0.631589 frames=4359 count=122
2017/08/28 12:11:20 Training policy...
2017/08/28 12:11:23 step 0: objective=0.4603521
2017/08/28 12:11:23 step 1: objective=0.47874835
2017/08/28 12:11:24 step 2: objective=0.49456602
2017/08/28 12:11:25 step 3: objective=0.5082612
2017/08/28 12:11:26 step 4: objective=0.52156454
2017/08/28 12:11:27 step 5: objective=0.5337622
2017/08/28 12:11:28 step 6: objective=0.53997165
2017/08/28 12:11:29 step 7: objective=0.5455465
2017/08/28 12:11:29 Training value function...
2017/08/28 12:11:31 step 0: mse=164.938772 step=0.100000
2017/08/28 12:11:32 step 1: mse=162.972816 step=0.100000
2017/08/28 12:11:32 step 2: mse=161.330188 step=0.100000
2017/08/28 12:11:33 step 3: mse=159.664767 step=0.100000
2017/08/28 12:11:34 step 4: mse=158.331353 step=0.100000
2017/08/28 12:11:35 step 5: mse=157.101056 step=0.100000
2017/08/28 12:11:36 step 6: mse=155.930763 step=0.100000
2017/08/28 12:11:37 step 7: mse=154.527836 step=0.100000
2017/08/28 12:11:37 Saving...
2017/08/28 12:11:37 Gathering batch of experience...
2017/08/28 12:12:42 batch 161: mean=30.748092 stddev=27.584248 entropy=0.629703 frames=4325 count=131
2017/08/28 12:12:42 Training policy...
2017/08/28 12:12:45 step 0: objective=0.22111501
2017/08/28 12:12:46 step 1: objective=0.23473991
2017/08/28 12:12:47 step 2: objective=0.24742422
2017/08/28 12:12:48 step 3: objective=0.26151875
2017/08/28 12:12:49 step 4: objective=0.2746553
2017/08/28 12:12:50 step 5: objective=0.2846168
2017/08/28 12:12:51 step 6: objective=0.29443616
2017/08/28 12:12:52 step 7: objective=0.2994035
2017/08/28 12:12:52 Training value function...
2017/08/28 12:12:53 step 0: mse=118.943696 step=0.100000
2017/08/28 12:12:54 step 1: mse=117.452927 step=0.100000
2017/08/28 12:12:55 step 2: mse=116.037691 step=0.100000
2017/08/28 12:12:56 step 3: mse=114.954356 step=0.100000
2017/08/28 12:12:57 step 4: mse=113.871777 step=0.100000
2017/08/28 12:12:57 step 5: mse=113.003233 step=0.100000
2017/08/28 12:12:58 step 6: mse=111.862956 step=0.100000
2017/08/28 12:12:59 step 7: mse=110.792614 step=0.100000
2017/08/28 12:12:59 Saving...
2017/08/28 12:12:59 Gathering batch of experience...
2017/08/28 12:13:58 batch 162: mean=34.949153 stddev=32.646761 entropy=0.632082 frames=4348 count=118
2017/08/28 12:13:58 Training policy...
2017/08/28 12:14:01 step 0: objective=1.1547064
2017/08/28 12:14:02 step 1: objective=1.1685044
2017/08/28 12:14:03 step 2: objective=1.182967
2017/08/28 12:14:04 step 3: objective=1.1930243
2017/08/28 12:14:05 step 4: objective=1.2018659
2017/08/28 12:14:06 step 5: objective=1.2116553
2017/08/28 12:14:07 step 6: objective=1.2199048
2017/08/28 12:14:08 step 7: objective=1.2286931
2017/08/28 12:14:08 Training value function...
2017/08/28 12:14:09 step 0: mse=149.875296 step=0.100000
2017/08/28 12:14:10 step 1: mse=147.252123 step=0.100000
2017/08/28 12:14:11 step 2: mse=144.867271 step=0.100000
2017/08/28 12:14:12 step 3: mse=143.193575 step=0.100000
2017/08/28 12:14:13 step 4: mse=141.573044 step=0.100000
2017/08/28 12:14:14 step 5: mse=140.250177 step=0.100000
2017/08/28 12:14:15 step 6: mse=139.060288 step=0.100000
2017/08/28 12:14:15 step 7: mse=138.013648 step=0.100000
2017/08/28 12:14:15 Saving...
2017/08/28 12:14:16 Gathering batch of experience...
2017/08/28 12:15:15 batch 163: mean=33.608696 stddev=33.879761 entropy=0.634753 frames=4445 count=115
2017/08/28 12:15:15 Training policy...
2017/08/28 12:15:18 step 0: objective=0.61713
2017/08/28 12:15:19 step 1: objective=0.6285434
2017/08/28 12:15:20 step 2: objective=0.643545
2017/08/28 12:15:21 step 3: objective=0.65078646
2017/08/28 12:15:22 step 4: objective=0.6640477
2017/08/28 12:15:23 step 5: objective=0.6715113
2017/08/28 12:15:24 step 6: objective=0.68416584
2017/08/28 12:15:25 step 7: objective=0.69170886
2017/08/28 12:15:25 Training value function...
2017/08/28 12:15:26 step 0: mse=128.155740 step=0.100000
2017/08/28 12:15:27 step 1: mse=127.619565 step=0.100000
2017/08/28 12:15:28 step 2: mse=126.401788 step=0.100000
2017/08/28 12:15:29 step 3: mse=125.676167 step=0.100000
2017/08/28 12:15:30 step 4: mse=124.876070 step=0.100000
2017/08/28 12:15:31 step 5: mse=124.407461 step=0.100000
2017/08/28 12:15:32 step 6: mse=123.692274 step=0.100000
2017/08/28 12:15:33 step 7: mse=122.797702 step=0.100000
2017/08/28 12:15:33 Saving...
2017/08/28 12:15:33 Gathering batch of experience...
2017/08/28 12:16:30 batch 164: mean=40.180952 stddev=38.383474 entropy=0.631853 frames=4494 count=105
2017/08/28 12:16:30 Training policy...
2017/08/28 12:16:32 step 0: objective=1.8120825
2017/08/28 12:16:33 step 1: objective=1.8186924
2017/08/28 12:16:34 step 2: objective=1.8288655
2017/08/28 12:16:35 step 3: objective=1.837712
2017/08/28 12:16:36 step 4: objective=1.844298
2017/08/28 12:16:37 step 5: objective=1.8552191
2017/08/28 12:16:38 step 6: objective=1.8617506
2017/08/28 12:16:39 step 7: objective=1.8683614
2017/08/28 12:16:39 Training value function...
2017/08/28 12:16:41 step 0: mse=165.444554 step=0.100000
2017/08/28 12:16:42 step 1: mse=162.877432 step=0.100000
2017/08/28 12:16:43 step 2: mse=160.175688 step=0.100000
2017/08/28 12:16:44 step 3: mse=157.804260 step=0.100000
2017/08/28 12:16:45 step 4: mse=155.590704 step=0.100000
2017/08/28 12:16:45 step 5: mse=153.454834 step=0.100000
2017/08/28 12:16:46 step 6: mse=151.956216 step=0.100000
2017/08/28 12:16:47 step 7: mse=150.262464 step=0.100000
2017/08/28 12:16:47 Saving...
2017/08/28 12:16:47 Gathering batch of experience...
2017/08/28 12:17:51 batch 165: mean=32.266129 stddev=32.203263 entropy=0.633642 frames=4418 count=124
2017/08/28 12:17:51 Training policy...
2017/08/28 12:17:54 step 0: objective=0.3198948
2017/08/28 12:17:55 step 1: objective=0.33817232
2017/08/28 12:17:56 step 2: objective=0.35020193
2017/08/28 12:17:57 step 3: objective=0.36502233
2017/08/28 12:17:58 step 4: objective=0.37488988
2017/08/28 12:17:59 step 5: objective=0.3820572
2017/08/28 12:18:00 step 6: objective=0.39174286
2017/08/28 12:18:01 step 7: objective=0.3963825
2017/08/28 12:18:01 Training value function...
2017/08/28 12:18:02 step 0: mse=152.006722 step=0.100000
2017/08/28 12:18:03 step 1: mse=150.790721 step=0.100000
2017/08/28 12:18:04 step 2: mse=149.798068 step=0.100000
2017/08/28 12:18:05 step 3: mse=148.713620 step=0.100000
2017/08/28 12:18:06 step 4: mse=147.662373 step=0.100000
2017/08/28 12:18:07 step 5: mse=146.903666 step=0.100000
2017/08/28 12:18:08 step 6: mse=146.235092 step=0.100000
2017/08/28 12:18:09 step 7: mse=145.358475 step=0.100000
2017/08/28 12:18:09 Saving...
2017/08/28 12:18:09 Gathering batch of experience...
2017/08/28 12:19:07 batch 166: mean=39.445455 stddev=38.676417 entropy=0.635056 frames=4493 count=110
2017/08/28 12:19:07 Training policy...
2017/08/28 12:19:10 step 0: objective=1.8237036
2017/08/28 12:19:11 step 1: objective=1.8363222
2017/08/28 12:19:12 step 2: objective=1.8548219
2017/08/28 12:19:13 step 3: objective=1.866915
2017/08/28 12:19:14 step 4: objective=1.8759753
2017/08/28 12:19:15 step 5: objective=1.8852212
2017/08/28 12:19:16 step 6: objective=1.8945215
2017/08/28 12:19:17 step 7: objective=1.903271
2017/08/28 12:19:17 Training value function...
2017/08/28 12:19:18 step 0: mse=174.263217 step=0.100000
2017/08/28 12:19:19 step 1: mse=170.280706 step=0.100000
2017/08/28 12:19:20 step 2: mse=167.340017 step=0.100000
2017/08/28 12:19:21 step 3: mse=164.211765 step=0.100000
2017/08/28 12:19:22 step 4: mse=162.026902 step=0.100000
2017/08/28 12:19:23 step 5: mse=160.135037 step=0.100000
2017/08/28 12:19:24 step 6: mse=157.875398 step=0.100000
2017/08/28 12:19:25 step 7: mse=156.371998 step=0.100000
2017/08/28 12:19:25 Saving...
2017/08/28 12:19:25 Gathering batch of experience...
2017/08/28 12:20:25 batch 167: mean=35.885965 stddev=35.938973 entropy=0.617491 frames=4347 count=114
2017/08/28 12:20:25 Training policy...
2017/08/28 12:20:27 step 0: objective=0.48212567
2017/08/28 12:20:28 step 1: objective=0.49807337
2017/08/28 12:20:29 step 2: objective=0.5093245
2017/08/28 12:20:30 step 3: objective=0.5235098
2017/08/28 12:20:31 step 4: objective=0.52912563
2017/08/28 12:20:32 step 5: objective=0.54274166
2017/08/28 12:20:33 step 6: objective=0.5528312
2017/08/28 12:20:34 step 7: objective=0.5579435
2017/08/28 12:20:34 Training value function...
2017/08/28 12:20:35 step 0: mse=170.335596 step=0.100000
2017/08/28 12:20:36 step 1: mse=169.082468 step=0.100000
2017/08/28 12:20:37 step 2: mse=168.005392 step=0.100000
2017/08/28 12:20:38 step 3: mse=166.557423 step=0.100000
2017/08/28 12:20:39 step 4: mse=165.219917 step=0.100000
2017/08/28 12:20:40 step 5: mse=164.574562 step=0.100000
2017/08/28 12:20:41 step 6: mse=163.566869 step=0.100000
2017/08/28 12:20:42 step 7: mse=162.898584 step=0.100000
2017/08/28 12:20:42 Saving...
2017/08/28 12:20:42 Gathering batch of experience...
2017/08/28 12:21:38 batch 168: mean=41.194175 stddev=37.720242 entropy=0.626647 frames=4460 count=103
2017/08/28 12:21:38 Training policy...
2017/08/28 12:21:41 step 0: objective=1.2064607
2017/08/28 12:21:42 step 1: objective=1.2176472
2017/08/28 12:21:43 step 2: objective=1.230331
2017/08/28 12:21:44 step 3: objective=1.2401721
2017/08/28 12:21:45 step 4: objective=1.2473853
2017/08/28 12:21:46 step 5: objective=1.2581617
2017/08/28 12:21:47 step 6: objective=1.2642608
2017/08/28 12:21:47 step 7: objective=1.2691698
2017/08/28 12:21:47 Training value function...
2017/08/28 12:21:49 step 0: mse=164.312458 step=0.100000
2017/08/28 12:21:50 step 1: mse=162.331801 step=0.100000
2017/08/28 12:21:51 step 2: mse=160.501234 step=0.100000
2017/08/28 12:21:52 step 3: mse=159.062629 step=0.100000
2017/08/28 12:21:53 step 4: mse=157.694886 step=0.100000
2017/08/28 12:21:54 step 5: mse=156.069030 step=0.100000
2017/08/28 12:21:55 step 6: mse=154.427212 step=0.100000
2017/08/28 12:21:56 step 7: mse=153.296733 step=0.100000
2017/08/28 12:21:56 Saving...
2017/08/28 12:21:56 Gathering batch of experience...
2017/08/28 12:22:57 batch 169: mean=40.125000 stddev=39.789878 entropy=0.631073 frames=4756 count=112
2017/08/28 12:22:57 Training policy...
2017/08/28 12:23:00 step 0: objective=0.92458516
2017/08/28 12:23:01 step 1: objective=0.9382731
2017/08/28 12:23:02 step 2: objective=0.9513951
2017/08/28 12:23:03 step 3: objective=0.9659854
2017/08/28 12:23:04 step 4: objective=0.9762915
2017/08/28 12:23:05 step 5: objective=0.9822295
2017/08/28 12:23:06 step 6: objective=0.9873112
2017/08/28 12:23:07 step 7: objective=0.99516124
2017/08/28 12:23:07 Training value function...
2017/08/28 12:23:09 step 0: mse=150.174088 step=0.100000
2017/08/28 12:23:10 step 1: mse=147.673512 step=0.100000
2017/08/28 12:23:11 step 2: mse=145.608904 step=0.100000
2017/08/28 12:23:12 step 3: mse=143.859408 step=0.100000
2017/08/28 12:23:13 step 4: mse=142.601347 step=0.100000
2017/08/28 12:23:14 step 5: mse=140.905822 step=0.100000
2017/08/28 12:23:15 step 6: mse=139.479090 step=0.100000
2017/08/28 12:23:16 step 7: mse=138.085633 step=0.100000
2017/08/28 12:23:16 Saving...
2017/08/28 12:23:16 Gathering batch of experience...
2017/08/28 12:24:13 batch 170: mean=39.971698 stddev=35.576773 entropy=0.613040 frames=4417 count=106
2017/08/28 12:24:13 Training policy...
2017/08/28 12:24:16 step 0: objective=0.75157523
2017/08/28 12:24:17 step 1: objective=0.7623922
2017/08/28 12:24:18 step 2: objective=0.7706093
2017/08/28 12:24:19 step 3: objective=0.7785932
2017/08/28 12:24:20 step 4: objective=0.7887095
2017/08/28 12:24:21 step 5: objective=0.7964735
2017/08/28 12:24:22 step 6: objective=0.80303603
2017/08/28 12:24:23 step 7: objective=0.8139824
2017/08/28 12:24:23 Training value function...
2017/08/28 12:24:24 step 0: mse=158.789249 step=0.100000
2017/08/28 12:24:25 step 1: mse=157.274381 step=0.100000
2017/08/28 12:24:26 step 2: mse=155.830055 step=0.100000
2017/08/28 12:24:27 step 3: mse=154.487980 step=0.100000
2017/08/28 12:24:28 step 4: mse=153.098678 step=0.100000
2017/08/28 12:24:29 step 5: mse=152.040315 step=0.100000
2017/08/28 12:24:30 step 6: mse=151.092215 step=0.100000
2017/08/28 12:24:31 step 7: mse=150.061339 step=0.100000
2017/08/28 12:24:31 Saving...
2017/08/28 12:24:31 Gathering batch of experience...
2017/08/28 12:25:30 batch 171: mean=39.339286 stddev=37.047642 entropy=0.619853 frames=4508 count=112
2017/08/28 12:25:30 Training policy...
2017/08/28 12:25:32 step 0: objective=0.95609117
2017/08/28 12:25:33 step 1: objective=0.9658126
2017/08/28 12:25:34 step 2: objective=0.9751259
2017/08/28 12:25:35 step 3: objective=0.98199457
2017/08/28 12:25:36 step 4: objective=0.98996824
2017/08/28 12:25:37 step 5: objective=0.9988461
2017/08/28 12:25:38 step 6: objective=1.0126375
2017/08/28 12:25:39 step 7: objective=1.0211581
2017/08/28 12:25:39 Training value function...
2017/08/28 12:25:41 step 0: mse=164.746071 step=0.100000
2017/08/28 12:25:42 step 1: mse=162.976943 step=0.100000
2017/08/28 12:25:43 step 2: mse=160.819505 step=0.100000
2017/08/28 12:25:44 step 3: mse=159.182080 step=0.100000
2017/08/28 12:25:45 step 4: mse=157.574462 step=0.100000
2017/08/28 12:25:46 step 5: mse=155.939315 step=0.100000
2017/08/28 12:25:46 step 6: mse=154.456902 step=0.100000
2017/08/28 12:25:47 step 7: mse=153.365487 step=0.100000
2017/08/28 12:25:47 Saving...
2017/08/28 12:25:47 Gathering batch of experience...
2017/08/28 12:26:45 batch 172: mean=34.909910 stddev=35.054025 entropy=0.631728 frames=4333 count=111
2017/08/28 12:26:45 Training policy...
2017/08/28 12:26:48 step 0: objective=0.24631938
2017/08/28 12:26:49 step 1: objective=0.26204556
2017/08/28 12:26:50 step 2: objective=0.27452064
2017/08/28 12:26:51 step 3: objective=0.29452357
2017/08/28 12:26:51 step 4: objective=0.30501333
2017/08/28 12:26:52 step 5: objective=0.31547788
2017/08/28 12:26:53 step 6: objective=0.32146206
2017/08/28 12:26:54 step 7: objective=0.33087474
2017/08/28 12:26:54 Training value function...
2017/08/28 12:26:56 step 0: mse=160.645695 step=0.100000
2017/08/28 12:26:57 step 1: mse=159.286129 step=0.100000
2017/08/28 12:26:58 step 2: mse=158.342617 step=0.100000
2017/08/28 12:26:59 step 3: mse=157.097500 step=0.100000
2017/08/28 12:27:00 step 4: mse=155.951468 step=0.100000
2017/08/28 12:27:00 step 5: mse=154.785598 step=0.100000
2017/08/28 12:27:01 step 6: mse=153.553143 step=0.100000
2017/08/28 12:27:02 step 7: mse=152.737722 step=0.100000
2017/08/28 12:27:02 Saving...
2017/08/28 12:27:02 Gathering batch of experience...
2017/08/28 12:28:04 batch 173: mean=35.483051 stddev=31.986950 entropy=0.622315 frames=4590 count=118
2017/08/28 12:28:04 Training policy...
2017/08/28 12:28:07 step 0: objective=0.48672462
2017/08/28 12:28:08 step 1: objective=0.49851206
2017/08/28 12:28:09 step 2: objective=0.5104833
2017/08/28 12:28:10 step 3: objective=0.51957196
2017/08/28 12:28:11 step 4: objective=0.5372424
2017/08/28 12:28:12 step 5: objective=0.54676616
2017/08/28 12:28:13 step 6: objective=0.55643266
2017/08/28 12:28:14 step 7: objective=0.5641948
2017/08/28 12:28:14 Training value function...
2017/08/28 12:28:16 step 0: mse=131.982873 step=0.100000
2017/08/28 12:28:17 step 1: mse=131.076809 step=0.100000
2017/08/28 12:28:18 step 2: mse=130.360813 step=0.100000
2017/08/28 12:28:19 step 3: mse=128.860311 step=0.100000
2017/08/28 12:28:19 step 4: mse=128.226342 step=0.100000
2017/08/28 12:28:20 step 5: mse=127.271849 step=0.100000
2017/08/28 12:28:21 step 6: mse=126.271818 step=0.100000
2017/08/28 12:28:22 step 7: mse=125.312253 step=0.100000
2017/08/28 12:28:22 Saving...
2017/08/28 12:28:22 Gathering batch of experience...
2017/08/28 12:29:21 batch 174: mean=35.223214 stddev=31.955245 entropy=0.615794 frames=4343 count=112
2017/08/28 12:29:21 Training policy...
2017/08/28 12:29:23 step 0: objective=0.3734336
2017/08/28 12:29:24 step 1: objective=0.38405076
2017/08/28 12:29:25 step 2: objective=0.40485153
2017/08/28 12:29:26 step 3: objective=0.4114736
2017/08/28 12:29:27 step 4: objective=0.42780155
2017/08/28 12:29:28 step 5: objective=0.44112036
2017/08/28 12:29:29 step 6: objective=0.45009223
2017/08/28 12:29:30 step 7: objective=0.4561775
2017/08/28 12:29:30 Training value function...
2017/08/28 12:29:32 step 0: mse=129.432493 step=0.100000
2017/08/28 12:29:32 step 1: mse=128.130649 step=0.100000
2017/08/28 12:29:33 step 2: mse=127.164501 step=0.100000
2017/08/28 12:29:34 step 3: mse=126.239824 step=0.100000
2017/08/28 12:29:35 step 4: mse=124.956557 step=0.100000
2017/08/28 12:29:36 step 5: mse=124.268442 step=0.100000
2017/08/28 12:29:37 step 6: mse=123.453059 step=0.100000
2017/08/28 12:29:38 step 7: mse=122.500213 step=0.100000
2017/08/28 12:29:38 Saving...
2017/08/28 12:29:38 Gathering batch of experience...
2017/08/28 12:30:38 batch 175: mean=35.565217 stddev=37.684302 entropy=0.605097 frames=4433 count=115
2017/08/28 12:30:38 Training policy...
2017/08/28 12:30:41 step 0: objective=1.2047353
2017/08/28 12:30:42 step 1: objective=1.2152038
2017/08/28 12:30:43 step 2: objective=1.2286327
2017/08/28 12:30:44 step 3: objective=1.236178
2017/08/28 12:30:45 step 4: objective=1.2431995
2017/08/28 12:30:46 step 5: objective=1.2580395
2017/08/28 12:30:47 step 6: objective=1.2694856
2017/08/28 12:30:48 step 7: objective=1.2769305
2017/08/28 12:30:48 Training value function...
2017/08/28 12:30:49 step 0: mse=169.642351 step=0.100000
2017/08/28 12:30:50 step 1: mse=166.915280 step=0.100000
2017/08/28 12:30:51 step 2: mse=163.923632 step=0.100000
2017/08/28 12:30:52 step 3: mse=161.415129 step=0.100000
2017/08/28 12:30:53 step 4: mse=158.886282 step=0.100000
2017/08/28 12:30:54 step 5: mse=157.265667 step=0.100000
2017/08/28 12:30:55 step 6: mse=155.541478 step=0.100000
2017/08/28 12:30:56 step 7: mse=153.608412 step=0.100000
2017/08/28 12:30:56 Saving...
2017/08/28 12:30:56 Gathering batch of experience...
2017/08/28 12:31:55 batch 176: mean=37.114035 stddev=40.186137 entropy=0.598830 frames=4374 count=114
2017/08/28 12:31:55 Training policy...
2017/08/28 12:31:58 step 0: objective=1.263709
2017/08/28 12:31:59 step 1: objective=1.2742548
2017/08/28 12:32:00 step 2: objective=1.2888283
2017/08/28 12:32:01 step 3: objective=1.2954636
2017/08/28 12:32:02 step 4: objective=1.3032107
2017/08/28 12:32:03 step 5: objective=1.3161467
2017/08/28 12:32:03 step 6: objective=1.3219205
2017/08/28 12:32:04 step 7: objective=1.3299266
2017/08/28 12:32:04 Training value function...
2017/08/28 12:32:06 step 0: mse=172.286321 step=0.100000
2017/08/28 12:32:07 step 1: mse=170.351371 step=0.100000
2017/08/28 12:32:08 step 2: mse=168.475922 step=0.100000
2017/08/28 12:32:09 step 3: mse=166.998358 step=0.100000
2017/08/28 12:32:10 step 4: mse=165.106090 step=0.100000
2017/08/28 12:32:11 step 5: mse=163.527189 step=0.100000
2017/08/28 12:32:11 step 6: mse=162.228961 step=0.100000
2017/08/28 12:32:12 step 7: mse=160.742715 step=0.100000
2017/08/28 12:32:12 Saving...
2017/08/28 12:32:12 Gathering batch of experience...
2017/08/28 12:33:07 batch 177: mean=39.762376 stddev=39.599517 entropy=0.600843 frames=4248 count=101
2017/08/28 12:33:07 Training policy...
2017/08/28 12:33:10 step 0: objective=0.9425379
2017/08/28 12:33:11 step 1: objective=0.96241814
2017/08/28 12:33:11 step 2: objective=0.98216844
2017/08/28 12:33:12 step 3: objective=0.99275684
2017/08/28 12:33:13 step 4: objective=1.001474
2017/08/28 12:33:14 step 5: objective=1.0069586
2017/08/28 12:33:15 step 6: objective=1.0167768
2017/08/28 12:33:16 step 7: objective=1.0221673
2017/08/28 12:33:16 Training value function...
2017/08/28 12:33:18 step 0: mse=153.462992 step=0.100000
2017/08/28 12:33:19 step 1: mse=151.787221 step=0.100000
2017/08/28 12:33:20 step 2: mse=150.167082 step=0.100000
2017/08/28 12:33:20 step 3: mse=148.617714 step=0.100000
2017/08/28 12:33:21 step 4: mse=147.276701 step=0.100000
2017/08/28 12:33:22 step 5: mse=146.326870 step=0.100000
2017/08/28 12:33:23 step 6: mse=144.981419 step=0.100000
2017/08/28 12:33:24 step 7: mse=143.895598 step=0.100000
2017/08/28 12:33:24 Saving...
2017/08/28 12:33:24 Gathering batch of experience...
2017/08/28 12:34:28 batch 178: mean=33.160000 stddev=31.012101 entropy=0.599309 frames=4656 count=125
2017/08/28 12:34:28 Training policy...
2017/08/28 12:34:31 step 0: objective=-0.026182475
2017/08/28 12:34:32 step 1: objective=-0.016835269
2017/08/28 12:34:33 step 2: objective=-0.007928833
2017/08/28 12:34:34 step 3: objective=0.0013045097
2017/08/28 12:34:35 step 4: objective=0.008288981
2017/08/28 12:34:36 step 5: objective=0.013500595
2017/08/28 12:34:37 step 6: objective=0.02245055
2017/08/28 12:34:38 step 7: objective=0.02953327
2017/08/28 12:34:38 Training value function...
2017/08/28 12:34:40 step 0: mse=116.871293 step=0.100000
2017/08/28 12:34:41 step 1: mse=116.056139 step=0.100000
2017/08/28 12:34:41 step 2: mse=115.242539 step=0.100000
2017/08/28 12:34:42 step 3: mse=114.351178 step=0.100000
2017/08/28 12:34:43 step 4: mse=113.576280 step=0.100000
2017/08/28 12:34:44 step 5: mse=113.259462 step=0.100000
2017/08/28 12:34:45 step 6: mse=112.735769 step=0.100000
2017/08/28 12:34:46 step 7: mse=112.012786 step=0.100000
2017/08/28 12:34:46 Saving...
2017/08/28 12:34:46 Gathering batch of experience...
2017/08/28 12:35:47 batch 179: mean=35.119658 stddev=36.061477 entropy=0.601838 frames=4472 count=117
2017/08/28 12:35:47 Training policy...
2017/08/28 12:35:50 step 0: objective=0.8330675
2017/08/28 12:35:51 step 1: objective=0.84110177
2017/08/28 12:35:52 step 2: objective=0.85303444
2017/08/28 12:35:53 step 3: objective=0.8673153
2017/08/28 12:35:53 step 4: objective=0.87590575
2017/08/28 12:35:54 step 5: objective=0.8871571
2017/08/28 12:35:55 step 6: objective=0.8937974
2017/08/28 12:35:56 step 7: objective=0.8994226
2017/08/28 12:35:56 Training value function...
2017/08/28 12:35:58 step 0: mse=148.869198 step=0.100000
2017/08/28 12:35:59 step 1: mse=147.363437 step=0.100000
2017/08/28 12:36:00 step 2: mse=145.767073 step=0.100000
2017/08/28 12:36:01 step 3: mse=144.585082 step=0.100000
2017/08/28 12:36:02 step 4: mse=143.445381 step=0.100000
2017/08/28 12:36:03 step 5: mse=142.166220 step=0.100000
2017/08/28 12:36:03 step 6: mse=140.991608 step=0.100000
2017/08/28 12:36:04 step 7: mse=139.570048 step=0.100000
2017/08/28 12:36:04 Saving...
2017/08/28 12:36:04 Gathering batch of experience...
2017/08/28 12:37:05 batch 180: mean=35.793103 stddev=29.545265 entropy=0.593886 frames=4424 count=116
2017/08/28 12:37:05 Training policy...
2017/08/28 12:37:08 step 0: objective=0.79176486
2017/08/28 12:37:09 step 1: objective=0.7992386
2017/08/28 12:37:10 step 2: objective=0.8082138
2017/08/28 12:37:11 step 3: objective=0.8156184
2017/08/28 12:37:11 step 4: objective=0.82723
2017/08/28 12:37:12 step 5: objective=0.8400782
2017/08/28 12:37:13 step 6: objective=0.84803134
2017/08/28 12:37:14 step 7: objective=0.8557137
2017/08/28 12:37:14 Training value function...
2017/08/28 12:37:16 step 0: mse=122.317329 step=0.100000
2017/08/28 12:37:17 step 1: mse=121.227976 step=0.100000
2017/08/28 12:37:18 step 2: mse=120.480500 step=0.100000
2017/08/28 12:37:19 step 3: mse=119.587858 step=0.100000
2017/08/28 12:37:20 step 4: mse=118.842992 step=0.100000
2017/08/28 12:37:21 step 5: mse=118.032832 step=0.100000
2017/08/28 12:37:21 step 6: mse=117.059209 step=0.100000
2017/08/28 12:37:22 step 7: mse=116.246347 step=0.100000
2017/08/28 12:37:22 Saving...
2017/08/28 12:37:22 Gathering batch of experience...
2017/08/28 12:38:23 batch 181: mean=37.271930 stddev=38.298753 entropy=0.597909 frames=4591 count=114
2017/08/28 12:38:23 Training policy...
2017/08/28 12:38:26 step 0: objective=1.3831552
2017/08/28 12:38:27 step 1: objective=1.396669
2017/08/28 12:38:28 step 2: objective=1.4053913
2017/08/28 12:38:29 step 3: objective=1.4132282
2017/08/28 12:38:30 step 4: objective=1.4218252
2017/08/28 12:38:31 step 5: objective=1.4299365
2017/08/28 12:38:32 step 6: objective=1.4365091
2017/08/28 12:38:33 step 7: objective=1.4453009
2017/08/28 12:38:33 Training value function...
2017/08/28 12:38:35 step 0: mse=173.876813 step=0.100000
2017/08/28 12:38:36 step 1: mse=171.271003 step=0.100000
2017/08/28 12:38:36 step 2: mse=168.615463 step=0.100000
2017/08/28 12:38:37 step 3: mse=166.586930 step=0.100000
2017/08/28 12:38:38 step 4: mse=164.145373 step=0.100000
2017/08/28 12:38:39 step 5: mse=162.762948 step=0.100000
2017/08/28 12:38:40 step 6: mse=161.072233 step=0.100000
2017/08/28 12:38:41 step 7: mse=158.810957 step=0.100000
2017/08/28 12:38:41 Saving...
2017/08/28 12:38:41 Gathering batch of experience...
2017/08/28 12:39:37 batch 182: mean=40.696078 stddev=37.082787 entropy=0.603221 frames=4535 count=102
2017/08/28 12:39:37 Training policy...
2017/08/28 12:39:40 step 0: objective=1.2656834
2017/08/28 12:39:41 step 1: objective=1.2775873
2017/08/28 12:39:42 step 2: objective=1.2928225
2017/08/28 12:39:43 step 3: objective=1.3043749
2017/08/28 12:39:44 step 4: objective=1.31684
2017/08/28 12:39:45 step 5: objective=1.3222084
2017/08/28 12:39:46 step 6: objective=1.3285466
2017/08/28 12:39:47 step 7: objective=1.3368957
2017/08/28 12:39:47 Training value function...
2017/08/28 12:39:49 step 0: mse=140.133347 step=0.100000
2017/08/28 12:39:50 step 1: mse=138.559394 step=0.100000
2017/08/28 12:39:51 step 2: mse=137.351008 step=0.100000
2017/08/28 12:39:52 step 3: mse=135.961822 step=0.100000
2017/08/28 12:39:53 step 4: mse=134.978180 step=0.100000
2017/08/28 12:39:54 step 5: mse=133.859463 step=0.100000
2017/08/28 12:39:54 step 6: mse=132.869264 step=0.100000
2017/08/28 12:39:55 step 7: mse=132.205526 step=0.100000
2017/08/28 12:39:55 Saving...
2017/08/28 12:39:55 Gathering batch of experience...
2017/08/28 12:40:50 batch 183: mean=41.465347 stddev=35.219696 entropy=0.598787 frames=4388 count=101
2017/08/28 12:40:50 Training policy...
2017/08/28 12:40:53 step 0: objective=1.0911051
2017/08/28 12:40:54 step 1: objective=1.1043643
2017/08/28 12:40:55 step 2: objective=1.1141812
2017/08/28 12:40:56 step 3: objective=1.1299273
2017/08/28 12:40:56 step 4: objective=1.1416677
2017/08/28 12:40:57 step 5: objective=1.1484762
2017/08/28 12:40:58 step 6: objective=1.1584048
2017/08/28 12:40:59 step 7: objective=1.165208
2017/08/28 12:40:59 Training value function...
2017/08/28 12:41:01 step 0: mse=147.864752 step=0.100000
2017/08/28 12:41:02 step 1: mse=145.934310 step=0.100000
2017/08/28 12:41:03 step 2: mse=144.303479 step=0.100000
2017/08/28 12:41:04 step 3: mse=142.747374 step=0.100000
2017/08/28 12:41:05 step 4: mse=141.509779 step=0.100000
2017/08/28 12:41:06 step 5: mse=139.986667 step=0.100000
2017/08/28 12:41:06 step 6: mse=139.109702 step=0.100000
2017/08/28 12:41:07 step 7: mse=138.177061 step=0.100000
2017/08/28 12:41:07 Saving...
2017/08/28 12:41:07 Gathering batch of experience...
2017/08/28 12:42:03 batch 184: mean=42.782178 stddev=35.462322 entropy=0.592461 frames=4382 count=101
2017/08/28 12:42:03 Training policy...
2017/08/28 12:42:06 step 0: objective=1.2227514
2017/08/28 12:42:07 step 1: objective=1.2360516
2017/08/28 12:42:08 step 2: objective=1.2521263
2017/08/28 12:42:09 step 3: objective=1.2646625
2017/08/28 12:42:10 step 4: objective=1.273889
2017/08/28 12:42:11 step 5: objective=1.2813907
2017/08/28 12:42:12 step 6: objective=1.2867504
2017/08/28 12:42:13 step 7: objective=1.2936803
2017/08/28 12:42:13 Training value function...
2017/08/28 12:42:15 step 0: mse=152.141432 step=0.100000
2017/08/28 12:42:15 step 1: mse=150.429576 step=0.100000
2017/08/28 12:42:16 step 2: mse=148.764865 step=0.100000
2017/08/28 12:42:17 step 3: mse=147.584677 step=0.100000
2017/08/28 12:42:18 step 4: mse=146.147222 step=0.100000
2017/08/28 12:42:19 step 5: mse=145.456792 step=0.100000
2017/08/28 12:42:20 step 6: mse=144.113027 step=0.100000
2017/08/28 12:42:21 step 7: mse=143.119172 step=0.100000
2017/08/28 12:42:21 Saving...
2017/08/28 12:42:21 Gathering batch of experience...
2017/08/28 12:43:24 batch 185: mean=33.459677 stddev=34.013375 entropy=0.596343 frames=4609 count=124
2017/08/28 12:43:24 Training policy...
2017/08/28 12:43:27 step 0: objective=-0.3305607
2017/08/28 12:43:28 step 1: objective=-0.3213825
2017/08/28 12:43:29 step 2: objective=-0.31079802
2017/08/28 12:43:30 step 3: objective=-0.3002284
2017/08/28 12:43:31 step 4: objective=-0.29240027
2017/08/28 12:43:32 step 5: objective=-0.2836224
2017/08/28 12:43:33 step 6: objective=-0.27086636
2017/08/28 12:43:34 step 7: objective=-0.2649367
2017/08/28 12:43:34 Training value function...
2017/08/28 12:43:36 step 0: mse=145.242218 step=0.100000
2017/08/28 12:43:37 step 1: mse=143.399856 step=0.100000
2017/08/28 12:43:37 step 2: mse=142.120277 step=0.100000
2017/08/28 12:43:38 step 3: mse=140.744143 step=0.100000
2017/08/28 12:43:39 step 4: mse=139.469578 step=0.100000
2017/08/28 12:43:40 step 5: mse=138.387676 step=0.100000
2017/08/28 12:43:41 step 6: mse=137.713896 step=0.100000
2017/08/28 12:43:42 step 7: mse=137.184009 step=0.100000
2017/08/28 12:43:42 Saving...
2017/08/28 12:43:42 Gathering batch of experience...
2017/08/28 12:44:39 batch 186: mean=40.112150 stddev=37.764476 entropy=0.597950 frames=4499 count=107
2017/08/28 12:44:39 Training policy...
2017/08/28 12:44:42 step 0: objective=1.2945896
2017/08/28 12:44:43 step 1: objective=1.3039957
2017/08/28 12:44:44 step 2: objective=1.3156551
2017/08/28 12:44:45 step 3: objective=1.33094
2017/08/28 12:44:46 step 4: objective=1.3411294
2017/08/28 12:44:47 step 5: objective=1.3516517
2017/08/28 12:44:48 step 6: objective=1.3609908
2017/08/28 12:44:49 step 7: objective=1.3709338
2017/08/28 12:44:49 Training value function...
2017/08/28 12:44:51 step 0: mse=141.809464 step=0.100000
2017/08/28 12:44:52 step 1: mse=139.899811 step=0.100000
2017/08/28 12:44:53 step 2: mse=138.555917 step=0.100000
2017/08/28 12:44:54 step 3: mse=137.144765 step=0.100000
2017/08/28 12:44:54 step 4: mse=136.272141 step=0.100000
2017/08/28 12:44:55 step 5: mse=135.081356 step=0.100000
2017/08/28 12:44:56 step 6: mse=134.253738 step=0.100000
2017/08/28 12:44:57 step 7: mse=133.316756 step=0.100000
2017/08/28 12:44:57 Saving...
2017/08/28 12:44:57 Gathering batch of experience...
2017/08/28 12:45:51 batch 187: mean=43.323232 stddev=40.725945 entropy=0.599160 frames=4462 count=99
2017/08/28 12:45:51 Training policy...
2017/08/28 12:45:54 step 0: objective=1.3689237
2017/08/28 12:45:55 step 1: objective=1.3773429
2017/08/28 12:45:56 step 2: objective=1.387546
2017/08/28 12:45:57 step 3: objective=1.3957485
2017/08/28 12:45:58 step 4: objective=1.4113904
2017/08/28 12:45:59 step 5: objective=1.4187071
2017/08/28 12:46:00 step 6: objective=1.4286774
2017/08/28 12:46:01 step 7: objective=1.4329255
2017/08/28 12:46:01 Training value function...
2017/08/28 12:46:03 step 0: mse=150.174764 step=0.100000
2017/08/28 12:46:04 step 1: mse=148.287265 step=0.100000
2017/08/28 12:46:05 step 2: mse=146.858978 step=0.100000
2017/08/28 12:46:05 step 3: mse=145.482771 step=0.100000
2017/08/28 12:46:06 step 4: mse=143.942257 step=0.100000
2017/08/28 12:46:07 step 5: mse=142.808647 step=0.100000
2017/08/28 12:46:08 step 6: mse=141.685768 step=0.100000
2017/08/28 12:46:09 step 7: mse=140.676359 step=0.100000
2017/08/28 12:46:09 Saving...
2017/08/28 12:46:09 Gathering batch of experience...
2017/08/28 12:47:10 batch 188: mean=34.210084 stddev=28.791010 entropy=0.592859 frames=4480 count=119
2017/08/28 12:47:10 Training policy...
2017/08/28 12:47:13 step 0: objective=-0.3078901
2017/08/28 12:47:14 step 1: objective=-0.29892778
2017/08/28 12:47:15 step 2: objective=-0.28812975
2017/08/28 12:47:16 step 3: objective=-0.2760276
2017/08/28 12:47:17 step 4: objective=-0.26228926
2017/08/28 12:47:18 step 5: objective=-0.25056714
2017/08/28 12:47:19 step 6: objective=-0.24086018
2017/08/28 12:47:20 step 7: objective=-0.23499413
2017/08/28 12:47:20 Training value function...
2017/08/28 12:47:22 step 0: mse=114.116309 step=0.100000
2017/08/28 12:47:22 step 1: mse=112.684116 step=0.100000
2017/08/28 12:47:23 step 2: mse=111.353712 step=0.100000
2017/08/28 12:47:24 step 3: mse=110.163988 step=0.100000
2017/08/28 12:47:25 step 4: mse=109.423965 step=0.100000
2017/08/28 12:47:26 step 5: mse=108.782932 step=0.100000
2017/08/28 12:47:27 step 6: mse=107.767162 step=0.100000
2017/08/28 12:47:28 step 7: mse=107.293213 step=0.100000
2017/08/28 12:47:28 Saving...
2017/08/28 12:47:28 Gathering batch of experience...
2017/08/28 12:48:21 batch 189: mean=42.156250 stddev=42.112282 entropy=0.600403 frames=4290 count=96
2017/08/28 12:48:21 Training policy...
2017/08/28 12:48:24 step 0: objective=1.6272763
2017/08/28 12:48:25 step 1: objective=1.6419683
2017/08/28 12:48:26 step 2: objective=1.6532255
2017/08/28 12:48:27 step 3: objective=1.6600633
2017/08/28 12:48:27 step 4: objective=1.6709605
2017/08/28 12:48:28 step 5: objective=1.6808339
2017/08/28 12:48:29 step 6: objective=1.6881279
2017/08/28 12:48:30 step 7: objective=1.6932725
2017/08/28 12:48:30 Training value function...
2017/08/28 12:48:32 step 0: mse=176.233824 step=0.100000
2017/08/28 12:48:33 step 1: mse=172.358117 step=0.100000
2017/08/28 12:48:34 step 2: mse=168.988809 step=0.100000
2017/08/28 12:48:35 step 3: mse=165.837823 step=0.100000
2017/08/28 12:48:36 step 4: mse=163.448091 step=0.100000
2017/08/28 12:48:36 step 5: mse=161.278045 step=0.100000
2017/08/28 12:48:37 step 6: mse=159.005098 step=0.100000
2017/08/28 12:48:38 step 7: mse=157.229089 step=0.100000
2017/08/28 12:48:38 Saving...
2017/08/28 12:48:38 Gathering batch of experience...
2017/08/28 12:49:34 batch 190: mean=39.783019 stddev=37.659098 entropy=0.598271 frames=4424 count=106
2017/08/28 12:49:34 Training policy...
2017/08/28 12:49:37 step 0: objective=0.9846826
2017/08/28 12:49:38 step 1: objective=0.9968733
2017/08/28 12:49:39 step 2: objective=1.0062674
2017/08/28 12:49:40 step 3: objective=1.016602
2017/08/28 12:49:41 step 4: objective=1.0256729
2017/08/28 12:49:42 step 5: objective=1.0320966
2017/08/28 12:49:43 step 6: objective=1.0372578
2017/08/28 12:49:44 step 7: objective=1.0489609
2017/08/28 12:49:44 Training value function...
2017/08/28 12:49:46 step 0: mse=149.263934 step=0.100000
2017/08/28 12:49:46 step 1: mse=147.273031 step=0.100000
2017/08/28 12:49:47 step 2: mse=145.554223 step=0.100000
2017/08/28 12:49:48 step 3: mse=143.671829 step=0.100000
2017/08/28 12:49:49 step 4: mse=142.303642 step=0.100000
2017/08/28 12:49:50 step 5: mse=140.764217 step=0.100000
2017/08/28 12:49:51 step 6: mse=139.505357 step=0.100000
2017/08/28 12:49:52 step 7: mse=138.269676 step=0.100000
2017/08/28 12:49:52 Saving...
2017/08/28 12:49:52 Gathering batch of experience...
2017/08/28 12:50:47 batch 191: mean=46.726316 stddev=50.230509 entropy=0.596478 frames=4847 count=95
2017/08/28 12:50:47 Training policy...
2017/08/28 12:50:50 step 0: objective=1.3800011
2017/08/28 12:50:51 step 1: objective=1.388189
2017/08/28 12:50:52 step 2: objective=1.3966161
2017/08/28 12:50:53 step 3: objective=1.4063601
2017/08/28 12:50:54 step 4: objective=1.4197961
2017/08/28 12:50:55 step 5: objective=1.4267719
2017/08/28 12:50:56 step 6: objective=1.433915
2017/08/28 12:50:58 step 7: objective=1.4434701
2017/08/28 12:50:58 Training value function...
2017/08/28 12:50:59 step 0: mse=160.758172 step=0.100000
2017/08/28 12:51:00 step 1: mse=157.578790 step=0.100000
2017/08/28 12:51:01 step 2: mse=155.282427 step=0.100000
2017/08/28 12:51:02 step 3: mse=153.271775 step=0.100000
2017/08/28 12:51:03 step 4: mse=151.555193 step=0.100000
2017/08/28 12:51:04 step 5: mse=150.040944 step=0.100000
2017/08/28 12:51:05 step 6: mse=148.761145 step=0.100000
2017/08/28 12:51:06 step 7: mse=147.226034 step=0.100000
2017/08/28 12:51:06 Saving...
2017/08/28 12:51:06 Gathering batch of experience...
2017/08/28 12:52:04 batch 192: mean=38.477064 stddev=35.379359 entropy=0.594541 frames=4336 count=109
2017/08/28 12:52:04 Training policy...
2017/08/28 12:52:07 step 0: objective=0.50545424
2017/08/28 12:52:07 step 1: objective=0.517578
2017/08/28 12:52:08 step 2: objective=0.52644163
2017/08/28 12:52:09 step 3: objective=0.54039115
2017/08/28 12:52:10 step 4: objective=0.55231124
2017/08/28 12:52:11 step 5: objective=0.561757
2017/08/28 12:52:12 step 6: objective=0.5724897
2017/08/28 12:52:13 step 7: objective=0.5783248
2017/08/28 12:52:13 Training value function...
2017/08/28 12:52:15 step 0: mse=155.661044 step=0.100000
2017/08/28 12:52:16 step 1: mse=154.161592 step=0.100000
2017/08/28 12:52:17 step 2: mse=153.029995 step=0.100000
2017/08/28 12:52:17 step 3: mse=151.301577 step=0.100000
2017/08/28 12:52:18 step 4: mse=149.798640 step=0.100000
2017/08/28 12:52:19 step 5: mse=148.715357 step=0.100000
2017/08/28 12:52:20 step 6: mse=147.776502 step=0.100000
2017/08/28 12:52:21 step 7: mse=146.801980 step=0.100000
2017/08/28 12:52:21 Saving...
2017/08/28 12:52:21 Gathering batch of experience...
2017/08/28 12:53:22 batch 193: mean=40.709091 stddev=41.111455 entropy=0.597420 frames=4775 count=110
2017/08/28 12:53:22 Training policy...
2017/08/28 12:53:25 step 0: objective=0.91111183
2017/08/28 12:53:26 step 1: objective=0.91943055
2017/08/28 12:53:27 step 2: objective=0.92950904
2017/08/28 12:53:28 step 3: objective=0.9361059
2017/08/28 12:53:29 step 4: objective=0.94534296
2017/08/28 12:53:30 step 5: objective=0.9498636
2017/08/28 12:53:31 step 6: objective=0.9584078
2017/08/28 12:53:32 step 7: objective=0.9697303
2017/08/28 12:53:32 Training value function...
2017/08/28 12:53:34 step 0: mse=165.597167 step=0.100000
2017/08/28 12:53:35 step 1: mse=162.824053 step=0.100000
2017/08/28 12:53:36 step 2: mse=160.023298 step=0.100000
2017/08/28 12:53:37 step 3: mse=157.790825 step=0.100000
2017/08/28 12:53:38 step 4: mse=155.682295 step=0.100000
2017/08/28 12:53:39 step 5: mse=153.887224 step=0.100000
2017/08/28 12:53:40 step 6: mse=152.191634 step=0.100000
2017/08/28 12:53:41 step 7: mse=150.755460 step=0.100000
2017/08/28 12:53:41 Saving...
2017/08/28 12:53:41 Gathering batch of experience...
2017/08/28 12:54:39 batch 194: mean=41.676190 stddev=36.673981 entropy=0.589301 frames=4561 count=105
2017/08/28 12:54:39 Training policy...
2017/08/28 12:54:42 step 0: objective=0.9382287
2017/08/28 12:54:43 step 1: objective=0.94886684
2017/08/28 12:54:44 step 2: objective=0.95884144
2017/08/28 12:54:45 step 3: objective=0.97354853
2017/08/28 12:54:46 step 4: objective=0.9802154
2017/08/28 12:54:47 step 5: objective=0.9874431
2017/08/28 12:54:48 step 6: objective=0.99542296
2017/08/28 12:54:48 step 7: objective=1.0028211
2017/08/28 12:54:48 Training value function...
2017/08/28 12:54:50 step 0: mse=150.201301 step=0.100000
2017/08/28 12:54:51 step 1: mse=148.693402 step=0.100000
2017/08/28 12:54:52 step 2: mse=147.335338 step=0.100000
2017/08/28 12:54:53 step 3: mse=146.270994 step=0.100000
2017/08/28 12:54:54 step 4: mse=144.940457 step=0.100000
2017/08/28 12:54:55 step 5: mse=143.731797 step=0.100000
2017/08/28 12:54:56 step 6: mse=142.556008 step=0.100000
2017/08/28 12:54:57 step 7: mse=141.611522 step=0.100000
2017/08/28 12:54:57 Saving...
2017/08/28 12:54:57 Gathering batch of experience...
2017/08/28 12:55:56 batch 195: mean=38.589286 stddev=37.538208 entropy=0.583475 frames=4473 count=112
2017/08/28 12:55:56 Training policy...
2017/08/28 12:55:59 step 0: objective=0.7294433
2017/08/28 12:56:00 step 1: objective=0.7451085
2017/08/28 12:56:00 step 2: objective=0.75801253
2017/08/28 12:56:01 step 3: objective=0.7689448
2017/08/28 12:56:02 step 4: objective=0.7745867
2017/08/28 12:56:03 step 5: objective=0.7797074
2017/08/28 12:56:04 step 6: objective=0.79323274
2017/08/28 12:56:05 step 7: objective=0.8015943
2017/08/28 12:56:05 Training value function...
2017/08/28 12:56:07 step 0: mse=149.196192 step=0.100000
2017/08/28 12:56:08 step 1: mse=147.835443 step=0.100000
2017/08/28 12:56:09 step 2: mse=146.685866 step=0.100000
2017/08/28 12:56:10 step 3: mse=145.785281 step=0.100000
2017/08/28 12:56:11 step 4: mse=144.597654 step=0.100000
2017/08/28 12:56:12 step 5: mse=143.289081 step=0.100000
2017/08/28 12:56:13 step 6: mse=142.517951 step=0.100000
2017/08/28 12:56:13 step 7: mse=141.883581 step=0.100000
2017/08/28 12:56:13 Saving...
2017/08/28 12:56:13 Gathering batch of experience...
2017/08/28 12:57:12 batch 196: mean=37.265487 stddev=40.047321 entropy=0.584676 frames=4307 count=113
2017/08/28 12:57:12 Training policy...
2017/08/28 12:57:15 step 0: objective=0.9567046
2017/08/28 12:57:16 step 1: objective=0.97500664
2017/08/28 12:57:17 step 2: objective=0.9881604
2017/08/28 12:57:18 step 3: objective=1.0005136
2017/08/28 12:57:18 step 4: objective=1.0130517
2017/08/28 12:57:19 step 5: objective=1.0186304
2017/08/28 12:57:20 step 6: objective=1.0300927
2017/08/28 12:57:21 step 7: objective=1.0351638
2017/08/28 12:57:21 Training value function...
2017/08/28 12:57:23 step 0: mse=185.582737 step=0.100000
2017/08/28 12:57:24 step 1: mse=184.443301 step=0.100000
2017/08/28 12:57:25 step 2: mse=182.459670 step=0.100000
2017/08/28 12:57:26 step 3: mse=180.570035 step=0.100000
2017/08/28 12:57:26 step 4: mse=179.456515 step=0.100000
2017/08/28 12:57:27 step 5: mse=177.861405 step=0.100000
2017/08/28 12:57:28 step 6: mse=176.079113 step=0.100000
2017/08/28 12:57:29 step 7: mse=174.738135 step=0.100000
2017/08/28 12:57:29 Saving...
2017/08/28 12:57:29 Gathering batch of experience...
2017/08/28 12:58:28 batch 197: mean=36.584071 stddev=32.886430 entropy=0.590649 frames=4453 count=113
2017/08/28 12:58:28 Training policy...
2017/08/28 12:58:31 step 0: objective=0.32533693
2017/08/28 12:58:32 step 1: objective=0.3410855
2017/08/28 12:58:33 step 2: objective=0.34970567
2017/08/28 12:58:34 step 3: objective=0.36198616
2017/08/28 12:58:35 step 4: objective=0.3789932
2017/08/28 12:58:36 step 5: objective=0.3836467
2017/08/28 12:58:37 step 6: objective=0.39253485
2017/08/28 12:58:38 step 7: objective=0.39973474
2017/08/28 12:58:38 Training value function...
2017/08/28 12:58:40 step 0: mse=152.201967 step=0.100000
2017/08/28 12:58:41 step 1: mse=150.968781 step=0.100000
2017/08/28 12:58:42 step 2: mse=149.835032 step=0.100000
2017/08/28 12:58:43 step 3: mse=148.640742 step=0.100000
2017/08/28 12:58:43 step 4: mse=147.327194 step=0.100000
2017/08/28 12:58:44 step 5: mse=146.733280 step=0.100000
2017/08/28 12:58:45 step 6: mse=145.452563 step=0.100000
2017/08/28 12:58:46 step 7: mse=144.026349 step=0.100000
2017/08/28 12:58:46 Saving...
2017/08/28 12:58:46 Gathering batch of experience...
2017/08/28 12:59:45 batch 198: mean=39.927928 stddev=35.684734 entropy=0.590933 frames=4385 count=111
2017/08/28 12:59:45 Training policy...
2017/08/28 12:59:48 step 0: objective=1.4757878
2017/08/28 12:59:49 step 1: objective=1.4837053
2017/08/28 12:59:50 step 2: objective=1.4925166
2017/08/28 12:59:51 step 3: objective=1.5025336
2017/08/28 12:59:52 step 4: objective=1.5120533
2017/08/28 12:59:53 step 5: objective=1.5203379
2017/08/28 12:59:54 step 6: objective=1.5266428
2017/08/28 12:59:55 step 7: objective=1.5315033
2017/08/28 12:59:55 Training value function...
2017/08/28 12:59:56 step 0: mse=152.818172 step=0.100000
2017/08/28 12:59:57 step 1: mse=150.600442 step=0.100000
2017/08/28 12:59:58 step 2: mse=148.375883 step=0.100000
2017/08/28 12:59:59 step 3: mse=146.516877 step=0.100000
2017/08/28 13:00:00 step 4: mse=145.084063 step=0.100000
2017/08/28 13:00:01 step 5: mse=143.496242 step=0.100000
2017/08/28 13:00:02 step 6: mse=142.164271 step=0.100000
2017/08/28 13:00:03 step 7: mse=140.813196 step=0.100000
2017/08/28 13:00:03 Saving...
2017/08/28 13:00:03 Gathering batch of experience...
2017/08/28 13:00:57 batch 199: mean=39.233010 stddev=38.282091 entropy=0.584188 frames=4300 count=103
2017/08/28 13:00:57 Training policy...
2017/08/28 13:01:00 step 0: objective=0.70372975
2017/08/28 13:01:01 step 1: objective=0.716211
2017/08/28 13:01:02 step 2: objective=0.72795427
2017/08/28 13:01:03 step 3: objective=0.7404521
2017/08/28 13:01:04 step 4: objective=0.7516242
2017/08/28 13:01:05 step 5: objective=0.76230407
2017/08/28 13:01:06 step 6: objective=0.7705538
2017/08/28 13:01:07 step 7: objective=0.7792999
2017/08/28 13:01:07 Training value function...
2017/08/28 13:01:08 step 0: mse=144.277667 step=0.100000
2017/08/28 13:01:09 step 1: mse=142.492756 step=0.100000
2017/08/28 13:01:10 step 2: mse=141.267725 step=0.100000
2017/08/28 13:01:11 step 3: mse=140.043015 step=0.100000
2017/08/28 13:01:12 step 4: mse=138.866599 step=0.100000
2017/08/28 13:01:13 step 5: mse=137.857116 step=0.100000
2017/08/28 13:01:14 step 6: mse=137.047866 step=0.100000
2017/08/28 13:01:14 step 7: mse=135.821895 step=0.100000
2017/08/28 13:01:14 Saving...
2017/08/28 13:01:14 Gathering batch of experience...
2017/08/28 13:02:16 batch 200: mean=35.508621 stddev=32.034328 entropy=0.585786 frames=4442 count=116
2017/08/28 13:02:16 Training policy...
2017/08/28 13:02:19 step 0: objective=0.41615975
2017/08/28 13:02:20 step 1: objective=0.42571136
2017/08/28 13:02:21 step 2: objective=0.43303186
2017/08/28 13:02:22 step 3: objective=0.43874383
2017/08/28 13:02:22 step 4: objective=0.44415724
2017/08/28 13:02:23 step 5: objective=0.44908655
2017/08/28 13:02:24 step 6: objective=0.45712435
2017/08/28 13:02:25 step 7: objective=0.46188322
2017/08/28 13:02:25 Training value function...
2017/08/28 13:02:27 step 0: mse=124.985139 step=0.100000
2017/08/28 13:02:28 step 1: mse=124.148736 step=0.100000
2017/08/28 13:02:29 step 2: mse=123.157795 step=0.100000
2017/08/28 13:02:30 step 3: mse=122.613493 step=0.100000
2017/08/28 13:02:31 step 4: mse=122.044458 step=0.100000
2017/08/28 13:02:32 step 5: mse=121.043155 step=0.100000
2017/08/28 13:02:33 step 6: mse=120.640548 step=0.100000
2017/08/28 13:02:33 step 7: mse=120.097413 step=0.100000
2017/08/28 13:02:33 Saving...
2017/08/28 13:02:33 Gathering batch of experience...
2017/08/28 13:03:29 batch 201: mean=44.877551 stddev=46.792260 entropy=0.581821 frames=4559 count=98
2017/08/28 13:03:29 Training policy...
2017/08/28 13:03:32 step 0: objective=2.0499208
2017/08/28 13:03:33 step 1: objective=2.0614662
2017/08/28 13:03:34 step 2: objective=2.0716338
2017/08/28 13:03:35 step 3: objective=2.082581
2017/08/28 13:03:36 step 4: objective=2.0890572
2017/08/28 13:03:37 step 5: objective=2.095573
2017/08/28 13:03:38 step 6: objective=2.1028674
2017/08/28 13:03:39 step 7: objective=2.110701
2017/08/28 13:03:39 Training value function...
2017/08/28 13:03:41 step 0: mse=179.445004 step=0.100000
2017/08/28 13:03:42 step 1: mse=174.378860 step=0.100000
2017/08/28 13:03:43 step 2: mse=170.232565 step=0.100000
2017/08/28 13:03:44 step 3: mse=166.779862 step=0.100000
2017/08/28 13:03:45 step 4: mse=163.756775 step=0.100000
2017/08/28 13:03:46 step 5: mse=161.212321 step=0.100000
2017/08/28 13:03:47 step 6: mse=158.977130 step=0.100000
2017/08/28 13:03:48 step 7: mse=156.864506 step=0.100000
2017/08/28 13:03:48 Saving...
2017/08/28 13:03:48 Gathering batch of experience...
2017/08/28 13:04:43 batch 202: mean=40.594059 stddev=40.652641 entropy=0.585768 frames=4367 count=101
2017/08/28 13:04:43 Training policy...
2017/08/28 13:04:46 step 0: objective=0.37066948
2017/08/28 13:04:47 step 1: objective=0.3814374
2017/08/28 13:04:48 step 2: objective=0.3973053
2017/08/28 13:04:49 step 3: objective=0.41392213
2017/08/28 13:04:50 step 4: objective=0.42186865
2017/08/28 13:04:51 step 5: objective=0.43145466
2017/08/28 13:04:52 step 6: objective=0.44090423
2017/08/28 13:04:53 step 7: objective=0.4485442
2017/08/28 13:04:53 Training value function...
2017/08/28 13:04:55 step 0: mse=151.224892 step=0.100000
2017/08/28 13:04:55 step 1: mse=148.390044 step=0.100000
2017/08/28 13:04:56 step 2: mse=145.959657 step=0.100000
2017/08/28 13:04:57 step 3: mse=144.212013 step=0.100000
2017/08/28 13:04:58 step 4: mse=142.824159 step=0.100000
2017/08/28 13:04:59 step 5: mse=141.657039 step=0.100000
2017/08/28 13:05:00 step 6: mse=140.386326 step=0.100000
2017/08/28 13:05:01 step 7: mse=139.136285 step=0.100000
2017/08/28 13:05:01 Saving...
2017/08/28 13:05:01 Gathering batch of experience...
2017/08/28 13:05:55 batch 203: mean=42.670103 stddev=33.045024 entropy=0.586454 frames=4364 count=97
2017/08/28 13:05:55 Training policy...
2017/08/28 13:05:57 step 0: objective=1.0481515
2017/08/28 13:05:58 step 1: objective=1.0596895
2017/08/28 13:05:59 step 2: objective=1.0720881
2017/08/28 13:06:00 step 3: objective=1.0878907
2017/08/28 13:06:01 step 4: objective=1.1002017
2017/08/28 13:06:02 step 5: objective=1.1077079
2017/08/28 13:06:03 step 6: objective=1.1137612
2017/08/28 13:06:04 step 7: objective=1.1251539
2017/08/28 13:06:04 Training value function...
2017/08/28 13:06:06 step 0: mse=138.678323 step=0.100000
2017/08/28 13:06:07 step 1: mse=136.625921 step=0.100000
2017/08/28 13:06:08 step 2: mse=134.805556 step=0.100000
2017/08/28 13:06:08 step 3: mse=133.262260 step=0.100000
2017/08/28 13:06:09 step 4: mse=131.786141 step=0.100000
2017/08/28 13:06:10 step 5: mse=130.596276 step=0.100000
2017/08/28 13:06:11 step 6: mse=129.638936 step=0.100000
2017/08/28 13:06:12 step 7: mse=128.567689 step=0.100000
2017/08/28 13:06:12 Saving...
2017/08/28 13:06:12 Gathering batch of experience...
2017/08/28 13:07:06 batch 204: mean=42.505051 stddev=40.778627 entropy=0.588006 frames=4336 count=99
2017/08/28 13:07:06 Training policy...
2017/08/28 13:07:09 step 0: objective=1.3362627
2017/08/28 13:07:09 step 1: objective=1.3501533
2017/08/28 13:07:10 step 2: objective=1.360967
2017/08/28 13:07:11 step 3: objective=1.367937
2017/08/28 13:07:12 step 4: objective=1.3778803
2017/08/28 13:07:13 step 5: objective=1.3901335
2017/08/28 13:07:14 step 6: objective=1.3965497
2017/08/28 13:07:15 step 7: objective=1.4086457
2017/08/28 13:07:15 Training value function...
2017/08/28 13:07:17 step 0: mse=158.708223 step=0.100000
2017/08/28 13:07:18 step 1: mse=157.015260 step=0.100000
2017/08/28 13:07:19 step 2: mse=155.197966 step=0.100000
2017/08/28 13:07:19 step 3: mse=153.740947 step=0.100000
2017/08/28 13:07:20 step 4: mse=152.345896 step=0.100000
2017/08/28 13:07:21 step 5: mse=150.785035 step=0.100000
2017/08/28 13:07:22 step 6: mse=149.540253 step=0.100000
2017/08/28 13:07:23 step 7: mse=148.280603 step=0.100000
2017/08/28 13:07:23 Saving...
2017/08/28 13:07:23 Gathering batch of experience...
2017/08/28 13:08:21 batch 205: mean=39.305556 stddev=33.436634 entropy=0.586407 frames=4412 count=108
2017/08/28 13:08:21 Training policy...
2017/08/28 13:08:24 step 0: objective=0.3472312
2017/08/28 13:08:25 step 1: objective=0.35471502
2017/08/28 13:08:26 step 2: objective=0.36515313
2017/08/28 13:08:27 step 3: objective=0.3723413
2017/08/28 13:08:28 step 4: objective=0.38703614
2017/08/28 13:08:29 step 5: objective=0.39619938
2017/08/28 13:08:30 step 6: objective=0.4056607
2017/08/28 13:08:31 step 7: objective=0.41276434
2017/08/28 13:08:31 Training value function...
2017/08/28 13:08:32 step 0: mse=140.839630 step=0.100000
2017/08/28 13:08:33 step 1: mse=139.495066 step=0.100000
2017/08/28 13:08:34 step 2: mse=138.199561 step=0.100000
2017/08/28 13:08:35 step 3: mse=137.173124 step=0.100000
2017/08/28 13:08:36 step 4: mse=136.244486 step=0.100000
2017/08/28 13:08:37 step 5: mse=135.256143 step=0.100000
2017/08/28 13:08:38 step 6: mse=134.326182 step=0.100000
2017/08/28 13:08:39 step 7: mse=133.527678 step=0.100000
2017/08/28 13:08:39 Saving...
2017/08/28 13:08:39 Gathering batch of experience...
2017/08/28 13:09:31 batch 206: mean=54.839080 stddev=50.691511 entropy=0.587403 frames=4897 count=87
2017/08/28 13:09:31 Training policy...
2017/08/28 13:09:34 step 0: objective=2.3916204
2017/08/28 13:09:35 step 1: objective=2.413184
2017/08/28 13:09:36 step 2: objective=2.4243748
2017/08/28 13:09:38 step 3: objective=2.4338896
2017/08/28 13:09:39 step 4: objective=2.4473307
2017/08/28 13:09:40 step 5: objective=2.4549677
2017/08/28 13:09:41 step 6: objective=2.4618614
2017/08/28 13:09:42 step 7: objective=2.4663925
2017/08/28 13:09:42 Training value function...
2017/08/28 13:09:44 step 0: mse=199.927193 step=0.100000
2017/08/28 13:09:45 step 1: mse=195.149230 step=0.100000
2017/08/28 13:09:46 step 2: mse=190.874379 step=0.100000
2017/08/28 13:09:47 step 3: mse=187.411235 step=0.100000
2017/08/28 13:09:48 step 4: mse=184.526418 step=0.100000
2017/08/28 13:09:49 step 5: mse=181.827221 step=0.100000
2017/08/28 13:09:50 step 6: mse=179.777723 step=0.100000
2017/08/28 13:09:51 step 7: mse=177.731365 step=0.100000
2017/08/28 13:09:51 Saving...
2017/08/28 13:09:51 Gathering batch of experience...
2017/08/28 13:10:46 batch 207: mean=44.845361 stddev=47.319781 entropy=0.577611 frames=4588 count=97
2017/08/28 13:10:46 Training policy...
2017/08/28 13:10:49 step 0: objective=0.49057254
2017/08/28 13:10:50 step 1: objective=0.50322807
2017/08/28 13:10:51 step 2: objective=0.512966
2017/08/28 13:10:52 step 3: objective=0.5237921
2017/08/28 13:10:53 step 4: objective=0.5322049
2017/08/28 13:10:54 step 5: objective=0.5403842
2017/08/28 13:10:55 step 6: objective=0.5469803
2017/08/28 13:10:56 step 7: objective=0.5520904
2017/08/28 13:10:56 Training value function...
2017/08/28 13:10:58 step 0: mse=162.978358 step=0.100000
2017/08/28 13:10:59 step 1: mse=160.550276 step=0.100000
2017/08/28 13:11:00 step 2: mse=158.136866 step=0.100000
2017/08/28 13:11:01 step 3: mse=156.029623 step=0.100000
2017/08/28 13:11:02 step 4: mse=154.301388 step=0.100000
2017/08/28 13:11:03 step 5: mse=152.666700 step=0.100000
2017/08/28 13:11:03 step 6: mse=151.051914 step=0.100000
2017/08/28 13:11:04 step 7: mse=149.792481 step=0.100000
2017/08/28 13:11:04 Saving...
2017/08/28 13:11:04 Gathering batch of experience...
2017/08/28 13:12:02 batch 208: mean=40.907407 stddev=41.941877 entropy=0.588323 frames=4665 count=108
2017/08/28 13:12:02 Training policy...
2017/08/28 13:12:05 step 0: objective=0.33044463
2017/08/28 13:12:06 step 1: objective=0.34934595
2017/08/28 13:12:07 step 2: objective=0.35825524
2017/08/28 13:12:08 step 3: objective=0.36599958
2017/08/28 13:12:09 step 4: objective=0.37898794
2017/08/28 13:12:10 step 5: objective=0.38827303
2017/08/28 13:12:11 step 6: objective=0.39595202
2017/08/28 13:12:12 step 7: objective=0.4064229
2017/08/28 13:12:12 Training value function...
2017/08/28 13:12:14 step 0: mse=144.116219 step=0.100000
2017/08/28 13:12:15 step 1: mse=142.727892 step=0.100000
2017/08/28 13:12:16 step 2: mse=141.979177 step=0.100000
2017/08/28 13:12:17 step 3: mse=141.289859 step=0.100000
2017/08/28 13:12:18 step 4: mse=140.610805 step=0.100000
2017/08/28 13:12:19 step 5: mse=139.948121 step=0.100000
2017/08/28 13:12:20 step 6: mse=138.922496 step=0.100000
2017/08/28 13:12:21 step 7: mse=138.355502 step=0.100000
2017/08/28 13:12:21 Saving...
2017/08/28 13:12:21 Gathering batch of experience...
2017/08/28 13:13:21 batch 209: mean=39.455357 stddev=33.433807 entropy=0.572043 frames=4466 count=112
2017/08/28 13:13:21 Training policy...
2017/08/28 13:13:24 step 0: objective=0.60673547
2017/08/28 13:13:25 step 1: objective=0.62370104
2017/08/28 13:13:26 step 2: objective=0.63438874
2017/08/28 13:13:27 step 3: objective=0.6450816
2017/08/28 13:13:28 step 4: objective=0.6564678
2017/08/28 13:13:28 step 5: objective=0.6636086
2017/08/28 13:13:29 step 6: objective=0.6709509
2017/08/28 13:13:30 step 7: objective=0.6756268
2017/08/28 13:13:30 Training value function...
2017/08/28 13:13:32 step 0: mse=132.984967 step=0.100000
2017/08/28 13:13:33 step 1: mse=130.836218 step=0.100000
2017/08/28 13:13:34 step 2: mse=128.899264 step=0.100000
2017/08/28 13:13:35 step 3: mse=127.439517 step=0.100000
2017/08/28 13:13:36 step 4: mse=125.998214 step=0.100000
2017/08/28 13:13:37 step 5: mse=124.943519 step=0.100000
2017/08/28 13:13:38 step 6: mse=124.097147 step=0.100000
2017/08/28 13:13:38 step 7: mse=122.905056 step=0.100000
2017/08/28 13:13:38 Saving...
2017/08/28 13:13:38 Gathering batch of experience...
2017/08/28 13:14:39 batch 210: mean=34.940678 stddev=31.182430 entropy=0.574993 frames=4403 count=118
2017/08/28 13:14:39 Training policy...
2017/08/28 13:14:42 step 0: objective=0.0873249
2017/08/28 13:14:43 step 1: objective=0.09626202
2017/08/28 13:14:44 step 2: objective=0.10716255
2017/08/28 13:14:45 step 3: objective=0.11620777
2017/08/28 13:14:46 step 4: objective=0.12342288
2017/08/28 13:14:47 step 5: objective=0.12915772
2017/08/28 13:14:48 step 6: objective=0.14247435
2017/08/28 13:14:49 step 7: objective=0.15056859
2017/08/28 13:14:49 Training value function...
2017/08/28 13:14:51 step 0: mse=131.526540 step=0.100000
2017/08/28 13:14:52 step 1: mse=130.458018 step=0.100000
2017/08/28 13:14:52 step 2: mse=129.566046 step=0.100000
2017/08/28 13:14:53 step 3: mse=128.647314 step=0.100000
2017/08/28 13:14:54 step 4: mse=128.065606 step=0.100000
2017/08/28 13:14:55 step 5: mse=127.196017 step=0.100000
2017/08/28 13:14:56 step 6: mse=126.345603 step=0.100000
2017/08/28 13:14:57 step 7: mse=125.332965 step=0.100000
2017/08/28 13:14:57 Saving...
2017/08/28 13:14:57 Gathering batch of experience...
2017/08/28 13:15:50 batch 211: mean=43.526316 stddev=42.806503 entropy=0.571207 frames=4438 count=95
2017/08/28 13:15:50 Training policy...
2017/08/28 13:15:53 step 0: objective=1.3231674
2017/08/28 13:15:54 step 1: objective=1.3360517
2017/08/28 13:15:55 step 2: objective=1.3458251
2017/08/28 13:15:56 step 3: objective=1.3557667
2017/08/28 13:15:57 step 4: objective=1.3633986
2017/08/28 13:15:58 step 5: objective=1.3724357
2017/08/28 13:15:59 step 6: objective=1.3818567
2017/08/28 13:16:00 step 7: objective=1.3915571
2017/08/28 13:16:00 Training value function...
2017/08/28 13:16:01 step 0: mse=160.870362 step=0.100000
2017/08/28 13:16:02 step 1: mse=158.391518 step=0.100000
2017/08/28 13:16:03 step 2: mse=156.157026 step=0.100000
2017/08/28 13:16:04 step 3: mse=153.886990 step=0.100000
2017/08/28 13:16:05 step 4: mse=152.651314 step=0.100000
2017/08/28 13:16:06 step 5: mse=151.054904 step=0.100000
2017/08/28 13:16:07 step 6: mse=149.024073 step=0.100000
2017/08/28 13:16:08 step 7: mse=147.442116 step=0.100000
2017/08/28 13:16:08 Saving...
2017/08/28 13:16:08 Gathering batch of experience...
2017/08/28 13:17:01 batch 212: mean=43.448980 stddev=40.196741 entropy=0.580909 frames=4330 count=98
2017/08/28 13:17:01 Training policy...
2017/08/28 13:17:04 step 0: objective=1.3299725
2017/08/28 13:17:05 step 1: objective=1.3464195
2017/08/28 13:17:06 step 2: objective=1.3586054
2017/08/28 13:17:07 step 3: objective=1.37427
2017/08/28 13:17:08 step 4: objective=1.3856025
2017/08/28 13:17:09 step 5: objective=1.3932552
2017/08/28 13:17:10 step 6: objective=1.4023547
2017/08/28 13:17:11 step 7: objective=1.4103442
2017/08/28 13:17:11 Training value function...
2017/08/28 13:17:12 step 0: mse=168.686912 step=0.100000
2017/08/28 13:17:13 step 1: mse=165.696198 step=0.100000
2017/08/28 13:17:14 step 2: mse=162.994832 step=0.100000
2017/08/28 13:17:15 step 3: mse=160.226018 step=0.100000
2017/08/28 13:17:16 step 4: mse=158.234602 step=0.100000
2017/08/28 13:17:17 step 5: mse=156.305934 step=0.100000
2017/08/28 13:17:18 step 6: mse=154.564811 step=0.100000
2017/08/28 13:17:19 step 7: mse=152.810559 step=0.100000
2017/08/28 13:17:19 Saving...
2017/08/28 13:17:19 Gathering batch of experience...
2017/08/28 13:18:14 batch 213: mean=42.480392 stddev=48.911230 entropy=0.575397 frames=4375 count=102
2017/08/28 13:18:14 Training policy...
2017/08/28 13:18:17 step 0: objective=1.3103881
2017/08/28 13:18:18 step 1: objective=1.3271348
2017/08/28 13:18:18 step 2: objective=1.3412358
2017/08/28 13:18:19 step 3: objective=1.3483436
2017/08/28 13:18:20 step 4: objective=1.3638482
2017/08/28 13:18:21 step 5: objective=1.3718256
2017/08/28 13:18:22 step 6: objective=1.3809273
2017/08/28 13:18:23 step 7: objective=1.3907346
2017/08/28 13:18:23 Training value function...
2017/08/28 13:18:25 step 0: mse=195.374684 step=0.100000
2017/08/28 13:18:26 step 1: mse=190.886188 step=0.100000
2017/08/28 13:18:27 step 2: mse=187.129512 step=0.100000
2017/08/28 13:18:28 step 3: mse=184.044984 step=0.100000
2017/08/28 13:18:29 step 4: mse=181.296577 step=0.100000
2017/08/28 13:18:30 step 5: mse=178.884624 step=0.100000
2017/08/28 13:18:30 step 6: mse=176.236118 step=0.100000
2017/08/28 13:18:31 step 7: mse=173.988526 step=0.100000
2017/08/28 13:18:31 Saving...
2017/08/28 13:18:31 Gathering batch of experience...
2017/08/28 13:19:22 batch 214: mean=57.378049 stddev=63.265341 entropy=0.574240 frames=4698 count=82
2017/08/28 13:19:22 Training policy...
2017/08/28 13:19:25 step 0: objective=2.0242245
2017/08/28 13:19:26 step 1: objective=2.0465245
2017/08/28 13:19:27 step 2: objective=2.0583866
2017/08/28 13:19:28 step 3: objective=2.0719252
2017/08/28 13:19:29 step 4: objective=2.0843337
2017/08/28 13:19:30 step 5: objective=2.09942
2017/08/28 13:19:31 step 6: objective=2.1104083
2017/08/28 13:19:32 step 7: objective=2.1157355
2017/08/28 13:19:32 Training value function...
2017/08/28 13:19:34 step 0: mse=228.837640 step=0.100000
2017/08/28 13:19:35 step 1: mse=223.768049 step=0.100000
2017/08/28 13:19:36 step 2: mse=219.222937 step=0.100000
2017/08/28 13:19:37 step 3: mse=215.612806 step=0.100000
2017/08/28 13:19:38 step 4: mse=212.199423 step=0.100000
2017/08/28 13:19:39 step 5: mse=209.327503 step=0.100000
2017/08/28 13:19:40 step 6: mse=206.516897 step=0.100000
2017/08/28 13:19:41 step 7: mse=203.973538 step=0.100000
2017/08/28 13:19:41 Saving...
2017/08/28 13:19:41 Gathering batch of experience...
2017/08/28 13:20:31 batch 215: mean=49.471264 stddev=43.978793 entropy=0.570374 frames=4397 count=87
2017/08/28 13:20:31 Training policy...
2017/08/28 13:20:34 step 0: objective=0.5105811
2017/08/28 13:20:34 step 1: objective=0.5226526
2017/08/28 13:20:35 step 2: objective=0.5332054
2017/08/28 13:20:36 step 3: objective=0.54339075
2017/08/28 13:20:37 step 4: objective=0.5564903
2017/08/28 13:20:38 step 5: objective=0.56732446
2017/08/28 13:20:39 step 6: objective=0.574464
2017/08/28 13:20:40 step 7: objective=0.58119065
2017/08/28 13:20:40 Training value function...
2017/08/28 13:20:42 step 0: mse=160.891153 step=0.100000
2017/08/28 13:20:43 step 1: mse=159.073298 step=0.100000
2017/08/28 13:20:44 step 2: mse=157.727020 step=0.100000
2017/08/28 13:20:45 step 3: mse=155.990539 step=0.100000
2017/08/28 13:20:46 step 4: mse=155.044765 step=0.100000
2017/08/28 13:20:46 step 5: mse=153.010989 step=0.100000
2017/08/28 13:20:47 step 6: mse=152.077274 step=0.100000
2017/08/28 13:20:48 step 7: mse=151.320794 step=0.100000
2017/08/28 13:20:48 Saving...
2017/08/28 13:20:48 Gathering batch of experience...
2017/08/28 13:21:45 batch 216: mean=46.070707 stddev=48.621451 entropy=0.578644 frames=4926 count=99
2017/08/28 13:21:45 Training policy...
2017/08/28 13:21:48 step 0: objective=0.23569964
2017/08/28 13:21:49 step 1: objective=0.24416432
2017/08/28 13:21:50 step 2: objective=0.26031676
2017/08/28 13:21:51 step 3: objective=0.2709734
2017/08/28 13:21:53 step 4: objective=0.28548792
2017/08/28 13:21:54 step 5: objective=0.2960178
2017/08/28 13:21:55 step 6: objective=0.30188414
2017/08/28 13:21:56 step 7: objective=0.30804902
2017/08/28 13:21:56 Training value function...
2017/08/28 13:21:58 step 0: mse=153.223463 step=0.100000
2017/08/28 13:21:59 step 1: mse=151.520897 step=0.100000
2017/08/28 13:22:00 step 2: mse=150.696060 step=0.100000
2017/08/28 13:22:01 step 3: mse=149.445834 step=0.100000
2017/08/28 13:22:02 step 4: mse=148.515723 step=0.100000
2017/08/28 13:22:03 step 5: mse=147.500924 step=0.100000
2017/08/28 13:22:04 step 6: mse=146.846068 step=0.100000
2017/08/28 13:22:05 step 7: mse=145.747513 step=0.100000
2017/08/28 13:22:05 Saving...
2017/08/28 13:22:05 Gathering batch of experience...
2017/08/28 13:22:58 batch 217: mean=53.566667 stddev=51.219365 entropy=0.577999 frames=4612 count=90
2017/08/28 13:22:58 Training policy...
2017/08/28 13:23:01 step 0: objective=2.0750475
2017/08/28 13:23:02 step 1: objective=2.0896688
2017/08/28 13:23:03 step 2: objective=2.1026194
2017/08/28 13:23:04 step 3: objective=2.114361
2017/08/28 13:23:05 step 4: objective=2.1216266
2017/08/28 13:23:06 step 5: objective=2.134665
2017/08/28 13:23:07 step 6: objective=2.1460025
2017/08/28 13:23:08 step 7: objective=2.1538897
2017/08/28 13:23:08 Training value function...
2017/08/28 13:23:10 step 0: mse=219.588477 step=0.100000
2017/08/28 13:23:11 step 1: mse=215.395723 step=0.100000
2017/08/28 13:23:12 step 2: mse=211.445248 step=0.100000
2017/08/28 13:23:13 step 3: mse=207.508321 step=0.100000
2017/08/28 13:23:14 step 4: mse=204.591795 step=0.100000
2017/08/28 13:23:15 step 5: mse=202.093345 step=0.100000
2017/08/28 13:23:16 step 6: mse=199.374885 step=0.100000
2017/08/28 13:23:17 step 7: mse=197.104755 step=0.100000
2017/08/28 13:23:17 Saving...
2017/08/28 13:23:17 Gathering batch of experience...
2017/08/28 13:24:07 batch 218: mean=47.393258 stddev=59.008972 entropy=0.576846 frames=4356 count=89
2017/08/28 13:24:07 Training policy...
2017/08/28 13:24:10 step 0: objective=0.44383934
2017/08/28 13:24:11 step 1: objective=0.4556933
2017/08/28 13:24:12 step 2: objective=0.47610638
2017/08/28 13:24:13 step 3: objective=0.49073875
2017/08/28 13:24:14 step 4: objective=0.5014014
2017/08/28 13:24:15 step 5: objective=0.50777686
2017/08/28 13:24:16 step 6: objective=0.5143255
2017/08/28 13:24:17 step 7: objective=0.52256334
2017/08/28 13:24:17 Training value function...
2017/08/28 13:24:18 step 0: mse=181.138488 step=0.100000
2017/08/28 13:24:19 step 1: mse=176.544933 step=0.100000
2017/08/28 13:24:20 step 2: mse=173.173364 step=0.100000
2017/08/28 13:24:21 step 3: mse=169.893028 step=0.100000
2017/08/28 13:24:22 step 4: mse=167.386049 step=0.100000
2017/08/28 13:24:23 step 5: mse=164.881420 step=0.100000
2017/08/28 13:24:24 step 6: mse=162.992947 step=0.100000
2017/08/28 13:24:25 step 7: mse=161.246766 step=0.100000
2017/08/28 13:24:25 Saving...
2017/08/28 13:24:25 Gathering batch of experience...
2017/08/28 13:25:20 batch 219: mean=42.920792 stddev=40.801059 entropy=0.569478 frames=4351 count=101
2017/08/28 13:25:20 Training policy...
2017/08/28 13:25:23 step 0: objective=0.3430469
2017/08/28 13:25:24 step 1: objective=0.35770285
2017/08/28 13:25:24 step 2: objective=0.3711376
2017/08/28 13:25:25 step 3: objective=0.38278255
2017/08/28 13:25:26 step 4: objective=0.39457336
2017/08/28 13:25:27 step 5: objective=0.4044382
2017/08/28 13:25:28 step 6: objective=0.41333333
2017/08/28 13:25:29 step 7: objective=0.42008495
2017/08/28 13:25:29 Training value function...
2017/08/28 13:25:31 step 0: mse=151.814700 step=0.100000
2017/08/28 13:25:32 step 1: mse=150.113652 step=0.100000
2017/08/28 13:25:33 step 2: mse=148.950741 step=0.100000
2017/08/28 13:25:34 step 3: mse=147.856898 step=0.100000
2017/08/28 13:25:35 step 4: mse=146.998986 step=0.100000
2017/08/28 13:25:35 step 5: mse=146.359710 step=0.100000
2017/08/28 13:25:36 step 6: mse=145.351700 step=0.100000
2017/08/28 13:25:37 step 7: mse=144.783844 step=0.100000
2017/08/28 13:25:37 Saving...
2017/08/28 13:25:37 Gathering batch of experience...
2017/08/28 13:26:34 batch 220: mean=38.700935 stddev=34.323152 entropy=0.568877 frames=4307 count=107
2017/08/28 13:26:34 Training policy...
2017/08/28 13:26:36 step 0: objective=0.11655145
2017/08/28 13:26:37 step 1: objective=0.12868313
2017/08/28 13:26:38 step 2: objective=0.1436075
2017/08/28 13:26:39 step 3: objective=0.16192475
2017/08/28 13:26:40 step 4: objective=0.17723002
2017/08/28 13:26:41 step 5: objective=0.18300103
2017/08/28 13:26:42 step 6: objective=0.19173612
2017/08/28 13:26:43 step 7: objective=0.19927022
2017/08/28 13:26:43 Training value function...
2017/08/28 13:26:45 step 0: mse=146.405682 step=0.100000
2017/08/28 13:26:45 step 1: mse=144.462201 step=0.100000
2017/08/28 13:26:46 step 2: mse=142.790934 step=0.100000
2017/08/28 13:26:47 step 3: mse=141.604980 step=0.100000
2017/08/28 13:26:48 step 4: mse=140.674667 step=0.100000
2017/08/28 13:26:49 step 5: mse=139.753208 step=0.100000
2017/08/28 13:26:50 step 6: mse=138.950008 step=0.100000
2017/08/28 13:26:51 step 7: mse=138.389893 step=0.100000
2017/08/28 13:26:51 Saving...
2017/08/28 13:26:51 Gathering batch of experience...
2017/08/28 13:27:46 batch 221: mean=48.389474 stddev=41.895684 entropy=0.570492 frames=4809 count=95
2017/08/28 13:27:46 Training policy...
2017/08/28 13:27:50 step 0: objective=1.2914066
2017/08/28 13:27:51 step 1: objective=1.3032347
2017/08/28 13:27:52 step 2: objective=1.3141627
2017/08/28 13:27:53 step 3: objective=1.3225065
2017/08/28 13:27:54 step 4: objective=1.3302597
2017/08/28 13:27:55 step 5: objective=1.3365906
2017/08/28 13:27:56 step 6: objective=1.3473973
2017/08/28 13:27:57 step 7: objective=1.3531455
2017/08/28 13:27:57 Training value function...
2017/08/28 13:27:59 step 0: mse=133.626958 step=0.100000
2017/08/28 13:28:00 step 1: mse=131.341068 step=0.100000
2017/08/28 13:28:01 step 2: mse=129.540978 step=0.100000
2017/08/28 13:28:02 step 3: mse=127.863289 step=0.100000
2017/08/28 13:28:03 step 4: mse=126.303298 step=0.100000
2017/08/28 13:28:04 step 5: mse=124.699867 step=0.100000
2017/08/28 13:28:05 step 6: mse=123.572206 step=0.100000
2017/08/28 13:28:06 step 7: mse=122.354679 step=0.100000
2017/08/28 13:28:06 Saving...
2017/08/28 13:28:06 Gathering batch of experience...
2017/08/28 13:28:58 batch 222: mean=48.130435 stddev=51.174513 entropy=0.576592 frames=4293 count=92
2017/08/28 13:28:58 Training policy...
2017/08/28 13:29:00 step 0: objective=1.684131
2017/08/28 13:29:01 step 1: objective=1.7093742
2017/08/28 13:29:02 step 2: objective=1.7285794
2017/08/28 13:29:03 step 3: objective=1.7413045
2017/08/28 13:29:04 step 4: objective=1.7552412
2017/08/28 13:29:05 step 5: objective=1.7637194
2017/08/28 13:29:06 step 6: objective=1.7703111
2017/08/28 13:29:07 step 7: objective=1.7757903
2017/08/28 13:29:07 Training value function...
2017/08/28 13:29:09 step 0: mse=207.168184 step=0.100000
2017/08/28 13:29:10 step 1: mse=202.462317 step=0.100000
2017/08/28 13:29:10 step 2: mse=198.783455 step=0.100000
2017/08/28 13:29:11 step 3: mse=195.247060 step=0.100000
2017/08/28 13:29:12 step 4: mse=192.556008 step=0.100000
2017/08/28 13:29:13 step 5: mse=189.623174 step=0.100000
2017/08/28 13:29:14 step 6: mse=187.151348 step=0.100000
2017/08/28 13:29:15 step 7: mse=185.075351 step=0.100000
2017/08/28 13:29:15 Saving...
2017/08/28 13:29:15 Gathering batch of experience...
2017/08/28 13:30:06 batch 223: mean=50.988764 stddev=47.727338 entropy=0.575804 frames=4595 count=89
2017/08/28 13:30:06 Training policy...
2017/08/28 13:30:09 step 0: objective=1.129378
2017/08/28 13:30:10 step 1: objective=1.1402742
2017/08/28 13:30:11 step 2: objective=1.1518914
2017/08/28 13:30:12 step 3: objective=1.1600872
2017/08/28 13:30:13 step 4: objective=1.172032
2017/08/28 13:30:14 step 5: objective=1.178274
2017/08/28 13:30:15 step 6: objective=1.1855044
2017/08/28 13:30:16 step 7: objective=1.1921306
2017/08/28 13:30:16 Training value function...
2017/08/28 13:30:18 step 0: mse=167.568552 step=0.100000
2017/08/28 13:30:19 step 1: mse=166.397346 step=0.100000
2017/08/28 13:30:20 step 2: mse=164.409776 step=0.100000
2017/08/28 13:30:21 step 3: mse=163.245889 step=0.100000
2017/08/28 13:30:22 step 4: mse=161.648145 step=0.100000
2017/08/28 13:30:23 step 5: mse=160.497022 step=0.100000
2017/08/28 13:30:24 step 6: mse=159.205814 step=0.100000
2017/08/28 13:30:25 step 7: mse=157.986532 step=0.100000
2017/08/28 13:30:25 Saving...
2017/08/28 13:30:25 Gathering batch of experience...
2017/08/28 13:31:19 batch 224: mean=44.918367 stddev=38.664880 entropy=0.557195 frames=4420 count=98
2017/08/28 13:31:19 Training policy...
2017/08/28 13:31:22 step 0: objective=0.83381134
2017/08/28 13:31:23 step 1: objective=0.8430372
2017/08/28 13:31:24 step 2: objective=0.8574691
2017/08/28 13:31:25 step 3: objective=0.8652168
2017/08/28 13:31:25 step 4: objective=0.8763696
2017/08/28 13:31:26 step 5: objective=0.88171756
2017/08/28 13:31:27 step 6: objective=0.88985455
2017/08/28 13:31:28 step 7: objective=0.8953851
2017/08/28 13:31:28 Training value function...
2017/08/28 13:31:30 step 0: mse=168.899107 step=0.100000
2017/08/28 13:31:31 step 1: mse=167.684728 step=0.100000
2017/08/28 13:31:32 step 2: mse=166.323536 step=0.100000
2017/08/28 13:31:33 step 3: mse=165.026393 step=0.100000
2017/08/28 13:31:34 step 4: mse=163.829216 step=0.100000
2017/08/28 13:31:35 step 5: mse=162.937512 step=0.100000
2017/08/28 13:31:36 step 6: mse=162.031202 step=0.100000
2017/08/28 13:31:37 step 7: mse=161.288397 step=0.100000
2017/08/28 13:31:37 Saving...
2017/08/28 13:31:37 Gathering batch of experience...
2017/08/28 13:32:34 batch 225: mean=46.750000 stddev=39.552592 entropy=0.558719 frames=4765 count=100
2017/08/28 13:32:34 Training policy...
2017/08/28 13:32:37 step 0: objective=0.7036659
2017/08/28 13:32:38 step 1: objective=0.7152359
2017/08/28 13:32:39 step 2: objective=0.72343165
2017/08/28 13:32:40 step 3: objective=0.7358532
2017/08/28 13:32:41 step 4: objective=0.74280894
2017/08/28 13:32:42 step 5: objective=0.75098103
2017/08/28 13:32:43 step 6: objective=0.7602173
2017/08/28 13:32:44 step 7: objective=0.7688031
2017/08/28 13:32:44 Training value function...
2017/08/28 13:32:46 step 0: mse=150.153147 step=0.100000
2017/08/28 13:32:47 step 1: mse=148.585056 step=0.100000
2017/08/28 13:32:48 step 2: mse=147.112466 step=0.100000
2017/08/28 13:32:49 step 3: mse=145.785091 step=0.100000
2017/08/28 13:32:50 step 4: mse=144.471337 step=0.100000
2017/08/28 13:32:51 step 5: mse=143.175499 step=0.100000
2017/08/28 13:32:52 step 6: mse=142.175260 step=0.100000
2017/08/28 13:32:53 step 7: mse=141.291152 step=0.100000
2017/08/28 13:32:53 Saving...
2017/08/28 13:32:53 Gathering batch of experience...
2017/08/28 13:33:45 batch 226: mean=48.967033 stddev=45.053924 entropy=0.565653 frames=4452 count=91
2017/08/28 13:33:45 Training policy...
2017/08/28 13:33:48 step 0: objective=1.1896276
2017/08/28 13:33:49 step 1: objective=1.2026168
2017/08/28 13:33:50 step 2: objective=1.2147967
2017/08/28 13:33:51 step 3: objective=1.2278675
2017/08/28 13:33:52 step 4: objective=1.2406274
2017/08/28 13:33:53 step 5: objective=1.247393
2017/08/28 13:33:54 step 6: objective=1.2599338
2017/08/28 13:33:55 step 7: objective=1.26614
2017/08/28 13:33:55 Training value function...
2017/08/28 13:33:57 step 0: mse=179.736087 step=0.100000
2017/08/28 13:33:58 step 1: mse=177.532315 step=0.100000
2017/08/28 13:33:58 step 2: mse=176.028293 step=0.100000
2017/08/28 13:33:59 step 3: mse=174.450531 step=0.100000
2017/08/28 13:34:00 step 4: mse=172.761878 step=0.100000
2017/08/28 13:34:01 step 5: mse=171.136257 step=0.100000
2017/08/28 13:34:02 step 6: mse=169.572412 step=0.100000
2017/08/28 13:34:03 step 7: mse=168.217170 step=0.100000
2017/08/28 13:34:03 Saving...
2017/08/28 13:34:03 Gathering batch of experience...
2017/08/28 13:35:00 batch 227: mean=37.633028 stddev=31.649358 entropy=0.563361 frames=4298 count=109
2017/08/28 13:35:00 Training policy...
2017/08/28 13:35:03 step 0: objective=-0.49851176
2017/08/28 13:35:04 step 1: objective=-0.48799992
2017/08/28 13:35:05 step 2: objective=-0.4775921
2017/08/28 13:35:06 step 3: objective=-0.4705428
2017/08/28 13:35:06 step 4: objective=-0.45851776
2017/08/28 13:35:07 step 5: objective=-0.4498756
2017/08/28 13:35:08 step 6: objective=-0.44039178
2017/08/28 13:35:09 step 7: objective=-0.4339467
2017/08/28 13:35:09 Training value function...
2017/08/28 13:35:11 step 0: mse=124.700695 step=0.100000
2017/08/28 13:35:12 step 1: mse=122.191731 step=0.100000
2017/08/28 13:35:13 step 2: mse=120.514256 step=0.100000
2017/08/28 13:35:14 step 3: mse=118.746362 step=0.100000
2017/08/28 13:35:15 step 4: mse=117.471605 step=0.100000
2017/08/28 13:35:15 step 5: mse=116.160304 step=0.100000
2017/08/28 13:35:16 step 6: mse=114.939127 step=0.100000
2017/08/28 13:35:17 step 7: mse=114.076983 step=0.100000
2017/08/28 13:35:17 Saving...
2017/08/28 13:35:17 Gathering batch of experience...
2017/08/28 13:36:09 batch 228: mean=50.550562 stddev=46.883554 entropy=0.559035 frames=4512 count=89
2017/08/28 13:36:09 Training policy...
2017/08/28 13:36:12 step 0: objective=1.8095454
2017/08/28 13:36:13 step 1: objective=1.8211259
2017/08/28 13:36:14 step 2: objective=1.836184
2017/08/28 13:36:15 step 3: objective=1.8484447
2017/08/28 13:36:16 step 4: objective=1.8555192
2017/08/28 13:36:17 step 5: objective=1.864183
2017/08/28 13:36:18 step 6: objective=1.8759439
2017/08/28 13:36:19 step 7: objective=1.8855422
2017/08/28 13:36:19 Training value function...
2017/08/28 13:36:21 step 0: mse=200.059084 step=0.100000
2017/08/28 13:36:22 step 1: mse=197.144546 step=0.100000
2017/08/28 13:36:23 step 2: mse=194.093568 step=0.100000
2017/08/28 13:36:23 step 3: mse=191.319332 step=0.100000
2017/08/28 13:36:24 step 4: mse=188.981052 step=0.100000
2017/08/28 13:36:25 step 5: mse=187.219941 step=0.100000
2017/08/28 13:36:26 step 6: mse=185.047973 step=0.100000
2017/08/28 13:36:27 step 7: mse=183.556047 step=0.100000
2017/08/28 13:36:27 Saving...
2017/08/28 13:36:27 Gathering batch of experience...
2017/08/28 13:37:24 batch 229: mean=43.841584 stddev=42.320262 entropy=0.556327 frames=4572 count=101
2017/08/28 13:37:24 Training policy...
2017/08/28 13:37:27 step 0: objective=0.6469552
2017/08/28 13:37:28 step 1: objective=0.6586429
2017/08/28 13:37:29 step 2: objective=0.66950256
2017/08/28 13:37:30 step 3: objective=0.6791739
2017/08/28 13:37:31 step 4: objective=0.68607783
2017/08/28 13:37:32 step 5: objective=0.6971802
2017/08/28 13:37:33 step 6: objective=0.70336217
2017/08/28 13:37:34 step 7: objective=0.7169741
2017/08/28 13:37:34 Training value function...
2017/08/28 13:37:36 step 0: mse=187.509390 step=0.100000
2017/08/28 13:37:37 step 1: mse=185.910974 step=0.100000
2017/08/28 13:37:38 step 2: mse=184.098414 step=0.100000
2017/08/28 13:37:39 step 3: mse=182.624314 step=0.100000
2017/08/28 13:37:40 step 4: mse=181.231216 step=0.100000
2017/08/28 13:37:41 step 5: mse=179.851283 step=0.100000
2017/08/28 13:37:41 step 6: mse=178.845623 step=0.100000
2017/08/28 13:37:42 step 7: mse=177.999384 step=0.100000
2017/08/28 13:37:42 Saving...
2017/08/28 13:37:42 Gathering batch of experience...
2017/08/28 13:38:33 batch 230: mean=47.563218 stddev=39.015087 entropy=0.557210 frames=4477 count=87
2017/08/28 13:38:33 Training policy...
2017/08/28 13:38:36 step 0: objective=0.5055055
2017/08/28 13:38:37 step 1: objective=0.5183282
2017/08/28 13:38:38 step 2: objective=0.53030694
2017/08/28 13:38:39 step 3: objective=0.5400087
2017/08/28 13:38:40 step 4: objective=0.54715997
2017/08/28 13:38:41 step 5: objective=0.55471987
2017/08/28 13:38:42 step 6: objective=0.5611101
2017/08/28 13:38:43 step 7: objective=0.5708588
2017/08/28 13:38:43 Training value function...
2017/08/28 13:38:45 step 0: mse=122.757225 step=0.100000
2017/08/28 13:38:46 step 1: mse=121.610503 step=0.100000
2017/08/28 13:38:47 step 2: mse=120.740975 step=0.100000
2017/08/28 13:38:47 step 3: mse=119.789607 step=0.100000
2017/08/28 13:38:48 step 4: mse=118.917885 step=0.100000
2017/08/28 13:38:49 step 5: mse=118.361041 step=0.100000
2017/08/28 13:38:50 step 6: mse=117.777134 step=0.100000
2017/08/28 13:38:51 step 7: mse=117.201582 step=0.100000
2017/08/28 13:38:51 Saving...
2017/08/28 13:38:51 Gathering batch of experience...
2017/08/28 13:39:51 batch 231: mean=38.681818 stddev=38.904997 entropy=0.548546 frames=4572 count=110
2017/08/28 13:39:51 Training policy...
2017/08/28 13:39:54 step 0: objective=0.28613636
2017/08/28 13:39:55 step 1: objective=0.29507655
2017/08/28 13:39:56 step 2: objective=0.30208567
2017/08/28 13:39:57 step 3: objective=0.31146023
2017/08/28 13:39:58 step 4: objective=0.3242555
2017/08/28 13:39:59 step 5: objective=0.33208624
2017/08/28 13:40:00 step 6: objective=0.33691886
2017/08/28 13:40:01 step 7: objective=0.34138334
2017/08/28 13:40:01 Training value function...
2017/08/28 13:40:03 step 0: mse=148.527964 step=0.100000
2017/08/28 13:40:04 step 1: mse=147.226180 step=0.100000
2017/08/28 13:40:05 step 2: mse=145.982906 step=0.100000
2017/08/28 13:40:06 step 3: mse=144.961908 step=0.100000
2017/08/28 13:40:07 step 4: mse=143.708258 step=0.100000
2017/08/28 13:40:08 step 5: mse=142.853734 step=0.100000
2017/08/28 13:40:09 step 6: mse=141.909557 step=0.100000
2017/08/28 13:40:10 step 7: mse=140.937117 step=0.100000
2017/08/28 13:40:10 Saving...
2017/08/28 13:40:10 Gathering batch of experience...
2017/08/28 13:41:04 batch 232: mean=49.648352 stddev=49.059590 entropy=0.550055 frames=4564 count=91
2017/08/28 13:41:04 Training policy...
2017/08/28 13:41:07 step 0: objective=1.9533683
2017/08/28 13:41:08 step 1: objective=1.9652486
2017/08/28 13:41:09 step 2: objective=1.9780195
2017/08/28 13:41:10 step 3: objective=1.9904906
2017/08/28 13:41:11 step 4: objective=1.9979734
2017/08/28 13:41:12 step 5: objective=2.0065331
2017/08/28 13:41:13 step 6: objective=2.010915
2017/08/28 13:41:14 step 7: objective=2.019768
2017/08/28 13:41:14 Training value function...
2017/08/28 13:41:15 step 0: mse=184.228282 step=0.100000
2017/08/28 13:41:16 step 1: mse=181.028849 step=0.100000
2017/08/28 13:41:17 step 2: mse=177.768372 step=0.100000
2017/08/28 13:41:18 step 3: mse=175.126344 step=0.100000
2017/08/28 13:41:19 step 4: mse=172.793561 step=0.100000
2017/08/28 13:41:20 step 5: mse=170.845074 step=0.100000
2017/08/28 13:41:21 step 6: mse=168.683080 step=0.100000
2017/08/28 13:41:22 step 7: mse=166.885948 step=0.100000
2017/08/28 13:41:22 Saving...
2017/08/28 13:41:22 Gathering batch of experience...
2017/08/28 13:42:17 batch 233: mean=41.088235 stddev=35.101004 entropy=0.548715 frames=4318 count=102
2017/08/28 13:42:17 Training policy...
2017/08/28 13:42:20 step 0: objective=0.050242957
2017/08/28 13:42:21 step 1: objective=0.06328429
2017/08/28 13:42:22 step 2: objective=0.0787329
2017/08/28 13:42:23 step 3: objective=0.08562866
2017/08/28 13:42:23 step 4: objective=0.09930233
2017/08/28 13:42:24 step 5: objective=0.113780566
2017/08/28 13:42:25 step 6: objective=0.12036303
2017/08/28 13:42:26 step 7: objective=0.12516922
2017/08/28 13:42:26 Training value function...
2017/08/28 13:42:28 step 0: mse=144.122840 step=0.100000
2017/08/28 13:42:29 step 1: mse=142.480319 step=0.100000
2017/08/28 13:42:30 step 2: mse=140.699228 step=0.100000
2017/08/28 13:42:31 step 3: mse=139.553594 step=0.100000
2017/08/28 13:42:32 step 4: mse=138.445134 step=0.100000
2017/08/28 13:42:32 step 5: mse=136.951937 step=0.100000
2017/08/28 13:42:33 step 6: mse=136.205362 step=0.100000
2017/08/28 13:42:34 step 7: mse=135.097899 step=0.100000
2017/08/28 13:42:34 Saving...
2017/08/28 13:42:34 Gathering batch of experience...
2017/08/28 13:43:30 batch 234: mean=47.424242 stddev=49.491575 entropy=0.544357 frames=4809 count=99
2017/08/28 13:43:30 Training policy...
2017/08/28 13:43:33 step 0: objective=1.761724
2017/08/28 13:43:34 step 1: objective=1.7697146
2017/08/28 13:43:35 step 2: objective=1.7772871
2017/08/28 13:43:36 step 3: objective=1.7889029
2017/08/28 13:43:37 step 4: objective=1.8037455
2017/08/28 13:43:39 step 5: objective=1.8139699
2017/08/28 13:43:40 step 6: objective=1.8203694
2017/08/28 13:43:41 step 7: objective=1.8260216
2017/08/28 13:43:41 Training value function...
2017/08/28 13:43:43 step 0: mse=185.863661 step=0.100000
2017/08/28 13:43:44 step 1: mse=182.136320 step=0.100000
2017/08/28 13:43:45 step 2: mse=178.544652 step=0.100000
2017/08/28 13:43:46 step 3: mse=175.309564 step=0.100000
2017/08/28 13:43:47 step 4: mse=172.580948 step=0.100000
2017/08/28 13:43:48 step 5: mse=170.229842 step=0.100000
2017/08/28 13:43:49 step 6: mse=168.360897 step=0.100000
2017/08/28 13:43:50 step 7: mse=166.557941 step=0.100000
2017/08/28 13:43:50 Saving...
2017/08/28 13:43:50 Gathering batch of experience...
2017/08/28 13:44:42 batch 235: mean=44.645161 stddev=41.201745 entropy=0.545430 frames=4381 count=93
2017/08/28 13:44:42 Training policy...
2017/08/28 13:44:45 step 0: objective=0.43424767
2017/08/28 13:44:46 step 1: objective=0.4446139
2017/08/28 13:44:47 step 2: objective=0.4541493
2017/08/28 13:44:48 step 3: objective=0.4671119
2017/08/28 13:44:48 step 4: objective=0.4803646
2017/08/28 13:44:49 step 5: objective=0.48629647
2017/08/28 13:44:50 step 6: objective=0.49556243
2017/08/28 13:44:51 step 7: objective=0.50572294
2017/08/28 13:44:51 Training value function...
2017/08/28 13:44:53 step 0: mse=155.001490 step=0.100000
2017/08/28 13:44:54 step 1: mse=153.321132 step=0.100000
2017/08/28 13:44:55 step 2: mse=151.326928 step=0.100000
2017/08/28 13:44:56 step 3: mse=149.839047 step=0.100000
2017/08/28 13:44:57 step 4: mse=148.658168 step=0.100000
2017/08/28 13:44:58 step 5: mse=147.310877 step=0.100000
2017/08/28 13:44:59 step 6: mse=146.340851 step=0.100000
2017/08/28 13:45:00 step 7: mse=145.483529 step=0.100000
2017/08/28 13:45:00 Saving...
2017/08/28 13:45:00 Gathering batch of experience...
2017/08/28 13:45:51 batch 236: mean=56.891566 stddev=54.202434 entropy=0.552567 frames=4729 count=83
2017/08/28 13:45:51 Training policy...
2017/08/28 13:45:54 step 0: objective=2.155331
2017/08/28 13:45:55 step 1: objective=2.1687582
2017/08/28 13:45:56 step 2: objective=2.1850283
2017/08/28 13:45:57 step 3: objective=2.1945548
2017/08/28 13:45:58 step 4: objective=2.2012691
2017/08/28 13:45:59 step 5: objective=2.2124178
2017/08/28 13:46:00 step 6: objective=2.2239711
2017/08/28 13:46:01 step 7: objective=2.228174
2017/08/28 13:46:01 Training value function...
2017/08/28 13:46:03 step 0: mse=199.601247 step=0.100000
2017/08/28 13:46:04 step 1: mse=194.814491 step=0.100000
2017/08/28 13:46:05 step 2: mse=190.732853 step=0.100000
2017/08/28 13:46:06 step 3: mse=187.607668 step=0.100000
2017/08/28 13:46:07 step 4: mse=184.852696 step=0.100000
2017/08/28 13:46:08 step 5: mse=182.265492 step=0.100000
2017/08/28 13:46:09 step 6: mse=179.977171 step=0.100000
2017/08/28 13:46:10 step 7: mse=177.813575 step=0.100000
2017/08/28 13:46:10 Saving...
2017/08/28 13:46:10 Gathering batch of experience...
2017/08/28 13:47:04 batch 237: mean=47.821053 stddev=39.306081 entropy=0.548474 frames=4709 count=95
2017/08/28 13:47:04 Training policy...
2017/08/28 13:47:07 step 0: objective=0.4040845
2017/08/28 13:47:08 step 1: objective=0.4132332
2017/08/28 13:47:09 step 2: objective=0.42309058
2017/08/28 13:47:10 step 3: objective=0.4315605
2017/08/28 13:47:11 step 4: objective=0.4395926
2017/08/28 13:47:12 step 5: objective=0.45419037
2017/08/28 13:47:13 step 6: objective=0.4630259
2017/08/28 13:47:14 step 7: objective=0.47147962
2017/08/28 13:47:14 Training value function...
2017/08/28 13:47:16 step 0: mse=148.410862 step=0.100000
2017/08/28 13:47:17 step 1: mse=147.104943 step=0.100000
2017/08/28 13:47:18 step 2: mse=146.011596 step=0.100000
2017/08/28 13:47:19 step 3: mse=144.947004 step=0.100000
2017/08/28 13:47:20 step 4: mse=143.994515 step=0.100000
2017/08/28 13:47:21 step 5: mse=142.876750 step=0.100000
2017/08/28 13:47:22 step 6: mse=141.859447 step=0.100000
2017/08/28 13:47:23 step 7: mse=140.896398 step=0.100000
2017/08/28 13:47:23 Saving...
2017/08/28 13:47:23 Gathering batch of experience...
2017/08/28 13:48:15 batch 238: mean=47.720430 stddev=42.922627 entropy=0.552364 frames=4449 count=93
2017/08/28 13:48:15 Training policy...
2017/08/28 13:48:18 step 0: objective=0.8113187
2017/08/28 13:48:19 step 1: objective=0.8302666
2017/08/28 13:48:20 step 2: objective=0.84208
2017/08/28 13:48:21 step 3: objective=0.8531787
2017/08/28 13:48:22 step 4: objective=0.86422324
2017/08/28 13:48:23 step 5: objective=0.8705191
2017/08/28 13:48:24 step 6: objective=0.88173324
2017/08/28 13:48:25 step 7: objective=0.8886028
2017/08/28 13:48:25 Training value function...
2017/08/28 13:48:26 step 0: mse=161.077910 step=0.100000
2017/08/28 13:48:27 step 1: mse=159.385221 step=0.100000
2017/08/28 13:48:28 step 2: mse=157.844093 step=0.100000
2017/08/28 13:48:29 step 3: mse=156.463772 step=0.100000
2017/08/28 13:48:30 step 4: mse=155.218986 step=0.100000
2017/08/28 13:48:31 step 5: mse=153.844999 step=0.100000
2017/08/28 13:48:32 step 6: mse=152.488203 step=0.100000
2017/08/28 13:48:33 step 7: mse=151.301815 step=0.100000
2017/08/28 13:48:33 Saving...
2017/08/28 13:48:33 Gathering batch of experience...
2017/08/28 13:49:29 batch 239: mean=46.820000 stddev=43.624163 entropy=0.544164 frames=4623 count=100
2017/08/28 13:49:29 Training policy...
2017/08/28 13:49:32 step 0: objective=0.90665686
2017/08/28 13:49:33 step 1: objective=0.92104894
2017/08/28 13:49:34 step 2: objective=0.93312323
2017/08/28 13:49:35 step 3: objective=0.94453937
2017/08/28 13:49:36 step 4: objective=0.956468
2017/08/28 13:49:37 step 5: objective=0.9630581
2017/08/28 13:49:38 step 6: objective=0.9720871
2017/08/28 13:49:39 step 7: objective=0.9791343
2017/08/28 13:49:39 Training value function...
2017/08/28 13:49:41 step 0: mse=156.968797 step=0.100000
2017/08/28 13:49:42 step 1: mse=155.828171 step=0.100000
2017/08/28 13:49:43 step 2: mse=154.694168 step=0.100000
2017/08/28 13:49:44 step 3: mse=153.618314 step=0.100000
2017/08/28 13:49:45 step 4: mse=153.038641 step=0.100000
2017/08/28 13:49:46 step 5: mse=152.649513 step=0.100000
2017/08/28 13:49:47 step 6: mse=151.694432 step=0.100000
2017/08/28 13:49:48 step 7: mse=150.919664 step=0.100000
2017/08/28 13:49:48 Saving...
2017/08/28 13:49:48 Gathering batch of experience...
2017/08/28 13:50:42 batch 240: mean=44.946809 stddev=42.599912 entropy=0.543994 frames=4504 count=94
2017/08/28 13:50:42 Training policy...
2017/08/28 13:50:45 step 0: objective=0.42691118
2017/08/28 13:50:46 step 1: objective=0.43437135
2017/08/28 13:50:47 step 2: objective=0.44347173
2017/08/28 13:50:48 step 3: objective=0.45030585
2017/08/28 13:50:49 step 4: objective=0.460168
2017/08/28 13:50:50 step 5: objective=0.47062966
2017/08/28 13:50:50 step 6: objective=0.47651273
2017/08/28 13:50:51 step 7: objective=0.48468482
2017/08/28 13:50:51 Training value function...
2017/08/28 13:50:53 step 0: mse=153.103139 step=0.100000
2017/08/28 13:50:54 step 1: mse=151.720064 step=0.100000
2017/08/28 13:50:55 step 2: mse=150.526654 step=0.100000
2017/08/28 13:50:56 step 3: mse=149.711104 step=0.100000
2017/08/28 13:50:57 step 4: mse=148.743817 step=0.100000
2017/08/28 13:50:58 step 5: mse=147.591020 step=0.100000
2017/08/28 13:50:59 step 6: mse=146.782452 step=0.100000
2017/08/28 13:51:00 step 7: mse=145.965543 step=0.100000
2017/08/28 13:51:00 Saving...
2017/08/28 13:51:00 Gathering batch of experience...
2017/08/28 13:51:52 batch 241: mean=52.103448 stddev=44.712115 entropy=0.544696 frames=4572 count=87
2017/08/28 13:51:52 Training policy...
2017/08/28 13:51:55 step 0: objective=1.5786133
2017/08/28 13:51:56 step 1: objective=1.5871664
2017/08/28 13:51:57 step 2: objective=1.5949532
2017/08/28 13:51:58 step 3: objective=1.610952
2017/08/28 13:51:59 step 4: objective=1.6198287
2017/08/28 13:52:00 step 5: objective=1.6256379
2017/08/28 13:52:01 step 6: objective=1.6321772
2017/08/28 13:52:02 step 7: objective=1.6415479
2017/08/28 13:52:02 Training value function...
2017/08/28 13:52:04 step 0: mse=168.293201 step=0.100000
2017/08/28 13:52:05 step 1: mse=166.005425 step=0.100000
2017/08/28 13:52:06 step 2: mse=163.859062 step=0.100000
2017/08/28 13:52:06 step 3: mse=161.973958 step=0.100000
2017/08/28 13:52:07 step 4: mse=160.606223 step=0.100000
2017/08/28 13:52:08 step 5: mse=159.247822 step=0.100000
2017/08/28 13:52:09 step 6: mse=157.779389 step=0.100000
2017/08/28 13:52:10 step 7: mse=156.620847 step=0.100000
2017/08/28 13:52:10 Saving...
2017/08/28 13:52:10 Gathering batch of experience...
2017/08/28 13:53:06 batch 242: mean=45.591837 stddev=46.190121 entropy=0.539361 frames=4601 count=98
2017/08/28 13:53:06 Training policy...
2017/08/28 13:53:09 step 0: objective=0.34575418
2017/08/28 13:53:10 step 1: objective=0.35844678
2017/08/28 13:53:11 step 2: objective=0.3660922
2017/08/28 13:53:12 step 3: objective=0.3811348
2017/08/28 13:53:13 step 4: objective=0.3909611
2017/08/28 13:53:14 step 5: objective=0.3965687
2017/08/28 13:53:15 step 6: objective=0.40560132
2017/08/28 13:53:16 step 7: objective=0.41127363
2017/08/28 13:53:16 Training value function...
2017/08/28 13:53:18 step 0: mse=158.424571 step=0.100000
2017/08/28 13:53:19 step 1: mse=156.414349 step=0.100000
2017/08/28 13:53:20 step 2: mse=154.856811 step=0.100000
2017/08/28 13:53:21 step 3: mse=153.144278 step=0.100000
2017/08/28 13:53:22 step 4: mse=151.821930 step=0.100000
2017/08/28 13:53:23 step 5: mse=150.485853 step=0.100000
2017/08/28 13:53:24 step 6: mse=149.562009 step=0.100000
2017/08/28 13:53:25 step 7: mse=148.449374 step=0.100000
2017/08/28 13:53:25 Saving...
2017/08/28 13:53:25 Gathering batch of experience...
2017/08/28 13:54:18 batch 243: mean=54.724138 stddev=50.358414 entropy=0.540925 frames=4610 count=87
2017/08/28 13:54:18 Training policy...
2017/08/28 13:54:21 step 0: objective=1.8221521
2017/08/28 13:54:22 step 1: objective=1.8313595
2017/08/28 13:54:23 step 2: objective=1.8480297
2017/08/28 13:54:24 step 3: objective=1.8551152
2017/08/28 13:54:25 step 4: objective=1.861417
2017/08/28 13:54:26 step 5: objective=1.8756099
2017/08/28 13:54:27 step 6: objective=1.8859259
2017/08/28 13:54:28 step 7: objective=1.8951128
2017/08/28 13:54:28 Training value function...
2017/08/28 13:54:30 step 0: mse=213.872138 step=0.100000
2017/08/28 13:54:31 step 1: mse=211.154615 step=0.100000
2017/08/28 13:54:32 step 2: mse=208.396906 step=0.100000
2017/08/28 13:54:33 step 3: mse=205.465532 step=0.100000
2017/08/28 13:54:34 step 4: mse=203.146121 step=0.100000
2017/08/28 13:54:35 step 5: mse=200.650308 step=0.100000
2017/08/28 13:54:36 step 6: mse=198.806805 step=0.100000
2017/08/28 13:54:37 step 7: mse=196.828570 step=0.100000
2017/08/28 13:54:37 Saving...
2017/08/28 13:54:37 Gathering batch of experience...
2017/08/28 13:55:30 batch 244: mean=50.184783 stddev=59.484914 entropy=0.539801 frames=4734 count=92
2017/08/28 13:55:30 Training policy...
2017/08/28 13:55:33 step 0: objective=0.76235545
2017/08/28 13:55:34 step 1: objective=0.7733062
2017/08/28 13:55:35 step 2: objective=0.7836623
2017/08/28 13:55:36 step 3: objective=0.7962741
2017/08/28 13:55:37 step 4: objective=0.81368905
2017/08/28 13:55:38 step 5: objective=0.8191043
2017/08/28 13:55:40 step 6: objective=0.8270596
2017/08/28 13:55:41 step 7: objective=0.83179075
2017/08/28 13:55:41 Training value function...
2017/08/28 13:55:43 step 0: mse=167.494189 step=0.100000
2017/08/28 13:55:44 step 1: mse=162.124521 step=0.100000
2017/08/28 13:55:45 step 2: mse=158.421214 step=0.100000
2017/08/28 13:55:45 step 3: mse=155.098248 step=0.100000
2017/08/28 13:55:46 step 4: mse=152.485967 step=0.100000
2017/08/28 13:55:47 step 5: mse=150.437555 step=0.100000
2017/08/28 13:55:48 step 6: mse=148.575566 step=0.100000
2017/08/28 13:55:49 step 7: mse=146.237769 step=0.100000
2017/08/28 13:55:49 Saving...
2017/08/28 13:55:49 Gathering batch of experience...
2017/08/28 13:56:47 batch 245: mean=54.855556 stddev=65.070827 entropy=0.533859 frames=4850 count=90
2017/08/28 13:56:47 Training policy...
2017/08/28 13:56:50 step 0: objective=1.4300059
2017/08/28 13:56:51 step 1: objective=1.444115
2017/08/28 13:56:52 step 2: objective=1.4578649
2017/08/28 13:56:53 step 3: objective=1.4752154
2017/08/28 13:56:54 step 4: objective=1.4841189
2017/08/28 13:56:55 step 5: objective=1.4948972
2017/08/28 13:56:56 step 6: objective=1.5015452
2017/08/28 13:56:57 step 7: objective=1.5086186
2017/08/28 13:56:57 Training value function...
2017/08/28 13:56:59 step 0: mse=206.882880 step=0.100000
2017/08/28 13:57:00 step 1: mse=202.612128 step=0.100000
2017/08/28 13:57:01 step 2: mse=199.377401 step=0.100000
2017/08/28 13:57:02 step 3: mse=196.121074 step=0.100000
2017/08/28 13:57:03 step 4: mse=193.259588 step=0.100000
2017/08/28 13:57:04 step 5: mse=190.885834 step=0.100000
2017/08/28 13:57:05 step 6: mse=188.111191 step=0.100000
2017/08/28 13:57:06 step 7: mse=185.956014 step=0.100000
2017/08/28 13:57:06 Saving...
2017/08/28 13:57:06 Gathering batch of experience...
2017/08/28 13:57:58 batch 246: mean=56.619048 stddev=54.619006 entropy=0.533491 frames=4514 count=84
2017/08/28 13:57:58 Training policy...
2017/08/28 13:58:01 step 0: objective=1.2252465
2017/08/28 13:58:02 step 1: objective=1.2369365
2017/08/28 13:58:03 step 2: objective=1.2536958
2017/08/28 13:58:04 step 3: objective=1.2613202
2017/08/28 13:58:05 step 4: objective=1.2741532
2017/08/28 13:58:06 step 5: objective=1.2824962
2017/08/28 13:58:07 step 6: objective=1.2916212
2017/08/28 13:58:08 step 7: objective=1.3027024
2017/08/28 13:58:08 Training value function...
2017/08/28 13:58:10 step 0: mse=194.193537 step=0.100000
2017/08/28 13:58:11 step 1: mse=191.421380 step=0.100000
2017/08/28 13:58:11 step 2: mse=189.754385 step=0.100000
2017/08/28 13:58:12 step 3: mse=187.286667 step=0.100000
2017/08/28 13:58:13 step 4: mse=185.503704 step=0.100000
2017/08/28 13:58:14 step 5: mse=183.367231 step=0.100000
2017/08/28 13:58:15 step 6: mse=181.777697 step=0.100000
2017/08/28 13:58:16 step 7: mse=180.275913 step=0.100000
2017/08/28 13:58:16 Saving...
2017/08/28 13:58:16 Gathering batch of experience...
2017/08/28 13:59:09 batch 247: mean=49.852273 stddev=46.893869 entropy=0.535197 frames=4707 count=88
2017/08/28 13:59:09 Training policy...
2017/08/28 13:59:12 step 0: objective=0.20613974
2017/08/28 13:59:13 step 1: objective=0.21723016
2017/08/28 13:59:14 step 2: objective=0.22403951
2017/08/28 13:59:15 step 3: objective=0.23136917
2017/08/28 13:59:16 step 4: objective=0.2379028
2017/08/28 13:59:17 step 5: objective=0.24696232
2017/08/28 13:59:18 step 6: objective=0.2564849
2017/08/28 13:59:19 step 7: objective=0.26252538
2017/08/28 13:59:19 Training value function...
2017/08/28 13:59:21 step 0: mse=151.176582 step=0.100000
2017/08/28 13:59:22 step 1: mse=150.039484 step=0.100000
2017/08/28 13:59:23 step 2: mse=149.178041 step=0.100000
2017/08/28 13:59:24 step 3: mse=148.418090 step=0.100000
2017/08/28 13:59:25 step 4: mse=147.545068 step=0.100000
2017/08/28 13:59:26 step 5: mse=146.916875 step=0.100000
2017/08/28 13:59:27 step 6: mse=146.013861 step=0.100000
2017/08/28 13:59:28 step 7: mse=145.202059 step=0.100000
2017/08/28 13:59:28 Saving...
2017/08/28 13:59:28 Gathering batch of experience...
2017/08/28 14:00:18 batch 248: mean=57.172840 stddev=45.790664 entropy=0.534498 frames=4691 count=81
2017/08/28 14:00:18 Training policy...
2017/08/28 14:00:21 step 0: objective=1.447852
2017/08/28 14:00:22 step 1: objective=1.4611723
2017/08/28 14:00:23 step 2: objective=1.4742922
2017/08/28 14:00:24 step 3: objective=1.4846535
2017/08/28 14:00:25 step 4: objective=1.4968642
2017/08/28 14:00:26 step 5: objective=1.5043031
2017/08/28 14:00:27 step 6: objective=1.5119231
2017/08/28 14:00:28 step 7: objective=1.5217307
2017/08/28 14:00:28 Training value function...
2017/08/28 14:00:30 step 0: mse=172.398082 step=0.100000
2017/08/28 14:00:31 step 1: mse=169.860384 step=0.100000
2017/08/28 14:00:32 step 2: mse=167.362879 step=0.100000
2017/08/28 14:00:33 step 3: mse=165.390802 step=0.100000
2017/08/28 14:00:34 step 4: mse=163.774067 step=0.100000
2017/08/28 14:00:35 step 5: mse=161.933673 step=0.100000
2017/08/28 14:00:36 step 6: mse=160.286327 step=0.100000
2017/08/28 14:00:37 step 7: mse=158.816939 step=0.100000
2017/08/28 14:00:37 Saving...
2017/08/28 14:00:37 Gathering batch of experience...
2017/08/28 14:01:27 batch 249: mean=48.806818 stddev=45.852495 entropy=0.527349 frames=4370 count=88
2017/08/28 14:01:27 Training policy...
2017/08/28 14:01:30 step 0: objective=0.44523162
2017/08/28 14:01:31 step 1: objective=0.4581771
2017/08/28 14:01:32 step 2: objective=0.46786797
2017/08/28 14:01:33 step 3: objective=0.48011807
2017/08/28 14:01:34 step 4: objective=0.4948029
2017/08/28 14:01:35 step 5: objective=0.5051176
2017/08/28 14:01:36 step 6: objective=0.5112824
2017/08/28 14:01:37 step 7: objective=0.5162974
2017/08/28 14:01:37 Training value function...
2017/08/28 14:01:39 step 0: mse=161.938471 step=0.100000
2017/08/28 14:01:40 step 1: mse=159.952415 step=0.100000
2017/08/28 14:01:41 step 2: mse=158.837274 step=0.100000
2017/08/28 14:01:41 step 3: mse=157.803312 step=0.100000
2017/08/28 14:01:42 step 4: mse=156.747512 step=0.100000
2017/08/28 14:01:43 step 5: mse=155.759108 step=0.100000
2017/08/28 14:01:44 step 6: mse=154.922310 step=0.100000
2017/08/28 14:01:45 step 7: mse=154.111130 step=0.100000
2017/08/28 14:01:45 Saving...
2017/08/28 14:01:45 Gathering batch of experience...
2017/08/28 14:02:33 batch 250: mean=59.962025 stddev=45.109275 entropy=0.526489 frames=4490 count=79
2017/08/28 14:02:33 Training policy...
2017/08/28 14:02:36 step 0: objective=1.8179457
2017/08/28 14:02:37 step 1: objective=1.8301011
2017/08/28 14:02:38 step 2: objective=1.8380845
2017/08/28 14:02:39 step 3: objective=1.847815
2017/08/28 14:02:40 step 4: objective=1.8565129
2017/08/28 14:02:41 step 5: objective=1.8618631
2017/08/28 14:02:42 step 6: objective=1.8690747
2017/08/28 14:02:43 step 7: objective=1.8761749
2017/08/28 14:02:43 Training value function...
2017/08/28 14:02:45 step 0: mse=194.534033 step=0.100000
2017/08/28 14:02:46 step 1: mse=191.055866 step=0.100000
2017/08/28 14:02:47 step 2: mse=187.549351 step=0.100000
2017/08/28 14:02:48 step 3: mse=184.613959 step=0.100000
2017/08/28 14:02:49 step 4: mse=182.103449 step=0.100000
2017/08/28 14:02:50 step 5: mse=179.793665 step=0.100000
2017/08/28 14:02:51 step 6: mse=177.600615 step=0.100000
2017/08/28 14:02:52 step 7: mse=175.496468 step=0.100000
2017/08/28 14:02:52 Saving...
2017/08/28 14:02:52 Gathering batch of experience...
2017/08/28 14:03:43 batch 251: mean=53.511364 stddev=56.149758 entropy=0.525769 frames=4561 count=88
2017/08/28 14:03:43 Training policy...
2017/08/28 14:03:46 step 0: objective=0.79591954
2017/08/28 14:03:47 step 1: objective=0.8153135
2017/08/28 14:03:48 step 2: objective=0.8317105
2017/08/28 14:03:49 step 3: objective=0.84627515
2017/08/28 14:03:50 step 4: objective=0.8616032
2017/08/28 14:03:51 step 5: objective=0.87196743
2017/08/28 14:03:52 step 6: objective=0.88351965
2017/08/28 14:03:53 step 7: objective=0.8879251
2017/08/28 14:03:53 Training value function...
2017/08/28 14:03:55 step 0: mse=208.185544 step=0.100000
2017/08/28 14:03:56 step 1: mse=203.447309 step=0.100000
2017/08/28 14:03:57 step 2: mse=199.499603 step=0.100000
2017/08/28 14:03:58 step 3: mse=196.432076 step=0.100000
2017/08/28 14:03:59 step 4: mse=193.528956 step=0.100000
2017/08/28 14:04:00 step 5: mse=191.132113 step=0.100000
2017/08/28 14:04:01 step 6: mse=188.701349 step=0.100000
2017/08/28 14:04:02 step 7: mse=186.739990 step=0.100000
2017/08/28 14:04:02 Saving...
2017/08/28 14:04:02 Gathering batch of experience...
2017/08/28 14:04:56 batch 252: mean=44.789474 stddev=45.438888 entropy=0.539709 frames=4653 count=95
2017/08/28 14:04:56 Training policy...
2017/08/28 14:04:59 step 0: objective=-0.39535934
2017/08/28 14:05:00 step 1: objective=-0.38560092
2017/08/28 14:05:01 step 2: objective=-0.37430698
2017/08/28 14:05:02 step 3: objective=-0.3622684
2017/08/28 14:05:03 step 4: objective=-0.3515418
2017/08/28 14:05:04 step 5: objective=-0.34116244
2017/08/28 14:05:05 step 6: objective=-0.33312744
2017/08/28 14:05:06 step 7: objective=-0.32807347
2017/08/28 14:05:06 Training value function...
2017/08/28 14:05:08 step 0: mse=147.574181 step=0.100000
2017/08/28 14:05:09 step 1: mse=145.324341 step=0.100000
2017/08/28 14:05:10 step 2: mse=143.505669 step=0.100000
2017/08/28 14:05:11 step 3: mse=141.793376 step=0.100000
2017/08/28 14:05:12 step 4: mse=139.998040 step=0.100000
2017/08/28 14:05:13 step 5: mse=138.372843 step=0.100000
2017/08/28 14:05:14 step 6: mse=137.087712 step=0.100000
2017/08/28 14:05:15 step 7: mse=135.979672 step=0.100000
2017/08/28 14:05:15 Saving...
2017/08/28 14:05:15 Gathering batch of experience...
2017/08/28 14:06:10 batch 253: mean=52.109890 stddev=50.871191 entropy=0.527455 frames=4698 count=91
2017/08/28 14:06:10 Training policy...
2017/08/28 14:06:13 step 0: objective=1.3767674
2017/08/28 14:06:14 step 1: objective=1.3860798
2017/08/28 14:06:15 step 2: objective=1.3950979
2017/08/28 14:06:16 step 3: objective=1.4030013
2017/08/28 14:06:17 step 4: objective=1.4178075
2017/08/28 14:06:18 step 5: objective=1.4262868
2017/08/28 14:06:19 step 6: objective=1.4311501
2017/08/28 14:06:20 step 7: objective=1.4392422
2017/08/28 14:06:20 Training value function...
2017/08/28 14:06:22 step 0: mse=160.688980 step=0.100000
2017/08/28 14:06:23 step 1: mse=158.204538 step=0.100000
2017/08/28 14:06:24 step 2: mse=156.610921 step=0.100000
2017/08/28 14:06:25 step 3: mse=154.856118 step=0.100000
2017/08/28 14:06:26 step 4: mse=153.275269 step=0.100000
2017/08/28 14:06:27 step 5: mse=151.685753 step=0.100000
2017/08/28 14:06:28 step 6: mse=150.496835 step=0.100000
2017/08/28 14:06:29 step 7: mse=149.085103 step=0.100000
2017/08/28 14:06:29 Saving...
2017/08/28 14:06:29 Gathering batch of experience...
2017/08/28 14:07:23 batch 254: mean=58.388235 stddev=68.629627 entropy=0.533113 frames=5043 count=85
2017/08/28 14:07:23 Training policy...
2017/08/28 14:07:26 step 0: objective=1.4178014
2017/08/28 14:07:27 step 1: objective=1.4288749
2017/08/28 14:07:29 step 2: objective=1.4371718
2017/08/28 14:07:30 step 3: objective=1.44461
2017/08/28 14:07:31 step 4: objective=1.4500049
2017/08/28 14:07:32 step 5: objective=1.4586135
2017/08/28 14:07:33 step 6: objective=1.4652416
2017/08/28 14:07:34 step 7: objective=1.4715205
2017/08/28 14:07:34 Training value function...
2017/08/28 14:07:36 step 0: mse=182.731433 step=0.100000
2017/08/28 14:07:37 step 1: mse=178.819611 step=0.100000
2017/08/28 14:07:38 step 2: mse=175.112828 step=0.100000
2017/08/28 14:07:39 step 3: mse=171.869511 step=0.100000
2017/08/28 14:07:40 step 4: mse=168.991159 step=0.100000
2017/08/28 14:07:41 step 5: mse=166.855150 step=0.100000
2017/08/28 14:07:43 step 6: mse=164.508286 step=0.100000
2017/08/28 14:07:44 step 7: mse=162.721680 step=0.100000
2017/08/28 14:07:44 Saving...
2017/08/28 14:07:44 Gathering batch of experience...
2017/08/28 14:08:33 batch 255: mean=57.531646 stddev=75.126027 entropy=0.531818 frames=4716 count=79
2017/08/28 14:08:33 Training policy...
2017/08/28 14:08:36 step 0: objective=1.0750865
2017/08/28 14:08:37 step 1: objective=1.0844895
2017/08/28 14:08:38 step 2: objective=1.0933574
2017/08/28 14:08:39 step 3: objective=1.1010512
2017/08/28 14:08:40 step 4: objective=1.1082149
2017/08/28 14:08:41 step 5: objective=1.115634
2017/08/28 14:08:42 step 6: objective=1.124401
2017/08/28 14:08:43 step 7: objective=1.1344333
2017/08/28 14:08:43 Training value function...
2017/08/28 14:08:45 step 0: mse=173.043800 step=0.100000
2017/08/28 14:08:46 step 1: mse=169.677365 step=0.100000
2017/08/28 14:08:47 step 2: mse=166.820500 step=0.100000
2017/08/28 14:08:48 step 3: mse=164.273726 step=0.100000
2017/08/28 14:08:49 step 4: mse=161.416902 step=0.100000
2017/08/28 14:08:50 step 5: mse=159.655645 step=0.100000
2017/08/28 14:08:51 step 6: mse=158.104247 step=0.100000
2017/08/28 14:08:52 step 7: mse=156.612121 step=0.100000
2017/08/28 14:08:52 Saving...
2017/08/28 14:08:52 Gathering batch of experience...
2017/08/28 14:09:44 batch 256: mean=50.528090 stddev=53.928811 entropy=0.519302 frames=4558 count=89
2017/08/28 14:09:44 Training policy...
2017/08/28 14:09:47 step 0: objective=0.5358016
2017/08/28 14:09:48 step 1: objective=0.550656
2017/08/28 14:09:49 step 2: objective=0.56705976
2017/08/28 14:09:50 step 3: objective=0.5826576
2017/08/28 14:09:51 step 4: objective=0.5888901
2017/08/28 14:09:52 step 5: objective=0.60159075
2017/08/28 14:09:53 step 6: objective=0.60759574
2017/08/28 14:09:54 step 7: objective=0.61462545
2017/08/28 14:09:54 Training value function...
2017/08/28 14:09:56 step 0: mse=192.206180 step=0.100000
2017/08/28 14:09:57 step 1: mse=189.982874 step=0.100000
2017/08/28 14:09:58 step 2: mse=187.613400 step=0.100000
2017/08/28 14:09:59 step 3: mse=186.023287 step=0.100000
2017/08/28 14:10:00 step 4: mse=184.647229 step=0.100000
2017/08/28 14:10:01 step 5: mse=183.502762 step=0.100000
2017/08/28 14:10:02 step 6: mse=182.483559 step=0.100000
2017/08/28 14:10:03 step 7: mse=181.235790 step=0.100000
2017/08/28 14:10:03 Saving...
2017/08/28 14:10:03 Gathering batch of experience...
2017/08/28 14:10:51 batch 257: mean=57.641026 stddev=46.222143 entropy=0.535434 frames=4504 count=78
2017/08/28 14:10:51 Training policy...
2017/08/28 14:10:54 step 0: objective=1.3336841
2017/08/28 14:10:55 step 1: objective=1.3434576
2017/08/28 14:10:56 step 2: objective=1.3527975
2017/08/28 14:10:57 step 3: objective=1.3595498
2017/08/28 14:10:58 step 4: objective=1.3707472
2017/08/28 14:10:59 step 5: objective=1.379837
2017/08/28 14:11:00 step 6: objective=1.3894483
2017/08/28 14:11:01 step 7: objective=1.3951125
2017/08/28 14:11:01 Training value function...
2017/08/28 14:11:03 step 0: mse=168.311864 step=0.100000
2017/08/28 14:11:04 step 1: mse=163.654615 step=0.100000
2017/08/28 14:11:05 step 2: mse=160.048934 step=0.100000
2017/08/28 14:11:06 step 3: mse=156.561034 step=0.100000
2017/08/28 14:11:07 step 4: mse=154.064865 step=0.100000
2017/08/28 14:11:08 step 5: mse=151.732725 step=0.100000
2017/08/28 14:11:08 step 6: mse=149.300631 step=0.100000
2017/08/28 14:11:09 step 7: mse=147.559334 step=0.100000
2017/08/28 14:11:09 Saving...
2017/08/28 14:11:09 Gathering batch of experience...
2017/08/28 14:12:04 batch 258: mean=47.406250 stddev=43.548961 entropy=0.522115 frames=4621 count=96
2017/08/28 14:12:04 Training policy...
2017/08/28 14:12:07 step 0: objective=0.37476385
2017/08/28 14:12:08 step 1: objective=0.39372036
2017/08/28 14:12:09 step 2: objective=0.40898737
2017/08/28 14:12:10 step 3: objective=0.42078522
2017/08/28 14:12:11 step 4: objective=0.42914265
2017/08/28 14:12:12 step 5: objective=0.43916556
2017/08/28 14:12:13 step 6: objective=0.4436825
2017/08/28 14:12:14 step 7: objective=0.44946295
2017/08/28 14:12:14 Training value function...
2017/08/28 14:12:16 step 0: mse=167.842165 step=0.100000
2017/08/28 14:12:17 step 1: mse=166.160653 step=0.100000
2017/08/28 14:12:18 step 2: mse=164.601073 step=0.100000
2017/08/28 14:12:19 step 3: mse=163.465139 step=0.100000
2017/08/28 14:12:20 step 4: mse=162.248203 step=0.100000
2017/08/28 14:12:21 step 5: mse=160.824828 step=0.100000
2017/08/28 14:12:22 step 6: mse=160.030154 step=0.100000
2017/08/28 14:12:23 step 7: mse=158.829130 step=0.100000
2017/08/28 14:12:23 Saving...
2017/08/28 14:12:23 Gathering batch of experience...
2017/08/28 14:13:14 batch 259: mean=49.588889 stddev=58.046896 entropy=0.529850 frames=4426 count=90
2017/08/28 14:13:14 Training policy...
2017/08/28 14:13:17 step 0: objective=1.0393918
2017/08/28 14:13:18 step 1: objective=1.0581232
2017/08/28 14:13:19 step 2: objective=1.070333
2017/08/28 14:13:20 step 3: objective=1.082302
2017/08/28 14:13:21 step 4: objective=1.0911511
2017/08/28 14:13:22 step 5: objective=1.1006
2017/08/28 14:13:23 step 6: objective=1.111482
2017/08/28 14:13:24 step 7: objective=1.1153662
2017/08/28 14:13:24 Training value function...
2017/08/28 14:13:26 step 0: mse=207.907602 step=0.100000
2017/08/28 14:13:27 step 1: mse=205.257260 step=0.100000
2017/08/28 14:13:28 step 2: mse=202.818278 step=0.100000
2017/08/28 14:13:29 step 3: mse=200.683929 step=0.100000
2017/08/28 14:13:30 step 4: mse=198.901799 step=0.100000
2017/08/28 14:13:31 step 5: mse=197.102167 step=0.100000
2017/08/28 14:13:31 step 6: mse=195.563615 step=0.100000
2017/08/28 14:13:32 step 7: mse=194.286746 step=0.100000
2017/08/28 14:13:32 Saving...
2017/08/28 14:13:32 Gathering batch of experience...
2017/08/28 14:14:22 batch 260: mean=52.397590 stddev=52.909548 entropy=0.520823 frames=4464 count=83
2017/08/28 14:14:22 Training policy...
2017/08/28 14:14:25 step 0: objective=0.8286516
2017/08/28 14:14:26 step 1: objective=0.8449852
2017/08/28 14:14:27 step 2: objective=0.8587225
2017/08/28 14:14:28 step 3: objective=0.86915606
2017/08/28 14:14:29 step 4: objective=0.8808399
2017/08/28 14:14:30 step 5: objective=0.8885585
2017/08/28 14:14:31 step 6: objective=0.8948875
2017/08/28 14:14:32 step 7: objective=0.90005285
2017/08/28 14:14:32 Training value function...
2017/08/28 14:14:34 step 0: mse=175.422353 step=0.100000
2017/08/28 14:14:35 step 1: mse=172.755107 step=0.100000
2017/08/28 14:14:36 step 2: mse=170.225575 step=0.100000
2017/08/28 14:14:37 step 3: mse=168.075688 step=0.100000
2017/08/28 14:14:38 step 4: mse=166.531506 step=0.100000
2017/08/28 14:14:38 step 5: mse=164.998975 step=0.100000
2017/08/28 14:14:39 step 6: mse=163.734039 step=0.100000
2017/08/28 14:14:40 step 7: mse=162.261762 step=0.100000
2017/08/28 14:14:40 Saving...
2017/08/28 14:14:40 Gathering batch of experience...
2017/08/28 14:15:27 batch 261: mean=59.093333 stddev=47.257923 entropy=0.531221 frames=4482 count=75
2017/08/28 14:15:27 Training policy...
2017/08/28 14:15:30 step 0: objective=1.127256
2017/08/28 14:15:31 step 1: objective=1.1380346
2017/08/28 14:15:32 step 2: objective=1.1478423
2017/08/28 14:15:33 step 3: objective=1.1568059
2017/08/28 14:15:34 step 4: objective=1.169012
2017/08/28 14:15:35 step 5: objective=1.1825917
2017/08/28 14:15:36 step 6: objective=1.1875098
2017/08/28 14:15:37 step 7: objective=1.1961417
2017/08/28 14:15:37 Training value function...
2017/08/28 14:15:39 step 0: mse=157.814635 step=0.100000
2017/08/28 14:15:40 step 1: mse=155.979166 step=0.100000
2017/08/28 14:15:41 step 2: mse=153.959517 step=0.100000
2017/08/28 14:15:41 step 3: mse=152.379550 step=0.100000
2017/08/28 14:15:42 step 4: mse=150.617115 step=0.100000
2017/08/28 14:15:43 step 5: mse=149.080411 step=0.100000
2017/08/28 14:15:44 step 6: mse=147.589575 step=0.100000
2017/08/28 14:15:45 step 7: mse=146.719446 step=0.100000
2017/08/28 14:15:45 Saving...
2017/08/28 14:15:45 Gathering batch of experience...
2017/08/28 14:16:34 batch 262: mean=56.790123 stddev=48.340795 entropy=0.521373 frames=4408 count=81
2017/08/28 14:16:34 Training policy...
2017/08/28 14:16:37 step 0: objective=1.2428257
2017/08/28 14:16:38 step 1: objective=1.2598922
2017/08/28 14:16:39 step 2: objective=1.2710066
2017/08/28 14:16:40 step 3: objective=1.2890118
2017/08/28 14:16:41 step 4: objective=1.2958146
2017/08/28 14:16:42 step 5: objective=1.3040009
2017/08/28 14:16:43 step 6: objective=1.3139987
2017/08/28 14:16:44 step 7: objective=1.3253357
2017/08/28 14:16:44 Training value function...
2017/08/28 14:16:46 step 0: mse=199.318614 step=0.100000
2017/08/28 14:16:46 step 1: mse=197.242543 step=0.100000
2017/08/28 14:16:47 step 2: mse=195.344587 step=0.100000
2017/08/28 14:16:48 step 3: mse=193.765744 step=0.100000
2017/08/28 14:16:49 step 4: mse=192.455248 step=0.100000
2017/08/28 14:16:50 step 5: mse=190.954530 step=0.100000
2017/08/28 14:16:51 step 6: mse=189.776682 step=0.100000
2017/08/28 14:16:52 step 7: mse=188.741261 step=0.100000
2017/08/28 14:16:52 Saving...
2017/08/28 14:16:52 Gathering batch of experience...
2017/08/28 14:17:48 batch 263: mean=43.135417 stddev=40.967879 entropy=0.523838 frames=4515 count=96
2017/08/28 14:17:48 Training policy...
2017/08/28 14:17:51 step 0: objective=-0.67882234
2017/08/28 14:17:52 step 1: objective=-0.66659874
2017/08/28 14:17:53 step 2: objective=-0.6545698
2017/08/28 14:17:54 step 3: objective=-0.64295256
2017/08/28 14:17:55 step 4: objective=-0.6307487
2017/08/28 14:17:56 step 5: objective=-0.62344694
2017/08/28 14:17:57 step 6: objective=-0.6135081
2017/08/28 14:17:58 step 7: objective=-0.6038082
2017/08/28 14:17:58 Training value function...
2017/08/28 14:18:00 step 0: mse=141.582446 step=0.100000
2017/08/28 14:18:01 step 1: mse=139.500095 step=0.100000
2017/08/28 14:18:02 step 2: mse=137.828738 step=0.100000
2017/08/28 14:18:02 step 3: mse=136.586582 step=0.100000
2017/08/28 14:18:03 step 4: mse=135.265644 step=0.100000
2017/08/28 14:18:04 step 5: mse=134.133748 step=0.100000
2017/08/28 14:18:05 step 6: mse=133.205937 step=0.100000
2017/08/28 14:18:06 step 7: mse=132.328820 step=0.100000
2017/08/28 14:18:06 Saving...
2017/08/28 14:18:06 Gathering batch of experience...
2017/08/28 14:19:02 batch 264: mean=49.118280 stddev=58.184514 entropy=0.519825 frames=4745 count=93
2017/08/28 14:19:02 Training policy...
2017/08/28 14:19:05 step 0: objective=1.1279707
2017/08/28 14:19:07 step 1: objective=1.1353176
2017/08/28 14:19:08 step 2: objective=1.1518527
2017/08/28 14:19:09 step 3: objective=1.1580712
2017/08/28 14:19:10 step 4: objective=1.1674002
2017/08/28 14:19:11 step 5: objective=1.1720232
2017/08/28 14:19:12 step 6: objective=1.1791778
2017/08/28 14:19:13 step 7: objective=1.1897436
2017/08/28 14:19:13 Training value function...
2017/08/28 14:19:15 step 0: mse=175.752487 step=0.100000
2017/08/28 14:19:16 step 1: mse=169.435325 step=0.100000
2017/08/28 14:19:17 step 2: mse=163.843390 step=0.100000
2017/08/28 14:19:18 step 3: mse=159.260372 step=0.100000
2017/08/28 14:19:19 step 4: mse=155.374458 step=0.100000
2017/08/28 14:19:20 step 5: mse=151.920478 step=0.100000
2017/08/28 14:19:21 step 6: mse=149.411862 step=0.100000
2017/08/28 14:19:22 step 7: mse=147.019467 step=0.100000
2017/08/28 14:19:22 Saving...
2017/08/28 14:19:22 Gathering batch of experience...
2017/08/28 14:20:11 batch 265: mean=54.234568 stddev=47.965850 entropy=0.527130 frames=4760 count=81
2017/08/28 14:20:11 Training policy...
2017/08/28 14:20:15 step 0: objective=1.0985701
2017/08/28 14:20:16 step 1: objective=1.11221
2017/08/28 14:20:17 step 2: objective=1.1219993
2017/08/28 14:20:18 step 3: objective=1.1292197
2017/08/28 14:20:19 step 4: objective=1.1433315
2017/08/28 14:20:20 step 5: objective=1.1497966
2017/08/28 14:20:21 step 6: objective=1.1589477
2017/08/28 14:20:22 step 7: objective=1.1645194
2017/08/28 14:20:22 Training value function...
2017/08/28 14:20:24 step 0: mse=150.802099 step=0.100000
2017/08/28 14:20:25 step 1: mse=148.062796 step=0.100000
2017/08/28 14:20:26 step 2: mse=146.074935 step=0.100000
2017/08/28 14:20:27 step 3: mse=144.162241 step=0.100000
2017/08/28 14:20:28 step 4: mse=142.765041 step=0.100000
2017/08/28 14:20:29 step 5: mse=141.317830 step=0.100000
2017/08/28 14:20:30 step 6: mse=139.994281 step=0.100000
2017/08/28 14:20:31 step 7: mse=138.658309 step=0.100000
2017/08/28 14:20:31 Saving...
2017/08/28 14:20:31 Gathering batch of experience...
2017/08/28 14:21:21 batch 266: mean=50.951807 stddev=47.022400 entropy=0.523779 frames=4563 count=83
2017/08/28 14:21:21 Training policy...
2017/08/28 14:21:24 step 0: objective=0.69695675
2017/08/28 14:21:25 step 1: objective=0.7067419
2017/08/28 14:21:26 step 2: objective=0.71243066
2017/08/28 14:21:27 step 3: objective=0.7182624
2017/08/28 14:21:28 step 4: objective=0.7341366
2017/08/28 14:21:29 step 5: objective=0.74008024
2017/08/28 14:21:30 step 6: objective=0.7494471
2017/08/28 14:21:31 step 7: objective=0.7566812
2017/08/28 14:21:31 Training value function...
2017/08/28 14:21:33 step 0: mse=138.026760 step=0.100000
2017/08/28 14:21:34 step 1: mse=137.364510 step=0.100000
2017/08/28 14:21:35 step 2: mse=136.564187 step=0.100000
2017/08/28 14:21:36 step 3: mse=135.725854 step=0.100000
2017/08/28 14:21:37 step 4: mse=135.082568 step=0.100000
2017/08/28 14:21:38 step 5: mse=134.110748 step=0.100000
2017/08/28 14:21:39 step 6: mse=133.362872 step=0.100000
2017/08/28 14:21:40 step 7: mse=132.274025 step=0.100000
2017/08/28 14:21:40 Saving...
2017/08/28 14:21:40 Gathering batch of experience...
2017/08/28 14:22:37 batch 267: mean=43.696078 stddev=49.996233 entropy=0.523877 frames=4664 count=102
2017/08/28 14:22:37 Training policy...
2017/08/28 14:22:40 step 0: objective=0.7595295
2017/08/28 14:22:41 step 1: objective=0.76962036
2017/08/28 14:22:42 step 2: objective=0.78183347
2017/08/28 14:22:43 step 3: objective=0.79131234
2017/08/28 14:22:44 step 4: objective=0.79831904
2017/08/28 14:22:45 step 5: objective=0.805547
2017/08/28 14:22:46 step 6: objective=0.8106549
2017/08/28 14:22:47 step 7: objective=0.8187664
2017/08/28 14:22:47 Training value function...
2017/08/28 14:22:49 step 0: mse=166.460825 step=0.100000
2017/08/28 14:22:50 step 1: mse=164.635980 step=0.100000
2017/08/28 14:22:51 step 2: mse=162.732724 step=0.100000
2017/08/28 14:22:52 step 3: mse=160.983430 step=0.100000
2017/08/28 14:22:53 step 4: mse=159.485446 step=0.100000
2017/08/28 14:22:54 step 5: mse=157.976928 step=0.100000
2017/08/28 14:22:55 step 6: mse=156.687188 step=0.100000
2017/08/28 14:22:56 step 7: mse=155.614847 step=0.100000
2017/08/28 14:22:56 Saving...
2017/08/28 14:22:56 Gathering batch of experience...
2017/08/28 14:23:44 batch 268: mean=52.237500 stddev=51.137130 entropy=0.519992 frames=4306 count=80
2017/08/28 14:23:44 Training policy...
2017/08/28 14:23:47 step 0: objective=1.3115185
2017/08/28 14:23:48 step 1: objective=1.3200419
2017/08/28 14:23:49 step 2: objective=1.3346207
2017/08/28 14:23:50 step 3: objective=1.3459504
2017/08/28 14:23:51 step 4: objective=1.3586066
2017/08/28 14:23:52 step 5: objective=1.3695902
2017/08/28 14:23:53 step 6: objective=1.3807576
2017/08/28 14:23:54 step 7: objective=1.3913649
2017/08/28 14:23:54 Training value function...
2017/08/28 14:23:56 step 0: mse=172.965619 step=0.100000
2017/08/28 14:23:57 step 1: mse=170.928340 step=0.100000
2017/08/28 14:23:57 step 2: mse=168.755589 step=0.100000
2017/08/28 14:23:58 step 3: mse=166.552102 step=0.100000
2017/08/28 14:23:59 step 4: mse=165.119334 step=0.100000
2017/08/28 14:24:00 step 5: mse=163.415283 step=0.100000
2017/08/28 14:24:01 step 6: mse=162.385468 step=0.100000
2017/08/28 14:24:02 step 7: mse=160.934079 step=0.100000
2017/08/28 14:24:02 Saving...
2017/08/28 14:24:02 Gathering batch of experience...
2017/08/28 14:24:54 batch 269: mean=52.693182 stddev=43.510280 entropy=0.514367 frames=4548 count=88
2017/08/28 14:24:54 Training policy...
2017/08/28 14:24:57 step 0: objective=1.297177
2017/08/28 14:24:58 step 1: objective=1.3109399
2017/08/28 14:24:59 step 2: objective=1.3244839
2017/08/28 14:25:00 step 3: objective=1.3354514
2017/08/28 14:25:01 step 4: objective=1.3471265
2017/08/28 14:25:02 step 5: objective=1.3525279
2017/08/28 14:25:03 step 6: objective=1.3577557
2017/08/28 14:25:04 step 7: objective=1.3632988
2017/08/28 14:25:04 Training value function...
2017/08/28 14:25:06 step 0: mse=157.559249 step=0.100000
2017/08/28 14:25:07 step 1: mse=156.038517 step=0.100000
2017/08/28 14:25:08 step 2: mse=154.358856 step=0.100000
2017/08/28 14:25:09 step 3: mse=153.034230 step=0.100000
2017/08/28 14:25:10 step 4: mse=152.016807 step=0.100000
2017/08/28 14:25:11 step 5: mse=150.967736 step=0.100000
2017/08/28 14:25:11 step 6: mse=150.007326 step=0.100000
2017/08/28 14:25:12 step 7: mse=149.052702 step=0.100000
2017/08/28 14:25:12 Saving...
2017/08/28 14:25:12 Gathering batch of experience...
2017/08/28 14:26:04 batch 270: mean=55.305882 stddev=58.888533 entropy=0.513608 frames=4584 count=85
2017/08/28 14:26:04 Training policy...
2017/08/28 14:26:07 step 0: objective=1.6282909
2017/08/28 14:26:08 step 1: objective=1.6370614
2017/08/28 14:26:09 step 2: objective=1.6460341
2017/08/28 14:26:10 step 3: objective=1.656409
2017/08/28 14:26:11 step 4: objective=1.6695342
2017/08/28 14:26:12 step 5: objective=1.6854265
2017/08/28 14:26:13 step 6: objective=1.6965289
2017/08/28 14:26:14 step 7: objective=1.702304
2017/08/28 14:26:14 Training value function...
2017/08/28 14:26:16 step 0: mse=240.095591 step=0.100000
2017/08/28 14:26:17 step 1: mse=233.361128 step=0.100000
2017/08/28 14:26:18 step 2: mse=226.691426 step=0.100000
2017/08/28 14:26:19 step 3: mse=221.373538 step=0.100000
2017/08/28 14:26:20 step 4: mse=216.969358 step=0.100000
2017/08/28 14:26:21 step 5: mse=213.410498 step=0.100000
2017/08/28 14:26:22 step 6: mse=210.142380 step=0.100000
2017/08/28 14:26:23 step 7: mse=206.618626 step=0.100000
2017/08/28 14:26:23 Saving...
2017/08/28 14:26:23 Gathering batch of experience...
2017/08/28 14:27:16 batch 271: mean=53.541176 stddev=51.551129 entropy=0.510052 frames=4779 count=85
2017/08/28 14:27:16 Training policy...
2017/08/28 14:27:19 step 0: objective=0.35563472
2017/08/28 14:27:20 step 1: objective=0.3701715
2017/08/28 14:27:21 step 2: objective=0.38345113
2017/08/28 14:27:22 step 3: objective=0.39560443
2017/08/28 14:27:23 step 4: objective=0.407534
2017/08/28 14:27:25 step 5: objective=0.4191349
2017/08/28 14:27:26 step 6: objective=0.42490068
2017/08/28 14:27:27 step 7: objective=0.43414292
2017/08/28 14:27:27 Training value function...
2017/08/28 14:27:29 step 0: mse=160.407904 step=0.100000
2017/08/28 14:27:30 step 1: mse=158.748919 step=0.100000
2017/08/28 14:27:31 step 2: mse=156.955570 step=0.100000
2017/08/28 14:27:32 step 3: mse=155.331855 step=0.100000
2017/08/28 14:27:33 step 4: mse=154.383621 step=0.100000
2017/08/28 14:27:34 step 5: mse=153.460385 step=0.100000
2017/08/28 14:27:35 step 6: mse=152.708868 step=0.100000
2017/08/28 14:27:36 step 7: mse=151.889345 step=0.100000
2017/08/28 14:27:36 Saving...
2017/08/28 14:27:36 Gathering batch of experience...
2017/08/28 14:28:28 batch 272: mean=52.790698 stddev=50.299595 entropy=0.515907 frames=4550 count=86
2017/08/28 14:28:28 Training policy...
2017/08/28 14:28:31 step 0: objective=1.1087075
2017/08/28 14:28:32 step 1: objective=1.1173396
2017/08/28 14:28:33 step 2: objective=1.1273246
2017/08/28 14:28:34 step 3: objective=1.1360861
2017/08/28 14:28:35 step 4: objective=1.1480788
2017/08/28 14:28:36 step 5: objective=1.1570321
2017/08/28 14:28:37 step 6: objective=1.1654826
2017/08/28 14:28:38 step 7: objective=1.1718276
2017/08/28 14:28:38 Training value function...
2017/08/28 14:28:40 step 0: mse=170.460833 step=0.100000
2017/08/28 14:28:41 step 1: mse=168.489833 step=0.100000
2017/08/28 14:28:42 step 2: mse=165.650920 step=0.100000
2017/08/28 14:28:43 step 3: mse=163.882560 step=0.100000
2017/08/28 14:28:44 step 4: mse=161.572968 step=0.100000
2017/08/28 14:28:45 step 5: mse=159.864570 step=0.100000
2017/08/28 14:28:46 step 6: mse=158.173875 step=0.100000
2017/08/28 14:28:46 step 7: mse=156.489001 step=0.100000
2017/08/28 14:28:46 Saving...
2017/08/28 14:28:46 Gathering batch of experience...
2017/08/28 14:29:39 batch 273: mean=57.083333 stddev=49.749900 entropy=0.510987 frames=4615 count=84
2017/08/28 14:29:39 Training policy...
2017/08/28 14:29:42 step 0: objective=1.435663
2017/08/28 14:29:43 step 1: objective=1.4447991
2017/08/28 14:29:44 step 2: objective=1.4599986
2017/08/28 14:29:45 step 3: objective=1.4690262
2017/08/28 14:29:46 step 4: objective=1.4754801
2017/08/28 14:29:47 step 5: objective=1.4822304
2017/08/28 14:29:48 step 6: objective=1.4871855
2017/08/28 14:29:49 step 7: objective=1.4934342
2017/08/28 14:29:49 Training value function...
2017/08/28 14:29:51 step 0: mse=189.502221 step=0.100000
2017/08/28 14:29:52 step 1: mse=185.478982 step=0.100000
2017/08/28 14:29:53 step 2: mse=182.281293 step=0.100000
2017/08/28 14:29:54 step 3: mse=179.282585 step=0.100000
2017/08/28 14:29:55 step 4: mse=176.824559 step=0.100000
2017/08/28 14:29:56 step 5: mse=174.527344 step=0.100000
2017/08/28 14:29:57 step 6: mse=172.945604 step=0.100000
2017/08/28 14:29:58 step 7: mse=171.273365 step=0.100000
2017/08/28 14:29:58 Saving...
2017/08/28 14:29:58 Gathering batch of experience...
2017/08/28 14:30:50 batch 274: mean=51.681818 stddev=49.883853 entropy=0.518009 frames=4788 count=88
2017/08/28 14:30:50 Training policy...
2017/08/28 14:30:53 step 0: objective=0.18714051
2017/08/28 14:30:54 step 1: objective=0.19757517
2017/08/28 14:30:55 step 2: objective=0.21167423
2017/08/28 14:30:56 step 3: objective=0.21954991
2017/08/28 14:30:57 step 4: objective=0.23144794
2017/08/28 14:30:58 step 5: objective=0.23732488
2017/08/28 14:30:59 step 6: objective=0.24697047
2017/08/28 14:31:00 step 7: objective=0.2553933
2017/08/28 14:31:00 Training value function...
2017/08/28 14:31:02 step 0: mse=159.109521 step=0.100000
2017/08/28 14:31:03 step 1: mse=157.613956 step=0.100000
2017/08/28 14:31:04 step 2: mse=156.051894 step=0.100000
2017/08/28 14:31:05 step 3: mse=155.321779 step=0.100000
2017/08/28 14:31:06 step 4: mse=154.103737 step=0.100000
2017/08/28 14:31:07 step 5: mse=152.953799 step=0.100000
2017/08/28 14:31:08 step 6: mse=151.700649 step=0.100000
2017/08/28 14:31:09 step 7: mse=150.610339 step=0.100000
2017/08/28 14:31:09 Saving...
2017/08/28 14:31:09 Gathering batch of experience...
2017/08/28 14:32:02 batch 275: mean=54.430233 stddev=62.781745 entropy=0.510967 frames=4759 count=86
2017/08/28 14:32:02 Training policy...
2017/08/28 14:32:05 step 0: objective=1.0722458
2017/08/28 14:32:06 step 1: objective=1.0904819
2017/08/28 14:32:07 step 2: objective=1.1027002
2017/08/28 14:32:08 step 3: objective=1.1112883
2017/08/28 14:32:09 step 4: objective=1.1198381
2017/08/28 14:32:10 step 5: objective=1.1314747
2017/08/28 14:32:11 step 6: objective=1.1392515
2017/08/28 14:32:12 step 7: objective=1.1433533
2017/08/28 14:32:12 Training value function...
2017/08/28 14:32:14 step 0: mse=214.487552 step=0.100000
2017/08/28 14:32:15 step 1: mse=206.404954 step=0.100000
2017/08/28 14:32:16 step 2: mse=199.773220 step=0.100000
2017/08/28 14:32:17 step 3: mse=194.214218 step=0.100000
2017/08/28 14:32:18 step 4: mse=189.447746 step=0.100000
2017/08/28 14:32:19 step 5: mse=185.560154 step=0.100000
2017/08/28 14:32:20 step 6: mse=182.493199 step=0.100000
2017/08/28 14:32:21 step 7: mse=180.206088 step=0.100000
2017/08/28 14:32:21 Saving...
2017/08/28 14:32:21 Gathering batch of experience...
2017/08/28 14:33:10 batch 276: mean=54.695122 stddev=47.775054 entropy=0.516074 frames=4538 count=82
2017/08/28 14:33:10 Training policy...
2017/08/28 14:33:13 step 0: objective=0.96972
2017/08/28 14:33:14 step 1: objective=0.9782971
2017/08/28 14:33:15 step 2: objective=0.9867258
2017/08/28 14:33:16 step 3: objective=0.99622697
2017/08/28 14:33:17 step 4: objective=1.0041101
2017/08/28 14:33:19 step 5: objective=1.0174259
2017/08/28 14:33:20 step 6: objective=1.0244335
2017/08/28 14:33:21 step 7: objective=1.0360897
2017/08/28 14:33:21 Training value function...
2017/08/28 14:33:22 step 0: mse=178.495041 step=0.100000
2017/08/28 14:33:23 step 1: mse=176.525388 step=0.100000
2017/08/28 14:33:24 step 2: mse=175.229916 step=0.100000
2017/08/28 14:33:25 step 3: mse=174.056261 step=0.100000
2017/08/28 14:33:26 step 4: mse=172.889194 step=0.100000
2017/08/28 14:33:27 step 5: mse=171.835449 step=0.100000
2017/08/28 14:33:28 step 6: mse=170.587868 step=0.100000
2017/08/28 14:33:29 step 7: mse=169.766982 step=0.100000
2017/08/28 14:33:29 Saving...
2017/08/28 14:33:29 Gathering batch of experience...
2017/08/28 14:34:19 batch 277: mean=52.752941 stddev=48.968635 entropy=0.511992 frames=4512 count=85
2017/08/28 14:34:19 Training policy...
2017/08/28 14:34:22 step 0: objective=0.9342634
2017/08/28 14:34:23 step 1: objective=0.94456285
2017/08/28 14:34:24 step 2: objective=0.95659256
2017/08/28 14:34:25 step 3: objective=0.97221017
2017/08/28 14:34:26 step 4: objective=0.98111004
2017/08/28 14:34:27 step 5: objective=0.98641294
2017/08/28 14:34:28 step 6: objective=0.99382526
2017/08/28 14:34:29 step 7: objective=1.0046906
2017/08/28 14:34:29 Training value function...
2017/08/28 14:34:31 step 0: mse=169.664161 step=0.100000
2017/08/28 14:34:32 step 1: mse=168.081848 step=0.100000
2017/08/28 14:34:33 step 2: mse=166.355758 step=0.100000
2017/08/28 14:34:34 step 3: mse=164.757194 step=0.100000
2017/08/28 14:34:35 step 4: mse=163.439632 step=0.100000
2017/08/28 14:34:36 step 5: mse=162.107546 step=0.100000
2017/08/28 14:34:37 step 6: mse=161.254667 step=0.100000
2017/08/28 14:34:37 step 7: mse=159.902230 step=0.100000
2017/08/28 14:34:37 Saving...
2017/08/28 14:34:38 Gathering batch of experience...
2017/08/28 14:35:29 batch 278: mean=57.468354 stddev=50.550347 entropy=0.516349 frames=4625 count=79
2017/08/28 14:35:29 Training policy...
2017/08/28 14:35:32 step 0: objective=1.2029059
2017/08/28 14:35:33 step 1: objective=1.2147702
2017/08/28 14:35:34 step 2: objective=1.2333969
2017/08/28 14:35:35 step 3: objective=1.2411904
2017/08/28 14:35:36 step 4: objective=1.2505404
2017/08/28 14:35:37 step 5: objective=1.2584789
2017/08/28 14:35:38 step 6: objective=1.2662313
2017/08/28 14:35:39 step 7: objective=1.2745427
2017/08/28 14:35:39 Training value function...
2017/08/28 14:35:41 step 0: mse=169.340240 step=0.100000
2017/08/28 14:35:42 step 1: mse=167.415809 step=0.100000
2017/08/28 14:35:43 step 2: mse=165.801743 step=0.100000
2017/08/28 14:35:44 step 3: mse=164.030428 step=0.100000
2017/08/28 14:35:45 step 4: mse=162.441441 step=0.100000
2017/08/28 14:35:46 step 5: mse=161.103272 step=0.100000
2017/08/28 14:35:47 step 6: mse=159.707711 step=0.100000
2017/08/28 14:35:48 step 7: mse=158.202702 step=0.100000
2017/08/28 14:35:48 Saving...
2017/08/28 14:35:48 Gathering batch of experience...
2017/08/28 14:36:38 batch 279: mean=50.779070 stddev=45.283192 entropy=0.504584 frames=4496 count=86
2017/08/28 14:36:38 Training policy...
2017/08/28 14:36:41 step 0: objective=0.5131231
2017/08/28 14:36:42 step 1: objective=0.52104664
2017/08/28 14:36:43 step 2: objective=0.5294974
2017/08/28 14:36:44 step 3: objective=0.5361832
2017/08/28 14:36:45 step 4: objective=0.5451814
2017/08/28 14:36:46 step 5: objective=0.5540546
2017/08/28 14:36:47 step 6: objective=0.5621854
2017/08/28 14:36:48 step 7: objective=0.56959623
2017/08/28 14:36:48 Training value function...
2017/08/28 14:36:50 step 0: mse=148.011443 step=0.100000
2017/08/28 14:36:51 step 1: mse=146.640895 step=0.100000
2017/08/28 14:36:52 step 2: mse=145.452836 step=0.100000
2017/08/28 14:36:53 step 3: mse=144.519428 step=0.100000
2017/08/28 14:36:54 step 4: mse=143.551681 step=0.100000
2017/08/28 14:36:55 step 5: mse=142.505974 step=0.100000
2017/08/28 14:36:56 step 6: mse=141.414344 step=0.100000
2017/08/28 14:36:57 step 7: mse=140.636300 step=0.100000
2017/08/28 14:36:57 Saving...
2017/08/28 14:36:57 Gathering batch of experience...
2017/08/28 14:37:46 batch 280: mean=64.378378 stddev=57.406493 entropy=0.513018 frames=4679 count=74
2017/08/28 14:37:46 Training policy...
2017/08/28 14:37:49 step 0: objective=2.0838916
2017/08/28 14:37:50 step 1: objective=2.0920148
2017/08/28 14:37:51 step 2: objective=2.1012113
2017/08/28 14:37:52 step 3: objective=2.110703
2017/08/28 14:37:53 step 4: objective=2.1198206
2017/08/28 14:37:54 step 5: objective=2.1281142
2017/08/28 14:37:55 step 6: objective=2.1320517
2017/08/28 14:37:56 step 7: objective=2.1376252
2017/08/28 14:37:56 Training value function...
2017/08/28 14:37:58 step 0: mse=191.781307 step=0.100000
2017/08/28 14:37:59 step 1: mse=187.818330 step=0.100000
2017/08/28 14:38:00 step 2: mse=184.246785 step=0.100000
2017/08/28 14:38:01 step 3: mse=181.125469 step=0.100000
2017/08/28 14:38:02 step 4: mse=178.735400 step=0.100000
2017/08/28 14:38:03 step 5: mse=176.107736 step=0.100000
2017/08/28 14:38:04 step 6: mse=174.291270 step=0.100000
2017/08/28 14:38:05 step 7: mse=172.229575 step=0.100000
2017/08/28 14:38:05 Saving...
2017/08/28 14:38:05 Gathering batch of experience...
2017/08/28 14:38:50 batch 281: mean=69.925373 stddev=64.405968 entropy=0.511349 frames=4587 count=67
2017/08/28 14:38:50 Training policy...
2017/08/28 14:38:53 step 0: objective=1.5446998
2017/08/28 14:38:54 step 1: objective=1.5557361
2017/08/28 14:38:55 step 2: objective=1.563153
2017/08/28 14:38:56 step 3: objective=1.5758959
2017/08/28 14:38:57 step 4: objective=1.5854598
2017/08/28 14:38:58 step 5: objective=1.5955851
2017/08/28 14:38:59 step 6: objective=1.6013621
2017/08/28 14:39:00 step 7: objective=1.6081507
2017/08/28 14:39:00 Training value function...
2017/08/28 14:39:02 step 0: mse=192.257612 step=0.100000
2017/08/28 14:39:03 step 1: mse=189.038203 step=0.100000
2017/08/28 14:39:04 step 2: mse=186.170876 step=0.100000
2017/08/28 14:39:05 step 3: mse=183.271027 step=0.100000
2017/08/28 14:39:06 step 4: mse=180.636229 step=0.100000
2017/08/28 14:39:07 step 5: mse=178.593899 step=0.100000
2017/08/28 14:39:08 step 6: mse=176.299324 step=0.100000
2017/08/28 14:39:08 step 7: mse=174.630918 step=0.100000
2017/08/28 14:39:08 Saving...
2017/08/28 14:39:09 Gathering batch of experience...
2017/08/28 14:40:01 batch 282: mean=55.951220 stddev=54.794050 entropy=0.510439 frames=4678 count=82
2017/08/28 14:40:01 Training policy...
2017/08/28 14:40:04 step 0: objective=0.18279961
2017/08/28 14:40:05 step 1: objective=0.19490103
2017/08/28 14:40:06 step 2: objective=0.20771842
2017/08/28 14:40:07 step 3: objective=0.21789928
2017/08/28 14:40:08 step 4: objective=0.22857666
2017/08/28 14:40:09 step 5: objective=0.23438959
2017/08/28 14:40:10 step 6: objective=0.24035817
2017/08/28 14:40:11 step 7: objective=0.25322464
2017/08/28 14:40:11 Training value function...
2017/08/28 14:40:13 step 0: mse=156.283303 step=0.100000
2017/08/28 14:40:14 step 1: mse=155.065612 step=0.100000
2017/08/28 14:40:15 step 2: mse=153.779014 step=0.100000
2017/08/28 14:40:16 step 3: mse=152.442990 step=0.100000
2017/08/28 14:40:17 step 4: mse=151.377471 step=0.100000
2017/08/28 14:40:18 step 5: mse=150.415798 step=0.100000
2017/08/28 14:40:19 step 6: mse=149.241173 step=0.100000
2017/08/28 14:40:20 step 7: mse=148.442354 step=0.100000
2017/08/28 14:40:20 Saving...
2017/08/28 14:40:20 Gathering batch of experience...
2017/08/28 14:41:14 batch 283: mean=52.111111 stddev=56.930454 entropy=0.508999 frames=4764 count=90
2017/08/28 14:41:14 Training policy...
2017/08/28 14:41:17 step 0: objective=0.4035386
2017/08/28 14:41:18 step 1: objective=0.4127519
2017/08/28 14:41:19 step 2: objective=0.42225477
2017/08/28 14:41:20 step 3: objective=0.4282858
2017/08/28 14:41:21 step 4: objective=0.43380854
2017/08/28 14:41:22 step 5: objective=0.44537526
2017/08/28 14:41:23 step 6: objective=0.45124936
2017/08/28 14:41:24 step 7: objective=0.46436474
2017/08/28 14:41:24 Training value function...
2017/08/28 14:41:26 step 0: mse=155.744385 step=0.100000
2017/08/28 14:41:27 step 1: mse=154.060472 step=0.100000
2017/08/28 14:41:28 step 2: mse=152.659820 step=0.100000
2017/08/28 14:41:29 step 3: mse=151.430348 step=0.100000
2017/08/28 14:41:30 step 4: mse=150.375803 step=0.100000
2017/08/28 14:41:31 step 5: mse=149.316175 step=0.100000
2017/08/28 14:41:32 step 6: mse=148.264691 step=0.100000
2017/08/28 14:41:33 step 7: mse=147.376625 step=0.100000
2017/08/28 14:41:33 Saving...
2017/08/28 14:41:33 Gathering batch of experience...
2017/08/28 14:42:19 batch 284: mean=64.273973 stddev=54.422815 entropy=0.512676 frames=4563 count=73
2017/08/28 14:42:19 Training policy...
2017/08/28 14:42:22 step 0: objective=1.7882179
2017/08/28 14:42:23 step 1: objective=1.7971376
2017/08/28 14:42:24 step 2: objective=1.8107879
2017/08/28 14:42:25 step 3: objective=1.8177924
2017/08/28 14:42:26 step 4: objective=1.8271196
2017/08/28 14:42:27 step 5: objective=1.8318228
2017/08/28 14:42:28 step 6: objective=1.8375263
2017/08/28 14:42:29 step 7: objective=1.8432631
2017/08/28 14:42:29 Training value function...
2017/08/28 14:42:31 step 0: mse=174.731559 step=0.100000
2017/08/28 14:42:32 step 1: mse=172.306198 step=0.100000
2017/08/28 14:42:33 step 2: mse=170.167026 step=0.100000
2017/08/28 14:42:34 step 3: mse=168.059870 step=0.100000
2017/08/28 14:42:35 step 4: mse=165.947235 step=0.100000
2017/08/28 14:42:36 step 5: mse=164.623982 step=0.100000
2017/08/28 14:42:37 step 6: mse=163.270090 step=0.100000
2017/08/28 14:42:38 step 7: mse=161.509576 step=0.100000
2017/08/28 14:42:38 Saving...
2017/08/28 14:42:38 Gathering batch of experience...
2017/08/28 14:43:28 batch 285: mean=55.395062 stddev=51.537516 entropy=0.505604 frames=4727 count=81
2017/08/28 14:43:28 Training policy...
2017/08/28 14:43:31 step 0: objective=0.6658376
2017/08/28 14:43:32 step 1: objective=0.6774307
2017/08/28 14:43:33 step 2: objective=0.68926215
2017/08/28 14:43:34 step 3: objective=0.6957352
2017/08/28 14:43:35 step 4: objective=0.7021219
2017/08/28 14:43:37 step 5: objective=0.7096133
2017/08/28 14:43:38 step 6: objective=0.71509314
2017/08/28 14:43:39 step 7: objective=0.7220238
2017/08/28 14:43:39 Training value function...
2017/08/28 14:43:41 step 0: mse=154.897711 step=0.100000
2017/08/28 14:43:42 step 1: mse=153.256102 step=0.100000
2017/08/28 14:43:43 step 2: mse=151.754038 step=0.100000
2017/08/28 14:43:44 step 3: mse=150.627636 step=0.100000
2017/08/28 14:43:44 step 4: mse=149.274674 step=0.100000
2017/08/28 14:43:45 step 5: mse=148.038681 step=0.100000
2017/08/28 14:43:46 step 6: mse=147.034648 step=0.100000
2017/08/28 14:43:47 step 7: mse=146.054145 step=0.100000
2017/08/28 14:43:47 Saving...
2017/08/28 14:43:47 Gathering batch of experience...
2017/08/28 14:44:35 batch 286: mean=53.602564 stddev=58.020407 entropy=0.505933 frames=4487 count=78
2017/08/28 14:44:35 Training policy...
2017/08/28 14:44:38 step 0: objective=0.36459187
2017/08/28 14:44:39 step 1: objective=0.37302774
2017/08/28 14:44:40 step 2: objective=0.38133287
2017/08/28 14:44:41 step 3: objective=0.38820717
2017/08/28 14:44:42 step 4: objective=0.39372662
2017/08/28 14:44:43 step 5: objective=0.404208
2017/08/28 14:44:44 step 6: objective=0.4162053
2017/08/28 14:44:45 step 7: objective=0.42413205
2017/08/28 14:44:45 Training value function...
2017/08/28 14:44:47 step 0: mse=171.017336 step=0.100000
2017/08/28 14:44:48 step 1: mse=168.070473 step=0.100000
2017/08/28 14:44:49 step 2: mse=165.642719 step=0.100000
2017/08/28 14:44:50 step 3: mse=163.739465 step=0.100000
2017/08/28 14:44:51 step 4: mse=161.974649 step=0.100000
2017/08/28 14:44:52 step 5: mse=160.227281 step=0.100000
2017/08/28 14:44:53 step 6: mse=158.693716 step=0.100000
2017/08/28 14:44:53 step 7: mse=157.176176 step=0.100000
2017/08/28 14:44:53 Saving...
2017/08/28 14:44:53 Gathering batch of experience...
2017/08/28 14:45:42 batch 287: mean=67.567568 stddev=63.443544 entropy=0.499339 frames=4956 count=74
2017/08/28 14:45:42 Training policy...
2017/08/28 14:45:45 step 0: objective=1.9607158
2017/08/28 14:45:46 step 1: objective=1.9682198
2017/08/28 14:45:47 step 2: objective=1.9752338
2017/08/28 14:45:49 step 3: objective=1.9835281
2017/08/28 14:45:50 step 4: objective=1.992403
2017/08/28 14:45:51 step 5: objective=1.9985529
2017/08/28 14:45:52 step 6: objective=2.0087972
2017/08/28 14:45:53 step 7: objective=2.0136175
2017/08/28 14:45:53 Training value function...
2017/08/28 14:45:55 step 0: mse=196.977725 step=0.100000
2017/08/28 14:45:56 step 1: mse=193.721255 step=0.100000
2017/08/28 14:45:57 step 2: mse=190.797103 step=0.100000
2017/08/28 14:45:58 step 3: mse=188.084739 step=0.100000
2017/08/28 14:45:59 step 4: mse=185.846803 step=0.100000
2017/08/28 14:46:00 step 5: mse=183.777837 step=0.100000
2017/08/28 14:46:01 step 6: mse=181.597020 step=0.100000
2017/08/28 14:46:02 step 7: mse=180.101810 step=0.100000
2017/08/28 14:46:02 Saving...
2017/08/28 14:46:02 Gathering batch of experience...
2017/08/28 14:46:55 batch 288: mean=59.962963 stddev=53.047252 entropy=0.507764 frames=4987 count=81
2017/08/28 14:46:55 Training policy...
2017/08/28 14:46:58 step 0: objective=0.39090532
2017/08/28 14:46:59 step 1: objective=0.40046543
2017/08/28 14:47:01 step 2: objective=0.41559592
2017/08/28 14:47:02 step 3: objective=0.42562664
2017/08/28 14:47:03 step 4: objective=0.43643963
2017/08/28 14:47:04 step 5: objective=0.4427273
2017/08/28 14:47:05 step 6: objective=0.45015723
2017/08/28 14:47:06 step 7: objective=0.45680812
2017/08/28 14:47:06 Training value function...
2017/08/28 14:47:08 step 0: mse=153.843314 step=0.100000
2017/08/28 14:47:09 step 1: mse=152.166947 step=0.100000
2017/08/28 14:47:10 step 2: mse=151.101817 step=0.100000
2017/08/28 14:47:11 step 3: mse=149.820520 step=0.100000
2017/08/28 14:47:12 step 4: mse=148.850967 step=0.100000
2017/08/28 14:47:13 step 5: mse=147.662146 step=0.100000
2017/08/28 14:47:14 step 6: mse=146.818177 step=0.100000
2017/08/28 14:47:16 step 7: mse=146.472748 step=0.100000
2017/08/28 14:47:16 Saving...
2017/08/28 14:47:16 Gathering batch of experience...
2017/08/28 14:48:06 batch 289: mean=48.134831 stddev=37.840348 entropy=0.498519 frames=4474 count=89
2017/08/28 14:48:06 Training policy...
2017/08/28 14:48:09 step 0: objective=-0.4851974
2017/08/28 14:48:10 step 1: objective=-0.47494966
2017/08/28 14:48:11 step 2: objective=-0.46529853
2017/08/28 14:48:12 step 3: objective=-0.45064887
2017/08/28 14:48:13 step 4: objective=-0.4452648
2017/08/28 14:48:14 step 5: objective=-0.4396274
2017/08/28 14:48:15 step 6: objective=-0.43333668
2017/08/28 14:48:16 step 7: objective=-0.42252538
2017/08/28 14:48:16 Training value function...
2017/08/28 14:48:18 step 0: mse=144.211408 step=0.100000
2017/08/28 14:48:19 step 1: mse=140.006378 step=0.100000
2017/08/28 14:48:20 step 2: mse=136.718147 step=0.100000
2017/08/28 14:48:21 step 3: mse=134.063692 step=0.100000
2017/08/28 14:48:22 step 4: mse=131.726123 step=0.100000
2017/08/28 14:48:23 step 5: mse=129.812504 step=0.100000
2017/08/28 14:48:24 step 6: mse=128.084980 step=0.100000
2017/08/28 14:48:25 step 7: mse=126.482700 step=0.100000
2017/08/28 14:48:25 Saving...
2017/08/28 14:48:25 Gathering batch of experience...
2017/08/28 14:49:13 batch 290: mean=54.185185 stddev=58.176426 entropy=0.510825 frames=4479 count=81
2017/08/28 14:49:13 Training policy...
2017/08/28 14:49:16 step 0: objective=1.5699753
2017/08/28 14:49:17 step 1: objective=1.580866
2017/08/28 14:49:18 step 2: objective=1.5935706
2017/08/28 14:49:19 step 3: objective=1.602219
2017/08/28 14:49:20 step 4: objective=1.6131109
2017/08/28 14:49:21 step 5: objective=1.619232
2017/08/28 14:49:22 step 6: objective=1.62617
2017/08/28 14:49:23 step 7: objective=1.6321666
2017/08/28 14:49:23 Training value function...
2017/08/28 14:49:25 step 0: mse=199.972777 step=0.100000
2017/08/28 14:49:26 step 1: mse=195.563798 step=0.100000
2017/08/28 14:49:27 step 2: mse=192.198019 step=0.100000
2017/08/28 14:49:28 step 3: mse=189.090778 step=0.100000
2017/08/28 14:49:29 step 4: mse=186.126756 step=0.100000
2017/08/28 14:49:30 step 5: mse=183.427764 step=0.100000
2017/08/28 14:49:31 step 6: mse=180.930556 step=0.100000
2017/08/28 14:49:32 step 7: mse=179.052301 step=0.100000
2017/08/28 14:49:32 Saving...
2017/08/28 14:49:32 Gathering batch of experience...
2017/08/28 14:50:20 batch 291: mean=56.721519 stddev=43.456638 entropy=0.505624 frames=4515 count=79
2017/08/28 14:50:20 Training policy...
2017/08/28 14:50:23 step 0: objective=1.0762044
2017/08/28 14:50:24 step 1: objective=1.089473
2017/08/28 14:50:25 step 2: objective=1.1025629
2017/08/28 14:50:26 step 3: objective=1.1120684
2017/08/28 14:50:27 step 4: objective=1.1231791
2017/08/28 14:50:28 step 5: objective=1.1338812
2017/08/28 14:50:29 step 6: objective=1.1446037
2017/08/28 14:50:30 step 7: objective=1.1484716
2017/08/28 14:50:30 Training value function...
2017/08/28 14:50:32 step 0: mse=150.549967 step=0.100000
2017/08/28 14:50:33 step 1: mse=148.561410 step=0.100000
2017/08/28 14:50:34 step 2: mse=146.903007 step=0.100000
2017/08/28 14:50:35 step 3: mse=145.439772 step=0.100000
2017/08/28 14:50:36 step 4: mse=143.971678 step=0.100000
2017/08/28 14:50:37 step 5: mse=142.714634 step=0.100000
2017/08/28 14:50:38 step 6: mse=141.713334 step=0.100000
2017/08/28 14:50:39 step 7: mse=140.834043 step=0.100000
2017/08/28 14:50:39 Saving...
2017/08/28 14:50:39 Gathering batch of experience...
2017/08/28 14:51:27 batch 292: mean=59.853333 stddev=57.670257 entropy=0.503351 frames=4494 count=75
2017/08/28 14:51:27 Training policy...
2017/08/28 14:51:30 step 0: objective=1.4824706
2017/08/28 14:51:31 step 1: objective=1.4979211
2017/08/28 14:51:32 step 2: objective=1.5139683
2017/08/28 14:51:33 step 3: objective=1.5226527
2017/08/28 14:51:34 step 4: objective=1.5333464
2017/08/28 14:51:35 step 5: objective=1.539982
2017/08/28 14:51:36 step 6: objective=1.5466707
2017/08/28 14:51:37 step 7: objective=1.5541514
2017/08/28 14:51:37 Training value function...
2017/08/28 14:51:39 step 0: mse=206.444362 step=0.100000
2017/08/28 14:51:40 step 1: mse=202.677317 step=0.100000
2017/08/28 14:51:41 step 2: mse=199.587056 step=0.100000
2017/08/28 14:51:42 step 3: mse=197.098013 step=0.100000
2017/08/28 14:51:43 step 4: mse=194.877292 step=0.100000
2017/08/28 14:51:44 step 5: mse=192.701809 step=0.100000
2017/08/28 14:51:45 step 6: mse=190.820539 step=0.100000
2017/08/28 14:51:45 step 7: mse=188.882612 step=0.100000
2017/08/28 14:51:45 Saving...
2017/08/28 14:51:46 Gathering batch of experience...
2017/08/28 14:52:36 batch 293: mean=67.405405 stddev=66.796771 entropy=0.507511 frames=4791 count=74
2017/08/28 14:52:36 Training policy...
2017/08/28 14:52:39 step 0: objective=2.0635555
2017/08/28 14:52:40 step 1: objective=2.0761585
2017/08/28 14:52:41 step 2: objective=2.087422
2017/08/28 14:52:42 step 3: objective=2.0975173
2017/08/28 14:52:43 step 4: objective=2.1040075
2017/08/28 14:52:44 step 5: objective=2.11149
2017/08/28 14:52:45 step 6: objective=2.115423
2017/08/28 14:52:46 step 7: objective=2.1228952
2017/08/28 14:52:46 Training value function...
2017/08/28 14:52:48 step 0: mse=186.641626 step=0.100000
2017/08/28 14:52:49 step 1: mse=180.995911 step=0.100000
2017/08/28 14:52:50 step 2: mse=176.148968 step=0.100000
2017/08/28 14:52:51 step 3: mse=171.968531 step=0.100000
2017/08/28 14:52:52 step 4: mse=168.829555 step=0.100000
2017/08/28 14:52:53 step 5: mse=165.834818 step=0.100000
2017/08/28 14:52:54 step 6: mse=163.242745 step=0.100000
2017/08/28 14:52:55 step 7: mse=161.099289 step=0.100000
2017/08/28 14:52:55 Saving...
2017/08/28 14:52:55 Gathering batch of experience...
2017/08/28 14:53:48 batch 294: mean=57.000000 stddev=56.636444 entropy=0.501132 frames=4812 count=83
2017/08/28 14:53:48 Training policy...
2017/08/28 14:53:51 step 0: objective=0.2556179
2017/08/28 14:53:52 step 1: objective=0.26784104
2017/08/28 14:53:53 step 2: objective=0.2820612
2017/08/28 14:53:54 step 3: objective=0.29268828
2017/08/28 14:53:56 step 4: objective=0.3033251
2017/08/28 14:53:57 step 5: objective=0.3080592
2017/08/28 14:53:58 step 6: objective=0.31482896
2017/08/28 14:53:59 step 7: objective=0.3197651
2017/08/28 14:53:59 Training value function...
2017/08/28 14:54:01 step 0: mse=178.008746 step=0.100000
2017/08/28 14:54:02 step 1: mse=176.888332 step=0.100000
2017/08/28 14:54:03 step 2: mse=175.692479 step=0.100000
2017/08/28 14:54:04 step 3: mse=174.569763 step=0.100000
2017/08/28 14:54:05 step 4: mse=173.867414 step=0.100000
2017/08/28 14:54:06 step 5: mse=173.067944 step=0.100000
2017/08/28 14:54:07 step 6: mse=172.179986 step=0.100000
2017/08/28 14:54:08 step 7: mse=170.846537 step=0.100000
2017/08/28 14:54:08 Saving...
2017/08/28 14:54:08 Gathering batch of experience...
2017/08/28 14:54:53 batch 295: mean=67.333333 stddev=57.899630 entropy=0.511687 frames=4592 count=69
2017/08/28 14:54:53 Training policy...
2017/08/28 14:54:56 step 0: objective=1.3181924
2017/08/28 14:54:57 step 1: objective=1.3261658
2017/08/28 14:54:59 step 2: objective=1.3368647
2017/08/28 14:55:00 step 3: objective=1.3450373
2017/08/28 14:55:01 step 4: objective=1.3604691
2017/08/28 14:55:02 step 5: objective=1.366707
2017/08/28 14:55:03 step 6: objective=1.3760996
2017/08/28 14:55:04 step 7: objective=1.3822112
2017/08/28 14:55:04 Training value function...
2017/08/28 14:55:06 step 0: mse=170.623936 step=0.100000
2017/08/28 14:55:07 step 1: mse=168.550141 step=0.100000
2017/08/28 14:55:08 step 2: mse=166.503371 step=0.100000
2017/08/28 14:55:09 step 3: mse=164.474842 step=0.100000
2017/08/28 14:55:10 step 4: mse=162.952689 step=0.100000
2017/08/28 14:55:11 step 5: mse=161.372629 step=0.100000
2017/08/28 14:55:11 step 6: mse=159.999975 step=0.100000
2017/08/28 14:55:12 step 7: mse=158.435671 step=0.100000
2017/08/28 14:55:12 Saving...
2017/08/28 14:55:12 Gathering batch of experience...
2017/08/28 14:55:58 batch 296: mean=57.958904 stddev=66.591875 entropy=0.510111 frames=4408 count=73
2017/08/28 14:55:58 Training policy...
2017/08/28 14:56:01 step 0: objective=0.5024439
2017/08/28 14:56:02 step 1: objective=0.5206928
2017/08/28 14:56:03 step 2: objective=0.53145385
2017/08/28 14:56:04 step 3: objective=0.54113793
2017/08/28 14:56:05 step 4: objective=0.5542902
2017/08/28 14:56:06 step 5: objective=0.5597699
2017/08/28 14:56:07 step 6: objective=0.564758
2017/08/28 14:56:08 step 7: objective=0.5701028
2017/08/28 14:56:08 Training value function...
2017/08/28 14:56:10 step 0: mse=185.416800 step=0.100000
2017/08/28 14:56:11 step 1: mse=179.471289 step=0.100000
2017/08/28 14:56:11 step 2: mse=174.133402 step=0.100000
2017/08/28 14:56:12 step 3: mse=169.884357 step=0.100000
2017/08/28 14:56:13 step 4: mse=166.384534 step=0.100000
2017/08/28 14:56:14 step 5: mse=163.502233 step=0.100000
2017/08/28 14:56:15 step 6: mse=160.952489 step=0.100000
2017/08/28 14:56:16 step 7: mse=158.761070 step=0.100000
2017/08/28 14:56:16 Saving...
2017/08/28 14:56:16 Gathering batch of experience...
2017/08/28 14:57:02 batch 297: mean=61.652778 stddev=51.453096 entropy=0.503168 frames=4734 count=72
2017/08/28 14:57:02 Training policy...
2017/08/28 14:57:06 step 0: objective=0.72926277
2017/08/28 14:57:07 step 1: objective=0.7425353
2017/08/28 14:57:08 step 2: objective=0.75020695
2017/08/28 14:57:09 step 3: objective=0.7646574
2017/08/28 14:57:10 step 4: objective=0.77121025
2017/08/28 14:57:11 step 5: objective=0.7780659
2017/08/28 14:57:12 step 6: objective=0.7827435
2017/08/28 14:57:13 step 7: objective=0.786619
2017/08/28 14:57:13 Training value function...
2017/08/28 14:57:15 step 0: mse=135.905332 step=0.100000
2017/08/28 14:57:16 step 1: mse=134.968064 step=0.100000
2017/08/28 14:57:17 step 2: mse=134.099962 step=0.100000
2017/08/28 14:57:18 step 3: mse=133.233815 step=0.100000
2017/08/28 14:57:19 step 4: mse=132.595239 step=0.100000
2017/08/28 14:57:20 step 5: mse=131.550256 step=0.100000
2017/08/28 14:57:21 step 6: mse=130.677587 step=0.100000
2017/08/28 14:57:22 step 7: mse=129.990161 step=0.100000
2017/08/28 14:57:22 Saving...
2017/08/28 14:57:22 Gathering batch of experience...
2017/08/28 14:58:13 batch 298: mean=62.293333 stddev=55.995660 entropy=0.504237 frames=4823 count=75
2017/08/28 14:58:13 Training policy...
2017/08/28 14:58:16 step 0: objective=1.2037238
2017/08/28 14:58:17 step 1: objective=1.2216555
2017/08/28 14:58:18 step 2: objective=1.2277288
2017/08/28 14:58:19 step 3: objective=1.2354276
2017/08/28 14:58:20 step 4: objective=1.2408034
2017/08/28 14:58:21 step 5: objective=1.2490771
2017/08/28 14:58:22 step 6: objective=1.2532452
2017/08/28 14:58:23 step 7: objective=1.257938
2017/08/28 14:58:23 Training value function...
2017/08/28 14:58:25 step 0: mse=162.214301 step=0.100000
2017/08/28 14:58:26 step 1: mse=160.180503 step=0.100000
2017/08/28 14:58:27 step 2: mse=158.175906 step=0.100000
2017/08/28 14:58:28 step 3: mse=156.648461 step=0.100000
2017/08/28 14:58:29 step 4: mse=154.995802 step=0.100000
2017/08/28 14:58:30 step 5: mse=153.694393 step=0.100000
2017/08/28 14:58:31 step 6: mse=152.344060 step=0.100000
2017/08/28 14:58:32 step 7: mse=150.982899 step=0.100000
2017/08/28 14:58:32 Saving...
2017/08/28 14:58:32 Gathering batch of experience...
2017/08/28 14:59:24 batch 299: mean=64.278481 stddev=62.322342 entropy=0.502790 frames=4834 count=79
2017/08/28 14:59:24 Training policy...
2017/08/28 14:59:27 step 0: objective=1.6362962
2017/08/28 14:59:28 step 1: objective=1.6513222
2017/08/28 14:59:29 step 2: objective=1.6622089
2017/08/28 14:59:30 step 3: objective=1.6714134
2017/08/28 14:59:32 step 4: objective=1.6801058
2017/08/28 14:59:33 step 5: objective=1.6881357
2017/08/28 14:59:34 step 6: objective=1.6982127
2017/08/28 14:59:35 step 7: objective=1.7060349
2017/08/28 14:59:35 Training value function...
2017/08/28 14:59:37 step 0: mse=193.469783 step=0.100000
2017/08/28 14:59:38 step 1: mse=189.438927 step=0.100000
2017/08/28 14:59:39 step 2: mse=186.157360 step=0.100000
2017/08/28 14:59:40 step 3: mse=183.426497 step=0.100000
2017/08/28 14:59:41 step 4: mse=180.922212 step=0.100000
2017/08/28 14:59:42 step 5: mse=178.418333 step=0.100000
2017/08/28 14:59:43 step 6: mse=176.796997 step=0.100000
2017/08/28 14:59:44 step 7: mse=175.046327 step=0.100000
2017/08/28 14:59:44 Saving...
2017/08/28 14:59:44 Gathering batch of experience...
2017/08/28 15:00:36 batch 300: mean=50.943182 stddev=43.382118 entropy=0.490360 frames=4461 count=88
2017/08/28 15:00:36 Training policy...
2017/08/28 15:00:39 step 0: objective=0.12816517
2017/08/28 15:00:40 step 1: objective=0.1408359
2017/08/28 15:00:41 step 2: objective=0.15215494
2017/08/28 15:00:42 step 3: objective=0.16502146
2017/08/28 15:00:43 step 4: objective=0.17318396
2017/08/28 15:00:44 step 5: objective=0.18003651
2017/08/28 15:00:45 step 6: objective=0.1889161
2017/08/28 15:00:46 step 7: objective=0.19725214
2017/08/28 15:00:46 Training value function...
2017/08/28 15:00:48 step 0: mse=154.572863 step=0.100000
2017/08/28 15:00:49 step 1: mse=152.443959 step=0.100000
2017/08/28 15:00:49 step 2: mse=150.260279 step=0.100000
2017/08/28 15:00:50 step 3: mse=148.103915 step=0.100000
2017/08/28 15:00:51 step 4: mse=146.827278 step=0.100000
2017/08/28 15:00:52 step 5: mse=145.333993 step=0.100000
2017/08/28 15:00:53 step 6: mse=143.992128 step=0.100000
2017/08/28 15:00:54 step 7: mse=142.743458 step=0.100000
2017/08/28 15:00:54 Saving...
2017/08/28 15:00:54 Gathering batch of experience...
2017/08/28 15:01:44 batch 301: mean=52.819277 stddev=44.981159 entropy=0.498885 frames=4592 count=83
2017/08/28 15:01:44 Training policy...
2017/08/28 15:01:47 step 0: objective=0.41158405
2017/08/28 15:01:48 step 1: objective=0.42005274
2017/08/28 15:01:49 step 2: objective=0.4340703
2017/08/28 15:01:51 step 3: objective=0.44223204
2017/08/28 15:01:52 step 4: objective=0.45017502
2017/08/28 15:01:53 step 5: objective=0.45961356
2017/08/28 15:01:54 step 6: objective=0.46618882
2017/08/28 15:01:55 step 7: objective=0.47239333
2017/08/28 15:01:55 Training value function...
2017/08/28 15:01:57 step 0: mse=152.516245 step=0.100000
2017/08/28 15:01:58 step 1: mse=151.116338 step=0.100000
2017/08/28 15:01:59 step 2: mse=149.656393 step=0.100000
2017/08/28 15:01:59 step 3: mse=148.584663 step=0.100000
2017/08/28 15:02:00 step 4: mse=147.150492 step=0.100000
2017/08/28 15:02:01 step 5: mse=145.951709 step=0.100000
2017/08/28 15:02:02 step 6: mse=144.945039 step=0.100000
2017/08/28 15:02:03 step 7: mse=143.886378 step=0.100000
2017/08/28 15:02:03 Saving...
2017/08/28 15:02:03 Gathering batch of experience...
2017/08/28 15:02:51 batch 302: mean=63.600000 stddev=64.236438 entropy=0.495802 frames=4743 count=75
2017/08/28 15:02:51 Training policy...
2017/08/28 15:02:54 step 0: objective=1.7355039
2017/08/28 15:02:55 step 1: objective=1.7452881
2017/08/28 15:02:57 step 2: objective=1.760179
2017/08/28 15:02:58 step 3: objective=1.7674357
2017/08/28 15:02:59 step 4: objective=1.7778188
2017/08/28 15:03:00 step 5: objective=1.7885451
2017/08/28 15:03:01 step 6: objective=1.7929776
2017/08/28 15:03:02 step 7: objective=1.8040524
2017/08/28 15:03:02 Training value function...
2017/08/28 15:03:04 step 0: mse=192.591044 step=0.100000
2017/08/28 15:03:05 step 1: mse=187.989209 step=0.100000
2017/08/28 15:03:06 step 2: mse=183.862300 step=0.100000
2017/08/28 15:03:07 step 3: mse=180.803843 step=0.100000
2017/08/28 15:03:08 step 4: mse=177.645966 step=0.100000
2017/08/28 15:03:09 step 5: mse=174.992850 step=0.100000
2017/08/28 15:03:10 step 6: mse=172.384584 step=0.100000
2017/08/28 15:03:11 step 7: mse=170.249511 step=0.100000
2017/08/28 15:03:11 Saving...
2017/08/28 15:03:11 Gathering batch of experience...
2017/08/28 15:03:58 batch 303: mean=62.945946 stddev=54.653921 entropy=0.495799 frames=4486 count=74
2017/08/28 15:03:58 Training policy...
2017/08/28 15:04:01 step 0: objective=1.4421318
2017/08/28 15:04:02 step 1: objective=1.4523829
2017/08/28 15:04:03 step 2: objective=1.4604945
2017/08/28 15:04:04 step 3: objective=1.4712831
2017/08/28 15:04:05 step 4: objective=1.4803201
2017/08/28 15:04:06 step 5: objective=1.4930531
2017/08/28 15:04:07 step 6: objective=1.4991091
2017/08/28 15:04:08 step 7: objective=1.5094999
2017/08/28 15:04:08 Training value function...
2017/08/28 15:04:10 step 0: mse=190.960785 step=0.100000
2017/08/28 15:04:11 step 1: mse=188.787540 step=0.100000
2017/08/28 15:04:12 step 2: mse=186.718398 step=0.100000
2017/08/28 15:04:12 step 3: mse=184.789815 step=0.100000
2017/08/28 15:04:13 step 4: mse=183.319364 step=0.100000
2017/08/28 15:04:14 step 5: mse=181.864884 step=0.100000
2017/08/28 15:04:15 step 6: mse=180.494340 step=0.100000
2017/08/28 15:04:16 step 7: mse=179.048391 step=0.100000
2017/08/28 15:04:16 Saving...
2017/08/28 15:04:16 Gathering batch of experience...
2017/08/28 15:05:03 batch 304: mean=57.972222 stddev=52.736760 entropy=0.498249 frames=4546 count=72
2017/08/28 15:05:03 Training policy...
2017/08/28 15:05:06 step 0: objective=-0.06926449
2017/08/28 15:05:07 step 1: objective=-0.0573268
2017/08/28 15:05:08 step 2: objective=-0.048633464
2017/08/28 15:05:09 step 3: objective=-0.04061659
2017/08/28 15:05:10 step 4: objective=-0.034082096
2017/08/28 15:05:11 step 5: objective=-0.026194546
2017/08/28 15:05:12 step 6: objective=-0.022080986
2017/08/28 15:05:13 step 7: objective=-0.01799531
2017/08/28 15:05:13 Training value function...
2017/08/28 15:05:15 step 0: mse=140.863878 step=0.100000
2017/08/28 15:05:16 step 1: mse=139.634241 step=0.100000
2017/08/28 15:05:17 step 2: mse=138.493548 step=0.100000
2017/08/28 15:05:18 step 3: mse=137.344840 step=0.100000
2017/08/28 15:05:19 step 4: mse=136.333273 step=0.100000
2017/08/28 15:05:20 step 5: mse=135.491696 step=0.100000
2017/08/28 15:05:21 step 6: mse=134.880754 step=0.100000
2017/08/28 15:05:22 step 7: mse=134.081822 step=0.100000
2017/08/28 15:05:22 Saving...
2017/08/28 15:05:22 Gathering batch of experience...
2017/08/28 15:06:10 batch 305: mean=65.105263 stddev=58.243721 entropy=0.501400 frames=4788 count=76
2017/08/28 15:06:10 Training policy...
2017/08/28 15:06:13 step 0: objective=1.760834
2017/08/28 15:06:14 step 1: objective=1.7747033
2017/08/28 15:06:15 step 2: objective=1.7853914
2017/08/28 15:06:17 step 3: objective=1.7938277
2017/08/28 15:06:18 step 4: objective=1.801336
2017/08/28 15:06:19 step 5: objective=1.8091977
2017/08/28 15:06:20 step 6: objective=1.8172653
2017/08/28 15:06:21 step 7: objective=1.8210547
2017/08/28 15:06:21 Training value function...
2017/08/28 15:06:23 step 0: mse=179.831335 step=0.100000
2017/08/28 15:06:24 step 1: mse=176.192727 step=0.100000
2017/08/28 15:06:25 step 2: mse=173.211337 step=0.100000
2017/08/28 15:06:26 step 3: mse=170.290684 step=0.100000
2017/08/28 15:06:27 step 4: mse=168.294318 step=0.100000
2017/08/28 15:06:28 step 5: mse=166.161115 step=0.100000
2017/08/28 15:06:29 step 6: mse=164.358985 step=0.100000
2017/08/28 15:06:30 step 7: mse=162.562270 step=0.100000
2017/08/28 15:06:30 Saving...
2017/08/28 15:06:30 Gathering batch of experience...
2017/08/28 15:07:18 batch 306: mean=63.171053 stddev=59.509041 entropy=0.498403 frames=4695 count=76
2017/08/28 15:07:18 Training policy...
2017/08/28 15:07:21 step 0: objective=1.3345959
2017/08/28 15:07:22 step 1: objective=1.3472563
2017/08/28 15:07:23 step 2: objective=1.3602966
2017/08/28 15:07:24 step 3: objective=1.3719411
2017/08/28 15:07:25 step 4: objective=1.3814707
2017/08/28 15:07:27 step 5: objective=1.3915074
2017/08/28 15:07:28 step 6: objective=1.397329
2017/08/28 15:07:29 step 7: objective=1.4040604
2017/08/28 15:07:29 Training value function...
2017/08/28 15:07:31 step 0: mse=175.078649 step=0.100000
2017/08/28 15:07:32 step 1: mse=173.286169 step=0.100000
2017/08/28 15:07:33 step 2: mse=171.278115 step=0.100000
2017/08/28 15:07:34 step 3: mse=169.384001 step=0.100000
2017/08/28 15:07:35 step 4: mse=167.578101 step=0.100000
2017/08/28 15:07:36 step 5: mse=166.058276 step=0.100000
2017/08/28 15:07:36 step 6: mse=164.644806 step=0.100000
2017/08/28 15:07:37 step 7: mse=162.964953 step=0.100000
2017/08/28 15:07:37 Saving...
2017/08/28 15:07:38 Gathering batch of experience...
2017/08/28 15:08:27 batch 307: mean=53.402439 stddev=57.582996 entropy=0.495826 frames=4578 count=82
2017/08/28 15:08:27 Training policy...
2017/08/28 15:08:30 step 0: objective=-0.015891429
2017/08/28 15:08:31 step 1: objective=-0.0026427435
2017/08/28 15:08:32 step 2: objective=0.0114456965
2017/08/28 15:08:33 step 3: objective=0.022025865
2017/08/28 15:08:34 step 4: objective=0.02884303
2017/08/28 15:08:35 step 5: objective=0.03449193
2017/08/28 15:08:36 step 6: objective=0.04003588
2017/08/28 15:08:37 step 7: objective=0.051560428
2017/08/28 15:08:37 Training value function...
2017/08/28 15:08:39 step 0: mse=168.088687 step=0.100000
2017/08/28 15:08:40 step 1: mse=165.583141 step=0.100000
2017/08/28 15:08:41 step 2: mse=162.947975 step=0.100000
2017/08/28 15:08:42 step 3: mse=161.045415 step=0.100000
2017/08/28 15:08:43 step 4: mse=159.213923 step=0.100000
2017/08/28 15:08:44 step 5: mse=157.650676 step=0.100000
2017/08/28 15:08:45 step 6: mse=156.558320 step=0.100000
2017/08/28 15:08:46 step 7: mse=155.552961 step=0.100000
2017/08/28 15:08:46 Saving...
2017/08/28 15:08:46 Gathering batch of experience...
2017/08/28 15:09:35 batch 308: mean=58.623377 stddev=60.707953 entropy=0.495401 frames=4556 count=77
2017/08/28 15:09:35 Training policy...
2017/08/28 15:09:38 step 0: objective=0.89192426
2017/08/28 15:09:39 step 1: objective=0.90088856
2017/08/28 15:09:40 step 2: objective=0.9109993
2017/08/28 15:09:41 step 3: objective=0.92931485
2017/08/28 15:09:42 step 4: objective=0.9372313
2017/08/28 15:09:43 step 5: objective=0.9460488
2017/08/28 15:09:44 step 6: objective=0.952628
2017/08/28 15:09:45 step 7: objective=0.9587981
2017/08/28 15:09:45 Training value function...
2017/08/28 15:09:47 step 0: mse=189.886284 step=0.100000
2017/08/28 15:09:48 step 1: mse=186.411461 step=0.100000
2017/08/28 15:09:49 step 2: mse=183.412402 step=0.100000
2017/08/28 15:09:50 step 3: mse=181.106481 step=0.100000
2017/08/28 15:09:51 step 4: mse=179.034719 step=0.100000
2017/08/28 15:09:52 step 5: mse=177.220301 step=0.100000
2017/08/28 15:09:53 step 6: mse=175.548576 step=0.100000
2017/08/28 15:09:54 step 7: mse=174.042951 step=0.100000
2017/08/28 15:09:54 Saving...
2017/08/28 15:09:54 Gathering batch of experience...
2017/08/28 15:10:39 batch 309: mean=64.811594 stddev=58.772288 entropy=0.494898 frames=4618 count=69
2017/08/28 15:10:39 Training policy...
2017/08/28 15:10:42 step 0: objective=0.8998917
2017/08/28 15:10:43 step 1: objective=0.90900725
2017/08/28 15:10:44 step 2: objective=0.91569704
2017/08/28 15:10:45 step 3: objective=0.92666435
2017/08/28 15:10:46 step 4: objective=0.9348194
2017/08/28 15:10:47 step 5: objective=0.94047993
2017/08/28 15:10:48 step 6: objective=0.9463247
2017/08/28 15:10:49 step 7: objective=0.95446616
2017/08/28 15:10:49 Training value function...
2017/08/28 15:10:51 step 0: mse=159.858849 step=0.100000
2017/08/28 15:10:52 step 1: mse=158.744569 step=0.100000
2017/08/28 15:10:53 step 2: mse=157.007621 step=0.100000
2017/08/28 15:10:54 step 3: mse=155.829356 step=0.100000
2017/08/28 15:10:55 step 4: mse=154.326155 step=0.100000
2017/08/28 15:10:56 step 5: mse=153.002848 step=0.100000
2017/08/28 15:10:57 step 6: mse=152.210239 step=0.100000
2017/08/28 15:10:58 step 7: mse=150.952827 step=0.100000
2017/08/28 15:10:58 Saving...
2017/08/28 15:10:58 Gathering batch of experience...
2017/08/28 15:11:44 batch 310: mean=72.468750 stddev=65.615587 entropy=0.491280 frames=4666 count=64
2017/08/28 15:11:44 Training policy...
2017/08/28 15:11:47 step 0: objective=1.5802416
2017/08/28 15:11:48 step 1: objective=1.588132
2017/08/28 15:11:49 step 2: objective=1.6015961
2017/08/28 15:11:51 step 3: objective=1.6073772
2017/08/28 15:11:52 step 4: objective=1.6183444
2017/08/28 15:11:53 step 5: objective=1.6240492
2017/08/28 15:11:54 step 6: objective=1.6285232
2017/08/28 15:11:55 step 7: objective=1.636816
2017/08/28 15:11:55 Training value function...
2017/08/28 15:11:57 step 0: mse=179.237105 step=0.100000
2017/08/28 15:11:58 step 1: mse=176.737647 step=0.100000
2017/08/28 15:11:59 step 2: mse=174.180339 step=0.100000
2017/08/28 15:12:00 step 3: mse=172.309058 step=0.100000
2017/08/28 15:12:01 step 4: mse=170.856145 step=0.100000
2017/08/28 15:12:02 step 5: mse=168.519286 step=0.100000
2017/08/28 15:12:03 step 6: mse=166.896855 step=0.100000
2017/08/28 15:12:03 step 7: mse=165.199710 step=0.100000
2017/08/28 15:12:03 Saving...
2017/08/28 15:12:04 Gathering batch of experience...
2017/08/28 15:12:50 batch 311: mean=61.549296 stddev=56.131081 entropy=0.497528 frames=4403 count=71
2017/08/28 15:12:50 Training policy...
2017/08/28 15:12:53 step 0: objective=0.65069
2017/08/28 15:12:54 step 1: objective=0.67344207
2017/08/28 15:12:55 step 2: objective=0.6873643
2017/08/28 15:12:56 step 3: objective=0.6960476
2017/08/28 15:12:57 step 4: objective=0.70390546
2017/08/28 15:12:58 step 5: objective=0.70995
2017/08/28 15:12:59 step 6: objective=0.717033
2017/08/28 15:13:00 step 7: objective=0.72499263
2017/08/28 15:13:00 Training value function...
2017/08/28 15:13:02 step 0: mse=163.346896 step=0.100000
2017/08/28 15:13:03 step 1: mse=162.051447 step=0.100000
2017/08/28 15:13:04 step 2: mse=160.968224 step=0.100000
2017/08/28 15:13:04 step 3: mse=159.522716 step=0.100000
2017/08/28 15:13:05 step 4: mse=158.395081 step=0.100000
2017/08/28 15:13:06 step 5: mse=157.890883 step=0.100000
2017/08/28 15:13:07 step 6: mse=157.190463 step=0.100000
2017/08/28 15:13:08 step 7: mse=156.186553 step=0.100000
2017/08/28 15:13:08 Saving...
2017/08/28 15:13:08 Gathering batch of experience...
2017/08/28 15:13:56 batch 312: mean=73.181818 stddev=55.525836 entropy=0.503466 frames=4710 count=66
2017/08/28 15:13:56 Training policy...
2017/08/28 15:13:59 step 0: objective=1.5021439
2017/08/28 15:14:00 step 1: objective=1.5097541
2017/08/28 15:14:01 step 2: objective=1.5185302
2017/08/28 15:14:02 step 3: objective=1.5246646
2017/08/28 15:14:03 step 4: objective=1.5377936
2017/08/28 15:14:04 step 5: objective=1.5487145
2017/08/28 15:14:05 step 6: objective=1.5581764
2017/08/28 15:14:06 step 7: objective=1.5657678
2017/08/28 15:14:06 Training value function...
2017/08/28 15:14:08 step 0: mse=174.052212 step=0.100000
2017/08/28 15:14:09 step 1: mse=171.304714 step=0.100000
2017/08/28 15:14:10 step 2: mse=168.292430 step=0.100000
2017/08/28 15:14:11 step 3: mse=166.048122 step=0.100000
2017/08/28 15:14:12 step 4: mse=163.794855 step=0.100000
2017/08/28 15:14:13 step 5: mse=162.254292 step=0.100000
2017/08/28 15:14:14 step 6: mse=159.931904 step=0.100000
2017/08/28 15:14:15 step 7: mse=158.378232 step=0.100000
2017/08/28 15:14:15 Saving...
2017/08/28 15:14:15 Gathering batch of experience...
2017/08/28 15:15:05 batch 313: mean=72.157143 stddev=85.906367 entropy=0.500033 frames=4840 count=70
2017/08/28 15:15:05 Training policy...
2017/08/28 15:15:08 step 0: objective=1.6339699
2017/08/28 15:15:10 step 1: objective=1.6453711
2017/08/28 15:15:11 step 2: objective=1.6554672
2017/08/28 15:15:12 step 3: objective=1.6693565
2017/08/28 15:15:13 step 4: objective=1.6784632
2017/08/28 15:15:14 step 5: objective=1.6872693
2017/08/28 15:15:15 step 6: objective=1.6954025
2017/08/28 15:15:16 step 7: objective=1.6999084
2017/08/28 15:15:16 Training value function...
2017/08/28 15:15:18 step 0: mse=227.391527 step=0.100000
2017/08/28 15:15:19 step 1: mse=220.428469 step=0.100000
2017/08/28 15:15:20 step 2: mse=214.578976 step=0.100000
2017/08/28 15:15:21 step 3: mse=209.289407 step=0.100000
2017/08/28 15:15:22 step 4: mse=205.360788 step=0.100000
2017/08/28 15:15:23 step 5: mse=201.459435 step=0.100000
2017/08/28 15:15:24 step 6: mse=198.303134 step=0.100000
2017/08/28 15:15:25 step 7: mse=195.762129 step=0.100000
2017/08/28 15:15:25 Saving...
2017/08/28 15:15:25 Gathering batch of experience...
2017/08/28 15:16:11 batch 314: mean=66.746269 stddev=50.039490 entropy=0.499999 frames=4695 count=67
2017/08/28 15:16:11 Training policy...
2017/08/28 15:16:15 step 0: objective=0.2051994
2017/08/28 15:16:16 step 1: objective=0.2135784
2017/08/28 15:16:17 step 2: objective=0.22341087
2017/08/28 15:16:18 step 3: objective=0.23698829
2017/08/28 15:16:19 step 4: objective=0.24346992
2017/08/28 15:16:20 step 5: objective=0.24974465
2017/08/28 15:16:21 step 6: objective=0.2572201
2017/08/28 15:16:22 step 7: objective=0.2636768
2017/08/28 15:16:22 Training value function...
2017/08/28 15:16:24 step 0: mse=144.889525 step=0.100000
2017/08/28 15:16:25 step 1: mse=143.382393 step=0.100000
2017/08/28 15:16:26 step 2: mse=141.929362 step=0.100000
2017/08/28 15:16:27 step 3: mse=140.698426 step=0.100000
2017/08/28 15:16:28 step 4: mse=139.427475 step=0.100000
2017/08/28 15:16:29 step 5: mse=138.344175 step=0.100000
2017/08/28 15:16:30 step 6: mse=137.524174 step=0.100000
2017/08/28 15:16:31 step 7: mse=137.016181 step=0.100000
2017/08/28 15:16:31 Saving...
2017/08/28 15:16:31 Gathering batch of experience...
2017/08/28 15:17:18 batch 315: mean=59.402597 stddev=52.411028 entropy=0.488720 frames=4548 count=77
2017/08/28 15:17:18 Training policy...
2017/08/28 15:17:21 step 0: objective=0.8335442
2017/08/28 15:17:23 step 1: objective=0.8408837
2017/08/28 15:17:24 step 2: objective=0.855328
2017/08/28 15:17:25 step 3: objective=0.867022
2017/08/28 15:17:26 step 4: objective=0.8773829
2017/08/28 15:17:27 step 5: objective=0.885188
2017/08/28 15:17:28 step 6: objective=0.8893682
2017/08/28 15:17:29 step 7: objective=0.894288
2017/08/28 15:17:29 Training value function...
2017/08/28 15:17:31 step 0: mse=160.564351 step=0.100000
2017/08/28 15:17:32 step 1: mse=158.710773 step=0.100000
2017/08/28 15:17:33 step 2: mse=156.714407 step=0.100000
2017/08/28 15:17:34 step 3: mse=155.577243 step=0.100000
2017/08/28 15:17:34 step 4: mse=154.398114 step=0.100000
2017/08/28 15:17:35 step 5: mse=153.452054 step=0.100000
2017/08/28 15:17:36 step 6: mse=151.966250 step=0.100000
2017/08/28 15:17:37 step 7: mse=150.451087 step=0.100000
2017/08/28 15:17:37 Saving...
2017/08/28 15:17:37 Gathering batch of experience...
2017/08/28 15:18:27 batch 316: mean=64.065789 stddev=60.359087 entropy=0.489823 frames=4712 count=76
2017/08/28 15:18:27 Training policy...
2017/08/28 15:18:30 step 0: objective=1.2680991
2017/08/28 15:18:31 step 1: objective=1.2760799
2017/08/28 15:18:32 step 2: objective=1.2843355
2017/08/28 15:18:33 step 3: objective=1.2922342
2017/08/28 15:18:34 step 4: objective=1.2997795
2017/08/28 15:18:36 step 5: objective=1.3073233
2017/08/28 15:18:37 step 6: objective=1.3158501
2017/08/28 15:18:38 step 7: objective=1.3215095
2017/08/28 15:18:38 Training value function...
2017/08/28 15:18:40 step 0: mse=210.811067 step=0.100000
2017/08/28 15:18:41 step 1: mse=208.447291 step=0.100000
2017/08/28 15:18:42 step 2: mse=205.973905 step=0.100000
2017/08/28 15:18:43 step 3: mse=203.934765 step=0.100000
2017/08/28 15:18:43 step 4: mse=201.970269 step=0.100000
2017/08/28 15:18:44 step 5: mse=200.373609 step=0.100000
2017/08/28 15:18:45 step 6: mse=198.416638 step=0.100000
2017/08/28 15:18:46 step 7: mse=197.031652 step=0.100000
2017/08/28 15:18:46 Saving...
2017/08/28 15:18:46 Gathering batch of experience...
2017/08/28 15:19:40 batch 317: mean=58.939024 stddev=56.690935 entropy=0.486909 frames=4827 count=82
2017/08/28 15:19:40 Training policy...
2017/08/28 15:19:43 step 0: objective=0.51247954
2017/08/28 15:19:44 step 1: objective=0.5237632
2017/08/28 15:19:45 step 2: objective=0.5319118
2017/08/28 15:19:46 step 3: objective=0.54076666
2017/08/28 15:19:47 step 4: objective=0.54841715
2017/08/28 15:19:48 step 5: objective=0.5573383
2017/08/28 15:19:50 step 6: objective=0.5618159
2017/08/28 15:19:51 step 7: objective=0.56847423
2017/08/28 15:19:51 Training value function...
2017/08/28 15:19:53 step 0: mse=163.186724 step=0.100000
2017/08/28 15:19:54 step 1: mse=161.938530 step=0.100000
2017/08/28 15:19:55 step 2: mse=161.123813 step=0.100000
2017/08/28 15:19:56 step 3: mse=160.168657 step=0.100000
2017/08/28 15:19:57 step 4: mse=159.515580 step=0.100000
2017/08/28 15:19:58 step 5: mse=158.875790 step=0.100000
2017/08/28 15:19:59 step 6: mse=158.216252 step=0.100000
2017/08/28 15:20:00 step 7: mse=157.679756 step=0.100000
2017/08/28 15:20:00 Saving...
2017/08/28 15:20:00 Gathering batch of experience...
2017/08/28 15:20:48 batch 318: mean=59.831169 stddev=57.235990 entropy=0.490269 frames=4563 count=77
2017/08/28 15:20:48 Training policy...
2017/08/28 15:20:51 step 0: objective=0.9339366
2017/08/28 15:20:52 step 1: objective=0.9453846
2017/08/28 15:20:53 step 2: objective=0.9610016
2017/08/28 15:20:54 step 3: objective=0.96878636
2017/08/28 15:20:56 step 4: objective=0.976004
2017/08/28 15:20:57 step 5: objective=0.9856836
2017/08/28 15:20:58 step 6: objective=0.9922565
2017/08/28 15:20:59 step 7: objective=0.9981077
2017/08/28 15:20:59 Training value function...
2017/08/28 15:21:01 step 0: mse=198.967291 step=0.100000
2017/08/28 15:21:01 step 1: mse=197.442961 step=0.100000
2017/08/28 15:21:02 step 2: mse=195.898732 step=0.100000
2017/08/28 15:21:03 step 3: mse=194.223454 step=0.100000
2017/08/28 15:21:04 step 4: mse=192.980806 step=0.100000
2017/08/28 15:21:05 step 5: mse=190.688237 step=0.100000
2017/08/28 15:21:06 step 6: mse=189.433449 step=0.100000
2017/08/28 15:21:07 step 7: mse=187.996623 step=0.100000
2017/08/28 15:21:07 Saving...
2017/08/28 15:21:07 Gathering batch of experience...
2017/08/28 15:21:55 batch 319: mean=75.074627 stddev=77.340942 entropy=0.492855 frames=4840 count=67
2017/08/28 15:21:55 Training policy...
2017/08/28 15:21:58 step 0: objective=2.0417023
2017/08/28 15:21:59 step 1: objective=2.0590937
2017/08/28 15:22:01 step 2: objective=2.0695505
2017/08/28 15:22:02 step 3: objective=2.0814056
2017/08/28 15:22:03 step 4: objective=2.0893195
2017/08/28 15:22:04 step 5: objective=2.0958893
2017/08/28 15:22:05 step 6: objective=2.1026027
2017/08/28 15:22:06 step 7: objective=2.1067176
2017/08/28 15:22:06 Training value function...
2017/08/28 15:22:08 step 0: mse=215.632728 step=0.100000
2017/08/28 15:22:09 step 1: mse=209.407785 step=0.100000
2017/08/28 15:22:10 step 2: mse=204.150619 step=0.100000
2017/08/28 15:22:11 step 3: mse=199.817637 step=0.100000
2017/08/28 15:22:12 step 4: mse=196.350242 step=0.100000
2017/08/28 15:22:13 step 5: mse=193.269353 step=0.100000
2017/08/28 15:22:14 step 6: mse=190.608890 step=0.100000
2017/08/28 15:22:15 step 7: mse=188.358111 step=0.100000
2017/08/28 15:22:15 Saving...
2017/08/28 15:22:15 Gathering batch of experience...
2017/08/28 15:23:04 batch 320: mean=57.769231 stddev=51.844917 entropy=0.491093 frames=4733 count=78
2017/08/28 15:23:04 Training policy...
2017/08/28 15:23:08 step 0: objective=-0.06709613
2017/08/28 15:23:09 step 1: objective=-0.05169248
2017/08/28 15:23:10 step 2: objective=-0.041690428
2017/08/28 15:23:11 step 3: objective=-0.034415983
2017/08/28 15:23:12 step 4: objective=-0.021452017
2017/08/28 15:23:13 step 5: objective=-0.009388452
2017/08/28 15:23:14 step 6: objective=-0.0014939726
2017/08/28 15:23:15 step 7: objective=0.005767253
2017/08/28 15:23:15 Training value function...
2017/08/28 15:23:17 step 0: mse=159.719538 step=0.100000
2017/08/28 15:23:18 step 1: mse=158.095068 step=0.100000
2017/08/28 15:23:19 step 2: mse=156.459827 step=0.100000
2017/08/28 15:23:20 step 3: mse=155.180352 step=0.100000
2017/08/28 15:23:21 step 4: mse=154.051178 step=0.100000
2017/08/28 15:23:22 step 5: mse=153.147573 step=0.100000
2017/08/28 15:23:23 step 6: mse=152.418794 step=0.100000
2017/08/28 15:23:24 step 7: mse=151.688984 step=0.100000
2017/08/28 15:23:24 Saving...
2017/08/28 15:23:24 Gathering batch of experience...
2017/08/28 15:24:10 batch 321: mean=67.794118 stddev=67.601679 entropy=0.486353 frames=4442 count=68
2017/08/28 15:24:10 Training policy...
2017/08/28 15:24:13 step 0: objective=1.8417264
2017/08/28 15:24:14 step 1: objective=1.8519276
2017/08/28 15:24:15 step 2: objective=1.8654078
2017/08/28 15:24:16 step 3: objective=1.8769263
2017/08/28 15:24:17 step 4: objective=1.8832802
2017/08/28 15:24:18 step 5: objective=1.8881003
2017/08/28 15:24:19 step 6: objective=1.8961179
2017/08/28 15:24:20 step 7: objective=1.9050448
2017/08/28 15:24:20 Training value function...
2017/08/28 15:24:22 step 0: mse=208.057430 step=0.100000
2017/08/28 15:24:22 step 1: mse=203.831839 step=0.100000
2017/08/28 15:24:23 step 2: mse=200.149897 step=0.100000
2017/08/28 15:24:24 step 3: mse=196.872248 step=0.100000
2017/08/28 15:24:25 step 4: mse=194.104089 step=0.100000
2017/08/28 15:24:26 step 5: mse=191.390156 step=0.100000
2017/08/28 15:24:27 step 6: mse=188.626811 step=0.100000
2017/08/28 15:24:28 step 7: mse=186.098098 step=0.100000
2017/08/28 15:24:28 Saving...
2017/08/28 15:24:28 Gathering batch of experience...
2017/08/28 15:25:17 batch 322: mean=70.820896 stddev=63.313700 entropy=0.486126 frames=5051 count=67
2017/08/28 15:25:17 Training policy...
2017/08/28 15:25:20 step 0: objective=0.62457263
2017/08/28 15:25:22 step 1: objective=0.6320168
2017/08/28 15:25:23 step 2: objective=0.6390896
2017/08/28 15:25:24 step 3: objective=0.64888054
2017/08/28 15:25:25 step 4: objective=0.65782744
2017/08/28 15:25:26 step 5: objective=0.6637947
2017/08/28 15:25:27 step 6: objective=0.6707486
2017/08/28 15:25:29 step 7: objective=0.6764874
2017/08/28 15:25:29 Training value function...
2017/08/28 15:25:31 step 0: mse=137.957966 step=0.100000
2017/08/28 15:25:32 step 1: mse=136.741571 step=0.100000
2017/08/28 15:25:33 step 2: mse=135.369129 step=0.100000
2017/08/28 15:25:34 step 3: mse=134.046107 step=0.100000
2017/08/28 15:25:35 step 4: mse=133.037781 step=0.100000
2017/08/28 15:25:36 step 5: mse=131.961093 step=0.100000
2017/08/28 15:25:37 step 6: mse=131.386911 step=0.100000
2017/08/28 15:25:38 step 7: mse=130.600114 step=0.100000
2017/08/28 15:25:38 Saving...
2017/08/28 15:25:38 Gathering batch of experience...
2017/08/28 15:26:27 batch 323: mean=59.592105 stddev=61.016430 entropy=0.481699 frames=4541 count=76
2017/08/28 15:26:27 Training policy...
2017/08/28 15:26:30 step 0: objective=0.81143713
2017/08/28 15:26:32 step 1: objective=0.82810885
2017/08/28 15:26:33 step 2: objective=0.8370767
2017/08/28 15:26:34 step 3: objective=0.8477792
2017/08/28 15:26:35 step 4: objective=0.8571855
2017/08/28 15:26:36 step 5: objective=0.8652233
2017/08/28 15:26:37 step 6: objective=0.8714762
2017/08/28 15:26:38 step 7: objective=0.8795921
2017/08/28 15:26:38 Training value function...
2017/08/28 15:26:40 step 0: mse=189.775724 step=0.100000
2017/08/28 15:26:41 step 1: mse=184.315472 step=0.100000
2017/08/28 15:26:42 step 2: mse=180.058498 step=0.100000
2017/08/28 15:26:43 step 3: mse=176.484669 step=0.100000
2017/08/28 15:26:43 step 4: mse=173.609552 step=0.100000
2017/08/28 15:26:44 step 5: mse=171.062711 step=0.100000
2017/08/28 15:26:45 step 6: mse=168.931281 step=0.100000
2017/08/28 15:26:46 step 7: mse=166.973348 step=0.100000
2017/08/28 15:26:46 Saving...
2017/08/28 15:26:46 Gathering batch of experience...
2017/08/28 15:27:35 batch 324: mean=61.581081 stddev=51.346467 entropy=0.488898 frames=4766 count=74
2017/08/28 15:27:35 Training policy...
2017/08/28 15:27:38 step 0: objective=0.76588756
2017/08/28 15:27:39 step 1: objective=0.7743053
2017/08/28 15:27:40 step 2: objective=0.78775096
2017/08/28 15:27:41 step 3: objective=0.79700863
2017/08/28 15:27:43 step 4: objective=0.8070911
2017/08/28 15:27:44 step 5: objective=0.8129967
2017/08/28 15:27:45 step 6: objective=0.81686044
2017/08/28 15:27:46 step 7: objective=0.82295066
2017/08/28 15:27:46 Training value function...
2017/08/28 15:27:48 step 0: mse=138.206602 step=0.100000
2017/08/28 15:27:49 step 1: mse=136.337760 step=0.100000
2017/08/28 15:27:50 step 2: mse=134.853756 step=0.100000
2017/08/28 15:27:51 step 3: mse=133.459857 step=0.100000
2017/08/28 15:27:52 step 4: mse=131.879073 step=0.100000
2017/08/28 15:27:53 step 5: mse=131.010016 step=0.100000
2017/08/28 15:27:54 step 6: mse=130.302660 step=0.100000
2017/08/28 15:27:55 step 7: mse=129.210632 step=0.100000
2017/08/28 15:27:55 Saving...
2017/08/28 15:27:55 Gathering batch of experience...
2017/08/28 15:28:46 batch 325: mean=60.650000 stddev=57.266941 entropy=0.481422 frames=4813 count=80
2017/08/28 15:28:46 Training policy...
2017/08/28 15:28:49 step 0: objective=0.994257
2017/08/28 15:28:50 step 1: objective=1.0092895
2017/08/28 15:28:52 step 2: objective=1.0187901
2017/08/28 15:28:53 step 3: objective=1.0276883
2017/08/28 15:28:54 step 4: objective=1.0383925
2017/08/28 15:28:55 step 5: objective=1.0462604
2017/08/28 15:28:56 step 6: objective=1.0543858
2017/08/28 15:28:57 step 7: objective=1.0634351
2017/08/28 15:28:57 Training value function...
2017/08/28 15:28:59 step 0: mse=183.272097 step=0.100000
2017/08/28 15:29:00 step 1: mse=180.191272 step=0.100000
2017/08/28 15:29:01 step 2: mse=177.568470 step=0.100000
2017/08/28 15:29:02 step 3: mse=175.351641 step=0.100000
2017/08/28 15:29:03 step 4: mse=173.569930 step=0.100000
2017/08/28 15:29:04 step 5: mse=171.721258 step=0.100000
2017/08/28 15:29:05 step 6: mse=169.784015 step=0.100000
2017/08/28 15:29:06 step 7: mse=168.048984 step=0.100000
2017/08/28 15:29:06 Saving...
2017/08/28 15:29:06 Gathering batch of experience...
2017/08/28 15:29:56 batch 326: mean=59.437500 stddev=57.125486 entropy=0.485077 frames=4650 count=80
2017/08/28 15:29:56 Training policy...
2017/08/28 15:29:59 step 0: objective=0.89727664
2017/08/28 15:30:00 step 1: objective=0.9078119
2017/08/28 15:30:01 step 2: objective=0.9187916
2017/08/28 15:30:02 step 3: objective=0.9250909
2017/08/28 15:30:03 step 4: objective=0.93536615
2017/08/28 15:30:05 step 5: objective=0.9450998
2017/08/28 15:30:06 step 6: objective=0.9564241
2017/08/28 15:30:07 step 7: objective=0.9639072
2017/08/28 15:30:07 Training value function...
2017/08/28 15:30:09 step 0: mse=176.322258 step=0.100000
2017/08/28 15:30:10 step 1: mse=174.824994 step=0.100000
2017/08/28 15:30:10 step 2: mse=173.433953 step=0.100000
2017/08/28 15:30:11 step 3: mse=172.345055 step=0.100000
2017/08/28 15:30:12 step 4: mse=171.483634 step=0.100000
2017/08/28 15:30:13 step 5: mse=170.748117 step=0.100000
2017/08/28 15:30:14 step 6: mse=169.580351 step=0.100000
2017/08/28 15:30:15 step 7: mse=168.685436 step=0.100000
2017/08/28 15:30:15 Saving...
2017/08/28 15:30:15 Gathering batch of experience...
2017/08/28 15:31:02 batch 327: mean=64.305556 stddev=56.526699 entropy=0.489483 frames=4661 count=72
2017/08/28 15:31:02 Training policy...
2017/08/28 15:31:05 step 0: objective=1.2461053
2017/08/28 15:31:07 step 1: objective=1.2566727
2017/08/28 15:31:08 step 2: objective=1.2729504
2017/08/28 15:31:09 step 3: objective=1.2884153
2017/08/28 15:31:10 step 4: objective=1.3027555
2017/08/28 15:31:11 step 5: objective=1.3106122
2017/08/28 15:31:12 step 6: objective=1.317811
2017/08/28 15:31:13 step 7: objective=1.3226867
2017/08/28 15:31:13 Training value function...
2017/08/28 15:31:15 step 0: mse=176.428972 step=0.100000
2017/08/28 15:31:16 step 1: mse=174.517455 step=0.100000
2017/08/28 15:31:17 step 2: mse=172.364434 step=0.100000
2017/08/28 15:31:18 step 3: mse=170.757759 step=0.100000
2017/08/28 15:31:19 step 4: mse=169.178832 step=0.100000
2017/08/28 15:31:20 step 5: mse=168.122574 step=0.100000
2017/08/28 15:31:21 step 6: mse=166.512943 step=0.100000
2017/08/28 15:31:22 step 7: mse=164.991564 step=0.100000
2017/08/28 15:31:22 Saving...
2017/08/28 15:31:22 Gathering batch of experience...
2017/08/28 15:32:13 batch 328: mean=58.567901 stddev=45.566378 entropy=0.480625 frames=4699 count=81
2017/08/28 15:32:13 Training policy...
2017/08/28 15:32:16 step 0: objective=0.57018554
2017/08/28 15:32:17 step 1: objective=0.5811385
2017/08/28 15:32:18 step 2: objective=0.5903571
2017/08/28 15:32:19 step 3: objective=0.59767175
2017/08/28 15:32:20 step 4: objective=0.61085826
2017/08/28 15:32:21 step 5: objective=0.61524266
2017/08/28 15:32:22 step 6: objective=0.6200331
2017/08/28 15:32:23 step 7: objective=0.6248541
2017/08/28 15:32:23 Training value function...
2017/08/28 15:32:25 step 0: mse=149.714943 step=0.100000
2017/08/28 15:32:26 step 1: mse=148.143427 step=0.100000
2017/08/28 15:32:27 step 2: mse=146.782730 step=0.100000
2017/08/28 15:32:28 step 3: mse=145.391228 step=0.100000
2017/08/28 15:32:29 step 4: mse=144.270263 step=0.100000
2017/08/28 15:32:30 step 5: mse=143.243530 step=0.100000
2017/08/28 15:32:31 step 6: mse=142.118662 step=0.100000
2017/08/28 15:32:32 step 7: mse=140.997116 step=0.100000
2017/08/28 15:32:32 Saving...
2017/08/28 15:32:32 Gathering batch of experience...
2017/08/28 15:33:23 batch 329: mean=52.831325 stddev=49.025889 entropy=0.479361 frames=4649 count=83
2017/08/28 15:33:23 Training policy...
2017/08/28 15:33:26 step 0: objective=-0.16036738
2017/08/28 15:33:27 step 1: objective=-0.1476315
2017/08/28 15:33:28 step 2: objective=-0.13826865
2017/08/28 15:33:29 step 3: objective=-0.12801518
2017/08/28 15:33:30 step 4: objective=-0.122064434
2017/08/28 15:33:32 step 5: objective=-0.116072774
2017/08/28 15:33:33 step 6: objective=-0.11071168
2017/08/28 15:33:34 step 7: objective=-0.10608468
2017/08/28 15:33:34 Training value function...
2017/08/28 15:33:36 step 0: mse=143.632808 step=0.100000
2017/08/28 15:33:37 step 1: mse=141.626869 step=0.100000
2017/08/28 15:33:38 step 2: mse=139.959276 step=0.100000
2017/08/28 15:33:38 step 3: mse=138.464354 step=0.100000
2017/08/28 15:33:39 step 4: mse=137.156337 step=0.100000
2017/08/28 15:33:40 step 5: mse=136.043844 step=0.100000
2017/08/28 15:33:41 step 6: mse=134.969658 step=0.100000
2017/08/28 15:33:42 step 7: mse=133.959718 step=0.100000
2017/08/28 15:33:42 Saving...
2017/08/28 15:33:42 Gathering batch of experience...
2017/08/28 15:34:31 batch 330: mean=58.769231 stddev=53.370722 entropy=0.475492 frames=4550 count=78
2017/08/28 15:34:31 Training policy...
2017/08/28 15:34:34 step 0: objective=1.467048
2017/08/28 15:34:35 step 1: objective=1.4819753
2017/08/28 15:34:36 step 2: objective=1.4902478
2017/08/28 15:34:37 step 3: objective=1.5041301
2017/08/28 15:34:38 step 4: objective=1.5108948
2017/08/28 15:34:40 step 5: objective=1.5187047
2017/08/28 15:34:41 step 6: objective=1.5276515
2017/08/28 15:34:42 step 7: objective=1.5333327
2017/08/28 15:34:42 Training value function...
2017/08/28 15:34:44 step 0: mse=165.168882 step=0.100000
2017/08/28 15:34:45 step 1: mse=163.644074 step=0.100000
2017/08/28 15:34:45 step 2: mse=162.119370 step=0.100000
2017/08/28 15:34:46 step 3: mse=160.691449 step=0.100000
2017/08/28 15:34:47 step 4: mse=159.386561 step=0.100000
2017/08/28 15:34:48 step 5: mse=157.885203 step=0.100000
2017/08/28 15:34:49 step 6: mse=156.618995 step=0.100000
2017/08/28 15:34:50 step 7: mse=154.995915 step=0.100000
2017/08/28 15:34:50 Saving...
2017/08/28 15:34:50 Gathering batch of experience...
2017/08/28 15:35:40 batch 331: mean=67.013699 stddev=58.424637 entropy=0.481717 frames=4782 count=73
2017/08/28 15:35:40 Training policy...
2017/08/28 15:35:43 step 0: objective=1.6829233
2017/08/28 15:35:45 step 1: objective=1.6990763
2017/08/28 15:35:46 step 2: objective=1.7092277
2017/08/28 15:35:47 step 3: objective=1.720092
2017/08/28 15:35:48 step 4: objective=1.7253047
2017/08/28 15:35:49 step 5: objective=1.7305065
2017/08/28 15:35:50 step 6: objective=1.7384489
2017/08/28 15:35:51 step 7: objective=1.7434155
2017/08/28 15:35:51 Training value function...
2017/08/28 15:35:53 step 0: mse=179.202107 step=0.100000
2017/08/28 15:35:54 step 1: mse=176.338650 step=0.100000
2017/08/28 15:35:55 step 2: mse=173.791501 step=0.100000
2017/08/28 15:35:56 step 3: mse=171.678966 step=0.100000
2017/08/28 15:35:57 step 4: mse=169.188571 step=0.100000
2017/08/28 15:35:58 step 5: mse=167.312547 step=0.100000
2017/08/28 15:35:59 step 6: mse=165.449769 step=0.100000
2017/08/28 15:36:00 step 7: mse=163.590576 step=0.100000
2017/08/28 15:36:00 Saving...
2017/08/28 15:36:00 Gathering batch of experience...
2017/08/28 15:36:48 batch 332: mean=64.369863 stddev=68.439055 entropy=0.482307 frames=4681 count=73
2017/08/28 15:36:48 Training policy...
2017/08/28 15:36:51 step 0: objective=1.1107737
2017/08/28 15:36:52 step 1: objective=1.129008
2017/08/28 15:36:53 step 2: objective=1.1376972
2017/08/28 15:36:54 step 3: objective=1.1461605
2017/08/28 15:36:55 step 4: objective=1.1536958
2017/08/28 15:36:56 step 5: objective=1.1600928
2017/08/28 15:36:57 step 6: objective=1.16673
2017/08/28 15:36:58 step 7: objective=1.172905
2017/08/28 15:36:58 Training value function...
2017/08/28 15:37:00 step 0: mse=220.968580 step=0.100000
2017/08/28 15:37:01 step 1: mse=215.444134 step=0.100000
2017/08/28 15:37:02 step 2: mse=210.702759 step=0.100000
2017/08/28 15:37:03 step 3: mse=206.353068 step=0.100000
2017/08/28 15:37:04 step 4: mse=202.935850 step=0.100000
2017/08/28 15:37:05 step 5: mse=200.200190 step=0.100000
2017/08/28 15:37:06 step 6: mse=197.700342 step=0.100000
2017/08/28 15:37:07 step 7: mse=195.048873 step=0.100000
2017/08/28 15:37:07 Saving...
2017/08/28 15:37:07 Gathering batch of experience...
2017/08/28 15:37:54 batch 333: mean=74.656716 stddev=67.000012 entropy=0.477525 frames=4912 count=67
2017/08/28 15:37:54 Training policy...
2017/08/28 15:37:58 step 0: objective=1.5136112
2017/08/28 15:37:59 step 1: objective=1.5319284
2017/08/28 15:38:00 step 2: objective=1.5415953
2017/08/28 15:38:01 step 3: objective=1.5461739
2017/08/28 15:38:02 step 4: objective=1.5544661
2017/08/28 15:38:03 step 5: objective=1.5594338
2017/08/28 15:38:05 step 6: objective=1.5648943
2017/08/28 15:38:06 step 7: objective=1.5691094
2017/08/28 15:38:06 Training value function...
2017/08/28 15:38:08 step 0: mse=190.379654 step=0.100000
2017/08/28 15:38:09 step 1: mse=187.324294 step=0.100000
2017/08/28 15:38:10 step 2: mse=183.759146 step=0.100000
2017/08/28 15:38:11 step 3: mse=180.837492 step=0.100000
2017/08/28 15:38:12 step 4: mse=178.945743 step=0.100000
2017/08/28 15:38:13 step 5: mse=176.854841 step=0.100000
2017/08/28 15:38:14 step 6: mse=174.727823 step=0.100000
2017/08/28 15:38:15 step 7: mse=172.930461 step=0.100000
2017/08/28 15:38:15 Saving...
2017/08/28 15:38:15 Gathering batch of experience...
2017/08/28 15:39:02 batch 334: mean=67.333333 stddev=57.958079 entropy=0.476018 frames=4711 count=72
2017/08/28 15:39:02 Training policy...
2017/08/28 15:39:05 step 0: objective=0.840483
2017/08/28 15:39:06 step 1: objective=0.8484288
2017/08/28 15:39:07 step 2: objective=0.8551823
2017/08/28 15:39:08 step 3: objective=0.8613986
2017/08/28 15:39:10 step 4: objective=0.8693491
2017/08/28 15:39:11 step 5: objective=0.87765855
2017/08/28 15:39:12 step 6: objective=0.8852998
2017/08/28 15:39:13 step 7: objective=0.89107656
2017/08/28 15:39:13 Training value function...
2017/08/28 15:39:15 step 0: mse=164.138087 step=0.100000
2017/08/28 15:39:16 step 1: mse=162.253007 step=0.100000
2017/08/28 15:39:17 step 2: mse=160.993336 step=0.100000
2017/08/28 15:39:18 step 3: mse=159.716799 step=0.100000
2017/08/28 15:39:19 step 4: mse=158.815382 step=0.100000
2017/08/28 15:39:20 step 5: mse=157.877316 step=0.100000
2017/08/28 15:39:21 step 6: mse=157.264621 step=0.100000
2017/08/28 15:39:22 step 7: mse=156.034468 step=0.100000
2017/08/28 15:39:22 Saving...
2017/08/28 15:39:22 Gathering batch of experience...
2017/08/28 15:40:06 batch 335: mean=68.317460 stddev=61.139140 entropy=0.476698 frames=4461 count=63
2017/08/28 15:40:06 Training policy...
2017/08/28 15:40:09 step 0: objective=0.5058059
2017/08/28 15:40:10 step 1: objective=0.5161059
2017/08/28 15:40:11 step 2: objective=0.52404314
2017/08/28 15:40:12 step 3: objective=0.5332792
2017/08/28 15:40:13 step 4: objective=0.54179215
2017/08/28 15:40:14 step 5: objective=0.5480017
2017/08/28 15:40:15 step 6: objective=0.5532639
2017/08/28 15:40:16 step 7: objective=0.5622144
2017/08/28 15:40:16 Training value function...
2017/08/28 15:40:18 step 0: mse=160.945967 step=0.100000
2017/08/28 15:40:19 step 1: mse=159.619804 step=0.100000
2017/08/28 15:40:20 step 2: mse=157.896365 step=0.100000
2017/08/28 15:40:21 step 3: mse=156.795409 step=0.100000
2017/08/28 15:40:22 step 4: mse=155.410883 step=0.100000
2017/08/28 15:40:22 step 5: mse=154.088153 step=0.100000
2017/08/28 15:40:23 step 6: mse=153.317428 step=0.100000
2017/08/28 15:40:24 step 7: mse=152.411301 step=0.100000
2017/08/28 15:40:24 Saving...
2017/08/28 15:40:24 Gathering batch of experience...
2017/08/28 15:41:16 batch 336: mean=69.875000 stddev=73.160580 entropy=0.479931 frames=5140 count=72
2017/08/28 15:41:16 Training policy...
2017/08/28 15:41:19 step 0: objective=1.1045378
2017/08/28 15:41:20 step 1: objective=1.1157888
2017/08/28 15:41:21 step 2: objective=1.1271328
2017/08/28 15:41:23 step 3: objective=1.1327991
2017/08/28 15:41:24 step 4: objective=1.1403658
2017/08/28 15:41:25 step 5: objective=1.1511375
2017/08/28 15:41:26 step 6: objective=1.1554117
2017/08/28 15:41:27 step 7: objective=1.1620303
2017/08/28 15:41:27 Training value function...
2017/08/28 15:41:30 step 0: mse=202.518164 step=0.100000
2017/08/28 15:41:31 step 1: mse=199.495877 step=0.100000
2017/08/28 15:41:32 step 2: mse=195.263362 step=0.100000
2017/08/28 15:41:33 step 3: mse=193.296363 step=0.100000
2017/08/28 15:41:34 step 4: mse=191.084239 step=0.100000
2017/08/28 15:41:35 step 5: mse=188.942986 step=0.100000
2017/08/28 15:41:36 step 6: mse=187.415295 step=0.100000
2017/08/28 15:41:37 step 7: mse=186.126644 step=0.100000
2017/08/28 15:41:37 Saving...
2017/08/28 15:41:37 Gathering batch of experience...
2017/08/28 15:42:25 batch 337: mean=68.602941 stddev=64.201919 entropy=0.485005 frames=4862 count=68
2017/08/28 15:42:25 Training policy...
2017/08/28 15:42:29 step 0: objective=0.66556406
2017/08/28 15:42:30 step 1: objective=0.677355
2017/08/28 15:42:31 step 2: objective=0.6907285
2017/08/28 15:42:32 step 3: objective=0.70278615
2017/08/28 15:42:33 step 4: objective=0.70767385
2017/08/28 15:42:34 step 5: objective=0.7141878
2017/08/28 15:42:35 step 6: objective=0.7214852
2017/08/28 15:42:37 step 7: objective=0.7250306
2017/08/28 15:42:37 Training value function...
2017/08/28 15:42:39 step 0: mse=154.209694 step=0.100000
2017/08/28 15:42:40 step 1: mse=153.071367 step=0.100000
2017/08/28 15:42:41 step 2: mse=152.740483 step=0.100000
2017/08/28 15:42:42 step 3: mse=152.401282 step=0.100000
2017/08/28 15:42:43 step 4: mse=151.448405 step=0.100000
2017/08/28 15:42:44 step 5: mse=150.509482 step=0.100000
2017/08/28 15:42:45 step 6: mse=150.185907 step=0.100000
2017/08/28 15:42:46 step 7: mse=149.719867 step=0.100000
2017/08/28 15:42:46 Saving...
2017/08/28 15:42:46 Gathering batch of experience...
2017/08/28 15:43:39 batch 338: mean=68.932432 stddev=74.238172 entropy=0.489837 frames=5006 count=74
2017/08/28 15:43:39 Training policy...
2017/08/28 15:43:42 step 0: objective=1.4131163
2017/08/28 15:43:44 step 1: objective=1.4299426
2017/08/28 15:43:45 step 2: objective=1.4401102
2017/08/28 15:43:46 step 3: objective=1.4497302
2017/08/28 15:43:47 step 4: objective=1.4621586
2017/08/28 15:43:48 step 5: objective=1.4706309
2017/08/28 15:43:49 step 6: objective=1.4774599
2017/08/28 15:43:50 step 7: objective=1.4836134
2017/08/28 15:43:50 Training value function...
2017/08/28 15:43:53 step 0: mse=193.809315 step=0.100000
2017/08/28 15:43:54 step 1: mse=191.268171 step=0.100000
2017/08/28 15:43:55 step 2: mse=188.958079 step=0.100000
2017/08/28 15:43:56 step 3: mse=187.192625 step=0.100000
2017/08/28 15:43:57 step 4: mse=185.919664 step=0.100000
2017/08/28 15:43:58 step 5: mse=184.448774 step=0.100000
2017/08/28 15:43:59 step 6: mse=183.200275 step=0.100000
2017/08/28 15:44:00 step 7: mse=181.274950 step=0.100000
2017/08/28 15:44:00 Saving...
2017/08/28 15:44:00 Gathering batch of experience...
2017/08/28 15:44:47 batch 339: mean=72.590909 stddev=62.810436 entropy=0.484022 frames=4738 count=66
2017/08/28 15:44:47 Training policy...
2017/08/28 15:44:50 step 0: objective=1.1871072
2017/08/28 15:44:51 step 1: objective=1.1958231
2017/08/28 15:44:52 step 2: objective=1.2075044
2017/08/28 15:44:53 step 3: objective=1.2148249
2017/08/28 15:44:54 step 4: objective=1.2209203
2017/08/28 15:44:55 step 5: objective=1.2279431
2017/08/28 15:44:57 step 6: objective=1.2329246
2017/08/28 15:44:58 step 7: objective=1.2401067
2017/08/28 15:44:58 Training value function...
2017/08/28 15:45:00 step 0: mse=180.321879 step=0.100000
2017/08/28 15:45:01 step 1: mse=177.833915 step=0.100000
2017/08/28 15:45:02 step 2: mse=176.106831 step=0.100000
2017/08/28 15:45:03 step 3: mse=174.455406 step=0.100000
2017/08/28 15:45:04 step 4: mse=173.005309 step=0.100000
2017/08/28 15:45:05 step 5: mse=171.647666 step=0.100000
2017/08/28 15:45:06 step 6: mse=170.616504 step=0.100000
2017/08/28 15:45:07 step 7: mse=169.519584 step=0.100000
2017/08/28 15:45:07 Saving...
2017/08/28 15:45:07 Gathering batch of experience...
2017/08/28 15:45:54 batch 340: mean=64.444444 stddev=50.279190 entropy=0.470967 frames=4740 count=72
2017/08/28 15:45:54 Training policy...
2017/08/28 15:45:57 step 0: objective=0.35307035
2017/08/28 15:45:58 step 1: objective=0.36856258
2017/08/28 15:46:00 step 2: objective=0.38137951
2017/08/28 15:46:01 step 3: objective=0.389114
2017/08/28 15:46:02 step 4: objective=0.40164074
2017/08/28 15:46:03 step 5: objective=0.40867102
2017/08/28 15:46:04 step 6: objective=0.41436556
2017/08/28 15:46:05 step 7: objective=0.4225331
2017/08/28 15:46:05 Training value function...
2017/08/28 15:46:07 step 0: mse=148.879330 step=0.100000
2017/08/28 15:46:08 step 1: mse=147.249100 step=0.100000
2017/08/28 15:46:09 step 2: mse=145.770006 step=0.100000
2017/08/28 15:46:10 step 3: mse=144.496110 step=0.100000
2017/08/28 15:46:11 step 4: mse=143.119831 step=0.100000
2017/08/28 15:46:12 step 5: mse=142.072882 step=0.100000
2017/08/28 15:46:13 step 6: mse=141.288279 step=0.100000
2017/08/28 15:46:14 step 7: mse=140.432490 step=0.100000
2017/08/28 15:46:14 Saving...
2017/08/28 15:46:14 Gathering batch of experience...
2017/08/28 15:47:02 batch 341: mean=64.458333 stddev=65.350962 entropy=0.466442 frames=4602 count=72
2017/08/28 15:47:02 Training policy...
2017/08/28 15:47:06 step 0: objective=0.95967746
2017/08/28 15:47:07 step 1: objective=0.97118634
2017/08/28 15:47:08 step 2: objective=0.9822452
2017/08/28 15:47:09 step 3: objective=0.9914539
2017/08/28 15:47:10 step 4: objective=0.9974623
2017/08/28 15:47:11 step 5: objective=1.0079803
2017/08/28 15:47:12 step 6: objective=1.0216477
2017/08/28 15:47:13 step 7: objective=1.0253409
2017/08/28 15:47:13 Training value function...
2017/08/28 15:47:15 step 0: mse=191.106003 step=0.100000
2017/08/28 15:47:16 step 1: mse=187.155716 step=0.100000
2017/08/28 15:47:17 step 2: mse=184.085468 step=0.100000
2017/08/28 15:47:18 step 3: mse=180.890747 step=0.100000
2017/08/28 15:47:19 step 4: mse=178.681340 step=0.100000
2017/08/28 15:47:20 step 5: mse=176.220562 step=0.100000
2017/08/28 15:47:21 step 6: mse=173.783264 step=0.100000
2017/08/28 15:47:22 step 7: mse=171.989987 step=0.100000
2017/08/28 15:47:22 Saving...
2017/08/28 15:47:22 Gathering batch of experience...
2017/08/28 15:48:13 batch 342: mean=55.268293 stddev=54.723039 entropy=0.474673 frames=4734 count=82
2017/08/28 15:48:13 Training policy...
2017/08/28 15:48:16 step 0: objective=0.16951208
2017/08/28 15:48:17 step 1: objective=0.18092413
2017/08/28 15:48:18 step 2: objective=0.18815927
2017/08/28 15:48:19 step 3: objective=0.19696565
2017/08/28 15:48:21 step 4: objective=0.20450634
2017/08/28 15:48:22 step 5: objective=0.21429622
2017/08/28 15:48:23 step 6: objective=0.22313264
2017/08/28 15:48:24 step 7: objective=0.23187213
2017/08/28 15:48:24 Training value function...
2017/08/28 15:48:26 step 0: mse=166.217067 step=0.100000
2017/08/28 15:48:27 step 1: mse=164.621675 step=0.100000
2017/08/28 15:48:28 step 2: mse=162.620473 step=0.100000
2017/08/28 15:48:29 step 3: mse=161.155881 step=0.100000
2017/08/28 15:48:30 step 4: mse=159.754736 step=0.100000
2017/08/28 15:48:31 step 5: mse=158.180733 step=0.100000
2017/08/28 15:48:32 step 6: mse=156.726164 step=0.100000
2017/08/28 15:48:33 step 7: mse=155.396706 step=0.100000
2017/08/28 15:48:33 Saving...
2017/08/28 15:48:33 Gathering batch of experience...
2017/08/28 15:49:19 batch 343: mean=66.149254 stddev=55.885345 entropy=0.468896 frames=4470 count=67
2017/08/28 15:49:19 Training policy...
2017/08/28 15:49:22 step 0: objective=1.4693506
2017/08/28 15:49:23 step 1: objective=1.4764953
2017/08/28 15:49:25 step 2: objective=1.4902506
2017/08/28 15:49:26 step 3: objective=1.4974252
2017/08/28 15:49:27 step 4: objective=1.5151913
2017/08/28 15:49:28 step 5: objective=1.5199641
2017/08/28 15:49:29 step 6: objective=1.5285891
2017/08/28 15:49:30 step 7: objective=1.5348823
2017/08/28 15:49:30 Training value function...
2017/08/28 15:49:32 step 0: mse=184.616613 step=0.100000
2017/08/28 15:49:33 step 1: mse=180.804673 step=0.100000
2017/08/28 15:49:33 step 2: mse=177.417342 step=0.100000
2017/08/28 15:49:34 step 3: mse=174.291016 step=0.100000
2017/08/28 15:49:35 step 4: mse=171.613241 step=0.100000
2017/08/28 15:49:36 step 5: mse=169.242464 step=0.100000
2017/08/28 15:49:37 step 6: mse=167.052404 step=0.100000
2017/08/28 15:49:38 step 7: mse=165.161424 step=0.100000
2017/08/28 15:49:38 Saving...
2017/08/28 15:49:38 Gathering batch of experience...
2017/08/28 15:50:22 batch 344: mean=72.349206 stddev=63.458813 entropy=0.472661 frames=4670 count=63
2017/08/28 15:50:22 Training policy...
2017/08/28 15:50:25 step 0: objective=1.2478062
2017/08/28 15:50:26 step 1: objective=1.2589263
2017/08/28 15:50:27 step 2: objective=1.267348
2017/08/28 15:50:28 step 3: objective=1.2734257
2017/08/28 15:50:29 step 4: objective=1.2792704
2017/08/28 15:50:31 step 5: objective=1.2908131
2017/08/28 15:50:32 step 6: objective=1.3016281
2017/08/28 15:50:33 step 7: objective=1.3059614
2017/08/28 15:50:33 Training value function...
2017/08/28 15:50:35 step 0: mse=153.076181 step=0.100000
2017/08/28 15:50:36 step 1: mse=150.990534 step=0.100000
2017/08/28 15:50:37 step 2: mse=149.461074 step=0.100000
2017/08/28 15:50:38 step 3: mse=148.127777 step=0.100000
2017/08/28 15:50:39 step 4: mse=146.750391 step=0.100000
2017/08/28 15:50:39 step 5: mse=145.294175 step=0.100000
2017/08/28 15:50:40 step 6: mse=144.031541 step=0.100000
2017/08/28 15:50:41 step 7: mse=143.048272 step=0.100000
2017/08/28 15:50:41 Saving...
2017/08/28 15:50:41 Gathering batch of experience...
2017/08/28 15:51:30 batch 345: mean=69.600000 stddev=63.392744 entropy=0.472555 frames=4963 count=70
2017/08/28 15:51:30 Training policy...
2017/08/28 15:51:33 step 0: objective=1.145681
2017/08/28 15:51:34 step 1: objective=1.1589068
2017/08/28 15:51:35 step 2: objective=1.1675094
2017/08/28 15:51:37 step 3: objective=1.1777668
2017/08/28 15:51:38 step 4: objective=1.1828779
2017/08/28 15:51:39 step 5: objective=1.1905195
2017/08/28 15:51:40 step 6: objective=1.1978372
2017/08/28 15:51:41 step 7: objective=1.2028981
2017/08/28 15:51:41 Training value function...
2017/08/28 15:51:43 step 0: mse=182.790284 step=0.100000
2017/08/28 15:51:44 step 1: mse=180.220196 step=0.100000
2017/08/28 15:51:45 step 2: mse=177.977038 step=0.100000
2017/08/28 15:51:46 step 3: mse=176.017723 step=0.100000
2017/08/28 15:51:47 step 4: mse=174.177037 step=0.100000
2017/08/28 15:51:48 step 5: mse=172.349098 step=0.100000
2017/08/28 15:51:49 step 6: mse=170.920692 step=0.100000
2017/08/28 15:51:50 step 7: mse=169.343263 step=0.100000
2017/08/28 15:51:50 Saving...
2017/08/28 15:51:50 Gathering batch of experience...
2017/08/28 15:52:35 batch 346: mean=66.637681 stddev=61.165959 entropy=0.474102 frames=4517 count=69
2017/08/28 15:52:35 Training policy...
2017/08/28 15:52:38 step 0: objective=1.0600383
2017/08/28 15:52:39 step 1: objective=1.0707827
2017/08/28 15:52:41 step 2: objective=1.0767908
2017/08/28 15:52:42 step 3: objective=1.0878599
2017/08/28 15:52:43 step 4: objective=1.0930972
2017/08/28 15:52:44 step 5: objective=1.0980002
2017/08/28 15:52:45 step 6: objective=1.1039265
2017/08/28 15:52:46 step 7: objective=1.1106875
2017/08/28 15:52:46 Training value function...
2017/08/28 15:52:48 step 0: mse=188.447743 step=0.100000
2017/08/28 15:52:49 step 1: mse=186.079228 step=0.100000
2017/08/28 15:52:50 step 2: mse=184.227088 step=0.100000
2017/08/28 15:52:51 step 3: mse=182.099745 step=0.100000
2017/08/28 15:52:51 step 4: mse=180.130385 step=0.100000
2017/08/28 15:52:52 step 5: mse=178.823989 step=0.100000
2017/08/28 15:52:53 step 6: mse=177.032380 step=0.100000
2017/08/28 15:52:54 step 7: mse=175.892494 step=0.100000
2017/08/28 15:52:54 Saving...
2017/08/28 15:52:54 Gathering batch of experience...
2017/08/28 15:53:42 batch 347: mean=66.128571 stddev=59.731045 entropy=0.473395 frames=4691 count=70
2017/08/28 15:53:42 Training policy...
2017/08/28 15:53:45 step 0: objective=0.88806975
2017/08/28 15:53:46 step 1: objective=0.9025962
2017/08/28 15:53:47 step 2: objective=0.9139247
2017/08/28 15:53:49 step 3: objective=0.9272168
2017/08/28 15:53:50 step 4: objective=0.9370746
2017/08/28 15:53:51 step 5: objective=0.94334763
2017/08/28 15:53:52 step 6: objective=0.95022225
2017/08/28 15:53:53 step 7: objective=0.95562625
2017/08/28 15:53:53 Training value function...
2017/08/28 15:53:55 step 0: mse=162.599176 step=0.100000
2017/08/28 15:53:56 step 1: mse=161.028720 step=0.100000
2017/08/28 15:53:57 step 2: mse=159.384608 step=0.100000
2017/08/28 15:53:58 step 3: mse=158.188313 step=0.100000
2017/08/28 15:53:59 step 4: mse=156.881679 step=0.100000
2017/08/28 15:54:00 step 5: mse=155.452230 step=0.100000
2017/08/28 15:54:01 step 6: mse=154.346823 step=0.100000
2017/08/28 15:54:02 step 7: mse=153.302376 step=0.100000
2017/08/28 15:54:02 Saving...
2017/08/28 15:54:02 Gathering batch of experience...
2017/08/28 15:54:52 batch 348: mean=63.786667 stddev=55.823602 entropy=0.473251 frames=4781 count=75
2017/08/28 15:54:52 Training policy...
2017/08/28 15:54:55 step 0: objective=0.58186567
2017/08/28 15:54:56 step 1: objective=0.5901776
2017/08/28 15:54:57 step 2: objective=0.60120356
2017/08/28 15:54:58 step 3: objective=0.61163
2017/08/28 15:54:59 step 4: objective=0.61780566
2017/08/28 15:55:00 step 5: objective=0.62494725
2017/08/28 15:55:01 step 6: objective=0.6307304
2017/08/28 15:55:03 step 7: objective=0.6362327
2017/08/28 15:55:03 Training value function...
2017/08/28 15:55:05 step 0: mse=162.207072 step=0.100000
2017/08/28 15:55:05 step 1: mse=159.996611 step=0.100000
2017/08/28 15:55:06 step 2: mse=158.133286 step=0.100000
2017/08/28 15:55:07 step 3: mse=156.624220 step=0.100000
2017/08/28 15:55:08 step 4: mse=155.490825 step=0.100000
2017/08/28 15:55:09 step 5: mse=154.094671 step=0.100000
2017/08/28 15:55:10 step 6: mse=153.017097 step=0.100000
2017/08/28 15:55:11 step 7: mse=151.955362 step=0.100000
2017/08/28 15:55:11 Saving...
2017/08/28 15:55:11 Gathering batch of experience...
2017/08/28 15:56:01 batch 349: mean=63.229730 stddev=61.815669 entropy=0.474692 frames=4912 count=74
2017/08/28 15:56:01 Training policy...
2017/08/28 15:56:05 step 0: objective=0.76303035
2017/08/28 15:56:06 step 1: objective=0.7818147
2017/08/28 15:56:07 step 2: objective=0.79206216
2017/08/28 15:56:08 step 3: objective=0.80334055
2017/08/28 15:56:09 step 4: objective=0.80818504
2017/08/28 15:56:10 step 5: objective=0.81437314
2017/08/28 15:56:11 step 6: objective=0.81923324
2017/08/28 15:56:13 step 7: objective=0.8237259
2017/08/28 15:56:13 Training value function...
2017/08/28 15:56:15 step 0: mse=171.820696 step=0.100000
2017/08/28 15:56:16 step 1: mse=170.246342 step=0.100000
2017/08/28 15:56:17 step 2: mse=168.977807 step=0.100000
2017/08/28 15:56:18 step 3: mse=167.688201 step=0.100000
2017/08/28 15:56:19 step 4: mse=166.413180 step=0.100000
2017/08/28 15:56:20 step 5: mse=165.205719 step=0.100000
2017/08/28 15:56:21 step 6: mse=164.158564 step=0.100000
2017/08/28 15:56:22 step 7: mse=163.188001 step=0.100000
2017/08/28 15:56:22 Saving...
2017/08/28 15:56:22 Gathering batch of experience...
2017/08/28 15:57:08 batch 350: mean=70.941176 stddev=68.948805 entropy=0.468775 frames=4787 count=68
2017/08/28 15:57:08 Training policy...
2017/08/28 15:57:11 step 0: objective=1.545224
2017/08/28 15:57:12 step 1: objective=1.5516894
2017/08/28 15:57:14 step 2: objective=1.5587556
2017/08/28 15:57:15 step 3: objective=1.5679885
2017/08/28 15:57:16 step 4: objective=1.5773488
2017/08/28 15:57:17 step 5: objective=1.5852538
2017/08/28 15:57:18 step 6: objective=1.5895848
2017/08/28 15:57:19 step 7: objective=1.5932562
2017/08/28 15:57:19 Training value function...
2017/08/28 15:57:21 step 0: mse=185.391181 step=0.100000
2017/08/28 15:57:22 step 1: mse=182.449946 step=0.100000
2017/08/28 15:57:23 step 2: mse=179.980770 step=0.100000
2017/08/28 15:57:24 step 3: mse=177.556090 step=0.100000
2017/08/28 15:57:25 step 4: mse=175.651477 step=0.100000
2017/08/28 15:57:26 step 5: mse=173.488054 step=0.100000
2017/08/28 15:57:27 step 6: mse=171.585835 step=0.100000
2017/08/28 15:57:28 step 7: mse=170.128188 step=0.100000
2017/08/28 15:57:28 Saving...
2017/08/28 15:57:28 Gathering batch of experience...
2017/08/28 15:58:14 batch 351: mean=69.212121 stddev=64.656087 entropy=0.469190 frames=4628 count=66
2017/08/28 15:58:14 Training policy...
2017/08/28 15:58:17 step 0: objective=0.97862726
2017/08/28 15:58:18 step 1: objective=0.99115723
2017/08/28 15:58:19 step 2: objective=1.005256
2017/08/28 15:58:20 step 3: objective=1.0131856
2017/08/28 15:58:21 step 4: objective=1.0184954
2017/08/28 15:58:22 step 5: objective=1.0279284
2017/08/28 15:58:23 step 6: objective=1.0333114
2017/08/28 15:58:24 step 7: objective=1.0415937
2017/08/28 15:58:24 Training value function...
2017/08/28 15:58:26 step 0: mse=152.751613 step=0.100000
2017/08/28 15:58:27 step 1: mse=151.353088 step=0.100000
2017/08/28 15:58:28 step 2: mse=149.949668 step=0.100000
2017/08/28 15:58:29 step 3: mse=149.006276 step=0.100000
2017/08/28 15:58:30 step 4: mse=147.882725 step=0.100000
2017/08/28 15:58:31 step 5: mse=147.333179 step=0.100000
2017/08/28 15:58:32 step 6: mse=146.420330 step=0.100000
2017/08/28 15:58:33 step 7: mse=145.424835 step=0.100000
2017/08/28 15:58:33 Saving...
2017/08/28 15:58:33 Gathering batch of experience...
2017/08/28 15:59:21 batch 352: mean=71.214286 stddev=62.304527 entropy=0.465361 frames=4872 count=70
2017/08/28 15:59:21 Training policy...
2017/08/28 15:59:24 step 0: objective=1.1132576
2017/08/28 15:59:25 step 1: objective=1.119804
2017/08/28 15:59:26 step 2: objective=1.1270927
2017/08/28 15:59:27 step 3: objective=1.1345941
2017/08/28 15:59:29 step 4: objective=1.141072
2017/08/28 15:59:30 step 5: objective=1.1470721
2017/08/28 15:59:31 step 6: objective=1.1546315
2017/08/28 15:59:32 step 7: objective=1.1650528
2017/08/28 15:59:32 Training value function...
2017/08/28 15:59:34 step 0: mse=157.365004 step=0.100000
2017/08/28 15:59:35 step 1: mse=155.222033 step=0.100000
2017/08/28 15:59:36 step 2: mse=153.004652 step=0.100000
2017/08/28 15:59:37 step 3: mse=151.475933 step=0.100000
2017/08/28 15:59:38 step 4: mse=150.094415 step=0.100000
2017/08/28 15:59:39 step 5: mse=148.757936 step=0.100000
2017/08/28 15:59:40 step 6: mse=147.468736 step=0.100000
2017/08/28 15:59:41 step 7: mse=146.535529 step=0.100000
2017/08/28 15:59:41 Saving...
2017/08/28 15:59:41 Gathering batch of experience...
2017/08/28 16:00:29 batch 353: mean=85.796875 stddev=80.012144 entropy=0.469601 frames=5099 count=64
2017/08/28 16:00:29 Training policy...
2017/08/28 16:00:33 step 0: objective=2.2210512
2017/08/28 16:00:34 step 1: objective=2.2360754
2017/08/28 16:00:35 step 2: objective=2.2484443
2017/08/28 16:00:36 step 3: objective=2.2555885
2017/08/28 16:00:38 step 4: objective=2.2626407
2017/08/28 16:00:39 step 5: objective=2.2671492
2017/08/28 16:00:40 step 6: objective=2.2729237
2017/08/28 16:00:41 step 7: objective=2.282155
2017/08/28 16:00:41 Training value function...
2017/08/28 16:00:43 step 0: mse=215.183743 step=0.100000
2017/08/28 16:00:44 step 1: mse=210.610742 step=0.100000
2017/08/28 16:00:45 step 2: mse=206.203088 step=0.100000
2017/08/28 16:00:47 step 3: mse=202.203394 step=0.100000
2017/08/28 16:00:48 step 4: mse=198.708536 step=0.100000
2017/08/28 16:00:49 step 5: mse=196.056198 step=0.100000
2017/08/28 16:00:50 step 6: mse=193.335478 step=0.100000
2017/08/28 16:00:51 step 7: mse=191.338615 step=0.100000
2017/08/28 16:00:51 Saving...
2017/08/28 16:00:51 Gathering batch of experience...
2017/08/28 16:01:34 batch 354: mean=84.396552 stddev=67.516522 entropy=0.473530 frames=4810 count=58
2017/08/28 16:01:34 Training policy...
2017/08/28 16:01:37 step 0: objective=1.0537331
2017/08/28 16:01:39 step 1: objective=1.0644587
2017/08/28 16:01:40 step 2: objective=1.0754535
2017/08/28 16:01:41 step 3: objective=1.0843985
2017/08/28 16:01:42 step 4: objective=1.0938773
2017/08/28 16:01:43 step 5: objective=1.1024039
2017/08/28 16:01:44 step 6: objective=1.1097987
2017/08/28 16:01:46 step 7: objective=1.1151695
2017/08/28 16:01:46 Training value function...
2017/08/28 16:01:48 step 0: mse=184.681777 step=0.100000
2017/08/28 16:01:49 step 1: mse=181.909486 step=0.100000
2017/08/28 16:01:50 step 2: mse=179.587765 step=0.100000
2017/08/28 16:01:51 step 3: mse=177.072647 step=0.100000
2017/08/28 16:01:52 step 4: mse=175.209807 step=0.100000
2017/08/28 16:01:53 step 5: mse=173.796128 step=0.100000
2017/08/28 16:01:54 step 6: mse=172.170763 step=0.100000
2017/08/28 16:01:55 step 7: mse=170.786129 step=0.100000
2017/08/28 16:01:55 Saving...
2017/08/28 16:01:55 Gathering batch of experience...
2017/08/28 16:02:42 batch 355: mean=74.865672 stddev=66.171396 entropy=0.464093 frames=4968 count=67
2017/08/28 16:02:42 Training policy...
2017/08/28 16:02:45 step 0: objective=0.29858342
2017/08/28 16:02:47 step 1: objective=0.3073298
2017/08/28 16:02:48 step 2: objective=0.31629282
2017/08/28 16:02:49 step 3: objective=0.32656693
2017/08/28 16:02:50 step 4: objective=0.33221996
2017/08/28 16:02:51 step 5: objective=0.33769056
2017/08/28 16:02:53 step 6: objective=0.34423304
2017/08/28 16:02:54 step 7: objective=0.3482389
2017/08/28 16:02:54 Training value function...
2017/08/28 16:02:56 step 0: mse=157.549089 step=0.100000
2017/08/28 16:02:57 step 1: mse=156.468220 step=0.100000
2017/08/28 16:02:58 step 2: mse=155.363885 step=0.100000
2017/08/28 16:02:59 step 3: mse=153.646745 step=0.100000
2017/08/28 16:03:00 step 4: mse=152.122535 step=0.100000
2017/08/28 16:03:01 step 5: mse=151.365480 step=0.100000
2017/08/28 16:03:02 step 6: mse=150.045472 step=0.100000
2017/08/28 16:03:03 step 7: mse=149.664341 step=0.100000
2017/08/28 16:03:03 Saving...
2017/08/28 16:03:03 Gathering batch of experience...
2017/08/28 16:03:50 batch 356: mean=80.578125 stddev=75.844991 entropy=0.469690 frames=4960 count=64
2017/08/28 16:03:50 Training policy...
2017/08/28 16:03:53 step 0: objective=1.308815
2017/08/28 16:03:54 step 1: objective=1.314176
2017/08/28 16:03:56 step 2: objective=1.3277658
2017/08/28 16:03:57 step 3: objective=1.3364538
2017/08/28 16:03:58 step 4: objective=1.3470705
2017/08/28 16:03:59 step 5: objective=1.3544377
2017/08/28 16:04:00 step 6: objective=1.3579537
2017/08/28 16:04:01 step 7: objective=1.3613997
2017/08/28 16:04:01 Training value function...
2017/08/28 16:04:04 step 0: mse=186.407955 step=0.100000
2017/08/28 16:04:05 step 1: mse=183.196961 step=0.100000
2017/08/28 16:04:06 step 2: mse=180.599577 step=0.100000
2017/08/28 16:04:07 step 3: mse=178.333872 step=0.100000
2017/08/28 16:04:08 step 4: mse=176.420142 step=0.100000
2017/08/28 16:04:09 step 5: mse=174.366698 step=0.100000
2017/08/28 16:04:10 step 6: mse=172.592783 step=0.100000
2017/08/28 16:04:11 step 7: mse=171.100389 step=0.100000
2017/08/28 16:04:11 Saving...
2017/08/28 16:04:11 Gathering batch of experience...
2017/08/28 16:05:01 batch 357: mean=99.466667 stddev=90.044335 entropy=0.471270 frames=5523 count=60
2017/08/28 16:05:01 Training policy...
2017/08/28 16:05:05 step 0: objective=2.0473895
2017/08/28 16:05:06 step 1: objective=2.0532026
2017/08/28 16:05:07 step 2: objective=2.0604477
2017/08/28 16:05:09 step 3: objective=2.0662873
2017/08/28 16:05:10 step 4: objective=2.0738583
2017/08/28 16:05:11 step 5: objective=2.0818448
2017/08/28 16:05:13 step 6: objective=2.0857377
2017/08/28 16:05:14 step 7: objective=2.091063
2017/08/28 16:05:14 Training value function...
2017/08/28 16:05:16 step 0: mse=200.701782 step=0.100000
2017/08/28 16:05:17 step 1: mse=197.008462 step=0.100000
2017/08/28 16:05:19 step 2: mse=193.602454 step=0.100000
2017/08/28 16:05:20 step 3: mse=190.433855 step=0.100000
2017/08/28 16:05:21 step 4: mse=187.769754 step=0.100000
2017/08/28 16:05:22 step 5: mse=185.307878 step=0.100000
2017/08/28 16:05:23 step 6: mse=183.081324 step=0.100000
2017/08/28 16:05:24 step 7: mse=181.259770 step=0.100000
2017/08/28 16:05:24 Saving...
2017/08/28 16:05:24 Gathering batch of experience...
2017/08/28 16:06:08 batch 358: mean=84.241379 stddev=71.480962 entropy=0.456002 frames=4723 count=58
2017/08/28 16:06:08 Training policy...
2017/08/28 16:06:11 step 0: objective=0.4230784
2017/08/28 16:06:12 step 1: objective=0.43436205
2017/08/28 16:06:13 step 2: objective=0.44122374
2017/08/28 16:06:14 step 3: objective=0.44750956
2017/08/28 16:06:16 step 4: objective=0.45700312
2017/08/28 16:06:17 step 5: objective=0.46446422
2017/08/28 16:06:18 step 6: objective=0.47346953
2017/08/28 16:06:19 step 7: objective=0.4856875
2017/08/28 16:06:19 Training value function...
2017/08/28 16:06:21 step 0: mse=182.600097 step=0.100000
2017/08/28 16:06:22 step 1: mse=180.214526 step=0.100000
2017/08/28 16:06:23 step 2: mse=178.351939 step=0.100000
2017/08/28 16:06:24 step 3: mse=176.671870 step=0.100000
2017/08/28 16:06:25 step 4: mse=175.139224 step=0.100000
2017/08/28 16:06:26 step 5: mse=173.922395 step=0.100000
2017/08/28 16:06:27 step 6: mse=172.262557 step=0.100000
2017/08/28 16:06:28 step 7: mse=170.797221 step=0.100000
2017/08/28 16:06:28 Saving...
2017/08/28 16:06:28 Gathering batch of experience...
2017/08/28 16:07:13 batch 359: mean=65.185714 stddev=56.449293 entropy=0.471063 frames=4600 count=70
2017/08/28 16:07:13 Training policy...
2017/08/28 16:07:17 step 0: objective=-0.122652404
2017/08/28 16:07:18 step 1: objective=-0.11171466
2017/08/28 16:07:19 step 2: objective=-0.100144714
2017/08/28 16:07:20 step 3: objective=-0.09155379
2017/08/28 16:07:21 step 4: objective=-0.08094126
2017/08/28 16:07:22 step 5: objective=-0.068193786
2017/08/28 16:07:23 step 6: objective=-0.058231845
2017/08/28 16:07:24 step 7: objective=-0.054082446
2017/08/28 16:07:24 Training value function...
2017/08/28 16:07:26 step 0: mse=156.867144 step=0.100000
2017/08/28 16:07:27 step 1: mse=153.514707 step=0.100000
2017/08/28 16:07:28 step 2: mse=150.818128 step=0.100000
2017/08/28 16:07:29 step 3: mse=148.465415 step=0.100000
2017/08/28 16:07:30 step 4: mse=146.648127 step=0.100000
2017/08/28 16:07:31 step 5: mse=145.301642 step=0.100000
2017/08/28 16:07:32 step 6: mse=144.228832 step=0.100000
2017/08/28 16:07:33 step 7: mse=143.198145 step=0.100000
2017/08/28 16:07:33 Saving...
2017/08/28 16:07:33 Gathering batch of experience...
2017/08/28 16:08:16 batch 360: mean=67.953125 stddev=66.376396 entropy=0.467514 frames=4362 count=64
2017/08/28 16:08:16 Training policy...
2017/08/28 16:08:19 step 0: objective=0.5753161
2017/08/28 16:08:20 step 1: objective=0.5855196
2017/08/28 16:08:21 step 2: objective=0.5942325
2017/08/28 16:08:22 step 3: objective=0.6016084
2017/08/28 16:08:23 step 4: objective=0.6098087
2017/08/28 16:08:24 step 5: objective=0.6185053
2017/08/28 16:08:26 step 6: objective=0.6282989
2017/08/28 16:08:27 step 7: objective=0.63717234
2017/08/28 16:08:27 Training value function...
2017/08/28 16:08:28 step 0: mse=187.711871 step=0.100000
2017/08/28 16:08:29 step 1: mse=184.984744 step=0.100000
2017/08/28 16:08:30 step 2: mse=182.461111 step=0.100000
2017/08/28 16:08:31 step 3: mse=180.102165 step=0.100000
2017/08/28 16:08:32 step 4: mse=178.440295 step=0.100000
2017/08/28 16:08:33 step 5: mse=176.594523 step=0.100000
2017/08/28 16:08:34 step 6: mse=174.939014 step=0.100000
2017/08/28 16:08:35 step 7: mse=173.441182 step=0.100000
2017/08/28 16:08:35 Saving...
2017/08/28 16:08:35 Gathering batch of experience...
2017/08/28 16:09:24 batch 361: mean=66.175676 stddev=52.619583 entropy=0.466166 frames=4814 count=74
2017/08/28 16:09:24 Training policy...
2017/08/28 16:09:28 step 0: objective=0.5694248
2017/08/28 16:09:29 step 1: objective=0.58290744
2017/08/28 16:09:30 step 2: objective=0.59625876
2017/08/28 16:09:31 step 3: objective=0.6063596
2017/08/28 16:09:32 step 4: objective=0.6161651
2017/08/28 16:09:33 step 5: objective=0.6214217
2017/08/28 16:09:35 step 6: objective=0.62587535
2017/08/28 16:09:36 step 7: objective=0.63178104
2017/08/28 16:09:36 Training value function...
2017/08/28 16:09:38 step 0: mse=149.235744 step=0.100000
2017/08/28 16:09:39 step 1: mse=147.689596 step=0.100000
2017/08/28 16:09:40 step 2: mse=146.349516 step=0.100000
2017/08/28 16:09:41 step 3: mse=145.377630 step=0.100000
2017/08/28 16:09:42 step 4: mse=144.575056 step=0.100000
2017/08/28 16:09:43 step 5: mse=143.394681 step=0.100000
2017/08/28 16:09:44 step 6: mse=142.494755 step=0.100000
2017/08/28 16:09:45 step 7: mse=141.804443 step=0.100000
2017/08/28 16:09:45 Saving...
2017/08/28 16:09:45 Gathering batch of experience...
2017/08/28 16:10:31 batch 362: mean=70.073529 stddev=61.591949 entropy=0.456333 frames=4704 count=68
2017/08/28 16:10:31 Training policy...
2017/08/28 16:10:35 step 0: objective=0.9768843
2017/08/28 16:10:36 step 1: objective=0.99032086
2017/08/28 16:10:37 step 2: objective=1.001899
2017/08/28 16:10:38 step 3: objective=1.0143892
2017/08/28 16:10:39 step 4: objective=1.0213134
2017/08/28 16:10:40 step 5: objective=1.029849
2017/08/28 16:10:41 step 6: objective=1.0372665
2017/08/28 16:10:42 step 7: objective=1.0437425
2017/08/28 16:10:42 Training value function...
2017/08/28 16:10:44 step 0: mse=158.595330 step=0.100000
2017/08/28 16:10:45 step 1: mse=156.770108 step=0.100000
2017/08/28 16:10:46 step 2: mse=155.449947 step=0.100000
2017/08/28 16:10:47 step 3: mse=154.196431 step=0.100000
2017/08/28 16:10:48 step 4: mse=153.001106 step=0.100000
2017/08/28 16:10:49 step 5: mse=151.445036 step=0.100000
2017/08/28 16:10:50 step 6: mse=150.452653 step=0.100000
2017/08/28 16:10:51 step 7: mse=149.708934 step=0.100000
2017/08/28 16:10:51 Saving...
2017/08/28 16:10:51 Gathering batch of experience...
2017/08/28 16:11:41 batch 363: mean=69.698630 stddev=66.456224 entropy=0.463928 frames=5025 count=73
2017/08/28 16:11:41 Training policy...
2017/08/28 16:11:45 step 0: objective=1.1963944
2017/08/28 16:11:46 step 1: objective=1.2117624
2017/08/28 16:11:47 step 2: objective=1.2219611
2017/08/28 16:11:48 step 3: objective=1.231177
2017/08/28 16:11:49 step 4: objective=1.2372476
2017/08/28 16:11:51 step 5: objective=1.2456081
2017/08/28 16:11:52 step 6: objective=1.2523097
2017/08/28 16:11:53 step 7: objective=1.2572303
2017/08/28 16:11:53 Training value function...
2017/08/28 16:11:55 step 0: mse=193.909890 step=0.100000
2017/08/28 16:11:56 step 1: mse=190.955176 step=0.100000
2017/08/28 16:11:57 step 2: mse=188.393608 step=0.100000
2017/08/28 16:11:58 step 3: mse=186.415767 step=0.100000
2017/08/28 16:11:59 step 4: mse=184.364382 step=0.100000
2017/08/28 16:12:00 step 5: mse=182.333896 step=0.100000
2017/08/28 16:12:01 step 6: mse=180.486814 step=0.100000
2017/08/28 16:12:02 step 7: mse=178.915424 step=0.100000
2017/08/28 16:12:02 Saving...
2017/08/28 16:12:02 Gathering batch of experience...
2017/08/28 16:12:48 batch 364: mean=81.163934 stddev=79.232834 entropy=0.462557 frames=4885 count=61
2017/08/28 16:12:48 Training policy...
2017/08/28 16:12:51 step 0: objective=1.5592678
2017/08/28 16:12:52 step 1: objective=1.5684785
2017/08/28 16:12:53 step 2: objective=1.5796402
2017/08/28 16:12:54 step 3: objective=1.586423
2017/08/28 16:12:56 step 4: objective=1.591623
2017/08/28 16:12:57 step 5: objective=1.6035181
2017/08/28 16:12:58 step 6: objective=1.6121861
2017/08/28 16:12:59 step 7: objective=1.6169785
2017/08/28 16:12:59 Training value function...
2017/08/28 16:13:01 step 0: mse=221.561462 step=0.100000
2017/08/28 16:13:02 step 1: mse=217.762305 step=0.100000
2017/08/28 16:13:03 step 2: mse=214.361436 step=0.100000
2017/08/28 16:13:04 step 3: mse=211.231220 step=0.100000
2017/08/28 16:13:05 step 4: mse=208.341777 step=0.100000
2017/08/28 16:13:06 step 5: mse=205.799591 step=0.100000
2017/08/28 16:13:07 step 6: mse=203.315390 step=0.100000
2017/08/28 16:13:08 step 7: mse=201.095094 step=0.100000
2017/08/28 16:13:08 Saving...
2017/08/28 16:13:08 Gathering batch of experience...
2017/08/28 16:13:55 batch 365: mean=67.323529 stddev=59.697138 entropy=0.459380 frames=4496 count=68
2017/08/28 16:13:55 Training policy...
2017/08/28 16:13:58 step 0: objective=0.45823961
2017/08/28 16:13:59 step 1: objective=0.46852237
2017/08/28 16:14:00 step 2: objective=0.48451728
2017/08/28 16:14:01 step 3: objective=0.4908136
2017/08/28 16:14:02 step 4: objective=0.5038087
2017/08/28 16:14:03 step 5: objective=0.50955844
2017/08/28 16:14:04 step 6: objective=0.51973283
2017/08/28 16:14:05 step 7: objective=0.5242761
2017/08/28 16:14:05 Training value function...
2017/08/28 16:14:07 step 0: mse=164.787982 step=0.100000
2017/08/28 16:14:08 step 1: mse=163.335853 step=0.100000
2017/08/28 16:14:09 step 2: mse=162.054145 step=0.100000
2017/08/28 16:14:10 step 3: mse=160.892734 step=0.100000
2017/08/28 16:14:11 step 4: mse=159.457017 step=0.100000
2017/08/28 16:14:12 step 5: mse=158.163867 step=0.100000
2017/08/28 16:14:13 step 6: mse=156.556842 step=0.100000
2017/08/28 16:14:14 step 7: mse=155.195701 step=0.100000
2017/08/28 16:14:14 Saving...
2017/08/28 16:14:14 Gathering batch of experience...
2017/08/28 16:15:02 batch 366: mean=69.371429 stddev=70.342869 entropy=0.457331 frames=4962 count=70
2017/08/28 16:15:02 Training policy...
2017/08/28 16:15:06 step 0: objective=0.6572814
2017/08/28 16:15:07 step 1: objective=0.66353345
2017/08/28 16:15:08 step 2: objective=0.6770183
2017/08/28 16:15:09 step 3: objective=0.68486965
2017/08/28 16:15:10 step 4: objective=0.69154024
2017/08/28 16:15:12 step 5: objective=0.6964324
2017/08/28 16:15:13 step 6: objective=0.707722
2017/08/28 16:15:14 step 7: objective=0.7136381
2017/08/28 16:15:14 Training value function...
2017/08/28 16:15:16 step 0: mse=153.916661 step=0.100000
2017/08/28 16:15:17 step 1: mse=150.447314 step=0.100000
2017/08/28 16:15:18 step 2: mse=147.419955 step=0.100000
2017/08/28 16:15:19 step 3: mse=145.084162 step=0.100000
2017/08/28 16:15:20 step 4: mse=142.888962 step=0.100000
2017/08/28 16:15:21 step 5: mse=140.822314 step=0.100000
2017/08/28 16:15:22 step 6: mse=139.263881 step=0.100000
2017/08/28 16:15:23 step 7: mse=137.754091 step=0.100000
2017/08/28 16:15:23 Saving...
2017/08/28 16:15:23 Gathering batch of experience...
2017/08/28 16:16:11 batch 367: mean=84.193548 stddev=76.274301 entropy=0.459975 frames=5015 count=62
2017/08/28 16:16:11 Training policy...
2017/08/28 16:16:14 step 0: objective=1.8527973
2017/08/28 16:16:16 step 1: objective=1.8608289
2017/08/28 16:16:17 step 2: objective=1.8752514
2017/08/28 16:16:18 step 3: objective=1.883038
2017/08/28 16:16:19 step 4: objective=1.8890193
2017/08/28 16:16:20 step 5: objective=1.8975022
2017/08/28 16:16:22 step 6: objective=1.9021538
2017/08/28 16:16:23 step 7: objective=1.90896
2017/08/28 16:16:23 Training value function...
2017/08/28 16:16:25 step 0: mse=208.811345 step=0.100000
2017/08/28 16:16:26 step 1: mse=204.026897 step=0.100000
2017/08/28 16:16:27 step 2: mse=199.888660 step=0.100000
2017/08/28 16:16:28 step 3: mse=196.836399 step=0.100000
2017/08/28 16:16:29 step 4: mse=193.669687 step=0.100000
2017/08/28 16:16:30 step 5: mse=190.939205 step=0.100000
2017/08/28 16:16:31 step 6: mse=188.655340 step=0.100000
2017/08/28 16:16:32 step 7: mse=186.866543 step=0.100000
2017/08/28 16:16:32 Saving...
2017/08/28 16:16:32 Gathering batch of experience...
2017/08/28 16:17:17 batch 368: mean=76.203125 stddev=68.652927 entropy=0.462351 frames=4780 count=64
2017/08/28 16:17:17 Training policy...
2017/08/28 16:17:20 step 0: objective=0.8611813
2017/08/28 16:17:22 step 1: objective=0.8711686
2017/08/28 16:17:23 step 2: objective=0.88396496
2017/08/28 16:17:24 step 3: objective=0.89269894
2017/08/28 16:17:25 step 4: objective=0.9019277
2017/08/28 16:17:26 step 5: objective=0.9107321
2017/08/28 16:17:27 step 6: objective=0.91812885
2017/08/28 16:17:28 step 7: objective=0.9235997
2017/08/28 16:17:28 Training value function...
2017/08/28 16:17:30 step 0: mse=187.230826 step=0.100000
2017/08/28 16:17:31 step 1: mse=184.949176 step=0.100000
2017/08/28 16:17:32 step 2: mse=183.316286 step=0.100000
2017/08/28 16:17:33 step 3: mse=181.952535 step=0.100000
2017/08/28 16:17:34 step 4: mse=180.292214 step=0.100000
2017/08/28 16:17:35 step 5: mse=178.495257 step=0.100000
2017/08/28 16:17:36 step 6: mse=177.377286 step=0.100000
2017/08/28 16:17:37 step 7: mse=176.419615 step=0.100000
2017/08/28 16:17:37 Saving...
2017/08/28 16:17:37 Gathering batch of experience...
2017/08/28 16:18:24 batch 369: mean=71.476923 stddev=69.721227 entropy=0.466330 frames=4713 count=65
2017/08/28 16:18:24 Training policy...
2017/08/28 16:18:27 step 0: objective=0.5235165
2017/08/28 16:18:28 step 1: objective=0.5337564
2017/08/28 16:18:29 step 2: objective=0.54573685
2017/08/28 16:18:31 step 3: objective=0.5565019
2017/08/28 16:18:32 step 4: objective=0.5635187
2017/08/28 16:18:33 step 5: objective=0.5722199
2017/08/28 16:18:34 step 6: objective=0.5817801
2017/08/28 16:18:35 step 7: objective=0.590673
2017/08/28 16:18:35 Training value function...
2017/08/28 16:18:37 step 0: mse=168.170126 step=0.100000
2017/08/28 16:18:38 step 1: mse=166.439191 step=0.100000
2017/08/28 16:18:39 step 2: mse=165.361981 step=0.100000
2017/08/28 16:18:40 step 3: mse=163.891988 step=0.100000
2017/08/28 16:18:41 step 4: mse=162.689928 step=0.100000
2017/08/28 16:18:42 step 5: mse=161.909806 step=0.100000
2017/08/28 16:18:43 step 6: mse=160.566479 step=0.100000
2017/08/28 16:18:44 step 7: mse=159.520916 step=0.100000
2017/08/28 16:18:44 Saving...
2017/08/28 16:18:44 Gathering batch of experience...
2017/08/28 16:19:31 batch 370: mean=70.820896 stddev=60.912936 entropy=0.454697 frames=4821 count=67
2017/08/28 16:19:31 Training policy...
2017/08/28 16:19:34 step 0: objective=0.6359218
2017/08/28 16:19:35 step 1: objective=0.6475266
2017/08/28 16:19:37 step 2: objective=0.6574775
2017/08/28 16:19:38 step 3: objective=0.6652605
2017/08/28 16:19:39 step 4: objective=0.6748518
2017/08/28 16:19:40 step 5: objective=0.6847585
2017/08/28 16:19:41 step 6: objective=0.69250625
2017/08/28 16:19:42 step 7: objective=0.6985151
2017/08/28 16:19:42 Training value function...
2017/08/28 16:19:44 step 0: mse=163.349118 step=0.100000
2017/08/28 16:19:45 step 1: mse=161.862337 step=0.100000
2017/08/28 16:19:46 step 2: mse=160.246752 step=0.100000
2017/08/28 16:19:47 step 3: mse=158.922087 step=0.100000
2017/08/28 16:19:48 step 4: mse=157.968606 step=0.100000
2017/08/28 16:19:49 step 5: mse=157.221693 step=0.100000
2017/08/28 16:19:50 step 6: mse=156.103117 step=0.100000
2017/08/28 16:19:51 step 7: mse=155.119912 step=0.100000
2017/08/28 16:19:51 Saving...
2017/08/28 16:19:51 Gathering batch of experience...
2017/08/28 16:20:42 batch 371: mean=67.486111 stddev=63.029533 entropy=0.456025 frames=5004 count=72
2017/08/28 16:20:42 Training policy...
2017/08/28 16:20:45 step 0: objective=0.6019337
2017/08/28 16:20:46 step 1: objective=0.6111851
2017/08/28 16:20:47 step 2: objective=0.62259656
2017/08/28 16:20:49 step 3: objective=0.6275351
2017/08/28 16:20:50 step 4: objective=0.63597596
2017/08/28 16:20:51 step 5: objective=0.6404533
2017/08/28 16:20:52 step 6: objective=0.6465934
2017/08/28 16:20:53 step 7: objective=0.6501686
2017/08/28 16:20:53 Training value function...
2017/08/28 16:20:55 step 0: mse=157.217809 step=0.100000
2017/08/28 16:20:56 step 1: mse=155.085847 step=0.100000
2017/08/28 16:20:57 step 2: mse=152.800246 step=0.100000
2017/08/28 16:20:59 step 3: mse=151.333525 step=0.100000
2017/08/28 16:21:00 step 4: mse=149.566377 step=0.100000
2017/08/28 16:21:01 step 5: mse=148.234107 step=0.100000
2017/08/28 16:21:02 step 6: mse=147.002160 step=0.100000
2017/08/28 16:21:03 step 7: mse=145.971936 step=0.100000
2017/08/28 16:21:03 Saving...
2017/08/28 16:21:03 Gathering batch of experience...
2017/08/28 16:21:49 batch 372: mean=81.500000 stddev=57.514584 entropy=0.461709 frames=4878 count=62
2017/08/28 16:21:49 Training policy...
2017/08/28 16:21:52 step 0: objective=1.5671285
2017/08/28 16:21:53 step 1: objective=1.5750582
2017/08/28 16:21:54 step 2: objective=1.5813491
2017/08/28 16:21:56 step 3: objective=1.5881723
2017/08/28 16:21:57 step 4: objective=1.5943857
2017/08/28 16:21:58 step 5: objective=1.6005243
2017/08/28 16:21:59 step 6: objective=1.6063288
2017/08/28 16:22:00 step 7: objective=1.6132778
2017/08/28 16:22:00 Training value function...
2017/08/28 16:22:02 step 0: mse=158.379330 step=0.100000
2017/08/28 16:22:03 step 1: mse=154.504098 step=0.100000
2017/08/28 16:22:04 step 2: mse=151.071361 step=0.100000
2017/08/28 16:22:05 step 3: mse=148.438618 step=0.100000
2017/08/28 16:22:06 step 4: mse=146.192018 step=0.100000
2017/08/28 16:22:07 step 5: mse=144.126035 step=0.100000
2017/08/28 16:22:08 step 6: mse=142.392402 step=0.100000
2017/08/28 16:22:09 step 7: mse=140.796606 step=0.100000
2017/08/28 16:22:09 Saving...
2017/08/28 16:22:09 Gathering batch of experience...
2017/08/28 16:22:54 batch 373: mean=77.703125 stddev=64.653084 entropy=0.448184 frames=4753 count=64
2017/08/28 16:22:54 Training policy...
2017/08/28 16:22:58 step 0: objective=1.3215264
2017/08/28 16:22:59 step 1: objective=1.3430582
2017/08/28 16:23:00 step 2: objective=1.3513434
2017/08/28 16:23:01 step 3: objective=1.3634535
2017/08/28 16:23:02 step 4: objective=1.3819194
2017/08/28 16:23:03 step 5: objective=1.388364
2017/08/28 16:23:05 step 6: objective=1.3968997
2017/08/28 16:23:06 step 7: objective=1.4010369
2017/08/28 16:23:06 Training value function...
2017/08/28 16:23:08 step 0: mse=208.147783 step=0.100000
2017/08/28 16:23:09 step 1: mse=205.443493 step=0.100000
2017/08/28 16:23:10 step 2: mse=202.768099 step=0.100000
2017/08/28 16:23:11 step 3: mse=200.475723 step=0.100000
2017/08/28 16:23:12 step 4: mse=198.732068 step=0.100000
2017/08/28 16:23:13 step 5: mse=197.339101 step=0.100000
2017/08/28 16:23:14 step 6: mse=195.346134 step=0.100000
2017/08/28 16:23:15 step 7: mse=193.835332 step=0.100000
2017/08/28 16:23:15 Saving...
2017/08/28 16:23:15 Gathering batch of experience...
2017/08/28 16:24:00 batch 374: mean=67.378788 stddev=65.596740 entropy=0.460093 frames=4420 count=66
2017/08/28 16:24:00 Training policy...
2017/08/28 16:24:03 step 0: objective=0.5699636
2017/08/28 16:24:04 step 1: objective=0.58104223
2017/08/28 16:24:05 step 2: objective=0.5910276
2017/08/28 16:24:06 step 3: objective=0.60570204
2017/08/28 16:24:07 step 4: objective=0.6189707
2017/08/28 16:24:08 step 5: objective=0.62532955
2017/08/28 16:24:09 step 6: objective=0.633674
2017/08/28 16:24:10 step 7: objective=0.6407692
2017/08/28 16:24:10 Training value function...
2017/08/28 16:24:12 step 0: mse=198.159707 step=0.100000
2017/08/28 16:24:13 step 1: mse=195.593441 step=0.100000
2017/08/28 16:24:14 step 2: mse=192.782620 step=0.100000
2017/08/28 16:24:15 step 3: mse=190.445962 step=0.100000
2017/08/28 16:24:16 step 4: mse=188.549135 step=0.100000
2017/08/28 16:24:17 step 5: mse=186.501852 step=0.100000
2017/08/28 16:24:18 step 6: mse=184.674399 step=0.100000
2017/08/28 16:24:19 step 7: mse=183.203292 step=0.100000
2017/08/28 16:24:19 Saving...
2017/08/28 16:24:19 Gathering batch of experience...
2017/08/28 16:25:04 batch 375: mean=76.546875 stddev=66.443098 entropy=0.461522 frames=4956 count=64
2017/08/28 16:25:04 Training policy...
2017/08/28 16:25:08 step 0: objective=0.8837456
2017/08/28 16:25:09 step 1: objective=0.8973734
2017/08/28 16:25:10 step 2: objective=0.9031682
2017/08/28 16:25:11 step 3: objective=0.90945125
2017/08/28 16:25:12 step 4: objective=0.9133675
2017/08/28 16:25:14 step 5: objective=0.91744894
2017/08/28 16:25:15 step 6: objective=0.9215832
2017/08/28 16:25:16 step 7: objective=0.9298816
2017/08/28 16:25:16 Training value function...
2017/08/28 16:25:18 step 0: mse=152.350872 step=0.100000
2017/08/28 16:25:19 step 1: mse=150.176449 step=0.100000
2017/08/28 16:25:20 step 2: mse=148.752799 step=0.100000
2017/08/28 16:25:21 step 3: mse=146.976742 step=0.100000
2017/08/28 16:25:22 step 4: mse=145.442371 step=0.100000
2017/08/28 16:25:23 step 5: mse=144.481772 step=0.100000
2017/08/28 16:25:24 step 6: mse=143.221711 step=0.100000
2017/08/28 16:25:25 step 7: mse=142.042494 step=0.100000
2017/08/28 16:25:25 Saving...
2017/08/28 16:25:25 Gathering batch of experience...
2017/08/28 16:26:14 batch 376: mean=70.507246 stddev=68.303802 entropy=0.454938 frames=4802 count=69
2017/08/28 16:26:14 Training policy...
2017/08/28 16:26:17 step 0: objective=0.972762
2017/08/28 16:26:18 step 1: objective=0.9861708
2017/08/28 16:26:19 step 2: objective=0.9962855
2017/08/28 16:26:20 step 3: objective=1.0030156
2017/08/28 16:26:21 step 4: objective=1.0112785
2017/08/28 16:26:23 step 5: objective=1.0232112
2017/08/28 16:26:24 step 6: objective=1.0332651
2017/08/28 16:26:25 step 7: objective=1.0406029
2017/08/28 16:26:25 Training value function...
2017/08/28 16:26:27 step 0: mse=198.153178 step=0.100000
2017/08/28 16:26:28 step 1: mse=194.115194 step=0.100000
2017/08/28 16:26:29 step 2: mse=190.475070 step=0.100000
2017/08/28 16:26:30 step 3: mse=187.274270 step=0.100000
2017/08/28 16:26:31 step 4: mse=184.733921 step=0.100000
2017/08/28 16:26:32 step 5: mse=182.411698 step=0.100000
2017/08/28 16:26:33 step 6: mse=180.182571 step=0.100000
2017/08/28 16:26:34 step 7: mse=178.223952 step=0.100000
2017/08/28 16:26:34 Saving...
2017/08/28 16:26:34 Gathering batch of experience...
2017/08/28 16:27:21 batch 377: mean=74.636364 stddev=70.327079 entropy=0.457815 frames=4985 count=66
2017/08/28 16:27:21 Training policy...
2017/08/28 16:27:25 step 0: objective=0.9823844
2017/08/28 16:27:26 step 1: objective=0.9954634
2017/08/28 16:27:27 step 2: objective=1.0084385
2017/08/28 16:27:28 step 3: objective=1.0171108
2017/08/28 16:27:30 step 4: objective=1.0263925
2017/08/28 16:27:31 step 5: objective=1.0378188
2017/08/28 16:27:32 step 6: objective=1.0431557
2017/08/28 16:27:33 step 7: objective=1.0469856
2017/08/28 16:27:33 Training value function...
2017/08/28 16:27:35 step 0: mse=180.551233 step=0.100000
2017/08/28 16:27:36 step 1: mse=176.967070 step=0.100000
2017/08/28 16:27:37 step 2: mse=173.901291 step=0.100000
2017/08/28 16:27:38 step 3: mse=171.207942 step=0.100000
2017/08/28 16:27:39 step 4: mse=168.817323 step=0.100000
2017/08/28 16:27:40 step 5: mse=166.750262 step=0.100000
2017/08/28 16:27:41 step 6: mse=164.955754 step=0.100000
2017/08/28 16:27:43 step 7: mse=163.478105 step=0.100000
2017/08/28 16:27:43 Saving...
2017/08/28 16:27:43 Gathering batch of experience...
2017/08/28 16:28:30 batch 378: mean=72.794118 stddev=68.140115 entropy=0.456128 frames=4869 count=68
2017/08/28 16:28:30 Training policy...
2017/08/28 16:28:34 step 0: objective=1.0681192
2017/08/28 16:28:35 step 1: objective=1.0814139
2017/08/28 16:28:36 step 2: objective=1.090597
2017/08/28 16:28:37 step 3: objective=1.1006109
2017/08/28 16:28:38 step 4: objective=1.105777
2017/08/28 16:28:40 step 5: objective=1.1108332
2017/08/28 16:28:41 step 6: objective=1.1174597
2017/08/28 16:28:42 step 7: objective=1.1244248
2017/08/28 16:28:42 Training value function...
2017/08/28 16:28:44 step 0: mse=176.492779 step=0.100000
2017/08/28 16:28:45 step 1: mse=173.862957 step=0.100000
2017/08/28 16:28:46 step 2: mse=171.391857 step=0.100000
2017/08/28 16:28:47 step 3: mse=169.421362 step=0.100000
2017/08/28 16:28:48 step 4: mse=167.466986 step=0.100000
2017/08/28 16:28:49 step 5: mse=165.689171 step=0.100000
2017/08/28 16:28:50 step 6: mse=164.095411 step=0.100000
2017/08/28 16:28:51 step 7: mse=162.520970 step=0.100000
2017/08/28 16:28:51 Saving...
2017/08/28 16:28:51 Gathering batch of experience...
2017/08/28 16:29:35 batch 379: mean=73.218750 stddev=54.180390 entropy=0.459919 frames=4601 count=64
2017/08/28 16:29:35 Training policy...
2017/08/28 16:29:38 step 0: objective=0.97526693
2017/08/28 16:29:40 step 1: objective=0.98567474
2017/08/28 16:29:41 step 2: objective=0.994062
2017/08/28 16:29:42 step 3: objective=1.003646
2017/08/28 16:29:43 step 4: objective=1.0122781
2017/08/28 16:29:44 step 5: objective=1.0186899
2017/08/28 16:29:45 step 6: objective=1.0252593
2017/08/28 16:29:46 step 7: objective=1.0290008
2017/08/28 16:29:46 Training value function...
2017/08/28 16:29:48 step 0: mse=144.526304 step=0.100000
2017/08/28 16:29:49 step 1: mse=140.759909 step=0.100000
2017/08/28 16:29:50 step 2: mse=137.911389 step=0.100000
2017/08/28 16:29:51 step 3: mse=135.250474 step=0.100000
2017/08/28 16:29:52 step 4: mse=133.254754 step=0.100000
2017/08/28 16:29:53 step 5: mse=131.532676 step=0.100000
2017/08/28 16:29:54 step 6: mse=130.034820 step=0.100000
2017/08/28 16:29:55 step 7: mse=128.680514 step=0.100000
2017/08/28 16:29:55 Saving...
2017/08/28 16:29:55 Gathering batch of experience...
2017/08/28 16:30:40 batch 380: mean=85.666667 stddev=75.228467 entropy=0.455968 frames=5017 count=60
2017/08/28 16:30:40 Training policy...
2017/08/28 16:30:43 step 0: objective=1.6363322
2017/08/28 16:30:44 step 1: objective=1.6458607
2017/08/28 16:30:45 step 2: objective=1.6535666
2017/08/28 16:30:47 step 3: objective=1.6620169
2017/08/28 16:30:48 step 4: objective=1.6749271
2017/08/28 16:30:49 step 5: objective=1.6798357
2017/08/28 16:30:50 step 6: objective=1.6833572
2017/08/28 16:30:51 step 7: objective=1.6869069
2017/08/28 16:30:51 Training value function...
2017/08/28 16:30:54 step 0: mse=206.729008 step=0.100000
2017/08/28 16:30:55 step 1: mse=203.083901 step=0.100000
2017/08/28 16:30:56 step 2: mse=200.014236 step=0.100000
2017/08/28 16:30:57 step 3: mse=197.454668 step=0.100000
2017/08/28 16:30:58 step 4: mse=195.144518 step=0.100000
2017/08/28 16:30:59 step 5: mse=192.538790 step=0.100000
2017/08/28 16:31:00 step 6: mse=190.641430 step=0.100000
2017/08/28 16:31:01 step 7: mse=188.912596 step=0.100000
2017/08/28 16:31:01 Saving...
2017/08/28 16:31:01 Gathering batch of experience...
2017/08/28 16:31:45 batch 381: mean=78.725806 stddev=69.685971 entropy=0.453675 frames=4785 count=62
2017/08/28 16:31:45 Training policy...
2017/08/28 16:31:49 step 0: objective=0.6994622
2017/08/28 16:31:50 step 1: objective=0.7187282
2017/08/28 16:31:51 step 2: objective=0.72678053
2017/08/28 16:31:52 step 3: objective=0.73722464
2017/08/28 16:31:53 step 4: objective=0.747781
2017/08/28 16:31:54 step 5: objective=0.75666255
2017/08/28 16:31:56 step 6: objective=0.76271355
2017/08/28 16:31:57 step 7: objective=0.77021044
2017/08/28 16:31:57 Training value function...
2017/08/28 16:31:59 step 0: mse=176.352647 step=0.100000
2017/08/28 16:32:00 step 1: mse=174.008076 step=0.100000
2017/08/28 16:32:01 step 2: mse=172.171078 step=0.100000
2017/08/28 16:32:02 step 3: mse=170.342502 step=0.100000
2017/08/28 16:32:03 step 4: mse=168.641694 step=0.100000
2017/08/28 16:32:04 step 5: mse=167.049909 step=0.100000
2017/08/28 16:32:05 step 6: mse=165.884321 step=0.100000
2017/08/28 16:32:06 step 7: mse=164.647208 step=0.100000
2017/08/28 16:32:06 Saving...
2017/08/28 16:32:06 Gathering batch of experience...
2017/08/28 16:32:53 batch 382: mean=77.548387 stddev=67.420844 entropy=0.458923 frames=4971 count=62
2017/08/28 16:32:53 Training policy...
2017/08/28 16:32:56 step 0: objective=0.4822128
2017/08/28 16:32:57 step 1: objective=0.4903999
2017/08/28 16:32:58 step 2: objective=0.50327283
2017/08/28 16:33:00 step 3: objective=0.5130979
2017/08/28 16:33:01 step 4: objective=0.52042675
2017/08/28 16:33:02 step 5: objective=0.5319384
2017/08/28 16:33:03 step 6: objective=0.53829795
2017/08/28 16:33:04 step 7: objective=0.54355997
2017/08/28 16:33:04 Training value function...
2017/08/28 16:33:06 step 0: mse=161.668853 step=0.100000
2017/08/28 16:33:07 step 1: mse=159.873987 step=0.100000
2017/08/28 16:33:08 step 2: mse=158.232351 step=0.100000
2017/08/28 16:33:10 step 3: mse=156.696054 step=0.100000
2017/08/28 16:33:11 step 4: mse=155.506563 step=0.100000
2017/08/28 16:33:12 step 5: mse=154.025430 step=0.100000
2017/08/28 16:33:13 step 6: mse=152.791315 step=0.100000
2017/08/28 16:33:14 step 7: mse=152.051111 step=0.100000
2017/08/28 16:33:14 Saving...
2017/08/28 16:33:14 Gathering batch of experience...
2017/08/28 16:33:59 batch 383: mean=87.457627 stddev=87.243148 entropy=0.461646 frames=4999 count=59
2017/08/28 16:33:59 Training policy...
2017/08/28 16:34:03 step 0: objective=1.7483274
2017/08/28 16:34:04 step 1: objective=1.7585396
2017/08/28 16:34:05 step 2: objective=1.768376
2017/08/28 16:34:06 step 3: objective=1.7794207
2017/08/28 16:34:07 step 4: objective=1.7882174
2017/08/28 16:34:09 step 5: objective=1.794679
2017/08/28 16:34:10 step 6: objective=1.8047533
2017/08/28 16:34:11 step 7: objective=1.8100361
2017/08/28 16:34:11 Training value function...
2017/08/28 16:34:13 step 0: mse=212.873532 step=0.100000
2017/08/28 16:34:14 step 1: mse=207.974021 step=0.100000
2017/08/28 16:34:15 step 2: mse=204.138876 step=0.100000
2017/08/28 16:34:16 step 3: mse=200.672694 step=0.100000
2017/08/28 16:34:17 step 4: mse=197.823101 step=0.100000
2017/08/28 16:34:18 step 5: mse=195.129287 step=0.100000
2017/08/28 16:34:19 step 6: mse=192.505050 step=0.100000
2017/08/28 16:34:20 step 7: mse=190.032026 step=0.100000
2017/08/28 16:34:20 Saving...
2017/08/28 16:34:20 Gathering batch of experience...
2017/08/28 16:35:08 batch 384: mean=80.934426 stddev=58.591072 entropy=0.454280 frames=5038 count=61
2017/08/28 16:35:08 Training policy...
2017/08/28 16:35:11 step 0: objective=0.4868734
2017/08/28 16:35:12 step 1: objective=0.498016
2017/08/28 16:35:14 step 2: objective=0.51063323
2017/08/28 16:35:15 step 3: objective=0.5226073
2017/08/28 16:35:16 step 4: objective=0.5323451
2017/08/28 16:35:17 step 5: objective=0.53882587
2017/08/28 16:35:18 step 6: objective=0.542744
2017/08/28 16:35:20 step 7: objective=0.5513075
2017/08/28 16:35:20 Training value function...
2017/08/28 16:35:22 step 0: mse=160.748013 step=0.100000
2017/08/28 16:35:23 step 1: mse=158.214169 step=0.100000
2017/08/28 16:35:24 step 2: mse=156.042145 step=0.100000
2017/08/28 16:35:25 step 3: mse=154.028257 step=0.100000
2017/08/28 16:35:26 step 4: mse=152.154095 step=0.100000
2017/08/28 16:35:27 step 5: mse=150.444473 step=0.100000
2017/08/28 16:35:28 step 6: mse=149.099943 step=0.100000
2017/08/28 16:35:29 step 7: mse=147.789270 step=0.100000
2017/08/28 16:35:29 Saving...
2017/08/28 16:35:29 Gathering batch of experience...
2017/08/28 16:36:17 batch 385: mean=74.205882 stddev=58.631842 entropy=0.460675 frames=4782 count=68
2017/08/28 16:36:17 Training policy...
2017/08/28 16:36:20 step 0: objective=1.0154572
2017/08/28 16:36:21 step 1: objective=1.0292315
2017/08/28 16:36:22 step 2: objective=1.04353
2017/08/28 16:36:23 step 3: objective=1.0514022
2017/08/28 16:36:25 step 4: objective=1.0643772
2017/08/28 16:36:26 step 5: objective=1.0713872
2017/08/28 16:36:27 step 6: objective=1.0756632
2017/08/28 16:36:28 step 7: objective=1.0800928
2017/08/28 16:36:28 Training value function...
2017/08/28 16:36:30 step 0: mse=165.994446 step=0.100000
2017/08/28 16:36:31 step 1: mse=164.456687 step=0.100000
2017/08/28 16:36:32 step 2: mse=162.707823 step=0.100000
2017/08/28 16:36:33 step 3: mse=161.205094 step=0.100000
2017/08/28 16:36:34 step 4: mse=160.152747 step=0.100000
2017/08/28 16:36:35 step 5: mse=159.123211 step=0.100000
2017/08/28 16:36:36 step 6: mse=157.740954 step=0.100000
2017/08/28 16:36:37 step 7: mse=156.684817 step=0.100000
2017/08/28 16:36:37 Saving...
2017/08/28 16:36:37 Gathering batch of experience...
2017/08/28 16:37:22 batch 386: mean=74.861538 stddev=66.204085 entropy=0.455938 frames=4827 count=65
2017/08/28 16:37:22 Training policy...
2017/08/28 16:37:25 step 0: objective=0.709735
2017/08/28 16:37:27 step 1: objective=0.7221262
2017/08/28 16:37:28 step 2: objective=0.72814274
2017/08/28 16:37:29 step 3: objective=0.7331967
2017/08/28 16:37:30 step 4: objective=0.73928666
2017/08/28 16:37:31 step 5: objective=0.7464677
2017/08/28 16:37:32 step 6: objective=0.75045043
2017/08/28 16:37:34 step 7: objective=0.75489175
2017/08/28 16:37:34 Training value function...
2017/08/28 16:37:36 step 0: mse=166.018985 step=0.100000
2017/08/28 16:37:37 step 1: mse=164.348982 step=0.100000
2017/08/28 16:37:38 step 2: mse=162.714487 step=0.100000
2017/08/28 16:37:39 step 3: mse=161.349183 step=0.100000
2017/08/28 16:37:40 step 4: mse=159.958257 step=0.100000
2017/08/28 16:37:41 step 5: mse=158.931147 step=0.100000
2017/08/28 16:37:42 step 6: mse=157.742103 step=0.100000
2017/08/28 16:37:43 step 7: mse=156.543496 step=0.100000
2017/08/28 16:37:43 Saving...
2017/08/28 16:37:43 Gathering batch of experience...
2017/08/28 16:38:32 batch 387: mean=79.061538 stddev=71.584028 entropy=0.461025 frames=5230 count=65
2017/08/28 16:38:32 Training policy...
2017/08/28 16:38:35 step 0: objective=1.0227864
2017/08/28 16:38:37 step 1: objective=1.0341165
2017/08/28 16:38:38 step 2: objective=1.0457617
2017/08/28 16:38:39 step 3: objective=1.0532098
2017/08/28 16:38:41 step 4: objective=1.0628248
2017/08/28 16:38:42 step 5: objective=1.0713263
2017/08/28 16:38:43 step 6: objective=1.0786964
2017/08/28 16:38:44 step 7: objective=1.0837082
2017/08/28 16:38:44 Training value function...
2017/08/28 16:38:46 step 0: mse=179.970904 step=0.100000
2017/08/28 16:38:47 step 1: mse=176.919722 step=0.100000
2017/08/28 16:38:49 step 2: mse=174.092270 step=0.100000
2017/08/28 16:38:50 step 3: mse=171.732639 step=0.100000
2017/08/28 16:38:51 step 4: mse=169.908849 step=0.100000
2017/08/28 16:38:52 step 5: mse=168.351979 step=0.100000
2017/08/28 16:38:53 step 6: mse=166.834416 step=0.100000
2017/08/28 16:38:54 step 7: mse=165.059176 step=0.100000
2017/08/28 16:38:54 Saving...
2017/08/28 16:38:54 Gathering batch of experience...
2017/08/28 16:39:35 batch 388: mean=78.267857 stddev=59.631455 entropy=0.453708 frames=4458 count=56
2017/08/28 16:39:35 Training policy...
2017/08/28 16:39:38 step 0: objective=0.8609247
2017/08/28 16:39:40 step 1: objective=0.8741712
2017/08/28 16:39:41 step 2: objective=0.8854618
2017/08/28 16:39:42 step 3: objective=0.8948638
2017/08/28 16:39:43 step 4: objective=0.90590316
2017/08/28 16:39:44 step 5: objective=0.91479427
2017/08/28 16:39:45 step 6: objective=0.92351115
2017/08/28 16:39:46 step 7: objective=0.929293
2017/08/28 16:39:46 Training value function...
2017/08/28 16:39:48 step 0: mse=172.583304 step=0.100000
2017/08/28 16:39:49 step 1: mse=167.360708 step=0.100000
2017/08/28 16:39:50 step 2: mse=163.302037 step=0.100000
2017/08/28 16:39:51 step 3: mse=159.591161 step=0.100000
2017/08/28 16:39:52 step 4: mse=156.686767 step=0.100000
2017/08/28 16:39:53 step 5: mse=154.170464 step=0.100000
2017/08/28 16:39:54 step 6: mse=151.806098 step=0.100000
2017/08/28 16:39:54 step 7: mse=149.874380 step=0.100000
2017/08/28 16:39:54 Saving...
2017/08/28 16:39:54 Gathering batch of experience...
2017/08/28 16:40:46 batch 389: mean=73.414286 stddev=68.723149 entropy=0.453057 frames=5072 count=70
2017/08/28 16:40:46 Training policy...
2017/08/28 16:40:50 step 0: objective=0.95739996
2017/08/28 16:40:51 step 1: objective=0.9701328
2017/08/28 16:40:52 step 2: objective=0.98309076
2017/08/28 16:40:53 step 3: objective=0.99202
2017/08/28 16:40:55 step 4: objective=0.9974982
2017/08/28 16:40:56 step 5: objective=1.0065686
2017/08/28 16:40:57 step 6: objective=1.0157235
2017/08/28 16:40:58 step 7: objective=1.020935
2017/08/28 16:40:58 Training value function...
2017/08/28 16:41:00 step 0: mse=186.768391 step=0.100000
2017/08/28 16:41:01 step 1: mse=184.441655 step=0.100000
2017/08/28 16:41:03 step 2: mse=181.475050 step=0.100000
2017/08/28 16:41:04 step 3: mse=179.566053 step=0.100000
2017/08/28 16:41:05 step 4: mse=177.327628 step=0.100000
2017/08/28 16:41:06 step 5: mse=175.363088 step=0.100000
2017/08/28 16:41:07 step 6: mse=174.179376 step=0.100000
2017/08/28 16:41:08 step 7: mse=172.573601 step=0.100000
2017/08/28 16:41:08 Saving...
2017/08/28 16:41:08 Gathering batch of experience...
2017/08/28 16:41:51 batch 390: mean=74.322581 stddev=60.208984 entropy=0.458492 frames=4636 count=62
2017/08/28 16:41:51 Training policy...
2017/08/28 16:41:54 step 0: objective=0.8472192
2017/08/28 16:41:55 step 1: objective=0.85414946
2017/08/28 16:41:56 step 2: objective=0.8676685
2017/08/28 16:41:58 step 3: objective=0.87459433
2017/08/28 16:41:59 step 4: objective=0.88334346
2017/08/28 16:42:00 step 5: objective=0.8911983
2017/08/28 16:42:01 step 6: objective=0.89718425
2017/08/28 16:42:02 step 7: objective=0.9033281
2017/08/28 16:42:02 Training value function...
2017/08/28 16:42:04 step 0: mse=156.203392 step=0.100000
2017/08/28 16:42:05 step 1: mse=154.428019 step=0.100000
2017/08/28 16:42:06 step 2: mse=153.017368 step=0.100000
2017/08/28 16:42:07 step 3: mse=151.982387 step=0.100000
2017/08/28 16:42:08 step 4: mse=150.586564 step=0.100000
2017/08/28 16:42:09 step 5: mse=149.127923 step=0.100000
2017/08/28 16:42:10 step 6: mse=148.176472 step=0.100000
2017/08/28 16:42:11 step 7: mse=146.983523 step=0.100000
2017/08/28 16:42:11 Saving...
2017/08/28 16:42:11 Gathering batch of experience...
2017/08/28 16:42:56 batch 391: mean=95.410714 stddev=83.759813 entropy=0.467136 frames=4934 count=56
2017/08/28 16:42:56 Training policy...
2017/08/28 16:42:59 step 0: objective=2.5361462
2017/08/28 16:43:00 step 1: objective=2.5453572
2017/08/28 16:43:02 step 2: objective=2.5548186
2017/08/28 16:43:03 step 3: objective=2.5637302
2017/08/28 16:43:04 step 4: objective=2.5770593
2017/08/28 16:43:05 step 5: objective=2.5856032
2017/08/28 16:43:06 step 6: objective=2.5925107
2017/08/28 16:43:08 step 7: objective=2.5963657
2017/08/28 16:43:08 Training value function...
2017/08/28 16:43:10 step 0: mse=227.890101 step=0.100000
2017/08/28 16:43:11 step 1: mse=221.700805 step=0.100000
2017/08/28 16:43:12 step 2: mse=216.273990 step=0.100000
2017/08/28 16:43:13 step 3: mse=211.071055 step=0.100000
2017/08/28 16:43:14 step 4: mse=207.042905 step=0.100000
2017/08/28 16:43:15 step 5: mse=203.524938 step=0.100000
2017/08/28 16:43:16 step 6: mse=200.100288 step=0.100000
2017/08/28 16:43:17 step 7: mse=197.026848 step=0.100000
2017/08/28 16:43:17 Saving...
2017/08/28 16:43:17 Gathering batch of experience...
2017/08/28 16:44:06 batch 392: mean=75.562500 stddev=69.091397 entropy=0.456302 frames=4911 count=64
2017/08/28 16:44:06 Training policy...
2017/08/28 16:44:09 step 0: objective=0.15623008
2017/08/28 16:44:10 step 1: objective=0.17260371
2017/08/28 16:44:11 step 2: objective=0.18497764
2017/08/28 16:44:13 step 3: objective=0.19841343
2017/08/28 16:44:14 step 4: objective=0.20643325
2017/08/28 16:44:15 step 5: objective=0.21234906
2017/08/28 16:44:16 step 6: objective=0.21920052
2017/08/28 16:44:17 step 7: objective=0.22454527
2017/08/28 16:44:17 Training value function...
2017/08/28 16:44:19 step 0: mse=166.479732 step=0.100000
2017/08/28 16:44:20 step 1: mse=165.007928 step=0.100000
2017/08/28 16:44:21 step 2: mse=163.600877 step=0.100000
2017/08/28 16:44:22 step 3: mse=162.393648 step=0.100000
2017/08/28 16:44:23 step 4: mse=161.427178 step=0.100000
2017/08/28 16:44:24 step 5: mse=160.378894 step=0.100000
2017/08/28 16:44:25 step 6: mse=159.358590 step=0.100000
2017/08/28 16:44:26 step 7: mse=158.864535 step=0.100000
2017/08/28 16:44:26 Saving...
2017/08/28 16:44:27 Gathering batch of experience...
2017/08/28 16:45:09 batch 393: mean=89.888889 stddev=83.241876 entropy=0.460329 frames=4820 count=54
2017/08/28 16:45:09 Training policy...
2017/08/28 16:45:13 step 0: objective=1.2279922
2017/08/28 16:45:14 step 1: objective=1.2362189
2017/08/28 16:45:15 step 2: objective=1.2453247
2017/08/28 16:45:16 step 3: objective=1.2515546
2017/08/28 16:45:17 step 4: objective=1.2574648
2017/08/28 16:45:18 step 5: objective=1.264109
2017/08/28 16:45:20 step 6: objective=1.268913
2017/08/28 16:45:21 step 7: objective=1.2724184
2017/08/28 16:45:21 Training value function...
2017/08/28 16:45:23 step 0: mse=187.237352 step=0.100000
2017/08/28 16:45:24 step 1: mse=184.183361 step=0.100000
2017/08/28 16:45:25 step 2: mse=181.091251 step=0.100000
2017/08/28 16:45:26 step 3: mse=178.480234 step=0.100000
2017/08/28 16:45:27 step 4: mse=176.184873 step=0.100000
2017/08/28 16:45:28 step 5: mse=174.669628 step=0.100000
2017/08/28 16:45:29 step 6: mse=172.705315 step=0.100000
2017/08/28 16:45:30 step 7: mse=170.918198 step=0.100000
2017/08/28 16:45:30 Saving...
2017/08/28 16:45:30 Gathering batch of experience...
2017/08/28 16:46:16 batch 394: mean=83.350000 stddev=75.888257 entropy=0.450383 frames=4762 count=60
2017/08/28 16:46:16 Training policy...
2017/08/28 16:46:19 step 0: objective=1.1970606
2017/08/28 16:46:21 step 1: objective=1.2031842
2017/08/28 16:46:22 step 2: objective=1.2141938
2017/08/28 16:46:23 step 3: objective=1.2209687
2017/08/28 16:46:24 step 4: objective=1.2279491
2017/08/28 16:46:25 step 5: objective=1.234257
2017/08/28 16:46:26 step 6: objective=1.2442266
2017/08/28 16:46:27 step 7: objective=1.2479974
2017/08/28 16:46:27 Training value function...
2017/08/28 16:46:29 step 0: mse=190.315827 step=0.100000
2017/08/28 16:46:30 step 1: mse=187.827661 step=0.100000
2017/08/28 16:46:31 step 2: mse=185.618365 step=0.100000
2017/08/28 16:46:32 step 3: mse=183.615772 step=0.100000
2017/08/28 16:46:33 step 4: mse=181.815610 step=0.100000
2017/08/28 16:46:34 step 5: mse=180.018116 step=0.100000
2017/08/28 16:46:35 step 6: mse=178.566213 step=0.100000
2017/08/28 16:46:36 step 7: mse=177.544644 step=0.100000
2017/08/28 16:46:36 Saving...
2017/08/28 16:46:36 Gathering batch of experience...
2017/08/28 16:47:22 batch 395: mean=84.824561 stddev=87.297660 entropy=0.454933 frames=4992 count=57
2017/08/28 16:47:22 Training policy...
2017/08/28 16:47:25 step 0: objective=0.67281723
2017/08/28 16:47:27 step 1: objective=0.68502474
2017/08/28 16:47:28 step 2: objective=0.6962273
2017/08/28 16:47:29 step 3: objective=0.7043239
2017/08/28 16:47:30 step 4: objective=0.71077204
2017/08/28 16:47:31 step 5: objective=0.71896935
2017/08/28 16:47:33 step 6: objective=0.728723
2017/08/28 16:47:34 step 7: objective=0.7363001
2017/08/28 16:47:34 Training value function...
2017/08/28 16:47:36 step 0: mse=165.291182 step=0.100000
2017/08/28 16:47:37 step 1: mse=162.483555 step=0.100000
2017/08/28 16:47:38 step 2: mse=160.348700 step=0.100000
2017/08/28 16:47:39 step 3: mse=158.087388 step=0.100000
2017/08/28 16:47:40 step 4: mse=156.215612 step=0.100000
2017/08/28 16:47:41 step 5: mse=154.391799 step=0.100000
2017/08/28 16:47:42 step 6: mse=152.872623 step=0.100000
2017/08/28 16:47:43 step 7: mse=151.388277 step=0.100000
2017/08/28 16:47:43 Saving...
2017/08/28 16:47:43 Gathering batch of experience...
2017/08/28 16:48:29 batch 396: mean=80.213115 stddev=67.635987 entropy=0.452555 frames=5053 count=61
2017/08/28 16:48:29 Training policy...
2017/08/28 16:48:33 step 0: objective=0.43396685
2017/08/28 16:48:34 step 1: objective=0.43976253
2017/08/28 16:48:35 step 2: objective=0.44504797
2017/08/28 16:48:36 step 3: objective=0.45106292
2017/08/28 16:48:38 step 4: objective=0.45914018
2017/08/28 16:48:39 step 5: objective=0.4694602
2017/08/28 16:48:40 step 6: objective=0.4763466
2017/08/28 16:48:41 step 7: objective=0.48154896
2017/08/28 16:48:41 Training value function...
2017/08/28 16:48:43 step 0: mse=147.829015 step=0.100000
2017/08/28 16:48:44 step 1: mse=145.988532 step=0.100000
2017/08/28 16:48:46 step 2: mse=144.229200 step=0.100000
2017/08/28 16:48:47 step 3: mse=142.816210 step=0.100000
2017/08/28 16:48:48 step 4: mse=141.462751 step=0.100000
2017/08/28 16:48:49 step 5: mse=140.324041 step=0.100000
2017/08/28 16:48:50 step 6: mse=139.388634 step=0.100000
2017/08/28 16:48:51 step 7: mse=138.381358 step=0.100000
2017/08/28 16:48:51 Saving...
2017/08/28 16:48:51 Gathering batch of experience...
2017/08/28 16:49:33 batch 397: mean=89.981132 stddev=72.681131 entropy=0.449890 frames=4909 count=53
2017/08/28 16:49:33 Training policy...
2017/08/28 16:49:36 step 0: objective=1.134082
2017/08/28 16:49:38 step 1: objective=1.142099
2017/08/28 16:49:39 step 2: objective=1.1494746
2017/08/28 16:49:40 step 3: objective=1.1548281
2017/08/28 16:49:41 step 4: objective=1.1613048
2017/08/28 16:49:42 step 5: objective=1.1655434
2017/08/28 16:49:44 step 6: objective=1.169581
2017/08/28 16:49:45 step 7: objective=1.1759709
2017/08/28 16:49:45 Training value function...
2017/08/28 16:49:47 step 0: mse=154.260870 step=0.100000
2017/08/28 16:49:48 step 1: mse=152.595388 step=0.100000
2017/08/28 16:49:49 step 2: mse=150.967596 step=0.100000
2017/08/28 16:49:50 step 3: mse=149.524994 step=0.100000
2017/08/28 16:49:51 step 4: mse=147.937924 step=0.100000
2017/08/28 16:49:52 step 5: mse=146.860387 step=0.100000
2017/08/28 16:49:53 step 6: mse=145.920906 step=0.100000
2017/08/28 16:49:54 step 7: mse=144.957891 step=0.100000
2017/08/28 16:49:54 Saving...
2017/08/28 16:49:54 Gathering batch of experience...
2017/08/28 16:50:39 batch 398: mean=88.901639 stddev=78.045112 entropy=0.441894 frames=5017 count=61
2017/08/28 16:50:39 Training policy...
2017/08/28 16:50:43 step 0: objective=1.842799
2017/08/28 16:50:44 step 1: objective=1.8488823
2017/08/28 16:50:45 step 2: objective=1.8582821
2017/08/28 16:50:46 step 3: objective=1.8659079
2017/08/28 16:50:48 step 4: objective=1.8746539
2017/08/28 16:50:49 step 5: objective=1.8798007
2017/08/28 16:50:50 step 6: objective=1.8839709
2017/08/28 16:50:51 step 7: objective=1.889227
2017/08/28 16:50:51 Training value function...
2017/08/28 16:50:53 step 0: mse=185.415317 step=0.100000
2017/08/28 16:50:54 step 1: mse=181.381764 step=0.100000
2017/08/28 16:50:55 step 2: mse=177.549846 step=0.100000
2017/08/28 16:50:56 step 3: mse=174.604201 step=0.100000
2017/08/28 16:50:57 step 4: mse=171.881840 step=0.100000
2017/08/28 16:50:59 step 5: mse=169.616751 step=0.100000
2017/08/28 16:51:00 step 6: mse=167.433566 step=0.100000
2017/08/28 16:51:01 step 7: mse=165.598124 step=0.100000
2017/08/28 16:51:01 Saving...
2017/08/28 16:51:01 Gathering batch of experience...
2017/08/28 16:51:46 batch 399: mean=87.775862 stddev=74.494629 entropy=0.450014 frames=5104 count=58
2017/08/28 16:51:46 Training policy...
2017/08/28 16:51:49 step 0: objective=0.55904037
2017/08/28 16:51:50 step 1: objective=0.5677717
2017/08/28 16:51:52 step 2: objective=0.5794677
2017/08/28 16:51:53 step 3: objective=0.5925483
2017/08/28 16:51:54 step 4: objective=0.59862494
2017/08/28 16:51:55 step 5: objective=0.60349476
2017/08/28 16:51:56 step 6: objective=0.6071748
2017/08/28 16:51:58 step 7: objective=0.61189234
2017/08/28 16:51:58 Training value function...
2017/08/28 16:52:00 step 0: mse=157.800606 step=0.100000
2017/08/28 16:52:01 step 1: mse=156.506276 step=0.100000
2017/08/28 16:52:02 step 2: mse=155.307417 step=0.100000
2017/08/28 16:52:03 step 3: mse=154.066018 step=0.100000
2017/08/28 16:52:04 step 4: mse=153.028892 step=0.100000
2017/08/28 16:52:05 step 5: mse=152.112580 step=0.100000
2017/08/28 16:52:06 step 6: mse=151.085566 step=0.100000
2017/08/28 16:52:07 step 7: mse=150.120799 step=0.100000
2017/08/28 16:52:07 Saving...
2017/08/28 16:52:07 Gathering batch of experience...
2017/08/28 16:52:53 batch 400: mean=76.781250 stddev=74.893355 entropy=0.444142 frames=4695 count=64
2017/08/28 16:52:53 Training policy...
2017/08/28 16:52:56 step 0: objective=0.6989698
2017/08/28 16:52:57 step 1: objective=0.7113958
2017/08/28 16:52:58 step 2: objective=0.7219675
2017/08/28 16:52:59 step 3: objective=0.73038435
2017/08/28 16:53:01 step 4: objective=0.7420838
2017/08/28 16:53:02 step 5: objective=0.746706
2017/08/28 16:53:03 step 6: objective=0.75423944
2017/08/28 16:53:04 step 7: objective=0.7624308
2017/08/28 16:53:04 Training value function...
2017/08/28 16:53:06 step 0: mse=183.509165 step=0.100000
2017/08/28 16:53:07 step 1: mse=178.871764 step=0.100000
2017/08/28 16:53:08 step 2: mse=175.597886 step=0.100000
2017/08/28 16:53:09 step 3: mse=172.517874 step=0.100000
2017/08/28 16:53:10 step 4: mse=170.058403 step=0.100000
2017/08/28 16:53:11 step 5: mse=168.230094 step=0.100000
2017/08/28 16:53:12 step 6: mse=166.515265 step=0.100000
2017/08/28 16:53:13 step 7: mse=165.118571 step=0.100000
2017/08/28 16:53:13 Saving...
2017/08/28 16:53:13 Gathering batch of experience...
2017/08/28 16:53:57 batch 401: mean=78.483871 stddev=63.909649 entropy=0.446694 frames=4751 count=62
2017/08/28 16:53:57 Training policy...
2017/08/28 16:54:00 step 0: objective=0.847378
2017/08/28 16:54:01 step 1: objective=0.854984
2017/08/28 16:54:02 step 2: objective=0.8629601
2017/08/28 16:54:03 step 3: objective=0.8718965
2017/08/28 16:54:05 step 4: objective=0.87893873
2017/08/28 16:54:06 step 5: objective=0.8839114
2017/08/28 16:54:07 step 6: objective=0.8921885
2017/08/28 16:54:08 step 7: objective=0.8974289
2017/08/28 16:54:08 Training value function...
2017/08/28 16:54:10 step 0: mse=182.122410 step=0.100000
2017/08/28 16:54:11 step 1: mse=179.484956 step=0.100000
2017/08/28 16:54:12 step 2: mse=177.083099 step=0.100000
2017/08/28 16:54:13 step 3: mse=175.158111 step=0.100000
2017/08/28 16:54:14 step 4: mse=173.212647 step=0.100000
2017/08/28 16:54:15 step 5: mse=171.513508 step=0.100000
2017/08/28 16:54:16 step 6: mse=170.064658 step=0.100000
2017/08/28 16:54:17 step 7: mse=168.839243 step=0.100000
2017/08/28 16:54:17 Saving...
2017/08/28 16:54:17 Gathering batch of experience...
2017/08/28 16:55:03 batch 402: mean=87.086207 stddev=78.506816 entropy=0.445650 frames=4954 count=58
2017/08/28 16:55:03 Training policy...
2017/08/28 16:55:06 step 0: objective=1.2629933
2017/08/28 16:55:07 step 1: objective=1.270955
2017/08/28 16:55:09 step 2: objective=1.2801437
2017/08/28 16:55:10 step 3: objective=1.2869809
2017/08/28 16:55:11 step 4: objective=1.2949668
2017/08/28 16:55:12 step 5: objective=1.3017572
2017/08/28 16:55:13 step 6: objective=1.3079895
2017/08/28 16:55:15 step 7: objective=1.3151016
2017/08/28 16:55:15 Training value function...
2017/08/28 16:55:17 step 0: mse=175.533069 step=0.100000
2017/08/28 16:55:18 step 1: mse=173.540045 step=0.100000
2017/08/28 16:55:19 step 2: mse=172.102960 step=0.100000
2017/08/28 16:55:20 step 3: mse=170.530935 step=0.100000
2017/08/28 16:55:21 step 4: mse=169.265822 step=0.100000
2017/08/28 16:55:22 step 5: mse=168.050106 step=0.100000
2017/08/28 16:55:23 step 6: mse=166.761777 step=0.100000
2017/08/28 16:55:24 step 7: mse=165.422123 step=0.100000
2017/08/28 16:55:24 Saving...
2017/08/28 16:55:24 Gathering batch of experience...
2017/08/28 16:56:09 batch 403: mean=87.474576 stddev=86.352324 entropy=0.449681 frames=4835 count=59
2017/08/28 16:56:09 Training policy...
2017/08/28 16:56:12 step 0: objective=1.8400468
2017/08/28 16:56:14 step 1: objective=1.8564467
2017/08/28 16:56:15 step 2: objective=1.8680786
2017/08/28 16:56:16 step 3: objective=1.8767608
2017/08/28 16:56:17 step 4: objective=1.890794
2017/08/28 16:56:18 step 5: objective=1.8948605
2017/08/28 16:56:20 step 6: objective=1.8998257
2017/08/28 16:56:21 step 7: objective=1.9039882
2017/08/28 16:56:21 Training value function...
2017/08/28 16:56:23 step 0: mse=210.685828 step=0.100000
2017/08/28 16:56:24 step 1: mse=205.149574 step=0.100000
2017/08/28 16:56:25 step 2: mse=200.012579 step=0.100000
2017/08/28 16:56:26 step 3: mse=195.722575 step=0.100000
2017/08/28 16:56:27 step 4: mse=192.704787 step=0.100000
2017/08/28 16:56:28 step 5: mse=189.395174 step=0.100000
2017/08/28 16:56:29 step 6: mse=186.951046 step=0.100000
2017/08/28 16:56:30 step 7: mse=184.344525 step=0.100000
2017/08/28 16:56:30 Saving...
2017/08/28 16:56:30 Gathering batch of experience...
2017/08/28 16:57:15 batch 404: mean=79.459016 stddev=70.700378 entropy=0.459192 frames=4947 count=61
2017/08/28 16:57:15 Training policy...
2017/08/28 16:57:18 step 0: objective=-0.022084093
2017/08/28 16:57:20 step 1: objective=-0.0131506855
2017/08/28 16:57:21 step 2: objective=-0.0030033442
2017/08/28 16:57:22 step 3: objective=0.0069857156
2017/08/28 16:57:23 step 4: objective=0.015801841
2017/08/28 16:57:24 step 5: objective=0.020556936
2017/08/28 16:57:26 step 6: objective=0.027294485
2017/08/28 16:57:27 step 7: objective=0.036505543
2017/08/28 16:57:27 Training value function...
2017/08/28 16:57:29 step 0: mse=169.756272 step=0.100000
2017/08/28 16:57:30 step 1: mse=167.364293 step=0.100000
2017/08/28 16:57:31 step 2: mse=165.230510 step=0.100000
2017/08/28 16:57:32 step 3: mse=163.423215 step=0.100000
2017/08/28 16:57:33 step 4: mse=161.863995 step=0.100000
2017/08/28 16:57:34 step 5: mse=160.912835 step=0.100000
2017/08/28 16:57:35 step 6: mse=159.736706 step=0.100000
2017/08/28 16:57:36 step 7: mse=158.481833 step=0.100000
2017/08/28 16:57:36 Saving...
2017/08/28 16:57:36 Gathering batch of experience...
2017/08/28 16:58:26 batch 405: mean=78.076923 stddev=65.185253 entropy=0.442327 frames=4955 count=65
2017/08/28 16:58:26 Training policy...
2017/08/28 16:58:29 step 0: objective=0.7778275
2017/08/28 16:58:30 step 1: objective=0.78750354
2017/08/28 16:58:31 step 2: objective=0.8001527
2017/08/28 16:58:33 step 3: objective=0.80624986
2017/08/28 16:58:34 step 4: objective=0.8168629
2017/08/28 16:58:35 step 5: objective=0.82210237
2017/08/28 16:58:36 step 6: objective=0.8278683
2017/08/28 16:58:37 step 7: objective=0.83308595
2017/08/28 16:58:37 Training value function...
2017/08/28 16:58:39 step 0: mse=167.773624 step=0.100000
2017/08/28 16:58:40 step 1: mse=165.375855 step=0.100000
2017/08/28 16:58:42 step 2: mse=163.604467 step=0.100000
2017/08/28 16:58:43 step 3: mse=161.906786 step=0.100000
2017/08/28 16:58:44 step 4: mse=160.542272 step=0.100000
2017/08/28 16:58:45 step 5: mse=159.541612 step=0.100000
2017/08/28 16:58:46 step 6: mse=158.023508 step=0.100000
2017/08/28 16:58:47 step 7: mse=156.731688 step=0.100000
2017/08/28 16:58:47 Saving...
2017/08/28 16:58:47 Gathering batch of experience...
2017/08/28 16:59:30 batch 406: mean=82.071429 stddev=93.949998 entropy=0.450963 frames=4665 count=56
2017/08/28 16:59:30 Training policy...
2017/08/28 16:59:33 step 0: objective=0.86847436
2017/08/28 16:59:34 step 1: objective=0.8792461
2017/08/28 16:59:35 step 2: objective=0.887213
2017/08/28 16:59:36 step 3: objective=0.89455605
2017/08/28 16:59:38 step 4: objective=0.8998749
2017/08/28 16:59:39 step 5: objective=0.9085088
2017/08/28 16:59:40 step 6: objective=0.91539663
2017/08/28 16:59:41 step 7: objective=0.91880244
2017/08/28 16:59:41 Training value function...
2017/08/28 16:59:43 step 0: mse=214.603843 step=0.100000
2017/08/28 16:59:44 step 1: mse=206.330538 step=0.100000
2017/08/28 16:59:45 step 2: mse=200.042821 step=0.100000
2017/08/28 16:59:46 step 3: mse=194.619608 step=0.100000
2017/08/28 16:59:47 step 4: mse=189.499157 step=0.100000
2017/08/28 16:59:48 step 5: mse=185.345692 step=0.100000
2017/08/28 16:59:49 step 6: mse=181.315813 step=0.100000
2017/08/28 16:59:50 step 7: mse=178.022140 step=0.100000
2017/08/28 16:59:50 Saving...
2017/08/28 16:59:50 Gathering batch of experience...
2017/08/28 17:00:36 batch 407: mean=75.555556 stddev=73.670389 entropy=0.448229 frames=4594 count=63
2017/08/28 17:00:36 Training policy...
2017/08/28 17:00:39 step 0: objective=1.1732421
2017/08/28 17:00:40 step 1: objective=1.1826566
2017/08/28 17:00:41 step 2: objective=1.1912522
2017/08/28 17:00:42 step 3: objective=1.2036633
2017/08/28 17:00:44 step 4: objective=1.2141438
2017/08/28 17:00:45 step 5: objective=1.2205552
2017/08/28 17:00:46 step 6: objective=1.2253987
2017/08/28 17:00:47 step 7: objective=1.2310705
2017/08/28 17:00:47 Training value function...
2017/08/28 17:00:49 step 0: mse=203.956493 step=0.100000
2017/08/28 17:00:50 step 1: mse=201.268529 step=0.100000
2017/08/28 17:00:51 step 2: mse=199.000595 step=0.100000
2017/08/28 17:00:52 step 3: mse=196.381627 step=0.100000
2017/08/28 17:00:53 step 4: mse=194.023664 step=0.100000
2017/08/28 17:00:54 step 5: mse=191.624762 step=0.100000
2017/08/28 17:00:54 step 6: mse=189.507200 step=0.100000
2017/08/28 17:00:55 step 7: mse=187.560263 step=0.100000
2017/08/28 17:00:55 Saving...
2017/08/28 17:00:55 Gathering batch of experience...
2017/08/28 17:01:47 batch 408: mean=85.477612 stddev=83.911887 entropy=0.448317 frames=5513 count=67
2017/08/28 17:01:47 Training policy...
2017/08/28 17:01:51 step 0: objective=1.3493961
2017/08/28 17:01:52 step 1: objective=1.3559158
2017/08/28 17:01:54 step 2: objective=1.3639513
2017/08/28 17:01:55 step 3: objective=1.3715801
2017/08/28 17:01:56 step 4: objective=1.3770682
2017/08/28 17:01:58 step 5: objective=1.3862537
2017/08/28 17:01:59 step 6: objective=1.3916211
2017/08/28 17:02:00 step 7: objective=1.3963537
2017/08/28 17:02:00 Training value function...
2017/08/28 17:02:03 step 0: mse=191.533402 step=0.100000
2017/08/28 17:02:04 step 1: mse=188.019036 step=0.100000
2017/08/28 17:02:05 step 2: mse=184.738781 step=0.100000
2017/08/28 17:02:06 step 3: mse=182.224587 step=0.100000
2017/08/28 17:02:07 step 4: mse=180.133449 step=0.100000
2017/08/28 17:02:08 step 5: mse=177.849633 step=0.100000
2017/08/28 17:02:10 step 6: mse=175.831142 step=0.100000
2017/08/28 17:02:11 step 7: mse=174.036729 step=0.100000
2017/08/28 17:02:11 Saving...
2017/08/28 17:02:11 Gathering batch of experience...
2017/08/28 17:02:59 batch 409: mean=73.562500 stddev=64.547917 entropy=0.451063 frames=4932 count=64
2017/08/28 17:02:59 Training policy...
2017/08/28 17:03:02 step 0: objective=0.12938364
2017/08/28 17:03:03 step 1: objective=0.143764
2017/08/28 17:03:05 step 2: objective=0.1579347
2017/08/28 17:03:06 step 3: objective=0.16452213
2017/08/28 17:03:07 step 4: objective=0.17184575
2017/08/28 17:03:08 step 5: objective=0.17798355
2017/08/28 17:03:09 step 6: objective=0.18374301
2017/08/28 17:03:11 step 7: objective=0.1879703
2017/08/28 17:03:11 Training value function...
2017/08/28 17:03:13 step 0: mse=160.182261 step=0.100000
2017/08/28 17:03:14 step 1: mse=157.583315 step=0.100000
2017/08/28 17:03:15 step 2: mse=155.060560 step=0.100000
2017/08/28 17:03:16 step 3: mse=153.334507 step=0.100000
2017/08/28 17:03:17 step 4: mse=151.805753 step=0.100000
2017/08/28 17:03:18 step 5: mse=150.647570 step=0.100000
2017/08/28 17:03:19 step 6: mse=149.498540 step=0.100000
2017/08/28 17:03:20 step 7: mse=148.108708 step=0.100000
2017/08/28 17:03:20 Saving...
2017/08/28 17:03:20 Gathering batch of experience...
2017/08/28 17:04:05 batch 410: mean=77.634921 stddev=69.823428 entropy=0.439565 frames=4714 count=63
2017/08/28 17:04:05 Training policy...
2017/08/28 17:04:08 step 0: objective=1.51161
2017/08/28 17:04:09 step 1: objective=1.5198507
2017/08/28 17:04:10 step 2: objective=1.5286514
2017/08/28 17:04:12 step 3: objective=1.5360764
2017/08/28 17:04:13 step 4: objective=1.547641
2017/08/28 17:04:14 step 5: objective=1.552354
2017/08/28 17:04:15 step 6: objective=1.5605041
2017/08/28 17:04:16 step 7: objective=1.5701737
2017/08/28 17:04:16 Training value function...
2017/08/28 17:04:18 step 0: mse=185.745741 step=0.100000
2017/08/28 17:04:19 step 1: mse=183.274401 step=0.100000
2017/08/28 17:04:20 step 2: mse=181.306774 step=0.100000
2017/08/28 17:04:21 step 3: mse=179.273888 step=0.100000
2017/08/28 17:04:22 step 4: mse=177.500707 step=0.100000
2017/08/28 17:04:23 step 5: mse=175.331992 step=0.100000
2017/08/28 17:04:24 step 6: mse=173.538926 step=0.100000
2017/08/28 17:04:25 step 7: mse=171.661840 step=0.100000
2017/08/28 17:04:25 Saving...
2017/08/28 17:04:25 Gathering batch of experience...
2017/08/28 17:05:13 batch 411: mean=92.054545 stddev=85.198894 entropy=0.448840 frames=4875 count=55
2017/08/28 17:05:13 Training policy...
2017/08/28 17:05:16 step 0: objective=1.590579
2017/08/28 17:05:17 step 1: objective=1.5979142
2017/08/28 17:05:19 step 2: objective=1.6056088
2017/08/28 17:05:20 step 3: objective=1.612045
2017/08/28 17:05:21 step 4: objective=1.6195736
2017/08/28 17:05:22 step 5: objective=1.6258684
2017/08/28 17:05:23 step 6: objective=1.6351779
2017/08/28 17:05:25 step 7: objective=1.6398484
2017/08/28 17:05:25 Training value function...
2017/08/28 17:05:27 step 0: mse=198.443001 step=0.100000
2017/08/28 17:05:28 step 1: mse=194.111509 step=0.100000
2017/08/28 17:05:29 step 2: mse=190.316894 step=0.100000
2017/08/28 17:05:30 step 3: mse=187.506506 step=0.100000
2017/08/28 17:05:31 step 4: mse=184.616830 step=0.100000
2017/08/28 17:05:32 step 5: mse=182.121035 step=0.100000
2017/08/28 17:05:33 step 6: mse=180.299541 step=0.100000
2017/08/28 17:05:34 step 7: mse=178.721391 step=0.100000
2017/08/28 17:05:34 Saving...
2017/08/28 17:05:34 Gathering batch of experience...
2017/08/28 17:06:22 batch 412: mean=96.473684 stddev=95.935122 entropy=0.451250 frames=5481 count=57
2017/08/28 17:06:22 Training policy...
2017/08/28 17:06:25 step 0: objective=1.1191326
2017/08/28 17:06:27 step 1: objective=1.1281371
2017/08/28 17:06:28 step 2: objective=1.1342448
2017/08/28 17:06:29 step 3: objective=1.1380396
2017/08/28 17:06:31 step 4: objective=1.1467294
2017/08/28 17:06:32 step 5: objective=1.1556469
2017/08/28 17:06:34 step 6: objective=1.1590452
2017/08/28 17:06:35 step 7: objective=1.1652187
2017/08/28 17:06:35 Training value function...
2017/08/28 17:06:37 step 0: mse=160.748769 step=0.100000
2017/08/28 17:06:38 step 1: mse=158.240377 step=0.100000
2017/08/28 17:06:39 step 2: mse=156.252071 step=0.100000
2017/08/28 17:06:41 step 3: mse=154.329221 step=0.100000
2017/08/28 17:06:42 step 4: mse=152.756931 step=0.100000
2017/08/28 17:06:43 step 5: mse=151.298443 step=0.100000
2017/08/28 17:06:44 step 6: mse=150.049688 step=0.100000
2017/08/28 17:06:45 step 7: mse=148.996560 step=0.100000
2017/08/28 17:06:45 Saving...
2017/08/28 17:06:45 Gathering batch of experience...
2017/08/28 17:07:28 batch 413: mean=85.157895 stddev=71.973628 entropy=0.445271 frames=4631 count=57
2017/08/28 17:07:28 Training policy...
2017/08/28 17:07:31 step 0: objective=0.9345315
2017/08/28 17:07:32 step 1: objective=0.9439512
2017/08/28 17:07:33 step 2: objective=0.95173323
2017/08/28 17:07:35 step 3: objective=0.96308917
2017/08/28 17:07:36 step 4: objective=0.97202617
2017/08/28 17:07:37 step 5: objective=0.98296785
2017/08/28 17:07:38 step 6: objective=0.98912716
2017/08/28 17:07:39 step 7: objective=0.9946308
2017/08/28 17:07:39 Training value function...
2017/08/28 17:07:41 step 0: mse=155.872735 step=0.100000
2017/08/28 17:07:42 step 1: mse=154.082011 step=0.100000
2017/08/28 17:07:43 step 2: mse=152.604075 step=0.100000
2017/08/28 17:07:44 step 3: mse=151.331721 step=0.100000
2017/08/28 17:07:45 step 4: mse=150.195983 step=0.100000
2017/08/28 17:07:46 step 5: mse=149.353355 step=0.100000
2017/08/28 17:07:47 step 6: mse=148.541028 step=0.100000
2017/08/28 17:07:48 step 7: mse=147.789608 step=0.100000
2017/08/28 17:07:48 Saving...
2017/08/28 17:07:48 Gathering batch of experience...
2017/08/28 17:08:36 batch 414: mean=81.000000 stddev=67.705244 entropy=0.447180 frames=5000 count=64
2017/08/28 17:08:36 Training policy...
2017/08/28 17:08:39 step 0: objective=0.7815566
2017/08/28 17:08:40 step 1: objective=0.79074043
2017/08/28 17:08:42 step 2: objective=0.8059378
2017/08/28 17:08:43 step 3: objective=0.8141773
2017/08/28 17:08:44 step 4: objective=0.8233746
2017/08/28 17:08:45 step 5: objective=0.8323917
2017/08/28 17:08:46 step 6: objective=0.8367149
2017/08/28 17:08:48 step 7: objective=0.8452658
2017/08/28 17:08:48 Training value function...
2017/08/28 17:08:50 step 0: mse=174.761919 step=0.100000
2017/08/28 17:08:51 step 1: mse=172.914862 step=0.100000
2017/08/28 17:08:52 step 2: mse=171.350587 step=0.100000
2017/08/28 17:08:53 step 3: mse=169.787884 step=0.100000
2017/08/28 17:08:54 step 4: mse=168.392033 step=0.100000
2017/08/28 17:08:55 step 5: mse=167.198912 step=0.100000
2017/08/28 17:08:56 step 6: mse=166.009302 step=0.100000
2017/08/28 17:08:57 step 7: mse=164.603782 step=0.100000
2017/08/28 17:08:57 Saving...
2017/08/28 17:08:57 Gathering batch of experience...
2017/08/28 17:09:42 batch 415: mean=82.147541 stddev=77.011567 entropy=0.441473 frames=4909 count=61
2017/08/28 17:09:42 Training policy...
2017/08/28 17:09:46 step 0: objective=0.89031285
2017/08/28 17:09:47 step 1: objective=0.89904696
2017/08/28 17:09:48 step 2: objective=0.9106636
2017/08/28 17:09:49 step 3: objective=0.9168565
2017/08/28 17:09:51 step 4: objective=0.92344457
2017/08/28 17:09:52 step 5: objective=0.93048024
2017/08/28 17:09:53 step 6: objective=0.93563926
2017/08/28 17:09:54 step 7: objective=0.94086254
2017/08/28 17:09:54 Training value function...
2017/08/28 17:09:56 step 0: mse=161.931594 step=0.100000
2017/08/28 17:09:57 step 1: mse=158.902355 step=0.100000
2017/08/28 17:09:58 step 2: mse=156.926949 step=0.100000
2017/08/28 17:09:59 step 3: mse=154.735123 step=0.100000
2017/08/28 17:10:00 step 4: mse=153.395441 step=0.100000
2017/08/28 17:10:01 step 5: mse=151.999634 step=0.100000
2017/08/28 17:10:02 step 6: mse=150.720102 step=0.100000
2017/08/28 17:10:03 step 7: mse=149.356820 step=0.100000
2017/08/28 17:10:03 Saving...
2017/08/28 17:10:04 Gathering batch of experience...
2017/08/28 17:10:51 batch 416: mean=93.192982 stddev=86.879921 entropy=0.451021 frames=5218 count=57
2017/08/28 17:10:51 Training policy...
2017/08/28 17:10:54 step 0: objective=1.2069604
2017/08/28 17:10:56 step 1: objective=1.2199179
2017/08/28 17:10:57 step 2: objective=1.2308087
2017/08/28 17:10:58 step 3: objective=1.2419478
2017/08/28 17:11:00 step 4: objective=1.2493455
2017/08/28 17:11:01 step 5: objective=1.2578415
2017/08/28 17:11:02 step 6: objective=1.2668834
2017/08/28 17:11:03 step 7: objective=1.2697833
2017/08/28 17:11:03 Training value function...
2017/08/28 17:11:06 step 0: mse=182.676598 step=0.100000
2017/08/28 17:11:07 step 1: mse=179.901207 step=0.100000
2017/08/28 17:11:08 step 2: mse=177.737122 step=0.100000
2017/08/28 17:11:09 step 3: mse=175.691052 step=0.100000
2017/08/28 17:11:10 step 4: mse=173.946327 step=0.100000
2017/08/28 17:11:11 step 5: mse=172.209502 step=0.100000
2017/08/28 17:11:12 step 6: mse=170.806694 step=0.100000
2017/08/28 17:11:13 step 7: mse=169.230483 step=0.100000
2017/08/28 17:11:13 Saving...
2017/08/28 17:11:13 Gathering batch of experience...
2017/08/28 17:11:58 batch 417: mean=79.412698 stddev=69.454024 entropy=0.442533 frames=4771 count=63
2017/08/28 17:11:58 Training policy...
2017/08/28 17:12:01 step 0: objective=0.99503666
2017/08/28 17:12:02 step 1: objective=1.0031991
2017/08/28 17:12:03 step 2: objective=1.0139025
2017/08/28 17:12:05 step 3: objective=1.0229276
2017/08/28 17:12:06 step 4: objective=1.0305516
2017/08/28 17:12:07 step 5: objective=1.0374109
2017/08/28 17:12:08 step 6: objective=1.0433561
2017/08/28 17:12:09 step 7: objective=1.0513574
2017/08/28 17:12:09 Training value function...
2017/08/28 17:12:11 step 0: mse=201.868231 step=0.100000
2017/08/28 17:12:12 step 1: mse=200.213662 step=0.100000
2017/08/28 17:12:13 step 2: mse=198.576439 step=0.100000
2017/08/28 17:12:14 step 3: mse=196.800355 step=0.100000
2017/08/28 17:12:15 step 4: mse=195.319929 step=0.100000
2017/08/28 17:12:16 step 5: mse=194.079176 step=0.100000
2017/08/28 17:12:17 step 6: mse=192.701293 step=0.100000
2017/08/28 17:12:18 step 7: mse=191.081825 step=0.100000
2017/08/28 17:12:18 Saving...
2017/08/28 17:12:18 Gathering batch of experience...
2017/08/28 17:13:03 batch 418: mean=87.603448 stddev=84.664844 entropy=0.446863 frames=4906 count=58
2017/08/28 17:13:03 Training policy...
2017/08/28 17:13:06 step 0: objective=1.151227
2017/08/28 17:13:07 step 1: objective=1.1626204
2017/08/28 17:13:08 step 2: objective=1.1742133
2017/08/28 17:13:10 step 3: objective=1.1835847
2017/08/28 17:13:11 step 4: objective=1.1905017
2017/08/28 17:13:12 step 5: objective=1.1987684
2017/08/28 17:13:13 step 6: objective=1.2040335
2017/08/28 17:13:14 step 7: objective=1.2086031
2017/08/28 17:13:14 Training value function...
2017/08/28 17:13:16 step 0: mse=174.180988 step=0.100000
2017/08/28 17:13:18 step 1: mse=170.690458 step=0.100000
2017/08/28 17:13:19 step 2: mse=167.907253 step=0.100000
2017/08/28 17:13:20 step 3: mse=165.357078 step=0.100000
2017/08/28 17:13:21 step 4: mse=163.315866 step=0.100000
2017/08/28 17:13:22 step 5: mse=161.542792 step=0.100000
2017/08/28 17:13:23 step 6: mse=159.585317 step=0.100000
2017/08/28 17:13:24 step 7: mse=158.174416 step=0.100000
2017/08/28 17:13:24 Saving...
2017/08/28 17:13:24 Gathering batch of experience...
2017/08/28 17:14:08 batch 419: mean=85.192982 stddev=74.907531 entropy=0.444204 frames=4787 count=57
2017/08/28 17:14:08 Training policy...
2017/08/28 17:14:12 step 0: objective=0.78960466
2017/08/28 17:14:13 step 1: objective=0.7963583
2017/08/28 17:14:14 step 2: objective=0.8051442
2017/08/28 17:14:15 step 3: objective=0.8111441
2017/08/28 17:14:16 step 4: objective=0.8169192
2017/08/28 17:14:17 step 5: objective=0.8253887
2017/08/28 17:14:19 step 6: objective=0.83140785
2017/08/28 17:14:20 step 7: objective=0.835245
2017/08/28 17:14:20 Training value function...
2017/08/28 17:14:22 step 0: mse=175.702732 step=0.100000
2017/08/28 17:14:23 step 1: mse=173.881722 step=0.100000
2017/08/28 17:14:24 step 2: mse=172.365717 step=0.100000
2017/08/28 17:14:25 step 3: mse=170.869134 step=0.100000
2017/08/28 17:14:26 step 4: mse=169.664700 step=0.100000
2017/08/28 17:14:27 step 5: mse=168.345485 step=0.100000
2017/08/28 17:14:28 step 6: mse=167.033725 step=0.100000
2017/08/28 17:14:29 step 7: mse=165.999143 step=0.100000
2017/08/28 17:14:29 Saving...
2017/08/28 17:14:29 Gathering batch of experience...
2017/08/28 17:15:12 batch 420: mean=105.408163 stddev=74.379314 entropy=0.452999 frames=5016 count=49
2017/08/28 17:15:12 Training policy...
2017/08/28 17:15:16 step 0: objective=1.568952
2017/08/28 17:15:17 step 1: objective=1.5768573
2017/08/28 17:15:18 step 2: objective=1.5872699
2017/08/28 17:15:20 step 3: objective=1.5998099
2017/08/28 17:15:21 step 4: objective=1.6076133
2017/08/28 17:15:22 step 5: objective=1.6148219
2017/08/28 17:15:23 step 6: objective=1.6179632
2017/08/28 17:15:24 step 7: objective=1.6231216
2017/08/28 17:15:24 Training value function...
2017/08/28 17:15:27 step 0: mse=156.001118 step=0.100000
2017/08/28 17:15:28 step 1: mse=152.220538 step=0.100000
2017/08/28 17:15:29 step 2: mse=149.242082 step=0.100000
2017/08/28 17:15:30 step 3: mse=146.362205 step=0.100000
2017/08/28 17:15:31 step 4: mse=144.208002 step=0.100000
2017/08/28 17:15:32 step 5: mse=142.302153 step=0.100000
2017/08/28 17:15:33 step 6: mse=140.375042 step=0.100000
2017/08/28 17:15:34 step 7: mse=138.933499 step=0.100000
2017/08/28 17:15:34 Saving...
2017/08/28 17:15:34 Gathering batch of experience...
2017/08/28 17:16:26 batch 421: mean=96.525424 stddev=80.762963 entropy=0.443534 frames=5278 count=59
2017/08/28 17:16:26 Training policy...
2017/08/28 17:16:29 step 0: objective=1.2816976
2017/08/28 17:16:31 step 1: objective=1.2905492
2017/08/28 17:16:32 step 2: objective=1.3012781
2017/08/28 17:16:33 step 3: objective=1.3117177
2017/08/28 17:16:35 step 4: objective=1.3179162
2017/08/28 17:16:36 step 5: objective=1.3246659
2017/08/28 17:16:37 step 6: objective=1.3304601
2017/08/28 17:16:39 step 7: objective=1.3360667
2017/08/28 17:16:39 Training value function...
2017/08/28 17:16:41 step 0: mse=189.185543 step=0.100000
2017/08/28 17:16:42 step 1: mse=186.563286 step=0.100000
2017/08/28 17:16:43 step 2: mse=184.313599 step=0.100000
2017/08/28 17:16:44 step 3: mse=182.386985 step=0.100000
2017/08/28 17:16:45 step 4: mse=180.665011 step=0.100000
2017/08/28 17:16:46 step 5: mse=178.969781 step=0.100000
2017/08/28 17:16:47 step 6: mse=177.601796 step=0.100000
2017/08/28 17:16:48 step 7: mse=175.960493 step=0.100000
2017/08/28 17:16:48 Saving...
2017/08/28 17:16:48 Gathering batch of experience...
2017/08/28 17:17:34 batch 422: mean=75.516667 stddev=58.931172 entropy=0.432977 frames=4873 count=60
2017/08/28 17:17:34 Training policy...
2017/08/28 17:17:38 step 0: objective=-0.90193254
2017/08/28 17:17:39 step 1: objective=-0.892272
2017/08/28 17:17:40 step 2: objective=-0.8793969
2017/08/28 17:17:41 step 3: objective=-0.8737563
2017/08/28 17:17:43 step 4: objective=-0.8671854
2017/08/28 17:17:44 step 5: objective=-0.8611314
2017/08/28 17:17:45 step 6: objective=-0.8568416
2017/08/28 17:17:46 step 7: objective=-0.8509861
2017/08/28 17:17:46 Training value function...
2017/08/28 17:17:48 step 0: mse=150.457572 step=0.100000
2017/08/28 17:17:49 step 1: mse=146.872579 step=0.100000
2017/08/28 17:17:50 step 2: mse=144.646698 step=0.100000
2017/08/28 17:17:51 step 3: mse=142.661843 step=0.100000
2017/08/28 17:17:52 step 4: mse=141.215463 step=0.100000
2017/08/28 17:17:53 step 5: mse=139.423065 step=0.100000
2017/08/28 17:17:54 step 6: mse=138.217263 step=0.100000
2017/08/28 17:17:55 step 7: mse=136.950638 step=0.100000
2017/08/28 17:17:55 Saving...
2017/08/28 17:17:55 Gathering batch of experience...
2017/08/28 17:18:38 batch 423: mean=91.849057 stddev=74.500702 entropy=0.446076 frames=4770 count=53
2017/08/28 17:18:38 Training policy...
2017/08/28 17:18:41 step 0: objective=1.7115061
2017/08/28 17:18:42 step 1: objective=1.7186102
2017/08/28 17:18:43 step 2: objective=1.7312624
2017/08/28 17:18:45 step 3: objective=1.7393731
2017/08/28 17:18:46 step 4: objective=1.7481681
2017/08/28 17:18:47 step 5: objective=1.7558708
2017/08/28 17:18:48 step 6: objective=1.7597699
2017/08/28 17:18:49 step 7: objective=1.7637664
2017/08/28 17:18:49 Training value function...
2017/08/28 17:18:51 step 0: mse=186.933145 step=0.100000
2017/08/28 17:18:52 step 1: mse=183.421512 step=0.100000
2017/08/28 17:18:53 step 2: mse=180.263697 step=0.100000
2017/08/28 17:18:54 step 3: mse=177.615493 step=0.100000
2017/08/28 17:18:55 step 4: mse=175.040062 step=0.100000
2017/08/28 17:18:56 step 5: mse=172.630122 step=0.100000
2017/08/28 17:18:57 step 6: mse=170.696393 step=0.100000
2017/08/28 17:18:58 step 7: mse=168.557324 step=0.100000
2017/08/28 17:18:58 Saving...
2017/08/28 17:18:58 Gathering batch of experience...
2017/08/28 17:19:47 batch 424: mean=93.566667 stddev=86.805024 entropy=0.447232 frames=5396 count=60
2017/08/28 17:19:47 Training policy...
2017/08/28 17:19:51 step 0: objective=1.590405
2017/08/28 17:19:52 step 1: objective=1.5972427
2017/08/28 17:19:54 step 2: objective=1.6051188
2017/08/28 17:19:55 step 3: objective=1.6104913
2017/08/28 17:19:56 step 4: objective=1.6182158
2017/08/28 17:19:58 step 5: objective=1.6265535
2017/08/28 17:19:59 step 6: objective=1.6305186
2017/08/28 17:20:00 step 7: objective=1.6366073
2017/08/28 17:20:00 Training value function...
2017/08/28 17:20:03 step 0: mse=203.229199 step=0.100000
2017/08/28 17:20:04 step 1: mse=199.206855 step=0.100000
2017/08/28 17:20:05 step 2: mse=195.655134 step=0.100000
2017/08/28 17:20:06 step 3: mse=192.900647 step=0.100000
2017/08/28 17:20:07 step 4: mse=190.169758 step=0.100000
2017/08/28 17:20:08 step 5: mse=187.801433 step=0.100000
2017/08/28 17:20:09 step 6: mse=185.687000 step=0.100000
2017/08/28 17:20:10 step 7: mse=184.029241 step=0.100000
2017/08/28 17:20:10 Saving...
2017/08/28 17:20:10 Gathering batch of experience...
2017/08/28 17:21:01 batch 425: mean=86.580645 stddev=89.100260 entropy=0.447169 frames=5198 count=62
2017/08/28 17:21:01 Training policy...
2017/08/28 17:21:05 step 0: objective=0.8576815
2017/08/28 17:21:06 step 1: objective=0.8711889
2017/08/28 17:21:07 step 2: objective=0.88245195
2017/08/28 17:21:09 step 3: objective=0.89460677
2017/08/28 17:21:10 step 4: objective=0.90313196
2017/08/28 17:21:11 step 5: objective=0.9110377
2017/08/28 17:21:12 step 6: objective=0.9175108
2017/08/28 17:21:14 step 7: objective=0.9220337
2017/08/28 17:21:14 Training value function...
2017/08/28 17:21:16 step 0: mse=196.253493 step=0.100000
2017/08/28 17:21:17 step 1: mse=193.508691 step=0.100000
2017/08/28 17:21:18 step 2: mse=190.850665 step=0.100000
2017/08/28 17:21:19 step 3: mse=188.929920 step=0.100000
2017/08/28 17:21:20 step 4: mse=187.343171 step=0.100000
2017/08/28 17:21:21 step 5: mse=185.658606 step=0.100000
2017/08/28 17:21:22 step 6: mse=183.758679 step=0.100000
2017/08/28 17:21:23 step 7: mse=181.933077 step=0.100000
2017/08/28 17:21:23 Saving...
2017/08/28 17:21:24 Gathering batch of experience...
2017/08/28 17:22:11 batch 426: mean=67.376812 stddev=58.629295 entropy=0.433314 frames=4752 count=69
2017/08/28 17:22:11 Training policy...
2017/08/28 17:22:14 step 0: objective=-0.34885043
2017/08/28 17:22:15 step 1: objective=-0.33974755
2017/08/28 17:22:16 step 2: objective=-0.32399833
2017/08/28 17:22:17 step 3: objective=-0.31472605
2017/08/28 17:22:19 step 4: objective=-0.306843
2017/08/28 17:22:20 step 5: objective=-0.29796013
2017/08/28 17:22:21 step 6: objective=-0.29341787
2017/08/28 17:22:22 step 7: objective=-0.2849334
2017/08/28 17:22:22 Training value function...
2017/08/28 17:22:24 step 0: mse=153.261564 step=0.100000
2017/08/28 17:22:25 step 1: mse=151.715978 step=0.100000
2017/08/28 17:22:26 step 2: mse=150.055931 step=0.100000
2017/08/28 17:22:27 step 3: mse=148.749806 step=0.100000
2017/08/28 17:22:28 step 4: mse=147.680093 step=0.100000
2017/08/28 17:22:29 step 5: mse=146.938655 step=0.100000
2017/08/28 17:22:30 step 6: mse=146.235273 step=0.100000
2017/08/28 17:22:31 step 7: mse=145.279219 step=0.100000
2017/08/28 17:22:31 Saving...
2017/08/28 17:22:31 Gathering batch of experience...
2017/08/28 17:23:19 batch 427: mean=75.281250 stddev=66.169637 entropy=0.433941 frames=4923 count=64
2017/08/28 17:23:19 Training policy...
2017/08/28 17:23:22 step 0: objective=0.9060661
2017/08/28 17:23:23 step 1: objective=0.9186078
2017/08/28 17:23:25 step 2: objective=0.9289434
2017/08/28 17:23:26 step 3: objective=0.93672925
2017/08/28 17:23:27 step 4: objective=0.9442925
2017/08/28 17:23:28 step 5: objective=0.95050496
2017/08/28 17:23:29 step 6: objective=0.95672554
2017/08/28 17:23:31 step 7: objective=0.9619447
2017/08/28 17:23:31 Training value function...
2017/08/28 17:23:33 step 0: mse=139.321503 step=0.100000
2017/08/28 17:23:34 step 1: mse=137.969389 step=0.100000
2017/08/28 17:23:35 step 2: mse=136.864539 step=0.100000
2017/08/28 17:23:36 step 3: mse=135.945118 step=0.100000
2017/08/28 17:23:37 step 4: mse=135.048085 step=0.100000
2017/08/28 17:23:38 step 5: mse=134.216746 step=0.100000
2017/08/28 17:23:39 step 6: mse=133.688924 step=0.100000
2017/08/28 17:23:40 step 7: mse=132.785090 step=0.100000
2017/08/28 17:23:40 Saving...
2017/08/28 17:23:40 Gathering batch of experience...
2017/08/28 17:24:25 batch 428: mean=100.327273 stddev=110.258383 entropy=0.437520 frames=5295 count=55
2017/08/28 17:24:25 Training policy...
2017/08/28 17:24:28 step 0: objective=2.5898523
2017/08/28 17:24:30 step 1: objective=2.6000798
2017/08/28 17:24:31 step 2: objective=2.6099436
2017/08/28 17:24:32 step 3: objective=2.616089
2017/08/28 17:24:34 step 4: objective=2.6203923
2017/08/28 17:24:35 step 5: objective=2.627449
2017/08/28 17:24:36 step 6: objective=2.6329534
2017/08/28 17:24:38 step 7: objective=2.6367114
2017/08/28 17:24:38 Training value function...
2017/08/28 17:24:40 step 0: mse=217.435804 step=0.100000
2017/08/28 17:24:41 step 1: mse=209.544296 step=0.100000
2017/08/28 17:24:42 step 2: mse=203.039882 step=0.100000
2017/08/28 17:24:43 step 3: mse=197.338454 step=0.100000
2017/08/28 17:24:44 step 4: mse=192.770009 step=0.100000
2017/08/28 17:24:45 step 5: mse=188.675685 step=0.100000
2017/08/28 17:24:46 step 6: mse=185.139038 step=0.100000
2017/08/28 17:24:48 step 7: mse=181.754509 step=0.100000
2017/08/28 17:24:48 Saving...
2017/08/28 17:24:48 Gathering batch of experience...
2017/08/28 17:25:38 batch 429: mean=88.250000 stddev=74.194480 entropy=0.439348 frames=5156 count=60
2017/08/28 17:25:38 Training policy...
2017/08/28 17:25:41 step 0: objective=0.79259205
2017/08/28 17:25:42 step 1: objective=0.8033708
2017/08/28 17:25:44 step 2: objective=0.81469905
2017/08/28 17:25:45 step 3: objective=0.82344013
2017/08/28 17:25:46 step 4: objective=0.83152604
2017/08/28 17:25:47 step 5: objective=0.83604974
2017/08/28 17:25:49 step 6: objective=0.8425621
2017/08/28 17:25:50 step 7: objective=0.8484088
2017/08/28 17:25:50 Training value function...
2017/08/28 17:25:52 step 0: mse=172.139126 step=0.100000
2017/08/28 17:25:53 step 1: mse=169.437495 step=0.100000
2017/08/28 17:25:54 step 2: mse=166.963575 step=0.100000
2017/08/28 17:25:55 step 3: mse=164.749485 step=0.100000
2017/08/28 17:25:56 step 4: mse=162.857044 step=0.100000
2017/08/28 17:25:58 step 5: mse=161.205606 step=0.100000
2017/08/28 17:25:59 step 6: mse=159.954302 step=0.100000
2017/08/28 17:26:00 step 7: mse=158.622566 step=0.100000
2017/08/28 17:26:00 Saving...
2017/08/28 17:26:00 Gathering batch of experience...
2017/08/28 17:26:44 batch 430: mean=80.929825 stddev=86.092944 entropy=0.433603 frames=4699 count=57
2017/08/28 17:26:44 Training policy...
2017/08/28 17:26:47 step 0: objective=0.42632595
2017/08/28 17:26:48 step 1: objective=0.4396262
2017/08/28 17:26:50 step 2: objective=0.45327002
2017/08/28 17:26:51 step 3: objective=0.46312925
2017/08/28 17:26:52 step 4: objective=0.47261593
2017/08/28 17:26:53 step 5: objective=0.47684395
2017/08/28 17:26:54 step 6: objective=0.48014534
2017/08/28 17:26:55 step 7: objective=0.48487675
2017/08/28 17:26:55 Training value function...
2017/08/28 17:26:57 step 0: mse=168.233265 step=0.100000
2017/08/28 17:26:58 step 1: mse=165.829588 step=0.100000
2017/08/28 17:26:59 step 2: mse=163.979040 step=0.100000
2017/08/28 17:27:00 step 3: mse=162.162155 step=0.100000
2017/08/28 17:27:01 step 4: mse=160.365158 step=0.100000
2017/08/28 17:27:02 step 5: mse=159.228854 step=0.100000
2017/08/28 17:27:03 step 6: mse=157.847003 step=0.100000
2017/08/28 17:27:04 step 7: mse=156.654456 step=0.100000
2017/08/28 17:27:04 Saving...
2017/08/28 17:27:04 Gathering batch of experience...
2017/08/28 17:27:50 batch 431: mean=94.709091 stddev=94.947004 entropy=0.436880 frames=5010 count=55
2017/08/28 17:27:50 Training policy...
2017/08/28 17:27:54 step 0: objective=1.5426099
2017/08/28 17:27:55 step 1: objective=1.5502654
2017/08/28 17:27:56 step 2: objective=1.558341
2017/08/28 17:27:57 step 3: objective=1.5653042
2017/08/28 17:27:58 step 4: objective=1.5741047
2017/08/28 17:28:00 step 5: objective=1.5810857
2017/08/28 17:28:01 step 6: objective=1.5877703
2017/08/28 17:28:02 step 7: objective=1.5925795
2017/08/28 17:28:02 Training value function...
2017/08/28 17:28:04 step 0: mse=192.818958 step=0.100000
2017/08/28 17:28:05 step 1: mse=188.532165 step=0.100000
2017/08/28 17:28:06 step 2: mse=185.491839 step=0.100000
2017/08/28 17:28:07 step 3: mse=182.398404 step=0.100000
2017/08/28 17:28:08 step 4: mse=179.496342 step=0.100000
2017/08/28 17:28:09 step 5: mse=177.109338 step=0.100000
2017/08/28 17:28:10 step 6: mse=175.107576 step=0.100000
2017/08/28 17:28:12 step 7: mse=173.355837 step=0.100000
2017/08/28 17:28:12 Saving...
2017/08/28 17:28:12 Gathering batch of experience...
2017/08/28 17:28:58 batch 432: mean=78.888889 stddev=83.441665 entropy=0.433659 frames=4984 count=63
2017/08/28 17:28:58 Training policy...
2017/08/28 17:29:02 step 0: objective=0.43946818
2017/08/28 17:29:03 step 1: objective=0.44846097
2017/08/28 17:29:04 step 2: objective=0.46166688
2017/08/28 17:29:05 step 3: objective=0.46894735
2017/08/28 17:29:07 step 4: objective=0.47628805
2017/08/28 17:29:08 step 5: objective=0.48724717
2017/08/28 17:29:09 step 6: objective=0.49201894
2017/08/28 17:29:10 step 7: objective=0.4964172
2017/08/28 17:29:10 Training value function...
2017/08/28 17:29:12 step 0: mse=173.994752 step=0.100000
2017/08/28 17:29:13 step 1: mse=171.288663 step=0.100000
2017/08/28 17:29:15 step 2: mse=169.091222 step=0.100000
2017/08/28 17:29:16 step 3: mse=166.895834 step=0.100000
2017/08/28 17:29:17 step 4: mse=165.287678 step=0.100000
2017/08/28 17:29:18 step 5: mse=163.615479 step=0.100000
2017/08/28 17:29:19 step 6: mse=162.324577 step=0.100000
2017/08/28 17:29:20 step 7: mse=160.944904 step=0.100000
2017/08/28 17:29:20 Saving...
2017/08/28 17:29:20 Gathering batch of experience...
2017/08/28 17:30:07 batch 433: mean=85.550000 stddev=76.480155 entropy=0.435887 frames=5307 count=60
2017/08/28 17:30:07 Training policy...
2017/08/28 17:30:11 step 0: objective=0.47821411
2017/08/28 17:30:12 step 1: objective=0.49101952
2017/08/28 17:30:14 step 2: objective=0.5025371
2017/08/28 17:30:15 step 3: objective=0.51033
2017/08/28 17:30:16 step 4: objective=0.5187316
2017/08/28 17:30:18 step 5: objective=0.52418697
2017/08/28 17:30:19 step 6: objective=0.53102833
2017/08/28 17:30:20 step 7: objective=0.53674746
2017/08/28 17:30:20 Training value function...
2017/08/28 17:30:22 step 0: mse=172.065675 step=0.100000
2017/08/28 17:30:24 step 1: mse=169.692397 step=0.100000
2017/08/28 17:30:25 step 2: mse=167.994781 step=0.100000
2017/08/28 17:30:26 step 3: mse=166.467502 step=0.100000
2017/08/28 17:30:27 step 4: mse=165.053785 step=0.100000
2017/08/28 17:30:28 step 5: mse=163.508645 step=0.100000
2017/08/28 17:30:29 step 6: mse=162.241492 step=0.100000
2017/08/28 17:30:30 step 7: mse=161.228857 step=0.100000
2017/08/28 17:30:30 Saving...
2017/08/28 17:30:30 Gathering batch of experience...
2017/08/28 17:31:14 batch 434: mean=90.909091 stddev=74.530841 entropy=0.428454 frames=4857 count=55
2017/08/28 17:31:14 Training policy...
2017/08/28 17:31:17 step 0: objective=1.5544434
2017/08/28 17:31:18 step 1: objective=1.5657983
2017/08/28 17:31:20 step 2: objective=1.5748292
2017/08/28 17:31:21 step 3: objective=1.5808862
2017/08/28 17:31:22 step 4: objective=1.5903772
2017/08/28 17:31:23 step 5: objective=1.6002401
2017/08/28 17:31:24 step 6: objective=1.6046984
2017/08/28 17:31:26 step 7: objective=1.6107529
2017/08/28 17:31:26 Training value function...
2017/08/28 17:31:28 step 0: mse=196.823516 step=0.100000
2017/08/28 17:31:29 step 1: mse=191.018869 step=0.100000
2017/08/28 17:31:30 step 2: mse=185.694560 step=0.100000
2017/08/28 17:31:31 step 3: mse=181.529513 step=0.100000
2017/08/28 17:31:32 step 4: mse=177.925169 step=0.100000
2017/08/28 17:31:33 step 5: mse=174.413066 step=0.100000
2017/08/28 17:31:34 step 6: mse=171.548735 step=0.100000
2017/08/28 17:31:35 step 7: mse=169.017810 step=0.100000
2017/08/28 17:31:35 Saving...
2017/08/28 17:31:35 Gathering batch of experience...
2017/08/28 17:32:17 batch 435: mean=110.791667 stddev=85.010038 entropy=0.443092 frames=5055 count=48
2017/08/28 17:32:17 Training policy...
2017/08/28 17:32:21 step 0: objective=1.8047566
2017/08/28 17:32:22 step 1: objective=1.8153232
2017/08/28 17:32:23 step 2: objective=1.8340634
2017/08/28 17:32:25 step 3: objective=1.8395095
2017/08/28 17:32:26 step 4: objective=1.845435
2017/08/28 17:32:27 step 5: objective=1.8545822
2017/08/28 17:32:28 step 6: objective=1.8654077
2017/08/28 17:32:30 step 7: objective=1.8724405
2017/08/28 17:32:30 Training value function...
2017/08/28 17:32:32 step 0: mse=185.425311 step=0.100000
2017/08/28 17:32:33 step 1: mse=181.525832 step=0.100000
2017/08/28 17:32:34 step 2: mse=178.482121 step=0.100000
2017/08/28 17:32:35 step 3: mse=175.628606 step=0.100000
2017/08/28 17:32:36 step 4: mse=172.898871 step=0.100000
2017/08/28 17:32:37 step 5: mse=170.836292 step=0.100000
2017/08/28 17:32:38 step 6: mse=168.696086 step=0.100000
2017/08/28 17:32:39 step 7: mse=166.803089 step=0.100000
2017/08/28 17:32:39 Saving...
2017/08/28 17:32:39 Gathering batch of experience...
2017/08/28 17:33:25 batch 436: mean=101.464286 stddev=98.983398 entropy=0.434248 frames=5345 count=56
2017/08/28 17:33:25 Training policy...
2017/08/28 17:33:29 step 0: objective=1.4051958
2017/08/28 17:33:30 step 1: objective=1.4133946
2017/08/28 17:33:32 step 2: objective=1.4218409
2017/08/28 17:33:33 step 3: objective=1.4292694
2017/08/28 17:33:34 step 4: objective=1.43399
2017/08/28 17:33:36 step 5: objective=1.4414196
2017/08/28 17:33:37 step 6: objective=1.4514575
2017/08/28 17:33:38 step 7: objective=1.4549917
2017/08/28 17:33:38 Training value function...
2017/08/28 17:33:40 step 0: mse=179.257033 step=0.100000
2017/08/28 17:33:42 step 1: mse=176.559587 step=0.100000
2017/08/28 17:33:43 step 2: mse=174.417038 step=0.100000
2017/08/28 17:33:44 step 3: mse=172.243610 step=0.100000
2017/08/28 17:33:45 step 4: mse=170.388498 step=0.100000
2017/08/28 17:33:46 step 5: mse=169.063710 step=0.100000
2017/08/28 17:33:47 step 6: mse=167.414148 step=0.100000
2017/08/28 17:33:48 step 7: mse=165.903074 step=0.100000
2017/08/28 17:33:48 Saving...
2017/08/28 17:33:48 Gathering batch of experience...
2017/08/28 17:34:29 batch 437: mean=97.941176 stddev=98.278797 entropy=0.434112 frames=4734 count=51
2017/08/28 17:34:29 Training policy...
2017/08/28 17:34:32 step 0: objective=0.8566931
2017/08/28 17:34:33 step 1: objective=0.8669081
2017/08/28 17:34:34 step 2: objective=0.8755549
2017/08/28 17:34:36 step 3: objective=0.8849847
2017/08/28 17:34:37 step 4: objective=0.8932668
2017/08/28 17:34:38 step 5: objective=0.8981867
2017/08/28 17:34:39 step 6: objective=0.9039169
2017/08/28 17:34:40 step 7: objective=0.9137576
2017/08/28 17:34:40 Training value function...
2017/08/28 17:34:42 step 0: mse=208.984345 step=0.100000
2017/08/28 17:34:43 step 1: mse=205.586400 step=0.100000
2017/08/28 17:34:44 step 2: mse=202.977886 step=0.100000
2017/08/28 17:34:45 step 3: mse=200.858407 step=0.100000
2017/08/28 17:34:46 step 4: mse=198.988341 step=0.100000
2017/08/28 17:34:47 step 5: mse=197.177843 step=0.100000
2017/08/28 17:34:48 step 6: mse=195.986466 step=0.100000
2017/08/28 17:34:49 step 7: mse=193.925595 step=0.100000
2017/08/28 17:34:49 Saving...
2017/08/28 17:34:49 Gathering batch of experience...
2017/08/28 17:35:38 batch 438: mean=82.171875 stddev=74.887114 entropy=0.427499 frames=5233 count=64
2017/08/28 17:35:38 Training policy...
2017/08/28 17:35:42 step 0: objective=-0.15055858
2017/08/28 17:35:43 step 1: objective=-0.13317291
2017/08/28 17:35:44 step 2: objective=-0.12112873
2017/08/28 17:35:46 step 3: objective=-0.110040925
2017/08/28 17:35:47 step 4: objective=-0.09996604
2017/08/28 17:35:48 step 5: objective=-0.09101322
2017/08/28 17:35:49 step 6: objective=-0.085077375
2017/08/28 17:35:51 step 7: objective=-0.07446924
2017/08/28 17:35:51 Training value function...
2017/08/28 17:35:53 step 0: mse=174.387163 step=0.100000
2017/08/28 17:35:54 step 1: mse=172.164949 step=0.100000
2017/08/28 17:35:55 step 2: mse=170.159324 step=0.100000
2017/08/28 17:35:56 step 3: mse=168.479394 step=0.100000
2017/08/28 17:35:57 step 4: mse=166.933442 step=0.100000
2017/08/28 17:35:58 step 5: mse=166.025989 step=0.100000
2017/08/28 17:35:59 step 6: mse=164.904260 step=0.100000
2017/08/28 17:36:01 step 7: mse=163.592379 step=0.100000
2017/08/28 17:36:01 Saving...
2017/08/28 17:36:01 Gathering batch of experience...
2017/08/28 17:36:47 batch 439: mean=89.327586 stddev=83.268653 entropy=0.435161 frames=5151 count=58
2017/08/28 17:36:47 Training policy...
2017/08/28 17:36:50 step 0: objective=0.9260404
2017/08/28 17:36:52 step 1: objective=0.9394361
2017/08/28 17:36:53 step 2: objective=0.9513488
2017/08/28 17:36:54 step 3: objective=0.9571872
2017/08/28 17:36:56 step 4: objective=0.9634613
2017/08/28 17:36:57 step 5: objective=0.9689674
2017/08/28 17:36:58 step 6: objective=0.97396857
2017/08/28 17:36:59 step 7: objective=0.97970283
2017/08/28 17:36:59 Training value function...
2017/08/28 17:37:02 step 0: mse=157.737336 step=0.100000
2017/08/28 17:37:03 step 1: mse=155.619482 step=0.100000
2017/08/28 17:37:04 step 2: mse=154.357017 step=0.100000
2017/08/28 17:37:05 step 3: mse=153.046865 step=0.100000
2017/08/28 17:37:06 step 4: mse=151.949773 step=0.100000
2017/08/28 17:37:07 step 5: mse=151.651195 step=0.100000
2017/08/28 17:37:08 step 6: mse=150.409050 step=0.100000
2017/08/28 17:37:09 step 7: mse=149.671231 step=0.100000
2017/08/28 17:37:09 Saving...
2017/08/28 17:37:09 Gathering batch of experience...
2017/08/28 17:37:59 batch 440: mean=94.140351 stddev=88.293060 entropy=0.431573 frames=5045 count=57
2017/08/28 17:37:59 Training policy...
2017/08/28 17:38:03 step 0: objective=1.6070815
2017/08/28 17:38:04 step 1: objective=1.6183279
2017/08/28 17:38:05 step 2: objective=1.6291358
2017/08/28 17:38:06 step 3: objective=1.6411134
2017/08/28 17:38:08 step 4: objective=1.6470808
2017/08/28 17:38:09 step 5: objective=1.6511469
2017/08/28 17:38:10 step 6: objective=1.6611729
2017/08/28 17:38:11 step 7: objective=1.6642555
2017/08/28 17:38:11 Training value function...
2017/08/28 17:38:14 step 0: mse=171.998532 step=0.100000
2017/08/28 17:38:15 step 1: mse=166.770753 step=0.100000
2017/08/28 17:38:16 step 2: mse=162.613439 step=0.100000
2017/08/28 17:38:17 step 3: mse=159.533932 step=0.100000
2017/08/28 17:38:18 step 4: mse=156.752225 step=0.100000
2017/08/28 17:38:19 step 5: mse=154.538075 step=0.100000
2017/08/28 17:38:20 step 6: mse=152.439998 step=0.100000
2017/08/28 17:38:21 step 7: mse=150.932043 step=0.100000
2017/08/28 17:38:21 Saving...
2017/08/28 17:38:21 Gathering batch of experience...
2017/08/28 17:39:07 batch 441: mean=92.982759 stddev=87.037545 entropy=0.433928 frames=5091 count=58
2017/08/28 17:39:07 Training policy...
2017/08/28 17:39:11 step 0: objective=1.3644512
2017/08/28 17:39:12 step 1: objective=1.3770188
2017/08/28 17:39:13 step 2: objective=1.3866417
2017/08/28 17:39:14 step 3: objective=1.3988863
2017/08/28 17:39:16 step 4: objective=1.4093701
2017/08/28 17:39:17 step 5: objective=1.4190879
2017/08/28 17:39:18 step 6: objective=1.4263384
2017/08/28 17:39:19 step 7: objective=1.4313415
2017/08/28 17:39:19 Training value function...
2017/08/28 17:39:21 step 0: mse=214.639027 step=0.100000
2017/08/28 17:39:23 step 1: mse=210.524552 step=0.100000
2017/08/28 17:39:24 step 2: mse=207.123191 step=0.100000
2017/08/28 17:39:25 step 3: mse=203.947751 step=0.100000
2017/08/28 17:39:26 step 4: mse=201.105240 step=0.100000
2017/08/28 17:39:27 step 5: mse=198.912592 step=0.100000
2017/08/28 17:39:28 step 6: mse=197.142364 step=0.100000
2017/08/28 17:39:29 step 7: mse=195.424650 step=0.100000
2017/08/28 17:39:29 Saving...
2017/08/28 17:39:29 Gathering batch of experience...
2017/08/28 17:40:16 batch 442: mean=79.460317 stddev=63.811684 entropy=0.430665 frames=4754 count=63
2017/08/28 17:40:16 Training policy...
2017/08/28 17:40:19 step 0: objective=0.3099482
2017/08/28 17:40:21 step 1: objective=0.32227427
2017/08/28 17:40:22 step 2: objective=0.3312531
2017/08/28 17:40:23 step 3: objective=0.34184873
2017/08/28 17:40:24 step 4: objective=0.34721184
2017/08/28 17:40:25 step 5: objective=0.3544355
2017/08/28 17:40:27 step 6: objective=0.3623052
2017/08/28 17:40:28 step 7: objective=0.37250206
2017/08/28 17:40:28 Training value function...
2017/08/28 17:40:30 step 0: mse=170.009908 step=0.100000
2017/08/28 17:40:31 step 1: mse=167.864399 step=0.100000
2017/08/28 17:40:32 step 2: mse=165.956503 step=0.100000
2017/08/28 17:40:33 step 3: mse=164.471910 step=0.100000
2017/08/28 17:40:34 step 4: mse=163.220918 step=0.100000
2017/08/28 17:40:35 step 5: mse=161.691959 step=0.100000
2017/08/28 17:40:36 step 6: mse=160.426232 step=0.100000
2017/08/28 17:40:37 step 7: mse=159.433034 step=0.100000
2017/08/28 17:40:37 Saving...
2017/08/28 17:40:37 Gathering batch of experience...
2017/08/28 17:41:23 batch 443: mean=82.883333 stddev=60.983356 entropy=0.426341 frames=5068 count=60
2017/08/28 17:41:23 Training policy...
2017/08/28 17:41:26 step 0: objective=0.4000914
2017/08/28 17:41:28 step 1: objective=0.4113249
2017/08/28 17:41:29 step 2: objective=0.42197415
2017/08/28 17:41:30 step 3: objective=0.43151674
2017/08/28 17:41:31 step 4: objective=0.4387182
2017/08/28 17:41:33 step 5: objective=0.44471577
2017/08/28 17:41:34 step 6: objective=0.45185828
2017/08/28 17:41:35 step 7: objective=0.4560084
2017/08/28 17:41:35 Training value function...
2017/08/28 17:41:37 step 0: mse=143.131376 step=0.100000
2017/08/28 17:41:38 step 1: mse=141.794423 step=0.100000
2017/08/28 17:41:39 step 2: mse=140.908055 step=0.100000
2017/08/28 17:41:40 step 3: mse=140.083134 step=0.100000
2017/08/28 17:41:41 step 4: mse=139.121325 step=0.100000
2017/08/28 17:41:43 step 5: mse=138.300878 step=0.100000
2017/08/28 17:41:44 step 6: mse=137.577536 step=0.100000
2017/08/28 17:41:45 step 7: mse=136.681678 step=0.100000
2017/08/28 17:41:45 Saving...
2017/08/28 17:41:45 Gathering batch of experience...
2017/08/28 17:42:28 batch 444: mean=94.576923 stddev=80.199834 entropy=0.431193 frames=4846 count=52
2017/08/28 17:42:28 Training policy...
2017/08/28 17:42:31 step 0: objective=1.450242
2017/08/28 17:42:33 step 1: objective=1.4585453
2017/08/28 17:42:34 step 2: objective=1.4654837
2017/08/28 17:42:35 step 3: objective=1.4719653
2017/08/28 17:42:36 step 4: objective=1.4768702
2017/08/28 17:42:37 step 5: objective=1.481504
2017/08/28 17:42:39 step 6: objective=1.492887
2017/08/28 17:42:40 step 7: objective=1.4982129
2017/08/28 17:42:40 Training value function...
2017/08/28 17:42:42 step 0: mse=184.345060 step=0.100000
2017/08/28 17:42:43 step 1: mse=179.506683 step=0.100000
2017/08/28 17:42:44 step 2: mse=175.698373 step=0.100000
2017/08/28 17:42:45 step 3: mse=172.264051 step=0.100000
2017/08/28 17:42:46 step 4: mse=169.410797 step=0.100000
2017/08/28 17:42:47 step 5: mse=166.973950 step=0.100000
2017/08/28 17:42:48 step 6: mse=164.918766 step=0.100000
2017/08/28 17:42:49 step 7: mse=163.316040 step=0.100000
2017/08/28 17:42:49 Saving...
2017/08/28 17:42:49 Gathering batch of experience...
2017/08/28 17:43:33 batch 445: mean=101.226415 stddev=101.559099 entropy=0.425942 frames=5112 count=53
2017/08/28 17:43:33 Training policy...
2017/08/28 17:43:36 step 0: objective=1.8940823
2017/08/28 17:43:37 step 1: objective=1.9100993
2017/08/28 17:43:39 step 2: objective=1.9211984
2017/08/28 17:43:40 step 3: objective=1.9327487
2017/08/28 17:43:41 step 4: objective=1.940937
2017/08/28 17:43:43 step 5: objective=1.9493415
2017/08/28 17:43:44 step 6: objective=1.9543327
2017/08/28 17:43:45 step 7: objective=1.9588351
2017/08/28 17:43:45 Training value function...
2017/08/28 17:43:47 step 0: mse=226.136128 step=0.100000
2017/08/28 17:43:48 step 1: mse=218.310607 step=0.100000
2017/08/28 17:43:49 step 2: mse=211.466490 step=0.100000
2017/08/28 17:43:51 step 3: mse=205.817347 step=0.100000
2017/08/28 17:43:52 step 4: mse=200.967177 step=0.100000
2017/08/28 17:43:53 step 5: mse=196.893679 step=0.100000
2017/08/28 17:43:54 step 6: mse=193.471309 step=0.100000
2017/08/28 17:43:55 step 7: mse=190.327032 step=0.100000
2017/08/28 17:43:55 Saving...
2017/08/28 17:43:55 Gathering batch of experience...
2017/08/28 17:44:47 batch 446: mean=122.280000 stddev=123.000494 entropy=0.428861 frames=5843 count=50
2017/08/28 17:44:47 Training policy...
2017/08/28 17:44:51 step 0: objective=1.9346507
2017/08/28 17:44:53 step 1: objective=1.941482
2017/08/28 17:44:54 step 2: objective=1.9502463
2017/08/28 17:44:56 step 3: objective=1.9550595
2017/08/28 17:44:57 step 4: objective=1.963355
2017/08/28 17:44:58 step 5: objective=1.9708447
2017/08/28 17:45:00 step 6: objective=1.9770054
2017/08/28 17:45:01 step 7: objective=1.982917
2017/08/28 17:45:01 Training value function...
2017/08/28 17:45:04 step 0: mse=221.510726 step=0.100000
2017/08/28 17:45:05 step 1: mse=212.346929 step=0.100000
2017/08/28 17:45:06 step 2: mse=204.533366 step=0.100000
2017/08/28 17:45:07 step 3: mse=198.410697 step=0.100000
2017/08/28 17:45:09 step 4: mse=193.009267 step=0.100000
2017/08/28 17:45:10 step 5: mse=188.468233 step=0.100000
2017/08/28 17:45:11 step 6: mse=184.542298 step=0.100000
2017/08/28 17:45:12 step 7: mse=181.039459 step=0.100000
2017/08/28 17:45:12 Saving...
2017/08/28 17:45:12 Gathering batch of experience...
2017/08/28 17:45:58 batch 447: mean=80.229508 stddev=59.718573 entropy=0.426927 frames=4773 count=61
2017/08/28 17:45:58 Training policy...
2017/08/28 17:46:02 step 0: objective=-0.12002885
2017/08/28 17:46:03 step 1: objective=-0.10651728
2017/08/28 17:46:04 step 2: objective=-0.08990285
2017/08/28 17:46:05 step 3: objective=-0.07967521
2017/08/28 17:46:07 step 4: objective=-0.07566943
2017/08/28 17:46:08 step 5: objective=-0.07203274
2017/08/28 17:46:09 step 6: objective=-0.06247508
2017/08/28 17:46:10 step 7: objective=-0.058055654
2017/08/28 17:46:10 Training value function...
2017/08/28 17:46:12 step 0: mse=148.710120 step=0.100000
2017/08/28 17:46:13 step 1: mse=145.958799 step=0.100000
2017/08/28 17:46:14 step 2: mse=143.397288 step=0.100000
2017/08/28 17:46:15 step 3: mse=141.436138 step=0.100000
2017/08/28 17:46:16 step 4: mse=140.011873 step=0.100000
2017/08/28 17:46:17 step 5: mse=138.624373 step=0.100000
2017/08/28 17:46:18 step 6: mse=137.397492 step=0.100000
2017/08/28 17:46:19 step 7: mse=136.499270 step=0.100000
2017/08/28 17:46:19 Saving...
2017/08/28 17:46:19 Gathering batch of experience...
2017/08/28 17:47:02 batch 448: mean=114.333333 stddev=91.052946 entropy=0.428125 frames=5143 count=48
2017/08/28 17:47:02 Training policy...
2017/08/28 17:47:06 step 0: objective=2.2503672
2017/08/28 17:47:07 step 1: objective=2.2638867
2017/08/28 17:47:08 step 2: objective=2.2693117
2017/08/28 17:47:10 step 3: objective=2.2767677
2017/08/28 17:47:11 step 4: objective=2.289184
2017/08/28 17:47:12 step 5: objective=2.2969077
2017/08/28 17:47:13 step 6: objective=2.3035939
2017/08/28 17:47:15 step 7: objective=2.3114603
2017/08/28 17:47:15 Training value function...
2017/08/28 17:47:17 step 0: mse=192.726870 step=0.100000
2017/08/28 17:47:18 step 1: mse=188.073597 step=0.100000
2017/08/28 17:47:19 step 2: mse=183.706871 step=0.100000
2017/08/28 17:47:20 step 3: mse=180.274435 step=0.100000
2017/08/28 17:47:21 step 4: mse=177.310125 step=0.100000
2017/08/28 17:47:22 step 5: mse=174.747498 step=0.100000
2017/08/28 17:47:23 step 6: mse=172.579911 step=0.100000
2017/08/28 17:47:24 step 7: mse=170.552672 step=0.100000
2017/08/28 17:47:24 Saving...
2017/08/28 17:47:24 Gathering batch of experience...
2017/08/28 17:48:08 batch 449: mean=114.531915 stddev=79.578103 entropy=0.435740 frames=5155 count=47
2017/08/28 17:48:08 Training policy...
2017/08/28 17:48:12 step 0: objective=1.4281843
2017/08/28 17:48:13 step 1: objective=1.4337258
2017/08/28 17:48:14 step 2: objective=1.4415975
2017/08/28 17:48:16 step 3: objective=1.4464581
2017/08/28 17:48:17 step 4: objective=1.4543756
2017/08/28 17:48:18 step 5: objective=1.4620966
2017/08/28 17:48:20 step 6: objective=1.4656924
2017/08/28 17:48:21 step 7: objective=1.4692291
2017/08/28 17:48:21 Training value function...
2017/08/28 17:48:23 step 0: mse=157.753720 step=0.100000
2017/08/28 17:48:24 step 1: mse=154.754615 step=0.100000
2017/08/28 17:48:25 step 2: mse=152.210282 step=0.100000
2017/08/28 17:48:26 step 3: mse=149.637937 step=0.100000
2017/08/28 17:48:27 step 4: mse=147.777833 step=0.100000
2017/08/28 17:48:28 step 5: mse=145.960737 step=0.100000
2017/08/28 17:48:29 step 6: mse=144.402633 step=0.100000
2017/08/28 17:48:31 step 7: mse=143.054071 step=0.100000
2017/08/28 17:48:31 Saving...
2017/08/28 17:48:31 Gathering batch of experience...
2017/08/28 17:49:11 batch 450: mean=102.240000 stddev=96.803628 entropy=0.426160 frames=4735 count=50
2017/08/28 17:49:11 Training policy...
2017/08/28 17:49:14 step 0: objective=1.100517
2017/08/28 17:49:16 step 1: objective=1.1112108
2017/08/28 17:49:17 step 2: objective=1.1244795
2017/08/28 17:49:18 step 3: objective=1.1377643
2017/08/28 17:49:19 step 4: objective=1.1497593
2017/08/28 17:49:20 step 5: objective=1.15516
2017/08/28 17:49:22 step 6: objective=1.1591064
2017/08/28 17:49:23 step 7: objective=1.1645077
2017/08/28 17:49:23 Training value function...
2017/08/28 17:49:25 step 0: mse=189.314872 step=0.100000
2017/08/28 17:49:26 step 1: mse=185.060866 step=0.100000
2017/08/28 17:49:27 step 2: mse=182.189434 step=0.100000
2017/08/28 17:49:28 step 3: mse=179.204315 step=0.100000
2017/08/28 17:49:29 step 4: mse=176.175764 step=0.100000
2017/08/28 17:49:30 step 5: mse=173.961729 step=0.100000
2017/08/28 17:49:31 step 6: mse=171.737684 step=0.100000
2017/08/28 17:49:32 step 7: mse=169.717775 step=0.100000
2017/08/28 17:49:32 Saving...
2017/08/28 17:49:32 Gathering batch of experience...
2017/08/28 17:50:19 batch 451: mean=112.076923 stddev=112.667456 entropy=0.434579 frames=5565 count=52
2017/08/28 17:50:19 Training policy...
2017/08/28 17:50:23 step 0: objective=1.1892294
2017/08/28 17:50:25 step 1: objective=1.1996716
2017/08/28 17:50:26 step 2: objective=1.2104547
2017/08/28 17:50:27 step 3: objective=1.2185981
2017/08/28 17:50:29 step 4: objective=1.2260695
2017/08/28 17:50:30 step 5: objective=1.230979
2017/08/28 17:50:32 step 6: objective=1.2378298
2017/08/28 17:50:33 step 7: objective=1.2422035
2017/08/28 17:50:33 Training value function...
2017/08/28 17:50:35 step 0: mse=187.177450 step=0.100000
2017/08/28 17:50:36 step 1: mse=184.010927 step=0.100000
2017/08/28 17:50:38 step 2: mse=181.263662 step=0.100000
2017/08/28 17:50:39 step 3: mse=178.852976 step=0.100000
2017/08/28 17:50:40 step 4: mse=177.017943 step=0.100000
2017/08/28 17:50:41 step 5: mse=175.142493 step=0.100000
2017/08/28 17:50:42 step 6: mse=173.478856 step=0.100000
2017/08/28 17:50:43 step 7: mse=171.985808 step=0.100000
2017/08/28 17:50:43 Saving...
2017/08/28 17:50:44 Gathering batch of experience...
2017/08/28 17:51:32 batch 452: mean=78.272727 stddev=69.587430 entropy=0.428160 frames=5193 count=66
2017/08/28 17:51:32 Training policy...
2017/08/28 17:51:36 step 0: objective=-0.61808014
2017/08/28 17:51:37 step 1: objective=-0.60354024
2017/08/28 17:51:39 step 2: objective=-0.5916065
2017/08/28 17:51:40 step 3: objective=-0.58596075
2017/08/28 17:51:41 step 4: objective=-0.5789985
2017/08/28 17:51:43 step 5: objective=-0.57367486
2017/08/28 17:51:44 step 6: objective=-0.5631749
2017/08/28 17:51:45 step 7: objective=-0.5570598
2017/08/28 17:51:45 Training value function...
2017/08/28 17:51:47 step 0: mse=157.270534 step=0.100000
2017/08/28 17:51:48 step 1: mse=154.531010 step=0.100000
2017/08/28 17:51:49 step 2: mse=152.160684 step=0.100000
2017/08/28 17:51:51 step 3: mse=150.607193 step=0.100000
2017/08/28 17:51:52 step 4: mse=149.022503 step=0.100000
2017/08/28 17:51:53 step 5: mse=147.894305 step=0.100000
2017/08/28 17:51:54 step 6: mse=146.803508 step=0.100000
2017/08/28 17:51:55 step 7: mse=145.961012 step=0.100000
2017/08/28 17:51:55 Saving...
2017/08/28 17:51:55 Gathering batch of experience...
2017/08/28 17:52:46 batch 453: mean=92.766667 stddev=89.756591 entropy=0.432794 frames=5549 count=60
2017/08/28 17:52:46 Training policy...
2017/08/28 17:52:50 step 0: objective=0.9698699
2017/08/28 17:52:51 step 1: objective=0.9774081
2017/08/28 17:52:53 step 2: objective=0.98870796
2017/08/28 17:52:54 step 3: objective=0.9948246
2017/08/28 17:52:56 step 4: objective=1.0050758
2017/08/28 17:52:57 step 5: objective=1.010879
2017/08/28 17:52:58 step 6: objective=1.0201365
2017/08/28 17:53:00 step 7: objective=1.0233463
2017/08/28 17:53:00 Training value function...
2017/08/28 17:53:02 step 0: mse=161.376355 step=0.100000
2017/08/28 17:53:03 step 1: mse=159.825644 step=0.100000
2017/08/28 17:53:04 step 2: mse=158.405449 step=0.100000
2017/08/28 17:53:05 step 3: mse=157.027946 step=0.100000
2017/08/28 17:53:07 step 4: mse=155.673143 step=0.100000
2017/08/28 17:53:08 step 5: mse=154.247817 step=0.100000
2017/08/28 17:53:09 step 6: mse=153.095545 step=0.100000
2017/08/28 17:53:10 step 7: mse=151.908680 step=0.100000
2017/08/28 17:53:10 Saving...
2017/08/28 17:53:10 Gathering batch of experience...
2017/08/28 17:53:51 batch 454: mean=97.979592 stddev=62.035372 entropy=0.425032 frames=4794 count=49
2017/08/28 17:53:51 Training policy...
2017/08/28 17:53:54 step 0: objective=0.96065474
2017/08/28 17:53:56 step 1: objective=0.96857643
2017/08/28 17:53:57 step 2: objective=0.9797253
2017/08/28 17:53:58 step 3: objective=0.9914686
2017/08/28 17:53:59 step 4: objective=0.9971502
2017/08/28 17:54:01 step 5: objective=1.004686
2017/08/28 17:54:02 step 6: objective=1.0098562
2017/08/28 17:54:03 step 7: objective=1.0170974
2017/08/28 17:54:03 Training value function...
2017/08/28 17:54:05 step 0: mse=161.130503 step=0.100000
2017/08/28 17:54:06 step 1: mse=156.882120 step=0.100000
2017/08/28 17:54:07 step 2: mse=153.271999 step=0.100000
2017/08/28 17:54:08 step 3: mse=150.281605 step=0.100000
2017/08/28 17:54:09 step 4: mse=147.649649 step=0.100000
2017/08/28 17:54:10 step 5: mse=145.500007 step=0.100000
2017/08/28 17:54:11 step 6: mse=143.534036 step=0.100000
2017/08/28 17:54:12 step 7: mse=141.815896 step=0.100000
2017/08/28 17:54:12 Saving...
2017/08/28 17:54:12 Gathering batch of experience...
2017/08/28 17:54:59 batch 455: mean=85.349206 stddev=77.594624 entropy=0.416503 frames=5212 count=63
2017/08/28 17:54:59 Training policy...
2017/08/28 17:55:02 step 0: objective=0.9109488
2017/08/28 17:55:04 step 1: objective=0.91978014
2017/08/28 17:55:05 step 2: objective=0.9324451
2017/08/28 17:55:06 step 3: objective=0.9396579
2017/08/28 17:55:08 step 4: objective=0.9501731
2017/08/28 17:55:09 step 5: objective=0.9571407
2017/08/28 17:55:10 step 6: objective=0.96387833
2017/08/28 17:55:12 step 7: objective=0.9670794
2017/08/28 17:55:12 Training value function...
2017/08/28 17:55:14 step 0: mse=193.260787 step=0.100000
2017/08/28 17:55:15 step 1: mse=190.808577 step=0.100000
2017/08/28 17:55:16 step 2: mse=188.551876 step=0.100000
2017/08/28 17:55:17 step 3: mse=186.685752 step=0.100000
2017/08/28 17:55:18 step 4: mse=184.705226 step=0.100000
2017/08/28 17:55:19 step 5: mse=182.881572 step=0.100000
2017/08/28 17:55:20 step 6: mse=181.669217 step=0.100000
2017/08/28 17:55:21 step 7: mse=180.018354 step=0.100000
2017/08/28 17:55:21 Saving...
2017/08/28 17:55:21 Gathering batch of experience...
2017/08/28 17:56:03 batch 456: mean=106.914894 stddev=84.928212 entropy=0.429287 frames=5022 count=47
2017/08/28 17:56:03 Training policy...
2017/08/28 17:56:06 step 0: objective=1.389276
2017/08/28 17:56:08 step 1: objective=1.3961524
2017/08/28 17:56:09 step 2: objective=1.402643
2017/08/28 17:56:10 step 3: objective=1.4086463
2017/08/28 17:56:11 step 4: objective=1.4159889
2017/08/28 17:56:13 step 5: objective=1.4227217
2017/08/28 17:56:14 step 6: objective=1.4308679
2017/08/28 17:56:15 step 7: objective=1.4358557
2017/08/28 17:56:15 Training value function...
2017/08/28 17:56:17 step 0: mse=176.983085 step=0.100000
2017/08/28 17:56:18 step 1: mse=173.813868 step=0.100000
2017/08/28 17:56:19 step 2: mse=171.058426 step=0.100000
2017/08/28 17:56:20 step 3: mse=168.957087 step=0.100000
2017/08/28 17:56:21 step 4: mse=166.769268 step=0.100000
2017/08/28 17:56:22 step 5: mse=164.872870 step=0.100000
2017/08/28 17:56:23 step 6: mse=163.110351 step=0.100000
2017/08/28 17:56:25 step 7: mse=161.762871 step=0.100000
2017/08/28 17:56:25 Saving...
2017/08/28 17:56:25 Gathering batch of experience...
2017/08/28 17:57:14 batch 457: mean=85.193548 stddev=86.579227 entropy=0.430304 frames=5200 count=62
2017/08/28 17:57:14 Training policy...
2017/08/28 17:57:18 step 0: objective=0.85839224
2017/08/28 17:57:19 step 1: objective=0.87012875
2017/08/28 17:57:21 step 2: objective=0.8776865
2017/08/28 17:57:22 step 3: objective=0.88254863
2017/08/28 17:57:23 step 4: objective=0.88823026
2017/08/28 17:57:25 step 5: objective=0.8936436
2017/08/28 17:57:26 step 6: objective=0.89948964
2017/08/28 17:57:27 step 7: objective=0.9039834
2017/08/28 17:57:27 Training value function...
2017/08/28 17:57:29 step 0: mse=173.430471 step=0.100000
2017/08/28 17:57:30 step 1: mse=171.743047 step=0.100000
2017/08/28 17:57:32 step 2: mse=169.744518 step=0.100000
2017/08/28 17:57:33 step 3: mse=168.350423 step=0.100000
2017/08/28 17:57:34 step 4: mse=166.878081 step=0.100000
2017/08/28 17:57:35 step 5: mse=165.771750 step=0.100000
2017/08/28 17:57:36 step 6: mse=164.560414 step=0.100000
2017/08/28 17:57:37 step 7: mse=163.383140 step=0.100000
2017/08/28 17:57:37 Saving...
2017/08/28 17:57:37 Gathering batch of experience...
2017/08/28 17:58:20 batch 458: mean=106.562500 stddev=88.910045 entropy=0.428555 frames=5122 count=48
2017/08/28 17:58:20 Training policy...
2017/08/28 17:58:24 step 0: objective=1.1267787
2017/08/28 17:58:25 step 1: objective=1.1386651
2017/08/28 17:58:26 step 2: objective=1.1438692
2017/08/28 17:58:28 step 3: objective=1.150784
2017/08/28 17:58:29 step 4: objective=1.1566821
2017/08/28 17:58:30 step 5: objective=1.1648113
2017/08/28 17:58:31 step 6: objective=1.1697093
2017/08/28 17:58:33 step 7: objective=1.175349
2017/08/28 17:58:33 Training value function...
2017/08/28 17:58:35 step 0: mse=157.014157 step=0.100000
2017/08/28 17:58:36 step 1: mse=154.618790 step=0.100000
2017/08/28 17:58:37 step 2: mse=152.796183 step=0.100000
2017/08/28 17:58:38 step 3: mse=151.170238 step=0.100000
2017/08/28 17:58:39 step 4: mse=149.593534 step=0.100000
2017/08/28 17:58:40 step 5: mse=148.238208 step=0.100000
2017/08/28 17:58:41 step 6: mse=146.936813 step=0.100000
2017/08/28 17:58:42 step 7: mse=145.767894 step=0.100000
2017/08/28 17:58:42 Saving...
2017/08/28 17:58:42 Gathering batch of experience...
2017/08/28 17:59:28 batch 459: mean=71.571429 stddev=61.448059 entropy=0.426585 frames=4659 count=63
2017/08/28 17:59:28 Training policy...
2017/08/28 17:59:31 step 0: objective=-0.2851847
2017/08/28 17:59:32 step 1: objective=-0.26998958
2017/08/28 17:59:33 step 2: objective=-0.2581273
2017/08/28 17:59:35 step 3: objective=-0.24576066
2017/08/28 17:59:36 step 4: objective=-0.23629372
2017/08/28 17:59:37 step 5: objective=-0.23009591
2017/08/28 17:59:38 step 6: objective=-0.22448389
2017/08/28 17:59:39 step 7: objective=-0.22085357
2017/08/28 17:59:39 Training value function...
2017/08/28 17:59:41 step 0: mse=162.855349 step=0.100000
2017/08/28 17:59:42 step 1: mse=161.072193 step=0.100000
2017/08/28 17:59:43 step 2: mse=159.486500 step=0.100000
2017/08/28 17:59:44 step 3: mse=158.348259 step=0.100000
2017/08/28 17:59:45 step 4: mse=157.150805 step=0.100000
2017/08/28 17:59:46 step 5: mse=156.029310 step=0.100000
2017/08/28 17:59:47 step 6: mse=155.090108 step=0.100000
2017/08/28 17:59:48 step 7: mse=154.210475 step=0.100000
2017/08/28 17:59:48 Saving...
2017/08/28 17:59:48 Gathering batch of experience...
2017/08/28 18:00:35 batch 460: mean=92.222222 stddev=83.118315 entropy=0.424725 frames=5070 count=54
2017/08/28 18:00:35 Training policy...
2017/08/28 18:00:39 step 0: objective=1.4041603
2017/08/28 18:00:40 step 1: objective=1.4144833
2017/08/28 18:00:41 step 2: objective=1.4282235
2017/08/28 18:00:42 step 3: objective=1.4340166
2017/08/28 18:00:44 step 4: objective=1.43929
2017/08/28 18:00:45 step 5: objective=1.4429923
2017/08/28 18:00:46 step 6: objective=1.4497014
2017/08/28 18:00:47 step 7: objective=1.4528902
2017/08/28 18:00:47 Training value function...
2017/08/28 18:00:50 step 0: mse=183.766506 step=0.100000
2017/08/28 18:00:51 step 1: mse=180.109357 step=0.100000
2017/08/28 18:00:52 step 2: mse=176.637375 step=0.100000
2017/08/28 18:00:53 step 3: mse=173.755967 step=0.100000
2017/08/28 18:00:54 step 4: mse=171.494602 step=0.100000
2017/08/28 18:00:55 step 5: mse=169.386219 step=0.100000
2017/08/28 18:00:56 step 6: mse=167.502173 step=0.100000
2017/08/28 18:00:57 step 7: mse=165.455694 step=0.100000
2017/08/28 18:00:57 Saving...
2017/08/28 18:00:57 Gathering batch of experience...
2017/08/28 18:01:41 batch 461: mean=97.039216 stddev=101.732437 entropy=0.431170 frames=4971 count=51
2017/08/28 18:01:41 Training policy...
2017/08/28 18:01:44 step 0: objective=1.5117977
2017/08/28 18:01:45 step 1: objective=1.5215731
2017/08/28 18:01:46 step 2: objective=1.5303711
2017/08/28 18:01:48 step 3: objective=1.5366238
2017/08/28 18:01:49 step 4: objective=1.5460036
2017/08/28 18:01:50 step 5: objective=1.5525898
2017/08/28 18:01:51 step 6: objective=1.5560371
2017/08/28 18:01:53 step 7: objective=1.5618502
2017/08/28 18:01:53 Training value function...
2017/08/28 18:01:55 step 0: mse=186.877238 step=0.100000
2017/08/28 18:01:56 step 1: mse=182.786593 step=0.100000
2017/08/28 18:01:57 step 2: mse=179.377489 step=0.100000
2017/08/28 18:01:58 step 3: mse=176.340819 step=0.100000
2017/08/28 18:01:59 step 4: mse=173.668320 step=0.100000
2017/08/28 18:02:00 step 5: mse=171.555850 step=0.100000
2017/08/28 18:02:01 step 6: mse=169.758796 step=0.100000
2017/08/28 18:02:02 step 7: mse=167.686986 step=0.100000
2017/08/28 18:02:02 Saving...
2017/08/28 18:02:02 Gathering batch of experience...
2017/08/28 18:02:45 batch 462: mean=103.857143 stddev=91.969161 entropy=0.435480 frames=4961 count=49
2017/08/28 18:02:45 Training policy...
2017/08/28 18:02:49 step 0: objective=1.5837684
2017/08/28 18:02:50 step 1: objective=1.5940279
2017/08/28 18:02:51 step 2: objective=1.601661
2017/08/28 18:02:52 step 3: objective=1.6079365
2017/08/28 18:02:54 step 4: objective=1.6199735
2017/08/28 18:02:55 step 5: objective=1.6281654
2017/08/28 18:02:56 step 6: objective=1.6373721
2017/08/28 18:02:57 step 7: objective=1.6405739
2017/08/28 18:02:57 Training value function...
2017/08/28 18:03:00 step 0: mse=182.799507 step=0.100000
2017/08/28 18:03:01 step 1: mse=179.118748 step=0.100000
2017/08/28 18:03:02 step 2: mse=176.091808 step=0.100000
2017/08/28 18:03:03 step 3: mse=173.353461 step=0.100000
2017/08/28 18:03:04 step 4: mse=170.820615 step=0.100000
2017/08/28 18:03:05 step 5: mse=168.406621 step=0.100000
2017/08/28 18:03:06 step 6: mse=166.784191 step=0.100000
2017/08/28 18:03:07 step 7: mse=164.871301 step=0.100000
2017/08/28 18:03:07 Saving...
2017/08/28 18:03:07 Gathering batch of experience...
2017/08/28 18:03:52 batch 463: mean=157.078947 stddev=109.873463 entropy=0.427287 frames=5577 count=38
2017/08/28 18:03:52 Training policy...
2017/08/28 18:03:56 step 0: objective=2.3920965
2017/08/28 18:03:57 step 1: objective=2.4012043
2017/08/28 18:03:58 step 2: objective=2.407424
2017/08/28 18:04:00 step 3: objective=2.4174054
2017/08/28 18:04:01 step 4: objective=2.4250035
2017/08/28 18:04:03 step 5: objective=2.4280217
2017/08/28 18:04:04 step 6: objective=2.431262
2017/08/28 18:04:05 step 7: objective=2.436539
2017/08/28 18:04:05 Training value function...
2017/08/28 18:04:08 step 0: mse=180.479099 step=0.100000
2017/08/28 18:04:09 step 1: mse=174.692831 step=0.100000
2017/08/28 18:04:10 step 2: mse=170.018153 step=0.100000
2017/08/28 18:04:11 step 3: mse=165.940893 step=0.100000
2017/08/28 18:04:12 step 4: mse=162.316249 step=0.100000
2017/08/28 18:04:14 step 5: mse=159.141745 step=0.100000
2017/08/28 18:04:15 step 6: mse=156.495251 step=0.100000
2017/08/28 18:04:16 step 7: mse=154.112115 step=0.100000
2017/08/28 18:04:16 Saving...
2017/08/28 18:04:16 Gathering batch of experience...
2017/08/28 18:05:00 batch 464: mean=102.196078 stddev=89.318557 entropy=0.424768 frames=5031 count=51
2017/08/28 18:05:00 Training policy...
2017/08/28 18:05:03 step 0: objective=0.18777753
2017/08/28 18:05:04 step 1: objective=0.19599515
2017/08/28 18:05:06 step 2: objective=0.20395324
2017/08/28 18:05:07 step 3: objective=0.20939006
2017/08/28 18:05:08 step 4: objective=0.22000414
2017/08/28 18:05:09 step 5: objective=0.23081905
2017/08/28 18:05:11 step 6: objective=0.2351082
2017/08/28 18:05:12 step 7: objective=0.24172474
2017/08/28 18:05:12 Training value function...
2017/08/28 18:05:14 step 0: mse=177.447336 step=0.100000
2017/08/28 18:05:15 step 1: mse=174.285580 step=0.100000
2017/08/28 18:05:16 step 2: mse=172.030468 step=0.100000
2017/08/28 18:05:17 step 3: mse=170.157619 step=0.100000
2017/08/28 18:05:18 step 4: mse=168.239512 step=0.100000
2017/08/28 18:05:19 step 5: mse=166.446255 step=0.100000
2017/08/28 18:05:20 step 6: mse=165.134505 step=0.100000
2017/08/28 18:05:21 step 7: mse=163.880325 step=0.100000
2017/08/28 18:05:21 Saving...
2017/08/28 18:05:21 Gathering batch of experience...
2017/08/28 18:06:06 batch 465: mean=99.760000 stddev=85.884704 entropy=0.421690 frames=5127 count=50
2017/08/28 18:06:06 Training policy...
2017/08/28 18:06:09 step 0: objective=-0.09338422
2017/08/28 18:06:10 step 1: objective=-0.08314402
2017/08/28 18:06:12 step 2: objective=-0.076255016
2017/08/28 18:06:13 step 3: objective=-0.0698968
2017/08/28 18:06:14 step 4: objective=-0.060733046
2017/08/28 18:06:16 step 5: objective=-0.05418032
2017/08/28 18:06:17 step 6: objective=-0.048604038
2017/08/28 18:06:18 step 7: objective=-0.045072075
2017/08/28 18:06:18 Training value function...
2017/08/28 18:06:20 step 0: mse=149.827288 step=0.100000
2017/08/28 18:06:21 step 1: mse=147.869689 step=0.100000
2017/08/28 18:06:22 step 2: mse=146.087806 step=0.100000
2017/08/28 18:06:24 step 3: mse=144.666793 step=0.100000
2017/08/28 18:06:25 step 4: mse=143.228850 step=0.100000
2017/08/28 18:06:26 step 5: mse=141.855509 step=0.100000
2017/08/28 18:06:27 step 6: mse=140.542241 step=0.100000
2017/08/28 18:06:28 step 7: mse=139.330069 step=0.100000
2017/08/28 18:06:28 Saving...
2017/08/28 18:06:28 Gathering batch of experience...
2017/08/28 18:07:11 batch 466: mean=82.872727 stddev=65.668328 entropy=0.422810 frames=4743 count=55
2017/08/28 18:07:11 Training policy...
2017/08/28 18:07:14 step 0: objective=-0.1532481
2017/08/28 18:07:16 step 1: objective=-0.1446768
2017/08/28 18:07:17 step 2: objective=-0.13344629
2017/08/28 18:07:18 step 3: objective=-0.12753488
2017/08/28 18:07:19 step 4: objective=-0.12127916
2017/08/28 18:07:20 step 5: objective=-0.11555769
2017/08/28 18:07:22 step 6: objective=-0.10919901
2017/08/28 18:07:23 step 7: objective=-0.10599607
2017/08/28 18:07:23 Training value function...
2017/08/28 18:07:25 step 0: mse=153.516949 step=0.100000
2017/08/28 18:07:26 step 1: mse=151.665377 step=0.100000
2017/08/28 18:07:27 step 2: mse=150.002544 step=0.100000
2017/08/28 18:07:28 step 3: mse=148.637302 step=0.100000
2017/08/28 18:07:29 step 4: mse=147.860480 step=0.100000
2017/08/28 18:07:30 step 5: mse=146.880564 step=0.100000
2017/08/28 18:07:31 step 6: mse=146.038281 step=0.100000
2017/08/28 18:07:32 step 7: mse=145.082552 step=0.100000
2017/08/28 18:07:32 Saving...
2017/08/28 18:07:32 Gathering batch of experience...
2017/08/28 18:08:15 batch 467: mean=100.750000 stddev=73.395890 entropy=0.420133 frames=4784 count=52
2017/08/28 18:08:15 Training policy...
2017/08/28 18:08:19 step 0: objective=2.15071
2017/08/28 18:08:20 step 1: objective=2.1568978
2017/08/28 18:08:21 step 2: objective=2.1685247
2017/08/28 18:08:22 step 3: objective=2.1780643
2017/08/28 18:08:23 step 4: objective=2.1831055
2017/08/28 18:08:25 step 5: objective=2.1897647
2017/08/28 18:08:26 step 6: objective=2.1954873
2017/08/28 18:08:27 step 7: objective=2.204508
2017/08/28 18:08:27 Training value function...
2017/08/28 18:08:29 step 0: mse=198.296105 step=0.100000
2017/08/28 18:08:30 step 1: mse=194.076956 step=0.100000
2017/08/28 18:08:31 step 2: mse=190.140642 step=0.100000
2017/08/28 18:08:32 step 3: mse=186.847802 step=0.100000
2017/08/28 18:08:33 step 4: mse=183.746461 step=0.100000
2017/08/28 18:08:34 step 5: mse=181.030703 step=0.100000
2017/08/28 18:08:35 step 6: mse=178.580466 step=0.100000
2017/08/28 18:08:36 step 7: mse=176.646346 step=0.100000
2017/08/28 18:08:36 Saving...
2017/08/28 18:08:36 Gathering batch of experience...
2017/08/28 18:09:21 batch 468: mean=103.603774 stddev=87.482686 entropy=0.424921 frames=5185 count=53
2017/08/28 18:09:21 Training policy...
2017/08/28 18:09:24 step 0: objective=1.7474853
2017/08/28 18:09:26 step 1: objective=1.7521545
2017/08/28 18:09:27 step 2: objective=1.7635114
2017/08/28 18:09:28 step 3: objective=1.768061
2017/08/28 18:09:30 step 4: objective=1.7726675
2017/08/28 18:09:31 step 5: objective=1.779129
2017/08/28 18:09:32 step 6: objective=1.7832538
2017/08/28 18:09:34 step 7: objective=1.7879083
2017/08/28 18:09:34 Training value function...
2017/08/28 18:09:36 step 0: mse=187.678021 step=0.100000
2017/08/28 18:09:37 step 1: mse=184.024121 step=0.100000
2017/08/28 18:09:38 step 2: mse=180.744249 step=0.100000
2017/08/28 18:09:39 step 3: mse=177.843566 step=0.100000
2017/08/28 18:09:40 step 4: mse=175.046187 step=0.100000
2017/08/28 18:09:41 step 5: mse=172.816166 step=0.100000
2017/08/28 18:09:42 step 6: mse=170.439605 step=0.100000
2017/08/28 18:09:43 step 7: mse=168.479741 step=0.100000
2017/08/28 18:09:43 Saving...
2017/08/28 18:09:43 Gathering batch of experience...
2017/08/28 18:10:26 batch 469: mean=85.636364 stddev=77.624823 entropy=0.418531 frames=4567 count=55
2017/08/28 18:10:26 Training policy...
2017/08/28 18:10:29 step 0: objective=0.19865553
2017/08/28 18:10:30 step 1: objective=0.20627719
2017/08/28 18:10:31 step 2: objective=0.21679048
2017/08/28 18:10:32 step 3: objective=0.23187305
2017/08/28 18:10:33 step 4: objective=0.23990847
2017/08/28 18:10:35 step 5: objective=0.24672896
2017/08/28 18:10:36 step 6: objective=0.25028935
2017/08/28 18:10:37 step 7: objective=0.25432566
2017/08/28 18:10:37 Training value function...
2017/08/28 18:10:39 step 0: mse=167.309604 step=0.100000
2017/08/28 18:10:40 step 1: mse=165.505297 step=0.100000
2017/08/28 18:10:41 step 2: mse=164.094794 step=0.100000
2017/08/28 18:10:42 step 3: mse=162.697594 step=0.100000
2017/08/28 18:10:43 step 4: mse=161.505509 step=0.100000
2017/08/28 18:10:44 step 5: mse=160.108045 step=0.100000
2017/08/28 18:10:44 step 6: mse=158.769954 step=0.100000
2017/08/28 18:10:45 step 7: mse=157.317617 step=0.100000
2017/08/28 18:10:45 Saving...
2017/08/28 18:10:45 Gathering batch of experience...
2017/08/28 18:11:36 batch 470: mean=92.393443 stddev=89.077104 entropy=0.414995 frames=5262 count=61
2017/08/28 18:11:36 Training policy...
2017/08/28 18:11:39 step 0: objective=1.2685629
2017/08/28 18:11:41 step 1: objective=1.2754183
2017/08/28 18:11:42 step 2: objective=1.2844096
2017/08/28 18:11:43 step 3: objective=1.2930145
2017/08/28 18:11:45 step 4: objective=1.3002607
2017/08/28 18:11:46 step 5: objective=1.3092586
2017/08/28 18:11:47 step 6: objective=1.3158654
2017/08/28 18:11:49 step 7: objective=1.320082
2017/08/28 18:11:49 Training value function...
2017/08/28 18:11:51 step 0: mse=188.546027 step=0.100000
2017/08/28 18:11:52 step 1: mse=184.801010 step=0.100000
2017/08/28 18:11:53 step 2: mse=180.015616 step=0.100000
2017/08/28 18:11:54 step 3: mse=177.524479 step=0.100000
2017/08/28 18:11:55 step 4: mse=175.350900 step=0.100000
2017/08/28 18:11:56 step 5: mse=171.926196 step=0.100000
2017/08/28 18:11:58 step 6: mse=169.943011 step=0.100000
2017/08/28 18:11:59 step 7: mse=168.536376 step=0.100000
2017/08/28 18:11:59 Saving...
2017/08/28 18:11:59 Gathering batch of experience...
2017/08/28 18:12:43 batch 471: mean=103.680000 stddev=87.148710 entropy=0.421003 frames=4972 count=50
2017/08/28 18:12:43 Training policy...
2017/08/28 18:12:46 step 0: objective=1.3057406
2017/08/28 18:12:47 step 1: objective=1.3172739
2017/08/28 18:12:49 step 2: objective=1.327648
2017/08/28 18:12:50 step 3: objective=1.3399563
2017/08/28 18:12:51 step 4: objective=1.3452715
2017/08/28 18:12:52 step 5: objective=1.3528143
2017/08/28 18:12:54 step 6: objective=1.3559406
2017/08/28 18:12:55 step 7: objective=1.3604244
2017/08/28 18:12:55 Training value function...
2017/08/28 18:12:57 step 0: mse=183.094234 step=0.100000
2017/08/28 18:12:58 step 1: mse=180.380698 step=0.100000
2017/08/28 18:12:59 step 2: mse=178.322579 step=0.100000
2017/08/28 18:13:00 step 3: mse=175.844214 step=0.100000
2017/08/28 18:13:01 step 4: mse=174.029275 step=0.100000
2017/08/28 18:13:02 step 5: mse=172.427577 step=0.100000
2017/08/28 18:13:03 step 6: mse=170.816398 step=0.100000
2017/08/28 18:13:04 step 7: mse=169.193366 step=0.100000
2017/08/28 18:13:04 Saving...
2017/08/28 18:13:04 Gathering batch of experience...
2017/08/28 18:13:50 batch 472: mean=97.000000 stddev=71.006197 entropy=0.426774 frames=4994 count=50
2017/08/28 18:13:50 Training policy...
2017/08/28 18:13:53 step 0: objective=0.27845842
2017/08/28 18:13:54 step 1: objective=0.28730774
2017/08/28 18:13:56 step 2: objective=0.29370293
2017/08/28 18:13:57 step 3: objective=0.30074465
2017/08/28 18:13:58 step 4: objective=0.3090758
2017/08/28 18:13:59 step 5: objective=0.31436497
2017/08/28 18:14:01 step 6: objective=0.3202678
2017/08/28 18:14:02 step 7: objective=0.32587478
2017/08/28 18:14:02 Training value function...
2017/08/28 18:14:04 step 0: mse=147.658330 step=0.100000
2017/08/28 18:14:05 step 1: mse=145.938469 step=0.100000
2017/08/28 18:14:06 step 2: mse=144.295028 step=0.100000
2017/08/28 18:14:07 step 3: mse=143.052395 step=0.100000
2017/08/28 18:14:08 step 4: mse=142.060479 step=0.100000
2017/08/28 18:14:09 step 5: mse=141.142907 step=0.100000
2017/08/28 18:14:10 step 6: mse=140.283741 step=0.100000
2017/08/28 18:14:11 step 7: mse=139.342234 step=0.100000
2017/08/28 18:14:11 Saving...
2017/08/28 18:14:11 Gathering batch of experience...
2017/08/28 18:14:58 batch 473: mean=87.606557 stddev=80.342969 entropy=0.416335 frames=5144 count=61
2017/08/28 18:14:58 Training policy...
2017/08/28 18:15:02 step 0: objective=1.2188947
2017/08/28 18:15:03 step 1: objective=1.2273276
2017/08/28 18:15:04 step 2: objective=1.2363096
2017/08/28 18:15:06 step 3: objective=1.2476447
2017/08/28 18:15:07 step 4: objective=1.2549542
2017/08/28 18:15:08 step 5: objective=1.2615882
2017/08/28 18:15:10 step 6: objective=1.2698798
2017/08/28 18:15:11 step 7: objective=1.2746965
2017/08/28 18:15:11 Training value function...
2017/08/28 18:15:13 step 0: mse=188.963693 step=0.100000
2017/08/28 18:15:14 step 1: mse=186.539787 step=0.100000
2017/08/28 18:15:15 step 2: mse=183.917498 step=0.100000
2017/08/28 18:15:16 step 3: mse=181.805647 step=0.100000
2017/08/28 18:15:17 step 4: mse=180.237724 step=0.100000
2017/08/28 18:15:18 step 5: mse=178.876492 step=0.100000
2017/08/28 18:15:19 step 6: mse=176.972421 step=0.100000
2017/08/28 18:15:21 step 7: mse=175.387522 step=0.100000
2017/08/28 18:15:21 Saving...
2017/08/28 18:15:21 Gathering batch of experience...
2017/08/28 18:16:10 batch 474: mean=85.400000 stddev=81.908933 entropy=0.425067 frames=5148 count=60
2017/08/28 18:16:10 Training policy...
2017/08/28 18:16:13 step 0: objective=0.42132616
2017/08/28 18:16:14 step 1: objective=0.4277305
2017/08/28 18:16:16 step 2: objective=0.4372472
2017/08/28 18:16:17 step 3: objective=0.44307953
2017/08/28 18:16:18 step 4: objective=0.4480864
2017/08/28 18:16:20 step 5: objective=0.45304543
2017/08/28 18:16:21 step 6: objective=0.45786026
2017/08/28 18:16:22 step 7: objective=0.46184686
2017/08/28 18:16:22 Training value function...
2017/08/28 18:16:24 step 0: mse=157.425279 step=0.100000
2017/08/28 18:16:25 step 1: mse=155.875203 step=0.100000
2017/08/28 18:16:26 step 2: mse=154.379878 step=0.100000
2017/08/28 18:16:28 step 3: mse=153.218690 step=0.100000
2017/08/28 18:16:29 step 4: mse=151.957795 step=0.100000
2017/08/28 18:16:30 step 5: mse=150.856752 step=0.100000
2017/08/28 18:16:31 step 6: mse=149.979657 step=0.100000
2017/08/28 18:16:32 step 7: mse=149.010315 step=0.100000
2017/08/28 18:16:32 Saving...
2017/08/28 18:16:32 Gathering batch of experience...
2017/08/28 18:17:16 batch 475: mean=134.214286 stddev=122.508219 entropy=0.425374 frames=5347 count=42
2017/08/28 18:17:16 Training policy...
2017/08/28 18:17:20 step 0: objective=2.6129694
2017/08/28 18:17:21 step 1: objective=2.6221263
2017/08/28 18:17:23 step 2: objective=2.6303651
2017/08/28 18:17:24 step 3: objective=2.6357195
2017/08/28 18:17:25 step 4: objective=2.6408067
2017/08/28 18:17:27 step 5: objective=2.647788
2017/08/28 18:17:28 step 6: objective=2.6533475
2017/08/28 18:17:29 step 7: objective=2.6580749
2017/08/28 18:17:29 Training value function...
2017/08/28 18:17:32 step 0: mse=216.671444 step=0.100000
2017/08/28 18:17:33 step 1: mse=210.084074 step=0.100000
2017/08/28 18:17:34 step 2: mse=203.930082 step=0.100000
2017/08/28 18:17:35 step 3: mse=198.889533 step=0.100000
2017/08/28 18:17:36 step 4: mse=194.386743 step=0.100000
2017/08/28 18:17:37 step 5: mse=190.533920 step=0.100000
2017/08/28 18:17:38 step 6: mse=186.963451 step=0.100000
2017/08/28 18:17:40 step 7: mse=184.115619 step=0.100000
2017/08/28 18:17:40 Saving...
2017/08/28 18:17:40 Gathering batch of experience...
2017/08/28 18:18:23 batch 476: mean=106.166667 stddev=97.191892 entropy=0.417403 frames=5012 count=48
2017/08/28 18:18:23 Training policy...
2017/08/28 18:18:26 step 0: objective=0.62870497
2017/08/28 18:18:28 step 1: objective=0.6368436
2017/08/28 18:18:29 step 2: objective=0.6428888
2017/08/28 18:18:30 step 3: objective=0.6484412
2017/08/28 18:18:31 step 4: objective=0.65310293
2017/08/28 18:18:33 step 5: objective=0.6598604
2017/08/28 18:18:34 step 6: objective=0.66875434
2017/08/28 18:18:35 step 7: objective=0.6737396
2017/08/28 18:18:35 Training value function...
2017/08/28 18:18:37 step 0: mse=166.919134 step=0.100000
2017/08/28 18:18:38 step 1: mse=165.076563 step=0.100000
2017/08/28 18:18:39 step 2: mse=163.506958 step=0.100000
2017/08/28 18:18:40 step 3: mse=161.849438 step=0.100000
2017/08/28 18:18:41 step 4: mse=160.600664 step=0.100000
2017/08/28 18:18:43 step 5: mse=159.810057 step=0.100000
2017/08/28 18:18:44 step 6: mse=158.824614 step=0.100000
2017/08/28 18:18:45 step 7: mse=158.186361 step=0.100000
2017/08/28 18:18:45 Saving...
2017/08/28 18:18:45 Gathering batch of experience...
2017/08/28 18:19:33 batch 477: mean=91.596491 stddev=87.613357 entropy=0.420125 frames=5203 count=57
2017/08/28 18:19:33 Training policy...
2017/08/28 18:19:36 step 0: objective=0.44339967
2017/08/28 18:19:38 step 1: objective=0.45500675
2017/08/28 18:19:39 step 2: objective=0.46777272
2017/08/28 18:19:40 step 3: objective=0.47589958
2017/08/28 18:19:42 step 4: objective=0.48341957
2017/08/28 18:19:43 step 5: objective=0.4879734
2017/08/28 18:19:44 step 6: objective=0.49164075
2017/08/28 18:19:45 step 7: objective=0.49482894
2017/08/28 18:19:45 Training value function...
2017/08/28 18:19:48 step 0: mse=166.042519 step=0.100000
2017/08/28 18:19:49 step 1: mse=164.913747 step=0.100000
2017/08/28 18:19:50 step 2: mse=164.093020 step=0.100000
2017/08/28 18:19:51 step 3: mse=163.228973 step=0.100000
2017/08/28 18:19:52 step 4: mse=162.043128 step=0.100000
2017/08/28 18:19:53 step 5: mse=161.173215 step=0.100000
2017/08/28 18:19:54 step 6: mse=160.003652 step=0.100000
2017/08/28 18:19:55 step 7: mse=159.034199 step=0.100000
2017/08/28 18:19:55 Saving...
2017/08/28 18:19:55 Gathering batch of experience...
2017/08/28 18:20:35 batch 478: mean=101.816327 stddev=83.070089 entropy=0.410996 frames=4622 count=49
2017/08/28 18:20:35 Training policy...
2017/08/28 18:20:39 step 0: objective=1.5937537
2017/08/28 18:20:40 step 1: objective=1.6081347
2017/08/28 18:20:41 step 2: objective=1.6231731
2017/08/28 18:20:42 step 3: objective=1.6354066
2017/08/28 18:20:43 step 4: objective=1.6461327
2017/08/28 18:20:45 step 5: objective=1.6498615
2017/08/28 18:20:46 step 6: objective=1.6544502
2017/08/28 18:20:47 step 7: objective=1.6600872
2017/08/28 18:20:47 Training value function...
2017/08/28 18:20:49 step 0: mse=198.541196 step=0.100000
2017/08/28 18:20:50 step 1: mse=194.888290 step=0.100000
2017/08/28 18:20:51 step 2: mse=192.231290 step=0.100000
2017/08/28 18:20:52 step 3: mse=189.269651 step=0.100000
2017/08/28 18:20:53 step 4: mse=187.167955 step=0.100000
2017/08/28 18:20:54 step 5: mse=184.725307 step=0.100000
2017/08/28 18:20:55 step 6: mse=182.993163 step=0.100000
2017/08/28 18:20:56 step 7: mse=181.363183 step=0.100000
2017/08/28 18:20:56 Saving...
2017/08/28 18:20:56 Gathering batch of experience...
2017/08/28 18:21:42 batch 479: mean=88.966667 stddev=77.335194 entropy=0.414471 frames=5010 count=60
2017/08/28 18:21:42 Training policy...
2017/08/28 18:21:45 step 0: objective=0.6724003
2017/08/28 18:21:46 step 1: objective=0.6862669
2017/08/28 18:21:48 step 2: objective=0.6971965
2017/08/28 18:21:49 step 3: objective=0.7114832
2017/08/28 18:21:50 step 4: objective=0.71787095
2017/08/28 18:21:52 step 5: objective=0.7235787
2017/08/28 18:21:53 step 6: objective=0.7319662
2017/08/28 18:21:54 step 7: objective=0.7393959
2017/08/28 18:21:54 Training value function...
2017/08/28 18:21:56 step 0: mse=163.652411 step=0.100000
2017/08/28 18:21:57 step 1: mse=162.403999 step=0.100000
2017/08/28 18:21:58 step 2: mse=161.413241 step=0.100000
2017/08/28 18:21:59 step 3: mse=160.574443 step=0.100000
2017/08/28 18:22:00 step 4: mse=159.818824 step=0.100000
2017/08/28 18:22:01 step 5: mse=158.931414 step=0.100000
2017/08/28 18:22:02 step 6: mse=158.332391 step=0.100000
2017/08/28 18:22:03 step 7: mse=157.341807 step=0.100000
2017/08/28 18:22:03 Saving...
2017/08/28 18:22:03 Gathering batch of experience...
2017/08/28 18:22:46 batch 480: mean=96.076923 stddev=86.799913 entropy=0.426081 frames=4922 count=52
2017/08/28 18:22:46 Training policy...
2017/08/28 18:22:50 step 0: objective=0.94117165
2017/08/28 18:22:51 step 1: objective=0.94643945
2017/08/28 18:22:52 step 2: objective=0.95405287
2017/08/28 18:22:54 step 3: objective=0.96422064
2017/08/28 18:22:55 step 4: objective=0.96994275
2017/08/28 18:22:56 step 5: objective=0.9755625
2017/08/28 18:22:57 step 6: objective=0.9804041
2017/08/28 18:22:59 step 7: objective=0.9867691
2017/08/28 18:22:59 Training value function...
2017/08/28 18:23:01 step 0: mse=182.703218 step=0.100000
2017/08/28 18:23:02 step 1: mse=181.347254 step=0.100000
2017/08/28 18:23:03 step 2: mse=179.760238 step=0.100000
2017/08/28 18:23:04 step 3: mse=178.472401 step=0.100000
2017/08/28 18:23:05 step 4: mse=177.280186 step=0.100000
2017/08/28 18:23:06 step 5: mse=176.333975 step=0.100000
2017/08/28 18:23:07 step 6: mse=175.323988 step=0.100000
2017/08/28 18:23:08 step 7: mse=174.497895 step=0.100000
2017/08/28 18:23:08 Saving...
2017/08/28 18:23:08 Gathering batch of experience...
2017/08/28 18:23:54 batch 481: mean=106.307692 stddev=93.719208 entropy=0.415285 frames=5144 count=52
2017/08/28 18:23:54 Training policy...
2017/08/28 18:23:57 step 0: objective=1.6018323
2017/08/28 18:23:59 step 1: objective=1.6083139
2017/08/28 18:24:00 step 2: objective=1.6130749
2017/08/28 18:24:01 step 3: objective=1.6191545
2017/08/28 18:24:03 step 4: objective=1.625366
2017/08/28 18:24:04 step 5: objective=1.6305102
2017/08/28 18:24:05 step 6: objective=1.6410184
2017/08/28 18:24:06 step 7: objective=1.6454533
2017/08/28 18:24:06 Training value function...
2017/08/28 18:24:09 step 0: mse=181.203310 step=0.100000
2017/08/28 18:24:10 step 1: mse=178.738046 step=0.100000
2017/08/28 18:24:11 step 2: mse=176.460644 step=0.100000
2017/08/28 18:24:12 step 3: mse=174.499577 step=0.100000
2017/08/28 18:24:13 step 4: mse=172.657181 step=0.100000
2017/08/28 18:24:14 step 5: mse=170.863988 step=0.100000
2017/08/28 18:24:15 step 6: mse=169.203769 step=0.100000
2017/08/28 18:24:16 step 7: mse=167.729159 step=0.100000
2017/08/28 18:24:16 Saving...
2017/08/28 18:24:16 Gathering batch of experience...
2017/08/28 18:25:01 batch 482: mean=120.659574 stddev=95.323252 entropy=0.419862 frames=5314 count=47
2017/08/28 18:25:01 Training policy...
2017/08/28 18:25:05 step 0: objective=1.6645731
2017/08/28 18:25:06 step 1: objective=1.676922
2017/08/28 18:25:07 step 2: objective=1.6830763
2017/08/28 18:25:09 step 3: objective=1.6884074
2017/08/28 18:25:10 step 4: objective=1.6938117
2017/08/28 18:25:11 step 5: objective=1.7010341
2017/08/28 18:25:13 step 6: objective=1.70413
2017/08/28 18:25:14 step 7: objective=1.7095307
2017/08/28 18:25:14 Training value function...
2017/08/28 18:25:16 step 0: mse=172.255727 step=0.100000
2017/08/28 18:25:17 step 1: mse=169.591248 step=0.100000
2017/08/28 18:25:18 step 2: mse=167.138441 step=0.100000
2017/08/28 18:25:20 step 3: mse=164.989836 step=0.100000
2017/08/28 18:25:21 step 4: mse=163.082915 step=0.100000
2017/08/28 18:25:22 step 5: mse=161.477392 step=0.100000
2017/08/28 18:25:23 step 6: mse=159.564917 step=0.100000
2017/08/28 18:25:24 step 7: mse=157.961325 step=0.100000
2017/08/28 18:25:24 Saving...
2017/08/28 18:25:24 Gathering batch of experience...
2017/08/28 18:26:10 batch 483: mean=88.071429 stddev=75.838375 entropy=0.412614 frames=4886 count=56
2017/08/28 18:26:10 Training policy...
2017/08/28 18:26:14 step 0: objective=-0.16699792
2017/08/28 18:26:15 step 1: objective=-0.15622781
2017/08/28 18:26:16 step 2: objective=-0.14709039
2017/08/28 18:26:18 step 3: objective=-0.13763009
2017/08/28 18:26:19 step 4: objective=-0.12727758
2017/08/28 18:26:20 step 5: objective=-0.12070418
2017/08/28 18:26:21 step 6: objective=-0.11527735
2017/08/28 18:26:23 step 7: objective=-0.111817084
2017/08/28 18:26:23 Training value function...
2017/08/28 18:26:25 step 0: mse=175.395880 step=0.100000
2017/08/28 18:26:26 step 1: mse=172.703701 step=0.100000
2017/08/28 18:26:27 step 2: mse=170.356545 step=0.100000
2017/08/28 18:26:28 step 3: mse=168.687353 step=0.100000
2017/08/28 18:26:29 step 4: mse=167.367399 step=0.100000
2017/08/28 18:26:30 step 5: mse=165.817748 step=0.100000
2017/08/28 18:26:31 step 6: mse=164.399928 step=0.100000
2017/08/28 18:26:32 step 7: mse=163.154945 step=0.100000
2017/08/28 18:26:32 Saving...
2017/08/28 18:26:32 Gathering batch of experience...
2017/08/28 18:27:13 batch 484: mean=128.214286 stddev=95.799527 entropy=0.420174 frames=5121 count=42
2017/08/28 18:27:13 Training policy...
2017/08/28 18:27:17 step 0: objective=1.9617952
2017/08/28 18:27:18 step 1: objective=1.9674338
2017/08/28 18:27:19 step 2: objective=1.9749366
2017/08/28 18:27:21 step 3: objective=1.9816318
2017/08/28 18:27:22 step 4: objective=1.9899845
2017/08/28 18:27:23 step 5: objective=1.9955986
2017/08/28 18:27:25 step 6: objective=2.003054
2017/08/28 18:27:26 step 7: objective=2.0085158
2017/08/28 18:27:26 Training value function...
2017/08/28 18:27:28 step 0: mse=186.412808 step=0.100000
2017/08/28 18:27:29 step 1: mse=183.680636 step=0.100000
2017/08/28 18:27:30 step 2: mse=180.647652 step=0.100000
2017/08/28 18:27:31 step 3: mse=178.398645 step=0.100000
2017/08/28 18:27:32 step 4: mse=176.384172 step=0.100000
2017/08/28 18:27:33 step 5: mse=174.737806 step=0.100000
2017/08/28 18:27:34 step 6: mse=173.181944 step=0.100000
2017/08/28 18:27:36 step 7: mse=171.640429 step=0.100000
2017/08/28 18:27:36 Saving...
2017/08/28 18:27:36 Gathering batch of experience...
2017/08/28 18:28:24 batch 485: mean=119.307692 stddev=106.810857 entropy=0.419813 frames=5875 count=52
2017/08/28 18:28:24 Training policy...
2017/08/28 18:28:28 step 0: objective=1.326908
2017/08/28 18:28:30 step 1: objective=1.3373941
2017/08/28 18:28:31 step 2: objective=1.3438092
2017/08/28 18:28:33 step 3: objective=1.351283
2017/08/28 18:28:34 step 4: objective=1.3597916
2017/08/28 18:28:36 step 5: objective=1.365186
2017/08/28 18:28:37 step 6: objective=1.3708762
2017/08/28 18:28:39 step 7: objective=1.3755449
2017/08/28 18:28:39 Training value function...
2017/08/28 18:28:41 step 0: mse=190.663550 step=0.100000
2017/08/28 18:28:42 step 1: mse=188.401124 step=0.100000
2017/08/28 18:28:43 step 2: mse=186.133773 step=0.100000
2017/08/28 18:28:45 step 3: mse=184.165820 step=0.100000
2017/08/28 18:28:46 step 4: mse=182.330417 step=0.100000
2017/08/28 18:28:47 step 5: mse=180.601952 step=0.100000
2017/08/28 18:28:48 step 6: mse=179.270408 step=0.100000
2017/08/28 18:28:50 step 7: mse=177.698357 step=0.100000
2017/08/28 18:28:50 Saving...
2017/08/28 18:28:50 Gathering batch of experience...
2017/08/28 18:29:32 batch 486: mean=95.000000 stddev=89.144078 entropy=0.411281 frames=4820 count=51
2017/08/28 18:29:32 Training policy...
2017/08/28 18:29:35 step 0: objective=-0.019338654
2017/08/28 18:29:36 step 1: objective=-0.005272199
2017/08/28 18:29:37 step 2: objective=0.0046862965
2017/08/28 18:29:39 step 3: objective=0.009600566
2017/08/28 18:29:40 step 4: objective=0.016874777
2017/08/28 18:29:41 step 5: objective=0.02318448
2017/08/28 18:29:42 step 6: objective=0.0324036
2017/08/28 18:29:44 step 7: objective=0.036180988
2017/08/28 18:29:44 Training value function...
2017/08/28 18:29:46 step 0: mse=145.223843 step=0.100000
2017/08/28 18:29:47 step 1: mse=143.572854 step=0.100000
2017/08/28 18:29:48 step 2: mse=142.087453 step=0.100000
2017/08/28 18:29:49 step 3: mse=140.545839 step=0.100000
2017/08/28 18:29:50 step 4: mse=139.722768 step=0.100000
2017/08/28 18:29:51 step 5: mse=138.924389 step=0.100000
2017/08/28 18:29:52 step 6: mse=138.227256 step=0.100000
2017/08/28 18:29:53 step 7: mse=137.487677 step=0.100000
2017/08/28 18:29:53 Saving...
2017/08/28 18:29:53 Gathering batch of experience...
2017/08/28 18:30:41 batch 487: mean=103.698113 stddev=83.645159 entropy=0.416173 frames=5435 count=53
2017/08/28 18:30:41 Training policy...
2017/08/28 18:30:45 step 0: objective=0.68585396
2017/08/28 18:30:46 step 1: objective=0.6944253
2017/08/28 18:30:48 step 2: objective=0.70032287
2017/08/28 18:30:49 step 3: objective=0.70984524
2017/08/28 18:30:51 step 4: objective=0.71783805
2017/08/28 18:30:52 step 5: objective=0.7241073
2017/08/28 18:30:53 step 6: objective=0.7296955
2017/08/28 18:30:55 step 7: objective=0.73781997
2017/08/28 18:30:55 Training value function...
2017/08/28 18:30:57 step 0: mse=148.490770 step=0.100000
2017/08/28 18:30:58 step 1: mse=146.956951 step=0.100000
2017/08/28 18:30:59 step 2: mse=145.551253 step=0.100000
2017/08/28 18:31:00 step 3: mse=144.269893 step=0.100000
2017/08/28 18:31:01 step 4: mse=143.087942 step=0.100000
2017/08/28 18:31:03 step 5: mse=142.052149 step=0.100000
2017/08/28 18:31:04 step 6: mse=141.000568 step=0.100000
2017/08/28 18:31:05 step 7: mse=139.890811 step=0.100000
2017/08/28 18:31:05 Saving...
2017/08/28 18:31:05 Gathering batch of experience...
2017/08/28 18:31:50 batch 488: mean=123.250000 stddev=117.052428 entropy=0.422057 frames=5509 count=48
2017/08/28 18:31:50 Training policy...
2017/08/28 18:31:54 step 0: objective=2.2423046
2017/08/28 18:31:55 step 1: objective=2.2507536
2017/08/28 18:31:56 step 2: objective=2.2603052
2017/08/28 18:31:58 step 3: objective=2.265198
2017/08/28 18:31:59 step 4: objective=2.271097
2017/08/28 18:32:01 step 5: objective=2.2752411
2017/08/28 18:32:02 step 6: objective=2.2826347
2017/08/28 18:32:04 step 7: objective=2.2885652
2017/08/28 18:32:04 Training value function...
2017/08/28 18:32:06 step 0: mse=210.810233 step=0.100000
2017/08/28 18:32:07 step 1: mse=203.565225 step=0.100000
2017/08/28 18:32:08 step 2: mse=197.363956 step=0.100000
2017/08/28 18:32:09 step 3: mse=192.275938 step=0.100000
2017/08/28 18:32:10 step 4: mse=187.808658 step=0.100000
2017/08/28 18:32:12 step 5: mse=183.915987 step=0.100000
2017/08/28 18:32:13 step 6: mse=180.471517 step=0.100000
2017/08/28 18:32:14 step 7: mse=177.543839 step=0.100000
2017/08/28 18:32:14 Saving...
2017/08/28 18:32:14 Gathering batch of experience...
2017/08/28 18:32:59 batch 489: mean=97.166667 stddev=69.292924 entropy=0.408832 frames=5227 count=54
2017/08/28 18:32:59 Training policy...
2017/08/28 18:33:03 step 0: objective=0.07907395
2017/08/28 18:33:04 step 1: objective=0.08767903
2017/08/28 18:33:06 step 2: objective=0.094069295
2017/08/28 18:33:07 step 3: objective=0.10198923
2017/08/28 18:33:08 step 4: objective=0.108600825
2017/08/28 18:33:10 step 5: objective=0.115224324
2017/08/28 18:33:11 step 6: objective=0.120098025
2017/08/28 18:33:12 step 7: objective=0.12853932
2017/08/28 18:33:12 Training value function...
2017/08/28 18:33:15 step 0: mse=155.712299 step=0.100000
2017/08/28 18:33:16 step 1: mse=151.798147 step=0.100000
2017/08/28 18:33:17 step 2: mse=148.794561 step=0.100000
2017/08/28 18:33:18 step 3: mse=146.369916 step=0.100000
2017/08/28 18:33:19 step 4: mse=144.138835 step=0.100000
2017/08/28 18:33:20 step 5: mse=142.335995 step=0.100000
2017/08/28 18:33:21 step 6: mse=140.836808 step=0.100000
2017/08/28 18:33:22 step 7: mse=139.474150 step=0.100000
2017/08/28 18:33:22 Saving...
2017/08/28 18:33:22 Gathering batch of experience...
2017/08/28 18:34:07 batch 490: mean=112.191489 stddev=96.484072 entropy=0.424617 frames=5164 count=47
2017/08/28 18:34:07 Training policy...
2017/08/28 18:34:11 step 0: objective=1.6818132
2017/08/28 18:34:12 step 1: objective=1.6913306
2017/08/28 18:34:14 step 2: objective=1.7002137
2017/08/28 18:34:15 step 3: objective=1.7082129
2017/08/28 18:34:16 step 4: objective=1.7151942
2017/08/28 18:34:18 step 5: objective=1.7217947
2017/08/28 18:34:19 step 6: objective=1.7249968
2017/08/28 18:34:20 step 7: objective=1.7300391
2017/08/28 18:34:20 Training value function...
2017/08/28 18:34:22 step 0: mse=191.040151 step=0.100000
2017/08/28 18:34:23 step 1: mse=187.800207 step=0.100000
2017/08/28 18:34:25 step 2: mse=184.825370 step=0.100000
2017/08/28 18:34:26 step 3: mse=182.239726 step=0.100000
2017/08/28 18:34:27 step 4: mse=179.656616 step=0.100000
2017/08/28 18:34:28 step 5: mse=177.351322 step=0.100000
2017/08/28 18:34:29 step 6: mse=175.323744 step=0.100000
2017/08/28 18:34:30 step 7: mse=173.393668 step=0.100000
2017/08/28 18:34:30 Saving...
2017/08/28 18:34:30 Gathering batch of experience...
2017/08/28 18:35:22 batch 491: mean=122.019608 stddev=106.471112 entropy=0.414838 frames=5915 count=51
2017/08/28 18:35:22 Training policy...
2017/08/28 18:35:26 step 0: objective=1.7969272
2017/08/28 18:35:27 step 1: objective=1.8031273
2017/08/28 18:35:29 step 2: objective=1.8102072
2017/08/28 18:35:30 step 3: objective=1.81726
2017/08/28 18:35:32 step 4: objective=1.8247378
2017/08/28 18:35:33 step 5: objective=1.8338257
2017/08/28 18:35:35 step 6: objective=1.8369821
2017/08/28 18:35:36 step 7: objective=1.8410407
2017/08/28 18:35:36 Training value function...
2017/08/28 18:35:39 step 0: mse=197.966378 step=0.100000
2017/08/28 18:35:40 step 1: mse=192.519069 step=0.100000
2017/08/28 18:35:41 step 2: mse=188.468140 step=0.100000
2017/08/28 18:35:42 step 3: mse=184.655947 step=0.100000
2017/08/28 18:35:44 step 4: mse=181.446854 step=0.100000
2017/08/28 18:35:45 step 5: mse=179.029026 step=0.100000
2017/08/28 18:35:46 step 6: mse=176.921235 step=0.100000
2017/08/28 18:35:47 step 7: mse=174.913059 step=0.100000
2017/08/28 18:35:47 Saving...
2017/08/28 18:35:47 Gathering batch of experience...
2017/08/28 18:36:31 batch 492: mean=96.094340 stddev=91.614299 entropy=0.419368 frames=5094 count=53
2017/08/28 18:36:31 Training policy...
2017/08/28 18:36:35 step 0: objective=0.0971786
2017/08/28 18:36:36 step 1: objective=0.11107305
2017/08/28 18:36:37 step 2: objective=0.11756106
2017/08/28 18:36:39 step 3: objective=0.12323168
2017/08/28 18:36:40 step 4: objective=0.1299992
2017/08/28 18:36:41 step 5: objective=0.13747542
2017/08/28 18:36:43 step 6: objective=0.14464106
2017/08/28 18:36:44 step 7: objective=0.14740053
2017/08/28 18:36:44 Training value function...
2017/08/28 18:36:46 step 0: mse=178.609326 step=0.100000
2017/08/28 18:36:47 step 1: mse=173.651994 step=0.100000
2017/08/28 18:36:48 step 2: mse=170.041211 step=0.100000
2017/08/28 18:36:49 step 3: mse=167.159441 step=0.100000
2017/08/28 18:36:50 step 4: mse=163.849095 step=0.100000
2017/08/28 18:36:51 step 5: mse=161.248692 step=0.100000
2017/08/28 18:36:52 step 6: mse=159.164583 step=0.100000
2017/08/28 18:36:54 step 7: mse=157.432807 step=0.100000
2017/08/28 18:36:54 Saving...
2017/08/28 18:36:54 Gathering batch of experience...
2017/08/28 18:37:34 batch 493: mean=115.069767 stddev=92.089793 entropy=0.408642 frames=4836 count=43
2017/08/28 18:37:34 Training policy...
2017/08/28 18:37:37 step 0: objective=1.1076137
2017/08/28 18:37:38 step 1: objective=1.117139
2017/08/28 18:37:40 step 2: objective=1.1309316
2017/08/28 18:37:41 step 3: objective=1.1434942
2017/08/28 18:37:42 step 4: objective=1.1478722
2017/08/28 18:37:43 step 5: objective=1.1586283
2017/08/28 18:37:45 step 6: objective=1.1634908
2017/08/28 18:37:46 step 7: objective=1.1683513
2017/08/28 18:37:46 Training value function...
2017/08/28 18:37:48 step 0: mse=174.183265 step=0.100000
2017/08/28 18:37:49 step 1: mse=170.629915 step=0.100000
2017/08/28 18:37:50 step 2: mse=167.757568 step=0.100000
2017/08/28 18:37:51 step 3: mse=165.646016 step=0.100000
2017/08/28 18:37:52 step 4: mse=163.580030 step=0.100000
2017/08/28 18:37:53 step 5: mse=161.841949 step=0.100000
2017/08/28 18:37:54 step 6: mse=159.912879 step=0.100000
2017/08/28 18:37:55 step 7: mse=158.322742 step=0.100000
2017/08/28 18:37:55 Saving...
2017/08/28 18:37:55 Gathering batch of experience...
2017/08/28 18:38:38 batch 494: mean=94.096154 stddev=88.095721 entropy=0.412979 frames=4817 count=52
2017/08/28 18:38:38 Training policy...
2017/08/28 18:38:41 step 0: objective=0.49318728
2017/08/28 18:38:42 step 1: objective=0.5094577
2017/08/28 18:38:44 step 2: objective=0.5240582
2017/08/28 18:38:45 step 3: objective=0.5329237
2017/08/28 18:38:46 step 4: objective=0.53937316
2017/08/28 18:38:47 step 5: objective=0.5458049
2017/08/28 18:38:49 step 6: objective=0.5514209
2017/08/28 18:38:50 step 7: objective=0.5563926
2017/08/28 18:38:50 Training value function...
2017/08/28 18:38:52 step 0: mse=189.972296 step=0.100000
2017/08/28 18:38:53 step 1: mse=188.025571 step=0.100000
2017/08/28 18:38:54 step 2: mse=186.332162 step=0.100000
2017/08/28 18:38:55 step 3: mse=184.822247 step=0.100000
2017/08/28 18:38:56 step 4: mse=183.379374 step=0.100000
2017/08/28 18:38:57 step 5: mse=182.003088 step=0.100000
2017/08/28 18:38:58 step 6: mse=180.405003 step=0.100000
2017/08/28 18:38:59 step 7: mse=179.116566 step=0.100000
2017/08/28 18:38:59 Saving...
2017/08/28 18:38:59 Gathering batch of experience...
2017/08/28 18:39:42 batch 495: mean=94.792453 stddev=83.945256 entropy=0.411259 frames=4784 count=53
2017/08/28 18:39:42 Training policy...
2017/08/28 18:39:45 step 0: objective=0.9562778
2017/08/28 18:39:47 step 1: objective=0.97072047
2017/08/28 18:39:48 step 2: objective=0.9873007
2017/08/28 18:39:49 step 3: objective=0.9985622
2017/08/28 18:39:50 step 4: objective=1.0077676
2017/08/28 18:39:52 step 5: objective=1.0123398
2017/08/28 18:39:53 step 6: objective=1.0222306
2017/08/28 18:39:54 step 7: objective=1.0325696
2017/08/28 18:39:54 Training value function...
2017/08/28 18:39:56 step 0: mse=187.641108 step=0.100000
2017/08/28 18:39:57 step 1: mse=185.777584 step=0.100000
2017/08/28 18:39:58 step 2: mse=183.807257 step=0.100000
2017/08/28 18:39:59 step 3: mse=182.256263 step=0.100000
2017/08/28 18:40:00 step 4: mse=180.679427 step=0.100000
2017/08/28 18:40:01 step 5: mse=179.098824 step=0.100000
2017/08/28 18:40:02 step 6: mse=177.938007 step=0.100000
2017/08/28 18:40:03 step 7: mse=176.724140 step=0.100000
2017/08/28 18:40:03 Saving...
2017/08/28 18:40:03 Gathering batch of experience...
2017/08/28 18:40:51 batch 496: mean=99.090909 stddev=84.421512 entropy=0.408723 frames=4995 count=55
2017/08/28 18:40:51 Training policy...
2017/08/28 18:40:54 step 0: objective=1.5016688
2017/08/28 18:40:56 step 1: objective=1.521407
2017/08/28 18:40:57 step 2: objective=1.5316947
2017/08/28 18:40:58 step 3: objective=1.5392672
2017/08/28 18:41:00 step 4: objective=1.544345
2017/08/28 18:41:01 step 5: objective=1.5512996
2017/08/28 18:41:02 step 6: objective=1.5559558
2017/08/28 18:41:03 step 7: objective=1.5623406
2017/08/28 18:41:03 Training value function...
2017/08/28 18:41:05 step 0: mse=214.012848 step=0.100000
2017/08/28 18:41:06 step 1: mse=210.708889 step=0.100000
2017/08/28 18:41:07 step 2: mse=207.891962 step=0.100000
2017/08/28 18:41:09 step 3: mse=205.377759 step=0.100000
2017/08/28 18:41:10 step 4: mse=203.047067 step=0.100000
2017/08/28 18:41:11 step 5: mse=200.783384 step=0.100000
2017/08/28 18:41:12 step 6: mse=198.615464 step=0.100000
2017/08/28 18:41:13 step 7: mse=196.806331 step=0.100000
2017/08/28 18:41:13 Saving...
2017/08/28 18:41:13 Gathering batch of experience...
2017/08/28 18:41:58 batch 497: mean=102.137255 stddev=82.420971 entropy=0.406641 frames=5400 count=51
2017/08/28 18:41:58 Training policy...
2017/08/28 18:42:02 step 0: objective=0.25992158
2017/08/28 18:42:04 step 1: objective=0.26718387
2017/08/28 18:42:05 step 2: objective=0.2750113
2017/08/28 18:42:06 step 3: objective=0.2823525
2017/08/28 18:42:08 step 4: objective=0.28763133
2017/08/28 18:42:09 step 5: objective=0.29290524
2017/08/28 18:42:11 step 6: objective=0.29659873
2017/08/28 18:42:12 step 7: objective=0.30148256
2017/08/28 18:42:12 Training value function...
2017/08/28 18:42:14 step 0: mse=125.160835 step=0.100000
2017/08/28 18:42:15 step 1: mse=124.326002 step=0.100000
2017/08/28 18:42:16 step 2: mse=123.578013 step=0.100000
2017/08/28 18:42:18 step 3: mse=122.915211 step=0.100000
2017/08/28 18:42:19 step 4: mse=122.398407 step=0.100000
2017/08/28 18:42:20 step 5: mse=121.768189 step=0.100000
2017/08/28 18:42:21 step 6: mse=121.209153 step=0.100000
2017/08/28 18:42:22 step 7: mse=120.768740 step=0.100000
2017/08/28 18:42:22 Saving...
2017/08/28 18:42:22 Gathering batch of experience...
2017/08/28 18:43:06 batch 498: mean=108.041667 stddev=98.273419 entropy=0.419369 frames=4949 count=48
2017/08/28 18:43:06 Training policy...
2017/08/28 18:43:09 step 0: objective=1.6127884
2017/08/28 18:43:11 step 1: objective=1.6246073
2017/08/28 18:43:12 step 2: objective=1.6316696
2017/08/28 18:43:13 step 3: objective=1.6422904
2017/08/28 18:43:14 step 4: objective=1.6491699
2017/08/28 18:43:16 step 5: objective=1.6543736
2017/08/28 18:43:17 step 6: objective=1.6599145
2017/08/28 18:43:18 step 7: objective=1.6655682
2017/08/28 18:43:18 Training value function...
2017/08/28 18:43:20 step 0: mse=198.059134 step=0.100000
2017/08/28 18:43:21 step 1: mse=193.559986 step=0.100000
2017/08/28 18:43:22 step 2: mse=189.466466 step=0.100000
2017/08/28 18:43:23 step 3: mse=186.020511 step=0.100000
2017/08/28 18:43:24 step 4: mse=183.093366 step=0.100000
2017/08/28 18:43:25 step 5: mse=180.401475 step=0.100000
2017/08/28 18:43:26 step 6: mse=178.065124 step=0.100000
2017/08/28 18:43:27 step 7: mse=175.973789 step=0.100000
2017/08/28 18:43:27 Saving...
2017/08/28 18:43:28 Gathering batch of experience...
2017/08/28 18:44:09 batch 499: mean=115.818182 stddev=107.419372 entropy=0.410407 frames=4775 count=44
2017/08/28 18:44:09 Training policy...
2017/08/28 18:44:12 step 0: objective=1.4664491
2017/08/28 18:44:14 step 1: objective=1.4732536
2017/08/28 18:44:15 step 2: objective=1.4822583
2017/08/28 18:44:16 step 3: objective=1.4899017
2017/08/28 18:44:17 step 4: objective=1.4952786
2017/08/28 18:44:18 step 5: objective=1.5069212
2017/08/28 18:44:20 step 6: objective=1.5117613
2017/08/28 18:44:21 step 7: objective=1.516394
2017/08/28 18:44:21 Training value function...
2017/08/28 18:44:23 step 0: mse=190.250986 step=0.100000
2017/08/28 18:44:24 step 1: mse=186.126112 step=0.100000
2017/08/28 18:44:25 step 2: mse=182.431525 step=0.100000
2017/08/28 18:44:26 step 3: mse=179.439537 step=0.100000
2017/08/28 18:44:27 step 4: mse=176.981357 step=0.100000
2017/08/28 18:44:28 step 5: mse=174.963247 step=0.100000
2017/08/28 18:44:29 step 6: mse=173.066126 step=0.100000
2017/08/28 18:44:30 step 7: mse=171.413277 step=0.100000
2017/08/28 18:44:30 Saving...
2017/08/28 18:44:30 Gathering batch of experience...
2017/08/28 18:45:14 batch 500: mean=96.777778 stddev=80.567355 entropy=0.412816 frames=5036 count=54
2017/08/28 18:45:14 Training policy...
2017/08/28 18:45:18 step 0: objective=0.425429
2017/08/28 18:45:19 step 1: objective=0.4391398
2017/08/28 18:45:21 step 2: objective=0.44707084
2017/08/28 18:45:22 step 3: objective=0.4535709
2017/08/28 18:45:23 step 4: objective=0.46075198
2017/08/28 18:45:24 step 5: objective=0.46824
2017/08/28 18:45:26 step 6: objective=0.47487217
2017/08/28 18:45:27 step 7: objective=0.47864714
2017/08/28 18:45:27 Training value function...
2017/08/28 18:45:29 step 0: mse=161.372089 step=0.100000
2017/08/28 18:45:30 step 1: mse=157.725197 step=0.100000
2017/08/28 18:45:31 step 2: mse=154.680049 step=0.100000
2017/08/28 18:45:32 step 3: mse=152.202750 step=0.100000
2017/08/28 18:45:33 step 4: mse=150.009643 step=0.100000
2017/08/28 18:45:34 step 5: mse=148.212299 step=0.100000
2017/08/28 18:45:35 step 6: mse=146.800422 step=0.100000
2017/08/28 18:45:36 step 7: mse=145.537626 step=0.100000
2017/08/28 18:45:36 Saving...
2017/08/28 18:45:37 Gathering batch of experience...
2017/08/28 18:46:25 batch 501: mean=108.250000 stddev=99.332363 entropy=0.409997 frames=5649 count=52
2017/08/28 18:46:25 Training policy...
2017/08/28 18:46:29 step 0: objective=0.87237024
2017/08/28 18:46:31 step 1: objective=0.8815034
2017/08/28 18:46:32 step 2: objective=0.88674194
2017/08/28 18:46:34 step 3: objective=0.8918461
2017/08/28 18:46:35 step 4: objective=0.8971069
2017/08/28 18:46:36 step 5: objective=0.9038862
2017/08/28 18:46:38 step 6: objective=0.90824264
2017/08/28 18:46:39 step 7: objective=0.91324073
2017/08/28 18:46:39 Training value function...
2017/08/28 18:46:42 step 0: mse=161.493912 step=0.100000
2017/08/28 18:46:43 step 1: mse=158.536998 step=0.100000
2017/08/28 18:46:44 step 2: mse=156.549208 step=0.100000
2017/08/28 18:46:45 step 3: mse=154.574565 step=0.100000
2017/08/28 18:46:46 step 4: mse=152.179601 step=0.100000
2017/08/28 18:46:48 step 5: mse=150.790850 step=0.100000
2017/08/28 18:46:49 step 6: mse=149.346416 step=0.100000
2017/08/28 18:46:50 step 7: mse=148.264593 step=0.100000
2017/08/28 18:46:50 Saving...
2017/08/28 18:46:50 Gathering batch of experience...
2017/08/28 18:47:32 batch 502: mean=102.680000 stddev=77.381507 entropy=0.415855 frames=4897 count=50
2017/08/28 18:47:32 Training policy...
2017/08/28 18:47:36 step 0: objective=1.0976696
2017/08/28 18:47:37 step 1: objective=1.1053563
2017/08/28 18:47:38 step 2: objective=1.1127981
2017/08/28 18:47:40 step 3: objective=1.1201961
2017/08/28 18:47:41 step 4: objective=1.1262687
2017/08/28 18:47:42 step 5: objective=1.1309068
2017/08/28 18:47:43 step 6: objective=1.1354614
2017/08/28 18:47:45 step 7: objective=1.1388874
2017/08/28 18:47:45 Training value function...
2017/08/28 18:47:47 step 0: mse=177.151123 step=0.100000
2017/08/28 18:47:48 step 1: mse=173.974381 step=0.100000
2017/08/28 18:47:49 step 2: mse=171.225551 step=0.100000
2017/08/28 18:47:50 step 3: mse=168.910325 step=0.100000
2017/08/28 18:47:51 step 4: mse=166.874139 step=0.100000
2017/08/28 18:47:52 step 5: mse=164.938275 step=0.100000
2017/08/28 18:47:53 step 6: mse=163.383066 step=0.100000
2017/08/28 18:47:54 step 7: mse=161.861685 step=0.100000
2017/08/28 18:47:54 Saving...
2017/08/28 18:47:54 Gathering batch of experience...
2017/08/28 18:48:40 batch 503: mean=114.333333 stddev=94.069478 entropy=0.414571 frames=5135 count=45
2017/08/28 18:48:40 Training policy...
2017/08/28 18:48:43 step 0: objective=1.0022857
2017/08/28 18:48:45 step 1: objective=1.0103263
2017/08/28 18:48:46 step 2: objective=1.0196899
2017/08/28 18:48:47 step 3: objective=1.0240604
2017/08/28 18:48:49 step 4: objective=1.0294472
2017/08/28 18:48:50 step 5: objective=1.0341227
2017/08/28 18:48:51 step 6: objective=1.0383766
2017/08/28 18:48:53 step 7: objective=1.0416653
2017/08/28 18:48:53 Training value function...
2017/08/28 18:48:55 step 0: mse=160.352017 step=0.100000
2017/08/28 18:48:56 step 1: mse=158.482697 step=0.100000
2017/08/28 18:48:57 step 2: mse=156.804207 step=0.100000
2017/08/28 18:48:58 step 3: mse=154.826314 step=0.100000
2017/08/28 18:48:59 step 4: mse=153.017909 step=0.100000
2017/08/28 18:49:00 step 5: mse=151.739013 step=0.100000
2017/08/28 18:49:01 step 6: mse=150.694550 step=0.100000
2017/08/28 18:49:02 step 7: mse=149.253228 step=0.100000
2017/08/28 18:49:02 Saving...
2017/08/28 18:49:02 Gathering batch of experience...
2017/08/28 18:49:47 batch 504: mean=102.740000 stddev=91.301875 entropy=0.407545 frames=5139 count=50
2017/08/28 18:49:47 Training policy...
2017/08/28 18:49:51 step 0: objective=0.517482
2017/08/28 18:49:52 step 1: objective=0.5248271
2017/08/28 18:49:54 step 2: objective=0.5302597
2017/08/28 18:49:55 step 3: objective=0.5361849
2017/08/28 18:49:56 step 4: objective=0.54584885
2017/08/28 18:49:58 step 5: objective=0.5535801
2017/08/28 18:49:59 step 6: objective=0.56085783
2017/08/28 18:50:00 step 7: objective=0.5655524
2017/08/28 18:50:00 Training value function...
2017/08/28 18:50:02 step 0: mse=177.147713 step=0.100000
2017/08/28 18:50:03 step 1: mse=173.033386 step=0.100000
2017/08/28 18:50:05 step 2: mse=169.707610 step=0.100000
2017/08/28 18:50:06 step 3: mse=167.326299 step=0.100000
2017/08/28 18:50:07 step 4: mse=165.427677 step=0.100000
2017/08/28 18:50:08 step 5: mse=163.825691 step=0.100000
2017/08/28 18:50:09 step 6: mse=161.814889 step=0.100000
2017/08/28 18:50:10 step 7: mse=160.337181 step=0.100000
2017/08/28 18:50:10 Saving...
2017/08/28 18:50:10 Gathering batch of experience...
2017/08/28 18:50:56 batch 505: mean=112.040000 stddev=102.559048 entropy=0.401371 frames=5162 count=50
2017/08/28 18:50:56 Training policy...
2017/08/28 18:51:00 step 0: objective=1.6115637
2017/08/28 18:51:01 step 1: objective=1.6213013
2017/08/28 18:51:03 step 2: objective=1.6320834
2017/08/28 18:51:04 step 3: objective=1.6400408
2017/08/28 18:51:05 step 4: objective=1.6473771
2017/08/28 18:51:07 step 5: objective=1.6538814
2017/08/28 18:51:08 step 6: objective=1.6606932
2017/08/28 18:51:09 step 7: objective=1.6645811
2017/08/28 18:51:09 Training value function...
2017/08/28 18:51:11 step 0: mse=191.445664 step=0.100000
2017/08/28 18:51:12 step 1: mse=186.209688 step=0.100000
2017/08/28 18:51:14 step 2: mse=181.852311 step=0.100000
2017/08/28 18:51:15 step 3: mse=178.007643 step=0.100000
2017/08/28 18:51:16 step 4: mse=174.785695 step=0.100000
2017/08/28 18:51:17 step 5: mse=172.197272 step=0.100000
2017/08/28 18:51:18 step 6: mse=169.797564 step=0.100000
2017/08/28 18:51:19 step 7: mse=167.653596 step=0.100000
2017/08/28 18:51:19 Saving...
2017/08/28 18:51:19 Gathering batch of experience...
2017/08/28 18:52:05 batch 506: mean=93.839286 stddev=86.689260 entropy=0.405836 frames=5339 count=56
2017/08/28 18:52:05 Training policy...
2017/08/28 18:52:09 step 0: objective=-0.18900687
2017/08/28 18:52:10 step 1: objective=-0.18321572
2017/08/28 18:52:12 step 2: objective=-0.17545739
2017/08/28 18:52:13 step 3: objective=-0.16879743
2017/08/28 18:52:14 step 4: objective=-0.16111147
2017/08/28 18:52:16 step 5: objective=-0.1558085
2017/08/28 18:52:17 step 6: objective=-0.15195139
2017/08/28 18:52:18 step 7: objective=-0.14449136
2017/08/28 18:52:18 Training value function...
2017/08/28 18:52:21 step 0: mse=176.993904 step=0.100000
2017/08/28 18:52:22 step 1: mse=173.063300 step=0.100000
2017/08/28 18:52:23 step 2: mse=170.015057 step=0.100000
2017/08/28 18:52:24 step 3: mse=167.423126 step=0.100000
2017/08/28 18:52:25 step 4: mse=165.200920 step=0.100000
2017/08/28 18:52:26 step 5: mse=163.373784 step=0.100000
2017/08/28 18:52:27 step 6: mse=161.841791 step=0.100000
2017/08/28 18:52:28 step 7: mse=160.192029 step=0.100000
2017/08/28 18:52:28 Saving...
2017/08/28 18:52:29 Gathering batch of experience...
2017/08/28 18:53:16 batch 507: mean=92.321429 stddev=85.880130 entropy=0.411613 frames=5069 count=56
2017/08/28 18:53:16 Training policy...
2017/08/28 18:53:20 step 0: objective=0.66323096
2017/08/28 18:53:21 step 1: objective=0.67692655
2017/08/28 18:53:22 step 2: objective=0.6872955
2017/08/28 18:53:24 step 3: objective=0.69508475
2017/08/28 18:53:25 step 4: objective=0.7071131
2017/08/28 18:53:26 step 5: objective=0.7140803
2017/08/28 18:53:28 step 6: objective=0.721566
2017/08/28 18:53:29 step 7: objective=0.72705555
2017/08/28 18:53:29 Training value function...
2017/08/28 18:53:31 step 0: mse=186.865377 step=0.100000
2017/08/28 18:53:32 step 1: mse=183.797256 step=0.100000
2017/08/28 18:53:33 step 2: mse=181.292838 step=0.100000
2017/08/28 18:53:34 step 3: mse=179.442688 step=0.100000
2017/08/28 18:53:35 step 4: mse=177.062315 step=0.100000
2017/08/28 18:53:36 step 5: mse=175.560210 step=0.100000
2017/08/28 18:53:37 step 6: mse=174.036143 step=0.100000
2017/08/28 18:53:39 step 7: mse=172.665151 step=0.100000
2017/08/28 18:53:39 Saving...
2017/08/28 18:53:39 Gathering batch of experience...
2017/08/28 18:54:22 batch 508: mean=101.877551 stddev=83.911429 entropy=0.409059 frames=4875 count=49
2017/08/28 18:54:22 Training policy...
2017/08/28 18:54:25 step 0: objective=0.94923526
2017/08/28 18:54:26 step 1: objective=0.9557036
2017/08/28 18:54:28 step 2: objective=0.96223867
2017/08/28 18:54:29 step 3: objective=0.969819
2017/08/28 18:54:30 step 4: objective=0.9769888
2017/08/28 18:54:32 step 5: objective=0.982742
2017/08/28 18:54:33 step 6: objective=0.9882299
2017/08/28 18:54:34 step 7: objective=0.99244875
2017/08/28 18:54:34 Training value function...
2017/08/28 18:54:36 step 0: mse=164.609623 step=0.100000
2017/08/28 18:54:37 step 1: mse=161.698558 step=0.100000
2017/08/28 18:54:38 step 2: mse=159.275269 step=0.100000
2017/08/28 18:54:39 step 3: mse=157.127159 step=0.100000
2017/08/28 18:54:40 step 4: mse=155.320459 step=0.100000
2017/08/28 18:54:41 step 5: mse=153.602325 step=0.100000
2017/08/28 18:54:42 step 6: mse=151.783319 step=0.100000
2017/08/28 18:54:43 step 7: mse=150.371969 step=0.100000
2017/08/28 18:54:43 Saving...
2017/08/28 18:54:43 Gathering batch of experience...
2017/08/28 18:55:30 batch 509: mean=87.228070 stddev=85.450923 entropy=0.404003 frames=5205 count=57
2017/08/28 18:55:30 Training policy...
2017/08/28 18:55:33 step 0: objective=0.088656746
2017/08/28 18:55:35 step 1: objective=0.09516295
2017/08/28 18:55:36 step 2: objective=0.10291719
2017/08/28 18:55:37 step 3: objective=0.10945167
2017/08/28 18:55:39 step 4: objective=0.11375619
2017/08/28 18:55:40 step 5: objective=0.11965721
2017/08/28 18:55:41 step 6: objective=0.12465798
2017/08/28 18:55:43 step 7: objective=0.13078026
2017/08/28 18:55:43 Training value function...
2017/08/28 18:55:45 step 0: mse=151.016351 step=0.100000
2017/08/28 18:55:46 step 1: mse=149.046115 step=0.100000
2017/08/28 18:55:47 step 2: mse=147.743175 step=0.100000
2017/08/28 18:55:48 step 3: mse=146.363641 step=0.100000
2017/08/28 18:55:49 step 4: mse=145.280935 step=0.100000
2017/08/28 18:55:50 step 5: mse=144.346771 step=0.100000
2017/08/28 18:55:51 step 6: mse=143.580413 step=0.100000
2017/08/28 18:55:52 step 7: mse=142.638375 step=0.100000
2017/08/28 18:55:52 Saving...
2017/08/28 18:55:53 Gathering batch of experience...
2017/08/28 18:56:36 batch 510: mean=109.520833 stddev=93.852719 entropy=0.413797 frames=4961 count=48
2017/08/28 18:56:36 Training policy...
2017/08/28 18:56:40 step 0: objective=2.0798335
2017/08/28 18:56:41 step 1: objective=2.0878427
2017/08/28 18:56:42 step 2: objective=2.0926418
2017/08/28 18:56:43 step 3: objective=2.1002724
2017/08/28 18:56:45 step 4: objective=2.1060328
2017/08/28 18:56:46 step 5: objective=2.1097708
2017/08/28 18:56:47 step 6: objective=2.1151514
2017/08/28 18:56:49 step 7: objective=2.1226232
2017/08/28 18:56:49 Training value function...
2017/08/28 18:56:51 step 0: mse=219.984576 step=0.100000
2017/08/28 18:56:52 step 1: mse=214.723729 step=0.100000
2017/08/28 18:56:53 step 2: mse=210.268296 step=0.100000
2017/08/28 18:56:54 step 3: mse=206.289836 step=0.100000
2017/08/28 18:56:55 step 4: mse=202.663157 step=0.100000
2017/08/28 18:56:56 step 5: mse=199.682083 step=0.100000
2017/08/28 18:56:57 step 6: mse=196.759273 step=0.100000
2017/08/28 18:56:58 step 7: mse=194.199449 step=0.100000
2017/08/28 18:56:58 Saving...
2017/08/28 18:56:58 Gathering batch of experience...
2017/08/28 18:57:43 batch 511: mean=99.166667 stddev=82.878481 entropy=0.404695 frames=5262 count=54
2017/08/28 18:57:43 Training policy...
2017/08/28 18:57:47 step 0: objective=0.75048
2017/08/28 18:57:48 step 1: objective=0.7604345
2017/08/28 18:57:50 step 2: objective=0.7673973
2017/08/28 18:57:51 step 3: objective=0.77453375
2017/08/28 18:57:52 step 4: objective=0.7807409
2017/08/28 18:57:54 step 5: objective=0.7910879
2017/08/28 18:57:55 step 6: objective=0.79420996
2017/08/28 18:57:56 step 7: objective=0.79769045
2017/08/28 18:57:56 Training value function...
2017/08/28 18:57:59 step 0: mse=179.327986 step=0.100000
2017/08/28 18:58:00 step 1: mse=177.036609 step=0.100000
2017/08/28 18:58:01 step 2: mse=175.281875 step=0.100000
2017/08/28 18:58:02 step 3: mse=174.053709 step=0.100000
2017/08/28 18:58:03 step 4: mse=172.709708 step=0.100000
2017/08/28 18:58:04 step 5: mse=171.701849 step=0.100000
2017/08/28 18:58:05 step 6: mse=170.721637 step=0.100000
2017/08/28 18:58:06 step 7: mse=169.765079 step=0.100000
2017/08/28 18:58:06 Saving...
2017/08/28 18:58:06 Gathering batch of experience...
2017/08/28 18:58:46 batch 512: mean=143.473684 stddev=134.284015 entropy=0.412926 frames=5044 count=38
2017/08/28 18:58:46 Training policy...
2017/08/28 18:58:49 step 0: objective=2.7279847
2017/08/28 18:58:51 step 1: objective=2.7407913
2017/08/28 18:58:52 step 2: objective=2.7480235
2017/08/28 18:58:53 step 3: objective=2.7592387
2017/08/28 18:58:55 step 4: objective=2.7671278
2017/08/28 18:58:56 step 5: objective=2.774769
2017/08/28 18:58:57 step 6: objective=2.7831006
2017/08/28 18:58:59 step 7: objective=2.7912123
2017/08/28 18:58:59 Training value function...
2017/08/28 18:59:01 step 0: mse=239.427463 step=0.100000
2017/08/28 18:59:02 step 1: mse=227.884735 step=0.100000
2017/08/28 18:59:03 step 2: mse=217.985320 step=0.100000
2017/08/28 18:59:04 step 3: mse=209.459983 step=0.100000
2017/08/28 18:59:05 step 4: mse=202.616294 step=0.100000
2017/08/28 18:59:06 step 5: mse=196.362510 step=0.100000
2017/08/28 18:59:07 step 6: mse=191.326103 step=0.100000
2017/08/28 18:59:08 step 7: mse=186.500822 step=0.100000
2017/08/28 18:59:08 Saving...
2017/08/28 18:59:08 Gathering batch of experience...
2017/08/28 18:59:51 batch 513: mean=92.188679 stddev=74.826858 entropy=0.407539 frames=4805 count=53
2017/08/28 18:59:51 Training policy...
2017/08/28 18:59:55 step 0: objective=-0.07728801
2017/08/28 18:59:56 step 1: objective=-0.06750809
2017/08/28 18:59:57 step 2: objective=-0.052043445
2017/08/28 18:59:59 step 3: objective=-0.04332066
2017/08/28 19:00:00 step 4: objective=-0.0360809
2017/08/28 19:00:01 step 5: objective=-0.02833344
2017/08/28 19:00:02 step 6: objective=-0.024392331
2017/08/28 19:00:03 step 7: objective=-0.018806193
2017/08/28 19:00:03 Training value function...
2017/08/28 19:00:05 step 0: mse=168.979786 step=0.100000
2017/08/28 19:00:06 step 1: mse=166.305694 step=0.100000
2017/08/28 19:00:07 step 2: mse=163.804097 step=0.100000
2017/08/28 19:00:08 step 3: mse=161.547578 step=0.100000
2017/08/28 19:00:09 step 4: mse=159.405951 step=0.100000
2017/08/28 19:00:10 step 5: mse=157.813189 step=0.100000
2017/08/28 19:00:11 step 6: mse=156.435604 step=0.100000
2017/08/28 19:00:12 step 7: mse=155.127021 step=0.100000
2017/08/28 19:00:12 Saving...
2017/08/28 19:00:12 Gathering batch of experience...
2017/08/28 19:00:58 batch 514: mean=81.032787 stddev=80.185025 entropy=0.408433 frames=4968 count=61
2017/08/28 19:00:58 Training policy...
2017/08/28 19:01:02 step 0: objective=-0.011350864
2017/08/28 19:01:03 step 1: objective=-0.0025833678
2017/08/28 19:01:05 step 2: objective=0.0032434494
2017/08/28 19:01:06 step 3: objective=0.009404675
2017/08/28 19:01:07 step 4: objective=0.017631477
2017/08/28 19:01:08 step 5: objective=0.027226716
2017/08/28 19:01:10 step 6: objective=0.031194355
2017/08/28 19:01:11 step 7: objective=0.03541755
2017/08/28 19:01:11 Training value function...
2017/08/28 19:01:13 step 0: mse=167.882897 step=0.100000
2017/08/28 19:01:14 step 1: mse=166.664237 step=0.100000
2017/08/28 19:01:15 step 2: mse=165.488354 step=0.100000
2017/08/28 19:01:16 step 3: mse=164.259995 step=0.100000
2017/08/28 19:01:17 step 4: mse=162.906756 step=0.100000
2017/08/28 19:01:18 step 5: mse=162.170020 step=0.100000
2017/08/28 19:01:19 step 6: mse=161.222941 step=0.100000
2017/08/28 19:01:20 step 7: mse=160.283244 step=0.100000
2017/08/28 19:01:20 Saving...
2017/08/28 19:01:20 Gathering batch of experience...
2017/08/28 19:02:05 batch 515: mean=109.897959 stddev=88.538760 entropy=0.404959 frames=5192 count=49
2017/08/28 19:02:05 Training policy...
2017/08/28 19:02:09 step 0: objective=1.6645128
2017/08/28 19:02:10 step 1: objective=1.676808
2017/08/28 19:02:12 step 2: objective=1.6870147
2017/08/28 19:02:13 step 3: objective=1.6936412
2017/08/28 19:02:14 step 4: objective=1.698141
2017/08/28 19:02:16 step 5: objective=1.7049968
2017/08/28 19:02:17 step 6: objective=1.7134088
2017/08/28 19:02:18 step 7: objective=1.719404
2017/08/28 19:02:18 Training value function...
2017/08/28 19:02:21 step 0: mse=190.792514 step=0.100000
2017/08/28 19:02:22 step 1: mse=188.178859 step=0.100000
2017/08/28 19:02:23 step 2: mse=185.589956 step=0.100000
2017/08/28 19:02:24 step 3: mse=183.577508 step=0.100000
2017/08/28 19:02:25 step 4: mse=181.316846 step=0.100000
2017/08/28 19:02:26 step 5: mse=179.101861 step=0.100000
2017/08/28 19:02:27 step 6: mse=177.317554 step=0.100000
2017/08/28 19:02:28 step 7: mse=175.765001 step=0.100000
2017/08/28 19:02:28 Saving...
2017/08/28 19:02:28 Gathering batch of experience...
2017/08/28 19:03:17 batch 516: mean=96.288462 stddev=96.009682 entropy=0.407854 frames=5010 count=52
2017/08/28 19:03:17 Training policy...
2017/08/28 19:03:21 step 0: objective=0.75261253
2017/08/28 19:03:22 step 1: objective=0.7603499
2017/08/28 19:03:23 step 2: objective=0.76553524
2017/08/28 19:03:25 step 3: objective=0.7757279
2017/08/28 19:03:26 step 4: objective=0.78111905
2017/08/28 19:03:27 step 5: objective=0.78541356
2017/08/28 19:03:28 step 6: objective=0.79091936
2017/08/28 19:03:30 step 7: objective=0.79844946
2017/08/28 19:03:30 Training value function...
2017/08/28 19:03:32 step 0: mse=162.221739 step=0.100000
2017/08/28 19:03:33 step 1: mse=159.980226 step=0.100000
2017/08/28 19:03:34 step 2: mse=157.062216 step=0.100000
2017/08/28 19:03:35 step 3: mse=154.886859 step=0.100000
2017/08/28 19:03:36 step 4: mse=153.516308 step=0.100000
2017/08/28 19:03:37 step 5: mse=151.579276 step=0.100000
2017/08/28 19:03:38 step 6: mse=150.227636 step=0.100000
2017/08/28 19:03:39 step 7: mse=148.779246 step=0.100000
2017/08/28 19:03:39 Saving...
2017/08/28 19:03:39 Gathering batch of experience...
2017/08/28 19:04:19 batch 517: mean=117.068182 stddev=75.885200 entropy=0.412879 frames=4777 count=44
2017/08/28 19:04:19 Training policy...
2017/08/28 19:04:23 step 0: objective=1.7632037
2017/08/28 19:04:24 step 1: objective=1.7697248
2017/08/28 19:04:25 step 2: objective=1.7773697
2017/08/28 19:04:26 step 3: objective=1.7824185
2017/08/28 19:04:28 step 4: objective=1.7893602
2017/08/28 19:04:29 step 5: objective=1.7964835
2017/08/28 19:04:30 step 6: objective=1.8044604
2017/08/28 19:04:31 step 7: objective=1.811154
2017/08/28 19:04:31 Training value function...
2017/08/28 19:04:33 step 0: mse=180.139065 step=0.100000
2017/08/28 19:04:34 step 1: mse=174.768072 step=0.100000
2017/08/28 19:04:35 step 2: mse=170.650559 step=0.100000
2017/08/28 19:04:36 step 3: mse=166.856031 step=0.100000
2017/08/28 19:04:37 step 4: mse=163.645850 step=0.100000
2017/08/28 19:04:38 step 5: mse=160.847122 step=0.100000
2017/08/28 19:04:39 step 6: mse=158.243738 step=0.100000
2017/08/28 19:04:40 step 7: mse=156.179814 step=0.100000
2017/08/28 19:04:40 Saving...
2017/08/28 19:04:40 Gathering batch of experience...
2017/08/28 19:05:27 batch 518: mean=126.739130 stddev=82.519414 entropy=0.409228 frames=5561 count=46
2017/08/28 19:05:27 Training policy...
2017/08/28 19:05:31 step 0: objective=1.3938965
2017/08/28 19:05:33 step 1: objective=1.4024559
2017/08/28 19:05:34 step 2: objective=1.4116951
2017/08/28 19:05:36 step 3: objective=1.4222277
2017/08/28 19:05:37 step 4: objective=1.42944
2017/08/28 19:05:39 step 5: objective=1.433938
2017/08/28 19:05:40 step 6: objective=1.4390855
2017/08/28 19:05:41 step 7: objective=1.4434054
2017/08/28 19:05:41 Training value function...
2017/08/28 19:05:44 step 0: mse=155.932958 step=0.100000
2017/08/28 19:05:45 step 1: mse=152.324885 step=0.100000
2017/08/28 19:05:46 step 2: mse=149.150882 step=0.100000
2017/08/28 19:05:47 step 3: mse=146.462382 step=0.100000
2017/08/28 19:05:48 step 4: mse=144.161865 step=0.100000
2017/08/28 19:05:50 step 5: mse=141.945419 step=0.100000
2017/08/28 19:05:51 step 6: mse=140.166504 step=0.100000
2017/08/28 19:05:52 step 7: mse=138.517761 step=0.100000
2017/08/28 19:05:52 Saving...
2017/08/28 19:05:52 Gathering batch of experience...
2017/08/28 19:06:34 batch 519: mean=115.088889 stddev=88.955125 entropy=0.406397 frames=4884 count=45
2017/08/28 19:06:34 Training policy...
2017/08/28 19:06:38 step 0: objective=0.93066543
2017/08/28 19:06:39 step 1: objective=0.9370809
2017/08/28 19:06:40 step 2: objective=0.94930893
2017/08/28 19:06:42 step 3: objective=0.95818776
2017/08/28 19:06:43 step 4: objective=0.9649583
2017/08/28 19:06:44 step 5: objective=0.96853775
2017/08/28 19:06:45 step 6: objective=0.97594106
2017/08/28 19:06:47 step 7: objective=0.9815849
2017/08/28 19:06:47 Training value function...
2017/08/28 19:06:49 step 0: mse=160.295478 step=0.100000
2017/08/28 19:06:50 step 1: mse=158.754314 step=0.100000
2017/08/28 19:06:51 step 2: mse=157.229267 step=0.100000
2017/08/28 19:06:52 step 3: mse=156.082447 step=0.100000
2017/08/28 19:06:53 step 4: mse=155.259455 step=0.100000
2017/08/28 19:06:54 step 5: mse=153.789915 step=0.100000
2017/08/28 19:06:55 step 6: mse=153.004349 step=0.100000
2017/08/28 19:06:56 step 7: mse=151.967881 step=0.100000
2017/08/28 19:06:56 Saving...
2017/08/28 19:06:56 Gathering batch of experience...
2017/08/28 19:07:44 batch 520: mean=95.473684 stddev=71.451396 entropy=0.399511 frames=5435 count=57
2017/08/28 19:07:44 Training policy...
2017/08/28 19:07:47 step 0: objective=-0.12490905
2017/08/28 19:07:49 step 1: objective=-0.115904294
2017/08/28 19:07:50 step 2: objective=-0.10923662
2017/08/28 19:07:52 step 3: objective=-0.10208682
2017/08/28 19:07:53 step 4: objective=-0.09298751
2017/08/28 19:07:55 step 5: objective=-0.087348424
2017/08/28 19:07:56 step 6: objective=-0.078900024
2017/08/28 19:07:57 step 7: objective=-0.076393045
2017/08/28 19:07:57 Training value function...
2017/08/28 19:08:00 step 0: mse=144.833982 step=0.100000
2017/08/28 19:08:01 step 1: mse=143.290377 step=0.100000
2017/08/28 19:08:02 step 2: mse=142.160668 step=0.100000
2017/08/28 19:08:03 step 3: mse=141.302774 step=0.100000
2017/08/28 19:08:04 step 4: mse=140.312201 step=0.100000
2017/08/28 19:08:05 step 5: mse=139.469220 step=0.100000
2017/08/28 19:08:06 step 6: mse=138.540980 step=0.100000
2017/08/28 19:08:08 step 7: mse=137.852853 step=0.100000
2017/08/28 19:08:08 Saving...
2017/08/28 19:08:08 Gathering batch of experience...
2017/08/28 19:08:49 batch 521: mean=125.238095 stddev=83.821752 entropy=0.401408 frames=4993 count=42
2017/08/28 19:08:49 Training policy...
2017/08/28 19:08:53 step 0: objective=1.8138108
2017/08/28 19:08:54 step 1: objective=1.819342
2017/08/28 19:08:55 step 2: objective=1.8284132
2017/08/28 19:08:56 step 3: objective=1.8378245
2017/08/28 19:08:58 step 4: objective=1.8465161
2017/08/28 19:08:59 step 5: objective=1.8508885
2017/08/28 19:09:00 step 6: objective=1.8547016
2017/08/28 19:09:02 step 7: objective=1.861007
2017/08/28 19:09:02 Training value function...
2017/08/28 19:09:04 step 0: mse=171.286160 step=0.100000
2017/08/28 19:09:05 step 1: mse=167.900837 step=0.100000
2017/08/28 19:09:06 step 2: mse=164.626450 step=0.100000
2017/08/28 19:09:07 step 3: mse=161.607475 step=0.100000
2017/08/28 19:09:08 step 4: mse=159.143808 step=0.100000
2017/08/28 19:09:09 step 5: mse=157.170722 step=0.100000
2017/08/28 19:09:10 step 6: mse=154.858980 step=0.100000
2017/08/28 19:09:11 step 7: mse=152.755362 step=0.100000
2017/08/28 19:09:11 Saving...
2017/08/28 19:09:11 Gathering batch of experience...
2017/08/28 19:09:53 batch 522: mean=121.744186 stddev=83.924965 entropy=0.405355 frames=5000 count=43
2017/08/28 19:09:53 Training policy...
2017/08/28 19:09:57 step 0: objective=1.0558971
2017/08/28 19:09:58 step 1: objective=1.0710994
2017/08/28 19:09:59 step 2: objective=1.085327
2017/08/28 19:10:01 step 3: objective=1.0904924
2017/08/28 19:10:02 step 4: objective=1.0997458
2017/08/28 19:10:03 step 5: objective=1.1056513
2017/08/28 19:10:05 step 6: objective=1.1094621
2017/08/28 19:10:06 step 7: objective=1.1123147
2017/08/28 19:10:06 Training value function...
2017/08/28 19:10:08 step 0: mse=176.141937 step=0.100000
2017/08/28 19:10:09 step 1: mse=174.052509 step=0.100000
2017/08/28 19:10:10 step 2: mse=172.415279 step=0.100000
2017/08/28 19:10:11 step 3: mse=170.494364 step=0.100000
2017/08/28 19:10:12 step 4: mse=168.993271 step=0.100000
2017/08/28 19:10:13 step 5: mse=167.322200 step=0.100000
2017/08/28 19:10:14 step 6: mse=165.712225 step=0.100000
2017/08/28 19:10:15 step 7: mse=164.264661 step=0.100000
2017/08/28 19:10:15 Saving...
2017/08/28 19:10:15 Gathering batch of experience...
2017/08/28 19:10:59 batch 523: mean=99.634615 stddev=68.324742 entropy=0.400528 frames=4983 count=52
2017/08/28 19:10:59 Training policy...
2017/08/28 19:11:03 step 0: objective=0.29599857
2017/08/28 19:11:04 step 1: objective=0.30944574
2017/08/28 19:11:06 step 2: objective=0.31924587
2017/08/28 19:11:07 step 3: objective=0.32466522
2017/08/28 19:11:08 step 4: objective=0.33664837
2017/08/28 19:11:09 step 5: objective=0.34258
2017/08/28 19:11:11 step 6: objective=0.34940368
2017/08/28 19:11:12 step 7: objective=0.35575652
2017/08/28 19:11:12 Training value function...
2017/08/28 19:11:14 step 0: mse=165.107949 step=0.100000
2017/08/28 19:11:15 step 1: mse=163.554202 step=0.100000
2017/08/28 19:11:16 step 2: mse=162.263825 step=0.100000
2017/08/28 19:11:17 step 3: mse=161.413547 step=0.100000
2017/08/28 19:11:18 step 4: mse=160.581654 step=0.100000
2017/08/28 19:11:19 step 5: mse=159.412630 step=0.100000
2017/08/28 19:11:20 step 6: mse=158.819548 step=0.100000
2017/08/28 19:11:21 step 7: mse=157.591195 step=0.100000
2017/08/28 19:11:21 Saving...
2017/08/28 19:11:21 Gathering batch of experience...
2017/08/28 19:12:04 batch 524: mean=138.666667 stddev=118.352312 entropy=0.413017 frames=5549 count=42
2017/08/28 19:12:04 Training policy...
2017/08/28 19:12:08 step 0: objective=2.238912
2017/08/28 19:12:10 step 1: objective=2.2508404
2017/08/28 19:12:11 step 2: objective=2.2607176
2017/08/28 19:12:13 step 3: objective=2.2708595
2017/08/28 19:12:14 step 4: objective=2.2811213
2017/08/28 19:12:16 step 5: objective=2.2873256
2017/08/28 19:12:17 step 6: objective=2.2922065
2017/08/28 19:12:18 step 7: objective=2.2951138
2017/08/28 19:12:18 Training value function...
2017/08/28 19:12:21 step 0: mse=207.054358 step=0.100000
2017/08/28 19:12:22 step 1: mse=200.602409 step=0.100000
2017/08/28 19:12:23 step 2: mse=195.031211 step=0.100000
2017/08/28 19:12:24 step 3: mse=190.342181 step=0.100000
2017/08/28 19:12:25 step 4: mse=186.461763 step=0.100000
2017/08/28 19:12:27 step 5: mse=182.828017 step=0.100000
2017/08/28 19:12:28 step 6: mse=179.805135 step=0.100000
2017/08/28 19:12:29 step 7: mse=177.224041 step=0.100000
2017/08/28 19:12:29 Saving...
2017/08/28 19:12:29 Gathering batch of experience...
2017/08/28 19:13:14 batch 525: mean=115.775510 stddev=103.461965 entropy=0.402803 frames=5504 count=49
2017/08/28 19:13:14 Training policy...
2017/08/28 19:13:18 step 0: objective=0.6782038
2017/08/28 19:13:19 step 1: objective=0.68346626
2017/08/28 19:13:21 step 2: objective=0.689778
2017/08/28 19:13:22 step 3: objective=0.6957465
2017/08/28 19:13:24 step 4: objective=0.70056057
2017/08/28 19:13:25 step 5: objective=0.7068975
2017/08/28 19:13:26 step 6: objective=0.7162737
2017/08/28 19:13:28 step 7: objective=0.7221863
2017/08/28 19:13:28 Training value function...
2017/08/28 19:13:30 step 0: mse=146.782760 step=0.100000
2017/08/28 19:13:31 step 1: mse=145.051894 step=0.100000
2017/08/28 19:13:32 step 2: mse=143.512004 step=0.100000
2017/08/28 19:13:34 step 3: mse=142.401566 step=0.100000
2017/08/28 19:13:35 step 4: mse=141.225143 step=0.100000
2017/08/28 19:13:36 step 5: mse=139.975025 step=0.100000
2017/08/28 19:13:37 step 6: mse=139.143993 step=0.100000
2017/08/28 19:13:38 step 7: mse=138.261135 step=0.100000
2017/08/28 19:13:38 Saving...
2017/08/28 19:13:38 Gathering batch of experience...
2017/08/28 19:14:19 batch 526: mean=119.318182 stddev=93.335605 entropy=0.417320 frames=4880 count=44
2017/08/28 19:14:19 Training policy...
2017/08/28 19:14:23 step 0: objective=1.3049332
2017/08/28 19:14:24 step 1: objective=1.3120786
2017/08/28 19:14:25 step 2: objective=1.3232874
2017/08/28 19:14:27 step 3: objective=1.3320235
2017/08/28 19:14:28 step 4: objective=1.339418
2017/08/28 19:14:29 step 5: objective=1.3486615
2017/08/28 19:14:31 step 6: objective=1.3530916
2017/08/28 19:14:32 step 7: objective=1.3581792
2017/08/28 19:14:32 Training value function...
2017/08/28 19:14:34 step 0: mse=179.181745 step=0.100000
2017/08/28 19:14:35 step 1: mse=176.902422 step=0.100000
2017/08/28 19:14:36 step 2: mse=174.918919 step=0.100000
2017/08/28 19:14:37 step 3: mse=172.960659 step=0.100000
2017/08/28 19:14:38 step 4: mse=171.129505 step=0.100000
2017/08/28 19:14:39 step 5: mse=169.427041 step=0.100000
2017/08/28 19:14:40 step 6: mse=168.053011 step=0.100000
2017/08/28 19:14:41 step 7: mse=166.831395 step=0.100000
2017/08/28 19:14:41 Saving...
2017/08/28 19:14:41 Gathering batch of experience...
2017/08/28 19:15:26 batch 527: mean=99.754717 stddev=85.510874 entropy=0.408921 frames=5143 count=53
2017/08/28 19:15:26 Training policy...
2017/08/28 19:15:30 step 0: objective=0.29901382
2017/08/28 19:15:31 step 1: objective=0.30616412
2017/08/28 19:15:33 step 2: objective=0.3148068
2017/08/28 19:15:34 step 3: objective=0.32921246
2017/08/28 19:15:35 step 4: objective=0.338185
2017/08/28 19:15:37 step 5: objective=0.34574756
2017/08/28 19:15:38 step 6: objective=0.34969315
2017/08/28 19:15:39 step 7: objective=0.3534507
2017/08/28 19:15:39 Training value function...
2017/08/28 19:15:42 step 0: mse=187.958234 step=0.100000
2017/08/28 19:15:43 step 1: mse=184.616695 step=0.100000
2017/08/28 19:15:44 step 2: mse=181.825871 step=0.100000
2017/08/28 19:15:45 step 3: mse=179.719225 step=0.100000
2017/08/28 19:15:46 step 4: mse=177.500118 step=0.100000
2017/08/28 19:15:47 step 5: mse=175.908377 step=0.100000
2017/08/28 19:15:48 step 6: mse=174.529179 step=0.100000
2017/08/28 19:15:49 step 7: mse=173.088082 step=0.100000
2017/08/28 19:15:49 Saving...
2017/08/28 19:15:49 Gathering batch of experience...
2017/08/28 19:16:28 batch 528: mean=136.421053 stddev=108.234305 entropy=0.407391 frames=4892 count=38
2017/08/28 19:16:28 Training policy...
2017/08/28 19:16:31 step 0: objective=2.0087874
2017/08/28 19:16:32 step 1: objective=2.0175672
2017/08/28 19:16:34 step 2: objective=2.027795
2017/08/28 19:16:35 step 3: objective=2.0339067
2017/08/28 19:16:36 step 4: objective=2.0390286
2017/08/28 19:16:38 step 5: objective=2.0441437
2017/08/28 19:16:39 step 6: objective=2.050757
2017/08/28 19:16:40 step 7: objective=2.0560033
2017/08/28 19:16:40 Training value function...
2017/08/28 19:16:42 step 0: mse=210.362097 step=0.100000
2017/08/28 19:16:43 step 1: mse=203.032159 step=0.100000
2017/08/28 19:16:44 step 2: mse=197.105070 step=0.100000
2017/08/28 19:16:45 step 3: mse=191.943956 step=0.100000
2017/08/28 19:16:46 step 4: mse=188.107893 step=0.100000
2017/08/28 19:16:47 step 5: mse=184.240883 step=0.100000
2017/08/28 19:16:48 step 6: mse=181.633140 step=0.100000
2017/08/28 19:16:49 step 7: mse=179.008899 step=0.100000
2017/08/28 19:16:49 Saving...
2017/08/28 19:16:49 Gathering batch of experience...
2017/08/28 19:17:31 batch 529: mean=88.711538 stddev=90.292545 entropy=0.402206 frames=4612 count=52
2017/08/28 19:17:31 Training policy...
2017/08/28 19:17:34 step 0: objective=-0.46371177
2017/08/28 19:17:35 step 1: objective=-0.4505161
2017/08/28 19:17:36 step 2: objective=-0.44198462
2017/08/28 19:17:38 step 3: objective=-0.4271861
2017/08/28 19:17:39 step 4: objective=-0.4208804
2017/08/28 19:17:40 step 5: objective=-0.41183937
2017/08/28 19:17:41 step 6: objective=-0.40538317
2017/08/28 19:17:43 step 7: objective=-0.40044138
2017/08/28 19:17:43 Training value function...
2017/08/28 19:17:44 step 0: mse=196.196067 step=0.100000
2017/08/28 19:17:45 step 1: mse=192.829647 step=0.100000
2017/08/28 19:17:46 step 2: mse=189.528565 step=0.100000
2017/08/28 19:17:47 step 3: mse=186.907298 step=0.100000
2017/08/28 19:17:48 step 4: mse=185.074695 step=0.100000
2017/08/28 19:17:49 step 5: mse=183.416320 step=0.100000
2017/08/28 19:17:50 step 6: mse=182.027217 step=0.100000
2017/08/28 19:17:51 step 7: mse=180.098731 step=0.100000
2017/08/28 19:17:51 Saving...
2017/08/28 19:17:51 Gathering batch of experience...
2017/08/28 19:18:36 batch 530: mean=126.418605 stddev=102.894444 entropy=0.412255 frames=5285 count=43
2017/08/28 19:18:36 Training policy...
2017/08/28 19:18:39 step 0: objective=1.6272887
2017/08/28 19:18:41 step 1: objective=1.6327852
2017/08/28 19:18:42 step 2: objective=1.6416478
2017/08/28 19:18:44 step 3: objective=1.6499404
2017/08/28 19:18:45 step 4: objective=1.6589048
2017/08/28 19:18:46 step 5: objective=1.6643142
2017/08/28 19:18:48 step 6: objective=1.6690972
2017/08/28 19:18:49 step 7: objective=1.6754098
2017/08/28 19:18:49 Training value function...
2017/08/28 19:18:51 step 0: mse=185.662597 step=0.100000
2017/08/28 19:18:52 step 1: mse=181.968736 step=0.100000
2017/08/28 19:18:54 step 2: mse=178.248348 step=0.100000
2017/08/28 19:18:55 step 3: mse=175.066016 step=0.100000
2017/08/28 19:18:56 step 4: mse=172.367187 step=0.100000
2017/08/28 19:18:57 step 5: mse=170.022911 step=0.100000
2017/08/28 19:18:58 step 6: mse=167.890619 step=0.100000
2017/08/28 19:18:59 step 7: mse=165.739682 step=0.100000
2017/08/28 19:18:59 Saving...
2017/08/28 19:18:59 Gathering batch of experience...
2017/08/28 19:19:45 batch 531: mean=96.254545 stddev=95.993223 entropy=0.404472 frames=5139 count=55
2017/08/28 19:19:45 Training policy...
2017/08/28 19:19:48 step 0: objective=0.5120438
2017/08/28 19:19:50 step 1: objective=0.5273187
2017/08/28 19:19:51 step 2: objective=0.54356253
2017/08/28 19:19:52 step 3: objective=0.5526685
2017/08/28 19:19:54 step 4: objective=0.55618906
2017/08/28 19:19:55 step 5: objective=0.56211776
2017/08/28 19:19:56 step 6: objective=0.57041305
2017/08/28 19:19:58 step 7: objective=0.57575595
2017/08/28 19:19:58 Training value function...
2017/08/28 19:20:00 step 0: mse=204.632884 step=0.100000
2017/08/28 19:20:01 step 1: mse=201.364673 step=0.100000
2017/08/28 19:20:02 step 2: mse=198.581634 step=0.100000
2017/08/28 19:20:03 step 3: mse=195.973294 step=0.100000
2017/08/28 19:20:04 step 4: mse=194.037080 step=0.100000
2017/08/28 19:20:05 step 5: mse=192.114501 step=0.100000
2017/08/28 19:20:06 step 6: mse=190.525473 step=0.100000
2017/08/28 19:20:07 step 7: mse=189.128022 step=0.100000
2017/08/28 19:20:07 Saving...
2017/08/28 19:20:07 Gathering batch of experience...
2017/08/28 19:20:53 batch 532: mean=114.354167 stddev=106.810675 entropy=0.412235 frames=5416 count=48
2017/08/28 19:20:53 Training policy...
2017/08/28 19:20:57 step 0: objective=0.9395468
2017/08/28 19:20:59 step 1: objective=0.9505775
2017/08/28 19:21:00 step 2: objective=0.9589207
2017/08/28 19:21:01 step 3: objective=0.9655036
2017/08/28 19:21:03 step 4: objective=0.9735285
2017/08/28 19:21:04 step 5: objective=0.98193055
2017/08/28 19:21:06 step 6: objective=0.9869911
2017/08/28 19:21:07 step 7: objective=0.9915173
2017/08/28 19:21:07 Training value function...
2017/08/28 19:21:09 step 0: mse=163.297813 step=0.100000
2017/08/28 19:21:10 step 1: mse=159.798192 step=0.100000
2017/08/28 19:21:12 step 2: mse=157.125277 step=0.100000
2017/08/28 19:21:13 step 3: mse=154.919584 step=0.100000
2017/08/28 19:21:14 step 4: mse=152.966003 step=0.100000
2017/08/28 19:21:15 step 5: mse=151.069217 step=0.100000
2017/08/28 19:21:16 step 6: mse=149.391125 step=0.100000
2017/08/28 19:21:17 step 7: mse=148.020992 step=0.100000
2017/08/28 19:21:17 Saving...
2017/08/28 19:21:17 Gathering batch of experience...
2017/08/28 19:22:04 batch 533: mean=96.580000 stddev=76.922582 entropy=0.401280 frames=5111 count=50
2017/08/28 19:22:04 Training policy...
2017/08/28 19:22:07 step 0: objective=-0.12053992
2017/08/28 19:22:09 step 1: objective=-0.11311784
2017/08/28 19:22:10 step 2: objective=-0.10542687
2017/08/28 19:22:11 step 3: objective=-0.09903683
2017/08/28 19:22:13 step 4: objective=-0.093051895
2017/08/28 19:22:14 step 5: objective=-0.08758235
2017/08/28 19:22:15 step 6: objective=-0.082442395
2017/08/28 19:22:17 step 7: objective=-0.0781675
2017/08/28 19:22:17 Training value function...
2017/08/28 19:22:19 step 0: mse=134.930361 step=0.100000
2017/08/28 19:22:20 step 1: mse=132.188389 step=0.100000
2017/08/28 19:22:21 step 2: mse=130.185809 step=0.100000
2017/08/28 19:22:22 step 3: mse=128.097908 step=0.100000
2017/08/28 19:22:23 step 4: mse=126.330846 step=0.100000
2017/08/28 19:22:24 step 5: mse=124.979429 step=0.100000
2017/08/28 19:22:25 step 6: mse=123.767589 step=0.100000
2017/08/28 19:22:26 step 7: mse=122.914961 step=0.100000
2017/08/28 19:22:26 Saving...
2017/08/28 19:22:26 Gathering batch of experience...
2017/08/28 19:23:08 batch 534: mean=107.916667 stddev=87.223810 entropy=0.406291 frames=4950 count=48
2017/08/28 19:23:08 Training policy...
2017/08/28 19:23:12 step 0: objective=1.8413068
2017/08/28 19:23:13 step 1: objective=1.8512344
2017/08/28 19:23:14 step 2: objective=1.8641198
2017/08/28 19:23:16 step 3: objective=1.8710645
2017/08/28 19:23:17 step 4: objective=1.8787739
2017/08/28 19:23:18 step 5: objective=1.8883499
2017/08/28 19:23:19 step 6: objective=1.8924519
2017/08/28 19:23:21 step 7: objective=1.8985173
2017/08/28 19:23:21 Training value function...
2017/08/28 19:23:23 step 0: mse=207.308829 step=0.100000
2017/08/28 19:23:24 step 1: mse=202.809141 step=0.100000
2017/08/28 19:23:25 step 2: mse=198.853606 step=0.100000
2017/08/28 19:23:26 step 3: mse=195.232824 step=0.100000
2017/08/28 19:23:27 step 4: mse=192.067508 step=0.100000
2017/08/28 19:23:28 step 5: mse=189.298803 step=0.100000
2017/08/28 19:23:29 step 6: mse=186.712753 step=0.100000
2017/08/28 19:23:30 step 7: mse=184.495764 step=0.100000
2017/08/28 19:23:30 Saving...
2017/08/28 19:23:30 Gathering batch of experience...
2017/08/28 19:24:20 batch 535: mean=136.533333 stddev=119.337169 entropy=0.408572 frames=6075 count=45
2017/08/28 19:24:20 Training policy...
2017/08/28 19:24:24 step 0: objective=1.6305366
2017/08/28 19:24:26 step 1: objective=1.6357499
2017/08/28 19:24:27 step 2: objective=1.6447269
2017/08/28 19:24:29 step 3: objective=1.649981
2017/08/28 19:24:30 step 4: objective=1.658889
2017/08/28 19:24:32 step 5: objective=1.6673151
2017/08/28 19:24:34 step 6: objective=1.6732887
2017/08/28 19:24:35 step 7: objective=1.6782929
2017/08/28 19:24:35 Training value function...
2017/08/28 19:24:38 step 0: mse=206.989188 step=0.100000
2017/08/28 19:24:39 step 1: mse=201.437262 step=0.100000
2017/08/28 19:24:40 step 2: mse=196.644405 step=0.100000
2017/08/28 19:24:41 step 3: mse=192.951018 step=0.100000
2017/08/28 19:24:43 step 4: mse=189.797875 step=0.100000
2017/08/28 19:24:44 step 5: mse=186.516584 step=0.100000
2017/08/28 19:24:45 step 6: mse=183.965627 step=0.100000
2017/08/28 19:24:46 step 7: mse=181.682487 step=0.100000
2017/08/28 19:24:46 Saving...
2017/08/28 19:24:47 Gathering batch of experience...
2017/08/28 19:25:28 batch 536: mean=136.225000 stddev=99.519467 entropy=0.403977 frames=5058 count=40
2017/08/28 19:25:28 Training policy...
2017/08/28 19:25:32 step 0: objective=1.7315111
2017/08/28 19:25:33 step 1: objective=1.7421663
2017/08/28 19:25:35 step 2: objective=1.7513174
2017/08/28 19:25:36 step 3: objective=1.7561145
2017/08/28 19:25:37 step 4: objective=1.7614691
2017/08/28 19:25:39 step 5: objective=1.7669095
2017/08/28 19:25:40 step 6: objective=1.77449
2017/08/28 19:25:41 step 7: objective=1.7805096
2017/08/28 19:25:41 Training value function...
2017/08/28 19:25:43 step 0: mse=184.159319 step=0.100000
2017/08/28 19:25:44 step 1: mse=180.351862 step=0.100000
2017/08/28 19:25:45 step 2: mse=177.214111 step=0.100000
2017/08/28 19:25:46 step 3: mse=174.625143 step=0.100000
2017/08/28 19:25:48 step 4: mse=172.239309 step=0.100000
2017/08/28 19:25:49 step 5: mse=169.750379 step=0.100000
2017/08/28 19:25:50 step 6: mse=167.736991 step=0.100000
2017/08/28 19:25:51 step 7: mse=165.745807 step=0.100000
2017/08/28 19:25:51 Saving...
2017/08/28 19:25:51 Gathering batch of experience...
2017/08/28 19:26:39 batch 537: mean=121.208333 stddev=104.610181 entropy=0.406240 frames=5683 count=48
2017/08/28 19:26:39 Training policy...
2017/08/28 19:26:43 step 0: objective=0.4746339
2017/08/28 19:26:45 step 1: objective=0.4801378
2017/08/28 19:26:46 step 2: objective=0.4859601
2017/08/28 19:26:48 step 3: objective=0.49370438
2017/08/28 19:26:49 step 4: objective=0.5014869
2017/08/28 19:26:50 step 5: objective=0.506936
2017/08/28 19:26:52 step 6: objective=0.5110158
2017/08/28 19:26:53 step 7: objective=0.5149735
2017/08/28 19:26:53 Training value function...
2017/08/28 19:26:56 step 0: mse=154.912234 step=0.100000
2017/08/28 19:26:57 step 1: mse=153.055450 step=0.100000
2017/08/28 19:26:58 step 2: mse=151.533438 step=0.100000
2017/08/28 19:26:59 step 3: mse=150.169234 step=0.100000
2017/08/28 19:27:01 step 4: mse=148.951477 step=0.100000
2017/08/28 19:27:02 step 5: mse=147.945504 step=0.100000
2017/08/28 19:27:03 step 6: mse=147.097367 step=0.100000
2017/08/28 19:27:04 step 7: mse=145.983074 step=0.100000
2017/08/28 19:27:04 Saving...
2017/08/28 19:27:04 Gathering batch of experience...
2017/08/28 19:27:49 batch 538: mean=113.500000 stddev=112.392727 entropy=0.410239 frames=5201 count=48
2017/08/28 19:27:49 Training policy...
2017/08/28 19:27:53 step 0: objective=0.9745242
2017/08/28 19:27:54 step 1: objective=0.98573965
2017/08/28 19:27:56 step 2: objective=0.99096084
2017/08/28 19:27:57 step 3: objective=1.0005668
2017/08/28 19:27:58 step 4: objective=1.0068576
2017/08/28 19:28:00 step 5: objective=1.0166892
2017/08/28 19:28:01 step 6: objective=1.023703
2017/08/28 19:28:02 step 7: objective=1.0282229
2017/08/28 19:28:02 Training value function...
2017/08/28 19:28:05 step 0: mse=169.166850 step=0.100000
2017/08/28 19:28:06 step 1: mse=167.484492 step=0.100000
2017/08/28 19:28:07 step 2: mse=165.859932 step=0.100000
2017/08/28 19:28:08 step 3: mse=164.533142 step=0.100000
2017/08/28 19:28:09 step 4: mse=163.098439 step=0.100000
2017/08/28 19:28:10 step 5: mse=162.020811 step=0.100000
2017/08/28 19:28:11 step 6: mse=161.257590 step=0.100000
2017/08/28 19:28:12 step 7: mse=159.948217 step=0.100000
2017/08/28 19:28:12 Saving...
2017/08/28 19:28:12 Gathering batch of experience...
2017/08/28 19:28:55 batch 539: mean=104.479167 stddev=78.471595 entropy=0.404777 frames=5112 count=48
2017/08/28 19:28:55 Training policy...
2017/08/28 19:28:58 step 0: objective=-0.078987606
2017/08/28 19:29:00 step 1: objective=-0.0732131
2017/08/28 19:29:01 step 2: objective=-0.06606849
2017/08/28 19:29:02 step 3: objective=-0.05794651
2017/08/28 19:29:04 step 4: objective=-0.053147227
2017/08/28 19:29:05 step 5: objective=-0.047063768
2017/08/28 19:29:06 step 6: objective=-0.044123154
2017/08/28 19:29:08 step 7: objective=-0.039059933
2017/08/28 19:29:08 Training value function...
2017/08/28 19:29:10 step 0: mse=129.227683 step=0.100000
2017/08/28 19:29:11 step 1: mse=127.377174 step=0.100000
2017/08/28 19:29:12 step 2: mse=125.522967 step=0.100000
2017/08/28 19:29:13 step 3: mse=124.184318 step=0.100000
2017/08/28 19:29:14 step 4: mse=122.914418 step=0.100000
2017/08/28 19:29:15 step 5: mse=122.038132 step=0.100000
2017/08/28 19:29:16 step 6: mse=121.131414 step=0.100000
2017/08/28 19:29:17 step 7: mse=120.117329 step=0.100000
2017/08/28 19:29:17 Saving...
2017/08/28 19:29:17 Gathering batch of experience...
2017/08/28 19:29:58 batch 540: mean=139.026316 stddev=92.466064 entropy=0.399811 frames=4929 count=38
2017/08/28 19:29:58 Training policy...
2017/08/28 19:30:01 step 0: objective=2.2325122
2017/08/28 19:30:02 step 1: objective=2.240721
2017/08/28 19:30:04 step 2: objective=2.2473595
2017/08/28 19:30:05 step 3: objective=2.2554684
2017/08/28 19:30:06 step 4: objective=2.2622027
2017/08/28 19:30:08 step 5: objective=2.2674568
2017/08/28 19:30:09 step 6: objective=2.2724233
2017/08/28 19:30:10 step 7: objective=2.2783177
2017/08/28 19:30:10 Training value function...
2017/08/28 19:30:12 step 0: mse=182.124507 step=0.100000
2017/08/28 19:30:13 step 1: mse=176.105426 step=0.100000
2017/08/28 19:30:14 step 2: mse=171.063550 step=0.100000
2017/08/28 19:30:15 step 3: mse=166.655903 step=0.100000
2017/08/28 19:30:16 step 4: mse=162.914859 step=0.100000
2017/08/28 19:30:17 step 5: mse=159.524464 step=0.100000
2017/08/28 19:30:18 step 6: mse=156.796241 step=0.100000
2017/08/28 19:30:20 step 7: mse=154.468750 step=0.100000
2017/08/28 19:30:20 Saving...
2017/08/28 19:30:20 Gathering batch of experience...
2017/08/28 19:31:03 batch 541: mean=106.877551 stddev=91.938230 entropy=0.395194 frames=4881 count=49
2017/08/28 19:31:03 Training policy...
2017/08/28 19:31:07 step 0: objective=0.6424956
2017/08/28 19:31:08 step 1: objective=0.65534663
2017/08/28 19:31:10 step 2: objective=0.66725224
2017/08/28 19:31:11 step 3: objective=0.6758659
2017/08/28 19:31:12 step 4: objective=0.6856114
2017/08/28 19:31:13 step 5: objective=0.6918352
2017/08/28 19:31:15 step 6: objective=0.69523996
2017/08/28 19:31:16 step 7: objective=0.70144105
2017/08/28 19:31:16 Training value function...
2017/08/28 19:31:18 step 0: mse=189.832263 step=0.100000
2017/08/28 19:31:19 step 1: mse=186.551664 step=0.100000
2017/08/28 19:31:20 step 2: mse=183.915788 step=0.100000
2017/08/28 19:31:21 step 3: mse=181.665694 step=0.100000
2017/08/28 19:31:22 step 4: mse=179.763776 step=0.100000
2017/08/28 19:31:23 step 5: mse=178.181312 step=0.100000
2017/08/28 19:31:24 step 6: mse=176.918910 step=0.100000
2017/08/28 19:31:25 step 7: mse=175.058986 step=0.100000
2017/08/28 19:31:25 Saving...
2017/08/28 19:31:25 Gathering batch of experience...
2017/08/28 19:32:10 batch 542: mean=96.634615 stddev=74.949734 entropy=0.394974 frames=4975 count=52
2017/08/28 19:32:10 Training policy...
2017/08/28 19:32:13 step 0: objective=-0.17953253
2017/08/28 19:32:15 step 1: objective=-0.168041
2017/08/28 19:32:16 step 2: objective=-0.16082144
2017/08/28 19:32:17 step 3: objective=-0.15382023
2017/08/28 19:32:19 step 4: objective=-0.14683826
2017/08/28 19:32:20 step 5: objective=-0.14148737
2017/08/28 19:32:21 step 6: objective=-0.13644792
2017/08/28 19:32:23 step 7: objective=-0.13126701
2017/08/28 19:32:23 Training value function...
2017/08/28 19:32:25 step 0: mse=150.463312 step=0.100000
2017/08/28 19:32:26 step 1: mse=147.923506 step=0.100000
2017/08/28 19:32:27 step 2: mse=145.896854 step=0.100000
2017/08/28 19:32:28 step 3: mse=144.452526 step=0.100000
2017/08/28 19:32:29 step 4: mse=143.139635 step=0.100000
2017/08/28 19:32:30 step 5: mse=142.073884 step=0.100000
2017/08/28 19:32:31 step 6: mse=140.898460 step=0.100000
2017/08/28 19:32:32 step 7: mse=140.156625 step=0.100000
2017/08/28 19:32:32 Saving...
2017/08/28 19:32:32 Gathering batch of experience...
2017/08/28 19:33:17 batch 543: mean=105.040000 stddev=84.790320 entropy=0.401100 frames=5229 count=50
2017/08/28 19:33:17 Training policy...
2017/08/28 19:33:20 step 0: objective=0.824168
2017/08/28 19:33:22 step 1: objective=0.83823717
2017/08/28 19:33:23 step 2: objective=0.84415525
2017/08/28 19:33:24 step 3: objective=0.85314316
2017/08/28 19:33:26 step 4: objective=0.8599623
2017/08/28 19:33:27 step 5: objective=0.8638702
2017/08/28 19:33:29 step 6: objective=0.8672211
2017/08/28 19:33:30 step 7: objective=0.871608
2017/08/28 19:33:30 Training value function...
2017/08/28 19:33:32 step 0: mse=155.720426 step=0.100000
2017/08/28 19:33:33 step 1: mse=154.400782 step=0.100000
2017/08/28 19:33:34 step 2: mse=153.066307 step=0.100000
2017/08/28 19:33:35 step 3: mse=151.836698 step=0.100000
2017/08/28 19:33:36 step 4: mse=150.494111 step=0.100000
2017/08/28 19:33:38 step 5: mse=149.412454 step=0.100000
2017/08/28 19:33:39 step 6: mse=148.335546 step=0.100000
2017/08/28 19:33:40 step 7: mse=147.375450 step=0.100000
2017/08/28 19:33:40 Saving...
2017/08/28 19:33:40 Gathering batch of experience...
2017/08/28 19:34:24 batch 544: mean=124.489362 stddev=94.509455 entropy=0.394311 frames=5299 count=47
2017/08/28 19:34:24 Training policy...
2017/08/28 19:34:27 step 0: objective=2.4152696
2017/08/28 19:34:29 step 1: objective=2.426157
2017/08/28 19:34:30 step 2: objective=2.4338715
2017/08/28 19:34:32 step 3: objective=2.443116
2017/08/28 19:34:33 step 4: objective=2.4517395
2017/08/28 19:34:35 step 5: objective=2.4566047
2017/08/28 19:34:36 step 6: objective=2.4609745
2017/08/28 19:34:37 step 7: objective=2.4653978
2017/08/28 19:34:37 Training value function...
2017/08/28 19:34:39 step 0: mse=222.681888 step=0.100000
2017/08/28 19:34:41 step 1: mse=216.483670 step=0.100000
2017/08/28 19:34:42 step 2: mse=211.455492 step=0.100000
2017/08/28 19:34:43 step 3: mse=206.895024 step=0.100000
2017/08/28 19:34:44 step 4: mse=202.887403 step=0.100000
2017/08/28 19:34:45 step 5: mse=199.574275 step=0.100000
2017/08/28 19:34:46 step 6: mse=196.751306 step=0.100000
2017/08/28 19:34:47 step 7: mse=194.101025 step=0.100000
2017/08/28 19:34:47 Saving...
2017/08/28 19:34:47 Gathering batch of experience...
2017/08/28 19:35:30 batch 545: mean=132.200000 stddev=107.989398 entropy=0.398666 frames=5145 count=40
2017/08/28 19:35:30 Training policy...
2017/08/28 19:35:34 step 0: objective=1.0998852
2017/08/28 19:35:35 step 1: objective=1.1074101
2017/08/28 19:35:37 step 2: objective=1.1147163
2017/08/28 19:35:38 step 3: objective=1.1206448
2017/08/28 19:35:39 step 4: objective=1.1273597
2017/08/28 19:35:41 step 5: objective=1.1332633
2017/08/28 19:35:42 step 6: objective=1.1367735
2017/08/28 19:35:43 step 7: objective=1.1409357
2017/08/28 19:35:43 Training value function...
2017/08/28 19:35:45 step 0: mse=172.923975 step=0.100000
2017/08/28 19:35:47 step 1: mse=168.645754 step=0.100000
2017/08/28 19:35:48 step 2: mse=165.698204 step=0.100000
2017/08/28 19:35:49 step 3: mse=163.081682 step=0.100000
2017/08/28 19:35:50 step 4: mse=160.718237 step=0.100000
2017/08/28 19:35:51 step 5: mse=158.277561 step=0.100000
2017/08/28 19:35:52 step 6: mse=156.498224 step=0.100000
2017/08/28 19:35:53 step 7: mse=154.945184 step=0.100000
2017/08/28 19:35:53 Saving...
2017/08/28 19:35:53 Gathering batch of experience...
2017/08/28 19:36:36 batch 546: mean=129.095238 stddev=109.092536 entropy=0.392618 frames=5016 count=42
2017/08/28 19:36:36 Training policy...
2017/08/28 19:36:39 step 0: objective=1.4001138
2017/08/28 19:36:41 step 1: objective=1.4091005
2017/08/28 19:36:42 step 2: objective=1.4161868
2017/08/28 19:36:43 step 3: objective=1.427222
2017/08/28 19:36:45 step 4: objective=1.4332305
2017/08/28 19:36:46 step 5: objective=1.4383376
2017/08/28 19:36:47 step 6: objective=1.4441918
2017/08/28 19:36:49 step 7: objective=1.450718
2017/08/28 19:36:49 Training value function...
2017/08/28 19:36:51 step 0: mse=167.255698 step=0.100000
2017/08/28 19:36:52 step 1: mse=164.414087 step=0.100000
2017/08/28 19:36:53 step 2: mse=161.741910 step=0.100000
2017/08/28 19:36:54 step 3: mse=159.431684 step=0.100000
2017/08/28 19:36:55 step 4: mse=157.239660 step=0.100000
2017/08/28 19:36:56 step 5: mse=155.499986 step=0.100000
2017/08/28 19:36:57 step 6: mse=153.504090 step=0.100000
2017/08/28 19:36:58 step 7: mse=151.920232 step=0.100000
2017/08/28 19:36:58 Saving...
2017/08/28 19:36:58 Gathering batch of experience...
2017/08/28 19:37:40 batch 547: mean=129.219512 stddev=104.847279 entropy=0.395190 frames=4896 count=41
2017/08/28 19:37:40 Training policy...
2017/08/28 19:37:43 step 0: objective=1.1712065
2017/08/28 19:37:45 step 1: objective=1.1841844
2017/08/28 19:37:46 step 2: objective=1.1929355
2017/08/28 19:37:47 step 3: objective=1.1986643
2017/08/28 19:37:48 step 4: objective=1.2021676
2017/08/28 19:37:50 step 5: objective=1.2065164
2017/08/28 19:37:51 step 6: objective=1.2108191
2017/08/28 19:37:52 step 7: objective=1.2162546
2017/08/28 19:37:52 Training value function...
2017/08/28 19:37:54 step 0: mse=176.140837 step=0.100000
2017/08/28 19:37:55 step 1: mse=173.121669 step=0.100000
2017/08/28 19:37:56 step 2: mse=170.622053 step=0.100000
2017/08/28 19:37:57 step 3: mse=168.525787 step=0.100000
2017/08/28 19:37:58 step 4: mse=166.480329 step=0.100000
2017/08/28 19:37:59 step 5: mse=164.930297 step=0.100000
2017/08/28 19:38:01 step 6: mse=163.394254 step=0.100000
2017/08/28 19:38:02 step 7: mse=161.705904 step=0.100000
2017/08/28 19:38:02 Saving...
2017/08/28 19:38:02 Gathering batch of experience...
2017/08/28 19:38:46 batch 548: mean=102.640000 stddev=79.023986 entropy=0.397489 frames=5163 count=50
2017/08/28 19:38:46 Training policy...
2017/08/28 19:38:49 step 0: objective=-0.3444753
2017/08/28 19:38:51 step 1: objective=-0.3294273
2017/08/28 19:38:52 step 2: objective=-0.31898478
2017/08/28 19:38:54 step 3: objective=-0.31349874
2017/08/28 19:38:55 step 4: objective=-0.30469435
2017/08/28 19:38:56 step 5: objective=-0.30145672
2017/08/28 19:38:58 step 6: objective=-0.29720825
2017/08/28 19:38:59 step 7: objective=-0.29354998
2017/08/28 19:38:59 Training value function...
2017/08/28 19:39:01 step 0: mse=149.750819 step=0.100000
2017/08/28 19:39:02 step 1: mse=145.971579 step=0.100000
2017/08/28 19:39:03 step 2: mse=142.895548 step=0.100000
2017/08/28 19:39:04 step 3: mse=140.646179 step=0.100000
2017/08/28 19:39:05 step 4: mse=138.570402 step=0.100000
2017/08/28 19:39:07 step 5: mse=136.901932 step=0.100000
2017/08/28 19:39:08 step 6: mse=135.591261 step=0.100000
2017/08/28 19:39:09 step 7: mse=134.644976 step=0.100000
2017/08/28 19:39:09 Saving...
2017/08/28 19:39:09 Gathering batch of experience...
2017/08/28 19:39:54 batch 549: mean=126.466667 stddev=113.094572 entropy=0.391223 frames=5421 count=45
2017/08/28 19:39:54 Training policy...
2017/08/28 19:39:58 step 0: objective=1.6384485
2017/08/28 19:40:00 step 1: objective=1.6451811
2017/08/28 19:40:01 step 2: objective=1.6501535
2017/08/28 19:40:03 step 3: objective=1.6560936
2017/08/28 19:40:04 step 4: objective=1.6665244
2017/08/28 19:40:05 step 5: objective=1.6738584
2017/08/28 19:40:07 step 6: objective=1.6777618
2017/08/28 19:40:08 step 7: objective=1.6829001
2017/08/28 19:40:08 Training value function...
2017/08/28 19:40:11 step 0: mse=178.396456 step=0.100000
2017/08/28 19:40:12 step 1: mse=173.933747 step=0.100000
2017/08/28 19:40:13 step 2: mse=170.535869 step=0.100000
2017/08/28 19:40:14 step 3: mse=167.674513 step=0.100000
2017/08/28 19:40:15 step 4: mse=165.038884 step=0.100000
2017/08/28 19:40:16 step 5: mse=162.678692 step=0.100000
2017/08/28 19:40:17 step 6: mse=160.476320 step=0.100000
2017/08/28 19:40:19 step 7: mse=158.615629 step=0.100000
2017/08/28 19:40:19 Saving...
2017/08/28 19:40:19 Gathering batch of experience...
2017/08/28 19:41:00 batch 550: mean=159.694444 stddev=114.544707 entropy=0.395458 frames=5552 count=36
2017/08/28 19:41:00 Training policy...
2017/08/28 19:41:03 step 0: objective=1.6816021
2017/08/28 19:41:05 step 1: objective=1.6859072
2017/08/28 19:41:06 step 2: objective=1.690769
2017/08/28 19:41:08 step 3: objective=1.6965029
2017/08/28 19:41:09 step 4: objective=1.7014327
2017/08/28 19:41:11 step 5: objective=1.708304
2017/08/28 19:41:12 step 6: objective=1.7150277
2017/08/28 19:41:14 step 7: objective=1.7188373
2017/08/28 19:41:14 Training value function...
2017/08/28 19:41:16 step 0: mse=183.378060 step=0.100000
2017/08/28 19:41:17 step 1: mse=180.020910 step=0.100000
2017/08/28 19:41:18 step 2: mse=177.169139 step=0.100000
2017/08/28 19:41:20 step 3: mse=174.653320 step=0.100000
2017/08/28 19:41:21 step 4: mse=172.565794 step=0.100000
2017/08/28 19:41:22 step 5: mse=170.179506 step=0.100000
2017/08/28 19:41:23 step 6: mse=168.370183 step=0.100000
2017/08/28 19:41:24 step 7: mse=166.900816 step=0.100000
2017/08/28 19:41:24 Saving...
2017/08/28 19:41:24 Gathering batch of experience...
2017/08/28 19:42:03 batch 551: mean=109.636364 stddev=111.324483 entropy=0.397025 frames=4526 count=44
2017/08/28 19:42:03 Training policy...
2017/08/28 19:42:06 step 0: objective=0.7576284
2017/08/28 19:42:08 step 1: objective=0.765995
2017/08/28 19:42:09 step 2: objective=0.7807461
2017/08/28 19:42:10 step 3: objective=0.78993356
2017/08/28 19:42:11 step 4: objective=0.7986183
2017/08/28 19:42:12 step 5: objective=0.8103027
2017/08/28 19:42:14 step 6: objective=0.8160522
2017/08/28 19:42:15 step 7: objective=0.81930447
2017/08/28 19:42:15 Training value function...
2017/08/28 19:42:17 step 0: mse=210.159076 step=0.100000
2017/08/28 19:42:18 step 1: mse=207.176906 step=0.100000
2017/08/28 19:42:19 step 2: mse=204.353723 step=0.100000
2017/08/28 19:42:20 step 3: mse=202.342213 step=0.100000
2017/08/28 19:42:21 step 4: mse=199.943645 step=0.100000
2017/08/28 19:42:22 step 5: mse=197.243417 step=0.100000
2017/08/28 19:42:23 step 6: mse=195.594076 step=0.100000
2017/08/28 19:42:23 step 7: mse=193.729918 step=0.100000
2017/08/28 19:42:23 Saving...
2017/08/28 19:42:24 Gathering batch of experience...
2017/08/28 19:43:14 batch 552: mean=106.392157 stddev=105.952279 entropy=0.392367 frames=5502 count=51
2017/08/28 19:43:14 Training policy...
2017/08/28 19:43:17 step 0: objective=0.019622998
2017/08/28 19:43:19 step 1: objective=0.030496884
2017/08/28 19:43:20 step 2: objective=0.0396567
2017/08/28 19:43:22 step 3: objective=0.04814555
2017/08/28 19:43:23 step 4: objective=0.053944994
2017/08/28 19:43:25 step 5: objective=0.05915331
2017/08/28 19:43:26 step 6: objective=0.063835636
2017/08/28 19:43:28 step 7: objective=0.06604888
2017/08/28 19:43:28 Training value function...
2017/08/28 19:43:30 step 0: mse=152.279109 step=0.100000
2017/08/28 19:43:31 step 1: mse=150.302943 step=0.100000
2017/08/28 19:43:32 step 2: mse=148.223803 step=0.100000
2017/08/28 19:43:33 step 3: mse=146.227181 step=0.100000
2017/08/28 19:43:35 step 4: mse=144.812224 step=0.100000
2017/08/28 19:43:36 step 5: mse=143.542055 step=0.100000
2017/08/28 19:43:37 step 6: mse=142.091666 step=0.100000
2017/08/28 19:43:38 step 7: mse=141.294318 step=0.100000
2017/08/28 19:43:38 Saving...
2017/08/28 19:43:38 Gathering batch of experience...
2017/08/28 19:44:24 batch 553: mean=124.574468 stddev=98.751514 entropy=0.394804 frames=5771 count=47
2017/08/28 19:44:24 Training policy...
2017/08/28 19:44:29 step 0: objective=1.2349687
2017/08/28 19:44:30 step 1: objective=1.2428385
2017/08/28 19:44:32 step 2: objective=1.2546393
2017/08/28 19:44:33 step 3: objective=1.2621536
2017/08/28 19:44:35 step 4: objective=1.270627
2017/08/28 19:44:36 step 5: objective=1.2739594
2017/08/28 19:44:38 step 6: objective=1.2771802
2017/08/28 19:44:39 step 7: objective=1.2801765
2017/08/28 19:44:39 Training value function...
2017/08/28 19:44:42 step 0: mse=175.875890 step=0.100000
2017/08/28 19:44:43 step 1: mse=172.283309 step=0.100000
2017/08/28 19:44:44 step 2: mse=169.300715 step=0.100000
2017/08/28 19:44:45 step 3: mse=166.738668 step=0.100000
2017/08/28 19:44:47 step 4: mse=164.352581 step=0.100000
2017/08/28 19:44:48 step 5: mse=162.355404 step=0.100000
2017/08/28 19:44:49 step 6: mse=160.587750 step=0.100000
2017/08/28 19:44:50 step 7: mse=159.112872 step=0.100000
2017/08/28 19:44:50 Saving...
2017/08/28 19:44:50 Gathering batch of experience...
2017/08/28 19:45:32 batch 554: mean=120.534884 stddev=101.987767 entropy=0.390490 frames=5142 count=43
2017/08/28 19:45:32 Training policy...
2017/08/28 19:45:36 step 0: objective=0.836847
2017/08/28 19:45:37 step 1: objective=0.8435179
2017/08/28 19:45:39 step 2: objective=0.85501343
2017/08/28 19:45:40 step 3: objective=0.85941297
2017/08/28 19:45:41 step 4: objective=0.86466545
2017/08/28 19:45:43 step 5: objective=0.8709662
2017/08/28 19:45:44 step 6: objective=0.8750235
2017/08/28 19:45:45 step 7: objective=0.8785308
2017/08/28 19:45:45 Training value function...
2017/08/28 19:45:48 step 0: mse=156.207393 step=0.100000
2017/08/28 19:45:49 step 1: mse=154.767843 step=0.100000
2017/08/28 19:45:50 step 2: mse=153.667422 step=0.100000
2017/08/28 19:45:51 step 3: mse=152.587014 step=0.100000
2017/08/28 19:45:52 step 4: mse=151.842319 step=0.100000
2017/08/28 19:45:53 step 5: mse=151.381242 step=0.100000
2017/08/28 19:45:54 step 6: mse=150.689931 step=0.100000
2017/08/28 19:45:55 step 7: mse=149.631191 step=0.100000
2017/08/28 19:45:55 Saving...
2017/08/28 19:45:55 Gathering batch of experience...
2017/08/28 19:46:38 batch 555: mean=107.250000 stddev=88.290359 entropy=0.388468 frames=4951 count=48
2017/08/28 19:46:38 Training policy...
2017/08/28 19:46:42 step 0: objective=0.7891953
2017/08/28 19:46:43 step 1: objective=0.79912126
2017/08/28 19:46:45 step 2: objective=0.8077955
2017/08/28 19:46:46 step 3: objective=0.81273186
2017/08/28 19:46:47 step 4: objective=0.81898
2017/08/28 19:46:49 step 5: objective=0.8258723
2017/08/28 19:46:50 step 6: objective=0.83095723
2017/08/28 19:46:51 step 7: objective=0.8378478
2017/08/28 19:46:51 Training value function...
2017/08/28 19:46:53 step 0: mse=150.862407 step=0.100000
2017/08/28 19:46:54 step 1: mse=149.384695 step=0.100000
2017/08/28 19:46:55 step 2: mse=147.592129 step=0.100000
2017/08/28 19:46:56 step 3: mse=146.019924 step=0.100000
2017/08/28 19:46:58 step 4: mse=144.830786 step=0.100000
2017/08/28 19:46:59 step 5: mse=143.572221 step=0.100000
2017/08/28 19:47:00 step 6: mse=142.440530 step=0.100000
2017/08/28 19:47:01 step 7: mse=141.320275 step=0.100000
2017/08/28 19:47:01 Saving...
2017/08/28 19:47:01 Gathering batch of experience...
2017/08/28 19:47:41 batch 556: mean=132.414634 stddev=109.095835 entropy=0.393431 frames=5038 count=41
2017/08/28 19:47:41 Training policy...
2017/08/28 19:47:45 step 0: objective=2.0886939
2017/08/28 19:47:46 step 1: objective=2.0966806
2017/08/28 19:47:47 step 2: objective=2.1042774
2017/08/28 19:47:49 step 3: objective=2.1092343
2017/08/28 19:47:50 step 4: objective=2.1157415
2017/08/28 19:47:51 step 5: objective=2.1207633
2017/08/28 19:47:53 step 6: objective=2.1257825
2017/08/28 19:47:54 step 7: objective=2.1328037
2017/08/28 19:47:54 Training value function...
2017/08/28 19:47:56 step 0: mse=230.300298 step=0.100000
2017/08/28 19:47:57 step 1: mse=224.118890 step=0.100000
2017/08/28 19:47:58 step 2: mse=218.904768 step=0.100000
2017/08/28 19:47:59 step 3: mse=214.582337 step=0.100000
2017/08/28 19:48:00 step 4: mse=210.863116 step=0.100000
2017/08/28 19:48:02 step 5: mse=207.258630 step=0.100000
2017/08/28 19:48:03 step 6: mse=204.065434 step=0.100000
2017/08/28 19:48:04 step 7: mse=201.293903 step=0.100000
2017/08/28 19:48:04 Saving...
2017/08/28 19:48:04 Gathering batch of experience...
2017/08/28 19:48:49 batch 557: mean=112.660000 stddev=88.334050 entropy=0.384403 frames=5154 count=50
2017/08/28 19:48:49 Training policy...
2017/08/28 19:48:53 step 0: objective=0.94371325
2017/08/28 19:48:54 step 1: objective=0.9539722
2017/08/28 19:48:55 step 2: objective=0.9646335
2017/08/28 19:48:57 step 3: objective=0.9711948
2017/08/28 19:48:58 step 4: objective=0.9815633
2017/08/28 19:48:59 step 5: objective=0.98733664
2017/08/28 19:49:01 step 6: objective=0.9922386
2017/08/28 19:49:02 step 7: objective=0.9965054
2017/08/28 19:49:02 Training value function...
2017/08/28 19:49:04 step 0: mse=193.048242 step=0.100000
2017/08/28 19:49:05 step 1: mse=190.628043 step=0.100000
2017/08/28 19:49:06 step 2: mse=188.531879 step=0.100000
2017/08/28 19:49:08 step 3: mse=186.436717 step=0.100000
2017/08/28 19:49:09 step 4: mse=183.991790 step=0.100000
2017/08/28 19:49:10 step 5: mse=182.105201 step=0.100000
2017/08/28 19:49:11 step 6: mse=180.128329 step=0.100000
2017/08/28 19:49:12 step 7: mse=178.320116 step=0.100000
2017/08/28 19:49:12 Saving...
2017/08/28 19:49:12 Gathering batch of experience...
2017/08/28 19:49:51 batch 558: mean=142.131579 stddev=101.101088 entropy=0.392930 frames=5083 count=38
2017/08/28 19:49:51 Training policy...
2017/08/28 19:49:55 step 0: objective=1.444168
2017/08/28 19:49:56 step 1: objective=1.4551916
2017/08/28 19:49:57 step 2: objective=1.4617274
2017/08/28 19:49:59 step 3: objective=1.4653403
2017/08/28 19:50:00 step 4: objective=1.470351
2017/08/28 19:50:01 step 5: objective=1.4732769
2017/08/28 19:50:03 step 6: objective=1.4765229
2017/08/28 19:50:04 step 7: objective=1.4802474
2017/08/28 19:50:04 Training value function...
2017/08/28 19:50:06 step 0: mse=162.453462 step=0.100000
2017/08/28 19:50:07 step 1: mse=159.693008 step=0.100000
2017/08/28 19:50:08 step 2: mse=157.159366 step=0.100000
2017/08/28 19:50:09 step 3: mse=154.996373 step=0.100000
2017/08/28 19:50:10 step 4: mse=153.094323 step=0.100000
2017/08/28 19:50:12 step 5: mse=151.202244 step=0.100000
2017/08/28 19:50:13 step 6: mse=149.672538 step=0.100000
2017/08/28 19:50:14 step 7: mse=148.118757 step=0.100000
2017/08/28 19:50:14 Saving...
2017/08/28 19:50:14 Gathering batch of experience...
2017/08/28 19:51:00 batch 559: mean=114.365385 stddev=103.218780 entropy=0.395077 frames=5593 count=52
2017/08/28 19:51:00 Training policy...
2017/08/28 19:51:04 step 0: objective=0.73163134
2017/08/28 19:51:06 step 1: objective=0.73683476
2017/08/28 19:51:07 step 2: objective=0.7468381
2017/08/28 19:51:09 step 3: objective=0.75186384
2017/08/28 19:51:10 step 4: objective=0.758951
2017/08/28 19:51:12 step 5: objective=0.76429266
2017/08/28 19:51:13 step 6: objective=0.77005535
2017/08/28 19:51:15 step 7: objective=0.7749336
2017/08/28 19:51:15 Training value function...
2017/08/28 19:51:17 step 0: mse=167.427840 step=0.100000
2017/08/28 19:51:18 step 1: mse=165.106679 step=0.100000
2017/08/28 19:51:19 step 2: mse=162.898871 step=0.100000
2017/08/28 19:51:21 step 3: mse=161.257097 step=0.100000
2017/08/28 19:51:22 step 4: mse=159.611104 step=0.100000
2017/08/28 19:51:23 step 5: mse=157.843679 step=0.100000
2017/08/28 19:51:24 step 6: mse=156.701515 step=0.100000
2017/08/28 19:51:25 step 7: mse=155.723725 step=0.100000
2017/08/28 19:51:25 Saving...
2017/08/28 19:51:25 Gathering batch of experience...
2017/08/28 19:52:06 batch 560: mean=102.042553 stddev=87.419497 entropy=0.389199 frames=4790 count=47
2017/08/28 19:52:06 Training policy...
2017/08/28 19:52:09 step 0: objective=0.021777557
2017/08/28 19:52:11 step 1: objective=0.032847285
2017/08/28 19:52:12 step 2: objective=0.0394555
2017/08/28 19:52:13 step 3: objective=0.04869756
2017/08/28 19:52:14 step 4: objective=0.054259375
2017/08/28 19:52:16 step 5: objective=0.05931712
2017/08/28 19:52:17 step 6: objective=0.06331235
2017/08/28 19:52:18 step 7: objective=0.069611676
2017/08/28 19:52:18 Training value function...
2017/08/28 19:52:20 step 0: mse=140.715172 step=0.100000
2017/08/28 19:52:21 step 1: mse=138.634440 step=0.100000
2017/08/28 19:52:22 step 2: mse=136.797850 step=0.100000
2017/08/28 19:52:23 step 3: mse=135.309051 step=0.100000
2017/08/28 19:52:24 step 4: mse=134.164954 step=0.100000
2017/08/28 19:52:25 step 5: mse=133.219927 step=0.100000
2017/08/28 19:52:26 step 6: mse=132.235316 step=0.100000
2017/08/28 19:52:27 step 7: mse=131.217061 step=0.100000
2017/08/28 19:52:27 Saving...
2017/08/28 19:52:27 Gathering batch of experience...
2017/08/28 19:53:09 batch 561: mean=117.488889 stddev=122.558942 entropy=0.390585 frames=4807 count=45
2017/08/28 19:53:09 Training policy...
2017/08/28 19:53:13 step 0: objective=1.9601371
2017/08/28 19:53:14 step 1: objective=1.977649
2017/08/28 19:53:15 step 2: objective=1.9906346
2017/08/28 19:53:17 step 3: objective=2.0008013
2017/08/28 19:53:18 step 4: objective=2.0068798
2017/08/28 19:53:19 step 5: objective=2.0106955
2017/08/28 19:53:21 step 6: objective=2.017806
2017/08/28 19:53:22 step 7: objective=2.0234191
2017/08/28 19:53:22 Training value function...
2017/08/28 19:53:24 step 0: mse=213.870191 step=0.100000
2017/08/28 19:53:25 step 1: mse=208.689886 step=0.100000
2017/08/28 19:53:26 step 2: mse=204.689747 step=0.100000
2017/08/28 19:53:27 step 3: mse=200.963686 step=0.100000
2017/08/28 19:53:28 step 4: mse=197.753429 step=0.100000
2017/08/28 19:53:29 step 5: mse=194.673657 step=0.100000
2017/08/28 19:53:30 step 6: mse=192.041951 step=0.100000
2017/08/28 19:53:31 step 7: mse=189.817527 step=0.100000
2017/08/28 19:53:31 Saving...
2017/08/28 19:53:31 Gathering batch of experience...
2017/08/28 19:54:14 batch 562: mean=119.133333 stddev=108.157005 entropy=0.388223 frames=4922 count=45
2017/08/28 19:54:14 Training policy...
2017/08/28 19:54:17 step 0: objective=1.3928196
2017/08/28 19:54:19 step 1: objective=1.4061297
2017/08/28 19:54:20 step 2: objective=1.4128106
2017/08/28 19:54:22 step 3: objective=1.4174854
2017/08/28 19:54:23 step 4: objective=1.4299873
2017/08/28 19:54:24 step 5: objective=1.4361105
2017/08/28 19:54:25 step 6: objective=1.439803
2017/08/28 19:54:27 step 7: objective=1.4462316
2017/08/28 19:54:27 Training value function...
2017/08/28 19:54:29 step 0: mse=205.354543 step=0.100000
2017/08/28 19:54:30 step 1: mse=203.079913 step=0.100000
2017/08/28 19:54:31 step 2: mse=200.997247 step=0.100000
2017/08/28 19:54:32 step 3: mse=198.550272 step=0.100000
2017/08/28 19:54:33 step 4: mse=197.020604 step=0.100000
2017/08/28 19:54:34 step 5: mse=195.069449 step=0.100000
2017/08/28 19:54:35 step 6: mse=193.459989 step=0.100000
2017/08/28 19:54:36 step 7: mse=191.389356 step=0.100000
2017/08/28 19:54:36 Saving...
2017/08/28 19:54:36 Gathering batch of experience...
2017/08/28 19:55:22 batch 563: mean=113.860000 stddev=108.578269 entropy=0.387029 frames=5444 count=50
2017/08/28 19:55:22 Training policy...
2017/08/28 19:55:26 step 0: objective=0.6833822
2017/08/28 19:55:27 step 1: objective=0.69078183
2017/08/28 19:55:29 step 2: objective=0.70092404
2017/08/28 19:55:30 step 3: objective=0.70573366
2017/08/28 19:55:31 step 4: objective=0.7121478
2017/08/28 19:55:33 step 5: objective=0.71624213
2017/08/28 19:55:34 step 6: objective=0.7219521
2017/08/28 19:55:36 step 7: objective=0.7278268
2017/08/28 19:55:36 Training value function...
2017/08/28 19:55:38 step 0: mse=185.690246 step=0.100000
2017/08/28 19:55:39 step 1: mse=182.091202 step=0.100000
2017/08/28 19:55:40 step 2: mse=178.157378 step=0.100000
2017/08/28 19:55:42 step 3: mse=175.634242 step=0.100000
2017/08/28 19:55:43 step 4: mse=173.704652 step=0.100000
2017/08/28 19:55:44 step 5: mse=172.128750 step=0.100000
2017/08/28 19:55:45 step 6: mse=170.226892 step=0.100000
2017/08/28 19:55:46 step 7: mse=168.922258 step=0.100000
2017/08/28 19:55:46 Saving...
2017/08/28 19:55:46 Gathering batch of experience...
2017/08/28 19:56:27 batch 564: mean=98.791667 stddev=81.025962 entropy=0.379167 frames=4618 count=48
2017/08/28 19:56:27 Training policy...
2017/08/28 19:56:31 step 0: objective=0.36901242
2017/08/28 19:56:32 step 1: objective=0.383139
2017/08/28 19:56:33 step 2: objective=0.39244398
2017/08/28 19:56:34 step 3: objective=0.40825453
2017/08/28 19:56:36 step 4: objective=0.4140595
2017/08/28 19:56:37 step 5: objective=0.4186454
2017/08/28 19:56:38 step 6: objective=0.42243567
2017/08/28 19:56:39 step 7: objective=0.42531303
2017/08/28 19:56:39 Training value function...
2017/08/28 19:56:41 step 0: mse=179.212005 step=0.100000
2017/08/28 19:56:42 step 1: mse=175.420093 step=0.100000
2017/08/28 19:56:43 step 2: mse=172.220913 step=0.100000
2017/08/28 19:56:44 step 3: mse=169.775779 step=0.100000
2017/08/28 19:56:45 step 4: mse=167.616894 step=0.100000
2017/08/28 19:56:46 step 5: mse=165.942560 step=0.100000
2017/08/28 19:56:47 step 6: mse=164.277776 step=0.100000
2017/08/28 19:56:48 step 7: mse=163.064213 step=0.100000
2017/08/28 19:56:48 Saving...
2017/08/28 19:56:48 Gathering batch of experience...
2017/08/28 19:57:36 batch 565: mean=138.622222 stddev=123.800967 entropy=0.389811 frames=5894 count=45
2017/08/28 19:57:36 Training policy...
2017/08/28 19:57:40 step 0: objective=2.123393
2017/08/28 19:57:42 step 1: objective=2.1275926
2017/08/28 19:57:44 step 2: objective=2.1357975
2017/08/28 19:57:45 step 3: objective=2.1456866
2017/08/28 19:57:47 step 4: objective=2.1489494
2017/08/28 19:57:48 step 5: objective=2.1529903
2017/08/28 19:57:50 step 6: objective=2.1590848
2017/08/28 19:57:52 step 7: objective=2.1624525
2017/08/28 19:57:52 Training value function...
2017/08/28 19:57:54 step 0: mse=195.830136 step=0.100000
2017/08/28 19:57:55 step 1: mse=190.578750 step=0.100000
2017/08/28 19:57:56 step 2: mse=185.724373 step=0.100000
2017/08/28 19:57:58 step 3: mse=181.539800 step=0.100000
2017/08/28 19:57:59 step 4: mse=178.013981 step=0.100000
2017/08/28 19:58:00 step 5: mse=174.949029 step=0.100000
2017/08/28 19:58:01 step 6: mse=172.114257 step=0.100000
2017/08/28 19:58:03 step 7: mse=169.776934 step=0.100000
2017/08/28 19:58:03 Saving...
2017/08/28 19:58:03 Gathering batch of experience...
2017/08/28 19:58:49 batch 566: mean=128.956522 stddev=88.948436 entropy=0.387261 frames=5592 count=46
2017/08/28 19:58:49 Training policy...
2017/08/28 19:58:53 step 0: objective=1.0631183
2017/08/28 19:58:55 step 1: objective=1.0692902
2017/08/28 19:58:56 step 2: objective=1.0768406
2017/08/28 19:58:58 step 3: objective=1.0829598
2017/08/28 19:58:59 step 4: objective=1.089308
2017/08/28 19:59:01 step 5: objective=1.0954856
2017/08/28 19:59:02 step 6: objective=1.1025643
2017/08/28 19:59:04 step 7: objective=1.1070193
2017/08/28 19:59:04 Training value function...
2017/08/28 19:59:06 step 0: mse=154.703334 step=0.100000
2017/08/28 19:59:07 step 1: mse=152.858838 step=0.100000
2017/08/28 19:59:09 step 2: mse=151.277775 step=0.100000
2017/08/28 19:59:10 step 3: mse=149.987568 step=0.100000
2017/08/28 19:59:11 step 4: mse=148.596310 step=0.100000
2017/08/28 19:59:12 step 5: mse=147.424987 step=0.100000
2017/08/28 19:59:13 step 6: mse=146.481642 step=0.100000
2017/08/28 19:59:14 step 7: mse=145.587890 step=0.100000
2017/08/28 19:59:14 Saving...
2017/08/28 19:59:14 Gathering batch of experience...
2017/08/28 20:00:05 batch 567: mean=124.304348 stddev=116.714976 entropy=0.386617 frames=5533 count=46
2017/08/28 20:00:05 Training policy...
2017/08/28 20:00:09 step 0: objective=0.8294134
2017/08/28 20:00:10 step 1: objective=0.8348463
2017/08/28 20:00:12 step 2: objective=0.83966917
2017/08/28 20:00:13 step 3: objective=0.84614307
2017/08/28 20:00:15 step 4: objective=0.8513337
2017/08/28 20:00:16 step 5: objective=0.8550531
2017/08/28 20:00:18 step 6: objective=0.8601791
2017/08/28 20:00:19 step 7: objective=0.86505425
2017/08/28 20:00:19 Training value function...
2017/08/28 20:00:22 step 0: mse=174.674239 step=0.100000
2017/08/28 20:00:23 step 1: mse=172.847965 step=0.100000
2017/08/28 20:00:24 step 2: mse=170.912866 step=0.100000
2017/08/28 20:00:25 step 3: mse=169.114217 step=0.100000
2017/08/28 20:00:26 step 4: mse=167.557531 step=0.100000
2017/08/28 20:00:27 step 5: mse=166.296976 step=0.100000
2017/08/28 20:00:29 step 6: mse=165.021870 step=0.100000
2017/08/28 20:00:30 step 7: mse=163.866531 step=0.100000
2017/08/28 20:00:30 Saving...
2017/08/28 20:00:30 Gathering batch of experience...
2017/08/28 20:01:12 batch 568: mean=124.590909 stddev=91.627288 entropy=0.382825 frames=5297 count=44
2017/08/28 20:01:12 Training policy...
2017/08/28 20:01:16 step 0: objective=0.83910596
2017/08/28 20:01:18 step 1: objective=0.8436852
2017/08/28 20:01:19 step 2: objective=0.852926
2017/08/28 20:01:21 step 3: objective=0.8586041
2017/08/28 20:01:22 step 4: objective=0.8632639
2017/08/28 20:01:23 step 5: objective=0.86710525
2017/08/28 20:01:25 step 6: objective=0.8700311
2017/08/28 20:01:26 step 7: objective=0.87369454
2017/08/28 20:01:26 Training value function...
2017/08/28 20:01:28 step 0: mse=152.371430 step=0.100000
2017/08/28 20:01:29 step 1: mse=149.384105 step=0.100000
2017/08/28 20:01:31 step 2: mse=147.131500 step=0.100000
2017/08/28 20:01:32 step 3: mse=144.928580 step=0.100000
2017/08/28 20:01:33 step 4: mse=143.027407 step=0.100000
2017/08/28 20:01:34 step 5: mse=141.369177 step=0.100000
2017/08/28 20:01:35 step 6: mse=140.011813 step=0.100000
2017/08/28 20:01:36 step 7: mse=138.709011 step=0.100000
2017/08/28 20:01:36 Saving...
2017/08/28 20:01:36 Gathering batch of experience...
2017/08/28 20:02:23 batch 569: mean=107.352941 stddev=88.849250 entropy=0.383670 frames=5343 count=51
2017/08/28 20:02:23 Training policy...
2017/08/28 20:02:26 step 0: objective=0.4094975
2017/08/28 20:02:28 step 1: objective=0.41859508
2017/08/28 20:02:29 step 2: objective=0.42645812
2017/08/28 20:02:31 step 3: objective=0.43703505
2017/08/28 20:02:32 step 4: objective=0.44118592
2017/08/28 20:02:34 step 5: objective=0.45035228
2017/08/28 20:02:35 step 6: objective=0.45548132
2017/08/28 20:02:36 step 7: objective=0.46056217
2017/08/28 20:02:36 Training value function...
2017/08/28 20:02:39 step 0: mse=171.027314 step=0.100000
2017/08/28 20:02:40 step 1: mse=168.585996 step=0.100000
2017/08/28 20:02:41 step 2: mse=166.858913 step=0.100000
2017/08/28 20:02:42 step 3: mse=165.530367 step=0.100000
2017/08/28 20:02:43 step 4: mse=164.309171 step=0.100000
2017/08/28 20:02:44 step 5: mse=162.776575 step=0.100000
2017/08/28 20:02:45 step 6: mse=161.510421 step=0.100000
2017/08/28 20:02:46 step 7: mse=160.149311 step=0.100000
2017/08/28 20:02:46 Saving...
2017/08/28 20:02:47 Gathering batch of experience...
2017/08/28 20:03:32 batch 570: mean=114.816327 stddev=106.703226 entropy=0.379598 frames=5185 count=49
2017/08/28 20:03:32 Training policy...
2017/08/28 20:03:35 step 0: objective=1.6586016
2017/08/28 20:03:37 step 1: objective=1.6671084
2017/08/28 20:03:38 step 2: objective=1.6754887
2017/08/28 20:03:39 step 3: objective=1.6871756
2017/08/28 20:03:41 step 4: objective=1.6927222
2017/08/28 20:03:42 step 5: objective=1.7015343
2017/08/28 20:03:44 step 6: objective=1.7057705
2017/08/28 20:03:45 step 7: objective=1.7102633
2017/08/28 20:03:45 Training value function...
2017/08/28 20:03:47 step 0: mse=208.815965 step=0.100000
2017/08/28 20:03:48 step 1: mse=204.002338 step=0.100000
2017/08/28 20:03:49 step 2: mse=199.788633 step=0.100000
2017/08/28 20:03:50 step 3: mse=196.255689 step=0.100000
2017/08/28 20:03:52 step 4: mse=193.158075 step=0.100000
2017/08/28 20:03:53 step 5: mse=190.216171 step=0.100000
2017/08/28 20:03:54 step 6: mse=187.728693 step=0.100000
2017/08/28 20:03:55 step 7: mse=185.560890 step=0.100000
2017/08/28 20:03:55 Saving...
2017/08/28 20:03:55 Gathering batch of experience...
2017/08/28 20:04:38 batch 571: mean=122.043478 stddev=94.219207 entropy=0.378148 frames=5278 count=46
2017/08/28 20:04:38 Training policy...
2017/08/28 20:04:42 step 0: objective=1.1507176
2017/08/28 20:04:43 step 1: objective=1.1621667
2017/08/28 20:04:45 step 2: objective=1.170046
2017/08/28 20:04:46 step 3: objective=1.1786401
2017/08/28 20:04:47 step 4: objective=1.1844201
2017/08/28 20:04:49 step 5: objective=1.1913588
2017/08/28 20:04:50 step 6: objective=1.1996659
2017/08/28 20:04:52 step 7: objective=1.2065738
2017/08/28 20:04:52 Training value function...
2017/08/28 20:04:54 step 0: mse=169.261237 step=0.100000
2017/08/28 20:04:55 step 1: mse=166.674776 step=0.100000
2017/08/28 20:04:56 step 2: mse=164.197415 step=0.100000
2017/08/28 20:04:57 step 3: mse=162.065612 step=0.100000
2017/08/28 20:04:58 step 4: mse=160.082323 step=0.100000
2017/08/28 20:04:59 step 5: mse=158.386539 step=0.100000
2017/08/28 20:05:01 step 6: mse=156.951243 step=0.100000
2017/08/28 20:05:02 step 7: mse=155.515276 step=0.100000
2017/08/28 20:05:02 Saving...
2017/08/28 20:05:02 Gathering batch of experience...
2017/08/28 20:05:42 batch 572: mean=151.000000 stddev=106.920806 entropy=0.391118 frames=5162 count=34
2017/08/28 20:05:42 Training policy...
2017/08/28 20:05:45 step 0: objective=1.0226861
2017/08/28 20:05:47 step 1: objective=1.027508
2017/08/28 20:05:48 step 2: objective=1.0331585
2017/08/28 20:05:49 step 3: objective=1.03947
2017/08/28 20:05:51 step 4: objective=1.042764
2017/08/28 20:05:52 step 5: objective=1.0498575
2017/08/28 20:05:54 step 6: objective=1.0552996
2017/08/28 20:05:55 step 7: objective=1.0589195
2017/08/28 20:05:55 Training value function...
2017/08/28 20:05:57 step 0: mse=142.947569 step=0.100000
2017/08/28 20:05:58 step 1: mse=140.052528 step=0.100000
2017/08/28 20:05:59 step 2: mse=137.707220 step=0.100000
2017/08/28 20:06:00 step 3: mse=135.737394 step=0.100000
2017/08/28 20:06:02 step 4: mse=133.857077 step=0.100000
2017/08/28 20:06:03 step 5: mse=132.297775 step=0.100000
2017/08/28 20:06:04 step 6: mse=130.738835 step=0.100000
2017/08/28 20:06:05 step 7: mse=129.459290 step=0.100000
2017/08/28 20:06:05 Saving...
2017/08/28 20:06:05 Gathering batch of experience...
2017/08/28 20:06:52 batch 573: mean=107.816327 stddev=89.834468 entropy=0.383991 frames=5225 count=49
2017/08/28 20:06:52 Training policy...
2017/08/28 20:06:56 step 0: objective=0.14685981
2017/08/28 20:06:57 step 1: objective=0.1586548
2017/08/28 20:06:59 step 2: objective=0.1663664
2017/08/28 20:07:00 step 3: objective=0.17315722
2017/08/28 20:07:01 step 4: objective=0.18359734
2017/08/28 20:07:03 step 5: objective=0.18754049
2017/08/28 20:07:04 step 6: objective=0.19399847
2017/08/28 20:07:06 step 7: objective=0.19962549
2017/08/28 20:07:06 Training value function...
2017/08/28 20:07:08 step 0: mse=160.651250 step=0.100000
2017/08/28 20:07:09 step 1: mse=155.692377 step=0.100000
2017/08/28 20:07:10 step 2: mse=151.312226 step=0.100000
2017/08/28 20:07:11 step 3: mse=147.377532 step=0.100000
2017/08/28 20:07:12 step 4: mse=144.747929 step=0.100000
2017/08/28 20:07:13 step 5: mse=142.094142 step=0.100000
2017/08/28 20:07:14 step 6: mse=140.114102 step=0.100000
2017/08/28 20:07:15 step 7: mse=138.101931 step=0.100000
2017/08/28 20:07:15 Saving...
2017/08/28 20:07:16 Gathering batch of experience...
2017/08/28 20:07:56 batch 574: mean=122.285714 stddev=101.079715 entropy=0.387662 frames=4973 count=42
2017/08/28 20:07:56 Training policy...
2017/08/28 20:07:59 step 0: objective=1.1573527
2017/08/28 20:08:01 step 1: objective=1.1694049
2017/08/28 20:08:02 step 2: objective=1.1744659
2017/08/28 20:08:03 step 3: objective=1.179463
2017/08/28 20:08:05 step 4: objective=1.1854291
2017/08/28 20:08:06 step 5: objective=1.1913158
2017/08/28 20:08:08 step 6: objective=1.1958386
2017/08/28 20:08:09 step 7: objective=1.1988549
2017/08/28 20:08:09 Training value function...
2017/08/28 20:08:11 step 0: mse=173.168943 step=0.100000
2017/08/28 20:08:12 step 1: mse=170.387490 step=0.100000
2017/08/28 20:08:13 step 2: mse=167.807884 step=0.100000
2017/08/28 20:08:14 step 3: mse=165.454422 step=0.100000
2017/08/28 20:08:15 step 4: mse=163.408455 step=0.100000
2017/08/28 20:08:16 step 5: mse=161.883984 step=0.100000
2017/08/28 20:08:17 step 6: mse=160.363043 step=0.100000
2017/08/28 20:08:18 step 7: mse=158.799803 step=0.100000
2017/08/28 20:08:18 Saving...
2017/08/28 20:08:18 Gathering batch of experience...
2017/08/28 20:09:03 batch 575: mean=86.771930 stddev=84.820971 entropy=0.380996 frames=4740 count=57
2017/08/28 20:09:03 Training policy...
2017/08/28 20:09:06 step 0: objective=0.02439623
2017/08/28 20:09:07 step 1: objective=0.04099005
2017/08/28 20:09:09 step 2: objective=0.055182554
2017/08/28 20:09:10 step 3: objective=0.063217774
2017/08/28 20:09:11 step 4: objective=0.07485093
2017/08/28 20:09:13 step 5: objective=0.08012482
2017/08/28 20:09:14 step 6: objective=0.08452349
2017/08/28 20:09:15 step 7: objective=0.08969116
2017/08/28 20:09:15 Training value function...
2017/08/28 20:09:17 step 0: mse=182.889916 step=0.100000
2017/08/28 20:09:18 step 1: mse=179.831434 step=0.100000
2017/08/28 20:09:19 step 2: mse=177.052831 step=0.100000
2017/08/28 20:09:20 step 3: mse=174.875818 step=0.100000
2017/08/28 20:09:21 step 4: mse=173.055838 step=0.100000
2017/08/28 20:09:22 step 5: mse=171.615628 step=0.100000
2017/08/28 20:09:23 step 6: mse=170.066943 step=0.100000
2017/08/28 20:09:24 step 7: mse=168.960788 step=0.100000
2017/08/28 20:09:24 Saving...
2017/08/28 20:09:24 Gathering batch of experience...
2017/08/28 20:10:07 batch 576: mean=118.422222 stddev=104.428708 entropy=0.381978 frames=5153 count=45
2017/08/28 20:10:07 Training policy...
2017/08/28 20:10:10 step 0: objective=1.4140576
2017/08/28 20:10:12 step 1: objective=1.4256676
2017/08/28 20:10:13 step 2: objective=1.432278
2017/08/28 20:10:15 step 3: objective=1.4393216
2017/08/28 20:10:16 step 4: objective=1.444114
2017/08/28 20:10:17 step 5: objective=1.450544
2017/08/28 20:10:19 step 6: objective=1.4535799
2017/08/28 20:10:20 step 7: objective=1.456576
2017/08/28 20:10:20 Training value function...
2017/08/28 20:10:22 step 0: mse=162.201579 step=0.100000
2017/08/28 20:10:23 step 1: mse=159.863066 step=0.100000
2017/08/28 20:10:24 step 2: mse=157.874428 step=0.100000
2017/08/28 20:10:26 step 3: mse=155.938744 step=0.100000
2017/08/28 20:10:27 step 4: mse=154.323156 step=0.100000
2017/08/28 20:10:28 step 5: mse=152.673812 step=0.100000
2017/08/28 20:10:29 step 6: mse=151.042488 step=0.100000
2017/08/28 20:10:30 step 7: mse=149.831425 step=0.100000
2017/08/28 20:10:30 Saving...
2017/08/28 20:10:30 Gathering batch of experience...
2017/08/28 20:11:25 batch 577: mean=153.441860 stddev=140.342654 entropy=0.393932 frames=6158 count=43
2017/08/28 20:11:25 Training policy...
2017/08/28 20:11:29 step 0: objective=2.2848535
2017/08/28 20:11:31 step 1: objective=2.2923234
2017/08/28 20:11:33 step 2: objective=2.3006752
2017/08/28 20:11:34 step 3: objective=2.30867
2017/08/28 20:11:36 step 4: objective=2.3148608
2017/08/28 20:11:38 step 5: objective=2.3205085
2017/08/28 20:11:39 step 6: objective=2.324216
2017/08/28 20:11:41 step 7: objective=2.3269715
2017/08/28 20:11:41 Training value function...
2017/08/28 20:11:44 step 0: mse=184.148249 step=0.100000
2017/08/28 20:11:45 step 1: mse=176.778880 step=0.100000
2017/08/28 20:11:46 step 2: mse=170.330678 step=0.100000
2017/08/28 20:11:48 step 3: mse=165.214419 step=0.100000
2017/08/28 20:11:49 step 4: mse=160.362640 step=0.100000
2017/08/28 20:11:50 step 5: mse=156.429807 step=0.100000
2017/08/28 20:11:51 step 6: mse=153.117824 step=0.100000
2017/08/28 20:11:53 step 7: mse=150.002646 step=0.100000
2017/08/28 20:11:53 Saving...
2017/08/28 20:11:53 Gathering batch of experience...
2017/08/28 20:12:35 batch 578: mean=141.219512 stddev=116.063169 entropy=0.382674 frames=5521 count=41
2017/08/28 20:12:35 Training policy...
2017/08/28 20:12:39 step 0: objective=1.0971667
2017/08/28 20:12:41 step 1: objective=1.102736
2017/08/28 20:12:42 step 2: objective=1.1076165
2017/08/28 20:12:44 step 3: objective=1.1134607
2017/08/28 20:12:45 step 4: objective=1.1203142
2017/08/28 20:12:47 step 5: objective=1.1242999
2017/08/28 20:12:48 step 6: objective=1.1279033
2017/08/28 20:12:50 step 7: objective=1.1313018
2017/08/28 20:12:50 Training value function...
2017/08/28 20:12:52 step 0: mse=176.301153 step=0.100000
2017/08/28 20:12:53 step 1: mse=173.789933 step=0.100000
2017/08/28 20:12:55 step 2: mse=171.272214 step=0.100000
2017/08/28 20:12:56 step 3: mse=169.255225 step=0.100000
2017/08/28 20:12:57 step 4: mse=167.508307 step=0.100000
2017/08/28 20:12:58 step 5: mse=165.368105 step=0.100000
2017/08/28 20:12:59 step 6: mse=163.532430 step=0.100000
2017/08/28 20:13:00 step 7: mse=161.975297 step=0.100000
2017/08/28 20:13:00 Saving...
2017/08/28 20:13:00 Gathering batch of experience...
2017/08/28 20:13:52 batch 579: mean=117.039216 stddev=109.407130 entropy=0.387362 frames=5872 count=51
2017/08/28 20:13:52 Training policy...
2017/08/28 20:13:56 step 0: objective=0.36749333
2017/08/28 20:13:58 step 1: objective=0.38008738
2017/08/28 20:13:59 step 2: objective=0.3847535
2017/08/28 20:14:01 step 3: objective=0.39190558
2017/08/28 20:14:02 step 4: objective=0.39539552
2017/08/28 20:14:04 step 5: objective=0.4051769
2017/08/28 20:14:06 step 6: objective=0.41096032
2017/08/28 20:14:07 step 7: objective=0.41511792
2017/08/28 20:14:07 Training value function...
2017/08/28 20:14:10 step 0: mse=157.797474 step=0.100000
2017/08/28 20:14:11 step 1: mse=156.796935 step=0.100000
2017/08/28 20:14:12 step 2: mse=155.720510 step=0.100000
2017/08/28 20:14:13 step 3: mse=155.213299 step=0.100000
2017/08/28 20:14:14 step 4: mse=154.521252 step=0.100000
2017/08/28 20:14:16 step 5: mse=153.857741 step=0.100000
2017/08/28 20:14:17 step 6: mse=153.174097 step=0.100000
2017/08/28 20:14:18 step 7: mse=152.565488 step=0.100000
2017/08/28 20:14:18 Saving...
2017/08/28 20:14:18 Gathering batch of experience...
2017/08/28 20:15:01 batch 580: mean=111.000000 stddev=93.240223 entropy=0.380677 frames=5188 count=46
2017/08/28 20:15:01 Training policy...
2017/08/28 20:15:05 step 0: objective=0.2028147
2017/08/28 20:15:07 step 1: objective=0.20800976
2017/08/28 20:15:08 step 2: objective=0.21389738
2017/08/28 20:15:09 step 3: objective=0.22347783
2017/08/28 20:15:11 step 4: objective=0.22797099
2017/08/28 20:15:12 step 5: objective=0.23236047
2017/08/28 20:15:14 step 6: objective=0.23880391
2017/08/28 20:15:15 step 7: objective=0.24324456
2017/08/28 20:15:15 Training value function...
2017/08/28 20:15:17 step 0: mse=147.171560 step=0.100000
2017/08/28 20:15:18 step 1: mse=145.786733 step=0.100000
2017/08/28 20:15:19 step 2: mse=144.813048 step=0.100000
2017/08/28 20:15:20 step 3: mse=143.646741 step=0.100000
2017/08/28 20:15:22 step 4: mse=142.424668 step=0.100000
2017/08/28 20:15:23 step 5: mse=141.685441 step=0.100000
2017/08/28 20:15:24 step 6: mse=141.062258 step=0.100000
2017/08/28 20:15:25 step 7: mse=140.369060 step=0.100000
2017/08/28 20:15:25 Saving...
2017/08/28 20:15:25 Gathering batch of experience...
2017/08/28 20:16:08 batch 581: mean=139.619048 stddev=99.286970 entropy=0.378124 frames=5394 count=42
2017/08/28 20:16:08 Training policy...
2017/08/28 20:16:12 step 0: objective=2.0685515
2017/08/28 20:16:13 step 1: objective=2.075004
2017/08/28 20:16:15 step 2: objective=2.0862613
2017/08/28 20:16:16 step 3: objective=2.0927665
2017/08/28 20:16:18 step 4: objective=2.1014132
2017/08/28 20:16:19 step 5: objective=2.1051443
2017/08/28 20:16:21 step 6: objective=2.1112113
2017/08/28 20:16:22 step 7: objective=2.1156821
2017/08/28 20:16:22 Training value function...
2017/08/28 20:16:24 step 0: mse=185.748071 step=0.100000
2017/08/28 20:16:25 step 1: mse=181.474308 step=0.100000
2017/08/28 20:16:26 step 2: mse=177.613241 step=0.100000
2017/08/28 20:16:28 step 3: mse=174.491996 step=0.100000
2017/08/28 20:16:29 step 4: mse=171.382623 step=0.100000
2017/08/28 20:16:30 step 5: mse=169.265518 step=0.100000
2017/08/28 20:16:31 step 6: mse=167.324234 step=0.100000
2017/08/28 20:16:32 step 7: mse=165.386003 step=0.100000
2017/08/28 20:16:32 Saving...
2017/08/28 20:16:32 Gathering batch of experience...
2017/08/28 20:17:20 batch 582: mean=115.200000 stddev=109.691203 entropy=0.386455 frames=5387 count=50
2017/08/28 20:17:20 Training policy...
2017/08/28 20:17:24 step 0: objective=0.90720356
2017/08/28 20:17:25 step 1: objective=0.9156205
2017/08/28 20:17:26 step 2: objective=0.9264816
2017/08/28 20:17:28 step 3: objective=0.9337452
2017/08/28 20:17:29 step 4: objective=0.9427895
2017/08/28 20:17:31 step 5: objective=0.9479516
2017/08/28 20:17:32 step 6: objective=0.9525082
2017/08/28 20:17:34 step 7: objective=0.95590687
2017/08/28 20:17:34 Training value function...
2017/08/28 20:17:36 step 0: mse=203.736795 step=0.100000
2017/08/28 20:17:37 step 1: mse=200.374362 step=0.100000
2017/08/28 20:17:38 step 2: mse=198.178323 step=0.100000
2017/08/28 20:17:39 step 3: mse=195.597429 step=0.100000
2017/08/28 20:17:40 step 4: mse=193.483930 step=0.100000
2017/08/28 20:17:42 step 5: mse=191.861263 step=0.100000
2017/08/28 20:17:43 step 6: mse=189.999066 step=0.100000
2017/08/28 20:17:44 step 7: mse=188.525572 step=0.100000
2017/08/28 20:17:44 Saving...
2017/08/28 20:17:44 Gathering batch of experience...
2017/08/28 20:18:30 batch 583: mean=118.152174 stddev=90.061565 entropy=0.386042 frames=5202 count=46
2017/08/28 20:18:30 Training policy...
2017/08/28 20:18:34 step 0: objective=0.81376106
2017/08/28 20:18:35 step 1: objective=0.8209161
2017/08/28 20:18:37 step 2: objective=0.8313963
2017/08/28 20:18:38 step 3: objective=0.8374358
2017/08/28 20:18:39 step 4: objective=0.84485507
2017/08/28 20:18:41 step 5: objective=0.8485138
2017/08/28 20:18:42 step 6: objective=0.8518191
2017/08/28 20:18:44 step 7: objective=0.8561729
2017/08/28 20:18:44 Training value function...
2017/08/28 20:18:46 step 0: mse=174.506377 step=0.100000
2017/08/28 20:18:47 step 1: mse=171.873125 step=0.100000
2017/08/28 20:18:48 step 2: mse=169.692527 step=0.100000
2017/08/28 20:18:49 step 3: mse=167.404026 step=0.100000
2017/08/28 20:18:50 step 4: mse=165.729820 step=0.100000
2017/08/28 20:18:51 step 5: mse=164.308470 step=0.100000
2017/08/28 20:18:52 step 6: mse=162.732351 step=0.100000
2017/08/28 20:18:53 step 7: mse=161.433052 step=0.100000
2017/08/28 20:18:53 Saving...
2017/08/28 20:18:53 Gathering batch of experience...
2017/08/28 20:19:35 batch 584: mean=126.357143 stddev=93.110743 entropy=0.382608 frames=5227 count=42
2017/08/28 20:19:35 Training policy...
2017/08/28 20:19:38 step 0: objective=0.68174344
2017/08/28 20:19:40 step 1: objective=0.69183147
2017/08/28 20:19:41 step 2: objective=0.6998227
2017/08/28 20:19:43 step 3: objective=0.70483303
2017/08/28 20:19:44 step 4: objective=0.7109181
2017/08/28 20:19:45 step 5: objective=0.7164162
2017/08/28 20:19:47 step 6: objective=0.7214402
2017/08/28 20:19:48 step 7: objective=0.7254744
2017/08/28 20:19:48 Training value function...
2017/08/28 20:19:50 step 0: mse=143.199498 step=0.100000
2017/08/28 20:19:52 step 1: mse=141.513143 step=0.100000
2017/08/28 20:19:53 step 2: mse=139.860906 step=0.100000
2017/08/28 20:19:54 step 3: mse=138.636339 step=0.100000
2017/08/28 20:19:55 step 4: mse=137.741724 step=0.100000
2017/08/28 20:19:56 step 5: mse=136.824097 step=0.100000
2017/08/28 20:19:57 step 6: mse=135.905439 step=0.100000
2017/08/28 20:19:58 step 7: mse=135.271842 step=0.100000
2017/08/28 20:19:58 Saving...
2017/08/28 20:19:58 Gathering batch of experience...
2017/08/28 20:20:39 batch 585: mean=121.953488 stddev=109.636175 entropy=0.384882 frames=4979 count=43
2017/08/28 20:20:39 Training policy...
2017/08/28 20:20:43 step 0: objective=1.3637618
2017/08/28 20:20:44 step 1: objective=1.3728608
2017/08/28 20:20:45 step 2: objective=1.3874352
2017/08/28 20:20:47 step 3: objective=1.3965589
2017/08/28 20:20:48 step 4: objective=1.4023373
2017/08/28 20:20:50 step 5: objective=1.4069326
2017/08/28 20:20:51 step 6: objective=1.4108157
2017/08/28 20:20:52 step 7: objective=1.4154406
2017/08/28 20:20:52 Training value function...
2017/08/28 20:20:54 step 0: mse=187.708522 step=0.100000
2017/08/28 20:20:55 step 1: mse=183.904107 step=0.100000
2017/08/28 20:20:56 step 2: mse=180.911139 step=0.100000
2017/08/28 20:20:57 step 3: mse=178.242940 step=0.100000
2017/08/28 20:20:59 step 4: mse=175.610845 step=0.100000
2017/08/28 20:21:00 step 5: mse=173.471185 step=0.100000
2017/08/28 20:21:01 step 6: mse=171.569316 step=0.100000
2017/08/28 20:21:02 step 7: mse=169.664717 step=0.100000
2017/08/28 20:21:02 Saving...
2017/08/28 20:21:02 Gathering batch of experience...
2017/08/28 20:21:46 batch 586: mean=106.361702 stddev=96.610080 entropy=0.376265 frames=5061 count=47
2017/08/28 20:21:46 Training policy...
2017/08/28 20:21:50 step 0: objective=0.24760295
2017/08/28 20:21:51 step 1: objective=0.2551676
2017/08/28 20:21:53 step 2: objective=0.26035142
2017/08/28 20:21:54 step 3: objective=0.26611808
2017/08/28 20:21:55 step 4: objective=0.27323276
2017/08/28 20:21:57 step 5: objective=0.2771877
2017/08/28 20:21:58 step 6: objective=0.2819114
2017/08/28 20:22:00 step 7: objective=0.28820896
2017/08/28 20:22:00 Training value function...
2017/08/28 20:22:02 step 0: mse=157.898717 step=0.100000
2017/08/28 20:22:03 step 1: mse=155.588117 step=0.100000
2017/08/28 20:22:04 step 2: mse=152.889260 step=0.100000
2017/08/28 20:22:05 step 3: mse=151.251256 step=0.100000
2017/08/28 20:22:06 step 4: mse=149.979872 step=0.100000
2017/08/28 20:22:07 step 5: mse=148.490250 step=0.100000
2017/08/28 20:22:08 step 6: mse=147.630038 step=0.100000
2017/08/28 20:22:09 step 7: mse=145.997354 step=0.100000
2017/08/28 20:22:09 Saving...
2017/08/28 20:22:09 Gathering batch of experience...
2017/08/28 20:22:52 batch 587: mean=133.487805 stddev=133.704100 entropy=0.382480 frames=5243 count=41
2017/08/28 20:22:52 Training policy...
2017/08/28 20:22:56 step 0: objective=1.7051761
2017/08/28 20:22:57 step 1: objective=1.7158667
2017/08/28 20:22:59 step 2: objective=1.7233295
2017/08/28 20:23:00 step 3: objective=1.7269659
2017/08/28 20:23:02 step 4: objective=1.7317867
2017/08/28 20:23:03 step 5: objective=1.7358043
2017/08/28 20:23:05 step 6: objective=1.7453835
2017/08/28 20:23:06 step 7: objective=1.748365
2017/08/28 20:23:06 Training value function...
2017/08/28 20:23:08 step 0: mse=191.640573 step=0.100000
2017/08/28 20:23:09 step 1: mse=185.325330 step=0.100000
2017/08/28 20:23:10 step 2: mse=179.900570 step=0.100000
2017/08/28 20:23:11 step 3: mse=175.835057 step=0.100000
2017/08/28 20:23:13 step 4: mse=172.093811 step=0.100000
2017/08/28 20:23:14 step 5: mse=169.190335 step=0.100000
2017/08/28 20:23:15 step 6: mse=166.548394 step=0.100000
2017/08/28 20:23:16 step 7: mse=164.260189 step=0.100000
2017/08/28 20:23:16 Saving...
2017/08/28 20:23:16 Gathering batch of experience...
2017/08/28 20:23:58 batch 588: mean=107.086957 stddev=90.225280 entropy=0.380832 frames=4925 count=46
2017/08/28 20:23:58 Training policy...
2017/08/28 20:24:02 step 0: objective=0.39537477
2017/08/28 20:24:03 step 1: objective=0.40663597
2017/08/28 20:24:04 step 2: objective=0.41828656
2017/08/28 20:24:06 step 3: objective=0.42555436
2017/08/28 20:24:07 step 4: objective=0.43017057
2017/08/28 20:24:08 step 5: objective=0.43358102
2017/08/28 20:24:10 step 6: objective=0.44090325
2017/08/28 20:24:11 step 7: objective=0.44747272
2017/08/28 20:24:11 Training value function...
2017/08/28 20:24:13 step 0: mse=167.044531 step=0.100000
2017/08/28 20:24:14 step 1: mse=165.408648 step=0.100000
2017/08/28 20:24:15 step 2: mse=163.314177 step=0.100000
2017/08/28 20:24:16 step 3: mse=162.010390 step=0.100000
2017/08/28 20:24:17 step 4: mse=161.372936 step=0.100000
2017/08/28 20:24:18 step 5: mse=160.503081 step=0.100000
2017/08/28 20:24:19 step 6: mse=159.817596 step=0.100000
2017/08/28 20:24:20 step 7: mse=158.977630 step=0.100000
2017/08/28 20:24:20 Saving...
2017/08/28 20:24:20 Gathering batch of experience...
2017/08/28 20:25:02 batch 589: mean=104.765957 stddev=102.754037 entropy=0.378175 frames=4866 count=47
2017/08/28 20:25:02 Training policy...
2017/08/28 20:25:05 step 0: objective=0.90405744
2017/08/28 20:25:06 step 1: objective=0.9176069
2017/08/28 20:25:08 step 2: objective=0.9247438
2017/08/28 20:25:09 step 3: objective=0.9340174
2017/08/28 20:25:10 step 4: objective=0.9400637
2017/08/28 20:25:12 step 5: objective=0.95047057
2017/08/28 20:25:13 step 6: objective=0.9572768
2017/08/28 20:25:14 step 7: objective=0.9654125
2017/08/28 20:25:14 Training value function...
2017/08/28 20:25:16 step 0: mse=183.592186 step=0.100000
2017/08/28 20:25:17 step 1: mse=178.959254 step=0.100000
2017/08/28 20:25:18 step 2: mse=174.764248 step=0.100000
2017/08/28 20:25:20 step 3: mse=171.465624 step=0.100000
2017/08/28 20:25:21 step 4: mse=168.574466 step=0.100000
2017/08/28 20:25:22 step 5: mse=165.977205 step=0.100000
2017/08/28 20:25:23 step 6: mse=163.650956 step=0.100000
2017/08/28 20:25:24 step 7: mse=161.901419 step=0.100000
2017/08/28 20:25:24 Saving...
2017/08/28 20:25:24 Gathering batch of experience...
2017/08/28 20:26:09 batch 590: mean=110.880000 stddev=92.100085 entropy=0.377526 frames=5238 count=50
2017/08/28 20:26:09 Training policy...
2017/08/28 20:26:13 step 0: objective=1.5109215
2017/08/28 20:26:14 step 1: objective=1.5183347
2017/08/28 20:26:16 step 2: objective=1.5257019
2017/08/28 20:26:17 step 3: objective=1.5316708
2017/08/28 20:26:19 step 4: objective=1.5391959
2017/08/28 20:26:20 step 5: objective=1.5448011
2017/08/28 20:26:22 step 6: objective=1.5497539
2017/08/28 20:26:23 step 7: objective=1.5539286
2017/08/28 20:26:23 Training value function...
2017/08/28 20:26:25 step 0: mse=187.914085 step=0.100000
2017/08/28 20:26:26 step 1: mse=184.608571 step=0.100000
2017/08/28 20:26:27 step 2: mse=181.873674 step=0.100000
2017/08/28 20:26:29 step 3: mse=179.298903 step=0.100000
2017/08/28 20:26:30 step 4: mse=177.117617 step=0.100000
2017/08/28 20:26:31 step 5: mse=175.213028 step=0.100000
2017/08/28 20:26:32 step 6: mse=173.671492 step=0.100000
2017/08/28 20:26:33 step 7: mse=171.827800 step=0.100000
2017/08/28 20:26:33 Saving...
2017/08/28 20:26:33 Gathering batch of experience...
2017/08/28 20:27:15 batch 591: mean=135.625000 stddev=108.866590 entropy=0.381833 frames=5390 count=40
2017/08/28 20:27:15 Training policy...
2017/08/28 20:27:19 step 0: objective=1.2325006
2017/08/28 20:27:21 step 1: objective=1.2378209
2017/08/28 20:27:22 step 2: objective=1.2475388
2017/08/28 20:27:24 step 3: objective=1.252104
2017/08/28 20:27:25 step 4: objective=1.2565075
2017/08/28 20:27:27 step 5: objective=1.2629057
2017/08/28 20:27:28 step 6: objective=1.2685884
2017/08/28 20:27:30 step 7: objective=1.2719276
2017/08/28 20:27:30 Training value function...
2017/08/28 20:27:32 step 0: mse=149.632830 step=0.100000
2017/08/28 20:27:33 step 1: mse=147.317761 step=0.100000
2017/08/28 20:27:34 step 2: mse=145.463390 step=0.100000
2017/08/28 20:27:35 step 3: mse=143.991248 step=0.100000
2017/08/28 20:27:36 step 4: mse=142.367788 step=0.100000
2017/08/28 20:27:37 step 5: mse=141.033894 step=0.100000
2017/08/28 20:27:39 step 6: mse=139.949146 step=0.100000
2017/08/28 20:27:40 step 7: mse=138.761702 step=0.100000
2017/08/28 20:27:40 Saving...
2017/08/28 20:27:40 Gathering batch of experience...
2017/08/28 20:28:22 batch 592: mean=126.581395 stddev=94.279454 entropy=0.373779 frames=5262 count=43
2017/08/28 20:28:22 Training policy...
2017/08/28 20:28:26 step 0: objective=0.95064163
2017/08/28 20:28:28 step 1: objective=0.9576442
2017/08/28 20:28:29 step 2: objective=0.9700625
2017/08/28 20:28:31 step 3: objective=0.97884494
2017/08/28 20:28:32 step 4: objective=0.9868002
2017/08/28 20:28:33 step 5: objective=0.99252284
2017/08/28 20:28:35 step 6: objective=0.99635684
2017/08/28 20:28:36 step 7: objective=1.0001621
2017/08/28 20:28:36 Training value function...
2017/08/28 20:28:38 step 0: mse=176.584377 step=0.100000
2017/08/28 20:28:40 step 1: mse=174.011894 step=0.100000
2017/08/28 20:28:41 step 2: mse=170.754369 step=0.100000
2017/08/28 20:28:42 step 3: mse=167.436788 step=0.100000
2017/08/28 20:28:43 step 4: mse=165.511651 step=0.100000
2017/08/28 20:28:44 step 5: mse=162.973847 step=0.100000
2017/08/28 20:28:45 step 6: mse=161.922071 step=0.100000
2017/08/28 20:28:46 step 7: mse=159.778914 step=0.100000
2017/08/28 20:28:46 Saving...
2017/08/28 20:28:46 Gathering batch of experience...
2017/08/28 20:29:33 batch 593: mean=126.739130 stddev=103.131076 entropy=0.382564 frames=5843 count=46
2017/08/28 20:29:33 Training policy...
2017/08/28 20:29:37 step 0: objective=0.71590704
2017/08/28 20:29:39 step 1: objective=0.72019887
2017/08/28 20:29:41 step 2: objective=0.72566164
2017/08/28 20:29:42 step 3: objective=0.7300875
2017/08/28 20:29:44 step 4: objective=0.73655194
2017/08/28 20:29:45 step 5: objective=0.73975563
2017/08/28 20:29:47 step 6: objective=0.74260753
2017/08/28 20:29:49 step 7: objective=0.74614096
2017/08/28 20:29:49 Training value function...
2017/08/28 20:29:51 step 0: mse=159.671270 step=0.100000
2017/08/28 20:29:52 step 1: mse=156.888574 step=0.100000
2017/08/28 20:29:53 step 2: mse=153.986004 step=0.100000
2017/08/28 20:29:55 step 3: mse=151.540875 step=0.100000
2017/08/28 20:29:56 step 4: mse=149.635794 step=0.100000
2017/08/28 20:29:57 step 5: mse=148.266686 step=0.100000
2017/08/28 20:29:58 step 6: mse=146.564265 step=0.100000
2017/08/28 20:29:59 step 7: mse=145.261060 step=0.100000
2017/08/28 20:29:59 Saving...
2017/08/28 20:30:00 Gathering batch of experience...
2017/08/28 20:30:48 batch 594: mean=93.890909 stddev=82.155877 entropy=0.375265 frames=5490 count=55
2017/08/28 20:30:48 Training policy...
2017/08/28 20:30:52 step 0: objective=-0.37153506
2017/08/28 20:30:53 step 1: objective=-0.36387455
2017/08/28 20:30:55 step 2: objective=-0.35730696
2017/08/28 20:30:56 step 3: objective=-0.34935367
2017/08/28 20:30:58 step 4: objective=-0.3444271
2017/08/28 20:30:59 step 5: objective=-0.33965248
2017/08/28 20:31:01 step 6: objective=-0.3356022
2017/08/28 20:31:02 step 7: objective=-0.3319004
2017/08/28 20:31:02 Training value function...
2017/08/28 20:31:05 step 0: mse=152.343270 step=0.100000
2017/08/28 20:31:06 step 1: mse=150.359961 step=0.100000
2017/08/28 20:31:07 step 2: mse=148.800781 step=0.100000
2017/08/28 20:31:08 step 3: mse=147.558096 step=0.100000
2017/08/28 20:31:09 step 4: mse=145.977349 step=0.100000
2017/08/28 20:31:10 step 5: mse=145.169502 step=0.100000
2017/08/28 20:31:12 step 6: mse=144.435769 step=0.100000
2017/08/28 20:31:13 step 7: mse=143.641083 step=0.100000
2017/08/28 20:31:13 Saving...
2017/08/28 20:31:13 Gathering batch of experience...
2017/08/28 20:32:02 batch 595: mean=130.777778 stddev=111.488293 entropy=0.379607 frames=5777 count=45
2017/08/28 20:32:02 Training policy...
2017/08/28 20:32:06 step 0: objective=1.9651783
2017/08/28 20:32:08 step 1: objective=1.9720117
2017/08/28 20:32:09 step 2: objective=1.9778422
2017/08/28 20:32:11 step 3: objective=1.9875517
2017/08/28 20:32:13 step 4: objective=1.9951832
2017/08/28 20:32:14 step 5: objective=1.9981031
2017/08/28 20:32:16 step 6: objective=2.0020554
2017/08/28 20:32:17 step 7: objective=2.0068276
2017/08/28 20:32:17 Training value function...
2017/08/28 20:32:20 step 0: mse=187.645732 step=0.100000
2017/08/28 20:32:21 step 1: mse=183.168450 step=0.100000
2017/08/28 20:32:22 step 2: mse=179.392570 step=0.100000
2017/08/28 20:32:23 step 3: mse=175.967755 step=0.100000
2017/08/28 20:32:25 step 4: mse=173.179893 step=0.100000
2017/08/28 20:32:26 step 5: mse=170.391081 step=0.100000
2017/08/28 20:32:27 step 6: mse=168.358365 step=0.100000
2017/08/28 20:32:28 step 7: mse=166.019449 step=0.100000
2017/08/28 20:32:28 Saving...
2017/08/28 20:32:28 Gathering batch of experience...
2017/08/28 20:33:13 batch 596: mean=147.000000 stddev=108.416576 entropy=0.382492 frames=5565 count=39
2017/08/28 20:33:13 Training policy...
2017/08/28 20:33:17 step 0: objective=1.7942233
2017/08/28 20:33:19 step 1: objective=1.8014758
2017/08/28 20:33:20 step 2: objective=1.8053861
2017/08/28 20:33:22 step 3: objective=1.8097949
2017/08/28 20:33:24 step 4: objective=1.8127925
2017/08/28 20:33:25 step 5: objective=1.8168834
2017/08/28 20:33:27 step 6: objective=1.8214923
2017/08/28 20:33:28 step 7: objective=1.8261086
2017/08/28 20:33:28 Training value function...
2017/08/28 20:33:30 step 0: mse=174.180703 step=0.100000
2017/08/28 20:33:32 step 1: mse=170.788570 step=0.100000
2017/08/28 20:33:33 step 2: mse=167.666431 step=0.100000
2017/08/28 20:33:34 step 3: mse=164.848427 step=0.100000
2017/08/28 20:33:35 step 4: mse=162.416534 step=0.100000
2017/08/28 20:33:36 step 5: mse=160.328548 step=0.100000
2017/08/28 20:33:37 step 6: mse=158.374528 step=0.100000
2017/08/28 20:33:39 step 7: mse=156.680359 step=0.100000
2017/08/28 20:33:39 Saving...
2017/08/28 20:33:39 Gathering batch of experience...
2017/08/28 20:34:23 batch 597: mean=111.744681 stddev=89.861470 entropy=0.374405 frames=5188 count=47
2017/08/28 20:34:23 Training policy...
2017/08/28 20:34:27 step 0: objective=0.3271255
2017/08/28 20:34:28 step 1: objective=0.33255133
2017/08/28 20:34:30 step 2: objective=0.3396429
2017/08/28 20:34:31 step 3: objective=0.34617645
2017/08/28 20:34:33 step 4: objective=0.35573772
2017/08/28 20:34:34 step 5: objective=0.36071438
2017/08/28 20:34:36 step 6: objective=0.36674654
2017/08/28 20:34:37 step 7: objective=0.37179482
2017/08/28 20:34:37 Training value function...
2017/08/28 20:34:39 step 0: mse=160.510590 step=0.100000
2017/08/28 20:34:40 step 1: mse=158.422529 step=0.100000
2017/08/28 20:34:41 step 2: mse=156.835355 step=0.100000
2017/08/28 20:34:42 step 3: mse=154.900992 step=0.100000
2017/08/28 20:34:44 step 4: mse=153.768025 step=0.100000
2017/08/28 20:34:45 step 5: mse=152.776435 step=0.100000
2017/08/28 20:34:46 step 6: mse=152.088768 step=0.100000
2017/08/28 20:34:47 step 7: mse=151.519254 step=0.100000
2017/08/28 20:34:47 Saving...
2017/08/28 20:34:47 Gathering batch of experience...
2017/08/28 20:35:31 batch 598: mean=143.736842 stddev=85.808442 entropy=0.373635 frames=5417 count=38
2017/08/28 20:35:31 Training policy...
2017/08/28 20:35:34 step 0: objective=1.2577375
2017/08/28 20:35:36 step 1: objective=1.2631124
2017/08/28 20:35:38 step 2: objective=1.2687955
2017/08/28 20:35:39 step 3: objective=1.2760931
2017/08/28 20:35:41 step 4: objective=1.2808082
2017/08/28 20:35:42 step 5: objective=1.2862812
2017/08/28 20:35:44 step 6: objective=1.2899897
2017/08/28 20:35:45 step 7: objective=1.2933123
2017/08/28 20:35:45 Training value function...
2017/08/28 20:35:47 step 0: mse=135.134426 step=0.100000
2017/08/28 20:35:48 step 1: mse=131.677473 step=0.100000
2017/08/28 20:35:50 step 2: mse=128.730383 step=0.100000
2017/08/28 20:35:51 step 3: mse=126.115433 step=0.100000
2017/08/28 20:35:52 step 4: mse=123.829082 step=0.100000
2017/08/28 20:35:53 step 5: mse=122.006351 step=0.100000
2017/08/28 20:35:54 step 6: mse=120.163299 step=0.100000
2017/08/28 20:35:55 step 7: mse=118.665019 step=0.100000
2017/08/28 20:35:55 Saving...
2017/08/28 20:35:55 Gathering batch of experience...
2017/08/28 20:36:39 batch 599: mean=140.476190 stddev=107.724569 entropy=0.372619 frames=5458 count=42
2017/08/28 20:36:39 Training policy...
2017/08/28 20:36:43 step 0: objective=1.8966452
2017/08/28 20:36:44 step 1: objective=1.9037882
2017/08/28 20:36:46 step 2: objective=1.9149048
2017/08/28 20:36:48 step 3: objective=1.9209206
2017/08/28 20:36:49 step 4: objective=1.9275379
2017/08/28 20:36:51 step 5: objective=1.9322658
2017/08/28 20:36:52 step 6: objective=1.9362345
2017/08/28 20:36:53 step 7: objective=1.9390095
2017/08/28 20:36:53 Training value function...
2017/08/28 20:36:56 step 0: mse=179.806367 step=0.100000
2017/08/28 20:36:57 step 1: mse=175.109722 step=0.100000
2017/08/28 20:36:58 step 2: mse=171.292819 step=0.100000
2017/08/28 20:36:59 step 3: mse=167.608175 step=0.100000
2017/08/28 20:37:00 step 4: mse=164.511933 step=0.100000
2017/08/28 20:37:02 step 5: mse=161.931056 step=0.100000
2017/08/28 20:37:03 step 6: mse=159.476124 step=0.100000
2017/08/28 20:37:04 step 7: mse=157.298504 step=0.100000
2017/08/28 20:37:04 Saving...
2017/08/28 20:37:04 Gathering batch of experience...
2017/08/28 20:37:46 batch 600: mean=157.461538 stddev=109.011608 entropy=0.368006 frames=5531 count=39
2017/08/28 20:37:46 Training policy...
2017/08/28 20:37:50 step 0: objective=2.0284843
2017/08/28 20:37:52 step 1: objective=2.0332825
2017/08/28 20:37:54 step 2: objective=2.042911
2017/08/28 20:37:55 step 3: objective=2.0504775
2017/08/28 20:37:57 step 4: objective=2.0539522
2017/08/28 20:37:58 step 5: objective=2.0592575
2017/08/28 20:38:00 step 6: objective=2.0621648
2017/08/28 20:38:01 step 7: objective=2.0692606
2017/08/28 20:38:01 Training value function...
2017/08/28 20:38:04 step 0: mse=197.279047 step=0.100000
2017/08/28 20:38:05 step 1: mse=193.769994 step=0.100000
2017/08/28 20:38:06 step 2: mse=190.576965 step=0.100000
2017/08/28 20:38:07 step 3: mse=187.835792 step=0.100000
2017/08/28 20:38:08 step 4: mse=185.630660 step=0.100000
2017/08/28 20:38:09 step 5: mse=183.143748 step=0.100000
2017/08/28 20:38:10 step 6: mse=180.635152 step=0.100000
2017/08/28 20:38:12 step 7: mse=178.751058 step=0.100000
2017/08/28 20:38:12 Saving...
2017/08/28 20:38:12 Gathering batch of experience...
2017/08/28 20:38:55 batch 601: mean=147.487179 stddev=135.154778 entropy=0.375056 frames=5613 count=39
2017/08/28 20:38:55 Training policy...
2017/08/28 20:38:59 step 0: objective=0.8147849
2017/08/28 20:39:01 step 1: objective=0.8210831
2017/08/28 20:39:02 step 2: objective=0.83177286
2017/08/28 20:39:04 step 3: objective=0.84159595
2017/08/28 20:39:05 step 4: objective=0.84874713
2017/08/28 20:39:07 step 5: objective=0.85590625
2017/08/28 20:39:08 step 6: objective=0.8588087
2017/08/28 20:39:10 step 7: objective=0.8640912
2017/08/28 20:39:10 Training value function...
2017/08/28 20:39:12 step 0: mse=175.301554 step=0.100000
2017/08/28 20:39:13 step 1: mse=170.519353 step=0.100000
2017/08/28 20:39:15 step 2: mse=166.897454 step=0.100000
2017/08/28 20:39:16 step 3: mse=163.277253 step=0.100000
2017/08/28 20:39:17 step 4: mse=160.279160 step=0.100000
2017/08/28 20:39:18 step 5: mse=157.937357 step=0.100000
2017/08/28 20:39:19 step 6: mse=155.946173 step=0.100000
2017/08/28 20:39:21 step 7: mse=154.026843 step=0.100000
2017/08/28 20:39:21 Saving...
2017/08/28 20:39:21 Gathering batch of experience...
2017/08/28 20:40:02 batch 602: mean=118.756098 stddev=104.196058 entropy=0.379914 frames=5015 count=41
2017/08/28 20:40:02 Training policy...
2017/08/28 20:40:05 step 0: objective=-0.11893811
2017/08/28 20:40:07 step 1: objective=-0.1081509
2017/08/28 20:40:08 step 2: objective=-0.09429568
2017/08/28 20:40:09 step 3: objective=-0.08804449
2017/08/28 20:40:11 step 4: objective=-0.084368184
2017/08/28 20:40:12 step 5: objective=-0.07988555
2017/08/28 20:40:14 step 6: objective=-0.07555475
2017/08/28 20:40:15 step 7: objective=-0.06957372
2017/08/28 20:40:15 Training value function...
2017/08/28 20:40:17 step 0: mse=145.972939 step=0.100000
2017/08/28 20:40:18 step 1: mse=143.053844 step=0.100000
2017/08/28 20:40:19 step 2: mse=141.028039 step=0.100000
2017/08/28 20:40:20 step 3: mse=139.194810 step=0.100000
2017/08/28 20:40:21 step 4: mse=137.453743 step=0.100000
2017/08/28 20:40:22 step 5: mse=136.374147 step=0.100000
2017/08/28 20:40:23 step 6: mse=135.108568 step=0.100000
2017/08/28 20:40:24 step 7: mse=134.324365 step=0.100000
2017/08/28 20:40:24 Saving...
2017/08/28 20:40:25 Gathering batch of experience...
2017/08/28 20:41:08 batch 603: mean=134.571429 stddev=112.941228 entropy=0.378132 frames=5348 count=42
2017/08/28 20:41:08 Training policy...
2017/08/28 20:41:12 step 0: objective=1.5254147
2017/08/28 20:41:13 step 1: objective=1.533666
2017/08/28 20:41:15 step 2: objective=1.541643
2017/08/28 20:41:16 step 3: objective=1.550727
2017/08/28 20:41:18 step 4: objective=1.5557302
2017/08/28 20:41:19 step 5: objective=1.5593574
2017/08/28 20:41:20 step 6: objective=1.5627476
2017/08/28 20:41:22 step 7: objective=1.5674294
2017/08/28 20:41:22 Training value function...
2017/08/28 20:41:24 step 0: mse=176.366534 step=0.100000
2017/08/28 20:41:25 step 1: mse=173.395947 step=0.100000
2017/08/28 20:41:26 step 2: mse=170.848653 step=0.100000
2017/08/28 20:41:28 step 3: mse=168.509197 step=0.100000
2017/08/28 20:41:29 step 4: mse=166.564478 step=0.100000
2017/08/28 20:41:30 step 5: mse=164.589519 step=0.100000
2017/08/28 20:41:31 step 6: mse=162.797242 step=0.100000
2017/08/28 20:41:32 step 7: mse=161.191551 step=0.100000
2017/08/28 20:41:32 Saving...
2017/08/28 20:41:32 Gathering batch of experience...
2017/08/28 20:42:15 batch 604: mean=145.333333 stddev=113.242950 entropy=0.384050 frames=5333 count=39
2017/08/28 20:42:15 Training policy...
2017/08/28 20:42:19 step 0: objective=1.5044453
2017/08/28 20:42:20 step 1: objective=1.5113666
2017/08/28 20:42:22 step 2: objective=1.5200996
2017/08/28 20:42:23 step 3: objective=1.5250895
2017/08/28 20:42:25 step 4: objective=1.5289643
2017/08/28 20:42:26 step 5: objective=1.5347798
2017/08/28 20:42:28 step 6: objective=1.5383068
2017/08/28 20:42:29 step 7: objective=1.5442606
2017/08/28 20:42:29 Training value function...
2017/08/28 20:42:32 step 0: mse=179.148715 step=0.100000
2017/08/28 20:42:33 step 1: mse=175.871531 step=0.100000
2017/08/28 20:42:34 step 2: mse=173.313445 step=0.100000
2017/08/28 20:42:35 step 3: mse=171.057932 step=0.100000
2017/08/28 20:42:36 step 4: mse=168.800185 step=0.100000
2017/08/28 20:42:37 step 5: mse=166.996209 step=0.100000
2017/08/28 20:42:38 step 6: mse=165.195400 step=0.100000
2017/08/28 20:42:39 step 7: mse=163.326167 step=0.100000
2017/08/28 20:42:39 Saving...
2017/08/28 20:42:40 Gathering batch of experience...
2017/08/28 20:43:28 batch 605: mean=116.062500 stddev=106.492841 entropy=0.377384 frames=5757 count=48
2017/08/28 20:43:28 Training policy...
2017/08/28 20:43:32 step 0: objective=-0.17151853
2017/08/28 20:43:34 step 1: objective=-0.1642402
2017/08/28 20:43:35 step 2: objective=-0.15930542
2017/08/28 20:43:37 step 3: objective=-0.15060146
2017/08/28 20:43:39 step 4: objective=-0.1475099
2017/08/28 20:43:40 step 5: objective=-0.14456092
2017/08/28 20:43:42 step 6: objective=-0.13870312
2017/08/28 20:43:43 step 7: objective=-0.13410595
2017/08/28 20:43:43 Training value function...
2017/08/28 20:43:46 step 0: mse=128.147372 step=0.100000
2017/08/28 20:43:47 step 1: mse=126.232480 step=0.100000
2017/08/28 20:43:48 step 2: mse=124.551981 step=0.100000
2017/08/28 20:43:49 step 3: mse=123.545127 step=0.100000
2017/08/28 20:43:50 step 4: mse=122.810218 step=0.100000
2017/08/28 20:43:52 step 5: mse=121.847235 step=0.100000
2017/08/28 20:43:53 step 6: mse=121.009345 step=0.100000
2017/08/28 20:43:54 step 7: mse=120.213497 step=0.100000
2017/08/28 20:43:54 Saving...
2017/08/28 20:43:54 Gathering batch of experience...
2017/08/28 20:44:42 batch 606: mean=132.958333 stddev=129.640843 entropy=0.375323 frames=5660 count=48
2017/08/28 20:44:42 Training policy...
2017/08/28 20:44:46 step 0: objective=2.3603125
2017/08/28 20:44:48 step 1: objective=2.3707578
2017/08/28 20:44:49 step 2: objective=2.3821309
2017/08/28 20:44:51 step 3: objective=2.391622
2017/08/28 20:44:53 step 4: objective=2.3962636
2017/08/28 20:44:54 step 5: objective=2.3996897
2017/08/28 20:44:56 step 6: objective=2.4029474
2017/08/28 20:44:57 step 7: objective=2.4077494
2017/08/28 20:44:57 Training value function...
2017/08/28 20:45:00 step 0: mse=243.907402 step=0.100000
2017/08/28 20:45:01 step 1: mse=236.827732 step=0.100000
2017/08/28 20:45:02 step 2: mse=230.219935 step=0.100000
2017/08/28 20:45:03 step 3: mse=224.416945 step=0.100000
2017/08/28 20:45:04 step 4: mse=219.412781 step=0.100000
2017/08/28 20:45:06 step 5: mse=214.612439 step=0.100000
2017/08/28 20:45:07 step 6: mse=210.913018 step=0.100000
2017/08/28 20:45:08 step 7: mse=207.750009 step=0.100000
2017/08/28 20:45:08 Saving...
2017/08/28 20:45:08 Gathering batch of experience...
2017/08/28 20:45:51 batch 607: mean=136.775000 stddev=93.564012 entropy=0.368957 frames=5536 count=40
2017/08/28 20:45:51 Training policy...
2017/08/28 20:45:55 step 0: objective=0.40105274
2017/08/28 20:45:56 step 1: objective=0.4067008
2017/08/28 20:45:58 step 2: objective=0.41359037
2017/08/28 20:45:59 step 3: objective=0.41838154
2017/08/28 20:46:01 step 4: objective=0.4250722
2017/08/28 20:46:02 step 5: objective=0.43260282
2017/08/28 20:46:04 step 6: objective=0.436689
2017/08/28 20:46:05 step 7: objective=0.4412324
2017/08/28 20:46:05 Training value function...
2017/08/28 20:46:08 step 0: mse=156.778511 step=0.100000
2017/08/28 20:46:09 step 1: mse=153.007181 step=0.100000
2017/08/28 20:46:10 step 2: mse=150.354793 step=0.100000
2017/08/28 20:46:11 step 3: mse=148.077788 step=0.100000
2017/08/28 20:46:12 step 4: mse=146.202853 step=0.100000
2017/08/28 20:46:13 step 5: mse=144.513202 step=0.100000
2017/08/28 20:46:15 step 6: mse=143.194549 step=0.100000
2017/08/28 20:46:16 step 7: mse=141.804866 step=0.100000
2017/08/28 20:46:16 Saving...
2017/08/28 20:46:16 Gathering batch of experience...
2017/08/28 20:47:01 batch 608: mean=127.155556 stddev=93.016117 entropy=0.370536 frames=5561 count=45
2017/08/28 20:47:01 Training policy...
2017/08/28 20:47:05 step 0: objective=1.0121619
2017/08/28 20:47:07 step 1: objective=1.0232741
2017/08/28 20:47:08 step 2: objective=1.0278375
2017/08/28 20:47:10 step 3: objective=1.0343186
2017/08/28 20:47:12 step 4: objective=1.0392296
2017/08/28 20:47:13 step 5: objective=1.0424496
2017/08/28 20:47:15 step 6: objective=1.0473537
2017/08/28 20:47:16 step 7: objective=1.0509955
2017/08/28 20:47:16 Training value function...
2017/08/28 20:47:18 step 0: mse=147.673201 step=0.100000
2017/08/28 20:47:20 step 1: mse=145.316969 step=0.100000
2017/08/28 20:47:21 step 2: mse=143.529902 step=0.100000
2017/08/28 20:47:22 step 3: mse=141.795698 step=0.100000
2017/08/28 20:47:23 step 4: mse=140.332776 step=0.100000
2017/08/28 20:47:24 step 5: mse=139.012580 step=0.100000
2017/08/28 20:47:25 step 6: mse=137.666001 step=0.100000
2017/08/28 20:47:27 step 7: mse=136.611541 step=0.100000
2017/08/28 20:47:27 Saving...
2017/08/28 20:47:27 Gathering batch of experience...
2017/08/28 20:48:09 batch 609: mean=116.295455 stddev=96.136168 entropy=0.362767 frames=5010 count=44
2017/08/28 20:48:09 Training policy...
2017/08/28 20:48:12 step 0: objective=0.60672486
2017/08/28 20:48:14 step 1: objective=0.6167364
2017/08/28 20:48:15 step 2: objective=0.6236598
2017/08/28 20:48:16 step 3: objective=0.6300828
2017/08/28 20:48:18 step 4: objective=0.6351141
2017/08/28 20:48:19 step 5: objective=0.64006525
2017/08/28 20:48:21 step 6: objective=0.6428439
2017/08/28 20:48:22 step 7: objective=0.6452534
2017/08/28 20:48:22 Training value function...
2017/08/28 20:48:24 step 0: mse=164.937989 step=0.100000
2017/08/28 20:48:25 step 1: mse=163.223735 step=0.100000
2017/08/28 20:48:26 step 2: mse=161.711308 step=0.100000
2017/08/28 20:48:27 step 3: mse=160.217434 step=0.100000
2017/08/28 20:48:28 step 4: mse=158.574743 step=0.100000
2017/08/28 20:48:29 step 5: mse=157.170471 step=0.100000
2017/08/28 20:48:30 step 6: mse=156.083396 step=0.100000
2017/08/28 20:48:31 step 7: mse=155.234815 step=0.100000
2017/08/28 20:48:31 Saving...
2017/08/28 20:48:31 Gathering batch of experience...
2017/08/28 20:49:14 batch 610: mean=120.659091 stddev=90.713320 entropy=0.371656 frames=5277 count=44
2017/08/28 20:49:14 Training policy...
2017/08/28 20:49:18 step 0: objective=0.8646639
2017/08/28 20:49:19 step 1: objective=0.8750873
2017/08/28 20:49:21 step 2: objective=0.8799512
2017/08/28 20:49:22 step 3: objective=0.88625044
2017/08/28 20:49:24 step 4: objective=0.8922141
2017/08/28 20:49:25 step 5: objective=0.89696544
2017/08/28 20:49:27 step 6: objective=0.89967626
2017/08/28 20:49:28 step 7: objective=0.90493864
2017/08/28 20:49:28 Training value function...
2017/08/28 20:49:30 step 0: mse=149.638935 step=0.100000
2017/08/28 20:49:31 step 1: mse=148.369190 step=0.100000
2017/08/28 20:49:32 step 2: mse=147.082850 step=0.100000
2017/08/28 20:49:34 step 3: mse=146.028582 step=0.100000
2017/08/28 20:49:35 step 4: mse=145.068782 step=0.100000
2017/08/28 20:49:36 step 5: mse=144.012697 step=0.100000
2017/08/28 20:49:37 step 6: mse=143.268223 step=0.100000
2017/08/28 20:49:38 step 7: mse=141.961395 step=0.100000
2017/08/28 20:49:38 Saving...
2017/08/28 20:49:38 Gathering batch of experience...
2017/08/28 20:50:23 batch 611: mean=158.368421 stddev=123.592374 entropy=0.372386 frames=5643 count=38
2017/08/28 20:50:23 Training policy...
2017/08/28 20:50:27 step 0: objective=2.1085706
2017/08/28 20:50:29 step 1: objective=2.113263
2017/08/28 20:50:31 step 2: objective=2.120125
2017/08/28 20:50:32 step 3: objective=2.1275783
2017/08/28 20:50:34 step 4: objective=2.1346672
2017/08/28 20:50:35 step 5: objective=2.1402078
2017/08/28 20:50:37 step 6: objective=2.1447833
2017/08/28 20:50:38 step 7: objective=2.1486878
2017/08/28 20:50:38 Training value function...
2017/08/28 20:50:41 step 0: mse=194.420267 step=0.100000
2017/08/28 20:50:42 step 1: mse=188.678772 step=0.100000
2017/08/28 20:50:43 step 2: mse=183.766798 step=0.100000
2017/08/28 20:50:44 step 3: mse=179.585040 step=0.100000
2017/08/28 20:50:46 step 4: mse=175.910900 step=0.100000
2017/08/28 20:50:47 step 5: mse=172.917704 step=0.100000
2017/08/28 20:50:48 step 6: mse=170.370267 step=0.100000
2017/08/28 20:50:49 step 7: mse=167.757075 step=0.100000
2017/08/28 20:50:49 Saving...
2017/08/28 20:50:49 Gathering batch of experience...
2017/08/28 20:51:32 batch 612: mean=138.500000 stddev=113.097356 entropy=0.375512 frames=5713 count=42
2017/08/28 20:51:32 Training policy...
2017/08/28 20:51:36 step 0: objective=0.6624709
2017/08/28 20:51:38 step 1: objective=0.6682289
2017/08/28 20:51:40 step 2: objective=0.67355704
2017/08/28 20:51:41 step 3: objective=0.6827631
2017/08/28 20:51:43 step 4: objective=0.6898459
2017/08/28 20:51:45 step 5: objective=0.6940166
2017/08/28 20:51:46 step 6: objective=0.6982473
2017/08/28 20:51:48 step 7: objective=0.70209455
2017/08/28 20:51:48 Training value function...
2017/08/28 20:51:50 step 0: mse=172.078659 step=0.100000
2017/08/28 20:51:51 step 1: mse=169.307381 step=0.100000
2017/08/28 20:51:52 step 2: mse=167.026643 step=0.100000
2017/08/28 20:51:54 step 3: mse=164.975339 step=0.100000
2017/08/28 20:51:55 step 4: mse=163.088327 step=0.100000
2017/08/28 20:51:56 step 5: mse=161.744678 step=0.100000
2017/08/28 20:51:57 step 6: mse=160.497207 step=0.100000
2017/08/28 20:51:58 step 7: mse=159.338263 step=0.100000
2017/08/28 20:51:58 Saving...
2017/08/28 20:51:59 Gathering batch of experience...
2017/08/28 20:52:40 batch 613: mean=125.476190 stddev=89.535372 entropy=0.370422 frames=5092 count=42
2017/08/28 20:52:40 Training policy...
2017/08/28 20:52:44 step 0: objective=0.709396
2017/08/28 20:52:45 step 1: objective=0.7222738
2017/08/28 20:52:46 step 2: objective=0.72946316
2017/08/28 20:52:48 step 3: objective=0.7351153
2017/08/28 20:52:49 step 4: objective=0.7424167
2017/08/28 20:52:51 step 5: objective=0.75018543
2017/08/28 20:52:52 step 6: objective=0.75620294
2017/08/28 20:52:54 step 7: objective=0.7616637
2017/08/28 20:52:54 Training value function...
2017/08/28 20:52:56 step 0: mse=149.055936 step=0.100000
2017/08/28 20:52:57 step 1: mse=147.259933 step=0.100000
2017/08/28 20:52:58 step 2: mse=145.404544 step=0.100000
2017/08/28 20:52:59 step 3: mse=143.904152 step=0.100000
2017/08/28 20:53:00 step 4: mse=142.685493 step=0.100000
2017/08/28 20:53:01 step 5: mse=141.408979 step=0.100000
2017/08/28 20:53:02 step 6: mse=140.212145 step=0.100000
2017/08/28 20:53:03 step 7: mse=139.041453 step=0.100000
2017/08/28 20:53:03 Saving...
2017/08/28 20:53:03 Gathering batch of experience...
2017/08/28 20:53:56 batch 614: mean=164.300000 stddev=152.627520 entropy=0.372516 frames=6122 count=40
2017/08/28 20:53:56 Training policy...
2017/08/28 20:54:00 step 0: objective=2.3715189
2017/08/28 20:54:02 step 1: objective=2.3777807
2017/08/28 20:54:04 step 2: objective=2.3835444
2017/08/28 20:54:05 step 3: objective=2.3918056
2017/08/28 20:54:07 step 4: objective=2.3947532
2017/08/28 20:54:09 step 5: objective=2.4002724
2017/08/28 20:54:11 step 6: objective=2.4029117
2017/08/28 20:54:12 step 7: objective=2.407189
2017/08/28 20:54:12 Training value function...
2017/08/28 20:54:15 step 0: mse=212.374472 step=0.100000
2017/08/28 20:54:16 step 1: mse=203.700275 step=0.100000
2017/08/28 20:54:17 step 2: mse=196.673010 step=0.100000
2017/08/28 20:54:19 step 3: mse=190.610344 step=0.100000
2017/08/28 20:54:20 step 4: mse=185.567199 step=0.100000
2017/08/28 20:54:21 step 5: mse=181.109604 step=0.100000
2017/08/28 20:54:23 step 6: mse=177.032818 step=0.100000
2017/08/28 20:54:24 step 7: mse=173.738147 step=0.100000
2017/08/28 20:54:24 Saving...
2017/08/28 20:54:24 Gathering batch of experience...
2017/08/28 20:55:07 batch 615: mean=137.731707 stddev=129.877996 entropy=0.375584 frames=5447 count=41
2017/08/28 20:55:07 Training policy...
2017/08/28 20:55:11 step 0: objective=0.71920973
2017/08/28 20:55:12 step 1: objective=0.72692543
2017/08/28 20:55:14 step 2: objective=0.7361859
2017/08/28 20:55:16 step 3: objective=0.74186605
2017/08/28 20:55:17 step 4: objective=0.75016063
2017/08/28 20:55:19 step 5: objective=0.7571558
2017/08/28 20:55:20 step 6: objective=0.7642761
2017/08/28 20:55:22 step 7: objective=0.76865923
2017/08/28 20:55:22 Training value function...
2017/08/28 20:55:24 step 0: mse=189.553281 step=0.100000
2017/08/28 20:55:25 step 1: mse=188.512547 step=0.100000
2017/08/28 20:55:26 step 2: mse=186.816590 step=0.100000
2017/08/28 20:55:27 step 3: mse=185.630674 step=0.100000
2017/08/28 20:55:28 step 4: mse=183.874017 step=0.100000
2017/08/28 20:55:30 step 5: mse=182.595104 step=0.100000
2017/08/28 20:55:31 step 6: mse=181.240212 step=0.100000
2017/08/28 20:55:32 step 7: mse=180.036098 step=0.100000
2017/08/28 20:55:32 Saving...
2017/08/28 20:55:32 Gathering batch of experience...
2017/08/28 20:56:15 batch 616: mean=131.886364 stddev=117.252683 entropy=0.373067 frames=5302 count=44
2017/08/28 20:56:15 Training policy...
2017/08/28 20:56:19 step 0: objective=1.2942142
2017/08/28 20:56:21 step 1: objective=1.3038636
2017/08/28 20:56:22 step 2: objective=1.3118489
2017/08/28 20:56:24 step 3: objective=1.3175461
2017/08/28 20:56:25 step 4: objective=1.3233129
2017/08/28 20:56:27 step 5: objective=1.3303351
2017/08/28 20:56:28 step 6: objective=1.3338983
2017/08/28 20:56:30 step 7: objective=1.338033
2017/08/28 20:56:30 Training value function...
2017/08/28 20:56:32 step 0: mse=206.242807 step=0.100000
2017/08/28 20:56:33 step 1: mse=203.746328 step=0.100000
2017/08/28 20:56:34 step 2: mse=201.453611 step=0.100000
2017/08/28 20:56:35 step 3: mse=199.886394 step=0.100000
2017/08/28 20:56:36 step 4: mse=197.721255 step=0.100000
2017/08/28 20:56:37 step 5: mse=196.414415 step=0.100000
2017/08/28 20:56:39 step 6: mse=194.613998 step=0.100000
2017/08/28 20:56:40 step 7: mse=193.003384 step=0.100000
2017/08/28 20:56:40 Saving...
2017/08/28 20:56:40 Gathering batch of experience...
2017/08/28 20:57:23 batch 617: mean=112.893617 stddev=84.762806 entropy=0.365641 frames=4949 count=47
2017/08/28 20:57:23 Training policy...
2017/08/28 20:57:27 step 0: objective=0.517961
2017/08/28 20:57:28 step 1: objective=0.52842146
2017/08/28 20:57:30 step 2: objective=0.5376285
2017/08/28 20:57:31 step 3: objective=0.5453403
2017/08/28 20:57:33 step 4: objective=0.5520289
2017/08/28 20:57:34 step 5: objective=0.55680674
2017/08/28 20:57:35 step 6: objective=0.56448287
2017/08/28 20:57:37 step 7: objective=0.56792927
2017/08/28 20:57:37 Training value function...
2017/08/28 20:57:39 step 0: mse=182.235192 step=0.100000
2017/08/28 20:57:40 step 1: mse=177.171524 step=0.100000
2017/08/28 20:57:41 step 2: mse=173.166346 step=0.100000
2017/08/28 20:57:42 step 3: mse=169.803478 step=0.100000
2017/08/28 20:57:43 step 4: mse=167.096171 step=0.100000
2017/08/28 20:57:44 step 5: mse=165.023897 step=0.100000
2017/08/28 20:57:45 step 6: mse=163.030738 step=0.100000
2017/08/28 20:57:46 step 7: mse=161.665450 step=0.100000
2017/08/28 20:57:46 Saving...
2017/08/28 20:57:46 Gathering batch of experience...
2017/08/28 20:58:32 batch 618: mean=131.857143 stddev=137.259672 entropy=0.366605 frames=5378 count=42
2017/08/28 20:58:32 Training policy...
2017/08/28 20:58:36 step 0: objective=1.09178
2017/08/28 20:58:38 step 1: objective=1.1028094
2017/08/28 20:58:39 step 2: objective=1.109547
2017/08/28 20:58:41 step 3: objective=1.1161816
2017/08/28 20:58:42 step 4: objective=1.1207542
2017/08/28 20:58:44 step 5: objective=1.1258374
2017/08/28 20:58:45 step 6: objective=1.1334993
2017/08/28 20:58:47 step 7: objective=1.1386597
2017/08/28 20:58:47 Training value function...
2017/08/28 20:58:49 step 0: mse=191.627320 step=0.100000
2017/08/28 20:58:50 step 1: mse=185.203030 step=0.100000
2017/08/28 20:58:51 step 2: mse=180.047384 step=0.100000
2017/08/28 20:58:52 step 3: mse=175.249576 step=0.100000
2017/08/28 20:58:53 step 4: mse=171.108749 step=0.100000
2017/08/28 20:58:55 step 5: mse=167.631981 step=0.100000
2017/08/28 20:58:56 step 6: mse=164.838215 step=0.100000
2017/08/28 20:58:57 step 7: mse=162.458418 step=0.100000
2017/08/28 20:58:57 Saving...
2017/08/28 20:58:57 Gathering batch of experience...
2017/08/28 20:59:43 batch 619: mean=134.047619 stddev=106.401520 entropy=0.371255 frames=5398 count=42
2017/08/28 20:59:43 Training policy...
2017/08/28 20:59:47 step 0: objective=0.87305665
2017/08/28 20:59:49 step 1: objective=0.8786556
2017/08/28 20:59:50 step 2: objective=0.88488954
2017/08/28 20:59:52 step 3: objective=0.8928268
2017/08/28 20:59:53 step 4: objective=0.8967444
2017/08/28 20:59:55 step 5: objective=0.9037307
2017/08/28 20:59:56 step 6: objective=0.909208
2017/08/28 20:59:58 step 7: objective=0.9119947
2017/08/28 20:59:58 Training value function...
2017/08/28 21:00:00 step 0: mse=188.535902 step=0.100000
2017/08/28 21:00:01 step 1: mse=185.755848 step=0.100000
2017/08/28 21:00:02 step 2: mse=183.546904 step=0.100000
2017/08/28 21:00:03 step 3: mse=181.587731 step=0.100000
2017/08/28 21:00:04 step 4: mse=179.980591 step=0.100000
2017/08/28 21:00:06 step 5: mse=178.082024 step=0.100000
2017/08/28 21:00:07 step 6: mse=176.591005 step=0.100000
2017/08/28 21:00:08 step 7: mse=174.902896 step=0.100000
2017/08/28 21:00:08 Saving...
2017/08/28 21:00:08 Gathering batch of experience...
2017/08/28 21:00:56 batch 620: mean=109.489796 stddev=92.018437 entropy=0.367906 frames=5429 count=49
2017/08/28 21:00:56 Training policy...
2017/08/28 21:01:00 step 0: objective=0.036482476
2017/08/28 21:01:02 step 1: objective=0.048623547
2017/08/28 21:01:03 step 2: objective=0.060355496
2017/08/28 21:01:05 step 3: objective=0.06911097
2017/08/28 21:01:06 step 4: objective=0.073690474
2017/08/28 21:01:08 step 5: objective=0.08240021
2017/08/28 21:01:09 step 6: objective=0.0854534
2017/08/28 21:01:11 step 7: objective=0.089692436
2017/08/28 21:01:11 Training value function...
2017/08/28 21:01:13 step 0: mse=166.310427 step=0.100000
2017/08/28 21:01:14 step 1: mse=165.492871 step=0.100000
2017/08/28 21:01:15 step 2: mse=164.161887 step=0.100000
2017/08/28 21:01:16 step 3: mse=163.046159 step=0.100000
2017/08/28 21:01:18 step 4: mse=161.910698 step=0.100000
2017/08/28 21:01:19 step 5: mse=160.810820 step=0.100000
2017/08/28 21:01:20 step 6: mse=159.879021 step=0.100000
2017/08/28 21:01:21 step 7: mse=159.111589 step=0.100000
2017/08/28 21:01:21 Saving...
2017/08/28 21:01:21 Gathering batch of experience...
2017/08/28 21:02:04 batch 621: mean=149.105263 stddev=104.671866 entropy=0.369738 frames=5490 count=38
2017/08/28 21:02:04 Training policy...
2017/08/28 21:02:08 step 0: objective=1.8883435
2017/08/28 21:02:10 step 1: objective=1.898732
2017/08/28 21:02:11 step 2: objective=1.907661
2017/08/28 21:02:13 step 3: objective=1.9176294
2017/08/28 21:02:14 step 4: objective=1.9243826
2017/08/28 21:02:16 step 5: objective=1.929608
2017/08/28 21:02:17 step 6: objective=1.9344857
2017/08/28 21:02:19 step 7: objective=1.9385586
2017/08/28 21:02:19 Training value function...
2017/08/28 21:02:21 step 0: mse=174.916707 step=0.100000
2017/08/28 21:02:22 step 1: mse=169.551996 step=0.100000
2017/08/28 21:02:24 step 2: mse=164.851471 step=0.100000
2017/08/28 21:02:25 step 3: mse=160.822495 step=0.100000
2017/08/28 21:02:26 step 4: mse=157.147777 step=0.100000
2017/08/28 21:02:27 step 5: mse=153.949915 step=0.100000
2017/08/28 21:02:28 step 6: mse=151.316229 step=0.100000
2017/08/28 21:02:29 step 7: mse=149.169214 step=0.100000
2017/08/28 21:02:29 Saving...
2017/08/28 21:02:29 Gathering batch of experience...
2017/08/28 21:03:14 batch 622: mean=128.906977 stddev=107.874564 entropy=0.370626 frames=5409 count=43
2017/08/28 21:03:14 Training policy...
2017/08/28 21:03:18 step 0: objective=0.97104996
2017/08/28 21:03:19 step 1: objective=0.9765418
2017/08/28 21:03:21 step 2: objective=0.98177445
2017/08/28 21:03:22 step 3: objective=0.9861529
2017/08/28 21:03:24 step 4: objective=0.9917947
2017/08/28 21:03:25 step 5: objective=0.9949405
2017/08/28 21:03:27 step 6: objective=0.99958676
2017/08/28 21:03:28 step 7: objective=1.0027775
2017/08/28 21:03:28 Training value function...
2017/08/28 21:03:31 step 0: mse=156.173745 step=0.100000
2017/08/28 21:03:32 step 1: mse=153.421419 step=0.100000
2017/08/28 21:03:33 step 2: mse=151.031397 step=0.100000
2017/08/28 21:03:34 step 3: mse=148.998177 step=0.100000
2017/08/28 21:03:35 step 4: mse=147.199220 step=0.100000
2017/08/28 21:03:36 step 5: mse=145.559385 step=0.100000
2017/08/28 21:03:38 step 6: mse=144.179935 step=0.100000
2017/08/28 21:03:39 step 7: mse=142.855250 step=0.100000
2017/08/28 21:03:39 Saving...
2017/08/28 21:03:39 Gathering batch of experience...
2017/08/28 21:04:22 batch 623: mean=110.116279 stddev=93.765965 entropy=0.369377 frames=4730 count=43
2017/08/28 21:04:22 Training policy...
2017/08/28 21:04:26 step 0: objective=0.34180602
2017/08/28 21:04:27 step 1: objective=0.3549875
2017/08/28 21:04:28 step 2: objective=0.36253807
2017/08/28 21:04:30 step 3: objective=0.3744057
2017/08/28 21:04:31 step 4: objective=0.37888426
2017/08/28 21:04:32 step 5: objective=0.3859695
2017/08/28 21:04:34 step 6: objective=0.3901481
2017/08/28 21:04:35 step 7: objective=0.3923803
2017/08/28 21:04:35 Training value function...
2017/08/28 21:04:37 step 0: mse=159.091927 step=0.100000
2017/08/28 21:04:38 step 1: mse=157.552652 step=0.100000
2017/08/28 21:04:39 step 2: mse=156.526202 step=0.100000
2017/08/28 21:04:40 step 3: mse=155.747981 step=0.100000
2017/08/28 21:04:41 step 4: mse=155.111078 step=0.100000
2017/08/28 21:04:42 step 5: mse=154.034622 step=0.100000
2017/08/28 21:04:43 step 6: mse=153.093684 step=0.100000
2017/08/28 21:04:44 step 7: mse=152.113462 step=0.100000
2017/08/28 21:04:44 Saving...
2017/08/28 21:04:44 Gathering batch of experience...
2017/08/28 21:05:30 batch 624: mean=120.531915 stddev=107.770807 entropy=0.366329 frames=5446 count=47
2017/08/28 21:05:30 Training policy...
2017/08/28 21:05:34 step 0: objective=1.4388903
2017/08/28 21:05:35 step 1: objective=1.4512814
2017/08/28 21:05:37 step 2: objective=1.4610022
2017/08/28 21:05:39 step 3: objective=1.4660199
2017/08/28 21:05:40 step 4: objective=1.4710392
2017/08/28 21:05:42 step 5: objective=1.4761367
2017/08/28 21:05:43 step 6: objective=1.4825962
2017/08/28 21:05:45 step 7: objective=1.4863908
2017/08/28 21:05:45 Training value function...
2017/08/28 21:05:47 step 0: mse=192.915819 step=0.100000
2017/08/28 21:05:48 step 1: mse=190.092960 step=0.100000
2017/08/28 21:05:49 step 2: mse=187.247116 step=0.100000
2017/08/28 21:05:50 step 3: mse=184.761278 step=0.100000
2017/08/28 21:05:51 step 4: mse=182.533666 step=0.100000
2017/08/28 21:05:53 step 5: mse=180.849593 step=0.100000
2017/08/28 21:05:54 step 6: mse=179.167107 step=0.100000
2017/08/28 21:05:55 step 7: mse=177.734824 step=0.100000
2017/08/28 21:05:55 Saving...
2017/08/28 21:05:55 Gathering batch of experience...
2017/08/28 21:06:36 batch 625: mean=148.864865 stddev=118.198450 entropy=0.373113 frames=5080 count=37
2017/08/28 21:06:36 Training policy...
2017/08/28 21:06:40 step 0: objective=2.0131295
2017/08/28 21:06:42 step 1: objective=2.0194454
2017/08/28 21:06:43 step 2: objective=2.0284774
2017/08/28 21:06:44 step 3: objective=2.0366623
2017/08/28 21:06:46 step 4: objective=2.0419738
2017/08/28 21:06:47 step 5: objective=2.046931
2017/08/28 21:06:49 step 6: objective=2.0502186
2017/08/28 21:06:50 step 7: objective=2.0577002
2017/08/28 21:06:50 Training value function...
2017/08/28 21:06:52 step 0: mse=229.536309 step=0.100000
2017/08/28 21:06:53 step 1: mse=222.527806 step=0.100000
2017/08/28 21:06:54 step 2: mse=216.438258 step=0.100000
2017/08/28 21:06:55 step 3: mse=211.210235 step=0.100000
2017/08/28 21:06:56 step 4: mse=206.761758 step=0.100000
2017/08/28 21:06:58 step 5: mse=202.721664 step=0.100000
2017/08/28 21:06:59 step 6: mse=199.260950 step=0.100000
2017/08/28 21:07:00 step 7: mse=195.792945 step=0.100000
2017/08/28 21:07:00 Saving...
2017/08/28 21:07:00 Gathering batch of experience...
2017/08/28 21:07:49 batch 626: mean=115.800000 stddev=85.428098 entropy=0.367608 frames=5549 count=50
2017/08/28 21:07:49 Training policy...
2017/08/28 21:07:53 step 0: objective=0.3010509
2017/08/28 21:07:54 step 1: objective=0.30976084
2017/08/28 21:07:56 step 2: objective=0.32176855
2017/08/28 21:07:58 step 3: objective=0.3318583
2017/08/28 21:07:59 step 4: objective=0.3409976
2017/08/28 21:08:01 step 5: objective=0.3465221
2017/08/28 21:08:02 step 6: objective=0.35246608
2017/08/28 21:08:04 step 7: objective=0.3572049
2017/08/28 21:08:04 Training value function...
2017/08/28 21:08:06 step 0: mse=168.169059 step=0.100000
2017/08/28 21:08:07 step 1: mse=166.105398 step=0.100000
2017/08/28 21:08:08 step 2: mse=164.404976 step=0.100000
2017/08/28 21:08:10 step 3: mse=163.084860 step=0.100000
2017/08/28 21:08:11 step 4: mse=161.875623 step=0.100000
2017/08/28 21:08:12 step 5: mse=160.660064 step=0.100000
2017/08/28 21:08:13 step 6: mse=159.770201 step=0.100000
2017/08/28 21:08:14 step 7: mse=158.755446 step=0.100000
2017/08/28 21:08:14 Saving...
2017/08/28 21:08:14 Gathering batch of experience...
2017/08/28 21:08:58 batch 627: mean=156.842105 stddev=137.523687 entropy=0.381535 frames=5659 count=38
2017/08/28 21:08:58 Training policy...
2017/08/28 21:09:03 step 0: objective=1.7685442
2017/08/28 21:09:04 step 1: objective=1.7766632
2017/08/28 21:09:06 step 2: objective=1.7829303
2017/08/28 21:09:07 step 3: objective=1.790851
2017/08/28 21:09:09 step 4: objective=1.7948934
2017/08/28 21:09:11 step 5: objective=1.8006694
2017/08/28 21:09:12 step 6: objective=1.8036222
2017/08/28 21:09:14 step 7: objective=1.8074496
2017/08/28 21:09:14 Training value function...
2017/08/28 21:09:16 step 0: mse=196.565100 step=0.100000
2017/08/28 21:09:17 step 1: mse=191.403069 step=0.100000
2017/08/28 21:09:19 step 2: mse=186.672657 step=0.100000
2017/08/28 21:09:20 step 3: mse=182.753492 step=0.100000
2017/08/28 21:09:21 step 4: mse=179.539556 step=0.100000
2017/08/28 21:09:22 step 5: mse=176.773234 step=0.100000
2017/08/28 21:09:23 step 6: mse=174.180980 step=0.100000
2017/08/28 21:09:25 step 7: mse=171.963956 step=0.100000
2017/08/28 21:09:25 Saving...
2017/08/28 21:09:25 Gathering batch of experience...
2017/08/28 21:10:07 batch 628: mean=168.121212 stddev=102.463521 entropy=0.370083 frames=5504 count=33
2017/08/28 21:10:07 Training policy...
2017/08/28 21:10:11 step 0: objective=0.85636735
2017/08/28 21:10:12 step 1: objective=0.86259764
2017/08/28 21:10:14 step 2: objective=0.8693245
2017/08/28 21:10:15 step 3: objective=0.87801737
2017/08/28 21:10:17 step 4: objective=0.88146794
2017/08/28 21:10:19 step 5: objective=0.88694364
2017/08/28 21:10:20 step 6: objective=0.89244354
2017/08/28 21:10:22 step 7: objective=0.8963292
2017/08/28 21:10:22 Training value function...
2017/08/28 21:10:24 step 0: mse=149.532841 step=0.100000
2017/08/28 21:10:25 step 1: mse=148.035165 step=0.100000
2017/08/28 21:10:26 step 2: mse=146.613670 step=0.100000
2017/08/28 21:10:27 step 3: mse=145.363030 step=0.100000
2017/08/28 21:10:29 step 4: mse=144.004826 step=0.100000
2017/08/28 21:10:30 step 5: mse=142.873343 step=0.100000
2017/08/28 21:10:31 step 6: mse=141.828423 step=0.100000
2017/08/28 21:10:32 step 7: mse=140.822851 step=0.100000
2017/08/28 21:10:32 Saving...
2017/08/28 21:10:32 Gathering batch of experience...
2017/08/28 21:11:21 batch 629: mean=172.058824 stddev=126.542004 entropy=0.370766 frames=5609 count=34
2017/08/28 21:11:21 Training policy...
2017/08/28 21:11:25 step 0: objective=1.5750135
2017/08/28 21:11:27 step 1: objective=1.5787363
2017/08/28 21:11:28 step 2: objective=1.5844274
2017/08/28 21:11:30 step 3: objective=1.5915478
2017/08/28 21:11:31 step 4: objective=1.5971024
2017/08/28 21:11:33 step 5: objective=1.6030166
2017/08/28 21:11:35 step 6: objective=1.6068964
2017/08/28 21:11:36 step 7: objective=1.6124517
2017/08/28 21:11:36 Training value function...
2017/08/28 21:11:38 step 0: mse=169.795074 step=0.100000
2017/08/28 21:11:40 step 1: mse=167.453810 step=0.100000
2017/08/28 21:11:41 step 2: mse=165.539201 step=0.100000
2017/08/28 21:11:42 step 3: mse=163.399090 step=0.100000
2017/08/28 21:11:43 step 4: mse=161.403810 step=0.100000
2017/08/28 21:11:44 step 5: mse=159.836595 step=0.100000
2017/08/28 21:11:46 step 6: mse=158.532827 step=0.100000
2017/08/28 21:11:47 step 7: mse=157.011714 step=0.100000
2017/08/28 21:11:47 Saving...
2017/08/28 21:11:47 Gathering batch of experience...
2017/08/28 21:12:31 batch 630: mean=109.978261 stddev=88.477088 entropy=0.365379 frames=5134 count=46
2017/08/28 21:12:31 Training policy...
2017/08/28 21:12:35 step 0: objective=-0.5383486
2017/08/28 21:12:37 step 1: objective=-0.52877057
2017/08/28 21:12:38 step 2: objective=-0.52345806
2017/08/28 21:12:40 step 3: objective=-0.51884294
2017/08/28 21:12:41 step 4: objective=-0.5118704
2017/08/28 21:12:42 step 5: objective=-0.5059666
2017/08/28 21:12:44 step 6: objective=-0.4982084
2017/08/28 21:12:45 step 7: objective=-0.49203938
2017/08/28 21:12:45 Training value function...
2017/08/28 21:12:47 step 0: mse=147.528498 step=0.100000
2017/08/28 21:12:49 step 1: mse=144.927699 step=0.100000
2017/08/28 21:12:50 step 2: mse=143.198771 step=0.100000
2017/08/28 21:12:51 step 3: mse=141.488048 step=0.100000
2017/08/28 21:12:52 step 4: mse=140.269232 step=0.100000
2017/08/28 21:12:53 step 5: mse=139.113158 step=0.100000
2017/08/28 21:12:54 step 6: mse=138.218042 step=0.100000
2017/08/28 21:12:55 step 7: mse=137.469055 step=0.100000
2017/08/28 21:12:55 Saving...
2017/08/28 21:12:55 Gathering batch of experience...
2017/08/28 21:13:38 batch 631: mean=116.723404 stddev=86.623102 entropy=0.369159 frames=5064 count=47
2017/08/28 21:13:38 Training policy...
2017/08/28 21:13:42 step 0: objective=1.1665274
2017/08/28 21:13:43 step 1: objective=1.1781715
2017/08/28 21:13:45 step 2: objective=1.1837085
2017/08/28 21:13:46 step 3: objective=1.1907731
2017/08/28 21:13:48 step 4: objective=1.1948178
2017/08/28 21:13:49 step 5: objective=1.2006327
2017/08/28 21:13:51 step 6: objective=1.2083178
2017/08/28 21:13:52 step 7: objective=1.2126029
2017/08/28 21:13:52 Training value function...
2017/08/28 21:13:54 step 0: mse=184.630832 step=0.100000
2017/08/28 21:13:55 step 1: mse=182.759823 step=0.100000
2017/08/28 21:13:56 step 2: mse=180.518066 step=0.100000
2017/08/28 21:13:57 step 3: mse=178.587376 step=0.100000
2017/08/28 21:13:58 step 4: mse=177.052753 step=0.100000
2017/08/28 21:13:59 step 5: mse=175.720421 step=0.100000
2017/08/28 21:14:01 step 6: mse=174.525192 step=0.100000
2017/08/28 21:14:02 step 7: mse=173.097168 step=0.100000
2017/08/28 21:14:02 Saving...
2017/08/28 21:14:02 Gathering batch of experience...
2017/08/28 21:14:51 batch 632: mean=153.350000 stddev=123.645168 entropy=0.364268 frames=5642 count=40
2017/08/28 21:14:51 Training policy...
2017/08/28 21:14:55 step 0: objective=2.2198217
2017/08/28 21:14:56 step 1: objective=2.2254949
2017/08/28 21:14:58 step 2: objective=2.2328634
2017/08/28 21:15:00 step 3: objective=2.2390366
2017/08/28 21:15:01 step 4: objective=2.2435906
2017/08/28 21:15:03 step 5: objective=2.249754
2017/08/28 21:15:04 step 6: objective=2.2535353
2017/08/28 21:15:06 step 7: objective=2.2588565
2017/08/28 21:15:06 Training value function...
2017/08/28 21:15:08 step 0: mse=209.920068 step=0.100000
2017/08/28 21:15:10 step 1: mse=200.678370 step=0.100000
2017/08/28 21:15:11 step 2: mse=192.916313 step=0.100000
2017/08/28 21:15:12 step 3: mse=186.405448 step=0.100000
2017/08/28 21:15:13 step 4: mse=180.990878 step=0.100000
2017/08/28 21:15:14 step 5: mse=176.155748 step=0.100000
2017/08/28 21:15:15 step 6: mse=172.211236 step=0.100000
2017/08/28 21:15:17 step 7: mse=168.696666 step=0.100000
2017/08/28 21:15:17 Saving...
2017/08/28 21:15:17 Gathering batch of experience...
2017/08/28 21:16:00 batch 633: mean=140.285714 stddev=107.801026 entropy=0.363981 frames=5353 count=42
2017/08/28 21:16:00 Training policy...
2017/08/28 21:16:04 step 0: objective=1.4359487
2017/08/28 21:16:05 step 1: objective=1.4438994
2017/08/28 21:16:07 step 2: objective=1.4515966
2017/08/28 21:16:09 step 3: objective=1.4595892
2017/08/28 21:16:10 step 4: objective=1.4699901
2017/08/28 21:16:12 step 5: objective=1.4742635
2017/08/28 21:16:13 step 6: objective=1.4812124
2017/08/28 21:16:15 step 7: objective=1.4872204
2017/08/28 21:16:15 Training value function...
2017/08/28 21:16:17 step 0: mse=198.107907 step=0.100000
2017/08/28 21:16:18 step 1: mse=193.911238 step=0.100000
2017/08/28 21:16:19 step 2: mse=190.069571 step=0.100000
2017/08/28 21:16:20 step 3: mse=187.045826 step=0.100000
2017/08/28 21:16:21 step 4: mse=184.308580 step=0.100000
2017/08/28 21:16:22 step 5: mse=181.998231 step=0.100000
2017/08/28 21:16:24 step 6: mse=179.549215 step=0.100000
2017/08/28 21:16:25 step 7: mse=177.728030 step=0.100000
2017/08/28 21:16:25 Saving...
2017/08/28 21:16:25 Gathering batch of experience...
2017/08/28 21:17:12 batch 634: mean=131.266667 stddev=117.824050 entropy=0.364415 frames=5800 count=45
2017/08/28 21:17:12 Training policy...
2017/08/28 21:17:16 step 0: objective=0.28945243
2017/08/28 21:17:18 step 1: objective=0.29560634
2017/08/28 21:17:20 step 2: objective=0.29939735
2017/08/28 21:17:21 step 3: objective=0.30386198
2017/08/28 21:17:23 step 4: objective=0.3078067
2017/08/28 21:17:25 step 5: objective=0.31363943
2017/08/28 21:17:26 step 6: objective=0.3166197
2017/08/28 21:17:28 step 7: objective=0.3205189
2017/08/28 21:17:28 Training value function...
2017/08/28 21:17:30 step 0: mse=138.383084 step=0.100000
2017/08/28 21:17:32 step 1: mse=136.574908 step=0.100000
2017/08/28 21:17:33 step 2: mse=134.863992 step=0.100000
2017/08/28 21:17:34 step 3: mse=133.523147 step=0.100000
2017/08/28 21:17:35 step 4: mse=132.373053 step=0.100000
2017/08/28 21:17:36 step 5: mse=131.311635 step=0.100000
2017/08/28 21:17:38 step 6: mse=130.505344 step=0.100000
2017/08/28 21:17:39 step 7: mse=129.788354 step=0.100000
2017/08/28 21:17:39 Saving...
2017/08/28 21:17:39 Gathering batch of experience...
2017/08/28 21:18:20 batch 635: mean=101.239130 stddev=98.510910 entropy=0.368187 frames=4770 count=46
2017/08/28 21:18:20 Training policy...
2017/08/28 21:18:23 step 0: objective=-0.60446346
2017/08/28 21:18:24 step 1: objective=-0.5922204
2017/08/28 21:18:26 step 2: objective=-0.58408517
2017/08/28 21:18:27 step 3: objective=-0.5754067
2017/08/28 21:18:29 step 4: objective=-0.56730515
2017/08/28 21:18:30 step 5: objective=-0.5613958
2017/08/28 21:18:31 step 6: objective=-0.5576795
2017/08/28 21:18:33 step 7: objective=-0.5508738
2017/08/28 21:18:33 Training value function...
2017/08/28 21:18:35 step 0: mse=167.660487 step=0.100000
2017/08/28 21:18:36 step 1: mse=163.179463 step=0.100000
2017/08/28 21:18:37 step 2: mse=159.507053 step=0.100000
2017/08/28 21:18:38 step 3: mse=156.728240 step=0.100000
2017/08/28 21:18:39 step 4: mse=154.296697 step=0.100000
2017/08/28 21:18:40 step 5: mse=152.275884 step=0.100000
2017/08/28 21:18:41 step 6: mse=150.472326 step=0.100000
2017/08/28 21:18:42 step 7: mse=149.390969 step=0.100000
2017/08/28 21:18:42 Saving...
2017/08/28 21:18:42 Gathering batch of experience...
2017/08/28 21:19:26 batch 636: mean=142.047619 stddev=118.226971 entropy=0.364837 frames=5691 count=42
2017/08/28 21:19:26 Training policy...
2017/08/28 21:19:30 step 0: objective=1.9589052
2017/08/28 21:19:32 step 1: objective=1.9634337
2017/08/28 21:19:34 step 2: objective=1.9721177
2017/08/28 21:19:35 step 3: objective=1.9781044
2017/08/28 21:19:37 step 4: objective=1.984888
2017/08/28 21:19:38 step 5: objective=1.9915115
2017/08/28 21:19:40 step 6: objective=1.9943151
2017/08/28 21:19:42 step 7: objective=1.9984022
2017/08/28 21:19:42 Training value function...
2017/08/28 21:19:44 step 0: mse=180.430236 step=0.100000
2017/08/28 21:19:45 step 1: mse=176.339268 step=0.100000
2017/08/28 21:19:46 step 2: mse=172.466366 step=0.100000
2017/08/28 21:19:48 step 3: mse=169.658206 step=0.100000
2017/08/28 21:19:49 step 4: mse=167.055763 step=0.100000
2017/08/28 21:19:50 step 5: mse=164.317723 step=0.100000
2017/08/28 21:19:51 step 6: mse=162.075608 step=0.100000
2017/08/28 21:19:52 step 7: mse=159.759018 step=0.100000
2017/08/28 21:19:52 Saving...
2017/08/28 21:19:52 Gathering batch of experience...
2017/08/28 21:20:36 batch 637: mean=111.217391 stddev=95.548966 entropy=0.369403 frames=5152 count=46
2017/08/28 21:20:36 Training policy...
2017/08/28 21:20:39 step 0: objective=0.32089278
2017/08/28 21:20:41 step 1: objective=0.32834876
2017/08/28 21:20:43 step 2: objective=0.3427872
2017/08/28 21:20:44 step 3: objective=0.35197872
2017/08/28 21:20:45 step 4: objective=0.3582751
2017/08/28 21:20:47 step 5: objective=0.36315504
2017/08/28 21:20:48 step 6: objective=0.36747158
2017/08/28 21:20:50 step 7: objective=0.37133956
2017/08/28 21:20:50 Training value function...
2017/08/28 21:20:52 step 0: mse=154.570774 step=0.100000
2017/08/28 21:20:53 step 1: mse=151.531645 step=0.100000
2017/08/28 21:20:54 step 2: mse=148.955225 step=0.100000
2017/08/28 21:20:55 step 3: mse=146.915438 step=0.100000
2017/08/28 21:20:56 step 4: mse=145.218640 step=0.100000
2017/08/28 21:20:57 step 5: mse=143.962834 step=0.100000
2017/08/28 21:20:59 step 6: mse=142.607258 step=0.100000
2017/08/28 21:21:00 step 7: mse=141.663168 step=0.100000
2017/08/28 21:21:00 Saving...
2017/08/28 21:21:00 Gathering batch of experience...
2017/08/28 21:21:47 batch 638: mean=126.979167 stddev=112.580987 entropy=0.360721 frames=5704 count=48
2017/08/28 21:21:47 Training policy...
2017/08/28 21:21:51 step 0: objective=1.6839442
2017/08/28 21:21:52 step 1: objective=1.6920238
2017/08/28 21:21:54 step 2: objective=1.7025051
2017/08/28 21:21:56 step 3: objective=1.7111247
2017/08/28 21:21:57 step 4: objective=1.717857
2017/08/28 21:21:59 step 5: objective=1.720901
2017/08/28 21:22:00 step 6: objective=1.7256272
2017/08/28 21:22:02 step 7: objective=1.7309175
2017/08/28 21:22:02 Training value function...
2017/08/28 21:22:04 step 0: mse=192.897183 step=0.100000
2017/08/28 21:22:06 step 1: mse=189.033909 step=0.100000
2017/08/28 21:22:07 step 2: mse=186.230972 step=0.100000
2017/08/28 21:22:08 step 3: mse=183.366057 step=0.100000
2017/08/28 21:22:09 step 4: mse=180.748370 step=0.100000
2017/08/28 21:22:10 step 5: mse=178.396088 step=0.100000
2017/08/28 21:22:12 step 6: mse=176.100646 step=0.100000
2017/08/28 21:22:13 step 7: mse=174.186305 step=0.100000
2017/08/28 21:22:13 Saving...
2017/08/28 21:22:13 Gathering batch of experience...
2017/08/28 21:22:56 batch 639: mean=129.674419 stddev=97.946526 entropy=0.362069 frames=5251 count=43
2017/08/28 21:22:56 Training policy...
2017/08/28 21:23:00 step 0: objective=1.1957301
2017/08/28 21:23:02 step 1: objective=1.205139
2017/08/28 21:23:03 step 2: objective=1.2115119
2017/08/28 21:23:05 step 3: objective=1.2212279
2017/08/28 21:23:06 step 4: objective=1.2282181
2017/08/28 21:23:08 step 5: objective=1.2350901
2017/08/28 21:23:09 step 6: objective=1.2412302
2017/08/28 21:23:11 step 7: objective=1.2439086
2017/08/28 21:23:11 Training value function...
2017/08/28 21:23:13 step 0: mse=181.636404 step=0.100000
2017/08/28 21:23:14 step 1: mse=179.775951 step=0.100000
2017/08/28 21:23:15 step 2: mse=178.225220 step=0.100000
2017/08/28 21:23:16 step 3: mse=176.877275 step=0.100000
2017/08/28 21:23:17 step 4: mse=175.857561 step=0.100000
2017/08/28 21:23:18 step 5: mse=175.106964 step=0.100000
2017/08/28 21:23:19 step 6: mse=174.064576 step=0.100000
2017/08/28 21:23:20 step 7: mse=172.817479 step=0.100000
2017/08/28 21:23:20 Saving...
2017/08/28 21:23:21 Gathering batch of experience...
2017/08/28 21:24:03 batch 640: mean=125.720930 stddev=112.187618 entropy=0.356346 frames=5195 count=43
2017/08/28 21:24:03 Training policy...
2017/08/28 21:24:07 step 0: objective=1.0402254
2017/08/28 21:24:09 step 1: objective=1.0475359
2017/08/28 21:24:10 step 2: objective=1.0559615
2017/08/28 21:24:12 step 3: objective=1.0614182
2017/08/28 21:24:13 step 4: objective=1.0676093
2017/08/28 21:24:14 step 5: objective=1.0737306
2017/08/28 21:24:16 step 6: objective=1.078422
2017/08/28 21:24:17 step 7: objective=1.081774
2017/08/28 21:24:17 Training value function...
2017/08/28 21:24:20 step 0: mse=164.440834 step=0.100000
2017/08/28 21:24:21 step 1: mse=162.545464 step=0.100000
2017/08/28 21:24:22 step 2: mse=160.746443 step=0.100000
2017/08/28 21:24:23 step 3: mse=158.916299 step=0.100000
2017/08/28 21:24:24 step 4: mse=157.262897 step=0.100000
2017/08/28 21:24:25 step 5: mse=155.999721 step=0.100000
2017/08/28 21:24:26 step 6: mse=154.726389 step=0.100000
2017/08/28 21:24:27 step 7: mse=153.364059 step=0.100000
2017/08/28 21:24:27 Saving...
2017/08/28 21:24:27 Gathering batch of experience...
2017/08/28 21:25:10 batch 641: mean=151.694444 stddev=118.087966 entropy=0.369392 frames=5379 count=36
2017/08/28 21:25:10 Training policy...
2017/08/28 21:25:14 step 0: objective=1.2579387
2017/08/28 21:25:16 step 1: objective=1.2631185
2017/08/28 21:25:17 step 2: objective=1.2704126
2017/08/28 21:25:19 step 3: objective=1.2737848
2017/08/28 21:25:20 step 4: objective=1.276807
2017/08/28 21:25:22 step 5: objective=1.2800602
2017/08/28 21:25:23 step 6: objective=1.2838624
2017/08/28 21:25:25 step 7: objective=1.286954
2017/08/28 21:25:25 Training value function...
2017/08/28 21:25:27 step 0: mse=154.877390 step=0.100000
2017/08/28 21:25:28 step 1: mse=152.729210 step=0.100000
2017/08/28 21:25:29 step 2: mse=150.819846 step=0.100000
2017/08/28 21:25:30 step 3: mse=149.219142 step=0.100000
2017/08/28 21:25:31 step 4: mse=147.714109 step=0.100000
2017/08/28 21:25:33 step 5: mse=146.286065 step=0.100000
2017/08/28 21:25:34 step 6: mse=145.102579 step=0.100000
2017/08/28 21:25:35 step 7: mse=143.709295 step=0.100000
2017/08/28 21:25:35 Saving...
2017/08/28 21:25:35 Gathering batch of experience...
2017/08/28 21:26:22 batch 642: mean=129.260870 stddev=106.295003 entropy=0.354445 frames=5613 count=46
2017/08/28 21:26:22 Training policy...
2017/08/28 21:26:26 step 0: objective=0.9687575
2017/08/28 21:26:27 step 1: objective=0.97590137
2017/08/28 21:26:29 step 2: objective=0.9815184
2017/08/28 21:26:31 step 3: objective=0.9891626
2017/08/28 21:26:32 step 4: objective=0.99544245
2017/08/28 21:26:34 step 5: objective=0.9990433
2017/08/28 21:26:35 step 6: objective=1.0021876
2017/08/28 21:26:37 step 7: objective=1.0084735
2017/08/28 21:26:37 Training value function...
2017/08/28 21:26:39 step 0: mse=191.121440 step=0.100000
2017/08/28 21:26:40 step 1: mse=189.221912 step=0.100000
2017/08/28 21:26:42 step 2: mse=187.308459 step=0.100000
2017/08/28 21:26:43 step 3: mse=185.842682 step=0.100000
2017/08/28 21:26:44 step 4: mse=184.505443 step=0.100000
2017/08/28 21:26:45 step 5: mse=182.869534 step=0.100000
2017/08/28 21:26:46 step 6: mse=181.484022 step=0.100000
2017/08/28 21:26:47 step 7: mse=180.320795 step=0.100000
2017/08/28 21:26:47 Saving...
2017/08/28 21:26:48 Gathering batch of experience...
2017/08/28 21:27:29 batch 643: mean=99.916667 stddev=93.740518 entropy=0.356614 frames=4724 count=48
2017/08/28 21:27:29 Training policy...
2017/08/28 21:27:33 step 0: objective=-0.27196386
2017/08/28 21:27:34 step 1: objective=-0.26276186
2017/08/28 21:27:35 step 2: objective=-0.25627562
2017/08/28 21:27:37 step 3: objective=-0.24347472
2017/08/28 21:27:38 step 4: objective=-0.23577078
2017/08/28 21:27:39 step 5: objective=-0.22853844
2017/08/28 21:27:41 step 6: objective=-0.22382925
2017/08/28 21:27:42 step 7: objective=-0.21851811
2017/08/28 21:27:42 Training value function...
2017/08/28 21:27:44 step 0: mse=166.299826 step=0.100000
2017/08/28 21:27:45 step 1: mse=161.646473 step=0.100000
2017/08/28 21:27:46 step 2: mse=158.226988 step=0.100000
2017/08/28 21:27:47 step 3: mse=155.444787 step=0.100000
2017/08/28 21:27:48 step 4: mse=153.115581 step=0.100000
2017/08/28 21:27:49 step 5: mse=151.234406 step=0.100000
2017/08/28 21:27:50 step 6: mse=149.759015 step=0.100000
2017/08/28 21:27:51 step 7: mse=147.938293 step=0.100000
2017/08/28 21:27:51 Saving...
2017/08/28 21:27:51 Gathering batch of experience...
2017/08/28 21:28:41 batch 644: mean=130.733333 stddev=117.522083 entropy=0.360057 frames=5442 count=45
2017/08/28 21:28:41 Training policy...
2017/08/28 21:28:45 step 0: objective=1.9379979
2017/08/28 21:28:47 step 1: objective=1.9486221
2017/08/28 21:28:48 step 2: objective=1.9563756
2017/08/28 21:28:50 step 3: objective=1.9651098
2017/08/28 21:28:52 step 4: objective=1.9701743
2017/08/28 21:28:53 step 5: objective=1.9744663
2017/08/28 21:28:55 step 6: objective=1.9771584
2017/08/28 21:28:56 step 7: objective=1.9801861
2017/08/28 21:28:56 Training value function...
2017/08/28 21:28:58 step 0: mse=207.031357 step=0.100000
2017/08/28 21:29:00 step 1: mse=201.683813 step=0.100000
2017/08/28 21:29:01 step 2: mse=197.265967 step=0.100000
2017/08/28 21:29:02 step 3: mse=193.366539 step=0.100000
2017/08/28 21:29:03 step 4: mse=190.231289 step=0.100000
2017/08/28 21:29:04 step 5: mse=187.217936 step=0.100000
2017/08/28 21:29:05 step 6: mse=184.752907 step=0.100000
2017/08/28 21:29:07 step 7: mse=182.561662 step=0.100000
2017/08/28 21:29:07 Saving...
2017/08/28 21:29:07 Gathering batch of experience...
2017/08/28 21:29:52 batch 645: mean=142.833333 stddev=127.858351 entropy=0.364101 frames=5754 count=42
2017/08/28 21:29:52 Training policy...
2017/08/28 21:29:56 step 0: objective=1.1305873
2017/08/28 21:29:58 step 1: objective=1.136397
2017/08/28 21:30:00 step 2: objective=1.146544
2017/08/28 21:30:02 step 3: objective=1.150546
2017/08/28 21:30:03 step 4: objective=1.1548288
2017/08/28 21:30:05 step 5: objective=1.1579078
2017/08/28 21:30:06 step 6: objective=1.162667
2017/08/28 21:30:08 step 7: objective=1.1662898
2017/08/28 21:30:08 Training value function...
2017/08/28 21:30:10 step 0: mse=147.725768 step=0.100000
2017/08/28 21:30:12 step 1: mse=146.282086 step=0.100000
2017/08/28 21:30:13 step 2: mse=145.104354 step=0.100000
2017/08/28 21:30:14 step 3: mse=143.741871 step=0.100000
2017/08/28 21:30:15 step 4: mse=142.848257 step=0.100000
2017/08/28 21:30:17 step 5: mse=141.879336 step=0.100000
2017/08/28 21:30:18 step 6: mse=141.063916 step=0.100000
2017/08/28 21:30:19 step 7: mse=139.957480 step=0.100000
2017/08/28 21:30:19 Saving...
2017/08/28 21:30:19 Gathering batch of experience...
2017/08/28 21:31:04 batch 646: mean=140.833333 stddev=119.847108 entropy=0.358924 frames=5322 count=42
2017/08/28 21:31:04 Training policy...
2017/08/28 21:31:08 step 0: objective=1.6611941
2017/08/28 21:31:09 step 1: objective=1.6691474
2017/08/28 21:31:11 step 2: objective=1.6745944
2017/08/28 21:31:12 step 3: objective=1.6833916
2017/08/28 21:31:14 step 4: objective=1.689466
2017/08/28 21:31:15 step 5: objective=1.6950284
2017/08/28 21:31:17 step 6: objective=1.7005941
2017/08/28 21:31:18 step 7: objective=1.7050192
2017/08/28 21:31:18 Training value function...
2017/08/28 21:31:21 step 0: mse=194.915118 step=0.100000
2017/08/28 21:31:22 step 1: mse=191.350067 step=0.100000
2017/08/28 21:31:23 step 2: mse=188.653661 step=0.100000
2017/08/28 21:31:24 step 3: mse=186.304587 step=0.100000
2017/08/28 21:31:25 step 4: mse=184.278525 step=0.100000
2017/08/28 21:31:26 step 5: mse=182.165140 step=0.100000
2017/08/28 21:31:27 step 6: mse=180.429263 step=0.100000
2017/08/28 21:31:28 step 7: mse=178.636620 step=0.100000
2017/08/28 21:31:28 Saving...
2017/08/28 21:31:28 Gathering batch of experience...
2017/08/28 21:32:17 batch 647: mean=147.795455 stddev=131.380360 entropy=0.358896 frames=6141 count=44
2017/08/28 21:32:17 Training policy...
2017/08/28 21:32:21 step 0: objective=1.0915735
2017/08/28 21:32:23 step 1: objective=1.1011689
2017/08/28 21:32:25 step 2: objective=1.1091665
2017/08/28 21:32:27 step 3: objective=1.1138539
2017/08/28 21:32:28 step 4: objective=1.1190169
2017/08/28 21:32:30 step 5: objective=1.1237377
2017/08/28 21:32:32 step 6: objective=1.1269518
2017/08/28 21:32:34 step 7: objective=1.1308397
2017/08/28 21:32:34 Training value function...
2017/08/28 21:32:36 step 0: mse=164.965734 step=0.100000
2017/08/28 21:32:37 step 1: mse=161.949693 step=0.100000
2017/08/28 21:32:39 step 2: mse=159.128292 step=0.100000
2017/08/28 21:32:40 step 3: mse=157.033930 step=0.100000
2017/08/28 21:32:41 step 4: mse=155.114326 step=0.100000
2017/08/28 21:32:43 step 5: mse=153.564160 step=0.100000
2017/08/28 21:32:44 step 6: mse=152.150361 step=0.100000
2017/08/28 21:32:45 step 7: mse=150.832003 step=0.100000
2017/08/28 21:32:45 Saving...
2017/08/28 21:32:45 Gathering batch of experience...
2017/08/28 21:33:27 batch 648: mean=140.700000 stddev=133.907468 entropy=0.356245 frames=5302 count=40
2017/08/28 21:33:27 Training policy...
2017/08/28 21:33:31 step 0: objective=0.8955499
2017/08/28 21:33:32 step 1: objective=0.9032431
2017/08/28 21:33:34 step 2: objective=0.90969723
2017/08/28 21:33:35 step 3: objective=0.9162872
2017/08/28 21:33:37 step 4: objective=0.9251389
2017/08/28 21:33:38 step 5: objective=0.9305176
2017/08/28 21:33:40 step 6: objective=0.93569744
2017/08/28 21:33:42 step 7: objective=0.94334126
2017/08/28 21:33:42 Training value function...
2017/08/28 21:33:44 step 0: mse=181.469752 step=0.100000
2017/08/28 21:33:45 step 1: mse=178.242538 step=0.100000
2017/08/28 21:33:46 step 2: mse=175.440339 step=0.100000
2017/08/28 21:33:47 step 3: mse=173.019117 step=0.100000
2017/08/28 21:33:48 step 4: mse=170.864983 step=0.100000
2017/08/28 21:33:49 step 5: mse=169.273909 step=0.100000
2017/08/28 21:33:50 step 6: mse=168.192765 step=0.100000
2017/08/28 21:33:52 step 7: mse=166.783604 step=0.100000
2017/08/28 21:33:52 Saving...
2017/08/28 21:33:52 Gathering batch of experience...
2017/08/28 21:34:36 batch 649: mean=163.131579 stddev=149.218344 entropy=0.356544 frames=5944 count=38
2017/08/28 21:34:36 Training policy...
2017/08/28 21:34:41 step 0: objective=1.1359198
2017/08/28 21:34:42 step 1: objective=1.1452593
2017/08/28 21:34:44 step 2: objective=1.1532946
2017/08/28 21:34:46 step 3: objective=1.1589568
2017/08/28 21:34:48 step 4: objective=1.1630961
2017/08/28 21:34:49 step 5: objective=1.1664454
2017/08/28 21:34:51 step 6: objective=1.1686943
2017/08/28 21:34:53 step 7: objective=1.1716151
2017/08/28 21:34:53 Training value function...
2017/08/28 21:34:55 step 0: mse=188.499331 step=0.100000
2017/08/28 21:34:57 step 1: mse=185.524908 step=0.100000
2017/08/28 21:34:58 step 2: mse=182.814892 step=0.100000
2017/08/28 21:34:59 step 3: mse=180.735603 step=0.100000
2017/08/28 21:35:00 step 4: mse=178.703796 step=0.100000
2017/08/28 21:35:02 step 5: mse=176.808958 step=0.100000
2017/08/28 21:35:03 step 6: mse=175.153194 step=0.100000
2017/08/28 21:35:04 step 7: mse=173.492064 step=0.100000
2017/08/28 21:35:04 Saving...
2017/08/28 21:35:04 Gathering batch of experience...
2017/08/28 21:35:47 batch 650: mean=144.897436 stddev=100.471656 entropy=0.361596 frames=5361 count=39
2017/08/28 21:35:47 Training policy...
2017/08/28 21:35:50 step 0: objective=0.77985495
2017/08/28 21:35:52 step 1: objective=0.7971561
2017/08/28 21:35:54 step 2: objective=0.8031424
2017/08/28 21:35:55 step 3: objective=0.8131331
2017/08/28 21:35:57 step 4: objective=0.8188004
2017/08/28 21:35:58 step 5: objective=0.82326293
2017/08/28 21:36:00 step 6: objective=0.8261731
2017/08/28 21:36:01 step 7: objective=0.8295272
2017/08/28 21:36:01 Training value function...
2017/08/28 21:36:04 step 0: mse=175.106994 step=0.100000
2017/08/28 21:36:05 step 1: mse=171.765383 step=0.100000
2017/08/28 21:36:06 step 2: mse=168.987883 step=0.100000
2017/08/28 21:36:07 step 3: mse=166.865298 step=0.100000
2017/08/28 21:36:08 step 4: mse=164.886286 step=0.100000
2017/08/28 21:36:09 step 5: mse=163.161149 step=0.100000
2017/08/28 21:36:10 step 6: mse=161.617172 step=0.100000
2017/08/28 21:36:11 step 7: mse=160.263547 step=0.100000
2017/08/28 21:36:11 Saving...
2017/08/28 21:36:12 Gathering batch of experience...
2017/08/28 21:37:01 batch 651: mean=157.850000 stddev=134.776584 entropy=0.361318 frames=5896 count=40
2017/08/28 21:37:01 Training policy...
2017/08/28 21:37:06 step 0: objective=1.4379789
2017/08/28 21:37:07 step 1: objective=1.447979
2017/08/28 21:37:09 step 2: objective=1.4566114
2017/08/28 21:37:11 step 3: objective=1.4601073
2017/08/28 21:37:12 step 4: objective=1.4678403
2017/08/28 21:37:14 step 5: objective=1.4743154
2017/08/28 21:37:16 step 6: objective=1.4781127
2017/08/28 21:37:17 step 7: objective=1.4804353
2017/08/28 21:37:17 Training value function...
2017/08/28 21:37:20 step 0: mse=183.302199 step=0.100000
2017/08/28 21:37:21 step 1: mse=178.743878 step=0.100000
2017/08/28 21:37:22 step 2: mse=174.929593 step=0.100000
2017/08/28 21:37:24 step 3: mse=171.321134 step=0.100000
2017/08/28 21:37:25 step 4: mse=168.324893 step=0.100000
2017/08/28 21:37:26 step 5: mse=165.652470 step=0.100000
2017/08/28 21:37:27 step 6: mse=163.510596 step=0.100000
2017/08/28 21:37:29 step 7: mse=161.512980 step=0.100000
2017/08/28 21:37:29 Saving...
2017/08/28 21:37:29 Gathering batch of experience...
2017/08/28 21:38:19 batch 652: mean=181.657895 stddev=131.248314 entropy=0.364865 frames=6594 count=38
2017/08/28 21:38:19 Training policy...
2017/08/28 21:38:24 step 0: objective=1.2761966
2017/08/28 21:38:25 step 1: objective=1.2852249
2017/08/28 21:38:27 step 2: objective=1.2904308
2017/08/28 21:38:29 step 3: objective=1.2969328
2017/08/28 21:38:31 step 4: objective=1.3016454
2017/08/28 21:38:33 step 5: objective=1.3051727
2017/08/28 21:38:35 step 6: objective=1.3128716
2017/08/28 21:38:37 step 7: objective=1.3159548
2017/08/28 21:38:37 Training value function...
2017/08/28 21:38:40 step 0: mse=156.585849 step=0.100000
2017/08/28 21:38:41 step 1: mse=153.859254 step=0.100000
2017/08/28 21:38:42 step 2: mse=151.885788 step=0.100000
2017/08/28 21:38:44 step 3: mse=150.043530 step=0.100000
2017/08/28 21:38:45 step 4: mse=148.223486 step=0.100000
2017/08/28 21:38:47 step 5: mse=146.587050 step=0.100000
2017/08/28 21:38:48 step 6: mse=145.332631 step=0.100000
2017/08/28 21:38:49 step 7: mse=144.107761 step=0.100000
2017/08/28 21:38:49 Saving...
2017/08/28 21:38:49 Gathering batch of experience...
2017/08/28 21:39:35 batch 653: mean=155.358974 stddev=127.787983 entropy=0.352317 frames=5532 count=39
2017/08/28 21:39:35 Training policy...
2017/08/28 21:39:39 step 0: objective=1.1840601
2017/08/28 21:39:41 step 1: objective=1.1913157
2017/08/28 21:39:43 step 2: objective=1.2007182
2017/08/28 21:39:44 step 3: objective=1.2046171
2017/08/28 21:39:46 step 4: objective=1.2087427
2017/08/28 21:39:47 step 5: objective=1.2144642
2017/08/28 21:39:49 step 6: objective=1.2187022
2017/08/28 21:39:51 step 7: objective=1.2213047
2017/08/28 21:39:51 Training value function...
2017/08/28 21:39:53 step 0: mse=182.390785 step=0.100000
2017/08/28 21:39:54 step 1: mse=179.458279 step=0.100000
2017/08/28 21:39:55 step 2: mse=177.047518 step=0.100000
2017/08/28 21:39:56 step 3: mse=174.817141 step=0.100000
2017/08/28 21:39:58 step 4: mse=172.595382 step=0.100000
2017/08/28 21:39:59 step 5: mse=170.462512 step=0.100000
2017/08/28 21:40:00 step 6: mse=169.173076 step=0.100000
2017/08/28 21:40:01 step 7: mse=167.959050 step=0.100000
2017/08/28 21:40:01 Saving...
2017/08/28 21:40:01 Gathering batch of experience...
2017/08/28 21:40:45 batch 654: mean=104.562500 stddev=93.730088 entropy=0.346993 frames=5056 count=48
2017/08/28 21:40:45 Training policy...
2017/08/28 21:40:48 step 0: objective=-0.7528352
2017/08/28 21:40:50 step 1: objective=-0.7417809
2017/08/28 21:40:51 step 2: objective=-0.73410296
2017/08/28 21:40:53 step 3: objective=-0.72607666
2017/08/28 21:40:54 step 4: objective=-0.71648574
2017/08/28 21:40:56 step 5: objective=-0.70799625
2017/08/28 21:40:57 step 6: objective=-0.70512193
2017/08/28 21:40:59 step 7: objective=-0.7007635
2017/08/28 21:40:59 Training value function...
2017/08/28 21:41:01 step 0: mse=152.626971 step=0.100000
2017/08/28 21:41:02 step 1: mse=148.455845 step=0.100000
2017/08/28 21:41:03 step 2: mse=145.025450 step=0.100000
2017/08/28 21:41:04 step 3: mse=142.182659 step=0.100000
2017/08/28 21:41:05 step 4: mse=139.945222 step=0.100000
2017/08/28 21:41:06 step 5: mse=138.182472 step=0.100000
2017/08/28 21:41:07 step 6: mse=136.875527 step=0.100000
2017/08/28 21:41:08 step 7: mse=135.846226 step=0.100000
2017/08/28 21:41:08 Saving...
2017/08/28 21:41:08 Gathering batch of experience...
2017/08/28 21:41:54 batch 655: mean=160.542857 stddev=119.915052 entropy=0.361730 frames=5618 count=35
2017/08/28 21:41:54 Training policy...
2017/08/28 21:41:58 step 0: objective=1.0998348
2017/08/28 21:42:00 step 1: objective=1.1084323
2017/08/28 21:42:02 step 2: objective=1.1140677
2017/08/28 21:42:03 step 3: objective=1.1203163
2017/08/28 21:42:05 step 4: objective=1.1256337
2017/08/28 21:42:06 step 5: objective=1.1292199
2017/08/28 21:42:08 step 6: objective=1.1315656
2017/08/28 21:42:10 step 7: objective=1.1355913
2017/08/28 21:42:10 Training value function...
2017/08/28 21:42:12 step 0: mse=149.708422 step=0.100000
2017/08/28 21:42:13 step 1: mse=146.589770 step=0.100000
2017/08/28 21:42:14 step 2: mse=144.112565 step=0.100000
2017/08/28 21:42:16 step 3: mse=142.017789 step=0.100000
2017/08/28 21:42:17 step 4: mse=140.337086 step=0.100000
2017/08/28 21:42:18 step 5: mse=138.881509 step=0.100000
2017/08/28 21:42:19 step 6: mse=136.990687 step=0.100000
2017/08/28 21:42:20 step 7: mse=135.450530 step=0.100000
2017/08/28 21:42:20 Saving...
2017/08/28 21:42:20 Gathering batch of experience...
2017/08/28 21:43:03 batch 656: mean=150.162162 stddev=106.072773 entropy=0.356262 frames=5491 count=37
2017/08/28 21:43:03 Training policy...
2017/08/28 21:43:07 step 0: objective=1.0823168
2017/08/28 21:43:09 step 1: objective=1.0892493
2017/08/28 21:43:11 step 2: objective=1.0954226
2017/08/28 21:43:12 step 3: objective=1.0999894
2017/08/28 21:43:14 step 4: objective=1.1049354
2017/08/28 21:43:15 step 5: objective=1.107858
2017/08/28 21:43:17 step 6: objective=1.110873
2017/08/28 21:43:18 step 7: objective=1.1178919
2017/08/28 21:43:18 Training value function...
2017/08/28 21:43:21 step 0: mse=139.689369 step=0.100000
2017/08/28 21:43:22 step 1: mse=136.074234 step=0.100000
2017/08/28 21:43:23 step 2: mse=133.242575 step=0.100000
2017/08/28 21:43:24 step 3: mse=130.704700 step=0.100000
2017/08/28 21:43:25 step 4: mse=128.516512 step=0.100000
2017/08/28 21:43:27 step 5: mse=126.693831 step=0.100000
2017/08/28 21:43:28 step 6: mse=125.038436 step=0.100000
2017/08/28 21:43:29 step 7: mse=123.371928 step=0.100000
2017/08/28 21:43:29 Saving...
2017/08/28 21:43:29 Gathering batch of experience...
2017/08/28 21:44:16 batch 657: mean=148.230769 stddev=146.913626 entropy=0.357115 frames=5706 count=39
2017/08/28 21:44:16 Training policy...
2017/08/28 21:44:20 step 0: objective=1.1933659
2017/08/28 21:44:22 step 1: objective=1.1982839
2017/08/28 21:44:23 step 2: objective=1.2028085
2017/08/28 21:44:25 step 3: objective=1.2122645
2017/08/28 21:44:27 step 4: objective=1.2164185
2017/08/28 21:44:28 step 5: objective=1.2222118
2017/08/28 21:44:30 step 6: objective=1.2272532
2017/08/28 21:44:32 step 7: objective=1.2321049
2017/08/28 21:44:32 Training value function...
2017/08/28 21:44:34 step 0: mse=193.337475 step=0.100000
2017/08/28 21:44:35 step 1: mse=187.303647 step=0.100000
2017/08/28 21:44:36 step 2: mse=182.332997 step=0.100000
2017/08/28 21:44:38 step 3: mse=178.283349 step=0.100000
2017/08/28 21:44:39 step 4: mse=174.697967 step=0.100000
2017/08/28 21:44:40 step 5: mse=171.580546 step=0.100000
2017/08/28 21:44:41 step 6: mse=169.096810 step=0.100000
2017/08/28 21:44:42 step 7: mse=167.035427 step=0.100000
2017/08/28 21:44:42 Saving...
2017/08/28 21:44:42 Gathering batch of experience...
2017/08/28 21:45:30 batch 658: mean=160.425000 stddev=127.366771 entropy=0.356777 frames=6032 count=40
2017/08/28 21:45:30 Training policy...
2017/08/28 21:45:35 step 0: objective=1.6870905
2017/08/28 21:45:36 step 1: objective=1.6936212
2017/08/28 21:45:38 step 2: objective=1.6981876
2017/08/28 21:45:40 step 3: objective=1.703536
2017/08/28 21:45:42 step 4: objective=1.7067279
2017/08/28 21:45:43 step 5: objective=1.7132343
2017/08/28 21:45:45 step 6: objective=1.7184746
2017/08/28 21:45:47 step 7: objective=1.7234492
2017/08/28 21:45:47 Training value function...
2017/08/28 21:45:49 step 0: mse=179.164766 step=0.100000
2017/08/28 21:45:51 step 1: mse=175.196185 step=0.100000
2017/08/28 21:45:52 step 2: mse=171.839467 step=0.100000
2017/08/28 21:45:53 step 3: mse=168.992878 step=0.100000
2017/08/28 21:45:54 step 4: mse=166.498801 step=0.100000
2017/08/28 21:45:56 step 5: mse=164.278766 step=0.100000
2017/08/28 21:45:57 step 6: mse=162.383535 step=0.100000
2017/08/28 21:45:58 step 7: mse=160.476799 step=0.100000
2017/08/28 21:45:58 Saving...
2017/08/28 21:45:58 Gathering batch of experience...
2017/08/28 21:46:44 batch 659: mean=132.238095 stddev=110.879559 entropy=0.359772 frames=5360 count=42
2017/08/28 21:46:44 Training policy...
2017/08/28 21:46:48 step 0: objective=0.52594787
2017/08/28 21:46:49 step 1: objective=0.5339825
2017/08/28 21:46:51 step 2: objective=0.53964823
2017/08/28 21:46:52 step 3: objective=0.5459601
2017/08/28 21:46:54 step 4: objective=0.55167794
2017/08/28 21:46:56 step 5: objective=0.5566347
2017/08/28 21:46:57 step 6: objective=0.56042254
2017/08/28 21:46:59 step 7: objective=0.56485283
2017/08/28 21:46:59 Training value function...
2017/08/28 21:47:01 step 0: mse=184.150293 step=0.100000
2017/08/28 21:47:02 step 1: mse=181.187165 step=0.100000
2017/08/28 21:47:03 step 2: mse=179.177469 step=0.100000
2017/08/28 21:47:04 step 3: mse=177.324135 step=0.100000
2017/08/28 21:47:05 step 4: mse=175.754913 step=0.100000
2017/08/28 21:47:06 step 5: mse=174.431645 step=0.100000
2017/08/28 21:47:08 step 6: mse=172.833959 step=0.100000
2017/08/28 21:47:09 step 7: mse=171.354407 step=0.100000
2017/08/28 21:47:09 Saving...
2017/08/28 21:47:09 Gathering batch of experience...
2017/08/28 21:47:51 batch 660: mean=119.255814 stddev=84.067828 entropy=0.357174 frames=5187 count=43
2017/08/28 21:47:51 Training policy...
2017/08/28 21:47:55 step 0: objective=0.16261928
2017/08/28 21:47:56 step 1: objective=0.16902728
2017/08/28 21:47:58 step 2: objective=0.17527907
2017/08/28 21:47:59 step 3: objective=0.18060552
2017/08/28 21:48:01 step 4: objective=0.18767267
2017/08/28 21:48:02 step 5: objective=0.19460954
2017/08/28 21:48:04 step 6: objective=0.20091587
2017/08/28 21:48:05 step 7: objective=0.20515737
2017/08/28 21:48:05 Training value function...
2017/08/28 21:48:07 step 0: mse=137.896941 step=0.100000
2017/08/28 21:48:08 step 1: mse=136.021933 step=0.100000
2017/08/28 21:48:10 step 2: mse=134.663206 step=0.100000
2017/08/28 21:48:11 step 3: mse=133.426347 step=0.100000
2017/08/28 21:48:12 step 4: mse=132.394303 step=0.100000
2017/08/28 21:48:13 step 5: mse=131.457195 step=0.100000
2017/08/28 21:48:14 step 6: mse=130.706035 step=0.100000
2017/08/28 21:48:15 step 7: mse=130.086068 step=0.100000
2017/08/28 21:48:15 Saving...
2017/08/28 21:48:15 Gathering batch of experience...
2017/08/28 21:49:04 batch 661: mean=131.863636 stddev=110.306101 entropy=0.358560 frames=5411 count=44
2017/08/28 21:49:04 Training policy...
2017/08/28 21:49:08 step 0: objective=1.6755699
2017/08/28 21:49:09 step 1: objective=1.6863164
2017/08/28 21:49:11 step 2: objective=1.6922026
2017/08/28 21:49:12 step 3: objective=1.6966957
2017/08/28 21:49:14 step 4: objective=1.7044842
2017/08/28 21:49:16 step 5: objective=1.7088524
2017/08/28 21:49:17 step 6: objective=1.7137244
2017/08/28 21:49:19 step 7: objective=1.7190249
2017/08/28 21:49:19 Training value function...
2017/08/28 21:49:21 step 0: mse=201.175040 step=0.100000
2017/08/28 21:49:22 step 1: mse=196.587669 step=0.100000
2017/08/28 21:49:23 step 2: mse=192.552978 step=0.100000
2017/08/28 21:49:24 step 3: mse=189.084316 step=0.100000
2017/08/28 21:49:25 step 4: mse=185.949961 step=0.100000
2017/08/28 21:49:27 step 5: mse=183.362993 step=0.100000
2017/08/28 21:49:28 step 6: mse=181.367479 step=0.100000
2017/08/28 21:49:29 step 7: mse=179.459141 step=0.100000
2017/08/28 21:49:29 Saving...
2017/08/28 21:49:29 Gathering batch of experience...
2017/08/28 21:50:13 batch 662: mean=154.358974 stddev=130.067140 entropy=0.365082 frames=5850 count=39
2017/08/28 21:50:13 Training policy...
2017/08/28 21:50:18 step 0: objective=1.4247379
2017/08/28 21:50:19 step 1: objective=1.4326384
2017/08/28 21:50:21 step 2: objective=1.4377402
2017/08/28 21:50:23 step 3: objective=1.4428259
2017/08/28 21:50:25 step 4: objective=1.4493376
2017/08/28 21:50:26 step 5: objective=1.4538494
2017/08/28 21:50:28 step 6: objective=1.458801
2017/08/28 21:50:30 step 7: objective=1.4639376
2017/08/28 21:50:30 Training value function...
2017/08/28 21:50:32 step 0: mse=163.696419 step=0.100000
2017/08/28 21:50:33 step 1: mse=161.174772 step=0.100000
2017/08/28 21:50:34 step 2: mse=158.661855 step=0.100000
2017/08/28 21:50:36 step 3: mse=156.417966 step=0.100000
2017/08/28 21:50:37 step 4: mse=153.924268 step=0.100000
2017/08/28 21:50:38 step 5: mse=152.297483 step=0.100000
2017/08/28 21:50:39 step 6: mse=150.608134 step=0.100000
2017/08/28 21:50:41 step 7: mse=149.091733 step=0.100000
2017/08/28 21:50:41 Saving...
2017/08/28 21:50:41 Gathering batch of experience...
2017/08/28 21:51:27 batch 663: mean=157.128205 stddev=123.241306 entropy=0.358563 frames=5683 count=39
2017/08/28 21:51:27 Training policy...
2017/08/28 21:51:31 step 0: objective=1.6658113
2017/08/28 21:51:33 step 1: objective=1.6741036
2017/08/28 21:51:35 step 2: objective=1.6800295
2017/08/28 21:51:36 step 3: objective=1.6888943
2017/08/28 21:51:38 step 4: objective=1.693038
2017/08/28 21:51:40 step 5: objective=1.6977401
2017/08/28 21:51:41 step 6: objective=1.7019794
2017/08/28 21:51:43 step 7: objective=1.7046537
2017/08/28 21:51:43 Training value function...
2017/08/28 21:51:45 step 0: mse=174.703764 step=0.100000
2017/08/28 21:51:46 step 1: mse=171.330220 step=0.100000
2017/08/28 21:51:48 step 2: mse=168.333263 step=0.100000
2017/08/28 21:51:49 step 3: mse=165.567878 step=0.100000
2017/08/28 21:51:50 step 4: mse=163.367909 step=0.100000
2017/08/28 21:51:51 step 5: mse=161.477784 step=0.100000
2017/08/28 21:51:52 step 6: mse=159.536389 step=0.100000
2017/08/28 21:51:53 step 7: mse=158.237337 step=0.100000
2017/08/28 21:51:53 Saving...
2017/08/28 21:51:54 Gathering batch of experience...
2017/08/28 21:52:34 batch 664: mean=139.078947 stddev=103.702607 entropy=0.353525 frames=5132 count=38
2017/08/28 21:52:34 Training policy...
2017/08/28 21:52:37 step 0: objective=0.42677057
2017/08/28 21:52:39 step 1: objective=0.4328895
2017/08/28 21:52:40 step 2: objective=0.43745282
2017/08/28 21:52:42 step 3: objective=0.4453461
2017/08/28 21:52:43 step 4: objective=0.44867277
2017/08/28 21:52:45 step 5: objective=0.45580408
2017/08/28 21:52:46 step 6: objective=0.45921952
2017/08/28 21:52:48 step 7: objective=0.4628654
2017/08/28 21:52:48 Training value function...
2017/08/28 21:52:50 step 0: mse=155.267559 step=0.100000
2017/08/28 21:52:51 step 1: mse=153.460713 step=0.100000
2017/08/28 21:52:52 step 2: mse=152.080756 step=0.100000
2017/08/28 21:52:53 step 3: mse=150.996026 step=0.100000
2017/08/28 21:52:54 step 4: mse=150.139709 step=0.100000
2017/08/28 21:52:55 step 5: mse=148.952523 step=0.100000
2017/08/28 21:52:56 step 6: mse=147.863274 step=0.100000
2017/08/28 21:52:58 step 7: mse=146.995392 step=0.100000
2017/08/28 21:52:58 Saving...
2017/08/28 21:52:58 Gathering batch of experience...
2017/08/28 21:53:44 batch 665: mean=136.463415 stddev=103.925653 entropy=0.353314 frames=5463 count=41
2017/08/28 21:53:44 Training policy...
2017/08/28 21:53:48 step 0: objective=0.79641193
2017/08/28 21:53:49 step 1: objective=0.8073243
2017/08/28 21:53:51 step 2: objective=0.818859
2017/08/28 21:53:52 step 3: objective=0.8253138
2017/08/28 21:53:54 step 4: objective=0.8290347
2017/08/28 21:53:56 step 5: objective=0.8319515
2017/08/28 21:53:57 step 6: objective=0.8365891
2017/08/28 21:53:59 step 7: objective=0.8387029
2017/08/28 21:53:59 Training value function...
2017/08/28 21:54:01 step 0: mse=150.423780 step=0.100000
2017/08/28 21:54:02 step 1: mse=148.313875 step=0.100000
2017/08/28 21:54:03 step 2: mse=146.072721 step=0.100000
2017/08/28 21:54:04 step 3: mse=144.180775 step=0.100000
2017/08/28 21:54:06 step 4: mse=142.250144 step=0.100000
2017/08/28 21:54:07 step 5: mse=141.280570 step=0.100000
2017/08/28 21:54:08 step 6: mse=140.112869 step=0.100000
2017/08/28 21:54:09 step 7: mse=139.062802 step=0.100000
2017/08/28 21:54:09 Saving...
2017/08/28 21:54:09 Gathering batch of experience...
2017/08/28 21:54:55 batch 666: mean=147.975000 stddev=101.658617 entropy=0.350860 frames=5704 count=40
2017/08/28 21:54:55 Training policy...
2017/08/28 21:54:59 step 0: objective=1.2704134
2017/08/28 21:55:00 step 1: objective=1.2798369
2017/08/28 21:55:02 step 2: objective=1.2856975
2017/08/28 21:55:04 step 3: objective=1.2925981
2017/08/28 21:55:05 step 4: objective=1.2976619
2017/08/28 21:55:07 step 5: objective=1.3041797
2017/08/28 21:55:09 step 6: objective=1.3075949
2017/08/28 21:55:10 step 7: objective=1.3103207
2017/08/28 21:55:10 Training value function...
2017/08/28 21:55:13 step 0: mse=160.676937 step=0.100000
2017/08/28 21:55:14 step 1: mse=157.638297 step=0.100000
2017/08/28 21:55:15 step 2: mse=155.183332 step=0.100000
2017/08/28 21:55:16 step 3: mse=153.026255 step=0.100000
2017/08/28 21:55:18 step 4: mse=150.653480 step=0.100000
2017/08/28 21:55:19 step 5: mse=148.987546 step=0.100000
2017/08/28 21:55:20 step 6: mse=147.252461 step=0.100000
2017/08/28 21:55:21 step 7: mse=145.980449 step=0.100000
2017/08/28 21:55:21 Saving...
2017/08/28 21:55:21 Gathering batch of experience...
2017/08/28 21:56:06 batch 667: mean=122.068182 stddev=93.750490 entropy=0.346117 frames=5163 count=44
2017/08/28 21:56:06 Training policy...
2017/08/28 21:56:10 step 0: objective=0.49984193
2017/08/28 21:56:12 step 1: objective=0.50446653
2017/08/28 21:56:13 step 2: objective=0.5167332
2017/08/28 21:56:15 step 3: objective=0.5239653
2017/08/28 21:56:16 step 4: objective=0.52842253
2017/08/28 21:56:18 step 5: objective=0.53223354
2017/08/28 21:56:19 step 6: objective=0.53684455
2017/08/28 21:56:21 step 7: objective=0.53967535
2017/08/28 21:56:21 Training value function...
2017/08/28 21:56:23 step 0: mse=150.751764 step=0.100000
2017/08/28 21:56:24 step 1: mse=149.192229 step=0.100000
2017/08/28 21:56:25 step 2: mse=147.662052 step=0.100000
2017/08/28 21:56:26 step 3: mse=146.393696 step=0.100000
2017/08/28 21:56:27 step 4: mse=145.458458 step=0.100000
2017/08/28 21:56:28 step 5: mse=144.552250 step=0.100000
2017/08/28 21:56:29 step 6: mse=143.495740 step=0.100000
2017/08/28 21:56:30 step 7: mse=142.490634 step=0.100000
2017/08/28 21:56:30 Saving...
2017/08/28 21:56:31 Gathering batch of experience...
2017/08/28 21:57:12 batch 668: mean=142.351351 stddev=121.265671 entropy=0.359625 frames=5187 count=37
2017/08/28 21:57:12 Training policy...
2017/08/28 21:57:15 step 0: objective=1.4019814
2017/08/28 21:57:17 step 1: objective=1.4093947
2017/08/28 21:57:19 step 2: objective=1.4154881
2017/08/28 21:57:20 step 3: objective=1.4203265
2017/08/28 21:57:22 step 4: objective=1.4274654
2017/08/28 21:57:23 step 5: objective=1.432153
2017/08/28 21:57:25 step 6: objective=1.4385523
2017/08/28 21:57:26 step 7: objective=1.4414414
2017/08/28 21:57:26 Training value function...
2017/08/28 21:57:28 step 0: mse=146.394288 step=0.100000
2017/08/28 21:57:29 step 1: mse=142.119347 step=0.100000
2017/08/28 21:57:31 step 2: mse=138.805012 step=0.100000
2017/08/28 21:57:32 step 3: mse=136.029685 step=0.100000
2017/08/28 21:57:33 step 4: mse=133.350116 step=0.100000
2017/08/28 21:57:34 step 5: mse=131.344481 step=0.100000
2017/08/28 21:57:35 step 6: mse=129.675230 step=0.100000
2017/08/28 21:57:36 step 7: mse=128.365994 step=0.100000
2017/08/28 21:57:36 Saving...
2017/08/28 21:57:36 Gathering batch of experience...
2017/08/28 21:58:19 batch 669: mean=135.700000 stddev=104.638234 entropy=0.355732 frames=5370 count=40
2017/08/28 21:58:19 Training policy...
2017/08/28 21:58:23 step 0: objective=0.5740516
2017/08/28 21:58:25 step 1: objective=0.5822592
2017/08/28 21:58:26 step 2: objective=0.5893151
2017/08/28 21:58:28 step 3: objective=0.5979351
2017/08/28 21:58:29 step 4: objective=0.60367644
2017/08/28 21:58:31 step 5: objective=0.60798556
2017/08/28 21:58:33 step 6: objective=0.61132765
2017/08/28 21:58:34 step 7: objective=0.61489797
2017/08/28 21:58:34 Training value function...
2017/08/28 21:58:36 step 0: mse=164.253381 step=0.100000
2017/08/28 21:58:37 step 1: mse=161.235962 step=0.100000
2017/08/28 21:58:39 step 2: mse=158.865062 step=0.100000
2017/08/28 21:58:40 step 3: mse=156.682379 step=0.100000
2017/08/28 21:58:41 step 4: mse=154.704211 step=0.100000
2017/08/28 21:58:42 step 5: mse=153.281935 step=0.100000
2017/08/28 21:58:43 step 6: mse=152.101359 step=0.100000
2017/08/28 21:58:44 step 7: mse=150.995074 step=0.100000
2017/08/28 21:58:44 Saving...
2017/08/28 21:58:44 Gathering batch of experience...
2017/08/28 21:59:25 batch 670: mean=138.076923 stddev=101.485728 entropy=0.359838 frames=5093 count=39
2017/08/28 21:59:25 Training policy...
2017/08/28 21:59:29 step 0: objective=1.3790808
2017/08/28 21:59:30 step 1: objective=1.386887
2017/08/28 21:59:32 step 2: objective=1.3976358
2017/08/28 21:59:33 step 3: objective=1.4061619
2017/08/28 21:59:35 step 4: objective=1.4157782
2017/08/28 21:59:36 step 5: objective=1.4203663
2017/08/28 21:59:38 step 6: objective=1.4240925
2017/08/28 21:59:39 step 7: objective=1.4270397
2017/08/28 21:59:39 Training value function...
2017/08/28 21:59:41 step 0: mse=159.012254 step=0.100000
2017/08/28 21:59:43 step 1: mse=156.142423 step=0.100000
2017/08/28 21:59:44 step 2: mse=153.671213 step=0.100000
2017/08/28 21:59:45 step 3: mse=151.584823 step=0.100000
2017/08/28 21:59:46 step 4: mse=149.895895 step=0.100000
2017/08/28 21:59:47 step 5: mse=148.285576 step=0.100000
2017/08/28 21:59:48 step 6: mse=146.594354 step=0.100000
2017/08/28 21:59:49 step 7: mse=145.375786 step=0.100000
2017/08/28 21:59:49 Saving...
2017/08/28 21:59:49 Gathering batch of experience...
2017/08/28 22:00:30 batch 671: mean=128.375000 stddev=152.808162 entropy=0.359067 frames=5158 count=40
2017/08/28 22:00:30 Training policy...
2017/08/28 22:00:34 step 0: objective=0.8324009
2017/08/28 22:00:36 step 1: objective=0.8407928
2017/08/28 22:00:37 step 2: objective=0.8462019
2017/08/28 22:00:39 step 3: objective=0.8532055
2017/08/28 22:00:40 step 4: objective=0.85858816
2017/08/28 22:00:42 step 5: objective=0.8642155
2017/08/28 22:00:43 step 6: objective=0.86956
2017/08/28 22:00:45 step 7: objective=0.87321264
2017/08/28 22:00:45 Training value function...
2017/08/28 22:00:47 step 0: mse=179.059723 step=0.100000
2017/08/28 22:00:48 step 1: mse=174.011702 step=0.100000
2017/08/28 22:00:49 step 2: mse=170.184897 step=0.100000
2017/08/28 22:00:50 step 3: mse=166.452547 step=0.100000
2017/08/28 22:00:51 step 4: mse=163.304297 step=0.100000
2017/08/28 22:00:52 step 5: mse=160.685940 step=0.100000
2017/08/28 22:00:53 step 6: mse=158.382530 step=0.100000
2017/08/28 22:00:54 step 7: mse=156.505772 step=0.100000
2017/08/28 22:00:54 Saving...
2017/08/28 22:00:55 Gathering batch of experience...
2017/08/28 22:01:41 batch 672: mean=143.674419 stddev=117.784139 entropy=0.357571 frames=5907 count=43
2017/08/28 22:01:41 Training policy...
2017/08/28 22:01:45 step 0: objective=1.5749291
2017/08/28 22:01:47 step 1: objective=1.5823321
2017/08/28 22:01:49 step 2: objective=1.5884523
2017/08/28 22:01:50 step 3: objective=1.5941172
2017/08/28 22:01:52 step 4: objective=1.5980294
2017/08/28 22:01:54 step 5: objective=1.6028067
2017/08/28 22:01:56 step 6: objective=1.6062433
2017/08/28 22:01:57 step 7: objective=1.609782
2017/08/28 22:01:57 Training value function...
2017/08/28 22:02:00 step 0: mse=171.771953 step=0.100000
2017/08/28 22:02:01 step 1: mse=169.270585 step=0.100000
2017/08/28 22:02:02 step 2: mse=167.078935 step=0.100000
2017/08/28 22:02:03 step 3: mse=164.910511 step=0.100000
2017/08/28 22:02:05 step 4: mse=163.056149 step=0.100000
2017/08/28 22:02:06 step 5: mse=161.320045 step=0.100000
2017/08/28 22:02:07 step 6: mse=159.561398 step=0.100000
2017/08/28 22:02:08 step 7: mse=158.166274 step=0.100000
2017/08/28 22:02:08 Saving...
2017/08/28 22:02:08 Gathering batch of experience...
2017/08/28 22:02:52 batch 673: mean=147.216216 stddev=114.993334 entropy=0.350552 frames=5197 count=37
2017/08/28 22:02:52 Training policy...
2017/08/28 22:02:56 step 0: objective=1.1735833
2017/08/28 22:02:57 step 1: objective=1.1815149
2017/08/28 22:02:59 step 2: objective=1.1903173
2017/08/28 22:03:00 step 3: objective=1.1961747
2017/08/28 22:03:02 step 4: objective=1.2056028
2017/08/28 22:03:03 step 5: objective=1.211689
2017/08/28 22:03:05 step 6: objective=1.2182466
2017/08/28 22:03:06 step 7: objective=1.2225955
2017/08/28 22:03:06 Training value function...
2017/08/28 22:03:09 step 0: mse=175.149657 step=0.100000
2017/08/28 22:03:10 step 1: mse=172.458741 step=0.100000
2017/08/28 22:03:11 step 2: mse=170.354811 step=0.100000
2017/08/28 22:03:12 step 3: mse=168.599633 step=0.100000
2017/08/28 22:03:13 step 4: mse=167.491276 step=0.100000
2017/08/28 22:03:14 step 5: mse=166.095484 step=0.100000
2017/08/28 22:03:15 step 6: mse=164.993280 step=0.100000
2017/08/28 22:03:16 step 7: mse=163.618552 step=0.100000
2017/08/28 22:03:16 Saving...
2017/08/28 22:03:16 Gathering batch of experience...
2017/08/28 22:04:02 batch 674: mean=156.184211 stddev=124.225571 entropy=0.356860 frames=5762 count=38
2017/08/28 22:04:02 Training policy...
2017/08/28 22:04:06 step 0: objective=1.0798512
2017/08/28 22:04:08 step 1: objective=1.0859181
2017/08/28 22:04:10 step 2: objective=1.091504
2017/08/28 22:04:11 step 3: objective=1.1024481
2017/08/28 22:04:13 step 4: objective=1.1059065
2017/08/28 22:04:15 step 5: objective=1.113914
2017/08/28 22:04:16 step 6: objective=1.116512
2017/08/28 22:04:18 step 7: objective=1.1204882
2017/08/28 22:04:18 Training value function...
2017/08/28 22:04:20 step 0: mse=170.355283 step=0.100000
2017/08/28 22:04:22 step 1: mse=167.141429 step=0.100000
2017/08/28 22:04:23 step 2: mse=164.363266 step=0.100000
2017/08/28 22:04:24 step 3: mse=161.856403 step=0.100000
2017/08/28 22:04:25 step 4: mse=159.969952 step=0.100000
2017/08/28 22:04:27 step 5: mse=158.076802 step=0.100000
2017/08/28 22:04:28 step 6: mse=156.460378 step=0.100000
2017/08/28 22:04:29 step 7: mse=155.020406 step=0.100000
2017/08/28 22:04:29 Saving...
2017/08/28 22:04:29 Gathering batch of experience...
2017/08/28 22:05:19 batch 675: mean=166.717949 stddev=152.539183 entropy=0.356227 frames=5881 count=39
2017/08/28 22:05:19 Training policy...
2017/08/28 22:05:24 step 0: objective=1.9985695
2017/08/28 22:05:25 step 1: objective=2.0091755
2017/08/28 22:05:27 step 2: objective=2.0168903
2017/08/28 22:05:29 step 3: objective=2.0244627
2017/08/28 22:05:30 step 4: objective=2.0292828
2017/08/28 22:05:32 step 5: objective=2.033896
2017/08/28 22:05:34 step 6: objective=2.0389884
2017/08/28 22:05:36 step 7: objective=2.0433657
2017/08/28 22:05:36 Training value function...
2017/08/28 22:05:38 step 0: mse=217.650705 step=0.100000
2017/08/28 22:05:39 step 1: mse=211.987906 step=0.100000
2017/08/28 22:05:40 step 2: mse=207.289479 step=0.100000
2017/08/28 22:05:42 step 3: mse=203.275267 step=0.100000
2017/08/28 22:05:43 step 4: mse=199.582105 step=0.100000
2017/08/28 22:05:44 step 5: mse=196.525295 step=0.100000
2017/08/28 22:05:45 step 6: mse=193.706552 step=0.100000
2017/08/28 22:05:47 step 7: mse=191.304692 step=0.100000
2017/08/28 22:05:47 Saving...
2017/08/28 22:05:47 Gathering batch of experience...
2017/08/28 22:06:34 batch 676: mean=149.800000 stddev=114.436270 entropy=0.361560 frames=5651 count=40
2017/08/28 22:06:34 Training policy...
2017/08/28 22:06:38 step 0: objective=0.6293417
2017/08/28 22:06:40 step 1: objective=0.6409126
2017/08/28 22:06:41 step 2: objective=0.6499916
2017/08/28 22:06:43 step 3: objective=0.66098326
2017/08/28 22:06:45 step 4: objective=0.66499376
2017/08/28 22:06:46 step 5: objective=0.6707628
2017/08/28 22:06:48 step 6: objective=0.67416906
2017/08/28 22:06:49 step 7: objective=0.68055975
2017/08/28 22:06:49 Training value function...
2017/08/28 22:06:52 step 0: mse=181.927746 step=0.100000
2017/08/28 22:06:53 step 1: mse=179.185048 step=0.100000
2017/08/28 22:06:54 step 2: mse=176.922161 step=0.100000
2017/08/28 22:06:55 step 3: mse=175.255504 step=0.100000
2017/08/28 22:06:57 step 4: mse=173.308837 step=0.100000
2017/08/28 22:06:58 step 5: mse=171.384555 step=0.100000
2017/08/28 22:06:59 step 6: mse=169.887019 step=0.100000
2017/08/28 22:07:00 step 7: mse=168.317546 step=0.100000
2017/08/28 22:07:00 Saving...
2017/08/28 22:07:00 Gathering batch of experience...
2017/08/28 22:07:45 batch 677: mean=148.804878 stddev=111.664178 entropy=0.355504 frames=5704 count=41
2017/08/28 22:07:45 Training policy...
2017/08/28 22:07:49 step 0: objective=0.87827843
2017/08/28 22:07:51 step 1: objective=0.886652
2017/08/28 22:07:53 step 2: objective=0.8940137
2017/08/28 22:07:54 step 3: objective=0.9008825
2017/08/28 22:07:56 step 4: objective=0.90846175
2017/08/28 22:07:58 step 5: objective=0.9142868
2017/08/28 22:07:59 step 6: objective=0.9189627
2017/08/28 22:08:01 step 7: objective=0.9222033
2017/08/28 22:08:01 Training value function...
2017/08/28 22:08:03 step 0: mse=141.503458 step=0.100000
2017/08/28 22:08:04 step 1: mse=140.328198 step=0.100000
2017/08/28 22:08:06 step 2: mse=139.466318 step=0.100000
2017/08/28 22:08:07 step 3: mse=138.727365 step=0.100000
2017/08/28 22:08:08 step 4: mse=137.874357 step=0.100000
2017/08/28 22:08:09 step 5: mse=136.904542 step=0.100000
2017/08/28 22:08:10 step 6: mse=136.044684 step=0.100000
2017/08/28 22:08:12 step 7: mse=135.290791 step=0.100000
2017/08/28 22:08:12 Saving...
2017/08/28 22:08:12 Gathering batch of experience...
2017/08/28 22:08:53 batch 678: mean=155.722222 stddev=123.405522 entropy=0.347123 frames=5283 count=36
2017/08/28 22:08:53 Training policy...
2017/08/28 22:08:57 step 0: objective=1.1216999
2017/08/28 22:08:58 step 1: objective=1.1305355
2017/08/28 22:09:00 step 2: objective=1.1347425
2017/08/28 22:09:02 step 3: objective=1.143364
2017/08/28 22:09:03 step 4: objective=1.147138
2017/08/28 22:09:05 step 5: objective=1.1501678
2017/08/28 22:09:06 step 6: objective=1.1537261
2017/08/28 22:09:08 step 7: objective=1.1586857
2017/08/28 22:09:08 Training value function...
2017/08/28 22:09:10 step 0: mse=152.859497 step=0.100000
2017/08/28 22:09:11 step 1: mse=149.533616 step=0.100000
2017/08/28 22:09:12 step 2: mse=146.740182 step=0.100000
2017/08/28 22:09:13 step 3: mse=144.308294 step=0.100000
2017/08/28 22:09:14 step 4: mse=142.252521 step=0.100000
2017/08/28 22:09:16 step 5: mse=140.510324 step=0.100000
2017/08/28 22:09:17 step 6: mse=138.984636 step=0.100000
2017/08/28 22:09:18 step 7: mse=137.524296 step=0.100000
2017/08/28 22:09:18 Saving...
2017/08/28 22:09:18 Gathering batch of experience...
2017/08/28 22:09:59 batch 679: mean=133.282051 stddev=130.650434 entropy=0.357614 frames=5001 count=39
2017/08/28 22:09:59 Training policy...
2017/08/28 22:10:02 step 0: objective=0.54227906
2017/08/28 22:10:04 step 1: objective=0.55101097
2017/08/28 22:10:05 step 2: objective=0.56111676
2017/08/28 22:10:07 step 3: objective=0.5683335
2017/08/28 22:10:08 step 4: objective=0.57540375
2017/08/28 22:10:10 step 5: objective=0.5811054
2017/08/28 22:10:11 step 6: objective=0.5863849
2017/08/28 22:10:13 step 7: objective=0.5914787
2017/08/28 22:10:13 Training value function...
2017/08/28 22:10:15 step 0: mse=180.409379 step=0.100000
2017/08/28 22:10:16 step 1: mse=178.384723 step=0.100000
2017/08/28 22:10:17 step 2: mse=175.887110 step=0.100000
2017/08/28 22:10:18 step 3: mse=173.048931 step=0.100000
2017/08/28 22:10:19 step 4: mse=171.606702 step=0.100000
2017/08/28 22:10:20 step 5: mse=169.621425 step=0.100000
2017/08/28 22:10:21 step 6: mse=167.701159 step=0.100000
2017/08/28 22:10:22 step 7: mse=167.022481 step=0.100000
2017/08/28 22:10:22 Saving...
2017/08/28 22:10:22 Gathering batch of experience...
2017/08/28 22:11:16 batch 680: mean=173.809524 stddev=147.467226 entropy=0.360530 frames=7010 count=42
2017/08/28 22:11:16 Training policy...
2017/08/28 22:11:22 step 0: objective=1.4056581
2017/08/28 22:11:24 step 1: objective=1.4119499
2017/08/28 22:11:26 step 2: objective=1.415101
2017/08/28 22:11:28 step 3: objective=1.4197809
2017/08/28 22:11:30 step 4: objective=1.4234939
2017/08/28 22:11:32 step 5: objective=1.4260962
2017/08/28 22:11:34 step 6: objective=1.4285067
2017/08/28 22:11:36 step 7: objective=1.4307591
2017/08/28 22:11:36 Training value function...
2017/08/28 22:11:39 step 0: mse=151.632491 step=0.100000
2017/08/28 22:11:41 step 1: mse=149.350942 step=0.100000
2017/08/28 22:11:42 step 2: mse=146.310755 step=0.100000
2017/08/28 22:11:43 step 3: mse=143.805092 step=0.100000
2017/08/28 22:11:45 step 4: mse=142.296360 step=0.100000
2017/08/28 22:11:46 step 5: mse=140.586030 step=0.100000
2017/08/28 22:11:48 step 6: mse=138.954757 step=0.100000
2017/08/28 22:11:49 step 7: mse=137.848402 step=0.100000
2017/08/28 22:11:49 Saving...
2017/08/28 22:11:49 Gathering batch of experience...
2017/08/28 22:12:28 batch 681: mean=154.588235 stddev=114.215513 entropy=0.352631 frames=5113 count=34
2017/08/28 22:12:28 Training policy...
2017/08/28 22:12:31 step 0: objective=0.6768345
2017/08/28 22:12:33 step 1: objective=0.6854544
2017/08/28 22:12:34 step 2: objective=0.6916019
2017/08/28 22:12:36 step 3: objective=0.6967031
2017/08/28 22:12:38 step 4: objective=0.70123035
2017/08/28 22:12:39 step 5: objective=0.7047188
2017/08/28 22:12:41 step 6: objective=0.71164113
2017/08/28 22:12:42 step 7: objective=0.7154893
2017/08/28 22:12:42 Training value function...
2017/08/28 22:12:44 step 0: mse=151.505687 step=0.100000
2017/08/28 22:12:45 step 1: mse=147.938502 step=0.100000
2017/08/28 22:12:46 step 2: mse=144.990251 step=0.100000
2017/08/28 22:12:47 step 3: mse=142.505249 step=0.100000
2017/08/28 22:12:48 step 4: mse=140.513308 step=0.100000
2017/08/28 22:12:50 step 5: mse=138.832094 step=0.100000
2017/08/28 22:12:51 step 6: mse=137.344357 step=0.100000
2017/08/28 22:12:52 step 7: mse=136.127974 step=0.100000
2017/08/28 22:12:52 Saving...
2017/08/28 22:12:52 Gathering batch of experience...
2017/08/28 22:13:33 batch 682: mean=146.611111 stddev=134.083365 entropy=0.356727 frames=5060 count=36
2017/08/28 22:13:33 Training policy...
2017/08/28 22:13:37 step 0: objective=1.0391859
2017/08/28 22:13:38 step 1: objective=1.0459031
2017/08/28 22:13:40 step 2: objective=1.0515134
2017/08/28 22:13:41 step 3: objective=1.0566769
2017/08/28 22:13:43 step 4: objective=1.0654382
2017/08/28 22:13:44 step 5: objective=1.0702006
2017/08/28 22:13:46 step 6: objective=1.0780168
2017/08/28 22:13:47 step 7: objective=1.0813335
2017/08/28 22:13:47 Training value function...
2017/08/28 22:13:49 step 0: mse=171.185644 step=0.100000
2017/08/28 22:13:51 step 1: mse=168.394800 step=0.100000
2017/08/28 22:13:52 step 2: mse=165.808608 step=0.100000
2017/08/28 22:13:53 step 3: mse=164.159023 step=0.100000
2017/08/28 22:13:54 step 4: mse=162.237642 step=0.100000
2017/08/28 22:13:55 step 5: mse=160.600443 step=0.100000
2017/08/28 22:13:56 step 6: mse=159.051760 step=0.100000
2017/08/28 22:13:57 step 7: mse=157.513966 step=0.100000
2017/08/28 22:13:57 Saving...
2017/08/28 22:13:57 Gathering batch of experience...
2017/08/28 22:14:43 batch 683: mean=174.194444 stddev=121.708171 entropy=0.355977 frames=5794 count=36
2017/08/28 22:14:43 Training policy...
2017/08/28 22:14:47 step 0: objective=1.6884652
2017/08/28 22:14:49 step 1: objective=1.697282
2017/08/28 22:14:51 step 2: objective=1.7053515
2017/08/28 22:14:53 step 3: objective=1.7104986
2017/08/28 22:14:54 step 4: objective=1.7177637
2017/08/28 22:14:56 step 5: objective=1.7219032
2017/08/28 22:14:58 step 6: objective=1.726446
2017/08/28 22:14:59 step 7: objective=1.7319397
2017/08/28 22:14:59 Training value function...
2017/08/28 22:15:02 step 0: mse=183.019543 step=0.100000
2017/08/28 22:15:03 step 1: mse=179.294431 step=0.100000
2017/08/28 22:15:04 step 2: mse=176.460481 step=0.100000
2017/08/28 22:15:05 step 3: mse=174.355049 step=0.100000
2017/08/28 22:15:07 step 4: mse=172.231558 step=0.100000
2017/08/28 22:15:08 step 5: mse=169.783598 step=0.100000
2017/08/28 22:15:09 step 6: mse=167.695941 step=0.100000
2017/08/28 22:15:10 step 7: mse=165.826664 step=0.100000
2017/08/28 22:15:10 Saving...
2017/08/28 22:15:10 Gathering batch of experience...
2017/08/28 22:15:58 batch 684: mean=150.500000 stddev=109.826454 entropy=0.354393 frames=5799 count=40
2017/08/28 22:15:58 Training policy...
2017/08/28 22:16:03 step 0: objective=0.68692887
2017/08/28 22:16:04 step 1: objective=0.696328
2017/08/28 22:16:06 step 2: objective=0.7013812
2017/08/28 22:16:08 step 3: objective=0.7113853
2017/08/28 22:16:09 step 4: objective=0.71590984
2017/08/28 22:16:11 step 5: objective=0.7219306
2017/08/28 22:16:13 step 6: objective=0.72567165
2017/08/28 22:16:15 step 7: objective=0.7285882
2017/08/28 22:16:15 Training value function...
2017/08/28 22:16:17 step 0: mse=150.337158 step=0.100000
2017/08/28 22:16:18 step 1: mse=148.702266 step=0.100000
2017/08/28 22:16:19 step 2: mse=147.078504 step=0.100000
2017/08/28 22:16:21 step 3: mse=145.722080 step=0.100000
2017/08/28 22:16:22 step 4: mse=143.952786 step=0.100000
2017/08/28 22:16:23 step 5: mse=142.580699 step=0.100000
2017/08/28 22:16:24 step 6: mse=141.699558 step=0.100000
2017/08/28 22:16:26 step 7: mse=140.860517 step=0.100000
2017/08/28 22:16:26 Saving...
2017/08/28 22:16:26 Gathering batch of experience...
2017/08/28 22:17:06 batch 685: mean=118.121951 stddev=82.694617 entropy=0.356434 frames=4833 count=41
2017/08/28 22:17:06 Training policy...
2017/08/28 22:17:09 step 0: objective=-0.3618584
2017/08/28 22:17:11 step 1: objective=-0.34875762
2017/08/28 22:17:12 step 2: objective=-0.3399559
2017/08/28 22:17:13 step 3: objective=-0.33605334
2017/08/28 22:17:15 step 4: objective=-0.33098868
2017/08/28 22:17:16 step 5: objective=-0.32422337
2017/08/28 22:17:18 step 6: objective=-0.3159683
2017/08/28 22:17:19 step 7: objective=-0.31171563
2017/08/28 22:17:19 Training value function...
2017/08/28 22:17:21 step 0: mse=142.052682 step=0.100000
2017/08/28 22:17:22 step 1: mse=138.998549 step=0.100000
2017/08/28 22:17:23 step 2: mse=136.438811 step=0.100000
2017/08/28 22:17:24 step 3: mse=134.481735 step=0.100000
2017/08/28 22:17:25 step 4: mse=132.755584 step=0.100000
2017/08/28 22:17:26 step 5: mse=131.335636 step=0.100000
2017/08/28 22:17:27 step 6: mse=130.261301 step=0.100000
2017/08/28 22:17:28 step 7: mse=129.209295 step=0.100000
2017/08/28 22:17:28 Saving...
2017/08/28 22:17:28 Gathering batch of experience...
2017/08/28 22:18:10 batch 686: mean=157.514286 stddev=132.874027 entropy=0.353503 frames=5330 count=35
2017/08/28 22:18:10 Training policy...
2017/08/28 22:18:14 step 0: objective=1.8244644
2017/08/28 22:18:15 step 1: objective=1.8302706
2017/08/28 22:18:17 step 2: objective=1.8346276
2017/08/28 22:18:19 step 3: objective=1.8392528
2017/08/28 22:18:20 step 4: objective=1.844728
2017/08/28 22:18:22 step 5: objective=1.848095
2017/08/28 22:18:23 step 6: objective=1.8551283
2017/08/28 22:18:25 step 7: objective=1.8620789
2017/08/28 22:18:25 Training value function...
2017/08/28 22:18:27 step 0: mse=193.326724 step=0.100000
2017/08/28 22:18:28 step 1: mse=187.797748 step=0.100000
2017/08/28 22:18:29 step 2: mse=183.070840 step=0.100000
2017/08/28 22:18:30 step 3: mse=178.650538 step=0.100000
2017/08/28 22:18:32 step 4: mse=175.232097 step=0.100000
2017/08/28 22:18:33 step 5: mse=172.479422 step=0.100000
2017/08/28 22:18:34 step 6: mse=169.778025 step=0.100000
2017/08/28 22:18:35 step 7: mse=167.680982 step=0.100000
2017/08/28 22:18:35 Saving...
2017/08/28 22:18:35 Gathering batch of experience...
2017/08/28 22:19:26 batch 687: mean=189.578947 stddev=167.716024 entropy=0.355363 frames=6352 count=38
2017/08/28 22:19:26 Training policy...
2017/08/28 22:19:31 step 0: objective=2.6999078
2017/08/28 22:19:33 step 1: objective=2.7071629
2017/08/28 22:19:35 step 2: objective=2.7121434
2017/08/28 22:19:37 step 3: objective=2.7195058
2017/08/28 22:19:39 step 4: objective=2.725308
2017/08/28 22:19:40 step 5: objective=2.7306273
2017/08/28 22:19:42 step 6: objective=2.736193
2017/08/28 22:19:44 step 7: objective=2.7388856
2017/08/28 22:19:44 Training value function...
2017/08/28 22:19:47 step 0: mse=217.432043 step=0.100000
2017/08/28 22:19:48 step 1: mse=209.852132 step=0.100000
2017/08/28 22:19:49 step 2: mse=203.115572 step=0.100000
2017/08/28 22:19:51 step 3: mse=197.388404 step=0.100000
2017/08/28 22:19:52 step 4: mse=192.612312 step=0.100000
2017/08/28 22:19:54 step 5: mse=188.127470 step=0.100000
2017/08/28 22:19:55 step 6: mse=184.463798 step=0.100000
2017/08/28 22:19:56 step 7: mse=181.145652 step=0.100000
2017/08/28 22:19:56 Saving...
2017/08/28 22:19:56 Gathering batch of experience...
2017/08/28 22:20:48 batch 688: mean=154.738095 stddev=153.513930 entropy=0.347326 frames=5973 count=42
2017/08/28 22:20:48 Training policy...
2017/08/28 22:20:52 step 0: objective=0.77169526
2017/08/28 22:20:54 step 1: objective=0.7793433
2017/08/28 22:20:56 step 2: objective=0.7854575
2017/08/28 22:20:57 step 3: objective=0.7919093
2017/08/28 22:20:59 step 4: objective=0.7976859
2017/08/28 22:21:01 step 5: objective=0.802948
2017/08/28 22:21:03 step 6: objective=0.8114391
2017/08/28 22:21:04 step 7: objective=0.8150963
2017/08/28 22:21:04 Training value function...
2017/08/28 22:21:07 step 0: mse=206.308482 step=0.100000
2017/08/28 22:21:08 step 1: mse=203.543014 step=0.100000
2017/08/28 22:21:09 step 2: mse=200.491174 step=0.100000
2017/08/28 22:21:11 step 3: mse=198.593193 step=0.100000
2017/08/28 22:21:12 step 4: mse=196.758675 step=0.100000
2017/08/28 22:21:13 step 5: mse=194.298734 step=0.100000
2017/08/28 22:21:14 step 6: mse=192.554488 step=0.100000
2017/08/28 22:21:16 step 7: mse=190.888296 step=0.100000
2017/08/28 22:21:16 Saving...
2017/08/28 22:21:16 Gathering batch of experience...
2017/08/28 22:22:11 batch 689: mean=145.104167 stddev=152.524894 entropy=0.356336 frames=6473 count=48
2017/08/28 22:22:11 Training policy...
2017/08/28 22:22:16 step 0: objective=0.76570284
2017/08/28 22:22:18 step 1: objective=0.7748782
2017/08/28 22:22:20 step 2: objective=0.77961767
2017/08/28 22:22:22 step 3: objective=0.79045767
2017/08/28 22:22:24 step 4: objective=0.79707974
2017/08/28 22:22:26 step 5: objective=0.80094177
2017/08/28 22:22:28 step 6: objective=0.8053896
2017/08/28 22:22:30 step 7: objective=0.8094065
2017/08/28 22:22:30 Training value function...
2017/08/28 22:22:32 step 0: mse=169.046540 step=0.100000
2017/08/28 22:22:34 step 1: mse=166.885385 step=0.100000
2017/08/28 22:22:35 step 2: mse=165.156520 step=0.100000
2017/08/28 22:22:36 step 3: mse=163.427075 step=0.100000
2017/08/28 22:22:38 step 4: mse=161.910424 step=0.100000
2017/08/28 22:22:39 step 5: mse=160.404390 step=0.100000
2017/08/28 22:22:41 step 6: mse=159.291911 step=0.100000
2017/08/28 22:22:42 step 7: mse=158.396489 step=0.100000
2017/08/28 22:22:42 Saving...
2017/08/28 22:22:42 Gathering batch of experience...
2017/08/28 22:23:28 batch 690: mean=130.133333 stddev=106.498325 entropy=0.355688 frames=5564 count=45
2017/08/28 22:23:28 Training policy...
2017/08/28 22:23:33 step 0: objective=0.3981652
2017/08/28 22:23:34 step 1: objective=0.4084602
2017/08/28 22:23:36 step 2: objective=0.41452375
2017/08/28 22:23:38 step 3: objective=0.4202852
2017/08/28 22:23:39 step 4: objective=0.42469934
2017/08/28 22:23:41 step 5: objective=0.43129236
2017/08/28 22:23:43 step 6: objective=0.43785393
2017/08/28 22:23:44 step 7: objective=0.44171512
2017/08/28 22:23:44 Training value function...
2017/08/28 22:23:47 step 0: mse=206.011738 step=0.100000
2017/08/28 22:23:48 step 1: mse=203.650400 step=0.100000
2017/08/28 22:23:49 step 2: mse=201.327285 step=0.100000
2017/08/28 22:23:50 step 3: mse=199.870356 step=0.100000
2017/08/28 22:23:51 step 4: mse=198.391493 step=0.100000
2017/08/28 22:23:52 step 5: mse=196.865995 step=0.100000
2017/08/28 22:23:54 step 6: mse=195.067160 step=0.100000
2017/08/28 22:23:55 step 7: mse=193.896571 step=0.100000
2017/08/28 22:23:55 Saving...
2017/08/28 22:23:55 Gathering batch of experience...
2017/08/28 22:24:40 batch 691: mean=118.347826 stddev=94.959767 entropy=0.345799 frames=5366 count=46
2017/08/28 22:24:40 Training policy...
2017/08/28 22:24:44 step 0: objective=0.16687275
2017/08/28 22:24:46 step 1: objective=0.1711976
2017/08/28 22:24:48 step 2: objective=0.17594108
2017/08/28 22:24:49 step 3: objective=0.1844911
2017/08/28 22:24:51 step 4: objective=0.18831672
2017/08/28 22:24:52 step 5: objective=0.19097523
2017/08/28 22:24:54 step 6: objective=0.1969395
2017/08/28 22:24:55 step 7: objective=0.20140257
2017/08/28 22:24:55 Training value function...
2017/08/28 22:24:58 step 0: mse=153.040517 step=0.100000
2017/08/28 22:24:59 step 1: mse=151.225429 step=0.100000
2017/08/28 22:25:00 step 2: mse=149.803288 step=0.100000
2017/08/28 22:25:01 step 3: mse=148.774502 step=0.100000
2017/08/28 22:25:02 step 4: mse=147.589394 step=0.100000
2017/08/28 22:25:03 step 5: mse=146.270211 step=0.100000
2017/08/28 22:25:04 step 6: mse=145.522583 step=0.100000
2017/08/28 22:25:06 step 7: mse=144.818840 step=0.100000
2017/08/28 22:25:06 Saving...
2017/08/28 22:25:06 Gathering batch of experience...
2017/08/28 22:25:50 batch 692: mean=138.476190 stddev=96.504438 entropy=0.345785 frames=5367 count=42
2017/08/28 22:25:50 Training policy...
2017/08/28 22:25:54 step 0: objective=1.7205696
2017/08/28 22:25:55 step 1: objective=1.7257628
2017/08/28 22:25:57 step 2: objective=1.7367816
2017/08/28 22:25:59 step 3: objective=1.7424564
2017/08/28 22:26:00 step 4: objective=1.7463652
2017/08/28 22:26:02 step 5: objective=1.7519956
2017/08/28 22:26:03 step 6: objective=1.7581588
2017/08/28 22:26:05 step 7: objective=1.7663295
2017/08/28 22:26:05 Training value function...
2017/08/28 22:26:07 step 0: mse=182.092275 step=0.100000
2017/08/28 22:26:08 step 1: mse=179.925186 step=0.100000
2017/08/28 22:26:09 step 2: mse=177.778791 step=0.100000
2017/08/28 22:26:11 step 3: mse=175.885707 step=0.100000
2017/08/28 22:26:12 step 4: mse=174.337992 step=0.100000
2017/08/28 22:26:13 step 5: mse=172.603106 step=0.100000
2017/08/28 22:26:14 step 6: mse=171.208028 step=0.100000
2017/08/28 22:26:15 step 7: mse=170.273454 step=0.100000
2017/08/28 22:26:15 Saving...
2017/08/28 22:26:15 Gathering batch of experience...
2017/08/28 22:27:01 batch 693: mean=132.651163 stddev=110.612015 entropy=0.351813 frames=5614 count=43
2017/08/28 22:27:01 Training policy...
2017/08/28 22:27:05 step 0: objective=0.7899216
2017/08/28 22:27:07 step 1: objective=0.796465
2017/08/28 22:27:09 step 2: objective=0.8049445
2017/08/28 22:27:10 step 3: objective=0.8153736
2017/08/28 22:27:12 step 4: objective=0.8191078
2017/08/28 22:27:14 step 5: objective=0.82422894
2017/08/28 22:27:15 step 6: objective=0.8275437
2017/08/28 22:27:17 step 7: objective=0.83033603
2017/08/28 22:27:17 Training value function...
2017/08/28 22:27:19 step 0: mse=143.048966 step=0.100000
2017/08/28 22:27:20 step 1: mse=141.254192 step=0.100000
2017/08/28 22:27:22 step 2: mse=139.739914 step=0.100000
2017/08/28 22:27:23 step 3: mse=138.835491 step=0.100000
2017/08/28 22:27:24 step 4: mse=137.246752 step=0.100000
2017/08/28 22:27:25 step 5: mse=136.091173 step=0.100000
2017/08/28 22:27:26 step 6: mse=135.103400 step=0.100000
2017/08/28 22:27:28 step 7: mse=134.013494 step=0.100000
2017/08/28 22:27:28 Saving...
2017/08/28 22:27:28 Gathering batch of experience...
2017/08/28 22:28:13 batch 694: mean=156.763158 stddev=142.538348 entropy=0.353683 frames=5536 count=38
2017/08/28 22:28:13 Training policy...
2017/08/28 22:28:17 step 0: objective=1.9368911
2017/08/28 22:28:19 step 1: objective=1.9458084
2017/08/28 22:28:20 step 2: objective=1.9559035
2017/08/28 22:28:22 step 3: objective=1.9594525
2017/08/28 22:28:24 step 4: objective=1.9655441
2017/08/28 22:28:25 step 5: objective=1.9709895
2017/08/28 22:28:27 step 6: objective=1.9747087
2017/08/28 22:28:29 step 7: objective=1.979244
2017/08/28 22:28:29 Training value function...
2017/08/28 22:28:31 step 0: mse=191.709396 step=0.100000
2017/08/28 22:28:32 step 1: mse=187.785540 step=0.100000
2017/08/28 22:28:33 step 2: mse=184.399690 step=0.100000
2017/08/28 22:28:34 step 3: mse=181.004254 step=0.100000
2017/08/28 22:28:36 step 4: mse=178.425707 step=0.100000
2017/08/28 22:28:37 step 5: mse=176.162730 step=0.100000
2017/08/28 22:28:38 step 6: mse=174.313709 step=0.100000
2017/08/28 22:28:39 step 7: mse=172.608031 step=0.100000
2017/08/28 22:28:39 Saving...
2017/08/28 22:28:39 Gathering batch of experience...
2017/08/28 22:29:25 batch 695: mean=155.918919 stddev=130.872411 entropy=0.350700 frames=5546 count=37
2017/08/28 22:29:25 Training policy...
2017/08/28 22:29:29 step 0: objective=1.0657102
2017/08/28 22:29:31 step 1: objective=1.0717982
2017/08/28 22:29:32 step 2: objective=1.0821532
2017/08/28 22:29:34 step 3: objective=1.0914303
2017/08/28 22:29:36 step 4: objective=1.0971309
2017/08/28 22:29:37 step 5: objective=1.1035738
2017/08/28 22:29:39 step 6: objective=1.1108792
2017/08/28 22:29:41 step 7: objective=1.1131784
2017/08/28 22:29:41 Training value function...
2017/08/28 22:29:43 step 0: mse=179.969110 step=0.100000
2017/08/28 22:29:44 step 1: mse=177.750746 step=0.100000
2017/08/28 22:29:45 step 2: mse=175.932315 step=0.100000
2017/08/28 22:29:46 step 3: mse=173.881738 step=0.100000
2017/08/28 22:29:48 step 4: mse=172.022766 step=0.100000
2017/08/28 22:29:49 step 5: mse=170.339550 step=0.100000
2017/08/28 22:29:50 step 6: mse=169.047574 step=0.100000
2017/08/28 22:29:51 step 7: mse=168.274157 step=0.100000
2017/08/28 22:29:51 Saving...
2017/08/28 22:29:51 Gathering batch of experience...
2017/08/28 22:30:44 batch 696: mean=139.765957 stddev=118.204513 entropy=0.348839 frames=6186 count=47
2017/08/28 22:30:44 Training policy...
2017/08/28 22:30:48 step 0: objective=0.92596364
2017/08/28 22:30:50 step 1: objective=0.9353595
2017/08/28 22:30:52 step 2: objective=0.94144356
2017/08/28 22:30:54 step 3: objective=0.94909805
2017/08/28 22:30:56 step 4: objective=0.95552486
2017/08/28 22:30:58 step 5: objective=0.9604691
2017/08/28 22:30:59 step 6: objective=0.9638452
2017/08/28 22:31:01 step 7: objective=0.9667514
2017/08/28 22:31:01 Training value function...
2017/08/28 22:31:04 step 0: mse=174.370255 step=0.100000
2017/08/28 22:31:05 step 1: mse=172.534138 step=0.100000
2017/08/28 22:31:06 step 2: mse=170.520274 step=0.100000
2017/08/28 22:31:08 step 3: mse=168.390188 step=0.100000
2017/08/28 22:31:09 step 4: mse=166.848566 step=0.100000
2017/08/28 22:31:10 step 5: mse=165.487884 step=0.100000
2017/08/28 22:31:12 step 6: mse=164.567350 step=0.100000
2017/08/28 22:31:13 step 7: mse=163.693068 step=0.100000
2017/08/28 22:31:13 Saving...
2017/08/28 22:31:13 Gathering batch of experience...
2017/08/28 22:31:59 batch 697: mean=164.263158 stddev=165.917177 entropy=0.351935 frames=5669 count=38
2017/08/28 22:31:59 Training policy...
2017/08/28 22:32:03 step 0: objective=1.8791459
2017/08/28 22:32:05 step 1: objective=1.8872106
2017/08/28 22:32:07 step 2: objective=1.894135
2017/08/28 22:32:09 step 3: objective=1.8979772
2017/08/28 22:32:10 step 4: objective=1.9076207
2017/08/28 22:32:12 step 5: objective=1.911256
2017/08/28 22:32:14 step 6: objective=1.9167477
2017/08/28 22:32:15 step 7: objective=1.9222869
2017/08/28 22:32:15 Training value function...
2017/08/28 22:32:18 step 0: mse=208.216387 step=0.100000
2017/08/28 22:32:19 step 1: mse=202.922103 step=0.100000
2017/08/28 22:32:20 step 2: mse=197.775120 step=0.100000
2017/08/28 22:32:21 step 3: mse=193.443074 step=0.100000
2017/08/28 22:32:22 step 4: mse=190.239329 step=0.100000
2017/08/28 22:32:24 step 5: mse=187.019032 step=0.100000
2017/08/28 22:32:25 step 6: mse=184.047666 step=0.100000
2017/08/28 22:32:26 step 7: mse=181.567214 step=0.100000
2017/08/28 22:32:26 Saving...
2017/08/28 22:32:26 Gathering batch of experience...
2017/08/28 22:33:08 batch 698: mean=193.562500 stddev=116.337585 entropy=0.350132 frames=5562 count=32
2017/08/28 22:33:08 Training policy...
2017/08/28 22:33:12 step 0: objective=1.8876356
2017/08/28 22:33:14 step 1: objective=1.8966148
2017/08/28 22:33:16 step 2: objective=1.9020516
2017/08/28 22:33:17 step 3: objective=1.9067119
2017/08/28 22:33:19 step 4: objective=1.9101077
2017/08/28 22:33:21 step 5: objective=1.9159342
2017/08/28 22:33:22 step 6: objective=1.9198532
2017/08/28 22:33:24 step 7: objective=1.9222285
2017/08/28 22:33:24 Training value function...
2017/08/28 22:33:26 step 0: mse=182.033075 step=0.100000
2017/08/28 22:33:28 step 1: mse=176.462806 step=0.100000
2017/08/28 22:33:29 step 2: mse=172.311916 step=0.100000
2017/08/28 22:33:30 step 3: mse=168.599573 step=0.100000
2017/08/28 22:33:31 step 4: mse=165.321626 step=0.100000
2017/08/28 22:33:32 step 5: mse=162.428670 step=0.100000
2017/08/28 22:33:33 step 6: mse=159.956792 step=0.100000
2017/08/28 22:33:35 step 7: mse=157.709330 step=0.100000
2017/08/28 22:33:35 Saving...
2017/08/28 22:33:35 Gathering batch of experience...
2017/08/28 22:34:21 batch 699: mean=122.042553 stddev=116.951883 entropy=0.357303 frames=5724 count=47
2017/08/28 22:34:21 Training policy...
2017/08/28 22:34:26 step 0: objective=-0.56292444
2017/08/28 22:34:28 step 1: objective=-0.5528123
2017/08/28 22:34:29 step 2: objective=-0.54487246
2017/08/28 22:34:31 step 3: objective=-0.53736633
2017/08/28 22:34:33 step 4: objective=-0.5322043
2017/08/28 22:34:34 step 5: objective=-0.5295351
2017/08/28 22:34:36 step 6: objective=-0.5270112
2017/08/28 22:34:38 step 7: objective=-0.5224417
2017/08/28 22:34:38 Training value function...
2017/08/28 22:34:40 step 0: mse=152.166878 step=0.100000
2017/08/28 22:34:41 step 1: mse=148.587024 step=0.100000
2017/08/28 22:34:43 step 2: mse=145.839565 step=0.100000
2017/08/28 22:34:44 step 3: mse=143.586109 step=0.100000
2017/08/28 22:34:45 step 4: mse=141.655754 step=0.100000
2017/08/28 22:34:46 step 5: mse=140.355942 step=0.100000
2017/08/28 22:34:47 step 6: mse=138.985401 step=0.100000
2017/08/28 22:34:49 step 7: mse=138.007438 step=0.100000
2017/08/28 22:34:49 Saving...
2017/08/28 22:34:49 Gathering batch of experience...
2017/08/28 22:35:37 batch 700: mean=166.810811 stddev=153.971187 entropy=0.355958 frames=5992 count=37
2017/08/28 22:35:37 Training policy...
2017/08/28 22:35:41 step 0: objective=1.2616324
2017/08/28 22:35:43 step 1: objective=1.2676475
2017/08/28 22:35:45 step 2: objective=1.2720838
2017/08/28 22:35:47 step 3: objective=1.2761728
2017/08/28 22:35:48 step 4: objective=1.2800088
2017/08/28 22:35:50 step 5: objective=1.2840801
2017/08/28 22:35:52 step 6: objective=1.2883353
2017/08/28 22:35:54 step 7: objective=1.2934403
2017/08/28 22:35:54 Training value function...
2017/08/28 22:35:56 step 0: mse=156.073734 step=0.100000
2017/08/28 22:35:57 step 1: mse=152.530519 step=0.100000
2017/08/28 22:35:59 step 2: mse=149.842456 step=0.100000
2017/08/28 22:36:00 step 3: mse=147.372839 step=0.100000
2017/08/28 22:36:01 step 4: mse=145.319202 step=0.100000
2017/08/28 22:36:03 step 5: mse=143.333102 step=0.100000
2017/08/28 22:36:04 step 6: mse=141.704880 step=0.100000
2017/08/28 22:36:05 step 7: mse=139.996816 step=0.100000
2017/08/28 22:36:05 Saving...
2017/08/28 22:36:05 Gathering batch of experience...
2017/08/28 22:36:49 batch 701: mean=161.421053 stddev=128.691723 entropy=0.350555 frames=5637 count=38
2017/08/28 22:36:49 Training policy...
2017/08/28 22:36:53 step 0: objective=1.6541269
2017/08/28 22:36:55 step 1: objective=1.6588467
2017/08/28 22:36:57 step 2: objective=1.6655841
2017/08/28 22:36:59 step 3: objective=1.669746
2017/08/28 22:37:00 step 4: objective=1.6741163
2017/08/28 22:37:02 step 5: objective=1.6772989
2017/08/28 22:37:04 step 6: objective=1.6814915
2017/08/28 22:37:05 step 7: objective=1.6864822
2017/08/28 22:37:05 Training value function...
2017/08/28 22:37:08 step 0: mse=172.435847 step=0.100000
2017/08/28 22:37:09 step 1: mse=168.575730 step=0.100000
2017/08/28 22:37:10 step 2: mse=165.167815 step=0.100000
2017/08/28 22:37:11 step 3: mse=161.941860 step=0.100000
2017/08/28 22:37:13 step 4: mse=159.241639 step=0.100000
2017/08/28 22:37:14 step 5: mse=156.691000 step=0.100000
2017/08/28 22:37:15 step 6: mse=154.951900 step=0.100000
2017/08/28 22:37:16 step 7: mse=153.115842 step=0.100000
2017/08/28 22:37:16 Saving...
2017/08/28 22:37:16 Gathering batch of experience...
2017/08/28 22:38:00 batch 702: mean=136.380952 stddev=129.734335 entropy=0.349750 frames=5362 count=42
2017/08/28 22:38:00 Training policy...
2017/08/28 22:38:04 step 0: objective=0.84419376
2017/08/28 22:38:06 step 1: objective=0.8553231
2017/08/28 22:38:07 step 2: objective=0.8643518
2017/08/28 22:38:09 step 3: objective=0.8718839
2017/08/28 22:38:11 step 4: objective=0.88289726
2017/08/28 22:38:12 step 5: objective=0.8860321
2017/08/28 22:38:14 step 6: objective=0.89240754
2017/08/28 22:38:15 step 7: objective=0.89715827
2017/08/28 22:38:15 Training value function...
2017/08/28 22:38:18 step 0: mse=192.965433 step=0.100000
2017/08/28 22:38:19 step 1: mse=190.016928 step=0.100000
2017/08/28 22:38:20 step 2: mse=187.307176 step=0.100000
2017/08/28 22:38:21 step 3: mse=185.214155 step=0.100000
2017/08/28 22:38:22 step 4: mse=183.059737 step=0.100000
2017/08/28 22:38:23 step 5: mse=181.078491 step=0.100000
2017/08/28 22:38:24 step 6: mse=179.432363 step=0.100000
2017/08/28 22:38:25 step 7: mse=177.787225 step=0.100000
2017/08/28 22:38:25 Saving...
2017/08/28 22:38:26 Gathering batch of experience...
2017/08/28 22:39:13 batch 703: mean=150.175000 stddev=127.515859 entropy=0.349918 frames=5686 count=40
2017/08/28 22:39:13 Training policy...
2017/08/28 22:39:17 step 0: objective=0.9470166
2017/08/28 22:39:19 step 1: objective=0.9551239
2017/08/28 22:39:21 step 2: objective=0.96064466
2017/08/28 22:39:22 step 3: objective=0.96457314
2017/08/28 22:39:24 step 4: objective=0.96856076
2017/08/28 22:39:26 step 5: objective=0.97381324
2017/08/28 22:39:27 step 6: objective=0.9763752
2017/08/28 22:39:29 step 7: objective=0.9788139
2017/08/28 22:39:29 Training value function...
2017/08/28 22:39:32 step 0: mse=162.158846 step=0.100000
2017/08/28 22:39:33 step 1: mse=160.417581 step=0.100000
2017/08/28 22:39:34 step 2: mse=158.909968 step=0.100000
2017/08/28 22:39:35 step 3: mse=157.424059 step=0.100000
2017/08/28 22:39:36 step 4: mse=156.247414 step=0.100000
2017/08/28 22:39:37 step 5: mse=155.178069 step=0.100000
2017/08/28 22:39:39 step 6: mse=153.681743 step=0.100000
2017/08/28 22:39:40 step 7: mse=152.644253 step=0.100000
2017/08/28 22:39:40 Saving...
2017/08/28 22:39:40 Gathering batch of experience...
2017/08/28 22:40:23 batch 704: mean=189.843750 stddev=163.424698 entropy=0.361096 frames=5679 count=32
2017/08/28 22:40:23 Training policy...
2017/08/28 22:40:27 step 0: objective=1.7541953
2017/08/28 22:40:29 step 1: objective=1.7650989
2017/08/28 22:40:31 step 2: objective=1.7697202
2017/08/28 22:40:33 step 3: objective=1.7772703
2017/08/28 22:40:34 step 4: objective=1.7819321
2017/08/28 22:40:36 step 5: objective=1.7886608
2017/08/28 22:40:38 step 6: objective=1.7930532
2017/08/28 22:40:40 step 7: objective=1.7972854
2017/08/28 22:40:40 Training value function...
2017/08/28 22:40:42 step 0: mse=188.415758 step=0.100000
2017/08/28 22:40:43 step 1: mse=184.646100 step=0.100000
2017/08/28 22:40:44 step 2: mse=181.314170 step=0.100000
2017/08/28 22:40:46 step 3: mse=178.202756 step=0.100000
2017/08/28 22:40:47 step 4: mse=175.305507 step=0.100000
2017/08/28 22:40:48 step 5: mse=172.597643 step=0.100000
2017/08/28 22:40:49 step 6: mse=170.099157 step=0.100000
2017/08/28 22:40:50 step 7: mse=168.206024 step=0.100000
2017/08/28 22:40:50 Saving...
2017/08/28 22:40:50 Gathering batch of experience...
2017/08/28 22:41:35 batch 705: mean=130.090909 stddev=120.652171 entropy=0.348591 frames=5480 count=44
2017/08/28 22:41:35 Training policy...
2017/08/28 22:41:39 step 0: objective=0.33278516
2017/08/28 22:41:41 step 1: objective=0.34398815
2017/08/28 22:41:43 step 2: objective=0.35537112
2017/08/28 22:41:45 step 3: objective=0.36168388
2017/08/28 22:41:46 step 4: objective=0.36692622
2017/08/28 22:41:48 step 5: objective=0.37360606
2017/08/28 22:41:50 step 6: objective=0.37637758
2017/08/28 22:41:51 step 7: objective=0.37998447
2017/08/28 22:41:51 Training value function...
2017/08/28 22:41:53 step 0: mse=198.188933 step=0.100000
2017/08/28 22:41:55 step 1: mse=194.054454 step=0.100000
2017/08/28 22:41:56 step 2: mse=190.819970 step=0.100000
2017/08/28 22:41:57 step 3: mse=187.964879 step=0.100000
2017/08/28 22:41:58 step 4: mse=185.838070 step=0.100000
2017/08/28 22:41:59 step 5: mse=184.063099 step=0.100000
2017/08/28 22:42:00 step 6: mse=182.676756 step=0.100000
2017/08/28 22:42:02 step 7: mse=181.131507 step=0.100000
2017/08/28 22:42:02 Saving...
2017/08/28 22:42:02 Gathering batch of experience...
2017/08/28 22:42:46 batch 706: mean=159.736842 stddev=101.605969 entropy=0.347614 frames=5736 count=38
2017/08/28 22:42:46 Training policy...
2017/08/28 22:42:50 step 0: objective=0.9863196
2017/08/28 22:42:52 step 1: objective=0.9933354
2017/08/28 22:42:54 step 2: objective=1.0019604
2017/08/28 22:42:56 step 3: objective=1.0072848
2017/08/28 22:42:57 step 4: objective=1.0112038
2017/08/28 22:42:59 step 5: objective=1.01496
2017/08/28 22:43:01 step 6: objective=1.0217302
2017/08/28 22:43:03 step 7: objective=1.0246239
2017/08/28 22:43:03 Training value function...
2017/08/28 22:43:05 step 0: mse=163.076284 step=0.100000
2017/08/28 22:43:06 step 1: mse=158.043845 step=0.100000
2017/08/28 22:43:07 step 2: mse=153.759030 step=0.100000
2017/08/28 22:43:09 step 3: mse=150.434059 step=0.100000
2017/08/28 22:43:10 step 4: mse=147.630220 step=0.100000
2017/08/28 22:43:11 step 5: mse=145.268814 step=0.100000
2017/08/28 22:43:12 step 6: mse=143.407064 step=0.100000
2017/08/28 22:43:13 step 7: mse=141.582965 step=0.100000
2017/08/28 22:43:13 Saving...
2017/08/28 22:43:13 Gathering batch of experience...
2017/08/28 22:43:58 batch 707: mean=176.000000 stddev=130.187258 entropy=0.347214 frames=5643 count=36
2017/08/28 22:43:58 Training policy...
2017/08/28 22:44:02 step 0: objective=2.0968041
2017/08/28 22:44:04 step 1: objective=2.1021342
2017/08/28 22:44:06 step 2: objective=2.1086485
2017/08/28 22:44:08 step 3: objective=2.1147425
2017/08/28 22:44:09 step 4: objective=2.1189132
2017/08/28 22:44:11 step 5: objective=2.1248488
2017/08/28 22:44:13 step 6: objective=2.130979
2017/08/28 22:44:14 step 7: objective=2.1355157
2017/08/28 22:44:14 Training value function...
2017/08/28 22:44:17 step 0: mse=188.137212 step=0.100000
2017/08/28 22:44:18 step 1: mse=182.168847 step=0.100000
2017/08/28 22:44:19 step 2: mse=177.120405 step=0.100000
2017/08/28 22:44:20 step 3: mse=173.168172 step=0.100000
2017/08/28 22:44:22 step 4: mse=169.454497 step=0.100000
2017/08/28 22:44:23 step 5: mse=166.567398 step=0.100000
2017/08/28 22:44:24 step 6: mse=163.894407 step=0.100000
2017/08/28 22:44:25 step 7: mse=161.258691 step=0.100000
2017/08/28 22:44:25 Saving...
2017/08/28 22:44:25 Gathering batch of experience...
2017/08/28 22:45:06 batch 708: mean=153.028571 stddev=112.649516 entropy=0.345334 frames=5051 count=35
2017/08/28 22:45:06 Training policy...
2017/08/28 22:45:10 step 0: objective=0.45996255
2017/08/28 22:45:12 step 1: objective=0.46565202
2017/08/28 22:45:13 step 2: objective=0.47166812
2017/08/28 22:45:15 step 3: objective=0.47615296
2017/08/28 22:45:16 step 4: objective=0.47992033
2017/08/28 22:45:18 step 5: objective=0.48663777
2017/08/28 22:45:19 step 6: objective=0.4932908
2017/08/28 22:45:21 step 7: objective=0.49893078
2017/08/28 22:45:21 Training value function...
2017/08/28 22:45:23 step 0: mse=142.731046 step=0.100000
2017/08/28 22:45:24 step 1: mse=140.474946 step=0.100000
2017/08/28 22:45:25 step 2: mse=138.695384 step=0.100000
2017/08/28 22:45:26 step 3: mse=137.281348 step=0.100000
2017/08/28 22:45:27 step 4: mse=136.107392 step=0.100000
2017/08/28 22:45:28 step 5: mse=135.057284 step=0.100000
2017/08/28 22:45:29 step 6: mse=134.302933 step=0.100000
2017/08/28 22:45:30 step 7: mse=133.388582 step=0.100000
2017/08/28 22:45:30 Saving...
2017/08/28 22:45:30 Gathering batch of experience...
2017/08/28 22:46:16 batch 709: mean=181.542857 stddev=132.299518 entropy=0.349564 frames=6077 count=35
2017/08/28 22:46:16 Training policy...
2017/08/28 22:46:21 step 0: objective=1.2325256
2017/08/28 22:46:23 step 1: objective=1.2422782
2017/08/28 22:46:24 step 2: objective=1.2533904
2017/08/28 22:46:26 step 3: objective=1.2612407
2017/08/28 22:46:28 step 4: objective=1.2650996
2017/08/28 22:46:30 step 5: objective=1.2691821
2017/08/28 22:46:32 step 6: objective=1.2725608
2017/08/28 22:46:34 step 7: objective=1.2749821
2017/08/28 22:46:34 Training value function...
2017/08/28 22:46:36 step 0: mse=171.432314 step=0.100000
2017/08/28 22:46:37 step 1: mse=168.758205 step=0.100000
2017/08/28 22:46:39 step 2: mse=166.309849 step=0.100000
2017/08/28 22:46:40 step 3: mse=164.133345 step=0.100000
2017/08/28 22:46:41 step 4: mse=162.543864 step=0.100000
2017/08/28 22:46:43 step 5: mse=160.848316 step=0.100000
2017/08/28 22:46:44 step 6: mse=159.288165 step=0.100000
2017/08/28 22:46:45 step 7: mse=157.957131 step=0.100000
2017/08/28 22:46:45 Saving...
2017/08/28 22:46:45 Gathering batch of experience...
2017/08/28 22:47:32 batch 710: mean=159.538462 stddev=103.545072 entropy=0.344785 frames=5885 count=39
2017/08/28 22:47:32 Training policy...
2017/08/28 22:47:36 step 0: objective=0.61794764
2017/08/28 22:47:38 step 1: objective=0.6237034
2017/08/28 22:47:40 step 2: objective=0.63372254
2017/08/28 22:47:41 step 3: objective=0.6373567
2017/08/28 22:47:43 step 4: objective=0.64313513
2017/08/28 22:47:45 step 5: objective=0.6478874
2017/08/28 22:47:47 step 6: objective=0.65136915
2017/08/28 22:47:49 step 7: objective=0.65445316
2017/08/28 22:47:49 Training value function...
2017/08/28 22:47:51 step 0: mse=145.894917 step=0.100000
2017/08/28 22:47:52 step 1: mse=142.097318 step=0.100000
2017/08/28 22:47:54 step 2: mse=138.559307 step=0.100000
2017/08/28 22:47:55 step 3: mse=135.693046 step=0.100000
2017/08/28 22:47:56 step 4: mse=134.048229 step=0.100000
2017/08/28 22:47:57 step 5: mse=132.227822 step=0.100000
2017/08/28 22:47:58 step 6: mse=130.535158 step=0.100000
2017/08/28 22:48:00 step 7: mse=129.044072 step=0.100000
2017/08/28 22:48:00 Saving...
2017/08/28 22:48:00 Gathering batch of experience...
2017/08/28 22:48:45 batch 711: mean=151.717949 stddev=119.269346 entropy=0.344607 frames=5605 count=39
2017/08/28 22:48:45 Training policy...
2017/08/28 22:48:49 step 0: objective=0.8764483
2017/08/28 22:48:51 step 1: objective=0.88807034
2017/08/28 22:48:52 step 2: objective=0.8934559
2017/08/28 22:48:54 step 3: objective=0.8992366
2017/08/28 22:48:56 step 4: objective=0.90327233
2017/08/28 22:48:57 step 5: objective=0.9076541
2017/08/28 22:48:59 step 6: objective=0.91238517
2017/08/28 22:49:01 step 7: objective=0.91648257
2017/08/28 22:49:01 Training value function...
2017/08/28 22:49:03 step 0: mse=191.291593 step=0.100000
2017/08/28 22:49:04 step 1: mse=187.932634 step=0.100000
2017/08/28 22:49:05 step 2: mse=185.236734 step=0.100000
2017/08/28 22:49:07 step 3: mse=182.748495 step=0.100000
2017/08/28 22:49:08 step 4: mse=180.713731 step=0.100000
2017/08/28 22:49:09 step 5: mse=178.971217 step=0.100000
2017/08/28 22:49:10 step 6: mse=177.555256 step=0.100000
2017/08/28 22:49:11 step 7: mse=176.403257 step=0.100000
2017/08/28 22:49:11 Saving...
2017/08/28 22:49:11 Gathering batch of experience...
2017/08/28 22:50:00 batch 712: mean=107.780000 stddev=96.834145 entropy=0.342447 frames=5120 count=50
2017/08/28 22:50:00 Training policy...
2017/08/28 22:50:04 step 0: objective=-0.14523698
2017/08/28 22:50:05 step 1: objective=-0.1368511
2017/08/28 22:50:07 step 2: objective=-0.12449101
2017/08/28 22:50:08 step 3: objective=-0.11717466
2017/08/28 22:50:10 step 4: objective=-0.11222496
2017/08/28 22:50:11 step 5: objective=-0.10778676
2017/08/28 22:50:13 step 6: objective=-0.10459341
2017/08/28 22:50:14 step 7: objective=-0.09758805
2017/08/28 22:50:14 Training value function...
2017/08/28 22:50:17 step 0: mse=176.578234 step=0.100000
2017/08/28 22:50:18 step 1: mse=171.460048 step=0.100000
2017/08/28 22:50:19 step 2: mse=167.558170 step=0.100000
2017/08/28 22:50:20 step 3: mse=164.418802 step=0.100000
2017/08/28 22:50:21 step 4: mse=161.483514 step=0.100000
2017/08/28 22:50:22 step 5: mse=159.510966 step=0.100000
2017/08/28 22:50:23 step 6: mse=157.774964 step=0.100000
2017/08/28 22:50:24 step 7: mse=156.207167 step=0.100000
2017/08/28 22:50:24 Saving...
2017/08/28 22:50:24 Gathering batch of experience...
2017/08/28 22:51:15 batch 713: mean=155.477273 stddev=140.409222 entropy=0.355967 frames=6299 count=44
2017/08/28 22:51:15 Training policy...
2017/08/28 22:51:19 step 0: objective=1.5916322
2017/08/28 22:51:21 step 1: objective=1.599797
2017/08/28 22:51:23 step 2: objective=1.6095406
2017/08/28 22:51:25 step 3: objective=1.6160535
2017/08/28 22:51:27 step 4: objective=1.6238816
2017/08/28 22:51:29 step 5: objective=1.6285363
2017/08/28 22:51:31 step 6: objective=1.6327676
2017/08/28 22:51:33 step 7: objective=1.6381395
2017/08/28 22:51:33 Training value function...
2017/08/28 22:51:35 step 0: mse=208.778320 step=0.100000
2017/08/28 22:51:37 step 1: mse=200.387640 step=0.100000
2017/08/28 22:51:38 step 2: mse=192.975929 step=0.100000
2017/08/28 22:51:39 step 3: mse=186.523705 step=0.100000
2017/08/28 22:51:41 step 4: mse=181.015538 step=0.100000
2017/08/28 22:51:42 step 5: mse=176.518424 step=0.100000
2017/08/28 22:51:43 step 6: mse=172.433982 step=0.100000
2017/08/28 22:51:45 step 7: mse=169.143423 step=0.100000
2017/08/28 22:51:45 Saving...
2017/08/28 22:51:45 Gathering batch of experience...
2017/08/28 22:52:37 batch 714: mean=157.904762 stddev=153.725762 entropy=0.352814 frames=6251 count=42
2017/08/28 22:52:37 Training policy...
2017/08/28 22:52:41 step 0: objective=1.1202431
2017/08/28 22:52:43 step 1: objective=1.1290325
2017/08/28 22:52:45 step 2: objective=1.1383226
2017/08/28 22:52:47 step 3: objective=1.143622
2017/08/28 22:52:49 step 4: objective=1.14704
2017/08/28 22:52:51 step 5: objective=1.1503183
2017/08/28 22:52:53 step 6: objective=1.1539161
2017/08/28 22:52:55 step 7: objective=1.1561925
2017/08/28 22:52:55 Training value function...
2017/08/28 22:52:57 step 0: mse=182.404085 step=0.100000
2017/08/28 22:52:59 step 1: mse=178.846627 step=0.100000
2017/08/28 22:53:00 step 2: mse=175.858608 step=0.100000
2017/08/28 22:53:01 step 3: mse=174.334135 step=0.100000
2017/08/28 22:53:03 step 4: mse=172.432195 step=0.100000
2017/08/28 22:53:04 step 5: mse=170.375662 step=0.100000
2017/08/28 22:53:05 step 6: mse=168.517096 step=0.100000
2017/08/28 22:53:07 step 7: mse=166.773543 step=0.100000
2017/08/28 22:53:07 Saving...
2017/08/28 22:53:07 Gathering batch of experience...
2017/08/28 22:53:53 batch 715: mean=155.102564 stddev=167.690006 entropy=0.367728 frames=6129 count=39
2017/08/28 22:53:53 Training policy...
2017/08/28 22:53:57 step 0: objective=0.45292288
2017/08/28 22:53:59 step 1: objective=0.45799193
2017/08/28 22:54:01 step 2: objective=0.46506602
2017/08/28 22:54:03 step 3: objective=0.4683318
2017/08/28 22:54:05 step 4: objective=0.47280273
2017/08/28 22:54:07 step 5: objective=0.47609407
2017/08/28 22:54:08 step 6: objective=0.48110437
2017/08/28 22:54:10 step 7: objective=0.48429468
2017/08/28 22:54:10 Training value function...
2017/08/28 22:54:13 step 0: mse=145.136341 step=0.100000
2017/08/28 22:54:14 step 1: mse=140.024690 step=0.100000
2017/08/28 22:54:15 step 2: mse=135.443988 step=0.100000
2017/08/28 22:54:17 step 3: mse=132.064556 step=0.100000
2017/08/28 22:54:18 step 4: mse=129.377440 step=0.100000
2017/08/28 22:54:19 step 5: mse=126.708158 step=0.100000
2017/08/28 22:54:21 step 6: mse=124.804234 step=0.100000
2017/08/28 22:54:22 step 7: mse=123.382207 step=0.100000
2017/08/28 22:54:22 Saving...
2017/08/28 22:54:22 Gathering batch of experience...
2017/08/28 22:55:11 batch 716: mean=192.828571 stddev=187.756603 entropy=0.360831 frames=6549 count=35
2017/08/28 22:55:11 Training policy...
2017/08/28 22:55:16 step 0: objective=1.6474407
2017/08/28 22:55:18 step 1: objective=1.653539
2017/08/28 22:55:20 step 2: objective=1.6574032
2017/08/28 22:55:22 step 3: objective=1.6615322
2017/08/28 22:55:24 step 4: objective=1.6649694
2017/08/28 22:55:26 step 5: objective=1.6709529
2017/08/28 22:55:28 step 6: objective=1.6747144
2017/08/28 22:55:30 step 7: objective=1.6784691
2017/08/28 22:55:30 Training value function...
2017/08/28 22:55:33 step 0: mse=176.820714 step=0.100000
2017/08/28 22:55:34 step 1: mse=170.497032 step=0.100000
2017/08/28 22:55:36 step 2: mse=165.555347 step=0.100000
2017/08/28 22:55:37 step 3: mse=161.306253 step=0.100000
2017/08/28 22:55:39 step 4: mse=157.678342 step=0.100000
2017/08/28 22:55:40 step 5: mse=154.493113 step=0.100000
2017/08/28 22:55:41 step 6: mse=152.024978 step=0.100000
2017/08/28 22:55:43 step 7: mse=149.499161 step=0.100000
2017/08/28 22:55:43 Saving...
2017/08/28 22:55:43 Gathering batch of experience...
2017/08/28 22:56:31 batch 717: mean=200.500000 stddev=175.022562 entropy=0.354757 frames=6672 count=34
2017/08/28 22:56:31 Training policy...
2017/08/28 22:56:36 step 0: objective=1.2239166
2017/08/28 22:56:38 step 1: objective=1.2282629
2017/08/28 22:56:40 step 2: objective=1.2352878
2017/08/28 22:56:42 step 3: objective=1.2392006
2017/08/28 22:56:44 step 4: objective=1.2422807
2017/08/28 22:56:46 step 5: objective=1.2457007
2017/08/28 22:56:48 step 6: objective=1.2492977
2017/08/28 22:56:50 step 7: objective=1.2550297
2017/08/28 22:56:50 Training value function...
2017/08/28 22:56:53 step 0: mse=161.332290 step=0.100000
2017/08/28 22:56:54 step 1: mse=159.319188 step=0.100000
2017/08/28 22:56:56 step 2: mse=157.036743 step=0.100000
2017/08/28 22:56:57 step 3: mse=155.425246 step=0.100000
2017/08/28 22:56:58 step 4: mse=153.698253 step=0.100000
2017/08/28 22:57:00 step 5: mse=152.021859 step=0.100000
2017/08/28 22:57:01 step 6: mse=150.845723 step=0.100000
2017/08/28 22:57:03 step 7: mse=149.643604 step=0.100000
2017/08/28 22:57:03 Saving...
2017/08/28 22:57:03 Gathering batch of experience...
2017/08/28 22:57:48 batch 718: mean=183.781250 stddev=137.044640 entropy=0.352463 frames=5555 count=32
2017/08/28 22:57:48 Training policy...
2017/08/28 22:57:52 step 0: objective=1.2584028
2017/08/28 22:57:53 step 1: objective=1.2645546
2017/08/28 22:57:55 step 2: objective=1.2738895
2017/08/28 22:57:57 step 3: objective=1.2797143
2017/08/28 22:57:58 step 4: objective=1.2872945
2017/08/28 22:58:00 step 5: objective=1.2915127
2017/08/28 22:58:02 step 6: objective=1.2959963
2017/08/28 22:58:04 step 7: objective=1.30148
2017/08/28 22:58:04 Training value function...
2017/08/28 22:58:06 step 0: mse=163.562760 step=0.100000
2017/08/28 22:58:07 step 1: mse=160.667286 step=0.100000
2017/08/28 22:58:08 step 2: mse=158.496984 step=0.100000
2017/08/28 22:58:09 step 3: mse=156.545210 step=0.100000
2017/08/28 22:58:11 step 4: mse=153.965603 step=0.100000
2017/08/28 22:58:12 step 5: mse=152.479577 step=0.100000
2017/08/28 22:58:13 step 6: mse=151.024831 step=0.100000
2017/08/28 22:58:14 step 7: mse=149.599806 step=0.100000
2017/08/28 22:58:14 Saving...
2017/08/28 22:58:14 Gathering batch of experience...
2017/08/28 22:58:56 batch 719: mean=152.676471 stddev=127.593500 entropy=0.356240 frames=5081 count=34
2017/08/28 22:58:56 Training policy...
2017/08/28 22:59:00 step 0: objective=0.4609259
2017/08/28 22:59:01 step 1: objective=0.46733725
2017/08/28 22:59:03 step 2: objective=0.47491676
2017/08/28 22:59:04 step 3: objective=0.4810034
2017/08/28 22:59:06 step 4: objective=0.48734948
2017/08/28 22:59:08 step 5: objective=0.49253097
2017/08/28 22:59:09 step 6: objective=0.4957943
2017/08/28 22:59:11 step 7: objective=0.50038195
2017/08/28 22:59:11 Training value function...
2017/08/28 22:59:13 step 0: mse=129.749632 step=0.100000
2017/08/28 22:59:14 step 1: mse=127.803764 step=0.100000
2017/08/28 22:59:15 step 2: mse=126.263139 step=0.100000
2017/08/28 22:59:16 step 3: mse=125.130369 step=0.100000
2017/08/28 22:59:17 step 4: mse=123.847522 step=0.100000
2017/08/28 22:59:18 step 5: mse=122.744783 step=0.100000
2017/08/28 22:59:19 step 6: mse=121.597948 step=0.100000
2017/08/28 22:59:20 step 7: mse=120.862794 step=0.100000
2017/08/28 22:59:20 Saving...
2017/08/28 22:59:20 Gathering batch of experience...
2017/08/28 23:00:08 batch 720: mean=148.697674 stddev=123.062951 entropy=0.345472 frames=6189 count=43
2017/08/28 23:00:08 Training policy...
2017/08/28 23:00:13 step 0: objective=0.5892981
2017/08/28 23:00:15 step 1: objective=0.5975116
2017/08/28 23:00:17 step 2: objective=0.6049741
2017/08/28 23:00:18 step 3: objective=0.6100025
2017/08/28 23:00:20 step 4: objective=0.6142199
2017/08/28 23:00:22 step 5: objective=0.6176474
2017/08/28 23:00:24 step 6: objective=0.62025815
2017/08/28 23:00:26 step 7: objective=0.6237434
2017/08/28 23:00:26 Training value function...
2017/08/28 23:00:29 step 0: mse=148.687089 step=0.100000
2017/08/28 23:00:30 step 1: mse=147.279405 step=0.100000
2017/08/28 23:00:31 step 2: mse=145.930166 step=0.100000
2017/08/28 23:00:33 step 3: mse=144.757559 step=0.100000
2017/08/28 23:00:34 step 4: mse=143.731600 step=0.100000
2017/08/28 23:00:35 step 5: mse=142.749130 step=0.100000
2017/08/28 23:00:36 step 6: mse=141.946934 step=0.100000
2017/08/28 23:00:38 step 7: mse=141.184384 step=0.100000
2017/08/28 23:00:38 Saving...
2017/08/28 23:00:38 Gathering batch of experience...
2017/08/28 23:01:25 batch 721: mean=179.882353 stddev=166.225708 entropy=0.356601 frames=5671 count=34
2017/08/28 23:01:25 Training policy...
2017/08/28 23:01:29 step 0: objective=1.9848895
2017/08/28 23:01:31 step 1: objective=1.9956342
2017/08/28 23:01:32 step 2: objective=2.0003638
2017/08/28 23:01:34 step 3: objective=2.0061853
2017/08/28 23:01:36 step 4: objective=2.011432
2017/08/28 23:01:38 step 5: objective=2.014619
2017/08/28 23:01:39 step 6: objective=2.0187447
2017/08/28 23:01:41 step 7: objective=2.022638
2017/08/28 23:01:41 Training value function...
2017/08/28 23:01:43 step 0: mse=201.068205 step=0.100000
2017/08/28 23:01:45 step 1: mse=193.106851 step=0.100000
2017/08/28 23:01:46 step 2: mse=186.017879 step=0.100000
2017/08/28 23:01:47 step 3: mse=180.374278 step=0.100000
2017/08/28 23:01:48 step 4: mse=175.294866 step=0.100000
2017/08/28 23:01:49 step 5: mse=171.078202 step=0.100000
2017/08/28 23:01:51 step 6: mse=167.705880 step=0.100000
2017/08/28 23:01:52 step 7: mse=164.684916 step=0.100000
2017/08/28 23:01:52 Saving...
2017/08/28 23:01:52 Gathering batch of experience...
2017/08/28 23:02:37 batch 722: mean=172.606061 stddev=137.213159 entropy=0.358116 frames=5656 count=33
2017/08/28 23:02:37 Training policy...
2017/08/28 23:02:41 step 0: objective=0.72449815
2017/08/28 23:02:43 step 1: objective=0.73153603
2017/08/28 23:02:44 step 2: objective=0.73863155
2017/08/28 23:02:46 step 3: objective=0.7425136
2017/08/28 23:02:48 step 4: objective=0.746266
2017/08/28 23:02:49 step 5: objective=0.7498523
2017/08/28 23:02:51 step 6: objective=0.7547244
2017/08/28 23:02:53 step 7: objective=0.7579846
2017/08/28 23:02:53 Training value function...
2017/08/28 23:02:55 step 0: mse=135.361519 step=0.100000
2017/08/28 23:02:57 step 1: mse=133.503942 step=0.100000
2017/08/28 23:02:58 step 2: mse=132.065519 step=0.100000
2017/08/28 23:02:59 step 3: mse=130.840262 step=0.100000
2017/08/28 23:03:00 step 4: mse=129.492363 step=0.100000
2017/08/28 23:03:01 step 5: mse=128.608594 step=0.100000
2017/08/28 23:03:02 step 6: mse=127.872374 step=0.100000
2017/08/28 23:03:04 step 7: mse=127.176340 step=0.100000
2017/08/28 23:03:04 Saving...
2017/08/28 23:03:04 Gathering batch of experience...
2017/08/28 23:03:54 batch 723: mean=163.243902 stddev=131.547410 entropy=0.348840 frames=6118 count=41
2017/08/28 23:03:54 Training policy...
2017/08/28 23:03:58 step 0: objective=1.5677816
2017/08/28 23:04:00 step 1: objective=1.5753516
2017/08/28 23:04:02 step 2: objective=1.5796677
2017/08/28 23:04:04 step 3: objective=1.5843074
2017/08/28 23:04:06 step 4: objective=1.5905758
2017/08/28 23:04:07 step 5: objective=1.5965022
2017/08/28 23:04:09 step 6: objective=1.6007946
2017/08/28 23:04:11 step 7: objective=1.603802
2017/08/28 23:04:11 Training value function...
2017/08/28 23:04:14 step 0: mse=162.731957 step=0.100000
2017/08/28 23:04:15 step 1: mse=160.148663 step=0.100000
2017/08/28 23:04:16 step 2: mse=157.702877 step=0.100000
2017/08/28 23:04:18 step 3: mse=155.432415 step=0.100000
2017/08/28 23:04:19 step 4: mse=153.429316 step=0.100000
2017/08/28 23:04:20 step 5: mse=151.777086 step=0.100000
2017/08/28 23:04:21 step 6: mse=150.039698 step=0.100000
2017/08/28 23:04:23 step 7: mse=148.454575 step=0.100000
2017/08/28 23:04:23 Saving...
2017/08/28 23:04:23 Gathering batch of experience...
2017/08/28 23:05:05 batch 724: mean=139.324324 stddev=120.567813 entropy=0.348848 frames=5280 count=37
2017/08/28 23:05:05 Training policy...
2017/08/28 23:05:09 step 0: objective=-0.32918808
2017/08/28 23:05:11 step 1: objective=-0.3175346
2017/08/28 23:05:13 step 2: objective=-0.31105354
2017/08/28 23:05:14 step 3: objective=-0.30528656
2017/08/28 23:05:16 step 4: objective=-0.2975827
2017/08/28 23:05:18 step 5: objective=-0.29261443
2017/08/28 23:05:19 step 6: objective=-0.28874642
2017/08/28 23:05:21 step 7: objective=-0.28645834
2017/08/28 23:05:21 Training value function...
2017/08/28 23:05:23 step 0: mse=143.777409 step=0.100000
2017/08/28 23:05:24 step 1: mse=141.726094 step=0.100000
2017/08/28 23:05:25 step 2: mse=140.489204 step=0.100000
2017/08/28 23:05:26 step 3: mse=139.204330 step=0.100000
2017/08/28 23:05:27 step 4: mse=138.327946 step=0.100000
2017/08/28 23:05:29 step 5: mse=137.694492 step=0.100000
2017/08/28 23:05:30 step 6: mse=137.237080 step=0.100000
2017/08/28 23:05:31 step 7: mse=136.368211 step=0.100000
2017/08/28 23:05:31 Saving...
2017/08/28 23:05:31 Gathering batch of experience...
2017/08/28 23:06:13 batch 725: mean=173.294118 stddev=137.275706 entropy=0.358654 frames=5434 count=34
2017/08/28 23:06:13 Training policy...
2017/08/28 23:06:17 step 0: objective=2.0086532
2017/08/28 23:06:19 step 1: objective=2.0180287
2017/08/28 23:06:21 step 2: objective=2.025772
2017/08/28 23:06:22 step 3: objective=2.0323706
2017/08/28 23:06:24 step 4: objective=2.0364833
2017/08/28 23:06:26 step 5: objective=2.0418808
2017/08/28 23:06:27 step 6: objective=2.0457604
2017/08/28 23:06:29 step 7: objective=2.0485022
2017/08/28 23:06:29 Training value function...
2017/08/28 23:06:31 step 0: mse=176.124453 step=0.100000
2017/08/28 23:06:32 step 1: mse=170.759031 step=0.100000
2017/08/28 23:06:33 step 2: mse=165.803292 step=0.100000
2017/08/28 23:06:35 step 3: mse=161.499800 step=0.100000
2017/08/28 23:06:36 step 4: mse=158.107885 step=0.100000
2017/08/28 23:06:37 step 5: mse=155.542623 step=0.100000
2017/08/28 23:06:38 step 6: mse=152.296760 step=0.100000
2017/08/28 23:06:39 step 7: mse=150.129598 step=0.100000
2017/08/28 23:06:39 Saving...
2017/08/28 23:06:39 Gathering batch of experience...
2017/08/28 23:07:27 batch 726: mean=180.588235 stddev=155.186627 entropy=0.350455 frames=5851 count=34
2017/08/28 23:07:27 Training policy...
2017/08/28 23:07:31 step 0: objective=1.2664689
2017/08/28 23:07:33 step 1: objective=1.2744094
2017/08/28 23:07:35 step 2: objective=1.2794777
2017/08/28 23:07:36 step 3: objective=1.2873881
2017/08/28 23:07:38 step 4: objective=1.2902206
2017/08/28 23:07:40 step 5: objective=1.29376
2017/08/28 23:07:42 step 6: objective=1.2999659
2017/08/28 23:07:44 step 7: objective=1.3026195
2017/08/28 23:07:44 Training value function...
2017/08/28 23:07:46 step 0: mse=188.637846 step=0.100000
2017/08/28 23:07:47 step 1: mse=184.512943 step=0.100000
2017/08/28 23:07:49 step 2: mse=180.907846 step=0.100000
2017/08/28 23:07:50 step 3: mse=177.886745 step=0.100000
2017/08/28 23:07:51 step 4: mse=175.096090 step=0.100000
2017/08/28 23:07:52 step 5: mse=172.443202 step=0.100000
2017/08/28 23:07:53 step 6: mse=170.138199 step=0.100000
2017/08/28 23:07:55 step 7: mse=168.096671 step=0.100000
2017/08/28 23:07:55 Saving...
2017/08/28 23:07:55 Gathering batch of experience...
2017/08/28 23:08:42 batch 727: mean=163.078947 stddev=125.108244 entropy=0.354946 frames=5980 count=38
2017/08/28 23:08:42 Training policy...
2017/08/28 23:08:46 step 0: objective=0.6745178
2017/08/28 23:08:48 step 1: objective=0.6803669
2017/08/28 23:08:50 step 2: objective=0.6866305
2017/08/28 23:08:52 step 3: objective=0.6903846
2017/08/28 23:08:54 step 4: objective=0.69557655
2017/08/28 23:08:56 step 5: objective=0.7011509
2017/08/28 23:08:58 step 6: objective=0.70577437
2017/08/28 23:08:59 step 7: objective=0.70854604
2017/08/28 23:08:59 Training value function...
2017/08/28 23:09:02 step 0: mse=153.635593 step=0.100000
2017/08/28 23:09:03 step 1: mse=152.907431 step=0.100000
2017/08/28 23:09:04 step 2: mse=152.306618 step=0.100000
2017/08/28 23:09:06 step 3: mse=151.357381 step=0.100000
2017/08/28 23:09:07 step 4: mse=150.383015 step=0.100000
2017/08/28 23:09:08 step 5: mse=149.298652 step=0.100000
2017/08/28 23:09:09 step 6: mse=148.542798 step=0.100000
2017/08/28 23:09:11 step 7: mse=147.938954 step=0.100000
2017/08/28 23:09:11 Saving...
2017/08/28 23:09:11 Gathering batch of experience...
2017/08/28 23:09:51 batch 728: mean=117.840909 stddev=87.570736 entropy=0.347104 frames=4789 count=44
2017/08/28 23:09:51 Training policy...
2017/08/28 23:09:54 step 0: objective=0.40922517
2017/08/28 23:09:56 step 1: objective=0.4220508
2017/08/28 23:09:57 step 2: objective=0.43064082
2017/08/28 23:09:59 step 3: objective=0.4367378
2017/08/28 23:10:00 step 4: objective=0.4428368
2017/08/28 23:10:02 step 5: objective=0.44719318
2017/08/28 23:10:03 step 6: objective=0.45338643
2017/08/28 23:10:05 step 7: objective=0.45632574
2017/08/28 23:10:05 Training value function...
2017/08/28 23:10:07 step 0: mse=152.072473 step=0.100000
2017/08/28 23:10:08 step 1: mse=150.280310 step=0.100000
2017/08/28 23:10:09 step 2: mse=148.435257 step=0.100000
2017/08/28 23:10:10 step 3: mse=146.937821 step=0.100000
2017/08/28 23:10:11 step 4: mse=145.803603 step=0.100000
2017/08/28 23:10:12 step 5: mse=144.803953 step=0.100000
2017/08/28 23:10:13 step 6: mse=143.731348 step=0.100000
2017/08/28 23:10:14 step 7: mse=142.902423 step=0.100000
2017/08/28 23:10:14 Saving...
2017/08/28 23:10:14 Gathering batch of experience...
2017/08/28 23:10:55 batch 729: mean=131.500000 stddev=100.200549 entropy=0.341061 frames=5027 count=40
2017/08/28 23:10:55 Training policy...
2017/08/28 23:10:59 step 0: objective=0.7976593
2017/08/28 23:11:00 step 1: objective=0.8045636
2017/08/28 23:11:02 step 2: objective=0.8122291
2017/08/28 23:11:03 step 3: objective=0.81779647
2017/08/28 23:11:05 step 4: objective=0.8225299
2017/08/28 23:11:07 step 5: objective=0.8262583
2017/08/28 23:11:08 step 6: objective=0.8305226
2017/08/28 23:11:10 step 7: objective=0.8338858
2017/08/28 23:11:10 Training value function...
2017/08/28 23:11:12 step 0: mse=170.694044 step=0.100000
2017/08/28 23:11:13 step 1: mse=169.595488 step=0.100000
2017/08/28 23:11:14 step 2: mse=168.559163 step=0.100000
2017/08/28 23:11:15 step 3: mse=168.012862 step=0.100000
2017/08/28 23:11:16 step 4: mse=166.833470 step=0.100000
2017/08/28 23:11:17 step 5: mse=166.039771 step=0.100000
2017/08/28 23:11:18 step 6: mse=165.400429 step=0.100000
2017/08/28 23:11:19 step 7: mse=164.780904 step=0.100000
2017/08/28 23:11:19 Saving...
2017/08/28 23:11:19 Gathering batch of experience...
2017/08/28 23:12:06 batch 730: mean=144.585366 stddev=93.276661 entropy=0.352440 frames=5598 count=41
2017/08/28 23:12:06 Training policy...
2017/08/28 23:12:10 step 0: objective=1.2701899
2017/08/28 23:12:12 step 1: objective=1.2773291
2017/08/28 23:12:14 step 2: objective=1.2869432
2017/08/28 23:12:16 step 3: objective=1.2917022
2017/08/28 23:12:17 step 4: objective=1.2957408
2017/08/28 23:12:19 step 5: objective=1.2992327
2017/08/28 23:12:21 step 6: objective=1.3036702
2017/08/28 23:12:22 step 7: objective=1.3068084
2017/08/28 23:12:22 Training value function...
2017/08/28 23:12:25 step 0: mse=167.155638 step=0.100000
2017/08/28 23:12:26 step 1: mse=163.666948 step=0.100000
2017/08/28 23:12:27 step 2: mse=160.873559 step=0.100000
2017/08/28 23:12:28 step 3: mse=158.400003 step=0.100000
2017/08/28 23:12:29 step 4: mse=156.079888 step=0.100000
2017/08/28 23:12:31 step 5: mse=154.208819 step=0.100000
2017/08/28 23:12:32 step 6: mse=152.497509 step=0.100000
2017/08/28 23:12:33 step 7: mse=150.934040 step=0.100000
2017/08/28 23:12:33 Saving...
2017/08/28 23:12:33 Gathering batch of experience...
2017/08/28 23:13:15 batch 731: mean=163.828571 stddev=117.531877 entropy=0.345076 frames=5373 count=35
2017/08/28 23:13:15 Training policy...
2017/08/28 23:13:19 step 0: objective=1.5896407
2017/08/28 23:13:21 step 1: objective=1.5975131
2017/08/28 23:13:23 step 2: objective=1.6043152
2017/08/28 23:13:24 step 3: objective=1.6095779
2017/08/28 23:13:26 step 4: objective=1.6162161
2017/08/28 23:13:28 step 5: objective=1.619855
2017/08/28 23:13:29 step 6: objective=1.6244655
2017/08/28 23:13:31 step 7: objective=1.6265638
2017/08/28 23:13:31 Training value function...
2017/08/28 23:13:33 step 0: mse=189.370360 step=0.100000
2017/08/28 23:13:34 step 1: mse=185.348838 step=0.100000
2017/08/28 23:13:35 step 2: mse=182.290585 step=0.100000
2017/08/28 23:13:37 step 3: mse=179.241091 step=0.100000
2017/08/28 23:13:38 step 4: mse=177.009028 step=0.100000
2017/08/28 23:13:39 step 5: mse=174.733187 step=0.100000
2017/08/28 23:13:40 step 6: mse=172.772760 step=0.100000
2017/08/28 23:13:41 step 7: mse=170.713236 step=0.100000
2017/08/28 23:13:41 Saving...
2017/08/28 23:13:41 Gathering batch of experience...
2017/08/28 23:14:28 batch 732: mean=193.200000 stddev=146.711145 entropy=0.352964 frames=6323 count=35
2017/08/28 23:14:28 Training policy...
2017/08/28 23:14:32 step 0: objective=1.761217
2017/08/28 23:14:34 step 1: objective=1.7655994
2017/08/28 23:14:36 step 2: objective=1.7690248
2017/08/28 23:14:38 step 3: objective=1.772311
2017/08/28 23:14:40 step 4: objective=1.7762369
2017/08/28 23:14:42 step 5: objective=1.7793361
2017/08/28 23:14:44 step 6: objective=1.7821841
2017/08/28 23:14:46 step 7: objective=1.7862582
2017/08/28 23:14:46 Training value function...
2017/08/28 23:14:49 step 0: mse=180.804799 step=0.100000
2017/08/28 23:14:50 step 1: mse=175.405317 step=0.100000
2017/08/28 23:14:51 step 2: mse=170.933102 step=0.100000
2017/08/28 23:14:53 step 3: mse=166.969554 step=0.100000
2017/08/28 23:14:54 step 4: mse=163.814615 step=0.100000
2017/08/28 23:14:55 step 5: mse=160.977826 step=0.100000
2017/08/28 23:14:57 step 6: mse=158.824051 step=0.100000
2017/08/28 23:14:58 step 7: mse=156.824307 step=0.100000
2017/08/28 23:14:58 Saving...
2017/08/28 23:14:58 Gathering batch of experience...
2017/08/28 23:15:46 batch 733: mean=144.435897 stddev=145.780797 entropy=0.351876 frames=5364 count=39
2017/08/28 23:15:46 Training policy...
2017/08/28 23:15:50 step 0: objective=0.60610133
2017/08/28 23:15:52 step 1: objective=0.615812
2017/08/28 23:15:53 step 2: objective=0.62471557
2017/08/28 23:15:55 step 3: objective=0.632972
2017/08/28 23:15:57 step 4: objective=0.63702667
2017/08/28 23:15:58 step 5: objective=0.64420223
2017/08/28 23:16:00 step 6: objective=0.65058714
2017/08/28 23:16:02 step 7: objective=0.65392363
2017/08/28 23:16:02 Training value function...
2017/08/28 23:16:04 step 0: mse=189.187220 step=0.100000
2017/08/28 23:16:05 step 1: mse=184.787328 step=0.100000
2017/08/28 23:16:06 step 2: mse=180.674818 step=0.100000
2017/08/28 23:16:07 step 3: mse=177.990798 step=0.100000
2017/08/28 23:16:08 step 4: mse=175.859564 step=0.100000
2017/08/28 23:16:10 step 5: mse=172.971949 step=0.100000
2017/08/28 23:16:11 step 6: mse=171.175206 step=0.100000
2017/08/28 23:16:12 step 7: mse=169.161494 step=0.100000
2017/08/28 23:16:12 Saving...
2017/08/28 23:16:12 Gathering batch of experience...
2017/08/28 23:17:00 batch 734: mean=178.027778 stddev=136.028691 entropy=0.347878 frames=5926 count=36
2017/08/28 23:17:00 Training policy...
2017/08/28 23:17:04 step 0: objective=1.4754335
2017/08/28 23:17:06 step 1: objective=1.4824911
2017/08/28 23:17:08 step 2: objective=1.4913795
2017/08/28 23:17:10 step 3: objective=1.4971275
2017/08/28 23:17:12 step 4: objective=1.502035
2017/08/28 23:17:14 step 5: objective=1.5055918
2017/08/28 23:17:15 step 6: objective=1.5103949
2017/08/28 23:17:17 step 7: objective=1.5151013
2017/08/28 23:17:17 Training value function...
2017/08/28 23:17:20 step 0: mse=169.495197 step=0.100000
2017/08/28 23:17:21 step 1: mse=165.989806 step=0.100000
2017/08/28 23:17:22 step 2: mse=163.247844 step=0.100000
2017/08/28 23:17:24 step 3: mse=160.860694 step=0.100000
2017/08/28 23:17:25 step 4: mse=158.781922 step=0.100000
2017/08/28 23:17:26 step 5: mse=156.814122 step=0.100000
2017/08/28 23:17:27 step 6: mse=155.081636 step=0.100000
2017/08/28 23:17:29 step 7: mse=153.638245 step=0.100000
2017/08/28 23:17:29 Saving...
2017/08/28 23:17:29 Gathering batch of experience...
2017/08/28 23:18:18 batch 735: mean=160.975000 stddev=156.649687 entropy=0.350760 frames=6139 count=40
2017/08/28 23:18:18 Training policy...
2017/08/28 23:18:23 step 0: objective=0.7534479
2017/08/28 23:18:25 step 1: objective=0.7597245
2017/08/28 23:18:27 step 2: objective=0.76537985
2017/08/28 23:18:29 step 3: objective=0.771385
2017/08/28 23:18:31 step 4: objective=0.7772101
2017/08/28 23:18:33 step 5: objective=0.782887
2017/08/28 23:18:35 step 6: objective=0.78572786
2017/08/28 23:18:36 step 7: objective=0.7896778
2017/08/28 23:18:36 Training value function...
2017/08/28 23:18:39 step 0: mse=165.277088 step=0.100000
2017/08/28 23:18:40 step 1: mse=162.231268 step=0.100000
2017/08/28 23:18:42 step 2: mse=159.911475 step=0.100000
2017/08/28 23:18:43 step 3: mse=157.960183 step=0.100000
2017/08/28 23:18:44 step 4: mse=156.398704 step=0.100000
2017/08/28 23:18:45 step 5: mse=154.744675 step=0.100000
2017/08/28 23:18:47 step 6: mse=153.571419 step=0.100000
2017/08/28 23:18:48 step 7: mse=152.403875 step=0.100000
2017/08/28 23:18:48 Saving...
2017/08/28 23:18:48 Gathering batch of experience...
2017/08/28 23:19:35 batch 736: mean=213.812500 stddev=137.666135 entropy=0.352509 frames=6147 count=32
2017/08/28 23:19:35 Training policy...
2017/08/28 23:19:40 step 0: objective=2.0208516
2017/08/28 23:19:42 step 1: objective=2.02563
2017/08/28 23:19:43 step 2: objective=2.0317073
2017/08/28 23:19:45 step 3: objective=2.0357113
2017/08/28 23:19:47 step 4: objective=2.0455062
2017/08/28 23:19:49 step 5: objective=2.0506656
2017/08/28 23:19:51 step 6: objective=2.0589225
2017/08/28 23:19:53 step 7: objective=2.0627232
2017/08/28 23:19:53 Training value function...
2017/08/28 23:19:56 step 0: mse=186.874111 step=0.100000
2017/08/28 23:19:57 step 1: mse=181.601634 step=0.100000
2017/08/28 23:19:58 step 2: mse=177.150742 step=0.100000
2017/08/28 23:19:59 step 3: mse=173.086696 step=0.100000
2017/08/28 23:20:01 step 4: mse=169.785254 step=0.100000
2017/08/28 23:20:02 step 5: mse=167.160008 step=0.100000
2017/08/28 23:20:03 step 6: mse=164.622082 step=0.100000
2017/08/28 23:20:05 step 7: mse=162.605400 step=0.100000
2017/08/28 23:20:05 Saving...
2017/08/28 23:20:05 Gathering batch of experience...
2017/08/28 23:20:56 batch 737: mean=147.930233 stddev=149.933070 entropy=0.353384 frames=6270 count=43
2017/08/28 23:20:56 Training policy...
2017/08/28 23:21:01 step 0: objective=-0.24551867
2017/08/28 23:21:03 step 1: objective=-0.23627299
2017/08/28 23:21:05 step 2: objective=-0.23097938
2017/08/28 23:21:07 step 3: objective=-0.22328904
2017/08/28 23:21:09 step 4: objective=-0.21797363
2017/08/28 23:21:11 step 5: objective=-0.21449481
2017/08/28 23:21:13 step 6: objective=-0.21045445
2017/08/28 23:21:15 step 7: objective=-0.20562094
2017/08/28 23:21:15 Training value function...
2017/08/28 23:21:17 step 0: mse=153.175493 step=0.100000
2017/08/28 23:21:19 step 1: mse=147.115328 step=0.100000
2017/08/28 23:21:20 step 2: mse=142.144302 step=0.100000
2017/08/28 23:21:21 step 3: mse=138.672776 step=0.100000
2017/08/28 23:21:23 step 4: mse=135.555545 step=0.100000
2017/08/28 23:21:24 step 5: mse=133.126180 step=0.100000
2017/08/28 23:21:25 step 6: mse=130.560941 step=0.100000
2017/08/28 23:21:27 step 7: mse=128.654021 step=0.100000
2017/08/28 23:21:27 Saving...
2017/08/28 23:21:27 Gathering batch of experience...
2017/08/28 23:22:14 batch 738: mean=136.727273 stddev=115.222189 entropy=0.344489 frames=5890 count=44
2017/08/28 23:22:14 Training policy...
2017/08/28 23:22:19 step 0: objective=0.4003254
2017/08/28 23:22:21 step 1: objective=0.4083968
2017/08/28 23:22:23 step 2: objective=0.41454178
2017/08/28 23:22:24 step 3: objective=0.42200163
2017/08/28 23:22:26 step 4: objective=0.42571285
2017/08/28 23:22:28 step 5: objective=0.43131578
2017/08/28 23:22:30 step 6: objective=0.43668625
2017/08/28 23:22:32 step 7: objective=0.43881688
2017/08/28 23:22:32 Training value function...
2017/08/28 23:22:34 step 0: mse=139.197890 step=0.100000
2017/08/28 23:22:35 step 1: mse=138.455826 step=0.100000
2017/08/28 23:22:37 step 2: mse=137.294368 step=0.100000
2017/08/28 23:22:38 step 3: mse=136.612232 step=0.100000
2017/08/28 23:22:39 step 4: mse=135.949347 step=0.100000
2017/08/28 23:22:40 step 5: mse=135.204326 step=0.100000
2017/08/28 23:22:42 step 6: mse=134.353079 step=0.100000
2017/08/28 23:22:43 step 7: mse=133.952754 step=0.100000
2017/08/28 23:22:43 Saving...
2017/08/28 23:22:43 Gathering batch of experience...
2017/08/28 23:23:28 batch 739: mean=147.600000 stddev=111.508027 entropy=0.347281 frames=5559 count=40
2017/08/28 23:23:28 Training policy...
2017/08/28 23:23:32 step 0: objective=1.2703649
2017/08/28 23:23:34 step 1: objective=1.2772741
2017/08/28 23:23:36 step 2: objective=1.2825024
2017/08/28 23:23:38 step 3: objective=1.2906749
2017/08/28 23:23:39 step 4: objective=1.2954689
2017/08/28 23:23:41 step 5: objective=1.3015854
2017/08/28 23:23:43 step 6: objective=1.3064148
2017/08/28 23:23:45 step 7: objective=1.3098803
2017/08/28 23:23:45 Training value function...
2017/08/28 23:23:47 step 0: mse=164.906067 step=0.100000
2017/08/28 23:23:48 step 1: mse=159.640011 step=0.100000
2017/08/28 23:23:49 step 2: mse=155.227135 step=0.100000
2017/08/28 23:23:50 step 3: mse=151.348591 step=0.100000
2017/08/28 23:23:52 step 4: mse=148.415939 step=0.100000
2017/08/28 23:23:53 step 5: mse=145.963280 step=0.100000
2017/08/28 23:23:54 step 6: mse=143.881799 step=0.100000
2017/08/28 23:23:55 step 7: mse=141.865657 step=0.100000
2017/08/28 23:23:55 Saving...
2017/08/28 23:23:55 Gathering batch of experience...
2017/08/28 23:24:39 batch 740: mean=189.352941 stddev=114.789547 entropy=0.346696 frames=5792 count=34
2017/08/28 23:24:39 Training policy...
2017/08/28 23:24:43 step 0: objective=2.1014278
2017/08/28 23:24:45 step 1: objective=2.1076274
2017/08/28 23:24:47 step 2: objective=2.1136746
2017/08/28 23:24:49 step 3: objective=2.1177895
2017/08/28 23:24:51 step 4: objective=2.1210036
2017/08/28 23:24:52 step 5: objective=2.128731
2017/08/28 23:24:54 step 6: objective=2.1339452
2017/08/28 23:24:56 step 7: objective=2.1385045
2017/08/28 23:24:56 Training value function...
2017/08/28 23:24:58 step 0: mse=182.957294 step=0.100000
2017/08/28 23:25:00 step 1: mse=178.680332 step=0.100000
2017/08/28 23:25:01 step 2: mse=175.035078 step=0.100000
2017/08/28 23:25:02 step 3: mse=171.454904 step=0.100000
2017/08/28 23:25:03 step 4: mse=168.473721 step=0.100000
2017/08/28 23:25:05 step 5: mse=165.803375 step=0.100000
2017/08/28 23:25:06 step 6: mse=163.326934 step=0.100000
2017/08/28 23:25:07 step 7: mse=161.177547 step=0.100000
2017/08/28 23:25:07 Saving...
2017/08/28 23:25:07 Gathering batch of experience...
2017/08/28 23:25:54 batch 741: mean=134.348837 stddev=104.277778 entropy=0.339150 frames=5564 count=43
2017/08/28 23:25:54 Training policy...
2017/08/28 23:25:58 step 0: objective=-0.19042128
2017/08/28 23:26:00 step 1: objective=-0.18419743
2017/08/28 23:26:01 step 2: objective=-0.1791175
2017/08/28 23:26:03 step 3: objective=-0.17325452
2017/08/28 23:26:05 step 4: objective=-0.16546662
2017/08/28 23:26:07 step 5: objective=-0.16011134
2017/08/28 23:26:08 step 6: objective=-0.15423517
2017/08/28 23:26:10 step 7: objective=-0.15123819
2017/08/28 23:26:10 Training value function...
2017/08/28 23:26:12 step 0: mse=161.478239 step=0.100000
2017/08/28 23:26:14 step 1: mse=159.648271 step=0.100000
2017/08/28 23:26:15 step 2: mse=158.134495 step=0.100000
2017/08/28 23:26:16 step 3: mse=156.819743 step=0.100000
2017/08/28 23:26:17 step 4: mse=155.983007 step=0.100000
2017/08/28 23:26:18 step 5: mse=154.898370 step=0.100000
2017/08/28 23:26:19 step 6: mse=154.049864 step=0.100000
2017/08/28 23:26:21 step 7: mse=153.381435 step=0.100000
2017/08/28 23:26:21 Saving...
2017/08/28 23:26:21 Gathering batch of experience...
2017/08/28 23:27:05 batch 742: mean=156.421053 stddev=127.975662 entropy=0.347694 frames=5413 count=38
2017/08/28 23:27:05 Training policy...
2017/08/28 23:27:09 step 0: objective=1.7861134
2017/08/28 23:27:11 step 1: objective=1.796545
2017/08/28 23:27:13 step 2: objective=1.805487
2017/08/28 23:27:14 step 3: objective=1.8116857
2017/08/28 23:27:16 step 4: objective=1.818798
2017/08/28 23:27:18 step 5: objective=1.8241633
2017/08/28 23:27:19 step 6: objective=1.8308613
2017/08/28 23:27:21 step 7: objective=1.8357141
2017/08/28 23:27:21 Training value function...
2017/08/28 23:27:23 step 0: mse=200.944551 step=0.100000
2017/08/28 23:27:24 step 1: mse=195.926406 step=0.100000
2017/08/28 23:27:26 step 2: mse=192.113666 step=0.100000
2017/08/28 23:27:27 step 3: mse=188.265837 step=0.100000
2017/08/28 23:27:28 step 4: mse=184.860091 step=0.100000
2017/08/28 23:27:29 step 5: mse=182.044026 step=0.100000
2017/08/28 23:27:30 step 6: mse=179.247476 step=0.100000
2017/08/28 23:27:31 step 7: mse=176.979534 step=0.100000
2017/08/28 23:27:31 Saving...
2017/08/28 23:27:31 Gathering batch of experience...
2017/08/28 23:28:18 batch 743: mean=157.384615 stddev=134.881071 entropy=0.350721 frames=6103 count=39
2017/08/28 23:28:18 Training policy...
2017/08/28 23:28:23 step 0: objective=0.49944112
2017/08/28 23:28:25 step 1: objective=0.5037389
2017/08/28 23:28:27 step 2: objective=0.50784105
2017/08/28 23:28:29 step 3: objective=0.5126187
2017/08/28 23:28:31 step 4: objective=0.5165204
2017/08/28 23:28:33 step 5: objective=0.5192474
2017/08/28 23:28:35 step 6: objective=0.5231834
2017/08/28 23:28:37 step 7: objective=0.5266415
2017/08/28 23:28:37 Training value function...
2017/08/28 23:28:39 step 0: mse=153.917134 step=0.100000
2017/08/28 23:28:40 step 1: mse=151.920267 step=0.100000
2017/08/28 23:28:42 step 2: mse=149.729114 step=0.100000
2017/08/28 23:28:43 step 3: mse=148.561377 step=0.100000
2017/08/28 23:28:44 step 4: mse=146.801241 step=0.100000
2017/08/28 23:28:46 step 5: mse=145.468443 step=0.100000
2017/08/28 23:28:47 step 6: mse=144.489345 step=0.100000
2017/08/28 23:28:48 step 7: mse=143.223451 step=0.100000
2017/08/28 23:28:48 Saving...
2017/08/28 23:28:48 Gathering batch of experience...
2017/08/28 23:29:37 batch 744: mean=151.825000 stddev=105.270339 entropy=0.341334 frames=5804 count=40
2017/08/28 23:29:37 Training policy...
2017/08/28 23:29:42 step 0: objective=0.8125434
2017/08/28 23:29:43 step 1: objective=0.8194547
2017/08/28 23:29:45 step 2: objective=0.825544
2017/08/28 23:29:47 step 3: objective=0.8312749
2017/08/28 23:29:49 step 4: objective=0.8366045
2017/08/28 23:29:51 step 5: objective=0.8406553
2017/08/28 23:29:53 step 6: objective=0.8473602
2017/08/28 23:29:54 step 7: objective=0.85076654
2017/08/28 23:29:54 Training value function...
2017/08/28 23:29:57 step 0: mse=153.880643 step=0.100000
2017/08/28 23:29:58 step 1: mse=150.635312 step=0.100000
2017/08/28 23:29:59 step 2: mse=148.092362 step=0.100000
2017/08/28 23:30:01 step 3: mse=145.883125 step=0.100000
2017/08/28 23:30:02 step 4: mse=144.094519 step=0.100000
2017/08/28 23:30:03 step 5: mse=142.525707 step=0.100000
2017/08/28 23:30:04 step 6: mse=141.316590 step=0.100000
2017/08/28 23:30:05 step 7: mse=140.123150 step=0.100000
2017/08/28 23:30:05 Saving...
2017/08/28 23:30:05 Gathering batch of experience...
2017/08/28 23:30:55 batch 745: mean=161.146341 stddev=123.066026 entropy=0.349439 frames=6105 count=41
2017/08/28 23:30:55 Training policy...
2017/08/28 23:31:00 step 0: objective=1.5954331
2017/08/28 23:31:02 step 1: objective=1.5999786
2017/08/28 23:31:03 step 2: objective=1.6066092
2017/08/28 23:31:05 step 3: objective=1.6107435
2017/08/28 23:31:07 step 4: objective=1.6142594
2017/08/28 23:31:09 step 5: objective=1.6201167
2017/08/28 23:31:11 step 6: objective=1.6256187
2017/08/28 23:31:13 step 7: objective=1.6289129
2017/08/28 23:31:13 Training value function...
2017/08/28 23:31:16 step 0: mse=181.447363 step=0.100000
2017/08/28 23:31:17 step 1: mse=177.872077 step=0.100000
2017/08/28 23:31:18 step 2: mse=174.904209 step=0.100000
2017/08/28 23:31:19 step 3: mse=172.190172 step=0.100000
2017/08/28 23:31:21 step 4: mse=169.807757 step=0.100000
2017/08/28 23:31:22 step 5: mse=167.872775 step=0.100000
2017/08/28 23:31:23 step 6: mse=166.121097 step=0.100000
2017/08/28 23:31:25 step 7: mse=164.461643 step=0.100000
2017/08/28 23:31:25 Saving...
2017/08/28 23:31:25 Gathering batch of experience...
2017/08/28 23:32:09 batch 746: mean=151.256410 stddev=135.883570 entropy=0.347767 frames=5717 count=39
2017/08/28 23:32:09 Training policy...
2017/08/28 23:32:13 step 0: objective=0.78080565
2017/08/28 23:32:15 step 1: objective=0.78671914
2017/08/28 23:32:17 step 2: objective=0.79371226
2017/08/28 23:32:19 step 3: objective=0.80068
2017/08/28 23:32:21 step 4: objective=0.8053753
2017/08/28 23:32:23 step 5: objective=0.8102032
2017/08/28 23:32:24 step 6: objective=0.8150022
2017/08/28 23:32:26 step 7: objective=0.8205162
2017/08/28 23:32:26 Training value function...
2017/08/28 23:32:29 step 0: mse=169.020243 step=0.100000
2017/08/28 23:32:30 step 1: mse=165.803623 step=0.100000
2017/08/28 23:32:31 step 2: mse=163.266192 step=0.100000
2017/08/28 23:32:32 step 3: mse=160.749559 step=0.100000
2017/08/28 23:32:33 step 4: mse=158.950920 step=0.100000
2017/08/28 23:32:35 step 5: mse=157.157217 step=0.100000
2017/08/28 23:32:36 step 6: mse=155.300793 step=0.100000
2017/08/28 23:32:37 step 7: mse=154.313084 step=0.100000
2017/08/28 23:32:37 Saving...
2017/08/28 23:32:37 Gathering batch of experience...
2017/08/28 23:33:28 batch 747: mean=131.377778 stddev=132.534824 entropy=0.345462 frames=5753 count=45
2017/08/28 23:33:28 Training policy...
2017/08/28 23:33:32 step 0: objective=0.4902352
2017/08/28 23:33:34 step 1: objective=0.49770164
2017/08/28 23:33:36 step 2: objective=0.5051627
2017/08/28 23:33:38 step 3: objective=0.5115065
2017/08/28 23:33:40 step 4: objective=0.5168915
2017/08/28 23:33:41 step 5: objective=0.5240311
2017/08/28 23:33:43 step 6: objective=0.53015655
2017/08/28 23:33:45 step 7: objective=0.5344834
2017/08/28 23:33:45 Training value function...
2017/08/28 23:33:47 step 0: mse=156.981577 step=0.100000
2017/08/28 23:33:49 step 1: mse=154.036288 step=0.100000
2017/08/28 23:33:50 step 2: mse=151.778346 step=0.100000
2017/08/28 23:33:51 step 3: mse=149.812520 step=0.100000
2017/08/28 23:33:52 step 4: mse=148.135290 step=0.100000
2017/08/28 23:33:54 step 5: mse=146.612410 step=0.100000
2017/08/28 23:33:55 step 6: mse=145.119737 step=0.100000
2017/08/28 23:33:56 step 7: mse=143.700979 step=0.100000
2017/08/28 23:33:56 Saving...
2017/08/28 23:33:56 Gathering batch of experience...
2017/08/28 23:34:41 batch 748: mean=129.673913 stddev=113.524189 entropy=0.340903 frames=5405 count=46
2017/08/28 23:34:41 Training policy...
2017/08/28 23:34:45 step 0: objective=1.6156366
2017/08/28 23:34:47 step 1: objective=1.6230528
2017/08/28 23:34:48 step 2: objective=1.6280936
2017/08/28 23:34:50 step 3: objective=1.6345357
2017/08/28 23:34:52 step 4: objective=1.6419941
2017/08/28 23:34:54 step 5: objective=1.6493286
2017/08/28 23:34:55 step 6: objective=1.6550902
2017/08/28 23:34:57 step 7: objective=1.6583549
2017/08/28 23:34:57 Training value function...
2017/08/28 23:34:59 step 0: mse=182.955054 step=0.100000
2017/08/28 23:35:00 step 1: mse=179.671294 step=0.100000
2017/08/28 23:35:01 step 2: mse=176.396730 step=0.100000
2017/08/28 23:35:03 step 3: mse=173.733838 step=0.100000
2017/08/28 23:35:04 step 4: mse=171.485891 step=0.100000
2017/08/28 23:35:05 step 5: mse=169.423506 step=0.100000
2017/08/28 23:35:06 step 6: mse=167.134396 step=0.100000
2017/08/28 23:35:07 step 7: mse=165.020370 step=0.100000
2017/08/28 23:35:07 Saving...
2017/08/28 23:35:07 Gathering batch of experience...
2017/08/28 23:35:52 batch 749: mean=153.200000 stddev=133.905228 entropy=0.347507 frames=5831 count=40
2017/08/28 23:35:52 Training policy...
2017/08/28 23:35:57 step 0: objective=1.1900738
2017/08/28 23:35:59 step 1: objective=1.1955
2017/08/28 23:36:01 step 2: objective=1.2026703
2017/08/28 23:36:02 step 3: objective=1.2114451
2017/08/28 23:36:04 step 4: objective=1.2183502
2017/08/28 23:36:06 step 5: objective=1.2224482
2017/08/28 23:36:08 step 6: objective=1.2262288
2017/08/28 23:36:10 step 7: objective=1.2299035
2017/08/28 23:36:10 Training value function...
2017/08/28 23:36:12 step 0: mse=172.052033 step=0.100000
2017/08/28 23:36:13 step 1: mse=169.625623 step=0.100000
2017/08/28 23:36:15 step 2: mse=167.497066 step=0.100000
2017/08/28 23:36:16 step 3: mse=165.443959 step=0.100000
2017/08/28 23:36:17 step 4: mse=163.042121 step=0.100000
2017/08/28 23:36:18 step 5: mse=161.852179 step=0.100000
2017/08/28 23:36:19 step 6: mse=160.596009 step=0.100000
2017/08/28 23:36:21 step 7: mse=158.958248 step=0.100000
2017/08/28 23:36:21 Saving...
2017/08/28 23:36:21 Gathering batch of experience...
2017/08/28 23:37:04 batch 750: mean=195.647059 stddev=154.291718 entropy=0.344796 frames=5944 count=34
2017/08/28 23:37:04 Training policy...
2017/08/28 23:37:09 step 0: objective=2.3207412
2017/08/28 23:37:11 step 1: objective=2.3272743
2017/08/28 23:37:13 step 2: objective=2.333886
2017/08/28 23:37:15 step 3: objective=2.338117
2017/08/28 23:37:17 step 4: objective=2.3432624
2017/08/28 23:37:18 step 5: objective=2.346372
2017/08/28 23:37:20 step 6: objective=2.3504288
2017/08/28 23:37:22 step 7: objective=2.3529801
2017/08/28 23:37:22 Training value function...
2017/08/28 23:37:25 step 0: mse=195.122771 step=0.100000
2017/08/28 23:37:26 step 1: mse=189.864474 step=0.100000
2017/08/28 23:37:27 step 2: mse=185.368984 step=0.100000
2017/08/28 23:37:28 step 3: mse=181.302750 step=0.100000
2017/08/28 23:37:30 step 4: mse=177.908803 step=0.100000
2017/08/28 23:37:31 step 5: mse=175.128602 step=0.100000
2017/08/28 23:37:32 step 6: mse=172.195254 step=0.100000
2017/08/28 23:37:33 step 7: mse=169.465649 step=0.100000
2017/08/28 23:37:33 Saving...
2017/08/28 23:37:34 Gathering batch of experience...
2017/08/28 23:38:15 batch 751: mean=181.125000 stddev=176.502612 entropy=0.354227 frames=5640 count=32
2017/08/28 23:38:15 Training policy...
2017/08/28 23:38:19 step 0: objective=0.6160609
2017/08/28 23:38:21 step 1: objective=0.6210841
2017/08/28 23:38:23 step 2: objective=0.6263958
2017/08/28 23:38:25 step 3: objective=0.6354537
2017/08/28 23:38:27 step 4: objective=0.6388301
2017/08/28 23:38:29 step 5: objective=0.64334875
2017/08/28 23:38:30 step 6: objective=0.6461312
2017/08/28 23:38:32 step 7: objective=0.65208477
2017/08/28 23:38:32 Training value function...
2017/08/28 23:38:34 step 0: mse=151.328891 step=0.100000
2017/08/28 23:38:36 step 1: mse=149.750494 step=0.100000
2017/08/28 23:38:37 step 2: mse=148.318842 step=0.100000
2017/08/28 23:38:38 step 3: mse=146.994482 step=0.100000
2017/08/28 23:38:39 step 4: mse=145.474633 step=0.100000
2017/08/28 23:38:40 step 5: mse=144.741909 step=0.100000
2017/08/28 23:38:42 step 6: mse=143.263235 step=0.100000
2017/08/28 23:38:43 step 7: mse=142.375875 step=0.100000
2017/08/28 23:38:43 Saving...
2017/08/28 23:38:43 Gathering batch of experience...
2017/08/28 23:39:30 batch 752: mean=145.302326 stddev=123.323838 entropy=0.344285 frames=5948 count=43
2017/08/28 23:39:30 Training policy...
2017/08/28 23:39:34 step 0: objective=0.583798
2017/08/28 23:39:36 step 1: objective=0.59485126
2017/08/28 23:39:38 step 2: objective=0.60285985
2017/08/28 23:39:40 step 3: objective=0.6066271
2017/08/28 23:39:42 step 4: objective=0.614348
2017/08/28 23:39:44 step 5: objective=0.6176218
2017/08/28 23:39:46 step 6: objective=0.62171954
2017/08/28 23:39:48 step 7: objective=0.62476647
2017/08/28 23:39:48 Training value function...
2017/08/28 23:39:50 step 0: mse=165.584310 step=0.100000
2017/08/28 23:39:51 step 1: mse=163.866483 step=0.100000
2017/08/28 23:39:53 step 2: mse=162.402274 step=0.100000
2017/08/28 23:39:54 step 3: mse=161.128612 step=0.100000
2017/08/28 23:39:55 step 4: mse=160.179072 step=0.100000
2017/08/28 23:39:56 step 5: mse=159.146613 step=0.100000
2017/08/28 23:39:58 step 6: mse=158.468117 step=0.100000
2017/08/28 23:39:59 step 7: mse=157.833798 step=0.100000
2017/08/28 23:39:59 Saving...
2017/08/28 23:39:59 Gathering batch of experience...
2017/08/28 23:40:46 batch 753: mean=125.022222 stddev=115.232034 entropy=0.342074 frames=5495 count=45
2017/08/28 23:40:46 Training policy...
2017/08/28 23:40:51 step 0: objective=0.25855508
2017/08/28 23:40:52 step 1: objective=0.2666072
2017/08/28 23:40:54 step 2: objective=0.27329916
2017/08/28 23:40:56 step 3: objective=0.2775165
2017/08/28 23:40:58 step 4: objective=0.2854492
2017/08/28 23:40:59 step 5: objective=0.29006508
2017/08/28 23:41:01 step 6: objective=0.2975551
2017/08/28 23:41:03 step 7: objective=0.303552
2017/08/28 23:41:03 Training value function...
2017/08/28 23:41:05 step 0: mse=168.547332 step=0.100000
2017/08/28 23:41:06 step 1: mse=165.502269 step=0.100000
2017/08/28 23:41:08 step 2: mse=163.456115 step=0.100000
2017/08/28 23:41:09 step 3: mse=161.515427 step=0.100000
2017/08/28 23:41:10 step 4: mse=159.418354 step=0.100000
2017/08/28 23:41:11 step 5: mse=157.978804 step=0.100000
2017/08/28 23:41:12 step 6: mse=156.727373 step=0.100000
2017/08/28 23:41:13 step 7: mse=155.869543 step=0.100000
2017/08/28 23:41:13 Saving...
2017/08/28 23:41:13 Gathering batch of experience...
2017/08/28 23:41:57 batch 754: mean=153.918919 stddev=127.236613 entropy=0.350932 frames=5367 count=37
2017/08/28 23:41:57 Training policy...
2017/08/28 23:42:01 step 0: objective=1.5086203
2017/08/28 23:42:03 step 1: objective=1.5149338
2017/08/28 23:42:05 step 2: objective=1.524262
2017/08/28 23:42:06 step 3: objective=1.5286255
2017/08/28 23:42:08 step 4: objective=1.5323929
2017/08/28 23:42:10 step 5: objective=1.535999
2017/08/28 23:42:12 step 6: objective=1.5407491
2017/08/28 23:42:13 step 7: objective=1.5438389
2017/08/28 23:42:13 Training value function...
2017/08/28 23:42:15 step 0: mse=185.806545 step=0.100000
2017/08/28 23:42:17 step 1: mse=180.573356 step=0.100000
2017/08/28 23:42:18 step 2: mse=176.532555 step=0.100000
2017/08/28 23:42:19 step 3: mse=172.853945 step=0.100000
2017/08/28 23:42:20 step 4: mse=169.599014 step=0.100000
2017/08/28 23:42:21 step 5: mse=166.997463 step=0.100000
2017/08/28 23:42:22 step 6: mse=164.666880 step=0.100000
2017/08/28 23:42:23 step 7: mse=162.768978 step=0.100000
2017/08/28 23:42:23 Saving...
2017/08/28 23:42:24 Gathering batch of experience...
2017/08/28 23:43:09 batch 755: mean=192.000000 stddev=159.813284 entropy=0.346850 frames=6248 count=35
2017/08/28 23:43:09 Training policy...
2017/08/28 23:43:14 step 0: objective=2.057924
2017/08/28 23:43:16 step 1: objective=2.0646086
2017/08/28 23:43:18 step 2: objective=2.069354
2017/08/28 23:43:20 step 3: objective=2.073375
2017/08/28 23:43:22 step 4: objective=2.076973
2017/08/28 23:43:24 step 5: objective=2.080562
2017/08/28 23:43:26 step 6: objective=2.0840378
2017/08/28 23:43:28 step 7: objective=2.0890899
2017/08/28 23:43:28 Training value function...
2017/08/28 23:43:31 step 0: mse=182.752565 step=0.100000
2017/08/28 23:43:32 step 1: mse=177.449353 step=0.100000
2017/08/28 23:43:33 step 2: mse=173.476045 step=0.100000
2017/08/28 23:43:35 step 3: mse=170.265254 step=0.100000
2017/08/28 23:43:36 step 4: mse=167.189715 step=0.100000
2017/08/28 23:43:37 step 5: mse=164.523695 step=0.100000
2017/08/28 23:43:39 step 6: mse=162.394221 step=0.100000
2017/08/28 23:43:40 step 7: mse=160.270735 step=0.100000
2017/08/28 23:43:40 Saving...
2017/08/28 23:43:40 Gathering batch of experience...
2017/08/28 23:44:26 batch 756: mean=111.041667 stddev=90.120743 entropy=0.343214 frames=5290 count=48
2017/08/28 23:44:26 Training policy...
2017/08/28 23:44:30 step 0: objective=-0.6531718
2017/08/28 23:44:32 step 1: objective=-0.6450142
2017/08/28 23:44:34 step 2: objective=-0.6341103
2017/08/28 23:44:35 step 3: objective=-0.6234061
2017/08/28 23:44:37 step 4: objective=-0.6157981
2017/08/28 23:44:39 step 5: objective=-0.6120592
2017/08/28 23:44:40 step 6: objective=-0.6080872
2017/08/28 23:44:42 step 7: objective=-0.6051324
2017/08/28 23:44:42 Training value function...
2017/08/28 23:44:44 step 0: mse=153.513561 step=0.100000
2017/08/28 23:44:45 step 1: mse=150.962689 step=0.100000
2017/08/28 23:44:47 step 2: mse=148.903676 step=0.100000
2017/08/28 23:44:48 step 3: mse=147.432189 step=0.100000
2017/08/28 23:44:49 step 4: mse=145.841104 step=0.100000
2017/08/28 23:44:50 step 5: mse=145.140887 step=0.100000
2017/08/28 23:44:51 step 6: mse=144.489763 step=0.100000
2017/08/28 23:44:52 step 7: mse=144.106473 step=0.100000
2017/08/28 23:44:52 Saving...
2017/08/28 23:44:52 Gathering batch of experience...
2017/08/28 23:45:41 batch 757: mean=166.333333 stddev=152.555889 entropy=0.352826 frames=6013 count=39
2017/08/28 23:45:41 Training policy...
2017/08/28 23:45:45 step 0: objective=2.2432587
2017/08/28 23:45:47 step 1: objective=2.2466033
2017/08/28 23:45:49 step 2: objective=2.2521415
2017/08/28 23:45:51 step 3: objective=2.2576714
2017/08/28 23:45:53 step 4: objective=2.2620132
2017/08/28 23:45:55 step 5: objective=2.2664177
2017/08/28 23:45:57 step 6: objective=2.2702987
2017/08/28 23:45:59 step 7: objective=2.2727375
2017/08/28 23:45:59 Training value function...
2017/08/28 23:46:01 step 0: mse=198.307290 step=0.100000
2017/08/28 23:46:02 step 1: mse=192.375334 step=0.100000
2017/08/28 23:46:04 step 2: mse=187.634445 step=0.100000
2017/08/28 23:46:05 step 3: mse=183.524092 step=0.100000
2017/08/28 23:46:06 step 4: mse=179.880836 step=0.100000
2017/08/28 23:46:08 step 5: mse=176.580349 step=0.100000
2017/08/28 23:46:09 step 6: mse=173.801708 step=0.100000
2017/08/28 23:46:10 step 7: mse=171.328071 step=0.100000
2017/08/28 23:46:10 Saving...
2017/08/28 23:46:10 Gathering batch of experience...
2017/08/28 23:46:55 batch 758: mean=144.358974 stddev=118.807642 entropy=0.344486 frames=5517 count=39
2017/08/28 23:46:55 Training policy...
2017/08/28 23:46:59 step 0: objective=0.6718275
2017/08/28 23:47:01 step 1: objective=0.6774796
2017/08/28 23:47:02 step 2: objective=0.6832844
2017/08/28 23:47:04 step 3: objective=0.68680084
2017/08/28 23:47:06 step 4: objective=0.6916737
2017/08/28 23:47:08 step 5: objective=0.69869286
2017/08/28 23:47:09 step 6: objective=0.70189667
2017/08/28 23:47:11 step 7: objective=0.7045427
2017/08/28 23:47:11 Training value function...
2017/08/28 23:47:13 step 0: mse=158.583280 step=0.100000
2017/08/28 23:47:15 step 1: mse=154.674286 step=0.100000
2017/08/28 23:47:16 step 2: mse=151.443236 step=0.100000
2017/08/28 23:47:17 step 3: mse=148.659638 step=0.100000
2017/08/28 23:47:18 step 4: mse=146.621912 step=0.100000
2017/08/28 23:47:19 step 5: mse=144.815374 step=0.100000
2017/08/28 23:47:20 step 6: mse=143.023425 step=0.100000
2017/08/28 23:47:22 step 7: mse=141.873404 step=0.100000
2017/08/28 23:47:22 Saving...
2017/08/28 23:47:22 Gathering batch of experience...
2017/08/28 23:48:13 batch 759: mean=194.555556 stddev=168.219672 entropy=0.350996 frames=6274 count=36
2017/08/28 23:48:13 Training policy...
2017/08/28 23:48:17 step 0: objective=2.7650924
2017/08/28 23:48:19 step 1: objective=2.774519
2017/08/28 23:48:21 step 2: objective=2.784744
2017/08/28 23:48:23 step 3: objective=2.7885082
2017/08/28 23:48:25 step 4: objective=2.7989085
2017/08/28 23:48:27 step 5: objective=2.8056102
2017/08/28 23:48:29 step 6: objective=2.808762
2017/08/28 23:48:31 step 7: objective=2.815767
2017/08/28 23:48:31 Training value function...
2017/08/28 23:48:34 step 0: mse=248.006832 step=0.100000
2017/08/28 23:48:35 step 1: mse=238.091341 step=0.100000
2017/08/28 23:48:37 step 2: mse=229.550890 step=0.100000
2017/08/28 23:48:38 step 3: mse=222.375832 step=0.100000
2017/08/28 23:48:39 step 4: mse=216.230537 step=0.100000
2017/08/28 23:48:41 step 5: mse=211.062906 step=0.100000
2017/08/28 23:48:42 step 6: mse=206.586656 step=0.100000
2017/08/28 23:48:43 step 7: mse=202.466120 step=0.100000
2017/08/28 23:48:43 Saving...
2017/08/28 23:48:43 Gathering batch of experience...
2017/08/28 23:49:28 batch 760: mean=152.026316 stddev=133.152561 entropy=0.347920 frames=5716 count=38
2017/08/28 23:49:28 Training policy...
2017/08/28 23:49:32 step 0: objective=-0.060390912
2017/08/28 23:49:34 step 1: objective=-0.055241965
2017/08/28 23:49:36 step 2: objective=-0.04949878
2017/08/28 23:49:38 step 3: objective=-0.040638242
2017/08/28 23:49:40 step 4: objective=-0.03549935
2017/08/28 23:49:41 step 5: objective=-0.029353937
2017/08/28 23:49:43 step 6: objective=-0.02269637
2017/08/28 23:49:45 step 7: objective=-0.018331388
2017/08/28 23:49:45 Training value function...
2017/08/28 23:49:47 step 0: mse=190.810143 step=0.100000
2017/08/28 23:49:49 step 1: mse=186.240079 step=0.100000
2017/08/28 23:49:50 step 2: mse=183.444534 step=0.100000
2017/08/28 23:49:51 step 3: mse=180.132435 step=0.100000
2017/08/28 23:49:52 step 4: mse=177.576595 step=0.100000
2017/08/28 23:49:53 step 5: mse=175.286066 step=0.100000
2017/08/28 23:49:55 step 6: mse=173.788182 step=0.100000
2017/08/28 23:49:56 step 7: mse=172.552830 step=0.100000
2017/08/28 23:49:56 Saving...
2017/08/28 23:49:56 Gathering batch of experience...
2017/08/28 23:50:39 batch 761: mean=148.459459 stddev=115.272086 entropy=0.336580 frames=5308 count=37
2017/08/28 23:50:39 Training policy...
2017/08/28 23:50:44 step 0: objective=0.7536503
2017/08/28 23:50:45 step 1: objective=0.75906277
2017/08/28 23:50:47 step 2: objective=0.7671273
2017/08/28 23:50:49 step 3: objective=0.7728954
2017/08/28 23:50:50 step 4: objective=0.77812225
2017/08/28 23:50:52 step 5: objective=0.78437966
2017/08/28 23:50:54 step 6: objective=0.7880401
2017/08/28 23:50:55 step 7: objective=0.7903016
2017/08/28 23:50:55 Training value function...
2017/08/28 23:50:58 step 0: mse=154.053896 step=0.100000
2017/08/28 23:50:59 step 1: mse=152.569237 step=0.100000
2017/08/28 23:51:00 step 2: mse=150.990720 step=0.100000
2017/08/28 23:51:01 step 3: mse=149.772949 step=0.100000
2017/08/28 23:51:02 step 4: mse=149.206551 step=0.100000
2017/08/28 23:51:03 step 5: mse=148.388348 step=0.100000
2017/08/28 23:51:04 step 6: mse=147.275995 step=0.100000
2017/08/28 23:51:05 step 7: mse=146.290798 step=0.100000
2017/08/28 23:51:05 Saving...
2017/08/28 23:51:06 Gathering batch of experience...
2017/08/28 23:51:52 batch 762: mean=197.424242 stddev=159.824531 entropy=0.348661 frames=6166 count=33
2017/08/28 23:51:52 Training policy...
2017/08/28 23:51:57 step 0: objective=1.7245008
2017/08/28 23:51:59 step 1: objective=1.7285721
2017/08/28 23:52:01 step 2: objective=1.7329098
2017/08/28 23:52:03 step 3: objective=1.7369672
2017/08/28 23:52:05 step 4: objective=1.7398676
2017/08/28 23:52:07 step 5: objective=1.7425188
2017/08/28 23:52:09 step 6: objective=1.7457162
2017/08/28 23:52:11 step 7: objective=1.7487544
2017/08/28 23:52:11 Training value function...
2017/08/28 23:52:13 step 0: mse=179.336950 step=0.100000
2017/08/28 23:52:15 step 1: mse=174.092804 step=0.100000
2017/08/28 23:52:16 step 2: mse=169.744705 step=0.100000
2017/08/28 23:52:17 step 3: mse=165.959952 step=0.100000
2017/08/28 23:52:19 step 4: mse=162.652562 step=0.100000
2017/08/28 23:52:20 step 5: mse=159.585471 step=0.100000
2017/08/28 23:52:21 step 6: mse=157.436967 step=0.100000
2017/08/28 23:52:23 step 7: mse=155.068158 step=0.100000
2017/08/28 23:52:23 Saving...
2017/08/28 23:52:23 Gathering batch of experience...
2017/08/28 23:53:07 batch 763: mean=132.121951 stddev=136.520560 entropy=0.347766 frames=5439 count=41
2017/08/28 23:53:07 Training policy...
2017/08/28 23:53:11 step 0: objective=-0.09863153
2017/08/28 23:53:13 step 1: objective=-0.09175551
2017/08/28 23:53:15 step 2: objective=-0.08487624
2017/08/28 23:53:17 step 3: objective=-0.078900516
2017/08/28 23:53:18 step 4: objective=-0.075300924
2017/08/28 23:53:20 step 5: objective=-0.07311047
2017/08/28 23:53:22 step 6: objective=-0.06532279
2017/08/28 23:53:24 step 7: objective=-0.060708523
2017/08/28 23:53:24 Training value function...
2017/08/28 23:53:26 step 0: mse=142.020451 step=0.100000
2017/08/28 23:53:27 step 1: mse=138.873431 step=0.100000
2017/08/28 23:53:28 step 2: mse=136.375459 step=0.100000
2017/08/28 23:53:29 step 3: mse=134.282767 step=0.100000
2017/08/28 23:53:31 step 4: mse=132.697690 step=0.100000
2017/08/28 23:53:32 step 5: mse=131.370213 step=0.100000
2017/08/28 23:53:33 step 6: mse=130.105831 step=0.100000
2017/08/28 23:53:34 step 7: mse=128.686066 step=0.100000
2017/08/28 23:53:34 Saving...
2017/08/28 23:53:34 Gathering batch of experience...
2017/08/28 23:54:18 batch 764: mean=148.564103 stddev=119.017731 entropy=0.338741 frames=5360 count=39
2017/08/28 23:54:18 Training policy...
2017/08/28 23:54:22 step 0: objective=1.6090529
2017/08/28 23:54:24 step 1: objective=1.6193993
2017/08/28 23:54:25 step 2: objective=1.626713
2017/08/28 23:54:27 step 3: objective=1.6310532
2017/08/28 23:54:29 step 4: objective=1.6360102
2017/08/28 23:54:30 step 5: objective=1.6419913
2017/08/28 23:54:32 step 6: objective=1.6454967
2017/08/28 23:54:34 step 7: objective=1.6518868
2017/08/28 23:54:34 Training value function...
2017/08/28 23:54:36 step 0: mse=173.084455 step=0.100000
2017/08/28 23:54:37 step 1: mse=169.682620 step=0.100000
2017/08/28 23:54:38 step 2: mse=166.768810 step=0.100000
2017/08/28 23:54:39 step 3: mse=164.322110 step=0.100000
2017/08/28 23:54:40 step 4: mse=162.267349 step=0.100000
2017/08/28 23:54:42 step 5: mse=160.407933 step=0.100000
2017/08/28 23:54:43 step 6: mse=159.082646 step=0.100000
2017/08/28 23:54:44 step 7: mse=157.238442 step=0.100000
2017/08/28 23:54:44 Saving...
2017/08/28 23:54:44 Gathering batch of experience...
2017/08/28 23:55:26 batch 765: mean=147.270270 stddev=113.044514 entropy=0.350014 frames=5336 count=37
2017/08/28 23:55:26 Training policy...
2017/08/28 23:55:30 step 0: objective=0.7263788
2017/08/28 23:55:32 step 1: objective=0.73410535
2017/08/28 23:55:34 step 2: objective=0.7398087
2017/08/28 23:55:35 step 3: objective=0.74632776
2017/08/28 23:55:37 step 4: objective=0.75214577
2017/08/28 23:55:39 step 5: objective=0.75501305
2017/08/28 23:55:40 step 6: objective=0.7582203
2017/08/28 23:55:42 step 7: objective=0.7622392
2017/08/28 23:55:42 Training value function...
2017/08/28 23:55:44 step 0: mse=158.322606 step=0.100000
2017/08/28 23:55:45 step 1: mse=156.015860 step=0.100000
2017/08/28 23:55:47 step 2: mse=154.179505 step=0.100000
2017/08/28 23:55:48 step 3: mse=152.664561 step=0.100000
2017/08/28 23:55:49 step 4: mse=151.511554 step=0.100000
2017/08/28 23:55:50 step 5: mse=150.412535 step=0.100000
2017/08/28 23:55:51 step 6: mse=149.243928 step=0.100000
2017/08/28 23:55:52 step 7: mse=148.529571 step=0.100000
2017/08/28 23:55:52 Saving...
2017/08/28 23:55:52 Gathering batch of experience...
2017/08/28 23:56:38 batch 766: mean=177.000000 stddev=129.271586 entropy=0.350962 frames=5635 count=35
2017/08/28 23:56:38 Training policy...
2017/08/28 23:56:42 step 0: objective=2.0802324
2017/08/28 23:56:44 step 1: objective=2.0872736
2017/08/28 23:56:46 step 2: objective=2.0925918
2017/08/28 23:56:48 step 3: objective=2.0999193
2017/08/28 23:56:50 step 4: objective=2.104224
2017/08/28 23:56:51 step 5: objective=2.1111097
2017/08/28 23:56:53 step 6: objective=2.1147623
2017/08/28 23:56:55 step 7: objective=2.1188154
2017/08/28 23:56:55 Training value function...
2017/08/28 23:56:57 step 0: mse=169.385598 step=0.100000
2017/08/28 23:56:59 step 1: mse=165.302988 step=0.100000
2017/08/28 23:57:00 step 2: mse=161.379395 step=0.100000
2017/08/28 23:57:01 step 3: mse=158.214222 step=0.100000
2017/08/28 23:57:02 step 4: mse=155.583716 step=0.100000
2017/08/28 23:57:03 step 5: mse=152.805551 step=0.100000
2017/08/28 23:57:04 step 6: mse=150.699434 step=0.100000
2017/08/28 23:57:06 step 7: mse=148.537715 step=0.100000
2017/08/28 23:57:06 Saving...
2017/08/28 23:57:06 Gathering batch of experience...
2017/08/28 23:57:48 batch 767: mean=137.736842 stddev=106.957366 entropy=0.348622 frames=5298 count=38
2017/08/28 23:57:48 Training policy...
2017/08/28 23:57:52 step 0: objective=-0.17498748
2017/08/28 23:57:53 step 1: objective=-0.16576828
2017/08/28 23:57:55 step 2: objective=-0.15649736
2017/08/28 23:57:57 step 3: objective=-0.1492437
2017/08/28 23:57:59 step 4: objective=-0.14298612
2017/08/28 23:58:00 step 5: objective=-0.13985643
2017/08/28 23:58:02 step 6: objective=-0.13518246
2017/08/28 23:58:04 step 7: objective=-0.13189994
2017/08/28 23:58:04 Training value function...
2017/08/28 23:58:06 step 0: mse=144.975463 step=0.100000
2017/08/28 23:58:07 step 1: mse=141.359202 step=0.100000
2017/08/28 23:58:08 step 2: mse=138.783525 step=0.100000
2017/08/28 23:58:09 step 3: mse=136.594639 step=0.100000
2017/08/28 23:58:10 step 4: mse=134.813565 step=0.100000
2017/08/28 23:58:12 step 5: mse=133.170613 step=0.100000
2017/08/28 23:58:13 step 6: mse=131.887467 step=0.100000
2017/08/28 23:58:14 step 7: mse=130.844957 step=0.100000
2017/08/28 23:58:14 Saving...
2017/08/28 23:58:14 Gathering batch of experience...
2017/08/28 23:58:57 batch 768: mean=160.333333 stddev=151.724897 entropy=0.348274 frames=5363 count=36
2017/08/28 23:58:57 Training policy...
2017/08/28 23:59:01 step 0: objective=2.1169035
2017/08/28 23:59:02 step 1: objective=2.1286862
2017/08/28 23:59:04 step 2: objective=2.135392
2017/08/28 23:59:06 step 3: objective=2.1426032
2017/08/28 23:59:08 step 4: objective=2.1484299
2017/08/28 23:59:09 step 5: objective=2.1516569
2017/08/28 23:59:11 step 6: objective=2.1555407
2017/08/28 23:59:13 step 7: objective=2.1585479
2017/08/28 23:59:13 Training value function...
2017/08/28 23:59:15 step 0: mse=186.766125 step=0.100000
2017/08/28 23:59:16 step 1: mse=178.411388 step=0.100000
2017/08/28 23:59:17 step 2: mse=171.664851 step=0.100000
2017/08/28 23:59:19 step 3: mse=165.929673 step=0.100000
2017/08/28 23:59:20 step 4: mse=161.049085 step=0.100000
2017/08/28 23:59:21 step 5: mse=157.049471 step=0.100000
2017/08/28 23:59:22 step 6: mse=153.653343 step=0.100000
2017/08/28 23:59:23 step 7: mse=150.726640 step=0.100000
2017/08/28 23:59:23 Saving...
2017/08/28 23:59:23 Gathering batch of experience...
2017/08/29 00:00:07 batch 769: mean=175.028571 stddev=139.024661 entropy=0.349991 frames=5985 count=35
2017/08/29 00:00:07 Training policy...
2017/08/29 00:00:12 step 0: objective=0.97640896
2017/08/29 00:00:14 step 1: objective=0.98217446
2017/08/29 00:00:16 step 2: objective=0.9858295
2017/08/29 00:00:18 step 3: objective=0.9891435
2017/08/29 00:00:20 step 4: objective=0.99278647
2017/08/29 00:00:22 step 5: objective=0.9987078
2017/08/29 00:00:24 step 6: objective=1.0026166
2017/08/29 00:00:26 step 7: objective=1.0078268
2017/08/29 00:00:26 Training value function...
2017/08/29 00:00:28 step 0: mse=162.146179 step=0.100000
2017/08/29 00:00:29 step 1: mse=158.397690 step=0.100000
2017/08/29 00:00:31 step 2: mse=155.488951 step=0.100000
2017/08/29 00:00:32 step 3: mse=152.818355 step=0.100000
2017/08/29 00:00:33 step 4: mse=150.710861 step=0.100000
2017/08/29 00:00:34 step 5: mse=148.719924 step=0.100000
2017/08/29 00:00:36 step 6: mse=147.108841 step=0.100000
2017/08/29 00:00:37 step 7: mse=145.394159 step=0.100000
2017/08/29 00:00:37 Saving...
2017/08/29 00:00:37 Gathering batch of experience...
2017/08/29 00:01:25 batch 770: mean=218.484848 stddev=160.789741 entropy=0.357295 frames=6601 count=33
2017/08/29 00:01:25 Training policy...
2017/08/29 00:01:30 step 0: objective=2.250986
2017/08/29 00:01:32 step 1: objective=2.2552936
2017/08/29 00:01:34 step 2: objective=2.2586524
2017/08/29 00:01:36 step 3: objective=2.263774
2017/08/29 00:01:39 step 4: objective=2.2678409
2017/08/29 00:01:41 step 5: objective=2.2717555
2017/08/29 00:01:43 step 6: objective=2.2762678
2017/08/29 00:01:45 step 7: objective=2.2792869
2017/08/29 00:01:45 Training value function...
2017/08/29 00:01:48 step 0: mse=197.096851 step=0.100000
2017/08/29 00:01:49 step 1: mse=191.041117 step=0.100000
2017/08/29 00:01:51 step 2: mse=185.425744 step=0.100000
2017/08/29 00:01:52 step 3: mse=181.680183 step=0.100000
2017/08/29 00:01:53 step 4: mse=177.809302 step=0.100000
2017/08/29 00:01:55 step 5: mse=174.316536 step=0.100000
2017/08/29 00:01:56 step 6: mse=171.652154 step=0.100000
2017/08/29 00:01:58 step 7: mse=168.914092 step=0.100000
2017/08/29 00:01:58 Saving...
2017/08/29 00:01:58 Gathering batch of experience...
2017/08/29 00:02:44 batch 771: mean=177.210526 stddev=171.419025 entropy=0.352551 frames=6050 count=38
2017/08/29 00:02:44 Training policy...
2017/08/29 00:02:49 step 0: objective=1.477835
2017/08/29 00:02:51 step 1: objective=1.4890202
2017/08/29 00:02:53 step 2: objective=1.4959241
2017/08/29 00:02:55 step 3: objective=1.503149
2017/08/29 00:02:57 step 4: objective=1.5088017
2017/08/29 00:02:59 step 5: objective=1.5143374
2017/08/29 00:03:01 step 6: objective=1.5165719
2017/08/29 00:03:03 step 7: objective=1.5197837
2017/08/29 00:03:03 Training value function...
2017/08/29 00:03:05 step 0: mse=187.937440 step=0.100000
2017/08/29 00:03:06 step 1: mse=183.372751 step=0.100000
2017/08/29 00:03:08 step 2: mse=178.736274 step=0.100000
2017/08/29 00:03:09 step 3: mse=175.061117 step=0.100000
2017/08/29 00:03:10 step 4: mse=171.860593 step=0.100000
2017/08/29 00:03:12 step 5: mse=169.334007 step=0.100000
2017/08/29 00:03:13 step 6: mse=167.200039 step=0.100000
2017/08/29 00:03:14 step 7: mse=164.926624 step=0.100000
2017/08/29 00:03:14 Saving...
2017/08/29 00:03:14 Gathering batch of experience...
2017/08/29 00:04:05 batch 772: mean=154.769231 stddev=120.661948 entropy=0.345404 frames=5928 count=39
2017/08/29 00:04:05 Training policy...
2017/08/29 00:04:09 step 0: objective=-0.09949846
2017/08/29 00:04:11 step 1: objective=-0.094668135
2017/08/29 00:04:13 step 2: objective=-0.0864002
2017/08/29 00:04:15 step 3: objective=-0.075430684
2017/08/29 00:04:17 step 4: objective=-0.07039953
2017/08/29 00:04:19 step 5: objective=-0.0671619
2017/08/29 00:04:21 step 6: objective=-0.063082725
2017/08/29 00:04:23 step 7: objective=-0.057538506
2017/08/29 00:04:23 Training value function...
2017/08/29 00:04:25 step 0: mse=175.540576 step=0.100000
2017/08/29 00:04:26 step 1: mse=170.866175 step=0.100000
2017/08/29 00:04:28 step 2: mse=166.823402 step=0.100000
2017/08/29 00:04:29 step 3: mse=164.079608 step=0.100000
2017/08/29 00:04:30 step 4: mse=161.745467 step=0.100000
2017/08/29 00:04:31 step 5: mse=160.221189 step=0.100000
2017/08/29 00:04:33 step 6: mse=158.601010 step=0.100000
2017/08/29 00:04:34 step 7: mse=157.254480 step=0.100000
2017/08/29 00:04:34 Saving...
2017/08/29 00:04:34 Gathering batch of experience...
2017/08/29 00:05:18 batch 773: mean=159.205128 stddev=144.121242 entropy=0.349339 frames=5828 count=39
2017/08/29 00:05:18 Training policy...
2017/08/29 00:05:22 step 0: objective=1.0541652
2017/08/29 00:05:24 step 1: objective=1.0628065
2017/08/29 00:05:26 step 2: objective=1.0698735
2017/08/29 00:05:28 step 3: objective=1.075754
2017/08/29 00:05:30 step 4: objective=1.079507
2017/08/29 00:05:32 step 5: objective=1.0828955
2017/08/29 00:05:34 step 6: objective=1.0881479
2017/08/29 00:05:36 step 7: objective=1.0943202
2017/08/29 00:05:36 Training value function...
2017/08/29 00:05:38 step 0: mse=195.400871 step=0.100000
2017/08/29 00:05:39 step 1: mse=191.556645 step=0.100000
2017/08/29 00:05:40 step 2: mse=188.447359 step=0.100000
2017/08/29 00:05:42 step 3: mse=185.698249 step=0.100000
2017/08/29 00:05:43 step 4: mse=183.266718 step=0.100000
2017/08/29 00:05:44 step 5: mse=181.215771 step=0.100000
2017/08/29 00:05:45 step 6: mse=179.349320 step=0.100000
2017/08/29 00:05:47 step 7: mse=177.604528 step=0.100000
2017/08/29 00:05:47 Saving...
2017/08/29 00:05:47 Gathering batch of experience...
2017/08/29 00:06:32 batch 774: mean=187.312500 stddev=135.249639 entropy=0.351967 frames=5750 count=32
2017/08/29 00:06:32 Training policy...
2017/08/29 00:06:36 step 0: objective=1.1629541
2017/08/29 00:06:38 step 1: objective=1.1709096
2017/08/29 00:06:40 step 2: objective=1.1759691
2017/08/29 00:06:42 step 3: objective=1.1809716
2017/08/29 00:06:44 step 4: objective=1.1850975
2017/08/29 00:06:45 step 5: objective=1.1894369
2017/08/29 00:06:47 step 6: objective=1.1931297
2017/08/29 00:06:49 step 7: objective=1.1953586
2017/08/29 00:06:49 Training value function...
2017/08/29 00:06:51 step 0: mse=133.670984 step=0.100000
2017/08/29 00:06:53 step 1: mse=129.801638 step=0.100000
2017/08/29 00:06:54 step 2: mse=126.712391 step=0.100000
2017/08/29 00:06:55 step 3: mse=124.080500 step=0.100000
2017/08/29 00:06:56 step 4: mse=121.880361 step=0.100000
2017/08/29 00:06:58 step 5: mse=119.963728 step=0.100000
2017/08/29 00:06:59 step 6: mse=118.350582 step=0.100000
2017/08/29 00:07:00 step 7: mse=116.975169 step=0.100000
2017/08/29 00:07:00 Saving...
2017/08/29 00:07:00 Gathering batch of experience...
2017/08/29 00:07:51 batch 775: mean=158.146341 stddev=115.313478 entropy=0.342281 frames=6280 count=41
2017/08/29 00:07:51 Training policy...
2017/08/29 00:07:56 step 0: objective=0.48611054
2017/08/29 00:07:58 step 1: objective=0.4935005
2017/08/29 00:08:00 step 2: objective=0.49965525
2017/08/29 00:08:02 step 3: objective=0.5066452
2017/08/29 00:08:04 step 4: objective=0.5116295
2017/08/29 00:08:06 step 5: objective=0.51447576
2017/08/29 00:08:08 step 6: objective=0.5184338
2017/08/29 00:08:10 step 7: objective=0.52104676
2017/08/29 00:08:10 Training value function...
2017/08/29 00:08:13 step 0: mse=142.153560 step=0.100000
2017/08/29 00:08:14 step 1: mse=140.511203 step=0.100000
2017/08/29 00:08:16 step 2: mse=139.480392 step=0.100000
2017/08/29 00:08:17 step 3: mse=138.416343 step=0.100000
2017/08/29 00:08:18 step 4: mse=137.423676 step=0.100000
2017/08/29 00:08:20 step 5: mse=136.844679 step=0.100000
2017/08/29 00:08:21 step 6: mse=136.394837 step=0.100000
2017/08/29 00:08:22 step 7: mse=135.681784 step=0.100000
2017/08/29 00:08:22 Saving...
2017/08/29 00:08:22 Gathering batch of experience...
2017/08/29 00:09:01 batch 776: mean=166.909091 stddev=100.150603 entropy=0.343185 frames=5078 count=33
2017/08/29 00:09:01 Training policy...
2017/08/29 00:09:05 step 0: objective=1.3673369
2017/08/29 00:09:07 step 1: objective=1.3848375
2017/08/29 00:09:09 step 2: objective=1.3921472
2017/08/29 00:09:10 step 3: objective=1.4032896
2017/08/29 00:09:12 step 4: objective=1.4092405
2017/08/29 00:09:14 step 5: objective=1.4136481
2017/08/29 00:09:15 step 6: objective=1.416935
2017/08/29 00:09:17 step 7: objective=1.4203978
2017/08/29 00:09:17 Training value function...
2017/08/29 00:09:19 step 0: mse=164.882905 step=0.100000
2017/08/29 00:09:20 step 1: mse=160.963306 step=0.100000
2017/08/29 00:09:21 step 2: mse=157.487014 step=0.100000
2017/08/29 00:09:22 step 3: mse=154.618629 step=0.100000
2017/08/29 00:09:23 step 4: mse=151.896918 step=0.100000
2017/08/29 00:09:24 step 5: mse=149.761095 step=0.100000
2017/08/29 00:09:25 step 6: mse=147.725877 step=0.100000
2017/08/29 00:09:26 step 7: mse=146.248190 step=0.100000
2017/08/29 00:09:26 Saving...
2017/08/29 00:09:26 Gathering batch of experience...
2017/08/29 00:10:18 batch 777: mean=158.853659 stddev=139.665727 entropy=0.347051 frames=6388 count=41
2017/08/29 00:10:18 Training policy...
2017/08/29 00:10:23 step 0: objective=0.72456604
2017/08/29 00:10:25 step 1: objective=0.7319122
2017/08/29 00:10:27 step 2: objective=0.74172986
2017/08/29 00:10:29 step 3: objective=0.7447234
2017/08/29 00:10:31 step 4: objective=0.74830365
2017/08/29 00:10:33 step 5: objective=0.75251645
2017/08/29 00:10:35 step 6: objective=0.7553532
2017/08/29 00:10:37 step 7: objective=0.7574391
2017/08/29 00:10:37 Training value function...
2017/08/29 00:10:40 step 0: mse=161.909097 step=0.100000
2017/08/29 00:10:41 step 1: mse=158.300754 step=0.100000
2017/08/29 00:10:43 step 2: mse=155.282669 step=0.100000
2017/08/29 00:10:44 step 3: mse=152.856909 step=0.100000
2017/08/29 00:10:45 step 4: mse=150.969690 step=0.100000
2017/08/29 00:10:47 step 5: mse=149.054656 step=0.100000
2017/08/29 00:10:48 step 6: mse=147.579176 step=0.100000
2017/08/29 00:10:49 step 7: mse=146.342358 step=0.100000
2017/08/29 00:10:49 Saving...
2017/08/29 00:10:49 Gathering batch of experience...
2017/08/29 00:11:40 batch 778: mean=168.073171 stddev=150.794868 entropy=0.341049 frames=6550 count=41
2017/08/29 00:11:40 Training policy...
2017/08/29 00:11:45 step 0: objective=1.4143523
2017/08/29 00:11:48 step 1: objective=1.4179817
2017/08/29 00:11:50 step 2: objective=1.4225689
2017/08/29 00:11:52 step 3: objective=1.4258994
2017/08/29 00:11:54 step 4: objective=1.4322882
2017/08/29 00:11:56 step 5: objective=1.4400619
2017/08/29 00:11:58 step 6: objective=1.4446343
2017/08/29 00:12:01 step 7: objective=1.4477009
2017/08/29 00:12:01 Training value function...
2017/08/29 00:12:03 step 0: mse=181.411474 step=0.100000
2017/08/29 00:12:05 step 1: mse=177.646497 step=0.100000
2017/08/29 00:12:06 step 2: mse=174.699030 step=0.100000
2017/08/29 00:12:07 step 3: mse=171.788531 step=0.100000
2017/08/29 00:12:09 step 4: mse=169.611508 step=0.100000
2017/08/29 00:12:10 step 5: mse=167.373533 step=0.100000
2017/08/29 00:12:11 step 6: mse=165.310811 step=0.100000
2017/08/29 00:12:13 step 7: mse=163.571678 step=0.100000
2017/08/29 00:12:13 Saving...
2017/08/29 00:12:13 Gathering batch of experience...
2017/08/29 00:12:57 batch 779: mean=162.527778 stddev=115.072317 entropy=0.343098 frames=5816 count=36
2017/08/29 00:12:57 Training policy...
2017/08/29 00:13:02 step 0: objective=0.6675609
2017/08/29 00:13:04 step 1: objective=0.675076
2017/08/29 00:13:06 step 2: objective=0.6800737
2017/08/29 00:13:08 step 3: objective=0.6863013
2017/08/29 00:13:10 step 4: objective=0.6907905
2017/08/29 00:13:11 step 5: objective=0.6962234
2017/08/29 00:13:13 step 6: objective=0.69945055
2017/08/29 00:13:15 step 7: objective=0.7031864
2017/08/29 00:13:15 Training value function...
2017/08/29 00:13:18 step 0: mse=151.697887 step=0.100000
2017/08/29 00:13:19 step 1: mse=149.089329 step=0.100000
2017/08/29 00:13:20 step 2: mse=147.350268 step=0.100000
2017/08/29 00:13:21 step 3: mse=145.623904 step=0.100000
2017/08/29 00:13:22 step 4: mse=144.275548 step=0.100000
2017/08/29 00:13:24 step 5: mse=143.030196 step=0.100000
2017/08/29 00:13:25 step 6: mse=142.074402 step=0.100000
2017/08/29 00:13:26 step 7: mse=141.035866 step=0.100000
2017/08/29 00:13:26 Saving...
2017/08/29 00:13:26 Gathering batch of experience...
2017/08/29 00:14:16 batch 780: mean=164.513514 stddev=126.799399 entropy=0.331301 frames=5857 count=37
2017/08/29 00:14:16 Training policy...
2017/08/29 00:14:20 step 0: objective=1.1986555
2017/08/29 00:14:22 step 1: objective=1.204643
2017/08/29 00:14:24 step 2: objective=1.2109593
2017/08/29 00:14:26 step 3: objective=1.2187412
2017/08/29 00:14:28 step 4: objective=1.2227829
2017/08/29 00:14:30 step 5: objective=1.2289336
2017/08/29 00:14:32 step 6: objective=1.2332197
2017/08/29 00:14:34 step 7: objective=1.2374611
2017/08/29 00:14:34 Training value function...
2017/08/29 00:14:36 step 0: mse=166.652578 step=0.100000
2017/08/29 00:14:37 step 1: mse=164.088110 step=0.100000
2017/08/29 00:14:38 step 2: mse=162.248696 step=0.100000
2017/08/29 00:14:40 step 3: mse=160.137282 step=0.100000
2017/08/29 00:14:41 step 4: mse=158.338657 step=0.100000
2017/08/29 00:14:42 step 5: mse=156.686335 step=0.100000
2017/08/29 00:14:43 step 6: mse=155.328591 step=0.100000
2017/08/29 00:14:45 step 7: mse=153.889965 step=0.100000
2017/08/29 00:14:45 Saving...
2017/08/29 00:14:45 Gathering batch of experience...
2017/08/29 00:15:33 batch 781: mean=147.175000 stddev=124.248317 entropy=0.333485 frames=5623 count=40
2017/08/29 00:15:33 Training policy...
2017/08/29 00:15:37 step 0: objective=0.86824155
2017/08/29 00:15:39 step 1: objective=0.87358093
2017/08/29 00:15:41 step 2: objective=0.881766
2017/08/29 00:15:43 step 3: objective=0.8887119
2017/08/29 00:15:45 step 4: objective=0.8937054
2017/08/29 00:15:46 step 5: objective=0.90024596
2017/08/29 00:15:48 step 6: objective=0.9047306
2017/08/29 00:15:50 step 7: objective=0.9072883
2017/08/29 00:15:50 Training value function...
2017/08/29 00:15:52 step 0: mse=180.222419 step=0.100000
2017/08/29 00:15:54 step 1: mse=177.435985 step=0.100000
2017/08/29 00:15:55 step 2: mse=175.101656 step=0.100000
2017/08/29 00:15:56 step 3: mse=173.125890 step=0.100000
2017/08/29 00:15:57 step 4: mse=171.363618 step=0.100000
2017/08/29 00:15:58 step 5: mse=169.705579 step=0.100000
2017/08/29 00:16:00 step 6: mse=168.122247 step=0.100000
2017/08/29 00:16:01 step 7: mse=166.891734 step=0.100000
2017/08/29 00:16:01 Saving...
2017/08/29 00:16:01 Gathering batch of experience...
2017/08/29 00:16:49 batch 782: mean=146.465116 stddev=136.728614 entropy=0.344173 frames=5836 count=43
2017/08/29 00:16:49 Training policy...
2017/08/29 00:16:53 step 0: objective=1.4756194
2017/08/29 00:16:55 step 1: objective=1.4878614
2017/08/29 00:16:57 step 2: objective=1.4954331
2017/08/29 00:16:59 step 3: objective=1.500517
2017/08/29 00:17:01 step 4: objective=1.5041761
2017/08/29 00:17:03 step 5: objective=1.5085453
2017/08/29 00:17:05 step 6: objective=1.5144445
2017/08/29 00:17:07 step 7: objective=1.517334
2017/08/29 00:17:07 Training value function...
2017/08/29 00:17:09 step 0: mse=212.170595 step=0.100000
2017/08/29 00:17:10 step 1: mse=204.736298 step=0.100000
2017/08/29 00:17:12 step 2: mse=198.792972 step=0.100000
2017/08/29 00:17:13 step 3: mse=193.885528 step=0.100000
2017/08/29 00:17:14 step 4: mse=189.468231 step=0.100000
2017/08/29 00:17:15 step 5: mse=185.572954 step=0.100000
2017/08/29 00:17:16 step 6: mse=182.423253 step=0.100000
2017/08/29 00:17:18 step 7: mse=179.702065 step=0.100000
2017/08/29 00:17:18 Saving...
2017/08/29 00:17:18 Gathering batch of experience...
2017/08/29 00:18:00 batch 783: mean=175.812500 stddev=158.650055 entropy=0.344141 frames=5417 count=32
2017/08/29 00:18:00 Training policy...
2017/08/29 00:18:04 step 0: objective=1.1368858
2017/08/29 00:18:06 step 1: objective=1.144134
2017/08/29 00:18:07 step 2: objective=1.153212
2017/08/29 00:18:09 step 3: objective=1.158857
2017/08/29 00:18:11 step 4: objective=1.1629013
2017/08/29 00:18:13 step 5: objective=1.1669922
2017/08/29 00:18:14 step 6: objective=1.1741928
2017/08/29 00:18:16 step 7: objective=1.1768135
2017/08/29 00:18:16 Training value function...
2017/08/29 00:18:19 step 0: mse=191.049154 step=0.100000
2017/08/29 00:18:20 step 1: mse=187.518214 step=0.100000
2017/08/29 00:18:21 step 2: mse=184.973976 step=0.100000
2017/08/29 00:18:22 step 3: mse=182.677600 step=0.100000
2017/08/29 00:18:23 step 4: mse=180.783849 step=0.100000
2017/08/29 00:18:24 step 5: mse=178.464197 step=0.100000
2017/08/29 00:18:25 step 6: mse=176.594341 step=0.100000
2017/08/29 00:18:27 step 7: mse=175.209534 step=0.100000
2017/08/29 00:18:27 Saving...
2017/08/29 00:18:27 Gathering batch of experience...
2017/08/29 00:19:10 batch 784: mean=157.131579 stddev=133.166530 entropy=0.341100 frames=5542 count=38
2017/08/29 00:19:10 Training policy...
2017/08/29 00:19:14 step 0: objective=1.1712338
2017/08/29 00:19:16 step 1: objective=1.1792297
2017/08/29 00:19:18 step 2: objective=1.1888709
2017/08/29 00:19:20 step 3: objective=1.1937928
2017/08/29 00:19:22 step 4: objective=1.1975079
2017/08/29 00:19:23 step 5: objective=1.202131
2017/08/29 00:19:25 step 6: objective=1.205723
2017/08/29 00:19:27 step 7: objective=1.2117354
2017/08/29 00:19:27 Training value function...
2017/08/29 00:19:29 step 0: mse=181.053993 step=0.100000
2017/08/29 00:19:30 step 1: mse=179.139640 step=0.100000
2017/08/29 00:19:32 step 2: mse=177.357931 step=0.100000
2017/08/29 00:19:33 step 3: mse=175.941458 step=0.100000
2017/08/29 00:19:34 step 4: mse=173.801224 step=0.100000
2017/08/29 00:19:35 step 5: mse=171.941333 step=0.100000
2017/08/29 00:19:36 step 6: mse=170.596490 step=0.100000
2017/08/29 00:19:37 step 7: mse=169.165920 step=0.100000
2017/08/29 00:19:37 Saving...
2017/08/29 00:19:38 Gathering batch of experience...
2017/08/29 00:20:19 batch 785: mean=164.181818 stddev=136.696180 entropy=0.343036 frames=5212 count=33
2017/08/29 00:20:19 Training policy...
2017/08/29 00:20:23 step 0: objective=0.77770495
2017/08/29 00:20:24 step 1: objective=0.7840724
2017/08/29 00:20:26 step 2: objective=0.78887445
2017/08/29 00:20:28 step 3: objective=0.79692036
2017/08/29 00:20:29 step 4: objective=0.80005294
2017/08/29 00:20:31 step 5: objective=0.8030303
2017/08/29 00:20:33 step 6: objective=0.80573714
2017/08/29 00:20:35 step 7: objective=0.80925244
2017/08/29 00:20:35 Training value function...
2017/08/29 00:20:37 step 0: mse=160.500944 step=0.100000
2017/08/29 00:20:38 step 1: mse=156.002972 step=0.100000
2017/08/29 00:20:39 step 2: mse=152.844246 step=0.100000
2017/08/29 00:20:40 step 3: mse=150.018774 step=0.100000
2017/08/29 00:20:41 step 4: mse=148.014709 step=0.100000
2017/08/29 00:20:42 step 5: mse=146.296781 step=0.100000
2017/08/29 00:20:43 step 6: mse=144.306784 step=0.100000
2017/08/29 00:20:44 step 7: mse=142.820910 step=0.100000
2017/08/29 00:20:44 Saving...
2017/08/29 00:20:45 Gathering batch of experience...
2017/08/29 00:21:29 batch 786: mean=157.837838 stddev=126.831771 entropy=0.346132 frames=5689 count=37
2017/08/29 00:21:29 Training policy...
2017/08/29 00:21:33 step 0: objective=0.6124784
2017/08/29 00:21:35 step 1: objective=0.61978734
2017/08/29 00:21:37 step 2: objective=0.6275749
2017/08/29 00:21:39 step 3: objective=0.63407344
2017/08/29 00:21:40 step 4: objective=0.6392327
2017/08/29 00:21:42 step 5: objective=0.643503
2017/08/29 00:21:44 step 6: objective=0.6471726
2017/08/29 00:21:46 step 7: objective=0.6514232
2017/08/29 00:21:46 Training value function...
2017/08/29 00:21:48 step 0: mse=169.088970 step=0.100000
2017/08/29 00:21:50 step 1: mse=166.396563 step=0.100000
2017/08/29 00:21:51 step 2: mse=164.466644 step=0.100000
2017/08/29 00:21:52 step 3: mse=162.632284 step=0.100000
2017/08/29 00:21:53 step 4: mse=161.106534 step=0.100000
2017/08/29 00:21:54 step 5: mse=159.776120 step=0.100000
2017/08/29 00:21:56 step 6: mse=158.650563 step=0.100000
2017/08/29 00:21:57 step 7: mse=157.595909 step=0.100000
2017/08/29 00:21:57 Saving...
2017/08/29 00:21:57 Gathering batch of experience...
2017/08/29 00:22:40 batch 787: mean=151.102564 stddev=143.732264 entropy=0.341308 frames=5469 count=39
2017/08/29 00:22:40 Training policy...
2017/08/29 00:22:44 step 0: objective=1.5071598
2017/08/29 00:22:46 step 1: objective=1.5156871
2017/08/29 00:22:48 step 2: objective=1.5302341
2017/08/29 00:22:49 step 3: objective=1.5374619
2017/08/29 00:22:51 step 4: objective=1.5438619
2017/08/29 00:22:53 step 5: objective=1.5528537
2017/08/29 00:22:55 step 6: objective=1.5592428
2017/08/29 00:22:57 step 7: objective=1.5624527
2017/08/29 00:22:57 Training value function...
2017/08/29 00:22:59 step 0: mse=187.810946 step=0.100000
2017/08/29 00:23:00 step 1: mse=184.202498 step=0.100000
2017/08/29 00:23:01 step 2: mse=180.832069 step=0.100000
2017/08/29 00:23:02 step 3: mse=178.000173 step=0.100000
2017/08/29 00:23:04 step 4: mse=175.053447 step=0.100000
2017/08/29 00:23:05 step 5: mse=172.754285 step=0.100000
2017/08/29 00:23:06 step 6: mse=170.433907 step=0.100000
2017/08/29 00:23:07 step 7: mse=168.302204 step=0.100000
2017/08/29 00:23:07 Saving...
2017/08/29 00:23:07 Gathering batch of experience...
2017/08/29 00:23:50 batch 788: mean=130.500000 stddev=101.032173 entropy=0.331957 frames=5154 count=40
2017/08/29 00:23:50 Training policy...
2017/08/29 00:23:54 step 0: objective=-0.123855844
2017/08/29 00:23:55 step 1: objective=-0.116590835
2017/08/29 00:23:57 step 2: objective=-0.104760855
2017/08/29 00:23:59 step 3: objective=-0.09686738
2017/08/29 00:24:00 step 4: objective=-0.091802776
2017/08/29 00:24:02 step 5: objective=-0.08713692
2017/08/29 00:24:04 step 6: objective=-0.08312376
2017/08/29 00:24:05 step 7: objective=-0.079680435
2017/08/29 00:24:05 Training value function...
2017/08/29 00:24:08 step 0: mse=177.204403 step=0.100000
2017/08/29 00:24:09 step 1: mse=173.996707 step=0.100000
2017/08/29 00:24:10 step 2: mse=171.434705 step=0.100000
2017/08/29 00:24:11 step 3: mse=169.223326 step=0.100000
2017/08/29 00:24:12 step 4: mse=167.309501 step=0.100000
2017/08/29 00:24:13 step 5: mse=166.019608 step=0.100000
2017/08/29 00:24:14 step 6: mse=164.968809 step=0.100000
2017/08/29 00:24:15 step 7: mse=163.744258 step=0.100000
2017/08/29 00:24:15 Saving...
2017/08/29 00:24:15 Gathering batch of experience...
2017/08/29 00:24:56 batch 789: mean=143.486486 stddev=121.371358 entropy=0.328800 frames=5240 count=37
2017/08/29 00:24:56 Training policy...
2017/08/29 00:25:00 step 0: objective=0.9993706
2017/08/29 00:25:02 step 1: objective=1.0046955
2017/08/29 00:25:04 step 2: objective=1.0116067
2017/08/29 00:25:05 step 3: objective=1.0176243
2017/08/29 00:25:07 step 4: objective=1.0213566
2017/08/29 00:25:09 step 5: objective=1.0265989
2017/08/29 00:25:11 step 6: objective=1.0321965
2017/08/29 00:25:12 step 7: objective=1.0356929
2017/08/29 00:25:12 Training value function...
2017/08/29 00:25:14 step 0: mse=155.102432 step=0.100000
2017/08/29 00:25:16 step 1: mse=152.208508 step=0.100000
2017/08/29 00:25:17 step 2: mse=149.467990 step=0.100000
2017/08/29 00:25:18 step 3: mse=147.198827 step=0.100000
2017/08/29 00:25:19 step 4: mse=145.120752 step=0.100000
2017/08/29 00:25:20 step 5: mse=143.440305 step=0.100000
2017/08/29 00:25:21 step 6: mse=141.971399 step=0.100000
2017/08/29 00:25:22 step 7: mse=140.773915 step=0.100000
2017/08/29 00:25:22 Saving...
2017/08/29 00:25:22 Gathering batch of experience...
2017/08/29 00:26:16 batch 790: mean=193.470588 stddev=152.793639 entropy=0.343964 frames=6317 count=34
2017/08/29 00:26:16 Training policy...
2017/08/29 00:26:21 step 0: objective=1.9269948
2017/08/29 00:26:23 step 1: objective=1.933951
2017/08/29 00:26:26 step 2: objective=1.9399241
2017/08/29 00:26:28 step 3: objective=1.9445093
2017/08/29 00:26:30 step 4: objective=1.9480745
2017/08/29 00:26:32 step 5: objective=1.9510212
2017/08/29 00:26:34 step 6: objective=1.9551499
2017/08/29 00:26:36 step 7: objective=1.957072
2017/08/29 00:26:36 Training value function...
2017/08/29 00:26:39 step 0: mse=176.208606 step=0.100000
2017/08/29 00:26:40 step 1: mse=170.052427 step=0.100000
2017/08/29 00:26:41 step 2: mse=164.493544 step=0.100000
2017/08/29 00:26:43 step 3: mse=160.440128 step=0.100000
2017/08/29 00:26:44 step 4: mse=156.449493 step=0.100000
2017/08/29 00:26:45 step 5: mse=153.789717 step=0.100000
2017/08/29 00:26:47 step 6: mse=150.905990 step=0.100000
2017/08/29 00:26:48 step 7: mse=148.560109 step=0.100000
2017/08/29 00:26:48 Saving...
2017/08/29 00:26:48 Gathering batch of experience...
2017/08/29 00:27:30 batch 791: mean=161.757576 stddev=127.759962 entropy=0.335285 frames=5163 count=33
2017/08/29 00:27:30 Training policy...
2017/08/29 00:27:34 step 0: objective=1.0021108
2017/08/29 00:27:36 step 1: objective=1.0093068
2017/08/29 00:27:37 step 2: objective=1.0195482
2017/08/29 00:27:39 step 3: objective=1.0286192
2017/08/29 00:27:41 step 4: objective=1.0326066
2017/08/29 00:27:42 step 5: objective=1.0362515
2017/08/29 00:27:44 step 6: objective=1.040878
2017/08/29 00:27:46 step 7: objective=1.0442252
2017/08/29 00:27:46 Training value function...
2017/08/29 00:27:48 step 0: mse=171.333214 step=0.100000
2017/08/29 00:27:49 step 1: mse=168.280889 step=0.100000
2017/08/29 00:27:50 step 2: mse=166.030959 step=0.100000
2017/08/29 00:27:51 step 3: mse=163.695954 step=0.100000
2017/08/29 00:27:52 step 4: mse=161.523126 step=0.100000
2017/08/29 00:27:53 step 5: mse=159.448227 step=0.100000
2017/08/29 00:27:55 step 6: mse=158.139463 step=0.100000
2017/08/29 00:27:56 step 7: mse=156.692769 step=0.100000
2017/08/29 00:27:56 Saving...
2017/08/29 00:27:56 Gathering batch of experience...
2017/08/29 00:28:42 batch 792: mean=140.428571 stddev=117.965116 entropy=0.337828 frames=5521 count=42
2017/08/29 00:28:42 Training policy...
2017/08/29 00:28:46 step 0: objective=0.96596086
2017/08/29 00:28:48 step 1: objective=0.9765289
2017/08/29 00:28:50 step 2: objective=0.9855262
2017/08/29 00:28:52 step 3: objective=0.9943324
2017/08/29 00:28:54 step 4: objective=0.9983796
2017/08/29 00:28:55 step 5: objective=1.0018315
2017/08/29 00:28:57 step 6: objective=1.0051123
2017/08/29 00:28:59 step 7: objective=1.0083325
2017/08/29 00:28:59 Training value function...
2017/08/29 00:29:01 step 0: mse=174.008555 step=0.100000
2017/08/29 00:29:02 step 1: mse=170.876155 step=0.100000
2017/08/29 00:29:04 step 2: mse=168.592650 step=0.100000
2017/08/29 00:29:05 step 3: mse=166.567360 step=0.100000
2017/08/29 00:29:06 step 4: mse=164.513230 step=0.100000
2017/08/29 00:29:07 step 5: mse=163.096600 step=0.100000
2017/08/29 00:29:08 step 6: mse=161.947428 step=0.100000
2017/08/29 00:29:09 step 7: mse=160.345565 step=0.100000
2017/08/29 00:29:09 Saving...
2017/08/29 00:29:10 Gathering batch of experience...
2017/08/29 00:29:55 batch 793: mean=223.740741 stddev=163.466973 entropy=0.347625 frames=5699 count=27
2017/08/29 00:29:55 Training policy...
2017/08/29 00:29:59 step 0: objective=1.7797692
2017/08/29 00:30:01 step 1: objective=1.7845844
2017/08/29 00:30:03 step 2: objective=1.7895505
2017/08/29 00:30:05 step 3: objective=1.7936714
2017/08/29 00:30:07 step 4: objective=1.796668
2017/08/29 00:30:09 step 5: objective=1.8018048
2017/08/29 00:30:10 step 6: objective=1.8076439
2017/08/29 00:30:12 step 7: objective=1.8108481
2017/08/29 00:30:12 Training value function...
2017/08/29 00:30:15 step 0: mse=179.425746 step=0.100000
2017/08/29 00:30:16 step 1: mse=174.875054 step=0.100000
2017/08/29 00:30:17 step 2: mse=171.029298 step=0.100000
2017/08/29 00:30:18 step 3: mse=167.564790 step=0.100000
2017/08/29 00:30:20 step 4: mse=164.673265 step=0.100000
2017/08/29 00:30:21 step 5: mse=162.026155 step=0.100000
2017/08/29 00:30:22 step 6: mse=159.789543 step=0.100000
2017/08/29 00:30:23 step 7: mse=157.589047 step=0.100000
2017/08/29 00:30:23 Saving...
2017/08/29 00:30:23 Gathering batch of experience...
2017/08/29 00:31:12 batch 794: mean=154.894737 stddev=114.673631 entropy=0.343629 frames=6033 count=38
2017/08/29 00:31:12 Training policy...
2017/08/29 00:31:17 step 0: objective=-0.38910013
2017/08/29 00:31:19 step 1: objective=-0.3828032
2017/08/29 00:31:21 step 2: objective=-0.37675893
2017/08/29 00:31:23 step 3: objective=-0.37207147
2017/08/29 00:31:25 step 4: objective=-0.36724925
2017/08/29 00:31:27 step 5: objective=-0.36265218
2017/08/29 00:31:29 step 6: objective=-0.35650614
2017/08/29 00:31:30 step 7: objective=-0.3540965
2017/08/29 00:31:30 Training value function...
2017/08/29 00:31:33 step 0: mse=146.890179 step=0.100000
2017/08/29 00:31:34 step 1: mse=143.471549 step=0.100000
2017/08/29 00:31:36 step 2: mse=140.692669 step=0.100000
2017/08/29 00:31:37 step 3: mse=138.865453 step=0.100000
2017/08/29 00:31:38 step 4: mse=137.365540 step=0.100000
2017/08/29 00:31:39 step 5: mse=135.694079 step=0.100000
2017/08/29 00:31:41 step 6: mse=134.598644 step=0.100000
2017/08/29 00:31:42 step 7: mse=133.768737 step=0.100000
2017/08/29 00:31:42 Saving...
2017/08/29 00:31:42 Gathering batch of experience...
2017/08/29 00:32:29 batch 795: mean=185.437500 stddev=125.796695 entropy=0.337995 frames=5947 count=32
2017/08/29 00:32:29 Training policy...
2017/08/29 00:32:33 step 0: objective=1.1074734
2017/08/29 00:32:35 step 1: objective=1.1160237
2017/08/29 00:32:37 step 2: objective=1.1205926
2017/08/29 00:32:39 step 3: objective=1.1245829
2017/08/29 00:32:41 step 4: objective=1.1307468
2017/08/29 00:32:43 step 5: objective=1.1363974
2017/08/29 00:32:45 step 6: objective=1.1397215
2017/08/29 00:32:47 step 7: objective=1.1446615
2017/08/29 00:32:47 Training value function...
2017/08/29 00:32:49 step 0: mse=145.078044 step=0.100000
2017/08/29 00:32:51 step 1: mse=142.871980 step=0.100000
2017/08/29 00:32:52 step 2: mse=141.054762 step=0.100000
2017/08/29 00:32:53 step 3: mse=139.171217 step=0.100000
2017/08/29 00:32:54 step 4: mse=137.697767 step=0.100000
2017/08/29 00:32:56 step 5: mse=136.210281 step=0.100000
2017/08/29 00:32:57 step 6: mse=135.089391 step=0.100000
2017/08/29 00:32:58 step 7: mse=133.682390 step=0.100000
2017/08/29 00:32:58 Saving...
2017/08/29 00:32:58 Gathering batch of experience...
2017/08/29 00:33:44 batch 796: mean=187.600000 stddev=147.630981 entropy=0.342713 frames=5627 count=30
2017/08/29 00:33:44 Training policy...
2017/08/29 00:33:48 step 0: objective=1.1830167
2017/08/29 00:33:50 step 1: objective=1.1898199
2017/08/29 00:33:52 step 2: objective=1.1961485
2017/08/29 00:33:54 step 3: objective=1.2016534
2017/08/29 00:33:56 step 4: objective=1.2070162
2017/08/29 00:33:58 step 5: objective=1.2103198
2017/08/29 00:34:00 step 6: objective=1.213941
2017/08/29 00:34:01 step 7: objective=1.2170199
2017/08/29 00:34:01 Training value function...
2017/08/29 00:34:04 step 0: mse=145.087694 step=0.100000
2017/08/29 00:34:05 step 1: mse=142.451715 step=0.100000
2017/08/29 00:34:06 step 2: mse=140.008105 step=0.100000
2017/08/29 00:34:07 step 3: mse=137.938385 step=0.100000
2017/08/29 00:34:09 step 4: mse=136.326915 step=0.100000
2017/08/29 00:34:10 step 5: mse=134.808445 step=0.100000
2017/08/29 00:34:11 step 6: mse=133.433145 step=0.100000
2017/08/29 00:34:12 step 7: mse=132.104468 step=0.100000
2017/08/29 00:34:12 Saving...
2017/08/29 00:34:12 Gathering batch of experience...
2017/08/29 00:35:02 batch 797: mean=181.512821 stddev=166.707924 entropy=0.341555 frames=6430 count=39
2017/08/29 00:35:02 Training policy...
2017/08/29 00:35:07 step 0: objective=2.0990627
2017/08/29 00:35:09 step 1: objective=2.1031508
2017/08/29 00:35:11 step 2: objective=2.1082945
2017/08/29 00:35:13 step 3: objective=2.1128294
2017/08/29 00:35:16 step 4: objective=2.11597
2017/08/29 00:35:18 step 5: objective=2.118574
2017/08/29 00:35:20 step 6: objective=2.1207337
2017/08/29 00:35:22 step 7: objective=2.1255877
2017/08/29 00:35:22 Training value function...
2017/08/29 00:35:25 step 0: mse=181.424417 step=0.100000
2017/08/29 00:35:26 step 1: mse=176.458982 step=0.100000
2017/08/29 00:35:27 step 2: mse=172.574468 step=0.100000
2017/08/29 00:35:29 step 3: mse=169.035408 step=0.100000
2017/08/29 00:35:30 step 4: mse=166.121921 step=0.100000
2017/08/29 00:35:32 step 5: mse=163.304356 step=0.100000
2017/08/29 00:35:33 step 6: mse=161.287954 step=0.100000
2017/08/29 00:35:34 step 7: mse=159.206493 step=0.100000
2017/08/29 00:35:34 Saving...
2017/08/29 00:35:34 Gathering batch of experience...
2017/08/29 00:36:16 batch 798: mean=131.800000 stddev=97.265924 entropy=0.332840 frames=5261 count=40
2017/08/29 00:36:16 Training policy...
2017/08/29 00:36:20 step 0: objective=-0.4490459
2017/08/29 00:36:22 step 1: objective=-0.44022977
2017/08/29 00:36:24 step 2: objective=-0.43490693
2017/08/29 00:36:26 step 3: objective=-0.42672092
2017/08/29 00:36:27 step 4: objective=-0.42270923
2017/08/29 00:36:29 step 5: objective=-0.4183289
2017/08/29 00:36:31 step 6: objective=-0.41245282
2017/08/29 00:36:33 step 7: objective=-0.40997726
2017/08/29 00:36:33 Training value function...
2017/08/29 00:36:35 step 0: mse=164.486281 step=0.100000
2017/08/29 00:36:36 step 1: mse=160.567480 step=0.100000
2017/08/29 00:36:37 step 2: mse=157.618465 step=0.100000
2017/08/29 00:36:38 step 3: mse=154.788583 step=0.100000
2017/08/29 00:36:39 step 4: mse=152.993391 step=0.100000
2017/08/29 00:36:40 step 5: mse=150.923192 step=0.100000
2017/08/29 00:36:41 step 6: mse=149.033487 step=0.100000
2017/08/29 00:36:42 step 7: mse=148.085527 step=0.100000
2017/08/29 00:36:42 Saving...
2017/08/29 00:36:43 Gathering batch of experience...
2017/08/29 00:37:29 batch 799: mean=153.853659 stddev=122.294838 entropy=0.333314 frames=5780 count=41
2017/08/29 00:37:29 Training policy...
2017/08/29 00:37:33 step 0: objective=1.8160399
2017/08/29 00:37:35 step 1: objective=1.820017
2017/08/29 00:37:37 step 2: objective=1.8286611
2017/08/29 00:37:39 step 3: objective=1.8338737
2017/08/29 00:37:41 step 4: objective=1.8414224
2017/08/29 00:37:43 step 5: objective=1.8451184
2017/08/29 00:37:45 step 6: objective=1.8481413
2017/08/29 00:37:47 step 7: objective=1.8510362
2017/08/29 00:37:47 Training value function...
2017/08/29 00:37:49 step 0: mse=188.832993 step=0.100000
2017/08/29 00:37:50 step 1: mse=185.805026 step=0.100000
2017/08/29 00:37:52 step 2: mse=183.018240 step=0.100000
2017/08/29 00:37:53 step 3: mse=180.614426 step=0.100000
2017/08/29 00:37:54 step 4: mse=178.706846 step=0.100000
2017/08/29 00:37:55 step 5: mse=176.702189 step=0.100000
2017/08/29 00:37:56 step 6: mse=175.168055 step=0.100000
2017/08/29 00:37:58 step 7: mse=173.589560 step=0.100000
2017/08/29 00:37:58 Saving...
2017/08/29 00:37:58 Gathering batch of experience...
2017/08/29 00:38:38 batch 800: mean=209.821429 stddev=151.310715 entropy=0.342869 frames=5275 count=28
2017/08/29 00:38:38 Training policy...
2017/08/29 00:38:42 step 0: objective=2.424859
2017/08/29 00:38:44 step 1: objective=2.434852
2017/08/29 00:38:45 step 2: objective=2.44376
2017/08/29 00:38:47 step 3: objective=2.4495919
2017/08/29 00:38:49 step 4: objective=2.4553485
2017/08/29 00:38:51 step 5: objective=2.4617927
2017/08/29 00:38:52 step 6: objective=2.4687304
2017/08/29 00:38:54 step 7: objective=2.4743502
2017/08/29 00:38:54 Training value function...
2017/08/29 00:38:56 step 0: mse=199.054421 step=0.100000
2017/08/29 00:38:57 step 1: mse=192.608149 step=0.100000
2017/08/29 00:38:59 step 2: mse=187.066598 step=0.100000
2017/08/29 00:39:00 step 3: mse=182.421514 step=0.100000
2017/08/29 00:39:01 step 4: mse=178.070115 step=0.100000
2017/08/29 00:39:02 step 5: mse=174.500114 step=0.100000
2017/08/29 00:39:03 step 6: mse=171.406066 step=0.100000
2017/08/29 00:39:04 step 7: mse=168.654809 step=0.100000
2017/08/29 00:39:04 Saving...
2017/08/29 00:39:04 Gathering batch of experience...
2017/08/29 00:39:48 batch 801: mean=171.147059 stddev=152.896953 entropy=0.337848 frames=5672 count=34
2017/08/29 00:39:48 Training policy...
2017/08/29 00:39:52 step 0: objective=0.46524397
2017/08/29 00:39:54 step 1: objective=0.4764975
2017/08/29 00:39:56 step 2: objective=0.48305762
2017/08/29 00:39:58 step 3: objective=0.4894352
2017/08/29 00:40:00 step 4: objective=0.4931171
2017/08/29 00:40:02 step 5: objective=0.495837
2017/08/29 00:40:04 step 6: objective=0.49992412
2017/08/29 00:40:06 step 7: objective=0.5021197
2017/08/29 00:40:06 Training value function...
2017/08/29 00:40:08 step 0: mse=158.167151 step=0.100000
2017/08/29 00:40:09 step 1: mse=155.659974 step=0.100000
2017/08/29 00:40:10 step 2: mse=153.878721 step=0.100000
2017/08/29 00:40:12 step 3: mse=152.148122 step=0.100000
2017/08/29 00:40:13 step 4: mse=150.607066 step=0.100000
2017/08/29 00:40:14 step 5: mse=149.106103 step=0.100000
2017/08/29 00:40:15 step 6: mse=148.117585 step=0.100000
2017/08/29 00:40:16 step 7: mse=147.217804 step=0.100000
2017/08/29 00:40:16 Saving...
2017/08/29 00:40:16 Gathering batch of experience...
2017/08/29 00:40:58 batch 802: mean=163.500000 stddev=122.314986 entropy=0.335751 frames=5442 count=34
2017/08/29 00:40:58 Training policy...
2017/08/29 00:41:03 step 0: objective=0.4677237
2017/08/29 00:41:04 step 1: objective=0.4732216
2017/08/29 00:41:06 step 2: objective=0.47979492
2017/08/29 00:41:08 step 3: objective=0.484213
2017/08/29 00:41:10 step 4: objective=0.48967168
2017/08/29 00:41:12 step 5: objective=0.49439195
2017/08/29 00:41:14 step 6: objective=0.4983638
2017/08/29 00:41:15 step 7: objective=0.5041448
2017/08/29 00:41:15 Training value function...
2017/08/29 00:41:18 step 0: mse=128.839069 step=0.100000
2017/08/29 00:41:19 step 1: mse=127.641626 step=0.100000
2017/08/29 00:41:20 step 2: mse=126.990059 step=0.100000
2017/08/29 00:41:21 step 3: mse=126.099615 step=0.100000
2017/08/29 00:41:22 step 4: mse=125.609121 step=0.100000
2017/08/29 00:41:23 step 5: mse=124.977550 step=0.100000
2017/08/29 00:41:25 step 6: mse=124.455849 step=0.100000
2017/08/29 00:41:26 step 7: mse=124.187348 step=0.100000
2017/08/29 00:41:26 Saving...
2017/08/29 00:41:26 Gathering batch of experience...
2017/08/29 00:42:11 batch 803: mean=156.833333 stddev=137.197647 entropy=0.338799 frames=5504 count=36
2017/08/29 00:42:11 Training policy...
2017/08/29 00:42:15 step 0: objective=0.77254564
2017/08/29 00:42:17 step 1: objective=0.778411
2017/08/29 00:42:19 step 2: objective=0.784602
2017/08/29 00:42:21 step 3: objective=0.7895535
2017/08/29 00:42:23 step 4: objective=0.7949757
2017/08/29 00:42:25 step 5: objective=0.8023316
2017/08/29 00:42:26 step 6: objective=0.8067587
2017/08/29 00:42:28 step 7: objective=0.80920506
2017/08/29 00:42:28 Training value function...
2017/08/29 00:42:31 step 0: mse=162.866743 step=0.100000
2017/08/29 00:42:32 step 1: mse=161.173874 step=0.100000
2017/08/29 00:42:33 step 2: mse=159.517821 step=0.100000
2017/08/29 00:42:34 step 3: mse=157.713527 step=0.100000
2017/08/29 00:42:35 step 4: mse=156.108981 step=0.100000
2017/08/29 00:42:36 step 5: mse=154.752968 step=0.100000
2017/08/29 00:42:37 step 6: mse=153.323284 step=0.100000
2017/08/29 00:42:39 step 7: mse=152.191795 step=0.100000
2017/08/29 00:42:39 Saving...
2017/08/29 00:42:39 Gathering batch of experience...
2017/08/29 00:43:27 batch 804: mean=125.130435 stddev=105.722896 entropy=0.340080 frames=5634 count=46
2017/08/29 00:43:27 Training policy...
2017/08/29 00:43:32 step 0: objective=0.3237375
2017/08/29 00:43:33 step 1: objective=0.33058465
2017/08/29 00:43:35 step 2: objective=0.33915144
2017/08/29 00:43:37 step 3: objective=0.34518918
2017/08/29 00:43:39 step 4: objective=0.3515063
2017/08/29 00:43:41 step 5: objective=0.35717356
2017/08/29 00:43:43 step 6: objective=0.36156064
2017/08/29 00:43:45 step 7: objective=0.36656013
2017/08/29 00:43:45 Training value function...
2017/08/29 00:43:47 step 0: mse=158.324684 step=0.100000
2017/08/29 00:43:48 step 1: mse=157.462309 step=0.100000
2017/08/29 00:43:50 step 2: mse=156.688133 step=0.100000
2017/08/29 00:43:51 step 3: mse=155.874859 step=0.100000
2017/08/29 00:43:52 step 4: mse=155.340515 step=0.100000
2017/08/29 00:43:53 step 5: mse=154.724129 step=0.100000
2017/08/29 00:43:54 step 6: mse=154.293358 step=0.100000
2017/08/29 00:43:55 step 7: mse=154.045731 step=0.100000
2017/08/29 00:43:55 Saving...
2017/08/29 00:43:56 Gathering batch of experience...
2017/08/29 00:44:42 batch 805: mean=213.935484 stddev=136.434774 entropy=0.343901 frames=6350 count=31
2017/08/29 00:44:42 Training policy...
2017/08/29 00:44:47 step 0: objective=2.1473248
2017/08/29 00:44:49 step 1: objective=2.1520352
2017/08/29 00:44:52 step 2: objective=2.1550708
2017/08/29 00:44:54 step 3: objective=2.157971
2017/08/29 00:44:56 step 4: objective=2.1620443
2017/08/29 00:44:58 step 5: objective=2.165072
2017/08/29 00:45:00 step 6: objective=2.1685512
2017/08/29 00:45:02 step 7: objective=2.171284
2017/08/29 00:45:02 Training value function...
2017/08/29 00:45:05 step 0: mse=141.429204 step=0.100000
2017/08/29 00:45:06 step 1: mse=136.646247 step=0.100000
2017/08/29 00:45:08 step 2: mse=132.653057 step=0.100000
2017/08/29 00:45:09 step 3: mse=129.190233 step=0.100000
2017/08/29 00:45:10 step 4: mse=126.046386 step=0.100000
2017/08/29 00:45:12 step 5: mse=123.270348 step=0.100000
2017/08/29 00:45:13 step 6: mse=120.961367 step=0.100000
2017/08/29 00:45:14 step 7: mse=118.970028 step=0.100000
2017/08/29 00:45:14 Saving...
2017/08/29 00:45:14 Gathering batch of experience...
2017/08/29 00:45:57 batch 806: mean=195.750000 stddev=141.235777 entropy=0.339143 frames=5389 count=28
2017/08/29 00:45:57 Training policy...
2017/08/29 00:46:02 step 0: objective=1.0357509
2017/08/29 00:46:03 step 1: objective=1.0440882
2017/08/29 00:46:05 step 2: objective=1.0516955
2017/08/29 00:46:07 step 3: objective=1.0551789
2017/08/29 00:46:09 step 4: objective=1.0592887
2017/08/29 00:46:11 step 5: objective=1.0633665
2017/08/29 00:46:12 step 6: objective=1.0666198
2017/08/29 00:46:14 step 7: objective=1.070015
2017/08/29 00:46:14 Training value function...
2017/08/29 00:46:16 step 0: mse=157.019372 step=0.100000
2017/08/29 00:46:18 step 1: mse=154.553305 step=0.100000
2017/08/29 00:46:19 step 2: mse=152.518604 step=0.100000
2017/08/29 00:46:20 step 3: mse=150.720797 step=0.100000
2017/08/29 00:46:21 step 4: mse=148.527013 step=0.100000
2017/08/29 00:46:22 step 5: mse=147.126211 step=0.100000
2017/08/29 00:46:23 step 6: mse=145.952694 step=0.100000
2017/08/29 00:46:24 step 7: mse=144.377617 step=0.100000
2017/08/29 00:46:24 Saving...
2017/08/29 00:46:25 Gathering batch of experience...
2017/08/29 00:47:07 batch 807: mean=179.117647 stddev=127.534716 entropy=0.342897 frames=5527 count=34
2017/08/29 00:47:07 Training policy...
2017/08/29 00:47:12 step 0: objective=1.7346847
2017/08/29 00:47:14 step 1: objective=1.7402813
2017/08/29 00:47:15 step 2: objective=1.7452242
2017/08/29 00:47:17 step 3: objective=1.751682
2017/08/29 00:47:19 step 4: objective=1.7559866
2017/08/29 00:47:21 step 5: objective=1.7599976
2017/08/29 00:47:23 step 6: objective=1.7653292
2017/08/29 00:47:25 step 7: objective=1.7691681
2017/08/29 00:47:25 Training value function...
2017/08/29 00:47:27 step 0: mse=181.537097 step=0.100000
2017/08/29 00:47:28 step 1: mse=177.875136 step=0.100000
2017/08/29 00:47:29 step 2: mse=174.803870 step=0.100000
2017/08/29 00:47:31 step 3: mse=172.016227 step=0.100000
2017/08/29 00:47:32 step 4: mse=169.762082 step=0.100000
2017/08/29 00:47:33 step 5: mse=167.716955 step=0.100000
2017/08/29 00:47:34 step 6: mse=165.662597 step=0.100000
2017/08/29 00:47:35 step 7: mse=163.619296 step=0.100000
2017/08/29 00:47:35 Saving...
2017/08/29 00:47:35 Gathering batch of experience...
2017/08/29 00:48:25 batch 808: mean=166.722222 stddev=145.853924 entropy=0.335807 frames=5597 count=36
2017/08/29 00:48:25 Training policy...
2017/08/29 00:48:30 step 0: objective=1.0676883
2017/08/29 00:48:31 step 1: objective=1.0756269
2017/08/29 00:48:33 step 2: objective=1.0832087
2017/08/29 00:48:35 step 3: objective=1.088825
2017/08/29 00:48:37 step 4: objective=1.0928032
2017/08/29 00:48:39 step 5: objective=1.0975852
2017/08/29 00:48:41 step 6: objective=1.1023806
2017/08/29 00:48:43 step 7: objective=1.1087997
2017/08/29 00:48:43 Training value function...
2017/08/29 00:48:45 step 0: mse=156.209404 step=0.100000
2017/08/29 00:48:46 step 1: mse=152.169497 step=0.100000
2017/08/29 00:48:47 step 2: mse=148.856425 step=0.100000
2017/08/29 00:48:48 step 3: mse=146.111428 step=0.100000
2017/08/29 00:48:50 step 4: mse=143.708086 step=0.100000
2017/08/29 00:48:51 step 5: mse=141.896632 step=0.100000
2017/08/29 00:48:52 step 6: mse=140.136483 step=0.100000
2017/08/29 00:48:53 step 7: mse=138.775903 step=0.100000
2017/08/29 00:48:53 Saving...
2017/08/29 00:48:53 Gathering batch of experience...
2017/08/29 00:49:34 batch 809: mean=187.800000 stddev=94.585905 entropy=0.340343 frames=5327 count=30
2017/08/29 00:49:34 Training policy...
2017/08/29 00:49:38 step 0: objective=0.96783036
2017/08/29 00:49:40 step 1: objective=0.9727662
2017/08/29 00:49:42 step 2: objective=0.98013425
2017/08/29 00:49:44 step 3: objective=0.98454046
2017/08/29 00:49:45 step 4: objective=0.98982435
2017/08/29 00:49:47 step 5: objective=0.99407566
2017/08/29 00:49:49 step 6: objective=0.9977815
2017/08/29 00:49:51 step 7: objective=1.0004988
2017/08/29 00:49:51 Training value function...
2017/08/29 00:49:53 step 0: mse=150.077062 step=0.100000
2017/08/29 00:49:54 step 1: mse=146.593527 step=0.100000
2017/08/29 00:49:55 step 2: mse=143.287714 step=0.100000
2017/08/29 00:49:56 step 3: mse=140.806037 step=0.100000
2017/08/29 00:49:58 step 4: mse=138.619106 step=0.100000
2017/08/29 00:49:59 step 5: mse=136.730230 step=0.100000
2017/08/29 00:50:00 step 6: mse=135.005442 step=0.100000
2017/08/29 00:50:01 step 7: mse=133.477149 step=0.100000
2017/08/29 00:50:01 Saving...
2017/08/29 00:50:01 Gathering batch of experience...
2017/08/29 00:50:49 batch 810: mean=175.888889 stddev=128.373322 entropy=0.337518 frames=6112 count=36
2017/08/29 00:50:49 Training policy...
2017/08/29 00:50:54 step 0: objective=0.73744303
2017/08/29 00:50:56 step 1: objective=0.7433855
2017/08/29 00:50:58 step 2: objective=0.74650675
2017/08/29 00:51:00 step 3: objective=0.74974173
2017/08/29 00:51:02 step 4: objective=0.75309056
2017/08/29 00:51:04 step 5: objective=0.7569496
2017/08/29 00:51:06 step 6: objective=0.76107734
2017/08/29 00:51:08 step 7: objective=0.76317626
2017/08/29 00:51:08 Training value function...
2017/08/29 00:51:11 step 0: mse=150.851206 step=0.100000
2017/08/29 00:51:12 step 1: mse=147.595100 step=0.100000
2017/08/29 00:51:13 step 2: mse=144.552387 step=0.100000
2017/08/29 00:51:14 step 3: mse=142.013836 step=0.100000
2017/08/29 00:51:16 step 4: mse=140.218804 step=0.100000
2017/08/29 00:51:17 step 5: mse=138.308446 step=0.100000
2017/08/29 00:51:18 step 6: mse=136.878552 step=0.100000
2017/08/29 00:51:20 step 7: mse=135.484757 step=0.100000
2017/08/29 00:51:20 Saving...
2017/08/29 00:51:20 Gathering batch of experience...
2017/08/29 00:52:05 batch 811: mean=200.843750 stddev=163.429478 entropy=0.340324 frames=5727 count=32
2017/08/29 00:52:05 Training policy...
2017/08/29 00:52:10 step 0: objective=2.443328
2017/08/29 00:52:12 step 1: objective=2.4490871
2017/08/29 00:52:14 step 2: objective=2.453288
2017/08/29 00:52:16 step 3: objective=2.4576235
2017/08/29 00:52:18 step 4: objective=2.4640968
2017/08/29 00:52:20 step 5: objective=2.4689095
2017/08/29 00:52:21 step 6: objective=2.4715397
2017/08/29 00:52:23 step 7: objective=2.476047
2017/08/29 00:52:23 Training value function...
2017/08/29 00:52:26 step 0: mse=215.559373 step=0.100000
2017/08/29 00:52:27 step 1: mse=207.013326 step=0.100000
2017/08/29 00:52:28 step 2: mse=199.698999 step=0.100000
2017/08/29 00:52:29 step 3: mse=193.537271 step=0.100000
2017/08/29 00:52:31 step 4: mse=188.459090 step=0.100000
2017/08/29 00:52:32 step 5: mse=183.772622 step=0.100000
2017/08/29 00:52:33 step 6: mse=179.849492 step=0.100000
2017/08/29 00:52:34 step 7: mse=176.468305 step=0.100000
2017/08/29 00:52:34 Saving...
2017/08/29 00:52:34 Gathering batch of experience...
2017/08/29 00:53:20 batch 812: mean=173.171429 stddev=153.182708 entropy=0.334303 frames=5686 count=35
2017/08/29 00:53:20 Training policy...
2017/08/29 00:53:24 step 0: objective=0.76294684
2017/08/29 00:53:26 step 1: objective=0.77171177
2017/08/29 00:53:28 step 2: objective=0.77856237
2017/08/29 00:53:30 step 3: objective=0.78274024
2017/08/29 00:53:32 step 4: objective=0.7897458
2017/08/29 00:53:34 step 5: objective=0.79417324
2017/08/29 00:53:36 step 6: objective=0.79713786
2017/08/29 00:53:38 step 7: objective=0.8004448
2017/08/29 00:53:38 Training value function...
2017/08/29 00:53:40 step 0: mse=171.121539 step=0.100000
2017/08/29 00:53:41 step 1: mse=168.926166 step=0.100000
2017/08/29 00:53:42 step 2: mse=165.853655 step=0.100000
2017/08/29 00:53:44 step 3: mse=163.823684 step=0.100000
2017/08/29 00:53:45 step 4: mse=162.260515 step=0.100000
2017/08/29 00:53:46 step 5: mse=160.491130 step=0.100000
2017/08/29 00:53:47 step 6: mse=158.822185 step=0.100000
2017/08/29 00:53:48 step 7: mse=157.208109 step=0.100000
2017/08/29 00:53:48 Saving...
2017/08/29 00:53:49 Gathering batch of experience...
2017/08/29 00:54:35 batch 813: mean=196.903226 stddev=130.376713 entropy=0.333920 frames=6107 count=31
2017/08/29 00:54:35 Training policy...
2017/08/29 00:54:40 step 0: objective=0.3260691
2017/08/29 00:54:42 step 1: objective=0.32925877
2017/08/29 00:54:44 step 2: objective=0.33700952
2017/08/29 00:54:46 step 3: objective=0.3428738
2017/08/29 00:54:48 step 4: objective=0.34669745
2017/08/29 00:54:50 step 5: objective=0.35242137
2017/08/29 00:54:52 step 6: objective=0.35548407
2017/08/29 00:54:54 step 7: objective=0.35845765
2017/08/29 00:54:54 Training value function...
2017/08/29 00:54:57 step 0: mse=145.051306 step=0.100000
2017/08/29 00:54:58 step 1: mse=142.286900 step=0.100000
2017/08/29 00:54:59 step 2: mse=140.023034 step=0.100000
2017/08/29 00:55:01 step 3: mse=138.345637 step=0.100000
2017/08/29 00:55:02 step 4: mse=136.822187 step=0.100000
2017/08/29 00:55:03 step 5: mse=135.222617 step=0.100000
2017/08/29 00:55:04 step 6: mse=134.269609 step=0.100000
2017/08/29 00:55:06 step 7: mse=133.096597 step=0.100000
2017/08/29 00:55:06 Saving...
2017/08/29 00:55:06 Gathering batch of experience...
2017/08/29 00:55:56 batch 814: mean=185.378378 stddev=161.517525 entropy=0.344031 frames=6681 count=37
2017/08/29 00:55:56 Training policy...
2017/08/29 00:56:02 step 0: objective=1.2249706
2017/08/29 00:56:04 step 1: objective=1.2343531
2017/08/29 00:56:06 step 2: objective=1.2386075
2017/08/29 00:56:08 step 3: objective=1.2423648
2017/08/29 00:56:11 step 4: objective=1.2465168
2017/08/29 00:56:13 step 5: objective=1.249724
2017/08/29 00:56:15 step 6: objective=1.2531514
2017/08/29 00:56:17 step 7: objective=1.2571783
2017/08/29 00:56:17 Training value function...
2017/08/29 00:56:20 step 0: mse=153.301955 step=0.100000
2017/08/29 00:56:22 step 1: mse=151.819031 step=0.100000
2017/08/29 00:56:23 step 2: mse=150.578043 step=0.100000
2017/08/29 00:56:24 step 3: mse=149.170773 step=0.100000
2017/08/29 00:56:26 step 4: mse=147.785866 step=0.100000
2017/08/29 00:56:27 step 5: mse=146.539023 step=0.100000
2017/08/29 00:56:29 step 6: mse=145.879899 step=0.100000
2017/08/29 00:56:30 step 7: mse=145.004525 step=0.100000
2017/08/29 00:56:30 Saving...
2017/08/29 00:56:30 Gathering batch of experience...
2017/08/29 00:57:17 batch 815: mean=181.470588 stddev=149.138750 entropy=0.335115 frames=5722 count=34
2017/08/29 00:57:17 Training policy...
2017/08/29 00:57:21 step 0: objective=1.5067081
2017/08/29 00:57:23 step 1: objective=1.51226
2017/08/29 00:57:25 step 2: objective=1.5183182
2017/08/29 00:57:27 step 3: objective=1.5225629
2017/08/29 00:57:29 step 4: objective=1.526568
2017/08/29 00:57:31 step 5: objective=1.5312227
2017/08/29 00:57:33 step 6: objective=1.5337676
2017/08/29 00:57:35 step 7: objective=1.5389092
2017/08/29 00:57:35 Training value function...
2017/08/29 00:57:37 step 0: mse=168.894279 step=0.100000
2017/08/29 00:57:39 step 1: mse=166.154179 step=0.100000
2017/08/29 00:57:40 step 2: mse=163.770046 step=0.100000
2017/08/29 00:57:41 step 3: mse=161.709606 step=0.100000
2017/08/29 00:57:42 step 4: mse=159.886868 step=0.100000
2017/08/29 00:57:43 step 5: mse=158.245576 step=0.100000
2017/08/29 00:57:45 step 6: mse=156.726801 step=0.100000
2017/08/29 00:57:46 step 7: mse=155.183393 step=0.100000
2017/08/29 00:57:46 Saving...
2017/08/29 00:57:46 Gathering batch of experience...
2017/08/29 00:58:29 batch 816: mean=155.131579 stddev=119.712192 entropy=0.337500 frames=5515 count=38
2017/08/29 00:58:29 Training policy...
2017/08/29 00:58:33 step 0: objective=0.6720008
2017/08/29 00:58:35 step 1: objective=0.67782456
2017/08/29 00:58:37 step 2: objective=0.6839307
2017/08/29 00:58:39 step 3: objective=0.69038075
2017/08/29 00:58:41 step 4: objective=0.695841
2017/08/29 00:58:43 step 5: objective=0.7004858
2017/08/29 00:58:44 step 6: objective=0.7047558
2017/08/29 00:58:46 step 7: objective=0.7090912
2017/08/29 00:58:46 Training value function...
2017/08/29 00:58:49 step 0: mse=167.669698 step=0.100000
2017/08/29 00:58:50 step 1: mse=164.399639 step=0.100000
2017/08/29 00:58:51 step 2: mse=161.944368 step=0.100000
2017/08/29 00:58:52 step 3: mse=159.373815 step=0.100000
2017/08/29 00:58:53 step 4: mse=157.135116 step=0.100000
2017/08/29 00:58:54 step 5: mse=155.552869 step=0.100000
2017/08/29 00:58:56 step 6: mse=154.333977 step=0.100000
2017/08/29 00:58:57 step 7: mse=152.860174 step=0.100000
2017/08/29 00:58:57 Saving...
2017/08/29 00:58:57 Gathering batch of experience...
2017/08/29 00:59:48 batch 817: mean=140.704545 stddev=128.525834 entropy=0.334747 frames=6179 count=44
2017/08/29 00:59:48 Training policy...
2017/08/29 00:59:53 step 0: objective=0.03744348
2017/08/29 00:59:55 step 1: objective=0.044887826
2017/08/29 00:59:57 step 2: objective=0.05462095
2017/08/29 00:59:59 step 3: objective=0.057643212
2017/08/29 01:00:01 step 4: objective=0.06141278
2017/08/29 01:00:03 step 5: objective=0.06581151
2017/08/29 01:00:05 step 6: objective=0.069668
2017/08/29 01:00:07 step 7: objective=0.072430514
2017/08/29 01:00:07 Training value function...
2017/08/29 01:00:10 step 0: mse=177.178779 step=0.100000
2017/08/29 01:00:11 step 1: mse=172.496563 step=0.100000
2017/08/29 01:00:12 step 2: mse=168.326587 step=0.100000
2017/08/29 01:00:14 step 3: mse=165.172612 step=0.100000
2017/08/29 01:00:15 step 4: mse=162.759375 step=0.100000
2017/08/29 01:00:16 step 5: mse=160.562868 step=0.100000
2017/08/29 01:00:18 step 6: mse=158.634258 step=0.100000
2017/08/29 01:00:19 step 7: mse=157.090334 step=0.100000
2017/08/29 01:00:19 Saving...
2017/08/29 01:00:19 Gathering batch of experience...
2017/08/29 01:01:05 batch 818: mean=180.676471 stddev=164.976954 entropy=0.333675 frames=5994 count=34
2017/08/29 01:01:05 Training policy...
2017/08/29 01:01:10 step 0: objective=1.4880728
2017/08/29 01:01:12 step 1: objective=1.4939225
2017/08/29 01:01:14 step 2: objective=1.4984596
2017/08/29 01:01:16 step 3: objective=1.5055629
2017/08/29 01:01:18 step 4: objective=1.513513
2017/08/29 01:01:20 step 5: objective=1.5181046
2017/08/29 01:01:22 step 6: objective=1.5221027
2017/08/29 01:01:24 step 7: objective=1.5259945
2017/08/29 01:01:24 Training value function...
2017/08/29 01:01:27 step 0: mse=177.892503 step=0.100000
2017/08/29 01:01:28 step 1: mse=172.428233 step=0.100000
2017/08/29 01:01:29 step 2: mse=167.966505 step=0.100000
2017/08/29 01:01:31 step 3: mse=163.707862 step=0.100000
2017/08/29 01:01:32 step 4: mse=160.337453 step=0.100000
2017/08/29 01:01:33 step 5: mse=157.244359 step=0.100000
2017/08/29 01:01:34 step 6: mse=154.728713 step=0.100000
2017/08/29 01:01:36 step 7: mse=152.494031 step=0.100000
2017/08/29 01:01:36 Saving...
2017/08/29 01:01:36 Gathering batch of experience...
2017/08/29 01:02:26 batch 819: mean=194.027778 stddev=177.698166 entropy=0.337359 frames=6598 count=36
2017/08/29 01:02:26 Training policy...
2017/08/29 01:02:31 step 0: objective=1.7883329
2017/08/29 01:02:34 step 1: objective=1.7920557
2017/08/29 01:02:36 step 2: objective=1.7966796
2017/08/29 01:02:38 step 3: objective=1.802476
2017/08/29 01:02:40 step 4: objective=1.8081515
2017/08/29 01:02:43 step 5: objective=1.8106349
2017/08/29 01:02:45 step 6: objective=1.8139468
2017/08/29 01:02:47 step 7: objective=1.8175266
2017/08/29 01:02:47 Training value function...
2017/08/29 01:02:50 step 0: mse=165.025258 step=0.100000
2017/08/29 01:02:51 step 1: mse=159.887678 step=0.100000
2017/08/29 01:02:53 step 2: mse=155.690422 step=0.100000
2017/08/29 01:02:54 step 3: mse=151.875676 step=0.100000
2017/08/29 01:02:55 step 4: mse=148.702929 step=0.100000
2017/08/29 01:02:57 step 5: mse=145.986853 step=0.100000
2017/08/29 01:02:58 step 6: mse=143.280714 step=0.100000
2017/08/29 01:02:59 step 7: mse=141.232526 step=0.100000
2017/08/29 01:02:59 Saving...
2017/08/29 01:03:00 Gathering batch of experience...
2017/08/29 01:03:46 batch 820: mean=165.714286 stddev=144.040782 entropy=0.335247 frames=5786 count=35
2017/08/29 01:03:46 Training policy...
2017/08/29 01:03:50 step 0: objective=0.30575237
2017/08/29 01:03:52 step 1: objective=0.3138402
2017/08/29 01:03:54 step 2: objective=0.3242291
2017/08/29 01:03:56 step 3: objective=0.32893538
2017/08/29 01:03:58 step 4: objective=0.33172375
2017/08/29 01:04:00 step 5: objective=0.3358809
2017/08/29 01:04:02 step 6: objective=0.33920535
2017/08/29 01:04:04 step 7: objective=0.3436077
2017/08/29 01:04:04 Training value function...
2017/08/29 01:04:06 step 0: mse=152.016803 step=0.100000
2017/08/29 01:04:08 step 1: mse=150.119034 step=0.100000
2017/08/29 01:04:09 step 2: mse=148.830438 step=0.100000
2017/08/29 01:04:10 step 3: mse=147.173521 step=0.100000
2017/08/29 01:04:11 step 4: mse=145.877873 step=0.100000
2017/08/29 01:04:13 step 5: mse=144.651164 step=0.100000
2017/08/29 01:04:14 step 6: mse=143.606089 step=0.100000
2017/08/29 01:04:15 step 7: mse=142.444531 step=0.100000
2017/08/29 01:04:15 Saving...
2017/08/29 01:04:15 Gathering batch of experience...
2017/08/29 01:05:01 batch 821: mean=179.352941 stddev=119.361261 entropy=0.330466 frames=5768 count=34
2017/08/29 01:05:01 Training policy...
2017/08/29 01:05:05 step 0: objective=1.3508328
2017/08/29 01:05:07 step 1: objective=1.354985
2017/08/29 01:05:09 step 2: objective=1.3590466
2017/08/29 01:05:11 step 3: objective=1.3627304
2017/08/29 01:05:13 step 4: objective=1.3669415
2017/08/29 01:05:15 step 5: objective=1.370968
2017/08/29 01:05:17 step 6: objective=1.3746327
2017/08/29 01:05:19 step 7: objective=1.3779892
2017/08/29 01:05:19 Training value function...
2017/08/29 01:05:22 step 0: mse=169.654747 step=0.100000
2017/08/29 01:05:23 step 1: mse=165.886868 step=0.100000
2017/08/29 01:05:24 step 2: mse=162.931545 step=0.100000
2017/08/29 01:05:25 step 3: mse=159.828486 step=0.100000
2017/08/29 01:05:27 step 4: mse=157.589544 step=0.100000
2017/08/29 01:05:28 step 5: mse=155.630969 step=0.100000
2017/08/29 01:05:29 step 6: mse=153.751414 step=0.100000
2017/08/29 01:05:30 step 7: mse=152.350219 step=0.100000
2017/08/29 01:05:30 Saving...
2017/08/29 01:05:30 Gathering batch of experience...
2017/08/29 01:06:18 batch 822: mean=167.297297 stddev=144.219215 entropy=0.332655 frames=5784 count=37
2017/08/29 01:06:18 Training policy...
2017/08/29 01:06:22 step 0: objective=1.2846214
2017/08/29 01:06:24 step 1: objective=1.2910903
2017/08/29 01:06:26 step 2: objective=1.2957016
2017/08/29 01:06:28 step 3: objective=1.3005384
2017/08/29 01:06:30 step 4: objective=1.3045278
2017/08/29 01:06:32 step 5: objective=1.3083243
2017/08/29 01:06:34 step 6: objective=1.3129508
2017/08/29 01:06:36 step 7: objective=1.316439
2017/08/29 01:06:36 Training value function...
2017/08/29 01:06:38 step 0: mse=168.995239 step=0.100000
2017/08/29 01:06:39 step 1: mse=166.927563 step=0.100000
2017/08/29 01:06:41 step 2: mse=164.912795 step=0.100000
2017/08/29 01:06:42 step 3: mse=163.243351 step=0.100000
2017/08/29 01:06:43 step 4: mse=161.738507 step=0.100000
2017/08/29 01:06:44 step 5: mse=160.431547 step=0.100000
2017/08/29 01:06:45 step 6: mse=159.374673 step=0.100000
2017/08/29 01:06:47 step 7: mse=157.845448 step=0.100000
2017/08/29 01:06:47 Saving...
2017/08/29 01:06:47 Gathering batch of experience...
2017/08/29 01:07:36 batch 823: mean=168.324324 stddev=140.187722 entropy=0.331711 frames=5842 count=37
2017/08/29 01:07:36 Training policy...
2017/08/29 01:07:41 step 0: objective=1.0258703
2017/08/29 01:07:43 step 1: objective=1.0332655
2017/08/29 01:07:45 step 2: objective=1.0400903
2017/08/29 01:07:47 step 3: objective=1.0460695
2017/08/29 01:07:49 step 4: objective=1.0514363
2017/08/29 01:07:51 step 5: objective=1.0568656
2017/08/29 01:07:52 step 6: objective=1.0616603
2017/08/29 01:07:54 step 7: objective=1.0641955
2017/08/29 01:07:54 Training value function...
2017/08/29 01:07:57 step 0: mse=151.574189 step=0.100000
2017/08/29 01:07:58 step 1: mse=149.445776 step=0.100000
2017/08/29 01:07:59 step 2: mse=147.673601 step=0.100000
2017/08/29 01:08:01 step 3: mse=145.990697 step=0.100000
2017/08/29 01:08:02 step 4: mse=144.653376 step=0.100000
2017/08/29 01:08:03 step 5: mse=143.485952 step=0.100000
2017/08/29 01:08:04 step 6: mse=142.295049 step=0.100000
2017/08/29 01:08:06 step 7: mse=141.231722 step=0.100000
2017/08/29 01:08:06 Saving...
2017/08/29 01:08:06 Gathering batch of experience...
2017/08/29 01:08:51 batch 824: mean=163.735294 stddev=153.852165 entropy=0.336214 frames=5263 count=34
2017/08/29 01:08:51 Training policy...
2017/08/29 01:08:55 step 0: objective=0.92526275
2017/08/29 01:08:57 step 1: objective=0.9307646
2017/08/29 01:08:59 step 2: objective=0.9365738
2017/08/29 01:09:00 step 3: objective=0.94365823
2017/08/29 01:09:02 step 4: objective=0.95041174
2017/08/29 01:09:04 step 5: objective=0.95517313
2017/08/29 01:09:06 step 6: objective=0.95956784
2017/08/29 01:09:08 step 7: objective=0.9638
2017/08/29 01:09:08 Training value function...
2017/08/29 01:09:10 step 0: mse=176.710591 step=0.100000
2017/08/29 01:09:11 step 1: mse=173.864004 step=0.100000
2017/08/29 01:09:12 step 2: mse=171.318918 step=0.100000
2017/08/29 01:09:13 step 3: mse=168.854491 step=0.100000
2017/08/29 01:09:14 step 4: mse=166.714544 step=0.100000
2017/08/29 01:09:15 step 5: mse=165.145718 step=0.100000
2017/08/29 01:09:16 step 6: mse=163.491436 step=0.100000
2017/08/29 01:09:18 step 7: mse=162.157025 step=0.100000
2017/08/29 01:09:18 Saving...
2017/08/29 01:09:18 Gathering batch of experience...
2017/08/29 01:09:58 batch 825: mean=190.379310 stddev=154.938122 entropy=0.341484 frames=5276 count=29
2017/08/29 01:09:58 Training policy...
2017/08/29 01:10:02 step 0: objective=1.1856034
2017/08/29 01:10:04 step 1: objective=1.1942496
2017/08/29 01:10:05 step 2: objective=1.2013092
2017/08/29 01:10:07 step 3: objective=1.2084157
2017/08/29 01:10:09 step 4: objective=1.2148156
2017/08/29 01:10:11 step 5: objective=1.2174013
2017/08/29 01:10:13 step 6: objective=1.2204312
2017/08/29 01:10:14 step 7: objective=1.2235698
2017/08/29 01:10:14 Training value function...
2017/08/29 01:10:17 step 0: mse=154.650803 step=0.100000
2017/08/29 01:10:18 step 1: mse=152.970081 step=0.100000
2017/08/29 01:10:19 step 2: mse=151.112775 step=0.100000
2017/08/29 01:10:20 step 3: mse=149.065194 step=0.100000
2017/08/29 01:10:21 step 4: mse=147.467556 step=0.100000
2017/08/29 01:10:22 step 5: mse=146.314312 step=0.100000
2017/08/29 01:10:23 step 6: mse=144.712294 step=0.100000
2017/08/29 01:10:24 step 7: mse=143.498848 step=0.100000
2017/08/29 01:10:24 Saving...
2017/08/29 01:10:24 Gathering batch of experience...
2017/08/29 01:11:12 batch 826: mean=228.928571 stddev=124.405423 entropy=0.344371 frames=6238 count=28
2017/08/29 01:11:12 Training policy...
2017/08/29 01:11:17 step 0: objective=1.1721323
2017/08/29 01:11:19 step 1: objective=1.1763734
2017/08/29 01:11:21 step 2: objective=1.1818657
2017/08/29 01:11:23 step 3: objective=1.1853683
2017/08/29 01:11:26 step 4: objective=1.1906215
2017/08/29 01:11:28 step 5: objective=1.1928977
2017/08/29 01:11:30 step 6: objective=1.1960078
2017/08/29 01:11:32 step 7: objective=1.1987228
2017/08/29 01:11:32 Training value function...
2017/08/29 01:11:35 step 0: mse=127.484112 step=0.100000
2017/08/29 01:11:36 step 1: mse=124.595992 step=0.100000
2017/08/29 01:11:37 step 2: mse=122.230765 step=0.100000
2017/08/29 01:11:39 step 3: mse=120.216325 step=0.100000
2017/08/29 01:11:40 step 4: mse=118.388409 step=0.100000
2017/08/29 01:11:41 step 5: mse=116.860868 step=0.100000
2017/08/29 01:11:43 step 6: mse=115.467918 step=0.100000
2017/08/29 01:11:44 step 7: mse=114.208563 step=0.100000
2017/08/29 01:11:44 Saving...
2017/08/29 01:11:44 Gathering batch of experience...
2017/08/29 01:12:26 batch 827: mean=153.342857 stddev=123.961271 entropy=0.329912 frames=5270 count=35
2017/08/29 01:12:26 Training policy...
2017/08/29 01:12:30 step 0: objective=0.19886406
2017/08/29 01:12:32 step 1: objective=0.20749326
2017/08/29 01:12:33 step 2: objective=0.2144665
2017/08/29 01:12:35 step 3: objective=0.2195024
2017/08/29 01:12:37 step 4: objective=0.22556268
2017/08/29 01:12:39 step 5: objective=0.2292782
2017/08/29 01:12:41 step 6: objective=0.23292957
2017/08/29 01:12:43 step 7: objective=0.2386228
2017/08/29 01:12:43 Training value function...
2017/08/29 01:12:45 step 0: mse=141.982843 step=0.100000
2017/08/29 01:12:46 step 1: mse=139.590235 step=0.100000
2017/08/29 01:12:47 step 2: mse=137.933631 step=0.100000
2017/08/29 01:12:48 step 3: mse=136.071549 step=0.100000
2017/08/29 01:12:49 step 4: mse=134.897595 step=0.100000
2017/08/29 01:12:50 step 5: mse=133.983201 step=0.100000
2017/08/29 01:12:51 step 6: mse=132.836915 step=0.100000
2017/08/29 01:12:53 step 7: mse=131.936505 step=0.100000
2017/08/29 01:12:53 Saving...
2017/08/29 01:12:53 Gathering batch of experience...
2017/08/29 01:13:36 batch 828: mean=185.727273 stddev=135.987360 entropy=0.338340 frames=5865 count=33
2017/08/29 01:13:36 Training policy...
2017/08/29 01:13:41 step 0: objective=1.3349726
2017/08/29 01:13:43 step 1: objective=1.3434355
2017/08/29 01:13:45 step 2: objective=1.3542663
2017/08/29 01:13:47 step 3: objective=1.3601654
2017/08/29 01:13:49 step 4: objective=1.3647376
2017/08/29 01:13:51 step 5: objective=1.3693935
2017/08/29 01:13:53 step 6: objective=1.3741564
2017/08/29 01:13:55 step 7: objective=1.3775067
2017/08/29 01:13:55 Training value function...
2017/08/29 01:13:58 step 0: mse=171.241077 step=0.100000
2017/08/29 01:13:59 step 1: mse=167.217087 step=0.100000
2017/08/29 01:14:00 step 2: mse=163.331790 step=0.100000
2017/08/29 01:14:01 step 3: mse=160.208245 step=0.100000
2017/08/29 01:14:02 step 4: mse=157.645299 step=0.100000
2017/08/29 01:14:04 step 5: mse=155.418998 step=0.100000
2017/08/29 01:14:05 step 6: mse=153.186110 step=0.100000
2017/08/29 01:14:06 step 7: mse=151.337440 step=0.100000
2017/08/29 01:14:06 Saving...
2017/08/29 01:14:06 Gathering batch of experience...
2017/08/29 01:14:50 batch 829: mean=244.692308 stddev=146.054723 entropy=0.342766 frames=6018 count=26
2017/08/29 01:14:50 Training policy...
2017/08/29 01:14:55 step 0: objective=1.7687622
2017/08/29 01:14:57 step 1: objective=1.7721595
2017/08/29 01:14:59 step 2: objective=1.7755333
2017/08/29 01:15:01 step 3: objective=1.7794707
2017/08/29 01:15:03 step 4: objective=1.782156
2017/08/29 01:15:05 step 5: objective=1.7846186
2017/08/29 01:15:07 step 6: objective=1.786983
2017/08/29 01:15:09 step 7: objective=1.7910472
2017/08/29 01:15:09 Training value function...
2017/08/29 01:15:12 step 0: mse=135.940848 step=0.100000
2017/08/29 01:15:13 step 1: mse=133.218304 step=0.100000
2017/08/29 01:15:15 step 2: mse=130.779395 step=0.100000
2017/08/29 01:15:16 step 3: mse=128.963316 step=0.100000
2017/08/29 01:15:17 step 4: mse=127.127165 step=0.100000
2017/08/29 01:15:18 step 5: mse=125.408476 step=0.100000
2017/08/29 01:15:20 step 6: mse=123.665713 step=0.100000
2017/08/29 01:15:21 step 7: mse=121.936105 step=0.100000
2017/08/29 01:15:21 Saving...
2017/08/29 01:15:21 Gathering batch of experience...
2017/08/29 01:16:01 batch 830: mean=167.156250 stddev=104.055006 entropy=0.332728 frames=5135 count=32
2017/08/29 01:16:01 Training policy...
2017/08/29 01:16:05 step 0: objective=0.36869016
2017/08/29 01:16:07 step 1: objective=0.37399065
2017/08/29 01:16:09 step 2: objective=0.38649288
2017/08/29 01:16:11 step 3: objective=0.38993418
2017/08/29 01:16:12 step 4: objective=0.39492112
2017/08/29 01:16:14 step 5: objective=0.39834857
2017/08/29 01:16:16 step 6: objective=0.4029217
2017/08/29 01:16:18 step 7: objective=0.40747
2017/08/29 01:16:18 Training value function...
2017/08/29 01:16:20 step 0: mse=138.201754 step=0.100000
2017/08/29 01:16:21 step 1: mse=136.251368 step=0.100000
2017/08/29 01:16:22 step 2: mse=134.802880 step=0.100000
2017/08/29 01:16:23 step 3: mse=133.426919 step=0.100000
2017/08/29 01:16:24 step 4: mse=132.444250 step=0.100000
2017/08/29 01:16:25 step 5: mse=131.460666 step=0.100000
2017/08/29 01:16:26 step 6: mse=130.616607 step=0.100000
2017/08/29 01:16:27 step 7: mse=129.927005 step=0.100000
2017/08/29 01:16:27 Saving...
2017/08/29 01:16:28 Gathering batch of experience...
2017/08/29 01:17:12 batch 831: mean=177.787879 stddev=137.452748 entropy=0.336460 frames=5709 count=33
2017/08/29 01:17:12 Training policy...
2017/08/29 01:17:16 step 0: objective=0.9197582
2017/08/29 01:17:18 step 1: objective=0.924985
2017/08/29 01:17:20 step 2: objective=0.9295652
2017/08/29 01:17:22 step 3: objective=0.9384706
2017/08/29 01:17:24 step 4: objective=0.9442765
2017/08/29 01:17:26 step 5: objective=0.947986
2017/08/29 01:17:28 step 6: objective=0.9515328
2017/08/29 01:17:30 step 7: objective=0.95389193
2017/08/29 01:17:30 Training value function...
2017/08/29 01:17:32 step 0: mse=140.755244 step=0.100000
2017/08/29 01:17:34 step 1: mse=136.861126 step=0.100000
2017/08/29 01:17:35 step 2: mse=133.599396 step=0.100000
2017/08/29 01:17:36 step 3: mse=130.744419 step=0.100000
2017/08/29 01:17:37 step 4: mse=128.314062 step=0.100000
2017/08/29 01:17:38 step 5: mse=126.439141 step=0.100000
2017/08/29 01:17:40 step 6: mse=124.922307 step=0.100000
2017/08/29 01:17:41 step 7: mse=123.515929 step=0.100000
2017/08/29 01:17:41 Saving...
2017/08/29 01:17:41 Gathering batch of experience...
2017/08/29 01:18:28 batch 832: mean=185.285714 stddev=145.941587 entropy=0.327587 frames=6163 count=35
2017/08/29 01:18:28 Training policy...
2017/08/29 01:18:33 step 0: objective=1.3219789
2017/08/29 01:18:35 step 1: objective=1.3315556
2017/08/29 01:18:37 step 2: objective=1.3366431
2017/08/29 01:18:40 step 3: objective=1.3443722
2017/08/29 01:18:42 step 4: objective=1.348036
2017/08/29 01:18:44 step 5: objective=1.3525746
2017/08/29 01:18:46 step 6: objective=1.3548849
2017/08/29 01:18:48 step 7: objective=1.3579494
2017/08/29 01:18:48 Training value function...
2017/08/29 01:18:51 step 0: mse=172.800307 step=0.100000
2017/08/29 01:18:52 step 1: mse=169.969815 step=0.100000
2017/08/29 01:18:53 step 2: mse=167.577093 step=0.100000
2017/08/29 01:18:54 step 3: mse=165.531977 step=0.100000
2017/08/29 01:18:56 step 4: mse=163.606084 step=0.100000
2017/08/29 01:18:57 step 5: mse=162.074759 step=0.100000
2017/08/29 01:18:58 step 6: mse=160.523013 step=0.100000
2017/08/29 01:19:00 step 7: mse=159.169384 step=0.100000
2017/08/29 01:19:00 Saving...
2017/08/29 01:19:00 Gathering batch of experience...
2017/08/29 01:19:49 batch 833: mean=165.447368 stddev=141.346848 entropy=0.330032 frames=6087 count=38
2017/08/29 01:19:49 Training policy...
2017/08/29 01:19:53 step 0: objective=0.8045999
2017/08/29 01:19:56 step 1: objective=0.81213146
2017/08/29 01:19:58 step 2: objective=0.81536615
2017/08/29 01:20:00 step 3: objective=0.81978613
2017/08/29 01:20:02 step 4: objective=0.8239919
2017/08/29 01:20:04 step 5: objective=0.8304493
2017/08/29 01:20:06 step 6: objective=0.8347719
2017/08/29 01:20:08 step 7: objective=0.83692944
2017/08/29 01:20:08 Training value function...
2017/08/29 01:20:11 step 0: mse=149.590184 step=0.100000
2017/08/29 01:20:12 step 1: mse=148.040686 step=0.100000
2017/08/29 01:20:13 step 2: mse=146.831607 step=0.100000
2017/08/29 01:20:15 step 3: mse=145.659625 step=0.100000
2017/08/29 01:20:16 step 4: mse=144.525536 step=0.100000
2017/08/29 01:20:17 step 5: mse=143.498935 step=0.100000
2017/08/29 01:20:18 step 6: mse=142.310241 step=0.100000
2017/08/29 01:20:20 step 7: mse=141.463962 step=0.100000
2017/08/29 01:20:20 Saving...
2017/08/29 01:20:20 Gathering batch of experience...
2017/08/29 01:21:06 batch 834: mean=181.600000 stddev=136.401550 entropy=0.334033 frames=5896 count=35
2017/08/29 01:21:06 Training policy...
2017/08/29 01:21:11 step 0: objective=1.4315704
2017/08/29 01:21:13 step 1: objective=1.4375799
2017/08/29 01:21:15 step 2: objective=1.4431843
2017/08/29 01:21:17 step 3: objective=1.449716
2017/08/29 01:21:19 step 4: objective=1.454068
2017/08/29 01:21:21 step 5: objective=1.457776
2017/08/29 01:21:23 step 6: objective=1.4617112
2017/08/29 01:21:25 step 7: objective=1.4640623
2017/08/29 01:21:25 Training value function...
2017/08/29 01:21:28 step 0: mse=181.213818 step=0.100000
2017/08/29 01:21:29 step 1: mse=178.668337 step=0.100000
2017/08/29 01:21:30 step 2: mse=176.176099 step=0.100000
2017/08/29 01:21:31 step 3: mse=173.459567 step=0.100000
2017/08/29 01:21:32 step 4: mse=171.541458 step=0.100000
2017/08/29 01:21:34 step 5: mse=169.711965 step=0.100000
2017/08/29 01:21:35 step 6: mse=168.009413 step=0.100000
2017/08/29 01:21:36 step 7: mse=166.366958 step=0.100000
2017/08/29 01:21:36 Saving...
2017/08/29 01:21:36 Gathering batch of experience...
2017/08/29 01:22:21 batch 835: mean=223.034483 stddev=166.372760 entropy=0.341302 frames=6043 count=29
2017/08/29 01:22:21 Training policy...
2017/08/29 01:22:26 step 0: objective=1.6976645
2017/08/29 01:22:28 step 1: objective=1.7049899
2017/08/29 01:22:30 step 2: objective=1.7085807
2017/08/29 01:22:32 step 3: objective=1.712805
2017/08/29 01:22:34 step 4: objective=1.7173078
2017/08/29 01:22:36 step 5: objective=1.7223886
2017/08/29 01:22:38 step 6: objective=1.7270765
2017/08/29 01:22:40 step 7: objective=1.7292918
2017/08/29 01:22:40 Training value function...
2017/08/29 01:22:43 step 0: mse=160.643227 step=0.100000
2017/08/29 01:22:44 step 1: mse=156.002804 step=0.100000
2017/08/29 01:22:45 step 2: mse=152.130038 step=0.100000
2017/08/29 01:22:47 step 3: mse=148.891386 step=0.100000
2017/08/29 01:22:48 step 4: mse=146.122829 step=0.100000
2017/08/29 01:22:49 step 5: mse=143.684023 step=0.100000
2017/08/29 01:22:50 step 6: mse=141.512300 step=0.100000
2017/08/29 01:22:52 step 7: mse=139.535972 step=0.100000
2017/08/29 01:22:52 Saving...
2017/08/29 01:22:52 Gathering batch of experience...
2017/08/29 01:23:34 batch 836: mean=173.424242 stddev=150.993885 entropy=0.328178 frames=5567 count=33
2017/08/29 01:23:34 Training policy...
2017/08/29 01:23:39 step 0: objective=0.3832293
2017/08/29 01:23:41 step 1: objective=0.38964853
2017/08/29 01:23:43 step 2: objective=0.3954241
2017/08/29 01:23:45 step 3: objective=0.40263483
2017/08/29 01:23:46 step 4: objective=0.40684688
2017/08/29 01:23:48 step 5: objective=0.40962648
2017/08/29 01:23:50 step 6: objective=0.41588274
2017/08/29 01:23:52 step 7: objective=0.42122924
2017/08/29 01:23:52 Training value function...
2017/08/29 01:23:55 step 0: mse=137.928029 step=0.100000
2017/08/29 01:23:56 step 1: mse=136.529685 step=0.100000
2017/08/29 01:23:57 step 2: mse=135.821123 step=0.100000
2017/08/29 01:23:58 step 3: mse=134.641649 step=0.100000
2017/08/29 01:23:59 step 4: mse=133.859875 step=0.100000
2017/08/29 01:24:00 step 5: mse=133.096383 step=0.100000
2017/08/29 01:24:02 step 6: mse=132.350704 step=0.100000
2017/08/29 01:24:03 step 7: mse=131.789593 step=0.100000
2017/08/29 01:24:03 Saving...
2017/08/29 01:24:03 Gathering batch of experience...
2017/08/29 01:24:50 batch 837: mean=198.906250 stddev=144.775982 entropy=0.336848 frames=6142 count=32
2017/08/29 01:24:50 Training policy...
2017/08/29 01:24:55 step 0: objective=1.0307426
2017/08/29 01:24:57 step 1: objective=1.0356948
2017/08/29 01:24:59 step 2: objective=1.0418973
2017/08/29 01:25:02 step 3: objective=1.0450171
2017/08/29 01:25:04 step 4: objective=1.0488051
2017/08/29 01:25:06 step 5: objective=1.0517603
2017/08/29 01:25:08 step 6: objective=1.0555134
2017/08/29 01:25:10 step 7: objective=1.057707
2017/08/29 01:25:10 Training value function...
2017/08/29 01:25:13 step 0: mse=138.488943 step=0.100000
2017/08/29 01:25:14 step 1: mse=136.141954 step=0.100000
2017/08/29 01:25:15 step 2: mse=134.364824 step=0.100000
2017/08/29 01:25:16 step 3: mse=132.962174 step=0.100000
2017/08/29 01:25:18 step 4: mse=131.503232 step=0.100000
2017/08/29 01:25:19 step 5: mse=130.432919 step=0.100000
2017/08/29 01:25:20 step 6: mse=129.445016 step=0.100000
2017/08/29 01:25:22 step 7: mse=128.519170 step=0.100000
2017/08/29 01:25:22 Saving...
2017/08/29 01:25:22 Gathering batch of experience...
2017/08/29 01:26:08 batch 838: mean=176.388889 stddev=133.788448 entropy=0.328068 frames=5905 count=36
2017/08/29 01:26:08 Training policy...
2017/08/29 01:26:13 step 0: objective=1.1253049
2017/08/29 01:26:15 step 1: objective=1.1297152
2017/08/29 01:26:17 step 2: objective=1.1385359
2017/08/29 01:26:19 step 3: objective=1.1431577
2017/08/29 01:26:21 step 4: objective=1.1473786
2017/08/29 01:26:23 step 5: objective=1.1497755
2017/08/29 01:26:25 step 6: objective=1.1528964
2017/08/29 01:26:27 step 7: objective=1.1551468
2017/08/29 01:26:27 Training value function...
2017/08/29 01:26:30 step 0: mse=171.383705 step=0.100000
2017/08/29 01:26:31 step 1: mse=169.431022 step=0.100000
2017/08/29 01:26:32 step 2: mse=167.302781 step=0.100000
2017/08/29 01:26:33 step 3: mse=166.120174 step=0.100000
2017/08/29 01:26:35 step 4: mse=164.820112 step=0.100000
2017/08/29 01:26:36 step 5: mse=163.731632 step=0.100000
2017/08/29 01:26:37 step 6: mse=162.412488 step=0.100000
2017/08/29 01:26:38 step 7: mse=161.089913 step=0.100000
2017/08/29 01:26:38 Saving...
2017/08/29 01:26:38 Gathering batch of experience...
2017/08/29 01:27:26 batch 839: mean=184.742857 stddev=163.970092 entropy=0.335408 frames=6338 count=35
2017/08/29 01:27:26 Training policy...
2017/08/29 01:27:31 step 0: objective=0.81275725
2017/08/29 01:27:33 step 1: objective=0.8212095
2017/08/29 01:27:35 step 2: objective=0.8285155
2017/08/29 01:27:38 step 3: objective=0.8345483
2017/08/29 01:27:40 step 4: objective=0.83999836
2017/08/29 01:27:42 step 5: objective=0.84246826
2017/08/29 01:27:44 step 6: objective=0.84533125
2017/08/29 01:27:46 step 7: objective=0.8478371
2017/08/29 01:27:46 Training value function...
2017/08/29 01:27:49 step 0: mse=157.901825 step=0.100000
2017/08/29 01:27:50 step 1: mse=154.502493 step=0.100000
2017/08/29 01:27:52 step 2: mse=151.500010 step=0.100000
2017/08/29 01:27:53 step 3: mse=149.250206 step=0.100000
2017/08/29 01:27:54 step 4: mse=148.060867 step=0.100000
2017/08/29 01:27:56 step 5: mse=146.292971 step=0.100000
2017/08/29 01:27:57 step 6: mse=144.663706 step=0.100000
2017/08/29 01:27:58 step 7: mse=143.407750 step=0.100000
2017/08/29 01:27:58 Saving...
2017/08/29 01:27:58 Gathering batch of experience...
2017/08/29 01:28:45 batch 840: mean=181.750000 stddev=137.137274 entropy=0.338931 frames=6059 count=36
2017/08/29 01:28:45 Training policy...
2017/08/29 01:28:50 step 0: objective=1.3577409
2017/08/29 01:28:52 step 1: objective=1.3617483
2017/08/29 01:28:54 step 2: objective=1.3665757
2017/08/29 01:28:57 step 3: objective=1.3699768
2017/08/29 01:28:59 step 4: objective=1.373896
2017/08/29 01:29:01 step 5: objective=1.3779324
2017/08/29 01:29:03 step 6: objective=1.3817952
2017/08/29 01:29:05 step 7: objective=1.3877906
2017/08/29 01:29:05 Training value function...
2017/08/29 01:29:07 step 0: mse=167.922122 step=0.100000
2017/08/29 01:29:09 step 1: mse=164.670781 step=0.100000
2017/08/29 01:29:10 step 2: mse=161.325744 step=0.100000
2017/08/29 01:29:11 step 3: mse=158.763613 step=0.100000
2017/08/29 01:29:13 step 4: mse=156.930145 step=0.100000
2017/08/29 01:29:14 step 5: mse=155.376697 step=0.100000
2017/08/29 01:29:15 step 6: mse=153.585691 step=0.100000
2017/08/29 01:29:16 step 7: mse=152.079291 step=0.100000
2017/08/29 01:29:16 Saving...
2017/08/29 01:29:16 Gathering batch of experience...
2017/08/29 01:30:02 batch 841: mean=171.914286 stddev=138.895721 entropy=0.333299 frames=5775 count=35
2017/08/29 01:30:02 Training policy...
2017/08/29 01:30:06 step 0: objective=0.71775997
2017/08/29 01:30:08 step 1: objective=0.7237861
2017/08/29 01:30:10 step 2: objective=0.7288414
2017/08/29 01:30:12 step 3: objective=0.73549074
2017/08/29 01:30:14 step 4: objective=0.7414037
2017/08/29 01:30:16 step 5: objective=0.74597317
2017/08/29 01:30:18 step 6: objective=0.75318944
2017/08/29 01:30:20 step 7: objective=0.75671023
2017/08/29 01:30:20 Training value function...
2017/08/29 01:30:23 step 0: mse=173.199641 step=0.100000
2017/08/29 01:30:24 step 1: mse=170.353558 step=0.100000
2017/08/29 01:30:25 step 2: mse=168.038643 step=0.100000
2017/08/29 01:30:26 step 3: mse=166.164649 step=0.100000
2017/08/29 01:30:28 step 4: mse=164.344015 step=0.100000
2017/08/29 01:30:29 step 5: mse=162.906365 step=0.100000
2017/08/29 01:30:30 step 6: mse=161.673138 step=0.100000
2017/08/29 01:30:31 step 7: mse=160.180731 step=0.100000
2017/08/29 01:30:31 Saving...
2017/08/29 01:30:31 Gathering batch of experience...
2017/08/29 01:31:17 batch 842: mean=156.500000 stddev=126.067552 entropy=0.333426 frames=5718 count=36
2017/08/29 01:31:17 Training policy...
2017/08/29 01:31:22 step 0: objective=0.16341983
2017/08/29 01:31:24 step 1: objective=0.17406031
2017/08/29 01:31:26 step 2: objective=0.18342203
2017/08/29 01:31:28 step 3: objective=0.18758832
2017/08/29 01:31:30 step 4: objective=0.19243081
2017/08/29 01:31:32 step 5: objective=0.2004669
2017/08/29 01:31:34 step 6: objective=0.20559563
2017/08/29 01:31:36 step 7: objective=0.20999095
2017/08/29 01:31:36 Training value function...
2017/08/29 01:31:38 step 0: mse=143.866353 step=0.100000
2017/08/29 01:31:39 step 1: mse=142.066608 step=0.100000
2017/08/29 01:31:41 step 2: mse=140.545774 step=0.100000
2017/08/29 01:31:42 step 3: mse=139.321190 step=0.100000
2017/08/29 01:31:43 step 4: mse=138.431188 step=0.100000
2017/08/29 01:31:44 step 5: mse=137.557817 step=0.100000
2017/08/29 01:31:45 step 6: mse=136.943760 step=0.100000
2017/08/29 01:31:47 step 7: mse=136.243002 step=0.100000
2017/08/29 01:31:47 Saving...
2017/08/29 01:31:47 Gathering batch of experience...
2017/08/29 01:32:38 batch 843: mean=180.461538 stddev=135.972442 entropy=0.328855 frames=6409 count=39
2017/08/29 01:32:38 Training policy...
2017/08/29 01:32:43 step 0: objective=1.9549928
2017/08/29 01:32:45 step 1: objective=1.958912
2017/08/29 01:32:47 step 2: objective=1.96371
2017/08/29 01:32:49 step 3: objective=1.9688321
2017/08/29 01:32:52 step 4: objective=1.9758909
2017/08/29 01:32:54 step 5: objective=1.9818275
2017/08/29 01:32:56 step 6: objective=1.9856391
2017/08/29 01:32:58 step 7: objective=1.9881623
2017/08/29 01:32:58 Training value function...
2017/08/29 01:33:01 step 0: mse=178.261216 step=0.100000
2017/08/29 01:33:02 step 1: mse=173.534900 step=0.100000
2017/08/29 01:33:04 step 2: mse=169.713504 step=0.100000
2017/08/29 01:33:05 step 3: mse=166.123012 step=0.100000
2017/08/29 01:33:06 step 4: mse=163.283804 step=0.100000
2017/08/29 01:33:08 step 5: mse=160.684760 step=0.100000
2017/08/29 01:33:09 step 6: mse=158.521805 step=0.100000
2017/08/29 01:33:10 step 7: mse=156.502230 step=0.100000
2017/08/29 01:33:10 Saving...
2017/08/29 01:33:10 Gathering batch of experience...
2017/08/29 01:33:57 batch 844: mean=149.256410 stddev=142.443820 entropy=0.332079 frames=5592 count=39
2017/08/29 01:33:57 Training policy...
2017/08/29 01:34:01 step 0: objective=0.74485666
2017/08/29 01:34:03 step 1: objective=0.750873
2017/08/29 01:34:05 step 2: objective=0.7552545
2017/08/29 01:34:07 step 3: objective=0.75995404
2017/08/29 01:34:09 step 4: objective=0.76695013
2017/08/29 01:34:11 step 5: objective=0.77055687
2017/08/29 01:34:13 step 6: objective=0.77316767
2017/08/29 01:34:15 step 7: objective=0.7769138
2017/08/29 01:34:15 Training value function...
2017/08/29 01:34:17 step 0: mse=166.643670 step=0.100000
2017/08/29 01:34:18 step 1: mse=163.559258 step=0.100000
2017/08/29 01:34:20 step 2: mse=160.979637 step=0.100000
2017/08/29 01:34:21 step 3: mse=158.850895 step=0.100000
2017/08/29 01:34:22 step 4: mse=156.979305 step=0.100000
2017/08/29 01:34:23 step 5: mse=155.410026 step=0.100000
2017/08/29 01:34:24 step 6: mse=154.043909 step=0.100000
2017/08/29 01:34:25 step 7: mse=152.938478 step=0.100000
2017/08/29 01:34:25 Saving...
2017/08/29 01:34:26 Gathering batch of experience...
2017/08/29 01:35:08 batch 845: mean=142.974359 stddev=111.219461 entropy=0.334463 frames=5154 count=39
2017/08/29 01:35:08 Training policy...
2017/08/29 01:35:12 step 0: objective=1.0124801
2017/08/29 01:35:14 step 1: objective=1.0235834
2017/08/29 01:35:16 step 2: objective=1.0334625
2017/08/29 01:35:18 step 3: objective=1.0423044
2017/08/29 01:35:20 step 4: objective=1.0493455
2017/08/29 01:35:21 step 5: objective=1.0543516
2017/08/29 01:35:23 step 6: objective=1.0582119
2017/08/29 01:35:25 step 7: objective=1.0611922
2017/08/29 01:35:25 Training value function...
2017/08/29 01:35:27 step 0: mse=156.371530 step=0.100000
2017/08/29 01:35:28 step 1: mse=153.696429 step=0.100000
2017/08/29 01:35:29 step 2: mse=151.417801 step=0.100000
2017/08/29 01:35:30 step 3: mse=149.310584 step=0.100000
2017/08/29 01:35:32 step 4: mse=147.639300 step=0.100000
2017/08/29 01:35:33 step 5: mse=146.302208 step=0.100000
2017/08/29 01:35:34 step 6: mse=145.139090 step=0.100000
2017/08/29 01:35:35 step 7: mse=144.185465 step=0.100000
2017/08/29 01:35:35 Saving...
2017/08/29 01:35:35 Gathering batch of experience...
2017/08/29 01:36:25 batch 846: mean=176.405405 stddev=145.869334 entropy=0.336291 frames=6366 count=37
2017/08/29 01:36:25 Training policy...
2017/08/29 01:36:30 step 0: objective=1.0835843
2017/08/29 01:36:32 step 1: objective=1.087988
2017/08/29 01:36:34 step 2: objective=1.0912101
2017/08/29 01:36:36 step 3: objective=1.0959027
2017/08/29 01:36:39 step 4: objective=1.1031951
2017/08/29 01:36:41 step 5: objective=1.1072763
2017/08/29 01:36:43 step 6: objective=1.1111529
2017/08/29 01:36:45 step 7: objective=1.1154884
2017/08/29 01:36:45 Training value function...
2017/08/29 01:36:48 step 0: mse=150.905697 step=0.100000
2017/08/29 01:36:49 step 1: mse=148.933604 step=0.100000
2017/08/29 01:36:51 step 2: mse=147.301605 step=0.100000
2017/08/29 01:36:52 step 3: mse=145.808491 step=0.100000
2017/08/29 01:36:53 step 4: mse=144.453147 step=0.100000
2017/08/29 01:36:55 step 5: mse=143.212517 step=0.100000
2017/08/29 01:36:56 step 6: mse=142.022375 step=0.100000
2017/08/29 01:36:57 step 7: mse=141.072742 step=0.100000
2017/08/29 01:36:57 Saving...
2017/08/29 01:36:57 Gathering batch of experience...
2017/08/29 01:37:44 batch 847: mean=187.323529 stddev=134.384812 entropy=0.335803 frames=6210 count=34
2017/08/29 01:37:44 Training policy...
2017/08/29 01:37:48 step 0: objective=1.113132
2017/08/29 01:37:51 step 1: objective=1.117579
2017/08/29 01:37:53 step 2: objective=1.122778
2017/08/29 01:37:55 step 3: objective=1.1280042
2017/08/29 01:37:57 step 4: objective=1.130522
2017/08/29 01:37:59 step 5: objective=1.1351713
2017/08/29 01:38:02 step 6: objective=1.1375744
2017/08/29 01:38:04 step 7: objective=1.14083
2017/08/29 01:38:04 Training value function...
2017/08/29 01:38:06 step 0: mse=125.405355 step=0.100000
2017/08/29 01:38:08 step 1: mse=122.825881 step=0.100000
2017/08/29 01:38:09 step 2: mse=120.655320 step=0.100000
2017/08/29 01:38:10 step 3: mse=118.592902 step=0.100000
2017/08/29 01:38:12 step 4: mse=116.829110 step=0.100000
2017/08/29 01:38:13 step 5: mse=115.393625 step=0.100000
2017/08/29 01:38:14 step 6: mse=114.061063 step=0.100000
2017/08/29 01:38:15 step 7: mse=113.015850 step=0.100000
2017/08/29 01:38:15 Saving...
2017/08/29 01:38:16 Gathering batch of experience...
2017/08/29 01:38:57 batch 848: mean=169.235294 stddev=130.049778 entropy=0.334051 frames=5470 count=34
2017/08/29 01:38:57 Training policy...
2017/08/29 01:39:01 step 0: objective=1.1319818
2017/08/29 01:39:03 step 1: objective=1.1370839
2017/08/29 01:39:05 step 2: objective=1.1459585
2017/08/29 01:39:07 step 3: objective=1.1517168
2017/08/29 01:39:09 step 4: objective=1.1570013
2017/08/29 01:39:11 step 5: objective=1.1650145
2017/08/29 01:39:13 step 6: objective=1.1695158
2017/08/29 01:39:15 step 7: objective=1.1729777
2017/08/29 01:39:15 Training value function...
2017/08/29 01:39:17 step 0: mse=137.498849 step=0.100000
2017/08/29 01:39:18 step 1: mse=135.139143 step=0.100000
2017/08/29 01:39:19 step 2: mse=133.181095 step=0.100000
2017/08/29 01:39:20 step 3: mse=131.310089 step=0.100000
2017/08/29 01:39:22 step 4: mse=129.822214 step=0.100000
2017/08/29 01:39:23 step 5: mse=128.484838 step=0.100000
2017/08/29 01:39:24 step 6: mse=127.132822 step=0.100000
2017/08/29 01:39:25 step 7: mse=126.042500 step=0.100000
2017/08/29 01:39:25 Saving...
2017/08/29 01:39:25 Gathering batch of experience...
2017/08/29 01:40:11 batch 849: mean=223.172414 stddev=171.415822 entropy=0.334154 frames=5862 count=29
2017/08/29 01:40:11 Training policy...
2017/08/29 01:40:16 step 0: objective=2.4476244
2017/08/29 01:40:18 step 1: objective=2.4554205
2017/08/29 01:40:20 step 2: objective=2.4628954
2017/08/29 01:40:22 step 3: objective=2.468674
2017/08/29 01:40:24 step 4: objective=2.4727795
2017/08/29 01:40:26 step 5: objective=2.4758713
2017/08/29 01:40:28 step 6: objective=2.4791315
2017/08/29 01:40:30 step 7: objective=2.4819894
2017/08/29 01:40:30 Training value function...
2017/08/29 01:40:33 step 0: mse=223.577071 step=0.100000
2017/08/29 01:40:34 step 1: mse=216.020443 step=0.100000
2017/08/29 01:40:35 step 2: mse=209.480443 step=0.100000
2017/08/29 01:40:36 step 3: mse=203.287776 step=0.100000
2017/08/29 01:40:38 step 4: mse=198.004934 step=0.100000
2017/08/29 01:40:39 step 5: mse=193.488925 step=0.100000
2017/08/29 01:40:40 step 6: mse=189.471846 step=0.100000
2017/08/29 01:40:41 step 7: mse=186.175142 step=0.100000
2017/08/29 01:40:41 Saving...
2017/08/29 01:40:41 Gathering batch of experience...
2017/08/29 01:41:22 batch 850: mean=159.000000 stddev=133.020084 entropy=0.329520 frames=5283 count=35
2017/08/29 01:41:22 Training policy...
2017/08/29 01:41:26 step 0: objective=0.29840052
2017/08/29 01:41:28 step 1: objective=0.30271927
2017/08/29 01:41:30 step 2: objective=0.3092719
2017/08/29 01:41:32 step 3: objective=0.31521112
2017/08/29 01:41:34 step 4: objective=0.32359698
2017/08/29 01:41:36 step 5: objective=0.33107397
2017/08/29 01:41:38 step 6: objective=0.33721673
2017/08/29 01:41:40 step 7: objective=0.3398843
2017/08/29 01:41:40 Training value function...
2017/08/29 01:41:42 step 0: mse=163.493257 step=0.100000
2017/08/29 01:41:43 step 1: mse=161.926286 step=0.100000
2017/08/29 01:41:44 step 2: mse=160.678015 step=0.100000
2017/08/29 01:41:45 step 3: mse=159.402092 step=0.100000
2017/08/29 01:41:46 step 4: mse=158.679619 step=0.100000
2017/08/29 01:41:47 step 5: mse=157.811196 step=0.100000
2017/08/29 01:41:48 step 6: mse=156.785142 step=0.100000
2017/08/29 01:41:50 step 7: mse=155.880177 step=0.100000
2017/08/29 01:41:50 Saving...
2017/08/29 01:41:50 Gathering batch of experience...
2017/08/29 01:42:36 batch 851: mean=184.294118 stddev=118.995682 entropy=0.326221 frames=5844 count=34
2017/08/29 01:42:36 Training policy...
2017/08/29 01:42:40 step 0: objective=1.1853294
2017/08/29 01:42:42 step 1: objective=1.1917207
2017/08/29 01:42:44 step 2: objective=1.1966833
2017/08/29 01:42:47 step 3: objective=1.2006636
2017/08/29 01:42:49 step 4: objective=1.2047447
2017/08/29 01:42:51 step 5: objective=1.2085513
2017/08/29 01:42:53 step 6: objective=1.2127707
2017/08/29 01:42:55 step 7: objective=1.2152369
2017/08/29 01:42:55 Training value function...
2017/08/29 01:42:57 step 0: mse=142.655409 step=0.100000
2017/08/29 01:42:58 step 1: mse=139.756060 step=0.100000
2017/08/29 01:43:00 step 2: mse=137.443268 step=0.100000
2017/08/29 01:43:01 step 3: mse=135.405660 step=0.100000
2017/08/29 01:43:02 step 4: mse=133.453999 step=0.100000
2017/08/29 01:43:03 step 5: mse=131.984438 step=0.100000
2017/08/29 01:43:04 step 6: mse=130.556044 step=0.100000
2017/08/29 01:43:06 step 7: mse=129.393839 step=0.100000
2017/08/29 01:43:06 Saving...
2017/08/29 01:43:06 Gathering batch of experience...
2017/08/29 01:43:58 batch 852: mean=174.641026 stddev=135.085251 entropy=0.330301 frames=6508 count=39
2017/08/29 01:43:58 Training policy...
2017/08/29 01:44:03 step 0: objective=0.78919214
2017/08/29 01:44:05 step 1: objective=0.79373676
2017/08/29 01:44:08 step 2: objective=0.79891974
2017/08/29 01:44:10 step 3: objective=0.8048437
2017/08/29 01:44:12 step 4: objective=0.8097235
2017/08/29 01:44:15 step 5: objective=0.8138398
2017/08/29 01:44:17 step 6: objective=0.8156611
2017/08/29 01:44:19 step 7: objective=0.81999624
2017/08/29 01:44:19 Training value function...
2017/08/29 01:44:22 step 0: mse=138.855727 step=0.100000
2017/08/29 01:44:23 step 1: mse=137.839247 step=0.100000
2017/08/29 01:44:25 step 2: mse=136.678201 step=0.100000
2017/08/29 01:44:26 step 3: mse=135.930295 step=0.100000
2017/08/29 01:44:27 step 4: mse=134.946593 step=0.100000
2017/08/29 01:44:29 step 5: mse=134.108986 step=0.100000
2017/08/29 01:44:30 step 6: mse=133.558936 step=0.100000
2017/08/29 01:44:31 step 7: mse=132.895095 step=0.100000
2017/08/29 01:44:31 Saving...
2017/08/29 01:44:32 Gathering batch of experience...
2017/08/29 01:45:17 batch 853: mean=141.358974 stddev=131.546324 entropy=0.324183 frames=5299 count=39
2017/08/29 01:45:17 Training policy...
2017/08/29 01:45:21 step 0: objective=0.49535275
2017/08/29 01:45:23 step 1: objective=0.5014384
2017/08/29 01:45:25 step 2: objective=0.5079237
2017/08/29 01:45:27 step 3: objective=0.5132056
2017/08/29 01:45:29 step 4: objective=0.52020943
2017/08/29 01:45:30 step 5: objective=0.52769595
2017/08/29 01:45:32 step 6: objective=0.53145486
2017/08/29 01:45:34 step 7: objective=0.5353743
2017/08/29 01:45:34 Training value function...
2017/08/29 01:45:36 step 0: mse=171.725350 step=0.100000
2017/08/29 01:45:37 step 1: mse=169.008896 step=0.100000
2017/08/29 01:45:39 step 2: mse=166.635694 step=0.100000
2017/08/29 01:45:40 step 3: mse=164.612053 step=0.100000
2017/08/29 01:45:41 step 4: mse=162.897844 step=0.100000
2017/08/29 01:45:42 step 5: mse=161.281579 step=0.100000
2017/08/29 01:45:43 step 6: mse=160.013960 step=0.100000
2017/08/29 01:45:44 step 7: mse=158.582652 step=0.100000
2017/08/29 01:45:44 Saving...
2017/08/29 01:45:44 Gathering batch of experience...
2017/08/29 01:46:32 batch 854: mean=170.194444 stddev=144.396795 entropy=0.338703 frames=6111 count=36
2017/08/29 01:46:32 Training policy...
2017/08/29 01:46:37 step 0: objective=0.84498966
2017/08/29 01:46:39 step 1: objective=0.85108966
2017/08/29 01:46:41 step 2: objective=0.856864
2017/08/29 01:46:43 step 3: objective=0.860578
2017/08/29 01:46:46 step 4: objective=0.86535716
2017/08/29 01:46:48 step 5: objective=0.86791176
2017/08/29 01:46:50 step 6: objective=0.87087816
2017/08/29 01:46:52 step 7: objective=0.87499744
2017/08/29 01:46:52 Training value function...
2017/08/29 01:46:55 step 0: mse=140.437265 step=0.100000
2017/08/29 01:46:56 step 1: mse=137.399282 step=0.100000
2017/08/29 01:46:57 step 2: mse=135.057612 step=0.100000
2017/08/29 01:46:58 step 3: mse=132.975523 step=0.100000
2017/08/29 01:47:00 step 4: mse=131.091972 step=0.100000
2017/08/29 01:47:01 step 5: mse=129.798286 step=0.100000
2017/08/29 01:47:02 step 6: mse=128.489751 step=0.100000
2017/08/29 01:47:04 step 7: mse=127.432323 step=0.100000
2017/08/29 01:47:04 Saving...
2017/08/29 01:47:04 Gathering batch of experience...
2017/08/29 01:47:49 batch 855: mean=186.366667 stddev=170.655302 entropy=0.338856 frames=5462 count=30
2017/08/29 01:47:49 Training policy...
2017/08/29 01:47:53 step 0: objective=1.166746
2017/08/29 01:47:55 step 1: objective=1.1753271
2017/08/29 01:47:57 step 2: objective=1.1808534
2017/08/29 01:47:59 step 3: objective=1.1853468
2017/08/29 01:48:01 step 4: objective=1.1902937
2017/08/29 01:48:03 step 5: objective=1.1950917
2017/08/29 01:48:05 step 6: objective=1.1991454
2017/08/29 01:48:07 step 7: objective=1.2022732
2017/08/29 01:48:07 Training value function...
2017/08/29 01:48:09 step 0: mse=157.890402 step=0.100000
2017/08/29 01:48:10 step 1: mse=153.657504 step=0.100000
2017/08/29 01:48:11 step 2: mse=150.496293 step=0.100000
2017/08/29 01:48:12 step 3: mse=147.830900 step=0.100000
2017/08/29 01:48:13 step 4: mse=145.332000 step=0.100000
2017/08/29 01:48:15 step 5: mse=143.841339 step=0.100000
2017/08/29 01:48:16 step 6: mse=142.193908 step=0.100000
2017/08/29 01:48:17 step 7: mse=140.368822 step=0.100000
2017/08/29 01:48:17 Saving...
2017/08/29 01:48:17 Gathering batch of experience...
2017/08/29 01:48:57 batch 856: mean=133.675676 stddev=119.996409 entropy=0.332006 frames=4908 count=37
2017/08/29 01:48:57 Training policy...
2017/08/29 01:49:01 step 0: objective=0.36526752
2017/08/29 01:49:03 step 1: objective=0.3732053
2017/08/29 01:49:04 step 2: objective=0.38417882
2017/08/29 01:49:06 step 3: objective=0.38948932
2017/08/29 01:49:08 step 4: objective=0.3936602
2017/08/29 01:49:10 step 5: objective=0.3986056
2017/08/29 01:49:11 step 6: objective=0.40193677
2017/08/29 01:49:13 step 7: objective=0.40517724
2017/08/29 01:49:13 Training value function...
2017/08/29 01:49:15 step 0: mse=158.696326 step=0.100000
2017/08/29 01:49:16 step 1: mse=156.421597 step=0.100000
2017/08/29 01:49:17 step 2: mse=154.624532 step=0.100000
2017/08/29 01:49:18 step 3: mse=153.268393 step=0.100000
2017/08/29 01:49:19 step 4: mse=151.805603 step=0.100000
2017/08/29 01:49:20 step 5: mse=150.750773 step=0.100000
2017/08/29 01:49:21 step 6: mse=149.535479 step=0.100000
2017/08/29 01:49:22 step 7: mse=148.547752 step=0.100000
2017/08/29 01:49:22 Saving...
2017/08/29 01:49:23 Gathering batch of experience...
2017/08/29 01:50:12 batch 857: mean=160.025641 stddev=155.782637 entropy=0.331055 frames=6048 count=39
2017/08/29 01:50:12 Training policy...
2017/08/29 01:50:16 step 0: objective=1.324861
2017/08/29 01:50:19 step 1: objective=1.3310302
2017/08/29 01:50:21 step 2: objective=1.3359119
2017/08/29 01:50:23 step 3: objective=1.3396202
2017/08/29 01:50:25 step 4: objective=1.3430692
2017/08/29 01:50:27 step 5: objective=1.3464819
2017/08/29 01:50:29 step 6: objective=1.3497534
2017/08/29 01:50:31 step 7: objective=1.3531548
2017/08/29 01:50:31 Training value function...
2017/08/29 01:50:34 step 0: mse=179.840630 step=0.100000
2017/08/29 01:50:35 step 1: mse=176.393886 step=0.100000
2017/08/29 01:50:36 step 2: mse=173.095023 step=0.100000
2017/08/29 01:50:38 step 3: mse=170.445279 step=0.100000
2017/08/29 01:50:39 step 4: mse=168.238311 step=0.100000
2017/08/29 01:50:40 step 5: mse=166.000237 step=0.100000
2017/08/29 01:50:42 step 6: mse=163.850478 step=0.100000
2017/08/29 01:50:43 step 7: mse=161.994181 step=0.100000
2017/08/29 01:50:43 Saving...
2017/08/29 01:50:43 Gathering batch of experience...
2017/08/29 01:51:36 batch 858: mean=197.447368 stddev=168.482499 entropy=0.337017 frames=7011 count=38
2017/08/29 01:51:36 Training policy...
2017/08/29 01:51:42 step 0: objective=1.8435729
2017/08/29 01:51:44 step 1: objective=1.8520191
2017/08/29 01:51:47 step 2: objective=1.8588063
2017/08/29 01:51:49 step 3: objective=1.8643553
2017/08/29 01:51:52 step 4: objective=1.8676738
2017/08/29 01:51:54 step 5: objective=1.8736961
2017/08/29 01:51:57 step 6: objective=1.8796686
2017/08/29 01:51:59 step 7: objective=1.8832668
2017/08/29 01:51:59 Training value function...
2017/08/29 01:52:02 step 0: mse=165.983571 step=0.100000
2017/08/29 01:52:04 step 1: mse=162.825592 step=0.100000
2017/08/29 01:52:05 step 2: mse=159.868119 step=0.100000
2017/08/29 01:52:06 step 3: mse=157.634876 step=0.100000
2017/08/29 01:52:08 step 4: mse=155.284596 step=0.100000
2017/08/29 01:52:09 step 5: mse=153.575056 step=0.100000
2017/08/29 01:52:11 step 6: mse=151.966891 step=0.100000
2017/08/29 01:52:12 step 7: mse=150.494788 step=0.100000
2017/08/29 01:52:12 Saving...
2017/08/29 01:52:12 Gathering batch of experience...
2017/08/29 01:52:59 batch 859: mean=194.029412 stddev=130.248966 entropy=0.325757 frames=6185 count=34
2017/08/29 01:52:59 Training policy...
2017/08/29 01:53:04 step 0: objective=1.2638965
2017/08/29 01:53:06 step 1: objective=1.2697172
2017/08/29 01:53:08 step 2: objective=1.2755029
2017/08/29 01:53:11 step 3: objective=1.2825845
2017/08/29 01:53:13 step 4: objective=1.2858809
2017/08/29 01:53:15 step 5: objective=1.2886406
2017/08/29 01:53:17 step 6: objective=1.2918534
2017/08/29 01:53:19 step 7: objective=1.2957971
2017/08/29 01:53:19 Training value function...
2017/08/29 01:53:22 step 0: mse=163.821981 step=0.100000
2017/08/29 01:53:23 step 1: mse=160.778459 step=0.100000
2017/08/29 01:53:25 step 2: mse=158.590346 step=0.100000
2017/08/29 01:53:26 step 3: mse=156.564603 step=0.100000
2017/08/29 01:53:27 step 4: mse=154.465615 step=0.100000
2017/08/29 01:53:28 step 5: mse=152.577226 step=0.100000
2017/08/29 01:53:30 step 6: mse=151.221297 step=0.100000
2017/08/29 01:53:31 step 7: mse=149.790805 step=0.100000
2017/08/29 01:53:31 Saving...
2017/08/29 01:53:31 Gathering batch of experience...
2017/08/29 01:54:16 batch 860: mean=166.142857 stddev=136.161908 entropy=0.326430 frames=5644 count=35
2017/08/29 01:54:16 Training policy...
2017/08/29 01:54:21 step 0: objective=0.5213222
2017/08/29 01:54:23 step 1: objective=0.52822375
2017/08/29 01:54:25 step 2: objective=0.53354627
2017/08/29 01:54:27 step 3: objective=0.53992057
2017/08/29 01:54:29 step 4: objective=0.5459333
2017/08/29 01:54:31 step 5: objective=0.55010056
2017/08/29 01:54:33 step 6: objective=0.554111
2017/08/29 01:54:35 step 7: objective=0.55663055
2017/08/29 01:54:35 Training value function...
2017/08/29 01:54:37 step 0: mse=163.529751 step=0.100000
2017/08/29 01:54:39 step 1: mse=161.164427 step=0.100000
2017/08/29 01:54:40 step 2: mse=158.789385 step=0.100000
2017/08/29 01:54:41 step 3: mse=156.468166 step=0.100000
2017/08/29 01:54:42 step 4: mse=154.793253 step=0.100000
2017/08/29 01:54:43 step 5: mse=152.807234 step=0.100000
2017/08/29 01:54:45 step 6: mse=151.866225 step=0.100000
2017/08/29 01:54:46 step 7: mse=150.656628 step=0.100000
2017/08/29 01:54:46 Saving...
2017/08/29 01:54:46 Gathering batch of experience...
2017/08/29 01:55:34 batch 861: mean=154.487179 stddev=113.304869 entropy=0.331462 frames=5806 count=39
2017/08/29 01:55:34 Training policy...
2017/08/29 01:55:39 step 0: objective=0.82408977
2017/08/29 01:55:41 step 1: objective=0.83414054
2017/08/29 01:55:43 step 2: objective=0.84187233
2017/08/29 01:55:45 step 3: objective=0.8445676
2017/08/29 01:55:47 step 4: objective=0.84954184
2017/08/29 01:55:49 step 5: objective=0.8560278
2017/08/29 01:55:51 step 6: objective=0.8582928
2017/08/29 01:55:53 step 7: objective=0.8619239
2017/08/29 01:55:53 Training value function...
2017/08/29 01:55:56 step 0: mse=144.000085 step=0.100000
2017/08/29 01:55:57 step 1: mse=141.435744 step=0.100000
2017/08/29 01:55:58 step 2: mse=139.297460 step=0.100000
2017/08/29 01:55:59 step 3: mse=137.560624 step=0.100000
2017/08/29 01:56:01 step 4: mse=135.928951 step=0.100000
2017/08/29 01:56:02 step 5: mse=134.494794 step=0.100000
2017/08/29 01:56:03 step 6: mse=133.215076 step=0.100000
2017/08/29 01:56:04 step 7: mse=132.163043 step=0.100000
2017/08/29 01:56:04 Saving...
2017/08/29 01:56:04 Gathering batch of experience...
2017/08/29 01:56:46 batch 862: mean=161.166667 stddev=134.331369 entropy=0.332765 frames=5471 count=36
2017/08/29 01:56:46 Training policy...
2017/08/29 01:56:51 step 0: objective=1.3087125
2017/08/29 01:56:53 step 1: objective=1.318449
2017/08/29 01:56:55 step 2: objective=1.324795
2017/08/29 01:56:57 step 3: objective=1.3304445
2017/08/29 01:56:59 step 4: objective=1.3342144
2017/08/29 01:57:01 step 5: objective=1.3397735
2017/08/29 01:57:03 step 6: objective=1.3452765
2017/08/29 01:57:04 step 7: objective=1.3480791
2017/08/29 01:57:04 Training value function...
2017/08/29 01:57:07 step 0: mse=166.453900 step=0.100000
2017/08/29 01:57:08 step 1: mse=163.005558 step=0.100000
2017/08/29 01:57:09 step 2: mse=160.181081 step=0.100000
2017/08/29 01:57:10 step 3: mse=157.594187 step=0.100000
2017/08/29 01:57:11 step 4: mse=155.348729 step=0.100000
2017/08/29 01:57:13 step 5: mse=153.401719 step=0.100000
2017/08/29 01:57:14 step 6: mse=151.830624 step=0.100000
2017/08/29 01:57:15 step 7: mse=150.210684 step=0.100000
2017/08/29 01:57:15 Saving...
2017/08/29 01:57:15 Gathering batch of experience...
2017/08/29 01:57:57 batch 863: mean=203.142857 stddev=124.727622 entropy=0.329968 frames=5552 count=28
2017/08/29 01:57:57 Training policy...
2017/08/29 01:58:02 step 0: objective=1.0187463
2017/08/29 01:58:04 step 1: objective=1.0274891
2017/08/29 01:58:06 step 2: objective=1.0318508
2017/08/29 01:58:08 step 3: objective=1.0358104
2017/08/29 01:58:10 step 4: objective=1.041577
2017/08/29 01:58:12 step 5: objective=1.0471115
2017/08/29 01:58:14 step 6: objective=1.0491797
2017/08/29 01:58:15 step 7: objective=1.0511293
2017/08/29 01:58:15 Training value function...
2017/08/29 01:58:18 step 0: mse=144.470771 step=0.100000
2017/08/29 01:58:19 step 1: mse=141.958656 step=0.100000
2017/08/29 01:58:20 step 2: mse=139.860099 step=0.100000
2017/08/29 01:58:21 step 3: mse=137.953345 step=0.100000
2017/08/29 01:58:22 step 4: mse=136.192190 step=0.100000
2017/08/29 01:58:24 step 5: mse=134.335928 step=0.100000
2017/08/29 01:58:25 step 6: mse=132.958264 step=0.100000
2017/08/29 01:58:26 step 7: mse=131.679347 step=0.100000
2017/08/29 01:58:26 Saving...
2017/08/29 01:58:26 Gathering batch of experience...
2017/08/29 01:59:12 batch 864: mean=173.270270 stddev=110.752133 entropy=0.327254 frames=5953 count=37
2017/08/29 01:59:12 Training policy...
2017/08/29 01:59:17 step 0: objective=1.1735774
2017/08/29 01:59:19 step 1: objective=1.1827334
2017/08/29 01:59:21 step 2: objective=1.1874278
2017/08/29 01:59:23 step 3: objective=1.1935004
2017/08/29 01:59:25 step 4: objective=1.1982391
2017/08/29 01:59:27 step 5: objective=1.202385
2017/08/29 01:59:29 step 6: objective=1.2052715
2017/08/29 01:59:31 step 7: objective=1.2084329
2017/08/29 01:59:31 Training value function...
2017/08/29 01:59:34 step 0: mse=163.914048 step=0.100000
2017/08/29 01:59:35 step 1: mse=162.247215 step=0.100000
2017/08/29 01:59:36 step 2: mse=160.441083 step=0.100000
2017/08/29 01:59:38 step 3: mse=158.745015 step=0.100000
2017/08/29 01:59:39 step 4: mse=157.662669 step=0.100000
2017/08/29 01:59:40 step 5: mse=156.416823 step=0.100000
2017/08/29 01:59:42 step 6: mse=155.219889 step=0.100000
2017/08/29 01:59:43 step 7: mse=153.866222 step=0.100000
2017/08/29 01:59:43 Saving...
2017/08/29 01:59:43 Gathering batch of experience...
2017/08/29 02:00:30 batch 865: mean=136.000000 stddev=121.903698 entropy=0.324570 frames=5849 count=43
2017/08/29 02:00:30 Training policy...
2017/08/29 02:00:35 step 0: objective=-0.07215931
2017/08/29 02:00:37 step 1: objective=-0.067201644
2017/08/29 02:00:39 step 2: objective=-0.060596827
2017/08/29 02:00:41 step 3: objective=-0.0552433
2017/08/29 02:00:43 step 4: objective=-0.049555052
2017/08/29 02:00:45 step 5: objective=-0.044536892
2017/08/29 02:00:47 step 6: objective=-0.039526545
2017/08/29 02:00:49 step 7: objective=-0.036559604
2017/08/29 02:00:49 Training value function...
2017/08/29 02:00:52 step 0: mse=147.394891 step=0.100000
2017/08/29 02:00:53 step 1: mse=145.257797 step=0.100000
2017/08/29 02:00:54 step 2: mse=143.505109 step=0.100000
2017/08/29 02:00:55 step 3: mse=141.977553 step=0.100000
2017/08/29 02:00:57 step 4: mse=140.969643 step=0.100000
2017/08/29 02:00:58 step 5: mse=139.969048 step=0.100000
2017/08/29 02:00:59 step 6: mse=139.116998 step=0.100000
2017/08/29 02:01:00 step 7: mse=138.266091 step=0.100000
2017/08/29 02:01:00 Saving...
2017/08/29 02:01:00 Gathering batch of experience...
2017/08/29 02:01:44 batch 866: mean=180.935484 stddev=156.673883 entropy=0.330513 frames=5429 count=31
2017/08/29 02:01:44 Training policy...
2017/08/29 02:01:48 step 0: objective=1.8743551
2017/08/29 02:01:50 step 1: objective=1.8810134
2017/08/29 02:01:52 step 2: objective=1.8902394
2017/08/29 02:01:54 step 3: objective=1.8969353
2017/08/29 02:01:56 step 4: objective=1.9031746
2017/08/29 02:01:58 step 5: objective=1.9065473
2017/08/29 02:02:00 step 6: objective=1.9092103
2017/08/29 02:02:02 step 7: objective=1.9122999
2017/08/29 02:02:02 Training value function...
2017/08/29 02:02:04 step 0: mse=188.547003 step=0.100000
2017/08/29 02:02:05 step 1: mse=181.586010 step=0.100000
2017/08/29 02:02:07 step 2: mse=175.387243 step=0.100000
2017/08/29 02:02:08 step 3: mse=170.135586 step=0.100000
2017/08/29 02:02:09 step 4: mse=165.573460 step=0.100000
2017/08/29 02:02:10 step 5: mse=161.757199 step=0.100000
2017/08/29 02:02:11 step 6: mse=158.354222 step=0.100000
2017/08/29 02:02:12 step 7: mse=155.660356 step=0.100000
2017/08/29 02:02:12 Saving...
2017/08/29 02:02:12 Gathering batch of experience...
2017/08/29 02:02:59 batch 867: mean=209.375000 stddev=183.026082 entropy=0.327049 frames=6358 count=32
2017/08/29 02:02:59 Training policy...
2017/08/29 02:03:04 step 0: objective=1.9789006
2017/08/29 02:03:07 step 1: objective=1.9858532
2017/08/29 02:03:09 step 2: objective=1.9941434
2017/08/29 02:03:11 step 3: objective=1.9978718
2017/08/29 02:03:14 step 4: objective=2.001827
2017/08/29 02:03:16 step 5: objective=2.0076003
2017/08/29 02:03:18 step 6: objective=2.0106301
2017/08/29 02:03:21 step 7: objective=2.0141034
2017/08/29 02:03:21 Training value function...
2017/08/29 02:03:23 step 0: mse=171.848754 step=0.100000
2017/08/29 02:03:25 step 1: mse=165.780105 step=0.100000
2017/08/29 02:03:26 step 2: mse=160.733030 step=0.100000
2017/08/29 02:03:27 step 3: mse=156.192787 step=0.100000
2017/08/29 02:03:29 step 4: mse=152.243089 step=0.100000
2017/08/29 02:03:30 step 5: mse=149.010723 step=0.100000
2017/08/29 02:03:31 step 6: mse=146.141005 step=0.100000
2017/08/29 02:03:33 step 7: mse=143.825507 step=0.100000
2017/08/29 02:03:33 Saving...
2017/08/29 02:03:33 Gathering batch of experience...
2017/08/29 02:04:20 batch 868: mean=209.906250 stddev=178.267944 entropy=0.328794 frames=6114 count=32
2017/08/29 02:04:20 Training policy...
2017/08/29 02:04:25 step 0: objective=1.8131787
2017/08/29 02:04:27 step 1: objective=1.8174616
2017/08/29 02:04:30 step 2: objective=1.8259634
2017/08/29 02:04:32 step 3: objective=1.829538
2017/08/29 02:04:34 step 4: objective=1.8347678
2017/08/29 02:04:36 step 5: objective=1.8406403
2017/08/29 02:04:38 step 6: objective=1.8441752
2017/08/29 02:04:41 step 7: objective=1.8486469
2017/08/29 02:04:41 Training value function...
2017/08/29 02:04:43 step 0: mse=185.411356 step=0.100000
2017/08/29 02:04:44 step 1: mse=181.961056 step=0.100000
2017/08/29 02:04:46 step 2: mse=178.539262 step=0.100000
2017/08/29 02:04:47 step 3: mse=175.939681 step=0.100000
2017/08/29 02:04:48 step 4: mse=173.471178 step=0.100000
2017/08/29 02:04:50 step 5: mse=171.389736 step=0.100000
2017/08/29 02:04:51 step 6: mse=169.702376 step=0.100000
2017/08/29 02:04:52 step 7: mse=168.228725 step=0.100000
2017/08/29 02:04:52 Saving...
2017/08/29 02:04:52 Gathering batch of experience...
2017/08/29 02:05:42 batch 869: mean=188.171429 stddev=142.096644 entropy=0.333361 frames=6449 count=35
2017/08/29 02:05:42 Training policy...
2017/08/29 02:05:47 step 0: objective=0.24019495
2017/08/29 02:05:49 step 1: objective=0.2500819
2017/08/29 02:05:52 step 2: objective=0.25756827
2017/08/29 02:05:54 step 3: objective=0.26074806
2017/08/29 02:05:56 step 4: objective=0.26460412
2017/08/29 02:05:59 step 5: objective=0.27069455
2017/08/29 02:06:01 step 6: objective=0.27392027
2017/08/29 02:06:03 step 7: objective=0.2756749
2017/08/29 02:06:03 Training value function...
2017/08/29 02:06:06 step 0: mse=143.272729 step=0.100000
2017/08/29 02:06:07 step 1: mse=139.934230 step=0.100000
2017/08/29 02:06:09 step 2: mse=137.504394 step=0.100000
2017/08/29 02:06:10 step 3: mse=135.103541 step=0.100000
2017/08/29 02:06:11 step 4: mse=133.369437 step=0.100000
2017/08/29 02:06:13 step 5: mse=131.806018 step=0.100000
2017/08/29 02:06:14 step 6: mse=130.570355 step=0.100000
2017/08/29 02:06:15 step 7: mse=129.412995 step=0.100000
2017/08/29 02:06:15 Saving...
2017/08/29 02:06:16 Gathering batch of experience...
2017/08/29 02:07:01 batch 870: mean=175.588235 stddev=104.326162 entropy=0.328184 frames=5653 count=34
2017/08/29 02:07:01 Training policy...
2017/08/29 02:07:06 step 0: objective=0.8144742
2017/08/29 02:07:08 step 1: objective=0.8212823
2017/08/29 02:07:10 step 2: objective=0.82741654
2017/08/29 02:07:12 step 3: objective=0.83451915
2017/08/29 02:07:14 step 4: objective=0.8377289
2017/08/29 02:07:16 step 5: objective=0.84346116
2017/08/29 02:07:18 step 6: objective=0.8473335
2017/08/29 02:07:20 step 7: objective=0.8515058
2017/08/29 02:07:20 Training value function...
2017/08/29 02:07:22 step 0: mse=146.502803 step=0.100000
2017/08/29 02:07:23 step 1: mse=144.370419 step=0.100000
2017/08/29 02:07:25 step 2: mse=142.883647 step=0.100000
2017/08/29 02:07:26 step 3: mse=141.366579 step=0.100000
2017/08/29 02:07:27 step 4: mse=140.127367 step=0.100000
2017/08/29 02:07:28 step 5: mse=138.855795 step=0.100000
2017/08/29 02:07:29 step 6: mse=137.950699 step=0.100000
2017/08/29 02:07:31 step 7: mse=136.790573 step=0.100000
2017/08/29 02:07:31 Saving...
2017/08/29 02:07:31 Gathering batch of experience...
2017/08/29 02:08:24 batch 871: mean=172.157895 stddev=150.806870 entropy=0.322857 frames=6369 count=38
2017/08/29 02:08:24 Training policy...
2017/08/29 02:08:29 step 0: objective=0.8391828
2017/08/29 02:08:31 step 1: objective=0.8424876
2017/08/29 02:08:33 step 2: objective=0.84643644
2017/08/29 02:08:36 step 3: objective=0.84898347
2017/08/29 02:08:38 step 4: objective=0.85298556
2017/08/29 02:08:40 step 5: objective=0.8571659
2017/08/29 02:08:43 step 6: objective=0.86072475
2017/08/29 02:08:45 step 7: objective=0.86361414
2017/08/29 02:08:45 Training value function...
2017/08/29 02:08:48 step 0: mse=139.845380 step=0.100000
2017/08/29 02:08:49 step 1: mse=137.759858 step=0.100000
2017/08/29 02:08:50 step 2: mse=135.768391 step=0.100000
2017/08/29 02:08:52 step 3: mse=134.275607 step=0.100000
2017/08/29 02:08:53 step 4: mse=132.971537 step=0.100000
2017/08/29 02:08:54 step 5: mse=131.778780 step=0.100000
2017/08/29 02:08:56 step 6: mse=130.453771 step=0.100000
2017/08/29 02:08:57 step 7: mse=129.145689 step=0.100000
2017/08/29 02:08:57 Saving...
2017/08/29 02:08:57 Gathering batch of experience...
2017/08/29 02:09:41 batch 872: mean=158.000000 stddev=149.840926 entropy=0.334195 frames=5126 count=33
2017/08/29 02:09:41 Training policy...
2017/08/29 02:09:45 step 0: objective=0.7458587
2017/08/29 02:09:47 step 1: objective=0.75365543
2017/08/29 02:09:49 step 2: objective=0.7620902
2017/08/29 02:09:51 step 3: objective=0.7675901
2017/08/29 02:09:52 step 4: objective=0.7728024
2017/08/29 02:09:54 step 5: objective=0.777251
2017/08/29 02:09:56 step 6: objective=0.78179556
2017/08/29 02:09:58 step 7: objective=0.78546804
2017/08/29 02:09:58 Training value function...
2017/08/29 02:10:00 step 0: mse=171.599368 step=0.100000
2017/08/29 02:10:01 step 1: mse=167.181047 step=0.100000
2017/08/29 02:10:02 step 2: mse=163.531642 step=0.100000
2017/08/29 02:10:03 step 3: mse=160.322931 step=0.100000
2017/08/29 02:10:04 step 4: mse=157.727077 step=0.100000
2017/08/29 02:10:05 step 5: mse=155.300147 step=0.100000
2017/08/29 02:10:07 step 6: mse=153.077265 step=0.100000
2017/08/29 02:10:08 step 7: mse=151.116713 step=0.100000
2017/08/29 02:10:08 Saving...
2017/08/29 02:10:08 Gathering batch of experience...
2017/08/29 02:10:55 batch 873: mean=196.970588 stddev=157.580509 entropy=0.324221 frames=6149 count=34
2017/08/29 02:10:55 Training policy...
2017/08/29 02:11:00 step 0: objective=1.9574457
2017/08/29 02:11:02 step 1: objective=1.9622712
2017/08/29 02:11:04 step 2: objective=1.9668424
2017/08/29 02:11:06 step 3: objective=1.9715267
2017/08/29 02:11:08 step 4: objective=1.9747969
2017/08/29 02:11:11 step 5: objective=1.9775586
2017/08/29 02:11:13 step 6: objective=1.979866
2017/08/29 02:11:15 step 7: objective=1.9842967
2017/08/29 02:11:15 Training value function...
2017/08/29 02:11:18 step 0: mse=203.513833 step=0.100000
2017/08/29 02:11:19 step 1: mse=199.073398 step=0.100000
2017/08/29 02:11:20 step 2: mse=195.262066 step=0.100000
2017/08/29 02:11:21 step 3: mse=192.110113 step=0.100000
2017/08/29 02:11:23 step 4: mse=189.135585 step=0.100000
2017/08/29 02:11:24 step 5: mse=186.418509 step=0.100000
2017/08/29 02:11:25 step 6: mse=184.306873 step=0.100000
2017/08/29 02:11:27 step 7: mse=182.412382 step=0.100000
2017/08/29 02:11:27 Saving...
2017/08/29 02:11:27 Gathering batch of experience...
2017/08/29 02:12:13 batch 874: mean=225.892857 stddev=168.832406 entropy=0.330771 frames=6057 count=28
2017/08/29 02:12:13 Training policy...
2017/08/29 02:12:18 step 0: objective=1.3143109
2017/08/29 02:12:20 step 1: objective=1.3218918
2017/08/29 02:12:23 step 2: objective=1.3294655
2017/08/29 02:12:25 step 3: objective=1.3336486
2017/08/29 02:12:27 step 4: objective=1.3390971
2017/08/29 02:12:29 step 5: objective=1.3436247
2017/08/29 02:12:31 step 6: objective=1.3475553
2017/08/29 02:12:34 step 7: objective=1.3503369
2017/08/29 02:12:34 Training value function...
2017/08/29 02:12:36 step 0: mse=160.031856 step=0.100000
2017/08/29 02:12:37 step 1: mse=153.930219 step=0.100000
2017/08/29 02:12:39 step 2: mse=149.217444 step=0.100000
2017/08/29 02:12:40 step 3: mse=145.471102 step=0.100000
2017/08/29 02:12:41 step 4: mse=141.778514 step=0.100000
2017/08/29 02:12:43 step 5: mse=139.049650 step=0.100000
2017/08/29 02:12:44 step 6: mse=136.652776 step=0.100000
2017/08/29 02:12:45 step 7: mse=134.184899 step=0.100000
2017/08/29 02:12:45 Saving...
2017/08/29 02:12:45 Gathering batch of experience...
2017/08/29 02:13:34 batch 875: mean=177.605263 stddev=147.326086 entropy=0.328125 frames=6387 count=38
2017/08/29 02:13:34 Training policy...
2017/08/29 02:13:40 step 0: objective=0.6862789
2017/08/29 02:13:42 step 1: objective=0.6939026
2017/08/29 02:13:44 step 2: objective=0.70454067
2017/08/29 02:13:47 step 3: objective=0.70998573
2017/08/29 02:13:49 step 4: objective=0.7156551
2017/08/29 02:13:51 step 5: objective=0.71963453
2017/08/29 02:13:53 step 6: objective=0.7241601
2017/08/29 02:13:56 step 7: objective=0.7263083
2017/08/29 02:13:56 Training value function...
2017/08/29 02:13:58 step 0: mse=176.197460 step=0.100000
2017/08/29 02:14:00 step 1: mse=172.504766 step=0.100000
2017/08/29 02:14:01 step 2: mse=169.321393 step=0.100000
2017/08/29 02:14:02 step 3: mse=166.873115 step=0.100000
2017/08/29 02:14:04 step 4: mse=164.704649 step=0.100000
2017/08/29 02:14:05 step 5: mse=162.940457 step=0.100000
2017/08/29 02:14:07 step 6: mse=161.254156 step=0.100000
2017/08/29 02:14:08 step 7: mse=159.924426 step=0.100000
2017/08/29 02:14:08 Saving...
2017/08/29 02:14:08 Gathering batch of experience...
2017/08/29 02:14:52 batch 876: mean=143.710526 stddev=103.571716 entropy=0.320807 frames=5575 count=38
2017/08/29 02:14:52 Training policy...
2017/08/29 02:14:57 step 0: objective=-0.44199714
2017/08/29 02:14:59 step 1: objective=-0.4366558
2017/08/29 02:15:01 step 2: objective=-0.4307371
2017/08/29 02:15:03 step 3: objective=-0.4239267
2017/08/29 02:15:05 step 4: objective=-0.4192469
2017/08/29 02:15:07 step 5: objective=-0.41636416
2017/08/29 02:15:09 step 6: objective=-0.4124767
2017/08/29 02:15:11 step 7: objective=-0.4076476
2017/08/29 02:15:11 Training value function...
2017/08/29 02:15:13 step 0: mse=119.471301 step=0.100000
2017/08/29 02:15:14 step 1: mse=116.509165 step=0.100000
2017/08/29 02:15:15 step 2: mse=114.177867 step=0.100000
2017/08/29 02:15:17 step 3: mse=112.513760 step=0.100000
2017/08/29 02:15:18 step 4: mse=111.275615 step=0.100000
2017/08/29 02:15:19 step 5: mse=110.104549 step=0.100000
2017/08/29 02:15:20 step 6: mse=109.378771 step=0.100000
2017/08/29 02:15:21 step 7: mse=108.773256 step=0.100000
2017/08/29 02:15:21 Saving...
2017/08/29 02:15:21 Gathering batch of experience...
2017/08/29 02:16:10 batch 877: mean=202.187500 stddev=131.763149 entropy=0.329839 frames=6143 count=32
2017/08/29 02:16:10 Training policy...
2017/08/29 02:16:15 step 0: objective=1.9401151
2017/08/29 02:16:17 step 1: objective=1.9456903
2017/08/29 02:16:19 step 2: objective=1.9533076
2017/08/29 02:16:21 step 3: objective=1.9595501
2017/08/29 02:16:24 step 4: objective=1.9653438
2017/08/29 02:16:26 step 5: objective=1.9680305
2017/08/29 02:16:28 step 6: objective=1.9733411
2017/08/29 02:16:30 step 7: objective=1.9754877
2017/08/29 02:16:30 Training value function...
2017/08/29 02:16:33 step 0: mse=185.787678 step=0.100000
2017/08/29 02:16:34 step 1: mse=181.213867 step=0.100000
2017/08/29 02:16:35 step 2: mse=177.479182 step=0.100000
2017/08/29 02:16:37 step 3: mse=173.730497 step=0.100000
2017/08/29 02:16:38 step 4: mse=170.531926 step=0.100000
2017/08/29 02:16:39 step 5: mse=167.869197 step=0.100000
2017/08/29 02:16:41 step 6: mse=165.277937 step=0.100000
2017/08/29 02:16:42 step 7: mse=163.020109 step=0.100000
2017/08/29 02:16:42 Saving...
2017/08/29 02:16:42 Gathering batch of experience...
2017/08/29 02:17:33 batch 878: mean=195.428571 stddev=145.695825 entropy=0.327444 frames=6307 count=35
2017/08/29 02:17:33 Training policy...
2017/08/29 02:17:37 step 0: objective=1.6803303
2017/08/29 02:17:40 step 1: objective=1.6868032
2017/08/29 02:17:42 step 2: objective=1.6937702
2017/08/29 02:17:44 step 3: objective=1.7013983
2017/08/29 02:17:47 step 4: objective=1.7059004
2017/08/29 02:17:49 step 5: objective=1.7092674
2017/08/29 02:17:51 step 6: objective=1.7154249
2017/08/29 02:17:54 step 7: objective=1.7186131
2017/08/29 02:17:54 Training value function...
2017/08/29 02:17:56 step 0: mse=173.974662 step=0.100000
2017/08/29 02:17:57 step 1: mse=169.363772 step=0.100000
2017/08/29 02:17:59 step 2: mse=165.163369 step=0.100000
2017/08/29 02:18:00 step 3: mse=161.551599 step=0.100000
2017/08/29 02:18:02 step 4: mse=158.621075 step=0.100000
2017/08/29 02:18:03 step 5: mse=156.037165 step=0.100000
2017/08/29 02:18:04 step 6: mse=153.885208 step=0.100000
2017/08/29 02:18:06 step 7: mse=152.042384 step=0.100000
2017/08/29 02:18:06 Saving...
2017/08/29 02:18:06 Gathering batch of experience...
2017/08/29 02:18:59 batch 879: mean=285.074074 stddev=181.732593 entropy=0.330952 frames=7321 count=27
2017/08/29 02:18:59 Training policy...
2017/08/29 02:19:05 step 0: objective=1.7947714
2017/08/29 02:19:08 step 1: objective=1.7989298
2017/08/29 02:19:10 step 2: objective=1.803391
2017/08/29 02:19:13 step 3: objective=1.8060583
2017/08/29 02:19:16 step 4: objective=1.8082718
2017/08/29 02:19:18 step 5: objective=1.8101739
2017/08/29 02:19:21 step 6: objective=1.8144456
2017/08/29 02:19:24 step 7: objective=1.8176492
2017/08/29 02:19:24 Training value function...
2017/08/29 02:19:27 step 0: mse=160.915464 step=0.100000
2017/08/29 02:19:28 step 1: mse=156.636214 step=0.100000
2017/08/29 02:19:30 step 2: mse=152.477708 step=0.100000
2017/08/29 02:19:31 step 3: mse=149.264489 step=0.100000
2017/08/29 02:19:33 step 4: mse=146.220777 step=0.100000
2017/08/29 02:19:34 step 5: mse=143.964307 step=0.100000
2017/08/29 02:19:36 step 6: mse=141.864397 step=0.100000
2017/08/29 02:19:38 step 7: mse=139.670803 step=0.100000
2017/08/29 02:19:38 Saving...
2017/08/29 02:19:38 Gathering batch of experience...
2017/08/29 02:20:30 batch 880: mean=183.297297 stddev=159.949631 entropy=0.331670 frames=6671 count=37
2017/08/29 02:20:30 Training policy...
2017/08/29 02:20:35 step 0: objective=0.285975
2017/08/29 02:20:38 step 1: objective=0.29505217
2017/08/29 02:20:40 step 2: objective=0.30437207
2017/08/29 02:20:43 step 3: objective=0.3085238
2017/08/29 02:20:45 step 4: objective=0.31106788
2017/08/29 02:20:47 step 5: objective=0.31382108
2017/08/29 02:20:50 step 6: objective=0.31656745
2017/08/29 02:20:52 step 7: objective=0.31867665
2017/08/29 02:20:52 Training value function...
2017/08/29 02:20:55 step 0: mse=143.874225 step=0.100000
2017/08/29 02:20:57 step 1: mse=141.907106 step=0.100000
2017/08/29 02:20:58 step 2: mse=140.045509 step=0.100000
2017/08/29 02:20:59 step 3: mse=138.808533 step=0.100000
2017/08/29 02:21:01 step 4: mse=137.341616 step=0.100000
2017/08/29 02:21:02 step 5: mse=136.181601 step=0.100000
2017/08/29 02:21:04 step 6: mse=135.237446 step=0.100000
2017/08/29 02:21:05 step 7: mse=134.260047 step=0.100000
2017/08/29 02:21:05 Saving...
2017/08/29 02:21:05 Gathering batch of experience...
2017/08/29 02:21:50 batch 881: mean=205.068966 stddev=139.862477 entropy=0.326948 frames=5713 count=29
2017/08/29 02:21:50 Training policy...
2017/08/29 02:21:54 step 0: objective=0.98403263
2017/08/29 02:21:56 step 1: objective=0.9952184
2017/08/29 02:21:59 step 2: objective=1.0007629
2017/08/29 02:22:01 step 3: objective=1.006356
2017/08/29 02:22:03 step 4: objective=1.0101705
2017/08/29 02:22:05 step 5: objective=1.0144043
2017/08/29 02:22:07 step 6: objective=1.0173666
2017/08/29 02:22:09 step 7: objective=1.0208138
2017/08/29 02:22:09 Training value function...
2017/08/29 02:22:11 step 0: mse=143.556132 step=0.100000
2017/08/29 02:22:12 step 1: mse=141.003194 step=0.100000
2017/08/29 02:22:14 step 2: mse=138.752695 step=0.100000
2017/08/29 02:22:15 step 3: mse=137.046474 step=0.100000
2017/08/29 02:22:16 step 4: mse=135.432067 step=0.100000
2017/08/29 02:22:17 step 5: mse=133.936609 step=0.100000
2017/08/29 02:22:18 step 6: mse=132.666083 step=0.100000
2017/08/29 02:22:20 step 7: mse=131.528607 step=0.100000
2017/08/29 02:22:20 Saving...
2017/08/29 02:22:20 Gathering batch of experience...
2017/08/29 02:23:06 batch 882: mean=161.027027 stddev=124.966479 entropy=0.326129 frames=5939 count=37
2017/08/29 02:23:06 Training policy...
2017/08/29 02:23:11 step 0: objective=0.16656342
2017/08/29 02:23:13 step 1: objective=0.1713802
2017/08/29 02:23:16 step 2: objective=0.17529368
2017/08/29 02:23:18 step 3: objective=0.17875294
2017/08/29 02:23:20 step 4: objective=0.18609314
2017/08/29 02:23:22 step 5: objective=0.18920337
2017/08/29 02:23:24 step 6: objective=0.19271761
2017/08/29 02:23:26 step 7: objective=0.19695453
2017/08/29 02:23:26 Training value function...
2017/08/29 02:23:29 step 0: mse=139.039190 step=0.100000
2017/08/29 02:23:30 step 1: mse=137.431094 step=0.100000
2017/08/29 02:23:31 step 2: mse=136.558881 step=0.100000
2017/08/29 02:23:33 step 3: mse=135.732092 step=0.100000
2017/08/29 02:23:34 step 4: mse=134.862193 step=0.100000
2017/08/29 02:23:35 step 5: mse=133.957078 step=0.100000
2017/08/29 02:23:36 step 6: mse=133.269078 step=0.100000
2017/08/29 02:23:38 step 7: mse=132.679784 step=0.100000
2017/08/29 02:23:38 Saving...
2017/08/29 02:23:38 Gathering batch of experience...
2017/08/29 02:24:25 batch 883: mean=180.028571 stddev=137.978153 entropy=0.322991 frames=6132 count=35
2017/08/29 02:24:25 Training policy...
2017/08/29 02:24:30 step 0: objective=1.0344372
2017/08/29 02:24:32 step 1: objective=1.0386382
2017/08/29 02:24:35 step 2: objective=1.0421131
2017/08/29 02:24:37 step 3: objective=1.0477253
2017/08/29 02:24:39 step 4: objective=1.0511802
2017/08/29 02:24:41 step 5: objective=1.0545809
2017/08/29 02:24:43 step 6: objective=1.0592676
2017/08/29 02:24:46 step 7: objective=1.0626618
2017/08/29 02:24:46 Training value function...
2017/08/29 02:24:48 step 0: mse=156.750028 step=0.100000
2017/08/29 02:24:49 step 1: mse=154.893427 step=0.100000
2017/08/29 02:24:51 step 2: mse=153.370427 step=0.100000
2017/08/29 02:24:52 step 3: mse=151.929906 step=0.100000
2017/08/29 02:24:53 step 4: mse=150.557440 step=0.100000
2017/08/29 02:24:55 step 5: mse=149.206951 step=0.100000
2017/08/29 02:24:56 step 6: mse=148.246623 step=0.100000
2017/08/29 02:24:57 step 7: mse=146.977280 step=0.100000
2017/08/29 02:24:57 Saving...
2017/08/29 02:24:57 Gathering batch of experience...
2017/08/29 02:25:45 batch 884: mean=195.000000 stddev=168.598265 entropy=0.330490 frames=5886 count=32
2017/08/29 02:25:45 Training policy...
2017/08/29 02:25:50 step 0: objective=1.6558782
2017/08/29 02:25:52 step 1: objective=1.660216
2017/08/29 02:25:54 step 2: objective=1.6648706
2017/08/29 02:25:56 step 3: objective=1.6701937
2017/08/29 02:25:58 step 4: objective=1.6736914
2017/08/29 02:26:00 step 5: objective=1.6780885
2017/08/29 02:26:03 step 6: objective=1.6837152
2017/08/29 02:26:05 step 7: objective=1.6860347
2017/08/29 02:26:05 Training value function...
2017/08/29 02:26:07 step 0: mse=175.678004 step=0.100000
2017/08/29 02:26:08 step 1: mse=170.160469 step=0.100000
2017/08/29 02:26:10 step 2: mse=165.320781 step=0.100000
2017/08/29 02:26:11 step 3: mse=161.375914 step=0.100000
2017/08/29 02:26:12 step 4: mse=157.978750 step=0.100000
2017/08/29 02:26:13 step 5: mse=155.166998 step=0.100000
2017/08/29 02:26:15 step 6: mse=152.664096 step=0.100000
2017/08/29 02:26:16 step 7: mse=150.536904 step=0.100000
2017/08/29 02:26:16 Saving...
2017/08/29 02:26:16 Gathering batch of experience...
2017/08/29 02:27:07 batch 885: mean=214.866667 stddev=139.784056 entropy=0.327110 frames=6014 count=30
2017/08/29 02:27:07 Training policy...
2017/08/29 02:27:12 step 0: objective=1.4285454
2017/08/29 02:27:14 step 1: objective=1.4333549
2017/08/29 02:27:16 step 2: objective=1.4370399
2017/08/29 02:27:18 step 3: objective=1.4414296
2017/08/29 02:27:21 step 4: objective=1.4440002
2017/08/29 02:27:23 step 5: objective=1.448703
2017/08/29 02:27:25 step 6: objective=1.4534594
2017/08/29 02:27:27 step 7: objective=1.4571074
2017/08/29 02:27:27 Training value function...
2017/08/29 02:27:30 step 0: mse=172.604433 step=0.100000
2017/08/29 02:27:31 step 1: mse=166.507313 step=0.100000
2017/08/29 02:27:32 step 2: mse=161.399424 step=0.100000
2017/08/29 02:27:33 step 3: mse=157.286934 step=0.100000
2017/08/29 02:27:35 step 4: mse=154.013254 step=0.100000
2017/08/29 02:27:36 step 5: mse=150.970005 step=0.100000
2017/08/29 02:27:37 step 6: mse=148.517927 step=0.100000
2017/08/29 02:27:39 step 7: mse=146.407023 step=0.100000
2017/08/29 02:27:39 Saving...
2017/08/29 02:27:39 Gathering batch of experience...
2017/08/29 02:28:23 batch 886: mean=162.432432 stddev=120.970745 entropy=0.322946 frames=5792 count=37
2017/08/29 02:28:23 Training policy...
2017/08/29 02:28:28 step 0: objective=0.30926347
2017/08/29 02:28:30 step 1: objective=0.31559628
2017/08/29 02:28:32 step 2: objective=0.32464015
2017/08/29 02:28:34 step 3: objective=0.33078468
2017/08/29 02:28:36 step 4: objective=0.33576927
2017/08/29 02:28:38 step 5: objective=0.3391135
2017/08/29 02:28:40 step 6: objective=0.34566313
2017/08/29 02:28:43 step 7: objective=0.34883258
2017/08/29 02:28:43 Training value function...
2017/08/29 02:28:45 step 0: mse=148.909922 step=0.100000
2017/08/29 02:28:46 step 1: mse=146.398565 step=0.100000
2017/08/29 02:28:47 step 2: mse=144.244363 step=0.100000
2017/08/29 02:28:49 step 3: mse=142.688842 step=0.100000
2017/08/29 02:28:50 step 4: mse=141.348283 step=0.100000
2017/08/29 02:28:51 step 5: mse=140.225671 step=0.100000
2017/08/29 02:28:52 step 6: mse=139.046668 step=0.100000
2017/08/29 02:28:54 step 7: mse=138.094749 step=0.100000
2017/08/29 02:28:54 Saving...
2017/08/29 02:28:54 Gathering batch of experience...
2017/08/29 02:29:41 batch 887: mean=195.151515 stddev=179.447827 entropy=0.324503 frames=6040 count=33
2017/08/29 02:29:41 Training policy...
2017/08/29 02:29:46 step 0: objective=1.7122852
2017/08/29 02:29:48 step 1: objective=1.7175193
2017/08/29 02:29:50 step 2: objective=1.7279024
2017/08/29 02:29:52 step 3: objective=1.7332894
2017/08/29 02:29:55 step 4: objective=1.7379369
2017/08/29 02:29:57 step 5: objective=1.7413715
2017/08/29 02:29:59 step 6: objective=1.744962
2017/08/29 02:30:01 step 7: objective=1.7480301
2017/08/29 02:30:01 Training value function...
2017/08/29 02:30:04 step 0: mse=213.945233 step=0.100000
2017/08/29 02:30:05 step 1: mse=204.232228 step=0.100000
2017/08/29 02:30:06 step 2: mse=196.983072 step=0.100000
2017/08/29 02:30:08 step 3: mse=190.461149 step=0.100000
2017/08/29 02:30:09 step 4: mse=184.781342 step=0.100000
2017/08/29 02:30:10 step 5: mse=180.321187 step=0.100000
2017/08/29 02:30:11 step 6: mse=176.586953 step=0.100000
2017/08/29 02:30:13 step 7: mse=173.194581 step=0.100000
2017/08/29 02:30:13 Saving...
2017/08/29 02:30:13 Gathering batch of experience...
2017/08/29 02:31:04 batch 888: mean=232.433333 stddev=183.786776 entropy=0.332912 frames=6818 count=30
2017/08/29 02:31:04 Training policy...
2017/08/29 02:31:09 step 0: objective=0.8153673
2017/08/29 02:31:12 step 1: objective=0.8189645
2017/08/29 02:31:14 step 2: objective=0.8271722
2017/08/29 02:31:17 step 3: objective=0.8311985
2017/08/29 02:31:19 step 4: objective=0.83469087
2017/08/29 02:31:22 step 5: objective=0.83796734
2017/08/29 02:31:24 step 6: objective=0.8434091
2017/08/29 02:31:27 step 7: objective=0.8456856
2017/08/29 02:31:27 Training value function...
2017/08/29 02:31:30 step 0: mse=149.038171 step=0.100000
2017/08/29 02:31:31 step 1: mse=146.797333 step=0.100000
2017/08/29 02:31:32 step 2: mse=144.935181 step=0.100000
2017/08/29 02:31:34 step 3: mse=143.394601 step=0.100000
2017/08/29 02:31:35 step 4: mse=141.978449 step=0.100000
2017/08/29 02:31:37 step 5: mse=140.893983 step=0.100000
2017/08/29 02:31:38 step 6: mse=139.856547 step=0.100000
2017/08/29 02:31:40 step 7: mse=138.883868 step=0.100000
2017/08/29 02:31:40 Saving...
2017/08/29 02:31:40 Gathering batch of experience...
2017/08/29 02:32:39 batch 889: mean=224.411765 stddev=208.334730 entropy=0.328296 frames=7149 count=34
2017/08/29 02:32:39 Training policy...
2017/08/29 02:32:44 step 0: objective=1.5004882
2017/08/29 02:32:47 step 1: objective=1.5047683
2017/08/29 02:32:50 step 2: objective=1.5132926
2017/08/29 02:32:52 step 3: objective=1.5176945
2017/08/29 02:32:55 step 4: objective=1.5232581
2017/08/29 02:32:58 step 5: objective=1.5269268
2017/08/29 02:33:00 step 6: objective=1.5308939
2017/08/29 02:33:03 step 7: objective=1.533061
2017/08/29 02:33:03 Training value function...
2017/08/29 02:33:06 step 0: mse=179.917371 step=0.100000
2017/08/29 02:33:07 step 1: mse=176.382349 step=0.100000
2017/08/29 02:33:09 step 2: mse=173.731369 step=0.100000
2017/08/29 02:33:10 step 3: mse=171.325543 step=0.100000
2017/08/29 02:33:12 step 4: mse=169.152826 step=0.100000
2017/08/29 02:33:13 step 5: mse=167.129859 step=0.100000
2017/08/29 02:33:15 step 6: mse=165.106325 step=0.100000
2017/08/29 02:33:16 step 7: mse=163.314349 step=0.100000
2017/08/29 02:33:16 Saving...
2017/08/29 02:33:16 Gathering batch of experience...
2017/08/29 02:34:06 batch 890: mean=242.137931 stddev=203.162195 entropy=0.330916 frames=6278 count=29
2017/08/29 02:34:06 Training policy...
2017/08/29 02:34:11 step 0: objective=1.9153407
2017/08/29 02:34:13 step 1: objective=1.9214513
2017/08/29 02:34:15 step 2: objective=1.9299496
2017/08/29 02:34:18 step 3: objective=1.93722
2017/08/29 02:34:20 step 4: objective=1.9421145
2017/08/29 02:34:22 step 5: objective=1.9458913
2017/08/29 02:34:24 step 6: objective=1.9499133
2017/08/29 02:34:27 step 7: objective=1.9542944
2017/08/29 02:34:27 Training value function...
2017/08/29 02:34:29 step 0: mse=190.701547 step=0.100000
2017/08/29 02:34:31 step 1: mse=184.786853 step=0.100000
2017/08/29 02:34:32 step 2: mse=179.937096 step=0.100000
2017/08/29 02:34:33 step 3: mse=175.402358 step=0.100000
2017/08/29 02:34:35 step 4: mse=172.043268 step=0.100000
2017/08/29 02:34:36 step 5: mse=168.912990 step=0.100000
2017/08/29 02:34:37 step 6: mse=165.743413 step=0.100000
2017/08/29 02:34:39 step 7: mse=163.276962 step=0.100000
2017/08/29 02:34:39 Saving...
2017/08/29 02:34:39 Gathering batch of experience...
2017/08/29 02:35:26 batch 891: mean=229.290323 stddev=162.089221 entropy=0.329397 frames=6589 count=31
2017/08/29 02:35:26 Training policy...
2017/08/29 02:35:31 step 0: objective=0.70633674
2017/08/29 02:35:34 step 1: objective=0.7121117
2017/08/29 02:35:36 step 2: objective=0.71522564
2017/08/29 02:35:39 step 3: objective=0.720382
2017/08/29 02:35:41 step 4: objective=0.7241088
2017/08/29 02:35:43 step 5: objective=0.7272397
2017/08/29 02:35:46 step 6: objective=0.72956556
2017/08/29 02:35:48 step 7: objective=0.7325031
2017/08/29 02:35:48 Training value function...
2017/08/29 02:35:51 step 0: mse=134.318809 step=0.100000
2017/08/29 02:35:52 step 1: mse=131.634851 step=0.100000
2017/08/29 02:35:54 step 2: mse=129.396385 step=0.100000
2017/08/29 02:35:55 step 3: mse=127.704808 step=0.100000
2017/08/29 02:35:57 step 4: mse=126.337944 step=0.100000
2017/08/29 02:35:58 step 5: mse=124.795695 step=0.100000
2017/08/29 02:35:59 step 6: mse=123.540533 step=0.100000
2017/08/29 02:36:01 step 7: mse=122.548074 step=0.100000
2017/08/29 02:36:01 Saving...
2017/08/29 02:36:01 Gathering batch of experience...
2017/08/29 02:36:49 batch 892: mean=160.257143 stddev=112.145656 entropy=0.323771 frames=5569 count=35
2017/08/29 02:36:49 Training policy...
2017/08/29 02:36:54 step 0: objective=-0.43326876
2017/08/29 02:36:56 step 1: objective=-0.4286479
2017/08/29 02:36:58 step 2: objective=-0.4214397
2017/08/29 02:37:00 step 3: objective=-0.41763636
2017/08/29 02:37:02 step 4: objective=-0.4139627
2017/08/29 02:37:04 step 5: objective=-0.40982237
2017/08/29 02:37:06 step 6: objective=-0.40558192
2017/08/29 02:37:08 step 7: objective=-0.40211582
2017/08/29 02:37:08 Training value function...
2017/08/29 02:37:10 step 0: mse=119.079983 step=0.100000
2017/08/29 02:37:11 step 1: mse=117.406280 step=0.100000
2017/08/29 02:37:12 step 2: mse=116.155668 step=0.100000
2017/08/29 02:37:14 step 3: mse=115.352004 step=0.100000
2017/08/29 02:37:15 step 4: mse=114.789089 step=0.100000
2017/08/29 02:37:16 step 5: mse=113.873096 step=0.100000
2017/08/29 02:37:17 step 6: mse=113.355494 step=0.100000
2017/08/29 02:37:18 step 7: mse=112.969888 step=0.100000
2017/08/29 02:37:18 Saving...
2017/08/29 02:37:18 Gathering batch of experience...
2017/08/29 02:38:12 batch 893: mean=189.944444 stddev=167.596895 entropy=0.329492 frames=7043 count=36
2017/08/29 02:38:12 Training policy...
2017/08/29 02:38:18 step 0: objective=0.7293141
2017/08/29 02:38:20 step 1: objective=0.73525155
2017/08/29 02:38:23 step 2: objective=0.7389528
2017/08/29 02:38:26 step 3: objective=0.7425654
2017/08/29 02:38:28 step 4: objective=0.74587613
2017/08/29 02:38:31 step 5: objective=0.74902076
2017/08/29 02:38:33 step 6: objective=0.7522673
2017/08/29 02:38:36 step 7: objective=0.75524414
2017/08/29 02:38:36 Training value function...
2017/08/29 02:38:39 step 0: mse=127.997594 step=0.100000
2017/08/29 02:38:40 step 1: mse=126.453135 step=0.100000
2017/08/29 02:38:42 step 2: mse=124.703340 step=0.100000
2017/08/29 02:38:43 step 3: mse=123.204974 step=0.100000
2017/08/29 02:38:45 step 4: mse=121.913749 step=0.100000
2017/08/29 02:38:46 step 5: mse=120.982101 step=0.100000
2017/08/29 02:38:48 step 6: mse=120.006363 step=0.100000
2017/08/29 02:38:49 step 7: mse=119.024240 step=0.100000
2017/08/29 02:38:49 Saving...
2017/08/29 02:38:49 Gathering batch of experience...
2017/08/29 02:39:31 batch 894: mean=200.033333 stddev=155.342736 entropy=0.324968 frames=5618 count=30
2017/08/29 02:39:31 Training policy...
2017/08/29 02:39:36 step 0: objective=1.8174227
2017/08/29 02:39:38 step 1: objective=1.8209162
2017/08/29 02:39:40 step 2: objective=1.824098
2017/08/29 02:39:42 step 3: objective=1.8283985
2017/08/29 02:39:44 step 4: objective=1.8365132
2017/08/29 02:39:46 step 5: objective=1.8412501
2017/08/29 02:39:48 step 6: objective=1.8465985
2017/08/29 02:39:50 step 7: objective=1.8493648
2017/08/29 02:39:50 Training value function...
2017/08/29 02:39:52 step 0: mse=158.263448 step=0.100000
2017/08/29 02:39:53 step 1: mse=153.621498 step=0.100000
2017/08/29 02:39:55 step 2: mse=149.857031 step=0.100000
2017/08/29 02:39:56 step 3: mse=146.137262 step=0.100000
2017/08/29 02:39:57 step 4: mse=143.341153 step=0.100000
2017/08/29 02:39:58 step 5: mse=140.722148 step=0.100000
2017/08/29 02:39:59 step 6: mse=138.546190 step=0.100000
2017/08/29 02:40:01 step 7: mse=136.610259 step=0.100000
2017/08/29 02:40:01 Saving...
2017/08/29 02:40:01 Gathering batch of experience...
2017/08/29 02:40:46 batch 895: mean=163.444444 stddev=93.295065 entropy=0.319849 frames=5459 count=36
2017/08/29 02:40:46 Training policy...
2017/08/29 02:40:50 step 0: objective=0.8539753
2017/08/29 02:40:52 step 1: objective=0.8597975
2017/08/29 02:40:54 step 2: objective=0.86966586
2017/08/29 02:40:56 step 3: objective=0.8736683
2017/08/29 02:40:58 step 4: objective=0.8771475
2017/08/29 02:41:00 step 5: objective=0.8805133
2017/08/29 02:41:02 step 6: objective=0.88359696
2017/08/29 02:41:04 step 7: objective=0.88660115
2017/08/29 02:41:04 Training value function...
2017/08/29 02:41:06 step 0: mse=155.876259 step=0.100000
2017/08/29 02:41:07 step 1: mse=152.902383 step=0.100000
2017/08/29 02:41:09 step 2: mse=150.183917 step=0.100000
2017/08/29 02:41:10 step 3: mse=148.060489 step=0.100000
2017/08/29 02:41:11 step 4: mse=146.022879 step=0.100000
2017/08/29 02:41:12 step 5: mse=144.104279 step=0.100000
2017/08/29 02:41:13 step 6: mse=142.633402 step=0.100000
2017/08/29 02:41:14 step 7: mse=141.275062 step=0.100000
2017/08/29 02:41:14 Saving...
2017/08/29 02:41:14 Gathering batch of experience...
2017/08/29 02:42:01 batch 896: mean=174.333333 stddev=144.137473 entropy=0.319350 frames=5944 count=36
2017/08/29 02:42:01 Training policy...
2017/08/29 02:42:06 step 0: objective=1.214286
2017/08/29 02:42:08 step 1: objective=1.2239945
2017/08/29 02:42:10 step 2: objective=1.2288765
2017/08/29 02:42:13 step 3: objective=1.2349122
2017/08/29 02:42:15 step 4: objective=1.2393072
2017/08/29 02:42:17 step 5: objective=1.2432802
2017/08/29 02:42:19 step 6: objective=1.249112
2017/08/29 02:42:21 step 7: objective=1.2557254
2017/08/29 02:42:21 Training value function...
2017/08/29 02:42:24 step 0: mse=207.479202 step=0.100000
2017/08/29 02:42:25 step 1: mse=199.428405 step=0.100000
2017/08/29 02:42:26 step 2: mse=193.159706 step=0.100000
2017/08/29 02:42:28 step 3: mse=186.922409 step=0.100000
2017/08/29 02:42:29 step 4: mse=182.192695 step=0.100000
2017/08/29 02:42:30 step 5: mse=178.805895 step=0.100000
2017/08/29 02:42:31 step 6: mse=175.509940 step=0.100000
2017/08/29 02:42:33 step 7: mse=172.589088 step=0.100000
2017/08/29 02:42:33 Saving...
2017/08/29 02:42:33 Gathering batch of experience...
2017/08/29 02:43:25 batch 897: mean=246.400000 stddev=161.487172 entropy=0.327744 frames=6791 count=30
2017/08/29 02:43:25 Training policy...
2017/08/29 02:43:31 step 0: objective=2.0533392
2017/08/29 02:43:33 step 1: objective=2.057118
2017/08/29 02:43:36 step 2: objective=2.0613747
2017/08/29 02:43:38 step 3: objective=2.0641875
2017/08/29 02:43:41 step 4: objective=2.068694
2017/08/29 02:43:43 step 5: objective=2.075392
2017/08/29 02:43:46 step 6: objective=2.079213
2017/08/29 02:43:48 step 7: objective=2.0812976
2017/08/29 02:43:48 Training value function...
2017/08/29 02:43:51 step 0: mse=174.861218 step=0.100000
2017/08/29 02:43:52 step 1: mse=171.366948 step=0.100000
2017/08/29 02:43:54 step 2: mse=167.875797 step=0.100000
2017/08/29 02:43:55 step 3: mse=165.116112 step=0.100000
2017/08/29 02:43:57 step 4: mse=162.508503 step=0.100000
2017/08/29 02:43:58 step 5: mse=160.227547 step=0.100000
2017/08/29 02:44:00 step 6: mse=157.992892 step=0.100000
2017/08/29 02:44:01 step 7: mse=156.077734 step=0.100000
2017/08/29 02:44:01 Saving...
2017/08/29 02:44:01 Gathering batch of experience...
2017/08/29 02:44:50 batch 898: mean=190.647059 stddev=151.338126 entropy=0.331577 frames=6426 count=34
2017/08/29 02:44:50 Training policy...
2017/08/29 02:44:55 step 0: objective=0.2834934
2017/08/29 02:44:57 step 1: objective=0.28901497
2017/08/29 02:45:00 step 2: objective=0.29450732
2017/08/29 02:45:02 step 3: objective=0.29827076
2017/08/29 02:45:04 step 4: objective=0.30279744
2017/08/29 02:45:07 step 5: objective=0.30588928
2017/08/29 02:45:09 step 6: objective=0.31095412
2017/08/29 02:45:12 step 7: objective=0.31515375
2017/08/29 02:45:12 Training value function...
2017/08/29 02:45:14 step 0: mse=144.114997 step=0.100000
2017/08/29 02:45:16 step 1: mse=142.992365 step=0.100000
2017/08/29 02:45:17 step 2: mse=142.081106 step=0.100000
2017/08/29 02:45:18 step 3: mse=141.309580 step=0.100000
2017/08/29 02:45:20 step 4: mse=140.431824 step=0.100000
2017/08/29 02:45:21 step 5: mse=139.744571 step=0.100000
2017/08/29 02:45:22 step 6: mse=139.203756 step=0.100000
2017/08/29 02:45:24 step 7: mse=138.627036 step=0.100000
2017/08/29 02:45:24 Saving...
2017/08/29 02:45:24 Gathering batch of experience...
2017/08/29 02:46:17 batch 899: mean=177.794872 stddev=169.412738 entropy=0.321943 frames=6683 count=39
2017/08/29 02:46:17 Training policy...
2017/08/29 02:46:23 step 0: objective=1.0317665
2017/08/29 02:46:25 step 1: objective=1.039739
2017/08/29 02:46:28 step 2: objective=1.0456547
2017/08/29 02:46:30 step 3: objective=1.0516332
2017/08/29 02:46:33 step 4: objective=1.0539966
2017/08/29 02:46:35 step 5: objective=1.0566436
2017/08/29 02:46:38 step 6: objective=1.0591954
2017/08/29 02:46:40 step 7: objective=1.0616864
2017/08/29 02:46:40 Training value function...
2017/08/29 02:46:43 step 0: mse=147.083590 step=0.100000
2017/08/29 02:46:44 step 1: mse=144.444241 step=0.100000
2017/08/29 02:46:46 step 2: mse=142.327791 step=0.100000
2017/08/29 02:46:47 step 3: mse=140.660129 step=0.100000
2017/08/29 02:46:48 step 4: mse=138.937284 step=0.100000
2017/08/29 02:46:50 step 5: mse=137.429815 step=0.100000
2017/08/29 02:46:51 step 6: mse=136.102285 step=0.100000
2017/08/29 02:46:53 step 7: mse=134.935045 step=0.100000
2017/08/29 02:46:53 Saving...
2017/08/29 02:46:53 Gathering batch of experience...
2017/08/29 02:47:45 batch 900: mean=188.324324 stddev=201.777514 entropy=0.323894 frames=6513 count=37
2017/08/29 02:47:45 Training policy...
2017/08/29 02:47:51 step 0: objective=1.4665796
2017/08/29 02:47:53 step 1: objective=1.4734424
2017/08/29 02:47:55 step 2: objective=1.4779055
2017/08/29 02:47:58 step 3: objective=1.4847327
2017/08/29 02:48:00 step 4: objective=1.4881674
2017/08/29 02:48:03 step 5: objective=1.4931785
2017/08/29 02:48:05 step 6: objective=1.4960282
2017/08/29 02:48:07 step 7: objective=1.500005
2017/08/29 02:48:07 Training value function...
2017/08/29 02:48:10 step 0: mse=188.456660 step=0.100000
2017/08/29 02:48:11 step 1: mse=181.670648 step=0.100000
2017/08/29 02:48:13 step 2: mse=175.798335 step=0.100000
2017/08/29 02:48:14 step 3: mse=171.303670 step=0.100000
2017/08/29 02:48:16 step 4: mse=167.183780 step=0.100000
2017/08/29 02:48:17 step 5: mse=163.578425 step=0.100000
2017/08/29 02:48:18 step 6: mse=160.635882 step=0.100000
2017/08/29 02:48:20 step 7: mse=158.569676 step=0.100000
2017/08/29 02:48:20 Saving...
2017/08/29 02:48:20 Gathering batch of experience...
2017/08/29 02:49:10 batch 901: mean=144.880952 stddev=109.162440 entropy=0.320844 frames=6002 count=42
2017/08/29 02:49:10 Training policy...
2017/08/29 02:49:15 step 0: objective=0.21558681
2017/08/29 02:49:17 step 1: objective=0.22208376
2017/08/29 02:49:19 step 2: objective=0.22921817
2017/08/29 02:49:22 step 3: objective=0.23455486
2017/08/29 02:49:24 step 4: objective=0.24193443
2017/08/29 02:49:26 step 5: objective=0.24614513
2017/08/29 02:49:28 step 6: objective=0.24828728
2017/08/29 02:49:30 step 7: objective=0.25134704
2017/08/29 02:49:30 Training value function...
2017/08/29 02:49:33 step 0: mse=140.849304 step=0.100000
2017/08/29 02:49:34 step 1: mse=139.019793 step=0.100000
2017/08/29 02:49:36 step 2: mse=137.471279 step=0.100000
2017/08/29 02:49:37 step 3: mse=136.474828 step=0.100000
2017/08/29 02:49:38 step 4: mse=135.488253 step=0.100000
2017/08/29 02:49:39 step 5: mse=134.742500 step=0.100000
2017/08/29 02:49:41 step 6: mse=133.985099 step=0.100000
2017/08/29 02:49:42 step 7: mse=133.159909 step=0.100000
2017/08/29 02:49:42 Saving...
2017/08/29 02:49:42 Gathering batch of experience...
2017/08/29 02:50:31 batch 902: mean=217.821429 stddev=177.092602 entropy=0.329324 frames=6260 count=28
2017/08/29 02:50:31 Training policy...
2017/08/29 02:50:36 step 0: objective=1.3009435
2017/08/29 02:50:39 step 1: objective=1.3047162
2017/08/29 02:50:41 step 2: objective=1.3086704
2017/08/29 02:50:43 step 3: objective=1.3119239
2017/08/29 02:50:46 step 4: objective=1.3147333
2017/08/29 02:50:48 step 5: objective=1.317956
2017/08/29 02:50:50 step 6: objective=1.3198959
2017/08/29 02:50:53 step 7: objective=1.3224591
2017/08/29 02:50:53 Training value function...
2017/08/29 02:50:55 step 0: mse=141.982352 step=0.100000
2017/08/29 02:50:56 step 1: mse=139.304421 step=0.100000
2017/08/29 02:50:58 step 2: mse=136.989052 step=0.100000
2017/08/29 02:50:59 step 3: mse=134.931223 step=0.100000
2017/08/29 02:51:00 step 4: mse=133.421554 step=0.100000
2017/08/29 02:51:02 step 5: mse=131.678620 step=0.100000
2017/08/29 02:51:03 step 6: mse=130.190327 step=0.100000
2017/08/29 02:51:04 step 7: mse=128.804856 step=0.100000
2017/08/29 02:51:04 Saving...
2017/08/29 02:51:04 Gathering batch of experience...
2017/08/29 02:51:55 batch 903: mean=191.297297 stddev=167.888455 entropy=0.322343 frames=6746 count=37
2017/08/29 02:51:55 Training policy...
2017/08/29 02:52:01 step 0: objective=1.6169746
2017/08/29 02:52:04 step 1: objective=1.620738
2017/08/29 02:52:06 step 2: objective=1.6257474
2017/08/29 02:52:08 step 3: objective=1.6311041
2017/08/29 02:52:11 step 4: objective=1.6344099
2017/08/29 02:52:13 step 5: objective=1.6386024
2017/08/29 02:52:16 step 6: objective=1.6419181
2017/08/29 02:52:18 step 7: objective=1.6448377
2017/08/29 02:52:18 Training value function...
2017/08/29 02:52:21 step 0: mse=160.199173 step=0.100000
2017/08/29 02:52:23 step 1: mse=156.083288 step=0.100000
2017/08/29 02:52:24 step 2: mse=152.422748 step=0.100000
2017/08/29 02:52:26 step 3: mse=149.438174 step=0.100000
2017/08/29 02:52:27 step 4: mse=146.723491 step=0.100000
2017/08/29 02:52:28 step 5: mse=144.462288 step=0.100000
2017/08/29 02:52:30 step 6: mse=142.577325 step=0.100000
2017/08/29 02:52:31 step 7: mse=140.983027 step=0.100000
2017/08/29 02:52:31 Saving...
2017/08/29 02:52:31 Gathering batch of experience...
2017/08/29 02:53:13 batch 904: mean=201.785714 stddev=114.640543 entropy=0.324398 frames=5530 count=28
2017/08/29 02:53:13 Training policy...
2017/08/29 02:53:18 step 0: objective=0.9585557
2017/08/29 02:53:20 step 1: objective=0.96469754
2017/08/29 02:53:22 step 2: objective=0.9716886
2017/08/29 02:53:24 step 3: objective=0.977952
2017/08/29 02:53:26 step 4: objective=0.9815546
2017/08/29 02:53:28 step 5: objective=0.9866089
2017/08/29 02:53:30 step 6: objective=0.99037033
2017/08/29 02:53:32 step 7: objective=0.99423265
2017/08/29 02:53:32 Training value function...
2017/08/29 02:53:35 step 0: mse=149.601509 step=0.100000
2017/08/29 02:53:36 step 1: mse=146.513441 step=0.100000
2017/08/29 02:53:37 step 2: mse=143.583911 step=0.100000
2017/08/29 02:53:38 step 3: mse=141.458874 step=0.100000
2017/08/29 02:53:39 step 4: mse=139.629026 step=0.100000
2017/08/29 02:53:40 step 5: mse=138.005288 step=0.100000
2017/08/29 02:53:42 step 6: mse=136.430000 step=0.100000
2017/08/29 02:53:43 step 7: mse=135.517269 step=0.100000
2017/08/29 02:53:43 Saving...
2017/08/29 02:53:43 Gathering batch of experience...
2017/08/29 02:54:32 batch 905: mean=199.483871 stddev=188.167028 entropy=0.328284 frames=5954 count=31
2017/08/29 02:54:32 Training policy...
2017/08/29 02:54:36 step 0: objective=1.358261
2017/08/29 02:54:39 step 1: objective=1.3651068
2017/08/29 02:54:41 step 2: objective=1.3705622
2017/08/29 02:54:43 step 3: objective=1.3746251
2017/08/29 02:54:45 step 4: objective=1.3791182
2017/08/29 02:54:47 step 5: objective=1.3833703
2017/08/29 02:54:50 step 6: objective=1.3870342
2017/08/29 02:54:52 step 7: objective=1.3903904
2017/08/29 02:54:52 Training value function...
2017/08/29 02:54:54 step 0: mse=177.663691 step=0.100000
2017/08/29 02:54:56 step 1: mse=172.019576 step=0.100000
2017/08/29 02:54:57 step 2: mse=166.785387 step=0.100000
2017/08/29 02:54:58 step 3: mse=162.872844 step=0.100000
2017/08/29 02:54:59 step 4: mse=159.682755 step=0.100000
2017/08/29 02:55:01 step 5: mse=156.844512 step=0.100000
2017/08/29 02:55:02 step 6: mse=154.578316 step=0.100000
2017/08/29 02:55:03 step 7: mse=152.311347 step=0.100000
2017/08/29 02:55:03 Saving...
2017/08/29 02:55:03 Gathering batch of experience...
2017/08/29 02:55:50 batch 906: mean=162.837838 stddev=151.530661 entropy=0.326301 frames=5701 count=37
2017/08/29 02:55:50 Training policy...
2017/08/29 02:55:54 step 0: objective=1.1529248
2017/08/29 02:55:56 step 1: objective=1.1632552
2017/08/29 02:55:59 step 2: objective=1.1737245
2017/08/29 02:56:01 step 3: objective=1.1842699
2017/08/29 02:56:03 step 4: objective=1.189419
2017/08/29 02:56:05 step 5: objective=1.1940796
2017/08/29 02:56:07 step 6: objective=1.1985295
2017/08/29 02:56:09 step 7: objective=1.2016445
2017/08/29 02:56:09 Training value function...
2017/08/29 02:56:11 step 0: mse=185.040794 step=0.100000
2017/08/29 02:56:13 step 1: mse=181.047510 step=0.100000
2017/08/29 02:56:14 step 2: mse=177.806212 step=0.100000
2017/08/29 02:56:15 step 3: mse=175.226436 step=0.100000
2017/08/29 02:56:16 step 4: mse=172.542465 step=0.100000
2017/08/29 02:56:17 step 5: mse=170.657096 step=0.100000
2017/08/29 02:56:19 step 6: mse=168.615189 step=0.100000
2017/08/29 02:56:20 step 7: mse=166.936397 step=0.100000
2017/08/29 02:56:20 Saving...
2017/08/29 02:56:20 Gathering batch of experience...
2017/08/29 02:57:15 batch 907: mean=205.968750 stddev=177.521915 entropy=0.325812 frames=6382 count=32
2017/08/29 02:57:15 Training policy...
2017/08/29 02:57:20 step 0: objective=1.3231784
2017/08/29 02:57:23 step 1: objective=1.3286943
2017/08/29 02:57:25 step 2: objective=1.3325474
2017/08/29 02:57:28 step 3: objective=1.3371991
2017/08/29 02:57:30 step 4: objective=1.3428473
2017/08/29 02:57:32 step 5: objective=1.3477556
2017/08/29 02:57:35 step 6: objective=1.3502914
2017/08/29 02:57:37 step 7: objective=1.3539522
2017/08/29 02:57:37 Training value function...
2017/08/29 02:57:40 step 0: mse=144.416000 step=0.100000
2017/08/29 02:57:41 step 1: mse=141.174121 step=0.100000
2017/08/29 02:57:42 step 2: mse=138.348836 step=0.100000
2017/08/29 02:57:44 step 3: mse=135.948282 step=0.100000
2017/08/29 02:57:45 step 4: mse=133.643612 step=0.100000
2017/08/29 02:57:47 step 5: mse=131.925263 step=0.100000
2017/08/29 02:57:48 step 6: mse=130.394606 step=0.100000
2017/08/29 02:57:49 step 7: mse=129.069463 step=0.100000
2017/08/29 02:57:49 Saving...
2017/08/29 02:57:49 Gathering batch of experience...
2017/08/29 02:58:38 batch 908: mean=224.612903 stddev=174.875933 entropy=0.329179 frames=6299 count=31
2017/08/29 02:58:38 Training policy...
2017/08/29 02:58:43 step 0: objective=1.9843053
2017/08/29 02:58:46 step 1: objective=1.988614
2017/08/29 02:58:48 step 2: objective=1.9975321
2017/08/29 02:58:51 step 3: objective=2.0001924
2017/08/29 02:58:53 step 4: objective=2.004374
2017/08/29 02:58:55 step 5: objective=2.0108967
2017/08/29 02:58:58 step 6: objective=2.0168319
2017/08/29 02:59:00 step 7: objective=2.0204368
2017/08/29 02:59:00 Training value function...
2017/08/29 02:59:03 step 0: mse=175.448302 step=0.100000
2017/08/29 02:59:04 step 1: mse=171.553911 step=0.100000
2017/08/29 02:59:05 step 2: mse=168.316063 step=0.100000
2017/08/29 02:59:07 step 3: mse=164.973183 step=0.100000
2017/08/29 02:59:08 step 4: mse=162.005056 step=0.100000
2017/08/29 02:59:09 step 5: mse=159.702556 step=0.100000
2017/08/29 02:59:11 step 6: mse=157.496502 step=0.100000
2017/08/29 02:59:12 step 7: mse=155.691383 step=0.100000
2017/08/29 02:59:12 Saving...
2017/08/29 02:59:12 Gathering batch of experience...
2017/08/29 02:59:57 batch 909: mean=202.896552 stddev=114.764330 entropy=0.317562 frames=5615 count=29
2017/08/29 02:59:57 Training policy...
2017/08/29 03:00:01 step 0: objective=0.5125199
2017/08/29 03:00:03 step 1: objective=0.518381
2017/08/29 03:00:06 step 2: objective=0.5237298
2017/08/29 03:00:08 step 3: objective=0.52952564
2017/08/29 03:00:10 step 4: objective=0.5333917
2017/08/29 03:00:12 step 5: objective=0.5367504
2017/08/29 03:00:14 step 6: objective=0.5392077
2017/08/29 03:00:16 step 7: objective=0.54165137
2017/08/29 03:00:16 Training value function...
2017/08/29 03:00:18 step 0: mse=110.402517 step=0.100000
2017/08/29 03:00:20 step 1: mse=108.719103 step=0.100000
2017/08/29 03:00:21 step 2: mse=107.363870 step=0.100000
2017/08/29 03:00:22 step 3: mse=106.232966 step=0.100000
2017/08/29 03:00:23 step 4: mse=105.278489 step=0.100000
2017/08/29 03:00:24 step 5: mse=104.447665 step=0.100000
2017/08/29 03:00:25 step 6: mse=103.690445 step=0.100000
2017/08/29 03:00:27 step 7: mse=103.049558 step=0.100000
2017/08/29 03:00:27 Saving...
2017/08/29 03:00:27 Gathering batch of experience...
2017/08/29 03:01:10 batch 910: mean=213.535714 stddev=129.029754 entropy=0.318423 frames=5886 count=28
2017/08/29 03:01:10 Training policy...
2017/08/29 03:01:15 step 0: objective=0.69478726
2017/08/29 03:01:17 step 1: objective=0.69978416
2017/08/29 03:01:20 step 2: objective=0.70357645
2017/08/29 03:01:22 step 3: objective=0.7065133
2017/08/29 03:01:24 step 4: objective=0.71036553
2017/08/29 03:01:26 step 5: objective=0.71276104
2017/08/29 03:01:28 step 6: objective=0.71521944
2017/08/29 03:01:30 step 7: objective=0.7178126
2017/08/29 03:01:30 Training value function...
2017/08/29 03:01:33 step 0: mse=138.732963 step=0.100000
2017/08/29 03:01:34 step 1: mse=137.395307 step=0.100000
2017/08/29 03:01:35 step 2: mse=136.071009 step=0.100000
2017/08/29 03:01:37 step 3: mse=134.716428 step=0.100000
2017/08/29 03:01:38 step 4: mse=133.462906 step=0.100000
2017/08/29 03:01:39 step 5: mse=132.109909 step=0.100000
2017/08/29 03:01:40 step 6: mse=131.165174 step=0.100000
2017/08/29 03:01:42 step 7: mse=130.246907 step=0.100000
2017/08/29 03:01:42 Saving...
2017/08/29 03:01:42 Gathering batch of experience...
2017/08/29 03:02:29 batch 911: mean=231.206897 stddev=161.150899 entropy=0.320211 frames=6246 count=29
2017/08/29 03:02:29 Training policy...
2017/08/29 03:02:34 step 0: objective=1.8735775
2017/08/29 03:02:36 step 1: objective=1.8785554
2017/08/29 03:02:39 step 2: objective=1.8845619
2017/08/29 03:02:41 step 3: objective=1.892031
2017/08/29 03:02:43 step 4: objective=1.8944105
2017/08/29 03:02:46 step 5: objective=1.8983127
2017/08/29 03:02:48 step 6: objective=1.9010296
2017/08/29 03:02:50 step 7: objective=1.9036717
2017/08/29 03:02:50 Training value function...
2017/08/29 03:02:53 step 0: mse=174.457627 step=0.100000
2017/08/29 03:02:54 step 1: mse=170.523909 step=0.100000
2017/08/29 03:02:56 step 2: mse=167.030856 step=0.100000
2017/08/29 03:02:57 step 3: mse=163.573718 step=0.100000
2017/08/29 03:02:58 step 4: mse=160.739822 step=0.100000
2017/08/29 03:03:00 step 5: mse=158.281941 step=0.100000
2017/08/29 03:03:01 step 6: mse=155.957368 step=0.100000
2017/08/29 03:03:02 step 7: mse=153.981155 step=0.100000
2017/08/29 03:03:02 Saving...
2017/08/29 03:03:02 Gathering batch of experience...
2017/08/29 03:03:49 batch 912: mean=223.666667 stddev=160.881599 entropy=0.329466 frames=6198 count=30
2017/08/29 03:03:49 Training policy...
2017/08/29 03:03:54 step 0: objective=1.3026047
2017/08/29 03:03:57 step 1: objective=1.3074561
2017/08/29 03:03:59 step 2: objective=1.3145497
2017/08/29 03:04:01 step 3: objective=1.3191135
2017/08/29 03:04:04 step 4: objective=1.3227638
2017/08/29 03:04:06 step 5: objective=1.3257761
2017/08/29 03:04:08 step 6: objective=1.3333642
2017/08/29 03:04:10 step 7: objective=1.3366052
2017/08/29 03:04:10 Training value function...
2017/08/29 03:04:13 step 0: mse=168.409880 step=0.100000
2017/08/29 03:04:14 step 1: mse=166.085811 step=0.100000
2017/08/29 03:04:16 step 2: mse=163.946838 step=0.100000
2017/08/29 03:04:17 step 3: mse=161.979099 step=0.100000
2017/08/29 03:04:18 step 4: mse=160.176187 step=0.100000
2017/08/29 03:04:20 step 5: mse=158.574642 step=0.100000
2017/08/29 03:04:21 step 6: mse=157.303599 step=0.100000
2017/08/29 03:04:22 step 7: mse=155.895662 step=0.100000
2017/08/29 03:04:22 Saving...
2017/08/29 03:04:22 Gathering batch of experience...
2017/08/29 03:05:13 batch 913: mean=207.454545 stddev=171.701131 entropy=0.324835 frames=6648 count=33
2017/08/29 03:05:13 Training policy...
2017/08/29 03:05:18 step 0: objective=0.58187735
2017/08/29 03:05:21 step 1: objective=0.58591306
2017/08/29 03:05:23 step 2: objective=0.59086496
2017/08/29 03:05:26 step 3: objective=0.59550905
2017/08/29 03:05:28 step 4: objective=0.5986591
2017/08/29 03:05:31 step 5: objective=0.6020626
2017/08/29 03:05:33 step 6: objective=0.60456866
2017/08/29 03:05:36 step 7: objective=0.6077842
2017/08/29 03:05:36 Training value function...
2017/08/29 03:05:38 step 0: mse=142.415914 step=0.100000
2017/08/29 03:05:40 step 1: mse=141.358731 step=0.100000
2017/08/29 03:05:41 step 2: mse=140.202354 step=0.100000
2017/08/29 03:05:43 step 3: mse=139.283677 step=0.100000
2017/08/29 03:05:44 step 4: mse=138.282131 step=0.100000
2017/08/29 03:05:45 step 5: mse=137.332495 step=0.100000
2017/08/29 03:05:47 step 6: mse=136.511310 step=0.100000
2017/08/29 03:05:48 step 7: mse=135.802872 step=0.100000
2017/08/29 03:05:48 Saving...
2017/08/29 03:05:48 Gathering batch of experience...
2017/08/29 03:06:31 batch 914: mean=186.548387 stddev=181.349038 entropy=0.329908 frames=5711 count=31
2017/08/29 03:06:31 Training policy...
2017/08/29 03:06:36 step 0: objective=0.7126583
2017/08/29 03:06:38 step 1: objective=0.7172087
2017/08/29 03:06:40 step 2: objective=0.7231028
2017/08/29 03:06:43 step 3: objective=0.72966063
2017/08/29 03:06:45 step 4: objective=0.73312235
2017/08/29 03:06:47 step 5: objective=0.73657066
2017/08/29 03:06:49 step 6: objective=0.7395003
2017/08/29 03:06:51 step 7: objective=0.7425437
2017/08/29 03:06:51 Training value function...
2017/08/29 03:06:53 step 0: mse=139.128239 step=0.100000
2017/08/29 03:06:55 step 1: mse=137.159587 step=0.100000
2017/08/29 03:06:56 step 2: mse=135.439629 step=0.100000
2017/08/29 03:06:57 step 3: mse=133.912820 step=0.100000
2017/08/29 03:06:58 step 4: mse=132.638198 step=0.100000
2017/08/29 03:07:00 step 5: mse=131.520320 step=0.100000
2017/08/29 03:07:01 step 6: mse=129.839019 step=0.100000
2017/08/29 03:07:02 step 7: mse=128.953352 step=0.100000
2017/08/29 03:07:02 Saving...
2017/08/29 03:07:02 Gathering batch of experience...
2017/08/29 03:07:53 batch 915: mean=198.428571 stddev=151.476596 entropy=0.326640 frames=6664 count=35
2017/08/29 03:07:53 Training policy...
2017/08/29 03:07:58 step 0: objective=0.95857435
2017/08/29 03:08:01 step 1: objective=0.9648689
2017/08/29 03:08:03 step 2: objective=0.9698818
2017/08/29 03:08:06 step 3: objective=0.9722008
2017/08/29 03:08:08 step 4: objective=0.9745853
2017/08/29 03:08:11 step 5: objective=0.9788017
2017/08/29 03:08:13 step 6: objective=0.9814729
2017/08/29 03:08:16 step 7: objective=0.98684037
2017/08/29 03:08:16 Training value function...
2017/08/29 03:08:18 step 0: mse=159.987491 step=0.100000
2017/08/29 03:08:20 step 1: mse=156.636849 step=0.100000
2017/08/29 03:08:21 step 2: mse=153.824130 step=0.100000
2017/08/29 03:08:23 step 3: mse=151.469093 step=0.100000
2017/08/29 03:08:24 step 4: mse=149.655890 step=0.100000
2017/08/29 03:08:25 step 5: mse=148.045444 step=0.100000
2017/08/29 03:08:27 step 6: mse=146.541274 step=0.100000
2017/08/29 03:08:28 step 7: mse=145.515838 step=0.100000
2017/08/29 03:08:28 Saving...
2017/08/29 03:08:28 Gathering batch of experience...
2017/08/29 03:09:18 batch 916: mean=216.545455 stddev=155.879342 entropy=0.325865 frames=6472 count=33
2017/08/29 03:09:18 Training policy...
2017/08/29 03:09:24 step 0: objective=1.7260344
2017/08/29 03:09:26 step 1: objective=1.7305608
2017/08/29 03:09:28 step 2: objective=1.7346684
2017/08/29 03:09:31 step 3: objective=1.7388581
2017/08/29 03:09:33 step 4: objective=1.7425996
2017/08/29 03:09:36 step 5: objective=1.7469919
2017/08/29 03:09:38 step 6: objective=1.7499927
2017/08/29 03:09:41 step 7: objective=1.751844
2017/08/29 03:09:41 Training value function...
2017/08/29 03:09:43 step 0: mse=182.054521 step=0.100000
2017/08/29 03:09:45 step 1: mse=178.215172 step=0.100000
2017/08/29 03:09:46 step 2: mse=174.981536 step=0.100000
2017/08/29 03:09:47 step 3: mse=171.928907 step=0.100000
2017/08/29 03:09:49 step 4: mse=169.521138 step=0.100000
2017/08/29 03:09:50 step 5: mse=167.338526 step=0.100000
2017/08/29 03:09:51 step 6: mse=165.519345 step=0.100000
2017/08/29 03:09:53 step 7: mse=163.637045 step=0.100000
2017/08/29 03:09:53 Saving...
2017/08/29 03:09:53 Gathering batch of experience...
2017/08/29 03:10:42 batch 917: mean=211.225806 stddev=165.436024 entropy=0.326980 frames=6281 count=31
2017/08/29 03:10:42 Training policy...
2017/08/29 03:10:47 step 0: objective=0.76743126
2017/08/29 03:10:49 step 1: objective=0.7747086
2017/08/29 03:10:52 step 2: objective=0.7821391
2017/08/29 03:10:54 step 3: objective=0.7879534
2017/08/29 03:10:57 step 4: objective=0.79054904
2017/08/29 03:10:59 step 5: objective=0.79642266
2017/08/29 03:11:01 step 6: objective=0.7999551
2017/08/29 03:11:04 step 7: objective=0.80292857
2017/08/29 03:11:04 Training value function...
2017/08/29 03:11:06 step 0: mse=152.712706 step=0.100000
2017/08/29 03:11:08 step 1: mse=149.818742 step=0.100000
2017/08/29 03:11:09 step 2: mse=147.612097 step=0.100000
2017/08/29 03:11:10 step 3: mse=145.859709 step=0.100000
2017/08/29 03:11:12 step 4: mse=144.357806 step=0.100000
2017/08/29 03:11:13 step 5: mse=142.911333 step=0.100000
2017/08/29 03:11:14 step 6: mse=141.543733 step=0.100000
2017/08/29 03:11:16 step 7: mse=140.246760 step=0.100000
2017/08/29 03:11:16 Saving...
2017/08/29 03:11:16 Gathering batch of experience...
2017/08/29 03:12:11 batch 918: mean=217.419355 stddev=175.667900 entropy=0.321912 frames=6449 count=31
2017/08/29 03:12:11 Training policy...
2017/08/29 03:12:16 step 0: objective=1.1187502
2017/08/29 03:12:19 step 1: objective=1.1248014
2017/08/29 03:12:21 step 2: objective=1.1328794
2017/08/29 03:12:24 step 3: objective=1.1359882
2017/08/29 03:12:26 step 4: objective=1.1405686
2017/08/29 03:12:29 step 5: objective=1.1436644
2017/08/29 03:12:31 step 6: objective=1.1467876
2017/08/29 03:12:33 step 7: objective=1.1510502
2017/08/29 03:12:33 Training value function...
2017/08/29 03:12:36 step 0: mse=158.740860 step=0.100000
2017/08/29 03:12:38 step 1: mse=155.006277 step=0.100000
2017/08/29 03:12:39 step 2: mse=151.947910 step=0.100000
2017/08/29 03:12:40 step 3: mse=148.992798 step=0.100000
2017/08/29 03:12:42 step 4: mse=146.530383 step=0.100000
2017/08/29 03:12:43 step 5: mse=144.406544 step=0.100000
2017/08/29 03:12:44 step 6: mse=142.701479 step=0.100000
2017/08/29 03:12:46 step 7: mse=140.215957 step=0.100000
2017/08/29 03:12:46 Saving...
2017/08/29 03:12:46 Gathering batch of experience...
2017/08/29 03:13:37 batch 919: mean=160.350000 stddev=148.279221 entropy=0.312967 frames=6102 count=40
2017/08/29 03:13:37 Training policy...
2017/08/29 03:13:42 step 0: objective=0.24749078
2017/08/29 03:13:44 step 1: objective=0.25577688
2017/08/29 03:13:47 step 2: objective=0.26043436
2017/08/29 03:13:49 step 3: objective=0.26989648
2017/08/29 03:13:51 step 4: objective=0.27274546
2017/08/29 03:13:53 step 5: objective=0.2776377
2017/08/29 03:13:56 step 6: objective=0.2809199
2017/08/29 03:13:58 step 7: objective=0.28375638
2017/08/29 03:13:58 Training value function...
2017/08/29 03:14:01 step 0: mse=155.195128 step=0.100000
2017/08/29 03:14:02 step 1: mse=153.142807 step=0.100000
2017/08/29 03:14:03 step 2: mse=151.029613 step=0.100000
2017/08/29 03:14:04 step 3: mse=148.646371 step=0.100000
2017/08/29 03:14:06 step 4: mse=147.029958 step=0.100000
2017/08/29 03:14:07 step 5: mse=145.548134 step=0.100000
2017/08/29 03:14:08 step 6: mse=144.861179 step=0.100000
2017/08/29 03:14:10 step 7: mse=143.880697 step=0.100000
2017/08/29 03:14:10 Saving...
2017/08/29 03:14:10 Gathering batch of experience...
2017/08/29 03:14:58 batch 920: mean=180.914286 stddev=143.266858 entropy=0.321268 frames=6205 count=35
2017/08/29 03:14:58 Training policy...
2017/08/29 03:15:03 step 0: objective=0.74519724
2017/08/29 03:15:06 step 1: objective=0.753599
2017/08/29 03:15:08 step 2: objective=0.7577265
2017/08/29 03:15:10 step 3: objective=0.76248395
2017/08/29 03:15:13 step 4: objective=0.7656527
2017/08/29 03:15:15 step 5: objective=0.76911396
2017/08/29 03:15:17 step 6: objective=0.7728618
2017/08/29 03:15:20 step 7: objective=0.7768918
2017/08/29 03:15:20 Training value function...
2017/08/29 03:15:22 step 0: mse=160.696052 step=0.100000
2017/08/29 03:15:24 step 1: mse=157.332078 step=0.100000
2017/08/29 03:15:25 step 2: mse=154.782715 step=0.100000
2017/08/29 03:15:26 step 3: mse=152.518150 step=0.100000
2017/08/29 03:15:27 step 4: mse=150.511323 step=0.100000
2017/08/29 03:15:29 step 5: mse=148.955756 step=0.100000
2017/08/29 03:15:30 step 6: mse=147.442367 step=0.100000
2017/08/29 03:15:31 step 7: mse=146.226092 step=0.100000
2017/08/29 03:15:31 Saving...
2017/08/29 03:15:32 Gathering batch of experience...
2017/08/29 03:16:23 batch 921: mean=228.419355 stddev=173.368110 entropy=0.327927 frames=6742 count=31
2017/08/29 03:16:23 Training policy...
2017/08/29 03:16:28 step 0: objective=1.6530851
2017/08/29 03:16:31 step 1: objective=1.6569201
2017/08/29 03:16:33 step 2: objective=1.660292
2017/08/29 03:16:36 step 3: objective=1.6644061
2017/08/29 03:16:38 step 4: objective=1.6674919
2017/08/29 03:16:41 step 5: objective=1.6703266
2017/08/29 03:16:43 step 6: objective=1.6743667
2017/08/29 03:16:46 step 7: objective=1.6772497
2017/08/29 03:16:46 Training value function...
2017/08/29 03:16:49 step 0: mse=160.879394 step=0.100000
2017/08/29 03:16:50 step 1: mse=157.616827 step=0.100000
2017/08/29 03:16:52 step 2: mse=154.333026 step=0.100000
2017/08/29 03:16:53 step 3: mse=151.955742 step=0.100000
2017/08/29 03:16:55 step 4: mse=149.813564 step=0.100000
2017/08/29 03:16:56 step 5: mse=147.509466 step=0.100000
2017/08/29 03:16:57 step 6: mse=145.856086 step=0.100000
2017/08/29 03:16:59 step 7: mse=144.147655 step=0.100000
2017/08/29 03:16:59 Saving...
2017/08/29 03:16:59 Gathering batch of experience...
2017/08/29 03:17:44 batch 922: mean=248.148148 stddev=129.560998 entropy=0.326754 frames=6148 count=27
2017/08/29 03:17:44 Training policy...
2017/08/29 03:17:49 step 0: objective=1.7558875
2017/08/29 03:17:51 step 1: objective=1.7632141
2017/08/29 03:17:53 step 2: objective=1.7689368
2017/08/29 03:17:56 step 3: objective=1.7738025
2017/08/29 03:17:58 step 4: objective=1.7780509
2017/08/29 03:18:00 step 5: objective=1.7811993
2017/08/29 03:18:03 step 6: objective=1.7838056
2017/08/29 03:18:05 step 7: objective=1.7867329
2017/08/29 03:18:05 Training value function...
2017/08/29 03:18:08 step 0: mse=167.516358 step=0.100000
2017/08/29 03:18:09 step 1: mse=163.366034 step=0.100000
2017/08/29 03:18:10 step 2: mse=159.520003 step=0.100000
2017/08/29 03:18:12 step 3: mse=155.837189 step=0.100000
2017/08/29 03:18:13 step 4: mse=152.635492 step=0.100000
2017/08/29 03:18:14 step 5: mse=150.041522 step=0.100000
2017/08/29 03:18:15 step 6: mse=147.643221 step=0.100000
2017/08/29 03:18:17 step 7: mse=145.636884 step=0.100000
2017/08/29 03:18:17 Saving...
2017/08/29 03:18:17 Gathering batch of experience...
2017/08/29 03:19:02 batch 923: mean=153.717949 stddev=146.015621 entropy=0.322012 frames=5496 count=39
2017/08/29 03:19:02 Training policy...
2017/08/29 03:19:07 step 0: objective=0.5825529
2017/08/29 03:19:09 step 1: objective=0.59600663
2017/08/29 03:19:11 step 2: objective=0.60458016
2017/08/29 03:19:13 step 3: objective=0.6096379
2017/08/29 03:19:15 step 4: objective=0.61586577
2017/08/29 03:19:18 step 5: objective=0.61940455
2017/08/29 03:19:20 step 6: objective=0.62258774
2017/08/29 03:19:22 step 7: objective=0.62640876
2017/08/29 03:19:22 Training value function...
2017/08/29 03:19:24 step 0: mse=193.741586 step=0.100000
2017/08/29 03:19:25 step 1: mse=189.598570 step=0.100000
2017/08/29 03:19:26 step 2: mse=186.429289 step=0.100000
2017/08/29 03:19:27 step 3: mse=183.390222 step=0.100000
2017/08/29 03:19:29 step 4: mse=180.946584 step=0.100000
2017/08/29 03:19:30 step 5: mse=178.879010 step=0.100000
2017/08/29 03:19:31 step 6: mse=177.044860 step=0.100000
2017/08/29 03:19:32 step 7: mse=175.520782 step=0.100000
2017/08/29 03:19:32 Saving...
2017/08/29 03:19:32 Gathering batch of experience...
2017/08/29 03:20:16 batch 924: mean=249.730769 stddev=194.763477 entropy=0.325332 frames=6118 count=26
2017/08/29 03:20:16 Training policy...
2017/08/29 03:20:21 step 0: objective=1.459776
2017/08/29 03:20:23 step 1: objective=1.4633898
2017/08/29 03:20:25 step 2: objective=1.4667308
2017/08/29 03:20:28 step 3: objective=1.4710747
2017/08/29 03:20:30 step 4: objective=1.4753387
2017/08/29 03:20:32 step 5: objective=1.4789308
2017/08/29 03:20:35 step 6: objective=1.4825692
2017/08/29 03:20:37 step 7: objective=1.4849421
2017/08/29 03:20:37 Training value function...
2017/08/29 03:20:40 step 0: mse=169.971538 step=0.100000
2017/08/29 03:20:41 step 1: mse=164.773986 step=0.100000
2017/08/29 03:20:42 step 2: mse=160.803594 step=0.100000
2017/08/29 03:20:43 step 3: mse=157.612206 step=0.100000
2017/08/29 03:20:45 step 4: mse=154.477930 step=0.100000
2017/08/29 03:20:46 step 5: mse=151.908998 step=0.100000
2017/08/29 03:20:47 step 6: mse=149.872249 step=0.100000
2017/08/29 03:20:49 step 7: mse=148.279511 step=0.100000
2017/08/29 03:20:49 Saving...
2017/08/29 03:20:49 Gathering batch of experience...
2017/08/29 03:21:31 batch 925: mean=152.323529 stddev=134.376714 entropy=0.319397 frames=5034 count=34
2017/08/29 03:21:31 Training policy...
2017/08/29 03:21:35 step 0: objective=0.018826919
2017/08/29 03:21:37 step 1: objective=0.0239523
2017/08/29 03:21:39 step 2: objective=0.036648955
2017/08/29 03:21:41 step 3: objective=0.04131524
2017/08/29 03:21:43 step 4: objective=0.047323275
2017/08/29 03:21:45 step 5: objective=0.053699013
2017/08/29 03:21:47 step 6: objective=0.058920592
2017/08/29 03:21:49 step 7: objective=0.06321372
2017/08/29 03:21:49 Training value function...
2017/08/29 03:21:51 step 0: mse=165.957417 step=0.100000
2017/08/29 03:21:52 step 1: mse=164.311580 step=0.100000
2017/08/29 03:21:53 step 2: mse=162.676403 step=0.100000
2017/08/29 03:21:54 step 3: mse=161.150162 step=0.100000
2017/08/29 03:21:55 step 4: mse=160.064835 step=0.100000
2017/08/29 03:21:56 step 5: mse=158.588890 step=0.100000
2017/08/29 03:21:57 step 6: mse=157.574575 step=0.100000
2017/08/29 03:21:58 step 7: mse=156.212592 step=0.100000
2017/08/29 03:21:58 Saving...
2017/08/29 03:21:58 Gathering batch of experience...
2017/08/29 03:22:42 batch 926: mean=166.558824 stddev=153.082483 entropy=0.326734 frames=5456 count=34
2017/08/29 03:22:42 Training policy...
2017/08/29 03:22:47 step 0: objective=0.9472278
2017/08/29 03:22:49 step 1: objective=0.95648295
2017/08/29 03:22:51 step 2: objective=0.96071464
2017/08/29 03:22:53 step 3: objective=0.96629107
2017/08/29 03:22:55 step 4: objective=0.97003543
2017/08/29 03:22:57 step 5: objective=0.9743767
2017/08/29 03:22:59 step 6: objective=0.9792502
2017/08/29 03:23:01 step 7: objective=0.98400503
2017/08/29 03:23:01 Training value function...
2017/08/29 03:23:03 step 0: mse=167.321234 step=0.100000
2017/08/29 03:23:04 step 1: mse=165.324787 step=0.100000
2017/08/29 03:23:06 step 2: mse=163.825782 step=0.100000
2017/08/29 03:23:07 step 3: mse=162.990681 step=0.100000
2017/08/29 03:23:08 step 4: mse=161.831378 step=0.100000
2017/08/29 03:23:09 step 5: mse=161.293264 step=0.100000
2017/08/29 03:23:10 step 6: mse=160.036282 step=0.100000
2017/08/29 03:23:11 step 7: mse=158.647820 step=0.100000
2017/08/29 03:23:11 Saving...
2017/08/29 03:23:11 Gathering batch of experience...
2017/08/29 03:24:01 batch 927: mean=183.805556 stddev=164.855462 entropy=0.329680 frames=6330 count=36
2017/08/29 03:24:01 Training policy...
2017/08/29 03:24:06 step 0: objective=1.2682695
2017/08/29 03:24:08 step 1: objective=1.2754232
2017/08/29 03:24:11 step 2: objective=1.2794635
2017/08/29 03:24:13 step 3: objective=1.2834016
2017/08/29 03:24:16 step 4: objective=1.2876401
2017/08/29 03:24:18 step 5: objective=1.2922353
2017/08/29 03:24:20 step 6: objective=1.2957715
2017/08/29 03:24:23 step 7: objective=1.2986745
2017/08/29 03:24:23 Training value function...
2017/08/29 03:24:26 step 0: mse=180.607662 step=0.100000
2017/08/29 03:24:27 step 1: mse=177.029119 step=0.100000
2017/08/29 03:24:28 step 2: mse=174.147068 step=0.100000
2017/08/29 03:24:30 step 3: mse=171.196682 step=0.100000
2017/08/29 03:24:31 step 4: mse=168.802670 step=0.100000
2017/08/29 03:24:32 step 5: mse=166.266087 step=0.100000
2017/08/29 03:24:34 step 6: mse=164.315660 step=0.100000
2017/08/29 03:24:35 step 7: mse=162.446453 step=0.100000
2017/08/29 03:24:35 Saving...
2017/08/29 03:24:35 Gathering batch of experience...
2017/08/29 03:25:24 batch 928: mean=193.441176 stddev=132.360068 entropy=0.325822 frames=6410 count=34
2017/08/29 03:25:24 Training policy...
2017/08/29 03:25:29 step 0: objective=0.8331215
2017/08/29 03:25:32 step 1: objective=0.83873177
2017/08/29 03:25:34 step 2: objective=0.8452284
2017/08/29 03:25:36 step 3: objective=0.8512871
2017/08/29 03:25:39 step 4: objective=0.8587901
2017/08/29 03:25:41 step 5: objective=0.8624406
2017/08/29 03:25:44 step 6: objective=0.86496717
2017/08/29 03:25:46 step 7: objective=0.86818105
2017/08/29 03:25:46 Training value function...
2017/08/29 03:25:49 step 0: mse=154.636110 step=0.100000
2017/08/29 03:25:50 step 1: mse=150.250326 step=0.100000
2017/08/29 03:25:52 step 2: mse=146.565510 step=0.100000
2017/08/29 03:25:53 step 3: mse=143.549630 step=0.100000
2017/08/29 03:25:54 step 4: mse=141.082532 step=0.100000
2017/08/29 03:25:56 step 5: mse=139.057721 step=0.100000
2017/08/29 03:25:57 step 6: mse=137.188309 step=0.100000
2017/08/29 03:25:58 step 7: mse=135.493357 step=0.100000
2017/08/29 03:25:58 Saving...
2017/08/29 03:25:58 Gathering batch of experience...
2017/08/29 03:26:46 batch 929: mean=200.451613 stddev=150.526997 entropy=0.323068 frames=6349 count=31
2017/08/29 03:26:46 Training policy...
2017/08/29 03:26:51 step 0: objective=0.45989922
2017/08/29 03:26:54 step 1: objective=0.4632204
2017/08/29 03:26:56 step 2: objective=0.46760693
2017/08/29 03:26:58 step 3: objective=0.47070792
2017/08/29 03:27:01 step 4: objective=0.4738445
2017/08/29 03:27:03 step 5: objective=0.47652087
2017/08/29 03:27:06 step 6: objective=0.479174
2017/08/29 03:27:08 step 7: objective=0.48327786
2017/08/29 03:27:08 Training value function...
2017/08/29 03:27:11 step 0: mse=132.096756 step=0.100000
2017/08/29 03:27:12 step 1: mse=129.827619 step=0.100000
2017/08/29 03:27:13 step 2: mse=127.958920 step=0.100000
2017/08/29 03:27:15 step 3: mse=126.115746 step=0.100000
2017/08/29 03:27:16 step 4: mse=124.616357 step=0.100000
2017/08/29 03:27:17 step 5: mse=122.896759 step=0.100000
2017/08/29 03:27:19 step 6: mse=121.836666 step=0.100000
2017/08/29 03:27:20 step 7: mse=120.543828 step=0.100000
2017/08/29 03:27:20 Saving...
2017/08/29 03:27:20 Gathering batch of experience...
2017/08/29 03:28:09 batch 930: mean=181.857143 stddev=137.793664 entropy=0.327406 frames=6135 count=35
2017/08/29 03:28:09 Training policy...
2017/08/29 03:28:14 step 0: objective=1.131197
2017/08/29 03:28:16 step 1: objective=1.1345965
2017/08/29 03:28:19 step 2: objective=1.1391432
2017/08/29 03:28:21 step 3: objective=1.1425236
2017/08/29 03:28:23 step 4: objective=1.1455455
2017/08/29 03:28:26 step 5: objective=1.1484691
2017/08/29 03:28:28 step 6: objective=1.1519605
2017/08/29 03:28:30 step 7: objective=1.1545258
2017/08/29 03:28:30 Training value function...
2017/08/29 03:28:33 step 0: mse=153.719704 step=0.100000
2017/08/29 03:28:34 step 1: mse=151.748079 step=0.100000
2017/08/29 03:28:35 step 2: mse=149.775371 step=0.100000
2017/08/29 03:28:37 step 3: mse=148.198197 step=0.100000
2017/08/29 03:28:38 step 4: mse=146.879939 step=0.100000
2017/08/29 03:28:39 step 5: mse=145.796187 step=0.100000
2017/08/29 03:28:41 step 6: mse=144.979852 step=0.100000
2017/08/29 03:28:42 step 7: mse=144.090037 step=0.100000
2017/08/29 03:28:42 Saving...
2017/08/29 03:28:42 Gathering batch of experience...
2017/08/29 03:29:29 batch 931: mean=214.838710 stddev=173.842735 entropy=0.323755 frames=6416 count=31
2017/08/29 03:29:29 Training policy...
2017/08/29 03:29:34 step 0: objective=1.6256727
2017/08/29 03:29:37 step 1: objective=1.6329753
2017/08/29 03:29:39 step 2: objective=1.6375736
2017/08/29 03:29:42 step 3: objective=1.6450173
2017/08/29 03:29:44 step 4: objective=1.6484756
2017/08/29 03:29:46 step 5: objective=1.6549655
2017/08/29 03:29:49 step 6: objective=1.6573743
2017/08/29 03:29:51 step 7: objective=1.661334
2017/08/29 03:29:51 Training value function...
2017/08/29 03:29:54 step 0: mse=169.559761 step=0.100000
2017/08/29 03:29:55 step 1: mse=166.262783 step=0.100000
2017/08/29 03:29:57 step 2: mse=163.308581 step=0.100000
2017/08/29 03:29:58 step 3: mse=161.075815 step=0.100000
2017/08/29 03:30:00 step 4: mse=158.440484 step=0.100000
2017/08/29 03:30:01 step 5: mse=156.031457 step=0.100000
2017/08/29 03:30:02 step 6: mse=153.891542 step=0.100000
2017/08/29 03:30:04 step 7: mse=151.968800 step=0.100000
2017/08/29 03:30:04 Saving...
2017/08/29 03:30:04 Gathering batch of experience...
2017/08/29 03:30:54 batch 932: mean=165.102564 stddev=140.970954 entropy=0.330162 frames=6148 count=39
2017/08/29 03:30:54 Training policy...
2017/08/29 03:30:59 step 0: objective=0.754556
2017/08/29 03:31:01 step 1: objective=0.7589546
2017/08/29 03:31:04 step 2: objective=0.7642325
2017/08/29 03:31:06 step 3: objective=0.7684874
2017/08/29 03:31:08 step 4: objective=0.7738729
2017/08/29 03:31:11 step 5: objective=0.777061
2017/08/29 03:31:13 step 6: objective=0.77913105
2017/08/29 03:31:15 step 7: objective=0.7816773
2017/08/29 03:31:15 Training value function...
2017/08/29 03:31:18 step 0: mse=151.018481 step=0.100000
2017/08/29 03:31:19 step 1: mse=149.479019 step=0.100000
2017/08/29 03:31:20 step 2: mse=148.109685 step=0.100000
2017/08/29 03:31:22 step 3: mse=147.306921 step=0.100000
2017/08/29 03:31:23 step 4: mse=146.120802 step=0.100000
2017/08/29 03:31:24 step 5: mse=145.121124 step=0.100000
2017/08/29 03:31:26 step 6: mse=144.333937 step=0.100000
2017/08/29 03:31:27 step 7: mse=143.438303 step=0.100000
2017/08/29 03:31:27 Saving...
2017/08/29 03:31:27 Gathering batch of experience...
2017/08/29 03:32:11 batch 933: mean=205.300000 stddev=126.549108 entropy=0.323707 frames=5819 count=30
2017/08/29 03:32:11 Training policy...
2017/08/29 03:32:16 step 0: objective=1.3297503
2017/08/29 03:32:18 step 1: objective=1.3357812
2017/08/29 03:32:21 step 2: objective=1.3422092
2017/08/29 03:32:23 step 3: objective=1.3478383
2017/08/29 03:32:25 step 4: objective=1.3510545
2017/08/29 03:32:27 step 5: objective=1.3546813
2017/08/29 03:32:30 step 6: objective=1.3598877
2017/08/29 03:32:32 step 7: objective=1.3623941
2017/08/29 03:32:32 Training value function...
2017/08/29 03:32:34 step 0: mse=159.244099 step=0.100000
2017/08/29 03:32:35 step 1: mse=156.147979 step=0.100000
2017/08/29 03:32:37 step 2: mse=153.262336 step=0.100000
2017/08/29 03:32:38 step 3: mse=150.752102 step=0.100000
2017/08/29 03:32:39 step 4: mse=148.524478 step=0.100000
2017/08/29 03:32:40 step 5: mse=146.642268 step=0.100000
2017/08/29 03:32:42 step 6: mse=145.119165 step=0.100000
2017/08/29 03:32:43 step 7: mse=143.808747 step=0.100000
2017/08/29 03:32:43 Saving...
2017/08/29 03:32:43 Gathering batch of experience...
2017/08/29 03:33:35 batch 934: mean=205.285714 stddev=179.802045 entropy=0.328934 frames=6477 count=35
2017/08/29 03:33:35 Training policy...
2017/08/29 03:33:40 step 0: objective=1.963696
2017/08/29 03:33:42 step 1: objective=1.9674911
2017/08/29 03:33:45 step 2: objective=1.9735965
2017/08/29 03:33:47 step 3: objective=1.9810274
2017/08/29 03:33:50 step 4: objective=1.9842162
2017/08/29 03:33:52 step 5: objective=1.9885961
2017/08/29 03:33:55 step 6: objective=1.9914826
2017/08/29 03:33:57 step 7: objective=1.9959424
2017/08/29 03:33:57 Training value function...
2017/08/29 03:34:00 step 0: mse=193.455362 step=0.100000
2017/08/29 03:34:01 step 1: mse=186.957941 step=0.100000
2017/08/29 03:34:03 step 2: mse=181.663095 step=0.100000
2017/08/29 03:34:04 step 3: mse=177.339844 step=0.100000
2017/08/29 03:34:05 step 4: mse=173.577901 step=0.100000
2017/08/29 03:34:07 step 5: mse=170.085585 step=0.100000
2017/08/29 03:34:08 step 6: mse=167.221775 step=0.100000
2017/08/29 03:34:10 step 7: mse=164.655026 step=0.100000
2017/08/29 03:34:10 Saving...
2017/08/29 03:34:10 Gathering batch of experience...
2017/08/29 03:34:55 batch 935: mean=197.935484 stddev=135.695802 entropy=0.324842 frames=5813 count=31
2017/08/29 03:34:55 Training policy...
2017/08/29 03:35:00 step 0: objective=0.694312
2017/08/29 03:35:02 step 1: objective=0.6978911
2017/08/29 03:35:04 step 2: objective=0.7048563
2017/08/29 03:35:07 step 3: objective=0.7106867
2017/08/29 03:35:09 step 4: objective=0.71692497
2017/08/29 03:35:11 step 5: objective=0.719582
2017/08/29 03:35:13 step 6: objective=0.72215295
2017/08/29 03:35:15 step 7: objective=0.7258673
2017/08/29 03:35:15 Training value function...
2017/08/29 03:35:18 step 0: mse=143.392827 step=0.100000
2017/08/29 03:35:19 step 1: mse=141.753739 step=0.100000
2017/08/29 03:35:20 step 2: mse=140.680405 step=0.100000
2017/08/29 03:35:22 step 3: mse=139.659023 step=0.100000
2017/08/29 03:35:23 step 4: mse=138.911097 step=0.100000
2017/08/29 03:35:24 step 5: mse=137.984932 step=0.100000
2017/08/29 03:35:25 step 6: mse=137.282421 step=0.100000
2017/08/29 03:35:27 step 7: mse=136.363569 step=0.100000
2017/08/29 03:35:27 Saving...
2017/08/29 03:35:27 Gathering batch of experience...
2017/08/29 03:36:16 batch 936: mean=251.107143 stddev=141.371431 entropy=0.327861 frames=6619 count=28
2017/08/29 03:36:16 Training policy...
2017/08/29 03:36:22 step 0: objective=1.5069106
2017/08/29 03:36:24 step 1: objective=1.5104481
2017/08/29 03:36:27 step 2: objective=1.513688
2017/08/29 03:36:29 step 3: objective=1.5169839
2017/08/29 03:36:32 step 4: objective=1.5193725
2017/08/29 03:36:34 step 5: objective=1.5233092
2017/08/29 03:36:37 step 6: objective=1.5274572
2017/08/29 03:36:39 step 7: objective=1.5302993
2017/08/29 03:36:39 Training value function...
2017/08/29 03:36:42 step 0: mse=147.875651 step=0.100000
2017/08/29 03:36:43 step 1: mse=145.911119 step=0.100000
2017/08/29 03:36:45 step 2: mse=144.046575 step=0.100000
2017/08/29 03:36:46 step 3: mse=142.611650 step=0.100000
2017/08/29 03:36:48 step 4: mse=140.919604 step=0.100000
2017/08/29 03:36:49 step 5: mse=139.741434 step=0.100000
2017/08/29 03:36:50 step 6: mse=138.817507 step=0.100000
2017/08/29 03:36:52 step 7: mse=137.600435 step=0.100000
2017/08/29 03:36:52 Saving...
2017/08/29 03:36:52 Gathering batch of experience...
2017/08/29 03:37:39 batch 937: mean=160.971429 stddev=109.172599 entropy=0.326852 frames=5593 count=35
2017/08/29 03:37:39 Training policy...
2017/08/29 03:37:44 step 0: objective=-0.2590846
2017/08/29 03:37:46 step 1: objective=-0.25344607
2017/08/29 03:37:48 step 2: objective=-0.24840398
2017/08/29 03:37:50 step 3: objective=-0.24400559
2017/08/29 03:37:52 step 4: objective=-0.23662423
2017/08/29 03:37:54 step 5: objective=-0.23187804
2017/08/29 03:37:56 step 6: objective=-0.22781016
2017/08/29 03:37:59 step 7: objective=-0.22489324
2017/08/29 03:37:59 Training value function...
2017/08/29 03:38:01 step 0: mse=144.985484 step=0.100000
2017/08/29 03:38:02 step 1: mse=143.042096 step=0.100000
2017/08/29 03:38:03 step 2: mse=141.249606 step=0.100000
2017/08/29 03:38:04 step 3: mse=140.100051 step=0.100000
2017/08/29 03:38:06 step 4: mse=139.184687 step=0.100000
2017/08/29 03:38:07 step 5: mse=138.195043 step=0.100000
2017/08/29 03:38:08 step 6: mse=137.295602 step=0.100000
2017/08/29 03:38:09 step 7: mse=136.709018 step=0.100000
2017/08/29 03:38:09 Saving...
2017/08/29 03:38:09 Gathering batch of experience...
2017/08/29 03:38:57 batch 938: mean=215.833333 stddev=143.776466 entropy=0.323267 frames=6150 count=30
2017/08/29 03:38:57 Training policy...
2017/08/29 03:39:02 step 0: objective=1.860015
2017/08/29 03:39:04 step 1: objective=1.8640726
2017/08/29 03:39:07 step 2: objective=1.8696818
2017/08/29 03:39:09 step 3: objective=1.87341
2017/08/29 03:39:12 step 4: objective=1.8770281
2017/08/29 03:39:14 step 5: objective=1.879712
2017/08/29 03:39:16 step 6: objective=1.8839087
2017/08/29 03:39:19 step 7: objective=1.8868762
2017/08/29 03:39:19 Training value function...
2017/08/29 03:39:21 step 0: mse=164.394604 step=0.100000
2017/08/29 03:39:22 step 1: mse=160.791903 step=0.100000
2017/08/29 03:39:24 step 2: mse=157.481436 step=0.100000
2017/08/29 03:39:25 step 3: mse=154.126172 step=0.100000
2017/08/29 03:39:26 step 4: mse=151.444787 step=0.100000
2017/08/29 03:39:28 step 5: mse=149.275815 step=0.100000
2017/08/29 03:39:29 step 6: mse=146.838237 step=0.100000
2017/08/29 03:39:30 step 7: mse=144.729460 step=0.100000
2017/08/29 03:39:30 Saving...
2017/08/29 03:39:30 Gathering batch of experience...
2017/08/29 03:40:21 batch 939: mean=219.870968 stddev=143.454105 entropy=0.326969 frames=6260 count=31
2017/08/29 03:40:21 Training policy...
2017/08/29 03:40:26 step 0: objective=1.7597941
2017/08/29 03:40:28 step 1: objective=1.7655557
2017/08/29 03:40:31 step 2: objective=1.7735574
2017/08/29 03:40:33 step 3: objective=1.7778953
2017/08/29 03:40:35 step 4: objective=1.7811612
2017/08/29 03:40:38 step 5: objective=1.78431
2017/08/29 03:40:40 step 6: objective=1.7866553
2017/08/29 03:40:43 step 7: objective=1.7903626
2017/08/29 03:40:43 Training value function...
2017/08/29 03:40:45 step 0: mse=148.884456 step=0.100000
2017/08/29 03:40:47 step 1: mse=146.058706 step=0.100000
2017/08/29 03:40:48 step 2: mse=143.722546 step=0.100000
2017/08/29 03:40:49 step 3: mse=141.579704 step=0.100000
2017/08/29 03:40:51 step 4: mse=139.675142 step=0.100000
2017/08/29 03:40:52 step 5: mse=137.909310 step=0.100000
2017/08/29 03:40:53 step 6: mse=136.327157 step=0.100000
2017/08/29 03:40:54 step 7: mse=134.865054 step=0.100000
2017/08/29 03:40:54 Saving...
2017/08/29 03:40:55 Gathering batch of experience...
2017/08/29 03:41:43 batch 940: mean=223.290323 stddev=180.064002 entropy=0.328511 frames=6481 count=31
2017/08/29 03:41:43 Training policy...
2017/08/29 03:41:48 step 0: objective=1.4338225
2017/08/29 03:41:51 step 1: objective=1.4378717
2017/08/29 03:41:53 step 2: objective=1.4426267
2017/08/29 03:41:56 step 3: objective=1.4470738
2017/08/29 03:41:58 step 4: objective=1.4509292
2017/08/29 03:42:01 step 5: objective=1.4533306
2017/08/29 03:42:03 step 6: objective=1.4564028
2017/08/29 03:42:05 step 7: objective=1.4598247
2017/08/29 03:42:05 Training value function...
2017/08/29 03:42:08 step 0: mse=178.296655 step=0.100000
2017/08/29 03:42:10 step 1: mse=173.459543 step=0.100000
2017/08/29 03:42:11 step 2: mse=169.619175 step=0.100000
2017/08/29 03:42:12 step 3: mse=166.141129 step=0.100000
2017/08/29 03:42:14 step 4: mse=163.428744 step=0.100000
2017/08/29 03:42:15 step 5: mse=160.821022 step=0.100000
2017/08/29 03:42:16 step 6: mse=158.972622 step=0.100000
2017/08/29 03:42:18 step 7: mse=156.855402 step=0.100000
2017/08/29 03:42:18 Saving...
2017/08/29 03:42:18 Gathering batch of experience...
2017/08/29 03:43:10 batch 941: mean=198.129032 stddev=166.715857 entropy=0.325093 frames=5823 count=31
2017/08/29 03:43:10 Training policy...
2017/08/29 03:43:14 step 0: objective=0.72689027
2017/08/29 03:43:17 step 1: objective=0.7354226
2017/08/29 03:43:19 step 2: objective=0.74084365
2017/08/29 03:43:21 step 3: objective=0.74556583
2017/08/29 03:43:23 step 4: objective=0.7500998
2017/08/29 03:43:25 step 5: objective=0.7525276
2017/08/29 03:43:28 step 6: objective=0.7555088
2017/08/29 03:43:30 step 7: objective=0.75803465
2017/08/29 03:43:30 Training value function...
2017/08/29 03:43:32 step 0: mse=149.164252 step=0.100000
2017/08/29 03:43:34 step 1: mse=146.487759 step=0.100000
2017/08/29 03:43:35 step 2: mse=143.714853 step=0.100000
2017/08/29 03:43:36 step 3: mse=141.360879 step=0.100000
2017/08/29 03:43:37 step 4: mse=139.470871 step=0.100000
2017/08/29 03:43:39 step 5: mse=137.775246 step=0.100000
2017/08/29 03:43:40 step 6: mse=135.965458 step=0.100000
2017/08/29 03:43:41 step 7: mse=134.600616 step=0.100000
2017/08/29 03:43:41 Saving...
2017/08/29 03:43:41 Gathering batch of experience...
2017/08/29 03:44:22 batch 942: mean=147.833333 stddev=101.800595 entropy=0.322278 frames=4976 count=36
2017/08/29 03:44:22 Training policy...
2017/08/29 03:44:26 step 0: objective=0.32471514
2017/08/29 03:44:28 step 1: objective=0.3309915
2017/08/29 03:44:30 step 2: objective=0.33897004
2017/08/29 03:44:32 step 3: objective=0.34641236
2017/08/29 03:44:34 step 4: objective=0.35075152
2017/08/29 03:44:36 step 5: objective=0.35774353
2017/08/29 03:44:37 step 6: objective=0.36152536
2017/08/29 03:44:39 step 7: objective=0.36522064
2017/08/29 03:44:39 Training value function...
2017/08/29 03:44:41 step 0: mse=178.449480 step=0.100000
2017/08/29 03:44:42 step 1: mse=175.565317 step=0.100000
2017/08/29 03:44:43 step 2: mse=173.342915 step=0.100000
2017/08/29 03:44:45 step 3: mse=171.337865 step=0.100000
2017/08/29 03:44:46 step 4: mse=169.380601 step=0.100000
2017/08/29 03:44:47 step 5: mse=168.008882 step=0.100000
2017/08/29 03:44:48 step 6: mse=166.548129 step=0.100000
2017/08/29 03:44:49 step 7: mse=165.270668 step=0.100000
2017/08/29 03:44:49 Saving...
2017/08/29 03:44:49 Gathering batch of experience...
2017/08/29 03:45:39 batch 943: mean=162.000000 stddev=154.165057 entropy=0.324415 frames=6048 count=37
2017/08/29 03:45:39 Training policy...
2017/08/29 03:45:44 step 0: objective=0.4185775
2017/08/29 03:45:46 step 1: objective=0.4257093
2017/08/29 03:45:48 step 2: objective=0.43188033
2017/08/29 03:45:51 step 3: objective=0.43607408
2017/08/29 03:45:53 step 4: objective=0.44181824
2017/08/29 03:45:55 step 5: objective=0.4470477
2017/08/29 03:45:58 step 6: objective=0.45022652
2017/08/29 03:46:00 step 7: objective=0.45264193
2017/08/29 03:46:00 Training value function...
2017/08/29 03:46:03 step 0: mse=151.560606 step=0.100000
2017/08/29 03:46:04 step 1: mse=149.559323 step=0.100000
2017/08/29 03:46:05 step 2: mse=148.065361 step=0.100000
2017/08/29 03:46:06 step 3: mse=146.446368 step=0.100000
2017/08/29 03:46:08 step 4: mse=145.054138 step=0.100000
2017/08/29 03:46:09 step 5: mse=144.050228 step=0.100000
2017/08/29 03:46:10 step 6: mse=142.991475 step=0.100000
2017/08/29 03:46:12 step 7: mse=142.034079 step=0.100000
2017/08/29 03:46:12 Saving...
2017/08/29 03:46:12 Gathering batch of experience...
2017/08/29 03:47:03 batch 944: mean=186.542857 stddev=145.938998 entropy=0.331450 frames=6469 count=35
2017/08/29 03:47:03 Training policy...
2017/08/29 03:47:08 step 0: objective=1.427546
2017/08/29 03:47:10 step 1: objective=1.4337764
2017/08/29 03:47:13 step 2: objective=1.4370254
2017/08/29 03:47:15 step 3: objective=1.4422219
2017/08/29 03:47:18 step 4: objective=1.4453709
2017/08/29 03:47:20 step 5: objective=1.4479243
2017/08/29 03:47:23 step 6: objective=1.4519782
2017/08/29 03:47:25 step 7: objective=1.4550229
2017/08/29 03:47:25 Training value function...
2017/08/29 03:47:28 step 0: mse=162.452713 step=0.100000
2017/08/29 03:47:29 step 1: mse=159.622609 step=0.100000
2017/08/29 03:47:31 step 2: mse=157.166668 step=0.100000
2017/08/29 03:47:32 step 3: mse=154.835645 step=0.100000
2017/08/29 03:47:33 step 4: mse=152.679409 step=0.100000
2017/08/29 03:47:35 step 5: mse=150.932522 step=0.100000
2017/08/29 03:47:36 step 6: mse=149.478047 step=0.100000
2017/08/29 03:47:38 step 7: mse=147.845788 step=0.100000
2017/08/29 03:47:38 Saving...
2017/08/29 03:47:38 Gathering batch of experience...
2017/08/29 03:48:23 batch 945: mean=204.967742 stddev=180.292322 entropy=0.325675 frames=6042 count=31
2017/08/29 03:48:23 Training policy...
2017/08/29 03:48:28 step 0: objective=1.7964612
2017/08/29 03:48:30 step 1: objective=1.8018936
2017/08/29 03:48:33 step 2: objective=1.8071588
2017/08/29 03:48:35 step 3: objective=1.8110569
2017/08/29 03:48:37 step 4: objective=1.8164212
2017/08/29 03:48:40 step 5: objective=1.819653
2017/08/29 03:48:42 step 6: objective=1.8242224
2017/08/29 03:48:44 step 7: objective=1.8266882
2017/08/29 03:48:44 Training value function...
2017/08/29 03:48:47 step 0: mse=176.532576 step=0.100000
2017/08/29 03:48:48 step 1: mse=172.108722 step=0.100000
2017/08/29 03:48:50 step 2: mse=168.245372 step=0.100000
2017/08/29 03:48:51 step 3: mse=164.850668 step=0.100000
2017/08/29 03:48:52 step 4: mse=162.124914 step=0.100000
2017/08/29 03:48:53 step 5: mse=159.617343 step=0.100000
2017/08/29 03:48:55 step 6: mse=157.594617 step=0.100000
2017/08/29 03:48:56 step 7: mse=155.806129 step=0.100000
2017/08/29 03:48:56 Saving...
2017/08/29 03:48:56 Gathering batch of experience...
2017/08/29 03:49:45 batch 946: mean=251.851852 stddev=166.693710 entropy=0.326925 frames=6496 count=27
2017/08/29 03:49:45 Training policy...
2017/08/29 03:49:51 step 0: objective=1.4297979
2017/08/29 03:49:53 step 1: objective=1.4346211
2017/08/29 03:49:56 step 2: objective=1.4388729
2017/08/29 03:49:58 step 3: objective=1.4429804
2017/08/29 03:50:01 step 4: objective=1.4464712
2017/08/29 03:50:03 step 5: objective=1.4486165
2017/08/29 03:50:06 step 6: objective=1.4532233
2017/08/29 03:50:08 step 7: objective=1.4559839
2017/08/29 03:50:08 Training value function...
2017/08/29 03:50:11 step 0: mse=143.064937 step=0.100000
2017/08/29 03:50:12 step 1: mse=140.297363 step=0.100000
2017/08/29 03:50:14 step 2: mse=138.058994 step=0.100000
2017/08/29 03:50:15 step 3: mse=136.002372 step=0.100000
2017/08/29 03:50:16 step 4: mse=134.197369 step=0.100000
2017/08/29 03:50:18 step 5: mse=132.546518 step=0.100000
2017/08/29 03:50:19 step 6: mse=131.084599 step=0.100000
2017/08/29 03:50:20 step 7: mse=129.754793 step=0.100000
2017/08/29 03:50:20 Saving...
2017/08/29 03:50:20 Gathering batch of experience...
2017/08/29 03:51:06 batch 947: mean=204.333333 stddev=138.004670 entropy=0.320267 frames=5876 count=30
2017/08/29 03:51:06 Training policy...
2017/08/29 03:51:11 step 0: objective=0.75641316
2017/08/29 03:51:13 step 1: objective=0.7637209
2017/08/29 03:51:16 step 2: objective=0.76690954
2017/08/29 03:51:18 step 3: objective=0.7727818
2017/08/29 03:51:20 step 4: objective=0.7768049
2017/08/29 03:51:22 step 5: objective=0.7794687
2017/08/29 03:51:25 step 6: objective=0.7817938
2017/08/29 03:51:27 step 7: objective=0.78602016
2017/08/29 03:51:27 Training value function...
2017/08/29 03:51:29 step 0: mse=142.507377 step=0.100000
2017/08/29 03:51:31 step 1: mse=139.381104 step=0.100000
2017/08/29 03:51:32 step 2: mse=136.370289 step=0.100000
2017/08/29 03:51:33 step 3: mse=134.267772 step=0.100000
2017/08/29 03:51:34 step 4: mse=132.232807 step=0.100000
2017/08/29 03:51:36 step 5: mse=130.419005 step=0.100000
2017/08/29 03:51:37 step 6: mse=129.079353 step=0.100000
2017/08/29 03:51:38 step 7: mse=127.888294 step=0.100000
2017/08/29 03:51:38 Saving...
2017/08/29 03:51:38 Gathering batch of experience...
2017/08/29 03:52:33 batch 948: mean=208.400000 stddev=207.212548 entropy=0.325889 frames=6782 count=35
2017/08/29 03:52:33 Training policy...
2017/08/29 03:52:39 step 0: objective=1.6297078
2017/08/29 03:52:41 step 1: objective=1.6347318
2017/08/29 03:52:44 step 2: objective=1.6398737
2017/08/29 03:52:46 step 3: objective=1.6430602
2017/08/29 03:52:49 step 4: objective=1.6481887
2017/08/29 03:52:52 step 5: objective=1.6552048
2017/08/29 03:52:54 step 6: objective=1.6587669
2017/08/29 03:52:57 step 7: objective=1.6620733
2017/08/29 03:52:57 Training value function...
2017/08/29 03:53:00 step 0: mse=191.246379 step=0.100000
2017/08/29 03:53:01 step 1: mse=184.987857 step=0.100000
2017/08/29 03:53:03 step 2: mse=179.836727 step=0.100000
2017/08/29 03:53:04 step 3: mse=175.904777 step=0.100000
2017/08/29 03:53:06 step 4: mse=172.455515 step=0.100000
2017/08/29 03:53:07 step 5: mse=169.237544 step=0.100000
2017/08/29 03:53:08 step 6: mse=166.843973 step=0.100000
2017/08/29 03:53:10 step 7: mse=164.471653 step=0.100000
2017/08/29 03:53:10 Saving...
2017/08/29 03:53:10 Gathering batch of experience...
2017/08/29 03:54:06 batch 949: mean=224.941176 stddev=196.423903 entropy=0.324143 frames=7144 count=34
2017/08/29 03:54:06 Training policy...
2017/08/29 03:54:12 step 0: objective=1.2667515
2017/08/29 03:54:15 step 1: objective=1.271254
2017/08/29 03:54:17 step 2: objective=1.2749388
2017/08/29 03:54:20 step 3: objective=1.2809358
2017/08/29 03:54:23 step 4: objective=1.2868814
2017/08/29 03:54:26 step 5: objective=1.2905544
2017/08/29 03:54:28 step 6: objective=1.2930702
2017/08/29 03:54:31 step 7: objective=1.2967293
2017/08/29 03:54:31 Training value function...
2017/08/29 03:54:34 step 0: mse=169.990775 step=0.100000
2017/08/29 03:54:35 step 1: mse=166.630058 step=0.100000
2017/08/29 03:54:37 step 2: mse=164.340168 step=0.100000
2017/08/29 03:54:38 step 3: mse=161.626236 step=0.100000
2017/08/29 03:54:40 step 4: mse=159.518854 step=0.100000
2017/08/29 03:54:41 step 5: mse=157.541126 step=0.100000
2017/08/29 03:54:43 step 6: mse=155.943524 step=0.100000
2017/08/29 03:54:45 step 7: mse=154.456787 step=0.100000
2017/08/29 03:54:45 Saving...
2017/08/29 03:54:45 Gathering batch of experience...
2017/08/29 03:55:34 batch 950: mean=192.696970 stddev=154.882064 entropy=0.318176 frames=6085 count=33
2017/08/29 03:55:34 Training policy...
2017/08/29 03:55:39 step 0: objective=0.60985565
2017/08/29 03:55:41 step 1: objective=0.6147799
2017/08/29 03:55:43 step 2: objective=0.62186563
2017/08/29 03:55:46 step 3: objective=0.6251659
2017/08/29 03:55:48 step 4: objective=0.6280725
2017/08/29 03:55:50 step 5: objective=0.63253796
2017/08/29 03:55:53 step 6: objective=0.63545287
2017/08/29 03:55:55 step 7: objective=0.63841456
2017/08/29 03:55:55 Training value function...
2017/08/29 03:55:58 step 0: mse=161.670670 step=0.100000
2017/08/29 03:55:59 step 1: mse=158.776088 step=0.100000
2017/08/29 03:56:00 step 2: mse=156.704880 step=0.100000
2017/08/29 03:56:01 step 3: mse=154.855683 step=0.100000
2017/08/29 03:56:03 step 4: mse=153.059229 step=0.100000
2017/08/29 03:56:04 step 5: mse=151.678633 step=0.100000
2017/08/29 03:56:05 step 6: mse=150.593098 step=0.100000
2017/08/29 03:56:07 step 7: mse=148.936874 step=0.100000
2017/08/29 03:56:07 Saving...
2017/08/29 03:56:07 Gathering batch of experience...
2017/08/29 03:56:56 batch 951: mean=229.250000 stddev=153.806087 entropy=0.320747 frames=6532 count=32
2017/08/29 03:56:56 Training policy...
2017/08/29 03:57:02 step 0: objective=1.900526
2017/08/29 03:57:04 step 1: objective=1.9038875
2017/08/29 03:57:07 step 2: objective=1.9071116
2017/08/29 03:57:09 step 3: objective=1.913545
2017/08/29 03:57:12 step 4: objective=1.9165664
2017/08/29 03:57:14 step 5: objective=1.9200178
2017/08/29 03:57:17 step 6: objective=1.9228244
2017/08/29 03:57:19 step 7: objective=1.9250706
2017/08/29 03:57:19 Training value function...
2017/08/29 03:57:22 step 0: mse=165.379544 step=0.100000
2017/08/29 03:57:24 step 1: mse=161.207593 step=0.100000
2017/08/29 03:57:25 step 2: mse=157.734987 step=0.100000
2017/08/29 03:57:26 step 3: mse=154.726381 step=0.100000
2017/08/29 03:57:28 step 4: mse=152.046442 step=0.100000
2017/08/29 03:57:29 step 5: mse=149.667082 step=0.100000
2017/08/29 03:57:30 step 6: mse=147.709314 step=0.100000
2017/08/29 03:57:32 step 7: mse=145.806904 step=0.100000
2017/08/29 03:57:32 Saving...
2017/08/29 03:57:32 Gathering batch of experience...
2017/08/29 03:58:20 batch 952: mean=202.068966 stddev=165.928720 entropy=0.321836 frames=5790 count=29
2017/08/29 03:58:20 Training policy...
2017/08/29 03:58:25 step 0: objective=0.04715029
2017/08/29 03:58:27 step 1: objective=0.05170825
2017/08/29 03:58:29 step 2: objective=0.061990283
2017/08/29 03:58:31 step 3: objective=0.06826839
2017/08/29 03:58:34 step 4: objective=0.07286201
2017/08/29 03:58:36 step 5: objective=0.075463295
2017/08/29 03:58:38 step 6: objective=0.07957574
2017/08/29 03:58:40 step 7: objective=0.083943725
2017/08/29 03:58:40 Training value function...
2017/08/29 03:58:43 step 0: mse=136.491770 step=0.100000
2017/08/29 03:58:44 step 1: mse=133.838452 step=0.100000
2017/08/29 03:58:45 step 2: mse=131.243509 step=0.100000
2017/08/29 03:58:46 step 3: mse=129.080114 step=0.100000
2017/08/29 03:58:48 step 4: mse=127.556638 step=0.100000
2017/08/29 03:58:49 step 5: mse=126.281721 step=0.100000
2017/08/29 03:58:50 step 6: mse=125.211910 step=0.100000
2017/08/29 03:58:51 step 7: mse=124.301982 step=0.100000
2017/08/29 03:58:51 Saving...
2017/08/29 03:58:51 Gathering batch of experience...
2017/08/29 03:59:36 batch 953: mean=207.833333 stddev=173.172185 entropy=0.326581 frames=5777 count=30
2017/08/29 03:59:36 Training policy...
2017/08/29 03:59:41 step 0: objective=1.5403804
2017/08/29 03:59:43 step 1: objective=1.5450745
2017/08/29 03:59:46 step 2: objective=1.5524205
2017/08/29 03:59:48 step 3: objective=1.5594932
2017/08/29 03:59:50 step 4: objective=1.5650923
2017/08/29 03:59:52 step 5: objective=1.5697913
2017/08/29 03:59:55 step 6: objective=1.5756049
2017/08/29 03:59:57 step 7: objective=1.577972
2017/08/29 03:59:57 Training value function...
2017/08/29 03:59:59 step 0: mse=193.229714 step=0.100000
2017/08/29 04:00:00 step 1: mse=189.285567 step=0.100000
2017/08/29 04:00:02 step 2: mse=185.988107 step=0.100000
2017/08/29 04:00:03 step 3: mse=182.614590 step=0.100000
2017/08/29 04:00:04 step 4: mse=180.107489 step=0.100000
2017/08/29 04:00:05 step 5: mse=177.504318 step=0.100000
2017/08/29 04:00:07 step 6: mse=175.509972 step=0.100000
2017/08/29 04:00:08 step 7: mse=173.521882 step=0.100000
2017/08/29 04:00:08 Saving...
2017/08/29 04:00:08 Gathering batch of experience...
2017/08/29 04:00:52 batch 954: mean=147.710526 stddev=122.628216 entropy=0.311431 frames=5498 count=38
2017/08/29 04:00:52 Training policy...
2017/08/29 04:00:57 step 0: objective=-0.22477041
2017/08/29 04:00:59 step 1: objective=-0.21965328
2017/08/29 04:01:01 step 2: objective=-0.21226096
2017/08/29 04:01:03 step 3: objective=-0.20655109
2017/08/29 04:01:05 step 4: objective=-0.20071526
2017/08/29 04:01:07 step 5: objective=-0.19586481
2017/08/29 04:01:09 step 6: objective=-0.19167858
2017/08/29 04:01:12 step 7: objective=-0.18757163
2017/08/29 04:01:12 Training value function...
2017/08/29 04:01:14 step 0: mse=159.432651 step=0.100000
2017/08/29 04:01:15 step 1: mse=156.681517 step=0.100000
2017/08/29 04:01:16 step 2: mse=154.574740 step=0.100000
2017/08/29 04:01:17 step 3: mse=152.740276 step=0.100000
2017/08/29 04:01:19 step 4: mse=151.088839 step=0.100000
2017/08/29 04:01:20 step 5: mse=149.741805 step=0.100000
2017/08/29 04:01:21 step 6: mse=148.681285 step=0.100000
2017/08/29 04:01:22 step 7: mse=147.965618 step=0.100000
2017/08/29 04:01:22 Saving...
2017/08/29 04:01:22 Gathering batch of experience...
2017/08/29 04:02:07 batch 955: mean=190.066667 stddev=148.045924 entropy=0.318339 frames=5480 count=30
2017/08/29 04:02:07 Training policy...
2017/08/29 04:02:11 step 0: objective=1.4138621
2017/08/29 04:02:14 step 1: objective=1.4183348
2017/08/29 04:02:16 step 2: objective=1.422435
2017/08/29 04:02:18 step 3: objective=1.4296736
2017/08/29 04:02:20 step 4: objective=1.4355606
2017/08/29 04:02:22 step 5: objective=1.4380107
2017/08/29 04:02:24 step 6: objective=1.4414167
2017/08/29 04:02:26 step 7: objective=1.4447893
2017/08/29 04:02:26 Training value function...
2017/08/29 04:02:29 step 0: mse=134.868479 step=0.100000
2017/08/29 04:02:30 step 1: mse=132.096849 step=0.100000
2017/08/29 04:02:31 step 2: mse=129.637263 step=0.100000
2017/08/29 04:02:32 step 3: mse=127.780391 step=0.100000
2017/08/29 04:02:33 step 4: mse=125.984045 step=0.100000
2017/08/29 04:02:34 step 5: mse=124.428943 step=0.100000
2017/08/29 04:02:35 step 6: mse=123.260448 step=0.100000
2017/08/29 04:02:37 step 7: mse=121.938614 step=0.100000
2017/08/29 04:02:37 Saving...
2017/08/29 04:02:37 Gathering batch of experience...
2017/08/29 04:03:21 batch 956: mean=170.823529 stddev=116.118973 entropy=0.312259 frames=5450 count=34
2017/08/29 04:03:21 Training policy...
2017/08/29 04:03:25 step 0: objective=1.0668942
2017/08/29 04:03:27 step 1: objective=1.0752039
2017/08/29 04:03:29 step 2: objective=1.0848855
2017/08/29 04:03:32 step 3: objective=1.0885456
2017/08/29 04:03:34 step 4: objective=1.093414
2017/08/29 04:03:36 step 5: objective=1.1006376
2017/08/29 04:03:38 step 6: objective=1.1042829
2017/08/29 04:03:40 step 7: objective=1.1066674
2017/08/29 04:03:40 Training value function...
2017/08/29 04:03:42 step 0: mse=177.931816 step=0.100000
2017/08/29 04:03:43 step 1: mse=175.802410 step=0.100000
2017/08/29 04:03:45 step 2: mse=173.833235 step=0.100000
2017/08/29 04:03:46 step 3: mse=172.138689 step=0.100000
2017/08/29 04:03:47 step 4: mse=170.363315 step=0.100000
2017/08/29 04:03:48 step 5: mse=169.329481 step=0.100000
2017/08/29 04:03:49 step 6: mse=167.730550 step=0.100000
2017/08/29 04:03:50 step 7: mse=166.549995 step=0.100000
2017/08/29 04:03:50 Saving...
2017/08/29 04:03:50 Gathering batch of experience...
2017/08/29 04:04:43 batch 957: mean=200.542857 stddev=171.643874 entropy=0.322551 frames=6857 count=35
2017/08/29 04:04:43 Training policy...
2017/08/29 04:04:49 step 0: objective=1.1612434
2017/08/29 04:04:52 step 1: objective=1.1648906
2017/08/29 04:04:54 step 2: objective=1.1690624
2017/08/29 04:04:57 step 3: objective=1.1751292
2017/08/29 04:05:00 step 4: objective=1.178216
2017/08/29 04:05:02 step 5: objective=1.1811357
2017/08/29 04:05:05 step 6: objective=1.1847088
2017/08/29 04:05:08 step 7: objective=1.1869199
2017/08/29 04:05:08 Training value function...
2017/08/29 04:05:11 step 0: mse=153.710524 step=0.100000
2017/08/29 04:05:12 step 1: mse=151.631087 step=0.100000
2017/08/29 04:05:14 step 2: mse=149.722243 step=0.100000
2017/08/29 04:05:15 step 3: mse=147.875417 step=0.100000
2017/08/29 04:05:16 step 4: mse=146.616257 step=0.100000
2017/08/29 04:05:18 step 5: mse=145.447433 step=0.100000
2017/08/29 04:05:19 step 6: mse=144.182997 step=0.100000
2017/08/29 04:05:21 step 7: mse=143.045788 step=0.100000
2017/08/29 04:05:21 Saving...
2017/08/29 04:05:21 Gathering batch of experience...
2017/08/29 04:06:07 batch 958: mean=220.580645 stddev=178.810365 entropy=0.322965 frames=6233 count=31
2017/08/29 04:06:07 Training policy...
2017/08/29 04:06:12 step 0: objective=2.121723
2017/08/29 04:06:15 step 1: objective=2.1270494
2017/08/29 04:06:17 step 2: objective=2.1326733
2017/08/29 04:06:20 step 3: objective=2.1365705
2017/08/29 04:06:22 step 4: objective=2.1393933
2017/08/29 04:06:24 step 5: objective=2.1416996
2017/08/29 04:06:27 step 6: objective=2.1449301
2017/08/29 04:06:29 step 7: objective=2.1502492
2017/08/29 04:06:29 Training value function...
2017/08/29 04:06:32 step 0: mse=170.492993 step=0.100000
2017/08/29 04:06:33 step 1: mse=165.647800 step=0.100000
2017/08/29 04:06:34 step 2: mse=161.276140 step=0.100000
2017/08/29 04:06:36 step 3: mse=157.696356 step=0.100000
2017/08/29 04:06:37 step 4: mse=154.560934 step=0.100000
2017/08/29 04:06:38 step 5: mse=151.918211 step=0.100000
2017/08/29 04:06:40 step 6: mse=149.460885 step=0.100000
2017/08/29 04:06:41 step 7: mse=147.180364 step=0.100000
2017/08/29 04:06:41 Saving...
2017/08/29 04:06:41 Gathering batch of experience...
2017/08/29 04:07:34 batch 959: mean=203.457143 stddev=198.429310 entropy=0.328098 frames=6878 count=35
2017/08/29 04:07:34 Training policy...
2017/08/29 04:07:40 step 0: objective=0.81119806
2017/08/29 04:07:43 step 1: objective=0.8163277
2017/08/29 04:07:46 step 2: objective=0.8212873
2017/08/29 04:07:48 step 3: objective=0.82495964
2017/08/29 04:07:51 step 4: objective=0.82931536
2017/08/29 04:07:54 step 5: objective=0.8348588
2017/08/29 04:07:56 step 6: objective=0.83876765
2017/08/29 04:07:59 step 7: objective=0.8417229
2017/08/29 04:07:59 Training value function...
2017/08/29 04:08:02 step 0: mse=152.950831 step=0.100000
2017/08/29 04:08:03 step 1: mse=150.460596 step=0.100000
2017/08/29 04:08:05 step 2: mse=148.380894 step=0.100000
2017/08/29 04:08:06 step 3: mse=146.854080 step=0.100000
2017/08/29 04:08:08 step 4: mse=145.191680 step=0.100000
2017/08/29 04:08:09 step 5: mse=143.661975 step=0.100000
2017/08/29 04:08:11 step 6: mse=142.540422 step=0.100000
2017/08/29 04:08:12 step 7: mse=141.759330 step=0.100000
2017/08/29 04:08:12 Saving...
2017/08/29 04:08:12 Gathering batch of experience...
2017/08/29 04:09:04 batch 960: mean=189.411765 stddev=175.312849 entropy=0.324129 frames=6064 count=34
2017/08/29 04:09:04 Training policy...
2017/08/29 04:09:09 step 0: objective=0.9558759
2017/08/29 04:09:12 step 1: objective=0.961024
2017/08/29 04:09:14 step 2: objective=0.96578133
2017/08/29 04:09:16 step 3: objective=0.970399
2017/08/29 04:09:19 step 4: objective=0.97439456
2017/08/29 04:09:21 step 5: objective=0.9769111
2017/08/29 04:09:24 step 6: objective=0.9814665
2017/08/29 04:09:26 step 7: objective=0.9839399
2017/08/29 04:09:26 Training value function...
2017/08/29 04:09:28 step 0: mse=143.755891 step=0.100000
2017/08/29 04:09:30 step 1: mse=140.605800 step=0.100000
2017/08/29 04:09:31 step 2: mse=138.129229 step=0.100000
2017/08/29 04:09:32 step 3: mse=135.751523 step=0.100000
2017/08/29 04:09:34 step 4: mse=134.255881 step=0.100000
2017/08/29 04:09:35 step 5: mse=132.514789 step=0.100000
2017/08/29 04:09:36 step 6: mse=131.131561 step=0.100000
2017/08/29 04:09:37 step 7: mse=130.066618 step=0.100000
2017/08/29 04:09:37 Saving...
2017/08/29 04:09:37 Gathering batch of experience...
2017/08/29 04:10:34 batch 961: mean=198.289474 stddev=177.271708 entropy=0.316315 frames=6973 count=38
2017/08/29 04:10:34 Training policy...
2017/08/29 04:10:40 step 0: objective=1.3374319
2017/08/29 04:10:43 step 1: objective=1.3434541
2017/08/29 04:10:45 step 2: objective=1.3497686
2017/08/29 04:10:48 step 3: objective=1.3559288
2017/08/29 04:10:51 step 4: objective=1.3600917
2017/08/29 04:10:54 step 5: objective=1.3671821
2017/08/29 04:10:56 step 6: objective=1.3715959
2017/08/29 04:10:59 step 7: objective=1.3759028
2017/08/29 04:10:59 Training value function...
2017/08/29 04:11:02 step 0: mse=166.598719 step=0.100000
2017/08/29 04:11:03 step 1: mse=163.786521 step=0.100000
2017/08/29 04:11:05 step 2: mse=161.251839 step=0.100000
2017/08/29 04:11:06 step 3: mse=159.374129 step=0.100000
2017/08/29 04:11:08 step 4: mse=157.540125 step=0.100000
2017/08/29 04:11:09 step 5: mse=155.636864 step=0.100000
2017/08/29 04:11:11 step 6: mse=154.178816 step=0.100000
2017/08/29 04:11:12 step 7: mse=152.747165 step=0.100000
2017/08/29 04:11:12 Saving...
2017/08/29 04:11:12 Gathering batch of experience...
2017/08/29 04:12:00 batch 962: mean=181.205882 stddev=142.024393 entropy=0.317803 frames=5653 count=34
2017/08/29 04:12:00 Training policy...
2017/08/29 04:12:05 step 0: objective=1.0288513
2017/08/29 04:12:07 step 1: objective=1.0353183
2017/08/29 04:12:09 step 2: objective=1.0398263
2017/08/29 04:12:11 step 3: objective=1.0459933
2017/08/29 04:12:14 step 4: objective=1.0533793
2017/08/29 04:12:16 step 5: objective=1.0582639
2017/08/29 04:12:18 step 6: objective=1.0618336
2017/08/29 04:12:20 step 7: objective=1.0659003
2017/08/29 04:12:20 Training value function...
2017/08/29 04:12:22 step 0: mse=168.556924 step=0.100000
2017/08/29 04:12:24 step 1: mse=166.624634 step=0.100000
2017/08/29 04:12:25 step 2: mse=164.544986 step=0.100000
2017/08/29 04:12:26 step 3: mse=163.556583 step=0.100000
2017/08/29 04:12:27 step 4: mse=161.982673 step=0.100000
2017/08/29 04:12:28 step 5: mse=160.906783 step=0.100000
2017/08/29 04:12:30 step 6: mse=159.931180 step=0.100000
2017/08/29 04:12:31 step 7: mse=159.480947 step=0.100000
2017/08/29 04:12:31 Saving...
2017/08/29 04:12:31 Gathering batch of experience...
2017/08/29 04:13:26 batch 963: mean=201.437500 stddev=180.762437 entropy=0.322267 frames=6290 count=32
2017/08/29 04:13:26 Training policy...
2017/08/29 04:13:31 step 0: objective=0.68110585
2017/08/29 04:13:33 step 1: objective=0.6878946
2017/08/29 04:13:36 step 2: objective=0.6941043
2017/08/29 04:13:38 step 3: objective=0.69670415
2017/08/29 04:13:41 step 4: objective=0.70116794
2017/08/29 04:13:43 step 5: objective=0.703918
2017/08/29 04:13:46 step 6: objective=0.7080453
2017/08/29 04:13:48 step 7: objective=0.7100846
2017/08/29 04:13:48 Training value function...
2017/08/29 04:13:51 step 0: mse=122.507167 step=0.100000
2017/08/29 04:13:52 step 1: mse=119.851090 step=0.100000
2017/08/29 04:13:53 step 2: mse=117.551955 step=0.100000
2017/08/29 04:13:55 step 3: mse=115.546092 step=0.100000
2017/08/29 04:13:56 step 4: mse=113.871661 step=0.100000
2017/08/29 04:13:57 step 5: mse=112.272384 step=0.100000
2017/08/29 04:13:59 step 6: mse=110.887852 step=0.100000
2017/08/29 04:14:00 step 7: mse=109.824903 step=0.100000
2017/08/29 04:14:00 Saving...
2017/08/29 04:14:00 Gathering batch of experience...
2017/08/29 04:14:53 batch 964: mean=169.157895 stddev=162.048162 entropy=0.319366 frames=6331 count=38
2017/08/29 04:14:53 Training policy...
2017/08/29 04:14:58 step 0: objective=0.54583657
2017/08/29 04:15:00 step 1: objective=0.5505815
2017/08/29 04:15:03 step 2: objective=0.55813456
2017/08/29 04:15:05 step 3: objective=0.56351596
2017/08/29 04:15:08 step 4: objective=0.56780714
2017/08/29 04:15:10 step 5: objective=0.57008153
2017/08/29 04:15:13 step 6: objective=0.5732894
2017/08/29 04:15:15 step 7: objective=0.5754913
2017/08/29 04:15:15 Training value function...
2017/08/29 04:15:18 step 0: mse=168.174241 step=0.100000
2017/08/29 04:15:19 step 1: mse=165.838616 step=0.100000
2017/08/29 04:15:21 step 2: mse=164.314503 step=0.100000
2017/08/29 04:15:22 step 3: mse=162.766271 step=0.100000
2017/08/29 04:15:23 step 4: mse=161.584065 step=0.100000
2017/08/29 04:15:25 step 5: mse=160.547598 step=0.100000
2017/08/29 04:15:26 step 6: mse=159.385742 step=0.100000
2017/08/29 04:15:27 step 7: mse=158.638134 step=0.100000
2017/08/29 04:15:27 Saving...
2017/08/29 04:15:27 Gathering batch of experience...
2017/08/29 04:16:19 batch 965: mean=195.114286 stddev=163.975917 entropy=0.317412 frames=6271 count=35
2017/08/29 04:16:19 Training policy...
2017/08/29 04:16:24 step 0: objective=1.6388884
2017/08/29 04:16:26 step 1: objective=1.6456147
2017/08/29 04:16:29 step 2: objective=1.6500779
2017/08/29 04:16:31 step 3: objective=1.6538006
2017/08/29 04:16:34 step 4: objective=1.6572088
2017/08/29 04:16:36 step 5: objective=1.6638379
2017/08/29 04:16:39 step 6: objective=1.6673565
2017/08/29 04:16:41 step 7: objective=1.6706649
2017/08/29 04:16:41 Training value function...
2017/08/29 04:16:44 step 0: mse=223.564926 step=0.100000
2017/08/29 04:16:45 step 1: mse=218.042661 step=0.100000
2017/08/29 04:16:46 step 2: mse=213.503093 step=0.100000
2017/08/29 04:16:48 step 3: mse=209.275064 step=0.100000
2017/08/29 04:16:49 step 4: mse=205.784944 step=0.100000
2017/08/29 04:16:50 step 5: mse=202.734158 step=0.100000
2017/08/29 04:16:52 step 6: mse=200.070929 step=0.100000
2017/08/29 04:16:53 step 7: mse=197.485406 step=0.100000
2017/08/29 04:16:53 Saving...
2017/08/29 04:16:53 Gathering batch of experience...
2017/08/29 04:17:40 batch 966: mean=214.645161 stddev=164.138720 entropy=0.326284 frames=5954 count=31
2017/08/29 04:17:40 Training policy...
2017/08/29 04:17:45 step 0: objective=1.6615047
2017/08/29 04:17:47 step 1: objective=1.6689755
2017/08/29 04:17:49 step 2: objective=1.676354
2017/08/29 04:17:52 step 3: objective=1.6823605
2017/08/29 04:17:54 step 4: objective=1.6855775
2017/08/29 04:17:56 step 5: objective=1.6900728
2017/08/29 04:17:59 step 6: objective=1.6923828
2017/08/29 04:18:01 step 7: objective=1.6953893
2017/08/29 04:18:01 Training value function...
2017/08/29 04:18:04 step 0: mse=185.528059 step=0.100000
2017/08/29 04:18:05 step 1: mse=181.924089 step=0.100000
2017/08/29 04:18:06 step 2: mse=179.200649 step=0.100000
2017/08/29 04:18:07 step 3: mse=176.235610 step=0.100000
2017/08/29 04:18:09 step 4: mse=174.267406 step=0.100000
2017/08/29 04:18:10 step 5: mse=172.547662 step=0.100000
2017/08/29 04:18:11 step 6: mse=170.316799 step=0.100000
2017/08/29 04:18:12 step 7: mse=168.382165 step=0.100000
2017/08/29 04:18:12 Saving...
2017/08/29 04:18:12 Gathering batch of experience...
2017/08/29 04:18:58 batch 967: mean=230.423077 stddev=170.312196 entropy=0.314944 frames=5649 count=26
2017/08/29 04:18:58 Training policy...
2017/08/29 04:19:02 step 0: objective=0.9955256
2017/08/29 04:19:05 step 1: objective=1.0022916
2017/08/29 04:19:07 step 2: objective=1.0095469
2017/08/29 04:19:09 step 3: objective=1.0161688
2017/08/29 04:19:11 step 4: objective=1.0197916
2017/08/29 04:19:14 step 5: objective=1.0221698
2017/08/29 04:19:16 step 6: objective=1.026734
2017/08/29 04:19:18 step 7: objective=1.028823
2017/08/29 04:19:18 Training value function...
2017/08/29 04:19:20 step 0: mse=146.488394 step=0.100000
2017/08/29 04:19:22 step 1: mse=142.644327 step=0.100000
2017/08/29 04:19:23 step 2: mse=138.766378 step=0.100000
2017/08/29 04:19:24 step 3: mse=135.760573 step=0.100000
2017/08/29 04:19:25 step 4: mse=133.156200 step=0.100000
2017/08/29 04:19:26 step 5: mse=131.105009 step=0.100000
2017/08/29 04:19:28 step 6: mse=129.238329 step=0.100000
2017/08/29 04:19:29 step 7: mse=127.715552 step=0.100000
2017/08/29 04:19:29 Saving...
2017/08/29 04:19:29 Gathering batch of experience...
2017/08/29 04:20:23 batch 968: mean=209.406250 stddev=171.369276 entropy=0.322595 frames=6284 count=32
2017/08/29 04:20:23 Training policy...
2017/08/29 04:20:28 step 0: objective=0.86208695
2017/08/29 04:20:31 step 1: objective=0.86991584
2017/08/29 04:20:33 step 2: objective=0.8779533
2017/08/29 04:20:36 step 3: objective=0.88376725
2017/08/29 04:20:38 step 4: objective=0.88634926
2017/08/29 04:20:41 step 5: objective=0.89153916
2017/08/29 04:20:43 step 6: objective=0.89493
2017/08/29 04:20:46 step 7: objective=0.8989036
2017/08/29 04:20:46 Training value function...
2017/08/29 04:20:48 step 0: mse=172.957185 step=0.100000
2017/08/29 04:20:50 step 1: mse=170.546844 step=0.100000
2017/08/29 04:20:51 step 2: mse=168.711168 step=0.100000
2017/08/29 04:20:52 step 3: mse=166.704809 step=0.100000
2017/08/29 04:20:54 step 4: mse=165.087060 step=0.100000
2017/08/29 04:20:55 step 5: mse=163.494216 step=0.100000
2017/08/29 04:20:56 step 6: mse=161.963520 step=0.100000
2017/08/29 04:20:58 step 7: mse=160.839848 step=0.100000
2017/08/29 04:20:58 Saving...
2017/08/29 04:20:58 Gathering batch of experience...
2017/08/29 04:21:42 batch 969: mean=199.000000 stddev=144.204156 entropy=0.314255 frames=5691 count=31
2017/08/29 04:21:42 Training policy...
2017/08/29 04:21:48 step 0: objective=1.1620982
2017/08/29 04:21:50 step 1: objective=1.170804
2017/08/29 04:21:53 step 2: objective=1.1773881
2017/08/29 04:21:56 step 3: objective=1.1831542
2017/08/29 04:21:59 step 4: objective=1.188628
2017/08/29 04:22:01 step 5: objective=1.1928607
2017/08/29 04:22:04 step 6: objective=1.1968786
2017/08/29 04:22:06 step 7: objective=1.20121
2017/08/29 04:22:06 Training value function...
2017/08/29 04:22:09 step 0: mse=160.938022 step=0.100000
2017/08/29 04:22:11 step 1: mse=158.752267 step=0.100000
2017/08/29 04:22:12 step 2: mse=157.073128 step=0.100000
2017/08/29 04:22:13 step 3: mse=155.662916 step=0.100000
2017/08/29 04:22:14 step 4: mse=153.953509 step=0.100000
2017/08/29 04:22:15 step 5: mse=152.369453 step=0.100000
2017/08/29 04:22:17 step 6: mse=151.010816 step=0.100000
2017/08/29 04:22:18 step 7: mse=149.607351 step=0.100000
2017/08/29 04:22:18 Saving...
2017/08/29 04:22:18 Gathering batch of experience...
2017/08/29 04:23:08 batch 970: mean=223.437500 stddev=185.657604 entropy=0.319176 frames=6561 count=32
2017/08/29 04:23:08 Training policy...
2017/08/29 04:23:14 step 0: objective=1.3559153
2017/08/29 04:23:17 step 1: objective=1.3590997
2017/08/29 04:23:19 step 2: objective=1.362964
2017/08/29 04:23:22 step 3: objective=1.3710835
2017/08/29 04:23:25 step 4: objective=1.3746485
2017/08/29 04:23:27 step 5: objective=1.3771628
2017/08/29 04:23:30 step 6: objective=1.3804742
2017/08/29 04:23:32 step 7: objective=1.3829851
2017/08/29 04:23:32 Training value function...
2017/08/29 04:23:35 step 0: mse=174.922827 step=0.100000
2017/08/29 04:23:37 step 1: mse=171.915427 step=0.100000
2017/08/29 04:23:38 step 2: mse=169.444233 step=0.100000
2017/08/29 04:23:39 step 3: mse=167.240393 step=0.100000
2017/08/29 04:23:41 step 4: mse=165.003704 step=0.100000
2017/08/29 04:23:42 step 5: mse=162.817530 step=0.100000
2017/08/29 04:23:43 step 6: mse=161.155618 step=0.100000
2017/08/29 04:23:45 step 7: mse=159.748596 step=0.100000
2017/08/29 04:23:45 Saving...
2017/08/29 04:23:45 Gathering batch of experience...
2017/08/29 04:24:36 batch 971: mean=271.538462 stddev=176.916371 entropy=0.318759 frames=6729 count=26
2017/08/29 04:24:36 Training policy...
2017/08/29 04:24:42 step 0: objective=1.0833064
2017/08/29 04:24:45 step 1: objective=1.0858092
2017/08/29 04:24:47 step 2: objective=1.0890734
2017/08/29 04:24:50 step 3: objective=1.0920451
2017/08/29 04:24:53 step 4: objective=1.094599
2017/08/29 04:24:55 step 5: objective=1.0977252
2017/08/29 04:24:58 step 6: objective=1.0996735
2017/08/29 04:25:01 step 7: objective=1.1015116
2017/08/29 04:25:01 Training value function...
2017/08/29 04:25:03 step 0: mse=120.372151 step=0.100000
2017/08/29 04:25:05 step 1: mse=118.929079 step=0.100000
2017/08/29 04:25:06 step 2: mse=117.566316 step=0.100000
2017/08/29 04:25:08 step 3: mse=116.389057 step=0.100000
2017/08/29 04:25:09 step 4: mse=115.431295 step=0.100000
2017/08/29 04:25:11 step 5: mse=114.315368 step=0.100000
2017/08/29 04:25:12 step 6: mse=113.370470 step=0.100000
2017/08/29 04:25:13 step 7: mse=112.492076 step=0.100000
2017/08/29 04:25:13 Saving...
2017/08/29 04:25:14 Gathering batch of experience...
2017/08/29 04:26:04 batch 972: mean=277.407407 stddev=221.293380 entropy=0.322603 frames=6955 count=27
2017/08/29 04:26:04 Training policy...
2017/08/29 04:26:10 step 0: objective=1.6369654
2017/08/29 04:26:13 step 1: objective=1.6417822
2017/08/29 04:26:16 step 2: objective=1.6477913
2017/08/29 04:26:18 step 3: objective=1.6528251
2017/08/29 04:26:21 step 4: objective=1.6558317
2017/08/29 04:26:24 step 5: objective=1.6581857
2017/08/29 04:26:27 step 6: objective=1.6633124
2017/08/29 04:26:29 step 7: objective=1.6665689
2017/08/29 04:26:29 Training value function...
2017/08/29 04:26:32 step 0: mse=152.047128 step=0.100000
2017/08/29 04:26:34 step 1: mse=147.320481 step=0.100000
2017/08/29 04:26:35 step 2: mse=143.936597 step=0.100000
2017/08/29 04:26:37 step 3: mse=140.448424 step=0.100000
2017/08/29 04:26:38 step 4: mse=137.684318 step=0.100000
2017/08/29 04:26:40 step 5: mse=135.082774 step=0.100000
2017/08/29 04:26:41 step 6: mse=132.987292 step=0.100000
2017/08/29 04:26:43 step 7: mse=131.249882 step=0.100000
2017/08/29 04:26:43 Saving...
2017/08/29 04:26:43 Gathering batch of experience...
2017/08/29 04:27:34 batch 973: mean=197.000000 stddev=190.369179 entropy=0.326552 frames=6308 count=33
2017/08/29 04:27:34 Training policy...
2017/08/29 04:27:39 step 0: objective=0.21261857
2017/08/29 04:27:42 step 1: objective=0.21635169
2017/08/29 04:27:44 step 2: objective=0.22256717
2017/08/29 04:27:47 step 3: objective=0.22832727
2017/08/29 04:27:49 step 4: objective=0.23461396
2017/08/29 04:27:52 step 5: objective=0.23907827
2017/08/29 04:27:54 step 6: objective=0.24441107
2017/08/29 04:27:57 step 7: objective=0.2474489
2017/08/29 04:27:57 Training value function...
2017/08/29 04:27:59 step 0: mse=142.014751 step=0.100000
2017/08/29 04:28:01 step 1: mse=139.952877 step=0.100000
2017/08/29 04:28:02 step 2: mse=138.287453 step=0.100000
2017/08/29 04:28:03 step 3: mse=136.579092 step=0.100000
2017/08/29 04:28:05 step 4: mse=135.382897 step=0.100000
2017/08/29 04:28:06 step 5: mse=134.412322 step=0.100000
2017/08/29 04:28:07 step 6: mse=133.467696 step=0.100000
2017/08/29 04:28:09 step 7: mse=132.586516 step=0.100000
2017/08/29 04:28:09 Saving...
2017/08/29 04:28:09 Gathering batch of experience...
2017/08/29 04:28:56 batch 974: mean=201.909091 stddev=158.396197 entropy=0.320589 frames=6235 count=33
2017/08/29 04:28:56 Training policy...
2017/08/29 04:29:01 step 0: objective=1.1710701
2017/08/29 04:29:04 step 1: objective=1.1749814
2017/08/29 04:29:06 step 2: objective=1.179085
2017/08/29 04:29:09 step 3: objective=1.183429
2017/08/29 04:29:11 step 4: objective=1.1880754
2017/08/29 04:29:14 step 5: objective=1.1924161
2017/08/29 04:29:16 step 6: objective=1.1955364
2017/08/29 04:29:18 step 7: objective=1.1999762
2017/08/29 04:29:18 Training value function...
2017/08/29 04:29:21 step 0: mse=175.548514 step=0.100000
2017/08/29 04:29:23 step 1: mse=171.762447 step=0.100000
2017/08/29 04:29:24 step 2: mse=168.615555 step=0.100000
2017/08/29 04:29:25 step 3: mse=165.986751 step=0.100000
2017/08/29 04:29:26 step 4: mse=163.629879 step=0.100000
2017/08/29 04:29:28 step 5: mse=161.447239 step=0.100000
2017/08/29 04:29:29 step 6: mse=159.442034 step=0.100000
2017/08/29 04:29:30 step 7: mse=158.144055 step=0.100000
2017/08/29 04:29:30 Saving...
2017/08/29 04:29:31 Gathering batch of experience...
2017/08/29 04:30:18 batch 975: mean=199.677419 stddev=157.666121 entropy=0.313069 frames=6167 count=31
2017/08/29 04:30:18 Training policy...
2017/08/29 04:30:23 step 0: objective=0.3903407
2017/08/29 04:30:26 step 1: objective=0.39873677
2017/08/29 04:30:28 step 2: objective=0.4034486
2017/08/29 04:30:31 step 3: objective=0.4084553
2017/08/29 04:30:33 step 4: objective=0.41288027
2017/08/29 04:30:35 step 5: objective=0.41667363
2017/08/29 04:30:38 step 6: objective=0.42047486
2017/08/29 04:30:40 step 7: objective=0.4232511
2017/08/29 04:30:40 Training value function...
2017/08/29 04:30:43 step 0: mse=139.935671 step=0.100000
2017/08/29 04:30:44 step 1: mse=137.133778 step=0.100000
2017/08/29 04:30:46 step 2: mse=135.061241 step=0.100000
2017/08/29 04:30:47 step 3: mse=133.410150 step=0.100000
2017/08/29 04:30:48 step 4: mse=132.344511 step=0.100000
2017/08/29 04:30:50 step 5: mse=130.809287 step=0.100000
2017/08/29 04:30:51 step 6: mse=129.680272 step=0.100000
2017/08/29 04:30:52 step 7: mse=128.710259 step=0.100000
2017/08/29 04:30:52 Saving...
2017/08/29 04:30:52 Gathering batch of experience...
2017/08/29 04:31:44 batch 976: mean=226.096774 stddev=159.457822 entropy=0.316696 frames=6855 count=31
2017/08/29 04:31:44 Training policy...
2017/08/29 04:31:50 step 0: objective=1.1161855
2017/08/29 04:31:53 step 1: objective=1.1212343
2017/08/29 04:31:55 step 2: objective=1.1266418
2017/08/29 04:31:58 step 3: objective=1.1298841
2017/08/29 04:32:01 step 4: objective=1.1338806
2017/08/29 04:32:04 step 5: objective=1.1385254
2017/08/29 04:32:06 step 6: objective=1.1412677
2017/08/29 04:32:09 step 7: objective=1.1444744
2017/08/29 04:32:09 Training value function...
2017/08/29 04:32:12 step 0: mse=138.120229 step=0.100000
2017/08/29 04:32:13 step 1: mse=134.975732 step=0.100000
2017/08/29 04:32:15 step 2: mse=132.660004 step=0.100000
2017/08/29 04:32:16 step 3: mse=130.223565 step=0.100000
2017/08/29 04:32:18 step 4: mse=127.994438 step=0.100000
2017/08/29 04:32:19 step 5: mse=126.106126 step=0.100000
2017/08/29 04:32:21 step 6: mse=124.617489 step=0.100000
2017/08/29 04:32:22 step 7: mse=123.295667 step=0.100000
2017/08/29 04:32:22 Saving...
2017/08/29 04:32:22 Gathering batch of experience...
2017/08/29 04:33:19 batch 977: mean=155.000000 stddev=160.627786 entropy=0.315868 frames=6081 count=42
2017/08/29 04:33:19 Training policy...
2017/08/29 04:33:24 step 0: objective=0.9587068
2017/08/29 04:33:26 step 1: objective=0.9679147
2017/08/29 04:33:29 step 2: objective=0.97184205
2017/08/29 04:33:31 step 3: objective=0.9771819
2017/08/29 04:33:33 step 4: objective=0.9830875
2017/08/29 04:33:36 step 5: objective=0.99008155
2017/08/29 04:33:38 step 6: objective=0.9937085
2017/08/29 04:33:41 step 7: objective=0.9962119
2017/08/29 04:33:41 Training value function...
2017/08/29 04:33:43 step 0: mse=172.992973 step=0.100000
2017/08/29 04:33:44 step 1: mse=170.382826 step=0.100000
2017/08/29 04:33:46 step 2: mse=167.511378 step=0.100000
2017/08/29 04:33:47 step 3: mse=165.484875 step=0.100000
2017/08/29 04:33:48 step 4: mse=163.306801 step=0.100000
2017/08/29 04:33:50 step 5: mse=161.608567 step=0.100000
2017/08/29 04:33:51 step 6: mse=160.233443 step=0.100000
2017/08/29 04:33:52 step 7: mse=158.908289 step=0.100000
2017/08/29 04:33:52 Saving...
2017/08/29 04:33:52 Gathering batch of experience...
2017/08/29 04:34:35 batch 978: mean=238.076923 stddev=137.079405 entropy=0.316064 frames=5899 count=26
2017/08/29 04:34:35 Training policy...
2017/08/29 04:34:40 step 0: objective=1.2528216
2017/08/29 04:34:42 step 1: objective=1.2587337
2017/08/29 04:34:45 step 2: objective=1.2661104
2017/08/29 04:34:47 step 3: objective=1.2702702
2017/08/29 04:34:49 step 4: objective=1.2751638
2017/08/29 04:34:52 step 5: objective=1.2811657
2017/08/29 04:34:54 step 6: objective=1.2849499
2017/08/29 04:34:56 step 7: objective=1.2901478
2017/08/29 04:34:56 Training value function...
2017/08/29 04:34:59 step 0: mse=149.624774 step=0.100000
2017/08/29 04:35:00 step 1: mse=147.115088 step=0.100000
2017/08/29 04:35:01 step 2: mse=145.020364 step=0.100000
2017/08/29 04:35:03 step 3: mse=143.169565 step=0.100000
2017/08/29 04:35:04 step 4: mse=141.497310 step=0.100000
2017/08/29 04:35:05 step 5: mse=139.982936 step=0.100000
2017/08/29 04:35:06 step 6: mse=138.294064 step=0.100000
2017/08/29 04:35:08 step 7: mse=137.092096 step=0.100000
2017/08/29 04:35:08 Saving...
2017/08/29 04:35:08 Gathering batch of experience...
2017/08/29 04:35:51 batch 979: mean=179.774194 stddev=154.228299 entropy=0.309536 frames=5326 count=31
2017/08/29 04:35:51 Training policy...
2017/08/29 04:35:55 step 0: objective=0.7732571
2017/08/29 04:35:57 step 1: objective=0.7783491
2017/08/29 04:35:59 step 2: objective=0.7846835
2017/08/29 04:36:01 step 3: objective=0.79454976
2017/08/29 04:36:04 step 4: objective=0.7981541
2017/08/29 04:36:06 step 5: objective=0.8033155
2017/08/29 04:36:08 step 6: objective=0.8063437
2017/08/29 04:36:10 step 7: objective=0.8088309
2017/08/29 04:36:10 Training value function...
2017/08/29 04:36:12 step 0: mse=152.357882 step=0.100000
2017/08/29 04:36:13 step 1: mse=149.371640 step=0.100000
2017/08/29 04:36:14 step 2: mse=146.673452 step=0.100000
2017/08/29 04:36:16 step 3: mse=144.591568 step=0.100000
2017/08/29 04:36:17 step 4: mse=142.654811 step=0.100000
2017/08/29 04:36:18 step 5: mse=141.056766 step=0.100000
2017/08/29 04:36:19 step 6: mse=139.736934 step=0.100000
2017/08/29 04:36:20 step 7: mse=139.010511 step=0.100000
2017/08/29 04:36:20 Saving...
2017/08/29 04:36:20 Gathering batch of experience...
2017/08/29 04:37:09 batch 980: mean=221.870968 stddev=170.355367 entropy=0.320604 frames=6490 count=31
2017/08/29 04:37:09 Training policy...
2017/08/29 04:37:14 step 0: objective=1.3816082
2017/08/29 04:37:17 step 1: objective=1.389208
2017/08/29 04:37:20 step 2: objective=1.3963857
2017/08/29 04:37:22 step 3: objective=1.4015213
2017/08/29 04:37:25 step 4: objective=1.4065329
2017/08/29 04:37:28 step 5: objective=1.410228
2017/08/29 04:37:30 step 6: objective=1.4133098
2017/08/29 04:37:33 step 7: objective=1.4156111
2017/08/29 04:37:33 Training value function...
2017/08/29 04:37:35 step 0: mse=168.650229 step=0.100000
2017/08/29 04:37:37 step 1: mse=163.875810 step=0.100000
2017/08/29 04:37:38 step 2: mse=160.030784 step=0.100000
2017/08/29 04:37:40 step 3: mse=156.968225 step=0.100000
2017/08/29 04:37:41 step 4: mse=154.185390 step=0.100000
2017/08/29 04:37:42 step 5: mse=151.895467 step=0.100000
2017/08/29 04:37:44 step 6: mse=149.516127 step=0.100000
2017/08/29 04:37:45 step 7: mse=147.587530 step=0.100000
2017/08/29 04:37:45 Saving...
2017/08/29 04:37:45 Gathering batch of experience...
2017/08/29 04:38:28 batch 981: mean=218.592593 stddev=155.917656 entropy=0.317702 frames=5708 count=27
2017/08/29 04:38:28 Training policy...
2017/08/29 04:38:33 step 0: objective=0.8126398
2017/08/29 04:38:35 step 1: objective=0.82010096
2017/08/29 04:38:37 step 2: objective=0.8249069
2017/08/29 04:38:40 step 3: objective=0.82822156
2017/08/29 04:38:42 step 4: objective=0.8309262
2017/08/29 04:38:44 step 5: objective=0.8335995
2017/08/29 04:38:47 step 6: objective=0.8359752
2017/08/29 04:38:49 step 7: objective=0.8388324
2017/08/29 04:38:49 Training value function...
2017/08/29 04:38:51 step 0: mse=142.584129 step=0.100000
2017/08/29 04:38:52 step 1: mse=141.338699 step=0.100000
2017/08/29 04:38:54 step 2: mse=139.985105 step=0.100000
2017/08/29 04:38:55 step 3: mse=138.467896 step=0.100000
2017/08/29 04:38:56 step 4: mse=137.357118 step=0.100000
2017/08/29 04:38:57 step 5: mse=136.489476 step=0.100000
2017/08/29 04:38:58 step 6: mse=135.657620 step=0.100000
2017/08/29 04:39:00 step 7: mse=134.902337 step=0.100000
2017/08/29 04:39:00 Saving...
2017/08/29 04:39:00 Gathering batch of experience...
2017/08/29 04:39:52 batch 982: mean=204.382353 stddev=173.607572 entropy=0.325143 frames=6595 count=34
2017/08/29 04:39:52 Training policy...
2017/08/29 04:39:58 step 0: objective=1.2466075
2017/08/29 04:40:01 step 1: objective=1.2513978
2017/08/29 04:40:03 step 2: objective=1.2576627
2017/08/29 04:40:06 step 3: objective=1.2624677
2017/08/29 04:40:08 step 4: objective=1.2654772
2017/08/29 04:40:11 step 5: objective=1.2726387
2017/08/29 04:40:14 step 6: objective=1.2752011
2017/08/29 04:40:16 step 7: objective=1.2786504
2017/08/29 04:40:16 Training value function...
2017/08/29 04:40:19 step 0: mse=170.668892 step=0.100000
2017/08/29 04:40:20 step 1: mse=166.481356 step=0.100000
2017/08/29 04:40:22 step 2: mse=162.679760 step=0.100000
2017/08/29 04:40:23 step 3: mse=159.539799 step=0.100000
2017/08/29 04:40:25 step 4: mse=157.262114 step=0.100000
2017/08/29 04:40:26 step 5: mse=155.299521 step=0.100000
2017/08/29 04:40:27 step 6: mse=153.624594 step=0.100000
2017/08/29 04:40:29 step 7: mse=152.131785 step=0.100000
2017/08/29 04:40:29 Saving...
2017/08/29 04:40:29 Gathering batch of experience...
2017/08/29 04:41:16 batch 983: mean=237.068966 stddev=181.496638 entropy=0.320025 frames=6435 count=29
2017/08/29 04:41:16 Training policy...
2017/08/29 04:41:21 step 0: objective=1.5094905
2017/08/29 04:41:24 step 1: objective=1.5163531
2017/08/29 04:41:27 step 2: objective=1.5234287
2017/08/29 04:41:29 step 3: objective=1.5278635
2017/08/29 04:41:32 step 4: objective=1.5314041
2017/08/29 04:41:34 step 5: objective=1.5337572
2017/08/29 04:41:37 step 6: objective=1.5359676
2017/08/29 04:41:39 step 7: objective=1.5384823
2017/08/29 04:41:39 Training value function...
2017/08/29 04:41:42 step 0: mse=144.861189 step=0.100000
2017/08/29 04:41:43 step 1: mse=142.739685 step=0.100000
2017/08/29 04:41:45 step 2: mse=140.415943 step=0.100000
2017/08/29 04:41:46 step 3: mse=138.794159 step=0.100000
2017/08/29 04:41:48 step 4: mse=137.215004 step=0.100000
2017/08/29 04:41:49 step 5: mse=135.677843 step=0.100000
2017/08/29 04:41:50 step 6: mse=134.092778 step=0.100000
2017/08/29 04:41:52 step 7: mse=132.929597 step=0.100000
2017/08/29 04:41:52 Saving...
2017/08/29 04:41:52 Gathering batch of experience...
2017/08/29 04:42:41 batch 984: mean=218.566667 stddev=170.179059 entropy=0.320723 frames=6153 count=30
2017/08/29 04:42:41 Training policy...
2017/08/29 04:42:46 step 0: objective=1.1196228
2017/08/29 04:42:48 step 1: objective=1.1272386
2017/08/29 04:42:51 step 2: objective=1.1368963
2017/08/29 04:42:53 step 3: objective=1.1407187
2017/08/29 04:42:56 step 4: objective=1.1450634
2017/08/29 04:42:58 step 5: objective=1.1497029
2017/08/29 04:43:01 step 6: objective=1.1529876
2017/08/29 04:43:03 step 7: objective=1.156122
2017/08/29 04:43:03 Training value function...
2017/08/29 04:43:06 step 0: mse=154.944447 step=0.100000
2017/08/29 04:43:07 step 1: mse=152.473331 step=0.100000
2017/08/29 04:43:08 step 2: mse=150.393465 step=0.100000
2017/08/29 04:43:10 step 3: mse=149.038194 step=0.100000
2017/08/29 04:43:11 step 4: mse=147.829112 step=0.100000
2017/08/29 04:43:12 step 5: mse=146.541775 step=0.100000
2017/08/29 04:43:13 step 6: mse=145.395947 step=0.100000
2017/08/29 04:43:15 step 7: mse=144.331073 step=0.100000
2017/08/29 04:43:15 Saving...
2017/08/29 04:43:15 Gathering batch of experience...
2017/08/29 04:44:13 batch 985: mean=262.862069 stddev=203.610806 entropy=0.318177 frames=7286 count=29
2017/08/29 04:44:13 Training policy...
2017/08/29 04:44:19 step 0: objective=1.0957936
2017/08/29 04:44:22 step 1: objective=1.0998731
2017/08/29 04:44:25 step 2: objective=1.103848
2017/08/29 04:44:28 step 3: objective=1.107008
2017/08/29 04:44:31 step 4: objective=1.1128999
2017/08/29 04:44:34 step 5: objective=1.1160097
2017/08/29 04:44:36 step 6: objective=1.1201816
2017/08/29 04:44:39 step 7: objective=1.1224529
2017/08/29 04:44:39 Training value function...
2017/08/29 04:44:42 step 0: mse=157.996155 step=0.100000
2017/08/29 04:44:44 step 1: mse=153.040614 step=0.100000
2017/08/29 04:44:46 step 2: mse=149.221327 step=0.100000
2017/08/29 04:44:47 step 3: mse=145.955258 step=0.100000
2017/08/29 04:44:49 step 4: mse=143.015668 step=0.100000
2017/08/29 04:44:50 step 5: mse=140.507434 step=0.100000
2017/08/29 04:44:52 step 6: mse=138.498314 step=0.100000
2017/08/29 04:44:53 step 7: mse=136.739077 step=0.100000
2017/08/29 04:44:53 Saving...
2017/08/29 04:44:53 Gathering batch of experience...
2017/08/29 04:45:37 batch 986: mean=183.500000 stddev=128.775726 entropy=0.309460 frames=5466 count=32
2017/08/29 04:45:37 Training policy...
2017/08/29 04:45:42 step 0: objective=0.68530995
2017/08/29 04:45:44 step 1: objective=0.6925568
2017/08/29 04:45:47 step 2: objective=0.69778895
2017/08/29 04:45:49 step 3: objective=0.70135087
2017/08/29 04:45:51 step 4: objective=0.7038367
2017/08/29 04:45:53 step 5: objective=0.71036434
2017/08/29 04:45:55 step 6: objective=0.7137117
2017/08/29 04:45:57 step 7: objective=0.71623135
2017/08/29 04:45:57 Training value function...
2017/08/29 04:46:00 step 0: mse=158.645428 step=0.100000
2017/08/29 04:46:01 step 1: mse=156.536736 step=0.100000
2017/08/29 04:46:02 step 2: mse=154.196737 step=0.100000
2017/08/29 04:46:03 step 3: mse=152.334692 step=0.100000
2017/08/29 04:46:04 step 4: mse=150.624439 step=0.100000
2017/08/29 04:46:06 step 5: mse=149.280455 step=0.100000
2017/08/29 04:46:07 step 6: mse=147.954653 step=0.100000
2017/08/29 04:46:08 step 7: mse=146.768560 step=0.100000
2017/08/29 04:46:08 Saving...
2017/08/29 04:46:08 Gathering batch of experience...
2017/08/29 04:46:51 batch 987: mean=200.933333 stddev=160.952981 entropy=0.312976 frames=5726 count=30
2017/08/29 04:46:51 Training policy...
2017/08/29 04:46:56 step 0: objective=1.1054757
2017/08/29 04:46:58 step 1: objective=1.111124
2017/08/29 04:47:01 step 2: objective=1.1173275
2017/08/29 04:47:03 step 3: objective=1.1214883
2017/08/29 04:47:05 step 4: objective=1.1252302
2017/08/29 04:47:08 step 5: objective=1.1330643
2017/08/29 04:47:10 step 6: objective=1.1406198
2017/08/29 04:47:12 step 7: objective=1.1447841
2017/08/29 04:47:12 Training value function...
2017/08/29 04:47:15 step 0: mse=158.928911 step=0.100000
2017/08/29 04:47:16 step 1: mse=156.251027 step=0.100000
2017/08/29 04:47:17 step 2: mse=154.037611 step=0.100000
2017/08/29 04:47:18 step 3: mse=152.309154 step=0.100000
2017/08/29 04:47:19 step 4: mse=150.563986 step=0.100000
2017/08/29 04:47:21 step 5: mse=148.850380 step=0.100000
2017/08/29 04:47:22 step 6: mse=147.639163 step=0.100000
2017/08/29 04:47:23 step 7: mse=146.439366 step=0.100000
2017/08/29 04:47:23 Saving...
2017/08/29 04:47:23 Gathering batch of experience...
2017/08/29 04:48:14 batch 988: mean=322.208333 stddev=161.062871 entropy=0.316989 frames=6944 count=24
2017/08/29 04:48:14 Training policy...
2017/08/29 04:48:20 step 0: objective=2.3342957
2017/08/29 04:48:23 step 1: objective=2.339807
2017/08/29 04:48:26 step 2: objective=2.344417
2017/08/29 04:48:28 step 3: objective=2.3479548
2017/08/29 04:48:31 step 4: objective=2.350496
2017/08/29 04:48:34 step 5: objective=2.3525162
2017/08/29 04:48:37 step 6: objective=2.3555894
2017/08/29 04:48:40 step 7: objective=2.3588245
2017/08/29 04:48:40 Training value function...
2017/08/29 04:48:43 step 0: mse=181.727837 step=0.100000
2017/08/29 04:48:44 step 1: mse=174.895695 step=0.100000
2017/08/29 04:48:45 step 2: mse=169.160425 step=0.100000
2017/08/29 04:48:47 step 3: mse=164.289031 step=0.100000
2017/08/29 04:48:48 step 4: mse=159.884890 step=0.100000
2017/08/29 04:48:50 step 5: mse=156.388481 step=0.100000
2017/08/29 04:48:51 step 6: mse=153.109757 step=0.100000
2017/08/29 04:48:53 step 7: mse=150.150663 step=0.100000
2017/08/29 04:48:53 Saving...
2017/08/29 04:48:53 Gathering batch of experience...
2017/08/29 04:49:42 batch 989: mean=188.200000 stddev=142.475823 entropy=0.313818 frames=6203 count=35
2017/08/29 04:49:42 Training policy...
2017/08/29 04:49:47 step 0: objective=0.084376365
2017/08/29 04:49:50 step 1: objective=0.09087831
2017/08/29 04:49:52 step 2: objective=0.09662231
2017/08/29 04:49:55 step 3: objective=0.101105034
2017/08/29 04:49:57 step 4: objective=0.10730817
2017/08/29 04:50:00 step 5: objective=0.11176225
2017/08/29 04:50:02 step 6: objective=0.11481196
2017/08/29 04:50:05 step 7: objective=0.11787319
2017/08/29 04:50:05 Training value function...
2017/08/29 04:50:07 step 0: mse=163.924395 step=0.100000
2017/08/29 04:50:09 step 1: mse=161.492469 step=0.100000
2017/08/29 04:50:10 step 2: mse=159.674005 step=0.100000
2017/08/29 04:50:11 step 3: mse=158.191351 step=0.100000
2017/08/29 04:50:13 step 4: mse=156.659026 step=0.100000
2017/08/29 04:50:14 step 5: mse=155.636058 step=0.100000
2017/08/29 04:50:15 step 6: mse=154.622693 step=0.100000
2017/08/29 04:50:17 step 7: mse=153.478194 step=0.100000
2017/08/29 04:50:17 Saving...
2017/08/29 04:50:17 Gathering batch of experience...
2017/08/29 04:51:04 batch 990: mean=249.607143 stddev=188.117239 entropy=0.319711 frames=6632 count=28
2017/08/29 04:51:04 Training policy...
2017/08/29 04:51:09 step 0: objective=1.5310141
2017/08/29 04:51:12 step 1: objective=1.5352669
2017/08/29 04:51:15 step 2: objective=1.5421855
2017/08/29 04:51:17 step 3: objective=1.546894
2017/08/29 04:51:20 step 4: objective=1.5511712
2017/08/29 04:51:23 step 5: objective=1.5571138
2017/08/29 04:51:25 step 6: objective=1.5608065
2017/08/29 04:51:28 step 7: objective=1.5646095
2017/08/29 04:51:28 Training value function...
2017/08/29 04:51:31 step 0: mse=169.118787 step=0.100000
2017/08/29 04:51:32 step 1: mse=163.491989 step=0.100000
2017/08/29 04:51:34 step 2: mse=158.422361 step=0.100000
2017/08/29 04:51:35 step 3: mse=154.142022 step=0.100000
2017/08/29 04:51:36 step 4: mse=150.835633 step=0.100000
2017/08/29 04:51:38 step 5: mse=147.849946 step=0.100000
2017/08/29 04:51:39 step 6: mse=145.355049 step=0.100000
2017/08/29 04:51:41 step 7: mse=143.462886 step=0.100000
2017/08/29 04:51:41 Saving...
2017/08/29 04:51:41 Gathering batch of experience...
2017/08/29 04:52:24 batch 991: mean=176.812500 stddev=130.735763 entropy=0.313400 frames=5591 count=32
2017/08/29 04:52:24 Training policy...
2017/08/29 04:52:29 step 0: objective=-0.11378579
2017/08/29 04:52:31 step 1: objective=-0.11022056
2017/08/29 04:52:33 step 2: objective=-0.105583765
2017/08/29 04:52:36 step 3: objective=-0.0964688
2017/08/29 04:52:38 step 4: objective=-0.09292467
2017/08/29 04:52:40 step 5: objective=-0.08695733
2017/08/29 04:52:42 step 6: objective=-0.08279475
2017/08/29 04:52:45 step 7: objective=-0.080466926
2017/08/29 04:52:45 Training value function...
2017/08/29 04:52:47 step 0: mse=140.103945 step=0.100000
2017/08/29 04:52:48 step 1: mse=138.562425 step=0.100000
2017/08/29 04:52:49 step 2: mse=137.217681 step=0.100000
2017/08/29 04:52:51 step 3: mse=136.475770 step=0.100000
2017/08/29 04:52:52 step 4: mse=135.672617 step=0.100000
2017/08/29 04:52:53 step 5: mse=134.858269 step=0.100000
2017/08/29 04:52:54 step 6: mse=134.261709 step=0.100000
2017/08/29 04:52:55 step 7: mse=133.660517 step=0.100000
2017/08/29 04:52:55 Saving...
2017/08/29 04:52:55 Gathering batch of experience...
2017/08/29 04:53:46 batch 992: mean=196.416667 stddev=166.345587 entropy=0.315725 frames=6581 count=36
2017/08/29 04:53:46 Training policy...
2017/08/29 04:53:52 step 0: objective=1.5586157
2017/08/29 04:53:55 step 1: objective=1.5636493
2017/08/29 04:53:57 step 2: objective=1.5704064
2017/08/29 04:54:00 step 3: objective=1.574865
2017/08/29 04:54:03 step 4: objective=1.5786117
2017/08/29 04:54:05 step 5: objective=1.5819992
2017/08/29 04:54:08 step 6: objective=1.5861981
2017/08/29 04:54:11 step 7: objective=1.589882
2017/08/29 04:54:11 Training value function...
2017/08/29 04:54:13 step 0: mse=171.491670 step=0.100000
2017/08/29 04:54:15 step 1: mse=166.802675 step=0.100000
2017/08/29 04:54:16 step 2: mse=163.160929 step=0.100000
2017/08/29 04:54:17 step 3: mse=160.116762 step=0.100000
2017/08/29 04:54:19 step 4: mse=157.565026 step=0.100000
2017/08/29 04:54:20 step 5: mse=154.821091 step=0.100000
2017/08/29 04:54:22 step 6: mse=152.292104 step=0.100000
2017/08/29 04:54:23 step 7: mse=150.279230 step=0.100000
2017/08/29 04:54:23 Saving...
2017/08/29 04:54:23 Gathering batch of experience...
2017/08/29 04:55:10 batch 993: mean=209.645161 stddev=178.303574 entropy=0.315969 frames=5969 count=31
2017/08/29 04:55:10 Training policy...
2017/08/29 04:55:15 step 0: objective=1.5269169
2017/08/29 04:55:17 step 1: objective=1.5344567
2017/08/29 04:55:20 step 2: objective=1.5396326
2017/08/29 04:55:22 step 3: objective=1.544725
2017/08/29 04:55:24 step 4: objective=1.5481445
2017/08/29 04:55:27 step 5: objective=1.5523304
2017/08/29 04:55:29 step 6: objective=1.5556288
2017/08/29 04:55:32 step 7: objective=1.5590739
2017/08/29 04:55:32 Training value function...
2017/08/29 04:55:34 step 0: mse=180.902437 step=0.100000
2017/08/29 04:55:35 step 1: mse=177.442001 step=0.100000
2017/08/29 04:55:37 step 2: mse=174.316633 step=0.100000
2017/08/29 04:55:38 step 3: mse=171.111831 step=0.100000
2017/08/29 04:55:39 step 4: mse=168.461426 step=0.100000
2017/08/29 04:55:40 step 5: mse=165.768700 step=0.100000
2017/08/29 04:55:42 step 6: mse=164.094010 step=0.100000
2017/08/29 04:55:43 step 7: mse=162.404527 step=0.100000
2017/08/29 04:55:43 Saving...
2017/08/29 04:55:43 Gathering batch of experience...
2017/08/29 04:56:34 batch 994: mean=252.137931 stddev=188.255462 entropy=0.320254 frames=6926 count=29
2017/08/29 04:56:34 Training policy...
2017/08/29 04:56:40 step 0: objective=1.250304
2017/08/29 04:56:43 step 1: objective=1.2564033
2017/08/29 04:56:46 step 2: objective=1.2620194
2017/08/29 04:56:48 step 3: objective=1.2665381
2017/08/29 04:56:51 step 4: objective=1.271028
2017/08/29 04:56:54 step 5: objective=1.2737584
2017/08/29 04:56:57 step 6: objective=1.2754682
2017/08/29 04:56:59 step 7: objective=1.2791991
2017/08/29 04:56:59 Training value function...
2017/08/29 04:57:02 step 0: mse=132.782400 step=0.100000
2017/08/29 04:57:04 step 1: mse=130.511600 step=0.100000
2017/08/29 04:57:05 step 2: mse=128.747852 step=0.100000
2017/08/29 04:57:07 step 3: mse=127.126691 step=0.100000
2017/08/29 04:57:08 step 4: mse=125.507967 step=0.100000
2017/08/29 04:57:10 step 5: mse=124.147207 step=0.100000
2017/08/29 04:57:11 step 6: mse=123.165587 step=0.100000
2017/08/29 04:57:13 step 7: mse=122.129826 step=0.100000
2017/08/29 04:57:13 Saving...
2017/08/29 04:57:13 Gathering batch of experience...
2017/08/29 04:58:05 batch 995: mean=268.137931 stddev=215.170297 entropy=0.317747 frames=7358 count=29
2017/08/29 04:58:05 Training policy...
2017/08/29 04:58:11 step 0: objective=1.3827559
2017/08/29 04:58:14 step 1: objective=1.388122
2017/08/29 04:58:17 step 2: objective=1.392358
2017/08/29 04:58:20 step 3: objective=1.3954208
2017/08/29 04:58:23 step 4: objective=1.3986906
2017/08/29 04:58:26 step 5: objective=1.400594
2017/08/29 04:58:29 step 6: objective=1.4023087
2017/08/29 04:58:32 step 7: objective=1.404662
2017/08/29 04:58:32 Training value function...
2017/08/29 04:58:35 step 0: mse=162.094345 step=0.100000
2017/08/29 04:58:37 step 1: mse=158.044194 step=0.100000
2017/08/29 04:58:39 step 2: mse=154.386118 step=0.100000
2017/08/29 04:58:40 step 3: mse=151.646442 step=0.100000
2017/08/29 04:58:42 step 4: mse=149.109568 step=0.100000
2017/08/29 04:58:43 step 5: mse=146.660332 step=0.100000
2017/08/29 04:58:45 step 6: mse=145.006643 step=0.100000
2017/08/29 04:58:46 step 7: mse=143.462408 step=0.100000
2017/08/29 04:58:46 Saving...
2017/08/29 04:58:47 Gathering batch of experience...
2017/08/29 04:59:38 batch 996: mean=223.500000 stddev=210.727905 entropy=0.318645 frames=5818 count=28
2017/08/29 04:59:38 Training policy...
2017/08/29 04:59:43 step 0: objective=1.0937021
2017/08/29 04:59:46 step 1: objective=1.1027609
2017/08/29 04:59:48 step 2: objective=1.1110958
2017/08/29 04:59:50 step 3: objective=1.1152577
2017/08/29 04:59:53 step 4: objective=1.119394
2017/08/29 04:59:55 step 5: objective=1.1247123
2017/08/29 04:59:57 step 6: objective=1.1281133
2017/08/29 05:00:00 step 7: objective=1.1331224
2017/08/29 05:00:00 Training value function...
2017/08/29 05:00:02 step 0: mse=178.838608 step=0.100000
2017/08/29 05:00:03 step 1: mse=173.838642 step=0.100000
2017/08/29 05:00:05 step 2: mse=169.353574 step=0.100000
2017/08/29 05:00:06 step 3: mse=165.687897 step=0.100000
2017/08/29 05:00:07 step 4: mse=162.913232 step=0.100000
2017/08/29 05:00:08 step 5: mse=160.004601 step=0.100000
2017/08/29 05:00:10 step 6: mse=157.721250 step=0.100000
2017/08/29 05:00:11 step 7: mse=155.725566 step=0.100000
2017/08/29 05:00:11 Saving...
2017/08/29 05:00:11 Gathering batch of experience...
2017/08/29 05:00:57 batch 997: mean=149.921053 stddev=122.871002 entropy=0.316023 frames=5512 count=38
2017/08/29 05:00:57 Training policy...
2017/08/29 05:01:01 step 0: objective=-0.16403165
2017/08/29 05:01:04 step 1: objective=-0.15251747
2017/08/29 05:01:06 step 2: objective=-0.14545646
2017/08/29 05:01:08 step 3: objective=-0.14141163
2017/08/29 05:01:10 step 4: objective=-0.13523762
2017/08/29 05:01:12 step 5: objective=-0.12952392
2017/08/29 05:01:15 step 6: objective=-0.12395252
2017/08/29 05:01:17 step 7: objective=-0.12009319
2017/08/29 05:01:17 Training value function...
2017/08/29 05:01:19 step 0: mse=191.968219 step=0.100000
2017/08/29 05:01:20 step 1: mse=187.430735 step=0.100000
2017/08/29 05:01:21 step 2: mse=183.319989 step=0.100000
2017/08/29 05:01:23 step 3: mse=180.525330 step=0.100000
2017/08/29 05:01:24 step 4: mse=178.086498 step=0.100000
2017/08/29 05:01:25 step 5: mse=175.782817 step=0.100000
2017/08/29 05:01:26 step 6: mse=173.748875 step=0.100000
2017/08/29 05:01:27 step 7: mse=172.044474 step=0.100000
2017/08/29 05:01:27 Saving...
2017/08/29 05:01:27 Gathering batch of experience...
2017/08/29 05:02:09 batch 998: mean=196.066667 stddev=184.823147 entropy=0.320711 frames=5605 count=30
2017/08/29 05:02:09 Training policy...
2017/08/29 05:02:14 step 0: objective=1.4514405
2017/08/29 05:02:17 step 1: objective=1.457901
2017/08/29 05:02:19 step 2: objective=1.4634908
2017/08/29 05:02:21 step 3: objective=1.4710058
2017/08/29 05:02:23 step 4: objective=1.4762198
2017/08/29 05:02:26 step 5: objective=1.4821635
2017/08/29 05:02:28 step 6: objective=1.4865879
2017/08/29 05:02:30 step 7: objective=1.4926107
2017/08/29 05:02:30 Training value function...
2017/08/29 05:02:33 step 0: mse=188.335326 step=0.100000
2017/08/29 05:02:34 step 1: mse=183.467786 step=0.100000
2017/08/29 05:02:35 step 2: mse=179.108083 step=0.100000
2017/08/29 05:02:36 step 3: mse=175.302447 step=0.100000
2017/08/29 05:02:37 step 4: mse=172.617666 step=0.100000
2017/08/29 05:02:38 step 5: mse=169.999751 step=0.100000
2017/08/29 05:02:40 step 6: mse=167.192270 step=0.100000
2017/08/29 05:02:41 step 7: mse=165.182599 step=0.100000
2017/08/29 05:02:41 Saving...
2017/08/29 05:02:41 Gathering batch of experience...
2017/08/29 05:03:29 batch 999: mean=201.066667 stddev=169.706204 entropy=0.314812 frames=5627 count=30
2017/08/29 05:03:29 Training policy...
2017/08/29 05:03:34 step 0: objective=1.3214339
2017/08/29 05:03:36 step 1: objective=1.3263879
2017/08/29 05:03:38 step 2: objective=1.3336174
2017/08/29 05:03:40 step 3: objective=1.3409327
2017/08/29 05:03:43 step 4: objective=1.3451378
2017/08/29 05:03:45 step 5: objective=1.3489056
2017/08/29 05:03:47 step 6: objective=1.3537874
2017/08/29 05:03:50 step 7: objective=1.3582076
2017/08/29 05:03:50 Training value function...
2017/08/29 05:03:52 step 0: mse=167.673132 step=0.100000
2017/08/29 05:03:53 step 1: mse=164.187188 step=0.100000
2017/08/29 05:03:54 step 2: mse=161.201424 step=0.100000
2017/08/29 05:03:56 step 3: mse=158.374385 step=0.100000
2017/08/29 05:03:57 step 4: mse=156.339638 step=0.100000
2017/08/29 05:03:58 step 5: mse=154.255106 step=0.100000
2017/08/29 05:03:59 step 6: mse=152.254562 step=0.100000
2017/08/29 05:04:00 step 7: mse=150.565852 step=0.100000
2017/08/29 05:04:00 Saving...
2017/08/29 05:04:00 Gathering batch of experience...
2017/08/29 05:04:46 batch 1000: mean=164.944444 stddev=118.950023 entropy=0.312612 frames=5758 count=36
2017/08/29 05:04:46 Training policy...
2017/08/29 05:04:51 step 0: objective=0.37807274
2017/08/29 05:04:53 step 1: objective=0.38640067
2017/08/29 05:04:56 step 2: objective=0.39151236
2017/08/29 05:04:58 step 3: objective=0.39783767
2017/08/29 05:05:00 step 4: objective=0.40205628
2017/08/29 05:05:03 step 5: objective=0.40473077
2017/08/29 05:05:05 step 6: objective=0.40841326
2017/08/29 05:05:07 step 7: objective=0.4117888
2017/08/29 05:05:07 Training value function...
2017/08/29 05:05:10 step 0: mse=138.097702 step=0.100000
2017/08/29 05:05:11 step 1: mse=135.459588 step=0.100000
2017/08/29 05:05:12 step 2: mse=133.019345 step=0.100000
2017/08/29 05:05:13 step 3: mse=130.919835 step=0.100000
2017/08/29 05:05:15 step 4: mse=129.153551 step=0.100000
2017/08/29 05:05:16 step 5: mse=127.864159 step=0.100000
2017/08/29 05:05:17 step 6: mse=126.770575 step=0.100000
2017/08/29 05:05:18 step 7: mse=125.813921 step=0.100000
2017/08/29 05:05:18 Saving...
2017/08/29 05:05:18 Gathering batch of experience...
2017/08/29 05:06:04 batch 1001: mean=216.551724 stddev=146.121486 entropy=0.313346 frames=5957 count=29
2017/08/29 05:06:04 Training policy...
2017/08/29 05:06:09 step 0: objective=1.4838798
2017/08/29 05:06:11 step 1: objective=1.4894549
2017/08/29 05:06:14 step 2: objective=1.4941864
2017/08/29 05:06:16 step 3: objective=1.4982882
2017/08/29 05:06:19 step 4: objective=1.5031911
2017/08/29 05:06:21 step 5: objective=1.5067424
2017/08/29 05:06:24 step 6: objective=1.5089624
2017/08/29 05:06:26 step 7: objective=1.5116018
2017/08/29 05:06:26 Training value function...
2017/08/29 05:06:28 step 0: mse=168.366960 step=0.100000
2017/08/29 05:06:30 step 1: mse=163.974479 step=0.100000
2017/08/29 05:06:31 step 2: mse=160.401412 step=0.100000
2017/08/29 05:06:32 step 3: mse=157.485159 step=0.100000
2017/08/29 05:06:34 step 4: mse=154.743628 step=0.100000
2017/08/29 05:06:35 step 5: mse=152.318856 step=0.100000
2017/08/29 05:06:36 step 6: mse=150.153773 step=0.100000
2017/08/29 05:06:37 step 7: mse=148.232523 step=0.100000
2017/08/29 05:06:37 Saving...
2017/08/29 05:06:37 Gathering batch of experience...
2017/08/29 05:07:23 batch 1002: mean=231.428571 stddev=187.477128 entropy=0.310242 frames=5882 count=28
2017/08/29 05:07:23 Training policy...
2017/08/29 05:07:28 step 0: objective=1.9717481
2017/08/29 05:07:30 step 1: objective=1.9792453
2017/08/29 05:07:32 step 2: objective=1.9847581
2017/08/29 05:07:35 step 3: objective=1.9916917
2017/08/29 05:07:37 step 4: objective=1.9961653
2017/08/29 05:07:40 step 5: objective=1.9990767
2017/08/29 05:07:42 step 6: objective=2.0053935
2017/08/29 05:07:44 step 7: objective=2.0088918
2017/08/29 05:07:44 Training value function...
2017/08/29 05:07:47 step 0: mse=171.900006 step=0.100000
2017/08/29 05:07:48 step 1: mse=167.469666 step=0.100000
2017/08/29 05:07:49 step 2: mse=163.292093 step=0.100000
2017/08/29 05:07:50 step 3: mse=159.710726 step=0.100000
2017/08/29 05:07:52 step 4: mse=156.378121 step=0.100000
2017/08/29 05:07:53 step 5: mse=153.634521 step=0.100000
2017/08/29 05:07:54 step 6: mse=151.574247 step=0.100000
2017/08/29 05:07:55 step 7: mse=149.372014 step=0.100000
2017/08/29 05:07:55 Saving...
2017/08/29 05:07:56 Gathering batch of experience...
2017/08/29 05:08:41 batch 1003: mean=185.484848 stddev=138.630777 entropy=0.314152 frames=5916 count=33
2017/08/29 05:08:41 Training policy...
2017/08/29 05:08:46 step 0: objective=0.24728265
2017/08/29 05:08:48 step 1: objective=0.25277302
2017/08/29 05:08:50 step 2: objective=0.25838566
2017/08/29 05:08:53 step 3: objective=0.2641811
2017/08/29 05:08:55 step 4: objective=0.26647502
2017/08/29 05:08:58 step 5: objective=0.27018926
2017/08/29 05:09:00 step 6: objective=0.2738495
2017/08/29 05:09:02 step 7: objective=0.2779532
2017/08/29 05:09:02 Training value function...
2017/08/29 05:09:05 step 0: mse=127.983132 step=0.100000
2017/08/29 05:09:06 step 1: mse=126.026135 step=0.100000
2017/08/29 05:09:08 step 2: mse=124.432889 step=0.100000
2017/08/29 05:09:09 step 3: mse=123.097348 step=0.100000
2017/08/29 05:09:10 step 4: mse=122.073274 step=0.100000
2017/08/29 05:09:11 step 5: mse=121.163869 step=0.100000
2017/08/29 05:09:13 step 6: mse=120.542863 step=0.100000
2017/08/29 05:09:14 step 7: mse=119.882798 step=0.100000
2017/08/29 05:09:14 Saving...
2017/08/29 05:09:14 Gathering batch of experience...
2017/08/29 05:10:04 batch 1004: mean=241.000000 stddev=160.360754 entropy=0.316770 frames=6231 count=28
2017/08/29 05:10:04 Training policy...
2017/08/29 05:10:09 step 0: objective=1.7141964
2017/08/29 05:10:12 step 1: objective=1.7177526
2017/08/29 05:10:14 step 2: objective=1.723874
2017/08/29 05:10:17 step 3: objective=1.7275007
2017/08/29 05:10:19 step 4: objective=1.7319826
2017/08/29 05:10:22 step 5: objective=1.7357299
2017/08/29 05:10:24 step 6: objective=1.7395512
2017/08/29 05:10:27 step 7: objective=1.7424735
2017/08/29 05:10:27 Training value function...
2017/08/29 05:10:29 step 0: mse=171.804069 step=0.100000
2017/08/29 05:10:31 step 1: mse=168.351019 step=0.100000
2017/08/29 05:10:32 step 2: mse=165.163687 step=0.100000
2017/08/29 05:10:33 step 3: mse=162.855961 step=0.100000
2017/08/29 05:10:35 step 4: mse=160.834744 step=0.100000
2017/08/29 05:10:36 step 5: mse=158.217455 step=0.100000
2017/08/29 05:10:37 step 6: mse=156.068559 step=0.100000
2017/08/29 05:10:39 step 7: mse=154.201256 step=0.100000
2017/08/29 05:10:39 Saving...
2017/08/29 05:10:39 Gathering batch of experience...
2017/08/29 05:11:27 batch 1005: mean=206.387097 stddev=174.590891 entropy=0.315000 frames=6148 count=31
2017/08/29 05:11:27 Training policy...
2017/08/29 05:11:32 step 0: objective=0.8313126
2017/08/29 05:11:34 step 1: objective=0.8357204
2017/08/29 05:11:37 step 2: objective=0.83984774
2017/08/29 05:11:39 step 3: objective=0.8431503
2017/08/29 05:11:42 step 4: objective=0.8468159
2017/08/29 05:11:44 step 5: objective=0.84985715
2017/08/29 05:11:47 step 6: objective=0.8530669
2017/08/29 05:11:49 step 7: objective=0.8585351
2017/08/29 05:11:49 Training value function...
2017/08/29 05:11:52 step 0: mse=143.597905 step=0.100000
2017/08/29 05:11:53 step 1: mse=141.035119 step=0.100000
2017/08/29 05:11:55 step 2: mse=139.088800 step=0.100000
2017/08/29 05:11:56 step 3: mse=137.110588 step=0.100000
2017/08/29 05:11:57 step 4: mse=135.269862 step=0.100000
2017/08/29 05:11:59 step 5: mse=133.555534 step=0.100000
2017/08/29 05:12:00 step 6: mse=132.036230 step=0.100000
2017/08/29 05:12:01 step 7: mse=130.642874 step=0.100000
2017/08/29 05:12:01 Saving...
2017/08/29 05:12:01 Gathering batch of experience...
2017/08/29 05:12:51 batch 1006: mean=220.741935 stddev=187.026817 entropy=0.315686 frames=6463 count=31
2017/08/29 05:12:51 Training policy...
2017/08/29 05:12:56 step 0: objective=1.206633
2017/08/29 05:12:59 step 1: objective=1.2106994
2017/08/29 05:13:02 step 2: objective=1.2151626
2017/08/29 05:13:04 step 3: objective=1.2194262
2017/08/29 05:13:07 step 4: objective=1.2241882
2017/08/29 05:13:10 step 5: objective=1.2288002
2017/08/29 05:13:12 step 6: objective=1.2313321
2017/08/29 05:13:15 step 7: objective=1.2342201
2017/08/29 05:13:15 Training value function...
2017/08/29 05:13:18 step 0: mse=164.098835 step=0.100000
2017/08/29 05:13:19 step 1: mse=160.129649 step=0.100000
2017/08/29 05:13:20 step 2: mse=156.720820 step=0.100000
2017/08/29 05:13:22 step 3: mse=153.959608 step=0.100000
2017/08/29 05:13:23 step 4: mse=151.479763 step=0.100000
2017/08/29 05:13:24 step 5: mse=149.211108 step=0.100000
2017/08/29 05:13:26 step 6: mse=147.354668 step=0.100000
2017/08/29 05:13:27 step 7: mse=145.695844 step=0.100000
2017/08/29 05:13:27 Saving...
2017/08/29 05:13:27 Gathering batch of experience...
2017/08/29 05:14:10 batch 1007: mean=229.423077 stddev=173.699159 entropy=0.312351 frames=5564 count=26
2017/08/29 05:14:10 Training policy...
2017/08/29 05:14:14 step 0: objective=1.3998857
2017/08/29 05:14:17 step 1: objective=1.4072099
2017/08/29 05:14:19 step 2: objective=1.4143813
2017/08/29 05:14:21 step 3: objective=1.419357
2017/08/29 05:14:23 step 4: objective=1.4251015
2017/08/29 05:14:26 step 5: objective=1.4295577
2017/08/29 05:14:28 step 6: objective=1.4327629
2017/08/29 05:14:30 step 7: objective=1.4378468
2017/08/29 05:14:30 Training value function...
2017/08/29 05:14:33 step 0: mse=184.984654 step=0.100000
2017/08/29 05:14:34 step 1: mse=180.043705 step=0.100000
2017/08/29 05:14:35 step 2: mse=175.299018 step=0.100000
2017/08/29 05:14:36 step 3: mse=170.730501 step=0.100000
2017/08/29 05:14:37 step 4: mse=165.824505 step=0.100000
2017/08/29 05:14:39 step 5: mse=161.419643 step=0.100000
2017/08/29 05:14:40 step 6: mse=158.997440 step=0.100000
2017/08/29 05:14:41 step 7: mse=156.831406 step=0.100000
2017/08/29 05:14:41 Saving...
2017/08/29 05:14:41 Gathering batch of experience...
2017/08/29 05:15:27 batch 1008: mean=198.939394 stddev=160.035780 entropy=0.312224 frames=6153 count=33
2017/08/29 05:15:27 Training policy...
2017/08/29 05:15:33 step 0: objective=0.66207767
2017/08/29 05:15:35 step 1: objective=0.6722708
2017/08/29 05:15:38 step 2: objective=0.67664677
2017/08/29 05:15:40 step 3: objective=0.6794045
2017/08/29 05:15:43 step 4: objective=0.6839716
2017/08/29 05:15:45 step 5: objective=0.68839246
2017/08/29 05:15:48 step 6: objective=0.69034487
2017/08/29 05:15:50 step 7: objective=0.6938378
2017/08/29 05:15:50 Training value function...
2017/08/29 05:15:53 step 0: mse=157.624417 step=0.100000
2017/08/29 05:15:54 step 1: mse=154.370459 step=0.100000
2017/08/29 05:15:56 step 2: mse=151.778992 step=0.100000
2017/08/29 05:15:57 step 3: mse=149.608687 step=0.100000
2017/08/29 05:15:58 step 4: mse=147.794208 step=0.100000
2017/08/29 05:15:59 step 5: mse=145.837505 step=0.100000
2017/08/29 05:16:01 step 6: mse=144.241724 step=0.100000
2017/08/29 05:16:02 step 7: mse=143.155317 step=0.100000
2017/08/29 05:16:02 Saving...
2017/08/29 05:16:02 Gathering batch of experience...
2017/08/29 05:16:51 batch 1009: mean=224.366667 stddev=190.946499 entropy=0.314430 frames=6300 count=30
2017/08/29 05:16:51 Training policy...
2017/08/29 05:16:56 step 0: objective=1.3420957
2017/08/29 05:16:59 step 1: objective=1.3480779
2017/08/29 05:17:01 step 2: objective=1.35291
2017/08/29 05:17:04 step 3: objective=1.3599285
2017/08/29 05:17:06 step 4: objective=1.3668629
2017/08/29 05:17:09 step 5: objective=1.3710505
2017/08/29 05:17:12 step 6: objective=1.3756493
2017/08/29 05:17:14 step 7: objective=1.3787575
2017/08/29 05:17:14 Training value function...
2017/08/29 05:17:17 step 0: mse=167.776013 step=0.100000
2017/08/29 05:17:18 step 1: mse=164.330127 step=0.100000
2017/08/29 05:17:19 step 2: mse=161.202559 step=0.100000
2017/08/29 05:17:21 step 3: mse=158.709271 step=0.100000
2017/08/29 05:17:22 step 4: mse=156.460763 step=0.100000
2017/08/29 05:17:23 step 5: mse=153.910245 step=0.100000
2017/08/29 05:17:25 step 6: mse=151.810303 step=0.100000
2017/08/29 05:17:26 step 7: mse=149.908067 step=0.100000
2017/08/29 05:17:26 Saving...
2017/08/29 05:17:26 Gathering batch of experience...
2017/08/29 05:18:19 batch 1010: mean=205.735294 stddev=184.576671 entropy=0.320583 frames=6486 count=34
2017/08/29 05:18:19 Training policy...
2017/08/29 05:18:25 step 0: objective=1.0527437
2017/08/29 05:18:27 step 1: objective=1.0565639
2017/08/29 05:18:30 step 2: objective=1.0626899
2017/08/29 05:18:33 step 3: objective=1.0661616
2017/08/29 05:18:35 step 4: objective=1.0701245
2017/08/29 05:18:38 step 5: objective=1.0726416
2017/08/29 05:18:41 step 6: objective=1.0751343
2017/08/29 05:18:43 step 7: objective=1.0805925
2017/08/29 05:18:43 Training value function...
2017/08/29 05:18:46 step 0: mse=155.508984 step=0.100000
2017/08/29 05:18:47 step 1: mse=153.547118 step=0.100000
2017/08/29 05:18:49 step 2: mse=152.024182 step=0.100000
2017/08/29 05:18:50 step 3: mse=150.779462 step=0.100000
2017/08/29 05:18:51 step 4: mse=149.222443 step=0.100000
2017/08/29 05:18:53 step 5: mse=148.449971 step=0.100000
2017/08/29 05:18:54 step 6: mse=147.379750 step=0.100000
2017/08/29 05:18:56 step 7: mse=146.553054 step=0.100000
2017/08/29 05:18:56 Saving...
2017/08/29 05:18:56 Gathering batch of experience...
2017/08/29 05:19:45 batch 1011: mean=251.178571 stddev=172.231998 entropy=0.317882 frames=6672 count=28
2017/08/29 05:19:45 Training policy...
2017/08/29 05:19:51 step 0: objective=1.0256128
2017/08/29 05:19:54 step 1: objective=1.0303016
2017/08/29 05:19:56 step 2: objective=1.033794
2017/08/29 05:19:59 step 3: objective=1.0374998
2017/08/29 05:20:02 step 4: objective=1.0417244
2017/08/29 05:20:05 step 5: objective=1.045418
2017/08/29 05:20:07 step 6: objective=1.0482134
2017/08/29 05:20:10 step 7: objective=1.052737
2017/08/29 05:20:10 Training value function...
2017/08/29 05:20:13 step 0: mse=160.624132 step=0.100000
2017/08/29 05:20:14 step 1: mse=157.959036 step=0.100000
2017/08/29 05:20:16 step 2: mse=155.734277 step=0.100000
2017/08/29 05:20:17 step 3: mse=153.978775 step=0.100000
2017/08/29 05:20:18 step 4: mse=152.388796 step=0.100000
2017/08/29 05:20:20 step 5: mse=150.658541 step=0.100000
2017/08/29 05:20:21 step 6: mse=149.420105 step=0.100000
2017/08/29 05:20:23 step 7: mse=148.131279 step=0.100000
2017/08/29 05:20:23 Saving...
2017/08/29 05:20:23 Gathering batch of experience...
2017/08/29 05:21:08 batch 1012: mean=178.281250 stddev=137.332679 entropy=0.315261 frames=5890 count=32
2017/08/29 05:21:08 Training policy...
2017/08/29 05:21:13 step 0: objective=-0.45380738
2017/08/29 05:21:16 step 1: objective=-0.44266135
2017/08/29 05:21:18 step 2: objective=-0.43619856
2017/08/29 05:21:21 step 3: objective=-0.43133676
2017/08/29 05:21:23 step 4: objective=-0.42711627
2017/08/29 05:21:26 step 5: objective=-0.4229555
2017/08/29 05:21:28 step 6: objective=-0.41853082
2017/08/29 05:21:30 step 7: objective=-0.415534
2017/08/29 05:21:30 Training value function...
2017/08/29 05:21:33 step 0: mse=120.130120 step=0.100000
2017/08/29 05:21:34 step 1: mse=118.412725 step=0.100000
2017/08/29 05:21:35 step 2: mse=117.029819 step=0.100000
2017/08/29 05:21:37 step 3: mse=115.792789 step=0.100000
2017/08/29 05:21:38 step 4: mse=115.005494 step=0.100000
2017/08/29 05:21:39 step 5: mse=114.366189 step=0.100000
2017/08/29 05:21:40 step 6: mse=113.679146 step=0.100000
2017/08/29 05:21:42 step 7: mse=113.132268 step=0.100000
2017/08/29 05:21:42 Saving...
2017/08/29 05:21:42 Gathering batch of experience...
2017/08/29 05:22:30 batch 1013: mean=176.176471 stddev=161.556122 entropy=0.313902 frames=5889 count=34
2017/08/29 05:22:30 Training policy...
2017/08/29 05:22:35 step 0: objective=0.9384776
2017/08/29 05:22:38 step 1: objective=0.9427102
2017/08/29 05:22:40 step 2: objective=0.94885194
2017/08/29 05:22:42 step 3: objective=0.9525027
2017/08/29 05:22:45 step 4: objective=0.95718163
2017/08/29 05:22:47 step 5: objective=0.9641416
2017/08/29 05:22:50 step 6: objective=0.9669324
2017/08/29 05:22:52 step 7: objective=0.9716729
2017/08/29 05:22:52 Training value function...
2017/08/29 05:22:55 step 0: mse=157.734732 step=0.100000
2017/08/29 05:22:56 step 1: mse=156.304488 step=0.100000
2017/08/29 05:22:57 step 2: mse=154.758269 step=0.100000
2017/08/29 05:22:58 step 3: mse=153.778665 step=0.100000
2017/08/29 05:23:00 step 4: mse=152.175806 step=0.100000
2017/08/29 05:23:01 step 5: mse=150.875746 step=0.100000
2017/08/29 05:23:02 step 6: mse=150.188983 step=0.100000
2017/08/29 05:23:03 step 7: mse=149.349698 step=0.100000
2017/08/29 05:23:03 Saving...
2017/08/29 05:23:03 Gathering batch of experience...
2017/08/29 05:23:58 batch 1014: mean=244.096774 stddev=167.442114 entropy=0.313902 frames=6759 count=31
2017/08/29 05:23:58 Training policy...
2017/08/29 05:24:04 step 0: objective=2.4718301
2017/08/29 05:24:07 step 1: objective=2.4784606
2017/08/29 05:24:09 step 2: objective=2.4819813
2017/08/29 05:24:12 step 3: objective=2.4847088
2017/08/29 05:24:15 step 4: objective=2.4870903
2017/08/29 05:24:18 step 5: objective=2.4895253
2017/08/29 05:24:20 step 6: objective=2.4928706
2017/08/29 05:24:23 step 7: objective=2.4965227
2017/08/29 05:24:23 Training value function...
2017/08/29 05:24:26 step 0: mse=192.190008 step=0.100000
2017/08/29 05:24:27 step 1: mse=185.225775 step=0.100000
2017/08/29 05:24:29 step 2: mse=179.498968 step=0.100000
2017/08/29 05:24:30 step 3: mse=174.800929 step=0.100000
2017/08/29 05:24:32 step 4: mse=170.454019 step=0.100000
2017/08/29 05:24:33 step 5: mse=166.759602 step=0.100000
2017/08/29 05:24:35 step 6: mse=163.657433 step=0.100000
2017/08/29 05:24:36 step 7: mse=160.968293 step=0.100000
2017/08/29 05:24:36 Saving...
2017/08/29 05:24:36 Gathering batch of experience...
2017/08/29 05:25:22 batch 1015: mean=221.321429 stddev=173.480146 entropy=0.315483 frames=6009 count=28
2017/08/29 05:25:22 Training policy...
2017/08/29 05:25:28 step 0: objective=0.62789255
2017/08/29 05:25:30 step 1: objective=0.6319088
2017/08/29 05:25:33 step 2: objective=0.6399294
2017/08/29 05:25:35 step 3: objective=0.64382815
2017/08/29 05:25:37 step 4: objective=0.64852256
2017/08/29 05:25:40 step 5: objective=0.65328956
2017/08/29 05:25:42 step 6: objective=0.65656793
2017/08/29 05:25:45 step 7: objective=0.65879637
2017/08/29 05:25:45 Training value function...
2017/08/29 05:25:47 step 0: mse=137.395474 step=0.100000
2017/08/29 05:25:49 step 1: mse=135.169694 step=0.100000
2017/08/29 05:25:50 step 2: mse=133.320788 step=0.100000
2017/08/29 05:25:51 step 3: mse=131.600527 step=0.100000
2017/08/29 05:25:52 step 4: mse=130.448061 step=0.100000
2017/08/29 05:25:54 step 5: mse=129.405837 step=0.100000
2017/08/29 05:25:55 step 6: mse=128.666763 step=0.100000
2017/08/29 05:25:56 step 7: mse=127.855956 step=0.100000
2017/08/29 05:25:56 Saving...
2017/08/29 05:25:56 Gathering batch of experience...
2017/08/29 05:26:45 batch 1016: mean=213.178571 stddev=160.450049 entropy=0.324269 frames=5480 count=28
2017/08/29 05:26:45 Training policy...
2017/08/29 05:26:50 step 0: objective=1.3933879
2017/08/29 05:26:52 step 1: objective=1.4055827
2017/08/29 05:26:54 step 2: objective=1.4156486
2017/08/29 05:26:56 step 3: objective=1.4211798
2017/08/29 05:26:59 step 4: objective=1.4250283
2017/08/29 05:27:01 step 5: objective=1.4306134
2017/08/29 05:27:03 step 6: objective=1.4334059
2017/08/29 05:27:05 step 7: objective=1.4374765
2017/08/29 05:27:05 Training value function...
2017/08/29 05:27:08 step 0: mse=184.508320 step=0.100000
2017/08/29 05:27:09 step 1: mse=180.213525 step=0.100000
2017/08/29 05:27:10 step 2: mse=176.486755 step=0.100000
2017/08/29 05:27:11 step 3: mse=172.989708 step=0.100000
2017/08/29 05:27:12 step 4: mse=170.104534 step=0.100000
2017/08/29 05:27:14 step 5: mse=167.515623 step=0.100000
2017/08/29 05:27:15 step 6: mse=165.261345 step=0.100000
2017/08/29 05:27:16 step 7: mse=163.132650 step=0.100000
2017/08/29 05:27:16 Saving...
2017/08/29 05:27:16 Gathering batch of experience...
2017/08/29 05:28:06 batch 1017: mean=214.939394 stddev=200.769873 entropy=0.317500 frames=6506 count=33
2017/08/29 05:28:06 Training policy...
2017/08/29 05:28:11 step 0: objective=1.3658813
2017/08/29 05:28:14 step 1: objective=1.3712721
2017/08/29 05:28:17 step 2: objective=1.3770002
2017/08/29 05:28:19 step 3: objective=1.3821564
2017/08/29 05:28:22 step 4: objective=1.3853028
2017/08/29 05:28:25 step 5: objective=1.3873696
2017/08/29 05:28:27 step 6: objective=1.39091
2017/08/29 05:28:30 step 7: objective=1.3945428
2017/08/29 05:28:30 Training value function...
2017/08/29 05:28:33 step 0: mse=155.307450 step=0.100000
2017/08/29 05:28:34 step 1: mse=152.281361 step=0.100000
2017/08/29 05:28:35 step 2: mse=149.869159 step=0.100000
2017/08/29 05:28:37 step 3: mse=147.790553 step=0.100000
2017/08/29 05:28:38 step 4: mse=146.161525 step=0.100000
2017/08/29 05:28:40 step 5: mse=144.749385 step=0.100000
2017/08/29 05:28:41 step 6: mse=142.939911 step=0.100000
2017/08/29 05:28:42 step 7: mse=141.672007 step=0.100000
2017/08/29 05:28:42 Saving...
2017/08/29 05:28:43 Gathering batch of experience...
2017/08/29 05:29:28 batch 1018: mean=178.909091 stddev=171.431294 entropy=0.313032 frames=5609 count=33
2017/08/29 05:29:28 Training policy...
2017/08/29 05:29:33 step 0: objective=0.40498072
2017/08/29 05:29:35 step 1: objective=0.41243076
2017/08/29 05:29:38 step 2: objective=0.41721645
2017/08/29 05:29:40 step 3: objective=0.42594156
2017/08/29 05:29:42 step 4: objective=0.43308532
2017/08/29 05:29:45 step 5: objective=0.4375307
2017/08/29 05:29:47 step 6: objective=0.4408141
2017/08/29 05:29:49 step 7: objective=0.44543332
2017/08/29 05:29:49 Training value function...
2017/08/29 05:29:52 step 0: mse=158.395449 step=0.100000
2017/08/29 05:29:53 step 1: mse=156.086044 step=0.100000
2017/08/29 05:29:54 step 2: mse=153.930323 step=0.100000
2017/08/29 05:29:55 step 3: mse=152.352749 step=0.100000
2017/08/29 05:29:56 step 4: mse=150.502145 step=0.100000
2017/08/29 05:29:57 step 5: mse=149.262179 step=0.100000
2017/08/29 05:29:59 step 6: mse=148.470366 step=0.100000
2017/08/29 05:30:00 step 7: mse=147.245068 step=0.100000
2017/08/29 05:30:00 Saving...
2017/08/29 05:30:00 Gathering batch of experience...
2017/08/29 05:30:46 batch 1019: mean=216.064516 stddev=147.654989 entropy=0.310338 frames=6103 count=31
2017/08/29 05:30:46 Training policy...
2017/08/29 05:30:52 step 0: objective=1.374949
2017/08/29 05:30:54 step 1: objective=1.3801783
2017/08/29 05:30:57 step 2: objective=1.3845736
2017/08/29 05:30:59 step 3: objective=1.389085
2017/08/29 05:31:02 step 4: objective=1.3925678
2017/08/29 05:31:04 step 5: objective=1.3986264
2017/08/29 05:31:07 step 6: objective=1.4016004
2017/08/29 05:31:09 step 7: objective=1.404438
2017/08/29 05:31:09 Training value function...
2017/08/29 05:31:12 step 0: mse=154.009496 step=0.100000
2017/08/29 05:31:13 step 1: mse=149.823875 step=0.100000
2017/08/29 05:31:15 step 2: mse=146.550593 step=0.100000
2017/08/29 05:31:16 step 3: mse=143.711424 step=0.100000
2017/08/29 05:31:17 step 4: mse=141.526327 step=0.100000
2017/08/29 05:31:18 step 5: mse=139.439727 step=0.100000
2017/08/29 05:31:20 step 6: mse=137.666754 step=0.100000
2017/08/29 05:31:21 step 7: mse=136.102508 step=0.100000
2017/08/29 05:31:21 Saving...
2017/08/29 05:31:21 Gathering batch of experience...
2017/08/29 05:32:22 batch 1020: mean=307.250000 stddev=217.419382 entropy=0.312554 frames=7784 count=28
2017/08/29 05:32:22 Training policy...
2017/08/29 05:32:28 step 0: objective=2.355283
2017/08/29 05:32:31 step 1: objective=2.3599744
2017/08/29 05:32:35 step 2: objective=2.3664734
2017/08/29 05:32:38 step 3: objective=2.3721418
2017/08/29 05:32:41 step 4: objective=2.3747797
2017/08/29 05:32:44 step 5: objective=2.3790295
2017/08/29 05:32:48 step 6: objective=2.3810322
2017/08/29 05:32:51 step 7: objective=2.3830907
2017/08/29 05:32:51 Training value function...
2017/08/29 05:32:54 step 0: mse=182.735581 step=0.100000
2017/08/29 05:32:56 step 1: mse=175.164503 step=0.100000
2017/08/29 05:32:57 step 2: mse=168.781977 step=0.100000
2017/08/29 05:32:59 step 3: mse=163.429205 step=0.100000
2017/08/29 05:33:01 step 4: mse=158.926400 step=0.100000
2017/08/29 05:33:02 step 5: mse=155.010943 step=0.100000
2017/08/29 05:33:04 step 6: mse=151.758246 step=0.100000
2017/08/29 05:33:06 step 7: mse=148.964614 step=0.100000
2017/08/29 05:33:06 Saving...
2017/08/29 05:33:06 Gathering batch of experience...
2017/08/29 05:33:49 batch 1021: mean=251.958333 stddev=195.956092 entropy=0.320247 frames=5824 count=24
2017/08/29 05:33:49 Training policy...
2017/08/29 05:33:54 step 0: objective=0.5970102
2017/08/29 05:33:56 step 1: objective=0.6011876
2017/08/29 05:33:59 step 2: objective=0.6064972
2017/08/29 05:34:01 step 3: objective=0.61154395
2017/08/29 05:34:04 step 4: objective=0.6184751
2017/08/29 05:34:06 step 5: objective=0.62441516
2017/08/29 05:34:08 step 6: objective=0.6278111
2017/08/29 05:34:11 step 7: objective=0.6322106
2017/08/29 05:34:11 Training value function...
2017/08/29 05:34:13 step 0: mse=143.954652 step=0.100000
2017/08/29 05:34:14 step 1: mse=141.764270 step=0.100000
2017/08/29 05:34:16 step 2: mse=139.694268 step=0.100000
2017/08/29 05:34:17 step 3: mse=137.711926 step=0.100000
2017/08/29 05:34:18 step 4: mse=135.865899 step=0.100000
2017/08/29 05:34:19 step 5: mse=134.700800 step=0.100000
2017/08/29 05:34:21 step 6: mse=133.496070 step=0.100000
2017/08/29 05:34:22 step 7: mse=131.794780 step=0.100000
2017/08/29 05:34:22 Saving...
2017/08/29 05:34:22 Gathering batch of experience...
2017/08/29 05:35:17 batch 1022: mean=229.593750 stddev=183.257479 entropy=0.319005 frames=6985 count=32
2017/08/29 05:35:17 Training policy...
2017/08/29 05:35:23 step 0: objective=0.7108846
2017/08/29 05:35:25 step 1: objective=0.71651185
2017/08/29 05:35:28 step 2: objective=0.72339606
2017/08/29 05:35:31 step 3: objective=0.7290593
2017/08/29 05:35:34 step 4: objective=0.7346136
2017/08/29 05:35:37 step 5: objective=0.73776793
2017/08/29 05:35:40 step 6: objective=0.7396029
2017/08/29 05:35:43 step 7: objective=0.7420915
2017/08/29 05:35:43 Training value function...
2017/08/29 05:35:46 step 0: mse=145.173829 step=0.100000
2017/08/29 05:35:47 step 1: mse=142.717616 step=0.100000
2017/08/29 05:35:49 step 2: mse=141.114776 step=0.100000
2017/08/29 05:35:50 step 3: mse=139.653611 step=0.100000
2017/08/29 05:35:52 step 4: mse=138.299926 step=0.100000
2017/08/29 05:35:53 step 5: mse=137.167536 step=0.100000
2017/08/29 05:35:55 step 6: mse=136.191715 step=0.100000
2017/08/29 05:35:56 step 7: mse=135.306577 step=0.100000
2017/08/29 05:35:56 Saving...
2017/08/29 05:35:56 Gathering batch of experience...
2017/08/29 05:36:38 batch 1023: mean=218.269231 stddev=171.078605 entropy=0.319949 frames=5390 count=26
2017/08/29 05:36:38 Training policy...
2017/08/29 05:36:43 step 0: objective=0.77639174
2017/08/29 05:36:45 step 1: objective=0.7810841
2017/08/29 05:36:47 step 2: objective=0.78829867
2017/08/29 05:36:49 step 3: objective=0.79273957
2017/08/29 05:36:52 step 4: objective=0.7984924
2017/08/29 05:36:54 step 5: objective=0.8025611
2017/08/29 05:36:56 step 6: objective=0.8068361
2017/08/29 05:36:58 step 7: objective=0.8111988
2017/08/29 05:36:58 Training value function...
2017/08/29 05:37:01 step 0: mse=151.950474 step=0.100000
2017/08/29 05:37:02 step 1: mse=149.480814 step=0.100000
2017/08/29 05:37:03 step 2: mse=147.978126 step=0.100000
2017/08/29 05:37:04 step 3: mse=146.312319 step=0.100000
2017/08/29 05:37:05 step 4: mse=144.803166 step=0.100000
2017/08/29 05:37:06 step 5: mse=143.563926 step=0.100000
2017/08/29 05:37:08 step 6: mse=142.761649 step=0.100000
2017/08/29 05:37:09 step 7: mse=141.814572 step=0.100000
2017/08/29 05:37:09 Saving...
2017/08/29 05:37:09 Gathering batch of experience...
2017/08/29 05:38:05 batch 1024: mean=222.588235 stddev=182.055440 entropy=0.313764 frames=7081 count=34
2017/08/29 05:38:05 Training policy...
2017/08/29 05:38:11 step 0: objective=1.1394469
2017/08/29 05:38:14 step 1: objective=1.148167
2017/08/29 05:38:17 step 2: objective=1.1554116
2017/08/29 05:38:20 step 3: objective=1.15878
2017/08/29 05:38:23 step 4: objective=1.1626918
2017/08/29 05:38:26 step 5: objective=1.1675164
2017/08/29 05:38:29 step 6: objective=1.1734201
2017/08/29 05:38:32 step 7: objective=1.1757902
2017/08/29 05:38:32 Training value function...
2017/08/29 05:38:35 step 0: mse=171.320656 step=0.100000
2017/08/29 05:38:36 step 1: mse=166.532323 step=0.100000
2017/08/29 05:38:38 step 2: mse=162.676110 step=0.100000
2017/08/29 05:38:39 step 3: mse=159.337171 step=0.100000
2017/08/29 05:38:41 step 4: mse=156.798743 step=0.100000
2017/08/29 05:38:42 step 5: mse=154.392099 step=0.100000
2017/08/29 05:38:44 step 6: mse=152.443627 step=0.100000
2017/08/29 05:38:45 step 7: mse=150.641686 step=0.100000
2017/08/29 05:38:45 Saving...
2017/08/29 05:38:45 Gathering batch of experience...
2017/08/29 05:39:35 batch 1025: mean=230.566667 stddev=140.345451 entropy=0.311517 frames=6626 count=30
2017/08/29 05:39:35 Training policy...
2017/08/29 05:39:41 step 0: objective=0.74651355
2017/08/29 05:39:44 step 1: objective=0.7529873
2017/08/29 05:39:46 step 2: objective=0.75705147
2017/08/29 05:39:49 step 3: objective=0.75996697
2017/08/29 05:39:52 step 4: objective=0.7637916
2017/08/29 05:39:54 step 5: objective=0.7703584
2017/08/29 05:39:57 step 6: objective=0.7726813
2017/08/29 05:40:00 step 7: objective=0.7756894
2017/08/29 05:40:00 Training value function...
2017/08/29 05:40:03 step 0: mse=140.337002 step=0.100000
2017/08/29 05:40:04 step 1: mse=138.860184 step=0.100000
2017/08/29 05:40:06 step 2: mse=137.322854 step=0.100000
2017/08/29 05:40:07 step 3: mse=135.939874 step=0.100000
2017/08/29 05:40:08 step 4: mse=134.838369 step=0.100000
2017/08/29 05:40:10 step 5: mse=133.963308 step=0.100000
2017/08/29 05:40:11 step 6: mse=133.180393 step=0.100000
2017/08/29 05:40:13 step 7: mse=132.211441 step=0.100000
2017/08/29 05:40:13 Saving...
2017/08/29 05:40:13 Gathering batch of experience...
2017/08/29 05:41:05 batch 1026: mean=201.323529 stddev=164.481131 entropy=0.312161 frames=6323 count=34
2017/08/29 05:41:05 Training policy...
2017/08/29 05:41:10 step 0: objective=1.1493586
2017/08/29 05:41:13 step 1: objective=1.1544307
2017/08/29 05:41:15 step 2: objective=1.1579275
2017/08/29 05:41:18 step 3: objective=1.1651256
2017/08/29 05:41:21 step 4: objective=1.1705828
2017/08/29 05:41:23 step 5: objective=1.1753545
2017/08/29 05:41:26 step 6: objective=1.1793424
2017/08/29 05:41:28 step 7: objective=1.1814653
2017/08/29 05:41:28 Training value function...
2017/08/29 05:41:31 step 0: mse=182.192575 step=0.100000
2017/08/29 05:41:32 step 1: mse=179.727834 step=0.100000
2017/08/29 05:41:34 step 2: mse=177.398501 step=0.100000
2017/08/29 05:41:35 step 3: mse=175.357169 step=0.100000
2017/08/29 05:41:36 step 4: mse=173.460359 step=0.100000
2017/08/29 05:41:38 step 5: mse=171.650352 step=0.100000
2017/08/29 05:41:39 step 6: mse=170.332173 step=0.100000
2017/08/29 05:41:40 step 7: mse=168.653749 step=0.100000
2017/08/29 05:41:40 Saving...
2017/08/29 05:41:40 Gathering batch of experience...
2017/08/29 05:42:26 batch 1027: mean=191.387097 stddev=150.543034 entropy=0.313194 frames=5831 count=31
2017/08/29 05:42:26 Training policy...
2017/08/29 05:42:31 step 0: objective=0.37093744
2017/08/29 05:42:33 step 1: objective=0.37518054
2017/08/29 05:42:35 step 2: objective=0.3800899
2017/08/29 05:42:38 step 3: objective=0.38363096
2017/08/29 05:42:40 step 4: objective=0.3871412
2017/08/29 05:42:43 step 5: objective=0.39041135
2017/08/29 05:42:45 step 6: objective=0.39667484
2017/08/29 05:42:48 step 7: objective=0.4009526
2017/08/29 05:42:48 Training value function...
2017/08/29 05:42:50 step 0: mse=156.438903 step=0.100000
2017/08/29 05:42:51 step 1: mse=153.731199 step=0.100000
2017/08/29 05:42:53 step 2: mse=151.694653 step=0.100000
2017/08/29 05:42:54 step 3: mse=149.972997 step=0.100000
2017/08/29 05:42:55 step 4: mse=147.996235 step=0.100000
2017/08/29 05:42:56 step 5: mse=146.606528 step=0.100000
2017/08/29 05:42:57 step 6: mse=145.689913 step=0.100000
2017/08/29 05:42:59 step 7: mse=144.906477 step=0.100000
2017/08/29 05:42:59 Saving...
2017/08/29 05:42:59 Gathering batch of experience...
2017/08/29 05:43:50 batch 1028: mean=282.821429 stddev=186.351828 entropy=0.313511 frames=7203 count=28
2017/08/29 05:43:50 Training policy...
2017/08/29 05:43:56 step 0: objective=2.264428
2017/08/29 05:43:59 step 1: objective=2.2679117
2017/08/29 05:44:02 step 2: objective=2.2729144
2017/08/29 05:44:05 step 3: objective=2.2765515
2017/08/29 05:44:08 step 4: objective=2.2798421
2017/08/29 05:44:11 step 5: objective=2.2830179
2017/08/29 05:44:14 step 6: objective=2.285658
2017/08/29 05:44:17 step 7: objective=2.287833
2017/08/29 05:44:17 Training value function...
2017/08/29 05:44:20 step 0: mse=176.755460 step=0.100000
2017/08/29 05:44:22 step 1: mse=171.957334 step=0.100000
2017/08/29 05:44:23 step 2: mse=167.765791 step=0.100000
2017/08/29 05:44:25 step 3: mse=164.262052 step=0.100000
2017/08/29 05:44:26 step 4: mse=161.460868 step=0.100000
2017/08/29 05:44:28 step 5: mse=158.702901 step=0.100000
2017/08/29 05:44:29 step 6: mse=156.351103 step=0.100000
2017/08/29 05:44:31 step 7: mse=154.572044 step=0.100000
2017/08/29 05:44:31 Saving...
2017/08/29 05:44:31 Gathering batch of experience...
2017/08/29 05:45:17 batch 1029: mean=161.184211 stddev=155.256639 entropy=0.309447 frames=5563 count=38
2017/08/29 05:45:17 Training policy...
2017/08/29 05:45:22 step 0: objective=0.41052482
2017/08/29 05:45:25 step 1: objective=0.41746414
2017/08/29 05:45:27 step 2: objective=0.42465794
2017/08/29 05:45:29 step 3: objective=0.43414608
2017/08/29 05:45:32 step 4: objective=0.4410307
2017/08/29 05:45:34 step 5: objective=0.44434088
2017/08/29 05:45:36 step 6: objective=0.44763362
2017/08/29 05:45:38 step 7: objective=0.4497807
2017/08/29 05:45:38 Training value function...
2017/08/29 05:45:41 step 0: mse=173.629725 step=0.100000
2017/08/29 05:45:42 step 1: mse=171.088832 step=0.100000
2017/08/29 05:45:43 step 2: mse=168.730274 step=0.100000
2017/08/29 05:45:44 step 3: mse=166.560022 step=0.100000
2017/08/29 05:45:46 step 4: mse=164.808953 step=0.100000
2017/08/29 05:45:47 step 5: mse=162.927103 step=0.100000
2017/08/29 05:45:48 step 6: mse=161.187374 step=0.100000
2017/08/29 05:45:49 step 7: mse=160.075274 step=0.100000
2017/08/29 05:45:49 Saving...
2017/08/29 05:45:49 Gathering batch of experience...
2017/08/29 05:46:37 batch 1030: mean=212.333333 stddev=168.447090 entropy=0.311502 frames=6002 count=30
2017/08/29 05:46:37 Training policy...
2017/08/29 05:46:42 step 0: objective=0.9582431
2017/08/29 05:46:45 step 1: objective=0.96633536
2017/08/29 05:46:47 step 2: objective=0.9723958
2017/08/29 05:46:50 step 3: objective=0.9753476
2017/08/29 05:46:52 step 4: objective=0.9797731
2017/08/29 05:46:55 step 5: objective=0.98369503
2017/08/29 05:46:57 step 6: objective=0.9883524
2017/08/29 05:47:00 step 7: objective=0.991245
2017/08/29 05:47:00 Training value function...
2017/08/29 05:47:02 step 0: mse=161.227116 step=0.100000
2017/08/29 05:47:04 step 1: mse=158.901983 step=0.100000
2017/08/29 05:47:05 step 2: mse=156.905231 step=0.100000
2017/08/29 05:47:06 step 3: mse=155.107617 step=0.100000
2017/08/29 05:47:08 step 4: mse=153.649401 step=0.100000
2017/08/29 05:47:09 step 5: mse=152.317656 step=0.100000
2017/08/29 05:47:10 step 6: mse=151.131981 step=0.100000
2017/08/29 05:47:11 step 7: mse=150.062501 step=0.100000
2017/08/29 05:47:11 Saving...
2017/08/29 05:47:11 Gathering batch of experience...
2017/08/29 05:47:55 batch 1031: mean=202.800000 stddev=147.144238 entropy=0.314141 frames=5763 count=30
2017/08/29 05:47:55 Training policy...
2017/08/29 05:48:00 step 0: objective=0.69004035
2017/08/29 05:48:03 step 1: objective=0.694339
2017/08/29 05:48:05 step 2: objective=0.6978067
2017/08/29 05:48:07 step 3: objective=0.7019236
2017/08/29 05:48:10 step 4: objective=0.7059893
2017/08/29 05:48:12 step 5: objective=0.7090338
2017/08/29 05:48:15 step 6: objective=0.7128279
2017/08/29 05:48:17 step 7: objective=0.7159455
2017/08/29 05:48:17 Training value function...
2017/08/29 05:48:19 step 0: mse=148.038923 step=0.100000
2017/08/29 05:48:21 step 1: mse=144.503887 step=0.100000
2017/08/29 05:48:22 step 2: mse=141.682829 step=0.100000
2017/08/29 05:48:23 step 3: mse=139.295367 step=0.100000
2017/08/29 05:48:24 step 4: mse=137.395606 step=0.100000
2017/08/29 05:48:26 step 5: mse=135.574419 step=0.100000
2017/08/29 05:48:27 step 6: mse=133.942630 step=0.100000
2017/08/29 05:48:28 step 7: mse=132.576969 step=0.100000
2017/08/29 05:48:28 Saving...
2017/08/29 05:48:28 Gathering batch of experience...
2017/08/29 05:49:17 batch 1032: mean=214.896552 stddev=195.562733 entropy=0.314287 frames=5712 count=29
2017/08/29 05:49:17 Training policy...
2017/08/29 05:49:22 step 0: objective=1.6656935
2017/08/29 05:49:24 step 1: objective=1.6719909
2017/08/29 05:49:26 step 2: objective=1.6769193
2017/08/29 05:49:29 step 3: objective=1.6835647
2017/08/29 05:49:31 step 4: objective=1.6898243
2017/08/29 05:49:33 step 5: objective=1.6938579
2017/08/29 05:49:36 step 6: objective=1.697494
2017/08/29 05:49:38 step 7: objective=1.7016087
2017/08/29 05:49:38 Training value function...
2017/08/29 05:49:41 step 0: mse=175.882960 step=0.100000
2017/08/29 05:49:42 step 1: mse=170.917547 step=0.100000
2017/08/29 05:49:43 step 2: mse=167.044906 step=0.100000
2017/08/29 05:49:44 step 3: mse=163.308306 step=0.100000
2017/08/29 05:49:45 step 4: mse=160.380348 step=0.100000
2017/08/29 05:49:47 step 5: mse=158.129146 step=0.100000
2017/08/29 05:49:48 step 6: mse=155.943941 step=0.100000
2017/08/29 05:49:49 step 7: mse=153.930460 step=0.100000
2017/08/29 05:49:49 Saving...
2017/08/29 05:49:49 Gathering batch of experience...
2017/08/29 05:50:36 batch 1033: mean=194.727273 stddev=157.505608 entropy=0.310248 frames=6112 count=33
2017/08/29 05:50:36 Training policy...
2017/08/29 05:50:41 step 0: objective=0.57373774
2017/08/29 05:50:44 step 1: objective=0.5813725
2017/08/29 05:50:46 step 2: objective=0.587495
2017/08/29 05:50:49 step 3: objective=0.5922529
2017/08/29 05:50:51 step 4: objective=0.59469795
2017/08/29 05:50:54 step 5: objective=0.5973847
2017/08/29 05:50:56 step 6: objective=0.59958994
2017/08/29 05:50:59 step 7: objective=0.60312694
2017/08/29 05:50:59 Training value function...
2017/08/29 05:51:02 step 0: mse=141.653517 step=0.100000
2017/08/29 05:51:03 step 1: mse=138.714060 step=0.100000
2017/08/29 05:51:04 step 2: mse=136.728843 step=0.100000
2017/08/29 05:51:05 step 3: mse=135.142555 step=0.100000
2017/08/29 05:51:07 step 4: mse=133.464826 step=0.100000
2017/08/29 05:51:08 step 5: mse=132.135556 step=0.100000
2017/08/29 05:51:09 step 6: mse=131.002882 step=0.100000
2017/08/29 05:51:11 step 7: mse=129.886102 step=0.100000
2017/08/29 05:51:11 Saving...
2017/08/29 05:51:11 Gathering batch of experience...
2017/08/29 05:51:57 batch 1034: mean=209.620690 stddev=184.882705 entropy=0.314799 frames=5790 count=29
2017/08/29 05:51:57 Training policy...
2017/08/29 05:52:02 step 0: objective=1.1020082
2017/08/29 05:52:04 step 1: objective=1.1067879
2017/08/29 05:52:07 step 2: objective=1.1122847
2017/08/29 05:52:09 step 3: objective=1.1174728
2017/08/29 05:52:12 step 4: objective=1.1220797
2017/08/29 05:52:14 step 5: objective=1.1246994
2017/08/29 05:52:16 step 6: objective=1.1287671
2017/08/29 05:52:19 step 7: objective=1.1312197
2017/08/29 05:52:19 Training value function...
2017/08/29 05:52:21 step 0: mse=169.925340 step=0.100000
2017/08/29 05:52:22 step 1: mse=167.135657 step=0.100000
2017/08/29 05:52:24 step 2: mse=164.611649 step=0.100000
2017/08/29 05:52:25 step 3: mse=162.404546 step=0.100000
2017/08/29 05:52:26 step 4: mse=160.679690 step=0.100000
2017/08/29 05:52:27 step 5: mse=158.740837 step=0.100000
2017/08/29 05:52:29 step 6: mse=157.254650 step=0.100000
2017/08/29 05:52:30 step 7: mse=155.652202 step=0.100000
2017/08/29 05:52:30 Saving...
2017/08/29 05:52:30 Gathering batch of experience...
2017/08/29 05:53:18 batch 1035: mean=273.148148 stddev=186.466898 entropy=0.315766 frames=6648 count=27
2017/08/29 05:53:18 Training policy...
2017/08/29 05:53:23 step 0: objective=2.1048167
2017/08/29 05:53:26 step 1: objective=2.1087825
2017/08/29 05:53:29 step 2: objective=2.112479
2017/08/29 05:53:32 step 3: objective=2.1161842
2017/08/29 05:53:35 step 4: objective=2.1212463
2017/08/29 05:53:37 step 5: objective=2.1267576
2017/08/29 05:53:40 step 6: objective=2.1293342
2017/08/29 05:53:43 step 7: objective=2.1326017
2017/08/29 05:53:43 Training value function...
2017/08/29 05:53:46 step 0: mse=194.660880 step=0.100000
2017/08/29 05:53:47 step 1: mse=189.274907 step=0.100000
2017/08/29 05:53:49 step 2: mse=184.933939 step=0.100000
2017/08/29 05:53:50 step 3: mse=180.966593 step=0.100000
2017/08/29 05:53:51 step 4: mse=177.609221 step=0.100000
2017/08/29 05:53:53 step 5: mse=174.803153 step=0.100000
2017/08/29 05:53:54 step 6: mse=172.279211 step=0.100000
2017/08/29 05:53:56 step 7: mse=169.856926 step=0.100000
2017/08/29 05:53:56 Saving...
2017/08/29 05:53:56 Gathering batch of experience...
2017/08/29 05:54:49 batch 1036: mean=220.281250 stddev=165.432054 entropy=0.313584 frames=6569 count=32
2017/08/29 05:54:49 Training policy...
2017/08/29 05:54:55 step 0: objective=0.7407263
2017/08/29 05:54:57 step 1: objective=0.7474834
2017/08/29 05:55:00 step 2: objective=0.75075936
2017/08/29 05:55:03 step 3: objective=0.75578696
2017/08/29 05:55:06 step 4: objective=0.75873846
2017/08/29 05:55:08 step 5: objective=0.7629363
2017/08/29 05:55:11 step 6: objective=0.7671075
2017/08/29 05:55:14 step 7: objective=0.7686841
2017/08/29 05:55:14 Training value function...
2017/08/29 05:55:17 step 0: mse=156.246906 step=0.100000
2017/08/29 05:55:18 step 1: mse=154.580407 step=0.100000
2017/08/29 05:55:19 step 2: mse=153.529512 step=0.100000
2017/08/29 05:55:21 step 3: mse=152.711119 step=0.100000
2017/08/29 05:55:22 step 4: mse=151.927549 step=0.100000
2017/08/29 05:55:24 step 5: mse=151.029669 step=0.100000
2017/08/29 05:55:25 step 6: mse=150.155936 step=0.100000
2017/08/29 05:55:26 step 7: mse=149.375960 step=0.100000
2017/08/29 05:55:26 Saving...
2017/08/29 05:55:26 Gathering batch of experience...
2017/08/29 05:56:09 batch 1037: mean=181.966667 stddev=131.628893 entropy=0.311141 frames=5404 count=30
2017/08/29 05:56:09 Training policy...
2017/08/29 05:56:14 step 0: objective=-0.046969384
2017/08/29 05:56:16 step 1: objective=-0.041550703
2017/08/29 05:56:18 step 2: objective=-0.03634646
2017/08/29 05:56:21 step 3: objective=-0.03211542
2017/08/29 05:56:23 step 4: objective=-0.026118442
2017/08/29 05:56:25 step 5: objective=-0.021315735
2017/08/29 05:56:27 step 6: objective=-0.016759256
2017/08/29 05:56:30 step 7: objective=-0.014779244
2017/08/29 05:56:30 Training value function...
2017/08/29 05:56:32 step 0: mse=147.637409 step=0.100000
2017/08/29 05:56:33 step 1: mse=145.208552 step=0.100000
2017/08/29 05:56:34 step 2: mse=143.148537 step=0.100000
2017/08/29 05:56:35 step 3: mse=141.422092 step=0.100000
2017/08/29 05:56:36 step 4: mse=139.810362 step=0.100000
2017/08/29 05:56:38 step 5: mse=138.640974 step=0.100000
2017/08/29 05:56:39 step 6: mse=137.888542 step=0.100000
2017/08/29 05:56:40 step 7: mse=137.053392 step=0.100000
2017/08/29 05:56:40 Saving...
2017/08/29 05:56:40 Gathering batch of experience...
2017/08/29 05:57:32 batch 1038: mean=223.031250 stddev=151.501750 entropy=0.313972 frames=6744 count=32
2017/08/29 05:57:32 Training policy...
2017/08/29 05:57:38 step 0: objective=1.3750281
2017/08/29 05:57:40 step 1: objective=1.3790878
2017/08/29 05:57:43 step 2: objective=1.3857306
2017/08/29 05:57:46 step 3: objective=1.3886387
2017/08/29 05:57:49 step 4: objective=1.3916723
2017/08/29 05:57:52 step 5: objective=1.3961506
2017/08/29 05:57:54 step 6: objective=1.3992954
2017/08/29 05:57:57 step 7: objective=1.4049628
2017/08/29 05:57:57 Training value function...
2017/08/29 05:58:00 step 0: mse=168.866503 step=0.100000
2017/08/29 05:58:01 step 1: mse=164.903820 step=0.100000
2017/08/29 05:58:03 step 2: mse=161.657503 step=0.100000
2017/08/29 05:58:04 step 3: mse=158.826318 step=0.100000
2017/08/29 05:58:06 step 4: mse=156.268304 step=0.100000
2017/08/29 05:58:07 step 5: mse=154.146536 step=0.100000
2017/08/29 05:58:09 step 6: mse=152.255343 step=0.100000
2017/08/29 05:58:10 step 7: mse=150.469662 step=0.100000
2017/08/29 05:58:10 Saving...
2017/08/29 05:58:10 Gathering batch of experience...
2017/08/29 05:59:03 batch 1039: mean=202.121212 stddev=163.226141 entropy=0.310296 frames=6293 count=33
2017/08/29 05:59:03 Training policy...
2017/08/29 05:59:09 step 0: objective=1.0440493
2017/08/29 05:59:11 step 1: objective=1.0483135
2017/08/29 05:59:14 step 2: objective=1.0549473
2017/08/29 05:59:17 step 3: objective=1.0597833
2017/08/29 05:59:19 step 4: objective=1.0630931
2017/08/29 05:59:22 step 5: objective=1.0657252
2017/08/29 05:59:25 step 6: objective=1.0705765
2017/08/29 05:59:27 step 7: objective=1.0746582
2017/08/29 05:59:27 Training value function...
2017/08/29 05:59:30 step 0: mse=167.401437 step=0.100000
2017/08/29 05:59:31 step 1: mse=165.022433 step=0.100000
2017/08/29 05:59:33 step 2: mse=162.983035 step=0.100000
2017/08/29 05:59:34 step 3: mse=161.343421 step=0.100000
2017/08/29 05:59:35 step 4: mse=159.567953 step=0.100000
2017/08/29 05:59:37 step 5: mse=158.161379 step=0.100000
2017/08/29 05:59:38 step 6: mse=156.646669 step=0.100000
2017/08/29 05:59:39 step 7: mse=155.471190 step=0.100000
2017/08/29 05:59:39 Saving...
2017/08/29 05:59:39 Gathering batch of experience...
2017/08/29 06:00:36 batch 1040: mean=235.032258 stddev=211.023081 entropy=0.316219 frames=7156 count=31
2017/08/29 06:00:36 Training policy...
2017/08/29 06:00:42 step 0: objective=1.0768998
2017/08/29 06:00:45 step 1: objective=1.0838606
2017/08/29 06:00:48 step 2: objective=1.0884376
2017/08/29 06:00:51 step 3: objective=1.0913045
2017/08/29 06:00:54 step 4: objective=1.0956712
2017/08/29 06:00:57 step 5: objective=1.098091
2017/08/29 06:01:00 step 6: objective=1.1010319
2017/08/29 06:01:03 step 7: objective=1.1025767
2017/08/29 06:01:03 Training value function...
2017/08/29 06:01:06 step 0: mse=150.431540 step=0.100000
2017/08/29 06:01:07 step 1: mse=146.966484 step=0.100000
2017/08/29 06:01:09 step 2: mse=144.316930 step=0.100000
2017/08/29 06:01:10 step 3: mse=141.869982 step=0.100000
2017/08/29 06:01:12 step 4: mse=139.826085 step=0.100000
2017/08/29 06:01:14 step 5: mse=138.216150 step=0.100000
2017/08/29 06:01:15 step 6: mse=136.605018 step=0.100000
2017/08/29 06:01:17 step 7: mse=135.270333 step=0.100000
2017/08/29 06:01:17 Saving...
2017/08/29 06:01:17 Gathering batch of experience...
2017/08/29 06:02:04 batch 1041: mean=255.346154 stddev=160.090105 entropy=0.313568 frames=6408 count=26
2017/08/29 06:02:04 Training policy...
2017/08/29 06:02:10 step 0: objective=1.0959901
2017/08/29 06:02:12 step 1: objective=1.101649
2017/08/29 06:02:15 step 2: objective=1.1065859
2017/08/29 06:02:18 step 3: objective=1.1089703
2017/08/29 06:02:21 step 4: objective=1.1129673
2017/08/29 06:02:23 step 5: objective=1.1176847
2017/08/29 06:02:26 step 6: objective=1.1207824
2017/08/29 06:02:29 step 7: objective=1.1245466
2017/08/29 06:02:29 Training value function...
2017/08/29 06:02:31 step 0: mse=163.415392 step=0.100000
2017/08/29 06:02:33 step 1: mse=160.074130 step=0.100000
2017/08/29 06:02:34 step 2: mse=157.494435 step=0.100000
2017/08/29 06:02:35 step 3: mse=154.999777 step=0.100000
2017/08/29 06:02:37 step 4: mse=153.293424 step=0.100000
2017/08/29 06:02:38 step 5: mse=151.302788 step=0.100000
2017/08/29 06:02:40 step 6: mse=149.544737 step=0.100000
2017/08/29 06:02:41 step 7: mse=148.114840 step=0.100000
2017/08/29 06:02:41 Saving...
2017/08/29 06:02:41 Gathering batch of experience...
2017/08/29 06:03:32 batch 1042: mean=196.028571 stddev=182.568263 entropy=0.311487 frames=6403 count=35
2017/08/29 06:03:32 Training policy...
2017/08/29 06:03:37 step 0: objective=1.2694591
2017/08/29 06:03:40 step 1: objective=1.273963
2017/08/29 06:03:43 step 2: objective=1.2775756
2017/08/29 06:03:45 step 3: objective=1.2833622
2017/08/29 06:03:48 step 4: objective=1.2878282
2017/08/29 06:03:51 step 5: objective=1.2921712
2017/08/29 06:03:53 step 6: objective=1.2972234
2017/08/29 06:03:56 step 7: objective=1.299475
2017/08/29 06:03:56 Training value function...
2017/08/29 06:03:59 step 0: mse=167.533768 step=0.100000
2017/08/29 06:04:00 step 1: mse=163.265373 step=0.100000
2017/08/29 06:04:01 step 2: mse=159.682653 step=0.100000
2017/08/29 06:04:03 step 3: mse=156.698449 step=0.100000
2017/08/29 06:04:04 step 4: mse=154.297426 step=0.100000
2017/08/29 06:04:05 step 5: mse=152.031425 step=0.100000
2017/08/29 06:04:07 step 6: mse=150.177959 step=0.100000
2017/08/29 06:04:08 step 7: mse=148.507838 step=0.100000
2017/08/29 06:04:08 Saving...
2017/08/29 06:04:08 Gathering batch of experience...
2017/08/29 06:04:58 batch 1043: mean=216.096774 stddev=168.178161 entropy=0.307846 frames=6182 count=31
2017/08/29 06:04:58 Training policy...
2017/08/29 06:05:03 step 0: objective=1.1333045
2017/08/29 06:05:06 step 1: objective=1.1417079
2017/08/29 06:05:08 step 2: objective=1.1483736
2017/08/29 06:05:11 step 3: objective=1.1545618
2017/08/29 06:05:14 step 4: objective=1.1614108
2017/08/29 06:05:16 step 5: objective=1.1665169
2017/08/29 06:05:19 step 6: objective=1.1689402
2017/08/29 06:05:21 step 7: objective=1.1709999
2017/08/29 06:05:21 Training value function...
2017/08/29 06:05:24 step 0: mse=165.887619 step=0.100000
2017/08/29 06:05:25 step 1: mse=161.642181 step=0.100000
2017/08/29 06:05:27 step 2: mse=158.124594 step=0.100000
2017/08/29 06:05:28 step 3: mse=155.054066 step=0.100000
2017/08/29 06:05:29 step 4: mse=152.469681 step=0.100000
2017/08/29 06:05:31 step 5: mse=150.327334 step=0.100000
2017/08/29 06:05:32 step 6: mse=148.583189 step=0.100000
2017/08/29 06:05:33 step 7: mse=146.890334 step=0.100000
2017/08/29 06:05:33 Saving...
2017/08/29 06:05:33 Gathering batch of experience...
2017/08/29 06:06:22 batch 1044: mean=218.225806 stddev=172.752239 entropy=0.305417 frames=6420 count=31
2017/08/29 06:06:22 Training policy...
2017/08/29 06:06:28 step 0: objective=0.7493729
2017/08/29 06:06:30 step 1: objective=0.7549282
2017/08/29 06:06:33 step 2: objective=0.76157665
2017/08/29 06:06:36 step 3: objective=0.7673539
2017/08/29 06:06:38 step 4: objective=0.7712457
2017/08/29 06:06:41 step 5: objective=0.7761162
2017/08/29 06:06:44 step 6: objective=0.77978396
2017/08/29 06:06:46 step 7: objective=0.7823283
2017/08/29 06:06:46 Training value function...
2017/08/29 06:06:49 step 0: mse=150.217453 step=0.100000
2017/08/29 06:06:50 step 1: mse=147.425935 step=0.100000
2017/08/29 06:06:52 step 2: mse=144.926186 step=0.100000
2017/08/29 06:06:53 step 3: mse=142.771852 step=0.100000
2017/08/29 06:06:55 step 4: mse=141.394713 step=0.100000
2017/08/29 06:06:56 step 5: mse=139.927332 step=0.100000
2017/08/29 06:06:57 step 6: mse=138.638640 step=0.100000
2017/08/29 06:06:59 step 7: mse=137.922196 step=0.100000
2017/08/29 06:06:59 Saving...
2017/08/29 06:06:59 Gathering batch of experience...
2017/08/29 06:07:45 batch 1045: mean=208.758621 stddev=187.445377 entropy=0.316463 frames=5898 count=29
2017/08/29 06:07:45 Training policy...
2017/08/29 06:07:50 step 0: objective=0.65021205
2017/08/29 06:07:52 step 1: objective=0.6545479
2017/08/29 06:07:55 step 2: objective=0.6581429
2017/08/29 06:07:57 step 3: objective=0.664248
2017/08/29 06:08:00 step 4: objective=0.66858584
2017/08/29 06:08:02 step 5: objective=0.67266595
2017/08/29 06:08:05 step 6: objective=0.67720985
2017/08/29 06:08:07 step 7: objective=0.68042064
2017/08/29 06:08:07 Training value function...
2017/08/29 06:08:10 step 0: mse=136.823721 step=0.100000
2017/08/29 06:08:11 step 1: mse=134.108106 step=0.100000
2017/08/29 06:08:12 step 2: mse=131.984807 step=0.100000
2017/08/29 06:08:13 step 3: mse=130.143903 step=0.100000
2017/08/29 06:08:15 step 4: mse=128.494301 step=0.100000
2017/08/29 06:08:16 step 5: mse=127.230042 step=0.100000
2017/08/29 06:08:17 step 6: mse=126.018060 step=0.100000
2017/08/29 06:08:18 step 7: mse=124.998819 step=0.100000
2017/08/29 06:08:18 Saving...
2017/08/29 06:08:18 Gathering batch of experience...
2017/08/29 06:09:10 batch 1046: mean=199.485714 stddev=170.413844 entropy=0.312768 frames=6706 count=35
2017/08/29 06:09:10 Training policy...
2017/08/29 06:09:16 step 0: objective=1.0568753
2017/08/29 06:09:18 step 1: objective=1.065451
2017/08/29 06:09:21 step 2: objective=1.0719255
2017/08/29 06:09:24 step 3: objective=1.0747316
2017/08/29 06:09:27 step 4: objective=1.0798411
2017/08/29 06:09:30 step 5: objective=1.0845497
2017/08/29 06:09:32 step 6: objective=1.0875965
2017/08/29 06:09:35 step 7: objective=1.0903574
2017/08/29 06:09:35 Training value function...
2017/08/29 06:09:38 step 0: mse=133.634136 step=0.100000
2017/08/29 06:09:40 step 1: mse=131.722071 step=0.100000
2017/08/29 06:09:41 step 2: mse=129.915354 step=0.100000
2017/08/29 06:09:42 step 3: mse=128.323632 step=0.100000
2017/08/29 06:09:44 step 4: mse=126.909264 step=0.100000
2017/08/29 06:09:45 step 5: mse=125.641902 step=0.100000
2017/08/29 06:09:47 step 6: mse=124.407617 step=0.100000
2017/08/29 06:09:48 step 7: mse=123.522480 step=0.100000
2017/08/29 06:09:48 Saving...
2017/08/29 06:09:48 Gathering batch of experience...
2017/08/29 06:10:44 batch 1047: mean=288.346154 stddev=199.829339 entropy=0.318878 frames=7008 count=26
2017/08/29 06:10:44 Training policy...
2017/08/29 06:10:50 step 0: objective=1.9222877
2017/08/29 06:10:53 step 1: objective=1.9262466
2017/08/29 06:10:56 step 2: objective=1.9294153
2017/08/29 06:10:59 step 3: objective=1.9329354
2017/08/29 06:11:02 step 4: objective=1.9353311
2017/08/29 06:11:05 step 5: objective=1.9391625
2017/08/29 06:11:08 step 6: objective=1.9440498
2017/08/29 06:11:11 step 7: objective=1.946208
2017/08/29 06:11:11 Training value function...
2017/08/29 06:11:14 step 0: mse=179.110664 step=0.100000
2017/08/29 06:11:16 step 1: mse=172.767193 step=0.100000
2017/08/29 06:11:17 step 2: mse=167.204922 step=0.100000
2017/08/29 06:11:19 step 3: mse=162.447629 step=0.100000
2017/08/29 06:11:20 step 4: mse=158.630563 step=0.100000
2017/08/29 06:11:22 step 5: mse=155.706538 step=0.100000
2017/08/29 06:11:23 step 6: mse=152.760293 step=0.100000
2017/08/29 06:11:25 step 7: mse=150.497773 step=0.100000
2017/08/29 06:11:25 Saving...
2017/08/29 06:11:25 Gathering batch of experience...
2017/08/29 06:12:08 batch 1048: mean=247.307692 stddev=164.643617 entropy=0.310946 frames=6048 count=26
2017/08/29 06:12:08 Training policy...
2017/08/29 06:12:13 step 0: objective=0.95406103
2017/08/29 06:12:16 step 1: objective=0.95852304
2017/08/29 06:12:18 step 2: objective=0.9624499
2017/08/29 06:12:21 step 3: objective=0.9650434
2017/08/29 06:12:23 step 4: objective=0.96828127
2017/08/29 06:12:26 step 5: objective=0.97074807
2017/08/29 06:12:29 step 6: objective=0.97305095
2017/08/29 06:12:31 step 7: objective=0.9749674
2017/08/29 06:12:31 Training value function...
2017/08/29 06:12:34 step 0: mse=132.651381 step=0.100000
2017/08/29 06:12:35 step 1: mse=130.626343 step=0.100000
2017/08/29 06:12:36 step 2: mse=128.940861 step=0.100000
2017/08/29 06:12:37 step 3: mse=127.496208 step=0.100000
2017/08/29 06:12:39 step 4: mse=126.181482 step=0.100000
2017/08/29 06:12:40 step 5: mse=125.377074 step=0.100000
2017/08/29 06:12:41 step 6: mse=124.205382 step=0.100000
2017/08/29 06:12:43 step 7: mse=123.064103 step=0.100000
2017/08/29 06:12:43 Saving...
2017/08/29 06:12:43 Gathering batch of experience...
2017/08/29 06:13:28 batch 1049: mean=173.529412 stddev=132.556810 entropy=0.307498 frames=5794 count=34
2017/08/29 06:13:28 Training policy...
2017/08/29 06:13:33 step 0: objective=-0.24754524
2017/08/29 06:13:35 step 1: objective=-0.23880024
2017/08/29 06:13:38 step 2: objective=-0.23255704
2017/08/29 06:13:40 step 3: objective=-0.22681627
2017/08/29 06:13:43 step 4: objective=-0.22335285
2017/08/29 06:13:45 step 5: objective=-0.21826059
2017/08/29 06:13:48 step 6: objective=-0.21490164
2017/08/29 06:13:50 step 7: objective=-0.21309257
2017/08/29 06:13:50 Training value function...
2017/08/29 06:13:53 step 0: mse=128.399826 step=0.100000
2017/08/29 06:13:54 step 1: mse=126.855187 step=0.100000
2017/08/29 06:13:55 step 2: mse=125.800736 step=0.100000
2017/08/29 06:13:56 step 3: mse=125.065018 step=0.100000
2017/08/29 06:13:57 step 4: mse=124.726482 step=0.100000
2017/08/29 06:13:59 step 5: mse=124.334473 step=0.100000
2017/08/29 06:14:00 step 6: mse=124.190037 step=0.100000
2017/08/29 06:14:01 step 7: mse=123.669680 step=0.100000
2017/08/29 06:14:01 Saving...
2017/08/29 06:14:01 Gathering batch of experience...
2017/08/29 06:14:55 batch 1050: mean=215.060606 stddev=174.074164 entropy=0.307073 frames=6605 count=33
2017/08/29 06:14:55 Training policy...
2017/08/29 06:15:00 step 0: objective=1.8518314
2017/08/29 06:15:03 step 1: objective=1.8580312
2017/08/29 06:15:06 step 2: objective=1.8625516
2017/08/29 06:15:09 step 3: objective=1.8662668
2017/08/29 06:15:11 step 4: objective=1.8710302
2017/08/29 06:15:14 step 5: objective=1.8752472
2017/08/29 06:15:17 step 6: objective=1.8776516
2017/08/29 06:15:20 step 7: objective=1.8818353
2017/08/29 06:15:20 Training value function...
2017/08/29 06:15:23 step 0: mse=166.375682 step=0.100000
2017/08/29 06:15:24 step 1: mse=159.718977 step=0.100000
2017/08/29 06:15:25 step 2: mse=154.244769 step=0.100000
2017/08/29 06:15:27 step 3: mse=149.710377 step=0.100000
2017/08/29 06:15:28 step 4: mse=145.846317 step=0.100000
2017/08/29 06:15:30 step 5: mse=142.669149 step=0.100000
2017/08/29 06:15:31 step 6: mse=140.078686 step=0.100000
2017/08/29 06:15:32 step 7: mse=137.852335 step=0.100000
2017/08/29 06:15:32 Saving...
2017/08/29 06:15:33 Gathering batch of experience...
2017/08/29 06:16:24 batch 1051: mean=212.843750 stddev=222.333802 entropy=0.312858 frames=6467 count=32
2017/08/29 06:16:24 Training policy...
2017/08/29 06:16:29 step 0: objective=1.3686457
2017/08/29 06:16:32 step 1: objective=1.3739451
2017/08/29 06:16:35 step 2: objective=1.3796958
2017/08/29 06:16:38 step 3: objective=1.3871293
2017/08/29 06:16:40 step 4: objective=1.3906403
2017/08/29 06:16:43 step 5: objective=1.395459
2017/08/29 06:16:46 step 6: objective=1.3978477
2017/08/29 06:16:49 step 7: objective=1.4004388
2017/08/29 06:16:49 Training value function...
2017/08/29 06:16:51 step 0: mse=178.753303 step=0.100000
2017/08/29 06:16:53 step 1: mse=173.620396 step=0.100000
2017/08/29 06:16:54 step 2: mse=168.834948 step=0.100000
2017/08/29 06:16:55 step 3: mse=165.819017 step=0.100000
2017/08/29 06:16:57 step 4: mse=162.660204 step=0.100000
2017/08/29 06:16:58 step 5: mse=159.860774 step=0.100000
2017/08/29 06:17:00 step 6: mse=157.023968 step=0.100000
2017/08/29 06:17:01 step 7: mse=154.659810 step=0.100000
2017/08/29 06:17:01 Saving...
2017/08/29 06:17:01 Gathering batch of experience...
2017/08/29 06:17:44 batch 1052: mean=183.548387 stddev=129.940641 entropy=0.303348 frames=5486 count=31
2017/08/29 06:17:44 Training policy...
2017/08/29 06:17:49 step 0: objective=0.6039355
2017/08/29 06:17:51 step 1: objective=0.61677074
2017/08/29 06:17:54 step 2: objective=0.62293625
2017/08/29 06:17:56 step 3: objective=0.6285961
2017/08/29 06:17:58 step 4: objective=0.63511264
2017/08/29 06:18:00 step 5: objective=0.6403827
2017/08/29 06:18:03 step 6: objective=0.642889
2017/08/29 06:18:05 step 7: objective=0.64521223
2017/08/29 06:18:05 Training value function...
2017/08/29 06:18:07 step 0: mse=145.280028 step=0.100000
2017/08/29 06:18:09 step 1: mse=143.226140 step=0.100000
2017/08/29 06:18:10 step 2: mse=141.833201 step=0.100000
2017/08/29 06:18:11 step 3: mse=140.587443 step=0.100000
2017/08/29 06:18:12 step 4: mse=139.359155 step=0.100000
2017/08/29 06:18:13 step 5: mse=138.342363 step=0.100000
2017/08/29 06:18:14 step 6: mse=137.127318 step=0.100000
2017/08/29 06:18:15 step 7: mse=136.366124 step=0.100000
2017/08/29 06:18:15 Saving...
2017/08/29 06:18:16 Gathering batch of experience...
2017/08/29 06:19:03 batch 1053: mean=170.939394 stddev=131.822410 entropy=0.307213 frames=5318 count=33
2017/08/29 06:19:03 Training policy...
2017/08/29 06:19:08 step 0: objective=1.12491
2017/08/29 06:19:10 step 1: objective=1.1339145
2017/08/29 06:19:12 step 2: objective=1.138181
2017/08/29 06:19:14 step 3: objective=1.1424123
2017/08/29 06:19:17 step 4: objective=1.148676
2017/08/29 06:19:19 step 5: objective=1.1536703
2017/08/29 06:19:21 step 6: objective=1.1573588
2017/08/29 06:19:23 step 7: objective=1.160711
2017/08/29 06:19:23 Training value function...
2017/08/29 06:19:25 step 0: mse=155.635963 step=0.100000
2017/08/29 06:19:27 step 1: mse=153.457146 step=0.100000
2017/08/29 06:19:28 step 2: mse=151.470732 step=0.100000
2017/08/29 06:19:29 step 3: mse=149.689596 step=0.100000
2017/08/29 06:19:30 step 4: mse=148.255216 step=0.100000
2017/08/29 06:19:31 step 5: mse=146.667409 step=0.100000
2017/08/29 06:19:32 step 6: mse=145.247632 step=0.100000
2017/08/29 06:19:33 step 7: mse=144.260585 step=0.100000
2017/08/29 06:19:33 Saving...
2017/08/29 06:19:33 Gathering batch of experience...
2017/08/29 06:20:20 batch 1054: mean=188.696970 stddev=195.460216 entropy=0.309530 frames=6018 count=33
2017/08/29 06:20:20 Training policy...
2017/08/29 06:20:25 step 0: objective=1.4483564
2017/08/29 06:20:27 step 1: objective=1.4529237
2017/08/29 06:20:30 step 2: objective=1.4596411
2017/08/29 06:20:33 step 3: objective=1.4633152
2017/08/29 06:20:35 step 4: objective=1.4686645
2017/08/29 06:20:38 step 5: objective=1.4739234
2017/08/29 06:20:40 step 6: objective=1.479137
2017/08/29 06:20:43 step 7: objective=1.4817617
2017/08/29 06:20:43 Training value function...
2017/08/29 06:20:45 step 0: mse=186.608984 step=0.100000
2017/08/29 06:20:47 step 1: mse=177.991642 step=0.100000
2017/08/29 06:20:48 step 2: mse=171.079166 step=0.100000
2017/08/29 06:20:49 step 3: mse=165.453389 step=0.100000
2017/08/29 06:20:50 step 4: mse=160.469351 step=0.100000
2017/08/29 06:20:52 step 5: mse=156.594976 step=0.100000
2017/08/29 06:20:53 step 6: mse=153.169197 step=0.100000
2017/08/29 06:20:54 step 7: mse=150.540131 step=0.100000
2017/08/29 06:20:54 Saving...
2017/08/29 06:20:54 Gathering batch of experience...
2017/08/29 06:21:43 batch 1055: mean=199.969697 stddev=147.156788 entropy=0.307230 frames=6313 count=33
2017/08/29 06:21:43 Training policy...
2017/08/29 06:21:49 step 0: objective=1.210763
2017/08/29 06:21:52 step 1: objective=1.219192
2017/08/29 06:21:54 step 2: objective=1.2258669
2017/08/29 06:21:57 step 3: objective=1.2330953
2017/08/29 06:22:00 step 4: objective=1.2403098
2017/08/29 06:22:02 step 5: objective=1.2436092
2017/08/29 06:22:05 step 6: objective=1.2478706
2017/08/29 06:22:08 step 7: objective=1.2498673
2017/08/29 06:22:08 Training value function...
2017/08/29 06:22:10 step 0: mse=181.265979 step=0.100000
2017/08/29 06:22:12 step 1: mse=176.441358 step=0.100000
2017/08/29 06:22:13 step 2: mse=172.421148 step=0.100000
2017/08/29 06:22:14 step 3: mse=169.107579 step=0.100000
2017/08/29 06:22:16 step 4: mse=166.922126 step=0.100000
2017/08/29 06:22:17 step 5: mse=164.544325 step=0.100000
2017/08/29 06:22:18 step 6: mse=162.080119 step=0.100000
2017/08/29 06:22:20 step 7: mse=160.031217 step=0.100000
2017/08/29 06:22:20 Saving...
2017/08/29 06:22:20 Gathering batch of experience...
2017/08/29 06:23:06 batch 1056: mean=242.071429 stddev=160.867498 entropy=0.312419 frames=6238 count=28
2017/08/29 06:23:06 Training policy...
2017/08/29 06:23:12 step 0: objective=1.7288039
2017/08/29 06:23:14 step 1: objective=1.7344801
2017/08/29 06:23:17 step 2: objective=1.7398089
2017/08/29 06:23:20 step 3: objective=1.7434338
2017/08/29 06:23:22 step 4: objective=1.7471848
2017/08/29 06:23:25 step 5: objective=1.7496862
2017/08/29 06:23:28 step 6: objective=1.7531706
2017/08/29 06:23:30 step 7: objective=1.7590244
2017/08/29 06:23:30 Training value function...
2017/08/29 06:23:33 step 0: mse=147.996400 step=0.100000
2017/08/29 06:23:34 step 1: mse=144.740397 step=0.100000
2017/08/29 06:23:35 step 2: mse=141.760398 step=0.100000
2017/08/29 06:23:37 step 3: mse=138.737847 step=0.100000
2017/08/29 06:23:38 step 4: mse=135.989647 step=0.100000
2017/08/29 06:23:39 step 5: mse=134.047356 step=0.100000
2017/08/29 06:23:41 step 6: mse=132.300586 step=0.100000
2017/08/29 06:23:42 step 7: mse=130.697998 step=0.100000
2017/08/29 06:23:42 Saving...
2017/08/29 06:23:42 Gathering batch of experience...
2017/08/29 06:24:26 batch 1057: mean=222.520000 stddev=174.654429 entropy=0.307514 frames=5447 count=25
2017/08/29 06:24:26 Training policy...
2017/08/29 06:24:30 step 0: objective=0.5712277
2017/08/29 06:24:33 step 1: objective=0.57677096
2017/08/29 06:24:35 step 2: objective=0.581585
2017/08/29 06:24:37 step 3: objective=0.5861155
2017/08/29 06:24:40 step 4: objective=0.58933306
2017/08/29 06:24:42 step 5: objective=0.5929958
2017/08/29 06:24:44 step 6: objective=0.5967979
2017/08/29 06:24:47 step 7: objective=0.60003203
2017/08/29 06:24:47 Training value function...
2017/08/29 06:24:49 step 0: mse=140.500889 step=0.100000
2017/08/29 06:24:50 step 1: mse=136.941966 step=0.100000
2017/08/29 06:24:51 step 2: mse=134.084459 step=0.100000
2017/08/29 06:24:52 step 3: mse=131.533522 step=0.100000
2017/08/29 06:24:54 step 4: mse=129.409316 step=0.100000
2017/08/29 06:24:55 step 5: mse=127.373136 step=0.100000
2017/08/29 06:24:56 step 6: mse=125.758325 step=0.100000
2017/08/29 06:24:57 step 7: mse=124.353694 step=0.100000
2017/08/29 06:24:57 Saving...
2017/08/29 06:24:57 Gathering batch of experience...
2017/08/29 06:25:43 batch 1058: mean=177.411765 stddev=130.573423 entropy=0.305680 frames=5853 count=34
2017/08/29 06:25:43 Training policy...
2017/08/29 06:25:48 step 0: objective=0.59608275
2017/08/29 06:25:51 step 1: objective=0.59979016
2017/08/29 06:25:54 step 2: objective=0.60825336
2017/08/29 06:25:56 step 3: objective=0.61211246
2017/08/29 06:25:59 step 4: objective=0.61601895
2017/08/29 06:26:01 step 5: objective=0.6218112
2017/08/29 06:26:04 step 6: objective=0.62640345
2017/08/29 06:26:06 step 7: objective=0.6290101
2017/08/29 06:26:06 Training value function...
2017/08/29 06:26:09 step 0: mse=152.309638 step=0.100000
2017/08/29 06:26:10 step 1: mse=150.365177 step=0.100000
2017/08/29 06:26:11 step 2: mse=148.936224 step=0.100000
2017/08/29 06:26:12 step 3: mse=147.586315 step=0.100000
2017/08/29 06:26:14 step 4: mse=146.089614 step=0.100000
2017/08/29 06:26:15 step 5: mse=144.873669 step=0.100000
2017/08/29 06:26:16 step 6: mse=143.785791 step=0.100000
2017/08/29 06:26:17 step 7: mse=143.129577 step=0.100000
2017/08/29 06:26:17 Saving...
2017/08/29 06:26:17 Gathering batch of experience...
2017/08/29 06:27:08 batch 1059: mean=254.740741 stddev=196.222397 entropy=0.310608 frames=6601 count=27
2017/08/29 06:27:08 Training policy...
2017/08/29 06:27:14 step 0: objective=1.77581
2017/08/29 06:27:16 step 1: objective=1.7819113
2017/08/29 06:27:19 step 2: objective=1.785188
2017/08/29 06:27:22 step 3: objective=1.7895515
2017/08/29 06:27:25 step 4: objective=1.7962264
2017/08/29 06:27:28 step 5: objective=1.7987114
2017/08/29 06:27:31 step 6: objective=1.8017924
2017/08/29 06:27:33 step 7: objective=1.8036289
2017/08/29 06:27:33 Training value function...
2017/08/29 06:27:36 step 0: mse=174.619148 step=0.100000
2017/08/29 06:27:38 step 1: mse=168.426828 step=0.100000
2017/08/29 06:27:39 step 2: mse=163.255090 step=0.100000
2017/08/29 06:27:40 step 3: mse=158.852923 step=0.100000
2017/08/29 06:27:42 step 4: mse=155.061901 step=0.100000
2017/08/29 06:27:43 step 5: mse=151.632341 step=0.100000
2017/08/29 06:27:45 step 6: mse=148.838146 step=0.100000
2017/08/29 06:27:46 step 7: mse=146.374750 step=0.100000
2017/08/29 06:27:46 Saving...
2017/08/29 06:27:46 Gathering batch of experience...
2017/08/29 06:28:27 batch 1060: mean=175.967742 stddev=111.150141 entropy=0.302674 frames=5039 count=31
2017/08/29 06:28:27 Training policy...
2017/08/29 06:28:31 step 0: objective=0.8203108
2017/08/29 06:28:34 step 1: objective=0.83133984
2017/08/29 06:28:36 step 2: objective=0.83744335
2017/08/29 06:28:38 step 3: objective=0.8426805
2017/08/29 06:28:40 step 4: objective=0.84635156
2017/08/29 06:28:42 step 5: objective=0.85092974
2017/08/29 06:28:44 step 6: objective=0.8558181
2017/08/29 06:28:46 step 7: objective=0.86027133
2017/08/29 06:28:46 Training value function...
2017/08/29 06:28:49 step 0: mse=164.062590 step=0.100000
2017/08/29 06:28:50 step 1: mse=161.367516 step=0.100000
2017/08/29 06:28:51 step 2: mse=158.793981 step=0.100000
2017/08/29 06:28:52 step 3: mse=157.052391 step=0.100000
2017/08/29 06:28:53 step 4: mse=155.512697 step=0.100000
2017/08/29 06:28:54 step 5: mse=154.208365 step=0.100000
2017/08/29 06:28:55 step 6: mse=152.540813 step=0.100000
2017/08/29 06:28:56 step 7: mse=151.646644 step=0.100000
2017/08/29 06:28:56 Saving...
2017/08/29 06:28:56 Gathering batch of experience...
2017/08/29 06:29:38 batch 1061: mean=179.548387 stddev=125.336924 entropy=0.297797 frames=5365 count=31
2017/08/29 06:29:38 Training policy...
2017/08/29 06:29:43 step 0: objective=0.69936895
2017/08/29 06:29:45 step 1: objective=0.70372033
2017/08/29 06:29:48 step 2: objective=0.7077325
2017/08/29 06:29:50 step 3: objective=0.711064
2017/08/29 06:29:52 step 4: objective=0.71511185
2017/08/29 06:29:54 step 5: objective=0.7176377
2017/08/29 06:29:57 step 6: objective=0.72081757
2017/08/29 06:29:59 step 7: objective=0.7229778
2017/08/29 06:29:59 Training value function...
2017/08/29 06:30:01 step 0: mse=153.559756 step=0.100000
2017/08/29 06:30:02 step 1: mse=151.070465 step=0.100000
2017/08/29 06:30:03 step 2: mse=148.952608 step=0.100000
2017/08/29 06:30:05 step 3: mse=147.183165 step=0.100000
2017/08/29 06:30:06 step 4: mse=145.723847 step=0.100000
2017/08/29 06:30:07 step 5: mse=144.232334 step=0.100000
2017/08/29 06:30:08 step 6: mse=142.887525 step=0.100000
2017/08/29 06:30:09 step 7: mse=141.983428 step=0.100000
2017/08/29 06:30:09 Saving...
2017/08/29 06:30:09 Gathering batch of experience...
2017/08/29 06:30:59 batch 1062: mean=229.000000 stddev=207.160485 entropy=0.306782 frames=6318 count=30
2017/08/29 06:30:59 Training policy...
2017/08/29 06:31:04 step 0: objective=2.346966
2017/08/29 06:31:07 step 1: objective=2.3534303
2017/08/29 06:31:10 step 2: objective=2.3586035
2017/08/29 06:31:12 step 3: objective=2.3647764
2017/08/29 06:31:15 step 4: objective=2.3692095
2017/08/29 06:31:18 step 5: objective=2.3715775
2017/08/29 06:31:20 step 6: objective=2.374745
2017/08/29 06:31:23 step 7: objective=2.3773668
2017/08/29 06:31:23 Training value function...
2017/08/29 06:31:26 step 0: mse=205.900430 step=0.100000
2017/08/29 06:31:27 step 1: mse=197.812609 step=0.100000
2017/08/29 06:31:28 step 2: mse=190.555975 step=0.100000
2017/08/29 06:31:30 step 3: mse=184.546128 step=0.100000
2017/08/29 06:31:31 step 4: mse=179.460223 step=0.100000
2017/08/29 06:31:32 step 5: mse=175.091305 step=0.100000
2017/08/29 06:31:34 step 6: mse=171.140418 step=0.100000
2017/08/29 06:31:35 step 7: mse=167.980862 step=0.100000
2017/08/29 06:31:35 Saving...
2017/08/29 06:31:35 Gathering batch of experience...
2017/08/29 06:32:21 batch 1063: mean=222.555556 stddev=121.552102 entropy=0.311931 frames=5765 count=27
2017/08/29 06:32:21 Training policy...
2017/08/29 06:32:26 step 0: objective=0.69108766
2017/08/29 06:32:28 step 1: objective=0.6949939
2017/08/29 06:32:31 step 2: objective=0.6995617
2017/08/29 06:32:33 step 3: objective=0.7062114
2017/08/29 06:32:36 step 4: objective=0.7121313
2017/08/29 06:32:38 step 5: objective=0.71532667
2017/08/29 06:32:41 step 6: objective=0.71884596
2017/08/29 06:32:43 step 7: objective=0.7209434
2017/08/29 06:32:43 Training value function...
2017/08/29 06:32:46 step 0: mse=138.932951 step=0.100000
2017/08/29 06:32:47 step 1: mse=136.694110 step=0.100000
2017/08/29 06:32:48 step 2: mse=134.423565 step=0.100000
2017/08/29 06:32:49 step 3: mse=132.538137 step=0.100000
2017/08/29 06:32:51 step 4: mse=131.232821 step=0.100000
2017/08/29 06:32:52 step 5: mse=129.897811 step=0.100000
2017/08/29 06:32:53 step 6: mse=128.771069 step=0.100000
2017/08/29 06:32:54 step 7: mse=127.603214 step=0.100000
2017/08/29 06:32:54 Saving...
2017/08/29 06:32:54 Gathering batch of experience...
2017/08/29 06:33:43 batch 1064: mean=218.968750 stddev=204.782886 entropy=0.311885 frames=6489 count=32
2017/08/29 06:33:43 Training policy...
2017/08/29 06:33:48 step 0: objective=1.8205149
2017/08/29 06:33:51 step 1: objective=1.8249704
2017/08/29 06:33:54 step 2: objective=1.8291765
2017/08/29 06:33:57 step 3: objective=1.8361963
2017/08/29 06:33:59 step 4: objective=1.8426558
2017/08/29 06:34:02 step 5: objective=1.8477384
2017/08/29 06:34:05 step 6: objective=1.8501605
2017/08/29 06:34:08 step 7: objective=1.854287
2017/08/29 06:34:08 Training value function...
2017/08/29 06:34:11 step 0: mse=181.275888 step=0.100000
2017/08/29 06:34:12 step 1: mse=174.523062 step=0.100000
2017/08/29 06:34:13 step 2: mse=169.166452 step=0.100000
2017/08/29 06:34:15 step 3: mse=164.593107 step=0.100000
2017/08/29 06:34:16 step 4: mse=160.537263 step=0.100000
2017/08/29 06:34:17 step 5: mse=156.923942 step=0.100000
2017/08/29 06:34:19 step 6: mse=153.986558 step=0.100000
2017/08/29 06:34:20 step 7: mse=151.734576 step=0.100000
2017/08/29 06:34:20 Saving...
2017/08/29 06:34:20 Gathering batch of experience...
2017/08/29 06:35:17 batch 1065: mean=245.300000 stddev=181.695377 entropy=0.315163 frames=7149 count=30
2017/08/29 06:35:17 Training policy...
2017/08/29 06:35:23 step 0: objective=0.80517817
2017/08/29 06:35:26 step 1: objective=0.8092722
2017/08/29 06:35:29 step 2: objective=0.81538224
2017/08/29 06:35:32 step 3: objective=0.8185343
2017/08/29 06:35:35 step 4: objective=0.82202363
2017/08/29 06:35:38 step 5: objective=0.82739735
2017/08/29 06:35:41 step 6: objective=0.8310996
2017/08/29 06:35:44 step 7: objective=0.83363295
2017/08/29 06:35:44 Training value function...
2017/08/29 06:35:47 step 0: mse=147.523182 step=0.100000
2017/08/29 06:35:49 step 1: mse=145.973909 step=0.100000
2017/08/29 06:35:50 step 2: mse=144.753821 step=0.100000
2017/08/29 06:35:52 step 3: mse=143.944262 step=0.100000
2017/08/29 06:35:53 step 4: mse=142.888289 step=0.100000
2017/08/29 06:35:55 step 5: mse=141.578403 step=0.100000
2017/08/29 06:35:56 step 6: mse=140.699882 step=0.100000
2017/08/29 06:35:58 step 7: mse=139.709470 step=0.100000
2017/08/29 06:35:58 Saving...
2017/08/29 06:35:58 Gathering batch of experience...
2017/08/29 06:36:51 batch 1066: mean=216.558824 stddev=186.707886 entropy=0.301285 frames=7148 count=34
2017/08/29 06:36:51 Training policy...
2017/08/29 06:36:57 step 0: objective=0.8447553
2017/08/29 06:37:00 step 1: objective=0.84833163
2017/08/29 06:37:03 step 2: objective=0.8527611
2017/08/29 06:37:07 step 3: objective=0.8576492
2017/08/29 06:37:10 step 4: objective=0.8617912
2017/08/29 06:37:13 step 5: objective=0.864372
2017/08/29 06:37:16 step 6: objective=0.866586
2017/08/29 06:37:19 step 7: objective=0.8700901
2017/08/29 06:37:19 Training value function...
2017/08/29 06:37:22 step 0: mse=150.860057 step=0.100000
2017/08/29 06:37:23 step 1: mse=149.828557 step=0.100000
2017/08/29 06:37:25 step 2: mse=148.682843 step=0.100000
2017/08/29 06:37:26 step 3: mse=147.477575 step=0.100000
2017/08/29 06:37:28 step 4: mse=146.500665 step=0.100000
2017/08/29 06:37:29 step 5: mse=145.466283 step=0.100000
2017/08/29 06:37:31 step 6: mse=144.441648 step=0.100000
2017/08/29 06:37:32 step 7: mse=143.682970 step=0.100000
2017/08/29 06:37:32 Saving...
2017/08/29 06:37:32 Gathering batch of experience...
2017/08/29 06:38:20 batch 1067: mean=241.896552 stddev=174.590624 entropy=0.308319 frames=6598 count=29
2017/08/29 06:38:20 Training policy...
2017/08/29 06:38:26 step 0: objective=1.3721803
2017/08/29 06:38:29 step 1: objective=1.379969
2017/08/29 06:38:32 step 2: objective=1.3841788
2017/08/29 06:38:35 step 3: objective=1.3896617
2017/08/29 06:38:38 step 4: objective=1.3926218
2017/08/29 06:38:41 step 5: objective=1.3958418
2017/08/29 06:38:43 step 6: objective=1.3980188
2017/08/29 06:38:46 step 7: objective=1.4003122
2017/08/29 06:38:46 Training value function...
2017/08/29 06:38:49 step 0: mse=159.656214 step=0.100000
2017/08/29 06:38:50 step 1: mse=157.212312 step=0.100000
2017/08/29 06:38:52 step 2: mse=154.535459 step=0.100000
2017/08/29 06:38:53 step 3: mse=152.317153 step=0.100000
2017/08/29 06:38:55 step 4: mse=150.398009 step=0.100000
2017/08/29 06:38:56 step 5: mse=148.825718 step=0.100000
2017/08/29 06:38:57 step 6: mse=147.586840 step=0.100000
2017/08/29 06:38:59 step 7: mse=146.220190 step=0.100000
2017/08/29 06:38:59 Saving...
2017/08/29 06:38:59 Gathering batch of experience...
2017/08/29 06:39:42 batch 1068: mean=225.629630 stddev=198.068104 entropy=0.306455 frames=5744 count=27
2017/08/29 06:39:42 Training policy...
2017/08/29 06:39:47 step 0: objective=1.069834
2017/08/29 06:39:50 step 1: objective=1.0742689
2017/08/29 06:39:52 step 2: objective=1.0798295
2017/08/29 06:39:55 step 3: objective=1.0830492
2017/08/29 06:39:57 step 4: objective=1.0856245
2017/08/29 06:40:00 step 5: objective=1.0889509
2017/08/29 06:40:02 step 6: objective=1.0914478
2017/08/29 06:40:05 step 7: objective=1.0947033
2017/08/29 06:40:05 Training value function...
2017/08/29 06:40:07 step 0: mse=170.994046 step=0.100000
2017/08/29 06:40:08 step 1: mse=165.429635 step=0.100000
2017/08/29 06:40:10 step 2: mse=160.945962 step=0.100000
2017/08/29 06:40:11 step 3: mse=157.039362 step=0.100000
2017/08/29 06:40:12 step 4: mse=154.199960 step=0.100000
2017/08/29 06:40:13 step 5: mse=151.491174 step=0.100000
2017/08/29 06:40:14 step 6: mse=149.364059 step=0.100000
2017/08/29 06:40:16 step 7: mse=147.330354 step=0.100000
2017/08/29 06:40:16 Saving...
2017/08/29 06:40:16 Gathering batch of experience...
2017/08/29 06:41:03 batch 1069: mean=175.617647 stddev=162.025963 entropy=0.300829 frames=5673 count=34
2017/08/29 06:41:03 Training policy...
2017/08/29 06:41:08 step 0: objective=0.45200503
2017/08/29 06:41:10 step 1: objective=0.45976534
2017/08/29 06:41:13 step 2: objective=0.46613067
2017/08/29 06:41:15 step 3: objective=0.47126877
2017/08/29 06:41:18 step 4: objective=0.4764733
2017/08/29 06:41:20 step 5: objective=0.48055014
2017/08/29 06:41:22 step 6: objective=0.48607945
2017/08/29 06:41:25 step 7: objective=0.4895257
2017/08/29 06:41:25 Training value function...
2017/08/29 06:41:27 step 0: mse=160.851490 step=0.100000
2017/08/29 06:41:28 step 1: mse=158.497359 step=0.100000
2017/08/29 06:41:30 step 2: mse=156.930190 step=0.100000
2017/08/29 06:41:31 step 3: mse=155.455236 step=0.100000
2017/08/29 06:41:32 step 4: mse=154.387097 step=0.100000
2017/08/29 06:41:33 step 5: mse=153.502060 step=0.100000
2017/08/29 06:41:34 step 6: mse=152.459977 step=0.100000
2017/08/29 06:41:36 step 7: mse=151.850276 step=0.100000
2017/08/29 06:41:36 Saving...
2017/08/29 06:41:36 Gathering batch of experience...
2017/08/29 06:42:31 batch 1070: mean=229.000000 stddev=183.274516 entropy=0.309637 frames=6586 count=31
2017/08/29 06:42:31 Training policy...
2017/08/29 06:42:36 step 0: objective=1.6276476
2017/08/29 06:42:39 step 1: objective=1.6347232
2017/08/29 06:42:42 step 2: objective=1.6383954
2017/08/29 06:42:45 step 3: objective=1.645716
2017/08/29 06:42:48 step 4: objective=1.6503136
2017/08/29 06:42:51 step 5: objective=1.6526544
2017/08/29 06:42:53 step 6: objective=1.6548139
2017/08/29 06:42:56 step 7: objective=1.6593349
2017/08/29 06:42:56 Training value function...
2017/08/29 06:42:59 step 0: mse=169.117733 step=0.100000
2017/08/29 06:43:00 step 1: mse=164.980660 step=0.100000
2017/08/29 06:43:02 step 2: mse=161.501374 step=0.100000
2017/08/29 06:43:03 step 3: mse=158.444337 step=0.100000
2017/08/29 06:43:05 step 4: mse=155.691309 step=0.100000
2017/08/29 06:43:06 step 5: mse=153.441594 step=0.100000
2017/08/29 06:43:07 step 6: mse=151.272297 step=0.100000
2017/08/29 06:43:09 step 7: mse=149.121755 step=0.100000
2017/08/29 06:43:09 Saving...
2017/08/29 06:43:09 Gathering batch of experience...
2017/08/29 06:43:55 batch 1071: mean=181.468750 stddev=146.712726 entropy=0.306668 frames=5649 count=32
2017/08/29 06:43:55 Training policy...
2017/08/29 06:44:00 step 0: objective=0.13099355
2017/08/29 06:44:02 step 1: objective=0.13522731
2017/08/29 06:44:05 step 2: objective=0.1430994
2017/08/29 06:44:07 step 3: objective=0.14796656
2017/08/29 06:44:10 step 4: objective=0.15209562
2017/08/29 06:44:12 step 5: objective=0.1551051
2017/08/29 06:44:14 step 6: objective=0.1578048
2017/08/29 06:44:17 step 7: objective=0.16364042
2017/08/29 06:44:17 Training value function...
2017/08/29 06:44:19 step 0: mse=161.654571 step=0.100000
2017/08/29 06:44:20 step 1: mse=158.275723 step=0.100000
2017/08/29 06:44:22 step 2: mse=155.432189 step=0.100000
2017/08/29 06:44:23 step 3: mse=153.257763 step=0.100000
2017/08/29 06:44:24 step 4: mse=151.558459 step=0.100000
2017/08/29 06:44:25 step 5: mse=150.266212 step=0.100000
2017/08/29 06:44:26 step 6: mse=148.762271 step=0.100000
2017/08/29 06:44:28 step 7: mse=147.538695 step=0.100000
2017/08/29 06:44:28 Saving...
2017/08/29 06:44:28 Gathering batch of experience...
2017/08/29 06:45:17 batch 1072: mean=224.103448 stddev=188.548420 entropy=0.309713 frames=5983 count=29
2017/08/29 06:45:17 Training policy...
2017/08/29 06:45:22 step 0: objective=1.970969
2017/08/29 06:45:25 step 1: objective=1.9760222
2017/08/29 06:45:27 step 2: objective=1.9800878
2017/08/29 06:45:30 step 3: objective=1.9860066
2017/08/29 06:45:32 step 4: objective=1.9910682
2017/08/29 06:45:35 step 5: objective=1.9939188
2017/08/29 06:45:37 step 6: objective=1.99692
2017/08/29 06:45:40 step 7: objective=1.999871
2017/08/29 06:45:40 Training value function...
2017/08/29 06:45:42 step 0: mse=184.453185 step=0.100000
2017/08/29 06:45:44 step 1: mse=176.896580 step=0.100000
2017/08/29 06:45:45 step 2: mse=170.688298 step=0.100000
2017/08/29 06:45:46 step 3: mse=165.512955 step=0.100000
2017/08/29 06:45:48 step 4: mse=161.330260 step=0.100000
2017/08/29 06:45:49 step 5: mse=157.511334 step=0.100000
2017/08/29 06:45:50 step 6: mse=154.362408 step=0.100000
2017/08/29 06:45:51 step 7: mse=151.466877 step=0.100000
2017/08/29 06:45:51 Saving...
2017/08/29 06:45:52 Gathering batch of experience...
2017/08/29 06:46:38 batch 1073: mean=190.823529 stddev=167.976096 entropy=0.306867 frames=6171 count=34
2017/08/29 06:46:38 Training policy...
2017/08/29 06:46:43 step 0: objective=0.7473497
2017/08/29 06:46:46 step 1: objective=0.7567178
2017/08/29 06:46:49 step 2: objective=0.76485735
2017/08/29 06:46:52 step 3: objective=0.772143
2017/08/29 06:46:54 step 4: objective=0.7758434
2017/08/29 06:46:57 step 5: objective=0.7820084
2017/08/29 06:46:59 step 6: objective=0.7853984
2017/08/29 06:47:02 step 7: objective=0.7890827
2017/08/29 06:47:02 Training value function...
2017/08/29 06:47:05 step 0: mse=167.432702 step=0.100000
2017/08/29 06:47:06 step 1: mse=161.655111 step=0.100000
2017/08/29 06:47:07 step 2: mse=156.866274 step=0.100000
2017/08/29 06:47:09 step 3: mse=152.877907 step=0.100000
2017/08/29 06:47:10 step 4: mse=149.797018 step=0.100000
2017/08/29 06:47:11 step 5: mse=147.542039 step=0.100000
2017/08/29 06:47:13 step 6: mse=145.421510 step=0.100000
2017/08/29 06:47:14 step 7: mse=143.279903 step=0.100000
2017/08/29 06:47:14 Saving...
2017/08/29 06:47:14 Gathering batch of experience...
2017/08/29 06:48:04 batch 1074: mean=218.625000 stddev=153.107346 entropy=0.308500 frames=6781 count=32
2017/08/29 06:48:04 Training policy...
2017/08/29 06:48:10 step 0: objective=0.9260743
2017/08/29 06:48:13 step 1: objective=0.9331934
2017/08/29 06:48:16 step 2: objective=0.93777
2017/08/29 06:48:19 step 3: objective=0.9422198
2017/08/29 06:48:23 step 4: objective=0.94711614
2017/08/29 06:48:26 step 5: objective=0.95027655
2017/08/29 06:48:29 step 6: objective=0.9545261
2017/08/29 06:48:32 step 7: objective=0.9577158
2017/08/29 06:48:32 Training value function...
2017/08/29 06:48:35 step 0: mse=155.105306 step=0.100000
2017/08/29 06:48:36 step 1: mse=152.180308 step=0.100000
2017/08/29 06:48:38 step 2: mse=149.524660 step=0.100000
2017/08/29 06:48:39 step 3: mse=147.343926 step=0.100000
2017/08/29 06:48:41 step 4: mse=145.696218 step=0.100000
2017/08/29 06:48:42 step 5: mse=143.951960 step=0.100000
2017/08/29 06:48:44 step 6: mse=142.430989 step=0.100000
2017/08/29 06:48:45 step 7: mse=141.183139 step=0.100000
2017/08/29 06:48:45 Saving...
2017/08/29 06:48:45 Gathering batch of experience...
2017/08/29 06:49:42 batch 1075: mean=240.272727 stddev=216.429885 entropy=0.313771 frames=7497 count=33
2017/08/29 06:49:42 Training policy...
2017/08/29 06:49:48 step 0: objective=1.7071677
2017/08/29 06:49:51 step 1: objective=1.7124836
2017/08/29 06:49:55 step 2: objective=1.716734
2017/08/29 06:49:58 step 3: objective=1.7192906
2017/08/29 06:50:01 step 4: objective=1.7254812
2017/08/29 06:50:04 step 5: objective=1.728036
2017/08/29 06:50:08 step 6: objective=1.7318456
2017/08/29 06:50:11 step 7: objective=1.733684
2017/08/29 06:50:11 Training value function...
2017/08/29 06:50:14 step 0: mse=178.644701 step=0.100000
2017/08/29 06:50:16 step 1: mse=173.776274 step=0.100000
2017/08/29 06:50:17 step 2: mse=169.582886 step=0.100000
2017/08/29 06:50:19 step 3: mse=166.018290 step=0.100000
2017/08/29 06:50:20 step 4: mse=163.179382 step=0.100000
2017/08/29 06:50:22 step 5: mse=160.554952 step=0.100000
2017/08/29 06:50:24 step 6: mse=158.161405 step=0.100000
2017/08/29 06:50:25 step 7: mse=156.047951 step=0.100000
2017/08/29 06:50:25 Saving...
2017/08/29 06:50:25 Gathering batch of experience...
2017/08/29 06:51:23 batch 1076: mean=229.031250 stddev=175.608493 entropy=0.309979 frames=7008 count=32
2017/08/29 06:51:23 Training policy...
2017/08/29 06:51:29 step 0: objective=0.8767226
2017/08/29 06:51:32 step 1: objective=0.882857
2017/08/29 06:51:35 step 2: objective=0.88600224
2017/08/29 06:51:38 step 3: objective=0.889547
2017/08/29 06:51:41 step 4: objective=0.8920407
2017/08/29 06:51:44 step 5: objective=0.89472044
2017/08/29 06:51:47 step 6: objective=0.89699167
2017/08/29 06:51:50 step 7: objective=0.8993485
2017/08/29 06:51:50 Training value function...
2017/08/29 06:51:53 step 0: mse=141.604925 step=0.100000
2017/08/29 06:51:55 step 1: mse=140.127285 step=0.100000
2017/08/29 06:51:56 step 2: mse=139.023234 step=0.100000
2017/08/29 06:51:58 step 3: mse=138.111214 step=0.100000
2017/08/29 06:51:59 step 4: mse=137.158446 step=0.100000
2017/08/29 06:52:01 step 5: mse=136.277597 step=0.100000
2017/08/29 06:52:02 step 6: mse=135.443882 step=0.100000
2017/08/29 06:52:04 step 7: mse=134.674493 step=0.100000
2017/08/29 06:52:04 Saving...
2017/08/29 06:52:04 Gathering batch of experience...
2017/08/29 06:52:53 batch 1077: mean=235.896552 stddev=176.164763 entropy=0.306773 frames=6809 count=29
2017/08/29 06:52:53 Training policy...
2017/08/29 06:52:59 step 0: objective=0.66430104
2017/08/29 06:53:02 step 1: objective=0.66683155
2017/08/29 06:53:05 step 2: objective=0.6692723
2017/08/29 06:53:08 step 3: objective=0.67314786
2017/08/29 06:53:10 step 4: objective=0.6767744
2017/08/29 06:53:13 step 5: objective=0.6795893
2017/08/29 06:53:16 step 6: objective=0.683569
2017/08/29 06:53:19 step 7: objective=0.6868395
2017/08/29 06:53:19 Training value function...
2017/08/29 06:53:22 step 0: mse=142.138743 step=0.100000
2017/08/29 06:53:24 step 1: mse=141.206219 step=0.100000
2017/08/29 06:53:25 step 2: mse=140.018628 step=0.100000
2017/08/29 06:53:27 step 3: mse=139.267406 step=0.100000
2017/08/29 06:53:28 step 4: mse=138.350952 step=0.100000
2017/08/29 06:53:29 step 5: mse=137.731189 step=0.100000
2017/08/29 06:53:31 step 6: mse=137.296199 step=0.100000
2017/08/29 06:53:32 step 7: mse=136.509945 step=0.100000
2017/08/29 06:53:32 Saving...
2017/08/29 06:53:32 Gathering batch of experience...
2017/08/29 06:54:26 batch 1078: mean=236.096774 stddev=165.123679 entropy=0.307537 frames=6918 count=31
2017/08/29 06:54:26 Training policy...
2017/08/29 06:54:32 step 0: objective=1.2431164
2017/08/29 06:54:35 step 1: objective=1.2485874
2017/08/29 06:54:38 step 2: objective=1.2523627
2017/08/29 06:54:41 step 3: objective=1.2554706
2017/08/29 06:54:44 step 4: objective=1.2577739
2017/08/29 06:54:47 step 5: objective=1.261212
2017/08/29 06:54:50 step 6: objective=1.2631098
2017/08/29 06:54:53 step 7: objective=1.266777
2017/08/29 06:54:53 Training value function...
2017/08/29 06:54:56 step 0: mse=157.990713 step=0.100000
2017/08/29 06:54:57 step 1: mse=155.961977 step=0.100000
2017/08/29 06:54:59 step 2: mse=154.055479 step=0.100000
2017/08/29 06:55:00 step 3: mse=152.543706 step=0.100000
2017/08/29 06:55:01 step 4: mse=150.945744 step=0.100000
2017/08/29 06:55:03 step 5: mse=149.719962 step=0.100000
2017/08/29 06:55:04 step 6: mse=148.320954 step=0.100000
2017/08/29 06:55:06 step 7: mse=146.889243 step=0.100000
2017/08/29 06:55:06 Saving...
2017/08/29 06:55:06 Gathering batch of experience...
2017/08/29 06:55:56 batch 1079: mean=182.828571 stddev=186.527744 entropy=0.303086 frames=6195 count=35
2017/08/29 06:55:56 Training policy...
2017/08/29 06:56:02 step 0: objective=0.6724129
2017/08/29 06:56:04 step 1: objective=0.679334
2017/08/29 06:56:07 step 2: objective=0.68562454
2017/08/29 06:56:10 step 3: objective=0.68983334
2017/08/29 06:56:12 step 4: objective=0.69469875
2017/08/29 06:56:15 step 5: objective=0.7012664
2017/08/29 06:56:18 step 6: objective=0.7047661
2017/08/29 06:56:20 step 7: objective=0.7065941
2017/08/29 06:56:20 Training value function...
2017/08/29 06:56:23 step 0: mse=159.600807 step=0.100000
2017/08/29 06:56:24 step 1: mse=157.807292 step=0.100000
2017/08/29 06:56:26 step 2: mse=156.638778 step=0.100000
2017/08/29 06:56:27 step 3: mse=155.301525 step=0.100000
2017/08/29 06:56:28 step 4: mse=154.532868 step=0.100000
2017/08/29 06:56:30 step 5: mse=153.201560 step=0.100000
2017/08/29 06:56:31 step 6: mse=152.420708 step=0.100000
2017/08/29 06:56:32 step 7: mse=151.142431 step=0.100000
2017/08/29 06:56:32 Saving...
2017/08/29 06:56:32 Gathering batch of experience...
2017/08/29 06:57:23 batch 1080: mean=232.300000 stddev=222.746066 entropy=0.305984 frames=6582 count=30
2017/08/29 06:57:23 Training policy...
2017/08/29 06:57:29 step 0: objective=1.6184679
2017/08/29 06:57:32 step 1: objective=1.6231328
2017/08/29 06:57:35 step 2: objective=1.6278292
2017/08/29 06:57:37 step 3: objective=1.6313266
2017/08/29 06:57:40 step 4: objective=1.6338174
2017/08/29 06:57:43 step 5: objective=1.6388906
2017/08/29 06:57:46 step 6: objective=1.6409318
2017/08/29 06:57:49 step 7: objective=1.6444591
2017/08/29 06:57:49 Training value function...
2017/08/29 06:57:52 step 0: mse=159.817757 step=0.100000
2017/08/29 06:57:53 step 1: mse=156.173490 step=0.100000
2017/08/29 06:57:54 step 2: mse=153.064214 step=0.100000
2017/08/29 06:57:56 step 3: mse=150.146215 step=0.100000
2017/08/29 06:57:57 step 4: mse=148.058726 step=0.100000
2017/08/29 06:57:59 step 5: mse=145.700082 step=0.100000
2017/08/29 06:58:00 step 6: mse=143.900531 step=0.100000
2017/08/29 06:58:01 step 7: mse=142.003333 step=0.100000
2017/08/29 06:58:01 Saving...
2017/08/29 06:58:02 Gathering batch of experience...
2017/08/29 06:58:54 batch 1081: mean=202.972222 stddev=179.246802 entropy=0.306089 frames=6869 count=36
2017/08/29 06:58:54 Training policy...
2017/08/29 06:59:00 step 0: objective=0.9926869
2017/08/29 06:59:03 step 1: objective=0.9988847
2017/08/29 06:59:06 step 2: objective=1.0042982
2017/08/29 06:59:09 step 3: objective=1.0108871
2017/08/29 06:59:12 step 4: objective=1.0158575
2017/08/29 06:59:15 step 5: objective=1.0207862
2017/08/29 06:59:18 step 6: objective=1.0262831
2017/08/29 06:59:21 step 7: objective=1.0302382
2017/08/29 06:59:21 Training value function...
2017/08/29 06:59:24 step 0: mse=168.343153 step=0.100000
2017/08/29 06:59:25 step 1: mse=166.514865 step=0.100000
2017/08/29 06:59:27 step 2: mse=165.024892 step=0.100000
2017/08/29 06:59:28 step 3: mse=163.518415 step=0.100000
2017/08/29 06:59:30 step 4: mse=162.098364 step=0.100000
2017/08/29 06:59:31 step 5: mse=160.992789 step=0.100000
2017/08/29 06:59:33 step 6: mse=159.426399 step=0.100000
2017/08/29 06:59:34 step 7: mse=158.771467 step=0.100000
2017/08/29 06:59:34 Saving...
2017/08/29 06:59:34 Gathering batch of experience...
2017/08/29 07:00:30 batch 1082: mean=251.400000 stddev=156.116111 entropy=0.300927 frames=6877 count=30
2017/08/29 07:00:30 Training policy...
2017/08/29 07:00:36 step 0: objective=1.6010157
2017/08/29 07:00:39 step 1: objective=1.607441
2017/08/29 07:00:42 step 2: objective=1.6140662
2017/08/29 07:00:45 step 3: objective=1.6174494
2017/08/29 07:00:48 step 4: objective=1.621767
2017/08/29 07:00:51 step 5: objective=1.6262624
2017/08/29 07:00:54 step 6: objective=1.6285645
2017/08/29 07:00:57 step 7: objective=1.6324823
2017/08/29 07:00:57 Training value function...
2017/08/29 07:01:00 step 0: mse=159.770866 step=0.100000
2017/08/29 07:01:01 step 1: mse=156.586288 step=0.100000
2017/08/29 07:01:02 step 2: mse=154.130469 step=0.100000
2017/08/29 07:01:04 step 3: mse=151.831920 step=0.100000
2017/08/29 07:01:05 step 4: mse=149.798755 step=0.100000
2017/08/29 07:01:07 step 5: mse=148.096750 step=0.100000
2017/08/29 07:01:08 step 6: mse=146.531135 step=0.100000
2017/08/29 07:01:10 step 7: mse=145.099091 step=0.100000
2017/08/29 07:01:10 Saving...
2017/08/29 07:01:10 Gathering batch of experience...
2017/08/29 07:01:51 batch 1083: mean=174.100000 stddev=137.583756 entropy=0.297062 frames=5083 count=30
2017/08/29 07:01:51 Training policy...
2017/08/29 07:01:55 step 0: objective=-0.20358972
2017/08/29 07:01:58 step 1: objective=-0.19597106
2017/08/29 07:02:00 step 2: objective=-0.19198014
2017/08/29 07:02:02 step 3: objective=-0.18698896
2017/08/29 07:02:04 step 4: objective=-0.18284367
2017/08/29 07:02:07 step 5: objective=-0.1787763
2017/08/29 07:02:09 step 6: objective=-0.17527199
2017/08/29 07:02:11 step 7: objective=-0.17294106
2017/08/29 07:02:11 Training value function...
2017/08/29 07:02:13 step 0: mse=148.673435 step=0.100000
2017/08/29 07:02:14 step 1: mse=146.702738 step=0.100000
2017/08/29 07:02:15 step 2: mse=145.108824 step=0.100000
2017/08/29 07:02:16 step 3: mse=143.937697 step=0.100000
2017/08/29 07:02:17 step 4: mse=142.946520 step=0.100000
2017/08/29 07:02:18 step 5: mse=141.554683 step=0.100000
2017/08/29 07:02:19 step 6: mse=140.707599 step=0.100000
2017/08/29 07:02:21 step 7: mse=139.570968 step=0.100000
2017/08/29 07:02:21 Saving...
2017/08/29 07:02:21 Gathering batch of experience...
2017/08/29 07:03:14 batch 1084: mean=191.916667 stddev=168.873617 entropy=0.299568 frames=6722 count=36
2017/08/29 07:03:14 Training policy...
2017/08/29 07:03:20 step 0: objective=0.97805005
2017/08/29 07:03:22 step 1: objective=0.98329955
2017/08/29 07:03:25 step 2: objective=0.9877269
2017/08/29 07:03:28 step 3: objective=0.9923691
2017/08/29 07:03:31 step 4: objective=0.9961735
2017/08/29 07:03:34 step 5: objective=0.9997259
2017/08/29 07:03:37 step 6: objective=1.001638
2017/08/29 07:03:40 step 7: objective=1.0036079
2017/08/29 07:03:40 Training value function...
2017/08/29 07:03:43 step 0: mse=153.888762 step=0.100000
2017/08/29 07:03:44 step 1: mse=150.491644 step=0.100000
2017/08/29 07:03:46 step 2: mse=147.859813 step=0.100000
2017/08/29 07:03:47 step 3: mse=145.607133 step=0.100000
2017/08/29 07:03:48 step 4: mse=143.554041 step=0.100000
2017/08/29 07:03:50 step 5: mse=141.841271 step=0.100000
2017/08/29 07:03:51 step 6: mse=140.329659 step=0.100000
2017/08/29 07:03:53 step 7: mse=139.074611 step=0.100000
2017/08/29 07:03:53 Saving...
2017/08/29 07:03:53 Gathering batch of experience...
2017/08/29 07:04:43 batch 1085: mean=187.764706 stddev=151.576628 entropy=0.304823 frames=6130 count=34
2017/08/29 07:04:43 Training policy...
2017/08/29 07:04:49 step 0: objective=0.93841517
2017/08/29 07:04:51 step 1: objective=0.946292
2017/08/29 07:04:54 step 2: objective=0.9513521
2017/08/29 07:04:57 step 3: objective=0.95644754
2017/08/29 07:04:59 step 4: objective=0.961629
2017/08/29 07:05:02 step 5: objective=0.9643604
2017/08/29 07:05:05 step 6: objective=0.9699375
2017/08/29 07:05:07 step 7: objective=0.9725764
2017/08/29 07:05:07 Training value function...
2017/08/29 07:05:10 step 0: mse=183.259673 step=0.100000
2017/08/29 07:05:11 step 1: mse=178.766419 step=0.100000
2017/08/29 07:05:13 step 2: mse=175.526507 step=0.100000
2017/08/29 07:05:14 step 3: mse=172.610311 step=0.100000
2017/08/29 07:05:15 step 4: mse=170.385414 step=0.100000
2017/08/29 07:05:16 step 5: mse=168.096931 step=0.100000
2017/08/29 07:05:18 step 6: mse=166.291563 step=0.100000
2017/08/29 07:05:19 step 7: mse=164.643688 step=0.100000
2017/08/29 07:05:19 Saving...
2017/08/29 07:05:19 Gathering batch of experience...
2017/08/29 07:06:10 batch 1086: mean=309.521739 stddev=225.216972 entropy=0.308331 frames=6622 count=23
2017/08/29 07:06:10 Training policy...
2017/08/29 07:06:16 step 0: objective=2.1091297
2017/08/29 07:06:19 step 1: objective=2.1139426
2017/08/29 07:06:22 step 2: objective=2.120029
2017/08/29 07:06:24 step 3: objective=2.1233103
2017/08/29 07:06:27 step 4: objective=2.12882
2017/08/29 07:06:30 step 5: objective=2.1317983
2017/08/29 07:06:33 step 6: objective=2.1370542
2017/08/29 07:06:36 step 7: objective=2.1400237
2017/08/29 07:06:36 Training value function...
2017/08/29 07:06:39 step 0: mse=198.170009 step=0.100000
2017/08/29 07:06:40 step 1: mse=190.871571 step=0.100000
2017/08/29 07:06:42 step 2: mse=184.664641 step=0.100000
2017/08/29 07:06:43 step 3: mse=178.698792 step=0.100000
2017/08/29 07:06:44 step 4: mse=174.030274 step=0.100000
2017/08/29 07:06:46 step 5: mse=170.115572 step=0.100000
2017/08/29 07:06:47 step 6: mse=166.767161 step=0.100000
2017/08/29 07:06:49 step 7: mse=163.904924 step=0.100000
2017/08/29 07:06:49 Saving...
2017/08/29 07:06:49 Gathering batch of experience...
2017/08/29 07:07:36 batch 1087: mean=224.600000 stddev=179.047033 entropy=0.305876 frames=6193 count=30
2017/08/29 07:07:36 Training policy...
2017/08/29 07:07:42 step 0: objective=1.0976136
2017/08/29 07:07:44 step 1: objective=1.1055362
2017/08/29 07:07:47 step 2: objective=1.1118075
2017/08/29 07:07:50 step 3: objective=1.1161444
2017/08/29 07:07:53 step 4: objective=1.1185892
2017/08/29 07:07:55 step 5: objective=1.1224107
2017/08/29 07:07:58 step 6: objective=1.1251719
2017/08/29 07:08:01 step 7: objective=1.1270592
2017/08/29 07:08:01 Training value function...
2017/08/29 07:08:03 step 0: mse=150.140161 step=0.100000
2017/08/29 07:08:05 step 1: mse=147.701309 step=0.100000
2017/08/29 07:08:06 step 2: mse=145.607480 step=0.100000
2017/08/29 07:08:07 step 3: mse=143.795241 step=0.100000
2017/08/29 07:08:09 step 4: mse=142.256170 step=0.100000
2017/08/29 07:08:10 step 5: mse=140.967043 step=0.100000
2017/08/29 07:08:11 step 6: mse=140.032720 step=0.100000
2017/08/29 07:08:13 step 7: mse=138.760589 step=0.100000
2017/08/29 07:08:13 Saving...
2017/08/29 07:08:13 Gathering batch of experience...
2017/08/29 07:08:59 batch 1088: mean=192.866667 stddev=171.320311 entropy=0.301685 frames=5744 count=30
2017/08/29 07:08:59 Training policy...
2017/08/29 07:09:04 step 0: objective=0.105508946
2017/08/29 07:09:06 step 1: objective=0.11125956
2017/08/29 07:09:09 step 2: objective=0.11746921
2017/08/29 07:09:11 step 3: objective=0.12018662
2017/08/29 07:09:14 step 4: objective=0.12632196
2017/08/29 07:09:16 step 5: objective=0.12991142
2017/08/29 07:09:19 step 6: objective=0.13251612
2017/08/29 07:09:21 step 7: objective=0.13466479
2017/08/29 07:09:21 Training value function...
2017/08/29 07:09:24 step 0: mse=126.022791 step=0.100000
2017/08/29 07:09:25 step 1: mse=124.326041 step=0.100000
2017/08/29 07:09:26 step 2: mse=122.855770 step=0.100000
2017/08/29 07:09:28 step 3: mse=121.557513 step=0.100000
2017/08/29 07:09:29 step 4: mse=120.954663 step=0.100000
2017/08/29 07:09:30 step 5: mse=120.653552 step=0.100000
2017/08/29 07:09:31 step 6: mse=119.906448 step=0.100000
2017/08/29 07:09:32 step 7: mse=119.197611 step=0.100000
2017/08/29 07:09:32 Saving...
2017/08/29 07:09:33 Gathering batch of experience...
2017/08/29 07:10:24 batch 1089: mean=262.461538 stddev=173.201135 entropy=0.305946 frames=6595 count=26
2017/08/29 07:10:24 Training policy...
2017/08/29 07:10:30 step 0: objective=1.3591357
2017/08/29 07:10:33 step 1: objective=1.3618147
2017/08/29 07:10:36 step 2: objective=1.3655602
2017/08/29 07:10:38 step 3: objective=1.3687509
2017/08/29 07:10:41 step 4: objective=1.3729875
2017/08/29 07:10:44 step 5: objective=1.3748268
2017/08/29 07:10:47 step 6: objective=1.3771834
2017/08/29 07:10:50 step 7: objective=1.3806753
2017/08/29 07:10:50 Training value function...
2017/08/29 07:10:53 step 0: mse=165.758785 step=0.100000
2017/08/29 07:10:54 step 1: mse=163.317743 step=0.100000
2017/08/29 07:10:56 step 2: mse=161.099220 step=0.100000
2017/08/29 07:10:57 step 3: mse=158.978777 step=0.100000
2017/08/29 07:10:58 step 4: mse=156.926395 step=0.100000
2017/08/29 07:11:00 step 5: mse=155.250667 step=0.100000
2017/08/29 07:11:01 step 6: mse=153.676072 step=0.100000
2017/08/29 07:11:03 step 7: mse=152.519572 step=0.100000
2017/08/29 07:11:03 Saving...
2017/08/29 07:11:03 Gathering batch of experience...
2017/08/29 07:11:49 batch 1090: mean=194.531250 stddev=183.613552 entropy=0.306231 frames=5883 count=32
2017/08/29 07:11:49 Training policy...
2017/08/29 07:11:54 step 0: objective=0.9618005
2017/08/29 07:11:57 step 1: objective=0.96853656
2017/08/29 07:12:00 step 2: objective=0.9761569
2017/08/29 07:12:02 step 3: objective=0.98400307
2017/08/29 07:12:05 step 4: objective=0.9900261
2017/08/29 07:12:07 step 5: objective=0.99616
2017/08/29 07:12:10 step 6: objective=1.0011972
2017/08/29 07:12:13 step 7: objective=1.0060784
2017/08/29 07:12:13 Training value function...
2017/08/29 07:12:15 step 0: mse=181.938112 step=0.100000
2017/08/29 07:12:16 step 1: mse=178.693733 step=0.100000
2017/08/29 07:12:17 step 2: mse=175.676972 step=0.100000
2017/08/29 07:12:19 step 3: mse=173.189970 step=0.100000
2017/08/29 07:12:20 step 4: mse=170.294995 step=0.100000
2017/08/29 07:12:21 step 5: mse=168.317981 step=0.100000
2017/08/29 07:12:22 step 6: mse=166.166402 step=0.100000
2017/08/29 07:12:24 step 7: mse=164.788602 step=0.100000
2017/08/29 07:12:24 Saving...
2017/08/29 07:12:24 Gathering batch of experience...
2017/08/29 07:13:18 batch 1091: mean=291.958333 stddev=202.147322 entropy=0.308784 frames=6169 count=24
2017/08/29 07:13:18 Training policy...
2017/08/29 07:13:23 step 0: objective=2.3239722
2017/08/29 07:13:26 step 1: objective=2.3308802
2017/08/29 07:13:28 step 2: objective=2.3397229
2017/08/29 07:13:31 step 3: objective=2.3437483
2017/08/29 07:13:34 step 4: objective=2.349366
2017/08/29 07:13:36 step 5: objective=2.3522232
2017/08/29 07:13:39 step 6: objective=2.354559
2017/08/29 07:13:42 step 7: objective=2.3572593
2017/08/29 07:13:42 Training value function...
2017/08/29 07:13:44 step 0: mse=178.023956 step=0.100000
2017/08/29 07:13:46 step 1: mse=171.047973 step=0.100000
2017/08/29 07:13:47 step 2: mse=164.961102 step=0.100000
2017/08/29 07:13:48 step 3: mse=159.847106 step=0.100000
2017/08/29 07:13:50 step 4: mse=155.516357 step=0.100000
2017/08/29 07:13:51 step 5: mse=151.855421 step=0.100000
2017/08/29 07:13:52 step 6: mse=148.639802 step=0.100000
2017/08/29 07:13:54 step 7: mse=145.613746 step=0.100000
2017/08/29 07:13:54 Saving...
2017/08/29 07:13:54 Gathering batch of experience...
2017/08/29 07:14:44 batch 1092: mean=254.000000 stddev=179.037706 entropy=0.301038 frames=6633 count=28
2017/08/29 07:14:44 Training policy...
2017/08/29 07:14:50 step 0: objective=0.6493464
2017/08/29 07:14:53 step 1: objective=0.65331197
2017/08/29 07:14:56 step 2: objective=0.65963095
2017/08/29 07:14:59 step 3: objective=0.6642276
2017/08/29 07:15:02 step 4: objective=0.66746336
2017/08/29 07:15:05 step 5: objective=0.67013204
2017/08/29 07:15:08 step 6: objective=0.67238677
2017/08/29 07:15:11 step 7: objective=0.674507
2017/08/29 07:15:11 Training value function...
2017/08/29 07:15:13 step 0: mse=136.676739 step=0.100000
2017/08/29 07:15:15 step 1: mse=134.698712 step=0.100000
2017/08/29 07:15:16 step 2: mse=132.664861 step=0.100000
2017/08/29 07:15:18 step 3: mse=131.462312 step=0.100000
2017/08/29 07:15:19 step 4: mse=130.259110 step=0.100000
2017/08/29 07:15:20 step 5: mse=129.067718 step=0.100000
2017/08/29 07:15:22 step 6: mse=128.192938 step=0.100000
2017/08/29 07:15:23 step 7: mse=127.388624 step=0.100000
2017/08/29 07:15:23 Saving...
2017/08/29 07:15:23 Gathering batch of experience...
2017/08/29 07:16:08 batch 1093: mean=190.437500 stddev=166.829055 entropy=0.295884 frames=5529 count=32
2017/08/29 07:16:08 Training policy...
2017/08/29 07:16:13 step 0: objective=0.69868845
2017/08/29 07:16:16 step 1: objective=0.70475435
2017/08/29 07:16:18 step 2: objective=0.7103123
2017/08/29 07:16:21 step 3: objective=0.7141318
2017/08/29 07:16:23 step 4: objective=0.72119266
2017/08/29 07:16:25 step 5: objective=0.72917795
2017/08/29 07:16:28 step 6: objective=0.7325255
2017/08/29 07:16:30 step 7: objective=0.7358118
2017/08/29 07:16:30 Training value function...
2017/08/29 07:16:33 step 0: mse=203.105526 step=0.100000
2017/08/29 07:16:34 step 1: mse=201.248673 step=0.100000
2017/08/29 07:16:35 step 2: mse=199.365905 step=0.100000
2017/08/29 07:16:36 step 3: mse=198.279924 step=0.100000
2017/08/29 07:16:37 step 4: mse=196.598046 step=0.100000
2017/08/29 07:16:38 step 5: mse=195.544680 step=0.100000
2017/08/29 07:16:40 step 6: mse=194.267583 step=0.100000
2017/08/29 07:16:41 step 7: mse=193.227647 step=0.100000
2017/08/29 07:16:41 Saving...
2017/08/29 07:16:41 Gathering batch of experience...
2017/08/29 07:17:29 batch 1094: mean=214.218750 stddev=189.826851 entropy=0.304316 frames=6071 count=32
2017/08/29 07:17:29 Training policy...
2017/08/29 07:17:35 step 0: objective=1.5669824
2017/08/29 07:17:37 step 1: objective=1.5727459
2017/08/29 07:17:40 step 2: objective=1.5777936
2017/08/29 07:17:43 step 3: objective=1.5815892
2017/08/29 07:17:45 step 4: objective=1.5889553
2017/08/29 07:17:48 step 5: objective=1.5938015
2017/08/29 07:17:51 step 6: objective=1.5987335
2017/08/29 07:17:53 step 7: objective=1.6020235
2017/08/29 07:17:53 Training value function...
2017/08/29 07:17:56 step 0: mse=193.801730 step=0.100000
2017/08/29 07:17:57 step 1: mse=188.450016 step=0.100000
2017/08/29 07:17:58 step 2: mse=183.780040 step=0.100000
2017/08/29 07:18:00 step 3: mse=180.014074 step=0.100000
2017/08/29 07:18:01 step 4: mse=176.639522 step=0.100000
2017/08/29 07:18:02 step 5: mse=173.382030 step=0.100000
2017/08/29 07:18:04 step 6: mse=170.940965 step=0.100000
2017/08/29 07:18:05 step 7: mse=168.868743 step=0.100000
2017/08/29 07:18:05 Saving...
2017/08/29 07:18:05 Gathering batch of experience...
2017/08/29 07:18:53 batch 1095: mean=213.468750 stddev=147.736037 entropy=0.308338 frames=6271 count=32
2017/08/29 07:18:53 Training policy...
2017/08/29 07:18:59 step 0: objective=0.73706144
2017/08/29 07:19:01 step 1: objective=0.74092877
2017/08/29 07:19:04 step 2: objective=0.74638253
2017/08/29 07:19:07 step 3: objective=0.7498701
2017/08/29 07:19:10 step 4: objective=0.7547451
2017/08/29 07:19:12 step 5: objective=0.75882643
2017/08/29 07:19:15 step 6: objective=0.76247716
2017/08/29 07:19:18 step 7: objective=0.768623
2017/08/29 07:19:18 Training value function...
2017/08/29 07:19:20 step 0: mse=161.962782 step=0.100000
2017/08/29 07:19:22 step 1: mse=160.107946 step=0.100000
2017/08/29 07:19:23 step 2: mse=158.183070 step=0.100000
2017/08/29 07:19:24 step 3: mse=156.790925 step=0.100000
2017/08/29 07:19:26 step 4: mse=155.282856 step=0.100000
2017/08/29 07:19:27 step 5: mse=154.237200 step=0.100000
2017/08/29 07:19:28 step 6: mse=152.958125 step=0.100000
2017/08/29 07:19:30 step 7: mse=151.963302 step=0.100000
2017/08/29 07:19:30 Saving...
2017/08/29 07:19:30 Gathering batch of experience...
2017/08/29 07:20:19 batch 1096: mean=207.781250 stddev=148.665256 entropy=0.298460 frames=6137 count=32
2017/08/29 07:20:19 Training policy...
2017/08/29 07:20:24 step 0: objective=0.86493945
2017/08/29 07:20:27 step 1: objective=0.87008303
2017/08/29 07:20:30 step 2: objective=0.87915903
2017/08/29 07:20:33 step 3: objective=0.88576573
2017/08/29 07:20:35 step 4: objective=0.88972
2017/08/29 07:20:38 step 5: objective=0.8931975
2017/08/29 07:20:41 step 6: objective=0.8954555
2017/08/29 07:20:43 step 7: objective=0.89997226
2017/08/29 07:20:43 Training value function...
2017/08/29 07:20:46 step 0: mse=159.035109 step=0.100000
2017/08/29 07:20:47 step 1: mse=156.472567 step=0.100000
2017/08/29 07:20:48 step 2: mse=154.322736 step=0.100000
2017/08/29 07:20:50 step 3: mse=152.205422 step=0.100000
2017/08/29 07:20:51 step 4: mse=150.563235 step=0.100000
2017/08/29 07:20:52 step 5: mse=148.927923 step=0.100000
2017/08/29 07:20:54 step 6: mse=147.658464 step=0.100000
2017/08/29 07:20:55 step 7: mse=146.471399 step=0.100000
2017/08/29 07:20:55 Saving...
2017/08/29 07:20:55 Gathering batch of experience...
2017/08/29 07:21:43 batch 1097: mean=203.218750 stddev=161.085136 entropy=0.295784 frames=6433 count=32
2017/08/29 07:21:43 Training policy...
2017/08/29 07:21:49 step 0: objective=0.2776515
2017/08/29 07:21:52 step 1: objective=0.283254
2017/08/29 07:21:55 step 2: objective=0.2895065
2017/08/29 07:21:57 step 3: objective=0.2935613
2017/08/29 07:22:00 step 4: objective=0.29704243
2017/08/29 07:22:03 step 5: objective=0.29955685
2017/08/29 07:22:06 step 6: objective=0.30195382
2017/08/29 07:22:09 step 7: objective=0.30732906
2017/08/29 07:22:09 Training value function...
2017/08/29 07:22:11 step 0: mse=137.914644 step=0.100000
2017/08/29 07:22:13 step 1: mse=136.438097 step=0.100000
2017/08/29 07:22:14 step 2: mse=135.272784 step=0.100000
2017/08/29 07:22:15 step 3: mse=134.292794 step=0.100000
2017/08/29 07:22:17 step 4: mse=133.419514 step=0.100000
2017/08/29 07:22:18 step 5: mse=132.576361 step=0.100000
2017/08/29 07:22:20 step 6: mse=131.876875 step=0.100000
2017/08/29 07:22:21 step 7: mse=131.168629 step=0.100000
2017/08/29 07:22:21 Saving...
2017/08/29 07:22:21 Gathering batch of experience...
2017/08/29 07:23:17 batch 1098: mean=264.758621 stddev=182.604086 entropy=0.303199 frames=7292 count=29
2017/08/29 07:23:17 Training policy...
2017/08/29 07:23:24 step 0: objective=1.608422
2017/08/29 07:23:27 step 1: objective=1.6110777
2017/08/29 07:23:30 step 2: objective=1.6147501
2017/08/29 07:23:33 step 3: objective=1.6179236
2017/08/29 07:23:36 step 4: objective=1.6211069
2017/08/29 07:23:40 step 5: objective=1.62319
2017/08/29 07:23:43 step 6: objective=1.6253767
2017/08/29 07:23:46 step 7: objective=1.6278515
2017/08/29 07:23:46 Training value function...
2017/08/29 07:23:49 step 0: mse=138.644793 step=0.100000
2017/08/29 07:23:51 step 1: mse=136.042536 step=0.100000
2017/08/29 07:23:52 step 2: mse=133.803572 step=0.100000
2017/08/29 07:23:54 step 3: mse=131.823507 step=0.100000
2017/08/29 07:23:55 step 4: mse=129.953204 step=0.100000
2017/08/29 07:23:57 step 5: mse=128.379614 step=0.100000
2017/08/29 07:23:58 step 6: mse=126.812117 step=0.100000
2017/08/29 07:24:00 step 7: mse=125.435067 step=0.100000
2017/08/29 07:24:00 Saving...
2017/08/29 07:24:00 Gathering batch of experience...
2017/08/29 07:24:50 batch 1099: mean=191.250000 stddev=167.148200 entropy=0.298572 frames=6340 count=36
2017/08/29 07:24:50 Training policy...
2017/08/29 07:24:56 step 0: objective=0.9417034
2017/08/29 07:24:58 step 1: objective=0.9480565
2017/08/29 07:25:01 step 2: objective=0.95333403
2017/08/29 07:25:04 step 3: objective=0.96121496
2017/08/29 07:25:07 step 4: objective=0.9659459
2017/08/29 07:25:09 step 5: objective=0.97073376
2017/08/29 07:25:12 step 6: objective=0.9740544
2017/08/29 07:25:15 step 7: objective=0.9775833
2017/08/29 07:25:15 Training value function...
2017/08/29 07:25:18 step 0: mse=160.369542 step=0.100000
2017/08/29 07:25:19 step 1: mse=157.214499 step=0.100000
2017/08/29 07:25:20 step 2: mse=154.718999 step=0.100000
2017/08/29 07:25:22 step 3: mse=152.418816 step=0.100000
2017/08/29 07:25:23 step 4: mse=150.584754 step=0.100000
2017/08/29 07:25:24 step 5: mse=149.016336 step=0.100000
2017/08/29 07:25:26 step 6: mse=147.792367 step=0.100000
2017/08/29 07:25:27 step 7: mse=146.139731 step=0.100000
2017/08/29 07:25:27 Saving...
2017/08/29 07:25:27 Gathering batch of experience...
2017/08/29 07:26:18 batch 1100: mean=241.178571 stddev=166.830122 entropy=0.309145 frames=6600 count=28
2017/08/29 07:26:18 Training policy...
2017/08/29 07:26:24 step 0: objective=0.5964586
2017/08/29 07:26:27 step 1: objective=0.6002397
2017/08/29 07:26:30 step 2: objective=0.60424536
2017/08/29 07:26:33 step 3: objective=0.6070237
2017/08/29 07:26:36 step 4: objective=0.6097883
2017/08/29 07:26:38 step 5: objective=0.61205465
2017/08/29 07:26:41 step 6: objective=0.61517036
2017/08/29 07:26:44 step 7: objective=0.6189245
2017/08/29 07:26:44 Training value function...
2017/08/29 07:26:47 step 0: mse=133.591752 step=0.100000
2017/08/29 07:26:48 step 1: mse=130.738318 step=0.100000
2017/08/29 07:26:50 step 2: mse=128.287740 step=0.100000
2017/08/29 07:26:51 step 3: mse=126.424457 step=0.100000
2017/08/29 07:26:53 step 4: mse=124.489702 step=0.100000
2017/08/29 07:26:54 step 5: mse=123.327228 step=0.100000
2017/08/29 07:26:55 step 6: mse=122.133213 step=0.100000
2017/08/29 07:26:57 step 7: mse=121.124550 step=0.100000
2017/08/29 07:26:57 Saving...
2017/08/29 07:26:57 Gathering batch of experience...
2017/08/29 07:27:47 batch 1101: mean=205.424242 stddev=145.714963 entropy=0.302330 frames=6571 count=33
2017/08/29 07:27:47 Training policy...
2017/08/29 07:27:53 step 0: objective=0.7689324
2017/08/29 07:27:56 step 1: objective=0.7734493
2017/08/29 07:27:59 step 2: objective=0.77853173
2017/08/29 07:28:02 step 3: objective=0.7830004
2017/08/29 07:28:05 step 4: objective=0.7882893
2017/08/29 07:28:08 step 5: objective=0.7912619
2017/08/29 07:28:10 step 6: objective=0.7939688
2017/08/29 07:28:13 step 7: objective=0.7968008
2017/08/29 07:28:13 Training value function...
2017/08/29 07:28:16 step 0: mse=142.160603 step=0.100000
2017/08/29 07:28:17 step 1: mse=140.231889 step=0.100000
2017/08/29 07:28:19 step 2: mse=138.581912 step=0.100000
2017/08/29 07:28:20 step 3: mse=137.007147 step=0.100000
2017/08/29 07:28:22 step 4: mse=135.665520 step=0.100000
2017/08/29 07:28:23 step 5: mse=134.398752 step=0.100000
2017/08/29 07:28:24 step 6: mse=133.275895 step=0.100000
2017/08/29 07:28:26 step 7: mse=132.237378 step=0.100000
2017/08/29 07:28:26 Saving...
2017/08/29 07:28:26 Gathering batch of experience...
2017/08/29 07:29:16 batch 1102: mean=227.137931 stddev=190.158867 entropy=0.302230 frames=6181 count=29
2017/08/29 07:29:16 Training policy...
2017/08/29 07:29:21 step 0: objective=1.5478181
2017/08/29 07:29:24 step 1: objective=1.5554602
2017/08/29 07:29:26 step 2: objective=1.5610709
2017/08/29 07:29:29 step 3: objective=1.5660886
2017/08/29 07:29:32 step 4: objective=1.5704613
2017/08/29 07:29:35 step 5: objective=1.5738158
2017/08/29 07:29:37 step 6: objective=1.5783869
2017/08/29 07:29:40 step 7: objective=1.5814831
2017/08/29 07:29:40 Training value function...
2017/08/29 07:29:43 step 0: mse=193.303504 step=0.100000
2017/08/29 07:29:44 step 1: mse=186.845671 step=0.100000
2017/08/29 07:29:45 step 2: mse=181.634906 step=0.100000
2017/08/29 07:29:47 step 3: mse=177.367274 step=0.100000
2017/08/29 07:29:48 step 4: mse=173.781751 step=0.100000
2017/08/29 07:29:49 step 5: mse=170.702341 step=0.100000
2017/08/29 07:29:51 step 6: mse=167.588654 step=0.100000
2017/08/29 07:29:52 step 7: mse=165.100243 step=0.100000
2017/08/29 07:29:52 Saving...
2017/08/29 07:29:52 Gathering batch of experience...
2017/08/29 07:30:38 batch 1103: mean=213.285714 stddev=193.178647 entropy=0.302131 frames=5942 count=28
2017/08/29 07:30:38 Training policy...
2017/08/29 07:30:43 step 0: objective=0.58536345
2017/08/29 07:30:46 step 1: objective=0.58992803
2017/08/29 07:30:49 step 2: objective=0.59633946
2017/08/29 07:30:51 step 3: objective=0.5992534
2017/08/29 07:30:54 step 4: objective=0.6022998
2017/08/29 07:30:57 step 5: objective=0.60705006
2017/08/29 07:30:59 step 6: objective=0.60951835
2017/08/29 07:31:02 step 7: objective=0.6117452
2017/08/29 07:31:02 Training value function...
2017/08/29 07:31:04 step 0: mse=154.902571 step=0.100000
2017/08/29 07:31:06 step 1: mse=152.933635 step=0.100000
2017/08/29 07:31:07 step 2: mse=151.016982 step=0.100000
2017/08/29 07:31:08 step 3: mse=149.597699 step=0.100000
2017/08/29 07:31:09 step 4: mse=148.256057 step=0.100000
2017/08/29 07:31:11 step 5: mse=146.619122 step=0.100000
2017/08/29 07:31:12 step 6: mse=145.342694 step=0.100000
2017/08/29 07:31:13 step 7: mse=144.042449 step=0.100000
2017/08/29 07:31:13 Saving...
2017/08/29 07:31:13 Gathering batch of experience...
2017/08/29 07:32:02 batch 1104: mean=267.857143 stddev=192.873703 entropy=0.304735 frames=6735 count=28
2017/08/29 07:32:02 Training policy...
2017/08/29 07:32:08 step 0: objective=2.3282301
2017/08/29 07:32:11 step 1: objective=2.334937
2017/08/29 07:32:14 step 2: objective=2.3405879
2017/08/29 07:32:17 step 3: objective=2.345694
2017/08/29 07:32:20 step 4: objective=2.349536
2017/08/29 07:32:23 step 5: objective=2.3527477
2017/08/29 07:32:26 step 6: objective=2.3557143
2017/08/29 07:32:29 step 7: objective=2.3583608
2017/08/29 07:32:29 Training value function...
2017/08/29 07:32:32 step 0: mse=204.655122 step=0.100000
2017/08/29 07:32:33 step 1: mse=198.495883 step=0.100000
2017/08/29 07:32:35 step 2: mse=193.498045 step=0.100000
2017/08/29 07:32:36 step 3: mse=189.067352 step=0.100000
2017/08/29 07:32:37 step 4: mse=185.288823 step=0.100000
2017/08/29 07:32:39 step 5: mse=182.309305 step=0.100000
2017/08/29 07:32:40 step 6: mse=179.464110 step=0.100000
2017/08/29 07:32:42 step 7: mse=176.092879 step=0.100000
2017/08/29 07:32:42 Saving...
2017/08/29 07:32:42 Gathering batch of experience...
2017/08/29 07:33:36 batch 1105: mean=261.892857 stddev=202.368183 entropy=0.303027 frames=6569 count=28
2017/08/29 07:33:36 Training policy...
2017/08/29 07:33:42 step 0: objective=1.4889014
2017/08/29 07:33:45 step 1: objective=1.4920971
2017/08/29 07:33:48 step 2: objective=1.4968848
2017/08/29 07:33:51 step 3: objective=1.5032867
2017/08/29 07:33:54 step 4: objective=1.5080969
2017/08/29 07:33:57 step 5: objective=1.5130118
2017/08/29 07:34:00 step 6: objective=1.5183916
2017/08/29 07:34:02 step 7: objective=1.522406
2017/08/29 07:34:02 Training value function...
2017/08/29 07:34:05 step 0: mse=187.710549 step=0.100000
2017/08/29 07:34:07 step 1: mse=185.163965 step=0.100000
2017/08/29 07:34:08 step 2: mse=183.023231 step=0.100000
2017/08/29 07:34:09 step 3: mse=181.074239 step=0.100000
2017/08/29 07:34:11 step 4: mse=179.146914 step=0.100000
2017/08/29 07:34:12 step 5: mse=177.591971 step=0.100000
2017/08/29 07:34:14 step 6: mse=175.721484 step=0.100000
2017/08/29 07:34:15 step 7: mse=174.137272 step=0.100000
2017/08/29 07:34:15 Saving...
2017/08/29 07:34:15 Gathering batch of experience...
2017/08/29 07:34:59 batch 1106: mean=213.241379 stddev=179.304337 entropy=0.300718 frames=5873 count=29
2017/08/29 07:34:59 Training policy...
2017/08/29 07:35:04 step 0: objective=0.3359513
2017/08/29 07:35:07 step 1: objective=0.3427468
2017/08/29 07:35:10 step 2: objective=0.35064307
2017/08/29 07:35:12 step 3: objective=0.35678294
2017/08/29 07:35:15 step 4: objective=0.3607376
2017/08/29 07:35:17 step 5: objective=0.36360097
2017/08/29 07:35:20 step 6: objective=0.36683744
2017/08/29 07:35:23 step 7: objective=0.36976975
2017/08/29 07:35:23 Training value function...
2017/08/29 07:35:25 step 0: mse=148.382140 step=0.100000
2017/08/29 07:35:26 step 1: mse=147.214991 step=0.100000
2017/08/29 07:35:27 step 2: mse=146.393424 step=0.100000
2017/08/29 07:35:29 step 3: mse=145.397935 step=0.100000
2017/08/29 07:35:30 step 4: mse=144.453234 step=0.100000
2017/08/29 07:35:31 step 5: mse=143.571776 step=0.100000
2017/08/29 07:35:32 step 6: mse=142.852506 step=0.100000
2017/08/29 07:35:34 step 7: mse=141.940960 step=0.100000
2017/08/29 07:35:34 Saving...
2017/08/29 07:35:34 Gathering batch of experience...
2017/08/29 07:36:23 batch 1107: mean=195.272727 stddev=153.879385 entropy=0.300030 frames=5935 count=33
2017/08/29 07:36:23 Training policy...
2017/08/29 07:36:28 step 0: objective=0.953479
2017/08/29 07:36:31 step 1: objective=0.95759684
2017/08/29 07:36:34 step 2: objective=0.96156377
2017/08/29 07:36:36 step 3: objective=0.9705199
2017/08/29 07:36:39 step 4: objective=0.97389495
2017/08/29 07:36:41 step 5: objective=0.9810535
2017/08/29 07:36:44 step 6: objective=0.98445404
2017/08/29 07:36:47 step 7: objective=0.98677534
2017/08/29 07:36:47 Training value function...
2017/08/29 07:36:49 step 0: mse=171.383562 step=0.100000
2017/08/29 07:36:50 step 1: mse=168.928821 step=0.100000
2017/08/29 07:36:52 step 2: mse=166.897865 step=0.100000
2017/08/29 07:36:53 step 3: mse=165.103305 step=0.100000
2017/08/29 07:36:54 step 4: mse=163.560338 step=0.100000
2017/08/29 07:36:55 step 5: mse=162.385179 step=0.100000
2017/08/29 07:36:57 step 6: mse=161.355173 step=0.100000
2017/08/29 07:36:58 step 7: mse=160.376538 step=0.100000
2017/08/29 07:36:58 Saving...
2017/08/29 07:36:58 Gathering batch of experience...
2017/08/29 07:37:42 batch 1108: mean=193.566667 stddev=145.929134 entropy=0.309018 frames=5603 count=30
2017/08/29 07:37:42 Training policy...
2017/08/29 07:37:47 step 0: objective=0.47146177
2017/08/29 07:37:49 step 1: objective=0.4807028
2017/08/29 07:37:52 step 2: objective=0.48648378
2017/08/29 07:37:54 step 3: objective=0.49165064
2017/08/29 07:37:57 step 4: objective=0.49561876
2017/08/29 07:37:59 step 5: objective=0.5020481
2017/08/29 07:38:02 step 6: objective=0.50478226
2017/08/29 07:38:04 step 7: objective=0.50777173
2017/08/29 07:38:04 Training value function...
2017/08/29 07:38:07 step 0: mse=161.896033 step=0.100000
2017/08/29 07:38:08 step 1: mse=159.097504 step=0.100000
2017/08/29 07:38:09 step 2: mse=156.545518 step=0.100000
2017/08/29 07:38:10 step 3: mse=154.691305 step=0.100000
2017/08/29 07:38:11 step 4: mse=153.031158 step=0.100000
2017/08/29 07:38:12 step 5: mse=151.747276 step=0.100000
2017/08/29 07:38:14 step 6: mse=150.404015 step=0.100000
2017/08/29 07:38:15 step 7: mse=149.243255 step=0.100000
2017/08/29 07:38:15 Saving...
2017/08/29 07:38:15 Gathering batch of experience...
2017/08/29 07:39:13 batch 1109: mean=237.121212 stddev=211.711748 entropy=0.301857 frames=7281 count=33
2017/08/29 07:39:13 Training policy...
2017/08/29 07:39:19 step 0: objective=1.9999446
2017/08/29 07:39:22 step 1: objective=2.005121
2017/08/29 07:39:26 step 2: objective=2.0090466
2017/08/29 07:39:29 step 3: objective=2.0136604
2017/08/29 07:39:32 step 4: objective=2.017711
2017/08/29 07:39:35 step 5: objective=2.020009
2017/08/29 07:39:39 step 6: objective=2.0219371
2017/08/29 07:39:42 step 7: objective=2.0243642
2017/08/29 07:39:42 Training value function...
2017/08/29 07:39:45 step 0: mse=161.035017 step=0.100000
2017/08/29 07:39:46 step 1: mse=155.308674 step=0.100000
2017/08/29 07:39:48 step 2: mse=150.772420 step=0.100000
2017/08/29 07:39:50 step 3: mse=146.812546 step=0.100000
2017/08/29 07:39:51 step 4: mse=143.420953 step=0.100000
2017/08/29 07:39:53 step 5: mse=140.520609 step=0.100000
2017/08/29 07:39:54 step 6: mse=138.225769 step=0.100000
2017/08/29 07:39:56 step 7: mse=135.889488 step=0.100000
2017/08/29 07:39:56 Saving...
2017/08/29 07:39:56 Gathering batch of experience...
2017/08/29 07:40:46 batch 1110: mean=186.971429 stddev=191.681803 entropy=0.306543 frames=6666 count=35
2017/08/29 07:40:46 Training policy...
2017/08/29 07:40:52 step 0: objective=0.04314689
2017/08/29 07:40:55 step 1: objective=0.049122278
2017/08/29 07:40:58 step 2: objective=0.055628303
2017/08/29 07:41:01 step 3: objective=0.059935987
2017/08/29 07:41:04 step 4: objective=0.06340928
2017/08/29 07:41:07 step 5: objective=0.06757536
2017/08/29 07:41:10 step 6: objective=0.06991108
2017/08/29 07:41:13 step 7: objective=0.07290496
2017/08/29 07:41:13 Training value function...
2017/08/29 07:41:16 step 0: mse=136.778535 step=0.100000
2017/08/29 07:41:17 step 1: mse=134.209686 step=0.100000
2017/08/29 07:41:18 step 2: mse=132.080920 step=0.100000
2017/08/29 07:41:20 step 3: mse=130.377443 step=0.100000
2017/08/29 07:41:21 step 4: mse=129.208431 step=0.100000
2017/08/29 07:41:23 step 5: mse=128.143780 step=0.100000
2017/08/29 07:41:24 step 6: mse=127.334689 step=0.100000
2017/08/29 07:41:25 step 7: mse=126.712549 step=0.100000
2017/08/29 07:41:25 Saving...
2017/08/29 07:41:26 Gathering batch of experience...
2017/08/29 07:42:17 batch 1111: mean=256.538462 stddev=187.144582 entropy=0.309895 frames=6312 count=26
2017/08/29 07:42:17 Training policy...
2017/08/29 07:42:22 step 0: objective=1.7184286
2017/08/29 07:42:25 step 1: objective=1.7243834
2017/08/29 07:42:28 step 2: objective=1.7294551
2017/08/29 07:42:31 step 3: objective=1.7331196
2017/08/29 07:42:34 step 4: objective=1.7381727
2017/08/29 07:42:36 step 5: objective=1.7428203
2017/08/29 07:42:39 step 6: objective=1.7454373
2017/08/29 07:42:42 step 7: objective=1.7484063
2017/08/29 07:42:42 Training value function...
2017/08/29 07:42:45 step 0: mse=163.544885 step=0.100000
2017/08/29 07:42:46 step 1: mse=160.362823 step=0.100000
2017/08/29 07:42:47 step 2: mse=157.518163 step=0.100000
2017/08/29 07:42:49 step 3: mse=155.037987 step=0.100000
2017/08/29 07:42:50 step 4: mse=152.618938 step=0.100000
2017/08/29 07:42:51 step 5: mse=150.455384 step=0.100000
2017/08/29 07:42:53 step 6: mse=148.318544 step=0.100000
2017/08/29 07:42:54 step 7: mse=146.516211 step=0.100000
2017/08/29 07:42:54 Saving...
2017/08/29 07:42:54 Gathering batch of experience...
2017/08/29 07:43:46 batch 1112: mean=232.933333 stddev=158.951341 entropy=0.303216 frames=6745 count=30
2017/08/29 07:43:46 Training policy...
2017/08/29 07:43:52 step 0: objective=0.9305119
2017/08/29 07:43:55 step 1: objective=0.9357482
2017/08/29 07:43:58 step 2: objective=0.9405639
2017/08/29 07:44:01 step 3: objective=0.9459935
2017/08/29 07:44:04 step 4: objective=0.9496943
2017/08/29 07:44:07 step 5: objective=0.9532226
2017/08/29 07:44:10 step 6: objective=0.95651114
2017/08/29 07:44:13 step 7: objective=0.9581621
2017/08/29 07:44:13 Training value function...
2017/08/29 07:44:16 step 0: mse=153.083040 step=0.100000
2017/08/29 07:44:18 step 1: mse=152.348369 step=0.100000
2017/08/29 07:44:19 step 2: mse=151.280982 step=0.100000
2017/08/29 07:44:20 step 3: mse=150.126867 step=0.100000
2017/08/29 07:44:22 step 4: mse=149.269425 step=0.100000
2017/08/29 07:44:23 step 5: mse=148.284369 step=0.100000
2017/08/29 07:44:25 step 6: mse=147.597125 step=0.100000
2017/08/29 07:44:26 step 7: mse=146.561267 step=0.100000
2017/08/29 07:44:26 Saving...
2017/08/29 07:44:26 Gathering batch of experience...
2017/08/29 07:45:19 batch 1113: mean=238.352941 stddev=188.005457 entropy=0.299517 frames=7286 count=34
2017/08/29 07:45:19 Training policy...
2017/08/29 07:45:26 step 0: objective=1.8861266
2017/08/29 07:45:29 step 1: objective=1.8917919
2017/08/29 07:45:32 step 2: objective=1.8973423
2017/08/29 07:45:36 step 3: objective=1.9011374
2017/08/29 07:45:39 step 4: objective=1.9040339
2017/08/29 07:45:42 step 5: objective=1.9081264
2017/08/29 07:45:45 step 6: objective=1.9101851
2017/08/29 07:45:48 step 7: objective=1.9130317
2017/08/29 07:45:48 Training value function...
2017/08/29 07:45:52 step 0: mse=167.951396 step=0.100000
2017/08/29 07:45:53 step 1: mse=163.402883 step=0.100000
2017/08/29 07:45:55 step 2: mse=159.626355 step=0.100000
2017/08/29 07:45:56 step 3: mse=156.656594 step=0.100000
2017/08/29 07:45:58 step 4: mse=153.729532 step=0.100000
2017/08/29 07:45:59 step 5: mse=151.301302 step=0.100000
2017/08/29 07:46:01 step 6: mse=149.149342 step=0.100000
2017/08/29 07:46:02 step 7: mse=147.126718 step=0.100000
2017/08/29 07:46:02 Saving...
2017/08/29 07:46:02 Gathering batch of experience...
2017/08/29 07:46:56 batch 1114: mean=270.071429 stddev=211.183388 entropy=0.306788 frames=7214 count=28
2017/08/29 07:46:56 Training policy...
2017/08/29 07:47:02 step 0: objective=1.0373093
2017/08/29 07:47:06 step 1: objective=1.0421449
2017/08/29 07:47:09 step 2: objective=1.0446343
2017/08/29 07:47:12 step 3: objective=1.0484732
2017/08/29 07:47:15 step 4: objective=1.0523363
2017/08/29 07:47:19 step 5: objective=1.0544456
2017/08/29 07:47:22 step 6: objective=1.0584371
2017/08/29 07:47:25 step 7: objective=1.061298
2017/08/29 07:47:25 Training value function...
2017/08/29 07:47:28 step 0: mse=147.079848 step=0.100000
2017/08/29 07:47:29 step 1: mse=143.055966 step=0.100000
2017/08/29 07:47:31 step 2: mse=140.075108 step=0.100000
2017/08/29 07:47:33 step 3: mse=137.395683 step=0.100000
2017/08/29 07:47:34 step 4: mse=135.229665 step=0.100000
2017/08/29 07:47:36 step 5: mse=133.200217 step=0.100000
2017/08/29 07:47:37 step 6: mse=131.594251 step=0.100000
2017/08/29 07:47:39 step 7: mse=130.150783 step=0.100000
2017/08/29 07:47:39 Saving...
2017/08/29 07:47:39 Gathering batch of experience...
2017/08/29 07:48:28 batch 1115: mean=246.500000 stddev=169.818916 entropy=0.308339 frames=6466 count=28
2017/08/29 07:48:28 Training policy...
2017/08/29 07:48:33 step 0: objective=1.0356486
2017/08/29 07:48:36 step 1: objective=1.0394738
2017/08/29 07:48:39 step 2: objective=1.0431505
2017/08/29 07:48:42 step 3: objective=1.0464389
2017/08/29 07:48:45 step 4: objective=1.0495657
2017/08/29 07:48:48 step 5: objective=1.054426
2017/08/29 07:48:51 step 6: objective=1.0573412
2017/08/29 07:48:54 step 7: objective=1.0600992
2017/08/29 07:48:54 Training value function...
2017/08/29 07:48:56 step 0: mse=147.658563 step=0.100000
2017/08/29 07:48:58 step 1: mse=144.881359 step=0.100000
2017/08/29 07:48:59 step 2: mse=142.807678 step=0.100000
2017/08/29 07:49:00 step 3: mse=141.202575 step=0.100000
2017/08/29 07:49:02 step 4: mse=139.665650 step=0.100000
2017/08/29 07:49:03 step 5: mse=138.323786 step=0.100000
2017/08/29 07:49:05 step 6: mse=137.042017 step=0.100000
2017/08/29 07:49:06 step 7: mse=136.079880 step=0.100000
2017/08/29 07:49:06 Saving...
2017/08/29 07:49:06 Gathering batch of experience...
2017/08/29 07:49:58 batch 1116: mean=198.470588 stddev=190.759817 entropy=0.305985 frames=6521 count=34
2017/08/29 07:49:58 Training policy...
2017/08/29 07:50:04 step 0: objective=0.4520723
2017/08/29 07:50:06 step 1: objective=0.45781937
2017/08/29 07:50:09 step 2: objective=0.4611065
2017/08/29 07:50:12 step 3: objective=0.46406204
2017/08/29 07:50:15 step 4: objective=0.4674478
2017/08/29 07:50:18 step 5: objective=0.47220916
2017/08/29 07:50:21 step 6: objective=0.47504705
2017/08/29 07:50:24 step 7: objective=0.47734356
2017/08/29 07:50:24 Training value function...
2017/08/29 07:50:26 step 0: mse=137.952396 step=0.100000
2017/08/29 07:50:28 step 1: mse=134.669706 step=0.100000
2017/08/29 07:50:29 step 2: mse=131.949620 step=0.100000
2017/08/29 07:50:31 step 3: mse=129.671585 step=0.100000
2017/08/29 07:50:32 step 4: mse=127.944708 step=0.100000
2017/08/29 07:50:33 step 5: mse=126.344080 step=0.100000
2017/08/29 07:50:35 step 6: mse=125.381919 step=0.100000
2017/08/29 07:50:36 step 7: mse=124.228384 step=0.100000
2017/08/29 07:50:36 Saving...
2017/08/29 07:50:36 Gathering batch of experience...
2017/08/29 07:51:29 batch 1117: mean=272.821429 stddev=184.736116 entropy=0.305547 frames=7088 count=28
2017/08/29 07:51:29 Training policy...
2017/08/29 07:51:35 step 0: objective=1.7884675
2017/08/29 07:51:38 step 1: objective=1.7928987
2017/08/29 07:51:41 step 2: objective=1.7962378
2017/08/29 07:51:44 step 3: objective=1.7992469
2017/08/29 07:51:48 step 4: objective=1.8022491
2017/08/29 07:51:51 step 5: objective=1.8057019
2017/08/29 07:51:54 step 6: objective=1.8087097
2017/08/29 07:51:57 step 7: objective=1.8105493
2017/08/29 07:51:57 Training value function...
2017/08/29 07:52:00 step 0: mse=149.666897 step=0.100000
2017/08/29 07:52:02 step 1: mse=145.951689 step=0.100000
2017/08/29 07:52:03 step 2: mse=142.978830 step=0.100000
2017/08/29 07:52:05 step 3: mse=140.723104 step=0.100000
2017/08/29 07:52:06 step 4: mse=138.536664 step=0.100000
2017/08/29 07:52:08 step 5: mse=136.407453 step=0.100000
2017/08/29 07:52:09 step 6: mse=134.792694 step=0.100000
2017/08/29 07:52:11 step 7: mse=133.423692 step=0.100000
2017/08/29 07:52:11 Saving...
2017/08/29 07:52:11 Gathering batch of experience...
2017/08/29 07:53:05 batch 1118: mean=180.638889 stddev=171.134313 entropy=0.298714 frames=6142 count=36
2017/08/29 07:53:05 Training policy...
2017/08/29 07:53:10 step 0: objective=0.39723122
2017/08/29 07:53:13 step 1: objective=0.40463495
2017/08/29 07:53:16 step 2: objective=0.4103323
2017/08/29 07:53:19 step 3: objective=0.41461667
2017/08/29 07:53:21 step 4: objective=0.42021045
2017/08/29 07:53:24 step 5: objective=0.4243399
2017/08/29 07:53:27 step 6: objective=0.42914566
2017/08/29 07:53:30 step 7: objective=0.4316826
2017/08/29 07:53:30 Training value function...
2017/08/29 07:53:32 step 0: mse=155.063910 step=0.100000
2017/08/29 07:53:33 step 1: mse=153.602923 step=0.100000
2017/08/29 07:53:35 step 2: mse=152.380635 step=0.100000
2017/08/29 07:53:36 step 3: mse=151.231244 step=0.100000
2017/08/29 07:53:37 step 4: mse=150.128921 step=0.100000
2017/08/29 07:53:39 step 5: mse=149.532143 step=0.100000
2017/08/29 07:53:40 step 6: mse=148.450546 step=0.100000
2017/08/29 07:53:41 step 7: mse=147.418215 step=0.100000
2017/08/29 07:53:41 Saving...
2017/08/29 07:53:41 Gathering batch of experience...
2017/08/29 07:54:30 batch 1119: mean=300.565217 stddev=165.470561 entropy=0.307283 frames=6679 count=23
2017/08/29 07:54:30 Training policy...
2017/08/29 07:54:36 step 0: objective=1.2999117
2017/08/29 07:54:39 step 1: objective=1.3035018
2017/08/29 07:54:42 step 2: objective=1.307396
2017/08/29 07:54:45 step 3: objective=1.311249
2017/08/29 07:54:48 step 4: objective=1.3152812
2017/08/29 07:54:51 step 5: objective=1.3191249
2017/08/29 07:54:54 step 6: objective=1.3216705
2017/08/29 07:54:57 step 7: objective=1.3253511
2017/08/29 07:54:57 Training value function...
2017/08/29 07:55:00 step 0: mse=152.694903 step=0.100000
2017/08/29 07:55:01 step 1: mse=148.270630 step=0.100000
2017/08/29 07:55:02 step 2: mse=144.652595 step=0.100000
2017/08/29 07:55:04 step 3: mse=141.630709 step=0.100000
2017/08/29 07:55:05 step 4: mse=139.100048 step=0.100000
2017/08/29 07:55:07 step 5: mse=136.721163 step=0.100000
2017/08/29 07:55:08 step 6: mse=134.797315 step=0.100000
2017/08/29 07:55:10 step 7: mse=132.998264 step=0.100000
2017/08/29 07:55:10 Saving...
2017/08/29 07:55:10 Gathering batch of experience...
2017/08/29 07:56:04 batch 1120: mean=240.300000 stddev=207.048811 entropy=0.309753 frames=7076 count=30
2017/08/29 07:56:04 Training policy...
2017/08/29 07:56:10 step 0: objective=0.769617
2017/08/29 07:56:14 step 1: objective=0.7746936
2017/08/29 07:56:17 step 2: objective=0.7800816
2017/08/29 07:56:20 step 3: objective=0.7820301
2017/08/29 07:56:23 step 4: objective=0.7854376
2017/08/29 07:56:26 step 5: objective=0.78986716
2017/08/29 07:56:30 step 6: objective=0.7935328
2017/08/29 07:56:33 step 7: objective=0.7958046
2017/08/29 07:56:33 Training value function...
2017/08/29 07:56:36 step 0: mse=128.734143 step=0.100000
2017/08/29 07:56:37 step 1: mse=126.417268 step=0.100000
2017/08/29 07:56:39 step 2: mse=124.595904 step=0.100000
2017/08/29 07:56:40 step 3: mse=122.856737 step=0.100000
2017/08/29 07:56:42 step 4: mse=121.150572 step=0.100000
2017/08/29 07:56:43 step 5: mse=119.752014 step=0.100000
2017/08/29 07:56:45 step 6: mse=118.826271 step=0.100000
2017/08/29 07:56:46 step 7: mse=118.002273 step=0.100000
2017/08/29 07:56:46 Saving...
2017/08/29 07:56:46 Gathering batch of experience...
2017/08/29 07:57:38 batch 1121: mean=244.851852 stddev=191.797096 entropy=0.302943 frames=6077 count=27
2017/08/29 07:57:38 Training policy...
2017/08/29 07:57:43 step 0: objective=1.6582069
2017/08/29 07:57:46 step 1: objective=1.6628227
2017/08/29 07:57:48 step 2: objective=1.6665225
2017/08/29 07:57:51 step 3: objective=1.6711024
2017/08/29 07:57:54 step 4: objective=1.6752896
2017/08/29 07:57:56 step 5: objective=1.6786296
2017/08/29 07:57:59 step 6: objective=1.6822239
2017/08/29 07:58:02 step 7: objective=1.6849521
2017/08/29 07:58:02 Training value function...
2017/08/29 07:58:04 step 0: mse=162.205634 step=0.100000
2017/08/29 07:58:06 step 1: mse=158.632023 step=0.100000
2017/08/29 07:58:07 step 2: mse=155.737217 step=0.100000
2017/08/29 07:58:08 step 3: mse=153.082300 step=0.100000
2017/08/29 07:58:10 step 4: mse=150.741854 step=0.100000
2017/08/29 07:58:11 step 5: mse=148.970170 step=0.100000
2017/08/29 07:58:12 step 6: mse=147.178955 step=0.100000
2017/08/29 07:58:13 step 7: mse=145.658601 step=0.100000
2017/08/29 07:58:13 Saving...
2017/08/29 07:58:14 Gathering batch of experience...
2017/08/29 07:59:14 batch 1122: mean=224.812500 stddev=239.710690 entropy=0.309472 frames=6642 count=32
2017/08/29 07:59:14 Training policy...
2017/08/29 07:59:20 step 0: objective=1.4751221
2017/08/29 07:59:23 step 1: objective=1.4815592
2017/08/29 07:59:26 step 2: objective=1.4876361
2017/08/29 07:59:28 step 3: objective=1.4913355
2017/08/29 07:59:31 step 4: objective=1.4947529
2017/08/29 07:59:34 step 5: objective=1.4973438
2017/08/29 07:59:37 step 6: objective=1.5011418
2017/08/29 07:59:40 step 7: objective=1.5038106
2017/08/29 07:59:40 Training value function...
2017/08/29 07:59:43 step 0: mse=184.028329 step=0.100000
2017/08/29 07:59:45 step 1: mse=175.866927 step=0.100000
2017/08/29 07:59:46 step 2: mse=169.479482 step=0.100000
2017/08/29 07:59:47 step 3: mse=164.420694 step=0.100000
2017/08/29 07:59:49 step 4: mse=160.207609 step=0.100000
2017/08/29 07:59:50 step 5: mse=156.398306 step=0.100000
2017/08/29 07:59:52 step 6: mse=153.021120 step=0.100000
2017/08/29 07:59:53 step 7: mse=150.226998 step=0.100000
2017/08/29 07:59:53 Saving...
2017/08/29 07:59:53 Gathering batch of experience...
2017/08/29 08:00:45 batch 1123: mean=245.344828 stddev=204.495388 entropy=0.307438 frames=6731 count=29
2017/08/29 08:00:45 Training policy...
2017/08/29 08:00:51 step 0: objective=0.98801965
2017/08/29 08:00:54 step 1: objective=0.9959798
2017/08/29 08:00:57 step 2: objective=1.0001757
2017/08/29 08:01:00 step 3: objective=1.0053358
2017/08/29 08:01:03 step 4: objective=1.0106238
2017/08/29 08:01:06 step 5: objective=1.0150231
2017/08/29 08:01:09 step 6: objective=1.0178963
2017/08/29 08:01:12 step 7: objective=1.0207093
2017/08/29 08:01:12 Training value function...
2017/08/29 08:01:15 step 0: mse=147.095522 step=0.100000
2017/08/29 08:01:16 step 1: mse=144.604208 step=0.100000
2017/08/29 08:01:17 step 2: mse=142.434310 step=0.100000
2017/08/29 08:01:19 step 3: mse=140.559729 step=0.100000
2017/08/29 08:01:20 step 4: mse=138.971362 step=0.100000
2017/08/29 08:01:22 step 5: mse=137.524830 step=0.100000
2017/08/29 08:01:23 step 6: mse=136.392871 step=0.100000
2017/08/29 08:01:25 step 7: mse=135.231976 step=0.100000
2017/08/29 08:01:25 Saving...
2017/08/29 08:01:25 Gathering batch of experience...
2017/08/29 08:02:12 batch 1124: mean=252.703704 stddev=167.276399 entropy=0.300376 frames=6217 count=27
2017/08/29 08:02:12 Training policy...
2017/08/29 08:02:18 step 0: objective=1.4360759
2017/08/29 08:02:20 step 1: objective=1.4416203
2017/08/29 08:02:23 step 2: objective=1.4459485
2017/08/29 08:02:26 step 3: objective=1.4503736
2017/08/29 08:02:29 step 4: objective=1.4544065
2017/08/29 08:02:32 step 5: objective=1.457679
2017/08/29 08:02:34 step 6: objective=1.4614625
2017/08/29 08:02:37 step 7: objective=1.465438
2017/08/29 08:02:37 Training value function...
2017/08/29 08:02:40 step 0: mse=163.122050 step=0.100000
2017/08/29 08:02:41 step 1: mse=159.418565 step=0.100000
2017/08/29 08:02:42 step 2: mse=156.312694 step=0.100000
2017/08/29 08:02:44 step 3: mse=153.706885 step=0.100000
2017/08/29 08:02:45 step 4: mse=151.345213 step=0.100000
2017/08/29 08:02:46 step 5: mse=149.241744 step=0.100000
2017/08/29 08:02:48 step 6: mse=147.479878 step=0.100000
2017/08/29 08:02:49 step 7: mse=145.869307 step=0.100000
2017/08/29 08:02:49 Saving...
2017/08/29 08:02:49 Gathering batch of experience...
2017/08/29 08:03:34 batch 1125: mean=217.586207 stddev=168.837714 entropy=0.299998 frames=5943 count=29
2017/08/29 08:03:34 Training policy...
2017/08/29 08:03:40 step 0: objective=0.64615244
2017/08/29 08:03:42 step 1: objective=0.6514109
2017/08/29 08:03:45 step 2: objective=0.65679437
2017/08/29 08:03:48 step 3: objective=0.6607196
2017/08/29 08:03:50 step 4: objective=0.6650477
2017/08/29 08:03:53 step 5: objective=0.6690419
2017/08/29 08:03:56 step 6: objective=0.67219675
2017/08/29 08:03:58 step 7: objective=0.6752589
2017/08/29 08:03:58 Training value function...
2017/08/29 08:04:01 step 0: mse=142.900117 step=0.100000
2017/08/29 08:04:02 step 1: mse=139.604232 step=0.100000
2017/08/29 08:04:03 step 2: mse=137.076124 step=0.100000
2017/08/29 08:04:05 step 3: mse=135.058848 step=0.100000
2017/08/29 08:04:06 step 4: mse=133.035326 step=0.100000
2017/08/29 08:04:07 step 5: mse=131.618291 step=0.100000
2017/08/29 08:04:08 step 6: mse=130.382250 step=0.100000
2017/08/29 08:04:10 step 7: mse=128.996519 step=0.100000
2017/08/29 08:04:10 Saving...
2017/08/29 08:04:10 Gathering batch of experience...
2017/08/29 08:05:03 batch 1126: mean=269.407407 stddev=196.560849 entropy=0.306172 frames=6800 count=27
2017/08/29 08:05:03 Training policy...
2017/08/29 08:05:09 step 0: objective=1.4084626
2017/08/29 08:05:12 step 1: objective=1.4138097
2017/08/29 08:05:15 step 2: objective=1.4175106
2017/08/29 08:05:18 step 3: objective=1.4205117
2017/08/29 08:05:21 step 4: objective=1.4240602
2017/08/29 08:05:24 step 5: objective=1.4263575
2017/08/29 08:05:27 step 6: objective=1.4312835
2017/08/29 08:05:30 step 7: objective=1.4348191
2017/08/29 08:05:30 Training value function...
2017/08/29 08:05:33 step 0: mse=151.503878 step=0.100000
2017/08/29 08:05:34 step 1: mse=148.732275 step=0.100000
2017/08/29 08:05:36 step 2: mse=146.430875 step=0.100000
2017/08/29 08:05:37 step 3: mse=144.607549 step=0.100000
2017/08/29 08:05:39 step 4: mse=142.774695 step=0.100000
2017/08/29 08:05:40 step 5: mse=141.564342 step=0.100000
2017/08/29 08:05:42 step 6: mse=140.251461 step=0.100000
2017/08/29 08:05:43 step 7: mse=139.395101 step=0.100000
2017/08/29 08:05:43 Saving...
2017/08/29 08:05:43 Gathering batch of experience...
2017/08/29 08:06:30 batch 1127: mean=257.107143 stddev=161.773506 entropy=0.307953 frames=6570 count=28
2017/08/29 08:06:30 Training policy...
2017/08/29 08:06:36 step 0: objective=1.3644778
2017/08/29 08:06:39 step 1: objective=1.3692721
2017/08/29 08:06:42 step 2: objective=1.3733922
2017/08/29 08:06:45 step 3: objective=1.3814596
2017/08/29 08:06:48 step 4: objective=1.3879405
2017/08/29 08:06:51 step 5: objective=1.3906595
2017/08/29 08:06:54 step 6: objective=1.3966506
2017/08/29 08:06:57 step 7: objective=1.3989085
2017/08/29 08:06:57 Training value function...
2017/08/29 08:07:00 step 0: mse=165.809051 step=0.100000
2017/08/29 08:07:01 step 1: mse=162.585821 step=0.100000
2017/08/29 08:07:03 step 2: mse=159.911888 step=0.100000
2017/08/29 08:07:04 step 3: mse=157.674315 step=0.100000
2017/08/29 08:07:05 step 4: mse=155.568095 step=0.100000
2017/08/29 08:07:07 step 5: mse=153.801787 step=0.100000
2017/08/29 08:07:08 step 6: mse=152.373792 step=0.100000
2017/08/29 08:07:10 step 7: mse=150.867666 step=0.100000
2017/08/29 08:07:10 Saving...
2017/08/29 08:07:10 Gathering batch of experience...
2017/08/29 08:08:05 batch 1128: mean=243.724138 stddev=201.154923 entropy=0.307421 frames=6752 count=29
2017/08/29 08:08:05 Training policy...
2017/08/29 08:08:11 step 0: objective=0.78402567
2017/08/29 08:08:14 step 1: objective=0.7919959
2017/08/29 08:08:17 step 2: objective=0.79656065
2017/08/29 08:08:20 step 3: objective=0.7997894
2017/08/29 08:08:23 step 4: objective=0.80358976
2017/08/29 08:08:26 step 5: objective=0.8086023
2017/08/29 08:08:29 step 6: objective=0.8127303
2017/08/29 08:08:32 step 7: objective=0.81485504
2017/08/29 08:08:32 Training value function...
2017/08/29 08:08:35 step 0: mse=134.091261 step=0.100000
2017/08/29 08:08:36 step 1: mse=132.443872 step=0.100000
2017/08/29 08:08:37 step 2: mse=131.407975 step=0.100000
2017/08/29 08:08:39 step 3: mse=130.319586 step=0.100000
2017/08/29 08:08:40 step 4: mse=129.333534 step=0.100000
2017/08/29 08:08:42 step 5: mse=128.036024 step=0.100000
2017/08/29 08:08:43 step 6: mse=127.216303 step=0.100000
2017/08/29 08:08:45 step 7: mse=126.747582 step=0.100000
2017/08/29 08:08:45 Saving...
2017/08/29 08:08:45 Gathering batch of experience...
2017/08/29 08:09:38 batch 1129: mean=250.633333 stddev=185.918707 entropy=0.309437 frames=7215 count=30
2017/08/29 08:09:38 Training policy...
2017/08/29 08:09:44 step 0: objective=0.8606985
2017/08/29 08:09:48 step 1: objective=0.8662815
2017/08/29 08:09:51 step 2: objective=0.87298346
2017/08/29 08:09:54 step 3: objective=0.8764132
2017/08/29 08:09:58 step 4: objective=0.878248
2017/08/29 08:10:01 step 5: objective=0.88142747
2017/08/29 08:10:04 step 6: objective=0.88372105
2017/08/29 08:10:07 step 7: objective=0.88611513
2017/08/29 08:10:07 Training value function...
2017/08/29 08:10:10 step 0: mse=142.946995 step=0.100000
2017/08/29 08:10:12 step 1: mse=140.805033 step=0.100000
2017/08/29 08:10:13 step 2: mse=138.989186 step=0.100000
2017/08/29 08:10:15 step 3: mse=137.406625 step=0.100000
2017/08/29 08:10:17 step 4: mse=135.903595 step=0.100000
2017/08/29 08:10:18 step 5: mse=134.781610 step=0.100000
2017/08/29 08:10:20 step 6: mse=133.838384 step=0.100000
2017/08/29 08:10:21 step 7: mse=132.765164 step=0.100000
2017/08/29 08:10:21 Saving...
2017/08/29 08:10:21 Gathering batch of experience...
2017/08/29 08:11:10 batch 1130: mean=243.000000 stddev=195.007515 entropy=0.308236 frames=6518 count=29
2017/08/29 08:11:10 Training policy...
2017/08/29 08:11:16 step 0: objective=1.4662188
2017/08/29 08:11:19 step 1: objective=1.4701555
2017/08/29 08:11:22 step 2: objective=1.4745935
2017/08/29 08:11:25 step 3: objective=1.4776176
2017/08/29 08:11:28 step 4: objective=1.4806128
2017/08/29 08:11:31 step 5: objective=1.4848217
2017/08/29 08:11:34 step 6: objective=1.4908946
2017/08/29 08:11:37 step 7: objective=1.4936082
2017/08/29 08:11:37 Training value function...
2017/08/29 08:11:39 step 0: mse=171.476286 step=0.100000
2017/08/29 08:11:41 step 1: mse=168.979114 step=0.100000
2017/08/29 08:11:42 step 2: mse=166.773671 step=0.100000
2017/08/29 08:11:43 step 3: mse=164.964283 step=0.100000
2017/08/29 08:11:45 step 4: mse=163.040180 step=0.100000
2017/08/29 08:11:46 step 5: mse=161.364857 step=0.100000
2017/08/29 08:11:48 step 6: mse=159.649321 step=0.100000
2017/08/29 08:11:49 step 7: mse=158.441780 step=0.100000
2017/08/29 08:11:49 Saving...
2017/08/29 08:11:49 Gathering batch of experience...
2017/08/29 08:12:34 batch 1131: mean=239.571429 stddev=195.015646 entropy=0.307233 frames=6149 count=28
2017/08/29 08:12:34 Training policy...
2017/08/29 08:12:39 step 0: objective=1.217687
2017/08/29 08:12:42 step 1: objective=1.2213581
2017/08/29 08:12:45 step 2: objective=1.2277141
2017/08/29 08:12:48 step 3: objective=1.2312461
2017/08/29 08:12:51 step 4: objective=1.2345188
2017/08/29 08:12:53 step 5: objective=1.2389439
2017/08/29 08:12:56 step 6: objective=1.2417431
2017/08/29 08:12:59 step 7: objective=1.244355
2017/08/29 08:12:59 Training value function...
2017/08/29 08:13:02 step 0: mse=163.738173 step=0.100000
2017/08/29 08:13:03 step 1: mse=161.544414 step=0.100000
2017/08/29 08:13:04 step 2: mse=159.294422 step=0.100000
2017/08/29 08:13:05 step 3: mse=157.744264 step=0.100000
2017/08/29 08:13:07 step 4: mse=155.946393 step=0.100000
2017/08/29 08:13:08 step 5: mse=154.799355 step=0.100000
2017/08/29 08:13:09 step 6: mse=153.553012 step=0.100000
2017/08/29 08:13:11 step 7: mse=152.269999 step=0.100000
2017/08/29 08:13:11 Saving...
2017/08/29 08:13:11 Gathering batch of experience...
2017/08/29 08:13:57 batch 1132: mean=262.000000 stddev=180.598339 entropy=0.302575 frames=6195 count=25
2017/08/29 08:13:57 Training policy...
2017/08/29 08:14:03 step 0: objective=0.9564651
2017/08/29 08:14:06 step 1: objective=0.95990705
2017/08/29 08:14:08 step 2: objective=0.9628916
2017/08/29 08:14:11 step 3: objective=0.9656437
2017/08/29 08:14:14 step 4: objective=0.9688608
2017/08/29 08:14:17 step 5: objective=0.9713428
2017/08/29 08:14:19 step 6: objective=0.974194
2017/08/29 08:14:22 step 7: objective=0.9778352
2017/08/29 08:14:22 Training value function...
2017/08/29 08:14:25 step 0: mse=138.216067 step=0.100000
2017/08/29 08:14:26 step 1: mse=136.351713 step=0.100000
2017/08/29 08:14:27 step 2: mse=135.097268 step=0.100000
2017/08/29 08:14:29 step 3: mse=134.109893 step=0.100000
2017/08/29 08:14:30 step 4: mse=132.741500 step=0.100000
2017/08/29 08:14:31 step 5: mse=131.860098 step=0.100000
2017/08/29 08:14:33 step 6: mse=130.587263 step=0.100000
2017/08/29 08:14:34 step 7: mse=129.693561 step=0.100000
2017/08/29 08:14:34 Saving...
2017/08/29 08:14:34 Gathering batch of experience...
2017/08/29 08:15:19 batch 1133: mean=206.321429 stddev=171.608161 entropy=0.305379 frames=5662 count=28
2017/08/29 08:15:19 Training policy...
2017/08/29 08:15:24 step 0: objective=0.19748232
2017/08/29 08:15:26 step 1: objective=0.20427729
2017/08/29 08:15:29 step 2: objective=0.20727843
2017/08/29 08:15:31 step 3: objective=0.21096785
2017/08/29 08:15:34 step 4: objective=0.21422668
2017/08/29 08:15:36 step 5: objective=0.21725687
2017/08/29 08:15:39 step 6: objective=0.21945715
2017/08/29 08:15:41 step 7: objective=0.2223353
2017/08/29 08:15:41 Training value function...
2017/08/29 08:15:44 step 0: mse=130.172939 step=0.100000
2017/08/29 08:15:45 step 1: mse=127.821338 step=0.100000
2017/08/29 08:15:46 step 2: mse=126.318514 step=0.100000
2017/08/29 08:15:47 step 3: mse=125.005344 step=0.100000
2017/08/29 08:15:49 step 4: mse=124.206823 step=0.100000
2017/08/29 08:15:50 step 5: mse=123.252123 step=0.100000
2017/08/29 08:15:51 step 6: mse=122.277455 step=0.100000
2017/08/29 08:15:52 step 7: mse=121.507907 step=0.100000
2017/08/29 08:15:52 Saving...
2017/08/29 08:15:52 Gathering batch of experience...
2017/08/29 08:16:40 batch 1134: mean=280.600000 stddev=177.504028 entropy=0.305091 frames=6134 count=25
2017/08/29 08:16:40 Training policy...
2017/08/29 08:16:46 step 0: objective=2.3919363
2017/08/29 08:16:48 step 1: objective=2.3983016
2017/08/29 08:16:51 step 2: objective=2.4028518
2017/08/29 08:16:54 step 3: objective=2.407645
2017/08/29 08:16:57 step 4: objective=2.4122634
2017/08/29 08:16:59 step 5: objective=2.4174578
2017/08/29 08:17:02 step 6: objective=2.4208708
2017/08/29 08:17:05 step 7: objective=2.4267366
2017/08/29 08:17:05 Training value function...
2017/08/29 08:17:08 step 0: mse=166.726252 step=0.100000
2017/08/29 08:17:09 step 1: mse=160.315085 step=0.100000
2017/08/29 08:17:10 step 2: mse=154.858988 step=0.100000
2017/08/29 08:17:12 step 3: mse=150.017974 step=0.100000
2017/08/29 08:17:13 step 4: mse=146.155662 step=0.100000
2017/08/29 08:17:14 step 5: mse=142.733721 step=0.100000
2017/08/29 08:17:15 step 6: mse=139.968187 step=0.100000
2017/08/29 08:17:17 step 7: mse=137.504714 step=0.100000
2017/08/29 08:17:17 Saving...
2017/08/29 08:17:17 Gathering batch of experience...
2017/08/29 08:18:06 batch 1135: mean=189.722222 stddev=172.433177 entropy=0.304407 frames=6267 count=36
2017/08/29 08:18:06 Training policy...
2017/08/29 08:18:12 step 0: objective=0.5378875
2017/08/29 08:18:14 step 1: objective=0.5423207
2017/08/29 08:18:17 step 2: objective=0.5478226
2017/08/29 08:18:20 step 3: objective=0.55248344
2017/08/29 08:18:23 step 4: objective=0.55845135
2017/08/29 08:18:26 step 5: objective=0.5625009
2017/08/29 08:18:29 step 6: objective=0.56825286
2017/08/29 08:18:31 step 7: objective=0.570871
2017/08/29 08:18:31 Training value function...
2017/08/29 08:18:34 step 0: mse=166.037218 step=0.100000
2017/08/29 08:18:35 step 1: mse=162.974422 step=0.100000
2017/08/29 08:18:37 step 2: mse=160.963344 step=0.100000
2017/08/29 08:18:38 step 3: mse=158.868285 step=0.100000
2017/08/29 08:18:39 step 4: mse=157.536722 step=0.100000
2017/08/29 08:18:41 step 5: mse=156.394304 step=0.100000
2017/08/29 08:18:42 step 6: mse=155.509851 step=0.100000
2017/08/29 08:18:43 step 7: mse=154.222036 step=0.100000
2017/08/29 08:18:43 Saving...
2017/08/29 08:18:43 Gathering batch of experience...
2017/08/29 08:19:38 batch 1136: mean=261.206897 stddev=203.789002 entropy=0.301337 frames=6907 count=29
2017/08/29 08:19:38 Training policy...
2017/08/29 08:19:45 step 0: objective=1.7131548
2017/08/29 08:19:48 step 1: objective=1.7209235
2017/08/29 08:19:51 step 2: objective=1.726359
2017/08/29 08:19:54 step 3: objective=1.7329327
2017/08/29 08:19:57 step 4: objective=1.7365121
2017/08/29 08:20:00 step 5: objective=1.7409109
2017/08/29 08:20:03 step 6: objective=1.744354
2017/08/29 08:20:06 step 7: objective=1.7486926
2017/08/29 08:20:06 Training value function...
2017/08/29 08:20:09 step 0: mse=162.256226 step=0.100000
2017/08/29 08:20:11 step 1: mse=158.244237 step=0.100000
2017/08/29 08:20:12 step 2: mse=154.790217 step=0.100000
2017/08/29 08:20:14 step 3: mse=151.709401 step=0.100000
2017/08/29 08:20:15 step 4: mse=149.399664 step=0.100000
2017/08/29 08:20:17 step 5: mse=146.958661 step=0.100000
2017/08/29 08:20:18 step 6: mse=145.349905 step=0.100000
2017/08/29 08:20:20 step 7: mse=144.035099 step=0.100000
2017/08/29 08:20:20 Saving...
2017/08/29 08:20:20 Gathering batch of experience...
2017/08/29 08:21:10 batch 1137: mean=204.875000 stddev=157.196285 entropy=0.302830 frames=6361 count=32
2017/08/29 08:21:10 Training policy...
2017/08/29 08:21:15 step 0: objective=-0.058696173
2017/08/29 08:21:18 step 1: objective=-0.053575028
2017/08/29 08:21:21 step 2: objective=-0.04944751
2017/08/29 08:21:24 step 3: objective=-0.0469857
2017/08/29 08:21:27 step 4: objective=-0.043639608
2017/08/29 08:21:30 step 5: objective=-0.03957477
2017/08/29 08:21:33 step 6: objective=-0.034293123
2017/08/29 08:21:36 step 7: objective=-0.030548995
2017/08/29 08:21:36 Training value function...
2017/08/29 08:21:38 step 0: mse=140.997922 step=0.100000
2017/08/29 08:21:40 step 1: mse=138.121977 step=0.100000
2017/08/29 08:21:41 step 2: mse=136.165695 step=0.100000
2017/08/29 08:21:42 step 3: mse=134.336800 step=0.100000
2017/08/29 08:21:44 step 4: mse=132.980176 step=0.100000
2017/08/29 08:21:45 step 5: mse=132.054819 step=0.100000
2017/08/29 08:21:46 step 6: mse=130.718102 step=0.100000
2017/08/29 08:21:48 step 7: mse=130.101138 step=0.100000
2017/08/29 08:21:48 Saving...
2017/08/29 08:21:48 Gathering batch of experience...
2017/08/29 08:22:39 batch 1138: mean=214.645161 stddev=174.047370 entropy=0.304849 frames=6356 count=31
2017/08/29 08:22:39 Training policy...
2017/08/29 08:22:44 step 0: objective=0.8335794
2017/08/29 08:22:47 step 1: objective=0.838481
2017/08/29 08:22:50 step 2: objective=0.84381
2017/08/29 08:22:53 step 3: objective=0.8475587
2017/08/29 08:22:56 step 4: objective=0.8547914
2017/08/29 08:22:59 step 5: objective=0.8601917
2017/08/29 08:23:02 step 6: objective=0.8636299
2017/08/29 08:23:05 step 7: objective=0.8664953
2017/08/29 08:23:05 Training value function...
2017/08/29 08:23:07 step 0: mse=152.493743 step=0.100000
2017/08/29 08:23:09 step 1: mse=148.811639 step=0.100000
2017/08/29 08:23:10 step 2: mse=145.688945 step=0.100000
2017/08/29 08:23:11 step 3: mse=143.263645 step=0.100000
2017/08/29 08:23:13 step 4: mse=140.784802 step=0.100000
2017/08/29 08:23:14 step 5: mse=138.778557 step=0.100000
2017/08/29 08:23:15 step 6: mse=137.096698 step=0.100000
2017/08/29 08:23:17 step 7: mse=135.643152 step=0.100000
2017/08/29 08:23:17 Saving...
2017/08/29 08:23:17 Gathering batch of experience...
2017/08/29 08:24:10 batch 1139: mean=306.826087 stddev=168.232927 entropy=0.308485 frames=6523 count=23
2017/08/29 08:24:10 Training policy...
2017/08/29 08:24:16 step 0: objective=1.8616294
2017/08/29 08:24:19 step 1: objective=1.8663573
2017/08/29 08:24:22 step 2: objective=1.8710626
2017/08/29 08:24:25 step 3: objective=1.8761314
2017/08/29 08:24:28 step 4: objective=1.8784117
2017/08/29 08:24:30 step 5: objective=1.8823858
2017/08/29 08:24:33 step 6: objective=1.8855776
2017/08/29 08:24:36 step 7: objective=1.8884718
2017/08/29 08:24:36 Training value function...
2017/08/29 08:24:39 step 0: mse=157.190808 step=0.100000
2017/08/29 08:24:41 step 1: mse=153.280873 step=0.100000
2017/08/29 08:24:42 step 2: mse=150.034626 step=0.100000
2017/08/29 08:24:43 step 3: mse=146.764329 step=0.100000
2017/08/29 08:24:45 step 4: mse=144.287475 step=0.100000
2017/08/29 08:24:46 step 5: mse=142.021070 step=0.100000
2017/08/29 08:24:47 step 6: mse=139.907305 step=0.100000
2017/08/29 08:24:49 step 7: mse=137.984336 step=0.100000
2017/08/29 08:24:49 Saving...
2017/08/29 08:24:49 Gathering batch of experience...
2017/08/29 08:25:39 batch 1140: mean=191.454545 stddev=163.155641 entropy=0.298601 frames=6093 count=33
2017/08/29 08:25:39 Training policy...
2017/08/29 08:25:44 step 0: objective=0.20245108
2017/08/29 08:25:47 step 1: objective=0.20842865
2017/08/29 08:25:50 step 2: objective=0.21526976
2017/08/29 08:25:53 step 3: objective=0.21823207
2017/08/29 08:25:55 step 4: objective=0.22129422
2017/08/29 08:25:58 step 5: objective=0.2249326
2017/08/29 08:26:01 step 6: objective=0.22719142
2017/08/29 08:26:04 step 7: objective=0.22952029
2017/08/29 08:26:04 Training value function...
2017/08/29 08:26:06 step 0: mse=136.331438 step=0.100000
2017/08/29 08:26:07 step 1: mse=134.829462 step=0.100000
2017/08/29 08:26:09 step 2: mse=133.853414 step=0.100000
2017/08/29 08:26:10 step 3: mse=132.958316 step=0.100000
2017/08/29 08:26:11 step 4: mse=132.229231 step=0.100000
2017/08/29 08:26:13 step 5: mse=131.432808 step=0.100000
2017/08/29 08:26:14 step 6: mse=130.807572 step=0.100000
2017/08/29 08:26:15 step 7: mse=130.171532 step=0.100000
2017/08/29 08:26:15 Saving...
2017/08/29 08:26:15 Gathering batch of experience...
2017/08/29 08:27:14 batch 1141: mean=289.285714 stddev=212.296265 entropy=0.311419 frames=7675 count=28
2017/08/29 08:27:14 Training policy...
2017/08/29 08:27:21 step 0: objective=1.6463872
2017/08/29 08:27:24 step 1: objective=1.6506493
2017/08/29 08:27:28 step 2: objective=1.6549449
2017/08/29 08:27:31 step 3: objective=1.6600901
2017/08/29 08:27:35 step 4: objective=1.6652647
2017/08/29 08:27:38 step 5: objective=1.6678896
2017/08/29 08:27:42 step 6: objective=1.6699256
2017/08/29 08:27:45 step 7: objective=1.6748446
2017/08/29 08:27:45 Training value function...
2017/08/29 08:27:48 step 0: mse=161.085794 step=0.100000
2017/08/29 08:27:50 step 1: mse=157.376077 step=0.100000
2017/08/29 08:27:52 step 2: mse=154.217177 step=0.100000
2017/08/29 08:27:53 step 3: mse=151.510963 step=0.100000
2017/08/29 08:27:55 step 4: mse=149.435715 step=0.100000
2017/08/29 08:27:57 step 5: mse=147.327509 step=0.100000
2017/08/29 08:27:58 step 6: mse=145.684541 step=0.100000
2017/08/29 08:28:00 step 7: mse=144.099788 step=0.100000
2017/08/29 08:28:00 Saving...
2017/08/29 08:28:00 Gathering batch of experience...
2017/08/29 08:28:44 batch 1142: mean=201.483871 stddev=133.830868 entropy=0.302789 frames=5677 count=31
2017/08/29 08:28:44 Training policy...
2017/08/29 08:28:49 step 0: objective=0.96713495
2017/08/29 08:28:52 step 1: objective=0.97380674
2017/08/29 08:28:54 step 2: objective=0.9831769
2017/08/29 08:28:57 step 3: objective=0.99120474
2017/08/29 08:29:00 step 4: objective=0.9952426
2017/08/29 08:29:02 step 5: objective=1.0019984
2017/08/29 08:29:05 step 6: objective=1.0074985
2017/08/29 08:29:07 step 7: objective=1.010993
2017/08/29 08:29:07 Training value function...
2017/08/29 08:29:10 step 0: mse=148.381905 step=0.100000
2017/08/29 08:29:11 step 1: mse=145.656149 step=0.100000
2017/08/29 08:29:12 step 2: mse=143.452753 step=0.100000
2017/08/29 08:29:13 step 3: mse=141.646081 step=0.100000
2017/08/29 08:29:14 step 4: mse=139.956698 step=0.100000
2017/08/29 08:29:16 step 5: mse=138.701082 step=0.100000
2017/08/29 08:29:17 step 6: mse=137.339873 step=0.100000
2017/08/29 08:29:18 step 7: mse=136.118847 step=0.100000
2017/08/29 08:29:18 Saving...
2017/08/29 08:29:18 Gathering batch of experience...
2017/08/29 08:30:09 batch 1143: mean=246.200000 stddev=184.272696 entropy=0.303716 frames=6672 count=30
2017/08/29 08:30:09 Training policy...
2017/08/29 08:30:15 step 0: objective=1.6383595
2017/08/29 08:30:18 step 1: objective=1.6441302
2017/08/29 08:30:21 step 2: objective=1.6502724
2017/08/29 08:30:25 step 3: objective=1.6589446
2017/08/29 08:30:28 step 4: objective=1.6624064
2017/08/29 08:30:31 step 5: objective=1.6648246
2017/08/29 08:30:34 step 6: objective=1.66863
2017/08/29 08:30:37 step 7: objective=1.6728065
2017/08/29 08:30:37 Training value function...
2017/08/29 08:30:39 step 0: mse=184.736791 step=0.100000
2017/08/29 08:30:41 step 1: mse=180.034262 step=0.100000
2017/08/29 08:30:42 step 2: mse=176.001770 step=0.100000
2017/08/29 08:30:44 step 3: mse=172.533271 step=0.100000
2017/08/29 08:30:45 step 4: mse=169.345234 step=0.100000
2017/08/29 08:30:47 step 5: mse=166.703249 step=0.100000
2017/08/29 08:30:48 step 6: mse=164.068768 step=0.100000
2017/08/29 08:30:49 step 7: mse=162.029493 step=0.100000
2017/08/29 08:30:49 Saving...
2017/08/29 08:30:49 Gathering batch of experience...
2017/08/29 08:31:38 batch 1144: mean=257.615385 stddev=175.628996 entropy=0.308163 frames=6469 count=26
2017/08/29 08:31:38 Training policy...
2017/08/29 08:31:44 step 0: objective=0.5956197
2017/08/29 08:31:47 step 1: objective=0.59980696
2017/08/29 08:31:50 step 2: objective=0.6032628
2017/08/29 08:31:53 step 3: objective=0.6092474
2017/08/29 08:31:55 step 4: objective=0.61221945
2017/08/29 08:31:58 step 5: objective=0.61634713
2017/08/29 08:32:01 step 6: objective=0.6203093
2017/08/29 08:32:04 step 7: objective=0.6236183
2017/08/29 08:32:04 Training value function...
2017/08/29 08:32:07 step 0: mse=135.100526 step=0.100000
2017/08/29 08:32:08 step 1: mse=132.782179 step=0.100000
2017/08/29 08:32:10 step 2: mse=131.151776 step=0.100000
2017/08/29 08:32:11 step 3: mse=129.483811 step=0.100000
2017/08/29 08:32:12 step 4: mse=127.831993 step=0.100000
2017/08/29 08:32:14 step 5: mse=126.539105 step=0.100000
2017/08/29 08:32:15 step 6: mse=125.430198 step=0.100000
2017/08/29 08:32:17 step 7: mse=124.399878 step=0.100000
2017/08/29 08:32:17 Saving...
2017/08/29 08:32:17 Gathering batch of experience...
2017/08/29 08:33:09 batch 1145: mean=226.606061 stddev=193.197017 entropy=0.304409 frames=6976 count=33
2017/08/29 08:33:09 Training policy...
2017/08/29 08:33:16 step 0: objective=1.1807871
2017/08/29 08:33:19 step 1: objective=1.1868318
2017/08/29 08:33:22 step 2: objective=1.1902931
2017/08/29 08:33:25 step 3: objective=1.1930968
2017/08/29 08:33:28 step 4: objective=1.1955348
2017/08/29 08:33:32 step 5: objective=1.1985195
2017/08/29 08:33:35 step 6: objective=1.2013872
2017/08/29 08:33:38 step 7: objective=1.2037996
2017/08/29 08:33:38 Training value function...
2017/08/29 08:33:41 step 0: mse=173.549147 step=0.100000
2017/08/29 08:33:42 step 1: mse=169.373036 step=0.100000
2017/08/29 08:33:44 step 2: mse=165.198449 step=0.100000
2017/08/29 08:33:45 step 3: mse=161.985943 step=0.100000
2017/08/29 08:33:47 step 4: mse=159.154268 step=0.100000
2017/08/29 08:33:48 step 5: mse=156.541477 step=0.100000
2017/08/29 08:33:50 step 6: mse=154.349150 step=0.100000
2017/08/29 08:33:51 step 7: mse=152.558771 step=0.100000
2017/08/29 08:33:51 Saving...
2017/08/29 08:33:51 Gathering batch of experience...
2017/08/29 08:34:35 batch 1146: mean=226.071429 stddev=188.926276 entropy=0.302017 frames=5961 count=28
2017/08/29 08:34:35 Training policy...
2017/08/29 08:34:40 step 0: objective=0.8526846
2017/08/29 08:34:43 step 1: objective=0.8594426
2017/08/29 08:34:46 step 2: objective=0.86589754
2017/08/29 08:34:48 step 3: objective=0.8692276
2017/08/29 08:34:51 step 4: objective=0.8735466
2017/08/29 08:34:54 step 5: objective=0.87780786
2017/08/29 08:34:56 step 6: objective=0.88054657
2017/08/29 08:34:59 step 7: objective=0.8825403
2017/08/29 08:34:59 Training value function...
2017/08/29 08:35:02 step 0: mse=162.906244 step=0.100000
2017/08/29 08:35:03 step 1: mse=160.116910 step=0.100000
2017/08/29 08:35:04 step 2: mse=157.731070 step=0.100000
2017/08/29 08:35:05 step 3: mse=155.856102 step=0.100000
2017/08/29 08:35:07 step 4: mse=154.206725 step=0.100000
2017/08/29 08:35:08 step 5: mse=152.693522 step=0.100000
2017/08/29 08:35:09 step 6: mse=151.115099 step=0.100000
2017/08/29 08:35:11 step 7: mse=149.981568 step=0.100000
2017/08/29 08:35:11 Saving...
2017/08/29 08:35:11 Gathering batch of experience...
2017/08/29 08:36:03 batch 1147: mean=245.931034 stddev=182.204306 entropy=0.303560 frames=6606 count=29
2017/08/29 08:36:03 Training policy...
2017/08/29 08:36:09 step 0: objective=1.3118788
2017/08/29 08:36:12 step 1: objective=1.3169038
2017/08/29 08:36:15 step 2: objective=1.3206836
2017/08/29 08:36:18 step 3: objective=1.3235421
2017/08/29 08:36:21 step 4: objective=1.3279694
2017/08/29 08:36:24 step 5: objective=1.3323115
2017/08/29 08:36:27 step 6: objective=1.338028
2017/08/29 08:36:30 step 7: objective=1.3419081
2017/08/29 08:36:30 Training value function...
2017/08/29 08:36:33 step 0: mse=165.367311 step=0.100000
2017/08/29 08:36:34 step 1: mse=162.824614 step=0.100000
2017/08/29 08:36:35 step 2: mse=160.342303 step=0.100000
2017/08/29 08:36:37 step 3: mse=158.041549 step=0.100000
2017/08/29 08:36:38 step 4: mse=156.116120 step=0.100000
2017/08/29 08:36:40 step 5: mse=154.253976 step=0.100000
2017/08/29 08:36:41 step 6: mse=152.806602 step=0.100000
2017/08/29 08:36:42 step 7: mse=151.529087 step=0.100000
2017/08/29 08:36:42 Saving...
2017/08/29 08:36:43 Gathering batch of experience...
2017/08/29 08:37:28 batch 1148: mean=230.192308 stddev=159.691293 entropy=0.306393 frames=5754 count=26
2017/08/29 08:37:28 Training policy...
2017/08/29 08:37:33 step 0: objective=0.68630916
2017/08/29 08:37:36 step 1: objective=0.6943363
2017/08/29 08:37:39 step 2: objective=0.7002901
2017/08/29 08:37:41 step 3: objective=0.7078463
2017/08/29 08:37:44 step 4: objective=0.71238065
2017/08/29 08:37:47 step 5: objective=0.71717656
2017/08/29 08:37:49 step 6: objective=0.7198477
2017/08/29 08:37:52 step 7: objective=0.7234826
2017/08/29 08:37:52 Training value function...
2017/08/29 08:37:54 step 0: mse=142.142518 step=0.100000
2017/08/29 08:37:55 step 1: mse=139.983989 step=0.100000
2017/08/29 08:37:57 step 2: mse=138.013687 step=0.100000
2017/08/29 08:37:58 step 3: mse=136.300892 step=0.100000
2017/08/29 08:37:59 step 4: mse=134.859621 step=0.100000
2017/08/29 08:38:00 step 5: mse=133.586917 step=0.100000
2017/08/29 08:38:02 step 6: mse=132.304292 step=0.100000
2017/08/29 08:38:03 step 7: mse=131.415242 step=0.100000
2017/08/29 08:38:03 Saving...
2017/08/29 08:38:03 Gathering batch of experience...
2017/08/29 08:38:51 batch 1149: mean=202.939394 stddev=158.467460 entropy=0.304408 frames=6071 count=33
2017/08/29 08:38:51 Training policy...
2017/08/29 08:38:56 step 0: objective=1.3370594
2017/08/29 08:38:59 step 1: objective=1.3457636
2017/08/29 08:39:02 step 2: objective=1.3545253
2017/08/29 08:39:05 step 3: objective=1.3585175
2017/08/29 08:39:07 step 4: objective=1.3630832
2017/08/29 08:39:10 step 5: objective=1.3676126
2017/08/29 08:39:13 step 6: objective=1.3702856
2017/08/29 08:39:16 step 7: objective=1.3743392
2017/08/29 08:39:16 Training value function...
2017/08/29 08:39:18 step 0: mse=198.216487 step=0.100000
2017/08/29 08:39:19 step 1: mse=194.046231 step=0.100000
2017/08/29 08:39:21 step 2: mse=190.586338 step=0.100000
2017/08/29 08:39:22 step 3: mse=187.297693 step=0.100000
2017/08/29 08:39:23 step 4: mse=184.664521 step=0.100000
2017/08/29 08:39:25 step 5: mse=182.111212 step=0.100000
2017/08/29 08:39:26 step 6: mse=180.151432 step=0.100000
2017/08/29 08:39:27 step 7: mse=178.417615 step=0.100000
2017/08/29 08:39:27 Saving...
2017/08/29 08:39:27 Gathering batch of experience...
2017/08/29 08:40:17 batch 1150: mean=315.304348 stddev=185.877808 entropy=0.306991 frames=6709 count=23
2017/08/29 08:40:17 Training policy...
2017/08/29 08:40:23 step 0: objective=1.7062758
2017/08/29 08:40:27 step 1: objective=1.7094375
2017/08/29 08:40:30 step 2: objective=1.7147857
2017/08/29 08:40:33 step 3: objective=1.718742
2017/08/29 08:40:36 step 4: objective=1.7232342
2017/08/29 08:40:39 step 5: objective=1.7256849
2017/08/29 08:40:42 step 6: objective=1.727579
2017/08/29 08:40:45 step 7: objective=1.7297692
2017/08/29 08:40:45 Training value function...
2017/08/29 08:40:48 step 0: mse=147.508838 step=0.100000
2017/08/29 08:40:49 step 1: mse=144.339115 step=0.100000
2017/08/29 08:40:51 step 2: mse=141.158972 step=0.100000
2017/08/29 08:40:52 step 3: mse=138.584163 step=0.100000
2017/08/29 08:40:54 step 4: mse=136.445153 step=0.100000
2017/08/29 08:40:55 step 5: mse=134.370484 step=0.100000
2017/08/29 08:40:56 step 6: mse=132.751192 step=0.100000
2017/08/29 08:40:58 step 7: mse=130.894950 step=0.100000
2017/08/29 08:40:58 Saving...
2017/08/29 08:40:58 Gathering batch of experience...
2017/08/29 08:41:52 batch 1151: mean=242.677419 stddev=174.477171 entropy=0.298910 frames=7025 count=31
2017/08/29 08:41:52 Training policy...
2017/08/29 08:41:59 step 0: objective=0.753425
2017/08/29 08:42:02 step 1: objective=0.7611464
2017/08/29 08:42:05 step 2: objective=0.7649669
2017/08/29 08:42:08 step 3: objective=0.7688615
2017/08/29 08:42:12 step 4: objective=0.7718958
2017/08/29 08:42:15 step 5: objective=0.7779953
2017/08/29 08:42:18 step 6: objective=0.78158426
2017/08/29 08:42:21 step 7: objective=0.78409636
2017/08/29 08:42:21 Training value function...
2017/08/29 08:42:24 step 0: mse=170.650756 step=0.100000
2017/08/29 08:42:26 step 1: mse=167.448543 step=0.100000
2017/08/29 08:42:27 step 2: mse=164.756631 step=0.100000
2017/08/29 08:42:29 step 3: mse=162.315408 step=0.100000
2017/08/29 08:42:30 step 4: mse=160.033778 step=0.100000
2017/08/29 08:42:32 step 5: mse=158.183046 step=0.100000
2017/08/29 08:42:33 step 6: mse=156.984003 step=0.100000
2017/08/29 08:42:35 step 7: mse=155.475590 step=0.100000
2017/08/29 08:42:35 Saving...
2017/08/29 08:42:35 Gathering batch of experience...
2017/08/29 08:43:23 batch 1152: mean=218.551724 stddev=174.947990 entropy=0.303619 frames=6283 count=29
2017/08/29 08:43:23 Training policy...
2017/08/29 08:43:29 step 0: objective=0.12123951
2017/08/29 08:43:32 step 1: objective=0.12646256
2017/08/29 08:43:35 step 2: objective=0.13086101
2017/08/29 08:43:37 step 3: objective=0.13321799
2017/08/29 08:43:40 step 4: objective=0.13651827
2017/08/29 08:43:43 step 5: objective=0.14025772
2017/08/29 08:43:46 step 6: objective=0.14234617
2017/08/29 08:43:49 step 7: objective=0.14503914
2017/08/29 08:43:49 Training value function...
2017/08/29 08:43:52 step 0: mse=128.326179 step=0.100000
2017/08/29 08:43:53 step 1: mse=126.893352 step=0.100000
2017/08/29 08:43:54 step 2: mse=125.561367 step=0.100000
2017/08/29 08:43:56 step 3: mse=124.732379 step=0.100000
2017/08/29 08:43:57 step 4: mse=124.077630 step=0.100000
2017/08/29 08:43:58 step 5: mse=123.644042 step=0.100000
2017/08/29 08:44:00 step 6: mse=123.177256 step=0.100000
2017/08/29 08:44:01 step 7: mse=122.776399 step=0.100000
2017/08/29 08:44:01 Saving...
2017/08/29 08:44:01 Gathering batch of experience...
2017/08/29 08:44:53 batch 1153: mean=233.225806 stddev=149.293111 entropy=0.303492 frames=6551 count=31
2017/08/29 08:44:53 Training policy...
2017/08/29 08:44:59 step 0: objective=1.615182
2017/08/29 08:45:02 step 1: objective=1.6194866
2017/08/29 08:45:05 step 2: objective=1.6239938
2017/08/29 08:45:08 step 3: objective=1.6312575
2017/08/29 08:45:11 step 4: objective=1.6347684
2017/08/29 08:45:14 step 5: objective=1.6392139
2017/08/29 08:45:17 step 6: objective=1.641758
2017/08/29 08:45:20 step 7: objective=1.6444037
2017/08/29 08:45:20 Training value function...
2017/08/29 08:45:23 step 0: mse=148.601661 step=0.100000
2017/08/29 08:45:24 step 1: mse=145.955965 step=0.100000
2017/08/29 08:45:26 step 2: mse=143.560713 step=0.100000
2017/08/29 08:45:27 step 3: mse=141.643953 step=0.100000
2017/08/29 08:45:28 step 4: mse=139.814984 step=0.100000
2017/08/29 08:45:30 step 5: mse=138.306155 step=0.100000
2017/08/29 08:45:31 step 6: mse=136.708412 step=0.100000
2017/08/29 08:45:33 step 7: mse=135.459837 step=0.100000
2017/08/29 08:45:33 Saving...
2017/08/29 08:45:33 Gathering batch of experience...
2017/08/29 08:46:28 batch 1154: mean=210.029412 stddev=178.767263 entropy=0.307974 frames=7200 count=34
2017/08/29 08:46:28 Training policy...
2017/08/29 08:46:34 step 0: objective=0.1496326
2017/08/29 08:46:38 step 1: objective=0.15258084
2017/08/29 08:46:41 step 2: objective=0.15604483
2017/08/29 08:46:44 step 3: objective=0.15890118
2017/08/29 08:46:48 step 4: objective=0.16466452
2017/08/29 08:46:51 step 5: objective=0.1679899
2017/08/29 08:46:54 step 6: objective=0.17013085
2017/08/29 08:46:57 step 7: objective=0.1726507
2017/08/29 08:46:57 Training value function...
2017/08/29 08:47:01 step 0: mse=144.728823 step=0.100000
2017/08/29 08:47:02 step 1: mse=141.799119 step=0.100000
2017/08/29 08:47:04 step 2: mse=139.583374 step=0.100000
2017/08/29 08:47:05 step 3: mse=137.830153 step=0.100000
2017/08/29 08:47:07 step 4: mse=135.826836 step=0.100000
2017/08/29 08:47:08 step 5: mse=134.462087 step=0.100000
2017/08/29 08:47:10 step 6: mse=133.668764 step=0.100000
2017/08/29 08:47:11 step 7: mse=132.554518 step=0.100000
2017/08/29 08:47:11 Saving...
2017/08/29 08:47:11 Gathering batch of experience...
2017/08/29 08:48:02 batch 1155: mean=212.424242 stddev=153.796999 entropy=0.300167 frames=6499 count=33
2017/08/29 08:48:02 Training policy...
2017/08/29 08:48:08 step 0: objective=1.5656706
2017/08/29 08:48:11 step 1: objective=1.5700794
2017/08/29 08:48:14 step 2: objective=1.5738558
2017/08/29 08:48:17 step 3: objective=1.5771142
2017/08/29 08:48:20 step 4: objective=1.5810753
2017/08/29 08:48:23 step 5: objective=1.5846391
2017/08/29 08:48:26 step 6: objective=1.5882933
2017/08/29 08:48:29 step 7: objective=1.5913916
2017/08/29 08:48:29 Training value function...
2017/08/29 08:48:32 step 0: mse=151.671232 step=0.100000
2017/08/29 08:48:33 step 1: mse=147.838081 step=0.100000
2017/08/29 08:48:34 step 2: mse=144.680520 step=0.100000
2017/08/29 08:48:36 step 3: mse=142.340102 step=0.100000
2017/08/29 08:48:37 step 4: mse=140.023836 step=0.100000
2017/08/29 08:48:38 step 5: mse=137.755593 step=0.100000
2017/08/29 08:48:40 step 6: mse=136.119877 step=0.100000
2017/08/29 08:48:41 step 7: mse=134.623228 step=0.100000
2017/08/29 08:48:41 Saving...
2017/08/29 08:48:41 Gathering batch of experience...
2017/08/29 08:49:32 batch 1156: mean=295.360000 stddev=153.853926 entropy=0.309746 frames=7003 count=25
2017/08/29 08:49:32 Training policy...
2017/08/29 08:49:38 step 0: objective=1.5989631
2017/08/29 08:49:41 step 1: objective=1.6037358
2017/08/29 08:49:44 step 2: objective=1.6079378
2017/08/29 08:49:48 step 3: objective=1.6127455
2017/08/29 08:49:51 step 4: objective=1.6164185
2017/08/29 08:49:54 step 5: objective=1.6205643
2017/08/29 08:49:57 step 6: objective=1.6230507
2017/08/29 08:50:01 step 7: objective=1.624784
2017/08/29 08:50:01 Training value function...
2017/08/29 08:50:03 step 0: mse=129.432980 step=0.100000
2017/08/29 08:50:05 step 1: mse=126.735367 step=0.100000
2017/08/29 08:50:06 step 2: mse=124.288331 step=0.100000
2017/08/29 08:50:08 step 3: mse=122.110354 step=0.100000
2017/08/29 08:50:09 step 4: mse=119.822737 step=0.100000
2017/08/29 08:50:11 step 5: mse=118.202326 step=0.100000
2017/08/29 08:50:12 step 6: mse=116.624817 step=0.100000
2017/08/29 08:50:14 step 7: mse=115.352446 step=0.100000
2017/08/29 08:50:14 Saving...
2017/08/29 08:50:14 Gathering batch of experience...
2017/08/29 08:51:07 batch 1157: mean=223.205882 stddev=184.483186 entropy=0.303207 frames=7106 count=34
2017/08/29 08:51:07 Training policy...
2017/08/29 08:51:14 step 0: objective=1.0237888
2017/08/29 08:51:17 step 1: objective=1.0283866
2017/08/29 08:51:20 step 2: objective=1.0318011
2017/08/29 08:51:24 step 3: objective=1.0351883
2017/08/29 08:51:27 step 4: objective=1.0395994
2017/08/29 08:51:30 step 5: objective=1.0444139
2017/08/29 08:51:33 step 6: objective=1.0473238
2017/08/29 08:51:37 step 7: objective=1.0539001
2017/08/29 08:51:37 Training value function...
2017/08/29 08:51:40 step 0: mse=176.344733 step=0.100000
2017/08/29 08:51:41 step 1: mse=173.371451 step=0.100000
2017/08/29 08:51:43 step 2: mse=171.283891 step=0.100000
2017/08/29 08:51:44 step 3: mse=169.210234 step=0.100000
2017/08/29 08:51:46 step 4: mse=167.323287 step=0.100000
2017/08/29 08:51:47 step 5: mse=165.812914 step=0.100000
2017/08/29 08:51:49 step 6: mse=164.411631 step=0.100000
2017/08/29 08:51:50 step 7: mse=162.841501 step=0.100000
2017/08/29 08:51:50 Saving...
2017/08/29 08:51:50 Gathering batch of experience...
2017/08/29 08:52:38 batch 1158: mean=212.517241 stddev=148.536915 entropy=0.297194 frames=5937 count=29
2017/08/29 08:52:38 Training policy...
2017/08/29 08:52:44 step 0: objective=0.6180263
2017/08/29 08:52:47 step 1: objective=0.6253442
2017/08/29 08:52:49 step 2: objective=0.6309993
2017/08/29 08:52:52 step 3: objective=0.63441294
2017/08/29 08:52:55 step 4: objective=0.63804585
2017/08/29 08:52:58 step 5: objective=0.6405699
2017/08/29 08:53:00 step 6: objective=0.64421624
2017/08/29 08:53:03 step 7: objective=0.64612687
2017/08/29 08:53:03 Training value function...
2017/08/29 08:53:05 step 0: mse=154.805842 step=0.100000
2017/08/29 08:53:07 step 1: mse=153.578541 step=0.100000
2017/08/29 08:53:08 step 2: mse=152.626545 step=0.100000
2017/08/29 08:53:09 step 3: mse=151.730334 step=0.100000
2017/08/29 08:53:10 step 4: mse=150.891320 step=0.100000
2017/08/29 08:53:12 step 5: mse=150.084233 step=0.100000
2017/08/29 08:53:13 step 6: mse=149.110006 step=0.100000
2017/08/29 08:53:14 step 7: mse=148.169919 step=0.100000
2017/08/29 08:53:14 Saving...
2017/08/29 08:53:14 Gathering batch of experience...
2017/08/29 08:54:06 batch 1159: mean=221.200000 stddev=164.609315 entropy=0.306501 frames=6392 count=30
2017/08/29 08:54:06 Training policy...
2017/08/29 08:54:11 step 0: objective=0.94269335
2017/08/29 08:54:14 step 1: objective=0.94650006
2017/08/29 08:54:17 step 2: objective=0.95181197
2017/08/29 08:54:20 step 3: objective=0.95509416
2017/08/29 08:54:23 step 4: objective=0.95833987
2017/08/29 08:54:26 step 5: objective=0.9615478
2017/08/29 08:54:29 step 6: objective=0.96316427
2017/08/29 08:54:32 step 7: objective=0.96519077
2017/08/29 08:54:32 Training value function...
2017/08/29 08:54:35 step 0: mse=124.159275 step=0.100000
2017/08/29 08:54:36 step 1: mse=122.016823 step=0.100000
2017/08/29 08:54:37 step 2: mse=120.166160 step=0.100000
2017/08/29 08:54:39 step 3: mse=118.603046 step=0.100000
2017/08/29 08:54:40 step 4: mse=117.261001 step=0.100000
2017/08/29 08:54:41 step 5: mse=116.094098 step=0.100000
2017/08/29 08:54:43 step 6: mse=115.064709 step=0.100000
2017/08/29 08:54:44 step 7: mse=114.095472 step=0.100000
2017/08/29 08:54:44 Saving...
2017/08/29 08:54:44 Gathering batch of experience...
2017/08/29 08:55:39 batch 1160: mean=225.937500 stddev=179.419888 entropy=0.298092 frames=6606 count=32
2017/08/29 08:55:39 Training policy...
2017/08/29 08:55:45 step 0: objective=1.5860162
2017/08/29 08:55:48 step 1: objective=1.5932912
2017/08/29 08:55:51 step 2: objective=1.5985054
2017/08/29 08:55:54 step 3: objective=1.6010753
2017/08/29 08:55:57 step 4: objective=1.6039984
2017/08/29 08:56:00 step 5: objective=1.6060935
2017/08/29 08:56:03 step 6: objective=1.6088151
2017/08/29 08:56:06 step 7: objective=1.6112511
2017/08/29 08:56:06 Training value function...
2017/08/29 08:56:09 step 0: mse=159.677906 step=0.100000
2017/08/29 08:56:11 step 1: mse=156.444485 step=0.100000
2017/08/29 08:56:12 step 2: mse=153.487245 step=0.100000
2017/08/29 08:56:14 step 3: mse=151.468622 step=0.100000
2017/08/29 08:56:15 step 4: mse=149.367999 step=0.100000
2017/08/29 08:56:16 step 5: mse=147.616487 step=0.100000
2017/08/29 08:56:18 step 6: mse=146.115570 step=0.100000
2017/08/29 08:56:19 step 7: mse=144.854763 step=0.100000
2017/08/29 08:56:19 Saving...
2017/08/29 08:56:19 Gathering batch of experience...
2017/08/29 08:57:05 batch 1161: mean=201.833333 stddev=137.299935 entropy=0.300392 frames=5649 count=30
2017/08/29 08:57:05 Training policy...
2017/08/29 08:57:10 step 0: objective=0.78134096
2017/08/29 08:57:13 step 1: objective=0.7868048
2017/08/29 08:57:15 step 2: objective=0.7963408
2017/08/29 08:57:18 step 3: objective=0.8029514
2017/08/29 08:57:20 step 4: objective=0.80633366
2017/08/29 08:57:23 step 5: objective=0.8110705
2017/08/29 08:57:25 step 6: objective=0.81474596
2017/08/29 08:57:28 step 7: objective=0.8168798
2017/08/29 08:57:28 Training value function...
2017/08/29 08:57:30 step 0: mse=145.547549 step=0.100000
2017/08/29 08:57:32 step 1: mse=144.451200 step=0.100000
2017/08/29 08:57:33 step 2: mse=142.661020 step=0.100000
2017/08/29 08:57:34 step 3: mse=141.463756 step=0.100000
2017/08/29 08:57:35 step 4: mse=140.480841 step=0.100000
2017/08/29 08:57:36 step 5: mse=139.654214 step=0.100000
2017/08/29 08:57:38 step 6: mse=138.969478 step=0.100000
2017/08/29 08:57:39 step 7: mse=138.189891 step=0.100000
2017/08/29 08:57:39 Saving...
2017/08/29 08:57:39 Gathering batch of experience...
2017/08/29 08:58:35 batch 1162: mean=249.866667 stddev=210.612082 entropy=0.301231 frames=6987 count=30
2017/08/29 08:58:35 Training policy...
2017/08/29 08:58:41 step 0: objective=1.6886927
2017/08/29 08:58:44 step 1: objective=1.6931996
2017/08/29 08:58:47 step 2: objective=1.697568
2017/08/29 08:58:51 step 3: objective=1.7000436
2017/08/29 08:58:54 step 4: objective=1.7023461
2017/08/29 08:58:57 step 5: objective=1.7068062
2017/08/29 08:59:00 step 6: objective=1.7091798
2017/08/29 08:59:04 step 7: objective=1.7115015
2017/08/29 08:59:04 Training value function...
2017/08/29 08:59:06 step 0: mse=176.618759 step=0.100000
2017/08/29 08:59:08 step 1: mse=171.391556 step=0.100000
2017/08/29 08:59:09 step 2: mse=166.693733 step=0.100000
2017/08/29 08:59:11 step 3: mse=162.812358 step=0.100000
2017/08/29 08:59:12 step 4: mse=159.627943 step=0.100000
2017/08/29 08:59:14 step 5: mse=156.510667 step=0.100000
2017/08/29 08:59:15 step 6: mse=153.889121 step=0.100000
2017/08/29 08:59:17 step 7: mse=151.761615 step=0.100000
2017/08/29 08:59:17 Saving...
2017/08/29 08:59:17 Gathering batch of experience...
2017/08/29 09:00:18 batch 1163: mean=232.322581 stddev=209.893581 entropy=0.309096 frames=7085 count=31
2017/08/29 09:00:18 Training policy...
2017/08/29 09:00:24 step 0: objective=0.5345821
2017/08/29 09:00:28 step 1: objective=0.5382599
2017/08/29 09:00:31 step 2: objective=0.54451066
2017/08/29 09:00:34 step 3: objective=0.5474331
2017/08/29 09:00:37 step 4: objective=0.5498029
2017/08/29 09:00:41 step 5: objective=0.5523233
2017/08/29 09:00:44 step 6: objective=0.5551938
2017/08/29 09:00:47 step 7: objective=0.55816597
2017/08/29 09:00:47 Training value function...
2017/08/29 09:00:50 step 0: mse=144.792328 step=0.100000
2017/08/29 09:00:52 step 1: mse=142.596368 step=0.100000
2017/08/29 09:00:53 step 2: mse=140.697532 step=0.100000
2017/08/29 09:00:55 step 3: mse=139.065877 step=0.100000
2017/08/29 09:00:56 step 4: mse=137.838291 step=0.100000
2017/08/29 09:00:58 step 5: mse=137.229744 step=0.100000
2017/08/29 09:00:59 step 6: mse=136.252672 step=0.100000
2017/08/29 09:01:01 step 7: mse=135.438177 step=0.100000
2017/08/29 09:01:01 Saving...
2017/08/29 09:01:01 Gathering batch of experience...
2017/08/29 09:01:58 batch 1164: mean=254.741935 stddev=218.631074 entropy=0.312071 frames=7485 count=31
2017/08/29 09:01:58 Training policy...
2017/08/29 09:02:05 step 0: objective=1.4713056
2017/08/29 09:02:08 step 1: objective=1.4742348
2017/08/29 09:02:12 step 2: objective=1.4790127
2017/08/29 09:02:15 step 3: objective=1.4818534
2017/08/29 09:02:19 step 4: objective=1.4845383
2017/08/29 09:02:22 step 5: objective=1.48732
2017/08/29 09:02:26 step 6: objective=1.4901505
2017/08/29 09:02:29 step 7: objective=1.4943981
2017/08/29 09:02:29 Training value function...
2017/08/29 09:02:32 step 0: mse=168.840054 step=0.100000
2017/08/29 09:02:34 step 1: mse=165.324947 step=0.100000
2017/08/29 09:02:35 step 2: mse=162.244739 step=0.100000
2017/08/29 09:02:37 step 3: mse=159.563588 step=0.100000
2017/08/29 09:02:39 step 4: mse=157.498000 step=0.100000
2017/08/29 09:02:40 step 5: mse=155.903483 step=0.100000
2017/08/29 09:02:42 step 6: mse=153.919512 step=0.100000
2017/08/29 09:02:43 step 7: mse=152.279428 step=0.100000
2017/08/29 09:02:43 Saving...
2017/08/29 09:02:44 Gathering batch of experience...
2017/08/29 09:03:29 batch 1165: mean=200.100000 stddev=168.310497 entropy=0.309004 frames=5889 count=30
2017/08/29 09:03:29 Training policy...
2017/08/29 09:03:34 step 0: objective=0.4858631
2017/08/29 09:03:37 step 1: objective=0.49197164
2017/08/29 09:03:40 step 2: objective=0.496807
2017/08/29 09:03:42 step 3: objective=0.5030614
2017/08/29 09:03:45 step 4: objective=0.506892
2017/08/29 09:03:48 step 5: objective=0.51048285
2017/08/29 09:03:50 step 6: objective=0.51349336
2017/08/29 09:03:53 step 7: objective=0.51533765
2017/08/29 09:03:53 Training value function...
2017/08/29 09:03:56 step 0: mse=147.758071 step=0.100000
2017/08/29 09:03:57 step 1: mse=145.446895 step=0.100000
2017/08/29 09:03:58 step 2: mse=143.595669 step=0.100000
2017/08/29 09:03:59 step 3: mse=142.002253 step=0.100000
2017/08/29 09:04:01 step 4: mse=140.672341 step=0.100000
2017/08/29 09:04:02 step 5: mse=139.653874 step=0.100000
2017/08/29 09:04:03 step 6: mse=138.557844 step=0.100000
2017/08/29 09:04:04 step 7: mse=137.657724 step=0.100000
2017/08/29 09:04:04 Saving...
2017/08/29 09:04:04 Gathering batch of experience...
2017/08/29 09:04:59 batch 1166: mean=231.066667 stddev=168.588638 entropy=0.305075 frames=6435 count=30
2017/08/29 09:04:59 Training policy...
2017/08/29 09:05:05 step 0: objective=1.5184337
2017/08/29 09:05:08 step 1: objective=1.5232422
2017/08/29 09:05:11 step 2: objective=1.5316104
2017/08/29 09:05:14 step 3: objective=1.5381612
2017/08/29 09:05:17 step 4: objective=1.5448174
2017/08/29 09:05:20 step 5: objective=1.5500782
2017/08/29 09:05:23 step 6: objective=1.5520941
2017/08/29 09:05:26 step 7: objective=1.5556568
2017/08/29 09:05:26 Training value function...
2017/08/29 09:05:29 step 0: mse=166.161936 step=0.100000
2017/08/29 09:05:30 step 1: mse=161.572217 step=0.100000
2017/08/29 09:05:31 step 2: mse=157.528536 step=0.100000
2017/08/29 09:05:33 step 3: mse=154.009505 step=0.100000
2017/08/29 09:05:34 step 4: mse=150.991697 step=0.100000
2017/08/29 09:05:36 step 5: mse=148.646377 step=0.100000
2017/08/29 09:05:37 step 6: mse=146.199283 step=0.100000
2017/08/29 09:05:38 step 7: mse=144.286247 step=0.100000
2017/08/29 09:05:38 Saving...
2017/08/29 09:05:38 Gathering batch of experience...
2017/08/29 09:06:28 batch 1167: mean=307.625000 stddev=220.928498 entropy=0.305757 frames=6750 count=24
2017/08/29 09:06:28 Training policy...
2017/08/29 09:06:34 step 0: objective=2.0404825
2017/08/29 09:06:37 step 1: objective=2.0454628
2017/08/29 09:06:40 step 2: objective=2.051189
2017/08/29 09:06:43 step 3: objective=2.0558949
2017/08/29 09:06:46 step 4: objective=2.0594294
2017/08/29 09:06:50 step 5: objective=2.063288
2017/08/29 09:06:53 step 6: objective=2.0668192
2017/08/29 09:06:56 step 7: objective=2.0702875
2017/08/29 09:06:56 Training value function...
2017/08/29 09:06:59 step 0: mse=156.070363 step=0.100000
2017/08/29 09:07:00 step 1: mse=150.537317 step=0.100000
2017/08/29 09:07:02 step 2: mse=146.239490 step=0.100000
2017/08/29 09:07:03 step 3: mse=142.738033 step=0.100000
2017/08/29 09:07:04 step 4: mse=139.398269 step=0.100000
2017/08/29 09:07:06 step 5: mse=136.602273 step=0.100000
2017/08/29 09:07:07 step 6: mse=133.970742 step=0.100000
2017/08/29 09:07:09 step 7: mse=131.657741 step=0.100000
2017/08/29 09:07:09 Saving...
2017/08/29 09:07:09 Gathering batch of experience...
2017/08/29 09:08:04 batch 1168: mean=202.305556 stddev=179.037212 entropy=0.306285 frames=6816 count=36
2017/08/29 09:08:04 Training policy...
2017/08/29 09:08:10 step 0: objective=0.3947525
2017/08/29 09:08:13 step 1: objective=0.40076298
2017/08/29 09:08:16 step 2: objective=0.4062247
2017/08/29 09:08:19 step 3: objective=0.41277885
2017/08/29 09:08:22 step 4: objective=0.4172946
2017/08/29 09:08:26 step 5: objective=0.421807
2017/08/29 09:08:29 step 6: objective=0.42544279
2017/08/29 09:08:32 step 7: objective=0.42694786
2017/08/29 09:08:32 Training value function...
2017/08/29 09:08:35 step 0: mse=148.545163 step=0.100000
2017/08/29 09:08:36 step 1: mse=146.118897 step=0.100000
2017/08/29 09:08:38 step 2: mse=144.168052 step=0.100000
2017/08/29 09:08:39 step 3: mse=142.307879 step=0.100000
2017/08/29 09:08:41 step 4: mse=140.782597 step=0.100000
2017/08/29 09:08:42 step 5: mse=139.065738 step=0.100000
2017/08/29 09:08:43 step 6: mse=138.021608 step=0.100000
2017/08/29 09:08:45 step 7: mse=136.704304 step=0.100000
2017/08/29 09:08:45 Saving...
2017/08/29 09:08:45 Gathering batch of experience...
2017/08/29 09:09:37 batch 1169: mean=245.892857 stddev=156.138981 entropy=0.306460 frames=6648 count=28
2017/08/29 09:09:37 Training policy...
2017/08/29 09:09:43 step 0: objective=0.71166766
2017/08/29 09:09:46 step 1: objective=0.71600944
2017/08/29 09:09:49 step 2: objective=0.72259235
2017/08/29 09:09:52 step 3: objective=0.7255633
2017/08/29 09:09:55 step 4: objective=0.7288641
2017/08/29 09:09:58 step 5: objective=0.7316256
2017/08/29 09:10:01 step 6: objective=0.734135
2017/08/29 09:10:04 step 7: objective=0.7398554
2017/08/29 09:10:04 Training value function...
2017/08/29 09:10:07 step 0: mse=142.736680 step=0.100000
2017/08/29 09:10:09 step 1: mse=140.925792 step=0.100000
2017/08/29 09:10:10 step 2: mse=139.686820 step=0.100000
2017/08/29 09:10:11 step 3: mse=138.549205 step=0.100000
2017/08/29 09:10:13 step 4: mse=137.505429 step=0.100000
2017/08/29 09:10:14 step 5: mse=136.786811 step=0.100000
2017/08/29 09:10:16 step 6: mse=135.970703 step=0.100000
2017/08/29 09:10:17 step 7: mse=135.425869 step=0.100000
2017/08/29 09:10:17 Saving...
2017/08/29 09:10:17 Gathering batch of experience...
2017/08/29 09:11:14 batch 1170: mean=207.971429 stddev=174.454494 entropy=0.301358 frames=6990 count=35
2017/08/29 09:11:14 Training policy...
2017/08/29 09:11:21 step 0: objective=0.70663464
2017/08/29 09:11:24 step 1: objective=0.7115091
2017/08/29 09:11:27 step 2: objective=0.7178877
2017/08/29 09:11:30 step 3: objective=0.7227721
2017/08/29 09:11:34 step 4: objective=0.72794336
2017/08/29 09:11:37 step 5: objective=0.73048747
2017/08/29 09:11:40 step 6: objective=0.7332965
2017/08/29 09:11:43 step 7: objective=0.73575383
2017/08/29 09:11:43 Training value function...
2017/08/29 09:11:46 step 0: mse=166.293730 step=0.100000
2017/08/29 09:11:48 step 1: mse=163.250136 step=0.100000
2017/08/29 09:11:49 step 2: mse=160.279133 step=0.100000
2017/08/29 09:11:51 step 3: mse=158.274807 step=0.100000
2017/08/29 09:11:52 step 4: mse=156.284826 step=0.100000
2017/08/29 09:11:54 step 5: mse=154.558911 step=0.100000
2017/08/29 09:11:55 step 6: mse=153.169331 step=0.100000
2017/08/29 09:11:57 step 7: mse=152.066118 step=0.100000
2017/08/29 09:11:57 Saving...
2017/08/29 09:11:57 Gathering batch of experience...
2017/08/29 09:12:47 batch 1171: mean=193.558824 stddev=142.834580 entropy=0.301991 frames=6267 count=34
2017/08/29 09:12:47 Training policy...
2017/08/29 09:12:53 step 0: objective=0.7330621
2017/08/29 09:12:56 step 1: objective=0.737792
2017/08/29 09:12:58 step 2: objective=0.74334216
2017/08/29 09:13:01 step 3: objective=0.7467887
2017/08/29 09:13:04 step 4: objective=0.75211495
2017/08/29 09:13:07 step 5: objective=0.7552148
2017/08/29 09:13:10 step 6: objective=0.758322
2017/08/29 09:13:13 step 7: objective=0.7612183
2017/08/29 09:13:13 Training value function...
2017/08/29 09:13:16 step 0: mse=143.595324 step=0.100000
2017/08/29 09:13:17 step 1: mse=139.879473 step=0.100000
2017/08/29 09:13:18 step 2: mse=136.863929 step=0.100000
2017/08/29 09:13:20 step 3: mse=134.478934 step=0.100000
2017/08/29 09:13:21 step 4: mse=132.539775 step=0.100000
2017/08/29 09:13:22 step 5: mse=130.621477 step=0.100000
2017/08/29 09:13:24 step 6: mse=128.979031 step=0.100000
2017/08/29 09:13:25 step 7: mse=127.766118 step=0.100000
2017/08/29 09:13:25 Saving...
2017/08/29 09:13:25 Gathering batch of experience...
2017/08/29 09:14:18 batch 1172: mean=251.275862 stddev=174.450644 entropy=0.301464 frames=6762 count=29
2017/08/29 09:14:18 Training policy...
2017/08/29 09:14:24 step 0: objective=1.8686111
2017/08/29 09:14:27 step 1: objective=1.8718797
2017/08/29 09:14:30 step 2: objective=1.8762996
2017/08/29 09:14:33 step 3: objective=1.8786842
2017/08/29 09:14:37 step 4: objective=1.8823842
2017/08/29 09:14:40 step 5: objective=1.8868792
2017/08/29 09:14:43 step 6: objective=1.8897386
2017/08/29 09:14:46 step 7: objective=1.8915365
2017/08/29 09:14:46 Training value function...
2017/08/29 09:14:49 step 0: mse=174.274103 step=0.100000
2017/08/29 09:14:50 step 1: mse=169.500779 step=0.100000
2017/08/29 09:14:52 step 2: mse=165.429056 step=0.100000
2017/08/29 09:14:53 step 3: mse=161.980912 step=0.100000
2017/08/29 09:14:55 step 4: mse=159.192851 step=0.100000
2017/08/29 09:14:56 step 5: mse=156.366027 step=0.100000
2017/08/29 09:14:58 step 6: mse=153.973187 step=0.100000
2017/08/29 09:14:59 step 7: mse=151.884087 step=0.100000
2017/08/29 09:14:59 Saving...
2017/08/29 09:14:59 Gathering batch of experience...
2017/08/29 09:15:47 batch 1173: mean=244.461538 stddev=146.958977 entropy=0.306407 frames=5889 count=26
2017/08/29 09:15:47 Training policy...
2017/08/29 09:15:52 step 0: objective=1.1833458
2017/08/29 09:15:55 step 1: objective=1.186535
2017/08/29 09:15:58 step 2: objective=1.1915474
2017/08/29 09:16:01 step 3: objective=1.1986984
2017/08/29 09:16:03 step 4: objective=1.2028373
2017/08/29 09:16:06 step 5: objective=1.2067188
2017/08/29 09:16:09 step 6: objective=1.2098767
2017/08/29 09:16:11 step 7: objective=1.2148992
2017/08/29 09:16:11 Training value function...
2017/08/29 09:16:14 step 0: mse=156.350406 step=0.100000
2017/08/29 09:16:15 step 1: mse=153.214275 step=0.100000
2017/08/29 09:16:16 step 2: mse=150.795013 step=0.100000
2017/08/29 09:16:18 step 3: mse=148.528355 step=0.100000
2017/08/29 09:16:19 step 4: mse=146.595909 step=0.100000
2017/08/29 09:16:20 step 5: mse=144.832797 step=0.100000
2017/08/29 09:16:21 step 6: mse=143.274061 step=0.100000
2017/08/29 09:16:23 step 7: mse=141.890222 step=0.100000
2017/08/29 09:16:23 Saving...
2017/08/29 09:16:23 Gathering batch of experience...
2017/08/29 09:17:14 batch 1174: mean=268.291667 stddev=180.324587 entropy=0.306876 frames=6168 count=24
2017/08/29 09:17:14 Training policy...
2017/08/29 09:17:20 step 0: objective=1.161424
2017/08/29 09:17:23 step 1: objective=1.1641724
2017/08/29 09:17:26 step 2: objective=1.1704547
2017/08/29 09:17:29 step 3: objective=1.173698
2017/08/29 09:17:31 step 4: objective=1.1775142
2017/08/29 09:17:34 step 5: objective=1.1818434
2017/08/29 09:17:37 step 6: objective=1.1839999
2017/08/29 09:17:40 step 7: objective=1.1882039
2017/08/29 09:17:40 Training value function...
2017/08/29 09:17:43 step 0: mse=150.486009 step=0.100000
2017/08/29 09:17:44 step 1: mse=147.339726 step=0.100000
2017/08/29 09:17:45 step 2: mse=144.972119 step=0.100000
2017/08/29 09:17:47 step 3: mse=142.616351 step=0.100000
2017/08/29 09:17:48 step 4: mse=140.379888 step=0.100000
2017/08/29 09:17:49 step 5: mse=138.673769 step=0.100000
2017/08/29 09:17:50 step 6: mse=136.963872 step=0.100000
2017/08/29 09:17:52 step 7: mse=135.335411 step=0.100000
2017/08/29 09:17:52 Saving...
2017/08/29 09:17:52 Gathering batch of experience...
2017/08/29 09:18:46 batch 1175: mean=223.032258 stddev=148.857690 entropy=0.301771 frames=6652 count=31
2017/08/29 09:18:46 Training policy...
2017/08/29 09:18:52 step 0: objective=0.5399726
2017/08/29 09:18:55 step 1: objective=0.54711425
2017/08/29 09:18:58 step 2: objective=0.552217
2017/08/29 09:19:01 step 3: objective=0.55649596
2017/08/29 09:19:04 step 4: objective=0.5589879
2017/08/29 09:19:07 step 5: objective=0.5637963
2017/08/29 09:19:10 step 6: objective=0.56596404
2017/08/29 09:19:13 step 7: objective=0.56981254
2017/08/29 09:19:13 Training value function...
2017/08/29 09:19:16 step 0: mse=151.001176 step=0.100000
2017/08/29 09:19:17 step 1: mse=148.345537 step=0.100000
2017/08/29 09:19:19 step 2: mse=146.009412 step=0.100000
2017/08/29 09:19:20 step 3: mse=144.117696 step=0.100000
2017/08/29 09:19:22 step 4: mse=142.612885 step=0.100000
2017/08/29 09:19:23 step 5: mse=141.322261 step=0.100000
2017/08/29 09:19:25 step 6: mse=139.843192 step=0.100000
2017/08/29 09:19:26 step 7: mse=138.465038 step=0.100000
2017/08/29 09:19:26 Saving...
2017/08/29 09:19:26 Gathering batch of experience...
2017/08/29 09:20:13 batch 1176: mean=256.481481 stddev=157.633511 entropy=0.308035 frames=6269 count=27
2017/08/29 09:20:13 Training policy...
2017/08/29 09:20:19 step 0: objective=1.8283666
2017/08/29 09:20:22 step 1: objective=1.8329215
2017/08/29 09:20:25 step 2: objective=1.8384413
2017/08/29 09:20:27 step 3: objective=1.8438891
2017/08/29 09:20:30 step 4: objective=1.8479474
2017/08/29 09:20:33 step 5: objective=1.8509116
2017/08/29 09:20:36 step 6: objective=1.8568618
2017/08/29 09:20:39 step 7: objective=1.8588797
2017/08/29 09:20:39 Training value function...
2017/08/29 09:20:42 step 0: mse=161.151535 step=0.100000
2017/08/29 09:20:43 step 1: mse=156.565422 step=0.100000
2017/08/29 09:20:44 step 2: mse=152.475966 step=0.100000
2017/08/29 09:20:46 step 3: mse=149.183701 step=0.100000
2017/08/29 09:20:47 step 4: mse=146.320194 step=0.100000
2017/08/29 09:20:48 step 5: mse=143.894678 step=0.100000
2017/08/29 09:20:50 step 6: mse=141.812064 step=0.100000
2017/08/29 09:20:51 step 7: mse=139.543816 step=0.100000
2017/08/29 09:20:51 Saving...
2017/08/29 09:20:51 Gathering batch of experience...
2017/08/29 09:21:41 batch 1177: mean=260.142857 stddev=197.543253 entropy=0.308458 frames=6570 count=28
2017/08/29 09:21:41 Training policy...
2017/08/29 09:21:47 step 0: objective=1.7214062
2017/08/29 09:21:50 step 1: objective=1.7280988
2017/08/29 09:21:53 step 2: objective=1.7310859
2017/08/29 09:21:56 step 3: objective=1.7343539
2017/08/29 09:21:59 step 4: objective=1.738792
2017/08/29 09:22:02 step 5: objective=1.7432473
2017/08/29 09:22:06 step 6: objective=1.7451047
2017/08/29 09:22:09 step 7: objective=1.7490275
2017/08/29 09:22:09 Training value function...
2017/08/29 09:22:11 step 0: mse=162.823697 step=0.100000
2017/08/29 09:22:13 step 1: mse=157.929974 step=0.100000
2017/08/29 09:22:14 step 2: mse=153.823673 step=0.100000
2017/08/29 09:22:16 step 3: mse=150.181749 step=0.100000
2017/08/29 09:22:17 step 4: mse=147.237024 step=0.100000
2017/08/29 09:22:18 step 5: mse=144.572010 step=0.100000
2017/08/29 09:22:20 step 6: mse=142.409342 step=0.100000
2017/08/29 09:22:21 step 7: mse=140.377361 step=0.100000
2017/08/29 09:22:21 Saving...
2017/08/29 09:22:21 Gathering batch of experience...
2017/08/29 09:23:14 batch 1178: mean=185.030303 stddev=163.641975 entropy=0.299219 frames=5801 count=33
2017/08/29 09:23:14 Training policy...
2017/08/29 09:23:19 step 0: objective=0.063709445
2017/08/29 09:23:22 step 1: objective=0.07308728
2017/08/29 09:23:25 step 2: objective=0.079025775
2017/08/29 09:23:27 step 3: objective=0.08338709
2017/08/29 09:23:30 step 4: objective=0.08721008
2017/08/29 09:23:33 step 5: objective=0.09247791
2017/08/29 09:23:35 step 6: objective=0.095879704
2017/08/29 09:23:38 step 7: objective=0.09833884
2017/08/29 09:23:38 Training value function...
2017/08/29 09:23:41 step 0: mse=156.067517 step=0.100000
2017/08/29 09:23:42 step 1: mse=153.352116 step=0.100000
2017/08/29 09:23:43 step 2: mse=151.556680 step=0.100000
2017/08/29 09:23:44 step 3: mse=150.228196 step=0.100000
2017/08/29 09:23:46 step 4: mse=148.655812 step=0.100000
2017/08/29 09:23:47 step 5: mse=147.604567 step=0.100000
2017/08/29 09:23:48 step 6: mse=146.561680 step=0.100000
2017/08/29 09:23:49 step 7: mse=145.480257 step=0.100000
2017/08/29 09:23:49 Saving...
2017/08/29 09:23:49 Gathering batch of experience...
2017/08/29 09:24:50 batch 1179: mean=255.142857 stddev=181.935176 entropy=0.300921 frames=7047 count=28
2017/08/29 09:24:50 Training policy...
2017/08/29 09:24:56 step 0: objective=0.8226773
2017/08/29 09:24:59 step 1: objective=0.8260742
2017/08/29 09:25:03 step 2: objective=0.8294982
2017/08/29 09:25:06 step 3: objective=0.8321077
2017/08/29 09:25:09 step 4: objective=0.835815
2017/08/29 09:25:12 step 5: objective=0.83910996
2017/08/29 09:25:16 step 6: objective=0.8416164
2017/08/29 09:25:19 step 7: objective=0.8436525
2017/08/29 09:25:19 Training value function...
2017/08/29 09:25:22 step 0: mse=137.103412 step=0.100000
2017/08/29 09:25:24 step 1: mse=135.700696 step=0.100000
2017/08/29 09:25:25 step 2: mse=134.445040 step=0.100000
2017/08/29 09:25:27 step 3: mse=132.842928 step=0.100000
2017/08/29 09:25:28 step 4: mse=131.733239 step=0.100000
2017/08/29 09:25:30 step 5: mse=131.077056 step=0.100000
2017/08/29 09:25:31 step 6: mse=130.350318 step=0.100000
2017/08/29 09:25:33 step 7: mse=129.509729 step=0.100000
2017/08/29 09:25:33 Saving...
2017/08/29 09:25:33 Gathering batch of experience...
2017/08/29 09:26:26 batch 1180: mean=256.962963 stddev=180.900317 entropy=0.304531 frames=6628 count=27
2017/08/29 09:26:26 Training policy...
2017/08/29 09:26:32 step 0: objective=1.1385914
2017/08/29 09:26:36 step 1: objective=1.142823
2017/08/29 09:26:39 step 2: objective=1.1502012
2017/08/29 09:26:42 step 3: objective=1.1545141
2017/08/29 09:26:45 step 4: objective=1.1585457
2017/08/29 09:26:48 step 5: objective=1.1634972
2017/08/29 09:26:51 step 6: objective=1.1653873
2017/08/29 09:26:54 step 7: objective=1.1682605
2017/08/29 09:26:54 Training value function...
2017/08/29 09:26:57 step 0: mse=158.717708 step=0.100000
2017/08/29 09:26:58 step 1: mse=155.329988 step=0.100000
2017/08/29 09:27:00 step 2: mse=152.535195 step=0.100000
2017/08/29 09:27:01 step 3: mse=150.619479 step=0.100000
2017/08/29 09:27:03 step 4: mse=148.247345 step=0.100000
2017/08/29 09:27:04 step 5: mse=146.518593 step=0.100000
2017/08/29 09:27:05 step 6: mse=145.164391 step=0.100000
2017/08/29 09:27:07 step 7: mse=143.676279 step=0.100000
2017/08/29 09:27:07 Saving...
2017/08/29 09:27:07 Gathering batch of experience...
2017/08/29 09:27:57 batch 1181: mean=245.137931 stddev=186.308370 entropy=0.299050 frames=6556 count=29
2017/08/29 09:27:57 Training policy...
2017/08/29 09:28:03 step 0: objective=1.4309393
2017/08/29 09:28:06 step 1: objective=1.4368556
2017/08/29 09:28:09 step 2: objective=1.4399514
2017/08/29 09:28:13 step 3: objective=1.4436151
2017/08/29 09:28:16 step 4: objective=1.4473406
2017/08/29 09:28:19 step 5: objective=1.4495363
2017/08/29 09:28:22 step 6: objective=1.4521781
2017/08/29 09:28:25 step 7: objective=1.4551967
2017/08/29 09:28:25 Training value function...
2017/08/29 09:28:28 step 0: mse=151.540615 step=0.100000
2017/08/29 09:28:29 step 1: mse=149.252614 step=0.100000
2017/08/29 09:28:30 step 2: mse=146.663912 step=0.100000
2017/08/29 09:28:32 step 3: mse=144.597839 step=0.100000
2017/08/29 09:28:33 step 4: mse=142.839579 step=0.100000
2017/08/29 09:28:35 step 5: mse=140.779559 step=0.100000
2017/08/29 09:28:36 step 6: mse=139.329593 step=0.100000
2017/08/29 09:28:37 step 7: mse=137.961653 step=0.100000
2017/08/29 09:28:37 Saving...
2017/08/29 09:28:37 Gathering batch of experience...
2017/08/29 09:29:26 batch 1182: mean=241.655172 stddev=174.926246 entropy=0.304373 frames=6547 count=29
2017/08/29 09:29:26 Training policy...
2017/08/29 09:29:32 step 0: objective=1.061791
2017/08/29 09:29:35 step 1: objective=1.0670748
2017/08/29 09:29:38 step 2: objective=1.0704135
2017/08/29 09:29:41 step 3: objective=1.0769238
2017/08/29 09:29:44 step 4: objective=1.0805619
2017/08/29 09:29:47 step 5: objective=1.0837032
2017/08/29 09:29:50 step 6: objective=1.0863936
2017/08/29 09:29:53 step 7: objective=1.0891933
2017/08/29 09:29:53 Training value function...
2017/08/29 09:29:56 step 0: mse=171.492705 step=0.100000
2017/08/29 09:29:57 step 1: mse=167.722242 step=0.100000
2017/08/29 09:29:59 step 2: mse=164.560515 step=0.100000
2017/08/29 09:30:00 step 3: mse=161.755199 step=0.100000
2017/08/29 09:30:01 step 4: mse=159.255058 step=0.100000
2017/08/29 09:30:03 step 5: mse=157.220358 step=0.100000
2017/08/29 09:30:04 step 6: mse=155.465143 step=0.100000
2017/08/29 09:30:06 step 7: mse=154.103236 step=0.100000
2017/08/29 09:30:06 Saving...
2017/08/29 09:30:06 Gathering batch of experience...
2017/08/29 09:30:59 batch 1183: mean=218.750000 stddev=186.181027 entropy=0.301492 frames=6486 count=32
2017/08/29 09:30:59 Training policy...
2017/08/29 09:31:04 step 0: objective=1.0763043
2017/08/29 09:31:07 step 1: objective=1.0804238
2017/08/29 09:31:10 step 2: objective=1.0849522
2017/08/29 09:31:14 step 3: objective=1.0897391
2017/08/29 09:31:17 step 4: objective=1.092486
2017/08/29 09:31:20 step 5: objective=1.0973083
2017/08/29 09:31:23 step 6: objective=1.1016425
2017/08/29 09:31:26 step 7: objective=1.1038224
2017/08/29 09:31:26 Training value function...
2017/08/29 09:31:28 step 0: mse=161.547193 step=0.100000
2017/08/29 09:31:30 step 1: mse=159.394589 step=0.100000
2017/08/29 09:31:31 step 2: mse=157.551799 step=0.100000
2017/08/29 09:31:33 step 3: mse=155.430482 step=0.100000
2017/08/29 09:31:34 step 4: mse=153.666623 step=0.100000
2017/08/29 09:31:35 step 5: mse=152.128046 step=0.100000
2017/08/29 09:31:37 step 6: mse=150.839550 step=0.100000
2017/08/29 09:31:38 step 7: mse=149.584285 step=0.100000
2017/08/29 09:31:38 Saving...
2017/08/29 09:31:38 Gathering batch of experience...
2017/08/29 09:32:30 batch 1184: mean=213.379310 stddev=169.863315 entropy=0.305069 frames=6078 count=29
2017/08/29 09:32:30 Training policy...
2017/08/29 09:32:35 step 0: objective=0.38595665
2017/08/29 09:32:38 step 1: objective=0.3920624
2017/08/29 09:32:41 step 2: objective=0.39794248
2017/08/29 09:32:44 step 3: objective=0.40058392
2017/08/29 09:32:47 step 4: objective=0.4037958
2017/08/29 09:32:49 step 5: objective=0.40812588
2017/08/29 09:32:52 step 6: objective=0.41151974
2017/08/29 09:32:55 step 7: objective=0.41413096
2017/08/29 09:32:55 Training value function...
2017/08/29 09:32:58 step 0: mse=133.772233 step=0.100000
2017/08/29 09:32:59 step 1: mse=132.281766 step=0.100000
2017/08/29 09:33:00 step 2: mse=130.761607 step=0.100000
2017/08/29 09:33:02 step 3: mse=129.628537 step=0.100000
2017/08/29 09:33:03 step 4: mse=128.539193 step=0.100000
2017/08/29 09:33:04 step 5: mse=127.552972 step=0.100000
2017/08/29 09:33:05 step 6: mse=126.792507 step=0.100000
2017/08/29 09:33:07 step 7: mse=126.405766 step=0.100000
2017/08/29 09:33:07 Saving...
2017/08/29 09:33:07 Gathering batch of experience...
2017/08/29 09:34:02 batch 1185: mean=242.862069 stddev=172.451237 entropy=0.303411 frames=6629 count=29
2017/08/29 09:34:02 Training policy...
2017/08/29 09:34:08 step 0: objective=1.3272746
2017/08/29 09:34:11 step 1: objective=1.3322874
2017/08/29 09:34:14 step 2: objective=1.3366984
2017/08/29 09:34:17 step 3: objective=1.3416207
2017/08/29 09:34:20 step 4: objective=1.3436568
2017/08/29 09:34:23 step 5: objective=1.3471389
2017/08/29 09:34:26 step 6: objective=1.3491409
2017/08/29 09:34:30 step 7: objective=1.3508694
2017/08/29 09:34:30 Training value function...
2017/08/29 09:34:32 step 0: mse=157.017885 step=0.100000
2017/08/29 09:34:34 step 1: mse=152.459305 step=0.100000
2017/08/29 09:34:35 step 2: mse=148.752598 step=0.100000
2017/08/29 09:34:37 step 3: mse=145.810353 step=0.100000
2017/08/29 09:34:38 step 4: mse=143.364097 step=0.100000
2017/08/29 09:34:39 step 5: mse=141.183102 step=0.100000
2017/08/29 09:34:41 step 6: mse=139.110284 step=0.100000
2017/08/29 09:34:42 step 7: mse=137.385928 step=0.100000
2017/08/29 09:34:42 Saving...
2017/08/29 09:34:42 Gathering batch of experience...
2017/08/29 09:35:32 batch 1186: mean=271.520000 stddev=155.279650 entropy=0.298833 frames=6377 count=25
2017/08/29 09:35:32 Training policy...
2017/08/29 09:35:38 step 0: objective=1.2967254
2017/08/29 09:35:41 step 1: objective=1.3040401
2017/08/29 09:35:44 step 2: objective=1.308815
2017/08/29 09:35:47 step 3: objective=1.313609
2017/08/29 09:35:50 step 4: objective=1.3160286
2017/08/29 09:35:53 step 5: objective=1.3196145
2017/08/29 09:35:56 step 6: objective=1.3243922
2017/08/29 09:35:59 step 7: objective=1.3270315
2017/08/29 09:35:59 Training value function...
2017/08/29 09:36:02 step 0: mse=142.971263 step=0.100000
2017/08/29 09:36:03 step 1: mse=140.557437 step=0.100000
2017/08/29 09:36:05 step 2: mse=138.623545 step=0.100000
2017/08/29 09:36:06 step 3: mse=136.738441 step=0.100000
2017/08/29 09:36:07 step 4: mse=134.959762 step=0.100000
2017/08/29 09:36:09 step 5: mse=133.269865 step=0.100000
2017/08/29 09:36:10 step 6: mse=131.827653 step=0.100000
2017/08/29 09:36:11 step 7: mse=130.877603 step=0.100000
2017/08/29 09:36:11 Saving...
2017/08/29 09:36:12 Gathering batch of experience...
2017/08/29 09:36:57 batch 1187: mean=278.250000 stddev=142.423152 entropy=0.303128 frames=6292 count=24
2017/08/29 09:36:57 Training policy...
2017/08/29 09:37:03 step 0: objective=1.0692403
2017/08/29 09:37:06 step 1: objective=1.0734774
2017/08/29 09:37:09 step 2: objective=1.0772519
2017/08/29 09:37:12 step 3: objective=1.0803142
2017/08/29 09:37:15 step 4: objective=1.083476
2017/08/29 09:37:18 step 5: objective=1.0862801
2017/08/29 09:37:21 step 6: objective=1.0886638
2017/08/29 09:37:24 step 7: objective=1.091618
2017/08/29 09:37:24 Training value function...
2017/08/29 09:37:26 step 0: mse=119.406468 step=0.100000
2017/08/29 09:37:28 step 1: mse=116.643837 step=0.100000
2017/08/29 09:37:29 step 2: mse=114.473381 step=0.100000
2017/08/29 09:37:30 step 3: mse=112.555846 step=0.100000
2017/08/29 09:37:32 step 4: mse=111.038025 step=0.100000
2017/08/29 09:37:33 step 5: mse=109.736751 step=0.100000
2017/08/29 09:37:34 step 6: mse=108.462678 step=0.100000
2017/08/29 09:37:36 step 7: mse=107.405605 step=0.100000
2017/08/29 09:37:36 Saving...
2017/08/29 09:37:36 Gathering batch of experience...
2017/08/29 09:38:24 batch 1188: mean=285.833333 stddev=214.998191 entropy=0.311384 frames=6210 count=24
2017/08/29 09:38:24 Training policy...
2017/08/29 09:38:30 step 0: objective=1.9339707
2017/08/29 09:38:33 step 1: objective=1.9384632
2017/08/29 09:38:36 step 2: objective=1.9430202
2017/08/29 09:38:39 step 3: objective=1.9459741
2017/08/29 09:38:42 step 4: objective=1.9506366
2017/08/29 09:38:44 step 5: objective=1.9552106
2017/08/29 09:38:47 step 6: objective=1.9583591
2017/08/29 09:38:50 step 7: objective=1.9626709
2017/08/29 09:38:50 Training value function...
2017/08/29 09:38:53 step 0: mse=203.761818 step=0.100000
2017/08/29 09:38:54 step 1: mse=197.905766 step=0.100000
2017/08/29 09:38:56 step 2: mse=192.436469 step=0.100000
2017/08/29 09:38:57 step 3: mse=187.922235 step=0.100000
2017/08/29 09:38:58 step 4: mse=184.468071 step=0.100000
2017/08/29 09:39:00 step 5: mse=181.645004 step=0.100000
2017/08/29 09:39:01 step 6: mse=178.969740 step=0.100000
2017/08/29 09:39:02 step 7: mse=176.162819 step=0.100000
2017/08/29 09:39:02 Saving...
2017/08/29 09:39:02 Gathering batch of experience...
2017/08/29 09:39:54 batch 1189: mean=249.689655 stddev=204.041764 entropy=0.306754 frames=6746 count=29
2017/08/29 09:39:54 Training policy...
2017/08/29 09:40:01 step 0: objective=0.9638452
2017/08/29 09:40:04 step 1: objective=0.9673904
2017/08/29 09:40:07 step 2: objective=0.9726361
2017/08/29 09:40:10 step 3: objective=0.9757933
2017/08/29 09:40:13 step 4: objective=0.97897094
2017/08/29 09:40:16 step 5: objective=0.9840831
2017/08/29 09:40:20 step 6: objective=0.9861372
2017/08/29 09:40:23 step 7: objective=0.98850095
2017/08/29 09:40:23 Training value function...
2017/08/29 09:40:26 step 0: mse=140.015433 step=0.100000
2017/08/29 09:40:27 step 1: mse=138.545016 step=0.100000
2017/08/29 09:40:29 step 2: mse=137.255879 step=0.100000
2017/08/29 09:40:30 step 3: mse=135.838223 step=0.100000
2017/08/29 09:40:31 step 4: mse=134.928654 step=0.100000
2017/08/29 09:40:33 step 5: mse=133.827109 step=0.100000
2017/08/29 09:40:34 step 6: mse=132.971475 step=0.100000
2017/08/29 09:40:36 step 7: mse=132.239285 step=0.100000
2017/08/29 09:40:36 Saving...
2017/08/29 09:40:36 Gathering batch of experience...
2017/08/29 09:41:28 batch 1190: mean=195.323529 stddev=144.947195 entropy=0.296278 frames=6484 count=34
2017/08/29 09:41:28 Training policy...
2017/08/29 09:41:33 step 0: objective=0.06175389
2017/08/29 09:41:37 step 1: objective=0.06660127
2017/08/29 09:41:40 step 2: objective=0.07169635
2017/08/29 09:41:43 step 3: objective=0.074550055
2017/08/29 09:41:46 step 4: objective=0.07808152
2017/08/29 09:41:49 step 5: objective=0.08122697
2017/08/29 09:41:52 step 6: objective=0.0841406
2017/08/29 09:41:55 step 7: objective=0.08665714
2017/08/29 09:41:55 Training value function...
2017/08/29 09:41:58 step 0: mse=139.234189 step=0.100000
2017/08/29 09:41:59 step 1: mse=137.491693 step=0.100000
2017/08/29 09:42:00 step 2: mse=135.989961 step=0.100000
2017/08/29 09:42:02 step 3: mse=134.886726 step=0.100000
2017/08/29 09:42:03 step 4: mse=133.854155 step=0.100000
2017/08/29 09:42:05 step 5: mse=133.125889 step=0.100000
2017/08/29 09:42:06 step 6: mse=132.371438 step=0.100000
2017/08/29 09:42:07 step 7: mse=131.634083 step=0.100000
2017/08/29 09:42:07 Saving...
2017/08/29 09:42:07 Gathering batch of experience...
2017/08/29 09:42:58 batch 1191: mean=249.000000 stddev=161.269960 entropy=0.304236 frames=6322 count=27
2017/08/29 09:42:58 Training policy...
2017/08/29 09:43:04 step 0: objective=1.4267242
2017/08/29 09:43:07 step 1: objective=1.4317632
2017/08/29 09:43:10 step 2: objective=1.4373897
2017/08/29 09:43:13 step 3: objective=1.4426082
2017/08/29 09:43:16 step 4: objective=1.44501
2017/08/29 09:43:19 step 5: objective=1.4505639
2017/08/29 09:43:22 step 6: objective=1.4533727
2017/08/29 09:43:25 step 7: objective=1.4561375
2017/08/29 09:43:25 Training value function...
2017/08/29 09:43:28 step 0: mse=162.635293 step=0.100000
2017/08/29 09:43:29 step 1: mse=159.852840 step=0.100000
2017/08/29 09:43:30 step 2: mse=157.363603 step=0.100000
2017/08/29 09:43:32 step 3: mse=154.767571 step=0.100000
2017/08/29 09:43:33 step 4: mse=152.878593 step=0.100000
2017/08/29 09:43:34 step 5: mse=151.426987 step=0.100000
2017/08/29 09:43:36 step 6: mse=149.551898 step=0.100000
2017/08/29 09:43:37 step 7: mse=148.138360 step=0.100000
2017/08/29 09:43:37 Saving...
2017/08/29 09:43:37 Gathering batch of experience...
2017/08/29 09:44:30 batch 1192: mean=345.045455 stddev=234.008057 entropy=0.312669 frames=7068 count=22
2017/08/29 09:44:30 Training policy...
2017/08/29 09:44:36 step 0: objective=2.245344
2017/08/29 09:44:39 step 1: objective=2.249106
2017/08/29 09:44:43 step 2: objective=2.2519088
2017/08/29 09:44:46 step 3: objective=2.2558708
2017/08/29 09:44:49 step 4: objective=2.2602196
2017/08/29 09:44:53 step 5: objective=2.2626286
2017/08/29 09:44:56 step 6: objective=2.266026
2017/08/29 09:44:59 step 7: objective=2.2693872
2017/08/29 09:44:59 Training value function...
2017/08/29 09:45:02 step 0: mse=188.167777 step=0.100000
2017/08/29 09:45:04 step 1: mse=177.326647 step=0.100000
2017/08/29 09:45:05 step 2: mse=168.560867 step=0.100000
2017/08/29 09:45:07 step 3: mse=161.394750 step=0.100000
2017/08/29 09:45:08 step 4: mse=155.594084 step=0.100000
2017/08/29 09:45:10 step 5: mse=150.823525 step=0.100000
2017/08/29 09:45:11 step 6: mse=146.417990 step=0.100000
2017/08/29 09:45:13 step 7: mse=142.744048 step=0.100000
2017/08/29 09:45:13 Saving...
2017/08/29 09:45:13 Gathering batch of experience...
2017/08/29 09:45:58 batch 1193: mean=225.666667 stddev=157.438759 entropy=0.307769 frames=5824 count=27
2017/08/29 09:45:58 Training policy...
2017/08/29 09:46:03 step 0: objective=0.37827322
2017/08/29 09:46:06 step 1: objective=0.38282573
2017/08/29 09:46:09 step 2: objective=0.38690412
2017/08/29 09:46:11 step 3: objective=0.39157417
2017/08/29 09:46:14 step 4: objective=0.3959771
2017/08/29 09:46:17 step 5: objective=0.40125534
2017/08/29 09:46:20 step 6: objective=0.40467814
2017/08/29 09:46:22 step 7: objective=0.40960562
2017/08/29 09:46:22 Training value function...
2017/08/29 09:46:25 step 0: mse=128.064008 step=0.100000
2017/08/29 09:46:26 step 1: mse=125.825043 step=0.100000
2017/08/29 09:46:27 step 2: mse=124.334873 step=0.100000
2017/08/29 09:46:29 step 3: mse=122.931043 step=0.100000
2017/08/29 09:46:30 step 4: mse=121.893640 step=0.100000
2017/08/29 09:46:31 step 5: mse=121.053726 step=0.100000
2017/08/29 09:46:32 step 6: mse=120.100681 step=0.100000
2017/08/29 09:46:33 step 7: mse=119.388829 step=0.100000
2017/08/29 09:46:33 Saving...
2017/08/29 09:46:34 Gathering batch of experience...
2017/08/29 09:47:24 batch 1194: mean=273.230769 stddev=186.780272 entropy=0.308077 frames=6514 count=26
2017/08/29 09:47:24 Training policy...
2017/08/29 09:47:30 step 0: objective=1.7283795
2017/08/29 09:47:33 step 1: objective=1.7339383
2017/08/29 09:47:36 step 2: objective=1.7386224
2017/08/29 09:47:39 step 3: objective=1.7441471
2017/08/29 09:47:42 step 4: objective=1.7496433
2017/08/29 09:47:45 step 5: objective=1.7532235
2017/08/29 09:47:48 step 6: objective=1.7555037
2017/08/29 09:47:51 step 7: objective=1.7584738
2017/08/29 09:47:51 Training value function...
2017/08/29 09:47:54 step 0: mse=143.311397 step=0.100000
2017/08/29 09:47:55 step 1: mse=139.910883 step=0.100000
2017/08/29 09:47:57 step 2: mse=136.863077 step=0.100000
2017/08/29 09:47:58 step 3: mse=134.571888 step=0.100000
2017/08/29 09:48:00 step 4: mse=132.308162 step=0.100000
2017/08/29 09:48:01 step 5: mse=130.233409 step=0.100000
2017/08/29 09:48:02 step 6: mse=128.580085 step=0.100000
2017/08/29 09:48:04 step 7: mse=127.187216 step=0.100000
2017/08/29 09:48:04 Saving...
2017/08/29 09:48:04 Gathering batch of experience...
2017/08/29 09:48:46 batch 1195: mean=247.115385 stddev=171.018516 entropy=0.301134 frames=5794 count=26
2017/08/29 09:48:46 Training policy...
2017/08/29 09:48:52 step 0: objective=1.1862152
2017/08/29 09:48:55 step 1: objective=1.189788
2017/08/29 09:48:57 step 2: objective=1.1931019
2017/08/29 09:49:00 step 3: objective=1.2001753
2017/08/29 09:49:03 step 4: objective=1.2041864
2017/08/29 09:49:05 step 5: objective=1.207561
2017/08/29 09:49:08 step 6: objective=1.2119079
2017/08/29 09:49:11 step 7: objective=1.2162039
2017/08/29 09:49:11 Training value function...
2017/08/29 09:49:13 step 0: mse=158.840373 step=0.100000
2017/08/29 09:49:15 step 1: mse=157.296089 step=0.100000
2017/08/29 09:49:16 step 2: mse=155.946504 step=0.100000
2017/08/29 09:49:17 step 3: mse=155.072517 step=0.100000
2017/08/29 09:49:18 step 4: mse=153.783407 step=0.100000
2017/08/29 09:49:20 step 5: mse=152.614000 step=0.100000
2017/08/29 09:49:21 step 6: mse=151.320325 step=0.100000
2017/08/29 09:49:22 step 7: mse=150.350315 step=0.100000
2017/08/29 09:49:22 Saving...
2017/08/29 09:49:22 Gathering batch of experience...
2017/08/29 09:50:23 batch 1196: mean=224.828571 stddev=211.931860 entropy=0.307356 frames=7385 count=35
2017/08/29 09:50:23 Training policy...
2017/08/29 09:50:30 step 0: objective=0.91263956
2017/08/29 09:50:33 step 1: objective=0.9164857
2017/08/29 09:50:37 step 2: objective=0.9209612
2017/08/29 09:50:40 step 3: objective=0.92577124
2017/08/29 09:50:44 step 4: objective=0.9311698
2017/08/29 09:50:47 step 5: objective=0.93400955
2017/08/29 09:50:51 step 6: objective=0.9382262
2017/08/29 09:50:54 step 7: objective=0.9418755
2017/08/29 09:50:54 Training value function...
2017/08/29 09:50:57 step 0: mse=178.152881 step=0.100000
2017/08/29 09:50:59 step 1: mse=173.036545 step=0.100000
2017/08/29 09:51:00 step 2: mse=168.766072 step=0.100000
2017/08/29 09:51:02 step 3: mse=164.915564 step=0.100000
2017/08/29 09:51:03 step 4: mse=162.099676 step=0.100000
2017/08/29 09:51:05 step 5: mse=159.032820 step=0.100000
2017/08/29 09:51:07 step 6: mse=156.694597 step=0.100000
2017/08/29 09:51:08 step 7: mse=154.690092 step=0.100000
2017/08/29 09:51:08 Saving...
2017/08/29 09:51:08 Gathering batch of experience...
2017/08/29 09:51:57 batch 1197: mean=192.379310 stddev=175.262446 entropy=0.301595 frames=5511 count=29
2017/08/29 09:51:57 Training policy...
2017/08/29 09:52:02 step 0: objective=0.2507843
2017/08/29 09:52:05 step 1: objective=0.2568953
2017/08/29 09:52:08 step 2: objective=0.26104236
2017/08/29 09:52:10 step 3: objective=0.26400703
2017/08/29 09:52:13 step 4: objective=0.2706403
2017/08/29 09:52:15 step 5: objective=0.27427137
2017/08/29 09:52:18 step 6: objective=0.27664098
2017/08/29 09:52:21 step 7: objective=0.28015268
2017/08/29 09:52:21 Training value function...
2017/08/29 09:52:23 step 0: mse=134.818670 step=0.100000
2017/08/29 09:52:24 step 1: mse=133.163057 step=0.100000
2017/08/29 09:52:25 step 2: mse=132.086676 step=0.100000
2017/08/29 09:52:26 step 3: mse=131.548986 step=0.100000
2017/08/29 09:52:28 step 4: mse=131.108445 step=0.100000
2017/08/29 09:52:29 step 5: mse=130.485501 step=0.100000
2017/08/29 09:52:30 step 6: mse=129.832684 step=0.100000
2017/08/29 09:52:31 step 7: mse=129.270399 step=0.100000
2017/08/29 09:52:31 Saving...
2017/08/29 09:52:31 Gathering batch of experience...
2017/08/29 09:53:28 batch 1198: mean=240.064516 stddev=178.937173 entropy=0.303218 frames=7116 count=31
2017/08/29 09:53:28 Training policy...
2017/08/29 09:53:35 step 0: objective=1.2259523
2017/08/29 09:53:38 step 1: objective=1.2301309
2017/08/29 09:53:42 step 2: objective=1.2332947
2017/08/29 09:53:45 step 3: objective=1.236547
2017/08/29 09:53:48 step 4: objective=1.2406248
2017/08/29 09:53:52 step 5: objective=1.2436105
2017/08/29 09:53:55 step 6: objective=1.2460563
2017/08/29 09:53:58 step 7: objective=1.24871
2017/08/29 09:53:58 Training value function...
2017/08/29 09:54:02 step 0: mse=155.508978 step=0.100000
2017/08/29 09:54:03 step 1: mse=153.096874 step=0.100000
2017/08/29 09:54:05 step 2: mse=150.733080 step=0.100000
2017/08/29 09:54:06 step 3: mse=148.479926 step=0.100000
2017/08/29 09:54:08 step 4: mse=146.552380 step=0.100000
2017/08/29 09:54:09 step 5: mse=144.943806 step=0.100000
2017/08/29 09:54:11 step 6: mse=143.639258 step=0.100000
2017/08/29 09:54:12 step 7: mse=142.273597 step=0.100000
2017/08/29 09:54:12 Saving...
2017/08/29 09:54:12 Gathering batch of experience...
2017/08/29 09:54:58 batch 1199: mean=282.541667 stddev=237.886174 entropy=0.299037 frames=6338 count=24
2017/08/29 09:54:58 Training policy...
2017/08/29 09:55:04 step 0: objective=1.80249
2017/08/29 09:55:07 step 1: objective=1.8077059
2017/08/29 09:55:10 step 2: objective=1.8135194
2017/08/29 09:55:13 step 3: objective=1.8175788
2017/08/29 09:55:16 step 4: objective=1.8214482
2017/08/29 09:55:19 step 5: objective=1.824806
2017/08/29 09:55:22 step 6: objective=1.829376
2017/08/29 09:55:25 step 7: objective=1.8341255
2017/08/29 09:55:25 Training value function...
2017/08/29 09:55:28 step 0: mse=174.573649 step=0.100000
2017/08/29 09:55:29 step 1: mse=168.628325 step=0.100000
2017/08/29 09:55:30 step 2: mse=163.643381 step=0.100000
2017/08/29 09:55:32 step 3: mse=159.564295 step=0.100000
2017/08/29 09:55:33 step 4: mse=155.838814 step=0.100000
2017/08/29 09:55:35 step 5: mse=152.589790 step=0.100000
2017/08/29 09:55:36 step 6: mse=150.099695 step=0.100000
2017/08/29 09:55:37 step 7: mse=147.929985 step=0.100000
2017/08/29 09:55:37 Saving...
2017/08/29 09:55:37 Gathering batch of experience...
2017/08/29 09:56:29 batch 1200: mean=259.035714 stddev=160.612996 entropy=0.301461 frames=6971 count=28
2017/08/29 09:56:29 Training policy...
2017/08/29 09:56:35 step 0: objective=0.85759157
2017/08/29 09:56:39 step 1: objective=0.86249584
2017/08/29 09:56:42 step 2: objective=0.8677931
2017/08/29 09:56:45 step 3: objective=0.87055814
2017/08/29 09:56:49 step 4: objective=0.87317175
2017/08/29 09:56:52 step 5: objective=0.8765608
2017/08/29 09:56:55 step 6: objective=0.8784644
2017/08/29 09:56:59 step 7: objective=0.88215613
2017/08/29 09:56:59 Training value function...
2017/08/29 09:57:02 step 0: mse=129.586005 step=0.100000
2017/08/29 09:57:03 step 1: mse=126.916681 step=0.100000
2017/08/29 09:57:05 step 2: mse=124.583116 step=0.100000
2017/08/29 09:57:06 step 3: mse=122.792298 step=0.100000
2017/08/29 09:57:07 step 4: mse=121.248827 step=0.100000
2017/08/29 09:57:09 step 5: mse=119.490422 step=0.100000
2017/08/29 09:57:10 step 6: mse=118.593093 step=0.100000
2017/08/29 09:57:12 step 7: mse=117.627339 step=0.100000
2017/08/29 09:57:12 Saving...
2017/08/29 09:57:12 Gathering batch of experience...
2017/08/29 09:57:59 batch 1201: mean=232.642857 stddev=152.977173 entropy=0.296816 frames=6010 count=28
2017/08/29 09:57:59 Training policy...
2017/08/29 09:58:05 step 0: objective=1.2304158
2017/08/29 09:58:08 step 1: objective=1.2367986
2017/08/29 09:58:11 step 2: objective=1.2422501
2017/08/29 09:58:13 step 3: objective=1.2471985
2017/08/29 09:58:16 step 4: objective=1.2549514
2017/08/29 09:58:19 step 5: objective=1.2594178
2017/08/29 09:58:22 step 6: objective=1.2627211
2017/08/29 09:58:25 step 7: objective=1.2667785
2017/08/29 09:58:25 Training value function...
2017/08/29 09:58:27 step 0: mse=173.561445 step=0.100000
2017/08/29 09:58:29 step 1: mse=168.828753 step=0.100000
2017/08/29 09:58:30 step 2: mse=164.901795 step=0.100000
2017/08/29 09:58:31 step 3: mse=161.576994 step=0.100000
2017/08/29 09:58:32 step 4: mse=158.835581 step=0.100000
2017/08/29 09:58:34 step 5: mse=156.441144 step=0.100000
2017/08/29 09:58:35 step 6: mse=154.415767 step=0.100000
2017/08/29 09:58:36 step 7: mse=152.628666 step=0.100000
2017/08/29 09:58:36 Saving...
2017/08/29 09:58:36 Gathering batch of experience...
2017/08/29 09:59:25 batch 1202: mean=289.291667 stddev=206.192159 entropy=0.301389 frames=6305 count=24
2017/08/29 09:59:25 Training policy...
2017/08/29 09:59:31 step 0: objective=1.5970684
2017/08/29 09:59:34 step 1: objective=1.6011302
2017/08/29 09:59:37 step 2: objective=1.6052688
2017/08/29 09:59:40 step 3: objective=1.6089479
2017/08/29 09:59:43 step 4: objective=1.6121602
2017/08/29 09:59:46 step 5: objective=1.615494
2017/08/29 09:59:49 step 6: objective=1.6190538
2017/08/29 09:59:52 step 7: objective=1.6236031
2017/08/29 09:59:52 Training value function...
2017/08/29 09:59:55 step 0: mse=207.528238 step=0.100000
2017/08/29 09:59:56 step 1: mse=201.690736 step=0.100000
2017/08/29 09:59:57 step 2: mse=195.195981 step=0.100000
2017/08/29 09:59:59 step 3: mse=189.720950 step=0.100000
2017/08/29 10:00:00 step 4: mse=184.970723 step=0.100000
2017/08/29 10:00:01 step 5: mse=180.987675 step=0.100000
2017/08/29 10:00:03 step 6: mse=177.928756 step=0.100000
2017/08/29 10:00:04 step 7: mse=175.206761 step=0.100000
2017/08/29 10:00:04 Saving...
2017/08/29 10:00:04 Gathering batch of experience...
2017/08/29 10:00:56 batch 1203: mean=261.448276 stddev=253.924451 entropy=0.306479 frames=7047 count=29
2017/08/29 10:00:56 Training policy...
2017/08/29 10:01:03 step 0: objective=0.92988706
2017/08/29 10:01:06 step 1: objective=0.9345707
2017/08/29 10:01:10 step 2: objective=0.9406848
2017/08/29 10:01:13 step 3: objective=0.94601095
2017/08/29 10:01:16 step 4: objective=0.94848365
2017/08/29 10:01:20 step 5: objective=0.95126367
2017/08/29 10:01:23 step 6: objective=0.9534743
2017/08/29 10:01:26 step 7: objective=0.95533234
2017/08/29 10:01:26 Training value function...
2017/08/29 10:01:29 step 0: mse=174.783428 step=0.100000
2017/08/29 10:01:31 step 1: mse=170.204765 step=0.100000
2017/08/29 10:01:32 step 2: mse=167.182865 step=0.100000
2017/08/29 10:01:34 step 3: mse=164.641399 step=0.100000
2017/08/29 10:01:35 step 4: mse=162.407630 step=0.100000
2017/08/29 10:01:37 step 5: mse=160.294495 step=0.100000
2017/08/29 10:01:38 step 6: mse=158.375573 step=0.100000
2017/08/29 10:01:40 step 7: mse=156.886874 step=0.100000
2017/08/29 10:01:40 Saving...
2017/08/29 10:01:40 Gathering batch of experience...
2017/08/29 10:02:30 batch 1204: mean=229.285714 stddev=153.389061 entropy=0.305521 frames=6229 count=28
2017/08/29 10:02:30 Training policy...
2017/08/29 10:02:36 step 0: objective=0.3886556
2017/08/29 10:02:39 step 1: objective=0.39334476
2017/08/29 10:02:42 step 2: objective=0.3972626
2017/08/29 10:02:45 step 3: objective=0.4021196
2017/08/29 10:02:48 step 4: objective=0.40600875
2017/08/29 10:02:51 step 5: objective=0.40791157
2017/08/29 10:02:54 step 6: objective=0.40960956
2017/08/29 10:02:57 step 7: objective=0.41134253
2017/08/29 10:02:57 Training value function...
2017/08/29 10:02:59 step 0: mse=137.379458 step=0.100000
2017/08/29 10:03:01 step 1: mse=134.424969 step=0.100000
2017/08/29 10:03:02 step 2: mse=131.936617 step=0.100000
2017/08/29 10:03:03 step 3: mse=129.813709 step=0.100000
2017/08/29 10:03:05 step 4: mse=128.594209 step=0.100000
2017/08/29 10:03:06 step 5: mse=127.312441 step=0.100000
2017/08/29 10:03:07 step 6: mse=126.160230 step=0.100000
2017/08/29 10:03:09 step 7: mse=125.071681 step=0.100000
2017/08/29 10:03:09 Saving...
2017/08/29 10:03:09 Gathering batch of experience...
2017/08/29 10:04:06 batch 1205: mean=278.444444 stddev=196.768963 entropy=0.302940 frames=7162 count=27
2017/08/29 10:04:06 Training policy...
2017/08/29 10:04:13 step 0: objective=1.3363417
2017/08/29 10:04:16 step 1: objective=1.3394476
2017/08/29 10:04:20 step 2: objective=1.3440783
2017/08/29 10:04:23 step 3: objective=1.348581
2017/08/29 10:04:26 step 4: objective=1.3514823
2017/08/29 10:04:30 step 5: objective=1.3534586
2017/08/29 10:04:33 step 6: objective=1.3583215
2017/08/29 10:04:37 step 7: objective=1.3623836
2017/08/29 10:04:37 Training value function...
2017/08/29 10:04:40 step 0: mse=149.203908 step=0.100000
2017/08/29 10:04:41 step 1: mse=145.844243 step=0.100000
2017/08/29 10:04:43 step 2: mse=142.879427 step=0.100000
2017/08/29 10:04:44 step 3: mse=140.302995 step=0.100000
2017/08/29 10:04:46 step 4: mse=138.106245 step=0.100000
2017/08/29 10:04:47 step 5: mse=136.160940 step=0.100000
2017/08/29 10:04:49 step 6: mse=134.234723 step=0.100000
2017/08/29 10:04:50 step 7: mse=132.798548 step=0.100000
2017/08/29 10:04:50 Saving...
2017/08/29 10:04:50 Gathering batch of experience...
2017/08/29 10:05:41 batch 1206: mean=173.810811 stddev=152.208044 entropy=0.300747 frames=6231 count=37
2017/08/29 10:05:41 Training policy...
2017/08/29 10:05:47 step 0: objective=0.16806762
2017/08/29 10:05:50 step 1: objective=0.17376447
2017/08/29 10:05:53 step 2: objective=0.17902888
2017/08/29 10:05:56 step 3: objective=0.1837071
2017/08/29 10:05:59 step 4: objective=0.18688077
2017/08/29 10:06:02 step 5: objective=0.18981895
2017/08/29 10:06:05 step 6: objective=0.19424719
2017/08/29 10:06:08 step 7: objective=0.19752479
2017/08/29 10:06:08 Training value function...
2017/08/29 10:06:11 step 0: mse=157.287218 step=0.100000
2017/08/29 10:06:12 step 1: mse=155.571238 step=0.100000
2017/08/29 10:06:13 step 2: mse=154.455960 step=0.100000
2017/08/29 10:06:14 step 3: mse=153.029860 step=0.100000
2017/08/29 10:06:16 step 4: mse=152.181689 step=0.100000
2017/08/29 10:06:17 step 5: mse=151.310647 step=0.100000
2017/08/29 10:06:18 step 6: mse=150.707140 step=0.100000
2017/08/29 10:06:20 step 7: mse=150.021660 step=0.100000
2017/08/29 10:06:20 Saving...
2017/08/29 10:06:20 Gathering batch of experience...
2017/08/29 10:07:15 batch 1207: mean=255.392857 stddev=178.586781 entropy=0.304856 frames=6900 count=28
2017/08/29 10:07:15 Training policy...
2017/08/29 10:07:21 step 0: objective=1.281108
2017/08/29 10:07:25 step 1: objective=1.2845894
2017/08/29 10:07:28 step 2: objective=1.2921692
2017/08/29 10:07:31 step 3: objective=1.2975644
2017/08/29 10:07:35 step 4: objective=1.3016992
2017/08/29 10:07:38 step 5: objective=1.3048182
2017/08/29 10:07:41 step 6: objective=1.3077863
2017/08/29 10:07:44 step 7: objective=1.3094125
2017/08/29 10:07:44 Training value function...
2017/08/29 10:07:47 step 0: mse=140.696242 step=0.100000
2017/08/29 10:07:49 step 1: mse=138.762906 step=0.100000
2017/08/29 10:07:50 step 2: mse=137.292617 step=0.100000
2017/08/29 10:07:52 step 3: mse=135.982858 step=0.100000
2017/08/29 10:07:53 step 4: mse=134.660135 step=0.100000
2017/08/29 10:07:55 step 5: mse=133.316344 step=0.100000
2017/08/29 10:07:56 step 6: mse=131.905696 step=0.100000
2017/08/29 10:07:58 step 7: mse=130.728817 step=0.100000
2017/08/29 10:07:58 Saving...
2017/08/29 10:07:58 Gathering batch of experience...
2017/08/29 10:08:56 batch 1208: mean=292.760000 stddev=184.433897 entropy=0.306851 frames=7072 count=25
2017/08/29 10:08:56 Training policy...
2017/08/29 10:09:02 step 0: objective=1.3074597
2017/08/29 10:09:06 step 1: objective=1.3108894
2017/08/29 10:09:09 step 2: objective=1.3134166
2017/08/29 10:09:12 step 3: objective=1.3153757
2017/08/29 10:09:16 step 4: objective=1.3195746
2017/08/29 10:09:19 step 5: objective=1.3212479
2017/08/29 10:09:22 step 6: objective=1.323552
2017/08/29 10:09:26 step 7: objective=1.3252136
2017/08/29 10:09:26 Training value function...
2017/08/29 10:09:29 step 0: mse=128.059875 step=0.100000
2017/08/29 10:09:30 step 1: mse=125.815256 step=0.100000
2017/08/29 10:09:32 step 2: mse=123.845781 step=0.100000
2017/08/29 10:09:33 step 3: mse=122.193049 step=0.100000
2017/08/29 10:09:35 step 4: mse=120.548380 step=0.100000
2017/08/29 10:09:36 step 5: mse=119.273348 step=0.100000
2017/08/29 10:09:38 step 6: mse=118.177963 step=0.100000
2017/08/29 10:09:39 step 7: mse=117.074235 step=0.100000
2017/08/29 10:09:39 Saving...
2017/08/29 10:09:39 Gathering batch of experience...
2017/08/29 10:10:24 batch 1209: mean=213.379310 stddev=161.541372 entropy=0.296371 frames=5773 count=29
2017/08/29 10:10:24 Training policy...
2017/08/29 10:10:30 step 0: objective=0.7973797
2017/08/29 10:10:33 step 1: objective=0.8030022
2017/08/29 10:10:36 step 2: objective=0.8072187
2017/08/29 10:10:38 step 3: objective=0.81229043
2017/08/29 10:10:41 step 4: objective=0.8190521
2017/08/29 10:10:44 step 5: objective=0.8218089
2017/08/29 10:10:47 step 6: objective=0.82810646
2017/08/29 10:10:49 step 7: objective=0.83225244
2017/08/29 10:10:49 Training value function...
2017/08/29 10:10:52 step 0: mse=186.644013 step=0.100000
2017/08/29 10:10:53 step 1: mse=184.222580 step=0.100000
2017/08/29 10:10:54 step 2: mse=181.677644 step=0.100000
2017/08/29 10:10:55 step 3: mse=179.452834 step=0.100000
2017/08/29 10:10:57 step 4: mse=177.472794 step=0.100000
2017/08/29 10:10:58 step 5: mse=175.576060 step=0.100000
2017/08/29 10:10:59 step 6: mse=173.886832 step=0.100000
2017/08/29 10:11:00 step 7: mse=172.468133 step=0.100000
2017/08/29 10:11:00 Saving...
2017/08/29 10:11:00 Gathering batch of experience...
2017/08/29 10:11:47 batch 1210: mean=255.629630 stddev=183.397796 entropy=0.300686 frames=6412 count=27
2017/08/29 10:11:47 Training policy...
2017/08/29 10:11:53 step 0: objective=1.5204254
2017/08/29 10:11:56 step 1: objective=1.5238138
2017/08/29 10:11:59 step 2: objective=1.5268753
2017/08/29 10:12:02 step 3: objective=1.5335186
2017/08/29 10:12:05 step 4: objective=1.5372937
2017/08/29 10:12:08 step 5: objective=1.5420692
2017/08/29 10:12:12 step 6: objective=1.5456038
2017/08/29 10:12:15 step 7: objective=1.5484009
2017/08/29 10:12:15 Training value function...
2017/08/29 10:12:17 step 0: mse=159.989732 step=0.100000
2017/08/29 10:12:19 step 1: mse=155.950847 step=0.100000
2017/08/29 10:12:20 step 2: mse=152.626245 step=0.100000
2017/08/29 10:12:21 step 3: mse=149.831496 step=0.100000
2017/08/29 10:12:23 step 4: mse=147.427145 step=0.100000
2017/08/29 10:12:24 step 5: mse=145.371824 step=0.100000
2017/08/29 10:12:26 step 6: mse=142.829352 step=0.100000
2017/08/29 10:12:27 step 7: mse=140.937364 step=0.100000
2017/08/29 10:12:27 Saving...
2017/08/29 10:12:27 Gathering batch of experience...
2017/08/29 10:13:26 batch 1211: mean=275.344828 stddev=230.504137 entropy=0.301885 frames=7717 count=29
2017/08/29 10:13:26 Training policy...
2017/08/29 10:13:33 step 0: objective=1.0493679
2017/08/29 10:13:37 step 1: objective=1.0517125
2017/08/29 10:13:41 step 2: objective=1.0544989
2017/08/29 10:13:44 step 3: objective=1.0593213
2017/08/29 10:13:48 step 4: objective=1.0613102
2017/08/29 10:13:52 step 5: objective=1.0648123
2017/08/29 10:13:55 step 6: objective=1.0663221
2017/08/29 10:13:59 step 7: objective=1.0690587
2017/08/29 10:13:59 Training value function...
2017/08/29 10:14:02 step 0: mse=144.360845 step=0.100000
2017/08/29 10:14:04 step 1: mse=140.824745 step=0.100000
2017/08/29 10:14:06 step 2: mse=137.725413 step=0.100000
2017/08/29 10:14:07 step 3: mse=135.098636 step=0.100000
2017/08/29 10:14:09 step 4: mse=133.169905 step=0.100000
2017/08/29 10:14:11 step 5: mse=131.276308 step=0.100000
2017/08/29 10:14:12 step 6: mse=129.778063 step=0.100000
2017/08/29 10:14:14 step 7: mse=128.491326 step=0.100000
2017/08/29 10:14:14 Saving...
2017/08/29 10:14:14 Gathering batch of experience...
2017/08/29 10:15:06 batch 1212: mean=254.896552 stddev=174.532152 entropy=0.303290 frames=7143 count=29
2017/08/29 10:15:06 Training policy...
2017/08/29 10:15:13 step 0: objective=0.84297544
2017/08/29 10:15:16 step 1: objective=0.848136
2017/08/29 10:15:20 step 2: objective=0.85215104
2017/08/29 10:15:23 step 3: objective=0.8563681
2017/08/29 10:15:27 step 4: objective=0.85903466
2017/08/29 10:15:30 step 5: objective=0.86152124
2017/08/29 10:15:33 step 6: objective=0.86352086
2017/08/29 10:15:37 step 7: objective=0.86633116
2017/08/29 10:15:37 Training value function...
2017/08/29 10:15:40 step 0: mse=121.075214 step=0.100000
2017/08/29 10:15:41 step 1: mse=120.322509 step=0.100000
2017/08/29 10:15:43 step 2: mse=119.663936 step=0.100000
2017/08/29 10:15:44 step 3: mse=119.281072 step=0.100000
2017/08/29 10:15:46 step 4: mse=118.808275 step=0.100000
2017/08/29 10:15:47 step 5: mse=118.309889 step=0.100000
2017/08/29 10:15:49 step 6: mse=117.685927 step=0.100000
2017/08/29 10:15:50 step 7: mse=117.349148 step=0.100000
2017/08/29 10:15:50 Saving...
2017/08/29 10:15:51 Gathering batch of experience...
2017/08/29 10:16:38 batch 1213: mean=181.818182 stddev=127.711193 entropy=0.307225 frames=5983 count=33
2017/08/29 10:16:38 Training policy...
2017/08/29 10:16:44 step 0: objective=-0.002767675
2017/08/29 10:16:47 step 1: objective=0.002707347
2017/08/29 10:16:50 step 2: objective=0.008991841
2017/08/29 10:16:53 step 3: objective=0.013338144
2017/08/29 10:16:55 step 4: objective=0.019008363
2017/08/29 10:16:58 step 5: objective=0.023616863
2017/08/29 10:17:01 step 6: objective=0.0264413
2017/08/29 10:17:04 step 7: objective=0.02968845
2017/08/29 10:17:04 Training value function...
2017/08/29 10:17:06 step 0: mse=136.915220 step=0.100000
2017/08/29 10:17:08 step 1: mse=134.898131 step=0.100000
2017/08/29 10:17:09 step 2: mse=133.182126 step=0.100000
2017/08/29 10:17:10 step 3: mse=132.034782 step=0.100000
2017/08/29 10:17:11 step 4: mse=131.037518 step=0.100000
2017/08/29 10:17:13 step 5: mse=130.402563 step=0.100000
2017/08/29 10:17:14 step 6: mse=129.539815 step=0.100000
2017/08/29 10:17:15 step 7: mse=128.687751 step=0.100000
2017/08/29 10:17:15 Saving...
2017/08/29 10:17:15 Gathering batch of experience...
2017/08/29 10:18:08 batch 1214: mean=284.307692 stddev=207.271982 entropy=0.308366 frames=6763 count=26
2017/08/29 10:18:08 Training policy...
2017/08/29 10:18:14 step 0: objective=2.5306942
2017/08/29 10:18:18 step 1: objective=2.535553
2017/08/29 10:18:21 step 2: objective=2.5394056
2017/08/29 10:18:24 step 3: objective=2.5458236
2017/08/29 10:18:27 step 4: objective=2.5504844
2017/08/29 10:18:31 step 5: objective=2.552968
2017/08/29 10:18:34 step 6: objective=2.558278
2017/08/29 10:18:37 step 7: objective=2.5635989
2017/08/29 10:18:37 Training value function...
2017/08/29 10:18:40 step 0: mse=199.899405 step=0.100000
2017/08/29 10:18:41 step 1: mse=191.001722 step=0.100000
2017/08/29 10:18:43 step 2: mse=183.009914 step=0.100000
2017/08/29 10:18:44 step 3: mse=176.460404 step=0.100000
2017/08/29 10:18:46 step 4: mse=170.794237 step=0.100000
2017/08/29 10:18:47 step 5: mse=165.978415 step=0.100000
2017/08/29 10:18:49 step 6: mse=161.959654 step=0.100000
2017/08/29 10:18:50 step 7: mse=158.468825 step=0.100000
2017/08/29 10:18:50 Saving...
2017/08/29 10:18:50 Gathering batch of experience...
2017/08/29 10:19:44 batch 1215: mean=256.500000 stddev=204.685735 entropy=0.304321 frames=7249 count=30
2017/08/29 10:19:44 Training policy...
2017/08/29 10:19:50 step 0: objective=1.2616556
2017/08/29 10:19:54 step 1: objective=1.2656318
2017/08/29 10:19:57 step 2: objective=1.2706578
2017/08/29 10:20:01 step 3: objective=1.2730176
2017/08/29 10:20:04 step 4: objective=1.2753376
2017/08/29 10:20:08 step 5: objective=1.2804053
2017/08/29 10:20:11 step 6: objective=1.2835978
2017/08/29 10:20:15 step 7: objective=1.2865605
2017/08/29 10:20:15 Training value function...
2017/08/29 10:20:18 step 0: mse=166.109980 step=0.100000
2017/08/29 10:20:19 step 1: mse=163.756893 step=0.100000
2017/08/29 10:20:21 step 2: mse=161.771389 step=0.100000
2017/08/29 10:20:22 step 3: mse=160.156787 step=0.100000
2017/08/29 10:20:24 step 4: mse=158.371362 step=0.100000
2017/08/29 10:20:26 step 5: mse=156.931291 step=0.100000
2017/08/29 10:20:27 step 6: mse=155.465715 step=0.100000
2017/08/29 10:20:29 step 7: mse=153.982920 step=0.100000
2017/08/29 10:20:29 Saving...
2017/08/29 10:20:29 Gathering batch of experience...
2017/08/29 10:21:18 batch 1216: mean=237.586207 stddev=199.478547 entropy=0.307207 frames=6492 count=29
2017/08/29 10:21:18 Training policy...
2017/08/29 10:21:23 step 0: objective=1.0113274
2017/08/29 10:21:27 step 1: objective=1.0161123
2017/08/29 10:21:30 step 2: objective=1.0222366
2017/08/29 10:21:33 step 3: objective=1.0263374
2017/08/29 10:21:36 step 4: objective=1.0299503
2017/08/29 10:21:39 step 5: objective=1.0344484
2017/08/29 10:21:42 step 6: objective=1.0377041
2017/08/29 10:21:45 step 7: objective=1.0411432
2017/08/29 10:21:45 Training value function...
2017/08/29 10:21:48 step 0: mse=148.191649 step=0.100000
2017/08/29 10:21:49 step 1: mse=145.277376 step=0.100000
2017/08/29 10:21:51 step 2: mse=141.920876 step=0.100000
2017/08/29 10:21:52 step 3: mse=139.264045 step=0.100000
2017/08/29 10:21:54 step 4: mse=137.192834 step=0.100000
2017/08/29 10:21:55 step 5: mse=135.260483 step=0.100000
2017/08/29 10:21:56 step 6: mse=133.583733 step=0.100000
2017/08/29 10:21:58 step 7: mse=132.421877 step=0.100000
2017/08/29 10:21:58 Saving...
2017/08/29 10:21:58 Gathering batch of experience...
2017/08/29 10:22:48 batch 1217: mean=244.096774 stddev=170.039531 entropy=0.306371 frames=6722 count=31
2017/08/29 10:22:48 Training policy...
2017/08/29 10:22:55 step 0: objective=1.6439604
2017/08/29 10:22:58 step 1: objective=1.6509475
2017/08/29 10:23:01 step 2: objective=1.6547319
2017/08/29 10:23:04 step 3: objective=1.6574988
2017/08/29 10:23:08 step 4: objective=1.6603571
2017/08/29 10:23:11 step 5: objective=1.6646525
2017/08/29 10:23:14 step 6: objective=1.6678923
2017/08/29 10:23:17 step 7: objective=1.6707809
2017/08/29 10:23:17 Training value function...
2017/08/29 10:23:20 step 0: mse=166.832011 step=0.100000
2017/08/29 10:23:22 step 1: mse=163.510834 step=0.100000
2017/08/29 10:23:23 step 2: mse=160.688726 step=0.100000
2017/08/29 10:23:25 step 3: mse=158.377700 step=0.100000
2017/08/29 10:23:26 step 4: mse=156.263258 step=0.100000
2017/08/29 10:23:27 step 5: mse=154.457944 step=0.100000
2017/08/29 10:23:29 step 6: mse=152.870638 step=0.100000
2017/08/29 10:23:30 step 7: mse=151.395548 step=0.100000
2017/08/29 10:23:30 Saving...
2017/08/29 10:23:30 Gathering batch of experience...
2017/08/29 10:24:18 batch 1218: mean=213.965517 stddev=189.418799 entropy=0.299039 frames=5865 count=29
2017/08/29 10:24:18 Training policy...
2017/08/29 10:24:24 step 0: objective=0.58486426
2017/08/29 10:24:26 step 1: objective=0.5913863
2017/08/29 10:24:29 step 2: objective=0.5981837
2017/08/29 10:24:32 step 3: objective=0.6015648
2017/08/29 10:24:35 step 4: objective=0.6043824
2017/08/29 10:24:38 step 5: objective=0.608385
2017/08/29 10:24:41 step 6: objective=0.6104622
2017/08/29 10:24:43 step 7: objective=0.6125381
2017/08/29 10:24:43 Training value function...
2017/08/29 10:24:46 step 0: mse=151.858678 step=0.100000
2017/08/29 10:24:47 step 1: mse=149.754542 step=0.100000
2017/08/29 10:24:48 step 2: mse=147.555400 step=0.100000
2017/08/29 10:24:50 step 3: mse=145.775982 step=0.100000
2017/08/29 10:24:51 step 4: mse=144.346642 step=0.100000
2017/08/29 10:24:52 step 5: mse=142.561041 step=0.100000
2017/08/29 10:24:53 step 6: mse=141.491639 step=0.100000
2017/08/29 10:24:55 step 7: mse=140.460649 step=0.100000
2017/08/29 10:24:55 Saving...
2017/08/29 10:24:55 Gathering batch of experience...
2017/08/29 10:25:47 batch 1219: mean=238.800000 stddev=186.052215 entropy=0.302308 frames=6831 count=30
2017/08/29 10:25:47 Training policy...
2017/08/29 10:25:53 step 0: objective=0.8678481
2017/08/29 10:25:56 step 1: objective=0.87307113
2017/08/29 10:26:00 step 2: objective=0.8770129
2017/08/29 10:26:03 step 3: objective=0.881262
2017/08/29 10:26:06 step 4: objective=0.8832815
2017/08/29 10:26:09 step 5: objective=0.88606745
2017/08/29 10:26:13 step 6: objective=0.8877943
2017/08/29 10:26:16 step 7: objective=0.8917541
2017/08/29 10:26:16 Training value function...
2017/08/29 10:26:19 step 0: mse=143.011879 step=0.100000
2017/08/29 10:26:20 step 1: mse=141.534631 step=0.100000
2017/08/29 10:26:22 step 2: mse=140.344643 step=0.100000
2017/08/29 10:26:23 step 3: mse=139.092229 step=0.100000
2017/08/29 10:26:25 step 4: mse=137.897027 step=0.100000
2017/08/29 10:26:26 step 5: mse=136.738519 step=0.100000
2017/08/29 10:26:28 step 6: mse=135.579636 step=0.100000
2017/08/29 10:26:29 step 7: mse=134.799438 step=0.100000
2017/08/29 10:26:29 Saving...
2017/08/29 10:26:29 Gathering batch of experience...
2017/08/29 10:27:20 batch 1220: mean=233.612903 stddev=193.813791 entropy=0.300608 frames=6797 count=31
2017/08/29 10:27:20 Training policy...
2017/08/29 10:27:27 step 0: objective=1.128864
2017/08/29 10:27:30 step 1: objective=1.133435
2017/08/29 10:27:33 step 2: objective=1.1396205
2017/08/29 10:27:37 step 3: objective=1.1473378
2017/08/29 10:27:40 step 4: objective=1.1503853
2017/08/29 10:27:43 step 5: objective=1.1545695
2017/08/29 10:27:46 step 6: objective=1.1586943
2017/08/29 10:27:50 step 7: objective=1.1608807
2017/08/29 10:27:50 Training value function...
2017/08/29 10:27:52 step 0: mse=157.892565 step=0.100000
2017/08/29 10:27:54 step 1: mse=155.911807 step=0.100000
2017/08/29 10:27:55 step 2: mse=154.111028 step=0.100000
2017/08/29 10:27:57 step 3: mse=152.564978 step=0.100000
2017/08/29 10:27:58 step 4: mse=151.245402 step=0.100000
2017/08/29 10:28:00 step 5: mse=149.643194 step=0.100000
2017/08/29 10:28:01 step 6: mse=148.530558 step=0.100000
2017/08/29 10:28:03 step 7: mse=147.401736 step=0.100000
2017/08/29 10:28:03 Saving...
2017/08/29 10:28:03 Gathering batch of experience...
2017/08/29 10:28:59 batch 1221: mean=262.620690 stddev=200.747468 entropy=0.296532 frames=7114 count=29
2017/08/29 10:28:59 Training policy...
2017/08/29 10:29:06 step 0: objective=1.4279268
2017/08/29 10:29:09 step 1: objective=1.4317482
2017/08/29 10:29:13 step 2: objective=1.4372734
2017/08/29 10:29:16 step 3: objective=1.4425081
2017/08/29 10:29:19 step 4: objective=1.4473021
2017/08/29 10:29:23 step 5: objective=1.4505123
2017/08/29 10:29:26 step 6: objective=1.4524212
2017/08/29 10:29:30 step 7: objective=1.4547436
2017/08/29 10:29:30 Training value function...
2017/08/29 10:29:33 step 0: mse=174.021369 step=0.100000
2017/08/29 10:29:34 step 1: mse=169.841677 step=0.100000
2017/08/29 10:29:36 step 2: mse=166.209126 step=0.100000
2017/08/29 10:29:37 step 3: mse=163.153529 step=0.100000
2017/08/29 10:29:39 step 4: mse=160.698703 step=0.100000
2017/08/29 10:29:40 step 5: mse=158.687412 step=0.100000
2017/08/29 10:29:42 step 6: mse=156.830876 step=0.100000
2017/08/29 10:29:43 step 7: mse=155.022144 step=0.100000
2017/08/29 10:29:43 Saving...
2017/08/29 10:29:43 Gathering batch of experience...
2017/08/29 10:30:36 batch 1222: mean=263.966667 stddev=189.901287 entropy=0.299907 frames=7245 count=30
2017/08/29 10:30:36 Training policy...
2017/08/29 10:30:42 step 0: objective=1.2707278
2017/08/29 10:30:46 step 1: objective=1.2774421
2017/08/29 10:30:49 step 2: objective=1.2834771
2017/08/29 10:30:53 step 3: objective=1.2898531
2017/08/29 10:30:56 step 4: objective=1.2946916
2017/08/29 10:31:00 step 5: objective=1.298702
2017/08/29 10:31:03 step 6: objective=1.3007113
2017/08/29 10:31:07 step 7: objective=1.3041259
2017/08/29 10:31:07 Training value function...
2017/08/29 10:31:10 step 0: mse=151.097727 step=0.100000
2017/08/29 10:31:12 step 1: mse=148.660253 step=0.100000
2017/08/29 10:31:13 step 2: mse=146.563904 step=0.100000
2017/08/29 10:31:15 step 3: mse=144.687886 step=0.100000
2017/08/29 10:31:16 step 4: mse=143.062882 step=0.100000
2017/08/29 10:31:18 step 5: mse=141.766496 step=0.100000
2017/08/29 10:31:19 step 6: mse=140.827008 step=0.100000
2017/08/29 10:31:21 step 7: mse=140.043550 step=0.100000
2017/08/29 10:31:21 Saving...
2017/08/29 10:31:21 Gathering batch of experience...
2017/08/29 10:32:09 batch 1223: mean=223.178571 stddev=190.458292 entropy=0.303502 frames=6160 count=28
2017/08/29 10:32:09 Training policy...
2017/08/29 10:32:15 step 0: objective=0.077903
2017/08/29 10:32:18 step 1: objective=0.08302744
2017/08/29 10:32:21 step 2: objective=0.090167165
2017/08/29 10:32:24 step 3: objective=0.094976194
2017/08/29 10:32:27 step 4: objective=0.0990373
2017/08/29 10:32:30 step 5: objective=0.10299416
2017/08/29 10:32:33 step 6: objective=0.10651821
2017/08/29 10:32:36 step 7: objective=0.11066481
2017/08/29 10:32:36 Training value function...
2017/08/29 10:32:38 step 0: mse=140.293250 step=0.100000
2017/08/29 10:32:40 step 1: mse=138.255169 step=0.100000
2017/08/29 10:32:41 step 2: mse=136.553016 step=0.100000
2017/08/29 10:32:42 step 3: mse=135.405923 step=0.100000
2017/08/29 10:32:44 step 4: mse=134.285002 step=0.100000
2017/08/29 10:32:45 step 5: mse=133.119532 step=0.100000
2017/08/29 10:32:46 step 6: mse=132.570000 step=0.100000
2017/08/29 10:32:47 step 7: mse=132.022759 step=0.100000
2017/08/29 10:32:47 Saving...
2017/08/29 10:32:48 Gathering batch of experience...
2017/08/29 10:33:40 batch 1224: mean=247.200000 stddev=185.940743 entropy=0.301340 frames=6760 count=30
2017/08/29 10:33:40 Training policy...
2017/08/29 10:33:46 step 0: objective=1.7090098
2017/08/29 10:33:50 step 1: objective=1.7142918
2017/08/29 10:33:53 step 2: objective=1.7212228
2017/08/29 10:33:56 step 3: objective=1.7255127
2017/08/29 10:33:59 step 4: objective=1.7323072
2017/08/29 10:34:03 step 5: objective=1.7355616
2017/08/29 10:34:06 step 6: objective=1.7387335
2017/08/29 10:34:09 step 7: objective=1.7418572
2017/08/29 10:34:09 Training value function...
2017/08/29 10:34:12 step 0: mse=181.100922 step=0.100000
2017/08/29 10:34:13 step 1: mse=177.576580 step=0.100000
2017/08/29 10:34:15 step 2: mse=174.155161 step=0.100000
2017/08/29 10:34:16 step 3: mse=170.955826 step=0.100000
2017/08/29 10:34:18 step 4: mse=168.439851 step=0.100000
2017/08/29 10:34:19 step 5: mse=166.130604 step=0.100000
2017/08/29 10:34:21 step 6: mse=164.011921 step=0.100000
2017/08/29 10:34:22 step 7: mse=161.882095 step=0.100000
2017/08/29 10:34:22 Saving...
2017/08/29 10:34:22 Gathering batch of experience...
2017/08/29 10:35:19 batch 1225: mean=331.130435 stddev=192.156482 entropy=0.308067 frames=7148 count=23
2017/08/29 10:35:19 Training policy...
2017/08/29 10:35:25 step 0: objective=1.4005383
2017/08/29 10:35:29 step 1: objective=1.4047496
2017/08/29 10:35:32 step 2: objective=1.4076513
2017/08/29 10:35:36 step 3: objective=1.4104615
2017/08/29 10:35:39 step 4: objective=1.4141222
2017/08/29 10:35:42 step 5: objective=1.416432
2017/08/29 10:35:46 step 6: objective=1.4186279
2017/08/29 10:35:49 step 7: objective=1.421358
2017/08/29 10:35:49 Training value function...
2017/08/29 10:35:52 step 0: mse=137.341838 step=0.100000
2017/08/29 10:35:54 step 1: mse=135.010994 step=0.100000
2017/08/29 10:35:55 step 2: mse=132.836259 step=0.100000
2017/08/29 10:35:57 step 3: mse=131.101554 step=0.100000
2017/08/29 10:35:58 step 4: mse=129.543089 step=0.100000
2017/08/29 10:36:00 step 5: mse=128.072738 step=0.100000
2017/08/29 10:36:02 step 6: mse=126.701987 step=0.100000
2017/08/29 10:36:03 step 7: mse=125.679454 step=0.100000
2017/08/29 10:36:03 Saving...
2017/08/29 10:36:03 Gathering batch of experience...
2017/08/29 10:36:55 batch 1226: mean=290.680000 stddev=189.136082 entropy=0.301490 frames=7025 count=25
2017/08/29 10:36:55 Training policy...
2017/08/29 10:37:01 step 0: objective=0.6864859
2017/08/29 10:37:05 step 1: objective=0.6896658
2017/08/29 10:37:08 step 2: objective=0.6929809
2017/08/29 10:37:11 step 3: objective=0.697004
2017/08/29 10:37:15 step 4: objective=0.70040286
2017/08/29 10:37:18 step 5: objective=0.70209193
2017/08/29 10:37:22 step 6: objective=0.7037342
2017/08/29 10:37:25 step 7: objective=0.70782655
2017/08/29 10:37:25 Training value function...
2017/08/29 10:37:28 step 0: mse=128.503017 step=0.100000
2017/08/29 10:37:29 step 1: mse=126.929758 step=0.100000
2017/08/29 10:37:31 step 2: mse=125.997889 step=0.100000
2017/08/29 10:37:32 step 3: mse=124.847419 step=0.100000
2017/08/29 10:37:34 step 4: mse=123.677837 step=0.100000
2017/08/29 10:37:35 step 5: mse=122.903783 step=0.100000
2017/08/29 10:37:37 step 6: mse=122.205705 step=0.100000
2017/08/29 10:37:38 step 7: mse=121.405078 step=0.100000
2017/08/29 10:37:38 Saving...
2017/08/29 10:37:39 Gathering batch of experience...
2017/08/29 10:38:33 batch 1227: mean=261.392857 stddev=185.578505 entropy=0.306456 frames=7184 count=28
2017/08/29 10:38:33 Training policy...
2017/08/29 10:38:40 step 0: objective=0.63343143
2017/08/29 10:38:43 step 1: objective=0.6391634
2017/08/29 10:38:47 step 2: objective=0.64229155
2017/08/29 10:38:50 step 3: objective=0.6466602
2017/08/29 10:38:54 step 4: objective=0.64960754
2017/08/29 10:38:57 step 5: objective=0.6515081
2017/08/29 10:39:01 step 6: objective=0.6540432
2017/08/29 10:39:04 step 7: objective=0.65791506
2017/08/29 10:39:04 Training value function...
2017/08/29 10:39:07 step 0: mse=113.864798 step=0.100000
2017/08/29 10:39:09 step 1: mse=113.377235 step=0.100000
2017/08/29 10:39:10 step 2: mse=112.885423 step=0.100000
2017/08/29 10:39:12 step 3: mse=112.308672 step=0.100000
2017/08/29 10:39:13 step 4: mse=111.654262 step=0.100000
2017/08/29 10:39:15 step 5: mse=111.311665 step=0.100000
2017/08/29 10:39:16 step 6: mse=110.916149 step=0.100000
2017/08/29 10:39:18 step 7: mse=110.336824 step=0.100000
2017/08/29 10:39:18 Saving...
2017/08/29 10:39:18 Gathering batch of experience...
2017/08/29 10:40:16 batch 1228: mean=273.724138 stddev=224.223549 entropy=0.302385 frames=7403 count=29
2017/08/29 10:40:16 Training policy...
2017/08/29 10:40:22 step 0: objective=1.7491523
2017/08/29 10:40:26 step 1: objective=1.7521756
2017/08/29 10:40:30 step 2: objective=1.7549133
2017/08/29 10:40:33 step 3: objective=1.7574719
2017/08/29 10:40:37 step 4: objective=1.7594998
2017/08/29 10:40:40 step 5: objective=1.7614554
2017/08/29 10:40:44 step 6: objective=1.7635201
2017/08/29 10:40:48 step 7: objective=1.7682072
2017/08/29 10:40:48 Training value function...
2017/08/29 10:40:51 step 0: mse=172.259091 step=0.100000
2017/08/29 10:40:52 step 1: mse=166.713311 step=0.100000
2017/08/29 10:40:54 step 2: mse=162.218448 step=0.100000
2017/08/29 10:40:55 step 3: mse=158.183676 step=0.100000
2017/08/29 10:40:57 step 4: mse=154.878879 step=0.100000
2017/08/29 10:40:59 step 5: mse=152.129822 step=0.100000
2017/08/29 10:41:00 step 6: mse=149.502423 step=0.100000
2017/08/29 10:41:02 step 7: mse=147.395745 step=0.100000
2017/08/29 10:41:02 Saving...
2017/08/29 10:41:02 Gathering batch of experience...
2017/08/29 10:41:50 batch 1229: mean=264.730769 stddev=176.104330 entropy=0.301520 frames=6461 count=26
2017/08/29 10:41:50 Training policy...
2017/08/29 10:41:56 step 0: objective=1.0656112
2017/08/29 10:41:59 step 1: objective=1.0712987
2017/08/29 10:42:02 step 2: objective=1.0777714
2017/08/29 10:42:05 step 3: objective=1.0833137
2017/08/29 10:42:08 step 4: objective=1.0878371
2017/08/29 10:42:11 step 5: objective=1.0905929
2017/08/29 10:42:15 step 6: objective=1.0932736
2017/08/29 10:42:18 step 7: objective=1.094859
2017/08/29 10:42:18 Training value function...
2017/08/29 10:42:20 step 0: mse=143.552819 step=0.100000
2017/08/29 10:42:22 step 1: mse=139.548422 step=0.100000
2017/08/29 10:42:23 step 2: mse=136.206992 step=0.100000
2017/08/29 10:42:25 step 3: mse=133.994378 step=0.100000
2017/08/29 10:42:26 step 4: mse=132.144560 step=0.100000
2017/08/29 10:42:27 step 5: mse=130.275947 step=0.100000
2017/08/29 10:42:29 step 6: mse=128.784271 step=0.100000
2017/08/29 10:42:30 step 7: mse=127.362325 step=0.100000
2017/08/29 10:42:30 Saving...
2017/08/29 10:42:30 Gathering batch of experience...
2017/08/29 10:43:18 batch 1230: mean=236.296296 stddev=179.710635 entropy=0.303527 frames=5951 count=27
2017/08/29 10:43:18 Training policy...
2017/08/29 10:43:24 step 0: objective=0.93848187
2017/08/29 10:43:27 step 1: objective=0.94551927
2017/08/29 10:43:30 step 2: objective=0.9524568
2017/08/29 10:43:32 step 3: objective=0.9569106
2017/08/29 10:43:35 step 4: objective=0.9612913
stat *.go: no such file or directory
2017/08/29 10:50:24 Run with arguments: [-algo mse -env PenguinSkip-v0 -step 0.03 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic PenguinSkip-v0/critic.json -actor PenguinSkip-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1 -tuneiters 8]
2017/08/29 10:50:24 Creating environments...
2017/08/29 10:50:35 Loaded forest from: PenguinSkip-v0/actor.json
2017/08/29 10:50:35 Loaded forest from: PenguinSkip-v0/critic.json
2017/08/29 10:50:35 Running. Press Ctrl+C to stop.
2017/08/29 10:50:35 Gathering batch of experience...
2017/08/29 10:51:22 batch 0: mean=255.178571 stddev=199.216869 entropy=0.300175 frames=6556 count=28
2017/08/29 10:51:22 Training policy...
2017/08/29 10:51:29 tune 0: objective=1.337658103025854 reg=0.0030017428604693875 prune=0
2017/08/29 10:51:32 tune 1: objective=1.3709778614055825 reg=0.002999592001951635 prune=0
2017/08/29 10:51:36 tune 2: objective=1.387643028571156 reg=0.0029947671896077424 prune=0
2017/08/29 10:51:39 tune 3: objective=1.3971156550297437 reg=0.002993475743515452 prune=0
2017/08/29 10:51:43 tune 4: objective=1.4056940922437462 reg=0.0029868724653093898 prune=0
2017/08/29 10:51:47 tune 5: objective=1.412426951456681 reg=0.0029818501102989808 prune=0
2017/08/29 10:51:50 tune 6: objective=1.4180730199435632 reg=0.00298087985287213 prune=0
2017/08/29 10:51:54 tune 7: objective=1.4232558319669004 reg=0.0029761376651486946 prune=0
2017/08/29 10:51:56 step 0: objective=1.427447483698139 reg=0.002973992625266186
2017/08/29 10:51:58 step 1: objective=1.4286047311146277 reg=0.0029738710157895974
2017/08/29 10:52:01 step 2: objective=1.4296091485852653 reg=0.0029733412290506786
2017/08/29 10:52:03 step 3: objective=1.4304450956185173 reg=0.0029729109409744234
2017/08/29 10:52:05 step 4: objective=1.4308089977215528 reg=0.0029727224171925345
2017/08/29 10:52:07 step 5: objective=1.4317466824283098 reg=0.0029728763200947248
2017/08/29 10:52:10 step 6: objective=1.4321432061279744 reg=0.002972904831407418
2017/08/29 10:52:12 step 7: objective=1.432568776454774 reg=0.0029722359792861796
2017/08/29 10:52:12 Training value function...
2017/08/29 10:52:15 step 0: mse=157.491059 step=0.100000
2017/08/29 10:52:16 step 1: mse=155.073983 step=0.100000
2017/08/29 10:52:17 step 2: mse=152.674301 step=0.100000
2017/08/29 10:52:19 step 3: mse=151.475013 step=0.100000
2017/08/29 10:52:20 step 4: mse=150.151426 step=0.100000
2017/08/29 10:52:22 step 5: mse=148.880549 step=0.100000
2017/08/29 10:52:23 step 6: mse=147.762918 step=0.100000
2017/08/29 10:52:24 step 7: mse=146.401580 step=0.100000
2017/08/29 10:52:24 Saving...
2017/08/29 10:52:25 Gathering batch of experience...
2017/08/29 10:53:16 batch 1: mean=248.724138 stddev=186.196021 entropy=0.301861 frames=6864 count=29
2017/08/29 10:53:16 Training policy...
2017/08/29 10:53:22 tune 0: objective=0.7042700138403264 reg=0.0030186045697796872 prune=0
2017/08/29 10:53:26 tune 1: objective=0.7357122959234775 reg=0.003009695828933538 prune=0
2017/08/29 10:53:30 tune 2: objective=0.7510417235759033 reg=0.0030026263568229054 prune=0
2017/08/29 10:53:34 tune 3: objective=0.761739735280995 reg=0.0030015884857355576 prune=0
2017/08/29 10:53:37 tune 4: objective=0.7696414405093605 reg=0.0030008518334591026 prune=0
2017/08/29 10:53:41 tune 5: objective=0.7761946813765661 reg=0.0029991048199313505 prune=0
2017/08/29 10:53:45 tune 6: objective=0.7814479730068109 reg=0.0029937448479356744 prune=0
2017/08/29 10:53:49 tune 7: objective=0.7848246114237325 reg=0.002997992477772675 prune=0
2017/08/29 10:53:51 step 0: objective=0.7871073120401734 reg=0.0029873992457534328
2017/08/29 10:53:53 step 1: objective=0.7898796455009834 reg=0.002988652193740809
2017/08/29 10:53:56 step 2: objective=0.7918114295372596 reg=0.0029884618479055123
2017/08/29 10:53:58 step 3: objective=0.7929440656186262 reg=0.0029890409438482254
2017/08/29 10:54:01 step 4: objective=0.7937839748142482 reg=0.0029892643570622085
2017/08/29 10:54:03 step 5: objective=0.794159504639241 reg=0.0029894502568633963
2017/08/29 10:54:05 step 6: objective=0.7949136231606935 reg=0.0029895764130812427
2017/08/29 10:54:08 step 7: objective=0.7953826975433421 reg=0.002989975444642536
2017/08/29 10:54:08 Training value function...
2017/08/29 10:54:11 step 0: mse=146.917615 step=0.100000
2017/08/29 10:54:12 step 1: mse=146.304101 step=0.100000
2017/08/29 10:54:13 step 2: mse=145.713388 step=0.100000
2017/08/29 10:54:15 step 3: mse=144.954036 step=0.100000
2017/08/29 10:54:16 step 4: mse=144.318837 step=0.100000
2017/08/29 10:54:18 step 5: mse=143.664369 step=0.100000
2017/08/29 10:54:19 step 6: mse=143.041177 step=0.100000
2017/08/29 10:54:21 step 7: mse=142.520872 step=0.100000
2017/08/29 10:54:21 Saving...
2017/08/29 10:54:21 Gathering batch of experience...
2017/08/29 10:55:04 batch 2: mean=252.500000 stddev=190.246652 entropy=0.299303 frames=6315 count=26
2017/08/29 10:55:04 Training policy...
2017/08/29 10:55:10 tune 0: objective=0.8481561293794537 reg=0.002993040167898388 prune=0
2017/08/29 10:55:14 tune 1: objective=0.8776684203038401 reg=0.002983075139641479 prune=0
2017/08/29 10:55:17 tune 2: objective=0.8937764437351544 reg=0.0029821741703664703 prune=0
2017/08/29 10:55:21 tune 3: objective=0.9037081539489311 reg=0.002978804672132479 prune=0
2017/08/29 10:55:24 tune 4: objective=0.9108198176464767 reg=0.0029775654240817378 prune=0
2017/08/29 10:55:28 tune 5: objective=0.9166450168250199 reg=0.002973924698757918 prune=0
2017/08/29 10:55:31 tune 6: objective=0.9220243839073635 reg=0.00297269390767657 prune=0
2017/08/29 10:55:34 tune 7: objective=0.9264196110451307 reg=0.0029696333908600554 prune=0
2017/08/29 10:55:37 step 0: objective=0.9301152390142519 reg=0.002969740613150578
2017/08/29 10:55:39 step 1: objective=0.9309613612183294 reg=0.002968947168200713
2017/08/29 10:55:41 step 2: objective=0.9313058256631038 reg=0.0029687816532283006
2017/08/29 10:55:49 Run with arguments: [-algo mse -env PenguinSkip-v0 -step 0.03 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic PenguinSkip-v0/critic.json -actor PenguinSkip-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1 -tuneiters 8 -tunestep 0.1]
2017/08/29 10:55:49 Creating environments...
2017/08/29 10:56:00 Loaded forest from: PenguinSkip-v0/actor.json
2017/08/29 10:56:00 Loaded forest from: PenguinSkip-v0/critic.json
2017/08/29 10:56:00 Running. Press Ctrl+C to stop.
2017/08/29 10:56:00 Gathering batch of experience...
2017/08/29 10:56:43 batch 0: mean=245.166667 stddev=174.313574 entropy=0.295566 frames=5830 count=24
2017/08/29 10:56:43 Training policy...
2017/08/29 10:56:49 tune 0: objective=0.4514975493808962 reg=0.002955656885896293 prune=0
2017/08/29 10:56:52 tune 1: objective=0.456189655807783 reg=0.0029546433411167987 prune=0
2017/08/29 10:56:55 tune 2: objective=0.4608035786074185 reg=0.0029536585865053465 prune=0
2017/08/29 10:56:58 tune 3: objective=0.4653471068289022 reg=0.0029526983689689306 prune=0
2017/08/29 10:57:01 tune 4: objective=0.46944795742656514 reg=0.0029517338983395085 prune=0
2017/08/29 10:57:05 tune 5: objective=0.473052318959048 reg=0.0029511077121845853 prune=0
2017/08/29 10:57:08 tune 6: objective=0.4762875800680746 reg=0.0029505394335267473 prune=0
2017/08/29 10:57:11 tune 7: objective=0.4788912162977058 reg=0.0029499963462659463 prune=0
2017/08/29 10:57:13 step 0: objective=0.4813641556335763 reg=0.0029497522841595864
2017/08/29 10:57:15 step 1: objective=0.4833512006861063 reg=0.0029499453091498713
2017/08/29 10:57:18 Run with arguments: [-algo mse -env PenguinSkip-v0 -step 0.03 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic PenguinSkip-v0/critic.json -actor PenguinSkip-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1 -tuneiters 8 -tunestep 0.1]
2017/08/29 10:57:18 Creating environments...
2017/08/29 10:57:29 Loaded forest from: PenguinSkip-v0/actor.json
2017/08/29 10:57:29 Loaded forest from: PenguinSkip-v0/critic.json
2017/08/29 10:57:29 Running. Press Ctrl+C to stop.
2017/08/29 10:57:29 Gathering batch of experience...
2017/08/29 10:58:19 batch 0: mean=224.967742 stddev=186.032339 entropy=0.294372 frames=6672 count=31
2017/08/29 10:58:19 Training policy...
2017/08/29 10:58:25 tune 0: objective=0.70400 reg=0.00294 prune=0
2017/08/29 10:58:29 tune 1: objective=0.70737 reg=0.00294 prune=0
2017/08/29 10:58:33 tune 2: objective=0.71071 reg=0.00294 prune=0
2017/08/29 10:58:36 tune 3: objective=0.71403 reg=0.00294 prune=0
2017/08/29 10:58:40 tune 4: objective=0.71731 reg=0.00294 prune=0
2017/08/29 10:58:44 tune 5: objective=0.72055 reg=0.00294 prune=0
2017/08/29 10:58:47 tune 6: objective=0.72354 reg=0.00294 prune=0
2017/08/29 10:58:51 tune 7: objective=0.72613 reg=0.00294 prune=0
2017/08/29 10:58:53 step 0: objective=0.72843 reg=0.00294
2017/08/29 10:58:56 step 1: objective=0.73234 reg=0.00294
2017/08/29 10:58:58 step 2: objective=0.73392 reg=0.00294
2017/08/29 10:59:00 step 3: objective=0.73522 reg=0.00294
2017/08/29 10:59:03 step 4: objective=0.73678 reg=0.00294
2017/08/29 10:59:05 step 5: objective=0.73935 reg=0.00294
2017/08/29 10:59:07 step 6: objective=0.74131 reg=0.00294
2017/08/29 10:59:10 step 7: objective=0.74289 reg=0.00294
2017/08/29 10:59:10 Training value function...
2017/08/29 10:59:12 step 0: mse=139.501544 step=0.100000
2017/08/29 10:59:14 step 1: mse=137.153654 step=0.100000
2017/08/29 10:59:15 step 2: mse=135.077632 step=0.100000
2017/08/29 10:59:17 step 3: mse=133.315031 step=0.100000
2017/08/29 10:59:18 step 4: mse=131.767514 step=0.100000
2017/08/29 10:59:19 step 5: mse=130.555347 step=0.100000
2017/08/29 10:59:21 step 6: mse=129.461291 step=0.100000
2017/08/29 10:59:22 step 7: mse=128.747952 step=0.100000
2017/08/29 10:59:22 Saving...
2017/08/29 10:59:22 Gathering batch of experience...
2017/08/29 11:00:12 batch 1: mean=284.285714 stddev=228.053073 entropy=0.300903 frames=7450 count=28
2017/08/29 11:00:12 Training policy...
2017/08/29 11:00:19 tune 0: objective=1.70681 reg=0.00301 prune=0
2017/08/29 11:00:26 Run with arguments: [-algo mse -env PenguinSkip-v0 -step 0.03 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic PenguinSkip-v0/critic.json -actor PenguinSkip-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1 -tuneiters 8 -tunestep 0.1]
2017/08/29 11:00:26 Creating environments...
2017/08/29 11:00:37 Loaded forest from: PenguinSkip-v0/actor.json
2017/08/29 11:00:37 Loaded forest from: PenguinSkip-v0/critic.json
2017/08/29 11:00:37 Running. Press Ctrl+C to stop.
2017/08/29 11:00:37 Gathering batch of experience...
2017/08/29 11:01:29 batch 0: mean=209.333333 stddev=165.798831 entropy=0.291984 frames=6812 count=33
2017/08/29 11:01:29 Training policy...
2017/08/29 11:01:36 tune 0: objective=0.381920 reg=0.002920 prune=0
2017/08/29 11:01:40 tune 1: objective=0.385509 reg=0.002920 prune=0
2017/08/29 11:01:43 tune 2: objective=0.389051 reg=0.002919 prune=0
2017/08/29 11:01:47 tune 3: objective=0.392548 reg=0.002919 prune=0
2017/08/29 11:01:51 tune 4: objective=0.396005 reg=0.002919 prune=0
2017/08/29 11:01:55 tune 5: objective=0.399148 reg=0.002919 prune=0
2017/08/29 11:01:58 tune 6: objective=0.401836 reg=0.002918 prune=0
2017/08/29 11:02:02 tune 7: objective=0.404315 reg=0.002918 prune=0
2017/08/29 11:02:04 step 0: objective=0.406583 reg=0.002918
2017/08/29 11:02:07 step 1: objective=0.408807 reg=0.002918
2017/08/29 11:02:09 step 2: objective=0.411307 reg=0.002919
2017/08/29 11:02:11 step 3: objective=0.413795 reg=0.002919
2017/08/29 11:02:14 step 4: objective=0.415812 reg=0.002918
2017/08/29 11:02:16 step 5: objective=0.417665 reg=0.002919
2017/08/29 11:02:19 step 6: objective=0.420258 reg=0.002919
2017/08/29 11:02:21 step 7: objective=0.422194 reg=0.002919
2017/08/29 11:02:21 Training value function...
2017/08/29 11:02:24 step 0: mse=134.442122 step=0.100000
2017/08/29 11:02:25 step 1: mse=134.010792 step=0.100000
2017/08/29 11:02:27 step 2: mse=133.544784 step=0.100000
2017/08/29 11:02:28 step 3: mse=132.983604 step=0.100000
2017/08/29 11:02:30 step 4: mse=132.831691 step=0.100000
2017/08/29 11:02:31 step 5: mse=132.543586 step=0.100000
2017/08/29 11:02:32 step 6: mse=132.227810 step=0.100000
2017/08/29 11:02:34 step 7: mse=132.207839 step=0.100000
2017/08/29 11:02:34 Saving...
2017/08/29 11:02:34 Gathering batch of experience...
2017/08/29 11:03:22 batch 1: mean=241.566667 stddev=199.082342 entropy=0.297806 frames=6960 count=30
2017/08/29 11:03:22 Training policy...
2017/08/29 11:03:29 tune 0: objective=1.459496 reg=0.002978 prune=0
2017/08/29 11:03:33 tune 1: objective=1.462734 reg=0.002978 prune=0
2017/08/29 11:03:36 tune 2: objective=1.465938 reg=0.002977 prune=0
2017/08/29 11:03:40 tune 3: objective=1.469103 reg=0.002977 prune=0
2017/08/29 11:03:44 tune 4: objective=1.472238 reg=0.002977 prune=0
2017/08/29 11:03:48 tune 5: objective=1.475128 reg=0.002976 prune=0
2017/08/29 11:03:52 tune 6: objective=1.477714 reg=0.002976 prune=0
2017/08/29 11:03:56 tune 7: objective=1.480048 reg=0.002976 prune=0
2017/08/29 11:03:58 step 0: objective=1.482266 reg=0.002976
2017/08/29 11:04:00 step 1: objective=1.484796 reg=0.002976
2017/08/29 11:04:03 step 2: objective=1.487714 reg=0.002976
2017/08/29 11:04:05 step 3: objective=1.488998 reg=0.002976
2017/08/29 11:04:08 step 4: objective=1.490623 reg=0.002975
2017/08/29 11:04:10 step 5: objective=1.493836 reg=0.002974
2017/08/29 11:04:12 step 6: objective=1.495568 reg=0.002974
2017/08/29 11:04:15 step 7: objective=1.497143 reg=0.002973
2017/08/29 11:04:15 Training value function...
2017/08/29 11:04:18 step 0: mse=150.950814 step=0.100000
2017/08/29 11:04:19 step 1: mse=149.343634 step=0.100000
2017/08/29 11:04:21 step 2: mse=147.955682 step=0.100000
2017/08/29 11:04:22 step 3: mse=146.674743 step=0.100000
2017/08/29 11:04:24 step 4: mse=145.575830 step=0.100000
2017/08/29 11:04:25 step 5: mse=144.532868 step=0.100000
2017/08/29 11:04:27 step 6: mse=143.275739 step=0.100000
2017/08/29 11:04:28 step 7: mse=142.274382 step=0.100000
2017/08/29 11:04:28 Saving...
2017/08/29 11:04:28 Gathering batch of experience...
2017/08/29 11:05:13 batch 2: mean=275.880000 stddev=163.779930 entropy=0.300330 frames=6571 count=25
2017/08/29 11:05:13 Training policy...
2017/08/29 11:05:19 tune 0: objective=1.342832 reg=0.003003 prune=0
2017/08/29 11:05:23 tune 1: objective=1.346883 reg=0.003003 prune=0
2017/08/29 11:05:27 tune 2: objective=1.350876 reg=0.003003 prune=0
2017/08/29 11:05:30 tune 3: objective=1.354655 reg=0.003003 prune=0
2017/08/29 11:05:34 tune 4: objective=1.357984 reg=0.003003 prune=0
2017/08/29 11:05:37 tune 5: objective=1.361105 reg=0.003003 prune=0
2017/08/29 11:05:41 tune 6: objective=1.364013 reg=0.003003 prune=0
2017/08/29 11:05:45 tune 7: objective=1.366682 reg=0.003003 prune=0
2017/08/29 11:05:47 step 0: objective=1.368908 reg=0.003003
2017/08/29 11:05:49 step 1: objective=1.372338 reg=0.003002
2017/08/29 11:05:51 step 2: objective=1.375313 reg=0.003001
2017/08/29 11:05:54 step 3: objective=1.376988 reg=0.003001
2017/08/29 11:05:56 step 4: objective=1.379123 reg=0.003001
2017/08/29 11:05:58 step 5: objective=1.381030 reg=0.003001
2017/08/29 11:06:00 step 6: objective=1.382233 reg=0.003001
2017/08/29 11:06:03 step 7: objective=1.383617 reg=0.003000
2017/08/29 11:06:03 Training value function...
2017/08/29 11:06:05 step 0: mse=148.990711 step=0.100000
2017/08/29 11:06:07 step 1: mse=146.323997 step=0.100000
2017/08/29 11:06:08 step 2: mse=144.128999 step=0.100000
2017/08/29 11:06:10 step 3: mse=141.880626 step=0.100000
2017/08/29 11:06:11 step 4: mse=140.170291 step=0.100000
2017/08/29 11:06:13 step 5: mse=138.470755 step=0.100000
2017/08/29 11:06:14 step 6: mse=137.217794 step=0.100000
2017/08/29 11:06:15 step 7: mse=135.823392 step=0.100000
2017/08/29 11:06:15 Saving...
2017/08/29 11:06:15 Gathering batch of experience...
2017/08/29 11:07:02 batch 3: mean=210.290323 stddev=182.391496 entropy=0.295451 frames=6039 count=31
2017/08/29 11:07:02 Training policy...
2017/08/29 11:07:07 tune 0: objective=1.250749 reg=0.002955 prune=0
2017/08/29 11:07:11 tune 1: objective=1.255529 reg=0.002953 prune=0
2017/08/29 11:07:14 tune 2: objective=1.260231 reg=0.002952 prune=0
2017/08/29 11:07:17 tune 3: objective=1.264864 reg=0.002951 prune=0
2017/08/29 11:07:21 tune 4: objective=1.269219 reg=0.002950 prune=0
2017/08/29 11:07:24 tune 5: objective=1.273031 reg=0.002949 prune=0
2017/08/29 11:07:27 tune 6: objective=1.276477 reg=0.002948 prune=0
2017/08/29 11:07:31 tune 7: objective=1.279627 reg=0.002948 prune=0
2017/08/29 11:07:33 step 0: objective=1.282285 reg=0.002947
2017/08/29 11:07:35 step 1: objective=1.285162 reg=0.002947
2017/08/29 11:07:37 step 2: objective=1.287465 reg=0.002947
2017/08/29 11:07:39 step 3: objective=1.291289 reg=0.002945
2017/08/29 11:07:41 step 4: objective=1.293396 reg=0.002945
2017/08/29 11:07:43 step 5: objective=1.296052 reg=0.002944
2017/08/29 11:07:45 step 6: objective=1.298570 reg=0.002944
2017/08/29 11:07:47 step 7: objective=1.299908 reg=0.002943
2017/08/29 11:07:47 Training value function...
2017/08/29 11:07:50 step 0: mse=160.124585 step=0.100000
2017/08/29 11:07:51 step 1: mse=158.360707 step=0.100000
2017/08/29 11:07:52 step 2: mse=156.810450 step=0.100000
2017/08/29 11:07:54 step 3: mse=155.364676 step=0.100000
2017/08/29 11:07:55 step 4: mse=154.285262 step=0.100000
2017/08/29 11:07:56 step 5: mse=152.751377 step=0.100000
2017/08/29 11:07:57 step 6: mse=151.560604 step=0.100000
2017/08/29 11:07:59 step 7: mse=150.454690 step=0.100000
2017/08/29 11:07:59 Saving...
2017/08/29 11:07:59 Gathering batch of experience...
2017/08/29 11:08:48 batch 4: mean=263.629630 stddev=197.528835 entropy=0.290513 frames=6759 count=27
2017/08/29 11:08:48 Training policy...
2017/08/29 11:08:54 tune 0: objective=1.111444 reg=0.002905 prune=0
2017/08/29 11:08:58 tune 1: objective=1.114827 reg=0.002905 prune=0
2017/08/29 11:09:02 tune 2: objective=1.118172 reg=0.002904 prune=0
2017/08/29 11:09:06 tune 3: objective=1.121474 reg=0.002903 prune=0
2017/08/29 11:09:09 tune 4: objective=1.124735 reg=0.002903 prune=0
2017/08/29 11:09:13 tune 5: objective=1.127924 reg=0.002902 prune=0
2017/08/29 11:09:17 tune 6: objective=1.130878 reg=0.002902 prune=0
2017/08/29 11:09:20 tune 7: objective=1.133483 reg=0.002901 prune=0
2017/08/29 11:09:23 step 0: objective=1.135836 reg=0.002901
2017/08/29 11:09:25 step 1: objective=1.137667 reg=0.002901
2017/08/29 11:09:28 step 2: objective=1.139274 reg=0.002901
2017/08/29 11:09:30 step 3: objective=1.141421 reg=0.002900
2017/08/29 11:09:32 step 4: objective=1.144423 reg=0.002900
2017/08/29 11:09:35 step 5: objective=1.146109 reg=0.002901
2017/08/29 11:09:37 step 6: objective=1.147716 reg=0.002901
2017/08/29 11:09:39 step 7: objective=1.150133 reg=0.002901
2017/08/29 11:09:39 Training value function...
2017/08/29 11:09:42 step 0: mse=151.005725 step=0.100000
2017/08/29 11:09:44 step 1: mse=148.620473 step=0.100000
2017/08/29 11:09:45 step 2: mse=146.817292 step=0.100000
2017/08/29 11:09:46 step 3: mse=145.463041 step=0.100000
2017/08/29 11:09:48 step 4: mse=144.010494 step=0.100000
2017/08/29 11:09:49 step 5: mse=142.820464 step=0.100000
2017/08/29 11:09:51 step 6: mse=141.637503 step=0.100000
2017/08/29 11:09:52 step 7: mse=140.608846 step=0.100000
2017/08/29 11:09:52 Saving...
2017/08/29 11:09:52 Gathering batch of experience...
2017/08/29 11:10:41 batch 5: mean=289.360000 stddev=187.934644 entropy=0.293582 frames=6544 count=25
2017/08/29 11:10:41 Training policy...
2017/08/29 11:10:47 tune 0: objective=1.753754 reg=0.002936 prune=0
2017/08/29 11:10:51 tune 1: objective=1.757654 reg=0.002936 prune=0
2017/08/29 11:10:55 tune 2: objective=1.761534 reg=0.002935 prune=0
2017/08/29 11:10:58 tune 3: objective=1.765410 reg=0.002935 prune=0
2017/08/29 11:11:02 tune 4: objective=1.769166 reg=0.002935 prune=0
2017/08/29 11:11:05 tune 5: objective=1.772595 reg=0.002935 prune=0
2017/08/29 11:11:09 tune 6: objective=1.775527 reg=0.002935 prune=0
2017/08/29 11:11:13 tune 7: objective=1.778205 reg=0.002935 prune=0
2017/08/29 11:11:15 step 0: objective=1.780664 reg=0.002935
2017/08/29 11:11:17 step 1: objective=1.783540 reg=0.002935
2017/08/29 11:11:19 step 2: objective=1.785906 reg=0.002936
2017/08/29 11:11:22 step 3: objective=1.789585 reg=0.002936
2017/08/29 11:11:24 step 4: objective=1.790882 reg=0.002936
2017/08/29 11:11:26 step 5: objective=1.793582 reg=0.002936
2017/08/29 11:11:28 step 6: objective=1.796286 reg=0.002936
2017/08/29 11:11:31 step 7: objective=1.797370 reg=0.002936
2017/08/29 11:11:31 Training value function...
2017/08/29 11:11:33 step 0: mse=161.954677 step=0.100000
2017/08/29 11:11:35 step 1: mse=158.705795 step=0.100000
2017/08/29 11:11:36 step 2: mse=155.825921 step=0.100000
2017/08/29 11:11:38 step 3: mse=153.257051 step=0.100000
2017/08/29 11:11:39 step 4: mse=151.216850 step=0.100000
2017/08/29 11:11:40 step 5: mse=149.497934 step=0.100000
2017/08/29 11:11:42 step 6: mse=147.844672 step=0.100000
2017/08/29 11:11:43 step 7: mse=146.387090 step=0.100000
2017/08/29 11:11:43 Saving...
2017/08/29 11:11:43 Gathering batch of experience...
2017/08/29 11:12:30 batch 6: mean=216.968750 stddev=157.862972 entropy=0.292323 frames=6329 count=32
2017/08/29 11:12:30 Training policy...
2017/08/29 11:12:36 tune 0: objective=0.677855 reg=0.002923 prune=0
2017/08/29 11:12:39 tune 1: objective=0.681883 reg=0.002923 prune=0
2017/08/29 11:12:43 tune 2: objective=0.685858 reg=0.002922 prune=0
2017/08/29 11:12:46 tune 3: objective=0.689783 reg=0.002922 prune=0
2017/08/29 11:12:50 tune 4: objective=0.693508 reg=0.002922 prune=0
2017/08/29 11:12:53 tune 5: objective=0.696962 reg=0.002921 prune=0
2017/08/29 11:12:57 tune 6: objective=0.700142 reg=0.002921 prune=0
2017/08/29 11:13:00 tune 7: objective=0.703062 reg=0.002920 prune=0
2017/08/29 11:13:02 step 0: objective=0.705562 reg=0.002920
2017/08/29 11:13:04 step 1: objective=0.708198 reg=0.002921
2017/08/29 11:13:07 step 2: objective=0.711446 reg=0.002920
2017/08/29 11:13:09 step 3: objective=0.713819 reg=0.002920
2017/08/29 11:13:11 step 4: objective=0.715422 reg=0.002921
2017/08/29 11:13:13 step 5: objective=0.716663 reg=0.002920
2017/08/29 11:13:15 step 6: objective=0.718498 reg=0.002920
2017/08/29 11:13:18 step 7: objective=0.719538 reg=0.002920
2017/08/29 11:13:18 Training value function...
2017/08/29 11:13:20 step 0: mse=138.514635 step=0.100000
2017/08/29 11:13:22 step 1: mse=138.178955 step=0.100000
2017/08/29 11:13:23 step 2: mse=137.888714 step=0.100000
2017/08/29 11:13:24 step 3: mse=137.470607 step=0.100000
2017/08/29 11:13:26 step 4: mse=137.132007 step=0.100000
2017/08/29 11:13:27 step 5: mse=136.929407 step=0.100000
2017/08/29 11:13:28 step 6: mse=136.415179 step=0.100000
2017/08/29 11:13:30 step 7: mse=136.163788 step=0.100000
2017/08/29 11:13:30 Saving...
2017/08/29 11:13:30 Gathering batch of experience...
2017/08/29 11:14:19 batch 7: mean=276.807692 stddev=187.989161 entropy=0.293015 frames=6799 count=26
2017/08/29 11:14:19 Training policy...
2017/08/29 11:14:26 tune 0: objective=1.089452 reg=0.002930 prune=0
2017/08/29 11:14:29 tune 1: objective=1.092634 reg=0.002929 prune=0
2017/08/29 11:14:33 tune 2: objective=1.095789 reg=0.002928 prune=0
2017/08/29 11:14:37 tune 3: objective=1.098916 reg=0.002927 prune=0
2017/08/29 11:14:41 tune 4: objective=1.102016 reg=0.002926 prune=0
2017/08/29 11:14:44 tune 5: objective=1.104982 reg=0.002925 prune=0
2017/08/29 11:14:48 tune 6: objective=1.107800 reg=0.002925 prune=0
2017/08/29 11:14:52 tune 7: objective=1.110465 reg=0.002924 prune=0
2017/08/29 11:14:54 step 0: objective=1.112815 reg=0.002923
2017/08/29 11:14:57 step 1: objective=1.115068 reg=0.002923
2017/08/29 11:14:59 step 2: objective=1.117059 reg=0.002922
2017/08/29 11:15:01 step 3: objective=1.119289 reg=0.002922
2017/08/29 11:15:04 step 4: objective=1.120418 reg=0.002921
2017/08/29 11:15:06 step 5: objective=1.122062 reg=0.002921
2017/08/29 11:15:08 step 6: objective=1.123435 reg=0.002920
2017/08/29 11:15:11 step 7: objective=1.125303 reg=0.002919
2017/08/29 11:15:11 Training value function...
2017/08/29 11:15:14 step 0: mse=137.672087 step=0.100000
2017/08/29 11:15:15 step 1: mse=136.299540 step=0.100000
2017/08/29 11:15:16 step 2: mse=134.971884 step=0.100000
2017/08/29 11:15:18 step 3: mse=133.951457 step=0.100000
2017/08/29 11:15:19 step 4: mse=133.060386 step=0.100000
2017/08/29 11:15:21 step 5: mse=132.367659 step=0.100000
2017/08/29 11:15:22 step 6: mse=131.640252 step=0.100000
2017/08/29 11:15:24 step 7: mse=130.993000 step=0.100000
2017/08/29 11:15:24 Saving...
2017/08/29 11:15:24 Gathering batch of experience...
2017/08/29 11:16:13 batch 8: mean=239.357143 stddev=173.363205 entropy=0.293521 frames=6439 count=28
2017/08/29 11:16:13 Training policy...
2017/08/29 11:16:19 tune 0: objective=0.527221 reg=0.002935 prune=0
2017/08/29 11:16:22 tune 1: objective=0.531449 reg=0.002934 prune=0
2017/08/29 11:16:26 tune 2: objective=0.535619 reg=0.002933 prune=0
2017/08/29 11:16:29 tune 3: objective=0.539729 reg=0.002932 prune=0
2017/08/29 11:16:33 tune 4: objective=0.543752 reg=0.002930 prune=0
2017/08/29 11:16:37 tune 5: objective=0.547374 reg=0.002929 prune=0
2017/08/29 11:16:40 tune 6: objective=0.550511 reg=0.002928 prune=0
2017/08/29 11:16:44 tune 7: objective=0.553313 reg=0.002928 prune=0
2017/08/29 11:16:46 step 0: objective=0.555710 reg=0.002927
2017/08/29 11:16:48 step 1: objective=0.557769 reg=0.002927
2017/08/29 11:16:50 step 2: objective=0.559142 reg=0.002926
2017/08/29 11:16:53 step 3: objective=0.561143 reg=0.002927
2017/08/29 11:16:55 step 4: objective=0.562180 reg=0.002927
2017/08/29 11:16:57 step 5: objective=0.563761 reg=0.002928
2017/08/29 11:16:59 step 6: objective=0.565445 reg=0.002927
2017/08/29 11:17:02 step 7: objective=0.566429 reg=0.002928
2017/08/29 11:17:02 Training value function...
2017/08/29 11:17:04 step 0: mse=135.407330 step=0.100000
2017/08/29 11:17:06 step 1: mse=133.998830 step=0.100000
2017/08/29 11:17:07 step 2: mse=132.827036 step=0.100000
2017/08/29 11:17:08 step 3: mse=131.957522 step=0.100000
2017/08/29 11:17:10 step 4: mse=131.148222 step=0.100000
2017/08/29 11:17:11 step 5: mse=130.638707 step=0.100000
2017/08/29 11:17:12 step 6: mse=130.276875 step=0.100000
2017/08/29 11:17:14 step 7: mse=129.803451 step=0.100000
2017/08/29 11:17:14 Saving...
2017/08/29 11:17:14 Gathering batch of experience...
2017/08/29 11:17:58 batch 9: mean=266.240000 stddev=203.476442 entropy=0.293743 frames=6066 count=25
2017/08/29 11:17:58 Training policy...
2017/08/29 11:18:04 tune 0: objective=1.699006 reg=0.002937 prune=0
2017/08/29 11:18:07 tune 1: objective=1.703782 reg=0.002937 prune=0
2017/08/29 11:18:11 tune 2: objective=1.708496 reg=0.002937 prune=0
2017/08/29 11:18:14 tune 3: objective=1.713140 reg=0.002937 prune=0
2017/08/29 11:18:17 tune 4: objective=1.717360 reg=0.002936 prune=0
2017/08/29 11:18:21 tune 5: objective=1.721164 reg=0.002936 prune=0
2017/08/29 11:18:24 tune 6: objective=1.724386 reg=0.002936 prune=0
2017/08/29 11:18:27 tune 7: objective=1.727364 reg=0.002936 prune=0
2017/08/29 11:18:29 step 0: objective=1.730050 reg=0.002936
2017/08/29 11:18:32 step 1: objective=1.732790 reg=0.002935
2017/08/29 11:18:34 step 2: objective=1.734877 reg=0.002936
2017/08/29 11:18:36 step 3: objective=1.737182 reg=0.002935
2017/08/29 11:18:38 step 4: objective=1.739761 reg=0.002934
2017/08/29 11:18:40 step 5: objective=1.742961 reg=0.002933
2017/08/29 11:18:42 step 6: objective=1.744889 reg=0.002933
2017/08/29 11:18:44 step 7: objective=1.746335 reg=0.002932
2017/08/29 11:18:44 Training value function...
2017/08/29 11:18:47 step 0: mse=174.228480 step=0.100000
2017/08/29 11:18:48 step 1: mse=170.345267 step=0.100000
2017/08/29 11:18:49 step 2: mse=167.154854 step=0.100000
2017/08/29 11:18:51 step 3: mse=164.345066 step=0.100000
2017/08/29 11:18:52 step 4: mse=161.580724 step=0.100000
2017/08/29 11:18:53 step 5: mse=159.407365 step=0.100000
2017/08/29 11:18:55 step 6: mse=157.534128 step=0.100000
2017/08/29 11:18:56 step 7: mse=155.741496 step=0.100000
2017/08/29 11:18:56 Saving...
2017/08/29 11:18:56 Gathering batch of experience...
2017/08/29 11:19:41 batch 10: mean=327.863636 stddev=150.235359 entropy=0.294669 frames=6497 count=22
2017/08/29 11:19:41 Training policy...
2017/08/29 11:19:48 tune 0: objective=1.618738 reg=0.002947 prune=0
2017/08/29 11:19:51 tune 1: objective=1.622919 reg=0.002945 prune=0
2017/08/29 11:19:55 tune 2: objective=1.627026 reg=0.002944 prune=0
2017/08/29 11:19:58 tune 3: objective=1.630979 reg=0.002943 prune=0
2017/08/29 11:20:02 tune 4: objective=1.634449 reg=0.002941 prune=0
2017/08/29 11:20:06 tune 5: objective=1.637629 reg=0.002940 prune=0
2017/08/29 11:20:09 tune 6: objective=1.640652 reg=0.002939 prune=0
2017/08/29 11:20:13 tune 7: objective=1.643310 reg=0.002937 prune=0
2017/08/29 11:20:15 step 0: objective=1.645718 reg=0.002936
2017/08/29 11:20:17 step 1: objective=1.648295 reg=0.002936
2017/08/29 11:20:20 step 2: objective=1.650077 reg=0.002935
2017/08/29 11:20:22 step 3: objective=1.652041 reg=0.002934
2017/08/29 11:20:24 step 4: objective=1.655980 reg=0.002934
2017/08/29 11:20:26 step 5: objective=1.657929 reg=0.002933
2017/08/29 11:20:29 step 6: objective=1.659154 reg=0.002932
2017/08/29 11:20:31 step 7: objective=1.661408 reg=0.002930
2017/08/29 11:20:31 Training value function...
2017/08/29 11:20:34 step 0: mse=163.590513 step=0.100000
2017/08/29 11:20:35 step 1: mse=160.569000 step=0.100000
2017/08/29 11:20:36 step 2: mse=158.223240 step=0.100000
2017/08/29 11:20:38 step 3: mse=155.987682 step=0.100000
2017/08/29 11:20:39 step 4: mse=154.435634 step=0.100000
2017/08/29 11:20:41 step 5: mse=153.025586 step=0.100000
2017/08/29 11:20:42 step 6: mse=151.504962 step=0.100000
2017/08/29 11:20:43 step 7: mse=150.184509 step=0.100000
2017/08/29 11:20:43 Saving...
2017/08/29 11:20:43 Gathering batch of experience...
2017/08/29 11:21:32 batch 11: mean=310.692308 stddev=237.555300 entropy=0.295824 frames=7424 count=26
2017/08/29 11:21:32 Training policy...
2017/08/29 11:21:39 tune 0: objective=1.281591 reg=0.002958 prune=0
2017/08/29 11:21:43 tune 1: objective=1.284581 reg=0.002958 prune=0
2017/08/29 11:21:47 tune 2: objective=1.287538 reg=0.002957 prune=0
2017/08/29 11:21:51 tune 3: objective=1.290470 reg=0.002957 prune=0
2017/08/29 11:21:56 tune 4: objective=1.293361 reg=0.002956 prune=0
2017/08/29 11:22:00 tune 5: objective=1.296041 reg=0.002956 prune=0
2017/08/29 11:22:04 tune 6: objective=1.298495 reg=0.002956 prune=0
2017/08/29 11:22:08 tune 7: objective=1.300767 reg=0.002955 prune=0
2017/08/29 11:22:10 step 0: objective=1.302867 reg=0.002955
2017/08/29 11:22:13 step 1: objective=1.304603 reg=0.002955
2017/08/29 11:22:16 step 2: objective=1.306446 reg=0.002955
2017/08/29 11:22:18 step 3: objective=1.308173 reg=0.002954
2017/08/29 11:22:21 step 4: objective=1.310419 reg=0.002954
2017/08/29 11:22:24 step 5: objective=1.312438 reg=0.002954
2017/08/29 11:22:26 step 6: objective=1.313524 reg=0.002954
2017/08/29 11:22:29 step 7: objective=1.314564 reg=0.002954
2017/08/29 11:22:29 Training value function...
2017/08/29 11:22:32 step 0: mse=158.817160 step=0.100000
2017/08/29 11:22:33 step 1: mse=155.402382 step=0.100000
2017/08/29 11:22:35 step 2: mse=152.220778 step=0.100000
2017/08/29 11:22:37 step 3: mse=150.015186 step=0.100000
2017/08/29 11:22:38 step 4: mse=147.971764 step=0.100000
2017/08/29 11:22:40 step 5: mse=145.762078 step=0.100000
2017/08/29 11:22:41 step 6: mse=143.719232 step=0.100000
2017/08/29 11:22:43 step 7: mse=142.664588 step=0.100000
2017/08/29 11:22:43 Saving...
2017/08/29 11:22:43 Gathering batch of experience...
2017/08/29 11:23:26 batch 12: mean=214.642857 stddev=188.457122 entropy=0.283623 frames=5782 count=28
2017/08/29 11:23:26 Training policy...
2017/08/29 11:23:31 tune 0: objective=0.018857 reg=0.002836 prune=0
2017/08/29 11:23:34 tune 1: objective=0.023355 reg=0.002835 prune=0
2017/08/29 11:23:38 tune 2: objective=0.027764 reg=0.002834 prune=0
2017/08/29 11:23:41 tune 3: objective=0.031905 reg=0.002832 prune=0
2017/08/29 11:23:44 tune 4: objective=0.035755 reg=0.002831 prune=0
2017/08/29 11:23:47 tune 5: objective=0.039449 reg=0.002830 prune=0
2017/08/29 11:23:50 tune 6: objective=0.042786 reg=0.002829 prune=0
2017/08/29 11:23:54 tune 7: objective=0.045690 reg=0.002828 prune=0
2017/08/29 11:23:56 step 0: objective=0.048377 reg=0.002827
2017/08/29 11:23:58 step 1: objective=0.052156 reg=0.002826
2017/08/29 11:24:00 step 2: objective=0.055336 reg=0.002826
2017/08/29 11:24:02 step 3: objective=0.057412 reg=0.002826
2017/08/29 11:24:04 step 4: objective=0.059141 reg=0.002827
2017/08/29 11:24:06 step 5: objective=0.060469 reg=0.002827
2017/08/29 11:24:08 step 6: objective=0.062306 reg=0.002827
2017/08/29 11:24:10 step 7: objective=0.063986 reg=0.002826
2017/08/29 11:24:10 Training value function...
2017/08/29 11:24:12 step 0: mse=152.527967 step=0.100000
2017/08/29 11:24:13 step 1: mse=150.189975 step=0.100000
2017/08/29 11:24:15 step 2: mse=148.598865 step=0.100000
2017/08/29 11:24:16 step 3: mse=147.094579 step=0.100000
2017/08/29 11:24:17 step 4: mse=146.118058 step=0.100000
2017/08/29 11:24:18 step 5: mse=145.210864 step=0.100000
2017/08/29 11:24:20 step 6: mse=144.298545 step=0.100000
2017/08/29 11:24:21 step 7: mse=143.679899 step=0.100000
2017/08/29 11:24:21 Saving...
2017/08/29 11:24:21 Gathering batch of experience...
2017/08/29 11:25:04 batch 13: mean=219.964286 stddev=211.422475 entropy=0.284042 frames=5787 count=28
2017/08/29 11:25:04 Training policy...
2017/08/29 11:25:10 tune 0: objective=1.075145 reg=0.002840 prune=0
2017/08/29 11:25:13 tune 1: objective=1.080623 reg=0.002840 prune=0
2017/08/29 11:25:16 tune 2: objective=1.085980 reg=0.002841 prune=0
2017/08/29 11:25:20 tune 3: objective=1.090886 reg=0.002841 prune=0
2017/08/29 11:25:23 tune 4: objective=1.094685 reg=0.002841 prune=0
2017/08/29 11:25:26 tune 5: objective=1.097924 reg=0.002841 prune=0
2017/08/29 11:25:29 tune 6: objective=1.100463 reg=0.002841 prune=0
2017/08/29 11:25:32 tune 7: objective=1.102744 reg=0.002841 prune=0
2017/08/29 11:25:34 step 0: objective=1.104911 reg=0.002841
2017/08/29 11:25:36 step 1: objective=1.106573 reg=0.002842
2017/08/29 11:25:38 step 2: objective=1.108349 reg=0.002842
2017/08/29 11:25:40 step 3: objective=1.110764 reg=0.002841
2017/08/29 11:25:43 step 4: objective=1.113380 reg=0.002840
2017/08/29 11:25:45 step 5: objective=1.114862 reg=0.002841
2017/08/29 11:25:47 step 6: objective=1.116984 reg=0.002840
2017/08/29 11:25:49 step 7: objective=1.118774 reg=0.002839
2017/08/29 11:25:49 Training value function...
2017/08/29 11:25:51 step 0: mse=150.791968 step=0.100000
2017/08/29 11:25:52 step 1: mse=147.936422 step=0.100000
2017/08/29 11:25:53 step 2: mse=145.544346 step=0.100000
2017/08/29 11:25:55 step 3: mse=143.097813 step=0.100000
2017/08/29 11:25:56 step 4: mse=141.529747 step=0.100000
2017/08/29 11:25:57 step 5: mse=139.892826 step=0.100000
2017/08/29 11:25:58 step 6: mse=138.673475 step=0.100000
2017/08/29 11:26:00 step 7: mse=137.246278 step=0.100000
2017/08/29 11:26:00 Saving...
2017/08/29 11:26:00 Gathering batch of experience...
2017/08/29 11:26:42 batch 14: mean=262.769231 stddev=180.152138 entropy=0.288745 frames=6248 count=26
2017/08/29 11:26:42 Training policy...
2017/08/29 11:26:48 tune 0: objective=1.133738 reg=0.002887 prune=0
2017/08/29 11:26:52 tune 1: objective=1.137385 reg=0.002887 prune=0
2017/08/29 11:26:55 tune 2: objective=1.140986 reg=0.002887 prune=0
2017/08/29 11:26:59 tune 3: objective=1.144542 reg=0.002886 prune=0
2017/08/29 11:27:02 tune 4: objective=1.147984 reg=0.002886 prune=0
2017/08/29 11:27:05 tune 5: objective=1.151105 reg=0.002886 prune=0
2017/08/29 11:27:09 tune 6: objective=1.154077 reg=0.002886 prune=0
2017/08/29 11:27:12 tune 7: objective=1.156972 reg=0.002885 prune=0
2017/08/29 11:27:15 step 0: objective=1.159673 reg=0.002885
2017/08/29 11:27:17 step 1: objective=1.161901 reg=0.002886
2017/08/29 11:27:19 step 2: objective=1.165495 reg=0.002885
2017/08/29 11:27:21 step 3: objective=1.168301 reg=0.002885
2017/08/29 11:27:23 step 4: objective=1.169643 reg=0.002885
2017/08/29 11:27:25 step 5: objective=1.171043 reg=0.002885
2017/08/29 11:27:28 step 6: objective=1.172386 reg=0.002885
2017/08/29 11:27:30 step 7: objective=1.174098 reg=0.002885
2017/08/29 11:27:30 Training value function...
2017/08/29 11:27:32 step 0: mse=136.866900 step=0.100000
2017/08/29 11:27:34 step 1: mse=134.075688 step=0.100000
2017/08/29 11:27:35 step 2: mse=131.804402 step=0.100000
2017/08/29 11:27:36 step 3: mse=129.688887 step=0.100000
2017/08/29 11:27:38 step 4: mse=128.035864 step=0.100000
2017/08/29 11:27:39 step 5: mse=126.549760 step=0.100000
2017/08/29 11:27:40 step 6: mse=125.071679 step=0.100000
2017/08/29 11:27:42 step 7: mse=123.756681 step=0.100000
2017/08/29 11:27:42 Saving...
2017/08/29 11:27:42 Gathering batch of experience...
2017/08/29 11:28:26 batch 15: mean=246.321429 stddev=173.118055 entropy=0.288944 frames=6468 count=28
2017/08/29 11:28:26 Training policy...
2017/08/29 11:28:32 tune 0: objective=0.754051 reg=0.002889 prune=0
2017/08/29 11:28:36 tune 1: objective=0.757838 reg=0.002889 prune=0
2017/08/29 11:28:39 tune 2: objective=0.761606 reg=0.002889 prune=0
2017/08/29 11:28:43 tune 3: objective=0.765357 reg=0.002889 prune=0
2017/08/29 11:28:46 tune 4: objective=0.768927 reg=0.002890 prune=0
2017/08/29 11:28:50 tune 5: objective=0.772137 reg=0.002889 prune=0
2017/08/29 11:28:54 tune 6: objective=0.775138 reg=0.002889 prune=0
2017/08/29 11:28:57 tune 7: objective=0.777904 reg=0.002889 prune=0
2017/08/29 11:28:59 step 0: objective=0.780433 reg=0.002889
2017/08/29 11:29:02 step 1: objective=0.782759 reg=0.002890
2017/08/29 11:29:04 step 2: objective=0.785300 reg=0.002890
2017/08/29 11:29:06 step 3: objective=0.786913 reg=0.002891
2017/08/29 11:29:09 step 4: objective=0.788232 reg=0.002891
2017/08/29 11:29:11 step 5: objective=0.789589 reg=0.002891
2017/08/29 11:29:13 step 6: objective=0.793848 reg=0.002892
2017/08/29 11:29:15 step 7: objective=0.795328 reg=0.002892
2017/08/29 11:29:15 Training value function...
2017/08/29 11:29:18 step 0: mse=146.663958 step=0.100000
2017/08/29 11:29:19 step 1: mse=144.699383 step=0.100000
2017/08/29 11:29:21 step 2: mse=143.272959 step=0.100000
2017/08/29 11:29:22 step 3: mse=142.097503 step=0.100000
2017/08/29 11:29:24 step 4: mse=140.600566 step=0.100000
2017/08/29 11:29:25 step 5: mse=139.556312 step=0.100000
2017/08/29 11:29:26 step 6: mse=138.757003 step=0.100000
2017/08/29 11:29:28 step 7: mse=137.883136 step=0.100000
2017/08/29 11:29:28 Saving...
2017/08/29 11:29:28 Gathering batch of experience...
2017/08/29 11:30:16 batch 16: mean=238.344828 stddev=191.404478 entropy=0.288016 frames=6515 count=29
2017/08/29 11:30:16 Training policy...
2017/08/29 11:30:22 tune 0: objective=0.958684 reg=0.002880 prune=0
2017/08/29 11:30:26 tune 1: objective=0.962976 reg=0.002879 prune=0
2017/08/29 11:30:30 tune 2: objective=0.967196 reg=0.002878 prune=0
2017/08/29 11:30:33 tune 3: objective=0.971342 reg=0.002877 prune=0
2017/08/29 11:30:37 tune 4: objective=0.975323 reg=0.002876 prune=0
2017/08/29 11:30:41 tune 5: objective=0.978750 reg=0.002876 prune=0
2017/08/29 11:30:44 tune 6: objective=0.981686 reg=0.002875 prune=0
2017/08/29 11:30:48 tune 7: objective=0.984442 reg=0.002874 prune=0
2017/08/29 11:30:50 step 0: objective=0.986979 reg=0.002873
2017/08/29 11:30:52 step 1: objective=0.989691 reg=0.002873
2017/08/29 11:30:55 step 2: objective=0.992282 reg=0.002874
2017/08/29 11:30:57 step 3: objective=0.993752 reg=0.002874
2017/08/29 11:30:59 step 4: objective=0.997155 reg=0.002873
2017/08/29 11:31:01 step 5: objective=0.998911 reg=0.002872
2017/08/29 11:31:04 step 6: objective=1.001206 reg=0.002873
2017/08/29 11:31:06 step 7: objective=1.002436 reg=0.002871
2017/08/29 11:31:06 Training value function...
2017/08/29 11:31:09 step 0: mse=137.937202 step=0.100000
2017/08/29 11:31:10 step 1: mse=136.454053 step=0.100000
2017/08/29 11:31:11 step 2: mse=134.846401 step=0.100000
2017/08/29 11:31:13 step 3: mse=133.434164 step=0.100000
2017/08/29 11:31:14 step 4: mse=132.156403 step=0.100000
2017/08/29 11:31:16 step 5: mse=131.341124 step=0.100000
2017/08/29 11:31:17 step 6: mse=130.425539 step=0.100000
2017/08/29 11:31:18 step 7: mse=129.727794 step=0.100000
2017/08/29 11:31:18 Saving...
2017/08/29 11:31:19 Gathering batch of experience...
2017/08/29 11:32:05 batch 17: mean=300.291667 stddev=222.689335 entropy=0.288314 frames=6750 count=24
2017/08/29 11:32:05 Training policy...
2017/08/29 11:32:11 tune 0: objective=1.573340 reg=0.002883 prune=0
2017/08/29 11:32:15 tune 1: objective=1.577062 reg=0.002882 prune=0
2017/08/29 11:32:19 tune 2: objective=1.580752 reg=0.002881 prune=0
2017/08/29 11:32:22 tune 3: objective=1.584423 reg=0.002880 prune=0
2017/08/29 11:32:26 tune 4: objective=1.587985 reg=0.002879 prune=0
2017/08/29 11:32:30 tune 5: objective=1.591111 reg=0.002878 prune=0
2017/08/29 11:32:34 tune 6: objective=1.594059 reg=0.002877 prune=0
2017/08/29 11:32:37 tune 7: objective=1.596727 reg=0.002876 prune=0
2017/08/29 11:32:40 step 0: objective=1.599096 reg=0.002876
2017/08/29 11:32:42 step 1: objective=1.601407 reg=0.002875
2017/08/29 11:32:44 step 2: objective=1.603816 reg=0.002875
2017/08/29 11:32:47 step 3: objective=1.605839 reg=0.002874
2017/08/29 11:32:49 step 4: objective=1.607790 reg=0.002873
2017/08/29 11:32:52 step 5: objective=1.609460 reg=0.002873
2017/08/29 11:32:54 step 6: objective=1.611382 reg=0.002872
2017/08/29 11:32:56 step 7: objective=1.613111 reg=0.002872
2017/08/29 11:32:56 Training value function...
2017/08/29 11:32:59 step 0: mse=157.417933 step=0.100000
2017/08/29 11:33:01 step 1: mse=154.319261 step=0.100000
2017/08/29 11:33:02 step 2: mse=151.689915 step=0.100000
2017/08/29 11:33:03 step 3: mse=149.299081 step=0.100000
2017/08/29 11:33:05 step 4: mse=147.178884 step=0.100000
2017/08/29 11:33:06 step 5: mse=145.595077 step=0.100000
2017/08/29 11:33:08 step 6: mse=144.109878 step=0.100000
2017/08/29 11:33:09 step 7: mse=142.629457 step=0.100000
2017/08/29 11:33:09 Saving...
2017/08/29 11:33:09 Gathering batch of experience...
2017/08/29 11:33:56 batch 18: mean=347.428571 stddev=195.396927 entropy=0.286587 frames=6983 count=21
2017/08/29 11:33:56 Training policy...
2017/08/29 11:34:03 tune 0: objective=1.121377 reg=0.002866 prune=0
2017/08/29 11:34:07 tune 1: objective=1.124121 reg=0.002865 prune=0
2017/08/29 11:34:11 tune 2: objective=1.126839 reg=0.002865 prune=0
2017/08/29 11:34:15 tune 3: objective=1.129546 reg=0.002865 prune=0
2017/08/29 11:34:19 tune 4: objective=1.132203 reg=0.002864 prune=0
2017/08/29 11:34:23 tune 5: objective=1.134664 reg=0.002864 prune=0
2017/08/29 11:34:27 tune 6: objective=1.136906 reg=0.002864 prune=0
2017/08/29 11:34:31 tune 7: objective=1.138997 reg=0.002864 prune=0
2017/08/29 11:34:33 step 0: objective=1.140989 reg=0.002863
2017/08/29 11:34:36 step 1: objective=1.142861 reg=0.002863
2017/08/29 11:34:38 step 2: objective=1.144453 reg=0.002863
2017/08/29 11:34:40 step 3: objective=1.145965 reg=0.002864
2017/08/29 11:34:43 step 4: objective=1.147553 reg=0.002864
2017/08/29 11:34:45 step 5: objective=1.149312 reg=0.002863
2017/08/29 11:34:48 step 6: objective=1.150650 reg=0.002862
2017/08/29 11:34:50 step 7: objective=1.152613 reg=0.002863
2017/08/29 11:34:50 Training value function...
2017/08/29 11:34:53 step 0: mse=114.988263 step=0.100000
2017/08/29 11:34:55 step 1: mse=113.103947 step=0.100000
2017/08/29 11:34:56 step 2: mse=111.547923 step=0.100000
2017/08/29 11:34:58 step 3: mse=110.327023 step=0.100000
2017/08/29 11:34:59 step 4: mse=109.158008 step=0.100000
2017/08/29 11:35:01 step 5: mse=108.240156 step=0.100000
2017/08/29 11:35:02 step 6: mse=107.571313 step=0.100000
2017/08/29 11:35:04 step 7: mse=106.950863 step=0.100000
2017/08/29 11:35:04 Saving...
2017/08/29 11:35:04 Gathering batch of experience...
2017/08/29 11:35:50 batch 19: mean=261.464286 stddev=210.413281 entropy=0.290297 frames=6805 count=28
2017/08/29 11:35:50 Training policy...
2017/08/29 11:35:57 tune 0: objective=0.997031 reg=0.002903 prune=0
2017/08/29 11:36:00 tune 1: objective=1.001414 reg=0.002903 prune=0
2017/08/29 11:36:04 tune 2: objective=1.005761 reg=0.002903 prune=0
2017/08/29 11:36:08 tune 3: objective=1.010069 reg=0.002904 prune=0
2017/08/29 11:36:12 tune 4: objective=1.014320 reg=0.002904 prune=0
2017/08/29 11:36:16 tune 5: objective=1.018359 reg=0.002904 prune=0
2017/08/29 11:36:19 tune 6: objective=1.021978 reg=0.002904 prune=0
2017/08/29 11:36:23 tune 7: objective=1.025011 reg=0.002904 prune=0
2017/08/29 11:36:26 step 0: objective=1.027582 reg=0.002904
2017/08/29 11:36:28 step 1: objective=1.030150 reg=0.002904
2017/08/29 11:36:30 step 2: objective=1.032795 reg=0.002904
2017/08/29 11:36:33 step 3: objective=1.034549 reg=0.002905
2017/08/29 11:36:35 step 4: objective=1.036368 reg=0.002904
2017/08/29 11:36:38 step 5: objective=1.038479 reg=0.002904
2017/08/29 11:36:40 step 6: objective=1.040123 reg=0.002905
2017/08/29 11:36:42 step 7: objective=1.041983 reg=0.002905
2017/08/29 11:36:42 Training value function...
2017/08/29 11:36:45 step 0: mse=145.883538 step=0.100000
2017/08/29 11:36:47 step 1: mse=144.188714 step=0.100000
2017/08/29 11:36:48 step 2: mse=142.676008 step=0.100000
2017/08/29 11:36:50 step 3: mse=141.430516 step=0.100000
2017/08/29 11:36:51 step 4: mse=140.391407 step=0.100000
2017/08/29 11:36:52 step 5: mse=139.425817 step=0.100000
2017/08/29 11:36:54 step 6: mse=138.348171 step=0.100000
2017/08/29 11:36:55 step 7: mse=137.614294 step=0.100000
2017/08/29 11:36:55 Saving...
2017/08/29 11:36:55 Gathering batch of experience...
2017/08/29 11:37:43 batch 20: mean=273.269231 stddev=202.727471 entropy=0.282062 frames=6504 count=26
2017/08/29 11:37:43 Training policy...
2017/08/29 11:37:49 tune 0: objective=1.328415 reg=0.002821 prune=0
2017/08/29 11:37:53 tune 1: objective=1.332535 reg=0.002821 prune=0
2017/08/29 11:37:56 tune 2: objective=1.336610 reg=0.002822 prune=0
2017/08/29 11:38:00 tune 3: objective=1.340647 reg=0.002822 prune=0
2017/08/29 11:38:04 tune 4: objective=1.344433 reg=0.002823 prune=0
2017/08/29 11:38:07 tune 5: objective=1.347981 reg=0.002824 prune=0
2017/08/29 11:38:11 tune 6: objective=1.351239 reg=0.002824 prune=0
2017/08/29 11:38:14 tune 7: objective=1.354142 reg=0.002825 prune=0
2017/08/29 11:38:17 step 0: objective=1.356788 reg=0.002826
2017/08/29 11:38:19 step 1: objective=1.359771 reg=0.002826
2017/08/29 11:38:21 step 2: objective=1.362607 reg=0.002827
2017/08/29 11:38:24 step 3: objective=1.365497 reg=0.002827
2017/08/29 11:38:26 step 4: objective=1.367610 reg=0.002827
2017/08/29 11:38:28 step 5: objective=1.369762 reg=0.002827
2017/08/29 11:38:31 step 6: objective=1.370952 reg=0.002827
2017/08/29 11:38:33 step 7: objective=1.372663 reg=0.002827
2017/08/29 11:38:33 Training value function...
2017/08/29 11:38:36 step 0: mse=173.705438 step=0.100000
2017/08/29 11:38:37 step 1: mse=169.408591 step=0.100000
2017/08/29 11:38:38 step 2: mse=166.586861 step=0.100000
2017/08/29 11:38:40 step 3: mse=163.488341 step=0.100000
2017/08/29 11:38:41 step 4: mse=161.060698 step=0.100000
2017/08/29 11:38:43 step 5: mse=158.793132 step=0.100000
2017/08/29 11:38:44 step 6: mse=156.915393 step=0.100000
2017/08/29 11:38:45 step 7: mse=155.280959 step=0.100000
2017/08/29 11:38:45 Saving...
2017/08/29 11:38:45 Gathering batch of experience...
2017/08/29 11:39:28 batch 21: mean=286.590909 stddev=216.100284 entropy=0.286563 frames=5589 count=22
2017/08/29 11:39:28 Training policy...
2017/08/29 11:39:33 tune 0: objective=1.630062 reg=0.002866 prune=0
2017/08/29 11:39:36 tune 1: objective=1.634261 reg=0.002864 prune=0
2017/08/29 11:39:39 tune 2: objective=1.638422 reg=0.002863 prune=0
2017/08/29 11:39:42 tune 3: objective=1.642533 reg=0.002862 prune=0
2017/08/29 11:39:46 tune 4: objective=1.646582 reg=0.002860 prune=0
2017/08/29 11:39:49 tune 5: objective=1.650371 reg=0.002859 prune=0
2017/08/29 11:39:52 tune 6: objective=1.653876 reg=0.002858 prune=0
2017/08/29 11:39:55 tune 7: objective=1.657040 reg=0.002856 prune=0
2017/08/29 11:39:57 step 0: objective=1.659807 reg=0.002855
2017/08/29 11:39:59 step 1: objective=1.662579 reg=0.002854
2017/08/29 11:40:01 step 2: objective=1.665022 reg=0.002854
2017/08/29 11:40:03 step 3: objective=1.668756 reg=0.002855
2017/08/29 11:40:05 step 4: objective=1.670469 reg=0.002854
2017/08/29 11:40:07 step 5: objective=1.671736 reg=0.002852
2017/08/29 11:40:09 step 6: objective=1.673682 reg=0.002852
2017/08/29 11:40:11 step 7: objective=1.675511 reg=0.002852
2017/08/29 11:40:11 Training value function...
2017/08/29 11:40:13 step 0: mse=168.763469 step=0.100000
2017/08/29 11:40:14 step 1: mse=165.789148 step=0.100000
2017/08/29 11:40:15 step 2: mse=163.139447 step=0.100000
2017/08/29 11:40:16 step 3: mse=160.766855 step=0.100000
2017/08/29 11:40:18 step 4: mse=158.562206 step=0.100000
2017/08/29 11:40:19 step 5: mse=156.697158 step=0.100000
2017/08/29 11:40:20 step 6: mse=155.090443 step=0.100000
2017/08/29 11:40:21 step 7: mse=153.234704 step=0.100000
2017/08/29 11:40:21 Saving...
2017/08/29 11:40:21 Gathering batch of experience...
2017/08/29 11:41:07 batch 22: mean=234.461538 stddev=189.133699 entropy=0.287473 frames=6007 count=26
2017/08/29 11:41:07 Training policy...
2017/08/29 11:41:13 tune 0: objective=-0.187668 reg=0.002875 prune=0
2017/08/29 11:41:16 tune 1: objective=-0.183183 reg=0.002874 prune=0
2017/08/29 11:41:20 tune 2: objective=-0.178772 reg=0.002874 prune=0
2017/08/29 11:41:23 tune 3: objective=-0.174431 reg=0.002874 prune=0
2017/08/29 11:41:26 tune 4: objective=-0.170470 reg=0.002874 prune=0
2017/08/29 11:41:30 tune 5: objective=-0.167121 reg=0.002873 prune=0
2017/08/29 11:41:33 tune 6: objective=-0.164005 reg=0.002873 prune=0
2017/08/29 11:41:36 tune 7: objective=-0.161278 reg=0.002873 prune=0
2017/08/29 11:41:38 step 0: objective=-0.158636 reg=0.002873
2017/08/29 11:41:41 step 1: objective=-0.156590 reg=0.002874
2017/08/29 11:41:43 step 2: objective=-0.154505 reg=0.002873
2017/08/29 11:41:45 step 3: objective=-0.151410 reg=0.002874
2017/08/29 11:41:47 step 4: objective=-0.149945 reg=0.002874
2017/08/29 11:41:49 step 5: objective=-0.148758 reg=0.002874
2017/08/29 11:41:51 step 6: objective=-0.146688 reg=0.002874
2017/08/29 11:41:53 step 7: objective=-0.145430 reg=0.002874
2017/08/29 11:41:53 Training value function...
2017/08/29 11:41:56 step 0: mse=147.014399 step=0.100000
2017/08/29 11:41:57 step 1: mse=144.945038 step=0.100000
2017/08/29 11:41:58 step 2: mse=143.541574 step=0.100000
2017/08/29 11:42:00 step 3: mse=141.955730 step=0.100000
2017/08/29 11:42:01 step 4: mse=140.613305 step=0.100000
2017/08/29 11:42:02 step 5: mse=139.773949 step=0.100000
2017/08/29 11:42:03 step 6: mse=139.459824 step=0.100000
2017/08/29 11:42:05 step 7: mse=138.740777 step=0.100000
2017/08/29 11:42:05 Saving...
2017/08/29 11:42:05 Gathering batch of experience...
2017/08/29 11:42:50 batch 23: mean=342.210526 stddev=198.763170 entropy=0.286124 frames=6319 count=19
2017/08/29 11:42:50 Training policy...
2017/08/29 11:42:57 tune 0: objective=1.059417 reg=0.002861 prune=0
2017/08/29 11:43:00 tune 1: objective=1.062391 reg=0.002861 prune=0
2017/08/29 11:43:04 tune 2: objective=1.065341 reg=0.002861 prune=0
2017/08/29 11:43:07 tune 3: objective=1.068271 reg=0.002861 prune=0
2017/08/29 11:43:11 tune 4: objective=1.071146 reg=0.002860 prune=0
2017/08/29 11:43:14 tune 5: objective=1.073830 reg=0.002860 prune=0
2017/08/29 11:43:18 tune 6: objective=1.076186 reg=0.002860 prune=0
2017/08/29 11:43:21 tune 7: objective=1.078308 reg=0.002860 prune=0
2017/08/29 11:43:24 step 0: objective=1.080286 reg=0.002860
2017/08/29 11:43:26 step 1: objective=1.082500 reg=0.002859
2017/08/29 11:43:28 step 2: objective=1.084754 reg=0.002859
2017/08/29 11:43:30 step 3: objective=1.086665 reg=0.002858
2017/08/29 11:43:32 step 4: objective=1.089401 reg=0.002858
2017/08/29 11:43:35 step 5: objective=1.090930 reg=0.002857
2017/08/29 11:43:37 step 6: objective=1.092043 reg=0.002857
2017/08/29 11:43:39 step 7: objective=1.093574 reg=0.002857
2017/08/29 11:43:39 Training value function...
2017/08/29 11:43:42 step 0: mse=131.864440 step=0.100000
2017/08/29 11:43:43 step 1: mse=129.689718 step=0.100000
2017/08/29 11:43:45 step 2: mse=127.752394 step=0.100000
2017/08/29 11:43:46 step 3: mse=126.046627 step=0.100000
2017/08/29 11:43:47 step 4: mse=124.732552 step=0.100000
2017/08/29 11:43:49 step 5: mse=123.494861 step=0.100000
2017/08/29 11:43:50 step 6: mse=122.390606 step=0.100000
2017/08/29 11:43:51 step 7: mse=121.397808 step=0.100000
2017/08/29 11:43:51 Saving...
2017/08/29 11:43:51 Gathering batch of experience...
2017/08/29 11:44:47 batch 24: mean=269.900000 stddev=205.402264 entropy=0.290742 frames=7597 count=30
2017/08/29 11:44:47 Training policy...
2017/08/29 11:44:54 tune 0: objective=1.150631 reg=0.002907 prune=0
2017/08/29 11:44:58 tune 1: objective=1.154200 reg=0.002907 prune=0
2017/08/29 11:45:03 tune 2: objective=1.157730 reg=0.002907 prune=0
2017/08/29 11:45:07 tune 3: objective=1.161226 reg=0.002906 prune=0
2017/08/29 11:45:11 tune 4: objective=1.164679 reg=0.002906 prune=0
2017/08/29 11:45:15 tune 5: objective=1.167881 reg=0.002906 prune=0
2017/08/29 11:45:20 tune 6: objective=1.170736 reg=0.002905 prune=0
2017/08/29 11:45:24 tune 7: objective=1.173260 reg=0.002905 prune=0
2017/08/29 11:45:27 step 0: objective=1.175678 reg=0.002904
2017/08/29 11:45:29 step 1: objective=1.178526 reg=0.002903
2017/08/29 11:45:32 step 2: objective=1.181122 reg=0.002902
2017/08/29 11:45:35 step 3: objective=1.184588 reg=0.002902
2017/08/29 11:45:38 step 4: objective=1.186491 reg=0.002901
2017/08/29 11:45:40 step 5: objective=1.189189 reg=0.002900
2017/08/29 11:45:43 step 6: objective=1.190881 reg=0.002899
2017/08/29 11:45:46 step 7: objective=1.192326 reg=0.002899
2017/08/29 11:45:46 Training value function...
2017/08/29 11:45:49 step 0: mse=148.928794 step=0.100000
2017/08/29 11:45:50 step 1: mse=147.398889 step=0.100000
2017/08/29 11:45:52 step 2: mse=145.905090 step=0.100000
2017/08/29 11:45:54 step 3: mse=144.729129 step=0.100000
2017/08/29 11:45:55 step 4: mse=143.542224 step=0.100000
2017/08/29 11:45:57 step 5: mse=142.553836 step=0.100000
2017/08/29 11:45:59 step 6: mse=141.531768 step=0.100000
2017/08/29 11:46:00 step 7: mse=140.600810 step=0.100000
2017/08/29 11:46:00 Saving...
2017/08/29 11:46:00 Gathering batch of experience...
2017/08/29 11:46:51 batch 25: mean=296.730769 stddev=195.681758 entropy=0.289508 frames=7181 count=26
2017/08/29 11:46:51 Training policy...
2017/08/29 11:46:58 tune 0: objective=1.282947 reg=0.002895 prune=0
2017/08/29 11:47:02 tune 1: objective=1.286164 reg=0.002894 prune=0
2017/08/29 11:47:06 tune 2: objective=1.289350 reg=0.002893 prune=0
2017/08/29 11:47:10 tune 3: objective=1.292500 reg=0.002892 prune=0
2017/08/29 11:47:14 tune 4: objective=1.295624 reg=0.002891 prune=0
2017/08/29 11:47:18 tune 5: objective=1.298621 reg=0.002890 prune=0
2017/08/29 11:47:22 tune 6: objective=1.301452 reg=0.002889 prune=0
2017/08/29 11:47:26 tune 7: objective=1.304097 reg=0.002889 prune=0
2017/08/29 11:47:29 step 0: objective=1.306392 reg=0.002888
2017/08/29 11:47:31 step 1: objective=1.309980 reg=0.002887
2017/08/29 11:47:34 step 2: objective=1.312753 reg=0.002887
2017/08/29 11:47:36 step 3: objective=1.314386 reg=0.002886
2017/08/29 11:47:39 step 4: objective=1.316225 reg=0.002886
2017/08/29 11:47:41 step 5: objective=1.317803 reg=0.002886
2017/08/29 11:47:44 step 6: objective=1.319441 reg=0.002886
2017/08/29 11:47:46 step 7: objective=1.321270 reg=0.002886
2017/08/29 11:47:46 Training value function...
2017/08/29 11:47:49 step 0: mse=144.710336 step=0.100000
2017/08/29 11:47:51 step 1: mse=141.486209 step=0.100000
2017/08/29 11:47:52 step 2: mse=138.818583 step=0.100000
2017/08/29 11:47:54 step 3: mse=136.619461 step=0.100000
2017/08/29 11:47:56 step 4: mse=134.462869 step=0.100000
2017/08/29 11:47:57 step 5: mse=132.786296 step=0.100000
2017/08/29 11:47:59 step 6: mse=131.390430 step=0.100000
2017/08/29 11:48:00 step 7: mse=129.969725 step=0.100000
2017/08/29 11:48:00 Saving...
2017/08/29 11:48:00 Gathering batch of experience...
2017/08/29 11:48:49 batch 26: mean=282.680000 stddev=193.200356 entropy=0.286736 frames=6550 count=25
2017/08/29 11:48:49 Training policy...
2017/08/29 11:48:55 tune 0: objective=1.102611 reg=0.002867 prune=0
2017/08/29 11:48:59 tune 1: objective=1.106168 reg=0.002867 prune=0
2017/08/29 11:49:03 tune 2: objective=1.109689 reg=0.002866 prune=0
2017/08/29 11:49:06 tune 3: objective=1.113174 reg=0.002866 prune=0
2017/08/29 11:49:10 tune 4: objective=1.116572 reg=0.002865 prune=0
2017/08/29 11:49:14 tune 5: objective=1.119810 reg=0.002865 prune=0
2017/08/29 11:49:17 tune 6: objective=1.122669 reg=0.002865 prune=0
2017/08/29 11:49:21 tune 7: objective=1.125249 reg=0.002865 prune=0
2017/08/29 11:49:23 step 0: objective=1.127540 reg=0.002865
2017/08/29 11:49:26 step 1: objective=1.129941 reg=0.002865
2017/08/29 11:49:28 step 2: objective=1.132525 reg=0.002865
2017/08/29 11:49:30 step 3: objective=1.134112 reg=0.002866
2017/08/29 11:49:33 step 4: objective=1.136213 reg=0.002866
2017/08/29 11:49:35 step 5: objective=1.138288 reg=0.002866
2017/08/29 11:49:37 step 6: objective=1.139747 reg=0.002866
2017/08/29 11:49:40 step 7: objective=1.141135 reg=0.002867
2017/08/29 11:49:40 Training value function...
2017/08/29 11:49:42 step 0: mse=149.074334 step=0.100000
2017/08/29 11:49:44 step 1: mse=147.866966 step=0.100000
2017/08/29 11:49:45 step 2: mse=146.515559 step=0.100000
2017/08/29 11:49:46 step 3: mse=145.342773 step=0.100000
2017/08/29 11:49:48 step 4: mse=144.428907 step=0.100000
2017/08/29 11:49:49 step 5: mse=143.590072 step=0.100000
2017/08/29 11:49:51 step 6: mse=142.523460 step=0.100000
2017/08/29 11:49:52 step 7: mse=141.488819 step=0.100000
2017/08/29 11:49:52 Saving...
2017/08/29 11:49:52 Gathering batch of experience...
2017/08/29 11:50:41 batch 27: mean=294.920000 stddev=194.303458 entropy=0.284478 frames=6709 count=25
2017/08/29 11:50:41 Training policy...
2017/08/29 11:50:48 tune 0: objective=1.384886 reg=0.002845 prune=0
2017/08/29 11:50:51 tune 1: objective=1.388685 reg=0.002844 prune=0
2017/08/29 11:50:55 tune 2: objective=1.392453 reg=0.002843 prune=0
2017/08/29 11:50:59 tune 3: objective=1.396197 reg=0.002842 prune=0
2017/08/29 11:51:03 tune 4: objective=1.399909 reg=0.002841 prune=0
2017/08/29 11:51:06 tune 5: objective=1.403416 reg=0.002840 prune=0
2017/08/29 11:51:10 tune 6: objective=1.406502 reg=0.002839 prune=0
2017/08/29 11:51:14 tune 7: objective=1.409294 reg=0.002838 prune=0
2017/08/29 11:51:16 step 0: objective=1.411839 reg=0.002838
2017/08/29 11:51:19 step 1: objective=1.413944 reg=0.002838
2017/08/29 11:51:21 step 2: objective=1.416445 reg=0.002837
2017/08/29 11:51:23 step 3: objective=1.419524 reg=0.002836
2017/08/29 11:51:26 step 4: objective=1.421696 reg=0.002835
2017/08/29 11:51:28 step 5: objective=1.423430 reg=0.002835
2017/08/29 11:51:31 step 6: objective=1.425967 reg=0.002835
2017/08/29 11:51:33 step 7: objective=1.427189 reg=0.002835
2017/08/29 11:51:33 Training value function...
2017/08/29 11:51:36 step 0: mse=150.738126 step=0.100000
2017/08/29 11:51:37 step 1: mse=149.256623 step=0.100000
2017/08/29 11:51:39 step 2: mse=147.623114 step=0.100000
2017/08/29 11:51:40 step 3: mse=146.252174 step=0.100000
2017/08/29 11:51:41 step 4: mse=145.057103 step=0.100000
2017/08/29 11:51:43 step 5: mse=144.085792 step=0.100000
2017/08/29 11:51:44 step 6: mse=142.864339 step=0.100000
2017/08/29 11:51:46 step 7: mse=141.927072 step=0.100000
2017/08/29 11:51:46 Saving...
2017/08/29 11:51:46 Gathering batch of experience...
2017/08/29 11:52:33 batch 28: mean=217.250000 stddev=146.447730 entropy=0.278837 frames=6875 count=32
2017/08/29 11:52:33 Training policy...
2017/08/29 11:52:40 tune 0: objective=-0.366367 reg=0.002788 prune=0
2017/08/29 11:52:44 tune 1: objective=-0.362718 reg=0.002788 prune=0
2017/08/29 11:52:48 tune 2: objective=-0.359130 reg=0.002787 prune=0
2017/08/29 11:52:52 tune 3: objective=-0.355601 reg=0.002787 prune=0
2017/08/29 11:52:56 tune 4: objective=-0.352184 reg=0.002786 prune=0
2017/08/29 11:53:00 tune 5: objective=-0.349007 reg=0.002785 prune=0
2017/08/29 11:53:03 tune 6: objective=-0.346178 reg=0.002785 prune=0
2017/08/29 11:53:07 tune 7: objective=-0.343781 reg=0.002785 prune=0
2017/08/29 11:53:10 step 0: objective=-0.341524 reg=0.002784
2017/08/29 11:53:12 step 1: objective=-0.339545 reg=0.002785
2017/08/29 11:53:15 step 2: objective=-0.336213 reg=0.002786
2017/08/29 11:53:17 step 3: objective=-0.334148 reg=0.002786
2017/08/29 11:53:20 step 4: objective=-0.332238 reg=0.002787
2017/08/29 11:53:22 step 5: objective=-0.330494 reg=0.002787
2017/08/29 11:53:24 step 6: objective=-0.329364 reg=0.002787
2017/08/29 11:53:27 step 7: objective=-0.327537 reg=0.002787
2017/08/29 11:53:27 Training value function...
2017/08/29 11:53:30 step 0: mse=124.179944 step=0.100000
2017/08/29 11:53:31 step 1: mse=122.791697 step=0.100000
2017/08/29 11:53:33 step 2: mse=121.855309 step=0.100000
2017/08/29 11:53:34 step 3: mse=121.193437 step=0.100000
2017/08/29 11:53:36 step 4: mse=120.734647 step=0.100000
2017/08/29 11:53:37 step 5: mse=120.292199 step=0.100000
2017/08/29 11:53:38 step 6: mse=120.315091 step=0.100000
2017/08/29 11:53:40 step 7: mse=120.147399 step=0.100000
2017/08/29 11:53:40 Saving...
2017/08/29 11:53:40 Gathering batch of experience...
2017/08/29 11:54:25 batch 29: mean=224.166667 stddev=192.768615 entropy=0.288686 frames=6453 count=30
2017/08/29 11:54:25 Training policy...
2017/08/29 11:54:32 tune 0: objective=1.172009 reg=0.002887 prune=0
2017/08/29 11:54:35 tune 1: objective=1.176008 reg=0.002886 prune=0
2017/08/29 11:54:39 tune 2: objective=1.179929 reg=0.002885 prune=0
2017/08/29 11:54:43 tune 3: objective=1.183625 reg=0.002884 prune=0
2017/08/29 11:54:46 tune 4: objective=1.187071 reg=0.002883 prune=0
2017/08/29 11:54:50 tune 5: objective=1.190330 reg=0.002882 prune=0
2017/08/29 11:54:54 tune 6: objective=1.193361 reg=0.002881 prune=0
2017/08/29 11:54:57 tune 7: objective=1.196061 reg=0.002881 prune=0
2017/08/29 11:55:00 step 0: objective=1.198602 reg=0.002880
2017/08/29 11:55:02 step 1: objective=1.200521 reg=0.002880
2017/08/29 11:55:04 step 2: objective=1.202465 reg=0.002880
2017/08/29 11:55:06 step 3: objective=1.204645 reg=0.002880
2017/08/29 11:55:09 step 4: objective=1.207562 reg=0.002881
2017/08/29 11:55:11 step 5: objective=1.209866 reg=0.002880
2017/08/29 11:55:13 step 6: objective=1.211129 reg=0.002880
2017/08/29 11:55:16 step 7: objective=1.212315 reg=0.002880
2017/08/29 11:55:16 Training value function...
2017/08/29 11:55:18 step 0: mse=156.309446 step=0.100000
2017/08/29 11:55:20 step 1: mse=154.862584 step=0.100000
2017/08/29 11:55:21 step 2: mse=153.580921 step=0.100000
2017/08/29 11:55:22 step 3: mse=152.249989 step=0.100000
2017/08/29 11:55:24 step 4: mse=151.020561 step=0.100000
2017/08/29 11:55:25 step 5: mse=149.851071 step=0.100000
2017/08/29 11:55:27 step 6: mse=149.050850 step=0.100000
2017/08/29 11:55:28 step 7: mse=148.085577 step=0.100000
2017/08/29 11:55:28 Saving...
2017/08/29 11:55:28 Gathering batch of experience...
2017/08/29 11:56:13 batch 30: mean=261.035714 stddev=215.111015 entropy=0.287110 frames=6478 count=28
2017/08/29 11:56:13 Training policy...
2017/08/29 11:56:20 tune 0: objective=2.290415 reg=0.002871 prune=0
2017/08/29 11:56:23 tune 1: objective=2.294575 reg=0.002870 prune=0
2017/08/29 11:56:27 tune 2: objective=2.298719 reg=0.002870 prune=0
2017/08/29 11:56:31 tune 3: objective=2.302850 reg=0.002869 prune=0
2017/08/29 11:56:34 tune 4: objective=2.306959 reg=0.002868 prune=0
2017/08/29 11:56:38 tune 5: objective=2.310871 reg=0.002868 prune=0
2017/08/29 11:56:42 tune 6: objective=2.314597 reg=0.002867 prune=0
2017/08/29 11:56:45 tune 7: objective=2.317768 reg=0.002867 prune=0
2017/08/29 11:56:48 step 0: objective=2.320722 reg=0.002866
2017/08/29 11:56:50 step 1: objective=2.322831 reg=0.002866
2017/08/29 11:56:52 step 2: objective=2.324794 reg=0.002866
2017/08/29 11:56:55 step 3: objective=2.327245 reg=0.002866
2017/08/29 11:56:57 step 4: objective=2.330405 reg=0.002866
2017/08/29 11:56:59 step 5: objective=2.332924 reg=0.002865
2017/08/29 11:57:01 step 6: objective=2.334402 reg=0.002865
2017/08/29 11:57:04 step 7: objective=2.337030 reg=0.002864
2017/08/29 11:57:04 Training value function...
2017/08/29 11:57:06 step 0: mse=196.040056 step=0.100000
2017/08/29 11:57:08 step 1: mse=190.485343 step=0.100000
2017/08/29 11:57:09 step 2: mse=185.088493 step=0.100000
2017/08/29 11:57:11 step 3: mse=180.904167 step=0.100000
2017/08/29 11:57:12 step 4: mse=177.178853 step=0.100000
2017/08/29 11:57:13 step 5: mse=173.826824 step=0.100000
2017/08/29 11:57:15 step 6: mse=171.145573 step=0.100000
2017/08/29 11:57:16 step 7: mse=168.965509 step=0.100000
2017/08/29 11:57:16 Saving...
2017/08/29 11:57:16 Gathering batch of experience...
2017/08/29 11:58:08 batch 31: mean=319.840000 stddev=220.130812 entropy=0.284527 frames=7659 count=25
2017/08/29 11:58:08 Training policy...
2017/08/29 11:58:16 tune 0: objective=1.033652 reg=0.002845 prune=0
2017/08/29 11:58:20 tune 1: objective=1.036222 reg=0.002845 prune=0
2017/08/29 11:58:25 tune 2: objective=1.038776 reg=0.002845 prune=0
2017/08/29 11:58:29 tune 3: objective=1.041323 reg=0.002845 prune=0
2017/08/29 11:58:33 tune 4: objective=1.043853 reg=0.002845 prune=0
2017/08/29 11:58:38 tune 5: objective=1.046374 reg=0.002845 prune=0
2017/08/29 11:58:42 tune 6: objective=1.048887 reg=0.002845 prune=0
2017/08/29 11:58:46 tune 7: objective=1.051281 reg=0.002845 prune=0
2017/08/29 11:58:49 step 0: objective=1.053581 reg=0.002845
2017/08/29 11:58:52 step 1: objective=1.055709 reg=0.002845
2017/08/29 11:58:55 step 2: objective=1.058947 reg=0.002845
2017/08/29 11:58:57 step 3: objective=1.060132 reg=0.002845
2017/08/29 11:59:00 step 4: objective=1.063095 reg=0.002844
2017/08/29 11:59:03 step 5: objective=1.065334 reg=0.002844
2017/08/29 11:59:05 step 6: objective=1.066224 reg=0.002845
2017/08/29 11:59:08 step 7: objective=1.067705 reg=0.002845
2017/08/29 11:59:08 Training value function...
2017/08/29 11:59:11 step 0: mse=143.755325 step=0.100000
2017/08/29 11:59:13 step 1: mse=142.193139 step=0.100000
2017/08/29 11:59:15 step 2: mse=140.794356 step=0.100000
2017/08/29 11:59:16 step 3: mse=139.766538 step=0.100000
2017/08/29 11:59:18 step 4: mse=138.864251 step=0.100000
2017/08/29 11:59:20 step 5: mse=137.894873 step=0.100000
2017/08/29 11:59:21 step 6: mse=137.152662 step=0.100000
2017/08/29 11:59:23 step 7: mse=136.297964 step=0.100000
2017/08/29 11:59:23 Saving...
2017/08/29 11:59:23 Gathering batch of experience...
2017/08/29 12:00:16 batch 32: mean=382.714286 stddev=235.527805 entropy=0.284075 frames=7486 count=21
2017/08/29 12:00:16 Training policy...
2017/08/29 12:00:23 tune 0: objective=1.654374 reg=0.002841 prune=0
2017/08/29 12:00:28 tune 1: objective=1.656627 reg=0.002841 prune=0
2017/08/29 12:00:32 tune 2: objective=1.658868 reg=0.002840 prune=0
2017/08/29 12:00:36 tune 3: objective=1.661102 reg=0.002840 prune=0
2017/08/29 12:00:40 tune 4: objective=1.663325 reg=0.002840 prune=0
2017/08/29 12:00:45 tune 5: objective=1.665526 reg=0.002840 prune=0
2017/08/29 12:00:49 tune 6: objective=1.667677 reg=0.002840 prune=0
2017/08/29 12:00:53 tune 7: objective=1.669721 reg=0.002840 prune=0
2017/08/29 12:00:56 step 0: objective=1.671667 reg=0.002840
2017/08/29 12:00:58 step 1: objective=1.673889 reg=0.002840
2017/08/29 12:01:01 step 2: objective=1.676578 reg=0.002839
2017/08/29 12:01:04 step 3: objective=1.678665 reg=0.002839
2017/08/29 12:01:06 step 4: objective=1.680079 reg=0.002839
2017/08/29 12:01:09 step 5: objective=1.681878 reg=0.002839
2017/08/29 12:01:12 step 6: objective=1.683079 reg=0.002840
2017/08/29 12:01:14 step 7: objective=1.684046 reg=0.002840
2017/08/29 12:01:14 Training value function...
2017/08/29 12:01:18 step 0: mse=156.653051 step=0.100000
2017/08/29 12:01:19 step 1: mse=152.523810 step=0.100000
2017/08/29 12:01:21 step 2: mse=149.428941 step=0.100000
2017/08/29 12:01:22 step 3: mse=146.863104 step=0.100000
2017/08/29 12:01:24 step 4: mse=144.280970 step=0.100000
2017/08/29 12:01:26 step 5: mse=141.960924 step=0.100000
2017/08/29 12:01:27 step 6: mse=140.180788 step=0.100000
2017/08/29 12:01:29 step 7: mse=138.537474 step=0.100000
2017/08/29 12:01:29 Saving...
2017/08/29 12:01:29 Gathering batch of experience...
2017/08/29 12:02:16 batch 33: mean=272.080000 stddev=212.242865 entropy=0.282967 frames=6444 count=25
2017/08/29 12:02:16 Training policy...
2017/08/29 12:02:22 tune 0: objective=0.594833 reg=0.002830 prune=0
2017/08/29 12:02:25 tune 1: objective=0.598448 reg=0.002830 prune=0
2017/08/29 12:02:29 tune 2: objective=0.602015 reg=0.002829 prune=0
2017/08/29 12:02:33 tune 3: objective=0.605530 reg=0.002829 prune=0
2017/08/29 12:02:36 tune 4: objective=0.608923 reg=0.002829 prune=0
2017/08/29 12:02:40 tune 5: objective=0.612002 reg=0.002829 prune=0
2017/08/29 12:02:44 tune 6: objective=0.614747 reg=0.002830 prune=0
2017/08/29 12:02:47 tune 7: objective=0.617320 reg=0.002830 prune=0
2017/08/29 12:02:50 step 0: objective=0.619728 reg=0.002830
2017/08/29 12:02:52 step 1: objective=0.622294 reg=0.002830
2017/08/29 12:02:54 step 2: objective=0.625618 reg=0.002829
2017/08/29 12:02:56 step 3: objective=0.628806 reg=0.002829
2017/08/29 12:02:59 step 4: objective=0.630150 reg=0.002828
2017/08/29 12:03:01 step 5: objective=0.631653 reg=0.002828
2017/08/29 12:03:03 step 6: objective=0.634156 reg=0.002829
2017/08/29 12:03:06 step 7: objective=0.635441 reg=0.002828
2017/08/29 12:03:06 Training value function...
2017/08/29 12:03:08 step 0: mse=145.492011 step=0.100000
2017/08/29 12:03:10 step 1: mse=142.303041 step=0.100000
2017/08/29 12:03:11 step 2: mse=139.778860 step=0.100000
2017/08/29 12:03:12 step 3: mse=137.705000 step=0.100000
2017/08/29 12:03:14 step 4: mse=136.003135 step=0.100000
2017/08/29 12:03:15 step 5: mse=134.665297 step=0.100000
2017/08/29 12:03:17 step 6: mse=133.304983 step=0.100000
2017/08/29 12:03:18 step 7: mse=132.224521 step=0.100000
2017/08/29 12:03:18 Saving...
2017/08/29 12:03:18 Gathering batch of experience...
2017/08/29 12:04:06 batch 34: mean=267.192308 stddev=191.349865 entropy=0.285355 frames=6456 count=26
2017/08/29 12:04:06 Training policy...
2017/08/29 12:04:13 tune 0: objective=1.106269 reg=0.002854 prune=0
2017/08/29 12:04:16 tune 1: objective=1.110300 reg=0.002853 prune=0
2017/08/29 12:04:20 tune 2: objective=1.114267 reg=0.002853 prune=0
2017/08/29 12:04:24 tune 3: objective=1.118164 reg=0.002852 prune=0
2017/08/29 12:04:27 tune 4: objective=1.121956 reg=0.002852 prune=0
2017/08/29 12:04:31 tune 5: objective=1.125121 reg=0.002852 prune=0
2017/08/29 12:04:35 tune 6: objective=1.127868 reg=0.002852 prune=0
2017/08/29 12:04:38 tune 7: objective=1.130239 reg=0.002851 prune=0
2017/08/29 12:04:41 step 0: objective=1.132301 reg=0.002852
2017/08/29 12:04:43 step 1: objective=1.135101 reg=0.002851
2017/08/29 12:04:45 step 2: objective=1.137260 reg=0.002851
2017/08/29 12:04:47 step 3: objective=1.138560 reg=0.002851
2017/08/29 12:04:50 step 4: objective=1.140812 reg=0.002851
2017/08/29 12:04:52 step 5: objective=1.142634 reg=0.002851
2017/08/29 12:04:54 step 6: objective=1.144077 reg=0.002852
2017/08/29 12:04:57 step 7: objective=1.145417 reg=0.002852
2017/08/29 12:04:57 Training value function...
2017/08/29 12:04:59 step 0: mse=148.026961 step=0.100000
2017/08/29 12:05:01 step 1: mse=146.036243 step=0.100000
2017/08/29 12:05:02 step 2: mse=144.286147 step=0.100000
2017/08/29 12:05:04 step 3: mse=142.833391 step=0.100000
2017/08/29 12:05:05 step 4: mse=141.718882 step=0.100000
2017/08/29 12:05:06 step 5: mse=140.672788 step=0.100000
2017/08/29 12:05:08 step 6: mse=139.726723 step=0.100000
2017/08/29 12:05:09 step 7: mse=138.940519 step=0.100000
2017/08/29 12:05:09 Saving...
2017/08/29 12:05:09 Gathering batch of experience...
2017/08/29 12:06:01 batch 35: mean=351.809524 stddev=190.688382 entropy=0.294702 frames=7108 count=21
2017/08/29 12:06:01 Training policy...
2017/08/29 12:06:08 tune 0: objective=1.014136 reg=0.002947 prune=0
2017/08/29 12:06:12 tune 1: objective=1.016819 reg=0.002947 prune=0
2017/08/29 12:06:16 tune 2: objective=1.019495 reg=0.002947 prune=0
2017/08/29 12:06:20 tune 3: objective=1.022157 reg=0.002948 prune=0
2017/08/29 12:06:24 tune 4: objective=1.024792 reg=0.002948 prune=0
2017/08/29 12:06:28 tune 5: objective=1.027329 reg=0.002948 prune=0
2017/08/29 12:06:32 tune 6: objective=1.029639 reg=0.002948 prune=0
2017/08/29 12:06:36 tune 7: objective=1.031832 reg=0.002948 prune=0
2017/08/29 12:06:38 step 0: objective=1.033918 reg=0.002948
2017/08/29 12:06:41 step 1: objective=1.035212 reg=0.002949
2017/08/29 12:06:43 step 2: objective=1.037253 reg=0.002950
2017/08/29 12:06:46 step 3: objective=1.038569 reg=0.002949
2017/08/29 12:06:48 step 4: objective=1.040519 reg=0.002950
2017/08/29 12:06:51 step 5: objective=1.042210 reg=0.002950
2017/08/29 12:06:54 step 6: objective=1.043237 reg=0.002950
2017/08/29 12:06:56 step 7: objective=1.044613 reg=0.002949
2017/08/29 12:06:56 Training value function...
2017/08/29 12:06:59 step 0: mse=117.082964 step=0.100000
2017/08/29 12:07:01 step 1: mse=116.124318 step=0.100000
2017/08/29 12:07:02 step 2: mse=115.463181 step=0.100000
2017/08/29 12:07:04 step 3: mse=114.690304 step=0.100000
2017/08/29 12:07:05 step 4: mse=113.902152 step=0.100000
2017/08/29 12:07:07 step 5: mse=113.336148 step=0.100000
2017/08/29 12:07:08 step 6: mse=112.717459 step=0.100000
2017/08/29 12:07:10 step 7: mse=112.138347 step=0.100000
2017/08/29 12:07:10 Saving...
2017/08/29 12:07:10 Gathering batch of experience...
2017/08/29 12:07:55 batch 36: mean=340.727273 stddev=188.169213 entropy=0.279593 frames=6819 count=22
2017/08/29 12:07:55 Training policy...
2017/08/29 12:08:02 tune 0: objective=1.591492 reg=0.002796 prune=0
2017/08/29 12:08:06 tune 1: objective=1.594408 reg=0.002796 prune=0
2017/08/29 12:08:10 tune 2: objective=1.597307 reg=0.002796 prune=0
2017/08/29 12:08:14 tune 3: objective=1.600191 reg=0.002796 prune=0
2017/08/29 12:08:17 tune 4: objective=1.603055 reg=0.002796 prune=0
2017/08/29 12:08:21 tune 5: objective=1.605850 reg=0.002796 prune=0
2017/08/29 12:08:25 tune 6: objective=1.608502 reg=0.002795 prune=0
2017/08/29 12:08:29 tune 7: objective=1.610860 reg=0.002795 prune=0
2017/08/29 12:08:32 step 0: objective=1.612998 reg=0.002795
2017/08/29 12:08:34 step 1: objective=1.615321 reg=0.002795
2017/08/29 12:08:36 step 2: objective=1.617321 reg=0.002795
2017/08/29 12:08:39 step 3: objective=1.618928 reg=0.002795
2017/08/29 12:08:41 step 4: objective=1.620208 reg=0.002794
2017/08/29 12:08:44 step 5: objective=1.622061 reg=0.002794
2017/08/29 12:08:46 step 6: objective=1.623801 reg=0.002794
2017/08/29 12:08:49 step 7: objective=1.625647 reg=0.002795
2017/08/29 12:08:49 Training value function...
2017/08/29 12:08:51 step 0: mse=141.840540 step=0.100000
2017/08/29 12:08:53 step 1: mse=137.390475 step=0.100000
2017/08/29 12:08:54 step 2: mse=133.919383 step=0.100000
2017/08/29 12:08:56 step 3: mse=130.848221 step=0.100000
2017/08/29 12:08:57 step 4: mse=128.468493 step=0.100000
2017/08/29 12:08:59 step 5: mse=126.262411 step=0.100000
2017/08/29 12:09:00 step 6: mse=124.444893 step=0.100000
2017/08/29 12:09:02 step 7: mse=122.842615 step=0.100000
2017/08/29 12:09:02 Saving...
2017/08/29 12:09:02 Gathering batch of experience...
2017/08/29 12:09:49 batch 37: mean=287.000000 stddev=183.909325 entropy=0.286338 frames=6731 count=25
2017/08/29 12:09:49 Training policy...
2017/08/29 12:09:55 tune 0: objective=0.584408 reg=0.002863 prune=0
2017/08/29 12:09:59 tune 1: objective=0.588388 reg=0.002863 prune=0
2017/08/29 12:10:03 tune 2: objective=0.592310 reg=0.002863 prune=0
2017/08/29 12:10:07 tune 3: objective=0.596177 reg=0.002863 prune=0
2017/08/29 12:10:11 tune 4: objective=0.599903 reg=0.002863 prune=0
2017/08/29 12:10:14 tune 5: objective=0.603332 reg=0.002864 prune=0
2017/08/29 12:10:18 tune 6: objective=0.606114 reg=0.002864 prune=0
2017/08/29 12:10:22 tune 7: objective=0.608531 reg=0.002864 prune=0
2017/08/29 12:10:24 step 0: objective=0.610753 reg=0.002864
2017/08/29 12:10:27 step 1: objective=0.613130 reg=0.002865
2017/08/29 12:10:29 step 2: objective=0.615261 reg=0.002864
2017/08/29 12:10:32 step 3: objective=0.617467 reg=0.002865
2017/08/29 12:10:34 step 4: objective=0.618942 reg=0.002865
2017/08/29 12:10:37 step 5: objective=0.621888 reg=0.002865
2017/08/29 12:10:39 step 6: objective=0.623037 reg=0.002865
2017/08/29 12:10:41 step 7: objective=0.625047 reg=0.002865
2017/08/29 12:10:41 Training value function...
2017/08/29 12:10:44 step 0: mse=131.442128 step=0.100000
2017/08/29 12:10:46 step 1: mse=129.736076 step=0.100000
2017/08/29 12:10:47 step 2: mse=128.614781 step=0.100000
2017/08/29 12:10:49 step 3: mse=127.172872 step=0.100000
2017/08/29 12:10:50 step 4: mse=126.448988 step=0.100000
2017/08/29 12:10:51 step 5: mse=125.275825 step=0.100000
2017/08/29 12:10:53 step 6: mse=124.500149 step=0.100000
2017/08/29 12:10:54 step 7: mse=123.726583 step=0.100000
2017/08/29 12:10:54 Saving...
2017/08/29 12:10:54 Gathering batch of experience...
2017/08/29 12:11:38 batch 38: mean=251.038462 stddev=161.034273 entropy=0.276298 frames=6114 count=26
2017/08/29 12:11:38 Training policy...
2017/08/29 12:11:44 tune 0: objective=0.659781 reg=0.002763 prune=0
2017/08/29 12:11:48 tune 1: objective=0.664174 reg=0.002763 prune=0
2017/08/29 12:11:51 tune 2: objective=0.668509 reg=0.002763 prune=0
2017/08/29 12:11:54 tune 3: objective=0.672774 reg=0.002762 prune=0
2017/08/29 12:11:58 tune 4: objective=0.676716 reg=0.002762 prune=0
2017/08/29 12:12:01 tune 5: objective=0.680225 reg=0.002762 prune=0
2017/08/29 12:12:05 tune 6: objective=0.683250 reg=0.002762 prune=0
2017/08/29 12:12:08 tune 7: objective=0.685962 reg=0.002763 prune=0
2017/08/29 12:12:10 step 0: objective=0.688474 reg=0.002763
2017/08/29 12:12:12 step 1: objective=0.691171 reg=0.002762
2017/08/29 12:12:14 step 2: objective=0.694716 reg=0.002761
2017/08/29 12:12:16 step 3: objective=0.696614 reg=0.002762
2017/08/29 12:12:19 step 4: objective=0.698276 reg=0.002762
2017/08/29 12:12:21 step 5: objective=0.699624 reg=0.002762
2017/08/29 12:12:23 step 6: objective=0.701345 reg=0.002763
2017/08/29 12:12:25 step 7: objective=0.704930 reg=0.002763
2017/08/29 12:12:25 Training value function...
2017/08/29 12:12:28 step 0: mse=145.619227 step=0.100000
2017/08/29 12:12:29 step 1: mse=143.695714 step=0.100000
2017/08/29 12:12:30 step 2: mse=142.068870 step=0.100000
2017/08/29 12:12:31 step 3: mse=140.245759 step=0.100000
2017/08/29 12:12:33 step 4: mse=138.841248 step=0.100000
2017/08/29 12:12:34 step 5: mse=137.784720 step=0.100000
2017/08/29 12:12:35 step 6: mse=136.688920 step=0.100000
2017/08/29 12:12:37 step 7: mse=135.624606 step=0.100000
2017/08/29 12:12:37 Saving...
2017/08/29 12:12:37 Gathering batch of experience...
2017/08/29 12:13:24 batch 39: mean=249.518519 stddev=195.777722 entropy=0.286585 frames=6549 count=27
2017/08/29 12:13:24 Training policy...
2017/08/29 12:13:30 tune 0: objective=0.655730 reg=0.002866 prune=0
2017/08/29 12:13:34 tune 1: objective=0.659424 reg=0.002866 prune=0
2017/08/29 12:13:37 tune 2: objective=0.663090 reg=0.002866 prune=0
2017/08/29 12:13:41 tune 3: objective=0.666733 reg=0.002865 prune=0
2017/08/29 12:13:44 tune 4: objective=0.670352 reg=0.002865 prune=0
2017/08/29 12:13:48 tune 5: objective=0.673846 reg=0.002865 prune=0
2017/08/29 12:13:51 tune 6: objective=0.677196 reg=0.002865 prune=0
2017/08/29 12:13:55 tune 7: objective=0.680144 reg=0.002865 prune=0
2017/08/29 12:13:57 step 0: objective=0.682819 reg=0.002865
2017/08/29 12:14:00 step 1: objective=0.687115 reg=0.002866
2017/08/29 12:14:02 step 2: objective=0.690677 reg=0.002867
2017/08/29 12:14:04 step 3: objective=0.692909 reg=0.002867
2017/08/29 12:14:06 step 4: objective=0.695991 reg=0.002866
2017/08/29 12:14:09 step 5: objective=0.697924 reg=0.002867
2017/08/29 12:14:11 step 6: objective=0.699581 reg=0.002867
2017/08/29 12:14:13 step 7: objective=0.701460 reg=0.002867
2017/08/29 12:14:13 Training value function...
2017/08/29 12:14:16 step 0: mse=144.417385 step=0.100000
2017/08/29 12:14:17 step 1: mse=142.333549 step=0.100000
2017/08/29 12:14:19 step 2: mse=140.661342 step=0.100000
2017/08/29 12:14:20 step 3: mse=139.062042 step=0.100000
2017/08/29 12:14:21 step 4: mse=137.773436 step=0.100000
2017/08/29 12:14:23 step 5: mse=136.193634 step=0.100000
2017/08/29 12:14:24 step 6: mse=135.431848 step=0.100000
2017/08/29 12:14:25 step 7: mse=134.678295 step=0.100000
2017/08/29 12:14:25 Saving...
2017/08/29 12:14:26 Gathering batch of experience...
2017/08/29 12:15:08 batch 40: mean=261.346154 stddev=174.077998 entropy=0.283987 frames=6155 count=26
2017/08/29 12:15:08 Training policy...
2017/08/29 12:15:14 tune 0: objective=1.571501 reg=0.002840 prune=0
2017/08/29 12:15:17 tune 1: objective=1.575822 reg=0.002840 prune=0
2017/08/29 12:15:20 tune 2: objective=1.580100 reg=0.002840 prune=0
2017/08/29 12:15:24 tune 3: objective=1.584339 reg=0.002840 prune=0
2017/08/29 12:15:27 tune 4: objective=1.588342 reg=0.002840 prune=0
2017/08/29 12:15:30 tune 5: objective=1.592205 reg=0.002840 prune=0
2017/08/29 12:15:33 tune 6: objective=1.595898 reg=0.002840 prune=0
2017/08/29 12:15:37 tune 7: objective=1.599211 reg=0.002840 prune=0
2017/08/29 12:15:39 step 0: objective=1.602149 reg=0.002839
2017/08/29 12:15:41 step 1: objective=1.606484 reg=0.002839
2017/08/29 12:15:43 step 2: objective=1.609528 reg=0.002839
2017/08/29 12:15:45 step 3: objective=1.612982 reg=0.002839
2017/08/29 12:15:47 step 4: objective=1.615974 reg=0.002839
2017/08/29 12:15:50 step 5: objective=1.617467 reg=0.002839
2017/08/29 12:15:52 step 6: objective=1.619084 reg=0.002839
2017/08/29 12:15:54 step 7: objective=1.621275 reg=0.002839
2017/08/29 12:15:54 Training value function...
2017/08/29 12:15:56 step 0: mse=190.095990 step=0.100000
2017/08/29 12:15:58 step 1: mse=187.786814 step=0.100000
2017/08/29 12:15:59 step 2: mse=184.899564 step=0.100000
2017/08/29 12:16:00 step 3: mse=182.048128 step=0.100000
2017/08/29 12:16:01 step 4: mse=180.395488 step=0.100000
2017/08/29 12:16:03 step 5: mse=178.540117 step=0.100000
2017/08/29 12:16:04 step 6: mse=176.600900 step=0.100000
2017/08/29 12:16:05 step 7: mse=174.912260 step=0.100000
2017/08/29 12:16:05 Saving...
2017/08/29 12:16:05 Gathering batch of experience...
2017/08/29 12:16:55 batch 41: mean=300.923077 stddev=232.054358 entropy=0.284712 frames=7106 count=26
2017/08/29 12:16:55 Training policy...
2017/08/29 12:17:02 tune 0: objective=1.743583 reg=0.002847 prune=0
2017/08/29 12:17:05 tune 1: objective=1.747380 reg=0.002847 prune=0
2017/08/29 12:17:09 tune 2: objective=1.751169 reg=0.002848 prune=0
2017/08/29 12:17:13 tune 3: objective=1.754947 reg=0.002848 prune=0
2017/08/29 12:17:17 tune 4: objective=1.758674 reg=0.002848 prune=0
2017/08/29 12:17:20 tune 5: objective=1.762232 reg=0.002848 prune=0
2017/08/29 12:17:24 tune 6: objective=1.765369 reg=0.002849 prune=0
2017/08/29 12:17:28 tune 7: objective=1.768120 reg=0.002849 prune=0
2017/08/29 12:17:30 step 0: objective=1.770683 reg=0.002849
2017/08/29 12:17:33 step 1: objective=1.772664 reg=0.002849
2017/08/29 12:17:35 step 2: objective=1.774647 reg=0.002849
2017/08/29 12:17:38 step 3: objective=1.777812 reg=0.002850
2017/08/29 12:17:40 step 4: objective=1.779398 reg=0.002849
2017/08/29 12:17:43 step 5: objective=1.780913 reg=0.002849
2017/08/29 12:17:45 step 6: objective=1.782238 reg=0.002849
2017/08/29 12:17:47 step 7: objective=1.783884 reg=0.002850
2017/08/29 12:17:47 Training value function...
2017/08/29 12:17:50 step 0: mse=190.097571 step=0.100000
2017/08/29 12:17:52 step 1: mse=184.292106 step=0.100000
2017/08/29 12:17:53 step 2: mse=178.758709 step=0.100000
2017/08/29 12:17:55 step 3: mse=173.851566 step=0.100000
2017/08/29 12:17:56 step 4: mse=169.556682 step=0.100000
2017/08/29 12:17:58 step 5: mse=166.336465 step=0.100000
2017/08/29 12:17:59 step 6: mse=163.596520 step=0.100000
2017/08/29 12:18:01 step 7: mse=161.179111 step=0.100000
2017/08/29 12:18:01 Saving...
2017/08/29 12:18:01 Gathering batch of experience...
2017/08/29 12:18:47 batch 42: mean=244.428571 stddev=145.357301 entropy=0.284767 frames=6640 count=28
2017/08/29 12:18:47 Training policy...
2017/08/29 12:18:53 tune 0: objective=0.114641 reg=0.002848 prune=0
2017/08/29 12:18:57 tune 1: objective=0.117880 reg=0.002847 prune=0
2017/08/29 12:19:00 tune 2: objective=0.121086 reg=0.002846 prune=0
2017/08/29 12:19:03 tune 3: objective=0.124259 reg=0.002846 prune=0
2017/08/29 12:19:07 tune 4: objective=0.127340 reg=0.002845 prune=0
2017/08/29 12:19:10 tune 5: objective=0.130184 reg=0.002845 prune=0
2017/08/29 12:19:14 tune 6: objective=0.132786 reg=0.002844 prune=0
2017/08/29 12:19:17 tune 7: objective=0.135205 reg=0.002844 prune=0
2017/08/29 12:19:19 step 0: objective=0.137397 reg=0.002843
2017/08/29 12:19:22 step 1: objective=0.140095 reg=0.002844
2017/08/29 12:19:24 step 2: objective=0.141851 reg=0.002843
2017/08/29 12:19:26 step 3: objective=0.143391 reg=0.002843
2017/08/29 12:19:29 step 4: objective=0.145554 reg=0.002842
2017/08/29 12:19:31 step 5: objective=0.147574 reg=0.002841
2017/08/29 12:19:33 step 6: objective=0.149188 reg=0.002841
2017/08/29 12:19:36 step 7: objective=0.150569 reg=0.002841
2017/08/29 12:19:36 Training value function...
2017/08/29 12:19:38 step 0: mse=116.337063 step=0.100000
2017/08/29 12:19:40 step 1: mse=113.415638 step=0.100000
2017/08/29 12:19:41 step 2: mse=111.082630 step=0.100000
2017/08/29 12:19:42 step 3: mse=109.292731 step=0.100000
2017/08/29 12:19:44 step 4: mse=107.681015 step=0.100000
2017/08/29 12:19:45 step 5: mse=106.609275 step=0.100000
2017/08/29 12:19:47 step 6: mse=105.683146 step=0.100000
2017/08/29 12:19:48 step 7: mse=104.984708 step=0.100000
2017/08/29 12:19:48 Saving...
2017/08/29 12:19:48 Gathering batch of experience...
2017/08/29 12:20:31 batch 43: mean=321.500000 stddev=184.222013 entropy=0.281468 frames=5987 count=20
2017/08/29 12:20:31 Training policy...
2017/08/29 12:20:36 tune 0: objective=1.706767 reg=0.002815 prune=0
2017/08/29 12:20:40 tune 1: objective=1.710623 reg=0.002814 prune=0
2017/08/29 12:20:43 tune 2: objective=1.714432 reg=0.002813 prune=0
2017/08/29 12:20:46 tune 3: objective=1.718193 reg=0.002812 prune=0
2017/08/29 12:20:49 tune 4: objective=1.721761 reg=0.002812 prune=0
2017/08/29 12:20:52 tune 5: objective=1.724792 reg=0.002811 prune=0
2017/08/29 12:20:55 tune 6: objective=1.727541 reg=0.002811 prune=0
2017/08/29 12:20:58 tune 7: objective=1.730070 reg=0.002810 prune=0
2017/08/29 12:21:00 step 0: objective=1.732328 reg=0.002810
2017/08/29 12:21:02 step 1: objective=1.734707 reg=0.002809
2017/08/29 12:21:04 step 2: objective=1.736205 reg=0.002810
2017/08/29 12:21:06 step 3: objective=1.738304 reg=0.002810
2017/08/29 12:21:08 step 4: objective=1.739921 reg=0.002810
2017/08/29 12:21:10 step 5: objective=1.742724 reg=0.002810
2017/08/29 12:21:12 step 6: objective=1.745112 reg=0.002810
2017/08/29 12:21:14 step 7: objective=1.747557 reg=0.002810
2017/08/29 12:21:14 Training value function...
2017/08/29 12:21:17 step 0: mse=149.302286 step=0.100000
2017/08/29 12:21:18 step 1: mse=144.826418 step=0.100000
2017/08/29 12:21:19 step 2: mse=141.528808 step=0.100000
2017/08/29 12:21:21 step 3: mse=138.571254 step=0.100000
2017/08/29 12:21:22 step 4: mse=135.702622 step=0.100000
2017/08/29 12:21:23 step 5: mse=133.438269 step=0.100000
2017/08/29 12:21:24 step 6: mse=131.348021 step=0.100000
2017/08/29 12:21:26 step 7: mse=129.360944 step=0.100000
2017/08/29 12:21:26 Saving...
2017/08/29 12:21:26 Gathering batch of experience...
2017/08/29 12:22:11 batch 44: mean=272.407407 stddev=205.217547 entropy=0.277155 frames=7096 count=27
2017/08/29 12:22:11 Training policy...
2017/08/29 12:22:18 tune 0: objective=0.778547 reg=0.002772 prune=0
2017/08/29 12:22:22 tune 1: objective=0.781659 reg=0.002771 prune=0
2017/08/29 12:22:25 tune 2: objective=0.784739 reg=0.002771 prune=0
2017/08/29 12:22:29 tune 3: objective=0.787795 reg=0.002770 prune=0
2017/08/29 12:22:33 tune 4: objective=0.790821 reg=0.002770 prune=0
2017/08/29 12:22:36 tune 5: objective=0.793819 reg=0.002770 prune=0
2017/08/29 12:22:40 tune 6: objective=0.796624 reg=0.002769 prune=0
2017/08/29 12:22:44 tune 7: objective=0.799206 reg=0.002769 prune=0
2017/08/29 12:22:46 step 0: objective=0.801508 reg=0.002769
2017/08/29 12:22:49 step 1: objective=0.803370 reg=0.002768
2017/08/29 12:22:51 step 2: objective=0.806149 reg=0.002768
2017/08/29 12:22:53 step 3: objective=0.808536 reg=0.002768
2017/08/29 12:22:56 step 4: objective=0.809820 reg=0.002768
2017/08/29 12:22:58 step 5: objective=0.811206 reg=0.002768
2017/08/29 12:23:01 step 6: objective=0.812790 reg=0.002767
2017/08/29 12:23:03 step 7: objective=0.814793 reg=0.002768
2017/08/29 12:23:03 Training value function...
2017/08/29 12:23:06 step 0: mse=156.887287 step=0.100000
2017/08/29 12:23:08 step 1: mse=154.991294 step=0.100000
2017/08/29 12:23:09 step 2: mse=152.762905 step=0.100000
2017/08/29 12:23:11 step 3: mse=150.926703 step=0.100000
2017/08/29 12:23:12 step 4: mse=149.644056 step=0.100000
2017/08/29 12:23:14 step 5: mse=148.177254 step=0.100000
2017/08/29 12:23:15 step 6: mse=147.416780 step=0.100000
2017/08/29 12:23:16 step 7: mse=146.452031 step=0.100000
2017/08/29 12:23:16 Saving...
2017/08/29 12:23:17 Gathering batch of experience...
2017/08/29 12:24:01 batch 45: mean=281.423077 stddev=233.312628 entropy=0.284261 frames=6786 count=26
2017/08/29 12:24:01 Training policy...
2017/08/29 12:24:08 tune 0: objective=1.373797 reg=0.002843 prune=0
2017/08/29 12:24:11 tune 1: objective=1.377116 reg=0.002842 prune=0
2017/08/29 12:24:15 tune 2: objective=1.380404 reg=0.002842 prune=0
2017/08/29 12:24:18 tune 3: objective=1.383659 reg=0.002841 prune=0
2017/08/29 12:24:22 tune 4: objective=1.386883 reg=0.002840 prune=0
2017/08/29 12:24:25 tune 5: objective=1.389791 reg=0.002840 prune=0
2017/08/29 12:24:29 tune 6: objective=1.392604 reg=0.002840 prune=0
2017/08/29 12:24:32 tune 7: objective=1.395301 reg=0.002839 prune=0
2017/08/29 12:24:34 step 0: objective=1.397769 reg=0.002839
2017/08/29 12:24:37 step 1: objective=1.400576 reg=0.002839
2017/08/29 12:24:39 step 2: objective=1.403354 reg=0.002839
2017/08/29 12:24:41 step 3: objective=1.405573 reg=0.002840
2017/08/29 12:24:44 step 4: objective=1.409315 reg=0.002840
2017/08/29 12:24:46 step 5: objective=1.410415 reg=0.002840
2017/08/29 12:24:48 step 6: objective=1.412795 reg=0.002839
2017/08/29 12:24:51 step 7: objective=1.414113 reg=0.002839
2017/08/29 12:24:51 Training value function...
2017/08/29 12:24:54 step 0: mse=160.985048 step=0.100000
2017/08/29 12:24:55 step 1: mse=157.143786 step=0.100000
2017/08/29 12:24:56 step 2: mse=153.680802 step=0.100000
2017/08/29 12:24:58 step 3: mse=151.044574 step=0.100000
2017/08/29 12:24:59 step 4: mse=148.560388 step=0.100000
2017/08/29 12:25:01 step 5: mse=146.492396 step=0.100000
2017/08/29 12:25:02 step 6: mse=144.781205 step=0.100000
2017/08/29 12:25:03 step 7: mse=143.501973 step=0.100000
2017/08/29 12:25:03 Saving...
2017/08/29 12:25:04 Gathering batch of experience...
2017/08/29 12:25:53 batch 46: mean=292.160000 stddev=149.195088 entropy=0.279350 frames=7031 count=25
2017/08/29 12:25:53 Training policy...
2017/08/29 12:26:00 tune 0: objective=0.672456 reg=0.002794 prune=0
2017/08/29 12:26:04 tune 1: objective=0.675396 reg=0.002793 prune=0
2017/08/29 12:26:07 tune 2: objective=0.678305 reg=0.002793 prune=0
2017/08/29 12:26:11 tune 3: objective=0.681181 reg=0.002792 prune=0
2017/08/29 12:26:15 tune 4: objective=0.684015 reg=0.002792 prune=0
2017/08/29 12:26:18 tune 5: objective=0.686594 reg=0.002792 prune=0
2017/08/29 12:26:22 tune 6: objective=0.689078 reg=0.002791 prune=0
2017/08/29 12:26:25 tune 7: objective=0.691394 reg=0.002791 prune=0
2017/08/29 12:26:28 step 0: objective=0.693515 reg=0.002791
2017/08/29 12:26:30 step 1: objective=0.697160 reg=0.002791
2017/08/29 12:26:33 step 2: objective=0.698777 reg=0.002790
2017/08/29 12:26:35 step 3: objective=0.700292 reg=0.002790
2017/08/29 12:26:38 step 4: objective=0.702745 reg=0.002789
2017/08/29 12:26:40 step 5: objective=0.704456 reg=0.002788
2017/08/29 12:26:42 step 6: objective=0.705613 reg=0.002788
2017/08/29 12:26:45 step 7: objective=0.707216 reg=0.002788
2017/08/29 12:26:45 Training value function...
2017/08/29 12:26:48 step 0: mse=126.804823 step=0.100000
2017/08/29 12:26:49 step 1: mse=123.884429 step=0.100000
2017/08/29 12:26:51 step 2: mse=121.369254 step=0.100000
2017/08/29 12:26:52 step 3: mse=119.517344 step=0.100000
2017/08/29 12:26:54 step 4: mse=117.866433 step=0.100000
2017/08/29 12:26:55 step 5: mse=116.589374 step=0.100000
2017/08/29 12:26:57 step 6: mse=115.484297 step=0.100000
2017/08/29 12:26:58 step 7: mse=114.541491 step=0.100000
2017/08/29 12:26:58 Saving...
2017/08/29 12:26:58 Gathering batch of experience...
2017/08/29 12:27:46 batch 47: mean=372.333333 stddev=177.022015 entropy=0.287531 frames=7545 count=21
2017/08/29 12:27:46 Training policy...
2017/08/29 12:27:53 tune 0: objective=1.374569 reg=0.002875 prune=0
2017/08/29 12:27:57 tune 1: objective=1.376842 reg=0.002875 prune=0
2017/08/29 12:28:01 tune 2: objective=1.379112 reg=0.002874 prune=0
2017/08/29 12:28:05 tune 3: objective=1.381379 reg=0.002873 prune=0
2017/08/29 12:28:08 tune 4: objective=1.383645 reg=0.002873 prune=0
2017/08/29 12:28:12 tune 5: objective=1.385853 reg=0.002872 prune=0
2017/08/29 12:28:16 tune 6: objective=1.387999 reg=0.002871 prune=0
2017/08/29 12:28:20 tune 7: objective=1.390074 reg=0.002871 prune=0
2017/08/29 12:28:23 step 0: objective=1.392046 reg=0.002870
2017/08/29 12:28:25 step 1: objective=1.394138 reg=0.002870
2017/08/29 12:28:28 step 2: objective=1.395814 reg=0.002870
2017/08/29 12:28:31 step 3: objective=1.397731 reg=0.002870
2017/08/29 12:28:33 step 4: objective=1.399983 reg=0.002870
2017/08/29 12:28:36 step 5: objective=1.401740 reg=0.002869
2017/08/29 12:28:38 step 6: objective=1.403257 reg=0.002869
2017/08/29 12:28:41 step 7: objective=1.405785 reg=0.002868
2017/08/29 12:28:41 Training value function...
2017/08/29 12:28:44 step 0: mse=130.308286 step=0.100000
2017/08/29 12:28:46 step 1: mse=128.101307 step=0.100000
2017/08/29 12:28:47 step 2: mse=126.085387 step=0.100000
2017/08/29 12:28:49 step 3: mse=124.508564 step=0.100000
2017/08/29 12:28:50 step 4: mse=123.154080 step=0.100000
2017/08/29 12:28:52 step 5: mse=121.954515 step=0.100000
2017/08/29 12:28:54 step 6: mse=120.745276 step=0.100000
2017/08/29 12:28:55 step 7: mse=119.745963 step=0.100000
2017/08/29 12:28:55 Saving...
2017/08/29 12:28:55 Gathering batch of experience...
2017/08/29 12:29:39 batch 48: mean=289.958333 stddev=204.763986 entropy=0.278777 frames=6573 count=24
2017/08/29 12:29:39 Training policy...
2017/08/29 12:29:45 tune 0: objective=1.157409 reg=0.002788 prune=0
2017/08/29 12:29:49 tune 1: objective=1.160425 reg=0.002788 prune=0
2017/08/29 12:29:52 tune 2: objective=1.163430 reg=0.002788 prune=0
2017/08/29 12:29:56 tune 3: objective=1.166420 reg=0.002788 prune=0
2017/08/29 12:29:59 tune 4: objective=1.169399 reg=0.002789 prune=0
2017/08/29 12:30:02 tune 5: objective=1.172329 reg=0.002789 prune=0
2017/08/29 12:30:06 tune 6: objective=1.175087 reg=0.002789 prune=0
2017/08/29 12:30:09 tune 7: objective=1.177647 reg=0.002790 prune=0
2017/08/29 12:30:12 step 0: objective=1.180046 reg=0.002790
2017/08/29 12:30:14 step 1: objective=1.183049 reg=0.002789
2017/08/29 12:30:16 step 2: objective=1.184922 reg=0.002790
2017/08/29 12:30:18 step 3: objective=1.186948 reg=0.002789
2017/08/29 12:30:21 step 4: objective=1.189260 reg=0.002790
2017/08/29 12:30:23 step 5: objective=1.191172 reg=0.002790
2017/08/29 12:30:25 step 6: objective=1.193043 reg=0.002790
2017/08/29 12:30:27 step 7: objective=1.194713 reg=0.002790
2017/08/29 12:30:27 Training value function...
2017/08/29 12:30:30 step 0: mse=134.363876 step=0.100000
2017/08/29 12:30:31 step 1: mse=132.882754 step=0.100000
2017/08/29 12:30:33 step 2: mse=131.765902 step=0.100000
2017/08/29 12:30:34 step 3: mse=130.942328 step=0.100000
2017/08/29 12:30:36 step 4: mse=129.964722 step=0.100000
2017/08/29 12:30:37 step 5: mse=129.259182 step=0.100000
2017/08/29 12:30:38 step 6: mse=128.322370 step=0.100000
2017/08/29 12:30:40 step 7: mse=127.654807 step=0.100000
2017/08/29 12:30:40 Saving...
2017/08/29 12:30:40 Gathering batch of experience...
2017/08/29 12:31:21 batch 49: mean=239.920000 stddev=194.176604 entropy=0.277791 frames=5642 count=25
2017/08/29 12:31:21 Training policy...
2017/08/29 12:31:26 tune 0: objective=0.627276 reg=0.002778 prune=0
2017/08/29 12:31:29 tune 1: objective=0.632166 reg=0.002778 prune=0
2017/08/29 12:31:32 tune 2: objective=0.636977 reg=0.002778 prune=0
2017/08/29 12:31:35 tune 3: objective=0.641621 reg=0.002778 prune=0
2017/08/29 12:31:38 tune 4: objective=0.645827 reg=0.002778 prune=0
2017/08/29 12:31:41 tune 5: objective=0.649828 reg=0.002777 prune=0
2017/08/29 12:31:44 tune 6: objective=0.653401 reg=0.002777 prune=0
2017/08/29 12:31:47 tune 7: objective=0.656449 reg=0.002778 prune=0
2017/08/29 12:31:48 step 0: objective=0.659234 reg=0.002777
2017/08/29 12:31:50 step 1: objective=0.661203 reg=0.002777
2017/08/29 12:31:52 step 2: objective=0.665811 reg=0.002777
2017/08/29 12:31:54 step 3: objective=0.667561 reg=0.002777
2017/08/29 12:31:56 step 4: objective=0.669999 reg=0.002776
2017/08/29 12:31:58 step 5: objective=0.671618 reg=0.002775
2017/08/29 12:32:00 step 6: objective=0.673351 reg=0.002775
2017/08/29 12:32:02 step 7: objective=0.676336 reg=0.002774
2017/08/29 12:32:02 Training value function...
2017/08/29 12:32:04 step 0: mse=170.700035 step=0.100000
2017/08/29 12:32:06 step 1: mse=165.457480 step=0.100000
2017/08/29 12:32:07 step 2: mse=162.388138 step=0.100000
2017/08/29 12:32:08 step 3: mse=159.982642 step=0.100000
2017/08/29 12:32:09 step 4: mse=157.651986 step=0.100000
2017/08/29 12:32:10 step 5: mse=155.024204 step=0.100000
2017/08/29 12:32:11 step 6: mse=153.212092 step=0.100000
2017/08/29 12:32:13 step 7: mse=151.985500 step=0.100000
2017/08/29 12:32:13 Saving...
2017/08/29 12:32:13 Gathering batch of experience...
2017/08/29 12:32:57 batch 50: mean=268.960000 stddev=186.884880 entropy=0.279240 frames=5977 count=25
2017/08/29 12:32:57 Training policy...
2017/08/29 12:33:02 tune 0: objective=1.647390 reg=0.002792 prune=0
2017/08/29 12:33:05 tune 1: objective=1.651544 reg=0.002792 prune=0
2017/08/29 12:33:08 tune 2: objective=1.655659 reg=0.002793 prune=0
2017/08/29 12:33:11 tune 3: objective=1.659743 reg=0.002793 prune=0
2017/08/29 12:33:15 tune 4: objective=1.663677 reg=0.002793 prune=0
2017/08/29 12:33:18 tune 5: objective=1.667393 reg=0.002793 prune=0
2017/08/29 12:33:21 tune 6: objective=1.670757 reg=0.002793 prune=0
2017/08/29 12:33:24 tune 7: objective=1.673773 reg=0.002793 prune=0
2017/08/29 12:33:26 step 0: objective=1.676433 reg=0.002794
2017/08/29 12:33:28 step 1: objective=1.680161 reg=0.002794
2017/08/29 12:33:30 step 2: objective=1.682848 reg=0.002795
2017/08/29 12:33:32 step 3: objective=1.684427 reg=0.002793
2017/08/29 12:33:34 step 4: objective=1.686895 reg=0.002794
2017/08/29 12:33:36 step 5: objective=1.689043 reg=0.002793
2017/08/29 12:33:38 step 6: objective=1.690137 reg=0.002793
2017/08/29 12:33:40 step 7: objective=1.692340 reg=0.002793
2017/08/29 12:33:40 Training value function...
2017/08/29 12:33:43 step 0: mse=171.160244 step=0.100000
2017/08/29 12:33:44 step 1: mse=167.013773 step=0.100000
2017/08/29 12:33:45 step 2: mse=163.592007 step=0.100000
2017/08/29 12:33:46 step 3: mse=161.137520 step=0.100000
2017/08/29 12:33:48 step 4: mse=159.067516 step=0.100000
2017/08/29 12:33:49 step 5: mse=157.105249 step=0.100000
2017/08/29 12:33:50 step 6: mse=155.518331 step=0.100000
2017/08/29 12:33:51 step 7: mse=153.955207 step=0.100000
2017/08/29 12:33:51 Saving...
2017/08/29 12:33:52 Gathering batch of experience...
2017/08/29 12:34:34 batch 51: mean=308.550000 stddev=176.454095 entropy=0.276095 frames=5954 count=20
2017/08/29 12:34:34 Training policy...
2017/08/29 12:34:39 tune 0: objective=0.632537 reg=0.002761 prune=0
2017/08/29 12:34:42 tune 1: objective=0.636116 reg=0.002760 prune=0
2017/08/29 12:34:45 tune 2: objective=0.639640 reg=0.002759 prune=0
2017/08/29 12:34:48 tune 3: objective=0.643099 reg=0.002757 prune=0
2017/08/29 12:34:51 tune 4: objective=0.646287 reg=0.002756 prune=0
2017/08/29 12:34:54 tune 5: objective=0.649121 reg=0.002755 prune=0
2017/08/29 12:34:57 tune 6: objective=0.651723 reg=0.002754 prune=0
2017/08/29 12:35:01 tune 7: objective=0.654141 reg=0.002754 prune=0
2017/08/29 12:35:03 step 0: objective=0.656424 reg=0.002753
2017/08/29 12:35:05 step 1: objective=0.658951 reg=0.002753
2017/08/29 12:35:07 step 2: objective=0.660996 reg=0.002753
2017/08/29 12:35:09 step 3: objective=0.662410 reg=0.002753
2017/08/29 12:35:11 step 4: objective=0.664233 reg=0.002753
2017/08/29 12:35:13 step 5: objective=0.665798 reg=0.002752
2017/08/29 12:35:15 step 6: objective=0.667853 reg=0.002752
2017/08/29 12:35:17 step 7: objective=0.668966 reg=0.002752
2017/08/29 12:35:17 Training value function...
2017/08/29 12:35:20 step 0: mse=131.556031 step=0.100000
2017/08/29 12:35:21 step 1: mse=129.931333 step=0.100000
2017/08/29 12:35:22 step 2: mse=128.787451 step=0.100000
2017/08/29 12:35:23 step 3: mse=127.277523 step=0.100000
2017/08/29 12:35:24 step 4: mse=126.550299 step=0.100000
2017/08/29 12:35:26 step 5: mse=125.606116 step=0.100000
2017/08/29 12:35:27 step 6: mse=125.047015 step=0.100000
2017/08/29 12:35:28 step 7: mse=124.639857 step=0.100000
2017/08/29 12:35:28 Saving...
2017/08/29 12:35:28 Gathering batch of experience...
2017/08/29 12:36:17 batch 52: mean=283.192308 stddev=175.378277 entropy=0.280203 frames=6875 count=26
2017/08/29 12:36:17 Training policy...
2017/08/29 12:36:23 tune 0: objective=1.103777 reg=0.002802 prune=0
2017/08/29 12:36:27 tune 1: objective=1.106628 reg=0.002802 prune=0
2017/08/29 12:36:30 tune 2: objective=1.109459 reg=0.002801 prune=0
2017/08/29 12:36:34 tune 3: objective=1.112273 reg=0.002801 prune=0
2017/08/29 12:36:37 tune 4: objective=1.115067 reg=0.002801 prune=0
2017/08/29 12:36:41 tune 5: objective=1.117817 reg=0.002801 prune=0
2017/08/29 12:36:45 tune 6: objective=1.120371 reg=0.002800 prune=0
2017/08/29 12:36:48 tune 7: objective=1.122869 reg=0.002800 prune=0
2017/08/29 12:36:50 step 0: objective=1.125175 reg=0.002799
2017/08/29 12:36:53 step 1: objective=1.128454 reg=0.002799
2017/08/29 12:36:55 step 2: objective=1.130016 reg=0.002800
2017/08/29 12:36:58 step 3: objective=1.134345 reg=0.002800
2017/08/29 12:37:00 step 4: objective=1.136291 reg=0.002800
2017/08/29 12:37:02 step 5: objective=1.138363 reg=0.002801
2017/08/29 12:37:05 step 6: objective=1.139499 reg=0.002801
2017/08/29 12:37:07 step 7: objective=1.141110 reg=0.002801
2017/08/29 12:37:07 Training value function...
2017/08/29 12:37:10 step 0: mse=146.170564 step=0.100000
2017/08/29 12:37:11 step 1: mse=144.190326 step=0.100000
2017/08/29 12:37:13 step 2: mse=142.636021 step=0.100000
2017/08/29 12:37:14 step 3: mse=141.289296 step=0.100000
2017/08/29 12:37:16 step 4: mse=140.012233 step=0.100000
2017/08/29 12:37:17 step 5: mse=139.079873 step=0.100000
2017/08/29 12:37:19 step 6: mse=138.161285 step=0.100000
2017/08/29 12:37:20 step 7: mse=137.225753 step=0.100000
2017/08/29 12:37:20 Saving...
2017/08/29 12:37:20 Gathering batch of experience...
2017/08/29 12:38:06 batch 53: mean=265.080000 stddev=182.905423 entropy=0.275187 frames=6577 count=25
2017/08/29 12:38:06 Training policy...
2017/08/29 12:38:12 tune 0: objective=0.358575 reg=0.002752 prune=0
2017/08/29 12:38:16 tune 1: objective=0.361312 reg=0.002751 prune=0
2017/08/29 12:38:19 tune 2: objective=0.364021 reg=0.002751 prune=0
2017/08/29 12:38:22 tune 3: objective=0.366702 reg=0.002750 prune=0
2017/08/29 12:38:26 tune 4: objective=0.369359 reg=0.002750 prune=0
2017/08/29 12:38:29 tune 5: objective=0.371957 reg=0.002750 prune=0
2017/08/29 12:38:33 tune 6: objective=0.374286 reg=0.002749 prune=0
2017/08/29 12:38:36 tune 7: objective=0.376406 reg=0.002749 prune=0
2017/08/29 12:38:38 step 0: objective=0.378391 reg=0.002749
2017/08/29 12:38:41 step 1: objective=0.380271 reg=0.002748
2017/08/29 12:38:43 step 2: objective=0.382078 reg=0.002748
2017/08/29 12:38:45 step 3: objective=0.383930 reg=0.002748
2017/08/29 12:38:48 step 4: objective=0.386078 reg=0.002748
2017/08/29 12:38:50 step 5: objective=0.387589 reg=0.002749
2017/08/29 12:38:52 step 6: objective=0.389774 reg=0.002748
2017/08/29 12:38:54 step 7: objective=0.391158 reg=0.002748
2017/08/29 12:38:54 Training value function...
2017/08/29 12:38:57 step 0: mse=126.285068 step=0.100000
2017/08/29 12:38:59 step 1: mse=125.342427 step=0.100000
2017/08/29 12:39:00 step 2: mse=124.465317 step=0.100000
2017/08/29 12:39:01 step 3: mse=123.776285 step=0.100000
2017/08/29 12:39:03 step 4: mse=123.241469 step=0.100000
2017/08/29 12:39:04 step 5: mse=122.750033 step=0.100000
2017/08/29 12:39:05 step 6: mse=122.263941 step=0.100000
2017/08/29 12:39:07 step 7: mse=121.895916 step=0.100000
2017/08/29 12:39:07 Saving...
2017/08/29 12:39:07 Gathering batch of experience...
2017/08/29 12:39:55 batch 54: mean=296.800000 stddev=217.147692 entropy=0.286552 frames=7156 count=25
2017/08/29 12:39:55 Training policy...
2017/08/29 12:40:02 tune 0: objective=1.452006 reg=0.002866 prune=0
2017/08/29 12:40:05 tune 1: objective=1.455104 reg=0.002865 prune=0
2017/08/29 12:40:09 tune 2: objective=1.458171 reg=0.002865 prune=0
2017/08/29 12:40:13 tune 3: objective=1.461209 reg=0.002864 prune=0
2017/08/29 12:40:17 tune 4: objective=1.464103 reg=0.002864 prune=0
2017/08/29 12:40:20 tune 5: objective=1.466771 reg=0.002863 prune=0
2017/08/29 12:40:24 tune 6: objective=1.469381 reg=0.002863 prune=0
2017/08/29 12:40:28 tune 7: objective=1.471902 reg=0.002862 prune=0
2017/08/29 12:40:30 step 0: objective=1.474242 reg=0.002862
2017/08/29 12:40:33 step 1: objective=1.476803 reg=0.002862
2017/08/29 12:40:35 step 2: objective=1.478143 reg=0.002863
2017/08/29 12:40:38 step 3: objective=1.480128 reg=0.002862
2017/08/29 12:40:40 step 4: objective=1.482424 reg=0.002862
2017/08/29 12:40:43 step 5: objective=1.484720 reg=0.002862
2017/08/29 12:40:45 step 6: objective=1.486605 reg=0.002862
2017/08/29 12:40:48 step 7: objective=1.488312 reg=0.002863
2017/08/29 12:40:48 Training value function...
2017/08/29 12:40:51 step 0: mse=145.159225 step=0.100000
2017/08/29 12:40:52 step 1: mse=141.639941 step=0.100000
2017/08/29 12:40:54 step 2: mse=138.245879 step=0.100000
2017/08/29 12:40:55 step 3: mse=135.360918 step=0.100000
2017/08/29 12:40:57 step 4: mse=133.261356 step=0.100000
2017/08/29 12:40:58 step 5: mse=131.234457 step=0.100000
2017/08/29 12:41:00 step 6: mse=129.595891 step=0.100000
2017/08/29 12:41:01 step 7: mse=128.180938 step=0.100000
2017/08/29 12:41:01 Saving...
2017/08/29 12:41:01 Gathering batch of experience...
2017/08/29 12:41:48 batch 55: mean=241.571429 stddev=173.917761 entropy=0.278376 frames=6600 count=28
2017/08/29 12:41:48 Training policy...
2017/08/29 12:41:54 tune 0: objective=0.593685 reg=0.002784 prune=0
2017/08/29 12:41:58 tune 1: objective=0.596577 reg=0.002783 prune=0
2017/08/29 12:42:01 tune 2: objective=0.599437 reg=0.002783 prune=0
2017/08/29 12:42:05 tune 3: objective=0.602265 reg=0.002783 prune=0
2017/08/29 12:42:08 tune 4: objective=0.605066 reg=0.002783 prune=0
2017/08/29 12:42:11 tune 5: objective=0.607839 reg=0.002783 prune=0
2017/08/29 12:42:15 tune 6: objective=0.610492 reg=0.002782 prune=0
2017/08/29 12:42:18 tune 7: objective=0.612954 reg=0.002782 prune=0
2017/08/29 12:42:21 step 0: objective=0.615177 reg=0.002782
2017/08/29 12:42:23 step 1: objective=0.618105 reg=0.002782
2017/08/29 12:42:25 step 2: objective=0.620179 reg=0.002782
2017/08/29 12:42:27 step 3: objective=0.621630 reg=0.002781
2017/08/29 12:42:30 step 4: objective=0.622924 reg=0.002781
2017/08/29 12:42:32 step 5: objective=0.624230 reg=0.002781
2017/08/29 12:42:34 step 6: objective=0.625561 reg=0.002781
2017/08/29 12:42:37 step 7: objective=0.626909 reg=0.002781
2017/08/29 12:42:37 Training value function...
2017/08/29 12:42:39 step 0: mse=124.411335 step=0.100000
2017/08/29 12:42:41 step 1: mse=123.325646 step=0.100000
2017/08/29 12:42:42 step 2: mse=122.246207 step=0.100000
2017/08/29 12:42:43 step 3: mse=121.597300 step=0.100000
2017/08/29 12:42:45 step 4: mse=121.034894 step=0.100000
2017/08/29 12:42:46 step 5: mse=120.414279 step=0.100000
2017/08/29 12:42:48 step 6: mse=119.837591 step=0.100000
2017/08/29 12:42:49 step 7: mse=119.367026 step=0.100000
2017/08/29 12:42:49 Saving...
2017/08/29 12:42:49 Gathering batch of experience...
2017/08/29 12:43:43 batch 56: mean=327.600000 stddev=218.159758 entropy=0.286921 frames=7653 count=25
2017/08/29 12:43:43 Training policy...
2017/08/29 12:43:50 tune 0: objective=1.996535 reg=0.002869 prune=0
2017/08/29 12:43:54 tune 1: objective=1.999372 reg=0.002869 prune=0
2017/08/29 12:43:58 tune 2: objective=2.002195 reg=0.002870 prune=0
2017/08/29 12:44:02 tune 3: objective=2.004998 reg=0.002870 prune=0
2017/08/29 12:44:06 tune 4: objective=2.007800 reg=0.002870 prune=0
2017/08/29 12:44:10 tune 5: objective=2.010591 reg=0.002870 prune=0
2017/08/29 12:44:14 tune 6: objective=2.013329 reg=0.002870 prune=0
2017/08/29 12:44:18 tune 7: objective=2.015856 reg=0.002870 prune=0
2017/08/29 12:44:20 step 0: objective=2.018178 reg=0.002871
2017/08/29 12:44:23 step 1: objective=2.020273 reg=0.002871
2017/08/29 12:44:26 step 2: objective=2.022742 reg=0.002870
2017/08/29 12:44:28 step 3: objective=2.025050 reg=0.002871
2017/08/29 12:44:31 step 4: objective=2.026875 reg=0.002871
2017/08/29 12:44:34 step 5: objective=2.029374 reg=0.002872
2017/08/29 12:44:36 step 6: objective=2.030931 reg=0.002872
2017/08/29 12:44:39 step 7: objective=2.033840 reg=0.002871
2017/08/29 12:44:39 Training value function...
2017/08/29 12:44:42 step 0: mse=180.164003 step=0.100000
2017/08/29 12:44:44 step 1: mse=175.639724 step=0.100000
2017/08/29 12:44:45 step 2: mse=171.696288 step=0.100000
2017/08/29 12:44:47 step 3: mse=168.361818 step=0.100000
2017/08/29 12:44:49 step 4: mse=165.359646 step=0.100000
2017/08/29 12:44:50 step 5: mse=162.960050 step=0.100000
2017/08/29 12:44:52 step 6: mse=160.578135 step=0.100000
2017/08/29 12:44:53 step 7: mse=158.594820 step=0.100000
2017/08/29 12:44:53 Saving...
2017/08/29 12:44:54 Gathering batch of experience...
2017/08/29 12:45:42 batch 57: mean=381.700000 stddev=203.669364 entropy=0.283726 frames=6990 count=20
2017/08/29 12:45:42 Training policy...
2017/08/29 12:45:48 tune 0: objective=1.851126 reg=0.002837 prune=0
2017/08/29 12:45:52 tune 1: objective=1.853694 reg=0.002837 prune=0
2017/08/29 12:45:56 tune 2: objective=1.856238 reg=0.002838 prune=0
2017/08/29 12:45:59 tune 3: objective=1.858778 reg=0.002838 prune=0
2017/08/29 12:46:03 tune 4: objective=1.861314 reg=0.002838 prune=0
2017/08/29 12:46:07 tune 5: objective=1.863752 reg=0.002838 prune=0
2017/08/29 12:46:10 tune 6: objective=1.866052 reg=0.002838 prune=0
2017/08/29 12:46:14 tune 7: objective=1.868271 reg=0.002839 prune=0
2017/08/29 12:46:16 step 0: objective=1.870445 reg=0.002839
2017/08/29 12:46:19 step 1: objective=1.873410 reg=0.002838
2017/08/29 12:46:21 step 2: objective=1.875124 reg=0.002839
2017/08/29 12:46:24 step 3: objective=1.877133 reg=0.002839
2017/08/29 12:46:26 step 4: objective=1.878540 reg=0.002838
2017/08/29 12:46:29 step 5: objective=1.879919 reg=0.002837
2017/08/29 12:46:31 step 6: objective=1.881437 reg=0.002838
2017/08/29 12:46:34 step 7: objective=1.883279 reg=0.002838
2017/08/29 12:46:34 Training value function...
2017/08/29 12:46:36 step 0: mse=135.596157 step=0.100000
2017/08/29 12:46:38 step 1: mse=132.366557 step=0.100000
2017/08/29 12:46:39 step 2: mse=129.356473 step=0.100000
2017/08/29 12:46:41 step 3: mse=126.894994 step=0.100000
2017/08/29 12:46:42 step 4: mse=124.801628 step=0.100000
2017/08/29 12:46:44 step 5: mse=123.054397 step=0.100000
2017/08/29 12:46:45 step 6: mse=121.138003 step=0.100000
2017/08/29 12:46:47 step 7: mse=119.743412 step=0.100000
2017/08/29 12:46:47 Saving...
2017/08/29 12:46:47 Gathering batch of experience...
2017/08/29 12:47:39 batch 58: mean=378.772727 stddev=167.674179 entropy=0.279985 frames=7575 count=22
2017/08/29 12:47:39 Training policy...
2017/08/29 12:47:46 tune 0: objective=1.271969 reg=0.002800 prune=0
2017/08/29 12:47:50 tune 1: objective=1.274664 reg=0.002800 prune=0
2017/08/29 12:47:54 tune 2: objective=1.277345 reg=0.002801 prune=0
2017/08/29 12:47:58 tune 3: objective=1.280007 reg=0.002801 prune=0
2017/08/29 12:48:02 tune 4: objective=1.282650 reg=0.002802 prune=0
2017/08/29 12:48:06 tune 5: objective=1.285180 reg=0.002802 prune=0
2017/08/29 12:48:10 tune 6: objective=1.287495 reg=0.002803 prune=0
2017/08/29 12:48:14 tune 7: objective=1.289756 reg=0.002803 prune=0
2017/08/29 12:48:17 step 0: objective=1.291796 reg=0.002803
2017/08/29 12:48:19 step 1: objective=1.295047 reg=0.002803
2017/08/29 12:48:22 step 2: objective=1.298148 reg=0.002803
2017/08/29 12:48:25 step 3: objective=1.300629 reg=0.002804
2017/08/29 12:48:27 step 4: objective=1.302055 reg=0.002803
2017/08/29 12:48:30 step 5: objective=1.303726 reg=0.002803
2017/08/29 12:48:33 step 6: objective=1.305215 reg=0.002802
2017/08/29 12:48:35 step 7: objective=1.306481 reg=0.002802
2017/08/29 12:48:35 Training value function...
2017/08/29 12:48:38 step 0: mse=147.160182 step=0.100000
2017/08/29 12:48:40 step 1: mse=144.352243 step=0.100000
2017/08/29 12:48:42 step 2: mse=142.055909 step=0.100000
2017/08/29 12:48:43 step 3: mse=140.188005 step=0.100000
2017/08/29 12:48:45 step 4: mse=138.382746 step=0.100000
2017/08/29 12:48:46 step 5: mse=136.856518 step=0.100000
2017/08/29 12:48:48 step 6: mse=135.736618 step=0.100000
2017/08/29 12:48:50 step 7: mse=134.621871 step=0.100000
2017/08/29 12:48:50 Saving...
2017/08/29 12:48:50 Gathering batch of experience...
2017/08/29 12:49:37 batch 59: mean=256.074074 stddev=203.099305 entropy=0.281118 frames=6860 count=27
2017/08/29 12:49:37 Training policy...
2017/08/29 12:49:44 tune 0: objective=-0.581053 reg=0.002811 prune=0
2017/08/29 12:49:47 tune 1: objective=-0.577584 reg=0.002810 prune=0
2017/08/29 12:49:51 tune 2: objective=-0.574164 reg=0.002809 prune=0
2017/08/29 12:49:54 tune 3: objective=-0.570787 reg=0.002808 prune=0
2017/08/29 12:49:58 tune 4: objective=-0.567497 reg=0.002806 prune=0
2017/08/29 12:50:01 tune 5: objective=-0.564472 reg=0.002805 prune=0
2017/08/29 12:50:05 tune 6: objective=-0.561800 reg=0.002804 prune=0
2017/08/29 12:50:09 tune 7: objective=-0.559476 reg=0.002803 prune=0
2017/08/29 12:50:11 step 0: objective=-0.557274 reg=0.002803
2017/08/29 12:50:13 step 1: objective=-0.554797 reg=0.002801
2017/08/29 12:50:16 step 2: objective=-0.551853 reg=0.002799
2017/08/29 12:50:18 step 3: objective=-0.549401 reg=0.002797
2017/08/29 12:50:21 step 4: objective=-0.546778 reg=0.002797
2017/08/29 12:50:23 step 5: objective=-0.545128 reg=0.002796
2017/08/29 12:50:25 step 6: objective=-0.543873 reg=0.002796
2017/08/29 12:50:28 step 7: objective=-0.542847 reg=0.002794
2017/08/29 12:50:28 Training value function...
2017/08/29 12:50:31 step 0: mse=135.490557 step=0.100000
2017/08/29 12:50:32 step 1: mse=130.560999 step=0.100000
2017/08/29 12:50:34 step 2: mse=126.645642 step=0.100000
2017/08/29 12:50:35 step 3: mse=123.453096 step=0.100000
2017/08/29 12:50:36 step 4: mse=121.214226 step=0.100000
2017/08/29 12:50:38 step 5: mse=119.356179 step=0.100000
2017/08/29 12:50:39 step 6: mse=118.065979 step=0.100000
2017/08/29 12:50:41 step 7: mse=116.930667 step=0.100000
2017/08/29 12:50:41 Saving...
2017/08/29 12:50:41 Gathering batch of experience...
2017/08/29 12:51:29 batch 60: mean=268.500000 stddev=198.193178 entropy=0.281795 frames=7316 count=28
2017/08/29 12:51:29 Training policy...
2017/08/29 12:51:36 tune 0: objective=0.899820 reg=0.002818 prune=0
2017/08/29 12:51:40 tune 1: objective=0.902628 reg=0.002818 prune=0
2017/08/29 12:51:44 tune 2: objective=0.905401 reg=0.002818 prune=0
2017/08/29 12:51:47 tune 3: objective=0.908137 reg=0.002817 prune=0
2017/08/29 12:51:51 tune 4: objective=0.910838 reg=0.002817 prune=0
2017/08/29 12:51:55 tune 5: objective=0.913443 reg=0.002817 prune=0
2017/08/29 12:51:59 tune 6: objective=0.915782 reg=0.002817 prune=0
2017/08/29 12:52:03 tune 7: objective=0.917807 reg=0.002817 prune=0
2017/08/29 12:52:05 step 0: objective=0.919688 reg=0.002817
2017/08/29 12:52:08 step 1: objective=0.922115 reg=0.002817
2017/08/29 12:52:10 step 2: objective=0.923695 reg=0.002817
2017/08/29 12:52:13 step 3: objective=0.925371 reg=0.002817
2017/08/29 12:52:16 step 4: objective=0.927307 reg=0.002817
2017/08/29 12:52:18 step 5: objective=0.930672 reg=0.002817
2017/08/29 12:52:21 step 6: objective=0.931754 reg=0.002817
2017/08/29 12:52:23 step 7: objective=0.932770 reg=0.002817
2017/08/29 12:52:23 Training value function...
2017/08/29 12:52:26 step 0: mse=129.664609 step=0.100000
2017/08/29 12:52:28 step 1: mse=128.277700 step=0.100000
2017/08/29 12:52:29 step 2: mse=127.152373 step=0.100000
2017/08/29 12:52:31 step 3: mse=126.113852 step=0.100000
2017/08/29 12:52:32 step 4: mse=125.294403 step=0.100000
2017/08/29 12:52:34 step 5: mse=124.493933 step=0.100000
2017/08/29 12:52:35 step 6: mse=123.774377 step=0.100000
2017/08/29 12:52:37 step 7: mse=123.325176 step=0.100000
2017/08/29 12:52:37 Saving...
2017/08/29 12:52:37 Gathering batch of experience...
2017/08/29 12:53:30 batch 61: mean=328.083333 stddev=216.365030 entropy=0.276574 frames=7399 count=24
2017/08/29 12:53:30 Training policy...
2017/08/29 12:53:37 tune 0: objective=1.612793 reg=0.002766 prune=0
2017/08/29 12:53:41 tune 1: objective=1.615366 reg=0.002766 prune=0
2017/08/29 12:53:44 tune 2: objective=1.617934 reg=0.002766 prune=0
2017/08/29 12:53:48 tune 3: objective=1.620488 reg=0.002765 prune=0
2017/08/29 12:53:52 tune 4: objective=1.623034 reg=0.002765 prune=0
2017/08/29 12:53:56 tune 5: objective=1.625525 reg=0.002765 prune=0
2017/08/29 12:54:00 tune 6: objective=1.627794 reg=0.002765 prune=0
2017/08/29 12:54:04 tune 7: objective=1.629945 reg=0.002765 prune=0
2017/08/29 12:54:07 step 0: objective=1.632027 reg=0.002765
2017/08/29 12:54:09 step 1: objective=1.633938 reg=0.002765
2017/08/29 12:54:12 step 2: objective=1.635454 reg=0.002765
2017/08/29 12:54:14 step 3: objective=1.637546 reg=0.002766
2017/08/29 12:54:17 step 4: objective=1.639033 reg=0.002766
2017/08/29 12:54:20 step 5: objective=1.640258 reg=0.002766
2017/08/29 12:54:22 step 6: objective=1.641251 reg=0.002766
2017/08/29 12:54:25 step 7: objective=1.642488 reg=0.002766
2017/08/29 12:54:25 Training value function...
2017/08/29 12:54:28 step 0: mse=154.160232 step=0.100000
2017/08/29 12:54:29 step 1: mse=150.697831 step=0.100000
2017/08/29 12:54:31 step 2: mse=147.158313 step=0.100000
2017/08/29 12:54:32 step 3: mse=144.300606 step=0.100000
2017/08/29 12:54:34 step 4: mse=142.416294 step=0.100000
2017/08/29 12:54:36 step 5: mse=140.692335 step=0.100000
2017/08/29 12:54:37 step 6: mse=139.101812 step=0.100000
2017/08/29 12:54:39 step 7: mse=137.902092 step=0.100000
2017/08/29 12:54:39 Saving...
2017/08/29 12:54:39 Gathering batch of experience...
2017/08/29 12:55:30 batch 62: mean=321.391304 stddev=186.689405 entropy=0.276016 frames=7139 count=23
2017/08/29 12:55:30 Training policy...
2017/08/29 12:55:37 tune 0: objective=0.759995 reg=0.002760 prune=0
2017/08/29 12:55:41 tune 1: objective=0.762472 reg=0.002760 prune=0
2017/08/29 12:55:44 tune 2: objective=0.764937 reg=0.002759 prune=0
2017/08/29 12:55:48 tune 3: objective=0.767392 reg=0.002758 prune=0
2017/08/29 12:55:52 tune 4: objective=0.769832 reg=0.002758 prune=0
2017/08/29 12:55:56 tune 5: objective=0.772151 reg=0.002757 prune=0
2017/08/29 12:55:59 tune 6: objective=0.774386 reg=0.002757 prune=0
2017/08/29 12:56:03 tune 7: objective=0.776532 reg=0.002756 prune=0
2017/08/29 12:56:06 step 0: objective=0.778418 reg=0.002756
2017/08/29 12:56:08 step 1: objective=0.780083 reg=0.002756
2017/08/29 12:56:11 step 2: objective=0.781945 reg=0.002756
2017/08/29 12:56:13 step 3: objective=0.784691 reg=0.002756
2017/08/29 12:56:16 step 4: objective=0.786496 reg=0.002756
2017/08/29 12:56:18 step 5: objective=0.788814 reg=0.002755
2017/08/29 12:56:21 step 6: objective=0.790029 reg=0.002755
2017/08/29 12:56:23 step 7: objective=0.791203 reg=0.002755
2017/08/29 12:56:23 Training value function...
2017/08/29 12:56:26 step 0: mse=125.664540 step=0.100000
2017/08/29 12:56:28 step 1: mse=125.090312 step=0.100000
2017/08/29 12:56:29 step 2: mse=124.765579 step=0.100000
2017/08/29 12:56:31 step 3: mse=124.425674 step=0.100000
2017/08/29 12:56:32 step 4: mse=123.801279 step=0.100000
2017/08/29 12:56:34 step 5: mse=123.348734 step=0.100000
2017/08/29 12:56:35 step 6: mse=122.826952 step=0.100000
2017/08/29 12:56:37 step 7: mse=122.445989 step=0.100000
2017/08/29 12:56:37 Saving...
2017/08/29 12:56:37 Gathering batch of experience...
2017/08/29 12:57:23 batch 63: mean=223.607143 stddev=151.834811 entropy=0.274736 frames=5947 count=28
2017/08/29 12:57:23 Training policy...
2017/08/29 12:57:29 tune 0: objective=0.556093 reg=0.002747 prune=0
2017/08/29 12:57:32 tune 1: objective=0.559868 reg=0.002747 prune=0
2017/08/29 12:57:35 tune 2: objective=0.563598 reg=0.002746 prune=0
2017/08/29 12:57:38 tune 3: objective=0.567286 reg=0.002745 prune=0
2017/08/29 12:57:41 tune 4: objective=0.570931 reg=0.002744 prune=0
2017/08/29 12:57:44 tune 5: objective=0.574432 reg=0.002744 prune=0
2017/08/29 12:57:47 tune 6: objective=0.577743 reg=0.002743 prune=0
2017/08/29 12:57:50 tune 7: objective=0.580749 reg=0.002742 prune=0
2017/08/29 12:57:53 step 0: objective=0.583531 reg=0.002742
2017/08/29 12:57:55 step 1: objective=0.586855 reg=0.002741
2017/08/29 12:57:57 step 2: objective=0.588277 reg=0.002741
2017/08/29 12:57:59 step 3: objective=0.590156 reg=0.002741
2017/08/29 12:58:01 step 4: objective=0.592953 reg=0.002741
2017/08/29 12:58:03 step 5: objective=0.594430 reg=0.002740
2017/08/29 12:58:05 step 6: objective=0.595808 reg=0.002740
2017/08/29 12:58:07 step 7: objective=0.598022 reg=0.002740
2017/08/29 12:58:07 Training value function...
2017/08/29 12:58:09 step 0: mse=149.014052 step=0.100000
2017/08/29 12:58:11 step 1: mse=146.432624 step=0.100000
2017/08/29 12:58:12 step 2: mse=144.467852 step=0.100000
2017/08/29 12:58:13 step 3: mse=142.736252 step=0.100000
2017/08/29 12:58:14 step 4: mse=141.478624 step=0.100000
2017/08/29 12:58:16 step 5: mse=140.257467 step=0.100000
2017/08/29 12:58:17 step 6: mse=139.385583 step=0.100000
2017/08/29 12:58:18 step 7: mse=138.543966 step=0.100000
2017/08/29 12:58:18 Saving...
2017/08/29 12:58:18 Gathering batch of experience...
2017/08/29 12:59:08 batch 64: mean=338.478261 stddev=229.094412 entropy=0.279129 frames=7187 count=23
2017/08/29 12:59:08 Training policy...
2017/08/29 12:59:14 tune 0: objective=2.090286 reg=0.002791 prune=0
2017/08/29 12:59:18 tune 1: objective=2.093239 reg=0.002791 prune=0
2017/08/29 12:59:22 tune 2: objective=2.096175 reg=0.002792 prune=0
2017/08/29 12:59:26 tune 3: objective=2.099090 reg=0.002792 prune=0
2017/08/29 12:59:30 tune 4: objective=2.101998 reg=0.002792 prune=0
2017/08/29 12:59:33 tune 5: objective=2.104894 reg=0.002792 prune=0
2017/08/29 12:59:37 tune 6: objective=2.107749 reg=0.002792 prune=0
2017/08/29 12:59:41 tune 7: objective=2.110364 reg=0.002792 prune=0
2017/08/29 12:59:44 step 0: objective=2.112729 reg=0.002792
2017/08/29 12:59:46 step 1: objective=2.115648 reg=0.002792
2017/08/29 12:59:49 step 2: objective=2.117820 reg=0.002793
2017/08/29 12:59:51 step 3: objective=2.119702 reg=0.002793
2017/08/29 12:59:54 step 4: objective=2.121738 reg=0.002793
2017/08/29 12:59:56 step 5: objective=2.124515 reg=0.002793
2017/08/29 12:59:59 step 6: objective=2.127376 reg=0.002794
2017/08/29 13:00:01 step 7: objective=2.128438 reg=0.002794
2017/08/29 13:00:01 Training value function...
2017/08/29 13:00:04 step 0: mse=166.376522 step=0.100000
2017/08/29 13:00:06 step 1: mse=160.881293 step=0.100000
2017/08/29 13:00:07 step 2: mse=156.264878 step=0.100000
2017/08/29 13:00:09 step 3: mse=152.213829 step=0.100000
2017/08/29 13:00:10 step 4: mse=148.598382 step=0.100000
2017/08/29 13:00:12 step 5: mse=145.642733 step=0.100000
2017/08/29 13:00:13 step 6: mse=143.046761 step=0.100000
2017/08/29 13:00:15 step 7: mse=140.696191 step=0.100000
2017/08/29 13:00:15 Saving...
2017/08/29 13:00:15 Gathering batch of experience...
2017/08/29 13:01:05 batch 65: mean=243.931034 stddev=201.387931 entropy=0.272060 frames=6743 count=29
2017/08/29 13:01:05 Training policy...
2017/08/29 13:01:11 tune 0: objective=0.669436 reg=0.002721 prune=0
2017/08/29 13:01:15 tune 1: objective=0.673051 reg=0.002720 prune=0
2017/08/29 13:01:18 tune 2: objective=0.676618 reg=0.002720 prune=0
2017/08/29 13:01:22 tune 3: objective=0.680132 reg=0.002720 prune=0
2017/08/29 13:01:26 tune 4: objective=0.683447 reg=0.002720 prune=0
2017/08/29 13:01:29 tune 5: objective=0.686528 reg=0.002720 prune=0
2017/08/29 13:01:33 tune 6: objective=0.689381 reg=0.002719 prune=0
2017/08/29 13:01:36 tune 7: objective=0.691980 reg=0.002719 prune=0
2017/08/29 13:01:39 step 0: objective=0.694344 reg=0.002719
2017/08/29 13:01:41 step 1: objective=0.697543 reg=0.002720
2017/08/29 13:01:43 step 2: objective=0.700407 reg=0.002719
2017/08/29 13:01:46 step 3: objective=0.702100 reg=0.002720
2017/08/29 13:01:48 step 4: objective=0.703902 reg=0.002720
2017/08/29 13:01:50 step 5: objective=0.705604 reg=0.002719
2017/08/29 13:01:53 step 6: objective=0.706871 reg=0.002719
2017/08/29 13:01:55 step 7: objective=0.708047 reg=0.002720
2017/08/29 13:01:55 Training value function...
2017/08/29 13:01:58 step 0: mse=146.897763 step=0.100000
2017/08/29 13:01:59 step 1: mse=145.076258 step=0.100000
2017/08/29 13:02:01 step 2: mse=143.537607 step=0.100000
2017/08/29 13:02:02 step 3: mse=142.765227 step=0.100000
2017/08/29 13:02:04 step 4: mse=141.905552 step=0.100000
2017/08/29 13:02:05 step 5: mse=140.927341 step=0.100000
2017/08/29 13:02:06 step 6: mse=140.519398 step=0.100000
2017/08/29 13:02:08 step 7: mse=139.731806 step=0.100000
2017/08/29 13:02:08 Saving...
2017/08/29 13:02:08 Gathering batch of experience...
2017/08/29 13:02:56 batch 66: mean=343.000000 stddev=218.379778 entropy=0.276215 frames=7067 count=22
2017/08/29 13:02:56 Training policy...
2017/08/29 13:03:02 tune 0: objective=1.430172 reg=0.002762 prune=0
2017/08/29 13:03:06 tune 1: objective=1.432740 reg=0.002762 prune=0
2017/08/29 13:03:10 tune 2: objective=1.435294 reg=0.002763 prune=0
2017/08/29 13:03:13 tune 3: objective=1.437840 reg=0.002763 prune=0
2017/08/29 13:03:17 tune 4: objective=1.440375 reg=0.002763 prune=0
2017/08/29 13:03:21 tune 5: objective=1.442901 reg=0.002763 prune=0
2017/08/29 13:03:25 tune 6: objective=1.445422 reg=0.002763 prune=0
2017/08/29 13:03:28 tune 7: objective=1.447765 reg=0.002764 prune=0
2017/08/29 13:03:31 step 0: objective=1.449902 reg=0.002764
2017/08/29 13:03:33 step 1: objective=1.451493 reg=0.002764
2017/08/29 13:03:36 step 2: objective=1.453331 reg=0.002764
2017/08/29 13:03:38 step 3: objective=1.454779 reg=0.002764
2017/08/29 13:03:41 step 4: objective=1.457206 reg=0.002764
2017/08/29 13:03:43 step 5: objective=1.459585 reg=0.002764
2017/08/29 13:03:46 step 6: objective=1.461193 reg=0.002763
2017/08/29 13:03:48 step 7: objective=1.463093 reg=0.002763
2017/08/29 13:03:48 Training value function...
2017/08/29 13:03:51 step 0: mse=150.052260 step=0.100000
2017/08/29 13:03:53 step 1: mse=145.851765 step=0.100000
2017/08/29 13:03:54 step 2: mse=142.474563 step=0.100000
2017/08/29 13:03:56 step 3: mse=139.185917 step=0.100000
2017/08/29 13:03:57 step 4: mse=136.325343 step=0.100000
2017/08/29 13:03:59 step 5: mse=134.226030 step=0.100000
2017/08/29 13:04:00 step 6: mse=132.417141 step=0.100000
2017/08/29 13:04:02 step 7: mse=130.804937 step=0.100000
2017/08/29 13:04:02 Saving...
2017/08/29 13:04:02 Gathering batch of experience...
2017/08/29 13:04:45 batch 67: mean=407.823529 stddev=155.463344 entropy=0.279079 frames=6612 count=17
2017/08/29 13:04:45 Training policy...
2017/08/29 13:04:51 tune 0: objective=1.014551 reg=0.002791 prune=0
2017/08/29 13:04:54 tune 1: objective=1.016669 reg=0.002790 prune=0
2017/08/29 13:04:58 tune 2: objective=1.018770 reg=0.002789 prune=0
2017/08/29 13:05:01 tune 3: objective=1.020861 reg=0.002789 prune=0
2017/08/29 13:05:05 tune 4: objective=1.022937 reg=0.002788 prune=0
2017/08/29 13:05:08 tune 5: objective=1.024910 reg=0.002787 prune=0
2017/08/29 13:05:12 tune 6: objective=1.026855 reg=0.002787 prune=0
2017/08/29 13:05:15 tune 7: objective=1.028795 reg=0.002786 prune=0
2017/08/29 13:05:18 step 0: objective=1.030691 reg=0.002785
2017/08/29 13:05:20 step 1: objective=1.032327 reg=0.002785
2017/08/29 13:05:22 step 2: objective=1.034013 reg=0.002785
2017/08/29 13:05:25 step 3: objective=1.037017 reg=0.002785
2017/08/29 13:05:27 step 4: objective=1.038874 reg=0.002784
2017/08/29 13:05:29 step 5: objective=1.040085 reg=0.002784
2017/08/29 13:05:32 step 6: objective=1.041960 reg=0.002784
2017/08/29 13:05:34 step 7: objective=1.043026 reg=0.002784
2017/08/29 13:05:34 Training value function...
2017/08/29 13:05:37 step 0: mse=141.216597 step=0.100000
2017/08/29 13:05:38 step 1: mse=137.767832 step=0.100000
2017/08/29 13:05:39 step 2: mse=134.900808 step=0.100000
2017/08/29 13:05:41 step 3: mse=132.355394 step=0.100000
2017/08/29 13:05:42 step 4: mse=130.574837 step=0.100000
2017/08/29 13:05:43 step 5: mse=128.782241 step=0.100000
2017/08/29 13:05:45 step 6: mse=127.361683 step=0.100000
2017/08/29 13:05:46 step 7: mse=126.331297 step=0.100000
2017/08/29 13:05:46 Saving...
2017/08/29 13:05:46 Gathering batch of experience...
2017/08/29 13:06:38 batch 68: mean=314.640000 stddev=205.339111 entropy=0.275990 frames=7414 count=25
2017/08/29 13:06:38 Training policy...
2017/08/29 13:06:45 tune 0: objective=0.946764 reg=0.002760 prune=0
2017/08/29 13:06:49 tune 1: objective=0.949865 reg=0.002760 prune=0
2017/08/29 13:06:53 tune 2: objective=0.952946 reg=0.002760 prune=0
2017/08/29 13:06:57 tune 3: objective=0.956002 reg=0.002759 prune=0
2017/08/29 13:07:01 tune 4: objective=0.959041 reg=0.002759 prune=0
2017/08/29 13:07:04 tune 5: objective=0.961994 reg=0.002759 prune=0
2017/08/29 13:07:08 tune 6: objective=0.964717 reg=0.002759 prune=0
2017/08/29 13:07:12 tune 7: objective=0.967294 reg=0.002759 prune=0
2017/08/29 13:07:15 step 0: objective=0.969696 reg=0.002759
2017/08/29 13:07:18 step 1: objective=0.973342 reg=0.002758
2017/08/29 13:07:20 step 2: objective=0.975988 reg=0.002757
2017/08/29 13:07:23 step 3: objective=0.978106 reg=0.002757
2017/08/29 13:07:25 step 4: objective=0.979928 reg=0.002757
2017/08/29 13:07:28 step 5: objective=0.981677 reg=0.002758
2017/08/29 13:07:31 step 6: objective=0.983589 reg=0.002758
2017/08/29 13:07:33 step 7: objective=0.984909 reg=0.002758
2017/08/29 13:07:33 Training value function...
2017/08/29 13:07:36 step 0: mse=142.280109 step=0.100000
2017/08/29 13:07:38 step 1: mse=139.857916 step=0.100000
2017/08/29 13:07:39 step 2: mse=137.757914 step=0.100000
2017/08/29 13:07:41 step 3: mse=136.269213 step=0.100000
2017/08/29 13:07:43 step 4: mse=134.779654 step=0.100000
2017/08/29 13:07:44 step 5: mse=133.521432 step=0.100000
2017/08/29 13:07:46 step 6: mse=132.545294 step=0.100000
2017/08/29 13:07:47 step 7: mse=131.366047 step=0.100000
2017/08/29 13:07:47 Saving...
2017/08/29 13:07:47 Gathering batch of experience...
2017/08/29 13:08:37 batch 69: mean=297.692308 stddev=209.365299 entropy=0.277267 frames=7255 count=26
2017/08/29 13:08:37 Training policy...
2017/08/29 13:08:44 tune 0: objective=1.095408 reg=0.002773 prune=0
2017/08/29 13:08:48 tune 1: objective=1.098543 reg=0.002772 prune=0
2017/08/29 13:08:52 tune 2: objective=1.101641 reg=0.002771 prune=0
2017/08/29 13:08:55 tune 3: objective=1.104709 reg=0.002771 prune=0
2017/08/29 13:08:59 tune 4: objective=1.107746 reg=0.002770 prune=0
2017/08/29 13:09:03 tune 5: objective=1.110584 reg=0.002769 prune=0
2017/08/29 13:09:07 tune 6: objective=1.113058 reg=0.002769 prune=0
2017/08/29 13:09:11 tune 7: objective=1.115396 reg=0.002769 prune=0
2017/08/29 13:09:13 step 0: objective=1.117502 reg=0.002768
2017/08/29 13:09:16 step 1: objective=1.119326 reg=0.002768
2017/08/29 13:09:19 step 2: objective=1.121419 reg=0.002767
2017/08/29 13:09:21 step 3: objective=1.122970 reg=0.002767
2017/08/29 13:09:24 step 4: objective=1.124210 reg=0.002767
2017/08/29 13:09:26 step 5: objective=1.127394 reg=0.002767
2017/08/29 13:09:29 step 6: objective=1.129577 reg=0.002766
2017/08/29 13:09:31 step 7: objective=1.130662 reg=0.002766
2017/08/29 13:09:31 Training value function...
2017/08/29 13:09:34 step 0: mse=132.617643 step=0.100000
2017/08/29 13:09:36 step 1: mse=130.221109 step=0.100000
2017/08/29 13:09:37 step 2: mse=128.301513 step=0.100000
2017/08/29 13:09:39 step 3: mse=126.972651 step=0.100000
2017/08/29 13:09:40 step 4: mse=125.565925 step=0.100000
2017/08/29 13:09:42 step 5: mse=124.620856 step=0.100000
2017/08/29 13:09:43 step 6: mse=123.440150 step=0.100000
2017/08/29 13:09:45 step 7: mse=122.720713 step=0.100000
2017/08/29 13:09:45 Saving...
2017/08/29 13:09:45 Gathering batch of experience...
2017/08/29 13:10:38 batch 70: mean=320.640000 stddev=211.356737 entropy=0.280705 frames=7519 count=25
2017/08/29 13:10:38 Training policy...
2017/08/29 13:10:45 tune 0: objective=1.041066 reg=0.002807 prune=0
2017/08/29 13:10:49 tune 1: objective=1.043607 reg=0.002806 prune=0
2017/08/29 13:10:53 tune 2: objective=1.046129 reg=0.002806 prune=0
2017/08/29 13:10:57 tune 3: objective=1.048627 reg=0.002805 prune=0
2017/08/29 13:11:01 tune 4: objective=1.051107 reg=0.002804 prune=0
2017/08/29 13:11:05 tune 5: objective=1.053565 reg=0.002804 prune=0
2017/08/29 13:11:09 tune 6: objective=1.055978 reg=0.002803 prune=0
2017/08/29 13:11:13 tune 7: objective=1.058295 reg=0.002803 prune=0
2017/08/29 13:11:16 step 0: objective=1.060381 reg=0.002802
2017/08/29 13:11:19 step 1: objective=1.062596 reg=0.002802
2017/08/29 13:11:21 step 2: objective=1.064511 reg=0.002802
2017/08/29 13:11:24 step 3: objective=1.066450 reg=0.002802
2017/08/29 13:11:27 step 4: objective=1.068235 reg=0.002802
2017/08/29 13:11:29 step 5: objective=1.070183 reg=0.002802
2017/08/29 13:11:32 step 6: objective=1.072150 reg=0.002801
2017/08/29 13:11:35 step 7: objective=1.073342 reg=0.002801
2017/08/29 13:11:35 Training value function...
2017/08/29 13:11:38 step 0: mse=141.333881 step=0.100000
2017/08/29 13:11:39 step 1: mse=138.966299 step=0.100000
2017/08/29 13:11:41 step 2: mse=137.415628 step=0.100000
2017/08/29 13:11:42 step 3: mse=135.969629 step=0.100000
2017/08/29 13:11:44 step 4: mse=134.668782 step=0.100000
2017/08/29 13:11:46 step 5: mse=133.587883 step=0.100000
2017/08/29 13:11:47 step 6: mse=132.427174 step=0.100000
2017/08/29 13:11:49 step 7: mse=131.441664 step=0.100000
2017/08/29 13:11:49 Saving...
2017/08/29 13:11:49 Gathering batch of experience...
2017/08/29 13:12:34 batch 71: mean=322.409091 stddev=216.133725 entropy=0.277630 frames=6823 count=22
2017/08/29 13:12:34 Training policy...
2017/08/29 13:12:41 tune 0: objective=0.908606 reg=0.002776 prune=0
2017/08/29 13:12:44 tune 1: objective=0.912136 reg=0.002777 prune=0
2017/08/29 13:12:48 tune 2: objective=0.915640 reg=0.002778 prune=0
2017/08/29 13:12:52 tune 3: objective=0.919126 reg=0.002779 prune=0
2017/08/29 13:12:55 tune 4: objective=0.922541 reg=0.002780 prune=0
2017/08/29 13:12:59 tune 5: objective=0.925831 reg=0.002781 prune=0
2017/08/29 13:13:03 tune 6: objective=0.928792 reg=0.002781 prune=0
2017/08/29 13:13:06 tune 7: objective=0.931401 reg=0.002782 prune=0
2017/08/29 13:13:09 step 0: objective=0.933816 reg=0.002783
2017/08/29 13:13:11 step 1: objective=0.935597 reg=0.002784
2017/08/29 13:13:13 step 2: objective=0.938509 reg=0.002783
2017/08/29 13:13:16 step 3: objective=0.940033 reg=0.002784
2017/08/29 13:13:18 step 4: objective=0.942026 reg=0.002784
2017/08/29 13:13:21 step 5: objective=0.943185 reg=0.002784
2017/08/29 13:13:23 step 6: objective=0.945338 reg=0.002784
2017/08/29 13:13:25 step 7: objective=0.946273 reg=0.002784
2017/08/29 13:13:25 Training value function...
2017/08/29 13:13:28 step 0: mse=132.261831 step=0.100000
2017/08/29 13:13:30 step 1: mse=130.211719 step=0.100000
2017/08/29 13:13:31 step 2: mse=128.848516 step=0.100000
2017/08/29 13:13:33 step 3: mse=127.476484 step=0.100000
2017/08/29 13:13:34 step 4: mse=126.422777 step=0.100000
2017/08/29 13:13:35 step 5: mse=125.426975 step=0.100000
2017/08/29 13:13:37 step 6: mse=124.403745 step=0.100000
2017/08/29 13:13:38 step 7: mse=123.591226 step=0.100000
2017/08/29 13:13:38 Saving...
2017/08/29 13:13:38 Gathering batch of experience...
2017/08/29 13:14:24 batch 72: mean=283.192308 stddev=168.528249 entropy=0.274239 frames=7060 count=26
2017/08/29 13:14:24 Training policy...
2017/08/29 13:14:31 tune 0: objective=0.553782 reg=0.002742 prune=0
2017/08/29 13:14:35 tune 1: objective=0.556721 reg=0.002742 prune=0
2017/08/29 13:14:39 tune 2: objective=0.559638 reg=0.002742 prune=0
2017/08/29 13:14:42 tune 3: objective=0.562533 reg=0.002742 prune=0
2017/08/29 13:14:46 tune 4: objective=0.565394 reg=0.002742 prune=0
2017/08/29 13:14:50 tune 5: objective=0.568103 reg=0.002742 prune=0
2017/08/29 13:14:54 tune 6: objective=0.570741 reg=0.002742 prune=0
2017/08/29 13:14:57 tune 7: objective=0.573288 reg=0.002741 prune=0
2017/08/29 13:15:00 step 0: objective=0.575591 reg=0.002741
2017/08/29 13:15:02 step 1: objective=0.577835 reg=0.002741
2017/08/29 13:15:05 step 2: objective=0.581045 reg=0.002741
2017/08/29 13:15:07 step 3: objective=0.582629 reg=0.002741
2017/08/29 13:15:10 step 4: objective=0.584228 reg=0.002741
2017/08/29 13:15:12 step 5: objective=0.585367 reg=0.002740
2017/08/29 13:15:15 step 6: objective=0.586776 reg=0.002740
2017/08/29 13:15:17 step 7: objective=0.588130 reg=0.002740
2017/08/29 13:15:17 Training value function...
2017/08/29 13:15:20 step 0: mse=132.310756 step=0.100000
2017/08/29 13:15:22 step 1: mse=131.154324 step=0.100000
2017/08/29 13:15:23 step 2: mse=130.000305 step=0.100000
2017/08/29 13:15:25 step 3: mse=129.123131 step=0.100000
2017/08/29 13:15:26 step 4: mse=128.456419 step=0.100000
2017/08/29 13:15:28 step 5: mse=127.970518 step=0.100000
2017/08/29 13:15:29 step 6: mse=127.245169 step=0.100000
2017/08/29 13:15:31 step 7: mse=126.830786 step=0.100000
2017/08/29 13:15:31 Saving...
2017/08/29 13:15:31 Gathering batch of experience...
2017/08/29 13:16:25 batch 73: mean=244.133333 stddev=193.615208 entropy=0.279628 frames=7102 count=30
2017/08/29 13:16:25 Training policy...
2017/08/29 13:16:31 tune 0: objective=0.588211 reg=0.002796 prune=0
2017/08/29 13:16:35 tune 1: objective=0.591044 reg=0.002796 prune=0
2017/08/29 13:16:39 tune 2: objective=0.593847 reg=0.002795 prune=0
2017/08/29 13:16:43 tune 3: objective=0.596623 reg=0.002795 prune=0
2017/08/29 13:16:46 tune 4: objective=0.599372 reg=0.002794 prune=0
2017/08/29 13:16:50 tune 5: objective=0.601887 reg=0.002794 prune=0
2017/08/29 13:16:54 tune 6: objective=0.604270 reg=0.002794 prune=0
2017/08/29 13:16:58 tune 7: objective=0.606584 reg=0.002793 prune=0
2017/08/29 13:17:00 step 0: objective=0.608701 reg=0.002793
2017/08/29 13:17:03 step 1: objective=0.611484 reg=0.002791
2017/08/29 13:17:05 step 2: objective=0.613257 reg=0.002791
2017/08/29 13:17:08 step 3: objective=0.615517 reg=0.002790
2017/08/29 13:17:10 step 4: objective=0.617331 reg=0.002789
2017/08/29 13:17:13 step 5: objective=0.618514 reg=0.002790
2017/08/29 13:17:15 step 6: objective=0.620482 reg=0.002789
2017/08/29 13:17:18 step 7: objective=0.622724 reg=0.002788
2017/08/29 13:17:18 Training value function...
2017/08/29 13:17:21 step 0: mse=134.654741 step=0.100000
2017/08/29 13:17:22 step 1: mse=133.343367 step=0.100000
2017/08/29 13:17:24 step 2: mse=132.405013 step=0.100000
2017/08/29 13:17:25 step 3: mse=131.300112 step=0.100000
2017/08/29 13:17:27 step 4: mse=130.492431 step=0.100000
2017/08/29 13:17:28 step 5: mse=129.748674 step=0.100000
2017/08/29 13:17:30 step 6: mse=128.889518 step=0.100000
2017/08/29 13:17:31 step 7: mse=128.456480 step=0.100000
2017/08/29 13:17:31 Saving...
2017/08/29 13:17:31 Gathering batch of experience...
2017/08/29 13:18:14 batch 74: mean=304.181818 stddev=189.765797 entropy=0.274259 frames=6165 count=22
2017/08/29 13:18:14 Training policy...
2017/08/29 13:18:20 tune 0: objective=1.800333 reg=0.002743 prune=0
2017/08/29 13:18:23 tune 1: objective=1.803598 reg=0.002742 prune=0
2017/08/29 13:18:26 tune 2: objective=1.806819 reg=0.002742 prune=0
2017/08/29 13:18:30 tune 3: objective=1.810005 reg=0.002742 prune=0
2017/08/29 13:18:33 tune 4: objective=1.813165 reg=0.002742 prune=0
2017/08/29 13:18:36 tune 5: objective=1.816150 reg=0.002742 prune=0
2017/08/29 13:18:40 tune 6: objective=1.818784 reg=0.002741 prune=0
2017/08/29 13:18:43 tune 7: objective=1.821228 reg=0.002741 prune=0
2017/08/29 13:18:45 step 0: objective=1.823291 reg=0.002741
2017/08/29 13:18:47 step 1: objective=1.826417 reg=0.002741
2017/08/29 13:18:49 step 2: objective=1.827952 reg=0.002742
2017/08/29 13:18:52 step 3: objective=1.831077 reg=0.002742
2017/08/29 13:18:54 step 4: objective=1.833321 reg=0.002743
2017/08/29 13:18:56 step 5: objective=1.835164 reg=0.002742
2017/08/29 13:18:58 step 6: objective=1.836486 reg=0.002742
2017/08/29 13:19:00 step 7: objective=1.837865 reg=0.002742
2017/08/29 13:19:00 Training value function...
2017/08/29 13:19:03 step 0: mse=154.616291 step=0.100000
2017/08/29 13:19:04 step 1: mse=151.355057 step=0.100000
2017/08/29 13:19:05 step 2: mse=148.760002 step=0.100000
2017/08/29 13:19:07 step 3: mse=146.333344 step=0.100000
2017/08/29 13:19:08 step 4: mse=144.360942 step=0.100000
2017/08/29 13:19:09 step 5: mse=142.440886 step=0.100000
2017/08/29 13:19:11 step 6: mse=140.994303 step=0.100000
2017/08/29 13:19:12 step 7: mse=139.662708 step=0.100000
2017/08/29 13:19:12 Saving...
2017/08/29 13:19:12 Gathering batch of experience...
2017/08/29 13:19:58 batch 75: mean=328.434783 stddev=191.596684 entropy=0.277586 frames=6874 count=23
2017/08/29 13:19:58 Training policy...
2017/08/29 13:20:04 tune 0: objective=1.606909 reg=0.002776 prune=0
2017/08/29 13:20:08 tune 1: objective=1.610623 reg=0.002776 prune=0
2017/08/29 13:20:12 tune 2: objective=1.614308 reg=0.002776 prune=0
2017/08/29 13:20:15 tune 3: objective=1.617963 reg=0.002776 prune=0
2017/08/29 13:20:19 tune 4: objective=1.621503 reg=0.002776 prune=0
2017/08/29 13:20:23 tune 5: objective=1.624741 reg=0.002776 prune=0
2017/08/29 13:20:26 tune 6: objective=1.627517 reg=0.002776 prune=0
2017/08/29 13:20:30 tune 7: objective=1.630022 reg=0.002776 prune=0
2017/08/29 13:20:33 step 0: objective=1.632342 reg=0.002776
2017/08/29 13:20:35 step 1: objective=1.634341 reg=0.002777
2017/08/29 13:20:37 step 2: objective=1.636061 reg=0.002777
2017/08/29 13:20:40 step 3: objective=1.638305 reg=0.002778
2017/08/29 13:20:42 step 4: objective=1.640205 reg=0.002778
2017/08/29 13:20:45 step 5: objective=1.642185 reg=0.002778
2017/08/29 13:20:47 step 6: objective=1.643509 reg=0.002777
2017/08/29 13:20:50 step 7: objective=1.645221 reg=0.002777
2017/08/29 13:20:50 Training value function...
2017/08/29 13:20:52 step 0: mse=165.298967 step=0.100000
2017/08/29 13:20:54 step 1: mse=162.197098 step=0.100000
2017/08/29 13:20:55 step 2: mse=159.951870 step=0.100000
2017/08/29 13:20:57 step 3: mse=157.870503 step=0.100000
2017/08/29 13:20:58 step 4: mse=155.601585 step=0.100000
2017/08/29 13:21:00 step 5: mse=154.046224 step=0.100000
2017/08/29 13:21:01 step 6: mse=152.269617 step=0.100000
2017/08/29 13:21:02 step 7: mse=151.280520 step=0.100000
2017/08/29 13:21:02 Saving...
2017/08/29 13:21:03 Gathering batch of experience...
2017/08/29 13:21:46 batch 76: mean=325.700000 stddev=209.331340 entropy=0.277802 frames=6157 count=20
2017/08/29 13:21:46 Training policy...
2017/08/29 13:21:52 tune 0: objective=0.870465 reg=0.002778 prune=0
2017/08/29 13:21:56 tune 1: objective=0.873822 reg=0.002777 prune=0
2017/08/29 13:21:59 tune 2: objective=0.877145 reg=0.002777 prune=0
2017/08/29 13:22:02 tune 3: objective=0.880434 reg=0.002776 prune=0
2017/08/29 13:22:05 tune 4: objective=0.883694 reg=0.002775 prune=0
2017/08/29 13:22:09 tune 5: objective=0.886683 reg=0.002775 prune=0
2017/08/29 13:22:12 tune 6: objective=0.889290 reg=0.002774 prune=0
2017/08/29 13:22:15 tune 7: objective=0.891699 reg=0.002774 prune=0
2017/08/29 13:22:17 step 0: objective=0.893964 reg=0.002774
2017/08/29 13:22:20 step 1: objective=0.896982 reg=0.002774
2017/08/29 13:22:22 step 2: objective=0.899401 reg=0.002774
2017/08/29 13:22:24 step 3: objective=0.901124 reg=0.002773
2017/08/29 13:22:26 step 4: objective=0.903175 reg=0.002773
2017/08/29 13:22:28 step 5: objective=0.904948 reg=0.002773
2017/08/29 13:22:31 step 6: objective=0.906184 reg=0.002774
2017/08/29 13:22:33 step 7: objective=0.907298 reg=0.002774
2017/08/29 13:22:33 Training value function...
2017/08/29 13:22:35 step 0: mse=127.808020 step=0.100000
2017/08/29 13:22:37 step 1: mse=126.903439 step=0.100000
2017/08/29 13:22:38 step 2: mse=126.169378 step=0.100000
2017/08/29 13:22:39 step 3: mse=125.487053 step=0.100000
2017/08/29 13:22:40 step 4: mse=124.763982 step=0.100000
2017/08/29 13:22:42 step 5: mse=124.045039 step=0.100000
2017/08/29 13:22:43 step 6: mse=123.359355 step=0.100000
2017/08/29 13:22:44 step 7: mse=122.561652 step=0.100000
2017/08/29 13:22:44 Saving...
2017/08/29 13:22:44 Gathering batch of experience...
2017/08/29 13:23:32 batch 77: mean=351.454545 stddev=184.443321 entropy=0.273387 frames=7521 count=22
2017/08/29 13:23:32 Training policy...
2017/08/29 13:23:40 tune 0: objective=0.790316 reg=0.002734 prune=0
2017/08/29 13:23:44 tune 1: objective=0.792661 reg=0.002734 prune=0
2017/08/29 13:23:48 tune 2: objective=0.794982 reg=0.002733 prune=0
2017/08/29 13:23:52 tune 3: objective=0.797281 reg=0.002733 prune=0
2017/08/29 13:23:56 tune 4: objective=0.799542 reg=0.002733 prune=0
2017/08/29 13:24:00 tune 5: objective=0.801577 reg=0.002732 prune=0
2017/08/29 13:24:04 tune 6: objective=0.803512 reg=0.002732 prune=0
2017/08/29 13:24:08 tune 7: objective=0.805330 reg=0.002732 prune=0
2017/08/29 13:24:10 step 0: objective=0.806987 reg=0.002732
2017/08/29 13:24:13 step 1: objective=0.808829 reg=0.002732
2017/08/29 13:24:16 step 2: objective=0.810279 reg=0.002731
2017/08/29 13:24:19 step 3: objective=0.811809 reg=0.002732
2017/08/29 13:24:21 step 4: objective=0.813143 reg=0.002732
2017/08/29 13:24:24 step 5: objective=0.813992 reg=0.002732
2017/08/29 13:24:27 step 6: objective=0.815244 reg=0.002732
2017/08/29 13:24:29 step 7: objective=0.816902 reg=0.002732
2017/08/29 13:24:29 Training value function...
2017/08/29 13:24:32 step 0: mse=122.701280 step=0.100000
2017/08/29 13:24:34 step 1: mse=121.945417 step=0.100000
2017/08/29 13:24:35 step 2: mse=121.340983 step=0.100000
2017/08/29 13:24:37 step 3: mse=121.055499 step=0.100000
2017/08/29 13:24:39 step 4: mse=120.592303 step=0.100000
2017/08/29 13:24:40 step 5: mse=120.051431 step=0.100000
2017/08/29 13:24:42 step 6: mse=119.681454 step=0.100000
2017/08/29 13:24:43 step 7: mse=119.409875 step=0.100000
2017/08/29 13:24:43 Saving...
2017/08/29 13:24:43 Gathering batch of experience...
2017/08/29 13:25:36 batch 78: mean=418.904762 stddev=191.207667 entropy=0.275129 frames=8179 count=21
2017/08/29 13:25:36 Training policy...
2017/08/29 13:25:44 tune 0: objective=1.785449 reg=0.002751 prune=0
2017/08/29 13:25:48 tune 1: objective=1.787335 reg=0.002751 prune=0
2017/08/29 13:25:53 tune 2: objective=1.789216 reg=0.002751 prune=0
2017/08/29 13:25:57 tune 3: objective=1.791087 reg=0.002750 prune=0
2017/08/29 13:26:02 tune 4: objective=1.792945 reg=0.002750 prune=0
2017/08/29 13:26:06 tune 5: objective=1.794803 reg=0.002750 prune=0
2017/08/29 13:26:10 tune 6: objective=1.796651 reg=0.002750 prune=0
2017/08/29 13:26:15 tune 7: objective=1.798427 reg=0.002749 prune=0
2017/08/29 13:26:18 step 0: objective=1.800077 reg=0.002749
2017/08/29 13:26:21 step 1: objective=1.802659 reg=0.002749
2017/08/29 13:26:24 step 2: objective=1.805723 reg=0.002749
2017/08/29 13:26:27 step 3: objective=1.807019 reg=0.002748
2017/08/29 13:26:29 step 4: objective=1.808654 reg=0.002749
2017/08/29 13:26:32 step 5: objective=1.809768 reg=0.002748
2017/08/29 13:26:35 step 6: objective=1.810942 reg=0.002749
2017/08/29 13:26:38 step 7: objective=1.812119 reg=0.002748
2017/08/29 13:26:38 Training value function...
2017/08/29 13:26:42 step 0: mse=126.289298 step=0.100000
2017/08/29 13:26:43 step 1: mse=122.717214 step=0.100000
2017/08/29 13:26:45 step 2: mse=119.953673 step=0.100000
2017/08/29 13:26:47 step 3: mse=117.467223 step=0.100000
2017/08/29 13:26:48 step 4: mse=115.360552 step=0.100000
2017/08/29 13:26:50 step 5: mse=113.581130 step=0.100000
2017/08/29 13:26:52 step 6: mse=111.928039 step=0.100000
2017/08/29 13:26:54 step 7: mse=110.316223 step=0.100000
2017/08/29 13:26:54 Saving...
2017/08/29 13:26:54 Gathering batch of experience...
2017/08/29 13:27:42 batch 79: mean=260.222222 stddev=176.542374 entropy=0.277921 frames=6766 count=27
2017/08/29 13:27:42 Training policy...
2017/08/29 13:27:48 tune 0: objective=0.223780 reg=0.002779 prune=0
2017/08/29 13:27:52 tune 1: objective=0.226690 reg=0.002778 prune=0
2017/08/29 13:27:56 tune 2: objective=0.229579 reg=0.002777 prune=0
2017/08/29 13:27:59 tune 3: objective=0.232446 reg=0.002776 prune=0
2017/08/29 13:28:03 tune 4: objective=0.235293 reg=0.002775 prune=0
2017/08/29 13:28:06 tune 5: objective=0.238114 reg=0.002775 prune=0
2017/08/29 13:28:10 tune 6: objective=0.240805 reg=0.002774 prune=0
2017/08/29 13:28:14 tune 7: objective=0.243284 reg=0.002773 prune=0
2017/08/29 13:28:16 step 0: objective=0.245601 reg=0.002772
2017/08/29 13:28:19 step 1: objective=0.247796 reg=0.002771
2017/08/29 13:28:21 step 2: objective=0.251405 reg=0.002770
2017/08/29 13:28:23 step 3: objective=0.252709 reg=0.002769
2017/08/29 13:28:26 step 4: objective=0.255054 reg=0.002769
2017/08/29 13:28:28 step 5: objective=0.257674 reg=0.002769
2017/08/29 13:28:31 step 6: objective=0.258869 reg=0.002769
2017/08/29 13:28:33 step 7: objective=0.260184 reg=0.002769
2017/08/29 13:28:33 Training value function...
2017/08/29 13:28:36 step 0: mse=130.300741 step=0.100000
2017/08/29 13:28:37 step 1: mse=128.052241 step=0.100000
2017/08/29 13:28:39 step 2: mse=126.287853 step=0.100000
2017/08/29 13:28:40 step 3: mse=124.680081 step=0.100000
2017/08/29 13:28:41 step 4: mse=123.479924 step=0.100000
2017/08/29 13:28:43 step 5: mse=122.601211 step=0.100000
2017/08/29 13:28:44 step 6: mse=121.794847 step=0.100000
2017/08/29 13:28:46 step 7: mse=121.096123 step=0.100000
2017/08/29 13:28:46 Saving...
2017/08/29 13:28:46 Gathering batch of experience...
2017/08/29 13:29:32 batch 80: mean=318.772727 stddev=193.196304 entropy=0.278111 frames=6950 count=22
2017/08/29 13:29:32 Training policy...
2017/08/29 13:29:38 tune 0: objective=0.759337 reg=0.002781 prune=0
2017/08/29 13:29:42 tune 1: objective=0.761938 reg=0.002781 prune=0
2017/08/29 13:29:46 tune 2: objective=0.764524 reg=0.002781 prune=0
2017/08/29 13:29:50 tune 3: objective=0.767096 reg=0.002781 prune=0
2017/08/29 13:29:53 tune 4: objective=0.769652 reg=0.002780 prune=0
2017/08/29 13:29:57 tune 5: objective=0.771997 reg=0.002780 prune=0
2017/08/29 13:30:01 tune 6: objective=0.774288 reg=0.002780 prune=0
2017/08/29 13:30:05 tune 7: objective=0.776485 reg=0.002780 prune=0
2017/08/29 13:30:07 step 0: objective=0.778451 reg=0.002780
2017/08/29 13:30:09 step 1: objective=0.781818 reg=0.002780
2017/08/29 13:30:12 step 2: objective=0.783375 reg=0.002779
2017/08/29 13:30:14 step 3: objective=0.785409 reg=0.002779
2017/08/29 13:30:17 step 4: objective=0.787502 reg=0.002778
2017/08/29 13:30:19 step 5: objective=0.790090 reg=0.002778
2017/08/29 13:30:22 step 6: objective=0.791910 reg=0.002778
2017/08/29 13:30:24 step 7: objective=0.793822 reg=0.002777
2017/08/29 13:30:24 Training value function...
2017/08/29 13:30:27 step 0: mse=119.415251 step=0.100000
2017/08/29 13:30:29 step 1: mse=118.288861 step=0.100000
2017/08/29 13:30:30 step 2: mse=117.440810 step=0.100000
2017/08/29 13:30:32 step 3: mse=116.675624 step=0.100000
2017/08/29 13:30:33 step 4: mse=116.032703 step=0.100000
2017/08/29 13:30:34 step 5: mse=115.523619 step=0.100000
2017/08/29 13:30:36 step 6: mse=115.032648 step=0.100000
2017/08/29 13:30:37 step 7: mse=114.512250 step=0.100000
2017/08/29 13:30:37 Saving...
2017/08/29 13:30:37 Gathering batch of experience...
2017/08/29 13:31:21 batch 81: mean=286.625000 stddev=172.954429 entropy=0.268786 frames=6388 count=24
2017/08/29 13:31:21 Training policy...
2017/08/29 13:31:27 tune 0: objective=1.493417 reg=0.002688 prune=0
2017/08/29 13:31:31 tune 1: objective=1.497222 reg=0.002688 prune=0
2017/08/29 13:31:34 tune 2: objective=1.500997 reg=0.002688 prune=0
2017/08/29 13:31:38 tune 3: objective=1.504742 reg=0.002689 prune=0
2017/08/29 13:31:41 tune 4: objective=1.508294 reg=0.002689 prune=0
2017/08/29 13:31:44 tune 5: objective=1.511661 reg=0.002689 prune=0
2017/08/29 13:31:48 tune 6: objective=1.514938 reg=0.002689 prune=0
2017/08/29 13:31:51 tune 7: objective=1.517911 reg=0.002690 prune=0
2017/08/29 13:31:54 step 0: objective=1.520485 reg=0.002690
2017/08/29 13:31:56 step 1: objective=1.524430 reg=0.002690
2017/08/29 13:31:58 step 2: objective=1.527719 reg=0.002692
2017/08/29 13:32:00 step 3: objective=1.529552 reg=0.002691
2017/08/29 13:32:03 step 4: objective=1.531547 reg=0.002691
2017/08/29 13:32:05 step 5: objective=1.532994 reg=0.002691
2017/08/29 13:32:07 step 6: objective=1.535710 reg=0.002691
2017/08/29 13:32:09 step 7: objective=1.537003 reg=0.002692
2017/08/29 13:32:09 Training value function...
2017/08/29 13:32:12 step 0: mse=152.260980 step=0.100000
2017/08/29 13:32:13 step 1: mse=149.415259 step=0.100000
2017/08/29 13:32:15 step 2: mse=146.850964 step=0.100000
2017/08/29 13:32:16 step 3: mse=144.237508 step=0.100000
2017/08/29 13:32:17 step 4: mse=142.181830 step=0.100000
2017/08/29 13:32:19 step 5: mse=140.447677 step=0.100000
2017/08/29 13:32:20 step 6: mse=139.094087 step=0.100000
2017/08/29 13:32:21 step 7: mse=137.756938 step=0.100000
2017/08/29 13:32:21 Saving...
2017/08/29 13:32:22 Gathering batch of experience...
2017/08/29 13:33:03 batch 82: mean=287.217391 stddev=191.401003 entropy=0.276219 frames=6107 count=23
2017/08/29 13:33:03 Training policy...
2017/08/29 13:33:09 tune 0: objective=1.384721 reg=0.002762 prune=0
2017/08/29 13:33:12 tune 1: objective=1.387869 reg=0.002761 prune=0
2017/08/29 13:33:15 tune 2: objective=1.390984 reg=0.002760 prune=0
2017/08/29 13:33:19 tune 3: objective=1.394064 reg=0.002759 prune=0
2017/08/29 13:33:22 tune 4: objective=1.397113 reg=0.002758 prune=0
2017/08/29 13:33:25 tune 5: objective=1.400117 reg=0.002756 prune=0
2017/08/29 13:33:28 tune 6: objective=1.402965 reg=0.002755 prune=0
2017/08/29 13:33:32 tune 7: objective=1.405461 reg=0.002754 prune=0
2017/08/29 13:33:34 step 0: objective=1.407738 reg=0.002753
2017/08/29 13:33:36 step 1: objective=1.410670 reg=0.002752
2017/08/29 13:33:38 step 2: objective=1.412168 reg=0.002751
2017/08/29 13:33:40 step 3: objective=1.413972 reg=0.002750
2017/08/29 13:33:42 step 4: objective=1.416086 reg=0.002749
2017/08/29 13:33:45 step 5: objective=1.418012 reg=0.002748
2017/08/29 13:33:47 step 6: objective=1.419532 reg=0.002746
2017/08/29 13:33:49 step 7: objective=1.420670 reg=0.002746
2017/08/29 13:33:49 Training value function...
2017/08/29 13:33:51 step 0: mse=135.234005 step=0.100000
2017/08/29 13:33:53 step 1: mse=132.187532 step=0.100000
2017/08/29 13:33:54 step 2: mse=129.591332 step=0.100000
2017/08/29 13:33:55 step 3: mse=127.429264 step=0.100000
2017/08/29 13:33:57 step 4: mse=125.447054 step=0.100000
2017/08/29 13:33:58 step 5: mse=123.775012 step=0.100000
2017/08/29 13:33:59 step 6: mse=122.346696 step=0.100000
2017/08/29 13:34:00 step 7: mse=121.208989 step=0.100000
2017/08/29 13:34:00 Saving...
2017/08/29 13:34:01 Gathering batch of experience...
2017/08/29 13:34:49 batch 83: mean=297.260870 stddev=201.092282 entropy=0.266288 frames=6467 count=23
2017/08/29 13:34:49 Training policy...
2017/08/29 13:34:55 tune 0: objective=0.918465 reg=0.002663 prune=0
2017/08/29 13:34:58 tune 1: objective=0.922006 reg=0.002662 prune=0
2017/08/29 13:35:02 tune 2: objective=0.925505 reg=0.002662 prune=0
2017/08/29 13:35:05 tune 3: objective=0.928966 reg=0.002662 prune=0
2017/08/29 13:35:09 tune 4: objective=0.932380 reg=0.002661 prune=0
2017/08/29 13:35:12 tune 5: objective=0.935602 reg=0.002661 prune=0
2017/08/29 13:35:16 tune 6: objective=0.938517 reg=0.002661 prune=0
2017/08/29 13:35:19 tune 7: objective=0.941107 reg=0.002661 prune=0
2017/08/29 13:35:22 step 0: objective=0.943452 reg=0.002661
2017/08/29 13:35:24 step 1: objective=0.947806 reg=0.002660
2017/08/29 13:35:26 step 2: objective=0.949749 reg=0.002662
2017/08/29 13:35:28 step 3: objective=0.952240 reg=0.002661
2017/08/29 13:35:31 step 4: objective=0.953545 reg=0.002661
2017/08/29 13:35:33 step 5: objective=0.955368 reg=0.002662
2017/08/29 13:35:35 step 6: objective=0.957223 reg=0.002662
2017/08/29 13:35:38 step 7: objective=0.959778 reg=0.002662
2017/08/29 13:35:38 Training value function...
2017/08/29 13:35:40 step 0: mse=150.737958 step=0.100000
2017/08/29 13:35:42 step 1: mse=148.120296 step=0.100000
2017/08/29 13:35:43 step 2: mse=145.684659 step=0.100000
2017/08/29 13:35:44 step 3: mse=143.770827 step=0.100000
2017/08/29 13:35:46 step 4: mse=142.389684 step=0.100000
2017/08/29 13:35:47 step 5: mse=140.777658 step=0.100000
2017/08/29 13:35:48 step 6: mse=139.490714 step=0.100000
2017/08/29 13:35:50 step 7: mse=138.489194 step=0.100000
2017/08/29 13:35:50 Saving...
2017/08/29 13:35:50 Gathering batch of experience...
2017/08/29 13:36:41 batch 84: mean=346.791667 stddev=227.031382 entropy=0.272680 frames=7619 count=24
2017/08/29 13:36:41 Training policy...
2017/08/29 13:36:48 tune 0: objective=1.736483 reg=0.002727 prune=0
2017/08/29 13:36:52 tune 1: objective=1.738868 reg=0.002726 prune=0
2017/08/29 13:36:56 tune 2: objective=1.741239 reg=0.002726 prune=0
2017/08/29 13:37:00 tune 3: objective=1.743590 reg=0.002725 prune=0
2017/08/29 13:37:04 tune 4: objective=1.745926 reg=0.002725 prune=0
2017/08/29 13:37:09 tune 5: objective=1.748119 reg=0.002724 prune=0
2017/08/29 13:37:13 tune 6: objective=1.750238 reg=0.002724 prune=0
2017/08/29 13:37:17 tune 7: objective=1.752331 reg=0.002723 prune=0
2017/08/29 13:37:20 step 0: objective=1.754367 reg=0.002723
2017/08/29 13:37:22 step 1: objective=1.757313 reg=0.002723
2017/08/29 13:37:25 step 2: objective=1.759015 reg=0.002724
2017/08/29 13:37:28 step 3: objective=1.760299 reg=0.002723
2017/08/29 13:37:30 step 4: objective=1.761812 reg=0.002723
2017/08/29 13:37:33 step 5: objective=1.764002 reg=0.002722
2017/08/29 13:37:36 step 6: objective=1.765141 reg=0.002722
2017/08/29 13:37:39 step 7: objective=1.766762 reg=0.002722
2017/08/29 13:37:39 Training value function...
2017/08/29 13:37:42 step 0: mse=157.854075 step=0.100000
2017/08/29 13:37:43 step 1: mse=155.142954 step=0.100000
2017/08/29 13:37:45 step 2: mse=152.458158 step=0.100000
2017/08/29 13:37:47 step 3: mse=149.893124 step=0.100000
2017/08/29 13:37:48 step 4: mse=147.858399 step=0.100000
2017/08/29 13:37:50 step 5: mse=145.958162 step=0.100000
2017/08/29 13:37:51 step 6: mse=144.322827 step=0.100000
2017/08/29 13:37:53 step 7: mse=142.743489 step=0.100000
2017/08/29 13:37:53 Saving...
2017/08/29 13:37:53 Gathering batch of experience...
2017/08/29 13:38:48 batch 85: mean=294.428571 stddev=227.558694 entropy=0.280028 frames=7834 count=28
2017/08/29 13:38:48 Training policy...
2017/08/29 13:38:55 tune 0: objective=0.661878 reg=0.002800 prune=0
2017/08/29 13:38:59 tune 1: objective=0.664683 reg=0.002800 prune=0
2017/08/29 13:39:04 tune 2: objective=0.667465 reg=0.002800 prune=0
2017/08/29 13:39:08 tune 3: objective=0.670232 reg=0.002799 prune=0
2017/08/29 13:39:12 tune 4: objective=0.672980 reg=0.002799 prune=0
2017/08/29 13:39:16 tune 5: objective=0.675637 reg=0.002799 prune=0
2017/08/29 13:39:20 tune 6: objective=0.678166 reg=0.002798 prune=0
2017/08/29 13:39:25 tune 7: objective=0.680540 reg=0.002798 prune=0
2017/08/29 13:39:28 step 0: objective=0.682600 reg=0.002798
2017/08/29 13:39:30 step 1: objective=0.685027 reg=0.002798
2017/08/29 13:39:33 step 2: objective=0.686292 reg=0.002798
2017/08/29 13:39:36 step 3: objective=0.687885 reg=0.002798
2017/08/29 13:39:39 step 4: objective=0.690513 reg=0.002798
2017/08/29 13:39:42 step 5: objective=0.691827 reg=0.002798
2017/08/29 13:39:44 step 6: objective=0.693394 reg=0.002798
2017/08/29 13:39:47 step 7: objective=0.695508 reg=0.002797
2017/08/29 13:39:47 Training value function...
2017/08/29 13:39:50 step 0: mse=139.725810 step=0.100000
2017/08/29 13:39:52 step 1: mse=138.581615 step=0.100000
2017/08/29 13:39:54 step 2: mse=137.477234 step=0.100000
2017/08/29 13:39:55 step 3: mse=136.680302 step=0.100000
2017/08/29 13:39:57 step 4: mse=135.888662 step=0.100000
2017/08/29 13:39:59 step 5: mse=135.225975 step=0.100000
2017/08/29 13:40:00 step 6: mse=134.509065 step=0.100000
2017/08/29 13:40:02 step 7: mse=134.167201 step=0.100000
2017/08/29 13:40:02 Saving...
2017/08/29 13:40:02 Gathering batch of experience...
2017/08/29 13:40:52 batch 86: mean=312.375000 stddev=195.320636 entropy=0.273766 frames=7266 count=24
2017/08/29 13:40:52 Training policy...
2017/08/29 13:40:59 tune 0: objective=0.605878 reg=0.002738 prune=0
2017/08/29 13:41:03 tune 1: objective=0.608170 reg=0.002737 prune=0
2017/08/29 13:41:07 tune 2: objective=0.610450 reg=0.002737 prune=0
2017/08/29 13:41:11 tune 3: objective=0.612717 reg=0.002737 prune=0
2017/08/29 13:41:15 tune 4: objective=0.614968 reg=0.002737 prune=0
2017/08/29 13:41:19 tune 5: objective=0.617198 reg=0.002737 prune=0
2017/08/29 13:41:23 tune 6: objective=0.619351 reg=0.002737 prune=0
2017/08/29 13:41:27 tune 7: objective=0.621497 reg=0.002736 prune=0
2017/08/29 13:41:29 step 0: objective=0.623498 reg=0.002736
2017/08/29 13:41:32 step 1: objective=0.625173 reg=0.002736
2017/08/29 13:41:34 step 2: objective=0.627223 reg=0.002736
2017/08/29 13:41:37 step 3: objective=0.630282 reg=0.002736
2017/08/29 13:41:40 step 4: objective=0.632107 reg=0.002737
2017/08/29 13:41:42 step 5: objective=0.633626 reg=0.002737
2017/08/29 13:41:45 step 6: objective=0.634970 reg=0.002737
2017/08/29 13:41:47 step 7: objective=0.636573 reg=0.002736
2017/08/29 13:41:47 Training value function...
2017/08/29 13:41:50 step 0: mse=112.257344 step=0.100000
2017/08/29 13:41:52 step 1: mse=111.657342 step=0.100000
2017/08/29 13:41:53 step 2: mse=111.198464 step=0.100000
2017/08/29 13:41:55 step 3: mse=110.901673 step=0.100000
2017/08/29 13:41:56 step 4: mse=110.658692 step=0.100000
2017/08/29 13:41:58 step 5: mse=110.213559 step=0.100000
2017/08/29 13:41:59 step 6: mse=109.832852 step=0.100000
2017/08/29 13:42:01 step 7: mse=109.719858 step=0.100000
2017/08/29 13:42:01 Saving...
2017/08/29 13:42:01 Gathering batch of experience...
2017/08/29 13:42:40 batch 87: mean=406.750000 stddev=215.188435 entropy=0.279497 frames=5981 count=16
2017/08/29 13:42:40 Training policy...
2017/08/29 13:42:46 tune 0: objective=2.081469 reg=0.002795 prune=0
2017/08/29 13:42:49 tune 1: objective=2.084536 reg=0.002795 prune=0
2017/08/29 13:42:53 tune 2: objective=2.087584 reg=0.002794 prune=0
2017/08/29 13:42:56 tune 3: objective=2.090622 reg=0.002794 prune=0
2017/08/29 13:42:59 tune 4: objective=2.093643 reg=0.002793 prune=0
2017/08/29 13:43:02 tune 5: objective=2.096607 reg=0.002793 prune=0
2017/08/29 13:43:05 tune 6: objective=2.099380 reg=0.002792 prune=0
2017/08/29 13:43:09 tune 7: objective=2.101711 reg=0.002792 prune=0
2017/08/29 13:43:11 step 0: objective=2.103815 reg=0.002792
2017/08/29 13:43:13 step 1: objective=2.105689 reg=0.002792
2017/08/29 13:43:15 step 2: objective=2.107157 reg=0.002792
2017/08/29 13:43:17 step 3: objective=2.108925 reg=0.002792
2017/08/29 13:43:19 step 4: objective=2.110422 reg=0.002793
2017/08/29 13:43:21 step 5: objective=2.111736 reg=0.002792
2017/08/29 13:43:24 step 6: objective=2.113799 reg=0.002793
2017/08/29 13:43:26 step 7: objective=2.115786 reg=0.002793
2017/08/29 13:43:26 Training value function...
2017/08/29 13:43:28 step 0: mse=148.822566 step=0.100000
2017/08/29 13:43:29 step 1: mse=144.215479 step=0.100000
2017/08/29 13:43:31 step 2: mse=140.069379 step=0.100000
2017/08/29 13:43:32 step 3: mse=136.816107 step=0.100000
2017/08/29 13:43:33 step 4: mse=133.878362 step=0.100000
2017/08/29 13:43:34 step 5: mse=131.191236 step=0.100000
2017/08/29 13:43:36 step 6: mse=129.207543 step=0.100000
2017/08/29 13:43:37 step 7: mse=127.204842 step=0.100000
2017/08/29 13:43:37 Saving...
2017/08/29 13:43:37 Gathering batch of experience...
2017/08/29 13:44:23 batch 88: mean=377.888889 stddev=182.673628 entropy=0.275889 frames=6544 count=18
2017/08/29 13:44:23 Training policy...
2017/08/29 13:44:29 tune 0: objective=0.639602 reg=0.002759 prune=0
2017/08/29 13:44:33 tune 1: objective=0.642093 reg=0.002759 prune=0
2017/08/29 13:44:36 tune 2: objective=0.644565 reg=0.002760 prune=0
2017/08/29 13:44:40 tune 3: objective=0.647020 reg=0.002760 prune=0
2017/08/29 13:44:43 tune 4: objective=0.649457 reg=0.002761 prune=0
2017/08/29 13:44:47 tune 5: objective=0.651881 reg=0.002761 prune=0
2017/08/29 13:44:50 tune 6: objective=0.654198 reg=0.002762 prune=0
2017/08/29 13:44:54 tune 7: objective=0.656260 reg=0.002762 prune=0
2017/08/29 13:44:56 step 0: objective=0.658034 reg=0.002763
2017/08/29 13:44:58 step 1: objective=0.659638 reg=0.002763
2017/08/29 13:45:01 step 2: objective=0.661082 reg=0.002763
2017/08/29 13:45:03 step 3: objective=0.662908 reg=0.002763
2017/08/29 13:45:06 step 4: objective=0.664162 reg=0.002764
2017/08/29 13:45:08 step 5: objective=0.666144 reg=0.002765
2017/08/29 13:45:10 step 6: objective=0.667396 reg=0.002765
2017/08/29 13:45:13 step 7: objective=0.669619 reg=0.002764
2017/08/29 13:45:13 Training value function...
2017/08/29 13:45:15 step 0: mse=125.438474 step=0.100000
2017/08/29 13:45:17 step 1: mse=123.971341 step=0.100000
2017/08/29 13:45:18 step 2: mse=123.089698 step=0.100000
2017/08/29 13:45:19 step 3: mse=122.227032 step=0.100000
2017/08/29 13:45:21 step 4: mse=121.429281 step=0.100000
2017/08/29 13:45:22 step 5: mse=120.920114 step=0.100000
2017/08/29 13:45:23 step 6: mse=120.539845 step=0.100000
2017/08/29 13:45:25 step 7: mse=120.238157 step=0.100000
2017/08/29 13:45:25 Saving...
2017/08/29 13:45:25 Gathering batch of experience...
2017/08/29 13:46:09 batch 89: mean=318.714286 stddev=230.884045 entropy=0.269872 frames=6113 count=21
2017/08/29 13:46:09 Training policy...
2017/08/29 13:46:15 tune 0: objective=1.461602 reg=0.002699 prune=0
2017/08/29 13:46:18 tune 1: objective=1.465029 reg=0.002698 prune=0
2017/08/29 13:46:21 tune 2: objective=1.468427 reg=0.002697 prune=0
2017/08/29 13:46:25 tune 3: objective=1.471799 reg=0.002696 prune=0
2017/08/29 13:46:28 tune 4: objective=1.475083 reg=0.002696 prune=0
2017/08/29 13:46:31 tune 5: objective=1.477988 reg=0.002695 prune=0
2017/08/29 13:46:34 tune 6: objective=1.480610 reg=0.002694 prune=0
2017/08/29 13:46:38 tune 7: objective=1.483097 reg=0.002694 prune=0
2017/08/29 13:46:40 step 0: objective=1.485365 reg=0.002693
2017/08/29 13:46:42 step 1: objective=1.488302 reg=0.002693
2017/08/29 13:46:44 step 2: objective=1.491559 reg=0.002693
2017/08/29 13:46:47 step 3: objective=1.493711 reg=0.002692
2017/08/29 13:46:49 step 4: objective=1.494984 reg=0.002693
2017/08/29 13:46:51 step 5: objective=1.497240 reg=0.002693
2017/08/29 13:46:53 step 6: objective=1.498778 reg=0.002693
2017/08/29 13:46:55 step 7: objective=1.499853 reg=0.002693
2017/08/29 13:46:55 Training value function...
2017/08/29 13:46:58 step 0: mse=127.189741 step=0.100000
2017/08/29 13:46:59 step 1: mse=125.080360 step=0.100000
2017/08/29 13:47:00 step 2: mse=123.101172 step=0.100000
2017/08/29 13:47:02 step 3: mse=121.482888 step=0.100000
2017/08/29 13:47:03 step 4: mse=120.193686 step=0.100000
2017/08/29 13:47:04 step 5: mse=118.603605 step=0.100000
2017/08/29 13:47:05 step 6: mse=117.198183 step=0.100000
2017/08/29 13:47:07 step 7: mse=116.202963 step=0.100000
2017/08/29 13:47:07 Saving...
2017/08/29 13:47:07 Gathering batch of experience...
2017/08/29 13:47:52 batch 90: mean=293.956522 stddev=185.881327 entropy=0.269892 frames=6345 count=23
2017/08/29 13:47:52 Training policy...
2017/08/29 13:47:58 tune 0: objective=0.666836 reg=0.002699 prune=0
2017/08/29 13:48:01 tune 1: objective=0.669716 reg=0.002699 prune=0
2017/08/29 13:48:05 tune 2: objective=0.672566 reg=0.002699 prune=0
2017/08/29 13:48:08 tune 3: objective=0.675379 reg=0.002699 prune=0
2017/08/29 13:48:12 tune 4: objective=0.678163 reg=0.002698 prune=0
2017/08/29 13:48:15 tune 5: objective=0.680783 reg=0.002698 prune=0
2017/08/29 13:48:18 tune 6: objective=0.683147 reg=0.002698 prune=0
2017/08/29 13:48:22 tune 7: objective=0.685431 reg=0.002698 prune=0
2017/08/29 13:48:24 step 0: objective=0.687523 reg=0.002699
2017/08/29 13:48:26 step 1: objective=0.689500 reg=0.002698
2017/08/29 13:48:29 step 2: objective=0.691559 reg=0.002698
2017/08/29 13:48:31 step 3: objective=0.693296 reg=0.002698
2017/08/29 13:48:33 step 4: objective=0.695289 reg=0.002699
2017/08/29 13:48:35 step 5: objective=0.696906 reg=0.002699
2017/08/29 13:48:38 step 6: objective=0.697963 reg=0.002699
2017/08/29 13:48:40 step 7: objective=0.699757 reg=0.002699
2017/08/29 13:48:40 Training value function...
2017/08/29 13:48:43 step 0: mse=119.069680 step=0.100000
2017/08/29 13:48:44 step 1: mse=118.106511 step=0.100000
2017/08/29 13:48:45 step 2: mse=117.399373 step=0.100000
2017/08/29 13:48:47 step 3: mse=116.721499 step=0.100000
2017/08/29 13:48:48 step 4: mse=116.437186 step=0.100000
2017/08/29 13:48:49 step 5: mse=116.072570 step=0.100000
2017/08/29 13:48:50 step 6: mse=115.618715 step=0.100000
2017/08/29 13:48:52 step 7: mse=115.157644 step=0.100000
2017/08/29 13:48:52 Saving...
2017/08/29 13:48:52 Gathering batch of experience...
2017/08/29 13:49:41 batch 91: mean=357.350000 stddev=210.805189 entropy=0.272416 frames=6665 count=20
2017/08/29 13:49:41 Training policy...
2017/08/29 13:49:47 tune 0: objective=1.426282 reg=0.002724 prune=0
2017/08/29 13:49:51 tune 1: objective=1.429039 reg=0.002724 prune=0
2017/08/29 13:49:55 tune 2: objective=1.431763 reg=0.002724 prune=0
2017/08/29 13:49:58 tune 3: objective=1.434465 reg=0.002724 prune=0
2017/08/29 13:50:02 tune 4: objective=1.437077 reg=0.002723 prune=0
2017/08/29 13:50:05 tune 5: objective=1.439537 reg=0.002723 prune=0
2017/08/29 13:50:09 tune 6: objective=1.441881 reg=0.002723 prune=0
2017/08/29 13:50:13 tune 7: objective=1.444036 reg=0.002723 prune=0
2017/08/29 13:50:15 step 0: objective=1.446146 reg=0.002723
2017/08/29 13:50:17 step 1: objective=1.448529 reg=0.002722
2017/08/29 13:50:20 step 2: objective=1.450504 reg=0.002722
2017/08/29 13:50:22 step 3: objective=1.453380 reg=0.002721
2017/08/29 13:50:25 step 4: objective=1.454977 reg=0.002721
2017/08/29 13:50:27 step 5: objective=1.456286 reg=0.002721
2017/08/29 13:50:29 step 6: objective=1.458347 reg=0.002721
2017/08/29 13:50:32 step 7: objective=1.460212 reg=0.002720
2017/08/29 13:50:32 Training value function...
2017/08/29 13:50:34 step 0: mse=136.632524 step=0.100000
2017/08/29 13:50:36 step 1: mse=134.740254 step=0.100000
2017/08/29 13:50:37 step 2: mse=133.289403 step=0.100000
2017/08/29 13:50:39 step 3: mse=131.973213 step=0.100000
2017/08/29 13:50:40 step 4: mse=130.901174 step=0.100000
2017/08/29 13:50:41 step 5: mse=129.500494 step=0.100000
2017/08/29 13:50:43 step 6: mse=128.557045 step=0.100000
2017/08/29 13:50:44 step 7: mse=127.461774 step=0.100000
2017/08/29 13:50:44 Saving...
2017/08/29 13:50:44 Gathering batch of experience...
2017/08/29 13:51:37 batch 92: mean=350.080000 stddev=242.709360 entropy=0.269321 frames=7820 count=25
2017/08/29 13:51:37 Training policy...
2017/08/29 13:51:44 tune 0: objective=1.717309 reg=0.002693 prune=0
2017/08/29 13:51:49 tune 1: objective=1.719925 reg=0.002693 prune=0
2017/08/29 13:51:53 tune 2: objective=1.722532 reg=0.002694 prune=0
2017/08/29 13:51:57 tune 3: objective=1.725125 reg=0.002694 prune=0
2017/08/29 13:52:01 tune 4: objective=1.727711 reg=0.002694 prune=0
2017/08/29 13:52:06 tune 5: objective=1.730285 reg=0.002694 prune=0
2017/08/29 13:52:10 tune 6: objective=1.732763 reg=0.002694 prune=0
2017/08/29 13:52:14 tune 7: objective=1.735113 reg=0.002695 prune=0
2017/08/29 13:52:17 step 0: objective=1.737332 reg=0.002695
2017/08/29 13:52:20 step 1: objective=1.740628 reg=0.002696
2017/08/29 13:52:23 step 2: objective=1.743163 reg=0.002695
2017/08/29 13:52:25 step 3: objective=1.744134 reg=0.002695
2017/08/29 13:52:28 step 4: objective=1.745308 reg=0.002694
2017/08/29 13:52:31 step 5: objective=1.747604 reg=0.002693
2017/08/29 13:52:34 step 6: objective=1.749384 reg=0.002693
2017/08/29 13:52:37 step 7: objective=1.750339 reg=0.002692
2017/08/29 13:52:37 Training value function...
2017/08/29 13:52:40 step 0: mse=170.419264 step=0.100000
2017/08/29 13:52:42 step 1: mse=167.648253 step=0.100000
2017/08/29 13:52:43 step 2: mse=165.385020 step=0.100000
2017/08/29 13:52:45 step 3: mse=163.389904 step=0.100000
2017/08/29 13:52:46 step 4: mse=161.590257 step=0.100000
2017/08/29 13:52:48 step 5: mse=160.164697 step=0.100000
2017/08/29 13:52:50 step 6: mse=158.556935 step=0.100000
2017/08/29 13:52:51 step 7: mse=157.198600 step=0.100000
2017/08/29 13:52:51 Saving...
2017/08/29 13:52:51 Gathering batch of experience...
2017/08/29 13:53:45 batch 93: mean=358.565217 stddev=202.544000 entropy=0.272118 frames=7830 count=23
2017/08/29 13:53:45 Training policy...
2017/08/29 13:53:52 tune 0: objective=0.542492 reg=0.002721 prune=0
2017/08/29 13:53:57 tune 1: objective=0.544802 reg=0.002721 prune=0
2017/08/29 13:54:01 tune 2: objective=0.547098 reg=0.002721 prune=0
2017/08/29 13:54:05 tune 3: objective=0.549380 reg=0.002722 prune=0
2017/08/29 13:54:09 tune 4: objective=0.551649 reg=0.002722 prune=0
2017/08/29 13:54:14 tune 5: objective=0.553905 reg=0.002722 prune=0
2017/08/29 13:54:18 tune 6: objective=0.556139 reg=0.002722 prune=0
2017/08/29 13:54:22 tune 7: objective=0.558253 reg=0.002722 prune=0
2017/08/29 13:54:25 step 0: objective=0.560174 reg=0.002722
2017/08/29 13:54:28 step 1: objective=0.561821 reg=0.002722
2017/08/29 13:54:31 step 2: objective=0.563436 reg=0.002723
2017/08/29 13:54:34 step 3: objective=0.565283 reg=0.002723
2017/08/29 13:54:36 step 4: objective=0.566356 reg=0.002724
2017/08/29 13:54:39 step 5: objective=0.567829 reg=0.002724
2017/08/29 13:54:42 step 6: objective=0.568748 reg=0.002724
2017/08/29 13:54:45 step 7: objective=0.570902 reg=0.002724
2017/08/29 13:54:45 Training value function...
2017/08/29 13:54:48 step 0: mse=117.073152 step=0.100000
2017/08/29 13:54:50 step 1: mse=116.085357 step=0.100000
2017/08/29 13:54:51 step 2: mse=115.272314 step=0.100000
2017/08/29 13:54:53 step 3: mse=114.514432 step=0.100000
2017/08/29 13:54:55 step 4: mse=113.961070 step=0.100000
2017/08/29 13:54:56 step 5: mse=113.647091 step=0.100000
2017/08/29 13:54:58 step 6: mse=113.415463 step=0.100000
2017/08/29 13:55:00 step 7: mse=113.071652 step=0.100000
2017/08/29 13:55:00 Saving...
2017/08/29 13:55:00 Gathering batch of experience...
2017/08/29 13:55:52 batch 94: mean=292.428571 stddev=235.605516 entropy=0.277081 frames=7649 count=28
2017/08/29 13:55:52 Training policy...
2017/08/29 13:55:59 tune 0: objective=0.912016 reg=0.002771 prune=0
2017/08/29 13:56:04 tune 1: objective=0.914899 reg=0.002770 prune=0
2017/08/29 13:56:08 tune 2: objective=0.917757 reg=0.002770 prune=0
2017/08/29 13:56:12 tune 3: objective=0.920590 reg=0.002770 prune=0
2017/08/29 13:56:16 tune 4: objective=0.923406 reg=0.002769 prune=0
2017/08/29 13:56:20 tune 5: objective=0.926198 reg=0.002769 prune=0
2017/08/29 13:56:25 tune 6: objective=0.928810 reg=0.002769 prune=0
2017/08/29 13:56:29 tune 7: objective=0.931038 reg=0.002768 prune=0
2017/08/29 13:56:31 step 0: objective=0.933148 reg=0.002768
2017/08/29 13:56:34 step 1: objective=0.936063 reg=0.002768
2017/08/29 13:56:37 step 2: objective=0.938168 reg=0.002768
2017/08/29 13:56:40 step 3: objective=0.941230 reg=0.002767
2017/08/29 13:56:43 step 4: objective=0.944743 reg=0.002768
2017/08/29 13:56:45 step 5: objective=0.945878 reg=0.002768
2017/08/29 13:56:48 step 6: objective=0.946804 reg=0.002768
2017/08/29 13:56:51 step 7: objective=0.948870 reg=0.002767
2017/08/29 13:56:51 Training value function...
2017/08/29 13:56:54 step 0: mse=136.366095 step=0.100000
2017/08/29 13:56:56 step 1: mse=135.101880 step=0.100000
2017/08/29 13:56:57 step 2: mse=133.706252 step=0.100000
2017/08/29 13:56:59 step 3: mse=132.411524 step=0.100000
2017/08/29 13:57:00 step 4: mse=131.434034 step=0.100000
2017/08/29 13:57:02 step 5: mse=130.815063 step=0.100000
2017/08/29 13:57:04 step 6: mse=130.117171 step=0.100000
2017/08/29 13:57:05 step 7: mse=129.340489 step=0.100000
2017/08/29 13:57:05 Saving...
2017/08/29 13:57:05 Gathering batch of experience...
2017/08/29 13:57:54 batch 95: mean=375.428571 stddev=199.864376 entropy=0.271514 frames=7293 count=21
2017/08/29 13:57:54 Training policy...
2017/08/29 13:58:01 tune 0: objective=1.248956 reg=0.002715 prune=0
2017/08/29 13:58:05 tune 1: objective=1.251457 reg=0.002715 prune=0
2017/08/29 13:58:09 tune 2: objective=1.253945 reg=0.002715 prune=0
2017/08/29 13:58:13 tune 3: objective=1.256417 reg=0.002716 prune=0
2017/08/29 13:58:17 tune 4: objective=1.258874 reg=0.002716 prune=0
2017/08/29 13:58:21 tune 5: objective=1.261318 reg=0.002716 prune=0
2017/08/29 13:58:25 tune 6: objective=1.263724 reg=0.002716 prune=0
2017/08/29 13:58:29 tune 7: objective=1.265924 reg=0.002716 prune=0
2017/08/29 13:58:32 step 0: objective=1.267858 reg=0.002717
2017/08/29 13:58:35 step 1: objective=1.270342 reg=0.002717
2017/08/29 13:58:37 step 2: objective=1.272893 reg=0.002717
2017/08/29 13:58:40 step 3: objective=1.274122 reg=0.002717
2017/08/29 13:58:42 step 4: objective=1.275735 reg=0.002717
2017/08/29 13:58:45 step 5: objective=1.277417 reg=0.002718
2017/08/29 13:58:48 step 6: objective=1.278529 reg=0.002719
2017/08/29 13:58:50 step 7: objective=1.279723 reg=0.002720
2017/08/29 13:58:50 Training value function...
2017/08/29 13:58:53 step 0: mse=142.446439 step=0.100000
2017/08/29 13:58:55 step 1: mse=139.909552 step=0.100000
2017/08/29 13:58:56 step 2: mse=137.724554 step=0.100000
2017/08/29 13:58:58 step 3: mse=135.935938 step=0.100000
2017/08/29 13:58:59 step 4: mse=134.471412 step=0.100000
2017/08/29 13:59:01 step 5: mse=133.112000 step=0.100000
2017/08/29 13:59:03 step 6: mse=131.469672 step=0.100000
2017/08/29 13:59:04 step 7: mse=130.366387 step=0.100000
2017/08/29 13:59:04 Saving...
2017/08/29 13:59:04 Gathering batch of experience...
2017/08/29 13:59:47 batch 96: mean=299.045455 stddev=200.062144 entropy=0.265789 frames=6183 count=22
2017/08/29 13:59:47 Training policy...
2017/08/29 13:59:53 tune 0: objective=0.715932 reg=0.002658 prune=0
2017/08/29 13:59:57 tune 1: objective=0.719891 reg=0.002658 prune=0
2017/08/29 14:00:00 tune 2: objective=0.723760 reg=0.002658 prune=0
2017/08/29 14:00:03 tune 3: objective=0.727546 reg=0.002658 prune=0
2017/08/29 14:00:07 tune 4: objective=0.730825 reg=0.002658 prune=0
2017/08/29 14:00:10 tune 5: objective=0.733400 reg=0.002658 prune=0
2017/08/29 14:00:13 tune 6: objective=0.735769 reg=0.002658 prune=0
2017/08/29 14:00:17 tune 7: objective=0.737934 reg=0.002658 prune=0
2017/08/29 14:00:19 step 0: objective=0.739994 reg=0.002658
2017/08/29 14:00:21 step 1: objective=0.741951 reg=0.002658
2017/08/29 14:00:23 step 2: objective=0.743579 reg=0.002659
2017/08/29 14:00:26 step 3: objective=0.744940 reg=0.002659
2017/08/29 14:00:28 step 4: objective=0.746521 reg=0.002659
2017/08/29 14:00:30 step 5: objective=0.747891 reg=0.002658
2017/08/29 14:00:32 step 6: objective=0.749865 reg=0.002658
2017/08/29 14:00:35 step 7: objective=0.751446 reg=0.002657
2017/08/29 14:00:35 Training value function...
2017/08/29 14:00:37 step 0: mse=125.982507 step=0.100000
2017/08/29 14:00:38 step 1: mse=124.650286 step=0.100000
2017/08/29 14:00:40 step 2: mse=123.363422 step=0.100000
2017/08/29 14:00:41 step 3: mse=122.636935 step=0.100000
2017/08/29 14:00:42 step 4: mse=121.722589 step=0.100000
2017/08/29 14:00:44 step 5: mse=120.876590 step=0.100000
2017/08/29 14:00:45 step 6: mse=120.374153 step=0.100000
2017/08/29 14:00:46 step 7: mse=119.539933 step=0.100000
2017/08/29 14:00:46 Saving...
2017/08/29 14:00:46 Gathering batch of experience...
2017/08/29 14:01:34 batch 97: mean=337.086957 stddev=200.079531 entropy=0.268504 frames=7168 count=23
2017/08/29 14:01:34 Training policy...
2017/08/29 14:01:41 tune 0: objective=1.278986 reg=0.002685 prune=0
2017/08/29 14:01:45 tune 1: objective=1.281698 reg=0.002685 prune=0
2017/08/29 14:01:48 tune 2: objective=1.284395 reg=0.002685 prune=0
2017/08/29 14:01:52 tune 3: objective=1.287063 reg=0.002684 prune=0
2017/08/29 14:01:56 tune 4: objective=1.289713 reg=0.002684 prune=0
2017/08/29 14:02:00 tune 5: objective=1.292223 reg=0.002684 prune=0
2017/08/29 14:02:04 tune 6: objective=1.294573 reg=0.002684 prune=0
2017/08/29 14:02:08 tune 7: objective=1.296848 reg=0.002684 prune=0
2017/08/29 14:02:11 step 0: objective=1.298998 reg=0.002684
2017/08/29 14:02:13 step 1: objective=1.301239 reg=0.002684
2017/08/29 14:02:16 step 2: objective=1.303499 reg=0.002683
2017/08/29 14:02:18 step 3: objective=1.305362 reg=0.002682
2017/08/29 14:02:21 step 4: objective=1.306688 reg=0.002681
2017/08/29 14:02:24 step 5: objective=1.308783 reg=0.002681
2017/08/29 14:02:26 step 6: objective=1.309802 reg=0.002681
2017/08/29 14:02:29 step 7: objective=1.310810 reg=0.002680
2017/08/29 14:02:29 Training value function...
2017/08/29 14:02:32 step 0: mse=130.880670 step=0.100000
2017/08/29 14:02:33 step 1: mse=128.685269 step=0.100000
2017/08/29 14:02:35 step 2: mse=126.548647 step=0.100000
2017/08/29 14:02:36 step 3: mse=124.860502 step=0.100000
2017/08/29 14:02:38 step 4: mse=123.639393 step=0.100000
2017/08/29 14:02:39 step 5: mse=122.189969 step=0.100000
2017/08/29 14:02:41 step 6: mse=121.285613 step=0.100000
2017/08/29 14:02:42 step 7: mse=120.438302 step=0.100000
2017/08/29 14:02:42 Saving...
2017/08/29 14:02:42 Gathering batch of experience...
2017/08/29 14:03:31 batch 98: mean=299.080000 stddev=170.506052 entropy=0.269579 frames=7067 count=25
2017/08/29 14:03:31 Training policy...
2017/08/29 14:03:38 tune 0: objective=0.647766 reg=0.002696 prune=0
2017/08/29 14:03:41 tune 1: objective=0.651318 reg=0.002694 prune=0
2017/08/29 14:03:45 tune 2: objective=0.654789 reg=0.002693 prune=0
2017/08/29 14:03:49 tune 3: objective=0.658153 reg=0.002691 prune=0
2017/08/29 14:03:53 tune 4: objective=0.661022 reg=0.002690 prune=0
2017/08/29 14:03:57 tune 5: objective=0.663402 reg=0.002689 prune=0
2017/08/29 14:04:01 tune 6: objective=0.665722 reg=0.002688 prune=0
2017/08/29 14:04:05 tune 7: objective=0.667990 reg=0.002688 prune=0
2017/08/29 14:04:07 step 0: objective=0.670097 reg=0.002687
2017/08/29 14:04:10 step 1: objective=0.673623 reg=0.002687
2017/08/29 14:04:12 step 2: objective=0.675084 reg=0.002686
2017/08/29 14:04:15 step 3: objective=0.676904 reg=0.002686
2017/08/29 14:04:17 step 4: objective=0.678595 reg=0.002686
2017/08/29 14:04:20 step 5: objective=0.680146 reg=0.002686
2017/08/29 14:04:23 step 6: objective=0.681301 reg=0.002686
2017/08/29 14:04:25 step 7: objective=0.683758 reg=0.002686
2017/08/29 14:04:25 Training value function...
2017/08/29 14:04:28 step 0: mse=140.214891 step=0.100000
2017/08/29 14:04:29 step 1: mse=138.322860 step=0.100000
2017/08/29 14:04:31 step 2: mse=137.020308 step=0.100000
2017/08/29 14:04:32 step 3: mse=135.978552 step=0.100000
2017/08/29 14:04:34 step 4: mse=135.111034 step=0.100000
2017/08/29 14:04:35 step 5: mse=133.980880 step=0.100000
2017/08/29 14:04:37 step 6: mse=133.219376 step=0.100000
2017/08/29 14:04:38 step 7: mse=132.463027 step=0.100000
2017/08/29 14:04:38 Saving...
2017/08/29 14:04:38 Gathering batch of experience...
2017/08/29 14:05:23 batch 99: mean=288.840000 stddev=196.861104 entropy=0.269628 frames=6732 count=25
2017/08/29 14:05:23 Training policy...
2017/08/29 14:05:30 tune 0: objective=1.119406 reg=0.002696 prune=0
2017/08/29 14:05:34 tune 1: objective=1.121992 reg=0.002695 prune=0
2017/08/29 14:05:37 tune 2: objective=1.124556 reg=0.002694 prune=0
2017/08/29 14:05:41 tune 3: objective=1.127102 reg=0.002694 prune=0
2017/08/29 14:05:45 tune 4: objective=1.129618 reg=0.002693 prune=0
2017/08/29 14:05:48 tune 5: objective=1.132022 reg=0.002692 prune=0
2017/08/29 14:05:52 tune 6: objective=1.134382 reg=0.002691 prune=0
2017/08/29 14:05:56 tune 7: objective=1.136595 reg=0.002690 prune=0
2017/08/29 14:05:58 step 0: objective=1.138646 reg=0.002689
2017/08/29 14:06:00 step 1: objective=1.142401 reg=0.002689
2017/08/29 14:06:03 step 2: objective=1.143610 reg=0.002689
2017/08/29 14:06:05 step 3: objective=1.145327 reg=0.002689
2017/08/29 14:06:08 step 4: objective=1.147999 reg=0.002688
2017/08/29 14:06:10 step 5: objective=1.149378 reg=0.002688
2017/08/29 14:06:13 step 6: objective=1.150294 reg=0.002687
2017/08/29 14:06:15 step 7: objective=1.151983 reg=0.002687
2017/08/29 14:06:15 Training value function...
2017/08/29 14:06:18 step 0: mse=125.261713 step=0.100000
2017/08/29 14:06:19 step 1: mse=122.925583 step=0.100000
2017/08/29 14:06:21 step 2: mse=121.375771 step=0.100000
2017/08/29 14:06:22 step 3: mse=119.832811 step=0.100000
2017/08/29 14:06:24 step 4: mse=118.515806 step=0.100000
2017/08/29 14:06:25 step 5: mse=117.134125 step=0.100000
2017/08/29 14:06:26 step 6: mse=115.943026 step=0.100000
2017/08/29 14:06:28 step 7: mse=114.907522 step=0.100000
2017/08/29 14:06:28 Saving...
2017/08/29 14:06:28 Gathering batch of experience...
2017/08/29 14:07:18 batch 100: mean=377.714286 stddev=208.590541 entropy=0.269694 frames=7263 count=21
2017/08/29 14:07:18 Training policy...
2017/08/29 14:07:25 tune 0: objective=1.653065 reg=0.002697 prune=0
2017/08/29 14:07:29 tune 1: objective=1.655465 reg=0.002697 prune=0
2017/08/29 14:07:33 tune 2: objective=1.657850 reg=0.002697 prune=0
2017/08/29 14:07:37 tune 3: objective=1.660230 reg=0.002698 prune=0
2017/08/29 14:07:41 tune 4: objective=1.662591 reg=0.002698 prune=0
2017/08/29 14:07:45 tune 5: objective=1.664947 reg=0.002698 prune=0
2017/08/29 14:07:49 tune 6: objective=1.667016 reg=0.002699 prune=0
2017/08/29 14:07:53 tune 7: objective=1.668869 reg=0.002699 prune=0
2017/08/29 14:07:55 step 0: objective=1.670660 reg=0.002699
2017/08/29 14:07:58 step 1: objective=1.672464 reg=0.002698
2017/08/29 14:08:01 step 2: objective=1.673910 reg=0.002699
2017/08/29 14:08:03 step 3: objective=1.675198 reg=0.002699
2017/08/29 14:08:06 step 4: objective=1.676449 reg=0.002699
2017/08/29 14:08:09 step 5: objective=1.678882 reg=0.002699
2017/08/29 14:08:11 step 6: objective=1.679981 reg=0.002698
2017/08/29 14:08:14 step 7: objective=1.681049 reg=0.002698
2017/08/29 14:08:14 Training value function...
2017/08/29 14:08:17 step 0: mse=140.658017 step=0.100000
2017/08/29 14:08:18 step 1: mse=137.348833 step=0.100000
2017/08/29 14:08:20 step 2: mse=134.682647 step=0.100000
2017/08/29 14:08:21 step 3: mse=132.866165 step=0.100000
2017/08/29 14:08:23 step 4: mse=130.596896 step=0.100000
2017/08/29 14:08:24 step 5: mse=128.840651 step=0.100000
2017/08/29 14:08:26 step 6: mse=127.190723 step=0.100000
2017/08/29 14:08:27 step 7: mse=125.719178 step=0.100000
2017/08/29 14:08:27 Saving...
2017/08/29 14:08:28 Gathering batch of experience...
2017/08/29 14:09:17 batch 101: mean=447.888889 stddev=162.610266 entropy=0.276562 frames=7681 count=18
2017/08/29 14:09:17 Training policy...
2017/08/29 14:09:25 tune 0: objective=0.955674 reg=0.002766 prune=0
2017/08/29 14:09:29 tune 1: objective=0.958016 reg=0.002765 prune=0
2017/08/29 14:09:33 tune 2: objective=0.960343 reg=0.002765 prune=0
2017/08/29 14:09:38 tune 3: objective=0.962653 reg=0.002765 prune=0
2017/08/29 14:09:42 tune 4: objective=0.964950 reg=0.002765 prune=0
2017/08/29 14:09:46 tune 5: objective=0.967185 reg=0.002765 prune=0
2017/08/29 14:09:50 tune 6: objective=0.969250 reg=0.002765 prune=0
2017/08/29 14:09:54 tune 7: objective=0.971164 reg=0.002765 prune=0
2017/08/29 14:09:57 step 0: objective=0.973004 reg=0.002765
2017/08/29 14:10:00 step 1: objective=0.975301 reg=0.002765
2017/08/29 14:10:03 step 2: objective=0.976656 reg=0.002764
2017/08/29 14:10:06 step 3: objective=0.979377 reg=0.002764
2017/08/29 14:10:08 step 4: objective=0.980331 reg=0.002765
2017/08/29 14:10:11 step 5: objective=0.982069 reg=0.002765
2017/08/29 14:10:14 step 6: objective=0.984328 reg=0.002765
2017/08/29 14:10:17 step 7: objective=0.985236 reg=0.002764
2017/08/29 14:10:17 Training value function...
2017/08/29 14:10:20 step 0: mse=125.624353 step=0.100000
2017/08/29 14:10:21 step 1: mse=123.374656 step=0.100000
2017/08/29 14:10:23 step 2: mse=121.604531 step=0.100000
2017/08/29 14:10:25 step 3: mse=120.062199 step=0.100000
2017/08/29 14:10:26 step 4: mse=118.483312 step=0.100000
2017/08/29 14:10:28 step 5: mse=117.266373 step=0.100000
2017/08/29 14:10:30 step 6: mse=116.208403 step=0.100000
2017/08/29 14:10:31 step 7: mse=115.642128 step=0.100000
2017/08/29 14:10:31 Saving...
2017/08/29 14:10:31 Gathering batch of experience...
2017/08/29 14:11:18 batch 102: mean=340.545455 stddev=191.937662 entropy=0.269470 frames=7118 count=22
2017/08/29 14:11:18 Training policy...
2017/08/29 14:11:25 tune 0: objective=0.651714 reg=0.002695 prune=0
2017/08/29 14:11:29 tune 1: objective=0.653935 reg=0.002695 prune=0
2017/08/29 14:11:33 tune 2: objective=0.656143 reg=0.002694 prune=0
2017/08/29 14:11:37 tune 3: objective=0.658338 reg=0.002694 prune=0
2017/08/29 14:11:41 tune 4: objective=0.660523 reg=0.002694 prune=0
2017/08/29 14:11:45 tune 5: objective=0.662630 reg=0.002694 prune=0
2017/08/29 14:11:49 tune 6: objective=0.664710 reg=0.002694 prune=0
2017/08/29 14:11:53 tune 7: objective=0.666782 reg=0.002694 prune=0
2017/08/29 14:11:55 step 0: objective=0.668745 reg=0.002693
2017/08/29 14:11:58 step 1: objective=0.670035 reg=0.002693
2017/08/29 14:12:00 step 2: objective=0.671524 reg=0.002693
2017/08/29 14:12:03 step 3: objective=0.672989 reg=0.002692
2017/08/29 14:12:05 step 4: objective=0.674029 reg=0.002692
2017/08/29 14:12:08 step 5: objective=0.675245 reg=0.002692
2017/08/29 14:12:11 step 6: objective=0.676527 reg=0.002691
2017/08/29 14:12:13 step 7: objective=0.678135 reg=0.002692
2017/08/29 14:12:13 Training value function...
2017/08/29 14:12:16 step 0: mse=115.021095 step=0.100000
2017/08/29 14:12:18 step 1: mse=113.853585 step=0.100000
2017/08/29 14:12:19 step 2: mse=112.893043 step=0.100000
2017/08/29 14:12:21 step 3: mse=112.122349 step=0.100000
2017/08/29 14:12:22 step 4: mse=111.612071 step=0.100000
2017/08/29 14:12:24 step 5: mse=111.162966 step=0.100000
2017/08/29 14:12:25 step 6: mse=110.741719 step=0.100000
2017/08/29 14:12:27 step 7: mse=110.098542 step=0.100000
2017/08/29 14:12:27 Saving...
2017/08/29 14:12:27 Gathering batch of experience...
2017/08/29 14:13:14 batch 103: mean=291.130435 stddev=188.743973 entropy=0.272836 frames=6607 count=23
2017/08/29 14:13:14 Training policy...
2017/08/29 14:13:21 tune 0: objective=0.350809 reg=0.002728 prune=0
2017/08/29 14:13:24 tune 1: objective=0.354062 reg=0.002728 prune=0
2017/08/29 14:13:28 tune 2: objective=0.357276 reg=0.002727 prune=0
2017/08/29 14:13:32 tune 3: objective=0.360454 reg=0.002727 prune=0
2017/08/29 14:13:35 tune 4: objective=0.363499 reg=0.002727 prune=0
2017/08/29 14:13:39 tune 5: objective=0.366369 reg=0.002726 prune=0
2017/08/29 14:13:42 tune 6: objective=0.368930 reg=0.002726 prune=0
2017/08/29 14:13:46 tune 7: objective=0.371275 reg=0.002725 prune=0
2017/08/29 14:13:48 step 0: objective=0.373431 reg=0.002725
2017/08/29 14:13:51 step 1: objective=0.375595 reg=0.002725
2017/08/29 14:13:53 step 2: objective=0.377294 reg=0.002725
2017/08/29 14:13:56 step 3: objective=0.378600 reg=0.002725
2017/08/29 14:13:58 step 4: objective=0.379999 reg=0.002725
2017/08/29 14:14:00 step 5: objective=0.381553 reg=0.002724
2017/08/29 14:14:03 step 6: objective=0.383067 reg=0.002724
2017/08/29 14:14:05 step 7: objective=0.384593 reg=0.002725
2017/08/29 14:14:05 Training value function...
2017/08/29 14:14:08 step 0: mse=123.832109 step=0.100000
2017/08/29 14:14:09 step 1: mse=121.659887 step=0.100000
2017/08/29 14:14:11 step 2: mse=119.978627 step=0.100000
2017/08/29 14:14:12 step 3: mse=118.486785 step=0.100000
2017/08/29 14:14:13 step 4: mse=117.297392 step=0.100000
2017/08/29 14:14:15 step 5: mse=116.146229 step=0.100000
2017/08/29 14:14:16 step 6: mse=115.436430 step=0.100000
2017/08/29 14:14:18 step 7: mse=114.629694 step=0.100000
2017/08/29 14:14:18 Saving...
2017/08/29 14:14:18 Gathering batch of experience...
2017/08/29 14:15:06 batch 104: mean=253.269231 stddev=194.039361 entropy=0.269663 frames=6450 count=26
2017/08/29 14:15:06 Training policy...
2017/08/29 14:15:12 tune 0: objective=0.512510 reg=0.002697 prune=0
2017/08/29 14:15:16 tune 1: objective=0.516281 reg=0.002696 prune=0
2017/08/29 14:15:19 tune 2: objective=0.519972 reg=0.002695 prune=0
2017/08/29 14:15:23 tune 3: objective=0.523541 reg=0.002694 prune=0
2017/08/29 14:15:26 tune 4: objective=0.526763 reg=0.002693 prune=0
2017/08/29 14:15:30 tune 5: objective=0.529469 reg=0.002693 prune=0
2017/08/29 14:15:33 tune 6: objective=0.531839 reg=0.002692 prune=0
2017/08/29 14:15:37 tune 7: objective=0.534081 reg=0.002692 prune=0
2017/08/29 14:15:39 step 0: objective=0.536284 reg=0.002692
2017/08/29 14:15:42 step 1: objective=0.539321 reg=0.002693
2017/08/29 14:15:44 step 2: objective=0.540813 reg=0.002692
2017/08/29 14:15:46 step 3: objective=0.542109 reg=0.002692
2017/08/29 14:15:49 step 4: objective=0.543638 reg=0.002692
2017/08/29 14:15:51 step 5: objective=0.545315 reg=0.002691
2017/08/29 14:15:53 step 6: objective=0.547065 reg=0.002691
2017/08/29 14:15:56 step 7: objective=0.548421 reg=0.002690
2017/08/29 14:15:56 Training value function...
2017/08/29 14:15:58 step 0: mse=140.439277 step=0.100000
2017/08/29 14:16:00 step 1: mse=139.524814 step=0.100000
2017/08/29 14:16:01 step 2: mse=138.427931 step=0.100000
2017/08/29 14:16:02 step 3: mse=137.701507 step=0.100000
2017/08/29 14:16:04 step 4: mse=137.098798 step=0.100000
2017/08/29 14:16:05 step 5: mse=136.980823 step=0.100000
2017/08/29 14:16:06 step 6: mse=136.242221 step=0.100000
2017/08/29 14:16:08 step 7: mse=135.613624 step=0.100000
2017/08/29 14:16:08 Saving...
2017/08/29 14:16:08 Gathering batch of experience...
2017/08/29 14:17:02 batch 105: mean=313.148148 stddev=211.852797 entropy=0.262121 frames=7856 count=27
2017/08/29 14:17:02 Training policy...
2017/08/29 14:17:09 tune 0: objective=1.834795 reg=0.002621 prune=0
2017/08/29 14:17:14 tune 1: objective=1.837493 reg=0.002620 prune=0
2017/08/29 14:17:18 tune 2: objective=1.840173 reg=0.002620 prune=0
2017/08/29 14:17:22 tune 3: objective=1.842838 reg=0.002619 prune=0
2017/08/29 14:17:27 tune 4: objective=1.845493 reg=0.002618 prune=0
2017/08/29 14:17:31 tune 5: objective=1.848128 reg=0.002617 prune=0
2017/08/29 14:17:36 tune 6: objective=1.850603 reg=0.002616 prune=0
2017/08/29 14:17:40 tune 7: objective=1.852797 reg=0.002615 prune=0
2017/08/29 14:17:43 step 0: objective=1.854816 reg=0.002615
2017/08/29 14:17:46 step 1: objective=1.857427 reg=0.002614
2017/08/29 14:17:48 step 2: objective=1.859906 reg=0.002614
2017/08/29 14:17:51 step 3: objective=1.862557 reg=0.002612
2017/08/29 14:17:54 step 4: objective=1.864229 reg=0.002611
2017/08/29 14:17:57 step 5: objective=1.865608 reg=0.002611
2017/08/29 14:18:00 step 6: objective=1.867438 reg=0.002611
2017/08/29 14:18:03 step 7: objective=1.868356 reg=0.002610
2017/08/29 14:18:03 Training value function...
2017/08/29 14:18:06 step 0: mse=147.617391 step=0.100000
2017/08/29 14:18:08 step 1: mse=144.030598 step=0.100000
2017/08/29 14:18:09 step 2: mse=141.046682 step=0.100000
2017/08/29 14:18:11 step 3: mse=138.560995 step=0.100000
2017/08/29 14:18:13 step 4: mse=136.295905 step=0.100000
2017/08/29 14:18:14 step 5: mse=134.361315 step=0.100000
2017/08/29 14:18:16 step 6: mse=132.600218 step=0.100000
2017/08/29 14:18:18 step 7: mse=131.006539 step=0.100000
2017/08/29 14:18:18 Saving...
2017/08/29 14:18:18 Gathering batch of experience...
2017/08/29 14:19:04 batch 106: mean=376.650000 stddev=224.210231 entropy=0.274376 frames=6966 count=20
2017/08/29 14:19:04 Training policy...
2017/08/29 14:19:11 tune 0: objective=1.638139 reg=0.002744 prune=0
2017/08/29 14:19:15 tune 1: objective=1.641504 reg=0.002744 prune=0
2017/08/29 14:19:19 tune 2: objective=1.644842 reg=0.002744 prune=0
2017/08/29 14:19:23 tune 3: objective=1.648147 reg=0.002744 prune=0
2017/08/29 14:19:26 tune 4: objective=1.651304 reg=0.002744 prune=0
2017/08/29 14:19:30 tune 5: objective=1.654209 reg=0.002743 prune=0
2017/08/29 14:19:34 tune 6: objective=1.656801 reg=0.002743 prune=0
2017/08/29 14:19:38 tune 7: objective=1.659149 reg=0.002743 prune=0
2017/08/29 14:19:40 step 0: objective=1.661323 reg=0.002743
2017/08/29 14:19:43 step 1: objective=1.662729 reg=0.002743
2017/08/29 14:19:45 step 2: objective=1.664655 reg=0.002743
2017/08/29 14:19:48 step 3: objective=1.667356 reg=0.002743
2017/08/29 14:19:51 step 4: objective=1.668911 reg=0.002743
2017/08/29 14:19:53 step 5: objective=1.671940 reg=0.002744
2017/08/29 14:19:56 step 6: objective=1.672918 reg=0.002744
2017/08/29 14:19:58 step 7: objective=1.674793 reg=0.002744
2017/08/29 14:19:58 Training value function...
2017/08/29 14:20:01 step 0: mse=154.023937 step=0.100000
2017/08/29 14:20:02 step 1: mse=151.720188 step=0.100000
2017/08/29 14:20:04 step 2: mse=148.723999 step=0.100000
2017/08/29 14:20:05 step 3: mse=145.727330 step=0.100000
2017/08/29 14:20:07 step 4: mse=143.615005 step=0.100000
2017/08/29 14:20:08 step 5: mse=141.708881 step=0.100000
2017/08/29 14:20:10 step 6: mse=139.900891 step=0.100000
2017/08/29 14:20:11 step 7: mse=138.292581 step=0.100000
2017/08/29 14:20:11 Saving...
2017/08/29 14:20:11 Gathering batch of experience...
2017/08/29 14:21:00 batch 107: mean=294.720000 stddev=216.047498 entropy=0.270703 frames=7017 count=25
2017/08/29 14:21:00 Training policy...
2017/08/29 14:21:06 tune 0: objective=0.680260 reg=0.002707 prune=0
2017/08/29 14:21:10 tune 1: objective=0.683661 reg=0.002706 prune=0
2017/08/29 14:21:14 tune 2: objective=0.687037 reg=0.002705 prune=0
2017/08/29 14:21:18 tune 3: objective=0.690385 reg=0.002704 prune=0
2017/08/29 14:21:22 tune 4: objective=0.693706 reg=0.002704 prune=0
2017/08/29 14:21:26 tune 5: objective=0.696884 reg=0.002703 prune=0
2017/08/29 14:21:29 tune 6: objective=0.699684 reg=0.002702 prune=0
2017/08/29 14:21:33 tune 7: objective=0.702189 reg=0.002702 prune=0
2017/08/29 14:21:36 step 0: objective=0.704472 reg=0.002701
2017/08/29 14:21:38 step 1: objective=0.706877 reg=0.002700
2017/08/29 14:21:41 step 2: objective=0.708618 reg=0.002700
2017/08/29 14:21:44 step 3: objective=0.710793 reg=0.002700
2017/08/29 14:21:46 step 4: objective=0.712311 reg=0.002701
2017/08/29 14:21:49 step 5: objective=0.714989 reg=0.002701
2017/08/29 14:21:51 step 6: objective=0.716406 reg=0.002701
2017/08/29 14:21:54 step 7: objective=0.718343 reg=0.002700
2017/08/29 14:21:54 Training value function...
2017/08/29 14:21:57 step 0: mse=156.801635 step=0.100000
2017/08/29 14:21:58 step 1: mse=153.960793 step=0.100000
2017/08/29 14:22:00 step 2: mse=151.310282 step=0.100000
2017/08/29 14:22:01 step 3: mse=149.066468 step=0.100000
2017/08/29 14:22:03 step 4: mse=147.216443 step=0.100000
2017/08/29 14:22:04 step 5: mse=145.740381 step=0.100000
2017/08/29 14:22:06 step 6: mse=144.431799 step=0.100000
2017/08/29 14:22:07 step 7: mse=143.193713 step=0.100000
2017/08/29 14:22:07 Saving...
2017/08/29 14:22:07 Gathering batch of experience...
2017/08/29 14:22:57 batch 108: mean=356.478261 stddev=222.054609 entropy=0.273955 frames=7493 count=23
2017/08/29 14:22:57 Training policy...
2017/08/29 14:23:05 tune 0: objective=1.525764 reg=0.002740 prune=0
2017/08/29 14:23:09 tune 1: objective=1.528390 reg=0.002740 prune=0
2017/08/29 14:23:13 tune 2: objective=1.531000 reg=0.002740 prune=0
2017/08/29 14:23:17 tune 3: objective=1.533589 reg=0.002740 prune=0
2017/08/29 14:23:21 tune 4: objective=1.536181 reg=0.002740 prune=0
2017/08/29 14:23:25 tune 5: objective=1.538759 reg=0.002740 prune=0
2017/08/29 14:23:30 tune 6: objective=1.541261 reg=0.002740 prune=0
2017/08/29 14:23:34 tune 7: objective=1.543659 reg=0.002740 prune=0
2017/08/29 14:23:36 step 0: objective=1.545870 reg=0.002741
2017/08/29 14:23:39 step 1: objective=1.548200 reg=0.002741
2017/08/29 14:23:42 step 2: objective=1.550039 reg=0.002741
2017/08/29 14:23:45 step 3: objective=1.552267 reg=0.002741
2017/08/29 14:23:47 step 4: objective=1.554022 reg=0.002741
2017/08/29 14:23:50 step 5: objective=1.555677 reg=0.002741
2017/08/29 14:23:53 step 6: objective=1.557437 reg=0.002741
2017/08/29 14:23:56 step 7: objective=1.559915 reg=0.002741
2017/08/29 14:23:56 Training value function...
2017/08/29 14:23:59 step 0: mse=164.385257 step=0.100000
2017/08/29 14:24:00 step 1: mse=161.736540 step=0.100000
2017/08/29 14:24:02 step 2: mse=159.176210 step=0.100000
2017/08/29 14:24:03 step 3: mse=157.191906 step=0.100000
2017/08/29 14:24:05 step 4: mse=155.364254 step=0.100000
2017/08/29 14:24:07 step 5: mse=153.935081 step=0.100000
2017/08/29 14:24:08 step 6: mse=152.487900 step=0.100000
2017/08/29 14:24:10 step 7: mse=151.186503 step=0.100000
2017/08/29 14:24:10 Saving...
2017/08/29 14:24:10 Gathering batch of experience...
2017/08/29 14:25:00 batch 109: mean=313.440000 stddev=180.220105 entropy=0.266315 frames=7450 count=25
2017/08/29 14:25:00 Training policy...
2017/08/29 14:25:07 tune 0: objective=0.569619 reg=0.002663 prune=0
2017/08/29 14:25:11 tune 1: objective=0.572795 reg=0.002662 prune=0
2017/08/29 14:25:15 tune 2: objective=0.575934 reg=0.002661 prune=0
2017/08/29 14:25:19 tune 3: objective=0.579034 reg=0.002661 prune=0
2017/08/29 14:25:23 tune 4: objective=0.582092 reg=0.002660 prune=0
2017/08/29 14:25:27 tune 5: objective=0.584934 reg=0.002659 prune=0
2017/08/29 14:25:32 tune 6: objective=0.587512 reg=0.002658 prune=0
2017/08/29 14:25:36 tune 7: objective=0.589859 reg=0.002658 prune=0
2017/08/29 14:25:38 step 0: objective=0.591936 reg=0.002657
2017/08/29 14:25:41 step 1: objective=0.593172 reg=0.002656
2017/08/29 14:25:44 step 2: objective=0.594683 reg=0.002655
2017/08/29 14:25:47 step 3: objective=0.597227 reg=0.002655
2017/08/29 14:25:49 step 4: objective=0.599531 reg=0.002655
2017/08/29 14:25:52 step 5: objective=0.600888 reg=0.002655
2017/08/29 14:25:55 step 6: objective=0.602549 reg=0.002655
2017/08/29 14:25:57 step 7: objective=0.604734 reg=0.002655
2017/08/29 14:25:57 Training value function...
2017/08/29 14:26:01 step 0: mse=143.405671 step=0.100000
2017/08/29 14:26:02 step 1: mse=141.548276 step=0.100000
2017/08/29 14:26:04 step 2: mse=140.323052 step=0.100000
2017/08/29 14:26:05 step 3: mse=139.128734 step=0.100000
2017/08/29 14:26:07 step 4: mse=138.111813 step=0.100000
2017/08/29 14:26:08 step 5: mse=137.254254 step=0.100000
2017/08/29 14:26:10 step 6: mse=136.579998 step=0.100000
2017/08/29 14:26:12 step 7: mse=135.844623 step=0.100000
2017/08/29 14:26:12 Saving...
2017/08/29 14:26:12 Gathering batch of experience...
2017/08/29 14:26:59 batch 110: mean=400.666667 stddev=222.308594 entropy=0.268236 frames=6725 count=18
2017/08/29 14:26:59 Training policy...
2017/08/29 14:27:06 tune 0: objective=1.529568 reg=0.002682 prune=0
2017/08/29 14:27:10 tune 1: objective=1.531898 reg=0.002682 prune=0
2017/08/29 14:27:13 tune 2: objective=1.534219 reg=0.002681 prune=0
2017/08/29 14:27:17 tune 3: objective=1.536542 reg=0.002681 prune=0
2017/08/29 14:27:21 tune 4: objective=1.538855 reg=0.002681 prune=0
2017/08/29 14:27:24 tune 5: objective=1.541169 reg=0.002680 prune=0
2017/08/29 14:27:28 tune 6: objective=1.543471 reg=0.002680 prune=0
2017/08/29 14:27:32 tune 7: objective=1.545670 reg=0.002679 prune=0
2017/08/29 14:27:34 step 0: objective=1.547755 reg=0.002679
2017/08/29 14:27:37 step 1: objective=1.550454 reg=0.002679
2017/08/29 14:27:39 step 2: objective=1.552355 reg=0.002678
2017/08/29 14:27:42 step 3: objective=1.553865 reg=0.002678
2017/08/29 14:27:44 step 4: objective=1.556119 reg=0.002677
2017/08/29 14:27:47 step 5: objective=1.559020 reg=0.002677
2017/08/29 14:27:49 step 6: objective=1.561210 reg=0.002676
2017/08/29 14:27:51 step 7: objective=1.562299 reg=0.002676
2017/08/29 14:27:51 Training value function...
2017/08/29 14:27:54 step 0: mse=152.734374 step=0.100000
2017/08/29 14:27:56 step 1: mse=148.854203 step=0.100000
2017/08/29 14:27:57 step 2: mse=145.382618 step=0.100000
2017/08/29 14:27:58 step 3: mse=142.788565 step=0.100000
2017/08/29 14:28:00 step 4: mse=140.371072 step=0.100000
2017/08/29 14:28:01 step 5: mse=138.085498 step=0.100000
2017/08/29 14:28:03 step 6: mse=136.146044 step=0.100000
2017/08/29 14:28:04 step 7: mse=134.582040 step=0.100000
2017/08/29 14:28:04 Saving...
2017/08/29 14:28:04 Gathering batch of experience...
2017/08/29 14:28:50 batch 111: mean=305.909091 stddev=203.367314 entropy=0.263974 frames=6525 count=22
2017/08/29 14:28:50 Training policy...
2017/08/29 14:28:56 tune 0: objective=0.435514 reg=0.002640 prune=0
2017/08/29 14:29:00 tune 1: objective=0.438320 reg=0.002640 prune=0
2017/08/29 14:29:03 tune 2: objective=0.441111 reg=0.002640 prune=0
2017/08/29 14:29:07 tune 3: objective=0.443885 reg=0.002639 prune=0
2017/08/29 14:29:10 tune 4: objective=0.446645 reg=0.002639 prune=0
2017/08/29 14:29:14 tune 5: objective=0.449389 reg=0.002639 prune=0
2017/08/29 14:29:18 tune 6: objective=0.451978 reg=0.002639 prune=0
2017/08/29 14:29:21 tune 7: objective=0.454319 reg=0.002639 prune=0
2017/08/29 14:29:24 step 0: objective=0.456490 reg=0.002639
2017/08/29 14:29:26 step 1: objective=0.458997 reg=0.002639
2017/08/29 14:29:28 step 2: objective=0.460871 reg=0.002639
2017/08/29 14:29:31 step 3: objective=0.463874 reg=0.002640
2017/08/29 14:29:33 step 4: objective=0.465449 reg=0.002640
2017/08/29 14:29:35 step 5: objective=0.467563 reg=0.002641
2017/08/29 14:29:38 step 6: objective=0.469171 reg=0.002640
2017/08/29 14:29:40 step 7: objective=0.471377 reg=0.002640
2017/08/29 14:29:40 Training value function...
2017/08/29 14:29:43 step 0: mse=138.302585 step=0.100000
2017/08/29 14:29:44 step 1: mse=136.820704 step=0.100000
2017/08/29 14:29:46 step 2: mse=135.800705 step=0.100000
2017/08/29 14:29:47 step 3: mse=135.038886 step=0.100000
2017/08/29 14:29:48 step 4: mse=134.126492 step=0.100000
2017/08/29 14:29:50 step 5: mse=133.167835 step=0.100000
2017/08/29 14:29:51 step 6: mse=132.432485 step=0.100000
2017/08/29 14:29:53 step 7: mse=131.790066 step=0.100000
2017/08/29 14:29:53 Saving...
2017/08/29 14:29:53 Gathering batch of experience...
2017/08/29 14:30:44 batch 112: mean=271.703704 stddev=219.005465 entropy=0.262331 frames=6712 count=27
2017/08/29 14:30:44 Training policy...
2017/08/29 14:30:50 tune 0: objective=1.389943 reg=0.002623 prune=0
2017/08/29 14:30:54 tune 1: objective=1.393733 reg=0.002622 prune=0
2017/08/29 14:30:57 tune 2: objective=1.397488 reg=0.002622 prune=0
2017/08/29 14:31:01 tune 3: objective=1.401218 reg=0.002621 prune=0
2017/08/29 14:31:05 tune 4: objective=1.404911 reg=0.002620 prune=0
2017/08/29 14:31:09 tune 5: objective=1.408504 reg=0.002619 prune=0
2017/08/29 14:31:12 tune 6: objective=1.411738 reg=0.002618 prune=0
2017/08/29 14:31:16 tune 7: objective=1.414648 reg=0.002617 prune=0
2017/08/29 14:31:19 step 0: objective=1.417189 reg=0.002617
2017/08/29 14:31:21 step 1: objective=1.420049 reg=0.002617
2017/08/29 14:31:23 step 2: objective=1.423533 reg=0.002618
2017/08/29 14:31:26 step 3: objective=1.426009 reg=0.002617
2017/08/29 14:31:28 step 4: objective=1.428133 reg=0.002617
2017/08/29 14:31:31 step 5: objective=1.429627 reg=0.002616
2017/08/29 14:31:33 step 6: objective=1.430584 reg=0.002616
2017/08/29 14:31:36 step 7: objective=1.431518 reg=0.002616
2017/08/29 14:31:36 Training value function...
2017/08/29 14:31:38 step 0: mse=167.225226 step=0.100000
2017/08/29 14:31:40 step 1: mse=163.672257 step=0.100000
2017/08/29 14:31:41 step 2: mse=160.789075 step=0.100000
2017/08/29 14:31:43 step 3: mse=157.997262 step=0.100000
2017/08/29 14:31:44 step 4: mse=155.436219 step=0.100000
2017/08/29 14:31:45 step 5: mse=153.465925 step=0.100000
2017/08/29 14:31:47 step 6: mse=151.861656 step=0.100000
2017/08/29 14:31:48 step 7: mse=150.294452 step=0.100000
2017/08/29 14:31:48 Saving...
2017/08/29 14:31:48 Gathering batch of experience...
2017/08/29 14:32:30 batch 113: mean=239.320000 stddev=201.302503 entropy=0.270417 frames=6041 count=25
2017/08/29 14:32:30 Training policy...
2017/08/29 14:32:36 tune 0: objective=-0.177112 reg=0.002704 prune=0
2017/08/29 14:32:39 tune 1: objective=-0.173753 reg=0.002704 prune=0
2017/08/29 14:32:43 tune 2: objective=-0.170433 reg=0.002704 prune=0
2017/08/29 14:32:46 tune 3: objective=-0.167149 reg=0.002703 prune=0
2017/08/29 14:32:49 tune 4: objective=-0.163951 reg=0.002703 prune=0
2017/08/29 14:32:53 tune 5: objective=-0.160903 reg=0.002703 prune=0
2017/08/29 14:32:56 tune 6: objective=-0.158062 reg=0.002703 prune=0
2017/08/29 14:32:59 tune 7: objective=-0.155604 reg=0.002703 prune=0
2017/08/29 14:33:02 step 0: objective=-0.153363 reg=0.002703
2017/08/29 14:33:04 step 1: objective=-0.150941 reg=0.002702
2017/08/29 14:33:06 step 2: objective=-0.148777 reg=0.002702
2017/08/29 14:33:08 step 3: objective=-0.146692 reg=0.002703
2017/08/29 14:33:10 step 4: objective=-0.143871 reg=0.002703
2017/08/29 14:33:13 step 5: objective=-0.141676 reg=0.002703
2017/08/29 14:33:15 step 6: objective=-0.139657 reg=0.002704
2017/08/29 14:33:17 step 7: objective=-0.138598 reg=0.002704
2017/08/29 14:33:17 Training value function...
2017/08/29 14:33:19 step 0: mse=123.299843 step=0.100000
2017/08/29 14:33:21 step 1: mse=121.089927 step=0.100000
2017/08/29 14:33:22 step 2: mse=119.303176 step=0.100000
2017/08/29 14:33:23 step 3: mse=117.910139 step=0.100000
2017/08/29 14:33:24 step 4: mse=116.567016 step=0.100000
2017/08/29 14:33:26 step 5: mse=115.423866 step=0.100000
2017/08/29 14:33:27 step 6: mse=114.477224 step=0.100000
2017/08/29 14:33:28 step 7: mse=113.741896 step=0.100000
2017/08/29 14:33:28 Saving...
2017/08/29 14:33:28 Gathering batch of experience...
2017/08/29 14:34:14 batch 114: mean=357.100000 stddev=214.377448 entropy=0.259237 frames=6533 count=20
2017/08/29 14:34:14 Training policy...
2017/08/29 14:34:20 tune 0: objective=2.244458 reg=0.002592 prune=0
2017/08/29 14:34:24 tune 1: objective=2.247499 reg=0.002592 prune=0
2017/08/29 14:34:27 tune 2: objective=2.250525 reg=0.002593 prune=0
2017/08/29 14:34:31 tune 3: objective=2.253555 reg=0.002593 prune=0
2017/08/29 14:34:35 tune 4: objective=2.256571 reg=0.002593 prune=0
2017/08/29 14:34:38 tune 5: objective=2.259465 reg=0.002593 prune=0
2017/08/29 14:34:42 tune 6: objective=2.262207 reg=0.002593 prune=0
2017/08/29 14:34:46 tune 7: objective=2.264830 reg=0.002593 prune=0
2017/08/29 14:34:48 step 0: objective=2.267181 reg=0.002593
2017/08/29 14:34:50 step 1: objective=2.268814 reg=0.002593
2017/08/29 14:34:53 step 2: objective=2.270918 reg=0.002592
2017/08/29 14:34:55 step 3: objective=2.273117 reg=0.002593
2017/08/29 14:34:57 step 4: objective=2.274462 reg=0.002593
2017/08/29 14:35:00 step 5: objective=2.275947 reg=0.002594
2017/08/29 14:35:02 step 6: objective=2.277505 reg=0.002594
2017/08/29 14:35:05 step 7: objective=2.279220 reg=0.002594
2017/08/29 14:35:05 Training value function...
2017/08/29 14:35:07 step 0: mse=176.679426 step=0.100000
2017/08/29 14:35:09 step 1: mse=171.622006 step=0.100000
2017/08/29 14:35:10 step 2: mse=166.732072 step=0.100000
2017/08/29 14:35:11 step 3: mse=162.954122 step=0.100000
2017/08/29 14:35:13 step 4: mse=159.266983 step=0.100000
2017/08/29 14:35:14 step 5: mse=156.332942 step=0.100000
2017/08/29 14:35:15 step 6: mse=153.530981 step=0.100000
2017/08/29 14:35:17 step 7: mse=151.385176 step=0.100000
2017/08/29 14:35:17 Saving...
2017/08/29 14:35:17 Gathering batch of experience...
2017/08/29 14:36:16 batch 115: mean=283.419355 stddev=205.657839 entropy=0.263463 frames=8367 count=31
2017/08/29 14:36:16 Training policy...
2017/08/29 14:36:24 tune 0: objective=0.631879 reg=0.002635 prune=0
2017/08/29 14:36:28 tune 1: objective=0.634439 reg=0.002634 prune=0
2017/08/29 14:36:33 tune 2: objective=0.636967 reg=0.002634 prune=0
2017/08/29 14:36:38 tune 3: objective=0.639464 reg=0.002634 prune=0
2017/08/29 14:36:43 tune 4: objective=0.641791 reg=0.002634 prune=0
2017/08/29 14:36:47 tune 5: objective=0.644033 reg=0.002633 prune=0
2017/08/29 14:36:52 tune 6: objective=0.646183 reg=0.002633 prune=0
2017/08/29 14:36:57 tune 7: objective=0.648088 reg=0.002633 prune=0
2017/08/29 14:37:00 step 0: objective=0.649754 reg=0.002633
2017/08/29 14:37:03 step 1: objective=0.652377 reg=0.002634
2017/08/29 14:37:06 step 2: objective=0.653625 reg=0.002633
2017/08/29 14:37:09 step 3: objective=0.655059 reg=0.002633
2017/08/29 14:37:12 step 4: objective=0.656829 reg=0.002633
2017/08/29 14:37:15 step 5: objective=0.658606 reg=0.002633
2017/08/29 14:37:18 step 6: objective=0.661169 reg=0.002634
2017/08/29 14:37:21 step 7: objective=0.662646 reg=0.002633
2017/08/29 14:37:21 Training value function...
2017/08/29 14:37:25 step 0: mse=133.145435 step=0.100000
2017/08/29 14:37:26 step 1: mse=131.596959 step=0.100000
2017/08/29 14:37:28 step 2: mse=130.672776 step=0.100000
2017/08/29 14:37:30 step 3: mse=129.729214 step=0.100000
2017/08/29 14:37:32 step 4: mse=129.092722 step=0.100000
2017/08/29 14:37:33 step 5: mse=128.656092 step=0.100000
2017/08/29 14:37:35 step 6: mse=128.274154 step=0.100000
2017/08/29 14:37:37 step 7: mse=128.067976 step=0.100000
2017/08/29 14:37:37 Saving...
2017/08/29 14:37:37 Gathering batch of experience...
2017/08/29 14:38:25 batch 116: mean=339.391304 stddev=223.882488 entropy=0.266914 frames=7144 count=23
2017/08/29 14:38:25 Training policy...
2017/08/29 14:38:32 tune 0: objective=1.784598 reg=0.002669 prune=0
2017/08/29 14:38:36 tune 1: objective=1.787407 reg=0.002669 prune=0
2017/08/29 14:38:40 tune 2: objective=1.790197 reg=0.002669 prune=0
2017/08/29 14:38:44 tune 3: objective=1.792982 reg=0.002669 prune=0
2017/08/29 14:38:48 tune 4: objective=1.795760 reg=0.002669 prune=0
2017/08/29 14:38:52 tune 5: objective=1.798522 reg=0.002669 prune=0
2017/08/29 14:38:56 tune 6: objective=1.801237 reg=0.002669 prune=0
2017/08/29 14:38:59 tune 7: objective=1.803830 reg=0.002669 prune=0
2017/08/29 14:39:02 step 0: objective=1.806198 reg=0.002669
2017/08/29 14:39:05 step 1: objective=1.810304 reg=0.002669
2017/08/29 14:39:07 step 2: objective=1.812005 reg=0.002669
2017/08/29 14:39:10 step 3: objective=1.815004 reg=0.002668
2017/08/29 14:39:13 step 4: objective=1.816354 reg=0.002667
2017/08/29 14:39:15 step 5: objective=1.818103 reg=0.002667
2017/08/29 14:39:18 step 6: objective=1.820049 reg=0.002666
2017/08/29 14:39:20 step 7: objective=1.821756 reg=0.002666
2017/08/29 14:39:20 Training value function...
2017/08/29 14:39:23 step 0: mse=162.710289 step=0.100000
2017/08/29 14:39:25 step 1: mse=159.207097 step=0.100000
2017/08/29 14:39:26 step 2: mse=156.295398 step=0.100000
2017/08/29 14:39:28 step 3: mse=153.847788 step=0.100000
2017/08/29 14:39:29 step 4: mse=151.798331 step=0.100000
2017/08/29 14:39:31 step 5: mse=149.939835 step=0.100000
2017/08/29 14:39:32 step 6: mse=147.972795 step=0.100000
2017/08/29 14:39:34 step 7: mse=146.562087 step=0.100000
2017/08/29 14:39:34 Saving...
2017/08/29 14:39:34 Gathering batch of experience...
2017/08/29 14:40:18 batch 117: mean=287.333333 stddev=186.062863 entropy=0.263691 frames=6610 count=24
2017/08/29 14:40:18 Training policy...
2017/08/29 14:40:24 tune 0: objective=0.449082 reg=0.002637 prune=0
2017/08/29 14:40:28 tune 1: objective=0.452445 reg=0.002636 prune=0
2017/08/29 14:40:32 tune 2: objective=0.455764 reg=0.002636 prune=0
2017/08/29 14:40:35 tune 3: objective=0.459042 reg=0.002635 prune=0
2017/08/29 14:40:39 tune 4: objective=0.462280 reg=0.002634 prune=0
2017/08/29 14:40:43 tune 5: objective=0.465411 reg=0.002634 prune=0
2017/08/29 14:40:46 tune 6: objective=0.468203 reg=0.002633 prune=0
2017/08/29 14:40:50 tune 7: objective=0.470701 reg=0.002633 prune=0
2017/08/29 14:40:52 step 0: objective=0.473002 reg=0.002632
2017/08/29 14:40:55 step 1: objective=0.475077 reg=0.002632
2017/08/29 14:40:57 step 2: objective=0.477232 reg=0.002632
2017/08/29 14:41:00 step 3: objective=0.480285 reg=0.002632
2017/08/29 14:41:02 step 4: objective=0.481941 reg=0.002632
2017/08/29 14:41:04 step 5: objective=0.483690 reg=0.002632
2017/08/29 14:41:07 step 6: objective=0.485345 reg=0.002632
2017/08/29 14:41:09 step 7: objective=0.486550 reg=0.002632
2017/08/29 14:41:09 Training value function...
2017/08/29 14:41:12 step 0: mse=125.188796 step=0.100000
2017/08/29 14:41:13 step 1: mse=122.669650 step=0.100000
2017/08/29 14:41:15 step 2: mse=121.212821 step=0.100000
2017/08/29 14:41:16 step 3: mse=119.679308 step=0.100000
2017/08/29 14:41:18 step 4: mse=118.537617 step=0.100000
2017/08/29 14:41:19 step 5: mse=117.550804 step=0.100000
2017/08/29 14:41:20 step 6: mse=116.968240 step=0.100000
2017/08/29 14:41:22 step 7: mse=116.371792 step=0.100000
2017/08/29 14:41:22 Saving...
2017/08/29 14:41:22 Gathering batch of experience...
2017/08/29 14:42:08 batch 118: mean=403.166667 stddev=232.176477 entropy=0.261453 frames=6774 count=18
2017/08/29 14:42:08 Training policy...
2017/08/29 14:42:15 tune 0: objective=1.645653 reg=0.002615 prune=0
2017/08/29 14:42:18 tune 1: objective=1.648319 reg=0.002615 prune=0
2017/08/29 14:42:22 tune 2: objective=1.650971 reg=0.002615 prune=0
2017/08/29 14:42:26 tune 3: objective=1.653613 reg=0.002615 prune=0
2017/08/29 14:42:30 tune 4: objective=1.656235 reg=0.002615 prune=0
2017/08/29 14:42:33 tune 5: objective=1.658852 reg=0.002615 prune=0
2017/08/29 14:42:37 tune 6: objective=1.661242 reg=0.002615 prune=0
2017/08/29 14:42:41 tune 7: objective=1.663237 reg=0.002614 prune=0
2017/08/29 14:42:43 step 0: objective=1.665142 reg=0.002614
2017/08/29 14:42:46 step 1: objective=1.666668 reg=0.002614
2017/08/29 14:42:48 step 2: objective=1.668607 reg=0.002614
2017/08/29 14:42:51 step 3: objective=1.669868 reg=0.002614
2017/08/29 14:42:53 step 4: objective=1.672265 reg=0.002613
2017/08/29 14:42:56 step 5: objective=1.673898 reg=0.002613
2017/08/29 14:42:58 step 6: objective=1.674958 reg=0.002613
2017/08/29 14:43:01 step 7: objective=1.676469 reg=0.002613
2017/08/29 14:43:01 Training value function...
2017/08/29 14:43:04 step 0: mse=128.055716 step=0.100000
2017/08/29 14:43:05 step 1: mse=124.671674 step=0.100000
2017/08/29 14:43:06 step 2: mse=121.993048 step=0.100000
2017/08/29 14:43:08 step 3: mse=119.768106 step=0.100000
2017/08/29 14:43:09 step 4: mse=117.596433 step=0.100000
2017/08/29 14:43:11 step 5: mse=115.917045 step=0.100000
2017/08/29 14:43:12 step 6: mse=114.143656 step=0.100000
2017/08/29 14:43:14 step 7: mse=112.929376 step=0.100000
2017/08/29 14:43:14 Saving...
2017/08/29 14:43:14 Gathering batch of experience...
2017/08/29 14:44:06 batch 119: mean=360.363636 stddev=205.538217 entropy=0.268089 frames=7687 count=22
2017/08/29 14:44:06 Training policy...
2017/08/29 14:44:14 tune 0: objective=0.587968 reg=0.002681 prune=0
2017/08/29 14:44:18 tune 1: objective=0.590129 reg=0.002681 prune=0
2017/08/29 14:44:22 tune 2: objective=0.592274 reg=0.002680 prune=0
2017/08/29 14:44:27 tune 3: objective=0.594405 reg=0.002680 prune=0
2017/08/29 14:44:31 tune 4: objective=0.596527 reg=0.002680 prune=0
2017/08/29 14:44:35 tune 5: objective=0.598632 reg=0.002679 prune=0
2017/08/29 14:44:40 tune 6: objective=0.600708 reg=0.002679 prune=0
2017/08/29 14:44:44 tune 7: objective=0.602676 reg=0.002679 prune=0
2017/08/29 14:44:47 step 0: objective=0.604474 reg=0.002679
2017/08/29 14:44:50 step 1: objective=0.606799 reg=0.002679
2017/08/29 14:44:52 step 2: objective=0.608804 reg=0.002680
2017/08/29 14:44:55 step 3: objective=0.610261 reg=0.002681
2017/08/29 14:44:58 step 4: objective=0.612493 reg=0.002681
2017/08/29 14:45:01 step 5: objective=0.614381 reg=0.002681
2017/08/29 14:45:04 step 6: objective=0.615526 reg=0.002681
2017/08/29 14:45:07 step 7: objective=0.616491 reg=0.002681
2017/08/29 14:45:07 Training value function...
2017/08/29 14:45:10 step 0: mse=132.089819 step=0.100000
2017/08/29 14:45:11 step 1: mse=130.165296 step=0.100000
2017/08/29 14:45:13 step 2: mse=128.874433 step=0.100000
2017/08/29 14:45:15 step 3: mse=127.682451 step=0.100000
2017/08/29 14:45:16 step 4: mse=126.436046 step=0.100000
2017/08/29 14:45:18 step 5: mse=125.510144 step=0.100000
2017/08/29 14:45:19 step 6: mse=124.940843 step=0.100000
2017/08/29 14:45:21 step 7: mse=124.396240 step=0.100000
2017/08/29 14:45:21 Saving...
2017/08/29 14:45:21 Gathering batch of experience...
2017/08/29 14:46:12 batch 120: mean=346.956522 stddev=215.411129 entropy=0.264120 frames=7473 count=23
2017/08/29 14:46:12 Training policy...
2017/08/29 14:46:19 tune 0: objective=1.270937 reg=0.002641 prune=0
2017/08/29 14:46:23 tune 1: objective=1.273637 reg=0.002641 prune=0
2017/08/29 14:46:28 tune 2: objective=1.276314 reg=0.002641 prune=0
2017/08/29 14:46:32 tune 3: objective=1.278965 reg=0.002640 prune=0
2017/08/29 14:46:36 tune 4: objective=1.281595 reg=0.002640 prune=0
2017/08/29 14:46:40 tune 5: objective=1.284130 reg=0.002640 prune=0
2017/08/29 14:46:44 tune 6: objective=1.286401 reg=0.002640 prune=0
2017/08/29 14:46:48 tune 7: objective=1.288411 reg=0.002639 prune=0
2017/08/29 14:46:51 step 0: objective=1.290287 reg=0.002639
2017/08/29 14:46:54 step 1: objective=1.292229 reg=0.002639
2017/08/29 14:46:57 step 2: objective=1.295246 reg=0.002639
2017/08/29 14:46:59 step 3: objective=1.297515 reg=0.002639
2017/08/29 14:47:02 step 4: objective=1.299792 reg=0.002639
2017/08/29 14:47:05 step 5: objective=1.302258 reg=0.002638
2017/08/29 14:47:08 step 6: objective=1.303836 reg=0.002639
2017/08/29 14:47:10 step 7: objective=1.304821 reg=0.002639
2017/08/29 14:47:10 Training value function...
2017/08/29 14:47:13 step 0: mse=163.139441 step=0.100000
2017/08/29 14:47:15 step 1: mse=159.176388 step=0.100000
2017/08/29 14:47:17 step 2: mse=156.027941 step=0.100000
2017/08/29 14:47:18 step 3: mse=153.076977 step=0.100000
2017/08/29 14:47:20 step 4: mse=150.856468 step=0.100000
2017/08/29 14:47:21 step 5: mse=148.716616 step=0.100000
2017/08/29 14:47:23 step 6: mse=147.062094 step=0.100000
2017/08/29 14:47:24 step 7: mse=145.669112 step=0.100000
2017/08/29 14:47:24 Saving...
2017/08/29 14:47:25 Gathering batch of experience...
2017/08/29 14:48:08 batch 121: mean=392.052632 stddev=208.072476 entropy=0.265873 frames=6803 count=19
2017/08/29 14:48:08 Training policy...
2017/08/29 14:48:15 tune 0: objective=1.435283 reg=0.002659 prune=0
2017/08/29 14:48:19 tune 1: objective=1.438013 reg=0.002659 prune=0
2017/08/29 14:48:22 tune 2: objective=1.440729 reg=0.002659 prune=0
2017/08/29 14:48:26 tune 3: objective=1.443426 reg=0.002659 prune=0
2017/08/29 14:48:30 tune 4: objective=1.446108 reg=0.002659 prune=0
2017/08/29 14:48:34 tune 5: objective=1.448773 reg=0.002659 prune=0
2017/08/29 14:48:38 tune 6: objective=1.451382 reg=0.002660 prune=0
2017/08/29 14:48:41 tune 7: objective=1.453706 reg=0.002660 prune=0
2017/08/29 14:48:44 step 0: objective=1.455716 reg=0.002660
2017/08/29 14:48:46 step 1: objective=1.458071 reg=0.002661
2017/08/29 14:48:49 step 2: objective=1.460090 reg=0.002661
2017/08/29 14:48:51 step 3: objective=1.461504 reg=0.002660
2017/08/29 14:48:54 step 4: objective=1.463353 reg=0.002660
2017/08/29 14:48:56 step 5: objective=1.465221 reg=0.002660
2017/08/29 14:48:59 step 6: objective=1.466617 reg=0.002660
2017/08/29 14:49:01 step 7: objective=1.467862 reg=0.002661
2017/08/29 14:49:01 Training value function...
2017/08/29 14:49:04 step 0: mse=142.921250 step=0.100000
2017/08/29 14:49:06 step 1: mse=140.829184 step=0.100000
2017/08/29 14:49:07 step 2: mse=139.172626 step=0.100000
2017/08/29 14:49:08 step 3: mse=137.623893 step=0.100000
2017/08/29 14:49:10 step 4: mse=136.337079 step=0.100000
2017/08/29 14:49:11 step 5: mse=134.804486 step=0.100000
2017/08/29 14:49:13 step 6: mse=133.557000 step=0.100000
2017/08/29 14:49:14 step 7: mse=132.518403 step=0.100000
2017/08/29 14:49:14 Saving...
2017/08/29 14:49:14 Gathering batch of experience...
2017/08/29 14:50:02 batch 122: mean=308.608696 stddev=216.353724 entropy=0.266837 frames=6686 count=23
2017/08/29 14:50:02 Training policy...
2017/08/29 14:50:09 tune 0: objective=0.565611 reg=0.002668 prune=0
2017/08/29 14:50:13 tune 1: objective=0.569186 reg=0.002668 prune=0
2017/08/29 14:50:16 tune 2: objective=0.572683 reg=0.002668 prune=0
2017/08/29 14:50:20 tune 3: objective=0.576077 reg=0.002668 prune=0
2017/08/29 14:50:24 tune 4: objective=0.578928 reg=0.002667 prune=0
2017/08/29 14:50:28 tune 5: objective=0.581346 reg=0.002667 prune=0
2017/08/29 14:50:31 tune 6: objective=0.583634 reg=0.002667 prune=0
2017/08/29 14:50:35 tune 7: objective=0.585785 reg=0.002666 prune=0
2017/08/29 14:50:37 step 0: objective=0.587732 reg=0.002666
2017/08/29 14:50:40 step 1: objective=0.589663 reg=0.002666
2017/08/29 14:50:42 step 2: objective=0.592379 reg=0.002666
2017/08/29 14:50:45 step 3: objective=0.594703 reg=0.002666
2017/08/29 14:50:47 step 4: objective=0.596588 reg=0.002666
2017/08/29 14:50:50 step 5: objective=0.598138 reg=0.002666
2017/08/29 14:50:52 step 6: objective=0.599345 reg=0.002667
2017/08/29 14:50:55 step 7: objective=0.600670 reg=0.002667
2017/08/29 14:50:55 Training value function...
2017/08/29 14:50:57 step 0: mse=132.258201 step=0.100000
2017/08/29 14:50:59 step 1: mse=130.826390 step=0.100000
2017/08/29 14:51:00 step 2: mse=129.856931 step=0.100000
2017/08/29 14:51:02 step 3: mse=129.011299 step=0.100000
2017/08/29 14:51:03 step 4: mse=128.400785 step=0.100000
2017/08/29 14:51:04 step 5: mse=127.774529 step=0.100000
2017/08/29 14:51:06 step 6: mse=127.263435 step=0.100000
2017/08/29 14:51:07 step 7: mse=126.563193 step=0.100000
2017/08/29 14:51:07 Saving...
2017/08/29 14:51:07 Gathering batch of experience...
2017/08/29 14:51:51 batch 123: mean=339.285714 stddev=188.251135 entropy=0.263228 frames=6772 count=21
2017/08/29 14:51:51 Training policy...
2017/08/29 14:51:58 tune 0: objective=0.839699 reg=0.002632 prune=0
2017/08/29 14:52:02 tune 1: objective=0.842515 reg=0.002632 prune=0
2017/08/29 14:52:05 tune 2: objective=0.845317 reg=0.002631 prune=0
2017/08/29 14:52:09 tune 3: objective=0.848098 reg=0.002631 prune=0
2017/08/29 14:52:13 tune 4: objective=0.850862 reg=0.002630 prune=0
2017/08/29 14:52:17 tune 5: objective=0.853537 reg=0.002630 prune=0
2017/08/29 14:52:21 tune 6: objective=0.856115 reg=0.002629 prune=0
2017/08/29 14:52:24 tune 7: objective=0.858425 reg=0.002629 prune=0
2017/08/29 14:52:27 step 0: objective=0.860518 reg=0.002629
2017/08/29 14:52:29 step 1: objective=0.862706 reg=0.002628
2017/08/29 14:52:32 step 2: objective=0.865098 reg=0.002628
2017/08/29 14:52:34 step 3: objective=0.866473 reg=0.002627
2017/08/29 14:52:37 step 4: objective=0.867970 reg=0.002626
2017/08/29 14:52:39 step 5: objective=0.871569 reg=0.002626
2017/08/29 14:52:42 step 6: objective=0.872694 reg=0.002625
2017/08/29 14:52:44 step 7: objective=0.873854 reg=0.002624
2017/08/29 14:52:44 Training value function...
2017/08/29 14:52:47 step 0: mse=130.776511 step=0.100000
2017/08/29 14:52:49 step 1: mse=130.018047 step=0.100000
2017/08/29 14:52:50 step 2: mse=129.204560 step=0.100000
2017/08/29 14:52:51 step 3: mse=128.525248 step=0.100000
2017/08/29 14:52:53 step 4: mse=128.114628 step=0.100000
2017/08/29 14:52:54 step 5: mse=127.381643 step=0.100000
2017/08/29 14:52:56 step 6: mse=126.959602 step=0.100000
2017/08/29 14:52:57 step 7: mse=126.239567 step=0.100000
2017/08/29 14:52:57 Saving...
2017/08/29 14:52:57 Gathering batch of experience...
2017/08/29 14:53:43 batch 124: mean=256.692308 stddev=173.624876 entropy=0.266196 frames=6312 count=26
2017/08/29 14:53:43 Training policy...
2017/08/29 14:53:49 tune 0: objective=0.544287 reg=0.002662 prune=0
2017/08/29 14:53:52 tune 1: objective=0.547885 reg=0.002662 prune=0
2017/08/29 14:53:56 tune 2: objective=0.551435 reg=0.002662 prune=0
2017/08/29 14:53:59 tune 3: objective=0.554937 reg=0.002661 prune=0
2017/08/29 14:54:03 tune 4: objective=0.558353 reg=0.002661 prune=0
2017/08/29 14:54:06 tune 5: objective=0.561423 reg=0.002661 prune=0
2017/08/29 14:54:10 tune 6: objective=0.564337 reg=0.002661 prune=0
2017/08/29 14:54:13 tune 7: objective=0.567015 reg=0.002661 prune=0
2017/08/29 14:54:16 step 0: objective=0.569347 reg=0.002661
2017/08/29 14:54:18 step 1: objective=0.570925 reg=0.002662
2017/08/29 14:54:20 step 2: objective=0.572413 reg=0.002662
2017/08/29 14:54:23 step 3: objective=0.574160 reg=0.002662
2017/08/29 14:54:25 step 4: objective=0.577451 reg=0.002662
2017/08/29 14:54:27 step 5: objective=0.579425 reg=0.002662
2017/08/29 14:54:30 step 6: objective=0.581579 reg=0.002662
2017/08/29 14:54:32 step 7: objective=0.583129 reg=0.002663
2017/08/29 14:54:32 Training value function...
2017/08/29 14:54:35 step 0: mse=130.690307 step=0.100000
2017/08/29 14:54:36 step 1: mse=129.534117 step=0.100000
2017/08/29 14:54:37 step 2: mse=128.860192 step=0.100000
2017/08/29 14:54:38 step 3: mse=128.367024 step=0.100000
2017/08/29 14:54:40 step 4: mse=127.656009 step=0.100000
2017/08/29 14:54:41 step 5: mse=127.412151 step=0.100000
2017/08/29 14:54:42 step 6: mse=127.146084 step=0.100000
2017/08/29 14:54:44 step 7: mse=126.465245 step=0.100000
2017/08/29 14:54:44 Saving...
2017/08/29 14:54:44 Gathering batch of experience...
2017/08/29 14:55:35 batch 125: mean=378.428571 stddev=199.297951 entropy=0.267780 frames=7319 count=21
2017/08/29 14:55:35 Training policy...
2017/08/29 14:55:42 tune 0: objective=1.774257 reg=0.002678 prune=0
2017/08/29 14:55:46 tune 1: objective=1.777315 reg=0.002678 prune=0
2017/08/29 14:55:50 tune 2: objective=1.780356 reg=0.002678 prune=0
2017/08/29 14:55:54 tune 3: objective=1.783377 reg=0.002678 prune=0
2017/08/29 14:55:59 tune 4: objective=1.786280 reg=0.002678 prune=0
2017/08/29 14:56:03 tune 5: objective=1.788991 reg=0.002678 prune=0
2017/08/29 14:56:07 tune 6: objective=1.791592 reg=0.002678 prune=0
2017/08/29 14:56:11 tune 7: objective=1.793894 reg=0.002678 prune=0
2017/08/29 14:56:14 step 0: objective=1.796075 reg=0.002678
2017/08/29 14:56:16 step 1: objective=1.798451 reg=0.002677
2017/08/29 14:56:19 step 2: objective=1.800920 reg=0.002677
2017/08/29 14:56:22 step 3: objective=1.803414 reg=0.002676
2017/08/29 14:56:24 step 4: objective=1.805972 reg=0.002677
2017/08/29 14:56:27 step 5: objective=1.808421 reg=0.002676
2017/08/29 14:56:30 step 6: objective=1.809882 reg=0.002676
2017/08/29 14:56:33 step 7: objective=1.812216 reg=0.002676
2017/08/29 14:56:33 Training value function...
2017/08/29 14:56:36 step 0: mse=154.050959 step=0.100000
2017/08/29 14:56:37 step 1: mse=149.571274 step=0.100000
2017/08/29 14:56:39 step 2: mse=145.976719 step=0.100000
2017/08/29 14:56:40 step 3: mse=142.759248 step=0.100000
2017/08/29 14:56:42 step 4: mse=139.783335 step=0.100000
2017/08/29 14:56:43 step 5: mse=137.421426 step=0.100000
2017/08/29 14:56:45 step 6: mse=135.284140 step=0.100000
2017/08/29 14:56:46 step 7: mse=133.567289 step=0.100000
2017/08/29 14:56:46 Saving...
2017/08/29 14:56:46 Gathering batch of experience...
2017/08/29 14:57:36 batch 126: mean=418.631579 stddev=198.409786 entropy=0.263013 frames=7372 count=19
2017/08/29 14:57:36 Training policy...
2017/08/29 14:57:43 tune 0: objective=1.403384 reg=0.002630 prune=0
2017/08/29 14:57:47 tune 1: objective=1.405699 reg=0.002630 prune=0
2017/08/29 14:57:51 tune 2: objective=1.408000 reg=0.002630 prune=0
2017/08/29 14:57:55 tune 3: objective=1.410287 reg=0.002630 prune=0
2017/08/29 14:57:59 tune 4: objective=1.412563 reg=0.002630 prune=0
2017/08/29 14:58:04 tune 5: objective=1.414728 reg=0.002630 prune=0
2017/08/29 14:58:08 tune 6: objective=1.416726 reg=0.002629 prune=0
2017/08/29 14:58:12 tune 7: objective=1.418662 reg=0.002629 prune=0
2017/08/29 14:58:15 step 0: objective=1.420413 reg=0.002629
2017/08/29 14:58:17 step 1: objective=1.422808 reg=0.002629
2017/08/29 14:58:20 step 2: objective=1.424301 reg=0.002630
2017/08/29 14:58:23 step 3: objective=1.425512 reg=0.002630
2017/08/29 14:58:25 step 4: objective=1.426965 reg=0.002629
2017/08/29 14:58:28 step 5: objective=1.428184 reg=0.002629
2017/08/29 14:58:31 step 6: objective=1.430607 reg=0.002629
2017/08/29 14:58:34 step 7: objective=1.431834 reg=0.002629
2017/08/29 14:58:34 Training value function...
2017/08/29 14:58:37 step 0: mse=132.575998 step=0.100000
2017/08/29 14:58:38 step 1: mse=130.263890 step=0.100000
2017/08/29 14:58:40 step 2: mse=128.110686 step=0.100000
2017/08/29 14:58:41 step 3: mse=126.349845 step=0.100000
2017/08/29 14:58:43 step 4: mse=124.341818 step=0.100000
2017/08/29 14:58:45 step 5: mse=123.126218 step=0.100000
2017/08/29 14:58:46 step 6: mse=121.880313 step=0.100000
2017/08/29 14:58:48 step 7: mse=120.685392 step=0.100000
2017/08/29 14:58:48 Saving...
2017/08/29 14:58:48 Gathering batch of experience...
2017/08/29 14:59:37 batch 127: mean=298.625000 stddev=212.340492 entropy=0.259664 frames=6775 count=24
2017/08/29 14:59:37 Training policy...
2017/08/29 14:59:43 tune 0: objective=0.492959 reg=0.002597 prune=0
2017/08/29 14:59:47 tune 1: objective=0.496320 reg=0.002596 prune=0
2017/08/29 14:59:51 tune 2: objective=0.499636 reg=0.002596 prune=0
2017/08/29 14:59:55 tune 3: objective=0.502907 reg=0.002595 prune=0
2017/08/29 14:59:58 tune 4: objective=0.506125 reg=0.002595 prune=0
2017/08/29 15:00:02 tune 5: objective=0.509102 reg=0.002594 prune=0
2017/08/29 15:00:06 tune 6: objective=0.511687 reg=0.002594 prune=0
2017/08/29 15:00:10 tune 7: objective=0.514231 reg=0.002594 prune=0
2017/08/29 15:00:12 step 0: objective=0.516633 reg=0.002593
2017/08/29 15:00:15 step 1: objective=0.519095 reg=0.002593
2017/08/29 15:00:17 step 2: objective=0.520906 reg=0.002593
2017/08/29 15:00:20 step 3: objective=0.522773 reg=0.002592
2017/08/29 15:00:22 step 4: objective=0.524685 reg=0.002591
2017/08/29 15:00:25 step 5: objective=0.527020 reg=0.002591
2017/08/29 15:00:27 step 6: objective=0.528863 reg=0.002590
2017/08/29 15:00:30 step 7: objective=0.530894 reg=0.002590
2017/08/29 15:00:30 Training value function...
2017/08/29 15:00:33 step 0: mse=146.509716 step=0.100000
2017/08/29 15:00:34 step 1: mse=145.570469 step=0.100000
2017/08/29 15:00:36 step 2: mse=144.913724 step=0.100000
2017/08/29 15:00:37 step 3: mse=144.157919 step=0.100000
2017/08/29 15:00:38 step 4: mse=143.465239 step=0.100000
2017/08/29 15:00:40 step 5: mse=143.069615 step=0.100000
2017/08/29 15:00:41 step 6: mse=142.744862 step=0.100000
2017/08/29 15:00:43 step 7: mse=142.151666 step=0.100000
2017/08/29 15:00:43 Saving...
2017/08/29 15:00:43 Gathering batch of experience...
2017/08/29 15:01:29 batch 128: mean=326.809524 stddev=247.789584 entropy=0.267866 frames=6476 count=21
2017/08/29 15:01:29 Training policy...
2017/08/29 15:01:35 tune 0: objective=1.286768 reg=0.002679 prune=0
2017/08/29 15:01:39 tune 1: objective=1.289637 reg=0.002678 prune=0
2017/08/29 15:01:42 tune 2: objective=1.292480 reg=0.002678 prune=0
2017/08/29 15:01:46 tune 3: objective=1.295299 reg=0.002677 prune=0
2017/08/29 15:01:50 tune 4: objective=1.298091 reg=0.002677 prune=0
2017/08/29 15:01:53 tune 5: objective=1.300812 reg=0.002677 prune=0
2017/08/29 15:01:57 tune 6: objective=1.303386 reg=0.002676 prune=0
2017/08/29 15:02:00 tune 7: objective=1.305726 reg=0.002676 prune=0
2017/08/29 15:02:03 step 0: objective=1.307870 reg=0.002676
2017/08/29 15:02:05 step 1: objective=1.309634 reg=0.002676
2017/08/29 15:02:08 step 2: objective=1.311711 reg=0.002675
2017/08/29 15:02:10 step 3: objective=1.313823 reg=0.002675
2017/08/29 15:02:12 step 4: objective=1.316503 reg=0.002676
2017/08/29 15:02:15 step 5: objective=1.317751 reg=0.002676
2017/08/29 15:02:17 step 6: objective=1.318688 reg=0.002676
2017/08/29 15:02:20 step 7: objective=1.319995 reg=0.002675
2017/08/29 15:02:20 Training value function...
2017/08/29 15:02:22 step 0: mse=130.598777 step=0.100000
2017/08/29 15:02:24 step 1: mse=127.797566 step=0.100000
2017/08/29 15:02:25 step 2: mse=125.471906 step=0.100000
2017/08/29 15:02:26 step 3: mse=123.151543 step=0.100000
2017/08/29 15:02:28 step 4: mse=121.006623 step=0.100000
2017/08/29 15:02:29 step 5: mse=119.471827 step=0.100000
2017/08/29 15:02:30 step 6: mse=118.454202 step=0.100000
2017/08/29 15:02:32 step 7: mse=117.306008 step=0.100000
2017/08/29 15:02:32 Saving...
2017/08/29 15:02:32 Gathering batch of experience...
2017/08/29 15:03:24 batch 129: mean=371.727273 stddev=242.770595 entropy=0.265787 frames=7710 count=22
2017/08/29 15:03:24 Training policy...
2017/08/29 15:03:32 tune 0: objective=1.134083 reg=0.002658 prune=0
2017/08/29 15:03:36 tune 1: objective=1.136489 reg=0.002658 prune=0
2017/08/29 15:03:41 tune 2: objective=1.138881 reg=0.002658 prune=0
2017/08/29 15:03:45 tune 3: objective=1.141258 reg=0.002657 prune=0
2017/08/29 15:03:49 tune 4: objective=1.143585 reg=0.002657 prune=0
2017/08/29 15:03:54 tune 5: objective=1.145701 reg=0.002657 prune=0
2017/08/29 15:03:58 tune 6: objective=1.147701 reg=0.002657 prune=0
2017/08/29 15:04:02 tune 7: objective=1.149520 reg=0.002657 prune=0
2017/08/29 15:04:05 step 0: objective=1.151227 reg=0.002657
2017/08/29 15:04:08 step 1: objective=1.154250 reg=0.002657
2017/08/29 15:04:11 step 2: objective=1.156574 reg=0.002657
2017/08/29 15:04:14 step 3: objective=1.159302 reg=0.002658
2017/08/29 15:04:17 step 4: objective=1.160553 reg=0.002656
2017/08/29 15:04:19 step 5: objective=1.161839 reg=0.002656
2017/08/29 15:04:22 step 6: objective=1.162887 reg=0.002656
2017/08/29 15:04:25 step 7: objective=1.164653 reg=0.002655
2017/08/29 15:04:25 Training value function...
2017/08/29 15:04:28 step 0: mse=142.146278 step=0.100000
2017/08/29 15:04:30 step 1: mse=139.198781 step=0.100000
2017/08/29 15:04:32 step 2: mse=136.995796 step=0.100000
2017/08/29 15:04:33 step 3: mse=135.168913 step=0.100000
2017/08/29 15:04:35 step 4: mse=133.507466 step=0.100000
2017/08/29 15:04:37 step 5: mse=132.180618 step=0.100000
2017/08/29 15:04:38 step 6: mse=130.852510 step=0.100000
2017/08/29 15:04:40 step 7: mse=129.486420 step=0.100000
2017/08/29 15:04:40 Saving...
2017/08/29 15:04:40 Gathering batch of experience...
2017/08/29 15:05:29 batch 130: mean=394.333333 stddev=210.357594 entropy=0.267464 frames=7669 count=21
2017/08/29 15:05:29 Training policy...
2017/08/29 15:05:37 tune 0: objective=1.360579 reg=0.002675 prune=0
2017/08/29 15:05:41 tune 1: objective=1.363076 reg=0.002674 prune=0
2017/08/29 15:05:45 tune 2: objective=1.365562 reg=0.002674 prune=0
2017/08/29 15:05:50 tune 3: objective=1.368023 reg=0.002674 prune=0
2017/08/29 15:05:54 tune 4: objective=1.370471 reg=0.002673 prune=0
2017/08/29 15:05:58 tune 5: objective=1.372826 reg=0.002673 prune=0
2017/08/29 15:06:03 tune 6: objective=1.375048 reg=0.002673 prune=0
2017/08/29 15:06:07 tune 7: objective=1.377245 reg=0.002673 prune=0
2017/08/29 15:06:10 step 0: objective=1.379254 reg=0.002672
2017/08/29 15:06:13 step 1: objective=1.382302 reg=0.002673
2017/08/29 15:06:16 step 2: objective=1.384680 reg=0.002673
2017/08/29 15:06:18 step 3: objective=1.386087 reg=0.002673
2017/08/29 15:06:21 step 4: objective=1.388271 reg=0.002673
2017/08/29 15:06:24 step 5: objective=1.389460 reg=0.002673
2017/08/29 15:06:27 step 6: objective=1.392150 reg=0.002673
2017/08/29 15:06:30 step 7: objective=1.393764 reg=0.002673
2017/08/29 15:06:30 Training value function...
2017/08/29 15:06:33 step 0: mse=151.852739 step=0.100000
2017/08/29 15:06:35 step 1: mse=149.922077 step=0.100000
2017/08/29 15:06:36 step 2: mse=148.196525 step=0.100000
2017/08/29 15:06:38 step 3: mse=146.697429 step=0.100000
2017/08/29 15:06:39 step 4: mse=145.475506 step=0.100000
2017/08/29 15:06:41 step 5: mse=144.564737 step=0.100000
2017/08/29 15:06:43 step 6: mse=143.610180 step=0.100000
2017/08/29 15:06:44 step 7: mse=142.347430 step=0.100000
2017/08/29 15:06:44 Saving...
2017/08/29 15:06:44 Gathering batch of experience...
2017/08/29 15:07:37 batch 131: mean=359.478261 stddev=224.671522 entropy=0.267334 frames=7756 count=23
2017/08/29 15:07:37 Training policy...
2017/08/29 15:07:44 tune 0: objective=0.916041 reg=0.002673 prune=0
2017/08/29 15:07:48 tune 1: objective=0.918390 reg=0.002673 prune=0
2017/08/29 15:07:53 tune 2: objective=0.920713 reg=0.002672 prune=0
2017/08/29 15:07:57 tune 3: objective=0.923010 reg=0.002672 prune=0
2017/08/29 15:08:02 tune 4: objective=0.925282 reg=0.002671 prune=0
2017/08/29 15:08:06 tune 5: objective=0.927466 reg=0.002671 prune=0
2017/08/29 15:08:10 tune 6: objective=0.929514 reg=0.002670 prune=0
2017/08/29 15:08:15 tune 7: objective=0.931316 reg=0.002670 prune=0
2017/08/29 15:08:18 step 0: objective=0.932948 reg=0.002669
2017/08/29 15:08:21 step 1: objective=0.934282 reg=0.002669
2017/08/29 15:08:23 step 2: objective=0.935950 reg=0.002668
2017/08/29 15:08:26 step 3: objective=0.937242 reg=0.002668
2017/08/29 15:08:29 step 4: objective=0.938387 reg=0.002669
2017/08/29 15:08:32 step 5: objective=0.940119 reg=0.002669
2017/08/29 15:08:35 step 6: objective=0.941115 reg=0.002669
2017/08/29 15:08:38 step 7: objective=0.942158 reg=0.002669
2017/08/29 15:08:38 Training value function...
2017/08/29 15:08:41 step 0: mse=108.494389 step=0.100000
2017/08/29 15:08:43 step 1: mse=107.840864 step=0.100000
2017/08/29 15:08:44 step 2: mse=107.172113 step=0.100000
2017/08/29 15:08:46 step 3: mse=106.317367 step=0.100000
2017/08/29 15:08:47 step 4: mse=105.705983 step=0.100000
2017/08/29 15:08:49 step 5: mse=105.250298 step=0.100000
2017/08/29 15:08:51 step 6: mse=104.764750 step=0.100000
2017/08/29 15:08:52 step 7: mse=104.274690 step=0.100000
2017/08/29 15:08:52 Saving...
2017/08/29 15:08:52 Gathering batch of experience...
2017/08/29 15:09:45 batch 132: mean=316.041667 stddev=220.892975 entropy=0.263982 frames=7216 count=24
2017/08/29 15:09:45 Training policy...
2017/08/29 15:09:52 tune 0: objective=0.616246 reg=0.002640 prune=0
2017/08/29 15:09:57 tune 1: objective=0.618854 reg=0.002640 prune=0
2017/08/29 15:10:01 tune 2: objective=0.621430 reg=0.002640 prune=0
2017/08/29 15:10:05 tune 3: objective=0.623971 reg=0.002640 prune=0
2017/08/29 15:10:09 tune 4: objective=0.626286 reg=0.002640 prune=0
2017/08/29 15:10:13 tune 5: objective=0.628438 reg=0.002640 prune=0
2017/08/29 15:10:17 tune 6: objective=0.630574 reg=0.002640 prune=0
2017/08/29 15:10:21 tune 7: objective=0.632639 reg=0.002640 prune=0
2017/08/29 15:10:24 step 0: objective=0.634521 reg=0.002640
2017/08/29 15:10:26 step 1: objective=0.636433 reg=0.002641
2017/08/29 15:10:29 step 2: objective=0.638210 reg=0.002640
2017/08/29 15:10:32 step 3: objective=0.640466 reg=0.002640
2017/08/29 15:10:34 step 4: objective=0.642174 reg=0.002640
2017/08/29 15:10:37 step 5: objective=0.643815 reg=0.002640
2017/08/29 15:10:40 step 6: objective=0.646150 reg=0.002640
2017/08/29 15:10:42 step 7: objective=0.647566 reg=0.002640
2017/08/29 15:10:42 Training value function...
2017/08/29 15:10:45 step 0: mse=142.147260 step=0.100000
2017/08/29 15:10:47 step 1: mse=141.026001 step=0.100000
2017/08/29 15:10:48 step 2: mse=140.563879 step=0.100000
2017/08/29 15:10:50 step 3: mse=139.860010 step=0.100000
2017/08/29 15:10:51 step 4: mse=139.256532 step=0.100000
2017/08/29 15:10:53 step 5: mse=138.834398 step=0.100000
2017/08/29 15:10:54 step 6: mse=138.540826 step=0.100000
2017/08/29 15:10:56 step 7: mse=138.445107 step=0.100000
2017/08/29 15:10:56 Saving...
2017/08/29 15:10:56 Gathering batch of experience...
2017/08/29 15:11:50 batch 133: mean=424.772727 stddev=235.544617 entropy=0.263223 frames=8431 count=22
2017/08/29 15:11:50 Training policy...
2017/08/29 15:11:58 tune 0: objective=1.943169 reg=0.002632 prune=0
2017/08/29 15:12:03 tune 1: objective=1.945373 reg=0.002632 prune=0
2017/08/29 15:12:07 tune 2: objective=1.947556 reg=0.002631 prune=0
2017/08/29 15:12:12 tune 3: objective=1.949722 reg=0.002631 prune=0
2017/08/29 15:12:17 tune 4: objective=1.951875 reg=0.002630 prune=0
2017/08/29 15:12:22 tune 5: objective=1.954016 reg=0.002630 prune=0
2017/08/29 15:12:27 tune 6: objective=1.956092 reg=0.002629 prune=0
2017/08/29 15:12:31 tune 7: objective=1.958093 reg=0.002629 prune=0
2017/08/29 15:12:35 step 0: objective=1.960005 reg=0.002628
2017/08/29 15:12:38 step 1: objective=1.963634 reg=0.002628
2017/08/29 15:12:41 step 2: objective=1.965100 reg=0.002627
2017/08/29 15:12:44 step 3: objective=1.967004 reg=0.002627
2017/08/29 15:12:47 step 4: objective=1.968523 reg=0.002627
2017/08/29 15:12:50 step 5: objective=1.971250 reg=0.002626
2017/08/29 15:12:53 step 6: objective=1.972262 reg=0.002625
2017/08/29 15:12:56 step 7: objective=1.973689 reg=0.002625
2017/08/29 15:12:56 Training value function...
2017/08/29 15:13:00 step 0: mse=153.245614 step=0.100000
2017/08/29 15:13:02 step 1: mse=150.152310 step=0.100000
2017/08/29 15:13:03 step 2: mse=147.458184 step=0.100000
2017/08/29 15:13:05 step 3: mse=145.245725 step=0.100000
2017/08/29 15:13:07 step 4: mse=142.950367 step=0.100000
2017/08/29 15:13:09 step 5: mse=141.057876 step=0.100000
2017/08/29 15:13:11 step 6: mse=139.044466 step=0.100000
2017/08/29 15:13:12 step 7: mse=137.682175 step=0.100000
2017/08/29 15:13:12 Saving...
2017/08/29 15:13:12 Gathering batch of experience...
2017/08/29 15:13:59 batch 134: mean=371.285714 stddev=234.256909 entropy=0.263662 frames=7255 count=21
2017/08/29 15:13:59 Training policy...
2017/08/29 15:14:06 tune 0: objective=0.862282 reg=0.002637 prune=0
2017/08/29 15:14:10 tune 1: objective=0.865000 reg=0.002637 prune=0
2017/08/29 15:14:14 tune 2: objective=0.867683 reg=0.002638 prune=0
2017/08/29 15:14:18 tune 3: objective=0.870328 reg=0.002638 prune=0
2017/08/29 15:14:22 tune 4: objective=0.872785 reg=0.002639 prune=0
2017/08/29 15:14:26 tune 5: objective=0.874987 reg=0.002639 prune=0
2017/08/29 15:14:31 tune 6: objective=0.876991 reg=0.002640 prune=0
2017/08/29 15:14:35 tune 7: objective=0.878933 reg=0.002640 prune=0
2017/08/29 15:14:37 step 0: objective=0.880688 reg=0.002641
2017/08/29 15:14:40 step 1: objective=0.883862 reg=0.002642
2017/08/29 15:14:43 step 2: objective=0.885661 reg=0.002641
2017/08/29 15:14:45 step 3: objective=0.888335 reg=0.002643
2017/08/29 15:14:48 step 4: objective=0.889830 reg=0.002643
2017/08/29 15:14:51 step 5: objective=0.891039 reg=0.002643
2017/08/29 15:14:54 step 6: objective=0.892257 reg=0.002642
2017/08/29 15:14:56 step 7: objective=0.894366 reg=0.002643
2017/08/29 15:14:56 Training value function...
2017/08/29 15:14:59 step 0: mse=119.150902 step=0.100000
2017/08/29 15:15:01 step 1: mse=118.668518 step=0.100000
2017/08/29 15:15:02 step 2: mse=118.213720 step=0.100000
2017/08/29 15:15:04 step 3: mse=117.704678 step=0.100000
2017/08/29 15:15:05 step 4: mse=117.424534 step=0.100000
2017/08/29 15:15:07 step 5: mse=117.017536 step=0.100000
2017/08/29 15:15:08 step 6: mse=116.673745 step=0.100000
2017/08/29 15:15:10 step 7: mse=116.231762 step=0.100000
2017/08/29 15:15:10 Saving...
2017/08/29 15:15:10 Gathering batch of experience...
2017/08/29 15:15:58 batch 135: mean=386.210526 stddev=208.729132 entropy=0.260808 frames=6838 count=19
2017/08/29 15:15:58 Training policy...
2017/08/29 15:16:04 tune 0: objective=0.978914 reg=0.002608 prune=0
2017/08/29 15:16:08 tune 1: objective=0.980968 reg=0.002608 prune=0
2017/08/29 15:16:12 tune 2: objective=0.983017 reg=0.002608 prune=0
2017/08/29 15:16:16 tune 3: objective=0.985060 reg=0.002608 prune=0
2017/08/29 15:16:20 tune 4: objective=0.987100 reg=0.002608 prune=0
2017/08/29 15:16:24 tune 5: objective=0.989133 reg=0.002608 prune=0
2017/08/29 15:16:28 tune 6: objective=0.991145 reg=0.002608 prune=0
2017/08/29 15:16:31 tune 7: objective=0.993087 reg=0.002607 prune=0
2017/08/29 15:16:34 step 0: objective=0.994946 reg=0.002607
2017/08/29 15:16:37 step 1: objective=0.996276 reg=0.002607
2017/08/29 15:16:39 step 2: objective=0.998375 reg=0.002607
2017/08/29 15:16:42 step 3: objective=1.001304 reg=0.002606
2017/08/29 15:16:44 step 4: objective=1.002643 reg=0.002606
2017/08/29 15:16:47 step 5: objective=1.003737 reg=0.002605
2017/08/29 15:16:49 step 6: objective=1.004896 reg=0.002605
2017/08/29 15:16:52 step 7: objective=1.005871 reg=0.002605
2017/08/29 15:16:52 Training value function...
2017/08/29 15:16:55 step 0: mse=123.188723 step=0.100000
2017/08/29 15:16:56 step 1: mse=121.130105 step=0.100000
2017/08/29 15:16:57 step 2: mse=119.620550 step=0.100000
2017/08/29 15:16:59 step 3: mse=118.370778 step=0.100000
2017/08/29 15:17:00 step 4: mse=117.183314 step=0.100000
2017/08/29 15:17:02 step 5: mse=116.068533 step=0.100000
2017/08/29 15:17:03 step 6: mse=114.952886 step=0.100000
2017/08/29 15:17:05 step 7: mse=114.280661 step=0.100000
2017/08/29 15:17:05 Saving...
2017/08/29 15:17:05 Gathering batch of experience...
2017/08/29 15:18:01 batch 136: mean=424.952381 stddev=196.135394 entropy=0.263683 frames=8247 count=21
2017/08/29 15:18:01 Training policy...
2017/08/29 15:18:09 tune 0: objective=1.200664 reg=0.002637 prune=0
2017/08/29 15:18:13 tune 1: objective=1.202781 reg=0.002636 prune=0
2017/08/29 15:18:18 tune 2: objective=1.204875 reg=0.002636 prune=0
2017/08/29 15:18:23 tune 3: objective=1.206945 reg=0.002635 prune=0
2017/08/29 15:18:28 tune 4: objective=1.208993 reg=0.002635 prune=0
2017/08/29 15:18:32 tune 5: objective=1.211019 reg=0.002634 prune=0
2017/08/29 15:18:37 tune 6: objective=1.212774 reg=0.002633 prune=0
2017/08/29 15:18:42 tune 7: objective=1.214405 reg=0.002633 prune=0
2017/08/29 15:18:45 step 0: objective=1.215973 reg=0.002632
2017/08/29 15:18:48 step 1: objective=1.217492 reg=0.002632
2017/08/29 15:18:51 step 2: objective=1.218940 reg=0.002633
2017/08/29 15:18:54 step 3: objective=1.220104 reg=0.002633
2017/08/29 15:18:57 step 4: objective=1.221804 reg=0.002633
2017/08/29 15:19:00 step 5: objective=1.223185 reg=0.002632
2017/08/29 15:19:03 step 6: objective=1.224655 reg=0.002632
2017/08/29 15:19:06 step 7: objective=1.226475 reg=0.002632
2017/08/29 15:19:06 Training value function...
2017/08/29 15:19:10 step 0: mse=136.350743 step=0.100000
2017/08/29 15:19:11 step 1: mse=133.459875 step=0.100000
2017/08/29 15:19:13 step 2: mse=130.956548 step=0.100000
2017/08/29 15:19:15 step 3: mse=128.961530 step=0.100000
2017/08/29 15:19:17 step 4: mse=127.293975 step=0.100000
2017/08/29 15:19:18 step 5: mse=125.705761 step=0.100000
2017/08/29 15:19:20 step 6: mse=124.714212 step=0.100000
2017/08/29 15:19:22 step 7: mse=123.412385 step=0.100000
2017/08/29 15:19:22 Saving...
2017/08/29 15:19:22 Gathering batch of experience...
2017/08/29 15:20:09 batch 137: mean=401.777778 stddev=224.517397 entropy=0.260100 frames=6750 count=18
2017/08/29 15:20:09 Training policy...
2017/08/29 15:20:16 tune 0: objective=0.984385 reg=0.002601 prune=0
2017/08/29 15:20:20 tune 1: objective=0.986672 reg=0.002601 prune=0
2017/08/29 15:20:24 tune 2: objective=0.988951 reg=0.002602 prune=0
2017/08/29 15:20:27 tune 3: objective=0.991219 reg=0.002602 prune=0
2017/08/29 15:20:31 tune 4: objective=0.993485 reg=0.002603 prune=0
2017/08/29 15:20:35 tune 5: objective=0.995742 reg=0.002603 prune=0
2017/08/29 15:20:39 tune 6: objective=0.997991 reg=0.002603 prune=0
2017/08/29 15:20:43 tune 7: objective=1.000145 reg=0.002604 prune=0
2017/08/29 15:20:45 step 0: objective=1.002157 reg=0.002604
2017/08/29 15:20:48 step 1: objective=1.004580 reg=0.002605
2017/08/29 15:20:50 step 2: objective=1.006377 reg=0.002606
2017/08/29 15:20:53 step 3: objective=1.008816 reg=0.002605
2017/08/29 15:20:55 step 4: objective=1.010746 reg=0.002606
2017/08/29 15:20:58 step 5: objective=1.011820 reg=0.002606
2017/08/29 15:21:00 step 6: objective=1.012952 reg=0.002606
2017/08/29 15:21:03 step 7: objective=1.013853 reg=0.002606
2017/08/29 15:21:03 Training value function...
2017/08/29 15:21:05 step 0: mse=111.957503 step=0.100000
2017/08/29 15:21:07 step 1: mse=111.118934 step=0.100000
2017/08/29 15:21:08 step 2: mse=110.303504 step=0.100000
2017/08/29 15:21:10 step 3: mse=109.667204 step=0.100000
2017/08/29 15:21:11 step 4: mse=108.776206 step=0.100000
2017/08/29 15:21:13 step 5: mse=108.183797 step=0.100000
2017/08/29 15:21:14 step 6: mse=107.468165 step=0.100000
2017/08/29 15:21:15 step 7: mse=106.746062 step=0.100000
2017/08/29 15:21:15 Saving...
2017/08/29 15:21:15 Gathering batch of experience...
2017/08/29 15:22:04 batch 138: mean=358.095238 stddev=227.611387 entropy=0.259138 frames=7062 count=21
2017/08/29 15:22:04 Training policy...
2017/08/29 15:22:11 tune 0: objective=0.892646 reg=0.002591 prune=0
2017/08/29 15:22:15 tune 1: objective=0.894789 reg=0.002592 prune=0
2017/08/29 15:22:19 tune 2: objective=0.896917 reg=0.002592 prune=0
2017/08/29 15:22:23 tune 3: objective=0.899032 reg=0.002592 prune=0
2017/08/29 15:22:27 tune 4: objective=0.901132 reg=0.002592 prune=0
2017/08/29 15:22:31 tune 5: objective=0.903220 reg=0.002592 prune=0
2017/08/29 15:22:35 tune 6: objective=0.905289 reg=0.002592 prune=0
2017/08/29 15:22:39 tune 7: objective=0.907214 reg=0.002592 prune=0
2017/08/29 15:22:41 step 0: objective=0.908981 reg=0.002592
2017/08/29 15:22:44 step 1: objective=0.911326 reg=0.002592
2017/08/29 15:22:47 step 2: objective=0.913084 reg=0.002592
2017/08/29 15:22:49 step 3: objective=0.914769 reg=0.002592
2017/08/29 15:22:52 step 4: objective=0.915849 reg=0.002592
2017/08/29 15:22:55 step 5: objective=0.917373 reg=0.002593
2017/08/29 15:22:57 step 6: objective=0.919678 reg=0.002593
2017/08/29 15:23:00 step 7: objective=0.921150 reg=0.002593
2017/08/29 15:23:00 Training value function...
2017/08/29 15:23:03 step 0: mse=111.325137 step=0.100000
2017/08/29 15:23:04 step 1: mse=110.169143 step=0.100000
2017/08/29 15:23:06 step 2: mse=109.584400 step=0.100000
2017/08/29 15:23:07 step 3: mse=109.113895 step=0.100000
2017/08/29 15:23:09 step 4: mse=108.088793 step=0.100000
2017/08/29 15:23:10 step 5: mse=107.307287 step=0.100000
2017/08/29 15:23:12 step 6: mse=106.737242 step=0.100000
2017/08/29 15:23:13 step 7: mse=106.025238 step=0.100000
2017/08/29 15:23:13 Saving...
2017/08/29 15:23:13 Gathering batch of experience...
2017/08/29 15:24:05 batch 139: mean=386.238095 stddev=191.139168 entropy=0.264834 frames=7464 count=21
2017/08/29 15:24:05 Training policy...
2017/08/29 15:24:12 tune 0: objective=1.221870 reg=0.002648 prune=0
2017/08/29 15:24:17 tune 1: objective=1.223919 reg=0.002647 prune=0
2017/08/29 15:24:21 tune 2: objective=1.225962 reg=0.002646 prune=0
2017/08/29 15:24:25 tune 3: objective=1.227985 reg=0.002646 prune=0
2017/08/29 15:24:29 tune 4: objective=1.230000 reg=0.002645 prune=0
2017/08/29 15:24:34 tune 5: objective=1.232005 reg=0.002644 prune=0
2017/08/29 15:24:38 tune 6: objective=1.233980 reg=0.002643 prune=0
2017/08/29 15:24:42 tune 7: objective=1.235829 reg=0.002642 prune=0
2017/08/29 15:24:45 step 0: objective=1.237565 reg=0.002641
2017/08/29 15:24:48 step 1: objective=1.238908 reg=0.002641
2017/08/29 15:24:50 step 2: objective=1.240360 reg=0.002640
2017/08/29 15:24:53 step 3: objective=1.241896 reg=0.002640
2017/08/29 15:24:56 step 4: objective=1.244591 reg=0.002639
2017/08/29 15:24:59 step 5: objective=1.246078 reg=0.002639
2017/08/29 15:25:01 step 6: objective=1.247200 reg=0.002639
2017/08/29 15:25:04 step 7: objective=1.248150 reg=0.002638
2017/08/29 15:25:04 Training value function...
2017/08/29 15:25:07 step 0: mse=134.452309 step=0.100000
2017/08/29 15:25:09 step 1: mse=132.628705 step=0.100000
2017/08/29 15:25:11 step 2: mse=131.304657 step=0.100000
2017/08/29 15:25:12 step 3: mse=129.886456 step=0.100000
2017/08/29 15:25:14 step 4: mse=128.961279 step=0.100000
2017/08/29 15:25:15 step 5: mse=127.883806 step=0.100000
2017/08/29 15:25:17 step 6: mse=126.810521 step=0.100000
2017/08/29 15:25:18 step 7: mse=125.779088 step=0.100000
2017/08/29 15:25:18 Saving...
2017/08/29 15:25:18 Gathering batch of experience...
2017/08/29 15:26:15 batch 140: mean=383.208333 stddev=207.898409 entropy=0.259506 frames=8335 count=24
2017/08/29 15:26:15 Training policy...
2017/08/29 15:26:23 tune 0: objective=1.352968 reg=0.002595 prune=0
2017/08/29 15:26:28 tune 1: objective=1.355265 reg=0.002594 prune=0
2017/08/29 15:26:33 tune 2: objective=1.357550 reg=0.002594 prune=0
2017/08/29 15:26:37 tune 3: objective=1.359834 reg=0.002593 prune=0
2017/08/29 15:26:42 tune 4: objective=1.362111 reg=0.002593 prune=0
2017/08/29 15:26:47 tune 5: objective=1.364347 reg=0.002592 prune=0
2017/08/29 15:26:52 tune 6: objective=1.366344 reg=0.002592 prune=0
2017/08/29 15:26:56 tune 7: objective=1.368216 reg=0.002591 prune=0
2017/08/29 15:26:59 step 0: objective=1.369906 reg=0.002591
2017/08/29 15:27:03 step 1: objective=1.371679 reg=0.002591
2017/08/29 15:27:06 step 2: objective=1.373399 reg=0.002590
2017/08/29 15:27:09 step 3: objective=1.374847 reg=0.002590
2017/08/29 15:27:12 step 4: objective=1.375922 reg=0.002591
2017/08/29 15:27:15 step 5: objective=1.378115 reg=0.002591
2017/08/29 15:27:18 step 6: objective=1.380622 reg=0.002590
2017/08/29 15:27:21 step 7: objective=1.382129 reg=0.002591
2017/08/29 15:27:21 Training value function...
2017/08/29 15:27:25 step 0: mse=130.848039 step=0.100000
2017/08/29 15:27:26 step 1: mse=128.968372 step=0.100000
2017/08/29 15:27:28 step 2: mse=127.360365 step=0.100000
2017/08/29 15:27:30 step 3: mse=125.847151 step=0.100000
2017/08/29 15:27:32 step 4: mse=124.946485 step=0.100000
2017/08/29 15:27:33 step 5: mse=123.915433 step=0.100000
2017/08/29 15:27:35 step 6: mse=123.117718 step=0.100000
2017/08/29 15:27:37 step 7: mse=122.215398 step=0.100000
2017/08/29 15:27:37 Saving...
2017/08/29 15:27:37 Gathering batch of experience...
2017/08/29 15:28:19 batch 141: mean=330.684211 stddev=199.528669 entropy=0.257482 frames=5817 count=19
2017/08/29 15:28:19 Training policy...
2017/08/29 15:28:25 tune 0: objective=0.696927 reg=0.002575 prune=0
2017/08/29 15:28:28 tune 1: objective=0.700498 reg=0.002574 prune=0
2017/08/29 15:28:31 tune 2: objective=0.704023 reg=0.002574 prune=0
2017/08/29 15:28:35 tune 3: objective=0.707449 reg=0.002573 prune=0
2017/08/29 15:28:38 tune 4: objective=0.710672 reg=0.002573 prune=0
2017/08/29 15:28:41 tune 5: objective=0.713662 reg=0.002572 prune=0
2017/08/29 15:28:44 tune 6: objective=0.716449 reg=0.002572 prune=0
2017/08/29 15:28:48 tune 7: objective=0.719055 reg=0.002571 prune=0
2017/08/29 15:28:50 step 0: objective=0.721430 reg=0.002571
2017/08/29 15:28:52 step 1: objective=0.724168 reg=0.002572
2017/08/29 15:28:54 step 2: objective=0.725781 reg=0.002571
2017/08/29 15:28:56 step 3: objective=0.728004 reg=0.002569
2017/08/29 15:28:59 step 4: objective=0.729323 reg=0.002569
2017/08/29 15:29:01 step 5: objective=0.731026 reg=0.002568
2017/08/29 15:29:03 step 6: objective=0.732684 reg=0.002568
2017/08/29 15:29:05 step 7: objective=0.733885 reg=0.002569
2017/08/29 15:29:05 Training value function...
2017/08/29 15:29:07 step 0: mse=141.214197 step=0.100000
2017/08/29 15:29:09 step 1: mse=139.797496 step=0.100000
2017/08/29 15:29:10 step 2: mse=138.620471 step=0.100000
2017/08/29 15:29:11 step 3: mse=137.559617 step=0.100000
2017/08/29 15:29:12 step 4: mse=136.896629 step=0.100000
2017/08/29 15:29:14 step 5: mse=135.942777 step=0.100000
2017/08/29 15:29:15 step 6: mse=135.242874 step=0.100000
2017/08/29 15:29:16 step 7: mse=134.463118 step=0.100000
2017/08/29 15:29:16 Saving...
2017/08/29 15:29:16 Gathering batch of experience...
2017/08/29 15:30:08 batch 142: mean=342.608696 stddev=184.289172 entropy=0.257640 frames=7549 count=23
2017/08/29 15:30:08 Training policy...
2017/08/29 15:30:15 tune 0: objective=0.468763 reg=0.002576 prune=0
2017/08/29 15:30:19 tune 1: objective=0.471251 reg=0.002576 prune=0
2017/08/29 15:30:24 tune 2: objective=0.473709 reg=0.002577 prune=0
2017/08/29 15:30:28 tune 3: objective=0.476140 reg=0.002577 prune=0
2017/08/29 15:30:32 tune 4: objective=0.478507 reg=0.002577 prune=0
2017/08/29 15:30:36 tune 5: objective=0.480698 reg=0.002577 prune=0
2017/08/29 15:30:41 tune 6: objective=0.482641 reg=0.002577 prune=0
2017/08/29 15:30:45 tune 7: objective=0.484352 reg=0.002577 prune=0
2017/08/29 15:30:48 step 0: objective=0.485941 reg=0.002577
2017/08/29 15:30:51 step 1: objective=0.487283 reg=0.002576
2017/08/29 15:30:54 step 2: objective=0.488493 reg=0.002577
2017/08/29 15:30:56 step 3: objective=0.489796 reg=0.002577
2017/08/29 15:30:59 step 4: objective=0.490864 reg=0.002577
2017/08/29 15:31:02 step 5: objective=0.493033 reg=0.002577
2017/08/29 15:31:05 step 6: objective=0.494168 reg=0.002577
2017/08/29 15:31:08 step 7: objective=0.495014 reg=0.002577
2017/08/29 15:31:08 Training value function...
2017/08/29 15:31:11 step 0: mse=113.940505 step=0.100000
2017/08/29 15:31:12 step 1: mse=112.849131 step=0.100000
2017/08/29 15:31:14 step 2: mse=111.993768 step=0.100000
2017/08/29 15:31:16 step 3: mse=111.438693 step=0.100000
2017/08/29 15:31:17 step 4: mse=110.900850 step=0.100000
2017/08/29 15:31:19 step 5: mse=110.676308 step=0.100000
2017/08/29 15:31:20 step 6: mse=110.544962 step=0.100000
2017/08/29 15:31:22 step 7: mse=110.361782 step=0.100000
2017/08/29 15:31:22 Saving...
2017/08/29 15:31:22 Gathering batch of experience...
2017/08/29 15:32:12 batch 143: mean=325.416667 stddev=207.461626 entropy=0.262650 frames=7199 count=24
2017/08/29 15:32:12 Training policy...
2017/08/29 15:32:19 tune 0: objective=1.331814 reg=0.002626 prune=0
2017/08/29 15:32:23 tune 1: objective=1.334141 reg=0.002627 prune=0
2017/08/29 15:32:27 tune 2: objective=1.336452 reg=0.002627 prune=0
2017/08/29 15:32:31 tune 3: objective=1.338755 reg=0.002627 prune=0
2017/08/29 15:32:35 tune 4: objective=1.341041 reg=0.002627 prune=0
2017/08/29 15:32:39 tune 5: objective=1.343314 reg=0.002627 prune=0
2017/08/29 15:32:43 tune 6: objective=1.345564 reg=0.002627 prune=0
2017/08/29 15:32:47 tune 7: objective=1.347648 reg=0.002627 prune=0
2017/08/29 15:32:50 step 0: objective=1.349619 reg=0.002627
2017/08/29 15:32:53 step 1: objective=1.351116 reg=0.002628
2017/08/29 15:32:56 step 2: objective=1.353093 reg=0.002627
2017/08/29 15:32:58 step 3: objective=1.355113 reg=0.002628
2017/08/29 15:33:01 step 4: objective=1.357360 reg=0.002629
2017/08/29 15:33:04 step 5: objective=1.359657 reg=0.002628
2017/08/29 15:33:06 step 6: objective=1.360963 reg=0.002628
2017/08/29 15:33:09 step 7: objective=1.363102 reg=0.002628
2017/08/29 15:33:09 Training value function...
2017/08/29 15:33:12 step 0: mse=133.994642 step=0.100000
2017/08/29 15:33:13 step 1: mse=132.463634 step=0.100000
2017/08/29 15:33:15 step 2: mse=131.110410 step=0.100000
2017/08/29 15:33:16 step 3: mse=129.989449 step=0.100000
2017/08/29 15:33:18 step 4: mse=129.195458 step=0.100000
2017/08/29 15:33:19 step 5: mse=128.072290 step=0.100000
2017/08/29 15:33:21 step 6: mse=127.395156 step=0.100000
2017/08/29 15:33:22 step 7: mse=126.805242 step=0.100000
2017/08/29 15:33:22 Saving...
2017/08/29 15:33:23 Gathering batch of experience...
2017/08/29 15:34:19 batch 144: mean=330.480000 stddev=179.922899 entropy=0.251734 frames=7787 count=25
2017/08/29 15:34:19 Training policy...
2017/08/29 15:34:27 tune 0: objective=0.784461 reg=0.002517 prune=0
2017/08/29 15:34:31 tune 1: objective=0.786940 reg=0.002517 prune=0
2017/08/29 15:34:36 tune 2: objective=0.789395 reg=0.002516 prune=0
2017/08/29 15:34:40 tune 3: objective=0.791821 reg=0.002516 prune=0
2017/08/29 15:34:45 tune 4: objective=0.794224 reg=0.002515 prune=0
2017/08/29 15:34:49 tune 5: objective=0.796550 reg=0.002515 prune=0
2017/08/29 15:34:54 tune 6: objective=0.798735 reg=0.002515 prune=0
2017/08/29 15:34:58 tune 7: objective=0.800799 reg=0.002514 prune=0
2017/08/29 15:35:01 step 0: objective=0.802767 reg=0.002514
2017/08/29 15:35:04 step 1: objective=0.804657 reg=0.002514
2017/08/29 15:35:07 step 2: objective=0.806899 reg=0.002513
2017/08/29 15:35:10 step 3: objective=0.808785 reg=0.002512
2017/08/29 15:35:13 step 4: objective=0.809797 reg=0.002512
2017/08/29 15:35:16 step 5: objective=0.811473 reg=0.002512
2017/08/29 15:35:18 step 6: objective=0.812897 reg=0.002512
2017/08/29 15:35:21 step 7: objective=0.814039 reg=0.002512
2017/08/29 15:35:21 Training value function...
2017/08/29 15:35:25 step 0: mse=138.135082 step=0.100000
2017/08/29 15:35:26 step 1: mse=136.469483 step=0.100000
2017/08/29 15:35:28 step 2: mse=135.121592 step=0.100000
2017/08/29 15:35:29 step 3: mse=133.985906 step=0.100000
2017/08/29 15:35:31 step 4: mse=132.967256 step=0.100000
2017/08/29 15:35:33 step 5: mse=132.074540 step=0.100000
2017/08/29 15:35:34 step 6: mse=131.415505 step=0.100000
2017/08/29 15:35:36 step 7: mse=130.677065 step=0.100000
2017/08/29 15:35:36 Saving...
2017/08/29 15:35:36 Gathering batch of experience...
2017/08/29 15:36:30 batch 145: mean=377.800000 stddev=205.163739 entropy=0.257583 frames=7273 count=20
2017/08/29 15:36:30 Training policy...
2017/08/29 15:36:37 tune 0: objective=1.016569 reg=0.002576 prune=0
2017/08/29 15:36:41 tune 1: objective=1.018707 reg=0.002575 prune=0
2017/08/29 15:36:45 tune 2: objective=1.020835 reg=0.002575 prune=0
2017/08/29 15:36:49 tune 3: objective=1.022951 reg=0.002574 prune=0
2017/08/29 15:36:54 tune 4: objective=1.025054 reg=0.002574 prune=0
2017/08/29 15:36:58 tune 5: objective=1.027133 reg=0.002573 prune=0
2017/08/29 15:37:02 tune 6: objective=1.029149 reg=0.002573 prune=0
2017/08/29 15:37:06 tune 7: objective=1.031080 reg=0.002572 prune=0
2017/08/29 15:37:09 step 0: objective=1.032835 reg=0.002572
2017/08/29 15:37:12 step 1: objective=1.034386 reg=0.002571
2017/08/29 15:37:14 step 2: objective=1.037240 reg=0.002572
2017/08/29 15:37:17 step 3: objective=1.038943 reg=0.002571
2017/08/29 15:37:20 step 4: objective=1.040739 reg=0.002572
2017/08/29 15:37:22 step 5: objective=1.041809 reg=0.002572
2017/08/29 15:37:25 step 6: objective=1.043026 reg=0.002572
2017/08/29 15:37:28 step 7: objective=1.043792 reg=0.002573
2017/08/29 15:37:28 Training value function...
2017/08/29 15:37:31 step 0: mse=133.993138 step=0.100000
2017/08/29 15:37:32 step 1: mse=132.078028 step=0.100000
2017/08/29 15:37:34 step 2: mse=130.466380 step=0.100000
2017/08/29 15:37:35 step 3: mse=129.201844 step=0.100000
2017/08/29 15:37:37 step 4: mse=128.186743 step=0.100000
2017/08/29 15:37:38 step 5: mse=126.974227 step=0.100000
2017/08/29 15:37:40 step 6: mse=126.259093 step=0.100000
2017/08/29 15:37:42 step 7: mse=125.652197 step=0.100000
2017/08/29 15:37:42 Saving...
2017/08/29 15:37:42 Gathering batch of experience...
2017/08/29 15:38:29 batch 146: mean=330.608696 stddev=253.333212 entropy=0.258997 frames=7095 count=23
2017/08/29 15:38:29 Training policy...
2017/08/29 15:38:36 tune 0: objective=1.399861 reg=0.002590 prune=0
2017/08/29 15:38:40 tune 1: objective=1.402418 reg=0.002590 prune=0
2017/08/29 15:38:44 tune 2: objective=1.404969 reg=0.002590 prune=0
2017/08/29 15:38:48 tune 3: objective=1.407494 reg=0.002589 prune=0
2017/08/29 15:38:52 tune 4: objective=1.410011 reg=0.002589 prune=0
2017/08/29 15:38:56 tune 5: objective=1.412512 reg=0.002589 prune=0
2017/08/29 15:39:00 tune 6: objective=1.414905 reg=0.002589 prune=0
2017/08/29 15:39:04 tune 7: objective=1.417051 reg=0.002589 prune=0
2017/08/29 15:39:07 step 0: objective=1.419009 reg=0.002588
2017/08/29 15:39:10 step 1: objective=1.420875 reg=0.002588
2017/08/29 15:39:12 step 2: objective=1.423458 reg=0.002588
2017/08/29 15:39:15 step 3: objective=1.425248 reg=0.002588
2017/08/29 15:39:18 step 4: objective=1.427528 reg=0.002588
2017/08/29 15:39:20 step 5: objective=1.428700 reg=0.002588
2017/08/29 15:39:23 step 6: objective=1.430126 reg=0.002588
2017/08/29 15:39:26 step 7: objective=1.431942 reg=0.002588
2017/08/29 15:39:26 Training value function...
2017/08/29 15:39:29 step 0: mse=137.336417 step=0.100000
2017/08/29 15:39:30 step 1: mse=134.765584 step=0.100000
2017/08/29 15:39:32 step 2: mse=132.574930 step=0.100000
2017/08/29 15:39:33 step 3: mse=130.607284 step=0.100000
2017/08/29 15:39:35 step 4: mse=128.810743 step=0.100000
2017/08/29 15:39:36 step 5: mse=127.276114 step=0.100000
2017/08/29 15:39:38 step 6: mse=125.837168 step=0.100000
2017/08/29 15:39:39 step 7: mse=124.443264 step=0.100000
2017/08/29 15:39:39 Saving...
2017/08/29 15:39:39 Gathering batch of experience...
2017/08/29 15:40:26 batch 147: mean=234.464286 stddev=210.566325 entropy=0.259092 frames=6301 count=28
2017/08/29 15:40:26 Training policy...
2017/08/29 15:40:32 tune 0: objective=0.356585 reg=0.002591 prune=0
2017/08/29 15:40:36 tune 1: objective=0.360581 reg=0.002590 prune=0
2017/08/29 15:40:40 tune 2: objective=0.364525 reg=0.002590 prune=0
2017/08/29 15:40:43 tune 3: objective=0.368418 reg=0.002589 prune=0
2017/08/29 15:40:47 tune 4: objective=0.372118 reg=0.002589 prune=0
2017/08/29 15:40:50 tune 5: objective=0.375547 reg=0.002588 prune=0
2017/08/29 15:40:54 tune 6: objective=0.378759 reg=0.002588 prune=0
2017/08/29 15:40:58 tune 7: objective=0.381652 reg=0.002588 prune=0
2017/08/29 15:41:00 step 0: objective=0.384064 reg=0.002587
2017/08/29 15:41:02 step 1: objective=0.385559 reg=0.002587
2017/08/29 15:41:05 step 2: objective=0.387492 reg=0.002586
2017/08/29 15:41:07 step 3: objective=0.390349 reg=0.002587
2017/08/29 15:41:09 step 4: objective=0.392909 reg=0.002588
2017/08/29 15:41:12 step 5: objective=0.395286 reg=0.002588
2017/08/29 15:41:14 step 6: objective=0.398010 reg=0.002588
2017/08/29 15:41:17 step 7: objective=0.399651 reg=0.002588
2017/08/29 15:41:17 Training value function...
2017/08/29 15:41:19 step 0: mse=158.363120 step=0.100000
2017/08/29 15:41:20 step 1: mse=156.919944 step=0.100000
2017/08/29 15:41:22 step 2: mse=155.567382 step=0.100000
2017/08/29 15:41:23 step 3: mse=154.012118 step=0.100000
2017/08/29 15:41:24 step 4: mse=152.974434 step=0.100000
2017/08/29 15:41:26 step 5: mse=152.004886 step=0.100000
2017/08/29 15:41:27 step 6: mse=151.264086 step=0.100000
2017/08/29 15:41:28 step 7: mse=150.633002 step=0.100000
2017/08/29 15:41:28 Saving...
2017/08/29 15:41:28 Gathering batch of experience...
2017/08/29 15:42:15 batch 148: mean=442.937500 stddev=191.991363 entropy=0.266051 frames=6940 count=16
2017/08/29 15:42:15 Training policy...
2017/08/29 15:42:22 tune 0: objective=1.092221 reg=0.002661 prune=0
2017/08/29 15:42:25 tune 1: objective=1.094422 reg=0.002661 prune=0
2017/08/29 15:42:29 tune 2: objective=1.096618 reg=0.002661 prune=0
2017/08/29 15:42:33 tune 3: objective=1.098807 reg=0.002662 prune=0
2017/08/29 15:42:37 tune 4: objective=1.100992 reg=0.002662 prune=0
2017/08/29 15:42:41 tune 5: objective=1.103172 reg=0.002662 prune=0
2017/08/29 15:42:45 tune 6: objective=1.105345 reg=0.002663 prune=0
2017/08/29 15:42:49 tune 7: objective=1.107435 reg=0.002663 prune=0
2017/08/29 15:42:52 step 0: objective=1.109375 reg=0.002663
2017/08/29 15:42:55 step 1: objective=1.110743 reg=0.002664
2017/08/29 15:42:57 step 2: objective=1.112851 reg=0.002664
2017/08/29 15:43:00 step 3: objective=1.114336 reg=0.002664
2017/08/29 15:43:02 step 4: objective=1.116390 reg=0.002665
2017/08/29 15:43:05 step 5: objective=1.117540 reg=0.002665
2017/08/29 15:43:08 step 6: objective=1.118623 reg=0.002666
2017/08/29 15:43:10 step 7: objective=1.120019 reg=0.002665
2017/08/29 15:43:10 Training value function...
2017/08/29 15:43:13 step 0: mse=117.955779 step=0.100000
2017/08/29 15:43:15 step 1: mse=116.631662 step=0.100000
2017/08/29 15:43:16 step 2: mse=115.333959 step=0.100000
2017/08/29 15:43:18 step 3: mse=113.933674 step=0.100000
2017/08/29 15:43:19 step 4: mse=112.747778 step=0.100000
2017/08/29 15:43:20 step 5: mse=111.683155 step=0.100000
2017/08/29 15:43:22 step 6: mse=110.812228 step=0.100000
2017/08/29 15:43:23 step 7: mse=110.180262 step=0.100000
2017/08/29 15:43:23 Saving...
2017/08/29 15:43:24 Gathering batch of experience...
2017/08/29 15:44:12 batch 149: mean=331.708333 stddev=247.099420 entropy=0.258179 frames=7092 count=24
2017/08/29 15:44:12 Training policy...
2017/08/29 15:44:19 tune 0: objective=2.044938 reg=0.002582 prune=0
2017/08/29 15:44:23 tune 1: objective=2.047992 reg=0.002582 prune=0
2017/08/29 15:44:28 tune 2: objective=2.051038 reg=0.002582 prune=0
2017/08/29 15:44:32 tune 3: objective=2.054060 reg=0.002581 prune=0
2017/08/29 15:44:36 tune 4: objective=2.057027 reg=0.002581 prune=0
2017/08/29 15:44:40 tune 5: objective=2.059894 reg=0.002581 prune=0
2017/08/29 15:44:44 tune 6: objective=2.062674 reg=0.002581 prune=0
2017/08/29 15:44:48 tune 7: objective=2.065206 reg=0.002581 prune=0
2017/08/29 15:44:50 step 0: objective=2.067564 reg=0.002581
2017/08/29 15:44:53 step 1: objective=2.069712 reg=0.002582
2017/08/29 15:44:56 step 2: objective=2.072146 reg=0.002581
2017/08/29 15:44:58 step 3: objective=2.075083 reg=0.002581
2017/08/29 15:45:01 step 4: objective=2.077573 reg=0.002581
2017/08/29 15:45:04 step 5: objective=2.078764 reg=0.002580
2017/08/29 15:45:06 step 6: objective=2.079785 reg=0.002580
2017/08/29 15:45:09 step 7: objective=2.081043 reg=0.002579
2017/08/29 15:45:09 Training value function...
2017/08/29 15:45:12 step 0: mse=175.189933 step=0.100000
2017/08/29 15:45:13 step 1: mse=170.873187 step=0.100000
2017/08/29 15:45:15 step 2: mse=167.333969 step=0.100000
2017/08/29 15:45:16 step 3: mse=164.186915 step=0.100000
2017/08/29 15:45:18 step 4: mse=161.442155 step=0.100000
2017/08/29 15:45:19 step 5: mse=159.007010 step=0.100000
2017/08/29 15:45:21 step 6: mse=156.715382 step=0.100000
2017/08/29 15:45:22 step 7: mse=154.824156 step=0.100000
2017/08/29 15:45:22 Saving...
2017/08/29 15:45:23 Gathering batch of experience...
2017/08/29 15:46:12 batch 150: mean=369.000000 stddev=194.131276 entropy=0.260596 frames=7207 count=21
2017/08/29 15:46:12 Training policy...
2017/08/29 15:46:19 tune 0: objective=0.991148 reg=0.002606 prune=0
2017/08/29 15:46:24 tune 1: objective=0.994056 reg=0.002605 prune=0
2017/08/29 15:46:28 tune 2: objective=0.996941 reg=0.002604 prune=0
2017/08/29 15:46:32 tune 3: objective=0.999799 reg=0.002603 prune=0
2017/08/29 15:46:36 tune 4: objective=1.002637 reg=0.002602 prune=0
2017/08/29 15:46:40 tune 5: objective=1.005292 reg=0.002602 prune=0
2017/08/29 15:46:44 tune 6: objective=1.007559 reg=0.002601 prune=0
2017/08/29 15:46:48 tune 7: objective=1.009746 reg=0.002600 prune=0
2017/08/29 15:46:51 step 0: objective=1.011776 reg=0.002599
2017/08/29 15:46:54 step 1: objective=1.013781 reg=0.002597
2017/08/29 15:46:57 step 2: objective=1.015853 reg=0.002596
2017/08/29 15:46:59 step 3: objective=1.017922 reg=0.002595
2017/08/29 15:47:02 step 4: objective=1.019432 reg=0.002594
2017/08/29 15:47:05 step 5: objective=1.021082 reg=0.002594
2017/08/29 15:47:07 step 6: objective=1.022913 reg=0.002593
2017/08/29 15:47:10 step 7: objective=1.024355 reg=0.002592
2017/08/29 15:47:10 Training value function...
2017/08/29 15:47:13 step 0: mse=140.303922 step=0.100000
2017/08/29 15:47:15 step 1: mse=137.316283 step=0.100000
2017/08/29 15:47:16 step 2: mse=134.962700 step=0.100000
2017/08/29 15:47:18 step 3: mse=132.863934 step=0.100000
2017/08/29 15:47:19 step 4: mse=131.440570 step=0.100000
2017/08/29 15:47:21 step 5: mse=129.894361 step=0.100000
2017/08/29 15:47:22 step 6: mse=128.504253 step=0.100000
2017/08/29 15:47:24 step 7: mse=127.427135 step=0.100000
2017/08/29 15:47:24 Saving...
2017/08/29 15:47:24 Gathering batch of experience...
2017/08/29 15:48:09 batch 151: mean=392.578947 stddev=190.964399 entropy=0.262310 frames=6955 count=19
2017/08/29 15:48:09 Training policy...
2017/08/29 15:48:16 tune 0: objective=1.087772 reg=0.002623 prune=0
2017/08/29 15:48:20 tune 1: objective=1.090138 reg=0.002623 prune=0
2017/08/29 15:48:24 tune 2: objective=1.092481 reg=0.002622 prune=0
2017/08/29 15:48:28 tune 3: objective=1.094811 reg=0.002622 prune=0
2017/08/29 15:48:32 tune 4: objective=1.097122 reg=0.002621 prune=0
2017/08/29 15:48:36 tune 5: objective=1.099413 reg=0.002621 prune=0
2017/08/29 15:48:40 tune 6: objective=1.101556 reg=0.002621 prune=0
2017/08/29 15:48:44 tune 7: objective=1.103639 reg=0.002620 prune=0
2017/08/29 15:48:46 step 0: objective=1.105622 reg=0.002620
2017/08/29 15:48:49 step 1: objective=1.107989 reg=0.002620
2017/08/29 15:48:51 step 2: objective=1.110496 reg=0.002620
2017/08/29 15:48:54 step 3: objective=1.111739 reg=0.002620
2017/08/29 15:48:57 step 4: objective=1.113268 reg=0.002620
2017/08/29 15:48:59 step 5: objective=1.114392 reg=0.002620
2017/08/29 15:49:02 step 6: objective=1.116788 reg=0.002620
2017/08/29 15:49:05 step 7: objective=1.117681 reg=0.002620
2017/08/29 15:49:05 Training value function...
2017/08/29 15:49:07 step 0: mse=143.398881 step=0.100000
2017/08/29 15:49:09 step 1: mse=140.859845 step=0.100000
2017/08/29 15:49:10 step 2: mse=138.486089 step=0.100000
2017/08/29 15:49:12 step 3: mse=136.583164 step=0.100000
2017/08/29 15:49:13 step 4: mse=134.984616 step=0.100000
2017/08/29 15:49:15 step 5: mse=133.343830 step=0.100000
2017/08/29 15:49:16 step 6: mse=131.935013 step=0.100000
2017/08/29 15:49:18 step 7: mse=130.985461 step=0.100000
2017/08/29 15:49:18 Saving...
2017/08/29 15:49:18 Gathering batch of experience...
2017/08/29 15:50:06 batch 152: mean=358.428571 stddev=228.755343 entropy=0.257447 frames=6890 count=21
2017/08/29 15:50:06 Training policy...
2017/08/29 15:50:13 tune 0: objective=1.206586 reg=0.002574 prune=0
2017/08/29 15:50:17 tune 1: objective=1.209257 reg=0.002575 prune=0
2017/08/29 15:50:21 tune 2: objective=1.211912 reg=0.002575 prune=0
2017/08/29 15:50:25 tune 3: objective=1.214548 reg=0.002575 prune=0
2017/08/29 15:50:29 tune 4: objective=1.217068 reg=0.002575 prune=0
2017/08/29 15:50:33 tune 5: objective=1.219524 reg=0.002576 prune=0
2017/08/29 15:50:37 tune 6: objective=1.221943 reg=0.002576 prune=0
2017/08/29 15:50:41 tune 7: objective=1.224248 reg=0.002576 prune=0
2017/08/29 15:50:44 step 0: objective=1.226373 reg=0.002576
2017/08/29 15:50:46 step 1: objective=1.228907 reg=0.002577
2017/08/29 15:50:49 step 2: objective=1.230720 reg=0.002577
2017/08/29 15:50:51 step 3: objective=1.234036 reg=0.002576
2017/08/29 15:50:54 step 4: objective=1.235278 reg=0.002576
2017/08/29 15:50:57 step 5: objective=1.236473 reg=0.002576
2017/08/29 15:50:59 step 6: objective=1.237437 reg=0.002576
2017/08/29 15:51:02 step 7: objective=1.239001 reg=0.002576
2017/08/29 15:51:02 Training value function...
2017/08/29 15:51:05 step 0: mse=125.634204 step=0.100000
2017/08/29 15:51:06 step 1: mse=123.379612 step=0.100000
2017/08/29 15:51:08 step 2: mse=121.495516 step=0.100000
2017/08/29 15:51:09 step 3: mse=119.791821 step=0.100000
2017/08/29 15:51:10 step 4: mse=118.504550 step=0.100000
2017/08/29 15:51:12 step 5: mse=117.322400 step=0.100000
2017/08/29 15:51:13 step 6: mse=116.277378 step=0.100000
2017/08/29 15:51:15 step 7: mse=115.518836 step=0.100000
2017/08/29 15:51:15 Saving...
2017/08/29 15:51:15 Gathering batch of experience...
2017/08/29 15:52:01 batch 153: mean=395.777778 stddev=223.468505 entropy=0.257840 frames=6538 count=18
2017/08/29 15:52:01 Training policy...
2017/08/29 15:52:08 tune 0: objective=1.298930 reg=0.002578 prune=0
2017/08/29 15:52:12 tune 1: objective=1.301341 reg=0.002578 prune=0
2017/08/29 15:52:15 tune 2: objective=1.303720 reg=0.002578 prune=0
2017/08/29 15:52:19 tune 3: objective=1.306084 reg=0.002578 prune=0
2017/08/29 15:52:23 tune 4: objective=1.308423 reg=0.002578 prune=0
2017/08/29 15:52:27 tune 5: objective=1.310710 reg=0.002578 prune=0
2017/08/29 15:52:30 tune 6: objective=1.312744 reg=0.002578 prune=0
2017/08/29 15:52:34 tune 7: objective=1.314552 reg=0.002578 prune=0
2017/08/29 15:52:37 step 0: objective=1.316263 reg=0.002578
2017/08/29 15:52:39 step 1: objective=1.317696 reg=0.002578
2017/08/29 15:52:42 step 2: objective=1.319436 reg=0.002578
2017/08/29 15:52:44 step 3: objective=1.320584 reg=0.002578
2017/08/29 15:52:46 step 4: objective=1.321586 reg=0.002578
2017/08/29 15:52:49 step 5: objective=1.322506 reg=0.002578
2017/08/29 15:52:51 step 6: objective=1.323919 reg=0.002578
2017/08/29 15:52:54 step 7: objective=1.325320 reg=0.002577
2017/08/29 15:52:54 Training value function...
2017/08/29 15:52:57 step 0: mse=135.477166 step=0.100000
2017/08/29 15:52:58 step 1: mse=133.810770 step=0.100000
2017/08/29 15:52:59 step 2: mse=132.452639 step=0.100000
2017/08/29 15:53:01 step 3: mse=130.946401 step=0.100000
2017/08/29 15:53:02 step 4: mse=129.785681 step=0.100000
2017/08/29 15:53:03 step 5: mse=128.747653 step=0.100000
2017/08/29 15:53:05 step 6: mse=127.851045 step=0.100000
2017/08/29 15:53:06 step 7: mse=127.097589 step=0.100000
2017/08/29 15:53:06 Saving...
2017/08/29 15:53:06 Gathering batch of experience...
2017/08/29 15:53:57 batch 154: mean=446.421053 stddev=190.897690 entropy=0.257452 frames=7861 count=19
2017/08/29 15:53:57 Training policy...
2017/08/29 15:54:05 tune 0: objective=1.158808 reg=0.002575 prune=0
2017/08/29 15:54:09 tune 1: objective=1.161198 reg=0.002574 prune=0
2017/08/29 15:54:14 tune 2: objective=1.163564 reg=0.002574 prune=0
2017/08/29 15:54:18 tune 3: objective=1.165912 reg=0.002574 prune=0
2017/08/29 15:54:23 tune 4: objective=1.168224 reg=0.002573 prune=0
2017/08/29 15:54:27 tune 5: objective=1.170383 reg=0.002573 prune=0
2017/08/29 15:54:32 tune 6: objective=1.172349 reg=0.002573 prune=0
2017/08/29 15:54:36 tune 7: objective=1.174184 reg=0.002573 prune=0
2017/08/29 15:54:39 step 0: objective=1.175910 reg=0.002573
2017/08/29 15:54:42 step 1: objective=1.178533 reg=0.002573
2017/08/29 15:54:45 step 2: objective=1.180222 reg=0.002572
2017/08/29 15:54:48 step 3: objective=1.182253 reg=0.002572
2017/08/29 15:54:51 step 4: objective=1.183739 reg=0.002572
2017/08/29 15:54:54 step 5: objective=1.185336 reg=0.002572
2017/08/29 15:54:57 step 6: objective=1.186756 reg=0.002573
2017/08/29 15:55:00 step 7: objective=1.187781 reg=0.002573
2017/08/29 15:55:00 Training value function...
2017/08/29 15:55:03 step 0: mse=130.304708 step=0.100000
2017/08/29 15:55:05 step 1: mse=128.715638 step=0.100000
2017/08/29 15:55:07 step 2: mse=127.681688 step=0.100000
2017/08/29 15:55:08 step 3: mse=126.664665 step=0.100000
2017/08/29 15:55:10 step 4: mse=125.846879 step=0.100000
2017/08/29 15:55:12 step 5: mse=124.894977 step=0.100000
2017/08/29 15:55:13 step 6: mse=124.087375 step=0.100000
2017/08/29 15:55:15 step 7: mse=123.430342 step=0.100000
2017/08/29 15:55:15 Saving...
2017/08/29 15:55:15 Gathering batch of experience...
2017/08/29 15:56:06 batch 155: mean=361.608696 stddev=217.008062 entropy=0.258152 frames=7907 count=23
2017/08/29 15:56:06 Training policy...
2017/08/29 15:56:14 tune 0: objective=0.589810 reg=0.002582 prune=0
2017/08/29 15:56:19 tune 1: objective=0.592006 reg=0.002582 prune=0
2017/08/29 15:56:23 tune 2: objective=0.594186 reg=0.002582 prune=0
2017/08/29 15:56:28 tune 3: objective=0.596349 reg=0.002582 prune=0
2017/08/29 15:56:32 tune 4: objective=0.598494 reg=0.002582 prune=0
2017/08/29 15:56:37 tune 5: objective=0.600624 reg=0.002582 prune=0
2017/08/29 15:56:42 tune 6: objective=0.602741 reg=0.002582 prune=0
2017/08/29 15:56:46 tune 7: objective=0.604619 reg=0.002582 prune=0
2017/08/29 15:56:49 step 0: objective=0.606302 reg=0.002582
2017/08/29 15:56:52 step 1: objective=0.609983 reg=0.002581
2017/08/29 15:56:55 step 2: objective=0.611180 reg=0.002581
2017/08/29 15:56:58 step 3: objective=0.612709 reg=0.002581
2017/08/29 15:57:01 step 4: objective=0.614486 reg=0.002581
2017/08/29 15:57:04 step 5: objective=0.615503 reg=0.002581
2017/08/29 15:57:07 step 6: objective=0.616678 reg=0.002582
2017/08/29 15:57:10 step 7: objective=0.618325 reg=0.002581
2017/08/29 15:57:10 Training value function...
2017/08/29 15:57:13 step 0: mse=145.604755 step=0.100000
2017/08/29 15:57:15 step 1: mse=143.721842 step=0.100000
2017/08/29 15:57:17 step 2: mse=142.434042 step=0.100000
2017/08/29 15:57:18 step 3: mse=141.378282 step=0.100000
2017/08/29 15:57:20 step 4: mse=140.364679 step=0.100000
2017/08/29 15:57:22 step 5: mse=139.479690 step=0.100000
2017/08/29 15:57:23 step 6: mse=138.751560 step=0.100000
2017/08/29 15:57:25 step 7: mse=137.787241 step=0.100000
2017/08/29 15:57:25 Saving...
2017/08/29 15:57:25 Gathering batch of experience...
2017/08/29 15:58:15 batch 156: mean=302.791667 stddev=217.398823 entropy=0.257630 frames=6777 count=24
2017/08/29 15:58:15 Training policy...
2017/08/29 15:58:21 tune 0: objective=0.838001 reg=0.002576 prune=0
2017/08/29 15:58:25 tune 1: objective=0.840869 reg=0.002576 prune=0
2017/08/29 15:58:29 tune 2: objective=0.843697 reg=0.002575 prune=0
2017/08/29 15:58:33 tune 3: objective=0.846485 reg=0.002575 prune=0
2017/08/29 15:58:37 tune 4: objective=0.849238 reg=0.002574 prune=0
2017/08/29 15:58:41 tune 5: objective=0.851756 reg=0.002574 prune=0
2017/08/29 15:58:45 tune 6: objective=0.853926 reg=0.002573 prune=0
2017/08/29 15:58:49 tune 7: objective=0.855965 reg=0.002573 prune=0
2017/08/29 15:58:51 step 0: objective=0.857831 reg=0.002572
2017/08/29 15:58:54 step 1: objective=0.859796 reg=0.002572
2017/08/29 15:58:56 step 2: objective=0.861496 reg=0.002573
2017/08/29 15:58:59 step 3: objective=0.862941 reg=0.002573
2017/08/29 15:59:01 step 4: objective=0.864448 reg=0.002572
2017/08/29 15:59:04 step 5: objective=0.866232 reg=0.002572
2017/08/29 15:59:07 step 6: objective=0.867878 reg=0.002572
2017/08/29 15:59:09 step 7: objective=0.869700 reg=0.002572
2017/08/29 15:59:09 Training value function...
2017/08/29 15:59:12 step 0: mse=136.818469 step=0.100000
2017/08/29 15:59:13 step 1: mse=134.613189 step=0.100000
2017/08/29 15:59:15 step 2: mse=132.232839 step=0.100000
2017/08/29 15:59:16 step 3: mse=130.927044 step=0.100000
2017/08/29 15:59:17 step 4: mse=129.099667 step=0.100000
2017/08/29 15:59:19 step 5: mse=127.549242 step=0.100000
2017/08/29 15:59:20 step 6: mse=126.202141 step=0.100000
2017/08/29 15:59:22 step 7: mse=125.399344 step=0.100000
2017/08/29 15:59:22 Saving...
2017/08/29 15:59:22 Gathering batch of experience...
2017/08/29 16:00:14 batch 157: mean=444.350000 stddev=226.380493 entropy=0.260550 frames=7844 count=20
2017/08/29 16:00:14 Training policy...
2017/08/29 16:00:22 tune 0: objective=2.013561 reg=0.002605 prune=0
2017/08/29 16:00:26 tune 1: objective=2.015801 reg=0.002606 prune=0
2017/08/29 16:00:31 tune 2: objective=2.018037 reg=0.002606 prune=0
2017/08/29 16:00:35 tune 3: objective=2.020266 reg=0.002606 prune=0
2017/08/29 16:00:40 tune 4: objective=2.022494 reg=0.002606 prune=0
2017/08/29 16:00:44 tune 5: objective=2.024719 reg=0.002606 prune=0
2017/08/29 16:00:49 tune 6: objective=2.026939 reg=0.002606 prune=0
2017/08/29 16:00:53 tune 7: objective=2.029151 reg=0.002606 prune=0
2017/08/29 16:00:56 step 0: objective=2.031315 reg=0.002606
2017/08/29 16:00:59 step 1: objective=2.033976 reg=0.002606
2017/08/29 16:01:02 step 2: objective=2.035933 reg=0.002607
2017/08/29 16:01:05 step 3: objective=2.038566 reg=0.002607
2017/08/29 16:01:08 step 4: objective=2.039848 reg=0.002607
2017/08/29 16:01:11 step 5: objective=2.041372 reg=0.002607
2017/08/29 16:01:14 step 6: objective=2.043634 reg=0.002607
2017/08/29 16:01:17 step 7: objective=2.045598 reg=0.002607
2017/08/29 16:01:17 Training value function...
2017/08/29 16:01:20 step 0: mse=150.274645 step=0.100000
2017/08/29 16:01:22 step 1: mse=146.818293 step=0.100000
2017/08/29 16:01:24 step 2: mse=143.643152 step=0.100000
2017/08/29 16:01:25 step 3: mse=140.777028 step=0.100000
2017/08/29 16:01:27 step 4: mse=138.309571 step=0.100000
2017/08/29 16:01:29 step 5: mse=136.367368 step=0.100000
2017/08/29 16:01:30 step 6: mse=134.475170 step=0.100000
2017/08/29 16:01:32 step 7: mse=132.761200 step=0.100000
2017/08/29 16:01:32 Saving...
2017/08/29 16:01:32 Gathering batch of experience...
2017/08/29 16:02:24 batch 158: mean=403.095238 stddev=223.257252 entropy=0.259356 frames=7741 count=21
2017/08/29 16:02:24 Training policy...
2017/08/29 16:02:32 tune 0: objective=0.937263 reg=0.002594 prune=0
2017/08/29 16:02:36 tune 1: objective=0.939465 reg=0.002594 prune=0
2017/08/29 16:02:41 tune 2: objective=0.941655 reg=0.002594 prune=0
2017/08/29 16:02:45 tune 3: objective=0.943833 reg=0.002594 prune=0
2017/08/29 16:02:50 tune 4: objective=0.946002 reg=0.002594 prune=0
2017/08/29 16:02:54 tune 5: objective=0.948159 reg=0.002594 prune=0
2017/08/29 16:02:59 tune 6: objective=0.950277 reg=0.002594 prune=0
2017/08/29 16:03:03 tune 7: objective=0.952271 reg=0.002594 prune=0
2017/08/29 16:03:06 step 0: objective=0.954147 reg=0.002594
2017/08/29 16:03:09 step 1: objective=0.956888 reg=0.002594
2017/08/29 16:03:12 step 2: objective=0.959817 reg=0.002594
2017/08/29 16:03:15 step 3: objective=0.963021 reg=0.002594
2017/08/29 16:03:18 step 4: objective=0.964710 reg=0.002593
2017/08/29 16:03:21 step 5: objective=0.965795 reg=0.002593
2017/08/29 16:03:24 step 6: objective=0.966705 reg=0.002593
2017/08/29 16:03:27 step 7: objective=0.967674 reg=0.002594
2017/08/29 16:03:27 Training value function...
2017/08/29 16:03:30 step 0: mse=134.985247 step=0.100000
2017/08/29 16:03:32 step 1: mse=133.527874 step=0.100000
2017/08/29 16:03:33 step 2: mse=132.287990 step=0.100000
2017/08/29 16:03:35 step 3: mse=131.286062 step=0.100000
2017/08/29 16:03:37 step 4: mse=130.163220 step=0.100000
2017/08/29 16:03:38 step 5: mse=129.400894 step=0.100000
2017/08/29 16:03:40 step 6: mse=128.657897 step=0.100000
2017/08/29 16:03:41 step 7: mse=127.653671 step=0.100000
2017/08/29 16:03:41 Saving...
2017/08/29 16:03:42 Gathering batch of experience...
2017/08/29 16:04:29 batch 159: mean=426.352941 stddev=178.542775 entropy=0.257854 frames=6582 count=17
2017/08/29 16:04:29 Training policy...
2017/08/29 16:04:36 tune 0: objective=1.037876 reg=0.002579 prune=0
2017/08/29 16:04:39 tune 1: objective=1.040632 reg=0.002578 prune=0
2017/08/29 16:04:43 tune 2: objective=1.043369 reg=0.002577 prune=0
2017/08/29 16:04:47 tune 3: objective=1.046093 reg=0.002577 prune=0
2017/08/29 16:04:51 tune 4: objective=1.048798 reg=0.002576 prune=0
2017/08/29 16:04:55 tune 5: objective=1.051390 reg=0.002575 prune=0
2017/08/29 16:04:59 tune 6: objective=1.053876 reg=0.002575 prune=0
2017/08/29 16:05:02 tune 7: objective=1.056196 reg=0.002574 prune=0
2017/08/29 16:05:05 step 0: objective=1.058372 reg=0.002574
2017/08/29 16:05:07 step 1: objective=1.060089 reg=0.002574
2017/08/29 16:05:10 step 2: objective=1.061520 reg=0.002573
2017/08/29 16:05:12 step 3: objective=1.062972 reg=0.002573
2017/08/29 16:05:15 step 4: objective=1.065924 reg=0.002573
2017/08/29 16:05:17 step 5: objective=1.068416 reg=0.002573
2017/08/29 16:05:20 step 6: objective=1.070647 reg=0.002572
2017/08/29 16:05:22 step 7: objective=1.072197 reg=0.002571
2017/08/29 16:05:22 Training value function...
2017/08/29 16:05:25 step 0: mse=137.691763 step=0.100000
2017/08/29 16:05:26 step 1: mse=134.818256 step=0.100000
2017/08/29 16:05:28 step 2: mse=132.577171 step=0.100000
2017/08/29 16:05:29 step 3: mse=130.586525 step=0.100000
2017/08/29 16:05:30 step 4: mse=128.992994 step=0.100000
2017/08/29 16:05:32 step 5: mse=127.459834 step=0.100000
2017/08/29 16:05:33 step 6: mse=126.316201 step=0.100000
2017/08/29 16:05:35 step 7: mse=125.179622 step=0.100000
2017/08/29 16:05:35 Saving...
2017/08/29 16:05:35 Gathering batch of experience...
2017/08/29 16:06:25 batch 160: mean=371.318182 stddev=222.462333 entropy=0.258297 frames=7697 count=22
2017/08/29 16:06:25 Training policy...
2017/08/29 16:06:33 tune 0: objective=0.502130 reg=0.002583 prune=0
2017/08/29 16:06:37 tune 1: objective=0.504157 reg=0.002583 prune=0
2017/08/29 16:06:42 tune 2: objective=0.506171 reg=0.002583 prune=0
2017/08/29 16:06:46 tune 3: objective=0.508175 reg=0.002583 prune=0
2017/08/29 16:06:50 tune 4: objective=0.510168 reg=0.002583 prune=0
2017/08/29 16:06:55 tune 5: objective=0.512149 reg=0.002582 prune=0
2017/08/29 16:06:59 tune 6: objective=0.514102 reg=0.002582 prune=0
2017/08/29 16:07:04 tune 7: objective=0.515932 reg=0.002582 prune=0
2017/08/29 16:07:07 step 0: objective=0.517632 reg=0.002582
2017/08/29 16:07:10 step 1: objective=0.520082 reg=0.002581
2017/08/29 16:07:13 step 2: objective=0.521494 reg=0.002582
2017/08/29 16:07:16 step 3: objective=0.523667 reg=0.002582
2017/08/29 16:07:18 step 4: objective=0.525846 reg=0.002582
2017/08/29 16:07:21 step 5: objective=0.528139 reg=0.002581
2017/08/29 16:07:24 step 6: objective=0.529970 reg=0.002581
2017/08/29 16:07:27 step 7: objective=0.531697 reg=0.002581
2017/08/29 16:07:27 Training value function...
2017/08/29 16:07:30 step 0: mse=120.255639 step=0.100000
2017/08/29 16:07:32 step 1: mse=119.333401 step=0.100000
2017/08/29 16:07:34 step 2: mse=118.381695 step=0.100000
2017/08/29 16:07:35 step 3: mse=117.758594 step=0.100000
2017/08/29 16:07:37 step 4: mse=117.207681 step=0.100000
2017/08/29 16:07:39 step 5: mse=116.484867 step=0.100000
2017/08/29 16:07:40 step 6: mse=116.124323 step=0.100000
2017/08/29 16:07:42 step 7: mse=115.521322 step=0.100000
2017/08/29 16:07:42 Saving...
2017/08/29 16:07:42 Gathering batch of experience...
2017/08/29 16:08:30 batch 161: mean=380.736842 stddev=225.424708 entropy=0.261356 frames=6859 count=19
2017/08/29 16:08:30 Training policy...
2017/08/29 16:08:36 tune 0: objective=0.934454 reg=0.002614 prune=0
2017/08/29 16:08:40 tune 1: objective=0.937228 reg=0.002613 prune=0
2017/08/29 16:08:44 tune 2: objective=0.939982 reg=0.002613 prune=0
2017/08/29 16:08:48 tune 3: objective=0.942714 reg=0.002613 prune=0
2017/08/29 16:08:52 tune 4: objective=0.945427 reg=0.002613 prune=0
2017/08/29 16:08:56 tune 5: objective=0.948044 reg=0.002613 prune=0
2017/08/29 16:09:00 tune 6: objective=0.950441 reg=0.002613 prune=0
2017/08/29 16:09:04 tune 7: objective=0.952771 reg=0.002613 prune=0
2017/08/29 16:09:07 step 0: objective=0.955006 reg=0.002613
2017/08/29 16:09:09 step 1: objective=0.957001 reg=0.002613
2017/08/29 16:09:12 step 2: objective=0.959321 reg=0.002613
2017/08/29 16:09:15 step 3: objective=0.961103 reg=0.002614
2017/08/29 16:09:17 step 4: objective=0.962252 reg=0.002613
2017/08/29 16:09:20 step 5: objective=0.963311 reg=0.002613
2017/08/29 16:09:22 step 6: objective=0.964322 reg=0.002613
2017/08/29 16:09:25 step 7: objective=0.965492 reg=0.002613
2017/08/29 16:09:25 Training value function...
2017/08/29 16:09:28 step 0: mse=136.937685 step=0.100000
2017/08/29 16:09:29 step 1: mse=134.364740 step=0.100000
2017/08/29 16:09:31 step 2: mse=131.902892 step=0.100000
2017/08/29 16:09:32 step 3: mse=129.949148 step=0.100000
2017/08/29 16:09:33 step 4: mse=128.207467 step=0.100000
2017/08/29 16:09:35 step 5: mse=126.919357 step=0.100000
2017/08/29 16:09:36 step 6: mse=125.878104 step=0.100000
2017/08/29 16:09:38 step 7: mse=124.853133 step=0.100000
2017/08/29 16:09:38 Saving...
2017/08/29 16:09:38 Gathering batch of experience...
2017/08/29 16:10:26 batch 162: mean=341.000000 stddev=204.482051 entropy=0.254076 frames=6999 count=22
2017/08/29 16:10:26 Training policy...
2017/08/29 16:10:33 tune 0: objective=0.976985 reg=0.002541 prune=0
2017/08/29 16:10:37 tune 1: objective=0.980214 reg=0.002540 prune=0
2017/08/29 16:10:41 tune 2: objective=0.983392 reg=0.002540 prune=0
2017/08/29 16:10:45 tune 3: objective=0.986528 reg=0.002539 prune=0
2017/08/29 16:10:49 tune 4: objective=0.989617 reg=0.002539 prune=0
2017/08/29 16:10:53 tune 5: objective=0.992545 reg=0.002539 prune=0
2017/08/29 16:10:57 tune 6: objective=0.994999 reg=0.002538 prune=0
2017/08/29 16:11:01 tune 7: objective=0.997144 reg=0.002538 prune=0
2017/08/29 16:11:04 step 0: objective=0.999177 reg=0.002538
2017/08/29 16:11:06 step 1: objective=1.000949 reg=0.002538
2017/08/29 16:11:09 step 2: objective=1.002576 reg=0.002538
2017/08/29 16:11:12 step 3: objective=1.004323 reg=0.002538
2017/08/29 16:11:14 step 4: objective=1.005516 reg=0.002538
2017/08/29 16:11:17 step 5: objective=1.007633 reg=0.002538
2017/08/29 16:11:20 step 6: objective=1.008761 reg=0.002538
2017/08/29 16:11:22 step 7: objective=1.010161 reg=0.002538
2017/08/29 16:11:22 Training value function...
2017/08/29 16:11:25 step 0: mse=151.897345 step=0.100000
2017/08/29 16:11:27 step 1: mse=150.575212 step=0.100000
2017/08/29 16:11:28 step 2: mse=149.148700 step=0.100000
2017/08/29 16:11:30 step 3: mse=148.122751 step=0.100000
2017/08/29 16:11:31 step 4: mse=147.074376 step=0.100000
2017/08/29 16:11:32 step 5: mse=146.340712 step=0.100000
2017/08/29 16:11:34 step 6: mse=145.693772 step=0.100000
2017/08/29 16:11:35 step 7: mse=144.844682 step=0.100000
2017/08/29 16:11:35 Saving...
2017/08/29 16:11:36 Gathering batch of experience...
2017/08/29 16:12:25 batch 163: mean=312.125000 stddev=239.069256 entropy=0.256928 frames=7218 count=24
2017/08/29 16:12:25 Training policy...
2017/08/29 16:12:32 tune 0: objective=0.634712 reg=0.002569 prune=0
2017/08/29 16:12:36 tune 1: objective=0.637338 reg=0.002569 prune=0
2017/08/29 16:12:41 tune 2: objective=0.639939 reg=0.002568 prune=0
2017/08/29 16:12:45 tune 3: objective=0.642516 reg=0.002568 prune=0
2017/08/29 16:12:49 tune 4: objective=0.645072 reg=0.002567 prune=0
2017/08/29 16:12:53 tune 5: objective=0.647538 reg=0.002566 prune=0
2017/08/29 16:12:57 tune 6: objective=0.649703 reg=0.002566 prune=0
2017/08/29 16:13:02 tune 7: objective=0.651642 reg=0.002565 prune=0
2017/08/29 16:13:04 step 0: objective=0.653451 reg=0.002565
2017/08/29 16:13:07 step 1: objective=0.655350 reg=0.002564
2017/08/29 16:13:10 step 2: objective=0.656820 reg=0.002563
2017/08/29 16:13:12 step 3: objective=0.658552 reg=0.002563
2017/08/29 16:13:15 step 4: objective=0.660182 reg=0.002562
2017/08/29 16:13:18 step 5: objective=0.661407 reg=0.002561
2017/08/29 16:13:21 step 6: objective=0.662468 reg=0.002561
2017/08/29 16:13:23 step 7: objective=0.664156 reg=0.002560
2017/08/29 16:13:23 Training value function...
2017/08/29 16:13:26 step 0: mse=138.663315 step=0.100000
2017/08/29 16:13:28 step 1: mse=136.336482 step=0.100000
2017/08/29 16:13:29 step 2: mse=134.628802 step=0.100000
2017/08/29 16:13:31 step 3: mse=133.149903 step=0.100000
2017/08/29 16:13:32 step 4: mse=131.828307 step=0.100000
2017/08/29 16:13:34 step 5: mse=131.008519 step=0.100000
2017/08/29 16:13:35 step 6: mse=130.087079 step=0.100000
2017/08/29 16:13:37 step 7: mse=129.508583 step=0.100000
2017/08/29 16:13:37 Saving...
2017/08/29 16:13:37 Gathering batch of experience...
2017/08/29 16:14:30 batch 164: mean=352.272727 stddev=191.743717 entropy=0.250648 frames=7307 count=22
2017/08/29 16:14:30 Training policy...
2017/08/29 16:14:37 tune 0: objective=1.002439 reg=0.002506 prune=0
2017/08/29 16:14:42 tune 1: objective=1.004668 reg=0.002506 prune=0
2017/08/29 16:14:46 tune 2: objective=1.006874 reg=0.002506 prune=0
2017/08/29 16:14:50 tune 3: objective=1.009055 reg=0.002506 prune=0
2017/08/29 16:14:54 tune 4: objective=1.011180 reg=0.002506 prune=0
2017/08/29 16:14:59 tune 5: objective=1.013132 reg=0.002506 prune=0
2017/08/29 16:15:03 tune 6: objective=1.015012 reg=0.002506 prune=0
2017/08/29 16:15:07 tune 7: objective=1.016789 reg=0.002506 prune=0
2017/08/29 16:15:10 step 0: objective=1.018493 reg=0.002506
2017/08/29 16:15:13 step 1: objective=1.019811 reg=0.002506
2017/08/29 16:15:15 step 2: objective=1.021654 reg=0.002507
2017/08/29 16:15:18 step 3: objective=1.022873 reg=0.002508
2017/08/29 16:15:21 step 4: objective=1.024652 reg=0.002507
2017/08/29 16:15:24 step 5: objective=1.026716 reg=0.002508
2017/08/29 16:15:27 step 6: objective=1.027671 reg=0.002508
2017/08/29 16:15:29 step 7: objective=1.028660 reg=0.002508
2017/08/29 16:15:29 Training value function...
2017/08/29 16:15:32 step 0: mse=116.628703 step=0.100000
2017/08/29 16:15:34 step 1: mse=115.522377 step=0.100000
2017/08/29 16:15:35 step 2: mse=114.797207 step=0.100000
2017/08/29 16:15:37 step 3: mse=113.935198 step=0.100000
2017/08/29 16:15:38 step 4: mse=113.498024 step=0.100000
2017/08/29 16:15:40 step 5: mse=112.801585 step=0.100000
2017/08/29 16:15:41 step 6: mse=112.541435 step=0.100000
2017/08/29 16:15:43 step 7: mse=112.318276 step=0.100000
2017/08/29 16:15:43 Saving...
2017/08/29 16:15:43 Gathering batch of experience...
2017/08/29 16:16:33 batch 165: mean=351.652174 stddev=199.527836 entropy=0.258983 frames=7375 count=23
2017/08/29 16:16:33 Training policy...
2017/08/29 16:16:40 tune 0: objective=1.501903 reg=0.002590 prune=0
2017/08/29 16:16:45 tune 1: objective=1.504825 reg=0.002589 prune=0
2017/08/29 16:16:49 tune 2: objective=1.507742 reg=0.002589 prune=0
2017/08/29 16:16:53 tune 3: objective=1.510653 reg=0.002588 prune=0
2017/08/29 16:16:58 tune 4: objective=1.513551 reg=0.002588 prune=0
2017/08/29 16:17:02 tune 5: objective=1.516413 reg=0.002587 prune=0
2017/08/29 16:17:06 tune 6: objective=1.519189 reg=0.002587 prune=0
2017/08/29 16:17:10 tune 7: objective=1.521807 reg=0.002586 prune=0
2017/08/29 16:17:13 step 0: objective=1.524131 reg=0.002586
2017/08/29 16:17:16 step 1: objective=1.526336 reg=0.002586
2017/08/29 16:17:19 step 2: objective=1.528287 reg=0.002585
2017/08/29 16:17:22 step 3: objective=1.530248 reg=0.002585
2017/08/29 16:17:24 step 4: objective=1.531716 reg=0.002585
2017/08/29 16:17:27 step 5: objective=1.533012 reg=0.002585
2017/08/29 16:17:30 step 6: objective=1.534746 reg=0.002586
2017/08/29 16:17:33 step 7: objective=1.536558 reg=0.002586
2017/08/29 16:17:33 Training value function...
2017/08/29 16:17:36 step 0: mse=175.892980 step=0.100000
2017/08/29 16:17:37 step 1: mse=171.762369 step=0.100000
2017/08/29 16:17:39 step 2: mse=167.995507 step=0.100000
2017/08/29 16:17:41 step 3: mse=165.057042 step=0.100000
2017/08/29 16:17:42 step 4: mse=162.497316 step=0.100000
2017/08/29 16:17:44 step 5: mse=160.359886 step=0.100000
2017/08/29 16:17:45 step 6: mse=158.378292 step=0.100000
2017/08/29 16:17:47 step 7: mse=156.438288 step=0.100000
2017/08/29 16:17:47 Saving...
2017/08/29 16:17:47 Gathering batch of experience...
2017/08/29 16:18:36 batch 166: mean=300.521739 stddev=235.539689 entropy=0.255314 frames=6706 count=23
2017/08/29 16:18:36 Training policy...
2017/08/29 16:18:43 tune 0: objective=0.462356 reg=0.002553 prune=0
2017/08/29 16:18:47 tune 1: objective=0.465219 reg=0.002553 prune=0
2017/08/29 16:18:51 tune 2: objective=0.468054 reg=0.002552 prune=0
2017/08/29 16:18:55 tune 3: objective=0.470860 reg=0.002552 prune=0
2017/08/29 16:18:59 tune 4: objective=0.473641 reg=0.002551 prune=0
2017/08/29 16:19:02 tune 5: objective=0.476329 reg=0.002551 prune=0
2017/08/29 16:19:06 tune 6: objective=0.478825 reg=0.002551 prune=0
2017/08/29 16:19:10 tune 7: objective=0.481183 reg=0.002550 prune=0
2017/08/29 16:19:13 step 0: objective=0.483348 reg=0.002550
2017/08/29 16:19:15 step 1: objective=0.485201 reg=0.002550
2017/08/29 16:19:18 step 2: objective=0.487031 reg=0.002549
2017/08/29 16:19:21 step 3: objective=0.488938 reg=0.002550
2017/08/29 16:19:23 step 4: objective=0.490839 reg=0.002549
2017/08/29 16:19:26 step 5: objective=0.491710 reg=0.002548
2017/08/29 16:19:28 step 6: objective=0.493364 reg=0.002548
2017/08/29 16:19:31 step 7: objective=0.494130 reg=0.002548
2017/08/29 16:19:31 Training value function...
2017/08/29 16:19:33 step 0: mse=124.553150 step=0.100000
2017/08/29 16:19:35 step 1: mse=123.066183 step=0.100000
2017/08/29 16:19:36 step 2: mse=122.025404 step=0.100000
2017/08/29 16:19:38 step 3: mse=121.034332 step=0.100000
2017/08/29 16:19:39 step 4: mse=120.088697 step=0.100000
2017/08/29 16:19:41 step 5: mse=119.334589 step=0.100000
2017/08/29 16:19:42 step 6: mse=118.649137 step=0.100000
2017/08/29 16:19:43 step 7: mse=118.048535 step=0.100000
2017/08/29 16:19:43 Saving...
2017/08/29 16:19:43 Gathering batch of experience...
2017/08/29 16:20:34 batch 167: mean=315.500000 stddev=209.093878 entropy=0.259816 frames=7362 count=24
2017/08/29 16:20:34 Training policy...
2017/08/29 16:20:41 tune 0: objective=0.721916 reg=0.002598 prune=0
2017/08/29 16:20:46 tune 1: objective=0.724209 reg=0.002598 prune=0
2017/08/29 16:20:50 tune 2: objective=0.726471 reg=0.002597 prune=0
2017/08/29 16:20:54 tune 3: objective=0.728705 reg=0.002597 prune=0
2017/08/29 16:20:58 tune 4: objective=0.730861 reg=0.002597 prune=0
2017/08/29 16:21:03 tune 5: objective=0.732910 reg=0.002596 prune=0
2017/08/29 16:21:07 tune 6: objective=0.734924 reg=0.002596 prune=0
2017/08/29 16:21:11 tune 7: objective=0.736666 reg=0.002595 prune=0
2017/08/29 16:21:14 step 0: objective=0.738208 reg=0.002595
2017/08/29 16:21:17 step 1: objective=0.740966 reg=0.002595
2017/08/29 16:21:20 step 2: objective=0.742795 reg=0.002595
2017/08/29 16:21:23 step 3: objective=0.744479 reg=0.002595
2017/08/29 16:21:25 step 4: objective=0.745755 reg=0.002594
2017/08/29 16:21:28 step 5: objective=0.746935 reg=0.002594
2017/08/29 16:21:31 step 6: objective=0.748685 reg=0.002594
2017/08/29 16:21:34 step 7: objective=0.749814 reg=0.002594
2017/08/29 16:21:34 Training value function...
2017/08/29 16:21:37 step 0: mse=115.088618 step=0.100000
2017/08/29 16:21:38 step 1: mse=114.086887 step=0.100000
2017/08/29 16:21:40 step 2: mse=113.009487 step=0.100000
2017/08/29 16:21:41 step 3: mse=112.258273 step=0.100000
2017/08/29 16:21:43 step 4: mse=111.664674 step=0.100000
2017/08/29 16:21:45 step 5: mse=111.213038 step=0.100000
2017/08/29 16:21:46 step 6: mse=110.736327 step=0.100000
2017/08/29 16:21:48 step 7: mse=110.351157 step=0.100000
2017/08/29 16:21:48 Saving...
2017/08/29 16:21:48 Gathering batch of experience...
2017/08/29 16:22:42 batch 168: mean=439.052632 stddev=170.143739 entropy=0.257310 frames=7936 count=19
2017/08/29 16:22:42 Training policy...
2017/08/29 16:22:50 tune 0: objective=1.595461 reg=0.002573 prune=0
2017/08/29 16:22:54 tune 1: objective=1.597562 reg=0.002573 prune=0
2017/08/29 16:22:59 tune 2: objective=1.599655 reg=0.002573 prune=0
2017/08/29 16:23:04 tune 3: objective=1.601749 reg=0.002573 prune=0
2017/08/29 16:23:08 tune 4: objective=1.603829 reg=0.002573 prune=0
2017/08/29 16:23:13 tune 5: objective=1.605776 reg=0.002573 prune=0
2017/08/29 16:23:18 tune 6: objective=1.607613 reg=0.002573 prune=0
2017/08/29 16:23:22 tune 7: objective=1.609386 reg=0.002573 prune=0
2017/08/29 16:23:25 step 0: objective=1.611028 reg=0.002573
2017/08/29 16:23:28 step 1: objective=1.613629 reg=0.002573
2017/08/29 16:23:31 step 2: objective=1.615209 reg=0.002573
2017/08/29 16:23:34 step 3: objective=1.617392 reg=0.002572
2017/08/29 16:23:37 step 4: objective=1.618559 reg=0.002573
2017/08/29 16:23:40 step 5: objective=1.620086 reg=0.002573
2017/08/29 16:23:43 step 6: objective=1.621521 reg=0.002573
2017/08/29 16:23:46 step 7: objective=1.622656 reg=0.002573
2017/08/29 16:23:46 Training value function...
2017/08/29 16:23:50 step 0: mse=124.693098 step=0.100000
2017/08/29 16:23:51 step 1: mse=122.211011 step=0.100000
2017/08/29 16:23:53 step 2: mse=120.016288 step=0.100000
2017/08/29 16:23:55 step 3: mse=118.215191 step=0.100000
2017/08/29 16:23:56 step 4: mse=116.725629 step=0.100000
2017/08/29 16:23:58 step 5: mse=115.224828 step=0.100000
2017/08/29 16:24:00 step 6: mse=113.983583 step=0.100000
2017/08/29 16:24:01 step 7: mse=113.048552 step=0.100000
2017/08/29 16:24:01 Saving...
2017/08/29 16:24:01 Gathering batch of experience...
2017/08/29 16:24:50 batch 169: mean=387.100000 stddev=200.104448 entropy=0.257741 frames=7170 count=20
2017/08/29 16:24:50 Training policy...
2017/08/29 16:24:57 tune 0: objective=1.470383 reg=0.002577 prune=0
2017/08/29 16:25:01 tune 1: objective=1.472901 reg=0.002577 prune=0
2017/08/29 16:25:05 tune 2: objective=1.475407 reg=0.002577 prune=0
2017/08/29 16:25:10 tune 3: objective=1.477899 reg=0.002577 prune=0
2017/08/29 16:25:14 tune 4: objective=1.480389 reg=0.002577 prune=0
2017/08/29 16:25:18 tune 5: objective=1.482853 reg=0.002577 prune=0
2017/08/29 16:25:22 tune 6: objective=1.485155 reg=0.002577 prune=0
2017/08/29 16:25:26 tune 7: objective=1.487301 reg=0.002576 prune=0
2017/08/29 16:25:29 step 0: objective=1.489225 reg=0.002576
2017/08/29 16:25:32 step 1: objective=1.492122 reg=0.002576
2017/08/29 16:25:35 step 2: objective=1.493681 reg=0.002576
2017/08/29 16:25:37 step 3: objective=1.495084 reg=0.002576
2017/08/29 16:25:40 step 4: objective=1.496430 reg=0.002575
2017/08/29 16:25:43 step 5: objective=1.498064 reg=0.002575
2017/08/29 16:25:45 step 6: objective=1.500064 reg=0.002575
2017/08/29 16:25:48 step 7: objective=1.502203 reg=0.002576
2017/08/29 16:25:48 Training value function...
2017/08/29 16:25:51 step 0: mse=144.479923 step=0.100000
2017/08/29 16:25:53 step 1: mse=142.701840 step=0.100000
2017/08/29 16:25:54 step 2: mse=141.017482 step=0.100000
2017/08/29 16:25:56 step 3: mse=139.274856 step=0.100000
2017/08/29 16:25:57 step 4: mse=138.007017 step=0.100000
2017/08/29 16:25:59 step 5: mse=136.397680 step=0.100000
2017/08/29 16:26:00 step 6: mse=135.141056 step=0.100000
2017/08/29 16:26:02 step 7: mse=134.065206 step=0.100000
2017/08/29 16:26:02 Saving...
2017/08/29 16:26:02 Gathering batch of experience...
2017/08/29 16:26:50 batch 170: mean=310.708333 stddev=207.684753 entropy=0.255065 frames=7039 count=24
2017/08/29 16:26:50 Training policy...
2017/08/29 16:26:57 tune 0: objective=0.728125 reg=0.002551 prune=0
2017/08/29 16:27:01 tune 1: objective=0.730806 reg=0.002551 prune=0
2017/08/29 16:27:05 tune 2: objective=0.733471 reg=0.002551 prune=0
2017/08/29 16:27:10 tune 3: objective=0.736121 reg=0.002550 prune=0
2017/08/29 16:27:14 tune 4: objective=0.738686 reg=0.002550 prune=0
2017/08/29 16:27:18 tune 5: objective=0.741012 reg=0.002550 prune=0
2017/08/29 16:27:22 tune 6: objective=0.743121 reg=0.002550 prune=0
2017/08/29 16:27:26 tune 7: objective=0.745035 reg=0.002550 prune=0
2017/08/29 16:27:29 step 0: objective=0.746888 reg=0.002550
2017/08/29 16:27:31 step 1: objective=0.748464 reg=0.002550
2017/08/29 16:27:34 step 2: objective=0.750700 reg=0.002550
2017/08/29 16:27:37 step 3: objective=0.753118 reg=0.002551
2017/08/29 16:27:39 step 4: objective=0.754370 reg=0.002552
2017/08/29 16:27:42 step 5: objective=0.755861 reg=0.002552
2017/08/29 16:27:45 step 6: objective=0.757075 reg=0.002552
2017/08/29 16:27:47 step 7: objective=0.757969 reg=0.002552
2017/08/29 16:27:47 Training value function...
2017/08/29 16:27:50 step 0: mse=131.438316 step=0.100000
2017/08/29 16:27:52 step 1: mse=130.177719 step=0.100000
2017/08/29 16:27:53 step 2: mse=129.096671 step=0.100000
2017/08/29 16:27:55 step 3: mse=128.535253 step=0.100000
2017/08/29 16:27:56 step 4: mse=127.757044 step=0.100000
2017/08/29 16:27:58 step 5: mse=127.408268 step=0.100000
2017/08/29 16:27:59 step 6: mse=126.951263 step=0.100000
2017/08/29 16:28:01 step 7: mse=126.426448 step=0.100000
2017/08/29 16:28:01 Saving...
2017/08/29 16:28:01 Gathering batch of experience...
2017/08/29 16:28:54 batch 171: mean=376.500000 stddev=212.684305 entropy=0.251275 frames=7681 count=22
2017/08/29 16:28:54 Training policy...
2017/08/29 16:29:02 tune 0: objective=1.460013 reg=0.002513 prune=0
2017/08/29 16:29:07 tune 1: objective=1.462154 reg=0.002513 prune=0
2017/08/29 16:29:11 tune 2: objective=1.464293 reg=0.002513 prune=0
2017/08/29 16:29:16 tune 3: objective=1.466427 reg=0.002513 prune=0
2017/08/29 16:29:20 tune 4: objective=1.468560 reg=0.002513 prune=0
2017/08/29 16:29:25 tune 5: objective=1.470682 reg=0.002513 prune=0
2017/08/29 16:29:29 tune 6: objective=1.472739 reg=0.002513 prune=0
2017/08/29 16:29:34 tune 7: objective=1.474796 reg=0.002513 prune=0
2017/08/29 16:29:37 step 0: objective=1.476831 reg=0.002513
2017/08/29 16:29:40 step 1: objective=1.478871 reg=0.002513
2017/08/29 16:29:43 step 2: objective=1.481057 reg=0.002512
2017/08/29 16:29:46 step 3: objective=1.483290 reg=0.002512
2017/08/29 16:29:48 step 4: objective=1.486281 reg=0.002512
2017/08/29 16:29:51 step 5: objective=1.487263 reg=0.002512
2017/08/29 16:29:54 step 6: objective=1.489325 reg=0.002511
2017/08/29 16:29:57 step 7: objective=1.491524 reg=0.002511
2017/08/29 16:29:57 Training value function...
2017/08/29 16:30:00 step 0: mse=147.135542 step=0.100000
2017/08/29 16:30:02 step 1: mse=145.129121 step=0.100000
2017/08/29 16:30:04 step 2: mse=143.014297 step=0.100000
2017/08/29 16:30:05 step 3: mse=141.339745 step=0.100000
2017/08/29 16:30:07 step 4: mse=139.848859 step=0.100000
2017/08/29 16:30:08 step 5: mse=138.164322 step=0.100000
2017/08/29 16:30:10 step 6: mse=136.862861 step=0.100000
2017/08/29 16:30:12 step 7: mse=135.572612 step=0.100000
2017/08/29 16:30:12 Saving...
2017/08/29 16:30:12 Gathering batch of experience...
2017/08/29 16:31:02 batch 172: mean=425.750000 stddev=215.725491 entropy=0.258990 frames=7934 count=20
2017/08/29 16:31:02 Training policy...
2017/08/29 16:31:10 tune 0: objective=1.365770 reg=0.002590 prune=0
2017/08/29 16:31:15 tune 1: objective=1.368034 reg=0.002590 prune=0
2017/08/29 16:31:20 tune 2: objective=1.370286 reg=0.002590 prune=0
2017/08/29 16:31:24 tune 3: objective=1.372522 reg=0.002590 prune=0
2017/08/29 16:31:29 tune 4: objective=1.374743 reg=0.002590 prune=0
2017/08/29 16:31:34 tune 5: objective=1.376834 reg=0.002590 prune=0
2017/08/29 16:31:38 tune 6: objective=1.378913 reg=0.002590 prune=0
2017/08/29 16:31:43 tune 7: objective=1.380873 reg=0.002591 prune=0
2017/08/29 16:31:46 step 0: objective=1.382706 reg=0.002591
2017/08/29 16:31:49 step 1: objective=1.384607 reg=0.002591
2017/08/29 16:31:52 step 2: objective=1.385610 reg=0.002591
2017/08/29 16:31:55 step 3: objective=1.386814 reg=0.002591
2017/08/29 16:31:58 step 4: objective=1.387815 reg=0.002591
2017/08/29 16:32:01 step 5: objective=1.389247 reg=0.002591
2017/08/29 16:32:04 step 6: objective=1.391137 reg=0.002592
2017/08/29 16:32:07 step 7: objective=1.392136 reg=0.002592
2017/08/29 16:32:07 Training value function...
2017/08/29 16:32:10 step 0: mse=127.035538 step=0.100000
2017/08/29 16:32:12 step 1: mse=125.231521 step=0.100000
2017/08/29 16:32:14 step 2: mse=123.604621 step=0.100000
2017/08/29 16:32:16 step 3: mse=122.187978 step=0.100000
2017/08/29 16:32:17 step 4: mse=120.830782 step=0.100000
2017/08/29 16:32:19 step 5: mse=119.795658 step=0.100000
2017/08/29 16:32:20 step 6: mse=118.878849 step=0.100000
2017/08/29 16:32:22 step 7: mse=117.820147 step=0.100000
2017/08/29 16:32:22 Saving...
2017/08/29 16:32:22 Gathering batch of experience...
2017/08/29 16:33:08 batch 173: mean=383.842105 stddev=241.182234 entropy=0.257969 frames=6555 count=19
2017/08/29 16:33:08 Training policy...
2017/08/29 16:33:14 tune 0: objective=1.595488 reg=0.002580 prune=0
2017/08/29 16:33:18 tune 1: objective=1.597617 reg=0.002580 prune=0
2017/08/29 16:33:22 tune 2: objective=1.599730 reg=0.002580 prune=0
2017/08/29 16:33:26 tune 3: objective=1.601815 reg=0.002580 prune=0
2017/08/29 16:33:30 tune 4: objective=1.603888 reg=0.002580 prune=0
2017/08/29 16:33:34 tune 5: objective=1.605937 reg=0.002580 prune=0
2017/08/29 16:33:37 tune 6: objective=1.607797 reg=0.002580 prune=0
2017/08/29 16:33:41 tune 7: objective=1.609563 reg=0.002580 prune=0
2017/08/29 16:33:44 step 0: objective=1.611220 reg=0.002580
2017/08/29 16:33:46 step 1: objective=1.612699 reg=0.002581
2017/08/29 16:33:49 step 2: objective=1.614222 reg=0.002581
2017/08/29 16:33:51 step 3: objective=1.615704 reg=0.002581
2017/08/29 16:33:54 step 4: objective=1.617931 reg=0.002581
2017/08/29 16:33:56 step 5: objective=1.619013 reg=0.002581
2017/08/29 16:33:59 step 6: objective=1.620163 reg=0.002582
2017/08/29 16:34:01 step 7: objective=1.621059 reg=0.002582
2017/08/29 16:34:01 Training value function...
2017/08/29 16:34:04 step 0: mse=138.033972 step=0.100000
2017/08/29 16:34:05 step 1: mse=134.917362 step=0.100000
2017/08/29 16:34:07 step 2: mse=132.189622 step=0.100000
2017/08/29 16:34:08 step 3: mse=129.724574 step=0.100000
2017/08/29 16:34:09 step 4: mse=127.959867 step=0.100000
2017/08/29 16:34:11 step 5: mse=126.384089 step=0.100000
2017/08/29 16:34:12 step 6: mse=124.855335 step=0.100000
2017/08/29 16:34:14 step 7: mse=123.677592 step=0.100000
2017/08/29 16:34:14 Saving...
2017/08/29 16:34:14 Gathering batch of experience...
2017/08/29 16:35:02 batch 174: mean=462.411765 stddev=196.132626 entropy=0.258319 frames=7046 count=17
2017/08/29 16:35:02 Training policy...
2017/08/29 16:35:09 tune 0: objective=1.441689 reg=0.002583 prune=0
2017/08/29 16:35:13 tune 1: objective=1.444013 reg=0.002582 prune=0
2017/08/29 16:35:17 tune 2: objective=1.446321 reg=0.002581 prune=0
2017/08/29 16:35:21 tune 3: objective=1.448608 reg=0.002580 prune=0
2017/08/29 16:35:25 tune 4: objective=1.450873 reg=0.002579 prune=0
2017/08/29 16:35:30 tune 5: objective=1.453031 reg=0.002578 prune=0
2017/08/29 16:35:34 tune 6: objective=1.455172 reg=0.002577 prune=0
2017/08/29 16:35:38 tune 7: objective=1.457254 reg=0.002576 prune=0
2017/08/29 16:35:41 step 0: objective=1.459133 reg=0.002575
2017/08/29 16:35:43 step 1: objective=1.461330 reg=0.002574
2017/08/29 16:35:46 step 2: objective=1.464901 reg=0.002573
2017/08/29 16:35:49 step 3: objective=1.466354 reg=0.002573
2017/08/29 16:35:51 step 4: objective=1.468065 reg=0.002572
2017/08/29 16:35:54 step 5: objective=1.469470 reg=0.002572
2017/08/29 16:35:57 step 6: objective=1.471214 reg=0.002572
2017/08/29 16:35:59 step 7: objective=1.472315 reg=0.002571
2017/08/29 16:35:59 Training value function...
2017/08/29 16:36:02 step 0: mse=162.229296 step=0.100000
2017/08/29 16:36:04 step 1: mse=158.805384 step=0.100000
2017/08/29 16:36:05 step 2: mse=156.126349 step=0.100000
2017/08/29 16:36:07 step 3: mse=153.630645 step=0.100000
2017/08/29 16:36:08 step 4: mse=151.498960 step=0.100000
2017/08/29 16:36:10 step 5: mse=149.911060 step=0.100000
2017/08/29 16:36:11 step 6: mse=148.214179 step=0.100000
2017/08/29 16:36:13 step 7: mse=146.673794 step=0.100000
2017/08/29 16:36:13 Saving...
2017/08/29 16:36:13 Gathering batch of experience...
2017/08/29 16:37:00 batch 175: mean=335.590909 stddev=257.755462 entropy=0.259181 frames=6793 count=22
2017/08/29 16:37:00 Training policy...
2017/08/29 16:37:07 tune 0: objective=0.661951 reg=0.002592 prune=0
2017/08/29 16:37:11 tune 1: objective=0.664822 reg=0.002592 prune=0
2017/08/29 16:37:15 tune 2: objective=0.667668 reg=0.002592 prune=0
2017/08/29 16:37:19 tune 3: objective=0.670489 reg=0.002592 prune=0
2017/08/29 16:37:23 tune 4: objective=0.673286 reg=0.002592 prune=0
2017/08/29 16:37:27 tune 5: objective=0.675918 reg=0.002592 prune=0
2017/08/29 16:37:31 tune 6: objective=0.678384 reg=0.002592 prune=0
2017/08/29 16:37:35 tune 7: objective=0.680658 reg=0.002592 prune=0
2017/08/29 16:37:38 step 0: objective=0.682687 reg=0.002592
2017/08/29 16:37:40 step 1: objective=0.684562 reg=0.002592
2017/08/29 16:37:43 step 2: objective=0.686181 reg=0.002593
2017/08/29 16:37:45 step 3: objective=0.689542 reg=0.002593
2017/08/29 16:37:48 step 4: objective=0.691992 reg=0.002593
2017/08/29 16:37:51 step 5: objective=0.693734 reg=0.002594
2017/08/29 16:37:53 step 6: objective=0.695082 reg=0.002594
2017/08/29 16:37:56 step 7: objective=0.696415 reg=0.002593
2017/08/29 16:37:56 Training value function...
2017/08/29 16:37:59 step 0: mse=138.487441 step=0.100000
2017/08/29 16:38:00 step 1: mse=135.660843 step=0.100000
2017/08/29 16:38:01 step 2: mse=133.468226 step=0.100000
2017/08/29 16:38:03 step 3: mse=131.883301 step=0.100000
2017/08/29 16:38:04 step 4: mse=130.344278 step=0.100000
2017/08/29 16:38:06 step 5: mse=129.059736 step=0.100000
2017/08/29 16:38:07 step 6: mse=127.975830 step=0.100000
2017/08/29 16:38:09 step 7: mse=127.036825 step=0.100000
2017/08/29 16:38:09 Saving...
2017/08/29 16:38:09 Gathering batch of experience...
2017/08/29 16:38:58 batch 176: mean=405.700000 stddev=250.975118 entropy=0.256351 frames=7323 count=20
2017/08/29 16:38:58 Training policy...
2017/08/29 16:39:05 tune 0: objective=1.367755 reg=0.002564 prune=0
2017/08/29 16:39:10 tune 1: objective=1.370298 reg=0.002563 prune=0
2017/08/29 16:39:14 tune 2: objective=1.372821 reg=0.002562 prune=0
2017/08/29 16:39:18 tune 3: objective=1.375323 reg=0.002562 prune=0
2017/08/29 16:39:22 tune 4: objective=1.377810 reg=0.002561 prune=0
2017/08/29 16:39:27 tune 5: objective=1.380278 reg=0.002561 prune=0
2017/08/29 16:39:31 tune 6: objective=1.382573 reg=0.002560 prune=0
2017/08/29 16:39:35 tune 7: objective=1.384676 reg=0.002560 prune=0
2017/08/29 16:39:38 step 0: objective=1.386677 reg=0.002560
2017/08/29 16:39:41 step 1: objective=1.388493 reg=0.002560
2017/08/29 16:39:44 step 2: objective=1.391394 reg=0.002560
2017/08/29 16:39:47 step 3: objective=1.392943 reg=0.002559
2017/08/29 16:39:49 step 4: objective=1.394203 reg=0.002559
2017/08/29 16:39:52 step 5: objective=1.395393 reg=0.002559
2017/08/29 16:39:55 step 6: objective=1.396463 reg=0.002558
2017/08/29 16:39:58 step 7: objective=1.397640 reg=0.002557
2017/08/29 16:39:58 Training value function...
2017/08/29 16:40:01 step 0: mse=150.668170 step=0.100000
2017/08/29 16:40:02 step 1: mse=148.632858 step=0.100000
2017/08/29 16:40:04 step 2: mse=146.830060 step=0.100000
2017/08/29 16:40:05 step 3: mse=145.593065 step=0.100000
2017/08/29 16:40:07 step 4: mse=144.321708 step=0.100000
2017/08/29 16:40:09 step 5: mse=142.831709 step=0.100000
2017/08/29 16:40:10 step 6: mse=141.556891 step=0.100000
2017/08/29 16:40:12 step 7: mse=140.574793 step=0.100000
2017/08/29 16:40:12 Saving...
2017/08/29 16:40:12 Gathering batch of experience...
2017/08/29 16:41:00 batch 177: mean=338.272727 stddev=228.327950 entropy=0.252432 frames=6944 count=22
2017/08/29 16:41:00 Training policy...
2017/08/29 16:41:07 tune 0: objective=0.538199 reg=0.002524 prune=0
2017/08/29 16:41:11 tune 1: objective=0.540709 reg=0.002524 prune=0
2017/08/29 16:41:15 tune 2: objective=0.543184 reg=0.002524 prune=0
2017/08/29 16:41:19 tune 3: objective=0.545628 reg=0.002524 prune=0
2017/08/29 16:41:24 tune 4: objective=0.548019 reg=0.002523 prune=0
2017/08/29 16:41:28 tune 5: objective=0.550284 reg=0.002523 prune=0
2017/08/29 16:41:32 tune 6: objective=0.552528 reg=0.002523 prune=0
2017/08/29 16:41:36 tune 7: objective=0.554618 reg=0.002523 prune=0
2017/08/29 16:41:38 step 0: objective=0.556400 reg=0.002523
2017/08/29 16:41:41 step 1: objective=0.559260 reg=0.002523
2017/08/29 16:41:44 step 2: objective=0.560589 reg=0.002523
2017/08/29 16:41:46 step 3: objective=0.562771 reg=0.002523
2017/08/29 16:41:49 step 4: objective=0.564231 reg=0.002523
2017/08/29 16:41:52 step 5: objective=0.565608 reg=0.002524
2017/08/29 16:41:54 step 6: objective=0.566949 reg=0.002523
2017/08/29 16:41:57 step 7: objective=0.567838 reg=0.002523
2017/08/29 16:41:57 Training value function...
2017/08/29 16:42:00 step 0: mse=116.625812 step=0.100000
2017/08/29 16:42:01 step 1: mse=115.742202 step=0.100000
2017/08/29 16:42:03 step 2: mse=115.117188 step=0.100000
2017/08/29 16:42:04 step 3: mse=114.633958 step=0.100000
2017/08/29 16:42:06 step 4: mse=114.006162 step=0.100000
2017/08/29 16:42:07 step 5: mse=113.605973 step=0.100000
2017/08/29 16:42:09 step 6: mse=113.375908 step=0.100000
2017/08/29 16:42:10 step 7: mse=113.016737 step=0.100000
2017/08/29 16:42:10 Saving...
2017/08/29 16:42:10 Gathering batch of experience...
2017/08/29 16:43:05 batch 178: mean=320.807692 stddev=243.254223 entropy=0.258220 frames=8058 count=26
2017/08/29 16:43:05 Training policy...
2017/08/29 16:43:13 tune 0: objective=0.424732 reg=0.002582 prune=0
2017/08/29 16:43:18 tune 1: objective=0.426808 reg=0.002582 prune=0
2017/08/29 16:43:23 tune 2: objective=0.428865 reg=0.002582 prune=0
2017/08/29 16:43:27 tune 3: objective=0.430905 reg=0.002582 prune=0
2017/08/29 16:43:32 tune 4: objective=0.432924 reg=0.002581 prune=0
2017/08/29 16:43:37 tune 5: objective=0.434927 reg=0.002581 prune=0
2017/08/29 16:43:42 tune 6: objective=0.436815 reg=0.002581 prune=0
2017/08/29 16:43:46 tune 7: objective=0.438593 reg=0.002581 prune=0
2017/08/29 16:43:50 step 0: objective=0.440269 reg=0.002581
2017/08/29 16:43:53 step 1: objective=0.442562 reg=0.002581
2017/08/29 16:43:56 step 2: objective=0.444992 reg=0.002581
2017/08/29 16:43:59 step 3: objective=0.446510 reg=0.002581
2017/08/29 16:44:02 step 4: objective=0.448259 reg=0.002580
2017/08/29 16:44:05 step 5: objective=0.449310 reg=0.002580
2017/08/29 16:44:08 step 6: objective=0.450706 reg=0.002581
2017/08/29 16:44:11 step 7: objective=0.451739 reg=0.002581
2017/08/29 16:44:11 Training value function...
2017/08/29 16:44:15 step 0: mse=123.340236 step=0.100000
2017/08/29 16:44:16 step 1: mse=122.544473 step=0.100000
2017/08/29 16:44:18 step 2: mse=121.882910 step=0.100000
2017/08/29 16:44:20 step 3: mse=121.431073 step=0.100000
2017/08/29 16:44:21 step 4: mse=120.912948 step=0.100000
2017/08/29 16:44:23 step 5: mse=120.368576 step=0.100000
2017/08/29 16:44:25 step 6: mse=120.038583 step=0.100000
2017/08/29 16:44:26 step 7: mse=119.517087 step=0.100000
2017/08/29 16:44:26 Saving...
2017/08/29 16:44:27 Gathering batch of experience...
2017/08/29 16:45:13 batch 179: mean=448.294118 stddev=163.047003 entropy=0.255185 frames=7112 count=17
2017/08/29 16:45:13 Training policy...
2017/08/29 16:45:20 tune 0: objective=1.383560 reg=0.002552 prune=0
2017/08/29 16:45:24 tune 1: objective=1.385497 reg=0.002552 prune=0
2017/08/29 16:45:28 tune 2: objective=1.387418 reg=0.002553 prune=0
2017/08/29 16:45:33 tune 3: objective=1.389334 reg=0.002553 prune=0
2017/08/29 16:45:37 tune 4: objective=1.391241 reg=0.002553 prune=0
2017/08/29 16:45:41 tune 5: objective=1.393139 reg=0.002554 prune=0
2017/08/29 16:45:45 tune 6: objective=1.394997 reg=0.002554 prune=0
2017/08/29 16:45:49 tune 7: objective=1.396801 reg=0.002554 prune=0
2017/08/29 16:45:52 step 0: objective=1.398443 reg=0.002555
2017/08/29 16:45:55 step 1: objective=1.399784 reg=0.002555
2017/08/29 16:45:58 step 2: objective=1.401115 reg=0.002556
2017/08/29 16:46:00 step 3: objective=1.402634 reg=0.002556
2017/08/29 16:46:03 step 4: objective=1.403919 reg=0.002557
2017/08/29 16:46:06 step 5: objective=1.405188 reg=0.002558
2017/08/29 16:46:08 step 6: objective=1.406583 reg=0.002558
2017/08/29 16:46:11 step 7: objective=1.407679 reg=0.002558
2017/08/29 16:46:11 Training value function...
2017/08/29 16:46:14 step 0: mse=140.740173 step=0.100000
2017/08/29 16:46:16 step 1: mse=138.103912 step=0.100000
2017/08/29 16:46:17 step 2: mse=135.771271 step=0.100000
2017/08/29 16:46:19 step 3: mse=133.994827 step=0.100000
2017/08/29 16:46:20 step 4: mse=132.384608 step=0.100000
2017/08/29 16:46:22 step 5: mse=131.167313 step=0.100000
2017/08/29 16:46:23 step 6: mse=130.069989 step=0.100000
2017/08/29 16:46:25 step 7: mse=128.794860 step=0.100000
2017/08/29 16:46:25 Saving...
2017/08/29 16:46:25 Gathering batch of experience...
2017/08/29 16:47:15 batch 180: mean=465.888889 stddev=187.124703 entropy=0.260647 frames=7813 count=18
2017/08/29 16:47:15 Training policy...
2017/08/29 16:47:23 tune 0: objective=1.297677 reg=0.002606 prune=0
2017/08/29 16:47:27 tune 1: objective=1.299682 reg=0.002606 prune=0
2017/08/29 16:47:32 tune 2: objective=1.301683 reg=0.002606 prune=0
2017/08/29 16:47:37 tune 3: objective=1.303677 reg=0.002606 prune=0
2017/08/29 16:47:41 tune 4: objective=1.305664 reg=0.002606 prune=0
2017/08/29 16:47:46 tune 5: objective=1.307525 reg=0.002606 prune=0
2017/08/29 16:47:50 tune 6: objective=1.309251 reg=0.002606 prune=0
2017/08/29 16:47:55 tune 7: objective=1.310897 reg=0.002605 prune=0
2017/08/29 16:47:58 step 0: objective=1.312464 reg=0.002605
2017/08/29 16:48:01 step 1: objective=1.314060 reg=0.002605
2017/08/29 16:48:04 step 2: objective=1.315628 reg=0.002604
2017/08/29 16:48:07 step 3: objective=1.316864 reg=0.002603
2017/08/29 16:48:10 step 4: objective=1.318456 reg=0.002603
2017/08/29 16:48:13 step 5: objective=1.319895 reg=0.002603
2017/08/29 16:48:16 step 6: objective=1.320917 reg=0.002602
2017/08/29 16:48:19 step 7: objective=1.322027 reg=0.002602
2017/08/29 16:48:19 Training value function...
2017/08/29 16:48:22 step 0: mse=131.510636 step=0.100000
2017/08/29 16:48:24 step 1: mse=128.273375 step=0.100000
2017/08/29 16:48:26 step 2: mse=125.195188 step=0.100000
2017/08/29 16:48:27 step 3: mse=122.840178 step=0.100000
2017/08/29 16:48:29 step 4: mse=120.643212 step=0.100000
2017/08/29 16:48:30 step 5: mse=118.955763 step=0.100000
2017/08/29 16:48:32 step 6: mse=117.374517 step=0.100000
2017/08/29 16:48:34 step 7: mse=116.036702 step=0.100000
2017/08/29 16:48:34 Saving...
2017/08/29 16:48:34 Gathering batch of experience...
2017/08/29 16:49:25 batch 181: mean=353.363636 stddev=211.518868 entropy=0.255507 frames=7224 count=22
2017/08/29 16:49:25 Training policy...
2017/08/29 16:49:32 tune 0: objective=0.894909 reg=0.002555 prune=0
2017/08/29 16:49:37 tune 1: objective=0.897086 reg=0.002555 prune=0
2017/08/29 16:49:41 tune 2: objective=0.899251 reg=0.002555 prune=0
2017/08/29 16:49:45 tune 3: objective=0.901406 reg=0.002555 prune=0
2017/08/29 16:49:49 tune 4: objective=0.903547 reg=0.002555 prune=0
2017/08/29 16:49:54 tune 5: objective=0.905667 reg=0.002555 prune=0
2017/08/29 16:49:58 tune 6: objective=0.907645 reg=0.002555 prune=0
2017/08/29 16:50:02 tune 7: objective=0.909572 reg=0.002555 prune=0
2017/08/29 16:50:05 step 0: objective=0.911478 reg=0.002556
2017/08/29 16:50:08 step 1: objective=0.913189 reg=0.002555
2017/08/29 16:50:10 step 2: objective=0.914678 reg=0.002556
2017/08/29 16:50:13 step 3: objective=0.915929 reg=0.002556
2017/08/29 16:50:16 step 4: objective=0.917429 reg=0.002556
2017/08/29 16:50:19 step 5: objective=0.918651 reg=0.002557
2017/08/29 16:50:22 step 6: objective=0.919662 reg=0.002557
2017/08/29 16:50:24 step 7: objective=0.921179 reg=0.002557
2017/08/29 16:50:24 Training value function...
2017/08/29 16:50:27 step 0: mse=125.516349 step=0.100000
2017/08/29 16:50:29 step 1: mse=124.303055 step=0.100000
2017/08/29 16:50:30 step 2: mse=123.214277 step=0.100000
2017/08/29 16:50:32 step 3: mse=122.394600 step=0.100000
2017/08/29 16:50:33 step 4: mse=121.689704 step=0.100000
2017/08/29 16:50:35 step 5: mse=120.966959 step=0.100000
2017/08/29 16:50:36 step 6: mse=120.472976 step=0.100000
2017/08/29 16:50:38 step 7: mse=119.822201 step=0.100000
2017/08/29 16:50:38 Saving...
2017/08/29 16:50:38 Gathering batch of experience...
2017/08/29 16:51:32 batch 182: mean=342.500000 stddev=209.531208 entropy=0.254565 frames=8055 count=26
2017/08/29 16:51:32 Training policy...
2017/08/29 16:51:41 tune 0: objective=1.252946 reg=0.002546 prune=0
2017/08/29 16:51:45 tune 1: objective=1.255289 reg=0.002546 prune=0
2017/08/29 16:51:50 tune 2: objective=1.257613 reg=0.002545 prune=0
2017/08/29 16:51:55 tune 3: objective=1.259920 reg=0.002545 prune=0
2017/08/29 16:52:00 tune 4: objective=1.262213 reg=0.002545 prune=0
2017/08/29 16:52:04 tune 5: objective=1.264497 reg=0.002545 prune=0
2017/08/29 16:52:09 tune 6: objective=1.266664 reg=0.002545 prune=0
2017/08/29 16:52:14 tune 7: objective=1.268757 reg=0.002545 prune=0
2017/08/29 16:52:17 step 0: objective=1.270692 reg=0.002545
2017/08/29 16:52:20 step 1: objective=1.272985 reg=0.002546
2017/08/29 16:52:23 step 2: objective=1.275149 reg=0.002544
2017/08/29 16:52:26 step 3: objective=1.276709 reg=0.002544
2017/08/29 16:52:30 step 4: objective=1.277916 reg=0.002544
2017/08/29 16:52:33 step 5: objective=1.278891 reg=0.002544
2017/08/29 16:52:36 step 6: objective=1.279930 reg=0.002543
2017/08/29 16:52:39 step 7: objective=1.280956 reg=0.002543
2017/08/29 16:52:39 Training value function...
2017/08/29 16:52:42 step 0: mse=145.839355 step=0.100000
2017/08/29 16:52:44 step 1: mse=143.953898 step=0.100000
2017/08/29 16:52:46 step 2: mse=142.329169 step=0.100000
2017/08/29 16:52:47 step 3: mse=140.796209 step=0.100000
2017/08/29 16:52:49 step 4: mse=139.574072 step=0.100000
2017/08/29 16:52:51 step 5: mse=138.331996 step=0.100000
2017/08/29 16:52:52 step 6: mse=137.274264 step=0.100000
2017/08/29 16:52:54 step 7: mse=136.398570 step=0.100000
2017/08/29 16:52:54 Saving...
2017/08/29 16:52:54 Gathering batch of experience...
2017/08/29 16:53:43 batch 183: mean=340.217391 stddev=224.953513 entropy=0.250315 frames=7281 count=23
2017/08/29 16:53:43 Training policy...
2017/08/29 16:53:50 tune 0: objective=0.780999 reg=0.002503 prune=0
2017/08/29 16:53:54 tune 1: objective=0.783583 reg=0.002503 prune=0
2017/08/29 16:53:59 tune 2: objective=0.786154 reg=0.002503 prune=0
2017/08/29 16:54:03 tune 3: objective=0.788706 reg=0.002502 prune=0
2017/08/29 16:54:07 tune 4: objective=0.791247 reg=0.002502 prune=0
2017/08/29 16:54:12 tune 5: objective=0.793660 reg=0.002502 prune=0
2017/08/29 16:54:16 tune 6: objective=0.796003 reg=0.002502 prune=0
2017/08/29 16:54:20 tune 7: objective=0.798179 reg=0.002501 prune=0
2017/08/29 16:54:23 step 0: objective=0.800241 reg=0.002501
2017/08/29 16:54:26 step 1: objective=0.802923 reg=0.002501
2017/08/29 16:54:29 step 2: objective=0.806737 reg=0.002500
2017/08/29 16:54:31 step 3: objective=0.808847 reg=0.002500
2017/08/29 16:54:34 step 4: objective=0.811175 reg=0.002500
2017/08/29 16:54:37 step 5: objective=0.812250 reg=0.002500
2017/08/29 16:54:40 step 6: objective=0.813557 reg=0.002500
2017/08/29 16:54:43 step 7: objective=0.815268 reg=0.002499
2017/08/29 16:54:43 Training value function...
2017/08/29 16:54:46 step 0: mse=135.366514 step=0.100000
2017/08/29 16:54:47 step 1: mse=134.385157 step=0.100000
2017/08/29 16:54:49 step 2: mse=133.363054 step=0.100000
2017/08/29 16:54:50 step 3: mse=132.490907 step=0.100000
2017/08/29 16:54:52 step 4: mse=131.321484 step=0.100000
2017/08/29 16:54:53 step 5: mse=130.639903 step=0.100000
2017/08/29 16:54:55 step 6: mse=130.065891 step=0.100000
2017/08/29 16:54:56 step 7: mse=129.389483 step=0.100000
2017/08/29 16:54:56 Saving...
2017/08/29 16:54:57 Gathering batch of experience...
2017/08/29 16:55:44 batch 184: mean=405.684211 stddev=258.292175 entropy=0.257479 frames=7157 count=19
2017/08/29 16:55:44 Training policy...
2017/08/29 16:55:52 tune 0: objective=1.337149 reg=0.002575 prune=0
2017/08/29 16:55:56 tune 1: objective=1.339213 reg=0.002575 prune=0
2017/08/29 16:56:00 tune 2: objective=1.341276 reg=0.002575 prune=0
2017/08/29 16:56:05 tune 3: objective=1.343348 reg=0.002575 prune=0
2017/08/29 16:56:09 tune 4: objective=1.345372 reg=0.002575 prune=0
2017/08/29 16:56:13 tune 5: objective=1.347198 reg=0.002575 prune=0
2017/08/29 16:56:17 tune 6: objective=1.348954 reg=0.002575 prune=0
2017/08/29 16:56:21 tune 7: objective=1.350687 reg=0.002575 prune=0
2017/08/29 16:56:24 step 0: objective=1.352359 reg=0.002575
2017/08/29 16:56:27 step 1: objective=1.353812 reg=0.002575
2017/08/29 16:56:30 step 2: objective=1.355305 reg=0.002575
2017/08/29 16:56:32 step 3: objective=1.356486 reg=0.002575
2017/08/29 16:56:35 step 4: objective=1.358002 reg=0.002575
2017/08/29 16:56:38 step 5: objective=1.359097 reg=0.002575
2017/08/29 16:56:41 step 6: objective=1.360147 reg=0.002575
2017/08/29 16:56:43 step 7: objective=1.361327 reg=0.002575
2017/08/29 16:56:43 Training value function...
2017/08/29 16:56:46 step 0: mse=116.163093 step=0.100000
2017/08/29 16:56:48 step 1: mse=114.636616 step=0.100000
2017/08/29 16:56:49 step 2: mse=113.520776 step=0.100000
2017/08/29 16:56:51 step 3: mse=112.406258 step=0.100000
2017/08/29 16:56:52 step 4: mse=111.237428 step=0.100000
2017/08/29 16:56:54 step 5: mse=110.301032 step=0.100000
2017/08/29 16:56:55 step 6: mse=109.324202 step=0.100000
2017/08/29 16:56:57 step 7: mse=108.412204 step=0.100000
2017/08/29 16:56:57 Saving...
2017/08/29 16:56:57 Gathering batch of experience...
2017/08/29 16:57:44 batch 185: mean=411.277778 stddev=209.171329 entropy=0.259439 frames=6921 count=18
2017/08/29 16:57:44 Training policy...
2017/08/29 16:57:51 tune 0: objective=0.997585 reg=0.002594 prune=0
2017/08/29 16:57:55 tune 1: objective=0.999814 reg=0.002594 prune=0
2017/08/29 16:57:59 tune 2: objective=1.002021 reg=0.002593 prune=0
2017/08/29 16:58:03 tune 3: objective=1.004210 reg=0.002593 prune=0
2017/08/29 16:58:07 tune 4: objective=1.006377 reg=0.002592 prune=0
2017/08/29 16:58:11 tune 5: objective=1.008431 reg=0.002592 prune=0
2017/08/29 16:58:15 tune 6: objective=1.010326 reg=0.002591 prune=0
2017/08/29 16:58:20 tune 7: objective=1.012181 reg=0.002591 prune=0
2017/08/29 16:58:22 step 0: objective=1.013943 reg=0.002590
2017/08/29 16:58:25 step 1: objective=1.015449 reg=0.002590
2017/08/29 16:58:28 step 2: objective=1.017038 reg=0.002590
2017/08/29 16:58:30 step 3: objective=1.019139 reg=0.002589
2017/08/29 16:58:33 step 4: objective=1.020684 reg=0.002588
2017/08/29 16:58:36 step 5: objective=1.021851 reg=0.002587
2017/08/29 16:58:38 step 6: objective=1.024173 reg=0.002588
2017/08/29 16:58:41 step 7: objective=1.026127 reg=0.002587
2017/08/29 16:58:41 Training value function...
2017/08/29 16:58:44 step 0: mse=110.285347 step=0.100000
2017/08/29 16:58:45 step 1: mse=108.743398 step=0.100000
2017/08/29 16:58:47 step 2: mse=107.305723 step=0.100000
2017/08/29 16:58:48 step 3: mse=106.183141 step=0.100000
2017/08/29 16:58:50 step 4: mse=105.294324 step=0.100000
2017/08/29 16:58:51 step 5: mse=104.780066 step=0.100000
2017/08/29 16:58:52 step 6: mse=104.080927 step=0.100000
2017/08/29 16:58:54 step 7: mse=103.178834 step=0.100000
2017/08/29 16:58:54 Saving...
2017/08/29 16:58:54 Gathering batch of experience...
2017/08/29 16:59:49 batch 186: mean=405.904762 stddev=228.475674 entropy=0.251093 frames=7507 count=21
2017/08/29 16:59:49 Training policy...
2017/08/29 16:59:57 tune 0: objective=1.819162 reg=0.002511 prune=0
2017/08/29 17:00:01 tune 1: objective=1.821845 reg=0.002511 prune=0
2017/08/29 17:00:06 tune 2: objective=1.824500 reg=0.002511 prune=0
2017/08/29 17:00:10 tune 3: objective=1.827138 reg=0.002511 prune=0
2017/08/29 17:00:15 tune 4: objective=1.829718 reg=0.002511 prune=0
2017/08/29 17:00:19 tune 5: objective=1.831866 reg=0.002512 prune=0
2017/08/29 17:00:23 tune 6: objective=1.833923 reg=0.002512 prune=0
2017/08/29 17:00:28 tune 7: objective=1.835961 reg=0.002512 prune=0
2017/08/29 17:00:31 step 0: objective=1.837941 reg=0.002512
2017/08/29 17:00:34 step 1: objective=1.839874 reg=0.002512
2017/08/29 17:00:37 step 2: objective=1.841933 reg=0.002512
2017/08/29 17:00:39 step 3: objective=1.843585 reg=0.002512
2017/08/29 17:00:42 step 4: objective=1.844895 reg=0.002512
2017/08/29 17:00:45 step 5: objective=1.846328 reg=0.002512
2017/08/29 17:00:48 step 6: objective=1.848566 reg=0.002512
2017/08/29 17:00:51 step 7: objective=1.849491 reg=0.002511
2017/08/29 17:00:51 Training value function...
2017/08/29 17:00:54 step 0: mse=160.968355 step=0.100000
2017/08/29 17:00:56 step 1: mse=157.818591 step=0.100000
2017/08/29 17:00:57 step 2: mse=155.153080 step=0.100000
2017/08/29 17:00:59 step 3: mse=152.744128 step=0.100000
2017/08/29 17:01:00 step 4: mse=150.864563 step=0.100000
2017/08/29 17:01:02 step 5: mse=148.948171 step=0.100000
2017/08/29 17:01:04 step 6: mse=147.240005 step=0.100000
2017/08/29 17:01:05 step 7: mse=146.000909 step=0.100000
2017/08/29 17:01:05 Saving...
2017/08/29 17:01:05 Gathering batch of experience...
2017/08/29 17:01:56 batch 187: mean=453.684211 stddev=230.095416 entropy=0.253822 frames=7776 count=19
2017/08/29 17:01:56 Training policy...
2017/08/29 17:02:04 tune 0: objective=1.248445 reg=0.002538 prune=0
2017/08/29 17:02:08 tune 1: objective=1.250385 reg=0.002538 prune=0
2017/08/29 17:02:13 tune 2: objective=1.252328 reg=0.002538 prune=0
2017/08/29 17:02:17 tune 3: objective=1.254267 reg=0.002539 prune=0
2017/08/29 17:02:22 tune 4: objective=1.256213 reg=0.002539 prune=0
2017/08/29 17:02:27 tune 5: objective=1.258027 reg=0.002539 prune=0
2017/08/29 17:02:31 tune 6: objective=1.259777 reg=0.002539 prune=0
2017/08/29 17:02:36 tune 7: objective=1.261474 reg=0.002539 prune=0
2017/08/29 17:02:39 step 0: objective=1.263052 reg=0.002539
2017/08/29 17:02:42 step 1: objective=1.264824 reg=0.002540
2017/08/29 17:02:45 step 2: objective=1.266766 reg=0.002540
2017/08/29 17:02:48 step 3: objective=1.268051 reg=0.002540
2017/08/29 17:02:51 step 4: objective=1.269218 reg=0.002540
2017/08/29 17:02:54 step 5: objective=1.270333 reg=0.002541
2017/08/29 17:02:57 step 6: objective=1.271408 reg=0.002541
2017/08/29 17:03:00 step 7: objective=1.273315 reg=0.002541
2017/08/29 17:03:00 Training value function...
2017/08/29 17:03:03 step 0: mse=129.796244 step=0.100000
2017/08/29 17:03:05 step 1: mse=128.104622 step=0.100000
2017/08/29 17:03:06 step 2: mse=126.374953 step=0.100000
2017/08/29 17:03:08 step 3: mse=125.069035 step=0.100000
2017/08/29 17:03:10 step 4: mse=123.660323 step=0.100000
2017/08/29 17:03:11 step 5: mse=122.165898 step=0.100000
2017/08/29 17:03:13 step 6: mse=121.034444 step=0.100000
2017/08/29 17:03:15 step 7: mse=120.247308 step=0.100000
2017/08/29 17:03:15 Saving...
2017/08/29 17:03:15 Gathering batch of experience...
2017/08/29 17:04:05 batch 188: mean=366.318182 stddev=241.247023 entropy=0.251388 frames=7569 count=22
2017/08/29 17:04:05 Training policy...
2017/08/29 17:04:13 tune 0: objective=0.409710 reg=0.002514 prune=0
2017/08/29 17:04:18 tune 1: objective=0.411713 reg=0.002514 prune=0
2017/08/29 17:04:22 tune 2: objective=0.413702 reg=0.002513 prune=0
2017/08/29 17:04:27 tune 3: objective=0.415675 reg=0.002513 prune=0
2017/08/29 17:04:31 tune 4: objective=0.417635 reg=0.002513 prune=0
2017/08/29 17:04:36 tune 5: objective=0.419566 reg=0.002512 prune=0
2017/08/29 17:04:40 tune 6: objective=0.421412 reg=0.002512 prune=0
2017/08/29 17:04:45 tune 7: objective=0.423193 reg=0.002512 prune=0
2017/08/29 17:04:48 step 0: objective=0.424908 reg=0.002512
2017/08/29 17:04:50 step 1: objective=0.427310 reg=0.002513
2017/08/29 17:04:53 step 2: objective=0.429195 reg=0.002513
2017/08/29 17:04:56 step 3: objective=0.431864 reg=0.002514
2017/08/29 17:04:59 step 4: objective=0.433563 reg=0.002514
2017/08/29 17:05:02 step 5: objective=0.434966 reg=0.002514
2017/08/29 17:05:05 step 6: objective=0.435879 reg=0.002514
2017/08/29 17:05:08 step 7: objective=0.437095 reg=0.002514
2017/08/29 17:05:08 Training value function...
2017/08/29 17:05:11 step 0: mse=122.533013 step=0.100000
2017/08/29 17:05:13 step 1: mse=120.928049 step=0.100000
2017/08/29 17:05:14 step 2: mse=119.940124 step=0.100000
2017/08/29 17:05:16 step 3: mse=118.971365 step=0.100000
2017/08/29 17:05:17 step 4: mse=118.294613 step=0.100000
2017/08/29 17:05:19 step 5: mse=117.569253 step=0.100000
2017/08/29 17:05:21 step 6: mse=116.865581 step=0.100000
2017/08/29 17:05:22 step 7: mse=116.353384 step=0.100000
2017/08/29 17:05:22 Saving...
2017/08/29 17:05:22 Gathering batch of experience...
2017/08/29 17:06:15 batch 189: mean=387.409091 stddev=184.183619 entropy=0.255081 frames=7930 count=22
2017/08/29 17:06:15 Training policy...
2017/08/29 17:06:23 tune 0: objective=0.760611 reg=0.002551 prune=0
2017/08/29 17:06:28 tune 1: objective=0.762732 reg=0.002551 prune=0
2017/08/29 17:06:33 tune 2: objective=0.764840 reg=0.002551 prune=0
2017/08/29 17:06:38 tune 3: objective=0.766930 reg=0.002550 prune=0
2017/08/29 17:06:42 tune 4: objective=0.769007 reg=0.002550 prune=0
2017/08/29 17:06:47 tune 5: objective=0.771069 reg=0.002550 prune=0
2017/08/29 17:06:52 tune 6: objective=0.773032 reg=0.002550 prune=0
2017/08/29 17:06:56 tune 7: objective=0.774928 reg=0.002550 prune=0
2017/08/29 17:07:00 step 0: objective=0.776779 reg=0.002550
2017/08/29 17:07:03 step 1: objective=0.778263 reg=0.002551
2017/08/29 17:07:06 step 2: objective=0.780670 reg=0.002551
2017/08/29 17:07:09 step 3: objective=0.782979 reg=0.002551
2017/08/29 17:07:12 step 4: objective=0.784227 reg=0.002551
2017/08/29 17:07:15 step 5: objective=0.785407 reg=0.002551
2017/08/29 17:07:18 step 6: objective=0.786408 reg=0.002551
2017/08/29 17:07:21 step 7: objective=0.788357 reg=0.002551
2017/08/29 17:07:21 Training value function...
2017/08/29 17:07:24 step 0: mse=119.163291 step=0.100000
2017/08/29 17:07:26 step 1: mse=118.158818 step=0.100000
2017/08/29 17:07:28 step 2: mse=117.080354 step=0.100000
2017/08/29 17:07:29 step 3: mse=116.063990 step=0.100000
2017/08/29 17:07:31 step 4: mse=115.364141 step=0.100000
2017/08/29 17:07:33 step 5: mse=114.656615 step=0.100000
2017/08/29 17:07:34 step 6: mse=114.201236 step=0.100000
2017/08/29 17:07:36 step 7: mse=113.749139 step=0.100000
2017/08/29 17:07:36 Saving...
2017/08/29 17:07:36 Gathering batch of experience...
2017/08/29 17:08:24 batch 190: mean=446.777778 stddev=205.932717 entropy=0.248979 frames=7110 count=18
2017/08/29 17:08:24 Training policy...
2017/08/29 17:08:31 tune 0: objective=1.963730 reg=0.002490 prune=0
2017/08/29 17:08:36 tune 1: objective=1.965592 reg=0.002490 prune=0
2017/08/29 17:08:40 tune 2: objective=1.967432 reg=0.002490 prune=0
2017/08/29 17:08:44 tune 3: objective=1.969280 reg=0.002490 prune=0
2017/08/29 17:08:48 tune 4: objective=1.971123 reg=0.002490 prune=0
2017/08/29 17:08:53 tune 5: objective=1.972942 reg=0.002490 prune=0
2017/08/29 17:08:57 tune 6: objective=1.974662 reg=0.002491 prune=0
2017/08/29 17:09:01 tune 7: objective=1.976359 reg=0.002491 prune=0
2017/08/29 17:09:04 step 0: objective=1.977992 reg=0.002491
2017/08/29 17:09:07 step 1: objective=1.980935 reg=0.002491
2017/08/29 17:09:09 step 2: objective=1.982725 reg=0.002491
2017/08/29 17:09:12 step 3: objective=1.984069 reg=0.002491
2017/08/29 17:09:15 step 4: objective=1.985814 reg=0.002492
2017/08/29 17:09:18 step 5: objective=1.987027 reg=0.002492
2017/08/29 17:09:20 step 6: objective=1.988532 reg=0.002492
2017/08/29 17:09:23 step 7: objective=1.989882 reg=0.002492
2017/08/29 17:09:23 Training value function...
2017/08/29 17:09:26 step 0: mse=152.962918 step=0.100000
2017/08/29 17:09:28 step 1: mse=149.277820 step=0.100000
2017/08/29 17:09:29 step 2: mse=146.407621 step=0.100000
2017/08/29 17:09:31 step 3: mse=143.846696 step=0.100000
2017/08/29 17:09:32 step 4: mse=141.507107 step=0.100000
2017/08/29 17:09:33 step 5: mse=139.459801 step=0.100000
2017/08/29 17:09:35 step 6: mse=137.694417 step=0.100000
2017/08/29 17:09:36 step 7: mse=135.864007 step=0.100000
2017/08/29 17:09:36 Saving...
2017/08/29 17:09:37 Gathering batch of experience...
2017/08/29 17:10:31 batch 191: mean=353.240000 stddev=229.269323 entropy=0.257410 frames=8250 count=25
2017/08/29 17:10:31 Training policy...
2017/08/29 17:10:39 tune 0: objective=0.457529 reg=0.002574 prune=0
2017/08/29 17:10:44 tune 1: objective=0.459674 reg=0.002574 prune=0
2017/08/29 17:10:49 tune 2: objective=0.461795 reg=0.002574 prune=0
2017/08/29 17:10:54 tune 3: objective=0.463890 reg=0.002573 prune=0
2017/08/29 17:10:59 tune 4: objective=0.465960 reg=0.002573 prune=0
2017/08/29 17:11:04 tune 5: objective=0.467825 reg=0.002573 prune=0
2017/08/29 17:11:09 tune 6: objective=0.469590 reg=0.002573 prune=0
2017/08/29 17:11:14 tune 7: objective=0.471224 reg=0.002572 prune=0
2017/08/29 17:11:17 step 0: objective=0.472795 reg=0.002572
2017/08/29 17:11:20 step 1: objective=0.474243 reg=0.002572
2017/08/29 17:11:23 step 2: objective=0.475617 reg=0.002571
2017/08/29 17:11:27 step 3: objective=0.476839 reg=0.002571
2017/08/29 17:11:30 step 4: objective=0.478643 reg=0.002571
2017/08/29 17:11:33 step 5: objective=0.479816 reg=0.002571
2017/08/29 17:11:36 step 6: objective=0.481597 reg=0.002571
2017/08/29 17:11:39 step 7: objective=0.482648 reg=0.002571
2017/08/29 17:11:39 Training value function...
2017/08/29 17:11:43 step 0: mse=122.673546 step=0.100000
2017/08/29 17:11:44 step 1: mse=122.032068 step=0.100000
2017/08/29 17:11:46 step 2: mse=121.622223 step=0.100000
2017/08/29 17:11:48 step 3: mse=121.210287 step=0.100000
2017/08/29 17:11:50 step 4: mse=120.887032 step=0.100000
2017/08/29 17:11:51 step 5: mse=120.727472 step=0.100000
2017/08/29 17:11:53 step 6: mse=120.327763 step=0.100000
2017/08/29 17:11:55 step 7: mse=120.178492 step=0.100000
2017/08/29 17:11:55 Saving...
2017/08/29 17:11:55 Gathering batch of experience...
2017/08/29 17:12:43 batch 192: mean=389.500000 stddev=202.401485 entropy=0.256310 frames=6855 count=18
2017/08/29 17:12:43 Training policy...
2017/08/29 17:12:50 tune 0: objective=0.356503 reg=0.002563 prune=0
2017/08/29 17:12:54 tune 1: objective=0.358960 reg=0.002563 prune=0
2017/08/29 17:12:58 tune 2: objective=0.361391 reg=0.002563 prune=0
2017/08/29 17:13:02 tune 3: objective=0.363796 reg=0.002563 prune=0
2017/08/29 17:13:06 tune 4: objective=0.366178 reg=0.002563 prune=0
2017/08/29 17:13:11 tune 5: objective=0.368426 reg=0.002563 prune=0
2017/08/29 17:13:15 tune 6: objective=0.370469 reg=0.002563 prune=0
2017/08/29 17:13:19 tune 7: objective=0.372379 reg=0.002563 prune=0
2017/08/29 17:13:21 step 0: objective=0.374152 reg=0.002563
2017/08/29 17:13:24 step 1: objective=0.376285 reg=0.002564
2017/08/29 17:13:27 step 2: objective=0.378634 reg=0.002565
2017/08/29 17:13:29 step 3: objective=0.379844 reg=0.002565
2017/08/29 17:13:32 step 4: objective=0.381785 reg=0.002566
2017/08/29 17:13:35 step 5: objective=0.383190 reg=0.002566
2017/08/29 17:13:37 step 6: objective=0.384836 reg=0.002566
2017/08/29 17:13:40 step 7: objective=0.386168 reg=0.002566
2017/08/29 17:13:40 Training value function...
2017/08/29 17:13:43 step 0: mse=101.349059 step=0.100000
2017/08/29 17:13:44 step 1: mse=100.242830 step=0.100000
2017/08/29 17:13:46 step 2: mse=99.779975 step=0.100000
2017/08/29 17:13:47 step 3: mse=99.399637 step=0.100000
2017/08/29 17:13:48 step 4: mse=99.147832 step=0.100000
2017/08/29 17:13:50 step 5: mse=98.879856 step=0.100000
2017/08/29 17:13:51 step 6: mse=98.780212 step=0.100000
2017/08/29 17:13:53 step 7: mse=98.716779 step=0.100000
2017/08/29 17:13:53 Saving...
2017/08/29 17:13:53 Gathering batch of experience...
2017/08/29 17:14:43 batch 193: mean=430.250000 stddev=216.120308 entropy=0.257536 frames=7900 count=20
2017/08/29 17:14:43 Training policy...
2017/08/29 17:14:51 tune 0: objective=1.797031 reg=0.002575 prune=0
2017/08/29 17:14:56 tune 1: objective=1.798936 reg=0.002575 prune=0
2017/08/29 17:15:00 tune 2: objective=1.800833 reg=0.002576 prune=0
2017/08/29 17:15:05 tune 3: objective=1.802726 reg=0.002576 prune=0
2017/08/29 17:15:10 tune 4: objective=1.804614 reg=0.002576 prune=0
2017/08/29 17:15:15 tune 5: objective=1.806498 reg=0.002576 prune=0
2017/08/29 17:15:19 tune 6: objective=1.808318 reg=0.002576 prune=0
2017/08/29 17:15:24 tune 7: objective=1.810006 reg=0.002577 prune=0
2017/08/29 17:15:27 step 0: objective=1.811650 reg=0.002577
2017/08/29 17:15:30 step 1: objective=1.813346 reg=0.002577
2017/08/29 17:15:33 step 2: objective=1.814446 reg=0.002577
2017/08/29 17:15:36 step 3: objective=1.815384 reg=0.002577
2017/08/29 17:15:39 step 4: objective=1.816808 reg=0.002577
2017/08/29 17:15:42 step 5: objective=1.818058 reg=0.002577
2017/08/29 17:15:45 step 6: objective=1.819678 reg=0.002577
2017/08/29 17:15:48 step 7: objective=1.820804 reg=0.002577
2017/08/29 17:15:48 Training value function...
2017/08/29 17:15:52 step 0: mse=121.372302 step=0.100000
2017/08/29 17:15:53 step 1: mse=117.595499 step=0.100000
2017/08/29 17:15:55 step 2: mse=114.401126 step=0.100000
2017/08/29 17:15:57 step 3: mse=111.680426 step=0.100000
2017/08/29 17:15:58 step 4: mse=109.373061 step=0.100000
2017/08/29 17:16:00 step 5: mse=107.313381 step=0.100000
2017/08/29 17:16:02 step 6: mse=105.529082 step=0.100000
2017/08/29 17:16:03 step 7: mse=104.070788 step=0.100000
2017/08/29 17:16:03 Saving...
2017/08/29 17:16:04 Gathering batch of experience...
2017/08/29 17:16:51 batch 194: mean=302.041667 stddev=201.661945 entropy=0.251508 frames=6636 count=24
2017/08/29 17:16:51 Training policy...
2017/08/29 17:16:58 tune 0: objective=0.549975 reg=0.002515 prune=0
2017/08/29 17:17:02 tune 1: objective=0.552904 reg=0.002515 prune=0
2017/08/29 17:17:06 tune 2: objective=0.555808 reg=0.002515 prune=0
2017/08/29 17:17:10 tune 3: objective=0.558688 reg=0.002514 prune=0
2017/08/29 17:17:14 tune 4: objective=0.561547 reg=0.002514 prune=0
2017/08/29 17:17:18 tune 5: objective=0.564387 reg=0.002514 prune=0
2017/08/29 17:17:22 tune 6: objective=0.567203 reg=0.002514 prune=0
2017/08/29 17:17:26 tune 7: objective=0.569943 reg=0.002514 prune=0
2017/08/29 17:17:28 step 0: objective=0.572396 reg=0.002514
2017/08/29 17:17:31 step 1: objective=0.574388 reg=0.002513
2017/08/29 17:17:33 step 2: objective=0.576576 reg=0.002514
2017/08/29 17:17:36 step 3: objective=0.577886 reg=0.002514
2017/08/29 17:17:38 step 4: objective=0.580031 reg=0.002514
2017/08/29 17:17:41 step 5: objective=0.581276 reg=0.002514
2017/08/29 17:17:43 step 6: objective=0.582973 reg=0.002515
2017/08/29 17:17:46 step 7: objective=0.584741 reg=0.002515
2017/08/29 17:17:46 Training value function...
2017/08/29 17:17:49 step 0: mse=139.437411 step=0.100000
2017/08/29 17:17:50 step 1: mse=136.855598 step=0.100000
2017/08/29 17:17:52 step 2: mse=134.824043 step=0.100000
2017/08/29 17:17:53 step 3: mse=133.107513 step=0.100000
2017/08/29 17:17:54 step 4: mse=131.828300 step=0.100000
2017/08/29 17:17:56 step 5: mse=130.825095 step=0.100000
2017/08/29 17:17:57 step 6: mse=129.799928 step=0.100000
2017/08/29 17:17:58 step 7: mse=128.951465 step=0.100000
2017/08/29 17:17:58 Saving...
2017/08/29 17:17:59 Gathering batch of experience...
2017/08/29 17:18:47 batch 195: mean=437.055556 stddev=253.136869 entropy=0.256317 frames=7146 count=18
2017/08/29 17:18:47 Training policy...
2017/08/29 17:18:54 tune 0: objective=1.970963 reg=0.002563 prune=0
2017/08/29 17:18:59 tune 1: objective=1.972995 reg=0.002563 prune=0
2017/08/29 17:19:03 tune 2: objective=1.975016 reg=0.002563 prune=0
2017/08/29 17:19:07 tune 3: objective=1.977032 reg=0.002564 prune=0
2017/08/29 17:19:11 tune 4: objective=1.979046 reg=0.002564 prune=0
2017/08/29 17:19:16 tune 5: objective=1.981058 reg=0.002564 prune=0
2017/08/29 17:19:20 tune 6: objective=1.983021 reg=0.002564 prune=0
2017/08/29 17:19:24 tune 7: objective=1.984940 reg=0.002564 prune=0
2017/08/29 17:19:27 step 0: objective=1.986824 reg=0.002564
2017/08/29 17:19:30 step 1: objective=1.988866 reg=0.002565
2017/08/29 17:19:33 step 2: objective=1.991586 reg=0.002565
2017/08/29 17:19:35 step 3: objective=1.992867 reg=0.002565
2017/08/29 17:19:38 step 4: objective=1.995498 reg=0.002566
2017/08/29 17:19:41 step 5: objective=1.997084 reg=0.002566
2017/08/29 17:19:44 step 6: objective=1.998957 reg=0.002566
2017/08/29 17:19:46 step 7: objective=2.000632 reg=0.002566
2017/08/29 17:19:46 Training value function...
2017/08/29 17:19:49 step 0: mse=168.648963 step=0.100000
2017/08/29 17:19:51 step 1: mse=162.383028 step=0.100000
2017/08/29 17:19:52 step 2: mse=157.235649 step=0.100000
2017/08/29 17:19:54 step 3: mse=152.766824 step=0.100000
2017/08/29 17:19:55 step 4: mse=149.046299 step=0.100000
2017/08/29 17:19:57 step 5: mse=146.019049 step=0.100000
2017/08/29 17:19:58 step 6: mse=143.275345 step=0.100000
2017/08/29 17:20:00 step 7: mse=140.766326 step=0.100000
2017/08/29 17:20:00 Saving...
2017/08/29 17:20:00 Gathering batch of experience...
2017/08/29 17:20:51 batch 196: mean=342.454545 stddev=203.403032 entropy=0.252750 frames=7322 count=22
2017/08/29 17:20:51 Training policy...
2017/08/29 17:20:59 tune 0: objective=0.174887 reg=0.002528 prune=0
2017/08/29 17:21:03 tune 1: objective=0.177327 reg=0.002527 prune=0
2017/08/29 17:21:07 tune 2: objective=0.179742 reg=0.002527 prune=0
2017/08/29 17:21:12 tune 3: objective=0.182135 reg=0.002527 prune=0
2017/08/29 17:21:16 tune 4: objective=0.184506 reg=0.002527 prune=0
2017/08/29 17:21:21 tune 5: objective=0.186828 reg=0.002526 prune=0
2017/08/29 17:21:25 tune 6: objective=0.188968 reg=0.002526 prune=0
2017/08/29 17:21:29 tune 7: objective=0.190817 reg=0.002526 prune=0
2017/08/29 17:21:32 step 0: objective=0.192517 reg=0.002526
2017/08/29 17:21:35 step 1: objective=0.194965 reg=0.002526
2017/08/29 17:21:38 step 2: objective=0.196225 reg=0.002526
2017/08/29 17:21:41 step 3: objective=0.198033 reg=0.002526
2017/08/29 17:21:43 step 4: objective=0.199508 reg=0.002526
2017/08/29 17:21:46 step 5: objective=0.201522 reg=0.002525
2017/08/29 17:21:49 step 6: objective=0.202400 reg=0.002525
2017/08/29 17:21:52 step 7: objective=0.203971 reg=0.002525
2017/08/29 17:21:52 Training value function...
2017/08/29 17:21:55 step 0: mse=121.090571 step=0.100000
2017/08/29 17:21:57 step 1: mse=119.713240 step=0.100000
2017/08/29 17:21:58 step 2: mse=118.842130 step=0.100000
2017/08/29 17:22:00 step 3: mse=118.087093 step=0.100000
2017/08/29 17:22:01 step 4: mse=117.524408 step=0.100000
2017/08/29 17:22:03 step 5: mse=116.881488 step=0.100000
2017/08/29 17:22:04 step 6: mse=116.367599 step=0.100000
2017/08/29 17:22:06 step 7: mse=116.008331 step=0.100000
2017/08/29 17:22:06 Saving...
2017/08/29 17:22:06 Gathering batch of experience...
2017/08/29 17:22:59 batch 197: mean=390.619048 stddev=246.683811 entropy=0.253539 frames=7748 count=21
2017/08/29 17:22:59 Training policy...
2017/08/29 17:23:07 tune 0: objective=1.307682 reg=0.002535 prune=0
2017/08/29 17:23:12 tune 1: objective=1.309573 reg=0.002535 prune=0
2017/08/29 17:23:16 tune 2: objective=1.311434 reg=0.002535 prune=0
2017/08/29 17:23:21 tune 3: objective=1.313290 reg=0.002535 prune=0
2017/08/29 17:23:26 tune 4: objective=1.315127 reg=0.002535 prune=0
2017/08/29 17:23:30 tune 5: objective=1.316928 reg=0.002535 prune=0
2017/08/29 17:23:35 tune 6: objective=1.318625 reg=0.002534 prune=0
2017/08/29 17:23:40 tune 7: objective=1.320182 reg=0.002534 prune=0
2017/08/29 17:23:43 step 0: objective=1.321672 reg=0.002534
2017/08/29 17:23:46 step 1: objective=1.323633 reg=0.002534
2017/08/29 17:23:49 step 2: objective=1.326577 reg=0.002534
2017/08/29 17:23:52 step 3: objective=1.328260 reg=0.002534
2017/08/29 17:23:55 step 4: objective=1.329377 reg=0.002534
2017/08/29 17:23:58 step 5: objective=1.330724 reg=0.002534
2017/08/29 17:24:01 step 6: objective=1.331632 reg=0.002534
2017/08/29 17:24:04 step 7: objective=1.332649 reg=0.002534
2017/08/29 17:24:04 Training value function...
2017/08/29 17:24:07 step 0: mse=123.942573 step=0.100000
2017/08/29 17:24:08 step 1: mse=122.290945 step=0.100000
2017/08/29 17:24:10 step 2: mse=121.019399 step=0.100000
2017/08/29 17:24:12 step 3: mse=119.792395 step=0.100000
2017/08/29 17:24:13 step 4: mse=118.660037 step=0.100000
2017/08/29 17:24:15 step 5: mse=117.754694 step=0.100000
2017/08/29 17:24:17 step 6: mse=116.923882 step=0.100000
2017/08/29 17:24:18 step 7: mse=115.927855 step=0.100000
2017/08/29 17:24:18 Saving...
2017/08/29 17:24:18 Gathering batch of experience...
2017/08/29 17:25:04 batch 198: mean=391.388889 stddev=208.799515 entropy=0.252716 frames=6548 count=18
2017/08/29 17:25:04 Training policy...
2017/08/29 17:25:10 tune 0: objective=1.136023 reg=0.002527 prune=0
2017/08/29 17:25:14 tune 1: objective=1.138438 reg=0.002526 prune=0
2017/08/29 17:25:18 tune 2: objective=1.140835 reg=0.002525 prune=0
2017/08/29 17:25:22 tune 3: objective=1.143215 reg=0.002525 prune=0
2017/08/29 17:25:26 tune 4: objective=1.145579 reg=0.002524 prune=0
2017/08/29 17:25:30 tune 5: objective=1.147917 reg=0.002523 prune=0
2017/08/29 17:25:34 tune 6: objective=1.150162 reg=0.002522 prune=0
2017/08/29 17:25:38 tune 7: objective=1.152275 reg=0.002521 prune=0
2017/08/29 17:25:40 step 0: objective=1.154259 reg=0.002521
2017/08/29 17:25:43 step 1: objective=1.155741 reg=0.002520
2017/08/29 17:25:45 step 2: objective=1.158333 reg=0.002520
2017/08/29 17:25:48 step 3: objective=1.159835 reg=0.002519
2017/08/29 17:25:50 step 4: objective=1.161431 reg=0.002519
2017/08/29 17:25:53 step 5: objective=1.163034 reg=0.002519
2017/08/29 17:25:55 step 6: objective=1.165574 reg=0.002519
2017/08/29 17:25:58 step 7: objective=1.166565 reg=0.002519
2017/08/29 17:25:58 Training value function...
2017/08/29 17:26:01 step 0: mse=107.219551 step=0.100000
2017/08/29 17:26:02 step 1: mse=105.931020 step=0.100000
2017/08/29 17:26:03 step 2: mse=104.643615 step=0.100000
2017/08/29 17:26:05 step 3: mse=103.416081 step=0.100000
2017/08/29 17:26:06 step 4: mse=102.228200 step=0.100000
2017/08/29 17:26:08 step 5: mse=101.564672 step=0.100000
2017/08/29 17:26:09 step 6: mse=101.067899 step=0.100000
2017/08/29 17:26:10 step 7: mse=100.268787 step=0.100000
2017/08/29 17:26:10 Saving...
2017/08/29 17:26:10 Gathering batch of experience...
2017/08/29 17:27:01 batch 199: mean=365.739130 stddev=218.429616 entropy=0.257559 frames=7730 count=23
2017/08/29 17:27:01 Training policy...
2017/08/29 17:27:09 tune 0: objective=1.281071 reg=0.002576 prune=0
2017/08/29 17:27:14 tune 1: objective=1.283029 reg=0.002575 prune=0
2017/08/29 17:27:19 tune 2: objective=1.284974 reg=0.002574 prune=0
2017/08/29 17:27:23 tune 3: objective=1.286901 reg=0.002574 prune=0
2017/08/29 17:27:28 tune 4: objective=1.288821 reg=0.002573 prune=0
2017/08/29 17:27:33 tune 5: objective=1.290701 reg=0.002573 prune=0
2017/08/29 17:27:37 tune 6: objective=1.292485 reg=0.002572 prune=0
2017/08/29 17:27:42 tune 7: objective=1.294198 reg=0.002572 prune=0
2017/08/29 17:27:45 step 0: objective=1.295859 reg=0.002572
2017/08/29 17:27:48 step 1: objective=1.297004 reg=0.002572
2017/08/29 17:27:51 step 2: objective=1.298237 reg=0.002572
2017/08/29 17:27:54 step 3: objective=1.300278 reg=0.002572
2017/08/29 17:27:57 step 4: objective=1.301459 reg=0.002572
2017/08/29 17:28:00 step 5: objective=1.302994 reg=0.002572
2017/08/29 17:28:03 step 6: objective=1.304257 reg=0.002572
2017/08/29 17:28:06 step 7: objective=1.305199 reg=0.002572
2017/08/29 17:28:06 Training value function...
2017/08/29 17:28:09 step 0: mse=137.760476 step=0.100000
2017/08/29 17:28:11 step 1: mse=136.190389 step=0.100000
2017/08/29 17:28:12 step 2: mse=134.846123 step=0.100000
2017/08/29 17:28:14 step 3: mse=134.007128 step=0.100000
2017/08/29 17:28:16 step 4: mse=133.103784 step=0.100000
2017/08/29 17:28:17 step 5: mse=132.010222 step=0.100000
2017/08/29 17:28:19 step 6: mse=131.301867 step=0.100000
2017/08/29 17:28:20 step 7: mse=130.740476 step=0.100000
2017/08/29 17:28:20 Saving...
2017/08/29 17:28:21 Gathering batch of experience...
2017/08/29 17:29:05 batch 200: mean=376.666667 stddev=220.550322 entropy=0.257846 frames=6598 count=18
2017/08/29 17:29:05 Training policy...
2017/08/29 17:29:12 tune 0: objective=0.418332 reg=0.002578 prune=0
2017/08/29 17:29:16 tune 1: objective=0.420660 reg=0.002578 prune=0
2017/08/29 17:29:20 tune 2: objective=0.422973 reg=0.002578 prune=0
2017/08/29 17:29:24 tune 3: objective=0.425276 reg=0.002578 prune=0
2017/08/29 17:29:28 tune 4: objective=0.427567 reg=0.002577 prune=0
2017/08/29 17:29:32 tune 5: objective=0.429787 reg=0.002577 prune=0
2017/08/29 17:29:36 tune 6: objective=0.431921 reg=0.002577 prune=0
2017/08/29 17:29:40 tune 7: objective=0.433909 reg=0.002577 prune=0
2017/08/29 17:29:42 step 0: objective=0.435724 reg=0.002576
2017/08/29 17:29:45 step 1: objective=0.438391 reg=0.002576
2017/08/29 17:29:47 step 2: objective=0.439958 reg=0.002576
2017/08/29 17:29:50 step 3: objective=0.441389 reg=0.002576
2017/08/29 17:29:52 step 4: objective=0.442850 reg=0.002576
2017/08/29 17:29:55 step 5: objective=0.443963 reg=0.002576
2017/08/29 17:29:58 step 6: objective=0.445156 reg=0.002576
2017/08/29 17:30:00 step 7: objective=0.446571 reg=0.002576
2017/08/29 17:30:00 Training value function...
2017/08/29 17:30:03 step 0: mse=109.248169 step=0.100000
2017/08/29 17:30:04 step 1: mse=107.554862 step=0.100000
2017/08/29 17:30:06 step 2: mse=105.922046 step=0.100000
2017/08/29 17:30:07 step 3: mse=104.833582 step=0.100000
2017/08/29 17:30:08 step 4: mse=103.671059 step=0.100000
2017/08/29 17:30:10 step 5: mse=102.895199 step=0.100000
2017/08/29 17:30:11 step 6: mse=102.015478 step=0.100000
2017/08/29 17:30:13 step 7: mse=101.481431 step=0.100000
2017/08/29 17:30:13 Saving...
2017/08/29 17:30:13 Gathering batch of experience...
2017/08/29 17:31:05 batch 201: mean=380.904762 stddev=200.675978 entropy=0.250106 frames=7559 count=21
2017/08/29 17:31:05 Training policy...
2017/08/29 17:31:13 tune 0: objective=0.922794 reg=0.002501 prune=0
2017/08/29 17:31:17 tune 1: objective=0.924957 reg=0.002501 prune=0
2017/08/29 17:31:22 tune 2: objective=0.927095 reg=0.002500 prune=0
2017/08/29 17:31:26 tune 3: objective=0.929213 reg=0.002500 prune=0
2017/08/29 17:31:31 tune 4: objective=0.931303 reg=0.002500 prune=0
2017/08/29 17:31:36 tune 5: objective=0.933254 reg=0.002500 prune=0
2017/08/29 17:31:40 tune 6: objective=0.935091 reg=0.002499 prune=0
2017/08/29 17:31:45 tune 7: objective=0.936782 reg=0.002499 prune=0
2017/08/29 17:31:48 step 0: objective=0.938215 reg=0.002499
2017/08/29 17:31:51 step 1: objective=0.940822 reg=0.002498
2017/08/29 17:31:54 step 2: objective=0.943235 reg=0.002497
2017/08/29 17:31:57 step 3: objective=0.944264 reg=0.002497
2017/08/29 17:31:59 step 4: objective=0.946425 reg=0.002497
2017/08/29 17:32:02 step 5: objective=0.947850 reg=0.002498
2017/08/29 17:32:05 step 6: objective=0.949173 reg=0.002497
2017/08/29 17:32:08 step 7: objective=0.950476 reg=0.002496
2017/08/29 17:32:08 Training value function...
2017/08/29 17:32:11 step 0: mse=136.227452 step=0.100000
2017/08/29 17:32:13 step 1: mse=132.297842 step=0.100000
2017/08/29 17:32:15 step 2: mse=129.483354 step=0.100000
2017/08/29 17:32:16 step 3: mse=127.226269 step=0.100000
2017/08/29 17:32:18 step 4: mse=125.197190 step=0.100000
2017/08/29 17:32:19 step 5: mse=123.722919 step=0.100000
2017/08/29 17:32:21 step 6: mse=122.363333 step=0.100000
2017/08/29 17:32:23 step 7: mse=121.081731 step=0.100000
2017/08/29 17:32:23 Saving...
2017/08/29 17:32:23 Gathering batch of experience...
2017/08/29 17:33:10 batch 202: mean=436.647059 stddev=234.530806 entropy=0.253653 frames=6552 count=17
2017/08/29 17:33:10 Training policy...
2017/08/29 17:33:16 tune 0: objective=2.223627 reg=0.002537 prune=0
2017/08/29 17:33:20 tune 1: objective=2.226357 reg=0.002537 prune=0
2017/08/29 17:33:24 tune 2: objective=2.229076 reg=0.002537 prune=0
2017/08/29 17:33:28 tune 3: objective=2.231782 reg=0.002537 prune=0
2017/08/29 17:33:32 tune 4: objective=2.234484 reg=0.002537 prune=0
2017/08/29 17:33:36 tune 5: objective=2.236952 reg=0.002537 prune=0
2017/08/29 17:33:40 tune 6: objective=2.239157 reg=0.002537 prune=0
2017/08/29 17:33:44 tune 7: objective=2.241036 reg=0.002537 prune=0
2017/08/29 17:33:47 step 0: objective=2.242843 reg=0.002537
2017/08/29 17:33:49 step 1: objective=2.245883 reg=0.002536
2017/08/29 17:33:52 step 2: objective=2.248756 reg=0.002536
2017/08/29 17:33:54 step 3: objective=2.249971 reg=0.002536
2017/08/29 17:33:57 step 4: objective=2.252093 reg=0.002536
2017/08/29 17:33:59 step 5: objective=2.253543 reg=0.002535
2017/08/29 17:34:02 step 6: objective=2.255056 reg=0.002536
2017/08/29 17:34:04 step 7: objective=2.256555 reg=0.002535
2017/08/29 17:34:04 Training value function...
2017/08/29 17:34:07 step 0: mse=157.781287 step=0.100000
2017/08/29 17:34:08 step 1: mse=152.360371 step=0.100000
2017/08/29 17:34:10 step 2: mse=147.596016 step=0.100000
2017/08/29 17:34:11 step 3: mse=143.894218 step=0.100000
2017/08/29 17:34:13 step 4: mse=140.381955 step=0.100000
2017/08/29 17:34:14 step 5: mse=136.959772 step=0.100000
2017/08/29 17:34:15 step 6: mse=134.418293 step=0.100000
2017/08/29 17:34:17 step 7: mse=132.187862 step=0.100000
2017/08/29 17:34:17 Saving...
2017/08/29 17:34:17 Gathering batch of experience...
2017/08/29 17:35:07 batch 203: mean=372.200000 stddev=206.225265 entropy=0.246927 frames=7164 count=20
2017/08/29 17:35:07 Training policy...
2017/08/29 17:35:14 tune 0: objective=0.243579 reg=0.002469 prune=0
2017/08/29 17:35:19 tune 1: objective=0.245936 reg=0.002469 prune=0
2017/08/29 17:35:23 tune 2: objective=0.248268 reg=0.002469 prune=0
2017/08/29 17:35:27 tune 3: objective=0.250578 reg=0.002469 prune=0
2017/08/29 17:35:32 tune 4: objective=0.252815 reg=0.002469 prune=0
2017/08/29 17:35:36 tune 5: objective=0.254889 reg=0.002469 prune=0
2017/08/29 17:35:40 tune 6: objective=0.256857 reg=0.002470 prune=0
2017/08/29 17:35:45 tune 7: objective=0.258683 reg=0.002470 prune=0
2017/08/29 17:35:48 step 0: objective=0.260365 reg=0.002470
2017/08/29 17:35:50 step 1: objective=0.262803 reg=0.002471
2017/08/29 17:35:53 step 2: objective=0.265124 reg=0.002471
2017/08/29 17:35:56 step 3: objective=0.266715 reg=0.002472
2017/08/29 17:35:59 step 4: objective=0.268406 reg=0.002472
2017/08/29 17:36:01 step 5: objective=0.270077 reg=0.002472
2017/08/29 17:36:04 step 6: objective=0.271852 reg=0.002472
2017/08/29 17:36:07 step 7: objective=0.273092 reg=0.002472
2017/08/29 17:36:07 Training value function...
2017/08/29 17:36:10 step 0: mse=128.185550 step=0.100000
2017/08/29 17:36:11 step 1: mse=126.781919 step=0.100000
2017/08/29 17:36:13 step 2: mse=125.514809 step=0.100000
2017/08/29 17:36:14 step 3: mse=124.577184 step=0.100000
2017/08/29 17:36:16 step 4: mse=123.804159 step=0.100000
2017/08/29 17:36:17 step 5: mse=123.016942 step=0.100000
2017/08/29 17:36:19 step 6: mse=122.563722 step=0.100000
2017/08/29 17:36:20 step 7: mse=122.028954 step=0.100000
2017/08/29 17:36:20 Saving...
2017/08/29 17:36:21 Gathering batch of experience...
2017/08/29 17:37:12 batch 204: mean=380.952381 stddev=218.305918 entropy=0.251358 frames=7381 count=21
2017/08/29 17:37:12 Training policy...
2017/08/29 17:37:19 tune 0: objective=1.330826 reg=0.002514 prune=0
2017/08/29 17:37:24 tune 1: objective=1.332887 reg=0.002513 prune=0
2017/08/29 17:37:28 tune 2: objective=1.334935 reg=0.002513 prune=0
2017/08/29 17:37:33 tune 3: objective=1.336983 reg=0.002513 prune=0
2017/08/29 17:37:37 tune 4: objective=1.339022 reg=0.002513 prune=0
2017/08/29 17:37:42 tune 5: objective=1.341065 reg=0.002513 prune=0
2017/08/29 17:37:46 tune 6: objective=1.343018 reg=0.002513 prune=0
2017/08/29 17:37:51 tune 7: objective=1.344970 reg=0.002513 prune=0
2017/08/29 17:37:53 step 0: objective=1.346877 reg=0.002513
2017/08/29 17:37:56 step 1: objective=1.348890 reg=0.002512
2017/08/29 17:37:59 step 2: objective=1.350530 reg=0.002512
2017/08/29 17:38:02 step 3: objective=1.353152 reg=0.002511
2017/08/29 17:38:05 step 4: objective=1.355507 reg=0.002511
2017/08/29 17:38:08 step 5: objective=1.357254 reg=0.002509
2017/08/29 17:38:11 step 6: objective=1.359589 reg=0.002509
2017/08/29 17:38:14 step 7: objective=1.361497 reg=0.002509
2017/08/29 17:38:14 Training value function...
2017/08/29 17:38:17 step 0: mse=135.020634 step=0.100000
2017/08/29 17:38:18 step 1: mse=133.246948 step=0.100000
2017/08/29 17:38:20 step 2: mse=131.386342 step=0.100000
2017/08/29 17:38:21 step 3: mse=129.688689 step=0.100000
2017/08/29 17:38:23 step 4: mse=128.248680 step=0.100000
2017/08/29 17:38:24 step 5: mse=126.932626 step=0.100000
2017/08/29 17:38:26 step 6: mse=125.716921 step=0.100000
2017/08/29 17:38:27 step 7: mse=124.693149 step=0.100000
2017/08/29 17:38:27 Saving...
2017/08/29 17:38:28 Gathering batch of experience...
2017/08/29 17:39:14 batch 205: mean=391.388889 stddev=234.943525 entropy=0.251821 frames=6766 count=18
2017/08/29 17:39:14 Training policy...
2017/08/29 17:39:21 tune 0: objective=0.777561 reg=0.002518 prune=0
2017/08/29 17:39:25 tune 1: objective=0.779731 reg=0.002518 prune=0
2017/08/29 17:39:29 tune 2: objective=0.781882 reg=0.002519 prune=0
2017/08/29 17:39:34 tune 3: objective=0.784011 reg=0.002519 prune=0
2017/08/29 17:39:38 tune 4: objective=0.786118 reg=0.002519 prune=0
2017/08/29 17:39:42 tune 5: objective=0.788072 reg=0.002520 prune=0
2017/08/29 17:39:46 tune 6: objective=0.789902 reg=0.002520 prune=0
2017/08/29 17:39:50 tune 7: objective=0.791484 reg=0.002520 prune=0
2017/08/29 17:39:53 step 0: objective=0.793001 reg=0.002520
2017/08/29 17:39:55 step 1: objective=0.795785 reg=0.002522
2017/08/29 17:39:58 step 2: objective=0.796955 reg=0.002522
2017/08/29 17:40:00 step 3: objective=0.798032 reg=0.002522
2017/08/29 17:40:03 step 4: objective=0.799383 reg=0.002522
2017/08/29 17:40:06 step 5: objective=0.800572 reg=0.002523
2017/08/29 17:40:08 step 6: objective=0.801845 reg=0.002524
2017/08/29 17:40:11 step 7: objective=0.802961 reg=0.002524
2017/08/29 17:40:11 Training value function...
2017/08/29 17:40:14 step 0: mse=135.838241 step=0.100000
2017/08/29 17:40:15 step 1: mse=133.510423 step=0.100000
2017/08/29 17:40:17 step 2: mse=131.296879 step=0.100000
2017/08/29 17:40:18 step 3: mse=129.417366 step=0.100000
2017/08/29 17:40:20 step 4: mse=127.855326 step=0.100000
2017/08/29 17:40:21 step 5: mse=126.698459 step=0.100000
2017/08/29 17:40:22 step 6: mse=125.688873 step=0.100000
2017/08/29 17:40:24 step 7: mse=124.760302 step=0.100000
2017/08/29 17:40:24 Saving...
2017/08/29 17:40:24 Gathering batch of experience...
2017/08/29 17:41:13 batch 206: mean=344.173913 stddev=193.103859 entropy=0.255437 frames=7339 count=23
2017/08/29 17:41:13 Training policy...
2017/08/29 17:41:21 tune 0: objective=1.043768 reg=0.002554 prune=0
2017/08/29 17:41:25 tune 1: objective=1.046471 reg=0.002554 prune=0
2017/08/29 17:41:30 tune 2: objective=1.049137 reg=0.002554 prune=0
2017/08/29 17:41:34 tune 3: objective=1.051761 reg=0.002553 prune=0
2017/08/29 17:41:39 tune 4: objective=1.054146 reg=0.002553 prune=0
2017/08/29 17:41:43 tune 5: objective=1.056471 reg=0.002553 prune=0
2017/08/29 17:41:47 tune 6: objective=1.058644 reg=0.002552 prune=0
2017/08/29 17:41:52 tune 7: objective=1.060585 reg=0.002552 prune=0
2017/08/29 17:41:55 step 0: objective=1.062445 reg=0.002552
2017/08/29 17:41:58 step 1: objective=1.065524 reg=0.002550
2017/08/29 17:42:01 step 2: objective=1.067576 reg=0.002551
2017/08/29 17:42:03 step 3: objective=1.069111 reg=0.002550
2017/08/29 17:42:06 step 4: objective=1.071536 reg=0.002550
2017/08/29 17:42:09 step 5: objective=1.072500 reg=0.002550
2017/08/29 17:42:12 step 6: objective=1.073554 reg=0.002550
2017/08/29 17:42:15 step 7: objective=1.074465 reg=0.002550
2017/08/29 17:42:15 Training value function...
2017/08/29 17:42:18 step 0: mse=137.637772 step=0.100000
2017/08/29 17:42:19 step 1: mse=135.804628 step=0.100000
2017/08/29 17:42:21 step 2: mse=134.249021 step=0.100000
2017/08/29 17:42:23 step 3: mse=132.703832 step=0.100000
2017/08/29 17:42:24 step 4: mse=131.377551 step=0.100000
2017/08/29 17:42:26 step 5: mse=130.289214 step=0.100000
2017/08/29 17:42:27 step 6: mse=129.412498 step=0.100000
2017/08/29 17:42:29 step 7: mse=128.646384 step=0.100000
2017/08/29 17:42:29 Saving...
2017/08/29 17:42:29 Gathering batch of experience...
2017/08/29 17:43:17 batch 207: mean=431.315789 stddev=234.850244 entropy=0.248927 frames=7661 count=19
2017/08/29 17:43:17 Training policy...
2017/08/29 17:43:25 tune 0: objective=1.402219 reg=0.002489 prune=0
2017/08/29 17:43:29 tune 1: objective=1.403773 reg=0.002489 prune=0
2017/08/29 17:43:34 tune 2: objective=1.405316 reg=0.002489 prune=0
2017/08/29 17:43:39 tune 3: objective=1.406861 reg=0.002489 prune=0
2017/08/29 17:43:43 tune 4: objective=1.408396 reg=0.002489 prune=0
2017/08/29 17:43:48 tune 5: objective=1.409939 reg=0.002489 prune=0
2017/08/29 17:43:53 tune 6: objective=1.411467 reg=0.002489 prune=0
2017/08/29 17:43:57 tune 7: objective=1.412895 reg=0.002490 prune=0
2017/08/29 17:44:00 step 0: objective=1.414293 reg=0.002489
2017/08/29 17:44:03 step 1: objective=1.416115 reg=0.002490
2017/08/29 17:44:06 step 2: objective=1.417523 reg=0.002490
2017/08/29 17:44:09 step 3: objective=1.418707 reg=0.002491
2017/08/29 17:44:12 step 4: objective=1.419762 reg=0.002490
2017/08/29 17:44:15 step 5: objective=1.420872 reg=0.002489
2017/08/29 17:44:18 step 6: objective=1.422403 reg=0.002489
2017/08/29 17:44:21 step 7: objective=1.423660 reg=0.002488
2017/08/29 17:44:21 Training value function...
2017/08/29 17:44:24 step 0: mse=128.924314 step=0.100000
2017/08/29 17:44:26 step 1: mse=126.643474 step=0.100000
2017/08/29 17:44:28 step 2: mse=124.792648 step=0.100000
2017/08/29 17:44:29 step 3: mse=123.147216 step=0.100000
2017/08/29 17:44:31 step 4: mse=121.783469 step=0.100000
2017/08/29 17:44:33 step 5: mse=120.580327 step=0.100000
2017/08/29 17:44:34 step 6: mse=119.594317 step=0.100000
2017/08/29 17:44:36 step 7: mse=118.471556 step=0.100000
2017/08/29 17:44:36 Saving...
2017/08/29 17:44:36 Gathering batch of experience...
2017/08/29 17:45:28 batch 208: mean=447.789474 stddev=145.321994 entropy=0.251437 frames=8011 count=19
2017/08/29 17:45:28 Training policy...
2017/08/29 17:45:36 tune 0: objective=1.002126 reg=0.002514 prune=0
2017/08/29 17:45:41 tune 1: objective=1.004149 reg=0.002514 prune=0
2017/08/29 17:45:46 tune 2: objective=1.006161 reg=0.002513 prune=0
2017/08/29 17:45:51 tune 3: objective=1.008155 reg=0.002512 prune=0
2017/08/29 17:45:56 tune 4: objective=1.010139 reg=0.002512 prune=0
2017/08/29 17:46:00 tune 5: objective=1.012100 reg=0.002511 prune=0
2017/08/29 17:46:05 tune 6: objective=1.013920 reg=0.002510 prune=0
2017/08/29 17:46:10 tune 7: objective=1.015584 reg=0.002510 prune=0
2017/08/29 17:46:13 step 0: objective=1.017129 reg=0.002509
2017/08/29 17:46:17 step 1: objective=1.018491 reg=0.002509
2017/08/29 17:46:20 step 2: objective=1.020633 reg=0.002508
2017/08/29 17:46:23 step 3: objective=1.022429 reg=0.002508
2017/08/29 17:46:26 step 4: objective=1.023711 reg=0.002507
2017/08/29 17:46:29 step 5: objective=1.024769 reg=0.002507
2017/08/29 17:46:32 step 6: objective=1.026171 reg=0.002506
2017/08/29 17:46:35 step 7: objective=1.027447 reg=0.002505
2017/08/29 17:46:35 Training value function...
2017/08/29 17:46:39 step 0: mse=116.887714 step=0.100000
2017/08/29 17:46:40 step 1: mse=114.999009 step=0.100000
2017/08/29 17:46:42 step 2: mse=112.930781 step=0.100000
2017/08/29 17:46:44 step 3: mse=111.370780 step=0.100000
2017/08/29 17:46:45 step 4: mse=110.087916 step=0.100000
2017/08/29 17:46:47 step 5: mse=109.189372 step=0.100000
2017/08/29 17:46:49 step 6: mse=108.352241 step=0.100000
2017/08/29 17:46:50 step 7: mse=107.465252 step=0.100000
2017/08/29 17:46:50 Saving...
2017/08/29 17:46:51 Gathering batch of experience...
2017/08/29 17:47:44 batch 209: mean=401.523810 stddev=186.822967 entropy=0.252708 frames=7927 count=21
2017/08/29 17:47:44 Training policy...
2017/08/29 17:47:53 tune 0: objective=0.992757 reg=0.002527 prune=0
2017/08/29 17:47:57 tune 1: objective=0.995147 reg=0.002527 prune=0
2017/08/29 17:48:02 tune 2: objective=0.997506 reg=0.002527 prune=0
2017/08/29 17:48:07 tune 3: objective=0.999844 reg=0.002527 prune=0
2017/08/29 17:48:12 tune 4: objective=1.002137 reg=0.002526 prune=0
2017/08/29 17:48:17 tune 5: objective=1.004303 reg=0.002526 prune=0
2017/08/29 17:48:22 tune 6: objective=1.006404 reg=0.002526 prune=0
2017/08/29 17:48:26 tune 7: objective=1.008288 reg=0.002526 prune=0
2017/08/29 17:48:29 step 0: objective=1.009983 reg=0.002526
2017/08/29 17:48:33 step 1: objective=1.011350 reg=0.002525
2017/08/29 17:48:36 step 2: objective=1.012936 reg=0.002525
2017/08/29 17:48:39 step 3: objective=1.014482 reg=0.002525
2017/08/29 17:48:42 step 4: objective=1.016128 reg=0.002525
2017/08/29 17:48:45 step 5: objective=1.017544 reg=0.002525
2017/08/29 17:48:48 step 6: objective=1.018775 reg=0.002524
2017/08/29 17:48:51 step 7: objective=1.019708 reg=0.002524
2017/08/29 17:48:51 Training value function...
2017/08/29 17:48:54 step 0: mse=122.808070 step=0.100000
2017/08/29 17:48:56 step 1: mse=121.612038 step=0.100000
2017/08/29 17:48:58 step 2: mse=120.369505 step=0.100000
2017/08/29 17:48:59 step 3: mse=119.576912 step=0.100000
2017/08/29 17:49:01 step 4: mse=118.625646 step=0.100000
2017/08/29 17:49:03 step 5: mse=118.107941 step=0.100000
2017/08/29 17:49:04 step 6: mse=117.558382 step=0.100000
2017/08/29 17:49:06 step 7: mse=117.139869 step=0.100000
2017/08/29 17:49:06 Saving...
2017/08/29 17:49:06 Gathering batch of experience...
2017/08/29 17:49:56 batch 210: mean=464.500000 stddev=189.865815 entropy=0.257951 frames=7832 count=18
2017/08/29 17:49:56 Training policy...
2017/08/29 17:50:05 tune 0: objective=1.326617 reg=0.002580 prune=0
2017/08/29 17:50:09 tune 1: objective=1.328432 reg=0.002579 prune=0
2017/08/29 17:50:14 tune 2: objective=1.330231 reg=0.002579 prune=0
2017/08/29 17:50:19 tune 3: objective=1.332025 reg=0.002578 prune=0
2017/08/29 17:50:24 tune 4: objective=1.333811 reg=0.002578 prune=0
2017/08/29 17:50:28 tune 5: objective=1.335578 reg=0.002577 prune=0
2017/08/29 17:50:33 tune 6: objective=1.337260 reg=0.002577 prune=0
2017/08/29 17:50:38 tune 7: objective=1.338937 reg=0.002577 prune=0
2017/08/29 17:50:41 step 0: objective=1.340559 reg=0.002576
2017/08/29 17:50:44 step 1: objective=1.342668 reg=0.002576
2017/08/29 17:50:47 step 2: objective=1.344586 reg=0.002577
2017/08/29 17:50:50 step 3: objective=1.346657 reg=0.002576
2017/08/29 17:50:53 step 4: objective=1.347955 reg=0.002576
2017/08/29 17:50:56 step 5: objective=1.349849 reg=0.002577
2017/08/29 17:50:59 step 6: objective=1.350715 reg=0.002576
2017/08/29 17:51:03 step 7: objective=1.351761 reg=0.002576
2017/08/29 17:51:03 Training value function...
2017/08/29 17:51:06 step 0: mse=129.613877 step=0.100000
2017/08/29 17:51:07 step 1: mse=127.922454 step=0.100000
2017/08/29 17:51:09 step 2: mse=126.497718 step=0.100000
2017/08/29 17:51:11 step 3: mse=125.311553 step=0.100000
2017/08/29 17:51:12 step 4: mse=123.985184 step=0.100000
2017/08/29 17:51:14 step 5: mse=123.066799 step=0.100000
2017/08/29 17:51:16 step 6: mse=122.028875 step=0.100000
2017/08/29 17:51:17 step 7: mse=121.097703 step=0.100000
2017/08/29 17:51:17 Saving...
2017/08/29 17:51:17 Gathering batch of experience...
2017/08/29 17:52:05 batch 211: mean=371.631579 stddev=238.969104 entropy=0.254442 frames=6732 count=19
2017/08/29 17:52:05 Training policy...
2017/08/29 17:52:12 tune 0: objective=0.869432 reg=0.002544 prune=0
2017/08/29 17:52:16 tune 1: objective=0.871491 reg=0.002545 prune=0
2017/08/29 17:52:20 tune 2: objective=0.873544 reg=0.002545 prune=0
2017/08/29 17:52:24 tune 3: objective=0.875587 reg=0.002545 prune=0
2017/08/29 17:52:28 tune 4: objective=0.877620 reg=0.002545 prune=0
2017/08/29 17:52:32 tune 5: objective=0.879595 reg=0.002546 prune=0
2017/08/29 17:52:36 tune 6: objective=0.881488 reg=0.002546 prune=0
2017/08/29 17:52:40 tune 7: objective=0.883318 reg=0.002546 prune=0
2017/08/29 17:52:43 step 0: objective=0.885083 reg=0.002546
2017/08/29 17:52:46 step 1: objective=0.887388 reg=0.002546
2017/08/29 17:52:48 step 2: objective=0.888803 reg=0.002547
2017/08/29 17:52:51 step 3: objective=0.890785 reg=0.002546
2017/08/29 17:52:53 step 4: objective=0.892041 reg=0.002546
2017/08/29 17:52:56 step 5: objective=0.893344 reg=0.002546
2017/08/29 17:52:59 step 6: objective=0.895470 reg=0.002546
2017/08/29 17:53:01 step 7: objective=0.896225 reg=0.002546
2017/08/29 17:53:01 Training value function...
2017/08/29 17:53:04 step 0: mse=122.414621 step=0.100000
2017/08/29 17:53:06 step 1: mse=121.317309 step=0.100000
2017/08/29 17:53:07 step 2: mse=119.764617 step=0.100000
2017/08/29 17:53:08 step 3: mse=118.552455 step=0.100000
2017/08/29 17:53:10 step 4: mse=117.490927 step=0.100000
2017/08/29 17:53:11 step 5: mse=116.868804 step=0.100000
2017/08/29 17:53:13 step 6: mse=116.139028 step=0.100000
2017/08/29 17:53:14 step 7: mse=115.587655 step=0.100000
2017/08/29 17:53:14 Saving...
2017/08/29 17:53:14 Gathering batch of experience...
2017/08/29 17:54:04 batch 212: mean=309.960000 stddev=224.539080 entropy=0.252546 frames=7049 count=25
2017/08/29 17:54:04 Training policy...
2017/08/29 17:54:11 tune 0: objective=1.143542 reg=0.002525 prune=0
2017/08/29 17:54:15 tune 1: objective=1.146307 reg=0.002525 prune=0
2017/08/29 17:54:20 tune 2: objective=1.149040 reg=0.002525 prune=0
2017/08/29 17:54:24 tune 3: objective=1.151753 reg=0.002525 prune=0
2017/08/29 17:54:28 tune 4: objective=1.154438 reg=0.002525 prune=0
2017/08/29 17:54:32 tune 5: objective=1.157070 reg=0.002525 prune=0
2017/08/29 17:54:37 tune 6: objective=1.159485 reg=0.002525 prune=0
2017/08/29 17:54:41 tune 7: objective=1.161668 reg=0.002525 prune=0
2017/08/29 17:54:44 step 0: objective=1.163641 reg=0.002525
2017/08/29 17:54:47 step 1: objective=1.165541 reg=0.002525
2017/08/29 17:54:49 step 2: objective=1.167068 reg=0.002525
2017/08/29 17:54:52 step 3: objective=1.169876 reg=0.002524
2017/08/29 17:54:55 step 4: objective=1.171460 reg=0.002524
2017/08/29 17:54:58 step 5: objective=1.173432 reg=0.002524
2017/08/29 17:55:00 step 6: objective=1.174571 reg=0.002525
2017/08/29 17:55:03 step 7: objective=1.175706 reg=0.002525
2017/08/29 17:55:03 Training value function...
2017/08/29 17:55:06 step 0: mse=136.095594 step=0.100000
2017/08/29 17:55:08 step 1: mse=134.598346 step=0.100000
2017/08/29 17:55:09 step 2: mse=133.224521 step=0.100000
2017/08/29 17:55:10 step 3: mse=132.035424 step=0.100000
2017/08/29 17:55:12 step 4: mse=130.802221 step=0.100000
2017/08/29 17:55:13 step 5: mse=129.640471 step=0.100000
2017/08/29 17:55:15 step 6: mse=128.738707 step=0.100000
2017/08/29 17:55:16 step 7: mse=127.956996 step=0.100000
2017/08/29 17:55:16 Saving...
2017/08/29 17:55:17 Gathering batch of experience...
2017/08/29 17:56:07 batch 213: mean=438.789474 stddev=202.277188 entropy=0.251144 frames=7577 count=19
2017/08/29 17:56:07 Training policy...
2017/08/29 17:56:15 tune 0: objective=1.620820 reg=0.002511 prune=0
2017/08/29 17:56:19 tune 1: objective=1.622771 reg=0.002512 prune=0
2017/08/29 17:56:24 tune 2: objective=1.624713 reg=0.002512 prune=0
2017/08/29 17:56:29 tune 3: objective=1.626650 reg=0.002512 prune=0
2017/08/29 17:56:33 tune 4: objective=1.628578 reg=0.002512 prune=0
2017/08/29 17:56:38 tune 5: objective=1.630497 reg=0.002512 prune=0
2017/08/29 17:56:42 tune 6: objective=1.632415 reg=0.002512 prune=0
2017/08/29 17:56:47 tune 7: objective=1.634254 reg=0.002512 prune=0
2017/08/29 17:56:50 step 0: objective=1.635974 reg=0.002513
2017/08/29 17:56:53 step 1: objective=1.638393 reg=0.002513
2017/08/29 17:56:56 step 2: objective=1.639934 reg=0.002513
2017/08/29 17:56:59 step 3: objective=1.641777 reg=0.002513
2017/08/29 17:57:02 step 4: objective=1.643176 reg=0.002513
2017/08/29 17:57:05 step 5: objective=1.644165 reg=0.002513
2017/08/29 17:57:08 step 6: objective=1.645751 reg=0.002512
2017/08/29 17:57:11 step 7: objective=1.646679 reg=0.002513
2017/08/29 17:57:11 Training value function...
2017/08/29 17:57:14 step 0: mse=121.510169 step=0.100000
2017/08/29 17:57:16 step 1: mse=119.389284 step=0.100000
2017/08/29 17:57:17 step 2: mse=117.278251 step=0.100000
2017/08/29 17:57:19 step 3: mse=115.647445 step=0.100000
2017/08/29 17:57:20 step 4: mse=114.270235 step=0.100000
2017/08/29 17:57:22 step 5: mse=113.137174 step=0.100000
2017/08/29 17:57:24 step 6: mse=112.074988 step=0.100000
2017/08/29 17:57:25 step 7: mse=110.952557 step=0.100000
2017/08/29 17:57:25 Saving...
2017/08/29 17:57:25 Gathering batch of experience...
2017/08/29 17:58:12 batch 214: mean=317.476190 stddev=290.436555 entropy=0.256203 frames=6147 count=21
2017/08/29 17:58:12 Training policy...
2017/08/29 17:58:18 tune 0: objective=0.994516 reg=0.002562 prune=0
2017/08/29 17:58:22 tune 1: objective=0.997644 reg=0.002562 prune=0
2017/08/29 17:58:25 tune 2: objective=1.000745 reg=0.002562 prune=0
2017/08/29 17:58:29 tune 3: objective=1.003818 reg=0.002563 prune=0
2017/08/29 17:58:33 tune 4: objective=1.006739 reg=0.002563 prune=0
2017/08/29 17:58:37 tune 5: objective=1.009392 reg=0.002563 prune=0
2017/08/29 17:58:40 tune 6: objective=1.011906 reg=0.002563 prune=0
2017/08/29 17:58:44 tune 7: objective=1.014362 reg=0.002563 prune=0
2017/08/29 17:58:46 step 0: objective=1.016605 reg=0.002563
2017/08/29 17:58:49 step 1: objective=1.019675 reg=0.002563
2017/08/29 17:58:51 step 2: objective=1.021499 reg=0.002564
2017/08/29 17:58:54 step 3: objective=1.023407 reg=0.002565
2017/08/29 17:58:56 step 4: objective=1.025570 reg=0.002564
2017/08/29 17:58:58 step 5: objective=1.026802 reg=0.002565
2017/08/29 17:59:01 step 6: objective=1.028637 reg=0.002564
2017/08/29 17:59:03 step 7: objective=1.030038 reg=0.002565
2017/08/29 17:59:03 Training value function...
2017/08/29 17:59:06 step 0: mse=163.229713 step=0.100000
2017/08/29 17:59:07 step 1: mse=158.378470 step=0.100000
2017/08/29 17:59:08 step 2: mse=154.518335 step=0.100000
2017/08/29 17:59:10 step 3: mse=151.256496 step=0.100000
2017/08/29 17:59:11 step 4: mse=148.397426 step=0.100000
2017/08/29 17:59:12 step 5: mse=146.017633 step=0.100000
2017/08/29 17:59:14 step 6: mse=144.042070 step=0.100000
2017/08/29 17:59:15 step 7: mse=142.392614 step=0.100000
2017/08/29 17:59:15 Saving...
2017/08/29 17:59:15 Gathering batch of experience...
2017/08/29 18:00:12 batch 215: mean=431.227273 stddev=247.853133 entropy=0.251981 frames=8544 count=22
2017/08/29 18:00:12 Training policy...
2017/08/29 18:00:21 tune 0: objective=1.500820 reg=0.002520 prune=0
2017/08/29 18:00:26 tune 1: objective=1.502854 reg=0.002520 prune=0
2017/08/29 18:00:32 tune 2: objective=1.504867 reg=0.002519 prune=0
2017/08/29 18:00:37 tune 3: objective=1.506872 reg=0.002519 prune=0
2017/08/29 18:00:42 tune 4: objective=1.508854 reg=0.002519 prune=0
2017/08/29 18:00:47 tune 5: objective=1.510803 reg=0.002519 prune=0
2017/08/29 18:00:53 tune 6: objective=1.512623 reg=0.002518 prune=0
2017/08/29 18:00:58 tune 7: objective=1.514365 reg=0.002518 prune=0
2017/08/29 18:01:01 step 0: objective=1.516017 reg=0.002518
2017/08/29 18:01:05 step 1: objective=1.518676 reg=0.002517
2017/08/29 18:01:08 step 2: objective=1.520362 reg=0.002516
2017/08/29 18:01:11 step 3: objective=1.521937 reg=0.002516
2017/08/29 18:01:15 step 4: objective=1.523172 reg=0.002515
2017/08/29 18:01:18 step 5: objective=1.524482 reg=0.002515
2017/08/29 18:01:22 step 6: objective=1.525987 reg=0.002515
2017/08/29 18:01:25 step 7: objective=1.527153 reg=0.002514
2017/08/29 18:01:25 Training value function...
2017/08/29 18:01:28 step 0: mse=141.479155 step=0.100000
2017/08/29 18:01:30 step 1: mse=139.433633 step=0.100000
2017/08/29 18:01:32 step 2: mse=137.826737 step=0.100000
2017/08/29 18:01:34 step 3: mse=136.197730 step=0.100000
2017/08/29 18:01:36 step 4: mse=134.832371 step=0.100000
2017/08/29 18:01:37 step 5: mse=133.521913 step=0.100000
2017/08/29 18:01:39 step 6: mse=132.465357 step=0.100000
2017/08/29 18:01:41 step 7: mse=131.493935 step=0.100000
2017/08/29 18:01:41 Saving...
2017/08/29 18:01:41 Gathering batch of experience...
2017/08/29 18:02:33 batch 216: mean=357.625000 stddev=261.471447 entropy=0.249321 frames=7768 count=24
2017/08/29 18:02:33 Training policy...
2017/08/29 18:02:41 tune 0: objective=1.003465 reg=0.002493 prune=0
2017/08/29 18:02:46 tune 1: objective=1.005636 reg=0.002493 prune=0
2017/08/29 18:02:51 tune 2: objective=1.007800 reg=0.002493 prune=0
2017/08/29 18:02:56 tune 3: objective=1.009958 reg=0.002493 prune=0
2017/08/29 18:03:00 tune 4: objective=1.012106 reg=0.002493 prune=0
2017/08/29 18:03:05 tune 5: objective=1.014250 reg=0.002493 prune=0
2017/08/29 18:03:10 tune 6: objective=1.016391 reg=0.002493 prune=0
2017/08/29 18:03:15 tune 7: objective=1.018444 reg=0.002493 prune=0
2017/08/29 18:03:18 step 0: objective=1.020329 reg=0.002493
2017/08/29 18:03:21 step 1: objective=1.021792 reg=0.002493
2017/08/29 18:03:24 step 2: objective=1.023386 reg=0.002493
2017/08/29 18:03:27 step 3: objective=1.026384 reg=0.002493
2017/08/29 18:03:30 step 4: objective=1.027657 reg=0.002492
2017/08/29 18:03:33 step 5: objective=1.029894 reg=0.002492
2017/08/29 18:03:36 step 6: objective=1.031111 reg=0.002493
2017/08/29 18:03:39 step 7: objective=1.032022 reg=0.002493
2017/08/29 18:03:39 Training value function...
2017/08/29 18:03:42 step 0: mse=128.309475 step=0.100000
2017/08/29 18:03:44 step 1: mse=125.903264 step=0.100000
2017/08/29 18:03:46 step 2: mse=124.037638 step=0.100000
2017/08/29 18:03:47 step 3: mse=122.582632 step=0.100000
2017/08/29 18:03:49 step 4: mse=121.184518 step=0.100000
2017/08/29 18:03:51 step 5: mse=120.016941 step=0.100000
2017/08/29 18:03:52 step 6: mse=118.999651 step=0.100000
2017/08/29 18:03:54 step 7: mse=118.377842 step=0.100000
2017/08/29 18:03:54 Saving...
2017/08/29 18:03:54 Gathering batch of experience...
2017/08/29 18:04:39 batch 217: mean=332.944444 stddev=248.306592 entropy=0.255933 frames=5640 count=18
2017/08/29 18:04:39 Training policy...
2017/08/29 18:04:45 tune 0: objective=0.400046 reg=0.002559 prune=0
2017/08/29 18:04:48 tune 1: objective=0.403351 reg=0.002559 prune=0
2017/08/29 18:04:52 tune 2: objective=0.406612 reg=0.002559 prune=0
2017/08/29 18:04:55 tune 3: objective=0.409828 reg=0.002558 prune=0
2017/08/29 18:04:59 tune 4: objective=0.412984 reg=0.002558 prune=0
2017/08/29 18:05:02 tune 5: objective=0.415746 reg=0.002558 prune=0
2017/08/29 18:05:06 tune 6: objective=0.418116 reg=0.002557 prune=0
2017/08/29 18:05:09 tune 7: objective=0.420244 reg=0.002557 prune=0
2017/08/29 18:05:11 step 0: objective=0.422265 reg=0.002557
2017/08/29 18:05:13 step 1: objective=0.424715 reg=0.002556
2017/08/29 18:05:16 step 2: objective=0.426050 reg=0.002556
2017/08/29 18:05:18 step 3: objective=0.427685 reg=0.002556
2017/08/29 18:05:20 step 4: objective=0.429413 reg=0.002556
2017/08/29 18:05:22 step 5: objective=0.430616 reg=0.002556
2017/08/29 18:05:24 step 6: objective=0.432218 reg=0.002555
2017/08/29 18:05:27 step 7: objective=0.433032 reg=0.002555
2017/08/29 18:05:27 Training value function...
2017/08/29 18:05:29 step 0: mse=121.773651 step=0.100000
2017/08/29 18:05:30 step 1: mse=119.977116 step=0.100000
2017/08/29 18:05:31 step 2: mse=118.664251 step=0.100000
2017/08/29 18:05:33 step 3: mse=117.499511 step=0.100000
2017/08/29 18:05:34 step 4: mse=116.674811 step=0.100000
2017/08/29 18:05:35 step 5: mse=116.056173 step=0.100000
2017/08/29 18:05:36 step 6: mse=115.398730 step=0.100000
2017/08/29 18:05:37 step 7: mse=115.004213 step=0.100000
2017/08/29 18:05:37 Saving...
2017/08/29 18:05:38 Gathering batch of experience...
2017/08/29 18:06:28 batch 218: mean=407.000000 stddev=204.243552 entropy=0.247887 frames=7646 count=21
2017/08/29 18:06:28 Training policy...
2017/08/29 18:06:36 tune 0: objective=1.530645 reg=0.002479 prune=0
2017/08/29 18:06:40 tune 1: objective=1.533274 reg=0.002479 prune=0
2017/08/29 18:06:45 tune 2: objective=1.535892 reg=0.002478 prune=0
2017/08/29 18:06:50 tune 3: objective=1.538494 reg=0.002478 prune=0
2017/08/29 18:06:54 tune 4: objective=1.541082 reg=0.002478 prune=0
2017/08/29 18:06:59 tune 5: objective=1.543652 reg=0.002477 prune=0
2017/08/29 18:07:04 tune 6: objective=1.546119 reg=0.002477 prune=0
2017/08/29 18:07:08 tune 7: objective=1.548327 reg=0.002477 prune=0
2017/08/29 18:07:11 step 0: objective=1.550314 reg=0.002476
2017/08/29 18:07:14 step 1: objective=1.552720 reg=0.002476
2017/08/29 18:07:17 step 2: objective=1.555527 reg=0.002475
2017/08/29 18:07:20 step 3: objective=1.556929 reg=0.002475
2017/08/29 18:07:23 step 4: objective=1.558610 reg=0.002475
2017/08/29 18:07:27 step 5: objective=1.560548 reg=0.002475
2017/08/29 18:07:30 step 6: objective=1.561984 reg=0.002475
2017/08/29 18:07:33 step 7: objective=1.563042 reg=0.002476
2017/08/29 18:07:33 Training value function...
2017/08/29 18:07:36 step 0: mse=142.868934 step=0.100000
2017/08/29 18:07:37 step 1: mse=140.301394 step=0.100000
2017/08/29 18:07:39 step 2: mse=137.804540 step=0.100000
2017/08/29 18:07:41 step 3: mse=136.174217 step=0.100000
2017/08/29 18:07:42 step 4: mse=134.600199 step=0.100000
2017/08/29 18:07:44 step 5: mse=133.217130 step=0.100000
2017/08/29 18:07:45 step 6: mse=132.068760 step=0.100000
2017/08/29 18:07:47 step 7: mse=130.901783 step=0.100000
2017/08/29 18:07:47 Saving...
2017/08/29 18:07:47 Gathering batch of experience...
2017/08/29 18:08:42 batch 219: mean=374.375000 stddev=271.447633 entropy=0.248861 frames=7996 count=24
2017/08/29 18:08:42 Training policy...
2017/08/29 18:08:50 tune 0: objective=1.474650 reg=0.002489 prune=0
2017/08/29 18:08:55 tune 1: objective=1.476711 reg=0.002489 prune=0
2017/08/29 18:09:00 tune 2: objective=1.478753 reg=0.002489 prune=0
2017/08/29 18:09:05 tune 3: objective=1.480787 reg=0.002489 prune=0
2017/08/29 18:09:10 tune 4: objective=1.482807 reg=0.002489 prune=0
2017/08/29 18:09:15 tune 5: objective=1.484763 reg=0.002489 prune=0
2017/08/29 18:09:20 tune 6: objective=1.486641 reg=0.002489 prune=0
2017/08/29 18:09:25 tune 7: objective=1.488515 reg=0.002489 prune=0
2017/08/29 18:09:28 step 0: objective=1.490322 reg=0.002489
2017/08/29 18:09:31 step 1: objective=1.492187 reg=0.002488
2017/08/29 18:09:34 step 2: objective=1.493554 reg=0.002488
2017/08/29 18:09:38 step 3: objective=1.494684 reg=0.002487
2017/08/29 18:09:41 step 4: objective=1.496295 reg=0.002487
2017/08/29 18:09:44 step 5: objective=1.497541 reg=0.002487
2017/08/29 18:09:47 step 6: objective=1.498558 reg=0.002487
2017/08/29 18:09:50 step 7: objective=1.499524 reg=0.002486
2017/08/29 18:09:50 Training value function...
2017/08/29 18:09:54 step 0: mse=147.043351 step=0.100000
2017/08/29 18:09:55 step 1: mse=143.940911 step=0.100000
2017/08/29 18:09:57 step 2: mse=141.654515 step=0.100000
2017/08/29 18:09:59 step 3: mse=139.510923 step=0.100000
2017/08/29 18:10:00 step 4: mse=137.707709 step=0.100000
2017/08/29 18:10:02 step 5: mse=136.325078 step=0.100000
2017/08/29 18:10:04 step 6: mse=134.650784 step=0.100000
2017/08/29 18:10:05 step 7: mse=133.449531 step=0.100000
2017/08/29 18:10:05 Saving...
2017/08/29 18:10:06 Gathering batch of experience...
2017/08/29 18:11:01 batch 220: mean=406.619048 stddev=195.212333 entropy=0.252781 frames=7862 count=21
2017/08/29 18:11:01 Training policy...
2017/08/29 18:11:09 tune 0: objective=0.721681 reg=0.002528 prune=0
2017/08/29 18:11:14 tune 1: objective=0.723503 reg=0.002528 prune=0
2017/08/29 18:11:19 tune 2: objective=0.725312 reg=0.002528 prune=0
2017/08/29 18:11:24 tune 3: objective=0.727109 reg=0.002528 prune=0
2017/08/29 18:11:29 tune 4: objective=0.728893 reg=0.002528 prune=0
2017/08/29 18:11:33 tune 5: objective=0.730665 reg=0.002528 prune=0
2017/08/29 18:11:38 tune 6: objective=0.732367 reg=0.002528 prune=0
2017/08/29 18:11:43 tune 7: objective=0.733989 reg=0.002529 prune=0
2017/08/29 18:11:46 step 0: objective=0.735591 reg=0.002529
2017/08/29 18:11:49 step 1: objective=0.738467 reg=0.002529
2017/08/29 18:11:52 step 2: objective=0.740021 reg=0.002529
2017/08/29 18:11:56 step 3: objective=0.741686 reg=0.002530
2017/08/29 18:11:59 step 4: objective=0.742671 reg=0.002530
2017/08/29 18:12:02 step 5: objective=0.744561 reg=0.002530
2017/08/29 18:12:05 step 6: objective=0.745518 reg=0.002530
2017/08/29 18:12:08 step 7: objective=0.746651 reg=0.002531
2017/08/29 18:12:08 Training value function...
2017/08/29 18:12:11 step 0: mse=116.094741 step=0.100000
2017/08/29 18:12:13 step 1: mse=114.345267 step=0.100000
2017/08/29 18:12:15 step 2: mse=112.979443 step=0.100000
2017/08/29 18:12:16 step 3: mse=111.862526 step=0.100000
2017/08/29 18:12:18 step 4: mse=110.918239 step=0.100000
2017/08/29 18:12:20 step 5: mse=110.223855 step=0.100000
2017/08/29 18:12:21 step 6: mse=109.610879 step=0.100000
2017/08/29 18:12:23 step 7: mse=108.988011 step=0.100000
2017/08/29 18:12:23 Saving...
2017/08/29 18:12:23 Gathering batch of experience...
2017/08/29 18:13:12 batch 221: mean=400.850000 stddev=194.495058 entropy=0.247351 frames=7562 count=20
2017/08/29 18:13:12 Training policy...
2017/08/29 18:13:20 tune 0: objective=0.685134 reg=0.002474 prune=0
2017/08/29 18:13:24 tune 1: objective=0.687482 reg=0.002473 prune=0
2017/08/29 18:13:29 tune 2: objective=0.689811 reg=0.002473 prune=0
2017/08/29 18:13:34 tune 3: objective=0.692120 reg=0.002473 prune=0
2017/08/29 18:13:38 tune 4: objective=0.694412 reg=0.002473 prune=0
2017/08/29 18:13:43 tune 5: objective=0.696691 reg=0.002473 prune=0
2017/08/29 18:13:48 tune 6: objective=0.698859 reg=0.002473 prune=0
2017/08/29 18:13:52 tune 7: objective=0.700800 reg=0.002473 prune=0
2017/08/29 18:13:55 step 0: objective=0.702566 reg=0.002473
2017/08/29 18:13:58 step 1: objective=0.704416 reg=0.002473
2017/08/29 18:14:01 step 2: objective=0.706337 reg=0.002472
2017/08/29 18:14:04 step 3: objective=0.708415 reg=0.002473
2017/08/29 18:14:07 step 4: objective=0.709594 reg=0.002473
2017/08/29 18:14:10 step 5: objective=0.710543 reg=0.002473
2017/08/29 18:14:13 step 6: objective=0.712017 reg=0.002472
2017/08/29 18:14:16 step 7: objective=0.713642 reg=0.002472
2017/08/29 18:14:16 Training value function...
2017/08/29 18:14:19 step 0: mse=139.215493 step=0.100000
2017/08/29 18:14:21 step 1: mse=137.529094 step=0.100000
2017/08/29 18:14:22 step 2: mse=136.229204 step=0.100000
2017/08/29 18:14:24 step 3: mse=134.919075 step=0.100000
2017/08/29 18:14:26 step 4: mse=133.817115 step=0.100000
2017/08/29 18:14:27 step 5: mse=133.160960 step=0.100000
2017/08/29 18:14:29 step 6: mse=132.286697 step=0.100000
2017/08/29 18:14:30 step 7: mse=131.555411 step=0.100000
2017/08/29 18:14:30 Saving...
2017/08/29 18:14:31 Gathering batch of experience...
2017/08/29 18:15:22 batch 222: mean=441.263158 stddev=200.889035 entropy=0.251859 frames=7783 count=19
2017/08/29 18:15:22 Training policy...
2017/08/29 18:15:30 tune 0: objective=1.227838 reg=0.002519 prune=0
2017/08/29 18:15:34 tune 1: objective=1.229797 reg=0.002518 prune=0
2017/08/29 18:15:39 tune 2: objective=1.231747 reg=0.002518 prune=0
2017/08/29 18:15:44 tune 3: objective=1.233695 reg=0.002518 prune=0
2017/08/29 18:15:49 tune 4: objective=1.235635 reg=0.002518 prune=0
2017/08/29 18:15:54 tune 5: objective=1.237564 reg=0.002518 prune=0
2017/08/29 18:15:59 tune 6: objective=1.239493 reg=0.002517 prune=0
2017/08/29 18:16:03 tune 7: objective=1.241348 reg=0.002517 prune=0
2017/08/29 18:16:06 step 0: objective=1.243078 reg=0.002517
2017/08/29 18:16:09 step 1: objective=1.245168 reg=0.002517
2017/08/29 18:16:13 step 2: objective=1.246580 reg=0.002516
2017/08/29 18:16:16 step 3: objective=1.247859 reg=0.002516
2017/08/29 18:16:19 step 4: objective=1.250086 reg=0.002516
2017/08/29 18:16:22 step 5: objective=1.251178 reg=0.002516
2017/08/29 18:16:25 step 6: objective=1.253194 reg=0.002515
2017/08/29 18:16:28 step 7: objective=1.254238 reg=0.002515
2017/08/29 18:16:28 Training value function...
2017/08/29 18:16:31 step 0: mse=140.873767 step=0.100000
2017/08/29 18:16:33 step 1: mse=138.769252 step=0.100000
2017/08/29 18:16:35 step 2: mse=136.851968 step=0.100000
2017/08/29 18:16:36 step 3: mse=135.185148 step=0.100000
2017/08/29 18:16:38 step 4: mse=133.962588 step=0.100000
2017/08/29 18:16:39 step 5: mse=132.833320 step=0.100000
2017/08/29 18:16:41 step 6: mse=131.854837 step=0.100000
2017/08/29 18:16:43 step 7: mse=130.781492 step=0.100000
2017/08/29 18:16:43 Saving...
2017/08/29 18:16:43 Gathering batch of experience...
2017/08/29 18:17:35 batch 223: mean=349.043478 stddev=261.429927 entropy=0.250714 frames=7511 count=23
2017/08/29 18:17:35 Training policy...
2017/08/29 18:17:43 tune 0: objective=0.923652 reg=0.002507 prune=0
2017/08/29 18:17:48 tune 1: objective=0.926025 reg=0.002507 prune=0
2017/08/29 18:17:52 tune 2: objective=0.928373 reg=0.002508 prune=0
2017/08/29 18:17:57 tune 3: objective=0.930701 reg=0.002508 prune=0
2017/08/29 18:18:02 tune 4: objective=0.933005 reg=0.002508 prune=0
2017/08/29 18:18:06 tune 5: objective=0.935245 reg=0.002508 prune=0
2017/08/29 18:18:11 tune 6: objective=0.937312 reg=0.002508 prune=0
2017/08/29 18:18:16 tune 7: objective=0.939201 reg=0.002509 prune=0
2017/08/29 18:18:19 step 0: objective=0.940941 reg=0.002509
2017/08/29 18:18:22 step 1: objective=0.943065 reg=0.002509
2017/08/29 18:18:25 step 2: objective=0.945096 reg=0.002510
2017/08/29 18:18:27 step 3: objective=0.947364 reg=0.002510
2017/08/29 18:18:30 step 4: objective=0.948599 reg=0.002510
2017/08/29 18:18:33 step 5: objective=0.950354 reg=0.002510
2017/08/29 18:18:36 step 6: objective=0.951753 reg=0.002510
2017/08/29 18:18:39 step 7: objective=0.952870 reg=0.002510
2017/08/29 18:18:39 Training value function...
2017/08/29 18:18:42 step 0: mse=148.164529 step=0.100000
2017/08/29 18:18:44 step 1: mse=146.650351 step=0.100000
2017/08/29 18:18:46 step 2: mse=145.176074 step=0.100000
2017/08/29 18:18:47 step 3: mse=143.934329 step=0.100000
2017/08/29 18:18:49 step 4: mse=142.865040 step=0.100000
2017/08/29 18:18:50 step 5: mse=141.950958 step=0.100000
2017/08/29 18:18:52 step 6: mse=140.917838 step=0.100000
2017/08/29 18:18:54 step 7: mse=140.110831 step=0.100000
2017/08/29 18:18:54 Saving...
2017/08/29 18:18:54 Gathering batch of experience...
2017/08/29 18:19:46 batch 224: mean=467.631579 stddev=206.851131 entropy=0.249687 frames=8186 count=19
2017/08/29 18:19:46 Training policy...
2017/08/29 18:19:54 tune 0: objective=1.467123 reg=0.002497 prune=0
2017/08/29 18:19:59 tune 1: objective=1.469025 reg=0.002497 prune=0
2017/08/29 18:20:04 tune 2: objective=1.470911 reg=0.002496 prune=0
2017/08/29 18:20:09 tune 3: objective=1.472781 reg=0.002496 prune=0
2017/08/29 18:20:15 tune 4: objective=1.474636 reg=0.002496 prune=0
2017/08/29 18:20:20 tune 5: objective=1.476459 reg=0.002495 prune=0
2017/08/29 18:20:25 tune 6: objective=1.478135 reg=0.002495 prune=0
2017/08/29 18:20:30 tune 7: objective=1.479745 reg=0.002495 prune=0
2017/08/29 18:20:33 step 0: objective=1.481311 reg=0.002495
2017/08/29 18:20:36 step 1: objective=1.482417 reg=0.002494
2017/08/29 18:20:39 step 2: objective=1.484355 reg=0.002493
2017/08/29 18:20:43 step 3: objective=1.485524 reg=0.002493
2017/08/29 18:20:46 step 4: objective=1.486747 reg=0.002492
2017/08/29 18:20:49 step 5: objective=1.487947 reg=0.002492
2017/08/29 18:20:52 step 6: objective=1.488875 reg=0.002491
2017/08/29 18:20:56 step 7: objective=1.489803 reg=0.002491
2017/08/29 18:20:56 Training value function...
2017/08/29 18:20:59 step 0: mse=134.243192 step=0.100000
2017/08/29 18:21:01 step 1: mse=131.196028 step=0.100000
2017/08/29 18:21:03 step 2: mse=128.576055 step=0.100000
2017/08/29 18:21:04 step 3: mse=126.293912 step=0.100000
2017/08/29 18:21:06 step 4: mse=124.631074 step=0.100000
2017/08/29 18:21:08 step 5: mse=123.003610 step=0.100000
2017/08/29 18:21:09 step 6: mse=121.666956 step=0.100000
2017/08/29 18:21:11 step 7: mse=120.697584 step=0.100000
2017/08/29 18:21:11 Saving...
2017/08/29 18:21:11 Gathering batch of experience...
2017/08/29 18:22:02 batch 225: mean=356.761905 stddev=188.578114 entropy=0.254047 frames=6986 count=21
2017/08/29 18:22:02 Training policy...
2017/08/29 18:22:09 tune 0: objective=0.535782 reg=0.002540 prune=0
2017/08/29 18:22:13 tune 1: objective=0.539466 reg=0.002540 prune=0
2017/08/29 18:22:18 tune 2: objective=0.543111 reg=0.002539 prune=0
2017/08/29 18:22:22 tune 3: objective=0.546715 reg=0.002539 prune=0
2017/08/29 18:22:26 tune 4: objective=0.550248 reg=0.002538 prune=0
2017/08/29 18:22:31 tune 5: objective=0.553485 reg=0.002537 prune=0
2017/08/29 18:22:35 tune 6: objective=0.556398 reg=0.002537 prune=0
2017/08/29 18:22:39 tune 7: objective=0.559034 reg=0.002536 prune=0
2017/08/29 18:22:42 step 0: objective=0.561304 reg=0.002535
2017/08/29 18:22:45 step 1: objective=0.563871 reg=0.002534
2017/08/29 18:22:47 step 2: objective=0.566749 reg=0.002534
2017/08/29 18:22:50 step 3: objective=0.569191 reg=0.002533
2017/08/29 18:22:53 step 4: objective=0.570435 reg=0.002533
2017/08/29 18:22:56 step 5: objective=0.572674 reg=0.002533
2017/08/29 18:22:58 step 6: objective=0.574020 reg=0.002534
2017/08/29 18:23:01 step 7: objective=0.574996 reg=0.002534
2017/08/29 18:23:01 Training value function...
2017/08/29 18:23:04 step 0: mse=142.674209 step=0.100000
2017/08/29 18:23:06 step 1: mse=139.415678 step=0.100000
2017/08/29 18:23:07 step 2: mse=136.630719 step=0.100000
2017/08/29 18:23:08 step 3: mse=134.304800 step=0.100000
2017/08/29 18:23:10 step 4: mse=132.072828 step=0.100000
2017/08/29 18:23:11 step 5: mse=130.364188 step=0.100000
2017/08/29 18:23:13 step 6: mse=129.095219 step=0.100000
2017/08/29 18:23:14 step 7: mse=127.959363 step=0.100000
2017/08/29 18:23:14 Saving...
2017/08/29 18:23:15 Gathering batch of experience...
2017/08/29 18:24:02 batch 226: mean=368.700000 stddev=228.539734 entropy=0.251490 frames=6972 count=20
2017/08/29 18:24:02 Training policy...
2017/08/29 18:24:09 tune 0: objective=0.930618 reg=0.002515 prune=0
2017/08/29 18:24:13 tune 1: objective=0.933098 reg=0.002515 prune=0
2017/08/29 18:24:18 tune 2: objective=0.935554 reg=0.002515 prune=0
2017/08/29 18:24:22 tune 3: objective=0.937997 reg=0.002515 prune=0
2017/08/29 18:24:26 tune 4: objective=0.940414 reg=0.002516 prune=0
2017/08/29 18:24:31 tune 5: objective=0.942498 reg=0.002516 prune=0
2017/08/29 18:24:35 tune 6: objective=0.944429 reg=0.002516 prune=0
2017/08/29 18:24:39 tune 7: objective=0.946307 reg=0.002516 prune=0
2017/08/29 18:24:42 step 0: objective=0.948116 reg=0.002516
2017/08/29 18:24:45 step 1: objective=0.949755 reg=0.002516
2017/08/29 18:24:47 step 2: objective=0.952081 reg=0.002516
2017/08/29 18:24:50 step 3: objective=0.953248 reg=0.002516
2017/08/29 18:24:53 step 4: objective=0.955396 reg=0.002516
2017/08/29 18:24:56 step 5: objective=0.956649 reg=0.002515
2017/08/29 18:24:58 step 6: objective=0.957774 reg=0.002515
2017/08/29 18:25:01 step 7: objective=0.959327 reg=0.002515
2017/08/29 18:25:01 Training value function...
2017/08/29 18:25:04 step 0: mse=141.132709 step=0.100000
2017/08/29 18:25:06 step 1: mse=139.002311 step=0.100000
2017/08/29 18:25:07 step 2: mse=137.339640 step=0.100000
2017/08/29 18:25:09 step 3: mse=135.770183 step=0.100000
2017/08/29 18:25:10 step 4: mse=134.479203 step=0.100000
2017/08/29 18:25:11 step 5: mse=133.407335 step=0.100000
2017/08/29 18:25:13 step 6: mse=132.591917 step=0.100000
2017/08/29 18:25:14 step 7: mse=131.896626 step=0.100000
2017/08/29 18:25:14 Saving...
2017/08/29 18:25:15 Gathering batch of experience...
2017/08/29 18:26:05 batch 227: mean=418.047619 stddev=191.574796 entropy=0.249994 frames=8059 count=21
2017/08/29 18:26:05 Training policy...
2017/08/29 18:26:14 tune 0: objective=1.432071 reg=0.002500 prune=0
2017/08/29 18:26:19 tune 1: objective=1.434509 reg=0.002500 prune=0
2017/08/29 18:26:24 tune 2: objective=1.436938 reg=0.002500 prune=0
2017/08/29 18:26:29 tune 3: objective=1.439357 reg=0.002500 prune=0
2017/08/29 18:26:34 tune 4: objective=1.441770 reg=0.002500 prune=0
2017/08/29 18:26:39 tune 5: objective=1.444152 reg=0.002500 prune=0
2017/08/29 18:26:44 tune 6: objective=1.446462 reg=0.002500 prune=0
2017/08/29 18:26:49 tune 7: objective=1.448722 reg=0.002500 prune=0
2017/08/29 18:26:52 step 0: objective=1.450810 reg=0.002500
2017/08/29 18:26:55 step 1: objective=1.452531 reg=0.002499
2017/08/29 18:26:58 step 2: objective=1.454224 reg=0.002498
2017/08/29 18:27:02 step 3: objective=1.456048 reg=0.002498
2017/08/29 18:27:05 step 4: objective=1.457168 reg=0.002498
2017/08/29 18:27:08 step 5: objective=1.458618 reg=0.002498
2017/08/29 18:27:11 step 6: objective=1.460297 reg=0.002498
2017/08/29 18:27:14 step 7: objective=1.461953 reg=0.002498
2017/08/29 18:27:14 Training value function...
2017/08/29 18:27:18 step 0: mse=132.408314 step=0.100000
2017/08/29 18:27:19 step 1: mse=129.998451 step=0.100000
2017/08/29 18:27:21 step 2: mse=127.607491 step=0.100000
2017/08/29 18:27:23 step 3: mse=125.890881 step=0.100000
2017/08/29 18:27:25 step 4: mse=124.029613 step=0.100000
2017/08/29 18:27:26 step 5: mse=122.471881 step=0.100000
2017/08/29 18:27:28 step 6: mse=121.115692 step=0.100000
2017/08/29 18:27:30 step 7: mse=120.191528 step=0.100000
2017/08/29 18:27:30 Saving...
2017/08/29 18:27:30 Gathering batch of experience...
2017/08/29 18:28:18 batch 228: mean=370.000000 stddev=246.377565 entropy=0.254503 frames=7223 count=21
2017/08/29 18:28:18 Training policy...
2017/08/29 18:28:25 tune 0: objective=1.102294 reg=0.002545 prune=0
2017/08/29 18:28:30 tune 1: objective=1.104862 reg=0.002545 prune=0
2017/08/29 18:28:34 tune 2: objective=1.107419 reg=0.002545 prune=0
2017/08/29 18:28:39 tune 3: objective=1.109968 reg=0.002545 prune=0
2017/08/29 18:28:43 tune 4: objective=1.112510 reg=0.002545 prune=0
2017/08/29 18:28:48 tune 5: objective=1.115022 reg=0.002545 prune=0
2017/08/29 18:28:52 tune 6: objective=1.117452 reg=0.002545 prune=0
2017/08/29 18:28:57 tune 7: objective=1.119771 reg=0.002545 prune=0
2017/08/29 18:29:00 step 0: objective=1.121938 reg=0.002545
2017/08/29 18:29:02 step 1: objective=1.123792 reg=0.002545
2017/08/29 18:29:05 step 2: objective=1.126367 reg=0.002545
2017/08/29 18:29:08 step 3: objective=1.127948 reg=0.002545
2017/08/29 18:29:11 step 4: objective=1.129396 reg=0.002545
2017/08/29 18:29:14 step 5: objective=1.131119 reg=0.002545
2017/08/29 18:29:17 step 6: objective=1.132288 reg=0.002546
2017/08/29 18:29:20 step 7: objective=1.133699 reg=0.002546
2017/08/29 18:29:20 Training value function...
2017/08/29 18:29:23 step 0: mse=127.491109 step=0.100000
2017/08/29 18:29:24 step 1: mse=126.400071 step=0.100000
2017/08/29 18:29:26 step 2: mse=125.212910 step=0.100000
2017/08/29 18:29:27 step 3: mse=124.322382 step=0.100000
2017/08/29 18:29:29 step 4: mse=123.486753 step=0.100000
2017/08/29 18:29:30 step 5: mse=122.786473 step=0.100000
2017/08/29 18:29:32 step 6: mse=122.002689 step=0.100000
2017/08/29 18:29:33 step 7: mse=121.230448 step=0.100000
2017/08/29 18:29:33 Saving...
2017/08/29 18:29:33 Gathering batch of experience...
2017/08/29 18:30:23 batch 229: mean=430.277778 stddev=204.359380 entropy=0.255011 frames=7416 count=18
2017/08/29 18:30:23 Training policy...
2017/08/29 18:30:30 tune 0: objective=0.803232 reg=0.002550 prune=0
2017/08/29 18:30:35 tune 1: objective=0.805060 reg=0.002550 prune=0
2017/08/29 18:30:40 tune 2: objective=0.806879 reg=0.002549 prune=0
2017/08/29 18:30:44 tune 3: objective=0.808688 reg=0.002549 prune=0
2017/08/29 18:30:49 tune 4: objective=0.810483 reg=0.002548 prune=0
2017/08/29 18:30:53 tune 5: objective=0.812245 reg=0.002548 prune=0
2017/08/29 18:30:58 tune 6: objective=0.813940 reg=0.002547 prune=0
2017/08/29 18:31:03 tune 7: objective=0.815631 reg=0.002547 prune=0
2017/08/29 18:31:05 step 0: objective=0.817306 reg=0.002547
2017/08/29 18:31:08 step 1: objective=0.819940 reg=0.002547
2017/08/29 18:31:11 step 2: objective=0.823580 reg=0.002547
2017/08/29 18:31:14 step 3: objective=0.825950 reg=0.002546
2017/08/29 18:31:17 step 4: objective=0.827612 reg=0.002546
2017/08/29 18:31:20 step 5: objective=0.829713 reg=0.002545
2017/08/29 18:31:23 step 6: objective=0.830997 reg=0.002544
2017/08/29 18:31:26 step 7: objective=0.831969 reg=0.002544
2017/08/29 18:31:26 Training value function...
2017/08/29 18:31:29 step 0: mse=125.489938 step=0.100000
2017/08/29 18:31:31 step 1: mse=124.368992 step=0.100000
2017/08/29 18:31:32 step 2: mse=124.172328 step=0.100000
2017/08/29 18:31:34 step 3: mse=123.933653 step=0.100000
2017/08/29 18:31:35 step 4: mse=122.966715 step=0.100000
2017/08/29 18:31:37 step 5: mse=122.649282 step=0.100000
2017/08/29 18:31:38 step 6: mse=122.244971 step=0.100000
2017/08/29 18:31:40 step 7: mse=122.115255 step=0.100000
2017/08/29 18:31:40 Saving...
2017/08/29 18:31:40 Gathering batch of experience...
2017/08/29 18:32:30 batch 230: mean=417.473684 stddev=218.434470 entropy=0.248396 frames=7307 count=19
2017/08/29 18:32:30 Training policy...
2017/08/29 18:32:37 tune 0: objective=1.493792 reg=0.002484 prune=0
2017/08/29 18:32:42 tune 1: objective=1.495691 reg=0.002484 prune=0
2017/08/29 18:32:46 tune 2: objective=1.497587 reg=0.002484 prune=0
2017/08/29 18:32:51 tune 3: objective=1.499479 reg=0.002485 prune=0
2017/08/29 18:32:55 tune 4: objective=1.501376 reg=0.002485 prune=0
2017/08/29 18:33:00 tune 5: objective=1.503269 reg=0.002485 prune=0
2017/08/29 18:33:04 tune 6: objective=1.505101 reg=0.002485 prune=0
2017/08/29 18:33:09 tune 7: objective=1.506852 reg=0.002486 prune=0
2017/08/29 18:33:12 step 0: objective=1.508527 reg=0.002486
2017/08/29 18:33:15 step 1: objective=1.509867 reg=0.002486
2017/08/29 18:33:18 step 2: objective=1.511525 reg=0.002486
2017/08/29 18:33:21 step 3: objective=1.512989 reg=0.002486
2017/08/29 18:33:23 step 4: objective=1.514180 reg=0.002486
2017/08/29 18:33:26 step 5: objective=1.515050 reg=0.002486
2017/08/29 18:33:29 step 6: objective=1.516297 reg=0.002486
2017/08/29 18:33:32 step 7: objective=1.517514 reg=0.002485
2017/08/29 18:33:32 Training value function...
2017/08/29 18:33:35 step 0: mse=127.907825 step=0.100000
2017/08/29 18:33:37 step 1: mse=125.933455 step=0.100000
2017/08/29 18:33:38 step 2: mse=124.041261 step=0.100000
2017/08/29 18:33:40 step 3: mse=122.409829 step=0.100000
2017/08/29 18:33:41 step 4: mse=120.952788 step=0.100000
2017/08/29 18:33:43 step 5: mse=119.690930 step=0.100000
2017/08/29 18:33:44 step 6: mse=118.492968 step=0.100000
2017/08/29 18:33:46 step 7: mse=117.493316 step=0.100000
2017/08/29 18:33:46 Saving...
2017/08/29 18:33:46 Gathering batch of experience...
2017/08/29 18:34:34 batch 231: mean=349.809524 stddev=226.495373 entropy=0.244950 frames=6877 count=21
2017/08/29 18:34:34 Training policy...
2017/08/29 18:34:41 tune 0: objective=0.892278 reg=0.002449 prune=0
2017/08/29 18:34:46 tune 1: objective=0.894565 reg=0.002449 prune=0
2017/08/29 18:34:50 tune 2: objective=0.896821 reg=0.002449 prune=0
2017/08/29 18:34:54 tune 3: objective=0.899055 reg=0.002449 prune=0
2017/08/29 18:34:58 tune 4: objective=0.901267 reg=0.002449 prune=0
2017/08/29 18:35:03 tune 5: objective=0.903412 reg=0.002449 prune=0
2017/08/29 18:35:07 tune 6: objective=0.905347 reg=0.002448 prune=0
2017/08/29 18:35:11 tune 7: objective=0.907151 reg=0.002448 prune=0
2017/08/29 18:35:14 step 0: objective=0.908882 reg=0.002448
2017/08/29 18:35:17 step 1: objective=0.911004 reg=0.002448
2017/08/29 18:35:19 step 2: objective=0.912941 reg=0.002448
2017/08/29 18:35:22 step 3: objective=0.914541 reg=0.002448
2017/08/29 18:35:25 step 4: objective=0.916200 reg=0.002448
2017/08/29 18:35:28 step 5: objective=0.917393 reg=0.002448
2017/08/29 18:35:30 step 6: objective=0.918449 reg=0.002448
2017/08/29 18:35:33 step 7: objective=0.920034 reg=0.002449
2017/08/29 18:35:33 Training value function...
2017/08/29 18:35:36 step 0: mse=149.263445 step=0.100000
2017/08/29 18:35:37 step 1: mse=146.764555 step=0.100000
2017/08/29 18:35:39 step 2: mse=144.680943 step=0.100000
2017/08/29 18:35:40 step 3: mse=142.952598 step=0.100000
2017/08/29 18:35:42 step 4: mse=141.599282 step=0.100000
2017/08/29 18:35:43 step 5: mse=140.357938 step=0.100000
2017/08/29 18:35:45 step 6: mse=139.180402 step=0.100000
2017/08/29 18:35:46 step 7: mse=138.117892 step=0.100000
2017/08/29 18:35:46 Saving...
2017/08/29 18:35:46 Gathering batch of experience...
2017/08/29 18:36:36 batch 232: mean=441.555556 stddev=204.623020 entropy=0.253737 frames=7406 count=18
2017/08/29 18:36:36 Training policy...
2017/08/29 18:36:44 tune 0: objective=1.132484 reg=0.002537 prune=0
2017/08/29 18:36:48 tune 1: objective=1.134611 reg=0.002537 prune=0
2017/08/29 18:36:53 tune 2: objective=1.136722 reg=0.002536 prune=0
2017/08/29 18:36:57 tune 3: objective=1.138822 reg=0.002535 prune=0
2017/08/29 18:37:02 tune 4: objective=1.140905 reg=0.002535 prune=0
2017/08/29 18:37:07 tune 5: objective=1.142889 reg=0.002534 prune=0
2017/08/29 18:37:11 tune 6: objective=1.144689 reg=0.002534 prune=0
2017/08/29 18:37:16 tune 7: objective=1.146436 reg=0.002533 prune=0
2017/08/29 18:37:19 step 0: objective=1.148144 reg=0.002532
2017/08/29 18:37:22 step 1: objective=1.150269 reg=0.002531
2017/08/29 18:37:25 step 2: objective=1.152293 reg=0.002531
2017/08/29 18:37:28 step 3: objective=1.154198 reg=0.002531
2017/08/29 18:37:31 step 4: objective=1.156357 reg=0.002531
2017/08/29 18:37:34 step 5: objective=1.158255 reg=0.002531
2017/08/29 18:37:36 step 6: objective=1.159482 reg=0.002530
2017/08/29 18:37:39 step 7: objective=1.161101 reg=0.002530
2017/08/29 18:37:39 Training value function...
2017/08/29 18:37:42 step 0: mse=143.209387 step=0.100000
2017/08/29 18:37:44 step 1: mse=139.150366 step=0.100000
2017/08/29 18:37:46 step 2: mse=135.673825 step=0.100000
2017/08/29 18:37:47 step 3: mse=133.034897 step=0.100000
2017/08/29 18:37:49 step 4: mse=130.752832 step=0.100000
2017/08/29 18:37:50 step 5: mse=129.045213 step=0.100000
2017/08/29 18:37:52 step 6: mse=127.324345 step=0.100000
2017/08/29 18:37:53 step 7: mse=125.970692 step=0.100000
2017/08/29 18:37:53 Saving...
2017/08/29 18:37:54 Gathering batch of experience...
2017/08/29 18:38:44 batch 233: mean=386.600000 stddev=271.655002 entropy=0.251020 frames=7326 count=20
2017/08/29 18:38:44 Training policy...
2017/08/29 18:38:52 tune 0: objective=1.056684 reg=0.002510 prune=0
2017/08/29 18:38:57 tune 1: objective=1.058793 reg=0.002510 prune=0
2017/08/29 18:39:01 tune 2: objective=1.060893 reg=0.002510 prune=0
2017/08/29 18:39:06 tune 3: objective=1.062974 reg=0.002510 prune=0
2017/08/29 18:39:10 tune 4: objective=1.065050 reg=0.002510 prune=0
2017/08/29 18:39:15 tune 5: objective=1.067093 reg=0.002510 prune=0
2017/08/29 18:39:19 tune 6: objective=1.069023 reg=0.002510 prune=0
2017/08/29 18:39:24 tune 7: objective=1.070880 reg=0.002511 prune=0
2017/08/29 18:39:27 step 0: objective=1.072669 reg=0.002511
2017/08/29 18:39:30 step 1: objective=1.074782 reg=0.002511
2017/08/29 18:39:33 step 2: objective=1.076255 reg=0.002510
2017/08/29 18:39:36 step 3: objective=1.078418 reg=0.002510
2017/08/29 18:39:39 step 4: objective=1.079349 reg=0.002510
2017/08/29 18:39:41 step 5: objective=1.080664 reg=0.002510
2017/08/29 18:39:44 step 6: objective=1.081585 reg=0.002510
2017/08/29 18:39:47 step 7: objective=1.083276 reg=0.002511
2017/08/29 18:39:47 Training value function...
2017/08/29 18:39:50 step 0: mse=148.634919 step=0.100000
2017/08/29 18:39:52 step 1: mse=146.101602 step=0.100000
2017/08/29 18:39:53 step 2: mse=143.901553 step=0.100000
2017/08/29 18:39:55 step 3: mse=142.230037 step=0.100000
2017/08/29 18:39:57 step 4: mse=140.503217 step=0.100000
2017/08/29 18:39:58 step 5: mse=139.147424 step=0.100000
2017/08/29 18:40:00 step 6: mse=138.013962 step=0.100000
2017/08/29 18:40:01 step 7: mse=137.000228 step=0.100000
2017/08/29 18:40:01 Saving...
2017/08/29 18:40:01 Gathering batch of experience...
2017/08/29 18:40:56 batch 234: mean=403.523810 stddev=215.548607 entropy=0.250084 frames=7939 count=21
2017/08/29 18:40:56 Training policy...
2017/08/29 18:41:04 tune 0: objective=0.961896 reg=0.002501 prune=0
2017/08/29 18:41:09 tune 1: objective=0.963940 reg=0.002501 prune=0
2017/08/29 18:41:14 tune 2: objective=0.965967 reg=0.002500 prune=0
2017/08/29 18:41:19 tune 3: objective=0.967980 reg=0.002500 prune=0
2017/08/29 18:41:24 tune 4: objective=0.969981 reg=0.002500 prune=0
2017/08/29 18:41:29 tune 5: objective=0.971930 reg=0.002499 prune=0
2017/08/29 18:41:34 tune 6: objective=0.973740 reg=0.002499 prune=0
2017/08/29 18:41:39 tune 7: objective=0.975472 reg=0.002499 prune=0
2017/08/29 18:41:42 step 0: objective=0.977096 reg=0.002499
2017/08/29 18:41:45 step 1: objective=0.978503 reg=0.002499
2017/08/29 18:41:49 step 2: objective=0.979850 reg=0.002499
2017/08/29 18:41:52 step 3: objective=0.981601 reg=0.002499
2017/08/29 18:41:55 step 4: objective=0.983313 reg=0.002499
2017/08/29 18:41:58 step 5: objective=0.985200 reg=0.002499
2017/08/29 18:42:01 step 6: objective=0.986230 reg=0.002499
2017/08/29 18:42:04 step 7: objective=0.987751 reg=0.002498
2017/08/29 18:42:04 Training value function...
2017/08/29 18:42:08 step 0: mse=136.991098 step=0.100000
2017/08/29 18:42:09 step 1: mse=135.778926 step=0.100000
2017/08/29 18:42:11 step 2: mse=134.754033 step=0.100000
2017/08/29 18:42:13 step 3: mse=133.872071 step=0.100000
2017/08/29 18:42:14 step 4: mse=133.180217 step=0.100000
2017/08/29 18:42:16 step 5: mse=132.479069 step=0.100000
2017/08/29 18:42:18 step 6: mse=131.652994 step=0.100000
2017/08/29 18:42:19 step 7: mse=131.088138 step=0.100000
2017/08/29 18:42:19 Saving...
2017/08/29 18:42:20 Gathering batch of experience...
2017/08/29 18:43:11 batch 235: mean=400.636364 stddev=259.840606 entropy=0.251531 frames=7924 count=22
2017/08/29 18:43:11 Training policy...
2017/08/29 18:43:19 tune 0: objective=1.690703 reg=0.002515 prune=0
2017/08/29 18:43:24 tune 1: objective=1.692681 reg=0.002515 prune=0
2017/08/29 18:43:29 tune 2: objective=1.694657 reg=0.002515 prune=0
2017/08/29 18:43:34 tune 3: objective=1.696630 reg=0.002516 prune=0
2017/08/29 18:43:39 tune 4: objective=1.698595 reg=0.002516 prune=0
2017/08/29 18:43:44 tune 5: objective=1.700551 reg=0.002516 prune=0
2017/08/29 18:43:49 tune 6: objective=1.702502 reg=0.002516 prune=0
2017/08/29 18:43:53 tune 7: objective=1.704307 reg=0.002516 prune=0
2017/08/29 18:43:57 step 0: objective=1.705989 reg=0.002516
2017/08/29 18:44:00 step 1: objective=1.708364 reg=0.002516
2017/08/29 18:44:03 step 2: objective=1.710099 reg=0.002516
2017/08/29 18:44:06 step 3: objective=1.711972 reg=0.002516
2017/08/29 18:44:09 step 4: objective=1.713199 reg=0.002516
2017/08/29 18:44:12 step 5: objective=1.715173 reg=0.002516
2017/08/29 18:44:16 step 6: objective=1.715888 reg=0.002515
2017/08/29 18:44:19 step 7: objective=1.717307 reg=0.002515
2017/08/29 18:44:19 Training value function...
2017/08/29 18:44:22 step 0: mse=145.338008 step=0.100000
2017/08/29 18:44:24 step 1: mse=141.360419 step=0.100000
2017/08/29 18:44:25 step 2: mse=138.355014 step=0.100000
2017/08/29 18:44:27 step 3: mse=135.633261 step=0.100000
2017/08/29 18:44:29 step 4: mse=133.142242 step=0.100000
2017/08/29 18:44:31 step 5: mse=131.174791 step=0.100000
2017/08/29 18:44:32 step 6: mse=129.350665 step=0.100000
2017/08/29 18:44:34 step 7: mse=127.752792 step=0.100000
2017/08/29 18:44:34 Saving...
2017/08/29 18:44:34 Gathering batch of experience...
2017/08/29 18:45:26 batch 236: mean=404.900000 stddev=207.464431 entropy=0.245390 frames=7591 count=20
2017/08/29 18:45:26 Training policy...
2017/08/29 18:45:34 tune 0: objective=0.714166 reg=0.002454 prune=0
2017/08/29 18:45:38 tune 1: objective=0.715888 reg=0.002453 prune=0
2017/08/29 18:45:43 tune 2: objective=0.717602 reg=0.002453 prune=0
2017/08/29 18:45:48 tune 3: objective=0.719308 reg=0.002452 prune=0
2017/08/29 18:45:53 tune 4: objective=0.721006 reg=0.002452 prune=0
2017/08/29 18:45:57 tune 5: objective=0.722690 reg=0.002451 prune=0
2017/08/29 18:46:02 tune 6: objective=0.724308 reg=0.002451 prune=0
2017/08/29 18:46:07 tune 7: objective=0.725850 reg=0.002450 prune=0
2017/08/29 18:46:10 step 0: objective=0.727369 reg=0.002450
2017/08/29 18:46:13 step 1: objective=0.728742 reg=0.002450
2017/08/29 18:46:16 step 2: objective=0.730051 reg=0.002449
2017/08/29 18:46:19 step 3: objective=0.731629 reg=0.002448
2017/08/29 18:46:22 step 4: objective=0.732952 reg=0.002448
2017/08/29 18:46:25 step 5: objective=0.734605 reg=0.002448
2017/08/29 18:46:28 step 6: objective=0.735897 reg=0.002448
2017/08/29 18:46:31 step 7: objective=0.736699 reg=0.002448
2017/08/29 18:46:31 Training value function...
2017/08/29 18:46:34 step 0: mse=117.152448 step=0.100000
2017/08/29 18:46:36 step 1: mse=115.044871 step=0.100000
2017/08/29 18:46:38 step 2: mse=113.193907 step=0.100000
2017/08/29 18:46:39 step 3: mse=111.655375 step=0.100000
2017/08/29 18:46:41 step 4: mse=110.535719 step=0.100000
2017/08/29 18:46:42 step 5: mse=109.534951 step=0.100000
2017/08/29 18:46:44 step 6: mse=108.735106 step=0.100000
2017/08/29 18:46:46 step 7: mse=107.879642 step=0.100000
2017/08/29 18:46:46 Saving...
2017/08/29 18:46:46 Gathering batch of experience...
2017/08/29 18:47:37 batch 237: mean=484.333333 stddev=203.159215 entropy=0.252749 frames=8181 count=18
2017/08/29 18:47:37 Training policy...
2017/08/29 18:47:46 tune 0: objective=1.178808 reg=0.002527 prune=0
2017/08/29 18:47:51 tune 1: objective=1.180626 reg=0.002528 prune=0
2017/08/29 18:47:56 tune 2: objective=1.182441 reg=0.002528 prune=0
2017/08/29 18:48:01 tune 3: objective=1.184248 reg=0.002528 prune=0
2017/08/29 18:48:06 tune 4: objective=1.186050 reg=0.002529 prune=0
2017/08/29 18:48:11 tune 5: objective=1.187822 reg=0.002529 prune=0
2017/08/29 18:48:17 tune 6: objective=1.189443 reg=0.002529 prune=0
2017/08/29 18:48:22 tune 7: objective=1.190932 reg=0.002530 prune=0
2017/08/29 18:48:25 step 0: objective=1.192291 reg=0.002530
2017/08/29 18:48:28 step 1: objective=1.194429 reg=0.002530
2017/08/29 18:48:31 step 2: objective=1.196831 reg=0.002531
2017/08/29 18:48:35 step 3: objective=1.198580 reg=0.002531
2017/08/29 18:48:38 step 4: objective=1.199930 reg=0.002531
2017/08/29 18:48:41 step 5: objective=1.200823 reg=0.002531
2017/08/29 18:48:45 step 6: objective=1.201754 reg=0.002531
2017/08/29 18:48:48 step 7: objective=1.202804 reg=0.002531
2017/08/29 18:48:48 Training value function...
2017/08/29 18:48:51 step 0: mse=120.287822 step=0.100000
2017/08/29 18:48:53 step 1: mse=118.886509 step=0.100000
2017/08/29 18:48:55 step 2: mse=117.669696 step=0.100000
2017/08/29 18:48:56 step 3: mse=116.445842 step=0.100000
2017/08/29 18:48:58 step 4: mse=115.420134 step=0.100000
2017/08/29 18:49:00 step 5: mse=114.601724 step=0.100000
2017/08/29 18:49:02 step 6: mse=113.903764 step=0.100000
2017/08/29 18:49:03 step 7: mse=113.208224 step=0.100000
2017/08/29 18:49:03 Saving...
2017/08/29 18:49:03 Gathering batch of experience...
2017/08/29 18:49:53 batch 238: mean=442.611111 stddev=206.256620 entropy=0.248477 frames=7451 count=18
2017/08/29 18:49:53 Training policy...
2017/08/29 18:50:00 tune 0: objective=1.201910 reg=0.002485 prune=0
2017/08/29 18:50:05 tune 1: objective=1.203837 reg=0.002485 prune=0
2017/08/29 18:50:10 tune 2: objective=1.205760 reg=0.002485 prune=0
2017/08/29 18:50:14 tune 3: objective=1.207674 reg=0.002485 prune=0
2017/08/29 18:50:19 tune 4: objective=1.209582 reg=0.002485 prune=0
2017/08/29 18:50:24 tune 5: objective=1.211492 reg=0.002485 prune=0
2017/08/29 18:50:28 tune 6: objective=1.213333 reg=0.002485 prune=0
2017/08/29 18:50:33 tune 7: objective=1.215075 reg=0.002486 prune=0
2017/08/29 18:50:36 step 0: objective=1.216706 reg=0.002486
2017/08/29 18:50:39 step 1: objective=1.218482 reg=0.002486
2017/08/29 18:50:42 step 2: objective=1.220446 reg=0.002486
2017/08/29 18:50:45 step 3: objective=1.222433 reg=0.002486
2017/08/29 18:50:48 step 4: objective=1.223551 reg=0.002487
2017/08/29 18:50:51 step 5: objective=1.224907 reg=0.002487
2017/08/29 18:50:54 step 6: objective=1.226253 reg=0.002487
2017/08/29 18:50:57 step 7: objective=1.227084 reg=0.002487
2017/08/29 18:50:57 Training value function...
2017/08/29 18:51:00 step 0: mse=121.530745 step=0.100000
2017/08/29 18:51:02 step 1: mse=119.686286 step=0.100000
2017/08/29 18:51:03 step 2: mse=118.094983 step=0.100000
2017/08/29 18:51:05 step 3: mse=116.885022 step=0.100000
2017/08/29 18:51:06 step 4: mse=115.648794 step=0.100000
2017/08/29 18:51:08 step 5: mse=114.692004 step=0.100000
2017/08/29 18:51:09 step 6: mse=113.755399 step=0.100000
2017/08/29 18:51:11 step 7: mse=113.000381 step=0.100000
2017/08/29 18:51:11 Saving...
2017/08/29 18:51:11 Gathering batch of experience...
2017/08/29 18:52:03 batch 239: mean=427.631579 stddev=227.702995 entropy=0.249444 frames=7543 count=19
2017/08/29 18:52:03 Training policy...
2017/08/29 18:52:11 tune 0: objective=1.042446 reg=0.002494 prune=0
2017/08/29 18:52:16 tune 1: objective=1.044508 reg=0.002494 prune=0
2017/08/29 18:52:20 tune 2: objective=1.046566 reg=0.002495 prune=0
2017/08/29 18:52:25 tune 3: objective=1.048624 reg=0.002495 prune=0
2017/08/29 18:52:30 tune 4: objective=1.050677 reg=0.002495 prune=0
2017/08/29 18:52:35 tune 5: objective=1.052723 reg=0.002495 prune=0
2017/08/29 18:52:39 tune 6: objective=1.054648 reg=0.002495 prune=0
2017/08/29 18:52:44 tune 7: objective=1.056516 reg=0.002495 prune=0
2017/08/29 18:52:47 step 0: objective=1.058270 reg=0.002495
2017/08/29 18:52:50 step 1: objective=1.059477 reg=0.002494
2017/08/29 18:52:53 step 2: objective=1.061348 reg=0.002495
2017/08/29 18:52:56 step 3: objective=1.063932 reg=0.002495
2017/08/29 18:52:59 step 4: objective=1.065974 reg=0.002494
2017/08/29 18:53:02 step 5: objective=1.067789 reg=0.002494
2017/08/29 18:53:05 step 6: objective=1.069257 reg=0.002494
2017/08/29 18:53:08 step 7: objective=1.070260 reg=0.002494
2017/08/29 18:53:08 Training value function...
2017/08/29 18:53:11 step 0: mse=131.366183 step=0.100000
2017/08/29 18:53:13 step 1: mse=130.378925 step=0.100000
2017/08/29 18:53:14 step 2: mse=129.026281 step=0.100000
2017/08/29 18:53:16 step 3: mse=127.996516 step=0.100000
2017/08/29 18:53:18 step 4: mse=127.149137 step=0.100000
2017/08/29 18:53:19 step 5: mse=126.242514 step=0.100000
2017/08/29 18:53:21 step 6: mse=125.359327 step=0.100000
2017/08/29 18:53:22 step 7: mse=124.745470 step=0.100000
2017/08/29 18:53:22 Saving...
2017/08/29 18:53:22 Gathering batch of experience...
2017/08/29 18:54:11 batch 240: mean=419.388889 stddev=219.976296 entropy=0.250723 frames=7072 count=18
2017/08/29 18:54:11 Training policy...
2017/08/29 18:54:18 tune 0: objective=0.936484 reg=0.002507 prune=0
2017/08/29 18:54:23 tune 1: objective=0.938233 reg=0.002507 prune=0
2017/08/29 18:54:27 tune 2: objective=0.939964 reg=0.002508 prune=0
2017/08/29 18:54:32 tune 3: objective=0.941683 reg=0.002508 prune=0
2017/08/29 18:54:36 tune 4: objective=0.943392 reg=0.002508 prune=0
2017/08/29 18:54:41 tune 5: objective=0.945092 reg=0.002508 prune=0
2017/08/29 18:54:45 tune 6: objective=0.946780 reg=0.002508 prune=0
2017/08/29 18:54:49 tune 7: objective=0.948387 reg=0.002508 prune=0
2017/08/29 18:54:52 step 0: objective=0.949881 reg=0.002509
2017/08/29 18:54:55 step 1: objective=0.951340 reg=0.002509
2017/08/29 18:54:58 step 2: objective=0.952950 reg=0.002510
2017/08/29 18:55:01 step 3: objective=0.954902 reg=0.002510
2017/08/29 18:55:04 step 4: objective=0.956255 reg=0.002510
2017/08/29 18:55:06 step 5: objective=0.957439 reg=0.002510
2017/08/29 18:55:09 step 6: objective=0.959060 reg=0.002510
2017/08/29 18:55:12 step 7: objective=0.959955 reg=0.002510
2017/08/29 18:55:12 Training value function...
2017/08/29 18:55:15 step 0: mse=112.151464 step=0.100000
2017/08/29 18:55:16 step 1: mse=111.483526 step=0.100000
2017/08/29 18:55:18 step 2: mse=110.886694 step=0.100000
2017/08/29 18:55:19 step 3: mse=110.325419 step=0.100000
2017/08/29 18:55:21 step 4: mse=109.740813 step=0.100000
2017/08/29 18:55:22 step 5: mse=109.325279 step=0.100000
2017/08/29 18:55:24 step 6: mse=109.011078 step=0.100000
2017/08/29 18:55:25 step 7: mse=108.619338 step=0.100000
2017/08/29 18:55:25 Saving...
2017/08/29 18:55:26 Gathering batch of experience...
2017/08/29 18:56:16 batch 241: mean=456.444444 stddev=167.344695 entropy=0.251193 frames=7742 count=18
2017/08/29 18:56:16 Training policy...
2017/08/29 18:56:24 tune 0: objective=0.831546 reg=0.002512 prune=0
2017/08/29 18:56:29 tune 1: objective=0.833412 reg=0.002511 prune=0
2017/08/29 18:56:33 tune 2: objective=0.835260 reg=0.002510 prune=0
2017/08/29 18:56:38 tune 3: objective=0.837093 reg=0.002510 prune=0
2017/08/29 18:56:43 tune 4: objective=0.838907 reg=0.002509 prune=0
2017/08/29 18:56:48 tune 5: objective=0.840638 reg=0.002508 prune=0
2017/08/29 18:56:53 tune 6: objective=0.842238 reg=0.002508 prune=0
2017/08/29 18:56:58 tune 7: objective=0.843813 reg=0.002507 prune=0
2017/08/29 18:57:01 step 0: objective=0.845329 reg=0.002507
2017/08/29 18:57:04 step 1: objective=0.846887 reg=0.002506
2017/08/29 18:57:07 step 2: objective=0.848810 reg=0.002506
2017/08/29 18:57:10 step 3: objective=0.850411 reg=0.002506
2017/08/29 18:57:13 step 4: objective=0.851607 reg=0.002506
2017/08/29 18:57:16 step 5: objective=0.853024 reg=0.002506
2017/08/29 18:57:19 step 6: objective=0.854239 reg=0.002506
2017/08/29 18:57:23 step 7: objective=0.855234 reg=0.002506
2017/08/29 18:57:23 Training value function...
2017/08/29 18:57:26 step 0: mse=116.569518 step=0.100000
2017/08/29 18:57:27 step 1: mse=115.548099 step=0.100000
2017/08/29 18:57:29 step 2: mse=114.524672 step=0.100000
2017/08/29 18:57:31 step 3: mse=113.433466 step=0.100000
2017/08/29 18:57:32 step 4: mse=112.722275 step=0.100000
2017/08/29 18:57:34 step 5: mse=112.034491 step=0.100000
2017/08/29 18:57:36 step 6: mse=111.525521 step=0.100000
2017/08/29 18:57:37 step 7: mse=111.158454 step=0.100000
2017/08/29 18:57:37 Saving...
2017/08/29 18:57:37 Gathering batch of experience...
2017/08/29 18:58:30 batch 242: mean=307.500000 stddev=227.205304 entropy=0.251717 frames=7607 count=26
2017/08/29 18:58:30 Training policy...
2017/08/29 18:58:38 tune 0: objective=0.560790 reg=0.002517 prune=0
2017/08/29 18:58:43 tune 1: objective=0.563561 reg=0.002517 prune=0
2017/08/29 18:58:48 tune 2: objective=0.566287 reg=0.002517 prune=0
2017/08/29 18:58:52 tune 3: objective=0.568971 reg=0.002516 prune=0
2017/08/29 18:58:57 tune 4: objective=0.571589 reg=0.002516 prune=0
2017/08/29 18:59:02 tune 5: objective=0.573875 reg=0.002516 prune=0
2017/08/29 18:59:07 tune 6: objective=0.575933 reg=0.002516 prune=0
2017/08/29 18:59:12 tune 7: objective=0.577830 reg=0.002516 prune=0
2017/08/29 18:59:15 step 0: objective=0.579549 reg=0.002516
2017/08/29 18:59:18 step 1: objective=0.581843 reg=0.002516
2017/08/29 18:59:21 step 2: objective=0.583474 reg=0.002516
2017/08/29 18:59:24 step 3: objective=0.584958 reg=0.002516
2017/08/29 18:59:27 step 4: objective=0.586058 reg=0.002515
2017/08/29 18:59:30 step 5: objective=0.587599 reg=0.002515
2017/08/29 18:59:33 step 6: objective=0.588561 reg=0.002515
2017/08/29 18:59:36 step 7: objective=0.590325 reg=0.002515
2017/08/29 18:59:36 Training value function...
2017/08/29 18:59:39 step 0: mse=132.005786 step=0.100000
2017/08/29 18:59:41 step 1: mse=130.276814 step=0.100000
2017/08/29 18:59:42 step 2: mse=128.957496 step=0.100000
2017/08/29 18:59:44 step 3: mse=127.780284 step=0.100000
2017/08/29 18:59:46 step 4: mse=126.818340 step=0.100000
2017/08/29 18:59:47 step 5: mse=125.938444 step=0.100000
2017/08/29 18:59:49 step 6: mse=125.334068 step=0.100000
2017/08/29 18:59:50 step 7: mse=124.678234 step=0.100000
2017/08/29 18:59:50 Saving...
2017/08/29 18:59:51 Gathering batch of experience...
2017/08/29 19:00:45 batch 243: mean=335.640000 stddev=228.132397 entropy=0.247128 frames=7909 count=25
2017/08/29 19:00:45 Training policy...
2017/08/29 19:00:54 tune 0: objective=0.935929 reg=0.002471 prune=0
2017/08/29 19:00:59 tune 1: objective=0.938150 reg=0.002471 prune=0
2017/08/29 19:01:04 tune 2: objective=0.940358 reg=0.002471 prune=0
2017/08/29 19:01:09 tune 3: objective=0.942555 reg=0.002471 prune=0
2017/08/29 19:01:14 tune 4: objective=0.944740 reg=0.002471 prune=0
2017/08/29 19:01:19 tune 5: objective=0.946902 reg=0.002471 prune=0
2017/08/29 19:01:24 tune 6: objective=0.948941 reg=0.002471 prune=0
2017/08/29 19:01:28 tune 7: objective=0.950922 reg=0.002471 prune=0
2017/08/29 19:01:32 step 0: objective=0.952815 reg=0.002471
2017/08/29 19:01:35 step 1: objective=0.956057 reg=0.002470
2017/08/29 19:01:38 step 2: objective=0.958652 reg=0.002471
2017/08/29 19:01:41 step 3: objective=0.960685 reg=0.002471
2017/08/29 19:01:44 step 4: objective=0.962213 reg=0.002471
2017/08/29 19:01:48 step 5: objective=0.964076 reg=0.002471
2017/08/29 19:01:51 step 6: objective=0.965621 reg=0.002472
2017/08/29 19:01:54 step 7: objective=0.967034 reg=0.002472
2017/08/29 19:01:54 Training value function...
2017/08/29 19:01:57 step 0: mse=136.016901 step=0.100000
2017/08/29 19:01:59 step 1: mse=134.132276 step=0.100000
2017/08/29 19:02:00 step 2: mse=132.857856 step=0.100000
2017/08/29 19:02:02 step 3: mse=131.566681 step=0.100000
2017/08/29 19:02:04 step 4: mse=130.313558 step=0.100000
2017/08/29 19:02:05 step 5: mse=129.167883 step=0.100000
2017/08/29 19:02:07 step 6: mse=128.229542 step=0.100000
2017/08/29 19:02:09 step 7: mse=127.319709 step=0.100000
2017/08/29 19:02:09 Saving...
2017/08/29 19:02:09 Gathering batch of experience...
2017/08/29 19:02:58 batch 244: mean=466.411765 stddev=211.488578 entropy=0.246966 frames=7431 count=17
2017/08/29 19:02:58 Training policy...
2017/08/29 19:03:06 tune 0: objective=1.381783 reg=0.002470 prune=0
2017/08/29 19:03:10 tune 1: objective=1.383477 reg=0.002469 prune=0
2017/08/29 19:03:15 tune 2: objective=1.385167 reg=0.002469 prune=0
2017/08/29 19:03:20 tune 3: objective=1.386848 reg=0.002469 prune=0
2017/08/29 19:03:24 tune 4: objective=1.388529 reg=0.002469 prune=0
2017/08/29 19:03:29 tune 5: objective=1.390205 reg=0.002469 prune=0
2017/08/29 19:03:34 tune 6: objective=1.391808 reg=0.002469 prune=0
2017/08/29 19:03:38 tune 7: objective=1.393358 reg=0.002469 prune=0
2017/08/29 19:03:41 step 0: objective=1.394915 reg=0.002468
2017/08/29 19:03:44 step 1: objective=1.396814 reg=0.002468
2017/08/29 19:03:47 step 2: objective=1.399098 reg=0.002468
2017/08/29 19:03:50 step 3: objective=1.401283 reg=0.002468
2017/08/29 19:03:53 step 4: objective=1.402659 reg=0.002468
2017/08/29 19:03:56 step 5: objective=1.403774 reg=0.002468
2017/08/29 19:03:59 step 6: objective=1.405053 reg=0.002469
2017/08/29 19:04:02 step 7: objective=1.405926 reg=0.002469
2017/08/29 19:04:02 Training value function...
2017/08/29 19:04:05 step 0: mse=129.966431 step=0.100000
2017/08/29 19:04:07 step 1: mse=127.927883 step=0.100000
2017/08/29 19:04:08 step 2: mse=126.013452 step=0.100000
2017/08/29 19:04:10 step 3: mse=124.286822 step=0.100000
2017/08/29 19:04:12 step 4: mse=122.903970 step=0.100000
2017/08/29 19:04:13 step 5: mse=121.534179 step=0.100000
2017/08/29 19:04:15 step 6: mse=120.294253 step=0.100000
2017/08/29 19:04:16 step 7: mse=119.208640 step=0.100000
2017/08/29 19:04:16 Saving...
2017/08/29 19:04:16 Gathering batch of experience...
2017/08/29 19:05:09 batch 245: mean=518.352941 stddev=153.022083 entropy=0.256540 frames=8424 count=17
2017/08/29 19:05:09 Training policy...
2017/08/29 19:05:18 tune 0: objective=1.037504 reg=0.002565 prune=0
2017/08/29 19:05:23 tune 1: objective=1.039030 reg=0.002565 prune=0
2017/08/29 19:05:28 tune 2: objective=1.040554 reg=0.002566 prune=0
2017/08/29 19:05:34 tune 3: objective=1.042070 reg=0.002566 prune=0
2017/08/29 19:05:39 tune 4: objective=1.043583 reg=0.002566 prune=0
2017/08/29 19:05:44 tune 5: objective=1.045087 reg=0.002566 prune=0
2017/08/29 19:05:50 tune 6: objective=1.046484 reg=0.002566 prune=0
2017/08/29 19:05:55 tune 7: objective=1.047867 reg=0.002566 prune=0
2017/08/29 19:05:58 step 0: objective=1.049186 reg=0.002566
2017/08/29 19:06:02 step 1: objective=1.050952 reg=0.002566
2017/08/29 19:06:05 step 2: objective=1.052166 reg=0.002567
2017/08/29 19:06:08 step 3: objective=1.054100 reg=0.002567
2017/08/29 19:06:12 step 4: objective=1.055271 reg=0.002567
2017/08/29 19:06:15 step 5: objective=1.056229 reg=0.002567
2017/08/29 19:06:19 step 6: objective=1.057151 reg=0.002567
2017/08/29 19:06:22 step 7: objective=1.058447 reg=0.002567
2017/08/29 19:06:22 Training value function...
2017/08/29 19:06:26 step 0: mse=107.203907 step=0.100000
2017/08/29 19:06:27 step 1: mse=106.376874 step=0.100000
2017/08/29 19:06:29 step 2: mse=105.625152 step=0.100000
2017/08/29 19:06:31 step 3: mse=105.130103 step=0.100000
2017/08/29 19:06:33 step 4: mse=104.645971 step=0.100000
2017/08/29 19:06:34 step 5: mse=104.211093 step=0.100000
2017/08/29 19:06:36 step 6: mse=103.670313 step=0.100000
2017/08/29 19:06:38 step 7: mse=103.209681 step=0.100000
2017/08/29 19:06:38 Saving...
2017/08/29 19:06:38 Gathering batch of experience...
2017/08/29 19:07:24 batch 246: mean=432.294118 stddev=234.208747 entropy=0.248265 frames=6465 count=17
2017/08/29 19:07:24 Training policy...
2017/08/29 19:07:31 tune 0: objective=1.993410 reg=0.002483 prune=0
2017/08/29 19:07:35 tune 1: objective=1.996002 reg=0.002482 prune=0
2017/08/29 19:07:39 tune 2: objective=1.998568 reg=0.002482 prune=0
2017/08/29 19:07:43 tune 3: objective=2.001106 reg=0.002482 prune=0
2017/08/29 19:07:47 tune 4: objective=2.003572 reg=0.002481 prune=0
2017/08/29 19:07:51 tune 5: objective=2.005890 reg=0.002481 prune=0
2017/08/29 19:07:56 tune 6: objective=2.008030 reg=0.002481 prune=0
2017/08/29 19:08:00 tune 7: objective=2.010162 reg=0.002480 prune=0
2017/08/29 19:08:02 step 0: objective=2.012228 reg=0.002480
2017/08/29 19:08:05 step 1: objective=2.013746 reg=0.002481
2017/08/29 19:08:07 step 2: objective=2.015602 reg=0.002481
2017/08/29 19:08:10 step 3: objective=2.017051 reg=0.002480
2017/08/29 19:08:13 step 4: objective=2.019180 reg=0.002479
2017/08/29 19:08:15 step 5: objective=2.020319 reg=0.002480
2017/08/29 19:08:18 step 6: objective=2.021413 reg=0.002480
2017/08/29 19:08:20 step 7: objective=2.022843 reg=0.002479
2017/08/29 19:08:20 Training value function...
2017/08/29 19:08:23 step 0: mse=180.319081 step=0.100000
2017/08/29 19:08:24 step 1: mse=176.032398 step=0.100000
2017/08/29 19:08:26 step 2: mse=172.662647 step=0.100000
2017/08/29 19:08:27 step 3: mse=169.548193 step=0.100000
2017/08/29 19:08:28 step 4: mse=166.953108 step=0.100000
2017/08/29 19:08:30 step 5: mse=164.267987 step=0.100000
2017/08/29 19:08:31 step 6: mse=162.118363 step=0.100000
2017/08/29 19:08:32 step 7: mse=160.065746 step=0.100000
2017/08/29 19:08:32 Saving...
2017/08/29 19:08:33 Gathering batch of experience...
2017/08/29 19:09:24 batch 247: mean=460.555556 stddev=187.489917 entropy=0.252060 frames=7805 count=18
2017/08/29 19:09:24 Training policy...
2017/08/29 19:09:33 tune 0: objective=0.692695 reg=0.002521 prune=0
2017/08/29 19:09:38 tune 1: objective=0.694353 reg=0.002521 prune=0
2017/08/29 19:09:43 tune 2: objective=0.696002 reg=0.002521 prune=0
2017/08/29 19:09:47 tune 3: objective=0.697645 reg=0.002521 prune=0
2017/08/29 19:09:52 tune 4: objective=0.699280 reg=0.002521 prune=0
2017/08/29 19:09:57 tune 5: objective=0.700910 reg=0.002521 prune=0
2017/08/29 19:10:02 tune 6: objective=0.702484 reg=0.002521 prune=0
2017/08/29 19:10:07 tune 7: objective=0.703865 reg=0.002521 prune=0
2017/08/29 19:10:10 step 0: objective=0.705148 reg=0.002521
2017/08/29 19:10:13 step 1: objective=0.706513 reg=0.002521
2017/08/29 19:10:17 step 2: objective=0.707837 reg=0.002521
2017/08/29 19:10:20 step 3: objective=0.709036 reg=0.002522
2017/08/29 19:10:23 step 4: objective=0.710086 reg=0.002522
2017/08/29 19:10:26 step 5: objective=0.710940 reg=0.002521
2017/08/29 19:10:29 step 6: objective=0.711657 reg=0.002521
2017/08/29 19:10:32 step 7: objective=0.712414 reg=0.002521
2017/08/29 19:10:32 Training value function...
2017/08/29 19:10:36 step 0: mse=105.081301 step=0.100000
2017/08/29 19:10:37 step 1: mse=104.774919 step=0.100000
2017/08/29 19:10:39 step 2: mse=104.139504 step=0.100000
2017/08/29 19:10:41 step 3: mse=103.952686 step=0.100000
2017/08/29 19:10:42 step 4: mse=103.478896 step=0.100000
2017/08/29 19:10:44 step 5: mse=103.089291 step=0.100000
2017/08/29 19:10:45 step 6: mse=102.894293 step=0.100000
2017/08/29 19:10:47 step 7: mse=102.482694 step=0.100000
2017/08/29 19:10:47 Saving...
2017/08/29 19:10:47 Gathering batch of experience...
2017/08/29 19:11:40 batch 248: mean=486.833333 stddev=220.677052 entropy=0.247307 frames=8168 count=18
2017/08/29 19:11:40 Training policy...
2017/08/29 19:11:49 tune 0: objective=1.137254 reg=0.002473 prune=0
2017/08/29 19:11:54 tune 1: objective=1.138930 reg=0.002473 prune=0
2017/08/29 19:11:59 tune 2: objective=1.140600 reg=0.002473 prune=0
2017/08/29 19:12:04 tune 3: objective=1.142273 reg=0.002473 prune=0
2017/08/29 19:12:09 tune 4: objective=1.143943 reg=0.002474 prune=0
2017/08/29 19:12:14 tune 5: objective=1.145520 reg=0.002474 prune=0
2017/08/29 19:12:20 tune 6: objective=1.147028 reg=0.002474 prune=0
2017/08/29 19:12:25 tune 7: objective=1.148531 reg=0.002474 prune=0
2017/08/29 19:12:28 step 0: objective=1.149894 reg=0.002474
2017/08/29 19:12:31 step 1: objective=1.152059 reg=0.002474
2017/08/29 19:12:35 step 2: objective=1.153424 reg=0.002474
2017/08/29 19:12:38 step 3: objective=1.154900 reg=0.002475
2017/08/29 19:12:41 step 4: objective=1.155714 reg=0.002474
2017/08/29 19:12:45 step 5: objective=1.156895 reg=0.002474
2017/08/29 19:12:48 step 6: objective=1.157731 reg=0.002475
2017/08/29 19:12:51 step 7: objective=1.159299 reg=0.002475
2017/08/29 19:12:51 Training value function...
2017/08/29 19:12:54 step 0: mse=128.611449 step=0.100000
2017/08/29 19:12:56 step 1: mse=127.315457 step=0.100000
2017/08/29 19:12:58 step 2: mse=126.045566 step=0.100000
2017/08/29 19:13:00 step 3: mse=124.907434 step=0.100000
2017/08/29 19:13:01 step 4: mse=124.170993 step=0.100000
2017/08/29 19:13:03 step 5: mse=123.345486 step=0.100000
2017/08/29 19:13:05 step 6: mse=122.669188 step=0.100000
2017/08/29 19:13:06 step 7: mse=121.832364 step=0.100000
2017/08/29 19:13:06 Saving...
2017/08/29 19:13:07 Gathering batch of experience...
2017/08/29 19:14:01 batch 249: mean=317.538462 stddev=193.912199 entropy=0.250899 frames=7838 count=26
2017/08/29 19:14:01 Training policy...
2017/08/29 19:14:09 tune 0: objective=0.284627 reg=0.002509 prune=0
2017/08/29 19:14:14 tune 1: objective=0.287216 reg=0.002509 prune=0
2017/08/29 19:14:19 tune 2: objective=0.289780 reg=0.002508 prune=0
2017/08/29 19:14:24 tune 3: objective=0.292318 reg=0.002508 prune=0
2017/08/29 19:14:29 tune 4: objective=0.294832 reg=0.002507 prune=0
2017/08/29 19:14:34 tune 5: objective=0.297220 reg=0.002507 prune=0
2017/08/29 19:14:38 tune 6: objective=0.299415 reg=0.002506 prune=0
2017/08/29 19:14:43 tune 7: objective=0.301488 reg=0.002506 prune=0
2017/08/29 19:14:47 step 0: objective=0.303393 reg=0.002505
2017/08/29 19:14:50 step 1: objective=0.305662 reg=0.002505
2017/08/29 19:14:53 step 2: objective=0.308126 reg=0.002505
2017/08/29 19:14:56 step 3: objective=0.310294 reg=0.002505
2017/08/29 19:14:59 step 4: objective=0.311684 reg=0.002504
2017/08/29 19:15:02 step 5: objective=0.314599 reg=0.002503
2017/08/29 19:15:06 step 6: objective=0.316297 reg=0.002503
2017/08/29 19:15:09 step 7: objective=0.317996 reg=0.002503
2017/08/29 19:15:09 Training value function...
2017/08/29 19:15:12 step 0: mse=115.393964 step=0.100000
2017/08/29 19:15:14 step 1: mse=114.659511 step=0.100000
2017/08/29 19:15:15 step 2: mse=113.911345 step=0.100000
2017/08/29 19:15:17 step 3: mse=113.507682 step=0.100000
2017/08/29 19:15:19 step 4: mse=113.209211 step=0.100000
2017/08/29 19:15:20 step 5: mse=112.863030 step=0.100000
2017/08/29 19:15:22 step 6: mse=112.657964 step=0.100000
2017/08/29 19:15:23 step 7: mse=112.402739 step=0.100000
2017/08/29 19:15:23 Saving...
2017/08/29 19:15:24 Gathering batch of experience...
2017/08/29 19:16:13 batch 250: mean=429.157895 stddev=217.493923 entropy=0.250439 frames=7611 count=19
2017/08/29 19:16:13 Training policy...
2017/08/29 19:16:21 tune 0: objective=1.515176 reg=0.002504 prune=0
2017/08/29 19:16:26 tune 1: objective=1.516931 reg=0.002504 prune=0
2017/08/29 19:16:31 tune 2: objective=1.518671 reg=0.002504 prune=0
2017/08/29 19:16:36 tune 3: objective=1.520401 reg=0.002504 prune=0
2017/08/29 19:16:41 tune 4: objective=1.522124 reg=0.002504 prune=0
2017/08/29 19:16:45 tune 5: objective=1.523844 reg=0.002504 prune=0
2017/08/29 19:16:50 tune 6: objective=1.525463 reg=0.002503 prune=0
2017/08/29 19:16:55 tune 7: objective=1.527037 reg=0.002503 prune=0
2017/08/29 19:16:58 step 0: objective=1.528566 reg=0.002503
2017/08/29 19:17:01 step 1: objective=1.529816 reg=0.002503
2017/08/29 19:17:04 step 2: objective=1.532455 reg=0.002504
2017/08/29 19:17:07 step 3: objective=1.533525 reg=0.002504
2017/08/29 19:17:10 step 4: objective=1.534859 reg=0.002503
2017/08/29 19:17:13 step 5: objective=1.536294 reg=0.002502
2017/08/29 19:17:17 step 6: objective=1.537291 reg=0.002502
2017/08/29 19:17:20 step 7: objective=1.538409 reg=0.002502
2017/08/29 19:17:20 Training value function...
2017/08/29 19:17:23 step 0: mse=138.911592 step=0.100000
2017/08/29 19:17:24 step 1: mse=137.152223 step=0.100000
2017/08/29 19:17:26 step 2: mse=135.596371 step=0.100000
2017/08/29 19:17:28 step 3: mse=134.311023 step=0.100000
2017/08/29 19:17:29 step 4: mse=133.099320 step=0.100000
2017/08/29 19:17:31 step 5: mse=131.878226 step=0.100000
2017/08/29 19:17:32 step 6: mse=130.991479 step=0.100000
2017/08/29 19:17:34 step 7: mse=130.129511 step=0.100000
2017/08/29 19:17:34 Saving...
2017/08/29 19:17:34 Gathering batch of experience...
2017/08/29 19:18:24 batch 251: mean=374.000000 stddev=192.419185 entropy=0.247951 frames=7354 count=21
2017/08/29 19:18:24 Training policy...
2017/08/29 19:18:32 tune 0: objective=0.853802 reg=0.002480 prune=0
2017/08/29 19:18:36 tune 1: objective=0.856301 reg=0.002479 prune=0
2017/08/29 19:18:41 tune 2: objective=0.858780 reg=0.002479 prune=0
2017/08/29 19:18:46 tune 3: objective=0.861237 reg=0.002479 prune=0
2017/08/29 19:18:50 tune 4: objective=0.863677 reg=0.002479 prune=0
2017/08/29 19:18:55 tune 5: objective=0.866096 reg=0.002479 prune=0
2017/08/29 19:18:59 tune 6: objective=0.868499 reg=0.002479 prune=0
2017/08/29 19:19:04 tune 7: objective=0.870748 reg=0.002479 prune=0
2017/08/29 19:19:07 step 0: objective=0.872797 reg=0.002479
2017/08/29 19:19:10 step 1: objective=0.874449 reg=0.002480
2017/08/29 19:19:13 step 2: objective=0.875654 reg=0.002480
2017/08/29 19:19:16 step 3: objective=0.876882 reg=0.002480
2017/08/29 19:19:19 step 4: objective=0.878627 reg=0.002480
2017/08/29 19:19:22 step 5: objective=0.880490 reg=0.002480
2017/08/29 19:19:25 step 6: objective=0.881992 reg=0.002481
2017/08/29 19:19:28 step 7: objective=0.883872 reg=0.002480
2017/08/29 19:19:28 Training value function...
2017/08/29 19:19:31 step 0: mse=144.368736 step=0.100000
2017/08/29 19:19:32 step 1: mse=142.982690 step=0.100000
2017/08/29 19:19:34 step 2: mse=142.073089 step=0.100000
2017/08/29 19:19:36 step 3: mse=140.902006 step=0.100000
2017/08/29 19:19:37 step 4: mse=139.933625 step=0.100000
2017/08/29 19:19:39 step 5: mse=139.092102 step=0.100000
2017/08/29 19:19:40 step 6: mse=138.442059 step=0.100000
2017/08/29 19:19:42 step 7: mse=137.897399 step=0.100000
2017/08/29 19:19:42 Saving...
2017/08/29 19:19:42 Gathering batch of experience...
2017/08/29 19:20:38 batch 252: mean=335.521739 stddev=210.282805 entropy=0.252181 frames=7672 count=23
2017/08/29 19:20:38 Training policy...
2017/08/29 19:20:46 tune 0: objective=0.209088 reg=0.002522 prune=0
2017/08/29 19:20:51 tune 1: objective=0.210961 reg=0.002521 prune=0
2017/08/29 19:20:56 tune 2: objective=0.212818 reg=0.002521 prune=0
2017/08/29 19:21:01 tune 3: objective=0.214660 reg=0.002521 prune=0
2017/08/29 19:21:06 tune 4: objective=0.216485 reg=0.002521 prune=0
2017/08/29 19:21:11 tune 5: objective=0.218296 reg=0.002520 prune=0
2017/08/29 19:21:15 tune 6: objective=0.220070 reg=0.002520 prune=0
2017/08/29 19:21:20 tune 7: objective=0.221737 reg=0.002520 prune=0
2017/08/29 19:21:23 step 0: objective=0.223322 reg=0.002519
2017/08/29 19:21:26 step 1: objective=0.225202 reg=0.002519
2017/08/29 19:21:30 step 2: objective=0.226386 reg=0.002519
2017/08/29 19:21:33 step 3: objective=0.227763 reg=0.002519
2017/08/29 19:21:36 step 4: objective=0.229152 reg=0.002519
2017/08/29 19:21:39 step 5: objective=0.230160 reg=0.002519
2017/08/29 19:21:42 step 6: objective=0.231410 reg=0.002519
2017/08/29 19:21:45 step 7: objective=0.232223 reg=0.002518
2017/08/29 19:21:45 Training value function...
2017/08/29 19:21:48 step 0: mse=111.233588 step=0.100000
2017/08/29 19:21:50 step 1: mse=109.668682 step=0.100000
2017/08/29 19:21:51 step 2: mse=108.665995 step=0.100000
2017/08/29 19:21:53 step 3: mse=107.490687 step=0.100000
2017/08/29 19:21:55 step 4: mse=106.659620 step=0.100000
2017/08/29 19:21:56 step 5: mse=106.011583 step=0.100000
2017/08/29 19:21:58 step 6: mse=105.489599 step=0.100000
2017/08/29 19:22:00 step 7: mse=105.180560 step=0.100000
2017/08/29 19:22:00 Saving...
2017/08/29 19:22:00 Gathering batch of experience...
2017/08/29 19:22:56 batch 253: mean=411.285714 stddev=223.265621 entropy=0.249350 frames=8014 count=21
2017/08/29 19:22:56 Training policy...
2017/08/29 19:23:04 tune 0: objective=1.792000 reg=0.002494 prune=0
2017/08/29 19:23:09 tune 1: objective=1.793875 reg=0.002493 prune=0
2017/08/29 19:23:14 tune 2: objective=1.795744 reg=0.002493 prune=0
2017/08/29 19:23:19 tune 3: objective=1.797603 reg=0.002493 prune=0
2017/08/29 19:23:24 tune 4: objective=1.799453 reg=0.002493 prune=0
2017/08/29 19:23:30 tune 5: objective=1.801262 reg=0.002493 prune=0
2017/08/29 19:23:35 tune 6: objective=1.802961 reg=0.002492 prune=0
2017/08/29 19:23:40 tune 7: objective=1.804577 reg=0.002492 prune=0
2017/08/29 19:23:43 step 0: objective=1.806157 reg=0.002492
2017/08/29 19:23:46 step 1: objective=1.807466 reg=0.002491
2017/08/29 19:23:49 step 2: objective=1.809424 reg=0.002492
2017/08/29 19:23:53 step 3: objective=1.811452 reg=0.002491
2017/08/29 19:23:56 step 4: objective=1.812686 reg=0.002491
2017/08/29 19:23:59 step 5: objective=1.815329 reg=0.002491
2017/08/29 19:24:02 step 6: objective=1.816992 reg=0.002490
2017/08/29 19:24:06 step 7: objective=1.818065 reg=0.002490
2017/08/29 19:24:06 Training value function...
2017/08/29 19:24:09 step 0: mse=142.597245 step=0.100000
2017/08/29 19:24:11 step 1: mse=138.827838 step=0.100000
2017/08/29 19:24:12 step 2: mse=135.776692 step=0.100000
2017/08/29 19:24:14 step 3: mse=133.182419 step=0.100000
2017/08/29 19:24:16 step 4: mse=130.875720 step=0.100000
2017/08/29 19:24:17 step 5: mse=129.016710 step=0.100000
2017/08/29 19:24:19 step 6: mse=127.228259 step=0.100000
2017/08/29 19:24:21 step 7: mse=126.013246 step=0.100000
2017/08/29 19:24:21 Saving...
2017/08/29 19:24:21 Gathering batch of experience...
2017/08/29 19:25:11 batch 254: mean=500.588235 stddev=201.402745 entropy=0.250468 frames=7622 count=17
2017/08/29 19:25:11 Training policy...
2017/08/29 19:25:19 tune 0: objective=2.083425 reg=0.002505 prune=0
2017/08/29 19:25:24 tune 1: objective=2.085327 reg=0.002504 prune=0
2017/08/29 19:25:29 tune 2: objective=2.087226 reg=0.002504 prune=0
2017/08/29 19:25:33 tune 3: objective=2.089109 reg=0.002503 prune=0
2017/08/29 19:25:38 tune 4: objective=2.090978 reg=0.002503 prune=0
2017/08/29 19:25:43 tune 5: objective=2.092737 reg=0.002502 prune=0
2017/08/29 19:25:48 tune 6: objective=2.094371 reg=0.002502 prune=0
2017/08/29 19:25:53 tune 7: objective=2.095931 reg=0.002502 prune=0
2017/08/29 19:25:56 step 0: objective=2.097426 reg=0.002501
2017/08/29 19:25:59 step 1: objective=2.098948 reg=0.002501
2017/08/29 19:26:02 step 2: objective=2.100426 reg=0.002500
2017/08/29 19:26:05 step 3: objective=2.101477 reg=0.002500
2017/08/29 19:26:08 step 4: objective=2.103419 reg=0.002499
2017/08/29 19:26:11 step 5: objective=2.105526 reg=0.002499
2017/08/29 19:26:14 step 6: objective=2.106971 reg=0.002499
2017/08/29 19:26:17 step 7: objective=2.108171 reg=0.002499
2017/08/29 19:26:17 Training value function...
2017/08/29 19:26:20 step 0: mse=148.825033 step=0.100000
2017/08/29 19:26:22 step 1: mse=144.099095 step=0.100000
2017/08/29 19:26:24 step 2: mse=139.574213 step=0.100000
2017/08/29 19:26:25 step 3: mse=135.800513 step=0.100000
2017/08/29 19:26:27 step 4: mse=132.254578 step=0.100000
2017/08/29 19:26:29 step 5: mse=129.423528 step=0.100000
2017/08/29 19:26:30 step 6: mse=127.238701 step=0.100000
2017/08/29 19:26:32 step 7: mse=125.159000 step=0.100000
2017/08/29 19:26:32 Saving...
2017/08/29 19:26:32 Gathering batch of experience...
2017/08/29 19:27:24 batch 255: mean=525.823529 stddev=167.490556 entropy=0.248774 frames=8172 count=17
2017/08/29 19:27:24 Training policy...
2017/08/29 19:27:32 tune 0: objective=1.233656 reg=0.002488 prune=0
2017/08/29 19:27:38 tune 1: objective=1.235280 reg=0.002488 prune=0
2017/08/29 19:27:43 tune 2: objective=1.236893 reg=0.002487 prune=0
2017/08/29 19:27:48 tune 3: objective=1.238499 reg=0.002487 prune=0
2017/08/29 19:27:53 tune 4: objective=1.240097 reg=0.002487 prune=0
2017/08/29 19:27:58 tune 5: objective=1.241685 reg=0.002487 prune=0
2017/08/29 19:28:04 tune 6: objective=1.243243 reg=0.002487 prune=0
2017/08/29 19:28:09 tune 7: objective=1.244696 reg=0.002487 prune=0
2017/08/29 19:28:12 step 0: objective=1.246107 reg=0.002487
2017/08/29 19:28:15 step 1: objective=1.247371 reg=0.002486
2017/08/29 19:28:19 step 2: objective=1.249068 reg=0.002487
2017/08/29 19:28:22 step 3: objective=1.251790 reg=0.002486
2017/08/29 19:28:25 step 4: objective=1.253331 reg=0.002486
2017/08/29 19:28:29 step 5: objective=1.255302 reg=0.002485
2017/08/29 19:28:32 step 6: objective=1.256402 reg=0.002485
2017/08/29 19:28:35 step 7: objective=1.257826 reg=0.002485
2017/08/29 19:28:35 Training value function...
2017/08/29 19:28:39 step 0: mse=109.661223 step=0.100000
2017/08/29 19:28:40 step 1: mse=108.080939 step=0.100000
2017/08/29 19:28:42 step 2: mse=106.852054 step=0.100000
2017/08/29 19:28:44 step 3: mse=105.704185 step=0.100000
2017/08/29 19:28:45 step 4: mse=104.767377 step=0.100000
2017/08/29 19:28:47 step 5: mse=103.941341 step=0.100000
2017/08/29 19:28:49 step 6: mse=103.147086 step=0.100000
2017/08/29 19:28:51 step 7: mse=102.378752 step=0.100000
2017/08/29 19:28:51 Saving...
2017/08/29 19:28:51 Gathering batch of experience...
2017/08/29 19:29:42 batch 256: mean=372.909091 stddev=244.381019 entropy=0.245816 frames=7436 count=22
2017/08/29 19:29:42 Training policy...
2017/08/29 19:29:50 tune 0: objective=0.950223 reg=0.002458 prune=0
2017/08/29 19:29:55 tune 1: objective=0.952398 reg=0.002458 prune=0
2017/08/29 19:30:00 tune 2: objective=0.954559 reg=0.002458 prune=0
2017/08/29 19:30:04 tune 3: objective=0.956703 reg=0.002458 prune=0
2017/08/29 19:30:09 tune 4: objective=0.958841 reg=0.002458 prune=0
2017/08/29 19:30:14 tune 5: objective=0.960963 reg=0.002458 prune=0
2017/08/29 19:30:19 tune 6: objective=0.962917 reg=0.002458 prune=0
2017/08/29 19:30:23 tune 7: objective=0.964841 reg=0.002458 prune=0
2017/08/29 19:30:26 step 0: objective=0.966714 reg=0.002458
2017/08/29 19:30:29 step 1: objective=0.968813 reg=0.002459
2017/08/29 19:30:32 step 2: objective=0.970839 reg=0.002459
2017/08/29 19:30:35 step 3: objective=0.973931 reg=0.002460
2017/08/29 19:30:38 step 4: objective=0.975393 reg=0.002460
2017/08/29 19:30:41 step 5: objective=0.976585 reg=0.002460
2017/08/29 19:30:44 step 6: objective=0.978390 reg=0.002460
2017/08/29 19:30:47 step 7: objective=0.979611 reg=0.002461
2017/08/29 19:30:47 Training value function...
2017/08/29 19:30:50 step 0: mse=136.029221 step=0.100000
2017/08/29 19:30:52 step 1: mse=135.500666 step=0.100000
2017/08/29 19:30:54 step 2: mse=134.986518 step=0.100000
2017/08/29 19:30:55 step 3: mse=134.229962 step=0.100000
2017/08/29 19:30:57 step 4: mse=133.788908 step=0.100000
2017/08/29 19:30:58 step 5: mse=133.090740 step=0.100000
2017/08/29 19:31:00 step 6: mse=132.528958 step=0.100000
2017/08/29 19:31:01 step 7: mse=131.853966 step=0.100000
2017/08/29 19:31:01 Saving...
2017/08/29 19:31:02 Gathering batch of experience...
2017/08/29 19:31:54 batch 257: mean=448.300000 stddev=193.654099 entropy=0.247242 frames=8076 count=20
2017/08/29 19:31:54 Training policy...
2017/08/29 19:32:03 tune 0: objective=1.112886 reg=0.002472 prune=0
2017/08/29 19:32:08 tune 1: objective=1.115308 reg=0.002472 prune=0
2017/08/29 19:32:13 tune 2: objective=1.117710 reg=0.002471 prune=0
2017/08/29 19:32:18 tune 3: objective=1.120096 reg=0.002471 prune=0
2017/08/29 19:32:23 tune 4: objective=1.122465 reg=0.002470 prune=0
2017/08/29 19:32:29 tune 5: objective=1.124734 reg=0.002469 prune=0
2017/08/29 19:32:34 tune 6: objective=1.126732 reg=0.002469 prune=0
2017/08/29 19:32:39 tune 7: objective=1.128529 reg=0.002468 prune=0
2017/08/29 19:32:42 step 0: objective=1.130269 reg=0.002468
2017/08/29 19:32:45 step 1: objective=1.131566 reg=0.002468
2017/08/29 19:32:49 step 2: objective=1.133302 reg=0.002467
2017/08/29 19:32:52 step 3: objective=1.135199 reg=0.002467
2017/08/29 19:32:55 step 4: objective=1.136716 reg=0.002467
2017/08/29 19:32:58 step 5: objective=1.137839 reg=0.002466
2017/08/29 19:33:02 step 6: objective=1.138739 reg=0.002466
2017/08/29 19:33:05 step 7: objective=1.141091 reg=0.002466
2017/08/29 19:33:05 Training value function...
2017/08/29 19:33:08 step 0: mse=129.689880 step=0.100000
2017/08/29 19:33:10 step 1: mse=127.425712 step=0.100000
2017/08/29 19:33:12 step 2: mse=125.407150 step=0.100000
2017/08/29 19:33:14 step 3: mse=123.949400 step=0.100000
2017/08/29 19:33:15 step 4: mse=122.713318 step=0.100000
2017/08/29 19:33:17 step 5: mse=121.734138 step=0.100000
2017/08/29 19:33:19 step 6: mse=120.648280 step=0.100000
2017/08/29 19:33:20 step 7: mse=119.738289 step=0.100000
2017/08/29 19:33:20 Saving...
2017/08/29 19:33:21 Gathering batch of experience...
2017/08/29 19:34:11 batch 258: mean=393.600000 stddev=185.354363 entropy=0.245609 frames=7745 count=20
2017/08/29 19:34:11 Training policy...
2017/08/29 19:34:19 tune 0: objective=-0.104182 reg=0.002456 prune=0
2017/08/29 19:34:24 tune 1: objective=-0.102199 reg=0.002456 prune=0
2017/08/29 19:34:29 tune 2: objective=-0.100232 reg=0.002456 prune=0
2017/08/29 19:34:34 tune 3: objective=-0.098278 reg=0.002455 prune=0
2017/08/29 19:34:39 tune 4: objective=-0.096338 reg=0.002455 prune=0
2017/08/29 19:34:44 tune 5: objective=-0.094483 reg=0.002455 prune=0
2017/08/29 19:34:49 tune 6: objective=-0.092763 reg=0.002454 prune=0
2017/08/29 19:34:54 tune 7: objective=-0.091126 reg=0.002454 prune=0
2017/08/29 19:34:57 step 0: objective=-0.089647 reg=0.002454
2017/08/29 19:35:00 step 1: objective=-0.088263 reg=0.002454
2017/08/29 19:35:03 step 2: objective=-0.086340 reg=0.002454
2017/08/29 19:35:06 step 3: objective=-0.085134 reg=0.002454
2017/08/29 19:35:09 step 4: objective=-0.084206 reg=0.002454
2017/08/29 19:35:12 step 5: objective=-0.082487 reg=0.002453
2017/08/29 19:35:16 step 6: objective=-0.080803 reg=0.002452
2017/08/29 19:35:19 step 7: objective=-0.080120 reg=0.002452
2017/08/29 19:35:19 Training value function...
2017/08/29 19:35:22 step 0: mse=94.945499 step=0.100000
2017/08/29 19:35:24 step 1: mse=92.893611 step=0.100000
2017/08/29 19:35:25 step 2: mse=91.346610 step=0.100000
2017/08/29 19:35:27 step 3: mse=89.987937 step=0.100000
2017/08/29 19:35:28 step 4: mse=89.082711 step=0.100000
2017/08/29 19:35:30 step 5: mse=88.431653 step=0.100000
2017/08/29 19:35:32 step 6: mse=88.002087 step=0.100000
2017/08/29 19:35:33 step 7: mse=87.614120 step=0.100000
2017/08/29 19:35:33 Saving...
2017/08/29 19:35:34 Gathering batch of experience...
2017/08/29 19:36:25 batch 259: mean=407.263158 stddev=219.828843 entropy=0.248189 frames=7116 count=19
2017/08/29 19:36:25 Training policy...
2017/08/29 19:36:33 tune 0: objective=1.581546 reg=0.002482 prune=0
2017/08/29 19:36:38 tune 1: objective=1.583561 reg=0.002482 prune=0
2017/08/29 19:36:42 tune 2: objective=1.585564 reg=0.002482 prune=0
2017/08/29 19:36:47 tune 3: objective=1.587565 reg=0.002482 prune=0
2017/08/29 19:36:51 tune 4: objective=1.589557 reg=0.002481 prune=0
2017/08/29 19:36:56 tune 5: objective=1.591496 reg=0.002481 prune=0
2017/08/29 19:37:00 tune 6: objective=1.593326 reg=0.002481 prune=0
2017/08/29 19:37:05 tune 7: objective=1.595125 reg=0.002481 prune=0
2017/08/29 19:37:08 step 0: objective=1.596877 reg=0.002481
2017/08/29 19:37:10 step 1: objective=1.599474 reg=0.002481
2017/08/29 19:37:13 step 2: objective=1.601422 reg=0.002482
2017/08/29 19:37:16 step 3: objective=1.603343 reg=0.002482
2017/08/29 19:37:19 step 4: objective=1.605145 reg=0.002482
2017/08/29 19:37:22 step 5: objective=1.606384 reg=0.002482
2017/08/29 19:37:25 step 6: objective=1.607314 reg=0.002482
2017/08/29 19:37:28 step 7: objective=1.609107 reg=0.002482
2017/08/29 19:37:28 Training value function...
2017/08/29 19:37:31 step 0: mse=151.553752 step=0.100000
2017/08/29 19:37:32 step 1: mse=146.067776 step=0.100000
2017/08/29 19:37:34 step 2: mse=141.551657 step=0.100000
2017/08/29 19:37:35 step 3: mse=137.919341 step=0.100000
2017/08/29 19:37:37 step 4: mse=135.555440 step=0.100000
2017/08/29 19:37:38 step 5: mse=133.201348 step=0.100000
2017/08/29 19:37:40 step 6: mse=131.268469 step=0.100000
2017/08/29 19:37:41 step 7: mse=129.334675 step=0.100000
2017/08/29 19:37:41 Saving...
2017/08/29 19:37:41 Gathering batch of experience...
2017/08/29 19:38:29 batch 260: mean=366.800000 stddev=243.854793 entropy=0.248500 frames=7009 count=20
2017/08/29 19:38:29 Training policy...
2017/08/29 19:38:37 tune 0: objective=0.654753 reg=0.002485 prune=0
2017/08/29 19:38:41 tune 1: objective=0.657261 reg=0.002484 prune=0
2017/08/29 19:38:46 tune 2: objective=0.659745 reg=0.002484 prune=0
2017/08/29 19:38:50 tune 3: objective=0.662210 reg=0.002483 prune=0
2017/08/29 19:38:55 tune 4: objective=0.664651 reg=0.002483 prune=0
2017/08/29 19:38:59 tune 5: objective=0.667075 reg=0.002482 prune=0
2017/08/29 19:39:04 tune 6: objective=0.669354 reg=0.002482 prune=0
2017/08/29 19:39:08 tune 7: objective=0.671257 reg=0.002481 prune=0
2017/08/29 19:39:11 step 0: objective=0.672993 reg=0.002481
2017/08/29 19:39:14 step 1: objective=0.674931 reg=0.002481
2017/08/29 19:39:17 step 2: objective=0.676407 reg=0.002480
2017/08/29 19:39:19 step 3: objective=0.677673 reg=0.002480
2017/08/29 19:39:22 step 4: objective=0.678847 reg=0.002481
2017/08/29 19:39:25 step 5: objective=0.679720 reg=0.002481
2017/08/29 19:39:28 step 6: objective=0.680639 reg=0.002481
2017/08/29 19:39:31 step 7: objective=0.681608 reg=0.002481
2017/08/29 19:39:31 Training value function...
2017/08/29 19:39:34 step 0: mse=125.364984 step=0.100000
2017/08/29 19:39:35 step 1: mse=124.382074 step=0.100000
2017/08/29 19:39:37 step 2: mse=123.444394 step=0.100000
2017/08/29 19:39:38 step 3: mse=122.593624 step=0.100000
2017/08/29 19:39:40 step 4: mse=121.913745 step=0.100000
2017/08/29 19:39:41 step 5: mse=121.307671 step=0.100000
2017/08/29 19:39:43 step 6: mse=120.728847 step=0.100000
2017/08/29 19:39:44 step 7: mse=120.129876 step=0.100000
2017/08/29 19:39:44 Saving...
2017/08/29 19:39:44 Gathering batch of experience...
2017/08/29 19:40:36 batch 261: mean=405.666667 stddev=242.742924 entropy=0.249670 frames=7721 count=21
2017/08/29 19:40:36 Training policy...
2017/08/29 19:40:44 tune 0: objective=1.724879 reg=0.002497 prune=0
2017/08/29 19:40:49 tune 1: objective=1.726808 reg=0.002496 prune=0
2017/08/29 19:40:54 tune 2: objective=1.728724 reg=0.002496 prune=0
2017/08/29 19:40:59 tune 3: objective=1.730625 reg=0.002496 prune=0
2017/08/29 19:41:04 tune 4: objective=1.732513 reg=0.002495 prune=0
2017/08/29 19:41:09 tune 5: objective=1.734388 reg=0.002495 prune=0
2017/08/29 19:41:14 tune 6: objective=1.736213 reg=0.002495 prune=0
2017/08/29 19:41:18 tune 7: objective=1.737831 reg=0.002495 prune=0
2017/08/29 19:41:22 step 0: objective=1.739320 reg=0.002495
2017/08/29 19:41:25 step 1: objective=1.742133 reg=0.002494
2017/08/29 19:41:28 step 2: objective=1.743709 reg=0.002495
2017/08/29 19:41:31 step 3: objective=1.744742 reg=0.002495
2017/08/29 19:41:34 step 4: objective=1.745878 reg=0.002495
2017/08/29 19:41:37 step 5: objective=1.747050 reg=0.002495
2017/08/29 19:41:40 step 6: objective=1.748372 reg=0.002495
2017/08/29 19:41:43 step 7: objective=1.749653 reg=0.002495
2017/08/29 19:41:43 Training value function...
2017/08/29 19:41:47 step 0: mse=139.222629 step=0.100000
2017/08/29 19:41:48 step 1: mse=135.727832 step=0.100000
2017/08/29 19:41:50 step 2: mse=132.759319 step=0.100000
