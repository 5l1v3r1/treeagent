2017/08/25 21:38:29 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.999 -maxtrees 5000]
2017/08/25 21:38:29 Creating environments...
2017/08/25 21:38:31 Creating new forest for: Breakout-ram-v0/actor.json
2017/08/25 21:38:31 Creating new forest for: Breakout-ram-v0/critic.json
2017/08/25 21:38:31 Running. Press Ctrl+C to stop.
2017/08/25 21:38:31 Gathering batch of experience...
2017/08/25 21:38:41 batch 0: mean=1.372093 stddev=1.220432 entropy=1.386295 frames=32450 count=129
2017/08/25 21:38:41 Training policy...
2017/08/25 21:38:43 step 0: objective=0.092661455
2017/08/25 21:38:43 step 1: objective=0.09271459
2017/08/25 21:38:44 step 2: objective=0.09276835
2017/08/25 21:38:44 step 3: objective=0.09282079
2017/08/25 21:38:45 step 4: objective=0.09287461
2017/08/25 21:38:45 step 5: objective=0.092928156
2017/08/25 21:38:45 step 6: objective=0.092928775
2017/08/25 21:38:46 step 7: objective=0.09294133
2017/08/25 21:38:46 Training value function...
2017/08/25 21:38:47 step 0: mse=0.387047 step=0.100000
2017/08/25 21:38:47 step 1: mse=0.334024 step=0.100000
2017/08/25 21:38:48 step 2: mse=0.290472 step=0.100000
2017/08/25 21:38:48 step 3: mse=0.255194 step=0.100000
2017/08/25 21:38:48 step 4: mse=0.226556 step=0.100000
2017/08/25 21:38:49 step 5: mse=0.203517 step=0.100000
2017/08/25 21:38:49 step 6: mse=0.184577 step=0.100000
2017/08/25 21:38:49 step 7: mse=0.169130 step=0.100000
2017/08/25 21:38:49 Saving...
2017/08/25 21:38:49 Gathering batch of experience...
2017/08/25 21:39:00 batch 1: mean=1.333333 stddev=1.360195 entropy=1.386196 frames=32086 count=129
2017/08/25 21:39:00 Training policy...
2017/08/25 21:39:01 step 0: objective=0.039023038
2017/08/25 21:39:02 step 1: objective=0.039041817
2017/08/25 21:39:02 step 2: objective=0.039060727
2017/08/25 21:39:02 step 3: objective=0.039079368
2017/08/25 21:39:03 step 4: objective=0.039098192
2017/08/25 21:39:03 step 5: objective=0.03911702
2017/08/25 21:39:04 step 6: objective=0.03913599
2017/08/25 21:39:04 step 7: objective=0.03915474
2017/08/25 21:39:04 Training value function...
2017/08/25 21:39:05 step 0: mse=0.166492 step=0.100000
2017/08/25 21:39:05 step 1: mse=0.155532 step=0.100000
2017/08/25 21:39:06 step 2: mse=0.146802 step=0.100000
2017/08/25 21:39:06 step 3: mse=0.139695 step=0.100000
2017/08/25 21:39:07 step 4: mse=0.133563 step=0.100000
2017/08/25 21:39:07 step 5: mse=0.128761 step=0.100000
2017/08/25 21:39:07 step 6: mse=0.124640 step=0.100000
2017/08/25 21:39:08 step 7: mse=0.121103 step=0.100000
2017/08/25 21:39:08 Saving...
2017/08/25 21:39:08 Gathering batch of experience...
2017/08/25 21:39:18 batch 2: mean=1.433071 stddev=1.319691 entropy=1.386087 frames=32142 count=127
2017/08/25 21:39:18 Training policy...
2017/08/25 21:39:19 step 0: objective=0.02422968
2017/08/25 21:39:20 step 1: objective=0.02425717
2017/08/25 21:39:20 step 2: objective=0.024285177
2017/08/25 21:39:21 step 3: objective=0.024313355
2017/08/25 21:39:21 step 4: objective=0.024341336
2017/08/25 21:39:22 step 5: objective=0.02436942
2017/08/25 21:39:22 step 6: objective=0.02439754
2017/08/25 21:39:22 step 7: objective=0.024425596
2017/08/25 21:39:22 Training value function...
2017/08/25 21:39:23 step 0: mse=0.131073 step=0.100000
2017/08/25 21:39:24 step 1: mse=0.126797 step=0.100000
2017/08/25 21:39:24 step 2: mse=0.123307 step=0.100000
2017/08/25 21:39:25 step 3: mse=0.120347 step=0.100000
2017/08/25 21:39:25 step 4: mse=0.118095 step=0.100000
2017/08/25 21:39:26 step 5: mse=0.115884 step=0.100000
2017/08/25 21:39:26 step 6: mse=0.114201 step=0.100000
2017/08/25 21:39:26 step 7: mse=0.112847 step=0.100000
2017/08/25 21:39:26 Saving...
2017/08/25 21:39:26 Gathering batch of experience...
2017/08/25 21:39:37 batch 3: mean=1.727273 stddev=1.471492 entropy=1.385880 frames=32379 count=121
2017/08/25 21:39:37 Training policy...
2017/08/25 21:39:38 step 0: objective=0.022611389
2017/08/25 21:39:38 step 1: objective=0.022642652
2017/08/25 21:39:39 step 2: objective=0.022674093
2017/08/25 21:39:39 step 3: objective=0.022705596
2017/08/25 21:39:40 step 4: objective=0.022736995
2017/08/25 21:39:40 step 5: objective=0.02276846
2017/08/25 21:39:41 step 6: objective=0.022800094
2017/08/25 21:39:41 step 7: objective=0.022831682
2017/08/25 21:39:41 Training value function...
2017/08/25 21:39:42 step 0: mse=0.132938 step=0.100000
2017/08/25 21:39:43 step 1: mse=0.129116 step=0.100000
2017/08/25 21:39:43 step 2: mse=0.126000 step=0.100000
2017/08/25 21:39:44 step 3: mse=0.123301 step=0.100000
2017/08/25 21:39:44 step 4: mse=0.121058 step=0.100000
2017/08/25 21:39:44 step 5: mse=0.119049 step=0.100000
2017/08/25 21:39:45 step 6: mse=0.117455 step=0.100000
2017/08/25 21:39:45 step 7: mse=0.115903 step=0.100000
2017/08/25 21:39:45 Saving...
2017/08/25 21:39:45 Gathering batch of experience...
2017/08/25 21:39:56 batch 4: mean=1.585366 stddev=1.502988 entropy=1.385557 frames=32084 count=123
2017/08/25 21:39:56 Training policy...
2017/08/25 21:39:57 step 0: objective=0.0068931016
2017/08/25 21:39:58 step 1: objective=0.0069295065
2017/08/25 21:39:58 step 2: objective=0.006965774
2017/08/25 21:39:59 step 3: objective=0.007001882
2017/08/25 21:39:59 step 4: objective=0.007037822
2017/08/25 21:39:59 step 5: objective=0.00707359
2017/08/25 21:40:00 step 6: objective=0.007105164
2017/08/25 21:40:00 step 7: objective=0.0071367603
2017/08/25 21:40:00 Training value function...
2017/08/25 21:40:01 step 0: mse=0.123311 step=0.100000
2017/08/25 21:40:02 step 1: mse=0.121371 step=0.100000
2017/08/25 21:40:02 step 2: mse=0.119758 step=0.100000
2017/08/25 21:40:03 step 3: mse=0.118339 step=0.100000
2017/08/25 21:40:03 step 4: mse=0.117147 step=0.100000
2017/08/25 21:40:04 step 5: mse=0.115627 step=0.100000
2017/08/25 21:40:04 step 6: mse=0.114542 step=0.100000
2017/08/25 21:40:04 step 7: mse=0.113384 step=0.100000
2017/08/25 21:40:04 Saving...
2017/08/25 21:40:04 Gathering batch of experience...
2017/08/25 21:40:15 batch 5: mean=1.789916 stddev=1.689682 entropy=1.385171 frames=32349 count=119
2017/08/25 21:40:15 Training policy...
2017/08/25 21:40:16 step 0: objective=0.013060305
2017/08/25 21:40:17 step 1: objective=0.013095317
2017/08/25 21:40:17 step 2: objective=0.013130452
2017/08/25 21:40:17 step 3: objective=0.013165716
2017/08/25 21:40:18 step 4: objective=0.013200956
2017/08/25 21:40:18 step 5: objective=0.013236148
2017/08/25 21:40:19 step 6: objective=0.013271451
2017/08/25 21:40:19 step 7: objective=0.013297107
2017/08/25 21:40:19 Training value function...
2017/08/25 21:40:20 step 0: mse=0.152080 step=0.100000
2017/08/25 21:40:21 step 1: mse=0.146991 step=0.100000
2017/08/25 21:40:21 step 2: mse=0.142961 step=0.100000
2017/08/25 21:40:22 step 3: mse=0.139147 step=0.100000
2017/08/25 21:40:22 step 4: mse=0.136368 step=0.100000
2017/08/25 21:40:23 step 5: mse=0.133663 step=0.100000
2017/08/25 21:40:23 step 6: mse=0.131745 step=0.100000
2017/08/25 21:40:24 step 7: mse=0.129892 step=0.100000
2017/08/25 21:40:24 Saving...
2017/08/25 21:40:24 Gathering batch of experience...
2017/08/25 21:40:34 batch 6: mean=2.000000 stddev=1.497825 entropy=1.384806 frames=32363 count=115
2017/08/25 21:40:34 Training policy...
2017/08/25 21:40:36 step 0: objective=0.014492921
2017/08/25 21:40:36 step 1: objective=0.014538396
2017/08/25 21:40:37 step 2: objective=0.014583947
2017/08/25 21:40:37 step 3: objective=0.014629595
2017/08/25 21:40:38 step 4: objective=0.014675354
2017/08/25 21:40:38 step 5: objective=0.014721271
2017/08/25 21:40:38 step 6: objective=0.014767124
2017/08/25 21:40:39 step 7: objective=0.014813114
2017/08/25 21:40:39 Training value function...
2017/08/25 21:40:40 step 0: mse=0.123847 step=0.100000
2017/08/25 21:40:40 step 1: mse=0.121634 step=0.100000
2017/08/25 21:40:41 step 2: mse=0.119746 step=0.100000
2017/08/25 21:40:41 step 3: mse=0.118058 step=0.100000
2017/08/25 21:40:42 step 4: mse=0.116582 step=0.100000
2017/08/25 21:40:42 step 5: mse=0.115430 step=0.100000
2017/08/25 21:40:43 step 6: mse=0.114470 step=0.100000
2017/08/25 21:40:44 step 7: mse=0.113312 step=0.100000
2017/08/25 21:40:44 Saving...
2017/08/25 21:40:44 Gathering batch of experience...
2017/08/25 21:40:54 batch 7: mean=1.871795 stddev=1.380811 entropy=1.384023 frames=32338 count=117
2017/08/25 21:40:54 Training policy...
2017/08/25 21:40:55 step 0: objective=0.0028219593
2017/08/25 21:40:56 step 1: objective=0.0028593887
2017/08/25 21:40:56 step 2: objective=0.0028968435
2017/08/25 21:40:57 step 3: objective=0.0029343104
2017/08/25 21:40:57 step 4: objective=0.0029718005
2017/08/25 21:40:58 step 5: objective=0.0030093023
2017/08/25 21:40:58 step 6: objective=0.0030468465
2017/08/25 21:40:59 step 7: objective=0.003084391
2017/08/25 21:40:59 Training value function...
2017/08/25 21:41:00 step 0: mse=0.127485 step=0.100000
2017/08/25 21:41:00 step 1: mse=0.123162 step=0.100000
2017/08/25 21:41:01 step 2: mse=0.119616 step=0.100000
2017/08/25 21:41:01 step 3: mse=0.116759 step=0.100000
2017/08/25 21:41:02 step 4: mse=0.114428 step=0.100000
2017/08/25 21:41:02 step 5: mse=0.112441 step=0.100000
2017/08/25 21:41:03 step 6: mse=0.110492 step=0.100000
2017/08/25 21:41:03 step 7: mse=0.108892 step=0.100000
2017/08/25 21:41:03 Saving...
2017/08/25 21:41:03 Gathering batch of experience...
2017/08/25 21:41:14 batch 8: mean=2.154545 stddev=1.440873 entropy=1.383254 frames=32186 count=110
2017/08/25 21:41:14 Training policy...
2017/08/25 21:41:15 step 0: objective=0.010948155
2017/08/25 21:41:16 step 1: objective=0.010972783
2017/08/25 21:41:16 step 2: objective=0.010997433
2017/08/25 21:41:17 step 3: objective=0.011022071
2017/08/25 21:41:17 step 4: objective=0.011046825
2017/08/25 21:41:18 step 5: objective=0.011071541
2017/08/25 21:41:18 step 6: objective=0.011096379
2017/08/25 21:41:19 step 7: objective=0.011121235
2017/08/25 21:41:19 Training value function...
2017/08/25 21:41:20 step 0: mse=0.118641 step=0.100000
2017/08/25 21:41:21 step 1: mse=0.115699 step=0.100000
2017/08/25 21:41:21 step 2: mse=0.113608 step=0.100000
2017/08/25 21:41:22 step 3: mse=0.111688 step=0.100000
2017/08/25 21:41:22 step 4: mse=0.110242 step=0.100000
2017/08/25 21:41:23 step 5: mse=0.108979 step=0.100000
2017/08/25 21:41:23 step 6: mse=0.107399 step=0.100000
2017/08/25 21:41:24 step 7: mse=0.106380 step=0.100000
2017/08/25 21:41:24 Saving...
2017/08/25 21:41:24 Gathering batch of experience...
2017/08/25 21:41:34 batch 9: mean=2.231481 stddev=1.670033 entropy=1.382761 frames=32006 count=108
2017/08/25 21:41:34 Training policy...
2017/08/25 21:41:35 step 0: objective=0.009612798
2017/08/25 21:41:36 step 1: objective=0.009634334
2017/08/25 21:41:36 step 2: objective=0.0096558705
2017/08/25 21:41:37 step 3: objective=0.009677346
2017/08/25 21:41:37 step 4: objective=0.009698799
2017/08/25 21:41:38 step 5: objective=0.0097202705
2017/08/25 21:41:38 step 6: objective=0.0097416965
2017/08/25 21:41:39 step 7: objective=0.009763021
2017/08/25 21:41:39 Training value function...
2017/08/25 21:41:40 step 0: mse=0.143248 step=0.100000
2017/08/25 21:41:41 step 1: mse=0.137691 step=0.100000
2017/08/25 21:41:41 step 2: mse=0.133672 step=0.100000
2017/08/25 21:41:42 step 3: mse=0.130511 step=0.100000
2017/08/25 21:41:42 step 4: mse=0.127200 step=0.100000
2017/08/25 21:41:43 step 5: mse=0.124938 step=0.100000
2017/08/25 21:41:43 step 6: mse=0.122747 step=0.100000
2017/08/25 21:41:44 step 7: mse=0.120842 step=0.100000
2017/08/25 21:41:44 Saving...
2017/08/25 21:41:44 Gathering batch of experience...
2017/08/25 21:41:54 batch 10: mean=2.234234 stddev=1.749929 entropy=1.381852 frames=32770 count=111
2017/08/25 21:41:54 Training policy...
2017/08/25 21:41:56 step 0: objective=0.0058034193
2017/08/25 21:41:56 step 1: objective=0.0058393637
2017/08/25 21:41:57 step 2: objective=0.0058753006
2017/08/25 21:41:57 step 3: objective=0.005911178
2017/08/25 21:41:58 step 4: objective=0.00594708
2017/08/25 21:41:58 step 5: objective=0.005982957
2017/08/25 21:41:59 step 6: objective=0.006018826
2017/08/25 21:41:59 step 7: objective=0.0060547125
2017/08/25 21:41:59 Training value function...
2017/08/25 21:42:01 step 0: mse=0.149922 step=0.100000
2017/08/25 21:42:01 step 1: mse=0.145493 step=0.100000
2017/08/25 21:42:02 step 2: mse=0.141849 step=0.100000
2017/08/25 21:42:02 step 3: mse=0.139377 step=0.100000
2017/08/25 21:42:03 step 4: mse=0.136697 step=0.100000
2017/08/25 21:42:03 step 5: mse=0.134889 step=0.100000
2017/08/25 21:42:04 step 6: mse=0.133536 step=0.100000
2017/08/25 21:42:05 step 7: mse=0.132260 step=0.100000
2017/08/25 21:42:05 Saving...
2017/08/25 21:42:05 Gathering batch of experience...
2017/08/25 21:42:15 batch 11: mean=2.044248 stddev=1.593068 entropy=1.380884 frames=32549 count=113
2017/08/25 21:42:15 Training policy...
2017/08/25 21:42:16 step 0: objective=-0.0013335269
2017/08/25 21:42:17 step 1: objective=-0.0013008846
2017/08/25 21:42:17 step 2: objective=-0.0012682676
2017/08/25 21:42:18 step 3: objective=-0.0012356798
2017/08/25 21:42:18 step 4: objective=-0.0012031243
2017/08/25 21:42:19 step 5: objective=-0.0011705898
2017/08/25 21:42:19 step 6: objective=-0.0011380988
2017/08/25 21:42:20 step 7: objective=-0.0011056422
2017/08/25 21:42:20 Training value function...
2017/08/25 21:42:21 step 0: mse=0.133542 step=0.100000
2017/08/25 21:42:22 step 1: mse=0.131741 step=0.100000
2017/08/25 21:42:22 step 2: mse=0.130211 step=0.100000
2017/08/25 21:42:23 step 3: mse=0.128516 step=0.100000
2017/08/25 21:42:23 step 4: mse=0.127389 step=0.100000
2017/08/25 21:42:24 step 5: mse=0.125270 step=0.100000
2017/08/25 21:42:25 step 6: mse=0.123933 step=0.100000
2017/08/25 21:42:25 step 7: mse=0.122582 step=0.100000
2017/08/25 21:42:25 Saving...
2017/08/25 21:42:25 Gathering batch of experience...
2017/08/25 21:42:36 batch 12: mean=2.435185 stddev=1.535223 entropy=1.379917 frames=32763 count=108
2017/08/25 21:42:36 Training policy...
2017/08/25 21:42:37 step 0: objective=0.010818532
2017/08/25 21:42:38 step 1: objective=0.010847821
2017/08/25 21:42:38 step 2: objective=0.010877002
2017/08/25 21:42:39 step 3: objective=0.01090639
2017/08/25 21:42:39 step 4: objective=0.010935607
2017/08/25 21:42:40 step 5: objective=0.010964975
2017/08/25 21:42:40 step 6: objective=0.010994353
2017/08/25 21:42:41 step 7: objective=0.011023741
2017/08/25 21:42:41 Training value function...
2017/08/25 21:42:42 step 0: mse=0.133891 step=0.100000
2017/08/25 21:42:43 step 1: mse=0.130207 step=0.100000
2017/08/25 21:42:43 step 2: mse=0.127203 step=0.100000
2017/08/25 21:42:44 step 3: mse=0.123557 step=0.100000
2017/08/25 21:42:44 step 4: mse=0.121439 step=0.100000
2017/08/25 21:42:45 step 5: mse=0.118758 step=0.100000
2017/08/25 21:42:46 step 6: mse=0.116581 step=0.100000
2017/08/25 21:42:46 step 7: mse=0.114533 step=0.100000
2017/08/25 21:42:46 Saving...
2017/08/25 21:42:46 Gathering batch of experience...
2017/08/25 21:42:57 batch 13: mean=2.542056 stddev=1.939652 entropy=1.378757 frames=32805 count=107
2017/08/25 21:42:57 Training policy...
2017/08/25 21:42:58 step 0: objective=0.012960266
2017/08/25 21:42:59 step 1: objective=0.012995235
2017/08/25 21:42:59 step 2: objective=0.013030316
2017/08/25 21:43:00 step 3: objective=0.013065313
2017/08/25 21:43:00 step 4: objective=0.013099071
2017/08/25 21:43:01 step 5: objective=0.013132789
2017/08/25 21:43:01 step 6: objective=0.013166705
2017/08/25 21:43:02 step 7: objective=0.013200621
2017/08/25 21:43:02 Training value function...
2017/08/25 21:43:03 step 0: mse=0.198119 step=0.100000
2017/08/25 21:43:04 step 1: mse=0.190827 step=0.100000
2017/08/25 21:43:04 step 2: mse=0.184871 step=0.100000
2017/08/25 21:43:05 step 3: mse=0.180464 step=0.100000
2017/08/25 21:43:06 step 4: mse=0.175462 step=0.100000
2017/08/25 21:43:06 step 5: mse=0.171753 step=0.100000
2017/08/25 21:43:07 step 6: mse=0.168106 step=0.100000
2017/08/25 21:43:08 step 7: mse=0.165405 step=0.100000
2017/08/25 21:43:08 Saving...
2017/08/25 21:43:08 Gathering batch of experience...
2017/08/25 21:43:18 batch 14: mean=2.650485 stddev=1.979059 entropy=1.377979 frames=32337 count=103
2017/08/25 21:43:18 Training policy...
2017/08/25 21:43:19 step 0: objective=0.01085216
2017/08/25 21:43:20 step 1: objective=0.010881283
2017/08/25 21:43:21 step 2: objective=0.010910362
2017/08/25 21:43:21 step 3: objective=0.010939556
2017/08/25 21:43:22 step 4: objective=0.0109689
2017/08/25 21:43:22 step 5: objective=0.010998204
2017/08/25 21:43:23 step 6: objective=0.011027646
2017/08/25 21:43:23 step 7: objective=0.01105712
2017/08/25 21:43:23 Training value function...
2017/08/25 21:43:24 step 0: mse=0.164014 step=0.100000
2017/08/25 21:43:25 step 1: mse=0.160506 step=0.100000
2017/08/25 21:43:26 step 2: mse=0.157240 step=0.100000
2017/08/25 21:43:27 step 3: mse=0.154755 step=0.100000
2017/08/25 21:43:27 step 4: mse=0.151578 step=0.100000
2017/08/25 21:43:28 step 5: mse=0.149115 step=0.100000
2017/08/25 21:43:29 step 6: mse=0.147075 step=0.100000
2017/08/25 21:43:29 step 7: mse=0.145323 step=0.100000
2017/08/25 21:43:29 Saving...
2017/08/25 21:43:29 Gathering batch of experience...
2017/08/25 21:43:39 batch 15: mean=2.774510 stddev=2.137008 entropy=1.377311 frames=32122 count=102
2017/08/25 21:43:39 Training policy...
2017/08/25 21:43:41 step 0: objective=0.016201725
2017/08/25 21:43:42 step 1: objective=0.016235337
2017/08/25 21:43:42 step 2: objective=0.016269093
2017/08/25 21:43:43 step 3: objective=0.01630277
2017/08/25 21:43:43 step 4: objective=0.016336503
2017/08/25 21:43:44 step 5: objective=0.016370155
2017/08/25 21:43:44 step 6: objective=0.016403744
2017/08/25 21:43:45 step 7: objective=0.01643737
2017/08/25 21:43:45 Training value function...
2017/08/25 21:43:46 step 0: mse=0.261021 step=0.100000
2017/08/25 21:43:47 step 1: mse=0.245602 step=0.100000
2017/08/25 21:43:48 step 2: mse=0.233075 step=0.100000
2017/08/25 21:43:48 step 3: mse=0.222832 step=0.100000
2017/08/25 21:43:49 step 4: mse=0.214467 step=0.100000
2017/08/25 21:43:50 step 5: mse=0.207671 step=0.100000
2017/08/25 21:43:50 step 6: mse=0.202274 step=0.100000
2017/08/25 21:43:51 step 7: mse=0.197576 step=0.100000
2017/08/25 21:43:51 Saving...
2017/08/25 21:43:51 Gathering batch of experience...
2017/08/25 21:44:01 batch 16: mean=3.010204 stddev=1.876247 entropy=1.376400 frames=32569 count=98
2017/08/25 21:44:01 Training policy...
2017/08/25 21:44:03 step 0: objective=0.006539616
2017/08/25 21:44:03 step 1: objective=0.006586962
2017/08/25 21:44:04 step 2: objective=0.0066346214
2017/08/25 21:44:05 step 3: objective=0.00668254
2017/08/25 21:44:05 step 4: objective=0.0067306743
2017/08/25 21:44:06 step 5: objective=0.006779071
2017/08/25 21:44:06 step 6: objective=0.0068186675
2017/08/25 21:44:07 step 7: objective=0.0068458193
2017/08/25 21:44:07 Training value function...
2017/08/25 21:44:08 step 0: mse=0.198940 step=0.100000
2017/08/25 21:44:09 step 1: mse=0.191916 step=0.100000
2017/08/25 21:44:10 step 2: mse=0.186212 step=0.100000
2017/08/25 21:44:10 step 3: mse=0.181266 step=0.100000
2017/08/25 21:44:11 step 4: mse=0.177543 step=0.100000
2017/08/25 21:44:12 step 5: mse=0.174313 step=0.100000
2017/08/25 21:44:13 step 6: mse=0.171452 step=0.100000
2017/08/25 21:44:14 step 7: mse=0.169298 step=0.100000
2017/08/25 21:44:14 Saving...
2017/08/25 21:44:14 Gathering batch of experience...
2017/08/25 21:44:24 batch 17: mean=2.910000 stddev=1.755534 entropy=1.375211 frames=32630 count=100
2017/08/25 21:44:24 Training policy...
2017/08/25 21:44:25 step 0: objective=0.0030525941
2017/08/25 21:44:26 step 1: objective=0.003097133
2017/08/25 21:44:27 step 2: objective=0.0031416533
2017/08/25 21:44:27 step 3: objective=0.003186076
2017/08/25 21:44:28 step 4: objective=0.0032305291
2017/08/25 21:44:28 step 5: objective=0.003274884
2017/08/25 21:44:29 step 6: objective=0.0033192164
2017/08/25 21:44:29 step 7: objective=0.0033635136
2017/08/25 21:44:29 Training value function...
2017/08/25 21:44:31 step 0: mse=0.181609 step=0.100000
2017/08/25 21:44:32 step 1: mse=0.173651 step=0.100000
2017/08/25 21:44:32 step 2: mse=0.167192 step=0.100000
2017/08/25 21:44:33 step 3: mse=0.162413 step=0.100000
2017/08/25 21:44:34 step 4: mse=0.157914 step=0.100000
2017/08/25 21:44:35 step 5: mse=0.154174 step=0.100000
2017/08/25 21:44:35 step 6: mse=0.150449 step=0.100000
2017/08/25 21:44:36 step 7: mse=0.148109 step=0.100000
2017/08/25 21:44:36 Saving...
2017/08/25 21:44:36 Gathering batch of experience...
2017/08/25 21:44:46 batch 18: mean=2.938776 stddev=1.877995 entropy=1.373592 frames=32421 count=98
2017/08/25 21:44:46 Training policy...
2017/08/25 21:44:48 step 0: objective=0.0037651365
2017/08/25 21:44:49 step 1: objective=0.0037987332
2017/08/25 21:44:49 step 2: objective=0.0038322946
2017/08/25 21:44:50 step 3: objective=0.003865762
2017/08/25 21:44:50 step 4: objective=0.0038991706
2017/08/25 21:44:51 step 5: objective=0.0039324905
2017/08/25 21:44:52 step 6: objective=0.0039657503
2017/08/25 21:44:52 step 7: objective=0.0039989688
2017/08/25 21:44:52 Training value function...
2017/08/25 21:44:53 step 0: mse=0.219198 step=0.100000
2017/08/25 21:44:54 step 1: mse=0.208242 step=0.100000
2017/08/25 21:44:55 step 2: mse=0.199298 step=0.100000
2017/08/25 21:44:56 step 3: mse=0.192044 step=0.100000
2017/08/25 21:44:57 step 4: mse=0.187070 step=0.100000
2017/08/25 21:44:57 step 5: mse=0.182744 step=0.100000
2017/08/25 21:44:58 step 6: mse=0.178966 step=0.100000
2017/08/25 21:44:59 step 7: mse=0.174483 step=0.100000
2017/08/25 21:44:59 Saving...
2017/08/25 21:44:59 Gathering batch of experience...
2017/08/25 21:45:09 batch 19: mean=2.725490 stddev=1.687072 entropy=1.372404 frames=32474 count=102
2017/08/25 21:45:09 Training policy...
2017/08/25 21:45:11 step 0: objective=-0.0035938818
2017/08/25 21:45:11 step 1: objective=-0.003556251
2017/08/25 21:45:12 step 2: objective=-0.0035185833
2017/08/25 21:45:13 step 3: objective=-0.0034808978
2017/08/25 21:45:13 step 4: objective=-0.0034432262
2017/08/25 21:45:14 step 5: objective=-0.0034055312
2017/08/25 21:45:14 step 6: objective=-0.0033678059
2017/08/25 21:45:15 step 7: objective=-0.0033301064
2017/08/25 21:45:15 Training value function...
2017/08/25 21:45:16 step 0: mse=0.154362 step=0.100000
2017/08/25 21:45:17 step 1: mse=0.150608 step=0.100000
2017/08/25 21:45:18 step 2: mse=0.147515 step=0.100000
2017/08/25 21:45:19 step 3: mse=0.144992 step=0.100000
2017/08/25 21:45:20 step 4: mse=0.142782 step=0.100000
2017/08/25 21:45:21 step 5: mse=0.141150 step=0.100000
2017/08/25 21:45:21 step 6: mse=0.139205 step=0.100000
2017/08/25 21:45:22 step 7: mse=0.137662 step=0.100000
2017/08/25 21:45:22 Saving...
2017/08/25 21:45:22 Gathering batch of experience...
2017/08/25 21:45:32 batch 20: mean=3.287234 stddev=1.933040 entropy=1.370534 frames=32608 count=94
2017/08/25 21:45:32 Training policy...
2017/08/25 21:45:34 step 0: objective=0.016291112
2017/08/25 21:45:35 step 1: objective=0.016325856
2017/08/25 21:45:35 step 2: objective=0.016360693
2017/08/25 21:45:36 step 3: objective=0.01639436
2017/08/25 21:45:37 step 4: objective=0.016428236
2017/08/25 21:45:37 step 5: objective=0.016462054
2017/08/25 21:45:38 step 6: objective=0.016496029
2017/08/25 21:45:39 step 7: objective=0.016529882
2017/08/25 21:45:39 Training value function...
2017/08/25 21:45:40 step 0: mse=0.185957 step=0.100000
2017/08/25 21:45:41 step 1: mse=0.180847 step=0.100000
2017/08/25 21:45:42 step 2: mse=0.176508 step=0.100000
2017/08/25 21:45:42 step 3: mse=0.173104 step=0.100000
2017/08/25 21:45:43 step 4: mse=0.169388 step=0.100000
2017/08/25 21:45:44 step 5: mse=0.167000 step=0.100000
2017/08/25 21:45:45 step 6: mse=0.163696 step=0.100000
2017/08/25 21:45:46 step 7: mse=0.160989 step=0.100000
2017/08/25 21:45:46 Saving...
2017/08/25 21:45:46 Gathering batch of experience...
2017/08/25 21:45:56 batch 21: mean=2.990000 stddev=1.791619 entropy=1.368903 frames=33309 count=100
2017/08/25 21:45:56 Training policy...
2017/08/25 21:45:58 step 0: objective=8.545497e-05
2017/08/25 21:45:59 step 1: objective=0.00012154878
2017/08/25 21:45:59 step 2: objective=0.00015766529
2017/08/25 21:46:00 step 3: objective=0.00019381178
2017/08/25 21:46:01 step 4: objective=0.00022997637
2017/08/25 21:46:01 step 5: objective=0.00026616163
2017/08/25 21:46:02 step 6: objective=0.0003023651
2017/08/25 21:46:03 step 7: objective=0.00033857956
2017/08/25 21:46:03 Training value function...
2017/08/25 21:46:04 step 0: mse=0.144962 step=0.100000
2017/08/25 21:46:05 step 1: mse=0.141050 step=0.100000
2017/08/25 21:46:06 step 2: mse=0.137877 step=0.100000
2017/08/25 21:46:07 step 3: mse=0.135291 step=0.100000
2017/08/25 21:46:08 step 4: mse=0.133030 step=0.100000
2017/08/25 21:46:09 step 5: mse=0.131201 step=0.100000
2017/08/25 21:46:10 step 6: mse=0.129234 step=0.100000
2017/08/25 21:46:10 step 7: mse=0.127857 step=0.100000
2017/08/25 21:46:10 Saving...
2017/08/25 21:46:10 Gathering batch of experience...
2017/08/25 21:46:21 batch 22: mean=3.561798 stddev=2.213112 entropy=1.366248 frames=31911 count=89
2017/08/25 21:46:21 Training policy...
2017/08/25 21:46:22 step 0: objective=0.019895615
2017/08/25 21:46:23 step 1: objective=0.019926958
2017/08/25 21:46:23 step 2: objective=0.01995836
2017/08/25 21:46:24 step 3: objective=0.019989997
2017/08/25 21:46:25 step 4: objective=0.020021759
2017/08/25 21:46:25 step 5: objective=0.020053618
2017/08/25 21:46:26 step 6: objective=0.02008521
2017/08/25 21:46:27 step 7: objective=0.020109527
2017/08/25 21:46:27 Training value function...
2017/08/25 21:46:28 step 0: mse=0.235227 step=0.100000
2017/08/25 21:46:29 step 1: mse=0.224070 step=0.100000
2017/08/25 21:46:30 step 2: mse=0.213773 step=0.100000
2017/08/25 21:46:31 step 3: mse=0.205648 step=0.100000
2017/08/25 21:46:32 step 4: mse=0.198946 step=0.100000
2017/08/25 21:46:33 step 5: mse=0.190945 step=0.100000
2017/08/25 21:46:33 step 6: mse=0.184505 step=0.100000
2017/08/25 21:46:34 step 7: mse=0.180077 step=0.100000
2017/08/25 21:46:34 Saving...
2017/08/25 21:46:34 Gathering batch of experience...
2017/08/25 21:46:45 batch 23: mean=3.322917 stddev=2.023275 entropy=1.366249 frames=33026 count=96
2017/08/25 21:46:45 Training policy...
2017/08/25 21:46:47 step 0: objective=0.008432671
2017/08/25 21:46:47 step 1: objective=0.008457887
2017/08/25 21:46:48 step 2: objective=0.008482897
2017/08/25 21:46:49 step 3: objective=0.008507643
2017/08/25 21:46:49 step 4: objective=0.008532241
2017/08/25 21:46:50 step 5: objective=0.008556516
2017/08/25 21:46:51 step 6: objective=0.008580612
2017/08/25 21:46:51 step 7: objective=0.008604445
2017/08/25 21:46:51 Training value function...
2017/08/25 21:46:53 step 0: mse=0.177623 step=0.100000
2017/08/25 21:46:54 step 1: mse=0.167381 step=0.100000
2017/08/25 21:46:55 step 2: mse=0.159324 step=0.100000
2017/08/25 21:46:56 step 3: mse=0.152755 step=0.100000
2017/08/25 21:46:57 step 4: mse=0.147059 step=0.100000
2017/08/25 21:46:58 step 5: mse=0.142636 step=0.100000
2017/08/25 21:46:59 step 6: mse=0.138804 step=0.100000
2017/08/25 21:47:00 step 7: mse=0.135827 step=0.100000
2017/08/25 21:47:00 Saving...
2017/08/25 21:47:00 Gathering batch of experience...
2017/08/25 21:47:10 batch 24: mean=3.510870 stddev=2.159381 entropy=1.363253 frames=32536 count=92
2017/08/25 21:47:10 Training policy...
2017/08/25 21:47:12 step 0: objective=0.007721571
2017/08/25 21:47:12 step 1: objective=0.0077566714
2017/08/25 21:47:13 step 2: objective=0.0077829696
2017/08/25 21:47:14 step 3: objective=0.0078092287
2017/08/25 21:47:14 step 4: objective=0.007835529
2017/08/25 21:47:15 step 5: objective=0.007861893
2017/08/25 21:47:16 step 6: objective=0.007888363
2017/08/25 21:47:16 step 7: objective=0.007914835
2017/08/25 21:47:16 Training value function...
2017/08/25 21:47:18 step 0: mse=0.216941 step=0.100000
2017/08/25 21:47:19 step 1: mse=0.210600 step=0.100000
2017/08/25 21:47:20 step 2: mse=0.205457 step=0.100000
2017/08/25 21:47:21 step 3: mse=0.201228 step=0.100000
2017/08/25 21:47:22 step 4: mse=0.197717 step=0.100000
2017/08/25 21:47:23 step 5: mse=0.194834 step=0.100000
2017/08/25 21:47:24 step 6: mse=0.192376 step=0.100000
2017/08/25 21:47:25 step 7: mse=0.189992 step=0.100000
2017/08/25 21:47:25 Saving...
2017/08/25 21:47:25 Gathering batch of experience...
2017/08/25 21:47:35 batch 25: mean=3.291667 stddev=2.091235 entropy=1.364657 frames=33083 count=96
2017/08/25 21:47:35 Training policy...
2017/08/25 21:47:37 step 0: objective=0.0041412357
2017/08/25 21:47:38 step 1: objective=0.0041634007
2017/08/25 21:47:38 step 2: objective=0.0041855685
2017/08/25 21:47:39 step 3: objective=0.004207789
2017/08/25 21:47:40 step 4: objective=0.0042300285
2017/08/25 21:47:41 step 5: objective=0.004252265
2017/08/25 21:47:41 step 6: objective=0.0042746
2017/08/25 21:47:42 step 7: objective=0.004296926
2017/08/25 21:47:42 Training value function...
2017/08/25 21:47:43 step 0: mse=0.216405 step=0.100000
2017/08/25 21:47:45 step 1: mse=0.208956 step=0.100000
2017/08/25 21:47:46 step 2: mse=0.202875 step=0.100000
2017/08/25 21:47:47 step 3: mse=0.197927 step=0.100000
2017/08/25 21:47:48 step 4: mse=0.194063 step=0.100000
2017/08/25 21:47:49 step 5: mse=0.187759 step=0.100000
2017/08/25 21:47:50 step 6: mse=0.184640 step=0.100000
2017/08/25 21:47:51 step 7: mse=0.179769 step=0.100000
2017/08/25 21:47:51 Saving...
2017/08/25 21:47:51 Gathering batch of experience...
2017/08/25 21:48:01 batch 26: mean=3.451613 stddev=2.040009 entropy=1.364206 frames=33343 count=93
2017/08/25 21:48:01 Training policy...
2017/08/25 21:48:03 step 0: objective=0.006019363
2017/08/25 21:48:04 step 1: objective=0.006038569
2017/08/25 21:48:04 step 2: objective=0.0060576457
2017/08/25 21:48:05 step 3: objective=0.006076711
2017/08/25 21:48:06 step 4: objective=0.006095721
2017/08/25 21:48:07 step 5: objective=0.006114671
2017/08/25 21:48:07 step 6: objective=0.006133538
2017/08/25 21:48:08 step 7: objective=0.0061524413
2017/08/25 21:48:08 Training value function...
2017/08/25 21:48:10 step 0: mse=0.179552 step=0.100000
2017/08/25 21:48:11 step 1: mse=0.172522 step=0.100000
2017/08/25 21:48:12 step 2: mse=0.166560 step=0.100000
2017/08/25 21:48:13 step 3: mse=0.161461 step=0.100000
2017/08/25 21:48:14 step 4: mse=0.157560 step=0.100000
2017/08/25 21:48:15 step 5: mse=0.154182 step=0.100000
2017/08/25 21:48:16 step 6: mse=0.151262 step=0.100000
2017/08/25 21:48:17 step 7: mse=0.149068 step=0.100000
2017/08/25 21:48:17 Saving...
2017/08/25 21:48:17 Gathering batch of experience...
2017/08/25 21:48:28 batch 27: mean=3.183673 stddev=2.120584 entropy=1.361740 frames=33129 count=98
2017/08/25 21:48:28 Training policy...
2017/08/25 21:48:30 step 0: objective=0.0013658325
2017/08/25 21:48:30 step 1: objective=0.0013949294
2017/08/25 21:48:31 step 2: objective=0.0014240585
2017/08/25 21:48:32 step 3: objective=0.0014531978
2017/08/25 21:48:33 step 4: objective=0.0014823925
2017/08/25 21:48:33 step 5: objective=0.0015115981
2017/08/25 21:48:34 step 6: objective=0.0015408306
2017/08/25 21:48:35 step 7: objective=0.0015700808
2017/08/25 21:48:35 Training value function...
2017/08/25 21:48:36 step 0: mse=0.196806 step=0.100000
2017/08/25 21:48:37 step 1: mse=0.186951 step=0.100000
2017/08/25 21:48:39 step 2: mse=0.178894 step=0.100000
2017/08/25 21:48:40 step 3: mse=0.172304 step=0.100000
2017/08/25 21:48:41 step 4: mse=0.166866 step=0.100000
2017/08/25 21:48:42 step 5: mse=0.162609 step=0.100000
2017/08/25 21:48:43 step 6: mse=0.158787 step=0.100000
2017/08/25 21:48:44 step 7: mse=0.155619 step=0.100000
2017/08/25 21:48:44 Saving...
2017/08/25 21:48:44 Gathering batch of experience...
2017/08/25 21:48:55 batch 28: mean=3.494737 stddev=2.071733 entropy=1.360803 frames=33565 count=95
2017/08/25 21:48:55 Training policy...
2017/08/25 21:48:56 step 0: objective=0.0088185035
2017/08/25 21:48:57 step 1: objective=0.00886366
2017/08/25 21:48:58 step 2: objective=0.008908912
2017/08/25 21:48:59 step 3: objective=0.008954202
2017/08/25 21:49:00 step 4: objective=0.008999691
2017/08/25 21:49:00 step 5: objective=0.009045191
2017/08/25 21:49:01 step 6: objective=0.009090824
2017/08/25 21:49:02 step 7: objective=0.009135266
2017/08/25 21:49:02 Training value function...
2017/08/25 21:49:04 step 0: mse=0.232834 step=0.100000
2017/08/25 21:49:05 step 1: mse=0.228641 step=0.100000
2017/08/25 21:49:06 step 2: mse=0.225238 step=0.100000
2017/08/25 21:49:07 step 3: mse=0.222094 step=0.100000
2017/08/25 21:49:08 step 4: mse=0.219729 step=0.100000
2017/08/25 21:49:09 step 5: mse=0.215156 step=0.100000
2017/08/25 21:49:10 step 6: mse=0.211918 step=0.100000
2017/08/25 21:49:12 step 7: mse=0.208170 step=0.100000
2017/08/25 21:49:12 Saving...
2017/08/25 21:49:12 Gathering batch of experience...
2017/08/25 21:49:22 batch 29: mean=3.707865 stddev=2.152617 entropy=1.360125 frames=32455 count=89
2017/08/25 21:49:22 Training policy...
2017/08/25 21:49:24 step 0: objective=0.012167096
2017/08/25 21:49:24 step 1: objective=0.012201574
2017/08/25 21:49:25 step 2: objective=0.012235944
2017/08/25 21:49:26 step 3: objective=0.012270142
2017/08/25 21:49:27 step 4: objective=0.01230417
2017/08/25 21:49:27 step 5: objective=0.01233802
2017/08/25 21:49:28 step 6: objective=0.012371643
2017/08/25 21:49:29 step 7: objective=0.012405041
2017/08/25 21:49:29 Training value function...
2017/08/25 21:49:30 step 0: mse=0.254252 step=0.100000
2017/08/25 21:49:31 step 1: mse=0.238804 step=0.100000
2017/08/25 21:49:33 step 2: mse=0.226255 step=0.100000
2017/08/25 21:49:34 step 3: mse=0.214966 step=0.100000
2017/08/25 21:49:35 step 4: mse=0.205842 step=0.100000
2017/08/25 21:49:36 step 5: mse=0.198934 step=0.100000
2017/08/25 21:49:37 step 6: mse=0.193183 step=0.100000
2017/08/25 21:49:38 step 7: mse=0.187620 step=0.100000
2017/08/25 21:49:38 Saving...
2017/08/25 21:49:38 Gathering batch of experience...
2017/08/25 21:49:49 batch 30: mean=3.588889 stddev=2.240508 entropy=1.358225 frames=32735 count=90
2017/08/25 21:49:49 Training policy...
2017/08/25 21:49:51 step 0: objective=0.003357021
2017/08/25 21:49:51 step 1: objective=0.0033810716
2017/08/25 21:49:52 step 2: objective=0.0034050778
2017/08/25 21:49:53 step 3: objective=0.0034289514
2017/08/25 21:49:54 step 4: objective=0.0034527835
2017/08/25 21:49:55 step 5: objective=0.0034765324
2017/08/25 21:49:55 step 6: objective=0.0035002031
2017/08/25 21:49:56 step 7: objective=0.003523779
2017/08/25 21:49:56 Training value function...
2017/08/25 21:49:58 step 0: mse=0.221331 step=0.100000
2017/08/25 21:49:59 step 1: mse=0.211478 step=0.100000
2017/08/25 21:50:00 step 2: mse=0.203351 step=0.100000
2017/08/25 21:50:01 step 3: mse=0.196247 step=0.100000
2017/08/25 21:50:02 step 4: mse=0.190497 step=0.100000
2017/08/25 21:50:04 step 5: mse=0.184777 step=0.100000
2017/08/25 21:50:05 step 6: mse=0.180236 step=0.100000
2017/08/25 21:50:06 step 7: mse=0.175829 step=0.100000
2017/08/25 21:50:06 Saving...
2017/08/25 21:50:06 Gathering batch of experience...
2017/08/25 21:50:16 batch 31: mean=3.965517 stddev=2.606130 entropy=1.355975 frames=32418 count=87
2017/08/25 21:50:16 Training policy...
2017/08/25 21:50:18 step 0: objective=0.010680945
2017/08/25 21:50:19 step 1: objective=0.010739227
2017/08/25 21:50:20 step 2: objective=0.010797849
2017/08/25 21:50:21 step 3: objective=0.010856796
2017/08/25 21:50:21 step 4: objective=0.010916042
2017/08/25 21:50:22 step 5: objective=0.01096959
2017/08/25 21:50:23 step 6: objective=0.011004707
2017/08/25 21:50:24 step 7: objective=0.011033095
2017/08/25 21:50:24 Training value function...
2017/08/25 21:50:25 step 0: mse=0.359641 step=0.100000
2017/08/25 21:50:27 step 1: mse=0.339470 step=0.100000
2017/08/25 21:50:28 step 2: mse=0.323009 step=0.100000
2017/08/25 21:50:29 step 3: mse=0.311609 step=0.100000
2017/08/25 21:50:30 step 4: mse=0.302371 step=0.100000
2017/08/25 21:50:31 step 5: mse=0.290039 step=0.100000
2017/08/25 21:50:33 step 6: mse=0.278851 step=0.100000
2017/08/25 21:50:34 step 7: mse=0.269173 step=0.100000
2017/08/25 21:50:34 Saving...
2017/08/25 21:50:34 Gathering batch of experience...
2017/08/25 21:50:44 batch 32: mean=3.611111 stddev=1.987150 entropy=1.356203 frames=32657 count=90
2017/08/25 21:50:44 Training policy...
2017/08/25 21:50:46 step 0: objective=-0.004509692
2017/08/25 21:50:47 step 1: objective=-0.0044732634
2017/08/25 21:50:48 step 2: objective=-0.004436961
2017/08/25 21:50:48 step 3: objective=-0.0044008223
2017/08/25 21:50:49 step 4: objective=-0.004364819
2017/08/25 21:50:50 step 5: objective=-0.0043289163
2017/08/25 21:50:51 step 6: objective=-0.0042931833
2017/08/25 21:50:51 step 7: objective=-0.0042575737
2017/08/25 21:50:51 Training value function...
2017/08/25 21:50:53 step 0: mse=0.218790 step=0.100000
2017/08/25 21:50:54 step 1: mse=0.213171 step=0.100000
2017/08/25 21:50:56 step 2: mse=0.209307 step=0.100000
2017/08/25 21:50:57 step 3: mse=0.205237 step=0.100000
2017/08/25 21:50:58 step 4: mse=0.202521 step=0.100000
2017/08/25 21:50:59 step 5: mse=0.200255 step=0.100000
2017/08/25 21:51:01 step 6: mse=0.197174 step=0.100000
2017/08/25 21:51:02 step 7: mse=0.190523 step=0.100000
2017/08/25 21:51:02 Saving...
2017/08/25 21:51:02 Gathering batch of experience...
2017/08/25 21:51:12 batch 33: mean=3.831461 stddev=2.450572 entropy=1.353512 frames=33165 count=89
2017/08/25 21:51:12 Training policy...
2017/08/25 21:51:14 step 0: objective=0.0070587276
2017/08/25 21:51:15 step 1: objective=0.0070939143
2017/08/25 21:51:16 step 2: objective=0.007129124
2017/08/25 21:51:17 step 3: objective=0.0071643507
2017/08/25 21:51:18 step 4: objective=0.007201407
2017/08/25 21:51:18 step 5: objective=0.007236685
2017/08/25 21:51:19 step 6: objective=0.0072737793
2017/08/25 21:51:20 step 7: objective=0.0073090815
2017/08/25 21:51:20 Training value function...
2017/08/25 21:51:22 step 0: mse=0.218287 step=0.100000
2017/08/25 21:51:23 step 1: mse=0.208191 step=0.100000
2017/08/25 21:51:24 step 2: mse=0.201627 step=0.100000
2017/08/25 21:51:26 step 3: mse=0.193087 step=0.100000
2017/08/25 21:51:27 step 4: mse=0.186115 step=0.100000
2017/08/25 21:51:28 step 5: mse=0.181272 step=0.100000
2017/08/25 21:51:30 step 6: mse=0.177130 step=0.100000
2017/08/25 21:51:31 step 7: mse=0.173684 step=0.100000
2017/08/25 21:51:31 Saving...
2017/08/25 21:51:31 Gathering batch of experience...
2017/08/25 21:51:41 batch 34: mean=4.309524 stddev=2.878393 entropy=1.352064 frames=32907 count=84
2017/08/25 21:51:41 Training policy...
2017/08/25 21:51:43 step 0: objective=0.008543062
2017/08/25 21:51:44 step 1: objective=0.008590105
2017/08/25 21:51:45 step 2: objective=0.008637282
2017/08/25 21:51:46 step 3: objective=0.008684585
2017/08/25 21:51:47 step 4: objective=0.008731999
2017/08/25 21:51:47 step 5: objective=0.008779504
2017/08/25 21:51:48 step 6: objective=0.008827207
2017/08/25 21:51:49 step 7: objective=0.008874896
2017/08/25 21:51:49 Training value function...
2017/08/25 21:51:51 step 0: mse=0.286180 step=0.100000
2017/08/25 21:51:52 step 1: mse=0.273769 step=0.100000
2017/08/25 21:51:54 step 2: mse=0.260758 step=0.100000
2017/08/25 21:51:55 step 3: mse=0.250090 step=0.100000
2017/08/25 21:51:56 step 4: mse=0.241358 step=0.100000
2017/08/25 21:51:57 step 5: mse=0.234438 step=0.100000
2017/08/25 21:51:59 step 6: mse=0.227903 step=0.100000
2017/08/25 21:52:00 step 7: mse=0.223067 step=0.100000
2017/08/25 21:52:00 Saving...
2017/08/25 21:52:00 Gathering batch of experience...
2017/08/25 21:52:10 batch 35: mean=3.965116 stddev=2.087881 entropy=1.350710 frames=32784 count=86
2017/08/25 21:52:10 Training policy...
2017/08/25 21:52:12 step 0: objective=0.011713976
2017/08/25 21:52:13 step 1: objective=0.011737519
2017/08/25 21:52:14 step 2: objective=0.011761019
2017/08/25 21:52:15 step 3: objective=0.011784454
2017/08/25 21:52:16 step 4: objective=0.011807808
2017/08/25 21:52:17 step 5: objective=0.011831133
2017/08/25 21:52:18 step 6: objective=0.011854399
2017/08/25 21:52:18 step 7: objective=0.011877583
2017/08/25 21:52:18 Training value function...
2017/08/25 21:52:20 step 0: mse=0.197072 step=0.100000
2017/08/25 21:52:22 step 1: mse=0.189314 step=0.100000
2017/08/25 21:52:23 step 2: mse=0.183301 step=0.100000
2017/08/25 21:52:24 step 3: mse=0.178045 step=0.100000
2017/08/25 21:52:25 step 4: mse=0.173552 step=0.100000
2017/08/25 21:52:27 step 5: mse=0.169313 step=0.100000
2017/08/25 21:52:28 step 6: mse=0.165830 step=0.100000
2017/08/25 21:52:29 step 7: mse=0.163221 step=0.100000
2017/08/25 21:52:29 Saving...
2017/08/25 21:52:29 Gathering batch of experience...
2017/08/25 21:52:40 batch 36: mean=3.824176 stddev=2.110119 entropy=1.349292 frames=33485 count=91
2017/08/25 21:52:40 Training policy...
2017/08/25 21:52:42 step 0: objective=-7.357222e-05
2017/08/25 21:52:43 step 1: objective=-4.3790507e-05
2017/08/25 21:52:44 step 2: objective=-1.413047e-05
2017/08/25 21:52:45 step 3: objective=1.5415495e-05
2017/08/25 21:52:46 step 4: objective=4.485856e-05
2017/08/25 21:52:47 step 5: objective=7.417597e-05
2017/08/25 21:52:47 step 6: objective=0.00010338474
2017/08/25 21:52:48 step 7: objective=0.0001324795
2017/08/25 21:52:48 Training value function...
2017/08/25 21:52:50 step 0: mse=0.234281 step=0.100000
2017/08/25 21:52:51 step 1: mse=0.222456 step=0.100000
2017/08/25 21:52:53 step 2: mse=0.213231 step=0.100000
2017/08/25 21:52:54 step 3: mse=0.205275 step=0.100000
2017/08/25 21:52:56 step 4: mse=0.198561 step=0.100000
2017/08/25 21:52:57 step 5: mse=0.191937 step=0.100000
2017/08/25 21:52:59 step 6: mse=0.187290 step=0.100000
2017/08/25 21:53:00 step 7: mse=0.182561 step=0.100000
2017/08/25 21:53:00 Saving...
2017/08/25 21:53:00 Gathering batch of experience...
2017/08/25 21:53:11 batch 37: mean=4.282353 stddev=2.329412 entropy=1.348520 frames=33682 count=85
2017/08/25 21:53:11 Training policy...
2017/08/25 21:53:13 step 0: objective=0.005338586
2017/08/25 21:53:14 step 1: objective=0.0053781476
2017/08/25 21:53:15 step 2: objective=0.005417515
2017/08/25 21:53:16 step 3: objective=0.005456674
2017/08/25 21:53:16 step 4: objective=0.0054949424
2017/08/25 21:53:17 step 5: objective=0.0055337697
2017/08/25 21:53:18 step 6: objective=0.0055717817
2017/08/25 21:53:19 step 7: objective=0.005609612
2017/08/25 21:53:19 Training value function...
2017/08/25 21:53:21 step 0: mse=0.226481 step=0.100000
2017/08/25 21:53:23 step 1: mse=0.214816 step=0.100000
2017/08/25 21:53:24 step 2: mse=0.205227 step=0.100000
2017/08/25 21:53:25 step 3: mse=0.197459 step=0.100000
2017/08/25 21:53:27 step 4: mse=0.191048 step=0.100000
2017/08/25 21:53:28 step 5: mse=0.185615 step=0.100000
2017/08/25 21:53:30 step 6: mse=0.181038 step=0.100000
2017/08/25 21:53:31 step 7: mse=0.177270 step=0.100000
2017/08/25 21:53:31 Saving...
2017/08/25 21:53:31 Gathering batch of experience...
2017/08/25 21:53:42 batch 38: mean=4.536585 stddev=2.333192 entropy=1.344683 frames=33343 count=82
2017/08/25 21:53:42 Training policy...
2017/08/25 21:53:44 step 0: objective=0.007945946
2017/08/25 21:53:45 step 1: objective=0.007995934
2017/08/25 21:53:46 step 2: objective=0.008045848
2017/08/25 21:53:47 step 3: objective=0.00809563
2017/08/25 21:53:47 step 4: objective=0.008145328
2017/08/25 21:53:48 step 5: objective=0.008194976
2017/08/25 21:53:49 step 6: objective=0.008244459
2017/08/25 21:53:50 step 7: objective=0.00829386
2017/08/25 21:53:50 Training value function...
2017/08/25 21:53:52 step 0: mse=0.234154 step=0.100000
2017/08/25 21:53:53 step 1: mse=0.220724 step=0.100000
2017/08/25 21:53:55 step 2: mse=0.209464 step=0.100000
2017/08/25 21:53:56 step 3: mse=0.200375 step=0.100000
2017/08/25 21:53:58 step 4: mse=0.192626 step=0.100000
2017/08/25 21:53:59 step 5: mse=0.185949 step=0.100000
2017/08/25 21:54:01 step 6: mse=0.180677 step=0.100000
2017/08/25 21:54:02 step 7: mse=0.176244 step=0.100000
2017/08/25 21:54:02 Saving...
2017/08/25 21:54:02 Gathering batch of experience...
2017/08/25 21:54:13 batch 39: mean=4.137931 stddev=2.445603 entropy=1.345287 frames=34026 count=87
2017/08/25 21:54:13 Training policy...
2017/08/25 21:54:15 step 0: objective=-0.0025238488
2017/08/25 21:54:16 step 1: objective=-0.0024962588
2017/08/25 21:54:17 step 2: objective=-0.0024687857
2017/08/25 21:54:18 step 3: objective=-0.0024414584
2017/08/25 21:54:19 step 4: objective=-0.0024142535
2017/08/25 21:54:20 step 5: objective=-0.0023871595
2017/08/25 21:54:21 step 6: objective=-0.002360173
2017/08/25 21:54:22 step 7: objective=-0.0023333607
2017/08/25 21:54:22 Training value function...
2017/08/25 21:54:24 step 0: mse=0.274059 step=0.100000
2017/08/25 21:54:25 step 1: mse=0.259804 step=0.100000
2017/08/25 21:54:27 step 2: mse=0.247784 step=0.100000
2017/08/25 21:54:28 step 3: mse=0.237414 step=0.100000
2017/08/25 21:54:30 step 4: mse=0.229114 step=0.100000
2017/08/25 21:54:31 step 5: mse=0.222559 step=0.100000
2017/08/25 21:54:33 step 6: mse=0.216480 step=0.100000
2017/08/25 21:54:35 step 7: mse=0.210707 step=0.100000
2017/08/25 21:54:35 Saving...
2017/08/25 21:54:35 Gathering batch of experience...
2017/08/25 21:54:45 batch 40: mean=4.091954 stddev=2.371440 entropy=1.344407 frames=33222 count=87
2017/08/25 21:54:45 Training policy...
2017/08/25 21:54:47 step 0: objective=0.004067514
2017/08/25 21:54:48 step 1: objective=0.004098933
2017/08/25 21:54:49 step 2: objective=0.004132176
2017/08/25 21:54:50 step 3: objective=0.004165351
2017/08/25 21:54:51 step 4: objective=0.0041985395
2017/08/25 21:54:52 step 5: objective=0.004231717
2017/08/25 21:54:53 step 6: objective=0.004264828
2017/08/25 21:54:54 step 7: objective=0.004297969
2017/08/25 21:54:54 Training value function...
2017/08/25 21:54:56 step 0: mse=0.255644 step=0.100000
2017/08/25 21:54:57 step 1: mse=0.250020 step=0.100000
2017/08/25 21:54:59 step 2: mse=0.242953 step=0.100000
2017/08/25 21:55:00 step 3: mse=0.237162 step=0.100000
2017/08/25 21:55:02 step 4: mse=0.234030 step=0.100000
2017/08/25 21:55:03 step 5: mse=0.229280 step=0.100000
2017/08/25 21:55:05 step 6: mse=0.225286 step=0.100000
2017/08/25 21:55:06 step 7: mse=0.222996 step=0.100000
2017/08/25 21:55:06 Saving...
2017/08/25 21:55:06 Gathering batch of experience...
2017/08/25 21:55:17 batch 41: mean=4.703704 stddev=2.584113 entropy=1.342680 frames=32889 count=81
2017/08/25 21:55:17 Training policy...
2017/08/25 21:55:19 step 0: objective=0.018245492
2017/08/25 21:55:20 step 1: objective=0.018277004
2017/08/25 21:55:21 step 2: objective=0.018308723
2017/08/25 21:55:22 step 3: objective=0.01834032
2017/08/25 21:55:22 step 4: objective=0.018371925
2017/08/25 21:55:23 step 5: objective=0.018403592
2017/08/25 21:55:24 step 6: objective=0.018435119
2017/08/25 21:55:25 step 7: objective=0.018466799
2017/08/25 21:55:25 Training value function...
2017/08/25 21:55:27 step 0: mse=0.371594 step=0.100000
2017/08/25 21:55:29 step 1: mse=0.349595 step=0.100000
2017/08/25 21:55:30 step 2: mse=0.331405 step=0.100000
2017/08/25 21:55:32 step 3: mse=0.316524 step=0.100000
2017/08/25 21:55:33 step 4: mse=0.302913 step=0.100000
2017/08/25 21:55:35 step 5: mse=0.291971 step=0.100000
2017/08/25 21:55:36 step 6: mse=0.281890 step=0.100000
2017/08/25 21:55:38 step 7: mse=0.272229 step=0.100000
2017/08/25 21:55:38 Saving...
2017/08/25 21:55:38 Gathering batch of experience...
2017/08/25 21:55:49 batch 42: mean=4.900000 stddev=2.567100 entropy=1.339631 frames=33793 count=80
2017/08/25 21:55:49 Training policy...
2017/08/25 21:55:51 step 0: objective=0.00885312
2017/08/25 21:55:52 step 1: objective=0.008885902
2017/08/25 21:55:53 step 2: objective=0.008918794
2017/08/25 21:55:54 step 3: objective=0.008951721
2017/08/25 21:55:55 step 4: objective=0.008984741
2017/08/25 21:55:56 step 5: objective=0.009017566
2017/08/25 21:55:57 step 6: objective=0.009042649
2017/08/25 21:55:58 step 7: objective=0.009075509
2017/08/25 21:55:58 Training value function...
2017/08/25 21:56:00 step 0: mse=0.310948 step=0.100000
2017/08/25 21:56:01 step 1: mse=0.294510 step=0.100000
2017/08/25 21:56:03 step 2: mse=0.280415 step=0.100000
2017/08/25 21:56:05 step 3: mse=0.268754 step=0.100000
2017/08/25 21:56:06 step 4: mse=0.259151 step=0.100000
2017/08/25 21:56:08 step 5: mse=0.248811 step=0.100000
2017/08/25 21:56:09 step 6: mse=0.239699 step=0.100000
2017/08/25 21:56:11 step 7: mse=0.231409 step=0.100000
2017/08/25 21:56:11 Saving...
2017/08/25 21:56:11 Gathering batch of experience...
2017/08/25 21:56:22 batch 43: mean=4.884615 stddev=2.270100 entropy=1.338391 frames=33996 count=78
2017/08/25 21:56:22 Training policy...
2017/08/25 21:56:24 step 0: objective=-0.0015233684
2017/08/25 21:56:25 step 1: objective=-0.0014568367
2017/08/25 21:56:26 step 2: objective=-0.0013908186
2017/08/25 21:56:27 step 3: objective=-0.0013253287
2017/08/25 21:56:28 step 4: objective=-0.001260357
2017/08/25 21:56:29 step 5: objective=-0.001195903
2017/08/25 21:56:30 step 6: objective=-0.0011368414
2017/08/25 21:56:31 step 7: objective=-0.0010867295
2017/08/25 21:56:31 Training value function...
2017/08/25 21:56:33 step 0: mse=0.245931 step=0.100000
2017/08/25 21:56:35 step 1: mse=0.234654 step=0.100000
2017/08/25 21:56:36 step 2: mse=0.224868 step=0.100000
2017/08/25 21:56:38 step 3: mse=0.217046 step=0.100000
2017/08/25 21:56:40 step 4: mse=0.209330 step=0.100000
2017/08/25 21:56:41 step 5: mse=0.203129 step=0.100000
2017/08/25 21:56:43 step 6: mse=0.197641 step=0.100000
2017/08/25 21:56:44 step 7: mse=0.193397 step=0.100000
2017/08/25 21:56:44 Saving...
2017/08/25 21:56:44 Gathering batch of experience...
2017/08/25 21:56:55 batch 44: mean=4.851852 stddev=2.592063 entropy=1.336724 frames=33721 count=81
2017/08/25 21:56:55 Training policy...
2017/08/25 21:56:58 step 0: objective=0.015460678
2017/08/25 21:56:59 step 1: objective=0.01549893
2017/08/25 21:57:00 step 2: objective=0.015536961
2017/08/25 21:57:01 step 3: objective=0.015574942
2017/08/25 21:57:02 step 4: objective=0.015612685
2017/08/25 21:57:03 step 5: objective=0.015650267
2017/08/25 21:57:04 step 6: objective=0.015687896
2017/08/25 21:57:05 step 7: objective=0.01572524
2017/08/25 21:57:05 Training value function...
2017/08/25 21:57:07 step 0: mse=0.308469 step=0.100000
2017/08/25 21:57:09 step 1: mse=0.293982 step=0.100000
2017/08/25 21:57:10 step 2: mse=0.281301 step=0.100000
2017/08/25 21:57:12 step 3: mse=0.271049 step=0.100000
2017/08/25 21:57:13 step 4: mse=0.262098 step=0.100000
2017/08/25 21:57:15 step 5: mse=0.254211 step=0.100000
2017/08/25 21:57:17 step 6: mse=0.247267 step=0.100000
2017/08/25 21:57:18 step 7: mse=0.241916 step=0.100000
2017/08/25 21:57:18 Saving...
2017/08/25 21:57:18 Gathering batch of experience...
2017/08/25 21:57:29 batch 45: mean=4.658537 stddev=2.390119 entropy=1.339018 frames=33276 count=82
2017/08/25 21:57:29 Training policy...
2017/08/25 21:57:32 step 0: objective=-0.003155274
2017/08/25 21:57:33 step 1: objective=-0.003107258
2017/08/25 21:57:34 step 2: objective=-0.0030594252
2017/08/25 21:57:35 step 3: objective=-0.0030117799
2017/08/25 21:57:36 step 4: objective=-0.0029643192
2017/08/25 21:57:36 step 5: objective=-0.0029171621
2017/08/25 21:57:38 step 6: objective=-0.0028741288
2017/08/25 21:57:38 step 7: objective=-0.0028247614
2017/08/25 21:57:38 Training value function...
2017/08/25 21:57:41 step 0: mse=0.292231 step=0.100000
2017/08/25 21:57:42 step 1: mse=0.283995 step=0.100000
2017/08/25 21:57:44 step 2: mse=0.277256 step=0.100000
2017/08/25 21:57:46 step 3: mse=0.270700 step=0.100000
2017/08/25 21:57:47 step 4: mse=0.263107 step=0.100000
2017/08/25 21:57:49 step 5: mse=0.257683 step=0.100000
2017/08/25 21:57:51 step 6: mse=0.250573 step=0.100000
2017/08/25 21:57:52 step 7: mse=0.245923 step=0.100000
2017/08/25 21:57:52 Saving...
2017/08/25 21:57:52 Gathering batch of experience...
2017/08/25 21:58:03 batch 46: mean=4.887500 stddev=2.683252 entropy=1.335740 frames=33318 count=80
2017/08/25 21:58:03 Training policy...
2017/08/25 21:58:05 step 0: objective=0.016296005
2017/08/25 21:58:06 step 1: objective=0.016333302
2017/08/25 21:58:07 step 2: objective=0.016370459
2017/08/25 21:58:08 step 3: objective=0.016407648
2017/08/25 21:58:09 step 4: objective=0.016444894
2017/08/25 21:58:10 step 5: objective=0.016482165
2017/08/25 21:58:11 step 6: objective=0.016519424
2017/08/25 21:58:12 step 7: objective=0.01655658
2017/08/25 21:58:12 Training value function...
2017/08/25 21:58:14 step 0: mse=0.374624 step=0.100000
2017/08/25 21:58:16 step 1: mse=0.351544 step=0.100000
2017/08/25 21:58:18 step 2: mse=0.332710 step=0.100000
2017/08/25 21:58:20 step 3: mse=0.317004 step=0.100000
2017/08/25 21:58:21 step 4: mse=0.303934 step=0.100000
2017/08/25 21:58:23 step 5: mse=0.293482 step=0.100000
2017/08/25 21:58:25 step 6: mse=0.281582 step=0.100000
2017/08/25 21:58:27 step 7: mse=0.270508 step=0.100000
2017/08/25 21:58:27 Saving...
2017/08/25 21:58:27 Gathering batch of experience...
2017/08/25 21:58:37 batch 47: mean=5.037975 stddev=2.308175 entropy=1.336472 frames=33503 count=79
2017/08/25 21:58:37 Training policy...
2017/08/25 21:58:40 step 0: objective=0.008466457
2017/08/25 21:58:41 step 1: objective=0.008490294
2017/08/25 21:58:42 step 2: objective=0.0085140085
2017/08/25 21:58:43 step 3: objective=0.00853755
2017/08/25 21:58:44 step 4: objective=0.008561045
2017/08/25 21:58:45 step 5: objective=0.008584401
2017/08/25 21:58:46 step 6: objective=0.00860757
2017/08/25 21:58:47 step 7: objective=0.008630621
2017/08/25 21:58:47 Training value function...
2017/08/25 21:58:49 step 0: mse=0.337495 step=0.100000
2017/08/25 21:58:51 step 1: mse=0.317595 step=0.100000
2017/08/25 21:58:53 step 2: mse=0.301947 step=0.100000
2017/08/25 21:58:54 step 3: mse=0.287945 step=0.100000
2017/08/25 21:58:56 step 4: mse=0.276880 step=0.100000
2017/08/25 21:58:58 step 5: mse=0.267656 step=0.100000
2017/08/25 21:58:59 step 6: mse=0.259987 step=0.100000
2017/08/25 21:59:01 step 7: mse=0.253842 step=0.100000
2017/08/25 21:59:01 Saving...
2017/08/25 21:59:01 Gathering batch of experience...
2017/08/25 21:59:12 batch 48: mean=5.253165 stddev=2.870489 entropy=1.333500 frames=34245 count=79
2017/08/25 21:59:12 Training policy...
2017/08/25 21:59:15 step 0: objective=0.008481881
2017/08/25 21:59:16 step 1: objective=0.008518849
2017/08/25 21:59:17 step 2: objective=0.008555798
2017/08/25 21:59:18 step 3: objective=0.008592752
2017/08/25 21:59:19 step 4: objective=0.008629693
2017/08/25 21:59:20 step 5: objective=0.008666617
2017/08/25 21:59:21 step 6: objective=0.008703501
2017/08/25 21:59:22 step 7: objective=0.008739529
2017/08/25 21:59:22 Training value function...
2017/08/25 21:59:25 step 0: mse=0.344208 step=0.100000
2017/08/25 21:59:27 step 1: mse=0.328506 step=0.100000
2017/08/25 21:59:28 step 2: mse=0.316302 step=0.100000
2017/08/25 21:59:30 step 3: mse=0.305528 step=0.100000
2017/08/25 21:59:32 step 4: mse=0.296781 step=0.100000
2017/08/25 21:59:34 step 5: mse=0.282003 step=0.100000
2017/08/25 21:59:36 step 6: mse=0.269920 step=0.100000
2017/08/25 21:59:37 step 7: mse=0.261079 step=0.100000
2017/08/25 21:59:37 Saving...
2017/08/25 21:59:37 Gathering batch of experience...
2017/08/25 21:59:48 batch 49: mean=4.848101 stddev=2.261895 entropy=1.334056 frames=33507 count=79
2017/08/25 21:59:48 Training policy...
2017/08/25 21:59:51 step 0: objective=-0.006681471
2017/08/25 21:59:52 step 1: objective=-0.006631623
2017/08/25 21:59:53 step 2: objective=-0.006582004
2017/08/25 21:59:54 step 3: objective=-0.006532527
2017/08/25 21:59:55 step 4: objective=-0.006483525
2017/08/25 21:59:56 step 5: objective=-0.006440617
2017/08/25 21:59:57 step 6: objective=-0.0064227553
2017/08/25 21:59:58 step 7: objective=-0.00641113
2017/08/25 21:59:58 Training value function...
2017/08/25 22:00:00 step 0: mse=0.316028 step=0.100000
2017/08/25 22:00:02 step 1: mse=0.295615 step=0.100000
2017/08/25 22:00:04 step 2: mse=0.278988 step=0.100000
2017/08/25 22:00:06 step 3: mse=0.265401 step=0.100000
2017/08/25 22:00:07 step 4: mse=0.254217 step=0.100000
2017/08/25 22:00:09 step 5: mse=0.242919 step=0.100000
2017/08/25 22:00:11 step 6: mse=0.233254 step=0.100000
2017/08/25 22:00:13 step 7: mse=0.225643 step=0.100000
2017/08/25 22:00:13 Saving...
2017/08/25 22:00:13 Gathering batch of experience...
2017/08/25 22:00:23 batch 50: mean=5.141026 stddev=2.673346 entropy=1.335388 frames=33256 count=78
2017/08/25 22:00:23 Training policy...
2017/08/25 22:00:26 step 0: objective=0.01764863
2017/08/25 22:00:27 step 1: objective=0.017696127
2017/08/25 22:00:28 step 2: objective=0.017748345
2017/08/25 22:00:29 step 3: objective=0.017800823
2017/08/25 22:00:30 step 4: objective=0.017853908
2017/08/25 22:00:31 step 5: objective=0.01790094
2017/08/25 22:00:32 step 6: objective=0.017960457
2017/08/25 22:00:33 step 7: objective=0.018016053
2017/08/25 22:00:33 Training value function...
2017/08/25 22:00:35 step 0: mse=0.365331 step=0.100000
2017/08/25 22:00:37 step 1: mse=0.347840 step=0.100000
2017/08/25 22:00:39 step 2: mse=0.333675 step=0.100000
2017/08/25 22:00:41 step 3: mse=0.322145 step=0.100000
2017/08/25 22:00:43 step 4: mse=0.313695 step=0.100000
2017/08/25 22:00:44 step 5: mse=0.305606 step=0.100000
2017/08/25 22:00:46 step 6: mse=0.289212 step=0.100000
2017/08/25 22:00:48 step 7: mse=0.283245 step=0.100000
2017/08/25 22:00:48 Saving...
2017/08/25 22:00:48 Gathering batch of experience...
2017/08/25 22:00:59 batch 51: mean=4.833333 stddev=2.289422 entropy=1.332328 frames=32473 count=78
2017/08/25 22:00:59 Training policy...
2017/08/25 22:01:01 step 0: objective=0.002010586
2017/08/25 22:01:02 step 1: objective=0.002083139
2017/08/25 22:01:03 step 2: objective=0.0021542856
2017/08/25 22:01:04 step 3: objective=0.0022263757
2017/08/25 22:01:05 step 4: objective=0.0022812206
2017/08/25 22:01:06 step 5: objective=0.0023194498
2017/08/25 22:01:07 step 6: objective=0.0023616103
2017/08/25 22:01:08 step 7: objective=0.0023993608
2017/08/25 22:01:08 Training value function...
2017/08/25 22:01:10 step 0: mse=0.309248 step=0.100000
2017/08/25 22:01:12 step 1: mse=0.290266 step=0.100000
2017/08/25 22:01:14 step 2: mse=0.275257 step=0.100000
2017/08/25 22:01:16 step 3: mse=0.263047 step=0.100000
2017/08/25 22:01:17 step 4: mse=0.252449 step=0.100000
2017/08/25 22:01:19 step 5: mse=0.243605 step=0.100000
2017/08/25 22:01:21 step 6: mse=0.234627 step=0.100000
2017/08/25 22:01:23 step 7: mse=0.228443 step=0.100000
2017/08/25 22:01:23 Saving...
2017/08/25 22:01:23 Gathering batch of experience...
2017/08/25 22:01:34 batch 52: mean=5.207792 stddev=2.659644 entropy=1.325852 frames=33866 count=77
2017/08/25 22:01:34 Training policy...
2017/08/25 22:01:36 step 0: objective=0.010527184
2017/08/25 22:01:37 step 1: objective=0.010557402
2017/08/25 22:01:38 step 2: objective=0.0105873225
2017/08/25 22:01:40 step 3: objective=0.0106171025
2017/08/25 22:01:41 step 4: objective=0.010646705
2017/08/25 22:01:42 step 5: objective=0.0106876325
2017/08/25 22:01:43 step 6: objective=0.010727961
2017/08/25 22:01:44 step 7: objective=0.010746313
2017/08/25 22:01:44 Training value function...
2017/08/25 22:01:46 step 0: mse=0.384771 step=0.100000
2017/08/25 22:01:48 step 1: mse=0.368523 step=0.100000
2017/08/25 22:01:50 step 2: mse=0.358992 step=0.100000
2017/08/25 22:01:52 step 3: mse=0.344004 step=0.100000
2017/08/25 22:01:54 step 4: mse=0.331773 step=0.100000
2017/08/25 22:01:56 step 5: mse=0.321174 step=0.100000
2017/08/25 22:01:58 step 6: mse=0.315266 step=0.100000
2017/08/25 22:02:00 step 7: mse=0.302354 step=0.100000
2017/08/25 22:02:00 Saving...
2017/08/25 22:02:00 Gathering batch of experience...
2017/08/25 22:02:11 batch 53: mean=5.453333 stddev=3.007960 entropy=1.328417 frames=33383 count=75
2017/08/25 22:02:11 Training policy...
2017/08/25 22:02:13 step 0: objective=0.012400416
2017/08/25 22:02:14 step 1: objective=0.012443394
2017/08/25 22:02:16 step 2: objective=0.012486518
2017/08/25 22:02:17 step 3: objective=0.0125292
2017/08/25 22:02:18 step 4: objective=0.012571706
2017/08/25 22:02:19 step 5: objective=0.012613814
2017/08/25 22:02:20 step 6: objective=0.012655505
2017/08/25 22:02:21 step 7: objective=0.012692203
2017/08/25 22:02:21 Training value function...
2017/08/25 22:02:23 step 0: mse=0.495887 step=0.100000
2017/08/25 22:02:25 step 1: mse=0.461817 step=0.100000
2017/08/25 22:02:27 step 2: mse=0.433669 step=0.100000
2017/08/25 22:02:29 step 3: mse=0.411521 step=0.100000
2017/08/25 22:02:31 step 4: mse=0.390284 step=0.100000
2017/08/25 22:02:33 step 5: mse=0.372756 step=0.100000
2017/08/25 22:02:35 step 6: mse=0.358546 step=0.100000
2017/08/25 22:02:37 step 7: mse=0.344146 step=0.100000
2017/08/25 22:02:37 Saving...
2017/08/25 22:02:37 Gathering batch of experience...
2017/08/25 22:02:47 batch 54: mean=4.530864 stddev=2.331144 entropy=1.330627 frames=32988 count=81
2017/08/25 22:02:47 Training policy...
2017/08/25 22:02:50 step 0: objective=-0.008717222
2017/08/25 22:02:51 step 1: objective=-0.0086749345
2017/08/25 22:02:52 step 2: objective=-0.008632749
2017/08/25 22:02:53 step 3: objective=-0.00859072
2017/08/25 22:02:54 step 4: objective=-0.008549069
2017/08/25 22:02:55 step 5: objective=-0.008507448
2017/08/25 22:02:56 step 6: objective=-0.008466091
2017/08/25 22:02:58 step 7: objective=-0.008424861
2017/08/25 22:02:58 Training value function...
2017/08/25 22:03:00 step 0: mse=0.235974 step=0.100000
2017/08/25 22:03:02 step 1: mse=0.225488 step=0.100000
2017/08/25 22:03:04 step 2: mse=0.216914 step=0.100000
2017/08/25 22:03:05 step 3: mse=0.209881 step=0.100000
2017/08/25 22:03:07 step 4: mse=0.204149 step=0.100000
2017/08/25 22:03:09 step 5: mse=0.199351 step=0.100000
2017/08/25 22:03:11 step 6: mse=0.195715 step=0.100000
2017/08/25 22:03:13 step 7: mse=0.192367 step=0.100000
2017/08/25 22:03:13 Saving...
2017/08/25 22:03:13 Gathering batch of experience...
2017/08/25 22:03:24 batch 55: mean=5.675676 stddev=2.838481 entropy=1.325290 frames=33829 count=74
2017/08/25 22:03:24 Training policy...
2017/08/25 22:03:27 step 0: objective=0.014142322
2017/08/25 22:03:28 step 1: objective=0.014180479
2017/08/25 22:03:29 step 2: objective=0.014218715
2017/08/25 22:03:30 step 3: objective=0.014257007
2017/08/25 22:03:31 step 4: objective=0.014295328
2017/08/25 22:03:32 step 5: objective=0.014333669
2017/08/25 22:03:34 step 6: objective=0.014371226
2017/08/25 22:03:35 step 7: objective=0.014421125
2017/08/25 22:03:35 Training value function...
2017/08/25 22:03:37 step 0: mse=0.304173 step=0.100000
2017/08/25 22:03:39 step 1: mse=0.284236 step=0.100000
2017/08/25 22:03:41 step 2: mse=0.267928 step=0.100000
2017/08/25 22:03:43 step 3: mse=0.254185 step=0.100000
2017/08/25 22:03:45 step 4: mse=0.242691 step=0.100000
2017/08/25 22:03:47 step 5: mse=0.233171 step=0.100000
2017/08/25 22:03:49 step 6: mse=0.225234 step=0.100000
2017/08/25 22:03:51 step 7: mse=0.217770 step=0.100000
2017/08/25 22:03:51 Saving...
2017/08/25 22:03:51 Gathering batch of experience...
2017/08/25 22:04:02 batch 56: mean=5.513514 stddev=2.820021 entropy=1.327685 frames=33455 count=74
2017/08/25 22:04:02 Training policy...
2017/08/25 22:04:04 step 0: objective=0.008564989
2017/08/25 22:04:05 step 1: objective=0.008628778
2017/08/25 22:04:07 step 2: objective=0.008692164
2017/08/25 22:04:08 step 3: objective=0.008755087
2017/08/25 22:04:09 step 4: objective=0.0088176215
2017/08/25 22:04:10 step 5: objective=0.008879763
2017/08/25 22:04:11 step 6: objective=0.008937562
2017/08/25 22:04:12 step 7: objective=0.0089831455
2017/08/25 22:04:12 Training value function...
2017/08/25 22:04:15 step 0: mse=0.313545 step=0.100000
2017/08/25 22:04:17 step 1: mse=0.302223 step=0.100000
2017/08/25 22:04:19 step 2: mse=0.292711 step=0.100000
2017/08/25 22:04:21 step 3: mse=0.284937 step=0.100000
2017/08/25 22:04:23 step 4: mse=0.278080 step=0.100000
2017/08/25 22:04:25 step 5: mse=0.270329 step=0.100000
2017/08/25 22:04:27 step 6: mse=0.263903 step=0.100000
2017/08/25 22:04:29 step 7: mse=0.259702 step=0.100000
2017/08/25 22:04:29 Saving...
2017/08/25 22:04:29 Gathering batch of experience...
2017/08/25 22:04:40 batch 57: mean=5.600000 stddev=2.818983 entropy=1.325968 frames=33727 count=75
2017/08/25 22:04:40 Training policy...
2017/08/25 22:04:42 step 0: objective=0.012478784
2017/08/25 22:04:44 step 1: objective=0.012518915
2017/08/25 22:04:45 step 2: objective=0.012559133
2017/08/25 22:04:46 step 3: objective=0.0125993835
2017/08/25 22:04:47 step 4: objective=0.012639653
2017/08/25 22:04:48 step 5: objective=0.012675878
2017/08/25 22:04:49 step 6: objective=0.012713019
2017/08/25 22:04:51 step 7: objective=0.01276421
2017/08/25 22:04:51 Training value function...
2017/08/25 22:04:53 step 0: mse=0.491445 step=0.100000
2017/08/25 22:04:55 step 1: mse=0.459231 step=0.100000
2017/08/25 22:04:57 step 2: mse=0.433099 step=0.100000
2017/08/25 22:04:59 step 3: mse=0.411403 step=0.100000
2017/08/25 22:05:01 step 4: mse=0.392907 step=0.100000
2017/08/25 22:05:03 step 5: mse=0.378172 step=0.100000
2017/08/25 22:05:05 step 6: mse=0.365345 step=0.100000
2017/08/25 22:05:07 step 7: mse=0.354825 step=0.100000
2017/08/25 22:05:07 Saving...
2017/08/25 22:05:07 Gathering batch of experience...
2017/08/25 22:05:18 batch 58: mean=5.129870 stddev=2.482932 entropy=1.326380 frames=33319 count=77
2017/08/25 22:05:18 Training policy...
2017/08/25 22:05:21 step 0: objective=-0.0011912168
2017/08/25 22:05:22 step 1: objective=-0.0011703876
2017/08/25 22:05:23 step 2: objective=-0.001149532
2017/08/25 22:05:25 step 3: objective=-0.0011286105
2017/08/25 22:05:26 step 4: objective=-0.0011076451
2017/08/25 22:05:27 step 5: objective=-0.0010866392
2017/08/25 22:05:28 step 6: objective=-0.0010655832
2017/08/25 22:05:29 step 7: objective=-0.0010446305
2017/08/25 22:05:29 Training value function...
2017/08/25 22:05:32 step 0: mse=0.286900 step=0.100000
2017/08/25 22:05:34 step 1: mse=0.274035 step=0.100000
2017/08/25 22:05:36 step 2: mse=0.263533 step=0.100000
2017/08/25 22:05:38 step 3: mse=0.254946 step=0.100000
2017/08/25 22:05:40 step 4: mse=0.247809 step=0.100000
2017/08/25 22:05:42 step 5: mse=0.241483 step=0.100000
2017/08/25 22:05:44 step 6: mse=0.236355 step=0.100000
2017/08/25 22:05:46 step 7: mse=0.232923 step=0.100000
2017/08/25 22:05:46 Saving...
2017/08/25 22:05:46 Gathering batch of experience...
2017/08/25 22:05:57 batch 59: mean=5.722222 stddev=2.849085 entropy=1.326063 frames=33518 count=72
2017/08/25 22:05:57 Training policy...
2017/08/25 22:06:00 step 0: objective=0.025414485
2017/08/25 22:06:01 step 1: objective=0.02547381
2017/08/25 22:06:02 step 2: objective=0.025533134
2017/08/25 22:06:03 step 3: objective=0.025592698
2017/08/25 22:06:05 step 4: objective=0.025652146
2017/08/25 22:06:06 step 5: objective=0.025711656
2017/08/25 22:06:07 step 6: objective=0.025768314
2017/08/25 22:06:08 step 7: objective=0.025830688
2017/08/25 22:06:08 Training value function...
2017/08/25 22:06:11 step 0: mse=0.548062 step=0.100000
2017/08/25 22:06:13 step 1: mse=0.499732 step=0.100000
2017/08/25 22:06:15 step 2: mse=0.461402 step=0.100000
2017/08/25 22:06:17 step 3: mse=0.424605 step=0.100000
2017/08/25 22:06:19 step 4: mse=0.394609 step=0.100000
2017/08/25 22:06:21 step 5: mse=0.367271 step=0.100000
2017/08/25 22:06:23 step 6: mse=0.347683 step=0.100000
2017/08/25 22:06:25 step 7: mse=0.328597 step=0.100000
2017/08/25 22:06:25 Saving...
2017/08/25 22:06:25 Gathering batch of experience...
2017/08/25 22:06:36 batch 60: mean=5.635135 stddev=2.998082 entropy=1.324095 frames=34292 count=74
2017/08/25 22:06:36 Training policy...
2017/08/25 22:06:39 step 0: objective=0.009518228
2017/08/25 22:06:40 step 1: objective=0.00956726
2017/08/25 22:06:42 step 2: objective=0.009616386
2017/08/25 22:06:43 step 3: objective=0.009665529
2017/08/25 22:06:44 step 4: objective=0.009713028
2017/08/25 22:06:45 step 5: objective=0.009737047
2017/08/25 22:06:47 step 6: objective=0.009765812
2017/08/25 22:06:48 step 7: objective=0.009792727
2017/08/25 22:06:48 Training value function...
2017/08/25 22:06:50 step 0: mse=0.410959 step=0.100000
2017/08/25 22:06:53 step 1: mse=0.381021 step=0.100000
2017/08/25 22:06:55 step 2: mse=0.356723 step=0.100000
2017/08/25 22:06:57 step 3: mse=0.337011 step=0.100000
2017/08/25 22:06:59 step 4: mse=0.320135 step=0.100000
2017/08/25 22:07:01 step 5: mse=0.306137 step=0.100000
2017/08/25 22:07:03 step 6: mse=0.293353 step=0.100000
2017/08/25 22:07:06 step 7: mse=0.281665 step=0.100000
2017/08/25 22:07:06 Saving...
2017/08/25 22:07:06 Gathering batch of experience...
2017/08/25 22:07:17 batch 61: mean=5.038462 stddev=2.539141 entropy=1.327415 frames=33565 count=78
2017/08/25 22:07:17 Training policy...
2017/08/25 22:07:19 step 0: objective=-0.0068926
2017/08/25 22:07:21 step 1: objective=-0.0068665068
2017/08/25 22:07:22 step 2: objective=-0.0068518054
2017/08/25 22:07:23 step 3: objective=-0.006825798
2017/08/25 22:07:24 step 4: objective=-0.006811105
2017/08/25 22:07:25 step 5: objective=-0.00678519
2017/08/25 22:07:27 step 6: objective=-0.0067704883
2017/08/25 22:07:28 step 7: objective=-0.006750819
2017/08/25 22:07:28 Training value function...
2017/08/25 22:07:30 step 0: mse=0.268345 step=0.100000
2017/08/25 22:07:33 step 1: mse=0.254386 step=0.100000
2017/08/25 22:07:35 step 2: mse=0.241492 step=0.100000
2017/08/25 22:07:37 step 3: mse=0.232188 step=0.100000
2017/08/25 22:07:39 step 4: mse=0.223391 step=0.100000
2017/08/25 22:07:41 step 5: mse=0.216976 step=0.100000
2017/08/25 22:07:43 step 6: mse=0.209837 step=0.100000
2017/08/25 22:07:45 step 7: mse=0.205452 step=0.100000
2017/08/25 22:07:45 Saving...
2017/08/25 22:07:45 Gathering batch of experience...
2017/08/25 22:07:56 batch 62: mean=5.704225 stddev=2.825410 entropy=1.324123 frames=33643 count=71
2017/08/25 22:07:56 Training policy...
2017/08/25 22:07:59 step 0: objective=0.0032021673
2017/08/25 22:08:00 step 1: objective=0.0032438058
2017/08/25 22:08:01 step 2: objective=0.0032853258
2017/08/25 22:08:03 step 3: objective=0.003326696
2017/08/25 22:08:04 step 4: objective=0.003367965
2017/08/25 22:08:05 step 5: objective=0.0034090795
2017/08/25 22:08:06 step 6: objective=0.0034459322
2017/08/25 22:08:08 step 7: objective=0.0034677372
2017/08/25 22:08:08 Training value function...
2017/08/25 22:08:10 step 0: mse=0.303202 step=0.100000
2017/08/25 22:08:12 step 1: mse=0.294145 step=0.100000
2017/08/25 22:08:15 step 2: mse=0.286771 step=0.100000
2017/08/25 22:08:17 step 3: mse=0.278700 step=0.100000
2017/08/25 22:08:19 step 4: mse=0.272142 step=0.100000
2017/08/25 22:08:21 step 5: mse=0.266743 step=0.100000
2017/08/25 22:08:23 step 6: mse=0.255990 step=0.100000
2017/08/25 22:08:25 step 7: mse=0.251810 step=0.100000
2017/08/25 22:08:25 Saving...
2017/08/25 22:08:25 Gathering batch of experience...
2017/08/25 22:08:36 batch 63: mean=4.846154 stddev=2.660619 entropy=1.325870 frames=33083 count=78
2017/08/25 22:08:36 Training policy...
2017/08/25 22:08:39 step 0: objective=-0.009189135
2017/08/25 22:08:40 step 1: objective=-0.0091608595
2017/08/25 22:08:42 step 2: objective=-0.009132636
2017/08/25 22:08:43 step 3: objective=-0.009104496
2017/08/25 22:08:44 step 4: objective=-0.009076446
2017/08/25 22:08:45 step 5: objective=-0.009048441
2017/08/25 22:08:46 step 6: objective=-0.009020536
2017/08/25 22:08:48 step 7: objective=-0.008992679
2017/08/25 22:08:48 Training value function...
2017/08/25 22:08:50 step 0: mse=0.255693 step=0.100000
2017/08/25 22:08:52 step 1: mse=0.248972 step=0.100000
2017/08/25 22:08:55 step 2: mse=0.243488 step=0.100000
2017/08/25 22:08:57 step 3: mse=0.238941 step=0.100000
2017/08/25 22:08:59 step 4: mse=0.235155 step=0.100000
2017/08/25 22:09:01 step 5: mse=0.230712 step=0.100000
2017/08/25 22:09:03 step 6: mse=0.225864 step=0.100000
2017/08/25 22:09:06 step 7: mse=0.223424 step=0.100000
2017/08/25 22:09:06 Saving...
2017/08/25 22:09:06 Gathering batch of experience...
2017/08/25 22:09:17 batch 64: mean=5.680000 stddev=2.776857 entropy=1.325531 frames=34541 count=75
2017/08/25 22:09:17 Training policy...
2017/08/25 22:09:20 step 0: objective=0.013921149
2017/08/25 22:09:21 step 1: objective=0.013946041
2017/08/25 22:09:22 step 2: objective=0.013970721
2017/08/25 22:09:24 step 3: objective=0.013995334
2017/08/25 22:09:25 step 4: objective=0.014019833
2017/08/25 22:09:26 step 5: objective=0.014044171
2017/08/25 22:09:28 step 6: objective=0.014068485
2017/08/25 22:09:29 step 7: objective=0.01409264
2017/08/25 22:09:29 Training value function...
2017/08/25 22:09:32 step 0: mse=0.342210 step=0.100000
2017/08/25 22:09:34 step 1: mse=0.325964 step=0.100000
2017/08/25 22:09:37 step 2: mse=0.313705 step=0.100000
2017/08/25 22:09:39 step 3: mse=0.303754 step=0.100000
2017/08/25 22:09:41 step 4: mse=0.295571 step=0.100000
2017/08/25 22:09:44 step 5: mse=0.285920 step=0.100000
2017/08/25 22:09:46 step 6: mse=0.280136 step=0.100000
2017/08/25 22:09:48 step 7: mse=0.274845 step=0.100000
2017/08/25 22:09:48 Saving...
2017/08/25 22:09:48 Gathering batch of experience...
2017/08/25 22:09:59 batch 65: mean=5.153846 stddev=3.162590 entropy=1.325433 frames=33225 count=78
2017/08/25 22:09:59 Training policy...
2017/08/25 22:10:02 step 0: objective=0.004024456
2017/08/25 22:10:03 step 1: objective=0.0040716683
2017/08/25 22:10:04 step 2: objective=0.0041190656
2017/08/25 22:10:06 step 3: objective=0.004166637
2017/08/25 22:10:07 step 4: objective=0.004214384
2017/08/25 22:10:08 step 5: objective=0.0042589065
2017/08/25 22:10:09 step 6: objective=0.0043032607
2017/08/25 22:10:11 step 7: objective=0.0043451195
2017/08/25 22:10:11 Training value function...
2017/08/25 22:10:13 step 0: mse=0.374255 step=0.100000
2017/08/25 22:10:16 step 1: mse=0.354917 step=0.100000
2017/08/25 22:10:18 step 2: mse=0.339151 step=0.100000
2017/08/25 22:10:20 step 3: mse=0.326119 step=0.100000
2017/08/25 22:10:22 step 4: mse=0.315700 step=0.100000
2017/08/25 22:10:24 step 5: mse=0.305301 step=0.100000
2017/08/25 22:10:27 step 6: mse=0.297625 step=0.100000
2017/08/25 22:10:29 step 7: mse=0.290725 step=0.100000
2017/08/25 22:10:29 Saving...
2017/08/25 22:10:29 Gathering batch of experience...
2017/08/25 22:10:40 batch 66: mean=5.589041 stddev=2.718962 entropy=1.323681 frames=33886 count=73
2017/08/25 22:10:40 Training policy...
2017/08/25 22:10:43 step 0: objective=-0.006742992
2017/08/25 22:10:44 step 1: objective=-0.006699224
2017/08/25 22:10:46 step 2: objective=-0.0066556204
2017/08/25 22:10:47 step 3: objective=-0.006612138
2017/08/25 22:10:48 step 4: objective=-0.0065687215
2017/08/25 22:10:49 step 5: objective=-0.0065253815
2017/08/25 22:10:51 step 6: objective=-0.0064823395
2017/08/25 22:10:52 step 7: objective=-0.0064454665
2017/08/25 22:10:52 Training value function...
2017/08/25 22:10:55 step 0: mse=0.356899 step=0.100000
2017/08/25 22:10:57 step 1: mse=0.338663 step=0.100000
2017/08/25 22:10:59 step 2: mse=0.323706 step=0.100000
2017/08/25 22:11:02 step 3: mse=0.308965 step=0.100000
2017/08/25 22:11:04 step 4: mse=0.298402 step=0.100000
2017/08/25 22:11:06 step 5: mse=0.287756 step=0.100000
2017/08/25 22:11:08 step 6: mse=0.278657 step=0.100000
2017/08/25 22:11:11 step 7: mse=0.269658 step=0.100000
2017/08/25 22:11:11 Saving...
2017/08/25 22:11:11 Gathering batch of experience...
2017/08/25 22:11:21 batch 67: mean=4.987179 stddev=2.662626 entropy=1.325698 frames=33303 count=78
2017/08/25 22:11:21 Training policy...
2017/08/25 22:11:24 step 0: objective=0.0011514792
2017/08/25 22:11:26 step 1: objective=0.0011903462
2017/08/25 22:11:27 step 2: objective=0.0012294672
2017/08/25 22:11:28 step 3: objective=0.001268827
2017/08/25 22:11:29 step 4: objective=0.0013084657
2017/08/25 22:11:31 step 5: objective=0.0013483278
2017/08/25 22:11:32 step 6: objective=0.0013727401
2017/08/25 22:11:33 step 7: objective=0.0013900067
2017/08/25 22:11:33 Training value function...
2017/08/25 22:11:36 step 0: mse=0.305819 step=0.100000
2017/08/25 22:11:38 step 1: mse=0.298733 step=0.100000
2017/08/25 22:11:41 step 2: mse=0.292832 step=0.100000
2017/08/25 22:11:43 step 3: mse=0.287722 step=0.100000
2017/08/25 22:11:45 step 4: mse=0.282562 step=0.100000
2017/08/25 22:11:47 step 5: mse=0.277957 step=0.100000
2017/08/25 22:11:50 step 6: mse=0.269114 step=0.100000
2017/08/25 22:11:52 step 7: mse=0.265439 step=0.100000
2017/08/25 22:11:52 Saving...
2017/08/25 22:11:52 Gathering batch of experience...
2017/08/25 22:12:03 batch 68: mean=5.341772 stddev=3.638354 entropy=1.324343 frames=33452 count=79
2017/08/25 22:12:03 Training policy...
2017/08/25 22:12:06 step 0: objective=0.029085834
2017/08/25 22:12:07 step 1: objective=0.029139753
2017/08/25 22:12:08 step 2: objective=0.029193748
2017/08/25 22:12:10 step 3: objective=0.02924778
2017/08/25 22:12:11 step 4: objective=0.02936418
2017/08/25 22:12:12 step 5: objective=0.029424764
2017/08/25 22:12:14 step 6: objective=0.02948157
2017/08/25 22:12:15 step 7: objective=0.029518053
2017/08/25 22:12:15 Training value function...
2017/08/25 22:12:18 step 0: mse=0.852055 step=0.100000
2017/08/25 22:12:20 step 1: mse=0.765945 step=0.100000
2017/08/25 22:12:22 step 2: mse=0.698136 step=0.100000
2017/08/25 22:12:24 step 3: mse=0.643242 step=0.100000
2017/08/25 22:12:27 step 4: mse=0.597057 step=0.100000
2017/08/25 22:12:29 step 5: mse=0.559754 step=0.100000
2017/08/25 22:12:31 step 6: mse=0.524076 step=0.100000
2017/08/25 22:12:34 step 7: mse=0.498339 step=0.100000
2017/08/25 22:12:34 Saving...
2017/08/25 22:12:34 Gathering batch of experience...
2017/08/25 22:12:45 batch 69: mean=5.346667 stddev=2.413812 entropy=1.324397 frames=33659 count=75
2017/08/25 22:12:45 Training policy...
2017/08/25 22:12:48 step 0: objective=-0.0060106404
2017/08/25 22:12:49 step 1: objective=-0.0059817643
2017/08/25 22:12:50 step 2: objective=-0.0059530037
2017/08/25 22:12:52 step 3: objective=-0.005924285
2017/08/25 22:12:53 step 4: objective=-0.0058956095
2017/08/25 22:12:54 step 5: objective=-0.005867033
2017/08/25 22:12:55 step 6: objective=-0.0058389157
2017/08/25 22:12:57 step 7: objective=-0.005814241
2017/08/25 22:12:57 Training value function...
2017/08/25 22:13:00 step 0: mse=0.251688 step=0.100000
2017/08/25 22:13:02 step 1: mse=0.239080 step=0.100000
2017/08/25 22:13:04 step 2: mse=0.228830 step=0.100000
2017/08/25 22:13:07 step 3: mse=0.222054 step=0.100000
2017/08/25 22:13:09 step 4: mse=0.214407 step=0.100000
2017/08/25 22:13:11 step 5: mse=0.209429 step=0.100000
2017/08/25 22:13:14 step 6: mse=0.203501 step=0.100000
2017/08/25 22:13:16 step 7: mse=0.198845 step=0.100000
2017/08/25 22:13:16 Saving...
2017/08/25 22:13:16 Gathering batch of experience...
2017/08/25 22:13:27 batch 70: mean=5.770270 stddev=3.112952 entropy=1.320975 frames=33813 count=74
2017/08/25 22:13:27 Training policy...
2017/08/25 22:13:30 step 0: objective=0.021105997
2017/08/25 22:13:32 step 1: objective=0.02117876
2017/08/25 22:13:33 step 2: objective=0.021251906
2017/08/25 22:13:34 step 3: objective=0.021325028
2017/08/25 22:13:36 step 4: objective=0.021398414
2017/08/25 22:13:37 step 5: objective=0.021468792
2017/08/25 22:13:38 step 6: objective=0.021524224
2017/08/25 22:13:40 step 7: objective=0.021571884
2017/08/25 22:13:40 Training value function...
2017/08/25 22:13:43 step 0: mse=0.552259 step=0.100000
2017/08/25 22:13:45 step 1: mse=0.509326 step=0.100000
2017/08/25 22:13:47 step 2: mse=0.478960 step=0.100000
2017/08/25 22:13:50 step 3: mse=0.450192 step=0.100000
2017/08/25 22:13:52 step 4: mse=0.426376 step=0.100000
2017/08/25 22:13:55 step 5: mse=0.407990 step=0.100000
2017/08/25 22:13:57 step 6: mse=0.390951 step=0.100000
2017/08/25 22:14:00 step 7: mse=0.374242 step=0.100000
2017/08/25 22:14:00 Saving...
2017/08/25 22:14:00 Gathering batch of experience...
2017/08/25 22:14:11 batch 71: mean=5.500000 stddev=3.024027 entropy=1.322961 frames=33885 count=76
2017/08/25 22:14:11 Training policy...
2017/08/25 22:14:14 step 0: objective=-0.0005390895
2017/08/25 22:14:15 step 1: objective=-0.00047585784
2017/08/25 22:14:16 step 2: objective=-0.0004125054
2017/08/25 22:14:18 step 3: objective=-0.00034902306
2017/08/25 22:14:19 step 4: objective=-0.0002888665
2017/08/25 22:14:20 step 5: objective=-0.00024001859
2017/08/25 22:14:22 step 6: objective=-0.00019658913
2017/08/25 22:14:23 step 7: objective=-0.00016506214
2017/08/25 22:14:23 Training value function...
2017/08/25 22:14:26 step 0: mse=0.418549 step=0.100000
2017/08/25 22:14:29 step 1: mse=0.395202 step=0.100000
2017/08/25 22:14:31 step 2: mse=0.376101 step=0.100000
2017/08/25 22:14:34 step 3: mse=0.360531 step=0.100000
2017/08/25 22:14:36 step 4: mse=0.347783 step=0.100000
2017/08/25 22:14:39 step 5: mse=0.337331 step=0.100000
2017/08/25 22:14:41 step 6: mse=0.328683 step=0.100000
2017/08/25 22:14:44 step 7: mse=0.317634 step=0.100000
2017/08/25 22:14:44 Saving...
2017/08/25 22:14:44 Gathering batch of experience...
2017/08/25 22:14:55 batch 72: mean=5.808219 stddev=3.046028 entropy=1.319768 frames=33492 count=73
2017/08/25 22:14:55 Training policy...
2017/08/25 22:14:58 step 0: objective=0.0048769903
2017/08/25 22:14:59 step 1: objective=0.004923687
2017/08/25 22:15:00 step 2: objective=0.0049702795
2017/08/25 22:15:02 step 3: objective=0.0050642174
2017/08/25 22:15:03 step 4: objective=0.005119416
2017/08/25 22:15:04 step 5: objective=0.005172211
2017/08/25 22:15:06 step 6: objective=0.0052157966
2017/08/25 22:15:07 step 7: objective=0.005247227
2017/08/25 22:15:07 Training value function...
2017/08/25 22:15:10 step 0: mse=0.505925 step=0.100000
2017/08/25 22:15:13 step 1: mse=0.477073 step=0.100000
2017/08/25 22:15:15 step 2: mse=0.446721 step=0.100000
2017/08/25 22:15:17 step 3: mse=0.416591 step=0.100000
2017/08/25 22:15:20 step 4: mse=0.392299 step=0.100000
2017/08/25 22:15:22 step 5: mse=0.373459 step=0.100000
2017/08/25 22:15:25 step 6: mse=0.354037 step=0.100000
2017/08/25 22:15:27 step 7: mse=0.338746 step=0.100000
2017/08/25 22:15:27 Saving...
2017/08/25 22:15:27 Gathering batch of experience...
2017/08/25 22:15:38 batch 73: mean=5.680000 stddev=3.270719 entropy=1.320513 frames=33633 count=75
2017/08/25 22:15:38 Training policy...
2017/08/25 22:15:41 step 0: objective=0.011520914
2017/08/25 22:15:43 step 1: objective=0.011574476
2017/08/25 22:15:44 step 2: objective=0.011627826
2017/08/25 22:15:45 step 3: objective=0.011681029
2017/08/25 22:15:47 step 4: objective=0.011733982
2017/08/25 22:15:48 step 5: objective=0.0117868
2017/08/25 22:15:50 step 6: objective=0.011839302
2017/08/25 22:15:51 step 7: objective=0.011888254
2017/08/25 22:15:51 Training value function...
2017/08/25 22:15:54 step 0: mse=0.497661 step=0.100000
2017/08/25 22:15:57 step 1: mse=0.472155 step=0.100000
2017/08/25 22:15:59 step 2: mse=0.451426 step=0.100000
2017/08/25 22:16:02 step 3: mse=0.434376 step=0.100000
2017/08/25 22:16:04 step 4: mse=0.420163 step=0.100000
2017/08/25 22:16:07 step 5: mse=0.408205 step=0.100000
2017/08/25 22:16:09 step 6: mse=0.396791 step=0.100000
2017/08/25 22:16:11 step 7: mse=0.385919 step=0.100000
2017/08/25 22:16:11 Saving...
2017/08/25 22:16:11 Gathering batch of experience...
2017/08/25 22:16:23 batch 74: mean=6.125000 stddev=3.312172 entropy=1.321763 frames=33865 count=72
2017/08/25 22:16:23 Training policy...
2017/08/25 22:16:26 step 0: objective=0.0061429474
2017/08/25 22:16:27 step 1: objective=0.006227427
2017/08/25 22:16:28 step 2: objective=0.0063126357
2017/08/25 22:16:30 step 3: objective=0.006398524
2017/08/25 22:16:31 step 4: objective=0.0064539253
2017/08/25 22:16:33 step 5: objective=0.0065046903
2017/08/25 22:16:34 step 6: objective=0.006538802
2017/08/25 22:16:35 step 7: objective=0.0065619545
2017/08/25 22:16:35 Training value function...
2017/08/25 22:16:38 step 0: mse=0.490056 step=0.100000
2017/08/25 22:16:41 step 1: mse=0.455321 step=0.100000
2017/08/25 22:16:44 step 2: mse=0.427000 step=0.100000
2017/08/25 22:16:46 step 3: mse=0.403158 step=0.100000
2017/08/25 22:16:49 step 4: mse=0.384008 step=0.100000
2017/08/25 22:16:51 step 5: mse=0.366171 step=0.100000
2017/08/25 22:16:54 step 6: mse=0.353035 step=0.100000
2017/08/25 22:16:56 step 7: mse=0.339609 step=0.100000
2017/08/25 22:16:56 Saving...
2017/08/25 22:16:56 Gathering batch of experience...
2017/08/25 22:17:07 batch 75: mean=5.573333 stddev=3.042689 entropy=1.323285 frames=34117 count=75
2017/08/25 22:17:07 Training policy...
2017/08/25 22:17:11 step 0: objective=-0.012394455
2017/08/25 22:17:12 step 1: objective=-0.012350651
2017/08/25 22:17:13 step 2: objective=-0.012306926
2017/08/25 22:17:15 step 3: objective=-0.01226315
2017/08/25 22:17:16 step 4: objective=-0.012219259
2017/08/25 22:17:18 step 5: objective=-0.012175252
2017/08/25 22:17:19 step 6: objective=-0.012132077
2017/08/25 22:17:21 step 7: objective=-0.012094913
2017/08/25 22:17:21 Training value function...
2017/08/25 22:17:24 step 0: mse=0.375195 step=0.100000
2017/08/25 22:17:26 step 1: mse=0.349865 step=0.100000
2017/08/25 22:17:29 step 2: mse=0.332081 step=0.100000
2017/08/25 22:17:31 step 3: mse=0.317410 step=0.100000
2017/08/25 22:17:34 step 4: mse=0.303301 step=0.100000
2017/08/25 22:17:36 step 5: mse=0.290771 step=0.100000
2017/08/25 22:17:39 step 6: mse=0.280376 step=0.100000
2017/08/25 22:17:41 step 7: mse=0.269520 step=0.100000
2017/08/25 22:17:41 Saving...
2017/08/25 22:17:41 Gathering batch of experience...
2017/08/25 22:17:53 batch 76: mean=5.666667 stddev=2.644911 entropy=1.323098 frames=34039 count=75
2017/08/25 22:17:53 Training policy...
2017/08/25 22:17:56 step 0: objective=-0.004702428
2017/08/25 22:17:57 step 1: objective=-0.0046706246
2017/08/25 22:17:59 step 2: objective=-0.0046300376
2017/08/25 22:18:00 step 3: objective=-0.004589816
2017/08/25 22:18:01 step 4: objective=-0.0045499653
2017/08/25 22:18:03 step 5: objective=-0.004510436
2017/08/25 22:18:04 step 6: objective=-0.0044712494
2017/08/25 22:18:06 step 7: objective=-0.004432381
2017/08/25 22:18:06 Training value function...
2017/08/25 22:18:09 step 0: mse=0.401191 step=0.100000
2017/08/25 22:18:11 step 1: mse=0.377023 step=0.100000
2017/08/25 22:18:14 step 2: mse=0.357467 step=0.100000
2017/08/25 22:18:17 step 3: mse=0.341211 step=0.100000
2017/08/25 22:18:19 step 4: mse=0.327765 step=0.100000
2017/08/25 22:18:22 step 5: mse=0.316547 step=0.100000
2017/08/25 22:18:24 step 6: mse=0.307026 step=0.100000
2017/08/25 22:18:27 step 7: mse=0.298690 step=0.100000
2017/08/25 22:18:27 Saving...
2017/08/25 22:18:27 Gathering batch of experience...
2017/08/25 22:18:38 batch 77: mean=5.386667 stddev=2.692673 entropy=1.324072 frames=33391 count=75
2017/08/25 22:18:38 Training policy...
2017/08/25 22:18:41 step 0: objective=0.0031671277
2017/08/25 22:18:43 step 1: objective=0.0032141677
2017/08/25 22:18:44 step 2: objective=0.0032610393
2017/08/25 22:18:45 step 3: objective=0.0033077165
2017/08/25 22:18:47 step 4: objective=0.003347329
2017/08/25 22:18:48 step 5: objective=0.0033867836
2017/08/25 22:18:50 step 6: objective=0.0034126497
2017/08/25 22:18:51 step 7: objective=0.0034588233
2017/08/25 22:18:51 Training value function...
2017/08/25 22:18:54 step 0: mse=0.389180 step=0.100000
2017/08/25 22:18:57 step 1: mse=0.369417 step=0.100000
2017/08/25 22:18:59 step 2: mse=0.353018 step=0.100000
2017/08/25 22:19:02 step 3: mse=0.338170 step=0.100000
2017/08/25 22:19:04 step 4: mse=0.328832 step=0.100000
2017/08/25 22:19:07 step 5: mse=0.317348 step=0.100000
2017/08/25 22:19:09 step 6: mse=0.307163 step=0.100000
2017/08/25 22:19:12 step 7: mse=0.294898 step=0.100000
2017/08/25 22:19:12 Saving...
2017/08/25 22:19:12 Gathering batch of experience...
2017/08/25 22:19:23 batch 78: mean=6.347222 stddev=3.379512 entropy=1.320046 frames=34508 count=72
2017/08/25 22:19:23 Training policy...
2017/08/25 22:19:27 step 0: objective=0.029016053
2017/08/25 22:19:28 step 1: objective=0.029106382
2017/08/25 22:19:29 step 2: objective=0.029197054
2017/08/25 22:19:31 step 3: objective=0.029287403
2017/08/25 22:19:32 step 4: objective=0.029377982
2017/08/25 22:19:34 step 5: objective=0.029466374
2017/08/25 22:19:35 step 6: objective=0.029533662
2017/08/25 22:19:37 step 7: objective=0.029601652
2017/08/25 22:19:37 Training value function...
2017/08/25 22:19:40 step 0: mse=0.471464 step=0.100000
2017/08/25 22:19:43 step 1: mse=0.441204 step=0.100000
2017/08/25 22:19:45 step 2: mse=0.416762 step=0.100000
2017/08/25 22:19:48 step 3: mse=0.395407 step=0.100000
2017/08/25 22:19:51 step 4: mse=0.379898 step=0.100000
2017/08/25 22:19:54 step 5: mse=0.366905 step=0.100000
2017/08/25 22:19:56 step 6: mse=0.354316 step=0.100000
2017/08/25 22:19:59 step 7: mse=0.344620 step=0.100000
2017/08/25 22:19:59 Saving...
2017/08/25 22:19:59 Gathering batch of experience...
2017/08/25 22:20:10 batch 79: mean=6.084507 stddev=2.905781 entropy=1.319371 frames=34517 count=71
2017/08/25 22:20:10 Training policy...
2017/08/25 22:20:14 step 0: objective=-0.006753853
2017/08/25 22:20:15 step 1: objective=-0.0066988315
2017/08/25 22:20:17 step 2: objective=-0.006643905
2017/08/25 22:20:18 step 3: objective=-0.006588976
2017/08/25 22:20:20 step 4: objective=-0.00653404
2017/08/25 22:20:21 step 5: objective=-0.006479222
2017/08/25 22:20:23 step 6: objective=-0.006435527
2017/08/25 22:20:24 step 7: objective=-0.0063958634
2017/08/25 22:20:24 Training value function...
2017/08/25 22:20:27 step 0: mse=0.420824 step=0.100000
2017/08/25 22:20:30 step 1: mse=0.399147 step=0.100000
2017/08/25 22:20:33 step 2: mse=0.381640 step=0.100000
2017/08/25 22:20:36 step 3: mse=0.366780 step=0.100000
2017/08/25 22:20:38 step 4: mse=0.349876 step=0.100000
2017/08/25 22:20:41 step 5: mse=0.339689 step=0.100000
2017/08/25 22:20:44 step 6: mse=0.331267 step=0.100000
2017/08/25 22:20:47 step 7: mse=0.321270 step=0.100000
2017/08/25 22:20:47 Saving...
2017/08/25 22:20:47 Gathering batch of experience...
2017/08/25 22:20:58 batch 80: mean=6.211268 stddev=2.731741 entropy=1.320585 frames=33977 count=71
2017/08/25 22:20:58 Training policy...
2017/08/25 22:21:01 step 0: objective=0.008042826
2017/08/25 22:21:02 step 1: objective=0.008096221
2017/08/25 22:21:04 step 2: objective=0.008150152
2017/08/25 22:21:05 step 3: objective=0.008203806
2017/08/25 22:21:07 step 4: objective=0.008257394
2017/08/25 22:21:08 step 5: objective=0.008310823
2017/08/25 22:21:10 step 6: objective=0.008364112
2017/08/25 22:21:11 step 7: objective=0.008409313
2017/08/25 22:21:11 Training value function...
2017/08/25 22:21:14 step 0: mse=0.438424 step=0.100000
2017/08/25 22:21:17 step 1: mse=0.411649 step=0.100000
2017/08/25 22:21:20 step 2: mse=0.389922 step=0.100000
2017/08/25 22:21:23 step 3: mse=0.365166 step=0.100000
2017/08/25 22:21:25 step 4: mse=0.349405 step=0.100000
2017/08/25 22:21:28 step 5: mse=0.331099 step=0.100000
2017/08/25 22:21:31 step 6: mse=0.316481 step=0.100000
2017/08/25 22:21:33 step 7: mse=0.306688 step=0.100000
2017/08/25 22:21:33 Saving...
2017/08/25 22:21:33 Gathering batch of experience...
2017/08/25 22:21:45 batch 81: mean=6.069444 stddev=3.215960 entropy=1.320891 frames=34080 count=72
2017/08/25 22:21:45 Training policy...
2017/08/25 22:21:48 step 0: objective=0.005549511
2017/08/25 22:21:50 step 1: objective=0.0055894814
2017/08/25 22:21:51 step 2: objective=0.0056287483
2017/08/25 22:21:53 step 3: objective=0.005676481
2017/08/25 22:21:54 step 4: objective=0.0057242136
2017/08/25 22:21:56 step 5: objective=0.0057719555
2017/08/25 22:21:57 step 6: objective=0.005819216
2017/08/25 22:21:59 step 7: objective=0.0058612805
2017/08/25 22:21:59 Training value function...
2017/08/25 22:22:02 step 0: mse=0.479670 step=0.100000
2017/08/25 22:22:05 step 1: mse=0.464097 step=0.100000
2017/08/25 22:22:07 step 2: mse=0.451342 step=0.100000
2017/08/25 22:22:10 step 3: mse=0.437051 step=0.100000
2017/08/25 22:22:13 step 4: mse=0.424277 step=0.100000
2017/08/25 22:22:16 step 5: mse=0.416898 step=0.100000
2017/08/25 22:22:18 step 6: mse=0.406953 step=0.100000
2017/08/25 22:22:21 step 7: mse=0.397305 step=0.100000
2017/08/25 22:22:21 Saving...
2017/08/25 22:22:21 Gathering batch of experience...
2017/08/25 22:22:32 batch 82: mean=5.698630 stddev=2.782947 entropy=1.319824 frames=33605 count=73
2017/08/25 22:22:32 Training policy...
2017/08/25 22:22:36 step 0: objective=-0.009753428
2017/08/25 22:22:37 step 1: objective=-0.009697232
2017/08/25 22:22:39 step 2: objective=-0.009641138
2017/08/25 22:22:40 step 3: objective=-0.009585026
2017/08/25 22:22:42 step 4: objective=-0.0095289145
2017/08/25 22:22:43 step 5: objective=-0.009472338
2017/08/25 22:22:45 step 6: objective=-0.009423971
2017/08/25 22:22:46 step 7: objective=-0.009375157
2017/08/25 22:22:46 Training value function...
2017/08/25 22:22:49 step 0: mse=0.353536 step=0.100000
2017/08/25 22:22:52 step 1: mse=0.342872 step=0.100000
2017/08/25 22:22:55 step 2: mse=0.327501 step=0.100000
2017/08/25 22:22:57 step 3: mse=0.317050 step=0.100000
2017/08/25 22:23:00 step 4: mse=0.309882 step=0.100000
2017/08/25 22:23:03 step 5: mse=0.294661 step=0.100000
2017/08/25 22:23:06 step 6: mse=0.289352 step=0.100000
2017/08/25 22:23:08 step 7: mse=0.276704 step=0.100000
2017/08/25 22:23:08 Saving...
2017/08/25 22:23:08 Gathering batch of experience...
2017/08/25 22:23:19 batch 83: mean=5.875000 stddev=3.041096 entropy=1.318540 frames=33683 count=72
2017/08/25 22:23:19 Training policy...
2017/08/25 22:23:23 step 0: objective=0.014630911
2017/08/25 22:23:24 step 1: objective=0.014691213
2017/08/25 22:23:26 step 2: objective=0.0147523675
2017/08/25 22:23:27 step 3: objective=0.014813173
2017/08/25 22:23:29 step 4: objective=0.014855316
2017/08/25 22:23:30 step 5: objective=0.014884351
2017/08/25 22:23:32 step 6: objective=0.014912975
2017/08/25 22:23:33 step 7: objective=0.014940241
2017/08/25 22:23:33 Training value function...
2017/08/25 22:23:36 step 0: mse=0.478410 step=0.100000
2017/08/25 22:23:39 step 1: mse=0.441328 step=0.100000
2017/08/25 22:23:42 step 2: mse=0.411073 step=0.100000
2017/08/25 22:23:45 step 3: mse=0.385935 step=0.100000
2017/08/25 22:23:47 step 4: mse=0.360654 step=0.100000
2017/08/25 22:23:50 step 5: mse=0.343407 step=0.100000
2017/08/25 22:23:53 step 6: mse=0.328791 step=0.100000
2017/08/25 22:23:56 step 7: mse=0.312905 step=0.100000
2017/08/25 22:23:56 Saving...
2017/08/25 22:23:56 Gathering batch of experience...
2017/08/25 22:24:07 batch 84: mean=4.876543 stddev=2.966407 entropy=1.320421 frames=33178 count=81
2017/08/25 22:24:07 Training policy...
2017/08/25 22:24:10 step 0: objective=0.0030337912
2017/08/25 22:24:11 step 1: objective=0.0030565902
2017/08/25 22:24:13 step 2: objective=0.0030792693
2017/08/25 22:24:14 step 3: objective=0.0031017847
2017/08/25 22:24:16 step 4: objective=0.0031241418
2017/08/25 22:24:17 step 5: objective=0.003146416
2017/08/25 22:24:19 step 6: objective=0.0031685142
2017/08/25 22:24:20 step 7: objective=0.0031904883
2017/08/25 22:24:20 Training value function...
2017/08/25 22:24:24 step 0: mse=0.493643 step=0.100000
2017/08/25 22:24:26 step 1: mse=0.458906 step=0.100000
2017/08/25 22:24:29 step 2: mse=0.430686 step=0.100000
2017/08/25 22:24:32 step 3: mse=0.407947 step=0.100000
2017/08/25 22:24:34 step 4: mse=0.384463 step=0.100000
2017/08/25 22:24:37 step 5: mse=0.371056 step=0.100000
2017/08/25 22:24:40 step 6: mse=0.350248 step=0.100000
2017/08/25 22:24:43 step 7: mse=0.332768 step=0.100000
2017/08/25 22:24:43 Saving...
2017/08/25 22:24:43 Gathering batch of experience...
2017/08/25 22:24:54 batch 85: mean=6.166667 stddev=2.813657 entropy=1.319252 frames=34502 count=72
2017/08/25 22:24:54 Training policy...
2017/08/25 22:24:58 step 0: objective=-0.009106998
2017/08/25 22:24:59 step 1: objective=-0.009036174
2017/08/25 22:25:01 step 2: objective=-0.00896592
2017/08/25 22:25:02 step 3: objective=-0.0088963015
2017/08/25 22:25:04 step 4: objective=-0.008830879
2017/08/25 22:25:06 step 5: objective=-0.00879848
2017/08/25 22:25:07 step 6: objective=-0.00874569
2017/08/25 22:25:09 step 7: objective=-0.008701209
2017/08/25 22:25:09 Training value function...
2017/08/25 22:25:12 step 0: mse=0.512131 step=0.100000
2017/08/25 22:25:15 step 1: mse=0.473057 step=0.100000
2017/08/25 22:25:18 step 2: mse=0.441448 step=0.100000
2017/08/25 22:25:21 step 3: mse=0.414684 step=0.100000
2017/08/25 22:25:24 step 4: mse=0.393177 step=0.100000
2017/08/25 22:25:27 step 5: mse=0.375089 step=0.100000
2017/08/25 22:25:30 step 6: mse=0.360517 step=0.100000
2017/08/25 22:25:33 step 7: mse=0.348021 step=0.100000
2017/08/25 22:25:33 Saving...
2017/08/25 22:25:33 Gathering batch of experience...
2017/08/25 22:25:43 batch 86: mean=5.943662 stddev=3.080549 entropy=1.317052 frames=32950 count=71
2017/08/25 22:25:43 Training policy...
2017/08/25 22:25:47 step 0: objective=0.014046039
2017/08/25 22:25:48 step 1: objective=0.014135029
2017/08/25 22:25:50 step 2: objective=0.01422405
2017/08/25 22:25:51 step 3: objective=0.014312935
2017/08/25 22:25:53 step 4: objective=0.014393902
2017/08/25 22:25:54 step 5: objective=0.0144382
2017/08/25 22:25:56 step 6: objective=0.014500147
2017/08/25 22:25:57 step 7: objective=0.014551765
2017/08/25 22:25:57 Training value function...
2017/08/25 22:26:01 step 0: mse=0.468556 step=0.100000
2017/08/25 22:26:03 step 1: mse=0.446639 step=0.100000
2017/08/25 22:26:06 step 2: mse=0.431218 step=0.100000
2017/08/25 22:26:09 step 3: mse=0.414441 step=0.100000
2017/08/25 22:26:12 step 4: mse=0.403395 step=0.100000
2017/08/25 22:26:15 step 5: mse=0.387187 step=0.100000
2017/08/25 22:26:18 step 6: mse=0.376075 step=0.100000
2017/08/25 22:26:21 step 7: mse=0.364189 step=0.100000
2017/08/25 22:26:21 Saving...
2017/08/25 22:26:21 Gathering batch of experience...
2017/08/25 22:26:32 batch 87: mean=5.888889 stddev=2.611702 entropy=1.319314 frames=33667 count=72
2017/08/25 22:26:32 Training policy...
2017/08/25 22:26:35 step 0: objective=0.0058080764
2017/08/25 22:26:37 step 1: objective=0.005900691
2017/08/25 22:26:38 step 2: objective=0.005993829
2017/08/25 22:26:40 step 3: objective=0.006087528
2017/08/25 22:26:41 step 4: objective=0.006181892
2017/08/25 22:26:43 step 5: objective=0.006254461
2017/08/25 22:26:45 step 6: objective=0.006299622
2017/08/25 22:26:46 step 7: objective=0.0063617323
2017/08/25 22:26:46 Training value function...
2017/08/25 22:26:50 step 0: mse=0.412471 step=0.100000
2017/08/25 22:26:52 step 1: mse=0.386180 step=0.100000
2017/08/25 22:26:55 step 2: mse=0.364866 step=0.100000
2017/08/25 22:26:58 step 3: mse=0.344710 step=0.100000
2017/08/25 22:27:01 step 4: mse=0.328365 step=0.100000
2017/08/25 22:27:04 step 5: mse=0.314696 step=0.100000
2017/08/25 22:27:07 step 6: mse=0.304630 step=0.100000
2017/08/25 22:27:10 step 7: mse=0.294738 step=0.100000
2017/08/25 22:27:10 Saving...
2017/08/25 22:27:10 Gathering batch of experience...
2017/08/25 22:27:21 batch 88: mean=6.041667 stddev=2.605750 entropy=1.320128 frames=34447 count=72
2017/08/25 22:27:21 Training policy...
2017/08/25 22:27:25 step 0: objective=-0.0067023
2017/08/25 22:27:26 step 1: objective=-0.0066277892
2017/08/25 22:27:28 step 2: objective=-0.0065528364
2017/08/25 22:27:29 step 3: objective=-0.006480064
2017/08/25 22:27:31 step 4: objective=-0.006430567
2017/08/25 22:27:33 step 5: objective=-0.006380203
2017/08/25 22:27:34 step 6: objective=-0.006317893
2017/08/25 22:27:36 step 7: objective=-0.0062828595
2017/08/25 22:27:36 Training value function...
2017/08/25 22:27:39 step 0: mse=0.420162 step=0.100000
2017/08/25 22:27:42 step 1: mse=0.396182 step=0.100000
2017/08/25 22:27:45 step 2: mse=0.376605 step=0.100000
2017/08/25 22:27:48 step 3: mse=0.360642 step=0.100000
2017/08/25 22:27:51 step 4: mse=0.347671 step=0.100000
2017/08/25 22:27:54 step 5: mse=0.334973 step=0.100000
2017/08/25 22:27:57 step 6: mse=0.323009 step=0.100000
2017/08/25 22:28:00 step 7: mse=0.310471 step=0.100000
2017/08/25 22:28:00 Saving...
2017/08/25 22:28:00 Gathering batch of experience...
2017/08/25 22:28:11 batch 89: mean=5.246753 stddev=2.731043 entropy=1.319639 frames=33866 count=77
2017/08/25 22:28:11 Training policy...
2017/08/25 22:28:15 step 0: objective=-0.01907337
2017/08/25 22:28:17 step 1: objective=-0.019002793
2017/08/25 22:28:18 step 2: objective=-0.018932424
2017/08/25 22:28:20 step 3: objective=-0.01886229
2017/08/25 22:28:21 step 4: objective=-0.018800024
2017/08/25 22:28:23 step 5: objective=-0.018735534
2017/08/25 22:28:24 step 6: objective=-0.018681783
2017/08/25 22:28:26 step 7: objective=-0.018639645
2017/08/25 22:28:26 Training value function...
2017/08/25 22:28:29 step 0: mse=0.335254 step=0.100000
2017/08/25 22:28:32 step 1: mse=0.318164 step=0.100000
2017/08/25 22:28:35 step 2: mse=0.304266 step=0.100000
2017/08/25 22:28:38 step 3: mse=0.293368 step=0.100000
2017/08/25 22:28:41 step 4: mse=0.284528 step=0.100000
2017/08/25 22:28:44 step 5: mse=0.276201 step=0.100000
2017/08/25 22:28:47 step 6: mse=0.269356 step=0.100000
2017/08/25 22:28:50 step 7: mse=0.264206 step=0.100000
2017/08/25 22:28:50 Saving...
2017/08/25 22:28:50 Gathering batch of experience...
2017/08/25 22:29:01 batch 90: mean=5.447368 stddev=3.019214 entropy=1.316855 frames=33441 count=76
2017/08/25 22:29:01 Training policy...
2017/08/25 22:29:05 step 0: objective=0.015811725
2017/08/25 22:29:06 step 1: objective=0.015866471
2017/08/25 22:29:08 step 2: objective=0.015920945
2017/08/25 22:29:09 step 3: objective=0.015975177
2017/08/25 22:29:11 step 4: objective=0.01602918
2017/08/25 22:29:13 step 5: objective=0.016082682
2017/08/25 22:29:14 step 6: objective=0.016130887
2017/08/25 22:29:16 step 7: objective=0.016181465
2017/08/25 22:29:16 Training value function...
2017/08/25 22:29:19 step 0: mse=0.487382 step=0.100000
2017/08/25 22:29:22 step 1: mse=0.450237 step=0.100000
2017/08/25 22:29:25 step 2: mse=0.423519 step=0.100000
2017/08/25 22:29:28 step 3: mse=0.401517 step=0.100000
2017/08/25 22:29:31 step 4: mse=0.377496 step=0.100000
2017/08/25 22:29:34 step 5: mse=0.360834 step=0.100000
2017/08/25 22:29:37 step 6: mse=0.343827 step=0.100000
2017/08/25 22:29:40 step 7: mse=0.332446 step=0.100000
2017/08/25 22:29:40 Saving...
2017/08/25 22:29:40 Gathering batch of experience...
2017/08/25 22:29:51 batch 91: mean=5.972222 stddev=2.778750 entropy=1.317188 frames=33948 count=72
2017/08/25 22:29:51 Training policy...
2017/08/25 22:29:54 step 0: objective=0.013111613
2017/08/25 22:29:56 step 1: objective=0.0131400535
2017/08/25 22:29:58 step 2: objective=0.013168248
2017/08/25 22:29:59 step 3: objective=0.013196255
2017/08/25 22:30:01 step 4: objective=0.013223822
2017/08/25 22:30:02 step 5: objective=0.013251166
2017/08/25 22:30:04 step 6: objective=0.01327849
2017/08/25 22:30:06 step 7: objective=0.013305513
2017/08/25 22:30:06 Training value function...
2017/08/25 22:30:09 step 0: mse=0.308240 step=0.100000
2017/08/25 22:30:12 step 1: mse=0.297337 step=0.100000
2017/08/25 22:30:15 step 2: mse=0.286742 step=0.100000
2017/08/25 22:30:18 step 3: mse=0.278719 step=0.100000
2017/08/25 22:30:21 step 4: mse=0.271204 step=0.100000
2017/08/25 22:30:24 step 5: mse=0.266479 step=0.100000
2017/08/25 22:30:27 step 6: mse=0.263001 step=0.100000
2017/08/25 22:30:30 step 7: mse=0.257006 step=0.100000
2017/08/25 22:30:30 Saving...
2017/08/25 22:30:30 Gathering batch of experience...
2017/08/25 22:30:42 batch 92: mean=6.338028 stddev=3.241212 entropy=1.315185 frames=34498 count=71
2017/08/25 22:30:42 Training policy...
2017/08/25 22:30:46 step 0: objective=0.011856816
2017/08/25 22:30:47 step 1: objective=0.011901638
2017/08/25 22:30:49 step 2: objective=0.011945839
2017/08/25 22:30:51 step 3: objective=0.011989431
2017/08/25 22:30:52 step 4: objective=0.012032198
2017/08/25 22:30:54 step 5: objective=0.012069378
2017/08/25 22:30:55 step 6: objective=0.012109268
2017/08/25 22:30:57 step 7: objective=0.012146562
2017/08/25 22:30:57 Training value function...
2017/08/25 22:31:01 step 0: mse=0.559123 step=0.100000
2017/08/25 22:31:04 step 1: mse=0.508780 step=0.100000
2017/08/25 22:31:07 step 2: mse=0.467800 step=0.100000
2017/08/25 22:31:10 step 3: mse=0.433745 step=0.100000
2017/08/25 22:31:13 step 4: mse=0.405893 step=0.100000
2017/08/25 22:31:16 step 5: mse=0.383590 step=0.100000
2017/08/25 22:31:19 step 6: mse=0.364112 step=0.100000
2017/08/25 22:31:22 step 7: mse=0.350244 step=0.100000
2017/08/25 22:31:22 Saving...
2017/08/25 22:31:23 Gathering batch of experience...
2017/08/25 22:31:34 batch 93: mean=5.545455 stddev=3.172714 entropy=1.315339 frames=33923 count=77
2017/08/25 22:31:34 Training policy...
2017/08/25 22:31:37 step 0: objective=-0.002717118
2017/08/25 22:31:39 step 1: objective=-0.0026713475
2017/08/25 22:31:41 step 2: objective=-0.0026251513
2017/08/25 22:31:42 step 3: objective=-0.0025785323
2017/08/25 22:31:44 step 4: objective=-0.0025322675
2017/08/25 22:31:46 step 5: objective=-0.0024910767
2017/08/25 22:31:47 step 6: objective=-0.002463995
2017/08/25 22:31:49 step 7: objective=-0.002442145
2017/08/25 22:31:49 Training value function...
2017/08/25 22:31:53 step 0: mse=0.466844 step=0.100000
2017/08/25 22:31:56 step 1: mse=0.444261 step=0.100000
2017/08/25 22:31:59 step 2: mse=0.426821 step=0.100000
2017/08/25 22:32:02 step 3: mse=0.413395 step=0.100000
2017/08/25 22:32:05 step 4: mse=0.399567 step=0.100000
2017/08/25 22:32:08 step 5: mse=0.389965 step=0.100000
2017/08/25 22:32:11 step 6: mse=0.372006 step=0.100000
2017/08/25 22:32:14 step 7: mse=0.357291 step=0.100000
2017/08/25 22:32:14 Saving...
2017/08/25 22:32:14 Gathering batch of experience...
2017/08/25 22:32:25 batch 94: mean=5.805556 stddev=2.801978 entropy=1.316024 frames=33976 count=72
2017/08/25 22:32:25 Training policy...
2017/08/25 22:32:29 step 0: objective=0.0008588335
2017/08/25 22:32:31 step 1: objective=0.00088787306
2017/08/25 22:32:32 step 2: objective=0.0009168275
2017/08/25 22:32:34 step 3: objective=0.0009456861
2017/08/25 22:32:36 step 4: objective=0.0009744683
2017/08/25 22:32:37 step 5: objective=0.0010031629
2017/08/25 22:32:39 step 6: objective=0.0010317765
2017/08/25 22:32:40 step 7: objective=0.0010603082
2017/08/25 22:32:40 Training value function...
2017/08/25 22:32:44 step 0: mse=0.374565 step=0.100000
2017/08/25 22:32:47 step 1: mse=0.354734 step=0.100000
2017/08/25 22:32:50 step 2: mse=0.338431 step=0.100000
2017/08/25 22:32:53 step 3: mse=0.324861 step=0.100000
2017/08/25 22:32:56 step 4: mse=0.304421 step=0.100000
2017/08/25 22:32:59 step 5: mse=0.287828 step=0.100000
2017/08/25 22:33:03 step 6: mse=0.274304 step=0.100000
2017/08/25 22:33:06 step 7: mse=0.263220 step=0.100000
2017/08/25 22:33:06 Saving...
2017/08/25 22:33:06 Gathering batch of experience...
2017/08/25 22:33:17 batch 95: mean=5.876712 stddev=3.087514 entropy=1.316321 frames=33567 count=73
2017/08/25 22:33:17 Training policy...
2017/08/25 22:33:21 step 0: objective=0.008932857
2017/08/25 22:33:22 step 1: objective=0.009012867
2017/08/25 22:33:24 step 2: objective=0.009092018
2017/08/25 22:33:25 step 3: objective=0.00917015
2017/08/25 22:33:27 step 4: objective=0.009247306
2017/08/25 22:33:29 step 5: objective=0.009299279
2017/08/25 22:33:30 step 6: objective=0.009347688
2017/08/25 22:33:32 step 7: objective=0.009423926
2017/08/25 22:33:32 Training value function...
2017/08/25 22:33:36 step 0: mse=0.676525 step=0.100000
2017/08/25 22:33:39 step 1: mse=0.629786 step=0.100000
2017/08/25 22:33:42 step 2: mse=0.592282 step=0.100000
2017/08/25 22:33:45 step 3: mse=0.560219 step=0.100000
2017/08/25 22:33:48 step 4: mse=0.534398 step=0.100000
2017/08/25 22:33:51 step 5: mse=0.512582 step=0.100000
2017/08/25 22:33:54 step 6: mse=0.494325 step=0.100000
2017/08/25 22:33:57 step 7: mse=0.479186 step=0.100000
2017/08/25 22:33:57 Saving...
2017/08/25 22:33:58 Gathering batch of experience...
2017/08/25 22:34:09 batch 96: mean=5.547945 stddev=2.606846 entropy=1.314939 frames=33466 count=73
2017/08/25 22:34:09 Training policy...
2017/08/25 22:34:12 step 0: objective=-0.007841519
2017/08/25 22:34:14 step 1: objective=-0.007795219
2017/08/25 22:34:16 step 2: objective=-0.007749155
2017/08/25 22:34:17 step 3: objective=-0.007703426
2017/08/25 22:34:19 step 4: objective=-0.0076579545
2017/08/25 22:34:20 step 5: objective=-0.0076139164
2017/08/25 22:34:22 step 6: objective=-0.00758717
2017/08/25 22:34:24 step 7: objective=-0.0075157294
2017/08/25 22:34:24 Training value function...
2017/08/25 22:34:27 step 0: mse=0.444940 step=0.100000
2017/08/25 22:34:31 step 1: mse=0.408570 step=0.100000
2017/08/25 22:34:34 step 2: mse=0.379486 step=0.100000
2017/08/25 22:34:37 step 3: mse=0.353567 step=0.100000
2017/08/25 22:34:40 step 4: mse=0.332595 step=0.100000
2017/08/25 22:34:43 step 5: mse=0.309575 step=0.100000
2017/08/25 22:34:46 step 6: mse=0.292225 step=0.100000
2017/08/25 22:34:49 step 7: mse=0.278114 step=0.100000
2017/08/25 22:34:49 Saving...
2017/08/25 22:34:49 Gathering batch of experience...
2017/08/25 22:35:01 batch 97: mean=5.394737 stddev=2.492510 entropy=1.315752 frames=33707 count=76
2017/08/25 22:35:01 Training policy...
2017/08/25 22:35:04 step 0: objective=0.0050557917
2017/08/25 22:35:06 step 1: objective=0.005099518
2017/08/25 22:35:08 step 2: objective=0.00514317
2017/08/25 22:35:09 step 3: objective=0.0051865987
2017/08/25 22:35:11 step 4: objective=0.0052299052
2017/08/25 22:35:13 step 5: objective=0.0052730516
2017/08/25 22:35:14 step 6: objective=0.005315811
2017/08/25 22:35:16 step 7: objective=0.0053551006
2017/08/25 22:35:16 Training value function...
2017/08/25 22:35:20 step 0: mse=0.401915 step=0.100000
2017/08/25 22:35:23 step 1: mse=0.379106 step=0.100000
2017/08/25 22:35:26 step 2: mse=0.358361 step=0.100000
2017/08/25 22:35:29 step 3: mse=0.342157 step=0.100000
2017/08/25 22:35:32 step 4: mse=0.328104 step=0.100000
2017/08/25 22:35:36 step 5: mse=0.311216 step=0.100000
2017/08/25 22:35:39 step 6: mse=0.298604 step=0.100000
2017/08/25 22:35:42 step 7: mse=0.285195 step=0.100000
2017/08/25 22:35:42 Saving...
2017/08/25 22:35:42 Gathering batch of experience...
2017/08/25 22:35:53 batch 98: mean=5.194805 stddev=3.045281 entropy=1.315445 frames=34008 count=77
2017/08/25 22:35:53 Training policy...
2017/08/25 22:35:57 step 0: objective=0.00024387038
2017/08/25 22:35:59 step 1: objective=0.00029721382
2017/08/25 22:36:01 step 2: objective=0.00035024772
2017/08/25 22:36:02 step 3: objective=0.00040297632
2017/08/25 22:36:04 step 4: objective=0.00045539023
2017/08/25 22:36:06 step 5: objective=0.0005074964
2017/08/25 22:36:07 step 6: objective=0.0005543809
2017/08/25 22:36:09 step 7: objective=0.0005782116
2017/08/25 22:36:09 Training value function...
2017/08/25 22:36:13 step 0: mse=0.401442 step=0.100000
2017/08/25 22:36:16 step 1: mse=0.390176 step=0.100000
2017/08/25 22:36:19 step 2: mse=0.377785 step=0.100000
2017/08/25 22:36:23 step 3: mse=0.367720 step=0.100000
2017/08/25 22:36:26 step 4: mse=0.359410 step=0.100000
2017/08/25 22:36:29 step 5: mse=0.350880 step=0.100000
2017/08/25 22:36:32 step 6: mse=0.343670 step=0.100000
2017/08/25 22:36:35 step 7: mse=0.337679 step=0.100000
2017/08/25 22:36:35 Saving...
2017/08/25 22:36:35 Gathering batch of experience...
2017/08/25 22:36:46 batch 99: mean=6.014085 stddev=3.195476 entropy=1.313995 frames=33314 count=71
2017/08/25 22:36:46 Training policy...
2017/08/25 22:36:50 step 0: objective=0.01173311
2017/08/25 22:36:52 step 1: objective=0.0118045015
2017/08/25 22:36:54 step 2: objective=0.011875502
2017/08/25 22:36:55 step 3: objective=0.011946071
2017/08/25 22:36:57 step 4: objective=0.0120127415
2017/08/25 22:36:59 step 5: objective=0.012047122
2017/08/25 22:37:00 step 6: objective=0.012087298
2017/08/25 22:37:02 step 7: objective=0.0121503165
2017/08/25 22:37:02 Training value function...
2017/08/25 22:37:06 step 0: mse=0.732098 step=0.100000
2017/08/25 22:37:09 step 1: mse=0.677768 step=0.100000
2017/08/25 22:37:12 step 2: mse=0.628472 step=0.100000
2017/08/25 22:37:16 step 3: mse=0.589220 step=0.100000
2017/08/25 22:37:19 step 4: mse=0.559491 step=0.100000
2017/08/25 22:37:22 step 5: mse=0.529420 step=0.100000
2017/08/25 22:37:25 step 6: mse=0.504771 step=0.100000
2017/08/25 22:37:28 step 7: mse=0.483123 step=0.100000
2017/08/25 22:37:28 Saving...
2017/08/25 22:37:28 Gathering batch of experience...
2017/08/25 22:37:40 batch 100: mean=6.273973 stddev=3.409336 entropy=1.311884 frames=34917 count=73
2017/08/25 22:37:40 Training policy...
2017/08/25 22:37:44 step 0: objective=0.027695978
2017/08/25 22:37:46 step 1: objective=0.027744412
2017/08/25 22:37:48 step 2: objective=0.027792325
2017/08/25 22:37:49 step 3: objective=0.02784386
2017/08/25 22:37:51 step 4: objective=0.027895566
2017/08/25 22:37:53 step 5: objective=0.027946731
2017/08/25 22:37:55 step 6: objective=0.0279864
2017/08/25 22:37:57 step 7: objective=0.028016953
2017/08/25 22:37:57 Training value function...
2017/08/25 22:38:01 step 0: mse=0.567720 step=0.100000
2017/08/25 22:38:04 step 1: mse=0.532197 step=0.100000
2017/08/25 22:38:07 step 2: mse=0.503983 step=0.100000
2017/08/25 22:38:11 step 3: mse=0.480668 step=0.100000
2017/08/25 22:38:14 step 4: mse=0.459279 step=0.100000
2017/08/25 22:38:18 step 5: mse=0.440262 step=0.100000
2017/08/25 22:38:21 step 6: mse=0.424815 step=0.100000
2017/08/25 22:38:24 step 7: mse=0.409760 step=0.100000
2017/08/25 22:38:24 Saving...
2017/08/25 22:38:24 Gathering batch of experience...
2017/08/25 22:38:36 batch 101: mean=5.729730 stddev=3.214399 entropy=1.310544 frames=33943 count=74
2017/08/25 22:38:36 Training policy...
2017/08/25 22:38:39 step 0: objective=-0.013825166
2017/08/25 22:38:41 step 1: objective=-0.013764241
2017/08/25 22:38:43 step 2: objective=-0.01370414
2017/08/25 22:38:45 step 3: objective=-0.013658464
2017/08/25 22:38:46 step 4: objective=-0.013613254
2017/08/25 22:38:48 step 5: objective=-0.01356924
2017/08/25 22:38:50 step 6: objective=-0.013547904
2017/08/25 22:38:52 step 7: objective=-0.013458575
2017/08/25 22:38:52 Training value function...
2017/08/25 22:38:55 step 0: mse=0.516216 step=0.100000
2017/08/25 22:38:59 step 1: mse=0.475950 step=0.100000
2017/08/25 22:39:02 step 2: mse=0.442018 step=0.100000
2017/08/25 22:39:05 step 3: mse=0.415370 step=0.100000
2017/08/25 22:39:09 step 4: mse=0.393578 step=0.100000
2017/08/25 22:39:12 step 5: mse=0.373715 step=0.100000
2017/08/25 22:39:15 step 6: mse=0.358346 step=0.100000
2017/08/25 22:39:19 step 7: mse=0.344610 step=0.100000
2017/08/25 22:39:19 Saving...
2017/08/25 22:39:19 Gathering batch of experience...
2017/08/25 22:39:30 batch 102: mean=6.027778 stddev=3.117924 entropy=1.313659 frames=34142 count=72
2017/08/25 22:39:30 Training policy...
2017/08/25 22:39:34 step 0: objective=0.00021478062
2017/08/25 22:39:36 step 1: objective=0.00028074507
2017/08/25 22:39:38 step 2: objective=0.00034698274
2017/08/25 22:39:40 step 3: objective=0.00040946607
2017/08/25 22:39:41 step 4: objective=0.00044138904
2017/08/25 22:39:43 step 5: objective=0.0004971616
2017/08/25 22:39:45 step 6: objective=0.00052309997
2017/08/25 22:39:47 step 7: objective=0.00056287856
2017/08/25 22:39:47 Training value function...
2017/08/25 22:39:51 step 0: mse=0.446910 step=0.100000
2017/08/25 22:39:54 step 1: mse=0.421379 step=0.100000
2017/08/25 22:39:57 step 2: mse=0.400579 step=0.100000
2017/08/25 22:40:00 step 3: mse=0.383523 step=0.100000
2017/08/25 22:40:04 step 4: mse=0.368764 step=0.100000
2017/08/25 22:40:07 step 5: mse=0.357643 step=0.100000
2017/08/25 22:40:10 step 6: mse=0.347415 step=0.100000
2017/08/25 22:40:14 step 7: mse=0.334129 step=0.100000
2017/08/25 22:40:14 Saving...
2017/08/25 22:40:14 Gathering batch of experience...
2017/08/25 22:40:25 batch 103: mean=6.681818 stddev=2.708903 entropy=1.312711 frames=33834 count=66
2017/08/25 22:40:25 Training policy...
2017/08/25 22:40:29 step 0: objective=0.01689352
2017/08/25 22:40:31 step 1: objective=0.016956287
2017/08/25 22:40:33 step 2: objective=0.017018935
2017/08/25 22:40:34 step 3: objective=0.017081441
2017/08/25 22:40:36 step 4: objective=0.01714405
2017/08/25 22:40:38 step 5: objective=0.017206268
2017/08/25 22:40:40 step 6: objective=0.017247247
2017/08/25 22:40:41 step 7: objective=0.017342383
2017/08/25 22:40:41 Training value function...
2017/08/25 22:40:45 step 0: mse=0.511711 step=0.100000
2017/08/25 22:40:49 step 1: mse=0.482681 step=0.100000
2017/08/25 22:40:52 step 2: mse=0.459075 step=0.100000
2017/08/25 22:40:55 step 3: mse=0.434736 step=0.100000
2017/08/25 22:40:59 step 4: mse=0.413070 step=0.100000
2017/08/25 22:41:02 step 5: mse=0.395619 step=0.100000
2017/08/25 22:41:05 step 6: mse=0.379447 step=0.100000
2017/08/25 22:41:09 step 7: mse=0.366846 step=0.100000
2017/08/25 22:41:09 Saving...
2017/08/25 22:41:09 Gathering batch of experience...
2017/08/25 22:41:20 batch 104: mean=5.346154 stddev=3.137151 entropy=1.315900 frames=33574 count=78
2017/08/25 22:41:20 Training policy...
2017/08/25 22:41:24 step 0: objective=-0.0034442425
2017/08/25 22:41:25 step 1: objective=-0.0033929197
2017/08/25 22:41:27 step 2: objective=-0.0033411582
2017/08/25 22:41:29 step 3: objective=-0.003289017
2017/08/25 22:41:31 step 4: objective=-0.0032364912
2017/08/25 22:41:33 step 5: objective=-0.0031836682
2017/08/25 22:41:34 step 6: objective=-0.0031390686
2017/08/25 22:41:36 step 7: objective=-0.0030801878
2017/08/25 22:41:36 Training value function...
2017/08/25 22:41:40 step 0: mse=0.465797 step=0.100000
2017/08/25 22:41:43 step 1: mse=0.432625 step=0.100000
2017/08/25 22:41:46 step 2: mse=0.405125 step=0.100000
2017/08/25 22:41:50 step 3: mse=0.383374 step=0.100000
2017/08/25 22:41:53 step 4: mse=0.364583 step=0.100000
2017/08/25 22:41:56 step 5: mse=0.349514 step=0.100000
2017/08/25 22:42:00 step 6: mse=0.336792 step=0.100000
2017/08/25 22:42:03 step 7: mse=0.323751 step=0.100000
2017/08/25 22:42:03 Saving...
2017/08/25 22:42:03 Gathering batch of experience...
2017/08/25 22:42:14 batch 105: mean=5.256410 stddev=2.628424 entropy=1.311275 frames=33723 count=78
2017/08/25 22:42:14 Training policy...
2017/08/25 22:42:18 step 0: objective=-0.016667329
2017/08/25 22:42:20 step 1: objective=-0.016632622
2017/08/25 22:42:22 step 2: objective=-0.016597632
2017/08/25 22:42:24 step 3: objective=-0.016562253
2017/08/25 22:42:25 step 4: objective=-0.016526608
2017/08/25 22:42:27 step 5: objective=-0.016490625
2017/08/25 22:42:29 step 6: objective=-0.016454423
2017/08/25 22:42:31 step 7: objective=-0.01642485
2017/08/25 22:42:31 Training value function...
2017/08/25 22:42:35 step 0: mse=0.467800 step=0.100000
2017/08/25 22:42:38 step 1: mse=0.434325 step=0.100000
2017/08/25 22:42:41 step 2: mse=0.407218 step=0.100000
2017/08/25 22:42:45 step 3: mse=0.385639 step=0.100000
2017/08/25 22:42:48 step 4: mse=0.367773 step=0.100000
2017/08/25 22:42:52 step 5: mse=0.349804 step=0.100000
2017/08/25 22:42:55 step 6: mse=0.335676 step=0.100000
2017/08/25 22:42:58 step 7: mse=0.325073 step=0.100000
2017/08/25 22:42:58 Saving...
2017/08/25 22:42:58 Gathering batch of experience...
2017/08/25 22:43:10 batch 106: mean=6.013514 stddev=3.160111 entropy=1.309027 frames=34246 count=74
2017/08/25 22:43:10 Training policy...
2017/08/25 22:43:14 step 0: objective=0.022281272
2017/08/25 22:43:16 step 1: objective=0.022347663
2017/08/25 22:43:18 step 2: objective=0.022414768
2017/08/25 22:43:19 step 3: objective=0.022482147
2017/08/25 22:43:21 step 4: objective=0.022504017
2017/08/25 22:43:23 step 5: objective=0.022555897
2017/08/25 22:43:25 step 6: objective=0.022605795
2017/08/25 22:43:27 step 7: objective=0.0226267
2017/08/25 22:43:27 Training value function...
2017/08/25 22:43:31 step 0: mse=0.608169 step=0.100000
2017/08/25 22:43:34 step 1: mse=0.565488 step=0.100000
2017/08/25 22:43:38 step 2: mse=0.530681 step=0.100000
2017/08/25 22:43:41 step 3: mse=0.502569 step=0.100000
2017/08/25 22:43:45 step 4: mse=0.478714 step=0.100000
2017/08/25 22:43:48 step 5: mse=0.459841 step=0.100000
2017/08/25 22:43:52 step 6: mse=0.443007 step=0.100000
2017/08/25 22:43:55 step 7: mse=0.428154 step=0.100000
2017/08/25 22:43:55 Saving...
2017/08/25 22:43:55 Gathering batch of experience...
2017/08/25 22:44:07 batch 107: mean=5.192308 stddev=3.025777 entropy=1.312906 frames=33827 count=78
2017/08/25 22:44:07 Training policy...
2017/08/25 22:44:11 step 0: objective=-0.010634737
2017/08/25 22:44:13 step 1: objective=-0.010565581
2017/08/25 22:44:14 step 2: objective=-0.010496334
2017/08/25 22:44:16 step 3: objective=-0.010426755
2017/08/25 22:44:18 step 4: objective=-0.010356888
2017/08/25 22:44:20 step 5: objective=-0.010294138
2017/08/25 22:44:22 step 6: objective=-0.010267912
2017/08/25 22:44:24 step 7: objective=-0.01022401
2017/08/25 22:44:24 Training value function...
2017/08/25 22:44:28 step 0: mse=0.462888 step=0.100000
2017/08/25 22:44:31 step 1: mse=0.438340 step=0.100000
2017/08/25 22:44:35 step 2: mse=0.418213 step=0.100000
2017/08/25 22:44:38 step 3: mse=0.399325 step=0.100000
2017/08/25 22:44:42 step 4: mse=0.383713 step=0.100000
2017/08/25 22:44:45 step 5: mse=0.370904 step=0.100000
2017/08/25 22:44:48 step 6: mse=0.361145 step=0.100000
2017/08/25 22:44:52 step 7: mse=0.351929 step=0.100000
2017/08/25 22:44:52 Saving...
2017/08/25 22:44:52 Gathering batch of experience...
2017/08/25 22:45:03 batch 108: mean=5.643836 stddev=3.369362 entropy=1.309679 frames=33447 count=73
2017/08/25 22:45:03 Training policy...
2017/08/25 22:45:07 step 0: objective=-0.0017363065
2017/08/25 22:45:09 step 1: objective=-0.0016739599
2017/08/25 22:45:11 step 2: objective=-0.0016126547
2017/08/25 22:45:13 step 3: objective=-0.0015523827
2017/08/25 22:45:14 step 4: objective=-0.0014931285
2017/08/25 22:45:16 step 5: objective=-0.0014385348
2017/08/25 22:45:18 step 6: objective=-0.0013953045
2017/08/25 22:45:20 step 7: objective=-0.0013626695
2017/08/25 22:45:20 Training value function...
2017/08/25 22:45:24 step 0: mse=0.427198 step=0.100000
2017/08/25 22:45:27 step 1: mse=0.406514 step=0.100000
2017/08/25 22:45:30 step 2: mse=0.389340 step=0.100000
2017/08/25 22:45:34 step 3: mse=0.374828 step=0.100000
2017/08/25 22:45:37 step 4: mse=0.353152 step=0.100000
2017/08/25 22:45:41 step 5: mse=0.335293 step=0.100000
2017/08/25 22:45:44 step 6: mse=0.323249 step=0.100000
2017/08/25 22:45:48 step 7: mse=0.308785 step=0.100000
2017/08/25 22:45:48 Saving...
2017/08/25 22:45:48 Gathering batch of experience...
2017/08/25 22:45:59 batch 109: mean=5.573333 stddev=2.781718 entropy=1.310953 frames=34119 count=75
2017/08/25 22:45:59 Training policy...
2017/08/25 22:46:03 step 0: objective=0.0033258416
2017/08/25 22:46:05 step 1: objective=0.003369021
2017/08/25 22:46:07 step 2: objective=0.0034122942
2017/08/25 22:46:09 step 3: objective=0.0034556834
2017/08/25 22:46:10 step 4: objective=0.0034991745
2017/08/25 22:46:12 step 5: objective=0.0035427897
2017/08/25 22:46:14 step 6: objective=0.0035757155
2017/08/25 22:46:16 step 7: objective=0.0036147295
2017/08/25 22:46:16 Training value function...
2017/08/25 22:46:20 step 0: mse=0.394346 step=0.100000
2017/08/25 22:46:23 step 1: mse=0.370090 step=0.100000
2017/08/25 22:46:27 step 2: mse=0.349662 step=0.100000
2017/08/25 22:46:31 step 3: mse=0.331451 step=0.100000
2017/08/25 22:46:34 step 4: mse=0.315967 step=0.100000
2017/08/25 22:46:38 step 5: mse=0.304023 step=0.100000
2017/08/25 22:46:41 step 6: mse=0.293284 step=0.100000
2017/08/25 22:46:45 step 7: mse=0.285344 step=0.100000
2017/08/25 22:46:45 Saving...
2017/08/25 22:46:45 Gathering batch of experience...
2017/08/25 22:46:56 batch 110: mean=6.263889 stddev=3.236052 entropy=1.309196 frames=34088 count=72
2017/08/25 22:46:56 Training policy...
2017/08/25 22:47:00 step 0: objective=0.025491675
2017/08/25 22:47:02 step 1: objective=0.025551546
2017/08/25 22:47:04 step 2: objective=0.025610399
2017/08/25 22:47:06 step 3: objective=0.025669118
2017/08/25 22:47:08 step 4: objective=0.02572732
2017/08/25 22:47:10 step 5: objective=0.025784893
2017/08/25 22:47:12 step 6: objective=0.025841594
2017/08/25 22:47:14 step 7: objective=0.025874496
2017/08/25 22:47:14 Training value function...
2017/08/25 22:47:18 step 0: mse=0.555680 step=0.100000
2017/08/25 22:47:21 step 1: mse=0.518070 step=0.100000
2017/08/25 22:47:25 step 2: mse=0.487527 step=0.100000
2017/08/25 22:47:28 step 3: mse=0.462661 step=0.100000
2017/08/25 22:47:32 step 4: mse=0.441533 step=0.100000
2017/08/25 22:47:36 step 5: mse=0.424593 step=0.100000
2017/08/25 22:47:39 step 6: mse=0.409960 step=0.100000
2017/08/25 22:47:43 step 7: mse=0.398232 step=0.100000
2017/08/25 22:47:43 Saving...
2017/08/25 22:47:43 Gathering batch of experience...
2017/08/25 22:47:54 batch 111: mean=5.355263 stddev=2.437125 entropy=1.310996 frames=33710 count=76
2017/08/25 22:47:54 Training policy...
2017/08/25 22:47:58 step 0: objective=-0.0032463619
2017/08/25 22:48:00 step 1: objective=-0.003200395
2017/08/25 22:48:02 step 2: objective=-0.0031548396
2017/08/25 22:48:04 step 3: objective=-0.003109636
2017/08/25 22:48:06 step 4: objective=-0.003064826
2017/08/25 22:48:08 step 5: objective=-0.0030203648
2017/08/25 22:48:09 step 6: objective=-0.0029763586
2017/08/25 22:48:11 step 7: objective=-0.002937721
2017/08/25 22:48:11 Training value function...
2017/08/25 22:48:16 step 0: mse=0.274148 step=0.100000
2017/08/25 22:48:19 step 1: mse=0.263870 step=0.100000
2017/08/25 22:48:23 step 2: mse=0.255542 step=0.100000
2017/08/25 22:48:26 step 3: mse=0.248694 step=0.100000
2017/08/25 22:48:30 step 4: mse=0.243100 step=0.100000
2017/08/25 22:48:33 step 5: mse=0.238480 step=0.100000
2017/08/25 22:48:37 step 6: mse=0.234684 step=0.100000
2017/08/25 22:48:40 step 7: mse=0.230916 step=0.100000
2017/08/25 22:48:40 Saving...
2017/08/25 22:48:40 Gathering batch of experience...
2017/08/25 22:48:52 batch 112: mean=5.337662 stddev=2.561505 entropy=1.308563 frames=33888 count=77
2017/08/25 22:48:52 Training policy...
2017/08/25 22:48:56 step 0: objective=-0.0018517466
2017/08/25 22:48:58 step 1: objective=-0.0018156793
2017/08/25 22:49:00 step 2: objective=-0.0017796428
2017/08/25 22:49:02 step 3: objective=-0.0017436297
2017/08/25 22:49:04 step 4: objective=-0.0017076302
2017/08/25 22:49:06 step 5: objective=-0.001671655
2017/08/25 22:49:07 step 6: objective=-0.001637047
2017/08/25 22:49:09 step 7: objective=-0.0015620197
2017/08/25 22:49:09 Training value function...
2017/08/25 22:49:13 step 0: mse=0.428111 step=0.100000
2017/08/25 22:49:17 step 1: mse=0.404285 step=0.100000
2017/08/25 22:49:21 step 2: mse=0.384982 step=0.100000
2017/08/25 22:49:24 step 3: mse=0.366013 step=0.100000
2017/08/25 22:49:28 step 4: mse=0.351491 step=0.100000
2017/08/25 22:49:31 step 5: mse=0.339715 step=0.100000
2017/08/25 22:49:35 step 6: mse=0.327073 step=0.100000
2017/08/25 22:49:39 step 7: mse=0.316114 step=0.100000
2017/08/25 22:49:39 Saving...
2017/08/25 22:49:39 Gathering batch of experience...
2017/08/25 22:49:50 batch 113: mean=5.901408 stddev=2.595527 entropy=1.306954 frames=33327 count=71
2017/08/25 22:49:50 Training policy...
2017/08/25 22:49:54 step 0: objective=0.011663065
2017/08/25 22:49:56 step 1: objective=0.0117304735
2017/08/25 22:49:58 step 2: objective=0.011797786
2017/08/25 22:49:59 step 3: objective=0.011864774
2017/08/25 22:50:01 step 4: objective=0.011931442
2017/08/25 22:50:03 step 5: objective=0.011998076
2017/08/25 22:50:05 step 6: objective=0.012063829
2017/08/25 22:50:07 step 7: objective=0.012148345
2017/08/25 22:50:07 Training value function...
2017/08/25 22:50:11 step 0: mse=0.388932 step=0.100000
2017/08/25 22:50:14 step 1: mse=0.370767 step=0.100000
2017/08/25 22:50:18 step 2: mse=0.356041 step=0.100000
2017/08/25 22:50:21 step 3: mse=0.344700 step=0.100000
2017/08/25 22:50:25 step 4: mse=0.335344 step=0.100000
2017/08/25 22:50:29 step 5: mse=0.326150 step=0.100000
2017/08/25 22:50:32 step 6: mse=0.314664 step=0.100000
2017/08/25 22:50:36 step 7: mse=0.305963 step=0.100000
2017/08/25 22:50:36 Saving...
2017/08/25 22:50:36 Gathering batch of experience...
2017/08/25 22:50:47 batch 114: mean=5.833333 stddev=3.539460 entropy=1.309445 frames=33253 count=72
2017/08/25 22:50:47 Training policy...
2017/08/25 22:50:51 step 0: objective=0.0052210647
2017/08/25 22:50:53 step 1: objective=0.005256688
2017/08/25 22:50:55 step 2: objective=0.005292009
2017/08/25 22:50:56 step 3: objective=0.005327112
2017/08/25 22:50:58 step 4: objective=0.00536188
2017/08/25 22:51:00 step 5: objective=0.0053964197
2017/08/25 22:51:02 step 6: objective=0.005430687
2017/08/25 22:51:04 step 7: objective=0.0054629324
2017/08/25 22:51:04 Training value function...
2017/08/25 22:51:08 step 0: mse=0.386706 step=0.100000
2017/08/25 22:51:12 step 1: mse=0.362966 step=0.100000
2017/08/25 22:51:15 step 2: mse=0.343678 step=0.100000
2017/08/25 22:51:18 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.999 -maxtrees 5000]
2017/08/25 22:51:18 Creating environments...
2017/08/25 22:51:20 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/25 22:51:20 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/25 22:51:20 Running. Press Ctrl+C to stop.
2017/08/25 22:51:20 Gathering batch of experience...
2017/08/25 22:51:31 batch 0: mean=5.113924 stddev=2.565533 entropy=1.308360 frames=33831 count=79
2017/08/25 22:51:31 Training policy...
2017/08/25 22:51:35 step 0: objective=-0.0030764395
2017/08/25 22:51:37 step 1: objective=-0.003017577
2017/08/25 22:51:39 step 2: objective=-0.0029590942
2017/08/25 22:51:40 step 3: objective=-0.0029009404
2017/08/25 22:51:42 step 4: objective=-0.0028431672
2017/08/25 22:51:44 step 5: objective=-0.0027858133
2017/08/25 22:51:45 step 6: objective=-0.002729152
2017/08/25 22:51:47 step 7: objective=-0.0026785512
2017/08/25 22:51:47 Training value function...
2017/08/25 22:51:51 step 0: mse=0.372006 step=0.100000
2017/08/25 22:51:54 step 1: mse=0.347414 step=0.100000
2017/08/25 22:51:58 step 2: mse=0.327426 step=0.100000
2017/08/25 22:52:01 step 3: mse=0.310888 step=0.100000
2017/08/25 22:52:05 step 4: mse=0.297319 step=0.100000
2017/08/25 22:52:08 step 5: mse=0.283467 step=0.100000
2017/08/25 22:52:12 step 6: mse=0.272890 step=0.100000
2017/08/25 22:52:15 step 7: mse=0.263549 step=0.100000
2017/08/25 22:52:15 Saving...
2017/08/25 22:52:15 Gathering batch of experience...
2017/08/25 22:52:26 batch 1: mean=6.228571 stddev=2.726439 entropy=1.305316 frames=34052 count=70
2017/08/25 22:52:26 Training policy...
2017/08/25 22:52:30 step 0: objective=0.024417443
2017/08/25 22:52:32 step 1: objective=0.024463372
2017/08/25 22:52:33 step 2: objective=0.024522465
2017/08/25 22:52:35 step 3: objective=0.024581851
2017/08/25 22:52:37 step 4: objective=0.02462861
2017/08/25 22:52:39 step 5: objective=0.024688303
2017/08/25 22:52:40 step 6: objective=0.024718164
2017/08/25 22:52:42 step 7: objective=0.024757328
2017/08/25 22:52:42 Training value function...
2017/08/25 22:52:46 step 0: mse=0.476546 step=0.100000
2017/08/25 22:52:50 step 1: mse=0.444443 step=0.100000
2017/08/25 22:52:53 step 2: mse=0.418459 step=0.100000
2017/08/25 22:52:57 step 3: mse=0.397273 step=0.100000
2017/08/25 22:53:00 step 4: mse=0.380112 step=0.100000
2017/08/25 22:53:04 step 5: mse=0.365707 step=0.100000
2017/08/25 22:53:07 step 6: mse=0.352290 step=0.100000
2017/08/25 22:53:11 step 7: mse=0.341417 step=0.100000
2017/08/25 22:53:11 Saving...
2017/08/25 22:53:11 Gathering batch of experience...
2017/08/25 22:53:22 batch 2: mean=5.861111 stddev=3.101548 entropy=1.307756 frames=33362 count=72
2017/08/25 22:53:22 Training policy...
2017/08/25 22:53:25 step 0: objective=0.0057691988
2017/08/25 22:53:27 step 1: objective=0.005881351
2017/08/25 22:53:29 step 2: objective=0.005994872
2017/08/25 22:53:31 step 3: objective=0.0060998015
2017/08/25 22:53:32 step 4: objective=0.006187307
2017/08/25 22:53:34 step 5: objective=0.006207976
2017/08/25 22:53:36 step 6: objective=0.0062522492
2017/08/25 22:53:38 step 7: objective=0.0062643047
2017/08/25 22:53:38 Training value function...
2017/08/25 22:53:42 step 0: mse=0.514785 step=0.100000
2017/08/25 22:53:45 step 1: mse=0.477457 step=0.100000
2017/08/25 22:53:49 step 2: mse=0.447223 step=0.100000
2017/08/25 22:53:52 step 3: mse=0.422630 step=0.100000
2017/08/25 22:53:56 step 4: mse=0.402036 step=0.100000
2017/08/25 22:53:59 step 5: mse=0.382709 step=0.100000
2017/08/25 22:54:02 step 6: mse=0.366755 step=0.100000
2017/08/25 22:54:06 step 7: mse=0.353585 step=0.100000
2017/08/25 22:54:06 Saving...
2017/08/25 22:54:06 Gathering batch of experience...
2017/08/25 22:54:17 batch 3: mean=5.594595 stddev=2.963375 entropy=1.304753 frames=33980 count=74
2017/08/25 22:54:17 Training policy...
2017/08/25 22:54:21 step 0: objective=-0.008171609
2017/08/25 22:54:23 step 1: objective=-0.00812096
2017/08/25 22:54:24 step 2: objective=-0.008070748
2017/08/25 22:54:26 step 3: objective=-0.008020989
2017/08/25 22:54:28 step 4: objective=-0.007971719
2017/08/25 22:54:30 step 5: objective=-0.007926066
2017/08/25 22:54:31 step 6: objective=-0.007885123
2017/08/25 22:54:33 step 7: objective=-0.007856904
2017/08/25 22:54:33 Training value function...
2017/08/25 22:54:37 step 0: mse=0.506351 step=0.100000
2017/08/25 22:54:41 step 1: mse=0.481928 step=0.100000
2017/08/25 22:54:44 step 2: mse=0.462071 step=0.100000
2017/08/25 22:54:48 step 3: mse=0.438783 step=0.100000
2017/08/25 22:54:52 step 4: mse=0.422539 step=0.100000
2017/08/25 22:54:55 step 5: mse=0.405946 step=0.100000
2017/08/25 22:54:59 step 6: mse=0.393622 step=0.100000
2017/08/25 22:55:02 step 7: mse=0.383189 step=0.100000
2017/08/25 22:55:02 Saving...
2017/08/25 22:55:02 Gathering batch of experience...
2017/08/25 22:55:13 batch 4: mean=5.657534 stddev=2.834326 entropy=1.306507 frames=33360 count=73
2017/08/25 22:55:13 Training policy...
2017/08/25 22:55:17 step 0: objective=0.005047197
2017/08/25 22:55:19 step 1: objective=0.005085998
2017/08/25 22:55:21 step 2: objective=0.005124684
2017/08/25 22:55:22 step 3: objective=0.005163306
2017/08/25 22:55:24 step 4: objective=0.005201823
2017/08/25 22:55:26 step 5: objective=0.005240268
2017/08/25 22:55:28 step 6: objective=0.0052780346
2017/08/25 22:55:29 step 7: objective=0.0053113406
2017/08/25 22:55:29 Training value function...
2017/08/25 22:55:33 step 0: mse=0.412275 step=0.100000
2017/08/25 22:55:37 step 1: mse=0.392597 step=0.100000
2017/08/25 22:55:41 step 2: mse=0.372846 step=0.100000
2017/08/25 22:55:44 step 3: mse=0.355835 step=0.100000
2017/08/25 22:55:48 step 4: mse=0.341252 step=0.100000
2017/08/25 22:55:51 step 5: mse=0.331396 step=0.100000
2017/08/25 22:55:54 step 6: mse=0.321488 step=0.100000
2017/08/25 22:55:58 step 7: mse=0.308219 step=0.100000
2017/08/25 22:55:58 Saving...
2017/08/25 22:55:58 Gathering batch of experience...
2017/08/25 22:56:09 batch 5: mean=5.413333 stddev=2.693663 entropy=1.309103 frames=33162 count=75
2017/08/25 22:56:09 Training policy...
2017/08/25 22:56:23 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 1 -maxtrees 5000]
2017/08/25 22:56:23 Creating environments...
2017/08/25 22:56:25 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/25 22:56:25 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/25 22:56:25 Running. Press Ctrl+C to stop.
2017/08/25 22:56:25 Gathering batch of experience...
2017/08/25 22:56:37 batch 0: mean=6.357143 stddev=2.888577 entropy=1.307090 frames=34221 count=70
2017/08/25 22:56:37 Training policy...
2017/08/25 22:56:41 step 0: objective=0.019185485
2017/08/25 22:56:42 step 1: objective=0.019238869
2017/08/25 22:56:44 step 2: objective=0.019291624
2017/08/25 22:56:46 step 3: objective=0.019344026
2017/08/25 22:56:48 step 4: objective=0.01939601
2017/08/25 22:56:50 step 5: objective=0.019444816
2017/08/25 22:56:51 step 6: objective=0.019488519
2017/08/25 22:56:53 step 7: objective=0.019526076
2017/08/25 22:56:53 Training value function...
2017/08/25 22:56:57 step 0: mse=0.505438 step=0.100000
2017/08/25 22:57:01 step 1: mse=0.469407 step=0.100000
2017/08/25 22:57:05 step 2: mse=0.440163 step=0.100000
2017/08/25 22:57:08 step 3: mse=0.417418 step=0.100000
2017/08/25 22:57:12 step 4: mse=0.397464 step=0.100000
2017/08/25 22:57:16 step 5: mse=0.382611 step=0.100000
2017/08/25 22:57:19 step 6: mse=0.366281 step=0.100000
2017/08/25 22:57:23 step 7: mse=0.354026 step=0.100000
2017/08/25 22:57:23 Saving...
2017/08/25 22:57:23 Gathering batch of experience...
2017/08/25 22:57:34 batch 1: mean=5.418919 stddev=2.504087 entropy=1.310367 frames=33117 count=74
2017/08/25 22:57:34 Training policy...
2017/08/25 22:57:38 step 0: objective=-0.013440571
2017/08/25 22:57:39 step 1: objective=-0.013413165
2017/08/25 22:57:41 step 2: objective=-0.01338594
2017/08/25 22:57:43 step 3: objective=-0.013358807
2017/08/25 22:57:45 step 4: objective=-0.013331806
2017/08/25 22:57:46 step 5: objective=-0.013305038
2017/08/25 22:57:48 step 6: objective=-0.013278344
2017/08/25 22:57:50 step 7: objective=-0.013251786
2017/08/25 22:57:50 Training value function...
2017/08/25 22:57:54 step 0: mse=0.335074 step=0.100000
2017/08/25 22:57:57 step 1: mse=0.319113 step=0.100000
2017/08/25 22:58:01 step 2: mse=0.306123 step=0.100000
2017/08/25 22:58:04 step 3: mse=0.293565 step=0.100000
2017/08/25 22:58:08 step 4: mse=0.283632 step=0.100000
2017/08/25 22:58:11 step 5: mse=0.274753 step=0.100000
2017/08/25 22:58:15 step 6: mse=0.265835 step=0.100000
2017/08/25 22:58:18 step 7: mse=0.258938 step=0.100000
2017/08/25 22:58:18 Saving...
2017/08/25 22:58:18 Gathering batch of experience...
2017/08/25 22:58:29 batch 2: mean=6.202899 stddev=2.574004 entropy=1.305205 frames=33424 count=69
2017/08/25 22:58:29 Training policy...
2017/08/25 22:58:33 step 0: objective=0.015741888
2017/08/25 22:58:35 step 1: objective=0.015775181
2017/08/25 22:58:37 step 2: objective=0.01580845
2017/08/25 22:58:38 step 3: objective=0.015838606
2017/08/25 22:58:40 step 4: objective=0.015868742
2017/08/25 22:58:42 step 5: objective=0.015898976
2017/08/25 22:58:44 step 6: objective=0.01592912
2017/08/25 22:58:46 step 7: objective=0.015959214
2017/08/25 22:58:46 Training value function...
2017/08/25 22:58:50 step 0: mse=0.392122 step=0.100000
2017/08/25 22:58:53 step 1: mse=0.371327 step=0.100000
2017/08/25 22:58:57 step 2: mse=0.354214 step=0.100000
2017/08/25 22:59:00 step 3: mse=0.340240 step=0.100000
2017/08/25 22:59:04 step 4: mse=0.330253 step=0.100000
2017/08/25 22:59:07 step 5: mse=0.318130 step=0.100000
2017/08/25 22:59:11 step 6: mse=0.311187 step=0.100000
2017/08/25 22:59:15 step 7: mse=0.302376 step=0.100000
2017/08/25 22:59:15 Saving...
2017/08/25 22:59:15 Gathering batch of experience...
2017/08/25 22:59:26 batch 3: mean=6.027397 stddev=2.779438 entropy=1.305630 frames=34428 count=73
2017/08/25 22:59:26 Training policy...
2017/08/25 22:59:30 step 0: objective=-0.000789316
2017/08/25 22:59:32 step 1: objective=-0.00074510754
2017/08/25 22:59:34 step 2: objective=-0.0007008138
2017/08/25 22:59:36 step 3: objective=-0.0006564184
2017/08/25 22:59:38 step 4: objective=-0.0006119041
2017/08/25 22:59:40 step 5: objective=-0.00056728063
2017/08/25 22:59:41 step 6: objective=-0.0005242268
2017/08/25 22:59:43 step 7: objective=-0.00048668697
2017/08/25 22:59:43 Training value function...
2017/08/25 22:59:48 step 0: mse=0.390218 step=0.100000
2017/08/25 22:59:51 step 1: mse=0.373147 step=0.100000
2017/08/25 22:59:55 step 2: mse=0.359048 step=0.100000
2017/08/25 22:59:59 step 3: mse=0.346551 step=0.100000
2017/08/25 23:00:03 step 4: mse=0.336279 step=0.100000
2017/08/25 23:00:06 step 5: mse=0.327064 step=0.100000
2017/08/25 23:00:10 step 6: mse=0.319440 step=0.100000
2017/08/25 23:00:14 step 7: mse=0.313540 step=0.100000
2017/08/25 23:00:14 Saving...
2017/08/25 23:00:14 Gathering batch of experience...
2017/08/25 23:00:25 batch 4: mean=6.485714 stddev=2.776137 entropy=1.302487 frames=34525 count=70
2017/08/25 23:00:25 Training policy...
2017/08/25 23:00:30 step 0: objective=0.01506066
2017/08/25 23:00:32 step 1: objective=0.015114437
2017/08/25 23:00:34 step 2: objective=0.015168466
2017/08/25 23:00:36 step 3: objective=0.015222774
2017/08/25 23:00:37 step 4: objective=0.015276788
2017/08/25 23:00:39 step 5: objective=0.015320491
2017/08/25 23:00:41 step 6: objective=0.015348363
2017/08/25 23:00:43 step 7: objective=0.015386559
2017/08/25 23:00:43 Training value function...
2017/08/25 23:00:47 step 0: mse=0.474486 step=0.100000
2017/08/25 23:00:51 step 1: mse=0.445584 step=0.100000
2017/08/25 23:00:55 step 2: mse=0.419559 step=0.100000
2017/08/25 23:00:59 step 3: mse=0.399481 step=0.100000
2017/08/25 23:01:02 step 4: mse=0.381305 step=0.100000
2017/08/25 23:01:06 step 5: mse=0.367325 step=0.100000
2017/08/25 23:01:10 step 6: mse=0.353133 step=0.100000
2017/08/25 23:01:14 step 7: mse=0.342664 step=0.100000
2017/08/25 23:01:14 Saving...
2017/08/25 23:01:14 Gathering batch of experience...
2017/08/25 23:01:25 batch 5: mean=6.169014 stddev=3.241396 entropy=1.301701 frames=33817 count=71
2017/08/25 23:01:25 Training policy...
2017/08/25 23:01:29 step 0: objective=-0.003634515
2017/08/25 23:01:31 step 1: objective=-0.003503495
2017/08/25 23:01:33 step 2: objective=-0.0033739433
2017/08/25 23:01:35 step 3: objective=-0.0032444645
2017/08/25 23:01:36 step 4: objective=-0.0031245472
2017/08/25 23:01:38 step 5: objective=-0.0030349488
2017/08/25 23:01:40 step 6: objective=-0.002948232
2017/08/25 23:01:42 step 7: objective=-0.0028802285
2017/08/25 23:01:42 Training value function...
2017/08/25 23:01:46 step 0: mse=0.565999 step=0.100000
2017/08/25 23:01:50 step 1: mse=0.537016 step=0.100000
2017/08/25 23:01:54 step 2: mse=0.515579 step=0.100000
2017/08/25 23:01:57 step 3: mse=0.494239 step=0.100000
2017/08/25 23:02:01 step 4: mse=0.479683 step=0.100000
2017/08/25 23:02:05 step 5: mse=0.469326 step=0.100000
2017/08/25 23:02:08 step 6: mse=0.448931 step=0.100000
2017/08/25 23:02:12 step 7: mse=0.440975 step=0.100000
2017/08/25 23:02:12 Saving...
2017/08/25 23:02:12 Gathering batch of experience...
2017/08/25 23:02:23 batch 6: mean=6.013889 stddev=3.066363 entropy=1.303071 frames=33482 count=72
2017/08/25 23:02:23 Training policy...
2017/08/25 23:02:27 step 0: objective=0.0041359277
2017/08/25 23:02:29 step 1: objective=0.0042210007
2017/08/25 23:02:31 step 2: objective=0.004306393
2017/08/25 23:02:33 step 3: objective=0.0043920926
2017/08/25 23:02:34 step 4: objective=0.0044749384
2017/08/25 23:02:36 step 5: objective=0.0045338366
2017/08/25 23:02:38 step 6: objective=0.0045862515
2017/08/25 23:02:40 step 7: objective=0.0046291566
2017/08/25 23:02:40 Training value function...
2017/08/25 23:02:44 step 0: mse=0.433877 step=0.100000
2017/08/25 23:02:47 step 1: mse=0.408808 step=0.100000
2017/08/25 23:02:51 step 2: mse=0.388268 step=0.100000
2017/08/25 23:02:55 step 3: mse=0.371099 step=0.100000
2017/08/25 23:02:59 step 4: mse=0.356645 step=0.100000
2017/08/25 23:03:03 step 5: mse=0.343603 step=0.100000
2017/08/25 23:03:06 step 6: mse=0.330964 step=0.100000
2017/08/25 23:03:10 step 7: mse=0.320682 step=0.100000
2017/08/25 23:03:10 Saving...
2017/08/25 23:03:10 Gathering batch of experience...
2017/08/25 23:03:21 batch 7: mean=6.573529 stddev=2.782911 entropy=1.301116 frames=34263 count=68
2017/08/25 23:03:21 Training policy...
2017/08/25 23:03:25 step 0: objective=0.0034243437
2017/08/25 23:03:27 step 1: objective=0.0035198138
2017/08/25 23:03:29 step 2: objective=0.0036138855
2017/08/25 23:03:31 step 3: objective=0.0037065763
2017/08/25 23:03:32 step 4: objective=0.0037957015
2017/08/25 23:03:34 step 5: objective=0.0038824144
2017/08/25 23:03:36 step 6: objective=0.0039389
2017/08/25 23:03:38 step 7: objective=0.003989731
2017/08/25 23:03:38 Training value function...
2017/08/25 23:03:42 step 0: mse=0.515575 step=0.100000
2017/08/25 23:03:46 step 1: mse=0.483979 step=0.100000
2017/08/25 23:03:50 step 2: mse=0.454567 step=0.100000
2017/08/25 23:03:53 step 3: mse=0.431360 step=0.100000
2017/08/25 23:03:57 step 4: mse=0.412050 step=0.100000
2017/08/25 23:04:01 step 5: mse=0.395768 step=0.100000
2017/08/25 23:04:04 step 6: mse=0.380697 step=0.100000
2017/08/25 23:04:08 step 7: mse=0.368377 step=0.100000
2017/08/25 23:04:08 Saving...
2017/08/25 23:04:08 Gathering batch of experience...
2017/08/25 23:04:19 batch 8: mean=5.500000 stddev=2.718251 entropy=1.301895 frames=33164 count=72
2017/08/25 23:04:19 Training policy...
2017/08/25 23:04:23 step 0: objective=-0.013749034
2017/08/25 23:04:25 step 1: objective=-0.013718422
2017/08/25 23:04:27 step 2: objective=-0.013676305
2017/08/25 23:04:28 step 3: objective=-0.013645942
2017/08/25 23:04:30 step 4: objective=-0.0136156315
2017/08/25 23:04:32 step 5: objective=-0.013574054
2017/08/25 23:04:34 step 6: objective=-0.01354392
2017/08/25 23:04:36 step 7: objective=-0.013502716
2017/08/25 23:04:36 Training value function...
2017/08/25 23:04:40 step 0: mse=0.493421 step=0.100000
2017/08/25 23:04:43 step 1: mse=0.444630 step=0.100000
2017/08/25 23:04:47 step 2: mse=0.405503 step=0.100000
2017/08/25 23:04:50 step 3: mse=0.373578 step=0.100000
2017/08/25 23:04:54 step 4: mse=0.347437 step=0.100000
2017/08/25 23:04:58 step 5: mse=0.324963 step=0.100000
2017/08/25 23:05:01 step 6: mse=0.306001 step=0.100000
2017/08/25 23:05:05 step 7: mse=0.290300 step=0.100000
2017/08/25 23:05:05 Saving...
2017/08/25 23:05:05 Gathering batch of experience...
2017/08/25 23:05:16 batch 9: mean=5.873239 stddev=2.954727 entropy=1.297211 frames=33290 count=71
2017/08/25 23:05:16 Training policy...
2017/08/25 23:05:20 step 0: objective=-0.009133668
2017/08/25 23:05:22 step 1: objective=-0.009057533
2017/08/25 23:05:24 step 2: objective=-0.008982018
2017/08/25 23:05:26 step 3: objective=-0.008907361
2017/08/25 23:05:27 step 4: objective=-0.008861356
2017/08/25 23:05:29 step 5: objective=-0.008820817
2017/08/25 23:05:31 step 6: objective=-0.008762935
2017/08/25 23:05:33 step 7: objective=-0.008713061
2017/08/25 23:05:33 Training value function...
2017/08/25 23:05:37 step 0: mse=0.514620 step=0.100000
2017/08/25 23:05:48 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.999 -maxtrees 5000]
2017/08/25 23:05:48 Creating environments...
2017/08/25 23:05:50 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/25 23:05:50 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/25 23:05:50 Running. Press Ctrl+C to stop.
2017/08/25 23:05:50 Gathering batch of experience...
2017/08/25 23:06:01 batch 0: mean=6.514286 stddev=2.877215 entropy=1.295258 frames=34197 count=70
2017/08/25 23:06:01 Training policy...
2017/08/25 23:06:06 step 0: objective=0.007798936
2017/08/25 23:06:08 step 1: objective=0.00786478
2017/08/25 23:06:10 step 2: objective=0.007931144
2017/08/25 23:06:11 step 3: objective=0.007997913
2017/08/25 23:06:13 step 4: objective=0.008058488
2017/08/25 23:06:15 step 5: objective=0.008129456
2017/08/25 23:06:17 step 6: objective=0.00818101
2017/08/25 23:06:19 step 7: objective=0.008236797
2017/08/25 23:06:19 Training value function...
2017/08/25 23:06:24 step 0: mse=0.576399 step=0.100000
2017/08/25 23:06:27 step 1: mse=0.545004 step=0.100000
2017/08/25 23:06:31 step 2: mse=0.519146 step=0.100000
2017/08/25 23:06:35 step 3: mse=0.496546 step=0.100000
2017/08/25 23:06:39 step 4: mse=0.478191 step=0.100000
2017/08/25 23:06:43 step 5: mse=0.462951 step=0.100000
2017/08/25 23:06:47 step 6: mse=0.448008 step=0.100000
2017/08/25 23:06:51 step 7: mse=0.435449 step=0.100000
2017/08/25 23:06:51 Saving...
2017/08/25 23:06:51 Gathering batch of experience...
2017/08/25 23:07:02 batch 1: mean=5.821918 stddev=2.603172 entropy=1.297966 frames=33601 count=73
2017/08/25 23:07:02 Training policy...
2017/08/25 23:07:06 step 0: objective=-0.0051017487
2017/08/25 23:07:08 step 1: objective=-0.005051892
2017/08/25 23:07:10 step 2: objective=-0.005001712
2017/08/25 23:07:12 step 3: objective=-0.004951139
2017/08/25 23:07:13 step 4: objective=-0.004900259
2017/08/25 23:07:15 step 5: objective=-0.0048567853
2017/08/25 23:07:17 step 6: objective=-0.0048132264
2017/08/25 23:07:19 step 7: objective=-0.0047676647
2017/08/25 23:07:19 Training value function...
2017/08/25 23:07:23 step 0: mse=0.390915 step=0.100000
2017/08/25 23:07:27 step 1: mse=0.368231 step=0.100000
2017/08/25 23:07:31 step 2: mse=0.348622 step=0.100000
2017/08/25 23:07:35 step 3: mse=0.332395 step=0.100000
2017/08/25 23:07:39 step 4: mse=0.318808 step=0.100000
2017/08/25 23:07:43 step 5: mse=0.308397 step=0.100000
2017/08/25 23:07:47 step 6: mse=0.297809 step=0.100000
2017/08/25 23:07:50 step 7: mse=0.290174 step=0.100000
2017/08/25 23:07:50 Saving...
2017/08/25 23:07:50 Gathering batch of experience...
2017/08/25 23:08:02 batch 2: mean=6.852941 stddev=3.602551 entropy=1.294206 frames=33959 count=68
2017/08/25 23:08:02 Training policy...
2017/08/25 23:08:06 step 0: objective=0.018398333
2017/08/25 23:08:08 step 1: objective=0.01853664
2017/08/25 23:08:10 step 2: objective=0.018675348
2017/08/25 23:08:12 step 3: objective=0.018808167
2017/08/25 23:08:14 step 4: objective=0.018871998
2017/08/25 23:08:16 step 5: objective=0.018952344
2017/08/25 23:08:18 step 6: objective=0.019008711
2017/08/25 23:08:20 step 7: objective=0.019057803
2017/08/25 23:08:20 Training value function...
2017/08/25 23:08:24 step 0: mse=0.742227 step=0.100000
2017/08/25 23:08:28 step 1: mse=0.697832 step=0.100000
2017/08/25 23:08:32 step 2: mse=0.661826 step=0.100000
2017/08/25 23:08:36 step 3: mse=0.620381 step=0.100000
2017/08/25 23:08:40 step 4: mse=0.586495 step=0.100000
2017/08/25 23:08:44 step 5: mse=0.559475 step=0.100000
2017/08/25 23:08:47 step 6: mse=0.532557 step=0.100000
2017/08/25 23:08:51 step 7: mse=0.514981 step=0.100000
2017/08/25 23:08:51 Saving...
2017/08/25 23:08:51 Gathering batch of experience...
2017/08/25 23:09:03 batch 3: mean=6.070423 stddev=2.994474 entropy=1.297892 frames=33874 count=71
2017/08/25 23:09:03 Training policy...
2017/08/25 23:09:07 step 0: objective=-0.019858684
2017/08/25 23:09:09 step 1: objective=-0.01980427
2017/08/25 23:09:11 step 2: objective=-0.019749826
2017/08/25 23:09:13 step 3: objective=-0.019695686
2017/08/25 23:09:15 step 4: objective=-0.019641463
2017/08/25 23:09:17 step 5: objective=-0.019598538
2017/08/25 23:09:19 step 6: objective=-0.019570418
2017/08/25 23:09:21 step 7: objective=-0.019513283
2017/08/25 23:09:21 Training value function...
2017/08/25 23:09:25 step 0: mse=0.384952 step=0.100000
2017/08/25 23:09:29 step 1: mse=0.363383 step=0.100000
2017/08/25 23:09:33 step 2: mse=0.345824 step=0.100000
2017/08/25 23:09:37 step 3: mse=0.331014 step=0.100000
2017/08/25 23:09:41 step 4: mse=0.315814 step=0.100000
2017/08/25 23:09:45 step 5: mse=0.303296 step=0.100000
2017/08/25 23:09:48 step 6: mse=0.291927 step=0.100000
2017/08/25 23:09:52 step 7: mse=0.282188 step=0.100000
2017/08/25 23:09:52 Saving...
2017/08/25 23:09:52 Gathering batch of experience...
2017/08/25 23:10:03 batch 4: mean=7.089552 stddev=3.627142 entropy=1.295721 frames=33631 count=67
2017/08/25 23:10:03 Training policy...
2017/08/25 23:10:08 step 0: objective=0.034610413
2017/08/25 23:10:09 step 1: objective=0.034731083
2017/08/25 23:10:11 step 2: objective=0.03487169
2017/08/25 23:10:13 step 3: objective=0.03501188
2017/08/25 23:10:15 step 4: objective=0.035093278
2017/08/25 23:10:17 step 5: objective=0.035162523
2017/08/25 23:10:19 step 6: objective=0.03523333
2017/08/25 23:10:20 step 7: objective=0.035263408
2017/08/25 23:10:20 Training value function...
2017/08/25 23:10:25 step 0: mse=0.887328 step=0.100000
2017/08/25 23:10:28 step 1: mse=0.806493 step=0.100000
2017/08/25 23:10:32 step 2: mse=0.740990 step=0.100000
2017/08/25 23:10:36 step 3: mse=0.687756 step=0.100000
2017/08/25 23:10:40 step 4: mse=0.643733 step=0.100000
2017/08/25 23:10:44 step 5: mse=0.607268 step=0.100000
2017/08/25 23:10:47 step 6: mse=0.571974 step=0.100000
2017/08/25 23:10:51 step 7: mse=0.551683 step=0.100000
2017/08/25 23:10:51 Saving...
2017/08/25 23:10:51 Gathering batch of experience...
2017/08/25 23:11:03 batch 5: mean=6.485714 stddev=2.901935 entropy=1.298723 frames=34367 count=70
2017/08/25 23:11:03 Training policy...
2017/08/25 23:11:07 step 0: objective=-0.009796864
2017/08/25 23:11:09 step 1: objective=-0.009722566
2017/08/25 23:11:11 step 2: objective=-0.009650149
2017/08/25 23:11:13 step 3: objective=-0.009579556
2017/08/25 23:11:15 step 4: objective=-0.009511099
2017/08/25 23:11:17 step 5: objective=-0.00946158
2017/08/25 23:11:18 step 6: objective=-0.0094287945
2017/08/25 23:11:20 step 7: objective=-0.009367169
2017/08/25 23:11:20 Training value function...
2017/08/25 23:11:25 step 0: mse=0.625887 step=0.100000
2017/08/25 23:11:29 step 1: mse=0.585773 step=0.100000
2017/08/25 23:11:33 step 2: mse=0.552401 step=0.100000
2017/08/25 23:11:37 step 3: mse=0.524879 step=0.100000
2017/08/25 23:11:40 step 4: mse=0.495266 step=0.100000
2017/08/25 23:11:44 step 5: mse=0.467959 step=0.100000
2017/08/25 23:11:48 step 6: mse=0.444687 step=0.100000
2017/08/25 23:11:52 step 7: mse=0.429986 step=0.100000
2017/08/25 23:11:52 Saving...
2017/08/25 23:11:52 Gathering batch of experience...
2017/08/25 23:12:03 batch 6: mean=5.972222 stddev=2.924856 entropy=1.298075 frames=34100 count=72
2017/08/25 23:12:03 Training policy...
2017/08/25 23:12:08 step 0: objective=-0.011173422
2017/08/25 23:12:10 step 1: objective=-0.011130365
2017/08/25 23:12:11 step 2: objective=-0.01108687
2017/08/25 23:12:14 step 3: objective=-0.01104308
2017/08/25 23:12:16 step 4: objective=-0.010998915
2017/08/25 23:12:17 step 5: objective=-0.01095908
2017/08/25 23:12:19 step 6: objective=-0.010898365
2017/08/25 23:12:21 step 7: objective=-0.010845384
2017/08/25 23:12:21 Training value function...
2017/08/25 23:12:26 step 0: mse=0.390412 step=0.100000
2017/08/25 23:12:30 step 1: mse=0.375725 step=0.100000
2017/08/25 23:12:34 step 2: mse=0.365399 step=0.100000
2017/08/25 23:12:38 step 3: mse=0.353683 step=0.100000
2017/08/25 23:12:42 step 4: mse=0.343814 step=0.100000
2017/08/25 23:12:46 step 5: mse=0.337577 step=0.100000
2017/08/25 23:12:50 step 6: mse=0.331444 step=0.100000
2017/08/25 23:12:53 step 7: mse=0.322891 step=0.100000
2017/08/25 23:12:53 Saving...
2017/08/25 23:12:53 Gathering batch of experience...
2017/08/25 23:13:04 batch 7: mean=5.864865 stddev=3.342294 entropy=1.301535 frames=33729 count=74
2017/08/25 23:13:04 Training policy...
2017/08/25 23:13:09 step 0: objective=8.350825e-05
2017/08/25 23:13:11 step 1: objective=0.00015281815
2017/08/25 23:13:13 step 2: objective=0.00022196391
2017/08/25 23:13:14 step 3: objective=0.00029094485
2017/08/25 23:13:16 step 4: objective=0.00035840095
2017/08/25 23:13:18 step 5: objective=0.000408779
2017/08/25 23:13:20 step 6: objective=0.00046155672
2017/08/25 23:13:22 step 7: objective=0.00053755014
2017/08/25 23:13:22 Training value function...
2017/08/25 23:13:26 step 0: mse=0.702032 step=0.100000
2017/08/25 23:13:30 step 1: mse=0.651726 step=0.100000
2017/08/25 23:13:34 step 2: mse=0.610923 step=0.100000
2017/08/25 23:13:38 step 3: mse=0.577851 step=0.100000
2017/08/25 23:13:42 step 4: mse=0.552013 step=0.100000
2017/08/25 23:13:46 step 5: mse=0.530384 step=0.100000
2017/08/25 23:13:50 step 6: mse=0.509506 step=0.100000
2017/08/25 23:13:54 step 7: mse=0.489854 step=0.100000
2017/08/25 23:13:54 Saving...
2017/08/25 23:13:54 Gathering batch of experience...
2017/08/25 23:14:05 batch 8: mean=5.716216 stddev=2.522977 entropy=1.303256 frames=33678 count=74
2017/08/25 23:14:05 Training policy...
2017/08/25 23:14:09 step 0: objective=-0.007384558
2017/08/25 23:14:11 step 1: objective=-0.0073201885
2017/08/25 23:14:13 step 2: objective=-0.007256011
2017/08/25 23:14:15 step 3: objective=-0.007191926
2017/08/25 23:14:17 step 4: objective=-0.0071279486
2017/08/25 23:14:19 step 5: objective=-0.0070700585
2017/08/25 23:14:21 step 6: objective=-0.0070175924
2017/08/25 23:14:23 step 7: objective=-0.006984007
2017/08/25 23:14:23 Training value function...
2017/08/25 23:14:27 step 0: mse=0.423796 step=0.100000
2017/08/25 23:14:31 step 1: mse=0.395931 step=0.100000
2017/08/25 23:14:35 step 2: mse=0.372504 step=0.100000
2017/08/25 23:14:39 step 3: mse=0.353083 step=0.100000
2017/08/25 23:14:43 step 4: mse=0.337075 step=0.100000
2017/08/25 23:14:47 step 5: mse=0.323101 step=0.100000
2017/08/25 23:14:51 step 6: mse=0.309084 step=0.100000
2017/08/25 23:14:55 step 7: mse=0.296982 step=0.100000
2017/08/25 23:14:55 Saving...
2017/08/25 23:14:55 Gathering batch of experience...
2017/08/25 23:15:06 batch 9: mean=5.958904 stddev=2.939753 entropy=1.300531 frames=34159 count=73
2017/08/25 23:15:06 Training policy...
2017/08/25 23:15:10 step 0: objective=0.005102782
2017/08/25 23:15:12 step 1: objective=0.0051791626
2017/08/25 23:15:14 step 2: objective=0.00525505
2017/08/25 23:15:16 step 3: objective=0.0053304657
2017/08/25 23:15:18 step 4: objective=0.0054053683
2017/08/25 23:15:20 step 5: objective=0.0054792464
2017/08/25 23:15:22 step 6: objective=0.0055415183
2017/08/25 23:15:24 step 7: objective=0.0055970624
2017/08/25 23:15:24 Training value function...
2017/08/25 23:15:28 step 0: mse=0.616213 step=0.100000
2017/08/25 23:15:32 step 1: mse=0.565802 step=0.100000
2017/08/25 23:15:36 step 2: mse=0.524803 step=0.100000
2017/08/25 23:15:40 step 3: mse=0.491447 step=0.100000
2017/08/25 23:15:44 step 4: mse=0.464234 step=0.100000
2017/08/25 23:15:48 step 5: mse=0.442198 step=0.100000
2017/08/25 23:15:53 step 6: mse=0.409336 step=0.100000
2017/08/25 23:15:57 step 7: mse=0.393770 step=0.100000
2017/08/25 23:15:57 Saving...
2017/08/25 23:15:57 Gathering batch of experience...
2017/08/25 23:16:08 batch 10: mean=5.958333 stddev=3.043379 entropy=1.301196 frames=33626 count=72
2017/08/25 23:16:08 Training policy...
2017/08/25 23:16:12 step 0: objective=0.0032338088
2017/08/25 23:16:14 step 1: objective=0.003311556
2017/08/25 23:16:16 step 2: objective=0.003388264
2017/08/25 23:16:18 step 3: objective=0.0034636664
2017/08/25 23:16:20 step 4: objective=0.0035031112
2017/08/25 23:16:22 step 5: objective=0.0035369208
2017/08/25 23:16:24 step 6: objective=0.0035807726
2017/08/25 23:16:26 step 7: objective=0.0036288667
2017/08/25 23:16:26 Training value function...
2017/08/25 23:16:30 step 0: mse=0.650385 step=0.100000
2017/08/25 23:16:34 step 1: mse=0.597485 step=0.100000
2017/08/25 23:16:38 step 2: mse=0.554461 step=0.100000
2017/08/25 23:16:42 step 3: mse=0.519372 step=0.100000
2017/08/25 23:16:46 step 4: mse=0.490651 step=0.100000
2017/08/25 23:16:50 step 5: mse=0.467814 step=0.100000
2017/08/25 23:16:54 step 6: mse=0.447893 step=0.100000
2017/08/25 23:16:58 step 7: mse=0.432046 step=0.100000
2017/08/25 23:16:58 Saving...
2017/08/25 23:16:58 Gathering batch of experience...
2017/08/25 23:17:09 batch 11: mean=6.142857 stddev=2.982260 entropy=1.299934 frames=33918 count=70
2017/08/25 23:17:09 Training policy...
2017/08/25 23:17:14 step 0: objective=-0.005890677
2017/08/25 23:17:16 step 1: objective=-0.005829629
2017/08/25 23:17:18 step 2: objective=-0.0057695177
2017/08/25 23:17:20 step 3: objective=-0.0057103634
2017/08/25 23:17:22 step 4: objective=-0.005652039
2017/08/25 23:17:23 step 5: objective=-0.005595022
2017/08/25 23:17:25 step 6: objective=-0.005546254
2017/08/25 23:17:27 step 7: objective=-0.005483816
2017/08/25 23:17:27 Training value function...
2017/08/25 23:17:32 step 0: mse=0.573095 step=0.100000
2017/08/25 23:17:36 step 1: mse=0.534691 step=0.100000
2017/08/25 23:17:40 step 2: mse=0.503275 step=0.100000
2017/08/25 23:17:44 step 3: mse=0.477531 step=0.100000
2017/08/25 23:17:48 step 4: mse=0.456436 step=0.100000
2017/08/25 23:17:52 step 5: mse=0.431155 step=0.100000
2017/08/25 23:17:56 step 6: mse=0.409851 step=0.100000
2017/08/25 23:18:00 step 7: mse=0.388187 step=0.100000
2017/08/25 23:18:00 Saving...
2017/08/25 23:18:00 Gathering batch of experience...
2017/08/25 23:18:11 batch 12: mean=6.295775 stddev=3.383449 entropy=1.300951 frames=34088 count=71
2017/08/25 23:18:11 Training policy...
2017/08/25 23:18:16 step 0: objective=0.024194319
2017/08/25 23:18:18 step 1: objective=0.024276862
2017/08/25 23:18:20 step 2: objective=0.024360154
2017/08/25 23:18:22 step 3: objective=0.024444021
2017/08/25 23:18:24 step 4: objective=0.024528138
2017/08/25 23:18:26 step 5: objective=0.024601806
2017/08/25 23:18:28 step 6: objective=0.024630407
2017/08/25 23:18:30 step 7: objective=0.024663378
2017/08/25 23:18:30 Training value function...
2017/08/25 23:18:35 step 0: mse=0.752047 step=0.100000
2017/08/25 23:18:39 step 1: mse=0.682999 step=0.100000
2017/08/25 23:18:43 step 2: mse=0.627069 step=0.100000
2017/08/25 23:18:47 step 3: mse=0.585775 step=0.100000
2017/08/25 23:18:51 step 4: mse=0.542292 step=0.100000
2017/08/25 23:18:55 step 5: mse=0.509701 step=0.100000
2017/08/25 23:18:59 step 6: mse=0.479600 step=0.100000
2017/08/25 23:19:03 step 7: mse=0.459776 step=0.100000
2017/08/25 23:19:03 Saving...
2017/08/25 23:19:04 Gathering batch of experience...
2017/08/25 23:19:15 batch 13: mean=5.743243 stddev=2.885475 entropy=1.299502 frames=33764 count=74
2017/08/25 23:19:15 Training policy...
2017/08/25 23:19:19 step 0: objective=0.004264368
2017/08/25 23:19:21 step 1: objective=0.0043821493
2017/08/25 23:19:23 step 2: objective=0.004498348
2017/08/25 23:19:25 step 3: objective=0.0046056258
2017/08/25 23:19:27 step 4: objective=0.0046860175
2017/08/25 23:19:29 step 5: objective=0.004742038
2017/08/25 23:19:31 step 6: objective=0.0047786217
2017/08/25 23:19:33 step 7: objective=0.004801013
2017/08/25 23:19:33 Training value function...
2017/08/25 23:19:37 step 0: mse=0.455319 step=0.100000
2017/08/25 23:19:41 step 1: mse=0.431259 step=0.100000
2017/08/25 23:19:45 step 2: mse=0.411237 step=0.100000
2017/08/25 23:19:49 step 3: mse=0.394210 step=0.100000
2017/08/25 23:19:54 step 4: mse=0.378487 step=0.100000
2017/08/25 23:19:58 step 5: mse=0.365693 step=0.100000
2017/08/25 23:20:02 step 6: mse=0.353195 step=0.100000
2017/08/25 23:20:06 step 7: mse=0.342774 step=0.100000
2017/08/25 23:20:06 Saving...
2017/08/25 23:20:06 Gathering batch of experience...
2017/08/25 23:20:17 batch 14: mean=5.710526 stddev=2.855354 entropy=1.304417 frames=33667 count=76
2017/08/25 23:20:17 Training policy...
2017/08/25 23:20:21 step 0: objective=0.010175818
2017/08/25 23:20:23 step 1: objective=0.01021357
2017/08/25 23:20:25 step 2: objective=0.01025153
2017/08/25 23:20:27 step 3: objective=0.010289604
2017/08/25 23:20:29 step 4: objective=0.010327683
2017/08/25 23:20:31 step 5: objective=0.010365139
2017/08/25 23:20:33 step 6: objective=0.010394291
2017/08/25 23:20:36 step 7: objective=0.010418776
2017/08/25 23:20:36 Training value function...
2017/08/25 23:20:40 step 0: mse=0.556446 step=0.100000
2017/08/25 23:20:44 step 1: mse=0.512390 step=0.100000
2017/08/25 23:20:48 step 2: mse=0.476284 step=0.100000
2017/08/25 23:20:52 step 3: mse=0.446493 step=0.100000
2017/08/25 23:20:56 step 4: mse=0.422109 step=0.100000
2017/08/25 23:21:00 step 5: mse=0.401833 step=0.100000
2017/08/25 23:21:04 step 6: mse=0.380790 step=0.100000
2017/08/25 23:21:09 step 7: mse=0.365466 step=0.100000
2017/08/25 23:21:09 Saving...
2017/08/25 23:21:09 Gathering batch of experience...
2017/08/25 23:21:20 batch 15: mean=5.726027 stddev=2.365623 entropy=1.301981 frames=33729 count=73
2017/08/25 23:21:20 Training policy...
2017/08/25 23:21:24 step 0: objective=-0.0046042292
2017/08/25 23:21:26 step 1: objective=-0.004498291
2017/08/25 23:21:28 step 2: objective=-0.004392626
2017/08/25 23:21:30 step 3: objective=-0.0042983377
2017/08/25 23:21:32 step 4: objective=-0.004214903
2017/08/25 23:21:34 step 5: objective=-0.0041451403
2017/08/25 23:21:36 step 6: objective=-0.0040937834
2017/08/25 23:21:38 step 7: objective=-0.0040689465
2017/08/25 23:21:38 Training value function...
2017/08/25 23:21:43 step 0: mse=0.594147 step=0.100000
2017/08/25 23:21:47 step 1: mse=0.531588 step=0.100000
2017/08/25 23:21:51 step 2: mse=0.480620 step=0.100000
2017/08/25 23:21:55 step 3: mse=0.439289 step=0.100000
2017/08/25 23:21:59 step 4: mse=0.408864 step=0.100000
2017/08/25 23:22:04 step 5: mse=0.383996 step=0.100000
2017/08/25 23:22:08 step 6: mse=0.360662 step=0.100000
2017/08/25 23:22:12 step 7: mse=0.341422 step=0.100000
2017/08/25 23:22:12 Saving...
2017/08/25 23:22:12 Gathering batch of experience...
2017/08/25 23:22:23 batch 16: mean=6.071429 stddev=2.972836 entropy=1.303880 frames=33119 count=70
2017/08/25 23:22:23 Training policy...
2017/08/25 23:22:27 step 0: objective=0.019396033
2017/08/25 23:22:29 step 1: objective=0.01949023
2017/08/25 23:22:32 step 2: objective=0.019585762
2017/08/25 23:22:34 step 3: objective=0.019682573
2017/08/25 23:22:36 step 4: objective=0.019738656
2017/08/25 23:22:38 step 5: objective=0.019785196
2017/08/25 23:22:40 step 6: objective=0.019843265
2017/08/25 23:22:41 step 7: objective=0.01989276
2017/08/25 23:22:41 Training value function...
2017/08/25 23:22:46 step 0: mse=0.683166 step=0.100000
2017/08/25 23:22:50 step 1: mse=0.625197 step=0.100000
2017/08/25 23:22:54 step 2: mse=0.578247 step=0.100000
2017/08/25 23:22:59 step 3: mse=0.540067 step=0.100000
2017/08/25 23:23:03 step 4: mse=0.504477 step=0.100000
2017/08/25 23:23:07 step 5: mse=0.478815 step=0.100000
2017/08/25 23:23:11 step 6: mse=0.453045 step=0.100000
2017/08/25 23:23:15 step 7: mse=0.432150 step=0.100000
2017/08/25 23:23:15 Saving...
2017/08/25 23:23:15 Gathering batch of experience...
2017/08/25 23:23:26 batch 17: mean=5.918919 stddev=2.550870 entropy=1.305667 frames=34110 count=74
2017/08/25 23:23:26 Training policy...
2017/08/25 23:23:31 step 0: objective=0.016489511
2017/08/25 23:23:33 step 1: objective=0.01654545
2017/08/25 23:23:35 step 2: objective=0.016600924
2017/08/25 23:23:37 step 3: objective=0.016655847
2017/08/25 23:23:39 step 4: objective=0.016711773
2017/08/25 23:23:41 step 5: objective=0.016772192
2017/08/25 23:23:43 step 6: objective=0.016819138
2017/08/25 23:23:45 step 7: objective=0.016852964
2017/08/25 23:23:45 Training value function...
2017/08/25 23:23:50 step 0: mse=0.512220 step=0.100000
2017/08/25 23:23:54 step 1: mse=0.473388 step=0.100000
2017/08/25 23:23:58 step 2: mse=0.440573 step=0.100000
2017/08/25 23:24:02 step 3: mse=0.414744 step=0.100000
2017/08/25 23:24:07 step 4: mse=0.392421 step=0.100000
2017/08/25 23:24:11 step 5: mse=0.374110 step=0.100000
2017/08/25 23:24:15 step 6: mse=0.358724 step=0.100000
2017/08/25 23:24:19 step 7: mse=0.344421 step=0.100000
2017/08/25 23:24:19 Saving...
2017/08/25 23:24:19 Gathering batch of experience...
2017/08/25 23:24:30 batch 18: mean=5.089744 stddev=2.627204 entropy=1.304044 frames=33419 count=78
2017/08/25 23:24:30 Training policy...
2017/08/25 23:24:35 step 0: objective=-0.02014755
2017/08/25 23:24:37 step 1: objective=-0.020114308
2017/08/25 23:24:39 step 2: objective=-0.020081168
2017/08/25 23:24:41 step 3: objective=-0.020047624
2017/08/25 23:24:43 step 4: objective=-0.02001412
2017/08/25 23:24:45 step 5: objective=-0.0199802
2017/08/25 23:24:47 step 6: objective=-0.019946165
2017/08/25 23:24:49 step 7: objective=-0.01991744
2017/08/25 23:24:49 Training value function...
2017/08/25 23:24:54 step 0: mse=0.405858 step=0.100000
2017/08/25 23:24:58 step 1: mse=0.378932 step=0.100000
2017/08/25 23:25:02 step 2: mse=0.356807 step=0.100000
2017/08/25 23:25:07 step 3: mse=0.338141 step=0.100000
2017/08/25 23:25:11 step 4: mse=0.316888 step=0.100000
2017/08/25 23:25:15 step 5: mse=0.299654 step=0.100000
2017/08/25 23:25:19 step 6: mse=0.284634 step=0.100000
2017/08/25 23:25:23 step 7: mse=0.272373 step=0.100000
2017/08/25 23:25:23 Saving...
2017/08/25 23:25:23 Gathering batch of experience...
2017/08/25 23:25:35 batch 19: mean=6.183099 stddev=3.216637 entropy=1.303669 frames=33862 count=71
2017/08/25 23:25:35 Training policy...
2017/08/25 23:25:39 step 0: objective=0.024159174
2017/08/25 23:25:41 step 1: objective=0.024235282
2017/08/25 23:25:43 step 2: objective=0.024311196
2017/08/25 23:25:45 step 3: objective=0.02438736
2017/08/25 23:25:47 step 4: objective=0.024461644
2017/08/25 23:25:49 step 5: objective=0.02451734
2017/08/25 23:25:51 step 6: objective=0.024571141
2017/08/25 23:25:54 step 7: objective=0.02461075
2017/08/25 23:25:54 Training value function...
2017/08/25 23:25:58 step 0: mse=0.720879 step=0.100000
2017/08/25 23:26:03 step 1: mse=0.673204 step=0.100000
2017/08/25 23:26:07 step 2: mse=0.634495 step=0.100000
2017/08/25 23:26:11 step 3: mse=0.602486 step=0.100000
2017/08/25 23:26:15 step 4: mse=0.564346 step=0.100000
2017/08/25 23:26:20 step 5: mse=0.533015 step=0.100000
2017/08/25 23:26:24 step 6: mse=0.507150 step=0.100000
2017/08/25 23:26:28 step 7: mse=0.487666 step=0.100000
2017/08/25 23:26:28 Saving...
2017/08/25 23:26:28 Gathering batch of experience...
2017/08/25 23:26:39 batch 20: mean=6.154930 stddev=3.191749 entropy=1.306226 frames=33283 count=71
2017/08/25 23:26:39 Training policy...
2017/08/25 23:26:44 step 0: objective=0.012631702
2017/08/25 23:26:46 step 1: objective=0.012689906
2017/08/25 23:26:48 step 2: objective=0.012748276
2017/08/25 23:26:50 step 3: objective=0.01280683
2017/08/25 23:26:52 step 4: objective=0.012865665
2017/08/25 23:26:54 step 5: objective=0.0129217645
2017/08/25 23:26:56 step 6: objective=0.01297737
2017/08/25 23:26:58 step 7: objective=0.013027053
2017/08/25 23:26:58 Training value function...
2017/08/25 23:27:03 step 0: mse=0.550145 step=0.100000
2017/08/25 23:27:07 step 1: mse=0.512134 step=0.100000
2017/08/25 23:27:11 step 2: mse=0.480221 step=0.100000
2017/08/25 23:27:16 step 3: mse=0.452368 step=0.100000
2017/08/25 23:27:20 step 4: mse=0.430739 step=0.100000
2017/08/25 23:27:24 step 5: mse=0.409502 step=0.100000
2017/08/25 23:27:28 step 6: mse=0.392635 step=0.100000
2017/08/25 23:27:32 step 7: mse=0.375261 step=0.100000
2017/08/25 23:27:32 Saving...
2017/08/25 23:27:32 Gathering batch of experience...
2017/08/25 23:27:43 batch 21: mean=5.662162 stddev=2.932931 entropy=1.302742 frames=33529 count=74
2017/08/25 23:27:43 Training policy...
2017/08/25 23:27:48 step 0: objective=-0.0066729733
2017/08/25 23:27:50 step 1: objective=-0.0066062957
2017/08/25 23:27:52 step 2: objective=-0.006539138
2017/08/25 23:27:54 step 3: objective=-0.006471464
2017/08/25 23:27:56 step 4: objective=-0.0064036185
2017/08/25 23:27:58 step 5: objective=-0.006344434
2017/08/25 23:28:01 step 6: objective=-0.006282031
2017/08/25 23:28:03 step 7: objective=-0.006245646
2017/08/25 23:28:03 Training value function...
2017/08/25 23:28:07 step 0: mse=0.496226 step=0.100000
2017/08/25 23:28:12 step 1: mse=0.465229 step=0.100000
2017/08/25 23:28:16 step 2: mse=0.445334 step=0.100000
2017/08/25 23:28:20 step 3: mse=0.428921 step=0.100000
2017/08/25 23:28:25 step 4: mse=0.408481 step=0.100000
2017/08/25 23:28:29 step 5: mse=0.386857 step=0.100000
2017/08/25 23:28:33 step 6: mse=0.372428 step=0.100000
2017/08/25 23:28:37 step 7: mse=0.363428 step=0.100000
2017/08/25 23:28:37 Saving...
2017/08/25 23:28:37 Gathering batch of experience...
2017/08/25 23:28:48 batch 22: mean=5.166667 stddev=2.812138 entropy=1.306253 frames=33380 count=78
2017/08/25 23:28:48 Training policy...
2017/08/25 23:28:53 step 0: objective=-0.0023119557
2017/08/25 23:28:55 step 1: objective=-0.002224163
2017/08/25 23:28:57 step 2: objective=-0.002136543
2017/08/25 23:28:59 step 3: objective=-0.002049075
2017/08/25 23:29:02 step 4: objective=-0.0019763517
2017/08/25 23:29:04 step 5: objective=-0.0019097155
2017/08/25 23:29:06 step 6: objective=-0.00183967
2017/08/25 23:29:08 step 7: objective=-0.0017813763
2017/08/25 23:29:08 Training value function...
2017/08/25 23:29:13 step 0: mse=0.416438 step=0.100000
2017/08/25 23:29:17 step 1: mse=0.395350 step=0.100000
2017/08/25 23:29:21 step 2: mse=0.378198 step=0.100000
2017/08/25 23:29:25 step 3: mse=0.363577 step=0.100000
2017/08/25 23:29:30 step 4: mse=0.350621 step=0.100000
2017/08/25 23:29:34 step 5: mse=0.339855 step=0.100000
2017/08/25 23:29:38 step 6: mse=0.330510 step=0.100000
2017/08/25 23:29:43 step 7: mse=0.322649 step=0.100000
2017/08/25 23:29:43 Saving...
2017/08/25 23:29:43 Gathering batch of experience...
2017/08/25 23:29:54 batch 23: mean=5.445946 stddev=2.766312 entropy=1.306850 frames=33175 count=74
2017/08/25 23:29:54 Training policy...
2017/08/25 23:29:58 step 0: objective=0.0051684785
2017/08/25 23:30:01 step 1: objective=0.0052292347
2017/08/25 23:30:03 step 2: objective=0.0052899215
2017/08/25 23:30:05 step 3: objective=0.0053506615
2017/08/25 23:30:07 step 4: objective=0.0054112445
2017/08/25 23:30:09 step 5: objective=0.0054700277
2017/08/25 23:30:11 step 6: objective=0.0055147936
2017/08/25 23:30:13 step 7: objective=0.005575395
2017/08/25 23:30:13 Training value function...
2017/08/25 23:30:18 step 0: mse=0.422671 step=0.100000
2017/08/25 23:30:22 step 1: mse=0.400233 step=0.100000
2017/08/25 23:30:27 step 2: mse=0.388237 step=0.100000
2017/08/25 23:30:31 step 3: mse=0.371337 step=0.100000
2017/08/25 23:30:35 step 4: mse=0.357514 step=0.100000
2017/08/25 23:30:40 step 5: mse=0.345632 step=0.100000
2017/08/25 23:30:44 step 6: mse=0.339138 step=0.100000
2017/08/25 23:30:49 step 7: mse=0.328834 step=0.100000
2017/08/25 23:30:49 Saving...
2017/08/25 23:30:49 Gathering batch of experience...
2017/08/25 23:31:00 batch 24: mean=5.552632 stddev=2.612695 entropy=1.307445 frames=33910 count=76
2017/08/25 23:31:00 Training policy...
2017/08/25 23:31:05 step 0: objective=0.0070755687
2017/08/25 23:31:07 step 1: objective=0.0071396637
2017/08/25 23:31:09 step 2: objective=0.007202815
2017/08/25 23:31:11 step 3: objective=0.007265094
2017/08/25 23:31:13 step 4: objective=0.007326401
2017/08/25 23:31:15 step 5: objective=0.0073729274
2017/08/25 23:31:17 step 6: objective=0.00741839
2017/08/25 23:31:20 step 7: objective=0.007446881
2017/08/25 23:31:20 Training value function...
2017/08/25 23:31:25 step 0: mse=0.419735 step=0.100000
2017/08/25 23:31:29 step 1: mse=0.399141 step=0.100000
2017/08/25 23:31:34 step 2: mse=0.382033 step=0.100000
2017/08/25 23:31:38 step 3: mse=0.369266 step=0.100000
2017/08/25 23:31:42 step 4: mse=0.355071 step=0.100000
2017/08/25 23:31:47 step 5: mse=0.344229 step=0.100000
2017/08/25 23:31:51 step 6: mse=0.334091 step=0.100000
2017/08/25 23:31:55 step 7: mse=0.317303 step=0.100000
2017/08/25 23:31:55 Saving...
2017/08/25 23:31:56 Gathering batch of experience...
2017/08/25 23:32:17 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 1 -maxtrees 5000]
2017/08/25 23:32:17 Creating environments...
2017/08/25 23:32:19 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/25 23:32:19 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/25 23:32:19 Running. Press Ctrl+C to stop.
2017/08/25 23:32:19 Gathering batch of experience...
2017/08/25 23:32:31 batch 0: mean=6.478873 stddev=3.071262 entropy=1.304541 frames=34663 count=71
2017/08/25 23:32:31 Training policy...
2017/08/25 23:32:36 step 0: objective=0.026724428
2017/08/25 23:32:38 step 1: objective=0.026822684
2017/08/25 23:32:40 step 2: objective=0.026919339
2017/08/25 23:32:42 step 3: objective=0.02701287
2017/08/25 23:32:45 step 4: objective=0.027051177
2017/08/25 23:32:47 step 5: objective=0.027101483
2017/08/25 23:32:49 step 6: objective=0.027130837
2017/08/25 23:32:51 step 7: objective=0.027190192
2017/08/25 23:32:51 Training value function...
2017/08/25 23:32:56 step 0: mse=0.718446 step=0.100000
2017/08/25 23:33:01 step 1: mse=0.661758 step=0.100000
2017/08/25 23:33:06 step 2: mse=0.616442 step=0.100000
2017/08/25 23:33:10 step 3: mse=0.576708 step=0.100000
2017/08/25 23:33:15 step 4: mse=0.539174 step=0.100000
2017/08/25 23:33:20 step 5: mse=0.512801 step=0.100000
2017/08/25 23:33:24 step 6: mse=0.490294 step=0.100000
2017/08/25 23:33:29 step 7: mse=0.472342 step=0.100000
2017/08/25 23:33:29 Saving...
2017/08/25 23:33:29 Gathering batch of experience...
2017/08/25 23:33:40 batch 1: mean=5.481013 stddev=3.117370 entropy=1.305145 frames=34384 count=79
2017/08/25 23:33:40 Training policy...
2017/08/25 23:33:45 step 0: objective=-0.004955446
2017/08/25 23:33:48 step 1: objective=-0.0046980237
2017/08/25 23:33:50 step 2: objective=-0.0045348164
2017/08/25 23:33:52 step 3: objective=-0.004391975
2017/08/25 23:33:54 step 4: objective=-0.004329572
2017/08/25 23:33:56 step 5: objective=-0.0043022293
2017/08/25 23:33:59 step 6: objective=-0.0042452686
2017/08/25 23:34:01 step 7: objective=-0.00424661
2017/08/25 23:34:01 Training value function...
2017/08/25 23:34:06 step 0: mse=0.612636 step=0.100000
2017/08/25 23:34:10 step 1: mse=0.556509 step=0.100000
2017/08/25 23:34:15 step 2: mse=0.511006 step=0.100000
2017/08/25 23:34:20 step 3: mse=0.475255 step=0.100000
2017/08/25 23:34:24 step 4: mse=0.444360 step=0.100000
2017/08/25 23:34:29 step 5: mse=0.417420 step=0.100000
2017/08/25 23:34:34 step 6: mse=0.396184 step=0.100000
2017/08/25 23:34:38 step 7: mse=0.379129 step=0.100000
2017/08/25 23:34:38 Saving...
2017/08/25 23:34:38 Gathering batch of experience...
2017/08/25 23:34:49 batch 2: mean=6.027778 stddev=3.068533 entropy=1.302185 frames=33676 count=72
2017/08/25 23:34:49 Training policy...
2017/08/25 23:34:54 step 0: objective=-0.006847731
2017/08/25 23:34:56 step 1: objective=-0.0067576645
2017/08/25 23:34:59 step 2: objective=-0.0066675404
2017/08/25 23:35:01 step 3: objective=-0.0065774447
2017/08/25 23:35:03 step 4: objective=-0.0064913253
2017/08/25 23:35:05 step 5: objective=-0.0064393124
2017/08/25 23:35:07 step 6: objective=-0.0063557876
2017/08/25 23:35:09 step 7: objective=-0.0062901294
2017/08/25 23:35:09 Training value function...
2017/08/25 23:35:14 step 0: mse=0.743329 step=0.100000
2017/08/25 23:35:19 step 1: mse=0.696099 step=0.100000
2017/08/25 23:35:24 step 2: mse=0.657827 step=0.100000
2017/08/25 23:35:29 step 3: mse=0.626670 step=0.100000
2017/08/25 23:35:33 step 4: mse=0.600342 step=0.100000
2017/08/25 23:35:38 step 5: mse=0.570198 step=0.100000
2017/08/25 23:35:42 step 6: mse=0.547001 step=0.100000
2017/08/25 23:35:47 step 7: mse=0.527374 step=0.100000
2017/08/25 23:35:47 Saving...
2017/08/25 23:35:47 Gathering batch of experience...
2017/08/25 23:35:58 batch 3: mean=5.750000 stddev=2.696448 entropy=1.301477 frames=33156 count=72
2017/08/25 23:35:58 Training policy...
2017/08/25 23:36:03 step 0: objective=-0.015464531
2017/08/25 23:36:05 step 1: objective=-0.0154038565
2017/08/25 23:36:07 step 2: objective=-0.015342718
2017/08/25 23:36:09 step 3: objective=-0.015281102
2017/08/25 23:36:12 step 4: objective=-0.0152225355
2017/08/25 23:36:14 step 5: objective=-0.015187803
2017/08/25 23:36:16 step 6: objective=-0.015113524
2017/08/25 23:36:18 step 7: objective=-0.015046502
2017/08/25 23:36:18 Training value function...
2017/08/25 23:36:23 step 0: mse=0.532124 step=0.100000
2017/08/25 23:36:28 step 1: mse=0.494016 step=0.100000
2017/08/25 23:36:32 step 2: mse=0.466376 step=0.100000
2017/08/25 23:36:37 step 3: mse=0.437847 step=0.100000
2017/08/25 23:36:41 step 4: mse=0.412759 step=0.100000
2017/08/25 23:36:45 step 5: mse=0.393138 step=0.100000
2017/08/25 23:36:50 step 6: mse=0.376970 step=0.100000
2017/08/25 23:36:54 step 7: mse=0.362048 step=0.100000
2017/08/25 23:36:54 Saving...
2017/08/25 23:36:54 Gathering batch of experience...
2017/08/25 23:37:06 batch 4: mean=6.100000 stddev=2.355237 entropy=1.301595 frames=33594 count=70
2017/08/25 23:37:06 Training policy...
2017/08/25 23:37:11 step 0: objective=0.0011412216
2017/08/25 23:37:13 step 1: objective=0.0011858718
2017/08/25 23:37:15 step 2: objective=0.001230043
2017/08/25 23:37:17 step 3: objective=0.0012737599
2017/08/25 23:37:20 step 4: objective=0.0013170074
2017/08/25 23:37:22 step 5: objective=0.001359811
2017/08/25 23:37:24 step 6: objective=0.0014021754
2017/08/25 23:37:26 step 7: objective=0.001441995
2017/08/25 23:37:26 Training value function...
2017/08/25 23:37:31 step 0: mse=0.421178 step=0.100000
2017/08/25 23:37:36 step 1: mse=0.400981 step=0.100000
2017/08/25 23:37:40 step 2: mse=0.379894 step=0.100000
2017/08/25 23:37:45 step 3: mse=0.365171 step=0.100000
2017/08/25 23:37:49 step 4: mse=0.344419 step=0.100000
2017/08/25 23:37:54 step 5: mse=0.330516 step=0.100000
2017/08/25 23:37:58 step 6: mse=0.318499 step=0.100000
2017/08/25 23:38:03 step 7: mse=0.304189 step=0.100000
2017/08/25 23:38:03 Saving...
2017/08/25 23:38:03 Gathering batch of experience...
2017/08/25 23:38:15 batch 5: mean=6.100000 stddev=2.547548 entropy=1.298864 frames=33147 count=70
2017/08/25 23:38:15 Training policy...
2017/08/25 23:38:20 step 0: objective=0.0030236035
2017/08/25 23:38:22 step 1: objective=0.0031262587
2017/08/25 23:38:24 step 2: objective=0.0032278104
2017/08/25 23:38:26 step 3: objective=0.0033248314
2017/08/25 23:38:28 step 4: objective=0.0033874782
2017/08/25 23:38:30 step 5: objective=0.0034886873
2017/08/25 23:38:32 step 6: objective=0.0035401788
2017/08/25 23:38:34 step 7: objective=0.0036178608
2017/08/25 23:38:34 Training value function...
2017/08/25 23:38:39 step 0: mse=0.482219 step=0.100000
2017/08/25 23:38:43 step 1: mse=0.452172 step=0.100000
2017/08/25 23:38:48 step 2: mse=0.427974 step=0.100000
2017/08/25 23:38:52 step 3: mse=0.407928 step=0.100000
2017/08/25 23:38:57 step 4: mse=0.391489 step=0.100000
2017/08/25 23:39:01 step 5: mse=0.377347 step=0.100000
2017/08/25 23:39:05 step 6: mse=0.365849 step=0.100000
2017/08/25 23:39:10 step 7: mse=0.354672 step=0.100000
2017/08/25 23:39:10 Saving...
2017/08/25 23:39:10 Gathering batch of experience...
2017/08/25 23:39:21 batch 6: mean=6.225352 stddev=2.611983 entropy=1.295127 frames=34332 count=71
2017/08/25 23:39:21 Training policy...
2017/08/25 23:39:26 step 0: objective=0.002103801
2017/08/25 23:39:28 step 1: objective=0.0021922672
2017/08/25 23:39:30 step 2: objective=0.0022821974
2017/08/25 23:39:33 step 3: objective=0.0023700409
2017/08/25 23:39:35 step 4: objective=0.0024273053
2017/08/25 23:39:37 step 5: objective=0.0024887468
2017/08/25 23:39:39 step 6: objective=0.0025501137
2017/08/25 23:39:42 step 7: objective=0.0026065034
2017/08/25 23:39:42 Training value function...
2017/08/25 23:39:47 step 0: mse=0.524181 step=0.100000
2017/08/25 23:39:52 step 1: mse=0.502318 step=0.100000
2017/08/25 23:39:56 step 2: mse=0.478826 step=0.100000
2017/08/25 23:40:01 step 3: mse=0.461257 step=0.100000
2017/08/25 23:40:06 step 4: mse=0.443243 step=0.100000
2017/08/25 23:40:10 step 5: mse=0.429438 step=0.100000
2017/08/25 23:40:15 step 6: mse=0.411076 step=0.100000
2017/08/25 23:40:20 step 7: mse=0.395055 step=0.100000
2017/08/25 23:40:20 Saving...
2017/08/25 23:40:20 Gathering batch of experience...
2017/08/25 23:40:31 batch 7: mean=6.352113 stddev=3.327642 entropy=1.295408 frames=34133 count=71
2017/08/25 23:40:31 Training policy...
2017/08/25 23:40:36 step 0: objective=0.01238995
2017/08/25 23:40:38 step 1: objective=0.012533961
2017/08/25 23:40:40 step 2: objective=0.0126684625
2017/08/25 23:40:42 step 3: objective=0.012755113
2017/08/25 23:40:44 step 4: objective=0.012795506
2017/08/25 23:40:47 step 5: objective=0.012847827
2017/08/25 23:40:49 step 6: objective=0.0129013145
2017/08/25 23:40:51 step 7: objective=0.012948867
2017/08/25 23:40:51 Training value function...
2017/08/25 23:40:56 step 0: mse=0.692401 step=0.100000
2017/08/25 23:41:01 step 1: mse=0.635188 step=0.100000
2017/08/25 23:41:05 step 2: mse=0.588378 step=0.100000
2017/08/25 23:41:10 step 3: mse=0.552497 step=0.100000
2017/08/25 23:41:15 step 4: mse=0.519884 step=0.100000
2017/08/25 23:41:19 step 5: mse=0.492051 step=0.100000
2017/08/25 23:41:24 step 6: mse=0.469277 step=0.100000
2017/08/25 23:41:28 step 7: mse=0.448501 step=0.100000
2017/08/25 23:41:28 Saving...
2017/08/25 23:41:29 Gathering batch of experience...
2017/08/25 23:41:39 batch 8: mean=6.347826 stddev=3.296138 entropy=1.295205 frames=33518 count=69
2017/08/25 23:41:39 Training policy...
2017/08/25 23:41:44 step 0: objective=0.0035446382
2017/08/25 23:41:47 step 1: objective=0.00364906
2017/08/25 23:41:49 step 2: objective=0.0037527117
2017/08/25 23:41:51 step 3: objective=0.003855695
2017/08/25 23:41:53 step 4: objective=0.0039508096
2017/08/25 23:41:55 step 5: objective=0.004031529
2017/08/25 23:41:58 step 6: objective=0.0041198223
2017/08/25 23:42:00 step 7: objective=0.0041776607
2017/08/25 23:42:00 Training value function...
2017/08/25 23:42:05 step 0: mse=0.553954 step=0.100000
2017/08/25 23:42:09 step 1: mse=0.516633 step=0.100000
2017/08/25 23:42:14 step 2: mse=0.486403 step=0.100000
2017/08/25 23:42:18 step 3: mse=0.461915 step=0.100000
2017/08/25 23:42:23 step 4: mse=0.442073 step=0.100000
2017/08/25 23:42:27 step 5: mse=0.426784 step=0.100000
2017/08/25 23:42:32 step 6: mse=0.414367 step=0.100000
2017/08/25 23:42:37 step 7: mse=0.401039 step=0.100000
2017/08/25 23:42:37 Saving...
2017/08/25 23:42:37 Gathering batch of experience...
2017/08/25 23:42:48 batch 9: mean=6.084507 stddev=3.218549 entropy=1.295727 frames=33344 count=71
2017/08/25 23:42:48 Training policy...
2017/08/25 23:42:53 step 0: objective=-0.0043397928
2017/08/25 23:42:55 step 1: objective=-0.0042757005
2017/08/25 23:42:57 step 2: objective=-0.0042122738
2017/08/25 23:42:59 step 3: objective=-0.004149462
2017/08/25 23:43:01 step 4: objective=-0.0040873447
2017/08/25 23:43:04 step 5: objective=-0.003958712
2017/08/25 23:43:06 step 6: objective=-0.0039122896
2017/08/25 23:43:08 step 7: objective=-0.0038635645
2017/08/25 23:43:08 Training value function...
2017/08/25 23:43:13 step 0: mse=0.757232 step=0.100000
2017/08/25 23:43:18 step 1: mse=0.701848 step=0.100000
2017/08/25 23:43:22 step 2: mse=0.656988 step=0.100000
2017/08/25 23:43:27 step 3: mse=0.620582 step=0.100000
2017/08/25 23:43:31 step 4: mse=0.590886 step=0.100000
2017/08/25 23:43:36 step 5: mse=0.566468 step=0.100000
2017/08/25 23:43:40 step 6: mse=0.542763 step=0.100000
2017/08/25 23:43:45 step 7: mse=0.518448 step=0.100000
2017/08/25 23:43:45 Saving...
2017/08/25 23:43:45 Gathering batch of experience...
2017/08/25 23:43:56 batch 10: mean=6.185714 stddev=2.763501 entropy=1.294737 frames=33782 count=70
2017/08/25 23:43:56 Training policy...
2017/08/25 23:44:01 step 0: objective=0.0041522286
2017/08/25 23:44:03 step 1: objective=0.0043172226
2017/08/25 23:44:05 step 2: objective=0.0044831275
2017/08/25 23:44:08 step 3: objective=0.004620039
2017/08/25 23:44:10 step 4: objective=0.0047179973
2017/08/25 23:44:12 step 5: objective=0.0048160576
2017/08/25 23:44:14 step 6: objective=0.0049129943
2017/08/25 23:44:17 step 7: objective=0.0049831904
2017/08/25 23:44:17 Training value function...
2017/08/25 23:44:22 step 0: mse=0.683123 step=0.100000
2017/08/25 23:44:26 step 1: mse=0.627474 step=0.100000
2017/08/25 23:44:31 step 2: mse=0.582088 step=0.100000
2017/08/25 23:44:36 step 3: mse=0.545130 step=0.100000
2017/08/25 23:44:40 step 4: mse=0.511077 step=0.100000
2017/08/25 23:44:45 step 5: mse=0.486073 step=0.100000
2017/08/25 23:44:49 step 6: mse=0.458041 step=0.100000
2017/08/25 23:44:54 step 7: mse=0.435158 step=0.100000
2017/08/25 23:44:54 Saving...
2017/08/25 23:44:54 Gathering batch of experience...
2017/08/25 23:45:05 batch 11: mean=6.865672 stddev=3.480845 entropy=1.291354 frames=33836 count=67
2017/08/25 23:45:05 Training policy...
2017/08/25 23:45:10 step 0: objective=0.011741817
2017/08/25 23:45:13 step 1: objective=0.01203851
2017/08/25 23:45:15 step 2: objective=0.0122946575
2017/08/25 23:45:17 step 3: objective=0.012407064
2017/08/25 23:45:19 step 4: objective=0.012500556
2017/08/25 23:45:21 step 5: objective=0.01259811
2017/08/25 23:45:24 step 6: objective=0.012671065
2017/08/25 23:45:26 step 7: objective=0.012726104
2017/08/25 23:45:26 Training value function...
2017/08/25 23:45:31 step 0: mse=0.917358 step=0.100000
2017/08/25 23:45:36 step 1: mse=0.850983 step=0.100000
2017/08/25 23:45:40 step 2: mse=0.784821 step=0.100000
2017/08/25 23:45:45 step 3: mse=0.735774 step=0.100000
2017/08/25 23:45:50 step 4: mse=0.689530 step=0.100000
2017/08/25 23:45:55 step 5: mse=0.651811 step=0.100000
2017/08/25 23:45:59 step 6: mse=0.618725 step=0.100000
2017/08/25 23:46:04 step 7: mse=0.585276 step=0.100000
2017/08/25 23:46:04 Saving...
2017/08/25 23:46:04 Gathering batch of experience...
2017/08/25 23:46:15 batch 12: mean=6.200000 stddev=3.357720 entropy=1.291981 frames=33446 count=70
2017/08/25 23:46:15 Training policy...
2017/08/25 23:46:20 step 0: objective=0.0034054318
2017/08/25 23:46:22 step 1: objective=0.003527798
2017/08/25 23:46:25 step 2: objective=0.003648778
2017/08/25 23:46:27 step 3: objective=0.0037648634
2017/08/25 23:46:30 step 4: objective=0.0038506056
2017/08/25 23:46:32 step 5: objective=0.0039471625
2017/08/25 23:46:34 step 6: objective=0.003992673
2017/08/25 23:46:36 step 7: objective=0.0040426366
2017/08/25 23:46:36 Training value function...
2017/08/25 23:46:41 step 0: mse=0.803061 step=0.100000
2017/08/25 23:46:46 step 1: mse=0.750785 step=0.100000
2017/08/25 23:46:51 step 2: mse=0.707737 step=0.100000
2017/08/25 23:46:55 step 3: mse=0.669222 step=0.100000
2017/08/25 23:47:00 step 4: mse=0.638585 step=0.100000
2017/08/25 23:47:04 step 5: mse=0.613898 step=0.100000
2017/08/25 23:47:09 step 6: mse=0.591640 step=0.100000
2017/08/25 23:47:14 step 7: mse=0.572324 step=0.100000
2017/08/25 23:47:14 Saving...
2017/08/25 23:47:14 Gathering batch of experience...
2017/08/25 23:47:25 batch 13: mean=6.304348 stddev=2.725640 entropy=1.290873 frames=33501 count=69
2017/08/25 23:47:25 Training policy...
2017/08/25 23:47:30 step 0: objective=0.002528127
2017/08/25 23:47:32 step 1: objective=0.002602397
2017/08/25 23:47:34 step 2: objective=0.0026767955
2017/08/25 23:47:36 step 3: objective=0.0027513902
2017/08/25 23:47:39 step 4: objective=0.0028258774
2017/08/25 23:47:41 step 5: objective=0.0028734154
2017/08/25 23:47:43 step 6: objective=0.002960813
2017/08/25 23:47:45 step 7: objective=0.0030297025
2017/08/25 23:47:45 Training value function...
2017/08/25 23:47:51 step 0: mse=0.542500 step=0.100000
2017/08/25 23:47:55 step 1: mse=0.516938 step=0.100000
2017/08/25 23:48:00 step 2: mse=0.496081 step=0.100000
2017/08/25 23:48:05 step 3: mse=0.478804 step=0.100000
2017/08/25 23:48:09 step 4: mse=0.464805 step=0.100000
2017/08/25 23:48:14 step 5: mse=0.451819 step=0.100000
2017/08/25 23:48:19 step 6: mse=0.442061 step=0.100000
2017/08/25 23:48:23 step 7: mse=0.432771 step=0.100000
2017/08/25 23:48:23 Saving...
2017/08/25 23:48:23 Gathering batch of experience...
2017/08/25 23:48:35 batch 14: mean=6.098592 stddev=2.888320 entropy=1.292152 frames=33851 count=71
2017/08/25 23:48:35 Training policy...
2017/08/25 23:48:40 step 0: objective=-0.018009242
2017/08/25 23:48:42 step 1: objective=-0.01796085
2017/08/25 23:48:44 step 2: objective=-0.01791254
2017/08/25 23:48:47 step 3: objective=-0.017864361
2017/08/25 23:48:49 step 4: objective=-0.017816264
2017/08/25 23:48:51 step 5: objective=-0.017768303
2017/08/25 23:48:53 step 6: objective=-0.017720344
2017/08/25 23:48:56 step 7: objective=-0.017675107
2017/08/25 23:48:56 Training value function...
2017/08/25 23:49:01 step 0: mse=0.536586 step=0.100000
2017/08/25 23:49:06 step 1: mse=0.506626 step=0.100000
2017/08/25 23:49:10 step 2: mse=0.482285 step=0.100000
2017/08/25 23:49:15 step 3: mse=0.460321 step=0.100000
2017/08/25 23:49:20 step 4: mse=0.444391 step=0.100000
2017/08/25 23:49:25 step 5: mse=0.429590 step=0.100000
2017/08/25 23:49:30 step 6: mse=0.406027 step=0.100000
2017/08/25 23:49:34 step 7: mse=0.393492 step=0.100000
2017/08/25 23:49:34 Saving...
2017/08/25 23:49:34 Gathering batch of experience...
2017/08/25 23:49:46 batch 15: mean=6.347222 stddev=3.727375 entropy=1.290369 frames=33773 count=72
2017/08/25 23:49:46 Training policy...
2017/08/25 23:49:51 step 0: objective=0.010148001
2017/08/25 23:49:53 step 1: objective=0.010293974
2017/08/25 23:49:55 step 2: objective=0.010439188
2017/08/25 23:49:58 step 3: objective=0.010542008
2017/08/25 23:50:00 step 4: objective=0.010598004
2017/08/25 23:50:02 step 5: objective=0.010697534
2017/08/25 23:50:04 step 6: objective=0.010768732
2017/08/25 23:50:07 step 7: objective=0.010834693
2017/08/25 23:50:07 Training value function...
2017/08/25 23:50:12 step 0: mse=0.847860 step=0.100000
2017/08/25 23:50:17 step 1: mse=0.797923 step=0.100000
2017/08/25 23:50:21 step 2: mse=0.757473 step=0.100000
2017/08/25 23:50:26 step 3: mse=0.721859 step=0.100000
2017/08/25 23:50:31 step 4: mse=0.691519 step=0.100000
2017/08/25 23:50:36 step 5: mse=0.666678 step=0.100000
2017/08/25 23:50:41 step 6: mse=0.646446 step=0.100000
2017/08/25 23:50:46 step 7: mse=0.625955 step=0.100000
2017/08/25 23:50:46 Saving...
2017/08/25 23:50:46 Gathering batch of experience...
2017/08/25 23:50:57 batch 16: mean=6.397059 stddev=2.834347 entropy=1.287365 frames=33759 count=68
2017/08/25 23:50:57 Training policy...
2017/08/25 23:51:02 step 0: objective=-0.0049515185
2017/08/25 23:51:04 step 1: objective=-0.0048609655
2017/08/25 23:51:07 step 2: objective=-0.004769507
2017/08/25 23:51:09 step 3: objective=-0.0046771322
2017/08/25 23:51:11 step 4: objective=-0.0046053436
2017/08/25 23:51:14 step 5: objective=-0.0044939406
2017/08/25 23:51:16 step 6: objective=-0.004403347
2017/08/25 23:51:18 step 7: objective=-0.004355673
2017/08/25 23:51:18 Training value function...
2017/08/25 23:51:23 step 0: mse=0.497698 step=0.100000
2017/08/25 23:51:28 step 1: mse=0.471875 step=0.100000
2017/08/25 23:51:33 step 2: mse=0.450910 step=0.100000
2017/08/25 23:51:38 step 3: mse=0.429086 step=0.100000
2017/08/25 23:51:43 step 4: mse=0.410747 step=0.100000
2017/08/25 23:51:48 step 5: mse=0.394633 step=0.100000
2017/08/25 23:51:53 step 6: mse=0.378444 step=0.100000
2017/08/25 23:51:57 step 7: mse=0.366043 step=0.100000
2017/08/25 23:51:57 Saving...
2017/08/25 23:51:57 Gathering batch of experience...
2017/08/25 23:52:09 batch 17: mean=6.225352 stddev=3.353355 entropy=1.289924 frames=33682 count=71
2017/08/25 23:52:09 Training policy...
2017/08/25 23:52:14 step 0: objective=0.005215125
2017/08/25 23:52:16 step 1: objective=0.0054171383
2017/08/25 23:52:18 step 2: objective=0.0056166872
2017/08/25 23:52:21 step 3: objective=0.005799936
2017/08/25 23:52:23 step 4: objective=0.005919768
2017/08/25 23:52:25 step 5: objective=0.0060120197
2017/08/25 23:52:28 step 6: objective=0.0060560964
2017/08/25 23:52:30 step 7: objective=0.006186482
2017/08/25 23:52:30 Training value function...
2017/08/25 23:52:35 step 0: mse=0.844665 step=0.100000
2017/08/25 23:52:40 step 1: mse=0.787841 step=0.100000
2017/08/25 23:52:45 step 2: mse=0.744893 step=0.100000
2017/08/25 23:52:50 step 3: mse=0.700604 step=0.100000
2017/08/25 23:52:55 step 4: mse=0.664519 step=0.100000
2017/08/25 23:53:00 step 5: mse=0.634718 step=0.100000
2017/08/25 23:53:04 step 6: mse=0.610256 step=0.100000
2017/08/25 23:53:09 step 7: mse=0.589669 step=0.100000
2017/08/25 23:53:09 Saving...
2017/08/25 23:53:09 Gathering batch of experience...
2017/08/25 23:53:21 batch 18: mean=6.776119 stddev=3.080128 entropy=1.287836 frames=34055 count=67
2017/08/25 23:53:21 Training policy...
2017/08/25 23:53:26 step 0: objective=0.013053265
2017/08/25 23:53:28 step 1: objective=0.013205607
2017/08/25 23:53:31 step 2: objective=0.013362253
2017/08/25 23:53:33 step 3: objective=0.0135045275
2017/08/25 23:53:35 step 4: objective=0.013589825
2017/08/25 23:53:38 step 5: objective=0.013643818
2017/08/25 23:53:40 step 6: objective=0.013697641
2017/08/25 23:53:42 step 7: objective=0.013754887
2017/08/25 23:53:42 Training value function...
2017/08/25 23:53:48 step 0: mse=0.646706 step=0.100000
2017/08/25 23:53:53 step 1: mse=0.615130 step=0.100000
2017/08/25 23:53:58 step 2: mse=0.578390 step=0.100000
2017/08/25 23:54:03 step 3: mse=0.548608 step=0.100000
2017/08/25 23:54:08 step 4: mse=0.524186 step=0.100000
2017/08/25 23:54:13 step 5: mse=0.505940 step=0.100000
2017/08/25 23:54:17 step 6: mse=0.492771 step=0.100000
2017/08/25 23:54:22 step 7: mse=0.479394 step=0.100000
2017/08/25 23:54:22 Saving...
2017/08/25 23:54:23 Gathering batch of experience...
2017/08/25 23:54:34 batch 19: mean=6.140845 stddev=2.942145 entropy=1.286627 frames=33932 count=71
2017/08/25 23:54:34 Training policy...
2017/08/25 23:54:39 step 0: objective=-0.0115387505
2017/08/25 23:54:41 step 1: objective=-0.011482278
2017/08/25 23:54:44 step 2: objective=-0.011426021
2017/08/25 23:54:46 step 3: objective=-0.011370061
2017/08/25 23:54:48 step 4: objective=-0.011314246
2017/08/25 23:54:51 step 5: objective=-0.011269454
2017/08/25 23:54:53 step 6: objective=-0.011224907
2017/08/25 23:54:55 step 7: objective=-0.011184159
2017/08/25 23:54:55 Training value function...
2017/08/25 23:55:01 step 0: mse=0.568290 step=0.100000
2017/08/25 23:55:06 step 1: mse=0.523124 step=0.100000
2017/08/25 23:55:11 step 2: mse=0.486506 step=0.100000
2017/08/25 23:55:55 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.999 -maxtrees 5000]
2017/08/25 23:55:55 Creating environments...
2017/08/25 23:55:58 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/25 23:55:58 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/25 23:55:58 Running. Press Ctrl+C to stop.
2017/08/25 23:55:58 Gathering batch of experience...
2017/08/25 23:56:09 batch 0: mean=6.521739 stddev=2.981142 entropy=1.289939 frames=33108 count=69
2017/08/25 23:56:09 Training policy...
2017/08/25 23:56:14 step 0: objective=0.007771527
2017/08/25 23:56:16 step 1: objective=0.007901363
2017/08/25 23:56:18 step 2: objective=0.00803063
2017/08/25 23:56:21 step 3: objective=0.008159389
2017/08/25 23:56:23 step 4: objective=0.008287071
2017/08/25 23:56:25 step 5: objective=0.00839019
2017/08/25 23:56:28 step 6: objective=0.00849012
2017/08/25 23:56:30 step 7: objective=0.008560142
2017/08/25 23:56:30 Training value function...
2017/08/25 23:56:35 step 0: mse=0.651465 step=0.100000
2017/08/25 23:56:40 step 1: mse=0.609159 step=0.100000
2017/08/25 23:56:45 step 2: mse=0.574685 step=0.100000
2017/08/25 23:56:53 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.9998 -maxtrees 5000]
2017/08/25 23:56:53 Creating environments...
2017/08/25 23:56:55 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/25 23:56:55 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/25 23:56:55 Running. Press Ctrl+C to stop.
2017/08/25 23:56:55 Gathering batch of experience...
2017/08/25 23:57:06 batch 0: mean=7.333333 stddev=3.116775 entropy=1.286706 frames=33776 count=63
2017/08/25 23:57:06 Training policy...
2017/08/25 23:57:11 step 0: objective=0.005895736
2017/08/25 23:57:14 step 1: objective=0.005946627
2017/08/25 23:57:16 step 2: objective=0.005997848
2017/08/25 23:57:18 step 3: objective=0.0060493243
2017/08/25 23:57:21 step 4: objective=0.0061011165
2017/08/25 23:57:23 step 5: objective=0.006153168
2017/08/25 23:57:25 step 6: objective=0.006201816
2017/08/25 23:57:28 step 7: objective=0.006240613
2017/08/25 23:57:28 Training value function...
2017/08/25 23:57:33 step 0: mse=0.556129 step=0.100000
2017/08/25 23:57:38 step 1: mse=0.520967 step=0.100000
2017/08/25 23:57:43 step 2: mse=0.491967 step=0.100000
2017/08/25 23:57:48 step 3: mse=0.467443 step=0.100000
2017/08/25 23:57:53 step 4: mse=0.447231 step=0.100000
2017/08/25 23:57:58 step 5: mse=0.429857 step=0.100000
2017/08/25 23:58:03 step 6: mse=0.415524 step=0.100000
2017/08/25 23:58:09 step 7: mse=0.402898 step=0.100000
2017/08/25 23:58:09 Saving...
2017/08/25 23:58:09 Gathering batch of experience...
2017/08/25 23:58:20 batch 1: mean=6.239437 stddev=3.387902 entropy=1.286504 frames=33877 count=71
2017/08/25 23:58:20 Training policy...
2017/08/25 23:58:25 step 0: objective=-0.004988406
2017/08/25 23:58:28 step 1: objective=-0.00487933
2017/08/25 23:58:30 step 2: objective=-0.0047695064
2017/08/25 23:58:32 step 3: objective=-0.0046589477
2017/08/25 23:58:35 step 4: objective=-0.0045883884
2017/08/25 23:58:37 step 5: objective=-0.0044115423
2017/08/25 23:58:40 step 6: objective=-0.004337267
2017/08/25 23:58:42 step 7: objective=-0.0042132763
2017/08/25 23:58:42 Training value function...
2017/08/25 23:58:48 step 0: mse=0.786746 step=0.100000
2017/08/25 23:58:53 step 1: mse=0.737245 step=0.100000
2017/08/25 23:58:58 step 2: mse=0.705745 step=0.100000
2017/08/25 23:59:03 step 3: mse=0.680210 step=0.100000
2017/08/25 23:59:08 step 4: mse=0.659386 step=0.100000
2017/08/25 23:59:13 step 5: mse=0.642251 step=0.100000
2017/08/25 23:59:18 step 6: mse=0.628254 step=0.100000
2017/08/25 23:59:23 step 7: mse=0.616616 step=0.100000
2017/08/25 23:59:23 Saving...
2017/08/25 23:59:23 Gathering batch of experience...
2017/08/25 23:59:35 batch 2: mean=6.863636 stddev=3.123161 entropy=1.287475 frames=34497 count=66
2017/08/25 23:59:35 Training policy...
2017/08/25 23:59:40 step 0: objective=-0.008002133
2017/08/25 23:59:43 step 1: objective=-0.007912086
2017/08/25 23:59:45 step 2: objective=-0.007822349
2017/08/25 23:59:48 step 3: objective=-0.0077327113
2017/08/25 23:59:50 step 4: objective=-0.0076440363
2017/08/25 23:59:53 step 5: objective=-0.007576092
2017/08/25 23:59:55 step 6: objective=-0.0074791033
2017/08/25 23:59:57 step 7: objective=-0.0073169693
2017/08/25 23:59:57 Training value function...
2017/08/26 00:00:03 step 0: mse=0.837972 step=0.100000
2017/08/26 00:00:08 step 1: mse=0.773155 step=0.100000
2017/08/26 00:00:14 step 2: mse=0.720437 step=0.100000
2017/08/26 00:00:19 step 3: mse=0.666538 step=0.100000
2017/08/26 00:00:24 step 4: mse=0.622371 step=0.100000
2017/08/26 00:00:30 step 5: mse=0.585415 step=0.100000
2017/08/26 00:00:35 step 6: mse=0.553547 step=0.100000
2017/08/26 00:00:40 step 7: mse=0.519733 step=0.100000
2017/08/26 00:00:40 Saving...
2017/08/26 00:00:40 Gathering batch of experience...
2017/08/26 00:00:52 batch 3: mean=6.366197 stddev=3.123015 entropy=1.287128 frames=34470 count=71
2017/08/26 00:00:52 Training policy...
2017/08/26 00:00:57 step 0: objective=0.008101839
2017/08/26 00:01:00 step 1: objective=0.008242172
2017/08/26 00:01:02 step 2: objective=0.008381755
2017/08/26 00:01:04 step 3: objective=0.0085130725
2017/08/26 00:01:07 step 4: objective=0.0086109
2017/08/26 00:01:09 step 5: objective=0.008644498
2017/08/26 00:01:12 step 6: objective=0.008718524
2017/08/26 00:01:14 step 7: objective=0.008754589
2017/08/26 00:01:14 Training value function...
2017/08/26 00:01:20 step 0: mse=0.578792 step=0.100000
2017/08/26 00:01:25 step 1: mse=0.540259 step=0.100000
2017/08/26 00:01:30 step 2: mse=0.508757 step=0.100000
2017/08/26 00:01:35 step 3: mse=0.482530 step=0.100000
2017/08/26 00:01:40 step 4: mse=0.460993 step=0.100000
2017/08/26 00:01:45 step 5: mse=0.443697 step=0.100000
2017/08/26 00:01:50 step 6: mse=0.428523 step=0.100000
2017/08/26 00:01:55 step 7: mse=0.416357 step=0.100000
2017/08/26 00:01:55 Saving...
2017/08/26 00:01:55 Gathering batch of experience...
2017/08/26 00:02:06 batch 4: mean=6.054795 stddev=2.316649 entropy=1.289829 frames=34197 count=73
2017/08/26 00:02:06 Training policy...
2017/08/26 00:02:12 step 0: objective=-0.0009462492
2017/08/26 00:02:14 step 1: objective=-0.0008622922
2017/08/26 00:02:17 step 2: objective=-0.00077784376
2017/08/26 00:02:19 step 3: objective=-0.0006958306
2017/08/26 00:02:21 step 4: objective=-0.0006415004
2017/08/26 00:02:24 step 5: objective=-0.00058635237
2017/08/26 00:02:26 step 6: objective=-0.00053872407
2017/08/26 00:02:29 step 7: objective=-0.0005073713
2017/08/26 00:02:29 Training value function...
2017/08/26 00:02:34 step 0: mse=0.466752 step=0.100000
2017/08/26 00:02:39 step 1: mse=0.452823 step=0.100000
2017/08/26 00:02:44 step 2: mse=0.441524 step=0.100000
2017/08/26 00:02:49 step 3: mse=0.420000 step=0.100000
2017/08/26 00:02:54 step 4: mse=0.403489 step=0.100000
2017/08/26 00:03:00 step 5: mse=0.395473 step=0.100000
2017/08/26 00:03:05 step 6: mse=0.380595 step=0.100000
2017/08/26 00:03:10 step 7: mse=0.369293 step=0.100000
2017/08/26 00:03:10 Saving...
2017/08/26 00:03:10 Gathering batch of experience...
2017/08/26 00:03:21 batch 5: mean=6.260870 stddev=3.326016 entropy=1.283861 frames=33693 count=69
2017/08/26 00:03:21 Training policy...
2017/08/26 00:03:26 step 0: objective=0.019891683
2017/08/26 00:03:29 step 1: objective=0.019941865
2017/08/26 00:03:31 step 2: objective=0.019992078
2017/08/26 00:03:33 step 3: objective=0.020087061
2017/08/26 00:03:36 step 4: objective=0.020137457
2017/08/26 00:03:38 step 5: objective=0.020226786
2017/08/26 00:03:40 step 6: objective=0.020262983
2017/08/26 00:03:43 step 7: objective=0.020359304
2017/08/26 00:03:43 Training value function...
2017/08/26 00:03:48 step 0: mse=1.080480 step=0.100000
2017/08/26 00:03:53 step 1: mse=0.974086 step=0.100000
2017/08/26 00:03:58 step 2: mse=0.885394 step=0.100000
2017/08/26 00:04:03 step 3: mse=0.814008 step=0.100000
2017/08/26 00:04:09 step 4: mse=0.753886 step=0.100000
2017/08/26 00:04:14 step 5: mse=0.700691 step=0.100000
2017/08/26 00:04:19 step 6: mse=0.657364 step=0.100000
2017/08/26 00:04:24 step 7: mse=0.620761 step=0.100000
2017/08/26 00:04:24 Saving...
2017/08/26 00:04:24 Gathering batch of experience...
2017/08/26 00:04:35 batch 6: mean=6.171429 stddev=2.912885 entropy=1.286810 frames=33744 count=70
2017/08/26 00:04:35 Training policy...
2017/08/26 00:04:40 step 0: objective=0.0035195006
2017/08/26 00:04:43 step 1: objective=0.0036688994
2017/08/26 00:04:45 step 2: objective=0.0038163103
2017/08/26 00:04:48 step 3: objective=0.003876138
2017/08/26 00:04:50 step 4: objective=0.003947448
2017/08/26 00:04:52 step 5: objective=0.0040452285
2017/08/26 00:04:55 step 6: objective=0.004136743
2017/08/26 00:04:57 step 7: objective=0.004173657
2017/08/26 00:04:57 Training value function...
2017/08/26 00:05:03 step 0: mse=0.549924 step=0.100000
2017/08/26 00:05:08 step 1: mse=0.519973 step=0.100000
2017/08/26 00:05:13 step 2: mse=0.495687 step=0.100000
2017/08/26 00:05:18 step 3: mse=0.475861 step=0.100000
2017/08/26 00:05:23 step 4: mse=0.462800 step=0.100000
2017/08/26 00:05:28 step 5: mse=0.446057 step=0.100000
2017/08/26 00:05:33 step 6: mse=0.434795 step=0.100000
2017/08/26 00:05:38 step 7: mse=0.427858 step=0.100000
2017/08/26 00:05:38 Saving...
2017/08/26 00:05:38 Gathering batch of experience...
2017/08/26 00:05:49 batch 7: mean=6.112676 stddev=3.278394 entropy=1.285809 frames=33444 count=71
2017/08/26 00:05:49 Training policy...
2017/08/26 00:05:54 step 0: objective=-0.0013672878
2017/08/26 00:05:57 step 1: objective=-0.0012518778
2017/08/26 00:05:59 step 2: objective=-0.001136651
2017/08/26 00:06:01 step 3: objective=-0.0010248409
2017/08/26 00:06:04 step 4: objective=-0.0009584444
2017/08/26 00:06:06 step 5: objective=-0.0008816752
2017/08/26 00:06:09 step 6: objective=-0.0008471455
2017/08/26 00:06:11 step 7: objective=-0.00081811514
2017/08/26 00:06:11 Training value function...
2017/08/26 00:06:16 step 0: mse=1.078208 step=0.100000
2017/08/26 00:06:22 step 1: mse=0.975177 step=0.100000
2017/08/26 00:06:27 step 2: mse=0.887116 step=0.100000
2017/08/26 00:06:32 step 3: mse=0.815299 step=0.100000
2017/08/26 00:06:37 step 4: mse=0.758628 step=0.100000
2017/08/26 00:06:42 step 5: mse=0.706685 step=0.100000
2017/08/26 00:06:47 step 6: mse=0.664381 step=0.100000
2017/08/26 00:06:52 step 7: mse=0.629940 step=0.100000
2017/08/26 00:06:52 Saving...
2017/08/26 00:06:52 Gathering batch of experience...
2017/08/26 00:07:03 batch 8: mean=6.676923 stddev=3.028621 entropy=1.281592 frames=32943 count=65
2017/08/26 00:07:03 Training policy...
2017/08/26 00:07:08 step 0: objective=-0.00046043258
2017/08/26 00:07:10 step 1: objective=-0.00016332275
2017/08/26 00:07:13 step 2: objective=8.068871e-06
2017/08/26 00:07:15 step 3: objective=6.549676e-05
2017/08/26 00:07:17 step 4: objective=0.00015724936
2017/08/26 00:07:20 step 5: objective=0.00030924767
2017/08/26 00:07:22 step 6: objective=0.00035980614
2017/08/26 00:07:24 step 7: objective=0.0004185765
2017/08/26 00:07:24 Training value function...
2017/08/26 00:07:30 step 0: mse=0.967484 step=0.100000
2017/08/26 00:07:35 step 1: mse=0.904276 step=0.100000
2017/08/26 00:07:40 step 2: mse=0.852729 step=0.100000
2017/08/26 00:07:45 step 3: mse=0.809557 step=0.100000
2017/08/26 00:07:50 step 4: mse=0.766077 step=0.100000
2017/08/26 00:07:55 step 5: mse=0.729539 step=0.100000
2017/08/26 00:08:00 step 6: mse=0.702989 step=0.100000
2017/08/26 00:08:05 step 7: mse=0.674388 step=0.100000
2017/08/26 00:08:05 Saving...
2017/08/26 00:08:05 Gathering batch of experience...
2017/08/26 00:08:17 batch 9: mean=6.571429 stddev=3.433330 entropy=1.283685 frames=34393 count=70
2017/08/26 00:08:17 Training policy...
2017/08/26 00:08:22 step 0: objective=0.0008915962
2017/08/26 00:08:25 step 1: objective=0.0012543119
2017/08/26 00:08:27 step 2: objective=0.0015593593
2017/08/26 00:08:30 step 3: objective=0.0017244216
2017/08/26 00:08:32 step 4: objective=0.0018482468
2017/08/26 00:08:35 step 5: objective=0.0019272146
2017/08/26 00:08:37 step 6: objective=0.0020373021
2017/08/26 00:08:39 step 7: objective=0.0020878625
2017/08/26 00:08:39 Training value function...
2017/08/26 00:08:45 step 0: mse=1.341995 step=0.100000
2017/08/26 00:08:50 step 1: mse=1.211655 step=0.100000
2017/08/26 00:08:56 step 2: mse=1.102989 step=0.100000
2017/08/26 00:09:01 step 3: mse=1.015871 step=0.100000
2017/08/26 00:09:06 step 4: mse=0.941994 step=0.100000
2017/08/26 00:09:11 step 5: mse=0.881646 step=0.100000
2017/08/26 00:09:17 step 6: mse=0.821016 step=0.100000
2017/08/26 00:09:22 step 7: mse=0.778994 step=0.100000
2017/08/26 00:09:22 Saving...
2017/08/26 00:09:22 Gathering batch of experience...
2017/08/26 00:09:33 batch 10: mean=6.084507 stddev=3.409789 entropy=1.282437 frames=33465 count=71
2017/08/26 00:09:33 Training policy...
2017/08/26 00:09:39 step 0: objective=0.007924386
2017/08/26 00:09:41 step 1: objective=0.007975293
2017/08/26 00:09:43 step 2: objective=0.008026189
2017/08/26 00:09:46 step 3: objective=0.008077067
2017/08/26 00:09:48 step 4: objective=0.0081278235
2017/08/26 00:09:51 step 5: objective=0.008175166
2017/08/26 00:09:53 step 6: objective=0.008279838
2017/08/26 00:09:56 step 7: objective=0.008340034
2017/08/26 00:09:56 Training value function...
2017/08/26 00:10:01 step 0: mse=0.842391 step=0.100000
2017/08/26 00:10:07 step 1: mse=0.788256 step=0.100000
2017/08/26 00:10:12 step 2: mse=0.744330 step=0.100000
2017/08/26 00:10:17 step 3: mse=0.698015 step=0.100000
2017/08/26 00:10:22 step 4: mse=0.659915 step=0.100000
2017/08/26 00:10:27 step 5: mse=0.626886 step=0.100000
2017/08/26 00:10:32 step 6: mse=0.597416 step=0.100000
2017/08/26 00:10:37 step 7: mse=0.573433 step=0.100000
2017/08/26 00:10:37 Saving...
2017/08/26 00:10:37 Gathering batch of experience...
2017/08/26 00:10:49 batch 11: mean=7.000000 stddev=2.763397 entropy=1.283414 frames=33675 count=66
2017/08/26 00:10:49 Training policy...
2017/08/26 00:10:54 step 0: objective=0.0070634573
2017/08/26 00:10:57 step 1: objective=0.0071489457
2017/08/26 00:10:59 step 2: objective=0.00723421
2017/08/26 00:11:02 step 3: objective=0.007319245
2017/08/26 00:11:04 step 4: objective=0.007403965
2017/08/26 00:11:06 step 5: objective=0.007483887
2017/08/26 00:11:09 step 6: objective=0.0075383387
2017/08/26 00:11:11 step 7: objective=0.007577038
2017/08/26 00:11:11 Training value function...
2017/08/26 00:11:17 step 0: mse=0.720294 step=0.100000
2017/08/26 00:11:22 step 1: mse=0.683080 step=0.100000
2017/08/26 00:11:28 step 2: mse=0.644056 step=0.100000
2017/08/26 00:11:33 step 3: mse=0.618216 step=0.100000
2017/08/26 00:11:38 step 4: mse=0.590009 step=0.100000
2017/08/26 00:11:43 step 5: mse=0.568879 step=0.100000
2017/08/26 00:11:48 step 6: mse=0.550866 step=0.100000
2017/08/26 00:11:53 step 7: mse=0.534026 step=0.100000
2017/08/26 00:11:53 Saving...
2017/08/26 00:11:54 Gathering batch of experience...
2017/08/26 00:12:05 batch 12: mean=6.422535 stddev=3.283171 entropy=1.283266 frames=34009 count=71
2017/08/26 00:12:05 Training policy...
2017/08/26 00:12:10 step 0: objective=-0.009353848
2017/08/26 00:12:13 step 1: objective=-0.009277542
2017/08/26 00:12:15 step 2: objective=-0.009202138
2017/08/26 00:12:18 step 3: objective=-0.009149885
2017/08/26 00:12:20 step 4: objective=-0.00909779
2017/08/26 00:12:23 step 5: objective=-0.009045809
2017/08/26 00:12:25 step 6: objective=-0.008996862
2017/08/26 00:12:28 step 7: objective=-0.008942808
2017/08/26 00:12:28 Training value function...
2017/08/26 00:12:33 step 0: mse=0.902998 step=0.100000
2017/08/26 00:12:39 step 1: mse=0.843766 step=0.100000
2017/08/26 00:12:44 step 2: mse=0.795250 step=0.100000
2017/08/26 00:12:50 step 3: mse=0.756532 step=0.100000
2017/08/26 00:12:55 step 4: mse=0.725506 step=0.100000
2017/08/26 00:13:01 step 5: mse=0.697163 step=0.100000
2017/08/26 00:13:06 step 6: mse=0.674003 step=0.100000
2017/08/26 00:13:12 step 7: mse=0.632836 step=0.100000
2017/08/26 00:13:12 Saving...
2017/08/26 00:13:12 Gathering batch of experience...
2017/08/26 00:13:23 batch 13: mean=6.521739 stddev=3.241974 entropy=1.284468 frames=33848 count=69
2017/08/26 00:13:23 Training policy...
2017/08/26 00:13:29 step 0: objective=0.0024928113
2017/08/26 00:13:31 step 1: objective=0.00262022
2017/08/26 00:13:34 step 2: objective=0.0027492298
2017/08/26 00:13:36 step 3: objective=0.0028798361
2017/08/26 00:13:39 step 4: objective=0.0029817494
2017/08/26 00:13:41 step 5: objective=0.0030638578
2017/08/26 00:13:44 step 6: objective=0.0031111727
2017/08/26 00:13:46 step 7: objective=0.0031514
2017/08/26 00:13:46 Training value function...
2017/08/26 00:13:52 step 0: mse=0.713263 step=0.100000
2017/08/26 00:13:57 step 1: mse=0.670080 step=0.100000
2017/08/26 00:14:02 step 2: mse=0.639609 step=0.100000
2017/08/26 00:14:08 step 3: mse=0.609123 step=0.100000
2017/08/26 00:14:13 step 4: mse=0.588261 step=0.100000
2017/08/26 00:14:18 step 5: mse=0.564492 step=0.100000
2017/08/26 00:14:23 step 6: mse=0.543564 step=0.100000
2017/08/26 00:14:28 step 7: mse=0.520311 step=0.100000
2017/08/26 00:14:28 Saving...
2017/08/26 00:14:29 Gathering batch of experience...
2017/08/26 00:14:40 batch 14: mean=6.925373 stddev=3.224502 entropy=1.280722 frames=34415 count=67
2017/08/26 00:14:40 Training policy...
2017/08/26 00:14:46 step 0: objective=0.020043137
2017/08/26 00:14:48 step 1: objective=0.020175265
2017/08/26 00:14:51 step 2: objective=0.020308716
2017/08/26 00:14:53 step 3: objective=0.020443324
2017/08/26 00:14:56 step 4: objective=0.020555142
2017/08/26 00:14:58 step 5: objective=0.020702375
2017/08/26 00:15:01 step 6: objective=0.020791624
2017/08/26 00:15:03 step 7: objective=0.020843552
2017/08/26 00:15:03 Training value function...
2017/08/26 00:15:09 step 0: mse=0.659732 step=0.100000
2017/08/26 00:15:15 step 1: mse=0.623462 step=0.100000
2017/08/26 00:15:20 step 2: mse=0.591524 step=0.100000
2017/08/26 00:15:25 step 3: mse=0.566754 step=0.100000
2017/08/26 00:15:31 step 4: mse=0.543560 step=0.100000
2017/08/26 00:15:36 step 5: mse=0.520442 step=0.100000
2017/08/26 00:15:42 step 6: mse=0.503506 step=0.100000
2017/08/26 00:15:47 step 7: mse=0.490731 step=0.100000
2017/08/26 00:15:47 Saving...
2017/08/26 00:15:47 Gathering batch of experience...
2017/08/26 00:15:59 batch 15: mean=6.449275 stddev=3.398790 entropy=1.281334 frames=33941 count=69
2017/08/26 00:15:59 Training policy...
2017/08/26 00:16:04 step 0: objective=-0.0034321786
2017/08/26 00:16:07 step 1: objective=-0.0030353747
2017/08/26 00:16:09 step 2: objective=-0.002912116
2017/08/26 00:16:12 step 3: objective=-0.0027934012
2017/08/26 00:16:14 step 4: objective=-0.0027168612
2017/08/26 00:16:17 step 5: objective=-0.0026649632
2017/08/26 00:16:20 step 6: objective=-0.002620607
2017/08/26 00:16:22 step 7: objective=-0.0025957949
2017/08/26 00:16:22 Training value function...
2017/08/26 00:16:28 step 0: mse=1.145536 step=0.100000
2017/08/26 00:16:33 step 1: mse=1.035394 step=0.100000
2017/08/26 00:16:39 step 2: mse=0.946163 step=0.100000
2017/08/26 00:16:44 step 3: mse=0.873106 step=0.100000
2017/08/26 00:16:49 step 4: mse=0.809275 step=0.100000
2017/08/26 00:16:55 step 5: mse=0.757426 step=0.100000
2017/08/26 00:17:00 step 6: mse=0.713503 step=0.100000
2017/08/26 00:17:05 step 7: mse=0.671032 step=0.100000
2017/08/26 00:17:05 Saving...
2017/08/26 00:17:05 Gathering batch of experience...
2017/08/26 00:17:17 batch 16: mean=6.761194 stddev=2.823619 entropy=1.281068 frames=33790 count=67
2017/08/26 00:17:17 Training policy...
2017/08/26 00:17:22 step 0: objective=-0.00020072951
2017/08/26 00:17:25 step 1: objective=-9.7015e-05
2017/08/26 00:17:27 step 2: objective=5.400069e-06
2017/08/26 00:17:30 step 3: objective=0.000106524516
2017/08/26 00:17:32 step 4: objective=0.00019238626
2017/08/26 00:17:35 step 5: objective=0.0002491408
2017/08/26 00:17:37 step 6: objective=0.00036010108
2017/08/26 00:17:40 step 7: objective=0.0004244457
2017/08/26 00:17:40 Training value function...
2017/08/26 00:17:46 step 0: mse=0.619317 step=0.100000
2017/08/26 00:17:51 step 1: mse=0.586846 step=0.100000
2017/08/26 00:17:56 step 2: mse=0.560329 step=0.100000
2017/08/26 00:18:02 step 3: mse=0.538057 step=0.100000
2017/08/26 00:18:07 step 4: mse=0.518865 step=0.100000
2017/08/26 00:18:12 step 5: mse=0.497942 step=0.100000
2017/08/26 00:18:18 step 6: mse=0.483819 step=0.100000
2017/08/26 00:18:23 step 7: mse=0.468871 step=0.100000
2017/08/26 00:18:23 Saving...
2017/08/26 00:18:23 Gathering batch of experience...
2017/08/26 00:18:34 batch 17: mean=6.761194 stddev=3.264872 entropy=1.277485 frames=33945 count=67
2017/08/26 00:18:34 Training policy...
2017/08/26 00:18:40 step 0: objective=-0.0042547258
2017/08/26 00:18:43 step 1: objective=-0.0041643493
2017/08/26 00:18:45 step 2: objective=-0.004072493
2017/08/26 00:18:48 step 3: objective=-0.0039792787
2017/08/26 00:18:50 step 4: objective=-0.003914648
2017/08/26 00:18:53 step 5: objective=-0.0037794777
2017/08/26 00:18:55 step 6: objective=-0.0037304752
2017/08/26 00:18:58 step 7: objective=-0.0035428687
2017/08/26 00:18:58 Training value function...
2017/08/26 00:19:04 step 0: mse=0.994335 step=0.100000
2017/08/26 00:19:09 step 1: mse=0.921859 step=0.100000
2017/08/26 00:19:15 step 2: mse=0.862692 step=0.100000
2017/08/26 00:19:20 step 3: mse=0.813893 step=0.100000
2017/08/26 00:19:26 step 4: mse=0.764816 step=0.100000
2017/08/26 00:19:31 step 5: mse=0.726503 step=0.100000
2017/08/26 00:19:36 step 6: mse=0.689843 step=0.100000
2017/08/26 00:19:42 step 7: mse=0.665877 step=0.100000
2017/08/26 00:19:42 Saving...
2017/08/26 00:19:42 Gathering batch of experience...
2017/08/26 00:19:53 batch 18: mean=6.647887 stddev=3.845973 entropy=1.279648 frames=34506 count=71
2017/08/26 00:19:53 Training policy...
2017/08/26 00:19:59 step 0: objective=0.02482908
2017/08/26 00:20:02 step 1: objective=0.025054539
2017/08/26 00:20:04 step 2: objective=0.025275927
2017/08/26 00:20:07 step 3: objective=0.025395997
2017/08/26 00:20:10 step 4: objective=0.025491746
2017/08/26 00:20:13 step 5: objective=0.025514802
2017/08/26 00:20:15 step 6: objective=0.025601389
2017/08/26 00:20:18 step 7: objective=0.025666326
2017/08/26 00:20:18 Training value function...
2017/08/26 00:20:24 step 0: mse=1.669375 step=0.100000
2017/08/26 00:20:29 step 1: mse=1.492419 step=0.100000
2017/08/26 00:20:35 step 2: mse=1.347860 step=0.100000
2017/08/26 00:20:41 step 3: mse=1.229401 step=0.100000
2017/08/26 00:20:46 step 4: mse=1.132642 step=0.100000
2017/08/26 00:20:52 step 5: mse=1.053439 step=0.100000
2017/08/26 00:20:57 step 6: mse=0.988529 step=0.100000
2017/08/26 00:21:03 step 7: mse=0.933942 step=0.100000
2017/08/26 00:21:03 Saving...
2017/08/26 00:21:03 Gathering batch of experience...
2017/08/26 00:21:14 batch 19: mean=6.281690 stddev=2.433239 entropy=1.280125 frames=34036 count=71
2017/08/26 00:21:14 Training policy...
2017/08/26 00:21:20 step 0: objective=-0.01546347
2017/08/26 00:21:22 step 1: objective=-0.015370753
2017/08/26 00:21:25 step 2: objective=-0.015278144
2017/08/26 00:21:28 step 3: objective=-0.015185694
2017/08/26 00:21:30 step 4: objective=-0.01509356
2017/08/26 00:21:33 step 5: objective=-0.015024863
2017/08/26 00:21:36 step 6: objective=-0.014972625
2017/08/26 00:21:38 step 7: objective=-0.0149023235
2017/08/26 00:21:38 Training value function...
2017/08/26 00:21:44 step 0: mse=0.541521 step=0.100000
2017/08/26 00:21:49 step 1: mse=0.510967 step=0.100000
2017/08/26 00:21:55 step 2: mse=0.485488 step=0.100000
2017/08/26 00:22:00 step 3: mse=0.464684 step=0.100000
2017/08/26 00:22:06 step 4: mse=0.447801 step=0.100000
2017/08/26 00:22:12 step 5: mse=0.432572 step=0.100000
2017/08/26 00:22:17 step 6: mse=0.420359 step=0.100000
2017/08/26 00:22:22 step 7: mse=0.409313 step=0.100000
2017/08/26 00:22:22 Saving...
2017/08/26 00:22:23 Gathering batch of experience...
2017/08/26 00:22:33 batch 20: mean=6.071429 stddev=2.855178 entropy=1.280777 frames=33301 count=70
2017/08/26 00:22:33 Training policy...
2017/08/26 00:22:39 step 0: objective=-0.0036798322
2017/08/26 00:22:42 step 1: objective=-0.003612528
2017/08/26 00:22:44 step 2: objective=-0.0035449937
2017/08/26 00:22:47 step 3: objective=-0.003477233
2017/08/26 00:22:49 step 4: objective=-0.0034299819
2017/08/26 00:22:52 step 5: objective=-0.0033470981
2017/08/26 00:22:55 step 6: objective=-0.0033033164
2017/08/26 00:22:57 step 7: objective=-0.0032143155
2017/08/26 00:22:57 Training value function...
2017/08/26 00:23:03 step 0: mse=0.680662 step=0.100000
2017/08/26 00:23:09 step 1: mse=0.630092 step=0.100000
2017/08/26 00:23:14 step 2: mse=0.589123 step=0.100000
2017/08/26 00:23:20 step 3: mse=0.555776 step=0.100000
2017/08/26 00:23:25 step 4: mse=0.524672 step=0.100000
2017/08/26 00:23:30 step 5: mse=0.501832 step=0.100000
2017/08/26 00:23:36 step 6: mse=0.478948 step=0.100000
2017/08/26 00:23:41 step 7: mse=0.454895 step=0.100000
2017/08/26 00:23:41 Saving...
2017/08/26 00:23:41 Gathering batch of experience...
2017/08/26 00:23:52 batch 21: mean=6.128571 stddev=3.046879 entropy=1.278549 frames=33862 count=70
2017/08/26 00:23:52 Training policy...
2017/08/26 00:23:58 step 0: objective=-0.0016454369
2017/08/26 00:24:01 step 1: objective=-0.0015954591
2017/08/26 00:24:03 step 2: objective=-0.0015458469
2017/08/26 00:24:06 step 3: objective=-0.0014966261
2017/08/26 00:24:08 step 4: objective=-0.0014477564
2017/08/26 00:24:11 step 5: objective=-0.0013993974
2017/08/26 00:24:14 step 6: objective=-0.0013572585
2017/08/26 00:24:16 step 7: objective=-0.0012991065
2017/08/26 00:24:16 Training value function...
2017/08/26 00:24:22 step 0: mse=0.653750 step=0.100000
2017/08/26 00:24:28 step 1: mse=0.628128 step=0.100000
2017/08/26 00:24:33 step 2: mse=0.607197 step=0.100000
2017/08/26 00:24:39 step 3: mse=0.590013 step=0.100000
2017/08/26 00:24:44 step 4: mse=0.567617 step=0.100000
2017/08/26 00:24:50 step 5: mse=0.554363 step=0.100000
2017/08/26 00:24:55 step 6: mse=0.536735 step=0.100000
2017/08/26 00:25:01 step 7: mse=0.516971 step=0.100000
2017/08/26 00:25:01 Saving...
2017/08/26 00:25:01 Gathering batch of experience...
2017/08/26 00:25:12 batch 22: mean=6.257143 stddev=3.133623 entropy=1.279995 frames=33825 count=70
2017/08/26 00:25:12 Training policy...
2017/08/26 00:25:18 step 0: objective=0.0041729794
2017/08/26 00:25:20 step 1: objective=0.004262081
2017/08/26 00:25:23 step 2: objective=0.004351768
2017/08/26 00:25:26 step 3: objective=0.0044420823
2017/08/26 00:25:28 step 4: objective=0.0045276396
2017/08/26 00:25:31 step 5: objective=0.0046007507
2017/08/26 00:25:34 step 6: objective=0.0046615344
2017/08/26 00:25:36 step 7: objective=0.0047376137
2017/08/26 00:25:36 Training value function...
2017/08/26 00:25:42 step 0: mse=0.575187 step=0.100000
2017/08/26 00:25:48 step 1: mse=0.548253 step=0.100000
2017/08/26 00:25:53 step 2: mse=0.527361 step=0.100000
2017/08/26 00:25:59 step 3: mse=0.500605 step=0.100000
2017/08/26 00:26:04 step 4: mse=0.486005 step=0.100000
2017/08/26 00:26:10 step 5: mse=0.470326 step=0.100000
2017/08/26 00:26:15 step 6: mse=0.456690 step=0.100000
2017/08/26 00:26:21 step 7: mse=0.443398 step=0.100000
2017/08/26 00:26:21 Saving...
2017/08/26 00:26:21 Gathering batch of experience...
2017/08/26 00:26:32 batch 23: mean=6.154930 stddev=3.334193 entropy=1.275957 frames=34008 count=71
2017/08/26 00:26:32 Training policy...
2017/08/26 00:26:38 step 0: objective=0.005306259
2017/08/26 00:26:40 step 1: objective=0.005565485
2017/08/26 00:26:43 step 2: objective=0.005708318
2017/08/26 00:26:46 step 3: objective=0.0058701606
2017/08/26 00:26:49 step 4: objective=0.0059751486
2017/08/26 00:26:51 step 5: objective=0.006022188
2017/08/26 00:26:54 step 6: objective=0.006081022
2017/08/26 00:26:57 step 7: objective=0.006119951
2017/08/26 00:26:57 Training value function...
2017/08/26 00:27:03 step 0: mse=1.021445 step=0.100000
2017/08/26 00:27:08 step 1: mse=0.932617 step=0.100000
2017/08/26 00:27:14 step 2: mse=0.857379 step=0.100000
2017/08/26 00:27:20 step 3: mse=0.796300 step=0.100000
2017/08/26 00:27:26 step 4: mse=0.744790 step=0.100000
2017/08/26 00:27:31 step 5: mse=0.703024 step=0.100000
2017/08/26 00:27:37 step 6: mse=0.664150 step=0.100000
2017/08/26 00:27:42 step 7: mse=0.632552 step=0.100000
2017/08/26 00:27:42 Saving...
2017/08/26 00:27:42 Gathering batch of experience...
2017/08/26 00:27:54 batch 24: mean=6.291667 stddev=3.272094 entropy=1.277542 frames=34279 count=72
2017/08/26 00:27:54 Training policy...
2017/08/26 00:28:00 step 0: objective=0.0019457821
2017/08/26 00:28:03 step 1: objective=0.0021155595
2017/08/26 00:28:05 step 2: objective=0.002220103
2017/08/26 00:28:08 step 3: objective=0.0023254403
2017/08/26 00:28:11 step 4: objective=0.0024313226
2017/08/26 00:28:13 step 5: objective=0.0025224406
2017/08/26 00:28:16 step 6: objective=0.0025777612
2017/08/26 00:28:19 step 7: objective=0.002621829
2017/08/26 00:28:19 Training value function...
2017/08/26 00:28:25 step 0: mse=0.801612 step=0.100000
2017/08/26 00:28:30 step 1: mse=0.751969 step=0.100000
2017/08/26 00:28:36 step 2: mse=0.708552 step=0.100000
2017/08/26 00:28:42 step 3: mse=0.675128 step=0.100000
2017/08/26 00:28:47 step 4: mse=0.645391 step=0.100000
2017/08/26 00:28:53 step 5: mse=0.621206 step=0.100000
2017/08/26 00:28:58 step 6: mse=0.594780 step=0.100000
2017/08/26 00:29:04 step 7: mse=0.578089 step=0.100000
2017/08/26 00:29:04 Saving...
2017/08/26 00:29:04 Gathering batch of experience...
2017/08/26 00:29:15 batch 25: mean=6.676471 stddev=3.141006 entropy=1.274917 frames=33633 count=68
2017/08/26 00:29:15 Training policy...
2017/08/26 00:29:21 step 0: objective=0.007253873
2017/08/26 00:29:24 step 1: objective=0.007368543
2017/08/26 00:29:27 step 2: objective=0.0074825105
2017/08/26 00:29:29 step 3: objective=0.007572076
2017/08/26 00:29:32 step 4: objective=0.007681621
2017/08/26 00:29:34 step 5: objective=0.0077555836
2017/08/26 00:29:37 step 6: objective=0.007865826
2017/08/26 00:29:40 step 7: objective=0.007916772
2017/08/26 00:29:40 Training value function...
2017/08/26 00:29:46 step 0: mse=0.899572 step=0.100000
2017/08/26 00:29:51 step 1: mse=0.851411 step=0.100000
2017/08/26 00:29:57 step 2: mse=0.812384 step=0.100000
2017/08/26 00:30:02 step 3: mse=0.779988 step=0.100000
2017/08/26 00:30:08 step 4: mse=0.729705 step=0.100000
2017/08/26 00:30:13 step 5: mse=0.684026 step=0.100000
2017/08/26 00:30:19 step 6: mse=0.643854 step=0.100000
2017/08/26 00:30:25 step 7: mse=0.611673 step=0.100000
2017/08/26 00:30:25 Saving...
2017/08/26 00:30:25 Gathering batch of experience...
2017/08/26 00:30:36 batch 26: mean=6.623188 stddev=2.808380 entropy=1.279376 frames=34081 count=69
2017/08/26 00:30:36 Training policy...
2017/08/26 00:30:42 step 0: objective=0.012671352
2017/08/26 00:30:45 step 1: objective=0.01283889
2017/08/26 00:30:48 step 2: objective=0.013008547
2017/08/26 00:30:50 step 3: objective=0.013191885
2017/08/26 00:30:53 step 4: objective=0.013300669
2017/08/26 00:30:56 step 5: objective=0.013381399
2017/08/26 00:30:58 step 6: objective=0.013456663
2017/08/26 00:31:01 step 7: objective=0.013566611
2017/08/26 00:31:01 Training value function...
2017/08/26 00:31:07 step 0: mse=0.706890 step=0.100000
2017/08/26 00:31:13 step 1: mse=0.650760 step=0.100000
2017/08/26 00:31:19 step 2: mse=0.620358 step=0.100000
2017/08/26 00:31:25 step 3: mse=0.585505 step=0.100000
2017/08/26 00:31:30 step 4: mse=0.557152 step=0.100000
2017/08/26 00:31:36 step 5: mse=0.524248 step=0.100000
2017/08/26 00:31:42 step 6: mse=0.502152 step=0.100000
2017/08/26 00:31:47 step 7: mse=0.484167 step=0.100000
2017/08/26 00:31:47 Saving...
2017/08/26 00:31:47 Gathering batch of experience...
2017/08/26 00:31:59 batch 27: mean=7.333333 stddev=2.835561 entropy=1.274034 frames=34048 count=66
2017/08/26 00:31:59 Training policy...
2017/08/26 00:32:05 step 0: objective=0.028038971
2017/08/26 00:32:08 step 1: objective=0.028162511
2017/08/26 00:32:10 step 2: objective=0.028285133
2017/08/26 00:32:13 step 3: objective=0.02840597
2017/08/26 00:32:16 step 4: objective=0.028474905
2017/08/26 00:32:19 step 5: objective=0.028548155
2017/08/26 00:32:21 step 6: objective=0.028638411
2017/08/26 00:32:24 step 7: objective=0.02871785
2017/08/26 00:32:24 Training value function...
2017/08/26 00:32:30 step 0: mse=0.891744 step=0.100000
2017/08/26 00:32:36 step 1: mse=0.826872 step=0.100000
2017/08/26 00:32:42 step 2: mse=0.774317 step=0.100000
2017/08/26 00:32:47 step 3: mse=0.731739 step=0.100000
2017/08/26 00:32:53 step 4: mse=0.697213 step=0.100000
2017/08/26 00:32:59 step 5: mse=0.665147 step=0.100000
2017/08/26 00:33:04 step 6: mse=0.639110 step=0.100000
2017/08/26 00:33:10 step 7: mse=0.616182 step=0.100000
2017/08/26 00:33:10 Saving...
2017/08/26 00:33:10 Gathering batch of experience...
2017/08/26 00:33:21 batch 28: mean=7.136364 stddev=3.338873 entropy=1.275612 frames=34304 count=66
2017/08/26 00:33:21 Training policy...
2017/08/26 00:33:27 step 0: objective=0.0004966161
2017/08/26 00:33:30 step 1: objective=0.0007065302
2017/08/26 00:33:33 step 2: objective=0.000911807
2017/08/26 00:33:36 step 3: objective=0.0011016158
2017/08/26 00:33:38 step 4: objective=0.001229339
2017/08/26 00:33:41 step 5: objective=0.0012590695
2017/08/26 00:33:44 step 6: objective=0.0014083699
2017/08/26 00:33:47 step 7: objective=0.0014782314
2017/08/26 00:33:47 Training value function...
2017/08/26 00:33:53 step 0: mse=1.289087 step=0.100000
2017/08/26 00:33:59 step 1: mse=1.163805 step=0.100000
2017/08/26 00:34:04 step 2: mse=1.062283 step=0.100000
2017/08/26 00:34:10 step 3: mse=0.979394 step=0.100000
2017/08/26 00:34:16 step 4: mse=0.912334 step=0.100000
2017/08/26 00:34:22 step 5: mse=0.857646 step=0.100000
2017/08/26 00:34:27 step 6: mse=0.811872 step=0.100000
2017/08/26 00:34:33 step 7: mse=0.772894 step=0.100000
2017/08/26 00:34:33 Saving...
2017/08/26 00:34:33 Gathering batch of experience...
2017/08/26 00:34:44 batch 29: mean=6.441176 stddev=3.055286 entropy=1.277831 frames=33841 count=68
2017/08/26 00:34:44 Training policy...
2017/08/26 00:34:50 step 0: objective=-0.0049396865
2017/08/26 00:34:53 step 1: objective=-0.004740428
2017/08/26 00:34:56 step 2: objective=-0.004545377
2017/08/26 00:34:59 step 3: objective=-0.0044133025
2017/08/26 00:35:01 step 4: objective=-0.004325628
2017/08/26 00:35:04 step 5: objective=-0.004265746
2017/08/26 00:35:07 step 6: objective=-0.004211374
2017/08/26 00:35:09 step 7: objective=-0.004180112
2017/08/26 00:35:09 Training value function...
2017/08/26 00:35:16 step 0: mse=0.818901 step=0.100000
2017/08/26 00:35:21 step 1: mse=0.749591 step=0.100000
2017/08/26 00:35:27 step 2: mse=0.693119 step=0.100000
2017/08/26 00:35:33 step 3: mse=0.635842 step=0.100000
2017/08/26 00:35:38 step 4: mse=0.589288 step=0.100000
2017/08/26 00:35:44 step 5: mse=0.552631 step=0.100000
2017/08/26 00:35:50 step 6: mse=0.520932 step=0.100000
2017/08/26 00:35:55 step 7: mse=0.498837 step=0.100000
2017/08/26 00:35:55 Saving...
2017/08/26 00:35:55 Gathering batch of experience...
2017/08/26 00:36:07 batch 30: mean=7.058824 stddev=3.559917 entropy=1.275460 frames=35271 count=68
2017/08/26 00:36:07 Training policy...
2017/08/26 00:36:14 step 0: objective=0.014216995
2017/08/26 00:36:16 step 1: objective=0.014375318
2017/08/26 00:36:19 step 2: objective=0.014532834
2017/08/26 00:36:22 step 3: objective=0.014672489
2017/08/26 00:36:25 step 4: objective=0.014777147
2017/08/26 00:36:28 step 5: objective=0.014837797
2017/08/26 00:36:31 step 6: objective=0.014911378
2017/08/26 00:36:34 step 7: objective=0.015022217
2017/08/26 00:36:34 Training value function...
2017/08/26 00:36:40 step 0: mse=1.327082 step=0.100000
2017/08/26 00:36:46 step 1: mse=1.206141 step=0.100000
2017/08/26 00:36:52 step 2: mse=1.107224 step=0.100000
2017/08/26 00:36:58 step 3: mse=1.025702 step=0.100000
2017/08/26 00:37:04 step 4: mse=0.957053 step=0.100000
2017/08/26 00:37:10 step 5: mse=0.900209 step=0.100000
2017/08/26 00:37:16 step 6: mse=0.852462 step=0.100000
2017/08/26 00:37:22 step 7: mse=0.795546 step=0.100000
2017/08/26 00:37:22 Saving...
2017/08/26 00:37:22 Gathering batch of experience...
2017/08/26 00:37:34 batch 31: mean=6.420290 stddev=3.494948 entropy=1.274160 frames=33834 count=69
2017/08/26 00:37:34 Training policy...
2017/08/26 00:37:40 step 0: objective=-0.005324293
2017/08/26 00:37:43 step 1: objective=-0.00520821
2017/08/26 00:37:45 step 2: objective=-0.00509255
2017/08/26 00:37:48 step 3: objective=-0.0049773515
2017/08/26 00:37:51 step 4: objective=-0.004863043
2017/08/26 00:37:54 step 5: objective=-0.00474894
2017/08/26 00:37:56 step 6: objective=-0.0046821237
2017/08/26 00:37:59 step 7: objective=-0.0046540257
2017/08/26 00:37:59 Training value function...
2017/08/26 00:38:05 step 0: mse=0.840283 step=0.100000
2017/08/26 00:38:11 step 1: mse=0.768919 step=0.100000
2017/08/26 00:38:17 step 2: mse=0.710907 step=0.100000
2017/08/26 00:38:22 step 3: mse=0.663767 step=0.100000
2017/08/26 00:38:28 step 4: mse=0.625148 step=0.100000
2017/08/26 00:38:34 step 5: mse=0.591898 step=0.100000
2017/08/26 00:38:40 step 6: mse=0.565013 step=0.100000
2017/08/26 00:38:46 step 7: mse=0.541869 step=0.100000
2017/08/26 00:38:46 Saving...
2017/08/26 00:38:46 Gathering batch of experience...
2017/08/26 00:38:58 batch 32: mean=7.328358 stddev=3.413704 entropy=1.276319 frames=34882 count=67
2017/08/26 00:38:58 Training policy...
2017/08/26 00:39:04 step 0: objective=0.013384052
2017/08/26 00:39:07 step 1: objective=0.013564936
2017/08/26 00:39:10 step 2: objective=0.013745206
2017/08/26 00:39:12 step 3: objective=0.013924809
2017/08/26 00:39:15 step 4: objective=0.014081176
2017/08/26 00:39:18 step 5: objective=0.014190243
2017/08/26 00:39:21 step 6: objective=0.014291306
2017/08/26 00:39:24 step 7: objective=0.014374942
2017/08/26 00:39:24 Training value function...
2017/08/26 00:39:30 step 0: mse=0.927806 step=0.100000
2017/08/26 00:39:36 step 1: mse=0.846745 step=0.100000
2017/08/26 00:39:42 step 2: mse=0.796868 step=0.100000
2017/08/26 00:39:48 step 3: mse=0.753582 step=0.100000
2017/08/26 00:39:54 step 4: mse=0.720788 step=0.100000
2017/08/26 00:40:00 step 5: mse=0.673611 step=0.100000
2017/08/26 00:40:06 step 6: mse=0.638992 step=0.100000
2017/08/26 00:40:12 step 7: mse=0.611309 step=0.100000
2017/08/26 00:40:12 Saving...
2017/08/26 00:40:12 Gathering batch of experience...
2017/08/26 00:40:24 batch 33: mean=7.375000 stddev=3.655048 entropy=1.270473 frames=34094 count=64
2017/08/26 00:40:24 Training policy...
2017/08/26 00:40:30 step 0: objective=-0.018433206
2017/08/26 00:40:33 step 1: objective=-0.018182565
2017/08/26 00:40:36 step 2: objective=-0.017948272
2017/08/26 00:40:38 step 3: objective=-0.017846035
2017/08/26 00:40:41 step 4: objective=-0.017702006
2017/08/26 00:40:44 step 5: objective=-0.01762292
2017/08/26 00:40:47 step 6: objective=-0.017534353
2017/08/26 00:40:50 step 7: objective=-0.017421555
2017/08/26 00:40:50 Training value function...
2017/08/26 00:40:56 step 0: mse=1.432464 step=0.100000
2017/08/26 00:41:02 step 1: mse=1.279390 step=0.100000
2017/08/26 00:41:08 step 2: mse=1.155371 step=0.100000
2017/08/26 00:41:13 step 3: mse=1.054071 step=0.100000
2017/08/26 00:41:19 step 4: mse=0.970880 step=0.100000
2017/08/26 00:41:25 step 5: mse=0.898097 step=0.100000
2017/08/26 00:41:31 step 6: mse=0.835396 step=0.100000
2017/08/26 00:41:37 step 7: mse=0.785235 step=0.100000
2017/08/26 00:41:37 Saving...
2017/08/26 00:41:37 Gathering batch of experience...
2017/08/26 00:41:49 batch 34: mean=6.536232 stddev=3.005211 entropy=1.275866 frames=34229 count=69
2017/08/26 00:41:49 Training policy...
2017/08/26 00:41:55 step 0: objective=-0.0022675786
2017/08/26 00:41:58 step 1: objective=-0.002062008
2017/08/26 00:42:01 step 2: objective=-0.0018545126
2017/08/26 00:42:03 step 3: objective=-0.0016843093
2017/08/26 00:42:06 step 4: objective=-0.001546636
2017/08/26 00:42:09 step 5: objective=-0.0014262043
2017/08/26 00:42:12 step 6: objective=-0.0013392345
2017/08/26 00:42:15 step 7: objective=-0.0012582638
2017/08/26 00:42:15 Training value function...
2017/08/26 00:42:21 step 0: mse=1.199722 step=0.100000
2017/08/26 00:42:27 step 1: mse=1.089175 step=0.100000
2017/08/26 00:42:33 step 2: mse=0.992137 step=0.100000
2017/08/26 00:42:39 step 3: mse=0.912745 step=0.100000
2017/08/26 00:42:45 step 4: mse=0.847992 step=0.100000
2017/08/26 00:42:51 step 5: mse=0.798139 step=0.100000
2017/08/26 00:42:57 step 6: mse=0.749999 step=0.100000
2017/08/26 00:43:03 step 7: mse=0.710905 step=0.100000
2017/08/26 00:43:03 Saving...
2017/08/26 00:43:03 Gathering batch of experience...
2017/08/26 00:43:14 batch 35: mean=6.863636 stddev=3.437257 entropy=1.273441 frames=34016 count=66
2017/08/26 00:43:14 Training policy...
2017/08/26 00:43:21 step 0: objective=-0.010422718
2017/08/26 00:43:24 step 1: objective=-0.010246098
2017/08/26 00:43:26 step 2: objective=-0.010069853
2017/08/26 00:43:29 step 3: objective=-0.009901223
2017/08/26 00:43:32 step 4: objective=-0.009730647
2017/08/26 00:43:35 step 5: objective=-0.009557805
2017/08/26 00:43:38 step 6: objective=-0.009439216
2017/08/26 00:43:41 step 7: objective=-0.009353809
2017/08/26 00:43:41 Training value function...
2017/08/26 00:43:47 step 0: mse=1.096172 step=0.100000
2017/08/26 00:43:53 step 1: mse=1.016562 step=0.100000
2017/08/26 00:43:59 step 2: mse=0.951244 step=0.100000
2017/08/26 00:44:05 step 3: mse=0.898206 step=0.100000
2017/08/26 00:44:11 step 4: mse=0.854552 step=0.100000
2017/08/26 00:44:17 step 5: mse=0.809653 step=0.100000
2017/08/26 00:44:23 step 6: mse=0.779071 step=0.100000
2017/08/26 00:44:29 step 7: mse=0.746551 step=0.100000
2017/08/26 00:44:29 Saving...
2017/08/26 00:44:29 Gathering batch of experience...
2017/08/26 00:44:40 batch 36: mean=6.314286 stddev=3.160212 entropy=1.274954 frames=34155 count=70
2017/08/26 00:44:40 Training policy...
2017/08/26 00:44:46 step 0: objective=-0.020505654
2017/08/26 00:44:49 step 1: objective=-0.020382008
2017/08/26 00:44:52 step 2: objective=-0.020258732
2017/08/26 00:44:55 step 3: objective=-0.020135757
2017/08/26 00:44:58 step 4: objective=-0.020034758
2017/08/26 00:45:01 step 5: objective=-0.01992284
2017/08/26 00:45:04 step 6: objective=-0.01973102
2017/08/26 00:45:07 step 7: objective=-0.019658415
2017/08/26 00:45:07 Training value function...
2017/08/26 00:45:13 step 0: mse=1.168957 step=0.100000
2017/08/26 00:45:19 step 1: mse=1.034890 step=0.100000
2017/08/26 00:45:25 step 2: mse=0.925875 step=0.100000
2017/08/26 00:45:31 step 3: mse=0.837500 step=0.100000
2017/08/26 00:45:37 step 4: mse=0.765824 step=0.100000
2017/08/26 00:45:43 step 5: mse=0.704842 step=0.100000
2017/08/26 00:45:49 step 6: mse=0.655328 step=0.100000
2017/08/26 00:45:55 step 7: mse=0.613985 step=0.100000
2017/08/26 00:45:55 Saving...
2017/08/26 00:45:55 Gathering batch of experience...
2017/08/26 00:46:06 batch 37: mean=7.166667 stddev=3.254756 entropy=1.271507 frames=34425 count=66
2017/08/26 00:46:06 Training policy...
2017/08/26 00:46:13 step 0: objective=-0.00072757306
2017/08/26 00:46:16 step 1: objective=-0.00055284443
2017/08/26 00:46:18 step 2: objective=-0.00037655406
2017/08/26 00:46:21 step 3: objective=-0.0002140768
2017/08/26 00:46:24 step 4: objective=-8.903667e-05
2017/08/26 00:46:27 step 5: objective=8.146958e-06
2017/08/26 00:46:30 step 6: objective=9.724839e-05
2017/08/26 00:46:33 step 7: objective=0.00027575606
2017/08/26 00:46:33 Training value function...
2017/08/26 00:46:39 step 0: mse=1.056645 step=0.100000
2017/08/26 00:46:46 step 1: mse=0.985899 step=0.100000
2017/08/26 00:46:52 step 2: mse=0.928584 step=0.100000
2017/08/26 00:46:58 step 3: mse=0.870923 step=0.100000
2017/08/26 00:47:04 step 4: mse=0.825677 step=0.100000
2017/08/26 00:47:10 step 5: mse=0.785201 step=0.100000
2017/08/26 00:47:16 step 6: mse=0.752905 step=0.100000
2017/08/26 00:47:22 step 7: mse=0.730039 step=0.100000
2017/08/26 00:47:22 Saving...
2017/08/26 00:47:22 Gathering batch of experience...
2017/08/26 00:47:34 batch 38: mean=6.328571 stddev=3.138341 entropy=1.274086 frames=33920 count=70
2017/08/26 00:47:34 Training policy...
2017/08/26 00:47:40 step 0: objective=-0.0036608991
2017/08/26 00:47:43 step 1: objective=-0.0034435503
2017/08/26 00:47:46 step 2: objective=-0.0032304241
2017/08/26 00:47:49 step 3: objective=-0.0031497541
2017/08/26 00:47:51 step 4: objective=-0.0030734043
2017/08/26 00:47:54 step 5: objective=-0.0030088953
2017/08/26 00:47:57 step 6: objective=-0.002902969
2017/08/26 00:48:00 step 7: objective=-0.002869342
2017/08/26 00:48:00 Training value function...
2017/08/26 00:48:06 step 0: mse=1.066898 step=0.100000
2017/08/26 00:48:12 step 1: mse=0.970036 step=0.100000
2017/08/26 00:48:18 step 2: mse=0.891298 step=0.100000
2017/08/26 00:48:24 step 3: mse=0.827000 step=0.100000
2017/08/26 00:48:30 step 4: mse=0.774145 step=0.100000
2017/08/26 00:48:36 step 5: mse=0.730922 step=0.100000
2017/08/26 00:48:42 step 6: mse=0.695185 step=0.100000
2017/08/26 00:48:48 step 7: mse=0.658201 step=0.100000
2017/08/26 00:48:48 Saving...
2017/08/26 00:48:48 Gathering batch of experience...
2017/08/26 00:48:59 batch 39: mean=6.485294 stddev=2.714301 entropy=1.279120 frames=34248 count=68
2017/08/26 00:48:59 Training policy...
2017/08/26 00:49:06 step 0: objective=-0.008350918
2017/08/26 00:49:09 step 1: objective=-0.008168288
2017/08/26 00:49:12 step 2: objective=-0.007987124
2017/08/26 00:49:14 step 3: objective=-0.007827874
2017/08/26 00:49:17 step 4: objective=-0.007726372
2017/08/26 00:49:20 step 5: objective=-0.007636632
2017/08/26 00:49:23 step 6: objective=-0.00738824
2017/08/26 00:49:26 step 7: objective=-0.007350718
2017/08/26 00:49:26 Training value function...
2017/08/26 00:49:33 step 0: mse=1.307105 step=0.100000
2017/08/26 00:49:39 step 1: mse=1.151332 step=0.100000
2017/08/26 00:49:45 step 2: mse=1.024709 step=0.100000
2017/08/26 00:49:51 step 3: mse=0.917691 step=0.100000
2017/08/26 00:49:57 step 4: mse=0.831267 step=0.100000
2017/08/26 00:50:03 step 5: mse=0.756609 step=0.100000
2017/08/26 00:50:09 step 6: mse=0.702559 step=0.100000
2017/08/26 00:50:15 step 7: mse=0.658819 step=0.100000
2017/08/26 00:50:15 Saving...
2017/08/26 00:50:16 Gathering batch of experience...
2017/08/26 00:50:27 batch 40: mean=6.867647 stddev=3.338300 entropy=1.274857 frames=34176 count=68
2017/08/26 00:50:27 Training policy...
2017/08/26 00:50:33 step 0: objective=0.016488576
2017/08/26 00:50:37 step 1: objective=0.016704703
2017/08/26 00:50:40 step 2: objective=0.016924093
2017/08/26 00:50:42 step 3: objective=0.01712412
2017/08/26 00:50:45 step 4: objective=0.017338578
2017/08/26 00:50:48 step 5: objective=0.01740415
2017/08/26 00:50:51 step 6: objective=0.017577294
2017/08/26 00:50:54 step 7: objective=0.017694077
2017/08/26 00:50:54 Training value function...
2017/08/26 00:51:01 step 0: mse=1.370637 step=0.100000
2017/08/26 00:51:07 step 1: mse=1.213256 step=0.100000
2017/08/26 00:51:13 step 2: mse=1.108934 step=0.100000
2017/08/26 00:51:19 step 3: mse=1.024421 step=0.100000
2017/08/26 00:51:25 step 4: mse=0.955498 step=0.100000
2017/08/26 00:51:31 step 5: mse=0.897513 step=0.100000
2017/08/26 00:51:37 step 6: mse=0.849991 step=0.100000
2017/08/26 00:51:43 step 7: mse=0.781536 step=0.100000
2017/08/26 00:51:43 Saving...
2017/08/26 00:51:43 Gathering batch of experience...
2017/08/26 00:51:55 batch 41: mean=7.030303 stddev=3.334710 entropy=1.275626 frames=34334 count=66
2017/08/26 00:51:55 Training policy...
2017/08/26 00:52:02 step 0: objective=0.004042913
2017/08/26 00:52:04 step 1: objective=0.004200896
2017/08/26 00:52:08 step 2: objective=0.0043595564
2017/08/26 00:52:10 step 3: objective=0.004591429
2017/08/26 00:52:13 step 4: objective=0.0047291974
2017/08/26 00:52:16 step 5: objective=0.0048707873
2017/08/26 00:52:19 step 6: objective=0.0049727247
2017/08/26 00:52:22 step 7: objective=0.0050668437
2017/08/26 00:52:22 Training value function...
2017/08/26 00:52:29 step 0: mse=1.153417 step=0.100000
2017/08/26 00:52:35 step 1: mse=1.049433 step=0.100000
2017/08/26 00:52:41 step 2: mse=0.964544 step=0.100000
2017/08/26 00:52:48 step 3: mse=0.910115 step=0.100000
2017/08/26 00:52:54 step 4: mse=0.865230 step=0.100000
2017/08/26 00:53:00 step 5: mse=0.811637 step=0.100000
2017/08/26 00:53:06 step 6: mse=0.763999 step=0.100000
2017/08/26 00:53:12 step 7: mse=0.732639 step=0.100000
2017/08/26 00:53:12 Saving...
2017/08/26 00:53:12 Gathering batch of experience...
2017/08/26 00:53:24 batch 42: mean=6.927536 stddev=3.222740 entropy=1.274201 frames=34842 count=69
2017/08/26 00:53:24 Training policy...
2017/08/26 00:53:30 step 0: objective=0.005594712
2017/08/26 00:53:33 step 1: objective=0.005753237
2017/08/26 00:53:36 step 2: objective=0.0059105274
2017/08/26 00:53:39 step 3: objective=0.0059815138
2017/08/26 00:53:42 step 4: objective=0.006002012
2017/08/26 00:53:45 step 5: objective=0.0061442778
2017/08/26 00:53:48 step 6: objective=0.0062969746
2017/08/26 00:53:51 step 7: objective=0.0063280184
2017/08/26 00:53:51 Training value function...
2017/08/26 00:53:58 step 0: mse=1.119261 step=0.100000
2017/08/26 00:54:04 step 1: mse=0.997993 step=0.100000
2017/08/26 00:54:11 step 2: mse=0.899329 step=0.100000
2017/08/26 00:54:17 step 3: mse=0.818882 step=0.100000
2017/08/26 00:54:23 step 4: mse=0.752691 step=0.100000
2017/08/26 00:54:30 step 5: mse=0.697068 step=0.100000
2017/08/26 00:54:36 step 6: mse=0.646129 step=0.100000
2017/08/26 00:54:42 step 7: mse=0.607260 step=0.100000
2017/08/26 00:54:42 Saving...
2017/08/26 00:54:42 Gathering batch of experience...
2017/08/26 00:54:54 batch 43: mean=5.878378 stddev=3.092942 entropy=1.272462 frames=34066 count=74
2017/08/26 00:54:54 Training policy...
2017/08/26 00:55:00 step 0: objective=-0.018844038
2017/08/26 00:55:03 step 1: objective=-0.018753422
2017/08/26 00:55:06 step 2: objective=-0.018663798
2017/08/26 00:55:09 step 3: objective=-0.018574987
2017/08/26 00:55:12 step 4: objective=-0.018499348
2017/08/26 00:55:15 step 5: objective=-0.018409468
2017/08/26 00:55:18 step 6: objective=-0.01840334
2017/08/26 00:55:21 step 7: objective=-0.018347329
2017/08/26 00:55:21 Training value function...
2017/08/26 00:55:27 step 0: mse=1.005369 step=0.100000
2017/08/26 00:55:33 step 1: mse=0.924489 step=0.100000
2017/08/26 00:55:39 step 2: mse=0.858275 step=0.100000
2017/08/26 00:55:46 step 3: mse=0.804077 step=0.100000
2017/08/26 00:55:52 step 4: mse=0.744069 step=0.100000
2017/08/26 00:55:58 step 5: mse=0.699929 step=0.100000
2017/08/26 00:56:04 step 6: mse=0.668073 step=0.100000
2017/08/26 00:56:11 step 7: mse=0.625422 step=0.100000
2017/08/26 00:56:11 Saving...
2017/08/26 00:56:11 Gathering batch of experience...
2017/08/26 00:56:22 batch 44: mean=6.214286 stddev=2.863030 entropy=1.275159 frames=33821 count=70
2017/08/26 00:56:22 Training policy...
2017/08/26 00:56:29 step 0: objective=-0.012175474
2017/08/26 00:56:32 step 1: objective=-0.011834774
2017/08/26 00:56:35 step 2: objective=-0.011704932
2017/08/26 00:56:38 step 3: objective=-0.011613097
2017/08/26 00:56:41 step 4: objective=-0.0116382865
2017/08/26 00:56:43 step 5: objective=-0.011562459
2017/08/26 00:56:46 step 6: objective=-0.011583978
2017/08/26 00:56:49 step 7: objective=-0.011524068
2017/08/26 00:56:49 Training value function...
2017/08/26 00:56:56 step 0: mse=0.698861 step=0.100000
2017/08/26 00:57:02 step 1: mse=0.657753 step=0.100000
2017/08/26 00:57:08 step 2: mse=0.623960 step=0.100000
2017/08/26 00:57:14 step 3: mse=0.591352 step=0.100000
2017/08/26 00:57:20 step 4: mse=0.565714 step=0.100000
2017/08/26 00:57:27 step 5: mse=0.541957 step=0.100000
2017/08/26 00:57:33 step 6: mse=0.522750 step=0.100000
2017/08/26 00:57:39 step 7: mse=0.506484 step=0.100000
2017/08/26 00:57:39 Saving...
2017/08/26 00:57:39 Gathering batch of experience...
2017/08/26 00:57:50 batch 45: mean=6.295775 stddev=3.146177 entropy=1.275892 frames=34041 count=71
2017/08/26 00:57:50 Training policy...
2017/08/26 00:57:57 step 0: objective=0.0060008657
2017/08/26 00:58:00 step 1: objective=0.0060630883
2017/08/26 00:58:03 step 2: objective=0.0061253025
2017/08/26 00:58:06 step 3: objective=0.006187438
2017/08/26 00:58:09 step 4: objective=0.0063647046
2017/08/26 00:58:12 step 5: objective=0.0064671985
2017/08/26 00:58:15 step 6: objective=0.0065525817
2017/08/26 00:58:18 step 7: objective=0.0066257007
2017/08/26 00:58:18 Training value function...
2017/08/26 00:58:24 step 0: mse=0.911786 step=0.100000
2017/08/26 00:58:31 step 1: mse=0.864249 step=0.100000
2017/08/26 00:58:37 step 2: mse=0.825586 step=0.100000
2017/08/26 00:58:43 step 3: mse=0.794547 step=0.100000
2017/08/26 00:58:49 step 4: mse=0.750436 step=0.100000
2017/08/26 00:58:55 step 5: mse=0.722757 step=0.100000
2017/08/26 00:59:01 step 6: mse=0.681269 step=0.100000
2017/08/26 00:59:08 step 7: mse=0.664340 step=0.100000
2017/08/26 00:59:08 Saving...
2017/08/26 00:59:08 Gathering batch of experience...
2017/08/26 00:59:19 batch 46: mean=6.391304 stddev=2.633218 entropy=1.274420 frames=33718 count=69
2017/08/26 00:59:19 Training policy...
2017/08/26 00:59:26 step 0: objective=0.011060092
2017/08/26 00:59:28 step 1: objective=0.011132868
2017/08/26 00:59:31 step 2: objective=0.011205313
2017/08/26 00:59:34 step 3: objective=0.011277554
2017/08/26 00:59:37 step 4: objective=0.0113494685
2017/08/26 00:59:40 step 5: objective=0.01141882
2017/08/26 00:59:43 step 6: objective=0.011451213
2017/08/26 00:59:46 step 7: objective=0.011490831
2017/08/26 00:59:46 Training value function...
2017/08/26 00:59:53 step 0: mse=0.497719 step=0.100000
2017/08/26 00:59:59 step 1: mse=0.476996 step=0.100000
2017/08/26 01:00:05 step 2: mse=0.458018 step=0.100000
2017/08/26 01:00:11 step 3: mse=0.443863 step=0.100000
2017/08/26 01:00:18 step 4: mse=0.430467 step=0.100000
2017/08/26 01:00:24 step 5: mse=0.417200 step=0.100000
2017/08/26 01:00:30 step 6: mse=0.406329 step=0.100000
2017/08/26 01:00:36 step 7: mse=0.397671 step=0.100000
2017/08/26 01:00:36 Saving...
2017/08/26 01:00:36 Gathering batch of experience...
2017/08/26 01:00:48 batch 47: mean=6.863636 stddev=3.334332 entropy=1.271786 frames=34120 count=66
2017/08/26 01:00:48 Training policy...
2017/08/26 01:00:54 step 0: objective=0.004879037
2017/08/26 01:00:57 step 1: objective=0.0050416794
2017/08/26 01:01:00 step 2: objective=0.0052010533
2017/08/26 01:01:03 step 3: objective=0.005342955
2017/08/26 01:01:06 step 4: objective=0.0054613356
2017/08/26 01:01:09 step 5: objective=0.005546397
2017/08/26 01:01:12 step 6: objective=0.0055981786
2017/08/26 01:01:15 step 7: objective=0.005684729
2017/08/26 01:01:15 Training value function...
2017/08/26 01:01:22 step 0: mse=1.147730 step=0.100000
2017/08/26 01:01:28 step 1: mse=1.042544 step=0.100000
2017/08/26 01:01:35 step 2: mse=0.957350 step=0.100000
2017/08/26 01:01:41 step 3: mse=0.880069 step=0.100000
2017/08/26 01:01:47 step 4: mse=0.817400 step=0.100000
2017/08/26 01:01:53 step 5: mse=0.766664 step=0.100000
2017/08/26 01:02:00 step 6: mse=0.726672 step=0.100000
2017/08/26 01:02:06 step 7: mse=0.690974 step=0.100000
2017/08/26 01:02:06 Saving...
2017/08/26 01:02:06 Gathering batch of experience...
2017/08/26 01:02:17 batch 48: mean=6.573529 stddev=3.574074 entropy=1.270718 frames=33842 count=68
2017/08/26 01:02:17 Training policy...
2017/08/26 01:02:24 step 0: objective=-0.0062180315
2017/08/26 01:02:27 step 1: objective=-0.005926468
2017/08/26 01:02:30 step 2: objective=-0.0056617227
2017/08/26 01:02:33 step 3: objective=-0.005528945
2017/08/26 01:02:36 step 4: objective=-0.005279491
2017/08/26 01:02:39 step 5: objective=-0.0051098512
2017/08/26 01:02:42 step 6: objective=-0.004901772
2017/08/26 01:02:45 step 7: objective=-0.004833832
2017/08/26 01:02:45 Training value function...
2017/08/26 01:02:52 step 0: mse=1.939134 step=0.100000
2017/08/26 01:02:59 step 1: mse=1.736691 step=0.100000
2017/08/26 01:03:05 step 2: mse=1.567565 step=0.100000
2017/08/26 01:03:11 step 3: mse=1.431893 step=0.100000
2017/08/26 01:03:17 step 4: mse=1.316187 step=0.100000
2017/08/26 01:03:24 step 5: mse=1.214689 step=0.100000
2017/08/26 01:03:30 step 6: mse=1.131876 step=0.100000
2017/08/26 01:03:36 step 7: mse=1.066617 step=0.100000
2017/08/26 01:03:36 Saving...
2017/08/26 01:03:36 Gathering batch of experience...
2017/08/26 01:03:48 batch 49: mean=6.985294 stddev=3.905097 entropy=1.270051 frames=34332 count=68
2017/08/26 01:03:48 Training policy...
2017/08/26 01:03:55 step 0: objective=0.0050279936
2017/08/26 01:03:58 step 1: objective=0.0055502136
2017/08/26 01:04:01 step 2: objective=0.0057181274
2017/08/26 01:04:04 step 3: objective=0.0059190276
2017/08/26 01:04:07 step 4: objective=0.0059868298
2017/08/26 01:04:10 step 5: objective=0.0061112223
2017/08/26 01:04:13 step 6: objective=0.0063394196
2017/08/26 01:04:16 step 7: objective=0.006440006
2017/08/26 01:04:16 Training value function...
2017/08/26 01:04:23 step 0: mse=1.466872 step=0.100000
2017/08/26 01:04:29 step 1: mse=1.339847 step=0.100000
2017/08/26 01:04:36 step 2: mse=1.235692 step=0.100000
2017/08/26 01:04:42 step 3: mse=1.150551 step=0.100000
2017/08/26 01:04:49 step 4: mse=1.076014 step=0.100000
2017/08/26 01:04:55 step 5: mse=1.008627 step=0.100000
2017/08/26 01:05:01 step 6: mse=0.958723 step=0.100000
2017/08/26 01:05:08 step 7: mse=0.917044 step=0.100000
2017/08/26 01:05:08 Saving...
2017/08/26 01:05:08 Gathering batch of experience...
2017/08/26 01:05:19 batch 50: mean=6.449275 stddev=3.827953 entropy=1.273579 frames=33652 count=69
2017/08/26 01:05:19 Training policy...
2017/08/26 01:05:26 step 0: objective=0.0108781895
2017/08/26 01:05:29 step 1: objective=0.0111070955
2017/08/26 01:05:32 step 2: objective=0.011334404
2017/08/26 01:05:35 step 3: objective=0.011483431
2017/08/26 01:05:38 step 4: objective=0.011675735
2017/08/26 01:05:41 step 5: objective=0.011728273
2017/08/26 01:05:44 step 6: objective=0.011907051
2017/08/26 01:05:47 step 7: objective=0.0120242145
2017/08/26 01:05:47 Training value function...
2017/08/26 01:05:54 step 0: mse=1.498449 step=0.100000
2017/08/26 01:06:00 step 1: mse=1.365973 step=0.100000
2017/08/26 01:06:06 step 2: mse=1.256967 step=0.100000
2017/08/26 01:06:13 step 3: mse=1.169786 step=0.100000
2017/08/26 01:06:19 step 4: mse=1.084412 step=0.100000
2017/08/26 01:06:25 step 5: mse=1.018901 step=0.100000
2017/08/26 01:06:32 step 6: mse=0.965044 step=0.100000
2017/08/26 01:06:38 step 7: mse=0.910800 step=0.100000
2017/08/26 01:06:38 Saving...
2017/08/26 01:06:38 Gathering batch of experience...
2017/08/26 01:06:49 batch 51: mean=6.478261 stddev=2.941993 entropy=1.271448 frames=33832 count=69
2017/08/26 01:06:49 Training policy...
2017/08/26 01:06:56 step 0: objective=0.022880703
2017/08/26 01:06:59 step 1: objective=0.023003258
2017/08/26 01:07:02 step 2: objective=0.02312685
2017/08/26 01:07:05 step 3: objective=0.023241652
2017/08/26 01:07:08 step 4: objective=0.023387283
2017/08/26 01:07:11 step 5: objective=0.023428382
2017/08/26 01:07:14 step 6: objective=0.023464954
2017/08/26 01:07:17 step 7: objective=0.023532167
2017/08/26 01:07:17 Training value function...
2017/08/26 01:07:24 step 0: mse=1.327674 step=0.100000
2017/08/26 01:07:30 step 1: mse=1.181535 step=0.100000
2017/08/26 01:07:36 step 2: mse=1.062952 step=0.100000
2017/08/26 01:07:43 step 3: mse=0.966378 step=0.100000
2017/08/26 01:07:49 step 4: mse=0.882474 step=0.100000
2017/08/26 01:07:55 step 5: mse=0.814798 step=0.100000
2017/08/26 01:08:02 step 6: mse=0.758949 step=0.100000
2017/08/26 01:08:08 step 7: mse=0.715274 step=0.100000
2017/08/26 01:08:08 Saving...
2017/08/26 01:08:08 Gathering batch of experience...
2017/08/26 01:08:20 batch 52: mean=6.681159 stddev=2.779285 entropy=1.271065 frames=34276 count=69
2017/08/26 01:08:20 Training policy...
2017/08/26 01:08:26 step 0: objective=0.0018424279
2017/08/26 01:08:30 step 1: objective=0.0020079934
2017/08/26 01:08:33 step 2: objective=0.0021743195
2017/08/26 01:08:36 step 3: objective=0.0023258445
2017/08/26 01:08:39 step 4: objective=0.0023860494
2017/08/26 01:08:42 step 5: objective=0.002567918
2017/08/26 01:08:45 step 6: objective=0.0026441466
2017/08/26 01:08:48 step 7: objective=0.0026870782
2017/08/26 01:08:48 Training value function...
2017/08/26 01:08:55 step 0: mse=0.809509 step=0.100000
2017/08/26 01:09:02 step 1: mse=0.768918 step=0.100000
2017/08/26 01:09:08 step 2: mse=0.736893 step=0.100000
2017/08/26 01:09:14 step 3: mse=0.711228 step=0.100000
2017/08/26 01:09:21 step 4: mse=0.688200 step=0.100000
2017/08/26 01:09:27 step 5: mse=0.664793 step=0.100000
2017/08/26 01:09:34 step 6: mse=0.633592 step=0.100000
2017/08/26 01:09:40 step 7: mse=0.605768 step=0.100000
2017/08/26 01:09:40 Saving...
2017/08/26 01:09:40 Gathering batch of experience...
2017/08/26 01:09:52 batch 53: mean=6.300000 stddev=2.763797 entropy=1.268609 frames=34271 count=70
2017/08/26 01:09:52 Training policy...
2017/08/26 01:09:59 step 0: objective=0.0036435723
2017/08/26 01:10:02 step 1: objective=0.0037520798
2017/08/26 01:10:05 step 2: objective=0.0038610338
2017/08/26 01:10:08 step 3: objective=0.003970345
2017/08/26 01:10:11 step 4: objective=0.0040732413
2017/08/26 01:10:14 step 5: objective=0.0041409596
2017/08/26 01:10:17 step 6: objective=0.00420753
2017/08/26 01:10:20 step 7: objective=0.004261497
2017/08/26 01:10:20 Training value function...
2017/08/26 01:10:27 step 0: mse=0.911877 step=0.100000
2017/08/26 01:10:34 step 1: mse=0.821373 step=0.100000
2017/08/26 01:10:40 step 2: mse=0.740805 step=0.100000
2017/08/26 01:10:46 step 3: mse=0.679364 step=0.100000
2017/08/26 01:10:53 step 4: mse=0.629481 step=0.100000
2017/08/26 01:10:59 step 5: mse=0.585081 step=0.100000
2017/08/26 01:11:06 step 6: mse=0.552081 step=0.100000
2017/08/26 01:11:12 step 7: mse=0.517350 step=0.100000
2017/08/26 01:11:12 Saving...
2017/08/26 01:11:12 Gathering batch of experience...
2017/08/26 01:11:24 batch 54: mean=6.085714 stddev=2.955590 entropy=1.269581 frames=33606 count=70
2017/08/26 01:11:24 Training policy...
2017/08/26 01:11:30 step 0: objective=-0.019673897
2017/08/26 01:11:33 step 1: objective=-0.019440968
2017/08/26 01:11:36 step 2: objective=-0.019281354
2017/08/26 01:11:39 step 3: objective=-0.01915212
2017/08/26 01:11:42 step 4: objective=-0.019068606
2017/08/26 01:11:45 step 5: objective=-0.018887864
2017/08/26 01:11:49 step 6: objective=-0.01880742
2017/08/26 01:11:52 step 7: objective=-0.018627431
2017/08/26 01:11:52 Training value function...
2017/08/26 01:11:58 step 0: mse=1.105810 step=0.100000
2017/08/26 01:12:05 step 1: mse=1.035566 step=0.100000
2017/08/26 01:12:11 step 2: mse=0.978564 step=0.100000
2017/08/26 01:12:17 step 3: mse=0.934108 step=0.100000
2017/08/26 01:12:24 step 4: mse=0.895046 step=0.100000
2017/08/26 01:12:30 step 5: mse=0.864864 step=0.100000
2017/08/26 01:12:37 step 6: mse=0.829977 step=0.100000
2017/08/26 01:12:43 step 7: mse=0.789898 step=0.100000
2017/08/26 01:12:43 Saving...
2017/08/26 01:12:43 Gathering batch of experience...
2017/08/26 01:12:55 batch 55: mean=6.428571 stddev=3.035840 entropy=1.271438 frames=34043 count=70
2017/08/26 01:12:55 Training policy...
2017/08/26 01:13:02 step 0: objective=0.005093822
2017/08/26 01:13:05 step 1: objective=0.0052291504
2017/08/26 01:13:08 step 2: objective=0.0053610746
2017/08/26 01:13:11 step 3: objective=0.005463546
2017/08/26 01:13:14 step 4: objective=0.005532711
2017/08/26 01:13:17 step 5: objective=0.0056054196
2017/08/26 01:13:20 step 6: objective=0.005685506
2017/08/26 01:13:24 step 7: objective=0.005788936
2017/08/26 01:13:24 Training value function...
2017/08/26 01:13:30 step 0: mse=1.013331 step=0.100000
2017/08/26 01:13:37 step 1: mse=0.943980 step=0.100000
2017/08/26 01:13:43 step 2: mse=0.887799 step=0.100000
2017/08/26 01:13:50 step 3: mse=0.841930 step=0.100000
2017/08/26 01:13:56 step 4: mse=0.807501 step=0.100000
2017/08/26 01:14:03 step 5: mse=0.774312 step=0.100000
2017/08/26 01:14:10 step 6: mse=0.731170 step=0.100000
2017/08/26 01:14:16 step 7: mse=0.696398 step=0.100000
2017/08/26 01:14:16 Saving...
2017/08/26 01:14:16 Gathering batch of experience...
2017/08/26 01:14:28 batch 56: mean=6.594203 stddev=3.245147 entropy=1.268520 frames=34069 count=69
2017/08/26 01:14:28 Training policy...
2017/08/26 01:14:35 step 0: objective=0.0036465037
2017/08/26 01:14:38 step 1: objective=0.0040951613
2017/08/26 01:14:41 step 2: objective=0.0043629687
2017/08/26 01:14:44 step 3: objective=0.0045869574
2017/08/26 01:14:47 step 4: objective=0.0047919946
2017/08/26 01:14:50 step 5: objective=0.0049712188
2017/08/26 01:14:54 step 6: objective=0.0050423453
2017/08/26 01:14:57 step 7: objective=0.005177475
2017/08/26 01:14:57 Training value function...
2017/08/26 01:15:04 step 0: mse=1.593387 step=0.100000
2017/08/26 01:15:10 step 1: mse=1.433432 step=0.100000
2017/08/26 01:15:17 step 2: mse=1.302176 step=0.100000
2017/08/26 01:15:23 step 3: mse=1.194842 step=0.100000
2017/08/26 01:15:30 step 4: mse=1.104769 step=0.100000
2017/08/26 01:15:36 step 5: mse=1.035276 step=0.100000
2017/08/26 01:15:43 step 6: mse=0.973802 step=0.100000
2017/08/26 01:15:49 step 7: mse=0.921437 step=0.100000
2017/08/26 01:15:49 Saving...
2017/08/26 01:15:49 Gathering batch of experience...
2017/08/26 01:16:01 batch 57: mean=6.661765 stddev=2.747246 entropy=1.269437 frames=33728 count=68
2017/08/26 01:16:01 Training policy...
2017/08/26 01:16:08 step 0: objective=0.0005748098
2017/08/26 01:16:11 step 1: objective=0.0007501304
2017/08/26 01:16:14 step 2: objective=0.00092278456
2017/08/26 01:16:17 step 3: objective=0.0009981084
2017/08/26 01:16:20 step 4: objective=0.0010823765
2017/08/26 01:16:23 step 5: objective=0.001193594
2017/08/26 01:16:26 step 6: objective=0.0012716259
2017/08/26 01:16:29 step 7: objective=0.001352856
2017/08/26 01:16:29 Training value function...
2017/08/26 01:16:36 step 0: mse=2.134135 step=0.100000
2017/08/26 01:16:43 step 1: mse=1.873854 step=0.100000
2017/08/26 01:16:49 step 2: mse=1.662476 step=0.100000
2017/08/26 01:16:55 step 3: mse=1.490946 step=0.100000
2017/08/26 01:17:02 step 4: mse=1.347698 step=0.100000
2017/08/26 01:17:08 step 5: mse=1.233191 step=0.100000
2017/08/26 01:17:15 step 6: mse=1.134672 step=0.100000
2017/08/26 01:17:21 step 7: mse=1.057979 step=0.100000
2017/08/26 01:17:21 Saving...
2017/08/26 01:17:21 Gathering batch of experience...
2017/08/26 01:17:33 batch 58: mean=6.808824 stddev=2.961803 entropy=1.270559 frames=34821 count=68
2017/08/26 01:17:33 Training policy...
2017/08/26 01:17:40 step 0: objective=0.006781908
2017/08/26 01:17:43 step 1: objective=0.0069079245
2017/08/26 01:17:47 step 2: objective=0.007033247
2017/08/26 01:17:50 step 3: objective=0.007158029
2017/08/26 01:17:53 step 4: objective=0.0072611235
2017/08/26 01:17:56 step 5: objective=0.0073071388
2017/08/26 01:17:59 step 6: objective=0.0075143855
2017/08/26 01:18:03 step 7: objective=0.007556932
2017/08/26 01:18:03 Training value function...
2017/08/26 01:18:10 step 0: mse=1.608441 step=0.100000
2017/08/26 01:18:17 step 1: mse=1.437825 step=0.100000
2017/08/26 01:18:24 step 2: mse=1.305871 step=0.100000
2017/08/26 01:18:30 step 3: mse=1.187814 step=0.100000
2017/08/26 01:18:37 step 4: mse=1.091970 step=0.100000
2017/08/26 01:18:44 step 5: mse=1.018707 step=0.100000
2017/08/26 01:18:51 step 6: mse=0.953152 step=0.100000
2017/08/26 01:20:07 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.9998 -maxtrees 5000]
2017/08/26 01:20:07 Creating environments...
2017/08/26 01:20:09 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/26 01:20:09 Creating new forest for: Breakout-ram-v0/critic.json
2017/08/26 01:20:09 Running. Press Ctrl+C to stop.
2017/08/26 01:20:09 Gathering batch of experience...
2017/08/26 01:20:21 batch 0: mean=6.623188 stddev=3.208239 entropy=1.274251 frames=34046 count=69
2017/08/26 01:20:21 Training policy...
2017/08/26 01:20:25 step 0: objective=0.22538227
2017/08/26 01:20:28 step 1: objective=0.22553523
2017/08/26 01:20:31 step 2: objective=0.2256865
2017/08/26 01:20:34 step 3: objective=0.2258364
2017/08/26 01:20:37 step 4: objective=0.22594221
2017/08/26 01:20:40 step 5: objective=0.22608404
2017/08/26 01:20:44 step 6: objective=0.22623251
2017/08/26 01:20:47 step 7: objective=0.22627337
2017/08/26 01:20:47 Training value function...
2017/08/26 01:20:47 step 0: mse=1.692768 step=0.100000
2017/08/26 01:20:48 step 1: mse=1.415061 step=0.100000
2017/08/26 01:20:48 step 2: mse=1.190041 step=0.100000
2017/08/26 01:20:49 step 3: mse=1.007563 step=0.100000
2017/08/26 01:20:49 step 4: mse=0.859722 step=0.100000
2017/08/26 01:20:49 step 5: mse=0.738691 step=0.100000
2017/08/26 01:20:50 step 6: mse=0.641329 step=0.100000
2017/08/26 01:20:50 step 7: mse=0.562230 step=0.100000
2017/08/26 01:20:50 Saving...
2017/08/26 01:20:50 Gathering batch of experience...
2017/08/26 01:21:02 batch 1: mean=6.432836 stddev=3.008564 entropy=1.269660 frames=33253 count=67
2017/08/26 01:21:02 Training policy...
2017/08/26 01:21:05 step 0: objective=0.09185433
2017/08/26 01:21:08 step 1: objective=0.09188301
2017/08/26 01:21:12 step 2: objective=0.0919121
2017/08/26 01:21:15 step 3: objective=0.09194022
2017/08/26 01:21:18 step 4: objective=0.09197045
2017/08/26 01:21:21 step 5: objective=0.09200038
2017/08/26 01:21:24 step 6: objective=0.092029765
2017/08/26 01:21:27 step 7: objective=0.0920483
2017/08/26 01:21:27 Training value function...
2017/08/26 01:21:28 step 0: mse=0.460871 step=0.100000
2017/08/26 01:21:28 step 1: mse=0.412900 step=0.100000
2017/08/26 01:21:28 step 2: mse=0.373938 step=0.100000
2017/08/26 01:21:29 step 3: mse=0.342056 step=0.100000
2017/08/26 01:21:29 step 4: mse=0.314915 step=0.100000
2017/08/26 01:21:30 step 5: mse=0.293262 step=0.100000
2017/08/26 01:21:30 step 6: mse=0.274329 step=0.100000
2017/08/26 01:21:31 step 7: mse=0.258271 step=0.100000
2017/08/26 01:21:31 Saving...
2017/08/26 01:21:31 Gathering batch of experience...
2017/08/26 01:21:42 batch 2: mean=7.061538 stddev=3.355257 entropy=1.270692 frames=33858 count=65
2017/08/26 01:21:42 Training policy...
2017/08/26 01:21:46 step 0: objective=0.051190425
2017/08/26 01:21:49 step 1: objective=0.051208038
2017/08/26 01:21:52 step 2: objective=0.051225103
2017/08/26 01:21:55 step 3: objective=0.05124231
2017/08/26 01:21:58 step 4: objective=0.051259436
2017/08/26 01:22:02 step 5: objective=0.051276766
2017/08/26 01:22:05 step 6: objective=0.051293883
2017/08/26 01:22:08 step 7: objective=0.051310778
2017/08/26 01:22:08 Training value function...
2017/08/26 01:22:09 step 0: mse=0.329548 step=0.100000
2017/08/26 01:22:09 step 1: mse=0.303362 step=0.100000
2017/08/26 01:22:10 step 2: mse=0.281691 step=0.100000
2017/08/26 01:22:10 step 3: mse=0.263595 step=0.100000
2017/08/26 01:22:10 step 4: mse=0.248852 step=0.100000
2017/08/26 01:22:11 step 5: mse=0.237183 step=0.100000
2017/08/26 01:22:11 step 6: mse=0.227678 step=0.100000
2017/08/26 01:22:12 step 7: mse=0.219439 step=0.100000
2017/08/26 01:22:12 Saving...
2017/08/26 01:22:12 Gathering batch of experience...
2017/08/26 01:22:24 batch 3: mean=7.560606 stddev=4.105166 entropy=1.266997 frames=34732 count=66
2017/08/26 01:22:24 Training policy...
2017/08/26 01:22:28 step 0: objective=0.035298344
2017/08/26 01:22:31 step 1: objective=0.03532213
2017/08/26 01:22:34 step 2: objective=0.035346173
2017/08/26 01:22:38 step 3: objective=0.03537009
2017/08/26 01:22:41 step 4: objective=0.035394583
2017/08/26 01:22:44 step 5: objective=0.03541871
2017/08/26 01:22:47 step 6: objective=0.03544313
2017/08/26 01:22:50 step 7: objective=0.035466775
2017/08/26 01:22:50 Training value function...
2017/08/26 01:22:51 step 0: mse=0.481081 step=0.100000
2017/08/26 01:22:52 step 1: mse=0.449925 step=0.100000
2017/08/26 01:22:52 step 2: mse=0.424297 step=0.100000
2017/08/26 01:22:53 step 3: mse=0.403935 step=0.100000
2017/08/26 01:22:53 step 4: mse=0.384985 step=0.100000
2017/08/26 01:22:54 step 5: mse=0.371091 step=0.100000
2017/08/26 01:22:54 step 6: mse=0.355268 step=0.100000
2017/08/26 01:22:55 step 7: mse=0.345377 step=0.100000
2017/08/26 01:22:55 Saving...
2017/08/26 01:22:55 Gathering batch of experience...
2017/08/26 01:23:07 batch 4: mean=6.535211 stddev=3.797074 entropy=1.272581 frames=33774 count=71
2017/08/26 01:23:07 Training policy...
2017/08/26 01:23:11 step 0: objective=0.0043417816
2017/08/26 01:23:14 step 1: objective=0.0044180946
2017/08/26 01:23:17 step 2: objective=0.0044943797
2017/08/26 01:23:20 step 3: objective=0.0045706695
2017/08/26 01:23:23 step 4: objective=0.0046468955
2017/08/26 01:23:26 step 5: objective=0.0047226823
2017/08/26 01:23:30 step 6: objective=0.0047962866
2017/08/26 01:23:33 step 7: objective=0.0048655584
2017/08/26 01:23:33 Training value function...
2017/08/26 01:23:34 step 0: mse=0.425420 step=0.100000
2017/08/26 01:23:34 step 1: mse=0.406153 step=0.100000
2017/08/26 01:23:35 step 2: mse=0.390893 step=0.100000
2017/08/26 01:23:35 step 3: mse=0.377321 step=0.100000
2017/08/26 01:23:36 step 4: mse=0.366290 step=0.100000
2017/08/26 01:23:36 step 5: mse=0.354798 step=0.100000
2017/08/26 01:23:37 step 6: mse=0.345909 step=0.100000
2017/08/26 01:23:37 step 7: mse=0.337773 step=0.100000
2017/08/26 01:23:37 Saving...
2017/08/26 01:23:37 Gathering batch of experience...
2017/08/26 01:23:49 batch 5: mean=6.695652 stddev=3.003883 entropy=1.265904 frames=34173 count=69
2017/08/26 01:23:49 Training policy...
2017/08/26 01:23:53 step 0: objective=-0.000985524
2017/08/26 01:23:56 step 1: objective=-0.00095594226
2017/08/26 01:23:59 step 2: objective=-0.0009264565
2017/08/26 01:24:02 step 3: objective=-0.0009012041
2017/08/26 01:24:06 step 4: objective=-0.00087551837
2017/08/26 01:24:09 step 5: objective=-0.0008499237
2017/08/26 01:24:12 step 6: objective=-0.00082442997
2017/08/26 01:24:15 step 7: objective=-0.00079903187
2017/08/26 01:24:15 Training value function...
2017/08/26 01:24:16 step 0: mse=0.358015 step=0.100000
2017/08/26 01:24:17 step 1: mse=0.342083 step=0.100000
2017/08/26 01:24:17 step 2: mse=0.329183 step=0.100000
2017/08/26 01:24:18 step 3: mse=0.318713 step=0.100000
2017/08/26 01:24:18 step 4: mse=0.310153 step=0.100000
2017/08/26 01:24:19 step 5: mse=0.303194 step=0.100000
2017/08/26 01:24:19 step 6: mse=0.295750 step=0.100000
2017/08/26 01:24:20 step 7: mse=0.288325 step=0.100000
2017/08/26 01:24:20 Saving...
2017/08/26 01:24:20 Gathering batch of experience...
2017/08/26 01:24:32 batch 6: mean=7.650794 stddev=3.423350 entropy=1.264357 frames=34308 count=63
2017/08/26 01:24:32 Training policy...
2017/08/26 01:24:36 step 0: objective=0.010949083
2017/08/26 01:24:39 step 1: objective=0.010975169
2017/08/26 01:24:42 step 2: objective=0.011001359
2017/08/26 01:24:45 step 3: objective=0.011027599
2017/08/26 01:24:48 step 4: objective=0.011053862
2017/08/26 01:24:51 step 5: objective=0.011080236
2017/08/26 01:24:55 step 6: objective=0.011106577
2017/08/26 01:24:58 step 7: objective=0.011132481
2017/08/26 01:24:58 Training value function...
2017/08/26 01:24:59 step 0: mse=0.309895 step=0.100000
2017/08/26 01:24:59 step 1: mse=0.294696 step=0.100000
2017/08/26 01:25:00 step 2: mse=0.282328 step=0.100000
2017/08/26 01:25:00 step 3: mse=0.272115 step=0.100000
2017/08/26 01:25:01 step 4: mse=0.261803 step=0.100000
2017/08/26 01:25:01 step 5: mse=0.250513 step=0.100000
2017/08/26 01:25:02 step 6: mse=0.241330 step=0.100000
2017/08/26 01:25:03 step 7: mse=0.235014 step=0.100000
2017/08/26 01:25:03 Saving...
2017/08/26 01:25:03 Gathering batch of experience...
2017/08/26 01:25:14 batch 7: mean=7.363636 stddev=3.092691 entropy=1.265386 frames=34099 count=66
2017/08/26 01:25:14 Training policy...
2017/08/26 01:25:18 step 0: objective=0.0048117083
2017/08/26 01:25:21 step 1: objective=0.0048517487
2017/08/26 01:25:24 step 2: objective=0.004891916
2017/08/26 01:25:28 step 3: objective=0.004932073
2017/08/26 01:25:31 step 4: objective=0.004972266
2017/08/26 01:25:34 step 5: objective=0.005012524
2017/08/26 01:25:37 step 6: objective=0.005052804
2017/08/26 01:25:40 step 7: objective=0.0050931615
2017/08/26 01:25:40 Training value function...
2017/08/26 01:25:41 step 0: mse=0.339280 step=0.100000
2017/08/26 01:25:41 step 1: mse=0.327888 step=0.100000
2017/08/26 01:25:42 step 2: mse=0.318663 step=0.100000
2017/08/26 01:25:42 step 3: mse=0.305172 step=0.100000
2017/08/26 01:25:43 step 4: mse=0.294055 step=0.100000
2017/08/26 01:25:43 step 5: mse=0.286460 step=0.100000
2017/08/26 01:25:44 step 6: mse=0.279731 step=0.100000
2017/08/26 01:25:45 step 7: mse=0.273218 step=0.100000
2017/08/26 01:25:45 Saving...
2017/08/26 01:25:45 Gathering batch of experience...
2017/08/26 01:25:56 batch 8: mean=7.230769 stddev=2.783298 entropy=1.256240 frames=34469 count=65
2017/08/26 01:25:56 Training policy...
2017/08/26 01:26:00 step 0: objective=-0.00015775247
2017/08/26 01:26:03 step 1: objective=-0.000113367045
2017/08/26 01:26:07 step 2: objective=-6.922128e-05
2017/08/26 01:26:10 step 3: objective=-2.5311194e-05
2017/08/26 01:26:13 step 4: objective=1.8358369e-05
2017/08/26 01:26:16 step 5: objective=5.6240722e-05
2017/08/26 01:26:19 step 6: objective=9.3987925e-05
2017/08/26 01:26:22 step 7: objective=0.0001315917
2017/08/26 01:26:22 Training value function...
2017/08/26 01:26:23 step 0: mse=0.256037 step=0.100000
2017/08/26 01:26:24 step 1: mse=0.242903 step=0.100000
2017/08/26 01:26:24 step 2: mse=0.232199 step=0.100000
2017/08/26 01:26:25 step 3: mse=0.223160 step=0.100000
2017/08/26 01:26:25 step 4: mse=0.215510 step=0.100000
2017/08/26 01:26:26 step 5: mse=0.207566 step=0.100000
2017/08/26 01:26:26 step 6: mse=0.201800 step=0.100000
2017/08/26 01:26:27 step 7: mse=0.195294 step=0.100000
2017/08/26 01:26:27 Saving...
2017/08/26 01:26:27 Gathering batch of experience...
2017/08/26 01:26:39 batch 9: mean=7.384615 stddev=3.404487 entropy=1.260402 frames=34467 count=65
2017/08/26 01:26:39 Training policy...
2017/08/26 01:26:43 step 0: objective=0.004923169
2017/08/26 01:26:46 step 1: objective=0.00496156
2017/08/26 01:26:49 step 2: objective=0.0049999612
2017/08/26 01:26:52 step 3: objective=0.005036723
2017/08/26 01:26:55 step 4: objective=0.005073496
2017/08/26 01:26:58 step 5: objective=0.0051102876
2017/08/26 01:27:01 step 6: objective=0.005144286
2017/08/26 01:27:05 step 7: objective=0.0051858914
2017/08/26 01:27:05 Training value function...
2017/08/26 01:27:06 step 0: mse=0.304674 step=0.100000
2017/08/26 01:27:06 step 1: mse=0.287461 step=0.100000
2017/08/26 01:27:07 step 2: mse=0.273795 step=0.100000
2017/08/26 01:27:08 step 3: mse=0.262239 step=0.100000
2017/08/26 01:27:08 step 4: mse=0.252068 step=0.100000
2017/08/26 01:27:09 step 5: mse=0.243123 step=0.100000
2017/08/26 01:27:09 step 6: mse=0.236243 step=0.100000
2017/08/26 01:27:10 step 7: mse=0.229071 step=0.100000
2017/08/26 01:27:10 Saving...
2017/08/26 01:27:10 Gathering batch of experience...
2017/08/26 01:27:22 batch 10: mean=7.089552 stddev=3.151552 entropy=1.259038 frames=34473 count=67
2017/08/26 01:27:22 Training policy...
2017/08/26 01:27:49 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.99 -maxtrees 500]
2017/08/26 01:27:49 Creating environments...
2017/08/26 01:27:51 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/26 01:27:51 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/26 01:27:51 Running. Press Ctrl+C to stop.
2017/08/26 01:27:51 Gathering batch of experience...
2017/08/26 01:28:02 batch 0: mean=7.119403 stddev=3.206907 entropy=1.261949 frames=34313 count=67
2017/08/26 01:28:02 Training policy...
2017/08/26 01:28:07 step 0: objective=0.0043608504
2017/08/26 01:28:10 step 1: objective=0.0044059497
2017/08/26 01:28:13 step 2: objective=0.0044491985
2017/08/26 01:28:16 step 3: objective=0.0044925027
2017/08/26 01:28:19 step 4: objective=0.0045358753
2017/08/26 01:28:23 step 5: objective=0.0045793196
2017/08/26 01:28:26 step 6: objective=0.0046227705
2017/08/26 01:28:29 step 7: objective=0.004664622
2017/08/26 01:28:29 Training value function...
2017/08/26 01:28:30 step 0: mse=0.342720 step=0.100000
2017/08/26 01:28:31 step 1: mse=0.326716 step=0.100000
2017/08/26 01:28:31 step 2: mse=0.313962 step=0.100000
2017/08/26 01:28:32 step 3: mse=0.303756 step=0.100000
2017/08/26 01:28:33 step 4: mse=0.295609 step=0.100000
2017/08/26 01:28:33 step 5: mse=0.289081 step=0.100000
2017/08/26 01:28:34 step 6: mse=0.272765 step=0.100000
2017/08/26 01:28:35 step 7: mse=0.259703 step=0.100000
2017/08/26 01:28:35 Saving...
2017/08/26 01:28:35 Gathering batch of experience...
2017/08/26 01:28:47 batch 1: mean=7.714286 stddev=3.410668 entropy=1.257580 frames=34071 count=63
2017/08/26 01:28:47 Training policy...
2017/08/26 01:28:51 step 0: objective=0.01863589
2017/08/26 01:28:54 step 1: objective=0.018671727
2017/08/26 01:28:57 step 2: objective=0.018710641
2017/08/26 01:29:00 step 3: objective=0.018749587
2017/08/26 01:29:03 step 4: objective=0.018785333
2017/08/26 01:29:06 step 5: objective=0.018824358
2017/08/26 01:29:10 step 6: objective=0.018863196
2017/08/26 01:29:13 step 7: objective=0.018896034
2017/08/26 01:29:13 Training value function...
2017/08/26 01:29:14 step 0: mse=0.427554 step=0.100000
2017/08/26 01:29:15 step 1: mse=0.396123 step=0.100000
2017/08/26 01:29:15 step 2: mse=0.371042 step=0.100000
2017/08/26 01:29:16 step 3: mse=0.350618 step=0.100000
2017/08/26 01:29:17 step 4: mse=0.334076 step=0.100000
2017/08/26 01:29:17 step 5: mse=0.319807 step=0.100000
2017/08/26 01:29:18 step 6: mse=0.308587 step=0.100000
2017/08/26 01:29:19 step 7: mse=0.299109 step=0.100000
2017/08/26 01:29:19 Saving...
2017/08/26 01:29:19 Gathering batch of experience...
2017/08/26 01:29:31 batch 2: mean=7.138462 stddev=3.092805 entropy=1.259534 frames=34187 count=65
2017/08/26 01:29:31 Training policy...
2017/08/26 01:29:35 step 0: objective=0.011855659
2017/08/26 01:29:38 step 1: objective=0.011872683
2017/08/26 01:29:42 step 2: objective=0.011889647
2017/08/26 01:29:45 step 3: objective=0.011906722
2017/08/26 01:29:48 step 4: objective=0.011923789
2017/08/26 01:29:51 step 5: objective=0.01194086
2017/08/26 01:29:55 step 6: objective=0.01195798
2017/08/26 01:29:58 step 7: objective=0.011975107
2017/08/26 01:29:58 Training value function...
2017/08/26 01:29:59 step 0: mse=0.357652 step=0.100000
2017/08/26 01:30:00 step 1: mse=0.337512 step=0.100000
2017/08/26 01:30:00 step 2: mse=0.322438 step=0.100000
2017/08/26 01:30:01 step 3: mse=0.310173 step=0.100000
2017/08/26 01:30:02 step 4: mse=0.299074 step=0.100000
2017/08/26 01:30:02 step 5: mse=0.287418 step=0.100000
2017/08/26 01:30:03 step 6: mse=0.279624 step=0.100000
2017/08/26 01:30:04 step 7: mse=0.272366 step=0.100000
2017/08/26 01:30:04 Saving...
2017/08/26 01:30:04 Gathering batch of experience...
2017/08/26 01:30:16 batch 3: mean=7.730159 stddev=3.035276 entropy=1.254932 frames=34050 count=63
2017/08/26 01:30:16 Training policy...
2017/08/26 01:30:20 step 0: objective=0.03023842
2017/08/26 01:30:23 step 1: objective=0.03027461
2017/08/26 01:30:26 step 2: objective=0.030310811
2017/08/26 01:30:29 step 3: objective=0.03034686
2017/08/26 01:30:33 step 4: objective=0.030382717
2017/08/26 01:30:36 step 5: objective=0.03041851
2017/08/26 01:30:39 step 6: objective=0.03045262
2017/08/26 01:30:42 step 7: objective=0.03049211
2017/08/26 01:30:42 Training value function...
2017/08/26 01:30:43 step 0: mse=0.377538 step=0.100000
2017/08/26 01:30:44 step 1: mse=0.362205 step=0.100000
2017/08/26 01:30:45 step 2: mse=0.349702 step=0.100000
2017/08/26 01:30:46 step 3: mse=0.339411 step=0.100000
2017/08/26 01:30:46 step 4: mse=0.330683 step=0.100000
2017/08/26 01:30:47 step 5: mse=0.320037 step=0.100000
2017/08/26 01:30:48 step 6: mse=0.311734 step=0.100000
2017/08/26 01:30:48 step 7: mse=0.300962 step=0.100000
2017/08/26 01:30:48 Saving...
2017/08/26 01:30:48 Gathering batch of experience...
2017/08/26 01:31:01 batch 4: mean=8.800000 stddev=4.085748 entropy=1.253538 frames=34961 count=60
2017/08/26 01:31:01 Training policy...
2017/08/26 01:31:05 step 0: objective=0.036825858
2017/08/26 01:31:08 step 1: objective=0.0368857
2017/08/26 01:31:11 step 2: objective=0.036946174
2017/08/26 01:31:14 step 3: objective=0.03700121
2017/08/26 01:31:18 step 4: objective=0.037057143
2017/08/26 01:31:21 step 5: objective=0.037112493
2017/08/26 01:31:25 step 6: objective=0.037159555
2017/08/26 01:31:28 step 7: objective=0.037215035
2017/08/26 01:31:28 Training value function...
2017/08/26 01:31:29 step 0: mse=0.492432 step=0.100000
2017/08/26 01:31:30 step 1: mse=0.466709 step=0.100000
2017/08/26 01:31:31 step 2: mse=0.451682 step=0.100000
2017/08/26 01:31:31 step 3: mse=0.432687 step=0.100000
2017/08/26 01:31:32 step 4: mse=0.416511 step=0.100000
2017/08/26 01:31:33 step 5: mse=0.403074 step=0.100000
2017/08/26 01:31:33 step 6: mse=0.392780 step=0.100000
2017/08/26 01:31:34 step 7: mse=0.384115 step=0.100000
2017/08/26 01:31:34 Saving...
2017/08/26 01:31:34 Gathering batch of experience...
2017/08/26 01:31:46 batch 5: mean=7.806452 stddev=3.176723 entropy=1.251565 frames=33848 count=62
2017/08/26 01:31:46 Training policy...
2017/08/26 01:31:50 step 0: objective=0.01091314
2017/08/26 01:31:53 step 1: objective=0.01094898
2017/08/26 01:31:57 step 2: objective=0.010980952
2017/08/26 01:32:00 step 3: objective=0.011016701
2017/08/26 01:32:03 step 4: objective=0.011048564
2017/08/26 01:32:06 step 5: objective=0.011080448
2017/08/26 01:32:10 step 6: objective=0.011115995
2017/08/26 01:32:13 step 7: objective=0.011146844
2017/08/26 01:32:13 Training value function...
2017/08/26 01:32:14 step 0: mse=0.357163 step=0.100000
2017/08/26 01:32:15 step 1: mse=0.336137 step=0.100000
2017/08/26 01:32:16 step 2: mse=0.319218 step=0.100000
2017/08/26 01:32:16 step 3: mse=0.306324 step=0.100000
2017/08/26 01:32:17 step 4: mse=0.295884 step=0.100000
2017/08/26 01:32:18 step 5: mse=0.287827 step=0.100000
2017/08/26 01:32:19 step 6: mse=0.278405 step=0.100000
2017/08/26 01:32:19 step 7: mse=0.271159 step=0.100000
2017/08/26 01:32:19 Saving...
2017/08/26 01:32:19 Gathering batch of experience...
2017/08/26 01:32:31 batch 6: mean=7.287879 stddev=3.333781 entropy=1.252865 frames=34729 count=66
2017/08/26 01:32:31 Training policy...
2017/08/26 01:32:36 step 0: objective=0.011987063
2017/08/26 01:32:39 step 1: objective=0.012028075
2017/08/26 01:32:42 step 2: objective=0.012069127
2017/08/26 01:32:46 step 3: objective=0.012110399
2017/08/26 01:32:49 step 4: objective=0.012151566
2017/08/26 01:32:53 step 5: objective=0.01218601
2017/08/26 01:32:56 step 6: objective=0.01222058
2017/08/26 01:32:59 step 7: objective=0.012255159
2017/08/26 01:32:59 Training value function...
2017/08/26 01:33:00 step 0: mse=0.398977 step=0.100000
2017/08/26 01:33:01 step 1: mse=0.373958 step=0.100000
2017/08/26 01:33:02 step 2: mse=0.355343 step=0.100000
2017/08/26 01:33:03 step 3: mse=0.340327 step=0.100000
2017/08/26 01:33:04 step 4: mse=0.328297 step=0.100000
2017/08/26 01:33:04 step 5: mse=0.318542 step=0.100000
2017/08/26 01:33:05 step 6: mse=0.310686 step=0.100000
2017/08/26 01:33:06 step 7: mse=0.302813 step=0.100000
2017/08/26 01:33:06 Saving...
2017/08/26 01:33:06 Gathering batch of experience...
2017/08/26 01:33:18 batch 7: mean=7.968254 stddev=3.919703 entropy=1.250544 frames=34916 count=63
2017/08/26 01:33:18 Training policy...
2017/08/26 01:33:23 step 0: objective=0.021840641
2017/08/26 01:33:26 step 1: objective=0.021866474
2017/08/26 01:33:29 step 2: objective=0.021892153
2017/08/26 01:33:33 step 3: objective=0.021917887
2017/08/26 01:33:36 step 4: objective=0.021943511
2017/08/26 01:33:39 step 5: objective=0.021968914
2017/08/26 01:33:42 step 6: objective=0.021994386
2017/08/26 01:33:46 step 7: objective=0.022019671
2017/08/26 01:33:46 Training value function...
2017/08/26 01:33:47 step 0: mse=0.379747 step=0.100000
2017/08/26 01:33:48 step 1: mse=0.366175 step=0.100000
2017/08/26 01:33:49 step 2: mse=0.355254 step=0.100000
2017/08/26 01:33:49 step 3: mse=0.348790 step=0.100000
2017/08/26 01:33:50 step 4: mse=0.340906 step=0.100000
2017/08/26 01:33:51 step 5: mse=0.334276 step=0.100000
2017/08/26 01:33:52 step 6: mse=0.325108 step=0.100000
2017/08/26 01:33:53 step 7: mse=0.319203 step=0.100000
2017/08/26 01:33:53 Saving...
2017/08/26 01:33:53 Gathering batch of experience...
2017/08/26 01:34:04 batch 8: mean=7.730159 stddev=2.945033 entropy=1.253303 frames=34708 count=63
2017/08/26 01:34:04 Training policy...
2017/08/26 01:34:09 step 0: objective=0.016661704
2017/08/26 01:34:12 step 1: objective=0.016707577
2017/08/26 01:34:15 step 2: objective=0.01675331
2017/08/26 01:34:19 step 3: objective=0.01679918
2017/08/26 01:34:22 step 4: objective=0.016844887
2017/08/26 01:34:25 step 5: objective=0.016889017
2017/08/26 01:34:29 step 6: objective=0.016926836
2017/08/26 01:34:32 step 7: objective=0.016975857
2017/08/26 01:34:32 Training value function...
2017/08/26 01:34:33 step 0: mse=0.331466 step=0.100000
2017/08/26 01:34:34 step 1: mse=0.313754 step=0.100000
2017/08/26 01:34:35 step 2: mse=0.299688 step=0.100000
2017/08/26 01:34:35 step 3: mse=0.287599 step=0.100000
2017/08/26 01:34:36 step 4: mse=0.277645 step=0.100000
2017/08/26 01:34:37 step 5: mse=0.267468 step=0.100000
2017/08/26 01:34:38 step 6: mse=0.261970 step=0.100000
2017/08/26 01:34:39 step 7: mse=0.253858 step=0.100000
2017/08/26 01:34:39 Saving...
2017/08/26 01:34:39 Gathering batch of experience...
2017/08/26 01:34:50 batch 9: mean=8.233333 stddev=3.242256 entropy=1.247391 frames=34031 count=60
2017/08/26 01:34:50 Training policy...
2017/08/26 01:34:54 step 0: objective=0.03047896
2017/08/26 01:34:58 step 1: objective=0.030518105
2017/08/26 01:35:01 step 2: objective=0.030557165
2017/08/26 01:35:04 step 3: objective=0.030596558
2017/08/26 01:35:07 step 4: objective=0.030635968
2017/08/26 01:35:10 step 5: objective=0.030662594
2017/08/26 01:35:14 step 6: objective=0.030682893
2017/08/26 01:35:17 step 7: objective=0.030709151
2017/08/26 01:35:17 Training value function...
2017/08/26 01:35:18 step 0: mse=0.402338 step=0.100000
2017/08/26 01:35:19 step 1: mse=0.382165 step=0.100000
2017/08/26 01:35:20 step 2: mse=0.365933 step=0.100000
2017/08/26 01:35:20 step 3: mse=0.352329 step=0.100000
2017/08/26 01:35:21 step 4: mse=0.341275 step=0.100000
2017/08/26 01:35:22 step 5: mse=0.332044 step=0.100000
2017/08/26 01:35:23 step 6: mse=0.325915 step=0.100000
2017/08/26 01:35:24 step 7: mse=0.320553 step=0.100000
2017/08/26 01:35:24 Saving...
2017/08/26 01:35:24 Gathering batch of experience...
2017/08/26 01:35:36 batch 10: mean=7.859375 stddev=3.587597 entropy=1.248702 frames=34798 count=64
2017/08/26 01:35:36 Training policy...
2017/08/26 01:35:40 step 0: objective=0.020737648
2017/08/26 01:35:43 step 1: objective=0.020784106
2017/08/26 01:35:47 step 2: objective=0.02083039
2017/08/26 01:35:50 step 3: objective=0.020876562
2017/08/26 01:35:53 step 4: objective=0.020946886
2017/08/26 01:35:57 step 5: objective=0.021016877
2017/08/26 01:36:00 step 6: objective=0.021082468
2017/08/26 01:36:03 step 7: objective=0.021125
2017/08/26 01:36:03 Training value function...
2017/08/26 01:36:05 step 0: mse=0.420038 step=0.100000
2017/08/26 01:36:06 step 1: mse=0.399561 step=0.100000
2017/08/26 01:36:06 step 2: mse=0.383177 step=0.100000
2017/08/26 01:36:07 step 3: mse=0.369761 step=0.100000
2017/08/26 01:36:08 step 4: mse=0.358878 step=0.100000
2017/08/26 01:36:09 step 5: mse=0.349684 step=0.100000
2017/08/26 01:36:10 step 6: mse=0.341865 step=0.100000
2017/08/26 01:36:11 step 7: mse=0.335325 step=0.100000
2017/08/26 01:36:11 Saving...
2017/08/26 01:36:11 Gathering batch of experience...
2017/08/26 01:36:23 batch 11: mean=8.096774 stddev=3.271133 entropy=1.248310 frames=34248 count=62
2017/08/26 01:36:23 Training policy...
2017/08/26 01:36:27 step 0: objective=0.02821157
2017/08/26 01:36:30 step 1: objective=0.028242106
2017/08/26 01:36:33 step 2: objective=0.028272973
2017/08/26 01:36:37 step 3: objective=0.028303934
2017/08/26 01:36:40 step 4: objective=0.028335014
2017/08/26 01:36:43 step 5: objective=0.028366359
2017/08/26 01:36:46 step 6: objective=0.028394384
2017/08/26 01:36:50 step 7: objective=0.028430276
2017/08/26 01:36:50 Training value function...
2017/08/26 01:36:51 step 0: mse=0.382243 step=0.100000
2017/08/26 01:36:52 step 1: mse=0.364668 step=0.100000
2017/08/26 01:36:53 step 2: mse=0.349496 step=0.100000
2017/08/26 01:36:53 step 3: mse=0.337382 step=0.100000
2017/08/26 01:36:54 step 4: mse=0.326826 step=0.100000
2017/08/26 01:36:55 step 5: mse=0.319800 step=0.100000
2017/08/26 01:36:56 step 6: mse=0.312667 step=0.100000
2017/08/26 01:36:57 step 7: mse=0.305439 step=0.100000
2017/08/26 01:36:57 Saving...
2017/08/26 01:36:57 Gathering batch of experience...
2017/08/26 01:37:09 batch 12: mean=8.433333 stddev=3.024162 entropy=1.243997 frames=34606 count=60
2017/08/26 01:37:09 Training policy...
2017/08/26 01:37:13 step 0: objective=0.027155789
2017/08/26 01:37:16 step 1: objective=0.027174965
2017/08/26 01:37:20 step 2: objective=0.027194167
2017/08/26 01:37:23 step 3: objective=0.027213512
2017/08/26 01:37:26 step 4: objective=0.027233085
2017/08/26 01:37:30 step 5: objective=0.02725244
2017/08/26 01:37:33 step 6: objective=0.0272729
2017/08/26 01:37:37 step 7: objective=0.02729378
2017/08/26 01:37:37 Training value function...
2017/08/26 01:37:38 step 0: mse=0.292681 step=0.100000
2017/08/26 01:37:39 step 1: mse=0.282190 step=0.100000
2017/08/26 01:37:40 step 2: mse=0.274234 step=0.100000
2017/08/26 01:37:41 step 3: mse=0.262923 step=0.100000
2017/08/26 01:37:42 step 4: mse=0.253757 step=0.100000
2017/08/26 01:37:43 step 5: mse=0.246969 step=0.100000
2017/08/26 01:37:44 step 6: mse=0.243095 step=0.100000
2017/08/26 01:37:45 step 7: mse=0.235753 step=0.100000
2017/08/26 01:37:45 Saving...
2017/08/26 01:37:45 Gathering batch of experience...
2017/08/26 01:37:57 batch 13: mean=8.416667 stddev=3.513269 entropy=1.243815 frames=34569 count=60
2017/08/26 01:37:57 Training policy...
2017/08/26 01:38:01 step 0: objective=0.023265483
2017/08/26 01:38:05 step 1: objective=0.02329202
2017/08/26 01:38:08 step 2: objective=0.02331849
2017/08/26 01:38:11 step 3: objective=0.023345206
2017/08/26 01:38:15 step 4: objective=0.023371859
2017/08/26 01:38:18 step 5: objective=0.023398615
2017/08/26 01:38:22 step 6: objective=0.023424963
2017/08/26 01:38:25 step 7: objective=0.023446007
2017/08/26 01:38:25 Training value function...
2017/08/26 01:38:26 step 0: mse=0.367876 step=0.100000
2017/08/26 01:38:27 step 1: mse=0.352450 step=0.100000
2017/08/26 01:38:28 step 2: mse=0.339992 step=0.100000
2017/08/26 01:38:29 step 3: mse=0.329824 step=0.100000
2017/08/26 01:38:30 step 4: mse=0.321530 step=0.100000
2017/08/26 01:38:31 step 5: mse=0.314695 step=0.100000
2017/08/26 01:38:32 step 6: mse=0.309053 step=0.100000
2017/08/26 01:38:33 step 7: mse=0.304343 step=0.100000
2017/08/26 01:38:33 Saving...
2017/08/26 01:38:33 Gathering batch of experience...
2017/08/26 01:38:45 batch 14: mean=8.644068 stddev=4.313018 entropy=1.247576 frames=34153 count=59
2017/08/26 01:38:45 Training policy...
2017/08/26 01:38:49 step 0: objective=0.02553114
2017/08/26 01:38:53 step 1: objective=0.025568744
2017/08/26 01:38:56 step 2: objective=0.025606278
2017/08/26 01:38:59 step 3: objective=0.025643751
2017/08/26 01:39:02 step 4: objective=0.02568128
2017/08/26 01:39:06 step 5: objective=0.02572092
2017/08/26 01:39:09 step 6: objective=0.025748134
2017/08/26 01:39:12 step 7: objective=0.025780536
2017/08/26 01:39:12 Training value function...
2017/08/26 01:39:13 step 0: mse=0.392624 step=0.100000
2017/08/26 01:39:14 step 1: mse=0.368573 step=0.100000
2017/08/26 01:39:15 step 2: mse=0.349264 step=0.100000
2017/08/26 01:39:16 step 3: mse=0.332263 step=0.100000
2017/08/26 01:39:17 step 4: mse=0.314240 step=0.100000
2017/08/26 01:39:18 step 5: mse=0.301575 step=0.100000
2017/08/26 01:39:19 step 6: mse=0.290860 step=0.100000
2017/08/26 01:39:20 step 7: mse=0.278537 step=0.100000
2017/08/26 01:39:20 Saving...
2017/08/26 01:39:20 Gathering batch of experience...
2017/08/26 01:39:32 batch 15: mean=8.483333 stddev=3.748296 entropy=1.241772 frames=34663 count=60
2017/08/26 01:39:32 Training policy...
2017/08/26 01:39:36 step 0: objective=0.020806462
2017/08/26 01:39:40 step 1: objective=0.020849308
2017/08/26 01:39:43 step 2: objective=0.020892246
2017/08/26 01:39:46 step 3: objective=0.020935122
2017/08/26 01:39:50 step 4: objective=0.020978106
2017/08/26 01:39:54 step 5: objective=0.02102032
2017/08/26 01:39:57 step 6: objective=0.021056961
2017/08/26 01:40:01 step 7: objective=0.021086128
2017/08/26 01:40:01 Training value function...
2017/08/26 01:40:02 step 0: mse=0.373716 step=0.100000
2017/08/26 01:40:03 step 1: mse=0.347224 step=0.100000
2017/08/26 01:40:04 step 2: mse=0.325601 step=0.100000
2017/08/26 01:40:05 step 3: mse=0.308324 step=0.100000
2017/08/26 01:40:06 step 4: mse=0.293954 step=0.100000
2017/08/26 01:40:07 step 5: mse=0.279952 step=0.100000
2017/08/26 01:40:08 step 6: mse=0.268251 step=0.100000
2017/08/26 01:40:09 step 7: mse=0.258986 step=0.100000
2017/08/26 01:40:09 Saving...
2017/08/26 01:40:09 Gathering batch of experience...
2017/08/26 01:40:22 batch 16: mean=8.682540 stddev=4.478610 entropy=1.243772 frames=35420 count=63
2017/08/26 01:40:22 Training policy...
2017/08/26 01:40:26 step 0: objective=0.033969134
2017/08/26 01:40:29 step 1: objective=0.034020487
2017/08/26 01:40:33 step 2: objective=0.03407214
2017/08/26 01:40:36 step 3: objective=0.034124132
2017/08/26 01:40:40 step 4: objective=0.03417502
2017/08/26 01:40:43 step 5: objective=0.034199003
2017/08/26 01:40:46 step 6: objective=0.034255724
2017/08/26 01:40:50 step 7: objective=0.034311935
2017/08/26 01:40:50 Training value function...
2017/08/26 01:40:51 step 0: mse=0.557367 step=0.100000
2017/08/26 01:40:52 step 1: mse=0.535167 step=0.100000
2017/08/26 01:40:53 step 2: mse=0.515417 step=0.100000
2017/08/26 01:40:55 step 3: mse=0.499545 step=0.100000
2017/08/26 01:40:56 step 4: mse=0.486458 step=0.100000
2017/08/26 01:40:57 step 5: mse=0.467568 step=0.100000
2017/08/26 01:40:58 step 6: mse=0.457275 step=0.100000
2017/08/26 01:40:59 step 7: mse=0.448942 step=0.100000
2017/08/26 01:40:59 Saving...
2017/08/26 01:40:59 Gathering batch of experience...
2017/08/26 01:41:11 batch 17: mean=8.819672 stddev=3.578204 entropy=1.243694 frames=35510 count=61
2017/08/26 01:41:11 Training policy...
2017/08/26 01:41:16 step 0: objective=0.030131992
2017/08/26 01:41:19 step 1: objective=0.030182822
2017/08/26 01:41:22 step 2: objective=0.03023341
2017/08/26 01:41:26 step 3: objective=0.030283967
2017/08/26 01:41:29 step 4: objective=0.03033437
2017/08/26 01:41:33 step 5: objective=0.030384641
2017/08/26 01:41:37 step 6: objective=0.030434674
2017/08/26 01:41:40 step 7: objective=0.03046754
2017/08/26 01:41:40 Training value function...
2017/08/26 01:41:41 step 0: mse=0.400562 step=0.100000
2017/08/26 01:41:43 step 1: mse=0.385659 step=0.100000
2017/08/26 01:41:44 step 2: mse=0.371840 step=0.100000
2017/08/26 01:41:45 step 3: mse=0.362666 step=0.100000
2017/08/26 01:41:46 step 4: mse=0.348290 step=0.100000
2017/08/26 01:41:47 step 5: mse=0.342224 step=0.100000
2017/08/26 01:41:48 step 6: mse=0.331813 step=0.100000
2017/08/26 01:41:49 step 7: mse=0.319712 step=0.100000
2017/08/26 01:41:49 Saving...
2017/08/26 01:41:49 Gathering batch of experience...
2017/08/26 01:42:01 batch 18: mean=8.898305 stddev=4.297003 entropy=1.242137 frames=34614 count=59
2017/08/26 01:42:01 Training policy...
2017/08/26 01:42:06 step 0: objective=0.01703847
2017/08/26 01:42:09 step 1: objective=0.017085662
2017/08/26 01:42:12 step 2: objective=0.01713227
2017/08/26 01:42:16 step 3: objective=0.017178614
2017/08/26 01:42:19 step 4: objective=0.01722446
2017/08/26 01:42:22 step 5: objective=0.017267976
2017/08/26 01:42:26 step 6: objective=0.017300682
2017/08/26 01:42:29 step 7: objective=0.017335393
2017/08/26 01:42:29 Training value function...
2017/08/26 01:42:31 step 0: mse=0.457549 step=0.100000
2017/08/26 01:42:32 step 1: mse=0.430970 step=0.100000
2017/08/26 01:42:33 step 2: mse=0.409204 step=0.100000
2017/08/26 01:42:34 step 3: mse=0.390919 step=0.100000
2017/08/26 01:42:35 step 4: mse=0.376726 step=0.100000
2017/08/26 01:42:36 step 5: mse=0.364785 step=0.100000
2017/08/26 01:42:37 step 6: mse=0.353643 step=0.100000
2017/08/26 01:42:38 step 7: mse=0.345399 step=0.100000
2017/08/26 01:42:38 Saving...
2017/08/26 01:42:38 Gathering batch of experience...
2017/08/26 01:42:50 batch 19: mean=8.016129 stddev=3.034702 entropy=1.239245 frames=34772 count=62
2017/08/26 01:42:50 Training policy...
2017/08/26 01:42:55 step 0: objective=0.004913432
2017/08/26 01:42:58 step 1: objective=0.0049511944
2017/08/26 01:43:01 step 2: objective=0.004988841
2017/08/26 01:43:05 step 3: objective=0.0050262786
2017/08/26 01:43:08 step 4: objective=0.005063563
2017/08/26 01:43:12 step 5: objective=0.0051006656
2017/08/26 01:43:15 step 6: objective=0.005137622
2017/08/26 01:43:18 step 7: objective=0.00517623
2017/08/26 01:43:18 Training value function...
2017/08/26 01:43:20 step 0: mse=0.329617 step=0.100000
2017/08/26 01:43:21 step 1: mse=0.319078 step=0.100000
2017/08/26 01:43:22 step 2: mse=0.304370 step=0.100000
2017/08/26 01:43:23 step 3: mse=0.293109 step=0.100000
2017/08/26 01:43:24 step 4: mse=0.284047 step=0.100000
2017/08/26 01:43:25 step 5: mse=0.277589 step=0.100000
2017/08/26 01:43:27 step 6: mse=0.271574 step=0.100000
2017/08/26 01:43:28 step 7: mse=0.267543 step=0.100000
2017/08/26 01:43:28 Saving...
2017/08/26 01:43:28 Gathering batch of experience...
2017/08/26 01:43:40 batch 20: mean=9.000000 stddev=3.991370 entropy=1.242861 frames=34908 count=58
2017/08/26 01:43:40 Training policy...
2017/08/26 01:43:44 step 0: objective=0.023850791
2017/08/26 01:43:48 step 1: objective=0.023881376
2017/08/26 01:43:51 step 2: objective=0.023912067
2017/08/26 01:43:54 step 3: objective=0.023942789
2017/08/26 01:43:58 step 4: objective=0.023973357
2017/08/26 01:44:01 step 5: objective=0.024003956
2017/08/26 01:44:05 step 6: objective=0.024034396
2017/08/26 01:44:08 step 7: objective=0.024063047
2017/08/26 01:44:08 Training value function...
2017/08/26 01:44:10 step 0: mse=0.414872 step=0.100000
2017/08/26 01:44:11 step 1: mse=0.399331 step=0.100000
2017/08/26 01:44:12 step 2: mse=0.386927 step=0.100000
2017/08/26 01:44:13 step 3: mse=0.373675 step=0.100000
2017/08/26 01:44:15 step 4: mse=0.359449 step=0.100000
2017/08/26 01:44:16 step 5: mse=0.350560 step=0.100000
2017/08/26 01:44:17 step 6: mse=0.339423 step=0.100000
2017/08/26 01:44:18 step 7: mse=0.329597 step=0.100000
2017/08/26 01:44:18 Saving...
2017/08/26 01:44:18 Gathering batch of experience...
2017/08/26 01:44:30 batch 21: mean=8.706897 stddev=4.197736 entropy=1.241217 frames=34001 count=58
2017/08/26 01:44:30 Training policy...
2017/08/26 01:44:34 step 0: objective=0.030750442
2017/08/26 01:44:38 step 1: objective=0.030780083
2017/08/26 01:44:41 step 2: objective=0.030810064
2017/08/26 01:44:44 step 3: objective=0.030840233
2017/08/26 01:44:48 step 4: objective=0.030870957
2017/08/26 01:44:51 step 5: objective=0.030901978
2017/08/26 01:44:54 step 6: objective=0.03092596
2017/08/26 01:44:57 step 7: objective=0.03097153
2017/08/26 01:44:57 Training value function...
2017/08/26 01:44:59 step 0: mse=0.407244 step=0.100000
2017/08/26 01:45:00 step 1: mse=0.386498 step=0.100000
2017/08/26 01:45:01 step 2: mse=0.368118 step=0.100000
2017/08/26 01:45:03 step 3: mse=0.354179 step=0.100000
2017/08/26 01:45:04 step 4: mse=0.341458 step=0.100000
2017/08/26 01:45:05 step 5: mse=0.329355 step=0.100000
2017/08/26 01:45:06 step 6: mse=0.319455 step=0.100000
2017/08/26 01:45:08 step 7: mse=0.308021 step=0.100000
2017/08/26 01:45:08 Saving...
2017/08/26 01:45:08 Gathering batch of experience...
2017/08/26 01:45:20 batch 22: mean=8.559322 stddev=3.253531 entropy=1.239574 frames=34357 count=59
2017/08/26 01:45:20 Training policy...
2017/08/26 01:45:24 step 0: objective=0.021237176
2017/08/26 01:45:27 step 1: objective=0.021278344
2017/08/26 01:45:31 step 2: objective=0.0213191
2017/08/26 01:45:34 step 3: objective=0.021359589
2017/08/26 01:45:38 step 4: objective=0.021397928
2017/08/26 01:45:41 step 5: objective=0.021436071
2017/08/26 01:45:44 step 6: objective=0.02147626
2017/08/26 01:45:48 step 7: objective=0.021516237
2017/08/26 01:45:48 Training value function...
2017/08/26 01:45:50 step 0: mse=0.430686 step=0.100000
2017/08/26 01:45:51 step 1: mse=0.412910 step=0.100000
2017/08/26 01:45:52 step 2: mse=0.397235 step=0.100000
2017/08/26 01:45:53 step 3: mse=0.382486 step=0.100000
2017/08/26 01:45:54 step 4: mse=0.371135 step=0.100000
2017/08/26 01:45:56 step 5: mse=0.361292 step=0.100000
2017/08/26 01:45:57 step 6: mse=0.353405 step=0.100000
2017/08/26 01:45:58 step 7: mse=0.346206 step=0.100000
2017/08/26 01:45:58 Saving...
2017/08/26 01:45:58 Gathering batch of experience...
2017/08/26 01:46:10 batch 23: mean=8.183333 stddev=2.667656 entropy=1.238551 frames=34709 count=60
2017/08/26 01:46:10 Training policy...
2017/08/26 01:46:15 step 0: objective=0.0054389606
2017/08/26 01:46:18 step 1: objective=0.005464105
2017/08/26 01:46:22 step 2: objective=0.005489233
2017/08/26 01:46:25 step 3: objective=0.005514297
2017/08/26 01:46:28 step 4: objective=0.005539385
2017/08/26 01:46:32 step 5: objective=0.0055644065
2017/08/26 01:46:35 step 6: objective=0.005589449
2017/08/26 01:46:39 step 7: objective=0.0056144786
2017/08/26 01:46:39 Training value function...
2017/08/26 01:46:40 step 0: mse=0.205467 step=0.100000
2017/08/26 01:46:42 step 1: mse=0.194660 step=0.100000
2017/08/26 01:46:43 step 2: mse=0.185945 step=0.100000
2017/08/26 01:46:44 step 3: mse=0.178981 step=0.100000
2017/08/26 01:46:46 step 4: mse=0.174228 step=0.100000
2017/08/26 01:46:47 step 5: mse=0.170039 step=0.100000
2017/08/26 01:46:48 step 6: mse=0.165796 step=0.100000
2017/08/26 01:46:49 step 7: mse=0.162998 step=0.100000
2017/08/26 01:46:49 Saving...
2017/08/26 01:46:49 Gathering batch of experience...
2017/08/26 01:47:01 batch 24: mean=9.375000 stddev=3.425547 entropy=1.240585 frames=33668 count=56
2017/08/26 01:47:01 Training policy...
2017/08/26 01:47:05 step 0: objective=0.041321974
2017/08/26 01:47:09 step 1: objective=0.04137021
2017/08/26 01:47:12 step 2: objective=0.041418456
2017/08/26 01:47:15 step 3: objective=0.04146606
2017/08/26 01:47:19 step 4: objective=0.04151328
2017/08/26 01:47:22 step 5: objective=0.04156001
2017/08/26 01:47:25 step 6: objective=0.04160522
2017/08/26 01:47:29 step 7: objective=0.041645028
2017/08/26 01:47:29 Training value function...
2017/08/26 01:47:30 step 0: mse=0.509957 step=0.100000
2017/08/26 01:47:32 step 1: mse=0.487342 step=0.100000
2017/08/26 01:47:33 step 2: mse=0.468589 step=0.100000
2017/08/26 01:47:34 step 3: mse=0.446137 step=0.100000
2017/08/26 01:47:35 step 4: mse=0.430977 step=0.100000
2017/08/26 01:47:37 step 5: mse=0.418039 step=0.100000
2017/08/26 01:47:38 step 6: mse=0.408237 step=0.100000
2017/08/26 01:47:39 step 7: mse=0.400905 step=0.100000
2017/08/26 01:47:39 Saving...
2017/08/26 01:47:39 Gathering batch of experience...
2017/08/26 01:47:51 batch 25: mean=8.177419 stddev=2.709149 entropy=1.240774 frames=35039 count=62
2017/08/26 01:47:51 Training policy...
2017/08/26 01:47:56 step 0: objective=0.0066468157
2017/08/26 01:48:00 step 1: objective=0.006676439
2017/08/26 01:48:03 step 2: objective=0.0067061544
2017/08/26 01:48:07 step 3: objective=0.006735921
2017/08/26 01:48:10 step 4: objective=0.006765781
2017/08/26 01:48:14 step 5: objective=0.006795688
2017/08/26 01:48:17 step 6: objective=0.006825644
2017/08/26 01:48:21 step 7: objective=0.0068541616
2017/08/26 01:48:21 Training value function...
2017/08/26 01:48:23 step 0: mse=0.262280 step=0.100000
2017/08/26 01:48:24 step 1: mse=0.253489 step=0.100000
2017/08/26 01:48:25 step 2: mse=0.246584 step=0.100000
2017/08/26 01:48:27 step 3: mse=0.240113 step=0.100000
2017/08/26 01:48:28 step 4: mse=0.235349 step=0.100000
2017/08/26 01:48:29 step 5: mse=0.231699 step=0.100000
2017/08/26 01:48:31 step 6: mse=0.227296 step=0.100000
2017/08/26 01:48:32 step 7: mse=0.223483 step=0.100000
2017/08/26 01:48:32 Saving...
2017/08/26 01:48:32 Gathering batch of experience...
2017/08/26 01:48:44 batch 26: mean=8.459016 stddev=3.038409 entropy=1.238856 frames=34925 count=61
2017/08/26 01:48:44 Training policy...
2017/08/26 01:48:50 step 0: objective=0.017403806
2017/08/26 01:48:53 step 1: objective=0.017427767
2017/08/26 01:48:57 step 2: objective=0.01745162
2017/08/26 01:49:00 step 3: objective=0.017475417
2017/08/26 01:49:04 step 4: objective=0.01749908
2017/08/26 01:49:07 step 5: objective=0.017522724
2017/08/26 01:49:11 step 6: objective=0.017546263
2017/08/26 01:49:14 step 7: objective=0.01756973
2017/08/26 01:49:14 Training value function...
2017/08/26 01:49:16 step 0: mse=0.362254 step=0.100000
2017/08/26 01:49:18 step 1: mse=0.345378 step=0.100000
2017/08/26 01:49:19 step 2: mse=0.331897 step=0.100000
2017/08/26 01:49:20 step 3: mse=0.320937 step=0.100000
2017/08/26 01:49:22 step 4: mse=0.311679 step=0.100000
2017/08/26 01:49:23 step 5: mse=0.303950 step=0.100000
2017/08/26 01:49:25 step 6: mse=0.297287 step=0.100000
2017/08/26 01:49:26 step 7: mse=0.292171 step=0.100000
2017/08/26 01:49:26 Saving...
2017/08/26 01:49:26 Gathering batch of experience...
2017/08/26 01:49:38 batch 27: mean=9.696429 stddev=4.187224 entropy=1.233912 frames=34253 count=56
2017/08/26 01:49:38 Training policy...
2017/08/26 01:49:43 step 0: objective=0.04726658
2017/08/26 01:49:46 step 1: objective=0.047296904
2017/08/26 01:49:50 step 2: objective=0.047327533
2017/08/26 01:49:53 step 3: objective=0.04735833
2017/08/26 01:49:57 step 4: objective=0.047388405
2017/08/26 01:50:00 step 5: objective=0.047419023
2017/08/26 01:50:04 step 6: objective=0.0474496
2017/08/26 01:50:07 step 7: objective=0.047477923
2017/08/26 01:50:07 Training value function...
2017/08/26 01:50:09 step 0: mse=0.527064 step=0.100000
2017/08/26 01:50:10 step 1: mse=0.494108 step=0.100000
2017/08/26 01:50:12 step 2: mse=0.467379 step=0.100000
2017/08/26 01:50:13 step 3: mse=0.444827 step=0.100000
2017/08/26 01:50:15 step 4: mse=0.426310 step=0.100000
2017/08/26 01:50:16 step 5: mse=0.411125 step=0.100000
2017/08/26 01:50:17 step 6: mse=0.395003 step=0.100000
2017/08/26 01:50:19 step 7: mse=0.383634 step=0.100000
2017/08/26 01:50:19 Saving...
2017/08/26 01:50:19 Gathering batch of experience...
2017/08/26 01:50:31 batch 28: mean=9.241379 stddev=3.313038 entropy=1.234932 frames=34806 count=58
2017/08/26 01:50:31 Training policy...
2017/08/26 01:50:36 step 0: objective=0.021491967
2017/08/26 01:50:39 step 1: objective=0.021511242
2017/08/26 01:50:43 step 2: objective=0.021530533
2017/08/26 01:50:46 step 3: objective=0.02154995
2017/08/26 01:50:50 step 4: objective=0.021569565
2017/08/26 01:50:53 step 5: objective=0.021589119
2017/08/26 01:50:57 step 6: objective=0.021608869
2017/08/26 01:51:01 step 7: objective=0.021628566
2017/08/26 01:51:01 Training value function...
2017/08/26 01:51:03 step 0: mse=0.430579 step=0.100000
2017/08/26 01:51:04 step 1: mse=0.405737 step=0.100000
2017/08/26 01:51:05 step 2: mse=0.389703 step=0.100000
2017/08/26 01:51:07 step 3: mse=0.376695 step=0.100000
2017/08/26 01:51:08 step 4: mse=0.364119 step=0.100000
2017/08/26 01:51:10 step 5: mse=0.352997 step=0.100000
2017/08/26 01:51:11 step 6: mse=0.345805 step=0.100000
2017/08/26 01:51:13 step 7: mse=0.337816 step=0.100000
2017/08/26 01:51:13 Saving...
2017/08/26 01:51:13 Gathering batch of experience...
2017/08/26 01:51:25 batch 29: mean=9.172414 stddev=4.030650 entropy=1.236133 frames=33984 count=58
2017/08/26 01:51:25 Training policy...
2017/08/26 01:51:29 step 0: objective=0.029869374
2017/08/26 01:51:33 step 1: objective=0.029901398
2017/08/26 01:51:36 step 2: objective=0.029933477
2017/08/26 01:51:40 step 3: objective=0.029965118
2017/08/26 01:51:43 step 4: objective=0.02999691
2017/08/26 01:51:47 step 5: objective=0.030028481
2017/08/26 01:51:50 step 6: objective=0.030059675
2017/08/26 01:51:54 step 7: objective=0.030090842
2017/08/26 01:51:54 Training value function...
2017/08/26 01:51:55 step 0: mse=0.536667 step=0.100000
2017/08/26 01:51:57 step 1: mse=0.497312 step=0.100000
2017/08/26 01:51:58 step 2: mse=0.467313 step=0.100000
2017/08/26 01:52:00 step 3: mse=0.439769 step=0.100000
2017/08/26 01:52:01 step 4: mse=0.419020 step=0.100000
2017/08/26 01:52:03 step 5: mse=0.400671 step=0.100000
2017/08/26 01:52:04 step 6: mse=0.383668 step=0.100000
2017/08/26 01:52:06 step 7: mse=0.368761 step=0.100000
2017/08/26 01:52:06 Saving...
2017/08/26 01:52:06 Gathering batch of experience...
2017/08/26 01:52:18 batch 30: mean=9.067797 stddev=3.995185 entropy=1.232928 frames=35440 count=59
2017/08/26 01:52:18 Training policy...
2017/08/26 01:52:23 step 0: objective=0.018609473
2017/08/26 01:52:26 step 1: objective=0.018639011
2017/08/26 01:52:30 step 2: objective=0.018673789
2017/08/26 01:52:34 step 3: objective=0.01870849
2017/08/26 01:52:37 step 4: objective=0.018743234
2017/08/26 01:52:41 step 5: objective=0.01877307
2017/08/26 01:52:44 step 6: objective=0.018808117
2017/08/26 01:52:48 step 7: objective=0.018842971
2017/08/26 01:52:48 Training value function...
2017/08/26 01:52:50 step 0: mse=0.486415 step=0.100000
2017/08/26 01:52:52 step 1: mse=0.461115 step=0.100000
2017/08/26 01:52:53 step 2: mse=0.441280 step=0.100000
2017/08/26 01:52:55 step 3: mse=0.425132 step=0.100000
2017/08/26 01:52:56 step 4: mse=0.411752 step=0.100000
2017/08/26 01:52:58 step 5: mse=0.401610 step=0.100000
2017/08/26 01:52:59 step 6: mse=0.392547 step=0.100000
2017/08/26 01:53:01 step 7: mse=0.384834 step=0.100000
2017/08/26 01:53:01 Saving...
2017/08/26 01:53:01 Gathering batch of experience...
2017/08/26 01:53:13 batch 31: mean=8.610169 stddev=3.124626 entropy=1.231519 frames=34139 count=59
2017/08/26 01:53:13 Training policy...
2017/08/26 01:53:17 step 0: objective=0.01907081
2017/08/26 01:53:21 step 1: objective=0.01909649
2017/08/26 01:53:24 step 2: objective=0.019122321
2017/08/26 01:53:28 step 3: objective=0.019147947
2017/08/26 01:53:32 step 4: objective=0.019172514
2017/08/26 01:53:35 step 5: objective=0.019197073
2017/08/26 01:53:39 step 6: objective=0.019221673
2017/08/26 01:53:42 step 7: objective=0.01924638
2017/08/26 01:53:42 Training value function...
2017/08/26 01:53:44 step 0: mse=0.389726 step=0.100000
2017/08/26 01:53:46 step 1: mse=0.365009 step=0.100000
2017/08/26 01:53:47 step 2: mse=0.345328 step=0.100000
2017/08/26 01:53:48 step 3: mse=0.329651 step=0.100000
2017/08/26 01:53:50 step 4: mse=0.317507 step=0.100000
2017/08/26 01:53:52 step 5: mse=0.308169 step=0.100000
2017/08/26 01:53:53 step 6: mse=0.299869 step=0.100000
2017/08/26 01:53:55 step 7: mse=0.293056 step=0.100000
2017/08/26 01:53:55 Saving...
2017/08/26 01:53:55 Gathering batch of experience...
2017/08/26 01:54:07 batch 32: mean=8.741379 stddev=3.288225 entropy=1.233876 frames=34312 count=58
2017/08/26 01:54:07 Training policy...
2017/08/26 01:54:11 step 0: objective=0.020841783
2017/08/26 01:54:15 step 1: objective=0.020872343
2017/08/26 01:54:18 step 2: objective=0.020902973
2017/08/26 01:54:22 step 3: objective=0.020933347
2017/08/26 01:54:25 step 4: objective=0.020960506
2017/08/26 01:54:29 step 5: objective=0.020987477
2017/08/26 01:54:32 step 6: objective=0.02101787
2017/08/26 01:54:36 step 7: objective=0.021044793
2017/08/26 01:54:36 Training value function...
2017/08/26 01:54:38 step 0: mse=0.268214 step=0.100000
2017/08/26 01:54:39 step 1: mse=0.260907 step=0.100000
2017/08/26 01:54:41 step 2: mse=0.254565 step=0.100000
2017/08/26 01:54:42 step 3: mse=0.249273 step=0.100000
2017/08/26 01:54:44 step 4: mse=0.243885 step=0.100000
2017/08/26 01:54:45 step 5: mse=0.239816 step=0.100000
2017/08/26 01:54:47 step 6: mse=0.230515 step=0.100000
2017/08/26 01:54:48 step 7: mse=0.225493 step=0.100000
2017/08/26 01:54:48 Saving...
2017/08/26 01:54:48 Gathering batch of experience...
2017/08/26 01:55:01 batch 33: mean=8.766667 stddev=3.461053 entropy=1.232203 frames=34836 count=60
2017/08/26 01:55:01 Training policy...
2017/08/26 01:55:05 step 0: objective=0.021693822
2017/08/26 01:55:09 step 1: objective=0.02172887
2017/08/26 01:55:13 step 2: objective=0.021764033
2017/08/26 01:55:16 step 3: objective=0.021794697
2017/08/26 01:55:20 step 4: objective=0.021830149
2017/08/26 01:55:24 step 5: objective=0.021861132
2017/08/26 01:55:27 step 6: objective=0.021894824
2017/08/26 01:55:31 step 7: objective=0.021918867
2017/08/26 01:55:31 Training value function...
2017/08/26 01:55:33 step 0: mse=0.356433 step=0.100000
2017/08/26 01:55:34 step 1: mse=0.344194 step=0.100000
2017/08/26 01:55:36 step 2: mse=0.335008 step=0.100000
2017/08/26 01:55:38 step 3: mse=0.326510 step=0.100000
2017/08/26 01:55:39 step 4: mse=0.320723 step=0.100000
2017/08/26 01:55:41 step 5: mse=0.313098 step=0.100000
2017/08/26 01:55:43 step 6: mse=0.297230 step=0.100000
2017/08/26 01:55:44 step 7: mse=0.290081 step=0.100000
2017/08/26 01:55:44 Saving...
2017/08/26 01:55:44 Gathering batch of experience...
2017/08/26 01:55:57 batch 34: mean=8.650000 stddev=3.936263 entropy=1.235837 frames=34691 count=60
2017/08/26 01:55:57 Training policy...
2017/08/26 01:56:01 step 0: objective=0.024811115
2017/08/26 01:56:05 step 1: objective=0.024850965
2017/08/26 01:56:08 step 2: objective=0.024890784
2017/08/26 01:56:12 step 3: objective=0.024930675
2017/08/26 01:56:16 step 4: objective=0.024970345
2017/08/26 01:56:19 step 5: objective=0.02501027
2017/08/26 01:56:23 step 6: objective=0.02504944
2017/08/26 01:56:26 step 7: objective=0.02508307
2017/08/26 01:56:26 Training value function...
2017/08/26 01:56:28 step 0: mse=0.392891 step=0.100000
2017/08/26 01:56:30 step 1: mse=0.374985 step=0.100000
2017/08/26 01:56:32 step 2: mse=0.360521 step=0.100000
2017/08/26 01:56:33 step 3: mse=0.346631 step=0.100000
2017/08/26 01:56:35 step 4: mse=0.336843 step=0.100000
2017/08/26 01:56:37 step 5: mse=0.325028 step=0.100000
2017/08/26 01:56:38 step 6: mse=0.317081 step=0.100000
2017/08/26 01:56:40 step 7: mse=0.308010 step=0.100000
2017/08/26 01:56:40 Saving...
2017/08/26 01:56:40 Gathering batch of experience...
2017/08/26 01:56:52 batch 35: mean=9.963636 stddev=3.196382 entropy=1.232316 frames=34807 count=55
2017/08/26 01:56:52 Training policy...
2017/08/26 01:56:57 step 0: objective=0.04028642
2017/08/26 01:57:00 step 1: objective=0.04032438
2017/08/26 01:57:04 step 2: objective=0.040361885
2017/08/26 01:57:08 step 3: objective=0.04039728
2017/08/26 01:57:11 step 4: objective=0.04043489
2017/08/26 01:57:15 step 5: objective=0.040470187
2017/08/26 01:57:18 step 6: objective=0.040505044
2017/08/26 01:57:22 step 7: objective=0.040542826
2017/08/26 01:57:22 Training value function...
2017/08/26 01:57:24 step 0: mse=0.397273 step=0.100000
2017/08/26 01:57:26 step 1: mse=0.373610 step=0.100000
2017/08/26 01:57:27 step 2: mse=0.354205 step=0.100000
2017/08/26 01:57:29 step 3: mse=0.340123 step=0.100000
2017/08/26 01:57:31 step 4: mse=0.328491 step=0.100000
2017/08/26 01:57:32 step 5: mse=0.317858 step=0.100000
2017/08/26 01:57:34 step 6: mse=0.308973 step=0.100000
2017/08/26 01:57:36 step 7: mse=0.299850 step=0.100000
2017/08/26 01:57:36 Saving...
2017/08/26 01:57:36 Gathering batch of experience...
2017/08/26 01:57:48 batch 36: mean=10.072727 stddev=3.774819 entropy=1.233516 frames=35023 count=55
2017/08/26 01:57:48 Training policy...
2017/08/26 01:57:53 step 0: objective=0.03820812
2017/08/26 01:57:57 step 1: objective=0.03823774
2017/08/26 01:58:00 step 2: objective=0.038267605
2017/08/26 01:58:04 step 3: objective=0.038297348
2017/08/26 01:58:08 step 4: objective=0.038327124
2017/08/26 01:58:12 step 5: objective=0.038356952
2017/08/26 01:58:15 step 6: objective=0.03838586
2017/08/26 01:58:19 step 7: objective=0.038413085
2017/08/26 01:58:19 Training value function...
2017/08/26 01:58:21 step 0: mse=0.446406 step=0.100000
2017/08/26 01:58:23 step 1: mse=0.422841 step=0.100000
2017/08/26 01:58:25 step 2: mse=0.403597 step=0.100000
2017/08/26 01:58:26 step 3: mse=0.384992 step=0.100000
2017/08/26 01:58:28 step 4: mse=0.370821 step=0.100000
2017/08/26 01:58:30 step 5: mse=0.357131 step=0.100000
2017/08/26 01:58:31 step 6: mse=0.346403 step=0.100000
2017/08/26 01:58:33 step 7: mse=0.337042 step=0.100000
2017/08/26 01:58:33 Saving...
2017/08/26 01:58:33 Gathering batch of experience...
2017/08/26 01:58:46 batch 37: mean=8.900000 stddev=4.109745 entropy=1.233948 frames=34639 count=60
2017/08/26 01:58:46 Training policy...
2017/08/26 01:58:51 step 0: objective=0.019433774
2017/08/26 01:58:54 step 1: objective=0.01945495
2017/08/26 01:58:58 step 2: objective=0.019476019
2017/08/26 01:59:02 step 3: objective=0.019497022
2017/08/26 01:59:05 step 4: objective=0.019518074
2017/08/26 01:59:10 step 5: objective=0.019538995
2017/08/26 01:59:13 step 6: objective=0.019559896
2017/08/26 01:59:17 step 7: objective=0.019580735
2017/08/26 01:59:17 Training value function...
2017/08/26 01:59:19 step 0: mse=0.524763 step=0.100000
2017/08/26 01:59:21 step 1: mse=0.486881 step=0.100000
2017/08/26 01:59:22 step 2: mse=0.456460 step=0.100000
2017/08/26 01:59:24 step 3: mse=0.431147 step=0.100000
2017/08/26 01:59:26 step 4: mse=0.411454 step=0.100000
2017/08/26 01:59:28 step 5: mse=0.395392 step=0.100000
2017/08/26 01:59:30 step 6: mse=0.382077 step=0.100000
2017/08/26 01:59:31 step 7: mse=0.369696 step=0.100000
2017/08/26 01:59:31 Saving...
2017/08/26 01:59:31 Gathering batch of experience...
2017/08/26 01:59:44 batch 38: mean=9.431034 stddev=3.625161 entropy=1.229425 frames=34772 count=58
2017/08/26 01:59:44 Training policy...
2017/08/26 01:59:48 step 0: objective=0.019568754
2017/08/26 01:59:52 step 1: objective=0.01965163
2017/08/26 01:59:56 step 2: objective=0.019733915
2017/08/26 01:59:59 step 3: objective=0.019815734
2017/08/26 02:00:03 step 4: objective=0.019897062
2017/08/26 02:00:07 step 5: objective=0.019970328
2017/08/26 02:00:10 step 6: objective=0.020012917
2017/08/26 02:00:14 step 7: objective=0.020058038
2017/08/26 02:00:14 Training value function...
2017/08/26 02:00:16 step 0: mse=0.568535 step=0.100000
2017/08/26 02:00:18 step 1: mse=0.523042 step=0.100000
2017/08/26 02:00:20 step 2: mse=0.486384 step=0.100000
2017/08/26 02:00:22 step 3: mse=0.456925 step=0.100000
2017/08/26 02:00:23 step 4: mse=0.433431 step=0.100000
2017/08/26 02:00:25 step 5: mse=0.413797 step=0.100000
2017/08/26 02:00:27 step 6: mse=0.396521 step=0.100000
2017/08/26 02:00:29 step 7: mse=0.383594 step=0.100000
2017/08/26 02:00:29 Saving...
2017/08/26 02:00:29 Gathering batch of experience...
2017/08/26 02:00:41 batch 39: mean=9.839286 stddev=3.609396 entropy=1.234021 frames=34466 count=56
2017/08/26 02:00:41 Training policy...
2017/08/26 02:00:46 step 0: objective=0.029804809
2017/08/26 02:00:49 step 1: objective=0.029838912
2017/08/26 02:00:53 step 2: objective=0.029873148
2017/08/26 02:00:57 step 3: objective=0.029907096
2017/08/26 02:01:00 step 4: objective=0.029940926
2017/08/26 02:01:04 step 5: objective=0.029974775
2017/08/26 02:01:07 step 6: objective=0.030008359
2017/08/26 02:01:11 step 7: objective=0.030039629
2017/08/26 02:01:11 Training value function...
2017/08/26 02:01:13 step 0: mse=0.513324 step=0.100000
2017/08/26 02:01:15 step 1: mse=0.487478 step=0.100000
2017/08/26 02:01:17 step 2: mse=0.461287 step=0.100000
2017/08/26 02:01:19 step 3: mse=0.440108 step=0.100000
2017/08/26 02:01:20 step 4: mse=0.424621 step=0.100000
2017/08/26 02:01:22 step 5: mse=0.412128 step=0.100000
2017/08/26 02:01:24 step 6: mse=0.399044 step=0.100000
2017/08/26 02:01:26 step 7: mse=0.388178 step=0.100000
2017/08/26 02:01:26 Saving...
2017/08/26 02:01:26 Gathering batch of experience...
2017/08/26 02:01:38 batch 40: mean=10.000000 stddev=4.432733 entropy=1.228570 frames=35907 count=57
2017/08/26 02:01:38 Training policy...
2017/08/26 02:01:44 step 0: objective=0.028874557
2017/08/26 02:01:47 step 1: objective=0.028892197
2017/08/26 02:01:51 step 2: objective=0.028910005
2017/08/26 02:01:55 step 3: objective=0.028927714
2017/08/26 02:01:59 step 4: objective=0.028945435
2017/08/26 02:02:02 step 5: objective=0.028963171
2017/08/26 02:02:06 step 6: objective=0.028981034
2017/08/26 02:02:10 step 7: objective=0.028998664
2017/08/26 02:02:10 Training value function...
2017/08/26 02:02:12 step 0: mse=0.527782 step=0.100000
2017/08/26 02:02:14 step 1: mse=0.486403 step=0.100000
2017/08/26 02:02:16 step 2: mse=0.452994 step=0.100000
2017/08/26 02:02:18 step 3: mse=0.428027 step=0.100000
2017/08/26 02:02:20 step 4: mse=0.405961 step=0.100000
2017/08/26 02:02:22 step 5: mse=0.386836 step=0.100000
2017/08/26 02:02:23 step 6: mse=0.371348 step=0.100000
2017/08/26 02:02:25 step 7: mse=0.356865 step=0.100000
2017/08/26 02:02:25 Saving...
2017/08/26 02:02:25 Gathering batch of experience...
2017/08/26 02:02:38 batch 41: mean=10.018182 stddev=4.915619 entropy=1.228552 frames=35023 count=55
2017/08/26 02:02:38 Training policy...
2017/08/26 02:02:43 step 0: objective=0.025477108
2017/08/26 02:02:46 step 1: objective=0.025561752
2017/08/26 02:02:50 step 2: objective=0.025646983
2017/08/26 02:02:54 step 3: objective=0.025731573
2017/08/26 02:02:57 step 4: objective=0.02579879
2017/08/26 02:03:01 step 5: objective=0.02586026
2017/08/26 02:03:05 step 6: objective=0.025883676
2017/08/26 02:03:08 step 7: objective=0.02590602
2017/08/26 02:03:08 Training value function...
2017/08/26 02:03:11 step 0: mse=0.567579 step=0.100000
2017/08/26 02:03:13 step 1: mse=0.535470 step=0.100000
2017/08/26 02:03:14 step 2: mse=0.514994 step=0.100000
2017/08/26 02:03:16 step 3: mse=0.491204 step=0.100000
2017/08/26 02:03:18 step 4: mse=0.471906 step=0.100000
2017/08/26 02:03:20 step 5: mse=0.458414 step=0.100000
2017/08/26 02:03:22 step 6: mse=0.441863 step=0.100000
2017/08/26 02:03:24 step 7: mse=0.429415 step=0.100000
2017/08/26 02:03:24 Saving...
2017/08/26 02:03:24 Gathering batch of experience...
2017/08/26 02:03:36 batch 42: mean=9.660714 stddev=3.987824 entropy=1.225881 frames=35310 count=56
2017/08/26 02:03:36 Training policy...
2017/08/26 02:03:42 step 0: objective=0.013283046
2017/08/26 02:03:45 step 1: objective=0.013311415
2017/08/26 02:03:49 step 2: objective=0.013339748
2017/08/26 02:03:53 step 3: objective=0.013368303
2017/08/26 02:03:56 step 4: objective=0.013396915
2017/08/26 02:04:00 step 5: objective=0.013425619
2017/08/26 02:04:04 step 6: objective=0.013453914
2017/08/26 02:04:07 step 7: objective=0.013477726
2017/08/26 02:04:07 Training value function...
2017/08/26 02:04:10 step 0: mse=0.400012 step=0.100000
2017/08/26 02:04:12 step 1: mse=0.381995 step=0.100000
2017/08/26 02:04:14 step 2: mse=0.368431 step=0.100000
2017/08/26 02:04:16 step 3: mse=0.357447 step=0.100000
2017/08/26 02:04:17 step 4: mse=0.344579 step=0.100000
2017/08/26 02:04:19 step 5: mse=0.331266 step=0.100000
2017/08/26 02:04:21 step 6: mse=0.320458 step=0.100000
2017/08/26 02:04:23 step 7: mse=0.310822 step=0.100000
2017/08/26 02:04:23 Saving...
2017/08/26 02:04:23 Gathering batch of experience...
2017/08/26 02:04:36 batch 43: mean=9.517241 stddev=4.383517 entropy=1.230787 frames=35316 count=58
2017/08/26 02:04:36 Training policy...
2017/08/26 02:04:41 step 0: objective=0.03301779
2017/08/26 02:04:45 step 1: objective=0.033051927
2017/08/26 02:04:48 step 2: objective=0.033085965
2017/08/26 02:04:52 step 3: objective=0.033120118
2017/08/26 02:04:56 step 4: objective=0.033154353
2017/08/26 02:05:00 step 5: objective=0.033188898
2017/08/26 02:05:03 step 6: objective=0.033224307
2017/08/26 02:05:07 step 7: objective=0.033258945
2017/08/26 02:05:07 Training value function...
2017/08/26 02:05:10 step 0: mse=0.440655 step=0.100000
2017/08/26 02:05:12 step 1: mse=0.414100 step=0.100000
2017/08/26 02:05:13 step 2: mse=0.393010 step=0.100000
2017/08/26 02:05:15 step 3: mse=0.375826 step=0.100000
2017/08/26 02:05:17 step 4: mse=0.362004 step=0.100000
2017/08/26 02:05:19 step 5: mse=0.349816 step=0.100000
2017/08/26 02:05:21 step 6: mse=0.338917 step=0.100000
2017/08/26 02:05:23 step 7: mse=0.330415 step=0.100000
2017/08/26 02:05:23 Saving...
2017/08/26 02:05:23 Gathering batch of experience...
2017/08/26 02:05:36 batch 44: mean=9.254237 stddev=3.462111 entropy=1.229949 frames=34446 count=59
2017/08/26 02:05:36 Training policy...
2017/08/26 02:05:41 step 0: objective=0.02408411
2017/08/26 02:05:44 step 1: objective=0.024156164
2017/08/26 02:05:48 step 2: objective=0.024227995
2017/08/26 02:05:52 step 3: objective=0.024294475
2017/08/26 02:05:55 step 4: objective=0.024320247
2017/08/26 02:05:59 step 5: objective=0.024351917
2017/08/26 02:06:03 step 6: objective=0.024383308
2017/08/26 02:06:06 step 7: objective=0.024414107
2017/08/26 02:06:06 Training value function...
2017/08/26 02:06:09 step 0: mse=0.406599 step=0.100000
2017/08/26 02:06:11 step 1: mse=0.399170 step=0.100000
2017/08/26 02:06:13 step 2: mse=0.384265 step=0.100000
2017/08/26 02:06:14 step 3: mse=0.371236 step=0.100000
2017/08/26 02:06:16 step 4: mse=0.360785 step=0.100000
2017/08/26 02:06:18 step 5: mse=0.356901 step=0.100000
2017/08/26 02:06:20 step 6: mse=0.349804 step=0.100000
2017/08/26 02:06:22 step 7: mse=0.342954 step=0.100000
2017/08/26 02:06:22 Saving...
2017/08/26 02:06:22 Gathering batch of experience...
2017/08/26 02:06:34 batch 45: mean=10.509434 stddev=3.868707 entropy=1.228066 frames=34702 count=53
2017/08/26 02:06:34 Training policy...
2017/08/26 02:06:39 step 0: objective=0.034782436
2017/08/26 02:06:43 step 1: objective=0.034812465
2017/08/26 02:06:47 step 2: objective=0.034842335
2017/08/26 02:06:51 step 3: objective=0.034872506
2017/08/26 02:06:54 step 4: objective=0.03490292
2017/08/26 02:06:58 step 5: objective=0.034933694
2017/08/26 02:07:02 step 6: objective=0.034961913
2017/08/26 02:07:05 step 7: objective=0.03500979
2017/08/26 02:07:05 Training value function...
2017/08/26 02:07:08 step 0: mse=0.541658 step=0.100000
2017/08/26 02:07:10 step 1: mse=0.515104 step=0.100000
2017/08/26 02:07:12 step 2: mse=0.489517 step=0.100000
2017/08/26 02:07:14 step 3: mse=0.468898 step=0.100000
2017/08/26 02:07:16 step 4: mse=0.450040 step=0.100000
2017/08/26 02:07:18 step 5: mse=0.433988 step=0.100000
2017/08/26 02:07:20 step 6: mse=0.419778 step=0.100000
2017/08/26 02:07:22 step 7: mse=0.409367 step=0.100000
2017/08/26 02:07:22 Saving...
2017/08/26 02:07:22 Gathering batch of experience...
2017/08/26 02:07:34 batch 46: mean=9.421053 stddev=4.026000 entropy=1.229032 frames=34377 count=57
2017/08/26 02:07:34 Training policy...
2017/08/26 02:07:39 step 0: objective=0.016737977
2017/08/26 02:07:43 step 1: objective=0.016786003
2017/08/26 02:07:46 step 2: objective=0.016834503
2017/08/26 02:07:50 step 3: objective=0.01688335
2017/08/26 02:07:54 step 4: objective=0.016932456
2017/08/26 02:07:58 step 5: objective=0.016980615
2017/08/26 02:08:01 step 6: objective=0.017020386
2017/08/26 02:08:05 step 7: objective=0.017044801
2017/08/26 02:08:05 Training value function...
2017/08/26 02:08:07 step 0: mse=0.420148 step=0.100000
2017/08/26 02:08:09 step 1: mse=0.392221 step=0.100000
2017/08/26 02:08:11 step 2: mse=0.369792 step=0.100000
2017/08/26 02:08:13 step 3: mse=0.349404 step=0.100000
2017/08/26 02:08:15 step 4: mse=0.333672 step=0.100000
2017/08/26 02:08:17 step 5: mse=0.320754 step=0.100000
2017/08/26 02:08:19 step 6: mse=0.307360 step=0.100000
2017/08/26 02:08:21 step 7: mse=0.296459 step=0.100000
2017/08/26 02:08:21 Saving...
2017/08/26 02:08:21 Gathering batch of experience...
2017/08/26 02:08:34 batch 47: mean=10.600000 stddev=4.413203 entropy=1.226080 frames=35401 count=55
2017/08/26 02:08:34 Training policy...
2017/08/26 02:08:39 step 0: objective=0.044434104
2017/08/26 02:08:43 step 1: objective=0.044477157
2017/08/26 02:08:47 step 2: objective=0.044519868
2017/08/26 02:08:50 step 3: objective=0.044562206
2017/08/26 02:08:54 step 4: objective=0.044603623
2017/08/26 02:08:58 step 5: objective=0.044645216
2017/08/26 02:09:02 step 6: objective=0.04468494
2017/08/26 02:09:06 step 7: objective=0.044725258
2017/08/26 02:09:06 Training value function...
2017/08/26 02:09:08 step 0: mse=0.559636 step=0.100000
2017/08/26 02:09:10 step 1: mse=0.526189 step=0.100000
2017/08/26 02:09:12 step 2: mse=0.498909 step=0.100000
2017/08/26 02:09:14 step 3: mse=0.476506 step=0.100000
2017/08/26 02:09:16 step 4: mse=0.450543 step=0.100000
2017/08/26 02:09:18 step 5: mse=0.430046 step=0.100000
2017/08/26 02:09:20 step 6: mse=0.411781 step=0.100000
2017/08/26 02:09:22 step 7: mse=0.399639 step=0.100000
2017/08/26 02:09:22 Saving...
2017/08/26 02:09:22 Gathering batch of experience...
2017/08/26 02:09:35 batch 48: mean=9.389831 stddev=4.426488 entropy=1.224992 frames=35313 count=59
2017/08/26 02:09:35 Training policy...
2017/08/26 02:09:40 step 0: objective=0.011315984
2017/08/26 02:09:44 step 1: objective=0.011376142
2017/08/26 02:09:48 step 2: objective=0.011436725
2017/08/26 02:09:51 step 3: objective=0.011491757
2017/08/26 02:09:55 step 4: objective=0.011545052
2017/08/26 02:09:59 step 5: objective=0.0115872435
2017/08/26 02:10:03 step 6: objective=0.011626661
2017/08/26 02:10:07 step 7: objective=0.01166526
2017/08/26 02:10:07 Training value function...
2017/08/26 02:10:09 step 0: mse=0.538195 step=0.100000
2017/08/26 02:10:12 step 1: mse=0.515328 step=0.100000
2017/08/26 02:10:14 step 2: mse=0.494797 step=0.100000
2017/08/26 02:10:16 step 3: mse=0.461854 step=0.100000
2017/08/26 02:10:18 step 4: mse=0.434830 step=0.100000
2017/08/26 02:10:20 step 5: mse=0.422571 step=0.100000
2017/08/26 02:10:22 step 6: mse=0.402220 step=0.100000
2017/08/26 02:10:24 step 7: mse=0.394029 step=0.100000
2017/08/26 02:10:24 Saving...
2017/08/26 02:10:24 Gathering batch of experience...
2017/08/26 02:10:37 batch 49: mean=9.051724 stddev=3.984550 entropy=1.223152 frames=34238 count=58
2017/08/26 02:10:37 Training policy...
2017/08/26 02:10:42 step 0: objective=0.016084405
2017/08/26 02:10:45 step 1: objective=0.016109603
2017/08/26 02:10:49 step 2: objective=0.016138796
2017/08/26 02:10:53 step 3: objective=0.016167989
2017/08/26 02:10:57 step 4: objective=0.016197233
2017/08/26 02:11:00 step 5: objective=0.016226608
2017/08/26 02:11:04 step 6: objective=0.016256036
2017/08/26 02:11:08 step 7: objective=0.01628517
2017/08/26 02:11:08 Training value function...
2017/08/26 02:11:10 step 0: mse=0.457573 step=0.100000
2017/08/26 02:11:12 step 1: mse=0.438361 step=0.100000
2017/08/26 02:11:14 step 2: mse=0.423167 step=0.100000
2017/08/26 02:11:16 step 3: mse=0.409125 step=0.100000
2017/08/26 02:11:18 step 4: mse=0.401110 step=0.100000
2017/08/26 02:11:20 step 5: mse=0.393859 step=0.100000
2017/08/26 02:11:22 step 6: mse=0.381976 step=0.100000
2017/08/26 02:11:24 step 7: mse=0.376627 step=0.100000
2017/08/26 02:11:24 Saving...
2017/08/26 02:11:24 Gathering batch of experience...
2017/08/26 02:11:37 batch 50: mean=9.474576 stddev=3.958924 entropy=1.227591 frames=35021 count=59
2017/08/26 02:11:37 Training policy...
2017/08/26 02:11:42 step 0: objective=0.028502088
2017/08/26 02:11:46 step 1: objective=0.028547278
2017/08/26 02:11:50 step 2: objective=0.02859228
2017/08/26 02:11:54 step 3: objective=0.028637184
2017/08/26 02:11:58 step 4: objective=0.02868236
2017/08/26 02:12:02 step 5: objective=0.028727334
2017/08/26 02:12:06 step 6: objective=0.028772438
2017/08/26 02:12:09 step 7: objective=0.028817583
2017/08/26 02:12:09 Training value function...
2017/08/26 02:12:12 step 0: mse=0.494237 step=0.100000
2017/08/26 02:12:14 step 1: mse=0.476796 step=0.100000
2017/08/26 02:12:16 step 2: mse=0.462195 step=0.100000
2017/08/26 02:12:18 step 3: mse=0.449325 step=0.100000
2017/08/26 02:12:20 step 4: mse=0.433947 step=0.100000
2017/08/26 02:12:22 step 5: mse=0.423845 step=0.100000
2017/08/26 02:12:25 step 6: mse=0.416718 step=0.100000
2017/08/26 02:12:27 step 7: mse=0.403986 step=0.100000
2017/08/26 02:12:27 Saving...
2017/08/26 02:12:27 Gathering batch of experience...
2017/08/26 02:12:39 batch 51: mean=9.631579 stddev=4.257631 entropy=1.221827 frames=35516 count=57
2017/08/26 02:12:39 Training policy...
2017/08/26 02:12:45 step 0: objective=0.0107222125
2017/08/26 02:12:49 step 1: objective=0.010759675
2017/08/26 02:12:52 step 2: objective=0.0107968245
2017/08/26 02:12:56 step 3: objective=0.010833927
2017/08/26 02:13:00 step 4: objective=0.010870946
2017/08/26 02:13:04 step 5: objective=0.010907841
2017/08/26 02:13:08 step 6: objective=0.010944766
2017/08/26 02:13:12 step 7: objective=0.010981516
2017/08/26 02:13:12 Training value function...
2017/08/26 02:13:14 step 0: mse=0.441043 step=0.100000
2017/08/26 02:13:17 step 1: mse=0.421485 step=0.100000
2017/08/26 02:13:19 step 2: mse=0.402583 step=0.100000
2017/08/26 02:13:21 step 3: mse=0.386840 step=0.100000
2017/08/26 02:13:23 step 4: mse=0.373537 step=0.100000
2017/08/26 02:13:26 step 5: mse=0.364637 step=0.100000
2017/08/26 02:13:28 step 6: mse=0.354900 step=0.100000
2017/08/26 02:13:30 step 7: mse=0.348499 step=0.100000
2017/08/26 02:13:30 Saving...
2017/08/26 02:13:30 Gathering batch of experience...
2017/08/26 02:13:43 batch 52: mean=10.145455 stddev=3.796736 entropy=1.222786 frames=35076 count=55
2017/08/26 02:13:43 Training policy...
2017/08/26 02:13:48 step 0: objective=0.02590674
2017/08/26 02:13:52 step 1: objective=0.025927216
2017/08/26 02:13:56 step 2: objective=0.025947645
2017/08/26 02:13:59 step 3: objective=0.025968252
2017/08/26 02:14:03 step 4: objective=0.025988685
2017/08/26 02:14:07 step 5: objective=0.026009034
2017/08/26 02:14:11 step 6: objective=0.026029749
2017/08/26 02:14:15 step 7: objective=0.026049692
2017/08/26 02:14:15 Training value function...
2017/08/26 02:14:17 step 0: mse=0.395963 step=0.100000
2017/08/26 02:14:20 step 1: mse=0.382689 step=0.100000
2017/08/26 02:14:22 step 2: mse=0.371742 step=0.100000
2017/08/26 02:14:24 step 3: mse=0.362369 step=0.100000
panic: first argument must be slice pointer

goroutine 34 [running]:
github.com/unixpickle/essentials.OrderedDelete(0x7b2e20, 0xc4253be020, 0x0)
	/home/alex/go/src/github.com/unixpickle/essentials/deletion.go:41 +0xf0
github.com/unixpickle/treeagent.(*Forest).RemoveFirst(0xc42001a2d0)
	/home/alex/go/src/github.com/unixpickle/treeagent/forest.go:45 +0x62
main.decayForest(0xc42000aa00, 0xc42001a2d0)
	/home/alex/go/src/github.com/unixpickle/treeagent/experiments/game_ppo/main.go:214 +0x5f
main.main.func2(0xc4207fc5c0, 0xc420070c00, 0x8, 0x8, 0xc42000aa00, 0xc420648f20, 0xc4200f9250, 0xc42001afa0, 0xc42001b040, 0xc42001a2d0, ...)
	/home/alex/go/src/github.com/unixpickle/treeagent/experiments/game_ppo/main.go:161 +0xa6e
created by main.main
	/home/alex/go/src/github.com/unixpickle/treeagent/experiments/game_ppo/main.go:182 +0xcd1
exit status 2
2017/08/26 02:22:40 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.99 -maxtrees 500]
2017/08/26 02:22:40 Creating environments...
2017/08/26 02:22:43 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/26 02:22:43 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/26 02:22:43 Running. Press Ctrl+C to stop.
2017/08/26 02:22:43 Gathering batch of experience...
2017/08/26 02:22:55 batch 0: mean=9.491228 stddev=4.437175 entropy=1.223115 frames=34356 count=57
2017/08/26 02:22:55 Training policy...
2017/08/26 02:23:00 step 0: objective=0.027002877
2017/08/26 02:23:04 step 1: objective=0.02703378
2017/08/26 02:23:07 step 2: objective=0.027064
2017/08/26 02:23:11 step 3: objective=0.027093943
2017/08/26 02:23:15 step 4: objective=0.027123649
2017/08/26 02:23:19 step 5: objective=0.027153498
2017/08/26 02:23:22 step 6: objective=0.027182903
2017/08/26 02:23:26 step 7: objective=0.027210662
2017/08/26 02:23:26 Training value function...
2017/08/26 02:23:29 step 0: mse=0.514929 step=0.100000
2017/08/26 02:23:31 step 1: mse=0.487298 step=0.100000
2017/08/26 02:23:33 step 2: mse=0.465064 step=0.100000
2017/08/26 02:23:35 step 3: mse=0.446933 step=0.100000
2017/08/26 02:23:37 step 4: mse=0.427451 step=0.100000
2017/08/26 02:23:39 step 5: mse=0.411635 step=0.100000
2017/08/26 02:23:41 step 6: mse=0.401957 step=0.100000
2017/08/26 02:23:43 step 7: mse=0.393467 step=0.100000
2017/08/26 02:23:43 Saving...
2017/08/26 02:23:43 Gathering batch of experience...
2017/08/26 02:23:56 batch 1: mean=9.224138 stddev=3.444351 entropy=1.221377 frames=34206 count=58
2017/08/26 02:23:56 Training policy...
2017/08/26 02:24:01 step 0: objective=0.02103562
2017/08/26 02:24:05 step 1: objective=0.021078445
2017/08/26 02:24:08 step 2: objective=0.02112895
2017/08/26 02:24:12 step 3: objective=0.021171035
2017/08/26 02:24:16 step 4: objective=0.021220759
2017/08/26 02:24:20 step 5: objective=0.021270249
2017/08/26 02:24:23 step 6: objective=0.021319415
2017/08/26 02:24:27 step 7: objective=0.021366542
2017/08/26 02:24:27 Training value function...
2017/08/26 02:24:30 step 0: mse=0.470488 step=0.100000
2017/08/26 02:24:32 step 1: mse=0.449714 step=0.100000
2017/08/26 02:24:34 step 2: mse=0.432894 step=0.100000
2017/08/26 02:24:36 step 3: mse=0.417474 step=0.100000
2017/08/26 02:24:38 step 4: mse=0.404883 step=0.100000
2017/08/26 02:24:40 step 5: mse=0.392528 step=0.100000
2017/08/26 02:24:42 step 6: mse=0.383091 step=0.100000
2017/08/26 02:24:44 step 7: mse=0.373182 step=0.100000
2017/08/26 02:24:44 Saving...
2017/08/26 02:24:44 Gathering batch of experience...
2017/08/26 02:24:57 batch 2: mean=10.000000 stddev=4.803016 entropy=1.215885 frames=35217 count=58
2017/08/26 02:24:57 Training policy...
2017/08/26 02:25:02 step 0: objective=0.044680513
2017/08/26 02:25:06 step 1: objective=0.04472921
2017/08/26 02:25:10 step 2: objective=0.0447806
2017/08/26 02:25:14 step 3: objective=0.044829685
2017/08/26 02:25:18 step 4: objective=0.044881634
2017/08/26 02:25:22 step 5: objective=0.044917554
2017/08/26 02:25:26 step 6: objective=0.044959247
2017/08/26 02:25:30 step 7: objective=0.04501135
2017/08/26 02:25:30 Training value function...
2017/08/26 02:25:32 step 0: mse=0.855793 step=0.100000
2017/08/26 02:25:35 step 1: mse=0.782110 step=0.100000
2017/08/26 02:25:37 step 2: mse=0.726256 step=0.100000
2017/08/26 02:25:39 step 3: mse=0.687440 step=0.100000
2017/08/26 02:25:41 step 4: mse=0.639976 step=0.100000
2017/08/26 02:25:43 step 5: mse=0.604154 step=0.100000
2017/08/26 02:25:45 step 6: mse=0.574872 step=0.100000
2017/08/26 02:25:48 step 7: mse=0.541310 step=0.100000
2017/08/26 02:25:48 Saving...
2017/08/26 02:25:48 Gathering batch of experience...
2017/08/26 02:26:00 batch 3: mean=9.553571 stddev=4.447791 entropy=1.218517 frames=34636 count=56
2017/08/26 02:26:00 Training policy...
2017/08/26 02:26:05 step 0: objective=0.020389518
2017/08/26 02:26:09 step 1: objective=0.020448526
2017/08/26 02:26:13 step 2: objective=0.02050724
2017/08/26 02:26:17 step 3: objective=0.020565398
2017/08/26 02:26:21 step 4: objective=0.020622268
2017/08/26 02:26:24 step 5: objective=0.020668283
2017/08/26 02:26:28 step 6: objective=0.020694656
2017/08/26 02:26:32 step 7: objective=0.020733684
2017/08/26 02:26:32 Training value function...
2017/08/26 02:26:35 step 0: mse=0.521826 step=0.100000
2017/08/26 02:26:37 step 1: mse=0.480152 step=0.100000
2017/08/26 02:26:39 step 2: mse=0.450284 step=0.100000
2017/08/26 02:26:41 step 3: mse=0.426182 step=0.100000
2017/08/26 02:26:43 step 4: mse=0.407088 step=0.100000
2017/08/26 02:26:46 step 5: mse=0.385720 step=0.100000
2017/08/26 02:26:48 step 6: mse=0.371547 step=0.100000
2017/08/26 02:26:50 step 7: mse=0.360587 step=0.100000
2017/08/26 02:26:50 Saving...
2017/08/26 02:26:50 Gathering batch of experience...
2017/08/26 02:27:03 batch 4: mean=11.500000 stddev=4.618108 entropy=1.220597 frames=35128 count=52
2017/08/26 02:27:03 Training policy...
2017/08/26 02:27:08 step 0: objective=0.048168924
2017/08/26 02:27:12 step 1: objective=0.048233487
2017/08/26 02:27:16 step 2: objective=0.04829897
2017/08/26 02:27:20 step 3: objective=0.048364513
2017/08/26 02:27:24 step 4: objective=0.048430078
2017/08/26 02:27:27 step 5: objective=0.048495974
2017/08/26 02:27:31 step 6: objective=0.048557844
2017/08/26 02:27:35 step 7: objective=0.048619583
2017/08/26 02:27:35 Training value function...
2017/08/26 02:27:38 step 0: mse=0.667952 step=0.100000
2017/08/26 02:27:40 step 1: mse=0.632972 step=0.100000
2017/08/26 02:27:42 step 2: mse=0.604307 step=0.100000
2017/08/26 02:27:44 step 3: mse=0.580809 step=0.100000
2017/08/26 02:27:47 step 4: mse=0.557563 step=0.100000
2017/08/26 02:27:49 step 5: mse=0.541164 step=0.100000
2017/08/26 02:27:51 step 6: mse=0.521896 step=0.100000
2017/08/26 02:27:53 step 7: mse=0.508386 step=0.100000
2017/08/26 02:27:53 Saving...
2017/08/26 02:27:53 Gathering batch of experience...
2017/08/26 02:28:06 batch 5: mean=11.415094 stddev=4.619213 entropy=1.219897 frames=35496 count=53
2017/08/26 02:28:06 Training policy...
2017/08/26 02:28:11 step 0: objective=0.036824238
2017/08/26 02:28:15 step 1: objective=0.03691799
2017/08/26 02:28:19 step 2: objective=0.037011333
2017/08/26 02:28:23 step 3: objective=0.037104115
2017/08/26 02:28:27 step 4: objective=0.03718055
2017/08/26 02:28:31 step 5: objective=0.03721294
2017/08/26 02:28:35 step 6: objective=0.03725178
2017/08/26 02:28:39 step 7: objective=0.037286177
2017/08/26 02:28:39 Training value function...
2017/08/26 02:28:41 step 0: mse=0.697063 step=0.100000
2017/08/26 02:28:43 step 1: mse=0.641488 step=0.100000
2017/08/26 02:28:46 step 2: mse=0.596277 step=0.100000
2017/08/26 02:28:48 step 3: mse=0.560608 step=0.100000
2017/08/26 02:28:50 step 4: mse=0.529910 step=0.100000
2017/08/26 02:28:52 step 5: mse=0.504712 step=0.100000
2017/08/26 02:28:54 step 6: mse=0.482708 step=0.100000
2017/08/26 02:28:56 step 7: mse=0.460033 step=0.100000
2017/08/26 02:28:56 Saving...
2017/08/26 02:28:56 Gathering batch of experience...
2017/08/26 02:29:08 batch 6: mean=9.836364 stddev=3.878911 entropy=1.218824 frames=34925 count=55
2017/08/26 02:29:08 Training policy...
2017/08/26 02:29:14 step 0: objective=0.0048334897
2017/08/26 02:29:18 step 1: objective=0.0048777517
2017/08/26 02:29:21 step 2: objective=0.004921885
2017/08/26 02:29:25 step 3: objective=0.0049658567
2017/08/26 02:29:29 step 4: objective=0.0050097364
2017/08/26 02:29:33 step 5: objective=0.0050533926
2017/08/26 02:29:36 step 6: objective=0.0050951876
2017/08/26 02:29:40 step 7: objective=0.0051323045
2017/08/26 02:29:40 Training value function...
2017/08/26 02:29:43 step 0: mse=0.429579 step=0.100000
2017/08/26 02:29:45 step 1: mse=0.406459 step=0.100000
2017/08/26 02:29:47 step 2: mse=0.388937 step=0.100000
2017/08/26 02:29:49 step 3: mse=0.373846 step=0.100000
2017/08/26 02:29:51 step 4: mse=0.362239 step=0.100000
2017/08/26 02:29:53 step 5: mse=0.349809 step=0.100000
2017/08/26 02:29:55 step 6: mse=0.335905 step=0.100000
2017/08/26 02:29:57 step 7: mse=0.324278 step=0.100000
2017/08/26 02:29:57 Saving...
2017/08/26 02:29:57 Gathering batch of experience...
2017/08/26 02:30:09 batch 7: mean=9.396552 stddev=3.699672 entropy=1.211184 frames=34832 count=58
2017/08/26 02:30:09 Training policy...
2017/08/26 02:30:15 step 0: objective=0.00981349
2017/08/26 02:30:18 step 1: objective=0.0098377
2017/08/26 02:30:22 step 2: objective=0.009861929
2017/08/26 02:30:26 step 3: objective=0.009886092
2017/08/26 02:30:30 step 4: objective=0.009910214
2017/08/26 02:30:34 step 5: objective=0.00993429
2017/08/26 02:30:37 step 6: objective=0.00995835
2017/08/26 02:30:41 step 7: objective=0.009981983
2017/08/26 02:30:41 Training value function...
2017/08/26 02:30:44 step 0: mse=0.440067 step=0.100000
2017/08/26 02:30:46 step 1: mse=0.423886 step=0.100000
2017/08/26 02:30:48 step 2: mse=0.409535 step=0.100000
2017/08/26 02:30:50 step 3: mse=0.399276 step=0.100000
2017/08/26 02:30:52 step 4: mse=0.391941 step=0.100000
2017/08/26 02:30:54 step 5: mse=0.378704 step=0.100000
2017/08/26 02:30:56 step 6: mse=0.368036 step=0.100000
2017/08/26 02:30:58 step 7: mse=0.359403 step=0.100000
2017/08/26 02:30:58 Saving...
2017/08/26 02:30:58 Gathering batch of experience...
2017/08/26 02:31:10 batch 8: mean=9.928571 stddev=3.821262 entropy=1.217654 frames=34487 count=56
2017/08/26 02:31:10 Training policy...
2017/08/26 02:31:16 step 0: objective=0.027934415
2017/08/26 02:31:19 step 1: objective=0.02798485
2017/08/26 02:31:23 step 2: objective=0.02803515
2017/08/26 02:31:27 step 3: objective=0.02808551
2017/08/26 02:31:31 step 4: objective=0.028135352
2017/08/26 02:31:34 step 5: objective=0.028183762
2017/08/26 02:31:38 step 6: objective=0.028239585
2017/08/26 02:31:42 step 7: objective=0.028293453
2017/08/26 02:31:42 Training value function...
2017/08/26 02:31:44 step 0: mse=0.534948 step=0.100000
2017/08/26 02:31:46 step 1: mse=0.503131 step=0.100000
2017/08/26 02:31:48 step 2: mse=0.479102 step=0.100000
2017/08/26 02:31:50 step 3: mse=0.456386 step=0.100000
2017/08/26 02:31:53 step 4: mse=0.437884 step=0.100000
2017/08/26 02:31:55 step 5: mse=0.421410 step=0.100000
2017/08/26 02:31:57 step 6: mse=0.411641 step=0.100000
2017/08/26 02:31:59 step 7: mse=0.403694 step=0.100000
2017/08/26 02:31:59 Saving...
2017/08/26 02:31:59 Gathering batch of experience...
2017/08/26 02:32:11 batch 9: mean=9.241379 stddev=4.145252 entropy=1.213046 frames=34788 count=58
2017/08/26 02:32:11 Training policy...
2017/08/26 02:32:16 step 0: objective=0.018973136
2017/08/26 02:32:20 step 1: objective=0.019032646
2017/08/26 02:32:24 step 2: objective=0.019092396
2017/08/26 02:32:28 step 3: objective=0.01915234
2017/08/26 02:32:32 step 4: objective=0.019212145
2017/08/26 02:32:36 step 5: objective=0.019248528
2017/08/26 02:32:39 step 6: objective=0.019277476
2017/08/26 02:32:43 step 7: objective=0.019310597
2017/08/26 02:32:43 Training value function...
2017/08/26 02:32:46 step 0: mse=0.373084 step=0.100000
2017/08/26 02:32:48 step 1: mse=0.352822 step=0.100000
2017/08/26 02:32:50 step 2: mse=0.335587 step=0.100000
2017/08/26 02:32:52 step 3: mse=0.321563 step=0.100000
2017/08/26 02:32:54 step 4: mse=0.309421 step=0.100000
2017/08/26 02:32:56 step 5: mse=0.300415 step=0.100000
2017/08/26 02:32:58 step 6: mse=0.291659 step=0.100000
2017/08/26 02:33:00 step 7: mse=0.284672 step=0.100000
2017/08/26 02:33:00 Saving...
2017/08/26 02:33:00 Gathering batch of experience...
2017/08/26 02:33:13 batch 10: mean=10.250000 stddev=4.054319 entropy=1.215731 frames=34801 count=56
2017/08/26 02:33:13 Training policy...
2017/08/26 02:33:18 step 0: objective=0.03887913
2017/08/26 02:33:22 step 1: objective=0.03894261
2017/08/26 02:33:26 step 2: objective=0.03900534
2017/08/26 02:33:30 step 3: objective=0.039067566
2017/08/26 02:33:34 step 4: objective=0.039127994
2017/08/26 02:33:38 step 5: objective=0.03915724
2017/08/26 02:33:41 step 6: objective=0.039184637
2017/08/26 02:33:45 step 7: objective=0.039208524
2017/08/26 02:33:45 Training value function...
2017/08/26 02:33:48 step 0: mse=0.597699 step=0.100000
2017/08/26 02:33:50 step 1: mse=0.570799 step=0.100000
2017/08/26 02:33:52 step 2: mse=0.545181 step=0.100000
2017/08/26 02:33:54 step 3: mse=0.521571 step=0.100000
2017/08/26 02:33:56 step 4: mse=0.501166 step=0.100000
2017/08/26 02:33:58 step 5: mse=0.488053 step=0.100000
2017/08/26 02:34:00 step 6: mse=0.475924 step=0.100000
2017/08/26 02:34:02 step 7: mse=0.464058 step=0.100000
2017/08/26 02:34:02 Saving...
2017/08/26 02:34:02 Gathering batch of experience...
2017/08/26 02:34:15 batch 11: mean=10.750000 stddev=4.539887 entropy=1.215507 frames=34573 count=52
2017/08/26 02:34:15 Training policy...
2017/08/26 02:34:20 step 0: objective=0.032582317
2017/08/26 02:34:24 step 1: objective=0.032615956
2017/08/26 02:34:28 step 2: objective=0.032649953
2017/08/26 02:34:31 step 3: objective=0.032683846
2017/08/26 02:34:35 step 4: objective=0.032718487
2017/08/26 02:34:39 step 5: objective=0.032748654
2017/08/26 02:34:43 step 6: objective=0.032768797
2017/08/26 02:34:47 step 7: objective=0.032788865
2017/08/26 02:34:47 Training value function...
2017/08/26 02:34:49 step 0: mse=0.478101 step=0.100000
2017/08/26 02:34:51 step 1: mse=0.461035 step=0.100000
2017/08/26 02:34:53 step 2: mse=0.442567 step=0.100000
2017/08/26 02:34:55 step 3: mse=0.430747 step=0.100000
2017/08/26 02:34:57 step 4: mse=0.412344 step=0.100000
2017/08/26 02:34:59 step 5: mse=0.394372 step=0.100000
2017/08/26 02:35:01 step 6: mse=0.380265 step=0.100000
2017/08/26 02:35:04 step 7: mse=0.370329 step=0.100000
2017/08/26 02:35:04 Saving...
2017/08/26 02:35:04 Gathering batch of experience...
2017/08/26 02:35:16 batch 12: mean=11.037736 stddev=6.124378 entropy=1.214659 frames=35094 count=53
2017/08/26 02:35:16 Training policy...
2017/08/26 02:35:21 step 0: objective=0.033767562
2017/08/26 02:35:25 step 1: objective=0.03381469
2017/08/26 02:35:29 step 2: objective=0.033862047
2017/08/26 02:35:33 step 3: objective=0.033908956
2017/08/26 02:35:37 step 4: objective=0.033954192
2017/08/26 02:35:41 step 5: objective=0.033987876
2017/08/26 02:35:45 step 6: objective=0.034012623
2017/08/26 02:35:48 step 7: objective=0.03403636
2017/08/26 02:35:48 Training value function...
2017/08/26 02:35:51 step 0: mse=0.872845 step=0.100000
2017/08/26 02:35:53 step 1: mse=0.787007 step=0.100000
2017/08/26 02:35:55 step 2: mse=0.707823 step=0.100000
2017/08/26 02:35:57 step 3: mse=0.650918 step=0.100000
2017/08/26 02:36:00 step 4: mse=0.603232 step=0.100000
2017/08/26 02:36:02 step 5: mse=0.556565 step=0.100000
2017/08/26 02:36:04 step 6: mse=0.519166 step=0.100000
2017/08/26 02:36:06 step 7: mse=0.489981 step=0.100000
2017/08/26 02:36:06 Saving...
2017/08/26 02:36:06 Gathering batch of experience...
2017/08/26 02:36:18 batch 13: mean=9.750000 stddev=3.631460 entropy=1.211856 frames=34861 count=56
2017/08/26 02:36:18 Training policy...
2017/08/26 02:36:24 step 0: objective=0.013217227
2017/08/26 02:36:27 step 1: objective=0.013264041
2017/08/26 02:36:31 step 2: objective=0.013310978
2017/08/26 02:36:35 step 3: objective=0.013357942
2017/08/26 02:36:39 step 4: objective=0.0134050315
2017/08/26 02:36:43 step 5: objective=0.01345214
2017/08/26 02:36:47 step 6: objective=0.013497466
2017/08/26 02:36:51 step 7: objective=0.01353775
2017/08/26 02:36:51 Training value function...
2017/08/26 02:36:53 step 0: mse=0.475083 step=0.100000
2017/08/26 02:36:56 step 1: mse=0.444643 step=0.100000
2017/08/26 02:36:58 step 2: mse=0.420115 step=0.100000
2017/08/26 02:37:00 step 3: mse=0.400486 step=0.100000
2017/08/26 02:37:02 step 4: mse=0.383912 step=0.100000
2017/08/26 02:37:04 step 5: mse=0.372110 step=0.100000
2017/08/26 02:37:06 step 6: mse=0.363306 step=0.100000
2017/08/26 02:37:08 step 7: mse=0.355024 step=0.100000
2017/08/26 02:37:08 Saving...
2017/08/26 02:37:08 Gathering batch of experience...
2017/08/26 02:37:21 batch 14: mean=10.333333 stddev=3.966232 entropy=1.211871 frames=35833 count=57
2017/08/26 02:37:21 Training policy...
2017/08/26 02:37:26 step 0: objective=0.019725736
2017/08/26 02:37:30 step 1: objective=0.019768067
2017/08/26 02:37:34 step 2: objective=0.019810524
2017/08/26 02:37:38 step 3: objective=0.01985316
2017/08/26 02:37:42 step 4: objective=0.019895853
2017/08/26 02:37:46 step 5: objective=0.019937525
2017/08/26 02:37:50 step 6: objective=0.019976314
2017/08/26 02:37:54 step 7: objective=0.020014906
2017/08/26 02:37:54 Training value function...
2017/08/26 02:37:57 step 0: mse=0.533525 step=0.100000
2017/08/26 02:37:59 step 1: mse=0.502975 step=0.100000
2017/08/26 02:38:01 step 2: mse=0.480981 step=0.100000
2017/08/26 02:38:03 step 3: mse=0.461424 step=0.100000
2017/08/26 02:38:05 step 4: mse=0.439729 step=0.100000
2017/08/26 02:38:07 step 5: mse=0.424066 step=0.100000
2017/08/26 02:38:10 step 6: mse=0.413360 step=0.100000
2017/08/26 02:38:12 step 7: mse=0.402213 step=0.100000
2017/08/26 02:38:12 Saving...
2017/08/26 02:38:12 Gathering batch of experience...
2017/08/26 02:38:24 batch 15: mean=10.072727 stddev=3.627444 entropy=1.211454 frames=34936 count=55
2017/08/26 02:38:24 Training policy...
2017/08/26 02:38:29 step 0: objective=0.017091164
2017/08/26 02:38:33 step 1: objective=0.017130494
2017/08/26 02:38:37 step 2: objective=0.017169748
2017/08/26 02:38:41 step 3: objective=0.017208971
2017/08/26 02:38:45 step 4: objective=0.01724797
2017/08/26 02:38:49 step 5: objective=0.017286683
2017/08/26 02:38:53 step 6: objective=0.017321287
2017/08/26 02:38:57 step 7: objective=0.017356452
2017/08/26 02:38:57 Training value function...
2017/08/26 02:38:59 step 0: mse=0.424042 step=0.100000
2017/08/26 02:39:01 step 1: mse=0.406772 step=0.100000
2017/08/26 02:39:04 step 2: mse=0.393064 step=0.100000
2017/08/26 02:39:06 step 3: mse=0.382129 step=0.100000
2017/08/26 02:39:08 step 4: mse=0.367392 step=0.100000
2017/08/26 02:39:10 step 5: mse=0.355497 step=0.100000
2017/08/26 02:39:12 step 6: mse=0.345117 step=0.100000
2017/08/26 02:39:14 step 7: mse=0.336275 step=0.100000
2017/08/26 02:39:14 Saving...
2017/08/26 02:39:14 Gathering batch of experience...
2017/08/26 02:39:26 batch 16: mean=9.944444 stddev=4.043361 entropy=1.213823 frames=34785 count=54
2017/08/26 02:39:26 Training policy...
2017/08/26 02:39:32 step 0: objective=0.0141269965
2017/08/26 02:39:36 step 1: objective=0.014153016
2017/08/26 02:39:39 step 2: objective=0.014178966
2017/08/26 02:39:43 step 3: objective=0.014205147
2017/08/26 02:39:47 step 4: objective=0.014231178
2017/08/26 02:39:51 step 5: objective=0.014257333
2017/08/26 02:39:55 step 6: objective=0.014282831
2017/08/26 02:39:59 step 7: objective=0.014304073
2017/08/26 02:39:59 Training value function...
2017/08/26 02:40:02 step 0: mse=0.445199 step=0.100000
2017/08/26 02:40:04 step 1: mse=0.414012 step=0.100000
2017/08/26 02:40:06 step 2: mse=0.385890 step=0.100000
2017/08/26 02:40:08 step 3: mse=0.362305 step=0.100000
2017/08/26 02:40:10 step 4: mse=0.342646 step=0.100000
2017/08/26 02:40:12 step 5: mse=0.324619 step=0.100000
2017/08/26 02:40:14 step 6: mse=0.309515 step=0.100000
2017/08/26 02:40:16 step 7: mse=0.295721 step=0.100000
2017/08/26 02:40:16 Saving...
2017/08/26 02:40:16 Gathering batch of experience...
2017/08/26 02:40:29 batch 17: mean=10.735849 stddev=3.972314 entropy=1.218065 frames=35120 count=53
2017/08/26 02:40:29 Training policy...
2017/08/26 02:40:34 step 0: objective=0.027521597
2017/08/26 02:40:38 step 1: objective=0.027553407
2017/08/26 02:40:42 step 2: objective=0.027585609
2017/08/26 02:40:46 step 3: objective=0.02761794
2017/08/26 02:40:50 step 4: objective=0.027650354
2017/08/26 02:40:54 step 5: objective=0.02768266
2017/08/26 02:40:58 step 6: objective=0.027712394
2017/08/26 02:41:02 step 7: objective=0.027734406
2017/08/26 02:41:02 Training value function...
2017/08/26 02:41:05 step 0: mse=0.585798 step=0.100000
2017/08/26 02:41:07 step 1: mse=0.543490 step=0.100000
2017/08/26 02:41:09 step 2: mse=0.507343 step=0.100000
2017/08/26 02:41:11 step 3: mse=0.476892 step=0.100000
2017/08/26 02:41:13 step 4: mse=0.452337 step=0.100000
2017/08/26 02:41:15 step 5: mse=0.431335 step=0.100000
2017/08/26 02:41:17 step 6: mse=0.413554 step=0.100000
2017/08/26 02:41:20 step 7: mse=0.396713 step=0.100000
2017/08/26 02:41:20 Saving...
2017/08/26 02:41:20 Gathering batch of experience...
2017/08/26 02:41:32 batch 18: mean=10.196429 stddev=4.572510 entropy=1.213509 frames=34679 count=56
2017/08/26 02:41:32 Training policy...
2017/08/26 02:41:37 step 0: objective=0.038056776
2017/08/26 02:41:41 step 1: objective=0.038103502
2017/08/26 02:41:45 step 2: objective=0.03814996
2017/08/26 02:41:49 step 3: objective=0.03819643
2017/08/26 02:41:53 step 4: objective=0.038242545
2017/08/26 02:41:57 step 5: objective=0.038287755
2017/08/26 02:42:01 step 6: objective=0.038331684
2017/08/26 02:42:04 step 7: objective=0.038373243
2017/08/26 02:42:04 Training value function...
2017/08/26 02:42:07 step 0: mse=0.635411 step=0.100000
2017/08/26 02:42:09 step 1: mse=0.601989 step=0.100000
2017/08/26 02:42:11 step 2: mse=0.569307 step=0.100000
2017/08/26 02:42:13 step 3: mse=0.546110 step=0.100000
2017/08/26 02:42:15 step 4: mse=0.526886 step=0.100000
2017/08/26 02:42:17 step 5: mse=0.504890 step=0.100000
2017/08/26 02:42:19 step 6: mse=0.490390 step=0.100000
2017/08/26 02:42:22 step 7: mse=0.478163 step=0.100000
2017/08/26 02:42:22 Saving...
2017/08/26 02:42:22 Gathering batch of experience...
2017/08/26 02:42:34 batch 19: mean=9.672727 stddev=4.147527 entropy=1.213797 frames=34369 count=55
2017/08/26 02:42:34 Training policy...
2017/08/26 02:42:39 step 0: objective=0.010508884
2017/08/26 02:42:43 step 1: objective=0.010535151
2017/08/26 02:42:47 step 2: objective=0.010561429
2017/08/26 02:42:51 step 3: objective=0.010587775
2017/08/26 02:42:55 step 4: objective=0.010614284
2017/08/26 02:42:59 step 5: objective=0.01064062
2017/08/26 02:43:03 step 6: objective=0.010667094
2017/08/26 02:43:07 step 7: objective=0.010693411
2017/08/26 02:43:07 Training value function...
2017/08/26 02:43:09 step 0: mse=0.384312 step=0.100000
2017/08/26 02:43:11 step 1: mse=0.370787 step=0.100000
2017/08/26 02:43:13 step 2: mse=0.361067 step=0.100000
2017/08/26 02:43:15 step 3: mse=0.343657 step=0.100000
2017/08/26 02:43:18 step 4: mse=0.333740 step=0.100000
2017/08/26 02:43:20 step 5: mse=0.327558 step=0.100000
2017/08/26 02:43:22 step 6: mse=0.315517 step=0.100000
2017/08/26 02:43:24 step 7: mse=0.308848 step=0.100000
2017/08/26 02:43:24 Saving...
2017/08/26 02:43:24 Gathering batch of experience...
2017/08/26 02:43:36 batch 20: mean=9.550000 stddev=4.181009 entropy=1.212526 frames=34673 count=60
2017/08/26 02:43:36 Training policy...
2017/08/26 02:43:41 step 0: objective=0.033587944
2017/08/26 02:43:45 step 1: objective=0.033666175
2017/08/26 02:43:49 step 2: objective=0.03374423
2017/08/26 02:43:53 step 3: objective=0.033783596
2017/08/26 02:43:57 step 4: objective=0.033860557
2017/08/26 02:44:01 step 5: objective=0.033917233
2017/08/26 02:44:05 step 6: objective=0.033969432
2017/08/26 02:44:09 step 7: objective=0.034009274
2017/08/26 02:44:09 Training value function...
2017/08/26 02:44:12 step 0: mse=0.631952 step=0.100000
2017/08/26 02:44:14 step 1: mse=0.598488 step=0.100000
2017/08/26 02:44:16 step 2: mse=0.562802 step=0.100000
2017/08/26 02:44:18 step 3: mse=0.539954 step=0.100000
2017/08/26 02:44:20 step 4: mse=0.514067 step=0.100000
2017/08/26 02:44:22 step 5: mse=0.492606 step=0.100000
2017/08/26 02:44:24 step 6: mse=0.479191 step=0.100000
2017/08/26 02:44:26 step 7: mse=0.467810 step=0.100000
2017/08/26 02:44:26 Saving...
2017/08/26 02:44:26 Gathering batch of experience...
2017/08/26 02:44:39 batch 21: mean=10.074074 stddev=4.379463 entropy=1.209064 frames=34736 count=54
2017/08/26 02:44:39 Training policy...
2017/08/26 02:44:44 step 0: objective=0.018601645
2017/08/26 02:44:48 step 1: objective=0.018639779
2017/08/26 02:44:52 step 2: objective=0.01867851
2017/08/26 02:44:56 step 3: objective=0.018717557
2017/08/26 02:45:00 step 4: objective=0.018756486
2017/08/26 02:45:04 step 5: objective=0.018785277
2017/08/26 02:45:08 step 6: objective=0.018804396
2017/08/26 02:45:11 step 7: objective=0.018822094
2017/08/26 02:45:11 Training value function...
2017/08/26 02:45:14 step 0: mse=0.374122 step=0.100000
2017/08/26 02:45:16 step 1: mse=0.358016 step=0.100000
2017/08/26 02:45:18 step 2: mse=0.347983 step=0.100000
2017/08/26 02:45:20 step 3: mse=0.338437 step=0.100000
2017/08/26 02:45:23 step 4: mse=0.331074 step=0.100000
2017/08/26 02:45:25 step 5: mse=0.322445 step=0.100000
2017/08/26 02:45:27 step 6: mse=0.317619 step=0.100000
2017/08/26 02:45:29 step 7: mse=0.303804 step=0.100000
2017/08/26 02:45:29 Saving...
2017/08/26 02:45:29 Gathering batch of experience...
2017/08/26 02:45:41 batch 22: mean=11.307692 stddev=4.986669 entropy=1.205855 frames=34776 count=52
2017/08/26 02:45:41 Training policy...
2017/08/26 02:45:47 step 0: objective=0.0447342
2017/08/26 02:45:51 step 1: objective=0.044764794
2017/08/26 02:45:55 step 2: objective=0.044795785
2017/08/26 02:45:59 step 3: objective=0.044826873
2017/08/26 02:46:03 step 4: objective=0.0448578
2017/08/26 02:46:07 step 5: objective=0.044888686
2017/08/26 02:46:11 step 6: objective=0.044913065
2017/08/26 02:46:15 step 7: objective=0.044943925
2017/08/26 02:46:15 Training value function...
2017/08/26 02:46:17 step 0: mse=0.628053 step=0.100000
2017/08/26 02:46:19 step 1: mse=0.583988 step=0.100000
2017/08/26 02:46:21 step 2: mse=0.547629 step=0.100000
2017/08/26 02:46:23 step 3: mse=0.515719 step=0.100000
2017/08/26 02:46:26 step 4: mse=0.488610 step=0.100000
2017/08/26 02:46:28 step 5: mse=0.466936 step=0.100000
2017/08/26 02:46:30 step 6: mse=0.446288 step=0.100000
2017/08/26 02:46:32 step 7: mse=0.431329 step=0.100000
2017/08/26 02:46:32 Saving...
2017/08/26 02:46:32 Gathering batch of experience...
2017/08/26 02:46:44 batch 23: mean=10.442308 stddev=4.221800 entropy=1.206640 frames=34405 count=52
2017/08/26 02:46:44 Training policy...
2017/08/26 02:46:50 step 0: objective=0.021958183
2017/08/26 02:46:54 step 1: objective=0.022017209
2017/08/26 02:46:57 step 2: objective=0.02207644
2017/08/26 02:47:01 step 3: objective=0.02213546
2017/08/26 02:47:06 step 4: objective=0.02218664
2017/08/26 02:47:10 step 5: objective=0.0222346
2017/08/26 02:47:14 step 6: objective=0.022278843
2017/08/26 02:47:18 step 7: objective=0.022321204
2017/08/26 02:47:18 Training value function...
2017/08/26 02:47:20 step 0: mse=0.497953 step=0.100000
2017/08/26 02:47:22 step 1: mse=0.452322 step=0.100000
2017/08/26 02:47:25 step 2: mse=0.415522 step=0.100000
2017/08/26 02:47:27 step 3: mse=0.392271 step=0.100000
2017/08/26 02:47:29 step 4: mse=0.366894 step=0.100000
2017/08/26 02:47:31 step 5: mse=0.351128 step=0.100000
2017/08/26 02:47:33 step 6: mse=0.333415 step=0.100000
2017/08/26 02:47:35 step 7: mse=0.322708 step=0.100000
2017/08/26 02:47:35 Saving...
2017/08/26 02:47:35 Gathering batch of experience...
2017/08/26 02:47:48 batch 24: mean=10.345455 stddev=4.037183 entropy=1.208334 frames=35338 count=55
2017/08/26 02:47:48 Training policy...
2017/08/26 02:47:53 step 0: objective=0.01931705
2017/08/26 02:47:57 step 1: objective=0.019347861
2017/08/26 02:48:01 step 2: objective=0.019378567
2017/08/26 02:48:06 step 3: objective=0.019409316
2017/08/26 02:48:10 step 4: objective=0.019440254
2017/08/26 02:48:14 step 5: objective=0.019471044
2017/08/26 02:48:18 step 6: objective=0.01950182
2017/08/26 02:48:22 step 7: objective=0.019532507
2017/08/26 02:48:22 Training value function...
2017/08/26 02:48:24 step 0: mse=0.523071 step=0.100000
2017/08/26 02:48:27 step 1: mse=0.496067 step=0.100000
2017/08/26 02:48:29 step 2: mse=0.471847 step=0.100000
2017/08/26 02:48:31 step 3: mse=0.453386 step=0.100000
2017/08/26 02:48:33 step 4: mse=0.434653 step=0.100000
2017/08/26 02:48:35 step 5: mse=0.420836 step=0.100000
2017/08/26 02:48:37 step 6: mse=0.409530 step=0.100000
2017/08/26 02:48:39 step 7: mse=0.393864 step=0.100000
2017/08/26 02:48:39 Saving...
2017/08/26 02:48:39 Gathering batch of experience...
2017/08/26 02:48:52 batch 25: mean=9.464286 stddev=3.343246 entropy=1.211464 frames=34345 count=56
2017/08/26 02:48:52 Training policy...
2017/08/26 02:48:57 step 0: objective=0.023148812
2017/08/26 02:49:01 step 1: objective=0.023173865
2017/08/26 02:49:05 step 2: objective=0.02319902
2017/08/26 02:49:09 step 3: objective=0.023224205
2017/08/26 02:49:13 step 4: objective=0.023249071
2017/08/26 02:49:17 step 5: objective=0.023274258
2017/08/26 02:49:21 step 6: objective=0.023299303
2017/08/26 02:49:25 step 7: objective=0.02332411
2017/08/26 02:49:25 Training value function...
2017/08/26 02:49:27 step 0: mse=0.355710 step=0.100000
2017/08/26 02:49:29 step 1: mse=0.343694 step=0.100000
2017/08/26 02:49:31 step 2: mse=0.330288 step=0.100000
2017/08/26 02:49:34 step 3: mse=0.319077 step=0.100000
2017/08/26 02:49:36 step 4: mse=0.313607 step=0.100000
2017/08/26 02:49:38 step 5: mse=0.307084 step=0.100000
2017/08/26 02:49:40 step 6: mse=0.301146 step=0.100000
2017/08/26 02:49:42 step 7: mse=0.296385 step=0.100000
2017/08/26 02:49:42 Saving...
2017/08/26 02:49:42 Gathering batch of experience...
2017/08/26 02:49:55 batch 26: mean=10.196429 stddev=4.376967 entropy=1.206791 frames=35780 count=56
2017/08/26 02:49:55 Training policy...
2017/08/26 02:50:01 step 0: objective=0.021841692
2017/08/26 02:50:05 step 1: objective=0.021872945
2017/08/26 02:50:09 step 2: objective=0.021903967
2017/08/26 02:50:13 step 3: objective=0.021934565
2017/08/26 02:50:17 step 4: objective=0.021964638
2017/08/26 02:50:21 step 5: objective=0.021994397
2017/08/26 02:50:25 step 6: objective=0.022020457
2017/08/26 02:50:29 step 7: objective=0.022044513
2017/08/26 02:50:29 Training value function...
2017/08/26 02:50:32 step 0: mse=0.510561 step=0.100000
2017/08/26 02:50:34 step 1: mse=0.484593 step=0.100000
2017/08/26 02:50:36 step 2: mse=0.449763 step=0.100000
2017/08/26 02:50:39 step 3: mse=0.421559 step=0.100000
2017/08/26 02:50:41 step 4: mse=0.398581 step=0.100000
2017/08/26 02:50:43 step 5: mse=0.379821 step=0.100000
2017/08/26 02:50:45 step 6: mse=0.367519 step=0.100000
2017/08/26 02:50:47 step 7: mse=0.357441 step=0.100000
2017/08/26 02:50:47 Saving...
2017/08/26 02:50:47 Gathering batch of experience...
2017/08/26 02:51:00 batch 27: mean=10.545455 stddev=4.853558 entropy=1.209820 frames=35059 count=55
2017/08/26 02:51:00 Training policy...
2017/08/26 02:51:05 step 0: objective=0.04013333
2017/08/26 02:51:09 step 1: objective=0.040169775
2017/08/26 02:51:13 step 2: objective=0.04020652
2017/08/26 02:51:18 step 3: objective=0.040242866
2017/08/26 02:51:22 step 4: objective=0.040279113
2017/08/26 02:51:26 step 5: objective=0.040315203
2017/08/26 02:51:30 step 6: objective=0.04035109
2017/08/26 02:51:34 step 7: objective=0.040384747
2017/08/26 02:51:34 Training value function...
2017/08/26 02:51:37 step 0: mse=0.579114 step=0.100000
2017/08/26 02:51:39 step 1: mse=0.549364 step=0.100000
2017/08/26 02:51:41 step 2: mse=0.524889 step=0.100000
2017/08/26 02:51:43 step 3: mse=0.504243 step=0.100000
2017/08/26 02:51:45 step 4: mse=0.486327 step=0.100000
2017/08/26 02:51:47 step 5: mse=0.466153 step=0.100000
2017/08/26 02:51:50 step 6: mse=0.453582 step=0.100000
2017/08/26 02:51:52 step 7: mse=0.441553 step=0.100000
2017/08/26 02:51:52 Saving...
2017/08/26 02:51:52 Gathering batch of experience...
2017/08/26 02:52:04 batch 28: mean=10.203704 stddev=3.917575 entropy=1.205604 frames=34495 count=54
2017/08/26 02:52:04 Training policy...
2017/08/26 02:52:10 step 0: objective=0.018422559
2017/08/26 02:52:14 step 1: objective=0.018475031
2017/08/26 02:52:17 step 2: objective=0.018527728
2017/08/26 02:52:21 step 3: objective=0.018580504
2017/08/26 02:52:26 step 4: objective=0.018633235
2017/08/26 02:52:30 step 5: objective=0.018684454
2017/08/26 02:52:34 step 6: objective=0.018717172
2017/08/26 02:52:38 step 7: objective=0.01874673
2017/08/26 02:52:38 Training value function...
2017/08/26 02:52:40 step 0: mse=0.435478 step=0.100000
2017/08/26 02:52:42 step 1: mse=0.415489 step=0.100000
2017/08/26 02:52:44 step 2: mse=0.399337 step=0.100000
2017/08/26 02:52:47 step 3: mse=0.386380 step=0.100000
2017/08/26 02:52:49 step 4: mse=0.375792 step=0.100000
2017/08/26 02:52:51 step 5: mse=0.365851 step=0.100000
2017/08/26 02:52:53 step 6: mse=0.357048 step=0.100000
2017/08/26 02:52:55 step 7: mse=0.350571 step=0.100000
2017/08/26 02:52:55 Saving...
2017/08/26 02:52:55 Gathering batch of experience...
2017/08/26 02:53:07 batch 29: mean=10.905660 stddev=4.548540 entropy=1.204392 frames=35148 count=53
2017/08/26 02:53:07 Training policy...
2017/08/26 02:53:13 step 0: objective=0.03365486
2017/08/26 02:53:17 step 1: objective=0.033710945
2017/08/26 02:53:21 step 2: objective=0.033766862
2017/08/26 02:53:25 step 3: objective=0.033822864
2017/08/26 02:53:29 step 4: objective=0.03387862
2017/08/26 02:53:33 step 5: objective=0.033932205
2017/08/26 02:53:37 step 6: objective=0.033983544
2017/08/26 02:53:41 step 7: objective=0.034022473
2017/08/26 02:53:41 Training value function...
2017/08/26 02:53:44 step 0: mse=0.588437 step=0.100000
2017/08/26 02:53:46 step 1: mse=0.552441 step=0.100000
2017/08/26 02:53:48 step 2: mse=0.518484 step=0.100000
2017/08/26 02:53:50 step 3: mse=0.493065 step=0.100000
2017/08/26 02:53:53 step 4: mse=0.472325 step=0.100000
2017/08/26 02:53:55 step 5: mse=0.454093 step=0.100000
2017/08/26 02:53:57 step 6: mse=0.433279 step=0.100000
2017/08/26 02:53:59 step 7: mse=0.421618 step=0.100000
2017/08/26 02:53:59 Saving...
2017/08/26 02:53:59 Gathering batch of experience...
2017/08/26 02:54:11 batch 30: mean=11.346154 stddev=4.759139 entropy=1.200818 frames=35430 count=52
2017/08/26 02:54:11 Training policy...
2017/08/26 02:54:17 step 0: objective=0.02527423
2017/08/26 02:54:21 step 1: objective=0.02532139
2017/08/26 02:54:25 step 2: objective=0.025368007
2017/08/26 02:54:30 step 3: objective=0.025414187
2017/08/26 02:54:34 step 4: objective=0.025459807
2017/08/26 02:54:38 step 5: objective=0.02550423
2017/08/26 02:54:42 step 6: objective=0.025535865
2017/08/26 02:54:46 step 7: objective=0.025566107
2017/08/26 02:54:46 Training value function...
2017/08/26 02:54:49 step 0: mse=0.507892 step=0.100000
2017/08/26 02:54:51 step 1: mse=0.480586 step=0.100000
2017/08/26 02:54:53 step 2: mse=0.460688 step=0.100000
2017/08/26 02:54:55 step 3: mse=0.437974 step=0.100000
2017/08/26 02:54:57 step 4: mse=0.424568 step=0.100000
2017/08/26 02:55:00 step 5: mse=0.411271 step=0.100000
2017/08/26 02:55:02 step 6: mse=0.397046 step=0.100000
2017/08/26 02:55:04 step 7: mse=0.388184 step=0.100000
2017/08/26 02:55:04 Saving...
2017/08/26 02:55:04 Gathering batch of experience...
2017/08/26 02:55:16 batch 31: mean=10.309091 stddev=3.944491 entropy=1.200674 frames=34661 count=55
2017/08/26 02:55:16 Training policy...
2017/08/26 02:55:22 step 0: objective=0.024839295
2017/08/26 02:55:26 step 1: objective=0.024899667
2017/08/26 02:55:30 step 2: objective=0.024960449
2017/08/26 02:55:34 step 3: objective=0.025021285
2017/08/26 02:55:38 step 4: objective=0.02508228
2017/08/26 02:55:42 step 5: objective=0.025140855
2017/08/26 02:55:46 step 6: objective=0.025187688
2017/08/26 02:55:51 step 7: objective=0.02523034
2017/08/26 02:55:51 Training value function...
2017/08/26 02:55:53 step 0: mse=0.583614 step=0.100000
2017/08/26 02:55:55 step 1: mse=0.550684 step=0.100000
2017/08/26 02:55:57 step 2: mse=0.524144 step=0.100000
2017/08/26 02:55:59 step 3: mse=0.501986 step=0.100000
2017/08/26 02:56:02 step 4: mse=0.482319 step=0.100000
2017/08/26 02:56:04 step 5: mse=0.463852 step=0.100000
2017/08/26 02:56:06 step 6: mse=0.446190 step=0.100000
2017/08/26 02:56:08 step 7: mse=0.434404 step=0.100000
2017/08/26 02:56:08 Saving...
2017/08/26 02:56:08 Gathering batch of experience...
2017/08/26 02:56:20 batch 32: mean=9.740741 stddev=4.168600 entropy=1.200309 frames=34082 count=54
2017/08/26 02:56:20 Training policy...
2017/08/26 02:56:26 step 0: objective=0.005142027
2017/08/26 02:56:30 step 1: objective=0.0051922216
2017/08/26 02:56:34 step 2: objective=0.005242858
2017/08/26 02:56:38 step 3: objective=0.005293755
2017/08/26 02:56:42 step 4: objective=0.0053382833
2017/08/26 02:56:46 step 5: objective=0.0053633642
2017/08/26 02:56:50 step 6: objective=0.0053786817
2017/08/26 02:56:54 step 7: objective=0.0054022744
2017/08/26 02:56:54 Training value function...
2017/08/26 02:56:57 step 0: mse=0.368038 step=0.100000
2017/08/26 02:56:59 step 1: mse=0.346097 step=0.100000
2017/08/26 02:57:01 step 2: mse=0.328615 step=0.100000
2017/08/26 02:57:03 step 3: mse=0.309524 step=0.100000
2017/08/26 02:57:05 step 4: mse=0.294171 step=0.100000
2017/08/26 02:57:07 step 5: mse=0.282410 step=0.100000
2017/08/26 02:57:09 step 6: mse=0.272249 step=0.100000
2017/08/26 02:57:11 step 7: mse=0.263747 step=0.100000
2017/08/26 02:57:11 Saving...
2017/08/26 02:57:11 Gathering batch of experience...
2017/08/26 02:57:24 batch 33: mean=10.181818 stddev=3.866363 entropy=1.196597 frames=35062 count=55
2017/08/26 02:57:24 Training policy...
2017/08/26 02:57:30 step 0: objective=0.030199768
2017/08/26 02:57:34 step 1: objective=0.030263508
2017/08/26 02:57:38 step 2: objective=0.030327199
2017/08/26 02:57:42 step 3: objective=0.03039047
2017/08/26 02:57:46 step 4: objective=0.030453691
2017/08/26 02:57:50 step 5: objective=0.030500794
2017/08/26 02:57:55 step 6: objective=0.030549953
2017/08/26 02:57:59 step 7: objective=0.030587567
2017/08/26 02:57:59 Training value function...
2017/08/26 02:58:01 step 0: mse=0.452932 step=0.100000
2017/08/26 02:58:03 step 1: mse=0.430831 step=0.100000
2017/08/26 02:58:06 step 2: mse=0.418383 step=0.100000
2017/08/26 02:58:08 step 3: mse=0.402530 step=0.100000
2017/08/26 02:58:10 step 4: mse=0.394518 step=0.100000
2017/08/26 02:58:12 step 5: mse=0.379732 step=0.100000
2017/08/26 02:58:14 step 6: mse=0.373846 step=0.100000
2017/08/26 02:58:16 step 7: mse=0.366646 step=0.100000
2017/08/26 02:58:16 Saving...
2017/08/26 02:58:16 Gathering batch of experience...
2017/08/26 02:58:29 batch 34: mean=10.980769 stddev=4.157895 entropy=1.198084 frames=34973 count=52
2017/08/26 02:58:29 Training policy...
2017/08/26 02:58:34 step 0: objective=0.034850705
2017/08/26 02:58:39 step 1: objective=0.03488629
2017/08/26 02:58:43 step 2: objective=0.034921937
2017/08/26 02:58:47 step 3: objective=0.03495774
2017/08/26 02:58:51 step 4: objective=0.034993462
2017/08/26 02:58:55 step 5: objective=0.03502925
2017/08/26 02:58:59 step 6: objective=0.035064932
2017/08/26 02:59:03 step 7: objective=0.035096936
2017/08/26 02:59:03 Training value function...
2017/08/26 02:59:06 step 0: mse=0.432708 step=0.100000
2017/08/26 02:59:08 step 1: mse=0.413099 step=0.100000
2017/08/26 02:59:10 step 2: mse=0.397357 step=0.100000
2017/08/26 02:59:12 step 3: mse=0.384074 step=0.100000
2017/08/26 02:59:14 step 4: mse=0.370783 step=0.100000
2017/08/26 02:59:17 step 5: mse=0.358893 step=0.100000
2017/08/26 02:59:19 step 6: mse=0.350568 step=0.100000
2017/08/26 02:59:21 step 7: mse=0.344999 step=0.100000
2017/08/26 02:59:21 Saving...
2017/08/26 02:59:21 Gathering batch of experience...
2017/08/26 02:59:34 batch 35: mean=11.423077 stddev=5.568960 entropy=1.190983 frames=35452 count=52
2017/08/26 02:59:34 Training policy...
2017/08/26 02:59:39 step 0: objective=0.038949497
2017/08/26 02:59:43 step 1: objective=0.03899542
2017/08/26 02:59:48 step 2: objective=0.039041597
2017/08/26 02:59:52 step 3: objective=0.039087627
2017/08/26 02:59:56 step 4: objective=0.039133854
2017/08/26 03:00:00 step 5: objective=0.039178446
2017/08/26 03:00:05 step 6: objective=0.039206367
2017/08/26 03:00:09 step 7: objective=0.03924182
2017/08/26 03:00:09 Training value function...
2017/08/26 03:00:12 step 0: mse=0.676059 step=0.100000
2017/08/26 03:00:14 step 1: mse=0.628588 step=0.100000
2017/08/26 03:00:16 step 2: mse=0.591135 step=0.100000
2017/08/26 03:00:18 step 3: mse=0.559431 step=0.100000
2017/08/26 03:00:20 step 4: mse=0.528820 step=0.100000
2017/08/26 03:00:23 step 5: mse=0.502056 step=0.100000
2017/08/26 03:00:25 step 6: mse=0.480505 step=0.100000
2017/08/26 03:00:27 step 7: mse=0.463834 step=0.100000
2017/08/26 03:00:27 Saving...
2017/08/26 03:00:27 Gathering batch of experience...
2017/08/26 03:00:40 batch 36: mean=11.403846 stddev=5.137568 entropy=1.196181 frames=35449 count=52
2017/08/26 03:00:40 Training policy...
2017/08/26 03:00:45 step 0: objective=0.038696755
2017/08/26 03:00:50 step 1: objective=0.038731143
2017/08/26 03:00:54 step 2: objective=0.038765606
2017/08/26 03:00:58 step 3: objective=0.038800016
2017/08/26 03:01:02 step 4: objective=0.038834143
2017/08/26 03:01:06 step 5: objective=0.038868804
2017/08/26 03:01:10 step 6: objective=0.038901314
2017/08/26 03:01:15 step 7: objective=0.03895202
2017/08/26 03:01:15 Training value function...
2017/08/26 03:01:17 step 0: mse=0.618747 step=0.100000
2017/08/26 03:01:19 step 1: mse=0.582965 step=0.100000
2017/08/26 03:01:22 step 2: mse=0.554911 step=0.100000
2017/08/26 03:01:24 step 3: mse=0.528609 step=0.100000
2017/08/26 03:01:26 step 4: mse=0.509843 step=0.100000
2017/08/26 03:01:28 step 5: mse=0.494410 step=0.100000
2017/08/26 03:01:30 step 6: mse=0.468415 step=0.100000
2017/08/26 03:01:32 step 7: mse=0.458091 step=0.100000
2017/08/26 03:01:32 Saving...
2017/08/26 03:01:33 Gathering batch of experience...
2017/08/26 03:01:45 batch 37: mean=10.636364 stddev=5.086037 entropy=1.197539 frames=35517 count=55
2017/08/26 03:01:45 Training policy...
2017/08/26 03:01:51 step 0: objective=0.01917674
2017/08/26 03:01:55 step 1: objective=0.01922845
2017/08/26 03:02:00 step 2: objective=0.019280564
2017/08/26 03:02:04 step 3: objective=0.019333154
2017/08/26 03:02:08 step 4: objective=0.019386066
2017/08/26 03:02:12 step 5: objective=0.019434378
2017/08/26 03:02:16 step 6: objective=0.019480972
2017/08/26 03:02:21 step 7: objective=0.01952058
2017/08/26 03:02:21 Training value function...
2017/08/26 03:02:23 step 0: mse=0.587381 step=0.100000
2017/08/26 03:02:26 step 1: mse=0.556716 step=0.100000
2017/08/26 03:02:28 step 2: mse=0.531510 step=0.100000
2017/08/26 03:02:30 step 3: mse=0.504451 step=0.100000
2017/08/26 03:02:32 step 4: mse=0.483969 step=0.100000
2017/08/26 03:02:35 step 5: mse=0.468811 step=0.100000
2017/08/26 03:02:37 step 6: mse=0.450896 step=0.100000
2017/08/26 03:02:39 step 7: mse=0.440009 step=0.100000
2017/08/26 03:02:39 Saving...
2017/08/26 03:02:39 Gathering batch of experience...
2017/08/26 03:02:52 batch 38: mean=9.696429 stddev=4.221203 entropy=1.199979 frames=34930 count=56
2017/08/26 03:02:52 Training policy...
2017/08/26 03:02:57 step 0: objective=0.011098001
2017/08/26 03:03:01 step 1: objective=0.011133254
2017/08/26 03:03:06 step 2: objective=0.01116848
2017/08/26 03:03:10 step 3: objective=0.011203819
2017/08/26 03:03:14 step 4: objective=0.011239188
2017/08/26 03:03:19 step 5: objective=0.011272191
2017/08/26 03:03:23 step 6: objective=0.011307518
2017/08/26 03:03:27 step 7: objective=0.011338134
2017/08/26 03:03:27 Training value function...
2017/08/26 03:03:30 step 0: mse=0.366618 step=0.100000
2017/08/26 03:03:32 step 1: mse=0.348170 step=0.100000
2017/08/26 03:03:34 step 2: mse=0.335021 step=0.100000
2017/08/26 03:03:36 step 3: mse=0.324700 step=0.100000
2017/08/26 03:03:38 step 4: mse=0.312029 step=0.100000
2017/08/26 03:03:41 step 5: mse=0.303583 step=0.100000
2017/08/26 03:03:43 step 6: mse=0.296315 step=0.100000
2017/08/26 03:03:45 step 7: mse=0.289576 step=0.100000
2017/08/26 03:03:45 Saving...
2017/08/26 03:03:45 Gathering batch of experience...
2017/08/26 03:03:58 batch 39: mean=11.358491 stddev=5.273981 entropy=1.197351 frames=35494 count=53
2017/08/26 03:03:58 Training policy...
2017/08/26 03:04:03 step 0: objective=0.04186443
2017/08/26 03:04:08 step 1: objective=0.041936662
2017/08/26 03:04:12 step 2: objective=0.042008683
2017/08/26 03:04:16 step 3: objective=0.04208082
2017/08/26 03:04:20 step 4: objective=0.042152807
2017/08/26 03:04:24 step 5: objective=0.042221207
2017/08/26 03:04:28 step 6: objective=0.04228483
2017/08/26 03:04:33 step 7: objective=0.042333316
2017/08/26 03:04:33 Training value function...
2017/08/26 03:04:35 step 0: mse=0.776680 step=0.100000
2017/08/26 03:04:37 step 1: mse=0.704925 step=0.100000
2017/08/26 03:04:40 step 2: mse=0.647114 step=0.100000
2017/08/26 03:04:42 step 3: mse=0.602475 step=0.100000
2017/08/26 03:04:44 step 4: mse=0.565851 step=0.100000
2017/08/26 03:04:46 step 5: mse=0.524560 step=0.100000
2017/08/26 03:04:48 step 6: mse=0.500252 step=0.100000
2017/08/26 03:04:51 step 7: mse=0.478240 step=0.100000
2017/08/26 03:04:51 Saving...
2017/08/26 03:04:51 Gathering batch of experience...
2017/08/26 03:05:04 batch 40: mean=11.490566 stddev=4.668734 entropy=1.199277 frames=36337 count=53
2017/08/26 03:05:04 Training policy...
2017/08/26 03:05:10 step 0: objective=0.029994464
2017/08/26 03:05:14 step 1: objective=0.030064397
2017/08/26 03:05:18 step 2: objective=0.030134294
2017/08/26 03:05:23 step 3: objective=0.030204153
2017/08/26 03:05:27 step 4: objective=0.030273428
2017/08/26 03:05:31 step 5: objective=0.03033384
2017/08/26 03:05:36 step 6: objective=0.030380122
2017/08/26 03:05:40 step 7: objective=0.030439096
2017/08/26 03:05:40 Training value function...
2017/08/26 03:05:43 step 0: mse=0.701353 step=0.100000
2017/08/26 03:05:45 step 1: mse=0.653829 step=0.100000
2017/08/26 03:05:47 step 2: mse=0.611906 step=0.100000
2017/08/26 03:05:50 step 3: mse=0.580655 step=0.100000
2017/08/26 03:05:52 step 4: mse=0.548451 step=0.100000
2017/08/26 03:05:54 step 5: mse=0.526921 step=0.100000
2017/08/26 03:05:57 step 6: mse=0.507615 step=0.100000
2017/08/26 03:05:59 step 7: mse=0.485401 step=0.100000
2017/08/26 03:05:59 Saving...
2017/08/26 03:05:59 Gathering batch of experience...
2017/08/26 03:06:11 batch 41: mean=10.388889 stddev=4.142895 entropy=1.194261 frames=34696 count=54
2017/08/26 03:06:11 Training policy...
2017/08/26 03:06:17 step 0: objective=0.011113743
2017/08/26 03:06:21 step 1: objective=0.011157824
2017/08/26 03:06:25 step 2: objective=0.011201961
2017/08/26 03:06:29 step 3: objective=0.011246056
2017/08/26 03:06:34 step 4: objective=0.011290185
2017/08/26 03:06:38 step 5: objective=0.0113342125
2017/08/26 03:06:42 step 6: objective=0.011377106
2017/08/26 03:06:46 step 7: objective=0.011408677
2017/08/26 03:06:46 Training value function...
2017/08/26 03:06:49 step 0: mse=0.424497 step=0.100000
2017/08/26 03:06:51 step 1: mse=0.402172 step=0.100000
2017/08/26 03:06:53 step 2: mse=0.385072 step=0.100000
2017/08/26 03:06:55 step 3: mse=0.372283 step=0.100000
2017/08/26 03:06:57 step 4: mse=0.356049 step=0.100000
2017/08/26 03:06:59 step 5: mse=0.343224 step=0.100000
2017/08/26 03:07:02 step 6: mse=0.333149 step=0.100000
2017/08/26 03:07:04 step 7: mse=0.320785 step=0.100000
2017/08/26 03:07:04 Saving...
2017/08/26 03:07:04 Gathering batch of experience...
2017/08/26 03:07:16 batch 42: mean=10.481481 stddev=3.650169 entropy=1.199558 frames=34724 count=54
2017/08/26 03:07:16 Training policy...
2017/08/26 03:07:22 step 0: objective=0.025977151
2017/08/26 03:07:26 step 1: objective=0.026030475
2017/08/26 03:07:30 step 2: objective=0.026083965
2017/08/26 03:07:35 step 3: objective=0.026137603
2017/08/26 03:07:39 step 4: objective=0.026188426
2017/08/26 03:07:43 step 5: objective=0.026219377
2017/08/26 03:07:47 step 6: objective=0.026247717
2017/08/26 03:07:51 step 7: objective=0.026275238
2017/08/26 03:07:51 Training value function...
2017/08/26 03:07:54 step 0: mse=0.496037 step=0.100000
2017/08/26 03:07:56 step 1: mse=0.467549 step=0.100000
2017/08/26 03:07:58 step 2: mse=0.444298 step=0.100000
2017/08/26 03:08:00 step 3: mse=0.427510 step=0.100000
2017/08/26 03:08:03 step 4: mse=0.411040 step=0.100000
2017/08/26 03:08:05 step 5: mse=0.399889 step=0.100000
2017/08/26 03:08:07 step 6: mse=0.390690 step=0.100000
2017/08/26 03:08:09 step 7: mse=0.379161 step=0.100000
2017/08/26 03:08:09 Saving...
2017/08/26 03:08:09 Gathering batch of experience...
2017/08/26 03:08:21 batch 43: mean=10.148148 stddev=3.817151 entropy=1.196932 frames=34677 count=54
2017/08/26 03:08:21 Training policy...
2017/08/26 03:08:27 step 0: objective=0.017114684
2017/08/26 03:08:31 step 1: objective=0.017141636
2017/08/26 03:08:36 step 2: objective=0.017168697
2017/08/26 03:08:40 step 3: objective=0.017195873
2017/08/26 03:08:44 step 4: objective=0.017222762
2017/08/26 03:08:48 step 5: objective=0.017249806
2017/08/26 03:08:53 step 6: objective=0.017276831
2017/08/26 03:08:57 step 7: objective=0.017303782
2017/08/26 03:08:57 Training value function...
2017/08/26 03:09:00 step 0: mse=0.465684 step=0.100000
2017/08/26 03:09:02 step 1: mse=0.440666 step=0.100000
2017/08/26 03:09:04 step 2: mse=0.419920 step=0.100000
2017/08/26 03:09:06 step 3: mse=0.401776 step=0.100000
2017/08/26 03:09:08 step 4: mse=0.386843 step=0.100000
2017/08/26 03:09:11 step 5: mse=0.374719 step=0.100000
2017/08/26 03:09:13 step 6: mse=0.364415 step=0.100000
2017/08/26 03:09:15 step 7: mse=0.353447 step=0.100000
2017/08/26 03:09:15 Saving...
2017/08/26 03:09:15 Gathering batch of experience...
2017/08/26 03:09:28 batch 44: mean=10.309091 stddev=4.689922 entropy=1.193184 frames=35299 count=55
2017/08/26 03:09:28 Training policy...
2017/08/26 03:09:33 step 0: objective=0.022409368
2017/08/26 03:09:38 step 1: objective=0.022431893
2017/08/26 03:09:42 step 2: objective=0.02245452
2017/08/26 03:09:46 step 3: objective=0.02247719
2017/08/26 03:09:51 step 4: objective=0.02249983
2017/08/26 03:09:55 step 5: objective=0.022522718
2017/08/26 03:09:59 step 6: objective=0.022544622
2017/08/26 03:10:03 step 7: objective=0.022562725
2017/08/26 03:10:03 Training value function...
2017/08/26 03:10:06 step 0: mse=0.471102 step=0.100000
2017/08/26 03:10:08 step 1: mse=0.450232 step=0.100000
2017/08/26 03:10:10 step 2: mse=0.435495 step=0.100000
2017/08/26 03:10:13 step 3: mse=0.423042 step=0.100000
2017/08/26 03:10:15 step 4: mse=0.412760 step=0.100000
2017/08/26 03:10:17 step 5: mse=0.404778 step=0.100000
2017/08/26 03:10:19 step 6: mse=0.393936 step=0.100000
2017/08/26 03:10:21 step 7: mse=0.384600 step=0.100000
2017/08/26 03:10:21 Saving...
2017/08/26 03:10:21 Gathering batch of experience...
2017/08/26 03:10:34 batch 45: mean=10.777778 stddev=4.775193 entropy=1.199178 frames=35208 count=54
2017/08/26 03:10:34 Training policy...
2017/08/26 03:10:40 step 0: objective=0.035924308
2017/08/26 03:10:44 step 1: objective=0.035978552
2017/08/26 03:10:49 step 2: objective=0.036033146
2017/08/26 03:10:53 step 3: objective=0.036087655
2017/08/26 03:10:57 step 4: objective=0.036140062
2017/08/26 03:11:02 step 5: objective=0.036176972
2017/08/26 03:11:06 step 6: objective=0.03621583
2017/08/26 03:11:10 step 7: objective=0.03626575
2017/08/26 03:11:10 Training value function...
2017/08/26 03:11:13 step 0: mse=0.588854 step=0.100000
2017/08/26 03:11:15 step 1: mse=0.550444 step=0.100000
2017/08/26 03:11:17 step 2: mse=0.521211 step=0.100000
2017/08/26 03:11:19 step 3: mse=0.497475 step=0.100000
2017/08/26 03:11:21 step 4: mse=0.474366 step=0.100000
2017/08/26 03:11:24 step 5: mse=0.456812 step=0.100000
2017/08/26 03:11:26 step 6: mse=0.438896 step=0.100000
2017/08/26 03:11:28 step 7: mse=0.425860 step=0.100000
2017/08/26 03:11:28 Saving...
2017/08/26 03:11:28 Gathering batch of experience...
2017/08/26 03:11:41 batch 46: mean=11.452830 stddev=5.236181 entropy=1.196795 frames=35695 count=53
2017/08/26 03:11:41 Training policy...
2017/08/26 03:11:47 step 0: objective=0.043184884
2017/08/26 03:11:51 step 1: objective=0.04322243
2017/08/26 03:11:56 step 2: objective=0.043259487
2017/08/26 03:12:00 step 3: objective=0.04329644
2017/08/26 03:12:04 step 4: objective=0.043332778
2017/08/26 03:12:09 step 5: objective=0.043364134
2017/08/26 03:12:13 step 6: objective=0.04339561
2017/08/26 03:12:17 step 7: objective=0.043427188
2017/08/26 03:12:17 Training value function...
2017/08/26 03:12:20 step 0: mse=0.696746 step=0.100000
2017/08/26 03:12:22 step 1: mse=0.650995 step=0.100000
2017/08/26 03:12:25 step 2: mse=0.613430 step=0.100000
2017/08/26 03:12:27 step 3: mse=0.581953 step=0.100000
2017/08/26 03:12:29 step 4: mse=0.556395 step=0.100000
2017/08/26 03:12:32 step 5: mse=0.535654 step=0.100000
2017/08/26 03:12:34 step 6: mse=0.517136 step=0.100000
2017/08/26 03:12:36 step 7: mse=0.502153 step=0.100000
2017/08/26 03:12:36 Saving...
2017/08/26 03:12:36 Gathering batch of experience...
2017/08/26 03:12:49 batch 47: mean=10.436364 stddev=3.730774 entropy=1.202482 frames=35316 count=55
2017/08/26 03:12:49 Training policy...
2017/08/26 03:12:55 step 0: objective=0.028197113
2017/08/26 03:12:59 step 1: objective=0.028229583
2017/08/26 03:13:04 step 2: objective=0.02826224
2017/08/26 03:13:08 step 3: objective=0.028294943
2017/08/26 03:13:12 step 4: objective=0.028327955
2017/08/26 03:13:17 step 5: objective=0.028360736
2017/08/26 03:13:21 step 6: objective=0.028393121
2017/08/26 03:13:25 step 7: objective=0.028443273
2017/08/26 03:13:25 Training value function...
2017/08/26 03:13:28 step 0: mse=0.592808 step=0.100000
2017/08/26 03:13:30 step 1: mse=0.566619 step=0.100000
2017/08/26 03:13:32 step 2: mse=0.544597 step=0.100000
2017/08/26 03:13:34 step 3: mse=0.523561 step=0.100000
2017/08/26 03:13:37 step 4: mse=0.506875 step=0.100000
2017/08/26 03:13:39 step 5: mse=0.492429 step=0.100000
2017/08/26 03:13:41 step 6: mse=0.480171 step=0.100000
2017/08/26 03:13:43 step 7: mse=0.469746 step=0.100000
2017/08/26 03:13:43 Saving...
2017/08/26 03:13:43 Gathering batch of experience...
2017/08/26 03:13:56 batch 48: mean=10.314815 stddev=4.458965 entropy=1.193088 frames=35098 count=54
2017/08/26 03:13:56 Training policy...
2017/08/26 03:14:02 step 0: objective=0.022240574
2017/08/26 03:14:06 step 1: objective=0.02225947
2017/08/26 03:14:10 step 2: objective=0.022278316
2017/08/26 03:14:14 step 3: objective=0.022297373
2017/08/26 03:14:19 step 4: objective=0.022316506
2017/08/26 03:14:23 step 5: objective=0.022335503
2017/08/26 03:14:27 step 6: objective=0.022354756
2017/08/26 03:14:32 step 7: objective=0.022373566
2017/08/26 03:14:32 Training value function...
2017/08/26 03:14:35 step 0: mse=0.464871 step=0.100000
2017/08/26 03:14:37 step 1: mse=0.430377 step=0.100000
2017/08/26 03:14:39 step 2: mse=0.402753 step=0.100000
2017/08/26 03:14:41 step 3: mse=0.379348 step=0.100000
2017/08/26 03:14:43 step 4: mse=0.359777 step=0.100000
2017/08/26 03:14:45 step 5: mse=0.340695 step=0.100000
2017/08/26 03:14:47 step 6: mse=0.326813 step=0.100000
2017/08/26 03:14:50 step 7: mse=0.310651 step=0.100000
2017/08/26 03:14:50 Saving...
2017/08/26 03:14:50 Gathering batch of experience...
2017/08/26 03:15:02 batch 49: mean=11.823529 stddev=4.833323 entropy=1.185770 frames=35486 count=51
2017/08/26 03:15:02 Training policy...
2017/08/26 03:15:08 step 0: objective=0.037460517
2017/08/26 03:15:13 step 1: objective=0.03753116
2017/08/26 03:15:17 step 2: objective=0.037602212
2017/08/26 03:15:21 step 3: objective=0.037673555
2017/08/26 03:15:26 step 4: objective=0.037745126
2017/08/26 03:15:30 step 5: objective=0.0378365
2017/08/26 03:15:34 step 6: objective=0.037891634
2017/08/26 03:15:39 step 7: objective=0.03795752
2017/08/26 03:15:39 Training value function...
2017/08/26 03:15:41 step 0: mse=0.589126 step=0.100000
2017/08/26 03:15:44 step 1: mse=0.560389 step=0.100000
2017/08/26 03:15:46 step 2: mse=0.535193 step=0.100000
2017/08/26 03:15:48 step 3: mse=0.510609 step=0.100000
2017/08/26 03:15:50 step 4: mse=0.488147 step=0.100000
2017/08/26 03:15:52 step 5: mse=0.470428 step=0.100000
2017/08/26 03:15:55 step 6: mse=0.454896 step=0.100000
2017/08/26 03:15:57 step 7: mse=0.441512 step=0.100000
2017/08/26 03:15:57 Saving...
2017/08/26 03:15:57 Gathering batch of experience...
2017/08/26 03:16:10 batch 50: mean=13.081633 stddev=4.810010 entropy=1.193188 frames=35384 count=49
2017/08/26 03:16:10 Training policy...
2017/08/26 03:16:16 step 0: objective=0.052038
2017/08/26 03:16:20 step 1: objective=0.052066796
2017/08/26 03:16:24 step 2: objective=0.052095696
2017/08/26 03:16:29 step 3: objective=0.052124552
2017/08/26 03:16:34 step 4: objective=0.052153166
2017/08/26 03:16:38 step 5: objective=0.052181873
2017/08/26 03:16:42 step 6: objective=0.052210417
2017/08/26 03:16:46 step 7: objective=0.052238654
2017/08/26 03:16:46 Training value function...
2017/08/26 03:16:49 step 0: mse=0.732676 step=0.100000
2017/08/26 03:16:51 step 1: mse=0.694164 step=0.100000
2017/08/26 03:16:54 step 2: mse=0.662299 step=0.100000
2017/08/26 03:16:56 step 3: mse=0.636213 step=0.100000
2017/08/26 03:16:58 step 4: mse=0.610812 step=0.100000
2017/08/26 03:17:00 step 5: mse=0.593837 step=0.100000
2017/08/26 03:17:03 step 6: mse=0.576788 step=0.100000
2017/08/26 03:17:05 step 7: mse=0.565146 step=0.100000
2017/08/26 03:17:05 Saving...
2017/08/26 03:17:05 Gathering batch of experience...
2017/08/26 03:17:18 batch 51: mean=11.462963 stddev=5.384178 entropy=1.190245 frames=35630 count=54
2017/08/26 03:17:18 Training policy...
2017/08/26 03:17:24 step 0: objective=0.020904878
2017/08/26 03:17:28 step 1: objective=0.020966612
2017/08/26 03:17:33 step 2: objective=0.021028524
2017/08/26 03:17:37 step 3: objective=0.021090783
2017/08/26 03:17:41 step 4: objective=0.02115328
2017/08/26 03:17:46 step 5: objective=0.021213733
2017/08/26 03:17:51 step 6: objective=0.021251298
2017/08/26 03:17:55 step 7: objective=0.021337735
2017/08/26 03:17:55 Training value function...
2017/08/26 03:17:58 step 0: mse=0.677466 step=0.100000
2017/08/26 03:18:00 step 1: mse=0.643775 step=0.100000
2017/08/26 03:18:02 step 2: mse=0.616756 step=0.100000
2017/08/26 03:18:05 step 3: mse=0.593116 step=0.100000
2017/08/26 03:18:07 step 4: mse=0.567110 step=0.100000
2017/08/26 03:18:09 step 5: mse=0.548588 step=0.100000
2017/08/26 03:18:11 step 6: mse=0.534685 step=0.100000
2017/08/26 03:18:13 step 7: mse=0.520140 step=0.100000
2017/08/26 03:18:13 Saving...
2017/08/26 03:18:13 Gathering batch of experience...
2017/08/26 03:18:26 batch 52: mean=11.452830 stddev=4.132549 entropy=1.193452 frames=35910 count=53
2017/08/26 03:18:26 Training policy...
2017/08/26 03:18:32 step 0: objective=0.028335528
2017/08/26 03:18:37 step 1: objective=0.028410953
2017/08/26 03:18:41 step 2: objective=0.028487597
2017/08/26 03:18:46 step 3: objective=0.028562237
2017/08/26 03:18:50 step 4: objective=0.028604157
2017/08/26 03:18:54 step 5: objective=0.028648961
2017/08/26 03:18:59 step 6: objective=0.02869238
2017/08/26 03:19:03 step 7: objective=0.028729405
2017/08/26 03:19:03 Training value function...
2017/08/26 03:19:06 step 0: mse=0.593726 step=0.100000
2017/08/26 03:19:08 step 1: mse=0.561422 step=0.100000
2017/08/26 03:19:11 step 2: mse=0.537108 step=0.100000
2017/08/26 03:19:13 step 3: mse=0.512627 step=0.100000
2017/08/26 03:19:15 step 4: mse=0.492728 step=0.100000
2017/08/26 03:19:17 step 5: mse=0.476271 step=0.100000
2017/08/26 03:19:19 step 6: mse=0.462310 step=0.100000
2017/08/26 03:19:22 step 7: mse=0.449371 step=0.100000
2017/08/26 03:19:22 Saving...
2017/08/26 03:19:22 Gathering batch of experience...
2017/08/26 03:19:34 batch 53: mean=10.500000 stddev=3.938180 entropy=1.190074 frames=35011 count=54
2017/08/26 03:19:34 Training policy...
2017/08/26 03:19:40 step 0: objective=0.008481463
2017/08/26 03:19:45 step 1: objective=0.008519963
2017/08/26 03:19:49 step 2: objective=0.008558796
2017/08/26 03:19:53 step 3: objective=0.008597943
2017/08/26 03:19:58 step 4: objective=0.008637337
2017/08/26 03:20:02 step 5: objective=0.008675452
2017/08/26 03:20:07 step 6: objective=0.008701262
2017/08/26 03:20:11 step 7: objective=0.008719882
2017/08/26 03:20:11 Training value function...
2017/08/26 03:20:14 step 0: mse=0.482377 step=0.100000
2017/08/26 03:20:16 step 1: mse=0.464751 step=0.100000
2017/08/26 03:20:18 step 2: mse=0.450011 step=0.100000
2017/08/26 03:20:20 step 3: mse=0.438883 step=0.100000
2017/08/26 03:20:23 step 4: mse=0.430020 step=0.100000
2017/08/26 03:20:25 step 5: mse=0.418113 step=0.100000
2017/08/26 03:20:27 step 6: mse=0.409318 step=0.100000
2017/08/26 03:20:29 step 7: mse=0.402584 step=0.100000
2017/08/26 03:20:29 Saving...
2017/08/26 03:20:29 Gathering batch of experience...
2017/08/26 03:20:42 batch 54: mean=10.833333 stddev=4.429489 entropy=1.191682 frames=35365 count=54
2017/08/26 03:20:42 Training policy...
2017/08/26 03:20:48 step 0: objective=0.03193456
2017/08/26 03:20:53 step 1: objective=0.031964205
2017/08/26 03:20:57 step 2: objective=0.03199403
2017/08/26 03:21:02 step 3: objective=0.032023624
2017/08/26 03:21:06 step 4: objective=0.032052737
2017/08/26 03:21:11 step 5: objective=0.032082237
2017/08/26 03:21:15 step 6: objective=0.032110024
2017/08/26 03:21:20 step 7: objective=0.032129176
2017/08/26 03:21:20 Training value function...
2017/08/26 03:21:22 step 0: mse=0.565591 step=0.100000
2017/08/26 03:21:25 step 1: mse=0.537827 step=0.100000
2017/08/26 03:21:27 step 2: mse=0.506066 step=0.100000
2017/08/26 03:21:29 step 3: mse=0.478985 step=0.100000
2017/08/26 03:21:31 step 4: mse=0.454609 step=0.100000
2017/08/26 03:21:33 step 5: mse=0.434641 step=0.100000
2017/08/26 03:21:36 step 6: mse=0.417751 step=0.100000
2017/08/26 03:21:38 step 7: mse=0.399382 step=0.100000
2017/08/26 03:21:38 Saving...
2017/08/26 03:21:38 Gathering batch of experience...
2017/08/26 03:21:51 batch 55: mean=11.400000 stddev=4.331282 entropy=1.188950 frames=34815 count=50
2017/08/26 03:21:51 Training policy...
2017/08/26 03:21:57 step 0: objective=0.025829967
2017/08/26 03:22:01 step 1: objective=0.025882611
2017/08/26 03:22:05 step 2: objective=0.025935873
2017/08/26 03:22:10 step 3: objective=0.025989562
2017/08/26 03:22:14 step 4: objective=0.026043413
2017/08/26 03:22:18 step 5: objective=0.026086211
2017/08/26 03:22:23 step 6: objective=0.026125202
2017/08/26 03:22:27 step 7: objective=0.026168004
2017/08/26 03:22:27 Training value function...
2017/08/26 03:22:30 step 0: mse=0.451888 step=0.100000
2017/08/26 03:22:32 step 1: mse=0.430213 step=0.100000
2017/08/26 03:22:34 step 2: mse=0.412409 step=0.100000
2017/08/26 03:22:36 step 3: mse=0.398383 step=0.100000
2017/08/26 03:22:38 step 4: mse=0.385226 step=0.100000
2017/08/26 03:22:40 step 5: mse=0.372620 step=0.100000
2017/08/26 03:22:42 step 6: mse=0.357670 step=0.100000
2017/08/26 03:22:45 step 7: mse=0.345224 step=0.100000
2017/08/26 03:22:45 Saving...
2017/08/26 03:22:45 Gathering batch of experience...
2017/08/26 03:22:58 batch 56: mean=11.941176 stddev=4.326896 entropy=1.191274 frames=35726 count=51
2017/08/26 03:22:58 Training policy...
2017/08/26 03:23:04 step 0: objective=0.036969297
2017/08/26 03:23:08 step 1: objective=0.036990047
2017/08/26 03:23:13 step 2: objective=0.03701121
2017/08/26 03:23:17 step 3: objective=0.037031826
2017/08/26 03:23:22 step 4: objective=0.037052568
2017/08/26 03:23:26 step 5: objective=0.03707324
2017/08/26 03:23:31 step 6: objective=0.03709391
2017/08/26 03:23:35 step 7: objective=0.037114754
2017/08/26 03:23:35 Training value function...
2017/08/26 03:23:38 step 0: mse=0.545186 step=0.100000
2017/08/26 03:23:40 step 1: mse=0.520936 step=0.100000
2017/08/26 03:23:42 step 2: mse=0.500117 step=0.100000
2017/08/26 03:23:44 step 3: mse=0.483481 step=0.100000
2017/08/26 03:23:47 step 4: mse=0.469585 step=0.100000
2017/08/26 03:23:49 step 5: mse=0.456951 step=0.100000
2017/08/26 03:23:51 step 6: mse=0.447063 step=0.100000
2017/08/26 03:23:53 step 7: mse=0.430373 step=0.100000
2017/08/26 03:23:53 Saving...
2017/08/26 03:23:54 Gathering batch of experience...
2017/08/26 03:24:06 batch 57: mean=10.672727 stddev=4.386154 entropy=1.190809 frames=34873 count=55
2017/08/26 03:24:06 Training policy...
2017/08/26 03:24:12 step 0: objective=0.02763889
2017/08/26 03:24:17 step 1: objective=0.02767741
2017/08/26 03:24:21 step 2: objective=0.027714835
2017/08/26 03:24:25 step 3: objective=0.027752277
2017/08/26 03:24:30 step 4: objective=0.027789837
2017/08/26 03:24:34 step 5: objective=0.027827337
2017/08/26 03:24:39 step 6: objective=0.027865192
2017/08/26 03:24:43 step 7: objective=0.02790201
2017/08/26 03:24:43 Training value function...
2017/08/26 03:24:46 step 0: mse=0.554608 step=0.100000
2017/08/26 03:24:48 step 1: mse=0.520953 step=0.100000
2017/08/26 03:24:50 step 2: mse=0.493967 step=0.100000
2017/08/26 03:24:52 step 3: mse=0.468972 step=0.100000
2017/08/26 03:24:54 step 4: mse=0.449102 step=0.100000
2017/08/26 03:24:57 step 5: mse=0.430327 step=0.100000
2017/08/26 03:24:59 step 6: mse=0.418460 step=0.100000
2017/08/26 03:25:01 step 7: mse=0.403194 step=0.100000
2017/08/26 03:25:01 Saving...
2017/08/26 03:25:01 Gathering batch of experience...
2017/08/26 03:25:14 batch 58: mean=11.584906 stddev=5.998220 entropy=1.190760 frames=35567 count=53
2017/08/26 03:25:14 Training policy...
2017/08/26 03:25:20 step 0: objective=0.0325116
2017/08/26 03:25:25 step 1: objective=0.032572728
2017/08/26 03:25:29 step 2: objective=0.03263363
2017/08/26 03:25:34 step 3: objective=0.03269431
2017/08/26 03:25:38 step 4: objective=0.032754842
2017/08/26 03:25:43 step 5: objective=0.03281058
2017/08/26 03:25:47 step 6: objective=0.03285688
2017/08/26 03:25:52 step 7: objective=0.03289367
2017/08/26 03:25:52 Training value function...
2017/08/26 03:25:54 step 0: mse=0.771621 step=0.100000
2017/08/26 03:25:56 step 1: mse=0.729139 step=0.100000
2017/08/26 03:25:59 step 2: mse=0.693711 step=0.100000
2017/08/26 03:26:01 step 3: mse=0.666351 step=0.100000
2017/08/26 03:26:03 step 4: mse=0.642033 step=0.100000
2017/08/26 03:26:05 step 5: mse=0.607513 step=0.100000
2017/08/26 03:26:08 step 6: mse=0.578373 step=0.100000
2017/08/26 03:26:10 step 7: mse=0.551878 step=0.100000
2017/08/26 03:26:10 Saving...
2017/08/26 03:26:10 Gathering batch of experience...
2017/08/26 03:26:23 batch 59: mean=12.000000 stddev=4.727172 entropy=1.194997 frames=35770 count=52
2017/08/26 03:26:23 Training policy...
2017/08/26 03:26:29 step 0: objective=0.027543386
2017/08/26 03:26:33 step 1: objective=0.027577557
2017/08/26 03:26:38 step 2: objective=0.027611746
2017/08/26 03:26:42 step 3: objective=0.027645959
2017/08/26 03:26:47 step 4: objective=0.027680289
2017/08/26 03:26:51 step 5: objective=0.02771451
2017/08/26 03:26:56 step 6: objective=0.02774893
2017/08/26 03:27:00 step 7: objective=0.027783252
2017/08/26 03:27:00 Training value function...
2017/08/26 03:27:03 step 0: mse=0.625759 step=0.100000
2017/08/26 03:27:05 step 1: mse=0.587063 step=0.100000
2017/08/26 03:27:08 step 2: mse=0.555784 step=0.100000
2017/08/26 03:27:10 step 3: mse=0.530548 step=0.100000
2017/08/26 03:27:12 step 4: mse=0.509127 step=0.100000
2017/08/26 03:27:14 step 5: mse=0.493661 step=0.100000
2017/08/26 03:27:16 step 6: mse=0.479326 step=0.100000
2017/08/26 03:27:19 step 7: mse=0.467734 step=0.100000
2017/08/26 03:27:19 Saving...
2017/08/26 03:27:19 Gathering batch of experience...
2017/08/26 03:27:32 batch 60: mean=11.074074 stddev=4.845203 entropy=1.191491 frames=35789 count=54
2017/08/26 03:27:32 Training policy...
2017/08/26 03:27:38 step 0: objective=0.019035168
2017/08/26 03:27:43 step 1: objective=0.019061774
2017/08/26 03:27:47 step 2: objective=0.019088164
2017/08/26 03:27:52 step 3: objective=0.019114567
2017/08/26 03:27:56 step 4: objective=0.019140767
2017/08/26 03:28:01 step 5: objective=0.01916666
2017/08/26 03:28:06 step 6: objective=0.019192472
2017/08/26 03:28:11 step 7: objective=0.0192177
2017/08/26 03:28:11 Training value function...
2017/08/26 03:28:14 step 0: mse=0.492744 step=0.100000
2017/08/26 03:28:16 step 1: mse=0.476299 step=0.100000
2017/08/26 03:28:18 step 2: mse=0.463075 step=0.100000
2017/08/26 03:28:20 step 3: mse=0.453160 step=0.100000
2017/08/26 03:28:23 step 4: mse=0.442793 step=0.100000
2017/08/26 03:28:25 step 5: mse=0.435516 step=0.100000
2017/08/26 03:28:27 step 6: mse=0.428013 step=0.100000
2017/08/26 03:28:29 step 7: mse=0.420875 step=0.100000
2017/08/26 03:28:29 Saving...
2017/08/26 03:28:29 Gathering batch of experience...
2017/08/26 03:28:42 batch 61: mean=11.326923 stddev=5.041067 entropy=1.198044 frames=34465 count=52
2017/08/26 03:28:42 Training policy...
2017/08/26 03:28:48 step 0: objective=0.028808929
2017/08/26 03:28:52 step 1: objective=0.028862419
2017/08/26 03:28:56 step 2: objective=0.028915698
2017/08/26 03:29:01 step 3: objective=0.028963577
2017/08/26 03:29:05 step 4: objective=0.029010296
2017/08/26 03:29:10 step 5: objective=0.029051993
2017/08/26 03:29:14 step 6: objective=0.029089978
2017/08/26 03:29:18 step 7: objective=0.029116683
2017/08/26 03:29:18 Training value function...
2017/08/26 03:29:21 step 0: mse=0.546967 step=0.100000
2017/08/26 03:29:23 step 1: mse=0.518609 step=0.100000
2017/08/26 03:29:25 step 2: mse=0.483497 step=0.100000
2017/08/26 03:29:27 step 3: mse=0.461016 step=0.100000
2017/08/26 03:29:30 step 4: mse=0.435404 step=0.100000
2017/08/26 03:29:32 step 5: mse=0.419687 step=0.100000
2017/08/26 03:29:34 step 6: mse=0.399122 step=0.100000
2017/08/26 03:29:36 step 7: mse=0.382062 step=0.100000
2017/08/26 03:29:36 Saving...
2017/08/26 03:29:36 Gathering batch of experience...
2017/08/26 03:29:49 batch 62: mean=11.283019 stddev=5.519698 entropy=1.197549 frames=35488 count=53
2017/08/26 03:29:49 Training policy...
2017/08/26 03:29:55 step 0: objective=0.022943065
2017/08/26 03:30:00 step 1: objective=0.02297835
2017/08/26 03:30:04 step 2: objective=0.023013804
2017/08/26 03:30:09 step 3: objective=0.023049232
2017/08/26 03:30:13 step 4: objective=0.023084568
2017/08/26 03:30:18 step 5: objective=0.02311348
2017/08/26 03:30:22 step 6: objective=0.02314215
2017/08/26 03:30:27 step 7: objective=0.023165233
2017/08/26 03:30:27 Training value function...
2017/08/26 03:30:29 step 0: mse=0.557105 step=0.100000
2017/08/26 03:30:31 step 1: mse=0.527571 step=0.100000
2017/08/26 03:30:34 step 2: mse=0.502540 step=0.100000
2017/08/26 03:30:36 step 3: mse=0.487629 step=0.100000
2017/08/26 03:30:38 step 4: mse=0.468194 step=0.100000
2017/08/26 03:30:40 step 5: mse=0.455996 step=0.100000
2017/08/26 03:30:43 step 6: mse=0.445686 step=0.100000
2017/08/26 03:30:45 step 7: mse=0.438210 step=0.100000
2017/08/26 03:30:45 Saving...
2017/08/26 03:30:45 Gathering batch of experience...
2017/08/26 03:30:58 batch 63: mean=10.517857 stddev=5.140842 entropy=1.193444 frames=36303 count=56
2017/08/26 03:30:58 Training policy...
2017/08/26 03:31:04 step 0: objective=0.010459675
2017/08/26 03:31:09 step 1: objective=0.010498889
2017/08/26 03:31:13 step 2: objective=0.010533705
2017/08/26 03:31:18 step 3: objective=0.010569555
2017/08/26 03:31:23 step 4: objective=0.010605051
2017/08/26 03:31:28 step 5: objective=0.010639247
2017/08/26 03:31:32 step 6: objective=0.010671784
2017/08/26 03:31:37 step 7: objective=0.010702523
2017/08/26 03:31:37 Training value function...
2017/08/26 03:31:40 step 0: mse=0.551133 step=0.100000
2017/08/26 03:31:42 step 1: mse=0.504715 step=0.100000
2017/08/26 03:31:44 step 2: mse=0.467919 step=0.100000
2017/08/26 03:31:47 step 3: mse=0.437749 step=0.100000
2017/08/26 03:31:49 step 4: mse=0.413103 step=0.100000
2017/08/26 03:31:51 step 5: mse=0.393642 step=0.100000
2017/08/26 03:31:54 step 6: mse=0.376605 step=0.100000
2017/08/26 03:31:56 step 7: mse=0.358652 step=0.100000
2017/08/26 03:31:56 Saving...
2017/08/26 03:31:56 Gathering batch of experience...
2017/08/26 03:32:09 batch 64: mean=12.625000 stddev=4.585416 entropy=1.189136 frames=35573 count=48
2017/08/26 03:32:09 Training policy...
2017/08/26 03:32:15 step 0: objective=0.031365834
2017/08/26 03:32:20 step 1: objective=0.03142921
2017/08/26 03:32:24 step 2: objective=0.031493336
2017/08/26 03:32:29 step 3: objective=0.031556025
2017/08/26 03:32:33 step 4: objective=0.031595964
2017/08/26 03:32:38 step 5: objective=0.031647526
2017/08/26 03:32:42 step 6: objective=0.031678967
2017/08/26 03:32:47 step 7: objective=0.031737898
2017/08/26 03:32:47 Training value function...
2017/08/26 03:32:50 step 0: mse=0.654596 step=0.100000
2017/08/26 03:32:52 step 1: mse=0.607591 step=0.100000
2017/08/26 03:32:54 step 2: mse=0.569434 step=0.100000
2017/08/26 03:32:57 step 3: mse=0.542265 step=0.100000
2017/08/26 03:32:59 step 4: mse=0.517787 step=0.100000
2017/08/26 03:33:01 step 5: mse=0.495023 step=0.100000
2017/08/26 03:33:04 step 6: mse=0.480392 step=0.100000
2017/08/26 03:33:06 step 7: mse=0.465386 step=0.100000
2017/08/26 03:33:06 Saving...
2017/08/26 03:33:06 Gathering batch of experience...
2017/08/26 03:33:19 batch 65: mean=10.607143 stddev=5.410567 entropy=1.186709 frames=35430 count=56
2017/08/26 03:33:19 Training policy...
2017/08/26 03:33:25 step 0: objective=0.01242162
2017/08/26 03:33:30 step 1: objective=0.012443948
2017/08/26 03:33:34 step 2: objective=0.0124661885
2017/08/26 03:33:39 step 3: objective=0.012488457
2017/08/26 03:33:43 step 4: objective=0.01251071
2017/08/26 03:33:48 step 5: objective=0.0125389565
2017/08/26 03:33:52 step 6: objective=0.012561196
2017/08/26 03:33:57 step 7: objective=0.012589264
2017/08/26 03:33:57 Training value function...
2017/08/26 03:34:00 step 0: mse=0.716806 step=0.100000
2017/08/26 03:34:02 step 1: mse=0.669104 step=0.100000
2017/08/26 03:34:04 step 2: mse=0.630576 step=0.100000
2017/08/26 03:34:07 step 3: mse=0.599352 step=0.100000
2017/08/26 03:34:09 step 4: mse=0.561713 step=0.100000
2017/08/26 03:34:11 step 5: mse=0.524277 step=0.100000
2017/08/26 03:34:13 step 6: mse=0.505329 step=0.100000
2017/08/26 03:34:15 step 7: mse=0.490773 step=0.100000
2017/08/26 03:34:15 Saving...
2017/08/26 03:34:15 Gathering batch of experience...
2017/08/26 03:34:28 batch 66: mean=11.269231 stddev=5.509137 entropy=1.189290 frames=35098 count=52
2017/08/26 03:34:28 Training policy...
2017/08/26 03:34:34 step 0: objective=0.024820877
2017/08/26 03:34:39 step 1: objective=0.024896313
2017/08/26 03:34:43 step 2: objective=0.024972726
2017/08/26 03:34:48 step 3: objective=0.025050191
2017/08/26 03:34:52 step 4: objective=0.025113719
2017/08/26 03:34:57 step 5: objective=0.025152653
2017/08/26 03:35:02 step 6: objective=0.025186077
2017/08/26 03:35:06 step 7: objective=0.025216388
2017/08/26 03:35:06 Training value function...
2017/08/26 03:35:09 step 0: mse=0.654191 step=0.100000
2017/08/26 03:35:11 step 1: mse=0.608642 step=0.100000
2017/08/26 03:35:13 step 2: mse=0.572203 step=0.100000
2017/08/26 03:35:15 step 3: mse=0.538950 step=0.100000
2017/08/26 03:35:18 step 4: mse=0.514111 step=0.100000
2017/08/26 03:35:20 step 5: mse=0.491344 step=0.100000
2017/08/26 03:35:22 step 6: mse=0.470288 step=0.100000
2017/08/26 03:35:24 step 7: mse=0.453057 step=0.100000
2017/08/26 03:35:24 Saving...
2017/08/26 03:35:24 Gathering batch of experience...
2017/08/26 03:35:37 batch 67: mean=11.433962 stddev=4.831147 entropy=1.192147 frames=35543 count=53
2017/08/26 03:35:37 Training policy...
2017/08/26 03:35:43 step 0: objective=0.043123305
2017/08/26 03:35:48 step 1: objective=0.043175906
2017/08/26 03:35:52 step 2: objective=0.04322872
2017/08/26 03:35:57 step 3: objective=0.0432816
2017/08/26 03:36:02 step 4: objective=0.043334752
2017/08/26 03:36:06 step 5: objective=0.043380402
2017/08/26 03:36:11 step 6: objective=0.043437377
2017/08/26 03:36:16 step 7: objective=0.043470766
2017/08/26 03:36:16 Training value function...
2017/08/26 03:36:18 step 0: mse=0.563232 step=0.100000
2017/08/26 03:36:21 step 1: mse=0.536763 step=0.100000
2017/08/26 03:36:23 step 2: mse=0.515501 step=0.100000
2017/08/26 03:36:25 step 3: mse=0.499787 step=0.100000
2017/08/26 03:36:27 step 4: mse=0.481190 step=0.100000
2017/08/26 03:36:29 step 5: mse=0.468216 step=0.100000
2017/08/26 03:36:32 step 6: mse=0.455528 step=0.100000
2017/08/26 03:36:34 step 7: mse=0.445519 step=0.100000
2017/08/26 03:36:34 Saving...
2017/08/26 03:36:34 Gathering batch of experience...
2017/08/26 03:36:47 batch 68: mean=11.396226 stddev=4.253033 entropy=1.185413 frames=35383 count=53
2017/08/26 03:36:47 Training policy...
2017/08/26 03:36:53 step 0: objective=0.02979395
2017/08/26 03:36:58 step 1: objective=0.029831145
2017/08/26 03:37:02 step 2: objective=0.029868232
2017/08/26 03:37:07 step 3: objective=0.029905416
2017/08/26 03:37:11 step 4: objective=0.029942572
2017/08/26 03:37:16 step 5: objective=0.029979687
2017/08/26 03:37:21 step 6: objective=0.030016752
2017/08/26 03:37:25 step 7: objective=0.0300725
2017/08/26 03:37:25 Training value function...
2017/08/26 03:37:28 step 0: mse=0.617575 step=0.100000
2017/08/26 03:37:30 step 1: mse=0.580900 step=0.100000
2017/08/26 03:37:32 step 2: mse=0.551162 step=0.100000
2017/08/26 03:37:35 step 3: mse=0.530031 step=0.100000
2017/08/26 03:37:37 step 4: mse=0.509452 step=0.100000
2017/08/26 03:37:39 step 5: mse=0.493833 step=0.100000
2017/08/26 03:37:42 step 6: mse=0.481769 step=0.100000
2017/08/26 03:37:44 step 7: mse=0.470859 step=0.100000
2017/08/26 03:37:44 Saving...
2017/08/26 03:37:44 Gathering batch of experience...
2017/08/26 03:37:57 batch 69: mean=10.641509 stddev=4.352810 entropy=1.191332 frames=35055 count=53
2017/08/26 03:37:57 Training policy...
2017/08/26 03:38:03 step 0: objective=0.0067159934
2017/08/26 03:38:07 step 1: objective=0.006754233
2017/08/26 03:38:12 step 2: objective=0.0067970753
2017/08/26 03:38:16 step 3: objective=0.006840087
2017/08/26 03:38:21 step 4: objective=0.006883186
2017/08/26 03:38:25 step 5: objective=0.0069258246
2017/08/26 03:38:30 step 6: objective=0.006957419
2017/08/26 03:38:35 step 7: objective=0.0069900574
2017/08/26 03:38:35 Training value function...
2017/08/26 03:38:37 step 0: mse=0.437886 step=0.100000
2017/08/26 03:38:40 step 1: mse=0.418346 step=0.100000
2017/08/26 03:38:42 step 2: mse=0.402766 step=0.100000
2017/08/26 03:38:44 step 3: mse=0.390403 step=0.100000
2017/08/26 03:38:46 step 4: mse=0.379335 step=0.100000
2017/08/26 03:38:48 step 5: mse=0.370301 step=0.100000
2017/08/26 03:38:51 step 6: mse=0.360657 step=0.100000
2017/08/26 03:38:53 step 7: mse=0.354249 step=0.100000
2017/08/26 03:38:53 Saving...
2017/08/26 03:38:53 Gathering batch of experience...
2017/08/26 03:39:05 batch 70: mean=10.200000 stddev=4.291217 entropy=1.188300 frames=34765 count=55
2017/08/26 03:39:05 Training policy...
2017/08/26 03:39:12 step 0: objective=0.017196637
2017/08/26 03:39:16 step 1: objective=0.017230162
2017/08/26 03:39:21 step 2: objective=0.017263675
2017/08/26 03:39:25 step 3: objective=0.017297452
2017/08/26 03:39:30 step 4: objective=0.017331196
2017/08/26 03:39:34 step 5: objective=0.017364746
2017/08/26 03:39:39 step 6: objective=0.017409168
2017/08/26 03:39:44 step 7: objective=0.017451873
2017/08/26 03:39:44 Training value function...
2017/08/26 03:39:47 step 0: mse=0.477410 step=0.100000
2017/08/26 03:39:49 step 1: mse=0.456875 step=0.100000
2017/08/26 03:39:51 step 2: mse=0.441504 step=0.100000
2017/08/26 03:39:53 step 3: mse=0.428949 step=0.100000
2017/08/26 03:39:55 step 4: mse=0.414750 step=0.100000
2017/08/26 03:39:57 step 5: mse=0.404219 step=0.100000
2017/08/26 03:40:00 step 6: mse=0.396154 step=0.100000
2017/08/26 03:40:02 step 7: mse=0.382094 step=0.100000
2017/08/26 03:40:02 Saving...
2017/08/26 03:40:02 Gathering batch of experience...
2017/08/26 03:40:15 batch 71: mean=11.264151 stddev=3.603724 entropy=1.182701 frames=35577 count=53
2017/08/26 03:40:15 Training policy...
2017/08/26 03:40:21 step 0: objective=0.029966531
2017/08/26 03:40:26 step 1: objective=0.029997548
2017/08/26 03:40:30 step 2: objective=0.030028628
2017/08/26 03:40:35 step 3: objective=0.0300596
2017/08/26 03:40:40 step 4: objective=0.03009082
2017/08/26 03:40:44 step 5: objective=0.03012172
2017/08/26 03:40:50 step 6: objective=0.030151257
2017/08/26 03:40:54 step 7: objective=0.030187586
2017/08/26 03:40:54 Training value function...
2017/08/26 03:40:57 step 0: mse=0.502433 step=0.100000
2017/08/26 03:40:59 step 1: mse=0.480154 step=0.100000
2017/08/26 03:41:02 step 2: mse=0.464070 step=0.100000
2017/08/26 03:41:04 step 3: mse=0.445445 step=0.100000
2017/08/26 03:41:06 step 4: mse=0.431548 step=0.100000
2017/08/26 03:41:08 step 5: mse=0.419025 step=0.100000
2017/08/26 03:41:11 step 6: mse=0.411802 step=0.100000
2017/08/26 03:41:13 step 7: mse=0.399200 step=0.100000
2017/08/26 03:41:13 Saving...
2017/08/26 03:41:13 Gathering batch of experience...
2017/08/26 03:41:26 batch 72: mean=12.019608 stddev=4.767086 entropy=1.185057 frames=35532 count=51
2017/08/26 03:41:26 Training policy...
2017/08/26 03:41:32 step 0: objective=0.03638776
2017/08/26 03:41:37 step 1: objective=0.03641858
2017/08/26 03:41:42 step 2: objective=0.03644927
2017/08/26 03:41:46 step 3: objective=0.036479965
2017/08/26 03:41:51 step 4: objective=0.03651085
2017/08/26 03:41:56 step 5: objective=0.03654131
2017/08/26 03:42:01 step 6: objective=0.03657125
2017/08/26 03:42:05 step 7: objective=0.036590543
2017/08/26 03:42:05 Training value function...
2017/08/26 03:42:08 step 0: mse=0.562446 step=0.100000
2017/08/26 03:42:10 step 1: mse=0.541103 step=0.100000
2017/08/26 03:42:12 step 2: mse=0.523993 step=0.100000
2017/08/26 03:42:15 step 3: mse=0.509641 step=0.100000
2017/08/26 03:42:17 step 4: mse=0.497819 step=0.100000
2017/08/26 03:42:19 step 5: mse=0.488600 step=0.100000
2017/08/26 03:42:21 step 6: mse=0.477041 step=0.100000
2017/08/26 03:42:23 step 7: mse=0.454588 step=0.100000
2017/08/26 03:42:23 Saving...
2017/08/26 03:42:24 Gathering batch of experience...
2017/08/26 03:42:37 batch 73: mean=12.280000 stddev=5.535486 entropy=1.187251 frames=35202 count=50
2017/08/26 03:42:37 Training policy...
2017/08/26 03:42:43 step 0: objective=0.02506114
2017/08/26 03:42:47 step 1: objective=0.02510504
2017/08/26 03:42:52 step 2: objective=0.025149172
2017/08/26 03:42:57 step 3: objective=0.025193153
2017/08/26 03:43:01 step 4: objective=0.025237445
2017/08/26 03:43:06 step 5: objective=0.025281547
2017/08/26 03:43:11 step 6: objective=0.025324788
2017/08/26 03:43:15 step 7: objective=0.02535914
2017/08/26 03:43:15 Training value function...
2017/08/26 03:43:18 step 0: mse=0.768788 step=0.100000
2017/08/26 03:43:20 step 1: mse=0.727338 step=0.100000
2017/08/26 03:43:22 step 2: mse=0.694003 step=0.100000
2017/08/26 03:43:25 step 3: mse=0.666220 step=0.100000
2017/08/26 03:43:27 step 4: mse=0.643861 step=0.100000
2017/08/26 03:43:29 step 5: mse=0.625646 step=0.100000
2017/08/26 03:43:31 step 6: mse=0.611528 step=0.100000
2017/08/26 03:43:34 step 7: mse=0.598227 step=0.100000
2017/08/26 03:43:34 Saving...
2017/08/26 03:43:34 Gathering batch of experience...
2017/08/26 03:43:47 batch 74: mean=11.296296 stddev=5.314654 entropy=1.186832 frames=36002 count=54
2017/08/26 03:43:47 Training policy...
2017/08/26 03:43:53 step 0: objective=0.03453799
2017/08/26 03:43:58 step 1: objective=0.034596458
2017/08/26 03:44:03 step 2: objective=0.03465466
2017/08/26 03:44:07 step 3: objective=0.03471272
2017/08/26 03:44:12 step 4: objective=0.034770582
2017/08/26 03:44:17 step 5: objective=0.034828357
2017/08/26 03:44:22 step 6: objective=0.034891985
2017/08/26 03:44:26 step 7: objective=0.034952905
2017/08/26 03:44:26 Training value function...
2017/08/26 03:44:29 step 0: mse=0.664528 step=0.100000
2017/08/26 03:44:31 step 1: mse=0.623987 step=0.100000
2017/08/26 03:44:34 step 2: mse=0.590089 step=0.100000
2017/08/26 03:44:36 step 3: mse=0.562854 step=0.100000
2017/08/26 03:44:38 step 4: mse=0.538388 step=0.100000
2017/08/26 03:44:40 step 5: mse=0.516381 step=0.100000
2017/08/26 03:44:42 step 6: mse=0.496393 step=0.100000
2017/08/26 03:44:45 step 7: mse=0.470118 step=0.100000
2017/08/26 03:44:45 Saving...
2017/08/26 03:44:45 Gathering batch of experience...
2017/08/26 03:44:58 batch 75: mean=11.192308 stddev=4.043221 entropy=1.190374 frames=35035 count=52
2017/08/26 03:44:58 Training policy...
2017/08/26 03:45:04 step 0: objective=0.016780246
2017/08/26 03:45:08 step 1: objective=0.016824393
2017/08/26 03:45:13 step 2: objective=0.01686842
2017/08/26 03:45:18 step 3: objective=0.01691244
2017/08/26 03:45:22 step 4: objective=0.01695643
2017/08/26 03:45:27 step 5: objective=0.01699899
2017/08/26 03:45:32 step 6: objective=0.0170287
2017/08/26 03:45:37 step 7: objective=0.017042292
2017/08/26 03:45:37 Training value function...
2017/08/26 03:45:39 step 0: mse=0.506702 step=0.100000
2017/08/26 03:45:41 step 1: mse=0.493703 step=0.100000
2017/08/26 03:45:44 step 2: mse=0.482836 step=0.100000
2017/08/26 03:45:46 step 3: mse=0.472757 step=0.100000
2017/08/26 03:45:48 step 4: mse=0.465863 step=0.100000
2017/08/26 03:45:50 step 5: mse=0.455816 step=0.100000
2017/08/26 03:45:52 step 6: mse=0.448323 step=0.100000
2017/08/26 03:45:55 step 7: mse=0.432103 step=0.100000
2017/08/26 03:45:55 Saving...
2017/08/26 03:45:55 Gathering batch of experience...
2017/08/26 03:46:08 batch 76: mean=11.692308 stddev=4.171969 entropy=1.189041 frames=35561 count=52
2017/08/26 03:46:08 Training policy...
2017/08/26 03:46:14 step 0: objective=0.03184582
2017/08/26 03:46:19 step 1: objective=0.03189754
2017/08/26 03:46:23 step 2: objective=0.031949468
2017/08/26 03:46:28 step 3: objective=0.032001838
2017/08/26 03:46:33 step 4: objective=0.032054402
2017/08/26 03:46:38 step 5: objective=0.032105
2017/08/26 03:46:42 step 6: objective=0.032135196
2017/08/26 03:46:47 step 7: objective=0.032166578
2017/08/26 03:46:47 Training value function...
2017/08/26 03:46:50 step 0: mse=0.554074 step=0.100000
2017/08/26 03:46:52 step 1: mse=0.536417 step=0.100000
2017/08/26 03:46:54 step 2: mse=0.521906 step=0.100000
2017/08/26 03:46:57 step 3: mse=0.506102 step=0.100000
2017/08/26 03:46:59 step 4: mse=0.494992 step=0.100000
2017/08/26 03:47:01 step 5: mse=0.481705 step=0.100000
2017/08/26 03:47:03 step 6: mse=0.467419 step=0.100000
2017/08/26 03:47:05 step 7: mse=0.458628 step=0.100000
2017/08/26 03:47:05 Saving...
2017/08/26 03:47:06 Gathering batch of experience...
2017/08/26 03:47:18 batch 77: mean=11.843137 stddev=4.551977 entropy=1.189945 frames=35051 count=51
2017/08/26 03:47:18 Training policy...
2017/08/26 03:47:25 step 0: objective=0.023964139
2017/08/26 03:47:30 step 1: objective=0.02399055
2017/08/26 03:47:35 step 2: objective=0.024016896
2017/08/26 03:47:40 step 3: objective=0.024043364
2017/08/26 03:47:45 step 4: objective=0.024069708
2017/08/26 03:47:49 step 5: objective=0.024095854
2017/08/26 03:47:54 step 6: objective=0.024122283
2017/08/26 03:47:59 step 7: objective=0.024148397
2017/08/26 03:47:59 Training value function...
2017/08/26 03:48:02 step 0: mse=0.579189 step=0.100000
2017/08/26 03:48:04 step 1: mse=0.551550 step=0.100000
2017/08/26 03:48:06 step 2: mse=0.526807 step=0.100000
2017/08/26 03:48:08 step 3: mse=0.501859 step=0.100000
2017/08/26 03:48:10 step 4: mse=0.483333 step=0.100000
2017/08/26 03:48:13 step 5: mse=0.466577 step=0.100000
2017/08/26 03:48:15 step 6: mse=0.452099 step=0.100000
2017/08/26 03:48:17 step 7: mse=0.441193 step=0.100000
2017/08/26 03:48:17 Saving...
2017/08/26 03:48:17 Gathering batch of experience...
2017/08/26 03:48:30 batch 78: mean=11.634615 stddev=5.140446 entropy=1.184404 frames=35341 count=52
2017/08/26 03:48:30 Training policy...
2017/08/26 03:48:36 step 0: objective=0.034867596
2017/08/26 03:48:41 step 1: objective=0.034930516
2017/08/26 03:48:46 step 2: objective=0.034993555
2017/08/26 03:48:50 step 3: objective=0.035056364
2017/08/26 03:48:55 step 4: objective=0.035119116
2017/08/26 03:49:00 step 5: objective=0.035175882
2017/08/26 03:49:05 step 6: objective=0.035202045
2017/08/26 03:49:09 step 7: objective=0.035238963
2017/08/26 03:49:09 Training value function...
2017/08/26 03:49:12 step 0: mse=0.619931 step=0.100000
2017/08/26 03:49:14 step 1: mse=0.585233 step=0.100000
2017/08/26 03:49:17 step 2: mse=0.559462 step=0.100000
2017/08/26 03:49:19 step 3: mse=0.530784 step=0.100000
2017/08/26 03:49:21 step 4: mse=0.511599 step=0.100000
2017/08/26 03:49:24 step 5: mse=0.487059 step=0.100000
2017/08/26 03:49:26 step 6: mse=0.471848 step=0.100000
2017/08/26 03:49:28 step 7: mse=0.460103 step=0.100000
2017/08/26 03:49:28 Saving...
2017/08/26 03:49:28 Gathering batch of experience...
2017/08/26 03:49:41 batch 79: mean=10.943396 stddev=3.662225 entropy=1.180651 frames=34651 count=53
2017/08/26 03:49:41 Training policy...
2017/08/26 03:49:47 step 0: objective=0.011253393
2017/08/26 03:49:52 step 1: objective=0.011306071
2017/08/26 03:49:56 step 2: objective=0.011358628
2017/08/26 03:50:01 step 3: objective=0.011411154
2017/08/26 03:50:06 step 4: objective=0.011463479
2017/08/26 03:50:10 step 5: objective=0.011514462
2017/08/26 03:50:15 step 6: objective=0.011572929
2017/08/26 03:50:20 step 7: objective=0.0115977395
2017/08/26 03:50:20 Training value function...
2017/08/26 03:50:22 step 0: mse=0.443292 step=0.100000
2017/08/26 03:50:25 step 1: mse=0.425112 step=0.100000
2017/08/26 03:50:27 step 2: mse=0.410571 step=0.100000
2017/08/26 03:50:29 step 3: mse=0.399473 step=0.100000
2017/08/26 03:50:31 step 4: mse=0.390305 step=0.100000
2017/08/26 03:50:33 step 5: mse=0.381694 step=0.100000
2017/08/26 03:50:36 step 6: mse=0.374028 step=0.100000
2017/08/26 03:50:38 step 7: mse=0.366026 step=0.100000
2017/08/26 03:50:38 Saving...
2017/08/26 03:50:38 Gathering batch of experience...
2017/08/26 03:50:51 batch 80: mean=10.290909 stddev=3.998512 entropy=1.187572 frames=34529 count=55
2017/08/26 03:50:51 Training policy...
2017/08/26 03:50:57 step 0: objective=0.017978963
2017/08/26 03:51:01 step 1: objective=0.018031653
2017/08/26 03:51:06 step 2: objective=0.018084357
2017/08/26 03:51:11 step 3: objective=0.018131822
2017/08/26 03:51:15 step 4: objective=0.018179666
2017/08/26 03:51:20 step 5: objective=0.018227695
2017/08/26 03:51:25 step 6: objective=0.018274855
2017/08/26 03:51:29 step 7: objective=0.018319659
2017/08/26 03:51:29 Training value function...
2017/08/26 03:51:32 step 0: mse=0.454356 step=0.100000
2017/08/26 03:51:34 step 1: mse=0.436986 step=0.100000
2017/08/26 03:51:36 step 2: mse=0.424177 step=0.100000
2017/08/26 03:51:38 step 3: mse=0.413624 step=0.100000
2017/08/26 03:51:41 step 4: mse=0.404760 step=0.100000
2017/08/26 03:51:43 step 5: mse=0.397887 step=0.100000
2017/08/26 03:51:45 step 6: mse=0.387774 step=0.100000
2017/08/26 03:51:47 step 7: mse=0.381895 step=0.100000
2017/08/26 03:51:47 Saving...
2017/08/26 03:51:47 Gathering batch of experience...
2017/08/26 03:52:00 batch 81: mean=10.327273 stddev=4.040947 entropy=1.188003 frames=35230 count=55
2017/08/26 03:52:00 Training policy...
2017/08/26 03:52:06 step 0: objective=0.014950153
2017/08/26 03:52:11 step 1: objective=0.0149753075
2017/08/26 03:52:16 step 2: objective=0.015000567
2017/08/26 03:52:21 step 3: objective=0.015026185
2017/08/26 03:52:26 step 4: objective=0.015051723
2017/08/26 03:52:30 step 5: objective=0.015077605
2017/08/26 03:52:35 step 6: objective=0.015103376
2017/08/26 03:52:40 step 7: objective=0.0151221575
2017/08/26 03:52:40 Training value function...
2017/08/26 03:52:43 step 0: mse=0.390109 step=0.100000
2017/08/26 03:52:45 step 1: mse=0.378102 step=0.100000
2017/08/26 03:52:47 step 2: mse=0.365596 step=0.100000
2017/08/26 03:52:49 step 3: mse=0.358034 step=0.100000
2017/08/26 03:52:52 step 4: mse=0.349090 step=0.100000
2017/08/26 03:52:54 step 5: mse=0.341094 step=0.100000
2017/08/26 03:52:56 step 6: mse=0.336667 step=0.100000
2017/08/26 03:52:58 step 7: mse=0.330160 step=0.100000
2017/08/26 03:52:58 Saving...
2017/08/26 03:52:58 Gathering batch of experience...
2017/08/26 03:53:11 batch 82: mean=11.075472 stddev=4.765636 entropy=1.180938 frames=34744 count=53
2017/08/26 03:53:11 Training policy...
2017/08/26 03:53:17 step 0: objective=0.040702883
2017/08/26 03:53:22 step 1: objective=0.040737126
2017/08/26 03:53:27 step 2: objective=0.040770933
2017/08/26 03:53:32 step 3: objective=0.040804565
2017/08/26 03:53:36 step 4: objective=0.040838037
2017/08/26 03:53:41 step 5: objective=0.040871352
2017/08/26 03:53:46 step 6: objective=0.04090494
2017/08/26 03:53:50 step 7: objective=0.040935364
2017/08/26 03:53:50 Training value function...
2017/08/26 03:53:53 step 0: mse=0.716567 step=0.100000
2017/08/26 03:53:55 step 1: mse=0.657716 step=0.100000
2017/08/26 03:53:57 step 2: mse=0.610936 step=0.100000
2017/08/26 03:54:00 step 3: mse=0.571724 step=0.100000
2017/08/26 03:54:02 step 4: mse=0.538836 step=0.100000
2017/08/26 03:54:04 step 5: mse=0.512267 step=0.100000
2017/08/26 03:54:06 step 6: mse=0.486051 step=0.100000
2017/08/26 03:54:08 step 7: mse=0.467844 step=0.100000
2017/08/26 03:54:08 Saving...
2017/08/26 03:54:08 Gathering batch of experience...
2017/08/26 03:54:21 batch 83: mean=10.596491 stddev=5.486378 entropy=1.189482 frames=35268 count=57
2017/08/26 03:54:21 Training policy...
2017/08/26 03:54:28 step 0: objective=0.024964457
2017/08/26 03:54:32 step 1: objective=0.024997387
2017/08/26 03:54:37 step 2: objective=0.025030091
2017/08/26 03:54:42 step 3: objective=0.025062617
2017/08/26 03:54:47 step 4: objective=0.025094872
2017/08/26 03:54:52 step 5: objective=0.025126932
2017/08/26 03:54:56 step 6: objective=0.025157632
2017/08/26 03:55:01 step 7: objective=0.025200712
2017/08/26 03:55:01 Training value function...
2017/08/26 03:55:04 step 0: mse=0.718627 step=0.100000
2017/08/26 03:55:06 step 1: mse=0.680791 step=0.100000
2017/08/26 03:55:08 step 2: mse=0.648573 step=0.100000
2017/08/26 03:55:10 step 3: mse=0.621994 step=0.100000
2017/08/26 03:55:13 step 4: mse=0.594229 step=0.100000
2017/08/26 03:55:15 step 5: mse=0.571268 step=0.100000
2017/08/26 03:55:17 step 6: mse=0.555984 step=0.100000
2017/08/26 03:55:19 step 7: mse=0.542480 step=0.100000
2017/08/26 03:55:19 Saving...
2017/08/26 03:55:19 Gathering batch of experience...
2017/08/26 03:55:32 batch 84: mean=11.509804 stddev=4.491266 entropy=1.183313 frames=35210 count=51
2017/08/26 03:55:32 Training policy...
2017/08/26 03:55:39 step 0: objective=0.024239097
2017/08/26 03:55:43 step 1: objective=0.024262136
2017/08/26 03:55:48 step 2: objective=0.024285095
2017/08/26 03:55:53 step 3: objective=0.024307901
2017/08/26 03:55:58 step 4: objective=0.024330415
2017/08/26 03:56:03 step 5: objective=0.024353158
2017/08/26 03:56:08 step 6: objective=0.024375658
2017/08/26 03:56:12 step 7: objective=0.02439778
2017/08/26 03:56:12 Training value function...
2017/08/26 03:56:15 step 0: mse=0.535953 step=0.100000
2017/08/26 03:56:17 step 1: mse=0.513001 step=0.100000
2017/08/26 03:56:20 step 2: mse=0.495004 step=0.100000
2017/08/26 03:56:22 step 3: mse=0.475231 step=0.100000
2017/08/26 03:56:24 step 4: mse=0.461791 step=0.100000
2017/08/26 03:56:26 step 5: mse=0.443906 step=0.100000
2017/08/26 03:56:28 step 6: mse=0.431078 step=0.100000
2017/08/26 03:56:31 step 7: mse=0.423289 step=0.100000
2017/08/26 03:56:31 Saving...
2017/08/26 03:56:31 Gathering batch of experience...
2017/08/26 03:56:44 batch 85: mean=11.148148 stddev=4.684124 entropy=1.186911 frames=35335 count=54
2017/08/26 03:56:44 Training policy...
2017/08/26 03:56:51 step 0: objective=0.0279466
2017/08/26 03:56:55 step 1: objective=0.027979473
2017/08/26 03:57:00 step 2: objective=0.02801246
2017/08/26 03:57:05 step 3: objective=0.028045045
2017/08/26 03:57:10 step 4: objective=0.028077712
2017/08/26 03:57:15 step 5: objective=0.028110232
2017/08/26 03:57:20 step 6: objective=0.028142834
2017/08/26 03:57:25 step 7: objective=0.02817489
2017/08/26 03:57:25 Training value function...
2017/08/26 03:57:27 step 0: mse=0.759719 step=0.100000
2017/08/26 03:57:30 step 1: mse=0.698727 step=0.100000
2017/08/26 03:57:32 step 2: mse=0.649654 step=0.100000
2017/08/26 03:57:34 step 3: mse=0.610047 step=0.100000
2017/08/26 03:57:36 step 4: mse=0.578035 step=0.100000
2017/08/26 03:57:39 step 5: mse=0.551963 step=0.100000
2017/08/26 03:57:41 step 6: mse=0.529025 step=0.100000
2017/08/26 03:57:43 step 7: mse=0.510154 step=0.100000
2017/08/26 03:57:43 Saving...
2017/08/26 03:57:43 Gathering batch of experience...
2017/08/26 03:57:56 batch 86: mean=10.836364 stddev=5.529306 entropy=1.175300 frames=34995 count=55
2017/08/26 03:57:56 Training policy...
2017/08/26 03:58:02 step 0: objective=0.021802895
2017/08/26 03:58:07 step 1: objective=0.021882154
2017/08/26 03:58:12 step 2: objective=0.021961179
2017/08/26 03:58:17 step 3: objective=0.02203977
2017/08/26 03:58:21 step 4: objective=0.022116067
2017/08/26 03:58:26 step 5: objective=0.0221966
2017/08/26 03:58:31 step 6: objective=0.022269921
2017/08/26 03:58:36 step 7: objective=0.022304041
2017/08/26 03:58:36 Training value function...
2017/08/26 03:58:39 step 0: mse=0.816384 step=0.100000
2017/08/26 03:58:41 step 1: mse=0.750103 step=0.100000
2017/08/26 03:58:43 step 2: mse=0.698203 step=0.100000
2017/08/26 03:58:45 step 3: mse=0.645777 step=0.100000
2017/08/26 03:58:48 step 4: mse=0.603600 step=0.100000
2017/08/26 03:58:50 step 5: mse=0.573661 step=0.100000
2017/08/26 03:58:52 step 6: mse=0.544502 step=0.100000
2017/08/26 03:58:54 step 7: mse=0.518313 step=0.100000
2017/08/26 03:58:54 Saving...
2017/08/26 03:58:54 Gathering batch of experience...
2017/08/26 03:59:07 batch 87: mean=11.283019 stddev=5.122563 entropy=1.172552 frames=35456 count=53
2017/08/26 03:59:07 Training policy...
2017/08/26 03:59:14 step 0: objective=0.016935075
2017/08/26 03:59:19 step 1: objective=0.01701052
2017/08/26 03:59:23 step 2: objective=0.01708645
2017/08/26 03:59:28 step 3: objective=0.017175071
2017/08/26 03:59:33 step 4: objective=0.017262135
2017/08/26 03:59:38 step 5: objective=0.017321553
2017/08/26 03:59:43 step 6: objective=0.017368225
2017/08/26 03:59:48 step 7: objective=0.017401392
2017/08/26 03:59:48 Training value function...
2017/08/26 03:59:51 step 0: mse=0.580709 step=0.100000
2017/08/26 03:59:53 step 1: mse=0.538688 step=0.100000
2017/08/26 03:59:55 step 2: mse=0.503580 step=0.100000
2017/08/26 03:59:57 step 3: mse=0.476781 step=0.100000
2017/08/26 04:00:00 step 4: mse=0.454606 step=0.100000
2017/08/26 04:00:02 step 5: mse=0.437393 step=0.100000
2017/08/26 04:00:04 step 6: mse=0.421874 step=0.100000
2017/08/26 04:00:06 step 7: mse=0.406736 step=0.100000
2017/08/26 04:00:06 Saving...
2017/08/26 04:00:06 Gathering batch of experience...
2017/08/26 04:00:19 batch 88: mean=10.232143 stddev=4.242603 entropy=1.178506 frames=35540 count=56
2017/08/26 04:00:19 Training policy...
2017/08/26 04:00:26 step 0: objective=0.018575173
2017/08/26 04:00:31 step 1: objective=0.018635167
2017/08/26 04:00:36 step 2: objective=0.018694783
2017/08/26 04:00:41 step 3: objective=0.0187538
2017/08/26 04:00:46 step 4: objective=0.018808939
2017/08/26 04:00:51 step 5: objective=0.018826721
2017/08/26 04:00:56 step 6: objective=0.018856168
2017/08/26 04:01:01 step 7: objective=0.018874004
2017/08/26 04:01:01 Training value function...
2017/08/26 04:01:04 step 0: mse=0.570714 step=0.100000
2017/08/26 04:01:06 step 1: mse=0.532025 step=0.100000
2017/08/26 04:01:08 step 2: mse=0.500889 step=0.100000
2017/08/26 04:01:10 step 3: mse=0.473962 step=0.100000
2017/08/26 04:01:12 step 4: mse=0.450407 step=0.100000
2017/08/26 04:01:15 step 5: mse=0.432641 step=0.100000
2017/08/26 04:01:17 step 6: mse=0.411510 step=0.100000
2017/08/26 04:01:19 step 7: mse=0.397759 step=0.100000
2017/08/26 04:01:19 Saving...
2017/08/26 04:01:19 Gathering batch of experience...
2017/08/26 04:01:32 batch 89: mean=11.115385 stddev=3.661934 entropy=1.180900 frames=35276 count=52
2017/08/26 04:01:32 Training policy...
2017/08/26 04:01:39 step 0: objective=0.03018538
2017/08/26 04:01:44 step 1: objective=0.030234113
2017/08/26 04:01:48 step 2: objective=0.030282753
2017/08/26 04:01:53 step 3: objective=0.03033141
2017/08/26 04:01:58 step 4: objective=0.030380009
2017/08/26 04:02:03 step 5: objective=0.030425481
2017/08/26 04:02:08 step 6: objective=0.030457443
2017/08/26 04:02:13 step 7: objective=0.030481918
2017/08/26 04:02:13 Training value function...
2017/08/26 04:02:16 step 0: mse=0.472995 step=0.100000
2017/08/26 04:02:18 step 1: mse=0.445849 step=0.100000
2017/08/26 04:02:20 step 2: mse=0.423694 step=0.100000
2017/08/26 04:02:22 step 3: mse=0.406631 step=0.100000
2017/08/26 04:02:25 step 4: mse=0.387675 step=0.100000
2017/08/26 04:02:27 step 5: mse=0.371344 step=0.100000
2017/08/26 04:02:29 step 6: mse=0.358344 step=0.100000
2017/08/26 04:02:31 step 7: mse=0.341312 step=0.100000
2017/08/26 04:02:31 Saving...
2017/08/26 04:02:32 Gathering batch of experience...
2017/08/26 04:02:44 batch 90: mean=11.192308 stddev=4.429093 entropy=1.179963 frames=34689 count=52
2017/08/26 04:02:44 Training policy...
2017/08/26 04:02:51 step 0: objective=0.02158237
2017/08/26 04:02:56 step 1: objective=0.021636639
2017/08/26 04:03:00 step 2: objective=0.021690859
2017/08/26 04:03:05 step 3: objective=0.02174518
2017/08/26 04:03:10 step 4: objective=0.021798953
2017/08/26 04:03:15 step 5: objective=0.0218425
2017/08/26 04:03:20 step 6: objective=0.021868574
2017/08/26 04:03:25 step 7: objective=0.021895453
2017/08/26 04:03:25 Training value function...
2017/08/26 04:03:27 step 0: mse=0.570732 step=0.100000
2017/08/26 04:03:30 step 1: mse=0.540421 step=0.100000
2017/08/26 04:03:32 step 2: mse=0.515827 step=0.100000
2017/08/26 04:03:34 step 3: mse=0.495804 step=0.100000
2017/08/26 04:03:36 step 4: mse=0.478910 step=0.100000
2017/08/26 04:03:38 step 5: mse=0.465052 step=0.100000
2017/08/26 04:03:40 step 6: mse=0.448826 step=0.100000
2017/08/26 04:03:43 step 7: mse=0.439204 step=0.100000
2017/08/26 04:03:43 Saving...
2017/08/26 04:03:43 Gathering batch of experience...
2017/08/26 04:03:56 batch 91: mean=11.680000 stddev=4.258826 entropy=1.180545 frames=34420 count=50
2017/08/26 04:03:56 Training policy...
2017/08/26 04:04:02 step 0: objective=0.031272516
2017/08/26 04:04:07 step 1: objective=0.031315356
2017/08/26 04:04:11 step 2: objective=0.031358566
2017/08/26 04:04:16 step 3: objective=0.031401787
2017/08/26 04:04:21 step 4: objective=0.031445216
2017/08/26 04:04:26 step 5: objective=0.031487726
2017/08/26 04:04:31 step 6: objective=0.03152371
2017/08/26 04:04:36 step 7: objective=0.03155803
2017/08/26 04:04:36 Training value function...
2017/08/26 04:04:38 step 0: mse=0.507382 step=0.100000
2017/08/26 04:04:40 step 1: mse=0.488748 step=0.100000
2017/08/26 04:04:43 step 2: mse=0.472496 step=0.100000
2017/08/26 04:04:45 step 3: mse=0.458348 step=0.100000
2017/08/26 04:04:47 step 4: mse=0.445301 step=0.100000
2017/08/26 04:04:49 step 5: mse=0.428123 step=0.100000
2017/08/26 04:04:51 step 6: mse=0.411879 step=0.100000
2017/08/26 04:04:53 step 7: mse=0.404667 step=0.100000
2017/08/26 04:04:53 Saving...
2017/08/26 04:04:53 Gathering batch of experience...
2017/08/26 04:05:07 batch 92: mean=11.173077 stddev=4.500945 entropy=1.180574 frames=35780 count=52
2017/08/26 04:05:07 Training policy...
2017/08/26 04:05:13 step 0: objective=0.009266534
2017/08/26 04:05:18 step 1: objective=0.00930846
2017/08/26 04:05:23 step 2: objective=0.00935045
2017/08/26 04:05:29 step 3: objective=0.009392418
2017/08/26 04:05:34 step 4: objective=0.009434381
2017/08/26 04:05:39 step 5: objective=0.009476245
2017/08/26 04:05:44 step 6: objective=0.009516563
2017/08/26 04:05:49 step 7: objective=0.009552394
2017/08/26 04:05:49 Training value function...
2017/08/26 04:05:52 step 0: mse=0.496543 step=0.100000
2017/08/26 04:05:54 step 1: mse=0.468586 step=0.100000
2017/08/26 04:05:57 step 2: mse=0.445792 step=0.100000
2017/08/26 04:05:59 step 3: mse=0.426817 step=0.100000
2017/08/26 04:06:01 step 4: mse=0.410888 step=0.100000
2017/08/26 04:06:03 step 5: mse=0.397587 step=0.100000
2017/08/26 04:06:06 step 6: mse=0.386759 step=0.100000
2017/08/26 04:06:08 step 7: mse=0.374396 step=0.100000
2017/08/26 04:06:08 Saving...
2017/08/26 04:06:08 Gathering batch of experience...
2017/08/26 04:06:22 batch 93: mean=11.576923 stddev=4.207805 entropy=1.173633 frames=35931 count=52
2017/08/26 04:06:22 Training policy...
2017/08/26 04:06:28 step 0: objective=0.022990309
2017/08/26 04:06:33 step 1: objective=0.023017159
2017/08/26 04:06:38 step 2: objective=0.023044381
2017/08/26 04:06:43 step 3: objective=0.0230716
2017/08/26 04:06:49 step 4: objective=0.02309879
2017/08/26 04:06:54 step 5: objective=0.023126168
2017/08/26 04:06:59 step 6: objective=0.023153488
2017/08/26 04:07:04 step 7: objective=0.023179187
2017/08/26 04:07:04 Training value function...
2017/08/26 04:07:07 step 0: mse=0.669778 step=0.100000
2017/08/26 04:07:09 step 1: mse=0.617670 step=0.100000
2017/08/26 04:07:11 step 2: mse=0.575745 step=0.100000
2017/08/26 04:07:14 step 3: mse=0.542419 step=0.100000
2017/08/26 04:07:16 step 4: mse=0.510429 step=0.100000
2017/08/26 04:07:18 step 5: mse=0.486851 step=0.100000
2017/08/26 04:07:20 step 6: mse=0.469157 step=0.100000
2017/08/26 04:07:23 step 7: mse=0.452941 step=0.100000
2017/08/26 04:07:23 Saving...
2017/08/26 04:07:23 Gathering batch of experience...
2017/08/26 04:07:36 batch 94: mean=11.865385 stddev=5.687465 entropy=1.178131 frames=34794 count=52
2017/08/26 04:07:36 Training policy...
2017/08/26 04:07:42 step 0: objective=0.04090305
2017/08/26 04:07:47 step 1: objective=0.040954754
2017/08/26 04:07:52 step 2: objective=0.041006435
2017/08/26 04:07:57 step 3: objective=0.041058067
2017/08/26 04:08:01 step 4: objective=0.041109424
2017/08/26 04:08:06 step 5: objective=0.041160792
2017/08/26 04:08:11 step 6: objective=0.041203022
2017/08/26 04:08:16 step 7: objective=0.041247703
2017/08/26 04:08:16 Training value function...
2017/08/26 04:08:19 step 0: mse=1.041051 step=0.100000
2017/08/26 04:08:21 step 1: mse=0.966681 step=0.100000
2017/08/26 04:08:23 step 2: mse=0.906690 step=0.100000
2017/08/26 04:08:26 step 3: mse=0.856340 step=0.100000
2017/08/26 04:08:28 step 4: mse=0.816302 step=0.100000
2017/08/26 04:08:30 step 5: mse=0.764187 step=0.100000
2017/08/26 04:08:32 step 6: mse=0.735153 step=0.100000
2017/08/26 04:08:34 step 7: mse=0.697629 step=0.100000
2017/08/26 04:08:34 Saving...
2017/08/26 04:08:34 Gathering batch of experience...
2017/08/26 04:08:48 batch 95: mean=12.840000 stddev=4.640517 entropy=1.181024 frames=36040 count=50
2017/08/26 04:08:48 Training policy...
2017/08/26 04:08:55 step 0: objective=0.044139955
2017/08/26 04:09:00 step 1: objective=0.044174526
2017/08/26 04:09:05 step 2: objective=0.044208508
2017/08/26 04:09:10 step 3: objective=0.04424313
2017/08/26 04:09:15 step 4: objective=0.044277333
2017/08/26 04:09:20 step 5: objective=0.044312023
2017/08/26 04:09:25 step 6: objective=0.044351872
2017/08/26 04:09:30 step 7: objective=0.04438178
2017/08/26 04:09:30 Training value function...
2017/08/26 04:09:33 step 0: mse=0.821887 step=0.100000
2017/08/26 04:09:35 step 1: mse=0.760130 step=0.100000
2017/08/26 04:09:38 step 2: mse=0.709398 step=0.100000
2017/08/26 04:09:40 step 3: mse=0.661018 step=0.100000
2017/08/26 04:09:42 step 4: mse=0.623994 step=0.100000
2017/08/26 04:09:44 step 5: mse=0.581943 step=0.100000
2017/08/26 04:09:47 step 6: mse=0.547854 step=0.100000
2017/08/26 04:09:49 step 7: mse=0.528269 step=0.100000
2017/08/26 04:09:49 Saving...
2017/08/26 04:09:49 Gathering batch of experience...
2017/08/26 04:10:02 batch 96: mean=12.938776 stddev=5.783185 entropy=1.178152 frames=35083 count=49
2017/08/26 04:10:02 Training policy...
2017/08/26 04:10:09 step 0: objective=0.004347454
2017/08/26 04:10:14 step 1: objective=0.0044319313
2017/08/26 04:10:19 step 2: objective=0.0045176605
2017/08/26 04:10:24 step 3: objective=0.004604614
2017/08/26 04:10:29 step 4: objective=0.004674986
2017/08/26 04:10:34 step 5: objective=0.004712722
2017/08/26 04:10:39 step 6: objective=0.0047388584
2017/08/26 04:10:44 step 7: objective=0.0047783596
2017/08/26 04:10:44 Training value function...
2017/08/26 04:10:46 step 0: mse=1.003402 step=0.100000
2017/08/26 04:10:49 step 1: mse=0.917415 step=0.100000
2017/08/26 04:10:51 step 2: mse=0.848834 step=0.100000
2017/08/26 04:10:53 step 3: mse=0.793470 step=0.100000
2017/08/26 04:10:55 step 4: mse=0.751329 step=0.100000
2017/08/26 04:10:57 step 5: mse=0.726568 step=0.100000
2017/08/26 04:11:00 step 6: mse=0.694005 step=0.100000
2017/08/26 04:11:02 step 7: mse=0.677457 step=0.100000
2017/08/26 04:11:02 Saving...
2017/08/26 04:11:02 Gathering batch of experience...
2017/08/26 04:11:15 batch 97: mean=10.127273 stddev=3.448607 entropy=1.179714 frames=35201 count=55
2017/08/26 04:11:15 Training policy...
2017/08/26 04:11:22 step 0: objective=-0.018442234
2017/08/26 04:11:27 step 1: objective=-0.018369824
2017/08/26 04:11:32 step 2: objective=-0.018310258
2017/08/26 04:11:37 step 3: objective=-0.018250467
2017/08/26 04:11:42 step 4: objective=-0.01819103
2017/08/26 04:11:47 step 5: objective=-0.018141018
2017/08/26 04:11:52 step 6: objective=-0.018098747
2017/08/26 04:11:57 step 7: objective=-0.018062644
2017/08/26 04:11:57 Training value function...
2017/08/26 04:12:00 step 0: mse=0.416618 step=0.100000
2017/08/26 04:12:02 step 1: mse=0.387938 step=0.100000
2017/08/26 04:12:04 step 2: mse=0.364003 step=0.100000
2017/08/26 04:12:06 step 3: mse=0.345745 step=0.100000
2017/08/26 04:12:09 step 4: mse=0.329948 step=0.100000
2017/08/26 04:12:11 step 5: mse=0.313336 step=0.100000
2017/08/26 04:12:13 step 6: mse=0.303093 step=0.100000
2017/08/26 04:12:15 step 7: mse=0.294735 step=0.100000
2017/08/26 04:12:15 Saving...
2017/08/26 04:12:15 Gathering batch of experience...
2017/08/26 04:12:28 batch 98: mean=11.666667 stddev=4.820978 entropy=1.174677 frames=35426 count=51
2017/08/26 04:12:28 Training policy...
2017/08/26 04:12:35 step 0: objective=0.030872665
2017/08/26 04:12:40 step 1: objective=0.030897358
2017/08/26 04:12:45 step 2: objective=0.030921882
2017/08/26 04:12:50 step 3: objective=0.030946843
2017/08/26 04:12:55 step 4: objective=0.030971818
2017/08/26 04:13:00 step 5: objective=0.030997138
2017/08/26 04:13:06 step 6: objective=0.031016042
2017/08/26 04:13:11 step 7: objective=0.031032106
2017/08/26 04:13:11 Training value function...
2017/08/26 04:13:13 step 0: mse=0.504767 step=0.100000
2017/08/26 04:13:16 step 1: mse=0.481840 step=0.100000
2017/08/26 04:13:18 step 2: mse=0.463065 step=0.100000
2017/08/26 04:13:20 step 3: mse=0.448003 step=0.100000
2017/08/26 04:13:22 step 4: mse=0.427819 step=0.100000
2017/08/26 04:13:24 step 5: mse=0.410931 step=0.100000
2017/08/26 04:13:27 step 6: mse=0.395876 step=0.100000
2017/08/26 04:13:29 step 7: mse=0.388291 step=0.100000
2017/08/26 04:13:29 Saving...
2017/08/26 04:13:29 Gathering batch of experience...
2017/08/26 04:13:42 batch 99: mean=11.784314 stddev=5.069376 entropy=1.170540 frames=34209 count=51
2017/08/26 04:13:42 Training policy...
2017/08/26 04:13:48 step 0: objective=0.0445081
2017/08/26 04:13:53 step 1: objective=0.04457025
2017/08/26 04:13:58 step 2: objective=0.04464074
2017/08/26 04:14:03 step 3: objective=0.044711363
2017/08/26 04:14:08 step 4: objective=0.044776835
2017/08/26 04:14:13 step 5: objective=0.044839382
2017/08/26 04:14:18 step 6: objective=0.044900708
2017/08/26 04:14:23 step 7: objective=0.044957433
2017/08/26 04:14:23 Training value function...
2017/08/26 04:14:26 step 0: mse=0.719486 step=0.100000
2017/08/26 04:14:28 step 1: mse=0.663253 step=0.100000
2017/08/26 04:14:30 step 2: mse=0.616903 step=0.100000
2017/08/26 04:14:32 step 3: mse=0.582543 step=0.100000
2017/08/26 04:14:34 step 4: mse=0.547809 step=0.100000
2017/08/26 04:14:36 step 5: mse=0.522876 step=0.100000
2017/08/26 04:14:39 step 6: mse=0.500111 step=0.100000
2017/08/26 04:14:41 step 7: mse=0.480859 step=0.100000
2017/08/26 04:14:41 Saving...
2017/08/26 04:14:41 Gathering batch of experience...
2017/08/26 04:14:54 batch 100: mean=11.685185 stddev=4.980793 entropy=1.177619 frames=36142 count=54
2017/08/26 04:14:54 Training policy...
2017/08/26 04:15:01 step 0: objective=0.030535324
2017/08/26 04:15:06 step 1: objective=0.030580562
2017/08/26 04:15:11 step 2: objective=0.030625943
2017/08/26 04:15:17 step 3: objective=0.030671148
2017/08/26 04:15:22 step 4: objective=0.030716
2017/08/26 04:15:27 step 5: objective=0.030760543
2017/08/26 04:15:32 step 6: objective=0.030801158
2017/08/26 04:15:37 step 7: objective=0.030861028
2017/08/26 04:15:37 Training value function...
2017/08/26 04:15:40 step 0: mse=0.697772 step=0.100000
2017/08/26 04:15:42 step 1: mse=0.662131 step=0.100000
2017/08/26 04:15:45 step 2: mse=0.636420 step=0.100000
2017/08/26 04:15:47 step 3: mse=0.609050 step=0.100000
2017/08/26 04:15:49 step 4: mse=0.587904 step=0.100000
2017/08/26 04:15:52 step 5: mse=0.568379 step=0.100000
2017/08/26 04:15:54 step 6: mse=0.555784 step=0.100000
2017/08/26 04:15:56 step 7: mse=0.545036 step=0.100000
2017/08/26 04:15:56 Saving...
2017/08/26 04:15:56 Gathering batch of experience...
2017/08/26 04:16:10 batch 101: mean=11.735849 stddev=5.216631 entropy=1.167673 frames=35558 count=53
2017/08/26 04:16:10 Training policy...
2017/08/26 04:16:16 step 0: objective=0.040746227
2017/08/26 04:16:21 step 1: objective=0.040821217
2017/08/26 04:16:27 step 2: objective=0.040895835
2017/08/26 04:16:32 step 3: objective=0.040970713
2017/08/26 04:16:37 step 4: objective=0.04104491
2017/08/26 04:16:42 step 5: objective=0.04110836
2017/08/26 04:16:47 step 6: objective=0.041158188
2017/08/26 04:16:52 step 7: objective=0.041205753
2017/08/26 04:16:52 Training value function...
2017/08/26 04:16:55 step 0: mse=0.756930 step=0.100000
2017/08/26 04:16:57 step 1: mse=0.701378 step=0.100000
2017/08/26 04:16:59 step 2: mse=0.652808 step=0.100000
2017/08/26 04:17:02 step 3: mse=0.613266 step=0.100000
2017/08/26 04:17:04 step 4: mse=0.584882 step=0.100000
2017/08/26 04:17:06 step 5: mse=0.556108 step=0.100000
2017/08/26 04:17:08 step 6: mse=0.531635 step=0.100000
2017/08/26 04:17:11 step 7: mse=0.511967 step=0.100000
2017/08/26 04:17:11 Saving...
2017/08/26 04:17:11 Gathering batch of experience...
2017/08/26 04:17:24 batch 102: mean=11.830189 stddev=4.851515 entropy=1.175591 frames=36422 count=53
2017/08/26 04:17:24 Training policy...
2017/08/26 04:17:31 step 0: objective=0.022786083
2017/08/26 04:17:36 step 1: objective=0.022830017
2017/08/26 04:17:42 step 2: objective=0.022874381
2017/08/26 04:17:47 step 3: objective=0.022919202
2017/08/26 04:17:53 step 4: objective=0.022963868
2017/08/26 04:17:58 step 5: objective=0.023000358
2017/08/26 04:18:03 step 6: objective=0.023033485
2017/08/26 04:18:08 step 7: objective=0.02307913
2017/08/26 04:18:08 Training value function...
2017/08/26 04:18:11 step 0: mse=0.524618 step=0.100000
2017/08/26 04:18:14 step 1: mse=0.504111 step=0.100000
2017/08/26 04:18:16 step 2: mse=0.487738 step=0.100000
2017/08/26 04:18:19 step 3: mse=0.474253 step=0.100000
2017/08/26 04:18:21 step 4: mse=0.460992 step=0.100000
2017/08/26 04:18:23 step 5: mse=0.451285 step=0.100000
2017/08/26 04:18:26 step 6: mse=0.441638 step=0.100000
2017/08/26 04:18:28 step 7: mse=0.432013 step=0.100000
2017/08/26 04:18:28 Saving...
2017/08/26 04:18:28 Gathering batch of experience...
2017/08/26 04:18:41 batch 103: mean=11.884615 stddev=4.631223 entropy=1.173783 frames=35404 count=52
2017/08/26 04:18:41 Training policy...
2017/08/26 04:18:48 step 0: objective=0.028572785
2017/08/26 04:18:53 step 1: objective=0.028624099
2017/08/26 04:18:59 step 2: objective=0.02867507
2017/08/26 04:19:04 step 3: objective=0.028725844
2017/08/26 04:19:09 step 4: objective=0.028776139
2017/08/26 04:19:14 step 5: objective=0.028824521
2017/08/26 04:19:19 step 6: objective=0.028862149
2017/08/26 04:19:24 step 7: objective=0.028898556
2017/08/26 04:19:24 Training value function...
2017/08/26 04:19:27 step 0: mse=0.718897 step=0.100000
2017/08/26 04:19:29 step 1: mse=0.684018 step=0.100000
2017/08/26 04:19:32 step 2: mse=0.651514 step=0.100000
2017/08/26 04:19:34 step 3: mse=0.628848 step=0.100000
2017/08/26 04:19:36 step 4: mse=0.610541 step=0.100000
2017/08/26 04:19:39 step 5: mse=0.590947 step=0.100000
2017/08/26 04:19:41 step 6: mse=0.577803 step=0.100000
2017/08/26 04:19:43 step 7: mse=0.565121 step=0.100000
2017/08/26 04:19:43 Saving...
2017/08/26 04:19:43 Gathering batch of experience...
2017/08/26 04:19:56 batch 104: mean=11.725490 stddev=4.187181 entropy=1.175304 frames=35668 count=51
2017/08/26 04:19:56 Training policy...
2017/08/26 04:20:03 step 0: objective=0.017858988
2017/08/26 04:20:09 step 1: objective=0.017914522
2017/08/26 04:20:14 step 2: objective=0.017969953
2017/08/26 04:20:19 step 3: objective=0.018024804
2017/08/26 04:20:24 step 4: objective=0.018078806
2017/08/26 04:20:29 step 5: objective=0.018132525
2017/08/26 04:20:35 step 6: objective=0.018170223
2017/08/26 04:20:40 step 7: objective=0.018204886
2017/08/26 04:20:40 Training value function...
2017/08/26 04:20:43 step 0: mse=0.547538 step=0.100000
2017/08/26 04:20:45 step 1: mse=0.512767 step=0.100000
2017/08/26 04:20:47 step 2: mse=0.485929 step=0.100000
2017/08/26 04:20:49 step 3: mse=0.464833 step=0.100000
2017/08/26 04:20:51 step 4: mse=0.445865 step=0.100000
2017/08/26 04:20:54 step 5: mse=0.430974 step=0.100000
2017/08/26 04:20:56 step 6: mse=0.422890 step=0.100000
2017/08/26 04:20:58 step 7: mse=0.407857 step=0.100000
2017/08/26 04:20:58 Saving...
2017/08/26 04:20:58 Gathering batch of experience...
2017/08/26 04:21:12 batch 105: mean=12.352941 stddev=5.342481 entropy=1.170618 frames=35091 count=51
2017/08/26 04:21:12 Training policy...
2017/08/26 04:21:18 step 0: objective=0.045203563
2017/08/26 04:21:23 step 1: objective=0.045273542
2017/08/26 04:21:28 step 2: objective=0.04534397
2017/08/26 04:21:34 step 3: objective=0.045414597
2017/08/26 04:21:39 step 4: objective=0.045483056
2017/08/26 04:21:44 step 5: objective=0.045522254
2017/08/26 04:21:49 step 6: objective=0.045552824
2017/08/26 04:21:55 step 7: objective=0.045592155
2017/08/26 04:21:55 Training value function...
2017/08/26 04:21:57 step 0: mse=0.832773 step=0.100000
2017/08/26 04:21:59 step 1: mse=0.788374 step=0.100000
2017/08/26 04:22:02 step 2: mse=0.745209 step=0.100000
2017/08/26 04:22:04 step 3: mse=0.708973 step=0.100000
2017/08/26 04:22:06 step 4: mse=0.670473 step=0.100000
2017/08/26 04:22:09 step 5: mse=0.639643 step=0.100000
2017/08/26 04:22:11 step 6: mse=0.616468 step=0.100000
2017/08/26 04:22:13 step 7: mse=0.591480 step=0.100000
2017/08/26 04:22:13 Saving...
2017/08/26 04:22:13 Gathering batch of experience...
2017/08/26 04:22:27 batch 106: mean=12.780000 stddev=6.123038 entropy=1.169555 frames=35584 count=50
2017/08/26 04:22:27 Training policy...
2017/08/26 04:22:34 step 0: objective=0.026798887
2017/08/26 04:22:39 step 1: objective=0.02685175
2017/08/26 04:22:44 step 2: objective=0.026904097
2017/08/26 04:22:49 step 3: objective=0.026956223
2017/08/26 04:22:54 step 4: objective=0.027007421
2017/08/26 04:22:59 step 5: objective=0.027097508
2017/08/26 04:23:05 step 6: objective=0.027179662
2017/08/26 04:23:10 step 7: objective=0.027242202
2017/08/26 04:23:10 Training value function...
2017/08/26 04:23:13 step 0: mse=0.970862 step=0.100000
2017/08/26 04:23:15 step 1: mse=0.882861 step=0.100000
2017/08/26 04:23:17 step 2: mse=0.811554 step=0.100000
2017/08/26 04:23:20 step 3: mse=0.745250 step=0.100000
2017/08/26 04:23:22 step 4: mse=0.690126 step=0.100000
2017/08/26 04:23:24 step 5: mse=0.650614 step=0.100000
2017/08/26 04:23:26 step 6: mse=0.612180 step=0.100000
2017/08/26 04:23:29 step 7: mse=0.582121 step=0.100000
2017/08/26 04:23:29 Saving...
2017/08/26 04:23:29 Gathering batch of experience...
2017/08/26 04:23:42 batch 107: mean=11.792453 stddev=4.435528 entropy=1.170685 frames=35163 count=53
2017/08/26 04:23:42 Training policy...
2017/08/26 04:23:49 step 0: objective=0.026594628
2017/08/26 04:23:54 step 1: objective=0.026647266
2017/08/26 04:23:59 step 2: objective=0.026699472
2017/08/26 04:24:04 step 3: objective=0.026751352
2017/08/26 04:24:09 step 4: objective=0.026803263
2017/08/26 04:24:14 step 5: objective=0.026854701
2017/08/26 04:24:20 step 6: objective=0.026903845
2017/08/26 04:24:25 step 7: objective=0.026943259
2017/08/26 04:24:25 Training value function...
2017/08/26 04:24:28 step 0: mse=0.790606 step=0.100000
2017/08/26 04:24:30 step 1: mse=0.753610 step=0.100000
2017/08/26 04:24:32 step 2: mse=0.723664 step=0.100000
2017/08/26 04:24:34 step 3: mse=0.698573 step=0.100000
2017/08/26 04:24:37 step 4: mse=0.676223 step=0.100000
2017/08/26 04:24:39 step 5: mse=0.656875 step=0.100000
2017/08/26 04:24:41 step 6: mse=0.640914 step=0.100000
2017/08/26 04:24:43 step 7: mse=0.615756 step=0.100000
2017/08/26 04:24:43 Saving...
2017/08/26 04:24:44 Gathering batch of experience...
2017/08/26 04:24:57 batch 108: mean=11.900000 stddev=4.830114 entropy=1.173929 frames=35281 count=50
2017/08/26 04:24:57 Training policy...
2017/08/26 04:25:04 step 0: objective=0.012175199
2017/08/26 04:25:09 step 1: objective=0.012249195
2017/08/26 04:25:14 step 2: objective=0.012323394
2017/08/26 04:25:20 step 3: objective=0.0123978
2017/08/26 04:25:25 step 4: objective=0.012466096
2017/08/26 04:25:30 step 5: objective=0.012515928
2017/08/26 04:25:35 step 6: objective=0.012542638
2017/08/26 04:25:40 step 7: objective=0.012584663
2017/08/26 04:25:40 Training value function...
2017/08/26 04:25:43 step 0: mse=0.598067 step=0.100000
2017/08/26 04:25:45 step 1: mse=0.558892 step=0.100000
2017/08/26 04:25:47 step 2: mse=0.527700 step=0.100000
2017/08/26 04:25:50 step 3: mse=0.500968 step=0.100000
2017/08/26 04:25:52 step 4: mse=0.476525 step=0.100000
2017/08/26 04:25:54 step 5: mse=0.452768 step=0.100000
2017/08/26 04:25:56 step 6: mse=0.435053 step=0.100000
2017/08/26 04:25:58 step 7: mse=0.419686 step=0.100000
2017/08/26 04:25:58 Saving...
2017/08/26 04:25:58 Gathering batch of experience...
2017/08/26 04:26:12 batch 109: mean=11.403846 stddev=4.329059 entropy=1.173762 frames=35419 count=52
2017/08/26 04:26:12 Training policy...
2017/08/26 04:26:19 step 0: objective=0.028224707
2017/08/26 04:26:24 step 1: objective=0.028257556
2017/08/26 04:26:29 step 2: objective=0.028290367
2017/08/26 04:26:34 step 3: objective=0.028323391
2017/08/26 04:26:40 step 4: objective=0.028356116
2017/08/26 04:26:45 step 5: objective=0.028388934
2017/08/26 04:26:50 step 6: objective=0.02842168
2017/08/26 04:26:56 step 7: objective=0.028454399
2017/08/26 04:26:56 Training value function...
2017/08/26 04:26:58 step 0: mse=0.565067 step=0.100000
2017/08/26 04:27:01 step 1: mse=0.532493 step=0.100000
2017/08/26 04:27:03 step 2: mse=0.509687 step=0.100000
2017/08/26 04:27:05 step 3: mse=0.485109 step=0.100000
2017/08/26 04:27:07 step 4: mse=0.468913 step=0.100000
2017/08/26 04:27:10 step 5: mse=0.455559 step=0.100000
2017/08/26 04:27:12 step 6: mse=0.439318 step=0.100000
2017/08/26 04:27:14 step 7: mse=0.429010 step=0.100000
2017/08/26 04:27:14 Saving...
2017/08/26 04:27:14 Gathering batch of experience...
2017/08/26 04:27:28 batch 110: mean=11.823529 stddev=4.570605 entropy=1.165024 frames=35719 count=51
2017/08/26 04:27:28 Training policy...
2017/08/26 04:27:35 step 0: objective=0.02916148
2017/08/26 04:27:40 step 1: objective=0.02921186
2017/08/26 04:27:45 step 2: objective=0.029262727
2017/08/26 04:27:51 step 3: objective=0.029314028
2017/08/26 04:27:56 step 4: objective=0.029376015
2017/08/26 04:28:01 step 5: objective=0.029432414
2017/08/26 04:28:06 step 6: objective=0.02947949
2017/08/26 04:28:12 step 7: objective=0.029497176
2017/08/26 04:28:12 Training value function...
2017/08/26 04:28:15 step 0: mse=0.504571 step=0.100000
2017/08/26 04:28:17 step 1: mse=0.478829 step=0.100000
2017/08/26 04:28:19 step 2: mse=0.457702 step=0.100000
2017/08/26 04:28:21 step 3: mse=0.440251 step=0.100000
2017/08/26 04:28:24 step 4: mse=0.426031 step=0.100000
2017/08/26 04:28:26 step 5: mse=0.411877 step=0.100000
2017/08/26 04:28:28 step 6: mse=0.401001 step=0.100000
2017/08/26 04:28:30 step 7: mse=0.389666 step=0.100000
2017/08/26 04:28:30 Saving...
2017/08/26 04:28:30 Gathering batch of experience...
2017/08/26 04:28:44 batch 111: mean=11.942308 stddev=4.997744 entropy=1.164719 frames=36515 count=52
2017/08/26 04:28:44 Training policy...
2017/08/26 04:28:51 step 0: objective=0.031838767
2017/08/26 04:28:57 step 1: objective=0.031882305
2017/08/26 04:29:02 step 2: objective=0.031925846
2017/08/26 04:29:08 step 3: objective=0.03196863
2017/08/26 04:29:13 step 4: objective=0.032011706
2017/08/26 04:29:18 step 5: objective=0.03205958
2017/08/26 04:29:24 step 6: objective=0.03210684
2017/08/26 04:29:29 step 7: objective=0.03214862
2017/08/26 04:29:29 Training value function...
2017/08/26 04:29:32 step 0: mse=0.587091 step=0.100000
2017/08/26 04:29:34 step 1: mse=0.560298 step=0.100000
2017/08/26 04:29:37 step 2: mse=0.538367 step=0.100000
2017/08/26 04:29:39 step 3: mse=0.515994 step=0.100000
2017/08/26 04:29:41 step 4: mse=0.497692 step=0.100000
2017/08/26 04:29:44 step 5: mse=0.482713 step=0.100000
2017/08/26 04:29:46 step 6: mse=0.463593 step=0.100000
2017/08/26 04:29:48 step 7: mse=0.452931 step=0.100000
2017/08/26 04:29:48 Saving...
2017/08/26 04:29:48 Gathering batch of experience...
2017/08/26 04:30:02 batch 112: mean=13.040816 stddev=5.714140 entropy=1.167817 frames=35412 count=49
2017/08/26 04:30:02 Training policy...
2017/08/26 04:30:09 step 0: objective=0.06027482
2017/08/26 04:30:14 step 1: objective=0.060344666
2017/08/26 04:30:19 step 2: objective=0.06041518
2017/08/26 04:30:24 step 3: objective=0.060485847
2017/08/26 04:30:30 step 4: objective=0.060550686
2017/08/26 04:30:35 step 5: objective=0.06061048
2017/08/26 04:30:40 step 6: objective=0.060648553
2017/08/26 04:30:46 step 7: objective=0.060702864
2017/08/26 04:30:46 Training value function...
2017/08/26 04:30:48 step 0: mse=0.991593 step=0.100000
2017/08/26 04:30:51 step 1: mse=0.922265 step=0.100000
2017/08/26 04:30:53 step 2: mse=0.867144 step=0.100000
2017/08/26 04:30:55 step 3: mse=0.817506 step=0.100000
2017/08/26 04:30:57 step 4: mse=0.776795 step=0.100000
2017/08/26 04:31:00 step 5: mse=0.741090 step=0.100000
2017/08/26 04:31:02 step 6: mse=0.707745 step=0.100000
2017/08/26 04:31:04 step 7: mse=0.682233 step=0.100000
2017/08/26 04:31:04 Saving...
2017/08/26 04:31:04 Gathering batch of experience...
2017/08/26 04:31:18 batch 113: mean=11.615385 stddev=5.313820 entropy=1.169371 frames=35222 count=52
2017/08/26 04:31:18 Training policy...
2017/08/26 04:31:25 step 0: objective=0.013807117
2017/08/26 04:31:30 step 1: objective=0.013851575
2017/08/26 04:31:35 step 2: objective=0.013888667
2017/08/26 04:31:41 step 3: objective=0.013925685
2017/08/26 04:31:46 step 4: objective=0.013962578
2017/08/26 04:31:51 step 5: objective=0.013999431
2017/08/26 04:31:57 step 6: objective=0.014031146
2017/08/26 04:32:02 step 7: objective=0.014089439
2017/08/26 04:32:02 Training value function...
2017/08/26 04:32:05 step 0: mse=0.575637 step=0.100000
2017/08/26 04:32:07 step 1: mse=0.547422 step=0.100000
2017/08/26 04:32:09 step 2: mse=0.522491 step=0.100000
2017/08/26 04:32:11 step 3: mse=0.496190 step=0.100000
2017/08/26 04:32:14 step 4: mse=0.479646 step=0.100000
2017/08/26 04:32:16 step 5: mse=0.459689 step=0.100000
2017/08/26 04:32:18 step 6: mse=0.450169 step=0.100000
2017/08/26 04:32:21 step 7: mse=0.440854 step=0.100000
2017/08/26 04:32:21 Saving...
2017/08/26 04:32:21 Gathering batch of experience...
2017/08/26 04:32:34 batch 114: mean=10.833333 stddev=4.412734 entropy=1.170988 frames=35030 count=54
2017/08/26 04:32:34 Training policy...
2017/08/26 04:32:41 step 0: objective=0.018431757
2017/08/26 04:32:46 step 1: objective=0.018465817
2017/08/26 04:32:51 step 2: objective=0.018500026
2017/08/26 04:32:57 step 3: objective=0.018534642
2017/08/26 04:33:02 step 4: objective=0.018569326
2017/08/26 04:33:07 step 5: objective=0.018603494
2017/08/26 04:33:13 step 6: objective=0.018626211
2017/08/26 04:33:18 step 7: objective=0.01864568
2017/08/26 04:33:18 Training value function...
2017/08/26 04:33:21 step 0: mse=0.500388 step=0.100000
2017/08/26 04:33:23 step 1: mse=0.474591 step=0.100000
2017/08/26 04:33:25 step 2: mse=0.453723 step=0.100000
2017/08/26 04:33:27 step 3: mse=0.435940 step=0.100000
2017/08/26 04:33:29 step 4: mse=0.420552 step=0.100000
2017/08/26 04:33:32 step 5: mse=0.406134 step=0.100000
2017/08/26 04:33:34 step 6: mse=0.394459 step=0.100000
2017/08/26 04:33:36 step 7: mse=0.384946 step=0.100000
2017/08/26 04:33:36 Saving...
2017/08/26 04:33:36 Gathering batch of experience...
2017/08/26 04:33:50 batch 115: mean=12.745098 stddev=6.103175 entropy=1.166814 frames=36786 count=51
2017/08/26 04:33:50 Training policy...
2017/08/26 04:33:57 step 0: objective=0.05045072
2017/08/26 04:34:03 step 1: objective=0.05049371
2017/08/26 04:34:08 step 2: objective=0.050536823
2017/08/26 04:34:14 step 3: objective=0.05058005
2017/08/26 04:34:20 step 4: objective=0.050623406
2017/08/26 04:34:25 step 5: objective=0.05066279
2017/08/26 04:34:31 step 6: objective=0.050697103
2017/08/26 04:34:36 step 7: objective=0.050726414
2017/08/26 04:34:36 Training value function...
2017/08/26 04:34:39 step 0: mse=0.772731 step=0.100000
2017/08/26 04:34:41 step 1: mse=0.711306 step=0.100000
2017/08/26 04:34:44 step 2: mse=0.661258 step=0.100000
2017/08/26 04:34:46 step 3: mse=0.620758 step=0.100000
2017/08/26 04:34:48 step 4: mse=0.587407 step=0.100000
2017/08/26 04:34:51 step 5: mse=0.552126 step=0.100000
2017/08/26 04:34:53 step 6: mse=0.526096 step=0.100000
2017/08/26 04:34:55 step 7: mse=0.503617 step=0.100000
2017/08/26 04:34:55 Saving...
2017/08/26 04:34:55 Gathering batch of experience...
2017/08/26 04:35:09 batch 116: mean=11.725490 stddev=5.265792 entropy=1.163823 frames=35709 count=51
2017/08/26 04:35:09 Training policy...
2017/08/26 04:35:16 step 0: objective=0.0222744
2017/08/26 04:35:22 step 1: objective=0.022313416
2017/08/26 04:35:27 step 2: objective=0.022352152
2017/08/26 04:35:32 step 3: objective=0.022390468
2017/08/26 04:35:38 step 4: objective=0.022428952
2017/08/26 04:35:43 step 5: objective=0.022467054
2017/08/26 04:35:49 step 6: objective=0.022504177
2017/08/26 04:35:54 step 7: objective=0.022563849
2017/08/26 04:35:54 Training value function...
2017/08/26 04:35:57 step 0: mse=0.575422 step=0.100000
2017/08/26 04:35:59 step 1: mse=0.536670 step=0.100000
2017/08/26 04:36:01 step 2: mse=0.504500 step=0.100000
2017/08/26 04:36:04 step 3: mse=0.478397 step=0.100000
2017/08/26 04:36:06 step 4: mse=0.456807 step=0.100000
2017/08/26 04:36:08 step 5: mse=0.438575 step=0.100000
2017/08/26 04:36:10 step 6: mse=0.423052 step=0.100000
2017/08/26 04:36:13 step 7: mse=0.405426 step=0.100000
2017/08/26 04:36:13 Saving...
2017/08/26 04:36:13 Gathering batch of experience...
2017/08/26 04:36:26 batch 117: mean=12.156863 stddev=4.811638 entropy=1.164494 frames=36038 count=51
2017/08/26 04:36:26 Training policy...
2017/08/26 04:36:34 step 0: objective=0.040682815
2017/08/26 04:36:39 step 1: objective=0.04070819
2017/08/26 04:36:44 step 2: objective=0.040734097
2017/08/26 04:36:50 step 3: objective=0.040759876
2017/08/26 04:36:56 step 4: objective=0.04078591
2017/08/26 04:37:01 step 5: objective=0.040812243
2017/08/26 04:37:07 step 6: objective=0.04083629
2017/08/26 04:37:13 step 7: objective=0.04085944
2017/08/26 04:37:13 Training value function...
2017/08/26 04:37:16 step 0: mse=0.720176 step=0.100000
2017/08/26 04:37:18 step 1: mse=0.676371 step=0.100000
2017/08/26 04:37:20 step 2: mse=0.640770 step=0.100000
2017/08/26 04:37:23 step 3: mse=0.611912 step=0.100000
2017/08/26 04:37:25 step 4: mse=0.590927 step=0.100000
2017/08/26 04:37:27 step 5: mse=0.573760 step=0.100000
2017/08/26 04:37:29 step 6: mse=0.559675 step=0.100000
2017/08/26 04:37:32 step 7: mse=0.542740 step=0.100000
2017/08/26 04:37:32 Saving...
2017/08/26 04:37:32 Gathering batch of experience...
2017/08/26 04:37:45 batch 118: mean=11.452830 stddev=4.788217 entropy=1.164206 frames=35681 count=53
2017/08/26 04:37:45 Training policy...
2017/08/26 04:37:52 step 0: objective=0.026351621
2017/08/26 04:37:58 step 1: objective=0.026381426
2017/08/26 04:38:04 step 2: objective=0.026411226
2017/08/26 04:38:09 step 3: objective=0.026441654
2017/08/26 04:38:15 step 4: objective=0.026472138
2017/08/26 04:38:20 step 5: objective=0.026498098
2017/08/26 04:38:26 step 6: objective=0.0265331
2017/08/26 04:38:31 step 7: objective=0.026557302
2017/08/26 04:38:31 Training value function...
2017/08/26 04:38:34 step 0: mse=0.587932 step=0.100000
2017/08/26 04:38:36 step 1: mse=0.545168 step=0.100000
2017/08/26 04:38:38 step 2: mse=0.512247 step=0.100000
2017/08/26 04:38:41 step 3: mse=0.483364 step=0.100000
2017/08/26 04:38:43 step 4: mse=0.460079 step=0.100000
2017/08/26 04:38:45 step 5: mse=0.440864 step=0.100000
2017/08/26 04:38:47 step 6: mse=0.423522 step=0.100000
2017/08/26 04:38:50 step 7: mse=0.405824 step=0.100000
2017/08/26 04:38:50 Saving...
2017/08/26 04:38:50 Gathering batch of experience...
2017/08/26 04:39:03 batch 119: mean=11.519231 stddev=4.805807 entropy=1.166873 frames=35226 count=52
2017/08/26 04:39:03 Training policy...
2017/08/26 04:39:10 step 0: objective=0.036582097
2017/08/26 04:39:15 step 1: objective=0.036639873
2017/08/26 04:39:21 step 2: objective=0.036697518
2017/08/26 04:39:26 step 3: objective=0.036755618
2017/08/26 04:39:31 step 4: objective=0.036813937
2017/08/26 04:39:37 step 5: objective=0.03687217
2017/08/26 04:39:42 step 6: objective=0.036930643
2017/08/26 04:39:47 step 7: objective=0.036984205
2017/08/26 04:39:47 Training value function...
2017/08/26 04:39:50 step 0: mse=0.739222 step=0.100000
2017/08/26 04:39:52 step 1: mse=0.707710 step=0.100000
2017/08/26 04:39:55 step 2: mse=0.679494 step=0.100000
2017/08/26 04:39:57 step 3: mse=0.657659 step=0.100000
2017/08/26 04:39:59 step 4: mse=0.628318 step=0.100000
2017/08/26 04:40:01 step 5: mse=0.611552 step=0.100000
2017/08/26 04:40:03 step 6: mse=0.589708 step=0.100000
2017/08/26 04:40:06 step 7: mse=0.554877 step=0.100000
2017/08/26 04:40:06 Saving...
2017/08/26 04:40:06 Gathering batch of experience...
2017/08/26 04:40:19 batch 120: mean=11.769231 stddev=4.664165 entropy=1.171235 frames=35411 count=52
2017/08/26 04:40:19 Training policy...
2017/08/26 04:40:26 step 0: objective=0.026963519
2017/08/26 04:40:31 step 1: objective=0.027019927
2017/08/26 04:40:37 step 2: objective=0.027076162
2017/08/26 04:40:42 step 3: objective=0.02713209
2017/08/26 04:40:48 step 4: objective=0.02718471
2017/08/26 04:40:54 step 5: objective=0.027216973
2017/08/26 04:40:59 step 6: objective=0.027249819
2017/08/26 04:41:05 step 7: objective=0.027287029
2017/08/26 04:41:05 Training value function...
2017/08/26 04:41:07 step 0: mse=0.670680 step=0.100000
2017/08/26 04:41:10 step 1: mse=0.633161 step=0.100000
2017/08/26 04:41:12 step 2: mse=0.602575 step=0.100000
2017/08/26 04:41:14 step 3: mse=0.577616 step=0.100000
2017/08/26 04:41:16 step 4: mse=0.558708 step=0.100000
2017/08/26 04:41:19 step 5: mse=0.541203 step=0.100000
2017/08/26 04:41:21 step 6: mse=0.527561 step=0.100000
2017/08/26 04:41:23 step 7: mse=0.503187 step=0.100000
2017/08/26 04:41:23 Saving...
2017/08/26 04:41:23 Gathering batch of experience...
2017/08/26 04:41:37 batch 121: mean=12.196078 stddev=5.980424 entropy=1.167001 frames=36494 count=51
2017/08/26 04:41:37 Training policy...
2017/08/26 04:41:44 step 0: objective=0.027224457
2017/08/26 04:41:50 step 1: objective=0.027273249
2017/08/26 04:41:55 step 2: objective=0.027322087
2017/08/26 04:42:01 step 3: objective=0.027370049
2017/08/26 04:42:07 step 4: objective=0.027400535
2017/08/26 04:42:12 step 5: objective=0.027435122
2017/08/26 04:42:18 step 6: objective=0.027458748
2017/08/26 04:42:24 step 7: objective=0.027493773
2017/08/26 04:42:24 Training value function...
2017/08/26 04:42:27 step 0: mse=0.754606 step=0.100000
2017/08/26 04:42:29 step 1: mse=0.683044 step=0.100000
2017/08/26 04:42:31 step 2: mse=0.626910 step=0.100000
2017/08/26 04:42:33 step 3: mse=0.579821 step=0.100000
2017/08/26 04:42:36 step 4: mse=0.541818 step=0.100000
2017/08/26 04:42:38 step 5: mse=0.508253 step=0.100000
2017/08/26 04:42:40 step 6: mse=0.481542 step=0.100000
2017/08/26 04:42:43 step 7: mse=0.457444 step=0.100000
2017/08/26 04:42:43 Saving...
2017/08/26 04:42:43 Gathering batch of experience...
2017/08/26 04:42:56 batch 122: mean=13.040816 stddev=5.569447 entropy=1.168897 frames=35451 count=49
2017/08/26 04:42:56 Training policy...
2017/08/26 04:43:03 step 0: objective=0.045686807
2017/08/26 04:43:09 step 1: objective=0.045734543
2017/08/26 04:43:14 step 2: objective=0.045781568
2017/08/26 04:43:20 step 3: objective=0.04583198
2017/08/26 04:43:25 step 4: objective=0.045881923
2017/08/26 04:43:31 step 5: objective=0.04592513
2017/08/26 04:43:36 step 6: objective=0.04597148
2017/08/26 04:43:42 step 7: objective=0.046017535
2017/08/26 04:43:42 Training value function...
2017/08/26 04:43:44 step 0: mse=0.717564 step=0.100000
2017/08/26 04:43:47 step 1: mse=0.678964 step=0.100000
2017/08/26 04:43:49 step 2: mse=0.646959 step=0.100000
2017/08/26 04:43:51 step 3: mse=0.617900 step=0.100000
2017/08/26 04:43:53 step 4: mse=0.594214 step=0.100000
2017/08/26 04:43:56 step 5: mse=0.573568 step=0.100000
2017/08/26 04:43:58 step 6: mse=0.556477 step=0.100000
2017/08/26 04:44:00 step 7: mse=0.542582 step=0.100000
2017/08/26 04:44:00 Saving...
2017/08/26 04:44:00 Gathering batch of experience...
2017/08/26 04:44:14 batch 123: mean=12.358491 stddev=5.733366 entropy=1.167111 frames=36545 count=53
2017/08/26 04:44:14 Training policy...
2017/08/26 04:44:21 step 0: objective=0.039910134
2017/08/26 04:44:27 step 1: objective=0.039943136
2017/08/26 04:44:33 step 2: objective=0.039976712
2017/08/26 04:44:39 step 3: objective=0.040009987
2017/08/26 04:44:44 step 4: objective=0.04004366
2017/08/26 04:44:50 step 5: objective=0.04007431
2017/08/26 04:44:56 step 6: objective=0.04012637
2017/08/26 04:45:01 step 7: objective=0.040174153
2017/08/26 04:45:01 Training value function...
2017/08/26 04:45:04 step 0: mse=0.829095 step=0.100000
2017/08/26 04:45:07 step 1: mse=0.768926 step=0.100000
2017/08/26 04:45:09 step 2: mse=0.720493 step=0.100000
2017/08/26 04:45:11 step 3: mse=0.680779 step=0.100000
2017/08/26 04:45:14 step 4: mse=0.646544 step=0.100000
2017/08/26 04:45:16 step 5: mse=0.616448 step=0.100000
2017/08/26 04:45:18 step 6: mse=0.585010 step=0.100000
2017/08/26 04:45:21 step 7: mse=0.561964 step=0.100000
2017/08/26 04:45:21 Saving...
2017/08/26 04:45:21 Gathering batch of experience...
2017/08/26 04:45:34 batch 124: mean=12.820000 stddev=4.650548 entropy=1.165271 frames=35858 count=50
2017/08/26 04:45:34 Training policy...
2017/08/26 04:45:41 step 0: objective=0.027022747
2017/08/26 04:45:47 step 1: objective=0.027067007
2017/08/26 04:45:52 step 2: objective=0.027111143
2017/08/26 04:45:58 step 3: objective=0.027155535
2017/08/26 04:46:03 step 4: objective=0.027200036
2017/08/26 04:46:09 step 5: objective=0.027244586
2017/08/26 04:46:14 step 6: objective=0.027281007
2017/08/26 04:46:20 step 7: objective=0.0273237
2017/08/26 04:46:20 Training value function...
2017/08/26 04:46:23 step 0: mse=0.622671 step=0.100000
2017/08/26 04:46:25 step 1: mse=0.598084 step=0.100000
2017/08/26 04:46:28 step 2: mse=0.572483 step=0.100000
2017/08/26 04:46:30 step 3: mse=0.552444 step=0.100000
2017/08/26 04:46:32 step 4: mse=0.533359 step=0.100000
2017/08/26 04:46:34 step 5: mse=0.517159 step=0.100000
2017/08/26 04:46:37 step 6: mse=0.501061 step=0.100000
2017/08/26 04:46:39 step 7: mse=0.490752 step=0.100000
2017/08/26 04:46:39 Saving...
2017/08/26 04:46:39 Gathering batch of experience...
2017/08/26 04:46:53 batch 125: mean=13.041667 stddev=4.329927 entropy=1.163486 frames=35705 count=48
2017/08/26 04:46:53 Training policy...
2017/08/26 04:47:00 step 0: objective=0.019088296
2017/08/26 04:47:05 step 1: objective=0.019123545
2017/08/26 04:47:11 step 2: objective=0.019158978
2017/08/26 04:47:16 step 3: objective=0.019194173
2017/08/26 04:47:22 step 4: objective=0.01922911
2017/08/26 04:47:27 step 5: objective=0.019264288
2017/08/26 04:47:33 step 6: objective=0.019298425
2017/08/26 04:47:38 step 7: objective=0.019342627
2017/08/26 04:47:38 Training value function...
2017/08/26 04:47:41 step 0: mse=0.617814 step=0.100000
2017/08/26 04:47:44 step 1: mse=0.595341 step=0.100000
2017/08/26 04:47:46 step 2: mse=0.579313 step=0.100000
2017/08/26 04:47:48 step 3: mse=0.563773 step=0.100000
2017/08/26 04:47:50 step 4: mse=0.550286 step=0.100000
2017/08/26 04:47:53 step 5: mse=0.533074 step=0.100000
2017/08/26 04:47:55 step 6: mse=0.520433 step=0.100000
2017/08/26 04:47:57 step 7: mse=0.508949 step=0.100000
2017/08/26 04:47:57 Saving...
2017/08/26 04:47:57 Gathering batch of experience...
2017/08/26 04:48:11 batch 126: mean=11.480769 stddev=5.160838 entropy=1.161645 frames=35039 count=52
2017/08/26 04:48:11 Training policy...
2017/08/26 04:48:18 step 0: objective=0.015029801
2017/08/26 04:48:23 step 1: objective=0.015065681
2017/08/26 04:48:29 step 2: objective=0.015101483
2017/08/26 04:48:34 step 3: objective=0.015137433
2017/08/26 04:48:39 step 4: objective=0.015173426
2017/08/26 04:48:45 step 5: objective=0.015206962
2017/08/26 04:48:50 step 6: objective=0.015271068
2017/08/26 04:48:56 step 7: objective=0.015334038
2017/08/26 04:48:56 Training value function...
2017/08/26 04:48:58 step 0: mse=0.621065 step=0.100000
2017/08/26 04:49:01 step 1: mse=0.600982 step=0.100000
2017/08/26 04:49:03 step 2: mse=0.584896 step=0.100000
2017/08/26 04:49:05 step 3: mse=0.572340 step=0.100000
2017/08/26 04:49:07 step 4: mse=0.551913 step=0.100000
2017/08/26 04:49:10 step 5: mse=0.537482 step=0.100000
2017/08/26 04:49:12 step 6: mse=0.521446 step=0.100000
2017/08/26 04:49:14 step 7: mse=0.513655 step=0.100000
2017/08/26 04:49:14 Saving...
2017/08/26 04:49:14 Gathering batch of experience...
2017/08/26 04:49:27 batch 127: mean=11.880000 stddev=3.912237 entropy=1.166051 frames=34769 count=50
2017/08/26 04:49:27 Training policy...
2017/08/26 04:49:34 step 0: objective=0.025061406
2017/08/26 04:49:40 step 1: objective=0.025080124
2017/08/26 04:49:45 step 2: objective=0.025099233
2017/08/26 04:49:51 step 3: objective=0.025118334
2017/08/26 04:49:56 step 4: objective=0.02513747
2017/08/26 04:50:02 step 5: objective=0.025156759
2017/08/26 04:50:07 step 6: objective=0.0251763
2017/08/26 04:50:13 step 7: objective=0.025195818
2017/08/26 04:50:13 Training value function...
2017/08/26 04:50:15 step 0: mse=0.536636 step=0.100000
2017/08/26 04:50:17 step 1: mse=0.510698 step=0.100000
2017/08/26 04:50:20 step 2: mse=0.490389 step=0.100000
2017/08/26 04:50:22 step 3: mse=0.472560 step=0.100000
2017/08/26 04:50:24 step 4: mse=0.458145 step=0.100000
2017/08/26 04:50:27 step 5: mse=0.446571 step=0.100000
2017/08/26 04:50:29 step 6: mse=0.437012 step=0.100000
2017/08/26 04:50:31 step 7: mse=0.427448 step=0.100000
2017/08/26 04:50:31 Saving...
2017/08/26 04:50:31 Gathering batch of experience...
2017/08/26 04:50:44 batch 128: mean=12.829787 stddev=4.994973 entropy=1.160270 frames=35268 count=47
2017/08/26 04:50:44 Training policy...
2017/08/26 04:50:52 step 0: objective=0.013717393
2017/08/26 04:50:57 step 1: objective=0.013758624
2017/08/26 04:51:03 step 2: objective=0.013799986
2017/08/26 04:51:09 step 3: objective=0.013841436
2017/08/26 04:51:14 step 4: objective=0.013882863
2017/08/26 04:51:20 step 5: objective=0.013919814
2017/08/26 04:51:25 step 6: objective=0.013992108
2017/08/26 04:51:31 step 7: objective=0.014047577
2017/08/26 04:51:31 Training value function...
2017/08/26 04:51:33 step 0: mse=0.616229 step=0.100000
2017/08/26 04:51:36 step 1: mse=0.581898 step=0.100000
2017/08/26 04:51:38 step 2: mse=0.554595 step=0.100000
2017/08/26 04:51:40 step 3: mse=0.529701 step=0.100000
2017/08/26 04:51:42 step 4: mse=0.509138 step=0.100000
2017/08/26 04:51:45 step 5: mse=0.492602 step=0.100000
2017/08/26 04:51:47 step 6: mse=0.475930 step=0.100000
2017/08/26 04:51:49 step 7: mse=0.460460 step=0.100000
2017/08/26 04:51:49 Saving...
2017/08/26 04:51:49 Gathering batch of experience...
2017/08/26 04:52:03 batch 129: mean=10.981132 stddev=4.453070 entropy=1.168762 frames=35791 count=53
2017/08/26 04:52:03 Training policy...
2017/08/26 04:52:11 step 0: objective=0.016012905
2017/08/26 04:52:17 step 1: objective=0.016034856
2017/08/26 04:52:22 step 2: objective=0.01605672
2017/08/26 04:52:28 step 3: objective=0.016078433
2017/08/26 04:52:34 step 4: objective=0.016100163
2017/08/26 04:52:39 step 5: objective=0.01612175
2017/08/26 04:52:45 step 6: objective=0.016143404
2017/08/26 04:52:50 step 7: objective=0.01616482
2017/08/26 04:52:50 Training value function...
2017/08/26 04:52:53 step 0: mse=0.397946 step=0.100000
2017/08/26 04:52:55 step 1: mse=0.381853 step=0.100000
2017/08/26 04:52:58 step 2: mse=0.364394 step=0.100000
2017/08/26 04:53:00 step 3: mse=0.352796 step=0.100000
2017/08/26 04:53:02 step 4: mse=0.341162 step=0.100000
2017/08/26 04:53:04 step 5: mse=0.333292 step=0.100000
2017/08/26 04:53:07 step 6: mse=0.323453 step=0.100000
2017/08/26 04:53:09 step 7: mse=0.317246 step=0.100000
2017/08/26 04:53:09 Saving...
2017/08/26 04:53:09 Gathering batch of experience...
2017/08/26 04:53:22 batch 130: mean=12.200000 stddev=5.433231 entropy=1.162837 frames=34974 count=50
2017/08/26 04:53:22 Training policy...
2017/08/26 04:53:30 step 0: objective=0.03700646
2017/08/26 04:53:35 step 1: objective=0.037047576
2017/08/26 04:53:41 step 2: objective=0.03708902
2017/08/26 04:53:46 step 3: objective=0.03713033
2017/08/26 04:53:52 step 4: objective=0.037172154
2017/08/26 04:53:58 step 5: objective=0.03720792
2017/08/26 04:54:03 step 6: objective=0.037227165
2017/08/26 04:54:09 step 7: objective=0.037244454
2017/08/26 04:54:09 Training value function...
2017/08/26 04:54:12 step 0: mse=0.697832 step=0.100000
2017/08/26 04:54:14 step 1: mse=0.648740 step=0.100000
2017/08/26 04:54:16 step 2: mse=0.608945 step=0.100000
2017/08/26 04:54:18 step 3: mse=0.575378 step=0.100000
2017/08/26 04:54:20 step 4: mse=0.548769 step=0.100000
2017/08/26 04:54:23 step 5: mse=0.525968 step=0.100000
2017/08/26 04:54:25 step 6: mse=0.508342 step=0.100000
2017/08/26 04:54:27 step 7: mse=0.493279 step=0.100000
2017/08/26 04:54:27 Saving...
2017/08/26 04:54:27 Gathering batch of experience...
2017/08/26 04:54:41 batch 131: mean=12.979592 stddev=5.426653 entropy=1.161488 frames=35189 count=49
2017/08/26 04:54:41 Training policy...
2017/08/26 04:54:48 step 0: objective=0.042739313
2017/08/26 04:54:54 step 1: objective=0.042814083
2017/08/26 04:55:00 step 2: objective=0.0428881
2017/08/26 04:55:06 step 3: objective=0.04296146
2017/08/26 04:55:11 step 4: objective=0.04302782
2017/08/26 04:55:17 step 5: objective=0.04306391
2017/08/26 04:55:23 step 6: objective=0.04312468
2017/08/26 04:55:28 step 7: objective=0.04318481
2017/08/26 04:55:28 Training value function...
2017/08/26 04:55:31 step 0: mse=0.840025 step=0.100000
2017/08/26 04:55:33 step 1: mse=0.780754 step=0.100000
2017/08/26 04:55:35 step 2: mse=0.734670 step=0.100000
2017/08/26 04:55:38 step 3: mse=0.691710 step=0.100000
2017/08/26 04:55:40 step 4: mse=0.659482 step=0.100000
2017/08/26 04:55:42 step 5: mse=0.628425 step=0.100000
2017/08/26 04:55:44 step 6: mse=0.605647 step=0.100000
2017/08/26 04:55:47 step 7: mse=0.579613 step=0.100000
2017/08/26 04:55:47 Saving...
2017/08/26 04:55:47 Gathering batch of experience...
2017/08/26 04:56:01 batch 132: mean=12.352941 stddev=4.566818 entropy=1.166223 frames=36172 count=51
2017/08/26 04:56:01 Training policy...
2017/08/26 04:56:08 step 0: objective=0.023161627
2017/08/26 04:56:14 step 1: objective=0.02320452
2017/08/26 04:56:19 step 2: objective=0.023247588
2017/08/26 04:56:25 step 3: objective=0.023290548
2017/08/26 04:56:31 step 4: objective=0.02333331
2017/08/26 04:56:37 step 5: objective=0.023372672
2017/08/26 04:56:42 step 6: objective=0.023411507
2017/08/26 04:56:48 step 7: objective=0.023436202
2017/08/26 04:56:48 Training value function...
2017/08/26 04:56:51 step 0: mse=0.521987 step=0.100000
2017/08/26 04:56:53 step 1: mse=0.494824 step=0.100000
2017/08/26 04:56:55 step 2: mse=0.472275 step=0.100000
2017/08/26 04:56:58 step 3: mse=0.454903 step=0.100000
2017/08/26 04:57:00 step 4: mse=0.442827 step=0.100000
2017/08/26 04:57:02 step 5: mse=0.430905 step=0.100000
2017/08/26 04:57:05 step 6: mse=0.415924 step=0.100000
2017/08/26 04:57:07 step 7: mse=0.410733 step=0.100000
2017/08/26 04:57:07 Saving...
2017/08/26 04:57:07 Gathering batch of experience...
2017/08/26 04:57:20 batch 133: mean=11.823529 stddev=4.310070 entropy=1.165397 frames=35198 count=51
2017/08/26 04:57:20 Training policy...
2017/08/26 04:57:28 step 0: objective=0.017403236
2017/08/26 04:57:33 step 1: objective=0.017425468
2017/08/26 04:57:39 step 2: objective=0.01744752
2017/08/26 04:57:45 step 3: objective=0.017469568
2017/08/26 04:57:50 step 4: objective=0.017491357
2017/08/26 04:57:56 step 5: objective=0.017513106
2017/08/26 04:58:02 step 6: objective=0.01753474
2017/08/26 04:58:07 step 7: objective=0.01755562
2017/08/26 04:58:07 Training value function...
2017/08/26 04:58:10 step 0: mse=0.600039 step=0.100000
2017/08/26 04:58:12 step 1: mse=0.559396 step=0.100000
2017/08/26 04:58:15 step 2: mse=0.528027 step=0.100000
2017/08/26 04:58:17 step 3: mse=0.500938 step=0.100000
2017/08/26 04:58:19 step 4: mse=0.478509 step=0.100000
2017/08/26 04:58:21 step 5: mse=0.460132 step=0.100000
2017/08/26 04:58:24 step 6: mse=0.445970 step=0.100000
2017/08/26 04:58:26 step 7: mse=0.432935 step=0.100000
2017/08/26 04:58:26 Saving...
2017/08/26 04:58:26 Gathering batch of experience...
2017/08/26 04:58:39 batch 134: mean=11.415094 stddev=5.026098 entropy=1.162954 frames=34707 count=53
2017/08/26 04:58:39 Training policy...
2017/08/26 04:58:46 step 0: objective=0.02969011
2017/08/26 04:58:52 step 1: objective=0.02972533
2017/08/26 04:58:57 step 2: objective=0.029760338
2017/08/26 04:59:03 step 3: objective=0.029792286
2017/08/26 04:59:09 step 4: objective=0.029824218
2017/08/26 04:59:14 step 5: objective=0.029856246
2017/08/26 04:59:20 step 6: objective=0.029887889
2017/08/26 04:59:25 step 7: objective=0.029914416
2017/08/26 04:59:25 Training value function...
2017/08/26 04:59:28 step 0: mse=0.646781 step=0.100000
2017/08/26 04:59:30 step 1: mse=0.615107 step=0.100000
2017/08/26 04:59:32 step 2: mse=0.589584 step=0.100000
2017/08/26 04:59:35 step 3: mse=0.568243 step=0.100000
2017/08/26 04:59:37 step 4: mse=0.545288 step=0.100000
2017/08/26 04:59:39 step 5: mse=0.530428 step=0.100000
2017/08/26 04:59:41 step 6: mse=0.513578 step=0.100000
2017/08/26 04:59:43 step 7: mse=0.501728 step=0.100000
2017/08/26 04:59:43 Saving...
2017/08/26 04:59:43 Gathering batch of experience...
2017/08/26 04:59:57 batch 135: mean=10.654545 stddev=4.243576 entropy=1.167701 frames=35705 count=55
2017/08/26 04:59:57 Training policy...
2017/08/26 05:00:04 step 0: objective=0.017569361
2017/08/26 05:00:10 step 1: objective=0.017609125
2017/08/26 05:00:16 step 2: objective=0.01764884
2017/08/26 05:00:22 step 3: objective=0.017688742
2017/08/26 05:00:27 step 4: objective=0.017717952
2017/08/26 05:00:33 step 5: objective=0.017740482
2017/08/26 05:00:39 step 6: objective=0.01776194
2017/08/26 05:00:45 step 7: objective=0.017785475
2017/08/26 05:00:45 Training value function...
2017/08/26 05:00:47 step 0: mse=0.468779 step=0.100000
2017/08/26 05:00:50 step 1: mse=0.445566 step=0.100000
2017/08/26 05:00:52 step 2: mse=0.427049 step=0.100000
2017/08/26 05:00:54 step 3: mse=0.412342 step=0.100000
2017/08/26 05:00:57 step 4: mse=0.398429 step=0.100000
2017/08/26 05:00:59 step 5: mse=0.388225 step=0.100000
2017/08/26 05:01:01 step 6: mse=0.378252 step=0.100000
2017/08/26 05:01:04 step 7: mse=0.370069 step=0.100000
2017/08/26 05:01:04 Saving...
2017/08/26 05:01:04 Gathering batch of experience...
2017/08/26 05:01:17 batch 136: mean=13.000000 stddev=5.692817 entropy=1.156250 frames=36416 count=49
2017/08/26 05:01:17 Training policy...
2017/08/26 05:01:25 step 0: objective=0.048602343
2017/08/26 05:01:31 step 1: objective=0.048665874
2017/08/26 05:01:37 step 2: objective=0.04872937
2017/08/26 05:01:43 step 3: objective=0.048792236
2017/08/26 05:01:48 step 4: objective=0.048854247
2017/08/26 05:01:54 step 5: objective=0.048908282
2017/08/26 05:02:00 step 6: objective=0.04896058
2017/08/26 05:02:06 step 7: objective=0.049022175
2017/08/26 05:02:06 Training value function...
2017/08/26 05:02:09 step 0: mse=0.759849 step=0.100000
2017/08/26 05:02:11 step 1: mse=0.723185 step=0.100000
2017/08/26 05:02:13 step 2: mse=0.685260 step=0.100000
2017/08/26 05:02:16 step 3: mse=0.641954 step=0.100000
2017/08/26 05:02:18 step 4: mse=0.619730 step=0.100000
2017/08/26 05:02:20 step 5: mse=0.584505 step=0.100000
2017/08/26 05:02:23 step 6: mse=0.562247 step=0.100000
2017/08/26 05:02:25 step 7: mse=0.541247 step=0.100000
2017/08/26 05:02:25 Saving...
2017/08/26 05:02:25 Gathering batch of experience...
2017/08/26 05:02:39 batch 137: mean=11.169811 stddev=4.717434 entropy=1.164173 frames=35235 count=53
2017/08/26 05:02:39 Training policy...
2017/08/26 05:02:46 step 0: objective=0.014893659
2017/08/26 05:02:52 step 1: objective=0.014933299
2017/08/26 05:02:57 step 2: objective=0.014972905
2017/08/26 05:03:03 step 3: objective=0.015012326
2017/08/26 05:03:09 step 4: objective=0.015051633
2017/08/26 05:03:15 step 5: objective=0.015090861
2017/08/26 05:03:20 step 6: objective=0.015126819
2017/08/26 05:03:26 step 7: objective=0.0151642645
2017/08/26 05:03:26 Training value function...
2017/08/26 05:03:29 step 0: mse=0.661800 step=0.100000
2017/08/26 05:03:31 step 1: mse=0.607529 step=0.100000
2017/08/26 05:03:33 step 2: mse=0.564017 step=0.100000
2017/08/26 05:03:35 step 3: mse=0.528835 step=0.100000
2017/08/26 05:03:38 step 4: mse=0.498720 step=0.100000
2017/08/26 05:03:40 step 5: mse=0.479551 step=0.100000
2017/08/26 05:03:42 step 6: mse=0.466160 step=0.100000
2017/08/26 05:03:44 step 7: mse=0.456768 step=0.100000
2017/08/26 05:03:44 Saving...
2017/08/26 05:03:44 Gathering batch of experience...
2017/08/26 05:03:58 batch 138: mean=13.520833 stddev=5.597580 entropy=1.157629 frames=36262 count=48
2017/08/26 05:03:58 Training policy...
2017/08/26 05:04:06 step 0: objective=0.05819348
2017/08/26 05:04:11 step 1: objective=0.058212854
2017/08/26 05:04:17 step 2: objective=0.058232058
2017/08/26 05:04:23 step 3: objective=0.058250755
2017/08/26 05:04:29 step 4: objective=0.058269646
2017/08/26 05:04:35 step 5: objective=0.058288354
2017/08/26 05:04:41 step 6: objective=0.058306716
2017/08/26 05:04:47 step 7: objective=0.058324855
2017/08/26 05:04:47 Training value function...
2017/08/26 05:04:50 step 0: mse=0.803108 step=0.100000
2017/08/26 05:04:52 step 1: mse=0.735910 step=0.100000
2017/08/26 05:04:54 step 2: mse=0.680555 step=0.100000
2017/08/26 05:04:56 step 3: mse=0.635730 step=0.100000
2017/08/26 05:04:59 step 4: mse=0.598013 step=0.100000
2017/08/26 05:05:01 step 5: mse=0.568248 step=0.100000
2017/08/26 05:05:03 step 6: mse=0.543542 step=0.100000
2017/08/26 05:05:06 step 7: mse=0.523212 step=0.100000
2017/08/26 05:05:06 Saving...
2017/08/26 05:05:06 Gathering batch of experience...
2017/08/26 05:05:19 batch 139: mean=13.163265 stddev=5.856610 entropy=1.156067 frames=35517 count=49
2017/08/26 05:05:19 Training policy...
2017/08/26 05:05:27 step 0: objective=0.035121523
2017/08/26 05:05:32 step 1: objective=0.035157964
2017/08/26 05:05:38 step 2: objective=0.035194527
2017/08/26 05:05:44 step 3: objective=0.035231054
2017/08/26 05:05:50 step 4: objective=0.03526712
2017/08/26 05:05:56 step 5: objective=0.03530333
2017/08/26 05:06:02 step 6: objective=0.03533936
2017/08/26 05:06:07 step 7: objective=0.035370383
2017/08/26 05:06:07 Training value function...
2017/08/26 05:06:10 step 0: mse=0.800564 step=0.100000
2017/08/26 05:06:13 step 1: mse=0.752967 step=0.100000
2017/08/26 05:06:15 step 2: mse=0.714602 step=0.100000
2017/08/26 05:06:17 step 3: mse=0.681771 step=0.100000
2017/08/26 05:06:19 step 4: mse=0.655789 step=0.100000
2017/08/26 05:06:22 step 5: mse=0.633137 step=0.100000
2017/08/26 05:06:24 step 6: mse=0.606413 step=0.100000
2017/08/26 05:06:26 step 7: mse=0.589670 step=0.100000
2017/08/26 05:06:26 Saving...
2017/08/26 05:06:26 Gathering batch of experience...
2017/08/26 05:06:40 batch 140: mean=13.224490 stddev=5.511640 entropy=1.150474 frames=36063 count=49
2017/08/26 05:06:40 Training policy...
2017/08/26 05:06:47 step 0: objective=0.044037864
2017/08/26 05:06:54 step 1: objective=0.044096168
2017/08/26 05:06:59 step 2: objective=0.044153903
2017/08/26 05:07:05 step 3: objective=0.044211533
2017/08/26 05:07:11 step 4: objective=0.04426889
2017/08/26 05:07:17 step 5: objective=0.04431795
2017/08/26 05:07:23 step 6: objective=0.044363394
2017/08/26 05:07:29 step 7: objective=0.044405077
2017/08/26 05:07:29 Training value function...
2017/08/26 05:07:31 step 0: mse=0.680777 step=0.100000
2017/08/26 05:07:34 step 1: mse=0.649209 step=0.100000
2017/08/26 05:07:36 step 2: mse=0.618910 step=0.100000
2017/08/26 05:07:38 step 3: mse=0.594128 step=0.100000
2017/08/26 05:07:41 step 4: mse=0.573208 step=0.100000
2017/08/26 05:07:43 step 5: mse=0.557336 step=0.100000
2017/08/26 05:07:45 step 6: mse=0.532960 step=0.100000
2017/08/26 05:07:47 step 7: mse=0.512448 step=0.100000
2017/08/26 05:07:47 Saving...
2017/08/26 05:07:48 Gathering batch of experience...
2017/08/26 05:08:01 batch 141: mean=12.700000 stddev=5.139066 entropy=1.159933 frames=35324 count=50
2017/08/26 05:08:01 Training policy...
2017/08/26 05:08:09 step 0: objective=0.028318834
2017/08/26 05:08:15 step 1: objective=0.02837638
2017/08/26 05:08:20 step 2: objective=0.028433869
2017/08/26 05:08:26 step 3: objective=0.02849165
2017/08/26 05:08:32 step 4: objective=0.028548814
2017/08/26 05:08:38 step 5: objective=0.028590636
2017/08/26 05:08:44 step 6: objective=0.028627984
2017/08/26 05:08:49 step 7: objective=0.028658787
2017/08/26 05:08:49 Training value function...
2017/08/26 05:08:52 step 0: mse=0.664952 step=0.100000
2017/08/26 05:08:54 step 1: mse=0.640317 step=0.100000
2017/08/26 05:08:57 step 2: mse=0.618023 step=0.100000
2017/08/26 05:08:59 step 3: mse=0.601008 step=0.100000
2017/08/26 05:09:01 step 4: mse=0.585620 step=0.100000
2017/08/26 05:09:03 step 5: mse=0.573029 step=0.100000
2017/08/26 05:09:05 step 6: mse=0.555606 step=0.100000
2017/08/26 05:09:08 step 7: mse=0.542666 step=0.100000
2017/08/26 05:09:08 Saving...
2017/08/26 05:09:08 Gathering batch of experience...
2017/08/26 05:09:21 batch 142: mean=12.117647 stddev=4.479352 entropy=1.153393 frames=35833 count=51
2017/08/26 05:09:21 Training policy...
2017/08/26 05:09:29 step 0: objective=0.012651155
2017/08/26 05:09:35 step 1: objective=0.012679607
2017/08/26 05:09:41 step 2: objective=0.012707873
2017/08/26 05:09:47 step 3: objective=0.0127359675
2017/08/26 05:09:53 step 4: objective=0.01276399
2017/08/26 05:09:58 step 5: objective=0.01279183
2017/08/26 05:10:04 step 6: objective=0.012819431
2017/08/26 05:10:10 step 7: objective=0.01284184
2017/08/26 05:10:10 Training value function...
2017/08/26 05:10:13 step 0: mse=0.507378 step=0.100000
2017/08/26 05:10:15 step 1: mse=0.481893 step=0.100000
2017/08/26 05:10:18 step 2: mse=0.461708 step=0.100000
2017/08/26 05:10:20 step 3: mse=0.444760 step=0.100000
2017/08/26 05:10:22 step 4: mse=0.431357 step=0.100000
2017/08/26 05:10:25 step 5: mse=0.419695 step=0.100000
2017/08/26 05:10:27 step 6: mse=0.410148 step=0.100000
2017/08/26 05:10:29 step 7: mse=0.400016 step=0.100000
2017/08/26 05:10:29 Saving...
2017/08/26 05:10:29 Gathering batch of experience...
2017/08/26 05:10:43 batch 143: mean=11.509804 stddev=5.003421 entropy=1.167450 frames=35040 count=51
2017/08/26 05:10:43 Training policy...
2017/08/26 05:10:50 step 0: objective=0.015527305
2017/08/26 05:10:56 step 1: objective=0.015555931
2017/08/26 05:11:02 step 2: objective=0.015584723
2017/08/26 05:11:07 step 3: objective=0.01561327
2017/08/26 05:11:13 step 4: objective=0.015641702
2017/08/26 05:11:19 step 5: objective=0.015670221
2017/08/26 05:11:25 step 6: objective=0.015698558
2017/08/26 05:11:30 step 7: objective=0.015726814
2017/08/26 05:11:30 Training value function...
2017/08/26 05:11:33 step 0: mse=0.492386 step=0.100000
2017/08/26 05:11:35 step 1: mse=0.468349 step=0.100000
2017/08/26 05:11:37 step 2: mse=0.450838 step=0.100000
2017/08/26 05:11:40 step 3: mse=0.434191 step=0.100000
2017/08/26 05:11:42 step 4: mse=0.416381 step=0.100000
2017/08/26 05:11:44 step 5: mse=0.403504 step=0.100000
2017/08/26 05:11:46 step 6: mse=0.391025 step=0.100000
2017/08/26 05:11:49 step 7: mse=0.379360 step=0.100000
2017/08/26 05:11:49 Saving...
2017/08/26 05:11:49 Gathering batch of experience...
2017/08/26 05:12:02 batch 144: mean=12.596154 stddev=6.171459 entropy=1.158816 frames=35729 count=52
2017/08/26 05:12:02 Training policy...
2017/08/26 05:12:10 step 0: objective=0.045008436
2017/08/26 05:12:16 step 1: objective=0.045063924
2017/08/26 05:12:22 step 2: objective=0.045119397
2017/08/26 05:12:28 step 3: objective=0.04517489
2017/08/26 05:12:34 step 4: objective=0.04523089
2017/08/26 05:12:40 step 5: objective=0.045286033
2017/08/26 05:12:46 step 6: objective=0.045338403
2017/08/26 05:12:52 step 7: objective=0.0453854
2017/08/26 05:12:52 Training value function...
2017/08/26 05:12:55 step 0: mse=0.812785 step=0.100000
2017/08/26 05:12:57 step 1: mse=0.769323 step=0.100000
2017/08/26 05:12:59 step 2: mse=0.730879 step=0.100000
2017/08/26 05:13:01 step 3: mse=0.697053 step=0.100000
2017/08/26 05:13:03 step 4: mse=0.669474 step=0.100000
2017/08/26 05:13:06 step 5: mse=0.646728 step=0.100000
2017/08/26 05:13:08 step 6: mse=0.625076 step=0.100000
2017/08/26 05:13:10 step 7: mse=0.595606 step=0.100000
2017/08/26 05:13:10 Saving...
2017/08/26 05:13:10 Gathering batch of experience...
2017/08/26 05:13:24 batch 145: mean=10.740741 stddev=4.477041 entropy=1.162453 frames=35765 count=54
2017/08/26 05:13:24 Training policy...
2017/08/26 05:13:32 step 0: objective=-9.2209666e-05
2017/08/26 05:13:38 step 1: objective=-4.04754e-05
2017/08/26 05:13:43 step 2: objective=1.1223677e-05
2017/08/26 05:13:49 step 3: objective=6.2896586e-05
2017/08/26 05:13:55 step 4: objective=0.00011417076
2017/08/26 05:14:01 step 5: objective=0.00015857072
2017/08/26 05:14:07 step 6: objective=0.00018824691
2017/08/26 05:14:14 step 7: objective=0.00021146005
2017/08/26 05:14:14 Training value function...
2017/08/26 05:14:16 step 0: mse=0.381294 step=0.100000
2017/08/26 05:14:18 step 1: mse=0.363903 step=0.100000
2017/08/26 05:14:21 step 2: mse=0.350260 step=0.100000
2017/08/26 05:14:23 step 3: mse=0.338967 step=0.100000
2017/08/26 05:14:25 step 4: mse=0.331653 step=0.100000
2017/08/26 05:14:27 step 5: mse=0.325959 step=0.100000
2017/08/26 05:14:30 step 6: mse=0.319327 step=0.100000
2017/08/26 05:14:32 step 7: mse=0.315657 step=0.100000
2017/08/26 05:14:32 Saving...
2017/08/26 05:14:32 Gathering batch of experience...
2017/08/26 05:14:45 batch 146: mean=12.102041 stddev=4.799000 entropy=1.162112 frames=34817 count=49
2017/08/26 05:14:45 Training policy...
2017/08/26 05:14:53 step 0: objective=0.032059155
2017/08/26 05:14:59 step 1: objective=0.032081235
2017/08/26 05:15:05 step 2: objective=0.032103542
2017/08/26 05:15:10 step 3: objective=0.032125626
2017/08/26 05:15:16 step 4: objective=0.032148004
2017/08/26 05:15:22 step 5: objective=0.03217038
2017/08/26 05:15:28 step 6: objective=0.032192692
2017/08/26 05:15:34 step 7: objective=0.032214954
2017/08/26 05:15:34 Training value function...
2017/08/26 05:15:36 step 0: mse=0.560683 step=0.100000
2017/08/26 05:15:38 step 1: mse=0.535468 step=0.100000
2017/08/26 05:15:41 step 2: mse=0.522468 step=0.100000
2017/08/26 05:15:43 step 3: mse=0.510161 step=0.100000
2017/08/26 05:15:45 step 4: mse=0.500706 step=0.100000
2017/08/26 05:15:47 step 5: mse=0.488345 step=0.100000
2017/08/26 05:15:49 step 6: mse=0.480483 step=0.100000
2017/08/26 05:15:52 step 7: mse=0.472128 step=0.100000
2017/08/26 05:15:52 Saving...
2017/08/26 05:15:52 Gathering batch of experience...
2017/08/26 05:16:05 batch 147: mean=11.431373 stddev=3.668920 entropy=1.163396 frames=35448 count=51
2017/08/26 05:16:05 Training policy...
2017/08/26 05:16:13 step 0: objective=0.01351065
2017/08/26 05:16:19 step 1: objective=0.013535764
2017/08/26 05:16:25 step 2: objective=0.013560852
2017/08/26 05:16:31 step 3: objective=0.013586069
2017/08/26 05:16:36 step 4: objective=0.01361121
2017/08/26 05:16:43 step 5: objective=0.013636415
2017/08/26 05:16:49 step 6: objective=0.013661632
2017/08/26 05:16:54 step 7: objective=0.013685417
2017/08/26 05:16:54 Training value function...
2017/08/26 05:16:57 step 0: mse=0.394779 step=0.100000
2017/08/26 05:16:59 step 1: mse=0.375908 step=0.100000
2017/08/26 05:17:02 step 2: mse=0.360889 step=0.100000
2017/08/26 05:17:04 step 3: mse=0.348474 step=0.100000
2017/08/26 05:17:06 step 4: mse=0.338199 step=0.100000
2017/08/26 05:17:08 step 5: mse=0.329063 step=0.100000
2017/08/26 05:17:10 step 6: mse=0.317468 step=0.100000
2017/08/26 05:17:13 step 7: mse=0.310047 step=0.100000
2017/08/26 05:17:13 Saving...
2017/08/26 05:17:13 Gathering batch of experience...
2017/08/26 05:17:27 batch 148: mean=13.300000 stddev=5.678908 entropy=1.159726 frames=35988 count=50
2017/08/26 05:17:27 Training policy...
2017/08/26 05:17:34 step 0: objective=0.057900477
2017/08/26 05:17:41 step 1: objective=0.057931107
2017/08/26 05:17:47 step 2: objective=0.057962544
2017/08/26 05:17:53 step 3: objective=0.05799385
2017/08/26 05:17:59 step 4: objective=0.058025587
2017/08/26 05:18:05 step 5: objective=0.05805757
2017/08/26 05:18:10 step 6: objective=0.058079567
2017/08/26 05:18:17 step 7: objective=0.058132287
2017/08/26 05:18:17 Training value function...
2017/08/26 05:18:19 step 0: mse=0.956017 step=0.100000
2017/08/26 05:18:22 step 1: mse=0.895739 step=0.100000
2017/08/26 05:18:24 step 2: mse=0.846470 step=0.100000
2017/08/26 05:18:26 step 3: mse=0.799150 step=0.100000
2017/08/26 05:18:28 step 4: mse=0.754975 step=0.100000
2017/08/26 05:18:31 step 5: mse=0.721767 step=0.100000
2017/08/26 05:18:33 step 6: mse=0.696012 step=0.100000
2017/08/26 05:18:36 step 7: mse=0.663286 step=0.100000
2017/08/26 05:18:36 Saving...
2017/08/26 05:18:36 Gathering batch of experience...
2017/08/26 05:18:49 batch 149: mean=12.580000 stddev=4.600391 entropy=1.149264 frames=35661 count=50
2017/08/26 05:18:49 Training policy...
2017/08/26 05:18:57 step 0: objective=0.02578554
2017/08/26 05:19:03 step 1: objective=0.025854371
2017/08/26 05:19:09 step 2: objective=0.025887616
2017/08/26 05:19:15 step 3: objective=0.025943473
2017/08/26 05:19:21 step 4: objective=0.026012272
2017/08/26 05:19:27 step 5: objective=0.026045546
2017/08/26 05:19:33 step 6: objective=0.02610063
2017/08/26 05:19:39 step 7: objective=0.026166696
2017/08/26 05:19:39 Training value function...
2017/08/26 05:19:42 step 0: mse=0.631481 step=0.100000
2017/08/26 05:19:44 step 1: mse=0.608213 step=0.100000
2017/08/26 05:19:47 step 2: mse=0.585138 step=0.100000
2017/08/26 05:19:49 step 3: mse=0.567540 step=0.100000
2017/08/26 05:19:51 step 4: mse=0.549049 step=0.100000
2017/08/26 05:19:54 step 5: mse=0.530816 step=0.100000
2017/08/26 05:19:56 step 6: mse=0.516314 step=0.100000
2017/08/26 05:19:58 step 7: mse=0.507497 step=0.100000
2017/08/26 05:19:58 Saving...
2017/08/26 05:19:58 Gathering batch of experience...
2017/08/26 05:20:12 batch 150: mean=12.294118 stddev=5.831941 entropy=1.161141 frames=35163 count=51
2017/08/26 05:20:12 Training policy...
2017/08/26 05:20:19 step 0: objective=0.031433664
2017/08/26 05:20:25 step 1: objective=0.03147087
2017/08/26 05:20:31 step 2: objective=0.031508096
2017/08/26 05:20:37 step 3: objective=0.031545773
2017/08/26 05:20:42 step 4: objective=0.03158372
2017/08/26 05:20:48 step 5: objective=0.031621866
2017/08/26 05:20:54 step 6: objective=0.031655215
2017/08/26 05:21:00 step 7: objective=0.031684097
2017/08/26 05:21:00 Training value function...
2017/08/26 05:21:03 step 0: mse=0.680597 step=0.100000
2017/08/26 05:21:05 step 1: mse=0.637087 step=0.100000
2017/08/26 05:21:07 step 2: mse=0.601778 step=0.100000
2017/08/26 05:21:10 step 3: mse=0.573277 step=0.100000
2017/08/26 05:21:12 step 4: mse=0.547483 step=0.100000
2017/08/26 05:21:14 step 5: mse=0.526521 step=0.100000
2017/08/26 05:21:16 step 6: mse=0.507634 step=0.100000
2017/08/26 05:21:18 step 7: mse=0.493297 step=0.100000
2017/08/26 05:21:18 Saving...
2017/08/26 05:21:18 Gathering batch of experience...
2017/08/26 05:21:32 batch 151: mean=13.520000 stddev=7.253248 entropy=1.164208 frames=36310 count=50
2017/08/26 05:21:32 Training policy...
2017/08/26 05:21:40 step 0: objective=0.03485043
2017/08/26 05:21:46 step 1: objective=0.034933444
2017/08/26 05:21:52 step 2: objective=0.035015833
2017/08/26 05:21:59 step 3: objective=0.03509472
2017/08/26 05:22:05 step 4: objective=0.035147835
2017/08/26 05:22:11 step 5: objective=0.03518966
2017/08/26 05:22:17 step 6: objective=0.0352195
2017/08/26 05:22:23 step 7: objective=0.03525247
2017/08/26 05:22:23 Training value function...
2017/08/26 05:22:26 step 0: mse=0.873579 step=0.100000
2017/08/26 05:22:28 step 1: mse=0.806189 step=0.100000
2017/08/26 05:22:30 step 2: mse=0.756056 step=0.100000
2017/08/26 05:22:33 step 3: mse=0.707634 step=0.100000
2017/08/26 05:22:35 step 4: mse=0.671701 step=0.100000
2017/08/26 05:22:37 step 5: mse=0.638113 step=0.100000
2017/08/26 05:22:40 step 6: mse=0.608790 step=0.100000
2017/08/26 05:22:42 step 7: mse=0.585327 step=0.100000
2017/08/26 05:22:42 Saving...
2017/08/26 05:22:42 Gathering batch of experience...
2017/08/26 05:22:56 batch 152: mean=12.700000 stddev=6.268174 entropy=1.156141 frames=35889 count=50
2017/08/26 05:22:56 Training policy...
2017/08/26 05:23:04 step 0: objective=0.025993222
2017/08/26 05:23:10 step 1: objective=0.026035953
2017/08/26 05:23:16 step 2: objective=0.026078548
2017/08/26 05:23:22 step 3: objective=0.026121028
2017/08/26 05:23:28 step 4: objective=0.026163578
2017/08/26 05:23:34 step 5: objective=0.026205897
2017/08/26 05:23:40 step 6: objective=0.026243366
2017/08/26 05:23:46 step 7: objective=0.02628
2017/08/26 05:23:46 Training value function...
2017/08/26 05:23:49 step 0: mse=0.861333 step=0.100000
2017/08/26 05:23:51 step 1: mse=0.802211 step=0.100000
2017/08/26 05:23:53 step 2: mse=0.753855 step=0.100000
2017/08/26 05:23:56 step 3: mse=0.714185 step=0.100000
2017/08/26 05:23:58 step 4: mse=0.679353 step=0.100000
2017/08/26 05:24:00 step 5: mse=0.650642 step=0.100000
2017/08/26 05:24:03 step 6: mse=0.627726 step=0.100000
2017/08/26 05:24:05 step 7: mse=0.604928 step=0.100000
2017/08/26 05:24:05 Saving...
2017/08/26 05:24:05 Gathering batch of experience...
2017/08/26 05:24:18 batch 153: mean=13.204082 stddev=6.468068 entropy=1.156771 frames=34826 count=49
2017/08/26 05:24:18 Training policy...
2017/08/26 05:24:26 step 0: objective=0.040264174
2017/08/26 05:24:32 step 1: objective=0.0403218
2017/08/26 05:24:38 step 2: objective=0.04037995
2017/08/26 05:24:44 step 3: objective=0.040437784
2017/08/26 05:24:50 step 4: objective=0.04048884
2017/08/26 05:24:56 step 5: objective=0.04053028
2017/08/26 05:25:02 step 6: objective=0.040577516
2017/08/26 05:25:08 step 7: objective=0.040624056
2017/08/26 05:25:08 Training value function...
2017/08/26 05:25:10 step 0: mse=0.883539 step=0.100000
2017/08/26 05:25:13 step 1: mse=0.838242 step=0.100000
2017/08/26 05:25:15 step 2: mse=0.799288 step=0.100000
2017/08/26 05:25:17 step 3: mse=0.761224 step=0.100000
2017/08/26 05:25:19 step 4: mse=0.720764 step=0.100000
2017/08/26 05:25:21 step 5: mse=0.693643 step=0.100000
2017/08/26 05:25:24 step 6: mse=0.671436 step=0.100000
2017/08/26 05:25:26 step 7: mse=0.646296 step=0.100000
2017/08/26 05:25:26 Saving...
2017/08/26 05:25:26 Gathering batch of experience...
2017/08/26 05:25:40 batch 154: mean=11.634615 stddev=5.945356 entropy=1.153683 frames=35745 count=52
2017/08/26 05:25:40 Training policy...
2017/08/26 05:25:47 step 0: objective=0.010626636
2017/08/26 05:25:53 step 1: objective=0.010679738
2017/08/26 05:25:59 step 2: objective=0.010733645
2017/08/26 05:26:05 step 3: objective=0.010787922
2017/08/26 05:26:11 step 4: objective=0.010832194
2017/08/26 05:26:18 step 5: objective=0.010872088
2017/08/26 05:26:24 step 6: objective=0.010909288
2017/08/26 05:26:30 step 7: objective=0.0109509975
2017/08/26 05:26:30 Training value function...
2017/08/26 05:26:33 step 0: mse=0.558097 step=0.100000
2017/08/26 05:26:35 step 1: mse=0.527729 step=0.100000
2017/08/26 05:26:37 step 2: mse=0.503263 step=0.100000
2017/08/26 05:26:39 step 3: mse=0.483782 step=0.100000
2017/08/26 05:26:42 step 4: mse=0.467492 step=0.100000
2017/08/26 05:26:44 step 5: mse=0.452781 step=0.100000
2017/08/26 05:26:46 step 6: mse=0.436798 step=0.100000
2017/08/26 05:26:49 step 7: mse=0.419875 step=0.100000
2017/08/26 05:26:49 Saving...
2017/08/26 05:26:49 Gathering batch of experience...
2017/08/26 05:27:02 batch 155: mean=10.962264 stddev=4.386782 entropy=1.159524 frames=35034 count=53
2017/08/26 05:27:02 Training policy...
2017/08/26 05:27:10 step 0: objective=0.026067968
2017/08/26 05:27:16 step 1: objective=0.02609726
2017/08/26 05:27:22 step 2: objective=0.026126396
2017/08/26 05:27:28 step 3: objective=0.026155435
2017/08/26 05:27:34 step 4: objective=0.026184507
2017/08/26 05:27:40 step 5: objective=0.026214805
2017/08/26 05:27:46 step 6: objective=0.026245354
2017/08/26 05:27:52 step 7: objective=0.026271397
2017/08/26 05:27:52 Training value function...
2017/08/26 05:27:54 step 0: mse=0.478026 step=0.100000
2017/08/26 05:27:57 step 1: mse=0.447079 step=0.100000
2017/08/26 05:27:59 step 2: mse=0.422189 step=0.100000
2017/08/26 05:28:01 step 3: mse=0.402037 step=0.100000
2017/08/26 05:28:03 step 4: mse=0.385403 step=0.100000
2017/08/26 05:28:06 step 5: mse=0.371675 step=0.100000
2017/08/26 05:28:08 step 6: mse=0.360493 step=0.100000
2017/08/26 05:28:10 step 7: mse=0.351494 step=0.100000
2017/08/26 05:28:10 Saving...
2017/08/26 05:28:10 Gathering batch of experience...
2017/08/26 05:28:23 batch 156: mean=11.788462 stddev=4.939389 entropy=1.164461 frames=34490 count=52
2017/08/26 05:28:23 Training policy...
2017/08/26 05:28:31 step 0: objective=0.035297003
2017/08/26 05:28:37 step 1: objective=0.035346575
2017/08/26 05:28:43 step 2: objective=0.035396382
2017/08/26 05:28:49 step 3: objective=0.035446204
2017/08/26 05:28:55 step 4: objective=0.03549388
2017/08/26 05:29:01 step 5: objective=0.035530396
2017/08/26 05:29:07 step 6: objective=0.035569236
2017/08/26 05:29:13 step 7: objective=0.035603095
2017/08/26 05:29:13 Training value function...
2017/08/26 05:29:15 step 0: mse=0.715906 step=0.100000
2017/08/26 05:29:17 step 1: mse=0.684422 step=0.100000
2017/08/26 05:29:20 step 2: mse=0.652922 step=0.100000
2017/08/26 05:29:22 step 3: mse=0.627427 step=0.100000
2017/08/26 05:29:24 step 4: mse=0.598471 step=0.100000
2017/08/26 05:29:26 step 5: mse=0.580453 step=0.100000
2017/08/26 05:29:28 step 6: mse=0.562793 step=0.100000
2017/08/26 05:29:30 step 7: mse=0.542822 step=0.100000
2017/08/26 05:29:30 Saving...
2017/08/26 05:29:30 Gathering batch of experience...
2017/08/26 05:29:44 batch 157: mean=12.489796 stddev=5.063364 entropy=1.154248 frames=35672 count=49
2017/08/26 05:29:44 Training policy...
2017/08/26 05:29:52 step 0: objective=0.027457718
2017/08/26 05:29:58 step 1: objective=0.027496127
2017/08/26 05:30:04 step 2: objective=0.027534239
2017/08/26 05:30:10 step 3: objective=0.027572172
2017/08/26 05:30:17 step 4: objective=0.027609805
2017/08/26 05:30:23 step 5: objective=0.02764749
2017/08/26 05:30:29 step 6: objective=0.02768343
2017/08/26 05:30:35 step 7: objective=0.027717706
2017/08/26 05:30:35 Training value function...
2017/08/26 05:30:38 step 0: mse=0.533836 step=0.100000
2017/08/26 05:30:40 step 1: mse=0.517417 step=0.100000
2017/08/26 05:30:42 step 2: mse=0.500653 step=0.100000
2017/08/26 05:30:45 step 3: mse=0.489567 step=0.100000
2017/08/26 05:30:47 step 4: mse=0.477515 step=0.100000
2017/08/26 05:30:49 step 5: mse=0.466812 step=0.100000
2017/08/26 05:30:51 step 6: mse=0.458009 step=0.100000
2017/08/26 05:30:54 step 7: mse=0.440836 step=0.100000
2017/08/26 05:30:54 Saving...
2017/08/26 05:30:54 Gathering batch of experience...
2017/08/26 05:31:08 batch 158: mean=11.557692 stddev=5.208770 entropy=1.157357 frames=35782 count=52
2017/08/26 05:31:08 Training policy...
2017/08/26 05:31:15 step 0: objective=0.0146916
2017/08/26 05:31:22 step 1: objective=0.014726934
2017/08/26 05:31:28 step 2: objective=0.014762223
2017/08/26 05:31:34 step 3: objective=0.014797522
2017/08/26 05:31:40 step 4: objective=0.014832792
2017/08/26 05:31:47 step 5: objective=0.014868176
2017/08/26 05:31:53 step 6: objective=0.014907569
2017/08/26 05:31:59 step 7: objective=0.014936721
2017/08/26 05:31:59 Training value function...
2017/08/26 05:32:02 step 0: mse=0.468747 step=0.100000
2017/08/26 05:32:04 step 1: mse=0.451499 step=0.100000
2017/08/26 05:32:06 step 2: mse=0.438395 step=0.100000
2017/08/26 05:32:09 step 3: mse=0.429236 step=0.100000
2017/08/26 05:32:11 step 4: mse=0.421914 step=0.100000
2017/08/26 05:32:13 step 5: mse=0.410980 step=0.100000
2017/08/26 05:32:15 step 6: mse=0.405336 step=0.100000
2017/08/26 05:32:18 step 7: mse=0.400684 step=0.100000
2017/08/26 05:32:18 Saving...
2017/08/26 05:32:18 Gathering batch of experience...
2017/08/26 05:32:31 batch 159: mean=12.156863 stddev=5.446253 entropy=1.155324 frames=35380 count=51
2017/08/26 05:32:31 Training policy...
2017/08/26 05:32:39 step 0: objective=0.04024573
2017/08/26 05:32:45 step 1: objective=0.040317878
2017/08/26 05:32:51 step 2: objective=0.04039066
2017/08/26 05:32:58 step 3: objective=0.040463764
2017/08/26 05:33:04 step 4: objective=0.04052692
2017/08/26 05:33:10 step 5: objective=0.04058592
2017/08/26 05:33:16 step 6: objective=0.0406099
2017/08/26 05:33:22 step 7: objective=0.040638916
2017/08/26 05:33:22 Training value function...
2017/08/26 05:33:25 step 0: mse=0.622017 step=0.100000
2017/08/26 05:33:27 step 1: mse=0.584701 step=0.100000
2017/08/26 05:33:30 step 2: mse=0.554543 step=0.100000
2017/08/26 05:33:32 step 3: mse=0.528988 step=0.100000
2017/08/26 05:33:34 step 4: mse=0.507357 step=0.100000
2017/08/26 05:33:36 step 5: mse=0.486950 step=0.100000
2017/08/26 05:33:39 step 6: mse=0.472945 step=0.100000
2017/08/26 05:33:41 step 7: mse=0.459445 step=0.100000
2017/08/26 05:33:41 Saving...
2017/08/26 05:33:41 Gathering batch of experience...
2017/08/26 05:33:54 batch 160: mean=11.396226 stddev=5.381098 entropy=1.151860 frames=35283 count=53
2017/08/26 05:33:54 Training policy...
2017/08/26 05:34:02 step 0: objective=0.023285938
2017/08/26 05:34:08 step 1: objective=0.023373011
2017/08/26 05:34:15 step 2: objective=0.023462567
2017/08/26 05:34:21 step 3: objective=0.023546789
2017/08/26 05:34:27 step 4: objective=0.02361147
2017/08/26 05:34:33 step 5: objective=0.023670005
2017/08/26 05:34:39 step 6: objective=0.023722813
2017/08/26 05:34:45 step 7: objective=0.023814313
2017/08/26 05:34:45 Training value function...
2017/08/26 05:34:48 step 0: mse=1.001880 step=0.100000
2017/08/26 05:34:50 step 1: mse=0.897997 step=0.100000
2017/08/26 05:34:53 step 2: mse=0.814545 step=0.100000
2017/08/26 05:34:55 step 3: mse=0.746765 step=0.100000
2017/08/26 05:34:57 step 4: mse=0.691814 step=0.100000
2017/08/26 05:34:59 step 5: mse=0.646895 step=0.100000
2017/08/26 05:35:02 step 6: mse=0.606782 step=0.100000
2017/08/26 05:35:04 step 7: mse=0.576493 step=0.100000
2017/08/26 05:35:04 Saving...
2017/08/26 05:35:04 Gathering batch of experience...
2017/08/26 05:35:18 batch 161: mean=13.880000 stddev=5.968718 entropy=1.151519 frames=37099 count=50
2017/08/26 05:35:18 Training policy...
2017/08/26 05:35:26 step 0: objective=0.060358033
2017/08/26 05:35:33 step 1: objective=0.060411323
2017/08/26 05:35:39 step 2: objective=0.060465194
2017/08/26 05:35:46 step 3: objective=0.06051876
2017/08/26 05:35:52 step 4: objective=0.060570415
2017/08/26 05:36:00 step 5: objective=0.060613856
2017/08/26 05:36:06 step 6: objective=0.0606508
2017/08/26 05:36:13 step 7: objective=0.06075495
2017/08/26 05:36:13 Training value function...
2017/08/26 05:36:16 step 0: mse=1.029797 step=0.100000
2017/08/26 05:36:18 step 1: mse=0.959355 step=0.100000
2017/08/26 05:36:21 step 2: mse=0.904658 step=0.100000
2017/08/26 05:36:23 step 3: mse=0.846204 step=0.100000
2017/08/26 05:36:25 step 4: mse=0.805099 step=0.100000
2017/08/26 05:36:28 step 5: mse=0.762710 step=0.100000
2017/08/26 05:36:30 step 6: mse=0.719756 step=0.100000
2017/08/26 05:36:33 step 7: mse=0.688886 step=0.100000
2017/08/26 05:36:33 Saving...
2017/08/26 05:36:33 Gathering batch of experience...
2017/08/26 05:36:47 batch 162: mean=13.019608 stddev=5.599335 entropy=1.156566 frames=36241 count=51
2017/08/26 05:36:47 Training policy...
2017/08/26 05:36:55 step 0: objective=0.02566331
2017/08/26 05:37:02 step 1: objective=0.02573565
2017/08/26 05:37:08 step 2: objective=0.02580785
2017/08/26 05:37:15 step 3: objective=0.025887446
2017/08/26 05:37:22 step 4: objective=0.025929037
2017/08/26 05:37:28 step 5: objective=0.025962802
2017/08/26 05:37:34 step 6: objective=0.026026053
2017/08/26 05:37:41 step 7: objective=0.026077604
2017/08/26 05:37:41 Training value function...
2017/08/26 05:37:43 step 0: mse=0.856164 step=0.100000
2017/08/26 05:37:46 step 1: mse=0.815588 step=0.100000
2017/08/26 05:37:48 step 2: mse=0.782192 step=0.100000
2017/08/26 05:37:50 step 3: mse=0.750864 step=0.100000
2017/08/26 05:37:52 step 4: mse=0.725201 step=0.100000
2017/08/26 05:37:55 step 5: mse=0.705139 step=0.100000
2017/08/26 05:37:57 step 6: mse=0.688194 step=0.100000
2017/08/26 05:37:59 step 7: mse=0.671579 step=0.100000
2017/08/26 05:37:59 Saving...
2017/08/26 05:37:59 Gathering batch of experience...
2017/08/26 05:38:13 batch 163: mean=12.173077 stddev=5.693185 entropy=1.155677 frames=35628 count=52
2017/08/26 05:38:13 Training policy...
2017/08/26 05:38:21 step 0: objective=0.025973074
2017/08/26 05:38:28 step 1: objective=0.026042959
2017/08/26 05:38:34 step 2: objective=0.026112134
2017/08/26 05:38:40 step 3: objective=0.026180511
2017/08/26 05:38:47 step 4: objective=0.026247842
2017/08/26 05:38:54 step 5: objective=0.026306113
2017/08/26 05:39:00 step 6: objective=0.026382202
2017/08/26 05:39:06 step 7: objective=0.026449163
2017/08/26 05:39:06 Training value function...
2017/08/26 05:39:09 step 0: mse=0.765144 step=0.100000
2017/08/26 05:39:11 step 1: mse=0.719188 step=0.100000
2017/08/26 05:39:13 step 2: mse=0.672557 step=0.100000
2017/08/26 05:39:16 step 3: mse=0.641792 step=0.100000
2017/08/26 05:39:18 step 4: mse=0.615897 step=0.100000
2017/08/26 05:39:20 step 5: mse=0.592609 step=0.100000
2017/08/26 05:39:23 step 6: mse=0.575138 step=0.100000
2017/08/26 05:39:25 step 7: mse=0.542948 step=0.100000
2017/08/26 05:39:25 Saving...
2017/08/26 05:39:25 Gathering batch of experience...
2017/08/26 05:39:39 batch 164: mean=12.979167 stddev=5.804056 entropy=1.145376 frames=35556 count=48
2017/08/26 05:39:39 Training policy...
2017/08/26 05:39:47 step 0: objective=0.020071212
2017/08/26 05:39:54 step 1: objective=0.02014143
2017/08/26 05:40:00 step 2: objective=0.020211691
2017/08/26 05:40:07 step 3: objective=0.020282181
2017/08/26 05:40:13 step 4: objective=0.020351563
2017/08/26 05:40:19 step 5: objective=0.020411499
2017/08/26 05:40:26 step 6: objective=0.020433242
2017/08/26 05:40:32 step 7: objective=0.020511165
2017/08/26 05:40:32 Training value function...
2017/08/26 05:40:35 step 0: mse=0.629784 step=0.100000
2017/08/26 05:40:37 step 1: mse=0.609643 step=0.100000
2017/08/26 05:40:39 step 2: mse=0.591482 step=0.100000
2017/08/26 05:40:41 step 3: mse=0.577638 step=0.100000
2017/08/26 05:40:44 step 4: mse=0.545885 step=0.100000
2017/08/26 05:40:46 step 5: mse=0.530840 step=0.100000
2017/08/26 05:40:48 step 6: mse=0.504560 step=0.100000
2017/08/26 05:40:51 step 7: mse=0.494463 step=0.100000
2017/08/26 05:40:51 Saving...
2017/08/26 05:40:51 Gathering batch of experience...
2017/08/26 05:41:05 batch 165: mean=13.145833 stddev=5.049709 entropy=1.144305 frames=35770 count=48
2017/08/26 05:41:05 Training policy...
2017/08/26 05:41:13 step 0: objective=0.022254035
2017/08/26 05:41:19 step 1: objective=0.022300068
2017/08/26 05:41:25 step 2: objective=0.022346787
2017/08/26 05:41:32 step 3: objective=0.022393301
2017/08/26 05:41:38 step 4: objective=0.022439577
2017/08/26 05:41:44 step 5: objective=0.022485945
2017/08/26 05:41:51 step 6: objective=0.022531847
2017/08/26 05:41:57 step 7: objective=0.022575058
2017/08/26 05:41:57 Training value function...
2017/08/26 05:42:00 step 0: mse=0.659779 step=0.100000
2017/08/26 05:42:02 step 1: mse=0.638022 step=0.100000
2017/08/26 05:42:05 step 2: mse=0.606422 step=0.100000
2017/08/26 05:42:07 step 3: mse=0.570763 step=0.100000
2017/08/26 05:42:09 step 4: mse=0.557354 step=0.100000
2017/08/26 05:42:12 step 5: mse=0.528943 step=0.100000
2017/08/26 05:42:14 step 6: mse=0.504037 step=0.100000
2017/08/26 05:42:16 step 7: mse=0.489033 step=0.100000
2017/08/26 05:42:16 Saving...
2017/08/26 05:42:16 Gathering batch of experience...
2017/08/26 05:42:30 batch 166: mean=11.846154 stddev=5.039783 entropy=1.153845 frames=35718 count=52
2017/08/26 05:42:30 Training policy...
2017/08/26 05:42:38 step 0: objective=0.021264255
2017/08/26 05:42:45 step 1: objective=0.0213223
2017/08/26 05:42:51 step 2: objective=0.021380007
2017/08/26 05:42:57 step 3: objective=0.021437488
2017/08/26 05:43:04 step 4: objective=0.02149495
2017/08/26 05:43:10 step 5: objective=0.021551441
2017/08/26 05:43:17 step 6: objective=0.021602204
2017/08/26 05:43:23 step 7: objective=0.02163496
2017/08/26 05:43:23 Training value function...
2017/08/26 05:43:26 step 0: mse=0.615698 step=0.100000
2017/08/26 05:43:28 step 1: mse=0.593680 step=0.100000
2017/08/26 05:43:30 step 2: mse=0.567020 step=0.100000
2017/08/26 05:43:33 step 3: mse=0.551977 step=0.100000
2017/08/26 05:43:35 step 4: mse=0.530967 step=0.100000
2017/08/26 05:43:37 step 5: mse=0.516272 step=0.100000
2017/08/26 05:43:40 step 6: mse=0.501276 step=0.100000
2017/08/26 05:43:42 step 7: mse=0.489677 step=0.100000
2017/08/26 05:43:42 Saving...
2017/08/26 05:43:42 Gathering batch of experience...
2017/08/26 05:43:56 batch 167: mean=12.791667 stddev=4.138027 entropy=1.147348 frames=35428 count=48
2017/08/26 05:43:56 Training policy...
2017/08/26 05:44:04 step 0: objective=0.023918506
2017/08/26 05:44:10 step 1: objective=0.023985367
2017/08/26 05:44:16 step 2: objective=0.024052331
2017/08/26 05:44:23 step 3: objective=0.024119435
2017/08/26 05:44:29 step 4: objective=0.02418673
2017/08/26 05:44:35 step 5: objective=0.024244025
2017/08/26 05:44:42 step 6: objective=0.024285182
2017/08/26 05:44:48 step 7: objective=0.024316963
2017/08/26 05:44:48 Training value function...
2017/08/26 05:44:51 step 0: mse=0.614362 step=0.100000
2017/08/26 05:44:53 step 1: mse=0.583534 step=0.100000
2017/08/26 05:44:55 step 2: mse=0.558993 step=0.100000
2017/08/26 05:44:58 step 3: mse=0.539410 step=0.100000
2017/08/26 05:45:00 step 4: mse=0.523766 step=0.100000
2017/08/26 05:45:02 step 5: mse=0.511044 step=0.100000
2017/08/26 05:45:05 step 6: mse=0.500694 step=0.100000
2017/08/26 05:45:07 step 7: mse=0.486727 step=0.100000
2017/08/26 05:45:07 Saving...
2017/08/26 05:45:07 Gathering batch of experience...
2017/08/26 05:45:21 batch 168: mean=14.458333 stddev=5.171872 entropy=1.153052 frames=36386 count=48
2017/08/26 05:45:21 Training policy...
2017/08/26 05:45:29 step 0: objective=0.06378491
2017/08/26 05:45:36 step 1: objective=0.06389972
2017/08/26 05:45:42 step 2: objective=0.06401543
2017/08/26 05:45:49 step 3: objective=0.06412616
2017/08/26 05:45:55 step 4: objective=0.06421484
2017/08/26 05:46:02 step 5: objective=0.0642878
2017/08/26 05:46:08 step 6: objective=0.064370684
2017/08/26 05:46:15 step 7: objective=0.06440421
2017/08/26 05:46:15 Training value function...
2017/08/26 05:46:18 step 0: mse=0.893880 step=0.100000
2017/08/26 05:46:20 step 1: mse=0.823011 step=0.100000
2017/08/26 05:46:22 step 2: mse=0.760870 step=0.100000
2017/08/26 05:46:25 step 3: mse=0.713775 step=0.100000
2017/08/26 05:46:27 step 4: mse=0.673062 step=0.100000
2017/08/26 05:46:29 step 5: mse=0.631589 step=0.100000
2017/08/26 05:46:32 step 6: mse=0.603449 step=0.100000
2017/08/26 05:46:34 step 7: mse=0.574299 step=0.100000
2017/08/26 05:46:34 Saving...
2017/08/26 05:46:34 Gathering batch of experience...
2017/08/26 05:46:48 batch 169: mean=12.333333 stddev=4.780133 entropy=1.151990 frames=36008 count=51
2017/08/26 05:46:48 Training policy...
2017/08/26 05:46:56 step 0: objective=0.009122549
2017/08/26 05:47:03 step 1: objective=0.009165137
2017/08/26 05:47:09 step 2: objective=0.009207267
2017/08/26 05:47:16 step 3: objective=0.009248753
2017/08/26 05:47:23 step 4: objective=0.009289782
2017/08/26 05:47:29 step 5: objective=0.00932594
2017/08/26 05:47:36 step 6: objective=0.009356865
2017/08/26 05:47:42 step 7: objective=0.009404414
2017/08/26 05:47:42 Training value function...
2017/08/26 05:47:45 step 0: mse=0.712877 step=0.100000
2017/08/26 05:47:47 step 1: mse=0.661446 step=0.100000
2017/08/26 05:47:49 step 2: mse=0.621662 step=0.100000
2017/08/26 05:47:52 step 3: mse=0.587056 step=0.100000
2017/08/26 05:47:54 step 4: mse=0.559385 step=0.100000
2017/08/26 05:47:57 step 5: mse=0.535493 step=0.100000
2017/08/26 05:47:59 step 6: mse=0.516597 step=0.100000
2017/08/26 05:48:01 step 7: mse=0.485276 step=0.100000
2017/08/26 05:48:01 Saving...
2017/08/26 05:48:01 Gathering batch of experience...
2017/08/26 05:48:15 batch 170: mean=12.274510 stddev=5.045201 entropy=1.143169 frames=36575 count=51
2017/08/26 05:48:15 Training policy...
2017/08/26 05:48:24 step 0: objective=0.0062129083
2017/08/26 05:48:31 step 1: objective=0.006248554
2017/08/26 05:48:37 step 2: objective=0.006284322
2017/08/26 05:48:44 step 3: objective=0.00632021
2017/08/26 05:48:51 step 4: objective=0.006356326
2017/08/26 05:48:57 step 5: objective=0.00639254
2017/08/26 05:49:04 step 6: objective=0.006426315
2017/08/26 05:49:11 step 7: objective=0.006448137
2017/08/26 05:49:11 Training value function...
2017/08/26 05:49:13 step 0: mse=0.595888 step=0.100000
2017/08/26 05:49:16 step 1: mse=0.554520 step=0.100000
2017/08/26 05:49:18 step 2: mse=0.521471 step=0.100000
2017/08/26 05:49:21 step 3: mse=0.494981 step=0.100000
2017/08/26 05:49:23 step 4: mse=0.473546 step=0.100000
2017/08/26 05:49:25 step 5: mse=0.455766 step=0.100000
2017/08/26 05:49:28 step 6: mse=0.442406 step=0.100000
2017/08/26 05:49:30 step 7: mse=0.431586 step=0.100000
2017/08/26 05:49:30 Saving...
2017/08/26 05:49:30 Gathering batch of experience...
2017/08/26 05:49:44 batch 171: mean=12.058824 stddev=4.750281 entropy=1.149317 frames=35784 count=51
2017/08/26 05:49:44 Training policy...
2017/08/26 05:49:52 step 0: objective=0.028464517
2017/08/26 05:49:59 step 1: objective=0.028508926
2017/08/26 05:50:06 step 2: objective=0.02855346
2017/08/26 05:50:12 step 3: objective=0.0285979
2017/08/26 05:50:19 step 4: objective=0.028644016
2017/08/26 05:50:25 step 5: objective=0.028690327
2017/08/26 05:50:32 step 6: objective=0.028734334
2017/08/26 05:50:39 step 7: objective=0.028776694
2017/08/26 05:50:39 Training value function...
2017/08/26 05:50:41 step 0: mse=0.544972 step=0.100000
2017/08/26 05:50:44 step 1: mse=0.519956 step=0.100000
2017/08/26 05:50:46 step 2: mse=0.499885 step=0.100000
2017/08/26 05:50:48 step 3: mse=0.485709 step=0.100000
2017/08/26 05:50:50 step 4: mse=0.468579 step=0.100000
2017/08/26 05:50:53 step 5: mse=0.453423 step=0.100000
2017/08/26 05:50:55 step 6: mse=0.440194 step=0.100000
2017/08/26 05:50:57 step 7: mse=0.430263 step=0.100000
2017/08/26 05:50:57 Saving...
2017/08/26 05:50:57 Gathering batch of experience...
2017/08/26 05:51:11 batch 172: mean=12.500000 stddev=4.908156 entropy=1.145172 frames=35664 count=50
2017/08/26 05:51:11 Training policy...
2017/08/26 05:51:20 step 0: objective=0.02621276
2017/08/26 05:51:26 step 1: objective=0.026241468
2017/08/26 05:51:33 step 2: objective=0.026270201
2017/08/26 05:51:39 step 3: objective=0.026298994
2017/08/26 05:51:46 step 4: objective=0.026327625
2017/08/26 05:51:53 step 5: objective=0.026356177
2017/08/26 05:51:59 step 6: objective=0.026382245
2017/08/26 05:52:06 step 7: objective=0.026409881
2017/08/26 05:52:06 Training value function...
2017/08/26 05:52:08 step 0: mse=0.682445 step=0.100000
2017/08/26 05:52:11 step 1: mse=0.633260 step=0.100000
2017/08/26 05:52:13 step 2: mse=0.593473 step=0.100000
2017/08/26 05:52:15 step 3: mse=0.563967 step=0.100000
2017/08/26 05:52:17 step 4: mse=0.532714 step=0.100000
2017/08/26 05:52:20 step 5: mse=0.506330 step=0.100000
2017/08/26 05:52:22 step 6: mse=0.484970 step=0.100000
2017/08/26 05:52:24 step 7: mse=0.466018 step=0.100000
2017/08/26 05:52:24 Saving...
2017/08/26 05:52:24 Gathering batch of experience...
2017/08/26 05:52:38 batch 173: mean=12.354167 stddev=4.639008 entropy=1.149558 frames=34270 count=48
2017/08/26 05:52:38 Training policy...
2017/08/26 05:52:46 step 0: objective=0.029193709
2017/08/26 05:52:52 step 1: objective=0.029254112
2017/08/26 05:52:58 step 2: objective=0.029314073
2017/08/26 05:53:05 step 3: objective=0.02937335
2017/08/26 05:53:11 step 4: objective=0.0294307
2017/08/26 05:53:17 step 5: objective=0.02946619
2017/08/26 05:53:24 step 6: objective=0.029508239
2017/08/26 05:53:30 step 7: objective=0.029547142
2017/08/26 05:53:30 Training value function...
2017/08/26 05:53:32 step 0: mse=0.548776 step=0.100000
2017/08/26 05:53:35 step 1: mse=0.516925 step=0.100000
2017/08/26 05:53:37 step 2: mse=0.491018 step=0.100000
2017/08/26 05:53:39 step 3: mse=0.469668 step=0.100000
2017/08/26 05:53:41 step 4: mse=0.455711 step=0.100000
2017/08/26 05:53:44 step 5: mse=0.438396 step=0.100000
2017/08/26 05:53:46 step 6: mse=0.428154 step=0.100000
2017/08/26 05:53:48 step 7: mse=0.415386 step=0.100000
2017/08/26 05:53:48 Saving...
2017/08/26 05:53:48 Gathering batch of experience...
2017/08/26 05:54:02 batch 174: mean=12.865385 stddev=4.949860 entropy=1.151301 frames=35648 count=52
2017/08/26 05:54:02 Training policy...
2017/08/26 05:54:10 step 0: objective=0.04664127
2017/08/26 05:54:17 step 1: objective=0.046701077
2017/08/26 05:54:23 step 2: objective=0.0467603
2017/08/26 05:54:30 step 3: objective=0.046819225
2017/08/26 05:54:37 step 4: objective=0.046872627
2017/08/26 05:54:43 step 5: objective=0.046910804
2017/08/26 05:54:50 step 6: objective=0.047028765
2017/08/26 05:54:57 step 7: objective=0.04706996
2017/08/26 05:54:57 Training value function...
2017/08/26 05:54:59 step 0: mse=1.100610 step=0.100000
2017/08/26 05:55:01 step 1: mse=1.031273 step=0.100000
2017/08/26 05:55:04 step 2: mse=0.956185 step=0.100000
2017/08/26 05:55:06 step 3: mse=0.908025 step=0.100000
2017/08/26 05:55:08 step 4: mse=0.861542 step=0.100000
2017/08/26 05:55:11 step 5: mse=0.829004 step=0.100000
2017/08/26 05:55:13 step 6: mse=0.786788 step=0.100000
2017/08/26 05:55:15 step 7: mse=0.760624 step=0.100000
2017/08/26 05:55:15 Saving...
2017/08/26 05:55:15 Gathering batch of experience...
2017/08/26 05:55:29 batch 175: mean=12.920000 stddev=5.976086 entropy=1.150376 frames=36002 count=50
2017/08/26 05:55:29 Training policy...
2017/08/26 05:55:37 step 0: objective=0.03217191
2017/08/26 05:55:44 step 1: objective=0.032207374
2017/08/26 05:55:51 step 2: objective=0.032243084
2017/08/26 05:55:57 step 3: objective=0.032278724
2017/08/26 05:56:04 step 4: objective=0.032313894
2017/08/26 05:56:11 step 5: objective=0.032341972
2017/08/26 05:56:17 step 6: objective=0.03238453
2017/08/26 05:56:24 step 7: objective=0.032418743
2017/08/26 05:56:24 Training value function...
2017/08/26 05:56:27 step 0: mse=0.864309 step=0.100000
2017/08/26 05:56:29 step 1: mse=0.794600 step=0.100000
2017/08/26 05:56:31 step 2: mse=0.735430 step=0.100000
2017/08/26 05:56:34 step 3: mse=0.688262 step=0.100000
2017/08/26 05:56:36 step 4: mse=0.640147 step=0.100000
2017/08/26 05:56:38 step 5: mse=0.608775 step=0.100000
2017/08/26 05:56:41 step 6: mse=0.574389 step=0.100000
2017/08/26 05:56:43 step 7: mse=0.552764 step=0.100000
2017/08/26 05:56:43 Saving...
2017/08/26 05:56:43 Gathering batch of experience...
2017/08/26 05:56:57 batch 176: mean=13.723404 stddev=6.603359 entropy=1.145520 frames=36005 count=47
2017/08/26 05:56:57 Training policy...
2017/08/26 05:57:05 step 0: objective=0.008089647
2017/08/26 05:57:12 step 1: objective=0.008139726
2017/08/26 05:57:19 step 2: objective=0.008176087
2017/08/26 05:57:26 step 3: objective=0.008212526
2017/08/26 05:57:32 step 4: objective=0.008249093
2017/08/26 05:57:40 step 5: objective=0.008284691
2017/08/26 05:57:46 step 6: objective=0.008314589
2017/08/26 05:57:53 step 7: objective=0.008367178
2017/08/26 05:57:53 Training value function...
2017/08/26 05:57:56 step 0: mse=0.584996 step=0.100000
2017/08/26 05:57:58 step 1: mse=0.543752 step=0.100000
2017/08/26 05:58:00 step 2: mse=0.511094 step=0.100000
2017/08/26 05:58:03 step 3: mse=0.482368 step=0.100000
2017/08/26 05:58:05 step 4: mse=0.456800 step=0.100000
2017/08/26 05:58:07 step 5: mse=0.435499 step=0.100000
2017/08/26 05:58:09 step 6: mse=0.417095 step=0.100000
2017/08/26 05:58:12 step 7: mse=0.401978 step=0.100000
2017/08/26 05:58:12 Saving...
2017/08/26 05:58:12 Gathering batch of experience...
2017/08/26 05:58:26 batch 177: mean=13.020000 stddev=6.670802 entropy=1.139022 frames=36231 count=50
2017/08/26 05:58:26 Training policy...
2017/08/26 05:58:35 step 0: objective=0.02140941
2017/08/26 05:58:41 step 1: objective=0.021452239
2017/08/26 05:58:48 step 2: objective=0.021495555
2017/08/26 05:58:55 step 3: objective=0.02153941
2017/08/26 05:59:02 step 4: objective=0.021579308
2017/08/26 05:59:08 step 5: objective=0.02162678
2017/08/26 05:59:15 step 6: objective=0.021690225
2017/08/26 05:59:22 step 7: objective=0.02175165
2017/08/26 05:59:22 Training value function...
2017/08/26 05:59:25 step 0: mse=1.012873 step=0.100000
2017/08/26 05:59:27 step 1: mse=0.927594 step=0.100000
2017/08/26 05:59:29 step 2: mse=0.859228 step=0.100000
2017/08/26 05:59:32 step 3: mse=0.804068 step=0.100000
2017/08/26 05:59:34 step 4: mse=0.761126 step=0.100000
2017/08/26 05:59:36 step 5: mse=0.701894 step=0.100000
2017/08/26 05:59:39 step 6: mse=0.650289 step=0.100000
2017/08/26 05:59:41 step 7: mse=0.609018 step=0.100000
2017/08/26 05:59:41 Saving...
2017/08/26 05:59:41 Gathering batch of experience...
2017/08/26 05:59:55 batch 178: mean=13.062500 stddev=5.490166 entropy=1.142708 frames=35216 count=48
2017/08/26 05:59:55 Training policy...
2017/08/26 06:00:03 step 0: objective=0.029255927
2017/08/26 06:00:10 step 1: objective=0.029299721
2017/08/26 06:00:16 step 2: objective=0.029343573
2017/08/26 06:00:23 step 3: objective=0.029387236
2017/08/26 06:00:29 step 4: objective=0.029430928
2017/08/26 06:00:36 step 5: objective=0.029474206
2017/08/26 06:00:43 step 6: objective=0.029511617
2017/08/26 06:00:49 step 7: objective=0.029544003
2017/08/26 06:00:49 Training value function...
2017/08/26 06:00:52 step 0: mse=0.776813 step=0.100000
2017/08/26 06:00:54 step 1: mse=0.729833 step=0.100000
2017/08/26 06:00:56 step 2: mse=0.692121 step=0.100000
2017/08/26 06:00:59 step 3: mse=0.661458 step=0.100000
2017/08/26 06:01:01 step 4: mse=0.635831 step=0.100000
2017/08/26 06:01:03 step 5: mse=0.609485 step=0.100000
2017/08/26 06:01:05 step 6: mse=0.589425 step=0.100000
2017/08/26 06:01:08 step 7: mse=0.573156 step=0.100000
2017/08/26 06:01:08 Saving...
2017/08/26 06:01:08 Gathering batch of experience...
2017/08/26 06:01:22 batch 179: mean=12.877551 stddev=6.032675 entropy=1.136914 frames=35776 count=49
2017/08/26 06:01:22 Training policy...
2017/08/26 06:01:30 step 0: objective=0.030505704
2017/08/26 06:01:37 step 1: objective=0.030557772
2017/08/26 06:01:44 step 2: objective=0.03061024
2017/08/26 06:01:50 step 3: objective=0.030662708
2017/08/26 06:01:57 step 4: objective=0.030713977
2017/08/26 06:02:04 step 5: objective=0.030778557
2017/08/26 06:02:11 step 6: objective=0.030829554
2017/08/26 06:02:17 step 7: objective=0.030919893
2017/08/26 06:02:17 Training value function...
2017/08/26 06:02:20 step 0: mse=0.902779 step=0.100000
2017/08/26 06:02:22 step 1: mse=0.829559 step=0.100000
2017/08/26 06:02:25 step 2: mse=0.770578 step=0.100000
2017/08/26 06:02:27 step 3: mse=0.722998 step=0.100000
2017/08/26 06:02:29 step 4: mse=0.683848 step=0.100000
2017/08/26 06:02:31 step 5: mse=0.635458 step=0.100000
2017/08/26 06:02:34 step 6: mse=0.611264 step=0.100000
2017/08/26 06:02:36 step 7: mse=0.587456 step=0.100000
2017/08/26 06:02:36 Saving...
2017/08/26 06:02:36 Gathering batch of experience...
2017/08/26 06:02:50 batch 180: mean=13.320000 stddev=4.826759 entropy=1.146151 frames=35840 count=50
2017/08/26 06:02:50 Training policy...
2017/08/26 06:02:59 step 0: objective=0.043184694
2017/08/26 06:03:05 step 1: objective=0.04322223
2017/08/26 06:03:12 step 2: objective=0.0432598
2017/08/26 06:03:20 step 3: objective=0.04329815
2017/08/26 06:03:26 step 4: objective=0.043336056
2017/08/26 06:03:33 step 5: objective=0.043422725
2017/08/26 06:03:40 step 6: objective=0.043467376
2017/08/26 06:03:47 step 7: objective=0.043502547
2017/08/26 06:03:47 Training value function...
2017/08/26 06:03:50 step 0: mse=0.978754 step=0.100000
2017/08/26 06:03:52 step 1: mse=0.917657 step=0.100000
2017/08/26 06:03:54 step 2: mse=0.865639 step=0.100000
2017/08/26 06:03:56 step 3: mse=0.825059 step=0.100000
2017/08/26 06:03:59 step 4: mse=0.783694 step=0.100000
2017/08/26 06:04:01 step 5: mse=0.745108 step=0.100000
2017/08/26 06:04:03 step 6: mse=0.714391 step=0.100000
2017/08/26 06:04:06 step 7: mse=0.689299 step=0.100000
2017/08/26 06:04:06 Saving...
2017/08/26 06:04:06 Gathering batch of experience...
2017/08/26 06:04:20 batch 181: mean=13.571429 stddev=5.827451 entropy=1.142140 frames=35670 count=49
2017/08/26 06:04:20 Training policy...
2017/08/26 06:04:28 step 0: objective=0.034096092
2017/08/26 06:04:35 step 1: objective=0.034157857
2017/08/26 06:04:42 step 2: objective=0.03421913
2017/08/26 06:04:48 step 3: objective=0.0342802
2017/08/26 06:04:55 step 4: objective=0.034339298
2017/08/26 06:05:02 step 5: objective=0.034385152
2017/08/26 06:05:09 step 6: objective=0.034450468
2017/08/26 06:05:15 step 7: objective=0.034508213
2017/08/26 06:05:15 Training value function...
2017/08/26 06:05:18 step 0: mse=0.816039 step=0.100000
2017/08/26 06:05:20 step 1: mse=0.765400 step=0.100000
2017/08/26 06:05:23 step 2: mse=0.724774 step=0.100000
2017/08/26 06:05:25 step 3: mse=0.691152 step=0.100000
2017/08/26 06:05:27 step 4: mse=0.664149 step=0.100000
2017/08/26 06:05:29 step 5: mse=0.638615 step=0.100000
2017/08/26 06:05:32 step 6: mse=0.618954 step=0.100000
2017/08/26 06:05:34 step 7: mse=0.604478 step=0.100000
2017/08/26 06:05:34 Saving...
2017/08/26 06:05:34 Gathering batch of experience...
2017/08/26 06:05:48 batch 182: mean=13.937500 stddev=6.577760 entropy=1.138958 frames=35980 count=48
2017/08/26 06:05:48 Training policy...
2017/08/26 06:05:56 step 0: objective=0.028680919
2017/08/26 06:06:03 step 1: objective=0.028759312
2017/08/26 06:06:10 step 2: objective=0.028837163
2017/08/26 06:06:18 step 3: objective=0.028914234
2017/08/26 06:06:24 step 4: objective=0.02898588
2017/08/26 06:06:31 step 5: objective=0.029047096
2017/08/26 06:06:38 step 6: objective=0.029116979
2017/08/26 06:06:45 step 7: objective=0.029164154
2017/08/26 06:06:45 Training value function...
2017/08/26 06:06:48 step 0: mse=0.978667 step=0.100000
2017/08/26 06:06:50 step 1: mse=0.910521 step=0.100000
2017/08/26 06:06:53 step 2: mse=0.851942 step=0.100000
2017/08/26 06:06:55 step 3: mse=0.808207 step=0.100000
2017/08/26 06:06:57 step 4: mse=0.761341 step=0.100000
2017/08/26 06:06:59 step 5: mse=0.719881 step=0.100000
2017/08/26 06:07:02 step 6: mse=0.682928 step=0.100000
2017/08/26 06:07:04 step 7: mse=0.652376 step=0.100000
2017/08/26 06:07:04 Saving...
2017/08/26 06:07:04 Gathering batch of experience...
2017/08/26 06:07:18 batch 183: mean=13.326531 stddev=7.279795 entropy=1.135726 frames=35309 count=49
2017/08/26 06:07:18 Training policy...
2017/08/26 06:07:27 step 0: objective=0.02973232
2017/08/26 06:07:33 step 1: objective=0.029781284
2017/08/26 06:07:40 step 2: objective=0.029822096
2017/08/26 06:07:47 step 3: objective=0.029863305
2017/08/26 06:07:53 step 4: objective=0.029904852
2017/08/26 06:08:01 step 5: objective=0.029945107
2017/08/26 06:08:07 step 6: objective=0.029980056
2017/08/26 06:08:14 step 7: objective=0.030001638
2017/08/26 06:08:14 Training value function...
2017/08/26 06:08:17 step 0: mse=0.871348 step=0.100000
2017/08/26 06:08:19 step 1: mse=0.825023 step=0.100000
2017/08/26 06:08:21 step 2: mse=0.787397 step=0.100000
2017/08/26 06:08:23 step 3: mse=0.756299 step=0.100000
2017/08/26 06:08:26 step 4: mse=0.728158 step=0.100000
2017/08/26 06:08:28 step 5: mse=0.706311 step=0.100000
2017/08/26 06:08:30 step 6: mse=0.683689 step=0.100000
2017/08/26 06:08:32 step 7: mse=0.667279 step=0.100000
2017/08/26 06:08:32 Saving...
2017/08/26 06:08:32 Gathering batch of experience...
2017/08/26 06:08:47 batch 184: mean=12.568627 stddev=6.065831 entropy=1.146850 frames=35796 count=51
2017/08/26 06:08:47 Training policy...
2017/08/26 06:08:55 step 0: objective=0.020170812
2017/08/26 06:09:02 step 1: objective=0.020265989
2017/08/26 06:09:09 step 2: objective=0.020362452
2017/08/26 06:09:16 step 3: objective=0.020408154
2017/08/26 06:09:23 step 4: objective=0.020455526
2017/08/26 06:09:30 step 5: objective=0.020493295
2017/08/26 06:09:36 step 6: objective=0.020542478
2017/08/26 06:09:43 step 7: objective=0.020585328
2017/08/26 06:09:43 Training value function...
2017/08/26 06:09:46 step 0: mse=0.706558 step=0.100000
2017/08/26 06:09:48 step 1: mse=0.672103 step=0.100000
2017/08/26 06:09:51 step 2: mse=0.645552 step=0.100000
2017/08/26 06:09:53 step 3: mse=0.617725 step=0.100000
2017/08/26 06:09:55 step 4: mse=0.599756 step=0.100000
2017/08/26 06:09:57 step 5: mse=0.570930 step=0.100000
2017/08/26 06:10:00 step 6: mse=0.550175 step=0.100000
2017/08/26 06:10:02 step 7: mse=0.531231 step=0.100000
2017/08/26 06:10:02 Saving...
2017/08/26 06:10:02 Gathering batch of experience...
2017/08/26 06:10:16 batch 185: mean=12.693878 stddev=4.862199 entropy=1.140879 frames=35498 count=49
2017/08/26 06:10:16 Training policy...
2017/08/26 06:10:24 step 0: objective=0.013005046
2017/08/26 06:10:31 step 1: objective=0.013068425
2017/08/26 06:10:38 step 2: objective=0.013132112
2017/08/26 06:10:45 step 3: objective=0.013195905
2017/08/26 06:10:52 step 4: objective=0.013259517
2017/08/26 06:10:58 step 5: objective=0.013317878
2017/08/26 06:11:05 step 6: objective=0.013359216
2017/08/26 06:11:12 step 7: objective=0.013399095
2017/08/26 06:11:12 Training value function...
2017/08/26 06:11:15 step 0: mse=0.577879 step=0.100000
2017/08/26 06:11:17 step 1: mse=0.552691 step=0.100000
2017/08/26 06:11:20 step 2: mse=0.532567 step=0.100000
2017/08/26 06:11:22 step 3: mse=0.515893 step=0.100000
2017/08/26 06:11:24 step 4: mse=0.501243 step=0.100000
2017/08/26 06:11:26 step 5: mse=0.486399 step=0.100000
2017/08/26 06:11:29 step 6: mse=0.463197 step=0.100000
2017/08/26 06:11:31 step 7: mse=0.457210 step=0.100000
2017/08/26 06:11:31 Saving...
2017/08/26 06:11:31 Gathering batch of experience...
2017/08/26 06:11:46 batch 186: mean=12.627451 stddev=6.249583 entropy=1.141611 frames=36852 count=51
2017/08/26 06:11:46 Training policy...
2017/08/26 06:11:54 step 0: objective=0.027133826
2017/08/26 06:12:02 step 1: objective=0.027169956
2017/08/26 06:12:09 step 2: objective=0.027205786
2017/08/26 06:12:16 step 3: objective=0.027241439
2017/08/26 06:12:23 step 4: objective=0.027276596
2017/08/26 06:12:30 step 5: objective=0.02731117
2017/08/26 06:12:37 step 6: objective=0.027343636
2017/08/26 06:12:44 step 7: objective=0.027368926
2017/08/26 06:12:44 Training value function...
2017/08/26 06:12:47 step 0: mse=0.692268 step=0.100000
2017/08/26 06:12:50 step 1: mse=0.648049 step=0.100000
2017/08/26 06:12:52 step 2: mse=0.612284 step=0.100000
2017/08/26 06:12:54 step 3: mse=0.583190 step=0.100000
2017/08/26 06:12:57 step 4: mse=0.557087 step=0.100000
2017/08/26 06:12:59 step 5: mse=0.536567 step=0.100000
2017/08/26 06:13:01 step 6: mse=0.519167 step=0.100000
2017/08/26 06:13:04 step 7: mse=0.497063 step=0.100000
2017/08/26 06:13:04 Saving...
2017/08/26 06:13:04 Gathering batch of experience...
2017/08/26 06:13:18 batch 187: mean=14.553191 stddev=6.129137 entropy=1.135165 frames=35598 count=47
2017/08/26 06:13:18 Training policy...
2017/08/26 06:13:26 step 0: objective=0.04737858
2017/08/26 06:13:33 step 1: objective=0.04742407
2017/08/26 06:13:40 step 2: objective=0.047469825
2017/08/26 06:13:47 step 3: objective=0.047515023
2017/08/26 06:13:54 step 4: objective=0.047560006
2017/08/26 06:14:01 step 5: objective=0.04760341
2017/08/26 06:14:08 step 6: objective=0.047638047
2017/08/26 06:14:15 step 7: objective=0.04768444
2017/08/26 06:14:15 Training value function...
2017/08/26 06:14:17 step 0: mse=0.927476 step=0.100000
2017/08/26 06:14:19 step 1: mse=0.867852 step=0.100000
2017/08/26 06:14:22 step 2: mse=0.818293 step=0.100000
2017/08/26 06:14:24 step 3: mse=0.778469 step=0.100000
2017/08/26 06:14:26 step 4: mse=0.742260 step=0.100000
2017/08/26 06:14:29 step 5: mse=0.703003 step=0.100000
2017/08/26 06:14:31 step 6: mse=0.668482 step=0.100000
2017/08/26 06:14:33 step 7: mse=0.645389 step=0.100000
2017/08/26 06:14:33 Saving...
2017/08/26 06:14:33 Gathering batch of experience...
2017/08/26 06:14:47 batch 188: mean=12.200000 stddev=4.707441 entropy=1.144342 frames=35486 count=50
2017/08/26 06:14:47 Training policy...
2017/08/26 06:14:56 step 0: objective=0.006095128
2017/08/26 06:15:03 step 1: objective=0.006129693
2017/08/26 06:15:09 step 2: objective=0.0061642323
2017/08/26 06:15:16 step 3: objective=0.006198639
2017/08/26 06:15:23 step 4: objective=0.0062330216
2017/08/26 06:15:30 step 5: objective=0.006267284
2017/08/26 06:15:37 step 6: objective=0.0063007865
2017/08/26 06:15:44 step 7: objective=0.0063294796
2017/08/26 06:15:44 Training value function...
2017/08/26 06:15:47 step 0: mse=0.545278 step=0.100000
2017/08/26 06:15:49 step 1: mse=0.534430 step=0.100000
2017/08/26 06:15:51 step 2: mse=0.522601 step=0.100000
2017/08/26 06:15:54 step 3: mse=0.499867 step=0.100000
2017/08/26 06:15:56 step 4: mse=0.486606 step=0.100000
2017/08/26 06:15:58 step 5: mse=0.470531 step=0.100000
2017/08/26 06:16:00 step 6: mse=0.462356 step=0.100000
2017/08/26 06:16:03 step 7: mse=0.457710 step=0.100000
2017/08/26 06:16:03 Saving...
2017/08/26 06:16:03 Gathering batch of experience...
2017/08/26 06:16:17 batch 189: mean=12.377358 stddev=5.338456 entropy=1.146308 frames=36392 count=53
2017/08/26 06:16:17 Training policy...
2017/08/26 06:16:26 step 0: objective=0.031036671
2017/08/26 06:16:33 step 1: objective=0.03106562
2017/08/26 06:16:40 step 2: objective=0.031094866
2017/08/26 06:16:47 step 3: objective=0.031124257
2017/08/26 06:16:55 step 4: objective=0.031153308
2017/08/26 06:17:02 step 5: objective=0.03118308
2017/08/26 06:17:09 step 6: objective=0.031212127
2017/08/26 06:17:16 step 7: objective=0.03125303
2017/08/26 06:17:16 Training value function...
2017/08/26 06:17:19 step 0: mse=0.679809 step=0.100000
2017/08/26 06:17:21 step 1: mse=0.651515 step=0.100000
2017/08/26 06:17:23 step 2: mse=0.628844 step=0.100000
2017/08/26 06:17:26 step 3: mse=0.610527 step=0.100000
2017/08/26 06:17:28 step 4: mse=0.578582 step=0.100000
2017/08/26 06:17:30 step 5: mse=0.551253 step=0.100000
2017/08/26 06:17:32 step 6: mse=0.529210 step=0.100000
2017/08/26 06:17:35 step 7: mse=0.510843 step=0.100000
2017/08/26 06:17:35 Saving...
2017/08/26 06:17:35 Gathering batch of experience...
2017/08/26 06:17:49 batch 190: mean=12.740000 stddev=5.705471 entropy=1.141033 frames=36154 count=50
2017/08/26 06:17:49 Training policy...
2017/08/26 06:17:58 step 0: objective=0.029314263
2017/08/26 06:18:05 step 1: objective=0.029367253
2017/08/26 06:18:12 step 2: objective=0.02942015
2017/08/26 06:18:20 step 3: objective=0.029473549
2017/08/26 06:18:27 step 4: objective=0.029526832
2017/08/26 06:18:34 step 5: objective=0.029566342
2017/08/26 06:18:41 step 6: objective=0.029615773
2017/08/26 06:18:48 step 7: objective=0.029654425
2017/08/26 06:18:48 Training value function...
2017/08/26 06:18:51 step 0: mse=0.719254 step=0.100000
2017/08/26 06:18:53 step 1: mse=0.692028 step=0.100000
2017/08/26 06:18:55 step 2: mse=0.670057 step=0.100000
2017/08/26 06:18:57 step 3: mse=0.649089 step=0.100000
2017/08/26 06:19:00 step 4: mse=0.631983 step=0.100000
2017/08/26 06:19:02 step 5: mse=0.621701 step=0.100000
2017/08/26 06:19:04 step 6: mse=0.607976 step=0.100000
2017/08/26 06:19:07 step 7: mse=0.590485 step=0.100000
2017/08/26 06:19:07 Saving...
2017/08/26 06:19:07 Gathering batch of experience...
2017/08/26 06:19:21 batch 191: mean=13.208333 stddev=4.773880 entropy=1.133821 frames=35896 count=48
2017/08/26 06:19:21 Training policy...
2017/08/26 06:19:29 step 0: objective=0.028313981
2017/08/26 06:19:37 step 1: objective=0.028342465
2017/08/26 06:19:44 step 2: objective=0.028371066
2017/08/26 06:19:51 step 3: objective=0.028400002
2017/08/26 06:19:58 step 4: objective=0.028429175
2017/08/26 06:20:05 step 5: objective=0.028457848
2017/08/26 06:20:12 step 6: objective=0.028490141
2017/08/26 06:20:19 step 7: objective=0.028519018
2017/08/26 06:20:19 Training value function...
2017/08/26 06:20:22 step 0: mse=0.528177 step=0.100000
2017/08/26 06:20:24 step 1: mse=0.501882 step=0.100000
2017/08/26 06:20:27 step 2: mse=0.480808 step=0.100000
2017/08/26 06:20:29 step 3: mse=0.463292 step=0.100000
2017/08/26 06:20:31 step 4: mse=0.447667 step=0.100000
2017/08/26 06:20:34 step 5: mse=0.433913 step=0.100000
2017/08/26 06:20:36 step 6: mse=0.423252 step=0.100000
2017/08/26 06:20:38 step 7: mse=0.412718 step=0.100000
2017/08/26 06:20:38 Saving...
2017/08/26 06:20:38 Gathering batch of experience...
2017/08/26 06:20:52 batch 192: mean=12.372549 stddev=4.970347 entropy=1.145707 frames=35508 count=51
2017/08/26 06:20:52 Training policy...
2017/08/26 06:21:01 step 0: objective=0.021209378
2017/08/26 06:21:08 step 1: objective=0.02123808
2017/08/26 06:21:15 step 2: objective=0.021266643
2017/08/26 06:21:22 step 3: objective=0.021295577
2017/08/26 06:21:29 step 4: objective=0.02132419
2017/08/26 06:21:36 step 5: objective=0.021352591
2017/08/26 06:21:43 step 6: objective=0.021372948
2017/08/26 06:21:50 step 7: objective=0.02139858
2017/08/26 06:21:50 Training value function...
2017/08/26 06:21:53 step 0: mse=0.655990 step=0.100000
2017/08/26 06:21:55 step 1: mse=0.626574 step=0.100000
2017/08/26 06:21:57 step 2: mse=0.595767 step=0.100000
2017/08/26 06:21:59 step 3: mse=0.570116 step=0.100000
2017/08/26 06:22:02 step 4: mse=0.547629 step=0.100000
2017/08/26 06:22:04 step 5: mse=0.529669 step=0.100000
2017/08/26 06:22:06 step 6: mse=0.516911 step=0.100000
2017/08/26 06:22:08 step 7: mse=0.503259 step=0.100000
2017/08/26 06:22:08 Saving...
2017/08/26 06:22:09 Gathering batch of experience...
2017/08/26 06:22:23 batch 193: mean=14.212766 stddev=5.287223 entropy=1.130546 frames=36342 count=47
2017/08/26 06:22:23 Training policy...
2017/08/26 06:22:32 step 0: objective=0.036011167
2017/08/26 06:22:39 step 1: objective=0.03610905
2017/08/26 06:22:46 step 2: objective=0.036205143
2017/08/26 06:22:53 step 3: objective=0.036298856
2017/08/26 06:23:00 step 4: objective=0.036359653
2017/08/26 06:23:07 step 5: objective=0.036422383
2017/08/26 06:23:15 step 6: objective=0.03645751
2017/08/26 06:23:22 step 7: objective=0.036491867
2017/08/26 06:23:22 Training value function...
2017/08/26 06:23:25 step 0: mse=0.818626 step=0.100000
2017/08/26 06:23:27 step 1: mse=0.758051 step=0.100000
2017/08/26 06:23:29 step 2: mse=0.708918 step=0.100000
2017/08/26 06:23:32 step 3: mse=0.676582 step=0.100000
2017/08/26 06:23:34 step 4: mse=0.638455 step=0.100000
2017/08/26 06:23:36 step 5: mse=0.617718 step=0.100000
2017/08/26 06:23:39 step 6: mse=0.592755 step=0.100000
2017/08/26 06:23:41 step 7: mse=0.570309 step=0.100000
2017/08/26 06:23:41 Saving...
2017/08/26 06:23:41 Gathering batch of experience...
2017/08/26 06:23:56 batch 194: mean=14.255319 stddev=6.786934 entropy=1.134872 frames=36378 count=47
2017/08/26 06:23:56 Training policy...
2017/08/26 06:24:04 step 0: objective=0.035976306
2017/08/26 06:24:12 step 1: objective=0.03602801
2017/08/26 06:24:19 step 2: objective=0.036079105
2017/08/26 06:24:26 step 3: objective=0.036129985
2017/08/26 06:24:33 step 4: objective=0.036180466
2017/08/26 06:24:40 step 5: objective=0.036229316
2017/08/26 06:24:48 step 6: objective=0.03627345
2017/08/26 06:24:55 step 7: objective=0.036308274
2017/08/26 06:24:55 Training value function...
2017/08/26 06:24:58 step 0: mse=0.837453 step=0.100000
2017/08/26 06:25:00 step 1: mse=0.778674 step=0.100000
2017/08/26 06:25:03 step 2: mse=0.729037 step=0.100000
2017/08/26 06:25:05 step 3: mse=0.690470 step=0.100000
2017/08/26 06:25:07 step 4: mse=0.659303 step=0.100000
2017/08/26 06:25:10 step 5: mse=0.634218 step=0.100000
2017/08/26 06:25:12 step 6: mse=0.611932 step=0.100000
2017/08/26 06:25:14 step 7: mse=0.593588 step=0.100000
2017/08/26 06:25:14 Saving...
2017/08/26 06:25:14 Gathering batch of experience...
2017/08/26 06:25:29 batch 195: mean=12.791667 stddev=4.765144 entropy=1.134915 frames=35773 count=48
2017/08/26 06:25:29 Training policy...
2017/08/26 06:25:37 step 0: objective=0.015536889
2017/08/26 06:25:45 step 1: objective=0.015560382
2017/08/26 06:25:52 step 2: objective=0.015584417
2017/08/26 06:25:59 step 3: objective=0.015608573
2017/08/26 06:26:06 step 4: objective=0.015632782
2017/08/26 06:26:13 step 5: objective=0.015656987
2017/08/26 06:26:20 step 6: objective=0.015681516
2017/08/26 06:26:27 step 7: objective=0.01572184
2017/08/26 06:26:27 Training value function...
2017/08/26 06:26:30 step 0: mse=0.611775 step=0.100000
2017/08/26 06:26:32 step 1: mse=0.583805 step=0.100000
2017/08/26 06:26:35 step 2: mse=0.560973 step=0.100000
2017/08/26 06:26:37 step 3: mse=0.543310 step=0.100000
2017/08/26 06:26:39 step 4: mse=0.524449 step=0.100000
2017/08/26 06:26:42 step 5: mse=0.506830 step=0.100000
2017/08/26 06:26:44 step 6: mse=0.491746 step=0.100000
2017/08/26 06:26:46 step 7: mse=0.480616 step=0.100000
2017/08/26 06:26:46 Saving...
2017/08/26 06:26:46 Gathering batch of experience...
2017/08/26 06:27:00 batch 196: mean=12.300000 stddev=5.193265 entropy=1.141372 frames=35560 count=50
2017/08/26 06:27:00 Training policy...
2017/08/26 06:27:09 step 0: objective=0.021220608
2017/08/26 06:27:16 step 1: objective=0.021254959
2017/08/26 06:27:23 step 2: objective=0.021289075
2017/08/26 06:27:31 step 3: objective=0.021323247
2017/08/26 06:27:38 step 4: objective=0.021357179
2017/08/26 06:27:45 step 5: objective=0.021391131
2017/08/26 06:27:52 step 6: objective=0.021424353
2017/08/26 06:27:59 step 7: objective=0.021450108
2017/08/26 06:27:59 Training value function...
2017/08/26 06:28:02 step 0: mse=0.550170 step=0.100000
2017/08/26 06:28:04 step 1: mse=0.516357 step=0.100000
2017/08/26 06:28:06 step 2: mse=0.486854 step=0.100000
2017/08/26 06:28:09 step 3: mse=0.465264 step=0.100000
2017/08/26 06:28:11 step 4: mse=0.445709 step=0.100000
2017/08/26 06:28:13 step 5: mse=0.429556 step=0.100000
2017/08/26 06:28:15 step 6: mse=0.414850 step=0.100000
2017/08/26 06:28:17 step 7: mse=0.402740 step=0.100000
2017/08/26 06:28:17 Saving...
2017/08/26 06:28:18 Gathering batch of experience...
2017/08/26 06:28:32 batch 197: mean=12.918367 stddev=4.943917 entropy=1.144372 frames=35920 count=49
2017/08/26 06:28:32 Training policy...
2017/08/26 06:28:41 step 0: objective=0.030808777
2017/08/26 06:28:49 step 1: objective=0.03086673
2017/08/26 06:28:56 step 2: objective=0.03092473
2017/08/26 06:29:03 step 3: objective=0.03098292
2017/08/26 06:29:10 step 4: objective=0.031041369
2017/08/26 06:29:17 step 5: objective=0.031102592
2017/08/26 06:29:24 step 6: objective=0.031156354
2017/08/26 06:29:32 step 7: objective=0.031177733
2017/08/26 06:29:32 Training value function...
2017/08/26 06:29:34 step 0: mse=0.576797 step=0.100000
2017/08/26 06:29:37 step 1: mse=0.550546 step=0.100000
2017/08/26 06:29:39 step 2: mse=0.529281 step=0.100000
2017/08/26 06:29:41 step 3: mse=0.510046 step=0.100000
2017/08/26 06:29:43 step 4: mse=0.496420 step=0.100000
2017/08/26 06:29:46 step 5: mse=0.477295 step=0.100000
2017/08/26 06:29:48 step 6: mse=0.468363 step=0.100000
2017/08/26 06:29:50 step 7: mse=0.459351 step=0.100000
2017/08/26 06:29:50 Saving...
2017/08/26 06:29:50 Gathering batch of experience...
2017/08/26 06:30:04 batch 198: mean=13.895833 stddev=5.712704 entropy=1.135879 frames=35849 count=48
2017/08/26 06:30:04 Training policy...
2017/08/26 06:30:13 step 0: objective=0.04893223
2017/08/26 06:30:20 step 1: objective=0.048996516
2017/08/26 06:30:28 step 2: objective=0.04906086
2017/08/26 06:30:35 step 3: objective=0.04912502
2017/08/26 06:30:43 step 4: objective=0.049184326
2017/08/26 06:30:50 step 5: objective=0.049243215
2017/08/26 06:30:57 step 6: objective=0.049301792
2017/08/26 06:31:04 step 7: objective=0.049354196
2017/08/26 06:31:04 Training value function...
2017/08/26 06:31:07 step 0: mse=0.818702 step=0.100000
2017/08/26 06:31:09 step 1: mse=0.772240 step=0.100000
2017/08/26 06:31:11 step 2: mse=0.734683 step=0.100000
2017/08/26 06:31:14 step 3: mse=0.703016 step=0.100000
2017/08/26 06:31:16 step 4: mse=0.667146 step=0.100000
2017/08/26 06:31:18 step 5: mse=0.638777 step=0.100000
2017/08/26 06:31:21 step 6: mse=0.614065 step=0.100000
2017/08/26 06:31:23 step 7: mse=0.596875 step=0.100000
2017/08/26 06:31:23 Saving...
2017/08/26 06:31:23 Gathering batch of experience...
2017/08/26 06:31:37 batch 199: mean=13.083333 stddev=6.126559 entropy=1.137397 frames=35510 count=48
2017/08/26 06:31:37 Training policy...
2017/08/26 06:31:46 step 0: objective=0.01876993
2017/08/26 06:31:53 step 1: objective=0.018826032
2017/08/26 06:32:00 step 2: objective=0.018881021
2017/08/26 06:32:07 step 3: objective=0.01893524
2017/08/26 06:32:15 step 4: objective=0.018984245
2017/08/26 06:32:22 step 5: objective=0.019021649
2017/08/26 06:32:29 step 6: objective=0.019055342
2017/08/26 06:32:36 step 7: objective=0.019087499
2017/08/26 06:32:36 Training value function...
2017/08/26 06:32:39 step 0: mse=0.650884 step=0.100000
2017/08/26 06:32:41 step 1: mse=0.608234 step=0.100000
2017/08/26 06:32:43 step 2: mse=0.574487 step=0.100000
2017/08/26 06:32:46 step 3: mse=0.546970 step=0.100000
2017/08/26 06:32:48 step 4: mse=0.524984 step=0.100000
2017/08/26 06:32:50 step 5: mse=0.504835 step=0.100000
2017/08/26 06:32:53 step 6: mse=0.488242 step=0.100000
2017/08/26 06:32:55 step 7: mse=0.475414 step=0.100000
2017/08/26 06:32:55 Saving...
2017/08/26 06:32:55 Gathering batch of experience...
2017/08/26 06:33:09 batch 200: mean=12.000000 stddev=4.150240 entropy=1.136675 frames=35010 count=49
2017/08/26 06:33:09 Training policy...
2017/08/26 06:33:18 step 0: objective=0.009290785
2017/08/26 06:33:25 step 1: objective=0.009323733
2017/08/26 06:33:32 step 2: objective=0.00935672
2017/08/26 06:33:39 step 3: objective=0.009389684
2017/08/26 06:33:46 step 4: objective=0.009422699
2017/08/26 06:33:53 step 5: objective=0.009455728
2017/08/26 06:34:01 step 6: objective=0.009486332
2017/08/26 06:34:08 step 7: objective=0.009518727
2017/08/26 06:34:08 Training value function...
2017/08/26 06:34:10 step 0: mse=0.457385 step=0.100000
2017/08/26 06:34:13 step 1: mse=0.427974 step=0.100000
2017/08/26 06:34:15 step 2: mse=0.406162 step=0.100000
2017/08/26 06:34:17 step 3: mse=0.386372 step=0.100000
2017/08/26 06:34:19 step 4: mse=0.370908 step=0.100000
2017/08/26 06:34:21 step 5: mse=0.358289 step=0.100000
2017/08/26 06:34:24 step 6: mse=0.346803 step=0.100000
2017/08/26 06:34:26 step 7: mse=0.337368 step=0.100000
2017/08/26 06:34:26 Saving...
2017/08/26 06:34:26 Gathering batch of experience...
2017/08/26 06:34:40 batch 201: mean=14.195652 stddev=5.863000 entropy=1.136135 frames=36447 count=46
2017/08/26 06:34:40 Training policy...
2017/08/26 06:34:49 step 0: objective=0.035689197
2017/08/26 06:34:57 step 1: objective=0.035767734
2017/08/26 06:35:04 step 2: objective=0.035845578
2017/08/26 06:35:12 step 3: objective=0.03592398
2017/08/26 06:35:19 step 4: objective=0.035999935
2017/08/26 06:35:26 step 5: objective=0.03606883
2017/08/26 06:35:34 step 6: objective=0.036105584
2017/08/26 06:35:41 step 7: objective=0.036129512
2017/08/26 06:35:41 Training value function...
2017/08/26 06:35:44 step 0: mse=0.625572 step=0.100000
2017/08/26 06:35:47 step 1: mse=0.602563 step=0.100000
2017/08/26 06:35:49 step 2: mse=0.583654 step=0.100000
2017/08/26 06:35:51 step 3: mse=0.563703 step=0.100000
2017/08/26 06:35:54 step 4: mse=0.550146 step=0.100000
2017/08/26 06:35:56 step 5: mse=0.533004 step=0.100000
2017/08/26 06:35:59 step 6: mse=0.511368 step=0.100000
2017/08/26 06:36:01 step 7: mse=0.502892 step=0.100000
2017/08/26 06:36:01 Saving...
2017/08/26 06:36:01 Gathering batch of experience...
2017/08/26 06:36:15 batch 202: mean=12.313725 stddev=5.300722 entropy=1.138260 frames=35449 count=51
2017/08/26 06:36:15 Training policy...
2017/08/26 06:36:24 step 0: objective=0.03547218
2017/08/26 06:36:31 step 1: objective=0.035511944
2017/08/26 06:36:38 step 2: objective=0.035551533
2017/08/26 06:36:46 step 3: objective=0.03559096
2017/08/26 06:36:53 step 4: objective=0.035630196
2017/08/26 06:37:00 step 5: objective=0.03566757
2017/08/26 06:37:08 step 6: objective=0.03569383
2017/08/26 06:37:15 step 7: objective=0.03571955
2017/08/26 06:37:15 Training value function...
2017/08/26 06:37:18 step 0: mse=0.667633 step=0.100000
2017/08/26 06:37:20 step 1: mse=0.638854 step=0.100000
2017/08/26 06:37:22 step 2: mse=0.617561 step=0.100000
2017/08/26 06:37:24 step 3: mse=0.598730 step=0.100000
2017/08/26 06:37:27 step 4: mse=0.583874 step=0.100000
2017/08/26 06:37:29 step 5: mse=0.553963 step=0.100000
2017/08/26 06:37:31 step 6: mse=0.529706 step=0.100000
2017/08/26 06:37:33 step 7: mse=0.509727 step=0.100000
2017/08/26 06:37:33 Saving...
2017/08/26 06:37:34 Gathering batch of experience...
2017/08/26 06:37:48 batch 203: mean=12.076923 stddev=5.618808 entropy=1.132772 frames=35209 count=52
2017/08/26 06:37:48 Training policy...
2017/08/26 06:37:57 step 0: objective=0.024420021
2017/08/26 06:38:04 step 1: objective=0.024483267
2017/08/26 06:38:11 step 2: objective=0.024546282
2017/08/26 06:38:18 step 3: objective=0.024609078
2017/08/26 06:38:26 step 4: objective=0.024671642
2017/08/26 06:38:33 step 5: objective=0.02473078
2017/08/26 06:38:40 step 6: objective=0.024771351
2017/08/26 06:38:47 step 7: objective=0.024811333
2017/08/26 06:38:47 Training value function...
2017/08/26 06:38:50 step 0: mse=0.721853 step=0.100000
2017/08/26 06:38:52 step 1: mse=0.683274 step=0.100000
2017/08/26 06:38:55 step 2: mse=0.653046 step=0.100000
2017/08/26 06:38:57 step 3: mse=0.620886 step=0.100000
2017/08/26 06:38:59 step 4: mse=0.598203 step=0.100000
2017/08/26 06:39:01 step 5: mse=0.579698 step=0.100000
2017/08/26 06:39:04 step 6: mse=0.563774 step=0.100000
2017/08/26 06:39:06 step 7: mse=0.550882 step=0.100000
2017/08/26 06:39:06 Saving...
2017/08/26 06:39:06 Gathering batch of experience...
2017/08/26 06:39:20 batch 204: mean=13.040000 stddev=5.702491 entropy=1.137640 frames=35527 count=50
2017/08/26 06:39:20 Training policy...
2017/08/26 06:39:29 step 0: objective=0.026994511
2017/08/26 06:39:36 step 1: objective=0.027050916
2017/08/26 06:39:44 step 2: objective=0.02710765
2017/08/26 06:39:51 step 3: objective=0.027164942
2017/08/26 06:39:58 step 4: objective=0.02721607
2017/08/26 06:40:06 step 5: objective=0.027245296
2017/08/26 06:40:13 step 6: objective=0.02726956
2017/08/26 06:40:21 step 7: objective=0.027299643
2017/08/26 06:40:21 Training value function...
2017/08/26 06:40:23 step 0: mse=0.795495 step=0.100000
2017/08/26 06:40:26 step 1: mse=0.735367 step=0.100000
2017/08/26 06:40:28 step 2: mse=0.682596 step=0.100000
2017/08/26 06:40:30 step 3: mse=0.642553 step=0.100000
2017/08/26 06:40:33 step 4: mse=0.606804 step=0.100000
2017/08/26 06:40:35 step 5: mse=0.581111 step=0.100000
2017/08/26 06:40:37 step 6: mse=0.554379 step=0.100000
2017/08/26 06:40:40 step 7: mse=0.532596 step=0.100000
2017/08/26 06:40:40 Saving...
2017/08/26 06:40:40 Gathering batch of experience...
2017/08/26 06:40:54 batch 205: mean=12.740000 stddev=5.090422 entropy=1.146337 frames=36021 count=50
2017/08/26 06:40:54 Training policy...
2017/08/26 06:41:03 step 0: objective=0.030386906
2017/08/26 06:41:11 step 1: objective=0.030426485
2017/08/26 06:41:18 step 2: objective=0.030465933
2017/08/26 06:41:26 step 3: objective=0.030505374
2017/08/26 06:41:33 step 4: objective=0.030545132
2017/08/26 06:41:41 step 5: objective=0.030583993
2017/08/26 06:41:48 step 6: objective=0.030631026
2017/08/26 06:41:55 step 7: objective=0.030662367
2017/08/26 06:41:55 Training value function...
2017/08/26 06:41:58 step 0: mse=0.607444 step=0.100000
2017/08/26 06:42:01 step 1: mse=0.575996 step=0.100000
2017/08/26 06:42:03 step 2: mse=0.547386 step=0.100000
2017/08/26 06:42:05 step 3: mse=0.525988 step=0.100000
2017/08/26 06:42:08 step 4: mse=0.508012 step=0.100000
2017/08/26 06:42:10 step 5: mse=0.488110 step=0.100000
2017/08/26 06:42:12 step 6: mse=0.472057 step=0.100000
2017/08/26 06:42:14 step 7: mse=0.460021 step=0.100000
2017/08/26 06:42:14 Saving...
2017/08/26 06:42:15 Gathering batch of experience...
2017/08/26 06:42:29 batch 206: mean=11.780000 stddev=4.281542 entropy=1.134045 frames=35243 count=50
2017/08/26 06:42:29 Training policy...
2017/08/26 06:42:38 step 0: objective=-0.0032525093
2017/08/26 06:42:45 step 1: objective=-0.0032246416
2017/08/26 06:42:52 step 2: objective=-0.0031967578
2017/08/26 06:43:00 step 3: objective=-0.0031688537
2017/08/26 06:43:08 step 4: objective=-0.003140922
2017/08/26 06:43:15 step 5: objective=-0.0031129918
2017/08/26 06:43:22 step 6: objective=-0.0030850053
2017/08/26 06:43:29 step 7: objective=-0.003057378
2017/08/26 06:43:29 Training value function...
2017/08/26 06:43:32 step 0: mse=0.572433 step=0.100000
2017/08/26 06:43:35 step 1: mse=0.516676 step=0.100000
2017/08/26 06:43:37 step 2: mse=0.471082 step=0.100000
2017/08/26 06:43:39 step 3: mse=0.436279 step=0.100000
2017/08/26 06:43:41 step 4: mse=0.407346 step=0.100000
2017/08/26 06:43:44 step 5: mse=0.382843 step=0.100000
2017/08/26 06:43:46 step 6: mse=0.364742 step=0.100000
2017/08/26 06:43:48 step 7: mse=0.349335 step=0.100000
2017/08/26 06:43:48 Saving...
2017/08/26 06:43:48 Gathering batch of experience...
2017/08/26 06:44:03 batch 207: mean=14.065217 stddev=5.462927 entropy=1.128813 frames=35686 count=46
2017/08/26 06:44:03 Training policy...
2017/08/26 06:44:12 step 0: objective=0.029596431
2017/08/26 06:44:19 step 1: objective=0.029641738
2017/08/26 06:44:26 step 2: objective=0.029686898
2017/08/26 06:44:34 step 3: objective=0.029731896
2017/08/26 06:44:41 step 4: objective=0.029776659
2017/08/26 06:44:49 step 5: objective=0.02982084
2017/08/26 06:44:56 step 6: objective=0.029859317
2017/08/26 06:45:04 step 7: objective=0.029896017
2017/08/26 06:45:04 Training value function...
2017/08/26 06:45:06 step 0: mse=0.633605 step=0.100000
2017/08/26 06:45:09 step 1: mse=0.603429 step=0.100000
2017/08/26 06:45:11 step 2: mse=0.579106 step=0.100000
2017/08/26 06:45:13 step 3: mse=0.557962 step=0.100000
2017/08/26 06:45:16 step 4: mse=0.537888 step=0.100000
2017/08/26 06:45:18 step 5: mse=0.517515 step=0.100000
2017/08/26 06:45:20 step 6: mse=0.504285 step=0.100000
2017/08/26 06:45:23 step 7: mse=0.488433 step=0.100000
2017/08/26 06:45:23 Saving...
2017/08/26 06:45:23 Gathering batch of experience...
2017/08/26 06:45:37 batch 208: mean=13.854167 stddev=6.027678 entropy=1.143214 frames=35827 count=48
2017/08/26 06:45:37 Training policy...
2017/08/26 06:45:46 step 0: objective=0.04343329
2017/08/26 06:45:54 step 1: objective=0.043475464
2017/08/26 06:46:01 step 2: objective=0.043518405
2017/08/26 06:46:09 step 3: objective=0.043561753
2017/08/26 06:46:16 step 4: objective=0.043604452
2017/08/26 06:46:23 step 5: objective=0.043633685
2017/08/26 06:46:31 step 6: objective=0.043683723
2017/08/26 06:46:39 step 7: objective=0.043711063
2017/08/26 06:46:39 Training value function...
2017/08/26 06:46:41 step 0: mse=0.857913 step=0.100000
2017/08/26 06:46:44 step 1: mse=0.802609 step=0.100000
2017/08/26 06:46:46 step 2: mse=0.752136 step=0.100000
2017/08/26 06:46:48 step 3: mse=0.717090 step=0.100000
2017/08/26 06:46:51 step 4: mse=0.682707 step=0.100000
2017/08/26 06:46:53 step 5: mse=0.652479 step=0.100000
2017/08/26 06:46:55 step 6: mse=0.622616 step=0.100000
2017/08/26 06:46:58 step 7: mse=0.598853 step=0.100000
2017/08/26 06:46:58 Saving...
2017/08/26 06:46:58 Gathering batch of experience...
2017/08/26 06:47:12 batch 209: mean=11.875000 stddev=4.191385 entropy=1.133276 frames=35140 count=48
2017/08/26 06:47:12 Training policy...
2017/08/26 06:47:21 step 0: objective=-0.0061470107
2017/08/26 06:47:28 step 1: objective=-0.006107473
2017/08/26 06:47:36 step 2: objective=-0.0060679712
2017/08/26 06:47:43 step 3: objective=-0.006028443
2017/08/26 06:47:50 step 4: objective=-0.005988905
2017/08/26 06:47:58 step 5: objective=-0.005949344
2017/08/26 06:48:05 step 6: objective=-0.005910297
2017/08/26 06:48:13 step 7: objective=-0.0058789086
2017/08/26 06:48:13 Training value function...
2017/08/26 06:48:15 step 0: mse=0.457354 step=0.100000
2017/08/26 06:48:17 step 1: mse=0.432929 step=0.100000
2017/08/26 06:48:20 step 2: mse=0.413815 step=0.100000
2017/08/26 06:48:22 step 3: mse=0.387971 step=0.100000
2017/08/26 06:48:24 step 4: mse=0.367463 step=0.100000
2017/08/26 06:48:26 step 5: mse=0.345045 step=0.100000
2017/08/26 06:48:28 step 6: mse=0.336338 step=0.100000
2017/08/26 06:48:31 step 7: mse=0.320650 step=0.100000
2017/08/26 06:48:31 Saving...
2017/08/26 06:48:31 Gathering batch of experience...
2017/08/26 06:48:45 batch 210: mean=14.437500 stddev=6.167476 entropy=1.129446 frames=36158 count=48
2017/08/26 06:48:45 Training policy...
2017/08/26 06:48:55 step 0: objective=0.07425608
2017/08/26 06:49:02 step 1: objective=0.074308254
2017/08/26 06:49:10 step 2: objective=0.07436101
2017/08/26 06:49:17 step 3: objective=0.07441298
2017/08/26 06:49:25 step 4: objective=0.07446602
2017/08/26 06:49:32 step 5: objective=0.07451619
2017/08/26 06:49:40 step 6: objective=0.07454953
2017/08/26 06:49:48 step 7: objective=0.07458752
2017/08/26 06:49:48 Training value function...
2017/08/26 06:49:50 step 0: mse=1.112119 step=0.100000
2017/08/26 06:49:53 step 1: mse=1.029972 step=0.100000
2017/08/26 06:49:55 step 2: mse=0.953320 step=0.100000
2017/08/26 06:49:57 step 3: mse=0.897176 step=0.100000
2017/08/26 06:50:00 step 4: mse=0.842763 step=0.100000
2017/08/26 06:50:02 step 5: mse=0.802161 step=0.100000
2017/08/26 06:50:04 step 6: mse=0.760252 step=0.100000
2017/08/26 06:50:07 step 7: mse=0.732542 step=0.100000
2017/08/26 06:50:07 Saving...
2017/08/26 06:50:07 Gathering batch of experience...
2017/08/26 06:50:21 batch 211: mean=12.895833 stddev=4.477907 entropy=1.138170 frames=35500 count=48
2017/08/26 06:50:21 Training policy...
2017/08/26 06:50:30 step 0: objective=0.012405363
2017/08/26 06:50:37 step 1: objective=0.0124320695
2017/08/26 06:50:45 step 2: objective=0.012458649
2017/08/26 06:50:52 step 3: objective=0.012485273
2017/08/26 06:51:00 step 4: objective=0.012511747
2017/08/26 06:51:07 step 5: objective=0.012538276
2017/08/26 06:51:15 step 6: objective=0.012564775
2017/08/26 06:51:22 step 7: objective=0.01259075
2017/08/26 06:51:22 Training value function...
2017/08/26 06:51:25 step 0: mse=0.570053 step=0.100000
2017/08/26 06:51:27 step 1: mse=0.537877 step=0.100000
2017/08/26 06:51:30 step 2: mse=0.513153 step=0.100000
2017/08/26 06:51:32 step 3: mse=0.494413 step=0.100000
2017/08/26 06:51:34 step 4: mse=0.479597 step=0.100000
2017/08/26 06:51:36 step 5: mse=0.461748 step=0.100000
2017/08/26 06:51:39 step 6: mse=0.449472 step=0.100000
2017/08/26 06:51:41 step 7: mse=0.434235 step=0.100000
2017/08/26 06:51:41 Saving...
2017/08/26 06:51:41 Gathering batch of experience...
2017/08/26 06:51:55 batch 212: mean=12.557692 stddev=5.765993 entropy=1.137252 frames=36008 count=52
2017/08/26 06:51:55 Training policy...
2017/08/26 06:52:05 step 0: objective=0.033534054
2017/08/26 06:52:12 step 1: objective=0.033573966
2017/08/26 06:52:20 step 2: objective=0.033613585
2017/08/26 06:52:27 step 3: objective=0.033653226
2017/08/26 06:52:35 step 4: objective=0.033693157
2017/08/26 06:52:43 step 5: objective=0.03373161
2017/08/26 06:52:51 step 6: objective=0.03375829
2017/08/26 06:52:58 step 7: objective=0.03378204
2017/08/26 06:52:58 Training value function...
2017/08/26 06:53:01 step 0: mse=0.903263 step=0.100000
2017/08/26 06:53:03 step 1: mse=0.836735 step=0.100000
2017/08/26 06:53:06 step 2: mse=0.783119 step=0.100000
2017/08/26 06:53:08 step 3: mse=0.740047 step=0.100000
2017/08/26 06:53:10 step 4: mse=0.701970 step=0.100000
2017/08/26 06:53:12 step 5: mse=0.675085 step=0.100000
2017/08/26 06:53:15 step 6: mse=0.647051 step=0.100000
2017/08/26 06:53:17 step 7: mse=0.627214 step=0.100000
2017/08/26 06:53:17 Saving...
2017/08/26 06:53:17 Gathering batch of experience...
2017/08/26 06:53:31 batch 213: mean=14.304348 stddev=5.535928 entropy=1.137210 frames=35185 count=46
2017/08/26 06:53:31 Training policy...
2017/08/26 06:53:40 step 0: objective=0.04581842
2017/08/26 06:53:48 step 1: objective=0.045885365
2017/08/26 06:53:55 step 2: objective=0.045952894
2017/08/26 06:54:03 step 3: objective=0.046020713
2017/08/26 06:54:10 step 4: objective=0.046086874
2017/08/26 06:54:17 step 5: objective=0.04613713
2017/08/26 06:54:25 step 6: objective=0.046175502
2017/08/26 06:54:32 step 7: objective=0.046240915
2017/08/26 06:54:32 Training value function...
2017/08/26 06:54:35 step 0: mse=0.861679 step=0.100000
2017/08/26 06:54:37 step 1: mse=0.803223 step=0.100000
2017/08/26 06:54:40 step 2: mse=0.748721 step=0.100000
2017/08/26 06:54:42 step 3: mse=0.704791 step=0.100000
2017/08/26 06:54:44 step 4: mse=0.673214 step=0.100000
2017/08/26 06:54:46 step 5: mse=0.637414 step=0.100000
2017/08/26 06:54:49 step 6: mse=0.611465 step=0.100000
2017/08/26 06:54:51 step 7: mse=0.575555 step=0.100000
2017/08/26 06:54:51 Saving...
2017/08/26 06:54:51 Gathering batch of experience...
2017/08/26 06:55:05 batch 214: mean=14.456522 stddev=6.278696 entropy=1.124332 frames=36161 count=46
2017/08/26 06:55:05 Training policy...
2017/08/26 06:55:15 step 0: objective=0.02795993
2017/08/26 06:55:23 step 1: objective=0.028019205
2017/08/26 06:55:30 step 2: objective=0.028078536
2017/08/26 06:55:38 step 3: objective=0.0281379
2017/08/26 06:55:46 step 4: objective=0.028197298
2017/08/26 06:55:54 step 5: objective=0.028251424
2017/08/26 06:56:02 step 6: objective=0.028303497
2017/08/26 06:56:10 step 7: objective=0.028352503
2017/08/26 06:56:10 Training value function...
2017/08/26 06:56:12 step 0: mse=0.816907 step=0.100000
2017/08/26 06:56:15 step 1: mse=0.760218 step=0.100000
2017/08/26 06:56:17 step 2: mse=0.716057 step=0.100000
2017/08/26 06:56:19 step 3: mse=0.680152 step=0.100000
2017/08/26 06:56:22 step 4: mse=0.647893 step=0.100000
2017/08/26 06:56:24 step 5: mse=0.618064 step=0.100000
2017/08/26 06:56:26 step 6: mse=0.588673 step=0.100000
2017/08/26 06:56:28 step 7: mse=0.568980 step=0.100000
2017/08/26 06:56:28 Saving...
2017/08/26 06:56:29 Gathering batch of experience...
2017/08/26 06:56:43 batch 215: mean=14.085106 stddev=5.812056 entropy=1.123701 frames=35763 count=47
2017/08/26 06:56:43 Training policy...
2017/08/26 06:56:52 step 0: objective=0.024828933
2017/08/26 06:57:00 step 1: objective=0.024881806
2017/08/26 06:57:08 step 2: objective=0.02493409
2017/08/26 06:57:15 step 3: objective=0.02498605
2017/08/26 06:57:23 step 4: objective=0.025037695
2017/08/26 06:57:30 step 5: objective=0.025087716
2017/08/26 06:57:38 step 6: objective=0.025110122
2017/08/26 06:57:46 step 7: objective=0.025130605
2017/08/26 06:57:46 Training value function...
2017/08/26 06:57:48 step 0: mse=0.709342 step=0.100000
2017/08/26 06:57:51 step 1: mse=0.675202 step=0.100000
2017/08/26 06:57:53 step 2: mse=0.646962 step=0.100000
2017/08/26 06:57:55 step 3: mse=0.611759 step=0.100000
2017/08/26 06:57:58 step 4: mse=0.579828 step=0.100000
2017/08/26 06:58:00 step 5: mse=0.561771 step=0.100000
2017/08/26 06:58:02 step 6: mse=0.537614 step=0.100000
2017/08/26 06:58:04 step 7: mse=0.524749 step=0.100000
2017/08/26 06:58:04 Saving...
2017/08/26 06:58:05 Gathering batch of experience...
2017/08/26 06:58:19 batch 216: mean=13.510204 stddev=5.599280 entropy=1.137079 frames=36216 count=49
2017/08/26 06:58:19 Training policy...
2017/08/26 06:58:29 step 0: objective=0.03243373
2017/08/26 06:58:36 step 1: objective=0.032469463
2017/08/26 06:58:44 step 2: objective=0.03250482
2017/08/26 06:58:52 step 3: objective=0.032540794
2017/08/26 06:59:00 step 4: objective=0.032576703
2017/08/26 06:59:07 step 5: objective=0.03261249
2017/08/26 06:59:15 step 6: objective=0.032648604
2017/08/26 06:59:23 step 7: objective=0.032678384
2017/08/26 06:59:23 Training value function...
2017/08/26 06:59:26 step 0: mse=0.709184 step=0.100000
2017/08/26 06:59:28 step 1: mse=0.677631 step=0.100000
2017/08/26 06:59:30 step 2: mse=0.651910 step=0.100000
2017/08/26 06:59:33 step 3: mse=0.628980 step=0.100000
2017/08/26 06:59:35 step 4: mse=0.600168 step=0.100000
2017/08/26 06:59:37 step 5: mse=0.575414 step=0.100000
2017/08/26 06:59:39 step 6: mse=0.559130 step=0.100000
2017/08/26 06:59:42 step 7: mse=0.541371 step=0.100000
2017/08/26 06:59:42 Saving...
2017/08/26 06:59:42 Gathering batch of experience...
2017/08/26 06:59:56 batch 217: mean=12.600000 stddev=5.047772 entropy=1.137781 frames=35625 count=50
2017/08/26 06:59:56 Training policy...
2017/08/26 07:00:05 step 0: objective=0.010322488
2017/08/26 07:00:13 step 1: objective=0.010367714
2017/08/26 07:00:21 step 2: objective=0.01040778
2017/08/26 07:00:29 step 3: objective=0.010445189
2017/08/26 07:00:36 step 4: objective=0.010480573
2017/08/26 07:00:44 step 5: objective=0.010515881
2017/08/26 07:00:52 step 6: objective=0.010551282
2017/08/26 07:00:59 step 7: objective=0.010588524
2017/08/26 07:00:59 Training value function...
2017/08/26 07:01:02 step 0: mse=0.568009 step=0.100000
2017/08/26 07:01:05 step 1: mse=0.547999 step=0.100000
2017/08/26 07:01:07 step 2: mse=0.528040 step=0.100000
2017/08/26 07:01:09 step 3: mse=0.513993 step=0.100000
2017/08/26 07:01:11 step 4: mse=0.502862 step=0.100000
2017/08/26 07:01:14 step 5: mse=0.486137 step=0.100000
2017/08/26 07:01:16 step 6: mse=0.478196 step=0.100000
2017/08/26 07:01:18 step 7: mse=0.461606 step=0.100000
2017/08/26 07:01:18 Saving...
2017/08/26 07:01:18 Gathering batch of experience...
2017/08/26 07:01:33 batch 218: mean=13.041667 stddev=4.730038 entropy=1.138714 frames=35638 count=48
2017/08/26 07:01:33 Training policy...
2017/08/26 07:01:42 step 0: objective=0.028026205
2017/08/26 07:01:50 step 1: objective=0.028063836
2017/08/26 07:01:57 step 2: objective=0.028101528
2017/08/26 07:02:05 step 3: objective=0.028139424
2017/08/26 07:02:13 step 4: objective=0.028177321
2017/08/26 07:02:21 step 5: objective=0.028214734
2017/08/26 07:02:28 step 6: objective=0.028246026
2017/08/26 07:02:36 step 7: objective=0.028321989
2017/08/26 07:02:36 Training value function...
2017/08/26 07:02:39 step 0: mse=0.489006 step=0.100000
2017/08/26 07:02:41 step 1: mse=0.461155 step=0.100000
2017/08/26 07:02:43 step 2: mse=0.440011 step=0.100000
2017/08/26 07:02:46 step 3: mse=0.428036 step=0.100000
2017/08/26 07:02:48 step 4: mse=0.416032 step=0.100000
2017/08/26 07:02:50 step 5: mse=0.405711 step=0.100000
2017/08/26 07:02:53 step 6: mse=0.398201 step=0.100000
2017/08/26 07:02:55 step 7: mse=0.390679 step=0.100000
2017/08/26 07:02:55 Saving...
2017/08/26 07:02:55 Gathering batch of experience...
2017/08/26 07:03:09 batch 219: mean=13.591837 stddev=7.700831 entropy=1.131300 frames=35670 count=49
2017/08/26 07:03:09 Training policy...
2017/08/26 07:03:19 step 0: objective=0.049602326
2017/08/26 07:03:26 step 1: objective=0.049672805
2017/08/26 07:03:34 step 2: objective=0.049743745
2017/08/26 07:03:42 step 3: objective=0.04981549
2017/08/26 07:03:49 step 4: objective=0.04986758
2017/08/26 07:03:57 step 5: objective=0.04990821
2017/08/26 07:04:05 step 6: objective=0.049961768
2017/08/26 07:04:13 step 7: objective=0.05001275
2017/08/26 07:04:13 Training value function...
2017/08/26 07:04:16 step 0: mse=1.241089 step=0.100000
2017/08/26 07:04:18 step 1: mse=1.128199 step=0.100000
2017/08/26 07:04:20 step 2: mse=1.033880 step=0.100000
2017/08/26 07:04:22 step 3: mse=0.953921 step=0.100000
2017/08/26 07:04:25 step 4: mse=0.889537 step=0.100000
2017/08/26 07:04:27 step 5: mse=0.834103 step=0.100000
2017/08/26 07:04:29 step 6: mse=0.789808 step=0.100000
2017/08/26 07:04:32 step 7: mse=0.750435 step=0.100000
2017/08/26 07:04:32 Saving...
2017/08/26 07:04:32 Gathering batch of experience...
2017/08/26 07:04:46 batch 220: mean=13.872340 stddev=5.552906 entropy=1.132352 frames=34816 count=47
2017/08/26 07:04:46 Training policy...
2017/08/26 07:04:55 step 0: objective=0.04118991
2017/08/26 07:05:03 step 1: objective=0.04124395
2017/08/26 07:05:10 step 2: objective=0.041298006
2017/08/26 07:05:18 step 3: objective=0.04135211
2017/08/26 07:05:25 step 4: objective=0.041404586
2017/08/26 07:05:33 step 5: objective=0.041437455
2017/08/26 07:05:40 step 6: objective=0.0414826
2017/08/26 07:05:48 step 7: objective=0.04153201
2017/08/26 07:05:48 Training value function...
2017/08/26 07:05:50 step 0: mse=0.801864 step=0.100000
2017/08/26 07:05:53 step 1: mse=0.765550 step=0.100000
2017/08/26 07:05:55 step 2: mse=0.736019 step=0.100000
2017/08/26 07:05:57 step 3: mse=0.708207 step=0.100000
2017/08/26 07:05:59 step 4: mse=0.687074 step=0.100000
2017/08/26 07:06:02 step 5: mse=0.669389 step=0.100000
2017/08/26 07:06:04 step 6: mse=0.651120 step=0.100000
2017/08/26 07:06:06 step 7: mse=0.635920 step=0.100000
2017/08/26 07:06:06 Saving...
2017/08/26 07:06:06 Gathering batch of experience...
2017/08/26 07:06:20 batch 221: mean=13.270833 stddev=5.134603 entropy=1.129443 frames=35638 count=48
2017/08/26 07:06:20 Training policy...
2017/08/26 07:06:30 step 0: objective=0.023736842
2017/08/26 07:06:38 step 1: objective=0.023787405
2017/08/26 07:06:46 step 2: objective=0.023838362
2017/08/26 07:06:53 step 3: objective=0.023888715
2017/08/26 07:07:01 step 4: objective=0.023919906
2017/08/26 07:07:09 step 5: objective=0.023947643
2017/08/26 07:07:17 step 6: objective=0.02398936
2017/08/26 07:07:24 step 7: objective=0.024030322
2017/08/26 07:07:24 Training value function...
2017/08/26 07:07:27 step 0: mse=0.639954 step=0.100000
2017/08/26 07:07:29 step 1: mse=0.608545 step=0.100000
2017/08/26 07:07:32 step 2: mse=0.582896 step=0.100000
2017/08/26 07:07:34 step 3: mse=0.561721 step=0.100000
2017/08/26 07:07:36 step 4: mse=0.544158 step=0.100000
2017/08/26 07:07:38 step 5: mse=0.528856 step=0.100000
2017/08/26 07:07:41 step 6: mse=0.510103 step=0.100000
2017/08/26 07:07:43 step 7: mse=0.492668 step=0.100000
2017/08/26 07:07:43 Saving...
2017/08/26 07:07:43 Gathering batch of experience...
2017/08/26 07:07:58 batch 222: mean=12.826923 stddev=5.608102 entropy=1.131819 frames=36697 count=52
2017/08/26 07:07:58 Training policy...
2017/08/26 07:08:07 step 0: objective=0.028194008
2017/08/26 07:08:15 step 1: objective=0.028233482
2017/08/26 07:08:23 step 2: objective=0.028272867
2017/08/26 07:08:32 step 3: objective=0.028312195
2017/08/26 07:08:40 step 4: objective=0.028351272
2017/08/26 07:08:48 step 5: objective=0.028390374
2017/08/26 07:08:56 step 6: objective=0.02842781
2017/08/26 07:09:04 step 7: objective=0.028485121
2017/08/26 07:09:04 Training value function...
2017/08/26 07:09:06 step 0: mse=0.762196 step=0.100000
2017/08/26 07:09:09 step 1: mse=0.708822 step=0.100000
2017/08/26 07:09:11 step 2: mse=0.667180 step=0.100000
2017/08/26 07:09:13 step 3: mse=0.642538 step=0.100000
2017/08/26 07:09:16 step 4: mse=0.612467 step=0.100000
2017/08/26 07:09:18 step 5: mse=0.591235 step=0.100000
2017/08/26 07:09:20 step 6: mse=0.567975 step=0.100000
2017/08/26 07:09:23 step 7: mse=0.552747 step=0.100000
2017/08/26 07:09:23 Saving...
2017/08/26 07:09:23 Gathering batch of experience...
2017/08/26 07:09:37 batch 223: mean=13.125000 stddev=5.010926 entropy=1.131822 frames=35546 count=48
2017/08/26 07:09:37 Training policy...
2017/08/26 07:09:47 step 0: objective=0.027093057
2017/08/26 07:09:54 step 1: objective=0.02713183
2017/08/26 07:10:02 step 2: objective=0.02717024
2017/08/26 07:10:10 step 3: objective=0.027208485
2017/08/26 07:10:18 step 4: objective=0.027246516
2017/08/26 07:10:25 step 5: objective=0.027284265
2017/08/26 07:10:33 step 6: objective=0.027303176
2017/08/26 07:10:41 step 7: objective=0.027321715
2017/08/26 07:10:41 Training value function...
2017/08/26 07:10:44 step 0: mse=0.583441 step=0.100000
2017/08/26 07:10:46 step 1: mse=0.553207 step=0.100000
2017/08/26 07:10:48 step 2: mse=0.528957 step=0.100000
2017/08/26 07:10:50 step 3: mse=0.507450 step=0.100000
2017/08/26 07:10:53 step 4: mse=0.489762 step=0.100000
2017/08/26 07:10:55 step 5: mse=0.476000 step=0.100000
2017/08/26 07:10:57 step 6: mse=0.465475 step=0.100000
2017/08/26 07:10:59 step 7: mse=0.448210 step=0.100000
2017/08/26 07:10:59 Saving...
2017/08/26 07:10:59 Gathering batch of experience...
2017/08/26 07:11:14 batch 224: mean=12.440000 stddev=4.725082 entropy=1.133849 frames=35737 count=50
2017/08/26 07:11:14 Training policy...
2017/08/26 07:11:23 step 0: objective=0.02304913
2017/08/26 07:11:31 step 1: objective=0.02307073
2017/08/26 07:11:40 step 2: objective=0.0230925
2017/08/26 07:11:47 step 3: objective=0.023114234
2017/08/26 07:11:55 step 4: objective=0.023136066
2017/08/26 07:12:03 step 5: objective=0.023157867
2017/08/26 07:12:11 step 6: objective=0.023179527
2017/08/26 07:12:19 step 7: objective=0.023200082
2017/08/26 07:12:19 Training value function...
2017/08/26 07:12:21 step 0: mse=0.564911 step=0.100000
2017/08/26 07:12:24 step 1: mse=0.537331 step=0.100000
2017/08/26 07:12:26 step 2: mse=0.514854 step=0.100000
2017/08/26 07:12:28 step 3: mse=0.494020 step=0.100000
2017/08/26 07:12:30 step 4: mse=0.477287 step=0.100000
2017/08/26 07:12:33 step 5: mse=0.463705 step=0.100000
2017/08/26 07:12:35 step 6: mse=0.447100 step=0.100000
2017/08/26 07:12:37 step 7: mse=0.437403 step=0.100000
2017/08/26 07:12:37 Saving...
2017/08/26 07:12:37 Gathering batch of experience...
2017/08/26 07:12:51 batch 225: mean=14.239130 stddev=4.741972 entropy=1.126620 frames=34940 count=46
2017/08/26 07:12:51 Training policy...
2017/08/26 07:13:01 step 0: objective=0.041158244
2017/08/26 07:13:08 step 1: objective=0.041209444
2017/08/26 07:13:16 step 2: objective=0.0412607
2017/08/26 07:13:24 step 3: objective=0.041312005
2017/08/26 07:13:31 step 4: objective=0.041360617
2017/08/26 07:13:39 step 5: objective=0.041391723
2017/08/26 07:13:47 step 6: objective=0.04142149
2017/08/26 07:13:54 step 7: objective=0.041478183
2017/08/26 07:13:54 Training value function...
2017/08/26 07:13:57 step 0: mse=0.656854 step=0.100000
2017/08/26 07:13:59 step 1: mse=0.634678 step=0.100000
2017/08/26 07:14:02 step 2: mse=0.608587 step=0.100000
2017/08/26 07:14:04 step 3: mse=0.596930 step=0.100000
2017/08/26 07:14:06 step 4: mse=0.586165 step=0.100000
2017/08/26 07:14:08 step 5: mse=0.566586 step=0.100000
2017/08/26 07:14:10 step 6: mse=0.554200 step=0.100000
2017/08/26 07:14:13 step 7: mse=0.544908 step=0.100000
2017/08/26 07:14:13 Saving...
2017/08/26 07:14:13 Gathering batch of experience...
2017/08/26 07:14:27 batch 226: mean=14.319149 stddev=6.607882 entropy=1.128847 frames=34918 count=47
2017/08/26 07:14:27 Training policy...
2017/08/26 07:14:36 step 0: objective=0.04417656
2017/08/26 07:14:44 step 1: objective=0.044210963
2017/08/26 07:14:52 step 2: objective=0.04424535
2017/08/26 07:15:00 step 3: objective=0.044279903
2017/08/26 07:15:07 step 4: objective=0.044314697
2017/08/26 07:15:15 step 5: objective=0.044349413
2017/08/26 07:15:23 step 6: objective=0.044383835
2017/08/26 07:15:31 step 7: objective=0.044419188
2017/08/26 07:15:31 Training value function...
2017/08/26 07:15:33 step 0: mse=1.163531 step=0.100000
2017/08/26 07:15:36 step 1: mse=1.071378 step=0.100000
2017/08/26 07:15:38 step 2: mse=0.997213 step=0.100000
2017/08/26 07:15:40 step 3: mse=0.937021 step=0.100000
2017/08/26 07:15:43 step 4: mse=0.887776 step=0.100000
2017/08/26 07:15:45 step 5: mse=0.847395 step=0.100000
2017/08/26 07:15:47 step 6: mse=0.804720 step=0.100000
2017/08/26 07:15:49 step 7: mse=0.772800 step=0.100000
2017/08/26 07:15:49 Saving...
2017/08/26 07:15:49 Gathering batch of experience...
2017/08/26 07:16:04 batch 227: mean=13.770833 stddev=5.063100 entropy=1.139533 frames=35479 count=48
2017/08/26 07:16:04 Training policy...
2017/08/26 07:16:13 step 0: objective=0.03072165
2017/08/26 07:16:21 step 1: objective=0.030753985
2017/08/26 07:16:29 step 2: objective=0.030786451
2017/08/26 07:16:37 step 3: objective=0.030818414
2017/08/26 07:16:45 step 4: objective=0.030850329
2017/08/26 07:16:53 step 5: objective=0.030882027
2017/08/26 07:17:01 step 6: objective=0.030912872
2017/08/26 07:17:09 step 7: objective=0.030937845
2017/08/26 07:17:09 Training value function...
2017/08/26 07:17:12 step 0: mse=0.693288 step=0.100000
2017/08/26 07:17:14 step 1: mse=0.654011 step=0.100000
2017/08/26 07:17:16 step 2: mse=0.620968 step=0.100000
2017/08/26 07:17:18 step 3: mse=0.594254 step=0.100000
2017/08/26 07:17:20 step 4: mse=0.568722 step=0.100000
2017/08/26 07:17:23 step 5: mse=0.546024 step=0.100000
2017/08/26 07:17:25 step 6: mse=0.530246 step=0.100000
2017/08/26 07:17:27 step 7: mse=0.522073 step=0.100000
2017/08/26 07:17:27 Saving...
2017/08/26 07:17:27 Gathering batch of experience...
2017/08/26 07:17:42 batch 228: mean=13.404255 stddev=5.286110 entropy=1.124082 frames=35512 count=47
2017/08/26 07:17:42 Training policy...
2017/08/26 07:17:51 step 0: objective=0.0062362268
2017/08/26 07:17:59 step 1: objective=0.006275999
2017/08/26 07:18:07 step 2: objective=0.006315914
2017/08/26 07:18:14 step 3: objective=0.00635592
2017/08/26 07:18:22 step 4: objective=0.0063961316
2017/08/26 07:18:30 step 5: objective=0.0064278636
2017/08/26 07:18:38 step 6: objective=0.006452715
2017/08/26 07:18:46 step 7: objective=0.0065029524
2017/08/26 07:18:46 Training value function...
2017/08/26 07:18:49 step 0: mse=0.646507 step=0.100000
2017/08/26 07:18:51 step 1: mse=0.605900 step=0.100000
2017/08/26 07:18:53 step 2: mse=0.573504 step=0.100000
2017/08/26 07:18:55 step 3: mse=0.547438 step=0.100000
2017/08/26 07:18:58 step 4: mse=0.525637 step=0.100000
2017/08/26 07:19:00 step 5: mse=0.507410 step=0.100000
2017/08/26 07:19:02 step 6: mse=0.492365 step=0.100000
2017/08/26 07:19:04 step 7: mse=0.471192 step=0.100000
2017/08/26 07:19:04 Saving...
2017/08/26 07:19:04 Gathering batch of experience...
2017/08/26 07:19:20 batch 229: mean=12.882353 stddev=5.508094 entropy=1.128296 frames=37216 count=51
2017/08/26 07:19:20 Training policy...
2017/08/26 07:19:29 step 0: objective=0.014629918
2017/08/26 07:19:38 step 1: objective=0.014661524
2017/08/26 07:19:47 step 2: objective=0.014692977
2017/08/26 07:19:55 step 3: objective=0.014724233
2017/08/26 07:20:03 step 4: objective=0.01475521
2017/08/26 07:20:11 step 5: objective=0.0147833675
2017/08/26 07:20:20 step 6: objective=0.014806895
2017/08/26 07:20:28 step 7: objective=0.014834922
2017/08/26 07:20:28 Training value function...
2017/08/26 07:20:31 step 0: mse=0.612739 step=0.100000
2017/08/26 07:20:34 step 1: mse=0.579749 step=0.100000
2017/08/26 07:20:36 step 2: mse=0.553540 step=0.100000
2017/08/26 07:20:38 step 3: mse=0.530642 step=0.100000
2017/08/26 07:20:41 step 4: mse=0.512488 step=0.100000
2017/08/26 07:20:43 step 5: mse=0.498940 step=0.100000
2017/08/26 07:20:46 step 6: mse=0.484526 step=0.100000
2017/08/26 07:20:48 step 7: mse=0.474145 step=0.100000
2017/08/26 07:20:48 Saving...
2017/08/26 07:20:48 Gathering batch of experience...
2017/08/26 07:21:02 batch 230: mean=14.086957 stddev=6.459998 entropy=1.123759 frames=34527 count=46
2017/08/26 07:21:02 Training policy...
2017/08/26 07:21:11 step 0: objective=0.051387683
2017/08/26 07:21:19 step 1: objective=0.051458117
2017/08/26 07:21:26 step 2: objective=0.05152955
2017/08/26 07:21:34 step 3: objective=0.051599856
2017/08/26 07:21:42 step 4: objective=0.05161895
2017/08/26 07:21:49 step 5: objective=0.051692475
2017/08/26 07:21:57 step 6: objective=0.0517355
2017/08/26 07:22:05 step 7: objective=0.051753793
2017/08/26 07:22:05 Training value function...
2017/08/26 07:22:07 step 0: mse=0.825369 step=0.100000
2017/08/26 07:22:10 step 1: mse=0.773369 step=0.100000
2017/08/26 07:22:12 step 2: mse=0.724463 step=0.100000
2017/08/26 07:22:14 step 3: mse=0.684231 step=0.100000
2017/08/26 07:22:16 step 4: mse=0.651549 step=0.100000
2017/08/26 07:22:18 step 5: mse=0.619385 step=0.100000
2017/08/26 07:22:21 step 6: mse=0.591555 step=0.100000
2017/08/26 07:22:23 step 7: mse=0.569649 step=0.100000
2017/08/26 07:22:23 Saving...
2017/08/26 07:22:23 Gathering batch of experience...
2017/08/26 07:22:38 batch 231: mean=13.625000 stddev=5.142247 entropy=1.125698 frames=36405 count=48
2017/08/26 07:22:38 Training policy...
2017/08/26 07:22:48 step 0: objective=0.032551486
2017/08/26 07:22:56 step 1: objective=0.032586683
2017/08/26 07:23:04 step 2: objective=0.032621685
2017/08/26 07:23:12 step 3: objective=0.032656793
2017/08/26 07:23:20 step 4: objective=0.032692056
2017/08/26 07:23:29 step 5: objective=0.032727115
2017/08/26 07:23:37 step 6: objective=0.03276087
2017/08/26 07:23:45 step 7: objective=0.03278883
2017/08/26 07:23:45 Training value function...
2017/08/26 07:23:48 step 0: mse=0.610684 step=0.100000
2017/08/26 07:23:50 step 1: mse=0.588604 step=0.100000
2017/08/26 07:23:52 step 2: mse=0.570932 step=0.100000
2017/08/26 07:23:55 step 3: mse=0.557110 step=0.100000
2017/08/26 07:23:57 step 4: mse=0.543459 step=0.100000
2017/08/26 07:23:59 step 5: mse=0.532956 step=0.100000
2017/08/26 07:24:02 step 6: mse=0.519958 step=0.100000
2017/08/26 07:24:04 step 7: mse=0.512337 step=0.100000
2017/08/26 07:24:04 Saving...
2017/08/26 07:24:04 Gathering batch of experience...
2017/08/26 07:24:19 batch 232: mean=13.122449 stddev=4.153350 entropy=1.126155 frames=36158 count=49
2017/08/26 07:24:19 Training policy...
2017/08/26 07:24:28 step 0: objective=0.01743742
2017/08/26 07:24:36 step 1: objective=0.017484335
2017/08/26 07:24:44 step 2: objective=0.01753127
2017/08/26 07:24:53 step 3: objective=0.017578062
2017/08/26 07:25:01 step 4: objective=0.017625025
2017/08/26 07:25:09 step 5: objective=0.017669896
2017/08/26 07:25:17 step 6: objective=0.017700847
2017/08/26 07:25:25 step 7: objective=0.017731732
2017/08/26 07:25:25 Training value function...
2017/08/26 07:25:28 step 0: mse=0.531951 step=0.100000
2017/08/26 07:25:30 step 1: mse=0.506115 step=0.100000
2017/08/26 07:25:33 step 2: mse=0.485074 step=0.100000
2017/08/26 07:25:35 step 3: mse=0.466481 step=0.100000
2017/08/26 07:25:37 step 4: mse=0.448996 step=0.100000
2017/08/26 07:25:39 step 5: mse=0.437259 step=0.100000
2017/08/26 07:25:42 step 6: mse=0.425370 step=0.100000
2017/08/26 07:25:44 step 7: mse=0.413927 step=0.100000
2017/08/26 07:25:44 Saving...
2017/08/26 07:25:44 Gathering batch of experience...
2017/08/26 07:25:59 batch 233: mean=15.065217 stddev=6.891716 entropy=1.120675 frames=35728 count=46
2017/08/26 07:25:59 Training policy...
2017/08/26 07:26:08 step 0: objective=0.041449644
2017/08/26 07:26:16 step 1: objective=0.04149425
2017/08/26 07:26:24 step 2: objective=0.041539297
2017/08/26 07:26:32 step 3: objective=0.041584685
2017/08/26 07:26:41 step 4: objective=0.041630447
2017/08/26 07:26:49 step 5: objective=0.041671164
2017/08/26 07:26:57 step 6: objective=0.041740697
2017/08/26 07:27:06 step 7: objective=0.041827306
2017/08/26 07:27:06 Training value function...
2017/08/26 07:27:08 step 0: mse=0.963606 step=0.100000
2017/08/26 07:27:11 step 1: mse=0.896118 step=0.100000
2017/08/26 07:27:13 step 2: mse=0.841563 step=0.100000
2017/08/26 07:27:15 step 3: mse=0.798250 step=0.100000
2017/08/26 07:27:17 step 4: mse=0.762950 step=0.100000
2017/08/26 07:27:20 step 5: mse=0.726403 step=0.100000
2017/08/26 07:27:22 step 6: mse=0.696778 step=0.100000
2017/08/26 07:27:24 step 7: mse=0.670751 step=0.100000
2017/08/26 07:27:24 Saving...
2017/08/26 07:27:24 Gathering batch of experience...
2017/08/26 07:27:39 batch 234: mean=13.395833 stddev=6.244129 entropy=1.125537 frames=35786 count=48
2017/08/26 07:27:39 Training policy...
2017/08/26 07:27:49 step 0: objective=0.004406021
2017/08/26 07:27:57 step 1: objective=0.0044584433
2017/08/26 07:28:05 step 2: objective=0.00451103
2017/08/26 07:28:13 step 3: objective=0.004563748
2017/08/26 07:28:21 step 4: objective=0.004616595
2017/08/26 07:28:29 step 5: objective=0.0046693264
2017/08/26 07:28:37 step 6: objective=0.004774015
2017/08/26 07:28:45 step 7: objective=0.0048694527
2017/08/26 07:28:45 Training value function...
2017/08/26 07:28:48 step 0: mse=0.651114 step=0.100000
2017/08/26 07:28:50 step 1: mse=0.609905 step=0.100000
2017/08/26 07:28:53 step 2: mse=0.577531 step=0.100000
2017/08/26 07:28:55 step 3: mse=0.550315 step=0.100000
2017/08/26 07:28:57 step 4: mse=0.529418 step=0.100000
2017/08/26 07:29:00 step 5: mse=0.511645 step=0.100000
2017/08/26 07:29:02 step 6: mse=0.497135 step=0.100000
2017/08/26 07:29:05 step 7: mse=0.484431 step=0.100000
2017/08/26 07:29:05 Saving...
2017/08/26 07:29:05 Gathering batch of experience...
2017/08/26 07:29:19 batch 235: mean=13.000000 stddev=4.956958 entropy=1.129593 frames=35554 count=49
2017/08/26 07:29:19 Training policy...
2017/08/26 07:29:29 step 0: objective=0.027868196
2017/08/26 07:29:37 step 1: objective=0.027897395
2017/08/26 07:29:45 step 2: objective=0.027926484
2017/08/26 07:29:54 step 3: objective=0.027955785
2017/08/26 07:30:02 step 4: objective=0.027985007
2017/08/26 07:30:10 step 5: objective=0.028014561
2017/08/26 07:30:18 step 6: objective=0.028038332
2017/08/26 07:30:26 step 7: objective=0.028074337
2017/08/26 07:30:26 Training value function...
2017/08/26 07:30:29 step 0: mse=0.556171 step=0.100000
2017/08/26 07:30:31 step 1: mse=0.527913 step=0.100000
2017/08/26 07:30:33 step 2: mse=0.505041 step=0.100000
2017/08/26 07:30:35 step 3: mse=0.487173 step=0.100000
2017/08/26 07:30:38 step 4: mse=0.470733 step=0.100000
2017/08/26 07:30:40 step 5: mse=0.456091 step=0.100000
2017/08/26 07:30:42 step 6: mse=0.446371 step=0.100000
2017/08/26 07:30:45 step 7: mse=0.436567 step=0.100000
2017/08/26 07:30:45 Saving...
2017/08/26 07:30:45 Gathering batch of experience...
2017/08/26 07:30:59 batch 236: mean=13.145833 stddev=6.017300 entropy=1.122891 frames=35681 count=48
2017/08/26 07:30:59 Training policy...
2017/08/26 07:31:09 step 0: objective=0.017532982
2017/08/26 07:31:17 step 1: objective=0.017572762
2017/08/26 07:31:25 step 2: objective=0.017612737
2017/08/26 07:31:33 step 3: objective=0.017652497
2017/08/26 07:31:41 step 4: objective=0.01769254
2017/08/26 07:31:50 step 5: objective=0.017732507
2017/08/26 07:31:58 step 6: objective=0.017770188
2017/08/26 07:32:06 step 7: objective=0.017807191
2017/08/26 07:32:06 Training value function...
2017/08/26 07:32:09 step 0: mse=0.571906 step=0.100000
2017/08/26 07:32:11 step 1: mse=0.545616 step=0.100000
2017/08/26 07:32:13 step 2: mse=0.521805 step=0.100000
2017/08/26 07:32:15 step 3: mse=0.503990 step=0.100000
2017/08/26 07:32:18 step 4: mse=0.487216 step=0.100000
2017/08/26 07:32:20 step 5: mse=0.474974 step=0.100000
2017/08/26 07:32:22 step 6: mse=0.462223 step=0.100000
2017/08/26 07:32:24 step 7: mse=0.453703 step=0.100000
2017/08/26 07:32:24 Saving...
2017/08/26 07:32:24 Gathering batch of experience...
2017/08/26 07:32:39 batch 237: mean=14.562500 stddev=4.928261 entropy=1.132098 frames=36535 count=48
2017/08/26 07:32:39 Training policy...
2017/08/26 07:32:49 step 0: objective=0.050633736
2017/08/26 07:32:58 step 1: objective=0.050671257
2017/08/26 07:33:07 step 2: objective=0.050708897
2017/08/26 07:33:15 step 3: objective=0.050746813
2017/08/26 07:33:23 step 4: objective=0.050785113
2017/08/26 07:33:32 step 5: objective=0.050822664
2017/08/26 07:33:40 step 6: objective=0.0508546
2017/08/26 07:33:49 step 7: objective=0.050885472
2017/08/26 07:33:49 Training value function...
2017/08/26 07:33:51 step 0: mse=0.988777 step=0.100000
2017/08/26 07:33:54 step 1: mse=0.919546 step=0.100000
2017/08/26 07:33:56 step 2: mse=0.863418 step=0.100000
2017/08/26 07:33:58 step 3: mse=0.831839 step=0.100000
2017/08/26 07:34:01 step 4: mse=0.784737 step=0.100000
2017/08/26 07:34:03 step 5: mse=0.743857 step=0.100000
2017/08/26 07:34:05 step 6: mse=0.701218 step=0.100000
2017/08/26 07:34:07 step 7: mse=0.674981 step=0.100000
2017/08/26 07:34:07 Saving...
2017/08/26 07:34:08 Gathering batch of experience...
2017/08/26 07:34:22 batch 238: mean=14.577778 stddev=5.893457 entropy=1.121386 frames=35658 count=45
2017/08/26 07:34:22 Training policy...
2017/08/26 07:34:32 step 0: objective=0.02571396
2017/08/26 07:34:40 step 1: objective=0.025744207
2017/08/26 07:34:48 step 2: objective=0.02577451
2017/08/26 07:34:57 step 3: objective=0.02580516
2017/08/26 07:35:05 step 4: objective=0.025835719
2017/08/26 07:35:13 step 5: objective=0.025866317
2017/08/26 07:35:21 step 6: objective=0.025894992
2017/08/26 07:35:30 step 7: objective=0.025922613
2017/08/26 07:35:30 Training value function...
2017/08/26 07:35:32 step 0: mse=0.663674 step=0.100000
2017/08/26 07:35:35 step 1: mse=0.629168 step=0.100000
2017/08/26 07:35:37 step 2: mse=0.600195 step=0.100000
2017/08/26 07:35:39 step 3: mse=0.574084 step=0.100000
2017/08/26 07:35:42 step 4: mse=0.547190 step=0.100000
2017/08/26 07:35:44 step 5: mse=0.525341 step=0.100000
2017/08/26 07:35:46 step 6: mse=0.513730 step=0.100000
2017/08/26 07:35:48 step 7: mse=0.499342 step=0.100000
2017/08/26 07:35:48 Saving...
2017/08/26 07:35:48 Gathering batch of experience...
2017/08/26 07:36:03 batch 239: mean=13.604167 stddev=5.434226 entropy=1.124576 frames=35532 count=48
2017/08/26 07:36:03 Training policy...
2017/08/26 07:36:13 step 0: objective=0.0070826453
2017/08/26 07:36:21 step 1: objective=0.007160765
2017/08/26 07:36:29 step 2: objective=0.007239514
2017/08/26 07:36:37 step 3: objective=0.0073185177
2017/08/26 07:36:47 step 4: objective=0.007387476
2017/08/26 07:36:55 step 5: objective=0.0074548707
2017/08/26 07:37:03 step 6: objective=0.007518785
2017/08/26 07:37:11 step 7: objective=0.0075814812
2017/08/26 07:37:11 Training value function...
2017/08/26 07:37:14 step 0: mse=0.855294 step=0.100000
2017/08/26 07:37:16 step 1: mse=0.790433 step=0.100000
2017/08/26 07:37:18 step 2: mse=0.738241 step=0.100000
2017/08/26 07:37:21 step 3: mse=0.695274 step=0.100000
2017/08/26 07:37:23 step 4: mse=0.658140 step=0.100000
2017/08/26 07:37:25 step 5: mse=0.627807 step=0.100000
2017/08/26 07:37:27 step 6: mse=0.601177 step=0.100000
2017/08/26 07:37:30 step 7: mse=0.580286 step=0.100000
2017/08/26 07:37:30 Saving...
2017/08/26 07:37:30 Gathering batch of experience...
2017/08/26 07:37:44 batch 240: mean=13.125000 stddev=5.449102 entropy=1.122248 frames=34626 count=48
2017/08/26 07:37:44 Training policy...
2017/08/26 07:37:53 step 0: objective=0.023102928
2017/08/26 07:38:01 step 1: objective=0.023142979
2017/08/26 07:38:09 step 2: objective=0.023182858
2017/08/26 07:38:17 step 3: objective=0.023223834
2017/08/26 07:38:25 step 4: objective=0.023264462
2017/08/26 07:38:33 step 5: objective=0.023305364
2017/08/26 07:38:41 step 6: objective=0.023345424
2017/08/26 07:38:49 step 7: objective=0.023379153
2017/08/26 07:38:49 Training value function...
2017/08/26 07:38:52 step 0: mse=0.661266 step=0.100000
2017/08/26 07:38:54 step 1: mse=0.625825 step=0.100000
2017/08/26 07:38:56 step 2: mse=0.597307 step=0.100000
2017/08/26 07:38:58 step 3: mse=0.573304 step=0.100000
2017/08/26 07:39:00 step 4: mse=0.554484 step=0.100000
2017/08/26 07:39:03 step 5: mse=0.535559 step=0.100000
2017/08/26 07:39:05 step 6: mse=0.523381 step=0.100000
2017/08/26 07:39:07 step 7: mse=0.511366 step=0.100000
2017/08/26 07:39:07 Saving...
2017/08/26 07:39:07 Gathering batch of experience...
2017/08/26 07:39:22 batch 241: mean=14.361702 stddev=6.579871 entropy=1.120006 frames=36946 count=47
2017/08/26 07:39:22 Training policy...
2017/08/26 07:39:32 step 0: objective=0.03129057
2017/08/26 07:39:41 step 1: objective=0.03133004
2017/08/26 07:39:49 step 2: objective=0.03136975
2017/08/26 07:39:58 step 3: objective=0.0314096
2017/08/26 07:40:06 step 4: objective=0.03144964
2017/08/26 07:40:15 step 5: objective=0.031486522
2017/08/26 07:40:23 step 6: objective=0.03151105
2017/08/26 07:40:32 step 7: objective=0.03153177
2017/08/26 07:40:32 Training value function...
2017/08/26 07:40:35 step 0: mse=0.746969 step=0.100000
2017/08/26 07:40:37 step 1: mse=0.702921 step=0.100000
2017/08/26 07:40:40 step 2: mse=0.657066 step=0.100000
2017/08/26 07:40:42 step 3: mse=0.618238 step=0.100000
2017/08/26 07:40:44 step 4: mse=0.585534 step=0.100000
2017/08/26 07:40:47 step 5: mse=0.555006 step=0.100000
2017/08/26 07:40:49 step 6: mse=0.527556 step=0.100000
2017/08/26 07:40:52 step 7: mse=0.502224 step=0.100000
2017/08/26 07:40:52 Saving...
2017/08/26 07:40:52 Gathering batch of experience...
2017/08/26 07:41:06 batch 242: mean=13.367347 stddev=6.394174 entropy=1.123003 frames=35902 count=49
2017/08/26 07:41:06 Training policy...
2017/08/26 07:41:16 step 0: objective=0.031822834
2017/08/26 07:41:25 step 1: objective=0.03186294
2017/08/26 07:41:34 step 2: objective=0.03190286
2017/08/26 07:41:42 step 3: objective=0.031942915
2017/08/26 07:41:50 step 4: objective=0.031982604
2017/08/26 07:41:59 step 5: objective=0.032011654
2017/08/26 07:42:07 step 6: objective=0.032039918
2017/08/26 07:42:15 step 7: objective=0.032058824
2017/08/26 07:42:15 Training value function...
2017/08/26 07:42:18 step 0: mse=1.030248 step=0.100000
2017/08/26 07:42:20 step 1: mse=0.935212 step=0.100000
2017/08/26 07:42:23 step 2: mse=0.850606 step=0.100000
2017/08/26 07:42:25 step 3: mse=0.783414 step=0.100000
2017/08/26 07:42:27 step 4: mse=0.725845 step=0.100000
2017/08/26 07:42:29 step 5: mse=0.670048 step=0.100000
2017/08/26 07:42:32 step 6: mse=0.626115 step=0.100000
2017/08/26 07:42:34 step 7: mse=0.593704 step=0.100000
2017/08/26 07:42:34 Saving...
2017/08/26 07:42:34 Gathering batch of experience...
2017/08/26 07:42:49 batch 243: mean=12.173077 stddev=4.709733 entropy=1.125206 frames=36136 count=52
2017/08/26 07:42:49 Training policy...
2017/08/26 07:42:59 step 0: objective=0.01380543
2017/08/26 07:43:07 step 1: objective=0.013846112
2017/08/26 07:43:16 step 2: objective=0.013886673
2017/08/26 07:43:24 step 3: objective=0.013926881
2017/08/26 07:43:32 step 4: objective=0.013967139
2017/08/26 07:43:41 step 5: objective=0.014000554
2017/08/26 07:43:49 step 6: objective=0.014034737
2017/08/26 07:43:58 step 7: objective=0.0140606
2017/08/26 07:43:58 Training value function...
2017/08/26 07:44:01 step 0: mse=0.703804 step=0.100000
2017/08/26 07:44:03 step 1: mse=0.657922 step=0.100000
2017/08/26 07:44:05 step 2: mse=0.621308 step=0.100000
2017/08/26 07:44:08 step 3: mse=0.594493 step=0.100000
2017/08/26 07:44:10 step 4: mse=0.565147 step=0.100000
2017/08/26 07:44:12 step 5: mse=0.540700 step=0.100000
2017/08/26 07:44:14 step 6: mse=0.518775 step=0.100000
2017/08/26 07:44:17 step 7: mse=0.501247 step=0.100000
2017/08/26 07:44:17 Saving...
2017/08/26 07:44:17 Gathering batch of experience...
2017/08/26 07:44:31 batch 244: mean=12.775510 stddev=6.041575 entropy=1.123501 frames=35009 count=49
2017/08/26 07:44:31 Training policy...
2017/08/26 07:44:41 step 0: objective=0.03605484
2017/08/26 07:44:49 step 1: objective=0.036080353
2017/08/26 07:44:57 step 2: objective=0.036106102
2017/08/26 07:45:05 step 3: objective=0.03613157
2017/08/26 07:45:13 step 4: objective=0.03615719
2017/08/26 07:45:22 step 5: objective=0.036182612
2017/08/26 07:45:30 step 6: objective=0.036197823
2017/08/26 07:45:38 step 7: objective=0.036222238
2017/08/26 07:45:38 Training value function...
2017/08/26 07:45:41 step 0: mse=0.733831 step=0.100000
2017/08/26 07:45:43 step 1: mse=0.701317 step=0.100000
2017/08/26 07:45:45 step 2: mse=0.674927 step=0.100000
2017/08/26 07:45:47 step 3: mse=0.643851 step=0.100000
2017/08/26 07:45:50 step 4: mse=0.623306 step=0.100000
2017/08/26 07:45:52 step 5: mse=0.605173 step=0.100000
2017/08/26 07:45:54 step 6: mse=0.590702 step=0.100000
2017/08/26 07:45:56 step 7: mse=0.577684 step=0.100000
2017/08/26 07:45:56 Saving...
2017/08/26 07:45:56 Gathering batch of experience...
2017/08/26 07:46:11 batch 245: mean=13.750000 stddev=5.157923 entropy=1.120893 frames=36022 count=48
2017/08/26 07:46:11 Training policy...
2017/08/26 07:46:21 step 0: objective=0.032661885
2017/08/26 07:46:29 step 1: objective=0.032699108
2017/08/26 07:46:38 step 2: objective=0.03273623
2017/08/26 07:46:46 step 3: objective=0.032773346
2017/08/26 07:46:55 step 4: objective=0.032810558
2017/08/26 07:47:03 step 5: objective=0.032847513
2017/08/26 07:47:12 step 6: objective=0.03288801
2017/08/26 07:47:20 step 7: objective=0.032925054
2017/08/26 07:47:20 Training value function...
2017/08/26 07:47:23 step 0: mse=0.796250 step=0.100000
2017/08/26 07:47:25 step 1: mse=0.743614 step=0.100000
2017/08/26 07:47:28 step 2: mse=0.700583 step=0.100000
2017/08/26 07:47:30 step 3: mse=0.662709 step=0.100000
2017/08/26 07:47:32 step 4: mse=0.632857 step=0.100000
2017/08/26 07:47:34 step 5: mse=0.606698 step=0.100000
2017/08/26 07:47:37 step 6: mse=0.585802 step=0.100000
2017/08/26 07:47:39 step 7: mse=0.565550 step=0.100000
2017/08/26 07:47:39 Saving...
2017/08/26 07:47:39 Gathering batch of experience...
2017/08/26 07:47:54 batch 246: mean=13.400000 stddev=6.006663 entropy=1.122481 frames=36476 count=50
2017/08/26 07:47:54 Training policy...
2017/08/26 07:48:04 step 0: objective=0.02696567
2017/08/26 07:48:13 step 1: objective=0.027071405
2017/08/26 07:48:21 step 2: objective=0.027177446
2017/08/26 07:48:31 step 3: objective=0.027275087
2017/08/26 07:48:39 step 4: objective=0.027338432
2017/08/26 07:48:48 step 5: objective=0.02738825
2017/08/26 07:48:56 step 6: objective=0.027415395
2017/08/26 07:49:05 step 7: objective=0.027466355
2017/08/26 07:49:05 Training value function...
2017/08/26 07:49:08 step 0: mse=0.897371 step=0.100000
2017/08/26 07:49:10 step 1: mse=0.840351 step=0.100000
2017/08/26 07:49:13 step 2: mse=0.780538 step=0.100000
2017/08/26 07:49:15 step 3: mse=0.736641 step=0.100000
2017/08/26 07:49:17 step 4: mse=0.703602 step=0.100000
2017/08/26 07:49:20 step 5: mse=0.667345 step=0.100000
2017/08/26 07:49:22 step 6: mse=0.644238 step=0.100000
2017/08/26 07:49:24 step 7: mse=0.614633 step=0.100000
2017/08/26 07:49:24 Saving...
2017/08/26 07:49:24 Gathering batch of experience...
2017/08/26 07:49:39 batch 247: mean=13.229167 stddev=6.148305 entropy=1.126216 frames=35281 count=48
2017/08/26 07:49:39 Training policy...
2017/08/26 07:49:49 step 0: objective=0.025676407
2017/08/26 07:49:57 step 1: objective=0.025710048
2017/08/26 07:50:06 step 2: objective=0.025743635
2017/08/26 07:50:15 step 3: objective=0.025777165
2017/08/26 07:50:24 step 4: objective=0.025810791
2017/08/26 07:50:32 step 5: objective=0.02584367
2017/08/26 07:50:41 step 6: objective=0.025866287
2017/08/26 07:50:49 step 7: objective=0.025888579
2017/08/26 07:50:49 Training value function...
2017/08/26 07:50:52 step 0: mse=0.675571 step=0.100000
2017/08/26 07:50:54 step 1: mse=0.643402 step=0.100000
2017/08/26 07:50:56 step 2: mse=0.616219 step=0.100000
2017/08/26 07:50:58 step 3: mse=0.594276 step=0.100000
2017/08/26 07:51:01 step 4: mse=0.576397 step=0.100000
2017/08/26 07:51:03 step 5: mse=0.559187 step=0.100000
2017/08/26 07:51:05 step 6: mse=0.546149 step=0.100000
2017/08/26 07:51:08 step 7: mse=0.529815 step=0.100000
2017/08/26 07:51:08 Saving...
2017/08/26 07:51:08 Gathering batch of experience...
2017/08/26 07:51:23 batch 248: mean=14.458333 stddev=6.331003 entropy=1.122472 frames=36920 count=48
2017/08/26 07:51:23 Training policy...
2017/08/26 07:51:33 step 0: objective=0.04541192
2017/08/26 07:51:42 step 1: objective=0.045462232
2017/08/26 07:51:51 step 2: objective=0.04551255
2017/08/26 07:51:59 step 3: objective=0.045562513
2017/08/26 07:52:08 step 4: objective=0.04561229
2017/08/26 07:52:17 step 5: objective=0.04566069
2017/08/26 07:52:26 step 6: objective=0.045711007
2017/08/26 07:52:34 step 7: objective=0.045779053
2017/08/26 07:52:34 Training value function...
2017/08/26 07:52:37 step 0: mse=0.871657 step=0.100000
2017/08/26 07:52:40 step 1: mse=0.813676 step=0.100000
2017/08/26 07:52:42 step 2: mse=0.766841 step=0.100000
2017/08/26 07:52:44 step 3: mse=0.728531 step=0.100000
2017/08/26 07:52:47 step 4: mse=0.697376 step=0.100000
2017/08/26 07:52:49 step 5: mse=0.670500 step=0.100000
2017/08/26 07:52:51 step 6: mse=0.648344 step=0.100000
2017/08/26 07:52:54 step 7: mse=0.621854 step=0.100000
2017/08/26 07:52:54 Saving...
2017/08/26 07:52:54 Gathering batch of experience...
2017/08/26 07:53:09 batch 249: mean=14.021277 stddev=5.333513 entropy=1.122363 frames=36032 count=47
2017/08/26 07:53:09 Training policy...
2017/08/26 07:53:19 step 0: objective=0.020656263
2017/08/26 07:53:28 step 1: objective=0.020683903
2017/08/26 07:53:36 step 2: objective=0.02071158
2017/08/26 07:53:45 step 3: objective=0.020739183
2017/08/26 07:53:54 step 4: objective=0.020766847
2017/08/26 07:54:02 step 5: objective=0.020794427
2017/08/26 07:54:11 step 6: objective=0.020822026
2017/08/26 07:54:19 step 7: objective=0.020849165
2017/08/26 07:54:19 Training value function...
2017/08/26 07:54:22 step 0: mse=0.595518 step=0.100000
2017/08/26 07:54:25 step 1: mse=0.561722 step=0.100000
2017/08/26 07:54:27 step 2: mse=0.532269 step=0.100000
2017/08/26 07:54:29 step 3: mse=0.508183 step=0.100000
2017/08/26 07:54:31 step 4: mse=0.485935 step=0.100000
2017/08/26 07:54:34 step 5: mse=0.464696 step=0.100000
2017/08/26 07:54:36 step 6: mse=0.449398 step=0.100000
2017/08/26 07:54:38 step 7: mse=0.438402 step=0.100000
2017/08/26 07:54:38 Saving...
2017/08/26 07:54:38 Gathering batch of experience...
2017/08/26 07:54:53 batch 250: mean=14.312500 stddev=5.224766 entropy=1.117770 frames=36057 count=48
2017/08/26 07:54:53 Training policy...
2017/08/26 07:55:03 step 0: objective=0.043186408
2017/08/26 07:55:12 step 1: objective=0.043249145
2017/08/26 07:55:20 step 2: objective=0.043313045
2017/08/26 07:55:29 step 3: objective=0.043377787
2017/08/26 07:55:38 step 4: objective=0.043435536
2017/08/26 07:55:46 step 5: objective=0.043488238
2017/08/26 07:55:55 step 6: objective=0.043568797
2017/08/26 07:56:03 step 7: objective=0.04362339
2017/08/26 07:56:03 Training value function...
2017/08/26 07:56:06 step 0: mse=0.845681 step=0.100000
2017/08/26 07:56:09 step 1: mse=0.807558 step=0.100000
2017/08/26 07:56:11 step 2: mse=0.776331 step=0.100000
2017/08/26 07:56:13 step 3: mse=0.740784 step=0.100000
2017/08/26 07:56:16 step 4: mse=0.718173 step=0.100000
2017/08/26 07:56:18 step 5: mse=0.697678 step=0.100000
2017/08/26 07:56:20 step 6: mse=0.677703 step=0.100000
2017/08/26 07:56:22 step 7: mse=0.664674 step=0.100000
2017/08/26 07:56:22 Saving...
2017/08/26 07:56:23 Gathering batch of experience...
2017/08/26 07:56:38 batch 251: mean=13.666667 stddev=6.259437 entropy=1.125745 frames=36326 count=48
2017/08/26 07:56:38 Training policy...
2017/08/26 07:56:48 step 0: objective=0.024645345
2017/08/26 07:56:57 step 1: objective=0.024695447
2017/08/26 07:57:05 step 2: objective=0.024745602
2017/08/26 07:57:14 step 3: objective=0.02479606
2017/08/26 07:57:23 step 4: objective=0.024846097
2017/08/26 07:57:32 step 5: objective=0.024880657
2017/08/26 07:57:40 step 6: objective=0.024915643
2017/08/26 07:57:49 step 7: objective=0.024949197
2017/08/26 07:57:49 Training value function...
2017/08/26 07:57:52 step 0: mse=1.155857 step=0.100000
2017/08/26 07:57:54 step 1: mse=1.024530 step=0.100000
2017/08/26 07:57:57 step 2: mse=0.918964 step=0.100000
2017/08/26 07:57:59 step 3: mse=0.833159 step=0.100000
2017/08/26 07:58:01 step 4: mse=0.763733 step=0.100000
2017/08/26 07:58:04 step 5: mse=0.705589 step=0.100000
2017/08/26 07:58:06 step 6: mse=0.655078 step=0.100000
2017/08/26 07:58:08 step 7: mse=0.612462 step=0.100000
2017/08/26 07:58:08 Saving...
2017/08/26 07:58:08 Gathering batch of experience...
2017/08/26 07:58:23 batch 252: mean=12.416667 stddev=5.559651 entropy=1.120704 frames=34532 count=48
2017/08/26 07:58:23 Training policy...
2017/08/26 07:58:32 step 0: objective=0.014391252
2017/08/26 07:58:41 step 1: objective=0.014416632
2017/08/26 07:58:49 step 2: objective=0.014442141
2017/08/26 07:58:57 step 3: objective=0.014467436
2017/08/26 07:59:06 step 4: objective=0.014492823
2017/08/26 07:59:14 step 5: objective=0.014518223
2017/08/26 07:59:22 step 6: objective=0.014543722
2017/08/26 07:59:31 step 7: objective=0.014569177
2017/08/26 07:59:31 Training value function...
2017/08/26 07:59:33 step 0: mse=0.627372 step=0.100000
2017/08/26 07:59:35 step 1: mse=0.595219 step=0.100000
2017/08/26 07:59:37 step 2: mse=0.570683 step=0.100000
2017/08/26 07:59:40 step 3: mse=0.546871 step=0.100000
2017/08/26 07:59:42 step 4: mse=0.530097 step=0.100000
2017/08/26 07:59:44 step 5: mse=0.511071 step=0.100000
2017/08/26 07:59:46 step 6: mse=0.495508 step=0.100000
2017/08/26 07:59:48 step 7: mse=0.483403 step=0.100000
2017/08/26 07:59:48 Saving...
2017/08/26 07:59:48 Gathering batch of experience...
2017/08/26 08:00:03 batch 253: mean=13.291667 stddev=5.098849 entropy=1.127465 frames=36168 count=48
2017/08/26 08:00:03 Training policy...
2017/08/26 08:00:14 step 0: objective=0.032869317
2017/08/26 08:00:22 step 1: objective=0.03290281
2017/08/26 08:00:31 step 2: objective=0.032936335
2017/08/26 08:00:40 step 3: objective=0.03296995
2017/08/26 08:00:49 step 4: objective=0.033003133
2017/08/26 08:00:57 step 5: objective=0.03303623
2017/08/26 08:01:06 step 6: objective=0.033065572
2017/08/26 08:01:15 step 7: objective=0.03311472
2017/08/26 08:01:15 Training value function...
2017/08/26 08:01:17 step 0: mse=0.585696 step=0.100000
2017/08/26 08:01:20 step 1: mse=0.549664 step=0.100000
2017/08/26 08:01:22 step 2: mse=0.520430 step=0.100000
2017/08/26 08:01:24 step 3: mse=0.493419 step=0.100000
2017/08/26 08:01:27 step 4: mse=0.470124 step=0.100000
2017/08/26 08:01:29 step 5: mse=0.450525 step=0.100000
2017/08/26 08:01:31 step 6: mse=0.434645 step=0.100000
2017/08/26 08:01:34 step 7: mse=0.421395 step=0.100000
2017/08/26 08:01:34 Saving...
2017/08/26 08:01:34 Gathering batch of experience...
2017/08/26 08:01:48 batch 254: mean=13.375000 stddev=5.471993 entropy=1.122811 frames=35706 count=48
2017/08/26 08:01:48 Training policy...
2017/08/26 08:01:59 step 0: objective=0.022055909
2017/08/26 08:02:07 step 1: objective=0.022082888
2017/08/26 08:02:16 step 2: objective=0.02210971
2017/08/26 08:02:25 step 3: objective=0.022136372
2017/08/26 08:02:33 step 4: objective=0.022162864
2017/08/26 08:02:42 step 5: objective=0.022189308
2017/08/26 08:02:51 step 6: objective=0.022215433
2017/08/26 08:02:59 step 7: objective=0.022240823
2017/08/26 08:02:59 Training value function...
2017/08/26 08:03:02 step 0: mse=0.661573 step=0.100000
2017/08/26 08:03:04 step 1: mse=0.626853 step=0.100000
2017/08/26 08:03:07 step 2: mse=0.593766 step=0.100000
2017/08/26 08:03:09 step 3: mse=0.567323 step=0.100000
2017/08/26 08:03:11 step 4: mse=0.546110 step=0.100000
2017/08/26 08:03:14 step 5: mse=0.526934 step=0.100000
2017/08/26 08:03:16 step 6: mse=0.511553 step=0.100000
2017/08/26 08:03:18 step 7: mse=0.497662 step=0.100000
2017/08/26 08:03:18 Saving...
2017/08/26 08:03:18 Gathering batch of experience...
2017/08/26 08:03:33 batch 255: mean=12.920000 stddev=5.918919 entropy=1.124562 frames=36141 count=50
2017/08/26 08:03:33 Training policy...
2017/08/26 08:03:44 step 0: objective=0.029675545
2017/08/26 08:03:52 step 1: objective=0.029704222
2017/08/26 08:04:01 step 2: objective=0.029732827
2017/08/26 08:04:10 step 3: objective=0.029761506
2017/08/26 08:04:18 step 4: objective=0.029789634
2017/08/26 08:04:27 step 5: objective=0.02981793
2017/08/26 08:04:36 step 6: objective=0.02986478
2017/08/26 08:04:45 step 7: objective=0.02988758
2017/08/26 08:04:45 Training value function...
2017/08/26 08:04:47 step 0: mse=0.645993 step=0.100000
2017/08/26 08:04:50 step 1: mse=0.606627 step=0.100000
2017/08/26 08:04:52 step 2: mse=0.574943 step=0.100000
2017/08/26 08:04:54 step 3: mse=0.548852 step=0.100000
2017/08/26 08:04:56 step 4: mse=0.527750 step=0.100000
2017/08/26 08:04:59 step 5: mse=0.510571 step=0.100000
2017/08/26 08:05:01 step 6: mse=0.486912 step=0.100000
2017/08/26 08:05:03 step 7: mse=0.470345 step=0.100000
2017/08/26 08:05:03 Saving...
2017/08/26 08:05:03 Gathering batch of experience...
2017/08/26 08:05:19 batch 256: mean=16.288889 stddev=6.872238 entropy=1.117927 frames=37166 count=45
2017/08/26 08:05:19 Training policy...
2017/08/26 08:05:29 step 0: objective=0.063255414
2017/08/26 08:05:38 step 1: objective=0.06333285
2017/08/26 08:05:47 step 2: objective=0.063411176
2017/08/26 08:05:56 step 3: objective=0.0634892
2017/08/26 08:06:05 step 4: objective=0.06358209
2017/08/26 08:06:15 step 5: objective=0.0636273
2017/08/26 08:06:24 step 6: objective=0.063714795
2017/08/26 08:06:33 step 7: objective=0.06379151
2017/08/26 08:06:33 Training value function...
2017/08/26 08:06:36 step 0: mse=0.962024 step=0.100000
2017/08/26 08:06:38 step 1: mse=0.895382 step=0.100000
2017/08/26 08:06:41 step 2: mse=0.840511 step=0.100000
2017/08/26 08:06:43 step 3: mse=0.799146 step=0.100000
2017/08/26 08:06:45 step 4: mse=0.757458 step=0.100000
2017/08/26 08:06:48 step 5: mse=0.722448 step=0.100000
2017/08/26 08:06:50 step 6: mse=0.691254 step=0.100000
2017/08/26 08:06:53 step 7: mse=0.665049 step=0.100000
2017/08/26 08:06:53 Saving...
2017/08/26 08:06:53 Gathering batch of experience...
2017/08/26 08:07:08 batch 257: mean=14.239130 stddev=5.251024 entropy=1.120421 frames=36093 count=46
2017/08/26 08:07:08 Training policy...
2017/08/26 08:07:18 step 0: objective=0.009383295
2017/08/26 08:07:27 step 1: objective=0.009452919
2017/08/26 08:07:36 step 2: objective=0.009523086
2017/08/26 08:07:44 step 3: objective=0.009593823
2017/08/26 08:07:53 step 4: objective=0.009650688
2017/08/26 08:08:02 step 5: objective=0.0096964035
2017/08/26 08:08:11 step 6: objective=0.009738155
2017/08/26 08:08:20 step 7: objective=0.009814107
2017/08/26 08:08:20 Training value function...
2017/08/26 08:08:22 step 0: mse=0.638009 step=0.100000
2017/08/26 08:08:25 step 1: mse=0.614891 step=0.100000
2017/08/26 08:08:27 step 2: mse=0.586839 step=0.100000
2017/08/26 08:08:29 step 3: mse=0.565655 step=0.100000
2017/08/26 08:08:32 step 4: mse=0.544995 step=0.100000
2017/08/26 08:08:34 step 5: mse=0.528472 step=0.100000
2017/08/26 08:08:36 step 6: mse=0.513327 step=0.100000
2017/08/26 08:08:39 step 7: mse=0.501281 step=0.100000
2017/08/26 08:08:39 Saving...
2017/08/26 08:08:39 Gathering batch of experience...
2017/08/26 08:08:53 batch 258: mean=12.860000 stddev=4.749779 entropy=1.129855 frames=35702 count=50
2017/08/26 08:08:53 Training policy...
2017/08/26 08:09:04 step 0: objective=0.017197274
2017/08/26 08:09:13 step 1: objective=0.017250396
2017/08/26 08:09:22 step 2: objective=0.017303346
2017/08/26 08:09:30 step 3: objective=0.01735573
2017/08/26 08:09:39 step 4: objective=0.017405875
2017/08/26 08:09:48 step 5: objective=0.017455691
2017/08/26 08:09:57 step 6: objective=0.017504806
2017/08/26 08:10:05 step 7: objective=0.01756147
2017/08/26 08:10:05 Training value function...
2017/08/26 08:10:08 step 0: mse=0.594116 step=0.100000
2017/08/26 08:10:10 step 1: mse=0.564822 step=0.100000
2017/08/26 08:10:13 step 2: mse=0.541096 step=0.100000
2017/08/26 08:10:15 step 3: mse=0.521543 step=0.100000
2017/08/26 08:10:17 step 4: mse=0.505520 step=0.100000
2017/08/26 08:10:20 step 5: mse=0.492400 step=0.100000
2017/08/26 08:10:22 step 6: mse=0.479234 step=0.100000
2017/08/26 08:10:24 step 7: mse=0.459716 step=0.100000
2017/08/26 08:10:24 Saving...
2017/08/26 08:10:24 Gathering batch of experience...
2017/08/26 08:10:39 batch 259: mean=16.086957 stddev=7.330182 entropy=1.124657 frames=36627 count=46
2017/08/26 08:10:39 Training policy...
2017/08/26 08:10:50 step 0: objective=0.06633433
2017/08/26 08:10:59 step 1: objective=0.066458814
2017/08/26 08:11:08 step 2: objective=0.06658463
2017/08/26 08:11:17 step 3: objective=0.06670768
2017/08/26 08:11:26 step 4: objective=0.06679893
2017/08/26 08:11:35 step 5: objective=0.06688885
2017/08/26 08:11:44 step 6: objective=0.0669394
2017/08/26 08:11:53 step 7: objective=0.067016095
2017/08/26 08:11:53 Training value function...
2017/08/26 08:11:56 step 0: mse=1.285180 step=0.100000
2017/08/26 08:11:59 step 1: mse=1.189015 step=0.100000
2017/08/26 08:12:01 step 2: mse=1.102815 step=0.100000
2017/08/26 08:12:03 step 3: mse=1.035806 step=0.100000
2017/08/26 08:12:06 step 4: mse=0.972464 step=0.100000
2017/08/26 08:12:08 step 5: mse=0.926647 step=0.100000
2017/08/26 08:12:10 step 6: mse=0.868314 step=0.100000
2017/08/26 08:12:13 step 7: mse=0.828659 step=0.100000
2017/08/26 08:12:13 Saving...
2017/08/26 08:12:13 Gathering batch of experience...
2017/08/26 08:12:28 batch 260: mean=15.891304 stddev=7.184610 entropy=1.121604 frames=35974 count=46
2017/08/26 08:12:28 Training policy...
2017/08/26 08:12:38 step 0: objective=0.03632532
2017/08/26 08:12:48 step 1: objective=0.036478847
2017/08/26 08:12:56 step 2: objective=0.03663162
2017/08/26 08:13:06 step 3: objective=0.0367825
2017/08/26 08:13:15 step 4: objective=0.036909364
2017/08/26 08:13:23 step 5: objective=0.037047315
2017/08/26 08:13:32 step 6: objective=0.037134033
2017/08/26 08:13:41 step 7: objective=0.037207525
2017/08/26 08:13:41 Training value function...
2017/08/26 08:13:44 step 0: mse=1.197728 step=0.100000
2017/08/26 08:13:46 step 1: mse=1.151204 step=0.100000
2017/08/26 08:13:48 step 2: mse=1.085418 step=0.100000
2017/08/26 08:13:51 step 3: mse=1.049296 step=0.100000
2017/08/26 08:13:53 step 4: mse=1.012132 step=0.100000
2017/08/26 08:13:55 step 5: mse=0.981660 step=0.100000
2017/08/26 08:13:58 step 6: mse=0.952537 step=0.100000
2017/08/26 08:14:00 step 7: mse=0.925851 step=0.100000
2017/08/26 08:14:00 Saving...
2017/08/26 08:14:00 Gathering batch of experience...
2017/08/26 08:14:14 batch 261: mean=13.702128 stddev=6.480461 entropy=1.129347 frames=35297 count=47
2017/08/26 08:14:14 Training policy...
2017/08/26 08:14:25 step 0: objective=0.011873821
2017/08/26 08:14:33 step 1: objective=0.011938517
2017/08/26 08:14:42 step 2: objective=0.012002521
2017/08/26 08:14:51 step 3: objective=0.012065684
2017/08/26 08:15:00 step 4: objective=0.012127701
2017/08/26 08:15:08 step 5: objective=0.012177582
2017/08/26 08:15:17 step 6: objective=0.012209885
2017/08/26 08:15:26 step 7: objective=0.012257538
2017/08/26 08:15:26 Training value function...
2017/08/26 08:15:28 step 0: mse=0.930428 step=0.100000
2017/08/26 08:15:31 step 1: mse=0.840918 step=0.100000
2017/08/26 08:15:33 step 2: mse=0.769144 step=0.100000
2017/08/26 08:15:35 step 3: mse=0.705779 step=0.100000
2017/08/26 08:15:37 step 4: mse=0.654806 step=0.100000
2017/08/26 08:15:40 step 5: mse=0.612510 step=0.100000
2017/08/26 08:15:42 step 6: mse=0.578406 step=0.100000
2017/08/26 08:15:44 step 7: mse=0.550013 step=0.100000
2017/08/26 08:15:44 Saving...
2017/08/26 08:15:44 Gathering batch of experience...
2017/08/26 08:15:59 batch 262: mean=14.391304 stddev=5.593001 entropy=1.126685 frames=35147 count=46
2017/08/26 08:15:59 Training policy...
2017/08/26 08:16:09 step 0: objective=0.020377545
2017/08/26 08:16:18 step 1: objective=0.020442858
2017/08/26 08:16:26 step 2: objective=0.020509187
2017/08/26 08:16:35 step 3: objective=0.020576105
2017/08/26 08:16:44 step 4: objective=0.02063976
2017/08/26 08:16:53 step 5: objective=0.02069543
2017/08/26 08:17:01 step 6: objective=0.020787803
2017/08/26 08:17:10 step 7: objective=0.0208596
2017/08/26 08:17:10 Training value function...
2017/08/26 08:17:13 step 0: mse=0.999089 step=0.100000
2017/08/26 08:17:15 step 1: mse=0.911338 step=0.100000
2017/08/26 08:17:17 step 2: mse=0.843383 step=0.100000
2017/08/26 08:17:19 step 3: mse=0.789706 step=0.100000
2017/08/26 08:17:22 step 4: mse=0.741942 step=0.100000
2017/08/26 08:17:24 step 5: mse=0.699434 step=0.100000
2017/08/26 08:17:26 step 6: mse=0.670569 step=0.100000
2017/08/26 08:17:28 step 7: mse=0.641412 step=0.100000
2017/08/26 08:17:28 Saving...
2017/08/26 08:17:28 Gathering batch of experience...
2017/08/26 08:17:43 batch 263: mean=14.312500 stddev=6.880396 entropy=1.121593 frames=35703 count=48
2017/08/26 08:17:43 Training policy...
2017/08/26 08:17:54 step 0: objective=0.027859963
2017/08/26 08:18:03 step 1: objective=0.027927054
2017/08/26 08:18:12 step 2: objective=0.027994446
2017/08/26 08:18:21 step 3: objective=0.028061569
2017/08/26 08:18:30 step 4: objective=0.028129084
2017/08/26 08:18:39 step 5: objective=0.028196005
2017/08/26 08:18:48 step 6: objective=0.028222587
2017/08/26 08:18:57 step 7: objective=0.028305288
2017/08/26 08:18:57 Training value function...
2017/08/26 08:18:59 step 0: mse=0.916117 step=0.100000
2017/08/26 08:19:01 step 1: mse=0.880446 step=0.100000
2017/08/26 08:19:04 step 2: mse=0.851469 step=0.100000
2017/08/26 08:19:06 step 3: mse=0.820147 step=0.100000
2017/08/26 08:19:08 step 4: mse=0.800111 step=0.100000
2017/08/26 08:19:10 step 5: mse=0.766756 step=0.100000
2017/08/26 08:19:13 step 6: mse=0.733312 step=0.100000
2017/08/26 08:19:15 step 7: mse=0.704477 step=0.100000
2017/08/26 08:19:15 Saving...
2017/08/26 08:19:15 Gathering batch of experience...
2017/08/26 08:19:29 batch 264: mean=13.104167 stddev=5.598510 entropy=1.125386 frames=34852 count=48
2017/08/26 08:19:29 Training policy...
2017/08/26 08:19:40 step 0: objective=0.020952044
2017/08/26 08:19:49 step 1: objective=0.02099281
2017/08/26 08:19:58 step 2: objective=0.021033581
2017/08/26 08:20:07 step 3: objective=0.02107423
2017/08/26 08:20:15 step 4: objective=0.021114755
2017/08/26 08:20:24 step 5: objective=0.02115277
2017/08/26 08:20:33 step 6: objective=0.02119412
2017/08/26 08:20:41 step 7: objective=0.021228183
2017/08/26 08:20:41 Training value function...
2017/08/26 08:20:44 step 0: mse=0.776376 step=0.100000
2017/08/26 08:20:46 step 1: mse=0.735513 step=0.100000
2017/08/26 08:20:48 step 2: mse=0.698752 step=0.100000
2017/08/26 08:20:51 step 3: mse=0.669164 step=0.100000
2017/08/26 08:20:53 step 4: mse=0.648396 step=0.100000
2017/08/26 08:20:55 step 5: mse=0.624323 step=0.100000
2017/08/26 08:20:57 step 6: mse=0.605191 step=0.100000
2017/08/26 08:20:59 step 7: mse=0.590572 step=0.100000
2017/08/26 08:20:59 Saving...
2017/08/26 08:21:00 Gathering batch of experience...
2017/08/26 08:21:15 batch 265: mean=14.319149 stddev=4.776300 entropy=1.118162 frames=36609 count=47
2017/08/26 08:21:15 Training policy...
2017/08/26 08:21:26 step 0: objective=0.028494226
2017/08/26 08:21:36 step 1: objective=0.0285353
2017/08/26 08:21:45 step 2: objective=0.028576585
2017/08/26 08:21:55 step 3: objective=0.028617917
2017/08/26 08:22:04 step 4: objective=0.028659418
2017/08/26 08:22:13 step 5: objective=0.028701205
2017/08/26 08:22:22 step 6: objective=0.028742848
2017/08/26 08:22:31 step 7: objective=0.028777797
2017/08/26 08:22:31 Training value function...
2017/08/26 08:22:34 step 0: mse=0.599955 step=0.100000
2017/08/26 08:22:37 step 1: mse=0.576886 step=0.100000
2017/08/26 08:22:39 step 2: mse=0.547037 step=0.100000
2017/08/26 08:22:41 step 3: mse=0.528725 step=0.100000
2017/08/26 08:22:44 step 4: mse=0.505552 step=0.100000
2017/08/26 08:22:46 step 5: mse=0.481958 step=0.100000
2017/08/26 08:22:48 step 6: mse=0.458229 step=0.100000
2017/08/26 08:22:51 step 7: mse=0.441139 step=0.100000
2017/08/26 08:22:51 Saving...
2017/08/26 08:22:51 Gathering batch of experience...
2017/08/26 08:23:06 batch 266: mean=14.489362 stddev=6.810106 entropy=1.122557 frames=36005 count=47
2017/08/26 08:23:06 Training policy...
2017/08/26 08:23:16 step 0: objective=0.041895863
2017/08/26 08:23:25 step 1: objective=0.041956957
2017/08/26 08:23:34 step 2: objective=0.042018574
2017/08/26 08:23:43 step 3: objective=0.042076133
2017/08/26 08:23:52 step 4: objective=0.042115334
2017/08/26 08:24:01 step 5: objective=0.042150367
2017/08/26 08:24:10 step 6: objective=0.042178232
2017/08/26 08:24:19 step 7: objective=0.042245746
2017/08/26 08:24:19 Training value function...
2017/08/26 08:24:22 step 0: mse=1.132269 step=0.100000
2017/08/26 08:24:24 step 1: mse=1.025661 step=0.100000
2017/08/26 08:24:27 step 2: mse=0.939394 step=0.100000
2017/08/26 08:24:29 step 3: mse=0.867588 step=0.100000
2017/08/26 08:24:31 step 4: mse=0.806899 step=0.100000
2017/08/26 08:24:34 step 5: mse=0.757806 step=0.100000
2017/08/26 08:24:36 step 6: mse=0.713255 step=0.100000
2017/08/26 08:24:38 step 7: mse=0.682293 step=0.100000
2017/08/26 08:24:38 Saving...
2017/08/26 08:24:38 Gathering batch of experience...
2017/08/26 08:24:54 batch 267: mean=15.956522 stddev=6.490651 entropy=1.118803 frames=36556 count=46
2017/08/26 08:24:54 Training policy...
2017/08/26 08:25:04 step 0: objective=0.04815744
2017/08/26 08:25:14 step 1: objective=0.048256557
2017/08/26 08:25:23 step 2: objective=0.048355956
2017/08/26 08:25:32 step 3: objective=0.04844863
2017/08/26 08:25:41 step 4: objective=0.048534527
2017/08/26 08:25:51 step 5: objective=0.04859375
2017/08/26 08:26:00 step 6: objective=0.048644315
2017/08/26 08:26:09 step 7: objective=0.048699237
2017/08/26 08:26:09 Training value function...
2017/08/26 08:26:12 step 0: mse=1.060667 step=0.100000
2017/08/26 08:26:14 step 1: mse=0.977737 step=0.100000
2017/08/26 08:26:16 step 2: mse=0.907680 step=0.100000
2017/08/26 08:26:19 step 3: mse=0.855253 step=0.100000
2017/08/26 08:26:21 step 4: mse=0.801446 step=0.100000
2017/08/26 08:26:23 step 5: mse=0.758548 step=0.100000
2017/08/26 08:26:26 step 6: mse=0.732425 step=0.100000
2017/08/26 08:26:28 step 7: mse=0.698239 step=0.100000
2017/08/26 08:26:28 Saving...
2017/08/26 08:26:28 Gathering batch of experience...
2017/08/26 08:26:43 batch 268: mean=13.489796 stddev=6.020789 entropy=1.123468 frames=36630 count=49
2017/08/26 08:26:43 Training policy...
2017/08/26 08:26:54 step 0: objective=0.0028791586
2017/08/26 08:27:04 step 1: objective=0.0029355632
2017/08/26 08:27:13 step 2: objective=0.0029913683
2017/08/26 08:27:22 step 3: objective=0.0030465843
2017/08/26 08:27:31 step 4: objective=0.0031006082
2017/08/26 08:27:41 step 5: objective=0.003139957
2017/08/26 08:27:50 step 6: objective=0.0031696858
2017/08/26 08:27:59 step 7: objective=0.003195182
2017/08/26 08:27:59 Training value function...
2017/08/26 08:28:02 step 0: mse=0.691750 step=0.100000
2017/08/26 08:28:04 step 1: mse=0.659353 step=0.100000
2017/08/26 08:28:07 step 2: mse=0.633528 step=0.100000
2017/08/26 08:28:09 step 3: mse=0.610372 step=0.100000
2017/08/26 08:28:11 step 4: mse=0.590342 step=0.100000
2017/08/26 08:28:14 step 5: mse=0.573935 step=0.100000
2017/08/26 08:28:16 step 6: mse=0.559738 step=0.100000
2017/08/26 08:28:19 step 7: mse=0.533386 step=0.100000
2017/08/26 08:28:19 Saving...
2017/08/26 08:28:19 Gathering batch of experience...
2017/08/26 08:28:34 batch 269: mean=14.125000 stddev=6.366007 entropy=1.116493 frames=37452 count=48
2017/08/26 08:28:34 Training policy...
2017/08/26 08:28:46 step 0: objective=0.016232666
2017/08/26 08:28:56 step 1: objective=0.016282886
2017/08/26 08:29:05 step 2: objective=0.016333194
2017/08/26 08:29:15 step 3: objective=0.016383706
2017/08/26 08:29:24 step 4: objective=0.016434593
2017/08/26 08:29:33 step 5: objective=0.016485238
2017/08/26 08:29:43 step 6: objective=0.016533159
2017/08/26 08:29:53 step 7: objective=0.016582714
2017/08/26 08:29:53 Training value function...
2017/08/26 08:29:56 step 0: mse=0.743531 step=0.100000
2017/08/26 08:29:58 step 1: mse=0.690340 step=0.100000
2017/08/26 08:30:00 step 2: mse=0.647210 step=0.100000
2017/08/26 08:30:03 step 3: mse=0.612717 step=0.100000
2017/08/26 08:30:05 step 4: mse=0.584680 step=0.100000
2017/08/26 08:30:08 step 5: mse=0.559034 step=0.100000
2017/08/26 08:30:10 step 6: mse=0.538258 step=0.100000
2017/08/26 08:30:12 step 7: mse=0.518503 step=0.100000
2017/08/26 08:30:12 Saving...
2017/08/26 08:30:12 Gathering batch of experience...
2017/08/26 08:30:27 batch 270: mean=12.632653 stddev=4.574525 entropy=1.124574 frames=35394 count=49
2017/08/26 08:30:27 Training policy...
2017/08/26 08:30:38 step 0: objective=0.011956868
2017/08/26 08:30:47 step 1: objective=0.012002383
2017/08/26 08:30:56 step 2: objective=0.012047615
2017/08/26 08:31:05 step 3: objective=0.012092528
2017/08/26 08:31:14 step 4: objective=0.012137196
2017/08/26 08:31:23 step 5: objective=0.012178674
2017/08/26 08:31:32 step 6: objective=0.012204522
2017/08/26 08:31:41 step 7: objective=0.012261506
2017/08/26 08:31:41 Training value function...
2017/08/26 08:31:44 step 0: mse=0.570792 step=0.100000
2017/08/26 08:31:46 step 1: mse=0.541190 step=0.100000
2017/08/26 08:31:48 step 2: mse=0.516414 step=0.100000
2017/08/26 08:31:50 step 3: mse=0.496744 step=0.100000
2017/08/26 08:31:53 step 4: mse=0.471911 step=0.100000
2017/08/26 08:31:55 step 5: mse=0.459302 step=0.100000
2017/08/26 08:31:57 step 6: mse=0.437484 step=0.100000
2017/08/26 08:31:59 step 7: mse=0.420126 step=0.100000
2017/08/26 08:31:59 Saving...
2017/08/26 08:31:59 Gathering batch of experience...
2017/08/26 08:32:15 batch 271: mean=13.666667 stddev=4.068852 entropy=1.125591 frames=36786 count=48
2017/08/26 08:32:15 Training policy...
2017/08/26 08:32:26 step 0: objective=0.027788024
2017/08/26 08:32:35 step 1: objective=0.027819902
2017/08/26 08:32:44 step 2: objective=0.027851915
2017/08/26 08:32:54 step 3: objective=0.027883852
2017/08/26 08:33:03 step 4: objective=0.027915621
2017/08/26 08:33:13 step 5: objective=0.027947558
2017/08/26 08:33:22 step 6: objective=0.02797849
2017/08/26 08:33:32 step 7: objective=0.028000629
2017/08/26 08:33:32 Training value function...
2017/08/26 08:33:34 step 0: mse=0.575014 step=0.100000
2017/08/26 08:33:37 step 1: mse=0.549189 step=0.100000
2017/08/26 08:33:39 step 2: mse=0.528304 step=0.100000
2017/08/26 08:33:42 step 3: mse=0.512795 step=0.100000
2017/08/26 08:33:44 step 4: mse=0.499251 step=0.100000
2017/08/26 08:33:46 step 5: mse=0.488144 step=0.100000
2017/08/26 08:33:49 step 6: mse=0.476710 step=0.100000
2017/08/26 08:33:51 step 7: mse=0.469674 step=0.100000
2017/08/26 08:33:51 Saving...
2017/08/26 08:33:51 Gathering batch of experience...
2017/08/26 08:34:06 batch 272: mean=13.460000 stddev=6.663963 entropy=1.120729 frames=35928 count=50
2017/08/26 08:34:06 Training policy...
2017/08/26 08:34:17 step 0: objective=0.04350642
2017/08/26 08:34:26 step 1: objective=0.04356847
2017/08/26 08:34:36 step 2: objective=0.043630455
2017/08/26 08:34:45 step 3: objective=0.043692272
2017/08/26 08:34:54 step 4: objective=0.04375224
2017/08/26 08:35:03 step 5: objective=0.04380275
2017/08/26 08:35:12 step 6: objective=0.043846384
2017/08/26 08:35:22 step 7: objective=0.043885846
2017/08/26 08:35:22 Training value function...
2017/08/26 08:35:24 step 0: mse=0.960129 step=0.100000
2017/08/26 08:35:27 step 1: mse=0.894215 step=0.100000
2017/08/26 08:35:29 step 2: mse=0.841281 step=0.100000
2017/08/26 08:35:31 step 3: mse=0.795195 step=0.100000
2017/08/26 08:35:34 step 4: mse=0.747551 step=0.100000
2017/08/26 08:35:36 step 5: mse=0.709417 step=0.100000
2017/08/26 08:35:38 step 6: mse=0.675135 step=0.100000
2017/08/26 08:35:40 step 7: mse=0.650028 step=0.100000
2017/08/26 08:35:40 Saving...
2017/08/26 08:35:40 Gathering batch of experience...
2017/08/26 08:35:55 batch 273: mean=14.369565 stddev=5.850896 entropy=1.122272 frames=36058 count=46
2017/08/26 08:35:55 Training policy...
2017/08/26 08:36:07 step 0: objective=0.03621231
2017/08/26 08:36:16 step 1: objective=0.036275778
2017/08/26 08:36:25 step 2: objective=0.0363402
2017/08/26 08:36:35 step 3: objective=0.036402013
2017/08/26 08:36:44 step 4: objective=0.036430262
2017/08/26 08:36:53 step 5: objective=0.036462512
2017/08/26 08:37:03 step 6: objective=0.03652114
2017/08/26 08:37:12 step 7: objective=0.03657581
2017/08/26 08:37:12 Training value function...
2017/08/26 08:37:15 step 0: mse=0.672830 step=0.100000
2017/08/26 08:37:17 step 1: mse=0.647486 step=0.100000
2017/08/26 08:37:20 step 2: mse=0.626952 step=0.100000
2017/08/26 08:37:22 step 3: mse=0.610031 step=0.100000
2017/08/26 08:37:25 step 4: mse=0.593753 step=0.100000
2017/08/26 08:37:27 step 5: mse=0.581861 step=0.100000
2017/08/26 08:37:29 step 6: mse=0.571170 step=0.100000
2017/08/26 08:37:32 step 7: mse=0.561428 step=0.100000
2017/08/26 08:37:32 Saving...
2017/08/26 08:37:32 Gathering batch of experience...
2017/08/26 08:37:47 batch 274: mean=13.920000 stddev=6.793644 entropy=1.119522 frames=36222 count=50
2017/08/26 08:37:47 Training policy...
2017/08/26 08:37:58 step 0: objective=0.039788365
2017/08/26 08:38:07 step 1: objective=0.03987475
2017/08/26 08:38:17 step 2: objective=0.039961006
2017/08/26 08:38:26 step 3: objective=0.04004601
2017/08/26 08:38:35 step 4: objective=0.040121626
2017/08/26 08:38:45 step 5: objective=0.040174615
2017/08/26 08:38:54 step 6: objective=0.040224504
2017/08/26 08:39:03 step 7: objective=0.040282182
2017/08/26 08:39:03 Training value function...
2017/08/26 08:39:06 step 0: mse=1.087153 step=0.100000
2017/08/26 08:39:09 step 1: mse=1.045438 step=0.100000
2017/08/26 08:39:11 step 2: mse=1.002548 step=0.100000
2017/08/26 08:39:13 step 3: mse=0.967123 step=0.100000
2017/08/26 08:39:16 step 4: mse=0.939387 step=0.100000
2017/08/26 08:39:18 step 5: mse=0.899933 step=0.100000
2017/08/26 08:39:20 step 6: mse=0.868068 step=0.100000
2017/08/26 08:39:23 step 7: mse=0.845411 step=0.100000
2017/08/26 08:39:23 Saving...
2017/08/26 08:39:23 Gathering batch of experience...
2017/08/26 08:39:38 batch 275: mean=14.458333 stddev=6.399734 entropy=1.109285 frames=36329 count=48
2017/08/26 08:39:38 Training policy...
2017/08/26 08:39:49 step 0: objective=0.04535507
2017/08/26 08:39:58 step 1: objective=0.045410775
2017/08/26 08:40:08 step 2: objective=0.045465525
2017/08/26 08:40:17 step 3: objective=0.045520417
2017/08/26 08:40:26 step 4: objective=0.04557447
2017/08/26 08:40:36 step 5: objective=0.045625336
2017/08/26 08:40:45 step 6: objective=0.045719516
2017/08/26 08:40:54 step 7: objective=0.04580357
2017/08/26 08:40:54 Training value function...
2017/08/26 08:40:57 step 0: mse=0.952121 step=0.100000
2017/08/26 08:41:00 step 1: mse=0.893288 step=0.100000
2017/08/26 08:41:02 step 2: mse=0.844876 step=0.100000
2017/08/26 08:41:04 step 3: mse=0.803771 step=0.100000
2017/08/26 08:41:07 step 4: mse=0.769783 step=0.100000
2017/08/26 08:41:09 step 5: mse=0.742348 step=0.100000
2017/08/26 08:41:11 step 6: mse=0.707638 step=0.100000
2017/08/26 08:41:14 step 7: mse=0.687408 step=0.100000
2017/08/26 08:41:14 Saving...
2017/08/26 08:41:14 Gathering batch of experience...
2017/08/26 08:41:29 batch 276: mean=15.422222 stddev=7.472881 entropy=1.114201 frames=36204 count=45
2017/08/26 08:41:29 Training policy...
2017/08/26 08:41:40 step 0: objective=0.033726074
2017/08/26 08:41:49 step 1: objective=0.033772428
2017/08/26 08:41:59 step 2: objective=0.033818606
2017/08/26 08:42:08 step 3: objective=0.033864852
2017/08/26 08:42:17 step 4: objective=0.033911332
2017/08/26 08:42:27 step 5: objective=0.033957217
2017/08/26 08:42:36 step 6: objective=0.03398751
2017/08/26 08:42:46 step 7: objective=0.034019288
2017/08/26 08:42:46 Training value function...
2017/08/26 08:42:48 step 0: mse=0.797729 step=0.100000
2017/08/26 08:42:51 step 1: mse=0.752414 step=0.100000
2017/08/26 08:42:53 step 2: mse=0.716927 step=0.100000
2017/08/26 08:42:55 step 3: mse=0.685807 step=0.100000
2017/08/26 08:42:58 step 4: mse=0.659708 step=0.100000
2017/08/26 08:43:00 step 5: mse=0.636881 step=0.100000
2017/08/26 08:43:02 step 6: mse=0.603815 step=0.100000
2017/08/26 08:43:05 step 7: mse=0.578262 step=0.100000
2017/08/26 08:43:05 Saving...
2017/08/26 08:43:05 Gathering batch of experience...
2017/08/26 08:43:20 batch 277: mean=12.764706 stddev=5.289977 entropy=1.119066 frames=37101 count=51
2017/08/26 08:43:20 Training policy...
2017/08/26 08:43:32 step 0: objective=0.0013841889
2017/08/26 08:43:41 step 1: objective=0.0014239926
2017/08/26 08:43:51 step 2: objective=0.0014636057
2017/08/26 08:44:01 step 3: objective=0.0015030535
2017/08/26 08:44:10 step 4: objective=0.0015420737
2017/08/26 08:44:20 step 5: objective=0.0015804376
2017/08/26 08:44:30 step 6: objective=0.0016174554
2017/08/26 08:44:40 step 7: objective=0.0016585016
2017/08/26 08:44:40 Training value function...
2017/08/26 08:44:42 step 0: mse=0.606685 step=0.100000
2017/08/26 08:44:45 step 1: mse=0.579944 step=0.100000
2017/08/26 08:44:47 step 2: mse=0.556070 step=0.100000
2017/08/26 08:44:50 step 3: mse=0.533476 step=0.100000
2017/08/26 08:44:52 step 4: mse=0.516415 step=0.100000
2017/08/26 08:44:54 step 5: mse=0.498357 step=0.100000
2017/08/26 08:44:57 step 6: mse=0.480501 step=0.100000
2017/08/26 08:44:59 step 7: mse=0.458241 step=0.100000
2017/08/26 08:44:59 Saving...
2017/08/26 08:44:59 Gathering batch of experience...
2017/08/26 08:45:14 batch 278: mean=14.625000 stddev=6.960080 entropy=1.121002 frames=36610 count=48
2017/08/26 08:45:14 Training policy...
2017/08/26 08:45:25 step 0: objective=0.043066494
2017/08/26 08:45:35 step 1: objective=0.043120902
2017/08/26 08:45:45 step 2: objective=0.04317488
2017/08/26 08:45:55 step 3: objective=0.04322872
2017/08/26 08:46:04 step 4: objective=0.043278564
2017/08/26 08:46:14 step 5: objective=0.043331824
2017/08/26 08:46:24 step 6: objective=0.043362983
2017/08/26 08:46:33 step 7: objective=0.04339199
2017/08/26 08:46:33 Training value function...
2017/08/26 08:46:36 step 0: mse=1.033654 step=0.100000
2017/08/26 08:46:38 step 1: mse=0.961275 step=0.100000
2017/08/26 08:46:41 step 2: mse=0.903794 step=0.100000
2017/08/26 08:46:43 step 3: mse=0.854988 step=0.100000
2017/08/26 08:46:46 step 4: mse=0.813240 step=0.100000
2017/08/26 08:46:48 step 5: mse=0.781065 step=0.100000
2017/08/26 08:46:50 step 6: mse=0.747974 step=0.100000
2017/08/26 08:46:53 step 7: mse=0.723854 step=0.100000
2017/08/26 08:46:53 Saving...
2017/08/26 08:46:53 Gathering batch of experience...
2017/08/26 08:47:08 batch 279: mean=13.916667 stddev=5.559651 entropy=1.118385 frames=36504 count=48
2017/08/26 08:47:08 Training policy...
2017/08/26 08:47:19 step 0: objective=0.041012943
2017/08/26 08:47:30 step 1: objective=0.04105521
2017/08/26 08:47:39 step 2: objective=0.041097675
2017/08/26 08:47:49 step 3: objective=0.041139707
2017/08/26 08:47:58 step 4: objective=0.04118099
2017/08/26 08:48:08 step 5: objective=0.041224584
2017/08/26 08:48:17 step 6: objective=0.041266028
2017/08/26 08:48:27 step 7: objective=0.041321836
2017/08/26 08:48:27 Training value function...
2017/08/26 08:48:30 step 0: mse=0.640720 step=0.100000
2017/08/26 08:48:32 step 1: mse=0.608360 step=0.100000
2017/08/26 08:48:34 step 2: mse=0.586117 step=0.100000
2017/08/26 08:48:37 step 3: mse=0.568161 step=0.100000
2017/08/26 08:48:39 step 4: mse=0.553200 step=0.100000
2017/08/26 08:48:41 step 5: mse=0.537621 step=0.100000
2017/08/26 08:48:44 step 6: mse=0.524688 step=0.100000
2017/08/26 08:48:46 step 7: mse=0.514591 step=0.100000
2017/08/26 08:48:46 Saving...
2017/08/26 08:48:46 Gathering batch of experience...
2017/08/26 08:49:01 batch 280: mean=11.750000 stddev=4.462989 entropy=1.122904 frames=35665 count=52
2017/08/26 08:49:01 Training policy...
2017/08/26 08:49:12 step 0: objective=0.006276531
2017/08/26 08:49:21 step 1: objective=0.0063024084
2017/08/26 08:49:31 step 2: objective=0.0063285804
2017/08/26 08:49:40 step 3: objective=0.006355123
2017/08/26 08:49:49 step 4: objective=0.0063820584
2017/08/26 08:49:59 step 5: objective=0.006409327
2017/08/26 08:50:08 step 6: objective=0.0064289942
2017/08/26 08:50:18 step 7: objective=0.006445081
2017/08/26 08:50:18 Training value function...
2017/08/26 08:50:20 step 0: mse=0.538228 step=0.100000
2017/08/26 08:50:23 step 1: mse=0.500400 step=0.100000
2017/08/26 08:50:25 step 2: mse=0.470200 step=0.100000
2017/08/26 08:50:27 step 3: mse=0.445710 step=0.100000
2017/08/26 08:50:29 step 4: mse=0.425983 step=0.100000
2017/08/26 08:50:32 step 5: mse=0.410976 step=0.100000
2017/08/26 08:50:34 step 6: mse=0.391241 step=0.100000
2017/08/26 08:50:36 step 7: mse=0.380270 step=0.100000
2017/08/26 08:50:36 Saving...
2017/08/26 08:50:36 Gathering batch of experience...
2017/08/26 08:50:51 batch 281: mean=14.978261 stddev=5.173045 entropy=1.117324 frames=35538 count=46
2017/08/26 08:50:51 Training policy...
2017/08/26 08:51:02 step 0: objective=0.05216251
2017/08/26 08:51:11 step 1: objective=0.05219999
2017/08/26 08:51:21 step 2: objective=0.05223804
2017/08/26 08:51:31 step 3: objective=0.05227658
2017/08/26 08:51:40 step 4: objective=0.052302204
2017/08/26 08:51:50 step 5: objective=0.052333236
2017/08/26 08:51:59 step 6: objective=0.05235568
2017/08/26 08:52:09 step 7: objective=0.052388404
2017/08/26 08:52:09 Training value function...
2017/08/26 08:52:11 step 0: mse=0.896789 step=0.100000
2017/08/26 08:52:14 step 1: mse=0.840453 step=0.100000
2017/08/26 08:52:16 step 2: mse=0.794484 step=0.100000
2017/08/26 08:52:18 step 3: mse=0.756848 step=0.100000
2017/08/26 08:52:20 step 4: mse=0.725401 step=0.100000
2017/08/26 08:52:23 step 5: mse=0.698420 step=0.100000
2017/08/26 08:52:25 step 6: mse=0.675928 step=0.100000
2017/08/26 08:52:28 step 7: mse=0.655155 step=0.100000
2017/08/26 08:52:28 Saving...
2017/08/26 08:52:28 Gathering batch of experience...
2017/08/26 08:52:42 batch 282: mean=13.869565 stddev=5.663033 entropy=1.111482 frames=35251 count=46
2017/08/26 08:52:42 Training policy...
2017/08/26 08:52:53 step 0: objective=0.011307931
2017/08/26 08:53:03 step 1: objective=0.011368387
2017/08/26 08:53:12 step 2: objective=0.011429406
2017/08/26 08:53:21 step 3: objective=0.011490872
2017/08/26 08:53:30 step 4: objective=0.011550817
2017/08/26 08:53:40 step 5: objective=0.011611427
2017/08/26 08:53:49 step 6: objective=0.011675795
2017/08/26 08:53:58 step 7: objective=0.011714872
2017/08/26 08:53:58 Training value function...
2017/08/26 08:54:01 step 0: mse=0.620444 step=0.100000
2017/08/26 08:54:03 step 1: mse=0.585043 step=0.100000
2017/08/26 08:54:05 step 2: mse=0.556460 step=0.100000
2017/08/26 08:54:08 step 3: mse=0.533359 step=0.100000
2017/08/26 08:54:10 step 4: mse=0.514377 step=0.100000
2017/08/26 08:54:12 step 5: mse=0.494460 step=0.100000
2017/08/26 08:54:15 step 6: mse=0.481163 step=0.100000
2017/08/26 08:54:17 step 7: mse=0.471210 step=0.100000
2017/08/26 08:54:17 Saving...
2017/08/26 08:54:17 Gathering batch of experience...
2017/08/26 08:54:32 batch 283: mean=12.431373 stddev=4.875931 entropy=1.124333 frames=35765 count=51
2017/08/26 08:54:32 Training policy...
2017/08/26 08:54:43 step 0: objective=0.015843337
2017/08/26 08:54:52 step 1: objective=0.015899217
2017/08/26 08:55:02 step 2: objective=0.015956672
2017/08/26 08:55:11 step 3: objective=0.016000861
2017/08/26 08:55:21 step 4: objective=0.016047297
2017/08/26 08:55:30 step 5: objective=0.016083041
2017/08/26 08:55:40 step 6: objective=0.016118545
2017/08/26 08:55:49 step 7: objective=0.016153693
2017/08/26 08:55:49 Training value function...
2017/08/26 08:55:52 step 0: mse=0.582746 step=0.100000
2017/08/26 08:55:54 step 1: mse=0.548756 step=0.100000
2017/08/26 08:55:56 step 2: mse=0.520807 step=0.100000
2017/08/26 08:55:59 step 3: mse=0.498099 step=0.100000
2017/08/26 08:56:01 step 4: mse=0.478188 step=0.100000
2017/08/26 08:56:03 step 5: mse=0.460508 step=0.100000
2017/08/26 08:56:05 step 6: mse=0.449275 step=0.100000
2017/08/26 08:56:08 step 7: mse=0.438818 step=0.100000
2017/08/26 08:56:08 Saving...
2017/08/26 08:56:08 Gathering batch of experience...
2017/08/26 08:56:23 batch 284: mean=14.791667 stddev=5.660383 entropy=1.114514 frames=36688 count=48
2017/08/26 08:56:23 Training policy...
2017/08/26 08:56:35 step 0: objective=0.061993312
2017/08/26 08:56:44 step 1: objective=0.062088065
2017/08/26 08:56:54 step 2: objective=0.062182866
2017/08/26 08:57:04 step 3: objective=0.06227736
2017/08/26 08:57:14 step 4: objective=0.06234341
2017/08/26 08:57:23 step 5: objective=0.062397007
2017/08/26 08:57:33 step 6: objective=0.062461223
2017/08/26 08:57:43 step 7: objective=0.06252856
2017/08/26 08:57:43 Training value function...
2017/08/26 08:57:46 step 0: mse=0.886455 step=0.100000
2017/08/26 08:57:48 step 1: mse=0.826358 step=0.100000
2017/08/26 08:57:51 step 2: mse=0.777298 step=0.100000
2017/08/26 08:57:53 step 3: mse=0.737112 step=0.100000
2017/08/26 08:57:56 step 4: mse=0.700986 step=0.100000
2017/08/26 08:57:58 step 5: mse=0.671241 step=0.100000
2017/08/26 08:58:00 step 6: mse=0.648585 step=0.100000
2017/08/26 08:58:03 step 7: mse=0.628670 step=0.100000
2017/08/26 08:58:03 Saving...
2017/08/26 08:58:03 Gathering batch of experience...
2017/08/26 08:58:18 batch 285: mean=14.255319 stddev=4.373363 entropy=1.116331 frames=35825 count=47
2017/08/26 08:58:18 Training policy...
2017/08/26 08:58:29 step 0: objective=0.02254762
2017/08/26 08:58:38 step 1: objective=0.022619825
2017/08/26 08:58:48 step 2: objective=0.022691635
2017/08/26 08:58:58 step 3: objective=0.02276362
2017/08/26 08:59:08 step 4: objective=0.022834105
2017/08/26 08:59:17 step 5: objective=0.022868158
2017/08/26 08:59:27 step 6: objective=0.022899214
2017/08/26 08:59:37 step 7: objective=0.022947691
2017/08/26 08:59:37 Training value function...
2017/08/26 08:59:40 step 0: mse=0.599663 step=0.100000
2017/08/26 08:59:42 step 1: mse=0.568089 step=0.100000
2017/08/26 08:59:44 step 2: mse=0.542746 step=0.100000
2017/08/26 08:59:46 step 3: mse=0.522171 step=0.100000
2017/08/26 08:59:49 step 4: mse=0.504246 step=0.100000
2017/08/26 08:59:51 step 5: mse=0.489203 step=0.100000
2017/08/26 08:59:53 step 6: mse=0.477002 step=0.100000
2017/08/26 08:59:56 step 7: mse=0.466201 step=0.100000
2017/08/26 08:59:56 Saving...
2017/08/26 08:59:56 Gathering batch of experience...
2017/08/26 09:00:11 batch 286: mean=17.541667 stddev=11.047168 entropy=1.114049 frames=37799 count=48
2017/08/26 09:00:11 Training policy...
2017/08/26 09:00:23 step 0: objective=0.08765811
2017/08/26 09:00:33 step 1: objective=0.08771812
2017/08/26 09:00:43 step 2: objective=0.087777354
2017/08/26 09:00:53 step 3: objective=0.087833
2017/08/26 09:01:04 step 4: objective=0.08789753
2017/08/26 09:01:14 step 5: objective=0.08797083
2017/08/26 09:01:24 step 6: objective=0.088013135
2017/08/26 09:01:34 step 7: objective=0.08805445
2017/08/26 09:01:34 Training value function...
2017/08/26 09:01:37 step 0: mse=2.368009 step=0.100000
2017/08/26 09:01:39 step 1: mse=2.122933 step=0.100000
2017/08/26 09:01:42 step 2: mse=1.924595 step=0.100000
2017/08/26 09:01:44 step 3: mse=1.757109 step=0.100000
2017/08/26 09:01:46 step 4: mse=1.615108 step=0.100000
2017/08/26 09:01:49 step 5: mse=1.500589 step=0.100000
2017/08/26 09:01:51 step 6: mse=1.403398 step=0.100000
2017/08/26 09:01:54 step 7: mse=1.321433 step=0.100000
2017/08/26 09:01:54 Saving...
2017/08/26 09:01:54 Gathering batch of experience...
2017/08/26 09:02:09 batch 287: mean=13.829787 stddev=5.356718 entropy=1.117832 frames=35719 count=47
2017/08/26 09:02:09 Training policy...
2017/08/26 09:02:20 step 0: objective=-0.0031107874
2017/08/26 09:02:30 step 1: objective=-0.0030363305
2017/08/26 09:02:39 step 2: objective=-0.0029619972
2017/08/26 09:02:49 step 3: objective=-0.002887796
2017/08/26 09:02:58 step 4: objective=-0.0028170722
2017/08/26 09:03:08 step 5: objective=-0.0027701794
2017/08/26 09:03:18 step 6: objective=-0.0027336122
2017/08/26 09:03:27 step 7: objective=-0.0026957546
2017/08/26 09:03:27 Training value function...
2017/08/26 09:03:30 step 0: mse=0.739458 step=0.100000
2017/08/26 09:03:32 step 1: mse=0.692442 step=0.100000
2017/08/26 09:03:34 step 2: mse=0.654776 step=0.100000
2017/08/26 09:03:37 step 3: mse=0.619906 step=0.100000
2017/08/26 09:03:39 step 4: mse=0.592873 step=0.100000
2017/08/26 09:03:41 step 5: mse=0.571046 step=0.100000
2017/08/26 09:03:43 step 6: mse=0.551337 step=0.100000
2017/08/26 09:03:46 step 7: mse=0.520272 step=0.100000
2017/08/26 09:03:46 Saving...
2017/08/26 09:03:46 Gathering batch of experience...
2017/08/26 09:04:01 batch 288: mean=12.480000 stddev=5.899966 entropy=1.116097 frames=36283 count=50
2017/08/26 09:04:01 Training policy...
2017/08/26 09:04:13 step 0: objective=0.0019467053
2017/08/26 09:04:22 step 1: objective=0.0020190438
2017/08/26 09:04:32 step 2: objective=0.0020908858
2017/08/26 09:04:42 step 3: objective=0.0021622768
2017/08/26 09:04:52 step 4: objective=0.0022331858
2017/08/26 09:05:01 step 5: objective=0.0023010918
2017/08/26 09:05:11 step 6: objective=0.0023528638
2017/08/26 09:05:21 step 7: objective=0.0024150782
2017/08/26 09:05:21 Training value function...
2017/08/26 09:05:24 step 0: mse=0.688783 step=0.100000
2017/08/26 09:05:26 step 1: mse=0.641019 step=0.100000
2017/08/26 09:05:28 step 2: mse=0.582053 step=0.100000
2017/08/26 09:05:31 step 3: mse=0.534246 step=0.100000
2017/08/26 09:05:33 step 4: mse=0.495563 step=0.100000
2017/08/26 09:05:35 step 5: mse=0.468008 step=0.100000
2017/08/26 09:05:37 step 6: mse=0.440645 step=0.100000
2017/08/26 09:05:40 step 7: mse=0.426562 step=0.100000
2017/08/26 09:05:40 Saving...
2017/08/26 09:05:40 Gathering batch of experience...
2017/08/26 09:05:55 batch 289: mean=13.914894 stddev=6.263130 entropy=1.117570 frames=35196 count=47
2017/08/26 09:05:55 Training policy...
2017/08/26 09:06:06 step 0: objective=0.039851967
2017/08/26 09:06:16 step 1: objective=0.039910033
2017/08/26 09:06:25 step 2: objective=0.03996701
2017/08/26 09:06:35 step 3: objective=0.040023487
2017/08/26 09:06:44 step 4: objective=0.040076964
2017/08/26 09:06:54 step 5: objective=0.040123593
2017/08/26 09:07:03 step 6: objective=0.040167276
2017/08/26 09:07:13 step 7: objective=0.04019379
2017/08/26 09:07:13 Training value function...
2017/08/26 09:07:15 step 0: mse=0.786762 step=0.100000
2017/08/26 09:07:18 step 1: mse=0.745169 step=0.100000
2017/08/26 09:07:20 step 2: mse=0.706340 step=0.100000
2017/08/26 09:07:22 step 3: mse=0.673035 step=0.100000
2017/08/26 09:07:24 step 4: mse=0.641350 step=0.100000
2017/08/26 09:07:27 step 5: mse=0.615205 step=0.100000
2017/08/26 09:07:29 step 6: mse=0.591685 step=0.100000
2017/08/26 09:07:31 step 7: mse=0.572968 step=0.100000
2017/08/26 09:07:31 Saving...
2017/08/26 09:07:31 Gathering batch of experience...
2017/08/26 09:07:46 batch 290: mean=15.022222 stddev=6.269818 entropy=1.114582 frames=35230 count=45
2017/08/26 09:07:46 Training policy...
2017/08/26 09:07:57 step 0: objective=0.048363734
2017/08/26 09:08:07 step 1: objective=0.048404686
2017/08/26 09:08:16 step 2: objective=0.04854248
2017/08/26 09:08:26 step 3: objective=0.048679013
2017/08/26 09:08:35 step 4: objective=0.04874484
2017/08/26 09:08:45 step 5: objective=0.048810642
2017/08/26 09:08:54 step 6: objective=0.048870247
2017/08/26 09:09:04 step 7: objective=0.04891439
2017/08/26 09:09:04 Training value function...
2017/08/26 09:09:06 step 0: mse=0.832389 step=0.100000
2017/08/26 09:09:09 step 1: mse=0.779060 step=0.100000
2017/08/26 09:09:11 step 2: mse=0.735328 step=0.100000
2017/08/26 09:09:13 step 3: mse=0.699836 step=0.100000
2017/08/26 09:09:15 step 4: mse=0.671004 step=0.100000
2017/08/26 09:09:17 step 5: mse=0.646462 step=0.100000
2017/08/26 09:09:20 step 6: mse=0.623703 step=0.100000
2017/08/26 09:09:22 step 7: mse=0.605083 step=0.100000
2017/08/26 09:09:22 Saving...
2017/08/26 09:09:22 Gathering batch of experience...
2017/08/26 09:09:37 batch 291: mean=14.297872 stddev=6.367854 entropy=1.104664 frames=36405 count=47
2017/08/26 09:09:37 Training policy...
2017/08/26 09:09:49 step 0: objective=0.023830118
2017/08/26 09:09:59 step 1: objective=0.023874307
2017/08/26 09:10:09 step 2: objective=0.023918314
2017/08/26 09:10:18 step 3: objective=0.023962364
2017/08/26 09:10:28 step 4: objective=0.024005989
2017/08/26 09:10:38 step 5: objective=0.024048895
2017/08/26 09:10:48 step 6: objective=0.024082119
2017/08/26 09:10:58 step 7: objective=0.02409865
2017/08/26 09:10:58 Training value function...
2017/08/26 09:11:01 step 0: mse=0.782386 step=0.100000
2017/08/26 09:11:03 step 1: mse=0.738969 step=0.100000
2017/08/26 09:11:05 step 2: mse=0.703925 step=0.100000
2017/08/26 09:11:08 step 3: mse=0.675808 step=0.100000
2017/08/26 09:11:10 step 4: mse=0.653117 step=0.100000
2017/08/26 09:11:12 step 5: mse=0.634422 step=0.100000
2017/08/26 09:11:15 step 6: mse=0.609039 step=0.100000
2017/08/26 09:11:17 step 7: mse=0.594247 step=0.100000
2017/08/26 09:11:17 Saving...
2017/08/26 09:11:17 Gathering batch of experience...
2017/08/26 09:11:32 batch 292: mean=14.125000 stddev=6.320024 entropy=1.118741 frames=36119 count=48
2017/08/26 09:11:32 Training policy...
2017/08/26 09:11:44 step 0: objective=0.029502846
2017/08/26 09:11:54 step 1: objective=0.02960924
2017/08/26 09:12:04 step 2: objective=0.029715816
2017/08/26 09:12:13 step 3: objective=0.029806945
2017/08/26 09:12:23 step 4: objective=0.029853558
2017/08/26 09:12:33 step 5: objective=0.029893413
2017/08/26 09:12:43 step 6: objective=0.029955536
2017/08/26 09:12:53 step 7: objective=0.030017262
2017/08/26 09:12:53 Training value function...
2017/08/26 09:12:56 step 0: mse=1.106536 step=0.100000
2017/08/26 09:12:58 step 1: mse=1.034525 step=0.100000
2017/08/26 09:13:00 step 2: mse=0.976590 step=0.100000
2017/08/26 09:13:02 step 3: mse=0.919270 step=0.100000
2017/08/26 09:13:05 step 4: mse=0.879594 step=0.100000
2017/08/26 09:13:07 step 5: mse=0.839540 step=0.100000
2017/08/26 09:13:09 step 6: mse=0.811833 step=0.100000
2017/08/26 09:13:12 step 7: mse=0.788604 step=0.100000
2017/08/26 09:13:12 Saving...
2017/08/26 09:13:12 Gathering batch of experience...
2017/08/26 09:13:27 batch 293: mean=14.957447 stddev=6.280525 entropy=1.117659 frames=36706 count=47
2017/08/26 09:13:27 Training policy...
2017/08/26 09:13:39 step 0: objective=0.038908124
2017/08/26 09:13:49 step 1: objective=0.038955297
2017/08/26 09:13:59 step 2: objective=0.03900276
2017/08/26 09:14:09 step 3: objective=0.039050054
2017/08/26 09:14:19 step 4: objective=0.039108194
2017/08/26 09:14:29 step 5: objective=0.03916614
2017/08/26 09:14:39 step 6: objective=0.039233353
2017/08/26 09:14:49 step 7: objective=0.039262183
2017/08/26 09:14:49 Training value function...
2017/08/26 09:14:52 step 0: mse=0.874074 step=0.100000
2017/08/26 09:14:54 step 1: mse=0.810079 step=0.100000
2017/08/26 09:14:57 step 2: mse=0.756960 step=0.100000
2017/08/26 09:14:59 step 3: mse=0.714133 step=0.100000
2017/08/26 09:15:01 step 4: mse=0.687387 step=0.100000
2017/08/26 09:15:04 step 5: mse=0.663911 step=0.100000
2017/08/26 09:15:06 step 6: mse=0.636770 step=0.100000
2017/08/26 09:15:08 step 7: mse=0.617344 step=0.100000
2017/08/26 09:15:08 Saving...
2017/08/26 09:15:08 Gathering batch of experience...
2017/08/26 09:15:24 batch 294: mean=14.425532 stddev=6.515921 entropy=1.107950 frames=36270 count=47
2017/08/26 09:15:24 Training policy...
2017/08/26 09:15:35 step 0: objective=0.026394958
2017/08/26 09:15:46 step 1: objective=0.026421178
2017/08/26 09:15:56 step 2: objective=0.02644694
2017/08/26 09:16:05 step 3: objective=0.026472623
2017/08/26 09:16:16 step 4: objective=0.026498025
2017/08/26 09:16:26 step 5: objective=0.0265225
2017/08/26 09:16:36 step 6: objective=0.026547767
2017/08/26 09:16:45 step 7: objective=0.026570331
2017/08/26 09:16:45 Training value function...
2017/08/26 09:16:48 step 0: mse=0.799423 step=0.100000
2017/08/26 09:16:51 step 1: mse=0.742585 step=0.100000
2017/08/26 09:16:53 step 2: mse=0.697155 step=0.100000
2017/08/26 09:16:55 step 3: mse=0.653457 step=0.100000
2017/08/26 09:16:58 step 4: mse=0.617001 step=0.100000
2017/08/26 09:17:00 step 5: mse=0.589357 step=0.100000
2017/08/26 09:17:02 step 6: mse=0.567653 step=0.100000
2017/08/26 09:17:05 step 7: mse=0.544252 step=0.100000
2017/08/26 09:17:05 Saving...
2017/08/26 09:17:05 Gathering batch of experience...
2017/08/26 09:17:20 batch 295: mean=13.520833 stddev=5.086705 entropy=1.120459 frames=34990 count=48
2017/08/26 09:17:20 Training policy...
2017/08/26 09:17:31 step 0: objective=0.028545242
2017/08/26 09:17:40 step 1: objective=0.02861336
2017/08/26 09:17:50 step 2: objective=0.028681137
2017/08/26 09:17:59 step 3: objective=0.028748324
2017/08/26 09:18:09 step 4: objective=0.02881501
2017/08/26 09:18:19 step 5: objective=0.028874137
2017/08/26 09:18:29 step 6: objective=0.02894948
2017/08/26 09:18:38 step 7: objective=0.029018296
2017/08/26 09:18:38 Training value function...
2017/08/26 09:18:41 step 0: mse=0.890377 step=0.100000
2017/08/26 09:18:43 step 1: mse=0.828279 step=0.100000
2017/08/26 09:18:45 step 2: mse=0.778360 step=0.100000
2017/08/26 09:18:48 step 3: mse=0.732425 step=0.100000
2017/08/26 09:18:50 step 4: mse=0.693957 step=0.100000
2017/08/26 09:18:52 step 5: mse=0.663363 step=0.100000
2017/08/26 09:18:54 step 6: mse=0.638179 step=0.100000
2017/08/26 09:18:56 step 7: mse=0.617277 step=0.100000
2017/08/26 09:18:56 Saving...
2017/08/26 09:18:56 Gathering batch of experience...
2017/08/26 09:19:12 batch 296: mean=14.382979 stddev=5.393271 entropy=1.118125 frames=35941 count=47
2017/08/26 09:19:12 Training policy...
2017/08/26 09:19:23 step 0: objective=0.0353128
2017/08/26 09:19:33 step 1: objective=0.03534266
2017/08/26 09:19:44 step 2: objective=0.03537258
2017/08/26 09:19:54 step 3: objective=0.035401814
2017/08/26 09:20:04 step 4: objective=0.035431292
2017/08/26 09:20:13 step 5: objective=0.035460696
2017/08/26 09:20:23 step 6: objective=0.03548988
2017/08/26 09:20:33 step 7: objective=0.035549555
2017/08/26 09:20:33 Training value function...
2017/08/26 09:20:36 step 0: mse=0.775141 step=0.100000
2017/08/26 09:20:38 step 1: mse=0.727335 step=0.100000
2017/08/26 09:20:40 step 2: mse=0.683294 step=0.100000
2017/08/26 09:20:43 step 3: mse=0.650870 step=0.100000
2017/08/26 09:20:45 step 4: mse=0.619341 step=0.100000
2017/08/26 09:20:47 step 5: mse=0.593318 step=0.100000
2017/08/26 09:20:49 step 6: mse=0.581724 step=0.100000
2017/08/26 09:20:52 step 7: mse=0.569922 step=0.100000
2017/08/26 09:20:52 Saving...
2017/08/26 09:20:52 Gathering batch of experience...
2017/08/26 09:21:07 batch 297: mean=15.488889 stddev=6.943013 entropy=1.106879 frames=36308 count=45
2017/08/26 09:21:07 Training policy...
2017/08/26 09:21:19 step 0: objective=0.03250518
2017/08/26 09:21:29 step 1: objective=0.032577343
2017/08/26 09:21:40 step 2: objective=0.032649547
2017/08/26 09:21:50 step 3: objective=0.032721933
2017/08/26 09:22:00 step 4: objective=0.032793626
2017/08/26 09:22:10 step 5: objective=0.03285705
2017/08/26 09:22:20 step 6: objective=0.032940786
2017/08/26 09:22:30 step 7: objective=0.032984313
2017/08/26 09:22:30 Training value function...
2017/08/26 09:22:33 step 0: mse=0.893775 step=0.100000
2017/08/26 09:22:35 step 1: mse=0.836174 step=0.100000
2017/08/26 09:22:38 step 2: mse=0.802579 step=0.100000
2017/08/26 09:22:40 step 3: mse=0.763138 step=0.100000
2017/08/26 09:22:42 step 4: mse=0.725074 step=0.100000
2017/08/26 09:22:45 step 5: mse=0.712320 step=0.100000
2017/08/26 09:22:47 step 6: mse=0.686842 step=0.100000
2017/08/26 09:22:49 step 7: mse=0.672477 step=0.100000
2017/08/26 09:22:49 Saving...
2017/08/26 09:22:50 Gathering batch of experience...
2017/08/26 09:23:05 batch 298: mean=14.478261 stddev=6.240607 entropy=1.109635 frames=35526 count=46
2017/08/26 09:23:05 Training policy...
2017/08/26 09:23:16 step 0: objective=0.027400011
2017/08/26 09:23:26 step 1: objective=0.027467247
2017/08/26 09:23:36 step 2: objective=0.0275348
2017/08/26 09:23:45 step 3: objective=0.02760255
2017/08/26 09:23:55 step 4: objective=0.027670005
2017/08/26 09:24:05 step 5: objective=0.027740931
2017/08/26 09:24:15 step 6: objective=0.027812818
2017/08/26 09:24:25 step 7: objective=0.027863318
2017/08/26 09:24:25 Training value function...
2017/08/26 09:24:27 step 0: mse=0.791415 step=0.100000
2017/08/26 09:24:30 step 1: mse=0.746794 step=0.100000
2017/08/26 09:24:32 step 2: mse=0.710196 step=0.100000
2017/08/26 09:24:34 step 3: mse=0.672451 step=0.100000
2017/08/26 09:24:37 step 4: mse=0.639093 step=0.100000
2017/08/26 09:24:39 step 5: mse=0.614091 step=0.100000
2017/08/26 09:24:42 step 6: mse=0.596068 step=0.100000
2017/08/26 09:24:44 step 7: mse=0.573179 step=0.100000
2017/08/26 09:24:44 Saving...
2017/08/26 09:24:44 Gathering batch of experience...
2017/08/26 09:24:59 batch 299: mean=14.173913 stddev=5.541560 entropy=1.112320 frames=35667 count=46
2017/08/26 09:24:59 Training policy...
2017/08/26 09:25:10 step 0: objective=0.019421471
2017/08/26 09:25:21 step 1: objective=0.019454725
2017/08/26 09:25:31 step 2: objective=0.019487964
2017/08/26 09:25:40 step 3: objective=0.019521425
2017/08/26 09:25:50 step 4: objective=0.019554863
2017/08/26 09:26:00 step 5: objective=0.019588662
2017/08/26 09:26:10 step 6: objective=0.019622572
2017/08/26 09:26:20 step 7: objective=0.019655827
2017/08/26 09:26:20 Training value function...
2017/08/26 09:26:23 step 0: mse=0.926977 step=0.100000
2017/08/26 09:26:25 step 1: mse=0.862767 step=0.100000
2017/08/26 09:26:27 step 2: mse=0.810837 step=0.100000
2017/08/26 09:26:29 step 3: mse=0.764996 step=0.100000
2017/08/26 09:26:32 step 4: mse=0.729233 step=0.100000
2017/08/26 09:26:34 step 5: mse=0.694825 step=0.100000
2017/08/26 09:26:36 step 6: mse=0.667054 step=0.100000
2017/08/26 09:26:38 step 7: mse=0.649037 step=0.100000
2017/08/26 09:26:38 Saving...
2017/08/26 09:26:38 Gathering batch of experience...
2017/08/26 09:26:54 batch 300: mean=13.061224 stddev=5.426346 entropy=1.119624 frames=35568 count=49
2017/08/26 09:26:54 Training policy...
2017/08/26 09:27:05 step 0: objective=0.024338823
2017/08/26 09:27:15 step 1: objective=0.024376294
2017/08/26 09:27:25 step 2: objective=0.02441353
2017/08/26 09:27:35 step 3: objective=0.024450574
2017/08/26 09:27:45 step 4: objective=0.02450025
2017/08/26 09:27:55 step 5: objective=0.024549605
2017/08/26 09:28:05 step 6: objective=0.024598893
2017/08/26 09:28:15 step 7: objective=0.024647877
2017/08/26 09:28:15 Training value function...
2017/08/26 09:28:17 step 0: mse=0.764955 step=0.100000
2017/08/26 09:28:20 step 1: mse=0.720747 step=0.100000
2017/08/26 09:28:22 step 2: mse=0.683513 step=0.100000
2017/08/26 09:28:24 step 3: mse=0.651596 step=0.100000
2017/08/26 09:28:26 step 4: mse=0.626640 step=0.100000
2017/08/26 09:28:29 step 5: mse=0.606227 step=0.100000
2017/08/26 09:28:31 step 6: mse=0.589567 step=0.100000
2017/08/26 09:28:33 step 7: mse=0.575292 step=0.100000
2017/08/26 09:28:33 Saving...
2017/08/26 09:28:33 Gathering batch of experience...
2017/08/26 09:28:48 batch 301: mean=14.000000 stddev=5.852350 entropy=1.120109 frames=35592 count=48
2017/08/26 09:28:48 Training policy...
2017/08/26 09:29:00 step 0: objective=0.033295024
2017/08/26 09:29:10 step 1: objective=0.0333285
2017/08/26 09:29:20 step 2: objective=0.033362087
2017/08/26 09:29:29 step 3: objective=0.03339573
2017/08/26 09:29:39 step 4: objective=0.0334294
2017/08/26 09:29:49 step 5: objective=0.03346322
2017/08/26 09:29:59 step 6: objective=0.033493355
2017/08/26 09:30:09 step 7: objective=0.033539522
2017/08/26 09:30:09 Training value function...
2017/08/26 09:30:12 step 0: mse=0.776807 step=0.100000
2017/08/26 09:30:14 step 1: mse=0.737056 step=0.100000
2017/08/26 09:30:17 step 2: mse=0.689141 step=0.100000
2017/08/26 09:30:19 step 3: mse=0.650511 step=0.100000
2017/08/26 09:30:21 step 4: mse=0.624558 step=0.100000
2017/08/26 09:30:23 step 5: mse=0.594850 step=0.100000
2017/08/26 09:30:26 step 6: mse=0.569151 step=0.100000
2017/08/26 09:30:28 step 7: mse=0.545803 step=0.100000
2017/08/26 09:30:28 Saving...
2017/08/26 09:30:28 Gathering batch of experience...
2017/08/26 09:30:43 batch 302: mean=13.062500 stddev=5.351815 entropy=1.125503 frames=35134 count=48
2017/08/26 09:30:43 Training policy...
2017/08/26 09:30:54 step 0: objective=0.011044028
2017/08/26 09:31:04 step 1: objective=0.0110686915
2017/08/26 09:31:14 step 2: objective=0.011093303
2017/08/26 09:31:24 step 3: objective=0.011117845
2017/08/26 09:31:33 step 4: objective=0.011142362
2017/08/26 09:31:43 step 5: objective=0.011166292
2017/08/26 09:31:53 step 6: objective=0.011196442
2017/08/26 09:32:03 step 7: objective=0.011216837
2017/08/26 09:32:03 Training value function...
2017/08/26 09:32:06 step 0: mse=0.664397 step=0.100000
2017/08/26 09:32:08 step 1: mse=0.640270 step=0.100000
2017/08/26 09:32:11 step 2: mse=0.620968 step=0.100000
2017/08/26 09:32:13 step 3: mse=0.605340 step=0.100000
2017/08/26 09:32:15 step 4: mse=0.584919 step=0.100000
2017/08/26 09:32:17 step 5: mse=0.571840 step=0.100000
2017/08/26 09:32:20 step 6: mse=0.554726 step=0.100000
2017/08/26 09:32:22 step 7: mse=0.542468 step=0.100000
2017/08/26 09:32:22 Saving...
2017/08/26 09:32:22 Gathering batch of experience...
2017/08/26 09:32:37 batch 303: mean=13.360000 stddev=6.114769 entropy=1.116370 frames=36353 count=50
2017/08/26 09:32:37 Training policy...
2017/08/26 09:32:49 step 0: objective=0.037143853
2017/08/26 09:32:59 step 1: objective=0.0371794
2017/08/26 09:33:09 step 2: objective=0.037215263
2017/08/26 09:33:19 step 3: objective=0.03725125
2017/08/26 09:33:29 step 4: objective=0.03728689
2017/08/26 09:33:40 step 5: objective=0.037321687
2017/08/26 09:33:50 step 6: objective=0.037350997
2017/08/26 09:34:00 step 7: objective=0.03737441
2017/08/26 09:34:00 Training value function...
2017/08/26 09:34:03 step 0: mse=0.830911 step=0.100000
2017/08/26 09:34:05 step 1: mse=0.781257 step=0.100000
2017/08/26 09:34:07 step 2: mse=0.738073 step=0.100000
2017/08/26 09:34:10 step 3: mse=0.700278 step=0.100000
2017/08/26 09:34:12 step 4: mse=0.672485 step=0.100000
2017/08/26 09:34:14 step 5: mse=0.644858 step=0.100000
2017/08/26 09:34:17 step 6: mse=0.624695 step=0.100000
2017/08/26 09:34:19 step 7: mse=0.607588 step=0.100000
2017/08/26 09:34:19 Saving...
2017/08/26 09:34:19 Gathering batch of experience...
2017/08/26 09:34:34 batch 304: mean=15.022222 stddev=5.682288 entropy=1.104126 frames=36121 count=45
2017/08/26 09:34:34 Training policy...
2017/08/26 09:34:46 step 0: objective=0.03134314
2017/08/26 09:34:56 step 1: objective=0.031417776
2017/08/26 09:35:07 step 2: objective=0.031494245
2017/08/26 09:35:17 step 3: objective=0.03155119
2017/08/26 09:35:27 step 4: objective=0.031604387
2017/08/26 09:35:37 step 5: objective=0.031645775
2017/08/26 09:35:47 step 6: objective=0.031681087
2017/08/26 09:35:57 step 7: objective=0.03171581
2017/08/26 09:35:57 Training value function...
2017/08/26 09:36:00 step 0: mse=0.804009 step=0.100000
2017/08/26 09:36:02 step 1: mse=0.755871 step=0.100000
2017/08/26 09:36:05 step 2: mse=0.716450 step=0.100000
2017/08/26 09:36:07 step 3: mse=0.683958 step=0.100000
2017/08/26 09:36:09 step 4: mse=0.655410 step=0.100000
2017/08/26 09:36:12 step 5: mse=0.634921 step=0.100000
2017/08/26 09:36:14 step 6: mse=0.615990 step=0.100000
2017/08/26 09:36:17 step 7: mse=0.600176 step=0.100000
2017/08/26 09:36:17 Saving...
2017/08/26 09:36:17 Gathering batch of experience...
2017/08/26 09:36:32 batch 305: mean=14.125000 stddev=8.405417 entropy=1.112293 frames=36425 count=48
2017/08/26 09:36:32 Training policy...
2017/08/26 09:36:44 step 0: objective=0.032505114
2017/08/26 09:36:54 step 1: objective=0.0325728
2017/08/26 09:37:05 step 2: objective=0.032640506
2017/08/26 09:37:15 step 3: objective=0.032707985
2017/08/26 09:37:25 step 4: objective=0.032775216
2017/08/26 09:37:36 step 5: objective=0.03283903
2017/08/26 09:37:46 step 6: objective=0.03291129
2017/08/26 09:37:57 step 7: objective=0.032973737
2017/08/26 09:37:57 Training value function...
2017/08/26 09:38:00 step 0: mse=0.925987 step=0.100000
2017/08/26 09:38:02 step 1: mse=0.870511 step=0.100000
2017/08/26 09:38:04 step 2: mse=0.825087 step=0.100000
2017/08/26 09:38:07 step 3: mse=0.786599 step=0.100000
2017/08/26 09:38:09 step 4: mse=0.753245 step=0.100000
2017/08/26 09:38:11 step 5: mse=0.726910 step=0.100000
2017/08/26 09:38:14 step 6: mse=0.704452 step=0.100000
2017/08/26 09:38:16 step 7: mse=0.684986 step=0.100000
2017/08/26 09:38:16 Saving...
2017/08/26 09:38:16 Gathering batch of experience...
2017/08/26 09:38:32 batch 306: mean=15.468085 stddev=6.607060 entropy=1.106409 frames=37254 count=47
2017/08/26 09:38:32 Training policy...
2017/08/26 09:38:44 step 0: objective=0.051813815
2017/08/26 09:38:55 step 1: objective=0.05187549
2017/08/26 09:39:06 step 2: objective=0.05193784
2017/08/26 09:39:16 step 3: objective=0.05199968
2017/08/26 09:39:27 step 4: objective=0.052055307
2017/08/26 09:39:37 step 5: objective=0.052119996
2017/08/26 09:39:48 step 6: objective=0.052162148
2017/08/26 09:39:58 step 7: objective=0.05219824
2017/08/26 09:39:58 Training value function...
2017/08/26 09:40:01 step 0: mse=0.958832 step=0.100000
2017/08/26 09:40:04 step 1: mse=0.889892 step=0.100000
2017/08/26 09:40:06 step 2: mse=0.831556 step=0.100000
2017/08/26 09:40:08 step 3: mse=0.785207 step=0.100000
2017/08/26 09:40:11 step 4: mse=0.746212 step=0.100000
2017/08/26 09:40:13 step 5: mse=0.713501 step=0.100000
2017/08/26 09:40:15 step 6: mse=0.680062 step=0.100000
2017/08/26 09:40:18 step 7: mse=0.654014 step=0.100000
2017/08/26 09:40:18 Saving...
2017/08/26 09:40:18 Gathering batch of experience...
2017/08/26 09:40:33 batch 307: mean=15.088889 stddev=6.039949 entropy=1.111557 frames=35436 count=45
2017/08/26 09:40:33 Training policy...
2017/08/26 09:40:45 step 0: objective=0.024749607
2017/08/26 09:40:55 step 1: objective=0.024835248
2017/08/26 09:41:05 step 2: objective=0.024920031
2017/08/26 09:41:15 step 3: objective=0.025004243
2017/08/26 09:41:25 step 4: objective=0.025079079
2017/08/26 09:41:35 step 5: objective=0.02511903
2017/08/26 09:41:45 step 6: objective=0.02516658
2017/08/26 09:41:55 step 7: objective=0.025210662
2017/08/26 09:41:55 Training value function...
2017/08/26 09:41:58 step 0: mse=0.874261 step=0.100000
2017/08/26 09:42:00 step 1: mse=0.823666 step=0.100000
2017/08/26 09:42:02 step 2: mse=0.780430 step=0.100000
2017/08/26 09:42:05 step 3: mse=0.738464 step=0.100000
2017/08/26 09:42:07 step 4: mse=0.708684 step=0.100000
2017/08/26 09:42:09 step 5: mse=0.680777 step=0.100000
2017/08/26 09:42:12 step 6: mse=0.656575 step=0.100000
2017/08/26 09:42:14 step 7: mse=0.639974 step=0.100000
2017/08/26 09:42:14 Saving...
2017/08/26 09:42:14 Gathering batch of experience...
2017/08/26 09:42:29 batch 308: mean=16.340909 stddev=8.073366 entropy=1.106781 frames=36307 count=44
2017/08/26 09:42:29 Training policy...
2017/08/26 09:42:41 step 0: objective=0.05355796
2017/08/26 09:42:52 step 1: objective=0.053673357
2017/08/26 09:43:02 step 2: objective=0.053788807
2017/08/26 09:43:12 step 3: objective=0.053897496
2017/08/26 09:43:22 step 4: objective=0.053947542
2017/08/26 09:43:33 step 5: objective=0.053995844
2017/08/26 09:43:43 step 6: objective=0.054034345
2017/08/26 09:43:54 step 7: objective=0.054094516
2017/08/26 09:43:54 Training value function...
2017/08/26 09:43:56 step 0: mse=1.256880 step=0.100000
2017/08/26 09:43:59 step 1: mse=1.148984 step=0.100000
2017/08/26 09:44:01 step 2: mse=1.062066 step=0.100000
2017/08/26 09:44:03 step 3: mse=0.989906 step=0.100000
2017/08/26 09:44:06 step 4: mse=0.931688 step=0.100000
2017/08/26 09:44:08 step 5: mse=0.884530 step=0.100000
2017/08/26 09:44:10 step 6: mse=0.842702 step=0.100000
2017/08/26 09:44:13 step 7: mse=0.802377 step=0.100000
2017/08/26 09:44:13 Saving...
2017/08/26 09:44:13 Gathering batch of experience...
2017/08/26 09:44:28 batch 309: mean=13.775510 stddev=5.463292 entropy=1.110620 frames=36302 count=49
2017/08/26 09:44:28 Training policy...
2017/08/26 09:44:40 step 0: objective=0.016915005
2017/08/26 09:44:51 step 1: objective=0.016967297
2017/08/26 09:45:01 step 2: objective=0.017019873
2017/08/26 09:45:12 step 3: objective=0.017072938
2017/08/26 09:45:22 step 4: objective=0.017126277
2017/08/26 09:45:32 step 5: objective=0.017174643
2017/08/26 09:45:43 step 6: objective=0.017228242
2017/08/26 09:45:53 step 7: objective=0.01726554
2017/08/26 09:45:53 Training value function...
2017/08/26 09:45:56 step 0: mse=0.817868 step=0.100000
2017/08/26 09:45:58 step 1: mse=0.780330 step=0.100000
2017/08/26 09:46:01 step 2: mse=0.749923 step=0.100000
2017/08/26 09:46:03 step 3: mse=0.718422 step=0.100000
2017/08/26 09:46:05 step 4: mse=0.692810 step=0.100000
2017/08/26 09:46:07 step 5: mse=0.670814 step=0.100000
2017/08/26 09:46:10 step 6: mse=0.652141 step=0.100000
2017/08/26 09:46:12 step 7: mse=0.633670 step=0.100000
2017/08/26 09:46:12 Saving...
2017/08/26 09:46:12 Gathering batch of experience...
2017/08/26 09:46:27 batch 310: mean=14.478261 stddev=5.792571 entropy=1.113979 frames=35500 count=46
2017/08/26 09:46:27 Training policy...
2017/08/26 09:46:39 step 0: objective=0.020191304
2017/08/26 09:46:49 step 1: objective=0.02026967
2017/08/26 09:46:59 step 2: objective=0.020348048
2017/08/26 09:47:10 step 3: objective=0.02042561
2017/08/26 09:47:20 step 4: objective=0.02049468
2017/08/26 09:47:30 step 5: objective=0.02056797
2017/08/26 09:47:41 step 6: objective=0.02063032
2017/08/26 09:47:51 step 7: objective=0.020697743
2017/08/26 09:47:51 Training value function...
2017/08/26 09:47:53 step 0: mse=0.902505 step=0.100000
2017/08/26 09:47:56 step 1: mse=0.854035 step=0.100000
2017/08/26 09:47:58 step 2: mse=0.815053 step=0.100000
2017/08/26 09:48:00 step 3: mse=0.780333 step=0.100000
2017/08/26 09:48:02 step 4: mse=0.752414 step=0.100000
2017/08/26 09:48:05 step 5: mse=0.730337 step=0.100000
2017/08/26 09:48:07 step 6: mse=0.699174 step=0.100000
2017/08/26 09:48:09 step 7: mse=0.680727 step=0.100000
2017/08/26 09:48:09 Saving...
2017/08/26 09:48:09 Gathering batch of experience...
2017/08/26 09:48:24 batch 311: mean=14.632653 stddev=6.564263 entropy=1.117341 frames=36068 count=49
2017/08/26 09:48:24 Training policy...
2017/08/26 09:48:36 step 0: objective=0.045304615
2017/08/26 09:48:47 step 1: objective=0.04535897
2017/08/26 09:48:57 step 2: objective=0.045413233
2017/08/26 09:49:08 step 3: objective=0.04546805
2017/08/26 09:49:18 step 4: objective=0.04552003
2017/08/26 09:49:29 step 5: objective=0.045560658
2017/08/26 09:49:39 step 6: objective=0.045600682
2017/08/26 09:49:50 step 7: objective=0.04563933
2017/08/26 09:49:50 Training value function...
2017/08/26 09:49:53 step 0: mse=1.071778 step=0.100000
2017/08/26 09:49:55 step 1: mse=1.000619 step=0.100000
2017/08/26 09:49:57 step 2: mse=0.940355 step=0.100000
2017/08/26 09:50:00 step 3: mse=0.883510 step=0.100000
2017/08/26 09:50:02 step 4: mse=0.842783 step=0.100000
2017/08/26 09:50:04 step 5: mse=0.798214 step=0.100000
2017/08/26 09:50:06 step 6: mse=0.759314 step=0.100000
2017/08/26 09:50:09 step 7: mse=0.731844 step=0.100000
2017/08/26 09:50:09 Saving...
2017/08/26 09:50:09 Gathering batch of experience...
2017/08/26 09:50:24 batch 312: mean=14.891304 stddev=6.069268 entropy=1.110283 frames=35982 count=46
2017/08/26 09:50:24 Training policy...
2017/08/26 09:50:36 step 0: objective=0.03136066
2017/08/26 09:50:46 step 1: objective=0.03139478
2017/08/26 09:50:57 step 2: objective=0.031428505
2017/08/26 09:51:07 step 3: objective=0.031461947
2017/08/26 09:51:18 step 4: objective=0.031495076
2017/08/26 09:51:28 step 5: objective=0.031527545
2017/08/26 09:51:38 step 6: objective=0.0315539
2017/08/26 09:51:49 step 7: objective=0.03159359
2017/08/26 09:51:49 Training value function...
2017/08/26 09:51:51 step 0: mse=0.941632 step=0.100000
2017/08/26 09:51:54 step 1: mse=0.879429 step=0.100000
2017/08/26 09:51:56 step 2: mse=0.828880 step=0.100000
2017/08/26 09:51:58 step 3: mse=0.784534 step=0.100000
2017/08/26 09:52:01 step 4: mse=0.748636 step=0.100000
2017/08/26 09:52:03 step 5: mse=0.714695 step=0.100000
2017/08/26 09:52:05 step 6: mse=0.687684 step=0.100000
2017/08/26 09:52:08 step 7: mse=0.667778 step=0.100000
2017/08/26 09:52:08 Saving...
2017/08/26 09:52:08 Gathering batch of experience...
2017/08/26 09:52:23 batch 313: mean=12.959184 stddev=5.158544 entropy=1.110812 frames=36600 count=49
2017/08/26 09:52:23 Training policy...
2017/08/26 09:52:36 step 0: objective=-0.011451438
2017/08/26 09:52:46 step 1: objective=-0.011427308
2017/08/26 09:52:57 step 2: objective=-0.011402982
2017/08/26 09:53:08 step 3: objective=-0.01137829
2017/08/26 09:53:18 step 4: objective=-0.011353475
2017/08/26 09:53:29 step 5: objective=-0.011329022
2017/08/26 09:53:39 step 6: objective=-0.011296901
2017/08/26 09:53:50 step 7: objective=-0.011264317
2017/08/26 09:53:50 Training value function...
2017/08/26 09:53:53 step 0: mse=0.622301 step=0.100000
2017/08/26 09:53:55 step 1: mse=0.588302 step=0.100000
2017/08/26 09:53:57 step 2: mse=0.563901 step=0.100000
2017/08/26 09:53:59 step 3: mse=0.538549 step=0.100000
2017/08/26 09:54:02 step 4: mse=0.511530 step=0.100000
2017/08/26 09:54:04 step 5: mse=0.494133 step=0.100000
2017/08/26 09:54:06 step 6: mse=0.472645 step=0.100000
2017/08/26 09:54:09 step 7: mse=0.461356 step=0.100000
2017/08/26 09:54:09 Saving...
2017/08/26 09:54:09 Gathering batch of experience...
2017/08/26 09:54:24 batch 314: mean=14.687500 stddev=6.961670 entropy=1.113528 frames=36454 count=48
2017/08/26 09:54:24 Training policy...
2017/08/26 09:54:37 step 0: objective=0.04829505
2017/08/26 09:54:48 step 1: objective=0.048346736
2017/08/26 09:54:59 step 2: objective=0.048397385
2017/08/26 09:55:09 step 3: objective=0.048447523
2017/08/26 09:55:20 step 4: objective=0.04849462
2017/08/26 09:55:31 step 5: objective=0.048533674
2017/08/26 09:55:41 step 6: objective=0.048588123
2017/08/26 09:55:52 step 7: objective=0.04863556
2017/08/26 09:55:52 Training value function...
2017/08/26 09:55:55 step 0: mse=1.084317 step=0.100000
2017/08/26 09:55:57 step 1: mse=1.009659 step=0.100000
2017/08/26 09:55:59 step 2: mse=0.953661 step=0.100000
2017/08/26 09:56:02 step 3: mse=0.907171 step=0.100000
2017/08/26 09:56:04 step 4: mse=0.866911 step=0.100000
2017/08/26 09:56:06 step 5: mse=0.833302 step=0.100000
2017/08/26 09:56:09 step 6: mse=0.800871 step=0.100000
2017/08/26 09:56:11 step 7: mse=0.776372 step=0.100000
2017/08/26 09:56:11 Saving...
2017/08/26 09:56:11 Gathering batch of experience...
2017/08/26 09:56:27 batch 315: mean=16.111111 stddev=6.201155 entropy=1.110098 frames=36657 count=45
2017/08/26 09:56:27 Training policy...
2017/08/26 09:56:39 step 0: objective=0.04028315
2017/08/26 09:56:50 step 1: objective=0.04032861
2017/08/26 09:57:00 step 2: objective=0.04037361
2017/08/26 09:57:11 step 3: objective=0.040418863
2017/08/26 09:57:22 step 4: objective=0.040462434
2017/08/26 09:57:32 step 5: objective=0.040492505
2017/08/26 09:57:43 step 6: objective=0.04051826
2017/08/26 09:57:54 step 7: objective=0.04053954
2017/08/26 09:57:54 Training value function...
2017/08/26 09:57:57 step 0: mse=0.909326 step=0.100000
2017/08/26 09:57:59 step 1: mse=0.845214 step=0.100000
2017/08/26 09:58:01 step 2: mse=0.793396 step=0.100000
2017/08/26 09:58:04 step 3: mse=0.751798 step=0.100000
2017/08/26 09:58:06 step 4: mse=0.713811 step=0.100000
2017/08/26 09:58:08 step 5: mse=0.681217 step=0.100000
2017/08/26 09:58:11 step 6: mse=0.654377 step=0.100000
2017/08/26 09:58:13 step 7: mse=0.627793 step=0.100000
2017/08/26 09:58:13 Saving...
2017/08/26 09:58:13 Gathering batch of experience...
2017/08/26 09:58:29 batch 316: mean=14.395833 stddev=6.759991 entropy=1.111698 frames=36444 count=48
2017/08/26 09:58:29 Training policy...
2017/08/26 09:58:41 step 0: objective=0.0284062
2017/08/26 09:58:52 step 1: objective=0.028448958
2017/08/26 09:59:02 step 2: objective=0.028492382
2017/08/26 09:59:13 step 3: objective=0.028536156
2017/08/26 09:59:23 step 4: objective=0.028575929
2017/08/26 09:59:34 step 5: objective=0.028609015
2017/08/26 09:59:44 step 6: objective=0.028642926
2017/08/26 09:59:55 step 7: objective=0.028676692
2017/08/26 09:59:55 Training value function...
2017/08/26 09:59:58 step 0: mse=0.818858 step=0.100000
2017/08/26 10:00:00 step 1: mse=0.761163 step=0.100000
2017/08/26 10:00:03 step 2: mse=0.710667 step=0.100000
2017/08/26 10:00:05 step 3: mse=0.669775 step=0.100000
2017/08/26 10:00:07 step 4: mse=0.636465 step=0.100000
2017/08/26 10:00:10 step 5: mse=0.613555 step=0.100000
2017/08/26 10:00:12 step 6: mse=0.594763 step=0.100000
2017/08/26 10:00:14 step 7: mse=0.577409 step=0.100000
2017/08/26 10:00:14 Saving...
2017/08/26 10:00:14 Gathering batch of experience...
2017/08/26 10:00:30 batch 317: mean=15.222222 stddev=7.317829 entropy=1.107344 frames=35826 count=45
2017/08/26 10:00:30 Training policy...
2017/08/26 10:00:43 step 0: objective=0.013723086
2017/08/26 10:00:54 step 1: objective=0.0138019025
2017/08/26 10:01:05 step 2: objective=0.013879967
2017/08/26 10:01:15 step 3: objective=0.01395742
2017/08/26 10:01:25 step 4: objective=0.01403178
2017/08/26 10:01:36 step 5: objective=0.014092659
2017/08/26 10:01:46 step 6: objective=0.014149534
2017/08/26 10:01:57 step 7: objective=0.014212857
2017/08/26 10:01:57 Training value function...
2017/08/26 10:02:00 step 0: mse=0.994681 step=0.100000
2017/08/26 10:02:02 step 1: mse=0.931919 step=0.100000
2017/08/26 10:02:04 step 2: mse=0.876516 step=0.100000
2017/08/26 10:02:07 step 3: mse=0.848986 step=0.100000
2017/08/26 10:02:09 step 4: mse=0.809275 step=0.100000
2017/08/26 10:02:11 step 5: mse=0.777080 step=0.100000
2017/08/26 10:02:14 step 6: mse=0.756845 step=0.100000
2017/08/26 10:02:16 step 7: mse=0.740925 step=0.100000
2017/08/26 10:02:16 Saving...
2017/08/26 10:02:16 Gathering batch of experience...
2017/08/26 10:02:32 batch 318: mean=14.448980 stddev=7.125869 entropy=1.110086 frames=36812 count=49
2017/08/26 10:02:32 Training policy...
2017/08/26 10:02:44 step 0: objective=0.045172982
2017/08/26 10:02:55 step 1: objective=0.045208547
2017/08/26 10:03:06 step 2: objective=0.045244824
2017/08/26 10:03:17 step 3: objective=0.045280196
2017/08/26 10:03:27 step 4: objective=0.04531555
2017/08/26 10:03:38 step 5: objective=0.045350324
2017/08/26 10:03:49 step 6: objective=0.045380272
2017/08/26 10:04:00 step 7: objective=0.04540878
2017/08/26 10:04:00 Training value function...
2017/08/26 10:04:03 step 0: mse=1.104218 step=0.100000
2017/08/26 10:04:05 step 1: mse=1.013847 step=0.100000
2017/08/26 10:04:07 step 2: mse=0.940137 step=0.100000
2017/08/26 10:04:10 step 3: mse=0.880744 step=0.100000
2017/08/26 10:04:12 step 4: mse=0.826763 step=0.100000
2017/08/26 10:04:14 step 5: mse=0.786793 step=0.100000
2017/08/26 10:04:17 step 6: mse=0.749770 step=0.100000
2017/08/26 10:04:19 step 7: mse=0.721374 step=0.100000
2017/08/26 10:04:19 Saving...
2017/08/26 10:04:19 Gathering batch of experience...
2017/08/26 10:04:35 batch 319: mean=13.617021 stddev=5.583232 entropy=1.112967 frames=36093 count=47
2017/08/26 10:04:35 Training policy...
2017/08/26 10:04:47 step 0: objective=0.00941298
2017/08/26 10:04:57 step 1: objective=0.009441722
2017/08/26 10:05:08 step 2: objective=0.009470377
2017/08/26 10:05:19 step 3: objective=0.009499085
2017/08/26 10:05:29 step 4: objective=0.009527666
2017/08/26 10:05:40 step 5: objective=0.009556336
2017/08/26 10:05:51 step 6: objective=0.009584746
2017/08/26 10:06:01 step 7: objective=0.009609005
2017/08/26 10:06:01 Training value function...
2017/08/26 10:06:04 step 0: mse=0.581477 step=0.100000
2017/08/26 10:06:06 step 1: mse=0.552841 step=0.100000
2017/08/26 10:06:09 step 2: mse=0.532327 step=0.100000
2017/08/26 10:06:11 step 3: mse=0.511247 step=0.100000
2017/08/26 10:06:13 step 4: mse=0.486422 step=0.100000
2017/08/26 10:06:15 step 5: mse=0.473958 step=0.100000
2017/08/26 10:06:18 step 6: mse=0.459699 step=0.100000
2017/08/26 10:06:20 step 7: mse=0.449857 step=0.100000
2017/08/26 10:06:20 Saving...
2017/08/26 10:06:20 Gathering batch of experience...
2017/08/26 10:06:35 batch 320: mean=13.872340 stddev=6.041055 entropy=1.108270 frames=35273 count=47
2017/08/26 10:06:35 Training policy...
2017/08/26 10:06:47 step 0: objective=0.035302978
2017/08/26 10:06:57 step 1: objective=0.035364933
2017/08/26 10:07:08 step 2: objective=0.035426427
2017/08/26 10:07:18 step 3: objective=0.035487853
2017/08/26 10:07:29 step 4: objective=0.035549175
2017/08/26 10:07:39 step 5: objective=0.035609692
2017/08/26 10:07:49 step 6: objective=0.035662793
2017/08/26 10:08:00 step 7: objective=0.035715565
2017/08/26 10:08:00 Training value function...
2017/08/26 10:08:02 step 0: mse=0.721316 step=0.100000
2017/08/26 10:08:05 step 1: mse=0.686900 step=0.100000
2017/08/26 10:08:07 step 2: mse=0.658839 step=0.100000
2017/08/26 10:08:09 step 3: mse=0.628628 step=0.100000
2017/08/26 10:08:11 step 4: mse=0.606598 step=0.100000
2017/08/26 10:08:14 step 5: mse=0.591456 step=0.100000
2017/08/26 10:08:16 step 6: mse=0.566480 step=0.100000
2017/08/26 10:08:18 step 7: mse=0.556153 step=0.100000
2017/08/26 10:08:18 Saving...
2017/08/26 10:08:18 Gathering batch of experience...
2017/08/26 10:08:34 batch 321: mean=13.632653 stddev=6.235821 entropy=1.102769 frames=35591 count=49
2017/08/26 10:08:34 Training policy...
2017/08/26 10:08:46 step 0: objective=0.032002106
2017/08/26 10:08:56 step 1: objective=0.032065812
2017/08/26 10:09:07 step 2: objective=0.032129772
2017/08/26 10:09:17 step 3: objective=0.032193847
2017/08/26 10:09:28 step 4: objective=0.032255944
2017/08/26 10:09:38 step 5: objective=0.032304693
2017/08/26 10:09:49 step 6: objective=0.032361586
2017/08/26 10:10:00 step 7: objective=0.03241507
2017/08/26 10:10:00 Training value function...
2017/08/26 10:10:02 step 0: mse=0.801816 step=0.100000
2017/08/26 10:10:05 step 1: mse=0.763910 step=0.100000
2017/08/26 10:10:07 step 2: mse=0.735142 step=0.100000
2017/08/26 10:10:09 step 3: mse=0.700176 step=0.100000
2017/08/26 10:10:12 step 4: mse=0.675473 step=0.100000
2017/08/26 10:10:14 step 5: mse=0.659959 step=0.100000
2017/08/26 10:10:16 step 6: mse=0.637003 step=0.100000
2017/08/26 10:10:19 step 7: mse=0.625564 step=0.100000
2017/08/26 10:10:19 Saving...
2017/08/26 10:10:19 Gathering batch of experience...
2017/08/26 10:10:34 batch 322: mean=15.022222 stddev=6.378746 entropy=1.103566 frames=36225 count=45
2017/08/26 10:10:34 Training policy...
2017/08/26 10:10:47 step 0: objective=0.04543168
2017/08/26 10:10:58 step 1: objective=0.045473017
2017/08/26 10:11:08 step 2: objective=0.04551385
2017/08/26 10:11:19 step 3: objective=0.04555455
2017/08/26 10:11:30 step 4: objective=0.04559426
2017/08/26 10:11:40 step 5: objective=0.04563171
2017/08/26 10:11:51 step 6: objective=0.045669343
2017/08/26 10:12:02 step 7: objective=0.045704704
2017/08/26 10:12:02 Training value function...
2017/08/26 10:12:05 step 0: mse=0.811875 step=0.100000
2017/08/26 10:12:07 step 1: mse=0.762672 step=0.100000
2017/08/26 10:12:10 step 2: mse=0.711478 step=0.100000
2017/08/26 10:12:12 step 3: mse=0.669944 step=0.100000
2017/08/26 10:12:14 step 4: mse=0.625548 step=0.100000
2017/08/26 10:12:17 step 5: mse=0.592235 step=0.100000
2017/08/26 10:12:19 step 6: mse=0.562053 step=0.100000
2017/08/26 10:12:21 step 7: mse=0.535843 step=0.100000
2017/08/26 10:12:21 Saving...
2017/08/26 10:12:21 Gathering batch of experience...
2017/08/26 10:12:37 batch 323: mean=13.875000 stddev=5.614806 entropy=1.112586 frames=36586 count=48
2017/08/26 10:12:37 Training policy...
2017/08/26 10:12:49 step 0: objective=0.020636674
2017/08/26 10:13:01 step 1: objective=0.02066837
2017/08/26 10:13:11 step 2: objective=0.020699885
2017/08/26 10:13:22 step 3: objective=0.020731403
2017/08/26 10:13:33 step 4: objective=0.020762622
2017/08/26 10:13:44 step 5: objective=0.020793594
2017/08/26 10:13:56 step 6: objective=0.020819852
2017/08/26 10:14:07 step 7: objective=0.020835174
2017/08/26 10:14:07 Training value function...
2017/08/26 10:14:09 step 0: mse=0.567203 step=0.100000
2017/08/26 10:14:12 step 1: mse=0.542876 step=0.100000
2017/08/26 10:14:14 step 2: mse=0.525703 step=0.100000
2017/08/26 10:14:16 step 3: mse=0.508468 step=0.100000
2017/08/26 10:14:19 step 4: mse=0.495821 step=0.100000
2017/08/26 10:14:21 step 5: mse=0.484310 step=0.100000
2017/08/26 10:14:23 step 6: mse=0.476106 step=0.100000
2017/08/26 10:14:26 step 7: mse=0.467120 step=0.100000
2017/08/26 10:14:26 Saving...
2017/08/26 10:14:26 Gathering batch of experience...
2017/08/26 10:14:41 batch 324: mean=12.540000 stddev=4.124124 entropy=1.114048 frames=35768 count=50
2017/08/26 10:14:41 Training policy...
2017/08/26 10:14:53 step 0: objective=0.021351729
2017/08/26 10:15:04 step 1: objective=0.021382837
2017/08/26 10:15:15 step 2: objective=0.021414192
2017/08/26 10:15:26 step 3: objective=0.0214456
2017/08/26 10:15:37 step 4: objective=0.021477167
2017/08/26 10:15:47 step 5: objective=0.021508653
2017/08/26 10:15:58 step 6: objective=0.021539671
2017/08/26 10:16:09 step 7: objective=0.021566566
2017/08/26 10:16:09 Training value function...
2017/08/26 10:16:11 step 0: mse=0.540281 step=0.100000
2017/08/26 10:16:13 step 1: mse=0.512778 step=0.100000
2017/08/26 10:16:16 step 2: mse=0.490719 step=0.100000
2017/08/26 10:16:18 step 3: mse=0.465383 step=0.100000
2017/08/26 10:16:20 step 4: mse=0.446522 step=0.100000
2017/08/26 10:16:22 step 5: mse=0.435835 step=0.100000
2017/08/26 10:16:25 step 6: mse=0.424855 step=0.100000
2017/08/26 10:16:27 step 7: mse=0.416662 step=0.100000
2017/08/26 10:16:27 Saving...
2017/08/26 10:16:27 Gathering batch of experience...
2017/08/26 10:16:42 batch 325: mean=12.510204 stddev=4.806978 entropy=1.122789 frames=35088 count=49
2017/08/26 10:16:42 Training policy...
2017/08/26 10:16:54 step 0: objective=0.01343679
2017/08/26 10:17:04 step 1: objective=0.013471195
2017/08/26 10:17:15 step 2: objective=0.0135056395
2017/08/26 10:17:25 step 3: objective=0.013540254
2017/08/26 10:17:36 step 4: objective=0.013575096
2017/08/26 10:17:46 step 5: objective=0.013609428
2017/08/26 10:17:56 step 6: objective=0.0136602
2017/08/26 10:18:07 step 7: objective=0.013704204
2017/08/26 10:18:07 Training value function...
2017/08/26 10:18:10 step 0: mse=0.492133 step=0.100000
2017/08/26 10:18:12 step 1: mse=0.481451 step=0.100000
2017/08/26 10:18:14 step 2: mse=0.469083 step=0.100000
2017/08/26 10:18:16 step 3: mse=0.456191 step=0.100000
2017/08/26 10:18:19 step 4: mse=0.445473 step=0.100000
2017/08/26 10:18:21 step 5: mse=0.432424 step=0.100000
2017/08/26 10:18:23 step 6: mse=0.412399 step=0.100000
2017/08/26 10:18:25 step 7: mse=0.396315 step=0.100000
2017/08/26 10:18:25 Saving...
2017/08/26 10:18:25 Gathering batch of experience...
2017/08/26 10:18:41 batch 326: mean=12.078431 stddev=4.493320 entropy=1.114860 frames=35871 count=51
2017/08/26 10:18:41 Training policy...
2017/08/26 10:18:53 step 0: objective=0.02657799
2017/08/26 10:19:04 step 1: objective=0.026609711
2017/08/26 10:19:14 step 2: objective=0.026641328
2017/08/26 10:19:25 step 3: objective=0.026673203
2017/08/26 10:19:36 step 4: objective=0.026704883
2017/08/26 10:19:47 step 5: objective=0.026736557
2017/08/26 10:19:58 step 6: objective=0.02676832
2017/08/26 10:20:08 step 7: objective=0.026799293
2017/08/26 10:20:08 Training value function...
2017/08/26 10:20:11 step 0: mse=0.451997 step=0.100000
2017/08/26 10:20:13 step 1: mse=0.429408 step=0.100000
2017/08/26 10:20:16 step 2: mse=0.409941 step=0.100000
2017/08/26 10:20:18 step 3: mse=0.389650 step=0.100000
2017/08/26 10:20:20 step 4: mse=0.376095 step=0.100000
2017/08/26 10:20:23 step 5: mse=0.364529 step=0.100000
2017/08/26 10:20:25 step 6: mse=0.355388 step=0.100000
2017/08/26 10:20:27 step 7: mse=0.346927 step=0.100000
2017/08/26 10:20:27 Saving...
2017/08/26 10:20:27 Gathering batch of experience...
2017/08/26 10:20:43 batch 327: mean=14.787234 stddev=7.428915 entropy=1.114675 frames=36387 count=47
2017/08/26 10:20:43 Training policy...
2017/08/26 10:20:55 step 0: objective=0.064080715
2017/08/26 10:21:06 step 1: objective=0.06413796
2017/08/26 10:21:17 step 2: objective=0.06419525
2017/08/26 10:21:28 step 3: objective=0.064251184
2017/08/26 10:21:39 step 4: objective=0.0642913
2017/08/26 10:21:50 step 5: objective=0.064328626
2017/08/26 10:22:01 step 6: objective=0.0643628
2017/08/26 10:22:12 step 7: objective=0.06438874
2017/08/26 10:22:12 Training value function...
2017/08/26 10:22:15 step 0: mse=1.278382 step=0.100000
2017/08/26 10:22:17 step 1: mse=1.152431 step=0.100000
2017/08/26 10:22:20 step 2: mse=1.048167 step=0.100000
2017/08/26 10:22:22 step 3: mse=0.960805 step=0.100000
2017/08/26 10:22:24 step 4: mse=0.889587 step=0.100000
2017/08/26 10:22:27 step 5: mse=0.829372 step=0.100000
2017/08/26 10:22:29 step 6: mse=0.779811 step=0.100000
2017/08/26 10:22:31 step 7: mse=0.740082 step=0.100000
2017/08/26 10:22:31 Saving...
2017/08/26 10:22:31 Gathering batch of experience...
2017/08/26 10:22:47 batch 328: mean=15.511111 stddev=6.486301 entropy=1.107672 frames=35434 count=45
2017/08/26 10:22:47 Training policy...
2017/08/26 10:22:59 step 0: objective=0.05246388
2017/08/26 10:23:10 step 1: objective=0.05253097
2017/08/26 10:23:21 step 2: objective=0.052597858
2017/08/26 10:23:31 step 3: objective=0.052664053
2017/08/26 10:23:42 step 4: objective=0.052722763
2017/08/26 10:23:53 step 5: objective=0.052780706
2017/08/26 10:24:03 step 6: objective=0.05282636
2017/08/26 10:24:15 step 7: objective=0.052886553
2017/08/26 10:24:15 Training value function...
2017/08/26 10:24:17 step 0: mse=0.918468 step=0.100000
2017/08/26 10:24:20 step 1: mse=0.877342 step=0.100000
2017/08/26 10:24:22 step 2: mse=0.849802 step=0.100000
2017/08/26 10:24:24 step 3: mse=0.808432 step=0.100000
2017/08/26 10:24:26 step 4: mse=0.782597 step=0.100000
2017/08/26 10:24:29 step 5: mse=0.757460 step=0.100000
2017/08/26 10:24:31 step 6: mse=0.735187 step=0.100000
2017/08/26 10:24:33 step 7: mse=0.714581 step=0.100000
2017/08/26 10:24:33 Saving...
2017/08/26 10:24:33 Gathering batch of experience...
2017/08/26 10:24:48 batch 329: mean=13.765957 stddev=5.787782 entropy=1.107575 frames=35225 count=47
2017/08/26 10:24:48 Training policy...
2017/08/26 10:25:01 step 0: objective=0.0125709865
2017/08/26 10:25:11 step 1: objective=0.012621245
2017/08/26 10:25:22 step 2: objective=0.012671283
2017/08/26 10:25:32 step 3: objective=0.012721141
2017/08/26 10:25:43 step 4: objective=0.012773438
2017/08/26 10:25:53 step 5: objective=0.012823122
2017/08/26 10:26:04 step 6: objective=0.012869866
2017/08/26 10:26:15 step 7: objective=0.012905489
2017/08/26 10:26:15 Training value function...
2017/08/26 10:26:17 step 0: mse=0.776141 step=0.100000
2017/08/26 10:26:19 step 1: mse=0.728010 step=0.100000
2017/08/26 10:26:22 step 2: mse=0.689204 step=0.100000
2017/08/26 10:26:24 step 3: mse=0.660752 step=0.100000
2017/08/26 10:26:26 step 4: mse=0.632473 step=0.100000
2017/08/26 10:26:28 step 5: mse=0.609432 step=0.100000
2017/08/26 10:26:31 step 6: mse=0.593230 step=0.100000
2017/08/26 10:26:33 step 7: mse=0.576856 step=0.100000
2017/08/26 10:26:33 Saving...
2017/08/26 10:26:33 Gathering batch of experience...
2017/08/26 10:26:49 batch 330: mean=14.888889 stddev=5.271400 entropy=1.106209 frames=36080 count=45
2017/08/26 10:26:49 Training policy...
2017/08/26 10:27:01 step 0: objective=0.031024711
2017/08/26 10:27:12 step 1: objective=0.031057732
2017/08/26 10:27:23 step 2: objective=0.031090105
2017/08/26 10:27:34 step 3: objective=0.03112207
2017/08/26 10:27:45 step 4: objective=0.031153498
2017/08/26 10:27:56 step 5: objective=0.031184563
2017/08/26 10:28:07 step 6: objective=0.03121369
2017/08/26 10:28:17 step 7: objective=0.03123884
2017/08/26 10:28:17 Training value function...
2017/08/26 10:28:20 step 0: mse=0.731548 step=0.100000
2017/08/26 10:28:23 step 1: mse=0.692049 step=0.100000
2017/08/26 10:28:25 step 2: mse=0.659804 step=0.100000
2017/08/26 10:28:27 step 3: mse=0.631872 step=0.100000
2017/08/26 10:28:30 step 4: mse=0.616970 step=0.100000
2017/08/26 10:28:32 step 5: mse=0.603473 step=0.100000
2017/08/26 10:28:34 step 6: mse=0.583612 step=0.100000
2017/08/26 10:28:37 step 7: mse=0.573403 step=0.100000
2017/08/26 10:28:37 Saving...
2017/08/26 10:28:37 Gathering batch of experience...
2017/08/26 10:28:52 batch 331: mean=13.395833 stddev=5.453361 entropy=1.112025 frames=35386 count=48
2017/08/26 10:28:52 Training policy...
2017/08/26 10:29:04 step 0: objective=0.016786728
2017/08/26 10:29:15 step 1: objective=0.01683849
2017/08/26 10:29:26 step 2: objective=0.01689043
2017/08/26 10:29:36 step 3: objective=0.016942536
2017/08/26 10:29:47 step 4: objective=0.016994828
2017/08/26 10:29:58 step 5: objective=0.017047206
2017/08/26 10:30:08 step 6: objective=0.017108696
2017/08/26 10:30:19 step 7: objective=0.017157685
2017/08/26 10:30:19 Training value function...
2017/08/26 10:30:22 step 0: mse=0.725213 step=0.100000
2017/08/26 10:30:24 step 1: mse=0.685297 step=0.100000
2017/08/26 10:30:26 step 2: mse=0.653855 step=0.100000
2017/08/26 10:30:29 step 3: mse=0.618948 step=0.100000
2017/08/26 10:30:31 step 4: mse=0.587320 step=0.100000
2017/08/26 10:30:33 step 5: mse=0.566212 step=0.100000
2017/08/26 10:30:35 step 6: mse=0.549573 step=0.100000
2017/08/26 10:30:38 step 7: mse=0.527935 step=0.100000
2017/08/26 10:30:38 Saving...
2017/08/26 10:30:38 Gathering batch of experience...
2017/08/26 10:30:53 batch 332: mean=13.437500 stddev=5.199785 entropy=1.103042 frames=35653 count=48
2017/08/26 10:30:53 Training policy...
2017/08/26 10:31:05 step 0: objective=0.022966396
2017/08/26 10:31:16 step 1: objective=0.023025582
2017/08/26 10:31:27 step 2: objective=0.023083936
2017/08/26 10:31:37 step 3: objective=0.023141244
2017/08/26 10:31:48 step 4: objective=0.023193412
2017/08/26 10:31:59 step 5: objective=0.023235122
2017/08/26 10:32:10 step 6: objective=0.023266772
2017/08/26 10:32:21 step 7: objective=0.023309434
2017/08/26 10:32:21 Training value function...
2017/08/26 10:32:23 step 0: mse=0.791587 step=0.100000
2017/08/26 10:32:26 step 1: mse=0.737559 step=0.100000
2017/08/26 10:32:28 step 2: mse=0.695452 step=0.100000
2017/08/26 10:32:30 step 3: mse=0.659999 step=0.100000
2017/08/26 10:32:33 step 4: mse=0.627933 step=0.100000
2017/08/26 10:32:35 step 5: mse=0.602864 step=0.100000
2017/08/26 10:32:37 step 6: mse=0.580386 step=0.100000
2017/08/26 10:32:39 step 7: mse=0.561053 step=0.100000
2017/08/26 10:32:39 Saving...
2017/08/26 10:32:39 Gathering batch of experience...
2017/08/26 10:32:55 batch 333: mean=15.954545 stddev=6.082593 entropy=1.110726 frames=35495 count=44
2017/08/26 10:32:55 Training policy...
2017/08/26 10:33:07 step 0: objective=0.054406866
2017/08/26 10:33:18 step 1: objective=0.05446338
2017/08/26 10:33:29 step 2: objective=0.05451966
2017/08/26 10:33:39 step 3: objective=0.05457629
2017/08/26 10:33:50 step 4: objective=0.054631986
2017/08/26 10:34:01 step 5: objective=0.054683074
2017/08/26 10:34:12 step 6: objective=0.054725375
2017/08/26 10:34:22 step 7: objective=0.054784156
2017/08/26 10:34:22 Training value function...
2017/08/26 10:34:25 step 0: mse=0.959174 step=0.100000
2017/08/26 10:34:27 step 1: mse=0.921385 step=0.100000
2017/08/26 10:34:30 step 2: mse=0.890217 step=0.100000
2017/08/26 10:34:32 step 3: mse=0.862819 step=0.100000
2017/08/26 10:34:34 step 4: mse=0.833755 step=0.100000
2017/08/26 10:34:36 step 5: mse=0.806039 step=0.100000
2017/08/26 10:34:39 step 6: mse=0.788385 step=0.100000
2017/08/26 10:34:41 step 7: mse=0.763830 step=0.100000
2017/08/26 10:34:41 Saving...
2017/08/26 10:34:41 Gathering batch of experience...
2017/08/26 10:34:56 batch 334: mean=14.063830 stddev=5.121520 entropy=1.114788 frames=35379 count=47
2017/08/26 10:34:56 Training policy...
2017/08/26 10:35:09 step 0: objective=0.01508399
2017/08/26 10:35:20 step 1: objective=0.01512195
2017/08/26 10:35:30 step 2: objective=0.01515999
2017/08/26 10:35:41 step 3: objective=0.015198296
2017/08/26 10:35:52 step 4: objective=0.015235882
2017/08/26 10:36:03 step 5: objective=0.015270425
2017/08/26 10:36:13 step 6: objective=0.015298948
2017/08/26 10:36:24 step 7: objective=0.015317228
2017/08/26 10:36:24 Training value function...
2017/08/26 10:36:27 step 0: mse=0.996323 step=0.100000
2017/08/26 10:36:29 step 1: mse=0.948685 step=0.100000
2017/08/26 10:36:31 step 2: mse=0.897300 step=0.100000
2017/08/26 10:36:34 step 3: mse=0.857290 step=0.100000
2017/08/26 10:36:36 step 4: mse=0.823323 step=0.100000
2017/08/26 10:36:38 step 5: mse=0.798714 step=0.100000
2017/08/26 10:36:40 step 6: mse=0.768261 step=0.100000
2017/08/26 10:36:42 step 7: mse=0.741243 step=0.100000
2017/08/26 10:36:42 Saving...
2017/08/26 10:36:43 Gathering batch of experience...
2017/08/26 10:36:58 batch 335: mean=14.400000 stddev=5.828665 entropy=1.108254 frames=35099 count=45
2017/08/26 10:36:58 Training policy...
2017/08/26 10:37:10 step 0: objective=0.02553499
2017/08/26 10:37:21 step 1: objective=0.025589814
2017/08/26 10:37:32 step 2: objective=0.025644949
2017/08/26 10:37:42 step 3: objective=0.025700444
2017/08/26 10:37:53 step 4: objective=0.02575614
2017/08/26 10:38:04 step 5: objective=0.025803255
2017/08/26 10:38:14 step 6: objective=0.025863366
2017/08/26 10:38:25 step 7: objective=0.025890106
2017/08/26 10:38:25 Training value function...
2017/08/26 10:38:28 step 0: mse=0.785354 step=0.100000
2017/08/26 10:38:30 step 1: mse=0.737752 step=0.100000
2017/08/26 10:38:32 step 2: mse=0.700504 step=0.100000
2017/08/26 10:38:34 step 3: mse=0.668007 step=0.100000
2017/08/26 10:38:37 step 4: mse=0.639211 step=0.100000
2017/08/26 10:38:39 step 5: mse=0.615913 step=0.100000
2017/08/26 10:38:41 step 6: mse=0.602190 step=0.100000
2017/08/26 10:38:43 step 7: mse=0.573583 step=0.100000
2017/08/26 10:38:43 Saving...
2017/08/26 10:38:44 Gathering batch of experience...
2017/08/26 10:38:59 batch 336: mean=12.720000 stddev=6.059835 entropy=1.110495 frames=35607 count=50
2017/08/26 10:38:59 Training policy...
2017/08/26 10:39:12 step 0: objective=0.013351461
2017/08/26 10:39:22 step 1: objective=0.013395983
2017/08/26 10:39:33 step 2: objective=0.013440342
2017/08/26 10:39:44 step 3: objective=0.01348446
2017/08/26 10:39:55 step 4: objective=0.01352851
2017/08/26 10:40:06 step 5: objective=0.013571879
2017/08/26 10:40:17 step 6: objective=0.013610864
2017/08/26 10:40:28 step 7: objective=0.013643047
2017/08/26 10:40:28 Training value function...
2017/08/26 10:40:31 step 0: mse=0.733887 step=0.100000
2017/08/26 10:40:33 step 1: mse=0.673440 step=0.100000
2017/08/26 10:40:35 step 2: mse=0.622532 step=0.100000
2017/08/26 10:40:38 step 3: mse=0.583044 step=0.100000
2017/08/26 10:40:40 step 4: mse=0.546896 step=0.100000
2017/08/26 10:40:42 step 5: mse=0.518513 step=0.100000
2017/08/26 10:40:45 step 6: mse=0.496699 step=0.100000
2017/08/26 10:40:47 step 7: mse=0.479432 step=0.100000
2017/08/26 10:40:47 Saving...
2017/08/26 10:40:47 Gathering batch of experience...
2017/08/26 10:41:02 batch 337: mean=12.254902 stddev=5.121440 entropy=1.110755 frames=35412 count=51
2017/08/26 10:41:02 Training policy...
2017/08/26 10:41:15 step 0: objective=0.017413126
2017/08/26 10:41:26 step 1: objective=0.017499393
2017/08/26 10:41:36 step 2: objective=0.017585028
2017/08/26 10:41:47 step 3: objective=0.017670188
2017/08/26 10:41:58 step 4: objective=0.01774054
2017/08/26 10:42:09 step 5: objective=0.017801322
2017/08/26 10:42:20 step 6: objective=0.017856723
2017/08/26 10:42:31 step 7: objective=0.017886471
2017/08/26 10:42:31 Training value function...
2017/08/26 10:42:33 step 0: mse=0.713255 step=0.100000
2017/08/26 10:42:36 step 1: mse=0.675694 step=0.100000
2017/08/26 10:42:38 step 2: mse=0.650858 step=0.100000
2017/08/26 10:42:40 step 3: mse=0.631755 step=0.100000
2017/08/26 10:42:42 step 4: mse=0.608121 step=0.100000
2017/08/26 10:42:45 step 5: mse=0.585891 step=0.100000
2017/08/26 10:42:47 step 6: mse=0.569097 step=0.100000
2017/08/26 10:42:49 step 7: mse=0.549394 step=0.100000
2017/08/26 10:42:49 Saving...
2017/08/26 10:42:49 Gathering batch of experience...
2017/08/26 10:43:05 batch 338: mean=14.304348 stddev=5.094198 entropy=1.114736 frames=35487 count=46
2017/08/26 10:43:05 Training policy...
2017/08/26 10:43:17 step 0: objective=0.031587295
2017/08/26 10:43:28 step 1: objective=0.031650383
2017/08/26 10:43:39 step 2: objective=0.031713367
2017/08/26 10:43:50 step 3: objective=0.031776026
2017/08/26 10:44:01 step 4: objective=0.031831887
2017/08/26 10:44:12 step 5: objective=0.031869758
2017/08/26 10:44:23 step 6: objective=0.031893536
2017/08/26 10:44:34 step 7: objective=0.03191853
2017/08/26 10:44:34 Training value function...
2017/08/26 10:44:37 step 0: mse=0.638452 step=0.100000
2017/08/26 10:44:39 step 1: mse=0.600661 step=0.100000
2017/08/26 10:44:41 step 2: mse=0.570217 step=0.100000
2017/08/26 10:44:43 step 3: mse=0.543615 step=0.100000
2017/08/26 10:44:46 step 4: mse=0.522814 step=0.100000
2017/08/26 10:44:48 step 5: mse=0.499836 step=0.100000
2017/08/26 10:44:50 step 6: mse=0.489951 step=0.100000
2017/08/26 10:44:52 step 7: mse=0.481958 step=0.100000
2017/08/26 10:44:52 Saving...
2017/08/26 10:44:53 Gathering batch of experience...
2017/08/26 10:45:08 batch 339: mean=14.127660 stddev=6.303046 entropy=1.111006 frames=35731 count=47
2017/08/26 10:45:08 Training policy...
2017/08/26 10:45:20 step 0: objective=0.0365379
2017/08/26 10:45:32 step 1: objective=0.03656807
2017/08/26 10:45:43 step 2: objective=0.036598407
2017/08/26 10:45:54 step 3: objective=0.03662848
2017/08/26 10:46:05 step 4: objective=0.03665881
2017/08/26 10:46:16 step 5: objective=0.036687896
2017/08/26 10:46:27 step 6: objective=0.036737066
2017/08/26 10:46:38 step 7: objective=0.03676198
2017/08/26 10:46:38 Training value function...
2017/08/26 10:46:40 step 0: mse=0.715597 step=0.100000
2017/08/26 10:46:43 step 1: mse=0.663002 step=0.100000
2017/08/26 10:46:45 step 2: mse=0.619840 step=0.100000
2017/08/26 10:46:47 step 3: mse=0.584715 step=0.100000
2017/08/26 10:46:49 step 4: mse=0.555761 step=0.100000
2017/08/26 10:46:52 step 5: mse=0.531911 step=0.100000
2017/08/26 10:46:54 step 6: mse=0.510481 step=0.100000
2017/08/26 10:46:56 step 7: mse=0.493837 step=0.100000
2017/08/26 10:46:56 Saving...
2017/08/26 10:46:58 Gathering batch of experience...
2017/08/26 10:47:14 batch 340: mean=16.444444 stddev=8.236924 entropy=1.100704 frames=37166 count=45
2017/08/26 10:47:14 Training policy...
2017/08/26 10:47:27 step 0: objective=0.07342183
2017/08/26 10:47:39 step 1: objective=0.073481016
2017/08/26 10:47:50 step 2: objective=0.073539324
2017/08/26 10:48:02 step 3: objective=0.073596954
2017/08/26 10:48:13 step 4: objective=0.0736538
2017/08/26 10:48:25 step 5: objective=0.073700376
2017/08/26 10:48:36 step 6: objective=0.07375671
2017/08/26 10:48:48 step 7: objective=0.07384132
2017/08/26 10:48:48 Training value function...
2017/08/26 10:48:50 step 0: mse=1.162185 step=0.100000
2017/08/26 10:48:53 step 1: mse=1.069633 step=0.100000
2017/08/26 10:48:55 step 2: mse=0.992084 step=0.100000
2017/08/26 10:48:58 step 3: mse=0.925988 step=0.100000
2017/08/26 10:49:00 step 4: mse=0.869579 step=0.100000
2017/08/26 10:49:02 step 5: mse=0.819569 step=0.100000
2017/08/26 10:49:05 step 6: mse=0.781453 step=0.100000
2017/08/26 10:49:07 step 7: mse=0.740976 step=0.100000
2017/08/26 10:49:07 Saving...
2017/08/26 10:49:07 Gathering batch of experience...
2017/08/26 10:49:23 batch 341: mean=14.000000 stddev=5.180090 entropy=1.106706 frames=35919 count=48
2017/08/26 10:49:23 Training policy...
2017/08/26 10:49:35 step 0: objective=0.013286657
2017/08/26 10:49:46 step 1: objective=0.013338528
2017/08/26 10:49:58 step 2: objective=0.0133901965
2017/08/26 10:50:09 step 3: objective=0.013447968
2017/08/26 10:50:20 step 4: objective=0.013505841
2017/08/26 10:50:31 step 5: objective=0.013560818
2017/08/26 10:50:42 step 6: objective=0.013636972
2017/08/26 10:50:53 step 7: objective=0.0136999525
2017/08/26 10:50:53 Training value function...
2017/08/26 10:50:56 step 0: mse=0.729829 step=0.100000
2017/08/26 10:50:58 step 1: mse=0.697252 step=0.100000
2017/08/26 10:51:01 step 2: mse=0.672474 step=0.100000
2017/08/26 10:51:03 step 3: mse=0.649652 step=0.100000
2017/08/26 10:51:05 step 4: mse=0.622855 step=0.100000
2017/08/26 10:51:07 step 5: mse=0.608682 step=0.100000
2017/08/26 10:51:10 step 6: mse=0.587705 step=0.100000
2017/08/26 10:51:12 step 7: mse=0.569369 step=0.100000
2017/08/26 10:51:12 Saving...
2017/08/26 10:51:12 Gathering batch of experience...
2017/08/26 10:51:28 batch 342: mean=13.770833 stddev=5.712704 entropy=1.109563 frames=36008 count=48
2017/08/26 10:51:28 Training policy...
2017/08/26 10:51:41 step 0: objective=0.012728493
2017/08/26 10:51:52 step 1: objective=0.012805837
2017/08/26 10:52:03 step 2: objective=0.012882814
2017/08/26 10:52:15 step 3: objective=0.012959584
2017/08/26 10:52:26 step 4: objective=0.013036031
2017/08/26 10:52:37 step 5: objective=0.013108673
2017/08/26 10:52:48 step 6: objective=0.013178324
2017/08/26 10:52:59 step 7: objective=0.0132239275
2017/08/26 10:52:59 Training value function...
2017/08/26 10:53:02 step 0: mse=0.874200 step=0.100000
2017/08/26 10:53:04 step 1: mse=0.816372 step=0.100000
2017/08/26 10:53:07 step 2: mse=0.770156 step=0.100000
2017/08/26 10:53:09 step 3: mse=0.728772 step=0.100000
2017/08/26 10:53:11 step 4: mse=0.698569 step=0.100000
2017/08/26 10:53:14 step 5: mse=0.668166 step=0.100000
2017/08/26 10:53:16 step 6: mse=0.641257 step=0.100000
2017/08/26 10:53:18 step 7: mse=0.619692 step=0.100000
2017/08/26 10:53:18 Saving...
2017/08/26 10:53:18 Gathering batch of experience...
2017/08/26 10:53:34 batch 343: mean=15.173913 stddev=5.979328 entropy=1.109890 frames=36472 count=46
2017/08/26 10:53:34 Training policy...
2017/08/26 10:53:47 step 0: objective=0.036034953
2017/08/26 10:53:58 step 1: objective=0.03607107
2017/08/26 10:54:10 step 2: objective=0.036107596
2017/08/26 10:54:21 step 3: objective=0.03614387
2017/08/26 10:54:33 step 4: objective=0.036180172
2017/08/26 10:54:44 step 5: objective=0.03621651
2017/08/26 10:54:55 step 6: objective=0.036252942
2017/08/26 10:55:06 step 7: objective=0.03628826
2017/08/26 10:55:06 Training value function...
2017/08/26 10:55:09 step 0: mse=0.798901 step=0.100000
2017/08/26 10:55:12 step 1: mse=0.751540 step=0.100000
2017/08/26 10:55:14 step 2: mse=0.705388 step=0.100000
2017/08/26 10:55:16 step 3: mse=0.672562 step=0.100000
2017/08/26 10:55:19 step 4: mse=0.643239 step=0.100000
2017/08/26 10:55:21 step 5: mse=0.617911 step=0.100000
2017/08/26 10:55:24 step 6: mse=0.598919 step=0.100000
2017/08/26 10:55:26 step 7: mse=0.578920 step=0.100000
2017/08/26 10:55:26 Saving...
2017/08/26 10:55:26 Gathering batch of experience...
2017/08/26 10:55:42 batch 344: mean=13.958333 stddev=6.024112 entropy=1.118385 frames=36882 count=48
2017/08/26 10:55:42 Training policy...
2017/08/26 10:55:55 step 0: objective=0.021122897
2017/08/26 10:56:07 step 1: objective=0.02116865
2017/08/26 10:56:18 step 2: objective=0.021215059
2017/08/26 10:56:30 step 3: objective=0.02126186
2017/08/26 10:56:41 step 4: objective=0.021309184
2017/08/26 10:56:53 step 5: objective=0.021350857
2017/08/26 10:57:04 step 6: objective=0.021382222
2017/08/26 10:57:16 step 7: objective=0.021410631
2017/08/26 10:57:16 Training value function...
2017/08/26 10:57:19 step 0: mse=0.609035 step=0.100000
2017/08/26 10:57:21 step 1: mse=0.589766 step=0.100000
2017/08/26 10:57:23 step 2: mse=0.570896 step=0.100000
2017/08/26 10:57:26 step 3: mse=0.557259 step=0.100000
2017/08/26 10:57:28 step 4: mse=0.545488 step=0.100000
2017/08/26 10:57:30 step 5: mse=0.524906 step=0.100000
2017/08/26 10:57:33 step 6: mse=0.507264 step=0.100000
2017/08/26 10:57:35 step 7: mse=0.498070 step=0.100000
2017/08/26 10:57:35 Saving...
2017/08/26 10:57:35 Gathering batch of experience...
2017/08/26 10:57:51 batch 345: mean=15.478261 stddev=6.251049 entropy=1.106309 frames=36521 count=46
2017/08/26 10:57:51 Training policy...
2017/08/26 10:58:04 step 0: objective=0.037102364
2017/08/26 10:58:18 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.99 -maxtrees 500]
2017/08/26 10:58:18 Creating environments...
2017/08/26 10:58:21 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/26 10:58:21 Loaded forest from: Breakout-ram-v0/critic.json
2017/08/26 10:58:21 Running. Press Ctrl+C to stop.
2017/08/26 10:58:21 Gathering batch of experience...
2017/08/26 10:58:35 batch 0: mean=15.555556 stddev=7.631967 entropy=1.108830 frames=36354 count=45
2017/08/26 10:58:35 Training policy...
2017/08/26 10:58:39 step 0: objective=0.051341612
2017/08/26 10:58:41 step 1: objective=0.051397968
2017/08/26 10:58:43 step 2: objective=0.05145392
2017/08/26 10:58:45 step 3: objective=0.051509727
2017/08/26 10:58:47 step 4: objective=0.051605448
2017/08/26 10:58:49 step 5: objective=0.05169827
2017/08/26 10:58:51 step 6: objective=0.051758695
2017/08/26 10:58:54 step 7: objective=0.05179072
2017/08/26 10:58:54 Training value function...
2017/08/26 10:58:55 step 0: mse=0.997547 step=0.100000
2017/08/26 10:58:55 step 1: mse=0.924070 step=0.100000
2017/08/26 10:58:56 step 2: mse=0.864680 step=0.100000
2017/08/26 10:58:57 step 3: mse=0.814681 step=0.100000
2017/08/26 10:58:58 step 4: mse=0.771077 step=0.100000
2017/08/26 10:58:58 step 5: mse=0.735506 step=0.100000
2017/08/26 10:58:59 step 6: mse=0.703907 step=0.100000
2017/08/26 10:59:00 step 7: mse=0.677087 step=0.100000
2017/08/26 10:59:00 Saving...
2017/08/26 10:59:00 Gathering batch of experience...
2017/08/26 10:59:15 batch 1: mean=15.000000 stddev=7.010630 entropy=1.096515 frames=36980 count=47
2017/08/26 10:59:15 Training policy...
2017/08/26 10:59:19 step 0: objective=0.022764144
2017/08/26 10:59:21 step 1: objective=0.022873009
2017/08/26 10:59:23 step 2: objective=0.02298032
2017/08/26 10:59:25 step 3: objective=0.023077162
2017/08/26 10:59:27 step 4: objective=0.023160165
2017/08/26 10:59:30 step 5: objective=0.023243075
2017/08/26 10:59:32 step 6: objective=0.023296937
2017/08/26 10:59:34 step 7: objective=0.023347937
2017/08/26 10:59:34 Training value function...
2017/08/26 10:59:35 step 0: mse=0.973397 step=0.100000
2017/08/26 10:59:36 step 1: mse=0.929947 step=0.100000
2017/08/26 10:59:37 step 2: mse=0.894751 step=0.100000
2017/08/26 10:59:37 step 3: mse=0.863862 step=0.100000
2017/08/26 10:59:38 step 4: mse=0.842486 step=0.100000
2017/08/26 10:59:39 step 5: mse=0.826203 step=0.100000
2017/08/26 10:59:40 step 6: mse=0.804428 step=0.100000
2017/08/26 10:59:41 step 7: mse=0.786816 step=0.100000
2017/08/26 10:59:41 Saving...
2017/08/26 10:59:41 Gathering batch of experience...
2017/08/26 10:59:56 batch 2: mean=15.911111 stddev=7.506507 entropy=1.100575 frames=36244 count=45
2017/08/26 10:59:56 Training policy...
2017/08/26 10:59:59 step 0: objective=0.050769158
2017/08/26 11:00:01 step 1: objective=0.0508361
2017/08/26 11:00:03 step 2: objective=0.050903246
2017/08/26 11:00:05 step 3: objective=0.050971117
2017/08/26 11:00:08 step 4: objective=0.05103847
2017/08/26 11:00:10 step 5: objective=0.051071245
2017/08/26 11:00:12 step 6: objective=0.05110509
2017/08/26 11:00:14 step 7: objective=0.05112507
2017/08/26 11:00:14 Training value function...
2017/08/26 11:00:15 step 0: mse=0.958793 step=0.100000
2017/08/26 11:00:16 step 1: mse=0.897283 step=0.100000
2017/08/26 11:00:17 step 2: mse=0.840770 step=0.100000
2017/08/26 11:00:17 step 3: mse=0.796196 step=0.100000
2017/08/26 11:00:18 step 4: mse=0.754672 step=0.100000
2017/08/26 11:00:19 step 5: mse=0.719095 step=0.100000
2017/08/26 11:00:20 step 6: mse=0.689246 step=0.100000
2017/08/26 11:00:20 step 7: mse=0.661433 step=0.100000
2017/08/26 11:00:20 Saving...
2017/08/26 11:00:20 Gathering batch of experience...
2017/08/26 11:00:36 batch 3: mean=13.740000 stddev=5.949151 entropy=1.110994 frames=36475 count=50
2017/08/26 11:00:36 Training policy...
2017/08/26 11:00:39 step 0: objective=0.015739046
2017/08/26 11:00:41 step 1: objective=0.015769942
2017/08/26 11:00:44 step 2: objective=0.015800765
2017/08/26 11:00:46 step 3: objective=0.015831286
2017/08/26 11:00:48 step 4: objective=0.015861595
2017/08/26 11:00:50 step 5: objective=0.015891898
2017/08/26 11:00:52 step 6: objective=0.015920492
2017/08/26 11:00:54 step 7: objective=0.01596334
2017/08/26 11:00:54 Training value function...
2017/08/26 11:00:55 step 0: mse=0.831222 step=0.100000
2017/08/26 11:00:56 step 1: mse=0.784905 step=0.100000
2017/08/26 11:00:57 step 2: mse=0.736500 step=0.100000
2017/08/26 11:00:58 step 3: mse=0.695617 step=0.100000
2017/08/26 11:00:58 step 4: mse=0.663969 step=0.100000
2017/08/26 11:00:59 step 5: mse=0.636551 step=0.100000
2017/08/26 11:01:00 step 6: mse=0.615337 step=0.100000
2017/08/26 11:01:01 step 7: mse=0.599077 step=0.100000
2017/08/26 11:01:01 Saving...
2017/08/26 11:01:01 Gathering batch of experience...
2017/08/26 11:01:16 batch 4: mean=13.938776 stddev=6.139229 entropy=1.117830 frames=36779 count=49
2017/08/26 11:01:16 Training policy...
2017/08/26 11:01:19 step 0: objective=0.016017616
2017/08/26 11:01:22 step 1: objective=0.016071377
2017/08/26 11:01:24 step 2: objective=0.01612545
2017/08/26 11:01:26 step 3: objective=0.01617966
2017/08/26 11:01:28 step 4: objective=0.016234184
2017/08/26 11:01:30 step 5: objective=0.016282838
2017/08/26 11:01:32 step 6: objective=0.01631933
2017/08/26 11:01:35 step 7: objective=0.016345667
2017/08/26 11:01:35 Training value function...
2017/08/26 11:01:36 step 0: mse=0.770482 step=0.100000
2017/08/26 11:01:37 step 1: mse=0.729986 step=0.100000
2017/08/26 11:01:37 step 2: mse=0.694475 step=0.100000
2017/08/26 11:01:38 step 3: mse=0.664040 step=0.100000
2017/08/26 11:01:39 step 4: mse=0.645829 step=0.100000
2017/08/26 11:01:40 step 5: mse=0.625922 step=0.100000
2017/08/26 11:01:40 step 6: mse=0.599963 step=0.100000
2017/08/26 11:01:41 step 7: mse=0.579377 step=0.100000
2017/08/26 11:01:41 Saving...
2017/08/26 11:01:41 Gathering batch of experience...
2017/08/26 11:01:56 batch 5: mean=15.869565 stddev=7.224983 entropy=1.112243 frames=36813 count=46
2017/08/26 11:01:56 Training policy...
2017/08/26 11:02:00 step 0: objective=0.043826766
2017/08/26 11:02:02 step 1: objective=0.04387862
2017/08/26 11:02:04 step 2: objective=0.043931574
2017/08/26 11:02:06 step 3: objective=0.043985102
2017/08/26 11:02:08 step 4: objective=0.044026412
2017/08/26 11:02:10 step 5: objective=0.044084713
2017/08/26 11:02:12 step 6: objective=0.04413548
2017/08/26 11:02:14 step 7: objective=0.04417892
2017/08/26 11:02:14 Training value function...
2017/08/26 11:02:16 step 0: mse=1.026681 step=0.100000
2017/08/26 11:02:16 step 1: mse=0.971373 step=0.100000
2017/08/26 11:02:17 step 2: mse=0.925262 step=0.100000
2017/08/26 11:02:18 step 3: mse=0.887868 step=0.100000
2017/08/26 11:02:19 step 4: mse=0.852094 step=0.100000
2017/08/26 11:02:19 step 5: mse=0.824518 step=0.100000
2017/08/26 11:02:20 step 6: mse=0.799914 step=0.100000
2017/08/26 11:02:21 step 7: mse=0.779072 step=0.100000
2017/08/26 11:02:21 Saving...
2017/08/26 11:02:21 Gathering batch of experience...
2017/08/26 11:02:36 batch 6: mean=13.458333 stddev=4.623123 entropy=1.108835 frames=36063 count=48
2017/08/26 11:02:36 Training policy...
2017/08/26 11:02:50 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.99 -maxtrees 500]
2017/08/26 11:02:50 Creating environments...
2017/08/26 11:02:52 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/26 11:02:52 Creating new forest for: Breakout-ram-v0/critic.json
2017/08/26 11:02:52 Running. Press Ctrl+C to stop.
2017/08/26 11:02:52 Gathering batch of experience...
2017/08/26 11:03:06 batch 0: mean=15.090909 stddev=5.763593 entropy=1.107276 frames=35765 count=44
2017/08/26 11:03:06 Training policy...
2017/08/26 11:03:09 step 0: objective=0.31187072
2017/08/26 11:03:11 step 1: objective=0.31200072
2017/08/26 11:03:13 step 2: objective=0.31212956
2017/08/26 11:03:15 step 3: objective=0.3122552
2017/08/26 11:03:17 step 4: objective=0.3123803
2017/08/26 11:03:19 step 5: objective=0.31250012
2017/08/26 11:03:22 step 6: objective=0.31259888
2017/08/26 11:03:24 step 7: objective=0.31269342
2017/08/26 11:03:24 Training value function...
2017/08/26 11:03:24 step 0: mse=3.551431 step=0.100000
2017/08/26 11:03:25 step 1: mse=2.973167 step=0.100000
2017/08/26 11:03:25 step 2: mse=2.509604 step=0.100000
2017/08/26 11:03:26 step 3: mse=2.133679 step=0.100000
2017/08/26 11:03:26 step 4: mse=1.829928 step=0.100000
2017/08/26 11:03:26 step 5: mse=1.584588 step=0.100000
2017/08/26 11:03:27 step 6: mse=1.381959 step=0.100000
2017/08/26 11:03:27 step 7: mse=1.220432 step=0.100000
2017/08/26 11:03:27 Saving...
2017/08/26 11:03:27 Gathering batch of experience...
2017/08/26 11:03:42 batch 1: mean=13.509804 stddev=6.777623 entropy=1.114339 frames=36478 count=51
2017/08/26 11:03:42 Training policy...
2017/08/26 11:03:45 step 0: objective=0.14438528
2017/08/26 11:03:48 step 1: objective=0.144418
2017/08/26 11:03:50 step 2: objective=0.14445288
2017/08/26 11:03:52 step 3: objective=0.14448735
2017/08/26 11:03:54 step 4: objective=0.14452186
2017/08/26 11:03:56 step 5: objective=0.14455426
2017/08/26 11:03:58 step 6: objective=0.14461306
2017/08/26 11:04:00 step 7: objective=0.14467031
2017/08/26 11:04:00 Training value function...
2017/08/26 11:04:01 step 0: mse=1.404723 step=0.100000
2017/08/26 11:04:02 step 1: mse=1.267033 step=0.100000
2017/08/26 11:04:02 step 2: mse=1.151041 step=0.100000
2017/08/26 11:04:03 step 3: mse=1.058233 step=0.100000
2017/08/26 11:04:03 step 4: mse=0.979527 step=0.100000
2017/08/26 11:04:03 step 5: mse=0.915022 step=0.100000
2017/08/26 11:04:04 step 6: mse=0.859893 step=0.100000
2017/08/26 11:04:04 step 7: mse=0.812542 step=0.100000
2017/08/26 11:04:04 Saving...
2017/08/26 11:04:04 Gathering batch of experience...
2017/08/26 11:04:20 batch 2: mean=15.765957 stddev=7.641468 entropy=1.108468 frames=37010 count=47
2017/08/26 11:04:20 Training policy...
2017/08/26 11:04:23 step 0: objective=0.09307545
2017/08/26 11:04:25 step 1: objective=0.09313439
2017/08/26 11:04:27 step 2: objective=0.093193255
2017/08/26 11:04:29 step 3: objective=0.09325191
2017/08/26 11:04:31 step 4: objective=0.09330951
2017/08/26 11:04:33 step 5: objective=0.093364425
2017/08/26 11:04:35 step 6: objective=0.09341601
2017/08/26 11:04:38 step 7: objective=0.093461595
2017/08/26 11:04:38 Training value function...
2017/08/26 11:04:39 step 0: mse=1.279804 step=0.100000
2017/08/26 11:04:39 step 1: mse=1.180848 step=0.100000
2017/08/26 11:04:40 step 2: mse=1.101621 step=0.100000
2017/08/26 11:04:40 step 3: mse=1.035243 step=0.100000
2017/08/26 11:04:40 step 4: mse=0.978093 step=0.100000
2017/08/26 11:04:41 step 5: mse=0.922118 step=0.100000
2017/08/26 11:04:41 step 6: mse=0.876338 step=0.100000
2017/08/26 11:04:42 step 7: mse=0.838781 step=0.100000
2017/08/26 11:04:42 Saving...
2017/08/26 11:04:42 Gathering batch of experience...
2017/08/26 11:04:57 batch 3: mean=14.913043 stddev=7.809766 entropy=1.094679 frames=36389 count=46
2017/08/26 11:04:57 Training policy...
2017/08/26 11:05:00 step 0: objective=0.03409809
2017/08/26 11:05:02 step 1: objective=0.034144875
2017/08/26 11:05:04 step 2: objective=0.0341917
2017/08/26 11:05:06 step 3: objective=0.03423816
2017/08/26 11:05:08 step 4: objective=0.034284387
2017/08/26 11:05:10 step 5: objective=0.034324463
2017/08/26 11:05:12 step 6: objective=0.034370877
2017/08/26 11:05:14 step 7: objective=0.03441346
2017/08/26 11:05:14 Training value function...
2017/08/26 11:05:15 step 0: mse=0.805592 step=0.100000
2017/08/26 11:05:16 step 1: mse=0.755518 step=0.100000
2017/08/26 11:05:16 step 2: mse=0.712327 step=0.100000
2017/08/26 11:05:17 step 3: mse=0.676489 step=0.100000
2017/08/26 11:05:17 step 4: mse=0.649085 step=0.100000
2017/08/26 11:05:18 step 5: mse=0.624948 step=0.100000
2017/08/26 11:05:18 step 6: mse=0.604141 step=0.100000
2017/08/26 11:05:19 step 7: mse=0.582734 step=0.100000
2017/08/26 11:05:19 Saving...
2017/08/26 11:05:19 Gathering batch of experience...
2017/08/26 11:05:33 batch 4: mean=14.800000 stddev=5.694442 entropy=1.109078 frames=35743 count=45
2017/08/26 11:05:33 Training policy...
2017/08/26 11:05:36 step 0: objective=0.023231711
2017/08/26 11:05:38 step 1: objective=0.0232797
2017/08/26 11:05:41 step 2: objective=0.023327941
2017/08/26 11:05:43 step 3: objective=0.023376314
2017/08/26 11:05:45 step 4: objective=0.023424964
2017/08/26 11:05:47 step 5: objective=0.02346904
2017/08/26 11:05:49 step 6: objective=0.023508154
2017/08/26 11:05:51 step 7: objective=0.023592513
2017/08/26 11:05:51 Training value function...
2017/08/26 11:05:52 step 0: mse=0.634600 step=0.100000
2017/08/26 11:05:52 step 1: mse=0.608119 step=0.100000
2017/08/26 11:05:53 step 2: mse=0.583607 step=0.100000
2017/08/26 11:05:53 step 3: mse=0.563996 step=0.100000
2017/08/26 11:05:54 step 4: mse=0.548050 step=0.100000
2017/08/26 11:05:54 step 5: mse=0.525179 step=0.100000
2017/08/26 11:05:54 step 6: mse=0.513488 step=0.100000
2017/08/26 11:05:55 step 7: mse=0.498372 step=0.100000
2017/08/26 11:05:55 Saving...
2017/08/26 11:05:55 Gathering batch of experience...
2017/08/26 11:06:10 batch 5: mean=14.933333 stddev=6.433938 entropy=1.113139 frames=35520 count=45
2017/08/26 11:06:10 Training policy...
2017/08/26 11:06:12 step 0: objective=0.031284414
2017/08/26 11:06:15 step 1: objective=0.03131806
2017/08/26 11:06:17 step 2: objective=0.031351604
2017/08/26 11:06:19 step 3: objective=0.03138493
2017/08/26 11:06:21 step 4: objective=0.03141598
2017/08/26 11:06:23 step 5: objective=0.031436708
2017/08/26 11:06:25 step 6: objective=0.031486843
2017/08/26 11:06:27 step 7: objective=0.031533014
2017/08/26 11:06:27 Training value function...
2017/08/26 11:06:28 step 0: mse=0.757910 step=0.100000
2017/08/26 11:06:28 step 1: mse=0.715234 step=0.100000
2017/08/26 11:06:29 step 2: mse=0.695312 step=0.100000
2017/08/26 11:06:29 step 3: mse=0.661331 step=0.100000
2017/08/26 11:06:30 step 4: mse=0.644091 step=0.100000
2017/08/26 11:06:30 step 5: mse=0.610270 step=0.100000
2017/08/26 11:06:31 step 6: mse=0.597120 step=0.100000
2017/08/26 11:06:31 step 7: mse=0.581744 step=0.100000
2017/08/26 11:06:31 Saving...
2017/08/26 11:06:31 Gathering batch of experience...
2017/08/26 11:06:46 batch 6: mean=14.104167 stddev=5.534888 entropy=1.115003 frames=36269 count=48
2017/08/26 11:06:46 Training policy...
2017/08/26 11:06:49 step 0: objective=0.030094188
2017/08/26 11:06:51 step 1: objective=0.030179633
2017/08/26 11:06:54 step 2: objective=0.030265542
2017/08/26 11:06:56 step 3: objective=0.03034689
2017/08/26 11:06:58 step 4: objective=0.030401058
2017/08/26 11:07:00 step 5: objective=0.030451752
2017/08/26 11:07:02 step 6: objective=0.03049981
2017/08/26 11:07:04 step 7: objective=0.030530903
2017/08/26 11:07:04 Training value function...
2017/08/26 11:07:05 step 0: mse=0.716523 step=0.100000
2017/08/26 11:07:06 step 1: mse=0.677192 step=0.100000
2017/08/26 11:07:06 step 2: mse=0.645826 step=0.100000
2017/08/26 11:07:07 step 3: mse=0.617391 step=0.100000
2017/08/26 11:07:07 step 4: mse=0.593574 step=0.100000
2017/08/26 11:07:07 step 5: mse=0.574049 step=0.100000
2017/08/26 11:07:08 step 6: mse=0.555366 step=0.100000
2017/08/26 11:07:08 step 7: mse=0.541493 step=0.100000
2017/08/26 11:07:08 Saving...
2017/08/26 11:07:08 Gathering batch of experience...
2017/08/26 11:07:24 batch 7: mean=14.145833 stddev=5.548985 entropy=1.118492 frames=36985 count=48
2017/08/26 11:07:24 Training policy...
2017/08/26 11:07:27 step 0: objective=0.0290917
2017/08/26 11:07:29 step 1: objective=0.029132033
2017/08/26 11:07:31 step 2: objective=0.029172527
2017/08/26 11:07:33 step 3: objective=0.029212892
2017/08/26 11:07:35 step 4: objective=0.029253226
2017/08/26 11:07:38 step 5: objective=0.029291
2017/08/26 11:07:40 step 6: objective=0.029319784
2017/08/26 11:07:42 step 7: objective=0.02936277
2017/08/26 11:07:42 Training value function...
2017/08/26 11:07:43 step 0: mse=0.552262 step=0.100000
2017/08/26 11:07:43 step 1: mse=0.528912 step=0.100000
2017/08/26 11:07:44 step 2: mse=0.507769 step=0.100000
2017/08/26 11:07:44 step 3: mse=0.484578 step=0.100000
2017/08/26 11:07:45 step 4: mse=0.472521 step=0.100000
2017/08/26 11:07:45 step 5: mse=0.463626 step=0.100000
2017/08/26 11:07:46 step 6: mse=0.456731 step=0.100000
2017/08/26 11:07:46 step 7: mse=0.446851 step=0.100000
2017/08/26 11:07:46 Saving...
2017/08/26 11:07:46 Gathering batch of experience...
2017/08/26 11:08:01 batch 8: mean=13.875000 stddev=6.610046 entropy=1.107720 frames=35718 count=48
2017/08/26 11:08:01 Training policy...
2017/08/26 11:08:04 step 0: objective=0.025486095
2017/08/26 11:08:06 step 1: objective=0.025538668
2017/08/26 11:08:08 step 2: objective=0.02559132
2017/08/26 11:08:10 step 3: objective=0.025643915
2017/08/26 11:08:12 step 4: objective=0.025696537
2017/08/26 11:08:14 step 5: objective=0.025748115
2017/08/26 11:08:16 step 6: objective=0.0258011
2017/08/26 11:08:19 step 7: objective=0.025839582
2017/08/26 11:08:19 Training value function...
2017/08/26 11:08:20 step 0: mse=0.767007 step=0.100000
2017/08/26 11:08:20 step 1: mse=0.730096 step=0.100000
2017/08/26 11:08:21 step 2: mse=0.690658 step=0.100000
2017/08/26 11:08:21 step 3: mse=0.664406 step=0.100000
2017/08/26 11:08:21 step 4: mse=0.641543 step=0.100000
2017/08/26 11:08:22 step 5: mse=0.621929 step=0.100000
2017/08/26 11:08:22 step 6: mse=0.598078 step=0.100000
2017/08/26 11:08:23 step 7: mse=0.584114 step=0.100000
2017/08/26 11:08:23 Saving...
2017/08/26 11:08:23 Gathering batch of experience...
2017/08/26 11:08:38 batch 9: mean=16.244444 stddev=6.433093 entropy=1.104941 frames=36982 count=45
2017/08/26 11:08:38 Training policy...
2017/08/26 11:08:41 step 0: objective=0.04721246
2017/08/26 11:08:44 step 1: objective=0.047332212
2017/08/26 11:08:46 step 2: objective=0.047452863
2017/08/26 11:08:48 step 3: objective=0.047574397
2017/08/26 11:08:50 step 4: objective=0.047690164
2017/08/26 11:08:52 step 5: objective=0.047772232
2017/08/26 11:08:54 step 6: objective=0.047859143
2017/08/26 11:08:56 step 7: objective=0.04792279
2017/08/26 11:08:56 Training value function...
2017/08/26 11:08:57 step 0: mse=0.882534 step=0.100000
2017/08/26 11:08:58 step 1: mse=0.840564 step=0.100000
2017/08/26 11:08:58 step 2: mse=0.795741 step=0.100000
2017/08/26 11:08:59 step 3: mse=0.762825 step=0.100000
2017/08/26 11:08:59 step 4: mse=0.728691 step=0.100000
2017/08/26 11:09:00 step 5: mse=0.705690 step=0.100000
2017/08/26 11:09:00 step 6: mse=0.677813 step=0.100000
2017/08/26 11:09:01 step 7: mse=0.661692 step=0.100000
2017/08/26 11:09:01 Saving...
2017/08/26 11:09:01 Gathering batch of experience...
2017/08/26 11:09:17 batch 10: mean=15.260870 stddev=5.619975 entropy=1.099042 frames=37315 count=46
2017/08/26 11:09:17 Training policy...
2017/08/26 11:09:20 step 0: objective=0.02068526
2017/08/26 11:09:22 step 1: objective=0.020721382
2017/08/26 11:09:24 step 2: objective=0.020758562
2017/08/26 11:09:26 step 3: objective=0.020795794
2017/08/26 11:09:29 step 4: objective=0.02083294
2017/08/26 11:09:31 step 5: objective=0.02087006
2017/08/26 11:09:33 step 6: objective=0.02090679
2017/08/26 11:09:35 step 7: objective=0.020936005
2017/08/26 11:09:35 Training value function...
2017/08/26 11:09:36 step 0: mse=0.756036 step=0.100000
2017/08/26 11:09:37 step 1: mse=0.718769 step=0.100000
2017/08/26 11:09:37 step 2: mse=0.689558 step=0.100000
2017/08/26 11:09:38 step 3: mse=0.664053 step=0.100000
2017/08/26 11:09:38 step 4: mse=0.641945 step=0.100000
2017/08/26 11:09:39 step 5: mse=0.623563 step=0.100000
2017/08/26 11:09:39 step 6: mse=0.599550 step=0.100000
2017/08/26 11:09:39 step 7: mse=0.582026 step=0.100000
2017/08/26 11:09:39 Saving...
2017/08/26 11:09:40 Gathering batch of experience...
2017/08/26 11:09:55 batch 11: mean=15.652174 stddev=6.669911 entropy=1.096189 frames=37194 count=46
2017/08/26 11:09:55 Training policy...
2017/08/26 11:09:58 step 0: objective=0.02910973
2017/08/26 11:10:00 step 1: objective=0.02916215
2017/08/26 11:10:02 step 2: objective=0.029213943
2017/08/26 11:10:05 step 3: objective=0.029265692
2017/08/26 11:10:07 step 4: objective=0.02930532
2017/08/26 11:10:09 step 5: objective=0.029354759
2017/08/26 11:10:11 step 6: objective=0.029402979
2017/08/26 11:10:13 step 7: objective=0.02944057
2017/08/26 11:10:13 Training value function...
2017/08/26 11:10:14 step 0: mse=0.928032 step=0.100000
2017/08/26 11:10:15 step 1: mse=0.865278 step=0.100000
2017/08/26 11:10:16 step 2: mse=0.814411 step=0.100000
2017/08/26 11:10:16 step 3: mse=0.773171 step=0.100000
2017/08/26 11:10:17 step 4: mse=0.737869 step=0.100000
2017/08/26 11:10:17 step 5: mse=0.709118 step=0.100000
2017/08/26 11:10:18 step 6: mse=0.682767 step=0.100000
2017/08/26 11:10:18 step 7: mse=0.667495 step=0.100000
2017/08/26 11:10:18 Saving...
2017/08/26 11:10:18 Gathering batch of experience...
2017/08/26 11:10:33 batch 12: mean=15.130435 stddev=6.013061 entropy=1.100054 frames=36736 count=46
2017/08/26 11:10:33 Training policy...
2017/08/26 11:10:36 step 0: objective=0.018837249
2017/08/26 11:10:39 step 1: objective=0.01891868
2017/08/26 11:10:41 step 2: objective=0.0190004
2017/08/26 11:10:43 step 3: objective=0.019081961
2017/08/26 11:10:45 step 4: objective=0.019157385
2017/08/26 11:10:47 step 5: objective=0.019223101
2017/08/26 11:10:49 step 6: objective=0.019288022
2017/08/26 11:10:51 step 7: objective=0.019357163
2017/08/26 11:10:51 Training value function...
2017/08/26 11:10:52 step 0: mse=0.775307 step=0.100000
2017/08/26 11:10:53 step 1: mse=0.732222 step=0.100000
2017/08/26 11:10:53 step 2: mse=0.698682 step=0.100000
2017/08/26 11:10:54 step 3: mse=0.665753 step=0.100000
2017/08/26 11:10:54 step 4: mse=0.640678 step=0.100000
2017/08/26 11:10:55 step 5: mse=0.607164 step=0.100000
2017/08/26 11:10:55 step 6: mse=0.580114 step=0.100000
2017/08/26 11:10:56 step 7: mse=0.556309 step=0.100000
2017/08/26 11:10:56 Saving...
2017/08/26 11:10:56 Gathering batch of experience...
2017/08/26 11:11:11 batch 13: mean=14.395833 stddev=6.260789 entropy=1.107025 frames=36603 count=48
2017/08/26 11:11:11 Training policy...
2017/08/26 11:11:14 step 0: objective=0.023533685
2017/08/26 11:11:16 step 1: objective=0.02360721
2017/08/26 11:11:18 step 2: objective=0.02368038
2017/08/26 11:11:20 step 3: objective=0.023753604
2017/08/26 11:11:22 step 4: objective=0.023820227
2017/08/26 11:11:25 step 5: objective=0.023892071
2017/08/26 11:11:27 step 6: objective=0.023945808
2017/08/26 11:11:29 step 7: objective=0.023992732
2017/08/26 11:11:29 Training value function...
2017/08/26 11:11:30 step 0: mse=0.806259 step=0.100000
2017/08/26 11:11:30 step 1: mse=0.753751 step=0.100000
2017/08/26 11:11:31 step 2: mse=0.705709 step=0.100000
2017/08/26 11:11:31 step 3: mse=0.669980 step=0.100000
2017/08/26 11:11:32 step 4: mse=0.634314 step=0.100000
2017/08/26 11:11:32 step 5: mse=0.601183 step=0.100000
2017/08/26 11:11:33 step 6: mse=0.578560 step=0.100000
2017/08/26 11:11:33 step 7: mse=0.555512 step=0.100000
2017/08/26 11:11:33 Saving...
2017/08/26 11:11:33 Gathering batch of experience...
2017/08/26 11:11:48 batch 14: mean=15.021277 stddev=6.268765 entropy=1.092829 frames=36052 count=47
2017/08/26 11:11:48 Training policy...
2017/08/26 11:11:51 step 0: objective=0.04869099
2017/08/26 11:11:53 step 1: objective=0.048717704
2017/08/26 11:11:55 step 2: objective=0.04874433
2017/08/26 11:11:57 step 3: objective=0.048770692
2017/08/26 11:11:59 step 4: objective=0.0487964
2017/08/26 11:12:02 step 5: objective=0.048822135
2017/08/26 11:12:04 step 6: objective=0.04884717
2017/08/26 11:12:06 step 7: objective=0.048870713
2017/08/26 11:12:06 Training value function...
2017/08/26 11:12:07 step 0: mse=0.962012 step=0.100000
2017/08/26 11:12:07 step 1: mse=0.909026 step=0.100000
2017/08/26 11:12:08 step 2: mse=0.863551 step=0.100000
2017/08/26 11:12:08 step 3: mse=0.824900 step=0.100000
2017/08/26 11:12:09 step 4: mse=0.795011 step=0.100000
2017/08/26 11:12:09 step 5: mse=0.774264 step=0.100000
2017/08/26 11:12:09 step 6: mse=0.757743 step=0.100000
2017/08/26 11:12:10 step 7: mse=0.744171 step=0.100000
2017/08/26 11:12:10 Saving...
2017/08/26 11:12:10 Gathering batch of experience...
2017/08/26 11:12:25 batch 15: mean=12.820000 stddev=4.827795 entropy=1.110638 frames=36450 count=50
2017/08/26 11:12:25 Training policy...
2017/08/26 11:12:28 step 0: objective=0.0023796773
2017/08/26 11:12:30 step 1: objective=0.00243179
2017/08/26 11:12:32 step 2: objective=0.0024838757
2017/08/26 11:12:34 step 3: objective=0.0025359883
2017/08/26 11:12:36 step 4: objective=0.0025880793
2017/08/26 11:12:38 step 5: objective=0.0026393947
2017/08/26 11:12:40 step 6: objective=0.0026882533
2017/08/26 11:12:42 step 7: objective=0.0027355468
2017/08/26 11:12:42 Training value function...
2017/08/26 11:12:43 step 0: mse=0.485352 step=0.100000
2017/08/26 11:12:44 step 1: mse=0.468835 step=0.100000
2017/08/26 11:12:44 step 2: mse=0.455573 step=0.100000
2017/08/26 11:12:45 step 3: mse=0.441485 step=0.100000
2017/08/26 11:12:45 step 4: mse=0.431891 step=0.100000
2017/08/26 11:12:46 step 5: mse=0.424098 step=0.100000
2017/08/26 11:12:46 step 6: mse=0.417852 step=0.100000
2017/08/26 11:12:47 step 7: mse=0.413283 step=0.100000
2017/08/26 11:12:47 Saving...
2017/08/26 11:12:47 Gathering batch of experience...
2017/08/26 11:13:02 batch 16: mean=15.340909 stddev=6.327944 entropy=1.097196 frames=36197 count=44
2017/08/26 11:13:02 Training policy...
2017/08/26 11:13:05 step 0: objective=0.03304756
2017/08/26 11:13:07 step 1: objective=0.033109497
2017/08/26 11:13:09 step 2: objective=0.03317135
2017/08/26 11:13:11 step 3: objective=0.033232395
2017/08/26 11:13:13 step 4: objective=0.03327417
2017/08/26 11:13:15 step 5: objective=0.033315085
2017/08/26 11:13:17 step 6: objective=0.03335396
2017/08/26 11:13:19 step 7: objective=0.033389196
2017/08/26 11:13:19 Training value function...
2017/08/26 11:13:20 step 0: mse=0.678058 step=0.100000
2017/08/26 11:13:21 step 1: mse=0.648550 step=0.100000
2017/08/26 11:13:21 step 2: mse=0.624031 step=0.100000
2017/08/26 11:13:22 step 3: mse=0.601722 step=0.100000
2017/08/26 11:13:22 step 4: mse=0.584582 step=0.100000
2017/08/26 11:13:23 step 5: mse=0.553328 step=0.100000
2017/08/26 11:13:23 step 6: mse=0.539638 step=0.100000
2017/08/26 11:13:24 step 7: mse=0.527407 step=0.100000
2017/08/26 11:13:24 Saving...
2017/08/26 11:13:24 Gathering batch of experience...
2017/08/26 11:13:38 batch 17: mean=14.521739 stddev=6.835773 entropy=1.106017 frames=35329 count=46
2017/08/26 11:13:38 Training policy...
2017/08/26 11:13:41 step 0: objective=0.0385952
2017/08/26 11:13:43 step 1: objective=0.038682148
2017/08/26 11:13:45 step 2: objective=0.038790263
2017/08/26 11:13:47 step 3: objective=0.038897388
2017/08/26 11:13:49 step 4: objective=0.038991116
2017/08/26 11:13:51 step 5: objective=0.039045397
2017/08/26 11:13:53 step 6: objective=0.039115887
2017/08/26 11:13:56 step 7: objective=0.039153766
2017/08/26 11:13:56 Training value function...
2017/08/26 11:13:56 step 0: mse=0.933437 step=0.100000
2017/08/26 11:13:57 step 1: mse=0.872636 step=0.100000
2017/08/26 11:13:57 step 2: mse=0.823240 step=0.100000
2017/08/26 11:13:58 step 3: mse=0.777260 step=0.100000
2017/08/26 11:13:58 step 4: mse=0.742506 step=0.100000
2017/08/26 11:13:59 step 5: mse=0.711501 step=0.100000
2017/08/26 11:13:59 step 6: mse=0.683661 step=0.100000
2017/08/26 11:14:00 step 7: mse=0.656397 step=0.100000
2017/08/26 11:14:00 Saving...
2017/08/26 11:14:00 Gathering batch of experience...
2017/08/26 11:14:15 batch 18: mean=15.088889 stddev=6.483559 entropy=1.103930 frames=35785 count=45
2017/08/26 11:14:15 Training policy...
2017/08/26 11:14:18 step 0: objective=0.043816183
2017/08/26 11:14:20 step 1: objective=0.04387543
2017/08/26 11:14:22 step 2: objective=0.0439338
2017/08/26 11:14:24 step 3: objective=0.043992057
2017/08/26 11:14:26 step 4: objective=0.044047404
2017/08/26 11:14:28 step 5: objective=0.044073302
2017/08/26 11:14:30 step 6: objective=0.044098098
2017/08/26 11:14:32 step 7: objective=0.044130668
2017/08/26 11:14:32 Training value function...
2017/08/26 11:14:33 step 0: mse=0.899689 step=0.100000
2017/08/26 11:14:33 step 1: mse=0.835854 step=0.100000
2017/08/26 11:14:34 step 2: mse=0.782539 step=0.100000
2017/08/26 11:14:34 step 3: mse=0.739170 step=0.100000
2017/08/26 11:14:35 step 4: mse=0.702299 step=0.100000
2017/08/26 11:14:35 step 5: mse=0.665240 step=0.100000
2017/08/26 11:14:36 step 6: mse=0.638326 step=0.100000
2017/08/26 11:14:36 step 7: mse=0.612671 step=0.100000
2017/08/26 11:14:36 Saving...
2017/08/26 11:14:37 Gathering batch of experience...
2017/08/26 11:14:51 batch 19: mean=14.739130 stddev=6.084316 entropy=1.105051 frames=35881 count=46
2017/08/26 11:14:51 Training policy...
2017/08/26 11:14:54 step 0: objective=0.03194577
2017/08/26 11:14:56 step 1: objective=0.03200483
2017/08/26 11:14:58 step 2: objective=0.03206389
2017/08/26 11:15:01 step 3: objective=0.032122906
2017/08/26 11:15:03 step 4: objective=0.032162778
2017/08/26 11:15:05 step 5: objective=0.032198425
2017/08/26 11:15:07 step 6: objective=0.03225644
2017/08/26 11:15:09 step 7: objective=0.032305166
2017/08/26 11:15:09 Training value function...
2017/08/26 11:15:10 step 0: mse=0.870761 step=0.100000
2017/08/26 11:15:10 step 1: mse=0.825966 step=0.100000
2017/08/26 11:15:11 step 2: mse=0.789877 step=0.100000
2017/08/26 11:15:11 step 3: mse=0.759629 step=0.100000
2017/08/26 11:15:12 step 4: mse=0.735395 step=0.100000
2017/08/26 11:15:12 step 5: mse=0.714475 step=0.100000
2017/08/26 11:15:13 step 6: mse=0.693090 step=0.100000
2017/08/26 11:15:13 step 7: mse=0.678264 step=0.100000
2017/08/26 11:15:13 Saving...
2017/08/26 11:15:13 Gathering batch of experience...
2017/08/26 11:15:28 batch 20: mean=15.333333 stddev=7.609935 entropy=1.091803 frames=35199 count=45
2017/08/26 11:15:28 Training policy...
2017/08/26 11:15:31 step 0: objective=0.043928385
2017/08/26 11:15:33 step 1: objective=0.043973837
2017/08/26 11:15:35 step 2: objective=0.0440191
2017/08/26 11:15:37 step 3: objective=0.044064473
2017/08/26 11:15:39 step 4: objective=0.04410967
2017/08/26 11:15:41 step 5: objective=0.044146717
2017/08/26 11:15:43 step 6: objective=0.04418311
2017/08/26 11:15:45 step 7: objective=0.044218853
2017/08/26 11:15:45 Training value function...
2017/08/26 11:15:46 step 0: mse=1.419249 step=0.100000
2017/08/26 11:15:46 step 1: mse=1.284516 step=0.100000
2017/08/26 11:15:47 step 2: mse=1.176176 step=0.100000
2017/08/26 11:15:47 step 3: mse=1.088191 step=0.100000
2017/08/26 11:15:48 step 4: mse=1.008290 step=0.100000
2017/08/26 11:15:48 step 5: mse=0.943859 step=0.100000
2017/08/26 11:15:49 step 6: mse=0.891892 step=0.100000
2017/08/26 11:15:49 step 7: mse=0.840292 step=0.100000
2017/08/26 11:15:49 Saving...
2017/08/26 11:15:50 Gathering batch of experience...
2017/08/26 11:16:05 batch 21: mean=16.000000 stddev=6.207522 entropy=1.100824 frames=36488 count=45
2017/08/26 11:16:05 Training policy...
2017/08/26 11:16:08 step 0: objective=0.037253007
2017/08/26 11:16:10 step 1: objective=0.037351266
2017/08/26 11:16:12 step 2: objective=0.03744861
2017/08/26 11:16:14 step 3: objective=0.037545573
2017/08/26 11:16:16 step 4: objective=0.03763872
2017/08/26 11:16:18 step 5: objective=0.037738834
2017/08/26 11:16:20 step 6: objective=0.037813593
2017/08/26 11:16:23 step 7: objective=0.037902247
2017/08/26 11:16:23 Training value function...
2017/08/26 11:16:24 step 0: mse=1.070065 step=0.100000
2017/08/26 11:16:24 step 1: mse=0.994549 step=0.100000
2017/08/26 11:16:25 step 2: mse=0.934181 step=0.100000
2017/08/26 11:16:25 step 3: mse=0.883950 step=0.100000
2017/08/26 11:16:26 step 4: mse=0.847781 step=0.100000
2017/08/26 11:16:26 step 5: mse=0.820744 step=0.100000
2017/08/26 11:16:27 step 6: mse=0.783607 step=0.100000
2017/08/26 11:16:27 step 7: mse=0.764593 step=0.100000
2017/08/26 11:16:27 Saving...
2017/08/26 11:16:27 Gathering batch of experience...
2017/08/26 11:16:43 batch 22: mean=14.638298 stddev=5.058911 entropy=1.103321 frames=36819 count=47
2017/08/26 11:16:43 Training policy...
2017/08/26 11:16:46 step 0: objective=0.0077225203
2017/08/26 11:16:48 step 1: objective=0.007778361
2017/08/26 11:16:50 step 2: objective=0.007833523
2017/08/26 11:16:52 step 3: objective=0.007888041
2017/08/26 11:16:55 step 4: objective=0.007940813
2017/08/26 11:16:57 step 5: objective=0.007970262
2017/08/26 11:16:59 step 6: objective=0.007998269
2017/08/26 11:17:01 step 7: objective=0.008021016
2017/08/26 11:17:01 Training value function...
2017/08/26 11:17:02 step 0: mse=0.736391 step=0.100000
2017/08/26 11:17:03 step 1: mse=0.690539 step=0.100000
2017/08/26 11:17:03 step 2: mse=0.655284 step=0.100000
2017/08/26 11:17:04 step 3: mse=0.625520 step=0.100000
2017/08/26 11:17:04 step 4: mse=0.600909 step=0.100000
2017/08/26 11:17:05 step 5: mse=0.582320 step=0.100000
2017/08/26 11:17:05 step 6: mse=0.567118 step=0.100000
2017/08/26 11:17:06 step 7: mse=0.546472 step=0.100000
2017/08/26 11:17:06 Saving...
2017/08/26 11:17:06 Gathering batch of experience...
2017/08/26 11:17:20 batch 23: mean=14.288889 stddev=6.427795 entropy=1.099234 frames=35531 count=45
2017/08/26 11:17:20 Training policy...
2017/08/26 11:17:23 step 0: objective=0.0034165564
2017/08/26 11:17:26 step 1: objective=0.0034625288
2017/08/26 11:17:28 step 2: objective=0.0035085978
2017/08/26 11:17:30 step 3: objective=0.0035547498
2017/08/26 11:17:32 step 4: objective=0.0036010237
2017/08/26 11:17:34 step 5: objective=0.0036473852
2017/08/26 11:17:36 step 6: objective=0.003690846
2017/08/26 11:17:38 step 7: objective=0.0037258998
2017/08/26 11:17:38 Training value function...
2017/08/26 11:17:39 step 0: mse=0.632797 step=0.100000
2017/08/26 11:17:39 step 1: mse=0.592828 step=0.100000
2017/08/26 11:17:40 step 2: mse=0.561049 step=0.100000
2017/08/26 11:17:41 step 3: mse=0.535394 step=0.100000
2017/08/26 11:17:41 step 4: mse=0.514859 step=0.100000
2017/08/26 11:17:42 step 5: mse=0.495031 step=0.100000
2017/08/26 11:17:42 step 6: mse=0.478318 step=0.100000
2017/08/26 11:17:43 step 7: mse=0.464667 step=0.100000
2017/08/26 11:17:43 Saving...
2017/08/26 11:17:43 Gathering batch of experience...
2017/08/26 11:17:58 batch 24: mean=13.916667 stddev=5.449898 entropy=1.097471 frames=36761 count=48
2017/08/26 11:17:58 Training policy...
2017/08/26 11:18:01 step 0: objective=0.03651261
2017/08/26 11:18:03 step 1: objective=0.036544956
2017/08/26 11:18:05 step 2: objective=0.036576934
2017/08/26 11:18:08 step 3: objective=0.036608905
2017/08/26 11:18:10 step 4: objective=0.036640428
2017/08/26 11:18:12 step 5: objective=0.03667157
2017/08/26 11:18:14 step 6: objective=0.036699496
2017/08/26 11:18:16 step 7: objective=0.03671765
2017/08/26 11:18:16 Training value function...
2017/08/26 11:18:17 step 0: mse=0.582193 step=0.100000
2017/08/26 11:18:18 step 1: mse=0.562971 step=0.100000
2017/08/26 11:18:19 step 2: mse=0.536363 step=0.100000
2017/08/26 11:18:19 step 3: mse=0.522056 step=0.100000
2017/08/26 11:18:20 step 4: mse=0.502528 step=0.100000
2017/08/26 11:18:20 step 5: mse=0.491763 step=0.100000
2017/08/26 11:18:21 step 6: mse=0.482100 step=0.100000
2017/08/26 11:18:21 step 7: mse=0.460801 step=0.100000
2017/08/26 11:18:21 Saving...
2017/08/26 11:18:21 Gathering batch of experience...
2017/08/26 11:18:36 batch 25: mean=13.750000 stddev=5.702704 entropy=1.101933 frames=36230 count=48
2017/08/26 11:18:36 Training policy...
2017/08/26 11:18:40 step 0: objective=0.02598482
2017/08/26 11:18:42 step 1: objective=0.026053661
2017/08/26 11:18:44 step 2: objective=0.026123814
2017/08/26 11:18:46 step 3: objective=0.026193526
2017/08/26 11:18:48 step 4: objective=0.026228523
2017/08/26 11:18:50 step 5: objective=0.026288562
2017/08/26 11:18:52 step 6: objective=0.026333103
2017/08/26 11:18:55 step 7: objective=0.02636767
2017/08/26 11:18:55 Training value function...
2017/08/26 11:18:56 step 0: mse=0.885965 step=0.100000
2017/08/26 11:18:56 step 1: mse=0.821102 step=0.100000
2017/08/26 11:18:57 step 2: mse=0.768634 step=0.100000
2017/08/26 11:18:57 step 3: mse=0.726094 step=0.100000
2017/08/26 11:18:58 step 4: mse=0.690664 step=0.100000
2017/08/26 11:18:58 step 5: mse=0.655659 step=0.100000
2017/08/26 11:18:59 step 6: mse=0.631528 step=0.100000
2017/08/26 11:18:59 step 7: mse=0.606877 step=0.100000
2017/08/26 11:18:59 Saving...
2017/08/26 11:19:00 Gathering batch of experience...
2017/08/26 11:19:14 batch 26: mean=13.250000 stddev=4.656984 entropy=1.111228 frames=36064 count=48
2017/08/26 11:19:14 Training policy...
2017/08/26 11:19:18 step 0: objective=0.021780016
2017/08/26 11:19:20 step 1: objective=0.021824267
2017/08/26 11:19:22 step 2: objective=0.021869045
2017/08/26 11:19:24 step 3: objective=0.021902636
2017/08/26 11:19:26 step 4: objective=0.02193611
2017/08/26 11:19:28 step 5: objective=0.021980215
2017/08/26 11:19:30 step 6: objective=0.02202356
2017/08/26 11:19:32 step 7: objective=0.022063501
2017/08/26 11:19:32 Training value function...
2017/08/26 11:19:33 step 0: mse=0.622467 step=0.100000
2017/08/26 11:19:34 step 1: mse=0.586290 step=0.100000
2017/08/26 11:19:35 step 2: mse=0.556425 step=0.100000
2017/08/26 11:19:35 step 3: mse=0.535729 step=0.100000
2017/08/26 11:19:36 step 4: mse=0.516997 step=0.100000
2017/08/26 11:19:36 step 5: mse=0.502361 step=0.100000
2017/08/26 11:19:37 step 6: mse=0.488294 step=0.100000
2017/08/26 11:19:37 step 7: mse=0.478285 step=0.100000
2017/08/26 11:19:37 Saving...
2017/08/26 11:19:37 Gathering batch of experience...
2017/08/26 11:19:53 batch 27: mean=14.804348 stddev=6.648372 entropy=1.101575 frames=36567 count=46
2017/08/26 11:19:53 Training policy...
2017/08/26 11:19:56 step 0: objective=0.042602427
2017/08/26 11:19:58 step 1: objective=0.042643283
2017/08/26 11:20:00 step 2: objective=0.042684104
2017/08/26 11:20:02 step 3: objective=0.042723905
2017/08/26 11:20:05 step 4: objective=0.042764198
2017/08/26 11:20:07 step 5: objective=0.042803705
2017/08/26 11:20:09 step 6: objective=0.042843096
2017/08/26 11:20:11 step 7: objective=0.04287471
2017/08/26 11:20:11 Training value function...
2017/08/26 11:20:12 step 0: mse=0.807441 step=0.100000
2017/08/26 11:20:13 step 1: mse=0.766031 step=0.100000
2017/08/26 11:20:13 step 2: mse=0.732556 step=0.100000
2017/08/26 11:20:14 step 3: mse=0.690460 step=0.100000
2017/08/26 11:20:14 step 4: mse=0.663862 step=0.100000
2017/08/26 11:20:15 step 5: mse=0.630256 step=0.100000
2017/08/26 11:20:15 step 6: mse=0.612654 step=0.100000
2017/08/26 11:20:16 step 7: mse=0.586135 step=0.100000
2017/08/26 11:20:16 Saving...
2017/08/26 11:20:16 Gathering batch of experience...
2017/08/26 11:20:31 batch 28: mean=14.170213 stddev=6.054080 entropy=1.090268 frames=36435 count=47
2017/08/26 11:20:31 Training policy...
2017/08/26 11:20:34 step 0: objective=0.022146573
2017/08/26 11:20:37 step 1: objective=0.022203503
2017/08/26 11:20:39 step 2: objective=0.022259971
2017/08/26 11:20:41 step 3: objective=0.022313088
2017/08/26 11:20:43 step 4: objective=0.022357224
2017/08/26 11:20:45 step 5: objective=0.022397013
2017/08/26 11:20:48 step 6: objective=0.022436317
2017/08/26 11:20:50 step 7: objective=0.02246929
2017/08/26 11:20:50 Training value function...
2017/08/26 11:20:51 step 0: mse=0.621888 step=0.100000
2017/08/26 11:20:51 step 1: mse=0.585541 step=0.100000
2017/08/26 11:20:52 step 2: mse=0.556379 step=0.100000
2017/08/26 11:20:52 step 3: mse=0.529018 step=0.100000
2017/08/26 11:20:53 step 4: mse=0.507424 step=0.100000
2017/08/26 11:20:53 step 5: mse=0.489514 step=0.100000
2017/08/26 11:20:54 step 6: mse=0.473216 step=0.100000
2017/08/26 11:20:55 step 7: mse=0.458684 step=0.100000
2017/08/26 11:20:55 Saving...
2017/08/26 11:20:55 Gathering batch of experience...
2017/08/26 11:21:10 batch 29: mean=15.608696 stddev=6.948501 entropy=1.089847 frames=37529 count=46
2017/08/26 11:21:10 Training policy...
2017/08/26 11:21:13 step 0: objective=0.046493627
2017/08/26 11:21:16 step 1: objective=0.04654345
2017/08/26 11:21:18 step 2: objective=0.04659343
2017/08/26 11:21:20 step 3: objective=0.04664367
2017/08/26 11:21:22 step 4: objective=0.046684608
2017/08/26 11:21:25 step 5: objective=0.04670439
2017/08/26 11:21:27 step 6: objective=0.046729885
2017/08/26 11:21:29 step 7: objective=0.046761088
2017/08/26 11:21:29 Training value function...
2017/08/26 11:21:30 step 0: mse=0.920253 step=0.100000
2017/08/26 11:21:31 step 1: mse=0.851649 step=0.100000
2017/08/26 11:21:31 step 2: mse=0.794992 step=0.100000
2017/08/26 11:21:32 step 3: mse=0.744017 step=0.100000
2017/08/26 11:21:32 step 4: mse=0.705786 step=0.100000
2017/08/26 11:21:33 step 5: mse=0.670450 step=0.100000
2017/08/26 11:21:34 step 6: mse=0.642083 step=0.100000
2017/08/26 11:21:34 step 7: mse=0.616743 step=0.100000
2017/08/26 11:21:34 Saving...
2017/08/26 11:21:34 Gathering batch of experience...
2017/08/26 11:21:49 batch 30: mean=15.288889 stddev=5.057985 entropy=1.100839 frames=36098 count=45
2017/08/26 11:21:49 Training policy...
2017/08/26 11:21:52 step 0: objective=0.034421977
2017/08/26 11:21:55 step 1: objective=0.03445854
2017/08/26 11:21:57 step 2: objective=0.034495518
2017/08/26 11:21:59 step 3: objective=0.034532975
2017/08/26 11:22:01 step 4: objective=0.03457086
2017/08/26 11:22:03 step 5: objective=0.03460837
2017/08/26 11:22:05 step 6: objective=0.034641005
2017/08/26 11:22:07 step 7: objective=0.03466029
2017/08/26 11:22:07 Training value function...
2017/08/26 11:22:08 step 0: mse=0.824135 step=0.100000
2017/08/26 11:22:09 step 1: mse=0.786736 step=0.100000
2017/08/26 11:22:10 step 2: mse=0.755680 step=0.100000
2017/08/26 11:22:10 step 3: mse=0.722420 step=0.100000
2017/08/26 11:22:11 step 4: mse=0.696220 step=0.100000
2017/08/26 11:22:11 step 5: mse=0.672922 step=0.100000
2017/08/26 11:22:12 step 6: mse=0.656645 step=0.100000
2017/08/26 11:22:12 step 7: mse=0.643141 step=0.100000
2017/08/26 11:22:12 Saving...
2017/08/26 11:22:13 Gathering batch of experience...
2017/08/26 11:22:27 batch 31: mean=14.711111 stddev=6.177458 entropy=1.096657 frames=35592 count=45
2017/08/26 11:22:27 Training policy...
2017/08/26 11:22:31 step 0: objective=0.016210182
2017/08/26 11:22:33 step 1: objective=0.016241396
2017/08/26 11:22:35 step 2: objective=0.016272813
2017/08/26 11:22:37 step 3: objective=0.016304402
2017/08/26 11:22:39 step 4: objective=0.01633824
2017/08/26 11:22:41 step 5: objective=0.016369626
2017/08/26 11:22:43 step 6: objective=0.01640004
2017/08/26 11:22:46 step 7: objective=0.016456721
2017/08/26 11:22:46 Training value function...
2017/08/26 11:22:47 step 0: mse=0.643240 step=0.100000
2017/08/26 11:22:47 step 1: mse=0.617653 step=0.100000
2017/08/26 11:22:48 step 2: mse=0.591114 step=0.100000
2017/08/26 11:22:48 step 3: mse=0.573481 step=0.100000
2017/08/26 11:22:49 step 4: mse=0.554118 step=0.100000
2017/08/26 11:22:49 step 5: mse=0.540680 step=0.100000
2017/08/26 11:22:50 step 6: mse=0.527088 step=0.100000
2017/08/26 11:22:51 step 7: mse=0.517306 step=0.100000
2017/08/26 11:22:51 Saving...
2017/08/26 11:22:51 Gathering batch of experience...
2017/08/26 11:23:05 batch 32: mean=13.895833 stddev=6.991780 entropy=1.099599 frames=35375 count=48
2017/08/26 11:23:05 Training policy...
2017/08/26 11:23:09 step 0: objective=0.044231724
2017/08/26 11:23:11 step 1: objective=0.04428812
2017/08/26 11:23:13 step 2: objective=0.04434471
2017/08/26 11:23:15 step 3: objective=0.044401452
2017/08/26 11:23:17 step 4: objective=0.04444949
2017/08/26 11:23:19 step 5: objective=0.044497456
2017/08/26 11:23:21 step 6: objective=0.044539087
2017/08/26 11:23:23 step 7: objective=0.04456906
2017/08/26 11:23:23 Training value function...
2017/08/26 11:23:24 step 0: mse=0.883529 step=0.100000
2017/08/26 11:23:25 step 1: mse=0.815331 step=0.100000
2017/08/26 11:23:26 step 2: mse=0.757556 step=0.100000
2017/08/26 11:23:26 step 3: mse=0.711761 step=0.100000
2017/08/26 11:23:27 step 4: mse=0.671748 step=0.100000
2017/08/26 11:23:27 step 5: mse=0.642153 step=0.100000
2017/08/26 11:23:28 step 6: mse=0.611533 step=0.100000
2017/08/26 11:23:28 step 7: mse=0.588988 step=0.100000
2017/08/26 11:23:28 Saving...
2017/08/26 11:23:28 Gathering batch of experience...
2017/08/26 11:23:44 batch 33: mean=14.604167 stddev=5.415024 entropy=1.101352 frames=37077 count=48
2017/08/26 11:23:44 Training policy...
2017/08/26 11:23:47 step 0: objective=0.025728121
2017/08/26 11:23:49 step 1: objective=0.025780724
2017/08/26 11:23:52 step 2: objective=0.025834082
2017/08/26 11:23:54 step 3: objective=0.025887879
2017/08/26 11:23:56 step 4: objective=0.025942506
2017/08/26 11:23:58 step 5: objective=0.025991995
2017/08/26 11:24:01 step 6: objective=0.026036311
2017/08/26 11:24:03 step 7: objective=0.02607442
2017/08/26 11:24:03 Training value function...
2017/08/26 11:24:04 step 0: mse=0.832982 step=0.100000
2017/08/26 11:24:05 step 1: mse=0.790177 step=0.100000
2017/08/26 11:24:05 step 2: mse=0.749287 step=0.100000
2017/08/26 11:24:06 step 3: mse=0.719638 step=0.100000
2017/08/26 11:24:06 step 4: mse=0.686815 step=0.100000
2017/08/26 11:24:07 step 5: mse=0.658407 step=0.100000
2017/08/26 11:24:08 step 6: mse=0.639501 step=0.100000
2017/08/26 11:24:08 step 7: mse=0.606786 step=0.100000
2017/08/26 11:24:08 Saving...
2017/08/26 11:24:08 Gathering batch of experience...
2017/08/26 11:24:23 batch 34: mean=15.477273 stddev=6.232206 entropy=1.094573 frames=36523 count=44
2017/08/26 11:24:23 Training policy...
2017/08/26 11:24:27 step 0: objective=0.029243836
2017/08/26 11:24:29 step 1: objective=0.029304212
2017/08/26 11:24:31 step 2: objective=0.029364968
2017/08/26 11:24:33 step 3: objective=0.029425958
2017/08/26 11:24:35 step 4: objective=0.029482359
2017/08/26 11:24:38 step 5: objective=0.029513616
2017/08/26 11:24:40 step 6: objective=0.029556584
2017/08/26 11:24:42 step 7: objective=0.029601417
2017/08/26 11:24:42 Training value function...
2017/08/26 11:24:43 step 0: mse=0.756530 step=0.100000
2017/08/26 11:24:44 step 1: mse=0.696735 step=0.100000
2017/08/26 11:24:44 step 2: mse=0.648543 step=0.100000
2017/08/26 11:24:45 step 3: mse=0.608190 step=0.100000
2017/08/26 11:24:46 step 4: mse=0.575509 step=0.100000
2017/08/26 11:24:46 step 5: mse=0.548143 step=0.100000
2017/08/26 11:24:47 step 6: mse=0.524267 step=0.100000
2017/08/26 11:24:47 step 7: mse=0.506069 step=0.100000
2017/08/26 11:24:47 Saving...
2017/08/26 11:24:47 Gathering batch of experience...
2017/08/26 11:25:03 batch 35: mean=16.022222 stddev=6.005512 entropy=1.096490 frames=36398 count=45
2017/08/26 11:25:03 Training policy...
2017/08/26 11:25:06 step 0: objective=0.04730408
2017/08/26 11:25:08 step 1: objective=0.047388196
2017/08/26 11:25:10 step 2: objective=0.04747302
2017/08/26 11:25:12 step 3: objective=0.047556963
2017/08/26 11:25:15 step 4: objective=0.047631
2017/08/26 11:25:17 step 5: objective=0.047711074
2017/08/26 11:25:19 step 6: objective=0.047809016
2017/08/26 11:25:21 step 7: objective=0.047920097
2017/08/26 11:25:21 Training value function...
2017/08/26 11:25:22 step 0: mse=1.032037 step=0.100000
2017/08/26 11:25:23 step 1: mse=0.971989 step=0.100000
2017/08/26 11:25:23 step 2: mse=0.923475 step=0.100000
2017/08/26 11:25:24 step 3: mse=0.880449 step=0.100000
2017/08/26 11:25:25 step 4: mse=0.847478 step=0.100000
2017/08/26 11:25:25 step 5: mse=0.818020 step=0.100000
2017/08/26 11:25:26 step 6: mse=0.793402 step=0.100000
2017/08/26 11:25:26 step 7: mse=0.774653 step=0.100000
2017/08/26 11:25:26 Saving...
2017/08/26 11:25:27 Gathering batch of experience...
2017/08/26 11:25:42 batch 36: mean=15.000000 stddev=6.018089 entropy=1.095513 frames=35582 count=46
2017/08/26 11:25:42 Training policy...
2017/08/26 11:25:45 step 0: objective=0.045119878
2017/08/26 11:25:47 step 1: objective=0.045142617
2017/08/26 11:25:49 step 2: objective=0.045165572
2017/08/26 11:25:51 step 3: objective=0.045189336
2017/08/26 11:25:54 step 4: objective=0.045212235
2017/08/26 11:25:56 step 5: objective=0.045235492
2017/08/26 11:25:58 step 6: objective=0.04525889
2017/08/26 11:26:00 step 7: objective=0.04528204
2017/08/26 11:26:00 Training value function...
2017/08/26 11:26:01 step 0: mse=0.832654 step=0.100000
2017/08/26 11:26:02 step 1: mse=0.777373 step=0.100000
2017/08/26 11:26:02 step 2: mse=0.731336 step=0.100000
2017/08/26 11:26:03 step 3: mse=0.691232 step=0.100000
2017/08/26 11:26:03 step 4: mse=0.660335 step=0.100000
2017/08/26 11:26:04 step 5: mse=0.631589 step=0.100000
2017/08/26 11:26:05 step 6: mse=0.609735 step=0.100000
2017/08/26 11:26:05 step 7: mse=0.579302 step=0.100000
2017/08/26 11:26:05 Saving...
2017/08/26 11:26:05 Gathering batch of experience...
2017/08/26 11:26:21 batch 37: mean=14.808511 stddev=7.103006 entropy=1.098853 frames=36348 count=47
2017/08/26 11:26:21 Training policy...
2017/08/26 11:26:24 step 0: objective=0.019108897
2017/08/26 11:26:26 step 1: objective=0.019175127
2017/08/26 11:26:28 step 2: objective=0.01924191
2017/08/26 11:26:31 step 3: objective=0.01930846
2017/08/26 11:26:33 step 4: objective=0.019354425
2017/08/26 11:26:35 step 5: objective=0.019397832
2017/08/26 11:26:37 step 6: objective=0.019422129
2017/08/26 11:26:39 step 7: objective=0.019453755
2017/08/26 11:26:39 Training value function...
2017/08/26 11:26:40 step 0: mse=0.898025 step=0.100000
2017/08/26 11:26:41 step 1: mse=0.851031 step=0.100000
2017/08/26 11:26:42 step 2: mse=0.812766 step=0.100000
2017/08/26 11:26:42 step 3: mse=0.780568 step=0.100000
2017/08/26 11:26:43 step 4: mse=0.761942 step=0.100000
2017/08/26 11:26:44 step 5: mse=0.742704 step=0.100000
2017/08/26 11:26:44 step 6: mse=0.728290 step=0.100000
2017/08/26 11:26:45 step 7: mse=0.704796 step=0.100000
2017/08/26 11:26:45 Saving...
2017/08/26 11:26:45 Gathering batch of experience...
2017/08/26 11:27:00 batch 38: mean=13.285714 stddev=6.161102 entropy=1.098028 frames=36168 count=49
2017/08/26 11:27:00 Training policy...
2017/08/26 11:27:03 step 0: objective=0.011655376
2017/08/26 11:27:05 step 1: objective=0.011709281
2017/08/26 11:27:08 step 2: objective=0.011763267
2017/08/26 11:27:10 step 3: objective=0.0118171
2017/08/26 11:27:12 step 4: objective=0.0118707605
2017/08/26 11:27:14 step 5: objective=0.011904715
2017/08/26 11:27:16 step 6: objective=0.0119557455
2017/08/26 11:27:19 step 7: objective=0.011999535
2017/08/26 11:27:19 Training value function...
2017/08/26 11:27:20 step 0: mse=0.783082 step=0.100000
2017/08/26 11:27:20 step 1: mse=0.723791 step=0.100000
2017/08/26 11:27:21 step 2: mse=0.676342 step=0.100000
2017/08/26 11:27:22 step 3: mse=0.638067 step=0.100000
2017/08/26 11:27:22 step 4: mse=0.605876 step=0.100000
2017/08/26 11:27:23 step 5: mse=0.585889 step=0.100000
2017/08/26 11:27:23 step 6: mse=0.562826 step=0.100000
2017/08/26 11:27:24 step 7: mse=0.542859 step=0.100000
2017/08/26 11:27:24 Saving...
2017/08/26 11:27:24 Gathering batch of experience...
2017/08/26 11:27:39 batch 39: mean=14.369565 stddev=5.172497 entropy=1.093781 frames=35619 count=46
2017/08/26 11:27:39 Training policy...
2017/08/26 11:27:42 step 0: objective=0.03364291
2017/08/26 11:27:45 step 1: objective=0.03368199
2017/08/26 11:27:47 step 2: objective=0.0337205
2017/08/26 11:27:49 step 3: objective=0.033759143
2017/08/26 11:27:51 step 4: objective=0.03379755
2017/08/26 11:27:53 step 5: objective=0.03385556
2017/08/26 11:27:56 step 6: objective=0.033913273
2017/08/26 11:27:58 step 7: objective=0.033967104
2017/08/26 11:27:58 Training value function...
2017/08/26 11:27:59 step 0: mse=0.761580 step=0.100000
2017/08/26 11:27:59 step 1: mse=0.705911 step=0.100000
2017/08/26 11:28:00 step 2: mse=0.661324 step=0.100000
2017/08/26 11:28:01 step 3: mse=0.624516 step=0.100000
2017/08/26 11:28:01 step 4: mse=0.596037 step=0.100000
2017/08/26 11:28:02 step 5: mse=0.572528 step=0.100000
2017/08/26 11:28:02 step 6: mse=0.552551 step=0.100000
2017/08/26 11:28:03 step 7: mse=0.533713 step=0.100000
2017/08/26 11:28:03 Saving...
2017/08/26 11:28:03 Gathering batch of experience...
2017/08/26 11:28:18 batch 40: mean=15.152174 stddev=6.230944 entropy=1.088901 frames=36195 count=46
2017/08/26 11:28:18 Training policy...
2017/08/26 11:28:22 step 0: objective=0.04751345
2017/08/26 11:28:24 step 1: objective=0.047584757
2017/08/26 11:28:26 step 2: objective=0.047656134
2017/08/26 11:28:28 step 3: objective=0.04772739
2017/08/26 11:28:30 step 4: objective=0.04779597
2017/08/26 11:28:33 step 5: objective=0.047852613
2017/08/26 11:28:35 step 6: objective=0.047915727
2017/08/26 11:28:37 step 7: objective=0.047944542
2017/08/26 11:28:37 Training value function...
2017/08/26 11:28:38 step 0: mse=0.968062 step=0.100000
2017/08/26 11:28:39 step 1: mse=0.906328 step=0.100000
2017/08/26 11:28:39 step 2: mse=0.855400 step=0.100000
2017/08/26 11:28:40 step 3: mse=0.803494 step=0.100000
2017/08/26 11:28:41 step 4: mse=0.763015 step=0.100000
2017/08/26 11:28:41 step 5: mse=0.725855 step=0.100000
2017/08/26 11:28:42 step 6: mse=0.696123 step=0.100000
2017/08/26 11:28:42 step 7: mse=0.663091 step=0.100000
2017/08/26 11:28:42 Saving...
2017/08/26 11:28:42 Gathering batch of experience...
2017/08/26 11:28:58 batch 41: mean=13.285714 stddev=6.611678 entropy=1.102623 frames=36033 count=49
2017/08/26 11:28:58 Training policy...
2017/08/26 11:29:01 step 0: objective=0.0103933355
2017/08/26 11:29:03 step 1: objective=0.010421963
2017/08/26 11:29:05 step 2: objective=0.010450655
2017/08/26 11:29:08 step 3: objective=0.010479395
2017/08/26 11:29:10 step 4: objective=0.010508172
2017/08/26 11:29:12 step 5: objective=0.010536972
2017/08/26 11:29:14 step 6: objective=0.010565818
2017/08/26 11:29:16 step 7: objective=0.010593098
2017/08/26 11:29:16 Training value function...
2017/08/26 11:29:18 step 0: mse=0.930414 step=0.100000
2017/08/26 11:29:18 step 1: mse=0.836607 step=0.100000
2017/08/26 11:29:19 step 2: mse=0.760540 step=0.100000
2017/08/26 11:29:19 step 3: mse=0.699008 step=0.100000
2017/08/26 11:29:20 step 4: mse=0.647844 step=0.100000
2017/08/26 11:29:21 step 5: mse=0.606648 step=0.100000
2017/08/26 11:29:21 step 6: mse=0.569952 step=0.100000
2017/08/26 11:29:22 step 7: mse=0.538241 step=0.100000
2017/08/26 11:29:22 Saving...
2017/08/26 11:29:22 Gathering batch of experience...
2017/08/26 11:29:38 batch 42: mean=15.239130 stddev=6.587817 entropy=1.091595 frames=37126 count=46
2017/08/26 11:29:38 Training policy...
2017/08/26 11:29:41 step 0: objective=0.038819045
2017/08/26 11:29:44 step 1: objective=0.03887898
2017/08/26 11:29:46 step 2: objective=0.038939
2017/08/26 11:29:48 step 3: objective=0.038999688
2017/08/26 11:29:50 step 4: objective=0.039060332
2017/08/26 11:29:53 step 5: objective=0.039121147
2017/08/26 11:29:55 step 6: objective=0.03917919
2017/08/26 11:29:57 step 7: objective=0.03921452
2017/08/26 11:29:57 Training value function...
2017/08/26 11:29:58 step 0: mse=0.858120 step=0.100000
2017/08/26 11:29:59 step 1: mse=0.805326 step=0.100000
2017/08/26 11:30:00 step 2: mse=0.762313 step=0.100000
2017/08/26 11:30:00 step 3: mse=0.726871 step=0.100000
2017/08/26 11:30:01 step 4: mse=0.697930 step=0.100000
2017/08/26 11:30:02 step 5: mse=0.673471 step=0.100000
2017/08/26 11:30:02 step 6: mse=0.643745 step=0.100000
2017/08/26 11:30:03 step 7: mse=0.619100 step=0.100000
2017/08/26 11:30:03 Saving...
2017/08/26 11:30:03 Gathering batch of experience...
2017/08/26 11:30:19 batch 43: mean=14.851064 stddev=6.490513 entropy=1.088792 frames=37655 count=47
2017/08/26 11:30:19 Training policy...
2017/08/26 11:30:22 step 0: objective=0.018033072
2017/08/26 11:30:25 step 1: objective=0.018081903
2017/08/26 11:30:27 step 2: objective=0.018128376
2017/08/26 11:30:29 step 3: objective=0.018174883
2017/08/26 11:30:32 step 4: objective=0.018223528
2017/08/26 11:30:34 step 5: objective=0.01827201
2017/08/26 11:30:36 step 6: objective=0.01831549
2017/08/26 11:30:39 step 7: objective=0.01837554
2017/08/26 11:30:39 Training value function...
2017/08/26 11:30:40 step 0: mse=0.814119 step=0.100000
2017/08/26 11:30:41 step 1: mse=0.777936 step=0.100000
2017/08/26 11:30:41 step 2: mse=0.752231 step=0.100000
2017/08/26 11:30:42 step 3: mse=0.731282 step=0.100000
2017/08/26 11:30:43 step 4: mse=0.709697 step=0.100000
2017/08/26 11:30:43 step 5: mse=0.694986 step=0.100000
2017/08/26 11:30:44 step 6: mse=0.677972 step=0.100000
2017/08/26 11:30:45 step 7: mse=0.661596 step=0.100000
2017/08/26 11:30:45 Saving...
2017/08/26 11:30:45 Gathering batch of experience...
2017/08/26 11:31:00 batch 44: mean=16.744186 stddev=6.758605 entropy=1.081257 frames=37021 count=43
2017/08/26 11:31:00 Training policy...
2017/08/26 11:31:04 step 0: objective=0.023484396
2017/08/26 11:31:06 step 1: objective=0.023549719
2017/08/26 11:31:09 step 2: objective=0.02361419
2017/08/26 11:31:11 step 3: objective=0.023678478
2017/08/26 11:31:13 step 4: objective=0.023742339
2017/08/26 11:31:15 step 5: objective=0.023805482
2017/08/26 11:31:18 step 6: objective=0.023865625
2017/08/26 11:31:20 step 7: objective=0.023939274
2017/08/26 11:31:20 Training value function...
2017/08/26 11:31:21 step 0: mse=0.942457 step=0.100000
2017/08/26 11:31:22 step 1: mse=0.879393 step=0.100000
2017/08/26 11:31:22 step 2: mse=0.826772 step=0.100000
2017/08/26 11:31:23 step 3: mse=0.784263 step=0.100000
2017/08/26 11:31:24 step 4: mse=0.749211 step=0.100000
2017/08/26 11:31:24 step 5: mse=0.719585 step=0.100000
2017/08/26 11:31:25 step 6: mse=0.694273 step=0.100000
2017/08/26 11:31:26 step 7: mse=0.672294 step=0.100000
2017/08/26 11:31:26 Saving...
2017/08/26 11:31:26 Gathering batch of experience...
2017/08/26 11:31:41 batch 45: mean=14.021277 stddev=6.554159 entropy=1.084587 frames=35986 count=47
2017/08/26 11:31:41 Training policy...
2017/08/26 11:31:44 step 0: objective=0.017152295
2017/08/26 11:31:47 step 1: objective=0.017178252
2017/08/26 11:31:49 step 2: objective=0.017204456
2017/08/26 11:31:51 step 3: objective=0.01723069
2017/08/26 11:31:53 step 4: objective=0.017257182
2017/08/26 11:31:56 step 5: objective=0.017283747
2017/08/26 11:31:58 step 6: objective=0.017305523
2017/08/26 11:32:00 step 7: objective=0.017328544
2017/08/26 11:32:00 Training value function...
2017/08/26 11:32:01 step 0: mse=0.977050 step=0.100000
2017/08/26 11:32:02 step 1: mse=0.895855 step=0.100000
2017/08/26 11:32:03 step 2: mse=0.823689 step=0.100000
2017/08/26 11:32:03 step 3: mse=0.771505 step=0.100000
2017/08/26 11:32:04 step 4: mse=0.722419 step=0.100000
2017/08/26 11:32:04 step 5: mse=0.679762 step=0.100000
2017/08/26 11:32:05 step 6: mse=0.639203 step=0.100000
2017/08/26 11:32:06 step 7: mse=0.611194 step=0.100000
2017/08/26 11:32:06 Saving...
2017/08/26 11:32:06 Gathering batch of experience...
2017/08/26 11:32:22 batch 46: mean=15.042553 stddev=6.661919 entropy=1.099242 frames=36996 count=47
2017/08/26 11:32:22 Training policy...
2017/08/26 11:32:25 step 0: objective=0.045044772
2017/08/26 11:32:28 step 1: objective=0.045082446
2017/08/26 11:32:30 step 2: objective=0.04512011
2017/08/26 11:32:32 step 3: objective=0.04515748
2017/08/26 11:32:34 step 4: objective=0.045194454
2017/08/26 11:32:37 step 5: objective=0.045231003
2017/08/26 11:32:39 step 6: objective=0.045261316
2017/08/26 11:32:41 step 7: objective=0.04528874
2017/08/26 11:32:41 Training value function...
2017/08/26 11:32:42 step 0: mse=0.943081 step=0.100000
2017/08/26 11:32:43 step 1: mse=0.885694 step=0.100000
2017/08/26 11:32:44 step 2: mse=0.838294 step=0.100000
2017/08/26 11:32:44 step 3: mse=0.796220 step=0.100000
2017/08/26 11:32:45 step 4: mse=0.750392 step=0.100000
2017/08/26 11:32:46 step 5: mse=0.715909 step=0.100000
2017/08/26 11:32:46 step 6: mse=0.688901 step=0.100000
2017/08/26 11:32:47 step 7: mse=0.663445 step=0.100000
2017/08/26 11:32:47 Saving...
2017/08/26 11:32:47 Gathering batch of experience...
2017/08/26 11:33:03 batch 47: mean=16.159091 stddev=6.171574 entropy=1.088950 frames=36171 count=44
2017/08/26 11:33:03 Training policy...
2017/08/26 11:33:06 step 0: objective=0.044323586
2017/08/26 11:33:08 step 1: objective=0.044395916
2017/08/26 11:33:11 step 2: objective=0.04446837
2017/08/26 11:33:13 step 3: objective=0.044541072
2017/08/26 11:33:15 step 4: objective=0.044612434
2017/08/26 11:33:17 step 5: objective=0.044680014
2017/08/26 11:33:20 step 6: objective=0.044719055
2017/08/26 11:33:22 step 7: objective=0.044761047
2017/08/26 11:33:22 Training value function...
2017/08/26 11:33:23 step 0: mse=0.919821 step=0.100000
2017/08/26 11:33:24 step 1: mse=0.871131 step=0.100000
2017/08/26 11:33:24 step 2: mse=0.831593 step=0.100000
2017/08/26 11:33:25 step 3: mse=0.784342 step=0.100000
2017/08/26 11:33:26 step 4: mse=0.753343 step=0.100000
2017/08/26 11:33:26 step 5: mse=0.718351 step=0.100000
2017/08/26 11:33:27 step 6: mse=0.698512 step=0.100000
2017/08/26 11:33:28 step 7: mse=0.678431 step=0.100000
2017/08/26 11:33:28 Saving...
2017/08/26 11:33:28 Gathering batch of experience...
2017/08/26 11:33:43 batch 48: mean=14.437500 stddev=6.486866 entropy=1.096816 frames=36450 count=48
2017/08/26 11:33:43 Training policy...
2017/08/26 11:33:47 step 0: objective=0.012752167
2017/08/26 11:33:49 step 1: objective=0.012787401
2017/08/26 11:33:51 step 2: objective=0.012822615
2017/08/26 11:33:53 step 3: objective=0.012856275
2017/08/26 11:33:56 step 4: objective=0.01288991
2017/08/26 11:33:58 step 5: objective=0.0129233645
2017/08/26 11:34:00 step 6: objective=0.012953793
2017/08/26 11:34:02 step 7: objective=0.012976997
2017/08/26 11:34:02 Training value function...
2017/08/26 11:34:03 step 0: mse=0.878522 step=0.100000
2017/08/26 11:34:04 step 1: mse=0.803925 step=0.100000
2017/08/26 11:34:05 step 2: mse=0.743557 step=0.100000
2017/08/26 11:34:05 step 3: mse=0.691283 step=0.100000
2017/08/26 11:34:06 step 4: mse=0.650573 step=0.100000
2017/08/26 11:34:07 step 5: mse=0.612702 step=0.100000
2017/08/26 11:34:07 step 6: mse=0.588593 step=0.100000
2017/08/26 11:34:08 step 7: mse=0.564402 step=0.100000
2017/08/26 11:34:08 Saving...
2017/08/26 11:34:08 Gathering batch of experience...
2017/08/26 11:34:24 batch 49: mean=14.446809 stddev=4.902490 entropy=1.092442 frames=35955 count=47
2017/08/26 11:34:24 Training policy...
2017/08/26 11:34:27 step 0: objective=0.027227353
2017/08/26 11:34:29 step 1: objective=0.027273273
2017/08/26 11:34:32 step 2: objective=0.027319398
2017/08/26 11:34:34 step 3: objective=0.027365698
2017/08/26 11:34:36 step 4: objective=0.027411852
2017/08/26 11:34:38 step 5: objective=0.027454266
2017/08/26 11:34:41 step 6: objective=0.027501127
2017/08/26 11:34:43 step 7: objective=0.027530931
2017/08/26 11:34:43 Training value function...
2017/08/26 11:34:44 step 0: mse=0.624184 step=0.100000
2017/08/26 11:34:45 step 1: mse=0.595222 step=0.100000
2017/08/26 11:34:45 step 2: mse=0.574119 step=0.100000
2017/08/26 11:34:46 step 3: mse=0.553332 step=0.100000
2017/08/26 11:34:47 step 4: mse=0.540402 step=0.100000
2017/08/26 11:34:47 step 5: mse=0.524868 step=0.100000
2017/08/26 11:34:48 step 6: mse=0.511696 step=0.100000
2017/08/26 11:34:49 step 7: mse=0.501035 step=0.100000
2017/08/26 11:34:49 Saving...
2017/08/26 11:34:49 Gathering batch of experience...
2017/08/26 11:35:04 batch 50: mean=15.177778 stddev=6.103875 entropy=1.092645 frames=35667 count=45
2017/08/26 11:35:04 Training policy...
2017/08/26 11:35:07 step 0: objective=0.03069051
2017/08/26 11:35:10 step 1: objective=0.030743621
2017/08/26 11:35:12 step 2: objective=0.030796947
2017/08/26 11:35:14 step 3: objective=0.030848568
2017/08/26 11:35:16 step 4: objective=0.03087723
2017/08/26 11:35:19 step 5: objective=0.03090495
2017/08/26 11:35:21 step 6: objective=0.030931221
2017/08/26 11:35:23 step 7: objective=0.030976586
2017/08/26 11:35:23 Training value function...
2017/08/26 11:35:24 step 0: mse=0.765151 step=0.100000
2017/08/26 11:35:25 step 1: mse=0.720529 step=0.100000
2017/08/26 11:35:25 step 2: mse=0.681163 step=0.100000
2017/08/26 11:35:26 step 3: mse=0.652953 step=0.100000
2017/08/26 11:35:27 step 4: mse=0.616520 step=0.100000
2017/08/26 11:35:27 step 5: mse=0.592685 step=0.100000
2017/08/26 11:35:28 step 6: mse=0.569852 step=0.100000
2017/08/26 11:35:29 step 7: mse=0.552206 step=0.100000
2017/08/26 11:35:29 Saving...
2017/08/26 11:35:29 Gathering batch of experience...
2017/08/26 11:35:44 batch 51: mean=17.761905 stddev=5.747917 entropy=1.083457 frames=35978 count=42
2017/08/26 11:35:44 Training policy...
2017/08/26 11:35:48 step 0: objective=0.0614548
2017/08/26 11:35:50 step 1: objective=0.06153631
2017/08/26 11:35:52 step 2: objective=0.061618384
2017/08/26 11:35:54 step 3: objective=0.061696753
2017/08/26 11:35:57 step 4: objective=0.061739825
2017/08/26 11:35:59 step 5: objective=0.06177882
2017/08/26 11:36:01 step 6: objective=0.061805286
2017/08/26 11:36:03 step 7: objective=0.06188749
2017/08/26 11:36:03 Training value function...
2017/08/26 11:36:05 step 0: mse=1.145426 step=0.100000
2017/08/26 11:36:05 step 1: mse=1.063812 step=0.100000
2017/08/26 11:36:06 step 2: mse=0.995640 step=0.100000
2017/08/26 11:36:07 step 3: mse=0.939657 step=0.100000
2017/08/26 11:36:07 step 4: mse=0.892428 step=0.100000
2017/08/26 11:36:08 step 5: mse=0.849784 step=0.100000
2017/08/26 11:36:09 step 6: mse=0.815009 step=0.100000
2017/08/26 11:36:09 step 7: mse=0.784180 step=0.100000
2017/08/26 11:36:09 Saving...
2017/08/26 11:36:09 Gathering batch of experience...
2017/08/26 11:36:25 batch 52: mean=14.285714 stddev=8.369039 entropy=1.089605 frames=36611 count=49
2017/08/26 11:36:25 Training policy...
2017/08/26 11:36:29 step 0: objective=0.019749785
2017/08/26 11:36:31 step 1: objective=0.01979761
2017/08/26 11:36:33 step 2: objective=0.019844772
2017/08/26 11:36:36 step 3: objective=0.019891564
2017/08/26 11:36:38 step 4: objective=0.019937685
2017/08/26 11:36:40 step 5: objective=0.01998202
2017/08/26 11:36:43 step 6: objective=0.020024402
2017/08/26 11:36:45 step 7: objective=0.020078609
2017/08/26 11:36:45 Training value function...
2017/08/26 11:36:46 step 0: mse=1.425452 step=0.100000
2017/08/26 11:36:47 step 1: mse=1.277346 step=0.100000
2017/08/26 11:36:47 step 2: mse=1.158172 step=0.100000
2017/08/26 11:36:48 step 3: mse=1.058931 step=0.100000
2017/08/26 11:36:49 step 4: mse=0.982831 step=0.100000
2017/08/26 11:36:49 step 5: mse=0.919468 step=0.100000
2017/08/26 11:36:50 step 6: mse=0.864810 step=0.100000
2017/08/26 11:36:51 step 7: mse=0.818965 step=0.100000
2017/08/26 11:36:51 Saving...
2017/08/26 11:36:51 Gathering batch of experience...
2017/08/26 11:37:06 batch 53: mean=14.531915 stddev=6.045399 entropy=1.100543 frames=35677 count=47
2017/08/26 11:37:06 Training policy...
2017/08/26 11:37:10 step 0: objective=0.03789369
2017/08/26 11:37:12 step 1: objective=0.037949536
2017/08/26 11:37:14 step 2: objective=0.038005717
2017/08/26 11:37:16 step 3: objective=0.03806204
2017/08/26 11:37:19 step 4: objective=0.03811865
2017/08/26 11:37:21 step 5: objective=0.038150165
2017/08/26 11:37:23 step 6: objective=0.038173556
2017/08/26 11:37:25 step 7: objective=0.03822531
2017/08/26 11:37:25 Training value function...
2017/08/26 11:37:26 step 0: mse=0.822914 step=0.100000
2017/08/26 11:37:27 step 1: mse=0.766900 step=0.100000
2017/08/26 11:37:28 step 2: mse=0.718774 step=0.100000
2017/08/26 11:37:28 step 3: mse=0.679530 step=0.100000
2017/08/26 11:37:29 step 4: mse=0.649640 step=0.100000
2017/08/26 11:37:30 step 5: mse=0.618099 step=0.100000
2017/08/26 11:37:30 step 6: mse=0.598996 step=0.100000
2017/08/26 11:37:31 step 7: mse=0.576949 step=0.100000
2017/08/26 11:37:31 Saving...
2017/08/26 11:37:31 Gathering batch of experience...
2017/08/26 11:37:47 batch 54: mean=16.477273 stddev=6.354986 entropy=1.086999 frames=36806 count=44
2017/08/26 11:37:47 Training policy...
2017/08/26 11:37:50 step 0: objective=0.043614153
2017/08/26 11:37:53 step 1: objective=0.043688096
2017/08/26 11:37:55 step 2: objective=0.043761734
2017/08/26 11:37:57 step 3: objective=0.043835554
2017/08/26 11:37:59 step 4: objective=0.04390866
2017/08/26 11:38:02 step 5: objective=0.043963436
2017/08/26 11:38:04 step 6: objective=0.04401621
2017/08/26 11:38:06 step 7: objective=0.044077534
2017/08/26 11:38:06 Training value function...
2017/08/26 11:38:07 step 0: mse=0.869553 step=0.100000
2017/08/26 11:38:08 step 1: mse=0.814057 step=0.100000
2017/08/26 11:38:09 step 2: mse=0.770425 step=0.100000
2017/08/26 11:38:10 step 3: mse=0.733015 step=0.100000
2017/08/26 11:38:10 step 4: mse=0.702563 step=0.100000
2017/08/26 11:38:11 step 5: mse=0.674926 step=0.100000
2017/08/26 11:38:12 step 6: mse=0.652800 step=0.100000
2017/08/26 11:38:12 step 7: mse=0.628871 step=0.100000
2017/08/26 11:38:12 Saving...
2017/08/26 11:38:12 Gathering batch of experience...
2017/08/26 11:38:28 batch 55: mean=16.444444 stddev=7.398365 entropy=1.086327 frames=36245 count=45
2017/08/26 11:38:28 Training policy...
2017/08/26 11:38:32 step 0: objective=0.033801347
2017/08/26 11:38:34 step 1: objective=0.033841502
2017/08/26 11:38:36 step 2: objective=0.03388132
2017/08/26 11:38:38 step 3: objective=0.033921696
2017/08/26 11:38:41 step 4: objective=0.033961564
2017/08/26 11:38:43 step 5: objective=0.03400086
2017/08/26 11:38:45 step 6: objective=0.034032237
2017/08/26 11:38:47 step 7: objective=0.034094665
2017/08/26 11:38:47 Training value function...
2017/08/26 11:38:49 step 0: mse=1.001888 step=0.100000
2017/08/26 11:38:49 step 1: mse=0.937674 step=0.100000
2017/08/26 11:38:50 step 2: mse=0.886184 step=0.100000
2017/08/26 11:38:51 step 3: mse=0.843664 step=0.100000
2017/08/26 11:38:51 step 4: mse=0.806983 step=0.100000
2017/08/26 11:38:52 step 5: mse=0.775546 step=0.100000
2017/08/26 11:38:53 step 6: mse=0.750263 step=0.100000
2017/08/26 11:38:54 step 7: mse=0.727039 step=0.100000
2017/08/26 11:38:54 Saving...
2017/08/26 11:38:54 Gathering batch of experience...
2017/08/26 11:39:09 batch 56: mean=15.326087 stddev=6.855827 entropy=1.102162 frames=36607 count=46
2017/08/26 11:39:09 Training policy...
2017/08/26 11:39:13 step 0: objective=0.012192453
2017/08/26 11:39:15 step 1: objective=0.012262806
2017/08/26 11:39:18 step 2: objective=0.012333598
2017/08/26 11:39:20 step 3: objective=0.012404708
2017/08/26 11:39:22 step 4: objective=0.012464996
2017/08/26 11:39:24 step 5: objective=0.012537029
2017/08/26 11:39:27 step 6: objective=0.012602893
2017/08/26 11:39:29 step 7: objective=0.012684881
2017/08/26 11:39:29 Training value function...
2017/08/26 11:39:30 step 0: mse=0.985066 step=0.100000
2017/08/26 11:39:31 step 1: mse=0.924087 step=0.100000
2017/08/26 11:39:32 step 2: mse=0.881862 step=0.100000
2017/08/26 11:39:32 step 3: mse=0.839988 step=0.100000
2017/08/26 11:39:33 step 4: mse=0.809840 step=0.100000
2017/08/26 11:39:34 step 5: mse=0.769656 step=0.100000
2017/08/26 11:39:35 step 6: mse=0.746133 step=0.100000
2017/08/26 11:39:35 step 7: mse=0.717089 step=0.100000
2017/08/26 11:39:35 Saving...
2017/08/26 11:39:35 Gathering batch of experience...
2017/08/26 11:39:51 batch 57: mean=16.288889 stddev=6.554463 entropy=1.093545 frames=35920 count=45
2017/08/26 11:39:51 Training policy...
2017/08/26 11:39:54 step 0: objective=0.051359076
2017/08/26 11:39:57 step 1: objective=0.05140299
2017/08/26 11:39:59 step 2: objective=0.051446553
2017/08/26 11:40:01 step 3: objective=0.05149215
2017/08/26 11:40:03 step 4: objective=0.05153782
2017/08/26 11:40:06 step 5: objective=0.051575568
2017/08/26 11:40:08 step 6: objective=0.05165184
2017/08/26 11:40:10 step 7: objective=0.051696748
2017/08/26 11:40:10 Training value function...
2017/08/26 11:40:11 step 0: mse=1.163585 step=0.100000
2017/08/26 11:40:12 step 1: mse=1.090195 step=0.100000
2017/08/26 11:40:13 step 2: mse=1.032109 step=0.100000
2017/08/26 11:40:14 step 3: mse=0.984174 step=0.100000
2017/08/26 11:40:14 step 4: mse=0.943472 step=0.100000
2017/08/26 11:40:15 step 5: mse=0.905061 step=0.100000
2017/08/26 11:40:16 step 6: mse=0.880875 step=0.100000
2017/08/26 11:40:16 step 7: mse=0.858409 step=0.100000
2017/08/26 11:40:16 Saving...
2017/08/26 11:40:16 Gathering batch of experience...
2017/08/26 11:40:32 batch 58: mean=14.489362 stddev=5.441653 entropy=1.094047 frames=36624 count=47
2017/08/26 11:40:32 Training policy...
2017/08/26 11:40:36 step 0: objective=0.009031473
2017/08/26 11:40:38 step 1: objective=0.009078063
2017/08/26 11:40:40 step 2: objective=0.009124278
2017/08/26 11:40:43 step 3: objective=0.009170125
2017/08/26 11:40:45 step 4: objective=0.009215752
2017/08/26 11:40:47 step 5: objective=0.009258031
2017/08/26 11:40:50 step 6: objective=0.009295088
2017/08/26 11:40:52 step 7: objective=0.009315806
2017/08/26 11:40:52 Training value function...
2017/08/26 11:40:53 step 0: mse=0.637682 step=0.100000
2017/08/26 11:40:54 step 1: mse=0.612433 step=0.100000
2017/08/26 11:40:55 step 2: mse=0.591882 step=0.100000
2017/08/26 11:40:55 step 3: mse=0.574538 step=0.100000
2017/08/26 11:40:56 step 4: mse=0.552385 step=0.100000
2017/08/26 11:40:57 step 5: mse=0.540405 step=0.100000
2017/08/26 11:40:58 step 6: mse=0.519796 step=0.100000
2017/08/26 11:40:58 step 7: mse=0.504022 step=0.100000
2017/08/26 11:40:58 Saving...
2017/08/26 11:40:58 Gathering batch of experience...
2017/08/26 11:41:14 batch 59: mean=17.456522 stddev=8.764321 entropy=1.077949 frames=37181 count=46
2017/08/26 11:41:14 Training policy...
2017/08/26 11:41:18 step 0: objective=0.050049685
2017/08/26 11:41:20 step 1: objective=0.05011214
2017/08/26 11:41:23 step 2: objective=0.050174247
2017/08/26 11:41:25 step 3: objective=0.05023622
2017/08/26 11:41:27 step 4: objective=0.05029778
2017/08/26 11:41:30 step 5: objective=0.05035378
2017/08/26 11:41:32 step 6: objective=0.050406
2017/08/26 11:41:35 step 7: objective=0.05045326
2017/08/26 11:41:35 Training value function...
2017/08/26 11:41:36 step 0: mse=1.276672 step=0.100000
2017/08/26 11:41:36 step 1: mse=1.181152 step=0.100000
2017/08/26 11:41:37 step 2: mse=1.106779 step=0.100000
2017/08/26 11:41:38 step 3: mse=1.036675 step=0.100000
2017/08/26 11:41:39 step 4: mse=0.983026 step=0.100000
2017/08/26 11:41:39 step 5: mse=0.937580 step=0.100000
2017/08/26 11:41:40 step 6: mse=0.895435 step=0.100000
2017/08/26 11:41:41 step 7: mse=0.859696 step=0.100000
2017/08/26 11:41:41 Saving...
2017/08/26 11:41:41 Gathering batch of experience...
2017/08/26 11:41:57 batch 60: mean=15.145833 stddev=6.904074 entropy=1.093787 frames=37134 count=48
2017/08/26 11:41:57 Training policy...
2017/08/26 11:42:01 step 0: objective=0.028505111
2017/08/26 11:42:03 step 1: objective=0.02854344
2017/08/26 11:42:05 step 2: objective=0.02858201
2017/08/26 11:42:08 step 3: objective=0.02862052
2017/08/26 11:42:10 step 4: objective=0.028659167
2017/08/26 11:42:12 step 5: objective=0.02869401
2017/08/26 11:42:15 step 6: objective=0.028723564
2017/08/26 11:42:17 step 7: objective=0.028773045
2017/08/26 11:42:17 Training value function...
2017/08/26 11:42:18 step 0: mse=1.177570 step=0.100000
2017/08/26 11:42:19 step 1: mse=1.085117 step=0.100000
2017/08/26 11:42:20 step 2: mse=1.010918 step=0.100000
2017/08/26 11:42:21 step 3: mse=0.948868 step=0.100000
2017/08/26 11:42:21 step 4: mse=0.894095 step=0.100000
2017/08/26 11:42:22 step 5: mse=0.849386 step=0.100000
2017/08/26 11:42:23 step 6: mse=0.812794 step=0.100000
2017/08/26 11:42:24 step 7: mse=0.778183 step=0.100000
2017/08/26 11:42:24 Saving...
2017/08/26 11:42:24 Gathering batch of experience...
2017/08/26 11:42:39 batch 61: mean=14.666667 stddev=6.577529 entropy=1.098360 frames=36363 count=48
2017/08/26 11:42:39 Training policy...
2017/08/26 11:42:43 step 0: objective=0.03370108
2017/08/26 11:42:45 step 1: objective=0.033736568
2017/08/26 11:42:48 step 2: objective=0.033772033
2017/08/26 11:42:50 step 3: objective=0.03380714
2017/08/26 11:42:52 step 4: objective=0.033842284
2017/08/26 11:42:55 step 5: objective=0.033877213
2017/08/26 11:42:57 step 6: objective=0.03390955
2017/08/26 11:42:59 step 7: objective=0.03394185
2017/08/26 11:42:59 Training value function...
2017/08/26 11:43:01 step 0: mse=0.839696 step=0.100000
2017/08/26 11:43:01 step 1: mse=0.799606 step=0.100000
2017/08/26 11:43:02 step 2: mse=0.766986 step=0.100000
2017/08/26 11:43:03 step 3: mse=0.741552 step=0.100000
2017/08/26 11:43:04 step 4: mse=0.720622 step=0.100000
2017/08/26 11:43:04 step 5: mse=0.703592 step=0.100000
2017/08/26 11:43:05 step 6: mse=0.683009 step=0.100000
2017/08/26 11:43:06 step 7: mse=0.665024 step=0.100000
2017/08/26 11:43:06 Saving...
2017/08/26 11:43:06 Gathering batch of experience...
2017/08/26 11:43:21 batch 62: mean=15.844444 stddev=6.025706 entropy=1.102468 frames=36273 count=45
2017/08/26 11:43:21 Training policy...
2017/08/26 11:43:25 step 0: objective=0.026471749
2017/08/26 11:43:27 step 1: objective=0.026511954
2017/08/26 11:43:30 step 2: objective=0.026551986
2017/08/26 11:43:32 step 3: objective=0.0265919
2017/08/26 11:43:34 step 4: objective=0.026626749
2017/08/26 11:43:37 step 5: objective=0.026680358
2017/08/26 11:43:39 step 6: objective=0.026733536
2017/08/26 11:43:41 step 7: objective=0.026785495
2017/08/26 11:43:41 Training value function...
2017/08/26 11:43:43 step 0: mse=0.757376 step=0.100000
2017/08/26 11:43:43 step 1: mse=0.725616 step=0.100000
2017/08/26 11:43:44 step 2: mse=0.701599 step=0.100000
2017/08/26 11:43:45 step 3: mse=0.681858 step=0.100000
2017/08/26 11:43:46 step 4: mse=0.656006 step=0.100000
2017/08/26 11:43:46 step 5: mse=0.640780 step=0.100000
2017/08/26 11:43:47 step 6: mse=0.628780 step=0.100000
2017/08/26 11:43:48 step 7: mse=0.611318 step=0.100000
2017/08/26 11:43:48 Saving...
2017/08/26 11:43:48 Gathering batch of experience...
2017/08/26 11:44:03 batch 63: mean=14.652174 stddev=5.771811 entropy=1.097696 frames=36267 count=46
2017/08/26 11:44:03 Training policy...
2017/08/26 11:44:07 step 0: objective=0.013532011
2017/08/26 11:44:10 step 1: objective=0.013562712
2017/08/26 11:44:12 step 2: objective=0.013593592
2017/08/26 11:44:14 step 3: objective=0.013624518
2017/08/26 11:44:17 step 4: objective=0.013655496
2017/08/26 11:44:19 step 5: objective=0.0136865135
2017/08/26 11:44:21 step 6: objective=0.013717509
2017/08/26 11:44:24 step 7: objective=0.013747127
2017/08/26 11:44:24 Training value function...
2017/08/26 11:44:25 step 0: mse=0.745593 step=0.100000
2017/08/26 11:44:25 step 1: mse=0.715730 step=0.100000
2017/08/26 11:44:26 step 2: mse=0.691868 step=0.100000
2017/08/26 11:44:27 step 3: mse=0.670747 step=0.100000
2017/08/26 11:44:28 step 4: mse=0.656560 step=0.100000
2017/08/26 11:44:28 step 5: mse=0.635913 step=0.100000
2017/08/26 11:44:29 step 6: mse=0.624265 step=0.100000
2017/08/26 11:44:30 step 7: mse=0.610999 step=0.100000
2017/08/26 11:44:30 Saving...
2017/08/26 11:44:30 Gathering batch of experience...
2017/08/26 11:44:45 batch 64: mean=13.680851 stddev=5.019563 entropy=1.097482 frames=35476 count=47
2017/08/26 11:44:45 Training policy...
2017/08/26 11:44:49 step 0: objective=0.019354602
2017/08/26 11:44:51 step 1: objective=0.019420233
2017/08/26 11:44:53 step 2: objective=0.019486412
2017/08/26 11:44:56 step 3: objective=0.019553082
2017/08/26 11:44:58 step 4: objective=0.019596843
2017/08/26 11:45:00 step 5: objective=0.019637898
2017/08/26 11:45:02 step 6: objective=0.01969478
2017/08/26 11:45:05 step 7: objective=0.019750314
2017/08/26 11:45:05 Training value function...
2017/08/26 11:45:06 step 0: mse=0.561508 step=0.100000
2017/08/26 11:45:07 step 1: mse=0.531621 step=0.100000
2017/08/26 11:45:07 step 2: mse=0.506302 step=0.100000
2017/08/26 11:45:08 step 3: mse=0.483793 step=0.100000
2017/08/26 11:45:09 step 4: mse=0.469489 step=0.100000
2017/08/26 11:45:09 step 5: mse=0.459212 step=0.100000
2017/08/26 11:45:10 step 6: mse=0.447168 step=0.100000
2017/08/26 11:45:11 step 7: mse=0.442254 step=0.100000
2017/08/26 11:45:11 Saving...
2017/08/26 11:45:11 Gathering batch of experience...
2017/08/26 11:45:26 batch 65: mean=15.644444 stddev=5.933541 entropy=1.099602 frames=36225 count=45
2017/08/26 11:45:26 Training policy...
2017/08/26 11:45:30 step 0: objective=0.04364618
2017/08/26 11:45:33 step 1: objective=0.0436972
2017/08/26 11:45:35 step 2: objective=0.043747764
2017/08/26 11:45:37 step 3: objective=0.043797586
2017/08/26 11:45:40 step 4: objective=0.043884713
2017/08/26 11:45:42 step 5: objective=0.043967154
2017/08/26 11:45:44 step 6: objective=0.044045404
2017/08/26 11:45:47 step 7: objective=0.04412007
2017/08/26 11:45:47 Training value function...
2017/08/26 11:45:48 step 0: mse=0.811915 step=0.100000
2017/08/26 11:45:48 step 1: mse=0.744852 step=0.100000
2017/08/26 11:45:49 step 2: mse=0.695094 step=0.100000
2017/08/26 11:45:50 step 3: mse=0.655000 step=0.100000
2017/08/26 11:45:51 step 4: mse=0.622407 step=0.100000
2017/08/26 11:45:51 step 5: mse=0.596171 step=0.100000
2017/08/26 11:45:52 step 6: mse=0.568558 step=0.100000
2017/08/26 11:45:53 step 7: mse=0.549650 step=0.100000
2017/08/26 11:45:53 Saving...
2017/08/26 11:45:53 Gathering batch of experience...
2017/08/26 11:46:08 batch 66: mean=14.866667 stddev=6.588205 entropy=1.081151 frames=35970 count=45
2017/08/26 11:46:08 Training policy...
2017/08/26 11:46:12 step 0: objective=0.028854014
2017/08/26 11:46:15 step 1: objective=0.028897097
2017/08/26 11:46:17 step 2: objective=0.0289458
2017/08/26 11:46:19 step 3: objective=0.028993689
2017/08/26 11:46:22 step 4: objective=0.029039936
2017/08/26 11:46:24 step 5: objective=0.029070303
2017/08/26 11:46:26 step 6: objective=0.02910503
2017/08/26 11:46:28 step 7: objective=0.029139189
2017/08/26 11:46:28 Training value function...
2017/08/26 11:46:30 step 0: mse=0.617596 step=0.100000
2017/08/26 11:46:30 step 1: mse=0.582423 step=0.100000
2017/08/26 11:46:31 step 2: mse=0.552325 step=0.100000
2017/08/26 11:46:32 step 3: mse=0.527391 step=0.100000
2017/08/26 11:46:33 step 4: mse=0.507144 step=0.100000
2017/08/26 11:46:33 step 5: mse=0.490075 step=0.100000
2017/08/26 11:46:34 step 6: mse=0.473615 step=0.100000
2017/08/26 11:46:35 step 7: mse=0.460655 step=0.100000
2017/08/26 11:46:35 Saving...
2017/08/26 11:46:35 Gathering batch of experience...
2017/08/26 11:46:50 batch 67: mean=15.622222 stddev=6.880856 entropy=1.093845 frames=36069 count=45
2017/08/26 11:46:50 Training policy...
2017/08/26 11:46:54 step 0: objective=0.05503057
2017/08/26 11:46:57 step 1: objective=0.055111043
2017/08/26 11:46:59 step 2: objective=0.05519194
2017/08/26 11:47:01 step 3: objective=0.055273004
2017/08/26 11:47:04 step 4: objective=0.055349596
2017/08/26 11:47:06 step 5: objective=0.055415068
2017/08/26 11:47:08 step 6: objective=0.055484794
2017/08/26 11:47:10 step 7: objective=0.055550035
2017/08/26 11:47:10 Training value function...
2017/08/26 11:47:12 step 0: mse=0.911395 step=0.100000
2017/08/26 11:47:12 step 1: mse=0.847555 step=0.100000
2017/08/26 11:47:13 step 2: mse=0.781529 step=0.100000
2017/08/26 11:47:14 step 3: mse=0.727983 step=0.100000
2017/08/26 11:47:15 step 4: mse=0.691034 step=0.100000
2017/08/26 11:47:15 step 5: mse=0.652267 step=0.100000
2017/08/26 11:47:16 step 6: mse=0.626405 step=0.100000
2017/08/26 11:47:17 step 7: mse=0.596847 step=0.100000
2017/08/26 11:47:17 Saving...
2017/08/26 11:47:17 Gathering batch of experience...
2017/08/26 11:47:32 batch 68: mean=15.276596 stddev=8.912583 entropy=1.093971 frames=36126 count=47
2017/08/26 11:47:32 Training policy...
2017/08/26 11:47:36 step 0: objective=0.043172657
2017/08/26 11:47:38 step 1: objective=0.043220665
2017/08/26 11:47:41 step 2: objective=0.043269265
2017/08/26 11:47:43 step 3: objective=0.043318003
2017/08/26 11:47:45 step 4: objective=0.04336484
2017/08/26 11:47:48 step 5: objective=0.04339729
2017/08/26 11:47:50 step 6: objective=0.043414943
2017/08/26 11:47:53 step 7: objective=0.043454416
2017/08/26 11:47:53 Training value function...
2017/08/26 11:47:54 step 0: mse=1.018320 step=0.100000
2017/08/26 11:47:54 step 1: mse=0.946504 step=0.100000
2017/08/26 11:47:55 step 2: mse=0.886077 step=0.100000
2017/08/26 11:47:56 step 3: mse=0.836916 step=0.100000
2017/08/26 11:47:57 step 4: mse=0.794728 step=0.100000
2017/08/26 11:47:57 step 5: mse=0.762351 step=0.100000
2017/08/26 11:47:58 step 6: mse=0.732555 step=0.100000
2017/08/26 11:47:59 step 7: mse=0.708493 step=0.100000
2017/08/26 11:47:59 Saving...
2017/08/26 11:47:59 Gathering batch of experience...
2017/08/26 11:48:15 batch 69: mean=15.586957 stddev=8.759035 entropy=1.084249 frames=37214 count=46
2017/08/26 11:48:15 Training policy...
2017/08/26 11:48:19 step 0: objective=0.026931737
2017/08/26 11:48:21 step 1: objective=0.027022058
2017/08/26 11:48:24 step 2: objective=0.027112758
2017/08/26 11:48:26 step 3: objective=0.027203122
2017/08/26 11:48:29 step 4: objective=0.027282966
2017/08/26 11:48:31 step 5: objective=0.027344974
2017/08/26 11:48:33 step 6: objective=0.027430313
2017/08/26 11:48:36 step 7: objective=0.02745702
2017/08/26 11:48:36 Training value function...
2017/08/26 11:48:37 step 0: mse=1.211854 step=0.100000
2017/08/26 11:48:38 step 1: mse=1.130372 step=0.100000
2017/08/26 11:48:39 step 2: mse=1.066760 step=0.100000
2017/08/26 11:48:39 step 3: mse=1.011515 step=0.100000
2017/08/26 11:48:40 step 4: mse=0.966776 step=0.100000
2017/08/26 11:48:41 step 5: mse=0.929584 step=0.100000
2017/08/26 11:48:42 step 6: mse=0.898000 step=0.100000
2017/08/26 11:48:42 step 7: mse=0.875934 step=0.100000
2017/08/26 11:48:42 Saving...
2017/08/26 11:48:42 Gathering batch of experience...
2017/08/26 11:48:58 batch 70: mean=15.500000 stddev=6.655335 entropy=1.096446 frames=37156 count=46
2017/08/26 11:48:58 Training policy...
2017/08/26 11:49:02 step 0: objective=0.026558593
2017/08/26 11:49:05 step 1: objective=0.026621893
2017/08/26 11:49:07 step 2: objective=0.026685042
2017/08/26 11:49:10 step 3: objective=0.026747996
2017/08/26 11:49:12 step 4: objective=0.026783401
2017/08/26 11:49:15 step 5: objective=0.026817502
2017/08/26 11:49:17 step 6: objective=0.02685751
2017/08/26 11:49:19 step 7: objective=0.026890662
2017/08/26 11:49:19 Training value function...
2017/08/26 11:49:21 step 0: mse=0.777878 step=0.100000
2017/08/26 11:49:21 step 1: mse=0.727301 step=0.100000
2017/08/26 11:49:22 step 2: mse=0.686288 step=0.100000
2017/08/26 11:49:23 step 3: mse=0.653742 step=0.100000
2017/08/26 11:49:24 step 4: mse=0.627195 step=0.100000
2017/08/26 11:49:24 step 5: mse=0.605668 step=0.100000
2017/08/26 11:49:25 step 6: mse=0.589451 step=0.100000
2017/08/26 11:49:26 step 7: mse=0.572290 step=0.100000
2017/08/26 11:49:26 Saving...
2017/08/26 11:49:26 Gathering batch of experience...
2017/08/26 11:49:41 batch 71: mean=14.125000 stddev=6.349623 entropy=1.093978 frames=35741 count=48
2017/08/26 11:49:41 Training policy...
2017/08/26 11:49:45 step 0: objective=0.033773188
2017/08/26 11:49:47 step 1: objective=0.033821166
2017/08/26 11:49:50 step 2: objective=0.03386963
2017/08/26 11:49:52 step 3: objective=0.03391873
2017/08/26 11:49:54 step 4: objective=0.033965882
2017/08/26 11:49:57 step 5: objective=0.03401394
2017/08/26 11:49:59 step 6: objective=0.034052864
2017/08/26 11:50:01 step 7: objective=0.034085605
2017/08/26 11:50:01 Training value function...
2017/08/26 11:50:03 step 0: mse=0.911758 step=0.100000
2017/08/26 11:50:03 step 1: mse=0.861955 step=0.100000
2017/08/26 11:50:04 step 2: mse=0.820069 step=0.100000
2017/08/26 11:50:05 step 3: mse=0.785706 step=0.100000
2017/08/26 11:50:06 step 4: mse=0.757345 step=0.100000
2017/08/26 11:50:06 step 5: mse=0.727288 step=0.100000
2017/08/26 11:50:07 step 6: mse=0.705061 step=0.100000
2017/08/26 11:50:08 step 7: mse=0.686868 step=0.100000
2017/08/26 11:50:08 Saving...
2017/08/26 11:50:08 Gathering batch of experience...
2017/08/26 11:50:23 batch 72: mean=13.702128 stddev=4.976177 entropy=1.098230 frames=35798 count=47
2017/08/26 11:50:23 Training policy...
2017/08/26 11:50:27 step 0: objective=0.00039182213
2017/08/26 11:50:29 step 1: objective=0.00043943292
2017/08/26 11:50:32 step 2: objective=0.0004868901
2017/08/26 11:50:34 step 3: objective=0.00053422403
2017/08/26 11:50:36 step 4: objective=0.0005808785
2017/08/26 11:50:39 step 5: objective=0.00062214263
2017/08/26 11:50:41 step 6: objective=0.00067686255
2017/08/26 11:50:43 step 7: objective=0.0007320877
2017/08/26 11:50:43 Training value function...
2017/08/26 11:50:44 step 0: mse=1.055893 step=0.100000
2017/08/26 11:50:45 step 1: mse=0.942828 step=0.100000
2017/08/26 11:50:46 step 2: mse=0.854108 step=0.100000
2017/08/26 11:50:47 step 3: mse=0.783316 step=0.100000
2017/08/26 11:50:47 step 4: mse=0.726438 step=0.100000
2017/08/26 11:50:48 step 5: mse=0.681011 step=0.100000
2017/08/26 11:50:49 step 6: mse=0.644439 step=0.100000
2017/08/26 11:50:50 step 7: mse=0.614277 step=0.100000
2017/08/26 11:50:50 Saving...
2017/08/26 11:50:50 Gathering batch of experience...
2017/08/26 11:51:06 batch 73: mean=14.645833 stddev=5.206125 entropy=1.099711 frames=37443 count=48
2017/08/26 11:51:06 Training policy...
2017/08/26 11:51:10 step 0: objective=0.029220507
2017/08/26 11:51:12 step 1: objective=0.02925748
2017/08/26 11:51:15 step 2: objective=0.029294362
2017/08/26 11:51:17 step 3: objective=0.029331546
2017/08/26 11:51:20 step 4: objective=0.029368915
2017/08/26 11:51:22 step 5: objective=0.029406184
2017/08/26 11:51:24 step 6: objective=0.029441059
2017/08/26 11:51:27 step 7: objective=0.029479396
2017/08/26 11:51:27 Training value function...
2017/08/26 11:51:28 step 0: mse=0.731215 step=0.100000
2017/08/26 11:51:29 step 1: mse=0.693814 step=0.100000
2017/08/26 11:51:30 step 2: mse=0.662949 step=0.100000
2017/08/26 11:51:31 step 3: mse=0.638001 step=0.100000
2017/08/26 11:51:31 step 4: mse=0.618084 step=0.100000
2017/08/26 11:51:32 step 5: mse=0.601394 step=0.100000
2017/08/26 11:51:33 step 6: mse=0.587564 step=0.100000
2017/08/26 11:51:34 step 7: mse=0.576533 step=0.100000
2017/08/26 11:51:34 Saving...
2017/08/26 11:51:34 Gathering batch of experience...
2017/08/26 11:51:49 batch 74: mean=13.729167 stddev=4.653581 entropy=1.103014 frames=35612 count=48
2017/08/26 11:51:49 Training policy...
2017/08/26 11:51:53 step 0: objective=0.033696536
2017/08/26 11:51:55 step 1: objective=0.033747874
2017/08/26 11:51:57 step 2: objective=0.033799082
2017/08/26 11:52:00 step 3: objective=0.033850264
2017/08/26 11:52:02 step 4: objective=0.03389948
2017/08/26 11:52:04 step 5: objective=0.03392465
2017/08/26 11:52:07 step 6: objective=0.033949163
2017/08/26 11:52:09 step 7: objective=0.033969082
2017/08/26 11:52:09 Training value function...
2017/08/26 11:52:10 step 0: mse=0.636390 step=0.100000
2017/08/26 11:52:11 step 1: mse=0.615179 step=0.100000
2017/08/26 11:52:12 step 2: mse=0.600720 step=0.100000
2017/08/26 11:52:12 step 3: mse=0.584951 step=0.100000
2017/08/26 11:52:13 step 4: mse=0.574327 step=0.100000
2017/08/26 11:52:14 step 5: mse=0.562292 step=0.100000
2017/08/26 11:52:15 step 6: mse=0.546292 step=0.100000
2017/08/26 11:52:15 step 7: mse=0.535741 step=0.100000
2017/08/26 11:52:15 Saving...
2017/08/26 11:52:15 Gathering batch of experience...
2017/08/26 11:52:31 batch 75: mean=16.863636 stddev=8.167538 entropy=1.081284 frames=36652 count=44
2017/08/26 11:52:31 Training policy...
2017/08/26 11:52:35 step 0: objective=0.061413296
2017/08/26 11:52:37 step 1: objective=0.061489113
2017/08/26 11:52:40 step 2: objective=0.061593127
2017/08/26 11:52:42 step 3: objective=0.06165997
2017/08/26 11:52:45 step 4: objective=0.061726246
2017/08/26 11:52:47 step 5: objective=0.06178598
2017/08/26 11:52:49 step 6: objective=0.06183628
2017/08/26 11:52:52 step 7: objective=0.061920557
2017/08/26 11:52:52 Training value function...
2017/08/26 11:52:53 step 0: mse=1.594954 step=0.100000
2017/08/26 11:52:54 step 1: mse=1.424352 step=0.100000
2017/08/26 11:52:55 step 2: mse=1.286558 step=0.100000
2017/08/26 11:52:55 step 3: mse=1.174934 step=0.100000
2017/08/26 11:52:56 step 4: mse=1.083317 step=0.100000
2017/08/26 11:52:57 step 5: mse=1.007106 step=0.100000
2017/08/26 11:52:58 step 6: mse=0.940333 step=0.100000
2017/08/26 11:52:58 step 7: mse=0.885921 step=0.100000
2017/08/26 11:52:58 Saving...
2017/08/26 11:52:58 Gathering batch of experience...
2017/08/26 11:53:14 batch 76: mean=14.395833 stddev=6.257461 entropy=1.094827 frames=36349 count=48
2017/08/26 11:53:14 Training policy...
2017/08/26 11:53:18 step 0: objective=0.020893112
2017/08/26 11:53:20 step 1: objective=0.0209512
2017/08/26 11:53:23 step 2: objective=0.021008737
2017/08/26 11:53:25 step 3: objective=0.021065906
2017/08/26 11:53:28 step 4: objective=0.02112192
2017/08/26 11:53:30 step 5: objective=0.021162493
2017/08/26 11:53:32 step 6: objective=0.021209495
2017/08/26 11:53:35 step 7: objective=0.021253308
2017/08/26 11:53:35 Training value function...
2017/08/26 11:53:36 step 0: mse=0.876180 step=0.100000
2017/08/26 11:53:37 step 1: mse=0.813129 step=0.100000
2017/08/26 11:53:37 step 2: mse=0.763230 step=0.100000
2017/08/26 11:53:38 step 3: mse=0.724448 step=0.100000
2017/08/26 11:53:39 step 4: mse=0.687597 step=0.100000
2017/08/26 11:53:40 step 5: mse=0.659748 step=0.100000
2017/08/26 11:53:40 step 6: mse=0.625409 step=0.100000
2017/08/26 11:53:41 step 7: mse=0.603543 step=0.100000
2017/08/26 11:53:41 Saving...
2017/08/26 11:53:41 Gathering batch of experience...
2017/08/26 11:53:57 batch 77: mean=14.489362 stddev=5.339027 entropy=1.092984 frames=36573 count=47
2017/08/26 11:53:57 Training policy...
2017/08/26 11:54:01 step 0: objective=0.016713856
2017/08/26 11:54:03 step 1: objective=0.016767055
2017/08/26 11:54:06 step 2: objective=0.016819762
2017/08/26 11:54:08 step 3: objective=0.016872758
2017/08/26 11:54:10 step 4: objective=0.016925884
2017/08/26 11:54:13 step 5: objective=0.01697516
2017/08/26 11:54:15 step 6: objective=0.017018287
2017/08/26 11:54:18 step 7: objective=0.017060803
2017/08/26 11:54:18 Training value function...
2017/08/26 11:54:19 step 0: mse=0.760388 step=0.100000
2017/08/26 11:54:20 step 1: mse=0.719314 step=0.100000
2017/08/26 11:54:20 step 2: mse=0.686519 step=0.100000
2017/08/26 11:54:21 step 3: mse=0.659132 step=0.100000
2017/08/26 11:54:22 step 4: mse=0.637392 step=0.100000
2017/08/26 11:54:23 step 5: mse=0.622317 step=0.100000
2017/08/26 11:54:23 step 6: mse=0.605195 step=0.100000
2017/08/26 11:54:24 step 7: mse=0.581426 step=0.100000
2017/08/26 11:54:24 Saving...
2017/08/26 11:54:24 Gathering batch of experience...
2017/08/26 11:54:39 batch 78: mean=14.347826 stddev=5.576415 entropy=1.091137 frames=35741 count=46
2017/08/26 11:54:39 Training policy...
2017/08/26 11:54:43 step 0: objective=0.016581422
2017/08/26 11:54:46 step 1: objective=0.016635163
2017/08/26 11:54:48 step 2: objective=0.016689094
2017/08/26 11:54:50 step 3: objective=0.016743034
2017/08/26 11:54:53 step 4: objective=0.016792854
2017/08/26 11:54:55 step 5: objective=0.016851379
2017/08/26 11:54:57 step 6: objective=0.016905995
2017/08/26 11:55:00 step 7: objective=0.01693204
2017/08/26 11:55:00 Training value function...
2017/08/26 11:55:01 step 0: mse=0.715414 step=0.100000
2017/08/26 11:55:01 step 1: mse=0.666691 step=0.100000
2017/08/26 11:55:02 step 2: mse=0.627215 step=0.100000
2017/08/26 11:55:03 step 3: mse=0.595026 step=0.100000
2017/08/26 11:55:04 step 4: mse=0.567099 step=0.100000
2017/08/26 11:55:04 step 5: mse=0.543367 step=0.100000
2017/08/26 11:55:05 step 6: mse=0.522643 step=0.100000
2017/08/26 11:55:06 step 7: mse=0.502813 step=0.100000
2017/08/26 11:55:06 Saving...
2017/08/26 11:55:06 Gathering batch of experience...
2017/08/26 11:55:22 batch 79: mean=15.787234 stddev=7.371412 entropy=1.083797 frames=36524 count=47
2017/08/26 11:55:22 Training policy...
2017/08/26 11:55:26 step 0: objective=0.07027392
2017/08/26 11:55:28 step 1: objective=0.070314445
2017/08/26 11:55:31 step 2: objective=0.07035443
2017/08/26 11:55:33 step 3: objective=0.07039515
2017/08/26 11:55:35 step 4: objective=0.07043516
2017/08/26 11:55:38 step 5: objective=0.070473865
2017/08/26 11:55:40 step 6: objective=0.07051171
2017/08/26 11:55:43 step 7: objective=0.070543185
2017/08/26 11:55:43 Training value function...
2017/08/26 11:55:44 step 0: mse=1.188702 step=0.100000
2017/08/26 11:55:45 step 1: mse=1.092241 step=0.100000
2017/08/26 11:55:45 step 2: mse=1.006045 step=0.100000
2017/08/26 11:55:46 step 3: mse=0.940088 step=0.100000
2017/08/26 11:55:47 step 4: mse=0.881417 step=0.100000
2017/08/26 11:55:48 step 5: mse=0.829964 step=0.100000
2017/08/26 11:55:48 step 6: mse=0.782189 step=0.100000
2017/08/26 11:55:49 step 7: mse=0.740016 step=0.100000
2017/08/26 11:55:49 Saving...
2017/08/26 11:55:49 Gathering batch of experience...
2017/08/26 11:56:05 batch 80: mean=15.681818 stddev=6.808326 entropy=1.088649 frames=36081 count=44
2017/08/26 11:56:05 Training policy...
2017/08/26 11:56:09 step 0: objective=0.016510982
2017/08/26 11:56:11 step 1: objective=0.01659215
2017/08/26 11:56:13 step 2: objective=0.016673364
2017/08/26 11:56:16 step 3: objective=0.016754448
2017/08/26 11:56:18 step 4: objective=0.01683554
2017/08/26 11:56:20 step 5: objective=0.01691216
2017/08/26 11:56:23 step 6: objective=0.016952492
2017/08/26 11:56:25 step 7: objective=0.017015934
2017/08/26 11:56:25 Training value function...
2017/08/26 11:56:26 step 0: mse=0.727950 step=0.100000
2017/08/26 11:56:27 step 1: mse=0.702864 step=0.100000
2017/08/26 11:56:28 step 2: mse=0.678869 step=0.100000
2017/08/26 11:56:29 step 3: mse=0.647399 step=0.100000
2017/08/26 11:56:29 step 4: mse=0.631852 step=0.100000
2017/08/26 11:56:30 step 5: mse=0.602958 step=0.100000
2017/08/26 11:56:31 step 6: mse=0.591588 step=0.100000
2017/08/26 11:56:31 step 7: mse=0.571877 step=0.100000
2017/08/26 11:56:31 Saving...
2017/08/26 11:56:32 Gathering batch of experience...
2017/08/26 11:56:47 batch 81: mean=15.911111 stddev=6.411179 entropy=1.083431 frames=36318 count=45
2017/08/26 11:56:47 Training policy...
2017/08/26 11:56:51 step 0: objective=0.053735282
2017/08/26 11:56:54 step 1: objective=0.05378252
2017/08/26 11:56:56 step 2: objective=0.05382962
2017/08/26 11:56:58 step 3: objective=0.05387749
2017/08/26 11:57:01 step 4: objective=0.053925287
2017/08/26 11:57:03 step 5: objective=0.053970948
2017/08/26 11:57:06 step 6: objective=0.054003306
2017/08/26 11:57:08 step 7: objective=0.054032974
2017/08/26 11:57:08 Training value function...
2017/08/26 11:57:09 step 0: mse=1.101399 step=0.100000
2017/08/26 11:57:10 step 1: mse=1.030000 step=0.100000
2017/08/26 11:57:11 step 2: mse=0.973056 step=0.100000
2017/08/26 11:57:12 step 3: mse=0.913428 step=0.100000
2017/08/26 11:57:12 step 4: mse=0.873707 step=0.100000
2017/08/26 11:57:13 step 5: mse=0.835431 step=0.100000
2017/08/26 11:57:14 step 6: mse=0.800601 step=0.100000
2017/08/26 11:57:15 step 7: mse=0.774001 step=0.100000
2017/08/26 11:57:15 Saving...
2017/08/26 11:57:15 Gathering batch of experience...
2017/08/26 11:57:31 batch 82: mean=15.234043 stddev=7.258781 entropy=1.092928 frames=37034 count=47
2017/08/26 11:57:31 Training policy...
2017/08/26 11:57:35 step 0: objective=0.023752682
2017/08/26 11:57:37 step 1: objective=0.023842823
2017/08/26 11:57:40 step 2: objective=0.023933243
2017/08/26 11:57:42 step 3: objective=0.024023883
2017/08/26 11:57:44 step 4: objective=0.024108684
2017/08/26 11:57:47 step 5: objective=0.02415906
2017/08/26 11:57:49 step 6: objective=0.024207534
2017/08/26 11:57:52 step 7: objective=0.024254622
2017/08/26 11:57:52 Training value function...
2017/08/26 11:57:53 step 0: mse=0.805985 step=0.100000
2017/08/26 11:57:54 step 1: mse=0.770141 step=0.100000
2017/08/26 11:57:54 step 2: mse=0.739529 step=0.100000
2017/08/26 11:57:55 step 3: mse=0.715469 step=0.100000
2017/08/26 11:57:56 step 4: mse=0.683012 step=0.100000
2017/08/26 11:57:57 step 5: mse=0.667248 step=0.100000
2017/08/26 11:57:57 step 6: mse=0.645159 step=0.100000
2017/08/26 11:57:58 step 7: mse=0.631861 step=0.100000
2017/08/26 11:57:58 Saving...
2017/08/26 11:57:58 Gathering batch of experience...
2017/08/26 11:58:14 batch 83: mean=15.644444 stddev=6.753289 entropy=1.090279 frames=36168 count=45
2017/08/26 11:58:14 Training policy...
2017/08/26 11:58:18 step 0: objective=0.027542096
2017/08/26 11:58:20 step 1: objective=0.027575962
2017/08/26 11:58:22 step 2: objective=0.027609602
2017/08/26 11:58:25 step 3: objective=0.027643334
2017/08/26 11:58:27 step 4: objective=0.027676769
2017/08/26 11:58:30 step 5: objective=0.027709752
2017/08/26 11:58:32 step 6: objective=0.02773938
2017/08/26 11:58:34 step 7: objective=0.02777922
2017/08/26 11:58:34 Training value function...
2017/08/26 11:58:36 step 0: mse=0.786498 step=0.100000
2017/08/26 11:58:36 step 1: mse=0.733797 step=0.100000
2017/08/26 11:58:37 step 2: mse=0.691464 step=0.100000
2017/08/26 11:58:38 step 3: mse=0.656813 step=0.100000
2017/08/26 11:58:39 step 4: mse=0.628858 step=0.100000
2017/08/26 11:58:39 step 5: mse=0.604125 step=0.100000
2017/08/26 11:58:40 step 6: mse=0.583730 step=0.100000
2017/08/26 11:58:41 step 7: mse=0.564443 step=0.100000
2017/08/26 11:58:41 Saving...
2017/08/26 11:58:41 Gathering batch of experience...
2017/08/26 11:58:57 batch 84: mean=16.933333 stddev=7.939773 entropy=1.083130 frames=37564 count=45
2017/08/26 11:58:57 Training policy...
2017/08/26 11:59:01 step 0: objective=0.035986733
2017/08/26 11:59:04 step 1: objective=0.036025316
2017/08/26 11:59:06 step 2: objective=0.036064126
2017/08/26 11:59:09 step 3: objective=0.03610315
2017/08/26 11:59:11 step 4: objective=0.036142312
2017/08/26 11:59:14 step 5: objective=0.036189448
2017/08/26 11:59:16 step 6: objective=0.036233056
2017/08/26 11:59:19 step 7: objective=0.036278203
2017/08/26 11:59:19 Training value function...
2017/08/26 11:59:20 step 0: mse=1.165692 step=0.100000
2017/08/26 11:59:21 step 1: mse=1.091167 step=0.100000
2017/08/26 11:59:22 step 2: mse=1.031312 step=0.100000
2017/08/26 11:59:22 step 3: mse=0.981330 step=0.100000
2017/08/26 11:59:23 step 4: mse=0.944173 step=0.100000
2017/08/26 11:59:24 step 5: mse=0.909463 step=0.100000
2017/08/26 11:59:25 step 6: mse=0.883142 step=0.100000
2017/08/26 11:59:26 step 7: mse=0.850325 step=0.100000
2017/08/26 11:59:26 Saving...
2017/08/26 11:59:26 Gathering batch of experience...
2017/08/26 11:59:41 batch 85: mean=15.955556 stddev=7.728606 entropy=1.087422 frames=36174 count=45
2017/08/26 11:59:41 Training policy...
2017/08/26 11:59:45 step 0: objective=0.036192972
2017/08/26 11:59:48 step 1: objective=0.036287546
2017/08/26 11:59:50 step 2: objective=0.03638177
2017/08/26 11:59:53 step 3: objective=0.036471937
2017/08/26 11:59:55 step 4: objective=0.036584932
2017/08/26 11:59:57 step 5: objective=0.036660574
2017/08/26 12:00:00 step 6: objective=0.036722608
2017/08/26 12:00:02 step 7: objective=0.036782656
2017/08/26 12:00:02 Training value function...
2017/08/26 12:00:03 step 0: mse=1.218143 step=0.100000
2017/08/26 12:00:04 step 1: mse=1.159118 step=0.100000
2017/08/26 12:00:05 step 2: mse=1.114256 step=0.100000
2017/08/26 12:00:06 step 3: mse=1.069140 step=0.100000
2017/08/26 12:00:06 step 4: mse=1.032095 step=0.100000
2017/08/26 12:00:07 step 5: mse=1.000141 step=0.100000
2017/08/26 12:00:08 step 6: mse=0.971325 step=0.100000
2017/08/26 12:00:09 step 7: mse=0.946753 step=0.100000
2017/08/26 12:00:09 Saving...
2017/08/26 12:00:09 Gathering batch of experience...
2017/08/26 12:00:24 batch 86: mean=15.456522 stddev=7.853846 entropy=1.100286 frames=35038 count=46
2017/08/26 12:00:24 Training policy...
2017/08/26 12:00:28 step 0: objective=0.041950066
2017/08/26 12:00:30 step 1: objective=0.041994434
2017/08/26 12:00:32 step 2: objective=0.04203911
2017/08/26 12:00:35 step 3: objective=0.04208375
2017/08/26 12:00:37 step 4: objective=0.042127892
2017/08/26 12:00:39 step 5: objective=0.042172763
2017/08/26 12:00:42 step 6: objective=0.042215224
2017/08/26 12:00:44 step 7: objective=0.042314913
2017/08/26 12:00:44 Training value function...
2017/08/26 12:00:45 step 0: mse=0.955940 step=0.100000
2017/08/26 12:00:46 step 1: mse=0.893255 step=0.100000
2017/08/26 12:00:47 step 2: mse=0.841064 step=0.100000
2017/08/26 12:00:47 step 3: mse=0.799215 step=0.100000
2017/08/26 12:00:48 step 4: mse=0.763978 step=0.100000
2017/08/26 12:00:49 step 5: mse=0.734038 step=0.100000
2017/08/26 12:00:49 step 6: mse=0.702143 step=0.100000
2017/08/26 12:00:50 step 7: mse=0.681005 step=0.100000
2017/08/26 12:00:50 Saving...
2017/08/26 12:00:50 Gathering batch of experience...
2017/08/26 12:01:06 batch 87: mean=14.382979 stddev=5.766939 entropy=1.091617 frames=36004 count=47
2017/08/26 12:01:06 Training policy...
2017/08/26 12:01:10 step 0: objective=0.0038463862
2017/08/26 12:01:12 step 1: objective=0.0038783108
2017/08/26 12:01:14 step 2: objective=0.0039099646
2017/08/26 12:01:17 step 3: objective=0.0039414205
2017/08/26 12:01:19 step 4: objective=0.0039726747
2017/08/26 12:01:22 step 5: objective=0.004003368
2017/08/26 12:01:24 step 6: objective=0.0040288293
2017/08/26 12:01:26 step 7: objective=0.0040494725
2017/08/26 12:01:26 Training value function...
2017/08/26 12:01:28 step 0: mse=0.798240 step=0.100000
2017/08/26 12:01:28 step 1: mse=0.757996 step=0.100000
2017/08/26 12:01:29 step 2: mse=0.725871 step=0.100000
2017/08/26 12:01:30 step 3: mse=0.700605 step=0.100000
2017/08/26 12:01:31 step 4: mse=0.667107 step=0.100000
2017/08/26 12:01:31 step 5: mse=0.640484 step=0.100000
2017/08/26 12:01:32 step 6: mse=0.616385 step=0.100000
2017/08/26 12:01:33 step 7: mse=0.602374 step=0.100000
2017/08/26 12:01:33 Saving...
2017/08/26 12:01:33 Gathering batch of experience...
2017/08/26 12:01:48 batch 88: mean=15.977273 stddev=7.072638 entropy=1.086235 frames=35966 count=44
2017/08/26 12:01:48 Training policy...
2017/08/26 12:01:52 step 0: objective=0.023475451
2017/08/26 12:01:55 step 1: objective=0.023519082
2017/08/26 12:01:57 step 2: objective=0.023562672
2017/08/26 12:02:00 step 3: objective=0.023606148
2017/08/26 12:02:02 step 4: objective=0.023649523
2017/08/26 12:02:05 step 5: objective=0.02369232
2017/08/26 12:02:07 step 6: objective=0.023731558
2017/08/26 12:02:09 step 7: objective=0.02377119
2017/08/26 12:02:09 Training value function...
2017/08/26 12:02:11 step 0: mse=0.897840 step=0.100000
2017/08/26 12:02:11 step 1: mse=0.856486 step=0.100000
2017/08/26 12:02:12 step 2: mse=0.820058 step=0.100000
2017/08/26 12:02:13 step 3: mse=0.790291 step=0.100000
2017/08/26 12:02:14 step 4: mse=0.771116 step=0.100000
2017/08/26 12:02:14 step 5: mse=0.736723 step=0.100000
2017/08/26 12:02:15 step 6: mse=0.719079 step=0.100000
2017/08/26 12:02:16 step 7: mse=0.703342 step=0.100000
2017/08/26 12:02:16 Saving...
2017/08/26 12:02:16 Gathering batch of experience...
2017/08/26 12:02:32 batch 89: mean=14.244898 stddev=5.905828 entropy=1.089262 frames=36829 count=49
2017/08/26 12:02:32 Training policy...
2017/08/26 12:02:36 step 0: objective=0.021523187
2017/08/26 12:02:38 step 1: objective=0.021596767
2017/08/26 12:02:41 step 2: objective=0.021670582
2017/08/26 12:02:43 step 3: objective=0.021743754
2017/08/26 12:02:46 step 4: objective=0.021794045
2017/08/26 12:02:48 step 5: objective=0.0218429
2017/08/26 12:02:51 step 6: objective=0.021897655
2017/08/26 12:02:53 step 7: objective=0.021926057
2017/08/26 12:02:53 Training value function...
2017/08/26 12:02:55 step 0: mse=0.653911 step=0.100000
2017/08/26 12:02:55 step 1: mse=0.638804 step=0.100000
2017/08/26 12:02:56 step 2: mse=0.624113 step=0.100000
2017/08/26 12:02:57 step 3: mse=0.612370 step=0.100000
2017/08/26 12:02:58 step 4: mse=0.597238 step=0.100000
2017/08/26 12:02:58 step 5: mse=0.589735 step=0.100000
2017/08/26 12:02:59 step 6: mse=0.582353 step=0.100000
2017/08/26 12:03:00 step 7: mse=0.571756 step=0.100000
2017/08/26 12:03:00 Saving...
2017/08/26 12:03:00 Gathering batch of experience...
2017/08/26 12:03:16 batch 90: mean=14.869565 stddev=6.418752 entropy=1.096939 frames=36594 count=46
2017/08/26 12:03:16 Training policy...
2017/08/26 12:03:20 step 0: objective=0.026601411
2017/08/26 12:03:22 step 1: objective=0.026650028
2017/08/26 12:03:25 step 2: objective=0.026698427
2017/08/26 12:03:27 step 3: objective=0.026746606
2017/08/26 12:03:30 step 4: objective=0.026794292
2017/08/26 12:03:32 step 5: objective=0.026827412
2017/08/26 12:03:35 step 6: objective=0.026866915
2017/08/26 12:03:37 step 7: objective=0.026925387
2017/08/26 12:03:37 Training value function...
2017/08/26 12:03:38 step 0: mse=0.778991 step=0.100000
2017/08/26 12:03:39 step 1: mse=0.731844 step=0.100000
2017/08/26 12:03:40 step 2: mse=0.693981 step=0.100000
2017/08/26 12:03:41 step 3: mse=0.663343 step=0.100000
2017/08/26 12:03:41 step 4: mse=0.636045 step=0.100000
2017/08/26 12:03:42 step 5: mse=0.614208 step=0.100000
2017/08/26 12:03:43 step 6: mse=0.591744 step=0.100000
2017/08/26 12:03:44 step 7: mse=0.574231 step=0.100000
2017/08/26 12:03:44 Saving...
2017/08/26 12:03:44 Gathering batch of experience...
2017/08/26 12:03:59 batch 91: mean=14.152174 stddev=6.125383 entropy=1.091694 frames=35540 count=46
2017/08/26 12:03:59 Training policy...
2017/08/26 12:04:03 step 0: objective=0.0138313975
2017/08/26 12:04:06 step 1: objective=0.013852959
2017/08/26 12:04:08 step 2: objective=0.013874448
2017/08/26 12:04:10 step 3: objective=0.013895964
2017/08/26 12:04:13 step 4: objective=0.013917358
2017/08/26 12:04:15 step 5: objective=0.01393865
2017/08/26 12:04:18 step 6: objective=0.0139598455
2017/08/26 12:04:20 step 7: objective=0.013980897
2017/08/26 12:04:20 Training value function...
2017/08/26 12:04:21 step 0: mse=0.705185 step=0.100000
2017/08/26 12:04:22 step 1: mse=0.674382 step=0.100000
2017/08/26 12:04:23 step 2: mse=0.649278 step=0.100000
2017/08/26 12:04:23 step 3: mse=0.626377 step=0.100000
2017/08/26 12:04:24 step 4: mse=0.606607 step=0.100000
2017/08/26 12:04:25 step 5: mse=0.593435 step=0.100000
2017/08/26 12:04:25 step 6: mse=0.565483 step=0.100000
2017/08/26 12:04:26 step 7: mse=0.545893 step=0.100000
2017/08/26 12:04:26 Saving...
2017/08/26 12:04:26 Gathering batch of experience...
2017/08/26 12:04:42 batch 92: mean=15.522727 stddev=6.347829 entropy=1.084762 frames=35540 count=44
2017/08/26 12:04:42 Training policy...
2017/08/26 12:04:46 step 0: objective=0.038372222
2017/08/26 12:04:48 step 1: objective=0.03840956
2017/08/26 12:04:51 step 2: objective=0.038447537
2017/08/26 12:04:53 step 3: objective=0.038484648
2017/08/26 12:04:55 step 4: objective=0.038522452
2017/08/26 12:04:58 step 5: objective=0.038559765
2017/08/26 12:05:00 step 6: objective=0.038588904
2017/08/26 12:05:03 step 7: objective=0.038641334
2017/08/26 12:05:03 Training value function...
2017/08/26 12:05:04 step 0: mse=0.886480 step=0.100000
2017/08/26 12:05:05 step 1: mse=0.826957 step=0.100000
2017/08/26 12:05:05 step 2: mse=0.776019 step=0.100000
2017/08/26 12:05:06 step 3: mse=0.734365 step=0.100000
2017/08/26 12:05:07 step 4: mse=0.696249 step=0.100000
2017/08/26 12:05:07 step 5: mse=0.666591 step=0.100000
2017/08/26 12:05:08 step 6: mse=0.638329 step=0.100000
2017/08/26 12:05:09 step 7: mse=0.612775 step=0.100000
2017/08/26 12:05:09 Saving...
2017/08/26 12:05:09 Gathering batch of experience...
2017/08/26 12:05:25 batch 93: mean=16.697674 stddev=8.743196 entropy=1.078773 frames=36469 count=43
2017/08/26 12:05:25 Training policy...
2017/08/26 12:05:29 step 0: objective=0.046170864
2017/08/26 12:05:31 step 1: objective=0.046216734
2017/08/26 12:05:34 step 2: objective=0.046262417
2017/08/26 12:05:36 step 3: objective=0.04631915
2017/08/26 12:05:39 step 4: objective=0.046388485
2017/08/26 12:05:41 step 5: objective=0.046457227
2017/08/26 12:05:44 step 6: objective=0.046524316
2017/08/26 12:05:46 step 7: objective=0.046572708
2017/08/26 12:05:46 Training value function...
2017/08/26 12:05:47 step 0: mse=1.143842 step=0.100000
2017/08/26 12:05:48 step 1: mse=1.047715 step=0.100000
2017/08/26 12:05:49 step 2: mse=0.966738 step=0.100000
2017/08/26 12:05:50 step 3: mse=0.901069 step=0.100000
2017/08/26 12:05:50 step 4: mse=0.847670 step=0.100000
2017/08/26 12:05:51 step 5: mse=0.800952 step=0.100000
2017/08/26 12:05:52 step 6: mse=0.763248 step=0.100000
2017/08/26 12:05:52 step 7: mse=0.721980 step=0.100000
2017/08/26 12:05:52 Saving...
2017/08/26 12:05:53 Gathering batch of experience...
2017/08/26 12:06:08 batch 94: mean=17.568182 stddev=6.154812 entropy=1.084219 frames=36434 count=44
2017/08/26 12:06:08 Training policy...
2017/08/26 12:06:13 step 0: objective=0.072344765
2017/08/26 12:06:15 step 1: objective=0.0724105
2017/08/26 12:06:17 step 2: objective=0.0724756
2017/08/26 12:06:20 step 3: objective=0.07254082
2017/08/26 12:06:22 step 4: objective=0.07260018
2017/08/26 12:06:25 step 5: objective=0.07266165
2017/08/26 12:06:27 step 6: objective=0.07271715
2017/08/26 12:06:30 step 7: objective=0.072765276
2017/08/26 12:06:30 Training value function...
2017/08/26 12:06:31 step 0: mse=1.110193 step=0.100000
2017/08/26 12:06:32 step 1: mse=1.041907 step=0.100000
2017/08/26 12:06:33 step 2: mse=0.985206 step=0.100000
2017/08/26 12:06:33 step 3: mse=0.937611 step=0.100000
2017/08/26 12:06:34 step 4: mse=0.902218 step=0.100000
2017/08/26 12:06:35 step 5: mse=0.866095 step=0.100000
2017/08/26 12:06:36 step 6: mse=0.836843 step=0.100000
2017/08/26 12:06:36 step 7: mse=0.802281 step=0.100000
2017/08/26 12:06:36 Saving...
2017/08/26 12:06:36 Gathering batch of experience...
2017/08/26 12:06:52 batch 95: mean=14.708333 stddev=5.263706 entropy=1.097980 frames=36705 count=48
2017/08/26 12:06:52 Training policy...
2017/08/26 12:06:56 step 0: objective=0.014576619
2017/08/26 12:06:59 step 1: objective=0.0146360295
2017/08/26 12:07:01 step 2: objective=0.014695329
2017/08/26 12:07:04 step 3: objective=0.014754524
2017/08/26 12:07:06 step 4: objective=0.014809628
2017/08/26 12:07:09 step 5: objective=0.014851853
2017/08/26 12:07:11 step 6: objective=0.014883381
2017/08/26 12:07:14 step 7: objective=0.014940615
2017/08/26 12:07:14 Training value function...
2017/08/26 12:07:15 step 0: mse=0.913665 step=0.100000
2017/08/26 12:07:16 step 1: mse=0.866201 step=0.100000
2017/08/26 12:07:17 step 2: mse=0.827330 step=0.100000
2017/08/26 12:07:17 step 3: mse=0.796300 step=0.100000
2017/08/26 12:07:18 step 4: mse=0.762898 step=0.100000
2017/08/26 12:07:19 step 5: mse=0.740732 step=0.100000
2017/08/26 12:07:20 step 6: mse=0.703841 step=0.100000
2017/08/26 12:07:20 step 7: mse=0.688033 step=0.100000
2017/08/26 12:07:20 Saving...
2017/08/26 12:07:20 Gathering batch of experience...
2017/08/26 12:07:37 batch 96: mean=15.777778 stddev=6.517971 entropy=1.082044 frames=37106 count=45
2017/08/26 12:07:37 Training policy...
2017/08/26 12:07:41 step 0: objective=0.024274278
2017/08/26 12:07:43 step 1: objective=0.024331179
2017/08/26 12:07:46 step 2: objective=0.024389733
2017/08/26 12:07:49 step 3: objective=0.024431882
2017/08/26 12:07:51 step 4: objective=0.024459431
2017/08/26 12:07:54 step 5: objective=0.024521222
2017/08/26 12:07:56 step 6: objective=0.024573086
2017/08/26 12:07:59 step 7: objective=0.02462986
2017/08/26 12:07:59 Training value function...
2017/08/26 12:08:00 step 0: mse=0.766393 step=0.100000
2017/08/26 12:08:01 step 1: mse=0.714323 step=0.100000
2017/08/26 12:08:02 step 2: mse=0.672627 step=0.100000
2017/08/26 12:08:02 step 3: mse=0.639543 step=0.100000
2017/08/26 12:08:03 step 4: mse=0.612062 step=0.100000
2017/08/26 12:08:04 step 5: mse=0.578068 step=0.100000
2017/08/26 12:08:05 step 6: mse=0.555608 step=0.100000
2017/08/26 12:08:05 step 7: mse=0.530016 step=0.100000
2017/08/26 12:08:05 Saving...
2017/08/26 12:08:05 Gathering batch of experience...
2017/08/26 12:08:22 batch 97: mean=14.361702 stddev=5.494390 entropy=1.083675 frames=36607 count=47
2017/08/26 12:08:22 Training policy...
2017/08/26 12:08:26 step 0: objective=0.011778379
2017/08/26 12:08:28 step 1: objective=0.0118180495
2017/08/26 12:08:31 step 2: objective=0.011857989
2017/08/26 12:08:33 step 3: objective=0.0118982345
2017/08/26 12:08:36 step 4: objective=0.011938667
2017/08/26 12:08:38 step 5: objective=0.011977134
2017/08/26 12:08:41 step 6: objective=0.012007307
2017/08/26 12:08:43 step 7: objective=0.012031451
2017/08/26 12:08:43 Training value function...
2017/08/26 12:08:44 step 0: mse=0.698359 step=0.100000
2017/08/26 12:08:45 step 1: mse=0.662263 step=0.100000
2017/08/26 12:08:46 step 2: mse=0.631058 step=0.100000
2017/08/26 12:08:47 step 3: mse=0.606656 step=0.100000
2017/08/26 12:08:47 step 4: mse=0.583490 step=0.100000
2017/08/26 12:08:48 step 5: mse=0.564559 step=0.100000
2017/08/26 12:08:49 step 6: mse=0.549436 step=0.100000
2017/08/26 12:08:50 step 7: mse=0.533805 step=0.100000
2017/08/26 12:08:50 Saving...
2017/08/26 12:08:50 Gathering batch of experience...
2017/08/26 12:09:06 batch 98: mean=16.041667 stddev=11.210037 entropy=1.086949 frames=37439 count=48
2017/08/26 12:09:06 Training policy...
2017/08/26 12:09:11 step 0: objective=0.060414772
2017/08/26 12:09:13 step 1: objective=0.060529098
2017/08/26 12:09:16 step 2: objective=0.060643673
2017/08/26 12:09:18 step 3: objective=0.06074655
2017/08/26 12:09:21 step 4: objective=0.060772326
2017/08/26 12:09:23 step 5: objective=0.060800437
2017/08/26 12:09:26 step 6: objective=0.060829133
2017/08/26 12:09:29 step 7: objective=0.060872957
2017/08/26 12:09:29 Training value function...
2017/08/26 12:09:30 step 0: mse=1.676366 step=0.100000
2017/08/26 12:09:31 step 1: mse=1.480219 step=0.100000
2017/08/26 12:09:31 step 2: mse=1.316557 step=0.100000
2017/08/26 12:09:32 step 3: mse=1.191373 step=0.100000
2017/08/26 12:09:33 step 4: mse=1.083928 step=0.100000
2017/08/26 12:09:34 step 5: mse=0.997994 step=0.100000
2017/08/26 12:09:34 step 6: mse=0.923809 step=0.100000
2017/08/26 12:09:35 step 7: mse=0.864806 step=0.100000
2017/08/26 12:09:35 Saving...
2017/08/26 12:09:35 Gathering batch of experience...
2017/08/26 12:09:51 batch 99: mean=15.086957 stddev=6.765726 entropy=1.084838 frames=35777 count=46
2017/08/26 12:09:51 Training policy...
2017/08/26 12:09:55 step 0: objective=0.030188425
2017/08/26 12:09:57 step 1: objective=0.030257149
2017/08/26 12:10:00 step 2: objective=0.030326143
2017/08/26 12:10:02 step 3: objective=0.030390847
2017/08/26 12:10:05 step 4: objective=0.030427491
2017/08/26 12:10:07 step 5: objective=0.030460479
2017/08/26 12:10:10 step 6: objective=0.030493377
2017/08/26 12:10:12 step 7: objective=0.030517943
2017/08/26 12:10:12 Training value function...
2017/08/26 12:10:13 step 0: mse=1.062434 step=0.100000
2017/08/26 12:10:14 step 1: mse=1.007191 step=0.100000
2017/08/26 12:10:15 step 2: mse=0.962968 step=0.100000
2017/08/26 12:10:15 step 3: mse=0.916379 step=0.100000
2017/08/26 12:10:16 step 4: mse=0.884138 step=0.100000
2017/08/26 12:10:17 step 5: mse=0.841747 step=0.100000
2017/08/26 12:10:18 step 6: mse=0.822109 step=0.100000
2017/08/26 12:10:18 step 7: mse=0.791293 step=0.100000
2017/08/26 12:10:18 Saving...
2017/08/26 12:10:18 Gathering batch of experience...
2017/08/26 12:10:34 batch 100: mean=15.840909 stddev=5.165195 entropy=1.082371 frames=35722 count=44
2017/08/26 12:10:34 Training policy...
2017/08/26 12:10:38 step 0: objective=0.026705088
2017/08/26 12:10:40 step 1: objective=0.026795972
2017/08/26 12:10:43 step 2: objective=0.026887454
2017/08/26 12:10:45 step 3: objective=0.026962651
2017/08/26 12:10:48 step 4: objective=0.027007585
2017/08/26 12:10:50 step 5: objective=0.027044589
2017/08/26 12:10:53 step 6: objective=0.027076801
2017/08/26 12:10:55 step 7: objective=0.027119339
2017/08/26 12:10:55 Training value function...
2017/08/26 12:10:56 step 0: mse=0.824989 step=0.100000
2017/08/26 12:10:57 step 1: mse=0.773927 step=0.100000
2017/08/26 12:10:58 step 2: mse=0.732881 step=0.100000
2017/08/26 12:10:59 step 3: mse=0.701961 step=0.100000
2017/08/26 12:10:59 step 4: mse=0.671093 step=0.100000
2017/08/26 12:11:00 step 5: mse=0.649394 step=0.100000
2017/08/26 12:11:01 step 6: mse=0.626211 step=0.100000
2017/08/26 12:11:02 step 7: mse=0.604859 step=0.100000
2017/08/26 12:11:02 Saving...
2017/08/26 12:11:02 Gathering batch of experience...
2017/08/26 12:11:18 batch 101: mean=15.600000 stddev=6.671332 entropy=1.082250 frames=36161 count=45
2017/08/26 12:11:18 Training policy...
2017/08/26 12:11:22 step 0: objective=0.036964763
2017/08/26 12:11:24 step 1: objective=0.037005022
2017/08/26 12:11:27 step 2: objective=0.037045356
2017/08/26 12:11:29 step 3: objective=0.037086476
2017/08/26 12:11:32 step 4: objective=0.037127603
2017/08/26 12:11:34 step 5: objective=0.037176885
2017/08/26 12:11:37 step 6: objective=0.03721964
2017/08/26 12:11:39 step 7: objective=0.037245538
2017/08/26 12:11:39 Training value function...
2017/08/26 12:11:40 step 0: mse=0.998905 step=0.100000
2017/08/26 12:11:41 step 1: mse=0.944396 step=0.100000
2017/08/26 12:11:42 step 2: mse=0.886217 step=0.100000
2017/08/26 12:11:43 step 3: mse=0.838942 step=0.100000
2017/08/26 12:11:43 step 4: mse=0.807143 step=0.100000
2017/08/26 12:11:44 step 5: mse=0.772535 step=0.100000
2017/08/26 12:11:45 step 6: mse=0.745395 step=0.100000
2017/08/26 12:11:46 step 7: mse=0.710082 step=0.100000
2017/08/26 12:11:46 Saving...
2017/08/26 12:11:46 Gathering batch of experience...
2017/08/26 12:12:02 batch 102: mean=16.304348 stddev=7.024397 entropy=1.090484 frames=36994 count=46
2017/08/26 12:12:02 Training policy...
2017/08/26 12:12:06 step 0: objective=0.04622365
2017/08/26 12:12:09 step 1: objective=0.046348333
2017/08/26 12:12:11 step 2: objective=0.046474043
2017/08/26 12:12:14 step 3: objective=0.046583463
2017/08/26 12:12:16 step 4: objective=0.046648636
2017/08/26 12:12:19 step 5: objective=0.046699528
2017/08/26 12:12:22 step 6: objective=0.046736658
2017/08/26 12:12:24 step 7: objective=0.046781607
2017/08/26 12:12:24 Training value function...
2017/08/26 12:12:25 step 0: mse=1.034564 step=0.100000
2017/08/26 12:12:26 step 1: mse=0.959482 step=0.100000
2017/08/26 12:12:27 step 2: mse=0.898849 step=0.100000
2017/08/26 12:12:28 step 3: mse=0.849620 step=0.100000
2017/08/26 12:12:29 step 4: mse=0.808371 step=0.100000
2017/08/26 12:12:29 step 5: mse=0.774386 step=0.100000
2017/08/26 12:12:30 step 6: mse=0.740620 step=0.100000
2017/08/26 12:12:31 step 7: mse=0.716237 step=0.100000
2017/08/26 12:12:31 Saving...
2017/08/26 12:12:31 Gathering batch of experience...
2017/08/26 12:12:47 batch 103: mean=16.930233 stddev=6.147018 entropy=1.088762 frames=36343 count=43
2017/08/26 12:12:47 Training policy...
2017/08/26 12:12:51 step 0: objective=0.035607286
2017/08/26 12:12:53 step 1: objective=0.035650697
2017/08/26 12:12:56 step 2: objective=0.03568167
2017/08/26 12:12:58 step 3: objective=0.035712417
2017/08/26 12:13:01 step 4: objective=0.035743166
2017/08/26 12:13:03 step 5: objective=0.03578427
2017/08/26 12:13:06 step 6: objective=0.035810076
2017/08/26 12:13:08 step 7: objective=0.035845887
2017/08/26 12:13:08 Training value function...
2017/08/26 12:13:10 step 0: mse=0.820189 step=0.100000
2017/08/26 12:13:10 step 1: mse=0.782376 step=0.100000
2017/08/26 12:13:11 step 2: mse=0.751385 step=0.100000
2017/08/26 12:13:12 step 3: mse=0.722116 step=0.100000
2017/08/26 12:13:13 step 4: mse=0.697800 step=0.100000
2017/08/26 12:13:13 step 5: mse=0.674126 step=0.100000
2017/08/26 12:13:14 step 6: mse=0.651504 step=0.100000
2017/08/26 12:13:15 step 7: mse=0.632994 step=0.100000
2017/08/26 12:13:15 Saving...
2017/08/26 12:13:15 Gathering batch of experience...
2017/08/26 12:13:31 batch 104: mean=14.565217 stddev=6.519710 entropy=1.078770 frames=35525 count=46
2017/08/26 12:13:31 Training policy...
2017/08/26 12:13:35 step 0: objective=0.014766273
2017/08/26 12:13:37 step 1: objective=0.0147969695
2017/08/26 12:13:40 step 2: objective=0.014827813
2017/08/26 12:13:42 step 3: objective=0.014858737
2017/08/26 12:13:44 step 4: objective=0.014889951
2017/08/26 12:13:47 step 5: objective=0.014917906
2017/08/26 12:13:49 step 6: objective=0.014953316
2017/08/26 12:13:52 step 7: objective=0.015044715
2017/08/26 12:13:52 Training value function...
2017/08/26 12:13:53 step 0: mse=0.910290 step=0.100000
2017/08/26 12:13:54 step 1: mse=0.861536 step=0.100000
2017/08/26 12:13:55 step 2: mse=0.821411 step=0.100000
2017/08/26 12:13:55 step 3: mse=0.784128 step=0.100000
2017/08/26 12:13:56 step 4: mse=0.757569 step=0.100000
2017/08/26 12:13:57 step 5: mse=0.727105 step=0.100000
2017/08/26 12:13:57 step 6: mse=0.709125 step=0.100000
2017/08/26 12:13:58 step 7: mse=0.687848 step=0.100000
2017/08/26 12:13:58 Saving...
2017/08/26 12:13:58 Gathering batch of experience...
2017/08/26 12:14:14 batch 105: mean=15.260870 stddev=6.012432 entropy=1.089848 frames=36589 count=46
2017/08/26 12:14:14 Training policy...
2017/08/26 12:14:19 step 0: objective=0.02956941
2017/08/26 12:14:21 step 1: objective=0.02961115
2017/08/26 12:14:24 step 2: objective=0.029653214
2017/08/26 12:14:26 step 3: objective=0.029695135
2017/08/26 12:14:29 step 4: objective=0.029735843
2017/08/26 12:14:31 step 5: objective=0.029782934
2017/08/26 12:14:34 step 6: objective=0.029812807
2017/08/26 12:14:36 step 7: objective=0.029856259
2017/08/26 12:14:36 Training value function...
2017/08/26 12:14:38 step 0: mse=0.887752 step=0.100000
2017/08/26 12:14:38 step 1: mse=0.849685 step=0.100000
2017/08/26 12:14:39 step 2: mse=0.793102 step=0.100000
2017/08/26 12:14:40 step 3: mse=0.747746 step=0.100000
2017/08/26 12:14:41 step 4: mse=0.722755 step=0.100000
2017/08/26 12:14:41 step 5: mse=0.688298 step=0.100000
2017/08/26 12:14:42 step 6: mse=0.661525 step=0.100000
2017/08/26 12:14:43 step 7: mse=0.640824 step=0.100000
2017/08/26 12:14:43 Saving...
2017/08/26 12:14:43 Gathering batch of experience...
2017/08/26 12:14:59 batch 106: mean=18.833333 stddev=7.524299 entropy=1.082322 frames=37187 count=42
2017/08/26 12:14:59 Training policy...
2017/08/26 12:15:03 step 0: objective=0.06916675
2017/08/26 12:15:06 step 1: objective=0.06921667
2017/08/26 12:15:09 step 2: objective=0.06926574
2017/08/26 12:15:11 step 3: objective=0.06931511
2017/08/26 12:15:14 step 4: objective=0.06936338
2017/08/26 12:15:16 step 5: objective=0.06943135
2017/08/26 12:15:19 step 6: objective=0.06947259
2017/08/26 12:15:21 step 7: objective=0.06951947
2017/08/26 12:15:21 Training value function...
2017/08/26 12:15:23 step 0: mse=1.527870 step=0.100000
2017/08/26 12:15:24 step 1: mse=1.419854 step=0.100000
2017/08/26 12:15:24 step 2: mse=1.332396 step=0.100000
2017/08/26 12:15:25 step 3: mse=1.258169 step=0.100000
2017/08/26 12:15:26 step 4: mse=1.192575 step=0.100000
2017/08/26 12:15:27 step 5: mse=1.145178 step=0.100000
2017/08/26 12:15:27 step 6: mse=1.096787 step=0.100000
2017/08/26 12:15:28 step 7: mse=1.055210 step=0.100000
2017/08/26 12:15:28 Saving...
2017/08/26 12:15:28 Gathering batch of experience...
2017/08/26 12:15:44 batch 107: mean=16.333333 stddev=7.130529 entropy=1.083737 frames=36596 count=45
2017/08/26 12:15:44 Training policy...
2017/08/26 12:15:48 step 0: objective=0.029649584
2017/08/26 12:15:51 step 1: objective=0.029739635
2017/08/26 12:15:53 step 2: objective=0.029828623
2017/08/26 12:15:56 step 3: objective=0.029916769
2017/08/26 12:15:58 step 4: objective=0.029999986
2017/08/26 12:16:01 step 5: objective=0.03006241
2017/08/26 12:16:04 step 6: objective=0.030127374
2017/08/26 12:16:06 step 7: objective=0.030181998
2017/08/26 12:16:06 Training value function...
2017/08/26 12:16:07 step 0: mse=1.071031 step=0.100000
2017/08/26 12:16:08 step 1: mse=1.007619 step=0.100000
2017/08/26 12:16:09 step 2: mse=0.957205 step=0.100000
2017/08/26 12:16:10 step 3: mse=0.913142 step=0.100000
2017/08/26 12:16:10 step 4: mse=0.887294 step=0.100000
2017/08/26 12:16:11 step 5: mse=0.861163 step=0.100000
2017/08/26 12:16:12 step 6: mse=0.835765 step=0.100000
2017/08/26 12:16:12 step 7: mse=0.806572 step=0.100000
2017/08/26 12:16:12 Saving...
2017/08/26 12:16:13 Gathering batch of experience...
2017/08/26 12:16:28 batch 108: mean=15.043478 stddev=7.156501 entropy=1.087904 frames=36070 count=46
2017/08/26 12:16:28 Training policy...
2017/08/26 12:16:33 step 0: objective=0.012829487
2017/08/26 12:16:35 step 1: objective=0.012877114
2017/08/26 12:16:38 step 2: objective=0.012924689
2017/08/26 12:16:40 step 3: objective=0.012972147
2017/08/26 12:16:43 step 4: objective=0.013019429
2017/08/26 12:16:45 step 5: objective=0.013062565
2017/08/26 12:16:48 step 6: objective=0.013102454
2017/08/26 12:16:50 step 7: objective=0.013136702
2017/08/26 12:16:50 Training value function...
2017/08/26 12:16:51 step 0: mse=0.898893 step=0.100000
2017/08/26 12:16:52 step 1: mse=0.830610 step=0.100000
2017/08/26 12:16:53 step 2: mse=0.777421 step=0.100000
2017/08/26 12:16:54 step 3: mse=0.732963 step=0.100000
2017/08/26 12:16:54 step 4: mse=0.694963 step=0.100000
2017/08/26 12:16:55 step 5: mse=0.661241 step=0.100000
2017/08/26 12:16:56 step 6: mse=0.635327 step=0.100000
2017/08/26 12:16:57 step 7: mse=0.603137 step=0.100000
2017/08/26 12:16:57 Saving...
2017/08/26 12:16:57 Gathering batch of experience...
2017/08/26 12:17:13 batch 109: mean=15.617021 stddev=6.214442 entropy=1.089769 frames=37060 count=47
2017/08/26 12:17:13 Training policy...
2017/08/26 12:17:17 step 0: objective=0.023612378
2017/08/26 12:17:20 step 1: objective=0.023702286
2017/08/26 12:17:22 step 2: objective=0.023791337
2017/08/26 12:17:25 step 3: objective=0.023879422
2017/08/26 12:17:28 step 4: objective=0.023977166
2017/08/26 12:17:30 step 5: objective=0.024033481
2017/08/26 12:17:33 step 6: objective=0.024087248
2017/08/26 12:17:35 step 7: objective=0.024148395
2017/08/26 12:17:35 Training value function...
2017/08/26 12:17:37 step 0: mse=1.010927 step=0.100000
2017/08/26 12:17:37 step 1: mse=0.959426 step=0.100000
2017/08/26 12:17:38 step 2: mse=0.908045 step=0.100000
2017/08/26 12:17:39 step 3: mse=0.860554 step=0.100000
2017/08/26 12:17:40 step 4: mse=0.823376 step=0.100000
2017/08/26 12:17:40 step 5: mse=0.785757 step=0.100000
2017/08/26 12:17:41 step 6: mse=0.755453 step=0.100000
2017/08/26 12:17:42 step 7: mse=0.733358 step=0.100000
2017/08/26 12:17:42 Saving...
2017/08/26 12:17:42 Gathering batch of experience...
2017/08/26 12:17:58 batch 110: mean=16.000000 stddev=6.735253 entropy=1.088836 frames=36750 count=44
2017/08/26 12:17:58 Training policy...
2017/08/26 12:18:02 step 0: objective=0.027974693
2017/08/26 12:18:05 step 1: objective=0.028024195
2017/08/26 12:18:07 step 2: objective=0.028074468
2017/08/26 12:18:10 step 3: objective=0.028125359
2017/08/26 12:18:13 step 4: objective=0.028176505
2017/08/26 12:18:15 step 5: objective=0.028215302
2017/08/26 12:18:18 step 6: objective=0.028247157
2017/08/26 12:18:20 step 7: objective=0.028273793
2017/08/26 12:18:20 Training value function...
2017/08/26 12:18:22 step 0: mse=0.839894 step=0.100000
2017/08/26 12:18:22 step 1: mse=0.778387 step=0.100000
2017/08/26 12:18:23 step 2: mse=0.729476 step=0.100000
2017/08/26 12:18:24 step 3: mse=0.689026 step=0.100000
2017/08/26 12:18:25 step 4: mse=0.655694 step=0.100000
2017/08/26 12:18:25 step 5: mse=0.611076 step=0.100000
2017/08/26 12:18:26 step 6: mse=0.588095 step=0.100000
2017/08/26 12:18:27 step 7: mse=0.555208 step=0.100000
2017/08/26 12:18:27 Saving...
2017/08/26 12:18:27 Gathering batch of experience...
2017/08/26 12:18:43 batch 111: mean=15.000000 stddev=7.893310 entropy=1.090886 frames=36501 count=46
2017/08/26 12:18:43 Training policy...
2017/08/26 12:18:47 step 0: objective=0.021326244
2017/08/26 12:18:50 step 1: objective=0.021372505
2017/08/26 12:18:52 step 2: objective=0.021418745
2017/08/26 12:18:55 step 3: objective=0.02146489
2017/08/26 12:18:58 step 4: objective=0.021508643
2017/08/26 12:19:00 step 5: objective=0.021531727
2017/08/26 12:19:03 step 6: objective=0.021552676
2017/08/26 12:19:05 step 7: objective=0.021573998
2017/08/26 12:19:05 Training value function...
2017/08/26 12:19:06 step 0: mse=1.027100 step=0.100000
2017/08/26 12:19:07 step 1: mse=0.936193 step=0.100000
2017/08/26 12:19:08 step 2: mse=0.862858 step=0.100000
2017/08/26 12:19:09 step 3: mse=0.801671 step=0.100000
2017/08/26 12:19:09 step 4: mse=0.753039 step=0.100000
2017/08/26 12:19:10 step 5: mse=0.708121 step=0.100000
2017/08/26 12:19:11 step 6: mse=0.677333 step=0.100000
2017/08/26 12:19:12 step 7: mse=0.646083 step=0.100000
2017/08/26 12:19:12 Saving...
2017/08/26 12:19:12 Gathering batch of experience...
2017/08/26 12:19:28 batch 112: mean=16.173913 stddev=8.011688 entropy=1.081269 frames=37106 count=46
2017/08/26 12:19:28 Training policy...
2017/08/26 12:19:32 step 0: objective=0.04428624
2017/08/26 12:19:35 step 1: objective=0.04434543
2017/08/26 12:19:38 step 2: objective=0.04440411
2017/08/26 12:19:40 step 3: objective=0.04446245
2017/08/26 12:19:43 step 4: objective=0.044520635
2017/08/26 12:19:45 step 5: objective=0.04457484
2017/08/26 12:19:48 step 6: objective=0.04461635
2017/08/26 12:19:51 step 7: objective=0.04465101
2017/08/26 12:19:51 Training value function...
2017/08/26 12:19:52 step 0: mse=1.262156 step=0.100000
2017/08/26 12:19:53 step 1: mse=1.163718 step=0.100000
2017/08/26 12:19:53 step 2: mse=1.084181 step=0.100000
2017/08/26 12:19:54 step 3: mse=1.023173 step=0.100000
2017/08/26 12:19:55 step 4: mse=0.966202 step=0.100000
2017/08/26 12:19:56 step 5: mse=0.919564 step=0.100000
2017/08/26 12:19:56 step 6: mse=0.884751 step=0.100000
2017/08/26 12:19:57 step 7: mse=0.846868 step=0.100000
2017/08/26 12:19:57 Saving...
2017/08/26 12:19:57 Gathering batch of experience...
2017/08/26 12:20:13 batch 113: mean=15.217391 stddev=7.156369 entropy=1.083949 frames=35873 count=46
2017/08/26 12:20:13 Training policy...
2017/08/26 12:20:17 step 0: objective=0.014859354
2017/08/26 12:20:20 step 1: objective=0.014988126
2017/08/26 12:20:22 step 2: objective=0.015117668
2017/08/26 12:20:25 step 3: objective=0.015244572
2017/08/26 12:20:27 step 4: objective=0.015331203
2017/08/26 12:20:30 step 5: objective=0.015428715
2017/08/26 12:20:32 step 6: objective=0.015488003
2017/08/26 12:20:35 step 7: objective=0.015552942
2017/08/26 12:20:35 Training value function...
2017/08/26 12:20:36 step 0: mse=1.058503 step=0.100000
2017/08/26 12:20:37 step 1: mse=0.990309 step=0.100000
2017/08/26 12:20:37 step 2: mse=0.931862 step=0.100000
2017/08/26 12:20:38 step 3: mse=0.887890 step=0.100000
2017/08/26 12:20:39 step 4: mse=0.849643 step=0.100000
2017/08/26 12:20:40 step 5: mse=0.819404 step=0.100000
2017/08/26 12:20:40 step 6: mse=0.789569 step=0.100000
2017/08/26 12:20:41 step 7: mse=0.761612 step=0.100000
2017/08/26 12:20:41 Saving...
2017/08/26 12:20:41 Gathering batch of experience...
2017/08/26 12:20:57 batch 114: mean=17.476190 stddev=9.251095 entropy=1.075914 frames=34888 count=42
2017/08/26 12:20:57 Training policy...
2017/08/26 12:21:01 step 0: objective=0.05893642
2017/08/26 12:21:03 step 1: objective=0.059023894
2017/08/26 12:21:05 step 2: objective=0.059110686
2017/08/26 12:21:08 step 3: objective=0.059196886
2017/08/26 12:21:10 step 4: objective=0.059277955
2017/08/26 12:21:13 step 5: objective=0.059352275
2017/08/26 12:21:15 step 6: objective=0.059403602
2017/08/26 12:21:18 step 7: objective=0.059450522
2017/08/26 12:21:18 Training value function...
2017/08/26 12:21:19 step 0: mse=1.848720 step=0.100000
2017/08/26 12:21:20 step 1: mse=1.710632 step=0.100000
2017/08/26 12:21:21 step 2: mse=1.598962 step=0.100000
2017/08/26 12:21:21 step 3: mse=1.508403 step=0.100000
2017/08/26 12:21:22 step 4: mse=1.434108 step=0.100000
2017/08/26 12:21:23 step 5: mse=1.369264 step=0.100000
2017/08/26 12:21:23 step 6: mse=1.313661 step=0.100000
2017/08/26 12:21:24 step 7: mse=1.261552 step=0.100000
2017/08/26 12:21:24 Saving...
2017/08/26 12:21:24 Gathering batch of experience...
2017/08/26 12:21:40 batch 115: mean=14.250000 stddev=5.956439 entropy=1.080770 frames=35879 count=48
2017/08/26 12:21:40 Training policy...
2017/08/26 12:21:44 step 0: objective=-0.018154554
2017/08/26 12:21:47 step 1: objective=-0.018029403
2017/08/26 12:21:49 step 2: objective=-0.017901223
2017/08/26 12:21:52 step 3: objective=-0.017802848
2017/08/26 12:21:54 step 4: objective=-0.017687645
2017/08/26 12:21:57 step 5: objective=-0.017577019
2017/08/26 12:21:59 step 6: objective=-0.01746866
2017/08/26 12:22:02 step 7: objective=-0.017377155
2017/08/26 12:22:02 Training value function...
2017/08/26 12:22:03 step 0: mse=1.518162 step=0.100000
2017/08/26 12:22:04 step 1: mse=1.324912 step=0.100000
2017/08/26 12:22:05 step 2: mse=1.164821 step=0.100000
2017/08/26 12:22:05 step 3: mse=1.039932 step=0.100000
2017/08/26 12:22:06 step 4: mse=0.942948 step=0.100000
2017/08/26 12:22:07 step 5: mse=0.863206 step=0.100000
2017/08/26 12:22:08 step 6: mse=0.789807 step=0.100000
2017/08/26 12:22:08 step 7: mse=0.733731 step=0.100000
2017/08/26 12:22:08 Saving...
2017/08/26 12:22:08 Gathering batch of experience...
2017/08/26 12:22:24 batch 116: mean=15.200000 stddev=5.170859 entropy=1.093753 frames=36017 count=45
2017/08/26 12:22:24 Training policy...
2017/08/26 12:22:28 step 0: objective=0.034239758
2017/08/26 12:22:31 step 1: objective=0.03429819
2017/08/26 12:22:34 step 2: objective=0.034358338
2017/08/26 12:22:36 step 3: objective=0.034419477
2017/08/26 12:22:39 step 4: objective=0.034468327
2017/08/26 12:22:41 step 5: objective=0.034521464
2017/08/26 12:22:44 step 6: objective=0.034544557
2017/08/26 12:22:46 step 7: objective=0.03456892
2017/08/26 12:22:46 Training value function...
2017/08/26 12:22:48 step 0: mse=0.862352 step=0.100000
2017/08/26 12:22:48 step 1: mse=0.810762 step=0.100000
2017/08/26 12:22:49 step 2: mse=0.763346 step=0.100000
2017/08/26 12:22:50 step 3: mse=0.728261 step=0.100000
2017/08/26 12:22:51 step 4: mse=0.693314 step=0.100000
2017/08/26 12:22:51 step 5: mse=0.664855 step=0.100000
2017/08/26 12:22:52 step 6: mse=0.636937 step=0.100000
2017/08/26 12:22:53 step 7: mse=0.617673 step=0.100000
2017/08/26 12:22:53 Saving...
2017/08/26 12:22:53 Gathering batch of experience...
2017/08/26 12:23:09 batch 117: mean=15.244444 stddev=6.481274 entropy=1.083372 frames=36598 count=45
2017/08/26 12:23:09 Training policy...
2017/08/26 12:23:13 step 0: objective=0.011288012
2017/08/26 12:23:16 step 1: objective=0.01134491
2017/08/26 12:23:18 step 2: objective=0.011401234
2017/08/26 12:23:21 step 3: objective=0.011457001
2017/08/26 12:23:24 step 4: objective=0.011507923
2017/08/26 12:23:26 step 5: objective=0.01159262
2017/08/26 12:23:29 step 6: objective=0.011681873
2017/08/26 12:23:31 step 7: objective=0.011743587
2017/08/26 12:23:31 Training value function...
2017/08/26 12:23:33 step 0: mse=0.771981 step=0.100000
2017/08/26 12:23:33 step 1: mse=0.730680 step=0.100000
2017/08/26 12:23:34 step 2: mse=0.697216 step=0.100000
2017/08/26 12:23:35 step 3: mse=0.669816 step=0.100000
2017/08/26 12:23:36 step 4: mse=0.647157 step=0.100000
2017/08/26 12:23:37 step 5: mse=0.629018 step=0.100000
2017/08/26 12:23:37 step 6: mse=0.613653 step=0.100000
2017/08/26 12:23:38 step 7: mse=0.600298 step=0.100000
2017/08/26 12:23:38 Saving...
2017/08/26 12:23:38 Gathering batch of experience...
2017/08/26 12:23:54 batch 118: mean=15.355556 stddev=6.815523 entropy=1.081149 frames=36032 count=45
2017/08/26 12:23:54 Training policy...
2017/08/26 12:23:58 step 0: objective=0.04016274
2017/08/26 12:24:01 step 1: objective=0.040210854
2017/08/26 12:24:04 step 2: objective=0.040268335
2017/08/26 12:24:06 step 3: objective=0.04031683
2017/08/26 12:24:09 step 4: objective=0.04037324
2017/08/26 12:24:11 step 5: objective=0.04040632
2017/08/26 12:24:14 step 6: objective=0.040494494
2017/08/26 12:24:16 step 7: objective=0.0405464
2017/08/26 12:24:16 Training value function...
2017/08/26 12:24:18 step 0: mse=1.102369 step=0.100000
2017/08/26 12:24:18 step 1: mse=1.007302 step=0.100000
2017/08/26 12:24:19 step 2: mse=0.933023 step=0.100000
2017/08/26 12:24:20 step 3: mse=0.870064 step=0.100000
2017/08/26 12:24:21 step 4: mse=0.822852 step=0.100000
2017/08/26 12:24:21 step 5: mse=0.776027 step=0.100000
2017/08/26 12:24:22 step 6: mse=0.736784 step=0.100000
2017/08/26 12:24:23 step 7: mse=0.711518 step=0.100000
2017/08/26 12:24:23 Saving...
2017/08/26 12:24:23 Gathering batch of experience...
2017/08/26 12:24:39 batch 119: mean=14.936170 stddev=7.114278 entropy=1.088498 frames=36345 count=47
2017/08/26 12:24:39 Training policy...
2017/08/26 12:24:43 step 0: objective=0.022172833
2017/08/26 12:24:46 step 1: objective=0.022251127
2017/08/26 12:24:48 step 2: objective=0.022330232
2017/08/26 12:24:51 step 3: objective=0.022405213
2017/08/26 12:24:54 step 4: objective=0.022454757
2017/08/26 12:24:56 step 5: objective=0.022494117
2017/08/26 12:24:59 step 6: objective=0.02253949
2017/08/26 12:25:01 step 7: objective=0.022584498
2017/08/26 12:25:01 Training value function...
2017/08/26 12:25:03 step 0: mse=0.884082 step=0.100000
2017/08/26 12:25:03 step 1: mse=0.829638 step=0.100000
2017/08/26 12:25:04 step 2: mse=0.784251 step=0.100000
2017/08/26 12:25:05 step 3: mse=0.746276 step=0.100000
2017/08/26 12:25:06 step 4: mse=0.720506 step=0.100000
2017/08/26 12:25:06 step 5: mse=0.691873 step=0.100000
2017/08/26 12:25:07 step 6: mse=0.669016 step=0.100000
2017/08/26 12:25:08 step 7: mse=0.652800 step=0.100000
2017/08/26 12:25:08 Saving...
2017/08/26 12:25:08 Gathering batch of experience...
2017/08/26 12:25:24 batch 120: mean=16.000000 stddev=7.255092 entropy=1.081671 frames=36288 count=44
2017/08/26 12:25:24 Training policy...
2017/08/26 12:25:28 step 0: objective=0.036949597
2017/08/26 12:25:31 step 1: objective=0.037028536
2017/08/26 12:25:33 step 2: objective=0.037107505
2017/08/26 12:25:36 step 3: objective=0.037185732
2017/08/26 12:25:39 step 4: objective=0.03725803
2017/08/26 12:25:41 step 5: objective=0.037314624
2017/08/26 12:25:44 step 6: objective=0.037379075
2017/08/26 12:25:46 step 7: objective=0.037435915
2017/08/26 12:25:46 Training value function...
2017/08/26 12:25:48 step 0: mse=0.953884 step=0.100000
2017/08/26 12:25:48 step 1: mse=0.904162 step=0.100000
2017/08/26 12:25:49 step 2: mse=0.863824 step=0.100000
2017/08/26 12:25:50 step 3: mse=0.824360 step=0.100000
2017/08/26 12:25:51 step 4: mse=0.785754 step=0.100000
2017/08/26 12:25:51 step 5: mse=0.742793 step=0.100000
2017/08/26 12:25:52 step 6: mse=0.709869 step=0.100000
2017/08/26 12:25:53 step 7: mse=0.673368 step=0.100000
2017/08/26 12:25:53 Saving...
2017/08/26 12:25:53 Gathering batch of experience...
2017/08/26 12:26:08 batch 121: mean=15.704545 stddev=6.507267 entropy=1.087639 frames=34989 count=44
2017/08/26 12:26:08 Training policy...
2017/08/26 12:26:12 step 0: objective=0.052304592
2017/08/26 12:26:15 step 1: objective=0.05236525
2017/08/26 12:26:17 step 2: objective=0.052417807
2017/08/26 12:26:20 step 3: objective=0.05247012
2017/08/26 12:26:23 step 4: objective=0.05252196
2017/08/26 12:26:25 step 5: objective=0.052568763
2017/08/26 12:26:28 step 6: objective=0.0526172
2017/08/26 12:26:30 step 7: objective=0.05266531
2017/08/26 12:26:30 Training value function...
2017/08/26 12:26:31 step 0: mse=0.980901 step=0.100000
2017/08/26 12:26:32 step 1: mse=0.912520 step=0.100000
2017/08/26 12:26:33 step 2: mse=0.857167 step=0.100000
2017/08/26 12:26:33 step 3: mse=0.811337 step=0.100000
2017/08/26 12:26:34 step 4: mse=0.769860 step=0.100000
2017/08/26 12:26:35 step 5: mse=0.735345 step=0.100000
2017/08/26 12:26:36 step 6: mse=0.708871 step=0.100000
2017/08/26 12:26:36 step 7: mse=0.680151 step=0.100000
2017/08/26 12:26:36 Saving...
2017/08/26 12:26:36 Gathering batch of experience...
2017/08/26 12:26:52 batch 122: mean=15.795455 stddev=8.192512 entropy=1.077739 frames=35144 count=44
2017/08/26 12:26:52 Training policy...
2017/08/26 12:26:56 step 0: objective=0.027423693
2017/08/26 12:26:58 step 1: objective=0.027463095
2017/08/26 12:27:01 step 2: objective=0.027502261
2017/08/26 12:27:04 step 3: objective=0.02754148
2017/08/26 12:27:06 step 4: objective=0.027580556
2017/08/26 12:27:09 step 5: objective=0.0276198
2017/08/26 12:27:11 step 6: objective=0.02765806
2017/08/26 12:27:14 step 7: objective=0.02769945
2017/08/26 12:27:14 Training value function...
2017/08/26 12:27:15 step 0: mse=1.156342 step=0.100000
2017/08/26 12:27:16 step 1: mse=1.091307 step=0.100000
2017/08/26 12:27:16 step 2: mse=1.038515 step=0.100000
2017/08/26 12:27:17 step 3: mse=0.988314 step=0.100000
2017/08/26 12:27:18 step 4: mse=0.952769 step=0.100000
2017/08/26 12:27:18 step 5: mse=0.918225 step=0.100000
2017/08/26 12:27:19 step 6: mse=0.861623 step=0.100000
2017/08/26 12:27:20 step 7: mse=0.813800 step=0.100000
2017/08/26 12:27:20 Saving...
2017/08/26 12:27:20 Gathering batch of experience...
2017/08/26 12:27:36 batch 123: mean=15.695652 stddev=6.227113 entropy=1.086550 frames=36630 count=46
2017/08/26 12:27:36 Training policy...
2017/08/26 12:27:40 step 0: objective=0.028618084
2017/08/26 12:27:43 step 1: objective=0.028672276
2017/08/26 12:27:46 step 2: objective=0.028726624
2017/08/26 12:27:48 step 3: objective=0.028781347
2017/08/26 12:27:51 step 4: objective=0.028827503
2017/08/26 12:27:54 step 5: objective=0.028851846
2017/08/26 12:27:56 step 6: objective=0.028875895
2017/08/26 12:27:59 step 7: objective=0.02889979
2017/08/26 12:27:59 Training value function...
2017/08/26 12:28:00 step 0: mse=1.026650 step=0.100000
2017/08/26 12:28:01 step 1: mse=0.962407 step=0.100000
2017/08/26 12:28:02 step 2: mse=0.908872 step=0.100000
2017/08/26 12:28:02 step 3: mse=0.864511 step=0.100000
2017/08/26 12:28:03 step 4: mse=0.828538 step=0.100000
2017/08/26 12:28:04 step 5: mse=0.794126 step=0.100000
2017/08/26 12:28:04 step 6: mse=0.767091 step=0.100000
2017/08/26 12:28:05 step 7: mse=0.742859 step=0.100000
2017/08/26 12:28:05 Saving...
2017/08/26 12:28:05 Gathering batch of experience...
2017/08/26 12:28:21 batch 124: mean=15.021739 stddev=7.449800 entropy=1.091467 frames=35901 count=46
2017/08/26 12:28:21 Training policy...
2017/08/26 12:28:25 step 0: objective=0.033683177
2017/08/26 12:28:28 step 1: objective=0.033770792
2017/08/26 12:28:30 step 2: objective=0.033859044
2017/08/26 12:28:33 step 3: objective=0.033946205
2017/08/26 12:28:36 step 4: objective=0.03398719
2017/08/26 12:28:38 step 5: objective=0.03404182
2017/08/26 12:28:41 step 6: objective=0.034094993
2017/08/26 12:28:43 step 7: objective=0.03413484
2017/08/26 12:28:43 Training value function...
2017/08/26 12:28:45 step 0: mse=0.956492 step=0.100000
2017/08/26 12:28:45 step 1: mse=0.886860 step=0.100000
2017/08/26 12:28:46 step 2: mse=0.830561 step=0.100000
2017/08/26 12:28:47 step 3: mse=0.784273 step=0.100000
2017/08/26 12:28:48 step 4: mse=0.743205 step=0.100000
2017/08/26 12:28:48 step 5: mse=0.710415 step=0.100000
2017/08/26 12:28:49 step 6: mse=0.682789 step=0.100000
2017/08/26 12:28:50 step 7: mse=0.658158 step=0.100000
2017/08/26 12:28:50 Saving...
2017/08/26 12:28:50 Gathering batch of experience...
2017/08/26 12:29:06 batch 125: mean=17.619048 stddev=8.679347 entropy=1.072863 frames=37221 count=42
2017/08/26 12:29:06 Training policy...
2017/08/26 12:29:11 step 0: objective=0.031384405
2017/08/26 12:29:14 step 1: objective=0.031422693
2017/08/26 12:29:16 step 2: objective=0.031460945
2017/08/26 12:29:19 step 3: objective=0.03149926
2017/08/26 12:29:22 step 4: objective=0.03153753
2017/08/26 12:29:24 step 5: objective=0.031575818
2017/08/26 12:29:27 step 6: objective=0.031612743
2017/08/26 12:29:30 step 7: objective=0.0316604
2017/08/26 12:29:30 Training value function...
2017/08/26 12:29:31 step 0: mse=0.856498 step=0.100000
2017/08/26 12:29:32 step 1: mse=0.801275 step=0.100000
2017/08/26 12:29:32 step 2: mse=0.760138 step=0.100000
2017/08/26 12:29:33 step 3: mse=0.729924 step=0.100000
2017/08/26 12:29:34 step 4: mse=0.695721 step=0.100000
2017/08/26 12:29:35 step 5: mse=0.671552 step=0.100000
2017/08/26 12:29:36 step 6: mse=0.644491 step=0.100000
2017/08/26 12:29:36 step 7: mse=0.622589 step=0.100000
2017/08/26 12:29:36 Saving...
2017/08/26 12:29:36 Gathering batch of experience...
2017/08/26 12:29:53 batch 126: mean=14.617021 stddev=6.567338 entropy=1.082805 frames=36909 count=47
2017/08/26 12:29:53 Training policy...
2017/08/26 12:29:57 step 0: objective=0.026316678
2017/08/26 12:30:00 step 1: objective=0.026344594
2017/08/26 12:30:03 step 2: objective=0.026372392
2017/08/26 12:30:05 step 3: objective=0.026400335
2017/08/26 12:30:08 step 4: objective=0.026428131
2017/08/26 12:30:11 step 5: objective=0.026455792
2017/08/26 12:30:13 step 6: objective=0.026481705
2017/08/26 12:30:16 step 7: objective=0.026510907
2017/08/26 12:30:16 Training value function...
2017/08/26 12:30:17 step 0: mse=0.628381 step=0.100000
2017/08/26 12:30:18 step 1: mse=0.604054 step=0.100000
2017/08/26 12:30:19 step 2: mse=0.582885 step=0.100000
2017/08/26 12:30:19 step 3: mse=0.561055 step=0.100000
2017/08/26 12:30:20 step 4: mse=0.546395 step=0.100000
2017/08/26 12:30:21 step 5: mse=0.529954 step=0.100000
2017/08/26 12:30:22 step 6: mse=0.520877 step=0.100000
2017/08/26 12:30:22 step 7: mse=0.501424 step=0.100000
2017/08/26 12:30:22 Saving...
2017/08/26 12:30:22 Gathering batch of experience...
2017/08/26 12:30:39 batch 127: mean=15.555556 stddev=5.057692 entropy=1.083704 frames=36676 count=45
2017/08/26 12:30:39 Training policy...
2017/08/26 12:30:43 step 0: objective=0.03924953
2017/08/26 12:30:46 step 1: objective=0.0393127
2017/08/26 12:30:49 step 2: objective=0.03937636
2017/08/26 12:30:51 step 3: objective=0.039439563
2017/08/26 12:30:54 step 4: objective=0.03949889
2017/08/26 12:30:57 step 5: objective=0.039541975
2017/08/26 12:30:59 step 6: objective=0.0395751
2017/08/26 12:31:02 step 7: objective=0.039607283
2017/08/26 12:31:02 Training value function...
2017/08/26 12:31:03 step 0: mse=0.751282 step=0.100000
2017/08/26 12:31:04 step 1: mse=0.708899 step=0.100000
2017/08/26 12:31:05 step 2: mse=0.674674 step=0.100000
2017/08/26 12:31:05 step 3: mse=0.646561 step=0.100000
2017/08/26 12:31:06 step 4: mse=0.623444 step=0.100000
2017/08/26 12:31:07 step 5: mse=0.602404 step=0.100000
2017/08/26 12:31:08 step 6: mse=0.578059 step=0.100000
2017/08/26 12:31:08 step 7: mse=0.563364 step=0.100000
2017/08/26 12:31:08 Saving...
2017/08/26 12:31:08 Gathering batch of experience...
2017/08/26 12:31:24 batch 128: mean=14.652174 stddev=6.051293 entropy=1.087849 frames=35971 count=46
2017/08/26 12:31:24 Training policy...
2017/08/26 12:31:29 step 0: objective=0.008219031
2017/08/26 12:31:31 step 1: objective=0.008276048
2017/08/26 12:31:34 step 2: objective=0.008332384
2017/08/26 12:31:37 step 3: objective=0.00838772
2017/08/26 12:31:39 step 4: objective=0.008430101
2017/08/26 12:31:42 step 5: objective=0.008493296
2017/08/26 12:31:44 step 6: objective=0.008517166
2017/08/26 12:31:47 step 7: objective=0.008581151
2017/08/26 12:31:47 Training value function...
2017/08/26 12:31:48 step 0: mse=0.724231 step=0.100000
2017/08/26 12:31:49 step 1: mse=0.679232 step=0.100000
2017/08/26 12:31:50 step 2: mse=0.643384 step=0.100000
2017/08/26 12:31:50 step 3: mse=0.612482 step=0.100000
2017/08/26 12:31:51 step 4: mse=0.595170 step=0.100000
2017/08/26 12:31:52 step 5: mse=0.572678 step=0.100000
2017/08/26 12:31:53 step 6: mse=0.550520 step=0.100000
2017/08/26 12:31:53 step 7: mse=0.536888 step=0.100000
2017/08/26 12:31:53 Saving...
2017/08/26 12:31:54 Gathering batch of experience...
2017/08/26 12:32:10 batch 129: mean=15.956522 stddev=7.980837 entropy=1.076791 frames=36705 count=46
2017/08/26 12:32:10 Training policy...
2017/08/26 12:32:15 step 0: objective=0.044173233
2017/08/26 12:32:17 step 1: objective=0.04421993
2017/08/26 12:32:20 step 2: objective=0.04426609
2017/08/26 12:32:22 step 3: objective=0.044312038
2017/08/26 12:32:25 step 4: objective=0.04435788
2017/08/26 12:32:28 step 5: objective=0.044403635
2017/08/26 12:32:31 step 6: objective=0.04444531
2017/08/26 12:32:33 step 7: objective=0.044491187
2017/08/26 12:32:33 Training value function...
2017/08/26 12:32:34 step 0: mse=0.964331 step=0.100000
2017/08/26 12:32:35 step 1: mse=0.925399 step=0.100000
2017/08/26 12:32:36 step 2: mse=0.890198 step=0.100000
2017/08/26 12:32:37 step 3: mse=0.866706 step=0.100000
2017/08/26 12:32:38 step 4: mse=0.847234 step=0.100000
2017/08/26 12:32:38 step 5: mse=0.817249 step=0.100000
2017/08/26 12:32:39 step 6: mse=0.794149 step=0.100000
2017/08/26 12:32:40 step 7: mse=0.779811 step=0.100000
2017/08/26 12:32:40 Saving...
2017/08/26 12:32:40 Gathering batch of experience...
2017/08/26 12:32:56 batch 130: mean=14.958333 stddev=6.550949 entropy=1.085306 frames=36635 count=48
2017/08/26 12:32:56 Training policy...
2017/08/26 12:33:00 step 0: objective=0.027287452
2017/08/26 12:33:03 step 1: objective=0.027327621
2017/08/26 12:33:06 step 2: objective=0.027367938
2017/08/26 12:33:08 step 3: objective=0.027408078
2017/08/26 12:33:11 step 4: objective=0.027448537
2017/08/26 12:33:14 step 5: objective=0.02748881
2017/08/26 12:33:16 step 6: objective=0.027526105
2017/08/26 12:33:19 step 7: objective=0.02755797
2017/08/26 12:33:19 Training value function...
2017/08/26 12:33:20 step 0: mse=0.917659 step=0.100000
2017/08/26 12:33:21 step 1: mse=0.870564 step=0.100000
2017/08/26 12:33:22 step 2: mse=0.833025 step=0.100000
2017/08/26 12:33:23 step 3: mse=0.801292 step=0.100000
2017/08/26 12:33:23 step 4: mse=0.773210 step=0.100000
2017/08/26 12:33:24 step 5: mse=0.744358 step=0.100000
2017/08/26 12:33:25 step 6: mse=0.712666 step=0.100000
2017/08/26 12:33:26 step 7: mse=0.692091 step=0.100000
2017/08/26 12:33:26 Saving...
2017/08/26 12:33:26 Gathering batch of experience...
2017/08/26 12:33:42 batch 131: mean=16.886364 stddev=6.064861 entropy=1.078869 frames=37066 count=44
2017/08/26 12:33:42 Training policy...
2017/08/26 12:33:47 step 0: objective=0.04514912
2017/08/26 12:33:49 step 1: objective=0.04521104
2017/08/26 12:33:52 step 2: objective=0.04527358
2017/08/26 12:33:55 step 3: objective=0.04533634
2017/08/26 12:33:58 step 4: objective=0.04540415
2017/08/26 12:34:00 step 5: objective=0.045462582
2017/08/26 12:34:03 step 6: objective=0.04552121
2017/08/26 12:34:06 step 7: objective=0.045584977
2017/08/26 12:34:06 Training value function...
2017/08/26 12:34:07 step 0: mse=1.176470 step=0.100000
2017/08/26 12:34:08 step 1: mse=1.100436 step=0.100000
2017/08/26 12:34:08 step 2: mse=1.028683 step=0.100000
2017/08/26 12:34:09 step 3: mse=0.986665 step=0.100000
2017/08/26 12:34:10 step 4: mse=0.935153 step=0.100000
2017/08/26 12:34:11 step 5: mse=0.893160 step=0.100000
2017/08/26 12:34:11 step 6: mse=0.866919 step=0.100000
2017/08/26 12:34:12 step 7: mse=0.840091 step=0.100000
2017/08/26 12:34:12 Saving...
2017/08/26 12:34:12 Gathering batch of experience...
2017/08/26 12:34:29 batch 132: mean=15.777778 stddev=7.070719 entropy=1.083011 frames=36994 count=45
2017/08/26 12:34:29 Training policy...
2017/08/26 12:34:33 step 0: objective=0.0495413
2017/08/26 12:34:36 step 1: objective=0.049629908
2017/08/26 12:34:39 step 2: objective=0.04971937
2017/08/26 12:34:41 step 3: objective=0.049809206
2017/08/26 12:34:44 step 4: objective=0.04988574
2017/08/26 12:34:47 step 5: objective=0.049927406
2017/08/26 12:34:49 step 6: objective=0.049969684
2017/08/26 12:34:52 step 7: objective=0.05003348
2017/08/26 12:34:52 Training value function...
2017/08/26 12:34:53 step 0: mse=1.300423 step=0.100000
2017/08/26 12:34:54 step 1: mse=1.173965 step=0.100000
2017/08/26 12:34:55 step 2: mse=1.071724 step=0.100000
2017/08/26 12:34:56 step 3: mse=0.989268 step=0.100000
2017/08/26 12:34:56 step 4: mse=0.916970 step=0.100000
2017/08/26 12:34:57 step 5: mse=0.854093 step=0.100000
2017/08/26 12:34:58 step 6: mse=0.801939 step=0.100000
2017/08/26 12:34:59 step 7: mse=0.762518 step=0.100000
2017/08/26 12:34:59 Saving...
2017/08/26 12:34:59 Gathering batch of experience...
2017/08/26 12:35:15 batch 133: mean=14.224490 stddev=6.701402 entropy=1.088358 frames=36729 count=49
2017/08/26 12:35:15 Training policy...
2017/08/26 12:35:20 step 0: objective=0.0325133
2017/08/26 12:35:22 step 1: objective=0.032586332
2017/08/26 12:35:25 step 2: objective=0.032658912
2017/08/26 12:35:28 step 3: objective=0.032731265
2017/08/26 12:35:30 step 4: objective=0.03280347
2017/08/26 12:35:33 step 5: objective=0.03287316
2017/08/26 12:35:36 step 6: objective=0.0329252
2017/08/26 12:35:39 step 7: objective=0.032968983
2017/08/26 12:35:39 Training value function...
2017/08/26 12:35:40 step 0: mse=0.849947 step=0.100000
2017/08/26 12:35:41 step 1: mse=0.789040 step=0.100000
2017/08/26 12:35:41 step 2: mse=0.739919 step=0.100000
2017/08/26 12:35:42 step 3: mse=0.699097 step=0.100000
2017/08/26 12:35:43 step 4: mse=0.668555 step=0.100000
2017/08/26 12:35:44 step 5: mse=0.645090 step=0.100000
2017/08/26 12:35:44 step 6: mse=0.615979 step=0.100000
2017/08/26 12:35:45 step 7: mse=0.598569 step=0.100000
2017/08/26 12:35:45 Saving...
2017/08/26 12:35:45 Gathering batch of experience...
2017/08/26 12:36:02 batch 134: mean=17.465116 stddev=8.286579 entropy=1.068419 frames=36965 count=43
2017/08/26 12:36:02 Training policy...
2017/08/26 12:36:06 step 0: objective=0.054609805
2017/08/26 12:36:09 step 1: objective=0.054655768
2017/08/26 12:36:11 step 2: objective=0.054701876
2017/08/26 12:36:14 step 3: objective=0.054747816
2017/08/26 12:36:17 step 4: objective=0.05479324
2017/08/26 12:36:20 step 5: objective=0.054838162
2017/08/26 12:36:22 step 6: objective=0.054886058
2017/08/26 12:36:25 step 7: objective=0.054949455
2017/08/26 12:36:25 Training value function...
2017/08/26 12:36:26 step 0: mse=1.269502 step=0.100000
2017/08/26 12:36:27 step 1: mse=1.171388 step=0.100000
2017/08/26 12:36:28 step 2: mse=1.091142 step=0.100000
2017/08/26 12:36:29 step 3: mse=1.024005 step=0.100000
2017/08/26 12:36:29 step 4: mse=0.973518 step=0.100000
2017/08/26 12:36:30 step 5: mse=0.928623 step=0.100000
2017/08/26 12:36:31 step 6: mse=0.889512 step=0.100000
2017/08/26 12:36:32 step 7: mse=0.843247 step=0.100000
2017/08/26 12:36:32 Saving...
2017/08/26 12:36:32 Gathering batch of experience...
2017/08/26 12:36:48 batch 135: mean=15.422222 stddev=6.212850 entropy=1.085074 frames=36756 count=45
2017/08/26 12:36:48 Training policy...
2017/08/26 12:36:53 step 0: objective=-0.0002955247
2017/08/26 12:36:55 step 1: objective=-0.0002271351
2017/08/26 12:36:58 step 2: objective=-0.00015878236
2017/08/26 12:37:01 step 3: objective=-9.0468166e-05
2017/08/26 12:37:04 step 4: objective=-2.2299082e-05
2017/08/26 12:37:06 step 5: objective=3.894951e-05
2017/08/26 12:37:09 step 6: objective=7.2888026e-05
2017/08/26 12:37:12 step 7: objective=0.00015133317
2017/08/26 12:37:12 Training value function...
2017/08/26 12:37:13 step 0: mse=1.092931 step=0.100000
2017/08/26 12:37:14 step 1: mse=0.994943 step=0.100000
2017/08/26 12:37:15 step 2: mse=0.918965 step=0.100000
2017/08/26 12:37:15 step 3: mse=0.853591 step=0.100000
2017/08/26 12:37:16 step 4: mse=0.799854 step=0.100000
2017/08/26 12:37:17 step 5: mse=0.756629 step=0.100000
2017/08/26 12:37:18 step 6: mse=0.723509 step=0.100000
2017/08/26 12:37:18 step 7: mse=0.692963 step=0.100000
2017/08/26 12:37:18 Saving...
2017/08/26 12:37:18 Gathering batch of experience...
2017/08/26 12:37:35 batch 136: mean=15.956522 stddev=7.532413 entropy=1.080361 frames=36545 count=46
2017/08/26 12:37:35 Training policy...
2017/08/26 12:37:39 step 0: objective=0.048282545
2017/08/26 12:37:42 step 1: objective=0.04836951
2017/08/26 12:37:44 step 2: objective=0.048455376
2017/08/26 12:37:47 step 3: objective=0.048541825
2017/08/26 12:37:50 step 4: objective=0.048627004
2017/08/26 12:37:53 step 5: objective=0.048706513
2017/08/26 12:37:55 step 6: objective=0.04875355
2017/08/26 12:37:58 step 7: objective=0.04879709
2017/08/26 12:37:58 Training value function...
2017/08/26 12:37:59 step 0: mse=1.164542 step=0.100000
2017/08/26 12:38:00 step 1: mse=1.092184 step=0.100000
2017/08/26 12:38:01 step 2: mse=1.030714 step=0.100000
2017/08/26 12:38:01 step 3: mse=0.970149 step=0.100000
2017/08/26 12:38:02 step 4: mse=0.928188 step=0.100000
2017/08/26 12:38:03 step 5: mse=0.886189 step=0.100000
2017/08/26 12:38:04 step 6: mse=0.850093 step=0.100000
2017/08/26 12:38:04 step 7: mse=0.824331 step=0.100000
2017/08/26 12:38:04 Saving...
2017/08/26 12:38:04 Gathering batch of experience...
2017/08/26 12:38:21 batch 137: mean=17.833333 stddev=9.180509 entropy=1.077142 frames=36529 count=42
2017/08/26 12:38:21 Training policy...
2017/08/26 12:38:25 step 0: objective=0.045944802
2017/08/26 12:38:28 step 1: objective=0.046008524
2017/08/26 12:38:31 step 2: objective=0.046072673
2017/08/26 12:38:33 step 3: objective=0.046135716
2017/08/26 12:38:36 step 4: objective=0.04617382
2017/08/26 12:38:39 step 5: objective=0.046210546
2017/08/26 12:38:41 step 6: objective=0.04623819
2017/08/26 12:38:44 step 7: objective=0.04626344
2017/08/26 12:38:44 Training value function...
2017/08/26 12:38:45 step 0: mse=1.063951 step=0.100000
2017/08/26 12:38:46 step 1: mse=1.007135 step=0.100000
2017/08/26 12:38:47 step 2: mse=0.960981 step=0.100000
2017/08/26 12:38:48 step 3: mse=0.925738 step=0.100000
2017/08/26 12:38:48 step 4: mse=0.893190 step=0.100000
2017/08/26 12:38:49 step 5: mse=0.864585 step=0.100000
2017/08/26 12:38:50 step 6: mse=0.835632 step=0.100000
2017/08/26 12:38:51 step 7: mse=0.817465 step=0.100000
2017/08/26 12:38:51 Saving...
2017/08/26 12:38:51 Gathering batch of experience...
2017/08/26 12:39:07 batch 138: mean=17.651163 stddev=7.909028 entropy=1.066270 frames=37056 count=43
2017/08/26 12:39:07 Training policy...
2017/08/26 12:39:12 step 0: objective=0.03741014
2017/08/26 12:39:15 step 1: objective=0.03743851
2017/08/26 12:39:17 step 2: objective=0.037467327
2017/08/26 12:39:20 step 3: objective=0.037496105
2017/08/26 12:39:23 step 4: objective=0.037530914
2017/08/26 12:39:26 step 5: objective=0.037565634
2017/08/26 12:39:28 step 6: objective=0.037591178
2017/08/26 12:39:31 step 7: objective=0.037622318
2017/08/26 12:39:31 Training value function...
2017/08/26 12:39:32 step 0: mse=1.072569 step=0.100000
2017/08/26 12:39:33 step 1: mse=1.007518 step=0.100000
2017/08/26 12:39:34 step 2: mse=0.954183 step=0.100000
2017/08/26 12:39:35 step 3: mse=0.910676 step=0.100000
2017/08/26 12:39:36 step 4: mse=0.874590 step=0.100000
2017/08/26 12:39:36 step 5: mse=0.850053 step=0.100000
2017/08/26 12:39:37 step 6: mse=0.817725 step=0.100000
2017/08/26 12:39:38 step 7: mse=0.796240 step=0.100000
2017/08/26 12:39:38 Saving...
2017/08/26 12:39:38 Gathering batch of experience...
2017/08/26 12:39:54 batch 139: mean=13.530612 stddev=5.750251 entropy=1.086001 frames=36023 count=49
2017/08/26 12:39:54 Training policy...
2017/08/26 12:39:59 step 0: objective=0.0014187897
2017/08/26 12:40:01 step 1: objective=0.0014454906
2017/08/26 12:40:04 step 2: objective=0.0014721076
2017/08/26 12:40:07 step 3: objective=0.001498634
2017/08/26 12:40:09 step 4: objective=0.0015250698
2017/08/26 12:40:12 step 5: objective=0.0015514238
2017/08/26 12:40:15 step 6: objective=0.001577035
2017/08/26 12:40:17 step 7: objective=0.0016033282
2017/08/26 12:40:17 Training value function...
2017/08/26 12:40:19 step 0: mse=0.697612 step=0.100000
2017/08/26 12:40:19 step 1: mse=0.673340 step=0.100000
2017/08/26 12:40:20 step 2: mse=0.657012 step=0.100000
2017/08/26 12:40:21 step 3: mse=0.640872 step=0.100000
2017/08/26 12:40:22 step 4: mse=0.625094 step=0.100000
2017/08/26 12:40:23 step 5: mse=0.601260 step=0.100000
2017/08/26 12:40:23 step 6: mse=0.590447 step=0.100000
2017/08/26 12:40:24 step 7: mse=0.572247 step=0.100000
2017/08/26 12:40:24 Saving...
2017/08/26 12:40:24 Gathering batch of experience...
2017/08/26 12:40:40 batch 140: mean=16.681818 stddev=6.560116 entropy=1.076825 frames=35983 count=44
2017/08/26 12:40:40 Training policy...
2017/08/26 12:40:44 step 0: objective=0.050674662
2017/08/26 12:40:47 step 1: objective=0.050759975
2017/08/26 12:40:50 step 2: objective=0.050844833
2017/08/26 12:40:53 step 3: objective=0.05092953
2017/08/26 12:40:55 step 4: objective=0.050986227
2017/08/26 12:40:58 step 5: objective=0.051037423
2017/08/26 12:41:01 step 6: objective=0.051081616
2017/08/26 12:41:03 step 7: objective=0.051123925
2017/08/26 12:41:03 Training value function...
2017/08/26 12:41:04 step 0: mse=0.888883 step=0.100000
2017/08/26 12:41:05 step 1: mse=0.847681 step=0.100000
2017/08/26 12:41:06 step 2: mse=0.814128 step=0.100000
2017/08/26 12:41:07 step 3: mse=0.786544 step=0.100000
2017/08/26 12:41:07 step 4: mse=0.765948 step=0.100000
2017/08/26 12:41:08 step 5: mse=0.744602 step=0.100000
2017/08/26 12:41:09 step 6: mse=0.726627 step=0.100000
2017/08/26 12:41:10 step 7: mse=0.708910 step=0.100000
2017/08/26 12:41:10 Saving...
2017/08/26 12:41:10 Gathering batch of experience...
2017/08/26 12:41:26 batch 141: mean=15.086957 stddev=7.430332 entropy=1.083604 frames=36313 count=46
2017/08/26 12:41:26 Training policy...
2017/08/26 12:41:30 step 0: objective=0.032638732
2017/08/26 12:41:33 step 1: objective=0.032691885
2017/08/26 12:41:36 step 2: objective=0.032744877
2017/08/26 12:41:39 step 3: objective=0.032797664
2017/08/26 12:41:41 step 4: objective=0.032849602
2017/08/26 12:41:44 step 5: objective=0.032898292
2017/08/26 12:41:47 step 6: objective=0.032939762
2017/08/26 12:41:49 step 7: objective=0.032994714
2017/08/26 12:41:49 Training value function...
2017/08/26 12:41:51 step 0: mse=1.113897 step=0.100000
2017/08/26 12:41:51 step 1: mse=0.996793 step=0.100000
2017/08/26 12:41:52 step 2: mse=0.902499 step=0.100000
2017/08/26 12:41:53 step 3: mse=0.825840 step=0.100000
2017/08/26 12:41:54 step 4: mse=0.763933 step=0.100000
2017/08/26 12:41:54 step 5: mse=0.713271 step=0.100000
2017/08/26 12:41:55 step 6: mse=0.671594 step=0.100000
2017/08/26 12:41:56 step 7: mse=0.635926 step=0.100000
2017/08/26 12:41:56 Saving...
2017/08/26 12:41:56 Gathering batch of experience...
2017/08/26 12:42:12 batch 142: mean=16.302326 stddev=6.677052 entropy=1.080090 frames=35691 count=43
2017/08/26 12:42:12 Training policy...
2017/08/26 12:42:16 step 0: objective=0.040595166
2017/08/26 12:42:19 step 1: objective=0.040632963
2017/08/26 12:42:22 step 2: objective=0.04067059
2017/08/26 12:42:24 step 3: objective=0.040708236
2017/08/26 12:42:27 step 4: objective=0.04074618
2017/08/26 12:42:30 step 5: objective=0.040783823
2017/08/26 12:42:32 step 6: objective=0.040820014
2017/08/26 12:42:35 step 7: objective=0.040862177
2017/08/26 12:42:35 Training value function...
2017/08/26 12:42:36 step 0: mse=0.781438 step=0.100000
2017/08/26 12:42:37 step 1: mse=0.738523 step=0.100000
2017/08/26 12:42:38 step 2: mse=0.700862 step=0.100000
2017/08/26 12:42:38 step 3: mse=0.671244 step=0.100000
2017/08/26 12:42:39 step 4: mse=0.644565 step=0.100000
2017/08/26 12:42:40 step 5: mse=0.624011 step=0.100000
2017/08/26 12:42:41 step 6: mse=0.601717 step=0.100000
2017/08/26 12:42:41 step 7: mse=0.587072 step=0.100000
2017/08/26 12:42:41 Saving...
2017/08/26 12:42:41 Gathering batch of experience...
2017/08/26 12:42:58 batch 143: mean=14.170213 stddev=5.501718 entropy=1.092112 frames=36048 count=47
2017/08/26 12:42:58 Training policy...
2017/08/26 12:43:02 step 0: objective=0.009047457
2017/08/26 12:43:05 step 1: objective=0.009128678
2017/08/26 12:43:07 step 2: objective=0.009211099
2017/08/26 12:43:10 step 3: objective=0.009293145
2017/08/26 12:43:13 step 4: objective=0.009328661
2017/08/26 12:43:16 step 5: objective=0.009357501
2017/08/26 12:43:18 step 6: objective=0.00938805
2017/08/26 12:43:21 step 7: objective=0.009451097
2017/08/26 12:43:21 Training value function...
2017/08/26 12:43:22 step 0: mse=0.775568 step=0.100000
2017/08/26 12:43:23 step 1: mse=0.746976 step=0.100000
2017/08/26 12:43:24 step 2: mse=0.725729 step=0.100000
2017/08/26 12:43:24 step 3: mse=0.706224 step=0.100000
2017/08/26 12:43:25 step 4: mse=0.692971 step=0.100000
2017/08/26 12:43:26 step 5: mse=0.675744 step=0.100000
2017/08/26 12:43:27 step 6: mse=0.663666 step=0.100000
2017/08/26 12:43:27 step 7: mse=0.655544 step=0.100000
2017/08/26 12:43:27 Saving...
2017/08/26 12:43:27 Gathering batch of experience...
2017/08/26 12:43:44 batch 144: mean=14.847826 stddev=5.445251 entropy=1.086157 frames=36252 count=46
2017/08/26 12:43:44 Training policy...
2017/08/26 12:43:48 step 0: objective=0.01941222
2017/08/26 12:43:51 step 1: objective=0.019437257
2017/08/26 12:43:54 step 2: objective=0.019462384
2017/08/26 12:43:56 step 3: objective=0.019487409
2017/08/26 12:43:59 step 4: objective=0.019512594
2017/08/26 12:44:02 step 5: objective=0.01953767
2017/08/26 12:44:04 step 6: objective=0.019562667
2017/08/26 12:44:07 step 7: objective=0.019586172
2017/08/26 12:44:07 Training value function...
2017/08/26 12:44:08 step 0: mse=0.785803 step=0.100000
2017/08/26 12:44:09 step 1: mse=0.738856 step=0.100000
2017/08/26 12:44:10 step 2: mse=0.701213 step=0.100000
2017/08/26 12:44:11 step 3: mse=0.669764 step=0.100000
2017/08/26 12:44:11 step 4: mse=0.642041 step=0.100000
2017/08/26 12:44:12 step 5: mse=0.618434 step=0.100000
2017/08/26 12:44:13 step 6: mse=0.597536 step=0.100000
2017/08/26 12:44:14 step 7: mse=0.580403 step=0.100000
2017/08/26 12:44:14 Saving...
2017/08/26 12:44:14 Gathering batch of experience...
2017/08/26 12:44:30 batch 145: mean=16.422222 stddev=5.475152 entropy=1.077275 frames=36528 count=45
2017/08/26 12:44:30 Training policy...
2017/08/26 12:44:35 step 0: objective=0.050404213
2017/08/26 12:44:37 step 1: objective=0.050438996
2017/08/26 12:44:40 step 2: objective=0.05047392
2017/08/26 12:44:43 step 3: objective=0.050508298
2017/08/26 12:44:46 step 4: objective=0.050543003
2017/08/26 12:44:48 step 5: objective=0.050576698
2017/08/26 12:44:51 step 6: objective=0.05060626
2017/08/26 12:44:54 step 7: objective=0.050629053
2017/08/26 12:44:54 Training value function...
2017/08/26 12:44:55 step 0: mse=1.049469 step=0.100000
2017/08/26 12:44:56 step 1: mse=0.991847 step=0.100000
2017/08/26 12:44:57 step 2: mse=0.941021 step=0.100000
2017/08/26 12:44:57 step 3: mse=0.898893 step=0.100000
2017/08/26 12:44:58 step 4: mse=0.862737 step=0.100000
2017/08/26 12:44:59 step 5: mse=0.833729 step=0.100000
2017/08/26 12:45:00 step 6: mse=0.798259 step=0.100000
2017/08/26 12:45:01 step 7: mse=0.776661 step=0.100000
2017/08/26 12:45:01 Saving...
2017/08/26 12:45:01 Gathering batch of experience...
2017/08/26 12:45:17 batch 146: mean=15.630435 stddev=7.458169 entropy=1.071423 frames=36106 count=46
2017/08/26 12:45:17 Training policy...
2017/08/26 12:45:21 step 0: objective=0.019129645
2017/08/26 12:45:24 step 1: objective=0.019171884
2017/08/26 12:45:27 step 2: objective=0.019214507
2017/08/26 12:45:30 step 3: objective=0.019257655
2017/08/26 12:45:32 step 4: objective=0.019300671
2017/08/26 12:45:35 step 5: objective=0.01940232
2017/08/26 12:45:38 step 6: objective=0.019507311
2017/08/26 12:45:41 step 7: objective=0.019534752
2017/08/26 12:45:41 Training value function...
2017/08/26 12:45:42 step 0: mse=1.047512 step=0.100000
2017/08/26 12:45:42 step 1: mse=0.974905 step=0.100000
2017/08/26 12:45:43 step 2: mse=0.915959 step=0.100000
2017/08/26 12:45:44 step 3: mse=0.872213 step=0.100000
2017/08/26 12:45:45 step 4: mse=0.831540 step=0.100000
2017/08/26 12:45:45 step 5: mse=0.793490 step=0.100000
2017/08/26 12:45:46 step 6: mse=0.764501 step=0.100000
2017/08/26 12:45:47 step 7: mse=0.737893 step=0.100000
2017/08/26 12:45:47 Saving...
2017/08/26 12:45:47 Gathering batch of experience...
2017/08/26 12:46:04 batch 147: mean=15.021739 stddev=7.385324 entropy=1.078073 frames=36751 count=46
2017/08/26 12:46:04 Training policy...
2017/08/26 12:46:08 step 0: objective=0.02415128
2017/08/26 12:46:11 step 1: objective=0.024195777
2017/08/26 12:46:14 step 2: objective=0.024240682
2017/08/26 12:46:16 step 3: objective=0.024286138
2017/08/26 12:46:19 step 4: objective=0.024331646
2017/08/26 12:46:22 step 5: objective=0.024363149
2017/08/26 12:46:25 step 6: objective=0.024402592
2017/08/26 12:46:28 step 7: objective=0.024439758
2017/08/26 12:46:28 Training value function...
2017/08/26 12:46:29 step 0: mse=1.003080 step=0.100000
2017/08/26 12:46:30 step 1: mse=0.930867 step=0.100000
2017/08/26 12:46:30 step 2: mse=0.862368 step=0.100000
2017/08/26 12:46:31 step 3: mse=0.812583 step=0.100000
2017/08/26 12:46:32 step 4: mse=0.756011 step=0.100000
2017/08/26 12:46:33 step 5: mse=0.720766 step=0.100000
2017/08/26 12:46:33 step 6: mse=0.679155 step=0.100000
2017/08/26 12:46:34 step 7: mse=0.646142 step=0.100000
2017/08/26 12:46:34 Saving...
2017/08/26 12:46:34 Gathering batch of experience...
2017/08/26 12:46:50 batch 148: mean=15.333333 stddev=5.800383 entropy=1.073009 frames=35602 count=45
2017/08/26 12:46:50 Training policy...
2017/08/26 12:46:55 step 0: objective=0.033870917
2017/08/26 12:46:57 step 1: objective=0.033997063
2017/08/26 12:47:00 step 2: objective=0.034123413
2017/08/26 12:47:03 step 3: objective=0.03422646
2017/08/26 12:47:06 step 4: objective=0.03431631
2017/08/26 12:47:08 step 5: objective=0.034378897
2017/08/26 12:47:11 step 6: objective=0.034419686
2017/08/26 12:47:14 step 7: objective=0.03445787
2017/08/26 12:47:14 Training value function...
2017/08/26 12:47:15 step 0: mse=0.788434 step=0.100000
2017/08/26 12:47:16 step 1: mse=0.744866 step=0.100000
2017/08/26 12:47:16 step 2: mse=0.710441 step=0.100000
2017/08/26 12:47:17 step 3: mse=0.682251 step=0.100000
2017/08/26 12:47:18 step 4: mse=0.651225 step=0.100000
2017/08/26 12:47:18 step 5: mse=0.628506 step=0.100000
2017/08/26 12:47:19 step 6: mse=0.597309 step=0.100000
2017/08/26 12:47:20 step 7: mse=0.583286 step=0.100000
2017/08/26 12:47:20 Saving...
2017/08/26 12:47:20 Gathering batch of experience...
2017/08/26 12:47:36 batch 149: mean=14.000000 stddev=5.307562 entropy=1.082151 frames=35821 count=47
2017/08/26 12:47:36 Training policy...
2017/08/26 12:47:40 step 0: objective=0.015792241
2017/08/26 12:47:43 step 1: objective=0.015815936
2017/08/26 12:47:46 step 2: objective=0.015839392
2017/08/26 12:47:49 step 3: objective=0.015862817
2017/08/26 12:47:51 step 4: objective=0.015886296
2017/08/26 12:47:54 step 5: objective=0.015909858
2017/08/26 12:47:57 step 6: objective=0.01593338
2017/08/26 12:47:59 step 7: objective=0.015954234
2017/08/26 12:47:59 Training value function...
2017/08/26 12:48:01 step 0: mse=0.614554 step=0.100000
2017/08/26 12:48:01 step 1: mse=0.585422 step=0.100000
2017/08/26 12:48:02 step 2: mse=0.560942 step=0.100000
2017/08/26 12:48:03 step 3: mse=0.541214 step=0.100000
2017/08/26 12:48:04 step 4: mse=0.527838 step=0.100000
2017/08/26 12:48:04 step 5: mse=0.511950 step=0.100000
2017/08/26 12:48:05 step 6: mse=0.499323 step=0.100000
2017/08/26 12:48:06 step 7: mse=0.486230 step=0.100000
2017/08/26 12:48:06 Saving...
2017/08/26 12:48:06 Gathering batch of experience...
2017/08/26 12:48:22 batch 150: mean=16.883721 stddev=6.047138 entropy=1.078136 frames=37027 count=43
2017/08/26 12:48:22 Training policy...
2017/08/26 12:48:27 step 0: objective=0.05000608
2017/08/26 12:48:30 step 1: objective=0.050044257
2017/08/26 12:48:32 step 2: objective=0.05008275
2017/08/26 12:48:35 step 3: objective=0.05012094
2017/08/26 12:48:38 step 4: objective=0.050159335
2017/08/26 12:48:41 step 5: objective=0.05019742
2017/08/26 12:48:44 step 6: objective=0.05023381
2017/08/26 12:48:47 step 7: objective=0.050264314
2017/08/26 12:48:47 Training value function...
2017/08/26 12:48:48 step 0: mse=0.924678 step=0.100000
2017/08/26 12:48:49 step 1: mse=0.860698 step=0.100000
2017/08/26 12:48:49 step 2: mse=0.809045 step=0.100000
2017/08/26 12:48:50 step 3: mse=0.757906 step=0.100000
2017/08/26 12:48:51 step 4: mse=0.722902 step=0.100000
2017/08/26 12:48:52 step 5: mse=0.688194 step=0.100000
2017/08/26 12:48:52 step 6: mse=0.661502 step=0.100000
2017/08/26 12:48:53 step 7: mse=0.635868 step=0.100000
2017/08/26 12:48:53 Saving...
2017/08/26 12:48:53 Gathering batch of experience...
2017/08/26 12:49:10 batch 151: mean=15.434783 stddev=6.243787 entropy=1.083273 frames=36296 count=46
2017/08/26 12:49:10 Training policy...
2017/08/26 12:49:14 step 0: objective=0.040456966
2017/08/26 12:49:17 step 1: objective=0.040491514
2017/08/26 12:49:19 step 2: objective=0.040525828
2017/08/26 12:49:22 step 3: objective=0.04056015
2017/08/26 12:49:25 step 4: objective=0.040594097
2017/08/26 12:49:28 step 5: objective=0.040627077
2017/08/26 12:49:31 step 6: objective=0.040657856
2017/08/26 12:49:33 step 7: objective=0.040687285
2017/08/26 12:49:33 Training value function...
2017/08/26 12:49:35 step 0: mse=0.950815 step=0.100000
2017/08/26 12:49:35 step 1: mse=0.893233 step=0.100000
2017/08/26 12:49:36 step 2: mse=0.846787 step=0.100000
2017/08/26 12:49:37 step 3: mse=0.808872 step=0.100000
2017/08/26 12:49:38 step 4: mse=0.770717 step=0.100000
2017/08/26 12:49:38 step 5: mse=0.739713 step=0.100000
2017/08/26 12:49:39 step 6: mse=0.712391 step=0.100000
2017/08/26 12:49:40 step 7: mse=0.679019 step=0.100000
2017/08/26 12:49:40 Saving...
2017/08/26 12:49:40 Gathering batch of experience...
2017/08/26 12:49:56 batch 152: mean=15.697674 stddev=5.285060 entropy=1.072050 frames=36661 count=43
2017/08/26 12:49:56 Training policy...
2017/08/26 12:50:01 step 0: objective=0.0126805855
2017/08/26 12:50:03 step 1: objective=0.012744719
2017/08/26 12:50:06 step 2: objective=0.012808428
2017/08/26 12:50:09 step 3: objective=0.012872031
2017/08/26 12:50:12 step 4: objective=0.012931749
2017/08/26 12:50:15 step 5: objective=0.012986634
2017/08/26 12:50:18 step 6: objective=0.013026869
2017/08/26 12:50:20 step 7: objective=0.013063465
2017/08/26 12:50:20 Training value function...
2017/08/26 12:50:22 step 0: mse=0.691143 step=0.100000
2017/08/26 12:50:22 step 1: mse=0.644556 step=0.100000
2017/08/26 12:50:23 step 2: mse=0.609436 step=0.100000
2017/08/26 12:50:24 step 3: mse=0.575062 step=0.100000
2017/08/26 12:50:25 step 4: mse=0.549851 step=0.100000
2017/08/26 12:50:25 step 5: mse=0.525227 step=0.100000
2017/08/26 12:50:26 step 6: mse=0.506361 step=0.100000
2017/08/26 12:50:27 step 7: mse=0.490258 step=0.100000
2017/08/26 12:50:27 Saving...
2017/08/26 12:50:27 Gathering batch of experience...
2017/08/26 12:50:43 batch 153: mean=15.717391 stddev=7.756240 entropy=1.078114 frames=36363 count=46
2017/08/26 12:50:43 Training policy...
2017/08/26 12:50:48 step 0: objective=0.05619141
2017/08/26 12:50:51 step 1: objective=0.056287978
2017/08/26 12:50:53 step 2: objective=0.05638374
2017/08/26 12:50:56 step 3: objective=0.05647303
2017/08/26 12:50:59 step 4: objective=0.05654068
2017/08/26 12:51:02 step 5: objective=0.056594837
2017/08/26 12:51:05 step 6: objective=0.056646857
2017/08/26 12:51:07 step 7: objective=0.056701038
2017/08/26 12:51:07 Training value function...
2017/08/26 12:51:09 step 0: mse=1.307719 step=0.100000
2017/08/26 12:51:09 step 1: mse=1.207524 step=0.100000
2017/08/26 12:51:10 step 2: mse=1.124671 step=0.100000
2017/08/26 12:51:11 step 3: mse=1.057427 step=0.100000
2017/08/26 12:51:12 step 4: mse=0.990196 step=0.100000
2017/08/26 12:51:13 step 5: mse=0.933956 step=0.100000
2017/08/26 12:51:13 step 6: mse=0.888609 step=0.100000
2017/08/26 12:51:14 step 7: mse=0.852896 step=0.100000
2017/08/26 12:51:14 Saving...
2017/08/26 12:51:14 Gathering batch of experience...
2017/08/26 12:51:30 batch 154: mean=16.239130 stddev=7.247743 entropy=1.080103 frames=36551 count=46
2017/08/26 12:51:30 Training policy...
2017/08/26 12:51:35 step 0: objective=0.054956257
2017/08/26 12:51:38 step 1: objective=0.05501097
2017/08/26 12:51:41 step 2: objective=0.055065792
2017/08/26 12:51:43 step 3: objective=0.055120397
2017/08/26 12:51:46 step 4: objective=0.05517312
2017/08/26 12:51:49 step 5: objective=0.055223856
2017/08/26 12:51:52 step 6: objective=0.055257034
2017/08/26 12:51:55 step 7: objective=0.055326883
2017/08/26 12:51:55 Training value function...
2017/08/26 12:51:56 step 0: mse=1.390159 step=0.100000
2017/08/26 12:51:57 step 1: mse=1.309190 step=0.100000
2017/08/26 12:51:58 step 2: mse=1.226789 step=0.100000
2017/08/26 12:51:58 step 3: mse=1.168746 step=0.100000
2017/08/26 12:51:59 step 4: mse=1.120522 step=0.100000
2017/08/26 12:52:00 step 5: mse=1.076764 step=0.100000
2017/08/26 12:52:01 step 6: mse=1.025381 step=0.100000
2017/08/26 12:52:01 step 7: mse=0.985973 step=0.100000
2017/08/26 12:52:01 Saving...
2017/08/26 12:52:01 Gathering batch of experience...
2017/08/26 12:52:18 batch 155: mean=15.586957 stddev=6.222596 entropy=1.075508 frames=36971 count=46
2017/08/26 12:52:18 Training policy...
2017/08/26 12:52:23 step 0: objective=0.026057431
2017/08/26 12:52:25 step 1: objective=0.026132055
2017/08/26 12:52:28 step 2: objective=0.026207598
2017/08/26 12:52:31 step 3: objective=0.026283918
2017/08/26 12:52:34 step 4: objective=0.026356269
2017/08/26 12:52:37 step 5: objective=0.026439138
2017/08/26 12:52:40 step 6: objective=0.026518408
2017/08/26 12:52:43 step 7: objective=0.026590656
2017/08/26 12:52:43 Training value function...
2017/08/26 12:52:44 step 0: mse=0.782973 step=0.100000
2017/08/26 12:52:45 step 1: mse=0.745076 step=0.100000
2017/08/26 12:52:45 step 2: mse=0.715110 step=0.100000
2017/08/26 12:52:46 step 3: mse=0.689908 step=0.100000
2017/08/26 12:52:47 step 4: mse=0.668037 step=0.100000
2017/08/26 12:52:48 step 5: mse=0.650141 step=0.100000
2017/08/26 12:52:48 step 6: mse=0.632126 step=0.100000
2017/08/26 12:52:49 step 7: mse=0.612590 step=0.100000
2017/08/26 12:52:49 Saving...
2017/08/26 12:52:49 Gathering batch of experience...
2017/08/26 12:53:06 batch 156: mean=15.127660 stddev=6.124999 entropy=1.075786 frames=36766 count=47
2017/08/26 12:53:06 Training policy...
2017/08/26 12:53:10 step 0: objective=0.027533013
2017/08/26 12:53:13 step 1: objective=0.027574504
2017/08/26 12:53:16 step 2: objective=0.027615994
2017/08/26 12:53:19 step 3: objective=0.027657215
2017/08/26 12:53:22 step 4: objective=0.027698701
2017/08/26 12:53:25 step 5: objective=0.02773956
2017/08/26 12:53:28 step 6: objective=0.027782412
2017/08/26 12:53:31 step 7: objective=0.027816728
2017/08/26 12:53:31 Training value function...
2017/08/26 12:53:32 step 0: mse=0.842232 step=0.100000
2017/08/26 12:53:33 step 1: mse=0.806887 step=0.100000
2017/08/26 12:53:33 step 2: mse=0.778410 step=0.100000
2017/08/26 12:53:34 step 3: mse=0.755009 step=0.100000
2017/08/26 12:53:35 step 4: mse=0.733623 step=0.100000
2017/08/26 12:53:36 step 5: mse=0.714496 step=0.100000
2017/08/26 12:53:36 step 6: mse=0.699515 step=0.100000
2017/08/26 12:53:37 step 7: mse=0.687134 step=0.100000
2017/08/26 12:53:37 Saving...
2017/08/26 12:53:37 Gathering batch of experience...
2017/08/26 12:53:53 batch 157: mean=16.688889 stddev=7.957728 entropy=1.070063 frames=35917 count=45
2017/08/26 12:53:53 Training policy...
2017/08/26 12:53:58 step 0: objective=0.058117066
2017/08/26 12:54:01 step 1: objective=0.05819107
2017/08/26 12:54:03 step 2: objective=0.05826555
2017/08/26 12:54:06 step 3: objective=0.058336947
2017/08/26 12:54:09 step 4: objective=0.058403566
2017/08/26 12:54:12 step 5: objective=0.058485027
2017/08/26 12:54:15 step 6: objective=0.05853853
2017/08/26 12:54:17 step 7: objective=0.058651194
2017/08/26 12:54:17 Training value function...
2017/08/26 12:54:19 step 0: mse=1.403353 step=0.100000
2017/08/26 12:54:19 step 1: mse=1.281759 step=0.100000
2017/08/26 12:54:20 step 2: mse=1.181663 step=0.100000
2017/08/26 12:54:21 step 3: mse=1.098097 step=0.100000
2017/08/26 12:54:22 step 4: mse=1.029678 step=0.100000
2017/08/26 12:54:22 step 5: mse=0.964385 step=0.100000
2017/08/26 12:54:23 step 6: mse=0.911381 step=0.100000
2017/08/26 12:54:24 step 7: mse=0.868409 step=0.100000
2017/08/26 12:54:24 Saving...
2017/08/26 12:54:24 Gathering batch of experience...
2017/08/26 12:54:40 batch 158: mean=15.152174 stddev=5.778398 entropy=1.082054 frames=35507 count=46
2017/08/26 12:54:40 Training policy...
2017/08/26 12:54:44 step 0: objective=0.016031327
2017/08/26 12:54:47 step 1: objective=0.016084487
2017/08/26 12:54:50 step 2: objective=0.016137488
2017/08/26 12:54:52 step 3: objective=0.016190495
2017/08/26 12:54:55 step 4: objective=0.016238509
2017/08/26 12:54:58 step 5: objective=0.016265739
2017/08/26 12:55:01 step 6: objective=0.016303243
2017/08/26 12:55:03 step 7: objective=0.01633867
2017/08/26 12:55:03 Training value function...
2017/08/26 12:55:05 step 0: mse=0.861497 step=0.100000
2017/08/26 12:55:05 step 1: mse=0.825056 step=0.100000
2017/08/26 12:55:06 step 2: mse=0.796068 step=0.100000
2017/08/26 12:55:07 step 3: mse=0.766699 step=0.100000
2017/08/26 12:55:07 step 4: mse=0.741467 step=0.100000
2017/08/26 12:55:08 step 5: mse=0.722156 step=0.100000
2017/08/26 12:55:09 step 6: mse=0.705285 step=0.100000
2017/08/26 12:55:09 step 7: mse=0.690334 step=0.100000
2017/08/26 12:55:09 Saving...
2017/08/26 12:55:10 Gathering batch of experience...
2017/08/26 12:55:26 batch 159: mean=15.688889 stddev=5.299150 entropy=1.079686 frames=36164 count=45
2017/08/26 12:55:26 Training policy...
2017/08/26 12:55:30 step 0: objective=0.029294036
2017/08/26 12:55:33 step 1: objective=0.029353192
2017/08/26 12:55:36 step 2: objective=0.029413272
2017/08/26 12:55:39 step 3: objective=0.02947301
2017/08/26 12:55:42 step 4: objective=0.029521437
2017/08/26 12:55:44 step 5: objective=0.029554727
2017/08/26 12:55:47 step 6: objective=0.029584229
2017/08/26 12:55:50 step 7: objective=0.029605754
2017/08/26 12:55:50 Training value function...
2017/08/26 12:55:51 step 0: mse=0.735428 step=0.100000
2017/08/26 12:55:52 step 1: mse=0.696945 step=0.100000
2017/08/26 12:55:53 step 2: mse=0.663594 step=0.100000
2017/08/26 12:55:53 step 3: mse=0.634063 step=0.100000
2017/08/26 12:55:54 step 4: mse=0.613822 step=0.100000
2017/08/26 12:55:55 step 5: mse=0.584834 step=0.100000
2017/08/26 12:55:56 step 6: mse=0.561220 step=0.100000
2017/08/26 12:55:56 step 7: mse=0.540681 step=0.100000
2017/08/26 12:55:56 Saving...
2017/08/26 12:55:56 Gathering batch of experience...
2017/08/26 12:56:13 batch 160: mean=16.023256 stddev=6.496827 entropy=1.078227 frames=36521 count=43
2017/08/26 12:56:13 Training policy...
2017/08/26 12:56:18 step 0: objective=0.017801747
2017/08/26 12:56:20 step 1: objective=0.017831566
2017/08/26 12:56:23 step 2: objective=0.017861405
2017/08/26 12:56:26 step 3: objective=0.01789126
2017/08/26 12:56:29 step 4: objective=0.017921071
2017/08/26 12:56:32 step 5: objective=0.017946048
2017/08/26 12:56:35 step 6: objective=0.017988853
2017/08/26 12:56:38 step 7: objective=0.018023543
2017/08/26 12:56:38 Training value function...
2017/08/26 12:56:39 step 0: mse=0.791169 step=0.100000
2017/08/26 12:56:40 step 1: mse=0.738003 step=0.100000
2017/08/26 12:56:40 step 2: mse=0.698791 step=0.100000
2017/08/26 12:56:41 step 3: mse=0.657473 step=0.100000
2017/08/26 12:56:42 step 4: mse=0.626270 step=0.100000
2017/08/26 12:56:43 step 5: mse=0.597577 step=0.100000
2017/08/26 12:56:43 step 6: mse=0.574975 step=0.100000
2017/08/26 12:56:44 step 7: mse=0.553572 step=0.100000
2017/08/26 12:56:44 Saving...
2017/08/26 12:56:44 Gathering batch of experience...
2017/08/26 12:57:01 batch 161: mean=14.914894 stddev=6.597323 entropy=1.078824 frames=36617 count=47
2017/08/26 12:57:01 Training policy...
2017/08/26 12:57:05 step 0: objective=0.033504527
2017/08/26 12:57:08 step 1: objective=0.03357322
2017/08/26 12:57:11 step 2: objective=0.033641044
2017/08/26 12:57:14 step 3: objective=0.033707518
2017/08/26 12:57:17 step 4: objective=0.033768065
2017/08/26 12:57:20 step 5: objective=0.033805087
2017/08/26 12:57:22 step 6: objective=0.033832356
2017/08/26 12:57:25 step 7: objective=0.033859376
2017/08/26 12:57:25 Training value function...
2017/08/26 12:57:27 step 0: mse=0.969532 step=0.100000
2017/08/26 12:57:27 step 1: mse=0.902052 step=0.100000
2017/08/26 12:57:28 step 2: mse=0.845101 step=0.100000
2017/08/26 12:57:29 step 3: mse=0.798751 step=0.100000
2017/08/26 12:57:30 step 4: mse=0.762756 step=0.100000
2017/08/26 12:57:30 step 5: mse=0.724763 step=0.100000
2017/08/26 12:57:31 step 6: mse=0.698899 step=0.100000
2017/08/26 12:57:32 step 7: mse=0.677603 step=0.100000
2017/08/26 12:57:32 Saving...
2017/08/26 12:57:32 Gathering batch of experience...
2017/08/26 12:57:48 batch 162: mean=14.695652 stddev=7.252794 entropy=1.082506 frames=36000 count=46
2017/08/26 12:57:48 Training policy...
2017/08/26 12:57:53 step 0: objective=0.027243674
2017/08/26 12:57:56 step 1: objective=0.027290903
2017/08/26 12:57:58 step 2: objective=0.027338343
2017/08/26 12:58:01 step 3: objective=0.027393552
2017/08/26 12:58:04 step 4: objective=0.027447825
2017/08/26 12:58:07 step 5: objective=0.027502473
2017/08/26 12:58:10 step 6: objective=0.027549444
2017/08/26 12:58:13 step 7: objective=0.02759447
2017/08/26 12:58:13 Training value function...
2017/08/26 12:58:14 step 0: mse=0.945824 step=0.100000
2017/08/26 12:58:15 step 1: mse=0.903469 step=0.100000
2017/08/26 12:58:15 step 2: mse=0.874821 step=0.100000
2017/08/26 12:58:16 step 3: mse=0.839337 step=0.100000
2017/08/26 12:58:17 step 4: mse=0.814601 step=0.100000
2017/08/26 12:58:18 step 5: mse=0.794096 step=0.100000
2017/08/26 12:58:18 step 6: mse=0.777232 step=0.100000
2017/08/26 12:58:19 step 7: mse=0.762123 step=0.100000
2017/08/26 12:58:19 Saving...
2017/08/26 12:58:19 Gathering batch of experience...
2017/08/26 12:58:35 batch 163: mean=15.043478 stddev=6.849172 entropy=1.080806 frames=35732 count=46
2017/08/26 12:58:35 Training policy...
2017/08/26 12:58:40 step 0: objective=0.03585717
2017/08/26 12:58:42 step 1: objective=0.03590907
2017/08/26 12:58:45 step 2: objective=0.0359615
2017/08/26 12:58:48 step 3: objective=0.036013607
2017/08/26 12:58:51 step 4: objective=0.036046736
2017/08/26 12:58:54 step 5: objective=0.03609817
2017/08/26 12:58:56 step 6: objective=0.03615705
2017/08/26 12:58:59 step 7: objective=0.03621152
2017/08/26 12:58:59 Training value function...
2017/08/26 12:59:00 step 0: mse=0.966913 step=0.100000
2017/08/26 12:59:01 step 1: mse=0.901364 step=0.100000
2017/08/26 12:59:02 step 2: mse=0.850722 step=0.100000
2017/08/26 12:59:03 step 3: mse=0.806257 step=0.100000
2017/08/26 12:59:03 step 4: mse=0.767449 step=0.100000
2017/08/26 12:59:04 step 5: mse=0.736266 step=0.100000
2017/08/26 12:59:05 step 6: mse=0.713704 step=0.100000
2017/08/26 12:59:05 step 7: mse=0.694865 step=0.100000
2017/08/26 12:59:05 Saving...
2017/08/26 12:59:06 Gathering batch of experience...
2017/08/26 12:59:22 batch 164: mean=15.260870 stddev=6.336351 entropy=1.082392 frames=36302 count=46
2017/08/26 12:59:22 Training policy...
2017/08/26 12:59:26 step 0: objective=0.033534955
2017/08/26 12:59:29 step 1: objective=0.03357309
2017/08/26 12:59:32 step 2: objective=0.033611417
2017/08/26 12:59:35 step 3: objective=0.033649802
2017/08/26 12:59:38 step 4: objective=0.03368832
2017/08/26 12:59:41 step 5: objective=0.033723596
2017/08/26 12:59:44 step 6: objective=0.033749063
2017/08/26 12:59:47 step 7: objective=0.03376663
2017/08/26 12:59:47 Training value function...
2017/08/26 12:59:48 step 0: mse=0.864820 step=0.100000
2017/08/26 12:59:49 step 1: mse=0.825821 step=0.100000
2017/08/26 12:59:49 step 2: mse=0.797400 step=0.100000
2017/08/26 12:59:50 step 3: mse=0.781285 step=0.100000
2017/08/26 12:59:51 step 4: mse=0.754306 step=0.100000
2017/08/26 12:59:52 step 5: mse=0.729220 step=0.100000
2017/08/26 12:59:52 step 6: mse=0.707617 step=0.100000
2017/08/26 12:59:53 step 7: mse=0.691649 step=0.100000
2017/08/26 12:59:53 Saving...
2017/08/26 12:59:53 Gathering batch of experience...
2017/08/26 13:00:09 batch 165: mean=14.500000 stddev=6.619306 entropy=1.083956 frames=35755 count=46
2017/08/26 13:00:09 Training policy...
2017/08/26 13:00:14 step 0: objective=0.020145768
2017/08/26 13:00:17 step 1: objective=0.02019945
2017/08/26 13:00:19 step 2: objective=0.020247152
2017/08/26 13:00:22 step 3: objective=0.020294426
2017/08/26 13:00:25 step 4: objective=0.020347549
2017/08/26 13:00:28 step 5: objective=0.020394234
2017/08/26 13:00:31 step 6: objective=0.02043972
2017/08/26 13:00:33 step 7: objective=0.020481316
2017/08/26 13:00:33 Training value function...
2017/08/26 13:00:35 step 0: mse=0.671903 step=0.100000
2017/08/26 13:00:35 step 1: mse=0.643166 step=0.100000
2017/08/26 13:00:36 step 2: mse=0.623578 step=0.100000
2017/08/26 13:00:37 step 3: mse=0.599975 step=0.100000
2017/08/26 13:00:38 step 4: mse=0.581731 step=0.100000
2017/08/26 13:00:38 step 5: mse=0.563186 step=0.100000
2017/08/26 13:00:39 step 6: mse=0.550544 step=0.100000
2017/08/26 13:00:40 step 7: mse=0.539449 step=0.100000
2017/08/26 13:00:40 Saving...
2017/08/26 13:00:40 Gathering batch of experience...
2017/08/26 13:00:56 batch 166: mean=16.386364 stddev=7.274538 entropy=1.078778 frames=36331 count=44
2017/08/26 13:00:56 Training policy...
2017/08/26 13:01:01 step 0: objective=0.04609213
2017/08/26 13:01:04 step 1: objective=0.04613126
2017/08/26 13:01:07 step 2: objective=0.0461697
2017/08/26 13:01:10 step 3: objective=0.046207953
2017/08/26 13:01:12 step 4: objective=0.046245996
2017/08/26 13:01:15 step 5: objective=0.046282917
2017/08/26 13:01:18 step 6: objective=0.046323393
2017/08/26 13:01:21 step 7: objective=0.046356443
2017/08/26 13:01:21 Training value function...
2017/08/26 13:01:22 step 0: mse=0.960363 step=0.100000
2017/08/26 13:01:23 step 1: mse=0.899117 step=0.100000
2017/08/26 13:01:24 step 2: mse=0.849573 step=0.100000
2017/08/26 13:01:25 step 3: mse=0.807831 step=0.100000
2017/08/26 13:01:25 step 4: mse=0.773607 step=0.100000
2017/08/26 13:01:26 step 5: mse=0.740705 step=0.100000
2017/08/26 13:01:27 step 6: mse=0.714211 step=0.100000
2017/08/26 13:01:28 step 7: mse=0.690831 step=0.100000
2017/08/26 13:01:28 Saving...
2017/08/26 13:01:28 Gathering batch of experience...
2017/08/26 13:01:44 batch 167: mean=15.479167 stddev=7.452599 entropy=1.082264 frames=36718 count=48
2017/08/26 13:01:44 Training policy...
2017/08/26 13:01:49 step 0: objective=0.04208671
2017/08/26 13:01:52 step 1: objective=0.042154264
2017/08/26 13:01:55 step 2: objective=0.042221725
2017/08/26 13:01:58 step 3: objective=0.04228913
2017/08/26 13:02:01 step 4: objective=0.04235046
2017/08/26 13:02:03 step 5: objective=0.0424317
2017/08/26 13:02:06 step 6: objective=0.0424987
2017/08/26 13:02:09 step 7: objective=0.042567503
2017/08/26 13:02:09 Training value function...
2017/08/26 13:02:11 step 0: mse=1.142008 step=0.100000
2017/08/26 13:02:11 step 1: mse=1.065778 step=0.100000
2017/08/26 13:02:12 step 2: mse=1.003508 step=0.100000
2017/08/26 13:02:13 step 3: mse=0.950851 step=0.100000
2017/08/26 13:02:14 step 4: mse=0.907729 step=0.100000
2017/08/26 13:02:14 step 5: mse=0.872286 step=0.100000
2017/08/26 13:02:15 step 6: mse=0.843193 step=0.100000
2017/08/26 13:02:16 step 7: mse=0.815609 step=0.100000
2017/08/26 13:02:16 Saving...
2017/08/26 13:02:16 Gathering batch of experience...
2017/08/26 13:02:32 batch 168: mean=13.829787 stddev=5.455113 entropy=1.079587 frames=35874 count=47
2017/08/26 13:02:32 Training policy...
2017/08/26 13:02:37 step 0: objective=0.007887231
2017/08/26 13:02:40 step 1: objective=0.007919113
2017/08/26 13:02:42 step 2: objective=0.007950927
2017/08/26 13:02:45 step 3: objective=0.007982631
2017/08/26 13:02:48 step 4: objective=0.00801432
2017/08/26 13:02:51 step 5: objective=0.008045859
2017/08/26 13:02:54 step 6: objective=0.008079971
2017/08/26 13:02:57 step 7: objective=0.008110997
2017/08/26 13:02:57 Training value function...
2017/08/26 13:02:58 step 0: mse=0.596920 step=0.100000
2017/08/26 13:02:59 step 1: mse=0.563127 step=0.100000
2017/08/26 13:02:59 step 2: mse=0.536107 step=0.100000
2017/08/26 13:03:00 step 3: mse=0.512061 step=0.100000
2017/08/26 13:03:01 step 4: mse=0.495992 step=0.100000
2017/08/26 13:03:01 step 5: mse=0.473764 step=0.100000
2017/08/26 13:03:02 step 6: mse=0.462886 step=0.100000
2017/08/26 13:03:03 step 7: mse=0.441554 step=0.100000
2017/08/26 13:03:03 Saving...
2017/08/26 13:03:03 Gathering batch of experience...
2017/08/26 13:03:20 batch 169: mean=16.822222 stddev=6.815958 entropy=1.069569 frames=36992 count=45
2017/08/26 13:03:20 Training policy...
2017/08/26 13:03:24 step 0: objective=0.047205396
2017/08/26 13:03:27 step 1: objective=0.047289927
2017/08/26 13:03:30 step 2: objective=0.047373556
2017/08/26 13:03:33 step 3: objective=0.047450095
2017/08/26 13:03:36 step 4: objective=0.047549307
2017/08/26 13:03:39 step 5: objective=0.047644574
2017/08/26 13:03:42 step 6: objective=0.047706164
2017/08/26 13:03:45 step 7: objective=0.04778168
2017/08/26 13:03:45 Training value function...
2017/08/26 13:03:46 step 0: mse=1.123379 step=0.100000
2017/08/26 13:03:47 step 1: mse=1.064900 step=0.100000
2017/08/26 13:03:48 step 2: mse=1.017437 step=0.100000
2017/08/26 13:03:48 step 3: mse=0.972625 step=0.100000
2017/08/26 13:03:49 step 4: mse=0.936028 step=0.100000
2017/08/26 13:03:50 step 5: mse=0.904873 step=0.100000
2017/08/26 13:03:51 step 6: mse=0.880038 step=0.100000
2017/08/26 13:03:51 step 7: mse=0.858405 step=0.100000
2017/08/26 13:03:51 Saving...
2017/08/26 13:03:52 Gathering batch of experience...
2017/08/26 13:04:08 batch 170: mean=16.200000 stddev=5.994813 entropy=1.077621 frames=36455 count=45
2017/08/26 13:04:08 Training policy...
2017/08/26 13:04:13 step 0: objective=0.02818622
2017/08/26 13:04:15 step 1: objective=0.028221766
2017/08/26 13:04:18 step 2: objective=0.028257012
2017/08/26 13:04:21 step 3: objective=0.028292164
2017/08/26 13:04:24 step 4: objective=0.0283271
2017/08/26 13:04:27 step 5: objective=0.028356591
2017/08/26 13:04:30 step 6: objective=0.028395878
2017/08/26 13:04:33 step 7: objective=0.028434651
2017/08/26 13:04:33 Training value function...
2017/08/26 13:04:34 step 0: mse=1.058585 step=0.100000
2017/08/26 13:04:35 step 1: mse=0.995316 step=0.100000
2017/08/26 13:04:36 step 2: mse=0.919538 step=0.100000
2017/08/26 13:04:36 step 3: mse=0.858549 step=0.100000
2017/08/26 13:04:37 step 4: mse=0.807615 step=0.100000
2017/08/26 13:04:38 step 5: mse=0.766448 step=0.100000
2017/08/26 13:04:39 step 6: mse=0.732619 step=0.100000
2017/08/26 13:04:39 step 7: mse=0.702167 step=0.100000
2017/08/26 13:04:39 Saving...
2017/08/26 13:04:39 Gathering batch of experience...
2017/08/26 13:04:56 batch 171: mean=17.204545 stddev=6.740581 entropy=1.079374 frames=36486 count=44
2017/08/26 13:04:56 Training policy...
2017/08/26 13:05:01 step 0: objective=0.046146996
2017/08/26 13:05:04 step 1: objective=0.04619093
2017/08/26 13:05:06 step 2: objective=0.04623479
2017/08/26 13:05:09 step 3: objective=0.046278857
2017/08/26 13:05:12 step 4: objective=0.046321213
2017/08/26 13:05:15 step 5: objective=0.04635634
2017/08/26 13:05:18 step 6: objective=0.046391454
2017/08/26 13:05:21 step 7: objective=0.04646671
2017/08/26 13:05:21 Training value function...
2017/08/26 13:05:22 step 0: mse=1.369355 step=0.100000
2017/08/26 13:05:23 step 1: mse=1.296649 step=0.100000
2017/08/26 13:05:24 step 2: mse=1.228950 step=0.100000
2017/08/26 13:05:25 step 3: mse=1.177003 step=0.100000
2017/08/26 13:05:25 step 4: mse=1.125966 step=0.100000
2017/08/26 13:05:26 step 5: mse=1.067598 step=0.100000
2017/08/26 13:05:27 step 6: mse=1.020086 step=0.100000
2017/08/26 13:05:28 step 7: mse=0.976111 step=0.100000
2017/08/26 13:05:28 Saving...
2017/08/26 13:05:28 Gathering batch of experience...
2017/08/26 13:05:44 batch 172: mean=16.600000 stddev=6.584156 entropy=1.068682 frames=36815 count=45
2017/08/26 13:05:44 Training policy...
2017/08/26 13:05:49 step 0: objective=0.028177628
2017/08/26 13:05:52 step 1: objective=0.028228201
2017/08/26 13:05:55 step 2: objective=0.028278695
2017/08/26 13:05:58 step 3: objective=0.028329033
2017/08/26 13:06:01 step 4: objective=0.028378922
2017/08/26 13:06:04 step 5: objective=0.028421361
2017/08/26 13:06:07 step 6: objective=0.02845862
2017/08/26 13:06:10 step 7: objective=0.028495548
2017/08/26 13:06:10 Training value function...
2017/08/26 13:06:11 step 0: mse=1.005918 step=0.100000
2017/08/26 13:06:12 step 1: mse=0.947178 step=0.100000
2017/08/26 13:06:13 step 2: mse=0.899843 step=0.100000
2017/08/26 13:06:13 step 3: mse=0.851538 step=0.100000
2017/08/26 13:06:14 step 4: mse=0.818615 step=0.100000
2017/08/26 13:06:15 step 5: mse=0.783109 step=0.100000
2017/08/26 13:06:16 step 6: mse=0.754230 step=0.100000
2017/08/26 13:06:16 step 7: mse=0.729960 step=0.100000
2017/08/26 13:06:16 Saving...
2017/08/26 13:06:16 Gathering batch of experience...
2017/08/26 13:06:33 batch 173: mean=16.045455 stddev=6.108692 entropy=1.065410 frames=36989 count=44
2017/08/26 13:06:33 Training policy...
2017/08/26 13:06:38 step 0: objective=0.0051674168
2017/08/26 13:06:41 step 1: objective=0.0052253804
2017/08/26 13:06:44 step 2: objective=0.005282851
2017/08/26 13:06:47 step 3: objective=0.0053386125
2017/08/26 13:06:50 step 4: objective=0.00538458
2017/08/26 13:06:53 step 5: objective=0.005433345
2017/08/26 13:06:56 step 6: objective=0.0054821004
2017/08/26 13:06:59 step 7: objective=0.0055296146
2017/08/26 13:06:59 Training value function...
2017/08/26 13:07:00 step 0: mse=0.723176 step=0.100000
2017/08/26 13:07:01 step 1: mse=0.678904 step=0.100000
2017/08/26 13:07:02 step 2: mse=0.650191 step=0.100000
2017/08/26 13:07:03 step 3: mse=0.616550 step=0.100000
2017/08/26 13:07:03 step 4: mse=0.597127 step=0.100000
2017/08/26 13:07:04 step 5: mse=0.570323 step=0.100000
2017/08/26 13:07:05 step 6: mse=0.556916 step=0.100000
2017/08/26 13:07:06 step 7: mse=0.538598 step=0.100000
2017/08/26 13:07:06 Saving...
2017/08/26 13:07:06 Gathering batch of experience...
2017/08/26 13:07:22 batch 174: mean=16.130435 stddev=7.674375 entropy=1.074381 frames=36276 count=46
2017/08/26 13:07:22 Training policy...
2017/08/26 13:07:27 step 0: objective=0.03516578
2017/08/26 13:07:30 step 1: objective=0.03524392
2017/08/26 13:07:33 step 2: objective=0.035321698
2017/08/26 13:07:36 step 3: objective=0.035398196
2017/08/26 13:07:39 step 4: objective=0.035463214
2017/08/26 13:07:41 step 5: objective=0.03553511
2017/08/26 13:07:44 step 6: objective=0.03556848
2017/08/26 13:07:47 step 7: objective=0.03565301
2017/08/26 13:07:47 Training value function...
2017/08/26 13:07:49 step 0: mse=1.282418 step=0.100000
2017/08/26 13:07:49 step 1: mse=1.205364 step=0.100000
2017/08/26 13:07:50 step 2: mse=1.143095 step=0.100000
2017/08/26 13:07:51 step 3: mse=1.087775 step=0.100000
2017/08/26 13:07:52 step 4: mse=1.042300 step=0.100000
2017/08/26 13:07:52 step 5: mse=0.990698 step=0.100000
2017/08/26 13:07:53 step 6: mse=0.959138 step=0.100000
2017/08/26 13:07:54 step 7: mse=0.924127 step=0.100000
2017/08/26 13:07:54 Saving...
2017/08/26 13:07:54 Gathering batch of experience...
2017/08/26 13:08:11 batch 175: mean=14.958333 stddev=7.918750 entropy=1.076241 frames=36865 count=48
2017/08/26 13:08:11 Training policy...
2017/08/26 13:08:15 step 0: objective=0.04159608
2017/08/26 13:08:18 step 1: objective=0.041647173
2017/08/26 13:08:21 step 2: objective=0.041698553
2017/08/26 13:08:24 step 3: objective=0.04174944
2017/08/26 13:08:27 step 4: objective=0.041800767
2017/08/26 13:08:30 step 5: objective=0.04184625
2017/08/26 13:08:33 step 6: objective=0.04188497
2017/08/26 13:08:36 step 7: objective=0.04193108
2017/08/26 13:08:36 Training value function...
2017/08/26 13:08:37 step 0: mse=1.075202 step=0.100000
2017/08/26 13:08:38 step 1: mse=0.977187 step=0.100000
2017/08/26 13:08:39 step 2: mse=0.896457 step=0.100000
2017/08/26 13:08:40 step 3: mse=0.831810 step=0.100000
2017/08/26 13:08:40 step 4: mse=0.775775 step=0.100000
2017/08/26 13:08:41 step 5: mse=0.729696 step=0.100000
2017/08/26 13:08:42 step 6: mse=0.694942 step=0.100000
2017/08/26 13:08:43 step 7: mse=0.663552 step=0.100000
2017/08/26 13:08:43 Saving...
2017/08/26 13:08:43 Gathering batch of experience...
2017/08/26 13:09:00 batch 176: mean=16.088889 stddev=6.555141 entropy=1.071645 frames=36866 count=45
2017/08/26 13:09:00 Training policy...
2017/08/26 13:09:04 step 0: objective=0.039822765
2017/08/26 13:09:07 step 1: objective=0.03984877
2017/08/26 13:09:10 step 2: objective=0.039875098
2017/08/26 13:09:13 step 3: objective=0.039901268
2017/08/26 13:09:16 step 4: objective=0.03992748
2017/08/26 13:09:19 step 5: objective=0.03995266
2017/08/26 13:09:22 step 6: objective=0.03996994
2017/08/26 13:09:25 step 7: objective=0.039986704
2017/08/26 13:09:25 Training value function...
2017/08/26 13:09:26 step 0: mse=0.876526 step=0.100000
2017/08/26 13:09:27 step 1: mse=0.809240 step=0.100000
2017/08/26 13:09:28 step 2: mse=0.754831 step=0.100000
2017/08/26 13:09:29 step 3: mse=0.712580 step=0.100000
2017/08/26 13:09:29 step 4: mse=0.672222 step=0.100000
2017/08/26 13:09:30 step 5: mse=0.633777 step=0.100000
2017/08/26 13:09:31 step 6: mse=0.610756 step=0.100000
2017/08/26 13:09:32 step 7: mse=0.584666 step=0.100000
2017/08/26 13:09:32 Saving...
2017/08/26 13:09:32 Gathering batch of experience...
2017/08/26 13:09:48 batch 177: mean=14.911111 stddev=5.223120 entropy=1.079832 frames=35820 count=45
2017/08/26 13:09:48 Training policy...
2017/08/26 13:09:52 step 0: objective=0.020533683
2017/08/26 13:09:55 step 1: objective=0.020612204
2017/08/26 13:09:58 step 2: objective=0.020689849
2017/08/26 13:10:01 step 3: objective=0.020764725
2017/08/26 13:10:04 step 4: objective=0.02083109
2017/08/26 13:10:07 step 5: objective=0.020876158
2017/08/26 13:10:10 step 6: objective=0.020930966
2017/08/26 13:10:13 step 7: objective=0.020968126
2017/08/26 13:10:13 Training value function...
2017/08/26 13:10:14 step 0: mse=0.798967 step=0.100000
2017/08/26 13:10:15 step 1: mse=0.754754 step=0.100000
2017/08/26 13:10:16 step 2: mse=0.717076 step=0.100000
2017/08/26 13:10:16 step 3: mse=0.687738 step=0.100000
2017/08/26 13:10:17 step 4: mse=0.664138 step=0.100000
2017/08/26 13:10:18 step 5: mse=0.642680 step=0.100000
2017/08/26 13:10:19 step 6: mse=0.624204 step=0.100000
2017/08/26 13:10:19 step 7: mse=0.608646 step=0.100000
2017/08/26 13:10:19 Saving...
2017/08/26 13:10:19 Gathering batch of experience...
2017/08/26 13:10:36 batch 178: mean=16.204545 stddev=6.764142 entropy=1.071691 frames=36844 count=44
2017/08/26 13:10:36 Training policy...
2017/08/26 13:10:41 step 0: objective=0.031885132
2017/08/26 13:10:44 step 1: objective=0.031931877
2017/08/26 13:10:47 step 2: objective=0.03197846
2017/08/26 13:10:50 step 3: objective=0.032025162
2017/08/26 13:10:53 step 4: objective=0.032068755
2017/08/26 13:10:56 step 5: objective=0.032140844
2017/08/26 13:10:59 step 6: objective=0.03221258
2017/08/26 13:11:02 step 7: objective=0.032282222
2017/08/26 13:11:02 Training value function...
2017/08/26 13:11:03 step 0: mse=0.940668 step=0.100000
2017/08/26 13:11:04 step 1: mse=0.885925 step=0.100000
2017/08/26 13:11:05 step 2: mse=0.837839 step=0.100000
2017/08/26 13:11:05 step 3: mse=0.802534 step=0.100000
2017/08/26 13:11:06 step 4: mse=0.763613 step=0.100000
2017/08/26 13:11:07 step 5: mse=0.730165 step=0.100000
2017/08/26 13:11:08 step 6: mse=0.706846 step=0.100000
2017/08/26 13:11:08 step 7: mse=0.685426 step=0.100000
2017/08/26 13:11:08 Saving...
2017/08/26 13:11:08 Gathering batch of experience...
2017/08/26 13:11:25 batch 179: mean=15.644444 stddev=5.692707 entropy=1.069291 frames=36079 count=45
2017/08/26 13:11:25 Training policy...
2017/08/26 13:11:29 step 0: objective=0.031057784
2017/08/26 13:11:32 step 1: objective=0.031115117
2017/08/26 13:11:35 step 2: objective=0.03117275
2017/08/26 13:11:38 step 3: objective=0.031230694
2017/08/26 13:11:41 step 4: objective=0.031283733
2017/08/26 13:11:44 step 5: objective=0.031335875
2017/08/26 13:11:47 step 6: objective=0.03138295
2017/08/26 13:11:50 step 7: objective=0.03142156
2017/08/26 13:11:50 Training value function...
2017/08/26 13:11:51 step 0: mse=0.777194 step=0.100000
2017/08/26 13:11:52 step 1: mse=0.732498 step=0.100000
2017/08/26 13:11:53 step 2: mse=0.693452 step=0.100000
2017/08/26 13:11:53 step 3: mse=0.662839 step=0.100000
2017/08/26 13:11:54 step 4: mse=0.638268 step=0.100000
2017/08/26 13:11:55 step 5: mse=0.619700 step=0.100000
2017/08/26 13:11:56 step 6: mse=0.602281 step=0.100000
2017/08/26 13:11:56 step 7: mse=0.576536 step=0.100000
2017/08/26 13:11:56 Saving...
2017/08/26 13:11:57 Gathering batch of experience...
2017/08/26 13:12:13 batch 180: mean=14.934783 stddev=6.575323 entropy=1.070812 frames=36290 count=46
2017/08/26 13:12:13 Training policy...
2017/08/26 13:12:18 step 0: objective=0.022505973
2017/08/26 13:12:21 step 1: objective=0.022565506
2017/08/26 13:12:24 step 2: objective=0.022624644
2017/08/26 13:12:27 step 3: objective=0.022683395
2017/08/26 13:12:30 step 4: objective=0.022737505
2017/08/26 13:12:33 step 5: objective=0.022783116
2017/08/26 13:12:36 step 6: objective=0.02282468
2017/08/26 13:12:39 step 7: objective=0.022853121
2017/08/26 13:12:39 Training value function...
2017/08/26 13:12:40 step 0: mse=0.852707 step=0.100000
2017/08/26 13:12:40 step 1: mse=0.798062 step=0.100000
2017/08/26 13:12:41 step 2: mse=0.754337 step=0.100000
2017/08/26 13:12:42 step 3: mse=0.719729 step=0.100000
2017/08/26 13:12:43 step 4: mse=0.691594 step=0.100000
2017/08/26 13:12:44 step 5: mse=0.667927 step=0.100000
2017/08/26 13:12:44 step 6: mse=0.644540 step=0.100000
2017/08/26 13:12:45 step 7: mse=0.619211 step=0.100000
2017/08/26 13:12:45 Saving...
2017/08/26 13:12:45 Gathering batch of experience...
2017/08/26 13:13:02 batch 181: mean=17.047619 stddev=6.417804 entropy=1.071082 frames=36410 count=42
2017/08/26 13:13:02 Training policy...
2017/08/26 13:13:06 step 0: objective=0.04452803
2017/08/26 13:13:09 step 1: objective=0.04457766
2017/08/26 13:13:12 step 2: objective=0.0446275
2017/08/26 13:13:15 step 3: objective=0.044677097
2017/08/26 13:13:18 step 4: objective=0.044726696
2017/08/26 13:13:21 step 5: objective=0.04477203
2017/08/26 13:13:24 step 6: objective=0.044812474
2017/08/26 13:13:27 step 7: objective=0.04484659
2017/08/26 13:13:27 Training value function...
2017/08/26 13:13:28 step 0: mse=1.018042 step=0.100000
2017/08/26 13:13:29 step 1: mse=0.959291 step=0.100000
2017/08/26 13:13:30 step 2: mse=0.905198 step=0.100000
2017/08/26 13:13:31 step 3: mse=0.860559 step=0.100000
2017/08/26 13:13:31 step 4: mse=0.822506 step=0.100000
2017/08/26 13:13:32 step 5: mse=0.791919 step=0.100000
2017/08/26 13:13:33 step 6: mse=0.764176 step=0.100000
2017/08/26 13:13:34 step 7: mse=0.737949 step=0.100000
2017/08/26 13:13:34 Saving...
2017/08/26 13:13:34 Gathering batch of experience...
2017/08/26 13:13:51 batch 182: mean=15.555556 stddev=5.878607 entropy=1.068117 frames=36257 count=45
2017/08/26 13:13:51 Training policy...
2017/08/26 13:13:55 step 0: objective=0.021492591
2017/08/26 13:13:58 step 1: objective=0.021561775
2017/08/26 13:14:01 step 2: objective=0.02163121
2017/08/26 13:14:04 step 3: objective=0.02170124
2017/08/26 13:14:07 step 4: objective=0.021759968
2017/08/26 13:14:10 step 5: objective=0.021813078
2017/08/26 13:14:13 step 6: objective=0.021853639
2017/08/26 13:14:16 step 7: objective=0.021894008
2017/08/26 13:14:16 Training value function...
2017/08/26 13:14:17 step 0: mse=0.704604 step=0.100000
2017/08/26 13:14:18 step 1: mse=0.667896 step=0.100000
2017/08/26 13:14:19 step 2: mse=0.636824 step=0.100000
2017/08/26 13:14:20 step 3: mse=0.607342 step=0.100000
2017/08/26 13:14:20 step 4: mse=0.588127 step=0.100000
2017/08/26 13:14:21 step 5: mse=0.563976 step=0.100000
2017/08/26 13:14:22 step 6: mse=0.545554 step=0.100000
2017/08/26 13:14:23 step 7: mse=0.527634 step=0.100000
2017/08/26 13:14:23 Saving...
2017/08/26 13:14:23 Gathering batch of experience...
2017/08/26 13:14:39 batch 183: mean=17.113636 stddev=7.052453 entropy=1.074214 frames=36364 count=44
2017/08/26 13:14:39 Training policy...
2017/08/26 13:14:44 step 0: objective=0.043434948
2017/08/26 13:14:47 step 1: objective=0.04350764
2017/08/26 13:14:50 step 2: objective=0.043580454
2017/08/26 13:14:53 step 3: objective=0.043652523
2017/08/26 13:14:56 step 4: objective=0.04372895
2017/08/26 13:14:59 step 5: objective=0.043792143
2017/08/26 13:15:02 step 6: objective=0.04388532
2017/08/26 13:15:05 step 7: objective=0.04392648
2017/08/26 13:15:05 Training value function...
2017/08/26 13:15:06 step 0: mse=1.078034 step=0.100000
2017/08/26 13:15:07 step 1: mse=1.039951 step=0.100000
2017/08/26 13:15:08 step 2: mse=1.009338 step=0.100000
2017/08/26 13:15:08 step 3: mse=0.972398 step=0.100000
2017/08/26 13:15:09 step 4: mse=0.940260 step=0.100000
2017/08/26 13:15:10 step 5: mse=0.920114 step=0.100000
2017/08/26 13:15:11 step 6: mse=0.896571 step=0.100000
2017/08/26 13:15:11 step 7: mse=0.881378 step=0.100000
2017/08/26 13:15:11 Saving...
2017/08/26 13:15:12 Gathering batch of experience...
2017/08/26 13:15:28 batch 184: mean=16.409091 stddev=8.470049 entropy=1.061074 frames=36153 count=44
2017/08/26 13:15:28 Training policy...
2017/08/26 13:15:33 step 0: objective=0.04187692
2017/08/26 13:15:36 step 1: objective=0.041912694
2017/08/26 13:15:39 step 2: objective=0.04194901
2017/08/26 13:15:42 step 3: objective=0.04198447
2017/08/26 13:15:45 step 4: objective=0.042020388
2017/08/26 13:15:48 step 5: objective=0.042053495
2017/08/26 13:15:51 step 6: objective=0.04208129
2017/08/26 13:15:54 step 7: objective=0.042157132
2017/08/26 13:15:54 Training value function...
2017/08/26 13:15:55 step 0: mse=1.257212 step=0.100000
2017/08/26 13:15:56 step 1: mse=1.133669 step=0.100000
2017/08/26 13:15:56 step 2: mse=1.035157 step=0.100000
2017/08/26 13:15:57 step 3: mse=0.951479 step=0.100000
2017/08/26 13:15:58 step 4: mse=0.884582 step=0.100000
2017/08/26 13:15:59 step 5: mse=0.826068 step=0.100000
2017/08/26 13:15:59 step 6: mse=0.771543 step=0.100000
2017/08/26 13:16:00 step 7: mse=0.733371 step=0.100000
2017/08/26 13:16:00 Saving...
2017/08/26 13:16:00 Gathering batch of experience...
2017/08/26 13:16:17 batch 185: mean=14.914894 stddev=8.310029 entropy=1.071522 frames=36546 count=47
2017/08/26 13:16:17 Training policy...
2017/08/26 13:16:22 step 0: objective=0.026460188
2017/08/26 13:16:25 step 1: objective=0.026507847
2017/08/26 13:16:28 step 2: objective=0.026555268
2017/08/26 13:16:31 step 3: objective=0.026602304
2017/08/26 13:16:34 step 4: objective=0.026648758
2017/08/26 13:16:37 step 5: objective=0.026684202
2017/08/26 13:16:40 step 6: objective=0.02671679
2017/08/26 13:16:43 step 7: objective=0.026736714
2017/08/26 13:16:43 Training value function...
2017/08/26 13:16:44 step 0: mse=1.174747 step=0.100000
2017/08/26 13:16:45 step 1: mse=1.072505 step=0.100000
2017/08/26 13:16:46 step 2: mse=0.990402 step=0.100000
2017/08/26 13:16:46 step 3: mse=0.923787 step=0.100000
2017/08/26 13:16:47 step 4: mse=0.871040 step=0.100000
2017/08/26 13:16:48 step 5: mse=0.826228 step=0.100000
2017/08/26 13:16:49 step 6: mse=0.779078 step=0.100000
2017/08/26 13:16:49 step 7: mse=0.745992 step=0.100000
2017/08/26 13:16:49 Saving...
2017/08/26 13:16:50 Gathering batch of experience...
2017/08/26 13:17:06 batch 186: mean=16.111111 stddev=8.257582 entropy=1.068370 frames=36175 count=45
2017/08/26 13:17:06 Training policy...
2017/08/26 13:17:11 step 0: objective=0.017846933
2017/08/26 13:17:14 step 1: objective=0.017927544
2017/08/26 13:17:17 step 2: objective=0.018006757
2017/08/26 13:17:20 step 3: objective=0.018074414
2017/08/26 13:17:23 step 4: objective=0.018172588
2017/08/26 13:17:26 step 5: objective=0.018268121
2017/08/26 13:17:29 step 6: objective=0.018326793
2017/08/26 13:17:32 step 7: objective=0.018389648
2017/08/26 13:17:32 Training value function...
2017/08/26 13:17:33 step 0: mse=1.210251 step=0.100000
2017/08/26 13:17:34 step 1: mse=1.139141 step=0.100000
2017/08/26 13:17:35 step 2: mse=1.082619 step=0.100000
2017/08/26 13:17:35 step 3: mse=1.037674 step=0.100000
2017/08/26 13:17:36 step 4: mse=0.979758 step=0.100000
2017/08/26 13:17:37 step 5: mse=0.944611 step=0.100000
2017/08/26 13:17:38 step 6: mse=0.908795 step=0.100000
2017/08/26 13:17:38 step 7: mse=0.877296 step=0.100000
2017/08/26 13:17:38 Saving...
2017/08/26 13:17:38 Gathering batch of experience...
2017/08/26 13:17:55 batch 187: mean=16.431818 stddev=6.562281 entropy=1.071036 frames=37089 count=44
2017/08/26 13:17:55 Training policy...
2017/08/26 13:18:00 step 0: objective=0.024325743
2017/08/26 13:18:03 step 1: objective=0.0243965
2017/08/26 13:18:06 step 2: objective=0.024467114
2017/08/26 13:18:09 step 3: objective=0.024534263
2017/08/26 13:18:13 step 4: objective=0.024576668
2017/08/26 13:18:16 step 5: objective=0.024594648
2017/08/26 13:18:19 step 6: objective=0.024646452
2017/08/26 13:18:22 step 7: objective=0.024695832
2017/08/26 13:18:22 Training value function...
2017/08/26 13:18:23 step 0: mse=0.766740 step=0.100000
2017/08/26 13:18:24 step 1: mse=0.713993 step=0.100000
2017/08/26 13:18:25 step 2: mse=0.671677 step=0.100000
2017/08/26 13:18:25 step 3: mse=0.637238 step=0.100000
2017/08/26 13:18:26 step 4: mse=0.607011 step=0.100000
2017/08/26 13:18:27 step 5: mse=0.586213 step=0.100000
2017/08/26 13:18:28 step 6: mse=0.575185 step=0.100000
2017/08/26 13:18:28 step 7: mse=0.555028 step=0.100000
2017/08/26 13:18:28 Saving...
2017/08/26 13:18:29 Gathering batch of experience...
2017/08/26 13:18:45 batch 188: mean=17.214286 stddev=9.269858 entropy=1.074820 frames=35830 count=42
2017/08/26 13:18:45 Training policy...
2017/08/26 13:18:49 step 0: objective=0.04376812
2017/08/26 13:18:52 step 1: objective=0.043845873
2017/08/26 13:18:55 step 2: objective=0.043947015
2017/08/26 13:18:58 step 3: objective=0.044037405
2017/08/26 13:19:01 step 4: objective=0.044099506
2017/08/26 13:19:04 step 5: objective=0.044138934
2017/08/26 13:19:07 step 6: objective=0.044207316
2017/08/26 13:19:10 step 7: objective=0.044238497
2017/08/26 13:19:10 Training value function...
2017/08/26 13:19:12 step 0: mse=1.393231 step=0.100000
2017/08/26 13:19:12 step 1: mse=1.277115 step=0.100000
2017/08/26 13:19:13 step 2: mse=1.177434 step=0.100000
2017/08/26 13:19:14 step 3: mse=1.097174 step=0.100000
2017/08/26 13:19:14 step 4: mse=1.027030 step=0.100000
2017/08/26 13:19:15 step 5: mse=0.976192 step=0.100000
2017/08/26 13:19:16 step 6: mse=0.927023 step=0.100000
2017/08/26 13:19:17 step 7: mse=0.889198 step=0.100000
2017/08/26 13:19:17 Saving...
2017/08/26 13:19:17 Gathering batch of experience...
2017/08/26 13:19:34 batch 189: mean=16.465116 stddev=6.905841 entropy=1.076966 frames=36275 count=43
2017/08/26 13:19:34 Training policy...
2017/08/26 13:19:38 step 0: objective=0.029891329
2017/08/26 13:19:41 step 1: objective=0.029935641
2017/08/26 13:19:44 step 2: objective=0.029979698
2017/08/26 13:19:47 step 3: objective=0.030023599
2017/08/26 13:19:50 step 4: objective=0.03006735
2017/08/26 13:19:53 step 5: objective=0.030110097
2017/08/26 13:19:57 step 6: objective=0.030162401
2017/08/26 13:20:00 step 7: objective=0.030203348
2017/08/26 13:20:00 Training value function...
2017/08/26 13:20:01 step 0: mse=0.888015 step=0.100000
2017/08/26 13:20:02 step 1: mse=0.839667 step=0.100000
2017/08/26 13:20:02 step 2: mse=0.802196 step=0.100000
2017/08/26 13:20:03 step 3: mse=0.767180 step=0.100000
2017/08/26 13:20:04 step 4: mse=0.737843 step=0.100000
2017/08/26 13:20:05 step 5: mse=0.710296 step=0.100000
2017/08/26 13:20:05 step 6: mse=0.678996 step=0.100000
2017/08/26 13:20:06 step 7: mse=0.646018 step=0.100000
2017/08/26 13:20:06 Saving...
2017/08/26 13:20:06 Gathering batch of experience...
2017/08/26 13:20:23 batch 190: mean=13.580000 stddev=6.738219 entropy=1.077935 frames=35354 count=50
2017/08/26 13:20:23 Training policy...
2017/08/26 13:20:27 step 0: objective=0.027677627
2017/08/26 13:20:30 step 1: objective=0.027755575
2017/08/26 13:20:33 step 2: objective=0.027834013
2017/08/26 13:20:36 step 3: objective=0.027906101
2017/08/26 13:20:39 step 4: objective=0.027974743
2017/08/26 13:20:42 step 5: objective=0.028032921
2017/08/26 13:20:45 step 6: objective=0.028063798
2017/08/26 13:20:48 step 7: objective=0.028105007
2017/08/26 13:20:48 Training value function...
2017/08/26 13:20:49 step 0: mse=1.103714 step=0.100000
2017/08/26 13:20:50 step 1: mse=1.034010 step=0.100000
2017/08/26 13:20:51 step 2: mse=0.977365 step=0.100000
2017/08/26 13:20:51 step 3: mse=0.931101 step=0.100000
2017/08/26 13:20:52 step 4: mse=0.887163 step=0.100000
2017/08/26 13:20:53 step 5: mse=0.851096 step=0.100000
2017/08/26 13:20:54 step 6: mse=0.822666 step=0.100000
2017/08/26 13:20:54 step 7: mse=0.796393 step=0.100000
2017/08/26 13:20:54 Saving...
2017/08/26 13:20:54 Gathering batch of experience...
2017/08/26 13:21:11 batch 191: mean=15.478261 stddev=8.594081 entropy=1.078868 frames=36169 count=46
2017/08/26 13:21:11 Training policy...
2017/08/26 13:21:16 step 0: objective=0.03198321
2017/08/26 13:21:19 step 1: objective=0.032067038
2017/08/26 13:21:22 step 2: objective=0.032152012
2017/08/26 13:21:25 step 3: objective=0.03222529
2017/08/26 13:21:28 step 4: objective=0.03228593
2017/08/26 13:21:31 step 5: objective=0.032328337
2017/08/26 13:21:34 step 6: objective=0.03237077
2017/08/26 13:21:37 step 7: objective=0.032413963
2017/08/26 13:21:37 Training value function...
2017/08/26 13:21:38 step 0: mse=1.036134 step=0.100000
2017/08/26 13:21:39 step 1: mse=0.972182 step=0.100000
2017/08/26 13:21:40 step 2: mse=0.917807 step=0.100000
2017/08/26 13:21:40 step 3: mse=0.875560 step=0.100000
2017/08/26 13:21:41 step 4: mse=0.841642 step=0.100000
2017/08/26 13:21:42 step 5: mse=0.808680 step=0.100000
2017/08/26 13:21:43 step 6: mse=0.784264 step=0.100000
2017/08/26 13:21:43 step 7: mse=0.760311 step=0.100000
2017/08/26 13:21:43 Saving...
2017/08/26 13:21:43 Gathering batch of experience...
2017/08/26 13:22:00 batch 192: mean=13.978723 stddev=5.008458 entropy=1.072900 frames=36518 count=47
2017/08/26 13:22:00 Training policy...
2017/08/26 13:22:05 step 0: objective=0.010374277
2017/08/26 13:22:08 step 1: objective=0.01042429
2017/08/26 13:22:11 step 2: objective=0.010474583
2017/08/26 13:22:14 step 3: objective=0.010524186
2017/08/26 13:22:17 step 4: objective=0.010566831
2017/08/26 13:22:21 step 5: objective=0.010606526
2017/08/26 13:22:24 step 6: objective=0.010639496
2017/08/26 13:22:27 step 7: objective=0.010670755
2017/08/26 13:22:27 Training value function...
2017/08/26 13:22:28 step 0: mse=0.637609 step=0.100000
2017/08/26 13:22:29 step 1: mse=0.602209 step=0.100000
2017/08/26 13:22:29 step 2: mse=0.573085 step=0.100000
2017/08/26 13:22:30 step 3: mse=0.546091 step=0.100000
2017/08/26 13:22:31 step 4: mse=0.521984 step=0.100000
2017/08/26 13:22:32 step 5: mse=0.507849 step=0.100000
2017/08/26 13:22:32 step 6: mse=0.483363 step=0.100000
2017/08/26 13:22:33 step 7: mse=0.471935 step=0.100000
2017/08/26 13:22:33 Saving...
2017/08/26 13:22:33 Gathering batch of experience...
2017/08/26 13:22:50 batch 193: mean=15.755556 stddev=7.024261 entropy=1.069886 frames=36698 count=45
2017/08/26 13:22:50 Training policy...
2017/08/26 13:22:55 step 0: objective=0.04009384
2017/08/26 13:22:58 step 1: objective=0.040143423
2017/08/26 13:23:01 step 2: objective=0.04019328
2017/08/26 13:23:04 step 3: objective=0.040242907
2017/08/26 13:23:07 step 4: objective=0.040293075
2017/08/26 13:23:10 step 5: objective=0.04034335
2017/08/26 13:23:13 step 6: objective=0.040376615
2017/08/26 13:23:16 step 7: objective=0.040434238
2017/08/26 13:23:16 Training value function...
2017/08/26 13:23:18 step 0: mse=1.003248 step=0.100000
2017/08/26 13:23:18 step 1: mse=0.934221 step=0.100000
2017/08/26 13:23:19 step 2: mse=0.882231 step=0.100000
2017/08/26 13:23:20 step 3: mse=0.833051 step=0.100000
2017/08/26 13:23:21 step 4: mse=0.789325 step=0.100000
2017/08/26 13:23:21 step 5: mse=0.752784 step=0.100000
2017/08/26 13:23:22 step 6: mse=0.715085 step=0.100000
2017/08/26 13:23:23 step 7: mse=0.684562 step=0.100000
2017/08/26 13:23:23 Saving...
2017/08/26 13:23:23 Gathering batch of experience...
2017/08/26 13:23:40 batch 194: mean=17.558140 stddev=8.370219 entropy=1.064596 frames=36663 count=43
2017/08/26 13:23:40 Training policy...
2017/08/26 13:23:45 step 0: objective=0.06933297
2017/08/26 13:23:48 step 1: objective=0.06941936
2017/08/26 13:23:51 step 2: objective=0.06947139
2017/08/26 13:23:54 step 3: objective=0.06952348
2017/08/26 13:23:57 step 4: objective=0.06957529
2017/08/26 13:24:00 step 5: objective=0.069627404
2017/08/26 13:24:03 step 6: objective=0.069706246
2017/08/26 13:24:06 step 7: objective=0.06974849
2017/08/26 13:24:06 Training value function...
2017/08/26 13:24:08 step 0: mse=1.328655 step=0.100000
2017/08/26 13:24:08 step 1: mse=1.211565 step=0.100000
2017/08/26 13:24:09 step 2: mse=1.114781 step=0.100000
2017/08/26 13:24:10 step 3: mse=1.029302 step=0.100000
2017/08/26 13:24:11 step 4: mse=0.963190 step=0.100000
2017/08/26 13:24:11 step 5: mse=0.909889 step=0.100000
2017/08/26 13:24:12 step 6: mse=0.857573 step=0.100000
2017/08/26 13:24:13 step 7: mse=0.802947 step=0.100000
2017/08/26 13:24:13 Saving...
2017/08/26 13:24:13 Gathering batch of experience...
2017/08/26 13:24:30 batch 195: mean=16.466667 stddev=6.017013 entropy=1.061211 frames=37263 count=45
2017/08/26 13:24:30 Training policy...
2017/08/26 13:24:35 step 0: objective=0.04609961
2017/08/26 13:24:38 step 1: objective=0.046155974
2017/08/26 13:24:41 step 2: objective=0.04621263
2017/08/26 13:24:44 step 3: objective=0.04626851
2017/08/26 13:24:48 step 4: objective=0.046323784
2017/08/26 13:24:51 step 5: objective=0.0463775
2017/08/26 13:24:54 step 6: objective=0.046444707
2017/08/26 13:24:57 step 7: objective=0.046516407
2017/08/26 13:24:57 Training value function...
2017/08/26 13:24:58 step 0: mse=0.874943 step=0.100000
2017/08/26 13:24:59 step 1: mse=0.835437 step=0.100000
2017/08/26 13:25:00 step 2: mse=0.803000 step=0.100000
2017/08/26 13:25:01 step 3: mse=0.778014 step=0.100000
2017/08/26 13:25:01 step 4: mse=0.757269 step=0.100000
2017/08/26 13:25:02 step 5: mse=0.736744 step=0.100000
2017/08/26 13:25:03 step 6: mse=0.720929 step=0.100000
2017/08/26 13:25:04 step 7: mse=0.704572 step=0.100000
2017/08/26 13:25:04 Saving...
2017/08/26 13:25:04 Gathering batch of experience...
2017/08/26 13:25:20 batch 196: mean=16.545455 stddev=6.883625 entropy=1.067427 frames=35899 count=44
2017/08/26 13:25:20 Training policy...
2017/08/26 13:25:25 step 0: objective=0.02878059
2017/08/26 13:25:28 step 1: objective=0.028814953
2017/08/26 13:25:31 step 2: objective=0.028849646
2017/08/26 13:25:34 step 3: objective=0.028884375
2017/08/26 13:25:37 step 4: objective=0.02891911
2017/08/26 13:25:40 step 5: objective=0.028950665
2017/08/26 13:25:43 step 6: objective=0.028992405
2017/08/26 13:25:46 step 7: objective=0.029035028
2017/08/26 13:25:46 Training value function...
2017/08/26 13:25:48 step 0: mse=1.054335 step=0.100000
2017/08/26 13:25:48 step 1: mse=0.995623 step=0.100000
2017/08/26 13:25:49 step 2: mse=0.949278 step=0.100000
2017/08/26 13:25:50 step 3: mse=0.909385 step=0.100000
2017/08/26 13:25:50 step 4: mse=0.877235 step=0.100000
2017/08/26 13:25:51 step 5: mse=0.843375 step=0.100000
2017/08/26 13:25:52 step 6: mse=0.809823 step=0.100000
2017/08/26 13:25:53 step 7: mse=0.784377 step=0.100000
2017/08/26 13:25:53 Saving...
2017/08/26 13:25:53 Gathering batch of experience...
2017/08/26 13:26:10 batch 197: mean=15.434783 stddev=6.945916 entropy=1.076228 frames=36386 count=46
2017/08/26 13:26:10 Training policy...
2017/08/26 13:26:14 step 0: objective=0.018750113
2017/08/26 13:26:17 step 1: objective=0.018816683
2017/08/26 13:26:20 step 2: objective=0.018900266
2017/08/26 13:26:24 step 3: objective=0.0189849
2017/08/26 13:26:27 step 4: objective=0.019062636
2017/08/26 13:26:30 step 5: objective=0.019098649
2017/08/26 13:26:33 step 6: objective=0.019159963
2017/08/26 13:26:36 step 7: objective=0.01919456
2017/08/26 13:26:36 Training value function...
2017/08/26 13:26:37 step 0: mse=0.961719 step=0.100000
2017/08/26 13:26:38 step 1: mse=0.896115 step=0.100000
2017/08/26 13:26:39 step 2: mse=0.843675 step=0.100000
2017/08/26 13:26:39 step 3: mse=0.799857 step=0.100000
2017/08/26 13:26:40 step 4: mse=0.760996 step=0.100000
2017/08/26 13:26:41 step 5: mse=0.727244 step=0.100000
2017/08/26 13:26:42 step 6: mse=0.700275 step=0.100000
2017/08/26 13:26:42 step 7: mse=0.674592 step=0.100000
2017/08/26 13:26:42 Saving...
2017/08/26 13:26:43 Gathering batch of experience...
2017/08/26 13:26:59 batch 198: mean=15.043478 stddev=6.057538 entropy=1.083955 frames=36428 count=46
2017/08/26 13:26:59 Training policy...
2017/08/26 13:27:04 step 0: objective=0.022025984
2017/08/26 13:27:07 step 1: objective=0.022060566
2017/08/26 13:27:10 step 2: objective=0.022104636
2017/08/26 13:27:13 step 3: objective=0.022148617
2017/08/26 13:27:16 step 4: objective=0.02219228
2017/08/26 13:27:19 step 5: objective=0.022235826
2017/08/26 13:27:22 step 6: objective=0.022279175
2017/08/26 13:27:25 step 7: objective=0.022321632
2017/08/26 13:27:25 Training value function...
2017/08/26 13:27:27 step 0: mse=0.753671 step=0.100000
2017/08/26 13:27:27 step 1: mse=0.720165 step=0.100000
2017/08/26 13:27:28 step 2: mse=0.692483 step=0.100000
2017/08/26 13:27:29 step 3: mse=0.668929 step=0.100000
2017/08/26 13:27:30 step 4: mse=0.646492 step=0.100000
2017/08/26 13:27:30 step 5: mse=0.630671 step=0.100000
2017/08/26 13:27:31 step 6: mse=0.615782 step=0.100000
2017/08/26 13:27:32 step 7: mse=0.605073 step=0.100000
2017/08/26 13:27:32 Saving...
2017/08/26 13:27:32 Gathering batch of experience...
2017/08/26 13:27:49 batch 199: mean=14.000000 stddev=6.238322 entropy=1.077590 frames=35855 count=48
2017/08/26 13:27:49 Training policy...
2017/08/26 13:27:53 step 0: objective=0.02261069
2017/08/26 13:27:56 step 1: objective=0.022648424
2017/08/26 13:27:59 step 2: objective=0.022691607
2017/08/26 13:28:02 step 3: objective=0.022734996
2017/08/26 13:28:05 step 4: objective=0.022778321
2017/08/26 13:28:09 step 5: objective=0.022843895
2017/08/26 13:28:12 step 6: objective=0.022897573
2017/08/26 13:28:15 step 7: objective=0.022954231
2017/08/26 13:28:15 Training value function...
2017/08/26 13:28:16 step 0: mse=0.788914 step=0.100000
2017/08/26 13:28:17 step 1: mse=0.736121 step=0.100000
2017/08/26 13:28:17 step 2: mse=0.691937 step=0.100000
2017/08/26 13:28:18 step 3: mse=0.653787 step=0.100000
2017/08/26 13:28:19 step 4: mse=0.621162 step=0.100000
2017/08/26 13:28:20 step 5: mse=0.593046 step=0.100000
2017/08/26 13:28:20 step 6: mse=0.569417 step=0.100000
2017/08/26 13:28:21 step 7: mse=0.543353 step=0.100000
2017/08/26 13:28:21 Saving...
2017/08/26 13:28:21 Gathering batch of experience...
2017/08/26 13:28:38 batch 200: mean=17.431818 stddev=10.532197 entropy=1.068211 frames=36549 count=44
2017/08/26 13:28:38 Training policy...
2017/08/26 13:28:43 step 0: objective=0.0681326
2017/08/26 13:28:46 step 1: objective=0.06817163
2017/08/26 13:28:49 step 2: objective=0.06821186
2017/08/26 13:28:52 step 3: objective=0.06825158
2017/08/26 13:28:55 step 4: objective=0.06829222
2017/08/26 13:28:59 step 5: objective=0.068331055
2017/08/26 13:29:02 step 6: objective=0.068360254
2017/08/26 13:29:05 step 7: objective=0.0683892
2017/08/26 13:29:05 Training value function...
2017/08/26 13:29:06 step 0: mse=1.480185 step=0.100000
2017/08/26 13:29:07 step 1: mse=1.343570 step=0.100000
2017/08/26 13:29:08 step 2: mse=1.235033 step=0.100000
2017/08/26 13:29:08 step 3: mse=1.139703 step=0.100000
2017/08/26 13:29:09 step 4: mse=1.063607 step=0.100000
2017/08/26 13:29:10 step 5: mse=0.999026 step=0.100000
2017/08/26 13:29:11 step 6: mse=0.946815 step=0.100000
2017/08/26 13:29:12 step 7: mse=0.903167 step=0.100000
2017/08/26 13:29:12 Saving...
2017/08/26 13:29:12 Gathering batch of experience...
2017/08/26 13:29:28 batch 201: mean=14.680851 stddev=6.770104 entropy=1.075192 frames=35771 count=47
2017/08/26 13:29:28 Training policy...
2017/08/26 13:29:33 step 0: objective=0.03062608
2017/08/26 13:29:36 step 1: objective=0.030731063
2017/08/26 13:29:39 step 2: objective=0.030834092
2017/08/26 13:29:42 step 3: objective=0.03093347
2017/08/26 13:29:45 step 4: objective=0.031017687
2017/08/26 13:29:48 step 5: objective=0.031092012
2017/08/26 13:29:51 step 6: objective=0.031140562
2017/08/26 13:29:54 step 7: objective=0.031200174
2017/08/26 13:29:54 Training value function...
2017/08/26 13:29:56 step 0: mse=1.093069 step=0.100000
2017/08/26 13:29:56 step 1: mse=1.025876 step=0.100000
2017/08/26 13:29:57 step 2: mse=0.969906 step=0.100000
2017/08/26 13:29:58 step 3: mse=0.917537 step=0.100000
2017/08/26 13:29:59 step 4: mse=0.875513 step=0.100000
2017/08/26 13:29:59 step 5: mse=0.840330 step=0.100000
2017/08/26 13:30:00 step 6: mse=0.810675 step=0.100000
2017/08/26 13:30:01 step 7: mse=0.784440 step=0.100000
2017/08/26 13:30:01 Saving...
2017/08/26 13:30:01 Gathering batch of experience...
2017/08/26 13:30:18 batch 202: mean=14.673913 stddev=6.714858 entropy=1.079925 frames=36031 count=46
2017/08/26 13:30:18 Training policy...
2017/08/26 13:30:22 step 0: objective=0.010309595
2017/08/26 13:30:25 step 1: objective=0.010342205
2017/08/26 13:30:28 step 2: objective=0.01037473
2017/08/26 13:30:32 step 3: objective=0.01040702
2017/08/26 13:30:35 step 4: objective=0.010439297
2017/08/26 13:30:38 step 5: objective=0.010470914
2017/08/26 13:30:41 step 6: objective=0.010532633
2017/08/26 13:30:44 step 7: objective=0.0105609
2017/08/26 13:30:44 Training value function...
2017/08/26 13:30:45 step 0: mse=0.863893 step=0.100000
2017/08/26 13:30:46 step 1: mse=0.799372 step=0.100000
2017/08/26 13:30:47 step 2: mse=0.746686 step=0.100000
2017/08/26 13:30:47 step 3: mse=0.704604 step=0.100000
2017/08/26 13:30:48 step 4: mse=0.670136 step=0.100000
2017/08/26 13:30:49 step 5: mse=0.640440 step=0.100000
2017/08/26 13:30:50 step 6: mse=0.617627 step=0.100000
2017/08/26 13:30:50 step 7: mse=0.597960 step=0.100000
2017/08/26 13:30:50 Saving...
2017/08/26 13:30:50 Gathering batch of experience...
2017/08/26 13:31:07 batch 203: mean=15.777778 stddev=6.742531 entropy=1.068787 frames=36524 count=45
2017/08/26 13:31:07 Training policy...
2017/08/26 13:31:12 step 0: objective=0.049627908
2017/08/26 13:31:15 step 1: objective=0.049684037
2017/08/26 13:31:18 step 2: objective=0.049740206
2017/08/26 13:31:22 step 3: objective=0.049777538
2017/08/26 13:31:25 step 4: objective=0.049815428
2017/08/26 13:31:28 step 5: objective=0.049848884
2017/08/26 13:31:31 step 6: objective=0.04989221
2017/08/26 13:31:34 step 7: objective=0.04992312
2017/08/26 13:31:34 Training value function...
2017/08/26 13:31:35 step 0: mse=0.927440 step=0.100000
2017/08/26 13:31:36 step 1: mse=0.875804 step=0.100000
2017/08/26 13:31:37 step 2: mse=0.831668 step=0.100000
2017/08/26 13:31:38 step 3: mse=0.795517 step=0.100000
2017/08/26 13:31:39 step 4: mse=0.757761 step=0.100000
2017/08/26 13:31:39 step 5: mse=0.732470 step=0.100000
2017/08/26 13:31:40 step 6: mse=0.698698 step=0.100000
2017/08/26 13:31:41 step 7: mse=0.679383 step=0.100000
2017/08/26 13:31:41 Saving...
2017/08/26 13:31:41 Gathering batch of experience...
2017/08/26 13:31:58 batch 204: mean=15.977273 stddev=6.039599 entropy=1.074957 frames=36287 count=44
2017/08/26 13:31:58 Training policy...
2017/08/26 13:32:02 step 0: objective=0.02987664
2017/08/26 13:32:06 step 1: objective=0.029960105
2017/08/26 13:32:09 step 2: objective=0.030043554
2017/08/26 13:32:12 step 3: objective=0.030124824
2017/08/26 13:32:15 step 4: objective=0.030176524
2017/08/26 13:32:18 step 5: objective=0.030230634
2017/08/26 13:32:21 step 6: objective=0.030287277
2017/08/26 13:32:24 step 7: objective=0.030321892
2017/08/26 13:32:24 Training value function...
2017/08/26 13:32:26 step 0: mse=0.872084 step=0.100000
2017/08/26 13:32:26 step 1: mse=0.830973 step=0.100000
2017/08/26 13:32:27 step 2: mse=0.795672 step=0.100000
2017/08/26 13:32:28 step 3: mse=0.762562 step=0.100000
2017/08/26 13:32:29 step 4: mse=0.735658 step=0.100000
2017/08/26 13:32:29 step 5: mse=0.710897 step=0.100000
2017/08/26 13:32:30 step 6: mse=0.688389 step=0.100000
2017/08/26 13:32:31 step 7: mse=0.665260 step=0.100000
2017/08/26 13:32:31 Saving...
2017/08/26 13:32:31 Gathering batch of experience...
2017/08/26 13:32:47 batch 205: mean=16.139535 stddev=6.271313 entropy=1.081547 frames=35518 count=43
2017/08/26 13:32:47 Training policy...
2017/08/26 13:32:52 step 0: objective=0.03353553
2017/08/26 13:32:55 step 1: objective=0.03357611
2017/08/26 13:32:58 step 2: objective=0.03361722
2017/08/26 13:33:01 step 3: objective=0.033658564
2017/08/26 13:33:04 step 4: objective=0.033700127
2017/08/26 13:33:07 step 5: objective=0.033741064
2017/08/26 13:33:10 step 6: objective=0.033805966
2017/08/26 13:33:14 step 7: objective=0.033861786
2017/08/26 13:33:14 Training value function...
2017/08/26 13:33:15 step 0: mse=0.969651 step=0.100000
2017/08/26 13:33:15 step 1: mse=0.905091 step=0.100000
2017/08/26 13:33:16 step 2: mse=0.853117 step=0.100000
2017/08/26 13:33:17 step 3: mse=0.810982 step=0.100000
2017/08/26 13:33:18 step 4: mse=0.774618 step=0.100000
2017/08/26 13:33:18 step 5: mse=0.744460 step=0.100000
2017/08/26 13:33:19 step 6: mse=0.716560 step=0.100000
2017/08/26 13:33:20 step 7: mse=0.696157 step=0.100000
2017/08/26 13:33:20 Saving...
2017/08/26 13:33:20 Gathering batch of experience...
2017/08/26 13:33:37 batch 206: mean=15.063830 stddev=6.075428 entropy=1.082642 frames=36497 count=47
2017/08/26 13:33:37 Training policy...
2017/08/26 13:33:42 step 0: objective=0.03092068
2017/08/26 13:33:45 step 1: objective=0.030969841
2017/08/26 13:33:48 step 2: objective=0.031018479
2017/08/26 13:33:51 step 3: objective=0.031065956
2017/08/26 13:33:54 step 4: objective=0.031129297
2017/08/26 13:33:58 step 5: objective=0.031174839
2017/08/26 13:34:01 step 6: objective=0.03121841
2017/08/26 13:34:04 step 7: objective=0.031258814
2017/08/26 13:34:04 Training value function...
2017/08/26 13:34:05 step 0: mse=0.831106 step=0.100000
2017/08/26 13:34:06 step 1: mse=0.796463 step=0.100000
2017/08/26 13:34:07 step 2: mse=0.774971 step=0.100000
2017/08/26 13:34:08 step 3: mse=0.749175 step=0.100000
2017/08/26 13:34:08 step 4: mse=0.733426 step=0.100000
2017/08/26 13:34:09 step 5: mse=0.717502 step=0.100000
2017/08/26 13:34:10 step 6: mse=0.678473 step=0.100000
2017/08/26 13:34:10 step 7: mse=0.659950 step=0.100000
2017/08/26 13:34:10 Saving...
2017/08/26 13:34:11 Gathering batch of experience...
2017/08/26 13:34:28 batch 207: mean=15.978261 stddev=7.487639 entropy=1.078894 frames=37100 count=46
2017/08/26 13:34:28 Training policy...
2017/08/26 13:34:33 step 0: objective=0.04849718
2017/08/26 13:34:36 step 1: objective=0.048573207
2017/08/26 13:34:40 step 2: objective=0.04864867
2017/08/26 13:34:43 step 3: objective=0.048723932
2017/08/26 13:34:46 step 4: objective=0.04879803
2017/08/26 13:34:49 step 5: objective=0.048855413
2017/08/26 13:34:53 step 6: objective=0.048898354
2017/08/26 13:34:56 step 7: objective=0.04893137
2017/08/26 13:34:56 Training value function...
2017/08/26 13:34:57 step 0: mse=1.059689 step=0.100000
2017/08/26 13:34:58 step 1: mse=0.965700 step=0.100000
2017/08/26 13:34:59 step 2: mse=0.887591 step=0.100000
2017/08/26 13:34:59 step 3: mse=0.820940 step=0.100000
2017/08/26 13:35:00 step 4: mse=0.765176 step=0.100000
2017/08/26 13:35:01 step 5: mse=0.719942 step=0.100000
2017/08/26 13:35:02 step 6: mse=0.683174 step=0.100000
2017/08/26 13:35:02 step 7: mse=0.651631 step=0.100000
2017/08/26 13:35:02 Saving...
2017/08/26 13:35:02 Gathering batch of experience...
2017/08/26 13:35:19 batch 208: mean=16.409091 stddev=6.935804 entropy=1.065439 frames=36463 count=44
2017/08/26 13:35:19 Training policy...
2017/08/26 13:35:24 step 0: objective=0.028022636
2017/08/26 13:35:27 step 1: objective=0.028113462
2017/08/26 13:35:31 step 2: objective=0.028205045
2017/08/26 13:35:34 step 3: objective=0.028289098
2017/08/26 13:35:37 step 4: objective=0.028342057
2017/08/26 13:35:40 step 5: objective=0.028405918
2017/08/26 13:35:43 step 6: objective=0.028444445
2017/08/26 13:35:47 step 7: objective=0.028480595
2017/08/26 13:35:47 Training value function...
2017/08/26 13:35:48 step 0: mse=0.817624 step=0.100000
2017/08/26 13:35:49 step 1: mse=0.783505 step=0.100000
2017/08/26 13:35:49 step 2: mse=0.756417 step=0.100000
2017/08/26 13:35:50 step 3: mse=0.733787 step=0.100000
2017/08/26 13:35:51 step 4: mse=0.715623 step=0.100000
2017/08/26 13:35:52 step 5: mse=0.691946 step=0.100000
2017/08/26 13:35:52 step 6: mse=0.677053 step=0.100000
2017/08/26 13:35:53 step 7: mse=0.660179 step=0.100000
2017/08/26 13:35:53 Saving...
2017/08/26 13:35:53 Gathering batch of experience...
2017/08/26 13:36:10 batch 209: mean=15.804348 stddev=7.376872 entropy=1.071049 frames=36267 count=46
2017/08/26 13:36:10 Training policy...
2017/08/26 13:36:15 step 0: objective=0.03424862
2017/08/26 13:36:18 step 1: objective=0.034315627
2017/08/26 13:36:21 step 2: objective=0.0343828
2017/08/26 13:36:24 step 3: objective=0.03445001
2017/08/26 13:36:27 step 4: objective=0.034516055
2017/08/26 13:36:31 step 5: objective=0.034562234
2017/08/26 13:36:34 step 6: objective=0.034591395
2017/08/26 13:36:37 step 7: objective=0.034689553
2017/08/26 13:36:37 Training value function...
2017/08/26 13:36:38 step 0: mse=1.325766 step=0.100000
2017/08/26 13:36:39 step 1: mse=1.220752 step=0.100000
2017/08/26 13:36:40 step 2: mse=1.135832 step=0.100000
2017/08/26 13:36:40 step 3: mse=1.059425 step=0.100000
2017/08/26 13:36:41 step 4: mse=0.997438 step=0.100000
2017/08/26 13:36:42 step 5: mse=0.939636 step=0.100000
2017/08/26 13:36:43 step 6: mse=0.889394 step=0.100000
2017/08/26 13:36:43 step 7: mse=0.851721 step=0.100000
2017/08/26 13:36:43 Saving...
2017/08/26 13:36:43 Gathering batch of experience...
2017/08/26 13:37:00 batch 210: mean=16.340909 stddev=5.604151 entropy=1.067534 frames=36075 count=44
2017/08/26 13:37:00 Training policy...
2017/08/26 13:37:05 step 0: objective=0.047631424
2017/08/26 13:37:08 step 1: objective=0.047680564
2017/08/26 13:37:12 step 2: objective=0.047726955
2017/08/26 13:37:15 step 3: objective=0.04777381
2017/08/26 13:37:18 step 4: objective=0.047820874
2017/08/26 13:37:21 step 5: objective=0.04786162
2017/08/26 13:37:24 step 6: objective=0.047902025
2017/08/26 13:37:27 step 7: objective=0.047943894
2017/08/26 13:37:27 Training value function...
2017/08/26 13:37:29 step 0: mse=1.006056 step=0.100000
2017/08/26 13:37:29 step 1: mse=0.944897 step=0.100000
2017/08/26 13:37:30 step 2: mse=0.891528 step=0.100000
2017/08/26 13:37:31 step 3: mse=0.847552 step=0.100000
2017/08/26 13:37:31 step 4: mse=0.810354 step=0.100000
2017/08/26 13:37:32 step 5: mse=0.780822 step=0.100000
2017/08/26 13:37:33 step 6: mse=0.753958 step=0.100000
2017/08/26 13:37:34 step 7: mse=0.727946 step=0.100000
2017/08/26 13:37:34 Saving...
2017/08/26 13:37:34 Gathering batch of experience...
2017/08/26 13:37:51 batch 211: mean=14.673913 stddev=4.805135 entropy=1.073676 frames=36779 count=46
2017/08/26 13:37:51 Training policy...
2017/08/26 13:37:56 step 0: objective=-0.00046129676
2017/08/26 13:37:59 step 1: objective=-0.00041923203
2017/08/26 13:38:02 step 2: objective=-0.0003771181
2017/08/26 13:38:06 step 3: objective=-0.0003349693
2017/08/26 13:38:09 step 4: objective=-0.00029277528
2017/08/26 13:38:12 step 5: objective=-0.00025090305
2017/08/26 13:38:15 step 6: objective=-0.00021927993
2017/08/26 13:38:19 step 7: objective=-0.00019052654
2017/08/26 13:38:19 Training value function...
2017/08/26 13:38:20 step 0: mse=0.690353 step=0.100000
2017/08/26 13:38:21 step 1: mse=0.645262 step=0.100000
2017/08/26 13:38:21 step 2: mse=0.606217 step=0.100000
2017/08/26 13:38:22 step 3: mse=0.575181 step=0.100000
2017/08/26 13:38:23 step 4: mse=0.553941 step=0.100000
2017/08/26 13:38:24 step 5: mse=0.537141 step=0.100000
2017/08/26 13:38:24 step 6: mse=0.523333 step=0.100000
2017/08/26 13:38:25 step 7: mse=0.510885 step=0.100000
2017/08/26 13:38:25 Saving...
2017/08/26 13:38:25 Gathering batch of experience...
2017/08/26 13:38:41 batch 212: mean=16.619048 stddev=7.511744 entropy=1.064508 frames=34977 count=42
2017/08/26 13:38:41 Training policy...
2017/08/26 13:38:46 step 0: objective=0.056080822
2017/08/26 13:38:49 step 1: objective=0.05615671
2017/08/26 13:38:52 step 2: objective=0.056232665
2017/08/26 13:38:55 step 3: objective=0.056306917
2017/08/26 13:38:58 step 4: objective=0.056368746
2017/08/26 13:39:01 step 5: objective=0.056431323
2017/08/26 13:39:04 step 6: objective=0.056498628
2017/08/26 13:39:07 step 7: objective=0.056526624
2017/08/26 13:39:07 Training value function...
2017/08/26 13:39:09 step 0: mse=1.107204 step=0.100000
2017/08/26 13:39:09 step 1: mse=1.036617 step=0.100000
2017/08/26 13:39:10 step 2: mse=0.974429 step=0.100000
2017/08/26 13:39:11 step 3: mse=0.925054 step=0.100000
2017/08/26 13:39:12 step 4: mse=0.882399 step=0.100000
2017/08/26 13:39:12 step 5: mse=0.847654 step=0.100000
2017/08/26 13:39:13 step 6: mse=0.814814 step=0.100000
2017/08/26 13:39:14 step 7: mse=0.779596 step=0.100000
2017/08/26 13:39:14 Saving...
2017/08/26 13:39:14 Gathering batch of experience...
2017/08/26 13:39:31 batch 213: mean=15.586957 stddev=7.146225 entropy=1.078414 frames=37484 count=46
2017/08/26 13:39:31 Training policy...
2017/08/26 13:39:36 step 0: objective=0.028513888
2017/08/26 13:39:40 step 1: objective=0.028547565
2017/08/26 13:39:43 step 2: objective=0.028581208
2017/08/26 13:39:46 step 3: objective=0.02861494
2017/08/26 13:39:50 step 4: objective=0.02864846
2017/08/26 13:39:53 step 5: objective=0.028682055
2017/08/26 13:39:56 step 6: objective=0.028715605
2017/08/26 13:39:59 step 7: objective=0.028746637
2017/08/26 13:39:59 Training value function...
2017/08/26 13:40:01 step 0: mse=0.878797 step=0.100000
2017/08/26 13:40:01 step 1: mse=0.829780 step=0.100000
2017/08/26 13:40:02 step 2: mse=0.790874 step=0.100000
2017/08/26 13:40:03 step 3: mse=0.756081 step=0.100000
2017/08/26 13:40:04 step 4: mse=0.727214 step=0.100000
2017/08/26 13:40:05 step 5: mse=0.703856 step=0.100000
2017/08/26 13:40:05 step 6: mse=0.683835 step=0.100000
2017/08/26 13:40:06 step 7: mse=0.644099 step=0.100000
2017/08/26 13:40:06 Saving...
2017/08/26 13:40:06 Gathering batch of experience...
2017/08/26 13:40:23 batch 214: mean=16.590909 stddev=7.640556 entropy=1.068830 frames=36272 count=44
2017/08/26 13:40:23 Training policy...
2017/08/26 13:40:28 step 0: objective=0.022110624
2017/08/26 13:40:31 step 1: objective=0.022166464
2017/08/26 13:40:34 step 2: objective=0.022221543
2017/08/26 13:40:38 step 3: objective=0.022276534
2017/08/26 13:40:41 step 4: objective=0.022324692
2017/08/26 13:40:44 step 5: objective=0.022372024
2017/08/26 13:40:47 step 6: objective=0.022418993
2017/08/26 13:40:51 step 7: objective=0.022469852
2017/08/26 13:40:51 Training value function...
2017/08/26 13:40:52 step 0: mse=1.065275 step=0.100000
2017/08/26 13:40:53 step 1: mse=0.995408 step=0.100000
2017/08/26 13:40:53 step 2: mse=0.939591 step=0.100000
2017/08/26 13:40:54 step 3: mse=0.893868 step=0.100000
2017/08/26 13:40:55 step 4: mse=0.856823 step=0.100000
2017/08/26 13:40:56 step 5: mse=0.824976 step=0.100000
2017/08/26 13:40:56 step 6: mse=0.796773 step=0.100000
2017/08/26 13:40:57 step 7: mse=0.772451 step=0.100000
2017/08/26 13:40:57 Saving...
2017/08/26 13:40:57 Gathering batch of experience...
2017/08/26 13:41:14 batch 215: mean=16.534884 stddev=6.827948 entropy=1.067938 frames=35863 count=43
2017/08/26 13:41:14 Training policy...
2017/08/26 13:41:19 step 0: objective=0.028947223
2017/08/26 13:41:22 step 1: objective=0.02902386
2017/08/26 13:41:25 step 2: objective=0.029101277
2017/08/26 13:41:28 step 3: objective=0.029179182
2017/08/26 13:41:31 step 4: objective=0.02924966
2017/08/26 13:41:35 step 5: objective=0.029285435
2017/08/26 13:41:38 step 6: objective=0.029323258
2017/08/26 13:41:41 step 7: objective=0.029377136
2017/08/26 13:41:41 Training value function...
2017/08/26 13:41:42 step 0: mse=1.195960 step=0.100000
2017/08/26 13:41:43 step 1: mse=1.082829 step=0.100000
2017/08/26 13:41:44 step 2: mse=0.993706 step=0.100000
2017/08/26 13:41:44 step 3: mse=0.917315 step=0.100000
2017/08/26 13:41:45 step 4: mse=0.861833 step=0.100000
2017/08/26 13:41:46 step 5: mse=0.804275 step=0.100000
2017/08/26 13:41:46 step 6: mse=0.763784 step=0.100000
2017/08/26 13:41:47 step 7: mse=0.730585 step=0.100000
2017/08/26 13:41:47 Saving...
2017/08/26 13:41:47 Gathering batch of experience...
2017/08/26 13:42:04 batch 216: mean=15.888889 stddev=5.007648 entropy=1.078860 frames=36531 count=45
2017/08/26 13:42:04 Training policy...
2017/08/26 13:42:09 step 0: objective=0.024986116
2017/08/26 13:42:12 step 1: objective=0.02503409
2017/08/26 13:42:16 step 2: objective=0.025082031
2017/08/26 13:42:19 step 3: objective=0.025130067
2017/08/26 13:42:22 step 4: objective=0.02517809
2017/08/26 13:42:25 step 5: objective=0.025226148
2017/08/26 13:42:29 step 6: objective=0.025271073
2017/08/26 13:42:32 step 7: objective=0.025314275
2017/08/26 13:42:32 Training value function...
2017/08/26 13:42:33 step 0: mse=0.895592 step=0.100000
2017/08/26 13:42:34 step 1: mse=0.852775 step=0.100000
2017/08/26 13:42:35 step 2: mse=0.815405 step=0.100000
2017/08/26 13:42:35 step 3: mse=0.783144 step=0.100000
2017/08/26 13:42:36 step 4: mse=0.751778 step=0.100000
2017/08/26 13:42:37 step 5: mse=0.729821 step=0.100000
2017/08/26 13:42:38 step 6: mse=0.707206 step=0.100000
2017/08/26 13:42:38 step 7: mse=0.691394 step=0.100000
2017/08/26 13:42:38 Saving...
2017/08/26 13:42:38 Gathering batch of experience...
2017/08/26 13:42:55 batch 217: mean=15.477273 stddev=5.929467 entropy=1.072461 frames=35896 count=44
2017/08/26 13:42:55 Training policy...
2017/08/26 13:43:00 step 0: objective=0.025897883
2017/08/26 13:43:03 step 1: objective=0.025926791
2017/08/26 13:43:06 step 2: objective=0.025955943
2017/08/26 13:43:10 step 3: objective=0.02598512
2017/08/26 13:43:13 step 4: objective=0.026014423
2017/08/26 13:43:16 step 5: objective=0.026043706
2017/08/26 13:43:19 step 6: objective=0.026071614
2017/08/26 13:43:22 step 7: objective=0.026120197
2017/08/26 13:43:22 Training value function...
2017/08/26 13:43:24 step 0: mse=0.717018 step=0.100000
2017/08/26 13:43:24 step 1: mse=0.679262 step=0.100000
2017/08/26 13:43:25 step 2: mse=0.647450 step=0.100000
2017/08/26 13:43:26 step 3: mse=0.621153 step=0.100000
2017/08/26 13:43:27 step 4: mse=0.597124 step=0.100000
2017/08/26 13:43:27 step 5: mse=0.574853 step=0.100000
2017/08/26 13:43:28 step 6: mse=0.559214 step=0.100000
2017/08/26 13:43:29 step 7: mse=0.549016 step=0.100000
2017/08/26 13:43:29 Saving...
2017/08/26 13:43:29 Gathering batch of experience...
2017/08/26 13:43:46 batch 218: mean=16.377778 stddev=6.037987 entropy=1.070999 frames=36652 count=45
2017/08/26 13:43:46 Training policy...
2017/08/26 13:43:51 step 0: objective=0.040866826
2017/08/26 13:43:54 step 1: objective=0.040961206
2017/08/26 13:43:58 step 2: objective=0.04105596
2017/08/26 13:44:01 step 3: objective=0.04114702
2017/08/26 13:44:04 step 4: objective=0.041244376
2017/08/26 13:44:07 step 5: objective=0.041285086
2017/08/26 13:44:11 step 6: objective=0.041324917
2017/08/26 13:44:14 step 7: objective=0.041360386
2017/08/26 13:44:14 Training value function...
2017/08/26 13:44:15 step 0: mse=0.944162 step=0.100000
2017/08/26 13:44:16 step 1: mse=0.908989 step=0.100000
2017/08/26 13:44:17 step 2: mse=0.862463 step=0.100000
2017/08/26 13:44:17 step 3: mse=0.836576 step=0.100000
2017/08/26 13:44:18 step 4: mse=0.806511 step=0.100000
2017/08/26 13:44:19 step 5: mse=0.776587 step=0.100000
2017/08/26 13:44:20 step 6: mse=0.751408 step=0.100000
2017/08/26 13:44:20 step 7: mse=0.737735 step=0.100000
2017/08/26 13:44:20 Saving...
2017/08/26 13:44:20 Gathering batch of experience...
2017/08/26 13:44:38 batch 219: mean=15.478261 stddev=7.497069 entropy=1.061171 frames=37056 count=46
2017/08/26 13:44:38 Training policy...
2017/08/26 13:44:43 step 0: objective=0.030802034
2017/08/26 13:44:46 step 1: objective=0.030837199
2017/08/26 13:44:49 step 2: objective=0.030872576
2017/08/26 13:44:53 step 3: objective=0.030907594
2017/08/26 13:44:56 step 4: objective=0.030943092
2017/08/26 13:44:59 step 5: objective=0.030974815
2017/08/26 13:45:03 step 6: objective=0.031017857
2017/08/26 13:45:06 step 7: objective=0.031049209
2017/08/26 13:45:06 Training value function...
2017/08/26 13:45:07 step 0: mse=1.111169 step=0.100000
2017/08/26 13:45:08 step 1: mse=1.020302 step=0.100000
2017/08/26 13:45:09 step 2: mse=0.947454 step=0.100000
2017/08/26 13:45:09 step 3: mse=0.884565 step=0.100000
2017/08/26 13:45:10 step 4: mse=0.834142 step=0.100000
2017/08/26 13:45:11 step 5: mse=0.786719 step=0.100000
2017/08/26 13:45:12 step 6: mse=0.756355 step=0.100000
2017/08/26 13:45:12 step 7: mse=0.729120 step=0.100000
2017/08/26 13:45:12 Saving...
2017/08/26 13:45:13 Gathering batch of experience...
2017/08/26 13:45:30 batch 220: mean=16.133333 stddev=7.547185 entropy=1.062610 frames=36727 count=45
2017/08/26 13:45:30 Training policy...
2017/08/26 13:45:35 step 0: objective=0.042775173
2017/08/26 13:45:38 step 1: objective=0.042814836
2017/08/26 13:45:41 step 2: objective=0.04285477
2017/08/26 13:45:45 step 3: objective=0.04289428
2017/08/26 13:45:48 step 4: objective=0.042933837
2017/08/26 13:45:51 step 5: objective=0.042969737
2017/08/26 13:45:54 step 6: objective=0.042997517
2017/08/26 13:45:58 step 7: objective=0.043024976
2017/08/26 13:45:58 Training value function...
2017/08/26 13:45:59 step 0: mse=0.862610 step=0.100000
2017/08/26 13:46:00 step 1: mse=0.802440 step=0.100000
2017/08/26 13:46:00 step 2: mse=0.753663 step=0.100000
2017/08/26 13:46:01 step 3: mse=0.714770 step=0.100000
2017/08/26 13:46:02 step 4: mse=0.672273 step=0.100000
2017/08/26 13:46:03 step 5: mse=0.640018 step=0.100000
2017/08/26 13:46:03 step 6: mse=0.608707 step=0.100000
2017/08/26 13:46:04 step 7: mse=0.581487 step=0.100000
2017/08/26 13:46:04 Saving...
2017/08/26 13:46:04 Gathering batch of experience...
2017/08/26 13:46:22 batch 221: mean=18.159091 stddev=8.928868 entropy=1.062474 frames=37174 count=44
2017/08/26 13:46:22 Training policy...
2017/08/26 13:46:27 step 0: objective=0.06502427
2017/08/26 13:46:30 step 1: objective=0.06509352
2017/08/26 13:46:33 step 2: objective=0.06516293
2017/08/26 13:46:37 step 3: objective=0.06523214
2017/08/26 13:46:40 step 4: objective=0.06529778
2017/08/26 13:46:43 step 5: objective=0.06536134
2017/08/26 13:46:47 step 6: objective=0.06540674
2017/08/26 13:46:50 step 7: objective=0.065491095
2017/08/26 13:46:50 Training value function...
2017/08/26 13:46:51 step 0: mse=1.338005 step=0.100000
2017/08/26 13:46:52 step 1: mse=1.251714 step=0.100000
2017/08/26 13:46:53 step 2: mse=1.183545 step=0.100000
2017/08/26 13:46:54 step 3: mse=1.123812 step=0.100000
2017/08/26 13:46:54 step 4: mse=1.073670 step=0.100000
2017/08/26 13:46:55 step 5: mse=1.024628 step=0.100000
2017/08/26 13:46:56 step 6: mse=0.986344 step=0.100000
2017/08/26 13:46:57 step 7: mse=0.947448 step=0.100000
2017/08/26 13:46:57 Saving...
2017/08/26 13:46:57 Gathering batch of experience...
2017/08/26 13:47:13 batch 222: mean=14.913043 stddev=6.107109 entropy=1.070093 frames=35243 count=46
2017/08/26 13:47:13 Training policy...
2017/08/26 13:47:18 step 0: objective=0.0019054965
2017/08/26 13:47:21 step 1: objective=0.001973037
2017/08/26 13:47:25 step 2: objective=0.0020398663
2017/08/26 13:47:28 step 3: objective=0.0021063494
2017/08/26 13:47:31 step 4: objective=0.0021629115
2017/08/26 13:47:34 step 5: objective=0.0021997823
2017/08/26 13:47:37 step 6: objective=0.0023617526
2017/08/26 13:47:40 step 7: objective=0.0023920187
2017/08/26 13:47:40 Training value function...
2017/08/26 13:47:41 step 0: mse=0.966769 step=0.100000
2017/08/26 13:47:42 step 1: mse=0.904135 step=0.100000
2017/08/26 13:47:43 step 2: mse=0.854126 step=0.100000
2017/08/26 13:47:44 step 3: mse=0.812587 step=0.100000
2017/08/26 13:47:44 step 4: mse=0.777952 step=0.100000
2017/08/26 13:47:45 step 5: mse=0.746945 step=0.100000
2017/08/26 13:47:46 step 6: mse=0.717288 step=0.100000
2017/08/26 13:47:47 step 7: mse=0.690279 step=0.100000
2017/08/26 13:47:47 Saving...
2017/08/26 13:47:47 Gathering batch of experience...
2017/08/26 13:48:04 batch 223: mean=15.863636 stddev=5.872087 entropy=1.068720 frames=36785 count=44
2017/08/26 13:48:04 Training policy...
2017/08/26 13:48:09 step 0: objective=0.016951934
2017/08/26 13:48:12 step 1: objective=0.016993193
2017/08/26 13:48:16 step 2: objective=0.017027358
2017/08/26 13:48:19 step 3: objective=0.017067794
2017/08/26 13:48:22 step 4: objective=0.01710782
2017/08/26 13:48:26 step 5: objective=0.017137676
2017/08/26 13:48:29 step 6: objective=0.017174812
2017/08/26 13:48:32 step 7: objective=0.01720885
2017/08/26 13:48:32 Training value function...
2017/08/26 13:48:33 step 0: mse=0.755935 step=0.100000
2017/08/26 13:48:34 step 1: mse=0.730842 step=0.100000
2017/08/26 13:48:35 step 2: mse=0.710665 step=0.100000
2017/08/26 13:48:36 step 3: mse=0.693888 step=0.100000
2017/08/26 13:48:37 step 4: mse=0.663925 step=0.100000
2017/08/26 13:48:37 step 5: mse=0.648176 step=0.100000
2017/08/26 13:48:38 step 6: mse=0.637037 step=0.100000
2017/08/26 13:48:39 step 7: mse=0.626862 step=0.100000
2017/08/26 13:48:39 Saving...
2017/08/26 13:48:39 Gathering batch of experience...
2017/08/26 13:48:56 batch 224: mean=15.200000 stddev=7.332121 entropy=1.072166 frames=35796 count=45
2017/08/26 13:48:56 Training policy...
2017/08/26 13:49:01 step 0: objective=0.03089908
2017/08/26 13:49:04 step 1: objective=0.03096565
2017/08/26 13:49:07 step 2: objective=0.031031668
2017/08/26 13:49:10 step 3: objective=0.03109671
2017/08/26 13:49:14 step 4: objective=0.031120602
2017/08/26 13:49:17 step 5: objective=0.031144176
2017/08/26 13:49:20 step 6: objective=0.031183312
2017/08/26 13:49:23 step 7: objective=0.03121005
2017/08/26 13:49:23 Training value function...
2017/08/26 13:49:25 step 0: mse=1.033161 step=0.100000
2017/08/26 13:49:25 step 1: mse=0.940115 step=0.100000
2017/08/26 13:49:26 step 2: mse=0.865083 step=0.100000
2017/08/26 13:49:27 step 3: mse=0.801526 step=0.100000
2017/08/26 13:49:27 step 4: mse=0.750101 step=0.100000
2017/08/26 13:49:28 step 5: mse=0.703203 step=0.100000
2017/08/26 13:49:29 step 6: mse=0.664725 step=0.100000
2017/08/26 13:49:30 step 7: mse=0.630770 step=0.100000
2017/08/26 13:49:30 Saving...
2017/08/26 13:49:30 Gathering batch of experience...
2017/08/26 13:49:47 batch 225: mean=16.177778 stddev=7.248874 entropy=1.066301 frames=36630 count=45
2017/08/26 13:49:47 Training policy...
2017/08/26 13:49:52 step 0: objective=0.03529056
2017/08/26 13:49:55 step 1: objective=0.035376158
2017/08/26 13:49:59 step 2: objective=0.03546127
2017/08/26 13:50:02 step 3: objective=0.035544224
2017/08/26 13:50:05 step 4: objective=0.035603154
2017/08/26 13:50:08 step 5: objective=0.035659652
2017/08/26 13:50:12 step 6: objective=0.03571402
2017/08/26 13:50:15 step 7: objective=0.03577458
2017/08/26 13:50:15 Training value function...
2017/08/26 13:50:16 step 0: mse=1.114835 step=0.100000
2017/08/26 13:50:17 step 1: mse=1.034158 step=0.100000
2017/08/26 13:50:18 step 2: mse=0.971249 step=0.100000
2017/08/26 13:50:19 step 3: mse=0.905501 step=0.100000
2017/08/26 13:50:19 step 4: mse=0.852114 step=0.100000
2017/08/26 13:50:20 step 5: mse=0.808707 step=0.100000
2017/08/26 13:50:21 step 6: mse=0.774153 step=0.100000
2017/08/26 13:50:22 step 7: mse=0.740494 step=0.100000
2017/08/26 13:50:22 Saving...
2017/08/26 13:50:22 Gathering batch of experience...
2017/08/26 13:50:39 batch 226: mean=15.577778 stddev=5.225956 entropy=1.072925 frames=36494 count=45
2017/08/26 13:50:39 Training policy...
2017/08/26 13:50:44 step 0: objective=0.018571952
2017/08/26 13:50:47 step 1: objective=0.018639548
2017/08/26 13:50:51 step 2: objective=0.018707335
2017/08/26 13:50:54 step 3: objective=0.018775577
2017/08/26 13:50:57 step 4: objective=0.018839134
2017/08/26 13:51:01 step 5: objective=0.018883536
2017/08/26 13:51:04 step 6: objective=0.01891267
2017/08/26 13:51:07 step 7: objective=0.018943954
2017/08/26 13:51:07 Training value function...
2017/08/26 13:51:08 step 0: mse=0.798099 step=0.100000
2017/08/26 13:51:09 step 1: mse=0.754590 step=0.100000
2017/08/26 13:51:10 step 2: mse=0.719704 step=0.100000
2017/08/26 13:51:11 step 3: mse=0.680805 step=0.100000
2017/08/26 13:51:12 step 4: mse=0.660821 step=0.100000
2017/08/26 13:51:12 step 5: mse=0.633300 step=0.100000
2017/08/26 13:51:13 step 6: mse=0.608656 step=0.100000
2017/08/26 13:51:14 step 7: mse=0.589046 step=0.100000
2017/08/26 13:51:14 Saving...
2017/08/26 13:51:14 Gathering batch of experience...
2017/08/26 13:51:31 batch 227: mean=15.681818 stddev=5.711920 entropy=1.062100 frames=36787 count=44
2017/08/26 13:51:31 Training policy...
2017/08/26 13:51:36 step 0: objective=0.017742725
2017/08/26 13:51:40 step 1: objective=0.017847659
2017/08/26 13:51:43 step 2: objective=0.017952884
2017/08/26 13:51:46 step 3: objective=0.018046932
2017/08/26 13:51:49 step 4: objective=0.01810326
2017/08/26 13:51:53 step 5: objective=0.018156797
2017/08/26 13:51:56 step 6: objective=0.018215975
2017/08/26 13:51:59 step 7: objective=0.018257163
2017/08/26 13:51:59 Training value function...
2017/08/26 13:52:01 step 0: mse=0.604705 step=0.100000
2017/08/26 13:52:02 step 1: mse=0.584650 step=0.100000
2017/08/26 13:52:02 step 2: mse=0.572058 step=0.100000
2017/08/26 13:52:03 step 3: mse=0.559193 step=0.100000
2017/08/26 13:52:04 step 4: mse=0.544481 step=0.100000
2017/08/26 13:52:04 step 5: mse=0.533126 step=0.100000
2017/08/26 13:52:05 step 6: mse=0.519378 step=0.100000
2017/08/26 13:52:06 step 7: mse=0.504481 step=0.100000
2017/08/26 13:52:06 Saving...
2017/08/26 13:52:06 Gathering batch of experience...
2017/08/26 13:52:23 batch 228: mean=15.555556 stddev=6.351047 entropy=1.076666 frames=35132 count=45
2017/08/26 13:52:23 Training policy...
2017/08/26 13:52:27 step 0: objective=0.04012171
2017/08/26 13:52:31 step 1: objective=0.040171962
2017/08/26 13:52:34 step 2: objective=0.040222332
2017/08/26 13:52:37 step 3: objective=0.040272746
2017/08/26 13:52:40 step 4: objective=0.040319324
2017/08/26 13:52:43 step 5: objective=0.040345464
2017/08/26 13:52:46 step 6: objective=0.04036894
2017/08/26 13:52:50 step 7: objective=0.04042763
2017/08/26 13:52:50 Training value function...
2017/08/26 13:52:51 step 0: mse=1.031485 step=0.100000
2017/08/26 13:52:51 step 1: mse=0.966386 step=0.100000
2017/08/26 13:52:52 step 2: mse=0.913131 step=0.100000
2017/08/26 13:52:53 step 3: mse=0.870609 step=0.100000
2017/08/26 13:52:54 step 4: mse=0.835486 step=0.100000
2017/08/26 13:52:54 step 5: mse=0.806479 step=0.100000
2017/08/26 13:52:55 step 6: mse=0.781320 step=0.100000
2017/08/26 13:52:56 step 7: mse=0.759976 step=0.100000
2017/08/26 13:52:56 Saving...
2017/08/26 13:52:56 Gathering batch of experience...
2017/08/26 13:53:13 batch 229: mean=15.933333 stddev=6.560488 entropy=1.073064 frames=36203 count=45
2017/08/26 13:53:13 Training policy...
2017/08/26 13:53:18 step 0: objective=0.041588172
2017/08/26 13:53:21 step 1: objective=0.0416312
2017/08/26 13:53:24 step 2: objective=0.04167454
2017/08/26 13:53:28 step 3: objective=0.04171805
2017/08/26 13:53:31 step 4: objective=0.04176146
2017/08/26 13:53:34 step 5: objective=0.041797414
2017/08/26 13:53:38 step 6: objective=0.041831516
2017/08/26 13:53:41 step 7: objective=0.041875497
2017/08/26 13:53:41 Training value function...
2017/08/26 13:53:42 step 0: mse=1.038817 step=0.100000
2017/08/26 13:53:43 step 1: mse=0.970655 step=0.100000
2017/08/26 13:53:44 step 2: mse=0.919104 step=0.100000
2017/08/26 13:53:44 step 3: mse=0.866259 step=0.100000
2017/08/26 13:53:45 step 4: mse=0.818498 step=0.100000
2017/08/26 13:53:46 step 5: mse=0.769764 step=0.100000
2017/08/26 13:53:47 step 6: mse=0.735771 step=0.100000
2017/08/26 13:53:47 step 7: mse=0.706034 step=0.100000
2017/08/26 13:53:47 Saving...
2017/08/26 13:53:47 Gathering batch of experience...
2017/08/26 13:54:05 batch 230: mean=14.829787 stddev=5.547931 entropy=1.074213 frames=36826 count=47
2017/08/26 13:54:05 Training policy...
2017/08/26 13:54:10 step 0: objective=0.022394901
2017/08/26 13:54:13 step 1: objective=0.022471508
2017/08/26 13:54:16 step 2: objective=0.022548473
2017/08/26 13:54:20 step 3: objective=0.022625946
2017/08/26 13:54:23 step 4: objective=0.02270109
2017/08/26 13:54:26 step 5: objective=0.022761315
2017/08/26 13:54:30 step 6: objective=0.022803836
2017/08/26 13:54:33 step 7: objective=0.022844458
2017/08/26 13:54:33 Training value function...
2017/08/26 13:54:34 step 0: mse=0.833296 step=0.100000
2017/08/26 13:54:35 step 1: mse=0.775554 step=0.100000
2017/08/26 13:54:36 step 2: mse=0.728346 step=0.100000
2017/08/26 13:54:37 step 3: mse=0.682802 step=0.100000
2017/08/26 13:54:37 step 4: mse=0.650812 step=0.100000
2017/08/26 13:54:38 step 5: mse=0.622175 step=0.100000
2017/08/26 13:54:39 step 6: mse=0.594924 step=0.100000
2017/08/26 13:54:40 step 7: mse=0.575368 step=0.100000
2017/08/26 13:54:40 Saving...
2017/08/26 13:54:40 Gathering batch of experience...
2017/08/26 13:54:57 batch 231: mean=15.826087 stddev=5.839537 entropy=1.064225 frames=36830 count=46
2017/08/26 13:54:57 Training policy...
2017/08/26 13:55:02 step 0: objective=0.034323487
2017/08/26 13:55:05 step 1: objective=0.03438852
2017/08/26 13:55:09 step 2: objective=0.03445344
2017/08/26 13:55:12 step 3: objective=0.034519095
2017/08/26 13:55:16 step 4: objective=0.03457554
2017/08/26 13:55:19 step 5: objective=0.034603834
2017/08/26 13:55:22 step 6: objective=0.034647096
2017/08/26 13:55:26 step 7: objective=0.03469001
2017/08/26 13:55:26 Training value function...
2017/08/26 13:55:27 step 0: mse=0.816518 step=0.100000
2017/08/26 13:55:28 step 1: mse=0.769835 step=0.100000
2017/08/26 13:55:28 step 2: mse=0.732103 step=0.100000
2017/08/26 13:55:29 step 3: mse=0.704427 step=0.100000
2017/08/26 13:55:30 step 4: mse=0.678916 step=0.100000
2017/08/26 13:55:31 step 5: mse=0.658708 step=0.100000
2017/08/26 13:55:31 step 6: mse=0.631781 step=0.100000
2017/08/26 13:55:32 step 7: mse=0.614119 step=0.100000
2017/08/26 13:55:32 Saving...
2017/08/26 13:55:32 Gathering batch of experience...
2017/08/26 13:55:49 batch 232: mean=15.500000 stddev=7.459310 entropy=1.067190 frames=36069 count=46
2017/08/26 13:55:49 Training policy...
2017/08/26 13:55:54 step 0: objective=0.034858678
2017/08/26 13:55:58 step 1: objective=0.034901958
2017/08/26 13:56:01 step 2: objective=0.03494549
2017/08/26 13:56:04 step 3: objective=0.034989495
2017/08/26 13:56:07 step 4: objective=0.03503321
2017/08/26 13:56:11 step 5: objective=0.03507853
2017/08/26 13:56:14 step 6: objective=0.03511872
2017/08/26 13:56:17 step 7: objective=0.035144508
2017/08/26 13:56:17 Training value function...
2017/08/26 13:56:18 step 0: mse=0.838307 step=0.100000
2017/08/26 13:56:19 step 1: mse=0.794674 step=0.100000
2017/08/26 13:56:20 step 2: mse=0.769021 step=0.100000
2017/08/26 13:56:21 step 3: mse=0.733801 step=0.100000
2017/08/26 13:56:21 step 4: mse=0.706397 step=0.100000
2017/08/26 13:56:22 step 5: mse=0.685686 step=0.100000
2017/08/26 13:56:23 step 6: mse=0.667821 step=0.100000
2017/08/26 13:56:24 step 7: mse=0.649130 step=0.100000
2017/08/26 13:56:24 Saving...
2017/08/26 13:56:24 Gathering batch of experience...
2017/08/26 13:56:42 batch 233: mean=18.088889 stddev=8.474333 entropy=1.065032 frames=37890 count=45
2017/08/26 13:56:42 Training policy...
2017/08/26 13:56:47 step 0: objective=0.07425853
2017/08/26 13:56:50 step 1: objective=0.07435423
2017/08/26 13:56:54 step 2: objective=0.07445085
2017/08/26 13:56:57 step 3: objective=0.07454472
2017/08/26 13:57:01 step 4: objective=0.07461696
2017/08/26 13:57:04 step 5: objective=0.074683204
2017/08/26 13:57:08 step 6: objective=0.07474509
2017/08/26 13:57:11 step 7: objective=0.07480614
2017/08/26 13:57:11 Training value function...
2017/08/26 13:57:13 step 0: mse=1.641382 step=0.100000
2017/08/26 13:57:13 step 1: mse=1.505905 step=0.100000
2017/08/26 13:57:14 step 2: mse=1.395583 step=0.100000
2017/08/26 13:57:15 step 3: mse=1.302116 step=0.100000
2017/08/26 13:57:16 step 4: mse=1.227812 step=0.100000
2017/08/26 13:57:16 step 5: mse=1.162545 step=0.100000
2017/08/26 13:57:17 step 6: mse=1.097300 step=0.100000
2017/08/26 13:57:18 step 7: mse=1.048201 step=0.100000
2017/08/26 13:57:18 Saving...
2017/08/26 13:57:18 Gathering batch of experience...
2017/08/26 13:57:35 batch 234: mean=15.250000 stddev=5.510836 entropy=1.067201 frames=35876 count=44
2017/08/26 13:57:35 Training policy...
2017/08/26 13:57:40 step 0: objective=0.00071283523
2017/08/26 13:57:43 step 1: objective=0.0007583143
2017/08/26 13:57:46 step 2: objective=0.0008037439
2017/08/26 13:57:50 step 3: objective=0.0008491508
2017/08/26 13:57:53 step 4: objective=0.0008945199
2017/08/26 13:57:56 step 5: objective=0.0009398605
2017/08/26 13:58:00 step 6: objective=0.0009786149
2017/08/26 13:58:03 step 7: objective=0.0010125184
2017/08/26 13:58:03 Training value function...
2017/08/26 13:58:04 step 0: mse=1.017801 step=0.100000
2017/08/26 13:58:05 step 1: mse=0.915750 step=0.100000
2017/08/26 13:58:05 step 2: mse=0.834861 step=0.100000
2017/08/26 13:58:06 step 3: mse=0.769828 step=0.100000
2017/08/26 13:58:07 step 4: mse=0.714769 step=0.100000
2017/08/26 13:58:08 step 5: mse=0.672244 step=0.100000
2017/08/26 13:58:08 step 6: mse=0.634818 step=0.100000
2017/08/26 13:58:09 step 7: mse=0.604918 step=0.100000
2017/08/26 13:58:09 Saving...
2017/08/26 13:58:09 Gathering batch of experience...
2017/08/26 13:58:27 batch 235: mean=17.093023 stddev=7.357369 entropy=1.072787 frames=36463 count=43
2017/08/26 13:58:27 Training policy...
2017/08/26 13:58:32 step 0: objective=0.046124194
2017/08/26 13:58:35 step 1: objective=0.04619565
2017/08/26 13:58:38 step 2: objective=0.04626678
2017/08/26 13:58:42 step 3: objective=0.04633589
2017/08/26 13:58:45 step 4: objective=0.046385285
2017/08/26 13:58:48 step 5: objective=0.04646644
2017/08/26 13:58:52 step 6: objective=0.04654055
2017/08/26 13:58:55 step 7: objective=0.046606187
2017/08/26 13:58:55 Training value function...
2017/08/26 13:58:56 step 0: mse=0.970479 step=0.100000
2017/08/26 13:58:57 step 1: mse=0.907960 step=0.100000
2017/08/26 13:58:58 step 2: mse=0.856502 step=0.100000
2017/08/26 13:58:59 step 3: mse=0.810526 step=0.100000
2017/08/26 13:58:59 step 4: mse=0.772607 step=0.100000
2017/08/26 13:59:00 step 5: mse=0.743580 step=0.100000
2017/08/26 13:59:01 step 6: mse=0.712116 step=0.100000
2017/08/26 13:59:02 step 7: mse=0.687721 step=0.100000
2017/08/26 13:59:02 Saving...
2017/08/26 13:59:02 Gathering batch of experience...
2017/08/26 13:59:19 batch 236: mean=15.545455 stddev=6.415374 entropy=1.076293 frames=35937 count=44
2017/08/26 13:59:19 Training policy...
2017/08/26 13:59:24 step 0: objective=0.00056639727
2017/08/26 13:59:27 step 1: objective=0.0006297956
2017/08/26 13:59:30 step 2: objective=0.0006930128
2017/08/26 13:59:34 step 3: objective=0.0007560239
2017/08/26 13:59:37 step 4: objective=0.0008184223
2017/08/26 13:59:40 step 5: objective=0.00087460445
2017/08/26 13:59:44 step 6: objective=0.0009208976
2017/08/26 13:59:47 step 7: objective=0.0009763585
2017/08/26 13:59:47 Training value function...
2017/08/26 13:59:48 step 0: mse=0.887391 step=0.100000
2017/08/26 13:59:49 step 1: mse=0.842726 step=0.100000
2017/08/26 13:59:50 step 2: mse=0.796730 step=0.100000
2017/08/26 13:59:50 step 3: mse=0.768946 step=0.100000
2017/08/26 13:59:51 step 4: mse=0.747088 step=0.100000
2017/08/26 13:59:52 step 5: mse=0.727289 step=0.100000
2017/08/26 13:59:53 step 6: mse=0.709106 step=0.100000
2017/08/26 13:59:53 step 7: mse=0.676120 step=0.100000
2017/08/26 13:59:53 Saving...
2017/08/26 13:59:53 Gathering batch of experience...
2017/08/26 14:00:10 batch 237: mean=14.425532 stddev=7.379514 entropy=1.073999 frames=35717 count=47
2017/08/26 14:00:10 Training policy...
2017/08/26 14:00:15 step 0: objective=0.023966733
2017/08/26 14:00:19 step 1: objective=0.024047654
2017/08/26 14:00:22 step 2: objective=0.024128191
2017/08/26 14:00:25 step 3: objective=0.024208691
2017/08/26 14:00:28 step 4: objective=0.024287676
2017/08/26 14:00:32 step 5: objective=0.024351677
2017/08/26 14:00:35 step 6: objective=0.024435312
2017/08/26 14:00:38 step 7: objective=0.02448181
2017/08/26 14:00:38 Training value function...
2017/08/26 14:00:39 step 0: mse=0.809408 step=0.100000
2017/08/26 14:00:40 step 1: mse=0.776784 step=0.100000
2017/08/26 14:00:41 step 2: mse=0.744924 step=0.100000
2017/08/26 14:00:42 step 3: mse=0.719422 step=0.100000
2017/08/26 14:00:42 step 4: mse=0.698312 step=0.100000
2017/08/26 14:00:43 step 5: mse=0.678654 step=0.100000
2017/08/26 14:00:44 step 6: mse=0.662923 step=0.100000
2017/08/26 14:00:45 step 7: mse=0.648468 step=0.100000
2017/08/26 14:00:45 Saving...
2017/08/26 14:00:45 Gathering batch of experience...
2017/08/26 14:01:02 batch 238: mean=16.113636 stddev=5.589015 entropy=1.071139 frames=36725 count=44
2017/08/26 14:01:02 Training policy...
2017/08/26 14:01:07 step 0: objective=0.030024488
2017/08/26 14:01:11 step 1: objective=0.030097533
2017/08/26 14:01:14 step 2: objective=0.030170823
2017/08/26 14:01:17 step 3: objective=0.030244147
2017/08/26 14:01:21 step 4: objective=0.03031724
2017/08/26 14:01:24 step 5: objective=0.030383704
2017/08/26 14:01:28 step 6: objective=0.030457126
2017/08/26 14:01:31 step 7: objective=0.030488882
2017/08/26 14:01:31 Training value function...
2017/08/26 14:01:32 step 0: mse=0.858924 step=0.100000
2017/08/26 14:01:33 step 1: mse=0.804283 step=0.100000
2017/08/26 14:01:34 step 2: mse=0.766137 step=0.100000
2017/08/26 14:01:34 step 3: mse=0.735618 step=0.100000
2017/08/26 14:01:35 step 4: mse=0.687067 step=0.100000
2017/08/26 14:01:36 step 5: mse=0.657748 step=0.100000
2017/08/26 14:01:37 step 6: mse=0.630339 step=0.100000
2017/08/26 14:01:37 step 7: mse=0.608708 step=0.100000
2017/08/26 14:01:37 Saving...
2017/08/26 14:01:38 Gathering batch of experience...
2017/08/26 14:01:55 batch 239: mean=14.957447 stddev=7.139812 entropy=1.067167 frames=37238 count=47
2017/08/26 14:01:55 Training policy...
2017/08/26 14:02:00 step 0: objective=0.01838956
2017/08/26 14:02:04 step 1: objective=0.01841923
2017/08/26 14:02:07 step 2: objective=0.018448794
2017/08/26 14:02:11 step 3: objective=0.018478395
2017/08/26 14:02:14 step 4: objective=0.018507965
2017/08/26 14:02:18 step 5: objective=0.018536955
2017/08/26 14:02:21 step 6: objective=0.018563872
2017/08/26 14:02:25 step 7: objective=0.01858932
2017/08/26 14:02:25 Training value function...
2017/08/26 14:02:26 step 0: mse=0.770403 step=0.100000
2017/08/26 14:02:27 step 1: mse=0.732020 step=0.100000
2017/08/26 14:02:27 step 2: mse=0.700440 step=0.100000
2017/08/26 14:02:28 step 3: mse=0.675298 step=0.100000
2017/08/26 14:02:29 step 4: mse=0.651821 step=0.100000
2017/08/26 14:02:30 step 5: mse=0.626351 step=0.100000
2017/08/26 14:02:31 step 6: mse=0.603313 step=0.100000
2017/08/26 14:02:31 step 7: mse=0.590525 step=0.100000
2017/08/26 14:02:31 Saving...
2017/08/26 14:02:31 Gathering batch of experience...
2017/08/26 14:02:49 batch 240: mean=15.688889 stddev=6.666074 entropy=1.068810 frames=37180 count=45
2017/08/26 14:02:49 Training policy...
2017/08/26 14:02:54 step 0: objective=0.03528398
2017/08/26 14:02:57 step 1: objective=0.035330158
2017/08/26 14:03:01 step 2: objective=0.03537605
2017/08/26 14:03:04 step 3: objective=0.035421338
2017/08/26 14:03:08 step 4: objective=0.03547688
2017/08/26 14:03:11 step 5: objective=0.03553204
2017/08/26 14:03:15 step 6: objective=0.03557619
2017/08/26 14:03:18 step 7: objective=0.035625342
2017/08/26 14:03:18 Training value function...
2017/08/26 14:03:19 step 0: mse=0.676701 step=0.100000
2017/08/26 14:03:20 step 1: mse=0.642523 step=0.100000
2017/08/26 14:03:21 step 2: mse=0.608819 step=0.100000
2017/08/26 14:03:22 step 3: mse=0.584845 step=0.100000
2017/08/26 14:03:23 step 4: mse=0.565595 step=0.100000
2017/08/26 14:03:23 step 5: mse=0.546087 step=0.100000
2017/08/26 14:03:24 step 6: mse=0.528427 step=0.100000
2017/08/26 14:03:25 step 7: mse=0.514034 step=0.100000
2017/08/26 14:03:25 Saving...
2017/08/26 14:03:25 Gathering batch of experience...
2017/08/26 14:03:42 batch 241: mean=15.446809 stddev=7.748187 entropy=1.071227 frames=36792 count=47
2017/08/26 14:03:42 Training policy...
2017/08/26 14:03:47 step 0: objective=0.044821594
2017/08/26 14:03:51 step 1: objective=0.04486902
2017/08/26 14:03:54 step 2: objective=0.04491661
2017/08/26 14:03:58 step 3: objective=0.044964075
2017/08/26 14:04:01 step 4: objective=0.04501177
2017/08/26 14:04:05 step 5: objective=0.045059748
2017/08/26 14:04:08 step 6: objective=0.04510361
2017/08/26 14:04:11 step 7: objective=0.04516033
2017/08/26 14:04:11 Training value function...
2017/08/26 14:04:13 step 0: mse=0.892675 step=0.100000
2017/08/26 14:04:13 step 1: mse=0.860777 step=0.100000
2017/08/26 14:04:14 step 2: mse=0.830018 step=0.100000
2017/08/26 14:04:15 step 3: mse=0.807151 step=0.100000
2017/08/26 14:04:15 step 4: mse=0.767139 step=0.100000
2017/08/26 14:04:16 step 5: mse=0.747545 step=0.100000
2017/08/26 14:04:17 step 6: mse=0.730816 step=0.100000
2017/08/26 14:04:18 step 7: mse=0.707762 step=0.100000
2017/08/26 14:04:18 Saving...
2017/08/26 14:04:18 Gathering batch of experience...
2017/08/26 14:04:35 batch 242: mean=14.586957 stddev=5.491401 entropy=1.067039 frames=37073 count=46
2017/08/26 14:04:35 Training policy...
2017/08/26 14:04:40 step 0: objective=0.008317172
2017/08/26 14:04:44 step 1: objective=0.008355414
2017/08/26 14:04:47 step 2: objective=0.008393525
2017/08/26 14:04:51 step 3: objective=0.008431596
2017/08/26 14:04:54 step 4: objective=0.008476804
2017/08/26 14:04:58 step 5: objective=0.008522024
2017/08/26 14:05:01 step 6: objective=0.008549809
2017/08/26 14:05:05 step 7: objective=0.008576007
2017/08/26 14:05:05 Training value function...
2017/08/26 14:05:06 step 0: mse=0.581285 step=0.100000
2017/08/26 14:05:07 step 1: mse=0.541324 step=0.100000
2017/08/26 14:05:07 step 2: mse=0.508738 step=0.100000
2017/08/26 14:05:08 step 3: mse=0.483333 step=0.100000
2017/08/26 14:05:09 step 4: mse=0.460956 step=0.100000
2017/08/26 14:05:10 step 5: mse=0.442833 step=0.100000
2017/08/26 14:05:10 step 6: mse=0.426896 step=0.100000
2017/08/26 14:05:11 step 7: mse=0.407100 step=0.100000
2017/08/26 14:05:11 Saving...
2017/08/26 14:05:11 Gathering batch of experience...
2017/08/26 14:05:28 batch 243: mean=15.866667 stddev=6.123180 entropy=1.066238 frames=36489 count=45
2017/08/26 14:05:28 Training policy...
2017/08/26 14:05:33 step 0: objective=0.05192058
2017/08/26 14:05:37 step 1: objective=0.051945888
2017/08/26 14:05:40 step 2: objective=0.051971115
2017/08/26 14:05:44 step 3: objective=0.051995985
2017/08/26 14:05:47 step 4: objective=0.052021228
2017/08/26 14:05:51 step 5: objective=0.05204571
2017/08/26 14:05:54 step 6: objective=0.05207047
2017/08/26 14:05:57 step 7: objective=0.052097104
2017/08/26 14:05:57 Training value function...
2017/08/26 14:05:58 step 0: mse=0.859455 step=0.100000
2017/08/26 14:05:59 step 1: mse=0.799244 step=0.100000
2017/08/26 14:06:00 step 2: mse=0.750371 step=0.100000
2017/08/26 14:06:01 step 3: mse=0.707780 step=0.100000
2017/08/26 14:06:01 step 4: mse=0.672407 step=0.100000
2017/08/26 14:06:02 step 5: mse=0.642847 step=0.100000
2017/08/26 14:06:03 step 6: mse=0.614527 step=0.100000
2017/08/26 14:06:04 step 7: mse=0.587904 step=0.100000
2017/08/26 14:06:04 Saving...
2017/08/26 14:06:04 Gathering batch of experience...
2017/08/26 14:06:21 batch 244: mean=16.000000 stddev=6.850791 entropy=1.067803 frames=36576 count=45
2017/08/26 14:06:21 Training policy...
2017/08/26 14:06:26 step 0: objective=0.039241396
2017/08/26 14:06:30 step 1: objective=0.03932579
2017/08/26 14:06:33 step 2: objective=0.03941065
2017/08/26 14:06:36 step 3: objective=0.039495442
2017/08/26 14:06:40 step 4: objective=0.0395745
2017/08/26 14:06:43 step 5: objective=0.039622948
2017/08/26 14:06:47 step 6: objective=0.039667863
2017/08/26 14:06:50 step 7: objective=0.039709568
2017/08/26 14:06:50 Training value function...
2017/08/26 14:06:51 step 0: mse=0.847246 step=0.100000
2017/08/26 14:06:52 step 1: mse=0.807951 step=0.100000
2017/08/26 14:06:53 step 2: mse=0.773606 step=0.100000
2017/08/26 14:06:54 step 3: mse=0.745966 step=0.100000
2017/08/26 14:06:54 step 4: mse=0.715169 step=0.100000
2017/08/26 14:06:55 step 5: mse=0.695626 step=0.100000
2017/08/26 14:06:56 step 6: mse=0.677443 step=0.100000
2017/08/26 14:06:57 step 7: mse=0.660498 step=0.100000
2017/08/26 14:06:57 Saving...
2017/08/26 14:06:57 Gathering batch of experience...
2017/08/26 14:07:14 batch 245: mean=16.113636 stddev=6.296521 entropy=1.059577 frames=36597 count=44
2017/08/26 14:07:14 Training policy...
2017/08/26 14:07:19 step 0: objective=0.043003675
2017/08/26 14:07:23 step 1: objective=0.043063566
2017/08/26 14:07:26 step 2: objective=0.043123342
2017/08/26 14:07:30 step 3: objective=0.04318277
2017/08/26 14:07:33 step 4: objective=0.04323065
2017/08/26 14:07:36 step 5: objective=0.043276526
2017/08/26 14:07:40 step 6: objective=0.04331177
2017/08/26 14:07:43 step 7: objective=0.043351483
2017/08/26 14:07:43 Training value function...
2017/08/26 14:07:45 step 0: mse=0.757517 step=0.100000
2017/08/26 14:07:45 step 1: mse=0.713504 step=0.100000
2017/08/26 14:07:46 step 2: mse=0.674544 step=0.100000
2017/08/26 14:07:47 step 3: mse=0.643362 step=0.100000
2017/08/26 14:07:48 step 4: mse=0.613933 step=0.100000
2017/08/26 14:07:48 step 5: mse=0.592499 step=0.100000
2017/08/26 14:07:49 step 6: mse=0.570115 step=0.100000
2017/08/26 14:07:50 step 7: mse=0.555880 step=0.100000
2017/08/26 14:07:50 Saving...
2017/08/26 14:07:50 Gathering batch of experience...
2017/08/26 14:08:07 batch 246: mean=13.857143 stddev=5.714286 entropy=1.062663 frames=36684 count=49
2017/08/26 14:08:07 Training policy...
2017/08/26 14:08:12 step 0: objective=0.021828867
2017/08/26 14:08:16 step 1: objective=0.021858497
2017/08/26 14:08:19 step 2: objective=0.021888182
2017/08/26 14:08:23 step 3: objective=0.02191818
2017/08/26 14:08:26 step 4: objective=0.021948358
2017/08/26 14:08:30 step 5: objective=0.021978617
2017/08/26 14:08:33 step 6: objective=0.022003023
2017/08/26 14:08:37 step 7: objective=0.022038857
2017/08/26 14:08:37 Training value function...
2017/08/26 14:08:38 step 0: mse=0.720207 step=0.100000
2017/08/26 14:08:39 step 1: mse=0.684314 step=0.100000
2017/08/26 14:08:40 step 2: mse=0.655198 step=0.100000
2017/08/26 14:08:40 step 3: mse=0.628394 step=0.100000
2017/08/26 14:08:41 step 4: mse=0.611902 step=0.100000
2017/08/26 14:08:42 step 5: mse=0.582716 step=0.100000
2017/08/26 14:08:42 step 6: mse=0.567876 step=0.100000
2017/08/26 14:08:43 step 7: mse=0.554890 step=0.100000
2017/08/26 14:08:43 Saving...
2017/08/26 14:08:43 Gathering batch of experience...
2017/08/26 14:09:01 batch 247: mean=18.523810 stddev=9.880809 entropy=1.047898 frames=37596 count=42
2017/08/26 14:09:01 Training policy...
2017/08/26 14:09:06 step 0: objective=0.062260542
2017/08/26 14:09:10 step 1: objective=0.062297907
2017/08/26 14:09:14 step 2: objective=0.0623359
2017/08/26 14:09:17 step 3: objective=0.06237378
2017/08/26 14:09:21 step 4: objective=0.062412173
2017/08/26 14:09:24 step 5: objective=0.062443428
2017/08/26 14:09:28 step 6: objective=0.06251903
2017/08/26 14:09:31 step 7: objective=0.06255848
2017/08/26 14:09:31 Training value function...
2017/08/26 14:09:32 step 0: mse=1.336840 step=0.100000
2017/08/26 14:09:33 step 1: mse=1.208130 step=0.100000
2017/08/26 14:09:34 step 2: mse=1.104777 step=0.100000
2017/08/26 14:09:35 step 3: mse=1.018453 step=0.100000
2017/08/26 14:09:36 step 4: mse=0.949037 step=0.100000
2017/08/26 14:09:37 step 5: mse=0.890882 step=0.100000
2017/08/26 14:09:37 step 6: mse=0.840232 step=0.100000
2017/08/26 14:09:38 step 7: mse=0.799186 step=0.100000
2017/08/26 14:09:38 Saving...
2017/08/26 14:09:38 Gathering batch of experience...
2017/08/26 14:09:56 batch 248: mean=15.617021 stddev=6.319686 entropy=1.074230 frames=37395 count=47
2017/08/26 14:09:56 Training policy...
2017/08/26 14:10:01 step 0: objective=0.03415062
2017/08/26 14:10:05 step 1: objective=0.03419381
2017/08/26 14:10:08 step 2: objective=0.034236666
2017/08/26 14:10:12 step 3: objective=0.03427995
2017/08/26 14:10:15 step 4: objective=0.034322724
2017/08/26 14:10:19 step 5: objective=0.034363247
2017/08/26 14:10:22 step 6: objective=0.03439999
2017/08/26 14:10:26 step 7: objective=0.03443016
2017/08/26 14:10:26 Training value function...
2017/08/26 14:10:27 step 0: mse=0.886430 step=0.100000
2017/08/26 14:10:28 step 1: mse=0.844989 step=0.100000
2017/08/26 14:10:29 step 2: mse=0.804385 step=0.100000
2017/08/26 14:10:29 step 3: mse=0.776069 step=0.100000
2017/08/26 14:10:30 step 4: mse=0.744609 step=0.100000
2017/08/26 14:10:31 step 5: mse=0.716846 step=0.100000
2017/08/26 14:10:32 step 6: mse=0.699085 step=0.100000
2017/08/26 14:10:32 step 7: mse=0.671064 step=0.100000
2017/08/26 14:10:32 Saving...
2017/08/26 14:10:33 Gathering batch of experience...
2017/08/26 14:10:50 batch 249: mean=15.276596 stddev=8.250602 entropy=1.067634 frames=37031 count=47
2017/08/26 14:10:50 Training policy...
2017/08/26 14:10:56 step 0: objective=0.01868209
2017/08/26 14:10:59 step 1: objective=0.018743385
2017/08/26 14:11:03 step 2: objective=0.01880489
2017/08/26 14:11:06 step 3: objective=0.01886665
2017/08/26 14:11:10 step 4: objective=0.018928329
2017/08/26 14:11:13 step 5: objective=0.018977933
2017/08/26 14:11:17 step 6: objective=0.019013248
2017/08/26 14:11:20 step 7: objective=0.019060276
2017/08/26 14:11:20 Training value function...
2017/08/26 14:11:21 step 0: mse=0.817387 step=0.100000
2017/08/26 14:11:22 step 1: mse=0.773336 step=0.100000
2017/08/26 14:11:23 step 2: mse=0.739252 step=0.100000
2017/08/26 14:11:24 step 3: mse=0.709436 step=0.100000
2017/08/26 14:11:24 step 4: mse=0.684589 step=0.100000
2017/08/26 14:11:25 step 5: mse=0.667324 step=0.100000
2017/08/26 14:11:26 step 6: mse=0.654517 step=0.100000
2017/08/26 14:11:27 step 7: mse=0.637642 step=0.100000
2017/08/26 14:11:27 Saving...
2017/08/26 14:11:27 Gathering batch of experience...
2017/08/26 14:11:45 batch 250: mean=17.767442 stddev=7.175012 entropy=1.062907 frames=37196 count=43
2017/08/26 14:11:45 Training policy...
2017/08/26 14:11:50 step 0: objective=0.046704426
2017/08/26 14:11:53 step 1: objective=0.046771336
2017/08/26 14:11:57 step 2: objective=0.04683914
2017/08/26 14:12:00 step 3: objective=0.046908002
2017/08/26 14:12:04 step 4: objective=0.046961926
2017/08/26 14:12:07 step 5: objective=0.047000747
2017/08/26 14:12:11 step 6: objective=0.047035705
2017/08/26 14:12:15 step 7: objective=0.047073685
2017/08/26 14:12:15 Training value function...
2017/08/26 14:12:16 step 0: mse=1.083800 step=0.100000
2017/08/26 14:12:17 step 1: mse=1.015357 step=0.100000
2017/08/26 14:12:17 step 2: mse=0.962387 step=0.100000
2017/08/26 14:12:18 step 3: mse=0.909561 step=0.100000
2017/08/26 14:12:19 step 4: mse=0.873020 step=0.100000
2017/08/26 14:12:19 step 5: mse=0.834817 step=0.100000
2017/08/26 14:12:20 step 6: mse=0.802894 step=0.100000
2017/08/26 14:12:21 step 7: mse=0.771370 step=0.100000
2017/08/26 14:12:21 Saving...
2017/08/26 14:12:21 Gathering batch of experience...
2017/08/26 14:12:38 batch 251: mean=16.372093 stddev=4.894341 entropy=1.063955 frames=35873 count=43
2017/08/26 14:12:38 Training policy...
2017/08/26 14:12:43 step 0: objective=0.03427566
2017/08/26 14:12:47 step 1: objective=0.034333494
2017/08/26 14:12:50 step 2: objective=0.034391142
2017/08/26 14:12:53 step 3: objective=0.034448553
2017/08/26 14:12:57 step 4: objective=0.03450478
2017/08/26 14:13:00 step 5: objective=0.034559026
2017/08/26 14:13:04 step 6: objective=0.034605138
2017/08/26 14:13:07 step 7: objective=0.034683596
2017/08/26 14:13:07 Training value function...
2017/08/26 14:13:08 step 0: mse=0.837788 step=0.100000
2017/08/26 14:13:09 step 1: mse=0.805012 step=0.100000
2017/08/26 14:13:10 step 2: mse=0.777858 step=0.100000
2017/08/26 14:13:10 step 3: mse=0.752826 step=0.100000
2017/08/26 14:13:11 step 4: mse=0.729415 step=0.100000
2017/08/26 14:13:12 step 5: mse=0.703262 step=0.100000
2017/08/26 14:13:13 step 6: mse=0.675628 step=0.100000
2017/08/26 14:13:13 step 7: mse=0.652407 step=0.100000
2017/08/26 14:13:13 Saving...
2017/08/26 14:13:13 Gathering batch of experience...
2017/08/26 14:13:30 batch 252: mean=16.155556 stddev=7.834271 entropy=1.064654 frames=35716 count=45
2017/08/26 14:13:30 Training policy...
2017/08/26 14:13:35 step 0: objective=0.037618574
2017/08/26 14:13:39 step 1: objective=0.037670445
2017/08/26 14:13:42 step 2: objective=0.037722535
2017/08/26 14:13:45 step 3: objective=0.0377741
2017/08/26 14:13:49 step 4: objective=0.037826028
2017/08/26 14:13:52 step 5: objective=0.037875082
2017/08/26 14:13:56 step 6: objective=0.037922543
2017/08/26 14:13:59 step 7: objective=0.037951697
2017/08/26 14:13:59 Training value function...
2017/08/26 14:14:00 step 0: mse=1.157694 step=0.100000
2017/08/26 14:14:01 step 1: mse=1.086050 step=0.100000
2017/08/26 14:14:02 step 2: mse=1.024910 step=0.100000
2017/08/26 14:14:02 step 3: mse=0.974699 step=0.100000
2017/08/26 14:14:03 step 4: mse=0.929390 step=0.100000
2017/08/26 14:14:04 step 5: mse=0.888756 step=0.100000
2017/08/26 14:14:05 step 6: mse=0.861287 step=0.100000
2017/08/26 14:14:05 step 7: mse=0.826316 step=0.100000
2017/08/26 14:14:05 Saving...
2017/08/26 14:14:05 Gathering batch of experience...
2017/08/26 14:14:23 batch 253: mean=17.044444 stddev=7.105414 entropy=1.063963 frames=37174 count=45
2017/08/26 14:14:23 Training policy...
2017/08/26 14:14:28 step 0: objective=0.039727096
2017/08/26 14:14:32 step 1: objective=0.03977211
2017/08/26 14:14:35 step 2: objective=0.039817385
2017/08/26 14:14:39 step 3: objective=0.039862346
2017/08/26 14:14:43 step 4: objective=0.03989667
2017/08/26 14:14:46 step 5: objective=0.039962582
2017/08/26 14:14:50 step 6: objective=0.040027484
2017/08/26 14:14:53 step 7: objective=0.04009208
2017/08/26 14:14:53 Training value function...
2017/08/26 14:14:54 step 0: mse=1.051120 step=0.100000
2017/08/26 14:14:55 step 1: mse=0.988480 step=0.100000
2017/08/26 14:14:56 step 2: mse=0.930443 step=0.100000
2017/08/26 14:14:57 step 3: mse=0.881712 step=0.100000
2017/08/26 14:14:57 step 4: mse=0.845430 step=0.100000
2017/08/26 14:14:58 step 5: mse=0.812383 step=0.100000
2017/08/26 14:14:59 step 6: mse=0.783063 step=0.100000
2017/08/26 14:15:00 step 7: mse=0.760616 step=0.100000
2017/08/26 14:15:00 Saving...
2017/08/26 14:15:00 Gathering batch of experience...
2017/08/26 14:15:18 batch 254: mean=17.068182 stddev=6.736595 entropy=1.061707 frames=37055 count=44
2017/08/26 14:15:18 Training policy...
2017/08/26 14:15:23 step 0: objective=0.025377015
2017/08/26 14:15:26 step 1: objective=0.025436
2017/08/26 14:15:30 step 2: objective=0.02549493
2017/08/26 14:15:33 step 3: objective=0.025553618
2017/08/26 14:15:37 step 4: objective=0.025612365
2017/08/26 14:15:41 step 5: objective=0.025667103
2017/08/26 14:15:44 step 6: objective=0.025714183
2017/08/26 14:15:48 step 7: objective=0.025770307
2017/08/26 14:15:48 Training value function...
2017/08/26 14:15:49 step 0: mse=0.813353 step=0.100000
2017/08/26 14:15:50 step 1: mse=0.779717 step=0.100000
2017/08/26 14:15:50 step 2: mse=0.751442 step=0.100000
2017/08/26 14:15:51 step 3: mse=0.728587 step=0.100000
2017/08/26 14:15:52 step 4: mse=0.697765 step=0.100000
2017/08/26 14:15:53 step 5: mse=0.681436 step=0.100000
2017/08/26 14:15:54 step 6: mse=0.653611 step=0.100000
2017/08/26 14:15:54 step 7: mse=0.630840 step=0.100000
2017/08/26 14:15:54 Saving...
2017/08/26 14:15:54 Gathering batch of experience...
2017/08/26 14:16:12 batch 255: mean=15.673913 stddev=6.695405 entropy=1.069297 frames=36813 count=46
2017/08/26 14:16:12 Training policy...
2017/08/26 14:16:17 step 0: objective=0.025159104
2017/08/26 14:16:21 step 1: objective=0.025233606
2017/08/26 14:16:24 step 2: objective=0.025303612
2017/08/26 14:16:28 step 3: objective=0.025373595
2017/08/26 14:16:31 step 4: objective=0.025443098
2017/08/26 14:16:35 step 5: objective=0.025492916
2017/08/26 14:16:38 step 6: objective=0.025570896
2017/08/26 14:16:42 step 7: objective=0.025642978
2017/08/26 14:16:42 Training value function...
2017/08/26 14:16:43 step 0: mse=0.842075 step=0.100000
2017/08/26 14:16:44 step 1: mse=0.807432 step=0.100000
2017/08/26 14:16:44 step 2: mse=0.781174 step=0.100000
2017/08/26 14:16:45 step 3: mse=0.757669 step=0.100000
2017/08/26 14:16:46 step 4: mse=0.732450 step=0.100000
2017/08/26 14:16:47 step 5: mse=0.715482 step=0.100000
2017/08/26 14:16:47 step 6: mse=0.696925 step=0.100000
2017/08/26 14:16:48 step 7: mse=0.685158 step=0.100000
2017/08/26 14:16:48 Saving...
2017/08/26 14:16:48 Gathering batch of experience...
2017/08/26 14:17:06 batch 256: mean=17.068182 stddev=5.990135 entropy=1.065343 frames=36423 count=44
2017/08/26 14:17:06 Training policy...
2017/08/26 14:17:11 step 0: objective=0.03650425
2017/08/26 14:17:14 step 1: objective=0.036591213
2017/08/26 14:17:18 step 2: objective=0.03667855
2017/08/26 14:17:21 step 3: objective=0.036765397
2017/08/26 14:17:25 step 4: objective=0.036827244
2017/08/26 14:17:28 step 5: objective=0.03686775
2017/08/26 14:17:32 step 6: objective=0.036920257
2017/08/26 14:17:35 step 7: objective=0.03696336
2017/08/26 14:17:35 Training value function...
2017/08/26 14:17:37 step 0: mse=0.912560 step=0.100000
2017/08/26 14:17:37 step 1: mse=0.880438 step=0.100000
2017/08/26 14:17:38 step 2: mse=0.854415 step=0.100000
2017/08/26 14:17:39 step 3: mse=0.822847 step=0.100000
2017/08/26 14:17:40 step 4: mse=0.797222 step=0.100000
2017/08/26 14:17:40 step 5: mse=0.778185 step=0.100000
2017/08/26 14:17:41 step 6: mse=0.761514 step=0.100000
2017/08/26 14:17:42 step 7: mse=0.747610 step=0.100000
2017/08/26 14:17:42 Saving...
2017/08/26 14:17:42 Gathering batch of experience...
2017/08/26 14:17:59 batch 257: mean=15.590909 stddev=5.909615 entropy=1.066137 frames=36386 count=44
2017/08/26 14:17:59 Training policy...
2017/08/26 14:18:04 step 0: objective=0.017504111
2017/08/26 14:18:08 step 1: objective=0.017535683
2017/08/26 14:18:11 step 2: objective=0.01756708
2017/08/26 14:18:15 step 3: objective=0.017598543
2017/08/26 14:18:18 step 4: objective=0.017637089
2017/08/26 14:18:22 step 5: objective=0.017674787
2017/08/26 14:18:25 step 6: objective=0.017698871
2017/08/26 14:18:29 step 7: objective=0.01773746
2017/08/26 14:18:29 Training value function...
2017/08/26 14:18:30 step 0: mse=0.752752 step=0.100000
2017/08/26 14:18:31 step 1: mse=0.711069 step=0.100000
2017/08/26 14:18:32 step 2: mse=0.685245 step=0.100000
2017/08/26 14:18:32 step 3: mse=0.664675 step=0.100000
2017/08/26 14:18:33 step 4: mse=0.628736 step=0.100000
2017/08/26 14:18:34 step 5: mse=0.598459 step=0.100000
2017/08/26 14:18:35 step 6: mse=0.570281 step=0.100000
2017/08/26 14:18:35 step 7: mse=0.549124 step=0.100000
2017/08/26 14:18:35 Saving...
2017/08/26 14:18:36 Gathering batch of experience...
2017/08/26 14:18:53 batch 258: mean=17.409091 stddev=7.142441 entropy=1.070081 frames=36484 count=44
2017/08/26 14:18:53 Training policy...
2017/08/26 14:18:58 step 0: objective=0.052938346
2017/08/26 14:19:01 step 1: objective=0.052975256
2017/08/26 14:19:05 step 2: objective=0.053012177
2017/08/26 14:19:08 step 3: objective=0.053049173
2017/08/26 14:19:12 step 4: objective=0.053084947
2017/08/26 14:19:16 step 5: objective=0.053137287
2017/08/26 14:19:19 step 6: objective=0.053170934
2017/08/26 14:19:23 step 7: objective=0.053220946
2017/08/26 14:19:23 Training value function...
2017/08/26 14:19:24 step 0: mse=1.127607 step=0.100000
2017/08/26 14:19:25 step 1: mse=1.058782 step=0.100000
2017/08/26 14:19:25 step 2: mse=1.002549 step=0.100000
2017/08/26 14:19:26 step 3: mse=0.958795 step=0.100000
2017/08/26 14:19:27 step 4: mse=0.919826 step=0.100000
2017/08/26 14:19:28 step 5: mse=0.879904 step=0.100000
2017/08/26 14:19:28 step 6: mse=0.839279 step=0.100000
2017/08/26 14:19:29 step 7: mse=0.798439 step=0.100000
2017/08/26 14:19:29 Saving...
2017/08/26 14:19:29 Gathering batch of experience...
2017/08/26 14:19:47 batch 259: mean=17.441860 stddev=7.546144 entropy=1.067532 frames=36582 count=43
2017/08/26 14:19:47 Training policy...
2017/08/26 14:19:52 step 0: objective=0.027091984
2017/08/26 14:19:55 step 1: objective=0.027144346
2017/08/26 14:19:59 step 2: objective=0.027197542
2017/08/26 14:20:02 step 3: objective=0.027251013
2017/08/26 14:20:06 step 4: objective=0.027303174
2017/08/26 14:20:09 step 5: objective=0.02734018
2017/08/26 14:20:13 step 6: objective=0.027378602
2017/08/26 14:20:16 step 7: objective=0.027411938
2017/08/26 14:20:16 Training value function...
2017/08/26 14:20:18 step 0: mse=1.206161 step=0.100000
2017/08/26 14:20:19 step 1: mse=1.119704 step=0.100000
2017/08/26 14:20:19 step 2: mse=1.049992 step=0.100000
2017/08/26 14:20:20 step 3: mse=0.997728 step=0.100000
2017/08/26 14:20:21 step 4: mse=0.962860 step=0.100000
2017/08/26 14:20:22 step 5: mse=0.919662 step=0.100000
2017/08/26 14:20:22 step 6: mse=0.895577 step=0.100000
2017/08/26 14:20:23 step 7: mse=0.862852 step=0.100000
2017/08/26 14:20:23 Saving...
2017/08/26 14:20:23 Gathering batch of experience...
2017/08/26 14:20:40 batch 260: mean=15.000000 stddev=6.567377 entropy=1.071565 frames=35329 count=46
2017/08/26 14:20:40 Training policy...
2017/08/26 14:20:45 step 0: objective=0.019741464
2017/08/26 14:20:49 step 1: objective=0.019832106
2017/08/26 14:20:52 step 2: objective=0.019923607
2017/08/26 14:20:55 step 3: objective=0.02000841
2017/08/26 14:20:59 step 4: objective=0.020069724
2017/08/26 14:21:02 step 5: objective=0.020122191
2017/08/26 14:21:06 step 6: objective=0.02015644
2017/08/26 14:21:09 step 7: objective=0.02018507
2017/08/26 14:21:09 Training value function...
2017/08/26 14:21:10 step 0: mse=0.951617 step=0.100000
2017/08/26 14:21:11 step 1: mse=0.893999 step=0.100000
2017/08/26 14:21:12 step 2: mse=0.846497 step=0.100000
2017/08/26 14:21:13 step 3: mse=0.807548 step=0.100000
2017/08/26 14:21:13 step 4: mse=0.774999 step=0.100000
2017/08/26 14:21:14 step 5: mse=0.750742 step=0.100000
2017/08/26 14:21:15 step 6: mse=0.729672 step=0.100000
2017/08/26 14:21:15 step 7: mse=0.717530 step=0.100000
2017/08/26 14:21:15 Saving...
2017/08/26 14:21:15 Gathering batch of experience...
2017/08/26 14:21:33 batch 261: mean=16.813953 stddev=6.066514 entropy=1.054865 frames=36532 count=43
2017/08/26 14:21:33 Training policy...
2017/08/26 14:21:38 step 0: objective=0.032803815
2017/08/26 14:21:42 step 1: objective=0.032849703
2017/08/26 14:21:45 step 2: objective=0.03289517
2017/08/26 14:21:49 step 3: objective=0.03294613
2017/08/26 14:21:52 step 4: objective=0.032996982
2017/08/26 14:21:56 step 5: objective=0.033046566
2017/08/26 14:21:59 step 6: objective=0.033063658
2017/08/26 14:22:03 step 7: objective=0.033081032
2017/08/26 14:22:03 Training value function...
2017/08/26 14:22:04 step 0: mse=0.851507 step=0.100000
2017/08/26 14:22:05 step 1: mse=0.803073 step=0.100000
2017/08/26 14:22:06 step 2: mse=0.760290 step=0.100000
2017/08/26 14:22:06 step 3: mse=0.726357 step=0.100000
2017/08/26 14:22:07 step 4: mse=0.695932 step=0.100000
2017/08/26 14:22:08 step 5: mse=0.671123 step=0.100000
2017/08/26 14:22:09 step 6: mse=0.649815 step=0.100000
2017/08/26 14:22:09 step 7: mse=0.632548 step=0.100000
2017/08/26 14:22:09 Saving...
2017/08/26 14:22:10 Gathering batch of experience...
2017/08/26 14:22:27 batch 262: mean=15.021739 stddev=5.983634 entropy=1.071256 frames=37452 count=46
2017/08/26 14:22:27 Training policy...
2017/08/26 14:22:33 step 0: objective=0.012659463
2017/08/26 14:22:36 step 1: objective=0.012690403
2017/08/26 14:22:40 step 2: objective=0.012721312
2017/08/26 14:22:44 step 3: objective=0.012752278
2017/08/26 14:22:47 step 4: objective=0.012783183
2017/08/26 14:22:51 step 5: objective=0.0128120715
2017/08/26 14:22:55 step 6: objective=0.012847111
2017/08/26 14:22:58 step 7: objective=0.012881451
2017/08/26 14:22:58 Training value function...
2017/08/26 14:22:59 step 0: mse=0.608926 step=0.100000
2017/08/26 14:23:00 step 1: mse=0.587731 step=0.100000
2017/08/26 14:23:01 step 2: mse=0.571208 step=0.100000
2017/08/26 14:23:02 step 3: mse=0.556106 step=0.100000
2017/08/26 14:23:03 step 4: mse=0.534310 step=0.100000
2017/08/26 14:23:03 step 5: mse=0.516603 step=0.100000
2017/08/26 14:23:04 step 6: mse=0.506293 step=0.100000
2017/08/26 14:23:05 step 7: mse=0.497098 step=0.100000
2017/08/26 14:23:05 Saving...
2017/08/26 14:23:05 Gathering batch of experience...
2017/08/26 14:23:23 batch 263: mean=18.558140 stddev=8.578779 entropy=1.053116 frames=36657 count=43
2017/08/26 14:23:23 Training policy...
2017/08/26 14:23:28 step 0: objective=0.076330796
2017/08/26 14:23:31 step 1: objective=0.07640031
2017/08/26 14:23:35 step 2: objective=0.07647052
2017/08/26 14:23:38 step 3: objective=0.076539785
2017/08/26 14:23:42 step 4: objective=0.07658206
2017/08/26 14:23:46 step 5: objective=0.07664764
2017/08/26 14:23:49 step 6: objective=0.07669978
2017/08/26 14:23:53 step 7: objective=0.07674597
2017/08/26 14:23:53 Training value function...
2017/08/26 14:23:54 step 0: mse=1.761415 step=0.100000
2017/08/26 14:23:55 step 1: mse=1.610398 step=0.100000
2017/08/26 14:23:55 step 2: mse=1.485627 step=0.100000
2017/08/26 14:23:56 step 3: mse=1.377189 step=0.100000
2017/08/26 14:23:57 step 4: mse=1.276866 step=0.100000
2017/08/26 14:23:58 step 5: mse=1.206806 step=0.100000
2017/08/26 14:23:58 step 6: mse=1.136162 step=0.100000
2017/08/26 14:23:59 step 7: mse=1.079126 step=0.100000
2017/08/26 14:23:59 Saving...
2017/08/26 14:23:59 Gathering batch of experience...
2017/08/26 14:24:17 batch 264: mean=14.913043 stddev=5.908086 entropy=1.071416 frames=36713 count=46
2017/08/26 14:24:17 Training policy...
2017/08/26 14:24:22 step 0: objective=0.005362426
2017/08/26 14:24:26 step 1: objective=0.005431641
2017/08/26 14:24:29 step 2: objective=0.0055007576
2017/08/26 14:24:33 step 3: objective=0.005569897
2017/08/26 14:24:36 step 4: objective=0.0056372825
2017/08/26 14:24:40 step 5: objective=0.005699104
2017/08/26 14:24:44 step 6: objective=0.005758955
2017/08/26 14:24:47 step 7: objective=0.005802625
2017/08/26 14:24:47 Training value function...
2017/08/26 14:24:48 step 0: mse=0.724200 step=0.100000
2017/08/26 14:24:49 step 1: mse=0.693717 step=0.100000
2017/08/26 14:24:50 step 2: mse=0.669425 step=0.100000
2017/08/26 14:24:51 step 3: mse=0.646821 step=0.100000
2017/08/26 14:24:51 step 4: mse=0.628635 step=0.100000
2017/08/26 14:24:52 step 5: mse=0.611691 step=0.100000
2017/08/26 14:24:53 step 6: mse=0.599761 step=0.100000
2017/08/26 14:24:54 step 7: mse=0.586394 step=0.100000
2017/08/26 14:24:54 Saving...
2017/08/26 14:24:54 Gathering batch of experience...
2017/08/26 14:25:11 batch 265: mean=16.177778 stddev=7.165624 entropy=1.073134 frames=36187 count=45
2017/08/26 14:25:11 Training policy...
2017/08/26 14:25:16 step 0: objective=0.042413734
2017/08/26 14:25:20 step 1: objective=0.042484134
2017/08/26 14:25:23 step 2: objective=0.04255416
2017/08/26 14:25:27 step 3: objective=0.042615123
2017/08/26 14:25:30 step 4: objective=0.042694695
2017/08/26 14:25:34 step 5: objective=0.042764723
2017/08/26 14:25:37 step 6: objective=0.042838152
2017/08/26 14:25:41 step 7: objective=0.042911153
2017/08/26 14:25:41 Training value function...
2017/08/26 14:25:42 step 0: mse=1.234022 step=0.100000
2017/08/26 14:25:43 step 1: mse=1.117246 step=0.100000
2017/08/26 14:25:44 step 2: mse=1.024554 step=0.100000
2017/08/26 14:25:44 step 3: mse=0.947225 step=0.100000
2017/08/26 14:25:45 step 4: mse=0.884581 step=0.100000
2017/08/26 14:25:46 step 5: mse=0.838180 step=0.100000
2017/08/26 14:25:47 step 6: mse=0.800998 step=0.100000
2017/08/26 14:25:47 step 7: mse=0.764795 step=0.100000
2017/08/26 14:25:47 Saving...
2017/08/26 14:25:47 Gathering batch of experience...
2017/08/26 14:26:05 batch 266: mean=14.934783 stddev=6.102039 entropy=1.069462 frames=36792 count=46
2017/08/26 14:26:05 Training policy...
2017/08/26 14:26:10 step 0: objective=-0.0023607705
2017/08/26 14:26:14 step 1: objective=-0.0022898305
2017/08/26 14:26:18 step 2: objective=-0.002219282
2017/08/26 14:26:21 step 3: objective=-0.0021489582
2017/08/26 14:26:25 step 4: objective=-0.0020798275
2017/08/26 14:26:28 step 5: objective=-0.0020532566
2017/08/26 14:26:32 step 6: objective=-0.0020281055
2017/08/26 14:26:36 step 7: objective=-0.002005311
2017/08/26 14:26:36 Training value function...
2017/08/26 14:26:37 step 0: mse=0.680247 step=0.100000
2017/08/26 14:26:38 step 1: mse=0.644671 step=0.100000
2017/08/26 14:26:39 step 2: mse=0.616431 step=0.100000
2017/08/26 14:26:39 step 3: mse=0.594215 step=0.100000
2017/08/26 14:26:40 step 4: mse=0.573448 step=0.100000
2017/08/26 14:26:41 step 5: mse=0.559091 step=0.100000
2017/08/26 14:26:42 step 6: mse=0.539579 step=0.100000
2017/08/26 14:26:42 step 7: mse=0.516772 step=0.100000
2017/08/26 14:26:42 Saving...
2017/08/26 14:26:42 Gathering batch of experience...
2017/08/26 14:27:00 batch 267: mean=15.543478 stddev=7.344642 entropy=1.075599 frames=35710 count=46
2017/08/26 14:27:00 Training policy...
2017/08/26 14:27:05 step 0: objective=0.053943325
2017/08/26 14:27:08 step 1: objective=0.05399139
2017/08/26 14:27:12 step 2: objective=0.05404008
2017/08/26 14:27:15 step 3: objective=0.05408855
2017/08/26 14:27:19 step 4: objective=0.05413727
2017/08/26 14:27:22 step 5: objective=0.05417903
2017/08/26 14:27:26 step 6: objective=0.054244272
2017/08/26 14:27:29 step 7: objective=0.054304678
2017/08/26 14:27:29 Training value function...
2017/08/26 14:27:30 step 0: mse=1.129949 step=0.100000
2017/08/26 14:27:31 step 1: mse=1.044114 step=0.100000
2017/08/26 14:27:32 step 2: mse=0.974567 step=0.100000
2017/08/26 14:27:32 step 3: mse=0.919296 step=0.100000
2017/08/26 14:27:33 step 4: mse=0.871602 step=0.100000
2017/08/26 14:27:34 step 5: mse=0.833621 step=0.100000
2017/08/26 14:27:35 step 6: mse=0.794124 step=0.100000
2017/08/26 14:27:35 step 7: mse=0.768075 step=0.100000
2017/08/26 14:27:35 Saving...
2017/08/26 14:27:35 Gathering batch of experience...
2017/08/26 14:27:53 batch 268: mean=16.500000 stddev=5.224712 entropy=1.061957 frames=35996 count=42
2017/08/26 14:27:53 Training policy...
2017/08/26 14:27:58 step 0: objective=0.014178503
2017/08/26 14:28:01 step 1: objective=0.014226161
2017/08/26 14:28:05 step 2: objective=0.014273623
2017/08/26 14:28:08 step 3: objective=0.0143209
2017/08/26 14:28:12 step 4: objective=0.014368109
2017/08/26 14:28:15 step 5: objective=0.014415176
2017/08/26 14:28:19 step 6: objective=0.014460681
2017/08/26 14:28:22 step 7: objective=0.014490948
2017/08/26 14:28:22 Training value function...
2017/08/26 14:28:24 step 0: mse=0.841398 step=0.100000
2017/08/26 14:28:24 step 1: mse=0.783483 step=0.100000
2017/08/26 14:28:25 step 2: mse=0.735395 step=0.100000
2017/08/26 14:28:26 step 3: mse=0.696905 step=0.100000
2017/08/26 14:28:27 step 4: mse=0.658877 step=0.100000
2017/08/26 14:28:27 step 5: mse=0.625799 step=0.100000
2017/08/26 14:28:28 step 6: mse=0.598738 step=0.100000
2017/08/26 14:28:29 step 7: mse=0.578214 step=0.100000
2017/08/26 14:28:29 Saving...
2017/08/26 14:28:29 Gathering batch of experience...
2017/08/26 14:28:46 batch 269: mean=16.697674 stddev=8.390290 entropy=1.051850 frames=35773 count=43
2017/08/26 14:28:46 Training policy...
2017/08/26 14:28:51 step 0: objective=0.027550582
2017/08/26 14:28:55 step 1: objective=0.027679628
2017/08/26 14:28:58 step 2: objective=0.027808608
2017/08/26 14:29:02 step 3: objective=0.027930954
2017/08/26 14:29:05 step 4: objective=0.028003331
2017/08/26 14:29:09 step 5: objective=0.028111484
2017/08/26 14:29:12 step 6: objective=0.028216422
2017/08/26 14:29:16 step 7: objective=0.028264275
2017/08/26 14:29:16 Training value function...
2017/08/26 14:29:17 step 0: mse=1.130871 step=0.100000
2017/08/26 14:29:18 step 1: mse=1.077282 step=0.100000
2017/08/26 14:29:18 step 2: mse=1.034146 step=0.100000
2017/08/26 14:29:19 step 3: mse=0.990982 step=0.100000
2017/08/26 14:29:20 step 4: mse=0.944109 step=0.100000
2017/08/26 14:29:21 step 5: mse=0.912776 step=0.100000
2017/08/26 14:29:21 step 6: mse=0.883626 step=0.100000
2017/08/26 14:29:22 step 7: mse=0.861239 step=0.100000
2017/08/26 14:29:22 Saving...
2017/08/26 14:29:22 Gathering batch of experience...
2017/08/26 14:29:40 batch 270: mean=16.638298 stddev=7.063317 entropy=1.059318 frames=37791 count=47
2017/08/26 14:29:40 Training policy...
2017/08/26 14:29:46 step 0: objective=0.045947775
2017/08/26 14:29:49 step 1: objective=0.046030063
2017/08/26 14:29:53 step 2: objective=0.046112634
2017/08/26 14:29:57 step 3: objective=0.046195656
2017/08/26 14:30:01 step 4: objective=0.0462515
2017/08/26 14:30:04 step 5: objective=0.046302997
2017/08/26 14:30:08 step 6: objective=0.04635315
2017/08/26 14:30:12 step 7: objective=0.04638561
2017/08/26 14:30:12 Training value function...
2017/08/26 14:30:13 step 0: mse=1.022895 step=0.100000
2017/08/26 14:30:14 step 1: mse=0.964834 step=0.100000
2017/08/26 14:30:15 step 2: mse=0.917934 step=0.100000
2017/08/26 14:30:15 step 3: mse=0.880983 step=0.100000
2017/08/26 14:30:16 step 4: mse=0.849825 step=0.100000
2017/08/26 14:30:17 step 5: mse=0.812175 step=0.100000
2017/08/26 14:30:18 step 6: mse=0.779965 step=0.100000
2017/08/26 14:30:18 step 7: mse=0.756074 step=0.100000
2017/08/26 14:30:18 Saving...
2017/08/26 14:30:18 Gathering batch of experience...
2017/08/26 14:30:36 batch 271: mean=16.688889 stddev=7.120619 entropy=1.063173 frames=36241 count=45
2017/08/26 14:30:36 Training policy...
2017/08/26 14:30:41 step 0: objective=0.05009373
2017/08/26 14:30:45 step 1: objective=0.05014501
2017/08/26 14:30:48 step 2: objective=0.050196525
2017/08/26 14:30:52 step 3: objective=0.050247192
2017/08/26 14:30:55 step 4: objective=0.050296634
2017/08/26 14:30:59 step 5: objective=0.050335463
2017/08/26 14:31:02 step 6: objective=0.050412327
2017/08/26 14:31:06 step 7: objective=0.050462183
2017/08/26 14:31:06 Training value function...
2017/08/26 14:31:07 step 0: mse=1.392450 step=0.100000
2017/08/26 14:31:08 step 1: mse=1.314950 step=0.100000
2017/08/26 14:31:09 step 2: mse=1.254187 step=0.100000
2017/08/26 14:31:09 step 3: mse=1.204529 step=0.100000
2017/08/26 14:31:10 step 4: mse=1.159931 step=0.100000
2017/08/26 14:31:11 step 5: mse=1.124493 step=0.100000
2017/08/26 14:31:12 step 6: mse=1.086158 step=0.100000
2017/08/26 14:31:12 step 7: mse=1.055746 step=0.100000
2017/08/26 14:31:12 Saving...
2017/08/26 14:31:13 Gathering batch of experience...
2017/08/26 14:31:31 batch 272: mean=15.822222 stddev=6.677621 entropy=1.070990 frames=37377 count=45
2017/08/26 14:31:31 Training policy...
2017/08/26 14:31:36 step 0: objective=0.0124119725
2017/08/26 14:31:40 step 1: objective=0.012456157
2017/08/26 14:31:43 step 2: objective=0.01250042
2017/08/26 14:31:47 step 3: objective=0.012544711
2017/08/26 14:31:51 step 4: objective=0.012586211
2017/08/26 14:31:55 step 5: objective=0.012622707
2017/08/26 14:31:58 step 6: objective=0.012657353
2017/08/26 14:32:02 step 7: objective=0.012691796
2017/08/26 14:32:02 Training value function...
2017/08/26 14:32:03 step 0: mse=0.925161 step=0.100000
2017/08/26 14:32:04 step 1: mse=0.851308 step=0.100000
2017/08/26 14:32:05 step 2: mse=0.792022 step=0.100000
2017/08/26 14:32:06 step 3: mse=0.737289 step=0.100000
2017/08/26 14:32:06 step 4: mse=0.690330 step=0.100000
2017/08/26 14:32:07 step 5: mse=0.659574 step=0.100000
2017/08/26 14:32:08 step 6: mse=0.628512 step=0.100000
2017/08/26 14:32:09 step 7: mse=0.599155 step=0.100000
2017/08/26 14:32:09 Saving...
2017/08/26 14:32:09 Gathering batch of experience...
2017/08/26 14:32:26 batch 273: mean=17.195122 stddev=5.190138 entropy=1.061467 frames=36620 count=41
2017/08/26 14:32:26 Training policy...
2017/08/26 14:32:32 step 0: objective=0.017844878
2017/08/26 14:32:35 step 1: objective=0.01790424
2017/08/26 14:32:39 step 2: objective=0.01796145
2017/08/26 14:32:43 step 3: objective=0.018020926
2017/08/26 14:32:46 step 4: objective=0.018077875
2017/08/26 14:32:50 step 5: objective=0.018132746
2017/08/26 14:32:53 step 6: objective=0.018185386
2017/08/26 14:32:57 step 7: objective=0.018228168
2017/08/26 14:32:57 Training value function...
2017/08/26 14:32:58 step 0: mse=0.810378 step=0.100000
2017/08/26 14:32:59 step 1: mse=0.758892 step=0.100000
2017/08/26 14:33:00 step 2: mse=0.714268 step=0.100000
2017/08/26 14:33:00 step 3: mse=0.677897 step=0.100000
2017/08/26 14:33:01 step 4: mse=0.645583 step=0.100000
2017/08/26 14:33:02 step 5: mse=0.620147 step=0.100000
2017/08/26 14:33:03 step 6: mse=0.596604 step=0.100000
2017/08/26 14:33:03 step 7: mse=0.576955 step=0.100000
2017/08/26 14:33:03 Saving...
2017/08/26 14:33:03 Gathering batch of experience...
2017/08/26 14:33:21 batch 274: mean=15.318182 stddev=5.911363 entropy=1.063495 frames=36202 count=44
2017/08/26 14:33:21 Training policy...
2017/08/26 14:33:26 step 0: objective=0.0057890257
2017/08/26 14:33:30 step 1: objective=0.0058826264
2017/08/26 14:33:33 step 2: objective=0.005976392
2017/08/26 14:33:37 step 3: objective=0.0060533513
2017/08/26 14:33:40 step 4: objective=0.0060975733
2017/08/26 14:33:44 step 5: objective=0.006147719
2017/08/26 14:33:48 step 6: objective=0.0061968695
2017/08/26 14:33:51 step 7: objective=0.0062299673
2017/08/26 14:33:51 Training value function...
2017/08/26 14:33:52 step 0: mse=0.798418 step=0.100000
2017/08/26 14:33:53 step 1: mse=0.753870 step=0.100000
2017/08/26 14:33:54 step 2: mse=0.719961 step=0.100000
2017/08/26 14:33:55 step 3: mse=0.690555 step=0.100000
2017/08/26 14:33:55 step 4: mse=0.659428 step=0.100000
2017/08/26 14:33:56 step 5: mse=0.637554 step=0.100000
2017/08/26 14:33:57 step 6: mse=0.621231 step=0.100000
2017/08/26 14:33:58 step 7: mse=0.603586 step=0.100000
2017/08/26 14:33:58 Saving...
2017/08/26 14:33:58 Gathering batch of experience...
2017/08/26 14:34:16 batch 275: mean=17.348837 stddev=7.448689 entropy=1.058380 frames=37083 count=43
2017/08/26 14:34:16 Training policy...
2017/08/26 14:34:21 step 0: objective=0.07014435
2017/08/26 14:34:25 step 1: objective=0.0702101
2017/08/26 14:34:28 step 2: objective=0.070275545
2017/08/26 14:34:32 step 3: objective=0.07034132
2017/08/26 14:34:36 step 4: objective=0.0704021
2017/08/26 14:34:39 step 5: objective=0.070441715
2017/08/26 14:34:43 step 6: objective=0.07048885
2017/08/26 14:34:47 step 7: objective=0.07051261
2017/08/26 14:34:47 Training value function...
2017/08/26 14:34:48 step 0: mse=1.167003 step=0.100000
2017/08/26 14:34:49 step 1: mse=1.071639 step=0.100000
2017/08/26 14:34:50 step 2: mse=0.999839 step=0.100000
2017/08/26 14:34:50 step 3: mse=0.936407 step=0.100000
2017/08/26 14:34:51 step 4: mse=0.877780 step=0.100000
2017/08/26 14:34:52 step 5: mse=0.834056 step=0.100000
2017/08/26 14:34:53 step 6: mse=0.798006 step=0.100000
2017/08/26 14:34:53 step 7: mse=0.766939 step=0.100000
2017/08/26 14:34:53 Saving...
2017/08/26 14:34:54 Gathering batch of experience...
2017/08/26 14:35:12 batch 276: mean=17.581395 stddev=7.767651 entropy=1.051623 frames=37723 count=43
2017/08/26 14:35:12 Training policy...
2017/08/26 14:35:17 step 0: objective=0.026419276
2017/08/26 14:35:21 step 1: objective=0.026497383
2017/08/26 14:35:25 step 2: objective=0.026575023
2017/08/26 14:35:28 step 3: objective=0.026652252
2017/08/26 14:35:32 step 4: objective=0.026724806
2017/08/26 14:35:36 step 5: objective=0.026782122
2017/08/26 14:35:40 step 6: objective=0.02683063
2017/08/26 14:35:43 step 7: objective=0.026901765
2017/08/26 14:35:43 Training value function...
2017/08/26 14:35:45 step 0: mse=1.056418 step=0.100000
2017/08/26 14:35:45 step 1: mse=1.001032 step=0.100000
2017/08/26 14:35:46 step 2: mse=0.957239 step=0.100000
2017/08/26 14:35:47 step 3: mse=0.915767 step=0.100000
2017/08/26 14:35:48 step 4: mse=0.891035 step=0.100000
2017/08/26 14:35:49 step 5: mse=0.863826 step=0.100000
2017/08/26 14:35:49 step 6: mse=0.841928 step=0.100000
2017/08/26 14:35:50 step 7: mse=0.817759 step=0.100000
2017/08/26 14:35:50 Saving...
2017/08/26 14:35:50 Gathering batch of experience...
2017/08/26 14:36:08 batch 277: mean=18.581395 stddev=8.147571 entropy=1.054004 frames=37474 count=43
2017/08/26 14:36:08 Training policy...
2017/08/26 14:36:14 step 0: objective=0.06866277
2017/08/26 14:36:18 step 1: objective=0.06870876
2017/08/26 14:36:21 step 2: objective=0.068754405
2017/08/26 14:36:25 step 3: objective=0.0688089
2017/08/26 14:36:29 step 4: objective=0.06886186
2017/08/26 14:36:33 step 5: objective=0.06890569
2017/08/26 14:36:36 step 6: objective=0.06896586
2017/08/26 14:36:40 step 7: objective=0.0690122
2017/08/26 14:36:40 Training value function...
2017/08/26 14:36:41 step 0: mse=1.281335 step=0.100000
2017/08/26 14:36:42 step 1: mse=1.199565 step=0.100000
2017/08/26 14:36:43 step 2: mse=1.132891 step=0.100000
2017/08/26 14:36:44 step 3: mse=1.068757 step=0.100000
2017/08/26 14:36:44 step 4: mse=1.019434 step=0.100000
2017/08/26 14:36:45 step 5: mse=0.981995 step=0.100000
2017/08/26 14:36:46 step 6: mse=0.950833 step=0.100000
2017/08/26 14:36:47 step 7: mse=0.914673 step=0.100000
2017/08/26 14:36:47 Saving...
2017/08/26 14:36:47 Gathering batch of experience...
2017/08/26 14:37:04 batch 278: mean=15.244444 stddev=6.525695 entropy=1.067147 frames=35839 count=45
2017/08/26 14:37:04 Training policy...
2017/08/26 14:37:10 step 0: objective=0.011428699
2017/08/26 14:37:13 step 1: objective=0.011461667
2017/08/26 14:37:17 step 2: objective=0.011494688
2017/08/26 14:37:20 step 3: objective=0.011527632
2017/08/26 14:37:24 step 4: objective=0.011560647
2017/08/26 14:37:27 step 5: objective=0.0115938345
2017/08/26 14:37:31 step 6: objective=0.011626327
2017/08/26 14:37:35 step 7: objective=0.0116615975
2017/08/26 14:37:35 Training value function...
2017/08/26 14:37:36 step 0: mse=0.836834 step=0.100000
2017/08/26 14:37:37 step 1: mse=0.778592 step=0.100000
2017/08/26 14:37:37 step 2: mse=0.732218 step=0.100000
2017/08/26 14:37:38 step 3: mse=0.697890 step=0.100000
2017/08/26 14:37:39 step 4: mse=0.666355 step=0.100000
2017/08/26 14:37:40 step 5: mse=0.645297 step=0.100000
2017/08/26 14:37:40 step 6: mse=0.622779 step=0.100000
2017/08/26 14:37:41 step 7: mse=0.607392 step=0.100000
2017/08/26 14:37:41 Saving...
2017/08/26 14:37:41 Gathering batch of experience...
2017/08/26 14:38:00 batch 279: mean=17.800000 stddev=7.511769 entropy=1.054694 frames=38383 count=45
2017/08/26 14:38:00 Training policy...
2017/08/26 14:38:05 step 0: objective=0.060259342
2017/08/26 14:38:09 step 1: objective=0.060315095
2017/08/26 14:38:13 step 2: objective=0.060370725
2017/08/26 14:38:17 step 3: objective=0.060426533
2017/08/26 14:38:21 step 4: objective=0.060477257
2017/08/26 14:38:24 step 5: objective=0.06053037
2017/08/26 14:38:28 step 6: objective=0.06057706
2017/08/26 14:38:32 step 7: objective=0.060628407
2017/08/26 14:38:32 Training value function...
2017/08/26 14:38:33 step 0: mse=1.246609 step=0.100000
2017/08/26 14:38:34 step 1: mse=1.149893 step=0.100000
2017/08/26 14:38:35 step 2: mse=1.070563 step=0.100000
2017/08/26 14:38:36 step 3: mse=1.002379 step=0.100000
2017/08/26 14:38:37 step 4: mse=0.947128 step=0.100000
2017/08/26 14:38:37 step 5: mse=0.902226 step=0.100000
2017/08/26 14:38:38 step 6: mse=0.866962 step=0.100000
2017/08/26 14:38:39 step 7: mse=0.833549 step=0.100000
2017/08/26 14:38:39 Saving...
2017/08/26 14:38:39 Gathering batch of experience...
2017/08/26 14:38:56 batch 280: mean=17.116279 stddev=7.622517 entropy=1.072071 frames=35420 count=43
2017/08/26 14:38:56 Training policy...
2017/08/26 14:39:01 step 0: objective=0.024383444
2017/08/26 14:39:05 step 1: objective=0.02447691
2017/08/26 14:39:08 step 2: objective=0.024582546
2017/08/26 14:39:12 step 3: objective=0.024685226
2017/08/26 14:39:16 step 4: objective=0.024787376
2017/08/26 14:39:19 step 5: objective=0.024875054
2017/08/26 14:39:23 step 6: objective=0.024926918
2017/08/26 14:39:26 step 7: objective=0.025008643
2017/08/26 14:39:26 Training value function...
2017/08/26 14:39:27 step 0: mse=1.355506 step=0.100000
2017/08/26 14:39:28 step 1: mse=1.280701 step=0.100000
2017/08/26 14:39:29 step 2: mse=1.207326 step=0.100000
2017/08/26 14:39:30 step 3: mse=1.150884 step=0.100000
2017/08/26 14:39:30 step 4: mse=1.103064 step=0.100000
2017/08/26 14:39:31 step 5: mse=1.058695 step=0.100000
2017/08/26 14:39:32 step 6: mse=1.007988 step=0.100000
2017/08/26 14:39:33 step 7: mse=0.976875 step=0.100000
2017/08/26 14:39:33 Saving...
2017/08/26 14:39:33 Gathering batch of experience...
2017/08/26 14:39:50 batch 281: mean=17.951220 stddev=9.066021 entropy=1.045862 frames=35349 count=41
2017/08/26 14:39:50 Training policy...
2017/08/26 14:39:55 step 0: objective=0.018263552
2017/08/26 14:39:59 step 1: objective=0.018367235
2017/08/26 14:40:02 step 2: objective=0.018470814
2017/08/26 14:40:06 step 3: objective=0.01857171
2017/08/26 14:40:09 step 4: objective=0.018642105
2017/08/26 14:40:13 step 5: objective=0.018705199
2017/08/26 14:40:16 step 6: objective=0.018769924
2017/08/26 14:40:20 step 7: objective=0.018826753
2017/08/26 14:40:20 Training value function...
2017/08/26 14:40:21 step 0: mse=1.197485 step=0.100000
2017/08/26 14:40:22 step 1: mse=1.122107 step=0.100000
2017/08/26 14:40:22 step 2: mse=1.066340 step=0.100000
2017/08/26 14:40:23 step 3: mse=1.008166 step=0.100000
2017/08/26 14:40:24 step 4: mse=0.952953 step=0.100000
2017/08/26 14:40:25 step 5: mse=0.921389 step=0.100000
2017/08/26 14:40:25 step 6: mse=0.889252 step=0.100000
2017/08/26 14:40:26 step 7: mse=0.847756 step=0.100000
2017/08/26 14:40:26 Saving...
2017/08/26 14:40:26 Gathering batch of experience...
2017/08/26 14:40:44 batch 282: mean=17.727273 stddev=8.252723 entropy=1.058924 frames=36893 count=44
2017/08/26 14:40:44 Training policy...
2017/08/26 14:40:50 step 0: objective=0.033861328
2017/08/26 14:40:53 step 1: objective=0.0339479
2017/08/26 14:40:57 step 2: objective=0.034033507
2017/08/26 14:41:01 step 3: objective=0.03411616
2017/08/26 14:41:04 step 4: objective=0.034182556
2017/08/26 14:41:08 step 5: objective=0.03425076
2017/08/26 14:41:12 step 6: objective=0.03429438
2017/08/26 14:41:15 step 7: objective=0.034370616
2017/08/26 14:41:15 Training value function...
2017/08/26 14:41:17 step 0: mse=1.338339 step=0.100000
2017/08/26 14:41:18 step 1: mse=1.245349 step=0.100000
2017/08/26 14:41:18 step 2: mse=1.170499 step=0.100000
2017/08/26 14:41:19 step 3: mse=1.115755 step=0.100000
2017/08/26 14:41:20 step 4: mse=1.077119 step=0.100000
2017/08/26 14:41:21 step 5: mse=1.015505 step=0.100000
2017/08/26 14:41:21 step 6: mse=0.987858 step=0.100000
2017/08/26 14:41:22 step 7: mse=0.940222 step=0.100000
2017/08/26 14:41:22 Saving...
2017/08/26 14:41:22 Gathering batch of experience...
2017/08/26 14:41:40 batch 283: mean=15.195652 stddev=6.347268 entropy=1.069960 frames=36262 count=46
2017/08/26 14:41:40 Training policy...
2017/08/26 14:41:45 step 0: objective=0.0087569505
2017/08/26 14:41:49 step 1: objective=0.00879498
2017/08/26 14:41:53 step 2: objective=0.008832903
2017/08/26 14:41:56 step 3: objective=0.008870696
2017/08/26 14:42:00 step 4: objective=0.008908242
2017/08/26 14:42:03 step 5: objective=0.008945719
2017/08/26 14:42:07 step 6: objective=0.008981929
2017/08/26 14:42:11 step 7: objective=0.009012358
2017/08/26 14:42:11 Training value function...
2017/08/26 14:42:12 step 0: mse=0.776782 step=0.100000
2017/08/26 14:42:13 step 1: mse=0.747815 step=0.100000
2017/08/26 14:42:13 step 2: mse=0.724568 step=0.100000
2017/08/26 14:42:14 step 3: mse=0.706903 step=0.100000
2017/08/26 14:42:15 step 4: mse=0.687663 step=0.100000
2017/08/26 14:42:16 step 5: mse=0.666507 step=0.100000
2017/08/26 14:42:16 step 6: mse=0.648957 step=0.100000
2017/08/26 14:42:17 step 7: mse=0.638252 step=0.100000
2017/08/26 14:42:17 Saving...
2017/08/26 14:42:17 Gathering batch of experience...
2017/08/26 14:42:36 batch 284: mean=17.627907 stddev=7.246565 entropy=1.058664 frames=37671 count=43
2017/08/26 14:42:36 Training policy...
2017/08/26 14:42:41 step 0: objective=0.039405618
2017/08/26 14:42:45 step 1: objective=0.039477546
2017/08/26 14:42:49 step 2: objective=0.03953486
2017/08/26 14:42:52 step 3: objective=0.039595336
2017/08/26 14:42:56 step 4: objective=0.039656032
2017/08/26 14:43:00 step 5: objective=0.03971426
2017/08/26 14:43:04 step 6: objective=0.03978334
2017/08/26 14:43:08 step 7: objective=0.03984563
2017/08/26 14:43:08 Training value function...
2017/08/26 14:43:09 step 0: mse=1.153143 step=0.100000
2017/08/26 14:43:10 step 1: mse=1.070205 step=0.100000
2017/08/26 14:43:10 step 2: mse=1.002589 step=0.100000
2017/08/26 14:43:11 step 3: mse=0.926589 step=0.100000
2017/08/26 14:43:12 step 4: mse=0.879619 step=0.100000
2017/08/26 14:43:13 step 5: mse=0.825182 step=0.100000
2017/08/26 14:43:14 step 6: mse=0.783305 step=0.100000
2017/08/26 14:43:14 step 7: mse=0.748976 step=0.100000
2017/08/26 14:43:14 Saving...
2017/08/26 14:43:14 Gathering batch of experience...
2017/08/26 14:43:32 batch 285: mean=18.095238 stddev=7.282757 entropy=1.063994 frames=36306 count=42
2017/08/26 14:43:32 Training policy...
2017/08/26 14:43:37 step 0: objective=0.051455103
2017/08/26 14:43:41 step 1: objective=0.051534344
2017/08/26 14:43:45 step 2: objective=0.051613577
2017/08/26 14:43:48 step 3: objective=0.051689073
2017/08/26 14:43:52 step 4: objective=0.051739544
2017/08/26 14:43:56 step 5: objective=0.051788244
2017/08/26 14:43:59 step 6: objective=0.05183013
2017/08/26 14:44:03 step 7: objective=0.05187292
2017/08/26 14:44:03 Training value function...
2017/08/26 14:44:04 step 0: mse=1.281795 step=0.100000
2017/08/26 14:44:05 step 1: mse=1.233142 step=0.100000
2017/08/26 14:44:06 step 2: mse=1.162179 step=0.100000
2017/08/26 14:44:07 step 3: mse=1.103255 step=0.100000
2017/08/26 14:44:07 step 4: mse=1.048132 step=0.100000
2017/08/26 14:44:08 step 5: mse=1.020564 step=0.100000
2017/08/26 14:44:09 step 6: mse=0.977583 step=0.100000
2017/08/26 14:44:10 step 7: mse=0.959183 step=0.100000
2017/08/26 14:44:10 Saving...
2017/08/26 14:44:10 Gathering batch of experience...
2017/08/26 14:44:28 batch 286: mean=17.068182 stddev=6.988295 entropy=1.058383 frames=37398 count=44
2017/08/26 14:44:28 Training policy...
2017/08/26 14:44:34 step 0: objective=0.015113937
2017/08/26 14:44:37 step 1: objective=0.015178303
2017/08/26 14:44:41 step 2: objective=0.015242888
2017/08/26 14:44:45 step 3: objective=0.015307417
2017/08/26 14:44:49 step 4: objective=0.01537173
2017/08/26 14:44:53 step 5: objective=0.015431151
2017/08/26 14:44:56 step 6: objective=0.015494726
2017/08/26 14:45:00 step 7: objective=0.015547618
2017/08/26 14:45:00 Training value function...
2017/08/26 14:45:01 step 0: mse=0.980893 step=0.100000
2017/08/26 14:45:02 step 1: mse=0.934605 step=0.100000
2017/08/26 14:45:03 step 2: mse=0.897599 step=0.100000
2017/08/26 14:45:04 step 3: mse=0.864071 step=0.100000
2017/08/26 14:45:05 step 4: mse=0.836676 step=0.100000
2017/08/26 14:45:05 step 5: mse=0.785881 step=0.100000
2017/08/26 14:45:06 step 6: mse=0.744655 step=0.100000
2017/08/26 14:45:07 step 7: mse=0.711187 step=0.100000
2017/08/26 14:45:07 Saving...
2017/08/26 14:45:07 Gathering batch of experience...
2017/08/26 14:45:25 batch 287: mean=15.978261 stddev=8.052785 entropy=1.058832 frames=37160 count=46
2017/08/26 14:45:25 Training policy...
2017/08/26 14:45:31 step 0: objective=0.01717538
2017/08/26 14:45:34 step 1: objective=0.017241454
2017/08/26 14:45:38 step 2: objective=0.017307889
2017/08/26 14:45:42 step 3: objective=0.017400183
2017/08/26 14:45:46 step 4: objective=0.01749168
2017/08/26 14:45:50 step 5: objective=0.017545946
2017/08/26 14:45:53 step 6: objective=0.017597623
2017/08/26 14:45:57 step 7: objective=0.01764313
2017/08/26 14:45:57 Training value function...
2017/08/26 14:45:58 step 0: mse=0.954727 step=0.100000
2017/08/26 14:45:59 step 1: mse=0.888196 step=0.100000
2017/08/26 14:46:00 step 2: mse=0.834749 step=0.100000
2017/08/26 14:46:01 step 3: mse=0.802982 step=0.100000
2017/08/26 14:46:01 step 4: mse=0.771603 step=0.100000
2017/08/26 14:46:02 step 5: mse=0.739872 step=0.100000
2017/08/26 14:46:03 step 6: mse=0.710953 step=0.100000
2017/08/26 14:46:04 step 7: mse=0.685629 step=0.100000
2017/08/26 14:46:04 Saving...
2017/08/26 14:46:04 Gathering batch of experience...
2017/08/26 14:46:21 batch 288: mean=17.477273 stddev=7.340698 entropy=1.060339 frames=36791 count=44
2017/08/26 14:46:21 Training policy...
2017/08/26 14:46:27 step 0: objective=0.04373483
2017/08/26 14:46:31 step 1: objective=0.043837234
2017/08/26 14:46:34 step 2: objective=0.04393941
2017/08/26 14:46:38 step 3: objective=0.04403818
2017/08/26 14:46:42 step 4: objective=0.044072207
2017/08/26 14:46:46 step 5: objective=0.044104863
2017/08/26 14:46:49 step 6: objective=0.044207893
2017/08/26 14:46:53 step 7: objective=0.044271294
2017/08/26 14:46:53 Training value function...
2017/08/26 14:46:54 step 0: mse=1.271986 step=0.100000
2017/08/26 14:46:55 step 1: mse=1.171966 step=0.100000
2017/08/26 14:46:56 step 2: mse=1.090672 step=0.100000
2017/08/26 14:46:57 step 3: mse=1.017590 step=0.100000
2017/08/26 14:46:57 step 4: mse=0.954047 step=0.100000
2017/08/26 14:46:58 step 5: mse=0.907961 step=0.100000
2017/08/26 14:46:59 step 6: mse=0.868359 step=0.100000
2017/08/26 14:47:00 step 7: mse=0.828928 step=0.100000
2017/08/26 14:47:00 Saving...
2017/08/26 14:47:00 Gathering batch of experience...
2017/08/26 14:47:18 batch 289: mean=16.568182 stddev=5.503708 entropy=1.066361 frames=37031 count=44
2017/08/26 14:47:18 Training policy...
2017/08/26 14:47:23 step 0: objective=0.031251088
2017/08/26 14:47:27 step 1: objective=0.031297613
2017/08/26 14:47:31 step 2: objective=0.03134374
2017/08/26 14:47:34 step 3: objective=0.03138987
2017/08/26 14:47:38 step 4: objective=0.03143551
2017/08/26 14:47:42 step 5: objective=0.031479396
2017/08/26 14:47:46 step 6: objective=0.0315182
2017/08/26 14:47:49 step 7: objective=0.031557206
2017/08/26 14:47:49 Training value function...
2017/08/26 14:47:51 step 0: mse=0.823072 step=0.100000
2017/08/26 14:47:52 step 1: mse=0.779116 step=0.100000
2017/08/26 14:47:52 step 2: mse=0.743361 step=0.100000
2017/08/26 14:47:53 step 3: mse=0.714361 step=0.100000
2017/08/26 14:47:54 step 4: mse=0.679985 step=0.100000
2017/08/26 14:47:54 step 5: mse=0.654399 step=0.100000
2017/08/26 14:47:55 step 6: mse=0.636375 step=0.100000
2017/08/26 14:47:56 step 7: mse=0.617268 step=0.100000
2017/08/26 14:47:56 Saving...
2017/08/26 14:47:56 Gathering batch of experience...
2017/08/26 14:48:14 batch 290: mean=14.333333 stddev=5.705748 entropy=1.073956 frames=36538 count=48
2017/08/26 14:48:14 Training policy...
2017/08/26 14:48:19 step 0: objective=0.0019154971
2017/08/26 14:48:23 step 1: objective=0.0019868247
2017/08/26 14:48:27 step 2: objective=0.0020587977
2017/08/26 14:48:30 step 3: objective=0.002131212
2017/08/26 14:48:34 step 4: objective=0.002189139
2017/08/26 14:48:38 step 5: objective=0.002234217
2017/08/26 14:48:42 step 6: objective=0.002268193
2017/08/26 14:48:45 step 7: objective=0.002301289
2017/08/26 14:48:45 Training value function...
2017/08/26 14:48:47 step 0: mse=0.747964 step=0.100000
2017/08/26 14:48:47 step 1: mse=0.710653 step=0.100000
2017/08/26 14:48:48 step 2: mse=0.680430 step=0.100000
2017/08/26 14:48:49 step 3: mse=0.656992 step=0.100000
2017/08/26 14:48:50 step 4: mse=0.637181 step=0.100000
2017/08/26 14:48:51 step 5: mse=0.618296 step=0.100000
2017/08/26 14:48:51 step 6: mse=0.603286 step=0.100000
2017/08/26 14:48:52 step 7: mse=0.589757 step=0.100000
2017/08/26 14:48:52 Saving...
2017/08/26 14:48:52 Gathering batch of experience...
2017/08/26 14:49:10 batch 291: mean=15.600000 stddev=6.967863 entropy=1.066495 frames=36755 count=45
2017/08/26 14:49:10 Training policy...
2017/08/26 14:49:16 step 0: objective=0.040478047
2017/08/26 14:49:19 step 1: objective=0.04053473
2017/08/26 14:49:23 step 2: objective=0.04058576
2017/08/26 14:49:27 step 3: objective=0.04063653
2017/08/26 14:49:31 step 4: objective=0.04068317
2017/08/26 14:49:35 step 5: objective=0.040729858
2017/08/26 14:49:38 step 6: objective=0.040776007
2017/08/26 14:49:42 step 7: objective=0.040811017
2017/08/26 14:49:42 Training value function...
2017/08/26 14:49:43 step 0: mse=0.783478 step=0.100000
2017/08/26 14:49:44 step 1: mse=0.735697 step=0.100000
2017/08/26 14:49:45 step 2: mse=0.696304 step=0.100000
2017/08/26 14:49:46 step 3: mse=0.663531 step=0.100000
2017/08/26 14:49:46 step 4: mse=0.636411 step=0.100000
2017/08/26 14:49:47 step 5: mse=0.608645 step=0.100000
2017/08/26 14:49:48 step 6: mse=0.586103 step=0.100000
2017/08/26 14:49:49 step 7: mse=0.568208 step=0.100000
2017/08/26 14:49:49 Saving...
2017/08/26 14:49:49 Gathering batch of experience...
2017/08/26 14:50:07 batch 292: mean=16.954545 stddev=7.739963 entropy=1.054318 frames=37066 count=44
2017/08/26 14:50:07 Training policy...
2017/08/26 14:50:12 step 0: objective=0.04200448
2017/08/26 14:50:16 step 1: objective=0.042126704
2017/08/26 14:50:20 step 2: objective=0.042248327
2017/08/26 14:50:24 step 3: objective=0.042353034
2017/08/26 14:50:27 step 4: objective=0.042383358
2017/08/26 14:50:31 step 5: objective=0.04241645
2017/08/26 14:50:35 step 6: objective=0.042497057
2017/08/26 14:50:39 step 7: objective=0.042543847
2017/08/26 14:50:39 Training value function...
2017/08/26 14:50:40 step 0: mse=1.275839 step=0.100000
2017/08/26 14:50:41 step 1: mse=1.194922 step=0.100000
2017/08/26 14:50:42 step 2: mse=1.129556 step=0.100000
2017/08/26 14:50:42 step 3: mse=1.077694 step=0.100000
2017/08/26 14:50:43 step 4: mse=1.033077 step=0.100000
2017/08/26 14:50:44 step 5: mse=0.984730 step=0.100000
2017/08/26 14:50:45 step 6: mse=0.949048 step=0.100000
2017/08/26 14:50:45 step 7: mse=0.922588 step=0.100000
2017/08/26 14:50:45 Saving...
2017/08/26 14:50:45 Gathering batch of experience...
2017/08/26 14:51:03 batch 293: mean=16.363636 stddev=5.756778 entropy=1.070367 frames=36046 count=44
2017/08/26 14:51:03 Training policy...
2017/08/26 14:51:08 step 0: objective=0.029715251
2017/08/26 14:51:12 step 1: objective=0.029750982
2017/08/26 14:51:16 step 2: objective=0.029786626
2017/08/26 14:51:19 step 3: objective=0.029822279
2017/08/26 14:51:23 step 4: objective=0.029857868
2017/08/26 14:51:27 step 5: objective=0.029893447
2017/08/26 14:51:31 step 6: objective=0.029928403
2017/08/26 14:51:34 step 7: objective=0.029989658
2017/08/26 14:51:34 Training value function...
2017/08/26 14:51:36 step 0: mse=1.022841 step=0.100000
2017/08/26 14:51:36 step 1: mse=0.980122 step=0.100000
2017/08/26 14:51:37 step 2: mse=0.934602 step=0.100000
2017/08/26 14:51:38 step 3: mse=0.902337 step=0.100000
2017/08/26 14:51:38 step 4: mse=0.865351 step=0.100000
2017/08/26 14:51:39 step 5: mse=0.846881 step=0.100000
2017/08/26 14:51:40 step 6: mse=0.817567 step=0.100000
2017/08/26 14:51:40 step 7: mse=0.797351 step=0.100000
2017/08/26 14:51:40 Saving...
2017/08/26 14:51:41 Gathering batch of experience...
2017/08/26 14:51:59 batch 294: mean=17.454545 stddev=7.056443 entropy=1.057393 frames=37329 count=44
2017/08/26 14:51:59 Training policy...
2017/08/26 14:52:04 step 0: objective=0.028252035
2017/08/26 14:52:08 step 1: objective=0.02833237
2017/08/26 14:52:12 step 2: objective=0.02841224
2017/08/26 14:52:16 step 3: objective=0.028491203
2017/08/26 14:52:20 step 4: objective=0.028560134
2017/08/26 14:52:23 step 5: objective=0.02861772
2017/08/26 14:52:27 step 6: objective=0.028644731
2017/08/26 14:52:31 step 7: objective=0.02867525
2017/08/26 14:52:31 Training value function...
2017/08/26 14:52:32 step 0: mse=0.975893 step=0.100000
2017/08/26 14:52:33 step 1: mse=0.925552 step=0.100000
2017/08/26 14:52:34 step 2: mse=0.876231 step=0.100000
2017/08/26 14:52:35 step 3: mse=0.843213 step=0.100000
2017/08/26 14:52:36 step 4: mse=0.808958 step=0.100000
2017/08/26 14:52:36 step 5: mse=0.784027 step=0.100000
2017/08/26 14:52:37 step 6: mse=0.758171 step=0.100000
2017/08/26 14:52:38 step 7: mse=0.737786 step=0.100000
2017/08/26 14:52:38 Saving...
2017/08/26 14:52:38 Gathering batch of experience...
2017/08/26 14:52:56 batch 295: mean=17.181818 stddev=7.997934 entropy=1.068002 frames=36757 count=44
2017/08/26 14:52:56 Training policy...
2017/08/26 14:53:01 step 0: objective=0.049239267
2017/08/26 14:53:05 step 1: objective=0.049305003
2017/08/26 14:53:09 step 2: objective=0.04937108
2017/08/26 14:53:12 step 3: objective=0.049435906
2017/08/26 14:53:16 step 4: objective=0.04949112
2017/08/26 14:53:20 step 5: objective=0.04953247
2017/08/26 14:53:24 step 6: objective=0.04956904
2017/08/26 14:53:28 step 7: objective=0.04962443
2017/08/26 14:53:28 Training value function...
2017/08/26 14:53:29 step 0: mse=0.993853 step=0.100000
2017/08/26 14:53:30 step 1: mse=0.933469 step=0.100000
2017/08/26 14:53:30 step 2: mse=0.878163 step=0.100000
2017/08/26 14:53:31 step 3: mse=0.834146 step=0.100000
2017/08/26 14:53:32 step 4: mse=0.793021 step=0.100000
2017/08/26 14:53:33 step 5: mse=0.760581 step=0.100000
2017/08/26 14:53:33 step 6: mse=0.733643 step=0.100000
2017/08/26 14:53:34 step 7: mse=0.710666 step=0.100000
2017/08/26 14:53:34 Saving...
2017/08/26 14:53:34 Gathering batch of experience...
2017/08/26 14:53:53 batch 296: mean=16.022222 stddev=5.264088 entropy=1.072626 frames=36928 count=45
2017/08/26 14:53:53 Training policy...
2017/08/26 14:53:58 step 0: objective=0.009569986
2017/08/26 14:54:02 step 1: objective=0.009599963
2017/08/26 14:54:06 step 2: objective=0.0096295765
2017/08/26 14:54:10 step 3: objective=0.00965879
2017/08/26 14:54:13 step 4: objective=0.009687625
2017/08/26 14:54:17 step 5: objective=0.0097160665
2017/08/26 14:54:21 step 6: objective=0.009742937
2017/08/26 14:54:25 step 7: objective=0.009777637
2017/08/26 14:54:25 Training value function...
2017/08/26 14:54:26 step 0: mse=0.768863 step=0.100000
2017/08/26 14:54:27 step 1: mse=0.726384 step=0.100000
2017/08/26 14:54:28 step 2: mse=0.690359 step=0.100000
2017/08/26 14:54:28 step 3: mse=0.660866 step=0.100000
2017/08/26 14:54:29 step 4: mse=0.637013 step=0.100000
2017/08/26 14:54:30 step 5: mse=0.617471 step=0.100000
2017/08/26 14:54:31 step 6: mse=0.602934 step=0.100000
2017/08/26 14:54:32 step 7: mse=0.588933 step=0.100000
2017/08/26 14:54:32 Saving...
2017/08/26 14:54:32 Gathering batch of experience...
2017/08/26 14:54:50 batch 297: mean=16.250000 stddev=6.428364 entropy=1.068922 frames=36905 count=44
2017/08/26 14:54:50 Training policy...
2017/08/26 14:54:55 step 0: objective=0.01608992
2017/08/26 14:54:59 step 1: objective=0.016131943
2017/08/26 14:55:03 step 2: objective=0.016173573
2017/08/26 14:55:07 step 3: objective=0.016215157
2017/08/26 14:55:10 step 4: objective=0.016256427
2017/08/26 14:55:14 step 5: objective=0.016296374
2017/08/26 14:55:18 step 6: objective=0.016328635
2017/08/26 14:55:22 step 7: objective=0.016367396
2017/08/26 14:55:22 Training value function...
2017/08/26 14:55:23 step 0: mse=0.928089 step=0.100000
2017/08/26 14:55:24 step 1: mse=0.878081 step=0.100000
2017/08/26 14:55:25 step 2: mse=0.837609 step=0.100000
2017/08/26 14:55:26 step 3: mse=0.802521 step=0.100000
2017/08/26 14:55:26 step 4: mse=0.772549 step=0.100000
2017/08/26 14:55:27 step 5: mse=0.748331 step=0.100000
2017/08/26 14:55:28 step 6: mse=0.728174 step=0.100000
2017/08/26 14:55:29 step 7: mse=0.691744 step=0.100000
2017/08/26 14:55:29 Saving...
2017/08/26 14:55:29 Gathering batch of experience...
2017/08/26 14:55:47 batch 298: mean=15.723404 stddev=6.228630 entropy=1.069909 frames=36410 count=47
2017/08/26 14:55:47 Training policy...
2017/08/26 14:55:52 step 0: objective=0.035923034
2017/08/26 14:55:56 step 1: objective=0.036000304
2017/08/26 14:55:59 step 2: objective=0.036078244
2017/08/26 14:56:03 step 3: objective=0.036156114
2017/08/26 14:56:07 step 4: objective=0.036216043
2017/08/26 14:56:11 step 5: objective=0.03626778
2017/08/26 14:56:15 step 6: objective=0.03632148
2017/08/26 14:56:18 step 7: objective=0.036392245
2017/08/26 14:56:18 Training value function...
2017/08/26 14:56:20 step 0: mse=1.067468 step=0.100000
2017/08/26 14:56:20 step 1: mse=1.011519 step=0.100000
2017/08/26 14:56:21 step 2: mse=0.965770 step=0.100000
2017/08/26 14:56:22 step 3: mse=0.929364 step=0.100000
2017/08/26 14:56:23 step 4: mse=0.899428 step=0.100000
2017/08/26 14:56:23 step 5: mse=0.865055 step=0.100000
2017/08/26 14:56:24 step 6: mse=0.837973 step=0.100000
2017/08/26 14:56:25 step 7: mse=0.815721 step=0.100000
2017/08/26 14:56:25 Saving...
2017/08/26 14:56:25 Gathering batch of experience...
2017/08/26 14:56:43 batch 299: mean=17.155556 stddev=7.921716 entropy=1.066306 frames=36838 count=45
2017/08/26 14:56:43 Training policy...
2017/08/26 14:56:48 step 0: objective=0.04391563
2017/08/26 14:56:52 step 1: objective=0.043949526
2017/08/26 14:56:56 step 2: objective=0.04398302
2017/08/26 14:57:00 step 3: objective=0.04401656
2017/08/26 14:57:04 step 4: objective=0.04405027
2017/08/26 14:57:08 step 5: objective=0.044078913
2017/08/26 14:57:11 step 6: objective=0.04410172
2017/08/26 14:57:15 step 7: objective=0.044164784
2017/08/26 14:57:15 Training value function...
2017/08/26 14:57:16 step 0: mse=1.178586 step=0.100000
2017/08/26 14:57:17 step 1: mse=1.097957 step=0.100000
2017/08/26 14:57:18 step 2: mse=1.027359 step=0.100000
2017/08/26 14:57:19 step 3: mse=0.969377 step=0.100000
2017/08/26 14:57:20 step 4: mse=0.922126 step=0.100000
2017/08/26 14:57:20 step 5: mse=0.880819 step=0.100000
2017/08/26 14:57:21 step 6: mse=0.846916 step=0.100000
2017/08/26 14:57:22 step 7: mse=0.819234 step=0.100000
2017/08/26 14:57:22 Saving...
2017/08/26 14:57:22 Gathering batch of experience...
2017/08/26 14:57:40 batch 300: mean=16.977778 stddev=8.391766 entropy=1.065338 frames=37377 count=45
2017/08/26 14:57:40 Training policy...
2017/08/26 14:57:46 step 0: objective=0.039092734
2017/08/26 14:57:50 step 1: objective=0.039200183
2017/08/26 14:57:53 step 2: objective=0.039307207
2017/08/26 14:57:57 step 3: objective=0.03939988
2017/08/26 14:58:01 step 4: objective=0.039497532
2017/08/26 14:58:05 step 5: objective=0.039545972
2017/08/26 14:58:09 step 6: objective=0.03960251
2017/08/26 14:58:13 step 7: objective=0.03965541
2017/08/26 14:58:13 Training value function...
2017/08/26 14:58:14 step 0: mse=1.209139 step=0.100000
2017/08/26 14:58:15 step 1: mse=1.146250 step=0.100000
2017/08/26 14:58:16 step 2: mse=1.086265 step=0.100000
2017/08/26 14:58:16 step 3: mse=1.043688 step=0.100000
2017/08/26 14:58:17 step 4: mse=1.001799 step=0.100000
2017/08/26 14:58:18 step 5: mse=0.971827 step=0.100000
2017/08/26 14:58:19 step 6: mse=0.945811 step=0.100000
2017/08/26 14:58:20 step 7: mse=0.924874 step=0.100000
2017/08/26 14:58:20 Saving...
2017/08/26 14:58:20 Gathering batch of experience...
2017/08/26 14:58:37 batch 301: mean=15.108696 stddev=8.937533 entropy=1.059655 frames=36111 count=46
2017/08/26 14:58:37 Training policy...
2017/08/26 14:58:43 step 0: objective=0.012138913
2017/08/26 14:58:46 step 1: objective=0.012220691
2017/08/26 14:58:50 step 2: objective=0.012302629
2017/08/26 14:58:54 step 3: objective=0.012377837
2017/08/26 14:58:58 step 4: objective=0.01242236
2017/08/26 14:59:01 step 5: objective=0.012472774
2017/08/26 14:59:05 step 6: objective=0.012524829
2017/08/26 14:59:09 step 7: objective=0.012571453
2017/08/26 14:59:09 Training value function...
2017/08/26 14:59:10 step 0: mse=1.089383 step=0.100000
2017/08/26 14:59:11 step 1: mse=0.979771 step=0.100000
2017/08/26 14:59:12 step 2: mse=0.891484 step=0.100000
2017/08/26 14:59:12 step 3: mse=0.820496 step=0.100000
2017/08/26 14:59:13 step 4: mse=0.762826 step=0.100000
2017/08/26 14:59:14 step 5: mse=0.719606 step=0.100000
2017/08/26 14:59:15 step 6: mse=0.676027 step=0.100000
2017/08/26 14:59:16 step 7: mse=0.641079 step=0.100000
2017/08/26 14:59:16 Saving...
2017/08/26 14:59:16 Gathering batch of experience...
2017/08/26 14:59:33 batch 302: mean=14.276596 stddev=5.927585 entropy=1.066166 frames=35756 count=47
2017/08/26 14:59:33 Training policy...
2017/08/26 14:59:38 step 0: objective=0.030899292
2017/08/26 14:59:42 step 1: objective=0.030948918
2017/08/26 14:59:46 step 2: objective=0.030998236
2017/08/26 14:59:50 step 3: objective=0.031047625
2017/08/26 14:59:53 step 4: objective=0.031096473
2017/08/26 14:59:57 step 5: objective=0.031143628
2017/08/26 15:00:01 step 6: objective=0.031192867
2017/08/26 15:00:05 step 7: objective=0.031238778
2017/08/26 15:00:05 Training value function...
2017/08/26 15:00:06 step 0: mse=0.706790 step=0.100000
2017/08/26 15:00:06 step 1: mse=0.669544 step=0.100000
2017/08/26 15:00:07 step 2: mse=0.647685 step=0.100000
2017/08/26 15:00:08 step 3: mse=0.629903 step=0.100000
2017/08/26 15:00:09 step 4: mse=0.610535 step=0.100000
2017/08/26 15:00:09 step 5: mse=0.586570 step=0.100000
2017/08/26 15:00:10 step 6: mse=0.574520 step=0.100000
2017/08/26 15:00:11 step 7: mse=0.562932 step=0.100000
2017/08/26 15:00:11 Saving...
2017/08/26 15:00:11 Gathering batch of experience...
2017/08/26 15:00:29 batch 303: mean=17.261905 stddev=6.761444 entropy=1.051842 frames=36380 count=42
2017/08/26 15:00:29 Training policy...
2017/08/26 15:00:34 step 0: objective=0.051401317
2017/08/26 15:00:38 step 1: objective=0.05148972
2017/08/26 15:00:42 step 2: objective=0.051578864
2017/08/26 15:00:45 step 3: objective=0.051659178
2017/08/26 15:00:49 step 4: objective=0.05174871
2017/08/26 15:00:53 step 5: objective=0.051823426
2017/08/26 15:00:57 step 6: objective=0.051903117
2017/08/26 15:01:01 step 7: objective=0.051970482
2017/08/26 15:01:01 Training value function...
2017/08/26 15:01:02 step 0: mse=1.016711 step=0.100000
2017/08/26 15:01:02 step 1: mse=0.955400 step=0.100000
2017/08/26 15:01:03 step 2: mse=0.901845 step=0.100000
2017/08/26 15:01:04 step 3: mse=0.854700 step=0.100000
2017/08/26 15:01:05 step 4: mse=0.811604 step=0.100000
2017/08/26 15:01:05 step 5: mse=0.770573 step=0.100000
2017/08/26 15:01:06 step 6: mse=0.746386 step=0.100000
2017/08/26 15:01:07 step 7: mse=0.711040 step=0.100000
2017/08/26 15:01:07 Saving...
2017/08/26 15:01:07 Gathering batch of experience...
2017/08/26 15:01:26 batch 304: mean=17.659091 stddev=8.530542 entropy=1.063270 frames=38325 count=44
2017/08/26 15:01:26 Training policy...
2017/08/26 15:01:31 step 0: objective=0.053701032
2017/08/26 15:01:35 step 1: objective=0.05377413
2017/08/26 15:01:39 step 2: objective=0.053847518
2017/08/26 15:01:43 step 3: objective=0.0539178
2017/08/26 15:01:47 step 4: objective=0.053957887
2017/08/26 15:01:51 step 5: objective=0.053995352
2017/08/26 15:01:55 step 6: objective=0.054027203
2017/08/26 15:01:59 step 7: objective=0.05406732
2017/08/26 15:01:59 Training value function...
2017/08/26 15:02:01 step 0: mse=1.414418 step=0.100000
2017/08/26 15:02:02 step 1: mse=1.288488 step=0.100000
2017/08/26 15:02:02 step 2: mse=1.187304 step=0.100000
2017/08/26 15:02:03 step 3: mse=1.098805 step=0.100000
2017/08/26 15:02:04 step 4: mse=1.026361 step=0.100000
2017/08/26 15:02:05 step 5: mse=0.972207 step=0.100000
2017/08/26 15:02:06 step 6: mse=0.925096 step=0.100000
2017/08/26 15:02:06 step 7: mse=0.888551 step=0.100000
2017/08/26 15:02:06 Saving...
2017/08/26 15:02:07 Gathering batch of experience...
2017/08/26 15:02:24 batch 305: mean=14.446809 stddev=6.149930 entropy=1.067402 frames=36514 count=47
2017/08/26 15:02:24 Training policy...
2017/08/26 15:02:30 step 0: objective=0.010368832
2017/08/26 15:02:34 step 1: objective=0.010396155
2017/08/26 15:02:38 step 2: objective=0.010423231
2017/08/26 15:02:41 step 3: objective=0.010450398
2017/08/26 15:02:45 step 4: objective=0.010477391
2017/08/26 15:02:49 step 5: objective=0.010504365
2017/08/26 15:02:53 step 6: objective=0.010531198
2017/08/26 15:02:57 step 7: objective=0.010557254
2017/08/26 15:02:57 Training value function...
2017/08/26 15:02:58 step 0: mse=0.676376 step=0.100000
2017/08/26 15:02:59 step 1: mse=0.643074 step=0.100000
2017/08/26 15:03:00 step 2: mse=0.616452 step=0.100000
2017/08/26 15:03:00 step 3: mse=0.595124 step=0.100000
2017/08/26 15:03:01 step 4: mse=0.578139 step=0.100000
2017/08/26 15:03:02 step 5: mse=0.563935 step=0.100000
2017/08/26 15:03:03 step 6: mse=0.545404 step=0.100000
2017/08/26 15:03:03 step 7: mse=0.531420 step=0.100000
2017/08/26 15:03:03 Saving...
2017/08/26 15:03:03 Gathering batch of experience...
2017/08/26 15:03:21 batch 306: mean=17.285714 stddev=6.370638 entropy=1.059956 frames=36008 count=42
2017/08/26 15:03:21 Training policy...
2017/08/26 15:03:27 step 0: objective=0.053999294
2017/08/26 15:03:30 step 1: objective=0.05403818
2017/08/26 15:03:34 step 2: objective=0.054076906
2017/08/26 15:03:38 step 3: objective=0.054115802
2017/08/26 15:03:42 step 4: objective=0.054155357
2017/08/26 15:03:46 step 5: objective=0.054185648
2017/08/26 15:03:49 step 6: objective=0.054211065
2017/08/26 15:03:53 step 7: objective=0.05423431
2017/08/26 15:03:53 Training value function...
2017/08/26 15:03:54 step 0: mse=0.978360 step=0.100000
2017/08/26 15:03:55 step 1: mse=0.924558 step=0.100000
2017/08/26 15:03:56 step 2: mse=0.879302 step=0.100000
2017/08/26 15:03:57 step 3: mse=0.841808 step=0.100000
2017/08/26 15:03:57 step 4: mse=0.808300 step=0.100000
2017/08/26 15:03:58 step 5: mse=0.765226 step=0.100000
2017/08/26 15:03:59 step 6: mse=0.728864 step=0.100000
2017/08/26 15:04:00 step 7: mse=0.703289 step=0.100000
2017/08/26 15:04:00 Saving...
2017/08/26 15:04:00 Gathering batch of experience...
2017/08/26 15:04:18 batch 307: mean=16.666667 stddev=7.786027 entropy=1.058792 frames=36319 count=45
2017/08/26 15:04:18 Training policy...
2017/08/26 15:04:23 step 0: objective=0.04191836
2017/08/26 15:04:27 step 1: objective=0.041959576
2017/08/26 15:04:31 step 2: objective=0.042000525
2017/08/26 15:04:35 step 3: objective=0.04204242
2017/08/26 15:04:38 step 4: objective=0.04208484
2017/08/26 15:04:42 step 5: objective=0.042116694
2017/08/26 15:04:46 step 6: objective=0.042174254
2017/08/26 15:04:50 step 7: objective=0.04222905
2017/08/26 15:04:50 Training value function...
2017/08/26 15:04:51 step 0: mse=1.304201 step=0.100000
2017/08/26 15:04:52 step 1: mse=1.217811 step=0.100000
2017/08/26 15:04:53 step 2: mse=1.147981 step=0.100000
2017/08/26 15:04:53 step 3: mse=1.114282 step=0.100000
2017/08/26 15:04:54 step 4: mse=1.078619 step=0.100000
2017/08/26 15:04:55 step 5: mse=1.056417 step=0.100000
2017/08/26 15:04:56 step 6: mse=0.995452 step=0.100000
2017/08/26 15:04:56 step 7: mse=0.971025 step=0.100000
2017/08/26 15:04:56 Saving...
2017/08/26 15:04:56 Gathering batch of experience...
2017/08/26 15:05:14 batch 308: mean=15.422222 stddev=6.448045 entropy=1.063975 frames=35517 count=45
2017/08/26 15:05:14 Training policy...
2017/08/26 15:05:19 step 0: objective=0.02089696
2017/08/26 15:05:23 step 1: objective=0.020939337
2017/08/26 15:05:27 step 2: objective=0.020981314
2017/08/26 15:05:30 step 3: objective=0.021021215
2017/08/26 15:05:34 step 4: objective=0.021060871
2017/08/26 15:05:38 step 5: objective=0.021100126
2017/08/26 15:05:42 step 6: objective=0.02112994
2017/08/26 15:05:45 step 7: objective=0.021188652
2017/08/26 15:05:45 Training value function...
2017/08/26 15:05:47 step 0: mse=0.880308 step=0.100000
2017/08/26 15:05:47 step 1: mse=0.828113 step=0.100000
2017/08/26 15:05:48 step 2: mse=0.785955 step=0.100000
2017/08/26 15:05:49 step 3: mse=0.758379 step=0.100000
2017/08/26 15:05:50 step 4: mse=0.725977 step=0.100000
2017/08/26 15:05:50 step 5: mse=0.705616 step=0.100000
2017/08/26 15:05:51 step 6: mse=0.684215 step=0.100000
2017/08/26 15:05:52 step 7: mse=0.670154 step=0.100000
2017/08/26 15:05:52 Saving...
2017/08/26 15:05:52 Gathering batch of experience...
2017/08/26 15:06:10 batch 309: mean=15.173913 stddev=6.913454 entropy=1.069899 frames=36263 count=46
2017/08/26 15:06:10 Training policy...
2017/08/26 15:06:15 step 0: objective=0.010843646
2017/08/26 15:06:19 step 1: objective=0.010903608
2017/08/26 15:06:23 step 2: objective=0.010963324
2017/08/26 15:06:26 step 3: objective=0.011022772
2017/08/26 15:06:30 step 4: objective=0.0110819815
2017/08/26 15:06:34 step 5: objective=0.011139122
2017/08/26 15:06:38 step 6: objective=0.011180779
2017/08/26 15:06:42 step 7: objective=0.011205984
2017/08/26 15:06:42 Training value function...
2017/08/26 15:06:43 step 0: mse=0.986697 step=0.100000
2017/08/26 15:06:44 step 1: mse=0.914099 step=0.100000
2017/08/26 15:06:45 step 2: mse=0.855619 step=0.100000
2017/08/26 15:06:45 step 3: mse=0.807348 step=0.100000
2017/08/26 15:06:46 step 4: mse=0.768380 step=0.100000
2017/08/26 15:06:47 step 5: mse=0.732560 step=0.100000
2017/08/26 15:06:48 step 6: mse=0.695848 step=0.100000
2017/08/26 15:06:48 step 7: mse=0.676963 step=0.100000
2017/08/26 15:06:48 Saving...
2017/08/26 15:06:48 Gathering batch of experience...
2017/08/26 15:07:06 batch 310: mean=17.651163 stddev=7.287721 entropy=1.061114 frames=36701 count=43
2017/08/26 15:07:06 Training policy...
2017/08/26 15:07:12 step 0: objective=0.03377694
2017/08/26 15:07:16 step 1: objective=0.033855543
2017/08/26 15:07:20 step 2: objective=0.033933885
2017/08/26 15:07:24 step 3: objective=0.034009747
2017/08/26 15:07:27 step 4: objective=0.03406848
2017/08/26 15:07:31 step 5: objective=0.034150004
2017/08/26 15:07:35 step 6: objective=0.034252703
2017/08/26 15:07:39 step 7: objective=0.03430684
2017/08/26 15:07:39 Training value function...
2017/08/26 15:07:40 step 0: mse=1.489856 step=0.100000
2017/08/26 15:07:41 step 1: mse=1.372283 step=0.100000
2017/08/26 15:07:42 step 2: mse=1.281742 step=0.100000
2017/08/26 15:07:43 step 3: mse=1.208635 step=0.100000
2017/08/26 15:07:43 step 4: mse=1.143658 step=0.100000
2017/08/26 15:07:44 step 5: mse=1.090119 step=0.100000
2017/08/26 15:07:45 step 6: mse=1.042350 step=0.100000
2017/08/26 15:07:46 step 7: mse=1.005276 step=0.100000
2017/08/26 15:07:46 Saving...
2017/08/26 15:07:46 Gathering batch of experience...
2017/08/26 15:08:04 batch 311: mean=15.826087 stddev=6.193630 entropy=1.073697 frames=36589 count=46
2017/08/26 15:08:04 Training policy...
2017/08/26 15:08:09 step 0: objective=0.021234568
2017/08/26 15:08:13 step 1: objective=0.021302473
2017/08/26 15:08:17 step 2: objective=0.021370085
2017/08/26 15:08:21 step 3: objective=0.0214376
2017/08/26 15:08:25 step 4: objective=0.021504972
2017/08/26 15:08:29 step 5: objective=0.021561919
2017/08/26 15:08:33 step 6: objective=0.021591956
2017/08/26 15:08:37 step 7: objective=0.021622457
2017/08/26 15:08:37 Training value function...
2017/08/26 15:08:38 step 0: mse=0.995264 step=0.100000
2017/08/26 15:08:39 step 1: mse=0.952120 step=0.100000
2017/08/26 15:08:39 step 2: mse=0.917455 step=0.100000
2017/08/26 15:08:40 step 3: mse=0.886897 step=0.100000
2017/08/26 15:08:41 step 4: mse=0.863596 step=0.100000
2017/08/26 15:08:42 step 5: mse=0.826482 step=0.100000
2017/08/26 15:08:42 step 6: mse=0.808888 step=0.100000
2017/08/26 15:08:43 step 7: mse=0.781618 step=0.100000
2017/08/26 15:08:43 Saving...
2017/08/26 15:08:43 Gathering batch of experience...
2017/08/26 15:09:01 batch 312: mean=16.977273 stddev=6.991841 entropy=1.053664 frames=37007 count=44
2017/08/26 15:09:01 Training policy...
2017/08/26 15:09:07 step 0: objective=0.015343493
2017/08/26 15:09:11 step 1: objective=0.015447583
2017/08/26 15:09:15 step 2: objective=0.015551334
2017/08/26 15:09:19 step 3: objective=0.015653508
2017/08/26 15:09:23 step 4: objective=0.015727395
2017/08/26 15:09:27 step 5: objective=0.01577702
2017/08/26 15:09:31 step 6: objective=0.015817478
2017/08/26 15:09:35 step 7: objective=0.015862126
2017/08/26 15:09:35 Training value function...
2017/08/26 15:09:36 step 0: mse=0.926202 step=0.100000
2017/08/26 15:09:37 step 1: mse=0.882245 step=0.100000
2017/08/26 15:09:37 step 2: mse=0.843024 step=0.100000
2017/08/26 15:09:38 step 3: mse=0.813858 step=0.100000
2017/08/26 15:09:39 step 4: mse=0.790219 step=0.100000
2017/08/26 15:09:40 step 5: mse=0.770300 step=0.100000
2017/08/26 15:09:41 step 6: mse=0.743073 step=0.100000
2017/08/26 15:09:41 step 7: mse=0.715915 step=0.100000
2017/08/26 15:09:41 Saving...
2017/08/26 15:09:41 Gathering batch of experience...
2017/08/26 15:10:00 batch 313: mean=15.673913 stddev=6.369268 entropy=1.066331 frames=37014 count=46
2017/08/26 15:10:00 Training policy...
2017/08/26 15:10:05 step 0: objective=0.02485123
2017/08/26 15:10:09 step 1: objective=0.024901247
2017/08/26 15:10:13 step 2: objective=0.024951847
2017/08/26 15:10:17 step 3: objective=0.02500276
2017/08/26 15:10:21 step 4: objective=0.02504927
2017/08/26 15:10:25 step 5: objective=0.025097977
2017/08/26 15:10:29 step 6: objective=0.025146067
2017/08/26 15:10:33 step 7: objective=0.025190549
2017/08/26 15:10:33 Training value function...
2017/08/26 15:10:34 step 0: mse=0.736715 step=0.100000
2017/08/26 15:10:35 step 1: mse=0.708771 step=0.100000
2017/08/26 15:10:36 step 2: mse=0.685037 step=0.100000
2017/08/26 15:10:36 step 3: mse=0.666140 step=0.100000
2017/08/26 15:10:37 step 4: mse=0.644655 step=0.100000
2017/08/26 15:10:38 step 5: mse=0.624998 step=0.100000
2017/08/26 15:10:39 step 6: mse=0.610812 step=0.100000
2017/08/26 15:10:39 step 7: mse=0.598247 step=0.100000
2017/08/26 15:10:39 Saving...
2017/08/26 15:10:39 Gathering batch of experience...
2017/08/26 15:10:58 batch 314: mean=16.822222 stddev=7.376506 entropy=1.055238 frames=37640 count=45
2017/08/26 15:10:58 Training policy...
2017/08/26 15:11:04 step 0: objective=0.04175259
2017/08/26 15:11:08 step 1: objective=0.041815918
2017/08/26 15:11:12 step 2: objective=0.041879024
2017/08/26 15:11:16 step 3: objective=0.041941386
2017/08/26 15:11:20 step 4: objective=0.041998096
2017/08/26 15:11:24 step 5: objective=0.04207049
2017/08/26 15:11:28 step 6: objective=0.042118646
2017/08/26 15:11:32 step 7: objective=0.042143207
2017/08/26 15:11:32 Training value function...
2017/08/26 15:11:33 step 0: mse=1.097094 step=0.100000
2017/08/26 15:11:34 step 1: mse=1.021366 step=0.100000
2017/08/26 15:11:35 step 2: mse=0.956029 step=0.100000
2017/08/26 15:11:36 step 3: mse=0.899915 step=0.100000
2017/08/26 15:11:36 step 4: mse=0.854269 step=0.100000
2017/08/26 15:11:37 step 5: mse=0.812997 step=0.100000
2017/08/26 15:11:38 step 6: mse=0.779464 step=0.100000
2017/08/26 15:11:39 step 7: mse=0.745636 step=0.100000
2017/08/26 15:11:39 Saving...
2017/08/26 15:11:39 Gathering batch of experience...
2017/08/26 15:11:57 batch 315: mean=17.976744 stddev=7.887253 entropy=1.055485 frames=37054 count=43
2017/08/26 15:11:57 Training policy...
2017/08/26 15:12:03 step 0: objective=0.057214633
2017/08/26 15:12:07 step 1: objective=0.057323452
2017/08/26 15:12:10 step 2: objective=0.057433136
2017/08/26 15:12:14 step 3: objective=0.057515524
2017/08/26 15:12:18 step 4: objective=0.057620805
2017/08/26 15:12:22 step 5: objective=0.057686277
2017/08/26 15:12:26 step 6: objective=0.057749834
2017/08/26 15:12:30 step 7: objective=0.057801962
2017/08/26 15:12:30 Training value function...
2017/08/26 15:12:31 step 0: mse=1.317224 step=0.100000
2017/08/26 15:12:32 step 1: mse=1.205515 step=0.100000
2017/08/26 15:12:33 step 2: mse=1.123595 step=0.100000
2017/08/26 15:12:34 step 3: mse=1.053420 step=0.100000
2017/08/26 15:12:34 step 4: mse=0.997924 step=0.100000
2017/08/26 15:12:35 step 5: mse=0.950004 step=0.100000
2017/08/26 15:12:36 step 6: mse=0.908344 step=0.100000
2017/08/26 15:12:37 step 7: mse=0.875596 step=0.100000
2017/08/26 15:12:37 Saving...
2017/08/26 15:12:37 Gathering batch of experience...
2017/08/26 15:12:55 batch 316: mean=17.780488 stddev=8.777777 entropy=1.055397 frames=35929 count=41
2017/08/26 15:12:55 Training policy...
2017/08/26 15:13:00 step 0: objective=0.028050508
2017/08/26 15:13:04 step 1: objective=0.028098658
2017/08/26 15:13:08 step 2: objective=0.0281468
2017/08/26 15:13:12 step 3: objective=0.028220503
2017/08/26 15:13:15 step 4: objective=0.028293965
2017/08/26 15:13:19 step 5: objective=0.028364355
2017/08/26 15:13:23 step 6: objective=0.028402722
2017/08/26 15:13:27 step 7: objective=0.02848275
2017/08/26 15:13:27 Training value function...
2017/08/26 15:13:28 step 0: mse=1.207693 step=0.100000
2017/08/26 15:13:29 step 1: mse=1.122972 step=0.100000
2017/08/26 15:13:30 step 2: mse=1.053783 step=0.100000
2017/08/26 15:13:30 step 3: mse=0.998943 step=0.100000
2017/08/26 15:13:31 step 4: mse=0.954388 step=0.100000
2017/08/26 15:13:32 step 5: mse=0.909388 step=0.100000
2017/08/26 15:13:33 step 6: mse=0.872673 step=0.100000
2017/08/26 15:13:33 step 7: mse=0.845357 step=0.100000
2017/08/26 15:13:33 Saving...
2017/08/26 15:13:33 Gathering batch of experience...
2017/08/26 15:13:52 batch 317: mean=18.116279 stddev=6.895261 entropy=1.059927 frames=36800 count=43
2017/08/26 15:13:52 Training policy...
2017/08/26 15:13:57 step 0: objective=0.03360554
2017/08/26 15:14:01 step 1: objective=0.033728234
2017/08/26 15:14:05 step 2: objective=0.033849947
2017/08/26 15:14:09 step 3: objective=0.033969473
2017/08/26 15:14:13 step 4: objective=0.0340715
2017/08/26 15:14:17 step 5: objective=0.034140162
2017/08/26 15:14:21 step 6: objective=0.03426208
2017/08/26 15:14:25 step 7: objective=0.03432874
2017/08/26 15:14:25 Training value function...
2017/08/26 15:14:26 step 0: mse=1.250815 step=0.100000
2017/08/26 15:14:27 step 1: mse=1.175593 step=0.100000
2017/08/26 15:14:28 step 2: mse=1.115272 step=0.100000
2017/08/26 15:14:29 step 3: mse=1.065226 step=0.100000
2017/08/26 15:14:29 step 4: mse=1.029144 step=0.100000
2017/08/26 15:14:30 step 5: mse=0.985345 step=0.100000
2017/08/26 15:14:31 step 6: mse=0.958366 step=0.100000
2017/08/26 15:14:32 step 7: mse=0.923138 step=0.100000
2017/08/26 15:14:32 Saving...
2017/08/26 15:14:32 Gathering batch of experience...
2017/08/26 15:14:50 batch 318: mean=15.777778 stddev=7.293494 entropy=1.056324 frames=36568 count=45
2017/08/26 15:14:50 Training policy...
2017/08/26 15:14:55 step 0: objective=0.0085802665
2017/08/26 15:14:59 step 1: objective=0.008632649
2017/08/26 15:15:03 step 2: objective=0.0086849015
2017/08/26 15:15:07 step 3: objective=0.0087369485
2017/08/26 15:15:11 step 4: objective=0.008787422
2017/08/26 15:15:15 step 5: objective=0.008825622
2017/08/26 15:15:19 step 6: objective=0.008859767
2017/08/26 15:15:23 step 7: objective=0.008886561
2017/08/26 15:15:23 Training value function...
2017/08/26 15:15:24 step 0: mse=0.909444 step=0.100000
2017/08/26 15:15:25 step 1: mse=0.855715 step=0.100000
2017/08/26 15:15:25 step 2: mse=0.812317 step=0.100000
2017/08/26 15:15:26 step 3: mse=0.773852 step=0.100000
2017/08/26 15:15:27 step 4: mse=0.743139 step=0.100000
2017/08/26 15:15:28 step 5: mse=0.711554 step=0.100000
2017/08/26 15:15:28 step 6: mse=0.686580 step=0.100000
2017/08/26 15:15:29 step 7: mse=0.667898 step=0.100000
2017/08/26 15:15:29 Saving...
2017/08/26 15:15:29 Gathering batch of experience...
2017/08/26 15:15:47 batch 319: mean=18.071429 stddev=5.933733 entropy=1.055233 frames=37256 count=42
2017/08/26 15:15:47 Training policy...
2017/08/26 15:15:53 step 0: objective=0.030787803
2017/08/26 15:15:57 step 1: objective=0.030887997
2017/08/26 15:16:01 step 2: objective=0.03098735
2017/08/26 15:16:05 step 3: objective=0.031084051
2017/08/26 15:16:09 step 4: objective=0.031181708
2017/08/26 15:16:13 step 5: objective=0.031238243
2017/08/26 15:16:17 step 6: objective=0.031298544
2017/08/26 15:16:21 step 7: objective=0.031361002
2017/08/26 15:16:21 Training value function...
2017/08/26 15:16:22 step 0: mse=0.913984 step=0.100000
2017/08/26 15:16:23 step 1: mse=0.855688 step=0.100000
2017/08/26 15:16:24 step 2: mse=0.808998 step=0.100000
2017/08/26 15:16:25 step 3: mse=0.769493 step=0.100000
2017/08/26 15:16:25 step 4: mse=0.737205 step=0.100000
2017/08/26 15:16:26 step 5: mse=0.707716 step=0.100000
2017/08/26 15:16:27 step 6: mse=0.684286 step=0.100000
2017/08/26 15:16:28 step 7: mse=0.665138 step=0.100000
2017/08/26 15:16:28 Saving...
2017/08/26 15:16:28 Gathering batch of experience...
2017/08/26 15:16:46 batch 320: mean=16.697674 stddev=7.302548 entropy=1.054011 frames=35842 count=43
2017/08/26 15:16:46 Training policy...
2017/08/26 15:16:51 step 0: objective=0.023982571
2017/08/26 15:16:55 step 1: objective=0.024025263
2017/08/26 15:16:59 step 2: objective=0.024067873
2017/08/26 15:17:03 step 3: objective=0.024099343
2017/08/26 15:17:07 step 4: objective=0.024130233
2017/08/26 15:17:11 step 5: objective=0.024159636
2017/08/26 15:17:14 step 6: objective=0.024188953
2017/08/26 15:17:18 step 7: objective=0.02422192
2017/08/26 15:17:18 Training value function...
2017/08/26 15:17:19 step 0: mse=0.889660 step=0.100000
2017/08/26 15:17:20 step 1: mse=0.846554 step=0.100000
2017/08/26 15:17:21 step 2: mse=0.812905 step=0.100000
2017/08/26 15:17:22 step 3: mse=0.784411 step=0.100000
2017/08/26 15:17:22 step 4: mse=0.755108 step=0.100000
2017/08/26 15:17:23 step 5: mse=0.736123 step=0.100000
2017/08/26 15:17:24 step 6: mse=0.702975 step=0.100000
2017/08/26 15:17:25 step 7: mse=0.691338 step=0.100000
2017/08/26 15:17:25 Saving...
2017/08/26 15:17:25 Gathering batch of experience...
2017/08/26 15:17:43 batch 321: mean=18.372093 stddev=6.480824 entropy=1.055674 frames=36723 count=43
2017/08/26 15:17:43 Training policy...
2017/08/26 15:17:48 step 0: objective=0.04918861
2017/08/26 15:17:52 step 1: objective=0.04926513
2017/08/26 15:17:56 step 2: objective=0.049329832
2017/08/26 15:18:00 step 3: objective=0.049394567
2017/08/26 15:18:04 step 4: objective=0.049465373
2017/08/26 15:18:08 step 5: objective=0.049531505
2017/08/26 15:18:12 step 6: objective=0.0496141
2017/08/26 15:18:16 step 7: objective=0.04967828
2017/08/26 15:18:16 Training value function...
2017/08/26 15:18:17 step 0: mse=1.184952 step=0.100000
2017/08/26 15:18:18 step 1: mse=1.119926 step=0.100000
2017/08/26 15:18:19 step 2: mse=1.055107 step=0.100000
2017/08/26 15:18:19 step 3: mse=1.007862 step=0.100000
2017/08/26 15:18:20 step 4: mse=0.956148 step=0.100000
2017/08/26 15:18:21 step 5: mse=0.921314 step=0.100000
2017/08/26 15:18:22 step 6: mse=0.881533 step=0.100000
2017/08/26 15:18:22 step 7: mse=0.852470 step=0.100000
2017/08/26 15:18:22 Saving...
2017/08/26 15:18:22 Gathering batch of experience...
2017/08/26 15:18:41 batch 322: mean=16.422222 stddev=8.100724 entropy=1.050177 frames=37115 count=45
2017/08/26 15:18:41 Training policy...
2017/08/26 15:18:47 step 0: objective=0.014818387
2017/08/26 15:18:51 step 1: objective=0.014871775
2017/08/26 15:18:55 step 2: objective=0.01492471
2017/08/26 15:18:59 step 3: objective=0.014977286
2017/08/26 15:19:03 step 4: objective=0.015029346
2017/08/26 15:19:07 step 5: objective=0.015077971
2017/08/26 15:19:11 step 6: objective=0.015117131
2017/08/26 15:19:15 step 7: objective=0.015151501
2017/08/26 15:19:15 Training value function...
2017/08/26 15:19:16 step 0: mse=1.098909 step=0.100000
2017/08/26 15:19:17 step 1: mse=1.003952 step=0.100000
2017/08/26 15:19:17 step 2: mse=0.932000 step=0.100000
2017/08/26 15:19:18 step 3: mse=0.866108 step=0.100000
2017/08/26 15:19:19 step 4: mse=0.819082 step=0.100000
2017/08/26 15:19:20 step 5: mse=0.770234 step=0.100000
2017/08/26 15:19:20 step 6: mse=0.728466 step=0.100000
2017/08/26 15:19:21 step 7: mse=0.699775 step=0.100000
2017/08/26 15:19:21 Saving...
2017/08/26 15:19:21 Gathering batch of experience...
2017/08/26 15:19:40 batch 323: mean=15.617021 stddev=7.060689 entropy=1.059893 frames=37638 count=47
2017/08/26 15:19:40 Training policy...
2017/08/26 15:19:46 step 0: objective=0.024686635
2017/08/26 15:19:50 step 1: objective=0.024719352
2017/08/26 15:19:54 step 2: objective=0.02475173
2017/08/26 15:19:58 step 3: objective=0.02478427
2017/08/26 15:20:02 step 4: objective=0.024816407
2017/08/26 15:20:06 step 5: objective=0.024848787
2017/08/26 15:20:10 step 6: objective=0.024880731
2017/08/26 15:20:14 step 7: objective=0.024908872
2017/08/26 15:20:14 Training value function...
2017/08/26 15:20:15 step 0: mse=0.821439 step=0.100000
2017/08/26 15:20:16 step 1: mse=0.781917 step=0.100000
2017/08/26 15:20:17 step 2: mse=0.742347 step=0.100000
2017/08/26 15:20:18 step 3: mse=0.715013 step=0.100000
2017/08/26 15:20:19 step 4: mse=0.685395 step=0.100000
2017/08/26 15:20:19 step 5: mse=0.660657 step=0.100000
2017/08/26 15:20:20 step 6: mse=0.635122 step=0.100000
2017/08/26 15:20:21 step 7: mse=0.604911 step=0.100000
2017/08/26 15:20:21 Saving...
2017/08/26 15:20:21 Gathering batch of experience...
2017/08/26 15:20:39 batch 324: mean=16.285714 stddev=5.465414 entropy=1.060538 frames=36353 count=42
2017/08/26 15:20:39 Training policy...
2017/08/26 15:20:44 step 0: objective=0.011640116
2017/08/26 15:20:48 step 1: objective=0.011679451
2017/08/26 15:20:52 step 2: objective=0.011718695
2017/08/26 15:20:56 step 3: objective=0.011757927
2017/08/26 15:21:00 step 4: objective=0.011796825
2017/08/26 15:21:04 step 5: objective=0.0118357595
2017/08/26 15:21:08 step 6: objective=0.011873877
2017/08/26 15:21:12 step 7: objective=0.011903383
2017/08/26 15:21:12 Training value function...
2017/08/26 15:21:13 step 0: mse=0.646982 step=0.100000
2017/08/26 15:21:14 step 1: mse=0.608174 step=0.100000
2017/08/26 15:21:15 step 2: mse=0.573275 step=0.100000
2017/08/26 15:21:15 step 3: mse=0.547843 step=0.100000
2017/08/26 15:21:16 step 4: mse=0.523124 step=0.100000
2017/08/26 15:21:17 step 5: mse=0.504606 step=0.100000
2017/08/26 15:21:17 step 6: mse=0.481848 step=0.100000
2017/08/26 15:21:18 step 7: mse=0.472358 step=0.100000
2017/08/26 15:21:18 Saving...
2017/08/26 15:21:18 Gathering batch of experience...
2017/08/26 15:21:36 batch 325: mean=15.977273 stddev=6.600581 entropy=1.062584 frames=35876 count=44
2017/08/26 15:21:36 Training policy...
2017/08/26 15:21:42 step 0: objective=0.03153107
2017/08/26 15:21:46 step 1: objective=0.03157976
2017/08/26 15:21:50 step 2: objective=0.031628378
2017/08/26 15:21:53 step 3: objective=0.031677075
2017/08/26 15:21:57 step 4: objective=0.031725693
2017/08/26 15:22:01 step 5: objective=0.03177426
2017/08/26 15:22:05 step 6: objective=0.03182122
2017/08/26 15:22:09 step 7: objective=0.03187172
2017/08/26 15:22:09 Training value function...
2017/08/26 15:22:10 step 0: mse=0.924299 step=0.100000
2017/08/26 15:22:11 step 1: mse=0.884853 step=0.100000
2017/08/26 15:22:12 step 2: mse=0.854661 step=0.100000
2017/08/26 15:22:12 step 3: mse=0.830577 step=0.100000
2017/08/26 15:22:13 step 4: mse=0.809590 step=0.100000
2017/08/26 15:22:14 step 5: mse=0.790798 step=0.100000
2017/08/26 15:22:15 step 6: mse=0.769229 step=0.100000
2017/08/26 15:22:15 step 7: mse=0.740195 step=0.100000
2017/08/26 15:22:15 Saving...
2017/08/26 15:22:15 Gathering batch of experience...
2017/08/26 15:22:33 batch 326: mean=14.800000 stddev=6.039132 entropy=1.069920 frames=35998 count=45
2017/08/26 15:22:33 Training policy...
2017/08/26 15:22:39 step 0: objective=0.0020334234
2017/08/26 15:22:42 step 1: objective=0.0020841155
2017/08/26 15:22:46 step 2: objective=0.0021346512
2017/08/26 15:22:50 step 3: objective=0.0021850495
2017/08/26 15:22:54 step 4: objective=0.0022352755
2017/08/26 15:22:58 step 5: objective=0.0022851091
2017/08/26 15:23:02 step 6: objective=0.002329582
2017/08/26 15:23:06 step 7: objective=0.0023731333
2017/08/26 15:23:06 Training value function...
2017/08/26 15:23:07 step 0: mse=0.745522 step=0.100000
2017/08/26 15:23:08 step 1: mse=0.700635 step=0.100000
2017/08/26 15:23:09 step 2: mse=0.665467 step=0.100000
2017/08/26 15:23:09 step 3: mse=0.635525 step=0.100000
2017/08/26 15:23:10 step 4: mse=0.615655 step=0.100000
2017/08/26 15:23:11 step 5: mse=0.592575 step=0.100000
2017/08/26 15:23:12 step 6: mse=0.569134 step=0.100000
2017/08/26 15:23:12 step 7: mse=0.555562 step=0.100000
2017/08/26 15:23:12 Saving...
2017/08/26 15:23:12 Gathering batch of experience...
2017/08/26 15:23:31 batch 327: mean=16.772727 stddev=7.567465 entropy=1.063953 frames=36916 count=44
2017/08/26 15:23:31 Training policy...
2017/08/26 15:23:37 step 0: objective=0.047306884
2017/08/26 15:23:41 step 1: objective=0.047348008
2017/08/26 15:23:45 step 2: objective=0.047389176
2017/08/26 15:23:49 step 3: objective=0.04743045
2017/08/26 15:23:53 step 4: objective=0.04747175
2017/08/26 15:23:57 step 5: objective=0.047506765
2017/08/26 15:24:01 step 6: objective=0.047561903
2017/08/26 15:24:05 step 7: objective=0.04761312
2017/08/26 15:24:05 Training value function...
2017/08/26 15:24:06 step 0: mse=0.994516 step=0.100000
2017/08/26 15:24:07 step 1: mse=0.941119 step=0.100000
2017/08/26 15:24:08 step 2: mse=0.900217 step=0.100000
2017/08/26 15:24:08 step 3: mse=0.861569 step=0.100000
2017/08/26 15:24:09 step 4: mse=0.821919 step=0.100000
2017/08/26 15:24:10 step 5: mse=0.795887 step=0.100000
2017/08/26 15:24:11 step 6: mse=0.768614 step=0.100000
2017/08/26 15:24:11 step 7: mse=0.750498 step=0.100000
2017/08/26 15:24:11 Saving...
2017/08/26 15:24:12 Gathering batch of experience...
2017/08/26 15:24:30 batch 328: mean=15.511111 stddev=5.596119 entropy=1.061716 frames=36341 count=45
2017/08/26 15:24:30 Training policy...
2017/08/26 15:24:35 step 0: objective=0.03140395
2017/08/26 15:24:39 step 1: objective=0.031452086
2017/08/26 15:24:43 step 2: objective=0.03150055
2017/08/26 15:24:47 step 3: objective=0.03154864
2017/08/26 15:24:51 step 4: objective=0.0315965
2017/08/26 15:24:55 step 5: objective=0.03164213
2017/08/26 15:24:59 step 6: objective=0.03167583
2017/08/26 15:25:03 step 7: objective=0.031703938
2017/08/26 15:25:03 Training value function...
2017/08/26 15:25:04 step 0: mse=0.749804 step=0.100000
2017/08/26 15:25:05 step 1: mse=0.713025 step=0.100000
2017/08/26 15:25:06 step 2: mse=0.678800 step=0.100000
2017/08/26 15:25:06 step 3: mse=0.659710 step=0.100000
2017/08/26 15:25:07 step 4: mse=0.644073 step=0.100000
2017/08/26 15:25:08 step 5: mse=0.630821 step=0.100000
2017/08/26 15:25:08 step 6: mse=0.607785 step=0.100000
2017/08/26 15:25:09 step 7: mse=0.598655 step=0.100000
2017/08/26 15:25:09 Saving...
2017/08/26 15:25:09 Gathering batch of experience...
2017/08/26 15:25:27 batch 329: mean=16.622222 stddev=6.165455 entropy=1.066304 frames=36451 count=45
2017/08/26 15:25:27 Training policy...
2017/08/26 15:25:33 step 0: objective=0.048957903
2017/08/26 15:25:37 step 1: objective=0.04906813
2017/08/26 15:25:41 step 2: objective=0.049179535
2017/08/26 15:25:45 step 3: objective=0.049280874
2017/08/26 15:25:49 step 4: objective=0.04934113
2017/08/26 15:25:53 step 5: objective=0.049399495
2017/08/26 15:25:57 step 6: objective=0.049464136
2017/08/26 15:26:01 step 7: objective=0.04954869
2017/08/26 15:26:01 Training value function...
2017/08/26 15:26:02 step 0: mse=1.190560 step=0.100000
2017/08/26 15:26:03 step 1: mse=1.134665 step=0.100000
2017/08/26 15:26:03 step 2: mse=1.088629 step=0.100000
2017/08/26 15:26:04 step 3: mse=1.051357 step=0.100000
2017/08/26 15:26:05 step 4: mse=1.019170 step=0.100000
2017/08/26 15:26:06 step 5: mse=0.991278 step=0.100000
2017/08/26 15:26:06 step 6: mse=0.953026 step=0.100000
2017/08/26 15:26:07 step 7: mse=0.914469 step=0.100000
2017/08/26 15:26:07 Saving...
2017/08/26 15:26:07 Gathering batch of experience...
2017/08/26 15:26:26 batch 330: mean=19.024390 stddev=8.808222 entropy=1.046725 frames=36955 count=41
2017/08/26 15:26:26 Training policy...
2017/08/26 15:26:31 step 0: objective=0.04759492
2017/08/26 15:26:35 step 1: objective=0.04765773
2017/08/26 15:26:39 step 2: objective=0.047721416
2017/08/26 15:26:43 step 3: objective=0.047781587
2017/08/26 15:26:47 step 4: objective=0.047815148
2017/08/26 15:26:52 step 5: objective=0.047853526
2017/08/26 15:26:56 step 6: objective=0.04793866
2017/08/26 15:27:00 step 7: objective=0.04797932
2017/08/26 15:27:00 Training value function...
2017/08/26 15:27:01 step 0: mse=1.261988 step=0.100000
2017/08/26 15:27:02 step 1: mse=1.168485 step=0.100000
2017/08/26 15:27:02 step 2: mse=1.094565 step=0.100000
2017/08/26 15:27:03 step 3: mse=1.027386 step=0.100000
2017/08/26 15:27:04 step 4: mse=0.976268 step=0.100000
2017/08/26 15:27:05 step 5: mse=0.929929 step=0.100000
2017/08/26 15:27:05 step 6: mse=0.891745 step=0.100000
2017/08/26 15:27:06 step 7: mse=0.859239 step=0.100000
2017/08/26 15:27:06 Saving...
2017/08/26 15:27:06 Gathering batch of experience...
2017/08/26 15:27:25 batch 331: mean=18.121951 stddev=6.522737 entropy=1.051078 frames=37065 count=41
2017/08/26 15:27:25 Training policy...
2017/08/26 15:27:30 step 0: objective=0.025278019
2017/08/26 15:27:34 step 1: objective=0.025313007
2017/08/26 15:27:39 step 2: objective=0.025347954
2017/08/26 15:27:43 step 3: objective=0.025382655
2017/08/26 15:27:47 step 4: objective=0.025417283
2017/08/26 15:27:51 step 5: objective=0.025451932
2017/08/26 15:27:55 step 6: objective=0.025486318
2017/08/26 15:27:59 step 7: objective=0.025520714
2017/08/26 15:27:59 Training value function...
2017/08/26 15:28:00 step 0: mse=0.746721 step=0.100000
2017/08/26 15:28:01 step 1: mse=0.722075 step=0.100000
2017/08/26 15:28:02 step 2: mse=0.701987 step=0.100000
2017/08/26 15:28:03 step 3: mse=0.684264 step=0.100000
2017/08/26 15:28:03 step 4: mse=0.659922 step=0.100000
2017/08/26 15:28:04 step 5: mse=0.642608 step=0.100000
2017/08/26 15:28:05 step 6: mse=0.626265 step=0.100000
2017/08/26 15:28:06 step 7: mse=0.609948 step=0.100000
2017/08/26 15:28:06 Saving...
2017/08/26 15:28:06 Gathering batch of experience...
2017/08/26 15:28:24 batch 332: mean=15.577778 stddev=6.868572 entropy=1.061953 frames=36351 count=45
2017/08/26 15:28:24 Training policy...
2017/08/26 15:28:29 step 0: objective=0.008742198
2017/08/26 15:28:33 step 1: objective=0.008799637
2017/08/26 15:28:37 step 2: objective=0.008857124
2017/08/26 15:28:41 step 3: objective=0.008914566
2017/08/26 15:28:45 step 4: objective=0.008965461
2017/08/26 15:28:49 step 5: objective=0.0089957565
2017/08/26 15:28:53 step 6: objective=0.009045924
2017/08/26 15:28:58 step 7: objective=0.0090691345
2017/08/26 15:28:58 Training value function...
2017/08/26 15:28:59 step 0: mse=0.769186 step=0.100000
2017/08/26 15:28:59 step 1: mse=0.724497 step=0.100000
2017/08/26 15:29:00 step 2: mse=0.688254 step=0.100000
2017/08/26 15:29:01 step 3: mse=0.658300 step=0.100000
2017/08/26 15:29:02 step 4: mse=0.633965 step=0.100000
2017/08/26 15:29:03 step 5: mse=0.613155 step=0.100000
2017/08/26 15:29:03 step 6: mse=0.590368 step=0.100000
2017/08/26 15:29:04 step 7: mse=0.573957 step=0.100000
2017/08/26 15:29:04 Saving...
2017/08/26 15:29:04 Gathering batch of experience...
2017/08/26 15:29:22 batch 333: mean=18.214286 stddev=10.070078 entropy=1.046921 frames=36541 count=42
2017/08/26 15:29:22 Training policy...
2017/08/26 15:29:28 step 0: objective=0.05995428
2017/08/26 15:29:32 step 1: objective=0.060017165
2017/08/26 15:29:36 step 2: objective=0.060080007
2017/08/26 15:29:40 step 3: objective=0.06014299
2017/08/26 15:29:44 step 4: objective=0.060204204
2017/08/26 15:29:48 step 5: objective=0.06026929
2017/08/26 15:29:52 step 6: objective=0.060329653
2017/08/26 15:29:56 step 7: objective=0.060396835
2017/08/26 15:29:56 Training value function...
2017/08/26 15:29:57 step 0: mse=2.049240 step=0.100000
2017/08/26 15:29:58 step 1: mse=1.790393 step=0.100000
2017/08/26 15:29:58 step 2: mse=1.582916 step=0.100000
2017/08/26 15:29:59 step 3: mse=1.415613 step=0.100000
2017/08/26 15:30:00 step 4: mse=1.280631 step=0.100000
2017/08/26 15:30:01 step 5: mse=1.171646 step=0.100000
2017/08/26 15:30:02 step 6: mse=1.083338 step=0.100000
2017/08/26 15:30:02 step 7: mse=1.009914 step=0.100000
2017/08/26 15:30:02 Saving...
2017/08/26 15:30:02 Gathering batch of experience...
2017/08/26 15:30:21 batch 334: mean=17.232558 stddev=7.932381 entropy=1.053877 frames=36814 count=43
2017/08/26 15:30:21 Training policy...
2017/08/26 15:30:26 step 0: objective=0.022044642
2017/08/26 15:30:30 step 1: objective=0.022079492
2017/08/26 15:30:34 step 2: objective=0.022114268
2017/08/26 15:30:38 step 3: objective=0.022148825
2017/08/26 15:30:42 step 4: objective=0.022182984
2017/08/26 15:30:47 step 5: objective=0.022217007
2017/08/26 15:30:51 step 6: objective=0.022249458
2017/08/26 15:30:55 step 7: objective=0.022276245
2017/08/26 15:30:55 Training value function...
2017/08/26 15:30:56 step 0: mse=1.116207 step=0.100000
2017/08/26 15:30:57 step 1: mse=1.032214 step=0.100000
2017/08/26 15:30:57 step 2: mse=0.957566 step=0.100000
2017/08/26 15:30:58 step 3: mse=0.902117 step=0.100000
2017/08/26 15:30:59 step 4: mse=0.841937 step=0.100000
2017/08/26 15:31:00 step 5: mse=0.794225 step=0.100000
2017/08/26 15:31:00 step 6: mse=0.745137 step=0.100000
2017/08/26 15:31:01 step 7: mse=0.719232 step=0.100000
2017/08/26 15:31:01 Saving...
2017/08/26 15:31:01 Gathering batch of experience...
2017/08/26 15:31:20 batch 335: mean=15.688889 stddev=6.555141 entropy=1.068167 frames=36811 count=45
2017/08/26 15:31:20 Training policy...
2017/08/26 15:31:25 step 0: objective=0.015087804
2017/08/26 15:31:29 step 1: objective=0.015135563
2017/08/26 15:31:33 step 2: objective=0.015183165
2017/08/26 15:31:38 step 3: objective=0.015230721
2017/08/26 15:31:42 step 4: objective=0.015278011
2017/08/26 15:31:46 step 5: objective=0.015322965
2017/08/26 15:31:50 step 6: objective=0.015357464
2017/08/26 15:31:54 step 7: objective=0.01538121
2017/08/26 15:31:54 Training value function...
2017/08/26 15:31:55 step 0: mse=0.831051 step=0.100000
2017/08/26 15:31:56 step 1: mse=0.768128 step=0.100000
2017/08/26 15:31:57 step 2: mse=0.717657 step=0.100000
2017/08/26 15:31:57 step 3: mse=0.676997 step=0.100000
2017/08/26 15:31:58 step 4: mse=0.643265 step=0.100000
2017/08/26 15:31:59 step 5: mse=0.624591 step=0.100000
2017/08/26 15:32:00 step 6: mse=0.609294 step=0.100000
2017/08/26 15:32:00 step 7: mse=0.594157 step=0.100000
2017/08/26 15:32:00 Saving...
2017/08/26 15:32:00 Gathering batch of experience...
2017/08/26 15:32:18 batch 336: mean=15.837209 stddev=7.204424 entropy=1.062764 frames=35011 count=43
2017/08/26 15:32:18 Training policy...
2017/08/26 15:32:23 step 0: objective=0.037095442
2017/08/26 15:32:27 step 1: objective=0.03713234
2017/08/26 15:32:31 step 2: objective=0.03716915
2017/08/26 15:32:35 step 3: objective=0.037206188
2017/08/26 15:32:39 step 4: objective=0.037239842
2017/08/26 15:32:43 step 5: objective=0.037265092
2017/08/26 15:32:46 step 6: objective=0.03729241
2017/08/26 15:32:50 step 7: objective=0.03731973
2017/08/26 15:32:50 Training value function...
2017/08/26 15:32:51 step 0: mse=1.018975 step=0.100000
2017/08/26 15:32:52 step 1: mse=0.929565 step=0.100000
2017/08/26 15:32:53 step 2: mse=0.848762 step=0.100000
2017/08/26 15:32:54 step 3: mse=0.778614 step=0.100000
2017/08/26 15:32:54 step 4: mse=0.722181 step=0.100000
2017/08/26 15:32:55 step 5: mse=0.672712 step=0.100000
2017/08/26 15:32:56 step 6: mse=0.636762 step=0.100000
2017/08/26 15:32:56 step 7: mse=0.603905 step=0.100000
2017/08/26 15:32:56 Saving...
2017/08/26 15:32:56 Gathering batch of experience...
2017/08/26 15:33:15 batch 337: mean=16.886364 stddev=6.691976 entropy=1.061162 frames=37655 count=44
2017/08/26 15:33:15 Training policy...
2017/08/26 15:33:21 step 0: objective=0.03035834
2017/08/26 15:33:25 step 1: objective=0.030442987
2017/08/26 15:33:29 step 2: objective=0.030527122
2017/08/26 15:33:34 step 3: objective=0.03061021
2017/08/26 15:33:38 step 4: objective=0.030643152
2017/08/26 15:33:42 step 5: objective=0.03065908
2017/08/26 15:33:46 step 6: objective=0.03067488
2017/08/26 15:33:50 step 7: objective=0.030690538
2017/08/26 15:33:50 Training value function...
2017/08/26 15:33:52 step 0: mse=0.932397 step=0.100000
2017/08/26 15:33:52 step 1: mse=0.849837 step=0.100000
2017/08/26 15:33:53 step 2: mse=0.783620 step=0.100000
2017/08/26 15:33:54 step 3: mse=0.736170 step=0.100000
2017/08/26 15:33:55 step 4: mse=0.692014 step=0.100000
2017/08/26 15:33:55 step 5: mse=0.655649 step=0.100000
2017/08/26 15:33:56 step 6: mse=0.627397 step=0.100000
2017/08/26 15:33:57 step 7: mse=0.601434 step=0.100000
2017/08/26 15:33:57 Saving...
2017/08/26 15:33:57 Gathering batch of experience...
2017/08/26 15:34:15 batch 338: mean=19.250000 stddev=8.566650 entropy=1.054427 frames=36171 count=40
2017/08/26 15:34:15 Training policy...
2017/08/26 15:34:21 step 0: objective=0.06276284
2017/08/26 15:34:25 step 1: objective=0.06281556
2017/08/26 15:34:29 step 2: objective=0.0628683
2017/08/26 15:34:33 step 3: objective=0.06292014
2017/08/26 15:34:37 step 4: objective=0.062960245
2017/08/26 15:34:41 step 5: objective=0.062988326
2017/08/26 15:34:45 step 6: objective=0.063024074
2017/08/26 15:34:49 step 7: objective=0.06306063
2017/08/26 15:34:49 Training value function...
2017/08/26 15:34:50 step 0: mse=1.461259 step=0.100000
2017/08/26 15:34:51 step 1: mse=1.338965 step=0.100000
2017/08/26 15:34:51 step 2: mse=1.241451 step=0.100000
2017/08/26 15:34:52 step 3: mse=1.158107 step=0.100000
2017/08/26 15:34:53 step 4: mse=1.082076 step=0.100000
2017/08/26 15:34:54 step 5: mse=1.037032 step=0.100000
2017/08/26 15:34:54 step 6: mse=0.982513 step=0.100000
2017/08/26 15:34:55 step 7: mse=0.936862 step=0.100000
2017/08/26 15:34:55 Saving...
2017/08/26 15:34:55 Gathering batch of experience...
2017/08/26 15:35:13 batch 339: mean=15.222222 stddev=5.898734 entropy=1.065527 frames=35152 count=45
2017/08/26 15:35:13 Training policy...
2017/08/26 15:35:18 step 0: objective=0.008810081
2017/08/26 15:35:22 step 1: objective=0.008882525
2017/08/26 15:35:26 step 2: objective=0.008954286
2017/08/26 15:35:30 step 3: objective=0.009025371
2017/08/26 15:35:34 step 4: objective=0.009088948
2017/08/26 15:35:38 step 5: objective=0.009157124
2017/08/26 15:35:41 step 6: objective=0.009228431
2017/08/26 15:35:45 step 7: objective=0.009302341
2017/08/26 15:35:45 Training value function...
2017/08/26 15:35:46 step 0: mse=0.875427 step=0.100000
2017/08/26 15:35:47 step 1: mse=0.838949 step=0.100000
2017/08/26 15:35:48 step 2: mse=0.806302 step=0.100000
2017/08/26 15:35:49 step 3: mse=0.780567 step=0.100000
2017/08/26 15:35:49 step 4: mse=0.758557 step=0.100000
2017/08/26 15:35:50 step 5: mse=0.739783 step=0.100000
2017/08/26 15:35:51 step 6: mse=0.726330 step=0.100000
2017/08/26 15:35:51 step 7: mse=0.711210 step=0.100000
2017/08/26 15:35:51 Saving...
2017/08/26 15:35:51 Gathering batch of experience...
2017/08/26 15:36:10 batch 340: mean=17.651163 stddev=7.129642 entropy=1.057635 frames=37323 count=43
2017/08/26 15:36:10 Training policy...
2017/08/26 15:36:16 step 0: objective=0.034625717
2017/08/26 15:36:20 step 1: objective=0.034688443
2017/08/26 15:36:24 step 2: objective=0.03474298
2017/08/26 15:36:28 step 3: objective=0.034796953
2017/08/26 15:36:32 step 4: objective=0.034869682
2017/08/26 15:36:37 step 5: objective=0.034926016
2017/08/26 15:36:41 step 6: objective=0.034972154
2017/08/26 15:36:45 step 7: objective=0.035053674
2017/08/26 15:36:45 Training value function...
2017/08/26 15:36:46 step 0: mse=1.026575 step=0.100000
2017/08/26 15:36:47 step 1: mse=0.977395 step=0.100000
2017/08/26 15:36:48 step 2: mse=0.921043 step=0.100000
2017/08/26 15:36:48 step 3: mse=0.875164 step=0.100000
2017/08/26 15:36:49 step 4: mse=0.834695 step=0.100000
2017/08/26 15:36:50 step 5: mse=0.799859 step=0.100000
2017/08/26 15:36:51 step 6: mse=0.772022 step=0.100000
2017/08/26 15:36:51 step 7: mse=0.740203 step=0.100000
2017/08/26 15:36:51 Saving...
2017/08/26 15:36:51 Gathering batch of experience...
2017/08/26 15:37:10 batch 341: mean=17.666667 stddev=7.974961 entropy=1.062268 frames=37698 count=45
2017/08/26 15:37:10 Training policy...
2017/08/26 15:37:16 step 0: objective=0.050649468
2017/08/26 15:37:20 step 1: objective=0.050695624
2017/08/26 15:37:25 step 2: objective=0.05074146
2017/08/26 15:37:29 step 3: objective=0.050787322
2017/08/26 15:37:33 step 4: objective=0.05082844
2017/08/26 15:37:37 step 5: objective=0.050851848
2017/08/26 15:37:41 step 6: objective=0.050874237
2017/08/26 15:37:46 step 7: objective=0.0508936
2017/08/26 15:37:46 Training value function...
2017/08/26 15:37:47 step 0: mse=1.244774 step=0.100000
2017/08/26 15:37:48 step 1: mse=1.147501 step=0.100000
2017/08/26 15:37:48 step 2: mse=1.068739 step=0.100000
2017/08/26 15:37:49 step 3: mse=1.004786 step=0.100000
2017/08/26 15:37:50 step 4: mse=0.951280 step=0.100000
2017/08/26 15:37:51 step 5: mse=0.908675 step=0.100000
2017/08/26 15:37:52 step 6: mse=0.870561 step=0.100000
2017/08/26 15:37:52 step 7: mse=0.837827 step=0.100000
2017/08/26 15:37:52 Saving...
2017/08/26 15:37:53 Gathering batch of experience...
2017/08/26 15:38:11 batch 342: mean=16.522727 stddev=8.771049 entropy=1.062445 frames=36434 count=44
2017/08/26 15:38:11 Training policy...
2017/08/26 15:38:17 step 0: objective=0.008493227
2017/08/26 15:38:21 step 1: objective=0.008547329
2017/08/26 15:38:25 step 2: objective=0.008601432
2017/08/26 15:38:29 step 3: objective=0.008655583
2017/08/26 15:38:33 step 4: objective=0.008708591
2017/08/26 15:38:37 step 5: objective=0.008753592
2017/08/26 15:38:41 step 6: objective=0.0088398615
2017/08/26 15:38:45 step 7: objective=0.008920449
2017/08/26 15:38:45 Training value function...
2017/08/26 15:38:46 step 0: mse=1.298596 step=0.100000
2017/08/26 15:38:47 step 1: mse=1.175803 step=0.100000
2017/08/26 15:38:48 step 2: mse=1.069536 step=0.100000
2017/08/26 15:38:49 step 3: mse=0.984940 step=0.100000
2017/08/26 15:38:49 step 4: mse=0.924890 step=0.100000
2017/08/26 15:38:50 step 5: mse=0.868975 step=0.100000
2017/08/26 15:38:51 step 6: mse=0.824414 step=0.100000
2017/08/26 15:38:52 step 7: mse=0.784623 step=0.100000
2017/08/26 15:38:52 Saving...
2017/08/26 15:38:52 Gathering batch of experience...
2017/08/26 15:39:10 batch 343: mean=16.441860 stddev=6.524738 entropy=1.064297 frames=36231 count=43
2017/08/26 15:39:10 Training policy...
2017/08/26 15:39:16 step 0: objective=0.010287625
2017/08/26 15:39:20 step 1: objective=0.010360423
2017/08/26 15:39:24 step 2: objective=0.010433201
2017/08/26 15:39:28 step 3: objective=0.010505683
2017/08/26 15:39:32 step 4: objective=0.010578063
2017/08/26 15:39:36 step 5: objective=0.010649313
2017/08/26 15:39:40 step 6: objective=0.010712226
2017/08/26 15:39:44 step 7: objective=0.010753438
2017/08/26 15:39:44 Training value function...
2017/08/26 15:39:45 step 0: mse=0.907125 step=0.100000
2017/08/26 15:39:46 step 1: mse=0.861012 step=0.100000
2017/08/26 15:39:47 step 2: mse=0.814799 step=0.100000
2017/08/26 15:39:48 step 3: mse=0.783463 step=0.100000
2017/08/26 15:39:48 step 4: mse=0.752059 step=0.100000
2017/08/26 15:39:49 step 5: mse=0.730579 step=0.100000
2017/08/26 15:39:50 step 6: mse=0.713499 step=0.100000
2017/08/26 15:39:51 step 7: mse=0.683802 step=0.100000
2017/08/26 15:39:51 Saving...
2017/08/26 15:39:51 Gathering batch of experience...
2017/08/26 15:40:09 batch 344: mean=15.866667 stddev=5.972530 entropy=1.069471 frames=37049 count=45
2017/08/26 15:40:09 Training policy...
2017/08/26 15:40:15 step 0: objective=0.029182423
2017/08/26 15:40:19 step 1: objective=0.029244198
2017/08/26 15:40:23 step 2: objective=0.029306367
2017/08/26 15:40:27 step 3: objective=0.029368775
2017/08/26 15:40:32 step 4: objective=0.029430287
2017/08/26 15:40:36 step 5: objective=0.029473541
2017/08/26 15:40:40 step 6: objective=0.029505033
2017/08/26 15:40:44 step 7: objective=0.029529698
2017/08/26 15:40:44 Training value function...
2017/08/26 15:40:45 step 0: mse=0.805563 step=0.100000
2017/08/26 15:40:46 step 1: mse=0.758101 step=0.100000
2017/08/26 15:40:47 step 2: mse=0.719359 step=0.100000
2017/08/26 15:40:48 step 3: mse=0.683698 step=0.100000
2017/08/26 15:40:48 step 4: mse=0.656211 step=0.100000
2017/08/26 15:40:49 step 5: mse=0.627185 step=0.100000
2017/08/26 15:40:50 step 6: mse=0.596929 step=0.100000
2017/08/26 15:40:51 step 7: mse=0.572356 step=0.100000
2017/08/26 15:40:51 Saving...
2017/08/26 15:40:51 Gathering batch of experience...
2017/08/26 15:41:09 batch 345: mean=17.232558 stddev=6.526644 entropy=1.063863 frames=36359 count=43
2017/08/26 15:41:09 Training policy...
2017/08/26 15:41:15 step 0: objective=0.037311453
2017/08/26 15:41:19 step 1: objective=0.037392657
2017/08/26 15:41:23 step 2: objective=0.03747428
2017/08/26 15:41:27 step 3: objective=0.037554286
2017/08/26 15:41:31 step 4: objective=0.0376459
2017/08/26 15:41:35 step 5: objective=0.03769136
2017/08/26 15:41:39 step 6: objective=0.03776459
2017/08/26 15:41:43 step 7: objective=0.037874117
2017/08/26 15:41:43 Training value function...
2017/08/26 15:41:44 step 0: mse=1.240426 step=0.100000
2017/08/26 15:41:45 step 1: mse=1.162499 step=0.100000
2017/08/26 15:41:46 step 2: mse=1.099813 step=0.100000
2017/08/26 15:41:47 step 3: mse=1.029405 step=0.100000
2017/08/26 15:41:47 step 4: mse=0.974560 step=0.100000
2017/08/26 15:41:48 step 5: mse=0.941561 step=0.100000
2017/08/26 15:41:49 step 6: mse=0.900956 step=0.100000
2017/08/26 15:41:50 step 7: mse=0.878928 step=0.100000
2017/08/26 15:41:50 Saving...
2017/08/26 15:41:50 Gathering batch of experience...
2017/08/26 15:42:09 batch 346: mean=16.043478 stddev=7.083221 entropy=1.073088 frames=37299 count=46
2017/08/26 15:42:09 Training policy...
2017/08/26 15:42:15 step 0: objective=0.0019713088
2017/08/26 15:42:19 step 1: objective=0.0020227486
2017/08/26 15:42:23 step 2: objective=0.0021099672
2017/08/26 15:42:27 step 3: objective=0.0021955613
2017/08/26 15:42:31 step 4: objective=0.0022808453
2017/08/26 15:42:35 step 5: objective=0.0023110858
2017/08/26 15:42:40 step 6: objective=0.0023739256
2017/08/26 15:42:44 step 7: objective=0.002427791
2017/08/26 15:42:44 Training value function...
2017/08/26 15:42:45 step 0: mse=1.171454 step=0.100000
2017/08/26 15:42:46 step 1: mse=1.056549 step=0.100000
2017/08/26 15:42:47 step 2: mse=0.964582 step=0.100000
2017/08/26 15:42:47 step 3: mse=0.891555 step=0.100000
2017/08/26 15:42:48 step 4: mse=0.831853 step=0.100000
2017/08/26 15:42:49 step 5: mse=0.783661 step=0.100000
2017/08/26 15:42:50 step 6: mse=0.739013 step=0.100000
2017/08/26 15:42:50 step 7: mse=0.703543 step=0.100000
2017/08/26 15:42:50 Saving...
2017/08/26 15:42:51 Gathering batch of experience...
2017/08/26 15:43:09 batch 347: mean=16.222222 stddev=6.528191 entropy=1.064028 frames=36797 count=45
2017/08/26 15:43:09 Training policy...
2017/08/26 15:43:15 step 0: objective=0.03108999
2017/08/26 15:43:19 step 1: objective=0.031133808
2017/08/26 15:43:23 step 2: objective=0.031177448
2017/08/26 15:43:27 step 3: objective=0.031221062
2017/08/26 15:43:31 step 4: objective=0.031264585
2017/08/26 15:43:35 step 5: objective=0.031305764
2017/08/26 15:43:40 step 6: objective=0.03135458
2017/08/26 15:43:44 step 7: objective=0.03140128
2017/08/26 15:43:44 Training value function...
2017/08/26 15:43:45 step 0: mse=0.900986 step=0.100000
2017/08/26 15:43:46 step 1: mse=0.848474 step=0.100000
2017/08/26 15:43:47 step 2: mse=0.805608 step=0.100000
2017/08/26 15:43:47 step 3: mse=0.773730 step=0.100000
2017/08/26 15:43:48 step 4: mse=0.745593 step=0.100000
2017/08/26 15:43:49 step 5: mse=0.721997 step=0.100000
2017/08/26 15:43:50 step 6: mse=0.701968 step=0.100000
2017/08/26 15:43:50 step 7: mse=0.680989 step=0.100000
2017/08/26 15:43:50 Saving...
2017/08/26 15:43:50 Gathering batch of experience...
2017/08/26 15:44:09 batch 348: mean=16.488372 stddev=7.111642 entropy=1.059859 frames=36374 count=43
2017/08/26 15:44:09 Training policy...
2017/08/26 15:44:15 step 0: objective=0.013230022
2017/08/26 15:44:19 step 1: objective=0.013285052
2017/08/26 15:44:23 step 2: objective=0.01334052
2017/08/26 15:44:27 step 3: objective=0.013396522
2017/08/26 15:44:31 step 4: objective=0.013451777
2017/08/26 15:44:35 step 5: objective=0.013491103
2017/08/26 15:44:39 step 6: objective=0.013529877
2017/08/26 15:44:43 step 7: objective=0.013578308
2017/08/26 15:44:43 Training value function...
2017/08/26 15:44:45 step 0: mse=0.867654 step=0.100000
2017/08/26 15:44:45 step 1: mse=0.825599 step=0.100000
2017/08/26 15:44:46 step 2: mse=0.791865 step=0.100000
2017/08/26 15:44:47 step 3: mse=0.767316 step=0.100000
2017/08/26 15:44:48 step 4: mse=0.742480 step=0.100000
2017/08/26 15:44:48 step 5: mse=0.728285 step=0.100000
2017/08/26 15:44:49 step 6: mse=0.719064 step=0.100000
2017/08/26 15:44:50 step 7: mse=0.699456 step=0.100000
2017/08/26 15:44:50 Saving...
2017/08/26 15:44:50 Gathering batch of experience...
2017/08/26 15:45:09 batch 349: mean=15.555556 stddev=6.977919 entropy=1.063596 frames=36611 count=45
2017/08/26 15:45:09 Training policy...
2017/08/26 15:45:14 step 0: objective=0.04791488
2017/08/26 15:45:19 step 1: objective=0.047973216
2017/08/26 15:45:23 step 2: objective=0.04803215
2017/08/26 15:45:27 step 3: objective=0.048091907
2017/08/26 15:45:31 step 4: objective=0.04814745
2017/08/26 15:45:35 step 5: objective=0.048189763
2017/08/26 15:45:39 step 6: objective=0.048216425
2017/08/26 15:45:43 step 7: objective=0.04824104
2017/08/26 15:45:43 Training value function...
2017/08/26 15:45:45 step 0: mse=0.913528 step=0.100000
2017/08/26 15:45:45 step 1: mse=0.850205 step=0.100000
2017/08/26 15:45:46 step 2: mse=0.797199 step=0.100000
2017/08/26 15:45:47 step 3: mse=0.753675 step=0.100000
2017/08/26 15:45:48 step 4: mse=0.716844 step=0.100000
2017/08/26 15:45:48 step 5: mse=0.679461 step=0.100000
2017/08/26 15:45:49 step 6: mse=0.650387 step=0.100000
2017/08/26 15:45:50 step 7: mse=0.615342 step=0.100000
2017/08/26 15:45:50 Saving...
2017/08/26 15:45:50 Gathering batch of experience...
2017/08/26 15:46:08 batch 350: mean=16.454545 stddev=6.261188 entropy=1.063539 frames=36527 count=44
2017/08/26 15:46:08 Training policy...
2017/08/26 15:46:14 step 0: objective=0.027759846
2017/08/26 15:46:18 step 1: objective=0.027821073
2017/08/26 15:46:23 step 2: objective=0.027882393
2017/08/26 15:46:27 step 3: objective=0.02794412
2017/08/26 15:46:31 step 4: objective=0.02800043
2017/08/26 15:46:35 step 5: objective=0.028050266
2017/08/26 15:46:39 step 6: objective=0.028090369
2017/08/26 15:46:43 step 7: objective=0.028129205
2017/08/26 15:46:43 Training value function...
2017/08/26 15:46:44 step 0: mse=0.843675 step=0.100000
2017/08/26 15:46:45 step 1: mse=0.816940 step=0.100000
2017/08/26 15:46:46 step 2: mse=0.794814 step=0.100000
2017/08/26 15:46:47 step 3: mse=0.770885 step=0.100000
2017/08/26 15:46:48 step 4: mse=0.741448 step=0.100000
2017/08/26 15:46:48 step 5: mse=0.718467 step=0.100000
2017/08/26 15:46:49 step 6: mse=0.685992 step=0.100000
2017/08/26 15:46:50 step 7: mse=0.674115 step=0.100000
2017/08/26 15:46:50 Saving...
2017/08/26 15:46:50 Gathering batch of experience...
2017/08/26 15:47:08 batch 351: mean=14.723404 stddev=7.236733 entropy=1.068032 frames=36381 count=47
2017/08/26 15:47:08 Training policy...
2017/08/26 15:47:14 step 0: objective=0.024243554
2017/08/26 15:47:18 step 1: objective=0.02426574
2017/08/26 15:47:22 step 2: objective=0.024288353
2017/08/26 15:47:26 step 3: objective=0.024310684
2017/08/26 15:47:30 step 4: objective=0.02433301
2017/08/26 15:47:34 step 5: objective=0.02435557
2017/08/26 15:47:39 step 6: objective=0.024378179
2017/08/26 15:47:43 step 7: objective=0.024399104
2017/08/26 15:47:43 Training value function...
2017/08/26 15:47:44 step 0: mse=0.812224 step=0.100000
2017/08/26 15:47:45 step 1: mse=0.783005 step=0.100000
2017/08/26 15:47:45 step 2: mse=0.759243 step=0.100000
2017/08/26 15:47:46 step 3: mse=0.739765 step=0.100000
2017/08/26 15:47:47 step 4: mse=0.724844 step=0.100000
2017/08/26 15:47:48 step 5: mse=0.702515 step=0.100000
2017/08/26 15:47:48 step 6: mse=0.683956 step=0.100000
2017/08/26 15:47:49 step 7: mse=0.663405 step=0.100000
2017/08/26 15:47:49 Saving...
2017/08/26 15:47:49 Gathering batch of experience...
2017/08/26 15:48:08 batch 352: mean=15.600000 stddev=6.440842 entropy=1.071356 frames=36606 count=45
2017/08/26 15:48:08 Training policy...
2017/08/26 15:48:14 step 0: objective=0.040577892
2017/08/26 15:48:18 step 1: objective=0.040605493
2017/08/26 15:48:22 step 2: objective=0.040633366
2017/08/26 15:48:26 step 3: objective=0.040660728
2017/08/26 15:48:30 step 4: objective=0.040688556
2017/08/26 15:48:34 step 5: objective=0.040713526
2017/08/26 15:48:39 step 6: objective=0.040733993
2017/08/26 15:48:43 step 7: objective=0.040771443
2017/08/26 15:48:43 Training value function...
2017/08/26 15:48:44 step 0: mse=0.932571 step=0.100000
2017/08/26 15:48:45 step 1: mse=0.867790 step=0.100000
2017/08/26 15:48:45 step 2: mse=0.814318 step=0.100000
2017/08/26 15:48:46 step 3: mse=0.770965 step=0.100000
2017/08/26 15:48:47 step 4: mse=0.735213 step=0.100000
2017/08/26 15:48:48 step 5: mse=0.701448 step=0.100000
2017/08/26 15:48:49 step 6: mse=0.674650 step=0.100000
2017/08/26 15:48:49 step 7: mse=0.653128 step=0.100000
2017/08/26 15:48:49 Saving...
2017/08/26 15:48:49 Gathering batch of experience...
2017/08/26 15:49:07 batch 353: mean=16.279070 stddev=6.377014 entropy=1.063902 frames=35737 count=43
2017/08/26 15:49:07 Training policy...
2017/08/26 15:49:13 step 0: objective=0.03299494
2017/08/26 15:49:17 step 1: objective=0.033074938
2017/08/26 15:49:21 step 2: objective=0.033155188
2017/08/26 15:49:25 step 3: objective=0.03323166
2017/08/26 15:49:29 step 4: objective=0.03327004
2017/08/26 15:49:33 step 5: objective=0.033306874
2017/08/26 15:49:37 step 6: objective=0.03334309
2017/08/26 15:49:41 step 7: objective=0.033373035
2017/08/26 15:49:41 Training value function...
2017/08/26 15:49:43 step 0: mse=0.778448 step=0.100000
2017/08/26 15:49:43 step 1: mse=0.755126 step=0.100000
2017/08/26 15:49:44 step 2: mse=0.724184 step=0.100000
2017/08/26 15:49:45 step 3: mse=0.699265 step=0.100000
2017/08/26 15:49:46 step 4: mse=0.686027 step=0.100000
2017/08/26 15:49:46 step 5: mse=0.664641 step=0.100000
2017/08/26 15:49:47 step 6: mse=0.653257 step=0.100000
2017/08/26 15:49:48 step 7: mse=0.643373 step=0.100000
2017/08/26 15:49:48 Saving...
2017/08/26 15:49:48 Gathering batch of experience...
2017/08/26 15:50:06 batch 354: mean=16.833333 stddev=7.609257 entropy=1.062892 frames=35762 count=42
2017/08/26 15:50:06 Training policy...
2017/08/26 15:50:12 step 0: objective=0.04699363
2017/08/26 15:50:16 step 1: objective=0.047043763
2017/08/26 15:50:20 step 2: objective=0.047093734
2017/08/26 15:50:24 step 3: objective=0.04714371
2017/08/26 15:50:28 step 4: objective=0.047193523
2017/08/26 15:50:32 step 5: objective=0.04724384
2017/08/26 15:50:36 step 6: objective=0.047292292
2017/08/26 15:50:40 step 7: objective=0.047343448
2017/08/26 15:50:40 Training value function...
2017/08/26 15:50:41 step 0: mse=1.103388 step=0.100000
2017/08/26 15:50:42 step 1: mse=1.000423 step=0.100000
2017/08/26 15:50:43 step 2: mse=0.917740 step=0.100000
2017/08/26 15:50:44 step 3: mse=0.842373 step=0.100000
2017/08/26 15:50:44 step 4: mse=0.782382 step=0.100000
2017/08/26 15:50:45 step 5: mse=0.728634 step=0.100000
2017/08/26 15:50:46 step 6: mse=0.681969 step=0.100000
2017/08/26 15:50:46 step 7: mse=0.645770 step=0.100000
2017/08/26 15:50:46 Saving...
2017/08/26 15:50:47 Gathering batch of experience...
2017/08/26 15:51:05 batch 355: mean=18.365854 stddev=8.078143 entropy=1.058589 frames=36284 count=41
2017/08/26 15:51:05 Training policy...
2017/08/26 15:51:11 step 0: objective=0.044175994
2017/08/26 15:51:15 step 1: objective=0.044230808
2017/08/26 15:51:19 step 2: objective=0.04428585
2017/08/26 15:51:23 step 3: objective=0.044340912
2017/08/26 15:51:27 step 4: objective=0.044395454
2017/08/26 15:51:31 step 5: objective=0.044459816
2017/08/26 15:51:35 step 6: objective=0.044520166
2017/08/26 15:51:39 step 7: objective=0.044558752
2017/08/26 15:51:39 Training value function...
2017/08/26 15:51:41 step 0: mse=0.943657 step=0.100000
2017/08/26 15:51:41 step 1: mse=0.885270 step=0.100000
2017/08/26 15:51:42 step 2: mse=0.837473 step=0.100000
2017/08/26 15:51:43 step 3: mse=0.796068 step=0.100000
2017/08/26 15:51:44 step 4: mse=0.763280 step=0.100000
2017/08/26 15:51:44 step 5: mse=0.734515 step=0.100000
2017/08/26 15:51:45 step 6: mse=0.711368 step=0.100000
2017/08/26 15:51:46 step 7: mse=0.691712 step=0.100000
2017/08/26 15:51:46 Saving...
2017/08/26 15:51:46 Gathering batch of experience...
2017/08/26 15:52:04 batch 356: mean=15.488372 stddev=5.682990 entropy=1.065730 frames=35889 count=43
2017/08/26 15:52:04 Training policy...
2017/08/26 15:52:10 step 0: objective=0.007161757
2017/08/26 15:52:14 step 1: objective=0.0072046435
2017/08/26 15:52:18 step 2: objective=0.0072469003
2017/08/26 15:52:22 step 3: objective=0.0072885863
2017/08/26 15:52:26 step 4: objective=0.0073284
2017/08/26 15:52:30 step 5: objective=0.007368397
2017/08/26 15:52:35 step 6: objective=0.0074050464
2017/08/26 15:52:39 step 7: objective=0.0074515883
2017/08/26 15:52:39 Training value function...
2017/08/26 15:52:40 step 0: mse=0.640393 step=0.100000
2017/08/26 15:52:41 step 1: mse=0.609430 step=0.100000
2017/08/26 15:52:41 step 2: mse=0.585545 step=0.100000
2017/08/26 15:52:42 step 3: mse=0.563239 step=0.100000
2017/08/26 15:52:43 step 4: mse=0.545366 step=0.100000
2017/08/26 15:52:44 step 5: mse=0.532403 step=0.100000
2017/08/26 15:52:44 step 6: mse=0.514832 step=0.100000
2017/08/26 15:52:45 step 7: mse=0.504983 step=0.100000
2017/08/26 15:52:45 Saving...
2017/08/26 15:52:45 Gathering batch of experience...
2017/08/26 15:53:03 batch 357: mean=14.913043 stddev=5.559270 entropy=1.070086 frames=35987 count=46
2017/08/26 15:53:03 Training policy...
2017/08/26 15:53:09 step 0: objective=0.027839892
2017/08/26 15:53:13 step 1: objective=0.027867783
2017/08/26 15:53:17 step 2: objective=0.027895844
2017/08/26 15:53:21 step 3: objective=0.027924117
2017/08/26 15:53:25 step 4: objective=0.02795239
2017/08/26 15:53:30 step 5: objective=0.027978843
2017/08/26 15:53:34 step 6: objective=0.02800178
2017/08/26 15:53:38 step 7: objective=0.028037068
2017/08/26 15:53:38 Training value function...
2017/08/26 15:53:39 step 0: mse=0.676035 step=0.100000
2017/08/26 15:53:40 step 1: mse=0.641173 step=0.100000
2017/08/26 15:53:41 step 2: mse=0.612263 step=0.100000
2017/08/26 15:53:41 step 3: mse=0.588427 step=0.100000
2017/08/26 15:53:42 step 4: mse=0.565096 step=0.100000
2017/08/26 15:53:43 step 5: mse=0.545112 step=0.100000
2017/08/26 15:53:43 step 6: mse=0.530048 step=0.100000
2017/08/26 15:53:44 step 7: mse=0.515142 step=0.100000
2017/08/26 15:53:44 Saving...
2017/08/26 15:53:44 Gathering batch of experience...
2017/08/26 15:54:02 batch 358: mean=15.866667 stddev=7.144851 entropy=1.068404 frames=36343 count=45
2017/08/26 15:54:02 Training policy...
2017/08/26 15:54:08 step 0: objective=0.03238501
2017/08/26 15:54:12 step 1: objective=0.032464225
2017/08/26 15:54:17 step 2: objective=0.032543577
2017/08/26 15:54:21 step 3: objective=0.032623302
2017/08/26 15:54:25 step 4: objective=0.03269286
2017/08/26 15:54:29 step 5: objective=0.032726392
2017/08/26 15:54:33 step 6: objective=0.032782722
2017/08/26 15:54:37 step 7: objective=0.032814
2017/08/26 15:54:37 Training value function...
2017/08/26 15:54:39 step 0: mse=0.993612 step=0.100000
2017/08/26 15:54:39 step 1: mse=0.944602 step=0.100000
2017/08/26 15:54:40 step 2: mse=0.905212 step=0.100000
2017/08/26 15:54:41 step 3: mse=0.866584 step=0.100000
2017/08/26 15:54:42 step 4: mse=0.827921 step=0.100000
2017/08/26 15:54:42 step 5: mse=0.800123 step=0.100000
2017/08/26 15:54:43 step 6: mse=0.772552 step=0.100000
2017/08/26 15:54:44 step 7: mse=0.749135 step=0.100000
2017/08/26 15:54:44 Saving...
2017/08/26 15:54:44 Gathering batch of experience...
2017/08/26 15:55:02 batch 359: mean=15.931818 stddev=5.474726 entropy=1.066400 frames=36137 count=44
2017/08/26 15:55:02 Training policy...
2017/08/26 15:55:08 step 0: objective=0.02985297
2017/08/26 15:55:12 step 1: objective=0.029943284
2017/08/26 15:55:16 step 2: objective=0.030033438
2017/08/26 15:55:20 step 3: objective=0.030123929
2017/08/26 15:55:25 step 4: objective=0.030209212
2017/08/26 15:55:29 step 5: objective=0.03028236
2017/08/26 15:55:33 step 6: objective=0.030345203
2017/08/26 15:55:37 step 7: objective=0.030390484
2017/08/26 15:55:37 Training value function...
2017/08/26 15:55:38 step 0: mse=0.876393 step=0.100000
2017/08/26 15:55:39 step 1: mse=0.817967 step=0.100000
2017/08/26 15:55:40 step 2: mse=0.770958 step=0.100000
2017/08/26 15:55:40 step 3: mse=0.734947 step=0.100000
2017/08/26 15:55:41 step 4: mse=0.708424 step=0.100000
2017/08/26 15:55:42 step 5: mse=0.681043 step=0.100000
2017/08/26 15:55:43 step 6: mse=0.651945 step=0.100000
2017/08/26 15:55:43 step 7: mse=0.631379 step=0.100000
2017/08/26 15:55:43 Saving...
2017/08/26 15:55:44 Gathering batch of experience...
2017/08/26 15:56:02 batch 360: mean=19.475000 stddev=7.499958 entropy=1.048460 frames=36517 count=40
2017/08/26 15:56:02 Training policy...
2017/08/26 15:56:08 step 0: objective=0.048492804
2017/08/26 15:56:12 step 1: objective=0.04857754
2017/08/26 15:56:16 step 2: objective=0.048661813
2017/08/26 15:56:20 step 3: objective=0.048746243
2017/08/26 15:56:24 step 4: objective=0.04882729
2017/08/26 15:56:29 step 5: objective=0.048869938
2017/08/26 15:56:33 step 6: objective=0.04891419
2017/08/26 15:56:37 step 7: objective=0.04896799
2017/08/26 15:56:37 Training value function...
2017/08/26 15:56:38 step 0: mse=1.704373 step=0.100000
2017/08/26 15:56:39 step 1: mse=1.569097 step=0.100000
2017/08/26 15:56:40 step 2: mse=1.460514 step=0.100000
2017/08/26 15:56:41 step 3: mse=1.350727 step=0.100000
2017/08/26 15:56:41 step 4: mse=1.284181 step=0.100000
2017/08/26 15:56:42 step 5: mse=1.217044 step=0.100000
2017/08/26 15:56:43 step 6: mse=1.172726 step=0.100000
2017/08/26 15:56:44 step 7: mse=1.103987 step=0.100000
2017/08/26 15:56:44 Saving...
2017/08/26 15:56:44 Gathering batch of experience...
2017/08/26 15:57:02 batch 361: mean=15.553191 stddev=6.747130 entropy=1.060017 frames=36599 count=47
2017/08/26 15:57:02 Training policy...
2017/08/26 15:57:08 step 0: objective=0.008779056
2017/08/26 15:57:12 step 1: objective=0.008831768
2017/08/26 15:57:17 step 2: objective=0.0088843545
2017/08/26 15:57:21 step 3: objective=0.008936955
2017/08/26 15:57:25 step 4: objective=0.008989445
2017/08/26 15:57:29 step 5: objective=0.009039954
2017/08/26 15:57:33 step 6: objective=0.009069472
2017/08/26 15:57:37 step 7: objective=0.00911164
2017/08/26 15:57:37 Training value function...
2017/08/26 15:57:39 step 0: mse=0.856777 step=0.100000
2017/08/26 15:57:39 step 1: mse=0.812596 step=0.100000
2017/08/26 15:57:40 step 2: mse=0.778582 step=0.100000
2017/08/26 15:57:41 step 3: mse=0.751029 step=0.100000
2017/08/26 15:57:42 step 4: mse=0.729597 step=0.100000
2017/08/26 15:57:43 step 5: mse=0.712968 step=0.100000
2017/08/26 15:57:43 step 6: mse=0.687926 step=0.100000
2017/08/26 15:57:44 step 7: mse=0.661220 step=0.100000
2017/08/26 15:57:44 Saving...
2017/08/26 15:57:44 Gathering batch of experience...
2017/08/26 15:58:03 batch 362: mean=16.340909 stddev=7.531580 entropy=1.071111 frames=36205 count=44
2017/08/26 15:58:03 Training policy...
2017/08/26 15:58:08 step 0: objective=0.016393129
2017/08/26 15:58:13 step 1: objective=0.016452437
2017/08/26 15:58:17 step 2: objective=0.016511805
2017/08/26 15:58:21 step 3: objective=0.016571222
2017/08/26 15:58:25 step 4: objective=0.016630094
2017/08/26 15:58:29 step 5: objective=0.016686074
2017/08/26 15:58:33 step 6: objective=0.016730921
2017/08/26 15:58:38 step 7: objective=0.016780134
2017/08/26 15:58:38 Training value function...
2017/08/26 15:58:39 step 0: mse=0.910171 step=0.100000
2017/08/26 15:58:40 step 1: mse=0.842154 step=0.100000
2017/08/26 15:58:40 step 2: mse=0.787980 step=0.100000
2017/08/26 15:58:41 step 3: mse=0.747208 step=0.100000
2017/08/26 15:58:42 step 4: mse=0.708489 step=0.100000
2017/08/26 15:58:42 step 5: mse=0.681246 step=0.100000
2017/08/26 15:58:43 step 6: mse=0.654556 step=0.100000
2017/08/26 15:58:44 step 7: mse=0.625206 step=0.100000
2017/08/26 15:58:44 Saving...
2017/08/26 15:58:44 Gathering batch of experience...
2017/08/26 15:59:03 batch 363: mean=17.409091 stddev=6.242516 entropy=1.065156 frames=36841 count=44
2017/08/26 15:59:03 Training policy...
2017/08/26 15:59:09 step 0: objective=0.045328878
2017/08/26 15:59:13 step 1: objective=0.04540572
2017/08/26 15:59:17 step 2: objective=0.045482904
2017/08/26 15:59:21 step 3: objective=0.04555908
2017/08/26 15:59:26 step 4: objective=0.045617178
2017/08/26 15:59:30 step 5: objective=0.045663726
2017/08/26 15:59:34 step 6: objective=0.045694
2017/08/26 15:59:38 step 7: objective=0.04575161
2017/08/26 15:59:38 Training value function...
2017/08/26 15:59:40 step 0: mse=1.012279 step=0.100000
2017/08/26 15:59:40 step 1: mse=0.966604 step=0.100000
2017/08/26 15:59:41 step 2: mse=0.929679 step=0.100000
2017/08/26 15:59:42 step 3: mse=0.892359 step=0.100000
2017/08/26 15:59:43 step 4: mse=0.857342 step=0.100000
2017/08/26 15:59:43 step 5: mse=0.829058 step=0.100000
2017/08/26 15:59:44 step 6: mse=0.810224 step=0.100000
2017/08/26 15:59:45 step 7: mse=0.779733 step=0.100000
2017/08/26 15:59:45 Saving...
2017/08/26 15:59:45 Gathering batch of experience...
2017/08/26 16:00:04 batch 364: mean=17.476190 stddev=6.740913 entropy=1.049188 frames=36441 count=42
2017/08/26 16:00:04 Training policy...
2017/08/26 16:00:09 step 0: objective=0.024972148
2017/08/26 16:00:14 step 1: objective=0.025028182
2017/08/26 16:00:18 step 2: objective=0.025084365
2017/08/26 16:00:22 step 3: objective=0.025139758
2017/08/26 16:00:26 step 4: objective=0.025185667
2017/08/26 16:00:31 step 5: objective=0.025237532
2017/08/26 16:00:35 step 6: objective=0.02529399
2017/08/26 16:00:39 step 7: objective=0.025326699
2017/08/26 16:00:39 Training value function...
2017/08/26 16:00:40 step 0: mse=0.951770 step=0.100000
2017/08/26 16:00:41 step 1: mse=0.883802 step=0.100000
2017/08/26 16:00:42 step 2: mse=0.829089 step=0.100000
2017/08/26 16:00:42 step 3: mse=0.782950 step=0.100000
2017/08/26 16:00:43 step 4: mse=0.746922 step=0.100000
2017/08/26 16:00:44 step 5: mse=0.715142 step=0.100000
2017/08/26 16:00:45 step 6: mse=0.689865 step=0.100000
2017/08/26 16:00:45 step 7: mse=0.665834 step=0.100000
2017/08/26 16:00:45 Saving...
2017/08/26 16:00:46 Gathering batch of experience...
2017/08/26 16:01:05 batch 365: mean=17.930233 stddev=6.828107 entropy=1.058195 frames=37927 count=43
2017/08/26 16:01:05 Training policy...
2017/08/26 16:01:11 step 0: objective=0.040216383
2017/08/26 16:01:16 step 1: objective=0.04029368
2017/08/26 16:01:20 step 2: objective=0.04037104
2017/08/26 16:01:25 step 3: objective=0.040448863
2017/08/26 16:01:29 step 4: objective=0.040513992
2017/08/26 16:01:33 step 5: objective=0.040578105
2017/08/26 16:01:38 step 6: objective=0.0406209
2017/08/26 16:01:42 step 7: objective=0.040650785
2017/08/26 16:01:42 Training value function...
2017/08/26 16:01:43 step 0: mse=1.017186 step=0.100000
2017/08/26 16:01:44 step 1: mse=0.949900 step=0.100000
2017/08/26 16:01:45 step 2: mse=0.894770 step=0.100000
2017/08/26 16:01:46 step 3: mse=0.843096 step=0.100000
2017/08/26 16:01:47 step 4: mse=0.803910 step=0.100000
2017/08/26 16:01:47 step 5: mse=0.765864 step=0.100000
2017/08/26 16:01:48 step 6: mse=0.727643 step=0.100000
2017/08/26 16:01:49 step 7: mse=0.698604 step=0.100000
2017/08/26 16:01:49 Saving...
2017/08/26 16:01:49 Gathering batch of experience...
2017/08/26 16:02:07 batch 366: mean=16.113636 stddev=6.015948 entropy=1.067829 frames=36338 count=44
2017/08/26 16:02:07 Training policy...
2017/08/26 16:02:13 step 0: objective=0.023864781
2017/08/26 16:02:17 step 1: objective=0.023892742
2017/08/26 16:02:22 step 2: objective=0.023920799
2017/08/26 16:02:26 step 3: objective=0.023948872
2017/08/26 16:02:30 step 4: objective=0.02397317
2017/08/26 16:02:34 step 5: objective=0.02399777
2017/08/26 16:02:39 step 6: objective=0.02402185
2017/08/26 16:02:43 step 7: objective=0.024049878
2017/08/26 16:02:43 Training value function...
2017/08/26 16:02:44 step 0: mse=0.714453 step=0.100000
2017/08/26 16:02:45 step 1: mse=0.680685 step=0.100000
2017/08/26 16:02:46 step 2: mse=0.647257 step=0.100000
2017/08/26 16:02:46 step 3: mse=0.620582 step=0.100000
2017/08/26 16:02:47 step 4: mse=0.597948 step=0.100000
2017/08/26 16:02:48 step 5: mse=0.579538 step=0.100000
2017/08/26 16:02:48 step 6: mse=0.556057 step=0.100000
2017/08/26 16:02:49 step 7: mse=0.539109 step=0.100000
2017/08/26 16:02:49 Saving...
2017/08/26 16:02:49 Gathering batch of experience...
2017/08/26 16:03:08 batch 367: mean=16.681818 stddev=8.036204 entropy=1.062668 frames=36764 count=44
2017/08/26 16:03:08 Training policy...
2017/08/26 16:03:14 step 0: objective=0.034490228
2017/08/26 16:03:18 step 1: objective=0.034550585
2017/08/26 16:03:23 step 2: objective=0.034611132
2017/08/26 16:03:27 step 3: objective=0.034671664
2017/08/26 16:03:31 step 4: objective=0.034732725
2017/08/26 16:03:35 step 5: objective=0.034786653
2017/08/26 16:03:40 step 6: objective=0.034856714
2017/08/26 16:03:44 step 7: objective=0.03492103
2017/08/26 16:03:44 Training value function...
2017/08/26 16:03:45 step 0: mse=0.979029 step=0.100000
2017/08/26 16:03:46 step 1: mse=0.907498 step=0.100000
2017/08/26 16:03:47 step 2: mse=0.857920 step=0.100000
2017/08/26 16:03:47 step 3: mse=0.813281 step=0.100000
2017/08/26 16:03:48 step 4: mse=0.776693 step=0.100000
2017/08/26 16:03:49 step 5: mse=0.735665 step=0.100000
2017/08/26 16:03:50 step 6: mse=0.704928 step=0.100000
2017/08/26 16:03:50 step 7: mse=0.670876 step=0.100000
2017/08/26 16:03:50 Saving...
2017/08/26 16:03:50 Gathering batch of experience...
2017/08/26 16:04:09 batch 368: mean=16.363636 stddev=6.505560 entropy=1.066275 frames=36807 count=44
2017/08/26 16:04:09 Training policy...
2017/08/26 16:04:15 step 0: objective=0.023335252
2017/08/26 16:04:19 step 1: objective=0.023381062
2017/08/26 16:04:24 step 2: objective=0.02342693
2017/08/26 16:04:28 step 3: objective=0.02347263
2017/08/26 16:04:32 step 4: objective=0.023518173
2017/08/26 16:04:37 step 5: objective=0.023561714
2017/08/26 16:04:41 step 6: objective=0.02359873
2017/08/26 16:04:45 step 7: objective=0.02361813
2017/08/26 16:04:45 Training value function...
2017/08/26 16:04:46 step 0: mse=0.781399 step=0.100000
2017/08/26 16:04:47 step 1: mse=0.738831 step=0.100000
2017/08/26 16:04:48 step 2: mse=0.704836 step=0.100000
2017/08/26 16:04:49 step 3: mse=0.669762 step=0.100000
2017/08/26 16:04:50 step 4: mse=0.641878 step=0.100000
2017/08/26 16:04:50 step 5: mse=0.617058 step=0.100000
2017/08/26 16:04:51 step 6: mse=0.597492 step=0.100000
2017/08/26 16:04:52 step 7: mse=0.577972 step=0.100000
2017/08/26 16:04:52 Saving...
2017/08/26 16:04:52 Gathering batch of experience...
2017/08/26 16:05:11 batch 369: mean=18.232558 stddev=7.054068 entropy=1.063886 frames=37230 count=43
2017/08/26 16:05:11 Training policy...
2017/08/26 16:05:17 step 0: objective=0.058484316
2017/08/26 16:05:21 step 1: objective=0.05860318
2017/08/26 16:05:26 step 2: objective=0.058720797
2017/08/26 16:05:30 step 3: objective=0.058764845
2017/08/26 16:05:34 step 4: objective=0.05882543
2017/08/26 16:05:39 step 5: objective=0.05887516
2017/08/26 16:05:43 step 6: objective=0.058935344
2017/08/26 16:05:47 step 7: objective=0.0589914
2017/08/26 16:05:47 Training value function...
2017/08/26 16:05:48 step 0: mse=1.186916 step=0.100000
2017/08/26 16:05:49 step 1: mse=1.123790 step=0.100000
2017/08/26 16:05:50 step 2: mse=1.067619 step=0.100000
2017/08/26 16:05:51 step 3: mse=1.022240 step=0.100000
2017/08/26 16:05:52 step 4: mse=0.967310 step=0.100000
2017/08/26 16:05:52 step 5: mse=0.928564 step=0.100000
2017/08/26 16:05:53 step 6: mse=0.897328 step=0.100000
2017/08/26 16:05:54 step 7: mse=0.860707 step=0.100000
2017/08/26 16:05:54 Saving...
2017/08/26 16:05:54 Gathering batch of experience...
2017/08/26 16:06:13 batch 370: mean=17.395349 stddev=7.477531 entropy=1.061130 frames=36562 count=43
2017/08/26 16:06:13 Training policy...
2017/08/26 16:06:18 step 0: objective=0.028454779
2017/08/26 16:06:23 step 1: objective=0.02850723
2017/08/26 16:06:27 step 2: objective=0.028559903
2017/08/26 16:06:31 step 3: objective=0.028612474
2017/08/26 16:06:36 step 4: objective=0.028665436
2017/08/26 16:06:40 step 5: objective=0.028715724
2017/08/26 16:06:44 step 6: objective=0.028790621
2017/08/26 16:06:48 step 7: objective=0.028840913
2017/08/26 16:06:48 Training value function...
2017/08/26 16:06:50 step 0: mse=1.160333 step=0.100000
2017/08/26 16:06:50 step 1: mse=1.098535 step=0.100000
2017/08/26 16:06:51 step 2: mse=1.050242 step=0.100000
2017/08/26 16:06:52 step 3: mse=1.009937 step=0.100000
2017/08/26 16:06:53 step 4: mse=0.974547 step=0.100000
2017/08/26 16:06:53 step 5: mse=0.946909 step=0.100000
2017/08/26 16:06:54 step 6: mse=0.922098 step=0.100000
2017/08/26 16:06:55 step 7: mse=0.895720 step=0.100000
2017/08/26 16:06:55 Saving...
2017/08/26 16:06:55 Gathering batch of experience...
2017/08/26 16:07:14 batch 371: mean=17.066667 stddev=7.672172 entropy=1.066639 frames=37902 count=45
2017/08/26 16:07:14 Training policy...
2017/08/26 16:07:21 step 0: objective=0.018244466
2017/08/26 16:07:25 step 1: objective=0.01831923
2017/08/26 16:07:29 step 2: objective=0.018394092
2017/08/26 16:07:34 step 3: objective=0.018468479
2017/08/26 16:07:38 step 4: objective=0.018541569
2017/08/26 16:07:43 step 5: objective=0.018606994
2017/08/26 16:07:47 step 6: objective=0.018650942
2017/08/26 16:07:52 step 7: objective=0.01870091
2017/08/26 16:07:52 Training value function...
2017/08/26 16:07:53 step 0: mse=0.903671 step=0.100000
2017/08/26 16:07:54 step 1: mse=0.860456 step=0.100000
2017/08/26 16:07:54 step 2: mse=0.825881 step=0.100000
2017/08/26 16:07:55 step 3: mse=0.798043 step=0.100000
2017/08/26 16:07:56 step 4: mse=0.774430 step=0.100000
2017/08/26 16:07:57 step 5: mse=0.752125 step=0.100000
2017/08/26 16:07:57 step 6: mse=0.731870 step=0.100000
2017/08/26 16:07:58 step 7: mse=0.717975 step=0.100000
2017/08/26 16:07:58 Saving...
2017/08/26 16:07:58 Gathering batch of experience...
2017/08/26 16:08:17 batch 372: mean=17.046512 stddev=6.583819 entropy=1.059313 frames=36502 count=43
2017/08/26 16:08:17 Training policy...
2017/08/26 16:08:23 step 0: objective=0.025470274
2017/08/26 16:08:27 step 1: objective=0.025570273
2017/08/26 16:08:31 step 2: objective=0.025667686
2017/08/26 16:08:36 step 3: objective=0.025730228
2017/08/26 16:08:40 step 4: objective=0.025760008
2017/08/26 16:08:44 step 5: objective=0.025796585
2017/08/26 16:08:49 step 6: objective=0.02582613
2017/08/26 16:08:53 step 7: objective=0.025848504
2017/08/26 16:08:53 Training value function...
2017/08/26 16:08:54 step 0: mse=0.855489 step=0.100000
2017/08/26 16:08:55 step 1: mse=0.815826 step=0.100000
2017/08/26 16:08:55 step 2: mse=0.778387 step=0.100000
2017/08/26 16:08:56 step 3: mse=0.747472 step=0.100000
2017/08/26 16:08:57 step 4: mse=0.724183 step=0.100000
2017/08/26 16:08:58 step 5: mse=0.700369 step=0.100000
2017/08/26 16:08:58 step 6: mse=0.681354 step=0.100000
2017/08/26 16:08:59 step 7: mse=0.664996 step=0.100000
2017/08/26 16:08:59 Saving...
2017/08/26 16:08:59 Gathering batch of experience...
2017/08/26 16:09:17 batch 373: mean=17.238095 stddev=7.043435 entropy=1.053525 frames=36037 count=42
2017/08/26 16:09:17 Training policy...
2017/08/26 16:09:23 step 0: objective=0.0271593
2017/08/26 16:09:27 step 1: objective=0.027196879
2017/08/26 16:09:32 step 2: objective=0.027234515
2017/08/26 16:09:36 step 3: objective=0.027272157
2017/08/26 16:09:40 step 4: objective=0.02730961
2017/08/26 16:09:44 step 5: objective=0.027347079
2017/08/26 16:09:49 step 6: objective=0.027383035
2017/08/26 16:09:53 step 7: objective=0.027412243
2017/08/26 16:09:53 Training value function...
2017/08/26 16:09:54 step 0: mse=0.825283 step=0.100000
2017/08/26 16:09:55 step 1: mse=0.773863 step=0.100000
2017/08/26 16:09:56 step 2: mse=0.730747 step=0.100000
2017/08/26 16:09:56 step 3: mse=0.696677 step=0.100000
2017/08/26 16:09:57 step 4: mse=0.668834 step=0.100000
2017/08/26 16:09:58 step 5: mse=0.642111 step=0.100000
2017/08/26 16:09:58 step 6: mse=0.620550 step=0.100000
2017/08/26 16:09:59 step 7: mse=0.602700 step=0.100000
2017/08/26 16:09:59 Saving...
2017/08/26 16:09:59 Gathering batch of experience...
2017/08/26 16:10:17 batch 374: mean=16.952381 stddev=8.047337 entropy=1.055907 frames=35664 count=42
2017/08/26 16:10:17 Training policy...
2017/08/26 16:10:23 step 0: objective=0.02131788
2017/08/26 16:10:27 step 1: objective=0.021359859
2017/08/26 16:10:31 step 2: objective=0.021402637
2017/08/26 16:10:36 step 3: objective=0.0214402
2017/08/26 16:10:40 step 4: objective=0.021459796
2017/08/26 16:10:44 step 5: objective=0.021513807
2017/08/26 16:10:48 step 6: objective=0.021559462
2017/08/26 16:10:52 step 7: objective=0.021610392
2017/08/26 16:10:52 Training value function...
2017/08/26 16:10:54 step 0: mse=0.905315 step=0.100000
2017/08/26 16:10:54 step 1: mse=0.850422 step=0.100000
2017/08/26 16:10:55 step 2: mse=0.807319 step=0.100000
2017/08/26 16:10:56 step 3: mse=0.763964 step=0.100000
2017/08/26 16:10:57 step 4: mse=0.733574 step=0.100000
2017/08/26 16:10:57 step 5: mse=0.714209 step=0.100000
2017/08/26 16:10:58 step 6: mse=0.684540 step=0.100000
2017/08/26 16:10:59 step 7: mse=0.668512 step=0.100000
2017/08/26 16:10:59 Saving...
2017/08/26 16:10:59 Gathering batch of experience...
2017/08/26 16:11:18 batch 375: mean=17.909091 stddev=7.415641 entropy=1.052768 frames=37980 count=44
2017/08/26 16:11:18 Training policy...
2017/08/26 16:11:24 step 0: objective=0.0530101
2017/08/26 16:11:29 step 1: objective=0.053057104
2017/08/26 16:11:33 step 2: objective=0.05310416
2017/08/26 16:11:38 step 3: objective=0.053150974
2017/08/26 16:11:42 step 4: objective=0.053195488
2017/08/26 16:11:47 step 5: objective=0.053234264
2017/08/26 16:11:51 step 6: objective=0.05326267
2017/08/26 16:11:56 step 7: objective=0.05328268
2017/08/26 16:11:56 Training value function...
2017/08/26 16:11:57 step 0: mse=1.076203 step=0.100000
2017/08/26 16:11:58 step 1: mse=1.008852 step=0.100000
2017/08/26 16:11:59 step 2: mse=0.954321 step=0.100000
2017/08/26 16:11:59 step 3: mse=0.909330 step=0.100000
2017/08/26 16:12:00 step 4: mse=0.864942 step=0.100000
2017/08/26 16:12:01 step 5: mse=0.822179 step=0.100000
2017/08/26 16:12:02 step 6: mse=0.789454 step=0.100000
2017/08/26 16:12:03 step 7: mse=0.760338 step=0.100000
2017/08/26 16:12:03 Saving...
2017/08/26 16:12:03 Gathering batch of experience...
2017/08/26 16:12:22 batch 376: mean=18.071429 stddev=7.890298 entropy=1.056417 frames=37603 count=42
2017/08/26 16:12:22 Training policy...
2017/08/26 16:12:28 step 0: objective=0.031639263
2017/08/26 16:12:32 step 1: objective=0.03169411
2017/08/26 16:12:37 step 2: objective=0.031748995
2017/08/26 16:12:41 step 3: objective=0.03180379
2017/08/26 16:12:46 step 4: objective=0.031858295
2017/08/26 16:12:50 step 5: objective=0.0319078
2017/08/26 16:12:54 step 6: objective=0.031975806
2017/08/26 16:12:59 step 7: objective=0.032023672
2017/08/26 16:12:59 Training value function...
2017/08/26 16:13:00 step 0: mse=0.992346 step=0.100000
2017/08/26 16:13:01 step 1: mse=0.937025 step=0.100000
2017/08/26 16:13:02 step 2: mse=0.902343 step=0.100000
2017/08/26 16:13:02 step 3: mse=0.873040 step=0.100000
2017/08/26 16:13:03 step 4: mse=0.847638 step=0.100000
2017/08/26 16:13:04 step 5: mse=0.825066 step=0.100000
2017/08/26 16:13:05 step 6: mse=0.804601 step=0.100000
2017/08/26 16:13:05 step 7: mse=0.787444 step=0.100000
2017/08/26 16:13:05 Saving...
2017/08/26 16:13:06 Gathering batch of experience...
2017/08/26 16:13:24 batch 377: mean=14.891304 stddev=6.494909 entropy=1.064732 frames=36389 count=46
2017/08/26 16:13:24 Training policy...
2017/08/26 16:13:30 step 0: objective=0.002185549
2017/08/26 16:13:34 step 1: objective=0.0022392878
2017/08/26 16:13:39 step 2: objective=0.0022931378
2017/08/26 16:13:43 step 3: objective=0.0023470966
2017/08/26 16:13:47 step 4: objective=0.0024011177
2017/08/26 16:13:52 step 5: objective=0.002453407
2017/08/26 16:13:56 step 6: objective=0.0025003734
2017/08/26 16:14:00 step 7: objective=0.0025400745
2017/08/26 16:14:00 Training value function...
2017/08/26 16:14:01 step 0: mse=0.729167 step=0.100000
2017/08/26 16:14:02 step 1: mse=0.692910 step=0.100000
2017/08/26 16:14:03 step 2: mse=0.663821 step=0.100000
2017/08/26 16:14:04 step 3: mse=0.640196 step=0.100000
2017/08/26 16:14:04 step 4: mse=0.621213 step=0.100000
2017/08/26 16:14:05 step 5: mse=0.595985 step=0.100000
2017/08/26 16:14:06 step 6: mse=0.575930 step=0.100000
2017/08/26 16:14:07 step 7: mse=0.559413 step=0.100000
2017/08/26 16:14:07 Saving...
2017/08/26 16:14:07 Gathering batch of experience...
2017/08/26 16:14:26 batch 378: mean=16.266667 stddev=7.934174 entropy=1.052561 frames=36429 count=45
2017/08/26 16:14:26 Training policy...
2017/08/26 16:14:31 step 0: objective=0.045953114
2017/08/26 16:14:36 step 1: objective=0.04600402
2017/08/26 16:14:40 step 2: objective=0.046055347
2017/08/26 16:14:44 step 3: objective=0.046107247
2017/08/26 16:14:49 step 4: objective=0.046159264
2017/08/26 16:14:53 step 5: objective=0.046201717
2017/08/26 16:14:57 step 6: objective=0.046243414
2017/08/26 16:15:02 step 7: objective=0.046296142
2017/08/26 16:15:02 Training value function...
2017/08/26 16:15:03 step 0: mse=0.957844 step=0.100000
2017/08/26 16:15:04 step 1: mse=0.910102 step=0.100000
2017/08/26 16:15:04 step 2: mse=0.863884 step=0.100000
2017/08/26 16:15:05 step 3: mse=0.825158 step=0.100000
2017/08/26 16:15:06 step 4: mse=0.791267 step=0.100000
2017/08/26 16:15:07 step 5: mse=0.764140 step=0.100000
2017/08/26 16:15:07 step 6: mse=0.735239 step=0.100000
2017/08/26 16:15:08 step 7: mse=0.708343 step=0.100000
2017/08/26 16:15:08 Saving...
2017/08/26 16:15:08 Gathering batch of experience...
2017/08/26 16:15:27 batch 379: mean=16.400000 stddev=7.006029 entropy=1.057320 frames=37363 count=45
2017/08/26 16:15:27 Training policy...
2017/08/26 16:15:33 step 0: objective=0.026637396
2017/08/26 16:15:38 step 1: objective=0.026687637
2017/08/26 16:15:42 step 2: objective=0.026745342
2017/08/26 16:15:47 step 3: objective=0.026803322
2017/08/26 16:15:51 step 4: objective=0.026861219
2017/08/26 16:15:55 step 5: objective=0.026917307
2017/08/26 16:16:00 step 6: objective=0.02697403
2017/08/26 16:16:04 step 7: objective=0.027027607
2017/08/26 16:16:04 Training value function...
2017/08/26 16:16:06 step 0: mse=0.702664 step=0.100000
2017/08/26 16:16:06 step 1: mse=0.675506 step=0.100000
2017/08/26 16:16:07 step 2: mse=0.650574 step=0.100000
2017/08/26 16:16:08 step 3: mse=0.630770 step=0.100000
2017/08/26 16:16:09 step 4: mse=0.618424 step=0.100000
2017/08/26 16:16:10 step 5: mse=0.608434 step=0.100000
2017/08/26 16:16:10 step 6: mse=0.590025 step=0.100000
2017/08/26 16:16:11 step 7: mse=0.577787 step=0.100000
2017/08/26 16:16:11 Saving...
2017/08/26 16:16:11 Gathering batch of experience...
2017/08/26 16:16:30 batch 380: mean=15.818182 stddev=5.820312 entropy=1.055129 frames=36881 count=44
2017/08/26 16:16:30 Training policy...
2017/08/26 16:16:36 step 0: objective=0.009208448
2017/08/26 16:16:40 step 1: objective=0.009278553
2017/08/26 16:16:45 step 2: objective=0.009326711
2017/08/26 16:16:49 step 3: objective=0.009374523
2017/08/26 16:16:54 step 4: objective=0.009421749
2017/08/26 16:16:58 step 5: objective=0.009464699
2017/08/26 16:17:02 step 6: objective=0.009502252
2017/08/26 16:17:07 step 7: objective=0.009550102
2017/08/26 16:17:07 Training value function...
2017/08/26 16:17:08 step 0: mse=0.723838 step=0.100000
2017/08/26 16:17:09 step 1: mse=0.681463 step=0.100000
2017/08/26 16:17:10 step 2: mse=0.646536 step=0.100000
2017/08/26 16:17:10 step 3: mse=0.618504 step=0.100000
2017/08/26 16:17:11 step 4: mse=0.594336 step=0.100000
2017/08/26 16:17:12 step 5: mse=0.573967 step=0.100000
2017/08/26 16:17:13 step 6: mse=0.555737 step=0.100000
2017/08/26 16:17:13 step 7: mse=0.540041 step=0.100000
2017/08/26 16:17:13 Saving...
2017/08/26 16:17:14 Gathering batch of experience...
2017/08/26 16:17:32 batch 381: mean=17.690476 stddev=6.688612 entropy=1.056190 frames=36509 count=42
2017/08/26 16:17:32 Training policy...
2017/08/26 16:17:38 step 0: objective=0.04810842
2017/08/26 16:17:42 step 1: objective=0.048185192
2017/08/26 16:17:47 step 2: objective=0.048261937
2017/08/26 16:17:51 step 3: objective=0.04830807
2017/08/26 16:17:55 step 4: objective=0.04834636
2017/08/26 16:18:00 step 5: objective=0.0483952
2017/08/26 16:18:04 step 6: objective=0.048440848
2017/08/26 16:18:08 step 7: objective=0.04850958
2017/08/26 16:18:08 Training value function...
2017/08/26 16:18:10 step 0: mse=1.064853 step=0.100000
2017/08/26 16:18:10 step 1: mse=0.999857 step=0.100000
2017/08/26 16:18:11 step 2: mse=0.947389 step=0.100000
2017/08/26 16:18:12 step 3: mse=0.906623 step=0.100000
2017/08/26 16:18:13 step 4: mse=0.868513 step=0.100000
2017/08/26 16:18:13 step 5: mse=0.845390 step=0.100000
2017/08/26 16:18:14 step 6: mse=0.819029 step=0.100000
2017/08/26 16:18:15 step 7: mse=0.801924 step=0.100000
2017/08/26 16:18:15 Saving...
2017/08/26 16:18:15 Gathering batch of experience...
2017/08/26 16:18:34 batch 382: mean=18.547619 stddev=4.660893 entropy=1.050892 frames=37278 count=42
2017/08/26 16:18:34 Training policy...
2017/08/26 16:18:40 step 0: objective=0.0379644
2017/08/26 16:18:44 step 1: objective=0.038014237
2017/08/26 16:18:49 step 2: objective=0.0380639
2017/08/26 16:18:53 step 3: objective=0.038113896
2017/08/26 16:18:58 step 4: objective=0.038163975
2017/08/26 16:19:02 step 5: objective=0.038236603
2017/08/26 16:19:07 step 6: objective=0.038300626
2017/08/26 16:19:11 step 7: objective=0.038381044
2017/08/26 16:19:11 Training value function...
2017/08/26 16:19:12 step 0: mse=0.992323 step=0.100000
2017/08/26 16:19:13 step 1: mse=0.930069 step=0.100000
2017/08/26 16:19:14 step 2: mse=0.876383 step=0.100000
2017/08/26 16:19:15 step 3: mse=0.833137 step=0.100000
2017/08/26 16:19:15 step 4: mse=0.786948 step=0.100000
2017/08/26 16:19:16 step 5: mse=0.752173 step=0.100000
2017/08/26 16:19:17 step 6: mse=0.708568 step=0.100000
2017/08/26 16:19:18 step 7: mse=0.675765 step=0.100000
2017/08/26 16:19:18 Saving...
2017/08/26 16:19:18 Gathering batch of experience...
2017/08/26 16:19:36 batch 383: mean=18.261905 stddev=9.314759 entropy=1.045142 frames=36012 count=42
2017/08/26 16:19:36 Training policy...
2017/08/26 16:19:42 step 0: objective=0.043348003
2017/08/26 16:19:47 step 1: objective=0.04343198
2017/08/26 16:19:51 step 2: objective=0.04351529
2017/08/26 16:19:55 step 3: objective=0.043598652
2017/08/26 16:19:59 step 4: objective=0.043677535
2017/08/26 16:20:04 step 5: objective=0.043733794
2017/08/26 16:20:08 step 6: objective=0.043768056
2017/08/26 16:20:12 step 7: objective=0.04380429
2017/08/26 16:20:12 Training value function...
2017/08/26 16:20:13 step 0: mse=1.388580 step=0.100000
2017/08/26 16:20:14 step 1: mse=1.276881 step=0.100000
2017/08/26 16:20:15 step 2: mse=1.186927 step=0.100000
2017/08/26 16:20:16 step 3: mse=1.110300 step=0.100000
2017/08/26 16:20:16 step 4: mse=1.052622 step=0.100000
2017/08/26 16:20:17 step 5: mse=1.000533 step=0.100000
2017/08/26 16:20:18 step 6: mse=0.960065 step=0.100000
2017/08/26 16:20:18 step 7: mse=0.913649 step=0.100000
2017/08/26 16:20:18 Saving...
2017/08/26 16:20:19 Gathering batch of experience...
2017/08/26 16:20:38 batch 384: mean=16.844444 stddev=7.048894 entropy=1.059963 frames=37307 count=45
2017/08/26 16:20:38 Training policy...
2017/08/26 16:20:44 step 0: objective=0.031154456
2017/08/26 16:20:48 step 1: objective=0.031210994
2017/08/26 16:20:53 step 2: objective=0.03126751
2017/08/26 16:20:57 step 3: objective=0.031321526
2017/08/26 16:21:02 step 4: objective=0.031358637
2017/08/26 16:21:06 step 5: objective=0.031399768
2017/08/26 16:21:11 step 6: objective=0.031450555
2017/08/26 16:21:15 step 7: objective=0.031487383
2017/08/26 16:21:15 Training value function...
2017/08/26 16:21:16 step 0: mse=1.063188 step=0.100000
2017/08/26 16:21:17 step 1: mse=1.002477 step=0.100000
2017/08/26 16:21:18 step 2: mse=0.940764 step=0.100000
2017/08/26 16:21:19 step 3: mse=0.894373 step=0.100000
2017/08/26 16:21:19 step 4: mse=0.853350 step=0.100000
2017/08/26 16:21:20 step 5: mse=0.821003 step=0.100000
2017/08/26 16:21:21 step 6: mse=0.787770 step=0.100000
2017/08/26 16:21:22 step 7: mse=0.751048 step=0.100000
2017/08/26 16:21:22 Saving...
2017/08/26 16:21:22 Gathering batch of experience...
2017/08/26 16:21:40 batch 385: mean=15.488889 stddev=5.840937 entropy=1.060923 frames=36510 count=45
2017/08/26 16:21:40 Training policy...
2017/08/26 16:21:46 step 0: objective=0.015112768
2017/08/26 16:21:51 step 1: objective=0.01518212
2017/08/26 16:21:55 step 2: objective=0.01525139
2017/08/26 16:21:59 step 3: objective=0.015319625
2017/08/26 16:22:04 step 4: objective=0.01537272
2017/08/26 16:22:08 step 5: objective=0.015420764
2017/08/26 16:22:13 step 6: objective=0.01547183
2017/08/26 16:22:17 step 7: objective=0.015514829
2017/08/26 16:22:17 Training value function...
2017/08/26 16:22:18 step 0: mse=0.882085 step=0.100000
2017/08/26 16:22:19 step 1: mse=0.830945 step=0.100000
2017/08/26 16:22:20 step 2: mse=0.785645 step=0.100000
2017/08/26 16:22:20 step 3: mse=0.749294 step=0.100000
2017/08/26 16:22:21 step 4: mse=0.721429 step=0.100000
2017/08/26 16:22:22 step 5: mse=0.698910 step=0.100000
2017/08/26 16:22:23 step 6: mse=0.672460 step=0.100000
2017/08/26 16:22:23 step 7: mse=0.653353 step=0.100000
2017/08/26 16:22:23 Saving...
2017/08/26 16:22:24 Gathering batch of experience...
2017/08/26 16:22:43 batch 386: mean=17.093023 stddev=7.751411 entropy=1.045543 frames=37070 count=43
2017/08/26 16:22:43 Training policy...
2017/08/26 16:22:49 step 0: objective=0.019517481
2017/08/26 16:22:53 step 1: objective=0.019579325
2017/08/26 16:22:58 step 2: objective=0.019641165
2017/08/26 16:23:02 step 3: objective=0.019703332
2017/08/26 16:23:07 step 4: objective=0.019757856
2017/08/26 16:23:11 step 5: objective=0.019794613
2017/08/26 16:23:16 step 6: objective=0.019835282
2017/08/26 16:23:20 step 7: objective=0.019874379
2017/08/26 16:23:20 Training value function...
2017/08/26 16:23:21 step 0: mse=1.071721 step=0.100000
2017/08/26 16:23:22 step 1: mse=0.983710 step=0.100000
2017/08/26 16:23:23 step 2: mse=0.912088 step=0.100000
2017/08/26 16:23:24 step 3: mse=0.853274 step=0.100000
2017/08/26 16:23:24 step 4: mse=0.806283 step=0.100000
2017/08/26 16:23:25 step 5: mse=0.767868 step=0.100000
2017/08/26 16:23:26 step 6: mse=0.734855 step=0.100000
2017/08/26 16:23:27 step 7: mse=0.705849 step=0.100000
2017/08/26 16:23:27 Saving...
2017/08/26 16:23:27 Gathering batch of experience...
2017/08/26 16:23:46 batch 387: mean=18.325581 stddev=7.309506 entropy=1.052068 frames=38095 count=43
2017/08/26 16:23:46 Training policy...
2017/08/26 16:23:53 step 0: objective=0.03715929
2017/08/26 16:23:57 step 1: objective=0.03723537
2017/08/26 16:24:02 step 2: objective=0.037311535
2017/08/26 16:24:06 step 3: objective=0.03738743
2017/08/26 16:24:11 step 4: objective=0.037452888
2017/08/26 16:24:15 step 5: objective=0.037526794
2017/08/26 16:24:20 step 6: objective=0.03757112
2017/08/26 16:24:25 step 7: objective=0.037635982
2017/08/26 16:24:25 Training value function...
2017/08/26 16:24:26 step 0: mse=1.211795 step=0.100000
2017/08/26 16:24:27 step 1: mse=1.118259 step=0.100000
2017/08/26 16:24:27 step 2: mse=1.042996 step=0.100000
2017/08/26 16:24:28 step 3: mse=0.983547 step=0.100000
2017/08/26 16:24:29 step 4: mse=0.936997 step=0.100000
2017/08/26 16:24:30 step 5: mse=0.889972 step=0.100000
2017/08/26 16:24:31 step 6: mse=0.857540 step=0.100000
2017/08/26 16:24:31 step 7: mse=0.823179 step=0.100000
2017/08/26 16:24:31 Saving...
2017/08/26 16:24:32 Gathering batch of experience...
2017/08/26 16:24:50 batch 388: mean=17.000000 stddev=6.462774 entropy=1.053496 frames=36268 count=43
2017/08/26 16:24:50 Training policy...
2017/08/26 16:24:56 step 0: objective=0.031633366
2017/08/26 16:25:01 step 1: objective=0.031671107
2017/08/26 16:25:05 step 2: objective=0.031709187
2017/08/26 16:25:10 step 3: objective=0.031747427
2017/08/26 16:25:14 step 4: objective=0.031786047
2017/08/26 16:25:18 step 5: objective=0.03182271
2017/08/26 16:25:23 step 6: objective=0.031886987
2017/08/26 16:25:27 step 7: objective=0.03191752
2017/08/26 16:25:27 Training value function...
2017/08/26 16:25:28 step 0: mse=1.037758 step=0.100000
2017/08/26 16:25:29 step 1: mse=0.978104 step=0.100000
2017/08/26 16:25:30 step 2: mse=0.928677 step=0.100000
2017/08/26 16:25:30 step 3: mse=0.878564 step=0.100000
2017/08/26 16:25:31 step 4: mse=0.849523 step=0.100000
2017/08/26 16:25:32 step 5: mse=0.815041 step=0.100000
2017/08/26 16:25:33 step 6: mse=0.791177 step=0.100000
2017/08/26 16:25:33 step 7: mse=0.766597 step=0.100000
2017/08/26 16:25:33 Saving...
2017/08/26 16:25:33 Gathering batch of experience...
2017/08/26 16:25:52 batch 389: mean=16.886364 stddev=6.712322 entropy=1.045571 frames=36690 count=44
2017/08/26 16:25:52 Training policy...
2017/08/26 16:25:58 step 0: objective=0.02320675
2017/08/26 16:26:03 step 1: objective=0.02325279
2017/08/26 16:26:07 step 2: objective=0.023298975
2017/08/26 16:26:12 step 3: objective=0.023344668
2017/08/26 16:26:16 step 4: objective=0.02339059
2017/08/26 16:26:20 step 5: objective=0.023434967
2017/08/26 16:26:25 step 6: objective=0.02347248
2017/08/26 16:26:29 step 7: objective=0.023505332
2017/08/26 16:26:29 Training value function...
2017/08/26 16:26:30 step 0: mse=1.069429 step=0.100000
2017/08/26 16:26:31 step 1: mse=1.017828 step=0.100000
2017/08/26 16:26:32 step 2: mse=0.973294 step=0.100000
2017/08/26 16:26:33 step 3: mse=0.931115 step=0.100000
2017/08/26 16:26:33 step 4: mse=0.899252 step=0.100000
2017/08/26 16:26:34 step 5: mse=0.863102 step=0.100000
2017/08/26 16:26:35 step 6: mse=0.826843 step=0.100000
2017/08/26 16:26:36 step 7: mse=0.805753 step=0.100000
2017/08/26 16:26:36 Saving...
2017/08/26 16:26:36 Gathering batch of experience...
2017/08/26 16:26:55 batch 390: mean=16.130435 stddev=8.034190 entropy=1.057023 frames=37217 count=46
2017/08/26 16:26:55 Training policy...
2017/08/26 16:27:01 step 0: objective=0.033844966
2017/08/26 16:27:06 step 1: objective=0.033899322
2017/08/26 16:27:10 step 2: objective=0.03395489
2017/08/26 16:27:15 step 3: objective=0.033999354
2017/08/26 16:27:19 step 4: objective=0.034068696
2017/08/26 16:27:24 step 5: objective=0.034129277
2017/08/26 16:27:28 step 6: objective=0.034190513
2017/08/26 16:27:33 step 7: objective=0.034292445
2017/08/26 16:27:33 Training value function...
2017/08/26 16:27:34 step 0: mse=1.243191 step=0.100000
2017/08/26 16:27:35 step 1: mse=1.142144 step=0.100000
2017/08/26 16:27:35 step 2: mse=1.061079 step=0.100000
2017/08/26 16:27:36 step 3: mse=0.997593 step=0.100000
2017/08/26 16:27:37 step 4: mse=0.942830 step=0.100000
2017/08/26 16:27:38 step 5: mse=0.889929 step=0.100000
2017/08/26 16:27:38 step 6: mse=0.848686 step=0.100000
2017/08/26 16:27:39 step 7: mse=0.811422 step=0.100000
2017/08/26 16:27:39 Saving...
2017/08/26 16:27:39 Gathering batch of experience...
2017/08/26 16:27:58 batch 391: mean=14.913043 stddev=5.331718 entropy=1.054737 frames=36074 count=46
2017/08/26 16:27:58 Training policy...
2017/08/26 16:28:04 step 0: objective=0.0056219134
2017/08/26 16:28:08 step 1: objective=0.0056832125
2017/08/26 16:28:13 step 2: objective=0.005744629
2017/08/26 16:28:17 step 3: objective=0.005806227
2017/08/26 16:28:21 step 4: objective=0.005865378
2017/08/26 16:28:26 step 5: objective=0.005911805
2017/08/26 16:28:30 step 6: objective=0.005947367
2017/08/26 16:28:34 step 7: objective=0.0060081086
2017/08/26 16:28:34 Training value function...
2017/08/26 16:28:36 step 0: mse=0.678931 step=0.100000
2017/08/26 16:28:36 step 1: mse=0.639805 step=0.100000
2017/08/26 16:28:37 step 2: mse=0.607000 step=0.100000
2017/08/26 16:28:38 step 3: mse=0.584925 step=0.100000
2017/08/26 16:28:39 step 4: mse=0.571648 step=0.100000
2017/08/26 16:28:39 step 5: mse=0.550329 step=0.100000
2017/08/26 16:28:40 step 6: mse=0.540937 step=0.100000
2017/08/26 16:28:41 step 7: mse=0.529745 step=0.100000
2017/08/26 16:28:41 Saving...
2017/08/26 16:28:41 Gathering batch of experience...
2017/08/26 16:29:00 batch 392: mean=19.450000 stddev=5.886213 entropy=1.052472 frames=37163 count=40
2017/08/26 16:29:00 Training policy...
2017/08/26 16:29:06 step 0: objective=0.070518695
2017/08/26 16:29:11 step 1: objective=0.07058114
2017/08/26 16:29:15 step 2: objective=0.070643924
2017/08/26 16:29:20 step 3: objective=0.070706576
2017/08/26 16:29:24 step 4: objective=0.07075923
2017/08/26 16:29:29 step 5: objective=0.07080352
2017/08/26 16:29:33 step 6: objective=0.07087258
2017/08/26 16:29:38 step 7: objective=0.0709414
2017/08/26 16:29:38 Training value function...
2017/08/26 16:29:39 step 0: mse=1.014681 step=0.100000
2017/08/26 16:29:40 step 1: mse=0.956684 step=0.100000
2017/08/26 16:29:41 step 2: mse=0.907594 step=0.100000
2017/08/26 16:29:41 step 3: mse=0.866918 step=0.100000
2017/08/26 16:29:42 step 4: mse=0.831360 step=0.100000
2017/08/26 16:29:43 step 5: mse=0.801651 step=0.100000
2017/08/26 16:29:44 step 6: mse=0.775238 step=0.100000
2017/08/26 16:29:44 step 7: mse=0.754245 step=0.100000
2017/08/26 16:29:44 Saving...
2017/08/26 16:29:45 Gathering batch of experience...
2017/08/26 16:30:03 batch 393: mean=17.088889 stddev=7.032693 entropy=1.055826 frames=36368 count=45
2017/08/26 16:30:03 Training policy...
2017/08/26 16:30:09 step 0: objective=0.044398583
2017/08/26 16:30:14 step 1: objective=0.04450348
2017/08/26 16:30:18 step 2: objective=0.044607833
2017/08/26 16:30:22 step 3: objective=0.044703912
2017/08/26 16:30:27 step 4: objective=0.04479807
2017/08/26 16:30:31 step 5: objective=0.044883236
2017/08/26 16:30:36 step 6: objective=0.044974323
2017/08/26 16:30:40 step 7: objective=0.045022406
2017/08/26 16:30:40 Training value function...
2017/08/26 16:30:41 step 0: mse=1.261978 step=0.100000
2017/08/26 16:30:42 step 1: mse=1.156823 step=0.100000
2017/08/26 16:30:43 step 2: mse=1.077612 step=0.100000
2017/08/26 16:30:43 step 3: mse=1.012657 step=0.100000
2017/08/26 16:30:44 step 4: mse=0.950590 step=0.100000
2017/08/26 16:30:45 step 5: mse=0.889865 step=0.100000
2017/08/26 16:30:46 step 6: mse=0.848619 step=0.100000
2017/08/26 16:30:46 step 7: mse=0.815490 step=0.100000
2017/08/26 16:30:46 Saving...
2017/08/26 16:30:47 Gathering batch of experience...
2017/08/26 16:31:06 batch 394: mean=18.651163 stddev=9.039664 entropy=1.040233 frames=37635 count=43
2017/08/26 16:31:06 Training policy...
2017/08/26 16:31:12 step 0: objective=0.03701684
2017/08/26 16:31:17 step 1: objective=0.03709283
2017/08/26 16:31:21 step 2: objective=0.037168946
2017/08/26 16:31:26 step 3: objective=0.037243977
2017/08/26 16:31:30 step 4: objective=0.037316665
2017/08/26 16:31:35 step 5: objective=0.037388306
2017/08/26 16:31:39 step 6: objective=0.037452914
2017/08/26 16:31:44 step 7: objective=0.037523232
2017/08/26 16:31:44 Training value function...
2017/08/26 16:31:45 step 0: mse=1.498243 step=0.100000
2017/08/26 16:31:46 step 1: mse=1.391036 step=0.100000
2017/08/26 16:31:47 step 2: mse=1.294627 step=0.100000
2017/08/26 16:31:47 step 3: mse=1.195338 step=0.100000
2017/08/26 16:31:48 step 4: mse=1.136087 step=0.100000
2017/08/26 16:31:49 step 5: mse=1.072808 step=0.100000
2017/08/26 16:31:50 step 6: mse=1.020251 step=0.100000
2017/08/26 16:31:51 step 7: mse=0.966674 step=0.100000
2017/08/26 16:31:51 Saving...
2017/08/26 16:31:51 Gathering batch of experience...
2017/08/26 16:32:09 batch 395: mean=16.204545 stddev=6.946482 entropy=1.053182 frames=36388 count=44
2017/08/26 16:32:09 Training policy...
2017/08/26 16:32:15 step 0: objective=0.021780245
2017/08/26 16:32:20 step 1: objective=0.021819444
2017/08/26 16:32:24 step 2: objective=0.021858923
2017/08/26 16:32:29 step 3: objective=0.021898562
2017/08/26 16:32:33 step 4: objective=0.021937292
2017/08/26 16:32:37 step 5: objective=0.021966657
2017/08/26 16:32:42 step 6: objective=0.021993108
2017/08/26 16:32:46 step 7: objective=0.022057211
2017/08/26 16:32:46 Training value function...
2017/08/26 16:32:47 step 0: mse=0.772208 step=0.100000
2017/08/26 16:32:48 step 1: mse=0.727181 step=0.100000
2017/08/26 16:32:49 step 2: mse=0.690508 step=0.100000
2017/08/26 16:32:50 step 3: mse=0.667152 step=0.100000
2017/08/26 16:32:50 step 4: mse=0.647142 step=0.100000
2017/08/26 16:32:51 step 5: mse=0.631519 step=0.100000
2017/08/26 16:32:52 step 6: mse=0.607048 step=0.100000
2017/08/26 16:32:52 step 7: mse=0.593214 step=0.100000
2017/08/26 16:32:52 Saving...
2017/08/26 16:32:53 Gathering batch of experience...
2017/08/26 16:33:11 batch 396: mean=15.377778 stddev=5.851074 entropy=1.049718 frames=36751 count=45
2017/08/26 16:33:11 Training policy...
2017/08/26 16:33:17 step 0: objective=0.008095932
2017/08/26 16:33:22 step 1: objective=0.008137755
2017/08/26 16:33:26 step 2: objective=0.008179463
2017/08/26 16:33:31 step 3: objective=0.008221251
2017/08/26 16:33:35 step 4: objective=0.008262888
2017/08/26 16:33:40 step 5: objective=0.008304466
2017/08/26 16:33:44 step 6: objective=0.008340359
2017/08/26 16:33:49 step 7: objective=0.008360252
2017/08/26 16:33:49 Training value function...
2017/08/26 16:33:50 step 0: mse=0.654763 step=0.100000
2017/08/26 16:33:51 step 1: mse=0.626192 step=0.100000
2017/08/26 16:33:52 step 2: mse=0.606540 step=0.100000
2017/08/26 16:33:52 step 3: mse=0.578841 step=0.100000
2017/08/26 16:33:53 step 4: mse=0.561349 step=0.100000
2017/08/26 16:33:54 step 5: mse=0.551725 step=0.100000
2017/08/26 16:33:55 step 6: mse=0.539808 step=0.100000
2017/08/26 16:33:55 step 7: mse=0.519071 step=0.100000
2017/08/26 16:33:55 Saving...
2017/08/26 16:33:56 Gathering batch of experience...
2017/08/26 16:34:14 batch 397: mean=17.738095 stddev=6.817553 entropy=1.046313 frames=36467 count=42
2017/08/26 16:34:14 Training policy...
2017/08/26 16:34:20 step 0: objective=0.040982872
2017/08/26 16:34:25 step 1: objective=0.041018
2017/08/26 16:34:29 step 2: objective=0.04105273
2017/08/26 16:34:33 step 3: objective=0.04108758
2017/08/26 16:34:38 step 4: objective=0.041121844
2017/08/26 16:34:42 step 5: objective=0.041155763
2017/08/26 16:34:47 step 6: objective=0.041194756
2017/08/26 16:34:51 step 7: objective=0.041220747
2017/08/26 16:34:51 Training value function...
2017/08/26 16:34:52 step 0: mse=1.017271 step=0.100000
2017/08/26 16:34:53 step 1: mse=0.952726 step=0.100000
2017/08/26 16:34:54 step 2: mse=0.895065 step=0.100000
2017/08/26 16:34:55 step 3: mse=0.851363 step=0.100000
2017/08/26 16:34:55 step 4: mse=0.806026 step=0.100000
2017/08/26 16:34:56 step 5: mse=0.775104 step=0.100000
2017/08/26 16:34:57 step 6: mse=0.739320 step=0.100000
2017/08/26 16:34:58 step 7: mse=0.715247 step=0.100000
2017/08/26 16:34:58 Saving...
2017/08/26 16:34:58 Gathering batch of experience...
2017/08/26 16:35:17 batch 398: mean=18.658537 stddev=8.385847 entropy=1.047040 frames=37588 count=41
2017/08/26 16:35:17 Training policy...
2017/08/26 16:35:23 step 0: objective=0.05819789
2017/08/26 16:35:28 step 1: objective=0.05825832
2017/08/26 16:35:32 step 2: objective=0.058318693
2017/08/26 16:35:37 step 3: objective=0.0583787
2017/08/26 16:35:42 step 4: objective=0.05843517
2017/08/26 16:35:46 step 5: objective=0.05848618
2017/08/26 16:35:51 step 6: objective=0.058520596
2017/08/26 16:35:55 step 7: objective=0.058555447
2017/08/26 16:35:55 Training value function...
2017/08/26 16:35:57 step 0: mse=1.186642 step=0.100000
2017/08/26 16:35:57 step 1: mse=1.070402 step=0.100000
2017/08/26 16:35:58 step 2: mse=0.976271 step=0.100000
2017/08/26 16:35:59 step 3: mse=0.898319 step=0.100000
2017/08/26 16:36:00 step 4: mse=0.834422 step=0.100000
2017/08/26 16:36:00 step 5: mse=0.783937 step=0.100000
2017/08/26 16:36:01 step 6: mse=0.741560 step=0.100000
2017/08/26 16:36:02 step 7: mse=0.695470 step=0.100000
2017/08/26 16:36:02 Saving...
2017/08/26 16:36:02 Gathering batch of experience...
2017/08/26 16:36:21 batch 399: mean=17.902439 stddev=6.705676 entropy=1.041351 frames=36521 count=41
2017/08/26 16:36:21 Training policy...
2017/08/26 16:36:27 step 0: objective=0.03359498
2017/08/26 16:36:32 step 1: objective=0.03363528
2017/08/26 16:36:36 step 2: objective=0.033676047
2017/08/26 16:36:41 step 3: objective=0.033716537
2017/08/26 16:36:45 step 4: objective=0.03375543
2017/08/26 16:36:50 step 5: objective=0.03377706
2017/08/26 16:36:54 step 6: objective=0.033794872
2017/08/26 16:36:58 step 7: objective=0.03382474
2017/08/26 16:36:58 Training value function...
2017/08/26 16:37:00 step 0: mse=0.800837 step=0.100000
2017/08/26 16:37:00 step 1: mse=0.768672 step=0.100000
2017/08/26 16:37:01 step 2: mse=0.742142 step=0.100000
2017/08/26 16:37:02 step 3: mse=0.713007 step=0.100000
2017/08/26 16:37:03 step 4: mse=0.682555 step=0.100000
2017/08/26 16:37:03 step 5: mse=0.668907 step=0.100000
2017/08/26 16:37:04 step 6: mse=0.657511 step=0.100000
2017/08/26 16:37:05 step 7: mse=0.642442 step=0.100000
2017/08/26 16:37:05 Saving...
2017/08/26 16:37:05 Gathering batch of experience...
2017/08/26 16:37:24 batch 400: mean=17.181818 stddev=5.697977 entropy=1.052022 frames=36372 count=44
2017/08/26 16:37:24 Training policy...
2017/08/26 16:37:30 step 0: objective=0.032087967
2017/08/26 16:37:34 step 1: objective=0.032123804
2017/08/26 16:37:39 step 2: objective=0.032159287
2017/08/26 16:37:43 step 3: objective=0.03219498
2017/08/26 16:37:48 step 4: objective=0.032230377
2017/08/26 16:37:52 step 5: objective=0.03226559
2017/08/26 16:37:57 step 6: objective=0.032299653
2017/08/26 16:38:01 step 7: objective=0.0324101
2017/08/26 16:38:01 Training value function...
2017/08/26 16:38:02 step 0: mse=1.098696 step=0.100000
2017/08/26 16:38:03 step 1: mse=1.048789 step=0.100000
2017/08/26 16:38:04 step 2: mse=1.008712 step=0.100000
2017/08/26 16:38:04 step 3: mse=0.968336 step=0.100000
2017/08/26 16:38:05 step 4: mse=0.935172 step=0.100000
2017/08/26 16:38:06 step 5: mse=0.888796 step=0.100000
2017/08/26 16:38:07 step 6: mse=0.859391 step=0.100000
2017/08/26 16:38:07 step 7: mse=0.822191 step=0.100000
2017/08/26 16:38:07 Saving...
2017/08/26 16:38:07 Gathering batch of experience...
2017/08/26 16:38:26 batch 401: mean=17.093023 stddev=6.576257 entropy=1.048043 frames=36453 count=43
2017/08/26 16:38:26 Training policy...
2017/08/26 16:38:33 step 0: objective=0.03551995
2017/08/26 16:38:37 step 1: objective=0.035550732
2017/08/26 16:38:41 step 2: objective=0.03558217
2017/08/26 16:38:46 step 3: objective=0.035613533
2017/08/26 16:38:50 step 4: objective=0.03564109
2017/08/26 16:38:55 step 5: objective=0.0357067
2017/08/26 16:38:59 step 6: objective=0.035726864
2017/08/26 16:39:04 step 7: objective=0.03575325
2017/08/26 16:39:04 Training value function...
2017/08/26 16:39:05 step 0: mse=0.877903 step=0.100000
2017/08/26 16:39:06 step 1: mse=0.814696 step=0.100000
2017/08/26 16:39:07 step 2: mse=0.763615 step=0.100000
2017/08/26 16:39:07 step 3: mse=0.722147 step=0.100000
2017/08/26 16:39:08 step 4: mse=0.686168 step=0.100000
2017/08/26 16:39:09 step 5: mse=0.653543 step=0.100000
2017/08/26 16:39:10 step 6: mse=0.627551 step=0.100000
2017/08/26 16:39:10 step 7: mse=0.604302 step=0.100000
2017/08/26 16:39:10 Saving...
2017/08/26 16:39:11 Gathering batch of experience...
2017/08/26 16:39:29 batch 402: mean=17.666667 stddev=7.408704 entropy=1.053257 frames=35880 count=42
2017/08/26 16:39:29 Training policy...
2017/08/26 16:39:35 step 0: objective=0.05518025
2017/08/26 16:39:39 step 1: objective=0.055251043
2017/08/26 16:39:44 step 2: objective=0.055323083
2017/08/26 16:39:48 step 3: objective=0.055391796
2017/08/26 16:39:53 step 4: objective=0.05544802
2017/08/26 16:39:57 step 5: objective=0.055485673
2017/08/26 16:40:01 step 6: objective=0.055517145
2017/08/26 16:40:06 step 7: objective=0.0555489
2017/08/26 16:40:06 Training value function...
2017/08/26 16:40:07 step 0: mse=1.063292 step=0.100000
2017/08/26 16:40:08 step 1: mse=0.993286 step=0.100000
2017/08/26 16:40:08 step 2: mse=0.936536 step=0.100000
2017/08/26 16:40:09 step 3: mse=0.888328 step=0.100000
2017/08/26 16:40:10 step 4: mse=0.850095 step=0.100000
2017/08/26 16:40:11 step 5: mse=0.819046 step=0.100000
2017/08/26 16:40:11 step 6: mse=0.787253 step=0.100000
2017/08/26 16:40:12 step 7: mse=0.762337 step=0.100000
2017/08/26 16:40:12 Saving...
2017/08/26 16:40:12 Gathering batch of experience...
2017/08/26 16:40:31 batch 403: mean=18.756098 stddev=8.759052 entropy=1.042290 frames=36024 count=41
2017/08/26 16:40:31 Training policy...
2017/08/26 16:40:37 step 0: objective=0.021602405
2017/08/26 16:40:42 step 1: objective=0.021658126
2017/08/26 16:40:46 step 2: objective=0.021713756
2017/08/26 16:40:50 step 3: objective=0.021769477
2017/08/26 16:40:55 step 4: objective=0.021824714
2017/08/26 16:40:59 step 5: objective=0.021873064
2017/08/26 16:41:04 step 6: objective=0.02192817
2017/08/26 16:41:08 step 7: objective=0.021996493
2017/08/26 16:41:08 Training value function...
2017/08/26 16:41:09 step 0: mse=1.240902 step=0.100000
2017/08/26 16:41:10 step 1: mse=1.147106 step=0.100000
2017/08/26 16:41:11 step 2: mse=1.072266 step=0.100000
2017/08/26 16:41:11 step 3: mse=1.006241 step=0.100000
2017/08/26 16:41:12 step 4: mse=0.956478 step=0.100000
2017/08/26 16:41:13 step 5: mse=0.906969 step=0.100000
2017/08/26 16:41:14 step 6: mse=0.868374 step=0.100000
2017/08/26 16:41:14 step 7: mse=0.829028 step=0.100000
2017/08/26 16:41:14 Saving...
2017/08/26 16:41:14 Gathering batch of experience...
2017/08/26 16:41:34 batch 404: mean=17.613636 stddev=7.407662 entropy=1.038422 frames=37286 count=44
2017/08/26 16:41:34 Training policy...
2017/08/26 16:41:40 step 0: objective=0.036132626
2017/08/26 16:41:44 step 1: objective=0.036234666
2017/08/26 16:41:49 step 2: objective=0.036335915
2017/08/26 16:41:54 step 3: objective=0.036435664
2017/08/26 16:41:58 step 4: objective=0.036524825
2017/08/26 16:42:03 step 5: objective=0.036597613
2017/08/26 16:42:07 step 6: objective=0.036666006
2017/08/26 16:42:12 step 7: objective=0.03675014
2017/08/26 16:42:12 Training value function...
2017/08/26 16:42:13 step 0: mse=0.950269 step=0.100000
2017/08/26 16:42:14 step 1: mse=0.904541 step=0.100000
2017/08/26 16:42:15 step 2: mse=0.867616 step=0.100000
2017/08/26 16:42:15 step 3: mse=0.837326 step=0.100000
2017/08/26 16:42:16 step 4: mse=0.809852 step=0.100000
2017/08/26 16:42:17 step 5: mse=0.787357 step=0.100000
2017/08/26 16:42:18 step 6: mse=0.764040 step=0.100000
2017/08/26 16:42:18 step 7: mse=0.745662 step=0.100000
2017/08/26 16:42:18 Saving...
2017/08/26 16:42:19 Gathering batch of experience...
2017/08/26 16:42:37 batch 405: mean=15.955556 stddev=6.953674 entropy=1.054441 frames=36199 count=45
2017/08/26 16:42:37 Training policy...
2017/08/26 16:42:43 step 0: objective=-0.013866189
2017/08/26 16:42:48 step 1: objective=-0.01378194
2017/08/26 16:42:52 step 2: objective=-0.013696982
2017/08/26 16:42:57 step 3: objective=-0.013612247
2017/08/26 16:43:01 step 4: objective=-0.01353137
2017/08/26 16:43:06 step 5: objective=-0.013472869
2017/08/26 16:43:10 step 6: objective=-0.0134269465
2017/08/26 16:43:15 step 7: objective=-0.013389945
2017/08/26 16:43:15 Training value function...
2017/08/26 16:43:16 step 0: mse=1.110610 step=0.100000
2017/08/26 16:43:16 step 1: mse=1.032206 step=0.100000
2017/08/26 16:43:17 step 2: mse=0.972175 step=0.100000
2017/08/26 16:43:18 step 3: mse=0.911647 step=0.100000
2017/08/26 16:43:19 step 4: mse=0.871544 step=0.100000
2017/08/26 16:43:19 step 5: mse=0.836925 step=0.100000
2017/08/26 16:43:20 step 6: mse=0.808297 step=0.100000
2017/08/26 16:43:21 step 7: mse=0.777420 step=0.100000
2017/08/26 16:43:21 Saving...
2017/08/26 16:43:21 Gathering batch of experience...
2017/08/26 16:43:40 batch 406: mean=18.439024 stddev=7.197726 entropy=1.038922 frames=36705 count=41
2017/08/26 16:43:40 Training policy...
2017/08/26 16:43:46 step 0: objective=0.031557
2017/08/26 16:43:51 step 1: objective=0.031638797
2017/08/26 16:43:55 step 2: objective=0.031719536
2017/08/26 16:44:00 step 3: objective=0.031794805
2017/08/26 16:44:04 step 4: objective=0.031842664
2017/08/26 16:44:09 step 5: objective=0.03186435
2017/08/26 16:44:13 step 6: objective=0.031891048
2017/08/26 16:44:18 step 7: objective=0.03191875
2017/08/26 16:44:18 Training value function...
2017/08/26 16:44:19 step 0: mse=1.035998 step=0.100000
2017/08/26 16:44:20 step 1: mse=0.978198 step=0.100000
2017/08/26 16:44:21 step 2: mse=0.931410 step=0.100000
2017/08/26 16:44:21 step 3: mse=0.894729 step=0.100000
2017/08/26 16:44:22 step 4: mse=0.865152 step=0.100000
2017/08/26 16:44:23 step 5: mse=0.829919 step=0.100000
2017/08/26 16:44:24 step 6: mse=0.795020 step=0.100000
2017/08/26 16:44:24 step 7: mse=0.777467 step=0.100000
2017/08/26 16:44:24 Saving...
2017/08/26 16:44:25 Gathering batch of experience...
2017/08/26 16:44:44 batch 407: mean=15.717391 stddev=6.316517 entropy=1.050327 frames=37028 count=46
2017/08/26 16:44:44 Training policy...
2017/08/26 16:44:50 step 0: objective=0.016191823
2017/08/26 16:44:54 step 1: objective=0.01624321
2017/08/26 16:44:59 step 2: objective=0.016295204
2017/08/26 16:45:04 step 3: objective=0.016347917
2017/08/26 16:45:08 step 4: objective=0.01639638
2017/08/26 16:45:13 step 5: objective=0.016453382
2017/08/26 16:45:17 step 6: objective=0.016482724
2017/08/26 16:45:22 step 7: objective=0.016536338
2017/08/26 16:45:22 Training value function...
2017/08/26 16:45:23 step 0: mse=0.934612 step=0.100000
2017/08/26 16:45:24 step 1: mse=0.879728 step=0.100000
2017/08/26 16:45:25 step 2: mse=0.836065 step=0.100000
2017/08/26 16:45:25 step 3: mse=0.800804 step=0.100000
2017/08/26 16:45:26 step 4: mse=0.772746 step=0.100000
2017/08/26 16:45:27 step 5: mse=0.748197 step=0.100000
2017/08/26 16:45:28 step 6: mse=0.724850 step=0.100000
2017/08/26 16:45:28 step 7: mse=0.706244 step=0.100000
2017/08/26 16:45:28 Saving...
2017/08/26 16:45:29 Gathering batch of experience...
2017/08/26 16:45:48 batch 408: mean=16.581395 stddev=6.210391 entropy=1.043114 frames=36480 count=43
2017/08/26 16:45:48 Training policy...
2017/08/26 16:45:54 step 0: objective=0.01644983
2017/08/26 16:45:58 step 1: objective=0.016497001
2017/08/26 16:46:03 step 2: objective=0.016543671
2017/08/26 16:46:07 step 3: objective=0.016589763
2017/08/26 16:46:12 step 4: objective=0.016635304
2017/08/26 16:46:16 step 5: objective=0.016676985
2017/08/26 16:46:21 step 6: objective=0.01671433
2017/08/26 16:46:25 step 7: objective=0.016756605
2017/08/26 16:46:25 Training value function...
2017/08/26 16:46:26 step 0: mse=0.762351 step=0.100000
2017/08/26 16:46:27 step 1: mse=0.714637 step=0.100000
2017/08/26 16:46:28 step 2: mse=0.683787 step=0.100000
2017/08/26 16:46:29 step 3: mse=0.663263 step=0.100000
2017/08/26 16:46:29 step 4: mse=0.639835 step=0.100000
2017/08/26 16:46:30 step 5: mse=0.617516 step=0.100000
2017/08/26 16:46:31 step 6: mse=0.597296 step=0.100000
2017/08/26 16:46:32 step 7: mse=0.586639 step=0.100000
2017/08/26 16:46:32 Saving...
2017/08/26 16:46:32 Gathering batch of experience...
2017/08/26 16:46:51 batch 409: mean=17.255814 stddev=7.345598 entropy=1.049699 frames=36408 count=43
2017/08/26 16:46:51 Training policy...
2017/08/26 16:46:57 step 0: objective=0.046384756
2017/08/26 16:47:01 step 1: objective=0.046418965
2017/08/26 16:47:06 step 2: objective=0.04645336
2017/08/26 16:47:10 step 3: objective=0.04648788
2017/08/26 16:47:15 step 4: objective=0.046522718
2017/08/26 16:47:19 step 5: objective=0.04655703
2017/08/26 16:47:24 step 6: objective=0.046577796
2017/08/26 16:47:29 step 7: objective=0.046601962
2017/08/26 16:47:29 Training value function...
2017/08/26 16:47:30 step 0: mse=1.033733 step=0.100000
2017/08/26 16:47:30 step 1: mse=0.962327 step=0.100000
2017/08/26 16:47:31 step 2: mse=0.904749 step=0.100000
2017/08/26 16:47:32 step 3: mse=0.857809 step=0.100000
2017/08/26 16:47:33 step 4: mse=0.819142 step=0.100000
2017/08/26 16:47:33 step 5: mse=0.789062 step=0.100000
2017/08/26 16:47:34 step 6: mse=0.754784 step=0.100000
2017/08/26 16:47:35 step 7: mse=0.727335 step=0.100000
2017/08/26 16:47:35 Saving...
2017/08/26 16:47:35 Gathering batch of experience...
2017/08/26 16:47:54 batch 410: mean=18.071429 stddev=8.765171 entropy=1.049490 frames=36818 count=42
2017/08/26 16:47:54 Training policy...
2017/08/26 16:48:00 step 0: objective=0.059032742
2017/08/26 16:48:05 step 1: objective=0.059104
2017/08/26 16:48:09 step 2: objective=0.059175085
2017/08/26 16:48:14 step 3: objective=0.05924587
2017/08/26 16:48:18 step 4: objective=0.05931624
2017/08/26 16:48:23 step 5: objective=0.059378445
2017/08/26 16:48:27 step 6: objective=0.059470177
2017/08/26 16:48:32 step 7: objective=0.059532475
2017/08/26 16:48:32 Training value function...
2017/08/26 16:48:33 step 0: mse=1.348479 step=0.100000
2017/08/26 16:48:34 step 1: mse=1.247591 step=0.100000
2017/08/26 16:48:35 step 2: mse=1.153821 step=0.100000
2017/08/26 16:48:35 step 3: mse=1.075899 step=0.100000
2017/08/26 16:48:36 step 4: mse=1.006240 step=0.100000
2017/08/26 16:48:37 step 5: mse=0.949679 step=0.100000
2017/08/26 16:48:38 step 6: mse=0.902458 step=0.100000
2017/08/26 16:48:38 step 7: mse=0.867086 step=0.100000
2017/08/26 16:48:38 Saving...
2017/08/26 16:48:39 Gathering batch of experience...
2017/08/26 16:48:58 batch 411: mean=16.622222 stddev=6.620805 entropy=1.053820 frames=38284 count=45
2017/08/26 16:48:58 Training policy...
2017/08/26 16:49:05 step 0: objective=0.022787895
2017/08/26 16:49:10 step 1: objective=0.022851631
2017/08/26 16:49:14 step 2: objective=0.022915421
2017/08/26 16:49:19 step 3: objective=0.022978906
2017/08/26 16:49:24 step 4: objective=0.02303789
2017/08/26 16:49:29 step 5: objective=0.02306964
2017/08/26 16:49:33 step 6: objective=0.023121955
2017/08/26 16:49:38 step 7: objective=0.023158787
2017/08/26 16:49:38 Training value function...
2017/08/26 16:49:39 step 0: mse=0.894070 step=0.100000
2017/08/26 16:49:40 step 1: mse=0.820508 step=0.100000
2017/08/26 16:49:41 step 2: mse=0.761379 step=0.100000
2017/08/26 16:49:42 step 3: mse=0.713582 step=0.100000
2017/08/26 16:49:42 step 4: mse=0.675668 step=0.100000
2017/08/26 16:49:43 step 5: mse=0.643900 step=0.100000
2017/08/26 16:49:44 step 6: mse=0.617166 step=0.100000
2017/08/26 16:49:45 step 7: mse=0.594656 step=0.100000
2017/08/26 16:49:45 Saving...
2017/08/26 16:49:45 Gathering batch of experience...
2017/08/26 16:50:04 batch 412: mean=17.162791 stddev=6.806051 entropy=1.053054 frames=36267 count=43
2017/08/26 16:50:04 Training policy...
2017/08/26 16:50:10 step 0: objective=0.031077461
2017/08/26 16:50:14 step 1: objective=0.03113102
2017/08/26 16:50:19 step 2: objective=0.031184662
2017/08/26 16:50:23 step 3: objective=0.031238522
2017/08/26 16:50:28 step 4: objective=0.031289678
2017/08/26 16:50:32 step 5: objective=0.03134169
2017/08/26 16:50:37 step 6: objective=0.03139844
2017/08/26 16:50:41 step 7: objective=0.031445034
2017/08/26 16:50:41 Training value function...
2017/08/26 16:50:43 step 0: mse=0.888095 step=0.100000
2017/08/26 16:50:43 step 1: mse=0.824023 step=0.100000
2017/08/26 16:50:44 step 2: mse=0.772209 step=0.100000
2017/08/26 16:50:45 step 3: mse=0.728778 step=0.100000
2017/08/26 16:50:45 step 4: mse=0.693364 step=0.100000
2017/08/26 16:50:46 step 5: mse=0.664360 step=0.100000
2017/08/26 16:50:47 step 6: mse=0.638730 step=0.100000
2017/08/26 16:50:48 step 7: mse=0.614242 step=0.100000
2017/08/26 16:50:48 Saving...
2017/08/26 16:50:48 Gathering batch of experience...
2017/08/26 16:51:07 batch 413: mean=18.333333 stddev=6.416744 entropy=1.044757 frames=36881 count=42
2017/08/26 16:51:07 Training policy...
2017/08/26 16:51:13 step 0: objective=0.036607612
2017/08/26 16:51:18 step 1: objective=0.036677882
2017/08/26 16:51:22 step 2: objective=0.036748227
2017/08/26 16:51:27 step 3: objective=0.036818556
2017/08/26 16:51:31 step 4: objective=0.036886606
2017/08/26 16:51:36 step 5: objective=0.036948502
2017/08/26 16:51:41 step 6: objective=0.036999844
2017/08/26 16:51:45 step 7: objective=0.037042655
2017/08/26 16:51:45 Training value function...
2017/08/26 16:51:46 step 0: mse=1.086478 step=0.100000
2017/08/26 16:51:47 step 1: mse=1.038585 step=0.100000
2017/08/26 16:51:48 step 2: mse=1.002059 step=0.100000
2017/08/26 16:51:49 step 3: mse=0.972759 step=0.100000
2017/08/26 16:51:49 step 4: mse=0.935201 step=0.100000
2017/08/26 16:51:50 step 5: mse=0.903418 step=0.100000
2017/08/26 16:51:51 step 6: mse=0.877464 step=0.100000
2017/08/26 16:51:52 step 7: mse=0.831789 step=0.100000
2017/08/26 16:51:52 Saving...
2017/08/26 16:51:52 Gathering batch of experience...
2017/08/26 16:52:11 batch 414: mean=17.000000 stddev=7.233131 entropy=1.051137 frames=36794 count=44
2017/08/26 16:52:11 Training policy...
2017/08/26 16:52:17 step 0: objective=0.02626249
2017/08/26 16:52:22 step 1: objective=0.02632198
2017/08/26 16:52:26 step 2: objective=0.026381552
2017/08/26 16:52:31 step 3: objective=0.026440637
2017/08/26 16:52:36 step 4: objective=0.026499983
2017/08/26 16:52:40 step 5: objective=0.026554354
2017/08/26 16:52:45 step 6: objective=0.026587732
2017/08/26 16:52:49 step 7: objective=0.026620109
2017/08/26 16:52:49 Training value function...
2017/08/26 16:52:51 step 0: mse=0.823589 step=0.100000
2017/08/26 16:52:51 step 1: mse=0.775074 step=0.100000
2017/08/26 16:52:52 step 2: mse=0.731792 step=0.100000
2017/08/26 16:52:53 step 3: mse=0.691302 step=0.100000
2017/08/26 16:52:54 step 4: mse=0.660526 step=0.100000
2017/08/26 16:52:54 step 5: mse=0.633076 step=0.100000
2017/08/26 16:52:55 step 6: mse=0.612963 step=0.100000
2017/08/26 16:52:56 step 7: mse=0.597205 step=0.100000
2017/08/26 16:52:56 Saving...
2017/08/26 16:52:56 Gathering batch of experience...
2017/08/26 16:53:15 batch 415: mean=16.568182 stddev=6.436394 entropy=1.049813 frames=36524 count=44
2017/08/26 16:53:15 Training policy...
2017/08/26 16:53:21 step 0: objective=0.025539294
2017/08/26 16:53:25 step 1: objective=0.025595747
2017/08/26 16:53:30 step 2: objective=0.02565201
2017/08/26 16:53:35 step 3: objective=0.025708059
2017/08/26 16:53:39 step 4: objective=0.02576375
2017/08/26 16:53:44 step 5: objective=0.02581173
2017/08/26 16:53:48 step 6: objective=0.025864147
2017/08/26 16:53:53 step 7: objective=0.02593209
2017/08/26 16:53:53 Training value function...
2017/08/26 16:53:54 step 0: mse=1.105583 step=0.100000
2017/08/26 16:53:55 step 1: mse=1.019588 step=0.100000
2017/08/26 16:53:56 step 2: mse=0.950770 step=0.100000
2017/08/26 16:53:56 step 3: mse=0.895560 step=0.100000
2017/08/26 16:53:57 step 4: mse=0.850876 step=0.100000
2017/08/26 16:53:58 step 5: mse=0.813556 step=0.100000
2017/08/26 16:53:59 step 6: mse=0.776402 step=0.100000
2017/08/26 16:54:00 step 7: mse=0.745343 step=0.100000
2017/08/26 16:54:00 Saving...
2017/08/26 16:54:00 Gathering batch of experience...
2017/08/26 16:54:19 batch 416: mean=18.255814 stddev=8.011889 entropy=1.043421 frames=37049 count=43
2017/08/26 16:54:19 Training policy...
2017/08/26 16:54:25 step 0: objective=0.06457149
2017/08/26 16:54:30 step 1: objective=0.06462576
2017/08/26 16:54:34 step 2: objective=0.064679466
2017/08/26 16:54:39 step 3: objective=0.064734295
2017/08/26 16:54:43 step 4: objective=0.06478731
2017/08/26 16:54:48 step 5: objective=0.064825535
2017/08/26 16:54:53 step 6: objective=0.06485526
2017/08/26 16:54:57 step 7: objective=0.06487629
2017/08/26 16:54:57 Training value function...
2017/08/26 16:54:59 step 0: mse=1.362694 step=0.100000
2017/08/26 16:54:59 step 1: mse=1.276633 step=0.100000
2017/08/26 16:55:00 step 2: mse=1.198930 step=0.100000
2017/08/26 16:55:01 step 3: mse=1.124239 step=0.100000
2017/08/26 16:55:02 step 4: mse=1.062112 step=0.100000
2017/08/26 16:55:02 step 5: mse=1.012762 step=0.100000
2017/08/26 16:55:03 step 6: mse=0.968139 step=0.100000
2017/08/26 16:55:04 step 7: mse=0.929732 step=0.100000
2017/08/26 16:55:04 Saving...
2017/08/26 16:55:04 Gathering batch of experience...
2017/08/26 16:55:23 batch 417: mean=19.357143 stddev=8.554646 entropy=1.033236 frames=37275 count=42
2017/08/26 16:55:23 Training policy...
2017/08/26 16:55:29 step 0: objective=0.044839054
2017/08/26 16:55:34 step 1: objective=0.04489505
2017/08/26 16:55:39 step 2: objective=0.044950932
2017/08/26 16:55:43 step 3: objective=0.04500607
2017/08/26 16:55:48 step 4: objective=0.045060765
2017/08/26 16:55:53 step 5: objective=0.045110155
2017/08/26 16:55:57 step 6: objective=0.045148253
2017/08/26 16:56:02 step 7: objective=0.045233306
2017/08/26 16:56:02 Training value function...
2017/08/26 16:56:03 step 0: mse=1.494464 step=0.100000
2017/08/26 16:56:04 step 1: mse=1.395583 step=0.100000
2017/08/26 16:56:05 step 2: mse=1.321030 step=0.100000
2017/08/26 16:56:05 step 3: mse=1.244370 step=0.100000
2017/08/26 16:56:06 step 4: mse=1.174272 step=0.100000
2017/08/26 16:56:07 step 5: mse=1.106505 step=0.100000
2017/08/26 16:56:08 step 6: mse=1.056408 step=0.100000
2017/08/26 16:56:08 step 7: mse=1.001256 step=0.100000
2017/08/26 16:56:08 Saving...
2017/08/26 16:56:09 Gathering batch of experience...
2017/08/26 16:56:28 batch 418: mean=20.100000 stddev=9.071384 entropy=1.035061 frames=36357 count=40
2017/08/26 16:56:28 Training policy...
2017/08/26 16:56:34 step 0: objective=0.0622595
2017/08/26 16:56:38 step 1: objective=0.06237529
2017/08/26 16:56:43 step 2: objective=0.062490914
2017/08/26 16:56:47 step 3: objective=0.06256993
2017/08/26 16:56:52 step 4: objective=0.062631585
2017/08/26 16:56:56 step 5: objective=0.06269078
2017/08/26 16:57:01 step 6: objective=0.06274367
2017/08/26 16:57:05 step 7: objective=0.062795796
2017/08/26 16:57:05 Training value function...
2017/08/26 16:57:07 step 0: mse=1.649515 step=0.100000
2017/08/26 16:57:07 step 1: mse=1.542626 step=0.100000
2017/08/26 16:57:08 step 2: mse=1.455701 step=0.100000
2017/08/26 16:57:09 step 3: mse=1.380833 step=0.100000
2017/08/26 16:57:10 step 4: mse=1.312218 step=0.100000
2017/08/26 16:57:11 step 5: mse=1.256143 step=0.100000
2017/08/26 16:57:11 step 6: mse=1.212952 step=0.100000
2017/08/26 16:57:12 step 7: mse=1.170596 step=0.100000
2017/08/26 16:57:12 Saving...
2017/08/26 16:57:12 Gathering batch of experience...
2017/08/26 16:57:31 batch 419: mean=17.069767 stddev=6.885763 entropy=1.052483 frames=36919 count=43
2017/08/26 16:57:31 Training policy...
2017/08/26 16:57:38 step 0: objective=0.008176247
2017/08/26 16:57:42 step 1: objective=0.008260931
2017/08/26 16:57:47 step 2: objective=0.008346341
2017/08/26 16:57:52 step 3: objective=0.008430726
2017/08/26 16:57:56 step 4: objective=0.0085004205
2017/08/26 16:58:01 step 5: objective=0.00854909
2017/08/26 16:58:06 step 6: objective=0.008592316
2017/08/26 16:58:10 step 7: objective=0.008667655
2017/08/26 16:58:10 Training value function...
2017/08/26 16:58:11 step 0: mse=0.995624 step=0.100000
2017/08/26 16:58:12 step 1: mse=0.930581 step=0.100000
2017/08/26 16:58:13 step 2: mse=0.869326 step=0.100000
2017/08/26 16:58:14 step 3: mse=0.816530 step=0.100000
2017/08/26 16:58:15 step 4: mse=0.778232 step=0.100000
2017/08/26 16:58:15 step 5: mse=0.741890 step=0.100000
2017/08/26 16:58:16 step 6: mse=0.713778 step=0.100000
2017/08/26 16:58:17 step 7: mse=0.687276 step=0.100000
2017/08/26 16:58:17 Saving...
2017/08/26 16:58:17 Gathering batch of experience...
2017/08/26 16:58:36 batch 420: mean=18.113636 stddev=8.155355 entropy=1.041796 frames=36942 count=44
2017/08/26 16:58:36 Training policy...
2017/08/26 16:58:43 step 0: objective=0.03139352
2017/08/26 16:58:47 step 1: objective=0.0315029
2017/08/26 16:58:52 step 2: objective=0.03161202
2017/08/26 16:58:57 step 3: objective=0.031710166
2017/08/26 16:59:01 step 4: objective=0.03181649
2017/08/26 16:59:06 step 5: objective=0.03189094
2017/08/26 16:59:11 step 6: objective=0.031961225
2017/08/26 16:59:15 step 7: objective=0.032027747
2017/08/26 16:59:15 Training value function...
2017/08/26 16:59:16 step 0: mse=1.513739 step=0.100000
2017/08/26 16:59:17 step 1: mse=1.399542 step=0.100000
2017/08/26 16:59:18 step 2: mse=1.306978 step=0.100000
2017/08/26 16:59:19 step 3: mse=1.234011 step=0.100000
2017/08/26 16:59:20 step 4: mse=1.171241 step=0.100000
2017/08/26 16:59:20 step 5: mse=1.121973 step=0.100000
2017/08/26 16:59:21 step 6: mse=1.078806 step=0.100000
2017/08/26 16:59:22 step 7: mse=1.042817 step=0.100000
2017/08/26 16:59:22 Saving...
2017/08/26 16:59:22 Gathering batch of experience...
2017/08/26 16:59:42 batch 421: mean=18.880952 stddev=7.616406 entropy=1.036508 frames=38783 count=42
2017/08/26 16:59:42 Training policy...
2017/08/26 16:59:49 step 0: objective=0.0382451
2017/08/26 16:59:54 step 1: objective=0.03828157
2017/08/26 16:59:59 step 2: objective=0.038317773
2017/08/26 17:00:04 step 3: objective=0.03835437
2017/08/26 17:00:09 step 4: objective=0.038390636
2017/08/26 17:00:13 step 5: objective=0.03842629
2017/08/26 17:00:18 step 6: objective=0.038450543
2017/08/26 17:00:23 step 7: objective=0.038490776
2017/08/26 17:00:23 Training value function...
2017/08/26 17:00:25 step 0: mse=0.954727 step=0.100000
2017/08/26 17:00:25 step 1: mse=0.904440 step=0.100000
2017/08/26 17:00:26 step 2: mse=0.860152 step=0.100000
2017/08/26 17:00:27 step 3: mse=0.826700 step=0.100000
2017/08/26 17:00:28 step 4: mse=0.796369 step=0.100000
2017/08/26 17:00:29 step 5: mse=0.774229 step=0.100000
2017/08/26 17:00:29 step 6: mse=0.755937 step=0.100000
2017/08/26 17:00:30 step 7: mse=0.737124 step=0.100000
2017/08/26 17:00:30 Saving...
2017/08/26 17:00:30 Gathering batch of experience...
2017/08/26 17:00:49 batch 422: mean=16.674419 stddev=5.865631 entropy=1.047762 frames=36215 count=43
2017/08/26 17:00:49 Training policy...
2017/08/26 17:00:55 step 0: objective=0.002080631
2017/08/26 17:01:00 step 1: objective=0.0021429344
2017/08/26 17:01:04 step 2: objective=0.0022052384
2017/08/26 17:01:09 step 3: objective=0.0022670378
2017/08/26 17:01:13 step 4: objective=0.0023170025
2017/08/26 17:01:18 step 5: objective=0.0023762544
2017/08/26 17:01:23 step 6: objective=0.002432268
2017/08/26 17:01:27 step 7: objective=0.0024800575
2017/08/26 17:01:27 Training value function...
2017/08/26 17:01:28 step 0: mse=0.941089 step=0.100000
2017/08/26 17:01:29 step 1: mse=0.867159 step=0.100000
2017/08/26 17:01:30 step 2: mse=0.806949 step=0.100000
2017/08/26 17:01:31 step 3: mse=0.759492 step=0.100000
2017/08/26 17:01:31 step 4: mse=0.720147 step=0.100000
2017/08/26 17:01:32 step 5: mse=0.688981 step=0.100000
2017/08/26 17:01:33 step 6: mse=0.664392 step=0.100000
2017/08/26 17:01:34 step 7: mse=0.643642 step=0.100000
2017/08/26 17:01:34 Saving...
2017/08/26 17:01:34 Gathering batch of experience...
2017/08/26 17:01:53 batch 423: mean=16.976744 stddev=5.529996 entropy=1.054695 frames=36557 count=43
2017/08/26 17:01:53 Training policy...
2017/08/26 17:01:59 step 0: objective=0.018383298
2017/08/26 17:02:04 step 1: objective=0.01841655
2017/08/26 17:02:08 step 2: objective=0.018446656
2017/08/26 17:02:13 step 3: objective=0.018479371
2017/08/26 17:02:17 step 4: objective=0.01851183
2017/08/26 17:02:22 step 5: objective=0.018544046
2017/08/26 17:02:27 step 6: objective=0.018575806
2017/08/26 17:02:31 step 7: objective=0.018604048
2017/08/26 17:02:31 Training value function...
2017/08/26 17:02:33 step 0: mse=0.824500 step=0.100000
2017/08/26 17:02:33 step 1: mse=0.802565 step=0.100000
2017/08/26 17:02:34 step 2: mse=0.764552 step=0.100000
2017/08/26 17:02:35 step 3: mse=0.735746 step=0.100000
2017/08/26 17:02:36 step 4: mse=0.718078 step=0.100000
2017/08/26 17:02:36 step 5: mse=0.701435 step=0.100000
2017/08/26 17:02:37 step 6: mse=0.682698 step=0.100000
2017/08/26 17:02:38 step 7: mse=0.673199 step=0.100000
2017/08/26 17:02:38 Saving...
2017/08/26 17:02:38 Gathering batch of experience...
2017/08/26 17:02:58 batch 424: mean=17.093023 stddev=6.671055 entropy=1.044265 frames=37098 count=43
2017/08/26 17:02:58 Training policy...
2017/08/26 17:03:04 step 0: objective=0.035185814
2017/08/26 17:03:09 step 1: objective=0.03523176
2017/08/26 17:03:13 step 2: objective=0.035279114
2017/08/26 17:03:18 step 3: objective=0.035326578
2017/08/26 17:03:23 step 4: objective=0.03537383
2017/08/26 17:03:28 step 5: objective=0.035419095
2017/08/26 17:03:32 step 6: objective=0.03545363
2017/08/26 17:03:37 step 7: objective=0.035479497
2017/08/26 17:03:37 Training value function...
2017/08/26 17:03:38 step 0: mse=0.863451 step=0.100000
2017/08/26 17:03:39 step 1: mse=0.820879 step=0.100000
2017/08/26 17:03:40 step 2: mse=0.777516 step=0.100000
2017/08/26 17:03:40 step 3: mse=0.746654 step=0.100000
2017/08/26 17:03:41 step 4: mse=0.706765 step=0.100000
2017/08/26 17:03:42 step 5: mse=0.674534 step=0.100000
2017/08/26 17:03:43 step 6: mse=0.648545 step=0.100000
2017/08/26 17:03:44 step 7: mse=0.626288 step=0.100000
2017/08/26 17:03:44 Saving...
2017/08/26 17:03:44 Gathering batch of experience...
2017/08/26 17:04:03 batch 425: mean=17.395349 stddev=6.534842 entropy=1.047712 frames=36662 count=43
2017/08/26 17:04:03 Training policy...
2017/08/26 17:04:09 step 0: objective=0.038072683
2017/08/26 17:04:14 step 1: objective=0.03813048
2017/08/26 17:04:18 step 2: objective=0.038188938
2017/08/26 17:04:23 step 3: objective=0.038247783
2017/08/26 17:04:28 step 4: objective=0.03830246
2017/08/26 17:04:32 step 5: objective=0.038334873
2017/08/26 17:04:37 step 6: objective=0.038358722
2017/08/26 17:04:42 step 7: objective=0.03838205
2017/08/26 17:04:42 Training value function...
2017/08/26 17:04:43 step 0: mse=0.945169 step=0.100000
2017/08/26 17:04:44 step 1: mse=0.907083 step=0.100000
2017/08/26 17:04:44 step 2: mse=0.876161 step=0.100000
2017/08/26 17:04:45 step 3: mse=0.830371 step=0.100000
2017/08/26 17:04:46 step 4: mse=0.807802 step=0.100000
2017/08/26 17:04:47 step 5: mse=0.773250 step=0.100000
2017/08/26 17:04:47 step 6: mse=0.757090 step=0.100000
2017/08/26 17:04:48 step 7: mse=0.725919 step=0.100000
2017/08/26 17:04:48 Saving...
2017/08/26 17:04:48 Gathering batch of experience...
2017/08/26 17:05:08 batch 426: mean=18.476190 stddev=9.011205 entropy=1.034678 frames=37238 count=42
2017/08/26 17:05:08 Training policy...
2017/08/26 17:05:14 step 0: objective=0.029837288
2017/08/26 17:05:19 step 1: objective=0.02987304
2017/08/26 17:05:24 step 2: objective=0.029909207
2017/08/26 17:05:28 step 3: objective=0.029945252
2017/08/26 17:05:33 step 4: objective=0.029981771
2017/08/26 17:05:38 step 5: objective=0.03003409
2017/08/26 17:05:42 step 6: objective=0.030083412
2017/08/26 17:05:47 step 7: objective=0.03011687
2017/08/26 17:05:47 Training value function...
2017/08/26 17:05:48 step 0: mse=1.109850 step=0.100000
2017/08/26 17:05:49 step 1: mse=1.039519 step=0.100000
2017/08/26 17:05:50 step 2: mse=0.984217 step=0.100000
2017/08/26 17:05:51 step 3: mse=0.939521 step=0.100000
2017/08/26 17:05:51 step 4: mse=0.903912 step=0.100000
2017/08/26 17:05:52 step 5: mse=0.872239 step=0.100000
2017/08/26 17:05:53 step 6: mse=0.839842 step=0.100000
2017/08/26 17:05:54 step 7: mse=0.814245 step=0.100000
2017/08/26 17:05:54 Saving...
2017/08/26 17:05:54 Gathering batch of experience...
2017/08/26 17:06:13 batch 427: mean=19.243902 stddev=8.842195 entropy=1.031905 frames=36773 count=41
2017/08/26 17:06:13 Training policy...
2017/08/26 17:06:19 step 0: objective=0.03827134
2017/08/26 17:06:24 step 1: objective=0.038339518
2017/08/26 17:06:29 step 2: objective=0.03840775
2017/08/26 17:06:33 step 3: objective=0.038474865
2017/08/26 17:06:38 step 4: objective=0.038528696
2017/08/26 17:06:43 step 5: objective=0.038557738
2017/08/26 17:06:47 step 6: objective=0.03858405
2017/08/26 17:06:52 step 7: objective=0.03865151
2017/08/26 17:06:52 Training value function...
2017/08/26 17:06:53 step 0: mse=1.048633 step=0.100000
2017/08/26 17:06:54 step 1: mse=0.992845 step=0.100000
2017/08/26 17:06:55 step 2: mse=0.951906 step=0.100000
2017/08/26 17:06:56 step 3: mse=0.919589 step=0.100000
2017/08/26 17:06:56 step 4: mse=0.875232 step=0.100000
2017/08/26 17:06:57 step 5: mse=0.837634 step=0.100000
2017/08/26 17:06:58 step 6: mse=0.801866 step=0.100000
2017/08/26 17:06:59 step 7: mse=0.770805 step=0.100000
2017/08/26 17:06:59 Saving...
2017/08/26 17:06:59 Gathering batch of experience...
2017/08/26 17:07:18 batch 428: mean=18.463415 stddev=6.814968 entropy=1.044260 frames=37085 count=41
2017/08/26 17:07:18 Training policy...
2017/08/26 17:07:24 step 0: objective=0.025592986
2017/08/26 17:07:29 step 1: objective=0.02562543
2017/08/26 17:07:34 step 2: objective=0.025658097
2017/08/26 17:07:39 step 3: objective=0.025690757
2017/08/26 17:07:43 step 4: objective=0.025723387
2017/08/26 17:07:48 step 5: objective=0.025756117
2017/08/26 17:07:53 step 6: objective=0.025783379
2017/08/26 17:07:57 step 7: objective=0.025806895
2017/08/26 17:07:57 Training value function...
2017/08/26 17:07:59 step 0: mse=0.911952 step=0.100000
2017/08/26 17:07:59 step 1: mse=0.850189 step=0.100000
2017/08/26 17:08:00 step 2: mse=0.799488 step=0.100000
2017/08/26 17:08:01 step 3: mse=0.760250 step=0.100000
2017/08/26 17:08:02 step 4: mse=0.728764 step=0.100000
2017/08/26 17:08:03 step 5: mse=0.702743 step=0.100000
2017/08/26 17:08:03 step 6: mse=0.683100 step=0.100000
2017/08/26 17:08:04 step 7: mse=0.665884 step=0.100000
2017/08/26 17:08:04 Saving...
2017/08/26 17:08:04 Gathering batch of experience...
2017/08/26 17:08:23 batch 429: mean=16.155556 stddev=7.108541 entropy=1.059510 frames=36912 count=45
2017/08/26 17:08:23 Training policy...
2017/08/26 17:08:29 step 0: objective=0.013218772
2017/08/26 17:08:34 step 1: objective=0.013283862
2017/08/26 17:08:39 step 2: objective=0.013349354
2017/08/26 17:08:44 step 3: objective=0.0134152295
2017/08/26 17:08:48 step 4: objective=0.013481022
2017/08/26 17:08:53 step 5: objective=0.013538635
2017/08/26 17:08:58 step 6: objective=0.013565613
2017/08/26 17:09:02 step 7: objective=0.013585953
2017/08/26 17:09:02 Training value function...
2017/08/26 17:09:04 step 0: mse=0.839516 step=0.100000
2017/08/26 17:09:05 step 1: mse=0.786455 step=0.100000
2017/08/26 17:09:05 step 2: mse=0.744120 step=0.100000
2017/08/26 17:09:06 step 3: mse=0.701494 step=0.100000
2017/08/26 17:09:07 step 4: mse=0.667451 step=0.100000
2017/08/26 17:09:08 step 5: mse=0.639192 step=0.100000
2017/08/26 17:09:08 step 6: mse=0.615683 step=0.100000
2017/08/26 17:09:09 step 7: mse=0.594526 step=0.100000
2017/08/26 17:09:09 Saving...
2017/08/26 17:09:09 Gathering batch of experience...
2017/08/26 17:09:29 batch 430: mean=18.837209 stddev=8.098034 entropy=1.038168 frames=37425 count=43
2017/08/26 17:09:29 Training policy...
2017/08/26 17:09:35 step 0: objective=0.054885723
2017/08/26 17:09:40 step 1: objective=0.05500495
2017/08/26 17:09:45 step 2: objective=0.055124976
2017/08/26 17:09:49 step 3: objective=0.055246353
2017/08/26 17:09:54 step 4: objective=0.055358466
2017/08/26 17:09:59 step 5: objective=0.055411696
2017/08/26 17:10:04 step 6: objective=0.05546458
2017/08/26 17:10:08 step 7: objective=0.05551761
2017/08/26 17:10:08 Training value function...
2017/08/26 17:10:10 step 0: mse=1.440596 step=0.100000
2017/08/26 17:10:11 step 1: mse=1.364076 step=0.100000
2017/08/26 17:10:11 step 2: mse=1.298263 step=0.100000
2017/08/26 17:10:12 step 3: mse=1.239865 step=0.100000
2017/08/26 17:10:13 step 4: mse=1.176666 step=0.100000
2017/08/26 17:10:14 step 5: mse=1.135301 step=0.100000
2017/08/26 17:10:14 step 6: mse=1.090262 step=0.100000
2017/08/26 17:10:15 step 7: mse=1.062221 step=0.100000
2017/08/26 17:10:15 Saving...
2017/08/26 17:10:15 Gathering batch of experience...
2017/08/26 17:10:35 batch 431: mean=17.068182 stddev=7.545010 entropy=1.045301 frames=36693 count=44
2017/08/26 17:10:35 Training policy...
2017/08/26 17:10:41 step 0: objective=0.016359841
2017/08/26 17:10:46 step 1: objective=0.0164142
2017/08/26 17:10:50 step 2: objective=0.016469095
2017/08/26 17:10:55 step 3: objective=0.016524376
2017/08/26 17:11:00 step 4: objective=0.016577916
2017/08/26 17:11:04 step 5: objective=0.01662882
2017/08/26 17:11:09 step 6: objective=0.016676374
2017/08/26 17:11:14 step 7: objective=0.016717829
2017/08/26 17:11:14 Training value function...
2017/08/26 17:11:15 step 0: mse=1.134187 step=0.100000
2017/08/26 17:11:16 step 1: mse=1.064164 step=0.100000
2017/08/26 17:11:16 step 2: mse=1.008277 step=0.100000
2017/08/26 17:11:17 step 3: mse=0.966102 step=0.100000
2017/08/26 17:11:18 step 4: mse=0.926078 step=0.100000
2017/08/26 17:11:19 step 5: mse=0.881587 step=0.100000
2017/08/26 17:11:19 step 6: mse=0.847100 step=0.100000
2017/08/26 17:11:20 step 7: mse=0.816868 step=0.100000
2017/08/26 17:11:20 Saving...
2017/08/26 17:11:20 Gathering batch of experience...
2017/08/26 17:11:40 batch 432: mean=16.813953 stddev=6.445679 entropy=1.044791 frames=37091 count=43
2017/08/26 17:11:40 Training policy...
2017/08/26 17:11:46 step 0: objective=0.008649098
2017/08/26 17:11:51 step 1: objective=0.008732951
2017/08/26 17:11:56 step 2: objective=0.008816365
2017/08/26 17:12:00 step 3: objective=0.008892168
2017/08/26 17:12:05 step 4: objective=0.008915509
2017/08/26 17:12:10 step 5: objective=0.0089367125
2017/08/26 17:12:15 step 6: objective=0.008955537
2017/08/26 17:12:19 step 7: objective=0.008975595
2017/08/26 17:12:19 Training value function...
2017/08/26 17:12:20 step 0: mse=0.750229 step=0.100000
2017/08/26 17:12:21 step 1: mse=0.711575 step=0.100000
2017/08/26 17:12:22 step 2: mse=0.678728 step=0.100000
2017/08/26 17:12:23 step 3: mse=0.652962 step=0.100000
2017/08/26 17:12:24 step 4: mse=0.632675 step=0.100000
2017/08/26 17:12:24 step 5: mse=0.610233 step=0.100000
2017/08/26 17:12:25 step 6: mse=0.591985 step=0.100000
2017/08/26 17:12:26 step 7: mse=0.576791 step=0.100000
2017/08/26 17:12:26 Saving...
2017/08/26 17:12:26 Gathering batch of experience...
2017/08/26 17:12:45 batch 433: mean=17.681818 stddev=7.618079 entropy=1.052605 frames=37548 count=44
2017/08/26 17:12:45 Training policy...
2017/08/26 17:12:52 step 0: objective=0.057926524
2017/08/26 17:12:56 step 1: objective=0.057994608
2017/08/26 17:13:01 step 2: objective=0.058063727
2017/08/26 17:13:06 step 3: objective=0.058128778
2017/08/26 17:13:11 step 4: objective=0.058175627
2017/08/26 17:13:16 step 5: objective=0.058220457
2017/08/26 17:13:21 step 6: objective=0.058253497
2017/08/26 17:13:25 step 7: objective=0.058313206
2017/08/26 17:13:25 Training value function...
2017/08/26 17:13:27 step 0: mse=1.230752 step=0.100000
2017/08/26 17:13:27 step 1: mse=1.121618 step=0.100000
2017/08/26 17:13:28 step 2: mse=1.032834 step=0.100000
2017/08/26 17:13:29 step 3: mse=0.963352 step=0.100000
2017/08/26 17:13:30 step 4: mse=0.906910 step=0.100000
2017/08/26 17:13:30 step 5: mse=0.855664 step=0.100000
2017/08/26 17:13:31 step 6: mse=0.816631 step=0.100000
2017/08/26 17:13:32 step 7: mse=0.781254 step=0.100000
2017/08/26 17:13:32 Saving...
2017/08/26 17:13:32 Gathering batch of experience...
2017/08/26 17:13:51 batch 434: mean=17.581395 stddev=6.481575 entropy=1.054532 frames=35797 count=43
2017/08/26 17:13:51 Training policy...
2017/08/26 17:13:57 step 0: objective=0.063636936
2017/08/26 17:14:02 step 1: objective=0.063711114
2017/08/26 17:14:06 step 2: objective=0.06378513
2017/08/26 17:14:11 step 3: objective=0.063858986
2017/08/26 17:14:15 step 4: objective=0.06392724
2017/08/26 17:14:20 step 5: objective=0.06399066
2017/08/26 17:14:25 step 6: objective=0.0640493
2017/08/26 17:14:29 step 7: objective=0.06411336
2017/08/26 17:14:29 Training value function...
2017/08/26 17:14:30 step 0: mse=1.473196 step=0.100000
2017/08/26 17:14:31 step 1: mse=1.383410 step=0.100000
2017/08/26 17:14:32 step 2: mse=1.309818 step=0.100000
2017/08/26 17:14:32 step 3: mse=1.251828 step=0.100000
2017/08/26 17:14:33 step 4: mse=1.200634 step=0.100000
2017/08/26 17:14:34 step 5: mse=1.146561 step=0.100000
2017/08/26 17:14:35 step 6: mse=1.091593 step=0.100000
2017/08/26 17:14:35 step 7: mse=1.043864 step=0.100000
2017/08/26 17:14:35 Saving...
2017/08/26 17:14:36 Gathering batch of experience...
2017/08/26 17:14:55 batch 435: mean=15.777778 stddev=5.601146 entropy=1.059713 frames=36957 count=45
2017/08/26 17:14:55 Training policy...
2017/08/26 17:15:01 step 0: objective=-0.0010251116
2017/08/26 17:15:06 step 1: objective=-0.0009670027
2017/08/26 17:15:11 step 2: objective=-0.0009088653
2017/08/26 17:15:16 step 3: objective=-0.00086081045
2017/08/26 17:15:21 step 4: objective=-0.00081414287
2017/08/26 17:15:25 step 5: objective=-0.00077547133
2017/08/26 17:15:30 step 6: objective=-0.00074070797
2017/08/26 17:15:35 step 7: objective=-0.0007062292
2017/08/26 17:15:35 Training value function...
2017/08/26 17:15:36 step 0: mse=0.703205 step=0.100000
2017/08/26 17:15:37 step 1: mse=0.657207 step=0.100000
2017/08/26 17:15:38 step 2: mse=0.620546 step=0.100000
2017/08/26 17:15:38 step 3: mse=0.591491 step=0.100000
2017/08/26 17:15:39 step 4: mse=0.569470 step=0.100000
2017/08/26 17:15:40 step 5: mse=0.539912 step=0.100000
2017/08/26 17:15:41 step 6: mse=0.519579 step=0.100000
2017/08/26 17:15:41 step 7: mse=0.504670 step=0.100000
2017/08/26 17:15:41 Saving...
2017/08/26 17:15:42 Gathering batch of experience...
2017/08/26 17:16:01 batch 436: mean=18.441860 stddev=7.025874 entropy=1.035332 frames=37289 count=43
2017/08/26 17:16:01 Training policy...
2017/08/26 17:16:07 step 0: objective=0.041926965
2017/08/26 17:16:12 step 1: objective=0.04201401
2017/08/26 17:16:17 step 2: objective=0.0421008
2017/08/26 17:16:22 step 3: objective=0.04218729
2017/08/26 17:16:27 step 4: objective=0.04227255
2017/08/26 17:16:31 step 5: objective=0.042350102
2017/08/26 17:16:36 step 6: objective=0.04240347
2017/08/26 17:16:41 step 7: objective=0.042464092
2017/08/26 17:16:41 Training value function...
2017/08/26 17:16:42 step 0: mse=1.063738 step=0.100000
2017/08/26 17:16:43 step 1: mse=1.012465 step=0.100000
2017/08/26 17:16:44 step 2: mse=0.968689 step=0.100000
2017/08/26 17:16:45 step 3: mse=0.918973 step=0.100000
2017/08/26 17:16:45 step 4: mse=0.888751 step=0.100000
2017/08/26 17:16:46 step 5: mse=0.848753 step=0.100000
2017/08/26 17:16:47 step 6: mse=0.827065 step=0.100000
2017/08/26 17:16:48 step 7: mse=0.788317 step=0.100000
2017/08/26 17:16:48 Saving...
2017/08/26 17:16:48 Gathering batch of experience...
2017/08/26 17:17:07 batch 437: mean=16.200000 stddev=6.933333 entropy=1.055765 frames=36421 count=45
2017/08/26 17:17:07 Training policy...
2017/08/26 17:17:13 step 0: objective=0.034013372
2017/08/26 17:17:18 step 1: objective=0.03405593
2017/08/26 17:17:22 step 2: objective=0.034099143
2017/08/26 17:17:27 step 3: objective=0.034142498
2017/08/26 17:17:32 step 4: objective=0.03418631
2017/08/26 17:17:37 step 5: objective=0.0342267
2017/08/26 17:17:41 step 6: objective=0.034257736
2017/08/26 17:17:46 step 7: objective=0.034293484
2017/08/26 17:17:46 Training value function...
2017/08/26 17:17:47 step 0: mse=0.976867 step=0.100000
2017/08/26 17:17:48 step 1: mse=0.918831 step=0.100000
2017/08/26 17:17:49 step 2: mse=0.872005 step=0.100000
2017/08/26 17:17:50 step 3: mse=0.833778 step=0.100000
2017/08/26 17:17:50 step 4: mse=0.802553 step=0.100000
2017/08/26 17:17:51 step 5: mse=0.775246 step=0.100000
2017/08/26 17:17:52 step 6: mse=0.753765 step=0.100000
2017/08/26 17:17:53 step 7: mse=0.735393 step=0.100000
2017/08/26 17:17:53 Saving...
2017/08/26 17:17:53 Gathering batch of experience...
2017/08/26 17:18:12 batch 438: mean=18.975000 stddev=9.245235 entropy=1.043169 frames=36717 count=40
2017/08/26 17:18:12 Training policy...
2017/08/26 17:18:18 step 0: objective=0.036184233
2017/08/26 17:18:23 step 1: objective=0.03621488
2017/08/26 17:18:28 step 2: objective=0.036245096
2017/08/26 17:18:33 step 3: objective=0.03627536
2017/08/26 17:18:37 step 4: objective=0.0363055
2017/08/26 17:18:42 step 5: objective=0.03633538
2017/08/26 17:18:47 step 6: objective=0.036364857
2017/08/26 17:18:51 step 7: objective=0.03639639
2017/08/26 17:18:51 Training value function...
2017/08/26 17:18:53 step 0: mse=1.281972 step=0.100000
2017/08/26 17:18:53 step 1: mse=1.161627 step=0.100000
2017/08/26 17:18:54 step 2: mse=1.072694 step=0.100000
2017/08/26 17:18:55 step 3: mse=0.991549 step=0.100000
2017/08/26 17:18:56 step 4: mse=0.932167 step=0.100000
2017/08/26 17:18:57 step 5: mse=0.880585 step=0.100000
2017/08/26 17:18:57 step 6: mse=0.841773 step=0.100000
2017/08/26 17:18:58 step 7: mse=0.806273 step=0.100000
2017/08/26 17:18:58 Saving...
2017/08/26 17:18:58 Gathering batch of experience...
2017/08/26 17:19:18 batch 439: mean=18.325581 stddev=7.705996 entropy=1.050540 frames=37464 count=43
2017/08/26 17:19:18 Training policy...
2017/08/26 17:19:25 step 0: objective=0.043021843
2017/08/26 17:19:29 step 1: objective=0.0430734
2017/08/26 17:19:34 step 2: objective=0.043124758
2017/08/26 17:19:39 step 3: objective=0.04317635
2017/08/26 17:19:44 step 4: objective=0.04322685
2017/08/26 17:19:49 step 5: objective=0.043272767
2017/08/26 17:19:53 step 6: objective=0.043311927
2017/08/26 17:19:58 step 7: objective=0.043390635
2017/08/26 17:19:58 Training value function...
2017/08/26 17:20:00 step 0: mse=0.986367 step=0.100000
2017/08/26 17:20:00 step 1: mse=0.934085 step=0.100000
2017/08/26 17:20:01 step 2: mse=0.885354 step=0.100000
2017/08/26 17:20:02 step 3: mse=0.845088 step=0.100000
2017/08/26 17:20:03 step 4: mse=0.815937 step=0.100000
2017/08/26 17:20:03 step 5: mse=0.795968 step=0.100000
2017/08/26 17:20:04 step 6: mse=0.774569 step=0.100000
2017/08/26 17:20:05 step 7: mse=0.759946 step=0.100000
2017/08/26 17:20:05 Saving...
2017/08/26 17:20:05 Gathering batch of experience...
2017/08/26 17:20:24 batch 440: mean=16.000000 stddev=5.577734 entropy=1.051254 frames=36255 count=45
2017/08/26 17:20:24 Training policy...
2017/08/26 17:20:30 step 0: objective=0.02902935
2017/08/26 17:20:35 step 1: objective=0.02906607
2017/08/26 17:20:40 step 2: objective=0.029102912
2017/08/26 17:20:44 step 3: objective=0.029139753
2017/08/26 17:20:49 step 4: objective=0.029176397
2017/08/26 17:20:54 step 5: objective=0.029200966
2017/08/26 17:20:59 step 6: objective=0.02922568
2017/08/26 17:21:03 step 7: objective=0.029249124
2017/08/26 17:21:03 Training value function...
2017/08/26 17:21:05 step 0: mse=0.939562 step=0.100000
2017/08/26 17:21:05 step 1: mse=0.893804 step=0.100000
2017/08/26 17:21:06 step 2: mse=0.854689 step=0.100000
2017/08/26 17:21:07 step 3: mse=0.823632 step=0.100000
2017/08/26 17:21:08 step 4: mse=0.790105 step=0.100000
2017/08/26 17:21:08 step 5: mse=0.763481 step=0.100000
2017/08/26 17:21:09 step 6: mse=0.742093 step=0.100000
2017/08/26 17:21:10 step 7: mse=0.720526 step=0.100000
2017/08/26 17:21:10 Saving...
2017/08/26 17:21:10 Gathering batch of experience...
2017/08/26 17:21:30 batch 441: mean=17.659091 stddev=7.528561 entropy=1.044478 frames=38554 count=44
2017/08/26 17:21:30 Training policy...
2017/08/26 17:21:36 step 0: objective=0.014877439
2017/08/26 17:21:41 step 1: objective=0.014928779
2017/08/26 17:21:46 step 2: objective=0.014980241
2017/08/26 17:21:51 step 3: objective=0.015031817
2017/08/26 17:21:56 step 4: objective=0.01508364
2017/08/26 17:22:01 step 5: objective=0.015135102
2017/08/26 17:22:06 step 6: objective=0.01517388
2017/08/26 17:22:11 step 7: objective=0.015208087
2017/08/26 17:22:11 Training value function...
2017/08/26 17:22:13 step 0: mse=1.155797 step=0.100000
2017/08/26 17:22:13 step 1: mse=1.114328 step=0.100000
2017/08/26 17:22:14 step 2: mse=1.056242 step=0.100000
2017/08/26 17:22:15 step 3: mse=1.026296 step=0.100000
2017/08/26 17:22:16 step 4: mse=0.993539 step=0.100000
2017/08/26 17:22:17 step 5: mse=0.939509 step=0.100000
2017/08/26 17:22:17 step 6: mse=0.902505 step=0.100000
2017/08/26 17:22:18 step 7: mse=0.852288 step=0.100000
2017/08/26 17:22:18 Saving...
2017/08/26 17:22:18 Gathering batch of experience...
2017/08/26 17:22:38 batch 442: mean=19.525000 stddev=7.459851 entropy=1.038919 frames=36950 count=40
2017/08/26 17:22:38 Training policy...
2017/08/26 17:22:44 step 0: objective=0.054455522
2017/08/26 17:22:49 step 1: objective=0.05449955
2017/08/26 17:22:54 step 2: objective=0.054543186
2017/08/26 17:22:58 step 3: objective=0.054587312
2017/08/26 17:23:03 step 4: objective=0.05463149
2017/08/26 17:23:08 step 5: objective=0.054674417
2017/08/26 17:23:13 step 6: objective=0.054709163
2017/08/26 17:23:18 step 7: objective=0.05473695
2017/08/26 17:23:18 Training value function...
2017/08/26 17:23:19 step 0: mse=1.111512 step=0.100000
2017/08/26 17:23:19 step 1: mse=1.053675 step=0.100000
2017/08/26 17:23:20 step 2: mse=1.006294 step=0.100000
2017/08/26 17:23:21 step 3: mse=0.967135 step=0.100000
2017/08/26 17:23:22 step 4: mse=0.934205 step=0.100000
2017/08/26 17:23:23 step 5: mse=0.904338 step=0.100000
2017/08/26 17:23:23 step 6: mse=0.877683 step=0.100000
2017/08/26 17:23:24 step 7: mse=0.856005 step=0.100000
2017/08/26 17:23:24 Saving...
2017/08/26 17:23:24 Gathering batch of experience...
2017/08/26 17:23:43 batch 443: mean=17.953488 stddev=8.517980 entropy=1.045322 frames=35950 count=43
2017/08/26 17:23:43 Training policy...
2017/08/26 17:23:50 step 0: objective=0.020659305
2017/08/26 17:23:54 step 1: objective=0.020728998
2017/08/26 17:23:59 step 2: objective=0.020799104
2017/08/26 17:24:04 step 3: objective=0.0208696
2017/08/26 17:24:08 step 4: objective=0.020939892
2017/08/26 17:24:13 step 5: objective=0.020986825
2017/08/26 17:24:18 step 6: objective=0.021050818
2017/08/26 17:24:22 step 7: objective=0.021098522
2017/08/26 17:24:22 Training value function...
2017/08/26 17:24:23 step 0: mse=1.317931 step=0.100000
2017/08/26 17:24:24 step 1: mse=1.202629 step=0.100000
2017/08/26 17:24:25 step 2: mse=1.119787 step=0.100000
2017/08/26 17:24:26 step 3: mse=1.051413 step=0.100000
2017/08/26 17:24:26 step 4: mse=0.998615 step=0.100000
2017/08/26 17:24:27 step 5: mse=0.953470 step=0.100000
2017/08/26 17:24:28 step 6: mse=0.910409 step=0.100000
2017/08/26 17:24:29 step 7: mse=0.879644 step=0.100000
2017/08/26 17:24:29 Saving...
2017/08/26 17:24:29 Gathering batch of experience...
2017/08/26 17:24:48 batch 444: mean=16.777778 stddev=7.728415 entropy=1.043078 frames=36623 count=45
2017/08/26 17:24:48 Training policy...
2017/08/26 17:24:54 step 0: objective=0.029314928
2017/08/26 17:24:59 step 1: objective=0.029352222
2017/08/26 17:25:04 step 2: objective=0.029389864
2017/08/26 17:25:09 step 3: objective=0.029427448
2017/08/26 17:25:13 step 4: objective=0.029465197
2017/08/26 17:25:18 step 5: objective=0.029501457
2017/08/26 17:25:23 step 6: objective=0.029586283
2017/08/26 17:25:28 step 7: objective=0.02964599
2017/08/26 17:25:28 Training value function...
2017/08/26 17:25:29 step 0: mse=1.491303 step=0.100000
2017/08/26 17:25:30 step 1: mse=1.354083 step=0.100000
2017/08/26 17:25:31 step 2: mse=1.244208 step=0.100000
2017/08/26 17:25:31 step 3: mse=1.155167 step=0.100000
2017/08/26 17:25:32 step 4: mse=1.083675 step=0.100000
2017/08/26 17:25:33 step 5: mse=1.025191 step=0.100000
2017/08/26 17:25:34 step 6: mse=0.974327 step=0.100000
2017/08/26 17:25:35 step 7: mse=0.934636 step=0.100000
2017/08/26 17:25:35 Saving...
2017/08/26 17:25:35 Gathering batch of experience...
2017/08/26 17:25:54 batch 445: mean=14.622222 stddev=5.978810 entropy=1.054768 frames=35825 count=45
2017/08/26 17:25:54 Training policy...
2017/08/26 17:26:00 step 0: objective=-0.015826147
2017/08/26 17:26:05 step 1: objective=-0.015714774
2017/08/26 17:26:10 step 2: objective=-0.01560465
2017/08/26 17:26:14 step 3: objective=-0.015508045
2017/08/26 17:26:19 step 4: objective=-0.015435666
2017/08/26 17:26:24 step 5: objective=-0.015353511
2017/08/26 17:26:28 step 6: objective=-0.0152952215
2017/08/26 17:26:33 step 7: objective=-0.015251206
2017/08/26 17:26:33 Training value function...
2017/08/26 17:26:34 step 0: mse=0.704314 step=0.100000
2017/08/26 17:26:35 step 1: mse=0.652894 step=0.100000
2017/08/26 17:26:36 step 2: mse=0.612395 step=0.100000
2017/08/26 17:26:36 step 3: mse=0.579876 step=0.100000
2017/08/26 17:26:37 step 4: mse=0.553904 step=0.100000
2017/08/26 17:26:38 step 5: mse=0.533366 step=0.100000
2017/08/26 17:26:39 step 6: mse=0.515711 step=0.100000
2017/08/26 17:26:39 step 7: mse=0.501730 step=0.100000
2017/08/26 17:26:39 Saving...
2017/08/26 17:26:39 Gathering batch of experience...
2017/08/26 17:26:58 batch 446: mean=15.666667 stddev=6.289321 entropy=1.050999 frames=35166 count=45
2017/08/26 17:26:58 Training policy...
2017/08/26 17:27:04 step 0: objective=0.04209211
2017/08/26 17:27:09 step 1: objective=0.042135473
2017/08/26 17:27:13 step 2: objective=0.042178787
2017/08/26 17:27:18 step 3: objective=0.042222563
2017/08/26 17:27:22 step 4: objective=0.042266022
2017/08/26 17:27:27 step 5: objective=0.04230596
2017/08/26 17:27:32 step 6: objective=0.04234546
2017/08/26 17:27:36 step 7: objective=0.04238606
2017/08/26 17:27:36 Training value function...
2017/08/26 17:27:37 step 0: mse=1.019394 step=0.100000
2017/08/26 17:27:38 step 1: mse=0.954683 step=0.100000
2017/08/26 17:27:39 step 2: mse=0.901753 step=0.100000
2017/08/26 17:27:39 step 3: mse=0.862665 step=0.100000
2017/08/26 17:27:40 step 4: mse=0.830835 step=0.100000
2017/08/26 17:27:41 step 5: mse=0.802441 step=0.100000
2017/08/26 17:27:41 step 6: mse=0.768756 step=0.100000
2017/08/26 17:27:42 step 7: mse=0.749848 step=0.100000
2017/08/26 17:27:42 Saving...
2017/08/26 17:27:42 Gathering batch of experience...
2017/08/26 17:28:02 batch 447: mean=17.022222 stddev=7.147615 entropy=1.043225 frames=37418 count=45
2017/08/26 17:28:02 Training policy...
2017/08/26 17:28:08 step 0: objective=0.03543653
2017/08/26 17:28:13 step 1: objective=0.03547008
2017/08/26 17:28:18 step 2: objective=0.035503432
2017/08/26 17:28:23 step 3: objective=0.035537336
2017/08/26 17:28:28 step 4: objective=0.03557096
2017/08/26 17:28:33 step 5: objective=0.035601895
2017/08/26 17:28:38 step 6: objective=0.035636853
2017/08/26 17:28:43 step 7: objective=0.035662055
2017/08/26 17:28:43 Training value function...
2017/08/26 17:28:44 step 0: mse=1.151306 step=0.100000
2017/08/26 17:28:45 step 1: mse=1.059551 step=0.100000
2017/08/26 17:28:46 step 2: mse=0.975531 step=0.100000
2017/08/26 17:28:46 step 3: mse=0.910400 step=0.100000
2017/08/26 17:28:47 step 4: mse=0.854085 step=0.100000
2017/08/26 17:28:48 step 5: mse=0.807626 step=0.100000
2017/08/26 17:28:49 step 6: mse=0.765559 step=0.100000
2017/08/26 17:28:49 step 7: mse=0.727111 step=0.100000
2017/08/26 17:28:49 Saving...
2017/08/26 17:28:49 Gathering batch of experience...
2017/08/26 17:29:09 batch 448: mean=15.266667 stddev=6.233957 entropy=1.046357 frames=36901 count=45
2017/08/26 17:29:09 Training policy...
2017/08/26 17:29:15 step 0: objective=-0.011040631
2017/08/26 17:29:20 step 1: objective=-0.010991512
2017/08/26 17:29:25 step 2: objective=-0.010941941
2017/08/26 17:29:30 step 3: objective=-0.010892129
2017/08/26 17:29:35 step 4: objective=-0.010844101
2017/08/26 17:29:40 step 5: objective=-0.010798685
2017/08/26 17:29:45 step 6: objective=-0.010753985
2017/08/26 17:29:50 step 7: objective=-0.010714124
2017/08/26 17:29:50 Training value function...
2017/08/26 17:29:51 step 0: mse=0.719966 step=0.100000
2017/08/26 17:29:51 step 1: mse=0.661379 step=0.100000
2017/08/26 17:29:52 step 2: mse=0.618307 step=0.100000
2017/08/26 17:29:53 step 3: mse=0.583127 step=0.100000
2017/08/26 17:29:54 step 4: mse=0.552564 step=0.100000
2017/08/26 17:29:54 step 5: mse=0.524350 step=0.100000
2017/08/26 17:29:55 step 6: mse=0.500114 step=0.100000
2017/08/26 17:29:56 step 7: mse=0.480914 step=0.100000
2017/08/26 17:29:56 Saving...
2017/08/26 17:29:56 Gathering batch of experience...
2017/08/26 17:30:16 batch 449: mean=19.285714 stddev=8.344618 entropy=1.041359 frames=38570 count=42
2017/08/26 17:30:16 Training policy...
2017/08/26 17:30:23 step 0: objective=0.06104336
2017/08/26 17:30:28 step 1: objective=0.061122
2017/08/26 17:30:33 step 2: objective=0.06120201
2017/08/26 17:30:38 step 3: objective=0.061282646
2017/08/26 17:30:43 step 4: objective=0.061342657
2017/08/26 17:30:48 step 5: objective=0.061396018
2017/08/26 17:30:53 step 6: objective=0.06144352
2017/08/26 17:30:58 step 7: objective=0.06150007
2017/08/26 17:30:58 Training value function...
2017/08/26 17:31:00 step 0: mse=1.239169 step=0.100000
2017/08/26 17:31:00 step 1: mse=1.147337 step=0.100000
2017/08/26 17:31:01 step 2: mse=1.082380 step=0.100000
2017/08/26 17:31:02 step 3: mse=1.023157 step=0.100000
2017/08/26 17:31:03 step 4: mse=0.955469 step=0.100000
2017/08/26 17:31:04 step 5: mse=0.892673 step=0.100000
2017/08/26 17:31:04 step 6: mse=0.857439 step=0.100000
2017/08/26 17:31:05 step 7: mse=0.819005 step=0.100000
2017/08/26 17:31:05 Saving...
2017/08/26 17:31:05 Gathering batch of experience...
2017/08/26 17:31:25 batch 450: mean=17.295455 stddev=7.451600 entropy=1.039084 frames=36764 count=44
2017/08/26 17:31:25 Training policy...
2017/08/26 17:31:31 step 0: objective=0.04054526
2017/08/26 17:31:36 step 1: objective=0.040606633
2017/08/26 17:31:41 step 2: objective=0.04064065
2017/08/26 17:31:46 step 3: objective=0.040674567
2017/08/26 17:31:51 step 4: objective=0.04070899
2017/08/26 17:31:56 step 5: objective=0.040739182
2017/08/26 17:32:01 step 6: objective=0.040807966
2017/08/26 17:32:05 step 7: objective=0.04085469
2017/08/26 17:32:05 Training value function...
2017/08/26 17:32:07 step 0: mse=1.172723 step=0.100000
2017/08/26 17:32:07 step 1: mse=1.082061 step=0.100000
2017/08/26 17:32:08 step 2: mse=1.008627 step=0.100000
2017/08/26 17:32:09 step 3: mse=0.948647 step=0.100000
2017/08/26 17:32:10 step 4: mse=0.898872 step=0.100000
2017/08/26 17:32:10 step 5: mse=0.855945 step=0.100000
2017/08/26 17:32:11 step 6: mse=0.821646 step=0.100000
2017/08/26 17:32:12 step 7: mse=0.792791 step=0.100000
2017/08/26 17:32:12 Saving...
2017/08/26 17:32:12 Gathering batch of experience...
2017/08/26 17:32:31 batch 451: mean=17.523810 stddev=6.199993 entropy=1.046571 frames=36134 count=42
2017/08/26 17:32:31 Training policy...
2017/08/26 17:32:37 step 0: objective=0.038901046
2017/08/26 17:32:42 step 1: objective=0.03901807
2017/08/26 17:32:47 step 2: objective=0.039134573
2017/08/26 17:32:52 step 3: objective=0.03924993
2017/08/26 17:32:56 step 4: objective=0.039293926
2017/08/26 17:33:01 step 5: objective=0.039368853
2017/08/26 17:33:06 step 6: objective=0.03944471
2017/08/26 17:33:11 step 7: objective=0.0394968
2017/08/26 17:33:11 Training value function...
2017/08/26 17:33:12 step 0: mse=1.001023 step=0.100000
2017/08/26 17:33:13 step 1: mse=0.952177 step=0.100000
2017/08/26 17:33:14 step 2: mse=0.912809 step=0.100000
2017/08/26 17:33:14 step 3: mse=0.880441 step=0.100000
2017/08/26 17:33:15 step 4: mse=0.853710 step=0.100000
2017/08/26 17:33:16 step 5: mse=0.831916 step=0.100000
2017/08/26 17:33:16 step 6: mse=0.813067 step=0.100000
2017/08/26 17:33:17 step 7: mse=0.787796 step=0.100000
2017/08/26 17:33:17 Saving...
2017/08/26 17:33:17 Gathering batch of experience...
2017/08/26 17:33:37 batch 452: mean=17.651163 stddev=8.907493 entropy=1.036819 frames=37412 count=43
2017/08/26 17:33:37 Training policy...
2017/08/26 17:33:44 step 0: objective=0.036509313
2017/08/26 17:33:49 step 1: objective=0.036591355
2017/08/26 17:33:53 step 2: objective=0.03667442
2017/08/26 17:33:58 step 3: objective=0.036757033
2017/08/26 17:34:03 step 4: objective=0.036833797
2017/08/26 17:34:08 step 5: objective=0.036867753
2017/08/26 17:34:13 step 6: objective=0.036890138
2017/08/26 17:34:18 step 7: objective=0.03694055
2017/08/26 17:34:18 Training value function...
2017/08/26 17:34:19 step 0: mse=1.092553 step=0.100000
2017/08/26 17:34:20 step 1: mse=1.011582 step=0.100000
2017/08/26 17:34:21 step 2: mse=0.938080 step=0.100000
2017/08/26 17:34:22 step 3: mse=0.876579 step=0.100000
2017/08/26 17:34:23 step 4: mse=0.828845 step=0.100000
2017/08/26 17:34:23 step 5: mse=0.785856 step=0.100000
2017/08/26 17:34:24 step 6: mse=0.754206 step=0.100000
2017/08/26 17:34:25 step 7: mse=0.719106 step=0.100000
2017/08/26 17:34:25 Saving...
2017/08/26 17:34:25 Gathering batch of experience...
2017/08/26 17:34:45 batch 453: mean=15.977778 stddev=7.558627 entropy=1.043082 frames=36822 count=45
2017/08/26 17:34:45 Training policy...
2017/08/26 17:34:51 step 0: objective=0.028784841
2017/08/26 17:34:56 step 1: objective=0.028843492
2017/08/26 17:35:01 step 2: objective=0.028901802
2017/08/26 17:35:06 step 3: objective=0.028959457
2017/08/26 17:35:11 step 4: objective=0.029016277
2017/08/26 17:35:16 step 5: objective=0.029065548
2017/08/26 17:35:20 step 6: objective=0.029089691
2017/08/26 17:35:25 step 7: objective=0.02914002
2017/08/26 17:35:25 Training value function...
2017/08/26 17:35:27 step 0: mse=0.958674 step=0.100000
2017/08/26 17:35:27 step 1: mse=0.890934 step=0.100000
2017/08/26 17:35:28 step 2: mse=0.835613 step=0.100000
2017/08/26 17:35:29 step 3: mse=0.791101 step=0.100000
2017/08/26 17:35:30 step 4: mse=0.754954 step=0.100000
2017/08/26 17:35:30 step 5: mse=0.717910 step=0.100000
2017/08/26 17:35:31 step 6: mse=0.691090 step=0.100000
2017/08/26 17:35:32 step 7: mse=0.655022 step=0.100000
2017/08/26 17:35:32 Saving...
2017/08/26 17:35:32 Gathering batch of experience...
2017/08/26 17:35:51 batch 454: mean=18.414634 stddev=7.444021 entropy=1.049068 frames=36058 count=41
2017/08/26 17:35:51 Training policy...
2017/08/26 17:35:57 step 0: objective=0.043128796
2017/08/26 17:36:02 step 1: objective=0.043181896
2017/08/26 17:36:07 step 2: objective=0.043234836
2017/08/26 17:36:11 step 3: objective=0.043287266
2017/08/26 17:36:16 step 4: objective=0.04333995
2017/08/26 17:36:21 step 5: objective=0.043392237
2017/08/26 17:36:26 step 6: objective=0.043442395
2017/08/26 17:36:30 step 7: objective=0.04350256
2017/08/26 17:36:30 Training value function...
2017/08/26 17:36:32 step 0: mse=1.258910 step=0.100000
2017/08/26 17:36:32 step 1: mse=1.183652 step=0.100000
2017/08/26 17:36:33 step 2: mse=1.114721 step=0.100000
2017/08/26 17:36:34 step 3: mse=1.046895 step=0.100000
2017/08/26 17:36:35 step 4: mse=1.004096 step=0.100000
2017/08/26 17:36:35 step 5: mse=0.954881 step=0.100000
2017/08/26 17:36:36 step 6: mse=0.922365 step=0.100000
2017/08/26 17:36:37 step 7: mse=0.883507 step=0.100000
2017/08/26 17:36:37 Saving...
2017/08/26 17:36:37 Gathering batch of experience...
2017/08/26 17:36:56 batch 455: mean=18.023810 stddev=7.038967 entropy=1.050206 frames=35719 count=42
2017/08/26 17:36:56 Training policy...
2017/08/26 17:37:02 step 0: objective=0.043173913
2017/08/26 17:37:07 step 1: objective=0.043273523
2017/08/26 17:37:12 step 2: objective=0.043373287
2017/08/26 17:37:17 step 3: objective=0.043467995
2017/08/26 17:37:21 step 4: objective=0.043539193
2017/08/26 17:37:26 step 5: objective=0.04362283
2017/08/26 17:37:31 step 6: objective=0.043702893
2017/08/26 17:37:36 step 7: objective=0.043748785
2017/08/26 17:37:36 Training value function...
2017/08/26 17:37:37 step 0: mse=1.165783 step=0.100000
2017/08/26 17:37:38 step 1: mse=1.110621 step=0.100000
2017/08/26 17:37:38 step 2: mse=1.066040 step=0.100000
2017/08/26 17:37:39 step 3: mse=1.029446 step=0.100000
2017/08/26 17:37:40 step 4: mse=0.994305 step=0.100000
2017/08/26 17:37:40 step 5: mse=0.967423 step=0.100000
2017/08/26 17:37:41 step 6: mse=0.908260 step=0.100000
2017/08/26 17:37:42 step 7: mse=0.878792 step=0.100000
2017/08/26 17:37:42 Saving...
2017/08/26 17:37:42 Gathering batch of experience...
2017/08/26 17:38:02 batch 456: mean=19.682927 stddev=5.710235 entropy=1.037894 frames=37670 count=41
2017/08/26 17:38:02 Training policy...
2017/08/26 17:38:08 step 0: objective=0.031250242
2017/08/26 17:38:13 step 1: objective=0.031332117
2017/08/26 17:38:18 step 2: objective=0.031413637
2017/08/26 17:38:23 step 3: objective=0.031494975
2017/08/26 17:38:28 step 4: objective=0.031569853
2017/08/26 17:38:33 step 5: objective=0.031627554
2017/08/26 17:38:38 step 6: objective=0.03172341
2017/08/26 17:38:43 step 7: objective=0.03177156
2017/08/26 17:38:43 Training value function...
2017/08/26 17:38:45 step 0: mse=1.051973 step=0.100000
2017/08/26 17:38:45 step 1: mse=1.011027 step=0.100000
2017/08/26 17:38:46 step 2: mse=0.978159 step=0.100000
2017/08/26 17:38:47 step 3: mse=0.951321 step=0.100000
2017/08/26 17:38:48 step 4: mse=0.909630 step=0.100000
2017/08/26 17:38:48 step 5: mse=0.875481 step=0.100000
2017/08/26 17:38:49 step 6: mse=0.856164 step=0.100000
2017/08/26 17:38:50 step 7: mse=0.827095 step=0.100000
2017/08/26 17:38:50 Saving...
2017/08/26 17:38:50 Gathering batch of experience...
2017/08/26 17:39:09 batch 457: mean=18.902439 stddev=8.398039 entropy=1.036564 frames=36554 count=41
2017/08/26 17:39:09 Training policy...
2017/08/26 17:39:16 step 0: objective=0.030866334
2017/08/26 17:39:21 step 1: objective=0.030915236
2017/08/26 17:39:26 step 2: objective=0.03096415
2017/08/26 17:39:30 step 3: objective=0.031012805
2017/08/26 17:39:35 step 4: objective=0.031059735
2017/08/26 17:39:40 step 5: objective=0.031123478
2017/08/26 17:39:45 step 6: objective=0.031184297
2017/08/26 17:39:50 step 7: objective=0.031256307
2017/08/26 17:39:50 Training value function...
2017/08/26 17:39:51 step 0: mse=1.248120 step=0.100000
2017/08/26 17:39:52 step 1: mse=1.164123 step=0.100000
2017/08/26 17:39:52 step 2: mse=1.095699 step=0.100000
2017/08/26 17:39:53 step 3: mse=1.039377 step=0.100000
2017/08/26 17:39:54 step 4: mse=0.987217 step=0.100000
2017/08/26 17:39:55 step 5: mse=0.940925 step=0.100000
2017/08/26 17:39:55 step 6: mse=0.908942 step=0.100000
2017/08/26 17:39:56 step 7: mse=0.878550 step=0.100000
2017/08/26 17:39:56 Saving...
2017/08/26 17:39:56 Gathering batch of experience...
2017/08/26 17:40:16 batch 458: mean=17.046512 stddev=7.252757 entropy=1.042081 frames=36865 count=43
2017/08/26 17:40:16 Training policy...
2017/08/26 17:40:23 step 0: objective=0.012580672
2017/08/26 17:40:27 step 1: objective=0.012631591
2017/08/26 17:40:32 step 2: objective=0.012679592
2017/08/26 17:40:37 step 3: objective=0.012727361
2017/08/26 17:40:42 step 4: objective=0.012775016
2017/08/26 17:40:47 step 5: objective=0.012818365
2017/08/26 17:40:52 step 6: objective=0.012858511
2017/08/26 17:40:57 step 7: objective=0.012909155
2017/08/26 17:40:57 Training value function...
2017/08/26 17:40:58 step 0: mse=0.925315 step=0.100000
2017/08/26 17:40:59 step 1: mse=0.873478 step=0.100000
2017/08/26 17:41:00 step 2: mse=0.831021 step=0.100000
2017/08/26 17:41:00 step 3: mse=0.774170 step=0.100000
2017/08/26 17:41:01 step 4: mse=0.729926 step=0.100000
2017/08/26 17:41:02 step 5: mse=0.689527 step=0.100000
2017/08/26 17:41:03 step 6: mse=0.658929 step=0.100000
2017/08/26 17:41:03 step 7: mse=0.646234 step=0.100000
2017/08/26 17:41:03 Saving...
2017/08/26 17:41:03 Gathering batch of experience...
2017/08/26 17:41:23 batch 459: mean=16.333333 stddev=6.596295 entropy=1.051219 frames=36052 count=45
2017/08/26 17:41:23 Training policy...
2017/08/26 17:41:29 step 0: objective=0.03446617
2017/08/26 17:41:34 step 1: objective=0.034500584
2017/08/26 17:41:39 step 2: objective=0.03453535
2017/08/26 17:41:44 step 3: objective=0.03457031
2017/08/26 17:41:48 step 4: objective=0.03460551
2017/08/26 17:41:53 step 5: objective=0.034640465
2017/08/26 17:41:58 step 6: objective=0.034666654
2017/08/26 17:42:03 step 7: objective=0.03470479
2017/08/26 17:42:03 Training value function...
2017/08/26 17:42:04 step 0: mse=1.032924 step=0.100000
2017/08/26 17:42:05 step 1: mse=0.993414 step=0.100000
2017/08/26 17:42:05 step 2: mse=0.965510 step=0.100000
2017/08/26 17:42:06 step 3: mse=0.932335 step=0.100000
2017/08/26 17:42:07 step 4: mse=0.902309 step=0.100000
2017/08/26 17:42:08 step 5: mse=0.871918 step=0.100000
2017/08/26 17:42:08 step 6: mse=0.846223 step=0.100000
2017/08/26 17:42:09 step 7: mse=0.824562 step=0.100000
2017/08/26 17:42:09 Saving...
2017/08/26 17:42:09 Gathering batch of experience...
2017/08/26 17:42:29 batch 460: mean=19.425000 stddev=9.079888 entropy=1.031942 frames=36776 count=40
2017/08/26 17:42:29 Training policy...
2017/08/26 17:42:35 step 0: objective=0.036564656
2017/08/26 17:42:40 step 1: objective=0.03661887
2017/08/26 17:42:45 step 2: objective=0.036673006
2017/08/26 17:42:50 step 3: objective=0.036726717
2017/08/26 17:42:55 step 4: objective=0.0367801
2017/08/26 17:43:00 step 5: objective=0.03683178
2017/08/26 17:43:05 step 6: objective=0.03687306
2017/08/26 17:43:10 step 7: objective=0.036935173
2017/08/26 17:43:10 Training value function...
2017/08/26 17:43:11 step 0: mse=1.257108 step=0.100000
2017/08/26 17:43:11 step 1: mse=1.188971 step=0.100000
2017/08/26 17:43:12 step 2: mse=1.120616 step=0.100000
2017/08/26 17:43:13 step 3: mse=1.075374 step=0.100000
2017/08/26 17:43:14 step 4: mse=1.030980 step=0.100000
2017/08/26 17:43:14 step 5: mse=0.991705 step=0.100000
2017/08/26 17:43:15 step 6: mse=0.958609 step=0.100000
2017/08/26 17:43:16 step 7: mse=0.905522 step=0.100000
2017/08/26 17:43:16 Saving...
2017/08/26 17:43:16 Gathering batch of experience...
2017/08/26 17:43:36 batch 461: mean=16.113636 stddev=6.249421 entropy=1.054318 frames=36867 count=44
2017/08/26 17:43:36 Training policy...
2017/08/26 17:43:42 step 0: objective=-0.0038568066
2017/08/26 17:43:47 step 1: objective=-0.0037867478
2017/08/26 17:43:52 step 2: objective=-0.0037163228
2017/08/26 17:43:57 step 3: objective=-0.0036455626
2017/08/26 17:44:02 step 4: objective=-0.0035746729
2017/08/26 17:44:07 step 5: objective=-0.0035144894
2017/08/26 17:44:12 step 6: objective=-0.0034681056
2017/08/26 17:44:17 step 7: objective=-0.0034105168
2017/08/26 17:44:17 Training value function...
2017/08/26 17:44:18 step 0: mse=0.733549 step=0.100000
2017/08/26 17:44:19 step 1: mse=0.699266 step=0.100000
2017/08/26 17:44:20 step 2: mse=0.672190 step=0.100000
2017/08/26 17:44:20 step 3: mse=0.650536 step=0.100000
2017/08/26 17:44:21 step 4: mse=0.632980 step=0.100000
2017/08/26 17:44:22 step 5: mse=0.601691 step=0.100000
2017/08/26 17:44:23 step 6: mse=0.584805 step=0.100000
2017/08/26 17:44:23 step 7: mse=0.565346 step=0.100000
2017/08/26 17:44:23 Saving...
2017/08/26 17:44:23 Gathering batch of experience...
2017/08/26 17:44:42 batch 462: mean=16.476190 stddev=7.928965 entropy=1.036106 frames=35783 count=42
2017/08/26 17:44:42 Training policy...
2017/08/26 17:44:49 step 0: objective=0.02626553
2017/08/26 17:44:53 step 1: objective=0.026320409
2017/08/26 17:44:58 step 2: objective=0.026375704
2017/08/26 17:45:03 step 3: objective=0.026431277
2017/08/26 17:45:08 step 4: objective=0.02647968
2017/08/26 17:45:13 step 5: objective=0.026561437
2017/08/26 17:45:17 step 6: objective=0.026625847
2017/08/26 17:45:22 step 7: objective=0.026688142
2017/08/26 17:45:22 Training value function...
2017/08/26 17:45:23 step 0: mse=0.847387 step=0.100000
2017/08/26 17:45:24 step 1: mse=0.801042 step=0.100000
2017/08/26 17:45:25 step 2: mse=0.764515 step=0.100000
2017/08/26 17:45:25 step 3: mse=0.731637 step=0.100000
2017/08/26 17:45:26 step 4: mse=0.700392 step=0.100000
2017/08/26 17:45:27 step 5: mse=0.673715 step=0.100000
2017/08/26 17:45:27 step 6: mse=0.654101 step=0.100000
2017/08/26 17:45:28 step 7: mse=0.633705 step=0.100000
2017/08/26 17:45:28 Saving...
2017/08/26 17:45:28 Gathering batch of experience...
2017/08/26 17:45:47 batch 463: mean=18.707317 stddev=7.545775 entropy=1.037658 frames=36061 count=41
2017/08/26 17:45:47 Training policy...
2017/08/26 17:45:54 step 0: objective=0.06496012
2017/08/26 17:45:58 step 1: objective=0.06504943
2017/08/26 17:46:03 step 2: objective=0.06513983
2017/08/26 17:46:08 step 3: objective=0.06522486
2017/08/26 17:46:13 step 4: objective=0.06530593
2017/08/26 17:46:18 step 5: objective=0.06534308
2017/08/26 17:46:23 step 6: objective=0.065364845
2017/08/26 17:46:27 step 7: objective=0.06538562
2017/08/26 17:46:27 Training value function...
2017/08/26 17:46:29 step 0: mse=1.219128 step=0.100000
2017/08/26 17:46:29 step 1: mse=1.130659 step=0.100000
2017/08/26 17:46:30 step 2: mse=1.058805 step=0.100000
2017/08/26 17:46:31 step 3: mse=1.001954 step=0.100000
2017/08/26 17:46:32 step 4: mse=0.955709 step=0.100000
2017/08/26 17:46:32 step 5: mse=0.916242 step=0.100000
2017/08/26 17:46:33 step 6: mse=0.877961 step=0.100000
2017/08/26 17:46:34 step 7: mse=0.846191 step=0.100000
2017/08/26 17:46:34 Saving...
2017/08/26 17:46:34 Gathering batch of experience...
2017/08/26 17:46:54 batch 464: mean=16.511111 stddev=7.009905 entropy=1.051139 frames=37397 count=45
2017/08/26 17:46:54 Training policy...
2017/08/26 17:47:01 step 0: objective=0.031650756
2017/08/26 17:47:06 step 1: objective=0.031719614
2017/08/26 17:47:11 step 2: objective=0.031787947
2017/08/26 17:47:16 step 3: objective=0.031856276
2017/08/26 17:47:21 step 4: objective=0.03192004
2017/08/26 17:47:26 step 5: objective=0.03194876
2017/08/26 17:47:31 step 6: objective=0.032013737
2017/08/26 17:47:36 step 7: objective=0.032059997
2017/08/26 17:47:36 Training value function...
2017/08/26 17:47:37 step 0: mse=1.151057 step=0.100000
2017/08/26 17:47:38 step 1: mse=1.063318 step=0.100000
2017/08/26 17:47:39 step 2: mse=0.993452 step=0.100000
2017/08/26 17:47:39 step 3: mse=0.935076 step=0.100000
2017/08/26 17:47:40 step 4: mse=0.881235 step=0.100000
2017/08/26 17:47:41 step 5: mse=0.833937 step=0.100000
2017/08/26 17:47:42 step 6: mse=0.795451 step=0.100000
2017/08/26 17:47:43 step 7: mse=0.762421 step=0.100000
2017/08/26 17:47:43 Saving...
2017/08/26 17:47:43 Gathering batch of experience...
2017/08/26 17:48:02 batch 465: mean=16.318182 stddev=8.047509 entropy=1.052647 frames=36071 count=44
2017/08/26 17:48:02 Training policy...
2017/08/26 17:48:08 step 0: objective=0.012800387
2017/08/26 17:48:13 step 1: objective=0.012828415
2017/08/26 17:48:18 step 2: objective=0.012856179
2017/08/26 17:48:23 step 3: objective=0.012883765
2017/08/26 17:48:28 step 4: objective=0.012920251
2017/08/26 17:48:33 step 5: objective=0.01295661
2017/08/26 17:48:37 step 6: objective=0.0130061535
2017/08/26 17:48:42 step 7: objective=0.013065197
2017/08/26 17:48:42 Training value function...
2017/08/26 17:48:43 step 0: mse=0.969254 step=0.100000
2017/08/26 17:48:44 step 1: mse=0.931980 step=0.100000
2017/08/26 17:48:45 step 2: mse=0.868033 step=0.100000
2017/08/26 17:48:46 step 3: mse=0.839104 step=0.100000
2017/08/26 17:48:46 step 4: mse=0.793067 step=0.100000
2017/08/26 17:48:47 step 5: mse=0.748515 step=0.100000
2017/08/26 17:48:48 step 6: mse=0.730635 step=0.100000
2017/08/26 17:48:49 step 7: mse=0.696386 step=0.100000
2017/08/26 17:48:49 Saving...
2017/08/26 17:48:49 Gathering batch of experience...
2017/08/26 17:49:09 batch 466: mean=20.615385 stddev=9.230983 entropy=1.025178 frames=37193 count=39
2017/08/26 17:49:09 Training policy...
2017/08/26 17:49:15 step 0: objective=0.03220602
2017/08/26 17:49:20 step 1: objective=0.0322473
2017/08/26 17:49:25 step 2: objective=0.032287445
2017/08/26 17:49:30 step 3: objective=0.032328244
2017/08/26 17:49:35 step 4: objective=0.032369226
2017/08/26 17:49:40 step 5: objective=0.03240744
2017/08/26 17:49:45 step 6: objective=0.032443613
2017/08/26 17:49:50 step 7: objective=0.03247695
2017/08/26 17:49:50 Training value function...
2017/08/26 17:49:51 step 0: mse=1.567984 step=0.100000
2017/08/26 17:49:52 step 1: mse=1.423561 step=0.100000
2017/08/26 17:49:53 step 2: mse=1.307342 step=0.100000
2017/08/26 17:49:54 step 3: mse=1.215542 step=0.100000
2017/08/26 17:49:54 step 4: mse=1.137535 step=0.100000
2017/08/26 17:49:55 step 5: mse=1.074181 step=0.100000
2017/08/26 17:49:56 step 6: mse=1.021389 step=0.100000
2017/08/26 17:49:57 step 7: mse=0.970685 step=0.100000
2017/08/26 17:49:57 Saving...
2017/08/26 17:49:57 Gathering batch of experience...
2017/08/26 17:50:16 batch 467: mean=16.159091 stddev=6.835546 entropy=1.039366 frames=36638 count=44
2017/08/26 17:50:16 Training policy...
2017/08/26 17:50:23 step 0: objective=0.0002386809
2017/08/26 17:50:28 step 1: objective=0.00030587977
2017/08/26 17:50:33 step 2: objective=0.00037199014
2017/08/26 17:50:38 step 3: objective=0.00043625242
2017/08/26 17:50:43 step 4: objective=0.00047882544
2017/08/26 17:50:48 step 5: objective=0.00050350034
2017/08/26 17:50:52 step 6: objective=0.00053461327
2017/08/26 17:50:57 step 7: objective=0.0005974428
2017/08/26 17:50:57 Training value function...
2017/08/26 17:50:59 step 0: mse=0.931805 step=0.100000
2017/08/26 17:50:59 step 1: mse=0.871268 step=0.100000
2017/08/26 17:51:00 step 2: mse=0.822830 step=0.100000
2017/08/26 17:51:01 step 3: mse=0.787354 step=0.100000
2017/08/26 17:51:02 step 4: mse=0.754166 step=0.100000
2017/08/26 17:51:03 step 5: mse=0.725726 step=0.100000
2017/08/26 17:51:03 step 6: mse=0.699243 step=0.100000
2017/08/26 17:51:04 step 7: mse=0.678813 step=0.100000
2017/08/26 17:51:04 Saving...
2017/08/26 17:51:04 Gathering batch of experience...
2017/08/26 17:51:24 batch 468: mean=16.906977 stddev=6.257327 entropy=1.054708 frames=36848 count=43
2017/08/26 17:51:24 Training policy...
2017/08/26 17:51:30 step 0: objective=0.010873937
2017/08/26 17:51:35 step 1: objective=0.010958197
2017/08/26 17:51:40 step 2: objective=0.011041343
2017/08/26 17:51:45 step 3: objective=0.011122009
2017/08/26 17:51:50 step 4: objective=0.011183651
2017/08/26 17:51:55 step 5: objective=0.011237832
2017/08/26 17:52:00 step 6: objective=0.011289635
2017/08/26 17:52:05 step 7: objective=0.011342026
2017/08/26 17:52:05 Training value function...
2017/08/26 17:52:06 step 0: mse=0.828390 step=0.100000
2017/08/26 17:52:07 step 1: mse=0.779825 step=0.100000
2017/08/26 17:52:08 step 2: mse=0.741506 step=0.100000
2017/08/26 17:52:09 step 3: mse=0.710841 step=0.100000
2017/08/26 17:52:09 step 4: mse=0.674644 step=0.100000
2017/08/26 17:52:10 step 5: mse=0.648211 step=0.100000
2017/08/26 17:52:11 step 6: mse=0.630445 step=0.100000
2017/08/26 17:52:12 step 7: mse=0.610972 step=0.100000
2017/08/26 17:52:12 Saving...
2017/08/26 17:52:12 Gathering batch of experience...
2017/08/26 17:52:31 batch 469: mean=15.711111 stddev=6.206170 entropy=1.045247 frames=35979 count=45
2017/08/26 17:52:31 Training policy...
2017/08/26 17:52:38 step 0: objective=0.030411892
2017/08/26 17:52:42 step 1: objective=0.0304457
2017/08/26 17:52:47 step 2: objective=0.030479416
2017/08/26 17:52:52 step 3: objective=0.030513123
2017/08/26 17:52:57 step 4: objective=0.0305466
2017/08/26 17:53:02 step 5: objective=0.030578323
2017/08/26 17:53:07 step 6: objective=0.030604511
2017/08/26 17:53:12 step 7: objective=0.030625049
2017/08/26 17:53:12 Training value function...
2017/08/26 17:53:13 step 0: mse=0.973560 step=0.100000
2017/08/26 17:53:14 step 1: mse=0.915648 step=0.100000
2017/08/26 17:53:15 step 2: mse=0.868950 step=0.100000
2017/08/26 17:53:15 step 3: mse=0.831676 step=0.100000
2017/08/26 17:53:16 step 4: mse=0.799451 step=0.100000
2017/08/26 17:53:17 step 5: mse=0.762159 step=0.100000
2017/08/26 17:53:18 step 6: mse=0.737354 step=0.100000
2017/08/26 17:53:18 step 7: mse=0.717294 step=0.100000
2017/08/26 17:53:18 Saving...
2017/08/26 17:53:18 Gathering batch of experience...
2017/08/26 17:53:38 batch 470: mean=16.069767 stddev=5.895980 entropy=1.041468 frames=36888 count=43
2017/08/26 17:53:38 Training policy...
2017/08/26 17:53:45 step 0: objective=0.01717519
2017/08/26 17:53:50 step 1: objective=0.017234104
2017/08/26 17:53:55 step 2: objective=0.017315168
2017/08/26 17:54:00 step 3: objective=0.017395753
2017/08/26 17:54:05 step 4: objective=0.017453857
2017/08/26 17:54:10 step 5: objective=0.017497985
2017/08/26 17:54:15 step 6: objective=0.01753054
2017/08/26 17:54:20 step 7: objective=0.017560823
2017/08/26 17:54:20 Training value function...
2017/08/26 17:54:21 step 0: mse=0.907237 step=0.100000
2017/08/26 17:54:22 step 1: mse=0.844726 step=0.100000
2017/08/26 17:54:23 step 2: mse=0.794633 step=0.100000
2017/08/26 17:54:23 step 3: mse=0.754150 step=0.100000
2017/08/26 17:54:24 step 4: mse=0.701549 step=0.100000
2017/08/26 17:54:25 step 5: mse=0.659441 step=0.100000
2017/08/26 17:54:26 step 6: mse=0.633831 step=0.100000
2017/08/26 17:54:26 step 7: mse=0.602047 step=0.100000
2017/08/26 17:54:26 Saving...
2017/08/26 17:54:27 Gathering batch of experience...
2017/08/26 17:54:47 batch 471: mean=16.545455 stddev=7.133323 entropy=1.050254 frames=37452 count=44
2017/08/26 17:54:47 Training policy...
2017/08/26 17:54:53 step 0: objective=0.032192566
2017/08/26 17:54:58 step 1: objective=0.032262478
2017/08/26 17:55:03 step 2: objective=0.032332767
2017/08/26 17:55:09 step 3: objective=0.032385346
2017/08/26 17:55:14 step 4: objective=0.032438427
2017/08/26 17:55:19 step 5: objective=0.03248978
2017/08/26 17:55:24 step 6: objective=0.032537535
2017/08/26 17:55:29 step 7: objective=0.03257164
2017/08/26 17:55:29 Training value function...
2017/08/26 17:55:30 step 0: mse=0.761172 step=0.100000
2017/08/26 17:55:31 step 1: mse=0.722012 step=0.100000
2017/08/26 17:55:32 step 2: mse=0.691553 step=0.100000
2017/08/26 17:55:32 step 3: mse=0.669455 step=0.100000
2017/08/26 17:55:33 step 4: mse=0.636422 step=0.100000
2017/08/26 17:55:34 step 5: mse=0.616725 step=0.100000
2017/08/26 17:55:35 step 6: mse=0.592919 step=0.100000
2017/08/26 17:55:35 step 7: mse=0.579046 step=0.100000
2017/08/26 17:55:35 Saving...
2017/08/26 17:55:36 Gathering batch of experience...
2017/08/26 17:55:55 batch 472: mean=18.166667 stddev=8.372053 entropy=1.040196 frames=36094 count=42
2017/08/26 17:55:55 Training policy...
2017/08/26 17:56:01 step 0: objective=0.05732141
2017/08/26 17:56:06 step 1: objective=0.05737246
2017/08/26 17:56:11 step 2: objective=0.057424378
2017/08/26 17:56:16 step 3: objective=0.057476766
2017/08/26 17:56:21 step 4: objective=0.05752857
2017/08/26 17:56:26 step 5: objective=0.05755673
2017/08/26 17:56:31 step 6: objective=0.057583727
2017/08/26 17:56:36 step 7: objective=0.05761913
2017/08/26 17:56:36 Training value function...
2017/08/26 17:56:37 step 0: mse=1.228376 step=0.100000
2017/08/26 17:56:38 step 1: mse=1.171591 step=0.100000
2017/08/26 17:56:38 step 2: mse=1.125598 step=0.100000
2017/08/26 17:56:39 step 3: mse=1.085923 step=0.100000
2017/08/26 17:56:40 step 4: mse=1.053546 step=0.100000
2017/08/26 17:56:41 step 5: mse=1.015010 step=0.100000
2017/08/26 17:56:41 step 6: mse=0.976151 step=0.100000
2017/08/26 17:56:42 step 7: mse=0.952046 step=0.100000
2017/08/26 17:56:42 Saving...
2017/08/26 17:56:42 Gathering batch of experience...
2017/08/26 17:57:02 batch 473: mean=18.952381 stddev=8.243186 entropy=1.035402 frames=37979 count=42
2017/08/26 17:57:02 Training policy...
2017/08/26 17:57:09 step 0: objective=0.05210589
2017/08/26 17:57:14 step 1: objective=0.052172873
2017/08/26 17:57:20 step 2: objective=0.05224118
2017/08/26 17:57:25 step 3: objective=0.052300572
2017/08/26 17:57:30 step 4: objective=0.05234337
2017/08/26 17:57:35 step 5: objective=0.052397825
2017/08/26 17:57:40 step 6: objective=0.052446086
2017/08/26 17:57:45 step 7: objective=0.052549396
2017/08/26 17:57:45 Training value function...
2017/08/26 17:57:47 step 0: mse=1.119169 step=0.100000
2017/08/26 17:57:47 step 1: mse=1.059068 step=0.100000
2017/08/26 17:57:48 step 2: mse=1.012567 step=0.100000
2017/08/26 17:57:49 step 3: mse=0.969460 step=0.100000
2017/08/26 17:57:50 step 4: mse=0.940077 step=0.100000
2017/08/26 17:57:50 step 5: mse=0.905133 step=0.100000
2017/08/26 17:57:51 step 6: mse=0.875530 step=0.100000
2017/08/26 17:57:52 step 7: mse=0.856202 step=0.100000
2017/08/26 17:57:52 Saving...
2017/08/26 17:57:52 Gathering batch of experience...
2017/08/26 17:58:11 batch 474: mean=16.288889 stddev=8.528702 entropy=1.059836 frames=35981 count=45
2017/08/26 17:58:11 Training policy...
2017/08/26 17:58:18 step 0: objective=0.03127839
2017/08/26 17:58:22 step 1: objective=0.031320192
2017/08/26 17:58:27 step 2: objective=0.03136187
2017/08/26 17:58:32 step 3: objective=0.031403083
2017/08/26 17:58:37 step 4: objective=0.031444274
2017/08/26 17:58:42 step 5: objective=0.031481724
2017/08/26 17:58:47 step 6: objective=0.03151402
2017/08/26 17:58:52 step 7: objective=0.0315978
2017/08/26 17:58:52 Training value function...
2017/08/26 17:58:53 step 0: mse=1.195195 step=0.100000
2017/08/26 17:58:54 step 1: mse=1.107640 step=0.100000
2017/08/26 17:58:54 step 2: mse=1.037207 step=0.100000
2017/08/26 17:58:55 step 3: mse=0.976317 step=0.100000
2017/08/26 17:58:56 step 4: mse=0.927253 step=0.100000
2017/08/26 17:58:57 step 5: mse=0.888703 step=0.100000
2017/08/26 17:58:57 step 6: mse=0.858367 step=0.100000
2017/08/26 17:58:58 step 7: mse=0.820497 step=0.100000
2017/08/26 17:58:58 Saving...
2017/08/26 17:58:58 Gathering batch of experience...
2017/08/26 17:59:18 batch 475: mean=17.809524 stddev=7.081963 entropy=1.034818 frames=36734 count=42
2017/08/26 17:59:18 Training policy...
2017/08/26 17:59:25 step 0: objective=0.026068024
2017/08/26 17:59:30 step 1: objective=0.02614201
2017/08/26 17:59:35 step 2: objective=0.026215991
2017/08/26 17:59:40 step 3: objective=0.02628987
2017/08/26 17:59:45 step 4: objective=0.026360322
2017/08/26 17:59:50 step 5: objective=0.026424728
2017/08/26 17:59:55 step 6: objective=0.02647874
2017/08/26 18:00:00 step 7: objective=0.026542384
2017/08/26 18:00:00 Training value function...
2017/08/26 18:00:01 step 0: mse=1.088782 step=0.100000
2017/08/26 18:00:02 step 1: mse=1.040661 step=0.100000
2017/08/26 18:00:02 step 2: mse=1.000428 step=0.100000
2017/08/26 18:00:03 step 3: mse=0.967287 step=0.100000
2017/08/26 18:00:04 step 4: mse=0.935172 step=0.100000
2017/08/26 18:00:05 step 5: mse=0.911368 step=0.100000
2017/08/26 18:00:06 step 6: mse=0.879920 step=0.100000
2017/08/26 18:00:06 step 7: mse=0.852766 step=0.100000
2017/08/26 18:00:06 Saving...
2017/08/26 18:00:06 Gathering batch of experience...
2017/08/26 18:00:26 batch 476: mean=16.674419 stddev=6.753882 entropy=1.048579 frames=36058 count=43
2017/08/26 18:00:26 Training policy...
2017/08/26 18:00:32 step 0: objective=0.03085893
2017/08/26 18:00:37 step 1: objective=0.030913161
2017/08/26 18:00:42 step 2: objective=0.030967293
2017/08/26 18:00:47 step 3: objective=0.03102124
2017/08/26 18:00:52 step 4: objective=0.031072054
2017/08/26 18:00:57 step 5: objective=0.031137493
2017/08/26 18:01:02 step 6: objective=0.031212145
2017/08/26 18:01:07 step 7: objective=0.031274945
2017/08/26 18:01:07 Training value function...
2017/08/26 18:01:08 step 0: mse=1.140421 step=0.100000
2017/08/26 18:01:09 step 1: mse=1.061238 step=0.100000
2017/08/26 18:01:10 step 2: mse=0.995865 step=0.100000
2017/08/26 18:01:10 step 3: mse=0.943278 step=0.100000
2017/08/26 18:01:11 step 4: mse=0.894431 step=0.100000
2017/08/26 18:01:12 step 5: mse=0.853369 step=0.100000
2017/08/26 18:01:13 step 6: mse=0.817490 step=0.100000
2017/08/26 18:01:13 step 7: mse=0.789913 step=0.100000
2017/08/26 18:01:13 Saving...
2017/08/26 18:01:13 Gathering batch of experience...
2017/08/26 18:01:33 batch 477: mean=17.512195 stddev=6.282465 entropy=1.034306 frames=36713 count=41
2017/08/26 18:01:33 Training policy...
2017/08/26 18:01:40 step 0: objective=0.016533624
2017/08/26 18:01:45 step 1: objective=0.016603846
2017/08/26 18:01:50 step 2: objective=0.016674018
2017/08/26 18:01:55 step 3: objective=0.016742526
2017/08/26 18:02:00 step 4: objective=0.01679167
2017/08/26 18:02:05 step 5: objective=0.016844701
2017/08/26 18:02:10 step 6: objective=0.016914953
2017/08/26 18:02:15 step 7: objective=0.016968228
2017/08/26 18:02:15 Training value function...
2017/08/26 18:02:16 step 0: mse=0.718422 step=0.100000
2017/08/26 18:02:17 step 1: mse=0.693513 step=0.100000
2017/08/26 18:02:18 step 2: mse=0.669729 step=0.100000
2017/08/26 18:02:19 step 3: mse=0.654123 step=0.100000
2017/08/26 18:02:19 step 4: mse=0.641026 step=0.100000
2017/08/26 18:02:20 step 5: mse=0.627683 step=0.100000
2017/08/26 18:02:21 step 6: mse=0.608980 step=0.100000
2017/08/26 18:02:22 step 7: mse=0.600203 step=0.100000
2017/08/26 18:02:22 Saving...
2017/08/26 18:02:22 Gathering batch of experience...
2017/08/26 18:02:41 batch 478: mean=15.627907 stddev=5.941667 entropy=1.050481 frames=35689 count=43
2017/08/26 18:02:41 Training policy...
2017/08/26 18:02:47 step 0: objective=0.015086008
2017/08/26 18:02:52 step 1: objective=0.015118228
2017/08/26 18:02:57 step 2: objective=0.015146075
2017/08/26 18:03:02 step 3: objective=0.01517408
2017/08/26 18:03:07 step 4: objective=0.015202095
2017/08/26 18:03:12 step 5: objective=0.015229923
2017/08/26 18:03:16 step 6: objective=0.015253975
2017/08/26 18:03:21 step 7: objective=0.015312984
2017/08/26 18:03:21 Training value function...
2017/08/26 18:03:23 step 0: mse=0.637996 step=0.100000
2017/08/26 18:03:23 step 1: mse=0.604696 step=0.100000
2017/08/26 18:03:24 step 2: mse=0.580158 step=0.100000
2017/08/26 18:03:25 step 3: mse=0.557551 step=0.100000
2017/08/26 18:03:26 step 4: mse=0.539740 step=0.100000
2017/08/26 18:03:26 step 5: mse=0.521399 step=0.100000
2017/08/26 18:03:27 step 6: mse=0.508590 step=0.100000
2017/08/26 18:03:28 step 7: mse=0.495162 step=0.100000
2017/08/26 18:03:28 Saving...
2017/08/26 18:03:28 Gathering batch of experience...
2017/08/26 18:03:48 batch 479: mean=18.642857 stddev=7.809705 entropy=1.044882 frames=36949 count=42
2017/08/26 18:03:48 Training policy...
2017/08/26 18:03:55 step 0: objective=0.05315491
2017/08/26 18:04:00 step 1: objective=0.053205237
2017/08/26 18:04:05 step 2: objective=0.05325614
2017/08/26 18:04:10 step 3: objective=0.053307723
2017/08/26 18:04:15 step 4: objective=0.0533548
2017/08/26 18:04:20 step 5: objective=0.053381607
2017/08/26 18:04:25 step 6: objective=0.053424973
2017/08/26 18:04:30 step 7: objective=0.05348361
2017/08/26 18:04:30 Training value function...
2017/08/26 18:04:31 step 0: mse=1.176917 step=0.100000
2017/08/26 18:04:32 step 1: mse=1.101056 step=0.100000
2017/08/26 18:04:33 step 2: mse=1.038738 step=0.100000
2017/08/26 18:04:34 step 3: mse=0.987975 step=0.100000
2017/08/26 18:04:34 step 4: mse=0.940140 step=0.100000
2017/08/26 18:04:35 step 5: mse=0.899773 step=0.100000
2017/08/26 18:04:36 step 6: mse=0.864950 step=0.100000
2017/08/26 18:04:37 step 7: mse=0.842409 step=0.100000
2017/08/26 18:04:37 Saving...
2017/08/26 18:04:37 Gathering batch of experience...
2017/08/26 18:04:56 batch 480: mean=16.863636 stddev=6.517776 entropy=1.046895 frames=36658 count=44
2017/08/26 18:04:56 Training policy...
2017/08/26 18:05:03 step 0: objective=0.016633036
2017/08/26 18:05:08 step 1: objective=0.01667225
2017/08/26 18:05:13 step 2: objective=0.016711438
2017/08/26 18:05:18 step 3: objective=0.016750565
2017/08/26 18:05:23 step 4: objective=0.016789524
2017/08/26 18:05:28 step 5: objective=0.016853264
2017/08/26 18:05:33 step 6: objective=0.016911665
2017/08/26 18:05:38 step 7: objective=0.01695738
2017/08/26 18:05:38 Training value function...
2017/08/26 18:05:39 step 0: mse=1.006086 step=0.100000
2017/08/26 18:05:40 step 1: mse=0.953265 step=0.100000
2017/08/26 18:05:41 step 2: mse=0.911069 step=0.100000
2017/08/26 18:05:42 step 3: mse=0.876793 step=0.100000
2017/08/26 18:05:42 step 4: mse=0.848490 step=0.100000
2017/08/26 18:05:43 step 5: mse=0.825278 step=0.100000
2017/08/26 18:05:44 step 6: mse=0.806493 step=0.100000
2017/08/26 18:05:45 step 7: mse=0.764546 step=0.100000
2017/08/26 18:05:45 Saving...
2017/08/26 18:05:45 Gathering batch of experience...
2017/08/26 18:06:04 batch 481: mean=17.190476 stddev=7.762051 entropy=1.046102 frames=36202 count=42
2017/08/26 18:06:04 Training policy...
2017/08/26 18:06:11 step 0: objective=0.028318202
2017/08/26 18:06:16 step 1: objective=0.028369866
2017/08/26 18:06:21 step 2: objective=0.028421048
2017/08/26 18:06:26 step 3: objective=0.028471867
2017/08/26 18:06:31 step 4: objective=0.028516471
2017/08/26 18:06:36 step 5: objective=0.028554961
2017/08/26 18:06:41 step 6: objective=0.028588884
2017/08/26 18:06:46 step 7: objective=0.028631488
2017/08/26 18:06:46 Training value function...
2017/08/26 18:06:47 step 0: mse=1.054941 step=0.100000
2017/08/26 18:06:48 step 1: mse=0.996128 step=0.100000
2017/08/26 18:06:48 step 2: mse=0.944313 step=0.100000
2017/08/26 18:06:49 step 3: mse=0.903667 step=0.100000
2017/08/26 18:06:50 step 4: mse=0.854520 step=0.100000
2017/08/26 18:06:51 step 5: mse=0.834097 step=0.100000
2017/08/26 18:06:51 step 6: mse=0.799979 step=0.100000
2017/08/26 18:06:52 step 7: mse=0.767366 step=0.100000
2017/08/26 18:06:52 Saving...
2017/08/26 18:06:52 Gathering batch of experience...
2017/08/26 18:07:12 batch 482: mean=17.261905 stddev=5.988320 entropy=1.043183 frames=36613 count=42
2017/08/26 18:07:12 Training policy...
2017/08/26 18:07:18 step 0: objective=0.024566734
2017/08/26 18:07:23 step 1: objective=0.024608608
2017/08/26 18:07:28 step 2: objective=0.024650529
2017/08/26 18:07:33 step 3: objective=0.024692364
2017/08/26 18:07:38 step 4: objective=0.02473425
2017/08/26 18:07:44 step 5: objective=0.02477611
2017/08/26 18:07:49 step 6: objective=0.024816979
2017/08/26 18:07:54 step 7: objective=0.024873763
2017/08/26 18:07:54 Training value function...
2017/08/26 18:07:55 step 0: mse=0.915085 step=0.100000
2017/08/26 18:07:56 step 1: mse=0.871184 step=0.100000
2017/08/26 18:07:56 step 2: mse=0.838978 step=0.100000
2017/08/26 18:07:57 step 3: mse=0.806961 step=0.100000
2017/08/26 18:07:58 step 4: mse=0.777412 step=0.100000
2017/08/26 18:07:59 step 5: mse=0.753457 step=0.100000
2017/08/26 18:07:59 step 6: mse=0.723212 step=0.100000
2017/08/26 18:08:00 step 7: mse=0.699592 step=0.100000
2017/08/26 18:08:00 Saving...
2017/08/26 18:08:00 Gathering batch of experience...
2017/08/26 18:08:20 batch 483: mean=18.476190 stddev=8.770182 entropy=1.040899 frames=37537 count=42
2017/08/26 18:08:20 Training policy...
2017/08/26 18:08:27 step 0: objective=0.064625606
2017/08/26 18:08:32 step 1: objective=0.064664975
2017/08/26 18:08:37 step 2: objective=0.06470438
2017/08/26 18:08:43 step 3: objective=0.06474424
2017/08/26 18:08:48 step 4: objective=0.064783394
2017/08/26 18:08:53 step 5: objective=0.06481715
2017/08/26 18:08:58 step 6: objective=0.06484532
2017/08/26 18:09:03 step 7: objective=0.06486853
2017/08/26 18:09:03 Training value function...
2017/08/26 18:09:05 step 0: mse=1.488082 step=0.100000
2017/08/26 18:09:05 step 1: mse=1.344754 step=0.100000
2017/08/26 18:09:06 step 2: mse=1.228712 step=0.100000
2017/08/26 18:09:07 step 3: mse=1.131291 step=0.100000
2017/08/26 18:09:08 step 4: mse=1.052597 step=0.100000
2017/08/26 18:09:09 step 5: mse=0.986021 step=0.100000
2017/08/26 18:09:09 step 6: mse=0.932164 step=0.100000
2017/08/26 18:09:10 step 7: mse=0.886264 step=0.100000
2017/08/26 18:09:10 Saving...
2017/08/26 18:09:10 Gathering batch of experience...
2017/08/26 18:09:30 batch 484: mean=15.217391 stddev=7.491772 entropy=1.052394 frames=36230 count=46
2017/08/26 18:09:30 Training policy...
2017/08/26 18:09:36 step 0: objective=0.023352064
2017/08/26 18:09:41 step 1: objective=0.023385173
2017/08/26 18:09:46 step 2: objective=0.023418115
2017/08/26 18:09:51 step 3: objective=0.023450626
2017/08/26 18:09:56 step 4: objective=0.023483096
2017/08/26 18:10:01 step 5: objective=0.023515254
2017/08/26 18:10:06 step 6: objective=0.023546439
2017/08/26 18:10:11 step 7: objective=0.023570228
2017/08/26 18:10:11 Training value function...
2017/08/26 18:10:12 step 0: mse=0.762209 step=0.100000
2017/08/26 18:10:13 step 1: mse=0.725224 step=0.100000
2017/08/26 18:10:14 step 2: mse=0.698841 step=0.100000
2017/08/26 18:10:15 step 3: mse=0.672348 step=0.100000
2017/08/26 18:10:15 step 4: mse=0.653582 step=0.100000
2017/08/26 18:10:16 step 5: mse=0.634510 step=0.100000
2017/08/26 18:10:17 step 6: mse=0.621378 step=0.100000
2017/08/26 18:10:18 step 7: mse=0.592258 step=0.100000
2017/08/26 18:10:18 Saving...
2017/08/26 18:10:18 Gathering batch of experience...
2017/08/26 18:10:37 batch 485: mean=18.238095 stddev=8.788005 entropy=1.033381 frames=36775 count=42
2017/08/26 18:10:37 Training policy...
2017/08/26 18:10:44 step 0: objective=0.04481032
2017/08/26 18:10:49 step 1: objective=0.044846952
2017/08/26 18:10:54 step 2: objective=0.044883143
2017/08/26 18:10:59 step 3: objective=0.04492007
2017/08/26 18:11:04 step 4: objective=0.044956565
2017/08/26 18:11:09 step 5: objective=0.044987705
2017/08/26 18:11:14 step 6: objective=0.045039672
2017/08/26 18:11:19 step 7: objective=0.0450751
2017/08/26 18:11:19 Training value function...
2017/08/26 18:11:21 step 0: mse=1.415493 step=0.100000
2017/08/26 18:11:21 step 1: mse=1.303313 step=0.100000
2017/08/26 18:11:22 step 2: mse=1.212035 step=0.100000
2017/08/26 18:11:23 step 3: mse=1.133765 step=0.100000
2017/08/26 18:11:24 step 4: mse=1.077475 step=0.100000
2017/08/26 18:11:25 step 5: mse=1.030247 step=0.100000
2017/08/26 18:11:25 step 6: mse=0.990646 step=0.100000
2017/08/26 18:11:26 step 7: mse=0.963083 step=0.100000
2017/08/26 18:11:26 Saving...
2017/08/26 18:11:26 Gathering batch of experience...
2017/08/26 18:11:47 batch 486: mean=20.404762 stddev=8.693346 entropy=1.039085 frames=38194 count=42
2017/08/26 18:11:47 Training policy...
2017/08/26 18:11:54 step 0: objective=0.059259176
2017/08/26 18:11:59 step 1: objective=0.059320897
2017/08/26 18:12:04 step 2: objective=0.05938247
2017/08/26 18:12:09 step 3: objective=0.05944359
2017/08/26 18:12:15 step 4: objective=0.05950418
2017/08/26 18:12:20 step 5: objective=0.05959892
2017/08/26 18:12:25 step 6: objective=0.059694402
2017/08/26 18:12:30 step 7: objective=0.05975518
2017/08/26 18:12:30 Training value function...
2017/08/26 18:12:32 step 0: mse=1.569298 step=0.100000
2017/08/26 18:12:33 step 1: mse=1.468550 step=0.100000
2017/08/26 18:12:33 step 2: mse=1.386114 step=0.100000
2017/08/26 18:12:34 step 3: mse=1.282363 step=0.100000
2017/08/26 18:12:35 step 4: mse=1.198301 step=0.100000
2017/08/26 18:12:36 step 5: mse=1.154620 step=0.100000
2017/08/26 18:12:36 step 6: mse=1.115455 step=0.100000
2017/08/26 18:12:37 step 7: mse=1.065897 step=0.100000
2017/08/26 18:12:37 Saving...
2017/08/26 18:12:37 Gathering batch of experience...
2017/08/26 18:12:57 batch 487: mean=16.930233 stddev=8.339860 entropy=1.048397 frames=36246 count=43
2017/08/26 18:12:57 Training policy...
2017/08/26 18:13:04 step 0: objective=0.003538742
2017/08/26 18:13:09 step 1: objective=0.0035809851
2017/08/26 18:13:14 step 2: objective=0.0036235326
2017/08/26 18:13:19 step 3: objective=0.0036663532
2017/08/26 18:13:24 step 4: objective=0.0037088823
2017/08/26 18:13:29 step 5: objective=0.0037474127
2017/08/26 18:13:34 step 6: objective=0.0037733265
2017/08/26 18:13:39 step 7: objective=0.0038070506
2017/08/26 18:13:39 Training value function...
2017/08/26 18:13:40 step 0: mse=0.993062 step=0.100000
2017/08/26 18:13:41 step 1: mse=0.912018 step=0.100000
2017/08/26 18:13:42 step 2: mse=0.847879 step=0.100000
2017/08/26 18:13:42 step 3: mse=0.796319 step=0.100000
2017/08/26 18:13:43 step 4: mse=0.754944 step=0.100000
2017/08/26 18:13:44 step 5: mse=0.719591 step=0.100000
2017/08/26 18:13:45 step 6: mse=0.689874 step=0.100000
2017/08/26 18:13:45 step 7: mse=0.663640 step=0.100000
2017/08/26 18:13:45 Saving...
2017/08/26 18:13:45 Gathering batch of experience...
2017/08/26 18:14:05 batch 488: mean=16.720930 stddev=7.022640 entropy=1.044337 frames=36799 count=43
2017/08/26 18:14:05 Training policy...
2017/08/26 18:14:12 step 0: objective=0.020824116
2017/08/26 18:14:17 step 1: objective=0.020847617
2017/08/26 18:14:22 step 2: objective=0.02087116
2017/08/26 18:14:27 step 3: objective=0.020894973
2017/08/26 18:14:32 step 4: objective=0.020918652
2017/08/26 18:14:37 step 5: objective=0.020942494
2017/08/26 18:14:43 step 6: objective=0.020966556
2017/08/26 18:14:48 step 7: objective=0.020989276
2017/08/26 18:14:48 Training value function...
2017/08/26 18:14:49 step 0: mse=0.914751 step=0.100000
2017/08/26 18:14:50 step 1: mse=0.870193 step=0.100000
2017/08/26 18:14:50 step 2: mse=0.831477 step=0.100000
2017/08/26 18:14:51 step 3: mse=0.798965 step=0.100000
2017/08/26 18:14:52 step 4: mse=0.771512 step=0.100000
2017/08/26 18:14:53 step 5: mse=0.747887 step=0.100000
2017/08/26 18:14:53 step 6: mse=0.727918 step=0.100000
2017/08/26 18:14:54 step 7: mse=0.710590 step=0.100000
2017/08/26 18:14:54 Saving...
2017/08/26 18:14:54 Gathering batch of experience...
2017/08/26 18:15:13 batch 489: mean=18.365854 stddev=8.354219 entropy=1.039430 frames=35754 count=41
2017/08/26 18:15:13 Training policy...
2017/08/26 18:15:20 step 0: objective=0.042312305
2017/08/26 18:15:25 step 1: objective=0.042378433
2017/08/26 18:15:30 step 2: objective=0.04244482
2017/08/26 18:15:35 step 3: objective=0.04251131
2017/08/26 18:15:40 step 4: objective=0.04257321
2017/08/26 18:15:45 step 5: objective=0.04262569
2017/08/26 18:15:49 step 6: objective=0.04268347
2017/08/26 18:15:54 step 7: objective=0.042728286
2017/08/26 18:15:54 Training value function...
2017/08/26 18:15:56 step 0: mse=1.312800 step=0.100000
2017/08/26 18:15:56 step 1: mse=1.212423 step=0.100000
2017/08/26 18:15:57 step 2: mse=1.121506 step=0.100000
2017/08/26 18:15:58 step 3: mse=1.048461 step=0.100000
2017/08/26 18:15:59 step 4: mse=0.988688 step=0.100000
2017/08/26 18:15:59 step 5: mse=0.938406 step=0.100000
2017/08/26 18:16:00 step 6: mse=0.897412 step=0.100000
2017/08/26 18:16:01 step 7: mse=0.863807 step=0.100000
2017/08/26 18:16:01 Saving...
2017/08/26 18:16:01 Gathering batch of experience...
2017/08/26 18:16:20 batch 490: mean=16.813953 stddev=6.655146 entropy=1.043132 frames=36271 count=43
2017/08/26 18:16:20 Training policy...
2017/08/26 18:16:27 step 0: objective=0.01950421
2017/08/26 18:16:32 step 1: objective=0.019600831
2017/08/26 18:16:37 step 2: objective=0.019698765
2017/08/26 18:16:42 step 3: objective=0.019791668
2017/08/26 18:16:47 step 4: objective=0.019833948
2017/08/26 18:16:52 step 5: objective=0.01987879
2017/08/26 18:16:57 step 6: objective=0.01990505
2017/08/26 18:17:02 step 7: objective=0.019930976
2017/08/26 18:17:02 Training value function...
2017/08/26 18:17:03 step 0: mse=1.154732 step=0.100000
2017/08/26 18:17:04 step 1: mse=1.080402 step=0.100000
2017/08/26 18:17:05 step 2: mse=1.020814 step=0.100000
2017/08/26 18:17:05 step 3: mse=0.974729 step=0.100000
2017/08/26 18:17:06 step 4: mse=0.938104 step=0.100000
2017/08/26 18:17:07 step 5: mse=0.909178 step=0.100000
2017/08/26 18:17:08 step 6: mse=0.882575 step=0.100000
2017/08/26 18:17:08 step 7: mse=0.862688 step=0.100000
2017/08/26 18:17:08 Saving...
2017/08/26 18:17:09 Gathering batch of experience...
2017/08/26 18:17:29 batch 491: mean=19.047619 stddev=7.091082 entropy=1.037091 frames=37530 count=42
2017/08/26 18:17:29 Training policy...
2017/08/26 18:17:36 step 0: objective=0.04449638
2017/08/26 18:17:41 step 1: objective=0.04454576
2017/08/26 18:17:46 step 2: objective=0.04459618
2017/08/26 18:17:51 step 3: objective=0.04464648
2017/08/26 18:17:57 step 4: objective=0.04472101
2017/08/26 18:18:02 step 5: objective=0.044816967
2017/08/26 18:18:07 step 6: objective=0.044897407
2017/08/26 18:18:12 step 7: objective=0.04497744
2017/08/26 18:18:12 Training value function...
2017/08/26 18:18:13 step 0: mse=1.140967 step=0.100000
2017/08/26 18:18:14 step 1: mse=1.098922 step=0.100000
2017/08/26 18:18:15 step 2: mse=1.056055 step=0.100000
2017/08/26 18:18:16 step 3: mse=0.999260 step=0.100000
2017/08/26 18:18:17 step 4: mse=0.965063 step=0.100000
2017/08/26 18:18:17 step 5: mse=0.922070 step=0.100000
2017/08/26 18:18:18 step 6: mse=0.897460 step=0.100000
2017/08/26 18:18:19 step 7: mse=0.869104 step=0.100000
2017/08/26 18:18:19 Saving...
2017/08/26 18:18:19 Gathering batch of experience...
2017/08/26 18:18:39 batch 492: mean=17.813953 stddev=7.140633 entropy=1.047599 frames=36877 count=43
2017/08/26 18:18:39 Training policy...
2017/08/26 18:18:46 step 0: objective=0.022846248
2017/08/26 18:18:51 step 1: objective=0.022890298
2017/08/26 18:18:56 step 2: objective=0.022934446
2017/08/26 18:19:01 step 3: objective=0.022978637
2017/08/26 18:19:06 step 4: objective=0.023022639
2017/08/26 18:19:11 step 5: objective=0.02305929
2017/08/26 18:19:17 step 6: objective=0.023119781
2017/08/26 18:19:22 step 7: objective=0.02316096
2017/08/26 18:19:22 Training value function...
2017/08/26 18:19:23 step 0: mse=1.198540 step=0.100000
2017/08/26 18:19:24 step 1: mse=1.097640 step=0.100000
2017/08/26 18:19:24 step 2: mse=1.012016 step=0.100000
2017/08/26 18:19:25 step 3: mse=0.943801 step=0.100000
2017/08/26 18:19:26 step 4: mse=0.894243 step=0.100000
2017/08/26 18:19:27 step 5: mse=0.833406 step=0.100000
2017/08/26 18:19:27 step 6: mse=0.785319 step=0.100000
2017/08/26 18:19:28 step 7: mse=0.750810 step=0.100000
2017/08/26 18:19:28 Saving...
2017/08/26 18:19:28 Gathering batch of experience...
2017/08/26 18:19:49 batch 493: mean=18.186047 stddev=8.156196 entropy=1.041620 frames=37273 count=43
2017/08/26 18:19:49 Training policy...
2017/08/26 18:19:56 step 0: objective=0.009385151
2017/08/26 18:20:01 step 1: objective=0.009449921
2017/08/26 18:20:06 step 2: objective=0.009514255
2017/08/26 18:20:11 step 3: objective=0.009577937
2017/08/26 18:20:16 step 4: objective=0.009634438
2017/08/26 18:20:22 step 5: objective=0.009702893
2017/08/26 18:20:27 step 6: objective=0.009788895
2017/08/26 18:20:32 step 7: objective=0.009903728
2017/08/26 18:20:32 Training value function...
2017/08/26 18:20:33 step 0: mse=1.646524 step=0.100000
2017/08/26 18:20:34 step 1: mse=1.503628 step=0.100000
2017/08/26 18:20:35 step 2: mse=1.390086 step=0.100000
2017/08/26 18:20:36 step 3: mse=1.300372 step=0.100000
2017/08/26 18:20:36 step 4: mse=1.222272 step=0.100000
2017/08/26 18:20:37 step 5: mse=1.156356 step=0.100000
2017/08/26 18:20:38 step 6: mse=1.095340 step=0.100000
2017/08/26 18:20:39 step 7: mse=1.038435 step=0.100000
2017/08/26 18:20:39 Saving...
2017/08/26 18:20:39 Gathering batch of experience...
2017/08/26 18:20:59 batch 494: mean=17.000000 stddev=5.485518 entropy=1.055068 frames=37160 count=44
2017/08/26 18:20:59 Training policy...
2017/08/26 18:21:05 step 0: objective=0.023001894
2017/08/26 18:21:11 step 1: objective=0.023057844
2017/08/26 18:21:16 step 2: objective=0.023113653
2017/08/26 18:21:21 step 3: objective=0.02316974
2017/08/26 18:21:26 step 4: objective=0.023225868
2017/08/26 18:21:32 step 5: objective=0.023278426
2017/08/26 18:21:37 step 6: objective=0.023333116
2017/08/26 18:21:42 step 7: objective=0.02336077
2017/08/26 18:21:42 Training value function...
2017/08/26 18:21:43 step 0: mse=0.898329 step=0.100000
2017/08/26 18:21:44 step 1: mse=0.833970 step=0.100000
2017/08/26 18:21:45 step 2: mse=0.782267 step=0.100000
2017/08/26 18:21:45 step 3: mse=0.740120 step=0.100000
2017/08/26 18:21:46 step 4: mse=0.705400 step=0.100000
2017/08/26 18:21:47 step 5: mse=0.681274 step=0.100000
2017/08/26 18:21:48 step 6: mse=0.660453 step=0.100000
2017/08/26 18:21:48 step 7: mse=0.635256 step=0.100000
2017/08/26 18:21:48 Saving...
2017/08/26 18:21:49 Gathering batch of experience...
2017/08/26 18:22:09 batch 495: mean=17.086957 stddev=9.622948 entropy=1.043684 frames=37301 count=46
2017/08/26 18:22:09 Training policy...
2017/08/26 18:22:16 step 0: objective=0.04580079
2017/08/26 18:22:21 step 1: objective=0.04587192
2017/08/26 18:22:26 step 2: objective=0.04594345
2017/08/26 18:22:31 step 3: objective=0.04601537
2017/08/26 18:22:37 step 4: objective=0.0460849
2017/08/26 18:22:42 step 5: objective=0.04616699
2017/08/26 18:22:47 step 6: objective=0.04622418
2017/08/26 18:22:52 step 7: objective=0.0462565
2017/08/26 18:22:52 Training value function...
2017/08/26 18:22:54 step 0: mse=1.711671 step=0.100000
2017/08/26 18:22:54 step 1: mse=1.568727 step=0.100000
2017/08/26 18:22:55 step 2: mse=1.458401 step=0.100000
2017/08/26 18:22:56 step 3: mse=1.368974 step=0.100000
2017/08/26 18:22:57 step 4: mse=1.285342 step=0.100000
2017/08/26 18:22:58 step 5: mse=1.217006 step=0.100000
2017/08/26 18:22:58 step 6: mse=1.156227 step=0.100000
2017/08/26 18:22:59 step 7: mse=1.106116 step=0.100000
2017/08/26 18:22:59 Saving...
2017/08/26 18:22:59 Gathering batch of experience...
2017/08/26 18:23:19 batch 496: mean=17.272727 stddev=9.046254 entropy=1.053076 frames=36522 count=44
2017/08/26 18:23:19 Training policy...
2017/08/26 18:23:25 step 0: objective=0.031979747
2017/08/26 18:23:31 step 1: objective=0.032045458
2017/08/26 18:23:36 step 2: objective=0.032111734
2017/08/26 18:23:41 step 3: objective=0.03217793
2017/08/26 18:23:46 step 4: objective=0.032243893
2017/08/26 18:23:51 step 5: objective=0.032300573
2017/08/26 18:23:56 step 6: objective=0.032374308
2017/08/26 18:24:01 step 7: objective=0.032467116
2017/08/26 18:24:01 Training value function...
2017/08/26 18:24:02 step 0: mse=1.561776 step=0.100000
2017/08/26 18:24:03 step 1: mse=1.431731 step=0.100000
2017/08/26 18:24:04 step 2: mse=1.323909 step=0.100000
2017/08/26 18:24:05 step 3: mse=1.228195 step=0.100000
2017/08/26 18:24:06 step 4: mse=1.151178 step=0.100000
2017/08/26 18:24:06 step 5: mse=1.089160 step=0.100000
2017/08/26 18:24:07 step 6: mse=1.038597 step=0.100000
2017/08/26 18:24:08 step 7: mse=0.996878 step=0.100000
2017/08/26 18:24:08 Saving...
2017/08/26 18:24:08 Gathering batch of experience...
2017/08/26 18:24:29 batch 497: mean=19.829268 stddev=7.929268 entropy=1.033878 frames=38423 count=41
2017/08/26 18:24:29 Training policy...
2017/08/26 18:24:36 step 0: objective=0.040337235
2017/08/26 18:24:41 step 1: objective=0.040394124
2017/08/26 18:24:46 step 2: objective=0.040450323
2017/08/26 18:24:52 step 3: objective=0.040505853
2017/08/26 18:24:57 step 4: objective=0.040601894
2017/08/26 18:25:03 step 5: objective=0.04070222
2017/08/26 18:25:08 step 6: objective=0.040795144
2017/08/26 18:25:13 step 7: objective=0.040874287
2017/08/26 18:25:13 Training value function...
2017/08/26 18:25:15 step 0: mse=1.407713 step=0.100000
2017/08/26 18:25:15 step 1: mse=1.292847 step=0.100000
2017/08/26 18:25:16 step 2: mse=1.199542 step=0.100000
2017/08/26 18:25:17 step 3: mse=1.124139 step=0.100000
2017/08/26 18:25:18 step 4: mse=1.058973 step=0.100000
2017/08/26 18:25:19 step 5: mse=1.005433 step=0.100000
2017/08/26 18:25:19 step 6: mse=0.958752 step=0.100000
2017/08/26 18:25:20 step 7: mse=0.917371 step=0.100000
2017/08/26 18:25:20 Saving...
2017/08/26 18:25:20 Gathering batch of experience...
2017/08/26 18:25:41 batch 498: mean=17.177778 stddev=9.175545 entropy=1.042482 frames=37360 count=45
2017/08/26 18:25:41 Training policy...
2017/08/26 18:25:48 step 0: objective=0.027285496
2017/08/26 18:25:53 step 1: objective=0.027340848
2017/08/26 18:25:58 step 2: objective=0.02739639
2017/08/26 18:26:03 step 3: objective=0.02745227
2017/08/26 18:26:09 step 4: objective=0.027507884
2017/08/26 18:26:14 step 5: objective=0.027599715
2017/08/26 18:26:19 step 6: objective=0.027687294
2017/08/26 18:26:24 step 7: objective=0.027756345
2017/08/26 18:26:24 Training value function...
2017/08/26 18:26:26 step 0: mse=2.123912 step=0.100000
2017/08/26 18:26:26 step 1: mse=1.901282 step=0.100000
2017/08/26 18:26:27 step 2: mse=1.722656 step=0.100000
2017/08/26 18:26:28 step 3: mse=1.579104 step=0.100000
2017/08/26 18:26:29 step 4: mse=1.458599 step=0.100000
2017/08/26 18:26:30 step 5: mse=1.351601 step=0.100000
2017/08/26 18:26:30 step 6: mse=1.268725 step=0.100000
2017/08/26 18:26:31 step 7: mse=1.199237 step=0.100000
2017/08/26 18:26:31 Saving...
2017/08/26 18:26:31 Gathering batch of experience...
2017/08/26 18:26:51 batch 499: mean=16.681818 stddev=6.642743 entropy=1.044004 frames=36712 count=44
2017/08/26 18:26:51 Training policy...
2017/08/26 18:26:58 step 0: objective=0.024328053
2017/08/26 18:27:03 step 1: objective=0.024440618
2017/08/26 18:27:08 step 2: objective=0.024553187
2017/08/26 18:27:13 step 3: objective=0.024659183
2017/08/26 18:27:19 step 4: objective=0.024750384
2017/08/26 18:27:24 step 5: objective=0.024807673
2017/08/26 18:27:29 step 6: objective=0.024854854
2017/08/26 18:27:34 step 7: objective=0.024895567
2017/08/26 18:27:34 Training value function...
2017/08/26 18:27:35 step 0: mse=1.198939 step=0.100000
2017/08/26 18:27:36 step 1: mse=1.127947 step=0.100000
2017/08/26 18:27:37 step 2: mse=1.071066 step=0.100000
2017/08/26 18:27:38 step 3: mse=1.025446 step=0.100000
2017/08/26 18:27:38 step 4: mse=0.985537 step=0.100000
2017/08/26 18:27:39 step 5: mse=0.951531 step=0.100000
2017/08/26 18:27:40 step 6: mse=0.918753 step=0.100000
2017/08/26 18:27:41 step 7: mse=0.886053 step=0.100000
2017/08/26 18:27:41 Saving...
2017/08/26 18:27:41 Gathering batch of experience...
2017/08/26 18:28:00 batch 500: mean=16.674419 stddev=6.853011 entropy=1.057115 frames=35613 count=43
2017/08/26 18:28:00 Training policy...
2017/08/26 18:28:07 step 0: objective=0.027193747
2017/08/26 18:28:12 step 1: objective=0.027247934
2017/08/26 18:28:17 step 2: objective=0.027302437
2017/08/26 18:28:22 step 3: objective=0.027357414
2017/08/26 18:28:27 step 4: objective=0.027413081
2017/08/26 18:28:32 step 5: objective=0.027464136
2017/08/26 18:28:37 step 6: objective=0.027532963
2017/08/26 18:28:42 step 7: objective=0.02757797
2017/08/26 18:28:42 Training value function...
2017/08/26 18:28:43 step 0: mse=1.254566 step=0.100000
2017/08/26 18:28:44 step 1: mse=1.143603 step=0.100000
2017/08/26 18:28:45 step 2: mse=1.054504 step=0.100000
2017/08/26 18:28:45 step 3: mse=0.982665 step=0.100000
2017/08/26 18:28:46 step 4: mse=0.924426 step=0.100000
2017/08/26 18:28:47 step 5: mse=0.875225 step=0.100000
2017/08/26 18:28:48 step 6: mse=0.836506 step=0.100000
2017/08/26 18:28:48 step 7: mse=0.804247 step=0.100000
2017/08/26 18:28:48 Saving...
2017/08/26 18:28:49 Gathering batch of experience...
2017/08/26 18:29:09 batch 501: mean=16.456522 stddev=6.794200 entropy=1.044215 frames=37102 count=46
2017/08/26 18:29:09 Training policy...
2017/08/26 18:29:15 step 0: objective=0.029217435
2017/08/26 18:29:21 step 1: objective=0.029247705
2017/08/26 18:29:26 step 2: objective=0.029277937
2017/08/26 18:29:31 step 3: objective=0.02930865
2017/08/26 18:29:36 step 4: objective=0.029339265
2017/08/26 18:29:42 step 5: objective=0.029370029
2017/08/26 18:29:47 step 6: objective=0.029397042
2017/08/26 18:29:52 step 7: objective=0.02945389
2017/08/26 18:29:52 Training value function...
2017/08/26 18:29:53 step 0: mse=0.935453 step=0.100000
2017/08/26 18:29:54 step 1: mse=0.907481 step=0.100000
2017/08/26 18:29:55 step 2: mse=0.884339 step=0.100000
2017/08/26 18:29:56 step 3: mse=0.863668 step=0.100000
2017/08/26 18:29:56 step 4: mse=0.836571 step=0.100000
2017/08/26 18:29:57 step 5: mse=0.811701 step=0.100000
2017/08/26 18:29:58 step 6: mse=0.795351 step=0.100000
2017/08/26 18:29:59 step 7: mse=0.769291 step=0.100000
2017/08/26 18:29:59 Saving...
2017/08/26 18:29:59 Gathering batch of experience...
2017/08/26 18:30:19 batch 502: mean=18.214286 stddev=5.986237 entropy=1.037759 frames=36700 count=42
2017/08/26 18:30:19 Training policy...
2017/08/26 18:30:25 step 0: objective=0.033841014
2017/08/26 18:30:31 step 1: objective=0.03390047
2017/08/26 18:30:36 step 2: objective=0.033960167
2017/08/26 18:30:41 step 3: objective=0.03401912
2017/08/26 18:30:46 step 4: objective=0.034075327
2017/08/26 18:30:51 step 5: objective=0.03412601
2017/08/26 18:30:57 step 6: objective=0.034200225
2017/08/26 18:31:02 step 7: objective=0.03429113
2017/08/26 18:31:02 Training value function...
2017/08/26 18:31:03 step 0: mse=0.963807 step=0.100000
2017/08/26 18:31:04 step 1: mse=0.920542 step=0.100000
2017/08/26 18:31:04 step 2: mse=0.885588 step=0.100000
2017/08/26 18:31:05 step 3: mse=0.856908 step=0.100000
2017/08/26 18:31:06 step 4: mse=0.832840 step=0.100000
2017/08/26 18:31:07 step 5: mse=0.806172 step=0.100000
2017/08/26 18:31:08 step 6: mse=0.787554 step=0.100000
2017/08/26 18:31:08 step 7: mse=0.759095 step=0.100000
2017/08/26 18:31:08 Saving...
2017/08/26 18:31:08 Gathering batch of experience...
2017/08/26 18:31:29 batch 503: mean=16.688889 stddev=8.961206 entropy=1.046879 frames=37855 count=45
2017/08/26 18:31:29 Training policy...
2017/08/26 18:31:36 step 0: objective=0.01818625
2017/08/26 18:31:41 step 1: objective=0.018249728
2017/08/26 18:31:47 step 2: objective=0.018313222
2017/08/26 18:31:52 step 3: objective=0.018376524
2017/08/26 18:31:58 step 4: objective=0.018432958
2017/08/26 18:32:03 step 5: objective=0.01845744
2017/08/26 18:32:08 step 6: objective=0.018493231
2017/08/26 18:32:14 step 7: objective=0.018529106
2017/08/26 18:32:14 Training value function...
2017/08/26 18:32:15 step 0: mse=1.355336 step=0.100000
2017/08/26 18:32:16 step 1: mse=1.224502 step=0.100000
2017/08/26 18:32:17 step 2: mse=1.119674 step=0.100000
2017/08/26 18:32:17 step 3: mse=1.034323 step=0.100000
2017/08/26 18:32:18 step 4: mse=0.963459 step=0.100000
2017/08/26 18:32:19 step 5: mse=0.898353 step=0.100000
2017/08/26 18:32:20 step 6: mse=0.851282 step=0.100000
2017/08/26 18:32:21 step 7: mse=0.806931 step=0.100000
2017/08/26 18:32:21 Saving...
2017/08/26 18:32:21 Gathering batch of experience...
2017/08/26 18:32:40 batch 504: mean=16.795455 stddev=8.189737 entropy=1.042876 frames=36220 count=44
2017/08/26 18:32:40 Training policy...
2017/08/26 18:32:47 step 0: objective=0.0173803
2017/08/26 18:32:52 step 1: objective=0.01745346
2017/08/26 18:32:57 step 2: objective=0.017527187
2017/08/26 18:33:03 step 3: objective=0.017601121
2017/08/26 18:33:08 step 4: objective=0.017656162
2017/08/26 18:33:13 step 5: objective=0.017703513
2017/08/26 18:33:18 step 6: objective=0.017746514
2017/08/26 18:33:23 step 7: objective=0.017784197
2017/08/26 18:33:23 Training value function...
2017/08/26 18:33:24 step 0: mse=1.419258 step=0.100000
2017/08/26 18:33:25 step 1: mse=1.319974 step=0.100000
2017/08/26 18:33:26 step 2: mse=1.240250 step=0.100000
2017/08/26 18:33:26 step 3: mse=1.170115 step=0.100000
2017/08/26 18:33:27 step 4: mse=1.116289 step=0.100000
2017/08/26 18:33:28 step 5: mse=1.066048 step=0.100000
2017/08/26 18:33:29 step 6: mse=1.025659 step=0.100000
2017/08/26 18:33:29 step 7: mse=1.001508 step=0.100000
2017/08/26 18:33:29 Saving...
2017/08/26 18:33:30 Gathering batch of experience...
2017/08/26 18:33:49 batch 505: mean=17.619048 stddev=8.085709 entropy=1.043479 frames=36443 count=42
2017/08/26 18:33:49 Training policy...
2017/08/26 18:33:56 step 0: objective=0.04902233
2017/08/26 18:34:01 step 1: objective=0.049087934
2017/08/26 18:34:06 step 2: objective=0.049153104
2017/08/26 18:34:12 step 3: objective=0.049217135
2017/08/26 18:34:17 step 4: objective=0.04929725
2017/08/26 18:34:22 step 5: objective=0.049344096
2017/08/26 18:34:27 step 6: objective=0.049372263
2017/08/26 18:34:32 step 7: objective=0.04940056
2017/08/26 18:34:32 Training value function...
2017/08/26 18:34:33 step 0: mse=1.157851 step=0.100000
2017/08/26 18:34:34 step 1: mse=1.087938 step=0.100000
2017/08/26 18:34:35 step 2: mse=1.031363 step=0.100000
2017/08/26 18:34:36 step 3: mse=0.979247 step=0.100000
2017/08/26 18:34:36 step 4: mse=0.933113 step=0.100000
2017/08/26 18:34:37 step 5: mse=0.896845 step=0.100000
2017/08/26 18:34:38 step 6: mse=0.861175 step=0.100000
2017/08/26 18:34:39 step 7: mse=0.820912 step=0.100000
2017/08/26 18:34:39 Saving...
2017/08/26 18:34:39 Gathering batch of experience...
2017/08/26 18:34:58 batch 506: mean=17.488372 stddev=6.499990 entropy=1.054986 frames=36380 count=43
2017/08/26 18:34:58 Training policy...
2017/08/26 18:35:05 step 0: objective=0.050438304
2017/08/26 18:35:10 step 1: objective=0.050500423
2017/08/26 18:35:15 step 2: objective=0.050562836
2017/08/26 18:35:21 step 3: objective=0.05062555
2017/08/26 18:35:26 step 4: objective=0.050684653
2017/08/26 18:35:31 step 5: objective=0.05074682
2017/08/26 18:35:36 step 6: objective=0.05080618
2017/08/26 18:35:42 step 7: objective=0.050878394
2017/08/26 18:35:42 Training value function...
2017/08/26 18:35:43 step 0: mse=1.057738 step=0.100000
2017/08/26 18:35:43 step 1: mse=0.991333 step=0.100000
2017/08/26 18:35:44 step 2: mse=0.937726 step=0.100000
2017/08/26 18:35:45 step 3: mse=0.875453 step=0.100000
2017/08/26 18:35:46 step 4: mse=0.822615 step=0.100000
2017/08/26 18:35:46 step 5: mse=0.785964 step=0.100000
2017/08/26 18:35:47 step 6: mse=0.750736 step=0.100000
2017/08/26 18:35:48 step 7: mse=0.724251 step=0.100000
2017/08/26 18:35:48 Saving...
2017/08/26 18:35:48 Gathering batch of experience...
2017/08/26 18:36:08 batch 507: mean=18.023256 stddev=8.188160 entropy=1.040000 frames=36788 count=43
2017/08/26 18:36:08 Training policy...
2017/08/26 18:36:15 step 0: objective=0.031294897
2017/08/26 18:36:20 step 1: objective=0.031399116
2017/08/26 18:36:25 step 2: objective=0.0315035
2017/08/26 18:36:30 step 3: objective=0.031607114
2017/08/26 18:36:35 step 4: objective=0.031656247
2017/08/26 18:36:41 step 5: objective=0.031707834
2017/08/26 18:36:46 step 6: objective=0.03176212
2017/08/26 18:36:51 step 7: objective=0.03180687
2017/08/26 18:36:51 Training value function...
2017/08/26 18:36:52 step 0: mse=1.432225 step=0.100000
2017/08/26 18:36:53 step 1: mse=1.326558 step=0.100000
2017/08/26 18:36:54 step 2: mse=1.241885 step=0.100000
2017/08/26 18:36:55 step 3: mse=1.170943 step=0.100000
2017/08/26 18:36:55 step 4: mse=1.108761 step=0.100000
2017/08/26 18:36:56 step 5: mse=1.061367 step=0.100000
2017/08/26 18:36:57 step 6: mse=1.020813 step=0.100000
2017/08/26 18:36:58 step 7: mse=0.983630 step=0.100000
2017/08/26 18:36:58 Saving...
2017/08/26 18:36:58 Gathering batch of experience...
2017/08/26 18:37:18 batch 508: mean=17.069767 stddev=7.387593 entropy=1.041884 frames=36639 count=43
2017/08/26 18:37:18 Training policy...
2017/08/26 18:37:24 step 0: objective=0.01534241
2017/08/26 18:37:30 step 1: objective=0.015392922
2017/08/26 18:37:35 step 2: objective=0.015443229
2017/08/26 18:37:40 step 3: objective=0.015492618
2017/08/26 18:37:45 step 4: objective=0.015536137
2017/08/26 18:37:51 step 5: objective=0.015590442
2017/08/26 18:37:56 step 6: objective=0.015637575
2017/08/26 18:38:01 step 7: objective=0.015701205
2017/08/26 18:38:01 Training value function...
2017/08/26 18:38:02 step 0: mse=0.849501 step=0.100000
2017/08/26 18:38:03 step 1: mse=0.787636 step=0.100000
2017/08/26 18:38:04 step 2: mse=0.737460 step=0.100000
2017/08/26 18:38:04 step 3: mse=0.698652 step=0.100000
2017/08/26 18:38:05 step 4: mse=0.662316 step=0.100000
2017/08/26 18:38:06 step 5: mse=0.631187 step=0.100000
2017/08/26 18:38:07 step 6: mse=0.604441 step=0.100000
2017/08/26 18:38:07 step 7: mse=0.584619 step=0.100000
2017/08/26 18:38:07 Saving...
2017/08/26 18:38:08 Gathering batch of experience...
2017/08/26 18:38:27 batch 509: mean=19.000000 stddev=8.456488 entropy=1.045264 frames=36730 count=41
2017/08/26 18:38:27 Training policy...
2017/08/26 18:38:34 step 0: objective=0.045760553
2017/08/26 18:38:39 step 1: objective=0.04580779
2017/08/26 18:38:45 step 2: objective=0.045854595
2017/08/26 18:38:50 step 3: objective=0.0459008
2017/08/26 18:38:55 step 4: objective=0.04594656
2017/08/26 18:39:00 step 5: objective=0.045992196
2017/08/26 18:39:05 step 6: objective=0.04603543
2017/08/26 18:39:10 step 7: objective=0.046117134
2017/08/26 18:39:10 Training value function...
2017/08/26 18:39:12 step 0: mse=1.391870 step=0.100000
2017/08/26 18:39:12 step 1: mse=1.296313 step=0.100000
2017/08/26 18:39:13 step 2: mse=1.214957 step=0.100000
2017/08/26 18:39:14 step 3: mse=1.148683 step=0.100000
2017/08/26 18:39:15 step 4: mse=1.091584 step=0.100000
2017/08/26 18:39:15 step 5: mse=1.048715 step=0.100000
2017/08/26 18:39:16 step 6: mse=1.006427 step=0.100000
2017/08/26 18:39:17 step 7: mse=0.958741 step=0.100000
2017/08/26 18:39:17 Saving...
2017/08/26 18:39:17 Gathering batch of experience...
2017/08/26 18:39:37 batch 510: mean=16.933333 stddev=7.316344 entropy=1.041664 frames=37498 count=45
2017/08/26 18:39:37 Training policy...
2017/08/26 18:39:44 step 0: objective=0.024977399
2017/08/26 18:39:49 step 1: objective=0.025025325
2017/08/26 18:39:55 step 2: objective=0.025072891
2017/08/26 18:40:00 step 3: objective=0.025120506
2017/08/26 18:40:05 step 4: objective=0.025167782
2017/08/26 18:40:11 step 5: objective=0.02521419
2017/08/26 18:40:16 step 6: objective=0.025271839
2017/08/26 18:40:21 step 7: objective=0.025330449
2017/08/26 18:40:21 Training value function...
2017/08/26 18:40:23 step 0: mse=1.040175 step=0.100000
2017/08/26 18:40:23 step 1: mse=0.991666 step=0.100000
2017/08/26 18:40:24 step 2: mse=0.952797 step=0.100000
2017/08/26 18:40:25 step 3: mse=0.922415 step=0.100000
2017/08/26 18:40:26 step 4: mse=0.898943 step=0.100000
2017/08/26 18:40:27 step 5: mse=0.863306 step=0.100000
2017/08/26 18:40:27 step 6: mse=0.825741 step=0.100000
2017/08/26 18:40:28 step 7: mse=0.806773 step=0.100000
2017/08/26 18:40:28 Saving...
2017/08/26 18:40:28 Gathering batch of experience...
2017/08/26 18:40:48 batch 511: mean=17.534884 stddev=8.622169 entropy=1.043159 frames=36867 count=43
2017/08/26 18:40:48 Training policy...
2017/08/26 18:40:55 step 0: objective=0.018089617
2017/08/26 18:41:00 step 1: objective=0.0181478
2017/08/26 18:41:06 step 2: objective=0.018205997
2017/08/26 18:41:11 step 3: objective=0.018264005
2017/08/26 18:41:16 step 4: objective=0.0183213
2017/08/26 18:41:21 step 5: objective=0.01836717
2017/08/26 18:41:27 step 6: objective=0.018421093
2017/08/26 18:41:32 step 7: objective=0.018486375
2017/08/26 18:41:32 Training value function...
2017/08/26 18:41:33 step 0: mse=1.290383 step=0.100000
2017/08/26 18:41:34 step 1: mse=1.169184 step=0.100000
2017/08/26 18:41:35 step 2: mse=1.067253 step=0.100000
2017/08/26 18:41:35 step 3: mse=0.985166 step=0.100000
2017/08/26 18:41:36 step 4: mse=0.919244 step=0.100000
2017/08/26 18:41:37 step 5: mse=0.864122 step=0.100000
2017/08/26 18:41:38 step 6: mse=0.815992 step=0.100000
2017/08/26 18:41:38 step 7: mse=0.777874 step=0.100000
2017/08/26 18:41:38 Saving...
2017/08/26 18:41:38 Gathering batch of experience...
2017/08/26 18:41:58 batch 512: mean=16.651163 stddev=7.618471 entropy=1.054347 frames=35722 count=43
2017/08/26 18:41:58 Training policy...
2017/08/26 18:42:05 step 0: objective=0.041720565
2017/08/26 18:42:10 step 1: objective=0.04177256
2017/08/26 18:42:15 step 2: objective=0.041824587
2017/08/26 18:42:20 step 3: objective=0.04187646
2017/08/26 18:42:25 step 4: objective=0.04192433
2017/08/26 18:42:30 step 5: objective=0.041971806
2017/08/26 18:42:35 step 6: objective=0.04205365
2017/08/26 18:42:40 step 7: objective=0.04212878
2017/08/26 18:42:40 Training value function...
2017/08/26 18:42:42 step 0: mse=1.635060 step=0.100000
2017/08/26 18:42:42 step 1: mse=1.476062 step=0.100000
2017/08/26 18:42:43 step 2: mse=1.359606 step=0.100000
2017/08/26 18:42:44 step 3: mse=1.258055 step=0.100000
2017/08/26 18:42:45 step 4: mse=1.178564 step=0.100000
2017/08/26 18:42:45 step 5: mse=1.098318 step=0.100000
2017/08/26 18:42:46 step 6: mse=1.030804 step=0.100000
2017/08/26 18:42:47 step 7: mse=0.975460 step=0.100000
2017/08/26 18:42:47 Saving...
2017/08/26 18:42:47 Gathering batch of experience...
2017/08/26 18:43:07 batch 513: mean=18.428571 stddev=11.049979 entropy=1.041092 frames=37195 count=42
2017/08/26 18:43:07 Training policy...
2017/08/26 18:43:14 step 0: objective=0.023927476
2017/08/26 18:43:19 step 1: objective=0.023990698
2017/08/26 18:43:24 step 2: objective=0.024054041
2017/08/26 18:43:30 step 3: objective=0.024117481
2017/08/26 18:43:35 step 4: objective=0.02417895
2017/08/26 18:43:40 step 5: objective=0.024217008
2017/08/26 18:43:46 step 6: objective=0.024257438
2017/08/26 18:43:51 step 7: objective=0.024293307
2017/08/26 18:43:51 Training value function...
2017/08/26 18:43:52 step 0: mse=1.581461 step=0.100000
2017/08/26 18:43:53 step 1: mse=1.423581 step=0.100000
2017/08/26 18:43:54 step 2: mse=1.295640 step=0.100000
2017/08/26 18:43:55 step 3: mse=1.191728 step=0.100000
2017/08/26 18:43:55 step 4: mse=1.106604 step=0.100000
2017/08/26 18:43:56 step 5: mse=1.034365 step=0.100000
2017/08/26 18:43:57 step 6: mse=0.979481 step=0.100000
2017/08/26 18:43:58 step 7: mse=0.938153 step=0.100000
2017/08/26 18:43:58 Saving...
2017/08/26 18:43:58 Gathering batch of experience...
2017/08/26 18:44:18 batch 514: mean=17.295455 stddev=6.166550 entropy=1.046080 frames=37646 count=44
2017/08/26 18:44:18 Training policy...
2017/08/26 18:44:25 step 0: objective=0.027522093
2017/08/26 18:44:31 step 1: objective=0.027627047
2017/08/26 18:44:36 step 2: objective=0.027731674
2017/08/26 18:44:42 step 3: objective=0.027835665
2017/08/26 18:44:47 step 4: objective=0.027894558
2017/08/26 18:44:52 step 5: objective=0.027962014
2017/08/26 18:44:58 step 6: objective=0.028020458
2017/08/26 18:45:03 step 7: objective=0.028076619
2017/08/26 18:45:03 Training value function...
2017/08/26 18:45:05 step 0: mse=1.046451 step=0.100000
2017/08/26 18:45:05 step 1: mse=0.977661 step=0.100000
2017/08/26 18:45:06 step 2: mse=0.915118 step=0.100000
2017/08/26 18:45:07 step 3: mse=0.872311 step=0.100000
2017/08/26 18:45:08 step 4: mse=0.830311 step=0.100000
2017/08/26 18:45:09 step 5: mse=0.791334 step=0.100000
2017/08/26 18:45:09 step 6: mse=0.763897 step=0.100000
2017/08/26 18:45:10 step 7: mse=0.740190 step=0.100000
2017/08/26 18:45:10 Saving...
2017/08/26 18:45:15 Gathering batch of experience...
2017/08/26 18:45:36 batch 515: mean=19.121951 stddev=6.804572 entropy=1.025951 frames=37783 count=41
2017/08/26 18:45:36 Training policy...
2017/08/26 18:45:43 step 0: objective=0.023117227
2017/08/26 18:45:48 step 1: objective=0.023190048
2017/08/26 18:45:54 step 2: objective=0.023262253
2017/08/26 18:45:59 step 3: objective=0.02333293
2017/08/26 18:46:04 step 4: objective=0.023387235
2017/08/26 18:46:10 step 5: objective=0.02347234
2017/08/26 18:46:15 step 6: objective=0.023524689
2017/08/26 18:46:21 step 7: objective=0.023620514
2017/08/26 18:46:21 Training value function...
2017/08/26 18:46:22 step 0: mse=1.131830 step=0.100000
2017/08/26 18:46:23 step 1: mse=1.081405 step=0.100000
2017/08/26 18:46:23 step 2: mse=1.037635 step=0.100000
2017/08/26 18:46:24 step 3: mse=0.987943 step=0.100000
2017/08/26 18:46:25 step 4: mse=0.948925 step=0.100000
2017/08/26 18:46:26 step 5: mse=0.910863 step=0.100000
2017/08/26 18:46:26 step 6: mse=0.888643 step=0.100000
2017/08/26 18:46:27 step 7: mse=0.853965 step=0.100000
2017/08/26 18:46:27 Saving...
2017/08/26 18:46:27 Gathering batch of experience...
2017/08/26 18:46:48 batch 516: mean=19.804878 stddev=7.292561 entropy=1.041920 frames=37663 count=41
2017/08/26 18:46:48 Training policy...
2017/08/26 18:46:55 step 0: objective=0.057326887
2017/08/26 18:47:00 step 1: objective=0.057412736
2017/08/26 18:47:06 step 2: objective=0.057498477
2017/08/26 18:47:11 step 3: objective=0.057584174
2017/08/26 18:47:16 step 4: objective=0.057664257
2017/08/26 18:47:22 step 5: objective=0.05773483
2017/08/26 18:47:27 step 6: objective=0.057817698
2017/08/26 18:47:33 step 7: objective=0.057880405
2017/08/26 18:47:33 Training value function...
2017/08/26 18:47:34 step 0: mse=1.265503 step=0.100000
2017/08/26 18:47:35 step 1: mse=1.182498 step=0.100000
2017/08/26 18:47:35 step 2: mse=1.114385 step=0.100000
2017/08/26 18:47:36 step 3: mse=1.057961 step=0.100000
2017/08/26 18:47:37 step 4: mse=1.009029 step=0.100000
2017/08/26 18:47:38 step 5: mse=0.968977 step=0.100000
2017/08/26 18:47:38 step 6: mse=0.930850 step=0.100000
2017/08/26 18:47:39 step 7: mse=0.903554 step=0.100000
2017/08/26 18:47:39 Saving...
2017/08/26 18:47:39 Gathering batch of experience...
2017/08/26 18:48:00 batch 517: mean=17.975610 stddev=7.588463 entropy=1.038830 frames=37497 count=41
2017/08/26 18:48:00 Training policy...
2017/08/26 18:48:07 step 0: objective=0.005585728
2017/08/26 18:48:12 step 1: objective=0.005661948
2017/08/26 18:48:18 step 2: objective=0.005738873
2017/08/26 18:48:23 step 3: objective=0.0058128154
2017/08/26 18:48:28 step 4: objective=0.005843059
2017/08/26 18:48:34 step 5: objective=0.0058989837
2017/08/26 18:48:39 step 6: objective=0.005925344
2017/08/26 18:48:45 step 7: objective=0.0059687467
2017/08/26 18:48:45 Training value function...
2017/08/26 18:48:46 step 0: mse=1.132324 step=0.100000
2017/08/26 18:48:47 step 1: mse=1.051154 step=0.100000
2017/08/26 18:48:47 step 2: mse=0.986446 step=0.100000
2017/08/26 18:48:48 step 3: mse=0.906141 step=0.100000
2017/08/26 18:48:49 step 4: mse=0.862108 step=0.100000
2017/08/26 18:48:50 step 5: mse=0.806735 step=0.100000
2017/08/26 18:48:50 step 6: mse=0.762307 step=0.100000
2017/08/26 18:48:51 step 7: mse=0.727414 step=0.100000
2017/08/26 18:48:51 Saving...
2017/08/26 18:48:51 Gathering batch of experience...
2017/08/26 18:49:12 batch 518: mean=16.355556 stddev=7.863151 entropy=1.041632 frames=37326 count=45
2017/08/26 18:49:12 Training policy...
2017/08/26 18:49:19 step 0: objective=0.018506426
2017/08/26 18:49:24 step 1: objective=0.018585641
2017/08/26 18:49:29 step 2: objective=0.018664602
2017/08/26 18:49:35 step 3: objective=0.018742299
2017/08/26 18:49:40 step 4: objective=0.01880462
2017/08/26 18:49:46 step 5: objective=0.018851327
2017/08/26 18:49:51 step 6: objective=0.01889616
2017/08/26 18:49:56 step 7: objective=0.018950194
2017/08/26 18:49:56 Training value function...
2017/08/26 18:49:58 step 0: mse=1.306353 step=0.100000
2017/08/26 18:49:58 step 1: mse=1.199722 step=0.100000
2017/08/26 18:49:59 step 2: mse=1.113628 step=0.100000
2017/08/26 18:50:00 step 3: mse=1.044745 step=0.100000
2017/08/26 18:50:01 step 4: mse=0.999465 step=0.100000
2017/08/26 18:50:01 step 5: mse=0.951394 step=0.100000
2017/08/26 18:50:02 step 6: mse=0.918697 step=0.100000
2017/08/26 18:50:03 step 7: mse=0.884101 step=0.100000
2017/08/26 18:50:03 Saving...
2017/08/26 18:50:03 Gathering batch of experience...
2017/08/26 18:50:23 batch 519: mean=17.152174 stddev=8.150667 entropy=1.039923 frames=37820 count=46
2017/08/26 18:50:23 Training policy...
2017/08/26 18:50:31 step 0: objective=0.03875553
2017/08/26 18:50:36 step 1: objective=0.038800463
2017/08/26 18:50:41 step 2: objective=0.038846083
2017/08/26 18:50:47 step 3: objective=0.038891714
2017/08/26 18:50:52 step 4: objective=0.038937867
2017/08/26 18:50:58 step 5: objective=0.038979027
2017/08/26 18:51:03 step 6: objective=0.03901108
2017/08/26 18:51:09 step 7: objective=0.039048783
2017/08/26 18:51:09 Training value function...
2017/08/26 18:51:10 step 0: mse=1.155518 step=0.100000
2017/08/26 18:51:11 step 1: mse=1.094341 step=0.100000
2017/08/26 18:51:12 step 2: mse=1.040381 step=0.100000
2017/08/26 18:51:12 step 3: mse=0.999162 step=0.100000
2017/08/26 18:51:13 step 4: mse=0.959576 step=0.100000
2017/08/26 18:51:14 step 5: mse=0.928473 step=0.100000
2017/08/26 18:51:15 step 6: mse=0.888947 step=0.100000
2017/08/26 18:51:15 step 7: mse=0.867300 step=0.100000
2017/08/26 18:51:15 Saving...
2017/08/26 18:51:16 Gathering batch of experience...
2017/08/26 18:51:35 batch 520: mean=16.272727 stddev=7.190156 entropy=1.050038 frames=36117 count=44
2017/08/26 18:51:35 Training policy...
2017/08/26 18:51:42 step 0: objective=0.024598844
2017/08/26 18:51:47 step 1: objective=0.024666177
2017/08/26 18:51:53 step 2: objective=0.024733178
2017/08/26 18:51:58 step 3: objective=0.024799597
2017/08/26 18:52:03 step 4: objective=0.024848832
2017/08/26 18:52:08 step 5: objective=0.024918742
2017/08/26 18:52:14 step 6: objective=0.024970569
2017/08/26 18:52:19 step 7: objective=0.025022414
2017/08/26 18:52:19 Training value function...
2017/08/26 18:52:20 step 0: mse=0.980396 step=0.100000
2017/08/26 18:52:21 step 1: mse=0.921991 step=0.100000
2017/08/26 18:52:22 step 2: mse=0.874168 step=0.100000
2017/08/26 18:52:22 step 3: mse=0.829922 step=0.100000
2017/08/26 18:52:23 step 4: mse=0.772920 step=0.100000
2017/08/26 18:52:24 step 5: mse=0.728098 step=0.100000
2017/08/26 18:52:25 step 6: mse=0.703840 step=0.100000
2017/08/26 18:52:25 step 7: mse=0.669018 step=0.100000
2017/08/26 18:52:25 Saving...
2017/08/26 18:52:25 Gathering batch of experience...
2017/08/26 18:52:45 batch 521: mean=17.404762 stddev=6.848912 entropy=1.044098 frames=36451 count=42
2017/08/26 18:52:45 Training policy...
2017/08/26 18:52:52 step 0: objective=0.025580566
2017/08/26 18:52:57 step 1: objective=0.025612796
2017/08/26 18:53:02 step 2: objective=0.02564553
2017/08/26 18:53:08 step 3: objective=0.02567838
2017/08/26 18:53:13 step 4: objective=0.02571091
2017/08/26 18:53:18 step 5: objective=0.025744833
2017/08/26 18:53:24 step 6: objective=0.025789583
2017/08/26 18:53:29 step 7: objective=0.025836274
2017/08/26 18:53:29 Training value function...
2017/08/26 18:53:30 step 0: mse=0.844658 step=0.100000
2017/08/26 18:53:31 step 1: mse=0.789415 step=0.100000
2017/08/26 18:53:32 step 2: mse=0.744201 step=0.100000
2017/08/26 18:53:32 step 3: mse=0.708352 step=0.100000
2017/08/26 18:53:33 step 4: mse=0.679604 step=0.100000
2017/08/26 18:53:34 step 5: mse=0.654151 step=0.100000
2017/08/26 18:53:35 step 6: mse=0.634892 step=0.100000
2017/08/26 18:53:35 step 7: mse=0.618862 step=0.100000
2017/08/26 18:53:35 Saving...
2017/08/26 18:53:35 Gathering batch of experience...
2017/08/26 18:53:55 batch 522: mean=17.975610 stddev=6.848492 entropy=1.036029 frames=36506 count=41
2017/08/26 18:53:55 Training policy...
2017/08/26 18:54:02 step 0: objective=0.03450311
2017/08/26 18:54:07 step 1: objective=0.034545593
2017/08/26 18:54:13 step 2: objective=0.03458863
2017/08/26 18:54:18 step 3: objective=0.03463022
2017/08/26 18:54:23 step 4: objective=0.034652766
2017/08/26 18:54:29 step 5: objective=0.034673367
2017/08/26 18:54:34 step 6: objective=0.034695618
2017/08/26 18:54:39 step 7: objective=0.034726087
2017/08/26 18:54:39 Training value function...
2017/08/26 18:54:40 step 0: mse=0.763770 step=0.100000
2017/08/26 18:54:41 step 1: mse=0.735041 step=0.100000
2017/08/26 18:54:42 step 2: mse=0.709320 step=0.100000
2017/08/26 18:54:43 step 3: mse=0.689118 step=0.100000
2017/08/26 18:54:44 step 4: mse=0.668089 step=0.100000
2017/08/26 18:54:44 step 5: mse=0.648854 step=0.100000
2017/08/26 18:54:45 step 6: mse=0.634611 step=0.100000
2017/08/26 18:54:46 step 7: mse=0.619742 step=0.100000
2017/08/26 18:54:46 Saving...
2017/08/26 18:54:46 Gathering batch of experience...
2017/08/26 18:55:06 batch 523: mean=16.177778 stddev=6.890537 entropy=1.047565 frames=36750 count=45
2017/08/26 18:55:06 Training policy...
2017/08/26 18:55:13 step 0: objective=0.016944585
2017/08/26 18:55:18 step 1: objective=0.016985398
2017/08/26 18:55:23 step 2: objective=0.017026456
2017/08/26 18:55:29 step 3: objective=0.01706781
2017/08/26 18:55:34 step 4: objective=0.017109575
2017/08/26 18:55:39 step 5: objective=0.017151296
2017/08/26 18:55:45 step 6: objective=0.017224241
2017/08/26 18:55:50 step 7: objective=0.017284943
2017/08/26 18:55:50 Training value function...
2017/08/26 18:55:51 step 0: mse=1.004938 step=0.100000
2017/08/26 18:55:52 step 1: mse=0.949119 step=0.100000
2017/08/26 18:55:53 step 2: mse=0.903520 step=0.100000
2017/08/26 18:55:54 step 3: mse=0.858346 step=0.100000
2017/08/26 18:55:55 step 4: mse=0.819791 step=0.100000
2017/08/26 18:55:55 step 5: mse=0.794307 step=0.100000
2017/08/26 18:55:56 step 6: mse=0.766715 step=0.100000
2017/08/26 18:55:57 step 7: mse=0.747777 step=0.100000
2017/08/26 18:55:57 Saving...
2017/08/26 18:55:57 Gathering batch of experience...
2017/08/26 18:56:17 batch 524: mean=17.595238 stddev=5.773748 entropy=1.049920 frames=36693 count=42
2017/08/26 18:56:17 Training policy...
2017/08/26 18:56:24 step 0: objective=0.031122856
2017/08/26 18:56:29 step 1: objective=0.031172233
2017/08/26 18:56:35 step 2: objective=0.031222122
2017/08/26 18:56:40 step 3: objective=0.031271815
2017/08/26 18:56:45 step 4: objective=0.031321872
2017/08/26 18:56:51 step 5: objective=0.031366814
2017/08/26 18:56:56 step 6: objective=0.03139429
2017/08/26 18:57:01 step 7: objective=0.0314543
2017/08/26 18:57:01 Training value function...
2017/08/26 18:57:02 step 0: mse=0.911135 step=0.100000
2017/08/26 18:57:03 step 1: mse=0.849340 step=0.100000
2017/08/26 18:57:04 step 2: mse=0.796729 step=0.100000
2017/08/26 18:57:05 step 3: mse=0.756881 step=0.100000
2017/08/26 18:57:05 step 4: mse=0.722476 step=0.100000
2017/08/26 18:57:06 step 5: mse=0.692454 step=0.100000
2017/08/26 18:57:07 step 6: mse=0.669485 step=0.100000
2017/08/26 18:57:08 step 7: mse=0.642235 step=0.100000
2017/08/26 18:57:08 Saving...
2017/08/26 18:57:08 Gathering batch of experience...
2017/08/26 18:57:28 batch 525: mean=17.813953 stddev=7.558318 entropy=1.041051 frames=37774 count=43
2017/08/26 18:57:28 Training policy...
2017/08/26 18:57:36 step 0: objective=0.042456195
2017/08/26 18:57:41 step 1: objective=0.042484276
2017/08/26 18:57:47 step 2: objective=0.042512227
2017/08/26 18:57:52 step 3: objective=0.042540237
2017/08/26 18:57:58 step 4: objective=0.04256817
2017/08/26 18:58:03 step 5: objective=0.04259631
2017/08/26 18:58:09 step 6: objective=0.042622764
2017/08/26 18:58:14 step 7: objective=0.04264777
2017/08/26 18:58:14 Training value function...
2017/08/26 18:58:15 step 0: mse=0.953493 step=0.100000
2017/08/26 18:58:16 step 1: mse=0.889634 step=0.100000
2017/08/26 18:58:17 step 2: mse=0.832864 step=0.100000
2017/08/26 18:58:18 step 3: mse=0.790229 step=0.100000
2017/08/26 18:58:19 step 4: mse=0.751146 step=0.100000
2017/08/26 18:58:19 step 5: mse=0.715724 step=0.100000
2017/08/26 18:58:20 step 6: mse=0.689772 step=0.100000
2017/08/26 18:58:21 step 7: mse=0.667841 step=0.100000
2017/08/26 18:58:21 Saving...
2017/08/26 18:58:21 Gathering batch of experience...
2017/08/26 18:58:41 batch 526: mean=17.238095 stddev=6.159814 entropy=1.043127 frames=36012 count=42
2017/08/26 18:58:41 Training policy...
2017/08/26 18:58:48 step 0: objective=0.03342831
2017/08/26 18:58:53 step 1: objective=0.033483602
2017/08/26 18:58:58 step 2: objective=0.03353828
2017/08/26 18:59:03 step 3: objective=0.033593033
2017/08/26 18:59:09 step 4: objective=0.033647634
2017/08/26 18:59:14 step 5: objective=0.033700295
2017/08/26 18:59:19 step 6: objective=0.03374684
2017/08/26 18:59:24 step 7: objective=0.03379516
2017/08/26 18:59:24 Training value function...
2017/08/26 18:59:26 step 0: mse=0.866088 step=0.100000
2017/08/26 18:59:26 step 1: mse=0.811982 step=0.100000
2017/08/26 18:59:27 step 2: mse=0.764814 step=0.100000
2017/08/26 18:59:28 step 3: mse=0.731634 step=0.100000
2017/08/26 18:59:29 step 4: mse=0.703567 step=0.100000
2017/08/26 18:59:29 step 5: mse=0.676487 step=0.100000
2017/08/26 18:59:30 step 6: mse=0.648972 step=0.100000
2017/08/26 18:59:31 step 7: mse=0.631871 step=0.100000
2017/08/26 18:59:31 Saving...
2017/08/26 18:59:31 Gathering batch of experience...
2017/08/26 18:59:52 batch 527: mean=16.956522 stddev=9.643553 entropy=1.050275 frames=38347 count=46
2017/08/26 18:59:52 Training policy...
2017/08/26 18:59:59 step 0: objective=0.03406748
2017/08/26 19:00:05 step 1: objective=0.034155477
2017/08/26 19:00:10 step 2: objective=0.034244005
2017/08/26 19:00:16 step 3: objective=0.034323823
2017/08/26 19:00:22 step 4: objective=0.03436364
2017/08/26 19:00:27 step 5: objective=0.034397993
2017/08/26 19:00:33 step 6: objective=0.034429483
2017/08/26 19:00:38 step 7: objective=0.03447967
2017/08/26 19:00:38 Training value function...
2017/08/26 19:00:40 step 0: mse=1.274259 step=0.100000
2017/08/26 19:00:40 step 1: mse=1.141841 step=0.100000
2017/08/26 19:00:41 step 2: mse=1.034153 step=0.100000
2017/08/26 19:00:42 step 3: mse=0.947557 step=0.100000
2017/08/26 19:00:43 step 4: mse=0.877482 step=0.100000
2017/08/26 19:00:44 step 5: mse=0.818655 step=0.100000
2017/08/26 19:00:45 step 6: mse=0.770621 step=0.100000
2017/08/26 19:00:45 step 7: mse=0.731277 step=0.100000
2017/08/26 19:00:45 Saving...
2017/08/26 19:00:45 Gathering batch of experience...
2017/08/26 19:01:06 batch 528: mean=16.930233 stddev=7.806960 entropy=1.047501 frames=37850 count=43
2017/08/26 19:01:06 Training policy...
2017/08/26 19:01:13 step 0: objective=0.013402669
2017/08/26 19:01:19 step 1: objective=0.0134748295
2017/08/26 19:01:24 step 2: objective=0.013547399
2017/08/26 19:01:30 step 3: objective=0.013620381
2017/08/26 19:01:35 step 4: objective=0.013686798
2017/08/26 19:01:41 step 5: objective=0.013751175
2017/08/26 19:01:46 step 6: objective=0.013787008
2017/08/26 19:01:52 step 7: objective=0.013823673
2017/08/26 19:01:52 Training value function...
2017/08/26 19:01:53 step 0: mse=0.990384 step=0.100000
2017/08/26 19:01:54 step 1: mse=0.914787 step=0.100000
2017/08/26 19:01:55 step 2: mse=0.853620 step=0.100000
2017/08/26 19:01:56 step 3: mse=0.803764 step=0.100000
2017/08/26 19:01:56 step 4: mse=0.761461 step=0.100000
2017/08/26 19:01:57 step 5: mse=0.728274 step=0.100000
2017/08/26 19:01:58 step 6: mse=0.683408 step=0.100000
2017/08/26 19:01:59 step 7: mse=0.658844 step=0.100000
2017/08/26 19:01:59 Saving...
2017/08/26 19:01:59 Gathering batch of experience...
2017/08/26 19:02:19 batch 529: mean=15.413043 stddev=7.057454 entropy=1.050903 frames=36835 count=46
2017/08/26 19:02:19 Training policy...
2017/08/26 19:02:26 step 0: objective=0.02182073
2017/08/26 19:02:31 step 1: objective=0.021855569
2017/08/26 19:02:37 step 2: objective=0.021890573
2017/08/26 19:02:42 step 3: objective=0.021926042
2017/08/26 19:02:47 step 4: objective=0.021961669
2017/08/26 19:02:53 step 5: objective=0.021995284
2017/08/26 19:02:58 step 6: objective=0.022028437
2017/08/26 19:03:04 step 7: objective=0.022052953
2017/08/26 19:03:04 Training value function...
2017/08/26 19:03:05 step 0: mse=0.726417 step=0.100000
2017/08/26 19:03:06 step 1: mse=0.682789 step=0.100000
2017/08/26 19:03:06 step 2: mse=0.647945 step=0.100000
2017/08/26 19:03:07 step 3: mse=0.624001 step=0.100000
2017/08/26 19:03:08 step 4: mse=0.604638 step=0.100000
2017/08/26 19:03:09 step 5: mse=0.583681 step=0.100000
2017/08/26 19:03:10 step 6: mse=0.570485 step=0.100000
2017/08/26 19:03:10 step 7: mse=0.548416 step=0.100000
2017/08/26 19:03:10 Saving...
2017/08/26 19:03:10 Gathering batch of experience...
2017/08/26 19:03:30 batch 530: mean=18.300000 stddev=7.685050 entropy=1.039241 frames=36092 count=40
2017/08/26 19:03:30 Training policy...
2017/08/26 19:03:37 step 0: objective=0.04901071
2017/08/26 19:03:42 step 1: objective=0.04913626
2017/08/26 19:03:47 step 2: objective=0.049261265
2017/08/26 19:03:53 step 3: objective=0.049334522
2017/08/26 19:03:58 step 4: objective=0.049403656
2017/08/26 19:04:03 step 5: objective=0.04945221
2017/08/26 19:04:09 step 6: objective=0.04949933
2017/08/26 19:04:14 step 7: objective=0.049529538
2017/08/26 19:04:14 Training value function...
2017/08/26 19:04:15 step 0: mse=1.073703 step=0.100000
2017/08/26 19:04:16 step 1: mse=0.997762 step=0.100000
2017/08/26 19:04:17 step 2: mse=0.935782 step=0.100000
2017/08/26 19:04:17 step 3: mse=0.886213 step=0.100000
2017/08/26 19:04:18 step 4: mse=0.842790 step=0.100000
2017/08/26 19:04:19 step 5: mse=0.808478 step=0.100000
2017/08/26 19:04:20 step 6: mse=0.778182 step=0.100000
2017/08/26 19:04:20 step 7: mse=0.750350 step=0.100000
2017/08/26 19:04:20 Saving...
2017/08/26 19:04:20 Gathering batch of experience...
2017/08/26 19:04:41 batch 531: mean=17.642857 stddev=7.282796 entropy=1.029723 frames=36964 count=42
2017/08/26 19:04:41 Training policy...
2017/08/26 19:04:48 step 0: objective=0.04224902
2017/08/26 19:04:53 step 1: objective=0.04229238
2017/08/26 19:04:59 step 2: objective=0.04233587
2017/08/26 19:05:04 step 3: objective=0.04237977
2017/08/26 19:05:09 step 4: objective=0.042423256
2017/08/26 19:05:15 step 5: objective=0.042458564
2017/08/26 19:05:20 step 6: objective=0.04250982
2017/08/26 19:05:26 step 7: objective=0.04255876
2017/08/26 19:05:26 Training value function...
2017/08/26 19:05:27 step 0: mse=0.910016 step=0.100000
2017/08/26 19:05:28 step 1: mse=0.860222 step=0.100000
2017/08/26 19:05:28 step 2: mse=0.814887 step=0.100000
2017/08/26 19:05:29 step 3: mse=0.775752 step=0.100000
2017/08/26 19:05:30 step 4: mse=0.738438 step=0.100000
2017/08/26 19:05:31 step 5: mse=0.707872 step=0.100000
2017/08/26 19:05:31 step 6: mse=0.680403 step=0.100000
2017/08/26 19:05:32 step 7: mse=0.657600 step=0.100000
2017/08/26 19:05:32 Saving...
2017/08/26 19:05:32 Gathering batch of experience...
2017/08/26 19:05:52 batch 532: mean=15.755556 stddev=6.193744 entropy=1.045509 frames=36268 count=45
2017/08/26 19:05:52 Training policy...
2017/08/26 19:05:59 step 0: objective=0.033345893
2017/08/26 19:06:04 step 1: objective=0.033407778
2017/08/26 19:06:09 step 2: objective=0.033469327
2017/08/26 19:06:15 step 3: objective=0.033530667
2017/08/26 19:06:20 step 4: objective=0.033591907
2017/08/26 19:06:25 step 5: objective=0.033651274
2017/08/26 19:06:31 step 6: objective=0.03371524
2017/08/26 19:06:36 step 7: objective=0.03374733
2017/08/26 19:06:36 Training value function...
2017/08/26 19:06:37 step 0: mse=1.063883 step=0.100000
2017/08/26 19:06:38 step 1: mse=0.998310 step=0.100000
2017/08/26 19:06:39 step 2: mse=0.944774 step=0.100000
2017/08/26 19:06:40 step 3: mse=0.887865 step=0.100000
2017/08/26 19:06:40 step 4: mse=0.838383 step=0.100000
2017/08/26 19:06:41 step 5: mse=0.807979 step=0.100000
2017/08/26 19:06:42 step 6: mse=0.771838 step=0.100000
2017/08/26 19:06:42 step 7: mse=0.742389 step=0.100000
2017/08/26 19:06:42 Saving...
2017/08/26 19:06:43 Gathering batch of experience...
2017/08/26 19:07:03 batch 533: mean=16.590909 stddev=8.110930 entropy=1.050143 frames=36249 count=44
2017/08/26 19:07:03 Training policy...
2017/08/26 19:07:09 step 0: objective=0.03475324
2017/08/26 19:07:15 step 1: objective=0.03479083
2017/08/26 19:07:20 step 2: objective=0.034828216
2017/08/26 19:07:25 step 3: objective=0.034865778
2017/08/26 19:07:31 step 4: objective=0.034903202
2017/08/26 19:07:36 step 5: objective=0.034940097
2017/08/26 19:07:41 step 6: objective=0.034969207
2017/08/26 19:07:47 step 7: objective=0.03500656
2017/08/26 19:07:47 Training value function...
2017/08/26 19:07:48 step 0: mse=1.139942 step=0.100000
2017/08/26 19:07:48 step 1: mse=1.047776 step=0.100000
2017/08/26 19:07:49 step 2: mse=0.972852 step=0.100000
2017/08/26 19:07:50 step 3: mse=0.911832 step=0.100000
2017/08/26 19:07:51 step 4: mse=0.860701 step=0.100000
2017/08/26 19:07:51 step 5: mse=0.818282 step=0.100000
2017/08/26 19:07:52 step 6: mse=0.779354 step=0.100000
2017/08/26 19:07:53 step 7: mse=0.749450 step=0.100000
2017/08/26 19:07:53 Saving...
2017/08/26 19:07:53 Gathering batch of experience...
2017/08/26 19:08:13 batch 534: mean=16.418605 stddev=7.368167 entropy=1.050017 frames=35938 count=43
2017/08/26 19:08:13 Training policy...
2017/08/26 19:08:19 step 0: objective=0.010244255
2017/08/26 19:08:25 step 1: objective=0.010374407
2017/08/26 19:08:30 step 2: objective=0.010504781
2017/08/26 19:08:35 step 3: objective=0.010624595
2017/08/26 19:08:40 step 4: objective=0.010708396
2017/08/26 19:08:46 step 5: objective=0.01077913
2017/08/26 19:08:51 step 6: objective=0.010838902
2017/08/26 19:08:56 step 7: objective=0.010905042
2017/08/26 19:08:56 Training value function...
2017/08/26 19:08:57 step 0: mse=0.925461 step=0.100000
2017/08/26 19:08:58 step 1: mse=0.862780 step=0.100000
2017/08/26 19:08:59 step 2: mse=0.812986 step=0.100000
2017/08/26 19:09:00 step 3: mse=0.769275 step=0.100000
2017/08/26 19:09:00 step 4: mse=0.737303 step=0.100000
2017/08/26 19:09:01 step 5: mse=0.701605 step=0.100000
2017/08/26 19:09:02 step 6: mse=0.680599 step=0.100000
2017/08/26 19:09:02 step 7: mse=0.658072 step=0.100000
2017/08/26 19:09:02 Saving...
2017/08/26 19:09:03 Gathering batch of experience...
2017/08/26 19:09:23 batch 535: mean=16.604651 stddev=7.585603 entropy=1.048621 frames=36499 count=43
2017/08/26 19:09:23 Training policy...
2017/08/26 19:09:38 Run with arguments: [-algo mse -env Breakout-ram-v0 -step 0.5 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic Breakout-ram-v0/critic.json -actor Breakout-ram-v0/actor.json -depth 4 -minleaf 512 -batch 30000 -reg 0.001 -decay 0.99 -maxtrees 500]
2017/08/26 19:09:38 Creating environments...
2017/08/26 19:09:40 Loaded forest from: Breakout-ram-v0/actor.json
2017/08/26 19:09:40 Creating new forest for: Breakout-ram-v0/critic.json
2017/08/26 19:09:40 Running. Press Ctrl+C to stop.
2017/08/26 19:09:40 Gathering batch of experience...
2017/08/26 19:09:59 batch 0: mean=16.418605 stddev=6.535173 entropy=1.040198 frames=36707 count=43
2017/08/26 19:09:59 Training policy...
2017/08/26 19:10:04 step 0: objective=0.3231255
2017/08/26 19:10:08 step 1: objective=0.32325357
2017/08/26 19:10:13 step 2: objective=0.32340273
2017/08/26 19:10:17 step 3: objective=0.3235443
2017/08/26 19:10:22 step 4: objective=0.32359838
2017/08/26 19:10:26 step 5: objective=0.32366565
2017/08/26 19:10:31 step 6: objective=0.32371598
2017/08/26 19:10:35 step 7: objective=0.32384595
2017/08/26 19:10:35 Training value function...
2017/08/26 19:10:36 step 0: mse=3.976626 step=0.100000
2017/08/26 19:10:37 step 1: mse=3.342952 step=0.100000
2017/08/26 19:10:37 step 2: mse=2.832480 step=0.100000
2017/08/26 19:10:38 step 3: mse=2.421588 step=0.100000
2017/08/26 19:10:38 step 4: mse=2.085109 step=0.100000
2017/08/26 19:10:38 step 5: mse=1.814277 step=0.100000
2017/08/26 19:10:39 step 6: mse=1.593156 step=0.100000
2017/08/26 19:10:39 step 7: mse=1.406056 step=0.100000
2017/08/26 19:10:39 Saving...
2017/08/26 19:10:39 Gathering batch of experience...
2017/08/26 19:10:59 batch 1: mean=18.309524 stddev=7.956693 entropy=1.044211 frames=37280 count=42
2017/08/26 19:10:59 Training policy...
2017/08/26 19:11:04 step 0: objective=0.1686143
2017/08/26 19:11:09 step 1: objective=0.16867629
2017/08/26 19:11:13 step 2: objective=0.16873772
2017/08/26 19:11:18 step 3: objective=0.16879956
2017/08/26 19:11:22 step 4: objective=0.1688435
2017/08/26 19:11:27 step 5: objective=0.1688852
2017/08/26 19:11:31 step 6: objective=0.16891338
2017/08/26 19:11:36 step 7: objective=0.16895986
2017/08/26 19:11:36 Training value function...
2017/08/26 19:11:37 step 0: mse=1.762621 step=0.100000
2017/08/26 19:11:37 step 1: mse=1.560806 step=0.100000
2017/08/26 19:11:38 step 2: mse=1.384363 step=0.100000
2017/08/26 19:11:38 step 3: mse=1.247680 step=0.100000
2017/08/26 19:11:39 step 4: mse=1.127261 step=0.100000
2017/08/26 19:11:39 step 5: mse=1.030573 step=0.100000
2017/08/26 19:11:40 step 6: mse=0.957376 step=0.100000
2017/08/26 19:11:40 step 7: mse=0.891572 step=0.100000
2017/08/26 19:11:40 Saving...
2017/08/26 19:11:40 Gathering batch of experience...
2017/08/26 19:11:59 batch 2: mean=16.933333 stddev=6.945502 entropy=1.045804 frames=37205 count=45
2017/08/26 19:11:59 Training policy...
2017/08/26 19:12:04 step 0: objective=0.0825644
2017/08/26 19:12:09 step 1: objective=0.08261047
2017/08/26 19:12:14 step 2: objective=0.082656436
2017/08/26 19:12:18 step 3: objective=0.0827022
2017/08/26 19:12:23 step 4: objective=0.08274864
2017/08/26 19:12:27 step 5: objective=0.082794465
2017/08/26 19:12:32 step 6: objective=0.08283411
2017/08/26 19:12:37 step 7: objective=0.082887895
2017/08/26 19:12:37 Training value function...
2017/08/26 19:12:38 step 0: mse=1.222919 step=0.100000
2017/08/26 19:12:38 step 1: mse=1.142874 step=0.100000
2017/08/26 19:12:38 step 2: mse=1.077785 step=0.100000
2017/08/26 19:12:39 step 3: mse=1.024768 step=0.100000
2017/08/26 19:12:39 step 4: mse=0.982397 step=0.100000
2017/08/26 19:12:40 step 5: mse=0.947305 step=0.100000
2017/08/26 19:12:40 step 6: mse=0.910415 step=0.100000
2017/08/26 19:12:41 step 7: mse=0.888569 step=0.100000
2017/08/26 19:12:41 Saving...
2017/08/26 19:12:41 Gathering batch of experience...
2017/08/26 19:13:00 batch 3: mean=16.446809 stddev=8.685543 entropy=1.045332 frames=37400 count=47
2017/08/26 19:13:00 Training policy...
2017/08/26 19:13:05 step 0: objective=0.04999541
2017/08/26 19:13:10 step 1: objective=0.05006376
2017/08/26 19:13:14 step 2: objective=0.05013369
2017/08/26 19:13:19 step 3: objective=0.050204284
2017/08/26 19:13:23 step 4: objective=0.05027374
2017/08/26 19:13:28 step 5: objective=0.050322425
2017/08/26 19:13:33 step 6: objective=0.050365634
2017/08/26 19:13:37 step 7: objective=0.050395705
2017/08/26 19:13:37 Training value function...
2017/08/26 19:13:38 step 0: mse=1.212005 step=0.100000
2017/08/26 19:13:39 step 1: mse=1.138149 step=0.100000
2017/08/26 19:13:39 step 2: mse=1.081836 step=0.100000
2017/08/26 19:13:40 step 3: mse=1.033232 step=0.100000
2017/08/26 19:13:40 step 4: mse=0.987133 step=0.100000
2017/08/26 19:13:41 step 5: mse=0.953929 step=0.100000
2017/08/26 19:13:41 step 6: mse=0.926864 step=0.100000
2017/08/26 19:13:42 step 7: mse=0.888838 step=0.100000
2017/08/26 19:13:42 Saving...
2017/08/26 19:13:42 Gathering batch of experience...
2017/08/26 19:14:01 batch 4: mean=19.813953 stddev=9.777182 entropy=1.035684 frames=37820 count=43
2017/08/26 19:14:01 Training policy...
2017/08/26 19:14:07 step 0: objective=0.0670118
2017/08/26 19:14:11 step 1: objective=0.06707256
2017/08/26 19:14:16 step 2: objective=0.06713257
2017/08/26 19:14:21 step 3: objective=0.067192264
2017/08/26 19:14:25 step 4: objective=0.067241676
2017/08/26 19:14:30 step 5: objective=0.06729769
2017/08/26 19:14:35 step 6: objective=0.06735804
2017/08/26 19:14:39 step 7: objective=0.067413315
2017/08/26 19:14:39 Training value function...
2017/08/26 19:14:40 step 0: mse=1.623095 step=0.100000
2017/08/26 19:14:41 step 1: mse=1.481676 step=0.100000
2017/08/26 19:14:41 step 2: mse=1.367635 step=0.100000
2017/08/26 19:14:42 step 3: mse=1.275441 step=0.100000
2017/08/26 19:14:42 step 4: mse=1.200273 step=0.100000
2017/08/26 19:14:43 step 5: mse=1.137527 step=0.100000
2017/08/26 19:14:43 step 6: mse=1.084737 step=0.100000
2017/08/26 19:14:44 step 7: mse=1.026021 step=0.100000
2017/08/26 19:14:44 Saving...
2017/08/26 19:14:44 Gathering batch of experience...
2017/08/26 19:15:03 batch 5: mean=16.666667 stddev=7.232642 entropy=1.056265 frames=36973 count=45
2017/08/26 19:15:03 Training policy...
2017/08/26 19:15:08 step 0: objective=0.03209029
2017/08/26 19:15:13 step 1: objective=0.032187015
2017/08/26 19:15:17 step 2: objective=0.032283884
2017/08/26 19:15:22 step 3: objective=0.032377098
2017/08/26 19:15:26 step 4: objective=0.032461233
2017/08/26 19:15:31 step 5: objective=0.03254094
2017/08/26 19:15:35 step 6: objective=0.03261914
2017/08/26 19:15:40 step 7: objective=0.03266343
2017/08/26 19:15:40 Training value function...
2017/08/26 19:15:41 step 0: mse=0.991609 step=0.100000
2017/08/26 19:15:41 step 1: mse=0.933826 step=0.100000
2017/08/26 19:15:42 step 2: mse=0.888344 step=0.100000
2017/08/26 19:15:42 step 3: mse=0.849082 step=0.100000
2017/08/26 19:15:43 step 4: mse=0.816735 step=0.100000
2017/08/26 19:15:43 step 5: mse=0.787867 step=0.100000
2017/08/26 19:15:44 step 6: mse=0.748447 step=0.100000
2017/08/26 19:15:44 step 7: mse=0.729741 step=0.100000
2017/08/26 19:15:44 Saving...
2017/08/26 19:15:44 Gathering batch of experience...
2017/08/26 19:16:03 batch 6: mean=19.121951 stddev=8.568789 entropy=1.040544 frames=36708 count=41
2017/08/26 19:16:03 Training policy...
2017/08/26 19:16:08 step 0: objective=0.02762392
2017/08/26 19:16:13 step 1: objective=0.027726103
2017/08/26 19:16:17 step 2: objective=0.027828626
2017/08/26 19:16:21 step 3: objective=0.027930524
2017/08/26 19:16:26 step 4: objective=0.028020969
2017/08/26 19:16:30 step 5: objective=0.028050307
2017/08/26 19:16:35 step 6: objective=0.028083341
2017/08/26 19:16:39 step 7: objective=0.028109297
2017/08/26 19:16:39 Training value function...
2017/08/26 19:16:40 step 0: mse=1.269317 step=0.100000
2017/08/26 19:16:40 step 1: mse=1.193219 step=0.100000
2017/08/26 19:16:41 step 2: mse=1.129701 step=0.100000
2017/08/26 19:16:41 step 3: mse=1.075739 step=0.100000
2017/08/26 19:16:42 step 4: mse=1.026642 step=0.100000
2017/08/26 19:16:42 step 5: mse=0.982252 step=0.100000
2017/08/26 19:16:43 step 6: mse=0.939060 step=0.100000
2017/08/26 19:16:43 step 7: mse=0.907875 step=0.100000
2017/08/26 19:16:43 Saving...
2017/08/26 19:16:43 Gathering batch of experience...
2017/08/26 19:17:02 batch 7: mean=17.232558 stddev=8.191990 entropy=1.047143 frames=36275 count=43
2017/08/26 19:17:02 Training policy...
2017/08/26 19:17:07 step 0: objective=0.039044138
2017/08/26 19:17:11 step 1: objective=0.039106958
2017/08/26 19:17:16 step 2: objective=0.039169624
2017/08/26 19:17:20 step 3: objective=0.03923206
2017/08/26 19:17:24 step 4: objective=0.039292865
2017/08/26 19:17:29 step 5: objective=0.03933848
2017/08/26 19:17:33 step 6: objective=0.039391547
2017/08/26 19:17:38 step 7: objective=0.039454587
2017/08/26 19:17:38 Training value function...
2017/08/26 19:17:38 step 0: mse=0.931612 step=0.100000
2017/08/26 19:17:39 step 1: mse=0.875380 step=0.100000
2017/08/26 19:17:39 step 2: mse=0.828020 step=0.100000
2017/08/26 19:17:40 step 3: mse=0.791005 step=0.100000
2017/08/26 19:17:40 step 4: mse=0.757171 step=0.100000
2017/08/26 19:17:41 step 5: mse=0.726775 step=0.100000
2017/08/26 19:17:41 step 6: mse=0.702005 step=0.100000
2017/08/26 19:17:42 step 7: mse=0.680733 step=0.100000
2017/08/26 19:17:42 Saving...
2017/08/26 19:17:42 Gathering batch of experience...
2017/08/26 19:17:59 batch 8: mean=16.976190 stddev=7.503929 entropy=1.049008 frames=35154 count=42
2017/08/26 19:17:59 Training policy...
2017/08/26 19:18:04 step 0: objective=0.025784997
2017/08/26 19:18:09 step 1: objective=0.02583854
2017/08/26 19:18:13 step 2: objective=0.025891984
2017/08/26 19:18:17 step 3: objective=0.025945015
2017/08/26 19:18:21 step 4: objective=0.025997883
2017/08/26 19:18:26 step 5: objective=0.026049834
2017/08/26 19:18:30 step 6: objective=0.026096055
2017/08/26 19:18:34 step 7: objective=0.026125515
2017/08/26 19:18:34 Training value function...
2017/08/26 19:18:35 step 0: mse=0.959120 step=0.100000
2017/08/26 19:18:35 step 1: mse=0.913352 step=0.100000
2017/08/26 19:18:36 step 2: mse=0.875354 step=0.100000
2017/08/26 19:18:36 step 3: mse=0.841897 step=0.100000
2017/08/26 19:18:37 step 4: mse=0.805804 step=0.100000
2017/08/26 19:18:37 step 5: mse=0.783181 step=0.100000
2017/08/26 19:18:37 step 6: mse=0.752717 step=0.100000
2017/08/26 19:18:38 step 7: mse=0.737449 step=0.100000
2017/08/26 19:18:38 Saving...
2017/08/26 19:18:38 Gathering batch of experience...
2017/08/26 19:18:56 batch 9: mean=18.186047 stddev=8.283511 entropy=1.032158 frames=36678 count=43
2017/08/26 19:18:56 Training policy...
2017/08/26 19:19:02 step 0: objective=0.039705437
2017/08/26 19:19:06 step 1: objective=0.039813295
2017/08/26 19:19:11 step 2: objective=0.039920084
2017/08/26 19:19:15 step 3: objective=0.040025983
2017/08/26 19:19:19 step 4: objective=0.040121358
2017/08/26 19:19:24 step 5: objective=0.040190656
2017/08/26 19:19:28 step 6: objective=0.04021831
2017/08/26 19:19:33 step 7: objective=0.040313255
2017/08/26 19:19:33 Training value function...
2017/08/26 19:19:34 step 0: mse=1.590385 step=0.100000
2017/08/26 19:19:34 step 1: mse=1.478393 step=0.100000
2017/08/26 19:19:35 step 2: mse=1.387831 step=0.100000
2017/08/26 19:19:35 step 3: mse=1.309533 step=0.100000
2017/08/26 19:19:36 step 4: mse=1.245811 step=0.100000
2017/08/26 19:19:36 step 5: mse=1.189653 step=0.100000
2017/08/26 19:19:36 step 6: mse=1.143397 step=0.100000
2017/08/26 19:19:37 step 7: mse=1.090111 step=0.100000
2017/08/26 19:19:37 Saving...
2017/08/26 19:19:37 Gathering batch of experience...
2017/08/26 19:19:56 batch 10: mean=17.295455 stddev=8.097641 entropy=1.041432 frames=37205 count=44
2017/08/26 19:19:56 Training policy...
2017/08/26 19:20:01 step 0: objective=0.02981215
2017/08/26 19:20:06 step 1: objective=0.029935423
2017/08/26 19:20:10 step 2: objective=0.030052235
2017/08/26 19:20:15 step 3: objective=0.030154392
2017/08/26 19:20:19 step 4: objective=0.030225584
2017/08/26 19:20:24 step 5: objective=0.030280413
2017/08/26 19:20:28 step 6: objective=0.030342933
2017/08/26 19:20:33 step 7: objective=0.030425282
2017/08/26 19:20:33 Training value function...
2017/08/26 19:20:34 step 0: mse=0.951272 step=0.100000
2017/08/26 19:20:34 step 1: mse=0.884815 step=0.100000
2017/08/26 19:20:35 step 2: mse=0.831582 step=0.100000
2017/08/26 19:20:35 step 3: mse=0.788142 step=0.100000
2017/08/26 19:20:36 step 4: mse=0.753577 step=0.100000
2017/08/26 19:20:36 step 5: mse=0.724448 step=0.100000
2017/08/26 19:20:37 step 6: mse=0.697819 step=0.100000
2017/08/26 19:20:37 step 7: mse=0.674841 step=0.100000
2017/08/26 19:20:37 Saving...
2017/08/26 19:20:37 Gathering batch of experience...
2017/08/26 19:20:56 batch 11: mean=19.675000 stddev=7.798678 entropy=1.033469 frames=37276 count=40
2017/08/26 19:20:56 Training policy...
2017/08/26 19:21:01 step 0: objective=0.046161015
2017/08/26 19:21:06 step 1: objective=0.046229612
2017/08/26 19:21:11 step 2: objective=0.046298325
2017/08/26 19:21:15 step 3: objective=0.046364285
2017/08/26 19:21:20 step 4: objective=0.046426903
2017/08/26 19:21:24 step 5: objective=0.046479728
2017/08/26 19:21:29 step 6: objective=0.04653973
2017/08/26 19:21:33 step 7: objective=0.04662414
2017/08/26 19:21:33 Training value function...
2017/08/26 19:21:34 step 0: mse=1.088390 step=0.100000
2017/08/26 19:21:35 step 1: mse=1.029674 step=0.100000
2017/08/26 19:21:35 step 2: mse=0.977085 step=0.100000
2017/08/26 19:21:36 step 3: mse=0.931557 step=0.100000
2017/08/26 19:21:36 step 4: mse=0.894063 step=0.100000
2017/08/26 19:21:36 step 5: mse=0.861572 step=0.100000
2017/08/26 19:21:37 step 6: mse=0.836501 step=0.100000
2017/08/26 19:21:37 step 7: mse=0.816390 step=0.100000
2017/08/26 19:21:37 Saving...
2017/08/26 19:21:37 Gathering batch of experience...
2017/08/26 19:21:56 batch 12: mean=19.925000 stddev=9.037111 entropy=1.036387 frames=36270 count=40
2017/08/26 19:21:56 Training policy...
2017/08/26 19:22:01 step 0: objective=0.032861598
2017/08/26 19:22:06 step 1: objective=0.032964017
2017/08/26 19:22:10 step 2: objective=0.03306581
2017/08/26 19:22:14 step 3: objective=0.033167046
2017/08/26 19:22:19 step 4: objective=0.033252396
2017/08/26 19:22:23 step 5: objective=0.033315197
2017/08/26 19:22:28 step 6: objective=0.03336427
2017/08/26 19:22:32 step 7: objective=0.033420186
2017/08/26 19:22:32 Training value function...
2017/08/26 19:22:33 step 0: mse=1.342981 step=0.100000
2017/08/26 19:22:33 step 1: mse=1.239352 step=0.100000
2017/08/26 19:22:34 step 2: mse=1.156534 step=0.100000
2017/08/26 19:22:34 step 3: mse=1.088026 step=0.100000
2017/08/26 19:22:35 step 4: mse=1.030241 step=0.100000
2017/08/26 19:22:35 step 5: mse=0.983463 step=0.100000
2017/08/26 19:22:36 step 6: mse=0.943485 step=0.100000
2017/08/26 19:22:36 step 7: mse=0.909503 step=0.100000
2017/08/26 19:22:36 Saving...
2017/08/26 19:22:36 Gathering batch of experience...
2017/08/26 19:22:56 batch 13: mean=17.395349 stddev=7.294916 entropy=1.040142 frames=37620 count=43
2017/08/26 19:22:56 Training policy...
2017/08/26 19:23:01 step 0: objective=0.013618353
2017/08/26 19:23:06 step 1: objective=0.01369218
2017/08/26 19:23:10 step 2: objective=0.01376555
2017/08/26 19:23:15 step 3: objective=0.013838224
2017/08/26 19:23:20 step 4: objective=0.013894829
2017/08/26 19:23:24 step 5: objective=0.013938214
2017/08/26 19:23:29 step 6: objective=0.013999059
2017/08/26 19:23:33 step 7: objective=0.0140332915
2017/08/26 19:23:33 Training value function...
2017/08/26 19:23:34 step 0: mse=1.013097 step=0.100000
2017/08/26 19:23:35 step 1: mse=0.960502 step=0.100000
2017/08/26 19:23:35 step 2: mse=0.906453 step=0.100000
2017/08/26 19:23:36 step 3: mse=0.863526 step=0.100000
2017/08/26 19:23:36 step 4: mse=0.831181 step=0.100000
2017/08/26 19:23:37 step 5: mse=0.789363 step=0.100000
2017/08/26 19:23:37 step 6: mse=0.758911 step=0.100000
2017/08/26 19:23:38 step 7: mse=0.729864 step=0.100000
2017/08/26 19:23:38 Saving...
2017/08/26 19:23:38 Gathering batch of experience...
2017/08/26 19:23:57 batch 14: mean=18.238095 stddev=8.178979 entropy=1.040360 frames=37257 count=42
2017/08/26 19:23:57 Training policy...
2017/08/26 19:24:02 step 0: objective=0.029969465
2017/08/26 19:24:07 step 1: objective=0.030038012
2017/08/26 19:24:11 step 2: objective=0.030106785
2017/08/26 19:24:16 step 3: objective=0.03017535
2017/08/26 19:24:20 step 4: objective=0.030242104
2017/08/26 19:24:25 step 5: objective=0.030307587
2017/08/26 19:24:30 step 6: objective=0.030330654
2017/08/26 19:24:34 step 7: objective=0.030384094
2017/08/26 19:24:34 Training value function...
2017/08/26 19:24:35 step 0: mse=1.163895 step=0.100000
2017/08/26 19:24:36 step 1: mse=1.100649 step=0.100000
2017/08/26 19:24:36 step 2: mse=1.039784 step=0.100000
2017/08/26 19:24:37 step 3: mse=0.998557 step=0.100000
2017/08/26 19:24:37 step 4: mse=0.967589 step=0.100000
2017/08/26 19:24:38 step 5: mse=0.930796 step=0.100000
2017/08/26 19:24:38 step 6: mse=0.901184 step=0.100000
2017/08/26 19:24:39 step 7: mse=0.877682 step=0.100000
2017/08/26 19:24:39 Saving...
2017/08/26 19:24:39 Gathering batch of experience...
2017/08/26 19:24:58 batch 15: mean=18.209302 stddev=8.337526 entropy=1.035571 frames=37848 count=43
2017/08/26 19:24:58 Training policy...
2017/08/26 19:25:03 step 0: objective=0.025907543
2017/08/26 19:25:08 step 1: objective=0.025998203
2017/08/26 19:25:12 step 2: objective=0.026087439
2017/08/26 19:25:17 step 3: objective=0.026163299
2017/08/26 19:25:22 step 4: objective=0.026237058
2017/08/26 19:25:26 step 5: objective=0.026290009
2017/08/26 19:25:31 step 6: objective=0.026329117
2017/08/26 19:25:36 step 7: objective=0.026384942
2017/08/26 19:25:36 Training value function...
2017/08/26 19:25:37 step 0: mse=1.208524 step=0.100000
2017/08/26 19:25:37 step 1: mse=1.158944 step=0.100000
2017/08/26 19:25:38 step 2: mse=1.112811 step=0.100000
2017/08/26 19:25:38 step 3: mse=1.079531 step=0.100000
2017/08/26 19:25:39 step 4: mse=1.043594 step=0.100000
2017/08/26 19:25:39 step 5: mse=0.999836 step=0.100000
2017/08/26 19:25:40 step 6: mse=0.972363 step=0.100000
2017/08/26 19:25:40 step 7: mse=0.936707 step=0.100000
2017/08/26 19:25:40 Saving...
2017/08/26 19:25:40 Gathering batch of experience...
2017/08/26 19:25:59 batch 16: mean=17.476190 stddev=6.561932 entropy=1.035277 frames=36948 count=42
2017/08/26 19:25:59 Training policy...
2017/08/26 19:26:05 step 0: objective=0.02748263
2017/08/26 19:26:09 step 1: objective=0.027546411
2017/08/26 19:26:14 step 2: objective=0.027609734
2017/08/26 19:26:18 step 3: objective=0.027672447
2017/08/26 19:26:23 step 4: objective=0.027742345
2017/08/26 19:26:28 step 5: objective=0.027805379
2017/08/26 19:26:32 step 6: objective=0.02782433
2017/08/26 19:26:37 step 7: objective=0.027873104
2017/08/26 19:26:37 Training value function...
2017/08/26 19:26:38 step 0: mse=0.870424 step=0.100000
2017/08/26 19:26:38 step 1: mse=0.816832 step=0.100000
2017/08/26 19:26:39 step 2: mse=0.770387 step=0.100000
2017/08/26 19:26:39 step 3: mse=0.731619 step=0.100000
2017/08/26 19:26:40 step 4: mse=0.697846 step=0.100000
2017/08/26 19:26:40 step 5: mse=0.663043 step=0.100000
2017/08/26 19:26:41 step 6: mse=0.641490 step=0.100000
2017/08/26 19:26:41 step 7: mse=0.615900 step=0.100000
2017/08/26 19:26:41 Saving...
2017/08/26 19:26:41 Gathering batch of experience...
2017/08/26 19:27:00 batch 17: mean=17.395349 stddev=6.820419 entropy=1.044981 frames=37061 count=43
2017/08/26 19:27:00 Training policy...
2017/08/26 19:27:05 step 0: objective=0.035333157
2017/08/26 19:27:10 step 1: objective=0.035386562
2017/08/26 19:27:15 step 2: objective=0.035440024
2017/08/26 19:27:19 step 3: objective=0.03549387
2017/08/26 19:27:24 step 4: objective=0.03554819
2017/08/26 19:27:28 step 5: objective=0.035600923
2017/08/26 19:27:33 step 6: objective=0.035649303
2017/08/26 19:27:37 step 7: objective=0.035695218
2017/08/26 19:27:37 Training value function...
2017/08/26 19:27:38 step 0: mse=0.837729 step=0.100000
2017/08/26 19:27:39 step 1: mse=0.795116 step=0.100000
2017/08/26 19:27:39 step 2: mse=0.760307 step=0.100000
2017/08/26 19:27:40 step 3: mse=0.731929 step=0.100000
2017/08/26 19:27:40 step 4: mse=0.707103 step=0.100000
2017/08/26 19:27:41 step 5: mse=0.689042 step=0.100000
2017/08/26 19:27:41 step 6: mse=0.664809 step=0.100000
2017/08/26 19:27:42 step 7: mse=0.651585 step=0.100000
2017/08/26 19:27:42 Saving...
2017/08/26 19:27:42 Gathering batch of experience...
2017/08/26 19:28:01 batch 18: mean=19.512195 stddev=8.664821 entropy=1.040555 frames=37767 count=41
2017/08/26 19:28:01 Training policy...
2017/08/26 19:28:07 step 0: objective=0.041247915
2017/08/26 19:28:11 step 1: objective=0.041307632
2017/08/26 19:28:16 step 2: objective=0.041367833
2017/08/26 19:28:21 step 3: objective=0.04142771
2017/08/26 19:28:25 step 4: objective=0.041480795
2017/08/26 19:28:30 step 5: objective=0.041535076
2017/08/26 19:28:35 step 6: objective=0.041576307
2017/08/26 19:28:39 step 7: objective=0.041606635
2017/08/26 19:28:39 Training value function...
2017/08/26 19:28:40 step 0: mse=1.216563 step=0.100000
2017/08/26 19:28:41 step 1: mse=1.117706 step=0.100000
2017/08/26 19:28:41 step 2: mse=1.033722 step=0.100000
2017/08/26 19:28:42 step 3: mse=0.964757 step=0.100000
2017/08/26 19:28:42 step 4: mse=0.906124 step=0.100000
2017/08/26 19:28:43 step 5: mse=0.857570 step=0.100000
2017/08/26 19:28:43 step 6: mse=0.815860 step=0.100000
2017/08/26 19:28:44 step 7: mse=0.773354 step=0.100000
2017/08/26 19:28:44 Saving...
2017/08/26 19:28:44 Gathering batch of experience...
2017/08/26 19:29:03 batch 19: mean=18.357143 stddev=6.671979 entropy=1.049136 frames=36408 count=42
2017/08/26 19:29:03 Training policy...
2017/08/26 19:29:08 step 0: objective=0.056323767
2017/08/26 19:29:12 step 1: objective=0.05639413
2017/08/26 19:29:17 step 2: objective=0.0564645
2017/08/26 19:29:21 step 3: objective=0.05653418
2017/08/26 19:29:26 step 4: objective=0.05660208
2017/08/26 19:29:30 step 5: objective=0.05666256
2017/08/26 19:29:35 step 6: objective=0.0567141
2017/08/26 19:29:39 step 7: objective=0.05675629
2017/08/26 19:29:39 Training value function...
2017/08/26 19:29:40 step 0: mse=1.201162 step=0.100000
2017/08/26 19:29:41 step 1: mse=1.146924 step=0.100000
2017/08/26 19:29:41 step 2: mse=1.094385 step=0.100000
2017/08/26 19:29:42 step 3: mse=1.029369 step=0.100000
2017/08/26 19:29:42 step 4: mse=0.997303 step=0.100000
2017/08/26 19:29:43 step 5: mse=0.948138 step=0.100000
2017/08/26 19:29:43 step 6: mse=0.910940 step=0.100000
2017/08/26 19:29:44 step 7: mse=0.885428 step=0.100000
2017/08/26 19:29:44 Saving...
2017/08/26 19:29:44 Gathering batch of experience...
2017/08/26 19:30:03 batch 20: mean=17.744186 stddev=8.480053 entropy=1.037266 frames=38005 count=43
2017/08/26 19:30:03 Training policy...
2017/08/26 19:30:09 step 0: objective=-0.0037739605
2017/08/26 19:30:14 step 1: objective=-0.0037297371
2017/08/26 19:30:18 step 2: objective=-0.0036849852
2017/08/26 19:30:23 step 3: objective=-0.0036401267
2017/08/26 19:30:28 step 4: objective=-0.0036055408
2017/08/26 19:30:33 step 5: objective=-0.0035658367
2017/08/26 19:30:37 step 6: objective=-0.0035268487
2017/08/26 19:30:42 step 7: objective=-0.0034907893
2017/08/26 19:30:42 Training value function...
2017/08/26 19:30:43 step 0: mse=1.110301 step=0.100000
2017/08/26 19:30:44 step 1: mse=1.037397 step=0.100000
2017/08/26 19:30:44 step 2: mse=0.976104 step=0.100000
2017/08/26 19:30:45 step 3: mse=0.924570 step=0.100000
2017/08/26 19:30:45 step 4: mse=0.884179 step=0.100000
2017/08/26 19:30:46 step 5: mse=0.851860 step=0.100000
2017/08/26 19:30:46 step 6: mse=0.810230 step=0.100000
2017/08/26 19:30:47 step 7: mse=0.785723 step=0.100000
2017/08/26 19:30:47 Saving...
2017/08/26 19:30:47 Gathering batch of experience...
2017/08/26 19:31:06 batch 21: mean=16.750000 stddev=8.707690 entropy=1.041193 frames=36706 count=44
2017/08/26 19:31:06 Training policy...
2017/08/26 19:31:11 step 0: objective=0.011859328
2017/08/26 19:31:16 step 1: objective=0.01190867
2017/08/26 19:31:20 step 2: objective=0.011957774
2017/08/26 19:31:25 step 3: objective=0.011992916
2017/08/26 19:31:30 step 4: objective=0.01202793
2017/08/26 19:31:34 step 5: objective=0.012062846
2017/08/26 19:31:39 step 6: objective=0.012096814
2017/08/26 19:31:43 step 7: objective=0.012157404
2017/08/26 19:31:43 Training value function...
2017/08/26 19:31:44 step 0: mse=0.747038 step=0.100000
2017/08/26 19:31:45 step 1: mse=0.708297 step=0.100000
2017/08/26 19:31:45 step 2: mse=0.677213 step=0.100000
2017/08/26 19:31:46 step 3: mse=0.650655 step=0.100000
2017/08/26 19:31:46 step 4: mse=0.635531 step=0.100000
2017/08/26 19:31:47 step 5: mse=0.622225 step=0.100000
2017/08/26 19:31:47 step 6: mse=0.611499 step=0.100000
2017/08/26 19:31:48 step 7: mse=0.591847 step=0.100000
2017/08/26 19:31:48 Saving...
2017/08/26 19:31:48 Gathering batch of experience...
2017/08/26 19:32:07 batch 22: mean=15.978261 stddev=6.879361 entropy=1.038964 frames=37104 count=46
2017/08/26 19:32:07 Training policy...
2017/08/26 19:32:12 step 0: objective=0.031932198
2017/08/26 19:32:17 step 1: objective=0.031989783
2017/08/26 19:32:22 step 2: objective=0.0320478
2017/08/26 19:32:26 step 3: objective=0.032105345
2017/08/26 19:32:31 step 4: objective=0.032162856
2017/08/26 19:32:35 step 5: objective=0.03221867
2017/08/26 19:32:40 step 6: objective=0.03224713
2017/08/26 19:32:44 step 7: objective=0.032274168
2017/08/26 19:32:44 Training value function...
2017/08/26 19:32:45 step 0: mse=0.850108 step=0.100000
2017/08/26 19:32:46 step 1: mse=0.797644 step=0.100000
2017/08/26 19:32:46 step 2: mse=0.756304 step=0.100000
2017/08/26 19:32:47 step 3: mse=0.718301 step=0.100000
2017/08/26 19:32:48 step 4: mse=0.687563 step=0.100000
2017/08/26 19:32:48 step 5: mse=0.664262 step=0.100000
2017/08/26 19:32:49 step 6: mse=0.638163 step=0.100000
2017/08/26 19:32:49 step 7: mse=0.621545 step=0.100000
2017/08/26 19:32:49 Saving...
2017/08/26 19:32:49 Gathering batch of experience...
2017/08/26 19:33:08 batch 23: mean=18.750000 stddev=9.710175 entropy=1.040717 frames=36578 count=40
2017/08/26 19:33:08 Training policy...
2017/08/26 19:33:13 step 0: objective=0.046302717
2017/08/26 19:33:18 step 1: objective=0.04633226
2017/08/26 19:33:23 step 2: objective=0.046361808
2017/08/26 19:33:27 step 3: objective=0.0463914
2017/08/26 19:33:32 step 4: objective=0.046421036
2017/08/26 19:33:36 step 5: objective=0.046450697
2017/08/26 19:33:41 step 6: objective=0.046478175
2017/08/26 19:33:45 step 7: objective=0.04650287
2017/08/26 19:33:45 Training value function...
2017/08/26 19:33:46 step 0: mse=1.221094 step=0.100000
2017/08/26 19:33:47 step 1: mse=1.100580 step=0.100000
2017/08/26 19:33:47 step 2: mse=1.003440 step=0.100000
2017/08/26 19:33:48 step 3: mse=0.923888 step=0.100000
2017/08/26 19:33:48 step 4: mse=0.860969 step=0.100000
2017/08/26 19:33:49 step 5: mse=0.809720 step=0.100000
2017/08/26 19:33:50 step 6: mse=0.772269 step=0.100000
2017/08/26 19:33:50 step 7: mse=0.741306 step=0.100000
2017/08/26 19:33:50 Saving...
2017/08/26 19:33:50 Gathering batch of experience...
2017/08/26 19:34:09 batch 24: mean=18.463415 stddev=7.654419 entropy=1.035903 frames=37125 count=41
2017/08/26 19:34:09 Training policy...
2017/08/26 19:34:15 step 0: objective=0.045024034
2017/08/26 19:34:19 step 1: objective=0.045070983
2017/08/26 19:34:24 step 2: objective=0.045118093
2017/08/26 19:34:28 step 3: objective=0.045165133
2017/08/26 19:34:33 step 4: objective=0.045212086
2017/08/26 19:34:38 step 5: objective=0.045256678
2017/08/26 19:34:42 step 6: objective=0.045294054
2017/08/26 19:34:47 step 7: objective=0.0453264
2017/08/26 19:34:47 Training value function...
2017/08/26 19:34:48 step 0: mse=1.201955 step=0.100000
2017/08/26 19:34:48 step 1: mse=1.118190 step=0.100000
2017/08/26 19:34:49 step 2: mse=1.045531 step=0.100000
2017/08/26 19:34:49 step 3: mse=0.991459 step=0.100000
2017/08/26 19:34:50 step 4: mse=0.942815 step=0.100000
2017/08/26 19:34:50 step 5: mse=0.894126 step=0.100000
2017/08/26 19:34:51 step 6: mse=0.853299 step=0.100000
2017/08/26 19:34:52 step 7: mse=0.820265 step=0.100000
2017/08/26 19:34:52 Saving...
2017/08/26 19:34:52 Gathering batch of experience...
2017/08/26 19:35:11 batch 25: mean=18.023256 stddev=6.373960 entropy=1.034315 frames=37620 count=43
2017/08/26 19:35:11 Training policy...
2017/08/26 19:35:17 step 0: objective=0.038955353
2017/08/26 19:35:21 step 1: objective=0.039018676
2017/08/26 19:35:26 step 2: objective=0.039082244
2017/08/26 19:35:31 step 3: objective=0.03913854
2017/08/26 19:35:35 step 4: objective=0.03920175
2017/08/26 19:35:40 step 5: objective=0.03925845
2017/08/26 19:35:45 step 6: objective=0.039320633
2017/08/26 19:35:49 step 7: objective=0.03940803
2017/08/26 19:35:49 Training value function...
2017/08/26 19:35:50 step 0: mse=0.969948 step=0.100000
2017/08/26 19:35:51 step 1: mse=0.912037 step=0.100000
2017/08/26 19:35:51 step 2: mse=0.854972 step=0.100000
2017/08/26 19:35:52 step 3: mse=0.809785 step=0.100000
2017/08/26 19:35:52 step 4: mse=0.770899 step=0.100000
2017/08/26 19:35:53 step 5: mse=0.733366 step=0.100000
2017/08/26 19:35:53 step 6: mse=0.708322 step=0.100000
2017/08/26 19:35:54 step 7: mse=0.682057 step=0.100000
2017/08/26 19:35:54 Saving...
2017/08/26 19:35:54 Gathering batch of experience...
2017/08/26 19:36:13 batch 26: mean=19.075000 stddev=7.065364 entropy=1.038316 frames=36836 count=40
2017/08/26 19:36:13 Training policy...
2017/08/26 19:36:18 step 0: objective=0.0388389
2017/08/26 19:36:23 step 1: objective=0.038879495
2017/08/26 19:36:28 step 2: objective=0.038920376
2017/08/26 19:36:32 step 3: objective=0.038941633
2017/08/26 19:36:37 step 4: objective=0.038962744
2017/08/26 19:36:41 step 5: objective=0.038984157
2017/08/26 19:36:46 step 6: objective=0.03900535
2017/08/26 19:36:51 step 7: objective=0.039023727
2017/08/26 19:36:51 Training value function...
2017/08/26 19:36:52 step 0: mse=0.884271 step=0.100000
2017/08/26 19:36:52 step 1: mse=0.825132 step=0.100000
2017/08/26 19:36:53 step 2: mse=0.775391 step=0.100000
2017/08/26 19:36:53 step 3: mse=0.736164 step=0.100000
2017/08/26 19:36:54 step 4: mse=0.702505 step=0.100000
2017/08/26 19:36:54 step 5: mse=0.676860 step=0.100000
2017/08/26 19:36:55 step 6: mse=0.653553 step=0.100000
2017/08/26 19:36:55 step 7: mse=0.629161 step=0.100000
2017/08/26 19:36:55 Saving...
2017/08/26 19:36:55 Gathering batch of experience...
2017/08/26 19:37:14 batch 27: mean=16.500000 stddev=6.614378 entropy=1.049625 frames=35930 count=44
2017/08/26 19:37:14 Training policy...
2017/08/26 19:37:19 step 0: objective=0.0169725
2017/08/26 19:37:24 step 1: objective=0.017049829
2017/08/26 19:37:28 step 2: objective=0.017127406
2017/08/26 19:37:32 step 3: objective=0.017205112
2017/08/26 19:37:37 step 4: objective=0.017282553
2017/08/26 19:37:41 step 5: objective=0.01735227
2017/08/26 19:37:46 step 6: objective=0.017408
2017/08/26 19:37:50 step 7: objective=0.0174451
2017/08/26 19:37:50 Training value function...
2017/08/26 19:37:51 step 0: mse=0.946573 step=0.100000
2017/08/26 19:37:52 step 1: mse=0.904985 step=0.100000
2017/08/26 19:37:52 step 2: mse=0.864465 step=0.100000
2017/08/26 19:37:53 step 3: mse=0.819903 step=0.100000
2017/08/26 19:37:53 step 4: mse=0.798568 step=0.100000
2017/08/26 19:37:54 step 5: mse=0.787321 step=0.100000
2017/08/26 19:37:54 step 6: mse=0.764908 step=0.100000
2017/08/26 19:37:55 step 7: mse=0.747374 step=0.100000
2017/08/26 19:37:55 Saving...
2017/08/26 19:37:55 Gathering batch of experience...
2017/08/26 19:38:14 batch 28: mean=16.133333 stddev=6.005923 entropy=1.056145 frames=37014 count=45
2017/08/26 19:38:14 Training policy...
2017/08/26 19:38:20 step 0: objective=0.019750014
2017/08/26 19:38:24 step 1: objective=0.01980866
2017/08/26 19:38:29 step 2: objective=0.019866792
2017/08/26 19:38:33 step 3: objective=0.019924864
2017/08/26 19:38:38 step 4: objective=0.01998249
2017/08/26 19:38:43 step 5: objective=0.020036792
2017/08/26 19:38:47 step 6: objective=0.020100957
2017/08/26 19:38:52 step 7: objective=0.020145187
2017/08/26 19:38:52 Training value function...
2017/08/26 19:38:53 step 0: mse=0.815942 step=0.100000
2017/08/26 19:38:53 step 1: mse=0.761082 step=0.100000
2017/08/26 19:38:54 step 2: mse=0.718279 step=0.100000
2017/08/26 19:38:55 step 3: mse=0.678035 step=0.100000
2017/08/26 19:38:55 step 4: mse=0.645964 step=0.100000
2017/08/26 19:38:56 step 5: mse=0.618532 step=0.100000
2017/08/26 19:38:56 step 6: mse=0.597729 step=0.100000
2017/08/26 19:38:57 step 7: mse=0.576723 step=0.100000
2017/08/26 19:38:57 Saving...
2017/08/26 19:38:57 Gathering batch of experience...
2017/08/26 19:39:16 batch 29: mean=17.523810 stddev=7.916944 entropy=1.036185 frames=36638 count=42
2017/08/26 19:39:16 Training policy...
2017/08/26 19:39:21 step 0: objective=0.03564944
2017/08/26 19:39:26 step 1: objective=0.035704277
2017/08/26 19:39:31 step 2: objective=0.035759293
2017/08/26 19:39:35 step 3: objective=0.035813615
2017/08/26 19:39:40 step 4: objective=0.035863895
2017/08/26 19:39:44 step 5: objective=0.0359129
2017/08/26 19:39:49 step 6: objective=0.03597768
2017/08/26 19:39:53 step 7: objective=0.035998788
2017/08/26 19:39:53 Training value function...
2017/08/26 19:39:54 step 0: mse=1.032279 step=0.100000
2017/08/26 19:39:55 step 1: mse=0.952443 step=0.100000
2017/08/26 19:39:56 step 2: mse=0.886884 step=0.100000
2017/08/26 19:39:56 step 3: mse=0.833703 step=0.100000
2017/08/26 19:39:57 step 4: mse=0.792380 step=0.100000
2017/08/26 19:39:57 step 5: mse=0.758217 step=0.100000
2017/08/26 19:39:58 step 6: mse=0.725867 step=0.100000
2017/08/26 19:39:59 step 7: mse=0.700173 step=0.100000
2017/08/26 19:39:59 Saving...
2017/08/26 19:39:59 Gathering batch of experience...
2017/08/26 19:40:17 batch 30: mean=18.325581 stddev=8.528259 entropy=1.041711 frames=36458 count=43
2017/08/26 19:40:17 Training policy...
2017/08/26 19:40:23 step 0: objective=0.04338353
2017/08/26 19:40:28 step 1: objective=0.043458637
2017/08/26 19:40:32 step 2: objective=0.043533
2017/08/26 19:40:37 step 3: objective=0.043607246
2017/08/26 19:40:41 step 4: objective=0.04366618
2017/08/26 19:40:46 step 5: objective=0.043704197
2017/08/26 19:40:50 step 6: objective=0.043735962
2017/08/26 19:40:55 step 7: objective=0.043777175
2017/08/26 19:40:55 Training value function...
2017/08/26 19:40:56 step 0: mse=1.672359 step=0.100000
2017/08/26 19:40:57 step 1: mse=1.511722 step=0.100000
2017/08/26 19:40:57 step 2: mse=1.383941 step=0.100000
2017/08/26 19:40:58 step 3: mse=1.278114 step=0.100000
2017/08/26 19:40:58 step 4: mse=1.191335 step=0.100000
2017/08/26 19:40:59 step 5: mse=1.121301 step=0.100000
2017/08/26 19:41:00 step 6: mse=1.055348 step=0.100000
2017/08/26 19:41:00 step 7: mse=0.999528 step=0.100000
2017/08/26 19:41:00 Saving...
2017/08/26 19:41:07 Gathering batch of experience...
2017/08/26 19:41:26 batch 31: mean=19.357143 stddev=8.695432 entropy=1.036889 frames=36411 count=42
2017/08/26 19:41:26 Training policy...
2017/08/26 19:41:31 step 0: objective=0.03357383
2017/08/26 19:41:36 step 1: objective=0.033644535
2017/08/26 19:41:40 step 2: objective=0.033714518
2017/08/26 19:41:45 step 3: objective=0.033784118
2017/08/26 19:41:49 step 4: objective=0.03385253
2017/08/26 19:41:54 step 5: objective=0.033908457
2017/08/26 19:41:59 step 6: objective=0.034006115
2017/08/26 19:42:03 step 7: objective=0.034096457
2017/08/26 19:42:03 Training value function...
2017/08/26 19:42:04 step 0: mse=1.302613 step=0.100000
2017/08/26 19:42:05 step 1: mse=1.227112 step=0.100000
2017/08/26 19:42:05 step 2: mse=1.166451 step=0.100000
2017/08/26 19:42:06 step 3: mse=1.116078 step=0.100000
2017/08/26 19:42:06 step 4: mse=1.080913 step=0.100000
2017/08/26 19:42:07 step 5: mse=1.050961 step=0.100000
2017/08/26 19:42:08 step 6: mse=1.001586 step=0.100000
2017/08/26 19:42:08 step 7: mse=0.976194 step=0.100000
2017/08/26 19:42:08 Saving...
2017/08/26 19:42:08 Gathering batch of experience...
2017/08/26 19:42:27 batch 32: mean=16.511628 stddev=7.387520 entropy=1.039070 frames=36042 count=43
2017/08/26 19:42:27 Training policy...
2017/08/26 19:42:32 step 0: objective=0.002356306
2017/08/26 19:42:37 step 1: objective=0.002394797
2017/08/26 19:42:42 step 2: objective=0.0024333983
2017/08/26 19:42:46 step 3: objective=0.002472172
2017/08/26 19:42:51 step 4: objective=0.0025110974
2017/08/26 19:42:55 step 5: objective=0.0025451495
2017/08/26 19:43:00 step 6: objective=0.0025817186
2017/08/26 19:43:04 step 7: objective=0.0026294591
2017/08/26 19:43:04 Training value function...
2017/08/26 19:43:05 step 0: mse=0.962800 step=0.100000
2017/08/26 19:43:06 step 1: mse=0.908056 step=0.100000
2017/08/26 19:43:06 step 2: mse=0.864563 step=0.100000
2017/08/26 19:43:07 step 3: mse=0.829943 step=0.100000
2017/08/26 19:43:08 step 4: mse=0.798092 step=0.100000
2017/08/26 19:43:08 step 5: mse=0.775444 step=0.100000
2017/08/26 19:43:09 step 6: mse=0.743682 step=0.100000
2017/08/26 19:43:09 step 7: mse=0.718279 step=0.100000
2017/08/26 19:43:09 Saving...
2017/08/26 19:43:09 Gathering batch of experience...
2017/08/26 19:43:29 batch 33: mean=17.906977 stddev=8.379970 entropy=1.041732 frames=38031 count=43
2017/08/26 19:43:29 Training policy...
2017/08/26 19:43:35 step 0: objective=0.04469782
2017/08/26 19:43:40 step 1: objective=0.044783797
2017/08/26 19:43:45 step 2: objective=0.044869833
2017/08/26 19:43:49 step 3: objective=0.044955287
2017/08/26 19:43:54 step 4: objective=0.045036037
2017/08/26 19:43:59 step 5: objective=0.045091156
2017/08/26 19:44:04 step 6: objective=0.045144897
2017/08/26 19:44:09 step 7: objective=0.045196246
2017/08/26 19:44:09 Training value function...
2017/08/26 19:44:10 step 0: mse=1.146738 step=0.100000
2017/08/26 19:44:10 step 1: mse=1.064814 step=0.100000
2017/08/26 19:44:11 step 2: mse=0.998235 step=0.100000
2017/08/26 19:44:11 step 3: mse=0.942621 step=0.100000
2017/08/26 19:44:12 step 4: mse=0.896284 step=0.100000
2017/08/26 19:44:13 step 5: mse=0.850134 step=0.100000
2017/08/26 19:44:13 step 6: mse=0.800049 step=0.100000
2017/08/26 19:44:14 step 7: mse=0.754208 step=0.100000
2017/08/26 19:44:14 Saving...
2017/08/26 19:44:14 Gathering batch of experience...
2017/08/26 19:44:33 batch 34: mean=17.292683 stddev=7.680333 entropy=1.038197 frames=37115 count=41
2017/08/26 19:44:33 Training policy...
2017/08/26 19:44:39 step 0: objective=0.0073984494
2017/08/26 19:44:44 step 1: objective=0.007451978
2017/08/26 19:44:49 step 2: objective=0.0075056115
2017/08/26 19:44:53 step 3: objective=0.0075592906
2017/08/26 19:44:58 step 4: objective=0.007610002
2017/08/26 19:45:03 step 5: objective=0.0076560066
2017/08/26 19:45:07 step 6: objective=0.007692334
2017/08/26 19:45:12 step 7: objective=0.0077651595
2017/08/26 19:45:12 Training value function...
2017/08/26 19:45:13 step 0: mse=0.833048 step=0.100000
2017/08/26 19:45:14 step 1: mse=0.774774 step=0.100000
2017/08/26 19:45:14 step 2: mse=0.727552 step=0.100000
2017/08/26 19:45:15 step 3: mse=0.688229 step=0.100000
2017/08/26 19:45:16 step 4: mse=0.655726 step=0.100000
2017/08/26 19:45:16 step 5: mse=0.623754 step=0.100000
2017/08/26 19:45:17 step 6: mse=0.598769 step=0.100000
2017/08/26 19:45:17 step 7: mse=0.575404 step=0.100000
2017/08/26 19:45:17 Saving...
2017/08/26 19:45:17 Gathering batch of experience...
