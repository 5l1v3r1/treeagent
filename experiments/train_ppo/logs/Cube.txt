2017/08/29 13:52:12 Run with arguments: [-algo mse -env Cube -step 10 -valstep 0.05 -iters 8 -valiters 8 -discount 1 -critic Cube/critic.json -actor Cube/actor.json -depth 4 -minleaf 1024 -batch 100000 -reg 0.01 -decay 0.99 -maxtrees 500]
2017/08/29 13:52:12 Creating environments...
2017/08/29 13:52:12 Creating new forest for: Cube/actor.json
2017/08/29 13:52:12 Creating new forest for: Cube/critic.json
2017/08/29 13:52:12 Running. Press Ctrl+C to stop.
2017/08/29 13:52:12 Gathering batch of experience...
2017/08/29 13:52:34 batch 0: mean=1.722788 stddev=1.111807 entropy=2.890417 frames=100140 count=5007
2017/08/29 13:52:34 Training policy...
2017/08/29 13:52:43 step 0: objective=0.483799 reg=0.028890
2017/08/29 13:52:48 step 1: objective=0.483861 reg=0.028879
2017/08/29 13:52:53 step 2: objective=0.469722 reg=0.028833
2017/08/29 13:52:58 step 3: objective=0.463051 reg=0.028824
2017/08/29 13:53:02 step 4: objective=0.476877 reg=0.028848
2017/08/29 13:53:07 step 5: objective=0.472221 reg=0.028827
2017/08/29 13:53:12 step 6: objective=0.468770 reg=0.028815
2017/08/29 13:53:17 step 7: objective=0.473013 reg=0.028825
2017/08/29 13:53:17 Training value function...
2017/08/29 13:53:22 step 0: mse=1.249261 step=0.050000
2017/08/29 13:53:24 step 1: mse=1.176806 step=0.050000
2017/08/29 13:53:27 step 2: mse=1.111996 step=0.050000
2017/08/29 13:53:30 step 3: mse=1.054018 step=0.050000
2017/08/29 13:53:32 step 4: mse=1.002112 step=0.050000
2017/08/29 13:53:35 step 5: mse=0.955596 step=0.050000
2017/08/29 13:53:38 step 6: mse=0.913893 step=0.050000
2017/08/29 13:53:41 step 7: mse=0.876480 step=0.050000
2017/08/29 13:53:41 Saving...
2017/08/29 13:53:41 Gathering batch of experience...
2017/08/29 13:54:04 batch 1: mean=1.787897 stddev=1.112841 entropy=2.881823 frames=100140 count=5007
2017/08/29 13:54:04 Training policy...
2017/08/29 13:54:13 step 0: objective=0.345207 reg=0.028812
2017/08/29 13:54:17 step 1: objective=0.346197 reg=0.028804
2017/08/29 13:54:22 step 2: objective=0.344672 reg=0.028797
2017/08/29 13:54:27 step 3: objective=0.343335 reg=0.028784
2017/08/29 13:54:32 step 4: objective=0.342925 reg=0.028778
2017/08/29 13:54:36 step 5: objective=0.341824 reg=0.028780
2017/08/29 13:54:41 step 6: objective=0.342404 reg=0.028773
2017/08/29 13:54:46 step 7: objective=0.343162 reg=0.028770
2017/08/29 13:54:46 Training value function...
2017/08/29 13:54:51 step 0: mse=0.854339 step=0.050000
2017/08/29 13:54:54 step 1: mse=0.821923 step=0.050000
2017/08/29 13:54:57 step 2: mse=0.792788 step=0.050000
2017/08/29 13:54:59 step 3: mse=0.766587 step=0.050000
2017/08/29 13:55:02 step 4: mse=0.742998 step=0.050000
2017/08/29 13:55:05 step 5: mse=0.721737 step=0.050000
2017/08/29 13:55:08 step 6: mse=0.702573 step=0.050000
2017/08/29 13:55:10 step 7: mse=0.685285 step=0.050000
2017/08/29 13:55:10 Saving...
2017/08/29 13:55:10 Gathering batch of experience...
2017/08/29 13:55:34 batch 2: mean=1.784502 stddev=1.140121 entropy=2.878494 frames=100140 count=5007
2017/08/29 13:55:34 Training policy...
2017/08/29 13:55:43 step 0: objective=0.260939 reg=0.028774
2017/08/29 13:55:47 step 1: objective=0.262011 reg=0.028768
2017/08/29 13:55:51 step 2: objective=0.262246 reg=0.028763
2017/08/29 13:55:56 step 3: objective=0.261948 reg=0.028755
2017/08/29 13:56:01 step 4: objective=0.261653 reg=0.028752
2017/08/29 13:56:06 step 5: objective=0.261310 reg=0.028743
2017/08/29 13:56:11 step 6: objective=0.261740 reg=0.028748
2017/08/29 13:56:16 step 7: objective=0.261765 reg=0.028743
2017/08/29 13:56:16 Training value function...
2017/08/29 13:56:21 step 0: mse=0.703369 step=0.050000
2017/08/29 13:56:23 step 1: mse=0.688071 step=0.050000
2017/08/29 13:56:26 step 2: mse=0.674241 step=0.050000
2017/08/29 13:56:29 step 3: mse=0.661724 step=0.050000
2017/08/29 13:56:32 step 4: mse=0.650381 step=0.050000
2017/08/29 13:56:34 step 5: mse=0.640099 step=0.050000
2017/08/29 13:56:37 step 6: mse=0.630753 step=0.050000
2017/08/29 13:56:40 step 7: mse=0.622262 step=0.050000
2017/08/29 13:56:40 Saving...
2017/08/29 13:56:40 Gathering batch of experience...
2017/08/29 13:57:03 batch 3: mean=1.799680 stddev=1.141312 entropy=2.875935 frames=100140 count=5007
2017/08/29 13:57:03 Training policy...
2017/08/29 13:57:12 step 0: objective=0.202644 reg=0.028748
2017/08/29 13:57:17 step 1: objective=0.203955 reg=0.028744
2017/08/29 13:57:21 step 2: objective=0.204347 reg=0.028735
2017/08/29 13:57:26 step 3: objective=0.204824 reg=0.028732
2017/08/29 13:57:31 step 4: objective=0.205059 reg=0.028726
2017/08/29 13:57:36 step 5: objective=0.205553 reg=0.028724
2017/08/29 13:57:41 step 6: objective=0.205725 reg=0.028723
2017/08/29 13:57:46 step 7: objective=0.206279 reg=0.028723
2017/08/29 13:57:46 Training value function...
2017/08/29 13:57:51 step 0: mse=0.633949 step=0.050000
2017/08/29 13:57:53 step 1: mse=0.626731 step=0.050000
2017/08/29 13:57:56 step 2: mse=0.620167 step=0.050000
2017/08/29 13:57:59 step 3: mse=0.614192 step=0.050000
2017/08/29 13:58:02 step 4: mse=0.608723 step=0.050000
2017/08/29 13:58:04 step 5: mse=0.603734 step=0.050000
2017/08/29 13:58:07 step 6: mse=0.599172 step=0.050000
2017/08/29 13:58:10 step 7: mse=0.594989 step=0.050000
2017/08/29 13:58:10 Saving...
2017/08/29 13:58:10 Gathering batch of experience...
2017/08/29 13:58:33 batch 4: mean=1.867186 stddev=1.144160 entropy=2.872545 frames=100140 count=5007
2017/08/29 13:58:33 Training policy...
2017/08/29 13:58:42 step 0: objective=0.193608 reg=0.028722
2017/08/29 13:58:46 step 1: objective=0.194946 reg=0.028713
2017/08/29 13:58:50 step 2: objective=0.194929 reg=0.028704
2017/08/29 13:58:54 step 3: objective=0.195258 reg=0.028698
2017/08/29 13:58:59 step 4: objective=0.195427 reg=0.028694
2017/08/29 13:59:03 step 5: objective=0.195808 reg=0.028691
2017/08/29 13:59:07 step 6: objective=0.196488 reg=0.028684
2017/08/29 13:59:12 step 7: objective=0.196813 reg=0.028687
2017/08/29 13:59:12 Training value function...
2017/08/29 13:59:17 step 0: mse=0.628551 step=0.050000
2017/08/29 13:59:19 step 1: mse=0.622962 step=0.050000
2017/08/29 13:59:22 step 2: mse=0.617857 step=0.050000
2017/08/29 13:59:25 step 3: mse=0.613194 step=0.050000
2017/08/29 13:59:27 step 4: mse=0.608921 step=0.050000
2017/08/29 13:59:30 step 5: mse=0.605006 step=0.050000
2017/08/29 13:59:32 step 6: mse=0.601413 step=0.050000
2017/08/29 13:59:35 step 7: mse=0.598104 step=0.050000
2017/08/29 13:59:35 Saving...
2017/08/29 13:59:35 Gathering batch of experience...
2017/08/29 13:59:59 batch 5: mean=1.934092 stddev=1.174104 entropy=2.868016 frames=100140 count=5007
2017/08/29 13:59:59 Training policy...
2017/08/29 14:00:07 step 0: objective=0.189332 reg=0.028683
2017/08/29 14:00:11 step 1: objective=0.190594 reg=0.028668
2017/08/29 14:00:16 step 2: objective=0.190782 reg=0.028660
2017/08/29 14:00:20 step 3: objective=0.191291 reg=0.028650
2017/08/29 14:00:24 step 4: objective=0.191425 reg=0.028643
2017/08/29 14:00:28 step 5: objective=0.191642 reg=0.028638
2017/08/29 14:00:32 step 6: objective=0.191920 reg=0.028635
2017/08/29 14:00:36 step 7: objective=0.192098 reg=0.028634
2017/08/29 14:00:36 Training value function...
2017/08/29 14:00:41 step 0: mse=0.670175 step=0.050000
2017/08/29 14:00:44 step 1: mse=0.665744 step=0.050000
2017/08/29 14:00:46 step 2: mse=0.661690 step=0.050000
2017/08/29 14:00:49 step 3: mse=0.657986 step=0.050000
2017/08/29 14:00:52 step 4: mse=0.654567 step=0.050000
2017/08/29 14:00:54 step 5: mse=0.651419 step=0.050000
2017/08/29 14:00:57 step 6: mse=0.648523 step=0.050000
2017/08/29 14:01:00 step 7: mse=0.645851 step=0.050000
2017/08/29 14:01:00 Saving...
2017/08/29 14:01:00 Gathering batch of experience...
2017/08/29 14:01:23 batch 6: mean=1.993010 stddev=1.178222 entropy=2.861453 frames=100140 count=5007
2017/08/29 14:01:23 Training policy...
2017/08/29 14:01:32 step 0: objective=0.169245 reg=0.028618
2017/08/29 14:01:36 step 1: objective=0.170396 reg=0.028608
2017/08/29 14:01:40 step 2: objective=0.171291 reg=0.028595
2017/08/29 14:01:44 step 3: objective=0.171778 reg=0.028589
2017/08/29 14:01:49 step 4: objective=0.172288 reg=0.028583
2017/08/29 14:01:53 step 5: objective=0.172890 reg=0.028574
2017/08/29 14:01:57 step 6: objective=0.173433 reg=0.028568
2017/08/29 14:02:01 step 7: objective=0.173985 reg=0.028563
2017/08/29 14:02:01 Training value function...
2017/08/29 14:02:06 step 0: mse=0.627683 step=0.050000
2017/08/29 14:02:09 step 1: mse=0.624840 step=0.050000
2017/08/29 14:02:11 step 2: mse=0.622228 step=0.050000
2017/08/29 14:02:14 step 3: mse=0.619827 step=0.050000
2017/08/29 14:02:17 step 4: mse=0.617614 step=0.050000
2017/08/29 14:02:19 step 5: mse=0.615590 step=0.050000
2017/08/29 14:02:22 step 6: mse=0.613684 step=0.050000
2017/08/29 14:02:25 step 7: mse=0.611941 step=0.050000
2017/08/29 14:02:25 Saving...
2017/08/29 14:02:25 Gathering batch of experience...
2017/08/29 14:02:48 batch 7: mean=2.078690 stddev=1.211010 entropy=2.855501 frames=100140 count=5007
2017/08/29 14:02:48 Training policy...
2017/08/29 14:02:57 step 0: objective=0.201751 reg=0.028557
2017/08/29 14:03:01 step 1: objective=0.202590 reg=0.028544
2017/08/29 14:03:05 step 2: objective=0.203788 reg=0.028529
2017/08/29 14:03:10 step 3: objective=0.204557 reg=0.028519
2017/08/29 14:03:14 step 4: objective=0.204904 reg=0.028505
2017/08/29 14:03:18 step 5: objective=0.205498 reg=0.028501
2017/08/29 14:03:22 step 6: objective=0.206039 reg=0.028498
2017/08/29 14:03:26 step 7: objective=0.206534 reg=0.028485
2017/08/29 14:03:26 Training value function...
2017/08/29 14:03:31 step 0: mse=0.695827 step=0.050000
2017/08/29 14:03:34 step 1: mse=0.690807 step=0.050000
2017/08/29 14:03:37 step 2: mse=0.686210 step=0.050000
2017/08/29 14:03:39 step 3: mse=0.681992 step=0.050000
2017/08/29 14:03:42 step 4: mse=0.678127 step=0.050000
2017/08/29 14:03:45 step 5: mse=0.674568 step=0.050000
2017/08/29 14:03:47 step 6: mse=0.671281 step=0.050000
2017/08/29 14:03:50 step 7: mse=0.668263 step=0.050000
2017/08/29 14:03:50 Saving...
2017/08/29 14:03:50 Gathering batch of experience...
2017/08/29 14:04:13 batch 8: mean=2.150389 stddev=1.230703 entropy=2.846706 frames=100140 count=5007
2017/08/29 14:04:13 Training policy...
2017/08/29 14:04:23 step 0: objective=0.200821 reg=0.028467
2017/08/29 14:04:27 step 1: objective=0.201687 reg=0.028452
2017/08/29 14:04:31 step 2: objective=0.202408 reg=0.028434
2017/08/29 14:04:35 step 3: objective=0.202988 reg=0.028432
2017/08/29 14:04:39 step 4: objective=0.204025 reg=0.028415
2017/08/29 14:04:43 step 5: objective=0.204469 reg=0.028406
2017/08/29 14:04:48 step 6: objective=0.205065 reg=0.028405
2017/08/29 14:04:52 step 7: objective=0.205528 reg=0.028394
2017/08/29 14:04:52 Training value function...
2017/08/29 14:04:57 step 0: mse=0.723874 step=0.050000
2017/08/29 14:05:00 step 1: mse=0.719398 step=0.050000
2017/08/29 14:05:02 step 2: mse=0.715310 step=0.050000
2017/08/29 14:05:05 step 3: mse=0.711571 step=0.050000
2017/08/29 14:05:08 step 4: mse=0.708132 step=0.050000
2017/08/29 14:05:10 step 5: mse=0.704972 step=0.050000
2017/08/29 14:05:13 step 6: mse=0.702066 step=0.050000
2017/08/29 14:05:16 step 7: mse=0.699375 step=0.050000
2017/08/29 14:05:16 Saving...
2017/08/29 14:05:16 Gathering batch of experience...
2017/08/29 14:05:39 batch 9: mean=2.244258 stddev=1.245745 entropy=2.838351 frames=100140 count=5007
2017/08/29 14:05:39 Training policy...
2017/08/29 14:05:49 step 0: objective=0.205249 reg=0.028384
2017/08/29 14:05:53 step 1: objective=0.206540 reg=0.028359
2017/08/29 14:05:57 step 2: objective=0.206913 reg=0.028345
2017/08/29 14:06:01 step 3: objective=0.207404 reg=0.028328
2017/08/29 14:06:06 step 4: objective=0.207552 reg=0.028322
2017/08/29 14:06:10 step 5: objective=0.207684 reg=0.028307
2017/08/29 14:06:14 step 6: objective=0.208065 reg=0.028314
2017/08/29 14:06:18 step 7: objective=0.208716 reg=0.028304
2017/08/29 14:06:18 Training value function...
2017/08/29 14:06:23 step 0: mse=0.745605 step=0.050000
2017/08/29 14:06:26 step 1: mse=0.740640 step=0.050000
2017/08/29 14:06:29 step 2: mse=0.736070 step=0.050000
2017/08/29 14:06:31 step 3: mse=0.731911 step=0.050000
2017/08/29 14:06:34 step 4: mse=0.728078 step=0.050000
2017/08/29 14:06:37 step 5: mse=0.724557 step=0.050000
2017/08/29 14:06:40 step 6: mse=0.721310 step=0.050000
2017/08/29 14:06:42 step 7: mse=0.718316 step=0.050000
2017/08/29 14:06:42 Saving...
2017/08/29 14:06:42 Gathering batch of experience...
2017/08/29 14:07:06 batch 10: mean=2.311963 stddev=1.259968 entropy=2.828538 frames=100140 count=5007
2017/08/29 14:07:06 Training policy...
2017/08/29 14:07:15 step 0: objective=0.202757 reg=0.028286
2017/08/29 14:07:19 step 1: objective=0.204054 reg=0.028256
2017/08/29 14:07:24 step 2: objective=0.204975 reg=0.028232
2017/08/29 14:07:28 step 3: objective=0.205205 reg=0.028218
2017/08/29 14:07:32 step 4: objective=0.205546 reg=0.028213
2017/08/29 14:07:36 step 5: objective=0.205802 reg=0.028200
2017/08/29 14:07:40 step 6: objective=0.205995 reg=0.028184
2017/08/29 14:07:44 step 7: objective=0.206227 reg=0.028179
2017/08/29 14:07:44 Training value function...
2017/08/29 14:07:50 step 0: mse=0.790980 step=0.050000
2017/08/29 14:07:52 step 1: mse=0.787214 step=0.050000
2017/08/29 14:07:55 step 2: mse=0.783758 step=0.050000
2017/08/29 14:07:58 step 3: mse=0.780584 step=0.050000
2017/08/29 14:08:00 step 4: mse=0.777663 step=0.050000
2017/08/29 14:08:03 step 5: mse=0.774932 step=0.050000
2017/08/29 14:08:06 step 6: mse=0.772427 step=0.050000
2017/08/29 14:08:09 step 7: mse=0.770106 step=0.050000
2017/08/29 14:08:09 Saving...
2017/08/29 14:08:09 Gathering batch of experience...
2017/08/29 14:08:32 batch 11: mean=2.406231 stddev=1.291978 entropy=2.816203 frames=100140 count=5007
2017/08/29 14:08:32 Training policy...
2017/08/29 14:08:41 step 0: objective=0.221311 reg=0.028162
2017/08/29 14:08:46 step 1: objective=0.222205 reg=0.028141
2017/08/29 14:08:50 step 2: objective=0.222990 reg=0.028127
2017/08/29 14:08:54 step 3: objective=0.223199 reg=0.028130
2017/08/29 14:08:58 step 4: objective=0.224019 reg=0.028108
2017/08/29 14:09:02 step 5: objective=0.224616 reg=0.028092
2017/08/29 14:09:07 step 6: objective=0.225236 reg=0.028074
2017/08/29 14:09:11 step 7: objective=0.225436 reg=0.028059
2017/08/29 14:09:11 Training value function...
2017/08/29 14:09:16 step 0: mse=0.830209 step=0.050000
2017/08/29 14:09:19 step 1: mse=0.824939 step=0.050000
2017/08/29 14:09:21 step 2: mse=0.820116 step=0.050000
2017/08/29 14:09:24 step 3: mse=0.815684 step=0.050000
2017/08/29 14:09:27 step 4: mse=0.811603 step=0.050000
2017/08/29 14:09:30 step 5: mse=0.807834 step=0.050000
2017/08/29 14:09:32 step 6: mse=0.804372 step=0.050000
2017/08/29 14:09:35 step 7: mse=0.801138 step=0.050000
2017/08/29 14:09:35 Saving...
2017/08/29 14:09:35 Gathering batch of experience...
2017/08/29 14:09:59 batch 12: mean=2.509686 stddev=1.281389 entropy=2.804688 frames=100140 count=5007
2017/08/29 14:09:59 Training policy...
2017/08/29 14:10:08 step 0: objective=0.231463 reg=0.028047
2017/08/29 14:10:12 step 1: objective=0.232114 reg=0.028023
2017/08/29 14:10:17 step 2: objective=0.233394 reg=0.028007
2017/08/29 14:10:21 step 3: objective=0.234028 reg=0.027993
2017/08/29 14:10:25 step 4: objective=0.234596 reg=0.027989
2017/08/29 14:10:30 step 5: objective=0.235181 reg=0.027968
2017/08/29 14:10:34 step 6: objective=0.235796 reg=0.027963
2017/08/29 14:10:38 step 7: objective=0.236203 reg=0.027946
2017/08/29 14:10:38 Training value function...
2017/08/29 14:10:43 step 0: mse=0.869522 step=0.050000
2017/08/29 14:10:46 step 1: mse=0.864082 step=0.050000
2017/08/29 14:10:49 step 2: mse=0.859102 step=0.050000
2017/08/29 14:10:52 step 3: mse=0.854537 step=0.050000
2017/08/29 14:10:54 step 4: mse=0.850336 step=0.050000
2017/08/29 14:10:57 step 5: mse=0.846464 step=0.050000
2017/08/29 14:11:00 step 6: mse=0.842899 step=0.050000
2017/08/29 14:11:02 step 7: mse=0.839601 step=0.050000
2017/08/29 14:11:02 Saving...
2017/08/29 14:11:02 Gathering batch of experience...
2017/08/29 14:11:26 batch 13: mean=2.601158 stddev=1.316994 entropy=2.791896 frames=100140 count=5007
2017/08/29 14:11:26 Training policy...
2017/08/29 14:11:36 step 0: objective=0.229433 reg=0.027919
2017/08/29 14:11:40 step 1: objective=0.230429 reg=0.027884
2017/08/29 14:11:44 step 2: objective=0.230959 reg=0.027856
2017/08/29 14:11:49 step 3: objective=0.231388 reg=0.027848
2017/08/29 14:11:53 step 4: objective=0.231990 reg=0.027846
2017/08/29 14:11:57 step 5: objective=0.232678 reg=0.027819
2017/08/29 14:12:02 step 6: objective=0.233074 reg=0.027822
2017/08/29 14:12:06 step 7: objective=0.233346 reg=0.027799
2017/08/29 14:12:06 Training value function...
2017/08/29 14:12:11 step 0: mse=0.917540 step=0.050000
2017/08/29 14:12:14 step 1: mse=0.912467 step=0.050000
2017/08/29 14:12:17 step 2: mse=0.907853 step=0.050000
2017/08/29 14:12:20 step 3: mse=0.903560 step=0.050000
2017/08/29 14:12:22 step 4: mse=0.899561 step=0.050000
2017/08/29 14:12:25 step 5: mse=0.895872 step=0.050000
2017/08/29 14:12:28 step 6: mse=0.892473 step=0.050000
2017/08/29 14:12:30 step 7: mse=0.889349 step=0.050000
2017/08/29 14:12:30 Saving...
2017/08/29 14:12:30 Gathering batch of experience...
2017/08/29 14:12:54 batch 14: mean=2.685440 stddev=1.339776 entropy=2.777154 frames=100140 count=5007
2017/08/29 14:12:54 Training policy...
2017/08/29 14:13:04 step 0: objective=0.246270 reg=0.027771
2017/08/29 14:13:08 step 1: objective=0.246979 reg=0.027726
2017/08/29 14:13:12 step 2: objective=0.247608 reg=0.027724
2017/08/29 14:13:17 step 3: objective=0.247924 reg=0.027683
2017/08/29 14:13:21 step 4: objective=0.248081 reg=0.027705
2017/08/29 14:13:25 step 5: objective=0.248787 reg=0.027675
2017/08/29 14:13:30 step 6: objective=0.249220 reg=0.027641
2017/08/29 14:13:34 step 7: objective=0.249853 reg=0.027620
2017/08/29 14:13:34 Training value function...
2017/08/29 14:13:39 step 0: mse=0.965949 step=0.050000
2017/08/29 14:13:42 step 1: mse=0.959635 step=0.050000
2017/08/29 14:13:45 step 2: mse=0.953852 step=0.050000
2017/08/29 14:13:48 step 3: mse=0.948532 step=0.050000
2017/08/29 14:13:50 step 4: mse=0.943660 step=0.050000
2017/08/29 14:13:53 step 5: mse=0.939147 step=0.050000
2017/08/29 14:13:56 step 6: mse=0.934983 step=0.050000
2017/08/29 14:13:58 step 7: mse=0.931134 step=0.050000
2017/08/29 14:13:58 Saving...
2017/08/29 14:13:59 Gathering batch of experience...
2017/08/29 14:14:23 batch 15: mean=2.767525 stddev=1.363992 entropy=2.758720 frames=100140 count=5007
2017/08/29 14:14:23 Training policy...
2017/08/29 14:14:32 step 0: objective=0.248383 reg=0.027587
2017/08/29 14:14:37 step 1: objective=0.248805 reg=0.027542
2017/08/29 14:14:41 step 2: objective=0.250174 reg=0.027501
2017/08/29 14:14:45 step 3: objective=0.250150 reg=0.027484
2017/08/29 14:14:50 step 4: objective=0.250737 reg=0.027460
2017/08/29 14:14:54 step 5: objective=0.251132 reg=0.027441
2017/08/29 14:14:58 step 6: objective=0.251161 reg=0.027455
2017/08/29 14:15:03 step 7: objective=0.251750 reg=0.027427
2017/08/29 14:15:03 Training value function...
2017/08/29 14:15:08 step 0: mse=0.999419 step=0.050000
2017/08/29 14:15:10 step 1: mse=0.993194 step=0.050000
2017/08/29 14:15:13 step 2: mse=0.987491 step=0.050000
2017/08/29 14:15:16 step 3: mse=0.982231 step=0.050000
2017/08/29 14:15:19 step 4: mse=0.977401 step=0.050000
2017/08/29 14:15:22 step 5: mse=0.972935 step=0.050000
2017/08/29 14:15:24 step 6: mse=0.968781 step=0.050000
2017/08/29 14:15:27 step 7: mse=0.964981 step=0.050000
2017/08/29 14:15:27 Saving...
2017/08/29 14:15:27 Gathering batch of experience...
2017/08/29 14:15:51 batch 16: mean=2.875175 stddev=1.374174 entropy=2.740757 frames=100140 count=5007
2017/08/29 14:15:51 Training policy...
2017/08/29 14:16:01 step 0: objective=0.254311 reg=0.027407
2017/08/29 14:16:05 step 1: objective=0.254591 reg=0.027346
2017/08/29 14:16:09 step 2: objective=0.254719 reg=0.027368
2017/08/29 14:16:14 step 3: objective=0.255068 reg=0.027337
2017/08/29 14:16:18 step 4: objective=0.255667 reg=0.027318
2017/08/29 14:16:22 step 5: objective=0.256160 reg=0.027258
2017/08/29 14:16:27 step 6: objective=0.256676 reg=0.027259
2017/08/29 14:16:31 step 7: objective=0.257136 reg=0.027231
2017/08/29 14:16:31 Training value function...
2017/08/29 14:16:36 step 0: mse=1.045497 step=0.050000
2017/08/29 14:16:39 step 1: mse=1.039253 step=0.050000
2017/08/29 14:16:42 step 2: mse=1.033525 step=0.050000
2017/08/29 14:16:45 step 3: mse=1.028277 step=0.050000
2017/08/29 14:16:48 step 4: mse=1.023408 step=0.050000
2017/08/29 14:16:50 step 5: mse=1.018943 step=0.050000
2017/08/29 14:16:53 step 6: mse=1.014795 step=0.050000
2017/08/29 14:16:56 step 7: mse=1.010977 step=0.050000
2017/08/29 14:16:56 Saving...
2017/08/29 14:16:56 Gathering batch of experience...
2017/08/29 14:17:20 batch 17: mean=2.962852 stddev=1.385327 entropy=2.719799 frames=100140 count=5007
2017/08/29 14:17:20 Training policy...
2017/08/29 14:17:30 step 0: objective=0.255516 reg=0.027198
2017/08/29 14:17:34 step 1: objective=0.256037 reg=0.027150
2017/08/29 14:17:39 step 2: objective=0.256492 reg=0.027138
2017/08/29 14:17:43 step 3: objective=0.257314 reg=0.027119
2017/08/29 14:17:47 step 4: objective=0.257176 reg=0.027133
2017/08/29 14:17:52 step 5: objective=0.257811 reg=0.027095
2017/08/29 14:17:56 step 6: objective=0.257878 reg=0.027084
2017/08/29 14:18:00 step 7: objective=0.258124 reg=0.027058
2017/08/29 14:18:00 Training value function...
2017/08/29 14:18:06 step 0: mse=1.066599 step=0.050000
2017/08/29 14:18:09 step 1: mse=1.060627 step=0.050000
2017/08/29 14:18:11 step 2: mse=1.055169 step=0.050000
2017/08/29 14:18:14 step 3: mse=1.050139 step=0.050000
2017/08/29 14:18:17 step 4: mse=1.045526 step=0.050000
2017/08/29 14:18:20 step 5: mse=1.041238 step=0.050000
2017/08/29 14:18:22 step 6: mse=1.037295 step=0.050000
2017/08/29 14:18:25 step 7: mse=1.033659 step=0.050000
2017/08/29 14:18:25 Saving...
2017/08/29 14:18:25 Gathering batch of experience...
2017/08/29 14:18:50 batch 18: mean=3.048133 stddev=1.387942 entropy=2.703166 frames=100140 count=5007
2017/08/29 14:18:50 Training policy...
2017/08/29 14:18:59 step 0: objective=0.261836 reg=0.027032
2017/08/29 14:19:04 step 1: objective=0.262427 reg=0.026979
2017/08/29 14:19:08 step 2: objective=0.263305 reg=0.026931
2017/08/29 14:19:13 step 3: objective=0.263252 reg=0.026947
2017/08/29 14:19:17 step 4: objective=0.263594 reg=0.026909
2017/08/29 14:19:21 step 5: objective=0.264068 reg=0.026901
2017/08/29 14:19:26 step 6: objective=0.264704 reg=0.026869
2017/08/29 14:19:30 step 7: objective=0.264518 reg=0.026860
2017/08/29 14:19:30 Training value function...
2017/08/29 14:19:35 step 0: mse=1.072979 step=0.050000
2017/08/29 14:19:38 step 1: mse=1.066200 step=0.050000
2017/08/29 14:19:41 step 2: mse=1.059988 step=0.050000
2017/08/29 14:19:44 step 3: mse=1.054286 step=0.050000
2017/08/29 14:19:47 step 4: mse=1.049035 step=0.050000
2017/08/29 14:19:50 step 5: mse=1.044094 step=0.050000
2017/08/29 14:19:52 step 6: mse=1.039548 step=0.050000
2017/08/29 14:19:55 step 7: mse=1.035342 step=0.050000
2017/08/29 14:19:55 Saving...
2017/08/29 14:19:55 Gathering batch of experience...
2017/08/29 14:20:19 batch 19: mean=3.124825 stddev=1.432802 entropy=2.685854 frames=100140 count=5007
2017/08/29 14:20:19 Training policy...
2017/08/29 14:20:29 step 0: objective=0.263342 reg=0.026858
2017/08/29 14:20:34 step 1: objective=0.264197 reg=0.026792
2017/08/29 14:20:38 step 2: objective=0.263403 reg=0.026841
2017/08/29 14:20:42 step 3: objective=0.263929 reg=0.026799
2017/08/29 14:20:47 step 4: objective=0.264322 reg=0.026748
2017/08/29 14:20:51 step 5: objective=0.264416 reg=0.026738
2017/08/29 14:20:56 step 6: objective=0.264200 reg=0.026733
2017/08/29 14:21:00 step 7: objective=0.264115 reg=0.026742
2017/08/29 14:21:00 Training value function...
2017/08/29 14:21:05 step 0: mse=1.124019 step=0.050000
2017/08/29 14:21:08 step 1: mse=1.117887 step=0.050000
2017/08/29 14:21:11 step 2: mse=1.112253 step=0.050000
2017/08/29 14:21:14 step 3: mse=1.107078 step=0.050000
2017/08/29 14:21:17 step 4: mse=1.102300 step=0.050000
2017/08/29 14:21:20 step 5: mse=1.097902 step=0.050000
2017/08/29 14:21:22 step 6: mse=1.093858 step=0.050000
2017/08/29 14:21:25 step 7: mse=1.090092 step=0.050000
2017/08/29 14:21:25 Saving...
2017/08/29 14:21:25 Gathering batch of experience...
2017/08/29 14:21:50 batch 20: mean=3.188336 stddev=1.442694 entropy=2.668921 frames=100140 count=5007
2017/08/29 14:21:50 Training policy...
2017/08/29 14:21:59 step 0: objective=0.249038 reg=0.026689
2017/08/29 14:22:04 step 1: objective=0.249142 reg=0.026592
2017/08/29 14:22:08 step 2: objective=0.249545 reg=0.026630
2017/08/29 14:22:13 step 3: objective=0.249914 reg=0.026615
2017/08/29 14:22:17 step 4: objective=0.249774 reg=0.026536
2017/08/29 14:22:21 step 5: objective=0.249911 reg=0.026577
2017/08/29 14:22:26 step 6: objective=0.250134 reg=0.026543
2017/08/29 14:22:30 step 7: objective=0.250400 reg=0.026485
2017/08/29 14:22:30 Training value function...
2017/08/29 14:22:35 step 0: mse=1.158566 step=0.050000
2017/08/29 14:22:38 step 1: mse=1.154490 step=0.050000
2017/08/29 14:22:41 step 2: mse=1.150730 step=0.050000
2017/08/29 14:22:44 step 3: mse=1.147273 step=0.050000
2017/08/29 14:22:47 step 4: mse=1.144073 step=0.050000
2017/08/29 14:22:49 step 5: mse=1.141110 step=0.050000
2017/08/29 14:22:52 step 6: mse=1.138364 step=0.050000
2017/08/29 14:22:55 step 7: mse=1.135829 step=0.050000
2017/08/29 14:22:55 Saving...
2017/08/29 14:22:55 Gathering batch of experience...
2017/08/29 14:23:20 batch 21: mean=3.277412 stddev=1.433269 entropy=2.647986 frames=100140 count=5007
2017/08/29 14:23:20 Training policy...
2017/08/29 14:23:30 step 0: objective=0.264704 reg=0.026480
2017/08/29 14:23:34 step 1: objective=0.265527 reg=0.026426
2017/08/29 14:23:38 step 2: objective=0.265359 reg=0.026339
2017/08/29 14:23:43 step 3: objective=0.266421 reg=0.026322
2017/08/29 14:23:47 step 4: objective=0.265910 reg=0.026306
2017/08/29 14:23:52 step 5: objective=0.266261 reg=0.026329
2017/08/29 14:23:56 step 6: objective=0.266809 reg=0.026297
2017/08/29 14:24:01 step 7: objective=0.267276 reg=0.026272
2017/08/29 14:24:01 Training value function...
2017/08/29 14:24:06 step 0: mse=1.184768 step=0.050000
2017/08/29 14:24:09 step 1: mse=1.179401 step=0.050000
2017/08/29 14:24:12 step 2: mse=1.174466 step=0.050000
2017/08/29 14:24:15 step 3: mse=1.169924 step=0.050000
2017/08/29 14:24:18 step 4: mse=1.165733 step=0.050000
2017/08/29 14:24:20 step 5: mse=1.161816 step=0.050000
2017/08/29 14:24:23 step 6: mse=1.158219 step=0.050000
2017/08/29 14:24:26 step 7: mse=1.154887 step=0.050000
2017/08/29 14:24:26 Saving...
2017/08/29 14:24:26 Gathering batch of experience...
2017/08/29 14:24:51 batch 22: mean=3.343719 stddev=1.469717 entropy=2.626132 frames=100140 count=5007
2017/08/29 14:24:51 Training policy...
2017/08/29 14:25:01 step 0: objective=0.268566 reg=0.026261
2017/08/29 14:25:05 step 1: objective=0.269269 reg=0.026206
2017/08/29 14:25:10 step 2: objective=0.269220 reg=0.026195
2017/08/29 14:25:14 step 3: objective=0.269908 reg=0.026154
2017/08/29 14:25:18 step 4: objective=0.270161 reg=0.026098
2017/08/29 14:25:23 step 5: objective=0.270011 reg=0.026098
2017/08/29 14:25:27 step 6: objective=0.269355 reg=0.026058
2017/08/29 14:25:32 step 7: objective=0.268851 reg=0.026096
2017/08/29 14:25:32 Training value function...
2017/08/29 14:25:37 step 0: mse=1.218182 step=0.050000
2017/08/29 14:25:40 step 1: mse=1.212674 step=0.050000
2017/08/29 14:25:43 step 2: mse=1.207611 step=0.050000
2017/08/29 14:25:46 step 3: mse=1.202977 step=0.050000
2017/08/29 14:25:49 step 4: mse=1.198706 step=0.050000
2017/08/29 14:25:51 step 5: mse=1.194763 step=0.050000
2017/08/29 14:25:54 step 6: mse=1.191042 step=0.050000
2017/08/29 14:25:57 step 7: mse=1.187588 step=0.050000
2017/08/29 14:25:57 Saving...
2017/08/29 14:25:57 Gathering batch of experience...
2017/08/29 14:26:22 batch 23: mean=3.390054 stddev=1.464664 entropy=2.603995 frames=100140 count=5007
2017/08/29 14:26:22 Training policy...
2017/08/29 14:26:32 step 0: objective=0.257068 reg=0.026040
2017/08/29 14:26:36 step 1: objective=0.257247 reg=0.025953
2017/08/29 14:26:41 step 2: objective=0.257341 reg=0.025981
2017/08/29 14:26:45 step 3: objective=0.257836 reg=0.025877
2017/08/29 14:26:50 step 4: objective=0.257501 reg=0.025947
2017/08/29 14:26:54 step 5: objective=0.258064 reg=0.025925
2017/08/29 14:26:58 step 6: objective=0.257846 reg=0.025823
2017/08/29 14:27:03 step 7: objective=0.257532 reg=0.025940
2017/08/29 14:27:03 Training value function...
2017/08/29 14:27:08 step 0: mse=1.200070 step=0.050000
2017/08/29 14:27:11 step 1: mse=1.195077 step=0.050000
2017/08/29 14:27:14 step 2: mse=1.190492 step=0.050000
2017/08/29 14:27:17 step 3: mse=1.186273 step=0.050000
2017/08/29 14:27:20 step 4: mse=1.182453 step=0.050000
2017/08/29 14:27:23 step 5: mse=1.178922 step=0.050000
2017/08/29 14:27:25 step 6: mse=1.175562 step=0.050000
2017/08/29 14:27:28 step 7: mse=1.172488 step=0.050000
2017/08/29 14:27:28 Saving...
2017/08/29 14:27:28 Gathering batch of experience...
2017/08/29 14:27:53 batch 24: mean=3.465948 stddev=1.464986 entropy=2.581209 frames=100140 count=5007
2017/08/29 14:27:53 Training policy...
2017/08/29 14:28:03 step 0: objective=0.267562 reg=0.025812
2017/08/29 14:28:08 step 1: objective=0.268100 reg=0.025738
2017/08/29 14:28:12 step 2: objective=0.267390 reg=0.025688
2017/08/29 14:28:16 step 3: objective=0.267861 reg=0.025691
2017/08/29 14:28:21 step 4: objective=0.267275 reg=0.025714
2017/08/29 14:28:25 step 5: objective=0.268367 reg=0.025676
2017/08/29 14:28:30 step 6: objective=0.268456 reg=0.025611
2017/08/29 14:28:34 step 7: objective=0.267809 reg=0.025673
2017/08/29 14:28:34 Training value function...
2017/08/29 14:28:40 step 0: mse=1.234862 step=0.050000
2017/08/29 14:28:43 step 1: mse=1.229470 step=0.050000
2017/08/29 14:28:46 step 2: mse=1.224509 step=0.050000
2017/08/29 14:28:49 step 3: mse=1.219935 step=0.050000
2017/08/29 14:28:51 step 4: mse=1.215712 step=0.050000
2017/08/29 14:28:54 step 5: mse=1.211716 step=0.050000
2017/08/29 14:28:57 step 6: mse=1.208037 step=0.050000
2017/08/29 14:29:00 step 7: mse=1.204683 step=0.050000
2017/08/29 14:29:00 Saving...
2017/08/29 14:29:00 Gathering batch of experience...
2017/08/29 14:29:25 batch 25: mean=3.526064 stddev=1.509728 entropy=2.558749 frames=100140 count=5007
2017/08/29 14:29:25 Training policy...
2017/08/29 14:29:35 step 0: objective=0.273392 reg=0.025587
2017/08/29 14:29:39 step 1: objective=0.273952 reg=0.025512
2017/08/29 14:29:44 step 2: objective=0.273428 reg=0.025461
2017/08/29 14:29:48 step 3: objective=0.272029 reg=0.025538
2017/08/29 14:29:53 step 4: objective=0.271762 reg=0.025557
2017/08/29 14:29:57 step 5: objective=0.273818 reg=0.025433
2017/08/29 14:30:02 step 6: objective=0.272596 reg=0.025530
2017/08/29 14:30:06 step 7: objective=0.273570 reg=0.025391
2017/08/29 14:30:06 Training value function...
2017/08/29 14:30:12 step 0: mse=1.295353 step=0.050000
2017/08/29 14:30:15 step 1: mse=1.289994 step=0.050000
2017/08/29 14:30:18 step 2: mse=1.285061 step=0.050000
2017/08/29 14:30:21 step 3: mse=1.280513 step=0.050000
2017/08/29 14:30:24 step 4: mse=1.276314 step=0.050000
2017/08/29 14:30:26 step 5: mse=1.272436 step=0.050000
2017/08/29 14:30:29 step 6: mse=1.268847 step=0.050000
2017/08/29 14:30:32 step 7: mse=1.265508 step=0.050000
2017/08/29 14:30:32 Saving...
2017/08/29 14:30:32 Gathering batch of experience...
2017/08/29 14:30:57 batch 26: mean=3.579389 stddev=1.478438 entropy=2.547838 frames=100140 count=5007
2017/08/29 14:30:57 Training policy...
2017/08/29 14:31:07 step 0: objective=0.269237 reg=0.025478
2017/08/29 14:31:12 step 1: objective=0.270115 reg=0.025391
2017/08/29 14:31:16 step 2: objective=0.269188 reg=0.025439
2017/08/29 14:31:21 step 3: objective=0.271014 reg=0.025341
2017/08/29 14:31:25 step 4: objective=0.270447 reg=0.025335
2017/08/29 14:31:30 step 5: objective=0.269971 reg=0.025338
2017/08/29 14:31:34 step 6: objective=0.270198 reg=0.025325
2017/08/29 14:31:39 step 7: objective=0.270316 reg=0.025296
2017/08/29 14:31:39 Training value function...
2017/08/29 14:31:44 step 0: mse=1.268829 step=0.050000
2017/08/29 14:31:47 step 1: mse=1.263785 step=0.050000
2017/08/29 14:31:50 step 2: mse=1.259126 step=0.050000
2017/08/29 14:31:53 step 3: mse=1.254830 step=0.050000
2017/08/29 14:31:56 step 4: mse=1.250871 step=0.050000
2017/08/29 14:31:59 step 5: mse=1.247139 step=0.050000
2017/08/29 14:32:02 step 6: mse=1.243733 step=0.050000
2017/08/29 14:32:05 step 7: mse=1.240555 step=0.050000
2017/08/29 14:32:05 Saving...
2017/08/29 14:32:05 Gathering batch of experience...
2017/08/29 14:32:29 batch 27: mean=3.582784 stddev=1.533686 entropy=2.525457 frames=100140 count=5007
2017/08/29 14:32:29 Training policy...
2017/08/29 14:32:40 step 0: objective=0.247085 reg=0.025255
2017/08/29 14:32:44 step 1: objective=0.247799 reg=0.025171
2017/08/29 14:32:48 step 2: objective=0.247728 reg=0.025222
2017/08/29 14:32:53 step 3: objective=0.248343 reg=0.025163
2017/08/29 14:32:58 step 4: objective=0.248032 reg=0.025187
2017/08/29 14:33:02 step 5: objective=0.248132 reg=0.025123
2017/08/29 14:33:07 step 6: objective=0.248223 reg=0.025143
2017/08/29 14:33:11 step 7: objective=0.247824 reg=0.025002
2017/08/29 14:33:11 Training value function...
2017/08/29 14:33:17 step 0: mse=1.289888 step=0.050000
2017/08/29 14:33:20 step 1: mse=1.287426 step=0.050000
2017/08/29 14:33:23 step 2: mse=1.285134 step=0.050000
2017/08/29 14:33:26 step 3: mse=1.283019 step=0.050000
2017/08/29 14:33:29 step 4: mse=1.281049 step=0.050000
2017/08/29 14:33:32 step 5: mse=1.279225 step=0.050000
2017/08/29 14:33:35 step 6: mse=1.277536 step=0.050000
2017/08/29 14:33:38 step 7: mse=1.275950 step=0.050000
2017/08/29 14:33:38 Saving...
2017/08/29 14:33:38 Gathering batch of experience...
2017/08/29 14:34:02 batch 28: mean=3.617136 stddev=1.485100 entropy=2.512294 frames=100140 count=5007
2017/08/29 14:34:02 Training policy...
2017/08/29 14:34:13 step 0: objective=0.258319 reg=0.025123
2017/08/29 14:34:17 step 1: objective=0.259153 reg=0.025066
2017/08/29 14:34:22 step 2: objective=0.259367 reg=0.025044
2017/08/29 14:34:26 step 3: objective=0.259595 reg=0.025007
2017/08/29 14:34:31 step 4: objective=0.259677 reg=0.024979
2017/08/29 14:34:35 step 5: objective=0.258860 reg=0.024980
2017/08/29 14:34:40 step 6: objective=0.259983 reg=0.024958
2017/08/29 14:34:44 step 7: objective=0.259517 reg=0.024932
2017/08/29 14:34:44 Training value function...
2017/08/29 14:34:50 step 0: mse=1.256355 step=0.050000
2017/08/29 14:34:52 step 1: mse=1.252428 step=0.050000
2017/08/29 14:34:55 step 2: mse=1.248799 step=0.050000
2017/08/29 14:34:58 step 3: mse=1.245447 step=0.050000
2017/08/29 14:35:01 step 4: mse=1.242260 step=0.050000
2017/08/29 14:35:04 step 5: mse=1.239310 step=0.050000
2017/08/29 14:35:07 step 6: mse=1.236629 step=0.050000
2017/08/29 14:35:10 step 7: mse=1.234139 step=0.050000
2017/08/29 14:35:10 Saving...
2017/08/29 14:35:10 Gathering batch of experience...
2017/08/29 14:35:35 batch 29: mean=3.720991 stddev=1.512297 entropy=2.493670 frames=100140 count=5007
2017/08/29 14:35:35 Training policy...
2017/08/29 14:35:45 step 0: objective=0.271002 reg=0.024937
2017/08/29 14:35:50 step 1: objective=0.271513 reg=0.024852
2017/08/29 14:35:54 step 2: objective=0.271230 reg=0.024846
2017/08/29 14:35:59 step 3: objective=0.270629 reg=0.024790
2017/08/29 14:36:03 step 4: objective=0.269622 reg=0.024729
2017/08/29 14:36:08 step 5: objective=0.269062 reg=0.024741
2017/08/29 14:36:13 step 6: objective=0.270014 reg=0.024720
2017/08/29 14:36:17 step 7: objective=0.269256 reg=0.024741
2017/08/29 14:36:17 Training value function...
2017/08/29 14:36:23 step 0: mse=1.301385 step=0.050000
2017/08/29 14:36:26 step 1: mse=1.296897 step=0.050000
2017/08/29 14:36:29 step 2: mse=1.292754 step=0.050000
2017/08/29 14:36:32 step 3: mse=1.288922 step=0.050000
2017/08/29 14:36:35 step 4: mse=1.285377 step=0.050000
2017/08/29 14:36:38 step 5: mse=1.282091 step=0.050000
2017/08/29 14:36:41 step 6: mse=1.279043 step=0.050000
2017/08/29 14:36:43 step 7: mse=1.276219 step=0.050000
2017/08/29 14:36:43 Saving...
2017/08/29 14:36:44 Gathering batch of experience...
2017/08/29 14:37:08 batch 30: mean=3.742161 stddev=1.494690 entropy=2.476757 frames=100140 count=5007
2017/08/29 14:37:08 Training policy...
2017/08/29 14:37:19 step 0: objective=0.256451 reg=0.024767
2017/08/29 14:37:23 step 1: objective=0.256700 reg=0.024679
2017/08/29 14:37:28 step 2: objective=0.254765 reg=0.024792
2017/08/29 14:37:32 step 3: objective=0.257078 reg=0.024694
2017/08/29 14:37:37 step 4: objective=0.256759 reg=0.024716
2017/08/29 14:37:41 step 5: objective=0.257652 reg=0.024656
2017/08/29 14:37:46 step 6: objective=0.257952 reg=0.024593
2017/08/29 14:37:51 step 7: objective=0.256709 reg=0.024698
2017/08/29 14:37:51 Training value function...
2017/08/29 14:37:56 step 0: mse=1.245188 step=0.050000
2017/08/29 14:37:59 step 1: mse=1.241570 step=0.050000
2017/08/29 14:38:02 step 2: mse=1.238233 step=0.050000
2017/08/29 14:38:05 step 3: mse=1.235112 step=0.050000
2017/08/29 14:38:08 step 4: mse=1.232228 step=0.050000
2017/08/29 14:38:11 step 5: mse=1.229526 step=0.050000
2017/08/29 14:38:14 step 6: mse=1.227027 step=0.050000
2017/08/29 14:38:17 step 7: mse=1.224679 step=0.050000
2017/08/29 14:38:17 Saving...
2017/08/29 14:38:17 Gathering batch of experience...
2017/08/29 14:38:42 batch 31: mean=3.765528 stddev=1.522006 entropy=2.456036 frames=100140 count=5007
2017/08/29 14:38:42 Training policy...
2017/08/29 14:38:52 step 0: objective=0.261318 reg=0.024560
2017/08/29 14:38:57 step 1: objective=0.261686 reg=0.024482
2017/08/29 14:39:01 step 2: objective=0.260328 reg=0.024579
2017/08/29 14:39:06 step 3: objective=0.262509 reg=0.024468
2017/08/29 14:39:11 step 4: objective=0.260211 reg=0.024533
2017/08/29 14:39:15 step 5: objective=0.261958 reg=0.024479
2017/08/29 14:39:20 step 6: objective=0.261041 reg=0.024487
2017/08/29 14:39:24 step 7: objective=0.262407 reg=0.024449
2017/08/29 14:39:24 Training value function...
2017/08/29 14:39:30 step 0: mse=1.337807 step=0.050000
2017/08/29 14:39:33 step 1: mse=1.334890 step=0.050000
2017/08/29 14:39:36 step 2: mse=1.332209 step=0.050000
2017/08/29 14:39:39 step 3: mse=1.329784 step=0.050000
2017/08/29 14:39:42 step 4: mse=1.327501 step=0.050000
2017/08/29 14:39:45 step 5: mse=1.325420 step=0.050000
2017/08/29 14:39:48 step 6: mse=1.323425 step=0.050000
2017/08/29 14:39:51 step 7: mse=1.321553 step=0.050000
2017/08/29 14:39:51 Saving...
2017/08/29 14:39:51 Gathering batch of experience...
2017/08/29 14:40:16 batch 32: mean=3.838226 stddev=1.523202 entropy=2.447588 frames=100140 count=5007
2017/08/29 14:40:16 Training policy...
2017/08/29 14:40:26 step 0: objective=0.263721 reg=0.024476
2017/08/29 14:40:31 step 1: objective=0.264036 reg=0.024379
2017/08/29 14:40:35 step 2: objective=0.263555 reg=0.024421
2017/08/29 14:40:40 step 3: objective=0.263630 reg=0.024303
2017/08/29 14:40:45 step 4: objective=0.263296 reg=0.024396
2017/08/29 14:40:49 step 5: objective=0.264008 reg=0.024302
2017/08/29 14:40:54 step 6: objective=0.263317 reg=0.024337
2017/08/29 14:40:58 step 7: objective=0.262713 reg=0.024338
2017/08/29 14:40:58 Training value function...
2017/08/29 14:41:04 step 0: mse=1.315949 step=0.050000
2017/08/29 14:41:07 step 1: mse=1.312208 step=0.050000
2017/08/29 14:41:10 step 2: mse=1.308775 step=0.050000
2017/08/29 14:41:13 step 3: mse=1.305579 step=0.050000
2017/08/29 14:41:16 step 4: mse=1.302609 step=0.050000
2017/08/29 14:41:19 step 5: mse=1.299858 step=0.050000
2017/08/29 14:41:22 step 6: mse=1.297284 step=0.050000
2017/08/29 14:41:25 step 7: mse=1.294841 step=0.050000
2017/08/29 14:41:25 Saving...
2017/08/29 14:41:25 Gathering batch of experience...
2017/08/29 14:41:50 batch 33: mean=3.823247 stddev=1.500055 entropy=2.436397 frames=100140 count=5007
2017/08/29 14:41:50 Training policy...
2017/08/29 14:42:00 step 0: objective=0.246117 reg=0.024364
2017/08/29 14:42:05 step 1: objective=0.246717 reg=0.024284
2017/08/29 14:42:10 step 2: objective=0.246601 reg=0.024300
2017/08/29 14:42:14 step 3: objective=0.246347 reg=0.024259
2017/08/29 14:42:19 step 4: objective=0.246847 reg=0.024236
2017/08/29 14:42:23 step 5: objective=0.247179 reg=0.024143
2017/08/29 14:42:28 step 6: objective=0.246775 reg=0.024242
2017/08/29 14:42:32 step 7: objective=0.247718 reg=0.024105
2017/08/29 14:42:32 Training value function...
2017/08/29 14:42:38 step 0: mse=1.260946 step=0.050000
2017/08/29 14:42:41 step 1: mse=1.258642 step=0.050000
2017/08/29 14:42:44 step 2: mse=1.256514 step=0.050000
2017/08/29 14:42:47 step 3: mse=1.254533 step=0.050000
2017/08/29 14:42:50 step 4: mse=1.252687 step=0.050000
2017/08/29 14:42:53 step 5: mse=1.250962 step=0.050000
2017/08/29 14:42:56 step 6: mse=1.249358 step=0.050000
2017/08/29 14:42:59 step 7: mse=1.247853 step=0.050000
2017/08/29 14:42:59 Saving...
2017/08/29 14:42:59 Gathering batch of experience...
2017/08/29 14:43:24 batch 34: mean=3.862792 stddev=1.521744 entropy=2.419835 frames=100140 count=5007
2017/08/29 14:43:24 Training policy...
2017/08/29 14:43:35 step 0: objective=0.249115 reg=0.024198
2017/08/29 14:43:39 step 1: objective=0.250019 reg=0.024136
2017/08/29 14:43:44 step 2: objective=0.249628 reg=0.024185
2017/08/29 14:43:49 step 3: objective=0.250433 reg=0.024095
2017/08/29 14:43:53 step 4: objective=0.250226 reg=0.024122
2017/08/29 14:43:58 step 5: objective=0.250042 reg=0.024071
2017/08/29 14:44:02 step 6: objective=0.249752 reg=0.024105
2017/08/29 14:44:07 step 7: objective=0.250605 reg=0.024030
2017/08/29 14:44:07 Training value function...
2017/08/29 14:44:12 step 0: mse=1.308359 step=0.050000
2017/08/29 14:44:15 step 1: mse=1.306039 step=0.050000
2017/08/29 14:44:18 step 2: mse=1.303894 step=0.050000
2017/08/29 14:44:21 step 3: mse=1.301937 step=0.050000
2017/08/29 14:44:24 step 4: mse=1.300023 step=0.050000
2017/08/29 14:44:27 step 5: mse=1.298239 step=0.050000
2017/08/29 14:44:30 step 6: mse=1.296579 step=0.050000
2017/08/29 14:44:33 step 7: mse=1.295025 step=0.050000
2017/08/29 14:44:33 Saving...
2017/08/29 14:44:34 Gathering batch of experience...
2017/08/29 14:44:59 batch 35: mean=3.861194 stddev=1.518446 entropy=2.404853 frames=100140 count=5007
2017/08/29 14:44:59 Training policy...
2017/08/29 14:45:09 step 0: objective=0.247885 reg=0.024049
2017/08/29 14:45:14 step 1: objective=0.248650 reg=0.023977
2017/08/29 14:45:18 step 2: objective=0.247810 reg=0.024044
2017/08/29 14:45:23 step 3: objective=0.248720 reg=0.023962
2017/08/29 14:45:28 step 4: objective=0.247861 reg=0.024000
2017/08/29 14:45:32 step 5: objective=0.248815 reg=0.023958
2017/08/29 14:45:37 step 6: objective=0.248402 reg=0.023853
2017/08/29 14:45:41 step 7: objective=0.247653 reg=0.023967
2017/08/29 14:45:41 Training value function...
2017/08/29 14:45:47 step 0: mse=1.277223 step=0.050000
2017/08/29 14:45:50 step 1: mse=1.275083 step=0.050000
2017/08/29 14:45:53 step 2: mse=1.273104 step=0.050000
2017/08/29 14:45:56 step 3: mse=1.271274 step=0.050000
2017/08/29 14:45:59 step 4: mse=1.269574 step=0.050000
2017/08/29 14:46:03 step 5: mse=1.267991 step=0.050000
2017/08/29 14:46:06 step 6: mse=1.266527 step=0.050000
2017/08/29 14:46:09 step 7: mse=1.265126 step=0.050000
2017/08/29 14:46:09 Saving...
2017/08/29 14:46:09 Gathering batch of experience...
2017/08/29 14:46:34 batch 36: mean=3.956860 stddev=1.478066 entropy=2.384159 frames=100140 count=5007
2017/08/29 14:46:34 Training policy...
2017/08/29 14:46:45 step 0: objective=0.259636 reg=0.023842
2017/08/29 14:46:49 step 1: objective=0.260639 reg=0.023787
2017/08/29 14:46:54 step 2: objective=0.260693 reg=0.023804
2017/08/29 14:46:59 step 3: objective=0.260840 reg=0.023733
2017/08/29 14:47:03 step 4: objective=0.260543 reg=0.023755
2017/08/29 14:47:08 step 5: objective=0.261059 reg=0.023690
2017/08/29 14:47:12 step 6: objective=0.259993 reg=0.023727
2017/08/29 14:47:17 step 7: objective=0.259916 reg=0.023685
2017/08/29 14:47:17 Training value function...
2017/08/29 14:47:23 step 0: mse=1.274195 step=0.050000
2017/08/29 14:47:26 step 1: mse=1.270852 step=0.050000
2017/08/29 14:47:29 step 2: mse=1.267732 step=0.050000
2017/08/29 14:47:32 step 3: mse=1.264859 step=0.050000
2017/08/29 14:47:35 step 4: mse=1.262187 step=0.050000
2017/08/29 14:47:38 step 5: mse=1.259719 step=0.050000
2017/08/29 14:47:41 step 6: mse=1.257387 step=0.050000
2017/08/29 14:47:44 step 7: mse=1.255221 step=0.050000
2017/08/29 14:47:44 Saving...
2017/08/29 14:47:44 Gathering batch of experience...
2017/08/29 14:48:09 batch 37: mean=4.000799 stddev=1.533072 entropy=2.367544 frames=100140 count=5007
2017/08/29 14:48:09 Training policy...
2017/08/29 14:48:20 step 0: objective=0.265959 reg=0.023676
2017/08/29 14:48:25 step 1: objective=0.266818 reg=0.023625
2017/08/29 14:48:30 step 2: objective=0.267165 reg=0.023590
2017/08/29 14:48:34 step 3: objective=0.267688 reg=0.023575
2017/08/29 14:48:39 step 4: objective=0.267185 reg=0.023486
2017/08/29 14:48:43 step 5: objective=0.266383 reg=0.023590
2017/08/29 14:48:48 step 6: objective=0.266518 reg=0.023429
2017/08/29 14:48:53 step 7: objective=0.266751 reg=0.023545
2017/08/29 14:48:53 Training value function...
2017/08/29 14:48:58 step 0: mse=1.333375 step=0.050000
2017/08/29 14:49:01 step 1: mse=1.330331 step=0.050000
2017/08/29 14:49:04 step 2: mse=1.327449 step=0.050000
2017/08/29 14:49:08 step 3: mse=1.324805 step=0.050000
2017/08/29 14:49:11 step 4: mse=1.322282 step=0.050000
2017/08/29 14:49:14 step 5: mse=1.319967 step=0.050000
2017/08/29 14:49:17 step 6: mse=1.317829 step=0.050000
2017/08/29 14:49:20 step 7: mse=1.315780 step=0.050000
2017/08/29 14:49:20 Saving...
2017/08/29 14:49:20 Gathering batch of experience...
2017/08/29 14:49:45 batch 38: mean=4.038546 stddev=1.531088 entropy=2.343338 frames=100140 count=5007
2017/08/29 14:49:45 Training policy...
2017/08/29 14:49:56 step 0: objective=0.275406 reg=0.023433
2017/08/29 14:50:01 step 1: objective=0.275801 reg=0.023375
2017/08/29 14:50:05 step 2: objective=0.276148 reg=0.023403
2017/08/29 14:50:10 step 3: objective=0.277000 reg=0.023328
2017/08/29 14:50:14 step 4: objective=0.277015 reg=0.023252
2017/08/29 14:50:19 step 5: objective=0.275070 reg=0.023389
2017/08/29 14:50:24 step 6: objective=0.277913 reg=0.023239
2017/08/29 14:50:28 step 7: objective=0.276797 reg=0.023339
2017/08/29 14:50:28 Training value function...
2017/08/29 14:50:34 step 0: mse=1.362746 step=0.050000
2017/08/29 14:50:37 step 1: mse=1.358887 step=0.050000
2017/08/29 14:50:40 step 2: mse=1.355316 step=0.050000
2017/08/29 14:50:43 step 3: mse=1.351972 step=0.050000
2017/08/29 14:50:46 step 4: mse=1.348843 step=0.050000
2017/08/29 14:50:49 step 5: mse=1.345947 step=0.050000
2017/08/29 14:50:53 step 6: mse=1.343230 step=0.050000
2017/08/29 14:50:56 step 7: mse=1.340716 step=0.050000
2017/08/29 14:50:56 Saving...
2017/08/29 14:50:56 Gathering batch of experience...
2017/08/29 14:51:21 batch 39: mean=4.080088 stddev=1.527779 entropy=2.322892 frames=100140 count=5007
2017/08/29 14:51:21 Training policy...
2017/08/29 14:51:32 step 0: objective=0.256006 reg=0.023229
2017/08/29 14:51:36 step 1: objective=0.256666 reg=0.023159
2017/08/29 14:51:41 step 2: objective=0.255968 reg=0.023179
2017/08/29 14:51:45 step 3: objective=0.256488 reg=0.023115
2017/08/29 14:51:50 step 4: objective=0.256206 reg=0.023179
2017/08/29 14:51:55 step 5: objective=0.256525 reg=0.023075
2017/08/29 14:51:59 step 6: objective=0.256070 reg=0.023159
2017/08/29 14:52:04 step 7: objective=0.256409 reg=0.023094
2017/08/29 14:52:04 Training value function...
2017/08/29 14:52:10 step 0: mse=1.326655 step=0.050000
2017/08/29 14:52:13 step 1: mse=1.324303 step=0.050000
2017/08/29 14:52:16 step 2: mse=1.322127 step=0.050000
2017/08/29 14:52:19 step 3: mse=1.320116 step=0.050000
2017/08/29 14:52:23 step 4: mse=1.318236 step=0.050000
2017/08/29 14:52:26 step 5: mse=1.316495 step=0.050000
2017/08/29 14:52:29 step 6: mse=1.314836 step=0.050000
2017/08/29 14:52:32 step 7: mse=1.313283 step=0.050000
2017/08/29 14:52:32 Saving...
2017/08/29 14:52:32 Gathering batch of experience...
2017/08/29 14:52:57 batch 40: mean=4.067905 stddev=1.528173 entropy=2.310532 frames=100140 count=5007
2017/08/29 14:52:57 Training policy...
2017/08/29 14:53:08 step 0: objective=0.252093 reg=0.023105
2017/08/29 14:53:13 step 1: objective=0.252775 reg=0.023030
2017/08/29 14:53:18 step 2: objective=0.253299 reg=0.023018
2017/08/29 14:53:22 step 3: objective=0.253329 reg=0.022918
2017/08/29 14:53:27 step 4: objective=0.252009 reg=0.023068
2017/08/29 14:53:32 step 5: objective=0.253450 reg=0.022872
2017/08/29 14:53:36 step 6: objective=0.252174 reg=0.022994
2017/08/29 14:53:41 step 7: objective=0.253965 reg=0.022860
2017/08/29 14:53:41 Training value function...
2017/08/29 14:53:47 step 0: mse=1.309805 step=0.050000
2017/08/29 14:53:50 step 1: mse=1.307505 step=0.050000
2017/08/29 14:53:53 step 2: mse=1.305351 step=0.050000
2017/08/29 14:53:56 step 3: mse=1.303381 step=0.050000
2017/08/29 14:53:59 step 4: mse=1.301488 step=0.050000
2017/08/29 14:54:02 step 5: mse=1.299717 step=0.050000
2017/08/29 14:54:05 step 6: mse=1.298086 step=0.050000
2017/08/29 14:54:09 step 7: mse=1.296530 step=0.050000
2017/08/29 14:54:09 Saving...
2017/08/29 14:54:09 Gathering batch of experience...
2017/08/29 14:54:34 batch 41: mean=4.134412 stddev=1.542717 entropy=2.304547 frames=100140 count=5007
2017/08/29 14:54:34 Training policy...
2017/08/29 14:54:45 step 0: objective=0.262668 reg=0.023046
2017/08/29 14:54:50 step 1: objective=0.263650 reg=0.022963
2017/08/29 14:54:55 step 2: objective=0.263886 reg=0.022940
2017/08/29 14:54:59 step 3: objective=0.263878 reg=0.022944
2017/08/29 14:55:04 step 4: objective=0.264169 reg=0.022912
2017/08/29 14:55:08 step 5: objective=0.264275 reg=0.022940
2017/08/29 14:55:13 step 6: objective=0.264005 reg=0.022851
2017/08/29 14:55:18 step 7: objective=0.263165 reg=0.022943
2017/08/29 14:55:18 Training value function...
2017/08/29 14:55:24 step 0: mse=1.366090 step=0.050000
2017/08/29 14:55:27 step 1: mse=1.363606 step=0.050000
2017/08/29 14:55:30 step 2: mse=1.361344 step=0.050000
2017/08/29 14:55:33 step 3: mse=1.359197 step=0.050000
2017/08/29 14:55:36 step 4: mse=1.357196 step=0.050000
2017/08/29 14:55:40 step 5: mse=1.355321 step=0.050000
2017/08/29 14:55:43 step 6: mse=1.353598 step=0.050000
2017/08/29 14:55:46 step 7: mse=1.351995 step=0.050000
2017/08/29 14:55:46 Saving...
2017/08/29 14:55:46 Gathering batch of experience...
2017/08/29 14:56:11 batch 42: mean=4.158778 stddev=1.545319 entropy=2.283362 frames=100140 count=5007
2017/08/29 14:56:11 Training policy...
2017/08/29 14:56:22 step 0: objective=0.274997 reg=0.022834
2017/08/29 14:56:27 step 1: objective=0.275801 reg=0.022754
2017/08/29 14:56:32 step 2: objective=0.275858 reg=0.022825
2017/08/29 14:56:36 step 3: objective=0.275828 reg=0.022654
2017/08/29 14:56:41 step 4: objective=0.274506 reg=0.022850
2017/08/29 14:56:45 step 5: objective=0.276091 reg=0.022592
2017/08/29 14:56:50 step 6: objective=0.274898 reg=0.022812
2017/08/29 14:56:55 step 7: objective=0.275877 reg=0.022598
2017/08/29 14:56:55 Training value function...
2017/08/29 14:57:01 step 0: mse=1.336523 step=0.050000
2017/08/29 14:57:04 step 1: mse=1.332625 step=0.050000
2017/08/29 14:57:07 step 2: mse=1.329024 step=0.050000
2017/08/29 14:57:10 step 3: mse=1.325689 step=0.050000
2017/08/29 14:57:13 step 4: mse=1.322600 step=0.050000
2017/08/29 14:57:16 step 5: mse=1.319736 step=0.050000
2017/08/29 14:57:20 step 6: mse=1.317076 step=0.050000
2017/08/29 14:57:23 step 7: mse=1.314607 step=0.050000
2017/08/29 14:57:23 Saving...
2017/08/29 14:57:23 Gathering batch of experience...
2017/08/29 14:57:48 batch 43: mean=4.127821 stddev=1.522496 entropy=2.284717 frames=100140 count=5007
2017/08/29 14:57:48 Training policy...
2017/08/29 14:57:59 step 0: objective=0.251555 reg=0.022847
2017/08/29 14:58:04 step 1: objective=0.252215 reg=0.022772
2017/08/29 14:58:08 step 2: objective=0.252424 reg=0.022802
2017/08/29 14:58:13 step 3: objective=0.252497 reg=0.022716
2017/08/29 14:58:18 step 4: objective=0.252164 reg=0.022808
2017/08/29 14:58:22 step 5: objective=0.252778 reg=0.022701
2017/08/29 14:58:27 step 6: objective=0.252988 reg=0.022704
2017/08/29 14:58:32 step 7: objective=0.253228 reg=0.022593
2017/08/29 14:58:32 Training value function...
2017/08/29 14:58:37 step 0: mse=1.258892 step=0.050000
2017/08/29 14:58:40 step 1: mse=1.256640 step=0.050000
2017/08/29 14:58:44 step 2: mse=1.254531 step=0.050000
2017/08/29 14:58:47 step 3: mse=1.252577 step=0.050000
2017/08/29 14:58:50 step 4: mse=1.250791 step=0.050000
2017/08/29 14:58:53 step 5: mse=1.249036 step=0.050000
2017/08/29 14:58:56 step 6: mse=1.247482 step=0.050000
2017/08/29 14:59:00 step 7: mse=1.246020 step=0.050000
2017/08/29 14:59:00 Saving...
2017/08/29 14:59:00 Gathering batch of experience...
2017/08/29 14:59:25 batch 44: mean=4.161174 stddev=1.543131 entropy=2.270990 frames=100140 count=5007
2017/08/29 14:59:25 Training policy...
2017/08/29 14:59:36 step 0: objective=0.243828 reg=0.022710
2017/08/29 14:59:41 step 1: objective=0.244597 reg=0.022644
2017/08/29 14:59:46 step 2: objective=0.243906 reg=0.022681
2017/08/29 14:59:50 step 3: objective=0.244584 reg=0.022669
2017/08/29 14:59:55 step 4: objective=0.243894 reg=0.022621
2017/08/29 14:59:59 step 5: objective=0.243708 reg=0.022640
2017/08/29 15:00:04 step 6: objective=0.242943 reg=0.022587
2017/08/29 15:00:09 step 7: objective=0.243816 reg=0.022656
2017/08/29 15:00:09 Training value function...
2017/08/29 15:00:15 step 0: mse=1.304419 step=0.050000
2017/08/29 15:00:18 step 1: mse=1.303320 step=0.050000
2017/08/29 15:00:21 step 2: mse=1.302336 step=0.050000
2017/08/29 15:00:24 step 3: mse=1.301412 step=0.050000
2017/08/29 15:00:28 step 4: mse=1.300590 step=0.050000
2017/08/29 15:00:31 step 5: mse=1.299806 step=0.050000
2017/08/29 15:00:34 step 6: mse=1.299079 step=0.050000
2017/08/29 15:00:37 step 7: mse=1.298351 step=0.050000
2017/08/29 15:00:37 Saving...
2017/08/29 15:00:37 Gathering batch of experience...
2017/08/29 15:01:02 batch 45: mean=4.213301 stddev=1.520396 entropy=2.256188 frames=100140 count=5007
2017/08/29 15:01:02 Training policy...
2017/08/29 15:01:14 step 0: objective=0.262099 reg=0.022562
2017/08/29 15:01:19 step 1: objective=0.262788 reg=0.022514
2017/08/29 15:01:23 step 2: objective=0.262995 reg=0.022518
2017/08/29 15:01:28 step 3: objective=0.263361 reg=0.022488
2017/08/29 15:01:33 step 4: objective=0.262917 reg=0.022436
2017/08/29 15:01:37 step 5: objective=0.262165 reg=0.022501
2017/08/29 15:01:42 step 6: objective=0.262620 reg=0.022390
2017/08/29 15:01:46 step 7: objective=0.261713 reg=0.022518
2017/08/29 15:01:46 Training value function...
2017/08/29 15:01:52 step 0: mse=1.358089 step=0.050000
2017/08/29 15:01:56 step 1: mse=1.355785 step=0.050000
2017/08/29 15:01:59 step 2: mse=1.353657 step=0.050000
2017/08/29 15:02:02 step 3: mse=1.351711 step=0.050000
2017/08/29 15:02:05 step 4: mse=1.349914 step=0.050000
2017/08/29 15:02:08 step 5: mse=1.348244 step=0.050000
2017/08/29 15:02:12 step 6: mse=1.346690 step=0.050000
2017/08/29 15:02:15 step 7: mse=1.345242 step=0.050000
2017/08/29 15:02:15 Saving...
2017/08/29 15:02:15 Gathering batch of experience...
2017/08/29 15:02:40 batch 46: mean=4.207310 stddev=1.554856 entropy=2.240540 frames=100140 count=5007
2017/08/29 15:02:40 Training policy...
2017/08/29 15:02:52 step 0: objective=0.258520 reg=0.022406
2017/08/29 15:02:57 step 1: objective=0.259178 reg=0.022338
2017/08/29 15:03:01 step 2: objective=0.259420 reg=0.022374
2017/08/29 15:03:06 step 3: objective=0.259881 reg=0.022296
2017/08/29 15:03:11 step 4: objective=0.259698 reg=0.022309
2017/08/29 15:03:15 step 5: objective=0.260703 reg=0.022201
2017/08/29 15:03:20 step 6: objective=0.259568 reg=0.022276
2017/08/29 15:03:25 step 7: objective=0.261297 reg=0.022165
2017/08/29 15:03:25 Training value function...
2017/08/29 15:03:31 step 0: mse=1.322315 step=0.050000
2017/08/29 15:03:34 step 1: mse=1.319764 step=0.050000
2017/08/29 15:03:37 step 2: mse=1.317393 step=0.050000
2017/08/29 15:03:40 step 3: mse=1.315194 step=0.050000
2017/08/29 15:03:44 step 4: mse=1.313137 step=0.050000
2017/08/29 15:03:47 step 5: mse=1.311227 step=0.050000
2017/08/29 15:03:50 step 6: mse=1.309457 step=0.050000
2017/08/29 15:03:53 step 7: mse=1.307811 step=0.050000
2017/08/29 15:03:53 Saving...
2017/08/29 15:03:53 Gathering batch of experience...
2017/08/29 15:04:19 batch 47: mean=4.309966 stddev=1.525689 entropy=2.222809 frames=100140 count=5007
2017/08/29 15:04:19 Training policy...
2017/08/29 15:04:30 step 0: objective=0.270224 reg=0.022228
2017/08/29 15:04:35 step 1: objective=0.270821 reg=0.022163
2017/08/29 15:04:40 step 2: objective=0.271327 reg=0.022175
2017/08/29 15:04:44 step 3: objective=0.272009 reg=0.022127
2017/08/29 15:04:49 step 4: objective=0.272475 reg=0.022139
2017/08/29 15:04:54 step 5: objective=0.273053 reg=0.022060
2017/08/29 15:04:59 step 6: objective=0.272472 reg=0.022108
2017/08/29 15:05:03 step 7: objective=0.272782 reg=0.022022
2017/08/29 15:05:03 Training value function...
2017/08/29 15:05:09 step 0: mse=1.332656 step=0.050000
2017/08/29 15:05:13 step 1: mse=1.329691 step=0.050000
2017/08/29 15:05:16 step 2: mse=1.326951 step=0.050000
2017/08/29 15:05:19 step 3: mse=1.324404 step=0.050000
2017/08/29 15:05:22 step 4: mse=1.322037 step=0.050000
2017/08/29 15:05:26 step 5: mse=1.319835 step=0.050000
2017/08/29 15:05:29 step 6: mse=1.317778 step=0.050000
2017/08/29 15:05:32 step 7: mse=1.315800 step=0.050000
2017/08/29 15:05:32 Saving...
2017/08/29 15:05:32 Gathering batch of experience...
2017/08/29 15:05:58 batch 48: mean=4.312363 stddev=1.545493 entropy=2.213106 frames=100140 count=5007
2017/08/29 15:05:58 Training policy...
2017/08/29 15:06:09 step 0: objective=0.278739 reg=0.022131
2017/08/29 15:06:14 step 1: objective=0.279291 reg=0.022056
2017/08/29 15:06:18 step 2: objective=0.278287 reg=0.022149
2017/08/29 15:06:23 step 3: objective=0.279335 reg=0.022045
2017/08/29 15:06:28 step 4: objective=0.279214 reg=0.022119
2017/08/29 15:06:32 step 5: objective=0.279378 reg=0.022061
2017/08/29 15:06:37 step 6: objective=0.279314 reg=0.022064
2017/08/29 15:06:42 step 7: objective=0.280079 reg=0.022011
2017/08/29 15:06:42 Training value function...
2017/08/29 15:06:47 step 0: mse=1.360018 step=0.050000
2017/08/29 15:06:51 step 1: mse=1.356505 step=0.050000
2017/08/29 15:06:54 step 2: mse=1.353238 step=0.050000
2017/08/29 15:06:57 step 3: mse=1.350188 step=0.050000
2017/08/29 15:07:01 step 4: mse=1.347312 step=0.050000
2017/08/29 15:07:04 step 5: mse=1.344677 step=0.050000
2017/08/29 15:07:07 step 6: mse=1.342211 step=0.050000
2017/08/29 15:07:10 step 7: mse=1.339911 step=0.050000
2017/08/29 15:07:10 Saving...
2017/08/29 15:07:10 Gathering batch of experience...
2017/08/29 15:07:36 batch 49: mean=4.302377 stddev=1.542825 entropy=2.202978 frames=100140 count=5007
2017/08/29 15:07:36 Training policy...
2017/08/29 15:07:47 step 0: objective=0.249198 reg=0.022030
2017/08/29 15:07:52 step 1: objective=0.250119 reg=0.021977
2017/08/29 15:07:56 step 2: objective=0.249448 reg=0.022031
2017/08/29 15:08:01 step 3: objective=0.250140 reg=0.021977
2017/08/29 15:08:06 step 4: objective=0.250063 reg=0.021983
2017/08/29 15:08:11 step 5: objective=0.250153 reg=0.021982
2017/08/29 15:08:15 step 6: objective=0.249730 reg=0.021935
2017/08/29 15:08:20 step 7: objective=0.250362 reg=0.021933
2017/08/29 15:08:20 Training value function...
2017/08/29 15:08:26 step 0: mse=1.335058 step=0.050000
2017/08/29 15:08:29 step 1: mse=1.333916 step=0.050000
2017/08/29 15:08:32 step 2: mse=1.332864 step=0.050000
2017/08/29 15:08:36 step 3: mse=1.331888 step=0.050000
2017/08/29 15:08:39 step 4: mse=1.330986 step=0.050000
2017/08/29 15:08:42 step 5: mse=1.330129 step=0.050000
2017/08/29 15:08:46 step 6: mse=1.329328 step=0.050000
2017/08/29 15:08:49 step 7: mse=1.328579 step=0.050000
2017/08/29 15:08:49 Saving...
2017/08/29 15:08:49 Gathering batch of experience...
2017/08/29 15:09:14 batch 50: mean=4.291392 stddev=1.548101 entropy=2.198017 frames=100140 count=5007
2017/08/29 15:09:14 Training policy...
2017/08/29 15:09:26 step 0: objective=0.241454 reg=0.021980
2017/08/29 15:09:31 step 1: objective=0.242427 reg=0.021952
2017/08/29 15:09:35 step 2: objective=0.242455 reg=0.021986
2017/08/29 15:09:40 step 3: objective=0.243202 reg=0.021882
2017/08/29 15:09:45 step 4: objective=0.242493 reg=0.021980
2017/08/29 15:09:50 step 5: objective=0.242835 reg=0.021881
2017/08/29 15:09:54 step 6: objective=0.243046 reg=0.021936
2017/08/29 15:09:59 step 7: objective=0.243273 reg=0.021871
2017/08/29 15:09:59 Training value function...
2017/08/29 15:10:05 step 0: mse=1.309410 step=0.050000
2017/08/29 15:10:08 step 1: mse=1.308464 step=0.050000
2017/08/29 15:10:11 step 2: mse=1.307596 step=0.050000
2017/08/29 15:10:15 step 3: mse=1.306794 step=0.050000
2017/08/29 15:10:18 step 4: mse=1.306059 step=0.050000
2017/08/29 15:10:21 step 5: mse=1.305328 step=0.050000
2017/08/29 15:10:25 step 6: mse=1.304679 step=0.050000
2017/08/29 15:10:28 step 7: mse=1.304081 step=0.050000
2017/08/29 15:10:28 Saving...
2017/08/29 15:10:28 Gathering batch of experience...
2017/08/29 15:10:53 batch 51: mean=4.310365 stddev=1.535135 entropy=2.199290 frames=100140 count=5007
2017/08/29 15:10:53 Training policy...
2017/08/29 15:11:05 step 0: objective=0.249681 reg=0.021993
2017/08/29 15:11:10 step 1: objective=0.250720 reg=0.021936
2017/08/29 15:11:14 step 2: objective=0.249495 reg=0.021999
2017/08/29 15:11:19 step 3: objective=0.250629 reg=0.021879
2017/08/29 15:11:24 step 4: objective=0.249701 reg=0.021983
2017/08/29 15:11:28 step 5: objective=0.251496 reg=0.021897
2017/08/29 15:11:33 step 6: objective=0.250892 reg=0.021893
2017/08/29 15:11:38 step 7: objective=0.251228 reg=0.021895
2017/08/29 15:11:38 Training value function...
2017/08/29 15:11:43 step 0: mse=1.320229 step=0.050000
2017/08/29 15:11:47 step 1: mse=1.318836 step=0.050000
2017/08/29 15:11:50 step 2: mse=1.317559 step=0.050000
2017/08/29 15:11:53 step 3: mse=1.316359 step=0.050000
2017/08/29 15:11:57 step 4: mse=1.315272 step=0.050000
2017/08/29 15:12:00 step 5: mse=1.314241 step=0.050000
2017/08/29 15:12:03 step 6: mse=1.313305 step=0.050000
2017/08/29 15:12:07 step 7: mse=1.312425 step=0.050000
2017/08/29 15:12:07 Saving...
2017/08/29 15:12:07 Gathering batch of experience...
2017/08/29 15:12:32 batch 52: mean=4.374476 stddev=1.546487 entropy=2.183978 frames=100140 count=5007
2017/08/29 15:12:32 Training policy...
2017/08/29 15:12:44 step 0: objective=0.262535 reg=0.021840
2017/08/29 15:12:49 step 1: objective=0.263075 reg=0.021779
2017/08/29 15:12:53 step 2: objective=0.262738 reg=0.021774
2017/08/29 15:12:58 step 3: objective=0.263078 reg=0.021777
2017/08/29 15:13:03 step 4: objective=0.262819 reg=0.021700
2017/08/29 15:13:07 step 5: objective=0.263013 reg=0.021772
2017/08/29 15:13:12 step 6: objective=0.263068 reg=0.021682
2017/08/29 15:13:17 step 7: objective=0.263773 reg=0.021740
2017/08/29 15:13:17 Training value function...
2017/08/29 15:13:23 step 0: mse=1.358466 step=0.050000
2017/08/29 15:13:26 step 1: mse=1.356563 step=0.050000
2017/08/29 15:13:30 step 2: mse=1.354738 step=0.050000
2017/08/29 15:13:33 step 3: mse=1.353019 step=0.050000
2017/08/29 15:13:36 step 4: mse=1.351437 step=0.050000
2017/08/29 15:13:40 step 5: mse=1.349938 step=0.050000
2017/08/29 15:13:43 step 6: mse=1.348520 step=0.050000
2017/08/29 15:13:46 step 7: mse=1.347226 step=0.050000
2017/08/29 15:13:46 Saving...
2017/08/29 15:13:46 Gathering batch of experience...
2017/08/29 15:14:12 batch 53: mean=4.389854 stddev=1.536521 entropy=2.160907 frames=100140 count=5007
2017/08/29 15:14:12 Training policy...
2017/08/29 15:14:23 step 0: objective=0.259887 reg=0.021609
2017/08/29 15:14:28 step 1: objective=0.260888 reg=0.021554
2017/08/29 15:14:33 step 2: objective=0.260400 reg=0.021584
2017/08/29 15:14:37 step 3: objective=0.260512 reg=0.021547
2017/08/29 15:14:42 step 4: objective=0.259697 reg=0.021592
2017/08/29 15:14:47 step 5: objective=0.260911 reg=0.021528
2017/08/29 15:14:52 step 6: objective=0.260327 reg=0.021556
2017/08/29 15:14:57 step 7: objective=0.261322 reg=0.021502
2017/08/29 15:14:57 Training value function...
2017/08/29 15:15:02 step 0: mse=1.336626 step=0.050000
2017/08/29 15:15:06 step 1: mse=1.334502 step=0.050000
2017/08/29 15:15:09 step 2: mse=1.332569 step=0.050000
2017/08/29 15:15:13 step 3: mse=1.330740 step=0.050000
2017/08/29 15:15:16 step 4: mse=1.329071 step=0.050000
2017/08/29 15:15:19 step 5: mse=1.327489 step=0.050000
2017/08/29 15:15:23 step 6: mse=1.326043 step=0.050000
2017/08/29 15:15:26 step 7: mse=1.324670 step=0.050000
2017/08/29 15:15:26 Saving...
2017/08/29 15:15:26 Gathering batch of experience...
2017/08/29 15:15:51 batch 54: mean=4.372279 stddev=1.484631 entropy=2.166324 frames=100140 count=5007
2017/08/29 15:15:51 Training policy...
2017/08/29 15:16:03 step 0: objective=0.249283 reg=0.021663
2017/08/29 15:16:08 step 1: objective=0.250282 reg=0.021628
2017/08/29 15:16:13 step 2: objective=0.250433 reg=0.021626
2017/08/29 15:16:18 step 3: objective=0.250677 reg=0.021600
2017/08/29 15:16:22 step 4: objective=0.250842 reg=0.021621
2017/08/29 15:16:27 step 5: objective=0.251418 reg=0.021569
2017/08/29 15:16:32 step 6: objective=0.251763 reg=0.021540
2017/08/29 15:16:37 step 7: objective=0.252330 reg=0.021507
2017/08/29 15:16:37 Training value function...
2017/08/29 15:16:43 step 0: mse=1.295124 step=0.050000
2017/08/29 15:16:46 step 1: mse=1.294050 step=0.050000
2017/08/29 15:16:49 step 2: mse=1.293045 step=0.050000
2017/08/29 15:16:53 step 3: mse=1.292113 step=0.050000
2017/08/29 15:16:56 step 4: mse=1.291243 step=0.050000
2017/08/29 15:16:59 step 5: mse=1.290430 step=0.050000
2017/08/29 15:17:03 step 6: mse=1.289659 step=0.050000
2017/08/29 15:17:06 step 7: mse=1.288920 step=0.050000
2017/08/29 15:17:06 Saving...
2017/08/29 15:17:06 Gathering batch of experience...
2017/08/29 15:17:32 batch 55: mean=4.406631 stddev=1.504676 entropy=2.155228 frames=100140 count=5007
2017/08/29 15:17:32 Training policy...
2017/08/29 15:17:43 step 0: objective=0.251644 reg=0.021552
2017/08/29 15:17:48 step 1: objective=0.252760 reg=0.021505
2017/08/29 15:17:53 step 2: objective=0.252891 reg=0.021531
2017/08/29 15:17:58 step 3: objective=0.253293 reg=0.021447
2017/08/29 15:18:03 step 4: objective=0.253293 reg=0.021509
2017/08/29 15:18:08 step 5: objective=0.253488 reg=0.021436
2017/08/29 15:18:12 step 6: objective=0.252754 reg=0.021517
2017/08/29 15:18:17 step 7: objective=0.253773 reg=0.021430
2017/08/29 15:18:17 Training value function...
2017/08/29 15:18:23 step 0: mse=1.287582 step=0.050000
2017/08/29 15:18:27 step 1: mse=1.286611 step=0.050000
2017/08/29 15:18:30 step 2: mse=1.285717 step=0.050000
2017/08/29 15:18:33 step 3: mse=1.284889 step=0.050000
2017/08/29 15:18:37 step 4: mse=1.284109 step=0.050000
2017/08/29 15:18:40 step 5: mse=1.283378 step=0.050000
2017/08/29 15:18:43 step 6: mse=1.282625 step=0.050000
2017/08/29 15:18:47 step 7: mse=1.281986 step=0.050000
2017/08/29 15:18:47 Saving...
2017/08/29 15:18:47 Gathering batch of experience...
2017/08/29 15:19:12 batch 56: mean=4.424805 stddev=1.528469 entropy=2.142279 frames=100140 count=5007
2017/08/29 15:19:12 Training policy...
2017/08/29 15:19:24 step 0: objective=0.263800 reg=0.021423
2017/08/29 15:19:29 step 1: objective=0.264692 reg=0.021373
2017/08/29 15:19:34 step 2: objective=0.264469 reg=0.021429
2017/08/29 15:19:39 step 3: objective=0.264983 reg=0.021342
2017/08/29 15:19:44 step 4: objective=0.265272 reg=0.021367
2017/08/29 15:19:49 step 5: objective=0.265982 reg=0.021299
2017/08/29 15:19:54 step 6: objective=0.265863 reg=0.021330
2017/08/29 15:19:58 step 7: objective=0.266116 reg=0.021307
2017/08/29 15:19:58 Training value function...
2017/08/29 15:20:04 step 0: mse=1.317689 step=0.050000
2017/08/29 15:20:08 step 1: mse=1.314791 step=0.050000
2017/08/29 15:20:11 step 2: mse=1.312099 step=0.050000
2017/08/29 15:20:14 step 3: mse=1.309519 step=0.050000
2017/08/29 15:20:18 step 4: mse=1.307180 step=0.050000
2017/08/29 15:20:21 step 5: mse=1.304937 step=0.050000
2017/08/29 15:20:25 step 6: mse=1.302891 step=0.050000
2017/08/29 15:20:28 step 7: mse=1.300976 step=0.050000
2017/08/29 15:20:28 Saving...
2017/08/29 15:20:28 Gathering batch of experience...
2017/08/29 15:20:54 batch 57: mean=4.405033 stddev=1.535714 entropy=2.132185 frames=100140 count=5007
2017/08/29 15:20:54 Training policy...
2017/08/29 15:21:06 step 0: objective=0.241307 reg=0.021322
2017/08/29 15:21:10 step 1: objective=0.242240 reg=0.021282
2017/08/29 15:21:15 step 2: objective=0.242335 reg=0.021289
2017/08/29 15:21:20 step 3: objective=0.242647 reg=0.021261
2017/08/29 15:21:25 step 4: objective=0.242745 reg=0.021278
2017/08/29 15:21:29 step 5: objective=0.242890 reg=0.021230
2017/08/29 15:21:35 step 6: objective=0.242782 reg=0.021270
2017/08/29 15:21:39 step 7: objective=0.243271 reg=0.021215
2017/08/29 15:21:39 Training value function...
2017/08/29 15:21:45 step 0: mse=1.269499 step=0.050000
2017/08/29 15:21:49 step 1: mse=1.268778 step=0.050000
2017/08/29 15:21:52 step 2: mse=1.268114 step=0.050000
2017/08/29 15:21:56 step 3: mse=1.267505 step=0.050000
2017/08/29 15:21:59 step 4: mse=1.266944 step=0.050000
2017/08/29 15:22:03 step 5: mse=1.266402 step=0.050000
2017/08/29 15:22:06 step 6: mse=1.265899 step=0.050000
2017/08/29 15:22:09 step 7: mse=1.265386 step=0.050000
2017/08/29 15:22:09 Saving...
2017/08/29 15:22:09 Gathering batch of experience...
2017/08/29 15:22:35 batch 58: mean=4.400240 stddev=1.518011 entropy=2.120704 frames=100140 count=5007
2017/08/29 15:22:35 Training policy...
2017/08/29 15:22:47 step 0: objective=0.244017 reg=0.021207
2017/08/29 15:22:52 step 1: objective=0.244970 reg=0.021147
2017/08/29 15:22:57 step 2: objective=0.244513 reg=0.021225
2017/08/29 15:23:01 step 3: objective=0.245575 reg=0.021133
2017/08/29 15:23:06 step 4: objective=0.244768 reg=0.021208
2017/08/29 15:23:11 step 5: objective=0.245582 reg=0.021094
2017/08/29 15:23:16 step 6: objective=0.245655 reg=0.021118
2017/08/29 15:23:21 step 7: objective=0.246286 reg=0.021044
2017/08/29 15:23:21 Training value function...
2017/08/29 15:23:27 step 0: mse=1.279384 step=0.050000
2017/08/29 15:23:30 step 1: mse=1.278581 step=0.050000
2017/08/29 15:23:33 step 2: mse=1.277851 step=0.050000
2017/08/29 15:23:37 step 3: mse=1.277183 step=0.050000
2017/08/29 15:23:40 step 4: mse=1.276540 step=0.050000
2017/08/29 15:23:43 step 5: mse=1.275957 step=0.050000
2017/08/29 15:23:47 step 6: mse=1.275394 step=0.050000
2017/08/29 15:23:50 step 7: mse=1.274889 step=0.050000
2017/08/29 15:23:50 Saving...
2017/08/29 15:23:50 Gathering batch of experience...
2017/08/29 15:24:16 batch 59: mean=4.477132 stddev=1.531321 entropy=2.114189 frames=100140 count=5007
2017/08/29 15:24:16 Training policy...
2017/08/29 15:24:28 step 0: objective=0.271794 reg=0.021142
2017/08/29 15:24:33 step 1: objective=0.272427 reg=0.021091
2017/08/29 15:24:38 step 2: objective=0.272144 reg=0.021144
2017/08/29 15:24:43 step 3: objective=0.272623 reg=0.021052
2017/08/29 15:24:47 step 4: objective=0.272295 reg=0.021126
2017/08/29 15:24:52 step 5: objective=0.272811 reg=0.021014
2017/08/29 15:24:57 step 6: objective=0.272671 reg=0.021111
2017/08/29 15:25:02 step 7: objective=0.273044 reg=0.020999
2017/08/29 15:25:02 Training value function...
2017/08/29 15:25:08 step 0: mse=1.337599 step=0.050000
2017/08/29 15:25:11 step 1: mse=1.334954 step=0.050000
2017/08/29 15:25:15 step 2: mse=1.332485 step=0.050000
2017/08/29 15:25:18 step 3: mse=1.330204 step=0.050000
2017/08/29 15:25:22 step 4: mse=1.328076 step=0.050000
2017/08/29 15:25:25 step 5: mse=1.326015 step=0.050000
2017/08/29 15:25:29 step 6: mse=1.324081 step=0.050000
2017/08/29 15:25:32 step 7: mse=1.322263 step=0.050000
2017/08/29 15:25:32 Saving...
2017/08/29 15:25:32 Gathering batch of experience...
2017/08/29 15:25:58 batch 60: mean=4.473537 stddev=1.527214 entropy=2.107982 frames=100140 count=5007
2017/08/29 15:25:58 Training policy...
2017/08/29 15:26:10 step 0: objective=0.256065 reg=0.021080
2017/08/29 15:26:15 step 1: objective=0.256924 reg=0.021050
2017/08/29 15:26:19 step 2: objective=0.256978 reg=0.021072
2017/08/29 15:26:24 step 3: objective=0.257789 reg=0.021036
2017/08/29 15:26:29 step 4: objective=0.257836 reg=0.021052
2017/08/29 15:26:34 step 5: objective=0.258542 reg=0.021016
2017/08/29 15:26:39 step 6: objective=0.258601 reg=0.021023
2017/08/29 15:26:44 step 7: objective=0.259033 reg=0.020991
2017/08/29 15:26:44 Training value function...
2017/08/29 15:26:50 step 0: mse=1.311181 step=0.050000
2017/08/29 15:26:53 step 1: mse=1.309733 step=0.050000
2017/08/29 15:26:56 step 2: mse=1.308351 step=0.050000
2017/08/29 15:27:00 step 3: mse=1.307072 step=0.050000
2017/08/29 15:27:03 step 4: mse=1.305863 step=0.050000
2017/08/29 15:27:07 step 5: mse=1.304753 step=0.050000
2017/08/29 15:27:10 step 6: mse=1.303696 step=0.050000
2017/08/29 15:27:14 step 7: mse=1.302698 step=0.050000
2017/08/29 15:27:14 Saving...
2017/08/29 15:27:14 Gathering batch of experience...
2017/08/29 15:27:39 batch 61: mean=4.495107 stddev=1.529657 entropy=2.098275 frames=100140 count=5007
2017/08/29 15:27:39 Training policy...
2017/08/29 15:27:51 step 0: objective=0.255044 reg=0.020983
2017/08/29 15:27:57 step 1: objective=0.255643 reg=0.020923
2017/08/29 15:28:01 step 2: objective=0.255077 reg=0.020984
2017/08/29 15:28:06 step 3: objective=0.255813 reg=0.020917
2017/08/29 15:28:11 step 4: objective=0.255471 reg=0.020970
2017/08/29 15:28:16 step 5: objective=0.255659 reg=0.020910
2017/08/29 15:28:21 step 6: objective=0.256109 reg=0.020964
2017/08/29 15:28:25 step 7: objective=0.256764 reg=0.020887
2017/08/29 15:28:25 Training value function...
2017/08/29 15:28:31 step 0: mse=1.275726 step=0.050000
2017/08/29 15:28:35 step 1: mse=1.274000 step=0.050000
2017/08/29 15:28:38 step 2: mse=1.272393 step=0.050000
2017/08/29 15:28:42 step 3: mse=1.270899 step=0.050000
2017/08/29 15:28:45 step 4: mse=1.269521 step=0.050000
2017/08/29 15:28:49 step 5: mse=1.268209 step=0.050000
2017/08/29 15:28:52 step 6: mse=1.266986 step=0.050000
2017/08/29 15:28:56 step 7: mse=1.265836 step=0.050000
2017/08/29 15:28:56 Saving...
2017/08/29 15:28:56 Gathering batch of experience...
2017/08/29 15:29:21 batch 62: mean=4.533453 stddev=1.502687 entropy=2.100017 frames=100140 count=5007
2017/08/29 15:29:21 Training policy...
2017/08/29 15:29:34 step 0: objective=0.254115 reg=0.021000
2017/08/29 15:29:39 step 1: objective=0.255154 reg=0.020969
2017/08/29 15:29:43 step 2: objective=0.255094 reg=0.020961
2017/08/29 15:29:48 step 3: objective=0.255321 reg=0.020974
2017/08/29 15:29:53 step 4: objective=0.255171 reg=0.020956
2017/08/29 15:29:58 step 5: objective=0.255360 reg=0.020940
2017/08/29 15:30:03 step 6: objective=0.255017 reg=0.020948
2017/08/29 15:30:08 step 7: objective=0.256169 reg=0.020946
2017/08/29 15:30:08 Training value function...
2017/08/29 15:30:14 step 0: mse=1.282287 step=0.050000
2017/08/29 15:30:17 step 1: mse=1.281127 step=0.050000
2017/08/29 15:30:21 step 2: mse=1.280058 step=0.050000
2017/08/29 15:30:24 step 3: mse=1.279017 step=0.050000
2017/08/29 15:30:27 step 4: mse=1.278148 step=0.050000
2017/08/29 15:30:31 step 5: mse=1.277361 step=0.050000
2017/08/29 15:30:34 step 6: mse=1.276591 step=0.050000
2017/08/29 15:30:38 step 7: mse=1.275894 step=0.050000
2017/08/29 15:30:38 Saving...
2017/08/29 15:30:38 Gathering batch of experience...
2017/08/29 15:31:03 batch 63: mean=4.503695 stddev=1.516416 entropy=2.089177 frames=100140 count=5007
2017/08/29 15:31:03 Training policy...
2017/08/29 15:31:16 step 0: objective=0.244100 reg=0.020892
2017/08/29 15:31:21 step 1: objective=0.244663 reg=0.020834
2017/08/29 15:31:25 step 2: objective=0.244657 reg=0.020881
2017/08/29 15:31:30 step 3: objective=0.245143 reg=0.020786
2017/08/29 15:31:35 step 4: objective=0.245296 reg=0.020861
2017/08/29 15:31:40 step 5: objective=0.245629 reg=0.020748
2017/08/29 15:31:45 step 6: objective=0.244786 reg=0.020881
2017/08/29 15:31:50 step 7: objective=0.245648 reg=0.020723
2017/08/29 15:31:50 Training value function...
2017/08/29 15:31:56 step 0: mse=1.304901 step=0.050000
2017/08/29 15:31:59 step 1: mse=1.304503 step=0.050000
2017/08/29 15:32:03 step 2: mse=1.304139 step=0.050000
2017/08/29 15:32:06 step 3: mse=1.303805 step=0.050000
2017/08/29 15:32:10 step 4: mse=1.303505 step=0.050000
2017/08/29 15:32:13 step 5: mse=1.303224 step=0.050000
2017/08/29 15:32:17 step 6: mse=1.302965 step=0.050000
2017/08/29 15:32:20 step 7: mse=1.302741 step=0.050000
2017/08/29 15:32:20 Saving...
2017/08/29 15:32:20 Gathering batch of experience...
2017/08/29 15:32:46 batch 64: mean=4.488716 stddev=1.549729 entropy=2.093762 frames=100140 count=5007
2017/08/29 15:32:46 Training policy...
2017/08/29 15:32:58 step 0: objective=0.251069 reg=0.020938
2017/08/29 15:33:03 step 1: objective=0.251451 reg=0.020889
2017/08/29 15:33:08 step 2: objective=0.251454 reg=0.020917
2017/08/29 15:33:12 step 3: objective=0.252592 reg=0.020881
2017/08/29 15:33:17 step 4: objective=0.252885 reg=0.020852
2017/08/29 15:33:22 step 5: objective=0.253608 reg=0.020811
2017/08/29 15:33:27 step 6: objective=0.253819 reg=0.020803
2017/08/29 15:33:32 step 7: objective=0.254008 reg=0.020783
2017/08/29 15:33:32 Training value function...
2017/08/29 15:33:38 step 0: mse=1.331329 step=0.050000
2017/08/29 15:33:41 step 1: mse=1.330422 step=0.050000
2017/08/29 15:33:45 step 2: mse=1.329558 step=0.050000
2017/08/29 15:33:48 step 3: mse=1.328753 step=0.050000
2017/08/29 15:33:52 step 4: mse=1.327979 step=0.050000
2017/08/29 15:33:55 step 5: mse=1.327250 step=0.050000
2017/08/29 15:33:58 step 6: mse=1.326540 step=0.050000
2017/08/29 15:34:02 step 7: mse=1.325876 step=0.050000
2017/08/29 15:34:02 Saving...
2017/08/29 15:34:02 Gathering batch of experience...
2017/08/29 15:34:28 batch 65: mean=4.565608 stddev=1.505213 entropy=2.077763 frames=100140 count=5007
2017/08/29 15:34:28 Training policy...
2017/08/29 15:34:40 step 0: objective=0.260367 reg=0.020778
2017/08/29 15:34:45 step 1: objective=0.261608 reg=0.020716
2017/08/29 15:34:50 step 2: objective=0.261435 reg=0.020787
2017/08/29 15:34:55 step 3: objective=0.261936 reg=0.020677
2017/08/29 15:35:00 step 4: objective=0.261455 reg=0.020793
2017/08/29 15:35:05 step 5: objective=0.262432 reg=0.020679
2017/08/29 15:35:09 step 6: objective=0.262155 reg=0.020775
2017/08/29 15:35:14 step 7: objective=0.262860 reg=0.020665
2017/08/29 15:35:14 Training value function...
2017/08/29 15:35:20 step 0: mse=1.299169 step=0.050000
2017/08/29 15:35:24 step 1: mse=1.297739 step=0.050000
2017/08/29 15:35:27 step 2: mse=1.296404 step=0.050000
2017/08/29 15:35:31 step 3: mse=1.295158 step=0.050000
2017/08/29 15:35:34 step 4: mse=1.293982 step=0.050000
2017/08/29 15:35:38 step 5: mse=1.292875 step=0.050000
2017/08/29 15:35:41 step 6: mse=1.291839 step=0.050000
2017/08/29 15:35:45 step 7: mse=1.290837 step=0.050000
2017/08/29 15:35:45 Saving...
2017/08/29 15:35:45 Gathering batch of experience...
2017/08/29 15:36:10 batch 66: mean=4.530457 stddev=1.541070 entropy=2.074827 frames=100140 count=5007
2017/08/29 15:36:10 Training policy...
2017/08/29 15:36:23 step 0: objective=0.252687 reg=0.020748
2017/08/29 15:36:27 step 1: objective=0.253497 reg=0.020701
2017/08/29 15:36:33 step 2: objective=0.254149 reg=0.020664
2017/08/29 15:36:38 step 3: objective=0.253860 reg=0.020667
2017/08/29 15:36:42 step 4: objective=0.254473 reg=0.020653
2017/08/29 15:36:47 step 5: objective=0.254577 reg=0.020684
2017/08/29 15:36:52 step 6: objective=0.254878 reg=0.020649
2017/08/29 15:36:57 step 7: objective=0.254757 reg=0.020643
2017/08/29 15:36:57 Training value function...
2017/08/29 15:37:03 step 0: mse=1.330617 step=0.050000
2017/08/29 15:37:07 step 1: mse=1.329511 step=0.050000
2017/08/29 15:37:10 step 2: mse=1.328492 step=0.050000
2017/08/29 15:37:14 step 3: mse=1.327551 step=0.050000
2017/08/29 15:37:17 step 4: mse=1.326676 step=0.050000
2017/08/29 15:37:20 step 5: mse=1.325829 step=0.050000
2017/08/29 15:37:24 step 6: mse=1.325066 step=0.050000
2017/08/29 15:37:27 step 7: mse=1.324349 step=0.050000
2017/08/29 15:37:27 Saving...
2017/08/29 15:37:27 Gathering batch of experience...
2017/08/29 15:37:53 batch 67: mean=4.555223 stddev=1.526576 entropy=2.063404 frames=100140 count=5007
2017/08/29 15:37:53 Training policy...
2017/08/29 15:38:06 step 0: objective=0.253106 reg=0.020634
2017/08/29 15:38:11 step 1: objective=0.254167 reg=0.020597
2017/08/29 15:38:16 step 2: objective=0.254709 reg=0.020572
2017/08/29 15:38:21 step 3: objective=0.255140 reg=0.020567
2017/08/29 15:38:25 step 4: objective=0.255085 reg=0.020563
2017/08/29 15:38:30 step 5: objective=0.254983 reg=0.020546
2017/08/29 15:38:35 step 6: objective=0.255447 reg=0.020543
2017/08/29 15:38:40 step 7: objective=0.255566 reg=0.020555
2017/08/29 15:38:40 Training value function...
2017/08/29 15:38:46 step 0: mse=1.293513 step=0.050000
2017/08/29 15:38:50 step 1: mse=1.292325 step=0.050000
2017/08/29 15:38:53 step 2: mse=1.291257 step=0.050000
2017/08/29 15:38:57 step 3: mse=1.290269 step=0.050000
2017/08/29 15:39:00 step 4: mse=1.289354 step=0.050000
2017/08/29 15:39:03 step 5: mse=1.288455 step=0.050000
2017/08/29 15:39:07 step 6: mse=1.287654 step=0.050000
2017/08/29 15:39:10 step 7: mse=1.286862 step=0.050000
2017/08/29 15:39:10 Saving...
2017/08/29 15:39:10 Gathering batch of experience...
2017/08/29 15:39:36 batch 68: mean=4.571600 stddev=1.496690 entropy=2.050419 frames=100140 count=5007
2017/08/29 15:39:36 Training policy...
2017/08/29 15:39:48 step 0: objective=0.254858 reg=0.020504
2017/08/29 15:39:53 step 1: objective=0.255904 reg=0.020482
2017/08/29 15:39:58 step 2: objective=0.256118 reg=0.020492
2017/08/29 15:40:03 step 3: objective=0.256660 reg=0.020421
2017/08/29 15:40:08 step 4: objective=0.256526 reg=0.020477
2017/08/29 15:40:13 step 5: objective=0.257246 reg=0.020396
2017/08/29 15:40:18 step 6: objective=0.257656 reg=0.020410
2017/08/29 15:40:23 step 7: objective=0.257991 reg=0.020394
2017/08/29 15:40:23 Training value function...
2017/08/29 15:40:29 step 0: mse=1.296220 step=0.050000
2017/08/29 15:40:33 step 1: mse=1.294991 step=0.050000
2017/08/29 15:40:36 step 2: mse=1.293844 step=0.050000
2017/08/29 15:40:40 step 3: mse=1.292785 step=0.050000
2017/08/29 15:40:43 step 4: mse=1.291786 step=0.050000
2017/08/29 15:40:47 step 5: mse=1.290859 step=0.050000
2017/08/29 15:40:50 step 6: mse=1.289983 step=0.050000
2017/08/29 15:40:53 step 7: mse=1.289170 step=0.050000
2017/08/29 15:40:53 Saving...
2017/08/29 15:40:54 Gathering batch of experience...
2017/08/29 15:41:19 batch 69: mean=4.594368 stddev=1.494893 entropy=2.043226 frames=100140 count=5007
2017/08/29 15:41:19 Training policy...
2017/08/29 15:41:32 step 0: objective=0.254252 reg=0.020432
2017/08/29 15:41:37 step 1: objective=0.255319 reg=0.020409
2017/08/29 15:41:42 step 2: objective=0.256079 reg=0.020374
2017/08/29 15:41:47 step 3: objective=0.256521 reg=0.020338
2017/08/29 15:41:52 step 4: objective=0.256752 reg=0.020310
2017/08/29 15:41:57 step 5: objective=0.256381 reg=0.020356
2017/08/29 15:42:02 step 6: objective=0.256762 reg=0.020263
2017/08/29 15:42:07 step 7: objective=0.255797 reg=0.020377
2017/08/29 15:42:07 Training value function...
2017/08/29 15:42:12 step 0: mse=1.276217 step=0.050000
2017/08/29 15:42:16 step 1: mse=1.275094 step=0.050000
2017/08/29 15:42:19 step 2: mse=1.274059 step=0.050000
2017/08/29 15:42:23 step 3: mse=1.273069 step=0.050000
2017/08/29 15:42:26 step 4: mse=1.272187 step=0.050000
2017/08/29 15:42:30 step 5: mse=1.271352 step=0.050000
2017/08/29 15:42:33 step 6: mse=1.270555 step=0.050000
2017/08/29 15:42:37 step 7: mse=1.269822 step=0.050000
2017/08/29 15:42:37 Saving...
2017/08/29 15:42:37 Gathering batch of experience...
2017/08/29 15:43:03 batch 70: mean=4.588376 stddev=1.492317 entropy=2.026381 frames=100140 count=5007
2017/08/29 15:43:03 Training policy...
2017/08/29 15:43:15 step 0: objective=0.251410 reg=0.020264
2017/08/29 15:43:20 step 1: objective=0.252399 reg=0.020219
2017/08/29 15:43:24 step 2: objective=0.252287 reg=0.020254
2017/08/29 15:43:29 step 3: objective=0.252804 reg=0.020153
2017/08/29 15:43:34 step 4: objective=0.252531 reg=0.020226
2017/08/29 15:43:39 step 5: objective=0.252753 reg=0.020129
2017/08/29 15:43:44 step 6: objective=0.252375 reg=0.020226
2017/08/29 15:43:49 step 7: objective=0.253343 reg=0.020115
2017/08/29 15:43:49 Training value function...
2017/08/29 15:43:55 step 0: mse=1.275905 step=0.050000
2017/08/29 15:43:59 step 1: mse=1.274758 step=0.050000
2017/08/29 15:44:02 step 2: mse=1.273696 step=0.050000
2017/08/29 15:44:05 step 3: mse=1.272740 step=0.050000
2017/08/29 15:44:09 step 4: mse=1.271818 step=0.050000
2017/08/29 15:44:12 step 5: mse=1.270986 step=0.050000
2017/08/29 15:44:16 step 6: mse=1.270168 step=0.050000
2017/08/29 15:44:19 step 7: mse=1.269436 step=0.050000
2017/08/29 15:44:19 Saving...
2017/08/29 15:44:19 Gathering batch of experience...
2017/08/29 15:44:45 batch 71: mean=4.635510 stddev=1.479492 entropy=2.018302 frames=100140 count=5007
2017/08/29 15:44:45 Training policy...
2017/08/29 15:44:57 step 0: objective=0.258544 reg=0.020183
2017/08/29 15:45:02 step 1: objective=0.259451 reg=0.020163
2017/08/29 15:45:07 step 2: objective=0.259170 reg=0.020155
2017/08/29 15:45:12 step 3: objective=0.259773 reg=0.020161
2017/08/29 15:45:17 step 4: objective=0.259567 reg=0.020135
2017/08/29 15:45:22 step 5: objective=0.260474 reg=0.020142
2017/08/29 15:45:27 step 6: objective=0.259666 reg=0.020142
2017/08/29 15:45:32 step 7: objective=0.260931 reg=0.020129
2017/08/29 15:45:32 Training value function...
2017/08/29 15:45:38 step 0: mse=1.302251 step=0.050000
2017/08/29 15:45:42 step 1: mse=1.300942 step=0.050000
2017/08/29 15:45:45 step 2: mse=1.299728 step=0.050000
2017/08/29 15:45:49 step 3: mse=1.298548 step=0.050000
2017/08/29 15:45:52 step 4: mse=1.297478 step=0.050000
2017/08/29 15:45:56 step 5: mse=1.296439 step=0.050000
2017/08/29 15:45:59 step 6: mse=1.295502 step=0.050000
2017/08/29 15:46:02 step 7: mse=1.294626 step=0.050000
2017/08/29 15:46:02 Saving...
2017/08/29 15:46:02 Gathering batch of experience...
2017/08/29 15:46:28 batch 72: mean=4.588776 stddev=1.486931 entropy=2.021130 frames=100140 count=5007
2017/08/29 15:46:28 Training policy...
2017/08/29 15:46:41 step 0: objective=0.246464 reg=0.020211
2017/08/29 15:46:46 step 1: objective=0.247233 reg=0.020170
2017/08/29 15:46:51 step 2: objective=0.247621 reg=0.020192
2017/08/29 15:46:56 step 3: objective=0.248429 reg=0.020143
2017/08/29 15:47:01 step 4: objective=0.248851 reg=0.020164
2017/08/29 15:47:06 step 5: objective=0.249280 reg=0.020109
2017/08/29 15:47:11 step 6: objective=0.249239 reg=0.020145
2017/08/29 15:47:16 step 7: objective=0.249199 reg=0.020110
2017/08/29 15:47:16 Training value function...
2017/08/29 15:47:22 step 0: mse=1.254889 step=0.050000
2017/08/29 15:47:25 step 1: mse=1.254182 step=0.050000
2017/08/29 15:47:29 step 2: mse=1.253528 step=0.050000
2017/08/29 15:47:32 step 3: mse=1.252916 step=0.050000
2017/08/29 15:47:36 step 4: mse=1.252355 step=0.050000
2017/08/29 15:47:39 step 5: mse=1.251832 step=0.050000
2017/08/29 15:47:43 step 6: mse=1.251332 step=0.050000
2017/08/29 15:47:46 step 7: mse=1.250857 step=0.050000
2017/08/29 15:47:46 Saving...
2017/08/29 15:47:46 Gathering batch of experience...
2017/08/29 15:48:12 batch 73: mean=4.601158 stddev=1.513438 entropy=2.013124 frames=100140 count=5007
2017/08/29 15:48:12 Training policy...
2017/08/29 15:48:24 step 0: objective=0.249285 reg=0.020131
2017/08/29 15:48:29 step 1: objective=0.249729 reg=0.020082
2017/08/29 15:48:34 step 2: objective=0.249421 reg=0.020131
2017/08/29 15:48:39 step 3: objective=0.250299 reg=0.020051
2017/08/29 15:48:44 step 4: objective=0.250142 reg=0.020120
2017/08/29 15:48:49 step 5: objective=0.250816 reg=0.020042
2017/08/29 15:48:54 step 6: objective=0.250481 reg=0.020107
2017/08/29 15:48:59 step 7: objective=0.251243 reg=0.020026
2017/08/29 15:48:59 Training value function...
2017/08/29 15:49:05 step 0: mse=1.250378 step=0.050000
2017/08/29 15:49:08 step 1: mse=1.249631 step=0.050000
2017/08/29 15:49:12 step 2: mse=1.248928 step=0.050000
2017/08/29 15:49:15 step 3: mse=1.248275 step=0.050000
2017/08/29 15:49:19 step 4: mse=1.247663 step=0.050000
2017/08/29 15:49:22 step 5: mse=1.247038 step=0.050000
2017/08/29 15:49:26 step 6: mse=1.246506 step=0.050000
2017/08/29 15:49:29 step 7: mse=1.245959 step=0.050000
2017/08/29 15:49:29 Saving...
2017/08/29 15:49:29 Gathering batch of experience...
2017/08/29 15:49:55 batch 74: mean=4.645696 stddev=1.513237 entropy=2.006860 frames=100140 count=5007
2017/08/29 15:49:55 Training policy...
2017/08/29 15:50:07 step 0: objective=0.261168 reg=0.020069
2017/08/29 15:50:12 step 1: objective=0.262259 reg=0.020023
2017/08/29 15:50:17 step 2: objective=0.262807 reg=0.020036
2017/08/29 15:50:22 step 3: objective=0.262909 reg=0.020021
2017/08/29 15:50:27 step 4: objective=0.263243 reg=0.020028
2017/08/29 15:50:32 step 5: objective=0.263581 reg=0.020006
2017/08/29 15:50:37 step 6: objective=0.264267 reg=0.019980
2017/08/29 15:50:42 step 7: objective=0.263922 reg=0.020021
2017/08/29 15:50:42 Training value function...
2017/08/29 15:50:48 step 0: mse=1.287524 step=0.050000
2017/08/29 15:50:51 step 1: mse=1.286000 step=0.050000
2017/08/29 15:50:55 step 2: mse=1.284592 step=0.050000
2017/08/29 15:50:58 step 3: mse=1.283275 step=0.050000
2017/08/29 15:51:02 step 4: mse=1.282057 step=0.050000
2017/08/29 15:51:05 step 5: mse=1.280916 step=0.050000
2017/08/29 15:51:09 step 6: mse=1.279843 step=0.050000
2017/08/29 15:51:12 step 7: mse=1.278832 step=0.050000
2017/08/29 15:51:12 Saving...
2017/08/29 15:51:12 Gathering batch of experience...
2017/08/29 15:51:38 batch 75: mean=4.646695 stddev=1.511424 entropy=1.999764 frames=100140 count=5007
2017/08/29 15:51:38 Training policy...
2017/08/29 15:51:51 step 0: objective=0.246209 reg=0.019998
2017/08/29 15:51:56 step 1: objective=0.247402 reg=0.019950
2017/08/29 15:52:01 step 2: objective=0.248143 reg=0.019943
2017/08/29 15:52:06 step 3: objective=0.248568 reg=0.019937
2017/08/29 15:52:11 step 4: objective=0.249178 reg=0.019916
2017/08/29 15:52:16 step 5: objective=0.249474 reg=0.019919
2017/08/29 15:52:21 step 6: objective=0.250153 reg=0.019895
2017/08/29 15:52:26 step 7: objective=0.250685 reg=0.019871
2017/08/29 15:52:26 Training value function...
2017/08/29 15:52:32 step 0: mse=1.264510 step=0.050000
2017/08/29 15:52:35 step 1: mse=1.263953 step=0.050000
2017/08/29 15:52:39 step 2: mse=1.263434 step=0.050000
2017/08/29 15:52:42 step 3: mse=1.262961 step=0.050000
2017/08/29 15:52:46 step 4: mse=1.262533 step=0.050000
2017/08/29 15:52:49 step 5: mse=1.262139 step=0.050000
2017/08/29 15:52:53 step 6: mse=1.261768 step=0.050000
2017/08/29 15:52:56 step 7: mse=1.261423 step=0.050000
2017/08/29 15:52:56 Saving...
2017/08/29 15:52:56 Gathering batch of experience...
2017/08/29 15:53:22 batch 76: mean=4.697224 stddev=1.505266 entropy=1.983574 frames=100140 count=5007
2017/08/29 15:53:22 Training policy...
2017/08/29 15:53:35 step 0: objective=0.261354 reg=0.019836
2017/08/29 15:53:40 step 1: objective=0.262537 reg=0.019804
2017/08/29 15:53:45 step 2: objective=0.262519 reg=0.019810
2017/08/29 15:53:50 step 3: objective=0.263111 reg=0.019776
2017/08/29 15:53:55 step 4: objective=0.263282 reg=0.019785
2017/08/29 15:54:00 step 5: objective=0.263328 reg=0.019709
2017/08/29 15:54:05 step 6: objective=0.262730 reg=0.019815
2017/08/29 15:54:10 step 7: objective=0.263539 reg=0.019679
2017/08/29 15:54:10 Training value function...
2017/08/29 15:54:16 step 0: mse=1.278586 step=0.050000
2017/08/29 15:54:20 step 1: mse=1.276886 step=0.050000
2017/08/29 15:54:23 step 2: mse=1.275306 step=0.050000
2017/08/29 15:54:27 step 3: mse=1.273795 step=0.050000
2017/08/29 15:54:30 step 4: mse=1.272393 step=0.050000
2017/08/29 15:54:34 step 5: mse=1.271064 step=0.050000
2017/08/29 15:54:37 step 6: mse=1.269841 step=0.050000
2017/08/29 15:54:41 step 7: mse=1.268667 step=0.050000
2017/08/29 15:54:41 Saving...
2017/08/29 15:54:41 Gathering batch of experience...
2017/08/29 15:55:07 batch 77: mean=4.659676 stddev=1.509314 entropy=1.979627 frames=100140 count=5007
2017/08/29 15:55:07 Training policy...
2017/08/29 15:55:19 step 0: objective=0.252285 reg=0.019796
2017/08/29 15:55:24 step 1: objective=0.253237 reg=0.019768
2017/08/29 15:55:29 step 2: objective=0.253603 reg=0.019768
2017/08/29 15:55:34 step 3: objective=0.254017 reg=0.019771
2017/08/29 15:55:39 step 4: objective=0.254383 reg=0.019757
2017/08/29 15:55:44 step 5: objective=0.254695 reg=0.019758
2017/08/29 15:55:49 step 6: objective=0.255232 reg=0.019694
2017/08/29 15:55:54 step 7: objective=0.254945 reg=0.019749
2017/08/29 15:55:54 Training value function...
2017/08/29 15:56:00 step 0: mse=1.258876 step=0.050000
2017/08/29 15:56:03 step 1: mse=1.257914 step=0.050000
2017/08/29 15:56:07 step 2: mse=1.257018 step=0.050000
2017/08/29 15:56:10 step 3: mse=1.256187 step=0.050000
2017/08/29 15:56:14 step 4: mse=1.255427 step=0.050000
2017/08/29 15:56:17 step 5: mse=1.254701 step=0.050000
2017/08/29 15:56:20 step 6: mse=1.254028 step=0.050000
2017/08/29 15:56:24 step 7: mse=1.253386 step=0.050000
2017/08/29 15:56:24 Saving...
2017/08/29 15:56:24 Gathering batch of experience...
2017/08/29 15:56:50 batch 78: mean=4.672259 stddev=1.499163 entropy=1.969875 frames=100140 count=5007
2017/08/29 15:56:50 Training policy...
2017/08/29 15:57:02 step 0: objective=0.250250 reg=0.019699
2017/08/29 15:57:07 step 1: objective=0.250792 reg=0.019657
2017/08/29 15:57:12 step 2: objective=0.250064 reg=0.019710
2017/08/29 15:57:17 step 3: objective=0.250998 reg=0.019626
2017/08/29 15:57:22 step 4: objective=0.250499 reg=0.019713
2017/08/29 15:57:27 step 5: objective=0.251306 reg=0.019618
2017/08/29 15:57:32 step 6: objective=0.250795 reg=0.019696
2017/08/29 15:57:37 step 7: objective=0.251692 reg=0.019615
2017/08/29 15:57:37 Training value function...
2017/08/29 15:57:43 step 0: mse=1.245785 step=0.050000
2017/08/29 15:57:47 step 1: mse=1.244749 step=0.050000
2017/08/29 15:57:50 step 2: mse=1.243791 step=0.050000
2017/08/29 15:57:54 step 3: mse=1.242901 step=0.050000
2017/08/29 15:57:57 step 4: mse=1.242085 step=0.050000
2017/08/29 15:58:01 step 5: mse=1.241324 step=0.050000
2017/08/29 15:58:04 step 6: mse=1.240520 step=0.050000
2017/08/29 15:58:08 step 7: mse=1.239815 step=0.050000
2017/08/29 15:58:08 Saving...
2017/08/29 15:58:08 Gathering batch of experience...
2017/08/29 15:58:34 batch 79: mean=4.681646 stddev=1.526187 entropy=1.965503 frames=100140 count=5007
2017/08/29 15:58:34 Training policy...
2017/08/29 15:58:46 step 0: objective=0.250787 reg=0.019655
2017/08/29 15:58:51 step 1: objective=0.251579 reg=0.019632
2017/08/29 15:58:56 step 2: objective=0.252350 reg=0.019615
2017/08/29 15:59:01 step 3: objective=0.252512 reg=0.019632
2017/08/29 15:59:06 step 4: objective=0.252969 reg=0.019601
2017/08/29 15:59:11 step 5: objective=0.253526 reg=0.019582
2017/08/29 15:59:16 step 6: objective=0.253524 reg=0.019596
2017/08/29 15:59:21 step 7: objective=0.254019 reg=0.019548
2017/08/29 15:59:21 Training value function...
2017/08/29 15:59:27 step 0: mse=1.269296 step=0.050000
2017/08/29 15:59:30 step 1: mse=1.268422 step=0.050000
2017/08/29 15:59:34 step 2: mse=1.267614 step=0.050000
2017/08/29 15:59:37 step 3: mse=1.266865 step=0.050000
2017/08/29 15:59:41 step 4: mse=1.266174 step=0.050000
2017/08/29 15:59:44 step 5: mse=1.265528 step=0.050000
2017/08/29 15:59:48 step 6: mse=1.264896 step=0.050000
2017/08/29 15:59:51 step 7: mse=1.264298 step=0.050000
2017/08/29 15:59:51 Saving...
2017/08/29 15:59:51 Gathering batch of experience...
2017/08/29 16:00:17 batch 80: mean=4.689035 stddev=1.477805 entropy=1.957694 frames=100140 count=5007
2017/08/29 16:00:17 Training policy...
2017/08/29 16:00:30 step 0: objective=0.249183 reg=0.019577
2017/08/29 16:00:35 step 1: objective=0.249865 reg=0.019555
2017/08/29 16:00:40 step 2: objective=0.249968 reg=0.019546
2017/08/29 16:00:45 step 3: objective=0.249886 reg=0.019549
2017/08/29 16:00:50 step 4: objective=0.250300 reg=0.019524
2017/08/29 16:00:55 step 5: objective=0.250172 reg=0.019549
2017/08/29 16:01:00 step 6: objective=0.250895 reg=0.019516
2017/08/29 16:01:05 step 7: objective=0.250380 reg=0.019561
2017/08/29 16:01:05 Training value function...
2017/08/29 16:01:11 step 0: mse=1.257944 step=0.050000
2017/08/29 16:01:14 step 1: mse=1.257267 step=0.050000
2017/08/29 16:01:17 step 2: mse=1.256666 step=0.050000
2017/08/29 16:01:21 step 3: mse=1.256082 step=0.050000
2017/08/29 16:01:25 step 4: mse=1.255565 step=0.050000
2017/08/29 16:01:28 step 5: mse=1.255065 step=0.050000
2017/08/29 16:01:31 step 6: mse=1.254575 step=0.050000
2017/08/29 16:01:35 step 7: mse=1.254149 step=0.050000
2017/08/29 16:01:35 Saving...
2017/08/29 16:01:35 Gathering batch of experience...
2017/08/29 16:02:01 batch 81: mean=4.734372 stddev=1.519510 entropy=1.951228 frames=100140 count=5007
2017/08/29 16:02:01 Training policy...
2017/08/29 16:02:13 step 0: objective=0.264266 reg=0.019512
2017/08/29 16:02:19 step 1: objective=0.265082 reg=0.019484
2017/08/29 16:02:24 step 2: objective=0.265829 reg=0.019468
2017/08/29 16:02:29 step 3: objective=0.266560 reg=0.019455
2017/08/29 16:02:34 step 4: objective=0.267208 reg=0.019434
2017/08/29 16:02:39 step 5: objective=0.267111 reg=0.019460
2017/08/29 16:02:44 step 6: objective=0.267551 reg=0.019414
2017/08/29 16:02:49 step 7: objective=0.267447 reg=0.019446
2017/08/29 16:02:49 Training value function...
2017/08/29 16:02:55 step 0: mse=1.294262 step=0.050000
2017/08/29 16:02:59 step 1: mse=1.292784 step=0.050000
2017/08/29 16:03:03 step 2: mse=1.291393 step=0.050000
2017/08/29 16:03:06 step 3: mse=1.290096 step=0.050000
2017/08/29 16:03:10 step 4: mse=1.288897 step=0.050000
2017/08/29 16:03:13 step 5: mse=1.287775 step=0.050000
2017/08/29 16:03:17 step 6: mse=1.286722 step=0.050000
2017/08/29 16:03:20 step 7: mse=1.285702 step=0.050000
2017/08/29 16:03:20 Saving...
2017/08/29 16:03:20 Gathering batch of experience...
2017/08/29 16:03:46 batch 82: mean=4.752746 stddev=1.520376 entropy=1.943886 frames=100140 count=5007
2017/08/29 16:03:46 Training policy...
2017/08/29 16:03:58 step 0: objective=0.269256 reg=0.019439
2017/08/29 16:04:03 step 1: objective=0.270314 reg=0.019406
2017/08/29 16:04:09 step 2: objective=0.270260 reg=0.019424
2017/08/29 16:04:14 step 3: objective=0.270881 reg=0.019388
2017/08/29 16:04:19 step 4: objective=0.270972 reg=0.019430
2017/08/29 16:04:24 step 5: objective=0.271538 reg=0.019361
2017/08/29 16:04:29 step 6: objective=0.271751 reg=0.019413
2017/08/29 16:04:34 step 7: objective=0.272085 reg=0.019355
2017/08/29 16:04:34 Training value function...
2017/08/29 16:04:40 step 0: mse=1.271366 step=0.050000
2017/08/29 16:04:43 step 1: mse=1.269249 step=0.050000
2017/08/29 16:04:47 step 2: mse=1.267274 step=0.050000
2017/08/29 16:04:50 step 3: mse=1.265428 step=0.050000
2017/08/29 16:04:54 step 4: mse=1.263701 step=0.050000
2017/08/29 16:04:57 step 5: mse=1.262071 step=0.050000
2017/08/29 16:05:01 step 6: mse=1.260550 step=0.050000
2017/08/29 16:05:04 step 7: mse=1.259118 step=0.050000
2017/08/29 16:05:04 Saving...
2017/08/29 16:05:04 Gathering batch of experience...
2017/08/29 16:05:30 batch 83: mean=4.756341 stddev=1.495666 entropy=1.940215 frames=100140 count=5007
2017/08/29 16:05:30 Training policy...
2017/08/29 16:05:43 step 0: objective=0.269565 reg=0.019402
2017/08/29 16:05:49 step 1: objective=0.270639 reg=0.019382
2017/08/29 16:05:54 step 2: objective=0.271316 reg=0.019370
2017/08/29 16:05:59 step 3: objective=0.271811 reg=0.019333
2017/08/29 16:06:04 step 4: objective=0.271506 reg=0.019391
2017/08/29 16:06:09 step 5: objective=0.272107 reg=0.019309
2017/08/29 16:06:14 step 6: objective=0.272001 reg=0.019389
2017/08/29 16:06:19 step 7: objective=0.272059 reg=0.019303
2017/08/29 16:06:19 Training value function...
2017/08/29 16:06:25 step 0: mse=1.297062 step=0.050000
2017/08/29 16:06:29 step 1: mse=1.294933 step=0.050000
2017/08/29 16:06:32 step 2: mse=1.292952 step=0.050000
2017/08/29 16:06:36 step 3: mse=1.291106 step=0.050000
2017/08/29 16:06:39 step 4: mse=1.289394 step=0.050000
2017/08/29 16:06:43 step 5: mse=1.287792 step=0.050000
2017/08/29 16:06:46 step 6: mse=1.286273 step=0.050000
2017/08/29 16:06:50 step 7: mse=1.284861 step=0.050000
2017/08/29 16:06:50 Saving...
2017/08/29 16:06:50 Gathering batch of experience...
2017/08/29 16:07:16 batch 84: mean=4.756741 stddev=1.491585 entropy=1.938182 frames=100140 count=5007
2017/08/29 16:07:16 Training policy...
2017/08/29 16:07:29 step 0: objective=0.247001 reg=0.019382
2017/08/29 16:07:34 step 1: objective=0.247867 reg=0.019369
2017/08/29 16:07:40 step 2: objective=0.248528 reg=0.019346
2017/08/29 16:07:46 step 3: objective=0.249123 reg=0.019349
2017/08/29 16:07:51 step 4: objective=0.249516 reg=0.019327
2017/08/29 16:07:56 step 5: objective=0.249651 reg=0.019328
2017/08/29 16:08:03 step 6: objective=0.249937 reg=0.019316
2017/08/29 16:08:09 step 7: objective=0.250133 reg=0.019299
2017/08/29 16:08:09 Training value function...
2017/08/29 16:08:14 step 0: mse=1.240536 step=0.050000
2017/08/29 16:08:18 step 1: mse=1.240140 step=0.050000
2017/08/29 16:08:21 step 2: mse=1.239782 step=0.050000
2017/08/29 16:08:25 step 3: mse=1.239452 step=0.050000
2017/08/29 16:08:28 step 4: mse=1.239160 step=0.050000
2017/08/29 16:08:32 step 5: mse=1.238880 step=0.050000
2017/08/29 16:08:35 step 6: mse=1.238619 step=0.050000
2017/08/29 16:08:38 step 7: mse=1.238371 step=0.050000
2017/08/29 16:08:38 Saving...
2017/08/29 16:08:39 Gathering batch of experience...
2017/08/29 16:09:05 batch 85: mean=4.772718 stddev=1.523228 entropy=1.931594 frames=100140 count=5007
2017/08/29 16:09:05 Training policy...
2017/08/29 16:09:17 step 0: objective=0.255410 reg=0.019316
2017/08/29 16:09:22 step 1: objective=0.256566 reg=0.019284
2017/08/29 16:09:27 step 2: objective=0.256534 reg=0.019313
2017/08/29 16:09:33 step 3: objective=0.257398 reg=0.019251
2017/08/29 16:09:38 step 4: objective=0.256735 reg=0.019329
2017/08/29 16:09:43 step 5: objective=0.257466 reg=0.019237
2017/08/29 16:09:48 step 6: objective=0.257065 reg=0.019328
2017/08/29 16:09:53 step 7: objective=0.257839 reg=0.019215
2017/08/29 16:09:53 Training value function...
2017/08/29 16:09:59 step 0: mse=1.295193 step=0.050000
2017/08/29 16:10:02 step 1: mse=1.294343 step=0.050000
2017/08/29 16:10:06 step 2: mse=1.293557 step=0.050000
2017/08/29 16:10:09 step 3: mse=1.292811 step=0.050000
2017/08/29 16:10:13 step 4: mse=1.292099 step=0.050000
2017/08/29 16:10:16 step 5: mse=1.291456 step=0.050000
2017/08/29 16:10:20 step 6: mse=1.290858 step=0.050000
2017/08/29 16:10:23 step 7: mse=1.290282 step=0.050000
2017/08/29 16:10:23 Saving...
2017/08/29 16:10:23 Gathering batch of experience...
2017/08/29 16:10:49 batch 86: mean=4.764530 stddev=1.487138 entropy=1.927406 frames=100140 count=5007
2017/08/29 16:10:49 Training policy...
2017/08/29 16:11:02 step 0: objective=0.258628 reg=0.019274
2017/08/29 16:11:07 step 1: objective=0.259096 reg=0.019225
2017/08/29 16:11:12 step 2: objective=0.258809 reg=0.019276
2017/08/29 16:11:17 step 3: objective=0.259351 reg=0.019195
2017/08/29 16:11:22 step 4: objective=0.259000 reg=0.019279
2017/08/29 16:11:27 step 5: objective=0.259665 reg=0.019182
2017/08/29 16:11:32 step 6: objective=0.259300 reg=0.019268
2017/08/29 16:11:37 step 7: objective=0.260058 reg=0.019176
2017/08/29 16:11:37 Training value function...
2017/08/29 16:11:43 step 0: mse=1.246533 step=0.050000
2017/08/29 16:11:46 step 1: mse=1.245444 step=0.050000
2017/08/29 16:11:50 step 2: mse=1.244416 step=0.050000
2017/08/29 16:11:53 step 3: mse=1.243455 step=0.050000
2017/08/29 16:11:57 step 4: mse=1.242573 step=0.050000
2017/08/29 16:12:00 step 5: mse=1.241697 step=0.050000
2017/08/29 16:12:04 step 6: mse=1.240886 step=0.050000
2017/08/29 16:12:07 step 7: mse=1.240125 step=0.050000
2017/08/29 16:12:07 Saving...
2017/08/29 16:12:07 Gathering batch of experience...
2017/08/29 16:12:34 batch 87: mean=4.776713 stddev=1.508803 entropy=1.930569 frames=100140 count=5007
2017/08/29 16:12:34 Training policy...
2017/08/29 16:12:46 step 0: objective=0.249576 reg=0.019306
2017/08/29 16:12:51 step 1: objective=0.250595 reg=0.019266
2017/08/29 16:12:56 step 2: objective=0.250763 reg=0.019297
2017/08/29 16:13:01 step 3: objective=0.251424 reg=0.019226
2017/08/29 16:13:06 step 4: objective=0.250914 reg=0.019290
2017/08/29 16:13:11 step 5: objective=0.251973 reg=0.019213
2017/08/29 16:13:16 step 6: objective=0.251502 reg=0.019268
2017/08/29 16:13:21 step 7: objective=0.252451 reg=0.019185
2017/08/29 16:13:21 Training value function...
2017/08/29 16:13:28 step 0: mse=1.269684 step=0.050000
2017/08/29 16:13:31 step 1: mse=1.268917 step=0.050000
2017/08/29 16:13:35 step 2: mse=1.268234 step=0.050000
2017/08/29 16:13:38 step 3: mse=1.267569 step=0.050000
2017/08/29 16:13:42 step 4: mse=1.266962 step=0.050000
2017/08/29 16:13:45 step 5: mse=1.266356 step=0.050000
2017/08/29 16:13:49 step 6: mse=1.265793 step=0.050000
2017/08/29 16:13:52 step 7: mse=1.265255 step=0.050000
2017/08/29 16:13:52 Saving...
2017/08/29 16:13:52 Gathering batch of experience...
2017/08/29 16:14:18 batch 88: mean=4.744358 stddev=1.498070 entropy=1.919881 frames=100140 count=5007
2017/08/29 16:14:18 Training policy...
2017/08/29 16:14:31 step 0: objective=0.242730 reg=0.019199
2017/08/29 16:14:36 step 1: objective=0.243563 reg=0.019181
2017/08/29 16:14:41 step 2: objective=0.244275 reg=0.019136
2017/08/29 16:14:46 step 3: objective=0.244723 reg=0.019116
2017/08/29 16:14:51 step 4: objective=0.245046 reg=0.019112
2017/08/29 16:14:56 step 5: objective=0.245489 reg=0.019085
2017/08/29 16:15:01 step 6: objective=0.245175 reg=0.019112
2017/08/29 16:15:06 step 7: objective=0.246376 reg=0.019065
2017/08/29 16:15:06 Training value function...
2017/08/29 16:15:12 step 0: mse=1.257715 step=0.050000
2017/08/29 16:15:16 step 1: mse=1.257853 step=0.050000
2017/08/29 16:15:19 step 2: mse=1.258002 step=0.050000
2017/08/29 16:15:23 step 3: mse=1.258157 step=0.050000
2017/08/29 16:15:26 step 4: mse=1.258317 step=0.050000
2017/08/29 16:15:30 step 5: mse=1.258479 step=0.050000
2017/08/29 16:15:33 step 6: mse=1.258633 step=0.050000
2017/08/29 16:15:37 step 7: mse=1.258777 step=0.050000
2017/08/29 16:15:37 Saving...
2017/08/29 16:15:37 Gathering batch of experience...
2017/08/29 16:16:03 batch 89: mean=4.778710 stddev=1.499005 entropy=1.911568 frames=100140 count=5007
2017/08/29 16:16:03 Training policy...
2017/08/29 16:16:15 step 0: objective=0.266851 reg=0.019116
2017/08/29 16:16:21 step 1: objective=0.267740 reg=0.019094
2017/08/29 16:16:27 step 2: objective=0.268409 reg=0.019086
2017/08/29 16:16:33 step 3: objective=0.268839 reg=0.019065
2017/08/29 16:16:38 step 4: objective=0.269402 reg=0.019063
2017/08/29 16:16:44 step 5: objective=0.269923 reg=0.019046
2017/08/29 16:16:49 step 6: objective=0.270368 reg=0.019026
2017/08/29 16:16:54 step 7: objective=0.270851 reg=0.019000
2017/08/29 16:16:54 Training value function...
2017/08/29 16:17:00 step 0: mse=1.262528 step=0.050000
2017/08/29 16:17:03 step 1: mse=1.260593 step=0.050000
2017/08/29 16:17:07 step 2: mse=1.258799 step=0.050000
2017/08/29 16:17:10 step 3: mse=1.257135 step=0.050000
2017/08/29 16:17:14 step 4: mse=1.255583 step=0.050000
2017/08/29 16:17:17 step 5: mse=1.254136 step=0.050000
2017/08/29 16:17:21 step 6: mse=1.252786 step=0.050000
2017/08/29 16:17:24 step 7: mse=1.251525 step=0.050000
2017/08/29 16:17:24 Saving...
2017/08/29 16:17:24 Gathering batch of experience...
2017/08/29 16:17:50 batch 90: mean=4.746155 stddev=1.507743 entropy=1.900510 frames=100140 count=5007
2017/08/29 16:17:50 Training policy...
2017/08/29 16:18:03 step 0: objective=0.237663 reg=0.019005
2017/08/29 16:18:08 step 1: objective=0.238547 reg=0.018978
2017/08/29 16:18:13 step 2: objective=0.238692 reg=0.018987
2017/08/29 16:18:18 step 3: objective=0.239413 reg=0.018961
2017/08/29 16:18:23 step 4: objective=0.239616 reg=0.018989
2017/08/29 16:18:29 step 5: objective=0.240580 reg=0.018937
2017/08/29 16:18:34 step 6: objective=0.240043 reg=0.018982
2017/08/29 16:18:39 step 7: objective=0.240965 reg=0.018914
2017/08/29 16:18:39 Training value function...
2017/08/29 16:18:45 step 0: mse=1.252053 step=0.050000
2017/08/29 16:18:49 step 1: mse=1.252021 step=0.050000
2017/08/29 16:18:52 step 2: mse=1.252010 step=0.050000
2017/08/29 16:18:55 step 3: mse=1.251996 step=0.050000
2017/08/29 16:18:59 step 4: mse=1.252011 step=0.050000
2017/08/29 16:19:02 step 5: mse=1.252022 step=0.050000
2017/08/29 16:19:06 step 6: mse=1.252048 step=0.050000
2017/08/29 16:19:09 step 7: mse=1.252065 step=0.050000
2017/08/29 16:19:09 Saving...
2017/08/29 16:19:09 Gathering batch of experience...
2017/08/29 16:19:36 batch 91: mean=4.800080 stddev=1.475374 entropy=1.899904 frames=100140 count=5007
2017/08/29 16:19:36 Training policy...
2017/08/29 16:19:48 step 0: objective=0.256040 reg=0.018999
2017/08/29 16:19:54 step 1: objective=0.256810 reg=0.018978
2017/08/29 16:20:00 step 2: objective=0.257368 reg=0.018952
2017/08/29 16:20:06 step 3: objective=0.257365 reg=0.018978
2017/08/29 16:20:11 step 4: objective=0.257769 reg=0.018919
2017/08/29 16:20:16 step 5: objective=0.257961 reg=0.018972
2017/08/29 16:20:21 step 6: objective=0.257936 reg=0.018914
2017/08/29 16:20:27 step 7: objective=0.258017 reg=0.018966
2017/08/29 16:20:27 Training value function...
2017/08/29 16:20:32 step 0: mse=1.242771 step=0.050000
2017/08/29 16:20:36 step 1: mse=1.241862 step=0.050000
2017/08/29 16:20:39 step 2: mse=1.241008 step=0.050000
2017/08/29 16:20:43 step 3: mse=1.240230 step=0.050000
2017/08/29 16:20:46 step 4: mse=1.239507 step=0.050000
2017/08/29 16:20:50 step 5: mse=1.238822 step=0.050000
2017/08/29 16:20:53 step 6: mse=1.238174 step=0.050000
2017/08/29 16:20:57 step 7: mse=1.237576 step=0.050000
2017/08/29 16:20:57 Saving...
2017/08/29 16:20:57 Gathering batch of experience...
2017/08/29 16:21:23 batch 92: mean=4.785700 stddev=1.473354 entropy=1.889582 frames=100140 count=5007
2017/08/29 16:21:23 Training policy...
2017/08/29 16:21:35 step 0: objective=0.243439 reg=0.018896
2017/08/29 16:21:41 step 1: objective=0.244300 reg=0.018878
2017/08/29 16:21:46 step 2: objective=0.245252 reg=0.018869
2017/08/29 16:21:51 step 3: objective=0.246207 reg=0.018851
2017/08/29 16:21:56 step 4: objective=0.246847 reg=0.018840
2017/08/29 16:22:02 step 5: objective=0.247352 reg=0.018830
2017/08/29 16:22:07 step 6: objective=0.247856 reg=0.018813
2017/08/29 16:22:12 step 7: objective=0.247872 reg=0.018777
2017/08/29 16:22:12 Training value function...
2017/08/29 16:22:18 step 0: mse=1.213527 step=0.050000
2017/08/29 16:22:21 step 1: mse=1.213363 step=0.050000
2017/08/29 16:22:25 step 2: mse=1.213205 step=0.050000
2017/08/29 16:22:28 step 3: mse=1.213073 step=0.050000
2017/08/29 16:22:32 step 4: mse=1.212976 step=0.050000
2017/08/29 16:22:35 step 5: mse=1.212873 step=0.050000
2017/08/29 16:22:39 step 6: mse=1.212768 step=0.050000
2017/08/29 16:22:42 step 7: mse=1.212678 step=0.050000
2017/08/29 16:22:42 Saving...
2017/08/29 16:22:42 Gathering batch of experience...
2017/08/29 16:23:09 batch 93: mean=4.818854 stddev=1.484673 entropy=1.884625 frames=100140 count=5007
2017/08/29 16:23:09 Training policy...
2017/08/29 16:23:21 step 0: objective=0.272999 reg=0.018846
2017/08/29 16:23:26 step 1: objective=0.273545 reg=0.018807
2017/08/29 16:23:31 step 2: objective=0.273824 reg=0.018818
2017/08/29 16:23:37 step 3: objective=0.274299 reg=0.018803
2017/08/29 16:23:42 step 4: objective=0.274562 reg=0.018811
2017/08/29 16:23:47 step 5: objective=0.274920 reg=0.018756
2017/08/29 16:23:52 step 6: objective=0.274880 reg=0.018801
2017/08/29 16:23:57 step 7: objective=0.275530 reg=0.018736
2017/08/29 16:23:57 Training value function...
2017/08/29 16:24:03 step 0: mse=1.236588 step=0.050000
2017/08/29 16:24:07 step 1: mse=1.234083 step=0.050000
2017/08/29 16:24:10 step 2: mse=1.231758 step=0.050000
2017/08/29 16:24:14 step 3: mse=1.229588 step=0.050000
2017/08/29 16:24:17 step 4: mse=1.227576 step=0.050000
2017/08/29 16:24:21 step 5: mse=1.225711 step=0.050000
2017/08/29 16:24:24 step 6: mse=1.223951 step=0.050000
2017/08/29 16:24:28 step 7: mse=1.222311 step=0.050000
2017/08/29 16:24:28 Saving...
2017/08/29 16:24:28 Gathering batch of experience...
2017/08/29 16:24:54 batch 94: mean=4.800879 stddev=1.469242 entropy=1.888680 frames=100140 count=5007
2017/08/29 16:24:54 Training policy...
2017/08/29 16:25:07 step 0: objective=0.237617 reg=0.018887
2017/08/29 16:25:12 step 1: objective=0.238373 reg=0.018857
2017/08/29 16:25:18 step 2: objective=0.238834 reg=0.018876
2017/08/29 16:25:23 step 3: objective=0.239150 reg=0.018808
2017/08/29 16:25:28 step 4: objective=0.239378 reg=0.018874
2017/08/29 16:25:33 step 5: objective=0.239508 reg=0.018795
2017/08/29 16:25:39 step 6: objective=0.239781 reg=0.018868
2017/08/29 16:25:44 step 7: objective=0.240035 reg=0.018785
2017/08/29 16:25:44 Training value function...
2017/08/29 16:25:50 step 0: mse=1.196871 step=0.050000
2017/08/29 16:25:53 step 1: mse=1.196828 step=0.050000
2017/08/29 16:25:57 step 2: mse=1.196811 step=0.050000
2017/08/29 16:26:00 step 3: mse=1.196797 step=0.050000
2017/08/29 16:26:04 step 4: mse=1.196808 step=0.050000
2017/08/29 16:26:07 step 5: mse=1.196817 step=0.050000
2017/08/29 16:26:10 step 6: mse=1.196829 step=0.050000
2017/08/29 16:26:14 step 7: mse=1.196846 step=0.050000
2017/08/29 16:26:14 Saving...
2017/08/29 16:26:14 Gathering batch of experience...
2017/08/29 16:26:40 batch 95: mean=4.847813 stddev=1.497620 entropy=1.879829 frames=100140 count=5007
2017/08/29 16:26:40 Training policy...
2017/08/29 16:26:53 step 0: objective=0.260472 reg=0.018798
2017/08/29 16:26:58 step 1: objective=0.261232 reg=0.018765
2017/08/29 16:27:03 step 2: objective=0.261707 reg=0.018759
2017/08/29 16:27:09 step 3: objective=0.262461 reg=0.018739
2017/08/29 16:27:14 step 4: objective=0.262660 reg=0.018761
2017/08/29 16:27:19 step 5: objective=0.262931 reg=0.018717
2017/08/29 16:27:24 step 6: objective=0.263053 reg=0.018758
2017/08/29 16:27:29 step 7: objective=0.263860 reg=0.018712
2017/08/29 16:27:29 Training value function...
2017/08/29 16:27:35 step 0: mse=1.271751 step=0.050000
2017/08/29 16:27:39 step 1: mse=1.270325 step=0.050000
2017/08/29 16:27:42 step 2: mse=1.269001 step=0.050000
2017/08/29 16:27:46 step 3: mse=1.267754 step=0.050000
2017/08/29 16:27:49 step 4: mse=1.266593 step=0.050000
2017/08/29 16:27:52 step 5: mse=1.265496 step=0.050000
2017/08/29 16:27:56 step 6: mse=1.264463 step=0.050000
2017/08/29 16:27:59 step 7: mse=1.263464 step=0.050000
2017/08/29 16:27:59 Saving...
2017/08/29 16:27:59 Gathering batch of experience...
2017/08/29 16:28:26 batch 96: mean=4.830038 stddev=1.475339 entropy=1.874890 frames=100140 count=5007
2017/08/29 16:28:26 Training policy...
2017/08/29 16:28:39 step 0: objective=0.264655 reg=0.018749
2017/08/29 16:28:44 step 1: objective=0.265711 reg=0.018717
2017/08/29 16:28:50 step 2: objective=0.266263 reg=0.018717
2017/08/29 16:28:56 step 3: objective=0.266670 reg=0.018679
2017/08/29 16:29:01 step 4: objective=0.266353 reg=0.018722
2017/08/29 16:29:07 step 5: objective=0.266529 reg=0.018652
2017/08/29 16:29:12 step 6: objective=0.266650 reg=0.018715
2017/08/29 16:29:18 step 7: objective=0.267138 reg=0.018637
2017/08/29 16:29:18 Training value function...
2017/08/29 16:29:24 step 0: mse=1.243515 step=0.050000
2017/08/29 16:29:27 step 1: mse=1.241910 step=0.050000
2017/08/29 16:29:30 step 2: mse=1.240414 step=0.050000
2017/08/29 16:29:34 step 3: mse=1.239016 step=0.050000
2017/08/29 16:29:37 step 4: mse=1.237687 step=0.050000
2017/08/29 16:29:41 step 5: mse=1.236469 step=0.050000
2017/08/29 16:29:44 step 6: mse=1.235333 step=0.050000
2017/08/29 16:29:48 step 7: mse=1.234253 step=0.050000
2017/08/29 16:29:48 Saving...
2017/08/29 16:29:48 Gathering batch of experience...
2017/08/29 16:30:14 batch 97: mean=4.856002 stddev=1.496496 entropy=1.866363 frames=100140 count=5007
2017/08/29 16:30:14 Training policy...
2017/08/29 16:30:27 step 0: objective=0.250951 reg=0.018664
2017/08/29 16:30:32 step 1: objective=0.251721 reg=0.018631
2017/08/29 16:30:37 step 2: objective=0.252374 reg=0.018651
2017/08/29 16:30:43 step 3: objective=0.253185 reg=0.018627
2017/08/29 16:30:48 step 4: objective=0.253474 reg=0.018657
2017/08/29 16:30:53 step 5: objective=0.253933 reg=0.018629
2017/08/29 16:30:58 step 6: objective=0.254285 reg=0.018592
2017/08/29 16:31:03 step 7: objective=0.254500 reg=0.018592
2017/08/29 16:31:03 Training value function...
2017/08/29 16:31:10 step 0: mse=1.218109 step=0.050000
2017/08/29 16:31:13 step 1: mse=1.217424 step=0.050000
2017/08/29 16:31:17 step 2: mse=1.216800 step=0.050000
2017/08/29 16:31:20 step 3: mse=1.216221 step=0.050000
2017/08/29 16:31:24 step 4: mse=1.215684 step=0.050000
2017/08/29 16:31:27 step 5: mse=1.215186 step=0.050000
2017/08/29 16:31:31 step 6: mse=1.214715 step=0.050000
2017/08/29 16:31:34 step 7: mse=1.214276 step=0.050000
2017/08/29 16:31:34 Saving...
2017/08/29 16:31:34 Gathering batch of experience...
2017/08/29 16:32:01 batch 98: mean=4.813661 stddev=1.475527 entropy=1.860539 frames=100140 count=5007
2017/08/29 16:32:01 Training policy...
2017/08/29 16:32:13 step 0: objective=0.236853 reg=0.018606
2017/08/29 16:32:18 step 1: objective=0.237861 reg=0.018596
2017/08/29 16:32:23 step 2: objective=0.238523 reg=0.018569
2017/08/29 16:32:29 step 3: objective=0.238683 reg=0.018576
2017/08/29 16:32:34 step 4: objective=0.239252 reg=0.018532
2017/08/29 16:32:39 step 5: objective=0.239138 reg=0.018576
2017/08/29 16:32:44 step 6: objective=0.239695 reg=0.018508
2017/08/29 16:32:50 step 7: objective=0.239313 reg=0.018581
2017/08/29 16:32:50 Training value function...
2017/08/29 16:32:56 step 0: mse=1.195615 step=0.050000
2017/08/29 16:32:59 step 1: mse=1.195545 step=0.050000
2017/08/29 16:33:02 step 2: mse=1.195499 step=0.050000
2017/08/29 16:33:06 step 3: mse=1.195465 step=0.050000
2017/08/29 16:33:09 step 4: mse=1.195450 step=0.050000
2017/08/29 16:33:13 step 5: mse=1.195441 step=0.050000
2017/08/29 16:33:16 step 6: mse=1.195424 step=0.050000
2017/08/29 16:33:20 step 7: mse=1.195416 step=0.050000
2017/08/29 16:33:20 Saving...
2017/08/29 16:33:20 Gathering batch of experience...
2017/08/29 16:33:46 batch 99: mean=4.844418 stddev=1.493465 entropy=1.852144 frames=100140 count=5007
2017/08/29 16:33:46 Training policy...
2017/08/29 16:33:59 step 0: objective=0.257766 reg=0.018521
2017/08/29 16:34:04 step 1: objective=0.258725 reg=0.018505
2017/08/29 16:34:10 step 2: objective=0.259221 reg=0.018495
2017/08/29 16:34:15 step 3: objective=0.259871 reg=0.018472
2017/08/29 16:34:20 step 4: objective=0.260215 reg=0.018475
2017/08/29 16:34:25 step 5: objective=0.260613 reg=0.018470
2017/08/29 16:34:31 step 6: objective=0.260970 reg=0.018442
2017/08/29 16:34:36 step 7: objective=0.260999 reg=0.018459
2017/08/29 16:34:36 Training value function...
2017/08/29 16:34:42 step 0: mse=1.235740 step=0.050000
2017/08/29 16:34:45 step 1: mse=1.234767 step=0.050000
2017/08/29 16:34:49 step 2: mse=1.233868 step=0.050000
2017/08/29 16:34:52 step 3: mse=1.233022 step=0.050000
2017/08/29 16:34:56 step 4: mse=1.232243 step=0.050000
2017/08/29 16:34:59 step 5: mse=1.231491 step=0.050000
2017/08/29 16:35:03 step 6: mse=1.230801 step=0.050000
2017/08/29 16:35:06 step 7: mse=1.230133 step=0.050000
2017/08/29 16:35:06 Saving...
2017/08/29 16:35:06 Gathering batch of experience...
2017/08/29 16:35:33 batch 100: mean=4.909327 stddev=1.499140 entropy=1.838668 frames=100140 count=5007
2017/08/29 16:35:33 Training policy...
2017/08/29 16:35:46 step 0: objective=0.273858 reg=0.018387
2017/08/29 16:35:51 step 1: objective=0.274746 reg=0.018378
2017/08/29 16:35:56 step 2: objective=0.275429 reg=0.018355
2017/08/29 16:36:02 step 3: objective=0.275740 reg=0.018373
2017/08/29 16:36:08 step 4: objective=0.276142 reg=0.018326
2017/08/29 16:36:13 step 5: objective=0.276146 reg=0.018377
2017/08/29 16:36:18 step 6: objective=0.276852 reg=0.018315
2017/08/29 16:36:24 step 7: objective=0.276775 reg=0.018351
2017/08/29 16:36:24 Training value function...
2017/08/29 16:36:29 step 0: mse=1.286245 step=0.050000
2017/08/29 16:36:33 step 1: mse=1.284199 step=0.050000
2017/08/29 16:36:36 step 2: mse=1.282308 step=0.050000
2017/08/29 16:36:40 step 3: mse=1.280553 step=0.050000
2017/08/29 16:36:43 step 4: mse=1.278910 step=0.050000
2017/08/29 16:36:47 step 5: mse=1.277368 step=0.050000
2017/08/29 16:36:50 step 6: mse=1.275913 step=0.050000
2017/08/29 16:36:54 step 7: mse=1.274549 step=0.050000
2017/08/29 16:36:54 Saving...
2017/08/29 16:36:54 Gathering batch of experience...
2017/08/29 16:37:20 batch 101: mean=4.889954 stddev=1.482631 entropy=1.834034 frames=100140 count=5007
2017/08/29 16:37:20 Training policy...
2017/08/29 16:37:33 step 0: objective=0.245835 reg=0.018340
2017/08/29 16:37:38 step 1: objective=0.246783 reg=0.018334
2017/08/29 16:37:44 step 2: objective=0.247166 reg=0.018316
2017/08/29 16:37:49 step 3: objective=0.247891 reg=0.018298
2017/08/29 16:37:54 step 4: objective=0.248457 reg=0.018297
2017/08/29 16:38:00 step 5: objective=0.248901 reg=0.018286
2017/08/29 16:38:05 step 6: objective=0.249355 reg=0.018269
2017/08/29 16:38:11 step 7: objective=0.249464 reg=0.018281
2017/08/29 16:38:11 Training value function...
2017/08/29 16:38:16 step 0: mse=1.215757 step=0.050000
2017/08/29 16:38:20 step 1: mse=1.215221 step=0.050000
2017/08/29 16:38:23 step 2: mse=1.214726 step=0.050000
2017/08/29 16:38:27 step 3: mse=1.214266 step=0.050000
2017/08/29 16:38:30 step 4: mse=1.213839 step=0.050000
2017/08/29 16:38:34 step 5: mse=1.213436 step=0.050000
2017/08/29 16:38:37 step 6: mse=1.213056 step=0.050000
2017/08/29 16:38:40 step 7: mse=1.212696 step=0.050000
2017/08/29 16:38:40 Saving...
2017/08/29 16:38:40 Gathering batch of experience...
2017/08/29 16:39:07 batch 102: mean=4.938886 stddev=1.493164 entropy=1.825908 frames=100140 count=5007
2017/08/29 16:39:07 Training policy...
2017/08/29 16:39:20 step 0: objective=0.278057 reg=0.018259
2017/08/29 16:39:25 step 1: objective=0.279241 reg=0.018245
2017/08/29 16:39:31 step 2: objective=0.279884 reg=0.018236
2017/08/29 16:39:36 step 3: objective=0.280539 reg=0.018222
2017/08/29 16:39:41 step 4: objective=0.280761 reg=0.018219
2017/08/29 16:39:46 step 5: objective=0.281132 reg=0.018210
2017/08/29 16:39:52 step 6: objective=0.281597 reg=0.018206
2017/08/29 16:39:57 step 7: objective=0.281896 reg=0.018198
2017/08/29 16:39:57 Training value function...
2017/08/29 16:40:03 step 0: mse=1.279977 step=0.050000
2017/08/29 16:40:06 step 1: mse=1.277539 step=0.050000
2017/08/29 16:40:10 step 2: mse=1.275272 step=0.050000
2017/08/29 16:40:13 step 3: mse=1.273164 step=0.050000
2017/08/29 16:40:17 step 4: mse=1.271219 step=0.050000
2017/08/29 16:40:20 step 5: mse=1.269406 step=0.050000
2017/08/29 16:40:24 step 6: mse=1.267710 step=0.050000
2017/08/29 16:40:27 step 7: mse=1.266097 step=0.050000
2017/08/29 16:40:27 Saving...
2017/08/29 16:40:27 Gathering batch of experience...
2017/08/29 16:40:54 batch 103: mean=4.950070 stddev=1.476229 entropy=1.818264 frames=100140 count=5007
2017/08/29 16:40:54 Training policy...
2017/08/29 16:41:06 step 0: objective=0.271870 reg=0.018183
2017/08/29 16:41:12 step 1: objective=0.272513 reg=0.018158
2017/08/29 16:41:17 step 2: objective=0.273152 reg=0.018137
2017/08/29 16:41:22 step 3: objective=0.273641 reg=0.018157
2017/08/29 16:41:28 step 4: objective=0.274280 reg=0.018128
2017/08/29 16:41:33 step 5: objective=0.274735 reg=0.018148
2017/08/29 16:41:38 step 6: objective=0.274874 reg=0.018130
2017/08/29 16:41:44 step 7: objective=0.275192 reg=0.018132
2017/08/29 16:41:44 Training value function...
2017/08/29 16:41:49 step 0: mse=1.232563 step=0.050000
2017/08/29 16:41:53 step 1: mse=1.230177 step=0.050000
2017/08/29 16:41:56 step 2: mse=1.227931 step=0.050000
2017/08/29 16:42:00 step 3: mse=1.225846 step=0.050000
2017/08/29 16:42:03 step 4: mse=1.223845 step=0.050000
2017/08/29 16:42:07 step 5: mse=1.222031 step=0.050000
2017/08/29 16:42:10 step 6: mse=1.220307 step=0.050000
2017/08/29 16:42:13 step 7: mse=1.218657 step=0.050000
2017/08/29 16:42:13 Saving...
2017/08/29 16:42:14 Gathering batch of experience...
2017/08/29 16:42:40 batch 104: mean=4.900739 stddev=1.500926 entropy=1.812900 frames=100140 count=5007
2017/08/29 16:42:40 Training policy...
2017/08/29 16:42:53 step 0: objective=0.246819 reg=0.018129
2017/08/29 16:42:58 step 1: objective=0.247699 reg=0.018113
2017/08/29 16:43:03 step 2: objective=0.248010 reg=0.018123
2017/08/29 16:43:09 step 3: objective=0.248568 reg=0.018098
2017/08/29 16:43:15 step 4: objective=0.248709 reg=0.018112
2017/08/29 16:43:20 step 5: objective=0.249084 reg=0.018088
2017/08/29 16:43:26 step 6: objective=0.249455 reg=0.018100
2017/08/29 16:43:31 step 7: objective=0.249845 reg=0.018070
2017/08/29 16:43:31 Training value function...
2017/08/29 16:43:37 step 0: mse=1.239916 step=0.050000
2017/08/29 16:43:40 step 1: mse=1.239885 step=0.050000
2017/08/29 16:43:44 step 2: mse=1.239859 step=0.050000
2017/08/29 16:43:47 step 3: mse=1.239812 step=0.050000
2017/08/29 16:43:51 step 4: mse=1.239786 step=0.050000
2017/08/29 16:43:54 step 5: mse=1.239763 step=0.050000
2017/08/29 16:43:58 step 6: mse=1.239744 step=0.050000
2017/08/29 16:44:01 step 7: mse=1.239722 step=0.050000
2017/08/29 16:44:01 Saving...
2017/08/29 16:44:01 Gathering batch of experience...
2017/08/29 16:44:28 batch 105: mean=4.939285 stddev=1.503045 entropy=1.809976 frames=100140 count=5007
2017/08/29 16:44:28 Training policy...
2017/08/29 16:44:41 step 0: objective=0.251750 reg=0.018100
2017/08/29 16:44:46 step 1: objective=0.252628 reg=0.018091
2017/08/29 16:44:52 step 2: objective=0.253034 reg=0.018094
2017/08/29 16:44:58 step 3: objective=0.253740 reg=0.018090
2017/08/29 16:45:04 step 4: objective=0.254417 reg=0.018064
2017/08/29 16:45:09 step 5: objective=0.254636 reg=0.018076
2017/08/29 16:45:14 step 6: objective=0.254901 reg=0.018029
2017/08/29 16:45:19 step 7: objective=0.254736 reg=0.018069
2017/08/29 16:45:19 Training value function...
2017/08/29 16:45:26 step 0: mse=1.251136 step=0.050000
2017/08/29 16:45:29 step 1: mse=1.250334 step=0.050000
2017/08/29 16:45:33 step 2: mse=1.249595 step=0.050000
2017/08/29 16:45:36 step 3: mse=1.248906 step=0.050000
2017/08/29 16:45:39 step 4: mse=1.248262 step=0.050000
2017/08/29 16:45:43 step 5: mse=1.247659 step=0.050000
2017/08/29 16:45:46 step 6: mse=1.247096 step=0.050000
2017/08/29 16:45:50 step 7: mse=1.246529 step=0.050000
2017/08/29 16:45:50 Saving...
2017/08/29 16:45:50 Gathering batch of experience...
2017/08/29 16:46:17 batch 106: mean=4.907729 stddev=1.496375 entropy=1.803546 frames=100140 count=5007
2017/08/29 16:46:17 Training policy...
2017/08/29 16:46:29 step 0: objective=0.248127 reg=0.018036
2017/08/29 16:46:35 step 1: objective=0.248929 reg=0.018025
2017/08/29 16:46:40 step 2: objective=0.249825 reg=0.018006
2017/08/29 16:46:45 step 3: objective=0.250467 reg=0.017996
2017/08/29 16:46:51 step 4: objective=0.250936 reg=0.017973
2017/08/29 16:46:56 step 5: objective=0.250915 reg=0.018002
2017/08/29 16:47:01 step 6: objective=0.251442 reg=0.017945
2017/08/29 16:47:07 step 7: objective=0.251451 reg=0.017983
2017/08/29 16:47:07 Training value function...
2017/08/29 16:47:13 step 0: mse=1.207075 step=0.050000
2017/08/29 16:47:16 step 1: mse=1.206736 step=0.050000
2017/08/29 16:47:20 step 2: mse=1.206428 step=0.050000
2017/08/29 16:47:23 step 3: mse=1.206142 step=0.050000
2017/08/29 16:47:27 step 4: mse=1.205878 step=0.050000
2017/08/29 16:47:30 step 5: mse=1.205629 step=0.050000
2017/08/29 16:47:34 step 6: mse=1.205388 step=0.050000
2017/08/29 16:47:37 step 7: mse=1.205167 step=0.050000
2017/08/29 16:47:37 Saving...
2017/08/29 16:47:37 Gathering batch of experience...
2017/08/29 16:48:04 batch 107: mean=4.931096 stddev=1.502626 entropy=1.795173 frames=100140 count=5007
2017/08/29 16:48:04 Training policy...
2017/08/29 16:48:17 step 0: objective=0.247289 reg=0.017952
2017/08/29 16:48:22 step 1: objective=0.248107 reg=0.017932
2017/08/29 16:48:27 step 2: objective=0.248598 reg=0.017945
2017/08/29 16:48:33 step 3: objective=0.249322 reg=0.017917
2017/08/29 16:48:38 step 4: objective=0.249651 reg=0.017927
2017/08/29 16:48:43 step 5: objective=0.250104 reg=0.017882
2017/08/29 16:48:49 step 6: objective=0.250050 reg=0.017916
2017/08/29 16:48:54 step 7: objective=0.250523 reg=0.017862
2017/08/29 16:48:54 Training value function...
2017/08/29 16:49:00 step 0: mse=1.228717 step=0.050000
2017/08/29 16:49:04 step 1: mse=1.228258 step=0.050000
2017/08/29 16:49:07 step 2: mse=1.227843 step=0.050000
2017/08/29 16:49:10 step 3: mse=1.227457 step=0.050000
2017/08/29 16:49:14 step 4: mse=1.227119 step=0.050000
2017/08/29 16:49:17 step 5: mse=1.226793 step=0.050000
2017/08/29 16:49:21 step 6: mse=1.226480 step=0.050000
2017/08/29 16:49:24 step 7: mse=1.226182 step=0.050000
2017/08/29 16:49:24 Saving...
2017/08/29 16:49:24 Gathering batch of experience...
2017/08/29 16:49:51 batch 108: mean=4.966447 stddev=1.510787 entropy=1.789463 frames=100140 count=5007
2017/08/29 16:49:51 Training policy...
2017/08/29 16:50:04 step 0: objective=0.263589 reg=0.017895
2017/08/29 16:50:09 step 1: objective=0.264736 reg=0.017891
2017/08/29 16:50:15 step 2: objective=0.265555 reg=0.017869
2017/08/29 16:50:21 step 3: objective=0.265925 reg=0.017871
2017/08/29 16:50:26 step 4: objective=0.266158 reg=0.017854
2017/08/29 16:50:31 step 5: objective=0.266266 reg=0.017873
2017/08/29 16:50:37 step 6: objective=0.266654 reg=0.017853
2017/08/29 16:50:42 step 7: objective=0.266816 reg=0.017851
2017/08/29 16:50:42 Training value function...
2017/08/29 16:50:48 step 0: mse=1.275960 step=0.050000
2017/08/29 16:50:51 step 1: mse=1.274738 step=0.050000
2017/08/29 16:50:55 step 2: mse=1.273596 step=0.050000
2017/08/29 16:50:58 step 3: mse=1.272524 step=0.050000
2017/08/29 16:51:02 step 4: mse=1.271535 step=0.050000
2017/08/29 16:51:05 step 5: mse=1.270598 step=0.050000
2017/08/29 16:51:09 step 6: mse=1.269724 step=0.050000
2017/08/29 16:51:12 step 7: mse=1.268897 step=0.050000
2017/08/29 16:51:12 Saving...
2017/08/29 16:51:12 Gathering batch of experience...
2017/08/29 16:51:39 batch 109: mean=4.926103 stddev=1.492184 entropy=1.789437 frames=100140 count=5007
2017/08/29 16:51:39 Training policy...
2017/08/29 16:51:52 step 0: objective=0.244439 reg=0.017894
2017/08/29 16:51:57 step 1: objective=0.245240 reg=0.017886
2017/08/29 16:52:02 step 2: objective=0.246132 reg=0.017876
2017/08/29 16:52:08 step 3: objective=0.246771 reg=0.017865
2017/08/29 16:52:13 step 4: objective=0.246979 reg=0.017872
2017/08/29 16:52:18 step 5: objective=0.247674 reg=0.017836
2017/08/29 16:52:24 step 6: objective=0.247941 reg=0.017851
2017/08/29 16:52:29 step 7: objective=0.248400 reg=0.017823
2017/08/29 16:52:29 Training value function...
2017/08/29 16:52:35 step 0: mse=1.196565 step=0.050000
2017/08/29 16:52:39 step 1: mse=1.196572 step=0.050000
2017/08/29 16:52:42 step 2: mse=1.196522 step=0.050000
2017/08/29 16:52:46 step 3: mse=1.196484 step=0.050000
2017/08/29 16:52:49 step 4: mse=1.196451 step=0.050000
2017/08/29 16:52:52 step 5: mse=1.196428 step=0.050000
2017/08/29 16:52:56 step 6: mse=1.196404 step=0.050000
2017/08/29 16:52:59 step 7: mse=1.196368 step=0.050000
2017/08/29 16:52:59 Saving...
2017/08/29 16:52:59 Gathering batch of experience...
2017/08/29 16:53:26 batch 110: mean=4.978430 stddev=1.497996 entropy=1.774750 frames=100140 count=5007
2017/08/29 16:53:26 Training policy...
2017/08/29 16:53:39 step 0: objective=0.266365 reg=0.017748
2017/08/29 16:53:44 step 1: objective=0.267043 reg=0.017722
2017/08/29 16:53:50 step 2: objective=0.267688 reg=0.017717
2017/08/29 16:53:55 step 3: objective=0.268480 reg=0.017717
2017/08/29 16:54:01 step 4: objective=0.268990 reg=0.017709
2017/08/29 16:54:06 step 5: objective=0.269500 reg=0.017706
2017/08/29 16:54:12 step 6: objective=0.269904 reg=0.017695
2017/08/29 16:54:17 step 7: objective=0.270504 reg=0.017678
2017/08/29 16:54:17 Training value function...
2017/08/29 16:54:23 step 0: mse=1.216974 step=0.050000
2017/08/29 16:54:27 step 1: mse=1.215134 step=0.050000
2017/08/29 16:54:30 step 2: mse=1.213422 step=0.050000
2017/08/29 16:54:34 step 3: mse=1.211761 step=0.050000
2017/08/29 16:54:37 step 4: mse=1.210262 step=0.050000
2017/08/29 16:54:40 step 5: mse=1.208859 step=0.050000
2017/08/29 16:54:44 step 6: mse=1.207502 step=0.050000
2017/08/29 16:54:47 step 7: mse=1.206271 step=0.050000
2017/08/29 16:54:47 Saving...
2017/08/29 16:54:47 Gathering batch of experience...
2017/08/29 16:55:14 batch 111: mean=4.950669 stddev=1.462453 entropy=1.771824 frames=100140 count=5007
2017/08/29 16:55:14 Training policy...
2017/08/29 16:55:27 step 0: objective=0.249845 reg=0.017718
2017/08/29 16:55:32 step 1: objective=0.250762 reg=0.017695
2017/08/29 16:55:38 step 2: objective=0.251645 reg=0.017680
2017/08/29 16:55:43 step 3: objective=0.252144 reg=0.017697
2017/08/29 16:55:48 step 4: objective=0.252706 reg=0.017659
2017/08/29 16:55:54 step 5: objective=0.252981 reg=0.017680
2017/08/29 16:55:59 step 6: objective=0.253423 reg=0.017648
2017/08/29 16:56:05 step 7: objective=0.253629 reg=0.017669
2017/08/29 16:56:05 Training value function...
2017/08/29 16:56:11 step 0: mse=1.195162 step=0.050000
2017/08/29 16:56:14 step 1: mse=1.194226 step=0.050000
2017/08/29 16:56:18 step 2: mse=1.193365 step=0.050000
2017/08/29 16:56:21 step 3: mse=1.192572 step=0.050000
2017/08/29 16:56:25 step 4: mse=1.191831 step=0.050000
2017/08/29 16:56:28 step 5: mse=1.191147 step=0.050000
2017/08/29 16:56:32 step 6: mse=1.190514 step=0.050000
2017/08/29 16:56:35 step 7: mse=1.189925 step=0.050000
2017/08/29 16:56:35 Saving...
2017/08/29 16:56:35 Gathering batch of experience...
2017/08/29 16:57:02 batch 112: mean=4.986818 stddev=1.464522 entropy=1.766021 frames=100140 count=5007
2017/08/29 16:57:02 Training policy...
2017/08/29 16:57:15 step 0: objective=0.263732 reg=0.017660
2017/08/29 16:57:21 step 1: objective=0.264639 reg=0.017650
2017/08/29 16:57:27 step 2: objective=0.265056 reg=0.017651
2017/08/29 16:57:32 step 3: objective=0.265225 reg=0.017657
2017/08/29 16:57:37 step 4: objective=0.265681 reg=0.017631
2017/08/29 16:57:43 step 5: objective=0.265748 reg=0.017659
2017/08/29 16:57:48 step 6: objective=0.266431 reg=0.017629
2017/08/29 16:57:54 step 7: objective=0.266410 reg=0.017647
2017/08/29 16:57:54 Training value function...
2017/08/29 16:58:00 step 0: mse=1.233511 step=0.050000
2017/08/29 16:58:03 step 1: mse=1.232391 step=0.050000
2017/08/29 16:58:06 step 2: mse=1.231351 step=0.050000
2017/08/29 16:58:10 step 3: mse=1.230382 step=0.050000
2017/08/29 16:58:13 step 4: mse=1.229480 step=0.050000
2017/08/29 16:58:17 step 5: mse=1.228631 step=0.050000
2017/08/29 16:58:20 step 6: mse=1.227840 step=0.050000
2017/08/29 16:58:24 step 7: mse=1.227100 step=0.050000
2017/08/29 16:58:24 Saving...
2017/08/29 16:58:24 Gathering batch of experience...
2017/08/29 16:58:51 batch 113: mean=4.969842 stddev=1.486538 entropy=1.764763 frames=100140 count=5007
2017/08/29 16:58:51 Training policy...
2017/08/29 16:59:03 step 0: objective=0.252621 reg=0.017647
2017/08/29 16:59:09 step 1: objective=0.253656 reg=0.017640
2017/08/29 16:59:14 step 2: objective=0.254161 reg=0.017640
2017/08/29 16:59:20 step 3: objective=0.254682 reg=0.017609
2017/08/29 16:59:25 step 4: objective=0.255101 reg=0.017613
2017/08/29 16:59:31 step 5: objective=0.255463 reg=0.017591
2017/08/29 16:59:36 step 6: objective=0.255790 reg=0.017606
2017/08/29 16:59:42 step 7: objective=0.256267 reg=0.017578
2017/08/29 16:59:42 Training value function...
2017/08/29 16:59:48 step 0: mse=1.218301 step=0.050000
2017/08/29 16:59:51 step 1: mse=1.217639 step=0.050000
2017/08/29 16:59:55 step 2: mse=1.217028 step=0.050000
2017/08/29 16:59:58 step 3: mse=1.216463 step=0.050000
2017/08/29 17:00:01 step 4: mse=1.215942 step=0.050000
2017/08/29 17:00:05 step 5: mse=1.215458 step=0.050000
2017/08/29 17:00:08 step 6: mse=1.215002 step=0.050000
2017/08/29 17:00:12 step 7: mse=1.214573 step=0.050000
2017/08/29 17:00:12 Saving...
2017/08/29 17:00:12 Gathering batch of experience...
2017/08/29 17:00:39 batch 114: mean=4.983623 stddev=1.508425 entropy=1.752662 frames=100140 count=5007
2017/08/29 17:00:39 Training policy...
2017/08/29 17:00:51 step 0: objective=0.243598 reg=0.017526
2017/08/29 17:00:57 step 1: objective=0.244685 reg=0.017514
2017/08/29 17:01:03 step 2: objective=0.245531 reg=0.017506
2017/08/29 17:01:09 step 3: objective=0.246303 reg=0.017506
2017/08/29 17:01:14 step 4: objective=0.246717 reg=0.017501
2017/08/29 17:01:19 step 5: objective=0.247041 reg=0.017481
2017/08/29 17:01:25 step 6: objective=0.246929 reg=0.017511
2017/08/29 17:01:30 step 7: objective=0.247293 reg=0.017463
2017/08/29 17:01:30 Training value function...
2017/08/29 17:01:36 step 0: mse=1.238691 step=0.050000
2017/08/29 17:01:40 step 1: mse=1.238472 step=0.050000
2017/08/29 17:01:43 step 2: mse=1.238265 step=0.050000
2017/08/29 17:01:47 step 3: mse=1.238081 step=0.050000
2017/08/29 17:01:50 step 4: mse=1.237909 step=0.050000
2017/08/29 17:01:53 step 5: mse=1.237753 step=0.050000
2017/08/29 17:01:57 step 6: mse=1.237600 step=0.050000
2017/08/29 17:02:00 step 7: mse=1.237458 step=0.050000
2017/08/29 17:02:00 Saving...
2017/08/29 17:02:00 Gathering batch of experience...
2017/08/29 17:02:27 batch 115: mean=5.005992 stddev=1.507310 entropy=1.752693 frames=100140 count=5007
2017/08/29 17:02:27 Training policy...
2017/08/29 17:02:41 step 0: objective=0.256893 reg=0.017527
2017/08/29 17:02:47 step 1: objective=0.257579 reg=0.017520
2017/08/29 17:02:52 step 2: objective=0.258438 reg=0.017517
2017/08/29 17:02:58 step 3: objective=0.259358 reg=0.017503
2017/08/29 17:03:03 step 4: objective=0.260032 reg=0.017488
2017/08/29 17:03:09 step 5: objective=0.260429 reg=0.017459
2017/08/29 17:03:14 step 6: objective=0.260478 reg=0.017461
2017/08/29 17:03:19 step 7: objective=0.260838 reg=0.017430
2017/08/29 17:03:19 Training value function...
2017/08/29 17:03:25 step 0: mse=1.220532 step=0.050000
2017/08/29 17:03:29 step 1: mse=1.219522 step=0.050000
2017/08/29 17:03:32 step 2: mse=1.218589 step=0.050000
2017/08/29 17:03:36 step 3: mse=1.217717 step=0.050000
2017/08/29 17:03:39 step 4: mse=1.216892 step=0.050000
2017/08/29 17:03:43 step 5: mse=1.216132 step=0.050000
2017/08/29 17:03:46 step 6: mse=1.215402 step=0.050000
2017/08/29 17:03:49 step 7: mse=1.214716 step=0.050000
2017/08/29 17:03:49 Saving...
2017/08/29 17:03:50 Gathering batch of experience...
2017/08/29 17:04:17 batch 116: mean=5.010186 stddev=1.505100 entropy=1.739963 frames=100140 count=5007
2017/08/29 17:04:17 Training policy...
2017/08/29 17:04:30 step 0: objective=0.261971 reg=0.017400
2017/08/29 17:04:35 step 1: objective=0.262525 reg=0.017378
2017/08/29 17:04:41 step 2: objective=0.262449 reg=0.017408
2017/08/29 17:04:46 step 3: objective=0.263089 reg=0.017357
2017/08/29 17:04:51 step 4: objective=0.263107 reg=0.017399
2017/08/29 17:04:57 step 5: objective=0.264068 reg=0.017347
2017/08/29 17:05:02 step 6: objective=0.263759 reg=0.017384
2017/08/29 17:05:08 step 7: objective=0.264368 reg=0.017353
2017/08/29 17:05:08 Training value function...
2017/08/29 17:05:14 step 0: mse=1.248048 step=0.050000
2017/08/29 17:05:17 step 1: mse=1.246880 step=0.050000
2017/08/29 17:05:21 step 2: mse=1.245793 step=0.050000
2017/08/29 17:05:24 step 3: mse=1.244767 step=0.050000
2017/08/29 17:05:28 step 4: mse=1.243808 step=0.050000
2017/08/29 17:05:31 step 5: mse=1.242913 step=0.050000
2017/08/29 17:05:35 step 6: mse=1.242073 step=0.050000
2017/08/29 17:05:38 step 7: mse=1.241286 step=0.050000
2017/08/29 17:05:38 Saving...
2017/08/29 17:05:38 Gathering batch of experience...
2017/08/29 17:06:05 batch 117: mean=4.992810 stddev=1.474620 entropy=1.742046 frames=100140 count=5007
2017/08/29 17:06:05 Training policy...
2017/08/29 17:06:18 step 0: objective=0.257098 reg=0.017420
2017/08/29 17:06:23 step 1: objective=0.257804 reg=0.017413
2017/08/29 17:06:29 step 2: objective=0.258388 reg=0.017409
2017/08/29 17:06:34 step 3: objective=0.258812 reg=0.017402
2017/08/29 17:06:40 step 4: objective=0.259196 reg=0.017393
2017/08/29 17:06:45 step 5: objective=0.259196 reg=0.017401
2017/08/29 17:06:51 step 6: objective=0.259588 reg=0.017381
2017/08/29 17:06:56 step 7: objective=0.259844 reg=0.017395
2017/08/29 17:06:56 Training value function...
2017/08/29 17:07:02 step 0: mse=1.218647 step=0.050000
2017/08/29 17:07:06 step 1: mse=1.217685 step=0.050000
2017/08/29 17:07:09 step 2: mse=1.216790 step=0.050000
2017/08/29 17:07:13 step 3: mse=1.215953 step=0.050000
2017/08/29 17:07:16 step 4: mse=1.215158 step=0.050000
2017/08/29 17:07:19 step 5: mse=1.214422 step=0.050000
2017/08/29 17:07:23 step 6: mse=1.213700 step=0.050000
2017/08/29 17:07:26 step 7: mse=1.213041 step=0.050000
2017/08/29 17:07:26 Saving...
2017/08/29 17:07:26 Gathering batch of experience...
2017/08/29 17:07:54 batch 118: mean=5.022768 stddev=1.518372 entropy=1.733153 frames=100140 count=5007
2017/08/29 17:07:54 Training policy...
2017/08/29 17:08:06 step 0: objective=0.262670 reg=0.017331
2017/08/29 17:08:12 step 1: objective=0.263399 reg=0.017314
2017/08/29 17:08:17 step 2: objective=0.263737 reg=0.017322
2017/08/29 17:08:23 step 3: objective=0.264217 reg=0.017291
2017/08/29 17:08:28 step 4: objective=0.264090 reg=0.017329
2017/08/29 17:08:34 step 5: objective=0.264488 reg=0.017280
2017/08/29 17:08:40 step 6: objective=0.264813 reg=0.017313
2017/08/29 17:08:46 step 7: objective=0.265080 reg=0.017271
2017/08/29 17:08:46 Training value function...
2017/08/29 17:08:52 step 0: mse=1.249035 step=0.050000
2017/08/29 17:08:55 step 1: mse=1.247844 step=0.050000
2017/08/29 17:08:59 step 2: mse=1.246721 step=0.050000
2017/08/29 17:09:02 step 3: mse=1.245676 step=0.050000
2017/08/29 17:09:06 step 4: mse=1.244708 step=0.050000
2017/08/29 17:09:09 step 5: mse=1.243818 step=0.050000
2017/08/29 17:09:13 step 6: mse=1.242952 step=0.050000
2017/08/29 17:09:16 step 7: mse=1.242138 step=0.050000
2017/08/29 17:09:16 Saving...
2017/08/29 17:09:16 Gathering batch of experience...
2017/08/29 17:09:43 batch 119: mean=4.992610 stddev=1.484137 entropy=1.735828 frames=100140 count=5007
2017/08/29 17:09:43 Training policy...
2017/08/29 17:09:56 step 0: objective=0.243368 reg=0.017358
2017/08/29 17:10:01 step 1: objective=0.243994 reg=0.017331
2017/08/29 17:10:07 step 2: objective=0.244300 reg=0.017342
2017/08/29 17:10:12 step 3: objective=0.244954 reg=0.017298
2017/08/29 17:10:18 step 4: objective=0.245386 reg=0.017337
2017/08/29 17:10:23 step 5: objective=0.245646 reg=0.017291
2017/08/29 17:10:29 step 6: objective=0.246101 reg=0.017334
2017/08/29 17:10:34 step 7: objective=0.246288 reg=0.017279
2017/08/29 17:10:34 Training value function...
2017/08/29 17:10:40 step 0: mse=1.190266 step=0.050000
2017/08/29 17:10:44 step 1: mse=1.190107 step=0.050000
2017/08/29 17:10:47 step 2: mse=1.189963 step=0.050000
2017/08/29 17:10:51 step 3: mse=1.189836 step=0.050000
2017/08/29 17:10:54 step 4: mse=1.189714 step=0.050000
2017/08/29 17:10:57 step 5: mse=1.189597 step=0.050000
2017/08/29 17:11:01 step 6: mse=1.189484 step=0.050000
2017/08/29 17:11:04 step 7: mse=1.189380 step=0.050000
2017/08/29 17:11:04 Saving...
2017/08/29 17:11:04 Gathering batch of experience...
2017/08/29 17:11:32 batch 120: mean=5.019373 stddev=1.488061 entropy=1.729658 frames=100140 count=5007
2017/08/29 17:11:32 Training policy...
2017/08/29 17:11:44 step 0: objective=0.255355 reg=0.017297
2017/08/29 17:11:50 step 1: objective=0.256013 reg=0.017274
2017/08/29 17:11:55 step 2: objective=0.256231 reg=0.017295
2017/08/29 17:12:01 step 3: objective=0.256665 reg=0.017249
2017/08/29 17:12:06 step 4: objective=0.256896 reg=0.017284
2017/08/29 17:12:12 step 5: objective=0.257383 reg=0.017247
2017/08/29 17:12:17 step 6: objective=0.257758 reg=0.017272
2017/08/29 17:12:22 step 7: objective=0.258235 reg=0.017244
2017/08/29 17:12:22 Training value function...
2017/08/29 17:12:29 step 0: mse=1.208853 step=0.050000
2017/08/29 17:12:32 step 1: mse=1.207670 step=0.050000
2017/08/29 17:12:36 step 2: mse=1.206572 step=0.050000
2017/08/29 17:12:39 step 3: mse=1.205549 step=0.050000
2017/08/29 17:12:42 step 4: mse=1.204592 step=0.050000
2017/08/29 17:12:46 step 5: mse=1.203641 step=0.050000
2017/08/29 17:12:49 step 6: mse=1.202796 step=0.050000
2017/08/29 17:12:53 step 7: mse=1.201954 step=0.050000
2017/08/29 17:12:53 Saving...
2017/08/29 17:12:53 Gathering batch of experience...
2017/08/29 17:13:20 batch 121: mean=5.054723 stddev=1.485904 entropy=1.725346 frames=100140 count=5007
2017/08/29 17:13:20 Training policy...
2017/08/29 17:13:33 step 0: objective=0.261861 reg=0.017253
2017/08/29 17:13:38 step 1: objective=0.262532 reg=0.017239
2017/08/29 17:13:44 step 2: objective=0.262800 reg=0.017257
2017/08/29 17:13:49 step 3: objective=0.263421 reg=0.017237
2017/08/29 17:13:55 step 4: objective=0.263908 reg=0.017251
2017/08/29 17:14:00 step 5: objective=0.264305 reg=0.017221
2017/08/29 17:14:06 step 6: objective=0.264210 reg=0.017248
2017/08/29 17:14:11 step 7: objective=0.264683 reg=0.017201
2017/08/29 17:14:11 Training value function...
2017/08/29 17:14:17 step 0: mse=1.245269 step=0.050000
2017/08/29 17:14:21 step 1: mse=1.243927 step=0.050000
2017/08/29 17:14:24 step 2: mse=1.242677 step=0.050000
2017/08/29 17:14:28 step 3: mse=1.241509 step=0.050000
2017/08/29 17:14:31 step 4: mse=1.240431 step=0.050000
2017/08/29 17:14:34 step 5: mse=1.239419 step=0.050000
2017/08/29 17:14:38 step 6: mse=1.238472 step=0.050000
2017/08/29 17:14:41 step 7: mse=1.237577 step=0.050000
2017/08/29 17:14:41 Saving...
2017/08/29 17:14:41 Gathering batch of experience...
2017/08/29 17:15:09 batch 122: mean=5.002596 stddev=1.493944 entropy=1.733119 frames=100140 count=5007
2017/08/29 17:15:09 Training policy...
2017/08/29 17:15:21 step 0: objective=0.233712 reg=0.017331
2017/08/29 17:15:27 step 1: objective=0.234482 reg=0.017320
2017/08/29 17:15:33 step 2: objective=0.234965 reg=0.017313
2017/08/29 17:15:38 step 3: objective=0.235220 reg=0.017329
2017/08/29 17:15:44 step 4: objective=0.235887 reg=0.017306
2017/08/29 17:15:49 step 5: objective=0.236176 reg=0.017308
2017/08/29 17:15:55 step 6: objective=0.236748 reg=0.017292
2017/08/29 17:16:00 step 7: objective=0.236851 reg=0.017292
2017/08/29 17:16:00 Training value function...
2017/08/29 17:16:06 step 0: mse=1.205591 step=0.050000
2017/08/29 17:16:10 step 1: mse=1.206235 step=0.050000
2017/08/29 17:16:13 step 2: mse=1.206860 step=0.050000
2017/08/29 17:16:16 step 3: mse=1.207462 step=0.050000
2017/08/29 17:16:20 step 4: mse=1.208033 step=0.050000
2017/08/29 17:16:23 step 5: mse=1.208578 step=0.050000
2017/08/29 17:16:27 step 6: mse=1.209094 step=0.050000
2017/08/29 17:16:30 step 7: mse=1.209584 step=0.050000
2017/08/29 17:16:30 Saving...
2017/08/29 17:16:30 Gathering batch of experience...
2017/08/29 17:16:58 batch 123: mean=5.024166 stddev=1.516837 entropy=1.719698 frames=100140 count=5007
2017/08/29 17:16:58 Training policy...
2017/08/29 17:17:10 step 0: objective=0.249104 reg=0.017197
2017/08/29 17:17:16 step 1: objective=0.250056 reg=0.017192
2017/08/29 17:17:22 step 2: objective=0.250838 reg=0.017171
2017/08/29 17:17:27 step 3: objective=0.251501 reg=0.017182
2017/08/29 17:17:33 step 4: objective=0.252010 reg=0.017145
2017/08/29 17:17:39 step 5: objective=0.252155 reg=0.017169
2017/08/29 17:17:44 step 6: objective=0.252598 reg=0.017149
2017/08/29 17:17:50 step 7: objective=0.252550 reg=0.017160
2017/08/29 17:17:50 Training value function...
2017/08/29 17:17:56 step 0: mse=1.247597 step=0.050000
2017/08/29 17:17:59 step 1: mse=1.247505 step=0.050000
2017/08/29 17:18:03 step 2: mse=1.247429 step=0.050000
2017/08/29 17:18:06 step 3: mse=1.247363 step=0.050000
2017/08/29 17:18:10 step 4: mse=1.247307 step=0.050000
2017/08/29 17:18:13 step 5: mse=1.247213 step=0.050000
2017/08/29 17:18:17 step 6: mse=1.247135 step=0.050000
2017/08/29 17:18:20 step 7: mse=1.247053 step=0.050000
2017/08/29 17:18:20 Saving...
2017/08/29 17:18:20 Gathering batch of experience...
2017/08/29 17:18:48 batch 124: mean=5.045536 stddev=1.477994 entropy=1.713837 frames=100140 count=5007
2017/08/29 17:18:48 Training policy...
2017/08/29 17:19:00 step 0: objective=0.263530 reg=0.017138
2017/08/29 17:19:06 step 1: objective=0.264433 reg=0.017131
2017/08/29 17:19:12 step 2: objective=0.265098 reg=0.017115
2017/08/29 17:19:17 step 3: objective=0.265519 reg=0.017114
2017/08/29 17:19:23 step 4: objective=0.265641 reg=0.017112
2017/08/29 17:19:28 step 5: objective=0.266035 reg=0.017099
2017/08/29 17:19:34 step 6: objective=0.266226 reg=0.017103
2017/08/29 17:19:39 step 7: objective=0.266659 reg=0.017093
2017/08/29 17:19:39 Training value function...
2017/08/29 17:19:45 step 0: mse=1.249424 step=0.050000
2017/08/29 17:19:48 step 1: mse=1.247950 step=0.050000
2017/08/29 17:19:52 step 2: mse=1.246579 step=0.050000
2017/08/29 17:19:55 step 3: mse=1.245305 step=0.050000
2017/08/29 17:19:59 step 4: mse=1.244120 step=0.050000
2017/08/29 17:20:02 step 5: mse=1.243041 step=0.050000
2017/08/29 17:20:06 step 6: mse=1.241998 step=0.050000
2017/08/29 17:20:09 step 7: mse=1.241052 step=0.050000
2017/08/29 17:20:09 Saving...
2017/08/29 17:20:09 Gathering batch of experience...
2017/08/29 17:20:37 batch 125: mean=5.069303 stddev=1.475920 entropy=1.709391 frames=100140 count=5007
2017/08/29 17:20:37 Training policy...
2017/08/29 17:20:49 step 0: objective=0.258467 reg=0.017094
2017/08/29 17:20:55 step 1: objective=0.259315 reg=0.017077
2017/08/29 17:21:00 step 2: objective=0.259659 reg=0.017086
2017/08/29 17:21:06 step 3: objective=0.259979 reg=0.017033
2017/08/29 17:21:12 step 4: objective=0.260406 reg=0.017046
2017/08/29 17:21:17 step 5: objective=0.260843 reg=0.017069
2017/08/29 17:21:23 step 6: objective=0.261290 reg=0.017029
2017/08/29 17:21:29 step 7: objective=0.261623 reg=0.017051
2017/08/29 17:21:29 Training value function...
2017/08/29 17:21:35 step 0: mse=1.215240 step=0.050000
2017/08/29 17:21:38 step 1: mse=1.214652 step=0.050000
2017/08/29 17:21:42 step 2: mse=1.214115 step=0.050000
2017/08/29 17:21:45 step 3: mse=1.213620 step=0.050000
2017/08/29 17:21:49 step 4: mse=1.213160 step=0.050000
2017/08/29 17:21:52 step 5: mse=1.212733 step=0.050000
2017/08/29 17:21:56 step 6: mse=1.212336 step=0.050000
2017/08/29 17:21:59 step 7: mse=1.211961 step=0.050000
2017/08/29 17:21:59 Saving...
2017/08/29 17:21:59 Gathering batch of experience...
2017/08/29 17:22:27 batch 126: mean=5.032954 stddev=1.493850 entropy=1.704990 frames=100140 count=5007
2017/08/29 17:22:27 Training policy...
2017/08/29 17:22:40 step 0: objective=0.254621 reg=0.017050
2017/08/29 17:22:46 step 1: objective=0.255389 reg=0.017052
2017/08/29 17:22:53 step 2: objective=0.255946 reg=0.017049
2017/08/29 17:22:59 step 3: objective=0.256137 reg=0.017039
2017/08/29 17:23:04 step 4: objective=0.256408 reg=0.017050
2017/08/29 17:23:10 step 5: objective=0.256962 reg=0.017035
2017/08/29 17:23:15 step 6: objective=0.257325 reg=0.017053
2017/08/29 17:23:21 step 7: objective=0.257784 reg=0.017026
2017/08/29 17:23:21 Training value function...
2017/08/29 17:23:27 step 0: mse=1.219777 step=0.050000
2017/08/29 17:23:30 step 1: mse=1.218929 step=0.050000
2017/08/29 17:23:34 step 2: mse=1.218144 step=0.050000
2017/08/29 17:23:37 step 3: mse=1.217420 step=0.050000
2017/08/29 17:23:41 step 4: mse=1.216749 step=0.050000
2017/08/29 17:23:44 step 5: mse=1.216122 step=0.050000
2017/08/29 17:23:48 step 6: mse=1.215514 step=0.050000
2017/08/29 17:23:51 step 7: mse=1.214951 step=0.050000
2017/08/29 17:23:51 Saving...
2017/08/29 17:23:51 Gathering batch of experience...
2017/08/29 17:24:18 batch 127: mean=5.043339 stddev=1.450301 entropy=1.705396 frames=100140 count=5007
2017/08/29 17:24:18 Training policy...
2017/08/29 17:24:31 step 0: objective=0.245614 reg=0.017054
2017/08/29 17:24:37 step 1: objective=0.246480 reg=0.017043
2017/08/29 17:24:42 step 2: objective=0.247222 reg=0.017025
2017/08/29 17:24:48 step 3: objective=0.247683 reg=0.017025
2017/08/29 17:24:54 step 4: objective=0.248093 reg=0.017015
2017/08/29 17:24:59 step 5: objective=0.248261 reg=0.017000
2017/08/29 17:25:05 step 6: objective=0.248404 reg=0.017018
2017/08/29 17:25:10 step 7: objective=0.248765 reg=0.016999
2017/08/29 17:25:10 Training value function...
2017/08/29 17:25:16 step 0: mse=1.178444 step=0.050000
2017/08/29 17:25:20 step 1: mse=1.178079 step=0.050000
2017/08/29 17:25:23 step 2: mse=1.177749 step=0.050000
2017/08/29 17:25:27 step 3: mse=1.177451 step=0.050000
2017/08/29 17:25:30 step 4: mse=1.177192 step=0.050000
2017/08/29 17:25:34 step 5: mse=1.176957 step=0.050000
2017/08/29 17:25:37 step 6: mse=1.176735 step=0.050000
2017/08/29 17:25:40 step 7: mse=1.176507 step=0.050000
2017/08/29 17:25:40 Saving...
2017/08/29 17:25:40 Gathering batch of experience...
2017/08/29 17:26:08 batch 128: mean=5.086878 stddev=1.493158 entropy=1.703281 frames=100140 count=5007
2017/08/29 17:26:08 Training policy...
2017/08/29 17:26:21 step 0: objective=0.255786 reg=0.017033
2017/08/29 17:26:26 step 1: objective=0.256323 reg=0.017012
2017/08/29 17:26:32 step 2: objective=0.256692 reg=0.017035
2017/08/29 17:26:38 step 3: objective=0.257375 reg=0.016993
2017/08/29 17:26:43 step 4: objective=0.257841 reg=0.017014
2017/08/29 17:26:49 step 5: objective=0.258413 reg=0.016987
2017/08/29 17:26:55 step 6: objective=0.258620 reg=0.017005
2017/08/29 17:27:00 step 7: objective=0.259229 reg=0.016983
2017/08/29 17:27:00 Training value function...
2017/08/29 17:27:06 step 0: mse=1.232162 step=0.050000
2017/08/29 17:27:10 step 1: mse=1.231444 step=0.050000
2017/08/29 17:27:13 step 2: mse=1.230774 step=0.050000
2017/08/29 17:27:17 step 3: mse=1.230146 step=0.050000
2017/08/29 17:27:20 step 4: mse=1.229556 step=0.050000
2017/08/29 17:27:24 step 5: mse=1.229005 step=0.050000
2017/08/29 17:27:27 step 6: mse=1.228481 step=0.050000
2017/08/29 17:27:31 step 7: mse=1.227984 step=0.050000
2017/08/29 17:27:31 Saving...
2017/08/29 17:27:31 Gathering batch of experience...
2017/08/29 17:27:58 batch 129: mean=5.061913 stddev=1.487234 entropy=1.694078 frames=100140 count=5007
2017/08/29 17:27:58 Training policy...
2017/08/29 17:28:12 step 0: objective=0.253050 reg=0.016941
2017/08/29 17:28:17 step 1: objective=0.253883 reg=0.016942
2017/08/29 17:28:23 step 2: objective=0.254711 reg=0.016931
2017/08/29 17:28:29 step 3: objective=0.255366 reg=0.016931
2017/08/29 17:28:34 step 4: objective=0.255827 reg=0.016913
2017/08/29 17:28:40 step 5: objective=0.255970 reg=0.016932
2017/08/29 17:28:45 step 6: objective=0.256266 reg=0.016897
2017/08/29 17:28:51 step 7: objective=0.256684 reg=0.016920
2017/08/29 17:28:51 Training value function...
2017/08/29 17:28:57 step 0: mse=1.163511 step=0.050000
2017/08/29 17:29:00 step 1: mse=1.162623 step=0.050000
2017/08/29 17:29:04 step 2: mse=1.161806 step=0.050000
2017/08/29 17:29:07 step 3: mse=1.161030 step=0.050000
2017/08/29 17:29:11 step 4: mse=1.160311 step=0.050000
2017/08/29 17:29:14 step 5: mse=1.159641 step=0.050000
2017/08/29 17:29:18 step 6: mse=1.158987 step=0.050000
2017/08/29 17:29:21 step 7: mse=1.158397 step=0.050000
2017/08/29 17:29:21 Saving...
2017/08/29 17:29:21 Gathering batch of experience...
2017/08/29 17:29:49 batch 130: mean=5.047334 stddev=1.496269 entropy=1.693528 frames=100140 count=5007
2017/08/29 17:29:49 Training policy...
2017/08/29 17:30:01 step 0: objective=0.245907 reg=0.016935
2017/08/29 17:30:07 step 1: objective=0.246700 reg=0.016936
2017/08/29 17:30:13 step 2: objective=0.247289 reg=0.016939
2017/08/29 17:30:18 step 3: objective=0.248046 reg=0.016932
2017/08/29 17:30:24 step 4: objective=0.248604 reg=0.016927
2017/08/29 17:30:30 step 5: objective=0.248915 reg=0.016926
2017/08/29 17:30:36 step 6: objective=0.249443 reg=0.016910
2017/08/29 17:30:41 step 7: objective=0.249890 reg=0.016904
2017/08/29 17:30:41 Training value function...
2017/08/29 17:30:47 step 0: mse=1.207150 step=0.050000
2017/08/29 17:30:50 step 1: mse=1.206755 step=0.050000
2017/08/29 17:30:54 step 2: mse=1.206379 step=0.050000
2017/08/29 17:30:57 step 3: mse=1.206029 step=0.050000
2017/08/29 17:31:01 step 4: mse=1.205707 step=0.050000
2017/08/29 17:31:04 step 5: mse=1.205413 step=0.050000
2017/08/29 17:31:08 step 6: mse=1.205127 step=0.050000
2017/08/29 17:31:11 step 7: mse=1.204854 step=0.050000
2017/08/29 17:31:11 Saving...
2017/08/29 17:31:11 Gathering batch of experience...
2017/08/29 17:31:39 batch 131: mean=5.034552 stddev=1.468192 entropy=1.688008 frames=100140 count=5007
2017/08/29 17:31:39 Training policy...
2017/08/29 17:31:52 step 0: objective=0.244046 reg=0.016880
2017/08/29 17:31:58 step 1: objective=0.244940 reg=0.016878
2017/08/29 17:32:03 step 2: objective=0.245894 reg=0.016868
2017/08/29 17:32:09 step 3: objective=0.246498 reg=0.016858
2017/08/29 17:32:15 step 4: objective=0.246765 reg=0.016870
2017/08/29 17:32:20 step 5: objective=0.247163 reg=0.016852
2017/08/29 17:32:26 step 6: objective=0.247899 reg=0.016846
2017/08/29 17:32:32 step 7: objective=0.248371 reg=0.016846
2017/08/29 17:32:32 Training value function...
2017/08/29 17:32:38 step 0: mse=1.173827 step=0.050000
2017/08/29 17:32:41 step 1: mse=1.174062 step=0.050000
2017/08/29 17:32:45 step 2: mse=1.174294 step=0.050000
2017/08/29 17:32:48 step 3: mse=1.174521 step=0.050000
2017/08/29 17:32:51 step 4: mse=1.174697 step=0.050000
2017/08/29 17:32:55 step 5: mse=1.174905 step=0.050000
2017/08/29 17:32:58 step 6: mse=1.175093 step=0.050000
2017/08/29 17:33:02 step 7: mse=1.175270 step=0.050000
2017/08/29 17:33:02 Saving...
2017/08/29 17:33:02 Gathering batch of experience...
2017/08/29 17:33:29 batch 132: mean=5.070901 stddev=1.463478 entropy=1.682387 frames=100140 count=5007
2017/08/29 17:33:29 Training policy...
2017/08/29 17:33:42 step 0: objective=0.257375 reg=0.016824
2017/08/29 17:33:48 step 1: objective=0.258144 reg=0.016818
2017/08/29 17:33:53 step 2: objective=0.258830 reg=0.016804
2017/08/29 17:33:59 step 3: objective=0.259173 reg=0.016799
2017/08/29 17:34:05 step 4: objective=0.259582 reg=0.016805
2017/08/29 17:34:10 step 5: objective=0.259923 reg=0.016780
2017/08/29 17:34:16 step 6: objective=0.260280 reg=0.016793
2017/08/29 17:34:21 step 7: objective=0.260674 reg=0.016760
2017/08/29 17:34:21 Training value function...
2017/08/29 17:34:27 step 0: mse=1.175245 step=0.050000
2017/08/29 17:34:31 step 1: mse=1.174417 step=0.050000
2017/08/29 17:34:34 step 2: mse=1.173646 step=0.050000
2017/08/29 17:34:38 step 3: mse=1.172925 step=0.050000
2017/08/29 17:34:41 step 4: mse=1.172239 step=0.050000
2017/08/29 17:34:45 step 5: mse=1.171607 step=0.050000
2017/08/29 17:34:48 step 6: mse=1.171007 step=0.050000
2017/08/29 17:34:52 step 7: mse=1.170436 step=0.050000
2017/08/29 17:34:52 Saving...
2017/08/29 17:34:52 Gathering batch of experience...
2017/08/29 17:35:19 batch 133: mean=5.068704 stddev=1.472901 entropy=1.674974 frames=100140 count=5007
2017/08/29 17:35:19 Training policy...
2017/08/29 17:35:32 step 0: objective=0.253089 reg=0.016750
2017/08/29 17:35:38 step 1: objective=0.253949 reg=0.016740
2017/08/29 17:35:43 step 2: objective=0.254660 reg=0.016733
2017/08/29 17:35:49 step 3: objective=0.255346 reg=0.016733
2017/08/29 17:35:54 step 4: objective=0.256021 reg=0.016725
2017/08/29 17:36:00 step 5: objective=0.256573 reg=0.016716
2017/08/29 17:36:05 step 6: objective=0.257036 reg=0.016705
2017/08/29 17:36:11 step 7: objective=0.257354 reg=0.016691
2017/08/29 17:36:11 Training value function...
2017/08/29 17:36:17 step 0: mse=1.168168 step=0.050000
2017/08/29 17:36:21 step 1: mse=1.167633 step=0.050000
2017/08/29 17:36:24 step 2: mse=1.167124 step=0.050000
2017/08/29 17:36:27 step 3: mse=1.166671 step=0.050000
2017/08/29 17:36:31 step 4: mse=1.166260 step=0.050000
2017/08/29 17:36:34 step 5: mse=1.165857 step=0.050000
2017/08/29 17:36:38 step 6: mse=1.165426 step=0.050000
2017/08/29 17:36:41 step 7: mse=1.165038 step=0.050000
2017/08/29 17:36:41 Saving...
2017/08/29 17:36:41 Gathering batch of experience...
2017/08/29 17:37:09 batch 134: mean=5.130617 stddev=1.482646 entropy=1.663174 frames=100140 count=5007
2017/08/29 17:37:09 Training policy...
2017/08/29 17:37:22 step 0: objective=0.274324 reg=0.016632
2017/08/29 17:37:27 step 1: objective=0.275070 reg=0.016613
2017/08/29 17:37:33 step 2: objective=0.275774 reg=0.016585
2017/08/29 17:37:38 step 3: objective=0.276223 reg=0.016597
2017/08/29 17:37:44 step 4: objective=0.276440 reg=0.016582
2017/08/29 17:37:50 step 5: objective=0.276731 reg=0.016610
2017/08/29 17:37:55 step 6: objective=0.277276 reg=0.016571
2017/08/29 17:38:01 step 7: objective=0.277465 reg=0.016601
2017/08/29 17:38:01 Training value function...
2017/08/29 17:38:07 step 0: mse=1.243580 step=0.050000
2017/08/29 17:38:10 step 1: mse=1.241408 step=0.050000
2017/08/29 17:38:14 step 2: mse=1.239385 step=0.050000
2017/08/29 17:38:17 step 3: mse=1.237449 step=0.050000
2017/08/29 17:38:21 step 4: mse=1.235636 step=0.050000
2017/08/29 17:38:24 step 5: mse=1.233941 step=0.050000
2017/08/29 17:38:28 step 6: mse=1.232351 step=0.050000
2017/08/29 17:38:31 step 7: mse=1.230861 step=0.050000
2017/08/29 17:38:31 Saving...
2017/08/29 17:38:31 Gathering batch of experience...
2017/08/29 17:38:59 batch 135: mean=5.064510 stddev=1.484233 entropy=1.661924 frames=100140 count=5007
2017/08/29 17:38:59 Training policy...
2017/08/29 17:39:12 step 0: objective=0.240983 reg=0.016619
2017/08/29 17:39:17 step 1: objective=0.241846 reg=0.016621
2017/08/29 17:39:23 step 2: objective=0.242555 reg=0.016613
2017/08/29 17:39:29 step 3: objective=0.243369 reg=0.016604
2017/08/29 17:39:34 step 4: objective=0.243974 reg=0.016597
2017/08/29 17:39:40 step 5: objective=0.244586 reg=0.016591
2017/08/29 17:39:46 step 6: objective=0.245181 reg=0.016590
2017/08/29 17:39:51 step 7: objective=0.245656 reg=0.016583
2017/08/29 17:39:51 Training value function...
2017/08/29 17:39:57 step 0: mse=1.175484 step=0.050000
2017/08/29 17:40:01 step 1: mse=1.175679 step=0.050000
2017/08/29 17:40:04 step 2: mse=1.175873 step=0.050000
2017/08/29 17:40:08 step 3: mse=1.176062 step=0.050000
2017/08/29 17:40:11 step 4: mse=1.176212 step=0.050000
2017/08/29 17:40:15 step 5: mse=1.176387 step=0.050000
2017/08/29 17:40:18 step 6: mse=1.176524 step=0.050000
2017/08/29 17:40:22 step 7: mse=1.176657 step=0.050000
2017/08/29 17:40:22 Saving...
2017/08/29 17:40:22 Gathering batch of experience...
2017/08/29 17:40:49 batch 136: mean=5.103655 stddev=1.488603 entropy=1.656318 frames=100140 count=5007
2017/08/29 17:40:49 Training policy...
2017/08/29 17:41:02 step 0: objective=0.254919 reg=0.016563
2017/08/29 17:41:08 step 1: objective=0.255343 reg=0.016531
2017/08/29 17:41:14 step 2: objective=0.255856 reg=0.016541
2017/08/29 17:41:20 step 3: objective=0.256296 reg=0.016509
2017/08/29 17:41:26 step 4: objective=0.256498 reg=0.016537
2017/08/29 17:41:32 step 5: objective=0.256679 reg=0.016524
2017/08/29 17:41:38 step 6: objective=0.256801 reg=0.016543
2017/08/29 17:41:43 step 7: objective=0.257189 reg=0.016502
2017/08/29 17:41:43 Training value function...
2017/08/29 17:41:49 step 0: mse=1.213631 step=0.050000
2017/08/29 17:41:53 step 1: mse=1.213003 step=0.050000
2017/08/29 17:41:56 step 2: mse=1.212423 step=0.050000
2017/08/29 17:42:00 step 3: mse=1.211886 step=0.050000
2017/08/29 17:42:03 step 4: mse=1.211388 step=0.050000
2017/08/29 17:42:06 step 5: mse=1.210929 step=0.050000
2017/08/29 17:42:10 step 6: mse=1.210498 step=0.050000
2017/08/29 17:42:13 step 7: mse=1.210094 step=0.050000
2017/08/29 17:42:13 Saving...
2017/08/29 17:42:13 Gathering batch of experience...
2017/08/29 17:42:41 batch 137: mean=5.140603 stddev=1.462740 entropy=1.652834 frames=100140 count=5007
2017/08/29 17:42:41 Training policy...
2017/08/29 17:42:54 step 0: objective=0.267974 reg=0.016528
2017/08/29 17:43:00 step 1: objective=0.268913 reg=0.016509
2017/08/29 17:43:06 step 2: objective=0.269455 reg=0.016507
2017/08/29 17:43:11 step 3: objective=0.269721 reg=0.016514
2017/08/29 17:43:18 step 4: objective=0.270306 reg=0.016501
2017/08/29 17:43:25 step 5: objective=0.270639 reg=0.016502
2017/08/29 17:43:30 step 6: objective=0.270957 reg=0.016494
2017/08/29 17:43:36 step 7: objective=0.271399 reg=0.016488
2017/08/29 17:43:36 Training value function...
2017/08/29 17:43:42 step 0: mse=1.198077 step=0.050000
2017/08/29 17:43:45 step 1: mse=1.196344 step=0.050000
2017/08/29 17:43:49 step 2: mse=1.194731 step=0.050000
2017/08/29 17:43:52 step 3: mse=1.193228 step=0.050000
2017/08/29 17:43:56 step 4: mse=1.191822 step=0.050000
2017/08/29 17:43:59 step 5: mse=1.190507 step=0.050000
2017/08/29 17:44:03 step 6: mse=1.189275 step=0.050000
2017/08/29 17:44:06 step 7: mse=1.188119 step=0.050000
2017/08/29 17:44:06 Saving...
2017/08/29 17:44:06 Gathering batch of experience...
2017/08/29 17:44:34 batch 138: mean=5.101458 stddev=1.470328 entropy=1.653749 frames=100140 count=5007
2017/08/29 17:44:34 Training policy...
2017/08/29 17:44:47 step 0: objective=0.245655 reg=0.016538
2017/08/29 17:44:53 step 1: objective=0.246485 reg=0.016523
2017/08/29 17:44:59 step 2: objective=0.247369 reg=0.016516
2017/08/29 17:45:05 step 3: objective=0.247839 reg=0.016503
2017/08/29 17:45:11 step 4: objective=0.248423 reg=0.016497
2017/08/29 17:45:17 step 5: objective=0.248989 reg=0.016489
2017/08/29 17:45:22 step 6: objective=0.249431 reg=0.016474
2017/08/29 17:45:28 step 7: objective=0.249769 reg=0.016467
2017/08/29 17:45:28 Training value function...
2017/08/29 17:45:34 step 0: mse=1.181128 step=0.050000
2017/08/29 17:45:37 step 1: mse=1.180750 step=0.050000
2017/08/29 17:45:41 step 2: mse=1.180419 step=0.050000
2017/08/29 17:45:44 step 3: mse=1.180141 step=0.050000
2017/08/29 17:45:48 step 4: mse=1.179808 step=0.050000
2017/08/29 17:45:51 step 5: mse=1.179509 step=0.050000
2017/08/29 17:45:55 step 6: mse=1.179234 step=0.050000
2017/08/29 17:45:58 step 7: mse=1.178976 step=0.050000
2017/08/29 17:45:58 Saving...
2017/08/29 17:45:58 Gathering batch of experience...
2017/08/29 17:46:26 batch 139: mean=5.108848 stddev=1.449205 entropy=1.645498 frames=100140 count=5007
2017/08/29 17:46:26 Training policy...
2017/08/29 17:46:39 step 0: objective=0.244493 reg=0.016455
2017/08/29 17:46:45 step 1: objective=0.245212 reg=0.016447
2017/08/29 17:46:51 step 2: objective=0.245797 reg=0.016444
2017/08/29 17:46:57 step 3: objective=0.246581 reg=0.016439
2017/08/29 17:47:03 step 4: objective=0.246950 reg=0.016439
2017/08/29 17:47:09 step 5: objective=0.247438 reg=0.016426
2017/08/29 17:47:15 step 6: objective=0.247613 reg=0.016432
2017/08/29 17:47:20 step 7: objective=0.248136 reg=0.016421
2017/08/29 17:47:20 Training value function...
2017/08/29 17:47:26 step 0: mse=1.154700 step=0.050000
2017/08/29 17:47:30 step 1: mse=1.154411 step=0.050000
2017/08/29 17:47:33 step 2: mse=1.154163 step=0.050000
2017/08/29 17:47:37 step 3: mse=1.153911 step=0.050000
2017/08/29 17:47:40 step 4: mse=1.153702 step=0.050000
2017/08/29 17:47:44 step 5: mse=1.153485 step=0.050000
2017/08/29 17:47:47 step 6: mse=1.153280 step=0.050000
2017/08/29 17:47:51 step 7: mse=1.153102 step=0.050000
2017/08/29 17:47:51 Saving...
2017/08/29 17:47:51 Gathering batch of experience...
2017/08/29 17:48:18 batch 140: mean=5.102057 stddev=1.469268 entropy=1.646910 frames=100140 count=5007
2017/08/29 17:48:18 Training policy...
2017/08/29 17:48:31 step 0: objective=0.249907 reg=0.016469
2017/08/29 17:48:37 step 1: objective=0.250588 reg=0.016460
2017/08/29 17:48:43 step 2: objective=0.251052 reg=0.016472
2017/08/29 17:48:48 step 3: objective=0.251667 reg=0.016449
2017/08/29 17:48:54 step 4: objective=0.251881 reg=0.016467
2017/08/29 17:49:00 step 5: objective=0.252425 reg=0.016456
2017/08/29 17:49:06 step 6: objective=0.252631 reg=0.016462
2017/08/29 17:49:12 step 7: objective=0.253058 reg=0.016453
2017/08/29 17:49:12 Training value function...
2017/08/29 17:49:18 step 0: mse=1.193426 step=0.050000
2017/08/29 17:49:21 step 1: mse=1.192845 step=0.050000
2017/08/29 17:49:24 step 2: mse=1.192300 step=0.050000
2017/08/29 17:49:28 step 3: mse=1.191784 step=0.050000
2017/08/29 17:49:31 step 4: mse=1.191311 step=0.050000
2017/08/29 17:49:35 step 5: mse=1.190870 step=0.050000
2017/08/29 17:49:38 step 6: mse=1.190460 step=0.050000
2017/08/29 17:49:42 step 7: mse=1.190072 step=0.050000
2017/08/29 17:49:42 Saving...
2017/08/29 17:49:42 Gathering batch of experience...
2017/08/29 17:50:10 batch 141: mean=5.090074 stddev=1.500042 entropy=1.639815 frames=100140 count=5007
2017/08/29 17:50:10 Training policy...
2017/08/29 17:50:23 step 0: objective=0.242425 reg=0.016398
2017/08/29 17:50:29 step 1: objective=0.243169 reg=0.016388
2017/08/29 17:50:35 step 2: objective=0.243761 reg=0.016380
2017/08/29 17:50:41 step 3: objective=0.244219 reg=0.016387
2017/08/29 17:50:47 step 4: objective=0.244599 reg=0.016384
2017/08/29 17:50:52 step 5: objective=0.245020 reg=0.016385
2017/08/29 17:50:58 step 6: objective=0.245379 reg=0.016381
2017/08/29 17:51:04 step 7: objective=0.245820 reg=0.016380
2017/08/29 17:51:04 Training value function...
2017/08/29 17:51:10 step 0: mse=1.202425 step=0.050000
2017/08/29 17:51:13 step 1: mse=1.202393 step=0.050000
2017/08/29 17:51:17 step 2: mse=1.202372 step=0.050000
2017/08/29 17:51:20 step 3: mse=1.202363 step=0.050000
2017/08/29 17:51:24 step 4: mse=1.202362 step=0.050000
2017/08/29 17:51:27 step 5: mse=1.202368 step=0.050000
2017/08/29 17:51:31 step 6: mse=1.202378 step=0.050000
2017/08/29 17:51:34 step 7: mse=1.202385 step=0.050000
2017/08/29 17:51:34 Saving...
2017/08/29 17:51:34 Gathering batch of experience...
2017/08/29 17:52:02 batch 142: mean=5.150190 stddev=1.473490 entropy=1.637499 frames=100140 count=5007
2017/08/29 17:52:02 Training policy...
2017/08/29 17:52:15 step 0: objective=0.268221 reg=0.016375
2017/08/29 17:52:21 step 1: objective=0.268972 reg=0.016368
2017/08/29 17:52:27 step 2: objective=0.269647 reg=0.016363
2017/08/29 17:52:33 step 3: objective=0.270399 reg=0.016361
2017/08/29 17:52:39 step 4: objective=0.270934 reg=0.016351
2017/08/29 17:52:45 step 5: objective=0.271044 reg=0.016371
2017/08/29 17:52:51 step 6: objective=0.271683 reg=0.016346
2017/08/29 17:52:57 step 7: objective=0.271967 reg=0.016338
2017/08/29 17:52:57 Training value function...
2017/08/29 17:53:03 step 0: mse=1.218478 step=0.050000
2017/08/29 17:53:07 step 1: mse=1.216932 step=0.050000
2017/08/29 17:53:10 step 2: mse=1.215496 step=0.050000
2017/08/29 17:53:14 step 3: mse=1.214177 step=0.050000
2017/08/29 17:53:17 step 4: mse=1.212918 step=0.050000
2017/08/29 17:53:21 step 5: mse=1.211723 step=0.050000
2017/08/29 17:53:24 step 6: mse=1.210616 step=0.050000
2017/08/29 17:53:28 step 7: mse=1.209557 step=0.050000
2017/08/29 17:53:28 Saving...
2017/08/29 17:53:28 Gathering batch of experience...
2017/08/29 17:53:55 batch 143: mean=5.164769 stddev=1.478362 entropy=1.629538 frames=100140 count=5007
2017/08/29 17:53:55 Training policy...
2017/08/29 17:54:08 step 0: objective=0.268436 reg=0.016295
2017/08/29 17:54:14 step 1: objective=0.269219 reg=0.016286
2017/08/29 17:54:20 step 2: objective=0.269978 reg=0.016271
2017/08/29 17:54:26 step 3: objective=0.270666 reg=0.016269
2017/08/29 17:54:32 step 4: objective=0.271343 reg=0.016257
2017/08/29 17:54:38 step 5: objective=0.271746 reg=0.016256
2017/08/29 17:54:43 step 6: objective=0.272015 reg=0.016234
2017/08/29 17:54:49 step 7: objective=0.272219 reg=0.016244
2017/08/29 17:54:49 Training value function...
2017/08/29 17:54:55 step 0: mse=1.228147 step=0.050000
2017/08/29 17:54:58 step 1: mse=1.226606 step=0.050000
2017/08/29 17:55:02 step 2: mse=1.225164 step=0.050000
2017/08/29 17:55:05 step 3: mse=1.223802 step=0.050000
2017/08/29 17:55:09 step 4: mse=1.222545 step=0.050000
2017/08/29 17:55:12 step 5: mse=1.221364 step=0.050000
2017/08/29 17:55:16 step 6: mse=1.220243 step=0.050000
2017/08/29 17:55:19 step 7: mse=1.219201 step=0.050000
2017/08/29 17:55:19 Saving...
2017/08/29 17:55:19 Gathering batch of experience...
2017/08/29 17:55:47 batch 144: mean=5.181546 stddev=1.468120 entropy=1.627192 frames=100140 count=5007
2017/08/29 17:55:47 Training policy...
2017/08/29 17:56:00 step 0: objective=0.258162 reg=0.016272
2017/08/29 17:56:06 step 1: objective=0.259022 reg=0.016260
2017/08/29 17:56:12 step 2: objective=0.259471 reg=0.016273
2017/08/29 17:56:17 step 3: objective=0.260130 reg=0.016250
2017/08/29 17:56:23 step 4: objective=0.260412 reg=0.016266
2017/08/29 17:56:29 step 5: objective=0.260781 reg=0.016242
2017/08/29 17:56:35 step 6: objective=0.260911 reg=0.016269
2017/08/29 17:56:41 step 7: objective=0.261115 reg=0.016236
2017/08/29 17:56:41 Training value function...
2017/08/29 17:56:47 step 0: mse=1.181620 step=0.050000
2017/08/29 17:56:50 step 1: mse=1.180805 step=0.050000
2017/08/29 17:56:54 step 2: mse=1.180049 step=0.050000
2017/08/29 17:56:57 step 3: mse=1.179348 step=0.050000
2017/08/29 17:57:01 step 4: mse=1.178649 step=0.050000
2017/08/29 17:57:04 step 5: mse=1.178041 step=0.050000
2017/08/29 17:57:08 step 6: mse=1.177472 step=0.050000
2017/08/29 17:57:11 step 7: mse=1.176916 step=0.050000
2017/08/29 17:57:11 Saving...
2017/08/29 17:57:11 Gathering batch of experience...
2017/08/29 17:57:39 batch 145: mean=5.142800 stddev=1.460819 entropy=1.623320 frames=100140 count=5007
2017/08/29 17:57:39 Training policy...
2017/08/29 17:57:52 step 0: objective=0.247604 reg=0.016233
2017/08/29 17:57:58 step 1: objective=0.248528 reg=0.016229
2017/08/29 17:58:04 step 2: objective=0.249360 reg=0.016235
2017/08/29 17:58:10 step 3: objective=0.249928 reg=0.016224
2017/08/29 17:58:16 step 4: objective=0.250329 reg=0.016224
2017/08/29 17:58:21 step 5: objective=0.250679 reg=0.016212
2017/08/29 17:58:27 step 6: objective=0.251007 reg=0.016228
2017/08/29 17:58:33 step 7: objective=0.251339 reg=0.016202
2017/08/29 17:58:33 Training value function...
2017/08/29 17:58:39 step 0: mse=1.169634 step=0.050000
2017/08/29 17:58:43 step 1: mse=1.169365 step=0.050000
2017/08/29 17:58:46 step 2: mse=1.169123 step=0.050000
2017/08/29 17:58:50 step 3: mse=1.168902 step=0.050000
2017/08/29 17:58:53 step 4: mse=1.168699 step=0.050000
2017/08/29 17:58:57 step 5: mse=1.168505 step=0.050000
2017/08/29 17:59:00 step 6: mse=1.168325 step=0.050000
2017/08/29 17:59:04 step 7: mse=1.168151 step=0.050000
2017/08/29 17:59:04 Saving...
2017/08/29 17:59:04 Gathering batch of experience...
2017/08/29 17:59:31 batch 146: mean=5.111644 stddev=1.442223 entropy=1.626541 frames=100140 count=5007
2017/08/29 17:59:31 Training policy...
2017/08/29 17:59:45 step 0: objective=0.227354 reg=0.016265
2017/08/29 17:59:51 step 1: objective=0.227984 reg=0.016253
2017/08/29 17:59:56 step 2: objective=0.228470 reg=0.016257
2017/08/29 18:00:02 step 3: objective=0.229016 reg=0.016245
2017/08/29 18:00:08 step 4: objective=0.229355 reg=0.016251
2017/08/29 18:00:14 step 5: objective=0.229731 reg=0.016245
2017/08/29 18:00:20 step 6: objective=0.230172 reg=0.016233
2017/08/29 18:00:26 step 7: objective=0.230712 reg=0.016225
2017/08/29 18:00:26 Training value function...
2017/08/29 18:00:32 step 0: mse=1.103160 step=0.050000
2017/08/29 18:00:35 step 1: mse=1.103761 step=0.050000
2017/08/29 18:00:39 step 2: mse=1.104318 step=0.050000
2017/08/29 18:00:42 step 3: mse=1.104850 step=0.050000
2017/08/29 18:00:46 step 4: mse=1.105349 step=0.050000
2017/08/29 18:00:49 step 5: mse=1.105817 step=0.050000
2017/08/29 18:00:52 step 6: mse=1.106261 step=0.050000
2017/08/29 18:00:56 step 7: mse=1.106674 step=0.050000
2017/08/29 18:00:56 Saving...
2017/08/29 18:00:56 Gathering batch of experience...
2017/08/29 18:01:24 batch 147: mean=5.154384 stddev=1.475698 entropy=1.617388 frames=100140 count=5007
2017/08/29 18:01:24 Training policy...
2017/08/29 18:01:37 step 0: objective=0.258292 reg=0.016174
2017/08/29 18:01:43 step 1: objective=0.258975 reg=0.016156
2017/08/29 18:01:48 step 2: objective=0.259556 reg=0.016176
2017/08/29 18:01:54 step 3: objective=0.259964 reg=0.016145
2017/08/29 18:02:00 step 4: objective=0.260389 reg=0.016173
2017/08/29 18:02:06 step 5: objective=0.260586 reg=0.016136
2017/08/29 18:02:12 step 6: objective=0.261045 reg=0.016168
2017/08/29 18:02:18 step 7: objective=0.261213 reg=0.016134
2017/08/29 18:02:18 Training value function...
2017/08/29 18:02:24 step 0: mse=1.186843 step=0.050000
2017/08/29 18:02:28 step 1: mse=1.186264 step=0.050000
2017/08/29 18:02:31 step 2: mse=1.185732 step=0.050000
2017/08/29 18:02:35 step 3: mse=1.185240 step=0.050000
2017/08/29 18:02:38 step 4: mse=1.184785 step=0.050000
2017/08/29 18:02:42 step 5: mse=1.184360 step=0.050000
2017/08/29 18:02:45 step 6: mse=1.183962 step=0.050000
2017/08/29 18:02:49 step 7: mse=1.183584 step=0.050000
2017/08/29 18:02:49 Saving...
2017/08/29 18:02:49 Gathering batch of experience...
2017/08/29 18:03:17 batch 148: mean=5.143799 stddev=1.447191 entropy=1.620576 frames=100140 count=5007
2017/08/29 18:03:17 Training policy...
2017/08/29 18:03:30 step 0: objective=0.244772 reg=0.016206
2017/08/29 18:03:36 step 1: objective=0.245683 reg=0.016199
2017/08/29 18:03:42 step 2: objective=0.246531 reg=0.016193
2017/08/29 18:03:47 step 3: objective=0.247017 reg=0.016177
2017/08/29 18:03:53 step 4: objective=0.247153 reg=0.016166
2017/08/29 18:03:59 step 5: objective=0.247506 reg=0.016168
2017/08/29 18:04:05 step 6: objective=0.247877 reg=0.016147
2017/08/29 18:04:10 step 7: objective=0.248188 reg=0.016151
2017/08/29 18:04:10 Training value function...
2017/08/29 18:04:16 step 0: mse=1.146452 step=0.050000
2017/08/29 18:04:20 step 1: mse=1.146141 step=0.050000
2017/08/29 18:04:23 step 2: mse=1.145786 step=0.050000
2017/08/29 18:04:27 step 3: mse=1.145466 step=0.050000
2017/08/29 18:04:30 step 4: mse=1.145178 step=0.050000
2017/08/29 18:04:33 step 5: mse=1.144914 step=0.050000
2017/08/29 18:04:37 step 6: mse=1.144680 step=0.050000
2017/08/29 18:04:41 step 7: mse=1.144442 step=0.050000
2017/08/29 18:04:41 Saving...
2017/08/29 18:04:41 Gathering batch of experience...
2017/08/29 18:05:08 batch 149: mean=5.157180 stddev=1.467666 entropy=1.616673 frames=100140 count=5007
2017/08/29 18:05:08 Training policy...
2017/08/29 18:05:22 step 0: objective=0.250611 reg=0.016167
2017/08/29 18:05:28 step 1: objective=0.251276 reg=0.016161
2017/08/29 18:05:33 step 2: objective=0.251822 reg=0.016157
2017/08/29 18:05:39 step 3: objective=0.252481 reg=0.016157
2017/08/29 18:05:45 step 4: objective=0.253005 reg=0.016138
2017/08/29 18:05:51 step 5: objective=0.253400 reg=0.016149
2017/08/29 18:05:57 step 6: objective=0.253914 reg=0.016134
2017/08/29 18:06:03 step 7: objective=0.254364 reg=0.016144
2017/08/29 18:06:03 Training value function...
2017/08/29 18:06:09 step 0: mse=1.181518 step=0.050000
2017/08/29 18:06:12 step 1: mse=1.181243 step=0.050000
2017/08/29 18:06:16 step 2: mse=1.180974 step=0.050000
2017/08/29 18:06:19 step 3: mse=1.180744 step=0.050000
2017/08/29 18:06:23 step 4: mse=1.180511 step=0.050000
2017/08/29 18:06:26 step 5: mse=1.180313 step=0.050000
2017/08/29 18:06:30 step 6: mse=1.180107 step=0.050000
2017/08/29 18:06:33 step 7: mse=1.179903 step=0.050000
2017/08/29 18:06:33 Saving...
2017/08/29 18:06:33 Gathering batch of experience...
2017/08/29 18:07:01 batch 150: mean=5.172758 stddev=1.467004 entropy=1.606836 frames=100140 count=5007
2017/08/29 18:07:01 Training policy...
2017/08/29 18:07:14 step 0: objective=0.258545 reg=0.016068
2017/08/29 18:07:21 step 1: objective=0.259509 reg=0.016062
2017/08/29 18:07:26 step 2: objective=0.260024 reg=0.016075
2017/08/29 18:07:32 step 3: objective=0.260441 reg=0.016050
2017/08/29 18:07:38 step 4: objective=0.260562 reg=0.016080
2017/08/29 18:07:44 step 5: objective=0.261311 reg=0.016043
2017/08/29 18:07:50 step 6: objective=0.261400 reg=0.016070
2017/08/29 18:07:56 step 7: objective=0.262056 reg=0.016026
2017/08/29 18:07:56 Training value function...
2017/08/29 18:08:02 step 0: mse=1.199648 step=0.050000
2017/08/29 18:08:05 step 1: mse=1.198696 step=0.050000
2017/08/29 18:08:09 step 2: mse=1.197809 step=0.050000
2017/08/29 18:08:12 step 3: mse=1.196981 step=0.050000
2017/08/29 18:08:16 step 4: mse=1.196202 step=0.050000
2017/08/29 18:08:19 step 5: mse=1.195458 step=0.050000
2017/08/29 18:08:22 step 6: mse=1.194758 step=0.050000
2017/08/29 18:08:26 step 7: mse=1.194098 step=0.050000
2017/08/29 18:08:26 Saving...
2017/08/29 18:08:26 Gathering batch of experience...
2017/08/29 18:08:54 batch 151: mean=5.138207 stddev=1.498309 entropy=1.610677 frames=100140 count=5007
2017/08/29 18:08:54 Training policy...
2017/08/29 18:09:08 step 0: objective=0.236598 reg=0.016107
2017/08/29 18:09:13 step 1: objective=0.237442 reg=0.016107
2017/08/29 18:09:19 step 2: objective=0.238123 reg=0.016107
2017/08/29 18:09:25 step 3: objective=0.238643 reg=0.016093
2017/08/29 18:09:31 step 4: objective=0.239015 reg=0.016105
2017/08/29 18:09:37 step 5: objective=0.239470 reg=0.016086
2017/08/29 18:09:43 step 6: objective=0.239752 reg=0.016096
2017/08/29 18:09:48 step 7: objective=0.240196 reg=0.016067
2017/08/29 18:09:48 Training value function...
2017/08/29 18:09:54 step 0: mse=1.164659 step=0.050000
2017/08/29 18:09:58 step 1: mse=1.164843 step=0.050000
2017/08/29 18:10:01 step 2: mse=1.165032 step=0.050000
2017/08/29 18:10:05 step 3: mse=1.165222 step=0.050000
2017/08/29 18:10:08 step 4: mse=1.165419 step=0.050000
2017/08/29 18:10:12 step 5: mse=1.165585 step=0.050000
2017/08/29 18:10:15 step 6: mse=1.165729 step=0.050000
2017/08/29 18:10:19 step 7: mse=1.165884 step=0.050000
2017/08/29 18:10:19 Saving...
2017/08/29 18:10:19 Gathering batch of experience...
2017/08/29 18:10:47 batch 152: mean=5.124226 stddev=1.508695 entropy=1.605860 frames=100140 count=5007
2017/08/29 18:10:47 Training policy...
2017/08/29 18:11:00 step 0: objective=0.249559 reg=0.016059
2017/08/29 18:11:06 step 1: objective=0.250397 reg=0.016056
2017/08/29 18:11:13 step 2: objective=0.251228 reg=0.016055
2017/08/29 18:11:20 step 3: objective=0.251583 reg=0.016056
2017/08/29 18:11:27 step 4: objective=0.252151 reg=0.016055
2017/08/29 18:11:33 step 5: objective=0.252602 reg=0.016055
2017/08/29 18:11:39 step 6: objective=0.252865 reg=0.016049
2017/08/29 18:11:45 step 7: objective=0.253116 reg=0.016053
2017/08/29 18:11:45 Training value function...
2017/08/29 18:11:51 step 0: mse=1.193523 step=0.050000
2017/08/29 18:11:55 step 1: mse=1.193106 step=0.050000
2017/08/29 18:11:58 step 2: mse=1.192681 step=0.050000
2017/08/29 18:12:02 step 3: mse=1.192263 step=0.050000
2017/08/29 18:12:05 step 4: mse=1.191881 step=0.050000
2017/08/29 18:12:08 step 5: mse=1.191512 step=0.050000
2017/08/29 18:12:12 step 6: mse=1.191181 step=0.050000
2017/08/29 18:12:15 step 7: mse=1.190846 step=0.050000
2017/08/29 18:12:15 Saving...
2017/08/29 18:12:15 Gathering batch of experience...
2017/08/29 18:12:44 batch 153: mean=5.179549 stddev=1.442984 entropy=1.599123 frames=100140 count=5007
2017/08/29 18:12:44 Training policy...
2017/08/29 18:12:57 step 0: objective=0.262075 reg=0.015991
2017/08/29 18:13:02 step 1: objective=0.262956 reg=0.015982
2017/08/29 18:13:08 step 2: objective=0.263543 reg=0.015967
2017/08/29 18:13:14 step 3: objective=0.263879 reg=0.015984
2017/08/29 18:13:20 step 4: objective=0.264429 reg=0.015948
2017/08/29 18:13:26 step 5: objective=0.264760 reg=0.015967
2017/08/29 18:13:32 step 6: objective=0.264999 reg=0.015943
2017/08/29 18:13:38 step 7: objective=0.265295 reg=0.015957
2017/08/29 18:13:38 Training value function...
2017/08/29 18:13:44 step 0: mse=1.182864 step=0.050000
2017/08/29 18:13:48 step 1: mse=1.181976 step=0.050000
2017/08/29 18:13:51 step 2: mse=1.181155 step=0.050000
2017/08/29 18:13:55 step 3: mse=1.180379 step=0.050000
2017/08/29 18:13:58 step 4: mse=1.179666 step=0.050000
2017/08/29 18:14:02 step 5: mse=1.178993 step=0.050000
2017/08/29 18:14:05 step 6: mse=1.178364 step=0.050000
2017/08/29 18:14:08 step 7: mse=1.177773 step=0.050000
2017/08/29 18:14:08 Saving...
2017/08/29 18:14:08 Gathering batch of experience...
2017/08/29 18:14:37 batch 154: mean=5.170761 stddev=1.470501 entropy=1.602486 frames=100140 count=5007
2017/08/29 18:14:37 Training policy...
2017/08/29 18:14:50 step 0: objective=0.251623 reg=0.016025
2017/08/29 18:14:56 step 1: objective=0.252335 reg=0.016008
2017/08/29 18:15:02 step 2: objective=0.253074 reg=0.015999
2017/08/29 18:15:08 step 3: objective=0.253511 reg=0.016003
2017/08/29 18:15:14 step 4: objective=0.254032 reg=0.015981
2017/08/29 18:15:20 step 5: objective=0.254216 reg=0.015994
2017/08/29 18:15:26 step 6: objective=0.254666 reg=0.015984
2017/08/29 18:15:31 step 7: objective=0.254877 reg=0.015984
2017/08/29 18:15:31 Training value function...
2017/08/29 18:15:38 step 0: mse=1.168984 step=0.050000
2017/08/29 18:15:41 step 1: mse=1.168314 step=0.050000
2017/08/29 18:15:44 step 2: mse=1.167697 step=0.050000
2017/08/29 18:15:48 step 3: mse=1.167090 step=0.050000
2017/08/29 18:15:51 step 4: mse=1.166504 step=0.050000
2017/08/29 18:15:55 step 5: mse=1.165966 step=0.050000
2017/08/29 18:15:58 step 6: mse=1.165466 step=0.050000
2017/08/29 18:16:02 step 7: mse=1.164976 step=0.050000
2017/08/29 18:16:02 Saving...
2017/08/29 18:16:02 Gathering batch of experience...
2017/08/29 18:16:30 batch 155: mean=5.212303 stddev=1.484042 entropy=1.590022 frames=100140 count=5007
2017/08/29 18:16:30 Training policy...
2017/08/29 18:16:43 step 0: objective=0.273896 reg=0.015900
2017/08/29 18:16:49 step 1: objective=0.274513 reg=0.015892
2017/08/29 18:16:55 step 2: objective=0.274485 reg=0.015917
2017/08/29 18:17:00 step 3: objective=0.275232 reg=0.015881
2017/08/29 18:17:06 step 4: objective=0.275336 reg=0.015909
2017/08/29 18:17:12 step 5: objective=0.276178 reg=0.015869
2017/08/29 18:17:18 step 6: objective=0.276107 reg=0.015899
2017/08/29 18:17:24 step 7: objective=0.276943 reg=0.015857
2017/08/29 18:17:24 Training value function...
2017/08/29 18:17:30 step 0: mse=1.211996 step=0.050000
2017/08/29 18:17:34 step 1: mse=1.209869 step=0.050000
2017/08/29 18:17:37 step 2: mse=1.207889 step=0.050000
2017/08/29 18:17:41 step 3: mse=1.206038 step=0.050000
2017/08/29 18:17:44 step 4: mse=1.204290 step=0.050000
2017/08/29 18:17:48 step 5: mse=1.202619 step=0.050000
2017/08/29 18:17:51 step 6: mse=1.201104 step=0.050000
2017/08/29 18:17:54 step 7: mse=1.199672 step=0.050000
2017/08/29 18:17:54 Saving...
2017/08/29 18:17:54 Gathering batch of experience...
2017/08/29 18:18:23 batch 156: mean=5.189734 stddev=1.486626 entropy=1.592811 frames=100140 count=5007
2017/08/29 18:18:23 Training policy...
2017/08/29 18:18:36 step 0: objective=0.253563 reg=0.015928
2017/08/29 18:18:42 step 1: objective=0.254373 reg=0.015923
2017/08/29 18:18:48 step 2: objective=0.254980 reg=0.015897
2017/08/29 18:18:54 step 3: objective=0.255767 reg=0.015895
2017/08/29 18:19:00 step 4: objective=0.256189 reg=0.015889
2017/08/29 18:19:06 step 5: objective=0.256849 reg=0.015891
2017/08/29 18:19:12 step 6: objective=0.257318 reg=0.015883
2017/08/29 18:19:18 step 7: objective=0.257836 reg=0.015878
2017/08/29 18:19:18 Training value function...
2017/08/29 18:19:24 step 0: mse=1.202633 step=0.050000
2017/08/29 18:19:27 step 1: mse=1.201886 step=0.050000
2017/08/29 18:19:31 step 2: mse=1.201195 step=0.050000
2017/08/29 18:19:34 step 3: mse=1.200559 step=0.050000
2017/08/29 18:19:38 step 4: mse=1.199952 step=0.050000
2017/08/29 18:19:41 step 5: mse=1.199390 step=0.050000
2017/08/29 18:19:44 step 6: mse=1.198836 step=0.050000
2017/08/29 18:19:48 step 7: mse=1.198335 step=0.050000
2017/08/29 18:19:48 Saving...
2017/08/29 18:19:48 Gathering batch of experience...
2017/08/29 18:20:16 batch 157: mean=5.188935 stddev=1.470247 entropy=1.586987 frames=100140 count=5007
2017/08/29 18:20:16 Training policy...
2017/08/29 18:20:29 step 0: objective=0.241101 reg=0.015870
2017/08/29 18:20:35 step 1: objective=0.241882 reg=0.015866
2017/08/29 18:20:42 step 2: objective=0.242566 reg=0.015858
2017/08/29 18:20:47 step 3: objective=0.243133 reg=0.015842
2017/08/29 18:20:53 step 4: objective=0.243507 reg=0.015863
2017/08/29 18:20:59 step 5: objective=0.243990 reg=0.015835
2017/08/29 18:21:05 step 6: objective=0.244324 reg=0.015856
2017/08/29 18:21:11 step 7: objective=0.244739 reg=0.015822
2017/08/29 18:21:11 Training value function...
2017/08/29 18:21:17 step 0: mse=1.176886 step=0.050000
2017/08/29 18:21:21 step 1: mse=1.177095 step=0.050000
2017/08/29 18:21:24 step 2: mse=1.177308 step=0.050000
2017/08/29 18:21:28 step 3: mse=1.177519 step=0.050000
2017/08/29 18:21:31 step 4: mse=1.177731 step=0.050000
2017/08/29 18:21:35 step 5: mse=1.177933 step=0.050000
2017/08/29 18:21:38 step 6: mse=1.178125 step=0.050000
2017/08/29 18:21:41 step 7: mse=1.178228 step=0.050000
2017/08/29 18:21:41 Saving...
2017/08/29 18:21:42 Gathering batch of experience...
2017/08/29 18:22:10 batch 158: mean=5.171360 stddev=1.463692 entropy=1.587809 frames=100140 count=5007
2017/08/29 18:22:10 Training policy...
2017/08/29 18:22:23 step 0: objective=0.254491 reg=0.015878
2017/08/29 18:22:29 step 1: objective=0.255393 reg=0.015878
2017/08/29 18:22:35 step 2: objective=0.256090 reg=0.015877
2017/08/29 18:22:41 step 3: objective=0.256630 reg=0.015864
2017/08/29 18:22:47 step 4: objective=0.257107 reg=0.015867
2017/08/29 18:22:53 step 5: objective=0.257732 reg=0.015856
2017/08/29 18:22:59 step 6: objective=0.258153 reg=0.015848
2017/08/29 18:23:05 step 7: objective=0.258527 reg=0.015836
2017/08/29 18:23:05 Training value function...
2017/08/29 18:23:11 step 0: mse=1.190449 step=0.050000
2017/08/29 18:23:14 step 1: mse=1.189816 step=0.050000
2017/08/29 18:23:18 step 2: mse=1.189227 step=0.050000
2017/08/29 18:23:21 step 3: mse=1.188680 step=0.050000
2017/08/29 18:23:25 step 4: mse=1.188171 step=0.050000
2017/08/29 18:23:28 step 5: mse=1.187705 step=0.050000
2017/08/29 18:23:32 step 6: mse=1.187256 step=0.050000
2017/08/29 18:23:35 step 7: mse=1.186792 step=0.050000
2017/08/29 18:23:35 Saving...
2017/08/29 18:23:35 Gathering batch of experience...
2017/08/29 18:24:04 batch 159: mean=5.186739 stddev=1.509599 entropy=1.573916 frames=100140 count=5007
2017/08/29 18:24:04 Training policy...
2017/08/29 18:24:17 step 0: objective=0.255328 reg=0.015739
2017/08/29 18:24:23 step 1: objective=0.256167 reg=0.015735
2017/08/29 18:24:29 step 2: objective=0.256718 reg=0.015738
2017/08/29 18:24:36 step 3: objective=0.257394 reg=0.015735
2017/08/29 18:24:43 step 4: objective=0.257794 reg=0.015729
2017/08/29 18:24:49 step 5: objective=0.258390 reg=0.015724
2017/08/29 18:24:55 step 6: objective=0.258672 reg=0.015727
2017/08/29 18:25:01 step 7: objective=0.258934 reg=0.015710
2017/08/29 18:25:01 Training value function...
2017/08/29 18:25:07 step 0: mse=1.191953 step=0.050000
2017/08/29 18:25:10 step 1: mse=1.191127 step=0.050000
2017/08/29 18:25:14 step 2: mse=1.190356 step=0.050000
2017/08/29 18:25:17 step 3: mse=1.189626 step=0.050000
2017/08/29 18:25:21 step 4: mse=1.188946 step=0.050000
2017/08/29 18:25:24 step 5: mse=1.188288 step=0.050000
2017/08/29 18:25:27 step 6: mse=1.187676 step=0.050000
2017/08/29 18:25:31 step 7: mse=1.187100 step=0.050000
2017/08/29 18:25:31 Saving...
2017/08/29 18:25:31 Gathering batch of experience...
2017/08/29 18:25:59 batch 160: mean=5.161774 stddev=1.456030 entropy=1.582425 frames=100140 count=5007
2017/08/29 18:25:59 Training policy...
2017/08/29 18:26:12 step 0: objective=0.234751 reg=0.015824
2017/08/29 18:26:18 step 1: objective=0.235604 reg=0.015816
2017/08/29 18:26:24 step 2: objective=0.236276 reg=0.015810
2017/08/29 18:26:30 step 3: objective=0.236853 reg=0.015801
2017/08/29 18:26:36 step 4: objective=0.237411 reg=0.015802
2017/08/29 18:26:43 step 5: objective=0.237652 reg=0.015812
2017/08/29 18:26:49 step 6: objective=0.238092 reg=0.015799
2017/08/29 18:26:55 step 7: objective=0.238405 reg=0.015796
2017/08/29 18:26:55 Training value function...
2017/08/29 18:27:01 step 0: mse=1.150606 step=0.050000
2017/08/29 18:27:04 step 1: mse=1.151153 step=0.050000
2017/08/29 18:27:08 step 2: mse=1.151686 step=0.050000
2017/08/29 18:27:11 step 3: mse=1.152157 step=0.050000
2017/08/29 18:27:14 step 4: mse=1.152625 step=0.050000
2017/08/29 18:27:18 step 5: mse=1.153059 step=0.050000
2017/08/29 18:27:21 step 6: mse=1.153474 step=0.050000
2017/08/29 18:27:25 step 7: mse=1.153880 step=0.050000
2017/08/29 18:27:25 Saving...
2017/08/29 18:27:25 Gathering batch of experience...
2017/08/29 18:27:53 batch 161: mean=5.181746 stddev=1.459158 entropy=1.583062 frames=100140 count=5007
2017/08/29 18:27:53 Training policy...
2017/08/29 18:28:06 step 0: objective=0.254604 reg=0.015831
2017/08/29 18:28:12 step 1: objective=0.255456 reg=0.015827
2017/08/29 18:28:18 step 2: objective=0.255985 reg=0.015824
2017/08/29 18:28:24 step 3: objective=0.256168 reg=0.015833
2017/08/29 18:28:30 step 4: objective=0.256720 reg=0.015824
2017/08/29 18:28:36 step 5: objective=0.257076 reg=0.015837
2017/08/29 18:28:42 step 6: objective=0.257604 reg=0.015817
2017/08/29 18:28:48 step 7: objective=0.257925 reg=0.015831
2017/08/29 18:28:48 Training value function...
2017/08/29 18:28:54 step 0: mse=1.171292 step=0.050000
2017/08/29 18:28:58 step 1: mse=1.170545 step=0.050000
2017/08/29 18:29:01 step 2: mse=1.169862 step=0.050000
2017/08/29 18:29:05 step 3: mse=1.169245 step=0.050000
2017/08/29 18:29:08 step 4: mse=1.168697 step=0.050000
2017/08/29 18:29:12 step 5: mse=1.168172 step=0.050000
2017/08/29 18:29:15 step 6: mse=1.167698 step=0.050000
2017/08/29 18:29:19 step 7: mse=1.167235 step=0.050000
2017/08/29 18:29:19 Saving...
2017/08/29 18:29:19 Gathering batch of experience...
2017/08/29 18:29:47 batch 162: mean=5.184741 stddev=1.449235 entropy=1.569631 frames=100140 count=5007
2017/08/29 18:29:47 Training policy...
2017/08/29 18:30:01 step 0: objective=0.247964 reg=0.015696
2017/08/29 18:30:07 step 1: objective=0.248666 reg=0.015686
2017/08/29 18:30:13 step 2: objective=0.249021 reg=0.015682
2017/08/29 18:30:19 step 3: objective=0.249392 reg=0.015690
2017/08/29 18:30:25 step 4: objective=0.249978 reg=0.015660
2017/08/29 18:30:31 step 5: objective=0.250136 reg=0.015682
2017/08/29 18:30:36 step 6: objective=0.250667 reg=0.015657
2017/08/29 18:30:42 step 7: objective=0.250906 reg=0.015672
2017/08/29 18:30:42 Training value function...
2017/08/29 18:30:48 step 0: mse=1.151510 step=0.050000
2017/08/29 18:30:52 step 1: mse=1.151147 step=0.050000
2017/08/29 18:30:56 step 2: mse=1.150814 step=0.050000
2017/08/29 18:30:59 step 3: mse=1.150509 step=0.050000
2017/08/29 18:31:02 step 4: mse=1.150240 step=0.050000
2017/08/29 18:31:06 step 5: mse=1.149975 step=0.050000
2017/08/29 18:31:09 step 6: mse=1.149729 step=0.050000
2017/08/29 18:31:13 step 7: mse=1.149474 step=0.050000
2017/08/29 18:31:13 Saving...
2017/08/29 18:31:13 Gathering batch of experience...
2017/08/29 18:31:41 batch 163: mean=5.213301 stddev=1.490412 entropy=1.567470 frames=100140 count=5007
2017/08/29 18:31:41 Training policy...
2017/08/29 18:31:55 step 0: objective=0.265333 reg=0.015675
2017/08/29 18:32:02 step 1: objective=0.265974 reg=0.015680
2017/08/29 18:32:08 step 2: objective=0.266923 reg=0.015674
2017/08/29 18:32:14 step 3: objective=0.267478 reg=0.015677
2017/08/29 18:32:20 step 4: objective=0.267976 reg=0.015667
2017/08/29 18:32:26 step 5: objective=0.268266 reg=0.015659
2017/08/29 18:32:32 step 6: objective=0.268379 reg=0.015666
2017/08/29 18:32:38 step 7: objective=0.268589 reg=0.015650
2017/08/29 18:32:38 Training value function...
2017/08/29 18:32:44 step 0: mse=1.215759 step=0.050000
2017/08/29 18:32:47 step 1: mse=1.214387 step=0.050000
2017/08/29 18:32:51 step 2: mse=1.213084 step=0.050000
2017/08/29 18:32:54 step 3: mse=1.211869 step=0.050000
2017/08/29 18:32:58 step 4: mse=1.210724 step=0.050000
2017/08/29 18:33:01 step 5: mse=1.209657 step=0.050000
2017/08/29 18:33:05 step 6: mse=1.208638 step=0.050000
2017/08/29 18:33:08 step 7: mse=1.207685 step=0.050000
2017/08/29 18:33:08 Saving...
2017/08/29 18:33:08 Gathering batch of experience...
2017/08/29 18:33:37 batch 164: mean=5.186539 stddev=1.473267 entropy=1.575113 frames=100140 count=5007
2017/08/29 18:33:37 Training policy...
2017/08/29 18:33:50 step 0: objective=0.249474 reg=0.015751
2017/08/29 18:33:56 step 1: objective=0.250329 reg=0.015751
2017/08/29 18:34:02 step 2: objective=0.251052 reg=0.015743
2017/08/29 18:34:08 step 3: objective=0.251771 reg=0.015735
2017/08/29 18:34:14 step 4: objective=0.252218 reg=0.015733
2017/08/29 18:34:21 step 5: objective=0.252692 reg=0.015718
2017/08/29 18:34:27 step 6: objective=0.253164 reg=0.015718
2017/08/29 18:34:34 step 7: objective=0.253622 reg=0.015718
2017/08/29 18:34:34 Training value function...
2017/08/29 18:34:40 step 0: mse=1.168579 step=0.050000
2017/08/29 18:34:43 step 1: mse=1.168208 step=0.050000
2017/08/29 18:34:47 step 2: mse=1.167889 step=0.050000
2017/08/29 18:34:50 step 3: mse=1.167567 step=0.050000
2017/08/29 18:34:54 step 4: mse=1.167293 step=0.050000
2017/08/29 18:34:57 step 5: mse=1.167053 step=0.050000
2017/08/29 18:35:01 step 6: mse=1.166844 step=0.050000
2017/08/29 18:35:04 step 7: mse=1.166601 step=0.050000
2017/08/29 18:35:04 Saving...
2017/08/29 18:35:04 Gathering batch of experience...
2017/08/29 18:35:32 batch 165: mean=5.172758 stddev=1.466323 entropy=1.569023 frames=100140 count=5007
2017/08/29 18:35:32 Training policy...
2017/08/29 18:35:46 step 0: objective=0.243199 reg=0.015690
2017/08/29 18:35:52 step 1: objective=0.244020 reg=0.015688
2017/08/29 18:35:58 step 2: objective=0.244653 reg=0.015689
2017/08/29 18:36:04 step 3: objective=0.245256 reg=0.015682
2017/08/29 18:36:10 step 4: objective=0.245695 reg=0.015672
2017/08/29 18:36:16 step 5: objective=0.246124 reg=0.015673
2017/08/29 18:36:22 step 6: objective=0.246563 reg=0.015667
2017/08/29 18:36:29 step 7: objective=0.247014 reg=0.015669
2017/08/29 18:36:29 Training value function...
2017/08/29 18:36:35 step 0: mse=1.155672 step=0.050000
2017/08/29 18:36:39 step 1: mse=1.155763 step=0.050000
2017/08/29 18:36:42 step 2: mse=1.155854 step=0.050000
2017/08/29 18:36:46 step 3: mse=1.155941 step=0.050000
2017/08/29 18:36:49 step 4: mse=1.156032 step=0.050000
2017/08/29 18:36:53 step 5: mse=1.156116 step=0.050000
2017/08/29 18:36:56 step 6: mse=1.156189 step=0.050000
2017/08/29 18:36:59 step 7: mse=1.156217 step=0.050000
2017/08/29 18:36:59 Saving...
2017/08/29 18:37:00 Gathering batch of experience...
2017/08/29 18:37:28 batch 166: mean=5.196525 stddev=1.481975 entropy=1.564984 frames=100140 count=5007
2017/08/29 18:37:28 Training policy...
2017/08/29 18:37:41 step 0: objective=0.247594 reg=0.015650
2017/08/29 18:37:48 step 1: objective=0.248461 reg=0.015646
2017/08/29 18:37:54 step 2: objective=0.249283 reg=0.015642
2017/08/29 18:38:00 step 3: objective=0.249969 reg=0.015632
2017/08/29 18:38:06 step 4: objective=0.250449 reg=0.015633
2017/08/29 18:38:12 step 5: objective=0.250955 reg=0.015626
2017/08/29 18:38:18 step 6: objective=0.251525 reg=0.015623
2017/08/29 18:38:24 step 7: objective=0.252097 reg=0.015608
2017/08/29 18:38:24 Training value function...
2017/08/29 18:38:30 step 0: mse=1.168709 step=0.050000
2017/08/29 18:38:34 step 1: mse=1.168517 step=0.050000
2017/08/29 18:38:37 step 2: mse=1.168333 step=0.050000
2017/08/29 18:38:41 step 3: mse=1.168174 step=0.050000
2017/08/29 18:38:44 step 4: mse=1.167976 step=0.050000
2017/08/29 18:38:48 step 5: mse=1.167811 step=0.050000
2017/08/29 18:38:51 step 6: mse=1.167649 step=0.050000
2017/08/29 18:38:55 step 7: mse=1.167493 step=0.050000
2017/08/29 18:38:55 Saving...
2017/08/29 18:38:55 Gathering batch of experience...
2017/08/29 18:39:23 batch 167: mean=5.203515 stddev=1.468368 entropy=1.555185 frames=100140 count=5007
2017/08/29 18:39:23 Training policy...
2017/08/29 18:39:37 step 0: objective=0.255599 reg=0.015552
2017/08/29 18:39:43 step 1: objective=0.256300 reg=0.015542
2017/08/29 18:39:49 step 2: objective=0.256634 reg=0.015543
2017/08/29 18:39:55 step 3: objective=0.257268 reg=0.015538
2017/08/29 18:40:01 step 4: objective=0.257788 reg=0.015539
2017/08/29 18:40:07 step 5: objective=0.258347 reg=0.015530
2017/08/29 18:40:13 step 6: objective=0.258720 reg=0.015530
2017/08/29 18:40:19 step 7: objective=0.259070 reg=0.015508
2017/08/29 18:40:19 Training value function...
2017/08/29 18:40:25 step 0: mse=1.193665 step=0.050000
2017/08/29 18:40:29 step 1: mse=1.193279 step=0.050000
2017/08/29 18:40:32 step 2: mse=1.192929 step=0.050000
2017/08/29 18:40:36 step 3: mse=1.192608 step=0.050000
2017/08/29 18:40:39 step 4: mse=1.192313 step=0.050000
2017/08/29 18:40:43 step 5: mse=1.192040 step=0.050000
2017/08/29 18:40:46 step 6: mse=1.191782 step=0.050000
2017/08/29 18:40:50 step 7: mse=1.191542 step=0.050000
2017/08/29 18:40:50 Saving...
2017/08/29 18:40:50 Gathering batch of experience...
2017/08/29 18:41:18 batch 168: mean=5.208508 stddev=1.454339 entropy=1.558644 frames=100140 count=5007
2017/08/29 18:41:18 Training policy...
2017/08/29 18:41:31 step 0: objective=0.247943 reg=0.015587
2017/08/29 18:41:38 step 1: objective=0.248772 reg=0.015574
2017/08/29 18:41:45 step 2: objective=0.249303 reg=0.015578
2017/08/29 18:41:52 step 3: objective=0.249807 reg=0.015560
2017/08/29 18:41:58 step 4: objective=0.249962 reg=0.015563
2017/08/29 18:42:04 step 5: objective=0.250443 reg=0.015547
2017/08/29 18:42:11 step 6: objective=0.250615 reg=0.015566
2017/08/29 18:42:17 step 7: objective=0.251077 reg=0.015544
2017/08/29 18:42:17 Training value function...
2017/08/29 18:42:23 step 0: mse=1.161115 step=0.050000
2017/08/29 18:42:26 step 1: mse=1.160873 step=0.050000
2017/08/29 18:42:30 step 2: mse=1.160652 step=0.050000
2017/08/29 18:42:33 step 3: mse=1.160446 step=0.050000
2017/08/29 18:42:37 step 4: mse=1.160254 step=0.050000
2017/08/29 18:42:40 step 5: mse=1.160071 step=0.050000
2017/08/29 18:42:44 step 6: mse=1.159901 step=0.050000
2017/08/29 18:42:47 step 7: mse=1.159740 step=0.050000
2017/08/29 18:42:47 Saving...
2017/08/29 18:42:47 Gathering batch of experience...
2017/08/29 18:43:16 batch 169: mean=5.254444 stddev=1.479224 entropy=1.552627 frames=100140 count=5007
2017/08/29 18:43:16 Training policy...
2017/08/29 18:43:29 step 0: objective=0.266653 reg=0.015526
2017/08/29 18:43:35 step 1: objective=0.267484 reg=0.015522
2017/08/29 18:43:41 step 2: objective=0.267920 reg=0.015530
2017/08/29 18:43:48 step 3: objective=0.268198 reg=0.015512
2017/08/29 18:43:54 step 4: objective=0.268624 reg=0.015530
2017/08/29 18:44:00 step 5: objective=0.269263 reg=0.015499
2017/08/29 18:44:06 step 6: objective=0.269464 reg=0.015515
2017/08/29 18:44:12 step 7: objective=0.269903 reg=0.015496
2017/08/29 18:44:12 Training value function...
2017/08/29 18:44:18 step 0: mse=1.224777 step=0.050000
2017/08/29 18:44:22 step 1: mse=1.223209 step=0.050000
2017/08/29 18:44:25 step 2: mse=1.221751 step=0.050000
2017/08/29 18:44:29 step 3: mse=1.220373 step=0.050000
2017/08/29 18:44:32 step 4: mse=1.219090 step=0.050000
2017/08/29 18:44:36 step 5: mse=1.217887 step=0.050000
2017/08/29 18:44:39 step 6: mse=1.216788 step=0.050000
2017/08/29 18:44:43 step 7: mse=1.215718 step=0.050000
2017/08/29 18:44:43 Saving...
2017/08/29 18:44:43 Gathering batch of experience...
2017/08/29 18:45:11 batch 170: mean=5.212902 stddev=1.486713 entropy=1.553576 frames=100140 count=5007
2017/08/29 18:45:11 Training policy...
2017/08/29 18:45:25 step 0: objective=0.261613 reg=0.015536
2017/08/29 18:45:31 step 1: objective=0.262239 reg=0.015531
2017/08/29 18:45:37 step 2: objective=0.262937 reg=0.015529
2017/08/29 18:45:43 step 3: objective=0.263493 reg=0.015526
2017/08/29 18:45:49 step 4: objective=0.264093 reg=0.015516
2017/08/29 18:45:56 step 5: objective=0.264639 reg=0.015512
2017/08/29 18:46:02 step 6: objective=0.265137 reg=0.015509
2017/08/29 18:46:08 step 7: objective=0.265595 reg=0.015505
2017/08/29 18:46:08 Training value function...
2017/08/29 18:46:14 step 0: mse=1.191942 step=0.050000
2017/08/29 18:46:17 step 1: mse=1.190505 step=0.050000
2017/08/29 18:46:21 step 2: mse=1.189170 step=0.050000
2017/08/29 18:46:24 step 3: mse=1.187952 step=0.050000
2017/08/29 18:46:28 step 4: mse=1.186746 step=0.050000
2017/08/29 18:46:31 step 5: mse=1.185645 step=0.050000
2017/08/29 18:46:35 step 6: mse=1.184615 step=0.050000
2017/08/29 18:46:38 step 7: mse=1.183672 step=0.050000
2017/08/29 18:46:38 Saving...
2017/08/29 18:46:38 Gathering batch of experience...
2017/08/29 18:47:07 batch 171: mean=5.222089 stddev=1.487384 entropy=1.551339 frames=100140 count=5007
2017/08/29 18:47:07 Training policy...
2017/08/29 18:47:21 step 0: objective=0.244338 reg=0.015513
2017/08/29 18:47:27 step 1: objective=0.245257 reg=0.015504
2017/08/29 18:47:34 step 2: objective=0.245818 reg=0.015496
2017/08/29 18:47:40 step 3: objective=0.246272 reg=0.015494
2017/08/29 18:47:46 step 4: objective=0.246865 reg=0.015489
2017/08/29 18:47:52 step 5: objective=0.247315 reg=0.015493
2017/08/29 18:47:59 step 6: objective=0.247810 reg=0.015482
2017/08/29 18:48:05 step 7: objective=0.248122 reg=0.015482
2017/08/29 18:48:05 Training value function...
2017/08/29 18:48:11 step 0: mse=1.181903 step=0.050000
2017/08/29 18:48:14 step 1: mse=1.181872 step=0.050000
2017/08/29 18:48:18 step 2: mse=1.181863 step=0.050000
2017/08/29 18:48:21 step 3: mse=1.181868 step=0.050000
2017/08/29 18:48:25 step 4: mse=1.181851 step=0.050000
2017/08/29 18:48:28 step 5: mse=1.181836 step=0.050000
2017/08/29 18:48:32 step 6: mse=1.181829 step=0.050000
2017/08/29 18:48:35 step 7: mse=1.181825 step=0.050000
2017/08/29 18:48:35 Saving...
2017/08/29 18:48:35 Gathering batch of experience...
2017/08/29 18:49:04 batch 172: mean=5.226283 stddev=1.461073 entropy=1.541617 frames=100140 count=5007
2017/08/29 18:49:04 Training policy...
2017/08/29 18:49:17 step 0: objective=0.257891 reg=0.015416
2017/08/29 18:49:23 step 1: objective=0.258680 reg=0.015414
2017/08/29 18:49:29 step 2: objective=0.259302 reg=0.015414
2017/08/29 18:49:36 step 3: objective=0.259980 reg=0.015410
2017/08/29 18:49:42 step 4: objective=0.260625 reg=0.015404
2017/08/29 18:49:48 step 5: objective=0.261046 reg=0.015402
2017/08/29 18:49:54 step 6: objective=0.261501 reg=0.015391
2017/08/29 18:50:00 step 7: objective=0.261911 reg=0.015392
2017/08/29 18:50:00 Training value function...
2017/08/29 18:50:06 step 0: mse=1.186954 step=0.050000
2017/08/29 18:50:10 step 1: mse=1.186097 step=0.050000
2017/08/29 18:50:13 step 2: mse=1.185304 step=0.050000
2017/08/29 18:50:17 step 3: mse=1.184568 step=0.050000
2017/08/29 18:50:20 step 4: mse=1.183895 step=0.050000
2017/08/29 18:50:24 step 5: mse=1.183234 step=0.050000
2017/08/29 18:50:27 step 6: mse=1.182618 step=0.050000
2017/08/29 18:50:31 step 7: mse=1.182050 step=0.050000
2017/08/29 18:50:31 Saving...
2017/08/29 18:50:31 Gathering batch of experience...
2017/08/29 18:50:59 batch 173: mean=5.226683 stddev=1.483396 entropy=1.537007 frames=100140 count=5007
2017/08/29 18:50:59 Training policy...
2017/08/29 18:51:13 step 0: objective=0.251979 reg=0.015370
2017/08/29 18:51:19 step 1: objective=0.252781 reg=0.015363
2017/08/29 18:51:25 step 2: objective=0.253557 reg=0.015356
2017/08/29 18:51:31 step 3: objective=0.254137 reg=0.015349
2017/08/29 18:51:37 step 4: objective=0.254816 reg=0.015346
2017/08/29 18:51:43 step 5: objective=0.255277 reg=0.015345
2017/08/29 18:51:50 step 6: objective=0.255780 reg=0.015342
2017/08/29 18:51:56 step 7: objective=0.256041 reg=0.015342
2017/08/29 18:51:56 Training value function...
2017/08/29 18:52:02 step 0: mse=1.175120 step=0.050000
2017/08/29 18:52:05 step 1: mse=1.174720 step=0.050000
2017/08/29 18:52:09 step 2: mse=1.174350 step=0.050000
2017/08/29 18:52:12 step 3: mse=1.174009 step=0.050000
2017/08/29 18:52:16 step 4: mse=1.173689 step=0.050000
2017/08/29 18:52:19 step 5: mse=1.173391 step=0.050000
2017/08/29 18:52:23 step 6: mse=1.173104 step=0.050000
2017/08/29 18:52:26 step 7: mse=1.172832 step=0.050000
2017/08/29 18:52:26 Saving...
2017/08/29 18:52:26 Gathering batch of experience...
2017/08/29 18:52:55 batch 174: mean=5.216896 stddev=1.470735 entropy=1.535870 frames=100140 count=5007
2017/08/29 18:52:55 Training policy...
2017/08/29 18:53:09 step 0: objective=0.244649 reg=0.015359
2017/08/29 18:53:16 step 1: objective=0.245560 reg=0.015354
2017/08/29 18:53:22 step 2: objective=0.246368 reg=0.015356
2017/08/29 18:53:28 step 3: objective=0.247097 reg=0.015357
2017/08/29 18:53:34 step 4: objective=0.247670 reg=0.015356
2017/08/29 18:53:40 step 5: objective=0.248184 reg=0.015352
2017/08/29 18:53:47 step 6: objective=0.248622 reg=0.015345
2017/08/29 18:53:53 step 7: objective=0.248963 reg=0.015340
2017/08/29 18:53:53 Training value function...
2017/08/29 18:53:59 step 0: mse=1.169235 step=0.050000
2017/08/29 18:54:02 step 1: mse=1.169059 step=0.050000
2017/08/29 18:54:06 step 2: mse=1.168885 step=0.050000
2017/08/29 18:54:09 step 3: mse=1.168735 step=0.050000
2017/08/29 18:54:13 step 4: mse=1.168607 step=0.050000
2017/08/29 18:54:16 step 5: mse=1.168496 step=0.050000
2017/08/29 18:54:20 step 6: mse=1.168383 step=0.050000
2017/08/29 18:54:23 step 7: mse=1.168274 step=0.050000
2017/08/29 18:54:23 Saving...
2017/08/29 18:54:23 Gathering batch of experience...
2017/08/29 18:54:52 batch 175: mean=5.279209 stddev=1.456764 entropy=1.529830 frames=100140 count=5007
2017/08/29 18:54:52 Training policy...
2017/08/29 18:55:06 step 0: objective=0.271382 reg=0.015298
2017/08/29 18:55:12 step 1: objective=0.272338 reg=0.015299
2017/08/29 18:55:18 step 2: objective=0.272917 reg=0.015290
2017/08/29 18:55:24 step 3: objective=0.273535 reg=0.015284
2017/08/29 18:55:30 step 4: objective=0.274077 reg=0.015284
2017/08/29 18:55:36 step 5: objective=0.274565 reg=0.015289
2017/08/29 18:55:43 step 6: objective=0.275011 reg=0.015279
2017/08/29 18:55:49 step 7: objective=0.275343 reg=0.015289
2017/08/29 18:55:49 Training value function...
2017/08/29 18:55:55 step 0: mse=1.198299 step=0.050000
2017/08/29 18:55:58 step 1: mse=1.196681 step=0.050000
2017/08/29 18:56:02 step 2: mse=1.195177 step=0.050000
2017/08/29 18:56:05 step 3: mse=1.193798 step=0.050000
2017/08/29 18:56:09 step 4: mse=1.192487 step=0.050000
2017/08/29 18:56:12 step 5: mse=1.191281 step=0.050000
2017/08/29 18:56:16 step 6: mse=1.190132 step=0.050000
2017/08/29 18:56:19 step 7: mse=1.189073 step=0.050000
2017/08/29 18:56:19 Saving...
2017/08/29 18:56:19 Gathering batch of experience...
2017/08/29 18:56:48 batch 176: mean=5.235470 stddev=1.469576 entropy=1.536871 frames=100140 count=5007
2017/08/29 18:56:48 Training policy...
2017/08/29 18:57:02 step 0: objective=0.241709 reg=0.015369
2017/08/29 18:57:08 step 1: objective=0.242612 reg=0.015367
2017/08/29 18:57:14 step 2: objective=0.243294 reg=0.015359
2017/08/29 18:57:21 step 3: objective=0.243965 reg=0.015355
2017/08/29 18:57:27 step 4: objective=0.244501 reg=0.015345
2017/08/29 18:57:33 step 5: objective=0.244963 reg=0.015333
2017/08/29 18:57:39 step 6: objective=0.245155 reg=0.015348
2017/08/29 18:57:45 step 7: objective=0.245443 reg=0.015321
2017/08/29 18:57:45 Training value function...
2017/08/29 18:57:51 step 0: mse=1.169276 step=0.050000
2017/08/29 18:57:55 step 1: mse=1.169289 step=0.050000
2017/08/29 18:57:58 step 2: mse=1.169305 step=0.050000
2017/08/29 18:58:02 step 3: mse=1.169304 step=0.050000
2017/08/29 18:58:06 step 4: mse=1.169314 step=0.050000
2017/08/29 18:58:09 step 5: mse=1.169300 step=0.050000
2017/08/29 18:58:13 step 6: mse=1.169301 step=0.050000
2017/08/29 18:58:16 step 7: mse=1.169281 step=0.050000
2017/08/29 18:58:16 Saving...
2017/08/29 18:58:16 Gathering batch of experience...
2017/08/29 18:58:45 batch 177: mean=5.226483 stddev=1.478234 entropy=1.533329 frames=100140 count=5007
2017/08/29 18:58:45 Training policy...
2017/08/29 18:58:59 step 0: objective=0.236596 reg=0.015333
2017/08/29 18:59:05 step 1: objective=0.237422 reg=0.015323
2017/08/29 18:59:11 step 2: objective=0.238027 reg=0.015325
2017/08/29 18:59:17 step 3: objective=0.238617 reg=0.015318
2017/08/29 18:59:23 step 4: objective=0.239139 reg=0.015314
2017/08/29 18:59:30 step 5: objective=0.239697 reg=0.015308
2017/08/29 18:59:36 step 6: objective=0.240251 reg=0.015303
2017/08/29 18:59:42 step 7: objective=0.240669 reg=0.015295
2017/08/29 18:59:42 Training value function...
2017/08/29 18:59:48 step 0: mse=1.143342 step=0.050000
2017/08/29 18:59:52 step 1: mse=1.143629 step=0.050000
2017/08/29 18:59:55 step 2: mse=1.143909 step=0.050000
2017/08/29 18:59:59 step 3: mse=1.144181 step=0.050000
2017/08/29 19:00:02 step 4: mse=1.144441 step=0.050000
2017/08/29 19:00:06 step 5: mse=1.144688 step=0.050000
2017/08/29 19:00:09 step 6: mse=1.144920 step=0.050000
2017/08/29 19:00:13 step 7: mse=1.145138 step=0.050000
2017/08/29 19:00:13 Saving...
2017/08/29 19:00:13 Gathering batch of experience...
2017/08/29 19:00:42 batch 178: mean=5.181945 stddev=1.493027 entropy=1.530641 frames=100140 count=5007
2017/08/29 19:00:42 Training policy...
2017/08/29 19:00:55 step 0: objective=0.236546 reg=0.015306
2017/08/29 19:01:01 step 1: objective=0.237425 reg=0.015308
2017/08/29 19:01:08 step 2: objective=0.238142 reg=0.015304
2017/08/29 19:01:14 step 3: objective=0.238837 reg=0.015302
2017/08/29 19:01:21 step 4: objective=0.239434 reg=0.015298
2017/08/29 19:01:27 step 5: objective=0.239821 reg=0.015285
2017/08/29 19:01:33 step 6: objective=0.240261 reg=0.015292
2017/08/29 19:01:39 step 7: objective=0.240589 reg=0.015272
2017/08/29 19:01:39 Training value function...
2017/08/29 19:01:45 step 0: mse=1.162990 step=0.050000
2017/08/29 19:01:49 step 1: mse=1.163307 step=0.050000
2017/08/29 19:01:52 step 2: mse=1.163620 step=0.050000
2017/08/29 19:01:56 step 3: mse=1.163943 step=0.050000
2017/08/29 19:01:59 step 4: mse=1.164243 step=0.050000
2017/08/29 19:02:03 step 5: mse=1.164532 step=0.050000
2017/08/29 19:02:06 step 6: mse=1.164820 step=0.050000
2017/08/29 19:02:10 step 7: mse=1.165082 step=0.050000
2017/08/29 19:02:10 Saving...
2017/08/29 19:02:10 Gathering batch of experience...
2017/08/29 19:02:38 batch 179: mean=5.193929 stddev=1.483462 entropy=1.528644 frames=100140 count=5007
2017/08/29 19:02:38 Training policy...
2017/08/29 19:02:52 step 0: objective=0.241289 reg=0.015286
2017/08/29 19:02:58 step 1: objective=0.242022 reg=0.015277
2017/08/29 19:03:04 step 2: objective=0.242624 reg=0.015264
2017/08/29 19:03:11 step 3: objective=0.242773 reg=0.015286
2017/08/29 19:03:17 step 4: objective=0.243590 reg=0.015267
2017/08/29 19:03:23 step 5: objective=0.243775 reg=0.015282
2017/08/29 19:03:29 step 6: objective=0.244372 reg=0.015265
2017/08/29 19:03:35 step 7: objective=0.244877 reg=0.015277
2017/08/29 19:03:35 Training value function...
2017/08/29 19:03:41 step 0: mse=1.162291 step=0.050000
2017/08/29 19:03:45 step 1: mse=1.162609 step=0.050000
2017/08/29 19:03:48 step 2: mse=1.162918 step=0.050000
2017/08/29 19:03:52 step 3: mse=1.163215 step=0.050000
2017/08/29 19:03:55 step 4: mse=1.163491 step=0.050000
2017/08/29 19:03:59 step 5: mse=1.163760 step=0.050000
2017/08/29 19:04:02 step 6: mse=1.163988 step=0.050000
2017/08/29 19:04:06 step 7: mse=1.164177 step=0.050000
2017/08/29 19:04:06 Saving...
2017/08/29 19:04:06 Gathering batch of experience...
2017/08/29 19:04:35 batch 180: mean=5.247653 stddev=1.456850 entropy=1.528070 frames=100140 count=5007
2017/08/29 19:04:35 Training policy...
2017/08/29 19:04:49 step 0: objective=0.258498 reg=0.015281
2017/08/29 19:04:55 step 1: objective=0.259326 reg=0.015282
2017/08/29 19:05:01 step 2: objective=0.260009 reg=0.015268
2017/08/29 19:05:07 step 3: objective=0.260639 reg=0.015264
2017/08/29 19:05:14 step 4: objective=0.261217 reg=0.015261
2017/08/29 19:05:20 step 5: objective=0.261648 reg=0.015263
2017/08/29 19:05:26 step 6: objective=0.262161 reg=0.015255
2017/08/29 19:05:33 step 7: objective=0.262615 reg=0.015261
2017/08/29 19:05:33 Training value function...
2017/08/29 19:05:39 step 0: mse=1.196877 step=0.050000
2017/08/29 19:05:42 step 1: mse=1.196141 step=0.050000
2017/08/29 19:05:45 step 2: mse=1.195465 step=0.050000
2017/08/29 19:05:49 step 3: mse=1.194839 step=0.050000
2017/08/29 19:05:52 step 4: mse=1.194214 step=0.050000
2017/08/29 19:05:56 step 5: mse=1.193631 step=0.050000
2017/08/29 19:05:59 step 6: mse=1.193070 step=0.050000
2017/08/29 19:06:03 step 7: mse=1.192556 step=0.050000
2017/08/29 19:06:03 Saving...
2017/08/29 19:06:03 Gathering batch of experience...
2017/08/29 19:06:32 batch 181: mean=5.241861 stddev=1.487858 entropy=1.523869 frames=100140 count=5007
2017/08/29 19:06:32 Training policy...
2017/08/29 19:06:46 step 0: objective=0.259612 reg=0.015239
2017/08/29 19:06:52 step 1: objective=0.260338 reg=0.015231
2017/08/29 19:06:58 step 2: objective=0.261001 reg=0.015224
2017/08/29 19:07:05 step 3: objective=0.261604 reg=0.015217
2017/08/29 19:07:11 step 4: objective=0.262055 reg=0.015230
2017/08/29 19:07:17 step 5: objective=0.262476 reg=0.015219
2017/08/29 19:07:24 step 6: objective=0.262860 reg=0.015222
2017/08/29 19:07:30 step 7: objective=0.263205 reg=0.015215
2017/08/29 19:07:30 Training value function...
2017/08/29 19:07:36 step 0: mse=1.178307 step=0.050000
2017/08/29 19:07:40 step 1: mse=1.177345 step=0.050000
2017/08/29 19:07:43 step 2: mse=1.176453 step=0.050000
2017/08/29 19:07:47 step 3: mse=1.175619 step=0.050000
2017/08/29 19:07:50 step 4: mse=1.174829 step=0.050000
2017/08/29 19:07:54 step 5: mse=1.174090 step=0.050000
2017/08/29 19:07:57 step 6: mse=1.173396 step=0.050000
2017/08/29 19:08:01 step 7: mse=1.172744 step=0.050000
2017/08/29 19:08:01 Saving...
2017/08/29 19:08:01 Gathering batch of experience...
2017/08/29 19:08:30 batch 182: mean=5.269423 stddev=1.457305 entropy=1.519747 frames=100140 count=5007
2017/08/29 19:08:30 Training policy...
2017/08/29 19:08:44 step 0: objective=0.266682 reg=0.015198
2017/08/29 19:08:50 step 1: objective=0.267491 reg=0.015190
2017/08/29 19:08:57 step 2: objective=0.268047 reg=0.015182
2017/08/29 19:09:03 step 3: objective=0.268656 reg=0.015175
2017/08/29 19:09:09 step 4: objective=0.269145 reg=0.015168
2017/08/29 19:09:15 step 5: objective=0.269732 reg=0.015166
2017/08/29 19:09:22 step 6: objective=0.270222 reg=0.015166
2017/08/29 19:09:28 step 7: objective=0.270657 reg=0.015162
2017/08/29 19:09:28 Training value function...
2017/08/29 19:09:34 step 0: mse=1.175641 step=0.050000
2017/08/29 19:09:38 step 1: mse=1.173958 step=0.050000
2017/08/29 19:09:41 step 2: mse=1.172385 step=0.050000
2017/08/29 19:09:45 step 3: mse=1.170871 step=0.050000
2017/08/29 19:09:48 step 4: mse=1.169470 step=0.050000
2017/08/29 19:09:52 step 5: mse=1.168145 step=0.050000
2017/08/29 19:09:55 step 6: mse=1.166911 step=0.050000
2017/08/29 19:09:59 step 7: mse=1.165743 step=0.050000
2017/08/29 19:09:59 Saving...
2017/08/29 19:09:59 Gathering batch of experience...
2017/08/29 19:10:28 batch 183: mean=5.237867 stddev=1.465923 entropy=1.518419 frames=100140 count=5007
2017/08/29 19:10:28 Training policy...
2017/08/29 19:10:41 step 0: objective=0.250290 reg=0.015184
2017/08/29 19:10:48 step 1: objective=0.250939 reg=0.015179
2017/08/29 19:10:55 step 2: objective=0.251609 reg=0.015183
2017/08/29 19:11:01 step 3: objective=0.252310 reg=0.015172
2017/08/29 19:11:08 step 4: objective=0.252683 reg=0.015174
2017/08/29 19:11:14 step 5: objective=0.253175 reg=0.015165
2017/08/29 19:11:20 step 6: objective=0.253671 reg=0.015163
2017/08/29 19:11:27 step 7: objective=0.254056 reg=0.015157
2017/08/29 19:11:27 Training value function...
2017/08/29 19:11:32 step 0: mse=1.191090 step=0.050000
2017/08/29 19:11:36 step 1: mse=1.191112 step=0.050000
2017/08/29 19:11:39 step 2: mse=1.191158 step=0.050000
2017/08/29 19:11:43 step 3: mse=1.191215 step=0.050000
2017/08/29 19:11:46 step 4: mse=1.191242 step=0.050000
2017/08/29 19:11:50 step 5: mse=1.191301 step=0.050000
2017/08/29 19:11:53 step 6: mse=1.191354 step=0.050000
2017/08/29 19:11:57 step 7: mse=1.191385 step=0.050000
2017/08/29 19:11:57 Saving...
2017/08/29 19:11:57 Gathering batch of experience...
2017/08/29 19:12:26 batch 184: mean=5.262832 stddev=1.462951 entropy=1.516251 frames=100140 count=5007
2017/08/29 19:12:26 Training policy...
2017/08/29 19:12:40 step 0: objective=0.263925 reg=0.015163
2017/08/29 19:12:46 step 1: objective=0.264660 reg=0.015160
2017/08/29 19:12:52 step 2: objective=0.265403 reg=0.015156
2017/08/29 19:12:59 step 3: objective=0.266024 reg=0.015155
2017/08/29 19:13:05 step 4: objective=0.266571 reg=0.015156
2017/08/29 19:13:11 step 5: objective=0.267064 reg=0.015153
2017/08/29 19:13:18 step 6: objective=0.267505 reg=0.015145
2017/08/29 19:13:24 step 7: objective=0.267948 reg=0.015147
2017/08/29 19:13:24 Training value function...
2017/08/29 19:13:30 step 0: mse=1.159577 step=0.050000
2017/08/29 19:13:33 step 1: mse=1.157798 step=0.050000
2017/08/29 19:13:37 step 2: mse=1.156140 step=0.050000
2017/08/29 19:13:40 step 3: mse=1.154588 step=0.050000
2017/08/29 19:13:44 step 4: mse=1.153126 step=0.050000
2017/08/29 19:13:47 step 5: mse=1.151758 step=0.050000
2017/08/29 19:13:51 step 6: mse=1.150477 step=0.050000
2017/08/29 19:13:54 step 7: mse=1.149275 step=0.050000
2017/08/29 19:13:54 Saving...
2017/08/29 19:13:54 Gathering batch of experience...
2017/08/29 19:14:23 batch 185: mean=5.264430 stddev=1.480038 entropy=1.516429 frames=100140 count=5007
2017/08/29 19:14:23 Training policy...
2017/08/29 19:14:37 step 0: objective=0.254797 reg=0.015164
2017/08/29 19:14:43 step 1: objective=0.255409 reg=0.015153
2017/08/29 19:14:50 step 2: objective=0.255928 reg=0.015161
2017/08/29 19:14:56 step 3: objective=0.256346 reg=0.015153
2017/08/29 19:15:03 step 4: objective=0.257003 reg=0.015148
2017/08/29 19:15:09 step 5: objective=0.257535 reg=0.015146
2017/08/29 19:15:15 step 6: objective=0.258014 reg=0.015136
2017/08/29 19:15:22 step 7: objective=0.258358 reg=0.015150
2017/08/29 19:15:22 Training value function...
2017/08/29 19:15:28 step 0: mse=1.164278 step=0.050000
2017/08/29 19:15:31 step 1: mse=1.163418 step=0.050000
2017/08/29 19:15:35 step 2: mse=1.162622 step=0.050000
2017/08/29 19:15:38 step 3: mse=1.161883 step=0.050000
2017/08/29 19:15:42 step 4: mse=1.161213 step=0.050000
2017/08/29 19:15:45 step 5: mse=1.160567 step=0.050000
2017/08/29 19:15:49 step 6: mse=1.159980 step=0.050000
2017/08/29 19:15:52 step 7: mse=1.159403 step=0.050000
2017/08/29 19:15:52 Saving...
2017/08/29 19:15:52 Gathering batch of experience...
2017/08/29 19:16:21 batch 186: mean=5.278410 stddev=1.475714 entropy=1.500970 frames=100140 count=5007
2017/08/29 19:16:21 Training policy...
2017/08/29 19:16:36 step 0: objective=0.257684 reg=0.015010
2017/08/29 19:16:42 step 1: objective=0.258303 reg=0.015005
2017/08/29 19:16:49 step 2: objective=0.258984 reg=0.015002
2017/08/29 19:16:56 step 3: objective=0.259640 reg=0.015010
2017/08/29 19:17:02 step 4: objective=0.260212 reg=0.015010
2017/08/29 19:17:08 step 5: objective=0.260764 reg=0.015006
2017/08/29 19:17:15 step 6: objective=0.261272 reg=0.015006
2017/08/29 19:17:21 step 7: objective=0.261786 reg=0.015000
2017/08/29 19:17:21 Training value function...
2017/08/29 19:17:27 step 0: mse=1.196487 step=0.050000
2017/08/29 19:17:31 step 1: mse=1.195595 step=0.050000
2017/08/29 19:17:34 step 2: mse=1.194773 step=0.050000
2017/08/29 19:17:38 step 3: mse=1.194011 step=0.050000
2017/08/29 19:17:41 step 4: mse=1.193307 step=0.050000
2017/08/29 19:17:45 step 5: mse=1.192651 step=0.050000
2017/08/29 19:17:48 step 6: mse=1.192036 step=0.050000
2017/08/29 19:17:52 step 7: mse=1.191464 step=0.050000
2017/08/29 19:17:52 Saving...
2017/08/29 19:17:52 Gathering batch of experience...
2017/08/29 19:18:21 batch 187: mean=5.274815 stddev=1.464571 entropy=1.508423 frames=100140 count=5007
2017/08/29 19:18:21 Training policy...
2017/08/29 19:18:35 step 0: objective=0.249100 reg=0.015084
2017/08/29 19:18:42 step 1: objective=0.249900 reg=0.015076
2017/08/29 19:18:48 step 2: objective=0.250417 reg=0.015073
2017/08/29 19:18:56 step 3: objective=0.250750 reg=0.015072
2017/08/29 19:19:02 step 4: objective=0.251083 reg=0.015079
2017/08/29 19:19:08 step 5: objective=0.251481 reg=0.015066
2017/08/29 19:19:14 step 6: objective=0.251847 reg=0.015079
2017/08/29 19:19:21 step 7: objective=0.252292 reg=0.015067
2017/08/29 19:19:21 Training value function...
2017/08/29 19:19:27 step 0: mse=1.180919 step=0.050000
2017/08/29 19:19:30 step 1: mse=1.180823 step=0.050000
2017/08/29 19:19:34 step 2: mse=1.180742 step=0.050000
2017/08/29 19:19:37 step 3: mse=1.180672 step=0.050000
2017/08/29 19:19:41 step 4: mse=1.180626 step=0.050000
2017/08/29 19:19:44 step 5: mse=1.180544 step=0.050000
2017/08/29 19:19:48 step 6: mse=1.180483 step=0.050000
2017/08/29 19:19:51 step 7: mse=1.180440 step=0.050000
2017/08/29 19:19:51 Saving...
2017/08/29 19:19:51 Gathering batch of experience...
2017/08/29 19:20:20 batch 188: mean=5.244058 stddev=1.469737 entropy=1.508173 frames=100140 count=5007
2017/08/29 19:20:20 Training policy...
2017/08/29 19:20:34 step 0: objective=0.238552 reg=0.015082
2017/08/29 19:20:40 step 1: objective=0.239276 reg=0.015084
2017/08/29 19:20:47 step 2: objective=0.239953 reg=0.015085
2017/08/29 19:20:53 step 3: objective=0.240445 reg=0.015074
2017/08/29 19:21:00 step 4: objective=0.240505 reg=0.015095
2017/08/29 19:21:06 step 5: objective=0.240907 reg=0.015065
2017/08/29 19:21:12 step 6: objective=0.241508 reg=0.015087
2017/08/29 19:21:19 step 7: objective=0.241737 reg=0.015057
2017/08/29 19:21:19 Training value function...
2017/08/29 19:21:25 step 0: mse=1.130874 step=0.050000
2017/08/29 19:21:28 step 1: mse=1.130929 step=0.050000
2017/08/29 19:21:32 step 2: mse=1.130996 step=0.050000
2017/08/29 19:21:35 step 3: mse=1.131069 step=0.050000
2017/08/29 19:21:39 step 4: mse=1.131131 step=0.050000
2017/08/29 19:21:42 step 5: mse=1.131204 step=0.050000
2017/08/29 19:21:46 step 6: mse=1.131263 step=0.050000
2017/08/29 19:21:49 step 7: mse=1.131326 step=0.050000
2017/08/29 19:21:49 Saving...
2017/08/29 19:21:50 Gathering batch of experience...
2017/08/29 19:22:19 batch 189: mean=5.242860 stddev=1.465582 entropy=1.506082 frames=100140 count=5007
2017/08/29 19:22:19 Training policy...
2017/08/29 19:22:33 step 0: objective=0.239307 reg=0.015061
2017/08/29 19:22:39 step 1: objective=0.239973 reg=0.015054
2017/08/29 19:22:45 step 2: objective=0.240397 reg=0.015063
2017/08/29 19:22:52 step 3: objective=0.241014 reg=0.015048
2017/08/29 19:22:58 step 4: objective=0.241609 reg=0.015038
2017/08/29 19:23:05 step 5: objective=0.242032 reg=0.015037
2017/08/29 19:23:11 step 6: objective=0.242509 reg=0.015028
2017/08/29 19:23:17 step 7: objective=0.242987 reg=0.015022
2017/08/29 19:23:17 Training value function...
2017/08/29 19:23:24 step 0: mse=1.156831 step=0.050000
2017/08/29 19:23:27 step 1: mse=1.157165 step=0.050000
2017/08/29 19:23:30 step 2: mse=1.157495 step=0.050000
2017/08/29 19:23:34 step 3: mse=1.157810 step=0.050000
2017/08/29 19:23:37 step 4: mse=1.158106 step=0.050000
2017/08/29 19:23:41 step 5: mse=1.158371 step=0.050000
2017/08/29 19:23:44 step 6: mse=1.158631 step=0.050000
2017/08/29 19:23:48 step 7: mse=1.158878 step=0.050000
2017/08/29 19:23:48 Saving...
2017/08/29 19:23:48 Gathering batch of experience...
2017/08/29 19:24:17 batch 190: mean=5.302776 stddev=1.495282 entropy=1.500542 frames=100140 count=5007
2017/08/29 19:24:17 Training policy...
2017/08/29 19:24:31 step 0: objective=0.263092 reg=0.015005
2017/08/29 19:24:37 step 1: objective=0.263996 reg=0.015002
2017/08/29 19:24:43 step 2: objective=0.264675 reg=0.014992
2017/08/29 19:24:50 step 3: objective=0.265132 reg=0.015003
2017/08/29 19:24:57 step 4: objective=0.265760 reg=0.015000
2017/08/29 19:25:04 step 5: objective=0.266043 reg=0.015009
2017/08/29 19:25:10 step 6: objective=0.266473 reg=0.014995
2017/08/29 19:25:17 step 7: objective=0.266704 reg=0.015005
2017/08/29 19:25:17 Training value function...
2017/08/29 19:25:23 step 0: mse=1.212646 step=0.050000
2017/08/29 19:25:26 step 1: mse=1.211496 step=0.050000
2017/08/29 19:25:30 step 2: mse=1.210431 step=0.050000
2017/08/29 19:25:33 step 3: mse=1.209441 step=0.050000
2017/08/29 19:25:37 step 4: mse=1.208523 step=0.050000
2017/08/29 19:25:40 step 5: mse=1.207653 step=0.050000
2017/08/29 19:25:44 step 6: mse=1.206843 step=0.050000
2017/08/29 19:25:47 step 7: mse=1.206077 step=0.050000
2017/08/29 19:25:47 Saving...
2017/08/29 19:25:47 Gathering batch of experience...
2017/08/29 19:26:16 batch 191: mean=5.288396 stddev=1.465641 entropy=1.496075 frames=100140 count=5007
2017/08/29 19:26:16 Training policy...
2017/08/29 19:26:30 step 0: objective=0.252999 reg=0.014961
2017/08/29 19:26:36 step 1: objective=0.253857 reg=0.014957
2017/08/29 19:26:43 step 2: objective=0.254453 reg=0.014950
2017/08/29 19:26:49 step 3: objective=0.254847 reg=0.014948
2017/08/29 19:26:56 step 4: objective=0.255423 reg=0.014937
2017/08/29 19:27:02 step 5: objective=0.255699 reg=0.014945
2017/08/29 19:27:09 step 6: objective=0.256162 reg=0.014926
2017/08/29 19:27:15 step 7: objective=0.256429 reg=0.014947
2017/08/29 19:27:15 Training value function...
2017/08/29 19:27:21 step 0: mse=1.185723 step=0.050000
2017/08/29 19:27:25 step 1: mse=1.185623 step=0.050000
2017/08/29 19:27:28 step 2: mse=1.185536 step=0.050000
2017/08/29 19:27:31 step 3: mse=1.185457 step=0.050000
2017/08/29 19:27:35 step 4: mse=1.185385 step=0.050000
2017/08/29 19:27:38 step 5: mse=1.185320 step=0.050000
2017/08/29 19:27:42 step 6: mse=1.185258 step=0.050000
2017/08/29 19:27:46 step 7: mse=1.185198 step=0.050000
2017/08/29 19:27:46 Saving...
2017/08/29 19:27:46 Gathering batch of experience...
2017/08/29 19:28:15 batch 192: mean=5.278610 stddev=1.466103 entropy=1.495296 frames=100140 count=5007
2017/08/29 19:28:15 Training policy...
2017/08/29 19:28:29 step 0: objective=0.254370 reg=0.014953
2017/08/29 19:28:35 step 1: objective=0.255171 reg=0.014948
2017/08/29 19:28:41 step 2: objective=0.255816 reg=0.014952
2017/08/29 19:28:48 step 3: objective=0.256260 reg=0.014937
2017/08/29 19:28:54 step 4: objective=0.256746 reg=0.014944
2017/08/29 19:29:01 step 5: objective=0.257114 reg=0.014934
2017/08/29 19:29:08 step 6: objective=0.257394 reg=0.014947
2017/08/29 19:29:15 step 7: objective=0.257647 reg=0.014930
2017/08/29 19:29:15 Training value function...
2017/08/29 19:29:21 step 0: mse=1.189275 step=0.050000
2017/08/29 19:29:24 step 1: mse=1.188630 step=0.050000
2017/08/29 19:29:28 step 2: mse=1.188006 step=0.050000
2017/08/29 19:29:31 step 3: mse=1.187391 step=0.050000
2017/08/29 19:29:35 step 4: mse=1.186844 step=0.050000
2017/08/29 19:29:38 step 5: mse=1.186330 step=0.050000
2017/08/29 19:29:41 step 6: mse=1.185809 step=0.050000
2017/08/29 19:29:45 step 7: mse=1.185355 step=0.050000
2017/08/29 19:29:45 Saving...
2017/08/29 19:29:45 Gathering batch of experience...
2017/08/29 19:30:14 batch 193: mean=5.286798 stddev=1.484906 entropy=1.495383 frames=100140 count=5007
2017/08/29 19:30:14 Training policy...
2017/08/29 19:30:28 step 0: objective=0.246098 reg=0.014954
2017/08/29 19:30:35 step 1: objective=0.246940 reg=0.014949
2017/08/29 19:30:41 step 2: objective=0.247744 reg=0.014938
2017/08/29 19:30:47 step 3: objective=0.248214 reg=0.014946
2017/08/29 19:30:54 step 4: objective=0.248732 reg=0.014923
2017/08/29 19:31:00 step 5: objective=0.249045 reg=0.014932
2017/08/29 19:31:07 step 6: objective=0.249261 reg=0.014900
2017/08/29 19:31:13 step 7: objective=0.249199 reg=0.014940
2017/08/29 19:31:13 Training value function...
2017/08/29 19:31:19 step 0: mse=1.207980 step=0.050000
2017/08/29 19:31:23 step 1: mse=1.207994 step=0.050000
2017/08/29 19:31:26 step 2: mse=1.208022 step=0.050000
2017/08/29 19:31:30 step 3: mse=1.208063 step=0.050000
2017/08/29 19:31:33 step 4: mse=1.208085 step=0.050000
2017/08/29 19:31:37 step 5: mse=1.208113 step=0.050000
2017/08/29 19:31:40 step 6: mse=1.208150 step=0.050000
2017/08/29 19:31:44 step 7: mse=1.208171 step=0.050000
2017/08/29 19:31:44 Saving...
2017/08/29 19:31:44 Gathering batch of experience...
2017/08/29 19:32:13 batch 194: mean=5.291192 stddev=1.482434 entropy=1.487291 frames=100140 count=5007
2017/08/29 19:32:13 Training policy...
2017/08/29 19:32:27 step 0: objective=0.242536 reg=0.014873
2017/08/29 19:32:34 step 1: objective=0.243181 reg=0.014874
2017/08/29 19:32:41 step 2: objective=0.243887 reg=0.014874
2017/08/29 19:32:47 step 3: objective=0.244541 reg=0.014875
2017/08/29 19:32:54 step 4: objective=0.245076 reg=0.014872
2017/08/29 19:33:00 step 5: objective=0.245471 reg=0.014876
2017/08/29 19:33:06 step 6: objective=0.245733 reg=0.014854
2017/08/29 19:33:13 step 7: objective=0.245876 reg=0.014875
2017/08/29 19:33:13 Training value function...
2017/08/29 19:33:19 step 0: mse=1.133931 step=0.050000
2017/08/29 19:33:22 step 1: mse=1.133696 step=0.050000
2017/08/29 19:33:26 step 2: mse=1.133490 step=0.050000
2017/08/29 19:33:29 step 3: mse=1.133289 step=0.050000
2017/08/29 19:33:33 step 4: mse=1.133112 step=0.050000
2017/08/29 19:33:36 step 5: mse=1.132938 step=0.050000
2017/08/29 19:33:40 step 6: mse=1.132786 step=0.050000
2017/08/29 19:33:43 step 7: mse=1.132597 step=0.050000
2017/08/29 19:33:43 Saving...
2017/08/29 19:33:43 Gathering batch of experience...
2017/08/29 19:34:13 batch 195: mean=5.289794 stddev=1.471554 entropy=1.485231 frames=100140 count=5007
2017/08/29 19:34:13 Training policy...
2017/08/29 19:34:27 step 0: objective=0.264153 reg=0.014852
2017/08/29 19:34:35 step 1: objective=0.265076 reg=0.014844
2017/08/29 19:34:41 step 2: objective=0.265730 reg=0.014837
2017/08/29 19:34:48 step 3: objective=0.266215 reg=0.014834
2017/08/29 19:34:54 step 4: objective=0.266648 reg=0.014834
2017/08/29 19:35:01 step 5: objective=0.267228 reg=0.014824
2017/08/29 19:35:07 step 6: objective=0.267603 reg=0.014826
2017/08/29 19:35:14 step 7: objective=0.267966 reg=0.014824
2017/08/29 19:35:14 Training value function...
2017/08/29 19:35:20 step 0: mse=1.151874 step=0.050000
2017/08/29 19:35:24 step 1: mse=1.150100 step=0.050000
2017/08/29 19:35:27 step 2: mse=1.148449 step=0.050000
2017/08/29 19:35:31 step 3: mse=1.146907 step=0.050000
2017/08/29 19:35:34 step 4: mse=1.145450 step=0.050000
2017/08/29 19:35:38 step 5: mse=1.144059 step=0.050000
2017/08/29 19:35:41 step 6: mse=1.142760 step=0.050000
2017/08/29 19:35:44 step 7: mse=1.141559 step=0.050000
2017/08/29 19:35:44 Saving...
2017/08/29 19:35:45 Gathering batch of experience...
2017/08/29 19:36:14 batch 196: mean=5.278810 stddev=1.474826 entropy=1.486715 frames=100140 count=5007
2017/08/29 19:36:14 Training policy...
2017/08/29 19:36:28 step 0: objective=0.239131 reg=0.014867
2017/08/29 19:36:34 step 1: objective=0.239942 reg=0.014867
2017/08/29 19:36:41 step 2: objective=0.240633 reg=0.014864
2017/08/29 19:36:47 step 3: objective=0.241108 reg=0.014855
2017/08/29 19:36:54 step 4: objective=0.241664 reg=0.014855
2017/08/29 19:37:00 step 5: objective=0.242133 reg=0.014857
2017/08/29 19:37:07 step 6: objective=0.242708 reg=0.014853
2017/08/29 19:37:13 step 7: objective=0.243074 reg=0.014849
2017/08/29 19:37:13 Training value function...
2017/08/29 19:37:19 step 0: mse=1.138387 step=0.050000
2017/08/29 19:37:23 step 1: mse=1.138714 step=0.050000
2017/08/29 19:37:26 step 2: mse=1.139033 step=0.050000
2017/08/29 19:37:30 step 3: mse=1.139347 step=0.050000
2017/08/29 19:37:33 step 4: mse=1.139668 step=0.050000
2017/08/29 19:37:37 step 5: mse=1.139961 step=0.050000
2017/08/29 19:37:40 step 6: mse=1.140260 step=0.050000
2017/08/29 19:37:44 step 7: mse=1.140513 step=0.050000
2017/08/29 19:37:44 Saving...
2017/08/29 19:37:44 Gathering batch of experience...
2017/08/29 19:38:13 batch 197: mean=5.274216 stddev=1.465706 entropy=1.486889 frames=100140 count=5007
2017/08/29 19:38:13 Training policy...
2017/08/29 19:38:28 step 0: objective=0.235428 reg=0.014869
2017/08/29 19:38:35 step 1: objective=0.236214 reg=0.014873
2017/08/29 19:38:42 step 2: objective=0.236834 reg=0.014873
2017/08/29 19:38:49 step 3: objective=0.237399 reg=0.014874
2017/08/29 19:38:55 step 4: objective=0.237945 reg=0.014870
2017/08/29 19:39:02 step 5: objective=0.238324 reg=0.014861
2017/08/29 19:39:08 step 6: objective=0.238559 reg=0.014871
2017/08/29 19:39:15 step 7: objective=0.238972 reg=0.014853
2017/08/29 19:39:15 Training value function...
2017/08/29 19:39:21 step 0: mse=1.157711 step=0.050000
2017/08/29 19:39:25 step 1: mse=1.158582 step=0.050000
2017/08/29 19:39:28 step 2: mse=1.159415 step=0.050000
2017/08/29 19:39:32 step 3: mse=1.160215 step=0.050000
2017/08/29 19:39:35 step 4: mse=1.160976 step=0.050000
2017/08/29 19:39:39 step 5: mse=1.161682 step=0.050000
2017/08/29 19:39:42 step 6: mse=1.162357 step=0.050000
2017/08/29 19:39:46 step 7: mse=1.162986 step=0.050000
2017/08/29 19:39:46 Saving...
2017/08/29 19:39:46 Gathering batch of experience...
2017/08/29 19:40:15 batch 198: mean=5.328141 stddev=1.483002 entropy=1.480646 frames=100140 count=5007
2017/08/29 19:40:15 Training policy...
2017/08/29 19:40:29 step 0: objective=0.269629 reg=0.014806
2017/08/29 19:40:36 step 1: objective=0.270454 reg=0.014808
2017/08/29 19:40:42 step 2: objective=0.271304 reg=0.014808
2017/08/29 19:40:49 step 3: objective=0.271935 reg=0.014803
2017/08/29 19:40:56 step 4: objective=0.272494 reg=0.014801
2017/08/29 19:41:03 step 5: objective=0.272948 reg=0.014797
2017/08/29 19:41:10 step 6: objective=0.273257 reg=0.014796
2017/08/29 19:41:16 step 7: objective=0.273734 reg=0.014792
2017/08/29 19:41:16 Training value function...
2017/08/29 19:41:22 step 0: mse=1.197736 step=0.050000
2017/08/29 19:41:26 step 1: mse=1.196120 step=0.050000
2017/08/29 19:41:29 step 2: mse=1.194596 step=0.050000
2017/08/29 19:41:33 step 3: mse=1.193157 step=0.050000
2017/08/29 19:41:36 step 4: mse=1.191831 step=0.050000
2017/08/29 19:41:40 step 5: mse=1.190580 step=0.050000
2017/08/29 19:41:43 step 6: mse=1.189381 step=0.050000
2017/08/29 19:41:47 step 7: mse=1.188267 step=0.050000
2017/08/29 19:41:47 Saving...
2017/08/29 19:41:47 Gathering batch of experience...
2017/08/29 19:42:16 batch 199: mean=5.294188 stddev=1.466602 entropy=1.480802 frames=100140 count=5007
2017/08/29 19:42:16 Training policy...
2017/08/29 19:42:30 step 0: objective=0.255591 reg=0.014808
2017/08/29 19:42:37 step 1: objective=0.256429 reg=0.014810
2017/08/29 19:42:43 step 2: objective=0.257068 reg=0.014809
2017/08/29 19:42:50 step 3: objective=0.257677 reg=0.014805
2017/08/29 19:42:56 step 4: objective=0.258127 reg=0.014808
2017/08/29 19:43:03 step 5: objective=0.258500 reg=0.014801
2017/08/29 19:43:09 step 6: objective=0.258808 reg=0.014806
2017/08/29 19:43:16 step 7: objective=0.259258 reg=0.014787
2017/08/29 19:43:16 Training value function...
2017/08/29 19:43:22 step 0: mse=1.156304 step=0.050000
2017/08/29 19:43:25 step 1: mse=1.155696 step=0.050000
2017/08/29 19:43:29 step 2: mse=1.155113 step=0.050000
2017/08/29 19:43:32 step 3: mse=1.154576 step=0.050000
2017/08/29 19:43:36 step 4: mse=1.154084 step=0.050000
2017/08/29 19:43:39 step 5: mse=1.153627 step=0.050000
2017/08/29 19:43:43 step 6: mse=1.153200 step=0.050000
2017/08/29 19:43:46 step 7: mse=1.152804 step=0.050000
2017/08/29 19:43:46 Saving...
2017/08/29 19:43:47 Gathering batch of experience...
2017/08/29 19:44:16 batch 200: mean=5.287398 stddev=1.459625 entropy=1.477894 frames=100140 count=5007
2017/08/29 19:44:16 Training policy...
2017/08/29 19:44:30 step 0: objective=0.250708 reg=0.014779
2017/08/29 19:44:36 step 1: objective=0.251407 reg=0.014779
2017/08/29 19:44:43 step 2: objective=0.251898 reg=0.014764
2017/08/29 19:44:49 step 3: objective=0.252393 reg=0.014778
2017/08/29 19:44:56 step 4: objective=0.252814 reg=0.014760
2017/08/29 19:45:03 step 5: objective=0.253268 reg=0.014778
2017/08/29 19:45:09 step 6: objective=0.253663 reg=0.014762
2017/08/29 19:45:16 step 7: objective=0.253887 reg=0.014769
2017/08/29 19:45:16 Training value function...
2017/08/29 19:45:22 step 0: mse=1.153617 step=0.050000
2017/08/29 19:45:25 step 1: mse=1.153312 step=0.050000
2017/08/29 19:45:29 step 2: mse=1.153000 step=0.050000
2017/08/29 19:45:32 step 3: mse=1.152714 step=0.050000
2017/08/29 19:45:36 step 4: mse=1.152440 step=0.050000
2017/08/29 19:45:39 step 5: mse=1.152186 step=0.050000
2017/08/29 19:45:43 step 6: mse=1.151943 step=0.050000
2017/08/29 19:45:46 step 7: mse=1.151714 step=0.050000
2017/08/29 19:45:46 Saving...
2017/08/29 19:45:46 Gathering batch of experience...
2017/08/29 19:46:15 batch 201: mean=5.309966 stddev=1.486033 entropy=1.477347 frames=100140 count=5007
2017/08/29 19:46:15 Training policy...
2017/08/29 19:46:30 step 0: objective=0.249913 reg=0.014773
2017/08/29 19:46:36 step 1: objective=0.250748 reg=0.014772
2017/08/29 19:46:43 step 2: objective=0.251408 reg=0.014769
2017/08/29 19:46:49 step 3: objective=0.252015 reg=0.014770
2017/08/29 19:46:56 step 4: objective=0.252653 reg=0.014767
2017/08/29 19:47:02 step 5: objective=0.253231 reg=0.014758
2017/08/29 19:47:09 step 6: objective=0.253696 reg=0.014751
2017/08/29 19:47:16 step 7: objective=0.254225 reg=0.014748
2017/08/29 19:47:16 Training value function...
2017/08/29 19:47:22 step 0: mse=1.158629 step=0.050000
2017/08/29 19:47:25 step 1: mse=1.157952 step=0.050000
2017/08/29 19:47:29 step 2: mse=1.157328 step=0.050000
2017/08/29 19:47:32 step 3: mse=1.156752 step=0.050000
2017/08/29 19:47:36 step 4: mse=1.156223 step=0.050000
2017/08/29 19:47:39 step 5: mse=1.155695 step=0.050000
2017/08/29 19:47:43 step 6: mse=1.155206 step=0.050000
2017/08/29 19:47:46 step 7: mse=1.154756 step=0.050000
2017/08/29 19:47:46 Saving...
2017/08/29 19:47:46 Gathering batch of experience...
2017/08/29 19:48:16 batch 202: mean=5.310765 stddev=1.471821 entropy=1.473293 frames=100140 count=5007
2017/08/29 19:48:16 Training policy...
2017/08/29 19:48:30 step 0: objective=0.249986 reg=0.014733
2017/08/29 19:48:36 step 1: objective=0.250747 reg=0.014729
2017/08/29 19:48:43 step 2: objective=0.251296 reg=0.014737
2017/08/29 19:48:49 step 3: objective=0.251662 reg=0.014709
2017/08/29 19:48:56 step 4: objective=0.251938 reg=0.014738
2017/08/29 19:49:03 step 5: objective=0.252522 reg=0.014704
2017/08/29 19:49:09 step 6: objective=0.252655 reg=0.014731
2017/08/29 19:49:16 step 7: objective=0.253251 reg=0.014701
2017/08/29 19:49:16 Training value function...
2017/08/29 19:49:22 step 0: mse=1.183550 step=0.050000
2017/08/29 19:49:26 step 1: mse=1.183084 step=0.050000
2017/08/29 19:49:30 step 2: mse=1.182646 step=0.050000
2017/08/29 19:49:33 step 3: mse=1.182242 step=0.050000
2017/08/29 19:49:37 step 4: mse=1.181869 step=0.050000
2017/08/29 19:49:40 step 5: mse=1.181524 step=0.050000
2017/08/29 19:49:44 step 6: mse=1.181201 step=0.050000
2017/08/29 19:49:47 step 7: mse=1.180825 step=0.050000
2017/08/29 19:49:47 Saving...
2017/08/29 19:49:47 Gathering batch of experience...
2017/08/29 19:50:17 batch 203: mean=5.269822 stddev=1.466929 entropy=1.474534 frames=100140 count=5007
2017/08/29 19:50:17 Training policy...
2017/08/29 19:50:31 step 0: objective=0.234249 reg=0.014746
2017/08/29 19:50:37 step 1: objective=0.235117 reg=0.014746
2017/08/29 19:50:44 step 2: objective=0.235711 reg=0.014737
2017/08/29 19:50:51 step 3: objective=0.236357 reg=0.014734
2017/08/29 19:50:57 step 4: objective=0.237000 reg=0.014731
2017/08/29 19:51:04 step 5: objective=0.237360 reg=0.014735
2017/08/29 19:51:11 step 6: objective=0.237803 reg=0.014731
2017/08/29 19:51:18 step 7: objective=0.238220 reg=0.014732
2017/08/29 19:51:18 Training value function...
2017/08/29 19:51:24 step 0: mse=1.129510 step=0.050000
2017/08/29 19:51:27 step 1: mse=1.130195 step=0.050000
2017/08/29 19:51:31 step 2: mse=1.130852 step=0.050000
2017/08/29 19:51:34 step 3: mse=1.131453 step=0.050000
2017/08/29 19:51:38 step 4: mse=1.132025 step=0.050000
2017/08/29 19:51:41 step 5: mse=1.132570 step=0.050000
2017/08/29 19:51:45 step 6: mse=1.133088 step=0.050000
2017/08/29 19:51:48 step 7: mse=1.133574 step=0.050000
2017/08/29 19:51:48 Saving...
2017/08/29 19:51:49 Gathering batch of experience...
2017/08/29 19:52:18 batch 204: mean=5.272818 stddev=1.469980 entropy=1.470212 frames=100140 count=5007
2017/08/29 19:52:18 Training policy...
2017/08/29 19:52:32 step 0: objective=0.252580 reg=0.014702
2017/08/29 19:52:39 step 1: objective=0.253278 reg=0.014702
2017/08/29 19:52:45 step 2: objective=0.253916 reg=0.014705
2017/08/29 19:52:52 step 3: objective=0.254519 reg=0.014701
2017/08/29 19:52:59 step 4: objective=0.255013 reg=0.014692
2017/08/29 19:53:06 step 5: objective=0.255722 reg=0.014685
2017/08/29 19:53:13 step 6: objective=0.256209 reg=0.014681
2017/08/29 19:53:20 step 7: objective=0.256552 reg=0.014681
2017/08/29 19:53:20 Training value function...
2017/08/29 19:53:26 step 0: mse=1.137590 step=0.050000
2017/08/29 19:53:29 step 1: mse=1.137210 step=0.050000
2017/08/29 19:53:33 step 2: mse=1.136864 step=0.050000
2017/08/29 19:53:36 step 3: mse=1.136507 step=0.050000
2017/08/29 19:53:40 step 4: mse=1.136173 step=0.050000
2017/08/29 19:53:43 step 5: mse=1.135847 step=0.050000
2017/08/29 19:53:47 step 6: mse=1.135559 step=0.050000
2017/08/29 19:53:50 step 7: mse=1.135274 step=0.050000
2017/08/29 19:53:50 Saving...
2017/08/29 19:53:50 Gathering batch of experience...
2017/08/29 19:54:20 batch 205: mean=5.296585 stddev=1.464483 entropy=1.469542 frames=100140 count=5007
2017/08/29 19:54:20 Training policy...
2017/08/29 19:54:34 step 0: objective=0.263947 reg=0.014696
2017/08/29 19:54:40 step 1: objective=0.264703 reg=0.014693
2017/08/29 19:54:47 step 2: objective=0.265224 reg=0.014703
2017/08/29 19:54:54 step 3: objective=0.265930 reg=0.014696
2017/08/29 19:55:01 step 4: objective=0.266549 reg=0.014695
2017/08/29 19:55:07 step 5: objective=0.266959 reg=0.014688
2017/08/29 19:55:14 step 6: objective=0.267290 reg=0.014687
2017/08/29 19:55:20 step 7: objective=0.267789 reg=0.014687
2017/08/29 19:55:20 Training value function...
2017/08/29 19:55:27 step 0: mse=1.191277 step=0.050000
2017/08/29 19:55:30 step 1: mse=1.190216 step=0.050000
2017/08/29 19:55:34 step 2: mse=1.189240 step=0.050000
2017/08/29 19:55:37 step 3: mse=1.188285 step=0.050000
2017/08/29 19:55:40 step 4: mse=1.187393 step=0.050000
2017/08/29 19:55:44 step 5: mse=1.186560 step=0.050000
2017/08/29 19:55:47 step 6: mse=1.185791 step=0.050000
2017/08/29 19:55:51 step 7: mse=1.185055 step=0.050000
2017/08/29 19:55:51 Saving...
2017/08/29 19:55:51 Gathering batch of experience...
2017/08/29 19:56:21 batch 206: mean=5.343519 stddev=1.459058 entropy=1.466217 frames=100140 count=5007
2017/08/29 19:56:21 Training policy...
2017/08/29 19:56:35 step 0: objective=0.268192 reg=0.014662
2017/08/29 19:56:41 step 1: objective=0.268887 reg=0.014647
2017/08/29 19:56:48 step 2: objective=0.269300 reg=0.014647
2017/08/29 19:56:55 step 3: objective=0.269830 reg=0.014635
2017/08/29 19:57:01 step 4: objective=0.270266 reg=0.014649
2017/08/29 19:57:08 step 5: objective=0.270703 reg=0.014634
2017/08/29 19:57:15 step 6: objective=0.271254 reg=0.014633
2017/08/29 19:57:21 step 7: objective=0.271620 reg=0.014623
2017/08/29 19:57:21 Training value function...
2017/08/29 19:57:27 step 0: mse=1.169515 step=0.050000
2017/08/29 19:57:31 step 1: mse=1.167908 step=0.050000
2017/08/29 19:57:34 step 2: mse=1.166408 step=0.050000
2017/08/29 19:57:38 step 3: mse=1.165009 step=0.050000
2017/08/29 19:57:41 step 4: mse=1.163696 step=0.050000
2017/08/29 19:57:45 step 5: mse=1.162465 step=0.050000
2017/08/29 19:57:48 step 6: mse=1.161308 step=0.050000
2017/08/29 19:57:52 step 7: mse=1.160220 step=0.050000
2017/08/29 19:57:52 Saving...
2017/08/29 19:57:52 Gathering batch of experience...
2017/08/29 19:58:22 batch 207: mean=5.306171 stddev=1.481100 entropy=1.465567 frames=100140 count=5007
2017/08/29 19:58:22 Training policy...
2017/08/29 19:58:36 step 0: objective=0.243674 reg=0.014656
2017/08/29 19:58:42 step 1: objective=0.244432 reg=0.014653
2017/08/29 19:58:49 step 2: objective=0.245155 reg=0.014646
2017/08/29 19:58:56 step 3: objective=0.245905 reg=0.014643
2017/08/29 19:59:03 step 4: objective=0.246397 reg=0.014639
2017/08/29 19:59:09 step 5: objective=0.246880 reg=0.014640
2017/08/29 19:59:16 step 6: objective=0.247293 reg=0.014636
2017/08/29 19:59:23 step 7: objective=0.247742 reg=0.014628
2017/08/29 19:59:23 Training value function...
2017/08/29 19:59:29 step 0: mse=1.144075 step=0.050000
2017/08/29 19:59:32 step 1: mse=1.144046 step=0.050000
2017/08/29 19:59:36 step 2: mse=1.144031 step=0.050000
2017/08/29 19:59:39 step 3: mse=1.144027 step=0.050000
2017/08/29 19:59:43 step 4: mse=1.144031 step=0.050000
2017/08/29 19:59:46 step 5: mse=1.144005 step=0.050000
2017/08/29 19:59:50 step 6: mse=1.143988 step=0.050000
2017/08/29 19:59:53 step 7: mse=1.143966 step=0.050000
2017/08/29 19:59:53 Saving...
2017/08/29 19:59:53 Gathering batch of experience...
2017/08/29 20:00:23 batch 208: mean=5.331736 stddev=1.483145 entropy=1.455913 frames=100140 count=5007
2017/08/29 20:00:23 Training policy...
2017/08/29 20:00:37 step 0: objective=0.261536 reg=0.014559
2017/08/29 20:00:44 step 1: objective=0.262256 reg=0.014554
2017/08/29 20:00:50 step 2: objective=0.262750 reg=0.014561
2017/08/29 20:00:57 step 3: objective=0.263200 reg=0.014559
2017/08/29 20:01:04 step 4: objective=0.263603 reg=0.014564
2017/08/29 20:01:11 step 5: objective=0.264039 reg=0.014561
2017/08/29 20:01:17 step 6: objective=0.264358 reg=0.014568
2017/08/29 20:01:24 step 7: objective=0.264685 reg=0.014561
2017/08/29 20:01:24 Training value function...
2017/08/29 20:01:30 step 0: mse=1.152102 step=0.050000
2017/08/29 20:01:33 step 1: mse=1.151168 step=0.050000
2017/08/29 20:01:37 step 2: mse=1.150301 step=0.050000
2017/08/29 20:01:41 step 3: mse=1.149496 step=0.050000
2017/08/29 20:01:44 step 4: mse=1.148738 step=0.050000
2017/08/29 20:01:47 step 5: mse=1.148003 step=0.050000
2017/08/29 20:01:51 step 6: mse=1.147266 step=0.050000
2017/08/29 20:01:54 step 7: mse=1.146618 step=0.050000
2017/08/29 20:01:54 Saving...
2017/08/29 20:01:55 Gathering batch of experience...
2017/08/29 20:02:24 batch 209: mean=5.347314 stddev=1.479034 entropy=1.456989 frames=100140 count=5007
2017/08/29 20:02:24 Training policy...
2017/08/29 20:02:38 step 0: objective=0.259783 reg=0.014570
2017/08/29 20:02:45 step 1: objective=0.260383 reg=0.014556
2017/08/29 20:02:52 step 2: objective=0.260560 reg=0.014572
2017/08/29 20:02:58 step 3: objective=0.260983 reg=0.014560
2017/08/29 20:03:05 step 4: objective=0.261356 reg=0.014575
2017/08/29 20:03:12 step 5: objective=0.261626 reg=0.014553
2017/08/29 20:03:19 step 6: objective=0.261932 reg=0.014575
2017/08/29 20:03:25 step 7: objective=0.262361 reg=0.014544
2017/08/29 20:03:25 Training value function...
2017/08/29 20:03:32 step 0: mse=1.184099 step=0.050000
2017/08/29 20:03:35 step 1: mse=1.183330 step=0.050000
2017/08/29 20:03:38 step 2: mse=1.182607 step=0.050000
2017/08/29 20:03:42 step 3: mse=1.181942 step=0.050000
2017/08/29 20:03:45 step 4: mse=1.181318 step=0.050000
2017/08/29 20:03:49 step 5: mse=1.180748 step=0.050000
2017/08/29 20:03:52 step 6: mse=1.180205 step=0.050000
2017/08/29 20:03:56 step 7: mse=1.179702 step=0.050000
2017/08/29 20:03:56 Saving...
2017/08/29 20:03:56 Gathering batch of experience...
2017/08/29 20:04:26 batch 210: mean=5.327142 stddev=1.467724 entropy=1.459482 frames=100140 count=5007
2017/08/29 20:04:26 Training policy...
2017/08/29 20:04:39 step 0: objective=0.249660 reg=0.014595
2017/08/29 20:04:46 step 1: objective=0.250509 reg=0.014589
2017/08/29 20:04:53 step 2: objective=0.251132 reg=0.014584
2017/08/29 20:05:00 step 3: objective=0.251762 reg=0.014583
2017/08/29 20:05:07 step 4: objective=0.252365 reg=0.014586
2017/08/29 20:05:15 step 5: objective=0.253002 reg=0.014585
2017/08/29 20:05:22 step 6: objective=0.253507 reg=0.014587
2017/08/29 20:05:29 step 7: objective=0.253898 reg=0.014579
2017/08/29 20:05:29 Training value function...
2017/08/29 20:05:35 step 0: mse=1.162234 step=0.050000
2017/08/29 20:05:38 step 1: mse=1.161947 step=0.050000
2017/08/29 20:05:42 step 2: mse=1.161666 step=0.050000
2017/08/29 20:05:45 step 3: mse=1.161424 step=0.050000
2017/08/29 20:05:49 step 4: mse=1.161183 step=0.050000
2017/08/29 20:05:52 step 5: mse=1.160973 step=0.050000
2017/08/29 20:05:56 step 6: mse=1.160759 step=0.050000
2017/08/29 20:05:59 step 7: mse=1.160562 step=0.050000
2017/08/29 20:05:59 Saving...
2017/08/29 20:05:59 Gathering batch of experience...
2017/08/29 20:06:29 batch 211: mean=5.314560 stddev=1.462231 entropy=1.457957 frames=100140 count=5007
2017/08/29 20:06:29 Training policy...
2017/08/29 20:06:43 step 0: objective=0.248022 reg=0.014579
2017/08/29 20:06:50 step 1: objective=0.248754 reg=0.014575
2017/08/29 20:06:57 step 2: objective=0.249510 reg=0.014576
2017/08/29 20:07:04 step 3: objective=0.250022 reg=0.014577
2017/08/29 20:07:10 step 4: objective=0.250542 reg=0.014577
2017/08/29 20:07:17 step 5: objective=0.250881 reg=0.014575
2017/08/29 20:07:24 step 6: objective=0.251291 reg=0.014568
2017/08/29 20:07:31 step 7: objective=0.251619 reg=0.014567
2017/08/29 20:07:31 Training value function...
2017/08/29 20:07:37 step 0: mse=1.182525 step=0.050000
2017/08/29 20:07:40 step 1: mse=1.182452 step=0.050000
2017/08/29 20:07:44 step 2: mse=1.182325 step=0.050000
2017/08/29 20:07:47 step 3: mse=1.182173 step=0.050000
2017/08/29 20:07:51 step 4: mse=1.182108 step=0.050000
2017/08/29 20:07:54 step 5: mse=1.182032 step=0.050000
2017/08/29 20:07:58 step 6: mse=1.181920 step=0.050000
2017/08/29 20:08:01 step 7: mse=1.181799 step=0.050000
2017/08/29 20:08:01 Saving...
2017/08/29 20:08:01 Gathering batch of experience...
2017/08/29 20:08:31 batch 212: mean=5.360096 stddev=1.466199 entropy=1.451636 frames=100140 count=5007
2017/08/29 20:08:31 Training policy...
2017/08/29 20:08:45 step 0: objective=0.262978 reg=0.014516
2017/08/29 20:08:52 step 1: objective=0.263661 reg=0.014510
2017/08/29 20:08:58 step 2: objective=0.264366 reg=0.014502
2017/08/29 20:09:05 step 3: objective=0.264864 reg=0.014509
2017/08/29 20:09:12 step 4: objective=0.265340 reg=0.014497
2017/08/29 20:09:19 step 5: objective=0.265630 reg=0.014511
2017/08/29 20:09:26 step 6: objective=0.266022 reg=0.014491
2017/08/29 20:09:33 step 7: objective=0.266230 reg=0.014510
2017/08/29 20:09:33 Training value function...
2017/08/29 20:09:38 step 0: mse=1.166875 step=0.050000
2017/08/29 20:09:42 step 1: mse=1.165379 step=0.050000
2017/08/29 20:09:45 step 2: mse=1.163980 step=0.050000
2017/08/29 20:09:49 step 3: mse=1.162672 step=0.050000
2017/08/29 20:09:52 step 4: mse=1.161452 step=0.050000
2017/08/29 20:09:56 step 5: mse=1.160308 step=0.050000
2017/08/29 20:10:00 step 6: mse=1.159219 step=0.050000
2017/08/29 20:10:03 step 7: mse=1.158191 step=0.050000
2017/08/29 20:10:03 Saving...
2017/08/29 20:10:03 Gathering batch of experience...
2017/08/29 20:10:33 batch 213: mean=5.316956 stddev=1.471790 entropy=1.455496 frames=100140 count=5007
2017/08/29 20:10:33 Training policy...
2017/08/29 20:10:47 step 0: objective=0.238253 reg=0.014555
2017/08/29 20:10:54 step 1: objective=0.238997 reg=0.014553
2017/08/29 20:11:01 step 2: objective=0.239793 reg=0.014551
2017/08/29 20:11:08 step 3: objective=0.240322 reg=0.014549
2017/08/29 20:11:15 step 4: objective=0.240822 reg=0.014543
2017/08/29 20:11:22 step 5: objective=0.241258 reg=0.014539
2017/08/29 20:11:28 step 6: objective=0.241616 reg=0.014542
2017/08/29 20:11:35 step 7: objective=0.242029 reg=0.014530
2017/08/29 20:11:35 Training value function...
2017/08/29 20:11:41 step 0: mse=1.120253 step=0.050000
2017/08/29 20:11:45 step 1: mse=1.120569 step=0.050000
2017/08/29 20:11:48 step 2: mse=1.120885 step=0.050000
2017/08/29 20:11:52 step 3: mse=1.121221 step=0.050000
2017/08/29 20:11:55 step 4: mse=1.121510 step=0.050000
2017/08/29 20:11:59 step 5: mse=1.121790 step=0.050000
2017/08/29 20:12:02 step 6: mse=1.122069 step=0.050000
2017/08/29 20:12:06 step 7: mse=1.122331 step=0.050000
2017/08/29 20:12:06 Saving...
2017/08/29 20:12:06 Gathering batch of experience...
2017/08/29 20:12:36 batch 214: mean=5.365888 stddev=1.472991 entropy=1.445583 frames=100140 count=5007
2017/08/29 20:12:36 Training policy...
2017/08/29 20:12:50 step 0: objective=0.263542 reg=0.014456
2017/08/29 20:12:57 step 1: objective=0.264349 reg=0.014452
2017/08/29 20:13:04 step 2: objective=0.265103 reg=0.014450
2017/08/29 20:13:11 step 3: objective=0.265782 reg=0.014445
2017/08/29 20:13:18 step 4: objective=0.266192 reg=0.014445
2017/08/29 20:13:25 step 5: objective=0.266696 reg=0.014443
2017/08/29 20:13:31 step 6: objective=0.267062 reg=0.014432
2017/08/29 20:13:38 step 7: objective=0.267323 reg=0.014445
2017/08/29 20:13:38 Training value function...
2017/08/29 20:13:44 step 0: mse=1.196353 step=0.050000
2017/08/29 20:13:48 step 1: mse=1.195142 step=0.050000
2017/08/29 20:13:51 step 2: mse=1.194020 step=0.050000
2017/08/29 20:13:55 step 3: mse=1.192967 step=0.050000
2017/08/29 20:13:58 step 4: mse=1.191975 step=0.050000
2017/08/29 20:14:02 step 5: mse=1.191049 step=0.050000
2017/08/29 20:14:05 step 6: mse=1.190180 step=0.050000
2017/08/29 20:14:09 step 7: mse=1.189367 step=0.050000
2017/08/29 20:14:09 Saving...
2017/08/29 20:14:09 Gathering batch of experience...
2017/08/29 20:14:39 batch 215: mean=5.320152 stddev=1.479086 entropy=1.441230 frames=100140 count=5007
2017/08/29 20:14:39 Training policy...
2017/08/29 20:14:53 step 0: objective=0.254151 reg=0.014412
2017/08/29 20:15:00 step 1: objective=0.254863 reg=0.014400
2017/08/29 20:15:07 step 2: objective=0.255300 reg=0.014402
2017/08/29 20:15:13 step 3: objective=0.255834 reg=0.014413
2017/08/29 20:15:20 step 4: objective=0.256428 reg=0.014403
2017/08/29 20:15:27 step 5: objective=0.256923 reg=0.014410
2017/08/29 20:15:34 step 6: objective=0.257495 reg=0.014406
2017/08/29 20:15:41 step 7: objective=0.257938 reg=0.014412
2017/08/29 20:15:41 Training value function...
2017/08/29 20:15:47 step 0: mse=1.170040 step=0.050000
2017/08/29 20:15:50 step 1: mse=1.169485 step=0.050000
2017/08/29 20:15:54 step 2: mse=1.168971 step=0.050000
2017/08/29 20:15:57 step 3: mse=1.168427 step=0.050000
2017/08/29 20:16:01 step 4: mse=1.167925 step=0.050000
2017/08/29 20:16:04 step 5: mse=1.167505 step=0.050000
2017/08/29 20:16:08 step 6: mse=1.167060 step=0.050000
2017/08/29 20:16:11 step 7: mse=1.166647 step=0.050000
2017/08/29 20:16:11 Saving...
2017/08/29 20:16:11 Gathering batch of experience...
2017/08/29 20:16:41 batch 216: mean=5.362692 stddev=1.445595 entropy=1.445308 frames=100140 count=5007
2017/08/29 20:16:41 Training policy...
2017/08/29 20:16:56 step 0: objective=0.254302 reg=0.014453
2017/08/29 20:17:03 step 1: objective=0.254938 reg=0.014450
2017/08/29 20:17:10 step 2: objective=0.255618 reg=0.014444
2017/08/29 20:17:17 step 3: objective=0.256252 reg=0.014442
2017/08/29 20:17:24 step 4: objective=0.256874 reg=0.014437
2017/08/29 20:17:30 step 5: objective=0.257242 reg=0.014444
2017/08/29 20:17:37 step 6: objective=0.257753 reg=0.014433
2017/08/29 20:17:44 step 7: objective=0.258199 reg=0.014439
2017/08/29 20:17:44 Training value function...
2017/08/29 20:17:50 step 0: mse=1.160318 step=0.050000
2017/08/29 20:17:53 step 1: mse=1.159871 step=0.050000
2017/08/29 20:17:57 step 2: mse=1.159458 step=0.050000
2017/08/29 20:18:00 step 3: mse=1.159078 step=0.050000
2017/08/29 20:18:04 step 4: mse=1.158726 step=0.050000
2017/08/29 20:18:07 step 5: mse=1.158400 step=0.050000
2017/08/29 20:18:11 step 6: mse=1.158078 step=0.050000
2017/08/29 20:18:14 step 7: mse=1.157787 step=0.050000
2017/08/29 20:18:14 Saving...
2017/08/29 20:18:14 Gathering batch of experience...
2017/08/29 20:18:44 batch 217: mean=5.343719 stddev=1.458121 entropy=1.441769 frames=100140 count=5007
2017/08/29 20:18:44 Training policy...
2017/08/29 20:18:59 step 0: objective=0.249764 reg=0.014418
2017/08/29 20:19:06 step 1: objective=0.250657 reg=0.014420
2017/08/29 20:19:13 step 2: objective=0.251284 reg=0.014425
2017/08/29 20:19:20 step 3: objective=0.252012 reg=0.014419
2017/08/29 20:19:26 step 4: objective=0.252672 reg=0.014418
2017/08/29 20:19:33 step 5: objective=0.253041 reg=0.014414
2017/08/29 20:19:40 step 6: objective=0.253414 reg=0.014412
2017/08/29 20:19:47 step 7: objective=0.253688 reg=0.014403
2017/08/29 20:19:47 Training value function...
2017/08/29 20:19:53 step 0: mse=1.155696 step=0.050000
2017/08/29 20:19:57 step 1: mse=1.155535 step=0.050000
2017/08/29 20:20:00 step 2: mse=1.155392 step=0.050000
2017/08/29 20:20:04 step 3: mse=1.155265 step=0.050000
2017/08/29 20:20:07 step 4: mse=1.155157 step=0.050000
2017/08/29 20:20:11 step 5: mse=1.155058 step=0.050000
2017/08/29 20:20:14 step 6: mse=1.154963 step=0.050000
2017/08/29 20:20:18 step 7: mse=1.154868 step=0.050000
2017/08/29 20:20:18 Saving...
2017/08/29 20:20:18 Gathering batch of experience...
2017/08/29 20:20:48 batch 218: mean=5.367486 stddev=1.496806 entropy=1.438254 frames=100140 count=5007
2017/08/29 20:20:48 Training policy...
2017/08/29 20:21:02 step 0: objective=0.255679 reg=0.014382
2017/08/29 20:21:09 step 1: objective=0.256346 reg=0.014373
2017/08/29 20:21:16 step 2: objective=0.256666 reg=0.014386
2017/08/29 20:21:23 step 3: objective=0.257183 reg=0.014362
2017/08/29 20:21:29 step 4: objective=0.257757 reg=0.014380
2017/08/29 20:21:36 step 5: objective=0.258134 reg=0.014351
2017/08/29 20:21:43 step 6: objective=0.258549 reg=0.014368
2017/08/29 20:21:50 step 7: objective=0.258840 reg=0.014342
2017/08/29 20:21:50 Training value function...
2017/08/29 20:21:56 step 0: mse=1.199126 step=0.050000
2017/08/29 20:22:00 step 1: mse=1.198382 step=0.050000
2017/08/29 20:22:03 step 2: mse=1.197694 step=0.050000
2017/08/29 20:22:07 step 3: mse=1.197056 step=0.050000
2017/08/29 20:22:10 step 4: mse=1.196433 step=0.050000
2017/08/29 20:22:14 step 5: mse=1.195869 step=0.050000
2017/08/29 20:22:17 step 6: mse=1.195341 step=0.050000
2017/08/29 20:22:21 step 7: mse=1.194826 step=0.050000
2017/08/29 20:22:21 Saving...
2017/08/29 20:22:21 Gathering batch of experience...
2017/08/29 20:22:51 batch 219: mean=5.385460 stddev=1.466493 entropy=1.438642 frames=100140 count=5007
2017/08/29 20:22:51 Training policy...
2017/08/29 20:23:05 step 0: objective=0.261835 reg=0.014386
2017/08/29 20:23:12 step 1: objective=0.262616 reg=0.014385
2017/08/29 20:23:18 step 2: objective=0.263214 reg=0.014383
2017/08/29 20:23:26 step 3: objective=0.263575 reg=0.014384
2017/08/29 20:23:33 step 4: objective=0.264202 reg=0.014379
2017/08/29 20:23:39 step 5: objective=0.264690 reg=0.014378
2017/08/29 20:23:46 step 6: objective=0.265221 reg=0.014378
2017/08/29 20:23:53 step 7: objective=0.265677 reg=0.014376
2017/08/29 20:23:53 Training value function...
2017/08/29 20:23:59 step 0: mse=1.167987 step=0.050000
2017/08/29 20:24:03 step 1: mse=1.166963 step=0.050000
2017/08/29 20:24:06 step 2: mse=1.165982 step=0.050000
2017/08/29 20:24:10 step 3: mse=1.165073 step=0.050000
2017/08/29 20:24:13 step 4: mse=1.164218 step=0.050000
2017/08/29 20:24:17 step 5: mse=1.163415 step=0.050000
2017/08/29 20:24:20 step 6: mse=1.162671 step=0.050000
2017/08/29 20:24:24 step 7: mse=1.161971 step=0.050000
2017/08/29 20:24:24 Saving...
2017/08/29 20:24:24 Gathering batch of experience...
2017/08/29 20:24:54 batch 220: mean=5.327342 stddev=1.440553 entropy=1.439397 frames=100140 count=5007
2017/08/29 20:24:54 Training policy...
2017/08/29 20:25:08 step 0: objective=0.239297 reg=0.014394
2017/08/29 20:25:15 step 1: objective=0.240076 reg=0.014400
2017/08/29 20:25:21 step 2: objective=0.240560 reg=0.014388
2017/08/29 20:25:28 step 3: objective=0.240995 reg=0.014406
2017/08/29 20:25:35 step 4: objective=0.241580 reg=0.014410
2017/08/29 20:25:42 step 5: objective=0.241998 reg=0.014391
2017/08/29 20:25:49 step 6: objective=0.242309 reg=0.014412
2017/08/29 20:25:56 step 7: objective=0.242738 reg=0.014396
2017/08/29 20:25:56 Training value function...
2017/08/29 20:26:02 step 0: mse=1.143311 step=0.050000
2017/08/29 20:26:05 step 1: mse=1.143979 step=0.050000
2017/08/29 20:26:09 step 2: mse=1.144621 step=0.050000
2017/08/29 20:26:12 step 3: mse=1.145234 step=0.050000
2017/08/29 20:26:16 step 4: mse=1.145816 step=0.050000
2017/08/29 20:26:19 step 5: mse=1.146368 step=0.050000
2017/08/29 20:26:23 step 6: mse=1.146888 step=0.050000
2017/08/29 20:26:26 step 7: mse=1.147379 step=0.050000
2017/08/29 20:26:26 Saving...
2017/08/29 20:26:26 Gathering batch of experience...
2017/08/29 20:26:56 batch 221: mean=5.298183 stddev=1.466476 entropy=1.439534 frames=100140 count=5007
2017/08/29 20:26:56 Training policy...
2017/08/29 20:27:11 step 0: objective=0.241148 reg=0.014395
2017/08/29 20:27:18 step 1: objective=0.241870 reg=0.014389
2017/08/29 20:27:25 step 2: objective=0.242579 reg=0.014390
2017/08/29 20:27:32 step 3: objective=0.243283 reg=0.014389
2017/08/29 20:27:39 step 4: objective=0.243813 reg=0.014389
2017/08/29 20:27:46 step 5: objective=0.244266 reg=0.014388
2017/08/29 20:27:53 step 6: objective=0.244738 reg=0.014390
2017/08/29 20:28:00 step 7: objective=0.245150 reg=0.014390
2017/08/29 20:28:00 Training value function...
2017/08/29 20:28:06 step 0: mse=1.141835 step=0.050000
2017/08/29 20:28:09 step 1: mse=1.141942 step=0.050000
2017/08/29 20:28:13 step 2: mse=1.142051 step=0.050000
2017/08/29 20:28:16 step 3: mse=1.142166 step=0.050000
2017/08/29 20:28:20 step 4: mse=1.142282 step=0.050000
2017/08/29 20:28:23 step 5: mse=1.142399 step=0.050000
2017/08/29 20:28:27 step 6: mse=1.142495 step=0.050000
2017/08/29 20:28:30 step 7: mse=1.142607 step=0.050000
2017/08/29 20:28:30 Saving...
2017/08/29 20:28:30 Gathering batch of experience...
2017/08/29 20:29:00 batch 222: mean=5.364490 stddev=1.448938 entropy=1.433609 frames=100140 count=5007
2017/08/29 20:29:00 Training policy...
2017/08/29 20:29:15 step 0: objective=0.254699 reg=0.014336
2017/08/29 20:29:22 step 1: objective=0.255316 reg=0.014328
2017/08/29 20:29:29 step 2: objective=0.256064 reg=0.014331
2017/08/29 20:29:36 step 3: objective=0.256736 reg=0.014318
2017/08/29 20:29:43 step 4: objective=0.257269 reg=0.014316
2017/08/29 20:29:50 step 5: objective=0.257792 reg=0.014310
2017/08/29 20:29:57 step 6: objective=0.258362 reg=0.014308
2017/08/29 20:30:04 step 7: objective=0.258927 reg=0.014308
2017/08/29 20:30:04 Training value function...
2017/08/29 20:30:10 step 0: mse=1.175130 step=0.050000
2017/08/29 20:30:14 step 1: mse=1.174602 step=0.050000
2017/08/29 20:30:17 step 2: mse=1.174072 step=0.050000
2017/08/29 20:30:21 step 3: mse=1.173535 step=0.050000
2017/08/29 20:30:24 step 4: mse=1.173036 step=0.050000
2017/08/29 20:30:28 step 5: mse=1.172555 step=0.050000
2017/08/29 20:30:31 step 6: mse=1.172121 step=0.050000
2017/08/29 20:30:35 step 7: mse=1.171699 step=0.050000
2017/08/29 20:30:35 Saving...
2017/08/29 20:30:35 Gathering batch of experience...
2017/08/29 20:31:05 batch 223: mean=5.350110 stddev=1.492894 entropy=1.434316 frames=100140 count=5007
2017/08/29 20:31:05 Training policy...
2017/08/29 20:31:19 step 0: objective=0.245955 reg=0.014343
2017/08/29 20:31:27 step 1: objective=0.246622 reg=0.014339
2017/08/29 20:31:34 step 2: objective=0.247038 reg=0.014334
2017/08/29 20:31:41 step 3: objective=0.247490 reg=0.014328
2017/08/29 20:31:48 step 4: objective=0.247877 reg=0.014335
2017/08/29 20:31:55 step 5: objective=0.248308 reg=0.014323
2017/08/29 20:32:02 step 6: objective=0.248824 reg=0.014317
2017/08/29 20:32:09 step 7: objective=0.249323 reg=0.014308
2017/08/29 20:32:09 Training value function...
2017/08/29 20:32:15 step 0: mse=1.210468 step=0.050000
2017/08/29 20:32:19 step 1: mse=1.210637 step=0.050000
2017/08/29 20:32:22 step 2: mse=1.210813 step=0.050000
2017/08/29 20:32:26 step 3: mse=1.210988 step=0.050000
2017/08/29 20:32:29 step 4: mse=1.211167 step=0.050000
2017/08/29 20:32:33 step 5: mse=1.211338 step=0.050000
2017/08/29 20:32:36 step 6: mse=1.211491 step=0.050000
2017/08/29 20:32:40 step 7: mse=1.211640 step=0.050000
2017/08/29 20:32:40 Saving...
2017/08/29 20:32:40 Gathering batch of experience...
2017/08/29 20:33:10 batch 224: mean=5.388856 stddev=1.494675 entropy=1.425000 frames=100140 count=5007
2017/08/29 20:33:10 Training policy...
2017/08/29 20:33:24 step 0: objective=0.269745 reg=0.014250
2017/08/29 20:33:31 step 1: objective=0.270567 reg=0.014244
2017/08/29 20:33:39 step 2: objective=0.271321 reg=0.014240
2017/08/29 20:33:46 step 3: objective=0.271856 reg=0.014235
2017/08/29 20:33:52 step 4: objective=0.272390 reg=0.014228
2017/08/29 20:34:00 step 5: objective=0.272937 reg=0.014231
2017/08/29 20:34:07 step 6: objective=0.273480 reg=0.014233
2017/08/29 20:34:14 step 7: objective=0.273972 reg=0.014234
2017/08/29 20:34:14 Training value function...
2017/08/29 20:34:20 step 0: mse=1.235155 step=0.050000
2017/08/29 20:34:23 step 1: mse=1.233669 step=0.050000
2017/08/29 20:34:27 step 2: mse=1.232286 step=0.050000
2017/08/29 20:34:30 step 3: mse=1.230998 step=0.050000
2017/08/29 20:34:34 step 4: mse=1.229816 step=0.050000
2017/08/29 20:34:37 step 5: mse=1.228684 step=0.050000
2017/08/29 20:34:41 step 6: mse=1.227646 step=0.050000
2017/08/29 20:34:44 step 7: mse=1.226649 step=0.050000
2017/08/29 20:34:44 Saving...
2017/08/29 20:34:44 Gathering batch of experience...
2017/08/29 20:35:15 batch 225: mean=5.357300 stddev=1.467427 entropy=1.425652 frames=100140 count=5007
2017/08/29 20:35:15 Training policy...
2017/08/29 20:35:29 step 0: objective=0.253524 reg=0.014256
2017/08/29 20:35:36 step 1: objective=0.254213 reg=0.014263
2017/08/29 20:35:44 step 2: objective=0.254893 reg=0.014258
2017/08/29 20:35:51 step 3: objective=0.255636 reg=0.014258
2017/08/29 20:35:58 step 4: objective=0.256285 reg=0.014246
2017/08/29 20:36:05 step 5: objective=0.256623 reg=0.014252
2017/08/29 20:36:12 step 6: objective=0.257132 reg=0.014236
2017/08/29 20:36:19 step 7: objective=0.257635 reg=0.014234
2017/08/29 20:36:19 Training value function...
2017/08/29 20:36:25 step 0: mse=1.175186 step=0.050000
2017/08/29 20:36:29 step 1: mse=1.174709 step=0.050000
2017/08/29 20:36:32 step 2: mse=1.174274 step=0.050000
2017/08/29 20:36:36 step 3: mse=1.173869 step=0.050000
2017/08/29 20:36:39 step 4: mse=1.173495 step=0.050000
2017/08/29 20:36:43 step 5: mse=1.173144 step=0.050000
2017/08/29 20:36:46 step 6: mse=1.172785 step=0.050000
2017/08/29 20:36:50 step 7: mse=1.172444 step=0.050000
2017/08/29 20:36:50 Saving...
2017/08/29 20:36:50 Gathering batch of experience...
2017/08/29 20:37:20 batch 226: mean=5.351708 stddev=1.480695 entropy=1.426018 frames=100140 count=5007
2017/08/29 20:37:20 Training policy...
2017/08/29 20:37:35 step 0: objective=0.248893 reg=0.014260
2017/08/29 20:37:42 step 1: objective=0.249634 reg=0.014258
2017/08/29 20:37:49 step 2: objective=0.250380 reg=0.014256
2017/08/29 20:37:56 step 3: objective=0.250966 reg=0.014260
2017/08/29 20:38:03 step 4: objective=0.251407 reg=0.014251
2017/08/29 20:38:10 step 5: objective=0.251804 reg=0.014250
2017/08/29 20:38:17 step 6: objective=0.252370 reg=0.014247
2017/08/29 20:38:24 step 7: objective=0.252715 reg=0.014240
2017/08/29 20:38:24 Training value function...
2017/08/29 20:38:30 step 0: mse=1.156549 step=0.050000
2017/08/29 20:38:34 step 1: mse=1.156039 step=0.050000
2017/08/29 20:38:37 step 2: mse=1.155547 step=0.050000
2017/08/29 20:38:41 step 3: mse=1.155101 step=0.050000
2017/08/29 20:38:44 step 4: mse=1.154662 step=0.050000
2017/08/29 20:38:48 step 5: mse=1.154262 step=0.050000
2017/08/29 20:38:51 step 6: mse=1.153869 step=0.050000
2017/08/29 20:38:55 step 7: mse=1.153513 step=0.050000
2017/08/29 20:38:55 Saving...
2017/08/29 20:38:55 Gathering batch of experience...
2017/08/29 20:39:25 batch 227: mean=5.333733 stddev=1.451935 entropy=1.427798 frames=100140 count=5007
2017/08/29 20:39:25 Training policy...
2017/08/29 20:39:40 step 0: objective=0.245708 reg=0.014278
2017/08/29 20:39:47 step 1: objective=0.246309 reg=0.014274
2017/08/29 20:39:54 step 2: objective=0.247034 reg=0.014265
2017/08/29 20:40:01 step 3: objective=0.247656 reg=0.014250
2017/08/29 20:40:08 step 4: objective=0.248315 reg=0.014249
2017/08/29 20:40:16 step 5: objective=0.248888 reg=0.014249
2017/08/29 20:40:24 step 6: objective=0.249245 reg=0.014244
2017/08/29 20:40:31 step 7: objective=0.249541 reg=0.014249
2017/08/29 20:40:31 Training value function...
2017/08/29 20:40:37 step 0: mse=1.141613 step=0.050000
2017/08/29 20:40:40 step 1: mse=1.141594 step=0.050000
2017/08/29 20:40:44 step 2: mse=1.141594 step=0.050000
2017/08/29 20:40:47 step 3: mse=1.141602 step=0.050000
2017/08/29 20:40:51 step 4: mse=1.141613 step=0.050000
2017/08/29 20:40:54 step 5: mse=1.141655 step=0.050000
2017/08/29 20:40:58 step 6: mse=1.141666 step=0.050000
2017/08/29 20:41:01 step 7: mse=1.141702 step=0.050000
2017/08/29 20:41:01 Saving...
2017/08/29 20:41:01 Gathering batch of experience...
2017/08/29 20:41:32 batch 228: mean=5.384661 stddev=1.450270 entropy=1.420981 frames=100140 count=5007
2017/08/29 20:41:32 Training policy...
2017/08/29 20:41:46 step 0: objective=0.261061 reg=0.014210
2017/08/29 20:41:53 step 1: objective=0.261706 reg=0.014206
2017/08/29 20:42:00 step 2: objective=0.262100 reg=0.014220
2017/08/29 20:42:08 step 3: objective=0.262678 reg=0.014220
2017/08/29 20:42:15 step 4: objective=0.263234 reg=0.014219
2017/08/29 20:42:22 step 5: objective=0.263720 reg=0.014224
2017/08/29 20:42:29 step 6: objective=0.264319 reg=0.014217
2017/08/29 20:42:36 step 7: objective=0.264722 reg=0.014214
2017/08/29 20:42:36 Training value function...
2017/08/29 20:42:42 step 0: mse=1.155260 step=0.050000
2017/08/29 20:42:45 step 1: mse=1.153913 step=0.050000
2017/08/29 20:42:49 step 2: mse=1.152659 step=0.050000
2017/08/29 20:42:52 step 3: mse=1.151435 step=0.050000
2017/08/29 20:42:56 step 4: mse=1.150336 step=0.050000
2017/08/29 20:42:59 step 5: mse=1.149263 step=0.050000
2017/08/29 20:43:03 step 6: mse=1.148296 step=0.050000
2017/08/29 20:43:06 step 7: mse=1.147353 step=0.050000
2017/08/29 20:43:06 Saving...
2017/08/29 20:43:06 Gathering batch of experience...
2017/08/29 20:43:37 batch 229: mean=5.341322 stddev=1.486621 entropy=1.420105 frames=100140 count=5007
2017/08/29 20:43:37 Training policy...
2017/08/29 20:43:51 step 0: objective=0.247180 reg=0.014201
2017/08/29 20:43:58 step 1: objective=0.247890 reg=0.014201
2017/08/29 20:44:05 step 2: objective=0.248452 reg=0.014198
2017/08/29 20:44:12 step 3: objective=0.248881 reg=0.014185
2017/08/29 20:44:19 step 4: objective=0.249272 reg=0.014193
2017/08/29 20:44:26 step 5: objective=0.249677 reg=0.014172
2017/08/29 20:44:34 step 6: objective=0.249823 reg=0.014197
2017/08/29 20:44:41 step 7: objective=0.250182 reg=0.014183
2017/08/29 20:44:41 Training value function...
2017/08/29 20:44:47 step 0: mse=1.152138 step=0.050000
2017/08/29 20:44:50 step 1: mse=1.151885 step=0.050000
2017/08/29 20:44:54 step 2: mse=1.151662 step=0.050000
2017/08/29 20:44:57 step 3: mse=1.151461 step=0.050000
2017/08/29 20:45:01 step 4: mse=1.151283 step=0.050000
2017/08/29 20:45:04 step 5: mse=1.151106 step=0.050000
2017/08/29 20:45:08 step 6: mse=1.150947 step=0.050000
2017/08/29 20:45:11 step 7: mse=1.150782 step=0.050000
2017/08/29 20:45:11 Saving...
2017/08/29 20:45:11 Gathering batch of experience...
2017/08/29 20:45:42 batch 230: mean=5.363291 stddev=1.491483 entropy=1.417295 frames=100140 count=5007
2017/08/29 20:45:42 Training policy...
2017/08/29 20:45:56 step 0: objective=0.245550 reg=0.014173
2017/08/29 20:46:03 step 1: objective=0.246405 reg=0.014172
2017/08/29 20:46:11 step 2: objective=0.247214 reg=0.014168
2017/08/29 20:46:19 step 3: objective=0.247701 reg=0.014163
2017/08/29 20:46:26 step 4: objective=0.248132 reg=0.014155
2017/08/29 20:46:33 step 5: objective=0.248664 reg=0.014161
2017/08/29 20:46:40 step 6: objective=0.249147 reg=0.014151
2017/08/29 20:46:48 step 7: objective=0.249623 reg=0.014145
2017/08/29 20:46:48 Training value function...
2017/08/29 20:46:54 step 0: mse=1.153434 step=0.050000
2017/08/29 20:46:57 step 1: mse=1.153511 step=0.050000
2017/08/29 20:47:01 step 2: mse=1.153593 step=0.050000
2017/08/29 20:47:04 step 3: mse=1.153642 step=0.050000
2017/08/29 20:47:08 step 4: mse=1.153694 step=0.050000
2017/08/29 20:47:11 step 5: mse=1.153733 step=0.050000
2017/08/29 20:47:15 step 6: mse=1.153780 step=0.050000
2017/08/29 20:47:18 step 7: mse=1.153816 step=0.050000
2017/08/29 20:47:18 Saving...
2017/08/29 20:47:18 Gathering batch of experience...
2017/08/29 20:47:49 batch 231: mean=5.386858 stddev=1.463466 entropy=1.414936 frames=100140 count=5007
2017/08/29 20:47:49 Training policy...
2017/08/29 20:48:03 step 0: objective=0.248170 reg=0.014149
2017/08/29 20:48:10 step 1: objective=0.249056 reg=0.014148
2017/08/29 20:48:17 step 2: objective=0.249769 reg=0.014145
2017/08/29 20:48:25 step 3: objective=0.250308 reg=0.014138
2017/08/29 20:48:32 step 4: objective=0.250954 reg=0.014123
2017/08/29 20:48:39 step 5: objective=0.251393 reg=0.014130
2017/08/29 20:48:46 step 6: objective=0.251866 reg=0.014124
2017/08/29 20:48:53 step 7: objective=0.252251 reg=0.014120
2017/08/29 20:48:53 Training value function...
2017/08/29 20:49:00 step 0: mse=1.173700 step=0.050000
2017/08/29 20:49:03 step 1: mse=1.173676 step=0.050000
2017/08/29 20:49:06 step 2: mse=1.173665 step=0.050000
2017/08/29 20:49:10 step 3: mse=1.173657 step=0.050000
2017/08/29 20:49:13 step 4: mse=1.173662 step=0.050000
2017/08/29 20:49:17 step 5: mse=1.173669 step=0.050000
2017/08/29 20:49:20 step 6: mse=1.173673 step=0.050000
2017/08/29 20:49:24 step 7: mse=1.173676 step=0.050000
2017/08/29 20:49:24 Saving...
2017/08/29 20:49:24 Gathering batch of experience...
2017/08/29 20:49:54 batch 232: mean=5.370481 stddev=1.455124 entropy=1.411614 frames=100140 count=5007
2017/08/29 20:49:54 Training policy...
2017/08/29 20:50:10 step 0: objective=0.253245 reg=0.014116
2017/08/29 20:50:17 step 1: objective=0.253884 reg=0.014120
2017/08/29 20:50:25 step 2: objective=0.254529 reg=0.014114
2017/08/29 20:50:32 step 3: objective=0.255056 reg=0.014115
2017/08/29 20:50:39 step 4: objective=0.255612 reg=0.014118
2017/08/29 20:50:46 step 5: objective=0.256106 reg=0.014112
2017/08/29 20:50:54 step 6: objective=0.256562 reg=0.014098
2017/08/29 20:51:01 step 7: objective=0.256754 reg=0.014112
2017/08/29 20:51:01 Training value function...
2017/08/29 20:51:07 step 0: mse=1.120563 step=0.050000
2017/08/29 20:51:10 step 1: mse=1.119814 step=0.050000
2017/08/29 20:51:14 step 2: mse=1.119123 step=0.050000
2017/08/29 20:51:17 step 3: mse=1.118459 step=0.050000
2017/08/29 20:51:21 step 4: mse=1.117852 step=0.050000
2017/08/29 20:51:24 step 5: mse=1.117291 step=0.050000
2017/08/29 20:51:28 step 6: mse=1.116733 step=0.050000
2017/08/29 20:51:31 step 7: mse=1.116230 step=0.050000
2017/08/29 20:51:31 Saving...
2017/08/29 20:51:31 Gathering batch of experience...
2017/08/29 20:52:02 batch 233: mean=5.391252 stddev=1.467070 entropy=1.409779 frames=100140 count=5007
2017/08/29 20:52:02 Training policy...
2017/08/29 20:52:17 step 0: objective=0.264173 reg=0.014098
2017/08/29 20:52:24 step 1: objective=0.265034 reg=0.014092
2017/08/29 20:52:31 step 2: objective=0.265702 reg=0.014091
2017/08/29 20:52:38 step 3: objective=0.266301 reg=0.014085
2017/08/29 20:52:46 step 4: objective=0.266802 reg=0.014084
2017/08/29 20:52:53 step 5: objective=0.267145 reg=0.014076
2017/08/29 20:53:00 step 6: objective=0.267327 reg=0.014094
2017/08/29 20:53:07 step 7: objective=0.267717 reg=0.014072
2017/08/29 20:53:07 Training value function...
2017/08/29 20:53:13 step 0: mse=1.184644 step=0.050000
2017/08/29 20:53:17 step 1: mse=1.183627 step=0.050000
2017/08/29 20:53:20 step 2: mse=1.182688 step=0.050000
2017/08/29 20:53:24 step 3: mse=1.181810 step=0.050000
2017/08/29 20:53:27 step 4: mse=1.180984 step=0.050000
2017/08/29 20:53:31 step 5: mse=1.180210 step=0.050000
2017/08/29 20:53:34 step 6: mse=1.179484 step=0.050000
2017/08/29 20:53:38 step 7: mse=1.178803 step=0.050000
2017/08/29 20:53:38 Saving...
2017/08/29 20:53:38 Gathering batch of experience...
2017/08/29 20:54:08 batch 234: mean=5.379469 stddev=1.457131 entropy=1.410166 frames=100140 count=5007
2017/08/29 20:54:08 Training policy...
2017/08/29 20:54:23 step 0: objective=0.246498 reg=0.014102
2017/08/29 20:54:30 step 1: objective=0.247211 reg=0.014097
2017/08/29 20:54:37 step 2: objective=0.247866 reg=0.014090
2017/08/29 20:54:44 step 3: objective=0.248318 reg=0.014093
2017/08/29 20:54:52 step 4: objective=0.248857 reg=0.014091
2017/08/29 20:54:59 step 5: objective=0.249413 reg=0.014089
2017/08/29 20:55:06 step 6: objective=0.249931 reg=0.014093
2017/08/29 20:55:14 step 7: objective=0.250308 reg=0.014090
2017/08/29 20:55:14 Training value function...
2017/08/29 20:55:20 step 0: mse=1.130826 step=0.050000
2017/08/29 20:55:24 step 1: mse=1.130685 step=0.050000
2017/08/29 20:55:27 step 2: mse=1.130548 step=0.050000
2017/08/29 20:55:31 step 3: mse=1.130418 step=0.050000
2017/08/29 20:55:34 step 4: mse=1.130302 step=0.050000
2017/08/29 20:55:38 step 5: mse=1.130187 step=0.050000
2017/08/29 20:55:41 step 6: mse=1.130077 step=0.050000
2017/08/29 20:55:45 step 7: mse=1.129950 step=0.050000
2017/08/29 20:55:45 Saving...
2017/08/29 20:55:45 Gathering batch of experience...
2017/08/29 20:56:15 batch 235: mean=5.374276 stddev=1.461072 entropy=1.406054 frames=100140 count=5007
2017/08/29 20:56:15 Training policy...
2017/08/29 20:56:30 step 0: objective=0.245891 reg=0.014061
2017/08/29 20:56:38 step 1: objective=0.246678 reg=0.014063
2017/08/29 20:56:46 step 2: objective=0.247208 reg=0.014065
2017/08/29 20:56:53 step 3: objective=0.247705 reg=0.014060
2017/08/29 20:57:00 step 4: objective=0.248251 reg=0.014057
2017/08/29 20:57:07 step 5: objective=0.248720 reg=0.014050
2017/08/29 20:57:15 step 6: objective=0.249170 reg=0.014048
2017/08/29 20:57:22 step 7: objective=0.249613 reg=0.014052
2017/08/29 20:57:22 Training value function...
2017/08/29 20:57:28 step 0: mse=1.148544 step=0.050000
2017/08/29 20:57:31 step 1: mse=1.148651 step=0.050000
2017/08/29 20:57:35 step 2: mse=1.148761 step=0.050000
2017/08/29 20:57:38 step 3: mse=1.148870 step=0.050000
2017/08/29 20:57:42 step 4: mse=1.148959 step=0.050000
2017/08/29 20:57:45 step 5: mse=1.149002 step=0.050000
2017/08/29 20:57:49 step 6: mse=1.149078 step=0.050000
2017/08/29 20:57:52 step 7: mse=1.149141 step=0.050000
2017/08/29 20:57:52 Saving...
2017/08/29 20:57:52 Gathering batch of experience...
2017/08/29 20:58:23 batch 236: mean=5.403435 stddev=1.463698 entropy=1.406397 frames=100140 count=5007
2017/08/29 20:58:23 Training policy...
2017/08/29 20:58:38 step 0: objective=0.256543 reg=0.014064
2017/08/29 20:58:46 step 1: objective=0.257309 reg=0.014068
2017/08/29 20:58:54 step 2: objective=0.257754 reg=0.014067
2017/08/29 20:59:01 step 3: objective=0.258091 reg=0.014080
2017/08/29 20:59:08 step 4: objective=0.258369 reg=0.014052
2017/08/29 20:59:15 step 5: objective=0.258587 reg=0.014087
2017/08/29 20:59:22 step 6: objective=0.259226 reg=0.014054
2017/08/29 20:59:30 step 7: objective=0.259450 reg=0.014085
2017/08/29 20:59:30 Training value function...
2017/08/29 20:59:36 step 0: mse=1.170182 step=0.050000
2017/08/29 20:59:39 step 1: mse=1.169405 step=0.050000
2017/08/29 20:59:43 step 2: mse=1.168680 step=0.050000
2017/08/29 20:59:46 step 3: mse=1.168003 step=0.050000
2017/08/29 20:59:50 step 4: mse=1.167367 step=0.050000
2017/08/29 20:59:53 step 5: mse=1.166771 step=0.050000
2017/08/29 20:59:57 step 6: mse=1.166206 step=0.050000
2017/08/29 21:00:00 step 7: mse=1.165689 step=0.050000
2017/08/29 21:00:00 Saving...
2017/08/29 21:00:00 Gathering batch of experience...
2017/08/29 21:00:31 batch 237: mean=5.369083 stddev=1.469749 entropy=1.405787 frames=100140 count=5007
2017/08/29 21:00:31 Training policy...
2017/08/29 21:00:46 step 0: objective=0.247533 reg=0.014058
2017/08/29 21:00:53 step 1: objective=0.248270 reg=0.014056
2017/08/29 21:01:00 step 2: objective=0.248900 reg=0.014045
2017/08/29 21:01:07 step 3: objective=0.249495 reg=0.014054
2017/08/29 21:01:14 step 4: objective=0.249952 reg=0.014044
2017/08/29 21:01:22 step 5: objective=0.250293 reg=0.014050
2017/08/29 21:01:29 step 6: objective=0.250747 reg=0.014054
2017/08/29 21:01:36 step 7: objective=0.251106 reg=0.014044
2017/08/29 21:01:36 Training value function...
2017/08/29 21:01:42 step 0: mse=1.164581 step=0.050000
2017/08/29 21:01:46 step 1: mse=1.164624 step=0.050000
2017/08/29 21:01:49 step 2: mse=1.164635 step=0.050000
2017/08/29 21:01:53 step 3: mse=1.164647 step=0.050000
2017/08/29 21:01:56 step 4: mse=1.164651 step=0.050000
2017/08/29 21:02:00 step 5: mse=1.164667 step=0.050000
2017/08/29 21:02:03 step 6: mse=1.164679 step=0.050000
2017/08/29 21:02:07 step 7: mse=1.164684 step=0.050000
2017/08/29 21:02:07 Saving...
2017/08/29 21:02:07 Gathering batch of experience...
2017/08/29 21:02:37 batch 238: mean=5.388057 stddev=1.475924 entropy=1.403764 frames=100140 count=5007
2017/08/29 21:02:37 Training policy...
2017/08/29 21:02:53 step 0: objective=0.255702 reg=0.014038
2017/08/29 21:03:00 step 1: objective=0.256565 reg=0.014040
2017/08/29 21:03:07 step 2: objective=0.257289 reg=0.014041
2017/08/29 21:03:15 step 3: objective=0.258004 reg=0.014037
2017/08/29 21:03:22 step 4: objective=0.258607 reg=0.014034
2017/08/29 21:03:29 step 5: objective=0.259021 reg=0.014032
2017/08/29 21:03:37 step 6: objective=0.259464 reg=0.014032
2017/08/29 21:03:44 step 7: objective=0.259918 reg=0.014027
2017/08/29 21:03:44 Training value function...
2017/08/29 21:03:50 step 0: mse=1.181136 step=0.050000
2017/08/29 21:03:53 step 1: mse=1.180565 step=0.050000
2017/08/29 21:03:57 step 2: mse=1.180040 step=0.050000
2017/08/29 21:04:00 step 3: mse=1.179531 step=0.050000
2017/08/29 21:04:04 step 4: mse=1.179065 step=0.050000
2017/08/29 21:04:07 step 5: mse=1.178597 step=0.050000
2017/08/29 21:04:11 step 6: mse=1.178159 step=0.050000
2017/08/29 21:04:14 step 7: mse=1.177745 step=0.050000
2017/08/29 21:04:14 Saving...
2017/08/29 21:04:14 Gathering batch of experience...
2017/08/29 21:04:45 batch 239: mean=5.406631 stddev=1.455148 entropy=1.402689 frames=100140 count=5007
2017/08/29 21:04:45 Training policy...
2017/08/29 21:05:00 step 0: objective=0.260183 reg=0.014027
2017/08/29 21:05:07 step 1: objective=0.261023 reg=0.014022
2017/08/29 21:05:15 step 2: objective=0.261761 reg=0.014017
2017/08/29 21:05:22 step 3: objective=0.262486 reg=0.014013
2017/08/29 21:05:30 step 4: objective=0.263026 reg=0.014015
2017/08/29 21:05:37 step 5: objective=0.263621 reg=0.014015
2017/08/29 21:05:44 step 6: objective=0.264071 reg=0.014007
2017/08/29 21:05:52 step 7: objective=0.264529 reg=0.014009
2017/08/29 21:05:52 Training value function...
2017/08/29 21:05:58 step 0: mse=1.200184 step=0.050000
2017/08/29 21:06:01 step 1: mse=1.199403 step=0.050000
2017/08/29 21:06:05 step 2: mse=1.198688 step=0.050000
2017/08/29 21:06:08 step 3: mse=1.197979 step=0.050000
2017/08/29 21:06:12 step 4: mse=1.197355 step=0.050000
2017/08/29 21:06:15 step 5: mse=1.196729 step=0.050000
2017/08/29 21:06:19 step 6: mse=1.196168 step=0.050000
2017/08/29 21:06:22 step 7: mse=1.195649 step=0.050000
2017/08/29 21:06:22 Saving...
2017/08/29 21:06:22 Gathering batch of experience...
2017/08/29 21:06:53 batch 240: mean=5.378870 stddev=1.464055 entropy=1.402077 frames=100140 count=5007
2017/08/29 21:06:53 Training policy...
2017/08/29 21:07:08 step 0: objective=0.244585 reg=0.014021
2017/08/29 21:07:15 step 1: objective=0.245333 reg=0.014028
2017/08/29 21:07:22 step 2: objective=0.245792 reg=0.014012
2017/08/29 21:07:30 step 3: objective=0.246079 reg=0.014028
2017/08/29 21:07:37 step 4: objective=0.246508 reg=0.014000
2017/08/29 21:07:44 step 5: objective=0.246691 reg=0.014031
2017/08/29 21:07:52 step 6: objective=0.247028 reg=0.014000
2017/08/29 21:07:59 step 7: objective=0.247314 reg=0.014032
2017/08/29 21:07:59 Training value function...
2017/08/29 21:08:05 step 0: mse=1.148831 step=0.050000
2017/08/29 21:08:09 step 1: mse=1.148753 step=0.050000
2017/08/29 21:08:12 step 2: mse=1.148698 step=0.050000
2017/08/29 21:08:16 step 3: mse=1.148656 step=0.050000
2017/08/29 21:08:19 step 4: mse=1.148624 step=0.050000
2017/08/29 21:08:23 step 5: mse=1.148601 step=0.050000
2017/08/29 21:08:26 step 6: mse=1.148585 step=0.050000
2017/08/29 21:08:30 step 7: mse=1.148573 step=0.050000
2017/08/29 21:08:30 Saving...
2017/08/29 21:08:30 Gathering batch of experience...
2017/08/29 21:09:00 batch 241: mean=5.358698 stddev=1.459101 entropy=1.398076 frames=100140 count=5007
2017/08/29 21:09:00 Training policy...
2017/08/29 21:09:16 step 0: objective=0.234925 reg=0.013981
2017/08/29 21:09:24 step 1: objective=0.235540 reg=0.013980
2017/08/29 21:09:31 step 2: objective=0.236135 reg=0.013978
2017/08/29 21:09:38 step 3: objective=0.236779 reg=0.013975
2017/08/29 21:09:47 step 4: objective=0.237357 reg=0.013973
2017/08/29 21:09:54 step 5: objective=0.237623 reg=0.013971
2017/08/29 21:10:01 step 6: objective=0.238045 reg=0.013963
2017/08/29 21:10:09 step 7: objective=0.238571 reg=0.013958
2017/08/29 21:10:09 Training value function...
2017/08/29 21:10:15 step 0: mse=1.132482 step=0.050000
2017/08/29 21:10:18 step 1: mse=1.132881 step=0.050000
2017/08/29 21:10:22 step 2: mse=1.133276 step=0.050000
2017/08/29 21:10:25 step 3: mse=1.133640 step=0.050000
2017/08/29 21:10:29 step 4: mse=1.133950 step=0.050000
2017/08/29 21:10:32 step 5: mse=1.134261 step=0.050000
2017/08/29 21:10:36 step 6: mse=1.134578 step=0.050000
2017/08/29 21:10:39 step 7: mse=1.134857 step=0.050000
2017/08/29 21:10:39 Saving...
2017/08/29 21:10:39 Gathering batch of experience...
2017/08/29 21:11:10 batch 242: mean=5.420811 stddev=1.456811 entropy=1.393550 frames=100140 count=5007
2017/08/29 21:11:10 Training policy...
2017/08/29 21:11:26 step 0: objective=0.269773 reg=0.013936
2017/08/29 21:11:33 step 1: objective=0.270389 reg=0.013935
2017/08/29 21:11:40 step 2: objective=0.270979 reg=0.013937
2017/08/29 21:11:48 step 3: objective=0.271470 reg=0.013932
2017/08/29 21:11:55 step 4: objective=0.271930 reg=0.013939
2017/08/29 21:12:03 step 5: objective=0.272386 reg=0.013929
2017/08/29 21:12:10 step 6: objective=0.272952 reg=0.013929
2017/08/29 21:12:17 step 7: objective=0.273398 reg=0.013925
2017/08/29 21:12:17 Training value function...
2017/08/29 21:12:23 step 0: mse=1.175993 step=0.050000
2017/08/29 21:12:27 step 1: mse=1.174356 step=0.050000
2017/08/29 21:12:30 step 2: mse=1.172834 step=0.050000
2017/08/29 21:12:34 step 3: mse=1.171414 step=0.050000
2017/08/29 21:12:37 step 4: mse=1.170088 step=0.050000
2017/08/29 21:12:41 step 5: mse=1.168837 step=0.050000
2017/08/29 21:12:44 step 6: mse=1.167665 step=0.050000
2017/08/29 21:12:48 step 7: mse=1.166528 step=0.050000
2017/08/29 21:12:48 Saving...
2017/08/29 21:12:48 Gathering batch of experience...
2017/08/29 21:13:19 batch 243: mean=5.402037 stddev=1.467830 entropy=1.395385 frames=100140 count=5007
2017/08/29 21:13:19 Training policy...
2017/08/29 21:13:33 step 0: objective=0.252656 reg=0.013954
2017/08/29 21:13:41 step 1: objective=0.253368 reg=0.013958
2017/08/29 21:13:48 step 2: objective=0.254009 reg=0.013951
2017/08/29 21:13:55 step 3: objective=0.254621 reg=0.013944
2017/08/29 21:14:03 step 4: objective=0.255173 reg=0.013942
2017/08/29 21:14:10 step 5: objective=0.255676 reg=0.013940
2017/08/29 21:14:17 step 6: objective=0.256139 reg=0.013938
2017/08/29 21:14:25 step 7: objective=0.256479 reg=0.013937
2017/08/29 21:14:25 Training value function...
2017/08/29 21:14:31 step 0: mse=1.177335 step=0.050000
2017/08/29 21:14:34 step 1: mse=1.177212 step=0.050000
2017/08/29 21:14:38 step 2: mse=1.177108 step=0.050000
2017/08/29 21:14:41 step 3: mse=1.177016 step=0.050000
2017/08/29 21:14:45 step 4: mse=1.176938 step=0.050000
2017/08/29 21:14:48 step 5: mse=1.176868 step=0.050000
2017/08/29 21:14:51 step 6: mse=1.176801 step=0.050000
2017/08/29 21:14:55 step 7: mse=1.176740 step=0.050000
2017/08/29 21:14:55 Saving...
2017/08/29 21:14:55 Gathering batch of experience...
2017/08/29 21:15:26 batch 244: mean=5.403835 stddev=1.479873 entropy=1.391145 frames=100140 count=5007
2017/08/29 21:15:26 Training policy...
2017/08/29 21:15:40 step 0: objective=0.254279 reg=0.013912
2017/08/29 21:15:48 step 1: objective=0.254910 reg=0.013915
2017/08/29 21:15:55 step 2: objective=0.255607 reg=0.013918
2017/08/29 21:16:02 step 3: objective=0.256168 reg=0.013916
2017/08/29 21:16:10 step 4: objective=0.256609 reg=0.013907
2017/08/29 21:16:17 step 5: objective=0.257044 reg=0.013905
2017/08/29 21:16:25 step 6: objective=0.257344 reg=0.013908
2017/08/29 21:16:32 step 7: objective=0.257932 reg=0.013907
2017/08/29 21:16:32 Training value function...
2017/08/29 21:16:38 step 0: mse=1.167907 step=0.050000
2017/08/29 21:16:41 step 1: mse=1.167148 step=0.050000
2017/08/29 21:16:45 step 2: mse=1.166451 step=0.050000
2017/08/29 21:16:48 step 3: mse=1.165797 step=0.050000
2017/08/29 21:16:52 step 4: mse=1.165198 step=0.050000
2017/08/29 21:16:55 step 5: mse=1.164633 step=0.050000
2017/08/29 21:16:59 step 6: mse=1.164111 step=0.050000
2017/08/29 21:17:02 step 7: mse=1.163615 step=0.050000
2017/08/29 21:17:02 Saving...
2017/08/29 21:17:03 Gathering batch of experience...
2017/08/29 21:17:33 batch 245: mean=5.394448 stddev=1.454040 entropy=1.391963 frames=100140 count=5007
2017/08/29 21:17:33 Training policy...
2017/08/29 21:17:48 step 0: objective=0.243737 reg=0.013920
2017/08/29 21:17:56 step 1: objective=0.244671 reg=0.013917
2017/08/29 21:18:03 step 2: objective=0.245399 reg=0.013920
2017/08/29 21:18:11 step 3: objective=0.246017 reg=0.013920
2017/08/29 21:18:18 step 4: objective=0.246543 reg=0.013916
2017/08/29 21:18:26 step 5: objective=0.246978 reg=0.013916
2017/08/29 21:18:34 step 6: objective=0.247336 reg=0.013909
2017/08/29 21:18:41 step 7: objective=0.247439 reg=0.013921
2017/08/29 21:18:41 Training value function...
2017/08/29 21:18:47 step 0: mse=1.145824 step=0.050000
2017/08/29 21:18:50 step 1: mse=1.146188 step=0.050000
2017/08/29 21:18:54 step 2: mse=1.146539 step=0.050000
2017/08/29 21:18:57 step 3: mse=1.146879 step=0.050000
2017/08/29 21:19:01 step 4: mse=1.147172 step=0.050000
2017/08/29 21:19:04 step 5: mse=1.147449 step=0.050000
2017/08/29 21:19:08 step 6: mse=1.147714 step=0.050000
2017/08/29 21:19:12 step 7: mse=1.147930 step=0.050000
2017/08/29 21:19:12 Saving...
2017/08/29 21:19:12 Gathering batch of experience...
2017/08/29 21:19:42 batch 246: mean=5.373877 stddev=1.434830 entropy=1.390232 frames=100140 count=5007
2017/08/29 21:19:42 Training policy...
2017/08/29 21:19:58 step 0: objective=0.249032 reg=0.013902
2017/08/29 21:20:05 step 1: objective=0.249711 reg=0.013907
2017/08/29 21:20:13 step 2: objective=0.250397 reg=0.013907
2017/08/29 21:20:21 step 3: objective=0.250953 reg=0.013898
2017/08/29 21:20:28 step 4: objective=0.251440 reg=0.013901
2017/08/29 21:20:35 step 5: objective=0.251930 reg=0.013898
2017/08/29 21:20:43 step 6: objective=0.252387 reg=0.013899
2017/08/29 21:20:50 step 7: objective=0.252865 reg=0.013897
2017/08/29 21:20:50 Training value function...
2017/08/29 21:20:56 step 0: mse=1.108661 step=0.050000
2017/08/29 21:21:00 step 1: mse=1.108192 step=0.050000
2017/08/29 21:21:03 step 2: mse=1.107768 step=0.050000
2017/08/29 21:21:07 step 3: mse=1.107381 step=0.050000
2017/08/29 21:21:10 step 4: mse=1.107039 step=0.050000
2017/08/29 21:21:14 step 5: mse=1.106725 step=0.050000
2017/08/29 21:21:17 step 6: mse=1.106432 step=0.050000
2017/08/29 21:21:21 step 7: mse=1.106160 step=0.050000
2017/08/29 21:21:21 Saving...
2017/08/29 21:21:21 Gathering batch of experience...
2017/08/29 21:21:52 batch 247: mean=5.383863 stddev=1.422115 entropy=1.389611 frames=100140 count=5007
2017/08/29 21:21:52 Training policy...
2017/08/29 21:22:07 step 0: objective=0.245319 reg=0.013896
2017/08/29 21:22:14 step 1: objective=0.245938 reg=0.013895
2017/08/29 21:22:22 step 2: objective=0.246442 reg=0.013892
2017/08/29 21:22:29 step 3: objective=0.247003 reg=0.013881
2017/08/29 21:22:36 step 4: objective=0.247489 reg=0.013884
2017/08/29 21:22:44 step 5: objective=0.247944 reg=0.013882
2017/08/29 21:22:51 step 6: objective=0.248358 reg=0.013877
2017/08/29 21:22:59 step 7: objective=0.248797 reg=0.013879
2017/08/29 21:22:59 Training value function...
2017/08/29 21:23:05 step 0: mse=1.107842 step=0.050000
2017/08/29 21:23:09 step 1: mse=1.107841 step=0.050000
2017/08/29 21:23:12 step 2: mse=1.107850 step=0.050000
2017/08/29 21:23:16 step 3: mse=1.107877 step=0.050000
2017/08/29 21:23:19 step 4: mse=1.107899 step=0.050000
2017/08/29 21:23:22 step 5: mse=1.107911 step=0.050000
2017/08/29 21:23:26 step 6: mse=1.107912 step=0.050000
2017/08/29 21:23:29 step 7: mse=1.107898 step=0.050000
2017/08/29 21:23:29 Saving...
2017/08/29 21:23:29 Gathering batch of experience...
2017/08/29 21:24:00 batch 248: mean=5.439585 stddev=1.442284 entropy=1.389004 frames=100140 count=5007
2017/08/29 21:24:00 Training policy...
2017/08/29 21:24:15 step 0: objective=0.253754 reg=0.013890
2017/08/29 21:24:23 step 1: objective=0.254555 reg=0.013881
2017/08/29 21:24:30 step 2: objective=0.255084 reg=0.013885
2017/08/29 21:24:39 step 3: objective=0.255798 reg=0.013883
2017/08/29 21:24:46 step 4: objective=0.256244 reg=0.013875
2017/08/29 21:24:54 step 5: objective=0.256723 reg=0.013880
2017/08/29 21:25:01 step 6: objective=0.257141 reg=0.013876
2017/08/29 21:25:09 step 7: objective=0.257586 reg=0.013872
2017/08/29 21:25:09 Training value function...
2017/08/29 21:25:15 step 0: mse=1.146856 step=0.050000
2017/08/29 21:25:18 step 1: mse=1.146289 step=0.050000
2017/08/29 21:25:22 step 2: mse=1.145754 step=0.050000
2017/08/29 21:25:25 step 3: mse=1.145273 step=0.050000
2017/08/29 21:25:29 step 4: mse=1.144819 step=0.050000
2017/08/29 21:25:32 step 5: mse=1.144401 step=0.050000
2017/08/29 21:25:36 step 6: mse=1.144012 step=0.050000
2017/08/29 21:25:39 step 7: mse=1.143645 step=0.050000
2017/08/29 21:25:39 Saving...
2017/08/29 21:25:39 Gathering batch of experience...
2017/08/29 21:26:10 batch 249: mean=5.393449 stddev=1.456575 entropy=1.383296 frames=100140 count=5007
2017/08/29 21:26:10 Training policy...
2017/08/29 21:26:25 step 0: objective=0.241159 reg=0.013833
2017/08/29 21:26:32 step 1: objective=0.241734 reg=0.013824
2017/08/29 21:26:40 step 2: objective=0.242268 reg=0.013829
2017/08/29 21:26:47 step 3: objective=0.242707 reg=0.013821
2017/08/29 21:26:55 step 4: objective=0.243058 reg=0.013820
2017/08/29 21:27:02 step 5: objective=0.243386 reg=0.013805
2017/08/29 21:27:09 step 6: objective=0.243571 reg=0.013826
2017/08/29 21:27:17 step 7: objective=0.243976 reg=0.013807
2017/08/29 21:27:17 Training value function...
2017/08/29 21:27:23 step 0: mse=1.135668 step=0.050000
2017/08/29 21:27:26 step 1: mse=1.136106 step=0.050000
2017/08/29 21:27:30 step 2: mse=1.136519 step=0.050000
2017/08/29 21:27:33 step 3: mse=1.136935 step=0.050000
2017/08/29 21:27:37 step 4: mse=1.137315 step=0.050000
2017/08/29 21:27:40 step 5: mse=1.137680 step=0.050000
2017/08/29 21:27:44 step 6: mse=1.138026 step=0.050000
2017/08/29 21:27:47 step 7: mse=1.138356 step=0.050000
2017/08/29 21:27:47 Saving...
2017/08/29 21:27:47 Gathering batch of experience...
2017/08/29 21:28:18 batch 250: mean=5.397843 stddev=1.469176 entropy=1.384989 frames=100140 count=5007
2017/08/29 21:28:18 Training policy...
2017/08/29 21:28:33 step 0: objective=0.267091 reg=0.013850
2017/08/29 21:28:41 step 1: objective=0.267765 reg=0.013857
2017/08/29 21:28:48 step 2: objective=0.268412 reg=0.013860
2017/08/29 21:28:55 step 3: objective=0.268981 reg=0.013854
2017/08/29 21:29:03 step 4: objective=0.269579 reg=0.013851
2017/08/29 21:29:11 step 5: objective=0.270095 reg=0.013849
2017/08/29 21:29:19 step 6: objective=0.270442 reg=0.013844
2017/08/29 21:29:26 step 7: objective=0.270947 reg=0.013841
2017/08/29 21:29:26 Training value function...
2017/08/29 21:29:32 step 0: mse=1.177538 step=0.050000
2017/08/29 21:29:36 step 1: mse=1.175953 step=0.050000
2017/08/29 21:29:39 step 2: mse=1.174496 step=0.050000
2017/08/29 21:29:43 step 3: mse=1.173113 step=0.050000
2017/08/29 21:29:46 step 4: mse=1.171835 step=0.050000
2017/08/29 21:29:50 step 5: mse=1.170620 step=0.050000
2017/08/29 21:29:53 step 6: mse=1.169497 step=0.050000
2017/08/29 21:29:56 step 7: mse=1.168427 step=0.050000
2017/08/29 21:29:56 Saving...
2017/08/29 21:29:57 Gathering batch of experience...
2017/08/29 21:30:28 batch 251: mean=5.413421 stddev=1.466367 entropy=1.384076 frames=100140 count=5007
2017/08/29 21:30:28 Training policy...
2017/08/29 21:30:42 step 0: objective=0.256876 reg=0.013841
2017/08/29 21:30:50 step 1: objective=0.257610 reg=0.013831
2017/08/29 21:30:57 step 2: objective=0.258325 reg=0.013830
2017/08/29 21:31:05 step 3: objective=0.258930 reg=0.013831
2017/08/29 21:31:13 step 4: objective=0.259613 reg=0.013829
2017/08/29 21:31:20 step 5: objective=0.260136 reg=0.013828
2017/08/29 21:31:28 step 6: objective=0.260679 reg=0.013824
2017/08/29 21:31:35 step 7: objective=0.261109 reg=0.013823
2017/08/29 21:31:35 Training value function...
2017/08/29 21:31:41 step 0: mse=1.170092 step=0.050000
2017/08/29 21:31:45 step 1: mse=1.169520 step=0.050000
2017/08/29 21:31:48 step 2: mse=1.168999 step=0.050000
2017/08/29 21:31:52 step 3: mse=1.168524 step=0.050000
2017/08/29 21:31:55 step 4: mse=1.168082 step=0.050000
2017/08/29 21:31:59 step 5: mse=1.167677 step=0.050000
2017/08/29 21:32:02 step 6: mse=1.167301 step=0.050000
2017/08/29 21:32:06 step 7: mse=1.166948 step=0.050000
2017/08/29 21:32:06 Saving...
2017/08/29 21:32:06 Gathering batch of experience...
2017/08/29 21:32:37 batch 252: mean=5.409826 stddev=1.481464 entropy=1.376699 frames=100140 count=5007
2017/08/29 21:32:37 Training policy...
2017/08/29 21:32:52 step 0: objective=0.257947 reg=0.013767
2017/08/29 21:32:59 step 1: objective=0.258730 reg=0.013764
2017/08/29 21:33:07 step 2: objective=0.259412 reg=0.013762
2017/08/29 21:33:14 step 3: objective=0.259825 reg=0.013759
2017/08/29 21:33:22 step 4: objective=0.260247 reg=0.013768
2017/08/29 21:33:29 step 5: objective=0.260658 reg=0.013756
2017/08/29 21:33:37 step 6: objective=0.261188 reg=0.013763
2017/08/29 21:33:44 step 7: objective=0.261645 reg=0.013761
2017/08/29 21:33:44 Training value function...
2017/08/29 21:33:51 step 0: mse=1.169333 step=0.050000
2017/08/29 21:33:54 step 1: mse=1.168735 step=0.050000
2017/08/29 21:33:58 step 2: mse=1.168183 step=0.050000
2017/08/29 21:34:01 step 3: mse=1.167671 step=0.050000
2017/08/29 21:34:05 step 4: mse=1.167184 step=0.050000
2017/08/29 21:34:08 step 5: mse=1.166744 step=0.050000
2017/08/29 21:34:12 step 6: mse=1.166313 step=0.050000
2017/08/29 21:34:15 step 7: mse=1.165921 step=0.050000
2017/08/29 21:34:15 Saving...
2017/08/29 21:34:15 Gathering batch of experience...
2017/08/29 21:34:46 batch 253: mean=5.393449 stddev=1.463005 entropy=1.381647 frames=100140 count=5007
2017/08/29 21:34:46 Training policy...
2017/08/29 21:35:01 step 0: objective=0.245624 reg=0.013816
2017/08/29 21:35:09 step 1: objective=0.246375 reg=0.013811
2017/08/29 21:35:17 step 2: objective=0.246925 reg=0.013813
2017/08/29 21:35:25 step 3: objective=0.247415 reg=0.013813
2017/08/29 21:35:32 step 4: objective=0.248018 reg=0.013808
2017/08/29 21:35:40 step 5: objective=0.248413 reg=0.013808
2017/08/29 21:35:48 step 6: objective=0.248879 reg=0.013803
2017/08/29 21:35:55 step 7: objective=0.249198 reg=0.013801
2017/08/29 21:35:55 Training value function...
2017/08/29 21:36:01 step 0: mse=1.140490 step=0.050000
2017/08/29 21:36:05 step 1: mse=1.140323 step=0.050000
2017/08/29 21:36:08 step 2: mse=1.140177 step=0.050000
2017/08/29 21:36:12 step 3: mse=1.140068 step=0.050000
2017/08/29 21:36:15 step 4: mse=1.139938 step=0.050000
2017/08/29 21:36:19 step 5: mse=1.139841 step=0.050000
2017/08/29 21:36:22 step 6: mse=1.139748 step=0.050000
2017/08/29 21:36:26 step 7: mse=1.139634 step=0.050000
2017/08/29 21:36:26 Saving...
2017/08/29 21:36:26 Gathering batch of experience...
2017/08/29 21:36:57 batch 254: mean=5.380068 stddev=1.458550 entropy=1.382724 frames=100140 count=5007
2017/08/29 21:36:57 Training policy...
2017/08/29 21:37:12 step 0: objective=0.238826 reg=0.013827
2017/08/29 21:37:19 step 1: objective=0.239505 reg=0.013830
2017/08/29 21:37:27 step 2: objective=0.240123 reg=0.013833
2017/08/29 21:37:34 step 3: objective=0.240779 reg=0.013834
2017/08/29 21:37:42 step 4: objective=0.241282 reg=0.013828
2017/08/29 21:37:49 step 5: objective=0.241608 reg=0.013830
2017/08/29 21:37:57 step 6: objective=0.242078 reg=0.013829
2017/08/29 21:38:04 step 7: objective=0.242546 reg=0.013826
2017/08/29 21:38:04 Training value function...
2017/08/29 21:38:10 step 0: mse=1.138642 step=0.050000
2017/08/29 21:38:14 step 1: mse=1.139207 step=0.050000
2017/08/29 21:38:17 step 2: mse=1.139769 step=0.050000
2017/08/29 21:38:21 step 3: mse=1.140321 step=0.050000
2017/08/29 21:38:24 step 4: mse=1.140859 step=0.050000
2017/08/29 21:38:28 step 5: mse=1.141375 step=0.050000
2017/08/29 21:38:31 step 6: mse=1.141863 step=0.050000
2017/08/29 21:38:35 step 7: mse=1.142326 step=0.050000
2017/08/29 21:38:35 Saving...
2017/08/29 21:38:35 Gathering batch of experience...
2017/08/29 21:39:06 batch 255: mean=5.405632 stddev=1.451510 entropy=1.379102 frames=100140 count=5007
2017/08/29 21:39:06 Training policy...
2017/08/29 21:39:21 step 0: objective=0.243934 reg=0.013791
2017/08/29 21:39:28 step 1: objective=0.244621 reg=0.013791
2017/08/29 21:39:36 step 2: objective=0.245252 reg=0.013789
2017/08/29 21:39:44 step 3: objective=0.245903 reg=0.013785
2017/08/29 21:39:51 step 4: objective=0.246396 reg=0.013787
2017/08/29 21:39:59 step 5: objective=0.246942 reg=0.013784
2017/08/29 21:40:07 step 6: objective=0.247495 reg=0.013783
2017/08/29 21:40:15 step 7: objective=0.247940 reg=0.013778
2017/08/29 21:40:15 Training value function...
2017/08/29 21:40:21 step 0: mse=1.148462 step=0.050000
2017/08/29 21:40:24 step 1: mse=1.148618 step=0.050000
2017/08/29 21:40:28 step 2: mse=1.148716 step=0.050000
2017/08/29 21:40:31 step 3: mse=1.148866 step=0.050000
2017/08/29 21:40:35 step 4: mse=1.148984 step=0.050000
2017/08/29 21:40:38 step 5: mse=1.149069 step=0.050000
2017/08/29 21:40:42 step 6: mse=1.149175 step=0.050000
2017/08/29 21:40:45 step 7: mse=1.149252 step=0.050000
2017/08/29 21:40:45 Saving...
2017/08/29 21:40:45 Gathering batch of experience...
2017/08/29 21:41:17 batch 256: mean=5.395247 stddev=1.492730 entropy=1.375111 frames=100140 count=5007
2017/08/29 21:41:17 Training policy...
2017/08/29 21:41:32 step 0: objective=0.260476 reg=0.013751
2017/08/29 21:41:40 step 1: objective=0.261108 reg=0.013747
2017/08/29 21:41:47 step 2: objective=0.261891 reg=0.013749
2017/08/29 21:41:55 step 3: objective=0.262411 reg=0.013746
2017/08/29 21:42:03 step 4: objective=0.263017 reg=0.013743
2017/08/29 21:42:10 step 5: objective=0.263458 reg=0.013739
2017/08/29 21:42:18 step 6: objective=0.263913 reg=0.013745
2017/08/29 21:42:26 step 7: objective=0.264278 reg=0.013747
2017/08/29 21:42:26 Training value function...
2017/08/29 21:42:32 step 0: mse=1.179195 step=0.050000
2017/08/29 21:42:35 step 1: mse=1.178246 step=0.050000
2017/08/29 21:42:38 step 2: mse=1.177363 step=0.050000
2017/08/29 21:42:42 step 3: mse=1.176539 step=0.050000
2017/08/29 21:42:45 step 4: mse=1.175771 step=0.050000
2017/08/29 21:42:49 step 5: mse=1.175049 step=0.050000
2017/08/29 21:42:52 step 6: mse=1.174370 step=0.050000
2017/08/29 21:42:56 step 7: mse=1.173729 step=0.050000
2017/08/29 21:42:56 Saving...
2017/08/29 21:42:56 Gathering batch of experience...
2017/08/29 21:43:27 batch 257: mean=5.378071 stddev=1.452209 entropy=1.375755 frames=100140 count=5007
2017/08/29 21:43:27 Training policy...
2017/08/29 21:43:42 step 0: objective=0.240502 reg=0.013758
2017/08/29 21:43:50 step 1: objective=0.241138 reg=0.013764
2017/08/29 21:43:57 step 2: objective=0.241641 reg=0.013752
2017/08/29 21:44:05 step 3: objective=0.241838 reg=0.013765
2017/08/29 21:44:13 step 4: objective=0.242443 reg=0.013746
2017/08/29 21:44:21 step 5: objective=0.242764 reg=0.013758
2017/08/29 21:44:28 step 6: objective=0.243326 reg=0.013741
2017/08/29 21:44:36 step 7: objective=0.243578 reg=0.013758
2017/08/29 21:44:36 Training value function...
2017/08/29 21:44:42 step 0: mse=1.151724 step=0.050000
2017/08/29 21:44:46 step 1: mse=1.152069 step=0.050000
2017/08/29 21:44:49 step 2: mse=1.152409 step=0.050000
2017/08/29 21:44:52 step 3: mse=1.152733 step=0.050000
2017/08/29 21:44:56 step 4: mse=1.153054 step=0.050000
2017/08/29 21:44:59 step 5: mse=1.153364 step=0.050000
2017/08/29 21:45:03 step 6: mse=1.153663 step=0.050000
2017/08/29 21:45:06 step 7: mse=1.153945 step=0.050000
2017/08/29 21:45:06 Saving...
2017/08/29 21:45:07 Gathering batch of experience...
2017/08/29 21:45:38 batch 258: mean=5.412622 stddev=1.496519 entropy=1.369018 frames=100140 count=5007
2017/08/29 21:45:38 Training policy...
2017/08/29 21:45:53 step 0: objective=0.267587 reg=0.013690
2017/08/29 21:46:00 step 1: objective=0.268251 reg=0.013684
2017/08/29 21:46:08 step 2: objective=0.268764 reg=0.013685
2017/08/29 21:46:16 step 3: objective=0.269510 reg=0.013681
2017/08/29 21:46:24 step 4: objective=0.270106 reg=0.013680
2017/08/29 21:46:31 step 5: objective=0.270748 reg=0.013675
2017/08/29 21:46:39 step 6: objective=0.271281 reg=0.013671
2017/08/29 21:46:47 step 7: objective=0.271703 reg=0.013662
2017/08/29 21:46:47 Training value function...
2017/08/29 21:46:53 step 0: mse=1.214837 step=0.050000
2017/08/29 21:46:56 step 1: mse=1.213420 step=0.050000
2017/08/29 21:47:00 step 2: mse=1.212101 step=0.050000
2017/08/29 21:47:03 step 3: mse=1.210866 step=0.050000
2017/08/29 21:47:07 step 4: mse=1.209698 step=0.050000
2017/08/29 21:47:10 step 5: mse=1.208602 step=0.050000
2017/08/29 21:47:14 step 6: mse=1.207572 step=0.050000
2017/08/29 21:47:17 step 7: mse=1.206603 step=0.050000
2017/08/29 21:47:17 Saving...
2017/08/29 21:47:17 Gathering batch of experience...
2017/08/29 21:47:48 batch 259: mean=5.407430 stddev=1.441548 entropy=1.370468 frames=100140 count=5007
2017/08/29 21:47:48 Training policy...
2017/08/29 21:48:03 step 0: objective=0.255851 reg=0.013705
2017/08/29 21:48:11 step 1: objective=0.256450 reg=0.013700
2017/08/29 21:48:19 step 2: objective=0.257011 reg=0.013691
2017/08/29 21:48:27 step 3: objective=0.257577 reg=0.013692
2017/08/29 21:48:34 step 4: objective=0.258175 reg=0.013696
2017/08/29 21:48:43 step 5: objective=0.258635 reg=0.013687
2017/08/29 21:48:51 step 6: objective=0.259117 reg=0.013685
2017/08/29 21:48:59 step 7: objective=0.259445 reg=0.013676
2017/08/29 21:48:59 Training value function...
2017/08/29 21:49:04 step 0: mse=1.121468 step=0.050000
2017/08/29 21:49:08 step 1: mse=1.120815 step=0.050000
2017/08/29 21:49:11 step 2: mse=1.120226 step=0.050000
2017/08/29 21:49:15 step 3: mse=1.119682 step=0.050000
2017/08/29 21:49:18 step 4: mse=1.119184 step=0.050000
2017/08/29 21:49:22 step 5: mse=1.118638 step=0.050000
2017/08/29 21:49:25 step 6: mse=1.118189 step=0.050000
2017/08/29 21:49:29 step 7: mse=1.117735 step=0.050000
2017/08/29 21:49:29 Saving...
2017/08/29 21:49:29 Gathering batch of experience...
2017/08/29 21:50:00 batch 260: mean=5.423607 stddev=1.456961 entropy=1.368383 frames=100140 count=5007
2017/08/29 21:50:00 Training policy...
2017/08/29 21:50:15 step 0: objective=0.252289 reg=0.013684
2017/08/29 21:50:23 step 1: objective=0.253033 reg=0.013680
2017/08/29 21:50:31 step 2: objective=0.253683 reg=0.013680
2017/08/29 21:50:38 step 3: objective=0.254238 reg=0.013674
2017/08/29 21:50:46 step 4: objective=0.254818 reg=0.013669
2017/08/29 21:50:54 step 5: objective=0.255311 reg=0.013665
2017/08/29 21:51:02 step 6: objective=0.255735 reg=0.013662
2017/08/29 21:51:09 step 7: objective=0.256199 reg=0.013660
2017/08/29 21:51:09 Training value function...
2017/08/29 21:51:15 step 0: mse=1.164177 step=0.050000
2017/08/29 21:51:19 step 1: mse=1.163806 step=0.050000
2017/08/29 21:51:22 step 2: mse=1.163468 step=0.050000
2017/08/29 21:51:26 step 3: mse=1.163158 step=0.050000
2017/08/29 21:51:29 step 4: mse=1.162885 step=0.050000
2017/08/29 21:51:33 step 5: mse=1.162630 step=0.050000
2017/08/29 21:51:36 step 6: mse=1.162390 step=0.050000
2017/08/29 21:51:40 step 7: mse=1.162140 step=0.050000
2017/08/29 21:51:40 Saving...
2017/08/29 21:51:40 Gathering batch of experience...
2017/08/29 21:52:11 batch 261: mean=5.400839 stddev=1.462842 entropy=1.357419 frames=100140 count=5007
2017/08/29 21:52:11 Training policy...
2017/08/29 21:52:27 step 0: objective=0.242440 reg=0.013574
2017/08/29 21:52:35 step 1: objective=0.243278 reg=0.013573
2017/08/29 21:52:43 step 2: objective=0.244090 reg=0.013574
2017/08/29 21:52:50 step 3: objective=0.244564 reg=0.013570
2017/08/29 21:52:58 step 4: objective=0.245060 reg=0.013563
2017/08/29 21:53:06 step 5: objective=0.245558 reg=0.013561
2017/08/29 21:53:14 step 6: objective=0.246071 reg=0.013557
2017/08/29 21:53:22 step 7: objective=0.246546 reg=0.013554
2017/08/29 21:53:22 Training value function...
2017/08/29 21:53:28 step 0: mse=1.143615 step=0.050000
2017/08/29 21:53:31 step 1: mse=1.143754 step=0.050000
2017/08/29 21:53:35 step 2: mse=1.143902 step=0.050000
2017/08/29 21:53:38 step 3: mse=1.144048 step=0.050000
2017/08/29 21:53:42 step 4: mse=1.144174 step=0.050000
2017/08/29 21:53:45 step 5: mse=1.144303 step=0.050000
2017/08/29 21:53:49 step 6: mse=1.144412 step=0.050000
2017/08/29 21:53:52 step 7: mse=1.144511 step=0.050000
2017/08/29 21:53:52 Saving...
2017/08/29 21:53:52 Gathering batch of experience...
2017/08/29 21:54:24 batch 262: mean=5.401438 stddev=1.463975 entropy=1.360404 frames=100140 count=5007
2017/08/29 21:54:24 Training policy...
2017/08/29 21:54:39 step 0: objective=0.254866 reg=0.013604
2017/08/29 21:54:46 step 1: objective=0.255750 reg=0.013599
2017/08/29 21:54:54 step 2: objective=0.256461 reg=0.013604
2017/08/29 21:55:02 step 3: objective=0.257129 reg=0.013601
2017/08/29 21:55:10 step 4: objective=0.257673 reg=0.013596
2017/08/29 21:55:17 step 5: objective=0.258115 reg=0.013595
2017/08/29 21:55:25 step 6: objective=0.258412 reg=0.013593
2017/08/29 21:55:33 step 7: objective=0.258667 reg=0.013587
2017/08/29 21:55:33 Training value function...
2017/08/29 21:55:39 step 0: mse=1.163095 step=0.050000
2017/08/29 21:55:42 step 1: mse=1.162319 step=0.050000
2017/08/29 21:55:46 step 2: mse=1.161591 step=0.050000
2017/08/29 21:55:49 step 3: mse=1.160914 step=0.050000
2017/08/29 21:55:53 step 4: mse=1.160278 step=0.050000
2017/08/29 21:55:56 step 5: mse=1.159685 step=0.050000
2017/08/29 21:56:00 step 6: mse=1.159128 step=0.050000
2017/08/29 21:56:03 step 7: mse=1.158605 step=0.050000
2017/08/29 21:56:03 Saving...
2017/08/29 21:56:03 Gathering batch of experience...
2017/08/29 21:56:34 batch 263: mean=5.419812 stddev=1.475420 entropy=1.358347 frames=100140 count=5007
2017/08/29 21:56:34 Training policy...
2017/08/29 21:56:49 step 0: objective=0.254436 reg=0.013583
2017/08/29 21:56:58 step 1: objective=0.255382 reg=0.013586
2017/08/29 21:57:06 step 2: objective=0.255867 reg=0.013584
2017/08/29 21:57:14 step 3: objective=0.256473 reg=0.013580
2017/08/29 21:57:21 step 4: objective=0.257027 reg=0.013578
2017/08/29 21:57:29 step 5: objective=0.257406 reg=0.013580
2017/08/29 21:57:37 step 6: objective=0.257810 reg=0.013579
2017/08/29 21:57:45 step 7: objective=0.258261 reg=0.013573
2017/08/29 21:57:45 Training value function...
2017/08/29 21:57:51 step 0: mse=1.176396 step=0.050000
2017/08/29 21:57:54 step 1: mse=1.175717 step=0.050000
2017/08/29 21:57:57 step 2: mse=1.175043 step=0.050000
2017/08/29 21:58:01 step 3: mse=1.174441 step=0.050000
2017/08/29 21:58:04 step 4: mse=1.173854 step=0.050000
2017/08/29 21:58:08 step 5: mse=1.173327 step=0.050000
2017/08/29 21:58:11 step 6: mse=1.172843 step=0.050000
2017/08/29 21:58:15 step 7: mse=1.172381 step=0.050000
2017/08/29 21:58:15 Saving...
2017/08/29 21:58:15 Gathering batch of experience...
2017/08/29 21:58:46 batch 264: mean=5.405632 stddev=1.481876 entropy=1.357836 frames=100140 count=5007
2017/08/29 21:58:46 Training policy...
2017/08/29 21:59:01 step 0: objective=0.258094 reg=0.013578
2017/08/29 21:59:09 step 1: objective=0.258857 reg=0.013578
2017/08/29 21:59:17 step 2: objective=0.259416 reg=0.013580
2017/08/29 21:59:25 step 3: objective=0.260006 reg=0.013576
2017/08/29 21:59:33 step 4: objective=0.260596 reg=0.013578
2017/08/29 21:59:40 step 5: objective=0.261024 reg=0.013580
2017/08/29 21:59:48 step 6: objective=0.261522 reg=0.013579
2017/08/29 21:59:56 step 7: objective=0.261938 reg=0.013575
2017/08/29 21:59:56 Training value function...
2017/08/29 22:00:02 step 0: mse=1.178107 step=0.050000
2017/08/29 22:00:06 step 1: mse=1.177246 step=0.050000
2017/08/29 22:00:09 step 2: mse=1.176449 step=0.050000
2017/08/29 22:00:13 step 3: mse=1.175730 step=0.050000
2017/08/29 22:00:16 step 4: mse=1.175036 step=0.050000
2017/08/29 22:00:20 step 5: mse=1.174407 step=0.050000
2017/08/29 22:00:23 step 6: mse=1.173796 step=0.050000
2017/08/29 22:00:27 step 7: mse=1.173245 step=0.050000
2017/08/29 22:00:27 Saving...
2017/08/29 22:00:27 Gathering batch of experience...
2017/08/29 22:00:58 batch 265: mean=5.432195 stddev=1.459850 entropy=1.361275 frames=100140 count=5007
2017/08/29 22:00:58 Training policy...
2017/08/29 22:01:14 step 0: objective=0.258759 reg=0.013613
2017/08/29 22:01:22 step 1: objective=0.259389 reg=0.013616
2017/08/29 22:01:30 step 2: objective=0.260161 reg=0.013609
2017/08/29 22:01:38 step 3: objective=0.260770 reg=0.013611
2017/08/29 22:01:46 step 4: objective=0.261256 reg=0.013610
2017/08/29 22:01:54 step 5: objective=0.261771 reg=0.013604
2017/08/29 22:02:02 step 6: objective=0.262184 reg=0.013602
2017/08/29 22:02:09 step 7: objective=0.262548 reg=0.013599
2017/08/29 22:02:09 Training value function...
2017/08/29 22:02:15 step 0: mse=1.180282 step=0.050000
2017/08/29 22:02:19 step 1: mse=1.179732 step=0.050000
2017/08/29 22:02:22 step 2: mse=1.179224 step=0.050000
2017/08/29 22:02:26 step 3: mse=1.178754 step=0.050000
2017/08/29 22:02:29 step 4: mse=1.178311 step=0.050000
2017/08/29 22:02:33 step 5: mse=1.177897 step=0.050000
2017/08/29 22:02:36 step 6: mse=1.177509 step=0.050000
2017/08/29 22:02:40 step 7: mse=1.177144 step=0.050000
2017/08/29 22:02:40 Saving...
2017/08/29 22:02:40 Gathering batch of experience...
2017/08/29 22:03:11 batch 266: mean=5.443978 stddev=1.464856 entropy=1.358358 frames=100140 count=5007
2017/08/29 22:03:11 Training policy...
2017/08/29 22:03:26 step 0: objective=0.244413 reg=0.013583
2017/08/29 22:03:34 step 1: objective=0.245112 reg=0.013579
2017/08/29 22:03:42 step 2: objective=0.245727 reg=0.013577
2017/08/29 22:03:50 step 3: objective=0.246209 reg=0.013575
2017/08/29 22:03:58 step 4: objective=0.246705 reg=0.013579
2017/08/29 22:04:05 step 5: objective=0.247142 reg=0.013577
2017/08/29 22:04:14 step 6: objective=0.247655 reg=0.013573
2017/08/29 22:04:21 step 7: objective=0.248253 reg=0.013566
2017/08/29 22:04:21 Training value function...
2017/08/29 22:04:27 step 0: mse=1.167574 step=0.050000
2017/08/29 22:04:31 step 1: mse=1.167761 step=0.050000
2017/08/29 22:04:34 step 2: mse=1.167943 step=0.050000
2017/08/29 22:04:38 step 3: mse=1.168113 step=0.050000
2017/08/29 22:04:41 step 4: mse=1.168258 step=0.050000
2017/08/29 22:04:45 step 5: mse=1.168419 step=0.050000
2017/08/29 22:04:48 step 6: mse=1.168546 step=0.050000
2017/08/29 22:04:52 step 7: mse=1.168652 step=0.050000
2017/08/29 22:04:52 Saving...
2017/08/29 22:04:52 Gathering batch of experience...
2017/08/29 22:05:23 batch 267: mean=5.466147 stddev=1.472470 entropy=1.348971 frames=100140 count=5007
2017/08/29 22:05:23 Training policy...
2017/08/29 22:05:38 step 0: objective=0.264828 reg=0.013490
2017/08/29 22:05:46 step 1: objective=0.265544 reg=0.013493
2017/08/29 22:05:54 step 2: objective=0.266350 reg=0.013486
2017/08/29 22:06:02 step 3: objective=0.266960 reg=0.013489
2017/08/29 22:06:10 step 4: objective=0.267450 reg=0.013480
2017/08/29 22:06:18 step 5: objective=0.267940 reg=0.013477
2017/08/29 22:06:25 step 6: objective=0.268467 reg=0.013471
2017/08/29 22:06:33 step 7: objective=0.268905 reg=0.013466
2017/08/29 22:06:33 Training value function...
2017/08/29 22:06:39 step 0: mse=1.177315 step=0.050000
2017/08/29 22:06:43 step 1: mse=1.176101 step=0.050000
2017/08/29 22:06:46 step 2: mse=1.174930 step=0.050000
2017/08/29 22:06:50 step 3: mse=1.173838 step=0.050000
2017/08/29 22:06:53 step 4: mse=1.172819 step=0.050000
2017/08/29 22:06:57 step 5: mse=1.171866 step=0.050000
2017/08/29 22:07:00 step 6: mse=1.170969 step=0.050000
2017/08/29 22:07:04 step 7: mse=1.170130 step=0.050000
2017/08/29 22:07:04 Saving...
2017/08/29 22:07:04 Gathering batch of experience...
2017/08/29 22:07:35 batch 268: mean=5.407829 stddev=1.452889 entropy=1.356503 frames=100140 count=5007
2017/08/29 22:07:35 Training policy...
2017/08/29 22:07:51 step 0: objective=0.239792 reg=0.013565
2017/08/29 22:07:59 step 1: objective=0.240492 reg=0.013566
2017/08/29 22:08:06 step 2: objective=0.241298 reg=0.013565
2017/08/29 22:08:14 step 3: objective=0.241846 reg=0.013561
2017/08/29 22:08:22 step 4: objective=0.242372 reg=0.013560
2017/08/29 22:08:30 step 5: objective=0.242930 reg=0.013557
2017/08/29 22:08:38 step 6: objective=0.243324 reg=0.013557
2017/08/29 22:08:46 step 7: objective=0.243836 reg=0.013553
2017/08/29 22:08:46 Training value function...
2017/08/29 22:08:52 step 0: mse=1.128771 step=0.050000
2017/08/29 22:08:55 step 1: mse=1.129084 step=0.050000
2017/08/29 22:08:59 step 2: mse=1.129390 step=0.050000
2017/08/29 22:09:02 step 3: mse=1.129680 step=0.050000
2017/08/29 22:09:06 step 4: mse=1.129962 step=0.050000
2017/08/29 22:09:09 step 5: mse=1.130223 step=0.050000
2017/08/29 22:09:13 step 6: mse=1.130470 step=0.050000
2017/08/29 22:09:16 step 7: mse=1.130700 step=0.050000
2017/08/29 22:09:16 Saving...
2017/08/29 22:09:16 Gathering batch of experience...
2017/08/29 22:09:48 batch 269: mean=5.426802 stddev=1.461094 entropy=1.352109 frames=100140 count=5007
2017/08/29 22:09:48 Training policy...
2017/08/29 22:10:03 step 0: objective=0.242561 reg=0.013521
2017/08/29 22:10:11 step 1: objective=0.243269 reg=0.013518
2017/08/29 22:10:19 step 2: objective=0.243831 reg=0.013510
2017/08/29 22:10:27 step 3: objective=0.244398 reg=0.013518
2017/08/29 22:10:35 step 4: objective=0.244728 reg=0.013500
2017/08/29 22:10:42 step 5: objective=0.245041 reg=0.013520
2017/08/29 22:10:51 step 6: objective=0.245458 reg=0.013497
2017/08/29 22:10:59 step 7: objective=0.245644 reg=0.013517
2017/08/29 22:10:59 Training value function...
2017/08/29 22:11:05 step 0: mse=1.134164 step=0.050000
2017/08/29 22:11:08 step 1: mse=1.134308 step=0.050000
2017/08/29 22:11:12 step 2: mse=1.134461 step=0.050000
2017/08/29 22:11:15 step 3: mse=1.134597 step=0.050000
2017/08/29 22:11:19 step 4: mse=1.134731 step=0.050000
2017/08/29 22:11:22 step 5: mse=1.134859 step=0.050000
2017/08/29 22:11:26 step 6: mse=1.134971 step=0.050000
2017/08/29 22:11:29 step 7: mse=1.135089 step=0.050000
2017/08/29 22:11:29 Saving...
2017/08/29 22:11:29 Gathering batch of experience...
2017/08/29 22:12:01 batch 270: mean=5.429599 stddev=1.466007 entropy=1.344591 frames=100140 count=5007
2017/08/29 22:12:01 Training policy...
2017/08/29 22:12:17 step 0: objective=0.269700 reg=0.013446
2017/08/29 22:12:25 step 1: objective=0.270356 reg=0.013447
2017/08/29 22:12:33 step 2: objective=0.270986 reg=0.013446
2017/08/29 22:12:40 step 3: objective=0.271609 reg=0.013449
2017/08/29 22:12:48 step 4: objective=0.272019 reg=0.013451
2017/08/29 22:12:56 step 5: objective=0.272490 reg=0.013454
2017/08/29 22:13:04 step 6: objective=0.272933 reg=0.013449
2017/08/29 22:13:12 step 7: objective=0.273361 reg=0.013446
2017/08/29 22:13:12 Training value function...
2017/08/29 22:13:18 step 0: mse=1.189993 step=0.050000
2017/08/29 22:13:22 step 1: mse=1.188707 step=0.050000
2017/08/29 22:13:25 step 2: mse=1.187506 step=0.050000
2017/08/29 22:13:29 step 3: mse=1.186390 step=0.050000
2017/08/29 22:13:32 step 4: mse=1.185351 step=0.050000
2017/08/29 22:13:36 step 5: mse=1.184372 step=0.050000
2017/08/29 22:13:39 step 6: mse=1.183431 step=0.050000
2017/08/29 22:13:43 step 7: mse=1.182552 step=0.050000
2017/08/29 22:13:43 Saving...
2017/08/29 22:13:43 Gathering batch of experience...
2017/08/29 22:14:15 batch 271: mean=5.413221 stddev=1.457339 entropy=1.344297 frames=100140 count=5007
2017/08/29 22:14:15 Training policy...
2017/08/29 22:14:30 step 0: objective=0.236995 reg=0.013443
2017/08/29 22:14:38 step 1: objective=0.237669 reg=0.013436
2017/08/29 22:14:46 step 2: objective=0.238043 reg=0.013443
2017/08/29 22:14:53 step 3: objective=0.238563 reg=0.013435
2017/08/29 22:15:01 step 4: objective=0.238931 reg=0.013448
2017/08/29 22:15:09 step 5: objective=0.239413 reg=0.013443
2017/08/29 22:15:18 step 6: objective=0.239819 reg=0.013449
2017/08/29 22:15:25 step 7: objective=0.240145 reg=0.013441
2017/08/29 22:15:25 Training value function...
2017/08/29 22:15:32 step 0: mse=1.101046 step=0.050000
2017/08/29 22:15:35 step 1: mse=1.101126 step=0.050000
2017/08/29 22:15:39 step 2: mse=1.101218 step=0.050000
2017/08/29 22:15:42 step 3: mse=1.101316 step=0.050000
2017/08/29 22:15:46 step 4: mse=1.101412 step=0.050000
2017/08/29 22:15:49 step 5: mse=1.101500 step=0.050000
2017/08/29 22:15:53 step 6: mse=1.101590 step=0.050000
2017/08/29 22:15:56 step 7: mse=1.101668 step=0.050000
2017/08/29 22:15:56 Saving...
2017/08/29 22:15:56 Gathering batch of experience...
2017/08/29 22:16:28 batch 272: mean=5.454763 stddev=1.448090 entropy=1.340686 frames=100140 count=5007
2017/08/29 22:16:28 Training policy...
2017/08/29 22:16:44 step 0: objective=0.254514 reg=0.013407
2017/08/29 22:16:52 step 1: objective=0.255147 reg=0.013407
2017/08/29 22:17:00 step 2: objective=0.255862 reg=0.013406
2017/08/29 22:17:08 step 3: objective=0.256421 reg=0.013411
2017/08/29 22:17:16 step 4: objective=0.256861 reg=0.013411
2017/08/29 22:17:24 step 5: objective=0.257288 reg=0.013408
2017/08/29 22:17:32 step 6: objective=0.257706 reg=0.013415
2017/08/29 22:17:40 step 7: objective=0.258188 reg=0.013413
2017/08/29 22:17:40 Training value function...
2017/08/29 22:17:46 step 0: mse=1.164700 step=0.050000
2017/08/29 22:17:49 step 1: mse=1.164257 step=0.050000
2017/08/29 22:17:53 step 2: mse=1.163858 step=0.050000
2017/08/29 22:17:56 step 3: mse=1.163490 step=0.050000
2017/08/29 22:18:00 step 4: mse=1.163153 step=0.050000
2017/08/29 22:18:03 step 5: mse=1.162816 step=0.050000
2017/08/29 22:18:07 step 6: mse=1.162505 step=0.050000
2017/08/29 22:18:10 step 7: mse=1.162214 step=0.050000
2017/08/29 22:18:10 Saving...
2017/08/29 22:18:10 Gathering batch of experience...
2017/08/29 22:18:42 batch 273: mean=5.423008 stddev=1.490940 entropy=1.348168 frames=100140 count=5007
2017/08/29 22:18:42 Training policy...
2017/08/29 22:18:58 step 0: objective=0.254580 reg=0.013482
2017/08/29 22:19:07 step 1: objective=0.255211 reg=0.013480
2017/08/29 22:19:15 step 2: objective=0.255782 reg=0.013477
2017/08/29 22:19:23 step 3: objective=0.256591 reg=0.013472
2017/08/29 22:19:31 step 4: objective=0.257065 reg=0.013465
2017/08/29 22:19:39 step 5: objective=0.257455 reg=0.013468
2017/08/29 22:19:47 step 6: objective=0.257724 reg=0.013459
2017/08/29 22:19:55 step 7: objective=0.258030 reg=0.013446
2017/08/29 22:19:55 Training value function...
2017/08/29 22:20:01 step 0: mse=1.177357 step=0.050000
2017/08/29 22:20:05 step 1: mse=1.176748 step=0.050000
2017/08/29 22:20:08 step 2: mse=1.176194 step=0.050000
2017/08/29 22:20:12 step 3: mse=1.175687 step=0.050000
2017/08/29 22:20:15 step 4: mse=1.175222 step=0.050000
2017/08/29 22:20:19 step 5: mse=1.174793 step=0.050000
2017/08/29 22:20:22 step 6: mse=1.174393 step=0.050000
2017/08/29 22:20:26 step 7: mse=1.174019 step=0.050000
2017/08/29 22:20:26 Saving...
2017/08/29 22:20:26 Gathering batch of experience...
2017/08/29 22:20:58 batch 274: mean=5.414020 stddev=1.458482 entropy=1.339910 frames=100140 count=5007
2017/08/29 22:20:58 Training policy...
2017/08/29 22:21:13 step 0: objective=0.240328 reg=0.013399
2017/08/29 22:21:22 step 1: objective=0.241067 reg=0.013398
2017/08/29 22:21:30 step 2: objective=0.241663 reg=0.013398
2017/08/29 22:21:38 step 3: objective=0.242118 reg=0.013397
2017/08/29 22:21:47 step 4: objective=0.242604 reg=0.013388
2017/08/29 22:21:55 step 5: objective=0.243060 reg=0.013387
2017/08/29 22:22:03 step 6: objective=0.243491 reg=0.013383
2017/08/29 22:22:11 step 7: objective=0.243893 reg=0.013383
2017/08/29 22:22:11 Training value function...
2017/08/29 22:22:17 step 0: mse=1.135308 step=0.050000
2017/08/29 22:22:20 step 1: mse=1.135727 step=0.050000
2017/08/29 22:22:24 step 2: mse=1.136141 step=0.050000
2017/08/29 22:22:27 step 3: mse=1.136536 step=0.050000
2017/08/29 22:22:31 step 4: mse=1.136921 step=0.050000
2017/08/29 22:22:34 step 5: mse=1.137290 step=0.050000
2017/08/29 22:22:38 step 6: mse=1.137617 step=0.050000
2017/08/29 22:22:41 step 7: mse=1.137928 step=0.050000
2017/08/29 22:22:41 Saving...
2017/08/29 22:22:42 Gathering batch of experience...
2017/08/29 22:23:13 batch 275: mean=5.428999 stddev=1.470739 entropy=1.344190 frames=100140 count=5007
2017/08/29 22:23:13 Training policy...
2017/08/29 22:23:29 step 0: objective=0.249727 reg=0.013442
2017/08/29 22:23:37 step 1: objective=0.250438 reg=0.013445
2017/08/29 22:23:45 step 2: objective=0.251172 reg=0.013439
2017/08/29 22:23:53 step 3: objective=0.251836 reg=0.013443
2017/08/29 22:24:01 step 4: objective=0.252344 reg=0.013442
2017/08/29 22:24:09 step 5: objective=0.252799 reg=0.013441
2017/08/29 22:24:17 step 6: objective=0.253227 reg=0.013437
2017/08/29 22:24:26 step 7: objective=0.253724 reg=0.013436
2017/08/29 22:24:26 Training value function...
2017/08/29 22:24:32 step 0: mse=1.164559 step=0.050000
2017/08/29 22:24:35 step 1: mse=1.164385 step=0.050000
2017/08/29 22:24:39 step 2: mse=1.164231 step=0.050000
2017/08/29 22:24:42 step 3: mse=1.164098 step=0.050000
2017/08/29 22:24:46 step 4: mse=1.163963 step=0.050000
2017/08/29 22:24:49 step 5: mse=1.163843 step=0.050000
2017/08/29 22:24:53 step 6: mse=1.163732 step=0.050000
2017/08/29 22:24:56 step 7: mse=1.163631 step=0.050000
2017/08/29 22:24:56 Saving...
2017/08/29 22:24:56 Gathering batch of experience...
2017/08/29 22:25:28 batch 276: mean=5.431995 stddev=1.504974 entropy=1.340879 frames=100140 count=5007
2017/08/29 22:25:28 Training policy...
2017/08/29 22:25:43 step 0: objective=0.257498 reg=0.013409
2017/08/29 22:25:51 step 1: objective=0.258407 reg=0.013410
2017/08/29 22:26:00 step 2: objective=0.259246 reg=0.013414
2017/08/29 22:26:08 step 3: objective=0.259738 reg=0.013407
2017/08/29 22:26:16 step 4: objective=0.260331 reg=0.013398
2017/08/29 22:26:24 step 5: objective=0.260679 reg=0.013397
2017/08/29 22:26:32 step 6: objective=0.261124 reg=0.013399
2017/08/29 22:26:40 step 7: objective=0.261390 reg=0.013398
2017/08/29 22:26:40 Training value function...
2017/08/29 22:26:46 step 0: mse=1.200441 step=0.050000
2017/08/29 22:26:49 step 1: mse=1.199961 step=0.050000
2017/08/29 22:26:52 step 2: mse=1.199520 step=0.050000
2017/08/29 22:26:56 step 3: mse=1.199111 step=0.050000
2017/08/29 22:26:59 step 4: mse=1.198739 step=0.050000
2017/08/29 22:27:03 step 5: mse=1.198343 step=0.050000
2017/08/29 22:27:07 step 6: mse=1.197975 step=0.050000
2017/08/29 22:27:10 step 7: mse=1.197633 step=0.050000
2017/08/29 22:27:10 Saving...
2017/08/29 22:27:10 Gathering batch of experience...
2017/08/29 22:27:42 batch 277: mean=5.408428 stddev=1.482052 entropy=1.340429 frames=100140 count=5007
2017/08/29 22:27:42 Training policy...
2017/08/29 22:27:57 step 0: objective=0.249985 reg=0.013404
2017/08/29 22:28:05 step 1: objective=0.250589 reg=0.013407
2017/08/29 22:28:14 step 2: objective=0.251289 reg=0.013404
2017/08/29 22:28:22 step 3: objective=0.251818 reg=0.013404
2017/08/29 22:28:30 step 4: objective=0.252374 reg=0.013406
2017/08/29 22:28:38 step 5: objective=0.252806 reg=0.013404
2017/08/29 22:28:47 step 6: objective=0.253221 reg=0.013408
2017/08/29 22:28:55 step 7: objective=0.253609 reg=0.013403
2017/08/29 22:28:55 Training value function...
2017/08/29 22:29:01 step 0: mse=1.148901 step=0.050000
2017/08/29 22:29:04 step 1: mse=1.148557 step=0.050000
2017/08/29 22:29:08 step 2: mse=1.148241 step=0.050000
2017/08/29 22:29:11 step 3: mse=1.147940 step=0.050000
2017/08/29 22:29:15 step 4: mse=1.147634 step=0.050000
2017/08/29 22:29:18 step 5: mse=1.147369 step=0.050000
2017/08/29 22:29:22 step 6: mse=1.147097 step=0.050000
2017/08/29 22:29:25 step 7: mse=1.146852 step=0.050000
2017/08/29 22:29:25 Saving...
2017/08/29 22:29:25 Gathering batch of experience...
2017/08/29 22:29:57 batch 278: mean=5.421210 stddev=1.418068 entropy=1.338400 frames=100140 count=5007
2017/08/29 22:29:57 Training policy...
2017/08/29 22:30:12 step 0: objective=0.252390 reg=0.013384
2017/08/29 22:30:20 step 1: objective=0.253123 reg=0.013391
2017/08/29 22:30:29 step 2: objective=0.253792 reg=0.013382
2017/08/29 22:30:37 step 3: objective=0.254371 reg=0.013381
2017/08/29 22:30:45 step 4: objective=0.254789 reg=0.013372
2017/08/29 22:30:53 step 5: objective=0.255279 reg=0.013368
2017/08/29 22:31:01 step 6: objective=0.255766 reg=0.013367
2017/08/29 22:31:10 step 7: objective=0.256223 reg=0.013364
2017/08/29 22:31:10 Training value function...
2017/08/29 22:31:16 step 0: mse=1.128114 step=0.050000
2017/08/29 22:31:19 step 1: mse=1.127667 step=0.050000
2017/08/29 22:31:23 step 2: mse=1.127257 step=0.050000
2017/08/29 22:31:26 step 3: mse=1.126879 step=0.050000
2017/08/29 22:31:30 step 4: mse=1.126531 step=0.050000
2017/08/29 22:31:33 step 5: mse=1.126206 step=0.050000
2017/08/29 22:31:36 step 6: mse=1.125903 step=0.050000
2017/08/29 22:31:40 step 7: mse=1.125618 step=0.050000
2017/08/29 22:31:40 Saving...
2017/08/29 22:31:40 Gathering batch of experience...
2017/08/29 22:32:12 batch 279: mean=5.444578 stddev=1.460099 entropy=1.335075 frames=100140 count=5007
2017/08/29 22:32:12 Training policy...
2017/08/29 22:32:28 step 0: objective=0.256434 reg=0.013351
2017/08/29 22:32:36 step 1: objective=0.257187 reg=0.013348
2017/08/29 22:32:44 step 2: objective=0.257816 reg=0.013350
2017/08/29 22:32:52 step 3: objective=0.258363 reg=0.013346
2017/08/29 22:33:00 step 4: objective=0.258867 reg=0.013344
2017/08/29 22:33:08 step 5: objective=0.259237 reg=0.013345
2017/08/29 22:33:16 step 6: objective=0.259769 reg=0.013345
2017/08/29 22:33:24 step 7: objective=0.260187 reg=0.013344
2017/08/29 22:33:24 Training value function...
2017/08/29 22:33:30 step 0: mse=1.149538 step=0.050000
2017/08/29 22:33:34 step 1: mse=1.148718 step=0.050000
2017/08/29 22:33:37 step 2: mse=1.147970 step=0.050000
2017/08/29 22:33:41 step 3: mse=1.147232 step=0.050000
2017/08/29 22:33:44 step 4: mse=1.146546 step=0.050000
2017/08/29 22:33:48 step 5: mse=1.145887 step=0.050000
2017/08/29 22:33:51 step 6: mse=1.145273 step=0.050000
2017/08/29 22:33:55 step 7: mse=1.144701 step=0.050000
2017/08/29 22:33:55 Saving...
2017/08/29 22:33:55 Gathering batch of experience...
2017/08/29 22:34:27 batch 280: mean=5.443579 stddev=1.456637 entropy=1.338816 frames=100140 count=5007
2017/08/29 22:34:27 Training policy...
2017/08/29 22:34:42 step 0: objective=0.256370 reg=0.013388
2017/08/29 22:34:51 step 1: objective=0.257151 reg=0.013385
2017/08/29 22:34:59 step 2: objective=0.257685 reg=0.013390
2017/08/29 22:35:08 step 3: objective=0.258406 reg=0.013391
2017/08/29 22:35:16 step 4: objective=0.258888 reg=0.013388
2017/08/29 22:35:24 step 5: objective=0.259277 reg=0.013387
2017/08/29 22:35:32 step 6: objective=0.259646 reg=0.013376
2017/08/29 22:35:40 step 7: objective=0.259824 reg=0.013388
2017/08/29 22:35:40 Training value function...
2017/08/29 22:35:46 step 0: mse=1.152295 step=0.050000
2017/08/29 22:35:50 step 1: mse=1.151619 step=0.050000
2017/08/29 22:35:53 step 2: mse=1.150969 step=0.050000
2017/08/29 22:35:57 step 3: mse=1.150357 step=0.050000
2017/08/29 22:36:00 step 4: mse=1.149790 step=0.050000
2017/08/29 22:36:04 step 5: mse=1.149255 step=0.050000
2017/08/29 22:36:07 step 6: mse=1.148752 step=0.050000
2017/08/29 22:36:11 step 7: mse=1.148279 step=0.050000
2017/08/29 22:36:11 Saving...
2017/08/29 22:36:11 Gathering batch of experience...
2017/08/29 22:36:43 batch 281: mean=5.413421 stddev=1.468137 entropy=1.336117 frames=100140 count=5007
2017/08/29 22:36:43 Training policy...
2017/08/29 22:36:58 step 0: objective=0.248969 reg=0.013361
2017/08/29 22:37:06 step 1: objective=0.249683 reg=0.013358
2017/08/29 22:37:14 step 2: objective=0.250083 reg=0.013357
2017/08/29 22:37:22 step 3: objective=0.250532 reg=0.013368
2017/08/29 22:37:30 step 4: objective=0.251049 reg=0.013360
2017/08/29 22:37:38 step 5: objective=0.251487 reg=0.013357
2017/08/29 22:37:47 step 6: objective=0.252000 reg=0.013350
2017/08/29 22:37:55 step 7: objective=0.252458 reg=0.013347
2017/08/29 22:37:55 Training value function...
2017/08/29 22:38:01 step 0: mse=1.146397 step=0.050000
2017/08/29 22:38:04 step 1: mse=1.146000 step=0.050000
2017/08/29 22:38:08 step 2: mse=1.145638 step=0.050000
2017/08/29 22:38:11 step 3: mse=1.145307 step=0.050000
2017/08/29 22:38:15 step 4: mse=1.145003 step=0.050000
2017/08/29 22:38:18 step 5: mse=1.144722 step=0.050000
2017/08/29 22:38:22 step 6: mse=1.144457 step=0.050000
2017/08/29 22:38:25 step 7: mse=1.144204 step=0.050000
2017/08/29 22:38:25 Saving...
2017/08/29 22:38:25 Gathering batch of experience...
2017/08/29 22:38:57 batch 282: mean=5.449571 stddev=1.465604 entropy=1.330101 frames=100140 count=5007
2017/08/29 22:38:57 Training policy...
2017/08/29 22:39:13 step 0: objective=0.252063 reg=0.013301
2017/08/29 22:39:21 step 1: objective=0.252762 reg=0.013296
2017/08/29 22:39:30 step 2: objective=0.253396 reg=0.013290
2017/08/29 22:39:38 step 3: objective=0.253770 reg=0.013295
2017/08/29 22:39:46 step 4: objective=0.254242 reg=0.013281
2017/08/29 22:39:54 step 5: objective=0.254431 reg=0.013293
2017/08/29 22:40:02 step 6: objective=0.254908 reg=0.013286
2017/08/29 22:40:10 step 7: objective=0.255193 reg=0.013297
2017/08/29 22:40:10 Training value function...
2017/08/29 22:40:16 step 0: mse=1.160774 step=0.050000
2017/08/29 22:40:20 step 1: mse=1.160233 step=0.050000
2017/08/29 22:40:23 step 2: mse=1.159734 step=0.050000
2017/08/29 22:40:27 step 3: mse=1.159263 step=0.050000
2017/08/29 22:40:30 step 4: mse=1.158740 step=0.050000
2017/08/29 22:40:34 step 5: mse=1.158297 step=0.050000
2017/08/29 22:40:37 step 6: mse=1.157848 step=0.050000
2017/08/29 22:40:41 step 7: mse=1.157453 step=0.050000
2017/08/29 22:40:41 Saving...
2017/08/29 22:40:41 Gathering batch of experience...
2017/08/29 22:41:13 batch 283: mean=5.441182 stddev=1.475073 entropy=1.328875 frames=100140 count=5007
2017/08/29 22:41:13 Training policy...
2017/08/29 22:41:28 step 0: objective=0.245042 reg=0.013289
2017/08/29 22:41:36 step 1: objective=0.245809 reg=0.013283
2017/08/29 22:41:44 step 2: objective=0.246457 reg=0.013286
2017/08/29 22:41:53 step 3: objective=0.247082 reg=0.013288
2017/08/29 22:42:01 step 4: objective=0.247605 reg=0.013291
2017/08/29 22:42:09 step 5: objective=0.248113 reg=0.013289
2017/08/29 22:42:17 step 6: objective=0.248553 reg=0.013283
2017/08/29 22:42:25 step 7: objective=0.248908 reg=0.013278
2017/08/29 22:42:25 Training value function...
2017/08/29 22:42:31 step 0: mse=1.161777 step=0.050000
2017/08/29 22:42:35 step 1: mse=1.161559 step=0.050000
2017/08/29 22:42:38 step 2: mse=1.161370 step=0.050000
2017/08/29 22:42:42 step 3: mse=1.161198 step=0.050000
2017/08/29 22:42:45 step 4: mse=1.161045 step=0.050000
2017/08/29 22:42:49 step 5: mse=1.160905 step=0.050000
2017/08/29 22:42:52 step 6: mse=1.160774 step=0.050000
2017/08/29 22:42:56 step 7: mse=1.160653 step=0.050000
2017/08/29 22:42:56 Saving...
2017/08/29 22:42:56 Gathering batch of experience...
2017/08/29 22:43:28 batch 284: mean=5.445976 stddev=1.436989 entropy=1.327758 frames=100140 count=5007
2017/08/29 22:43:28 Training policy...
2017/08/29 22:43:43 step 0: objective=0.255204 reg=0.013278
2017/08/29 22:43:51 step 1: objective=0.256051 reg=0.013279
2017/08/29 22:43:59 step 2: objective=0.256713 reg=0.013277
2017/08/29 22:44:08 step 3: objective=0.257261 reg=0.013276
2017/08/29 22:44:16 step 4: objective=0.257797 reg=0.013271
2017/08/29 22:44:24 step 5: objective=0.258215 reg=0.013269
2017/08/29 22:44:32 step 6: objective=0.258688 reg=0.013270
2017/08/29 22:44:40 step 7: objective=0.259207 reg=0.013267
2017/08/29 22:44:40 Training value function...
2017/08/29 22:44:46 step 0: mse=1.147377 step=0.050000
2017/08/29 22:44:50 step 1: mse=1.147204 step=0.050000
2017/08/29 22:44:53 step 2: mse=1.147050 step=0.050000
2017/08/29 22:44:57 step 3: mse=1.146912 step=0.050000
2017/08/29 22:45:00 step 4: mse=1.146793 step=0.050000
2017/08/29 22:45:04 step 5: mse=1.146682 step=0.050000
2017/08/29 22:45:07 step 6: mse=1.146578 step=0.050000
2017/08/29 22:45:11 step 7: mse=1.146480 step=0.050000
2017/08/29 22:45:11 Saving...
2017/08/29 22:45:11 Gathering batch of experience...
2017/08/29 22:45:43 batch 285: mean=5.469742 stddev=1.462067 entropy=1.324525 frames=100140 count=5007
2017/08/29 22:45:43 Training policy...
2017/08/29 22:45:58 step 0: objective=0.254964 reg=0.013245
2017/08/29 22:46:07 step 1: objective=0.255705 reg=0.013239
2017/08/29 22:46:15 step 2: objective=0.256200 reg=0.013238
2017/08/29 22:46:23 step 3: objective=0.256761 reg=0.013236
2017/08/29 22:46:31 step 4: objective=0.257336 reg=0.013236
2017/08/29 22:46:39 step 5: objective=0.257833 reg=0.013231
2017/08/29 22:46:48 step 6: objective=0.258286 reg=0.013226
2017/08/29 22:46:56 step 7: objective=0.258781 reg=0.013221
2017/08/29 22:46:56 Training value function...
2017/08/29 22:47:02 step 0: mse=1.162425 step=0.050000
2017/08/29 22:47:05 step 1: mse=1.161420 step=0.050000
2017/08/29 22:47:09 step 2: mse=1.160484 step=0.050000
2017/08/29 22:47:12 step 3: mse=1.159609 step=0.050000
2017/08/29 22:47:16 step 4: mse=1.158789 step=0.050000
2017/08/29 22:47:19 step 5: mse=1.158022 step=0.050000
2017/08/29 22:47:22 step 6: mse=1.157295 step=0.050000
2017/08/29 22:47:26 step 7: mse=1.156616 step=0.050000
2017/08/29 22:47:26 Saving...
2017/08/29 22:47:26 Gathering batch of experience...
2017/08/29 22:47:58 batch 286: mean=5.464550 stddev=1.473923 entropy=1.324593 frames=100140 count=5007
2017/08/29 22:47:58 Training policy...
2017/08/29 22:48:14 step 0: objective=0.253756 reg=0.013246
2017/08/29 22:48:23 step 1: objective=0.254421 reg=0.013252
2017/08/29 22:48:31 step 2: objective=0.255018 reg=0.013251
2017/08/29 22:48:39 step 3: objective=0.255556 reg=0.013252
2017/08/29 22:48:47 step 4: objective=0.256004 reg=0.013245
2017/08/29 22:48:56 step 5: objective=0.256524 reg=0.013244
2017/08/29 22:49:04 step 6: objective=0.257032 reg=0.013239
2017/08/29 22:49:13 step 7: objective=0.257549 reg=0.013235
2017/08/29 22:49:13 Training value function...
2017/08/29 22:49:19 step 0: mse=1.159946 step=0.050000
2017/08/29 22:49:22 step 1: mse=1.159356 step=0.050000
2017/08/29 22:49:26 step 2: mse=1.158813 step=0.050000
2017/08/29 22:49:29 step 3: mse=1.158320 step=0.050000
2017/08/29 22:49:33 step 4: mse=1.157869 step=0.050000
2017/08/29 22:49:36 step 5: mse=1.157445 step=0.050000
2017/08/29 22:49:40 step 6: mse=1.157033 step=0.050000
2017/08/29 22:49:43 step 7: mse=1.156645 step=0.050000
2017/08/29 22:49:43 Saving...
2017/08/29 22:49:43 Gathering batch of experience...
2017/08/29 22:50:15 batch 287: mean=5.439585 stddev=1.472162 entropy=1.322939 frames=100140 count=5007
2017/08/29 22:50:15 Training policy...
2017/08/29 22:50:31 step 0: objective=0.245450 reg=0.013229
2017/08/29 22:50:39 step 1: objective=0.246148 reg=0.013229
2017/08/29 22:50:48 step 2: objective=0.246836 reg=0.013229
2017/08/29 22:50:56 step 3: objective=0.247443 reg=0.013224
2017/08/29 22:51:04 step 4: objective=0.248056 reg=0.013224
2017/08/29 22:51:12 step 5: objective=0.248525 reg=0.013220
2017/08/29 22:51:21 step 6: objective=0.248957 reg=0.013220
2017/08/29 22:51:30 step 7: objective=0.249388 reg=0.013219
2017/08/29 22:51:30 Training value function...
2017/08/29 22:51:36 step 0: mse=1.162210 step=0.050000
2017/08/29 22:51:40 step 1: mse=1.162358 step=0.050000
2017/08/29 22:51:43 step 2: mse=1.162507 step=0.050000
2017/08/29 22:51:47 step 3: mse=1.162618 step=0.050000
2017/08/29 22:51:50 step 4: mse=1.162735 step=0.050000
2017/08/29 22:51:54 step 5: mse=1.162860 step=0.050000
2017/08/29 22:51:57 step 6: mse=1.162949 step=0.050000
2017/08/29 22:52:01 step 7: mse=1.163042 step=0.050000
2017/08/29 22:52:01 Saving...
2017/08/29 22:52:01 Gathering batch of experience...
2017/08/29 22:52:33 batch 288: mean=5.432794 stddev=1.454944 entropy=1.323419 frames=100140 count=5007
2017/08/29 22:52:33 Training policy...
2017/08/29 22:52:48 step 0: objective=0.241830 reg=0.013234
2017/08/29 22:52:57 step 1: objective=0.242502 reg=0.013231
2017/08/29 22:53:05 step 2: objective=0.243063 reg=0.013229
2017/08/29 22:53:13 step 3: objective=0.243534 reg=0.013232
2017/08/29 22:53:22 step 4: objective=0.243993 reg=0.013231
2017/08/29 22:53:30 step 5: objective=0.244488 reg=0.013225
2017/08/29 22:53:39 step 6: objective=0.245116 reg=0.013224
2017/08/29 22:53:48 step 7: objective=0.245571 reg=0.013225
2017/08/29 22:53:48 Training value function...
2017/08/29 22:53:54 step 0: mse=1.122020 step=0.050000
2017/08/29 22:53:57 step 1: mse=1.122019 step=0.050000
2017/08/29 22:54:00 step 2: mse=1.122027 step=0.050000
2017/08/29 22:54:04 step 3: mse=1.122042 step=0.050000
2017/08/29 22:54:07 step 4: mse=1.122063 step=0.050000
2017/08/29 22:54:11 step 5: mse=1.122088 step=0.050000
2017/08/29 22:54:14 step 6: mse=1.122128 step=0.050000
2017/08/29 22:54:18 step 7: mse=1.122162 step=0.050000
2017/08/29 22:54:18 Saving...
2017/08/29 22:54:18 Gathering batch of experience...
2017/08/29 22:54:50 batch 289: mean=5.464749 stddev=1.450572 entropy=1.322044 frames=100140 count=5007
2017/08/29 22:54:50 Training policy...
2017/08/29 22:55:06 step 0: objective=0.249868 reg=0.013220
2017/08/29 22:55:14 step 1: objective=0.250505 reg=0.013224
2017/08/29 22:55:23 step 2: objective=0.251125 reg=0.013228
2017/08/29 22:55:31 step 3: objective=0.251679 reg=0.013228
2017/08/29 22:55:40 step 4: objective=0.252140 reg=0.013229
2017/08/29 22:55:48 step 5: objective=0.252732 reg=0.013227
2017/08/29 22:55:56 step 6: objective=0.253083 reg=0.013225
2017/08/29 22:56:04 step 7: objective=0.253478 reg=0.013222
2017/08/29 22:56:04 Training value function...
2017/08/29 22:56:10 step 0: mse=1.120787 step=0.050000
2017/08/29 22:56:14 step 1: mse=1.120570 step=0.050000
2017/08/29 22:56:17 step 2: mse=1.120352 step=0.050000
2017/08/29 22:56:21 step 3: mse=1.120171 step=0.050000
2017/08/29 22:56:24 step 4: mse=1.120007 step=0.050000
2017/08/29 22:56:28 step 5: mse=1.119828 step=0.050000
2017/08/29 22:56:31 step 6: mse=1.119684 step=0.050000
2017/08/29 22:56:35 step 7: mse=1.119558 step=0.050000
2017/08/29 22:56:35 Saving...
2017/08/29 22:56:35 Gathering batch of experience...
2017/08/29 22:57:07 batch 290: mean=5.453964 stddev=1.485644 entropy=1.319132 frames=100140 count=5007
2017/08/29 22:57:07 Training policy...
2017/08/29 22:57:23 step 0: objective=0.246840 reg=0.013191
2017/08/29 22:57:31 step 1: objective=0.247605 reg=0.013185
2017/08/29 22:57:39 step 2: objective=0.248338 reg=0.013185
2017/08/29 22:57:48 step 3: objective=0.248799 reg=0.013174
2017/08/29 22:57:56 step 4: objective=0.249173 reg=0.013179
2017/08/29 22:58:05 step 5: objective=0.249587 reg=0.013164
2017/08/29 22:58:14 step 6: objective=0.249844 reg=0.013174
2017/08/29 22:58:22 step 7: objective=0.250277 reg=0.013172
2017/08/29 22:58:22 Training value function...
2017/08/29 22:58:28 step 0: mse=1.159140 step=0.050000
2017/08/29 22:58:31 step 1: mse=1.159237 step=0.050000
2017/08/29 22:58:35 step 2: mse=1.159339 step=0.050000
2017/08/29 22:58:38 step 3: mse=1.159424 step=0.050000
2017/08/29 22:58:41 step 4: mse=1.159528 step=0.050000
2017/08/29 22:58:45 step 5: mse=1.159622 step=0.050000
2017/08/29 22:58:48 step 6: mse=1.159704 step=0.050000
2017/08/29 22:58:52 step 7: mse=1.159776 step=0.050000
2017/08/29 22:58:52 Saving...
2017/08/29 22:58:52 Gathering batch of experience...
2017/08/29 22:59:24 batch 291: mean=5.431196 stddev=1.464857 entropy=1.318749 frames=100140 count=5007
2017/08/29 22:59:24 Training policy...
2017/08/29 22:59:40 step 0: objective=0.243527 reg=0.013187
2017/08/29 22:59:49 step 1: objective=0.244277 reg=0.013189
2017/08/29 22:59:57 step 2: objective=0.244871 reg=0.013190
2017/08/29 23:00:06 step 3: objective=0.245387 reg=0.013191
2017/08/29 23:00:14 step 4: objective=0.245793 reg=0.013189
2017/08/29 23:00:22 step 5: objective=0.246182 reg=0.013185
2017/08/29 23:00:31 step 6: objective=0.246655 reg=0.013183
2017/08/29 23:00:39 step 7: objective=0.247059 reg=0.013180
2017/08/29 23:00:39 Training value function...
2017/08/29 23:00:45 step 0: mse=1.116211 step=0.050000
2017/08/29 23:00:49 step 1: mse=1.116195 step=0.050000
2017/08/29 23:00:52 step 2: mse=1.116183 step=0.050000
2017/08/29 23:00:56 step 3: mse=1.116157 step=0.050000
2017/08/29 23:00:59 step 4: mse=1.116103 step=0.050000
2017/08/29 23:01:03 step 5: mse=1.116079 step=0.050000
2017/08/29 23:01:06 step 6: mse=1.116066 step=0.050000
2017/08/29 23:01:10 step 7: mse=1.116018 step=0.050000
2017/08/29 23:01:10 Saving...
2017/08/29 23:01:10 Gathering batch of experience...
2017/08/29 23:01:42 batch 292: mean=5.431196 stddev=1.455144 entropy=1.320394 frames=100140 count=5007
2017/08/29 23:01:42 Training policy...
2017/08/29 23:01:58 step 0: objective=0.244416 reg=0.013204
2017/08/29 23:02:06 step 1: objective=0.245100 reg=0.013201
2017/08/29 23:02:15 step 2: objective=0.245547 reg=0.013193
2017/08/29 23:02:23 step 3: objective=0.245827 reg=0.013206
2017/08/29 23:02:31 step 4: objective=0.246232 reg=0.013194
2017/08/29 23:02:40 step 5: objective=0.246611 reg=0.013204
2017/08/29 23:02:48 step 6: objective=0.247008 reg=0.013196
2017/08/29 23:02:57 step 7: objective=0.247548 reg=0.013192
2017/08/29 23:02:57 Training value function...
2017/08/29 23:03:03 step 0: mse=1.129510 step=0.050000
2017/08/29 23:03:06 step 1: mse=1.129292 step=0.050000
2017/08/29 23:03:10 step 2: mse=1.129097 step=0.050000
2017/08/29 23:03:13 step 3: mse=1.128920 step=0.050000
2017/08/29 23:03:17 step 4: mse=1.128758 step=0.050000
2017/08/29 23:03:20 step 5: mse=1.128604 step=0.050000
2017/08/29 23:03:24 step 6: mse=1.128461 step=0.050000
2017/08/29 23:03:27 step 7: mse=1.128327 step=0.050000
2017/08/29 23:03:27 Saving...
2017/08/29 23:03:27 Gathering batch of experience...
2017/08/29 23:04:00 batch 293: mean=5.459956 stddev=1.452237 entropy=1.312611 frames=100140 count=5007
2017/08/29 23:04:00 Training policy...
2017/08/29 23:04:16 step 0: objective=0.261305 reg=0.013126
2017/08/29 23:04:24 step 1: objective=0.262011 reg=0.013122
2017/08/29 23:04:33 step 2: objective=0.262757 reg=0.013117
2017/08/29 23:04:42 step 3: objective=0.263216 reg=0.013118
2017/08/29 23:04:50 step 4: objective=0.263876 reg=0.013113
2017/08/29 23:04:59 step 5: objective=0.264317 reg=0.013113
2017/08/29 23:05:07 step 6: objective=0.264793 reg=0.013110
2017/08/29 23:05:15 step 7: objective=0.265104 reg=0.013120
2017/08/29 23:05:15 Training value function...
2017/08/29 23:05:21 step 0: mse=1.130731 step=0.050000
2017/08/29 23:05:25 step 1: mse=1.129876 step=0.050000
2017/08/29 23:05:28 step 2: mse=1.129086 step=0.050000
2017/08/29 23:05:32 step 3: mse=1.128351 step=0.050000
2017/08/29 23:05:35 step 4: mse=1.127645 step=0.050000
2017/08/29 23:05:39 step 5: mse=1.126988 step=0.050000
2017/08/29 23:05:42 step 6: mse=1.126295 step=0.050000
2017/08/29 23:05:46 step 7: mse=1.125721 step=0.050000
2017/08/29 23:05:46 Saving...
2017/08/29 23:05:46 Gathering batch of experience...
2017/08/29 23:06:18 batch 294: mean=5.441182 stddev=1.429275 entropy=1.316701 frames=100140 count=5007
2017/08/29 23:06:18 Training policy...
2017/08/29 23:06:34 step 0: objective=0.247317 reg=0.013167
2017/08/29 23:06:42 step 1: objective=0.248059 reg=0.013169
2017/08/29 23:06:51 step 2: objective=0.248525 reg=0.013164
2017/08/29 23:06:59 step 3: objective=0.248894 reg=0.013179
2017/08/29 23:07:08 step 4: objective=0.249396 reg=0.013177
2017/08/29 23:07:16 step 5: objective=0.249870 reg=0.013176
2017/08/29 23:07:25 step 6: objective=0.250307 reg=0.013174
2017/08/29 23:07:33 step 7: objective=0.250689 reg=0.013170
2017/08/29 23:07:33 Training value function...
2017/08/29 23:07:39 step 0: mse=1.120672 step=0.050000
2017/08/29 23:07:43 step 1: mse=1.120532 step=0.050000
2017/08/29 23:07:46 step 2: mse=1.120407 step=0.050000
2017/08/29 23:07:50 step 3: mse=1.120296 step=0.050000
2017/08/29 23:07:53 step 4: mse=1.120199 step=0.050000
2017/08/29 23:07:57 step 5: mse=1.120100 step=0.050000
2017/08/29 23:08:00 step 6: mse=1.120009 step=0.050000
2017/08/29 23:08:04 step 7: mse=1.119919 step=0.050000
2017/08/29 23:08:04 Saving...
2017/08/29 23:08:04 Gathering batch of experience...
2017/08/29 23:08:36 batch 295: mean=5.478730 stddev=1.486339 entropy=1.312057 frames=100140 count=5007
2017/08/29 23:08:36 Training policy...
2017/08/29 23:08:53 step 0: objective=0.266487 reg=0.013120
2017/08/29 23:09:01 step 1: objective=0.267357 reg=0.013122
2017/08/29 23:09:10 step 2: objective=0.268041 reg=0.013122
2017/08/29 23:09:18 step 3: objective=0.268458 reg=0.013115
2017/08/29 23:09:27 step 4: objective=0.268915 reg=0.013108
2017/08/29 23:09:35 step 5: objective=0.269378 reg=0.013107
2017/08/29 23:09:43 step 6: objective=0.269769 reg=0.013107
2017/08/29 23:09:52 step 7: objective=0.270123 reg=0.013106
2017/08/29 23:09:52 Training value function...
2017/08/29 23:09:58 step 0: mse=1.180739 step=0.050000
2017/08/29 23:10:01 step 1: mse=1.179453 step=0.050000
2017/08/29 23:10:05 step 2: mse=1.178252 step=0.050000
2017/08/29 23:10:08 step 3: mse=1.177129 step=0.050000
2017/08/29 23:10:12 step 4: mse=1.176062 step=0.050000
2017/08/29 23:10:15 step 5: mse=1.175024 step=0.050000
2017/08/29 23:10:19 step 6: mse=1.174090 step=0.050000
2017/08/29 23:10:22 step 7: mse=1.173201 step=0.050000
2017/08/29 23:10:22 Saving...
2017/08/29 23:10:22 Gathering batch of experience...
2017/08/29 23:10:55 batch 296: mean=5.475335 stddev=1.468442 entropy=1.312454 frames=100140 count=5007
2017/08/29 23:10:55 Training policy...
2017/08/29 23:11:11 step 0: objective=0.252850 reg=0.013125
2017/08/29 23:11:20 step 1: objective=0.253428 reg=0.013122
2017/08/29 23:11:29 step 2: objective=0.254096 reg=0.013120
2017/08/29 23:11:37 step 3: objective=0.254665 reg=0.013118
2017/08/29 23:11:46 step 4: objective=0.255044 reg=0.013121
2017/08/29 23:11:54 step 5: objective=0.255521 reg=0.013119
2017/08/29 23:12:03 step 6: objective=0.256069 reg=0.013112
2017/08/29 23:12:11 step 7: objective=0.256428 reg=0.013118
2017/08/29 23:12:11 Training value function...
2017/08/29 23:12:17 step 0: mse=1.144959 step=0.050000
2017/08/29 23:12:21 step 1: mse=1.144336 step=0.050000
2017/08/29 23:12:24 step 2: mse=1.143740 step=0.050000
2017/08/29 23:12:27 step 3: mse=1.143189 step=0.050000
2017/08/29 23:12:31 step 4: mse=1.142703 step=0.050000
2017/08/29 23:12:34 step 5: mse=1.142198 step=0.050000
2017/08/29 23:12:38 step 6: mse=1.141753 step=0.050000
2017/08/29 23:12:41 step 7: mse=1.141317 step=0.050000
2017/08/29 23:12:41 Saving...
2017/08/29 23:12:42 Gathering batch of experience...
2017/08/29 23:13:14 batch 297: mean=5.452367 stddev=1.459827 entropy=1.313321 frames=100140 count=5007
2017/08/29 23:13:14 Training policy...
2017/08/29 23:13:30 step 0: objective=0.247218 reg=0.013133
2017/08/29 23:13:39 step 1: objective=0.247830 reg=0.013133
2017/08/29 23:13:47 step 2: objective=0.248394 reg=0.013137
2017/08/29 23:13:56 step 3: objective=0.248921 reg=0.013132
2017/08/29 23:14:04 step 4: objective=0.249487 reg=0.013128
2017/08/29 23:14:12 step 5: objective=0.249966 reg=0.013128
2017/08/29 23:14:21 step 6: objective=0.250396 reg=0.013124
2017/08/29 23:14:29 step 7: objective=0.250873 reg=0.013121
2017/08/29 23:14:29 Training value function...
2017/08/29 23:14:35 step 0: mse=1.164432 step=0.050000
2017/08/29 23:14:39 step 1: mse=1.164546 step=0.050000
2017/08/29 23:14:42 step 2: mse=1.164667 step=0.050000
2017/08/29 23:14:46 step 3: mse=1.164792 step=0.050000
2017/08/29 23:14:49 step 4: mse=1.164927 step=0.050000
2017/08/29 23:14:53 step 5: mse=1.165045 step=0.050000
2017/08/29 23:14:56 step 6: mse=1.165145 step=0.050000
2017/08/29 23:15:00 step 7: mse=1.165256 step=0.050000
2017/08/29 23:15:00 Saving...
2017/08/29 23:15:00 Gathering batch of experience...
2017/08/29 23:15:32 batch 298: mean=5.429199 stddev=1.488700 entropy=1.307266 frames=100140 count=5007
2017/08/29 23:15:32 Training policy...
2017/08/29 23:15:49 step 0: objective=0.247566 reg=0.013073
2017/08/29 23:15:57 step 1: objective=0.248527 reg=0.013070
2017/08/29 23:16:06 step 2: objective=0.249107 reg=0.013069
2017/08/29 23:16:14 step 3: objective=0.249603 reg=0.013072
2017/08/29 23:16:23 step 4: objective=0.250108 reg=0.013072
2017/08/29 23:16:31 step 5: objective=0.250624 reg=0.013068
2017/08/29 23:16:40 step 6: objective=0.251055 reg=0.013065
2017/08/29 23:16:48 step 7: objective=0.251499 reg=0.013064
2017/08/29 23:16:48 Training value function...
2017/08/29 23:16:54 step 0: mse=1.157118 step=0.050000
2017/08/29 23:16:58 step 1: mse=1.157135 step=0.050000
2017/08/29 23:17:01 step 2: mse=1.157161 step=0.050000
2017/08/29 23:17:05 step 3: mse=1.157193 step=0.050000
2017/08/29 23:17:08 step 4: mse=1.157213 step=0.050000
2017/08/29 23:17:12 step 5: mse=1.157158 step=0.050000
2017/08/29 23:17:15 step 6: mse=1.157098 step=0.050000
2017/08/29 23:17:19 step 7: mse=1.157072 step=0.050000
2017/08/29 23:17:19 Saving...
2017/08/29 23:17:19 Gathering batch of experience...
2017/08/29 23:17:51 batch 299: mean=5.442381 stddev=1.479581 entropy=1.303205 frames=100140 count=5007
2017/08/29 23:17:51 Training policy...
2017/08/29 23:18:07 step 0: objective=0.247212 reg=0.013032
2017/08/29 23:18:16 step 1: objective=0.247959 reg=0.013029
2017/08/29 23:18:25 step 2: objective=0.248841 reg=0.013028
2017/08/29 23:18:34 step 3: objective=0.249411 reg=0.013031
2017/08/29 23:18:42 step 4: objective=0.249968 reg=0.013034
2017/08/29 23:18:51 step 5: objective=0.250381 reg=0.013033
2017/08/29 23:19:00 step 6: objective=0.250591 reg=0.013039
2017/08/29 23:19:09 step 7: objective=0.250874 reg=0.013032
2017/08/29 23:19:09 Training value function...
2017/08/29 23:19:15 step 0: mse=1.166175 step=0.050000
2017/08/29 23:19:18 step 1: mse=1.166147 step=0.050000
2017/08/29 23:19:21 step 2: mse=1.166133 step=0.050000
2017/08/29 23:19:25 step 3: mse=1.166147 step=0.050000
2017/08/29 23:19:28 step 4: mse=1.166162 step=0.050000
2017/08/29 23:19:32 step 5: mse=1.166194 step=0.050000
2017/08/29 23:19:35 step 6: mse=1.166222 step=0.050000
2017/08/29 23:19:39 step 7: mse=1.166232 step=0.050000
2017/08/29 23:19:39 Saving...
2017/08/29 23:19:39 Gathering batch of experience...
2017/08/29 23:20:12 batch 300: mean=5.457559 stddev=1.454093 entropy=1.310059 frames=100140 count=5007
2017/08/29 23:20:12 Training policy...
2017/08/29 23:20:27 step 0: objective=0.254462 reg=0.013100
2017/08/29 23:20:36 step 1: objective=0.255219 reg=0.013096
2017/08/29 23:20:45 step 2: objective=0.255850 reg=0.013099
2017/08/29 23:20:54 step 3: objective=0.256319 reg=0.013094
2017/08/29 23:21:02 step 4: objective=0.256646 reg=0.013103
2017/08/29 23:21:11 step 5: objective=0.257015 reg=0.013085
2017/08/29 23:21:19 step 6: objective=0.257363 reg=0.013097
2017/08/29 23:21:28 step 7: objective=0.257615 reg=0.013074
2017/08/29 23:21:28 Training value function...
2017/08/29 23:21:34 step 0: mse=1.138231 step=0.050000
2017/08/29 23:21:37 step 1: mse=1.137728 step=0.050000
2017/08/29 23:21:41 step 2: mse=1.137266 step=0.050000
2017/08/29 23:21:44 step 3: mse=1.136799 step=0.050000
2017/08/29 23:21:48 step 4: mse=1.136397 step=0.050000
2017/08/29 23:21:51 step 5: mse=1.136033 step=0.050000
2017/08/29 23:21:55 step 6: mse=1.135683 step=0.050000
2017/08/29 23:21:58 step 7: mse=1.135355 step=0.050000
2017/08/29 23:21:58 Saving...
2017/08/29 23:21:58 Gathering batch of experience...
2017/08/29 23:22:31 batch 301: mean=5.461354 stddev=1.470044 entropy=1.306836 frames=100140 count=5007
2017/08/29 23:22:31 Training policy...
2017/08/29 23:22:47 step 0: objective=0.252955 reg=0.013068
2017/08/29 23:22:55 step 1: objective=0.253798 reg=0.013063
2017/08/29 23:23:04 step 2: objective=0.254416 reg=0.013062
2017/08/29 23:23:13 step 3: objective=0.254996 reg=0.013057
2017/08/29 23:23:21 step 4: objective=0.255504 reg=0.013055
2017/08/29 23:23:30 step 5: objective=0.255993 reg=0.013055
2017/08/29 23:23:38 step 6: objective=0.256476 reg=0.013047
2017/08/29 23:23:47 step 7: objective=0.256829 reg=0.013049
2017/08/29 23:23:47 Training value function...
2017/08/29 23:23:53 step 0: mse=1.177947 step=0.050000
2017/08/29 23:23:56 step 1: mse=1.177585 step=0.050000
2017/08/29 23:24:00 step 2: mse=1.177255 step=0.050000
2017/08/29 23:24:03 step 3: mse=1.176951 step=0.050000
2017/08/29 23:24:07 step 4: mse=1.176625 step=0.050000
2017/08/29 23:24:11 step 5: mse=1.176322 step=0.050000
2017/08/29 23:24:14 step 6: mse=1.176039 step=0.050000
2017/08/29 23:24:17 step 7: mse=1.175766 step=0.050000
2017/08/29 23:24:17 Saving...
2017/08/29 23:24:18 Gathering batch of experience...
2017/08/29 23:24:50 batch 302: mean=5.468145 stddev=1.459983 entropy=1.303124 frames=100140 count=5007
2017/08/29 23:24:50 Training policy...
2017/08/29 23:25:07 step 0: objective=0.258069 reg=0.013031
2017/08/29 23:25:16 step 1: objective=0.258689 reg=0.013029
2017/08/29 23:25:24 step 2: objective=0.259296 reg=0.013029
2017/08/29 23:25:33 step 3: objective=0.259897 reg=0.013018
2017/08/29 23:25:42 step 4: objective=0.260463 reg=0.013017
2017/08/29 23:25:50 step 5: objective=0.260948 reg=0.013018
2017/08/29 23:25:59 step 6: objective=0.261335 reg=0.013013
2017/08/29 23:26:08 step 7: objective=0.261784 reg=0.013017
2017/08/29 23:26:08 Training value function...
2017/08/29 23:26:14 step 0: mse=1.147353 step=0.050000
2017/08/29 23:26:17 step 1: mse=1.146771 step=0.050000
2017/08/29 23:26:21 step 2: mse=1.146231 step=0.050000
2017/08/29 23:26:24 step 3: mse=1.145730 step=0.050000
2017/08/29 23:26:28 step 4: mse=1.145251 step=0.050000
2017/08/29 23:26:31 step 5: mse=1.144803 step=0.050000
2017/08/29 23:26:35 step 6: mse=1.144390 step=0.050000
2017/08/29 23:26:38 step 7: mse=1.143991 step=0.050000
2017/08/29 23:26:38 Saving...
2017/08/29 23:26:38 Gathering batch of experience...
2017/08/29 23:27:11 batch 303: mean=5.476733 stddev=1.456447 entropy=1.297020 frames=100140 count=5007
2017/08/29 23:27:11 Training policy...
2017/08/29 23:27:27 step 0: objective=0.262615 reg=0.012970
2017/08/29 23:27:36 step 1: objective=0.263338 reg=0.012966
2017/08/29 23:27:45 step 2: objective=0.263910 reg=0.012965
2017/08/29 23:27:53 step 3: objective=0.264619 reg=0.012964
2017/08/29 23:28:02 step 4: objective=0.265200 reg=0.012963
2017/08/29 23:28:11 step 5: objective=0.265792 reg=0.012963
2017/08/29 23:28:19 step 6: objective=0.266266 reg=0.012957
2017/08/29 23:28:29 step 7: objective=0.266815 reg=0.012953
2017/08/29 23:28:29 Training value function...
2017/08/29 23:28:35 step 0: mse=1.168367 step=0.050000
2017/08/29 23:28:38 step 1: mse=1.167487 step=0.050000
2017/08/29 23:28:42 step 2: mse=1.166674 step=0.050000
2017/08/29 23:28:45 step 3: mse=1.165922 step=0.050000
2017/08/29 23:28:49 step 4: mse=1.165220 step=0.050000
2017/08/29 23:28:52 step 5: mse=1.164559 step=0.050000
2017/08/29 23:28:56 step 6: mse=1.163944 step=0.050000
2017/08/29 23:28:59 step 7: mse=1.163365 step=0.050000
2017/08/29 23:28:59 Saving...
2017/08/29 23:28:59 Gathering batch of experience...
2017/08/29 23:29:32 batch 304: mean=5.461354 stddev=1.445382 entropy=1.297421 frames=100140 count=5007
2017/08/29 23:29:32 Training policy...
2017/08/29 23:29:49 step 0: objective=0.241698 reg=0.012974
2017/08/29 23:29:58 step 1: objective=0.242446 reg=0.012976
2017/08/29 23:30:07 step 2: objective=0.242970 reg=0.012976
2017/08/29 23:30:16 step 3: objective=0.243342 reg=0.012971
2017/08/29 23:30:24 step 4: objective=0.243665 reg=0.012986
2017/08/29 23:30:33 step 5: objective=0.244057 reg=0.012974
2017/08/29 23:30:42 step 6: objective=0.244426 reg=0.012980
2017/08/29 23:30:50 step 7: objective=0.244731 reg=0.012966
2017/08/29 23:30:50 Training value function...
2017/08/29 23:30:56 step 0: mse=1.114192 step=0.050000
2017/08/29 23:31:00 step 1: mse=1.114434 step=0.050000
2017/08/29 23:31:03 step 2: mse=1.114674 step=0.050000
2017/08/29 23:31:07 step 3: mse=1.114894 step=0.050000
2017/08/29 23:31:10 step 4: mse=1.115125 step=0.050000
2017/08/29 23:31:14 step 5: mse=1.115341 step=0.050000
2017/08/29 23:31:17 step 6: mse=1.115528 step=0.050000
2017/08/29 23:31:21 step 7: mse=1.115705 step=0.050000
2017/08/29 23:31:21 Saving...
2017/08/29 23:31:21 Gathering batch of experience...
2017/08/29 23:31:54 batch 305: mean=5.494308 stddev=1.475557 entropy=1.298411 frames=100140 count=5007
2017/08/29 23:31:54 Training policy...
2017/08/29 23:32:10 step 0: objective=0.261597 reg=0.012984
2017/08/29 23:32:18 step 1: objective=0.262351 reg=0.012989
2017/08/29 23:32:27 step 2: objective=0.262931 reg=0.012988
2017/08/29 23:32:36 step 3: objective=0.263535 reg=0.012990
2017/08/29 23:32:45 step 4: objective=0.264035 reg=0.012985
2017/08/29 23:32:53 step 5: objective=0.264441 reg=0.012980
2017/08/29 23:33:02 step 6: objective=0.264732 reg=0.012987
2017/08/29 23:33:11 step 7: objective=0.265035 reg=0.012975
2017/08/29 23:33:11 Training value function...
2017/08/29 23:33:17 step 0: mse=1.193855 step=0.050000
2017/08/29 23:33:20 step 1: mse=1.192986 step=0.050000
2017/08/29 23:33:24 step 2: mse=1.192186 step=0.050000
2017/08/29 23:33:27 step 3: mse=1.191447 step=0.050000
2017/08/29 23:33:31 step 4: mse=1.190758 step=0.050000
2017/08/29 23:33:34 step 5: mse=1.190119 step=0.050000
2017/08/29 23:33:38 step 6: mse=1.189522 step=0.050000
2017/08/29 23:33:41 step 7: mse=1.188931 step=0.050000
2017/08/29 23:33:41 Saving...
2017/08/29 23:33:42 Gathering batch of experience...
2017/08/29 23:34:14 batch 306: mean=5.472139 stddev=1.467705 entropy=1.302265 frames=100140 count=5007
2017/08/29 23:34:14 Training policy...
2017/08/29 23:34:31 step 0: objective=0.244972 reg=0.013023
2017/08/29 23:34:40 step 1: objective=0.245539 reg=0.013023
2017/08/29 23:34:49 step 2: objective=0.246284 reg=0.013020
2017/08/29 23:34:57 step 3: objective=0.246825 reg=0.013018
2017/08/29 23:35:06 step 4: objective=0.247352 reg=0.013019
2017/08/29 23:35:15 step 5: objective=0.247866 reg=0.013013
2017/08/29 23:35:24 step 6: objective=0.248328 reg=0.013007
2017/08/29 23:35:32 step 7: objective=0.248643 reg=0.013015
2017/08/29 23:35:32 Training value function...
2017/08/29 23:35:38 step 0: mse=1.186991 step=0.050000
2017/08/29 23:35:42 step 1: mse=1.187356 step=0.050000
2017/08/29 23:35:45 step 2: mse=1.187715 step=0.050000
2017/08/29 23:35:49 step 3: mse=1.187999 step=0.050000
2017/08/29 23:35:52 step 4: mse=1.188289 step=0.050000
2017/08/29 23:35:56 step 5: mse=1.188507 step=0.050000
2017/08/29 23:35:59 step 6: mse=1.188735 step=0.050000
2017/08/29 23:36:03 step 7: mse=1.188920 step=0.050000
2017/08/29 23:36:03 Saving...
2017/08/29 23:36:03 Gathering batch of experience...
2017/08/29 23:36:36 batch 307: mean=5.461554 stddev=1.469913 entropy=1.300197 frames=100140 count=5007
2017/08/29 23:36:36 Training policy...
2017/08/29 23:36:52 step 0: objective=0.253852 reg=0.013002
2017/08/29 23:37:02 step 1: objective=0.254712 reg=0.013005
2017/08/29 23:37:11 step 2: objective=0.255216 reg=0.013007
2017/08/29 23:37:19 step 3: objective=0.255809 reg=0.013012
2017/08/29 23:37:28 step 4: objective=0.256328 reg=0.013015
2017/08/29 23:37:37 step 5: objective=0.256656 reg=0.013015
2017/08/29 23:37:46 step 6: objective=0.257104 reg=0.013014
2017/08/29 23:37:54 step 7: objective=0.257496 reg=0.013008
2017/08/29 23:37:54 Training value function...
2017/08/29 23:38:00 step 0: mse=1.191209 step=0.050000
2017/08/29 23:38:04 step 1: mse=1.190672 step=0.050000
2017/08/29 23:38:07 step 2: mse=1.190170 step=0.050000
2017/08/29 23:38:11 step 3: mse=1.189710 step=0.050000
2017/08/29 23:38:14 step 4: mse=1.189234 step=0.050000
2017/08/29 23:38:18 step 5: mse=1.188797 step=0.050000
2017/08/29 23:38:21 step 6: mse=1.188395 step=0.050000
2017/08/29 23:38:25 step 7: mse=1.188003 step=0.050000
2017/08/29 23:38:25 Saving...
2017/08/29 23:38:25 Gathering batch of experience...
2017/08/29 23:38:58 batch 308: mean=5.459956 stddev=1.461969 entropy=1.298889 frames=100140 count=5007
2017/08/29 23:38:58 Training policy...
2017/08/29 23:39:14 step 0: objective=0.246074 reg=0.012989
2017/08/29 23:39:23 step 1: objective=0.247004 reg=0.012992
2017/08/29 23:39:32 step 2: objective=0.247736 reg=0.012983
2017/08/29 23:39:41 step 3: objective=0.248277 reg=0.012986
2017/08/29 23:39:49 step 4: objective=0.248772 reg=0.012987
2017/08/29 23:39:58 step 5: objective=0.249204 reg=0.012985
2017/08/29 23:40:07 step 6: objective=0.249622 reg=0.012983
2017/08/29 23:40:16 step 7: objective=0.250060 reg=0.012979
2017/08/29 23:40:16 Training value function...
2017/08/29 23:40:22 step 0: mse=1.134451 step=0.050000
2017/08/29 23:40:25 step 1: mse=1.134582 step=0.050000
2017/08/29 23:40:29 step 2: mse=1.134721 step=0.050000
2017/08/29 23:40:32 step 3: mse=1.134858 step=0.050000
2017/08/29 23:40:36 step 4: mse=1.134998 step=0.050000
2017/08/29 23:40:39 step 5: mse=1.135131 step=0.050000
2017/08/29 23:40:43 step 6: mse=1.135259 step=0.050000
2017/08/29 23:40:46 step 7: mse=1.135380 step=0.050000
2017/08/29 23:40:46 Saving...
2017/08/29 23:40:46 Gathering batch of experience...
2017/08/29 23:41:19 batch 309: mean=5.487318 stddev=1.429450 entropy=1.293035 frames=100140 count=5007
2017/08/29 23:41:19 Training policy...
2017/08/29 23:41:35 step 0: objective=0.258282 reg=0.012930
2017/08/29 23:41:44 step 1: objective=0.259148 reg=0.012932
2017/08/29 23:41:53 step 2: objective=0.259816 reg=0.012929
2017/08/29 23:42:02 step 3: objective=0.260441 reg=0.012928
2017/08/29 23:42:11 step 4: objective=0.260917 reg=0.012932
2017/08/29 23:42:20 step 5: objective=0.261378 reg=0.012930
2017/08/29 23:42:28 step 6: objective=0.261733 reg=0.012926
2017/08/29 23:42:37 step 7: objective=0.262072 reg=0.012930
2017/08/29 23:42:37 Training value function...
2017/08/29 23:42:43 step 0: mse=1.146042 step=0.050000
2017/08/29 23:42:47 step 1: mse=1.145171 step=0.050000
2017/08/29 23:42:50 step 2: mse=1.144359 step=0.050000
2017/08/29 23:42:54 step 3: mse=1.143605 step=0.050000
2017/08/29 23:42:57 step 4: mse=1.142883 step=0.050000
2017/08/29 23:43:01 step 5: mse=1.142203 step=0.050000
2017/08/29 23:43:04 step 6: mse=1.141564 step=0.050000
2017/08/29 23:43:08 step 7: mse=1.140954 step=0.050000
2017/08/29 23:43:08 Saving...
2017/08/29 23:43:08 Gathering batch of experience...
2017/08/29 23:43:41 batch 310: mean=5.461354 stddev=1.481412 entropy=1.291427 frames=100140 count=5007
2017/08/29 23:43:41 Training policy...
2017/08/29 23:43:57 step 0: objective=0.248802 reg=0.012914
2017/08/29 23:44:06 step 1: objective=0.249499 reg=0.012914
2017/08/29 23:44:14 step 2: objective=0.249930 reg=0.012930
2017/08/29 23:44:23 step 3: objective=0.250428 reg=0.012919
2017/08/29 23:44:32 step 4: objective=0.250887 reg=0.012933
2017/08/29 23:44:41 step 5: objective=0.251199 reg=0.012924
2017/08/29 23:44:50 step 6: objective=0.251501 reg=0.012941
2017/08/29 23:44:59 step 7: objective=0.251870 reg=0.012921
2017/08/29 23:44:59 Training value function...
2017/08/29 23:45:05 step 0: mse=1.159999 step=0.050000
2017/08/29 23:45:08 step 1: mse=1.159735 step=0.050000
2017/08/29 23:45:12 step 2: mse=1.159500 step=0.050000
2017/08/29 23:45:15 step 3: mse=1.159289 step=0.050000
2017/08/29 23:45:19 step 4: mse=1.159098 step=0.050000
2017/08/29 23:45:22 step 5: mse=1.158921 step=0.050000
2017/08/29 23:45:26 step 6: mse=1.158756 step=0.050000
2017/08/29 23:45:29 step 7: mse=1.158600 step=0.050000
2017/08/29 23:45:29 Saving...
2017/08/29 23:45:29 Gathering batch of experience...
2017/08/29 23:46:02 batch 311: mean=5.482125 stddev=1.467860 entropy=1.293810 frames=100140 count=5007
2017/08/29 23:46:02 Training policy...
2017/08/29 23:46:18 step 0: objective=0.263980 reg=0.012938
2017/08/29 23:46:27 step 1: objective=0.264612 reg=0.012939
2017/08/29 23:46:36 step 2: objective=0.265265 reg=0.012936
2017/08/29 23:46:45 step 3: objective=0.265615 reg=0.012926
2017/08/29 23:46:54 step 4: objective=0.265964 reg=0.012940
2017/08/29 23:47:02 step 5: objective=0.266372 reg=0.012923
2017/08/29 23:47:11 step 6: objective=0.266744 reg=0.012937
2017/08/29 23:47:20 step 7: objective=0.267073 reg=0.012922
2017/08/29 23:47:20 Training value function...
2017/08/29 23:47:26 step 0: mse=1.189226 step=0.050000
2017/08/29 23:47:30 step 1: mse=1.187818 step=0.050000
2017/08/29 23:47:33 step 2: mse=1.186511 step=0.050000
2017/08/29 23:47:37 step 3: mse=1.185295 step=0.050000
2017/08/29 23:47:40 step 4: mse=1.184157 step=0.050000
2017/08/29 23:47:44 step 5: mse=1.183089 step=0.050000
2017/08/29 23:47:47 step 6: mse=1.182089 step=0.050000
2017/08/29 23:47:51 step 7: mse=1.181113 step=0.050000
2017/08/29 23:47:51 Saving...
2017/08/29 23:47:51 Gathering batch of experience...
2017/08/29 23:48:24 batch 312: mean=5.474935 stddev=1.448855 entropy=1.295269 frames=100140 count=5007
2017/08/29 23:48:24 Training policy...
2017/08/29 23:48:40 step 0: objective=0.253321 reg=0.012953
2017/08/29 23:48:49 step 1: objective=0.254036 reg=0.012953
2017/08/29 23:48:58 step 2: objective=0.254762 reg=0.012949
2017/08/29 23:49:07 step 3: objective=0.255469 reg=0.012953
2017/08/29 23:49:16 step 4: objective=0.255898 reg=0.012950
2017/08/29 23:49:25 step 5: objective=0.256334 reg=0.012946
2017/08/29 23:49:34 step 6: objective=0.256723 reg=0.012942
2017/08/29 23:49:43 step 7: objective=0.257125 reg=0.012941
2017/08/29 23:49:43 Training value function...
2017/08/29 23:49:49 step 0: mse=1.149062 step=0.050000
2017/08/29 23:49:53 step 1: mse=1.148797 step=0.050000
2017/08/29 23:49:56 step 2: mse=1.148558 step=0.050000
2017/08/29 23:50:00 step 3: mse=1.148342 step=0.050000
2017/08/29 23:50:03 step 4: mse=1.148157 step=0.050000
2017/08/29 23:50:07 step 5: mse=1.147987 step=0.050000
2017/08/29 23:50:10 step 6: mse=1.147834 step=0.050000
2017/08/29 23:50:14 step 7: mse=1.147685 step=0.050000
2017/08/29 23:50:14 Saving...
2017/08/29 23:50:14 Gathering batch of experience...
2017/08/29 23:50:47 batch 313: mean=5.470142 stddev=1.456464 entropy=1.295830 frames=100140 count=5007
2017/08/29 23:50:47 Training policy...
2017/08/29 23:51:03 step 0: objective=0.246100 reg=0.012958
2017/08/29 23:51:12 step 1: objective=0.246867 reg=0.012955
2017/08/29 23:51:21 step 2: objective=0.247463 reg=0.012955
2017/08/29 23:51:30 step 3: objective=0.247999 reg=0.012953
2017/08/29 23:51:39 step 4: objective=0.248547 reg=0.012950
2017/08/29 23:51:48 step 5: objective=0.249003 reg=0.012951
2017/08/29 23:51:57 step 6: objective=0.249431 reg=0.012951
2017/08/29 23:52:06 step 7: objective=0.249850 reg=0.012947
2017/08/29 23:52:06 Training value function...
2017/08/29 23:52:12 step 0: mse=1.161524 step=0.050000
2017/08/29 23:52:16 step 1: mse=1.161716 step=0.050000
2017/08/29 23:52:19 step 2: mse=1.161917 step=0.050000
2017/08/29 23:52:23 step 3: mse=1.162116 step=0.050000
2017/08/29 23:52:26 step 4: mse=1.162310 step=0.050000
2017/08/29 23:52:30 step 5: mse=1.162496 step=0.050000
2017/08/29 23:52:33 step 6: mse=1.162673 step=0.050000
2017/08/29 23:52:37 step 7: mse=1.162841 step=0.050000
2017/08/29 23:52:37 Saving...
2017/08/29 23:52:37 Gathering batch of experience...
2017/08/29 23:53:10 batch 314: mean=5.464949 stddev=1.464553 entropy=1.293216 frames=100140 count=5007
2017/08/29 23:53:10 Training policy...
2017/08/29 23:53:27 step 0: objective=0.241942 reg=0.012932
2017/08/29 23:53:36 step 1: objective=0.242527 reg=0.012934
2017/08/29 23:53:45 step 2: objective=0.243144 reg=0.012932
2017/08/29 23:53:54 step 3: objective=0.243784 reg=0.012933
2017/08/29 23:54:03 step 4: objective=0.244317 reg=0.012926
2017/08/29 23:54:13 step 5: objective=0.244924 reg=0.012922
2017/08/29 23:54:22 step 6: objective=0.245465 reg=0.012919
2017/08/29 23:54:31 step 7: objective=0.245934 reg=0.012916
2017/08/29 23:54:31 Training value function...
2017/08/29 23:54:37 step 0: mse=1.148795 step=0.050000
2017/08/29 23:54:40 step 1: mse=1.148965 step=0.050000
2017/08/29 23:54:44 step 2: mse=1.149131 step=0.050000
2017/08/29 23:54:47 step 3: mse=1.149295 step=0.050000
2017/08/29 23:54:51 step 4: mse=1.149453 step=0.050000
2017/08/29 23:54:54 step 5: mse=1.149590 step=0.050000
2017/08/29 23:54:57 step 6: mse=1.149722 step=0.050000
2017/08/29 23:55:01 step 7: mse=1.149858 step=0.050000
2017/08/29 23:55:01 Saving...
2017/08/29 23:55:01 Gathering batch of experience...
2017/08/29 23:55:34 batch 315: mean=5.471340 stddev=1.466192 entropy=1.291915 frames=100140 count=5007
2017/08/29 23:55:34 Training policy...
2017/08/29 23:55:50 step 0: objective=0.256486 reg=0.012919
2017/08/29 23:55:59 step 1: objective=0.257202 reg=0.012914
2017/08/29 23:56:08 step 2: objective=0.257887 reg=0.012910
2017/08/29 23:56:17 step 3: objective=0.258391 reg=0.012900
2017/08/29 23:56:26 step 4: objective=0.259064 reg=0.012904
2017/08/29 23:56:35 step 5: objective=0.259688 reg=0.012903
2017/08/29 23:56:44 step 6: objective=0.260098 reg=0.012897
2017/08/29 23:56:53 step 7: objective=0.260520 reg=0.012899
2017/08/29 23:56:53 Training value function...
2017/08/29 23:56:59 step 0: mse=1.148545 step=0.050000
2017/08/29 23:57:03 step 1: mse=1.147792 step=0.050000
2017/08/29 23:57:06 step 2: mse=1.147097 step=0.050000
2017/08/29 23:57:10 step 3: mse=1.146454 step=0.050000
2017/08/29 23:57:13 step 4: mse=1.145854 step=0.050000
2017/08/29 23:57:17 step 5: mse=1.145297 step=0.050000
2017/08/29 23:57:20 step 6: mse=1.144781 step=0.050000
2017/08/29 23:57:24 step 7: mse=1.144297 step=0.050000
2017/08/29 23:57:24 Saving...
2017/08/29 23:57:24 Gathering batch of experience...
2017/08/29 23:57:57 batch 316: mean=5.466747 stddev=1.474652 entropy=1.287927 frames=100140 count=5007
2017/08/29 23:57:57 Training policy...
2017/08/29 23:58:14 step 0: objective=0.249909 reg=0.012879
2017/08/29 23:58:24 step 1: objective=0.250608 reg=0.012875
2017/08/29 23:58:33 step 2: objective=0.251173 reg=0.012877
2017/08/29 23:58:42 step 3: objective=0.251832 reg=0.012871
2017/08/29 23:58:51 step 4: objective=0.252392 reg=0.012871
2017/08/29 23:59:00 step 5: objective=0.252794 reg=0.012871
2017/08/29 23:59:09 step 6: objective=0.253207 reg=0.012871
2017/08/29 23:59:18 step 7: objective=0.253609 reg=0.012873
2017/08/29 23:59:18 Training value function...
2017/08/29 23:59:24 step 0: mse=1.149844 step=0.050000
2017/08/29 23:59:28 step 1: mse=1.149241 step=0.050000
2017/08/29 23:59:31 step 2: mse=1.148682 step=0.050000
2017/08/29 23:59:35 step 3: mse=1.148165 step=0.050000
2017/08/29 23:59:38 step 4: mse=1.147651 step=0.050000
2017/08/29 23:59:42 step 5: mse=1.147175 step=0.050000
2017/08/29 23:59:45 step 6: mse=1.146728 step=0.050000
2017/08/29 23:59:49 step 7: mse=1.146310 step=0.050000
2017/08/29 23:59:49 Saving...
2017/08/29 23:59:49 Gathering batch of experience...
2017/08/30 00:00:22 batch 317: mean=5.502896 stddev=1.489978 entropy=1.280454 frames=100140 count=5007
2017/08/30 00:00:22 Training policy...
2017/08/30 00:00:38 step 0: objective=0.271630 reg=0.012805
2017/08/30 00:00:47 step 1: objective=0.272406 reg=0.012804
2017/08/30 00:00:56 step 2: objective=0.272875 reg=0.012805
2017/08/30 00:01:05 step 3: objective=0.273526 reg=0.012804
2017/08/30 00:01:15 step 4: objective=0.274028 reg=0.012800
2017/08/30 00:01:23 step 5: objective=0.274565 reg=0.012796
2017/08/30 00:01:32 step 6: objective=0.274972 reg=0.012794
2017/08/30 00:01:41 step 7: objective=0.275394 reg=0.012790
2017/08/30 00:01:41 Training value function...
2017/08/30 00:01:47 step 0: mse=1.201860 step=0.050000
2017/08/30 00:01:51 step 1: mse=1.200187 step=0.050000
2017/08/30 00:01:54 step 2: mse=1.198622 step=0.050000
2017/08/30 00:01:58 step 3: mse=1.197159 step=0.050000
2017/08/30 00:02:01 step 4: mse=1.195790 step=0.050000
2017/08/30 00:02:05 step 5: mse=1.194508 step=0.050000
2017/08/30 00:02:08 step 6: mse=1.193254 step=0.050000
2017/08/30 00:02:12 step 7: mse=1.192118 step=0.050000
2017/08/30 00:02:12 Saving...
2017/08/30 00:02:12 Gathering batch of experience...
2017/08/30 00:02:45 batch 318: mean=5.452367 stddev=1.462151 entropy=1.289891 frames=100140 count=5007
2017/08/30 00:02:45 Training policy...
2017/08/30 00:03:01 step 0: objective=0.225667 reg=0.012899
2017/08/30 00:03:10 step 1: objective=0.226309 reg=0.012904
2017/08/30 00:03:20 step 2: objective=0.226931 reg=0.012902
2017/08/30 00:03:29 step 3: objective=0.227553 reg=0.012905
2017/08/30 00:03:38 step 4: objective=0.228116 reg=0.012899
2017/08/30 00:03:47 step 5: objective=0.228593 reg=0.012897
2017/08/30 00:03:56 step 6: objective=0.229003 reg=0.012893
2017/08/30 00:04:05 step 7: objective=0.229374 reg=0.012894
2017/08/30 00:04:05 Training value function...
2017/08/30 00:04:11 step 0: mse=1.094161 step=0.050000
2017/08/30 00:04:14 step 1: mse=1.095199 step=0.050000
2017/08/30 00:04:18 step 2: mse=1.096196 step=0.050000
2017/08/30 00:04:21 step 3: mse=1.097146 step=0.050000
2017/08/30 00:04:25 step 4: mse=1.098054 step=0.050000
2017/08/30 00:04:28 step 5: mse=1.098914 step=0.050000
2017/08/30 00:04:32 step 6: mse=1.099731 step=0.050000
2017/08/30 00:04:35 step 7: mse=1.100450 step=0.050000
2017/08/30 00:04:35 Saving...
2017/08/30 00:04:35 Gathering batch of experience...
2017/08/30 00:05:09 batch 319: mean=5.490713 stddev=1.448077 entropy=1.281047 frames=100140 count=5007
2017/08/30 00:05:09 Training policy...
2017/08/30 00:05:25 step 0: objective=0.253685 reg=0.012810
2017/08/30 00:05:34 step 1: objective=0.254352 reg=0.012808
2017/08/30 00:05:43 step 2: objective=0.254882 reg=0.012803
2017/08/30 00:05:52 step 3: objective=0.255276 reg=0.012807
2017/08/30 00:06:01 step 4: objective=0.255521 reg=0.012795
2017/08/30 00:06:10 step 5: objective=0.255754 reg=0.012803
2017/08/30 00:06:19 step 6: objective=0.255973 reg=0.012795
2017/08/30 00:06:28 step 7: objective=0.256377 reg=0.012802
2017/08/30 00:06:28 Training value function...
2017/08/30 00:06:34 step 0: mse=1.139432 step=0.050000
2017/08/30 00:06:38 step 1: mse=1.138796 step=0.050000
2017/08/30 00:06:41 step 2: mse=1.138217 step=0.050000
2017/08/30 00:06:45 step 3: mse=1.137671 step=0.050000
2017/08/30 00:06:48 step 4: mse=1.137154 step=0.050000
2017/08/30 00:06:52 step 5: mse=1.136669 step=0.050000
2017/08/30 00:06:55 step 6: mse=1.136209 step=0.050000
2017/08/30 00:06:59 step 7: mse=1.135781 step=0.050000
2017/08/30 00:06:59 Saving...
2017/08/30 00:06:59 Gathering batch of experience...
2017/08/30 00:07:32 batch 320: mean=5.498103 stddev=1.464972 entropy=1.284862 frames=100140 count=5007
2017/08/30 00:07:32 Training policy...
2017/08/30 00:07:48 step 0: objective=0.256749 reg=0.012849
2017/08/30 00:07:58 step 1: objective=0.257426 reg=0.012849
2017/08/30 00:08:07 step 2: objective=0.258069 reg=0.012846
2017/08/30 00:08:16 step 3: objective=0.258556 reg=0.012849
2017/08/30 00:08:25 step 4: objective=0.259026 reg=0.012849
2017/08/30 00:08:34 step 5: objective=0.259483 reg=0.012845
2017/08/30 00:08:44 step 6: objective=0.259872 reg=0.012839
2017/08/30 00:08:53 step 7: objective=0.260304 reg=0.012840
2017/08/30 00:08:53 Training value function...
2017/08/30 00:08:59 step 0: mse=1.176272 step=0.050000
2017/08/30 00:09:02 step 1: mse=1.175980 step=0.050000
2017/08/30 00:09:06 step 2: mse=1.175715 step=0.050000
2017/08/30 00:09:09 step 3: mse=1.175471 step=0.050000
2017/08/30 00:09:13 step 4: mse=1.175257 step=0.050000
2017/08/30 00:09:16 step 5: mse=1.175056 step=0.050000
2017/08/30 00:09:20 step 6: mse=1.174865 step=0.050000
2017/08/30 00:09:23 step 7: mse=1.174687 step=0.050000
2017/08/30 00:09:23 Saving...
2017/08/30 00:09:23 Gathering batch of experience...
2017/08/30 00:09:56 batch 321: mean=5.472738 stddev=1.500817 entropy=1.279869 frames=100140 count=5007
2017/08/30 00:09:56 Training policy...
2017/08/30 00:10:13 step 0: objective=0.250902 reg=0.012799
2017/08/30 00:10:22 step 1: objective=0.251663 reg=0.012798
2017/08/30 00:10:31 step 2: objective=0.252312 reg=0.012792
2017/08/30 00:10:41 step 3: objective=0.252939 reg=0.012794
2017/08/30 00:10:50 step 4: objective=0.253467 reg=0.012794
2017/08/30 00:10:59 step 5: objective=0.253945 reg=0.012793
2017/08/30 00:11:08 step 6: objective=0.254385 reg=0.012793
2017/08/30 00:11:17 step 7: objective=0.254820 reg=0.012791
2017/08/30 00:11:17 Training value function...
2017/08/30 00:11:23 step 0: mse=1.193381 step=0.050000
2017/08/30 00:11:27 step 1: mse=1.193074 step=0.050000
2017/08/30 00:11:30 step 2: mse=1.192798 step=0.050000
2017/08/30 00:11:34 step 3: mse=1.192544 step=0.050000
2017/08/30 00:11:37 step 4: mse=1.192303 step=0.050000
2017/08/30 00:11:41 step 5: mse=1.192077 step=0.050000
2017/08/30 00:11:44 step 6: mse=1.191867 step=0.050000
2017/08/30 00:11:48 step 7: mse=1.191667 step=0.050000
2017/08/30 00:11:48 Saving...
2017/08/30 00:11:48 Gathering batch of experience...
2017/08/30 00:12:21 batch 322: mean=5.482125 stddev=1.484367 entropy=1.279105 frames=100140 count=5007
2017/08/30 00:12:21 Training policy...
2017/08/30 00:12:38 step 0: objective=0.250711 reg=0.012791
2017/08/30 00:12:47 step 1: objective=0.251395 reg=0.012788
2017/08/30 00:12:56 step 2: objective=0.252025 reg=0.012790
2017/08/30 00:13:06 step 3: objective=0.252634 reg=0.012789
2017/08/30 00:13:15 step 4: objective=0.253129 reg=0.012788
2017/08/30 00:13:24 step 5: objective=0.253801 reg=0.012783
2017/08/30 00:13:33 step 6: objective=0.254316 reg=0.012783
2017/08/30 00:13:42 step 7: objective=0.254749 reg=0.012780
2017/08/30 00:13:42 Training value function...
2017/08/30 00:13:48 step 0: mse=1.168135 step=0.050000
2017/08/30 00:13:52 step 1: mse=1.168002 step=0.050000
2017/08/30 00:13:55 step 2: mse=1.167894 step=0.050000
2017/08/30 00:13:59 step 3: mse=1.167803 step=0.050000
2017/08/30 00:14:02 step 4: mse=1.167729 step=0.050000
2017/08/30 00:14:06 step 5: mse=1.167652 step=0.050000
2017/08/30 00:14:09 step 6: mse=1.167560 step=0.050000
2017/08/30 00:14:13 step 7: mse=1.167494 step=0.050000
2017/08/30 00:14:13 Saving...
2017/08/30 00:14:13 Gathering batch of experience...
2017/08/30 00:14:46 batch 323: mean=5.506691 stddev=1.480418 entropy=1.275999 frames=100140 count=5007
2017/08/30 00:14:46 Training policy...
2017/08/30 00:15:04 step 0: objective=0.264149 reg=0.012760
2017/08/30 00:15:13 step 1: objective=0.264745 reg=0.012759
2017/08/30 00:15:22 step 2: objective=0.265269 reg=0.012760
2017/08/30 00:15:31 step 3: objective=0.265743 reg=0.012763
2017/08/30 00:15:40 step 4: objective=0.266228 reg=0.012755
2017/08/30 00:15:50 step 5: objective=0.266705 reg=0.012754
2017/08/30 00:15:59 step 6: objective=0.267172 reg=0.012755
2017/08/30 00:16:08 step 7: objective=0.267511 reg=0.012751
2017/08/30 00:16:08 Training value function...
2017/08/30 00:16:14 step 0: mse=1.194005 step=0.050000
2017/08/30 00:16:17 step 1: mse=1.192914 step=0.050000
2017/08/30 00:16:21 step 2: mse=1.191896 step=0.050000
2017/08/30 00:16:24 step 3: mse=1.190946 step=0.050000
2017/08/30 00:16:28 step 4: mse=1.190053 step=0.050000
2017/08/30 00:16:31 step 5: mse=1.189217 step=0.050000
2017/08/30 00:16:35 step 6: mse=1.188431 step=0.050000
2017/08/30 00:16:38 step 7: mse=1.187694 step=0.050000
2017/08/30 00:16:38 Saving...
2017/08/30 00:16:38 Gathering batch of experience...
2017/08/30 00:17:12 batch 324: mean=5.510485 stddev=1.455635 entropy=1.278606 frames=100140 count=5007
2017/08/30 00:17:12 Training policy...
2017/08/30 00:17:28 step 0: objective=0.259624 reg=0.012786
2017/08/30 00:17:38 step 1: objective=0.260233 reg=0.012786
2017/08/30 00:17:47 step 2: objective=0.260879 reg=0.012780
2017/08/30 00:17:56 step 3: objective=0.261515 reg=0.012777
2017/08/30 00:18:05 step 4: objective=0.261980 reg=0.012775
2017/08/30 00:18:14 step 5: objective=0.262432 reg=0.012778
2017/08/30 00:18:24 step 6: objective=0.262885 reg=0.012772
2017/08/30 00:18:33 step 7: objective=0.263259 reg=0.012770
2017/08/30 00:18:33 Training value function...
2017/08/30 00:18:39 step 0: mse=1.142297 step=0.050000
2017/08/30 00:18:42 step 1: mse=1.141516 step=0.050000
2017/08/30 00:18:46 step 2: mse=1.140796 step=0.050000
2017/08/30 00:18:49 step 3: mse=1.140132 step=0.050000
2017/08/30 00:18:53 step 4: mse=1.139524 step=0.050000
2017/08/30 00:18:56 step 5: mse=1.138950 step=0.050000
2017/08/30 00:19:00 step 6: mse=1.138376 step=0.050000
2017/08/30 00:19:03 step 7: mse=1.137884 step=0.050000
2017/08/30 00:19:03 Saving...
2017/08/30 00:19:03 Gathering batch of experience...
2017/08/30 00:19:37 batch 325: mean=5.460755 stddev=1.462263 entropy=1.274255 frames=100140 count=5007
2017/08/30 00:19:37 Training policy...
2017/08/30 00:19:53 step 0: objective=0.247147 reg=0.012742
2017/08/30 00:20:03 step 1: objective=0.247881 reg=0.012742
2017/08/30 00:20:12 step 2: objective=0.248559 reg=0.012743
2017/08/30 00:20:21 step 3: objective=0.249104 reg=0.012741
2017/08/30 00:20:31 step 4: objective=0.249647 reg=0.012739
2017/08/30 00:20:40 step 5: objective=0.250063 reg=0.012731
2017/08/30 00:20:49 step 6: objective=0.250397 reg=0.012737
2017/08/30 00:20:59 step 7: objective=0.250758 reg=0.012728
2017/08/30 00:20:59 Training value function...
2017/08/30 00:21:05 step 0: mse=1.138244 step=0.050000
2017/08/30 00:21:08 step 1: mse=1.138347 step=0.050000
2017/08/30 00:21:12 step 2: mse=1.138455 step=0.050000
2017/08/30 00:21:15 step 3: mse=1.138563 step=0.050000
2017/08/30 00:21:19 step 4: mse=1.138665 step=0.050000
2017/08/30 00:21:22 step 5: mse=1.138757 step=0.050000
2017/08/30 00:21:26 step 6: mse=1.138842 step=0.050000
2017/08/30 00:21:29 step 7: mse=1.138921 step=0.050000
2017/08/30 00:21:29 Saving...
2017/08/30 00:21:29 Gathering batch of experience...
2017/08/30 00:22:03 batch 326: mean=5.488316 stddev=1.493550 entropy=1.271963 frames=100140 count=5007
2017/08/30 00:22:03 Training policy...
2017/08/30 00:22:22 step 0: objective=0.250206 reg=0.012720
2017/08/30 00:22:31 step 1: objective=0.250792 reg=0.012723
2017/08/30 00:22:41 step 2: objective=0.251514 reg=0.012721
2017/08/30 00:22:50 step 3: objective=0.252163 reg=0.012720
2017/08/30 00:22:59 step 4: objective=0.252680 reg=0.012720
2017/08/30 00:23:09 step 5: objective=0.253193 reg=0.012719
2017/08/30 00:23:18 step 6: objective=0.253593 reg=0.012714
2017/08/30 00:23:27 step 7: objective=0.253952 reg=0.012717
2017/08/30 00:23:27 Training value function...
2017/08/30 00:23:33 step 0: mse=1.165113 step=0.050000
2017/08/30 00:23:37 step 1: mse=1.164554 step=0.050000
2017/08/30 00:23:40 step 2: mse=1.164037 step=0.050000
2017/08/30 00:23:44 step 3: mse=1.163552 step=0.050000
2017/08/30 00:23:47 step 4: mse=1.163021 step=0.050000
2017/08/30 00:23:51 step 5: mse=1.162595 step=0.050000
2017/08/30 00:23:54 step 6: mse=1.162162 step=0.050000
2017/08/30 00:23:58 step 7: mse=1.161783 step=0.050000
2017/08/30 00:23:58 Saving...
2017/08/30 00:23:58 Gathering batch of experience...
2017/08/30 00:24:31 batch 327: mean=5.490913 stddev=1.494771 entropy=1.272902 frames=100140 count=5007
2017/08/30 00:24:31 Training policy...
2017/08/30 00:24:48 step 0: objective=0.258385 reg=0.012729
2017/08/30 00:24:57 step 1: objective=0.259082 reg=0.012730
2017/08/30 00:25:06 step 2: objective=0.259725 reg=0.012728
2017/08/30 00:25:16 step 3: objective=0.260351 reg=0.012724
2017/08/30 00:25:25 step 4: objective=0.260896 reg=0.012721
2017/08/30 00:25:35 step 5: objective=0.261397 reg=0.012718
2017/08/30 00:25:44 step 6: objective=0.261897 reg=0.012721
2017/08/30 00:25:54 step 7: objective=0.262444 reg=0.012719
2017/08/30 00:25:54 Training value function...
2017/08/30 00:26:00 step 0: mse=1.191847 step=0.050000
2017/08/30 00:26:03 step 1: mse=1.191220 step=0.050000
2017/08/30 00:26:07 step 2: mse=1.190641 step=0.050000
2017/08/30 00:26:10 step 3: mse=1.190103 step=0.050000
2017/08/30 00:26:14 step 4: mse=1.189599 step=0.050000
2017/08/30 00:26:17 step 5: mse=1.189118 step=0.050000
2017/08/30 00:26:21 step 6: mse=1.188671 step=0.050000
2017/08/30 00:26:24 step 7: mse=1.188243 step=0.050000
2017/08/30 00:26:24 Saving...
2017/08/30 00:26:24 Gathering batch of experience...
2017/08/30 00:26:58 batch 328: mean=5.470142 stddev=1.478242 entropy=1.274179 frames=100140 count=5007
2017/08/30 00:26:58 Training policy...
2017/08/30 00:27:15 step 0: objective=0.241724 reg=0.012742
2017/08/30 00:27:25 step 1: objective=0.242523 reg=0.012743
2017/08/30 00:27:34 step 2: objective=0.243143 reg=0.012745
2017/08/30 00:27:44 step 3: objective=0.243686 reg=0.012741
2017/08/30 00:27:53 step 4: objective=0.244196 reg=0.012738
2017/08/30 00:28:03 step 5: objective=0.244452 reg=0.012731
2017/08/30 00:28:12 step 6: objective=0.244856 reg=0.012737
2017/08/30 00:28:21 step 7: objective=0.245292 reg=0.012727
2017/08/30 00:28:21 Training value function...
2017/08/30 00:28:27 step 0: mse=1.160441 step=0.050000
2017/08/30 00:28:31 step 1: mse=1.160789 step=0.050000
2017/08/30 00:28:34 step 2: mse=1.161109 step=0.050000
2017/08/30 00:28:38 step 3: mse=1.161395 step=0.050000
2017/08/30 00:28:41 step 4: mse=1.161630 step=0.050000
2017/08/30 00:28:45 step 5: mse=1.161861 step=0.050000
2017/08/30 00:28:48 step 6: mse=1.162105 step=0.050000
2017/08/30 00:28:52 step 7: mse=1.162317 step=0.050000
2017/08/30 00:28:52 Saving...
2017/08/30 00:28:52 Gathering batch of experience...
2017/08/30 00:29:25 batch 329: mean=5.490314 stddev=1.446004 entropy=1.275183 frames=100140 count=5007
2017/08/30 00:29:25 Training policy...
2017/08/30 00:29:42 step 0: objective=0.255004 reg=0.012752
2017/08/30 00:29:51 step 1: objective=0.255625 reg=0.012748
2017/08/30 00:30:01 step 2: objective=0.256181 reg=0.012754
2017/08/30 00:30:10 step 3: objective=0.256708 reg=0.012755
2017/08/30 00:30:19 step 4: objective=0.257147 reg=0.012752
2017/08/30 00:30:29 step 5: objective=0.257472 reg=0.012755
2017/08/30 00:30:38 step 6: objective=0.257785 reg=0.012748
2017/08/30 00:30:47 step 7: objective=0.258102 reg=0.012755
2017/08/30 00:30:47 Training value function...
2017/08/30 00:30:54 step 0: mse=1.150902 step=0.050000
2017/08/30 00:30:57 step 1: mse=1.150214 step=0.050000
2017/08/30 00:31:01 step 2: mse=1.149579 step=0.050000
2017/08/30 00:31:04 step 3: mse=1.148993 step=0.050000
2017/08/30 00:31:08 step 4: mse=1.148468 step=0.050000
2017/08/30 00:31:11 step 5: mse=1.147950 step=0.050000
2017/08/30 00:31:15 step 6: mse=1.147498 step=0.050000
2017/08/30 00:31:18 step 7: mse=1.147038 step=0.050000
2017/08/30 00:31:18 Saving...
2017/08/30 00:31:18 Gathering batch of experience...
2017/08/30 00:31:52 batch 330: mean=5.478730 stddev=1.491436 entropy=1.274017 frames=100140 count=5007
2017/08/30 00:31:52 Training policy...
2017/08/30 00:32:08 step 0: objective=0.249565 reg=0.012740
2017/08/30 00:32:18 step 1: objective=0.250232 reg=0.012729
2017/08/30 00:32:27 step 2: objective=0.250968 reg=0.012721
2017/08/30 00:32:37 step 3: objective=0.251526 reg=0.012722
2017/08/30 00:32:46 step 4: objective=0.252042 reg=0.012724
2017/08/30 00:32:56 step 5: objective=0.252583 reg=0.012725
2017/08/30 00:33:05 step 6: objective=0.253018 reg=0.012726
2017/08/30 00:33:15 step 7: objective=0.253428 reg=0.012723
2017/08/30 00:33:15 Training value function...
2017/08/30 00:33:21 step 0: mse=1.193400 step=0.050000
2017/08/30 00:33:24 step 1: mse=1.193575 step=0.050000
2017/08/30 00:33:27 step 2: mse=1.193747 step=0.050000
2017/08/30 00:33:31 step 3: mse=1.193914 step=0.050000
2017/08/30 00:33:34 step 4: mse=1.194069 step=0.050000
2017/08/30 00:33:38 step 5: mse=1.194216 step=0.050000
2017/08/30 00:33:41 step 6: mse=1.194359 step=0.050000
2017/08/30 00:33:45 step 7: mse=1.194476 step=0.050000
2017/08/30 00:33:45 Saving...
2017/08/30 00:33:45 Gathering batch of experience...
2017/08/30 00:34:19 batch 331: mean=5.472738 stddev=1.466763 entropy=1.272859 frames=100140 count=5007
2017/08/30 00:34:19 Training policy...
2017/08/30 00:34:35 step 0: objective=0.243665 reg=0.012729
2017/08/30 00:34:45 step 1: objective=0.244461 reg=0.012728
2017/08/30 00:34:55 step 2: objective=0.245199 reg=0.012729
2017/08/30 00:35:04 step 3: objective=0.245823 reg=0.012726
2017/08/30 00:35:13 step 4: objective=0.246357 reg=0.012722
2017/08/30 00:35:23 step 5: objective=0.246892 reg=0.012721
2017/08/30 00:35:33 step 6: objective=0.247265 reg=0.012723
2017/08/30 00:35:42 step 7: objective=0.247801 reg=0.012722
2017/08/30 00:35:42 Training value function...
2017/08/30 00:35:48 step 0: mse=1.123112 step=0.050000
2017/08/30 00:35:52 step 1: mse=1.123111 step=0.050000
2017/08/30 00:35:55 step 2: mse=1.123098 step=0.050000
2017/08/30 00:35:59 step 3: mse=1.123098 step=0.050000
2017/08/30 00:36:02 step 4: mse=1.123102 step=0.050000
2017/08/30 00:36:06 step 5: mse=1.123114 step=0.050000
2017/08/30 00:36:09 step 6: mse=1.123125 step=0.050000
2017/08/30 00:36:13 step 7: mse=1.123104 step=0.050000
2017/08/30 00:36:13 Saving...
2017/08/30 00:36:13 Gathering batch of experience...
2017/08/30 00:36:46 batch 332: mean=5.469942 stddev=1.475262 entropy=1.267039 frames=100140 count=5007
2017/08/30 00:36:46 Training policy...
2017/08/30 00:37:04 step 0: objective=0.256197 reg=0.012670
2017/08/30 00:37:13 step 1: objective=0.256890 reg=0.012674
2017/08/30 00:37:23 step 2: objective=0.257547 reg=0.012669
2017/08/30 00:37:32 step 3: objective=0.258104 reg=0.012665
2017/08/30 00:37:41 step 4: objective=0.258569 reg=0.012664
2017/08/30 00:37:51 step 5: objective=0.259042 reg=0.012662
2017/08/30 00:38:00 step 6: objective=0.259453 reg=0.012661
2017/08/30 00:38:10 step 7: objective=0.259778 reg=0.012656
2017/08/30 00:38:10 Training value function...
2017/08/30 00:38:16 step 0: mse=1.184934 step=0.050000
2017/08/30 00:38:20 step 1: mse=1.184476 step=0.050000
2017/08/30 00:38:23 step 2: mse=1.184057 step=0.050000
2017/08/30 00:38:27 step 3: mse=1.183675 step=0.050000
2017/08/30 00:38:30 step 4: mse=1.183329 step=0.050000
2017/08/30 00:38:34 step 5: mse=1.183004 step=0.050000
2017/08/30 00:38:37 step 6: mse=1.182697 step=0.050000
2017/08/30 00:38:41 step 7: mse=1.182407 step=0.050000
2017/08/30 00:38:41 Saving...
2017/08/30 00:38:41 Gathering batch of experience...
2017/08/30 00:39:14 batch 333: mean=5.475335 stddev=1.473466 entropy=1.268182 frames=100140 count=5007
2017/08/30 00:39:14 Training policy...
2017/08/30 00:39:31 step 0: objective=0.248751 reg=0.012682
2017/08/30 00:39:41 step 1: objective=0.249650 reg=0.012681
2017/08/30 00:39:50 step 2: objective=0.250330 reg=0.012682
2017/08/30 00:40:00 step 3: objective=0.250954 reg=0.012679
2017/08/30 00:40:09 step 4: objective=0.251435 reg=0.012674
2017/08/30 00:40:19 step 5: objective=0.251755 reg=0.012672
2017/08/30 00:40:29 step 6: objective=0.252163 reg=0.012668
2017/08/30 00:40:38 step 7: objective=0.252624 reg=0.012666
2017/08/30 00:40:38 Training value function...
2017/08/30 00:40:44 step 0: mse=1.153650 step=0.050000
2017/08/30 00:40:47 step 1: mse=1.153280 step=0.050000
2017/08/30 00:40:51 step 2: mse=1.152945 step=0.050000
2017/08/30 00:40:55 step 3: mse=1.152641 step=0.050000
2017/08/30 00:40:58 step 4: mse=1.152356 step=0.050000
2017/08/30 00:41:02 step 5: mse=1.152095 step=0.050000
2017/08/30 00:41:05 step 6: mse=1.151848 step=0.050000
2017/08/30 00:41:09 step 7: mse=1.151620 step=0.050000
2017/08/30 00:41:09 Saving...
2017/08/30 00:41:09 Gathering batch of experience...
2017/08/30 00:41:42 batch 334: mean=5.487517 stddev=1.472670 entropy=1.265389 frames=100140 count=5007
2017/08/30 00:41:42 Training policy...
2017/08/30 00:41:59 step 0: objective=0.250288 reg=0.012654
2017/08/30 00:42:09 step 1: objective=0.250938 reg=0.012648
2017/08/30 00:42:18 step 2: objective=0.251717 reg=0.012651
2017/08/30 00:42:28 step 3: objective=0.252224 reg=0.012650
2017/08/30 00:42:37 step 4: objective=0.252699 reg=0.012653
2017/08/30 00:42:47 step 5: objective=0.253199 reg=0.012655
2017/08/30 00:42:57 step 6: objective=0.253617 reg=0.012657
2017/08/30 00:43:06 step 7: objective=0.254044 reg=0.012655
2017/08/30 00:43:06 Training value function...
2017/08/30 00:43:12 step 0: mse=1.144176 step=0.050000
2017/08/30 00:43:16 step 1: mse=1.143638 step=0.050000
2017/08/30 00:43:19 step 2: mse=1.143146 step=0.050000
2017/08/30 00:43:23 step 3: mse=1.142692 step=0.050000
2017/08/30 00:43:26 step 4: mse=1.142276 step=0.050000
2017/08/30 00:43:30 step 5: mse=1.141889 step=0.050000
2017/08/30 00:43:33 step 6: mse=1.141520 step=0.050000
2017/08/30 00:43:37 step 7: mse=1.141168 step=0.050000
2017/08/30 00:43:37 Saving...
2017/08/30 00:43:37 Gathering batch of experience...
2017/08/30 00:44:11 batch 335: mean=5.543239 stddev=1.469100 entropy=1.262242 frames=100140 count=5007
2017/08/30 00:44:11 Training policy...
2017/08/30 00:44:27 step 0: objective=0.262216 reg=0.012622
2017/08/30 00:44:37 step 1: objective=0.263034 reg=0.012623
2017/08/30 00:44:47 step 2: objective=0.263641 reg=0.012620
2017/08/30 00:44:56 step 3: objective=0.264234 reg=0.012625
2017/08/30 00:45:06 step 4: objective=0.264617 reg=0.012618
2017/08/30 00:45:15 step 5: objective=0.264971 reg=0.012623
2017/08/30 00:45:25 step 6: objective=0.265334 reg=0.012614
2017/08/30 00:45:34 step 7: objective=0.265635 reg=0.012622
2017/08/30 00:45:34 Training value function...
2017/08/30 00:45:40 step 0: mse=1.194906 step=0.050000
2017/08/30 00:45:44 step 1: mse=1.194187 step=0.050000
2017/08/30 00:45:47 step 2: mse=1.193529 step=0.050000
2017/08/30 00:45:51 step 3: mse=1.192905 step=0.050000
2017/08/30 00:45:54 step 4: mse=1.192329 step=0.050000
2017/08/30 00:45:58 step 5: mse=1.191787 step=0.050000
2017/08/30 00:46:01 step 6: mse=1.191281 step=0.050000
2017/08/30 00:46:05 step 7: mse=1.190807 step=0.050000
2017/08/30 00:46:05 Saving...
2017/08/30 00:46:05 Gathering batch of experience...
2017/08/30 00:46:39 batch 336: mean=5.476333 stddev=1.481188 entropy=1.263224 frames=100140 count=5007
2017/08/30 00:46:39 Training policy...
2017/08/30 00:46:55 step 0: objective=0.248399 reg=0.012632
2017/08/30 00:47:06 step 1: objective=0.249045 reg=0.012630
2017/08/30 00:47:16 step 2: objective=0.249553 reg=0.012630
2017/08/30 00:47:25 step 3: objective=0.250165 reg=0.012632
2017/08/30 00:47:35 step 4: objective=0.250715 reg=0.012629
2017/08/30 00:47:45 step 5: objective=0.251275 reg=0.012629
2017/08/30 00:47:54 step 6: objective=0.251762 reg=0.012627
2017/08/30 00:48:04 step 7: objective=0.252268 reg=0.012623
2017/08/30 00:48:04 Training value function...
2017/08/30 00:48:10 step 0: mse=1.187081 step=0.050000
2017/08/30 00:48:13 step 1: mse=1.187079 step=0.050000
2017/08/30 00:48:17 step 2: mse=1.187079 step=0.050000
2017/08/30 00:48:20 step 3: mse=1.187088 step=0.050000
2017/08/30 00:48:24 step 4: mse=1.187089 step=0.050000
2017/08/30 00:48:27 step 5: mse=1.187095 step=0.050000
2017/08/30 00:48:31 step 6: mse=1.187101 step=0.050000
2017/08/30 00:48:34 step 7: mse=1.187107 step=0.050000
2017/08/30 00:48:34 Saving...
2017/08/30 00:48:34 Gathering batch of experience...
2017/08/30 00:49:08 batch 337: mean=5.484921 stddev=1.434587 entropy=1.262403 frames=100140 count=5007
2017/08/30 00:49:08 Training policy...
2017/08/30 00:49:26 step 0: objective=0.240392 reg=0.012624
2017/08/30 00:49:36 step 1: objective=0.240955 reg=0.012623
2017/08/30 00:49:45 step 2: objective=0.241496 reg=0.012620
2017/08/30 00:49:55 step 3: objective=0.241974 reg=0.012620
2017/08/30 00:50:05 step 4: objective=0.242492 reg=0.012617
2017/08/30 00:50:14 step 5: objective=0.243001 reg=0.012617
2017/08/30 00:50:24 step 6: objective=0.243472 reg=0.012615
2017/08/30 00:50:34 step 7: objective=0.243798 reg=0.012609
2017/08/30 00:50:34 Training value function...
2017/08/30 00:50:40 step 0: mse=1.114674 step=0.050000
2017/08/30 00:50:43 step 1: mse=1.115322 step=0.050000
2017/08/30 00:50:47 step 2: mse=1.115939 step=0.050000
2017/08/30 00:50:50 step 3: mse=1.116529 step=0.050000
2017/08/30 00:50:54 step 4: mse=1.117090 step=0.050000
2017/08/30 00:50:57 step 5: mse=1.117618 step=0.050000
2017/08/30 00:51:01 step 6: mse=1.118106 step=0.050000
2017/08/30 00:51:04 step 7: mse=1.118572 step=0.050000
2017/08/30 00:51:04 Saving...
2017/08/30 00:51:04 Gathering batch of experience...
2017/08/30 00:51:38 batch 338: mean=5.503295 stddev=1.475429 entropy=1.256703 frames=100140 count=5007
2017/08/30 00:51:38 Training policy...
2017/08/30 00:51:55 step 0: objective=0.254805 reg=0.012567
2017/08/30 00:52:06 step 1: objective=0.255430 reg=0.012567
2017/08/30 00:52:15 step 2: objective=0.255928 reg=0.012569
2017/08/30 00:52:25 step 3: objective=0.256474 reg=0.012570
2017/08/30 00:52:35 step 4: objective=0.257038 reg=0.012566
2017/08/30 00:52:45 step 5: objective=0.257577 reg=0.012567
2017/08/30 00:52:54 step 6: objective=0.258109 reg=0.012564
2017/08/30 00:53:04 step 7: objective=0.258557 reg=0.012565
2017/08/30 00:53:04 Training value function...
2017/08/30 00:53:10 step 0: mse=1.170631 step=0.050000
2017/08/30 00:53:14 step 1: mse=1.170102 step=0.050000
2017/08/30 00:53:17 step 2: mse=1.169621 step=0.050000
2017/08/30 00:53:21 step 3: mse=1.169139 step=0.050000
2017/08/30 00:53:24 step 4: mse=1.168661 step=0.050000
2017/08/30 00:53:27 step 5: mse=1.168247 step=0.050000
2017/08/30 00:53:31 step 6: mse=1.167854 step=0.050000
2017/08/30 00:53:34 step 7: mse=1.167490 step=0.050000
2017/08/30 00:53:34 Saving...
2017/08/30 00:53:35 Gathering batch of experience...
2017/08/30 00:54:08 batch 339: mean=5.495706 stddev=1.478537 entropy=1.259727 frames=100140 count=5007
2017/08/30 00:54:08 Training policy...
2017/08/30 00:54:25 step 0: objective=0.256281 reg=0.012597
2017/08/30 00:54:35 step 1: objective=0.256930 reg=0.012596
2017/08/30 00:54:45 step 2: objective=0.257629 reg=0.012593
2017/08/30 00:54:55 step 3: objective=0.258331 reg=0.012595
2017/08/30 00:55:05 step 4: objective=0.258881 reg=0.012593
2017/08/30 00:55:15 step 5: objective=0.259206 reg=0.012587
2017/08/30 00:55:24 step 6: objective=0.259615 reg=0.012581
2017/08/30 00:55:34 step 7: objective=0.259925 reg=0.012587
2017/08/30 00:55:34 Training value function...
2017/08/30 00:55:40 step 0: mse=1.165867 step=0.050000
2017/08/30 00:55:43 step 1: mse=1.165028 step=0.050000
2017/08/30 00:55:47 step 2: mse=1.164249 step=0.050000
2017/08/30 00:55:50 step 3: mse=1.163528 step=0.050000
2017/08/30 00:55:54 step 4: mse=1.162855 step=0.050000
2017/08/30 00:55:57 step 5: mse=1.162222 step=0.050000
2017/08/30 00:56:01 step 6: mse=1.161629 step=0.050000
2017/08/30 00:56:04 step 7: mse=1.161073 step=0.050000
2017/08/30 00:56:04 Saving...
2017/08/30 00:56:04 Gathering batch of experience...
2017/08/30 00:56:38 batch 340: mean=5.462353 stddev=1.514107 entropy=1.267366 frames=100140 count=5007
2017/08/30 00:56:38 Training policy...
2017/08/30 00:56:55 step 0: objective=0.243814 reg=0.012674
2017/08/30 00:57:05 step 1: objective=0.244478 reg=0.012672
2017/08/30 00:57:14 step 2: objective=0.245092 reg=0.012669
2017/08/30 00:57:24 step 3: objective=0.245661 reg=0.012669
2017/08/30 00:57:34 step 4: objective=0.246183 reg=0.012669
2017/08/30 00:57:44 step 5: objective=0.246618 reg=0.012674
2017/08/30 00:57:54 step 6: objective=0.247080 reg=0.012673
2017/08/30 00:58:03 step 7: objective=0.247573 reg=0.012669
2017/08/30 00:58:03 Training value function...
2017/08/30 00:58:09 step 0: mse=1.178242 step=0.050000
2017/08/30 00:58:13 step 1: mse=1.178291 step=0.050000
2017/08/30 00:58:16 step 2: mse=1.178354 step=0.050000
2017/08/30 00:58:20 step 3: mse=1.178417 step=0.050000
2017/08/30 00:58:23 step 4: mse=1.178489 step=0.050000
2017/08/30 00:58:27 step 5: mse=1.178567 step=0.050000
2017/08/30 00:58:30 step 6: mse=1.178638 step=0.050000
2017/08/30 00:58:33 step 7: mse=1.178710 step=0.050000
2017/08/30 00:58:33 Saving...
2017/08/30 00:58:34 Gathering batch of experience...
2017/08/30 00:59:08 batch 341: mean=5.514480 stddev=1.461626 entropy=1.253402 frames=100140 count=5007
2017/08/30 00:59:08 Training policy...
2017/08/30 00:59:25 step 0: objective=0.260332 reg=0.012534
2017/08/30 00:59:36 step 1: objective=0.260964 reg=0.012526
2017/08/30 00:59:47 step 2: objective=0.261371 reg=0.012536
2017/08/30 00:59:56 step 3: objective=0.261844 reg=0.012530
2017/08/30 01:00:06 step 4: objective=0.262205 reg=0.012533
2017/08/30 01:00:16 step 5: objective=0.262628 reg=0.012538
2017/08/30 01:00:26 step 6: objective=0.263105 reg=0.012531
2017/08/30 01:00:35 step 7: objective=0.263478 reg=0.012533
2017/08/30 01:00:35 Training value function...
2017/08/30 01:00:42 step 0: mse=1.163602 step=0.050000
2017/08/30 01:00:45 step 1: mse=1.162565 step=0.050000
2017/08/30 01:00:49 step 2: mse=1.161605 step=0.050000
2017/08/30 01:00:52 step 3: mse=1.160707 step=0.050000
2017/08/30 01:00:56 step 4: mse=1.159859 step=0.050000
2017/08/30 01:00:59 step 5: mse=1.159061 step=0.050000
2017/08/30 01:01:03 step 6: mse=1.158311 step=0.050000
2017/08/30 01:01:06 step 7: mse=1.157609 step=0.050000
2017/08/30 01:01:06 Saving...
2017/08/30 01:01:06 Gathering batch of experience...
2017/08/30 01:01:40 batch 342: mean=5.494508 stddev=1.480558 entropy=1.261011 frames=100140 count=5007
2017/08/30 01:01:40 Training policy...
2017/08/30 01:01:58 step 0: objective=0.248233 reg=0.012610
2017/08/30 01:02:08 step 1: objective=0.248753 reg=0.012611
2017/08/30 01:02:18 step 2: objective=0.249264 reg=0.012609
2017/08/30 01:02:27 step 3: objective=0.249713 reg=0.012608
2017/08/30 01:02:37 step 4: objective=0.250287 reg=0.012607
2017/08/30 01:02:48 step 5: objective=0.250746 reg=0.012612
2017/08/30 01:02:57 step 6: objective=0.251227 reg=0.012602
2017/08/30 01:03:07 step 7: objective=0.251682 reg=0.012597
2017/08/30 01:03:07 Training value function...
2017/08/30 01:03:13 step 0: mse=1.147709 step=0.050000
2017/08/30 01:03:17 step 1: mse=1.147579 step=0.050000
2017/08/30 01:03:20 step 2: mse=1.147467 step=0.050000
2017/08/30 01:03:24 step 3: mse=1.147360 step=0.050000
2017/08/30 01:03:27 step 4: mse=1.147272 step=0.050000
2017/08/30 01:03:30 step 5: mse=1.147216 step=0.050000
2017/08/30 01:03:34 step 6: mse=1.147173 step=0.050000
2017/08/30 01:03:37 step 7: mse=1.147138 step=0.050000
2017/08/30 01:03:37 Saving...
2017/08/30 01:03:38 Gathering batch of experience...
2017/08/30 01:04:11 batch 343: mean=5.480927 stddev=1.470292 entropy=1.257199 frames=100140 count=5007
2017/08/30 01:04:11 Training policy...
2017/08/30 01:04:29 step 0: objective=0.245008 reg=0.012572
2017/08/30 01:04:39 step 1: objective=0.245619 reg=0.012573
2017/08/30 01:04:49 step 2: objective=0.246090 reg=0.012572
2017/08/30 01:04:59 step 3: objective=0.246807 reg=0.012574
2017/08/30 01:05:09 step 4: objective=0.247478 reg=0.012573
2017/08/30 01:05:19 step 5: objective=0.248045 reg=0.012571
2017/08/30 01:05:28 step 6: objective=0.248454 reg=0.012571
2017/08/30 01:05:38 step 7: objective=0.248743 reg=0.012566
2017/08/30 01:05:38 Training value function...
2017/08/30 01:05:44 step 0: mse=1.142047 step=0.050000
2017/08/30 01:05:48 step 1: mse=1.141823 step=0.050000
2017/08/30 01:05:51 step 2: mse=1.141624 step=0.050000
2017/08/30 01:05:55 step 3: mse=1.141446 step=0.050000
2017/08/30 01:05:58 step 4: mse=1.141235 step=0.050000
2017/08/30 01:06:02 step 5: mse=1.141088 step=0.050000
2017/08/30 01:06:05 step 6: mse=1.140950 step=0.050000
2017/08/30 01:06:09 step 7: mse=1.140776 step=0.050000
2017/08/30 01:06:09 Saving...
2017/08/30 01:06:09 Gathering batch of experience...
2017/08/30 01:06:43 batch 344: mean=5.475734 stddev=1.490453 entropy=1.258149 frames=100140 count=5007
2017/08/30 01:06:43 Training policy...
2017/08/30 01:07:00 step 0: objective=0.246617 reg=0.012581
2017/08/30 01:07:10 step 1: objective=0.247319 reg=0.012581
2017/08/30 01:07:20 step 2: objective=0.247890 reg=0.012579
2017/08/30 01:07:30 step 3: objective=0.248447 reg=0.012580
2017/08/30 01:07:40 step 4: objective=0.248970 reg=0.012579
2017/08/30 01:07:50 step 5: objective=0.249451 reg=0.012580
2017/08/30 01:08:00 step 6: objective=0.249819 reg=0.012580
2017/08/30 01:08:10 step 7: objective=0.250214 reg=0.012576
2017/08/30 01:08:10 Training value function...
2017/08/30 01:08:16 step 0: mse=1.147660 step=0.050000
2017/08/30 01:08:19 step 1: mse=1.147504 step=0.050000
2017/08/30 01:08:23 step 2: mse=1.147368 step=0.050000
2017/08/30 01:08:26 step 3: mse=1.147187 step=0.050000
2017/08/30 01:08:30 step 4: mse=1.147075 step=0.050000
2017/08/30 01:08:33 step 5: mse=1.146919 step=0.050000
2017/08/30 01:08:37 step 6: mse=1.146776 step=0.050000
2017/08/30 01:08:40 step 7: mse=1.146682 step=0.050000
2017/08/30 01:08:40 Saving...
2017/08/30 01:08:40 Gathering batch of experience...
2017/08/30 01:09:14 batch 345: mean=5.491112 stddev=1.465764 entropy=1.251008 frames=100140 count=5007
2017/08/30 01:09:14 Training policy...
2017/08/30 01:09:31 step 0: objective=0.258312 reg=0.012510
2017/08/30 01:09:41 step 1: objective=0.258940 reg=0.012511
2017/08/30 01:09:51 step 2: objective=0.259569 reg=0.012513
2017/08/30 01:10:01 step 3: objective=0.260131 reg=0.012511
2017/08/30 01:10:12 step 4: objective=0.260701 reg=0.012510
2017/08/30 01:10:21 step 5: objective=0.261136 reg=0.012507
2017/08/30 01:10:32 step 6: objective=0.261626 reg=0.012508
2017/08/30 01:10:42 step 7: objective=0.262122 reg=0.012504
2017/08/30 01:10:42 Training value function...
2017/08/30 01:10:48 step 0: mse=1.153578 step=0.050000
2017/08/30 01:10:51 step 1: mse=1.152674 step=0.050000
2017/08/30 01:10:55 step 2: mse=1.151834 step=0.050000
2017/08/30 01:10:58 step 3: mse=1.151035 step=0.050000
2017/08/30 01:11:02 step 4: mse=1.150301 step=0.050000
2017/08/30 01:11:05 step 5: mse=1.149558 step=0.050000
2017/08/30 01:11:09 step 6: mse=1.148879 step=0.050000
2017/08/30 01:11:12 step 7: mse=1.148260 step=0.050000
2017/08/30 01:11:12 Saving...
2017/08/30 01:11:12 Gathering batch of experience...
2017/08/30 01:11:46 batch 346: mean=5.479728 stddev=1.459369 entropy=1.253650 frames=100140 count=5007
2017/08/30 01:11:46 Training policy...
2017/08/30 01:12:04 step 0: objective=0.241670 reg=0.012537
2017/08/30 01:12:13 step 1: objective=0.242270 reg=0.012533
2017/08/30 01:12:23 step 2: objective=0.242910 reg=0.012535
2017/08/30 01:12:33 step 3: objective=0.243505 reg=0.012537
2017/08/30 01:12:43 step 4: objective=0.244022 reg=0.012535
2017/08/30 01:12:54 step 5: objective=0.244466 reg=0.012539
2017/08/30 01:13:03 step 6: objective=0.244828 reg=0.012529
2017/08/30 01:13:13 step 7: objective=0.245231 reg=0.012525
2017/08/30 01:13:13 Training value function...
2017/08/30 01:13:19 step 0: mse=1.125589 step=0.050000
2017/08/30 01:13:23 step 1: mse=1.125939 step=0.050000
2017/08/30 01:13:26 step 2: mse=1.126281 step=0.050000
2017/08/30 01:13:30 step 3: mse=1.126612 step=0.050000
2017/08/30 01:13:33 step 4: mse=1.126929 step=0.050000
2017/08/30 01:13:37 step 5: mse=1.127224 step=0.050000
2017/08/30 01:13:40 step 6: mse=1.127502 step=0.050000
2017/08/30 01:13:44 step 7: mse=1.127782 step=0.050000
2017/08/30 01:13:44 Saving...
2017/08/30 01:13:44 Gathering batch of experience...
2017/08/30 01:14:18 batch 347: mean=5.509487 stddev=1.482425 entropy=1.249163 frames=100140 count=5007
2017/08/30 01:14:18 Training policy...
2017/08/30 01:14:35 step 0: objective=0.256350 reg=0.012492
2017/08/30 01:14:45 step 1: objective=0.257167 reg=0.012493
2017/08/30 01:14:55 step 2: objective=0.257615 reg=0.012491
2017/08/30 01:15:05 step 3: objective=0.258262 reg=0.012492
2017/08/30 01:15:15 step 4: objective=0.258706 reg=0.012490
2017/08/30 01:15:25 step 5: objective=0.259191 reg=0.012488
2017/08/30 01:15:35 step 6: objective=0.259686 reg=0.012488
2017/08/30 01:15:45 step 7: objective=0.260081 reg=0.012485
2017/08/30 01:15:45 Training value function...
2017/08/30 01:15:51 step 0: mse=1.186505 step=0.050000
2017/08/30 01:15:54 step 1: mse=1.186147 step=0.050000
2017/08/30 01:15:58 step 2: mse=1.185824 step=0.050000
2017/08/30 01:16:01 step 3: mse=1.185533 step=0.050000
2017/08/30 01:16:05 step 4: mse=1.185272 step=0.050000
2017/08/30 01:16:08 step 5: mse=1.185029 step=0.050000
2017/08/30 01:16:11 step 6: mse=1.184802 step=0.050000
2017/08/30 01:16:15 step 7: mse=1.184586 step=0.050000
2017/08/30 01:16:15 Saving...
2017/08/30 01:16:15 Gathering batch of experience...
2017/08/30 01:16:49 batch 348: mean=5.528061 stddev=1.465522 entropy=1.247330 frames=100140 count=5007
2017/08/30 01:16:49 Training policy...
2017/08/30 01:17:07 step 0: objective=0.265256 reg=0.012473
2017/08/30 01:17:17 step 1: objective=0.265953 reg=0.012471
2017/08/30 01:17:26 step 2: objective=0.266581 reg=0.012470
2017/08/30 01:17:36 step 3: objective=0.267223 reg=0.012471
2017/08/30 01:17:47 step 4: objective=0.267829 reg=0.012468
2017/08/30 01:17:57 step 5: objective=0.268299 reg=0.012464
2017/08/30 01:18:07 step 6: objective=0.268605 reg=0.012469
2017/08/30 01:18:16 step 7: objective=0.269040 reg=0.012468
2017/08/30 01:18:16 Training value function...
2017/08/30 01:18:23 step 0: mse=1.198877 step=0.050000
2017/08/30 01:18:26 step 1: mse=1.197670 step=0.050000
2017/08/30 01:18:30 step 2: mse=1.196531 step=0.050000
2017/08/30 01:18:33 step 3: mse=1.195427 step=0.050000
2017/08/30 01:18:37 step 4: mse=1.194384 step=0.050000
2017/08/30 01:18:40 step 5: mse=1.193454 step=0.050000
2017/08/30 01:18:43 step 6: mse=1.192533 step=0.050000
2017/08/30 01:18:47 step 7: mse=1.191677 step=0.050000
2017/08/30 01:18:47 Saving...
2017/08/30 01:18:47 Gathering batch of experience...
2017/08/30 01:19:21 batch 349: mean=5.514280 stddev=1.471840 entropy=1.249225 frames=100140 count=5007
2017/08/30 01:19:21 Training policy...
2017/08/30 01:19:39 step 0: objective=0.253061 reg=0.012492
2017/08/30 01:19:48 step 1: objective=0.253730 reg=0.012490
2017/08/30 01:19:58 step 2: objective=0.254271 reg=0.012493
2017/08/30 01:20:09 step 3: objective=0.254847 reg=0.012489
2017/08/30 01:20:19 step 4: objective=0.255414 reg=0.012484
2017/08/30 01:20:29 step 5: objective=0.255839 reg=0.012482
2017/08/30 01:20:39 step 6: objective=0.256343 reg=0.012479
2017/08/30 01:20:49 step 7: objective=0.256753 reg=0.012476
2017/08/30 01:20:49 Training value function...
2017/08/30 01:20:55 step 0: mse=1.156807 step=0.050000
2017/08/30 01:20:58 step 1: mse=1.156522 step=0.050000
2017/08/30 01:21:02 step 2: mse=1.156258 step=0.050000
2017/08/30 01:21:05 step 3: mse=1.156011 step=0.050000
2017/08/30 01:21:08 step 4: mse=1.155777 step=0.050000
2017/08/30 01:21:12 step 5: mse=1.155549 step=0.050000
2017/08/30 01:21:15 step 6: mse=1.155335 step=0.050000
2017/08/30 01:21:19 step 7: mse=1.155132 step=0.050000
2017/08/30 01:21:19 Saving...
2017/08/30 01:21:19 Gathering batch of experience...
2017/08/30 01:21:53 batch 350: mean=5.500499 stddev=1.468513 entropy=1.250023 frames=100140 count=5007
2017/08/30 01:21:53 Training policy...
2017/08/30 01:22:11 step 0: objective=0.248067 reg=0.012500
2017/08/30 01:22:21 step 1: objective=0.248883 reg=0.012506
2017/08/30 01:22:31 step 2: objective=0.249633 reg=0.012501
2017/08/30 01:22:41 step 3: objective=0.250090 reg=0.012500
2017/08/30 01:22:51 step 4: objective=0.250583 reg=0.012501
2017/08/30 01:23:01 step 5: objective=0.251026 reg=0.012498
2017/08/30 01:23:11 step 6: objective=0.251483 reg=0.012498
2017/08/30 01:23:22 step 7: objective=0.251886 reg=0.012496
2017/08/30 01:23:22 Training value function...
2017/08/30 01:23:28 step 0: mse=1.174670 step=0.050000
2017/08/30 01:23:31 step 1: mse=1.174662 step=0.050000
2017/08/30 01:23:35 step 2: mse=1.174669 step=0.050000
2017/08/30 01:23:38 step 3: mse=1.174667 step=0.050000
2017/08/30 01:23:42 step 4: mse=1.174682 step=0.050000
2017/08/30 01:23:45 step 5: mse=1.174680 step=0.050000
2017/08/30 01:23:49 step 6: mse=1.174693 step=0.050000
2017/08/30 01:23:52 step 7: mse=1.174689 step=0.050000
2017/08/30 01:23:52 Saving...
2017/08/30 01:23:52 Gathering batch of experience...
2017/08/30 01:24:26 batch 351: mean=5.495906 stddev=1.475698 entropy=1.248688 frames=100140 count=5007
2017/08/30 01:24:26 Training policy...
2017/08/30 01:24:45 step 0: objective=0.252377 reg=0.012487
2017/08/30 01:24:55 step 1: objective=0.252859 reg=0.012485
2017/08/30 01:25:05 step 2: objective=0.253440 reg=0.012488
2017/08/30 01:25:15 step 3: objective=0.253987 reg=0.012491
2017/08/30 01:25:25 step 4: objective=0.254522 reg=0.012491
2017/08/30 01:25:35 step 5: objective=0.254948 reg=0.012493
2017/08/30 01:25:45 step 6: objective=0.255394 reg=0.012488
2017/08/30 01:25:56 step 7: objective=0.255841 reg=0.012484
2017/08/30 01:25:56 Training value function...
2017/08/30 01:26:02 step 0: mse=1.185459 step=0.050000
2017/08/30 01:26:05 step 1: mse=1.185254 step=0.050000
2017/08/30 01:26:09 step 2: mse=1.185077 step=0.050000
2017/08/30 01:26:12 step 3: mse=1.184916 step=0.050000
2017/08/30 01:26:15 step 4: mse=1.184771 step=0.050000
2017/08/30 01:26:19 step 5: mse=1.184634 step=0.050000
2017/08/30 01:26:22 step 6: mse=1.184507 step=0.050000
2017/08/30 01:26:26 step 7: mse=1.184387 step=0.050000
2017/08/30 01:26:26 Saving...
2017/08/30 01:26:26 Gathering batch of experience...
2017/08/30 01:27:00 batch 352: mean=5.514679 stddev=1.463535 entropy=1.240226 frames=100140 count=5007
2017/08/30 01:27:00 Training policy...
2017/08/30 01:27:18 step 0: objective=0.253914 reg=0.012402
2017/08/30 01:27:28 step 1: objective=0.254679 reg=0.012402
2017/08/30 01:27:40 step 2: objective=0.255305 reg=0.012405
2017/08/30 01:27:50 step 3: objective=0.255676 reg=0.012401
2017/08/30 01:28:00 step 4: objective=0.256167 reg=0.012399
2017/08/30 01:28:10 step 5: objective=0.256846 reg=0.012397
2017/08/30 01:28:20 step 6: objective=0.257260 reg=0.012395
2017/08/30 01:28:30 step 7: objective=0.257648 reg=0.012392
2017/08/30 01:28:30 Training value function...
2017/08/30 01:28:36 step 0: mse=1.132727 step=0.050000
2017/08/30 01:28:40 step 1: mse=1.131773 step=0.050000
2017/08/30 01:28:43 step 2: mse=1.130895 step=0.050000
2017/08/30 01:28:47 step 3: mse=1.130074 step=0.050000
2017/08/30 01:28:50 step 4: mse=1.129305 step=0.050000
2017/08/30 01:28:54 step 5: mse=1.128590 step=0.050000
2017/08/30 01:28:57 step 6: mse=1.127904 step=0.050000
2017/08/30 01:29:00 step 7: mse=1.127272 step=0.050000
2017/08/30 01:29:00 Saving...
2017/08/30 01:29:01 Gathering batch of experience...
2017/08/30 01:29:35 batch 353: mean=5.498302 stddev=1.475297 entropy=1.244601 frames=100140 count=5007
2017/08/30 01:29:35 Training policy...
2017/08/30 01:29:53 step 0: objective=0.244074 reg=0.012446
2017/08/30 01:30:04 step 1: objective=0.244746 reg=0.012447
2017/08/30 01:30:14 step 2: objective=0.245391 reg=0.012444
2017/08/30 01:30:24 step 3: objective=0.245857 reg=0.012447
2017/08/30 01:30:34 step 4: objective=0.246417 reg=0.012447
2017/08/30 01:30:45 step 5: objective=0.246941 reg=0.012446
2017/08/30 01:30:55 step 6: objective=0.247425 reg=0.012447
2017/08/30 01:31:05 step 7: objective=0.247823 reg=0.012443
2017/08/30 01:31:05 Training value function...
2017/08/30 01:31:11 step 0: mse=1.136707 step=0.050000
2017/08/30 01:31:15 step 1: mse=1.136717 step=0.050000
2017/08/30 01:31:18 step 2: mse=1.136790 step=0.050000
2017/08/30 01:31:21 step 3: mse=1.136816 step=0.050000
2017/08/30 01:31:25 step 4: mse=1.136850 step=0.050000
2017/08/30 01:31:28 step 5: mse=1.136885 step=0.050000
2017/08/30 01:31:32 step 6: mse=1.136923 step=0.050000
2017/08/30 01:31:35 step 7: mse=1.136980 step=0.050000
2017/08/30 01:31:35 Saving...
2017/08/30 01:31:35 Gathering batch of experience...
2017/08/30 01:32:10 batch 354: mean=5.473936 stddev=1.471000 entropy=1.247201 frames=100140 count=5007
2017/08/30 01:32:10 Training policy...
2017/08/30 01:32:27 step 0: objective=0.233629 reg=0.012472
2017/08/30 01:32:39 step 1: objective=0.234229 reg=0.012472
2017/08/30 01:32:49 step 2: objective=0.234702 reg=0.012472
2017/08/30 01:32:59 step 3: objective=0.235174 reg=0.012468
2017/08/30 01:33:09 step 4: objective=0.235649 reg=0.012463
2017/08/30 01:33:19 step 5: objective=0.236110 reg=0.012460
2017/08/30 01:33:29 step 6: objective=0.236556 reg=0.012465
2017/08/30 01:33:40 step 7: objective=0.236967 reg=0.012459
2017/08/30 01:33:40 Training value function...
2017/08/30 01:33:45 step 0: mse=1.107460 step=0.050000
2017/08/30 01:33:49 step 1: mse=1.108095 step=0.050000
2017/08/30 01:33:52 step 2: mse=1.108738 step=0.050000
2017/08/30 01:33:56 step 3: mse=1.109346 step=0.050000
2017/08/30 01:33:59 step 4: mse=1.109891 step=0.050000
2017/08/30 01:34:03 step 5: mse=1.110441 step=0.050000
2017/08/30 01:34:06 step 6: mse=1.110929 step=0.050000
2017/08/30 01:34:10 step 7: mse=1.111424 step=0.050000
2017/08/30 01:34:10 Saving...
2017/08/30 01:34:10 Gathering batch of experience...
2017/08/30 01:34:44 batch 355: mean=5.512483 stddev=1.491536 entropy=1.240144 frames=100140 count=5007
2017/08/30 01:34:44 Training policy...
2017/08/30 01:35:02 step 0: objective=0.265012 reg=0.012401
2017/08/30 01:35:13 step 1: objective=0.265826 reg=0.012402
2017/08/30 01:35:23 step 2: objective=0.266427 reg=0.012398
2017/08/30 01:35:33 step 3: objective=0.267098 reg=0.012399
2017/08/30 01:35:44 step 4: objective=0.267652 reg=0.012393
2017/08/30 01:35:55 step 5: objective=0.268021 reg=0.012394
2017/08/30 01:36:05 step 6: objective=0.268369 reg=0.012386
2017/08/30 01:36:16 step 7: objective=0.268810 reg=0.012382
2017/08/30 01:36:16 Training value function...
2017/08/30 01:36:21 step 0: mse=1.186875 step=0.050000
2017/08/30 01:36:25 step 1: mse=1.185930 step=0.050000
2017/08/30 01:36:28 step 2: mse=1.184979 step=0.050000
2017/08/30 01:36:32 step 3: mse=1.184093 step=0.050000
2017/08/30 01:36:35 step 4: mse=1.183287 step=0.050000
2017/08/30 01:36:39 step 5: mse=1.182535 step=0.050000
2017/08/30 01:36:42 step 6: mse=1.181804 step=0.050000
2017/08/30 01:36:46 step 7: mse=1.181087 step=0.050000
2017/08/30 01:36:46 Saving...
2017/08/30 01:36:46 Gathering batch of experience...
2017/08/30 01:37:20 batch 356: mean=5.517076 stddev=1.465419 entropy=1.240367 frames=100140 count=5007
2017/08/30 01:37:20 Training policy...
2017/08/30 01:37:38 step 0: objective=0.254510 reg=0.012404
2017/08/30 01:37:48 step 1: objective=0.255200 reg=0.012405
2017/08/30 01:37:59 step 2: objective=0.255936 reg=0.012407
2017/08/30 01:38:09 step 3: objective=0.256438 reg=0.012406
2017/08/30 01:38:19 step 4: objective=0.256945 reg=0.012404
2017/08/30 01:38:30 step 5: objective=0.257409 reg=0.012405
2017/08/30 01:38:40 step 6: objective=0.257871 reg=0.012403
2017/08/30 01:38:50 step 7: objective=0.258334 reg=0.012405
2017/08/30 01:38:50 Training value function...
2017/08/30 01:38:56 step 0: mse=1.153196 step=0.050000
2017/08/30 01:39:00 step 1: mse=1.152604 step=0.050000
2017/08/30 01:39:03 step 2: mse=1.152063 step=0.050000
2017/08/30 01:39:07 step 3: mse=1.151563 step=0.050000
2017/08/30 01:39:10 step 4: mse=1.151098 step=0.050000
2017/08/30 01:39:14 step 5: mse=1.150657 step=0.050000
2017/08/30 01:39:17 step 6: mse=1.150254 step=0.050000
2017/08/30 01:39:21 step 7: mse=1.149833 step=0.050000
2017/08/30 01:39:21 Saving...
2017/08/30 01:39:21 Gathering batch of experience...
2017/08/30 01:39:55 batch 357: mean=5.529459 stddev=1.500510 entropy=1.236094 frames=100140 count=5007
2017/08/30 01:39:55 Training policy...
2017/08/30 01:40:13 step 0: objective=0.263510 reg=0.012361
2017/08/30 01:40:23 step 1: objective=0.264182 reg=0.012357
2017/08/30 01:40:33 step 2: objective=0.264671 reg=0.012367
2017/08/30 01:40:43 step 3: objective=0.265154 reg=0.012356
2017/08/30 01:40:54 step 4: objective=0.265469 reg=0.012368
2017/08/30 01:41:04 step 5: objective=0.265929 reg=0.012350
2017/08/30 01:41:15 step 6: objective=0.266240 reg=0.012360
2017/08/30 01:41:25 step 7: objective=0.266622 reg=0.012347
2017/08/30 01:41:25 Training value function...
2017/08/30 01:41:31 step 0: mse=1.194530 step=0.050000
2017/08/30 01:41:34 step 1: mse=1.193589 step=0.050000
2017/08/30 01:41:38 step 2: mse=1.192719 step=0.050000
2017/08/30 01:41:42 step 3: mse=1.191909 step=0.050000
2017/08/30 01:41:45 step 4: mse=1.191163 step=0.050000
2017/08/30 01:41:49 step 5: mse=1.190460 step=0.050000
2017/08/30 01:41:52 step 6: mse=1.189796 step=0.050000
2017/08/30 01:41:55 step 7: mse=1.189176 step=0.050000
2017/08/30 01:41:55 Saving...
2017/08/30 01:41:56 Gathering batch of experience...
2017/08/30 01:42:30 batch 358: mean=5.526463 stddev=1.454471 entropy=1.239946 frames=100140 count=5007
2017/08/30 01:42:30 Training policy...
2017/08/30 01:42:48 step 0: objective=0.245149 reg=0.012399
2017/08/30 01:42:58 step 1: objective=0.245860 reg=0.012403
2017/08/30 01:43:09 step 2: objective=0.246463 reg=0.012401
2017/08/30 01:43:19 step 3: objective=0.247020 reg=0.012404
2017/08/30 01:43:29 step 4: objective=0.247600 reg=0.012405
2017/08/30 01:43:40 step 5: objective=0.248114 reg=0.012405
2017/08/30 01:43:50 step 6: objective=0.248590 reg=0.012404
2017/08/30 01:44:00 step 7: objective=0.248964 reg=0.012405
2017/08/30 01:44:00 Training value function...
2017/08/30 01:44:06 step 0: mse=1.131241 step=0.050000
2017/08/30 01:44:09 step 1: mse=1.131397 step=0.050000
2017/08/30 01:44:13 step 2: mse=1.131559 step=0.050000
2017/08/30 01:44:16 step 3: mse=1.131700 step=0.050000
2017/08/30 01:44:20 step 4: mse=1.131850 step=0.050000
2017/08/30 01:44:23 step 5: mse=1.131980 step=0.050000
2017/08/30 01:44:27 step 6: mse=1.132117 step=0.050000
2017/08/30 01:44:30 step 7: mse=1.132233 step=0.050000
2017/08/30 01:44:30 Saving...
2017/08/30 01:44:30 Gathering batch of experience...
2017/08/30 01:45:05 batch 359: mean=5.527062 stddev=1.444125 entropy=1.240443 frames=100140 count=5007
2017/08/30 01:45:05 Training policy...
2017/08/30 01:45:24 step 0: objective=0.263530 reg=0.012404
2017/08/30 01:45:34 step 1: objective=0.264083 reg=0.012403
2017/08/30 01:45:45 step 2: objective=0.264697 reg=0.012399
2017/08/30 01:45:55 step 3: objective=0.265276 reg=0.012395
2017/08/30 01:46:05 step 4: objective=0.265737 reg=0.012390
2017/08/30 01:46:16 step 5: objective=0.266150 reg=0.012381
2017/08/30 01:46:26 step 6: objective=0.266597 reg=0.012376
2017/08/30 01:46:36 step 7: objective=0.266964 reg=0.012373
2017/08/30 01:46:36 Training value function...
2017/08/30 01:46:42 step 0: mse=1.167795 step=0.050000
2017/08/30 01:46:46 step 1: mse=1.166675 step=0.050000
2017/08/30 01:46:49 step 2: mse=1.165636 step=0.050000
2017/08/30 01:46:53 step 3: mse=1.164672 step=0.050000
2017/08/30 01:46:56 step 4: mse=1.163770 step=0.050000
2017/08/30 01:47:00 step 5: mse=1.162925 step=0.050000
2017/08/30 01:47:03 step 6: mse=1.162134 step=0.050000
2017/08/30 01:47:07 step 7: mse=1.161393 step=0.050000
2017/08/30 01:47:07 Saving...
2017/08/30 01:47:07 Gathering batch of experience...
2017/08/30 01:47:41 batch 360: mean=5.553026 stddev=1.468236 entropy=1.235696 frames=100140 count=5007
2017/08/30 01:47:41 Training policy...
2017/08/30 01:48:00 step 0: objective=0.256826 reg=0.012357
2017/08/30 01:48:10 step 1: objective=0.257582 reg=0.012352
2017/08/30 01:48:21 step 2: objective=0.258123 reg=0.012349
2017/08/30 01:48:31 step 3: objective=0.258687 reg=0.012350
2017/08/30 01:48:41 step 4: objective=0.259116 reg=0.012347
2017/08/30 01:48:52 step 5: objective=0.259597 reg=0.012344
2017/08/30 01:49:03 step 6: objective=0.260083 reg=0.012345
2017/08/30 01:49:13 step 7: objective=0.260423 reg=0.012346
2017/08/30 01:49:13 Training value function...
2017/08/30 01:49:19 step 0: mse=1.181984 step=0.050000
2017/08/30 01:49:23 step 1: mse=1.181332 step=0.050000
2017/08/30 01:49:26 step 2: mse=1.180755 step=0.050000
2017/08/30 01:49:30 step 3: mse=1.180193 step=0.050000
2017/08/30 01:49:33 step 4: mse=1.179640 step=0.050000
2017/08/30 01:49:36 step 5: mse=1.179146 step=0.050000
2017/08/30 01:49:40 step 6: mse=1.178664 step=0.050000
2017/08/30 01:49:43 step 7: mse=1.178224 step=0.050000
2017/08/30 01:49:43 Saving...
2017/08/30 01:49:44 Gathering batch of experience...
2017/08/30 01:50:18 batch 361: mean=5.480927 stddev=1.465803 entropy=1.239049 frames=100140 count=5007
2017/08/30 01:50:18 Training policy...
2017/08/30 01:50:36 step 0: objective=0.226803 reg=0.012390
2017/08/30 01:50:46 step 1: objective=0.227532 reg=0.012389
2017/08/30 01:50:57 step 2: objective=0.228089 reg=0.012390
2017/08/30 01:51:08 step 3: objective=0.228755 reg=0.012388
2017/08/30 01:51:18 step 4: objective=0.229205 reg=0.012388
2017/08/30 01:51:29 step 5: objective=0.229711 reg=0.012383
2017/08/30 01:51:39 step 6: objective=0.230177 reg=0.012381
2017/08/30 01:51:49 step 7: objective=0.230575 reg=0.012377
2017/08/30 01:51:49 Training value function...
2017/08/30 01:51:56 step 0: mse=1.125101 step=0.050000
2017/08/30 01:51:59 step 1: mse=1.126147 step=0.050000
2017/08/30 01:52:03 step 2: mse=1.127144 step=0.050000
2017/08/30 01:52:06 step 3: mse=1.128096 step=0.050000
2017/08/30 01:52:10 step 4: mse=1.128981 step=0.050000
2017/08/30 01:52:13 step 5: mse=1.129794 step=0.050000
2017/08/30 01:52:17 step 6: mse=1.130589 step=0.050000
2017/08/30 01:52:20 step 7: mse=1.131317 step=0.050000
2017/08/30 01:52:20 Saving...
2017/08/30 01:52:20 Gathering batch of experience...
2017/08/30 01:52:55 batch 362: mean=5.508688 stddev=1.443246 entropy=1.233925 frames=100140 count=5007
2017/08/30 01:52:55 Training policy...
2017/08/30 01:53:13 step 0: objective=0.253093 reg=0.012339
2017/08/30 01:53:23 step 1: objective=0.253699 reg=0.012338
2017/08/30 01:53:34 step 2: objective=0.254318 reg=0.012338
2017/08/30 01:53:44 step 3: objective=0.254895 reg=0.012338
2017/08/30 01:53:55 step 4: objective=0.255354 reg=0.012342
2017/08/30 01:54:05 step 5: objective=0.255830 reg=0.012341
2017/08/30 01:54:16 step 6: objective=0.256245 reg=0.012336
2017/08/30 01:54:27 step 7: objective=0.256715 reg=0.012333
2017/08/30 01:54:27 Training value function...
2017/08/30 01:54:33 step 0: mse=1.142123 step=0.050000
2017/08/30 01:54:36 step 1: mse=1.141692 step=0.050000
2017/08/30 01:54:40 step 2: mse=1.141297 step=0.050000
2017/08/30 01:54:43 step 3: mse=1.140932 step=0.050000
2017/08/30 01:54:47 step 4: mse=1.140598 step=0.050000
2017/08/30 01:54:50 step 5: mse=1.140287 step=0.050000
2017/08/30 01:54:54 step 6: mse=1.139993 step=0.050000
2017/08/30 01:54:57 step 7: mse=1.139719 step=0.050000
2017/08/30 01:54:57 Saving...
2017/08/30 01:54:57 Gathering batch of experience...
2017/08/30 01:55:32 batch 363: mean=5.518674 stddev=1.431200 entropy=1.239170 frames=100140 count=5007
2017/08/30 01:55:32 Training policy...
2017/08/30 01:55:49 step 0: objective=0.252784 reg=0.012392
2017/08/30 01:56:00 step 1: objective=0.253436 reg=0.012392
2017/08/30 01:56:10 step 2: objective=0.254035 reg=0.012388
2017/08/30 01:56:21 step 3: objective=0.254639 reg=0.012388
2017/08/30 01:56:32 step 4: objective=0.255127 reg=0.012386
2017/08/30 01:56:42 step 5: objective=0.255518 reg=0.012382
2017/08/30 01:56:53 step 6: objective=0.255969 reg=0.012381
2017/08/30 01:57:04 step 7: objective=0.256415 reg=0.012380
2017/08/30 01:57:04 Training value function...
2017/08/30 01:57:09 step 0: mse=1.114701 step=0.050000
2017/08/30 01:57:13 step 1: mse=1.114318 step=0.050000
2017/08/30 01:57:16 step 2: mse=1.113965 step=0.050000
2017/08/30 01:57:20 step 3: mse=1.113644 step=0.050000
2017/08/30 01:57:23 step 4: mse=1.113344 step=0.050000
2017/08/30 01:57:27 step 5: mse=1.113063 step=0.050000
2017/08/30 01:57:30 step 6: mse=1.112765 step=0.050000
2017/08/30 01:57:34 step 7: mse=1.112491 step=0.050000
2017/08/30 01:57:34 Saving...
2017/08/30 01:57:34 Gathering batch of experience...
2017/08/30 01:58:09 batch 364: mean=5.524466 stddev=1.457798 entropy=1.234812 frames=100140 count=5007
2017/08/30 01:58:09 Training policy...
2017/08/30 01:58:27 step 0: objective=0.253622 reg=0.012348
2017/08/30 01:58:38 step 1: objective=0.254175 reg=0.012346
2017/08/30 01:58:48 step 2: objective=0.254781 reg=0.012341
2017/08/30 01:58:59 step 3: objective=0.255178 reg=0.012346
2017/08/30 01:59:10 step 4: objective=0.255750 reg=0.012346
2017/08/30 01:59:20 step 5: objective=0.256223 reg=0.012343
2017/08/30 01:59:31 step 6: objective=0.256640 reg=0.012341
2017/08/30 01:59:41 step 7: objective=0.257077 reg=0.012338
2017/08/30 01:59:41 Training value function...
2017/08/30 01:59:48 step 0: mse=1.141917 step=0.050000
2017/08/30 01:59:51 step 1: mse=1.141299 step=0.050000
2017/08/30 01:59:54 step 2: mse=1.140733 step=0.050000
2017/08/30 01:59:58 step 3: mse=1.140211 step=0.050000
2017/08/30 02:00:01 step 4: mse=1.139746 step=0.050000
2017/08/30 02:00:05 step 5: mse=1.139312 step=0.050000
2017/08/30 02:00:08 step 6: mse=1.138895 step=0.050000
2017/08/30 02:00:12 step 7: mse=1.138493 step=0.050000
2017/08/30 02:00:12 Saving...
2017/08/30 02:00:12 Gathering batch of experience...
2017/08/30 02:00:47 batch 365: mean=5.525065 stddev=1.479276 entropy=1.236356 frames=100140 count=5007
2017/08/30 02:00:47 Training policy...
2017/08/30 02:01:04 step 0: objective=0.255956 reg=0.012363
2017/08/30 02:01:15 step 1: objective=0.256620 reg=0.012362
2017/08/30 02:01:26 step 2: objective=0.257220 reg=0.012357
2017/08/30 02:01:36 step 3: objective=0.257780 reg=0.012359
2017/08/30 02:01:47 step 4: objective=0.258287 reg=0.012357
2017/08/30 02:01:57 step 5: objective=0.258810 reg=0.012353
2017/08/30 02:02:08 step 6: objective=0.259252 reg=0.012355
2017/08/30 02:02:18 step 7: objective=0.259666 reg=0.012352
2017/08/30 02:02:18 Training value function...
2017/08/30 02:02:24 step 0: mse=1.171282 step=0.050000
2017/08/30 02:02:28 step 1: mse=1.170623 step=0.050000
2017/08/30 02:02:31 step 2: mse=1.169979 step=0.050000
2017/08/30 02:02:35 step 3: mse=1.169384 step=0.050000
2017/08/30 02:02:38 step 4: mse=1.168830 step=0.050000
2017/08/30 02:02:42 step 5: mse=1.168316 step=0.050000
2017/08/30 02:02:45 step 6: mse=1.167834 step=0.050000
2017/08/30 02:02:49 step 7: mse=1.167387 step=0.050000
2017/08/30 02:02:49 Saving...
2017/08/30 02:02:49 Gathering batch of experience...
2017/08/30 02:03:24 batch 366: mean=5.506890 stddev=1.464138 entropy=1.232471 frames=100140 count=5007
2017/08/30 02:03:24 Training policy...
2017/08/30 02:03:42 step 0: objective=0.251627 reg=0.012325
2017/08/30 02:03:52 step 1: objective=0.252226 reg=0.012326
2017/08/30 02:04:03 step 2: objective=0.252940 reg=0.012329
2017/08/30 02:04:14 step 3: objective=0.253566 reg=0.012327
2017/08/30 02:04:24 step 4: objective=0.254148 reg=0.012326
2017/08/30 02:04:35 step 5: objective=0.254589 reg=0.012326
2017/08/30 02:04:45 step 6: objective=0.254959 reg=0.012325
2017/08/30 02:04:56 step 7: objective=0.255410 reg=0.012325
2017/08/30 02:04:56 Training value function...
2017/08/30 02:05:02 step 0: mse=1.167284 step=0.050000
2017/08/30 02:05:06 step 1: mse=1.166982 step=0.050000
2017/08/30 02:05:09 step 2: mse=1.166708 step=0.050000
2017/08/30 02:05:13 step 3: mse=1.166455 step=0.050000
2017/08/30 02:05:16 step 4: mse=1.166205 step=0.050000
2017/08/30 02:05:20 step 5: mse=1.165955 step=0.050000
2017/08/30 02:05:23 step 6: mse=1.165742 step=0.050000
2017/08/30 02:05:27 step 7: mse=1.165530 step=0.050000
2017/08/30 02:05:27 Saving...
2017/08/30 02:05:27 Gathering batch of experience...
2017/08/30 02:06:02 batch 367: mean=5.529259 stddev=1.469717 entropy=1.227373 frames=100140 count=5007
2017/08/30 02:06:02 Training policy...
2017/08/30 02:06:20 step 0: objective=0.259480 reg=0.012274
2017/08/30 02:06:30 step 1: objective=0.259980 reg=0.012278
2017/08/30 02:06:41 step 2: objective=0.260496 reg=0.012270
2017/08/30 02:06:52 step 3: objective=0.260995 reg=0.012270
2017/08/30 02:07:03 step 4: objective=0.261586 reg=0.012268
2017/08/30 02:07:14 step 5: objective=0.262042 reg=0.012266
2017/08/30 02:07:24 step 6: objective=0.262481 reg=0.012264
2017/08/30 02:07:35 step 7: objective=0.262892 reg=0.012256
2017/08/30 02:07:35 Training value function...
2017/08/30 02:07:41 step 0: mse=1.181140 step=0.050000
2017/08/30 02:07:44 step 1: mse=1.180147 step=0.050000
2017/08/30 02:07:48 step 2: mse=1.179223 step=0.050000
2017/08/30 02:07:51 step 3: mse=1.178359 step=0.050000
2017/08/30 02:07:55 step 4: mse=1.177555 step=0.050000
2017/08/30 02:07:58 step 5: mse=1.176797 step=0.050000
2017/08/30 02:08:02 step 6: mse=1.176082 step=0.050000
2017/08/30 02:08:05 step 7: mse=1.175403 step=0.050000
2017/08/30 02:08:05 Saving...
2017/08/30 02:08:05 Gathering batch of experience...
2017/08/30 02:08:40 batch 368: mean=5.525065 stddev=1.456554 entropy=1.229800 frames=100140 count=5007
2017/08/30 02:08:40 Training policy...
2017/08/30 02:08:59 step 0: objective=0.262471 reg=0.012298
2017/08/30 02:09:09 step 1: objective=0.263009 reg=0.012297
2017/08/30 02:09:20 step 2: objective=0.263647 reg=0.012298
2017/08/30 02:09:31 step 3: objective=0.264287 reg=0.012295
2017/08/30 02:09:41 step 4: objective=0.264878 reg=0.012294
2017/08/30 02:09:52 step 5: objective=0.265188 reg=0.012296
2017/08/30 02:10:03 step 6: objective=0.265665 reg=0.012288
2017/08/30 02:10:14 step 7: objective=0.265955 reg=0.012294
2017/08/30 02:10:14 Training value function...
2017/08/30 02:10:20 step 0: mse=1.187028 step=0.050000
2017/08/30 02:10:23 step 1: mse=1.186152 step=0.050000
2017/08/30 02:10:27 step 2: mse=1.185301 step=0.050000
2017/08/30 02:10:30 step 3: mse=1.184538 step=0.050000
2017/08/30 02:10:34 step 4: mse=1.183785 step=0.050000
2017/08/30 02:10:37 step 5: mse=1.183108 step=0.050000
2017/08/30 02:10:41 step 6: mse=1.182461 step=0.050000
2017/08/30 02:10:44 step 7: mse=1.181851 step=0.050000
2017/08/30 02:10:44 Saving...
2017/08/30 02:10:44 Gathering batch of experience...
2017/08/30 02:11:19 batch 369: mean=5.546036 stddev=1.472953 entropy=1.223134 frames=100140 count=5007
2017/08/30 02:11:19 Training policy...
2017/08/30 02:11:37 step 0: objective=0.245747 reg=0.012231
2017/08/30 02:11:48 step 1: objective=0.246409 reg=0.012236
2017/08/30 02:11:58 step 2: objective=0.246950 reg=0.012235
2017/08/30 02:12:09 step 3: objective=0.247541 reg=0.012231
2017/08/30 02:12:20 step 4: objective=0.248053 reg=0.012225
2017/08/30 02:12:31 step 5: objective=0.248426 reg=0.012220
2017/08/30 02:12:41 step 6: objective=0.248864 reg=0.012218
2017/08/30 02:12:52 step 7: objective=0.249189 reg=0.012216
2017/08/30 02:12:52 Training value function...
2017/08/30 02:12:58 step 0: mse=1.159089 step=0.050000
2017/08/30 02:13:02 step 1: mse=1.159110 step=0.050000
2017/08/30 02:13:05 step 2: mse=1.159135 step=0.050000
2017/08/30 02:13:09 step 3: mse=1.159166 step=0.050000
2017/08/30 02:13:12 step 4: mse=1.159202 step=0.050000
2017/08/30 02:13:15 step 5: mse=1.159238 step=0.050000
2017/08/30 02:13:19 step 6: mse=1.159275 step=0.050000
2017/08/30 02:13:22 step 7: mse=1.159324 step=0.050000
2017/08/30 02:13:22 Saving...
2017/08/30 02:13:23 Gathering batch of experience...
2017/08/30 02:13:57 batch 370: mean=5.551029 stddev=1.450241 entropy=1.224373 frames=100140 count=5007
2017/08/30 02:13:57 Training policy...
2017/08/30 02:14:16 step 0: objective=0.256938 reg=0.012244
2017/08/30 02:14:27 step 1: objective=0.257470 reg=0.012243
2017/08/30 02:14:38 step 2: objective=0.258086 reg=0.012243
2017/08/30 02:14:48 step 3: objective=0.258545 reg=0.012245
2017/08/30 02:14:59 step 4: objective=0.259008 reg=0.012242
2017/08/30 02:15:10 step 5: objective=0.259449 reg=0.012238
2017/08/30 02:15:20 step 6: objective=0.259950 reg=0.012237
2017/08/30 02:15:31 step 7: objective=0.260354 reg=0.012230
2017/08/30 02:15:31 Training value function...
2017/08/30 02:15:37 step 0: mse=1.137820 step=0.050000
2017/08/30 02:15:41 step 1: mse=1.137066 step=0.050000
2017/08/30 02:15:44 step 2: mse=1.136371 step=0.050000
2017/08/30 02:15:48 step 3: mse=1.135724 step=0.050000
2017/08/30 02:15:51 step 4: mse=1.135112 step=0.050000
2017/08/30 02:15:55 step 5: mse=1.134538 step=0.050000
2017/08/30 02:15:58 step 6: mse=1.133957 step=0.050000
2017/08/30 02:16:02 step 7: mse=1.133420 step=0.050000
2017/08/30 02:16:02 Saving...
2017/08/30 02:16:02 Gathering batch of experience...
2017/08/30 02:16:37 batch 371: mean=5.486719 stddev=1.467092 entropy=1.226296 frames=100140 count=5007
2017/08/30 02:16:37 Training policy...
2017/08/30 02:16:55 step 0: objective=0.230647 reg=0.012263
2017/08/30 02:17:06 step 1: objective=0.231249 reg=0.012262
2017/08/30 02:17:17 step 2: objective=0.231888 reg=0.012259
2017/08/30 02:17:27 step 3: objective=0.232345 reg=0.012260
2017/08/30 02:17:38 step 4: objective=0.232777 reg=0.012257
2017/08/30 02:17:49 step 5: objective=0.233202 reg=0.012258
2017/08/30 02:18:00 step 6: objective=0.233718 reg=0.012250
2017/08/30 02:18:11 step 7: objective=0.234127 reg=0.012245
2017/08/30 02:18:11 Training value function...
2017/08/30 02:18:17 step 0: mse=1.139844 step=0.050000
2017/08/30 02:18:20 step 1: mse=1.140629 step=0.050000
2017/08/30 02:18:24 step 2: mse=1.141390 step=0.050000
2017/08/30 02:18:27 step 3: mse=1.142125 step=0.050000
2017/08/30 02:18:31 step 4: mse=1.142839 step=0.050000
2017/08/30 02:18:34 step 5: mse=1.143522 step=0.050000
2017/08/30 02:18:38 step 6: mse=1.144176 step=0.050000
2017/08/30 02:18:41 step 7: mse=1.144809 step=0.050000
2017/08/30 02:18:41 Saving...
2017/08/30 02:18:41 Gathering batch of experience...
2017/08/30 02:19:16 batch 372: mean=5.518075 stddev=1.446614 entropy=1.227341 frames=100140 count=5007
2017/08/30 02:19:16 Training policy...
2017/08/30 02:19:34 step 0: objective=0.259188 reg=0.012273
2017/08/30 02:19:45 step 1: objective=0.259793 reg=0.012264
2017/08/30 02:19:56 step 2: objective=0.260413 reg=0.012262
2017/08/30 02:20:07 step 3: objective=0.260926 reg=0.012260
2017/08/30 02:20:18 step 4: objective=0.261340 reg=0.012266
2017/08/30 02:20:29 step 5: objective=0.261829 reg=0.012264
2017/08/30 02:20:39 step 6: objective=0.262233 reg=0.012259
2017/08/30 02:20:50 step 7: objective=0.262645 reg=0.012256
2017/08/30 02:20:50 Training value function...
2017/08/30 02:20:56 step 0: mse=1.145623 step=0.050000
2017/08/30 02:21:00 step 1: mse=1.144894 step=0.050000
2017/08/30 02:21:03 step 2: mse=1.144243 step=0.050000
2017/08/30 02:21:07 step 3: mse=1.143613 step=0.050000
2017/08/30 02:21:10 step 4: mse=1.143037 step=0.050000
2017/08/30 02:21:14 step 5: mse=1.142482 step=0.050000
2017/08/30 02:21:17 step 6: mse=1.141977 step=0.050000
2017/08/30 02:21:21 step 7: mse=1.141487 step=0.050000
2017/08/30 02:21:21 Saving...
2017/08/30 02:21:21 Gathering batch of experience...
2017/08/30 02:21:56 batch 373: mean=5.515678 stddev=1.466252 entropy=1.223057 frames=100140 count=5007
2017/08/30 02:21:56 Training policy...
2017/08/30 02:22:14 step 0: objective=0.252012 reg=0.012231
2017/08/30 02:22:24 step 1: objective=0.252582 reg=0.012232
2017/08/30 02:22:35 step 2: objective=0.253115 reg=0.012231
2017/08/30 02:22:46 step 3: objective=0.253695 reg=0.012231
2017/08/30 02:22:57 step 4: objective=0.254126 reg=0.012227
2017/08/30 02:23:08 step 5: objective=0.254642 reg=0.012226
2017/08/30 02:23:19 step 6: objective=0.255186 reg=0.012226
2017/08/30 02:23:30 step 7: objective=0.255632 reg=0.012224
2017/08/30 02:23:30 Training value function...
2017/08/30 02:23:36 step 0: mse=1.155795 step=0.050000
2017/08/30 02:23:39 step 1: mse=1.155450 step=0.050000
2017/08/30 02:23:43 step 2: mse=1.155141 step=0.050000
2017/08/30 02:23:46 step 3: mse=1.154863 step=0.050000
2017/08/30 02:23:50 step 4: mse=1.154613 step=0.050000
2017/08/30 02:23:53 step 5: mse=1.154385 step=0.050000
2017/08/30 02:23:57 step 6: mse=1.154172 step=0.050000
2017/08/30 02:24:00 step 7: mse=1.153958 step=0.050000
2017/08/30 02:24:00 Saving...
2017/08/30 02:24:00 Gathering batch of experience...
2017/08/30 02:24:35 batch 374: mean=5.554224 stddev=1.481463 entropy=1.215932 frames=100140 count=5007
2017/08/30 02:24:35 Training policy...
2017/08/30 02:24:54 step 0: objective=0.257201 reg=0.012159
2017/08/30 02:25:04 step 1: objective=0.257913 reg=0.012155
2017/08/30 02:25:15 step 2: objective=0.258272 reg=0.012160
2017/08/30 02:25:26 step 3: objective=0.258705 reg=0.012146
2017/08/30 02:25:37 step 4: objective=0.259108 reg=0.012148
2017/08/30 02:25:49 step 5: objective=0.259528 reg=0.012143
2017/08/30 02:26:00 step 6: objective=0.259978 reg=0.012145
2017/08/30 02:26:10 step 7: objective=0.260413 reg=0.012144
2017/08/30 02:26:10 Training value function...
2017/08/30 02:26:17 step 0: mse=1.172063 step=0.050000
2017/08/30 02:26:20 step 1: mse=1.171314 step=0.050000
2017/08/30 02:26:23 step 2: mse=1.170624 step=0.050000
2017/08/30 02:26:27 step 3: mse=1.169983 step=0.050000
2017/08/30 02:26:30 step 4: mse=1.169382 step=0.050000
2017/08/30 02:26:34 step 5: mse=1.168817 step=0.050000
2017/08/30 02:26:37 step 6: mse=1.168291 step=0.050000
2017/08/30 02:26:41 step 7: mse=1.167795 step=0.050000
2017/08/30 02:26:41 Saving...
2017/08/30 02:26:41 Gathering batch of experience...
2017/08/30 02:27:16 batch 375: mean=5.517276 stddev=1.451998 entropy=1.215202 frames=100140 count=5007
2017/08/30 02:27:16 Training policy...
2017/08/30 02:27:35 step 0: objective=0.246984 reg=0.012152
2017/08/30 02:27:45 step 1: objective=0.247742 reg=0.012149
2017/08/30 02:27:57 step 2: objective=0.248346 reg=0.012149
2017/08/30 02:28:08 step 3: objective=0.248877 reg=0.012153
2017/08/30 02:28:19 step 4: objective=0.249340 reg=0.012148
2017/08/30 02:28:29 step 5: objective=0.249797 reg=0.012149
2017/08/30 02:28:42 step 6: objective=0.250240 reg=0.012143
2017/08/30 02:28:53 step 7: objective=0.250514 reg=0.012137
2017/08/30 02:28:53 Training value function...
2017/08/30 02:28:58 step 0: mse=1.123313 step=0.050000
2017/08/30 02:29:02 step 1: mse=1.122907 step=0.050000
2017/08/30 02:29:06 step 2: mse=1.122536 step=0.050000
2017/08/30 02:29:09 step 3: mse=1.122196 step=0.050000
2017/08/30 02:29:13 step 4: mse=1.121882 step=0.050000
2017/08/30 02:29:16 step 5: mse=1.121592 step=0.050000
2017/08/30 02:29:20 step 6: mse=1.121321 step=0.050000
2017/08/30 02:29:23 step 7: mse=1.121069 step=0.050000
2017/08/30 02:29:23 Saving...
2017/08/30 02:29:23 Gathering batch of experience...
2017/08/30 02:29:58 batch 376: mean=5.508888 stddev=1.440336 entropy=1.214715 frames=100140 count=5007
2017/08/30 02:29:58 Training policy...
2017/08/30 02:30:16 step 0: objective=0.242113 reg=0.012147
2017/08/30 02:30:27 step 1: objective=0.242781 reg=0.012144
2017/08/30 02:30:39 step 2: objective=0.243376 reg=0.012144
2017/08/30 02:30:50 step 3: objective=0.243797 reg=0.012140
2017/08/30 02:31:01 step 4: objective=0.244238 reg=0.012145
2017/08/30 02:31:12 step 5: objective=0.244623 reg=0.012137
2017/08/30 02:31:23 step 6: objective=0.244831 reg=0.012146
2017/08/30 02:31:34 step 7: objective=0.245259 reg=0.012134
2017/08/30 02:31:34 Training value function...
2017/08/30 02:31:40 step 0: mse=1.110654 step=0.050000
2017/08/30 02:31:43 step 1: mse=1.110858 step=0.050000
2017/08/30 02:31:47 step 2: mse=1.111048 step=0.050000
2017/08/30 02:31:50 step 3: mse=1.111235 step=0.050000
2017/08/30 02:31:54 step 4: mse=1.111400 step=0.050000
2017/08/30 02:31:57 step 5: mse=1.111575 step=0.050000
2017/08/30 02:32:01 step 6: mse=1.111733 step=0.050000
2017/08/30 02:32:04 step 7: mse=1.111871 step=0.050000
2017/08/30 02:32:04 Saving...
2017/08/30 02:32:05 Gathering batch of experience...
2017/08/30 02:32:40 batch 377: mean=5.540443 stddev=1.469996 entropy=1.213306 frames=100140 count=5007
2017/08/30 02:32:40 Training policy...
2017/08/30 02:32:59 step 0: objective=0.258894 reg=0.012133
2017/08/30 02:33:10 step 1: objective=0.259433 reg=0.012138
2017/08/30 02:33:21 step 2: objective=0.260041 reg=0.012131
2017/08/30 02:33:32 step 3: objective=0.260577 reg=0.012132
2017/08/30 02:33:44 step 4: objective=0.261080 reg=0.012129
2017/08/30 02:33:55 step 5: objective=0.261667 reg=0.012127
2017/08/30 02:34:06 step 6: objective=0.262080 reg=0.012125
2017/08/30 02:34:17 step 7: objective=0.262461 reg=0.012127
2017/08/30 02:34:17 Training value function...
2017/08/30 02:34:23 step 0: mse=1.161700 step=0.050000
2017/08/30 02:34:26 step 1: mse=1.161086 step=0.050000
2017/08/30 02:34:30 step 2: mse=1.160521 step=0.050000
2017/08/30 02:34:33 step 3: mse=1.159993 step=0.050000
2017/08/30 02:34:37 step 4: mse=1.159508 step=0.050000
2017/08/30 02:34:40 step 5: mse=1.159049 step=0.050000
2017/08/30 02:34:44 step 6: mse=1.158620 step=0.050000
2017/08/30 02:34:47 step 7: mse=1.158216 step=0.050000
2017/08/30 02:34:47 Saving...
2017/08/30 02:34:48 Gathering batch of experience...
2017/08/30 02:35:23 batch 378: mean=5.501498 stddev=1.456906 entropy=1.212293 frames=100140 count=5007
2017/08/30 02:35:23 Training policy...
2017/08/30 02:35:41 step 0: objective=0.245874 reg=0.012123
2017/08/30 02:35:52 step 1: objective=0.246519 reg=0.012121
2017/08/30 02:36:04 step 2: objective=0.247154 reg=0.012122
2017/08/30 02:36:15 step 3: objective=0.247725 reg=0.012129
2017/08/30 02:36:26 step 4: objective=0.248231 reg=0.012128
2017/08/30 02:36:38 step 5: objective=0.248763 reg=0.012126
2017/08/30 02:36:49 step 6: objective=0.249198 reg=0.012124
2017/08/30 02:37:00 step 7: objective=0.249583 reg=0.012123
2017/08/30 02:37:00 Training value function...
2017/08/30 02:37:06 step 0: mse=1.142657 step=0.050000
2017/08/30 02:37:10 step 1: mse=1.142502 step=0.050000
2017/08/30 02:37:13 step 2: mse=1.142373 step=0.050000
2017/08/30 02:37:16 step 3: mse=1.142262 step=0.050000
2017/08/30 02:37:20 step 4: mse=1.142169 step=0.050000
2017/08/30 02:37:23 step 5: mse=1.142045 step=0.050000
2017/08/30 02:37:27 step 6: mse=1.141982 step=0.050000
2017/08/30 02:37:30 step 7: mse=1.141924 step=0.050000
2017/08/30 02:37:30 Saving...
2017/08/30 02:37:30 Gathering batch of experience...
2017/08/30 02:38:06 batch 379: mean=5.544038 stddev=1.453358 entropy=1.215133 frames=100140 count=5007
2017/08/30 02:38:06 Training policy...
2017/08/30 02:38:24 step 0: objective=0.258058 reg=0.012151
2017/08/30 02:38:36 step 1: objective=0.258659 reg=0.012145
2017/08/30 02:38:47 step 2: objective=0.259469 reg=0.012148
2017/08/30 02:38:58 step 3: objective=0.260082 reg=0.012145
2017/08/30 02:39:10 step 4: objective=0.260579 reg=0.012144
2017/08/30 02:39:21 step 5: objective=0.260963 reg=0.012145
2017/08/30 02:39:33 step 6: objective=0.261411 reg=0.012144
2017/08/30 02:39:44 step 7: objective=0.261714 reg=0.012143
2017/08/30 02:39:44 Training value function...
2017/08/30 02:39:50 step 0: mse=1.161395 step=0.050000
2017/08/30 02:39:53 step 1: mse=1.160598 step=0.050000
2017/08/30 02:39:57 step 2: mse=1.159861 step=0.050000
2017/08/30 02:40:00 step 3: mse=1.159175 step=0.050000
2017/08/30 02:40:04 step 4: mse=1.158543 step=0.050000
2017/08/30 02:40:07 step 5: mse=1.157925 step=0.050000
2017/08/30 02:40:11 step 6: mse=1.157362 step=0.050000
2017/08/30 02:40:14 step 7: mse=1.156807 step=0.050000
2017/08/30 02:40:14 Saving...
2017/08/30 02:40:14 Gathering batch of experience...
2017/08/30 02:40:50 batch 380: mean=5.483923 stddev=1.495246 entropy=1.215533 frames=100140 count=5007
2017/08/30 02:40:50 Training policy...
2017/08/30 02:41:08 step 0: objective=0.236616 reg=0.012155
2017/08/30 02:41:20 step 1: objective=0.237278 reg=0.012155
2017/08/30 02:41:31 step 2: objective=0.237820 reg=0.012154
2017/08/30 02:41:42 step 3: objective=0.238314 reg=0.012148
2017/08/30 02:41:53 step 4: objective=0.238702 reg=0.012151
2017/08/30 02:42:04 step 5: objective=0.239149 reg=0.012144
2017/08/30 02:42:16 step 6: objective=0.239568 reg=0.012144
2017/08/30 02:42:27 step 7: objective=0.239996 reg=0.012146
2017/08/30 02:42:27 Training value function...
2017/08/30 02:42:33 step 0: mse=1.140431 step=0.050000
2017/08/30 02:42:36 step 1: mse=1.140916 step=0.050000
2017/08/30 02:42:40 step 2: mse=1.141364 step=0.050000
2017/08/30 02:42:43 step 3: mse=1.141798 step=0.050000
2017/08/30 02:42:47 step 4: mse=1.142204 step=0.050000
2017/08/30 02:42:50 step 5: mse=1.142587 step=0.050000
2017/08/30 02:42:54 step 6: mse=1.142955 step=0.050000
2017/08/30 02:42:57 step 7: mse=1.143300 step=0.050000
2017/08/30 02:42:57 Saving...
2017/08/30 02:42:57 Gathering batch of experience...
2017/08/30 02:43:33 batch 381: mean=5.537248 stddev=1.494601 entropy=1.213546 frames=100140 count=5007
2017/08/30 02:43:33 Training policy...
2017/08/30 02:43:52 step 0: objective=0.255130 reg=0.012135
2017/08/30 02:44:03 step 1: objective=0.255969 reg=0.012138
2017/08/30 02:44:15 step 2: objective=0.256525 reg=0.012139
2017/08/30 02:44:26 step 3: objective=0.257229 reg=0.012139
2017/08/30 02:44:37 step 4: objective=0.257646 reg=0.012135
2017/08/30 02:44:48 step 5: objective=0.258087 reg=0.012134
2017/08/30 02:45:00 step 6: objective=0.258511 reg=0.012134
2017/08/30 02:45:11 step 7: objective=0.259011 reg=0.012125
2017/08/30 02:45:11 Training value function...
2017/08/30 02:45:17 step 0: mse=1.167407 step=0.050000
2017/08/30 02:45:21 step 1: mse=1.166818 step=0.050000
2017/08/30 02:45:24 step 2: mse=1.166278 step=0.050000
2017/08/30 02:45:28 step 3: mse=1.165778 step=0.050000
2017/08/30 02:45:31 step 4: mse=1.165319 step=0.050000
2017/08/30 02:45:35 step 5: mse=1.164890 step=0.050000
2017/08/30 02:45:38 step 6: mse=1.164471 step=0.050000
2017/08/30 02:45:41 step 7: mse=1.164086 step=0.050000
2017/08/30 02:45:41 Saving...
2017/08/30 02:45:42 Gathering batch of experience...
2017/08/30 02:46:17 batch 382: mean=5.521270 stddev=1.453733 entropy=1.212902 frames=100140 count=5007
2017/08/30 02:46:17 Training policy...
2017/08/30 02:46:35 step 0: objective=0.242638 reg=0.012129
2017/08/30 02:46:47 step 1: objective=0.243340 reg=0.012130
2017/08/30 02:46:58 step 2: objective=0.243964 reg=0.012131
2017/08/30 02:47:09 step 3: objective=0.244466 reg=0.012137
2017/08/30 02:47:20 step 4: objective=0.244970 reg=0.012134
2017/08/30 02:47:31 step 5: objective=0.245358 reg=0.012128
2017/08/30 02:47:43 step 6: objective=0.245775 reg=0.012134
2017/08/30 02:47:54 step 7: objective=0.246162 reg=0.012128
2017/08/30 02:47:54 Training value function...
2017/08/30 02:48:00 step 0: mse=1.143267 step=0.050000
2017/08/30 02:48:04 step 1: mse=1.143534 step=0.050000
2017/08/30 02:48:07 step 2: mse=1.143731 step=0.050000
2017/08/30 02:48:11 step 3: mse=1.143926 step=0.050000
2017/08/30 02:48:14 step 4: mse=1.144113 step=0.050000
2017/08/30 02:48:18 step 5: mse=1.144297 step=0.050000
2017/08/30 02:48:21 step 6: mse=1.144468 step=0.050000
2017/08/30 02:48:25 step 7: mse=1.144630 step=0.050000
2017/08/30 02:48:25 Saving...
2017/08/30 02:48:25 Gathering batch of experience...
2017/08/30 02:49:00 batch 383: mean=5.511284 stddev=1.497692 entropy=1.211676 frames=100140 count=5007
2017/08/30 02:49:00 Training policy...
2017/08/30 02:49:19 step 0: objective=0.263789 reg=0.012117
2017/08/30 02:49:30 step 1: objective=0.264238 reg=0.012116
2017/08/30 02:49:42 step 2: objective=0.264761 reg=0.012115
2017/08/30 02:49:53 step 3: objective=0.265272 reg=0.012114
2017/08/30 02:50:04 step 4: objective=0.265821 reg=0.012112
2017/08/30 02:50:16 step 5: objective=0.266270 reg=0.012112
2017/08/30 02:50:27 step 6: objective=0.266810 reg=0.012107
2017/08/30 02:50:38 step 7: objective=0.267268 reg=0.012105
2017/08/30 02:50:38 Training value function...
2017/08/30 02:50:45 step 0: mse=1.173409 step=0.050000
2017/08/30 02:50:48 step 1: mse=1.172360 step=0.050000
2017/08/30 02:50:51 step 2: mse=1.171384 step=0.050000
2017/08/30 02:50:55 step 3: mse=1.170477 step=0.050000
2017/08/30 02:50:58 step 4: mse=1.169593 step=0.050000
2017/08/30 02:51:02 step 5: mse=1.168764 step=0.050000
2017/08/30 02:51:05 step 6: mse=1.167995 step=0.050000
2017/08/30 02:51:09 step 7: mse=1.167278 step=0.050000
2017/08/30 02:51:09 Saving...
2017/08/30 02:51:09 Gathering batch of experience...
2017/08/30 02:51:44 batch 384: mean=5.523667 stddev=1.456715 entropy=1.207471 frames=100140 count=5007
2017/08/30 02:51:44 Training policy...
2017/08/30 02:52:03 step 0: objective=0.253066 reg=0.012075
2017/08/30 02:52:14 step 1: objective=0.253698 reg=0.012081
2017/08/30 02:52:26 step 2: objective=0.254350 reg=0.012078
2017/08/30 02:52:37 step 3: objective=0.254863 reg=0.012077
2017/08/30 02:52:48 step 4: objective=0.255363 reg=0.012069
2017/08/30 02:53:00 step 5: objective=0.255871 reg=0.012065
2017/08/30 02:53:11 step 6: objective=0.256410 reg=0.012070
2017/08/30 02:53:23 step 7: objective=0.256810 reg=0.012066
2017/08/30 02:53:23 Training value function...
2017/08/30 02:53:29 step 0: mse=1.167522 step=0.050000
2017/08/30 02:53:32 step 1: mse=1.167067 step=0.050000
2017/08/30 02:53:36 step 2: mse=1.166654 step=0.050000
2017/08/30 02:53:39 step 3: mse=1.166276 step=0.050000
2017/08/30 02:53:43 step 4: mse=1.165918 step=0.050000
2017/08/30 02:53:46 step 5: mse=1.165586 step=0.050000
2017/08/30 02:53:50 step 6: mse=1.165272 step=0.050000
2017/08/30 02:53:53 step 7: mse=1.164977 step=0.050000
2017/08/30 02:53:53 Saving...
2017/08/30 02:53:53 Gathering batch of experience...
2017/08/30 02:54:29 batch 385: mean=5.527462 stddev=1.479638 entropy=1.208415 frames=100140 count=5007
2017/08/30 02:54:29 Training policy...
2017/08/30 02:54:47 step 0: objective=0.253630 reg=0.012084
2017/08/30 02:54:59 step 1: objective=0.254208 reg=0.012082
2017/08/30 02:55:10 step 2: objective=0.254910 reg=0.012083
2017/08/30 02:55:21 step 3: objective=0.255596 reg=0.012079
2017/08/30 02:55:33 step 4: objective=0.256064 reg=0.012078
2017/08/30 02:55:44 step 5: objective=0.256538 reg=0.012076
2017/08/30 02:55:56 step 6: objective=0.256958 reg=0.012077
2017/08/30 02:56:07 step 7: objective=0.257383 reg=0.012076
2017/08/30 02:56:07 Training value function...
2017/08/30 02:56:13 step 0: mse=1.181965 step=0.050000
2017/08/30 02:56:17 step 1: mse=1.181584 step=0.050000
2017/08/30 02:56:20 step 2: mse=1.181232 step=0.050000
2017/08/30 02:56:24 step 3: mse=1.180888 step=0.050000
2017/08/30 02:56:27 step 4: mse=1.180577 step=0.050000
2017/08/30 02:56:30 step 5: mse=1.180290 step=0.050000
2017/08/30 02:56:34 step 6: mse=1.180016 step=0.050000
2017/08/30 02:56:37 step 7: mse=1.179757 step=0.050000
2017/08/30 02:56:37 Saving...
2017/08/30 02:56:38 Gathering batch of experience...
2017/08/30 02:57:13 batch 386: mean=5.534252 stddev=1.492935 entropy=1.204180 frames=100140 count=5007
2017/08/30 02:57:13 Training policy...
2017/08/30 02:57:32 step 0: objective=0.256979 reg=0.012042
2017/08/30 02:57:44 step 1: objective=0.257510 reg=0.012048
2017/08/30 02:57:55 step 2: objective=0.258014 reg=0.012038
2017/08/30 02:58:07 step 3: objective=0.258578 reg=0.012036
2017/08/30 02:58:18 step 4: objective=0.259129 reg=0.012033
2017/08/30 02:58:30 step 5: objective=0.259564 reg=0.012028
2017/08/30 02:58:41 step 6: objective=0.260117 reg=0.012031
2017/08/30 02:58:52 step 7: objective=0.260539 reg=0.012030
2017/08/30 02:58:52 Training value function...
2017/08/30 02:58:59 step 0: mse=1.164513 step=0.050000
2017/08/30 02:59:02 step 1: mse=1.163488 step=0.050000
2017/08/30 02:59:05 step 2: mse=1.162554 step=0.050000
2017/08/30 02:59:09 step 3: mse=1.161680 step=0.050000
2017/08/30 02:59:12 step 4: mse=1.160863 step=0.050000
2017/08/30 02:59:16 step 5: mse=1.160069 step=0.050000
2017/08/30 02:59:19 step 6: mse=1.159343 step=0.050000
2017/08/30 02:59:23 step 7: mse=1.158665 step=0.050000
2017/08/30 02:59:23 Saving...
2017/08/30 02:59:23 Gathering batch of experience...
2017/08/30 02:59:58 batch 387: mean=5.560615 stddev=1.462763 entropy=1.206497 frames=100140 count=5007
2017/08/30 02:59:58 Training policy...
2017/08/30 03:00:17 step 0: objective=0.251523 reg=0.012065
2017/08/30 03:00:28 step 1: objective=0.252104 reg=0.012068
2017/08/30 03:00:40 step 2: objective=0.252662 reg=0.012069
2017/08/30 03:00:52 step 3: objective=0.253264 reg=0.012067
2017/08/30 03:01:03 step 4: objective=0.253798 reg=0.012068
2017/08/30 03:01:15 step 5: objective=0.254285 reg=0.012069
2017/08/30 03:01:26 step 6: objective=0.254719 reg=0.012068
2017/08/30 03:01:37 step 7: objective=0.255048 reg=0.012061
2017/08/30 03:01:37 Training value function...
2017/08/30 03:01:43 step 0: mse=1.133954 step=0.050000
2017/08/30 03:01:47 step 1: mse=1.133372 step=0.050000
2017/08/30 03:01:50 step 2: mse=1.132841 step=0.050000
2017/08/30 03:01:54 step 3: mse=1.132360 step=0.050000
2017/08/30 03:01:57 step 4: mse=1.131855 step=0.050000
2017/08/30 03:02:01 step 5: mse=1.131377 step=0.050000
2017/08/30 03:02:04 step 6: mse=1.130938 step=0.050000
2017/08/30 03:02:08 step 7: mse=1.130528 step=0.050000
2017/08/30 03:02:08 Saving...
2017/08/30 03:02:08 Gathering batch of experience...
2017/08/30 03:02:43 batch 388: mean=5.521470 stddev=1.463997 entropy=1.203788 frames=100140 count=5007
2017/08/30 03:02:43 Training policy...
2017/08/30 03:03:03 step 0: objective=0.247133 reg=0.012038
2017/08/30 03:03:14 step 1: objective=0.247776 reg=0.012035
2017/08/30 03:03:26 step 2: objective=0.248337 reg=0.012029
2017/08/30 03:03:38 step 3: objective=0.248901 reg=0.012029
2017/08/30 03:03:49 step 4: objective=0.249404 reg=0.012027
2017/08/30 03:04:01 step 5: objective=0.249858 reg=0.012023
2017/08/30 03:04:12 step 6: objective=0.250424 reg=0.012022
2017/08/30 03:04:25 step 7: objective=0.250804 reg=0.012022
2017/08/30 03:04:25 Training value function...
2017/08/30 03:04:31 step 0: mse=1.138750 step=0.050000
2017/08/30 03:04:34 step 1: mse=1.138751 step=0.050000
2017/08/30 03:04:38 step 2: mse=1.138765 step=0.050000
2017/08/30 03:04:41 step 3: mse=1.138787 step=0.050000
2017/08/30 03:04:45 step 4: mse=1.138821 step=0.050000
2017/08/30 03:04:48 step 5: mse=1.138857 step=0.050000
2017/08/30 03:04:52 step 6: mse=1.138894 step=0.050000
2017/08/30 03:04:55 step 7: mse=1.138911 step=0.050000
2017/08/30 03:04:55 Saving...
2017/08/30 03:04:55 Gathering batch of experience...
2017/08/30 03:05:31 batch 389: mean=5.504494 stddev=1.456077 entropy=1.205448 frames=100140 count=5007
2017/08/30 03:05:31 Training policy...
2017/08/30 03:05:49 step 0: objective=0.237613 reg=0.012054
2017/08/30 03:06:02 step 1: objective=0.238407 reg=0.012051
2017/08/30 03:06:13 step 2: objective=0.239220 reg=0.012051
2017/08/30 03:06:25 step 3: objective=0.239750 reg=0.012048
2017/08/30 03:06:37 step 4: objective=0.240334 reg=0.012044
2017/08/30 03:06:48 step 5: objective=0.240759 reg=0.012043
2017/08/30 03:07:00 step 6: objective=0.241137 reg=0.012044
2017/08/30 03:07:12 step 7: objective=0.241558 reg=0.012041
2017/08/30 03:07:12 Training value function...
2017/08/30 03:07:18 step 0: mse=1.134881 step=0.050000
2017/08/30 03:07:21 step 1: mse=1.135452 step=0.050000
2017/08/30 03:07:25 step 2: mse=1.136007 step=0.050000
2017/08/30 03:07:28 step 3: mse=1.136544 step=0.050000
2017/08/30 03:07:32 step 4: mse=1.137050 step=0.050000
2017/08/30 03:07:35 step 5: mse=1.137534 step=0.050000
2017/08/30 03:07:38 step 6: mse=1.137993 step=0.050000
2017/08/30 03:07:42 step 7: mse=1.138429 step=0.050000
2017/08/30 03:07:42 Saving...
2017/08/30 03:07:42 Gathering batch of experience...
2017/08/30 03:08:18 batch 390: mean=5.538047 stddev=1.453802 entropy=1.200754 frames=100140 count=5007
2017/08/30 03:08:18 Training policy...
2017/08/30 03:08:36 step 0: objective=0.264165 reg=0.012007
2017/08/30 03:08:48 step 1: objective=0.264778 reg=0.012010
2017/08/30 03:09:00 step 2: objective=0.265362 reg=0.012010
2017/08/30 03:09:11 step 3: objective=0.265855 reg=0.012011
2017/08/30 03:09:23 step 4: objective=0.266398 reg=0.012005
2017/08/30 03:09:35 step 5: objective=0.266754 reg=0.012016
2017/08/30 03:09:46 step 6: objective=0.267185 reg=0.012010
2017/08/30 03:09:58 step 7: objective=0.267455 reg=0.012014
2017/08/30 03:09:58 Training value function...
2017/08/30 03:10:04 step 0: mse=1.143316 step=0.050000
2017/08/30 03:10:07 step 1: mse=1.142268 step=0.050000
2017/08/30 03:10:11 step 2: mse=1.141291 step=0.050000
2017/08/30 03:10:14 step 3: mse=1.140376 step=0.050000
2017/08/30 03:10:17 step 4: mse=1.139512 step=0.050000
2017/08/30 03:10:21 step 5: mse=1.138701 step=0.050000
2017/08/30 03:10:24 step 6: mse=1.137937 step=0.050000
2017/08/30 03:10:28 step 7: mse=1.137221 step=0.050000
2017/08/30 03:10:28 Saving...
2017/08/30 03:10:28 Gathering batch of experience...
2017/08/30 03:11:04 batch 391: mean=5.542640 stddev=1.445961 entropy=1.202928 frames=100140 count=5007
2017/08/30 03:11:04 Training policy...
2017/08/30 03:11:23 step 0: objective=0.245734 reg=0.012029
2017/08/30 03:11:35 step 1: objective=0.246646 reg=0.012033
2017/08/30 03:11:46 step 2: objective=0.247248 reg=0.012029
2017/08/30 03:11:59 step 3: objective=0.247765 reg=0.012029
2017/08/30 03:12:10 step 4: objective=0.248135 reg=0.012029
2017/08/30 03:12:22 step 5: objective=0.248618 reg=0.012024
2017/08/30 03:12:34 step 6: objective=0.249038 reg=0.012026
2017/08/30 03:12:46 step 7: objective=0.249503 reg=0.012027
2017/08/30 03:12:46 Training value function...
2017/08/30 03:12:52 step 0: mse=1.135431 step=0.050000
2017/08/30 03:12:55 step 1: mse=1.135248 step=0.050000
2017/08/30 03:12:59 step 2: mse=1.135084 step=0.050000
2017/08/30 03:13:02 step 3: mse=1.134939 step=0.050000
2017/08/30 03:13:06 step 4: mse=1.134811 step=0.050000
2017/08/30 03:13:09 step 5: mse=1.134692 step=0.050000
2017/08/30 03:13:13 step 6: mse=1.134541 step=0.050000
2017/08/30 03:13:16 step 7: mse=1.134433 step=0.050000
2017/08/30 03:13:16 Saving...
2017/08/30 03:13:16 Gathering batch of experience...
2017/08/30 03:13:52 batch 392: mean=5.525864 stddev=1.474665 entropy=1.196992 frames=100140 count=5007
2017/08/30 03:13:52 Training policy...
2017/08/30 03:14:11 step 0: objective=0.248249 reg=0.011970
2017/08/30 03:14:23 step 1: objective=0.248837 reg=0.011971
2017/08/30 03:14:34 step 2: objective=0.249302 reg=0.011977
2017/08/30 03:14:46 step 3: objective=0.249834 reg=0.011981
2017/08/30 03:14:58 step 4: objective=0.250399 reg=0.011976
2017/08/30 03:15:10 step 5: objective=0.250721 reg=0.011972
2017/08/30 03:15:22 step 6: objective=0.251070 reg=0.011964
2017/08/30 03:15:33 step 7: objective=0.251366 reg=0.011970
2017/08/30 03:15:33 Training value function...
2017/08/30 03:15:39 step 0: mse=1.137728 step=0.050000
2017/08/30 03:15:43 step 1: mse=1.137526 step=0.050000
2017/08/30 03:15:46 step 2: mse=1.137347 step=0.050000
2017/08/30 03:15:50 step 3: mse=1.137183 step=0.050000
2017/08/30 03:15:53 step 4: mse=1.137028 step=0.050000
2017/08/30 03:15:56 step 5: mse=1.136861 step=0.050000
2017/08/30 03:16:00 step 6: mse=1.136724 step=0.050000
2017/08/30 03:16:04 step 7: mse=1.136576 step=0.050000
2017/08/30 03:16:04 Saving...
2017/08/30 03:16:04 Gathering batch of experience...
2017/08/30 03:16:39 batch 393: mean=5.553825 stddev=1.466437 entropy=1.201439 frames=100140 count=5007
2017/08/30 03:16:39 Training policy...
2017/08/30 03:16:58 step 0: objective=0.255604 reg=0.012014
2017/08/30 03:17:10 step 1: objective=0.256352 reg=0.012017
2017/08/30 03:17:21 step 2: objective=0.256949 reg=0.012018
2017/08/30 03:17:33 step 3: objective=0.257640 reg=0.012017
2017/08/30 03:17:45 step 4: objective=0.258052 reg=0.012018
2017/08/30 03:17:57 step 5: objective=0.258558 reg=0.012017
2017/08/30 03:18:08 step 6: objective=0.259062 reg=0.012014
2017/08/30 03:18:20 step 7: objective=0.259415 reg=0.012017
2017/08/30 03:18:20 Training value function...
2017/08/30 03:18:26 step 0: mse=1.174826 step=0.050000
2017/08/30 03:18:30 step 1: mse=1.174363 step=0.050000
2017/08/30 03:18:33 step 2: mse=1.173923 step=0.050000
2017/08/30 03:18:37 step 3: mse=1.173538 step=0.050000
2017/08/30 03:18:40 step 4: mse=1.173148 step=0.050000
2017/08/30 03:18:43 step 5: mse=1.172778 step=0.050000
2017/08/30 03:18:47 step 6: mse=1.172452 step=0.050000
2017/08/30 03:18:50 step 7: mse=1.172124 step=0.050000
2017/08/30 03:18:50 Saving...
2017/08/30 03:18:51 Gathering batch of experience...
2017/08/30 03:19:26 batch 394: mean=5.512283 stddev=1.465058 entropy=1.197463 frames=100140 count=5007
2017/08/30 03:19:26 Training policy...
2017/08/30 03:19:45 step 0: objective=0.246833 reg=0.011975
2017/08/30 03:19:57 step 1: objective=0.247512 reg=0.011973
2017/08/30 03:20:09 step 2: objective=0.248147 reg=0.011975
2017/08/30 03:20:21 step 3: objective=0.248876 reg=0.011976
2017/08/30 03:20:33 step 4: objective=0.249359 reg=0.011974
2017/08/30 03:20:44 step 5: objective=0.249837 reg=0.011974
2017/08/30 03:20:56 step 6: objective=0.250292 reg=0.011972
2017/08/30 03:21:08 step 7: objective=0.250691 reg=0.011971
2017/08/30 03:21:08 Training value function...
2017/08/30 03:21:14 step 0: mse=1.156235 step=0.050000
2017/08/30 03:21:18 step 1: mse=1.156247 step=0.050000
2017/08/30 03:21:21 step 2: mse=1.156280 step=0.050000
2017/08/30 03:21:25 step 3: mse=1.156328 step=0.050000
2017/08/30 03:21:28 step 4: mse=1.156385 step=0.050000
2017/08/30 03:21:32 step 5: mse=1.156443 step=0.050000
2017/08/30 03:21:35 step 6: mse=1.156498 step=0.050000
2017/08/30 03:21:39 step 7: mse=1.156554 step=0.050000
2017/08/30 03:21:39 Saving...
2017/08/30 03:21:39 Gathering batch of experience...
2017/08/30 03:22:14 batch 395: mean=5.589375 stddev=1.419131 entropy=1.198969 frames=100140 count=5007
2017/08/30 03:22:14 Training policy...
2017/08/30 03:22:33 step 0: objective=0.249172 reg=0.011990
2017/08/30 03:22:45 step 1: objective=0.249794 reg=0.011992
2017/08/30 03:22:57 step 2: objective=0.250336 reg=0.011995
2017/08/30 03:23:09 step 3: objective=0.250882 reg=0.011993
2017/08/30 03:23:21 step 4: objective=0.251351 reg=0.011992
2017/08/30 03:23:33 step 5: objective=0.251819 reg=0.011992
2017/08/30 03:23:45 step 6: objective=0.252223 reg=0.011993
2017/08/30 03:23:57 step 7: objective=0.252582 reg=0.011990
2017/08/30 03:23:57 Training value function...
2017/08/30 03:24:03 step 0: mse=1.138102 step=0.050000
2017/08/30 03:24:06 step 1: mse=1.138131 step=0.050000
2017/08/30 03:24:10 step 2: mse=1.138172 step=0.050000
2017/08/30 03:24:13 step 3: mse=1.138220 step=0.050000
2017/08/30 03:24:17 step 4: mse=1.138273 step=0.050000
2017/08/30 03:24:20 step 5: mse=1.138327 step=0.050000
2017/08/30 03:24:24 step 6: mse=1.138397 step=0.050000
2017/08/30 03:24:27 step 7: mse=1.138423 step=0.050000
2017/08/30 03:24:27 Saving...
2017/08/30 03:24:27 Gathering batch of experience...
2017/08/30 03:25:03 batch 396: mean=5.562013 stddev=1.497118 entropy=1.192898 frames=100140 count=5007
2017/08/30 03:25:03 Training policy...
2017/08/30 03:25:22 step 0: objective=0.254565 reg=0.011929
2017/08/30 03:25:34 step 1: objective=0.255336 reg=0.011929
2017/08/30 03:25:46 step 2: objective=0.256003 reg=0.011928
2017/08/30 03:25:58 step 3: objective=0.256556 reg=0.011933
2017/08/30 03:26:10 step 4: objective=0.257008 reg=0.011932
2017/08/30 03:26:22 step 5: objective=0.257461 reg=0.011930
2017/08/30 03:26:34 step 6: objective=0.257983 reg=0.011927
2017/08/30 03:26:45 step 7: objective=0.258342 reg=0.011929
2017/08/30 03:26:45 Training value function...
2017/08/30 03:26:51 step 0: mse=1.179749 step=0.050000
2017/08/30 03:26:55 step 1: mse=1.179277 step=0.050000
2017/08/30 03:26:58 step 2: mse=1.178867 step=0.050000
2017/08/30 03:27:02 step 3: mse=1.178462 step=0.050000
2017/08/30 03:27:05 step 4: mse=1.178113 step=0.050000
2017/08/30 03:27:09 step 5: mse=1.177763 step=0.050000
2017/08/30 03:27:12 step 6: mse=1.177455 step=0.050000
2017/08/30 03:27:16 step 7: mse=1.177142 step=0.050000
2017/08/30 03:27:16 Saving...
2017/08/30 03:27:16 Gathering batch of experience...
2017/08/30 03:27:52 batch 397: mean=5.504094 stddev=1.442297 entropy=1.196244 frames=100140 count=5007
2017/08/30 03:27:52 Training policy...
2017/08/30 03:28:11 step 0: objective=0.248313 reg=0.011962
2017/08/30 03:28:23 step 1: objective=0.248922 reg=0.011959
2017/08/30 03:28:34 step 2: objective=0.249536 reg=0.011957
2017/08/30 03:28:46 step 3: objective=0.250044 reg=0.011958
2017/08/30 03:28:58 step 4: objective=0.250505 reg=0.011956
2017/08/30 03:29:10 step 5: objective=0.250950 reg=0.011955
2017/08/30 03:29:22 step 6: objective=0.251368 reg=0.011954
2017/08/30 03:29:34 step 7: objective=0.251747 reg=0.011950
2017/08/30 03:29:34 Training value function...
2017/08/30 03:29:40 step 0: mse=1.104681 step=0.050000
2017/08/30 03:29:43 step 1: mse=1.104306 step=0.050000
2017/08/30 03:29:47 step 2: mse=1.103963 step=0.050000
2017/08/30 03:29:50 step 3: mse=1.103649 step=0.050000
2017/08/30 03:29:53 step 4: mse=1.103292 step=0.050000
2017/08/30 03:29:57 step 5: mse=1.102993 step=0.050000
2017/08/30 03:30:00 step 6: mse=1.102690 step=0.050000
2017/08/30 03:30:04 step 7: mse=1.102390 step=0.050000
2017/08/30 03:30:04 Saving...
2017/08/30 03:30:04 Gathering batch of experience...
2017/08/30 03:30:40 batch 398: mean=5.546036 stddev=1.433789 entropy=1.191457 frames=100140 count=5007
2017/08/30 03:30:40 Training policy...
2017/08/30 03:30:59 step 0: objective=0.252700 reg=0.011915
2017/08/30 03:31:11 step 1: objective=0.253287 reg=0.011916
2017/08/30 03:31:23 step 2: objective=0.253882 reg=0.011917
2017/08/30 03:31:35 step 3: objective=0.254406 reg=0.011918
2017/08/30 03:31:47 step 4: objective=0.254951 reg=0.011916
2017/08/30 03:31:59 step 5: objective=0.255476 reg=0.011915
2017/08/30 03:32:11 step 6: objective=0.255976 reg=0.011911
2017/08/30 03:32:23 step 7: objective=0.256313 reg=0.011911
2017/08/30 03:32:23 Training value function...
2017/08/30 03:32:29 step 0: mse=1.128555 step=0.050000
2017/08/30 03:32:32 step 1: mse=1.128095 step=0.050000
2017/08/30 03:32:35 step 2: mse=1.127595 step=0.050000
2017/08/30 03:32:39 step 3: mse=1.127171 step=0.050000
2017/08/30 03:32:42 step 4: mse=1.126736 step=0.050000
2017/08/30 03:32:46 step 5: mse=1.126364 step=0.050000
2017/08/30 03:32:49 step 6: mse=1.126020 step=0.050000
2017/08/30 03:32:53 step 7: mse=1.125697 step=0.050000
2017/08/30 03:32:53 Saving...
2017/08/30 03:32:53 Gathering batch of experience...
2017/08/30 03:33:29 batch 399: mean=5.491712 stddev=1.464813 entropy=1.198556 frames=100140 count=5007
2017/08/30 03:33:29 Training policy...
2017/08/30 03:33:48 step 0: objective=0.240855 reg=0.011986
2017/08/30 03:34:00 step 1: objective=0.241510 reg=0.011986
2017/08/30 03:34:12 step 2: objective=0.242066 reg=0.011989
2017/08/30 03:34:24 step 3: objective=0.242625 reg=0.011989
2017/08/30 03:34:36 step 4: objective=0.243115 reg=0.011988
2017/08/30 03:34:48 step 5: objective=0.243598 reg=0.011985
2017/08/30 03:35:00 step 6: objective=0.244112 reg=0.011984
2017/08/30 03:35:12 step 7: objective=0.244518 reg=0.011984
2017/08/30 03:35:12 Training value function...
2017/08/30 03:35:18 step 0: mse=1.112098 step=0.050000
2017/08/30 03:35:21 step 1: mse=1.112196 step=0.050000
2017/08/30 03:35:25 step 2: mse=1.112305 step=0.050000
2017/08/30 03:35:28 step 3: mse=1.112421 step=0.050000
2017/08/30 03:35:32 step 4: mse=1.112528 step=0.050000
2017/08/30 03:35:35 step 5: mse=1.112639 step=0.050000
2017/08/30 03:35:39 step 6: mse=1.112724 step=0.050000
2017/08/30 03:35:42 step 7: mse=1.112810 step=0.050000
2017/08/30 03:35:42 Saving...
2017/08/30 03:35:42 Gathering batch of experience...
2017/08/30 03:36:18 batch 400: mean=5.549830 stddev=1.447250 entropy=1.195113 frames=100140 count=5007
2017/08/30 03:36:18 Training policy...
2017/08/30 03:36:38 step 0: objective=0.259604 reg=0.011951
2017/08/30 03:36:50 step 1: objective=0.260285 reg=0.011950
2017/08/30 03:37:02 step 2: objective=0.260770 reg=0.011944
2017/08/30 03:37:14 step 3: objective=0.261205 reg=0.011953
2017/08/30 03:37:26 step 4: objective=0.261663 reg=0.011946
2017/08/30 03:37:38 step 5: objective=0.262107 reg=0.011943
2017/08/30 03:37:50 step 6: objective=0.262580 reg=0.011938
2017/08/30 03:38:02 step 7: objective=0.262928 reg=0.011939
2017/08/30 03:38:02 Training value function...
2017/08/30 03:38:08 step 0: mse=1.138248 step=0.050000
2017/08/30 03:38:11 step 1: mse=1.137268 step=0.050000
2017/08/30 03:38:15 step 2: mse=1.136353 step=0.050000
2017/08/30 03:38:18 step 3: mse=1.135505 step=0.050000
2017/08/30 03:38:22 step 4: mse=1.134723 step=0.050000
2017/08/30 03:38:25 step 5: mse=1.133993 step=0.050000
2017/08/30 03:38:29 step 6: mse=1.133321 step=0.050000
2017/08/30 03:38:32 step 7: mse=1.132677 step=0.050000
2017/08/30 03:38:32 Saving...
2017/08/30 03:38:32 Gathering batch of experience...
2017/08/30 03:39:08 batch 401: mean=5.573397 stddev=1.437242 entropy=1.190880 frames=100140 count=5007
2017/08/30 03:39:08 Training policy...
2017/08/30 03:39:27 step 0: objective=0.266838 reg=0.011909
2017/08/30 03:39:39 step 1: objective=0.267525 reg=0.011911
2017/08/30 03:39:51 step 2: objective=0.268114 reg=0.011914
2017/08/30 03:40:03 step 3: objective=0.268600 reg=0.011915
2017/08/30 03:40:15 step 4: objective=0.269031 reg=0.011914
2017/08/30 03:40:28 step 5: objective=0.269484 reg=0.011910
2017/08/30 03:40:40 step 6: objective=0.269818 reg=0.011914
2017/08/30 03:40:52 step 7: objective=0.270197 reg=0.011911
2017/08/30 03:40:52 Training value function...
2017/08/30 03:40:58 step 0: mse=1.137719 step=0.050000
2017/08/30 03:41:01 step 1: mse=1.136299 step=0.050000
2017/08/30 03:41:05 step 2: mse=1.134982 step=0.050000
2017/08/30 03:41:08 step 3: mse=1.133757 step=0.050000
2017/08/30 03:41:11 step 4: mse=1.132615 step=0.050000
2017/08/30 03:41:15 step 5: mse=1.131548 step=0.050000
2017/08/30 03:41:18 step 6: mse=1.130563 step=0.050000
2017/08/30 03:41:22 step 7: mse=1.129614 step=0.050000
2017/08/30 03:41:22 Saving...
2017/08/30 03:41:22 Gathering batch of experience...
2017/08/30 03:41:58 batch 402: mean=5.541242 stddev=1.482420 entropy=1.194566 frames=100140 count=5007
2017/08/30 03:41:58 Training policy...
2017/08/30 03:42:17 step 0: objective=0.244251 reg=0.011946
2017/08/30 03:42:30 step 1: objective=0.244905 reg=0.011946
2017/08/30 03:42:42 step 2: objective=0.245482 reg=0.011949
2017/08/30 03:42:54 step 3: objective=0.246071 reg=0.011946
2017/08/30 03:43:06 step 4: objective=0.246613 reg=0.011948
2017/08/30 03:43:18 step 5: objective=0.247090 reg=0.011948
2017/08/30 03:43:30 step 6: objective=0.247539 reg=0.011948
2017/08/30 03:43:42 step 7: objective=0.247945 reg=0.011946
2017/08/30 03:43:42 Training value function...
2017/08/30 03:43:48 step 0: mse=1.157678 step=0.050000
2017/08/30 03:43:52 step 1: mse=1.157947 step=0.050000
2017/08/30 03:43:55 step 2: mse=1.158216 step=0.050000
2017/08/30 03:43:59 step 3: mse=1.158444 step=0.050000
2017/08/30 03:44:02 step 4: mse=1.158690 step=0.050000
2017/08/30 03:44:06 step 5: mse=1.158927 step=0.050000
2017/08/30 03:44:09 step 6: mse=1.159117 step=0.050000
2017/08/30 03:44:13 step 7: mse=1.159313 step=0.050000
2017/08/30 03:44:13 Saving...
2017/08/30 03:44:13 Gathering batch of experience...
2017/08/30 03:44:49 batch 403: mean=5.543239 stddev=1.448703 entropy=1.188685 frames=100140 count=5007
2017/08/30 03:44:49 Training policy...
2017/08/30 03:45:08 step 0: objective=0.256163 reg=0.011887
2017/08/30 03:45:20 step 1: objective=0.256806 reg=0.011888
2017/08/30 03:45:33 step 2: objective=0.257455 reg=0.011890
2017/08/30 03:45:45 step 3: objective=0.257912 reg=0.011887
2017/08/30 03:45:57 step 4: objective=0.258484 reg=0.011883
2017/08/30 03:46:09 step 5: objective=0.258992 reg=0.011881
2017/08/30 03:46:22 step 6: objective=0.259361 reg=0.011881
2017/08/30 03:46:34 step 7: objective=0.259793 reg=0.011880
2017/08/30 03:46:34 Training value function...
2017/08/30 03:46:40 step 0: mse=1.144717 step=0.050000
2017/08/30 03:46:43 step 1: mse=1.144133 step=0.050000
2017/08/30 03:46:47 step 2: mse=1.143591 step=0.050000
2017/08/30 03:46:50 step 3: mse=1.143085 step=0.050000
2017/08/30 03:46:54 step 4: mse=1.142617 step=0.050000
2017/08/30 03:46:57 step 5: mse=1.142175 step=0.050000
2017/08/30 03:47:01 step 6: mse=1.141761 step=0.050000
2017/08/30 03:47:04 step 7: mse=1.141365 step=0.050000
2017/08/30 03:47:04 Saving...
2017/08/30 03:47:04 Gathering batch of experience...
2017/08/30 03:47:40 batch 404: mean=5.549231 stddev=1.472714 entropy=1.194184 frames=100140 count=5007
2017/08/30 03:47:40 Training policy...
2017/08/30 03:48:00 step 0: objective=0.243555 reg=0.011942
2017/08/30 03:48:12 step 1: objective=0.244367 reg=0.011943
2017/08/30 03:48:25 step 2: objective=0.245129 reg=0.011941
2017/08/30 03:48:37 step 3: objective=0.245653 reg=0.011941
2017/08/30 03:48:49 step 4: objective=0.246097 reg=0.011938
2017/08/30 03:49:02 step 5: objective=0.246484 reg=0.011936
2017/08/30 03:49:14 step 6: objective=0.246891 reg=0.011934
2017/08/30 03:49:27 step 7: objective=0.247298 reg=0.011930
2017/08/30 03:49:27 Training value function...
2017/08/30 03:49:33 step 0: mse=1.181007 step=0.050000
2017/08/30 03:49:37 step 1: mse=1.181210 step=0.050000
2017/08/30 03:49:40 step 2: mse=1.181421 step=0.050000
2017/08/30 03:49:44 step 3: mse=1.181634 step=0.050000
2017/08/30 03:49:47 step 4: mse=1.181835 step=0.050000
2017/08/30 03:49:51 step 5: mse=1.182032 step=0.050000
2017/08/30 03:49:54 step 6: mse=1.182185 step=0.050000
2017/08/30 03:49:58 step 7: mse=1.182329 step=0.050000
2017/08/30 03:49:58 Saving...
2017/08/30 03:49:58 Gathering batch of experience...
2017/08/30 03:50:34 batch 405: mean=5.562213 stddev=1.494305 entropy=1.187323 frames=100140 count=5007
2017/08/30 03:50:34 Training policy...
2017/08/30 03:50:54 step 0: objective=0.259754 reg=0.011873
2017/08/30 03:51:06 step 1: objective=0.260431 reg=0.011873
2017/08/30 03:51:18 step 2: objective=0.261041 reg=0.011870
2017/08/30 03:51:31 step 3: objective=0.261560 reg=0.011862
2017/08/30 03:51:43 step 4: objective=0.262152 reg=0.011859
2017/08/30 03:51:56 step 5: objective=0.262517 reg=0.011858
2017/08/30 03:52:08 step 6: objective=0.262829 reg=0.011852
2017/08/30 03:52:20 step 7: objective=0.263229 reg=0.011848
2017/08/30 03:52:20 Training value function...
2017/08/30 03:52:26 step 0: mse=1.167781 step=0.050000
2017/08/30 03:52:30 step 1: mse=1.166941 step=0.050000
2017/08/30 03:52:33 step 2: mse=1.166156 step=0.050000
2017/08/30 03:52:37 step 3: mse=1.165426 step=0.050000
2017/08/30 03:52:40 step 4: mse=1.164718 step=0.050000
2017/08/30 03:52:44 step 5: mse=1.164058 step=0.050000
2017/08/30 03:52:47 step 6: mse=1.163405 step=0.050000
2017/08/30 03:52:51 step 7: mse=1.162799 step=0.050000
2017/08/30 03:52:51 Saving...
2017/08/30 03:52:51 Gathering batch of experience...
2017/08/30 03:53:27 batch 406: mean=5.548632 stddev=1.470155 entropy=1.189037 frames=100140 count=5007
2017/08/30 03:53:27 Training policy...
2017/08/30 03:53:46 step 0: objective=0.255376 reg=0.011890
2017/08/30 03:53:59 step 1: objective=0.256041 reg=0.011894
2017/08/30 03:54:11 step 2: objective=0.256602 reg=0.011893
2017/08/30 03:54:23 step 3: objective=0.257266 reg=0.011891
2017/08/30 03:54:36 step 4: objective=0.257657 reg=0.011888
2017/08/30 03:54:48 step 5: objective=0.258132 reg=0.011889
2017/08/30 03:55:01 step 6: objective=0.258688 reg=0.011891
2017/08/30 03:55:13 step 7: objective=0.259082 reg=0.011888
2017/08/30 03:55:13 Training value function...
2017/08/30 03:55:19 step 0: mse=1.144283 step=0.050000
2017/08/30 03:55:22 step 1: mse=1.143754 step=0.050000
2017/08/30 03:55:26 step 2: mse=1.143267 step=0.050000
2017/08/30 03:55:29 step 3: mse=1.142817 step=0.050000
2017/08/30 03:55:33 step 4: mse=1.142384 step=0.050000
2017/08/30 03:55:36 step 5: mse=1.141945 step=0.050000
2017/08/30 03:55:40 step 6: mse=1.141520 step=0.050000
2017/08/30 03:55:43 step 7: mse=1.141146 step=0.050000
2017/08/30 03:55:43 Saving...
2017/08/30 03:55:43 Gathering batch of experience...
2017/08/30 03:56:19 batch 407: mean=5.536649 stddev=1.451226 entropy=1.193419 frames=100140 count=5007
2017/08/30 03:56:19 Training policy...
2017/08/30 03:56:39 step 0: objective=0.245453 reg=0.011934
2017/08/30 03:56:51 step 1: objective=0.246115 reg=0.011935
2017/08/30 03:57:04 step 2: objective=0.246640 reg=0.011934
2017/08/30 03:57:16 step 3: objective=0.247162 reg=0.011933
2017/08/30 03:57:29 step 4: objective=0.247788 reg=0.011935
2017/08/30 03:57:41 step 5: objective=0.248292 reg=0.011932
2017/08/30 03:57:54 step 6: objective=0.248813 reg=0.011934
2017/08/30 03:58:06 step 7: objective=0.249182 reg=0.011935
2017/08/30 03:58:06 Training value function...
2017/08/30 03:58:12 step 0: mse=1.139506 step=0.050000
2017/08/30 03:58:16 step 1: mse=1.139331 step=0.050000
2017/08/30 03:58:19 step 2: mse=1.139178 step=0.050000
2017/08/30 03:58:23 step 3: mse=1.139033 step=0.050000
2017/08/30 03:58:26 step 4: mse=1.138908 step=0.050000
2017/08/30 03:58:30 step 5: mse=1.138790 step=0.050000
2017/08/30 03:58:33 step 6: mse=1.138681 step=0.050000
2017/08/30 03:58:37 step 7: mse=1.138581 step=0.050000
2017/08/30 03:58:37 Saving...
2017/08/30 03:58:37 Gathering batch of experience...
2017/08/30 03:59:13 batch 408: mean=5.570202 stddev=1.484833 entropy=1.186831 frames=100140 count=5007
2017/08/30 03:59:13 Training policy...
2017/08/30 03:59:32 step 0: objective=0.258683 reg=0.011868
2017/08/30 03:59:45 step 1: objective=0.259299 reg=0.011869
2017/08/30 03:59:57 step 2: objective=0.259912 reg=0.011866
2017/08/30 04:00:09 step 3: objective=0.260507 reg=0.011861
2017/08/30 04:00:22 step 4: objective=0.260924 reg=0.011857
2017/08/30 04:00:34 step 5: objective=0.261428 reg=0.011851
2017/08/30 04:00:46 step 6: objective=0.261839 reg=0.011851
2017/08/30 04:00:59 step 7: objective=0.262233 reg=0.011848
2017/08/30 04:00:59 Training value function...
2017/08/30 04:01:05 step 0: mse=1.170034 step=0.050000
2017/08/30 04:01:08 step 1: mse=1.169383 step=0.050000
2017/08/30 04:01:12 step 2: mse=1.168784 step=0.050000
2017/08/30 04:01:15 step 3: mse=1.168222 step=0.050000
2017/08/30 04:01:19 step 4: mse=1.167675 step=0.050000
2017/08/30 04:01:22 step 5: mse=1.167174 step=0.050000
2017/08/30 04:01:26 step 6: mse=1.166686 step=0.050000
2017/08/30 04:01:29 step 7: mse=1.166244 step=0.050000
2017/08/30 04:01:29 Saving...
2017/08/30 04:01:29 Gathering batch of experience...
2017/08/30 04:02:05 batch 409: mean=5.556022 stddev=1.499486 entropy=1.183172 frames=100140 count=5007
2017/08/30 04:02:05 Training policy...
2017/08/30 04:02:26 step 0: objective=0.249518 reg=0.011832
2017/08/30 04:02:38 step 1: objective=0.250248 reg=0.011831
2017/08/30 04:02:51 step 2: objective=0.250861 reg=0.011834
2017/08/30 04:03:03 step 3: objective=0.251329 reg=0.011830
2017/08/30 04:03:16 step 4: objective=0.251774 reg=0.011830
2017/08/30 04:03:28 step 5: objective=0.252261 reg=0.011825
2017/08/30 04:03:41 step 6: objective=0.252762 reg=0.011821
2017/08/30 04:03:53 step 7: objective=0.253165 reg=0.011822
2017/08/30 04:03:53 Training value function...
2017/08/30 04:03:59 step 0: mse=1.177295 step=0.050000
2017/08/30 04:04:03 step 1: mse=1.177166 step=0.050000
2017/08/30 04:04:06 step 2: mse=1.177059 step=0.050000
2017/08/30 04:04:10 step 3: mse=1.176971 step=0.050000
2017/08/30 04:04:13 step 4: mse=1.176900 step=0.050000
2017/08/30 04:04:17 step 5: mse=1.176838 step=0.050000
2017/08/30 04:04:20 step 6: mse=1.176791 step=0.050000
2017/08/30 04:04:24 step 7: mse=1.176741 step=0.050000
2017/08/30 04:04:24 Saving...
2017/08/30 04:04:24 Gathering batch of experience...
2017/08/30 04:05:00 batch 410: mean=5.563811 stddev=1.484449 entropy=1.185925 frames=100140 count=5007
2017/08/30 04:05:00 Training policy...
2017/08/30 04:05:20 step 0: objective=0.257617 reg=0.011859
2017/08/30 04:05:32 step 1: objective=0.258269 reg=0.011860
2017/08/30 04:05:45 step 2: objective=0.258776 reg=0.011864
2017/08/30 04:05:58 step 3: objective=0.259323 reg=0.011861
2017/08/30 04:06:10 step 4: objective=0.259725 reg=0.011858
2017/08/30 04:06:22 step 5: objective=0.260081 reg=0.011868
2017/08/30 04:06:35 step 6: objective=0.260403 reg=0.011854
2017/08/30 04:06:47 step 7: objective=0.260712 reg=0.011869
2017/08/30 04:06:47 Training value function...
2017/08/30 04:06:53 step 0: mse=1.177277 step=0.050000
2017/08/30 04:06:57 step 1: mse=1.176597 step=0.050000
2017/08/30 04:07:00 step 2: mse=1.175973 step=0.050000
2017/08/30 04:07:04 step 3: mse=1.175387 step=0.050000
2017/08/30 04:07:07 step 4: mse=1.174850 step=0.050000
2017/08/30 04:07:11 step 5: mse=1.174343 step=0.050000
2017/08/30 04:07:14 step 6: mse=1.173868 step=0.050000
2017/08/30 04:07:18 step 7: mse=1.173423 step=0.050000
2017/08/30 04:07:18 Saving...
2017/08/30 04:07:18 Gathering batch of experience...
2017/08/30 04:07:54 batch 411: mean=5.543839 stddev=1.460903 entropy=1.181504 frames=100140 count=5007
2017/08/30 04:07:54 Training policy...
2017/08/30 04:08:14 step 0: objective=0.250584 reg=0.011815
2017/08/30 04:08:26 step 1: objective=0.251229 reg=0.011816
2017/08/30 04:08:39 step 2: objective=0.251780 reg=0.011826
2017/08/30 04:08:51 step 3: objective=0.252322 reg=0.011819
2017/08/30 04:09:04 step 4: objective=0.252875 reg=0.011818
2017/08/30 04:09:16 step 5: objective=0.253369 reg=0.011815
2017/08/30 04:09:29 step 6: objective=0.253853 reg=0.011815
2017/08/30 04:09:42 step 7: objective=0.254137 reg=0.011815
2017/08/30 04:09:42 Training value function...
2017/08/30 04:09:48 step 0: mse=1.138005 step=0.050000
2017/08/30 04:09:51 step 1: mse=1.138070 step=0.050000
2017/08/30 04:09:55 step 2: mse=1.138140 step=0.050000
2017/08/30 04:09:58 step 3: mse=1.138211 step=0.050000
2017/08/30 04:10:02 step 4: mse=1.138274 step=0.050000
2017/08/30 04:10:05 step 5: mse=1.138335 step=0.050000
2017/08/30 04:10:09 step 6: mse=1.138391 step=0.050000
2017/08/30 04:10:12 step 7: mse=1.138447 step=0.050000
2017/08/30 04:10:12 Saving...
2017/08/30 04:10:12 Gathering batch of experience...
2017/08/30 04:10:48 batch 412: mean=5.561813 stddev=1.474408 entropy=1.179354 frames=100140 count=5007
2017/08/30 04:10:48 Training policy...
2017/08/30 04:11:08 step 0: objective=0.256491 reg=0.011793
2017/08/30 04:11:21 step 1: objective=0.257138 reg=0.011791
2017/08/30 04:11:33 step 2: objective=0.257580 reg=0.011786
2017/08/30 04:11:46 step 3: objective=0.258014 reg=0.011791
2017/08/30 04:11:59 step 4: objective=0.258524 reg=0.011792
2017/08/30 04:12:12 step 5: objective=0.258902 reg=0.011795
2017/08/30 04:12:24 step 6: objective=0.259304 reg=0.011793
2017/08/30 04:12:37 step 7: objective=0.259868 reg=0.011791
2017/08/30 04:12:37 Training value function...
2017/08/30 04:12:43 step 0: mse=1.166809 step=0.050000
2017/08/30 04:12:47 step 1: mse=1.166147 step=0.050000
2017/08/30 04:12:50 step 2: mse=1.165530 step=0.050000
2017/08/30 04:12:54 step 3: mse=1.164959 step=0.050000
2017/08/30 04:12:57 step 4: mse=1.164421 step=0.050000
2017/08/30 04:13:01 step 5: mse=1.163901 step=0.050000
2017/08/30 04:13:04 step 6: mse=1.163416 step=0.050000
2017/08/30 04:13:08 step 7: mse=1.162962 step=0.050000
2017/08/30 04:13:08 Saving...
2017/08/30 04:13:08 Gathering batch of experience...
2017/08/30 04:13:44 batch 413: mean=5.568604 stddev=1.464321 entropy=1.179586 frames=100140 count=5007
2017/08/30 04:13:44 Training policy...
2017/08/30 04:14:05 step 0: objective=0.245226 reg=0.011796
2017/08/30 04:14:18 step 1: objective=0.245820 reg=0.011797
2017/08/30 04:14:30 step 2: objective=0.246583 reg=0.011793
2017/08/30 04:14:43 step 3: objective=0.247055 reg=0.011788
2017/08/30 04:14:55 step 4: objective=0.247478 reg=0.011794
2017/08/30 04:15:08 step 5: objective=0.247902 reg=0.011792
2017/08/30 04:15:21 step 6: objective=0.248272 reg=0.011790
2017/08/30 04:15:33 step 7: objective=0.248659 reg=0.011790
2017/08/30 04:15:33 Training value function...
2017/08/30 04:15:39 step 0: mse=1.157163 step=0.050000
2017/08/30 04:15:43 step 1: mse=1.157391 step=0.050000
2017/08/30 04:15:46 step 2: mse=1.157623 step=0.050000
2017/08/30 04:15:50 step 3: mse=1.157773 step=0.050000
2017/08/30 04:15:53 step 4: mse=1.157985 step=0.050000
2017/08/30 04:15:57 step 5: mse=1.158191 step=0.050000
2017/08/30 04:16:00 step 6: mse=1.158385 step=0.050000
2017/08/30 04:16:04 step 7: mse=1.158484 step=0.050000
2017/08/30 04:16:04 Saving...
2017/08/30 04:16:04 Gathering batch of experience...
2017/08/30 04:16:40 batch 414: mean=5.581786 stddev=1.472215 entropy=1.179093 frames=100140 count=5007
2017/08/30 04:16:40 Training policy...
2017/08/30 04:17:01 step 0: objective=0.255921 reg=0.011791
2017/08/30 04:17:13 step 1: objective=0.256664 reg=0.011790
2017/08/30 04:17:26 step 2: objective=0.257268 reg=0.011790
2017/08/30 04:17:39 step 3: objective=0.257752 reg=0.011789
2017/08/30 04:17:51 step 4: objective=0.258230 reg=0.011789
2017/08/30 04:18:04 step 5: objective=0.258793 reg=0.011787
2017/08/30 04:18:17 step 6: objective=0.259177 reg=0.011784
2017/08/30 04:18:29 step 7: objective=0.259579 reg=0.011780
2017/08/30 04:18:29 Training value function...
2017/08/30 04:18:35 step 0: mse=1.175221 step=0.050000
2017/08/30 04:18:39 step 1: mse=1.174599 step=0.050000
2017/08/30 04:18:42 step 2: mse=1.174023 step=0.050000
2017/08/30 04:18:46 step 3: mse=1.173372 step=0.050000
2017/08/30 04:18:49 step 4: mse=1.172778 step=0.050000
2017/08/30 04:18:52 step 5: mse=1.172227 step=0.050000
2017/08/30 04:18:56 step 6: mse=1.171755 step=0.050000
2017/08/30 04:18:59 step 7: mse=1.171311 step=0.050000
2017/08/30 04:18:59 Saving...
2017/08/30 04:19:00 Gathering batch of experience...
2017/08/30 04:19:36 batch 415: mean=5.546635 stddev=1.473205 entropy=1.176727 frames=100140 count=5007
2017/08/30 04:19:36 Training policy...
2017/08/30 04:19:55 step 0: objective=0.241469 reg=0.011767
2017/08/30 04:20:08 step 1: objective=0.242036 reg=0.011760
2017/08/30 04:20:21 step 2: objective=0.242626 reg=0.011763
2017/08/30 04:20:33 step 3: objective=0.243133 reg=0.011760
2017/08/30 04:20:46 step 4: objective=0.243705 reg=0.011760
2017/08/30 04:20:59 step 5: objective=0.244213 reg=0.011756
2017/08/30 04:21:12 step 6: objective=0.244617 reg=0.011756
2017/08/30 04:21:24 step 7: objective=0.244998 reg=0.011752
2017/08/30 04:21:24 Training value function...
2017/08/30 04:21:30 step 0: mse=1.145748 step=0.050000
2017/08/30 04:21:34 step 1: mse=1.146004 step=0.050000
2017/08/30 04:21:37 step 2: mse=1.146235 step=0.050000
2017/08/30 04:21:41 step 3: mse=1.146468 step=0.050000
2017/08/30 04:21:44 step 4: mse=1.146683 step=0.050000
2017/08/30 04:21:48 step 5: mse=1.146893 step=0.050000
2017/08/30 04:21:51 step 6: mse=1.147087 step=0.050000
2017/08/30 04:21:55 step 7: mse=1.147275 step=0.050000
2017/08/30 04:21:55 Saving...
2017/08/30 04:21:55 Gathering batch of experience...
2017/08/30 04:22:31 batch 416: mean=5.571999 stddev=1.467019 entropy=1.181489 frames=100140 count=5007
2017/08/30 04:22:31 Training policy...
2017/08/30 04:22:51 step 0: objective=0.258764 reg=0.011815
2017/08/30 04:23:04 step 1: objective=0.259561 reg=0.011812
2017/08/30 04:23:16 step 2: objective=0.260128 reg=0.011810
2017/08/30 04:23:29 step 3: objective=0.260883 reg=0.011809
2017/08/30 04:23:42 step 4: objective=0.261447 reg=0.011809
2017/08/30 04:23:55 step 5: objective=0.261907 reg=0.011804
2017/08/30 04:24:09 step 6: objective=0.262356 reg=0.011802
2017/08/30 04:24:21 step 7: objective=0.262640 reg=0.011802
2017/08/30 04:24:21 Training value function...
2017/08/30 04:24:27 step 0: mse=1.171478 step=0.050000
2017/08/30 04:24:31 step 1: mse=1.170727 step=0.050000
2017/08/30 04:24:34 step 2: mse=1.170032 step=0.050000
2017/08/30 04:24:38 step 3: mse=1.169380 step=0.050000
2017/08/30 04:24:41 step 4: mse=1.168769 step=0.050000
2017/08/30 04:24:45 step 5: mse=1.168192 step=0.050000
2017/08/30 04:24:48 step 6: mse=1.167651 step=0.050000
2017/08/30 04:24:52 step 7: mse=1.167145 step=0.050000
2017/08/30 04:24:52 Saving...
2017/08/30 04:24:52 Gathering batch of experience...
2017/08/30 04:25:28 batch 417: mean=5.548232 stddev=1.457891 entropy=1.179122 frames=100140 count=5007
2017/08/30 04:25:28 Training policy...
2017/08/30 04:25:49 step 0: objective=0.243238 reg=0.011791
2017/08/30 04:26:02 step 1: objective=0.243949 reg=0.011790
2017/08/30 04:26:15 step 2: objective=0.244581 reg=0.011794
2017/08/30 04:26:28 step 3: objective=0.245126 reg=0.011793
2017/08/30 04:26:40 step 4: objective=0.245644 reg=0.011794
2017/08/30 04:26:53 step 5: objective=0.246052 reg=0.011793
2017/08/30 04:27:06 step 6: objective=0.246522 reg=0.011789
2017/08/30 04:27:19 step 7: objective=0.246915 reg=0.011788
2017/08/30 04:27:19 Training value function...
2017/08/30 04:27:25 step 0: mse=1.155586 step=0.050000
2017/08/30 04:27:28 step 1: mse=1.155747 step=0.050000
2017/08/30 04:27:32 step 2: mse=1.155911 step=0.050000
2017/08/30 04:27:35 step 3: mse=1.156074 step=0.050000
2017/08/30 04:27:39 step 4: mse=1.156240 step=0.050000
2017/08/30 04:27:42 step 5: mse=1.156400 step=0.050000
2017/08/30 04:27:46 step 6: mse=1.156555 step=0.050000
2017/08/30 04:27:49 step 7: mse=1.156701 step=0.050000
2017/08/30 04:27:49 Saving...
2017/08/30 04:27:49 Gathering batch of experience...
2017/08/30 04:28:26 batch 418: mean=5.564410 stddev=1.460277 entropy=1.178379 frames=100140 count=5007
2017/08/30 04:28:26 Training policy...
2017/08/30 04:28:46 step 0: objective=0.256782 reg=0.011784
2017/08/30 04:29:00 step 1: objective=0.257581 reg=0.011783
2017/08/30 04:29:12 step 2: objective=0.258022 reg=0.011782
2017/08/30 04:29:25 step 3: objective=0.258832 reg=0.011780
2017/08/30 04:29:38 step 4: objective=0.259298 reg=0.011780
2017/08/30 04:29:51 step 5: objective=0.259789 reg=0.011780
2017/08/30 04:30:04 step 6: objective=0.260202 reg=0.011775
2017/08/30 04:30:17 step 7: objective=0.260597 reg=0.011775
2017/08/30 04:30:17 Training value function...
2017/08/30 04:30:23 step 0: mse=1.174016 step=0.050000
2017/08/30 04:30:27 step 1: mse=1.173894 step=0.050000
2017/08/30 04:30:30 step 2: mse=1.173766 step=0.050000
2017/08/30 04:30:33 step 3: mse=1.173648 step=0.050000
2017/08/30 04:30:37 step 4: mse=1.173539 step=0.050000
2017/08/30 04:30:40 step 5: mse=1.173437 step=0.050000
2017/08/30 04:30:44 step 6: mse=1.173340 step=0.050000
2017/08/30 04:30:47 step 7: mse=1.173248 step=0.050000
2017/08/30 04:30:47 Saving...
2017/08/30 04:30:48 Gathering batch of experience...
2017/08/30 04:31:24 batch 419: mean=5.547633 stddev=1.475070 entropy=1.176755 frames=100140 count=5007
2017/08/30 04:31:24 Training policy...
2017/08/30 04:31:44 step 0: objective=0.255526 reg=0.011767
2017/08/30 04:31:57 step 1: objective=0.256187 reg=0.011767
2017/08/30 04:32:10 step 2: objective=0.256810 reg=0.011765
2017/08/30 04:32:23 step 3: objective=0.257428 reg=0.011766
2017/08/30 04:32:36 step 4: objective=0.257977 reg=0.011763
2017/08/30 04:32:49 step 5: objective=0.258493 reg=0.011762
2017/08/30 04:33:02 step 6: objective=0.258961 reg=0.011760
2017/08/30 04:33:15 step 7: objective=0.259382 reg=0.011763
2017/08/30 04:33:15 Training value function...
2017/08/30 04:33:21 step 0: mse=1.185325 step=0.050000
2017/08/30 04:33:24 step 1: mse=1.184644 step=0.050000
2017/08/30 04:33:28 step 2: mse=1.183998 step=0.050000
2017/08/30 04:33:31 step 3: mse=1.183400 step=0.050000
2017/08/30 04:33:35 step 4: mse=1.182843 step=0.050000
2017/08/30 04:33:38 step 5: mse=1.182226 step=0.050000
2017/08/30 04:33:42 step 6: mse=1.181740 step=0.050000
2017/08/30 04:33:45 step 7: mse=1.181279 step=0.050000
2017/08/30 04:33:45 Saving...
2017/08/30 04:33:45 Gathering batch of experience...
2017/08/30 04:34:22 batch 420: mean=5.559017 stddev=1.459411 entropy=1.173350 frames=100140 count=5007
2017/08/30 04:34:22 Training policy...
2017/08/30 04:34:42 step 0: objective=0.256781 reg=0.011733
2017/08/30 04:34:55 step 1: objective=0.257334 reg=0.011733
2017/08/30 04:35:08 step 2: objective=0.257972 reg=0.011731
2017/08/30 04:35:21 step 3: objective=0.258604 reg=0.011731
2017/08/30 04:35:34 step 4: objective=0.259063 reg=0.011732
2017/08/30 04:35:47 step 5: objective=0.259560 reg=0.011733
2017/08/30 04:36:00 step 6: objective=0.259987 reg=0.011733
2017/08/30 04:36:13 step 7: objective=0.260465 reg=0.011730
2017/08/30 04:36:13 Training value function...
2017/08/30 04:36:19 step 0: mse=1.188382 step=0.050000
2017/08/30 04:36:23 step 1: mse=1.187910 step=0.050000
2017/08/30 04:36:26 step 2: mse=1.187518 step=0.050000
2017/08/30 04:36:30 step 3: mse=1.187158 step=0.050000
2017/08/30 04:36:33 step 4: mse=1.186835 step=0.050000
2017/08/30 04:36:37 step 5: mse=1.186513 step=0.050000
2017/08/30 04:36:40 step 6: mse=1.186226 step=0.050000
2017/08/30 04:36:43 step 7: mse=1.185939 step=0.050000
2017/08/30 04:36:43 Saving...
2017/08/30 04:36:44 Gathering batch of experience...
2017/08/30 04:37:20 batch 421: mean=5.566008 stddev=1.432172 entropy=1.175366 frames=100140 count=5007
2017/08/30 04:37:20 Training policy...
2017/08/30 04:37:40 step 0: objective=0.251429 reg=0.011754
2017/08/30 04:37:53 step 1: objective=0.252047 reg=0.011751
2017/08/30 04:38:06 step 2: objective=0.252579 reg=0.011751
2017/08/30 04:38:19 step 3: objective=0.253097 reg=0.011751
2017/08/30 04:38:33 step 4: objective=0.253666 reg=0.011747
2017/08/30 04:38:46 step 5: objective=0.254186 reg=0.011743
2017/08/30 04:39:00 step 6: objective=0.254603 reg=0.011744
2017/08/30 04:39:13 step 7: objective=0.254993 reg=0.011742
2017/08/30 04:39:13 Training value function...
2017/08/30 04:39:19 step 0: mse=1.133853 step=0.050000
2017/08/30 04:39:22 step 1: mse=1.133642 step=0.050000
2017/08/30 04:39:26 step 2: mse=1.133457 step=0.050000
2017/08/30 04:39:29 step 3: mse=1.133285 step=0.050000
2017/08/30 04:39:33 step 4: mse=1.133139 step=0.050000
2017/08/30 04:39:36 step 5: mse=1.133003 step=0.050000
2017/08/30 04:39:40 step 6: mse=1.132868 step=0.050000
2017/08/30 04:39:43 step 7: mse=1.132746 step=0.050000
2017/08/30 04:39:43 Saving...
2017/08/30 04:39:43 Gathering batch of experience...
2017/08/30 04:40:20 batch 422: mean=5.578191 stddev=1.464113 entropy=1.174299 frames=100140 count=5007
2017/08/30 04:40:20 Training policy...
2017/08/30 04:40:40 step 0: objective=0.255938 reg=0.011743
2017/08/30 04:40:53 step 1: objective=0.256548 reg=0.011743
2017/08/30 04:41:06 step 2: objective=0.257137 reg=0.011744
2017/08/30 04:41:19 step 3: objective=0.257729 reg=0.011741
2017/08/30 04:41:33 step 4: objective=0.258167 reg=0.011742
2017/08/30 04:41:46 step 5: objective=0.258537 reg=0.011741
2017/08/30 04:41:59 step 6: objective=0.258969 reg=0.011738
2017/08/30 04:42:12 step 7: objective=0.259383 reg=0.011736
2017/08/30 04:42:12 Training value function...
2017/08/30 04:42:18 step 0: mse=1.148047 step=0.050000
2017/08/30 04:42:21 step 1: mse=1.147440 step=0.050000
2017/08/30 04:42:25 step 2: mse=1.146864 step=0.050000
2017/08/30 04:42:28 step 3: mse=1.146334 step=0.050000
2017/08/30 04:42:32 step 4: mse=1.145828 step=0.050000
2017/08/30 04:42:35 step 5: mse=1.145359 step=0.050000
2017/08/30 04:42:39 step 6: mse=1.144914 step=0.050000
2017/08/30 04:42:42 step 7: mse=1.144492 step=0.050000
2017/08/30 04:42:42 Saving...
2017/08/30 04:42:42 Gathering batch of experience...
2017/08/30 04:43:19 batch 423: mean=5.618734 stddev=1.462340 entropy=1.169134 frames=100140 count=5007
2017/08/30 04:43:19 Training policy...
2017/08/30 04:43:40 step 0: objective=0.266121 reg=0.011691
2017/08/30 04:43:53 step 1: objective=0.266656 reg=0.011694
2017/08/30 04:44:06 step 2: objective=0.267356 reg=0.011691
2017/08/30 04:44:20 step 3: objective=0.267923 reg=0.011692
2017/08/30 04:44:33 step 4: objective=0.268406 reg=0.011695
2017/08/30 04:44:46 step 5: objective=0.268904 reg=0.011691
2017/08/30 04:45:00 step 6: objective=0.269314 reg=0.011690
2017/08/30 04:45:13 step 7: objective=0.269788 reg=0.011686
2017/08/30 04:45:13 Training value function...
2017/08/30 04:45:19 step 0: mse=1.202254 step=0.050000
2017/08/30 04:45:22 step 1: mse=1.201123 step=0.050000
2017/08/30 04:45:26 step 2: mse=1.200073 step=0.050000
2017/08/30 04:45:29 step 3: mse=1.199099 step=0.050000
2017/08/30 04:45:33 step 4: mse=1.198161 step=0.050000
2017/08/30 04:45:36 step 5: mse=1.197282 step=0.050000
2017/08/30 04:45:40 step 6: mse=1.196469 step=0.050000
2017/08/30 04:45:43 step 7: mse=1.195696 step=0.050000
2017/08/30 04:45:43 Saving...
2017/08/30 04:45:43 Gathering batch of experience...
2017/08/30 04:46:20 batch 424: mean=5.557619 stddev=1.436293 entropy=1.169781 frames=100140 count=5007
2017/08/30 04:46:20 Training policy...
2017/08/30 04:46:40 step 0: objective=0.255187 reg=0.011698
2017/08/30 04:46:54 step 1: objective=0.255822 reg=0.011698
2017/08/30 04:47:07 step 2: objective=0.256377 reg=0.011700
2017/08/30 04:47:20 step 3: objective=0.256902 reg=0.011700
2017/08/30 04:47:33 step 4: objective=0.257397 reg=0.011698
2017/08/30 04:47:47 step 5: objective=0.257804 reg=0.011698
2017/08/30 04:48:00 step 6: objective=0.258251 reg=0.011696
2017/08/30 04:48:13 step 7: objective=0.258668 reg=0.011698
2017/08/30 04:48:13 Training value function...
2017/08/30 04:48:19 step 0: mse=1.119744 step=0.050000
2017/08/30 04:48:22 step 1: mse=1.119118 step=0.050000
2017/08/30 04:48:26 step 2: mse=1.118537 step=0.050000
2017/08/30 04:48:29 step 3: mse=1.117998 step=0.050000
2017/08/30 04:48:33 step 4: mse=1.117496 step=0.050000
2017/08/30 04:48:36 step 5: mse=1.117032 step=0.050000
2017/08/30 04:48:40 step 6: mse=1.116595 step=0.050000
2017/08/30 04:48:43 step 7: mse=1.116185 step=0.050000
2017/08/30 04:48:43 Saving...
2017/08/30 04:48:43 Gathering batch of experience...
2017/08/30 04:49:20 batch 425: mean=5.541442 stddev=1.448066 entropy=1.172732 frames=100140 count=5007
2017/08/30 04:49:20 Training policy...
2017/08/30 04:49:40 step 0: objective=0.233800 reg=0.011727
2017/08/30 04:49:54 step 1: objective=0.234430 reg=0.011726
2017/08/30 04:50:07 step 2: objective=0.235018 reg=0.011721
2017/08/30 04:50:20 step 3: objective=0.235464 reg=0.011720
2017/08/30 04:50:34 step 4: objective=0.235965 reg=0.011719
2017/08/30 04:50:47 step 5: objective=0.236522 reg=0.011719
2017/08/30 04:51:01 step 6: objective=0.237001 reg=0.011719
2017/08/30 04:51:14 step 7: objective=0.237442 reg=0.011714
2017/08/30 04:51:14 Training value function...
2017/08/30 04:51:20 step 0: mse=1.122960 step=0.050000
2017/08/30 04:51:23 step 1: mse=1.123756 step=0.050000
2017/08/30 04:51:27 step 2: mse=1.124519 step=0.050000
2017/08/30 04:51:30 step 3: mse=1.125253 step=0.050000
2017/08/30 04:51:34 step 4: mse=1.125949 step=0.050000
2017/08/30 04:51:37 step 5: mse=1.126606 step=0.050000
2017/08/30 04:51:41 step 6: mse=1.127161 step=0.050000
2017/08/30 04:51:44 step 7: mse=1.127746 step=0.050000
2017/08/30 04:51:44 Saving...
2017/08/30 04:51:44 Gathering batch of experience...
2017/08/30 04:52:21 batch 426: mean=5.544638 stddev=1.455126 entropy=1.171650 frames=100140 count=5007
2017/08/30 04:52:21 Training policy...
2017/08/30 04:52:43 step 0: objective=0.235157 reg=0.011717
2017/08/30 04:52:56 step 1: objective=0.235669 reg=0.011716
2017/08/30 04:53:10 step 2: objective=0.236190 reg=0.011718
2017/08/30 04:53:23 step 3: objective=0.236862 reg=0.011716
2017/08/30 04:53:36 step 4: objective=0.237431 reg=0.011718
2017/08/30 04:53:50 step 5: objective=0.237908 reg=0.011717
2017/08/30 04:54:03 step 6: objective=0.238341 reg=0.011714
2017/08/30 04:54:16 step 7: objective=0.238681 reg=0.011716
2017/08/30 04:54:16 Training value function...
2017/08/30 04:54:22 step 0: mse=1.120202 step=0.050000
2017/08/30 04:54:26 step 1: mse=1.120785 step=0.050000
2017/08/30 04:54:29 step 2: mse=1.121349 step=0.050000
2017/08/30 04:54:33 step 3: mse=1.121871 step=0.050000
2017/08/30 04:54:36 step 4: mse=1.122386 step=0.050000
2017/08/30 04:54:40 step 5: mse=1.122863 step=0.050000
2017/08/30 04:54:43 step 6: mse=1.123317 step=0.050000
2017/08/30 04:54:47 step 7: mse=1.123732 step=0.050000
2017/08/30 04:54:47 Saving...
2017/08/30 04:54:47 Gathering batch of experience...
2017/08/30 04:55:23 batch 427: mean=5.550030 stddev=1.484170 entropy=1.167555 frames=100140 count=5007
2017/08/30 04:55:23 Training policy...
2017/08/30 04:55:44 step 0: objective=0.265813 reg=0.011676
2017/08/30 04:55:57 step 1: objective=0.266431 reg=0.011678
2017/08/30 04:56:10 step 2: objective=0.267094 reg=0.011679
2017/08/30 04:56:24 step 3: objective=0.267696 reg=0.011678
2017/08/30 04:56:37 step 4: objective=0.268222 reg=0.011674
2017/08/30 04:56:50 step 5: objective=0.268681 reg=0.011675
2017/08/30 04:57:03 step 6: objective=0.269116 reg=0.011674
2017/08/30 04:57:17 step 7: objective=0.269492 reg=0.011672
2017/08/30 04:57:17 Training value function...
2017/08/30 04:57:23 step 0: mse=1.175732 step=0.050000
2017/08/30 04:57:26 step 1: mse=1.174399 step=0.050000
2017/08/30 04:57:29 step 2: mse=1.173109 step=0.050000
2017/08/30 04:57:33 step 3: mse=1.171917 step=0.050000
2017/08/30 04:57:36 step 4: mse=1.170800 step=0.050000
2017/08/30 04:57:40 step 5: mse=1.169757 step=0.050000
2017/08/30 04:57:43 step 6: mse=1.168785 step=0.050000
2017/08/30 04:57:47 step 7: mse=1.167869 step=0.050000
2017/08/30 04:57:47 Saving...
2017/08/30 04:57:47 Gathering batch of experience...
2017/08/30 04:58:24 batch 428: mean=5.574995 stddev=1.483926 entropy=1.168579 frames=100140 count=5007
2017/08/30 04:58:24 Training policy...
2017/08/30 04:58:45 step 0: objective=0.257363 reg=0.011686
2017/08/30 04:58:58 step 1: objective=0.258101 reg=0.011683
2017/08/30 04:59:11 step 2: objective=0.258626 reg=0.011686
2017/08/30 04:59:25 step 3: objective=0.259230 reg=0.011683
2017/08/30 04:59:38 step 4: objective=0.259715 reg=0.011686
2017/08/30 04:59:53 step 5: objective=0.260143 reg=0.011682
2017/08/30 05:00:06 step 6: objective=0.260444 reg=0.011684
2017/08/30 05:00:19 step 7: objective=0.260874 reg=0.011680
2017/08/30 05:00:19 Training value function...
2017/08/30 05:00:25 step 0: mse=1.181744 step=0.050000
2017/08/30 05:00:29 step 1: mse=1.181563 step=0.050000
2017/08/30 05:00:32 step 2: mse=1.181400 step=0.050000
2017/08/30 05:00:36 step 3: mse=1.181251 step=0.050000
2017/08/30 05:00:39 step 4: mse=1.181093 step=0.050000
2017/08/30 05:00:43 step 5: mse=1.180946 step=0.050000
2017/08/30 05:00:46 step 6: mse=1.180811 step=0.050000
2017/08/30 05:00:50 step 7: mse=1.180684 step=0.050000
2017/08/30 05:00:50 Saving...
2017/08/30 05:00:50 Gathering batch of experience...
2017/08/30 05:01:26 batch 429: mean=5.556421 stddev=1.455814 entropy=1.166289 frames=100140 count=5007
2017/08/30 05:01:26 Training policy...
2017/08/30 05:01:47 step 0: objective=0.246638 reg=0.011663
2017/08/30 05:02:01 step 1: objective=0.247330 reg=0.011664
2017/08/30 05:02:14 step 2: objective=0.247948 reg=0.011663
2017/08/30 05:02:27 step 3: objective=0.248468 reg=0.011663
2017/08/30 05:02:41 step 4: objective=0.248931 reg=0.011663
2017/08/30 05:02:54 step 5: objective=0.249411 reg=0.011663
2017/08/30 05:03:08 step 6: objective=0.249942 reg=0.011660
2017/08/30 05:03:21 step 7: objective=0.250301 reg=0.011656
2017/08/30 05:03:21 Training value function...
2017/08/30 05:03:27 step 0: mse=1.133931 step=0.050000
2017/08/30 05:03:30 step 1: mse=1.133594 step=0.050000
2017/08/30 05:03:34 step 2: mse=1.133291 step=0.050000
2017/08/30 05:03:37 step 3: mse=1.133016 step=0.050000
2017/08/30 05:03:41 step 4: mse=1.132790 step=0.050000
2017/08/30 05:03:44 step 5: mse=1.132556 step=0.050000
2017/08/30 05:03:48 step 6: mse=1.132361 step=0.050000
2017/08/30 05:03:51 step 7: mse=1.132155 step=0.050000
2017/08/30 05:03:51 Saving...
2017/08/30 05:03:51 Gathering batch of experience...
2017/08/30 05:04:28 batch 430: mean=5.573597 stddev=1.465033 entropy=1.164396 frames=100140 count=5007
2017/08/30 05:04:28 Training policy...
2017/08/30 05:04:50 step 0: objective=0.247370 reg=0.011644
2017/08/30 05:05:03 step 1: objective=0.247947 reg=0.011644
2017/08/30 05:05:17 step 2: objective=0.248674 reg=0.011644
2017/08/30 05:05:30 step 3: objective=0.249093 reg=0.011642
2017/08/30 05:05:43 step 4: objective=0.249544 reg=0.011639
2017/08/30 05:05:57 step 5: objective=0.249868 reg=0.011644
2017/08/30 05:06:10 step 6: objective=0.250314 reg=0.011636
2017/08/30 05:06:24 step 7: objective=0.250717 reg=0.011639
2017/08/30 05:06:24 Training value function...
2017/08/30 05:06:30 step 0: mse=1.141336 step=0.050000
2017/08/30 05:06:33 step 1: mse=1.141270 step=0.050000
2017/08/30 05:06:37 step 2: mse=1.141219 step=0.050000
2017/08/30 05:06:40 step 3: mse=1.141154 step=0.050000
2017/08/30 05:06:44 step 4: mse=1.141111 step=0.050000
2017/08/30 05:06:47 step 5: mse=1.141057 step=0.050000
2017/08/30 05:06:51 step 6: mse=1.141017 step=0.050000
2017/08/30 05:06:54 step 7: mse=1.140970 step=0.050000
2017/08/30 05:06:54 Saving...
2017/08/30 05:06:54 Gathering batch of experience...
2017/08/30 05:07:31 batch 431: mean=5.594967 stddev=1.472373 entropy=1.162616 frames=100140 count=5007
2017/08/30 05:07:31 Training policy...
2017/08/30 05:07:53 step 0: objective=0.256256 reg=0.011626
2017/08/30 05:08:06 step 1: objective=0.256975 reg=0.011623
2017/08/30 05:08:20 step 2: objective=0.257533 reg=0.011624
2017/08/30 05:08:33 step 3: objective=0.258167 reg=0.011623
2017/08/30 05:08:47 step 4: objective=0.258665 reg=0.011624
2017/08/30 05:09:00 step 5: objective=0.259109 reg=0.011620
2017/08/30 05:09:14 step 6: objective=0.259502 reg=0.011619
2017/08/30 05:09:27 step 7: objective=0.259882 reg=0.011621
2017/08/30 05:09:27 Training value function...
2017/08/30 05:09:33 step 0: mse=1.173171 step=0.050000
2017/08/30 05:09:37 step 1: mse=1.172538 step=0.050000
2017/08/30 05:09:40 step 2: mse=1.171953 step=0.050000
2017/08/30 05:09:44 step 3: mse=1.171375 step=0.050000
2017/08/30 05:09:47 step 4: mse=1.170837 step=0.050000
2017/08/30 05:09:51 step 5: mse=1.170330 step=0.050000
2017/08/30 05:09:54 step 6: mse=1.169850 step=0.050000
2017/08/30 05:09:58 step 7: mse=1.169399 step=0.050000
2017/08/30 05:09:58 Saving...
2017/08/30 05:09:58 Gathering batch of experience...
2017/08/30 05:10:34 batch 432: mean=5.573198 stddev=1.466007 entropy=1.165929 frames=100140 count=5007
2017/08/30 05:10:34 Training policy...
2017/08/30 05:10:55 step 0: objective=0.257060 reg=0.011659
2017/08/30 05:11:09 step 1: objective=0.257600 reg=0.011652
2017/08/30 05:11:23 step 2: objective=0.258154 reg=0.011652
2017/08/30 05:11:36 step 3: objective=0.258772 reg=0.011651
2017/08/30 05:11:50 step 4: objective=0.259303 reg=0.011649
2017/08/30 05:12:03 step 5: objective=0.259781 reg=0.011647
2017/08/30 05:12:17 step 6: objective=0.260187 reg=0.011646
2017/08/30 05:12:31 step 7: objective=0.260477 reg=0.011642
2017/08/30 05:12:31 Training value function...
2017/08/30 05:12:37 step 0: mse=1.166341 step=0.050000
2017/08/30 05:12:40 step 1: mse=1.165812 step=0.050000
2017/08/30 05:12:44 step 2: mse=1.165327 step=0.050000
2017/08/30 05:12:47 step 3: mse=1.164877 step=0.050000
2017/08/30 05:12:50 step 4: mse=1.164469 step=0.050000
2017/08/30 05:12:54 step 5: mse=1.164097 step=0.050000
2017/08/30 05:12:57 step 6: mse=1.163735 step=0.050000
2017/08/30 05:13:01 step 7: mse=1.163392 step=0.050000
2017/08/30 05:13:01 Saving...
2017/08/30 05:13:01 Gathering batch of experience...
2017/08/30 05:13:38 batch 433: mean=5.560216 stddev=1.450577 entropy=1.164412 frames=100140 count=5007
2017/08/30 05:13:38 Training policy...
2017/08/30 05:13:58 step 0: objective=0.246954 reg=0.011644
2017/08/30 05:14:12 step 1: objective=0.247660 reg=0.011649
2017/08/30 05:14:26 step 2: objective=0.248239 reg=0.011649
2017/08/30 05:14:39 step 3: objective=0.248782 reg=0.011648
2017/08/30 05:14:53 step 4: objective=0.249259 reg=0.011647
2017/08/30 05:15:07 step 5: objective=0.249766 reg=0.011652
2017/08/30 05:15:20 step 6: objective=0.250136 reg=0.011649
2017/08/30 05:15:34 step 7: objective=0.250565 reg=0.011647
2017/08/30 05:15:34 Training value function...
2017/08/30 05:15:40 step 0: mse=1.153157 step=0.050000
2017/08/30 05:15:43 step 1: mse=1.152998 step=0.050000
2017/08/30 05:15:47 step 2: mse=1.152817 step=0.050000
2017/08/30 05:15:50 step 3: mse=1.152659 step=0.050000
2017/08/30 05:15:54 step 4: mse=1.152509 step=0.050000
2017/08/30 05:15:57 step 5: mse=1.152370 step=0.050000
2017/08/30 05:16:01 step 6: mse=1.152234 step=0.050000
2017/08/30 05:16:04 step 7: mse=1.152109 step=0.050000
2017/08/30 05:16:04 Saving...
2017/08/30 05:16:05 Gathering batch of experience...
2017/08/30 05:16:41 batch 434: mean=5.571999 stddev=1.482862 entropy=1.159904 frames=100140 count=5007
2017/08/30 05:16:41 Training policy...
2017/08/30 05:17:02 step 0: objective=0.256681 reg=0.011599
2017/08/30 05:17:16 step 1: objective=0.257406 reg=0.011605
2017/08/30 05:17:29 step 2: objective=0.257958 reg=0.011610
2017/08/30 05:17:43 step 3: objective=0.258463 reg=0.011608
2017/08/30 05:17:56 step 4: objective=0.258909 reg=0.011611
2017/08/30 05:18:10 step 5: objective=0.259310 reg=0.011610
2017/08/30 05:18:24 step 6: objective=0.259764 reg=0.011608
2017/08/30 05:18:38 step 7: objective=0.260210 reg=0.011605
2017/08/30 05:18:38 Training value function...
2017/08/30 05:18:44 step 0: mse=1.193627 step=0.050000
2017/08/30 05:18:47 step 1: mse=1.192979 step=0.050000
2017/08/30 05:18:51 step 2: mse=1.192386 step=0.050000
2017/08/30 05:18:54 step 3: mse=1.191837 step=0.050000
2017/08/30 05:18:58 step 4: mse=1.191336 step=0.050000
2017/08/30 05:19:01 step 5: mse=1.190866 step=0.050000
2017/08/30 05:19:05 step 6: mse=1.190427 step=0.050000
2017/08/30 05:19:08 step 7: mse=1.190017 step=0.050000
2017/08/30 05:19:08 Saving...
2017/08/30 05:19:08 Gathering batch of experience...
2017/08/30 05:19:45 batch 435: mean=5.568604 stddev=1.470310 entropy=1.160176 frames=100140 count=5007
2017/08/30 05:19:45 Training policy...
2017/08/30 05:20:07 step 0: objective=0.249840 reg=0.011602
2017/08/30 05:20:20 step 1: objective=0.250376 reg=0.011597
2017/08/30 05:20:34 step 2: objective=0.250903 reg=0.011593
2017/08/30 05:20:48 step 3: objective=0.251510 reg=0.011591
2017/08/30 05:21:01 step 4: objective=0.252003 reg=0.011591
2017/08/30 05:21:15 step 5: objective=0.252458 reg=0.011590
2017/08/30 05:21:29 step 6: objective=0.252921 reg=0.011591
2017/08/30 05:21:42 step 7: objective=0.253417 reg=0.011591
2017/08/30 05:21:42 Training value function...
2017/08/30 05:21:48 step 0: mse=1.157729 step=0.050000
2017/08/30 05:21:52 step 1: mse=1.157643 step=0.050000
2017/08/30 05:21:55 step 2: mse=1.157575 step=0.050000
2017/08/30 05:21:59 step 3: mse=1.157501 step=0.050000
2017/08/30 05:22:02 step 4: mse=1.157441 step=0.050000
2017/08/30 05:22:06 step 5: mse=1.157374 step=0.050000
2017/08/30 05:22:09 step 6: mse=1.157310 step=0.050000
2017/08/30 05:22:13 step 7: mse=1.157256 step=0.050000
2017/08/30 05:22:13 Saving...
2017/08/30 05:22:13 Gathering batch of experience...
2017/08/30 05:22:50 batch 436: mean=5.562812 stddev=1.473824 entropy=1.159967 frames=100140 count=5007
2017/08/30 05:22:50 Training policy...
2017/08/30 05:23:11 step 0: objective=0.244339 reg=0.011600
2017/08/30 05:23:25 step 1: objective=0.245022 reg=0.011597
2017/08/30 05:23:38 step 2: objective=0.245667 reg=0.011595
2017/08/30 05:23:52 step 3: objective=0.246245 reg=0.011596
2017/08/30 05:24:06 step 4: objective=0.246782 reg=0.011593
2017/08/30 05:24:19 step 5: objective=0.247202 reg=0.011595
2017/08/30 05:24:33 step 6: objective=0.247615 reg=0.011594
2017/08/30 05:24:47 step 7: objective=0.247948 reg=0.011598
2017/08/30 05:24:47 Training value function...
2017/08/30 05:24:53 step 0: mse=1.129269 step=0.050000
2017/08/30 05:24:57 step 1: mse=1.129201 step=0.050000
2017/08/30 05:25:00 step 2: mse=1.129151 step=0.050000
2017/08/30 05:25:04 step 3: mse=1.129115 step=0.050000
2017/08/30 05:25:07 step 4: mse=1.129094 step=0.050000
2017/08/30 05:25:10 step 5: mse=1.129081 step=0.050000
2017/08/30 05:25:14 step 6: mse=1.129073 step=0.050000
2017/08/30 05:25:17 step 7: mse=1.129041 step=0.050000
2017/08/30 05:25:17 Saving...
2017/08/30 05:25:18 Gathering batch of experience...
2017/08/30 05:25:54 batch 437: mean=5.638107 stddev=1.455707 entropy=1.157667 frames=100140 count=5007
2017/08/30 05:25:54 Training policy...
2017/08/30 05:26:16 step 0: objective=0.276274 reg=0.011577
2017/08/30 05:26:30 step 1: objective=0.276867 reg=0.011578
2017/08/30 05:26:44 step 2: objective=0.277418 reg=0.011577
2017/08/30 05:26:58 step 3: objective=0.278145 reg=0.011573
2017/08/30 05:27:12 step 4: objective=0.278723 reg=0.011573
2017/08/30 05:27:25 step 5: objective=0.279162 reg=0.011573
2017/08/30 05:27:39 step 6: objective=0.279573 reg=0.011570
2017/08/30 05:27:53 step 7: objective=0.280015 reg=0.011569
2017/08/30 05:27:53 Training value function...
2017/08/30 05:27:59 step 0: mse=1.212536 step=0.050000
2017/08/30 05:28:03 step 1: mse=1.211063 step=0.050000
2017/08/30 05:28:06 step 2: mse=1.209714 step=0.050000
2017/08/30 05:28:09 step 3: mse=1.208429 step=0.050000
2017/08/30 05:28:13 step 4: mse=1.207246 step=0.050000
2017/08/30 05:28:16 step 5: mse=1.206114 step=0.050000
2017/08/30 05:28:20 step 6: mse=1.205073 step=0.050000
2017/08/30 05:28:23 step 7: mse=1.204077 step=0.050000
2017/08/30 05:28:23 Saving...
2017/08/30 05:28:24 Gathering batch of experience...
2017/08/30 05:29:00 batch 438: mean=5.602756 stddev=1.455339 entropy=1.156797 frames=100140 count=5007
2017/08/30 05:29:00 Training policy...
2017/08/30 05:29:21 step 0: objective=0.256468 reg=0.011568
2017/08/30 05:29:35 step 1: objective=0.257090 reg=0.011568
2017/08/30 05:29:49 step 2: objective=0.257707 reg=0.011572
2017/08/30 05:30:03 step 3: objective=0.258223 reg=0.011569
2017/08/30 05:30:17 step 4: objective=0.258785 reg=0.011569
2017/08/30 05:30:31 step 5: objective=0.259358 reg=0.011568
2017/08/30 05:30:45 step 6: objective=0.259807 reg=0.011566
2017/08/30 05:30:59 step 7: objective=0.260178 reg=0.011568
2017/08/30 05:30:59 Training value function...
2017/08/30 05:31:05 step 0: mse=1.162679 step=0.050000
2017/08/30 05:31:08 step 1: mse=1.162264 step=0.050000
2017/08/30 05:31:12 step 2: mse=1.161887 step=0.050000
2017/08/30 05:31:15 step 3: mse=1.161528 step=0.050000
2017/08/30 05:31:19 step 4: mse=1.161195 step=0.050000
2017/08/30 05:31:22 step 5: mse=1.160869 step=0.050000
2017/08/30 05:31:26 step 6: mse=1.160575 step=0.050000
2017/08/30 05:31:29 step 7: mse=1.160256 step=0.050000
2017/08/30 05:31:29 Saving...
2017/08/30 05:31:29 Gathering batch of experience...
2017/08/30 05:32:06 batch 439: mean=5.582385 stddev=1.467834 entropy=1.157599 frames=100140 count=5007
2017/08/30 05:32:06 Training policy...
2017/08/30 05:32:27 step 0: objective=0.250701 reg=0.011576
2017/08/30 05:32:41 step 1: objective=0.251473 reg=0.011575
2017/08/30 05:32:55 step 2: objective=0.252219 reg=0.011574
2017/08/30 05:33:09 step 3: objective=0.252683 reg=0.011579
2017/08/30 05:33:23 step 4: objective=0.253105 reg=0.011582
2017/08/30 05:33:37 step 5: objective=0.253536 reg=0.011577
2017/08/30 05:33:51 step 6: objective=0.253880 reg=0.011576
2017/08/30 05:34:05 step 7: objective=0.254370 reg=0.011574
2017/08/30 05:34:05 Training value function...
2017/08/30 05:34:11 step 0: mse=1.173726 step=0.050000
2017/08/30 05:34:14 step 1: mse=1.173701 step=0.050000
2017/08/30 05:34:18 step 2: mse=1.173735 step=0.050000
2017/08/30 05:34:21 step 3: mse=1.173778 step=0.050000
2017/08/30 05:34:24 step 4: mse=1.173818 step=0.050000
2017/08/30 05:34:28 step 5: mse=1.173818 step=0.050000
2017/08/30 05:34:31 step 6: mse=1.173857 step=0.050000
2017/08/30 05:34:35 step 7: mse=1.173891 step=0.050000
2017/08/30 05:34:35 Saving...
2017/08/30 05:34:35 Gathering batch of experience...
2017/08/30 05:35:12 batch 440: mean=5.507889 stddev=1.457160 entropy=1.159837 frames=100140 count=5007
2017/08/30 05:35:12 Training policy...
2017/08/30 05:35:33 step 0: objective=0.223819 reg=0.011598
2017/08/30 05:35:47 step 1: objective=0.224393 reg=0.011598
2017/08/30 05:36:01 step 2: objective=0.224859 reg=0.011594
2017/08/30 05:36:15 step 3: objective=0.225247 reg=0.011600
2017/08/30 05:36:29 step 4: objective=0.225742 reg=0.011604
2017/08/30 05:36:43 step 5: objective=0.226119 reg=0.011601
2017/08/30 05:36:57 step 6: objective=0.226542 reg=0.011599
2017/08/30 05:37:11 step 7: objective=0.226952 reg=0.011595
2017/08/30 05:37:11 Training value function...
2017/08/30 05:37:17 step 0: mse=1.097903 step=0.050000
2017/08/30 05:37:21 step 1: mse=1.098935 step=0.050000
2017/08/30 05:37:24 step 2: mse=1.099928 step=0.050000
2017/08/30 05:37:28 step 3: mse=1.100881 step=0.050000
2017/08/30 05:37:31 step 4: mse=1.101788 step=0.050000
2017/08/30 05:37:35 step 5: mse=1.102629 step=0.050000
2017/08/30 05:37:38 step 6: mse=1.103434 step=0.050000
2017/08/30 05:37:42 step 7: mse=1.104195 step=0.050000
2017/08/30 05:37:42 Saving...
2017/08/30 05:37:42 Gathering batch of experience...
2017/08/30 05:38:18 batch 441: mean=5.558019 stddev=1.462732 entropy=1.157275 frames=100140 count=5007
2017/08/30 05:38:18 Training policy...
2017/08/30 05:38:40 step 0: objective=0.257904 reg=0.011573
2017/08/30 05:38:55 step 1: objective=0.258688 reg=0.011571
2017/08/30 05:39:09 step 2: objective=0.259186 reg=0.011568
2017/08/30 05:39:23 step 3: objective=0.259738 reg=0.011565
2017/08/30 05:39:37 step 4: objective=0.260147 reg=0.011570
2017/08/30 05:39:51 step 5: objective=0.260594 reg=0.011567
2017/08/30 05:40:05 step 6: objective=0.261094 reg=0.011570
2017/08/30 05:40:19 step 7: objective=0.261521 reg=0.011572
2017/08/30 05:40:19 Training value function...
2017/08/30 05:40:25 step 0: mse=1.154592 step=0.050000
2017/08/30 05:40:28 step 1: mse=1.153759 step=0.050000
2017/08/30 05:40:32 step 2: mse=1.152990 step=0.050000
2017/08/30 05:40:35 step 3: mse=1.152277 step=0.050000
2017/08/30 05:40:38 step 4: mse=1.151611 step=0.050000
2017/08/30 05:40:42 step 5: mse=1.150990 step=0.050000
2017/08/30 05:40:45 step 6: mse=1.150406 step=0.050000
2017/08/30 05:40:49 step 7: mse=1.149856 step=0.050000
2017/08/30 05:40:49 Saving...
2017/08/30 05:40:49 Gathering batch of experience...
2017/08/30 05:41:26 batch 442: mean=5.573797 stddev=1.463113 entropy=1.155607 frames=100140 count=5007
2017/08/30 05:41:26 Training policy...
2017/08/30 05:41:47 step 0: objective=0.250834 reg=0.011556
2017/08/30 05:42:01 step 1: objective=0.251426 reg=0.011556
2017/08/30 05:42:15 step 2: objective=0.251814 reg=0.011557
2017/08/30 05:42:29 step 3: objective=0.252372 reg=0.011557
2017/08/30 05:42:43 step 4: objective=0.252935 reg=0.011554
2017/08/30 05:42:58 step 5: objective=0.253288 reg=0.011559
2017/08/30 05:43:12 step 6: objective=0.253726 reg=0.011554
2017/08/30 05:43:26 step 7: objective=0.254136 reg=0.011552
2017/08/30 05:43:26 Training value function...
2017/08/30 05:43:32 step 0: mse=1.135564 step=0.050000
2017/08/30 05:43:35 step 1: mse=1.134998 step=0.050000
2017/08/30 05:43:39 step 2: mse=1.134478 step=0.050000
2017/08/30 05:43:42 step 3: mse=1.133997 step=0.050000
2017/08/30 05:43:46 step 4: mse=1.133545 step=0.050000
2017/08/30 05:43:49 step 5: mse=1.133126 step=0.050000
2017/08/30 05:43:53 step 6: mse=1.132734 step=0.050000
2017/08/30 05:43:56 step 7: mse=1.132366 step=0.050000
2017/08/30 05:43:56 Saving...
2017/08/30 05:43:56 Gathering batch of experience...
2017/08/30 05:44:33 batch 443: mean=5.570601 stddev=1.488575 entropy=1.154715 frames=100140 count=5007
2017/08/30 05:44:33 Training policy...
2017/08/30 05:44:54 step 0: objective=0.243553 reg=0.011547
2017/08/30 05:45:08 step 1: objective=0.244293 reg=0.011548
2017/08/30 05:45:22 step 2: objective=0.244862 reg=0.011553
2017/08/30 05:45:37 step 3: objective=0.245393 reg=0.011555
2017/08/30 05:45:51 step 4: objective=0.245957 reg=0.011555
2017/08/30 05:46:05 step 5: objective=0.246368 reg=0.011550
2017/08/30 05:46:19 step 6: objective=0.246731 reg=0.011554
2017/08/30 05:46:33 step 7: objective=0.247087 reg=0.011551
2017/08/30 05:46:33 Training value function...
2017/08/30 05:46:39 step 0: mse=1.166445 step=0.050000
2017/08/30 05:46:42 step 1: mse=1.166781 step=0.050000
2017/08/30 05:46:46 step 2: mse=1.167090 step=0.050000
2017/08/30 05:46:49 step 3: mse=1.167391 step=0.050000
2017/08/30 05:46:53 step 4: mse=1.167686 step=0.050000
2017/08/30 05:46:56 step 5: mse=1.167969 step=0.050000
2017/08/30 05:47:00 step 6: mse=1.168240 step=0.050000
2017/08/30 05:47:03 step 7: mse=1.168496 step=0.050000
2017/08/30 05:47:03 Saving...
2017/08/30 05:47:03 Gathering batch of experience...
2017/08/30 05:47:40 batch 444: mean=5.554624 stddev=1.468177 entropy=1.154892 frames=100140 count=5007
2017/08/30 05:47:40 Training policy...
2017/08/30 05:48:02 step 0: objective=0.248476 reg=0.011549
2017/08/30 05:48:17 step 1: objective=0.249112 reg=0.011553
2017/08/30 05:48:31 step 2: objective=0.249685 reg=0.011552
2017/08/30 05:48:46 step 3: objective=0.250364 reg=0.011551
2017/08/30 05:49:00 step 4: objective=0.250745 reg=0.011553
2017/08/30 05:49:14 step 5: objective=0.251185 reg=0.011553
2017/08/30 05:49:28 step 6: objective=0.251555 reg=0.011555
2017/08/30 05:49:43 step 7: objective=0.252010 reg=0.011552
2017/08/30 05:49:43 Training value function...
2017/08/30 05:49:49 step 0: mse=1.155326 step=0.050000
2017/08/30 05:49:52 step 1: mse=1.155372 step=0.050000
2017/08/30 05:49:56 step 2: mse=1.155361 step=0.050000
2017/08/30 05:49:59 step 3: mse=1.155411 step=0.050000
2017/08/30 05:50:03 step 4: mse=1.155453 step=0.050000
2017/08/30 05:50:06 step 5: mse=1.155442 step=0.050000
2017/08/30 05:50:10 step 6: mse=1.155458 step=0.050000
2017/08/30 05:50:13 step 7: mse=1.155427 step=0.050000
2017/08/30 05:50:13 Saving...
2017/08/30 05:50:13 Gathering batch of experience...
2017/08/30 05:50:50 batch 445: mean=5.588376 stddev=1.443334 entropy=1.152643 frames=100140 count=5007
2017/08/30 05:50:50 Training policy...
2017/08/30 05:51:12 step 0: objective=0.261834 reg=0.011526
2017/08/30 05:51:26 step 1: objective=0.262501 reg=0.011529
2017/08/30 05:51:40 step 2: objective=0.262938 reg=0.011531
2017/08/30 05:51:55 step 3: objective=0.263485 reg=0.011531
2017/08/30 05:52:09 step 4: objective=0.264028 reg=0.011530
2017/08/30 05:52:23 step 5: objective=0.264458 reg=0.011529
2017/08/30 05:52:38 step 6: objective=0.264917 reg=0.011527
2017/08/30 05:52:52 step 7: objective=0.265346 reg=0.011528
2017/08/30 05:52:52 Training value function...
2017/08/30 05:52:58 step 0: mse=1.185624 step=0.050000
2017/08/30 05:53:01 step 1: mse=1.184895 step=0.050000
2017/08/30 05:53:05 step 2: mse=1.184223 step=0.050000
2017/08/30 05:53:08 step 3: mse=1.183597 step=0.050000
2017/08/30 05:53:12 step 4: mse=1.183023 step=0.050000
2017/08/30 05:53:15 step 5: mse=1.182428 step=0.050000
2017/08/30 05:53:19 step 6: mse=1.181874 step=0.050000
2017/08/30 05:53:22 step 7: mse=1.181367 step=0.050000
2017/08/30 05:53:22 Saving...
2017/08/30 05:53:22 Gathering batch of experience...
2017/08/30 05:53:59 batch 446: mean=5.579589 stddev=1.480722 entropy=1.153828 frames=100140 count=5007
2017/08/30 05:53:59 Training policy...
2017/08/30 05:54:21 step 0: objective=0.252657 reg=0.011538
2017/08/30 05:54:35 step 1: objective=0.253419 reg=0.011535
2017/08/30 05:54:49 step 2: objective=0.254090 reg=0.011534
2017/08/30 05:55:03 step 3: objective=0.254581 reg=0.011533
2017/08/30 05:55:18 step 4: objective=0.255017 reg=0.011536
2017/08/30 05:55:32 step 5: objective=0.255498 reg=0.011535
2017/08/30 05:55:47 step 6: objective=0.255911 reg=0.011532
2017/08/30 05:56:01 step 7: objective=0.256278 reg=0.011533
2017/08/30 05:56:01 Training value function...
2017/08/30 05:56:07 step 0: mse=1.160833 step=0.050000
2017/08/30 05:56:11 step 1: mse=1.160409 step=0.050000
2017/08/30 05:56:14 step 2: mse=1.160022 step=0.050000
2017/08/30 05:56:18 step 3: mse=1.159665 step=0.050000
2017/08/30 05:56:21 step 4: mse=1.159327 step=0.050000
2017/08/30 05:56:24 step 5: mse=1.159007 step=0.050000
2017/08/30 05:56:28 step 6: mse=1.158712 step=0.050000
2017/08/30 05:56:31 step 7: mse=1.158427 step=0.050000
2017/08/30 05:56:31 Saving...
2017/08/30 05:56:32 Gathering batch of experience...
2017/08/30 05:57:08 batch 447: mean=5.580387 stddev=1.459211 entropy=1.154047 frames=100140 count=5007
2017/08/30 05:57:08 Training policy...
2017/08/30 05:57:30 step 0: objective=0.255953 reg=0.011540
2017/08/30 05:57:44 step 1: objective=0.256611 reg=0.011538
2017/08/30 05:57:59 step 2: objective=0.257133 reg=0.011537
2017/08/30 05:58:13 step 3: objective=0.257832 reg=0.011537
2017/08/30 05:58:28 step 4: objective=0.258292 reg=0.011535
2017/08/30 05:58:43 step 5: objective=0.258769 reg=0.011536
2017/08/30 05:58:58 step 6: objective=0.259225 reg=0.011537
2017/08/30 05:59:12 step 7: objective=0.259547 reg=0.011536
2017/08/30 05:59:12 Training value function...
2017/08/30 05:59:18 step 0: mse=1.142337 step=0.050000
2017/08/30 05:59:22 step 1: mse=1.141922 step=0.050000
2017/08/30 05:59:25 step 2: mse=1.141546 step=0.050000
2017/08/30 05:59:29 step 3: mse=1.141203 step=0.050000
2017/08/30 05:59:32 step 4: mse=1.140890 step=0.050000
2017/08/30 05:59:36 step 5: mse=1.140604 step=0.050000
2017/08/30 05:59:39 step 6: mse=1.140337 step=0.050000
2017/08/30 05:59:43 step 7: mse=1.140087 step=0.050000
2017/08/30 05:59:43 Saving...
2017/08/30 05:59:43 Gathering batch of experience...
2017/08/30 06:00:20 batch 448: mean=5.561614 stddev=1.476312 entropy=1.160038 frames=100140 count=5007
2017/08/30 06:00:20 Training policy...
2017/08/30 06:00:41 step 0: objective=0.249506 reg=0.011600
2017/08/30 06:00:56 step 1: objective=0.250177 reg=0.011604
2017/08/30 06:01:10 step 2: objective=0.250755 reg=0.011602
2017/08/30 06:01:24 step 3: objective=0.251336 reg=0.011605
2017/08/30 06:01:39 step 4: objective=0.251843 reg=0.011604
2017/08/30 06:01:53 step 5: objective=0.252204 reg=0.011608
2017/08/30 06:02:08 step 6: objective=0.252727 reg=0.011607
2017/08/30 06:02:22 step 7: objective=0.253134 reg=0.011608
2017/08/30 06:02:22 Training value function...
2017/08/30 06:02:28 step 0: mse=1.168359 step=0.050000
2017/08/30 06:02:31 step 1: mse=1.168177 step=0.050000
2017/08/30 06:02:35 step 2: mse=1.168014 step=0.050000
2017/08/30 06:02:38 step 3: mse=1.167848 step=0.050000
2017/08/30 06:02:42 step 4: mse=1.167715 step=0.050000
2017/08/30 06:02:45 step 5: mse=1.167593 step=0.050000
2017/08/30 06:02:49 step 6: mse=1.167461 step=0.050000
2017/08/30 06:02:52 step 7: mse=1.167342 step=0.050000
2017/08/30 06:02:52 Saving...
2017/08/30 06:02:52 Gathering batch of experience...
2017/08/30 06:03:29 batch 449: mean=5.590973 stddev=1.461872 entropy=1.152781 frames=100140 count=5007
2017/08/30 06:03:29 Training policy...
2017/08/30 06:03:51 step 0: objective=0.259618 reg=0.011528
2017/08/30 06:04:05 step 1: objective=0.260305 reg=0.011528
2017/08/30 06:04:20 step 2: objective=0.260815 reg=0.011533
2017/08/30 06:04:34 step 3: objective=0.261302 reg=0.011526
2017/08/30 06:04:48 step 4: objective=0.261831 reg=0.011525
2017/08/30 06:05:03 step 5: objective=0.262280 reg=0.011526
2017/08/30 06:05:17 step 6: objective=0.262709 reg=0.011523
2017/08/30 06:05:32 step 7: objective=0.263057 reg=0.011518
2017/08/30 06:05:32 Training value function...
2017/08/30 06:05:38 step 0: mse=1.155605 step=0.050000
2017/08/30 06:05:41 step 1: mse=1.154555 step=0.050000
2017/08/30 06:05:45 step 2: mse=1.153603 step=0.050000
2017/08/30 06:05:48 step 3: mse=1.152713 step=0.050000
2017/08/30 06:05:51 step 4: mse=1.151879 step=0.050000
2017/08/30 06:05:55 step 5: mse=1.151088 step=0.050000
2017/08/30 06:05:58 step 6: mse=1.150354 step=0.050000
2017/08/30 06:06:02 step 7: mse=1.149655 step=0.050000
2017/08/30 06:06:02 Saving...
2017/08/30 06:06:02 Gathering batch of experience...
2017/08/30 06:06:39 batch 450: mean=5.561214 stddev=1.467917 entropy=1.151459 frames=100140 count=5007
2017/08/30 06:06:39 Training policy...
2017/08/30 06:07:01 step 0: objective=0.239029 reg=0.011515
2017/08/30 06:07:16 step 1: objective=0.239673 reg=0.011516
2017/08/30 06:07:30 step 2: objective=0.240284 reg=0.011518
2017/08/30 06:07:45 step 3: objective=0.240759 reg=0.011521
2017/08/30 06:07:59 step 4: objective=0.241186 reg=0.011518
2017/08/30 06:08:14 step 5: objective=0.241773 reg=0.011522
2017/08/30 06:08:28 step 6: objective=0.242208 reg=0.011518
2017/08/30 06:08:43 step 7: objective=0.242522 reg=0.011517
2017/08/30 06:08:43 Training value function...
2017/08/30 06:08:49 step 0: mse=1.129923 step=0.050000
2017/08/30 06:08:52 step 1: mse=1.130245 step=0.050000
2017/08/30 06:08:56 step 2: mse=1.130544 step=0.050000
2017/08/30 06:08:59 step 3: mse=1.130838 step=0.050000
2017/08/30 06:09:03 step 4: mse=1.131107 step=0.050000
2017/08/30 06:09:06 step 5: mse=1.131375 step=0.050000
2017/08/30 06:09:10 step 6: mse=1.131619 step=0.050000
2017/08/30 06:09:13 step 7: mse=1.131856 step=0.050000
2017/08/30 06:09:13 Saving...
2017/08/30 06:09:13 Gathering batch of experience...
2017/08/30 06:09:50 batch 451: mean=5.579988 stddev=1.486220 entropy=1.149797 frames=100140 count=5007
2017/08/30 06:09:50 Training policy...
2017/08/30 06:10:12 step 0: objective=0.261592 reg=0.011498
2017/08/30 06:10:26 step 1: objective=0.262269 reg=0.011500
2017/08/30 06:10:41 step 2: objective=0.262879 reg=0.011500
2017/08/30 06:10:55 step 3: objective=0.263443 reg=0.011499
2017/08/30 06:11:10 step 4: objective=0.263867 reg=0.011497
2017/08/30 06:11:24 step 5: objective=0.264359 reg=0.011495
2017/08/30 06:11:39 step 6: objective=0.264910 reg=0.011495
2017/08/30 06:11:53 step 7: objective=0.265378 reg=0.011494
2017/08/30 06:11:53 Training value function...
2017/08/30 06:11:59 step 0: mse=1.163197 step=0.050000
2017/08/30 06:12:03 step 1: mse=1.161979 step=0.050000
2017/08/30 06:12:06 step 2: mse=1.160850 step=0.050000
2017/08/30 06:12:10 step 3: mse=1.159805 step=0.050000
2017/08/30 06:12:13 step 4: mse=1.158827 step=0.050000
2017/08/30 06:12:17 step 5: mse=1.157914 step=0.050000
2017/08/30 06:12:20 step 6: mse=1.157068 step=0.050000
2017/08/30 06:12:23 step 7: mse=1.156259 step=0.050000
2017/08/30 06:12:23 Saving...
2017/08/30 06:12:24 Gathering batch of experience...
2017/08/30 06:13:01 batch 452: mean=5.553625 stddev=1.475406 entropy=1.154807 frames=100140 count=5007
2017/08/30 06:13:01 Training policy...
2017/08/30 06:13:23 step 0: objective=0.249180 reg=0.011548
2017/08/30 06:13:37 step 1: objective=0.249921 reg=0.011549
2017/08/30 06:13:52 step 2: objective=0.250561 reg=0.011550
2017/08/30 06:14:06 step 3: objective=0.251139 reg=0.011547
2017/08/30 06:14:21 step 4: objective=0.251645 reg=0.011546
2017/08/30 06:14:35 step 5: objective=0.252104 reg=0.011542
2017/08/30 06:14:50 step 6: objective=0.252506 reg=0.011542
2017/08/30 06:15:05 step 7: objective=0.252876 reg=0.011543
2017/08/30 06:15:05 Training value function...
2017/08/30 06:15:11 step 0: mse=1.162177 step=0.050000
2017/08/30 06:15:14 step 1: mse=1.162435 step=0.050000
2017/08/30 06:15:18 step 2: mse=1.162697 step=0.050000
2017/08/30 06:15:21 step 3: mse=1.162942 step=0.050000
2017/08/30 06:15:25 step 4: mse=1.163196 step=0.050000
2017/08/30 06:15:28 step 5: mse=1.163430 step=0.050000
2017/08/30 06:15:32 step 6: mse=1.163649 step=0.050000
2017/08/30 06:15:35 step 7: mse=1.163850 step=0.050000
2017/08/30 06:15:35 Saving...
2017/08/30 06:15:35 Gathering batch of experience...
2017/08/30 06:16:12 batch 453: mean=5.609946 stddev=1.474720 entropy=1.151003 frames=100140 count=5007
2017/08/30 06:16:12 Training policy...
2017/08/30 06:16:34 step 0: objective=0.260594 reg=0.011510
2017/08/30 06:16:49 step 1: objective=0.261288 reg=0.011509
2017/08/30 06:17:03 step 2: objective=0.261771 reg=0.011512
2017/08/30 06:17:18 step 3: objective=0.262310 reg=0.011514
2017/08/30 06:17:32 step 4: objective=0.262818 reg=0.011514
2017/08/30 06:17:47 step 5: objective=0.263268 reg=0.011515
2017/08/30 06:18:02 step 6: objective=0.263786 reg=0.011512
2017/08/30 06:18:16 step 7: objective=0.264128 reg=0.011507
2017/08/30 06:18:16 Training value function...
2017/08/30 06:18:22 step 0: mse=1.199270 step=0.050000
2017/08/30 06:18:26 step 1: mse=1.198793 step=0.050000
2017/08/30 06:18:29 step 2: mse=1.198354 step=0.050000
2017/08/30 06:18:33 step 3: mse=1.197885 step=0.050000
2017/08/30 06:18:36 step 4: mse=1.197491 step=0.050000
2017/08/30 06:18:40 step 5: mse=1.197085 step=0.050000
2017/08/30 06:18:43 step 6: mse=1.196667 step=0.050000
2017/08/30 06:18:47 step 7: mse=1.196317 step=0.050000
2017/08/30 06:18:47 Saving...
2017/08/30 06:18:47 Gathering batch of experience...
2017/08/30 06:19:24 batch 454: mean=5.561614 stddev=1.483599 entropy=1.150024 frames=100140 count=5007
2017/08/30 06:19:24 Training policy...
2017/08/30 06:19:46 step 0: objective=0.243815 reg=0.011500
2017/08/30 06:20:00 step 1: objective=0.244462 reg=0.011500
2017/08/30 06:20:15 step 2: objective=0.245053 reg=0.011500
2017/08/30 06:20:30 step 3: objective=0.245583 reg=0.011495
2017/08/30 06:20:44 step 4: objective=0.246034 reg=0.011495
2017/08/30 06:20:59 step 5: objective=0.246510 reg=0.011496
2017/08/30 06:21:14 step 6: objective=0.246841 reg=0.011493
2017/08/30 06:21:29 step 7: objective=0.247325 reg=0.011494
2017/08/30 06:21:29 Training value function...
2017/08/30 06:21:35 step 0: mse=1.194802 step=0.050000
2017/08/30 06:21:38 step 1: mse=1.195189 step=0.050000
2017/08/30 06:21:42 step 2: mse=1.195569 step=0.050000
2017/08/30 06:21:45 step 3: mse=1.195941 step=0.050000
2017/08/30 06:21:49 step 4: mse=1.196303 step=0.050000
2017/08/30 06:21:52 step 5: mse=1.196647 step=0.050000
2017/08/30 06:21:56 step 6: mse=1.196980 step=0.050000
2017/08/30 06:21:59 step 7: mse=1.197294 step=0.050000
2017/08/30 06:21:59 Saving...
2017/08/30 06:21:59 Gathering batch of experience...
2017/08/30 06:22:36 batch 455: mean=5.556221 stddev=1.484083 entropy=1.152324 frames=100140 count=5007
2017/08/30 06:22:36 Training policy...
2017/08/30 06:22:58 step 0: objective=0.242530 reg=0.011523
2017/08/30 06:23:13 step 1: objective=0.243135 reg=0.011524
2017/08/30 06:23:28 step 2: objective=0.243685 reg=0.011528
2017/08/30 06:23:42 step 3: objective=0.244095 reg=0.011520
2017/08/30 06:23:57 step 4: objective=0.244659 reg=0.011518
2017/08/30 06:24:12 step 5: objective=0.245070 reg=0.011519
2017/08/30 06:24:26 step 6: objective=0.245488 reg=0.011518
2017/08/30 06:24:41 step 7: objective=0.245852 reg=0.011518
2017/08/30 06:24:41 Training value function...
2017/08/30 06:24:47 step 0: mse=1.156232 step=0.050000
2017/08/30 06:24:51 step 1: mse=1.156397 step=0.050000
2017/08/30 06:24:54 step 2: mse=1.156562 step=0.050000
2017/08/30 06:24:57 step 3: mse=1.156729 step=0.050000
2017/08/30 06:25:01 step 4: mse=1.156888 step=0.050000
2017/08/30 06:25:04 step 5: mse=1.157042 step=0.050000
2017/08/30 06:25:08 step 6: mse=1.157192 step=0.050000
2017/08/30 06:25:11 step 7: mse=1.157330 step=0.050000
2017/08/30 06:25:11 Saving...
2017/08/30 06:25:12 Gathering batch of experience...
2017/08/30 06:25:49 batch 456: mean=5.582984 stddev=1.460844 entropy=1.151336 frames=100140 count=5007
2017/08/30 06:25:49 Training policy...
2017/08/30 06:26:10 step 0: objective=0.249112 reg=0.011513
2017/08/30 06:26:25 step 1: objective=0.249809 reg=0.011511
2017/08/30 06:26:40 step 2: objective=0.250455 reg=0.011517
2017/08/30 06:26:55 step 3: objective=0.251068 reg=0.011517
2017/08/30 06:27:10 step 4: objective=0.251547 reg=0.011518
2017/08/30 06:27:25 step 5: objective=0.251988 reg=0.011516
2017/08/30 06:27:40 step 6: objective=0.252428 reg=0.011514
2017/08/30 06:27:54 step 7: objective=0.252818 reg=0.011511
2017/08/30 06:27:54 Training value function...
2017/08/30 06:28:01 step 0: mse=1.176339 step=0.050000
2017/08/30 06:28:04 step 1: mse=1.176252 step=0.050000
2017/08/30 06:28:08 step 2: mse=1.176176 step=0.050000
2017/08/30 06:28:11 step 3: mse=1.176116 step=0.050000
2017/08/30 06:28:15 step 4: mse=1.176050 step=0.050000
2017/08/30 06:28:18 step 5: mse=1.175992 step=0.050000
2017/08/30 06:28:22 step 6: mse=1.175937 step=0.050000
2017/08/30 06:28:25 step 7: mse=1.175883 step=0.050000
2017/08/30 06:28:25 Saving...
2017/08/30 06:28:25 Gathering batch of experience...
2017/08/30 06:29:02 batch 457: mean=5.533653 stddev=1.505869 entropy=1.150064 frames=100140 count=5007
2017/08/30 06:29:02 Training policy...
2017/08/30 06:29:25 step 0: objective=0.248317 reg=0.011501
2017/08/30 06:29:39 step 1: objective=0.249039 reg=0.011502
2017/08/30 06:29:54 step 2: objective=0.249529 reg=0.011506
2017/08/30 06:30:09 step 3: objective=0.249901 reg=0.011498
2017/08/30 06:30:24 step 4: objective=0.250217 reg=0.011508
2017/08/30 06:30:38 step 5: objective=0.250536 reg=0.011493
2017/08/30 06:30:53 step 6: objective=0.250815 reg=0.011509
2017/08/30 06:31:08 step 7: objective=0.251129 reg=0.011493
2017/08/30 06:31:08 Training value function...
2017/08/30 06:31:14 step 0: mse=1.160381 step=0.050000
2017/08/30 06:31:17 step 1: mse=1.160159 step=0.050000
2017/08/30 06:31:21 step 2: mse=1.159962 step=0.050000
2017/08/30 06:31:24 step 3: mse=1.159783 step=0.050000
2017/08/30 06:31:28 step 4: mse=1.159618 step=0.050000
2017/08/30 06:31:31 step 5: mse=1.159471 step=0.050000
2017/08/30 06:31:35 step 6: mse=1.159295 step=0.050000
2017/08/30 06:31:38 step 7: mse=1.159136 step=0.050000
2017/08/30 06:31:38 Saving...
2017/08/30 06:31:38 Gathering batch of experience...
2017/08/30 06:32:15 batch 458: mean=5.606950 stddev=1.461200 entropy=1.149024 frames=100140 count=5007
2017/08/30 06:32:15 Training policy...
2017/08/30 06:32:37 step 0: objective=0.268578 reg=0.011490
2017/08/30 06:32:52 step 1: objective=0.269321 reg=0.011487
2017/08/30 06:33:07 step 2: objective=0.269883 reg=0.011487
2017/08/30 06:33:22 step 3: objective=0.270272 reg=0.011488
2017/08/30 06:33:37 step 4: objective=0.270863 reg=0.011490
2017/08/30 06:33:52 step 5: objective=0.271320 reg=0.011491
2017/08/30 06:34:06 step 6: objective=0.271749 reg=0.011490
2017/08/30 06:34:21 step 7: objective=0.272176 reg=0.011491
2017/08/30 06:34:21 Training value function...
2017/08/30 06:34:27 step 0: mse=1.182538 step=0.050000
2017/08/30 06:34:31 step 1: mse=1.181171 step=0.050000
2017/08/30 06:34:34 step 2: mse=1.179899 step=0.050000
2017/08/30 06:34:38 step 3: mse=1.178714 step=0.050000
2017/08/30 06:34:41 step 4: mse=1.177612 step=0.050000
2017/08/30 06:34:45 step 5: mse=1.176548 step=0.050000
2017/08/30 06:34:48 step 6: mse=1.175556 step=0.050000
2017/08/30 06:34:52 step 7: mse=1.174629 step=0.050000
2017/08/30 06:34:52 Saving...
2017/08/30 06:34:52 Gathering batch of experience...
2017/08/30 06:35:29 batch 459: mean=5.554624 stddev=1.461223 entropy=1.146564 frames=100140 count=5007
2017/08/30 06:35:29 Training policy...
2017/08/30 06:35:51 step 0: objective=0.250184 reg=0.011466
2017/08/30 06:36:07 step 1: objective=0.250826 reg=0.011467
2017/08/30 06:36:22 step 2: objective=0.251225 reg=0.011472
2017/08/30 06:36:36 step 3: objective=0.251683 reg=0.011476
2017/08/30 06:36:52 step 4: objective=0.252255 reg=0.011475
2017/08/30 06:37:06 step 5: objective=0.252648 reg=0.011474
2017/08/30 06:37:21 step 6: objective=0.253083 reg=0.011475
2017/08/30 06:37:36 step 7: objective=0.253507 reg=0.011475
2017/08/30 06:37:36 Training value function...
2017/08/30 06:37:42 step 0: mse=1.149669 step=0.050000
2017/08/30 06:37:46 step 1: mse=1.149189 step=0.050000
2017/08/30 06:37:49 step 2: mse=1.148787 step=0.050000
2017/08/30 06:37:52 step 3: mse=1.148376 step=0.050000
2017/08/30 06:37:56 step 4: mse=1.147978 step=0.050000
2017/08/30 06:37:59 step 5: mse=1.147570 step=0.050000
2017/08/30 06:38:03 step 6: mse=1.147211 step=0.050000
2017/08/30 06:38:06 step 7: mse=1.146885 step=0.050000
2017/08/30 06:38:06 Saving...
2017/08/30 06:38:07 Gathering batch of experience...
2017/08/30 06:38:44 batch 460: mean=5.547234 stddev=1.462027 entropy=1.154320 frames=100140 count=5007
2017/08/30 06:38:44 Training policy...
2017/08/30 06:39:06 step 0: objective=0.248926 reg=0.011543
2017/08/30 06:39:20 step 1: objective=0.249634 reg=0.011535
2017/08/30 06:39:36 step 2: objective=0.250067 reg=0.011540
2017/08/30 06:39:51 step 3: objective=0.250584 reg=0.011533
2017/08/30 06:40:06 step 4: objective=0.251128 reg=0.011534
2017/08/30 06:40:21 step 5: objective=0.251627 reg=0.011529
2017/08/30 06:40:36 step 6: objective=0.252090 reg=0.011530
2017/08/30 06:40:51 step 7: objective=0.252519 reg=0.011526
2017/08/30 06:40:51 Training value function...
2017/08/30 06:40:57 step 0: mse=1.155155 step=0.050000
2017/08/30 06:41:00 step 1: mse=1.155118 step=0.050000
2017/08/30 06:41:04 step 2: mse=1.155096 step=0.050000
2017/08/30 06:41:07 step 3: mse=1.155081 step=0.050000
2017/08/30 06:41:11 step 4: mse=1.155076 step=0.050000
2017/08/30 06:41:14 step 5: mse=1.155076 step=0.050000
2017/08/30 06:41:18 step 6: mse=1.155050 step=0.050000
2017/08/30 06:41:21 step 7: mse=1.154971 step=0.050000
2017/08/30 06:41:21 Saving...
2017/08/30 06:41:21 Gathering batch of experience...
2017/08/30 06:41:59 batch 461: mean=5.557220 stddev=1.488479 entropy=1.147341 frames=100140 count=5007
2017/08/30 06:41:59 Training policy...
2017/08/30 06:42:22 step 0: objective=0.246473 reg=0.011473
2017/08/30 06:42:37 step 1: objective=0.247001 reg=0.011474
2017/08/30 06:42:52 step 2: objective=0.247603 reg=0.011473
2017/08/30 06:43:07 step 3: objective=0.248083 reg=0.011475
2017/08/30 06:43:21 step 4: objective=0.248574 reg=0.011475
2017/08/30 06:43:37 step 5: objective=0.249058 reg=0.011477
2017/08/30 06:43:52 step 6: objective=0.249615 reg=0.011474
2017/08/30 06:44:07 step 7: objective=0.250031 reg=0.011472
2017/08/30 06:44:07 Training value function...
2017/08/30 06:44:13 step 0: mse=1.166336 step=0.050000
2017/08/30 06:44:16 step 1: mse=1.166463 step=0.050000
2017/08/30 06:44:20 step 2: mse=1.166591 step=0.050000
2017/08/30 06:44:23 step 3: mse=1.166720 step=0.050000
2017/08/30 06:44:27 step 4: mse=1.166842 step=0.050000
2017/08/30 06:44:30 step 5: mse=1.166959 step=0.050000
2017/08/30 06:44:33 step 6: mse=1.167071 step=0.050000
2017/08/30 06:44:37 step 7: mse=1.167177 step=0.050000
2017/08/30 06:44:37 Saving...
2017/08/30 06:44:37 Gathering batch of experience...
2017/08/30 06:45:14 batch 462: mean=5.566207 stddev=1.475572 entropy=1.145551 frames=100140 count=5007
2017/08/30 06:45:14 Training policy...
2017/08/30 06:45:37 step 0: objective=0.259504 reg=0.011456
2017/08/30 06:45:52 step 1: objective=0.260104 reg=0.011452
2017/08/30 06:46:07 step 2: objective=0.260551 reg=0.011452
2017/08/30 06:46:22 step 3: objective=0.261049 reg=0.011450
2017/08/30 06:46:37 step 4: objective=0.261450 reg=0.011445
2017/08/30 06:46:52 step 5: objective=0.261968 reg=0.011446
2017/08/30 06:47:07 step 6: objective=0.262505 reg=0.011444
2017/08/30 06:47:22 step 7: objective=0.262896 reg=0.011442
2017/08/30 06:47:22 Training value function...
2017/08/30 06:47:28 step 0: mse=1.123031 step=0.050000
2017/08/30 06:47:32 step 1: mse=1.121765 step=0.050000
2017/08/30 06:47:35 step 2: mse=1.120583 step=0.050000
2017/08/30 06:47:39 step 3: mse=1.119488 step=0.050000
2017/08/30 06:47:42 step 4: mse=1.118477 step=0.050000
2017/08/30 06:47:46 step 5: mse=1.117535 step=0.050000
2017/08/30 06:47:49 step 6: mse=1.116657 step=0.050000
2017/08/30 06:47:53 step 7: mse=1.115835 step=0.050000
2017/08/30 06:47:53 Saving...
2017/08/30 06:47:53 Gathering batch of experience...
2017/08/30 06:48:30 batch 463: mean=5.507090 stddev=1.479876 entropy=1.153235 frames=100140 count=5007
2017/08/30 06:48:30 Training policy...
2017/08/30 06:48:52 step 0: objective=0.225450 reg=0.011532
2017/08/30 06:49:08 step 1: objective=0.226108 reg=0.011533
2017/08/30 06:49:23 step 2: objective=0.226826 reg=0.011533
2017/08/30 06:49:38 step 3: objective=0.227392 reg=0.011531
2017/08/30 06:49:53 step 4: objective=0.227788 reg=0.011533
2017/08/30 06:50:08 step 5: objective=0.228330 reg=0.011534
2017/08/30 06:50:23 step 6: objective=0.228809 reg=0.011533
2017/08/30 06:50:39 step 7: objective=0.229220 reg=0.011531
2017/08/30 06:50:39 Training value function...
2017/08/30 06:50:45 step 0: mse=1.153722 step=0.050000
2017/08/30 06:50:48 step 1: mse=1.155107 step=0.050000
2017/08/30 06:50:52 step 2: mse=1.156432 step=0.050000
2017/08/30 06:50:55 step 3: mse=1.157693 step=0.050000
2017/08/30 06:50:58 step 4: mse=1.158901 step=0.050000
2017/08/30 06:51:02 step 5: mse=1.160074 step=0.050000
2017/08/30 06:51:05 step 6: mse=1.161184 step=0.050000
2017/08/30 06:51:09 step 7: mse=1.162240 step=0.050000
2017/08/30 06:51:09 Saving...
2017/08/30 06:51:09 Gathering batch of experience...
2017/08/30 06:51:46 batch 464: mean=5.574396 stddev=1.453358 entropy=1.144750 frames=100140 count=5007
2017/08/30 06:51:46 Training policy...
2017/08/30 06:52:09 step 0: objective=0.259894 reg=0.011448
2017/08/30 06:52:24 step 1: objective=0.260627 reg=0.011449
2017/08/30 06:52:39 step 2: objective=0.261184 reg=0.011453
2017/08/30 06:52:55 step 3: objective=0.261935 reg=0.011456
2017/08/30 06:53:11 step 4: objective=0.262488 reg=0.011457
2017/08/30 06:53:26 step 5: objective=0.262911 reg=0.011455
2017/08/30 06:53:41 step 6: objective=0.263226 reg=0.011449
2017/08/30 06:53:56 step 7: objective=0.263576 reg=0.011452
2017/08/30 06:53:56 Training value function...
2017/08/30 06:54:02 step 0: mse=1.141259 step=0.050000
2017/08/30 06:54:06 step 1: mse=1.140648 step=0.050000
2017/08/30 06:54:09 step 2: mse=1.140055 step=0.050000
2017/08/30 06:54:13 step 3: mse=1.139478 step=0.050000
2017/08/30 06:54:16 step 4: mse=1.138951 step=0.050000
2017/08/30 06:54:20 step 5: mse=1.138455 step=0.050000
2017/08/30 06:54:23 step 6: mse=1.137949 step=0.050000
2017/08/30 06:54:27 step 7: mse=1.137514 step=0.050000
2017/08/30 06:54:27 Saving...
2017/08/30 06:54:27 Gathering batch of experience...
2017/08/30 06:55:04 batch 465: mean=5.570202 stddev=1.473762 entropy=1.148718 frames=100140 count=5007
2017/08/30 06:55:04 Training policy...
2017/08/30 06:55:26 step 0: objective=0.249026 reg=0.011487
2017/08/30 06:55:41 step 1: objective=0.249621 reg=0.011488
2017/08/30 06:55:57 step 2: objective=0.250074 reg=0.011492
2017/08/30 06:56:12 step 3: objective=0.250641 reg=0.011484
2017/08/30 06:56:27 step 4: objective=0.251198 reg=0.011480
2017/08/30 06:56:42 step 5: objective=0.251799 reg=0.011477
2017/08/30 06:56:58 step 6: objective=0.252187 reg=0.011475
2017/08/30 06:57:13 step 7: objective=0.252580 reg=0.011473
2017/08/30 06:57:13 Training value function...
2017/08/30 06:57:19 step 0: mse=1.144907 step=0.050000
2017/08/30 06:57:22 step 1: mse=1.144399 step=0.050000
2017/08/30 06:57:26 step 2: mse=1.143933 step=0.050000
2017/08/30 06:57:29 step 3: mse=1.143505 step=0.050000
2017/08/30 06:57:33 step 4: mse=1.143117 step=0.050000
2017/08/30 06:57:36 step 5: mse=1.142756 step=0.050000
2017/08/30 06:57:40 step 6: mse=1.142419 step=0.050000
2017/08/30 06:57:43 step 7: mse=1.142100 step=0.050000
2017/08/30 06:57:43 Saving...
2017/08/30 06:57:43 Gathering batch of experience...
2017/08/30 06:58:21 batch 466: mean=5.637907 stddev=1.456823 entropy=1.148319 frames=100140 count=5007
2017/08/30 06:58:21 Training policy...
2017/08/30 06:58:43 step 0: objective=0.280216 reg=0.011483
2017/08/30 06:58:58 step 1: objective=0.281003 reg=0.011485
2017/08/30 06:59:14 step 2: objective=0.281567 reg=0.011484
2017/08/30 06:59:29 step 3: objective=0.282083 reg=0.011482
2017/08/30 06:59:45 step 4: objective=0.282462 reg=0.011485
2017/08/30 07:00:00 step 5: objective=0.282892 reg=0.011481
2017/08/30 07:00:15 step 6: objective=0.283264 reg=0.011484
2017/08/30 07:00:31 step 7: objective=0.283700 reg=0.011479
2017/08/30 07:00:31 Training value function...
2017/08/30 07:00:37 step 0: mse=1.202265 step=0.050000
2017/08/30 07:00:40 step 1: mse=1.200186 step=0.050000
2017/08/30 07:00:44 step 2: mse=1.198268 step=0.050000
2017/08/30 07:00:47 step 3: mse=1.196478 step=0.050000
2017/08/30 07:00:51 step 4: mse=1.194801 step=0.050000
2017/08/30 07:00:54 step 5: mse=1.193226 step=0.050000
2017/08/30 07:00:58 step 6: mse=1.191751 step=0.050000
2017/08/30 07:01:01 step 7: mse=1.190372 step=0.050000
2017/08/30 07:01:01 Saving...
2017/08/30 07:01:01 Gathering batch of experience...
2017/08/30 07:01:39 batch 467: mean=5.556820 stddev=1.497324 entropy=1.149092 frames=100140 count=5007
2017/08/30 07:01:39 Training policy...
2017/08/30 07:02:02 step 0: objective=0.240081 reg=0.011491
2017/08/30 07:02:17 step 1: objective=0.240603 reg=0.011491
2017/08/30 07:02:32 step 2: objective=0.241168 reg=0.011492
2017/08/30 07:02:48 step 3: objective=0.241743 reg=0.011493
2017/08/30 07:03:03 step 4: objective=0.242323 reg=0.011493
2017/08/30 07:03:18 step 5: objective=0.242788 reg=0.011493
2017/08/30 07:03:34 step 6: objective=0.243239 reg=0.011491
2017/08/30 07:03:49 step 7: objective=0.243632 reg=0.011491
2017/08/30 07:03:49 Training value function...
2017/08/30 07:03:55 step 0: mse=1.155925 step=0.050000
2017/08/30 07:03:58 step 1: mse=1.156004 step=0.050000
2017/08/30 07:04:02 step 2: mse=1.156074 step=0.050000
2017/08/30 07:04:05 step 3: mse=1.156164 step=0.050000
2017/08/30 07:04:09 step 4: mse=1.156266 step=0.050000
2017/08/30 07:04:12 step 5: mse=1.156373 step=0.050000
2017/08/30 07:04:16 step 6: mse=1.156478 step=0.050000
2017/08/30 07:04:19 step 7: mse=1.156509 step=0.050000
2017/08/30 07:04:19 Saving...
2017/08/30 07:04:20 Gathering batch of experience...
2017/08/30 07:04:57 batch 468: mean=5.597364 stddev=1.477093 entropy=1.143778 frames=100140 count=5007
2017/08/30 07:04:57 Training policy...
2017/08/30 07:05:19 step 0: objective=0.262448 reg=0.011438
2017/08/30 07:05:35 step 1: objective=0.263065 reg=0.011438
2017/08/30 07:05:50 step 2: objective=0.263650 reg=0.011437
2017/08/30 07:06:05 step 3: objective=0.264170 reg=0.011437
2017/08/30 07:06:21 step 4: objective=0.264614 reg=0.011436
2017/08/30 07:06:36 step 5: objective=0.265025 reg=0.011434
2017/08/30 07:06:51 step 6: objective=0.265538 reg=0.011436
2017/08/30 07:07:07 step 7: objective=0.265951 reg=0.011434
2017/08/30 07:07:07 Training value function...
2017/08/30 07:07:13 step 0: mse=1.185420 step=0.050000
2017/08/30 07:07:16 step 1: mse=1.184693 step=0.050000
2017/08/30 07:07:20 step 2: mse=1.184017 step=0.050000
2017/08/30 07:07:23 step 3: mse=1.183386 step=0.050000
2017/08/30 07:07:27 step 4: mse=1.182793 step=0.050000
2017/08/30 07:07:30 step 5: mse=1.182236 step=0.050000
2017/08/30 07:07:34 step 6: mse=1.181714 step=0.050000
2017/08/30 07:07:37 step 7: mse=1.181220 step=0.050000
2017/08/30 07:07:37 Saving...
2017/08/30 07:07:37 Gathering batch of experience...
2017/08/30 07:08:15 batch 469: mean=5.565009 stddev=1.442084 entropy=1.145058 frames=100140 count=5007
2017/08/30 07:08:15 Training policy...
2017/08/30 07:08:38 step 0: objective=0.246390 reg=0.011451
2017/08/30 07:08:53 step 1: objective=0.247092 reg=0.011453
2017/08/30 07:09:08 step 2: objective=0.247675 reg=0.011453
2017/08/30 07:09:24 step 3: objective=0.248172 reg=0.011452
2017/08/30 07:09:39 step 4: objective=0.248609 reg=0.011454
2017/08/30 07:09:55 step 5: objective=0.249064 reg=0.011452
2017/08/30 07:10:10 step 6: objective=0.249481 reg=0.011453
2017/08/30 07:10:26 step 7: objective=0.249829 reg=0.011448
2017/08/30 07:10:26 Training value function...
2017/08/30 07:10:32 step 0: mse=1.111874 step=0.050000
2017/08/30 07:10:35 step 1: mse=1.111808 step=0.050000
2017/08/30 07:10:39 step 2: mse=1.111768 step=0.050000
2017/08/30 07:10:42 step 3: mse=1.111781 step=0.050000
2017/08/30 07:10:46 step 4: mse=1.111807 step=0.050000
2017/08/30 07:10:49 step 5: mse=1.111843 step=0.050000
2017/08/30 07:10:53 step 6: mse=1.111884 step=0.050000
2017/08/30 07:10:56 step 7: mse=1.111917 step=0.050000
2017/08/30 07:10:56 Saving...
2017/08/30 07:10:57 Gathering batch of experience...
2017/08/30 07:11:34 batch 470: mean=5.583982 stddev=1.461061 entropy=1.141364 frames=100140 count=5007
2017/08/30 07:11:34 Training policy...
2017/08/30 07:11:57 step 0: objective=0.254189 reg=0.011414
2017/08/30 07:12:13 step 1: objective=0.254910 reg=0.011410
2017/08/30 07:12:28 step 2: objective=0.255550 reg=0.011411
2017/08/30 07:12:44 step 3: objective=0.256116 reg=0.011414
2017/08/30 07:12:59 step 4: objective=0.256679 reg=0.011415
2017/08/30 07:13:15 step 5: objective=0.257077 reg=0.011416
2017/08/30 07:13:30 step 6: objective=0.257583 reg=0.011413
2017/08/30 07:13:45 step 7: objective=0.257998 reg=0.011413
2017/08/30 07:13:45 Training value function...
2017/08/30 07:13:52 step 0: mse=1.146509 step=0.050000
2017/08/30 07:13:55 step 1: mse=1.145940 step=0.050000
2017/08/30 07:13:59 step 2: mse=1.145421 step=0.050000
2017/08/30 07:14:02 step 3: mse=1.144938 step=0.050000
2017/08/30 07:14:06 step 4: mse=1.144506 step=0.050000
2017/08/30 07:14:09 step 5: mse=1.144106 step=0.050000
2017/08/30 07:14:12 step 6: mse=1.143718 step=0.050000
2017/08/30 07:14:16 step 7: mse=1.143359 step=0.050000
2017/08/30 07:14:16 Saving...
2017/08/30 07:14:16 Gathering batch of experience...
2017/08/30 07:14:53 batch 471: mean=5.607549 stddev=1.439259 entropy=1.138002 frames=100140 count=5007
2017/08/30 07:14:53 Training policy...
2017/08/30 07:15:16 step 0: objective=0.256490 reg=0.011380
2017/08/30 07:15:31 step 1: objective=0.257151 reg=0.011376
2017/08/30 07:15:47 step 2: objective=0.257780 reg=0.011374
2017/08/30 07:16:02 step 3: objective=0.258391 reg=0.011373
2017/08/30 07:16:18 step 4: objective=0.258860 reg=0.011369
2017/08/30 07:16:33 step 5: objective=0.259306 reg=0.011368
2017/08/30 07:16:49 step 6: objective=0.259725 reg=0.011370
2017/08/30 07:17:04 step 7: objective=0.260124 reg=0.011371
2017/08/30 07:17:04 Training value function...
2017/08/30 07:17:10 step 0: mse=1.151502 step=0.050000
2017/08/30 07:17:14 step 1: mse=1.151082 step=0.050000
2017/08/30 07:17:17 step 2: mse=1.150701 step=0.050000
2017/08/30 07:17:21 step 3: mse=1.150268 step=0.050000
2017/08/30 07:17:24 step 4: mse=1.149933 step=0.050000
2017/08/30 07:17:28 step 5: mse=1.149608 step=0.050000
2017/08/30 07:17:31 step 6: mse=1.149237 step=0.050000
2017/08/30 07:17:35 step 7: mse=1.148896 step=0.050000
2017/08/30 07:17:35 Saving...
2017/08/30 07:17:35 Gathering batch of experience...
2017/08/30 07:18:12 batch 472: mean=5.558418 stddev=1.480360 entropy=1.139859 frames=100140 count=5007
2017/08/30 07:18:12 Training policy...
2017/08/30 07:18:36 step 0: objective=0.242960 reg=0.011399
2017/08/30 07:18:52 step 1: objective=0.243494 reg=0.011395
2017/08/30 07:19:07 step 2: objective=0.244120 reg=0.011394
2017/08/30 07:19:23 step 3: objective=0.244647 reg=0.011394
2017/08/30 07:19:38 step 4: objective=0.245164 reg=0.011392
2017/08/30 07:19:54 step 5: objective=0.245711 reg=0.011391
2017/08/30 07:20:09 step 6: objective=0.246132 reg=0.011386
2017/08/30 07:20:25 step 7: objective=0.246539 reg=0.011389
2017/08/30 07:20:25 Training value function...
2017/08/30 07:20:31 step 0: mse=1.168028 step=0.050000
2017/08/30 07:20:34 step 1: mse=1.168189 step=0.050000
2017/08/30 07:20:38 step 2: mse=1.168317 step=0.050000
2017/08/30 07:20:41 step 3: mse=1.168467 step=0.050000
2017/08/30 07:20:45 step 4: mse=1.168582 step=0.050000
2017/08/30 07:20:48 step 5: mse=1.168716 step=0.050000
2017/08/30 07:20:52 step 6: mse=1.168854 step=0.050000
2017/08/30 07:20:55 step 7: mse=1.168971 step=0.050000
2017/08/30 07:20:55 Saving...
2017/08/30 07:20:55 Gathering batch of experience...
2017/08/30 07:21:33 batch 473: mean=5.592570 stddev=1.467907 entropy=1.137238 frames=100140 count=5007
2017/08/30 07:21:33 Training policy...
2017/08/30 07:21:56 step 0: objective=0.256914 reg=0.011372
2017/08/30 07:22:12 step 1: objective=0.257412 reg=0.011367
2017/08/30 07:22:27 step 2: objective=0.257768 reg=0.011373
2017/08/30 07:22:43 step 3: objective=0.258253 reg=0.011373
2017/08/30 07:22:58 step 4: objective=0.258834 reg=0.011368
2017/08/30 07:23:14 step 5: objective=0.259308 reg=0.011369
2017/08/30 07:23:30 step 6: objective=0.259838 reg=0.011367
2017/08/30 07:23:45 step 7: objective=0.260190 reg=0.011361
2017/08/30 07:23:45 Training value function...
2017/08/30 07:23:51 step 0: mse=1.179118 step=0.050000
2017/08/30 07:23:55 step 1: mse=1.178848 step=0.050000
2017/08/30 07:23:58 step 2: mse=1.178603 step=0.050000
2017/08/30 07:24:01 step 3: mse=1.178380 step=0.050000
2017/08/30 07:24:05 step 4: mse=1.178170 step=0.050000
2017/08/30 07:24:08 step 5: mse=1.177971 step=0.050000
2017/08/30 07:24:12 step 6: mse=1.177787 step=0.050000
2017/08/30 07:24:15 step 7: mse=1.177613 step=0.050000
2017/08/30 07:24:15 Saving...
2017/08/30 07:24:16 Gathering batch of experience...
2017/08/30 07:24:53 batch 474: mean=5.594767 stddev=1.486829 entropy=1.141926 frames=100140 count=5007
2017/08/30 07:24:53 Training policy...
2017/08/30 07:25:16 step 0: objective=0.258871 reg=0.011419
2017/08/30 07:25:32 step 1: objective=0.259394 reg=0.011418
2017/08/30 07:25:48 step 2: objective=0.260030 reg=0.011420
2017/08/30 07:26:03 step 3: objective=0.260686 reg=0.011419
2017/08/30 07:26:20 step 4: objective=0.261193 reg=0.011420
2017/08/30 07:26:35 step 5: objective=0.261616 reg=0.011419
2017/08/30 07:26:51 step 6: objective=0.262084 reg=0.011419
2017/08/30 07:27:07 step 7: objective=0.262543 reg=0.011417
2017/08/30 07:27:07 Training value function...
2017/08/30 07:27:13 step 0: mse=1.199025 step=0.050000
2017/08/30 07:27:16 step 1: mse=1.198127 step=0.050000
2017/08/30 07:27:20 step 2: mse=1.197296 step=0.050000
2017/08/30 07:27:23 step 3: mse=1.196522 step=0.050000
2017/08/30 07:27:27 step 4: mse=1.195798 step=0.050000
2017/08/30 07:27:30 step 5: mse=1.195097 step=0.050000
2017/08/30 07:27:34 step 6: mse=1.194421 step=0.050000
2017/08/30 07:27:37 step 7: mse=1.193794 step=0.050000
2017/08/30 07:27:37 Saving...
2017/08/30 07:27:37 Gathering batch of experience...
2017/08/30 07:28:15 batch 475: mean=5.541841 stddev=1.485230 entropy=1.138825 frames=100140 count=5007
2017/08/30 07:28:15 Training policy...
2017/08/30 07:28:38 step 0: objective=0.247488 reg=0.011388
2017/08/30 07:28:53 step 1: objective=0.248214 reg=0.011386
2017/08/30 07:29:09 step 2: objective=0.248945 reg=0.011382
2017/08/30 07:29:25 step 3: objective=0.249445 reg=0.011379
2017/08/30 07:29:40 step 4: objective=0.249873 reg=0.011383
2017/08/30 07:29:56 step 5: objective=0.250312 reg=0.011381
2017/08/30 07:30:12 step 6: objective=0.250778 reg=0.011382
2017/08/30 07:30:28 step 7: objective=0.251128 reg=0.011377
2017/08/30 07:30:28 Training value function...
2017/08/30 07:30:34 step 0: mse=1.186060 step=0.050000
2017/08/30 07:30:37 step 1: mse=1.186094 step=0.050000
2017/08/30 07:30:41 step 2: mse=1.186135 step=0.050000
2017/08/30 07:30:44 step 3: mse=1.186178 step=0.050000
2017/08/30 07:30:48 step 4: mse=1.186217 step=0.050000
2017/08/30 07:30:51 step 5: mse=1.186258 step=0.050000
2017/08/30 07:30:54 step 6: mse=1.186299 step=0.050000
2017/08/30 07:30:58 step 7: mse=1.186340 step=0.050000
2017/08/30 07:30:58 Saving...
2017/08/30 07:30:58 Gathering batch of experience...
2017/08/30 07:31:36 batch 476: mean=5.596765 stddev=1.468861 entropy=1.139130 frames=100140 count=5007
2017/08/30 07:31:36 Training policy...
2017/08/30 07:31:59 step 0: objective=0.257453 reg=0.011391
2017/08/30 07:32:15 step 1: objective=0.258185 reg=0.011390
2017/08/30 07:32:31 step 2: objective=0.258756 reg=0.011388
2017/08/30 07:32:46 step 3: objective=0.259291 reg=0.011386
2017/08/30 07:33:02 step 4: objective=0.259873 reg=0.011387
2017/08/30 07:33:18 step 5: objective=0.260329 reg=0.011389
2017/08/30 07:33:34 step 6: objective=0.260770 reg=0.011387
2017/08/30 07:33:49 step 7: objective=0.261202 reg=0.011388
2017/08/30 07:33:49 Training value function...
2017/08/30 07:33:55 step 0: mse=1.213094 step=0.050000
2017/08/30 07:33:59 step 1: mse=1.212790 step=0.050000
2017/08/30 07:34:02 step 2: mse=1.212479 step=0.050000
2017/08/30 07:34:06 step 3: mse=1.212225 step=0.050000
2017/08/30 07:34:09 step 4: mse=1.211993 step=0.050000
2017/08/30 07:34:13 step 5: mse=1.211745 step=0.050000
2017/08/30 07:34:16 step 6: mse=1.211541 step=0.050000
2017/08/30 07:34:20 step 7: mse=1.211335 step=0.050000
2017/08/30 07:34:20 Saving...
2017/08/30 07:34:20 Gathering batch of experience...
2017/08/30 07:34:57 batch 477: mean=5.604354 stddev=1.441297 entropy=1.137601 frames=100140 count=5007
2017/08/30 07:34:57 Training policy...
2017/08/30 07:35:20 step 0: objective=0.251711 reg=0.011376
2017/08/30 07:35:36 step 1: objective=0.252342 reg=0.011377
2017/08/30 07:35:52 step 2: objective=0.253033 reg=0.011378
2017/08/30 07:36:08 step 3: objective=0.253558 reg=0.011375
2017/08/30 07:36:24 step 4: objective=0.254077 reg=0.011374
2017/08/30 07:36:40 step 5: objective=0.254522 reg=0.011370
2017/08/30 07:36:55 step 6: objective=0.254899 reg=0.011367
2017/08/30 07:37:11 step 7: objective=0.255286 reg=0.011366
2017/08/30 07:37:11 Training value function...
2017/08/30 07:37:17 step 0: mse=1.148144 step=0.050000
2017/08/30 07:37:21 step 1: mse=1.147812 step=0.050000
2017/08/30 07:37:24 step 2: mse=1.147509 step=0.050000
2017/08/30 07:37:28 step 3: mse=1.147229 step=0.050000
2017/08/30 07:37:31 step 4: mse=1.146964 step=0.050000
2017/08/30 07:37:35 step 5: mse=1.146715 step=0.050000
2017/08/30 07:37:38 step 6: mse=1.146479 step=0.050000
2017/08/30 07:37:41 step 7: mse=1.146257 step=0.050000
2017/08/30 07:37:41 Saving...
2017/08/30 07:37:42 Gathering batch of experience...
2017/08/30 07:38:19 batch 478: mean=5.578390 stddev=1.473620 entropy=1.138691 frames=100140 count=5007
2017/08/30 07:38:19 Training policy...
2017/08/30 07:38:42 step 0: objective=0.244984 reg=0.011387
2017/08/30 07:38:59 step 1: objective=0.245657 reg=0.011387
2017/08/30 07:39:15 step 2: objective=0.246139 reg=0.011386
2017/08/30 07:39:31 step 3: objective=0.246746 reg=0.011385
2017/08/30 07:39:47 step 4: objective=0.247350 reg=0.011384
2017/08/30 07:40:03 step 5: objective=0.247817 reg=0.011383
2017/08/30 07:40:18 step 6: objective=0.248271 reg=0.011381
2017/08/30 07:40:34 step 7: objective=0.248654 reg=0.011376
2017/08/30 07:40:34 Training value function...
2017/08/30 07:40:40 step 0: mse=1.178119 step=0.050000
2017/08/30 07:40:44 step 1: mse=1.178203 step=0.050000
2017/08/30 07:40:48 step 2: mse=1.178301 step=0.050000
2017/08/30 07:40:51 step 3: mse=1.178393 step=0.050000
2017/08/30 07:40:54 step 4: mse=1.178504 step=0.050000
2017/08/30 07:40:58 step 5: mse=1.178604 step=0.050000
2017/08/30 07:41:01 step 6: mse=1.178693 step=0.050000
2017/08/30 07:41:05 step 7: mse=1.178788 step=0.050000
2017/08/30 07:41:05 Saving...
2017/08/30 07:41:05 Gathering batch of experience...
2017/08/30 07:41:43 batch 479: mean=5.595167 stddev=1.484922 entropy=1.129741 frames=100140 count=5007
2017/08/30 07:41:43 Training policy...
2017/08/30 07:42:06 step 0: objective=0.262623 reg=0.011297
2017/08/30 07:42:22 step 1: objective=0.263134 reg=0.011295
2017/08/30 07:42:38 step 2: objective=0.263722 reg=0.011295
2017/08/30 07:42:54 step 3: objective=0.264422 reg=0.011296
2017/08/30 07:43:10 step 4: objective=0.264885 reg=0.011294
2017/08/30 07:43:26 step 5: objective=0.265396 reg=0.011294
2017/08/30 07:43:42 step 6: objective=0.265824 reg=0.011292
2017/08/30 07:43:58 step 7: objective=0.266303 reg=0.011292
2017/08/30 07:43:58 Training value function...
2017/08/30 07:44:04 step 0: mse=1.195235 step=0.050000
2017/08/30 07:44:07 step 1: mse=1.194181 step=0.050000
2017/08/30 07:44:10 step 2: mse=1.193199 step=0.050000
2017/08/30 07:44:14 step 3: mse=1.192276 step=0.050000
2017/08/30 07:44:17 step 4: mse=1.191406 step=0.050000
2017/08/30 07:44:21 step 5: mse=1.190587 step=0.050000
2017/08/30 07:44:24 step 6: mse=1.189808 step=0.050000
2017/08/30 07:44:28 step 7: mse=1.189082 step=0.050000
2017/08/30 07:44:28 Saving...
2017/08/30 07:44:28 Gathering batch of experience...
2017/08/30 07:45:06 batch 480: mean=5.564410 stddev=1.458087 entropy=1.132941 frames=100140 count=5007
2017/08/30 07:45:06 Training policy...
2017/08/30 07:45:29 step 0: objective=0.237998 reg=0.011329
2017/08/30 07:45:45 step 1: objective=0.238541 reg=0.011330
2017/08/30 07:46:01 step 2: objective=0.239120 reg=0.011331
2017/08/30 07:46:16 step 3: objective=0.239603 reg=0.011328
2017/08/30 07:46:32 step 4: objective=0.240201 reg=0.011327
2017/08/30 07:46:48 step 5: objective=0.240617 reg=0.011333
2017/08/30 07:47:04 step 6: objective=0.241030 reg=0.011329
2017/08/30 07:47:20 step 7: objective=0.241473 reg=0.011327
2017/08/30 07:47:20 Training value function...
2017/08/30 07:47:26 step 0: mse=1.131784 step=0.050000
2017/08/30 07:47:30 step 1: mse=1.132369 step=0.050000
2017/08/30 07:47:33 step 2: mse=1.132935 step=0.050000
2017/08/30 07:47:37 step 3: mse=1.133474 step=0.050000
2017/08/30 07:47:40 step 4: mse=1.133994 step=0.050000
2017/08/30 07:47:44 step 5: mse=1.134487 step=0.050000
2017/08/30 07:47:47 step 6: mse=1.134953 step=0.050000
2017/08/30 07:47:50 step 7: mse=1.135394 step=0.050000
2017/08/30 07:47:50 Saving...
2017/08/30 07:47:51 Gathering batch of experience...
2017/08/30 07:48:28 batch 481: mean=5.556221 stddev=1.444805 entropy=1.133123 frames=100140 count=5007
2017/08/30 07:48:28 Training policy...
2017/08/30 07:48:51 step 0: objective=0.241204 reg=0.011331
2017/08/30 07:49:07 step 1: objective=0.241854 reg=0.011331
2017/08/30 07:49:23 step 2: objective=0.242462 reg=0.011337
2017/08/30 07:49:39 step 3: objective=0.242988 reg=0.011334
2017/08/30 07:49:55 step 4: objective=0.243504 reg=0.011335
2017/08/30 07:50:11 step 5: objective=0.243970 reg=0.011336
2017/08/30 07:50:27 step 6: objective=0.244389 reg=0.011333
2017/08/30 07:50:43 step 7: objective=0.244783 reg=0.011333
2017/08/30 07:50:43 Training value function...
2017/08/30 07:50:49 step 0: mse=1.102401 step=0.050000
2017/08/30 07:50:53 step 1: mse=1.102570 step=0.050000
2017/08/30 07:50:56 step 2: mse=1.102739 step=0.050000
2017/08/30 07:51:00 step 3: mse=1.102906 step=0.050000
2017/08/30 07:51:03 step 4: mse=1.103072 step=0.050000
2017/08/30 07:51:07 step 5: mse=1.103230 step=0.050000
2017/08/30 07:51:10 step 6: mse=1.103381 step=0.050000
2017/08/30 07:51:14 step 7: mse=1.103521 step=0.050000
2017/08/30 07:51:14 Saving...
2017/08/30 07:51:14 Gathering batch of experience...
2017/08/30 07:51:52 batch 482: mean=5.585380 stddev=1.461253 entropy=1.128187 frames=100140 count=5007
2017/08/30 07:51:52 Training policy...
2017/08/30 07:52:16 step 0: objective=0.257790 reg=0.011282
2017/08/30 07:52:32 step 1: objective=0.258232 reg=0.011282
2017/08/30 07:52:48 step 2: objective=0.258728 reg=0.011284
2017/08/30 07:53:04 step 3: objective=0.259244 reg=0.011283
2017/08/30 07:53:20 step 4: objective=0.259787 reg=0.011284
2017/08/30 07:53:36 step 5: objective=0.260197 reg=0.011279
2017/08/30 07:53:52 step 6: objective=0.260670 reg=0.011275
2017/08/30 07:54:08 step 7: objective=0.261127 reg=0.011276
2017/08/30 07:54:08 Training value function...
2017/08/30 07:54:14 step 0: mse=1.133023 step=0.050000
2017/08/30 07:54:18 step 1: mse=1.132418 step=0.050000
2017/08/30 07:54:21 step 2: mse=1.131846 step=0.050000
2017/08/30 07:54:25 step 3: mse=1.131307 step=0.050000
2017/08/30 07:54:28 step 4: mse=1.130804 step=0.050000
2017/08/30 07:54:31 step 5: mse=1.130272 step=0.050000
2017/08/30 07:54:35 step 6: mse=1.129775 step=0.050000
2017/08/30 07:54:38 step 7: mse=1.129294 step=0.050000
2017/08/30 07:54:38 Saving...
2017/08/30 07:54:39 Gathering batch of experience...
2017/08/30 07:55:16 batch 483: mean=5.598762 stddev=1.466142 entropy=1.130386 frames=100140 count=5007
2017/08/30 07:55:16 Training policy...
2017/08/30 07:55:40 step 0: objective=0.249345 reg=0.011304
2017/08/30 07:55:56 step 1: objective=0.249996 reg=0.011302
2017/08/30 07:56:12 step 2: objective=0.250522 reg=0.011297
2017/08/30 07:56:28 step 3: objective=0.250958 reg=0.011301
2017/08/30 07:56:44 step 4: objective=0.251434 reg=0.011303
2017/08/30 07:57:00 step 5: objective=0.251836 reg=0.011304
2017/08/30 07:57:16 step 6: objective=0.252378 reg=0.011305
2017/08/30 07:57:32 step 7: objective=0.252773 reg=0.011305
2017/08/30 07:57:32 Training value function...
2017/08/30 07:57:38 step 0: mse=1.161743 step=0.050000
2017/08/30 07:57:42 step 1: mse=1.161643 step=0.050000
2017/08/30 07:57:45 step 2: mse=1.161558 step=0.050000
2017/08/30 07:57:49 step 3: mse=1.161491 step=0.050000
2017/08/30 07:57:52 step 4: mse=1.161423 step=0.050000
2017/08/30 07:57:55 step 5: mse=1.161361 step=0.050000
2017/08/30 07:57:59 step 6: mse=1.161248 step=0.050000
2017/08/30 07:58:02 step 7: mse=1.161128 step=0.050000
2017/08/30 07:58:02 Saving...
2017/08/30 07:58:03 Gathering batch of experience...
2017/08/30 07:58:40 batch 484: mean=5.599960 stddev=1.474212 entropy=1.132464 frames=100140 count=5007
2017/08/30 07:58:40 Training policy...
2017/08/30 07:59:03 step 0: objective=0.255167 reg=0.011325
2017/08/30 07:59:20 step 1: objective=0.255784 reg=0.011323
2017/08/30 07:59:36 step 2: objective=0.256363 reg=0.011326
2017/08/30 07:59:52 step 3: objective=0.256921 reg=0.011325
2017/08/30 08:00:08 step 4: objective=0.257441 reg=0.011326
2017/08/30 08:00:24 step 5: objective=0.257958 reg=0.011327
2017/08/30 08:00:40 step 6: objective=0.258368 reg=0.011328
2017/08/30 08:00:56 step 7: objective=0.258862 reg=0.011326
2017/08/30 08:00:56 Training value function...
2017/08/30 08:01:02 step 0: mse=1.219529 step=0.050000
2017/08/30 08:01:06 step 1: mse=1.219281 step=0.050000
2017/08/30 08:01:09 step 2: mse=1.219060 step=0.050000
2017/08/30 08:01:13 step 3: mse=1.218880 step=0.050000
2017/08/30 08:01:16 step 4: mse=1.218718 step=0.050000
2017/08/30 08:01:20 step 5: mse=1.218570 step=0.050000
2017/08/30 08:01:23 step 6: mse=1.218411 step=0.050000
2017/08/30 08:01:27 step 7: mse=1.218264 step=0.050000
2017/08/30 08:01:27 Saving...
2017/08/30 08:01:27 Gathering batch of experience...
2017/08/30 08:02:05 batch 485: mean=5.559816 stddev=1.478819 entropy=1.135314 frames=100140 count=5007
2017/08/30 08:02:05 Training policy...
2017/08/30 08:02:29 step 0: objective=0.245694 reg=0.011353
2017/08/30 08:02:45 step 1: objective=0.246231 reg=0.011358
2017/08/30 08:03:01 step 2: objective=0.246843 reg=0.011356
2017/08/30 08:03:17 step 3: objective=0.247312 reg=0.011348
2017/08/30 08:03:34 step 4: objective=0.247909 reg=0.011349
2017/08/30 08:03:50 step 5: objective=0.248307 reg=0.011347
2017/08/30 08:04:06 step 6: objective=0.248736 reg=0.011345
2017/08/30 08:04:22 step 7: objective=0.249176 reg=0.011345
2017/08/30 08:04:22 Training value function...
2017/08/30 08:04:28 step 0: mse=1.145954 step=0.050000
2017/08/30 08:04:31 step 1: mse=1.145864 step=0.050000
2017/08/30 08:04:35 step 2: mse=1.145786 step=0.050000
2017/08/30 08:04:38 step 3: mse=1.145687 step=0.050000
2017/08/30 08:04:42 step 4: mse=1.145626 step=0.050000
2017/08/30 08:04:45 step 5: mse=1.145566 step=0.050000
2017/08/30 08:04:49 step 6: mse=1.145482 step=0.050000
2017/08/30 08:04:52 step 7: mse=1.145431 step=0.050000
2017/08/30 08:04:52 Saving...
2017/08/30 08:04:52 Gathering batch of experience...
2017/08/30 08:05:30 batch 486: mean=5.592770 stddev=1.464762 entropy=1.131728 frames=100140 count=5007
2017/08/30 08:05:30 Training policy...
2017/08/30 08:05:53 step 0: objective=0.257074 reg=0.011317
2017/08/30 08:06:10 step 1: objective=0.257646 reg=0.011315
2017/08/30 08:06:27 step 2: objective=0.258079 reg=0.011316
2017/08/30 08:06:43 step 3: objective=0.258718 reg=0.011315
2017/08/30 08:06:59 step 4: objective=0.259185 reg=0.011307
2017/08/30 08:07:15 step 5: objective=0.259601 reg=0.011311
2017/08/30 08:07:31 step 6: objective=0.260064 reg=0.011308
2017/08/30 08:07:48 step 7: objective=0.260458 reg=0.011303
2017/08/30 08:07:48 Training value function...
2017/08/30 08:07:54 step 0: mse=1.180512 step=0.050000
2017/08/30 08:07:57 step 1: mse=1.179812 step=0.050000
2017/08/30 08:08:01 step 2: mse=1.179247 step=0.050000
2017/08/30 08:08:04 step 3: mse=1.178634 step=0.050000
2017/08/30 08:08:08 step 4: mse=1.178138 step=0.050000
2017/08/30 08:08:11 step 5: mse=1.177594 step=0.050000
2017/08/30 08:08:14 step 6: mse=1.177156 step=0.050000
2017/08/30 08:08:18 step 7: mse=1.176728 step=0.050000
2017/08/30 08:08:18 Saving...
2017/08/30 08:08:18 Gathering batch of experience...
2017/08/30 08:08:56 batch 487: mean=5.609147 stddev=1.466904 entropy=1.129462 frames=100140 count=5007
2017/08/30 08:08:56 Training policy...
2017/08/30 08:09:19 step 0: objective=0.256965 reg=0.011295
2017/08/30 08:09:36 step 1: objective=0.257617 reg=0.011291
2017/08/30 08:09:52 step 2: objective=0.258204 reg=0.011289
2017/08/30 08:10:08 step 3: objective=0.258719 reg=0.011286
2017/08/30 08:10:25 step 4: objective=0.259302 reg=0.011293
2017/08/30 08:10:41 step 5: objective=0.259654 reg=0.011291
2017/08/30 08:10:57 step 6: objective=0.260045 reg=0.011286
2017/08/30 08:11:13 step 7: objective=0.260445 reg=0.011285
2017/08/30 08:11:13 Training value function...
2017/08/30 08:11:19 step 0: mse=1.170679 step=0.050000
2017/08/30 08:11:23 step 1: mse=1.169799 step=0.050000
2017/08/30 08:11:26 step 2: mse=1.168989 step=0.050000
2017/08/30 08:11:30 step 3: mse=1.168236 step=0.050000
2017/08/30 08:11:33 step 4: mse=1.167515 step=0.050000
2017/08/30 08:11:37 step 5: mse=1.166849 step=0.050000
2017/08/30 08:11:40 step 6: mse=1.166224 step=0.050000
2017/08/30 08:11:44 step 7: mse=1.165610 step=0.050000
2017/08/30 08:11:44 Saving...
2017/08/30 08:11:44 Gathering batch of experience...
2017/08/30 08:12:22 batch 488: mean=5.617935 stddev=1.489200 entropy=1.125359 frames=100140 count=5007
2017/08/30 08:12:22 Training policy...
2017/08/30 08:12:45 step 0: objective=0.261166 reg=0.011254
2017/08/30 08:13:02 step 1: objective=0.261794 reg=0.011254
2017/08/30 08:13:18 step 2: objective=0.262414 reg=0.011254
2017/08/30 08:13:34 step 3: objective=0.262854 reg=0.011258
2017/08/30 08:13:50 step 4: objective=0.263200 reg=0.011250
2017/08/30 08:14:07 step 5: objective=0.263595 reg=0.011253
2017/08/30 08:14:23 step 6: objective=0.263879 reg=0.011243
2017/08/30 08:14:39 step 7: objective=0.264356 reg=0.011243
2017/08/30 08:14:39 Training value function...
2017/08/30 08:14:45 step 0: mse=1.207567 step=0.050000
2017/08/30 08:14:49 step 1: mse=1.206971 step=0.050000
2017/08/30 08:14:52 step 2: mse=1.206412 step=0.050000
2017/08/30 08:14:56 step 3: mse=1.205888 step=0.050000
2017/08/30 08:14:59 step 4: mse=1.205397 step=0.050000
2017/08/30 08:15:03 step 5: mse=1.204936 step=0.050000
2017/08/30 08:15:06 step 6: mse=1.204499 step=0.050000
2017/08/30 08:15:10 step 7: mse=1.204085 step=0.050000
2017/08/30 08:15:10 Saving...
2017/08/30 08:15:10 Gathering batch of experience...
2017/08/30 08:15:48 batch 489: mean=5.612942 stddev=1.478417 entropy=1.124002 frames=100140 count=5007
2017/08/30 08:15:48 Training policy...
2017/08/30 08:16:12 step 0: objective=0.264027 reg=0.011240
2017/08/30 08:16:28 step 1: objective=0.264663 reg=0.011239
2017/08/30 08:16:45 step 2: objective=0.265273 reg=0.011237
2017/08/30 08:17:01 step 3: objective=0.265888 reg=0.011240
2017/08/30 08:17:17 step 4: objective=0.266321 reg=0.011237
2017/08/30 08:17:34 step 5: objective=0.266801 reg=0.011235
2017/08/30 08:17:50 step 6: objective=0.267204 reg=0.011232
2017/08/30 08:18:07 step 7: objective=0.267603 reg=0.011233
2017/08/30 08:18:07 Training value function...
2017/08/30 08:18:13 step 0: mse=1.180326 step=0.050000
2017/08/30 08:18:16 step 1: mse=1.179281 step=0.050000
2017/08/30 08:18:20 step 2: mse=1.178320 step=0.050000
2017/08/30 08:18:23 step 3: mse=1.177418 step=0.050000
2017/08/30 08:18:27 step 4: mse=1.176595 step=0.050000
2017/08/30 08:18:30 step 5: mse=1.175817 step=0.050000
2017/08/30 08:18:33 step 6: mse=1.175136 step=0.050000
2017/08/30 08:18:37 step 7: mse=1.174438 step=0.050000
2017/08/30 08:18:37 Saving...
2017/08/30 08:18:37 Gathering batch of experience...
2017/08/30 08:19:15 batch 490: mean=5.575594 stddev=1.459878 entropy=1.124019 frames=100140 count=5007
2017/08/30 08:19:15 Training policy...
2017/08/30 08:19:39 step 0: objective=0.238839 reg=0.011240
2017/08/30 08:19:56 step 1: objective=0.239484 reg=0.011238
2017/08/30 08:20:12 step 2: objective=0.240151 reg=0.011234
2017/08/30 08:20:28 step 3: objective=0.240668 reg=0.011235
2017/08/30 08:20:45 step 4: objective=0.241122 reg=0.011229
2017/08/30 08:21:01 step 5: objective=0.241551 reg=0.011229
2017/08/30 08:21:18 step 6: objective=0.241936 reg=0.011226
2017/08/30 08:21:34 step 7: objective=0.242318 reg=0.011225
2017/08/30 08:21:34 Training value function...
2017/08/30 08:21:40 step 0: mse=1.144656 step=0.050000
2017/08/30 08:21:44 step 1: mse=1.145170 step=0.050000
2017/08/30 08:21:47 step 2: mse=1.145657 step=0.050000
2017/08/30 08:21:51 step 3: mse=1.146130 step=0.050000
2017/08/30 08:21:54 step 4: mse=1.146577 step=0.050000
2017/08/30 08:21:58 step 5: mse=1.146999 step=0.050000
2017/08/30 08:22:01 step 6: mse=1.147399 step=0.050000
2017/08/30 08:22:05 step 7: mse=1.147768 step=0.050000
2017/08/30 08:22:05 Saving...
2017/08/30 08:22:05 Gathering batch of experience...
2017/08/30 08:22:43 batch 491: mean=5.601957 stddev=1.443268 entropy=1.124304 frames=100140 count=5007
2017/08/30 08:22:43 Training policy...
2017/08/30 08:23:06 step 0: objective=0.249181 reg=0.011243
2017/08/30 08:23:23 step 1: objective=0.249773 reg=0.011241
2017/08/30 08:23:39 step 2: objective=0.250221 reg=0.011242
2017/08/30 08:23:56 step 3: objective=0.250714 reg=0.011242
2017/08/30 08:24:12 step 4: objective=0.251164 reg=0.011244
2017/08/30 08:24:29 step 5: objective=0.251636 reg=0.011242
2017/08/30 08:24:45 step 6: objective=0.252063 reg=0.011239
2017/08/30 08:25:02 step 7: objective=0.252423 reg=0.011233
2017/08/30 08:25:02 Training value function...
2017/08/30 08:25:08 step 0: mse=1.144942 step=0.050000
2017/08/30 08:25:11 step 1: mse=1.144998 step=0.050000
2017/08/30 08:25:15 step 2: mse=1.145061 step=0.050000
2017/08/30 08:25:18 step 3: mse=1.145126 step=0.050000
2017/08/30 08:25:22 step 4: mse=1.145197 step=0.050000
2017/08/30 08:25:25 step 5: mse=1.145267 step=0.050000
2017/08/30 08:25:29 step 6: mse=1.145331 step=0.050000
2017/08/30 08:25:32 step 7: mse=1.145394 step=0.050000
2017/08/30 08:25:32 Saving...
2017/08/30 08:25:32 Gathering batch of experience...
2017/08/30 08:26:10 batch 492: mean=5.577591 stddev=1.476370 entropy=1.125923 frames=100140 count=5007
2017/08/30 08:26:10 Training policy...
2017/08/30 08:26:34 step 0: objective=0.251350 reg=0.011259
2017/08/30 08:26:50 step 1: objective=0.252071 reg=0.011260
2017/08/30 08:27:07 step 2: objective=0.252722 reg=0.011261
2017/08/30 08:27:24 step 3: objective=0.253163 reg=0.011263
2017/08/30 08:27:41 step 4: objective=0.253600 reg=0.011266
2017/08/30 08:27:57 step 5: objective=0.253916 reg=0.011258
2017/08/30 08:28:14 step 6: objective=0.254368 reg=0.011257
2017/08/30 08:28:31 step 7: objective=0.254697 reg=0.011255
2017/08/30 08:28:31 Training value function...
2017/08/30 08:28:37 step 0: mse=1.133949 step=0.050000
2017/08/30 08:28:40 step 1: mse=1.133503 step=0.050000
2017/08/30 08:28:44 step 2: mse=1.133098 step=0.050000
2017/08/30 08:28:47 step 3: mse=1.132726 step=0.050000
2017/08/30 08:28:51 step 4: mse=1.132364 step=0.050000
2017/08/30 08:28:54 step 5: mse=1.132039 step=0.050000
2017/08/30 08:28:58 step 6: mse=1.131725 step=0.050000
2017/08/30 08:29:01 step 7: mse=1.131444 step=0.050000
2017/08/30 08:29:01 Saving...
2017/08/30 08:29:02 Gathering batch of experience...
2017/08/30 08:29:40 batch 493: mean=5.534252 stddev=1.471103 entropy=1.126956 frames=100140 count=5007
2017/08/30 08:29:40 Training policy...
2017/08/30 08:30:04 step 0: objective=0.238662 reg=0.011270
2017/08/30 08:30:20 step 1: objective=0.239229 reg=0.011266
2017/08/30 08:30:37 step 2: objective=0.239741 reg=0.011266
2017/08/30 08:30:53 step 3: objective=0.240198 reg=0.011266
2017/08/30 08:31:10 step 4: objective=0.240646 reg=0.011264
2017/08/30 08:31:27 step 5: objective=0.241138 reg=0.011263
2017/08/30 08:31:44 step 6: objective=0.241527 reg=0.011261
2017/08/30 08:32:00 step 7: objective=0.241902 reg=0.011263
2017/08/30 08:32:00 Training value function...
2017/08/30 08:32:06 step 0: mse=1.110210 step=0.050000
2017/08/30 08:32:10 step 1: mse=1.110583 step=0.050000
2017/08/30 08:32:13 step 2: mse=1.110956 step=0.050000
2017/08/30 08:32:17 step 3: mse=1.111330 step=0.050000
2017/08/30 08:32:20 step 4: mse=1.111691 step=0.050000
2017/08/30 08:32:23 step 5: mse=1.112035 step=0.050000
2017/08/30 08:32:27 step 6: mse=1.112359 step=0.050000
2017/08/30 08:32:30 step 7: mse=1.112665 step=0.050000
2017/08/30 08:32:30 Saving...
2017/08/30 08:32:31 Gathering batch of experience...
2017/08/30 08:33:09 batch 494: mean=5.620531 stddev=1.468735 entropy=1.119270 frames=100140 count=5007
2017/08/30 08:33:09 Training policy...
2017/08/30 08:33:34 step 0: objective=0.256730 reg=0.011193
2017/08/30 08:33:50 step 1: objective=0.257278 reg=0.011193
2017/08/30 08:34:07 step 2: objective=0.257732 reg=0.011197
2017/08/30 08:34:24 step 3: objective=0.258225 reg=0.011190
2017/08/30 08:34:40 step 4: objective=0.258818 reg=0.011189
2017/08/30 08:34:57 step 5: objective=0.259255 reg=0.011184
2017/08/30 08:35:14 step 6: objective=0.259647 reg=0.011187
2017/08/30 08:35:30 step 7: objective=0.260076 reg=0.011187
2017/08/30 08:35:30 Training value function...
2017/08/30 08:35:36 step 0: mse=1.141300 step=0.050000
2017/08/30 08:35:40 step 1: mse=1.140412 step=0.050000
2017/08/30 08:35:43 step 2: mse=1.139572 step=0.050000
2017/08/30 08:35:47 step 3: mse=1.138812 step=0.050000
2017/08/30 08:35:50 step 4: mse=1.138086 step=0.050000
2017/08/30 08:35:54 step 5: mse=1.137431 step=0.050000
2017/08/30 08:35:57 step 6: mse=1.136826 step=0.050000
2017/08/30 08:36:01 step 7: mse=1.136231 step=0.050000
2017/08/30 08:36:01 Saving...
2017/08/30 08:36:01 Gathering batch of experience...
2017/08/30 08:36:39 batch 495: mean=5.596365 stddev=1.460296 entropy=1.118777 frames=100140 count=5007
2017/08/30 08:36:39 Training policy...
2017/08/30 08:37:04 step 0: objective=0.259315 reg=0.011188
2017/08/30 08:37:20 step 1: objective=0.259842 reg=0.011188
2017/08/30 08:37:37 step 2: objective=0.260276 reg=0.011191
2017/08/30 08:37:54 step 3: objective=0.260815 reg=0.011188
2017/08/30 08:38:10 step 4: objective=0.261247 reg=0.011185
2017/08/30 08:38:27 step 5: objective=0.261845 reg=0.011184
2017/08/30 08:38:44 step 6: objective=0.262265 reg=0.011181
2017/08/30 08:39:01 step 7: objective=0.262689 reg=0.011177
2017/08/30 08:39:01 Training value function...
2017/08/30 08:39:07 step 0: mse=1.198278 step=0.050000
2017/08/30 08:39:10 step 1: mse=1.197607 step=0.050000
2017/08/30 08:39:14 step 2: mse=1.196969 step=0.050000
2017/08/30 08:39:17 step 3: mse=1.196344 step=0.050000
2017/08/30 08:39:21 step 4: mse=1.195768 step=0.050000
2017/08/30 08:39:24 step 5: mse=1.195211 step=0.050000
2017/08/30 08:39:28 step 6: mse=1.194689 step=0.050000
2017/08/30 08:39:31 step 7: mse=1.194203 step=0.050000
2017/08/30 08:39:31 Saving...
2017/08/30 08:39:32 Gathering batch of experience...
2017/08/30 08:40:10 batch 496: mean=5.592371 stddev=1.481463 entropy=1.121045 frames=100140 count=5007
2017/08/30 08:40:10 Training policy...
2017/08/30 08:40:34 step 0: objective=0.244487 reg=0.011210
2017/08/30 08:40:51 step 1: objective=0.245132 reg=0.011208
2017/08/30 08:41:07 step 2: objective=0.245748 reg=0.011207
2017/08/30 08:41:24 step 3: objective=0.246183 reg=0.011207
2017/08/30 08:41:41 step 4: objective=0.246690 reg=0.011206
2017/08/30 08:41:58 step 5: objective=0.247194 reg=0.011206
2017/08/30 08:42:15 step 6: objective=0.247687 reg=0.011206
2017/08/30 08:42:32 step 7: objective=0.248087 reg=0.011204
2017/08/30 08:42:32 Training value function...
2017/08/30 08:42:38 step 0: mse=1.163760 step=0.050000
2017/08/30 08:42:41 step 1: mse=1.163990 step=0.050000
2017/08/30 08:42:45 step 2: mse=1.164222 step=0.050000
2017/08/30 08:42:48 step 3: mse=1.164420 step=0.050000
2017/08/30 08:42:52 step 4: mse=1.164615 step=0.050000
2017/08/30 08:42:55 step 5: mse=1.164774 step=0.050000
2017/08/30 08:42:59 step 6: mse=1.164932 step=0.050000
2017/08/30 08:43:02 step 7: mse=1.165060 step=0.050000
2017/08/30 08:43:02 Saving...
2017/08/30 08:43:02 Gathering batch of experience...
2017/08/30 08:43:40 batch 497: mean=5.586579 stddev=1.471398 entropy=1.119510 frames=100140 count=5007
2017/08/30 08:43:40 Training policy...
2017/08/30 08:44:04 step 0: objective=0.253644 reg=0.011195
2017/08/30 08:44:21 step 1: objective=0.254239 reg=0.011194
2017/08/30 08:44:38 step 2: objective=0.254823 reg=0.011200
2017/08/30 08:44:55 step 3: objective=0.255430 reg=0.011202
2017/08/30 08:45:12 step 4: objective=0.255928 reg=0.011204
2017/08/30 08:45:29 step 5: objective=0.256411 reg=0.011198
2017/08/30 08:45:46 step 6: objective=0.256839 reg=0.011200
2017/08/30 08:46:03 step 7: objective=0.257226 reg=0.011203
2017/08/30 08:46:03 Training value function...
2017/08/30 08:46:09 step 0: mse=1.159009 step=0.050000
2017/08/30 08:46:12 step 1: mse=1.158413 step=0.050000
2017/08/30 08:46:16 step 2: mse=1.157865 step=0.050000
2017/08/30 08:46:19 step 3: mse=1.157332 step=0.050000
2017/08/30 08:46:23 step 4: mse=1.156855 step=0.050000
2017/08/30 08:46:26 step 5: mse=1.156384 step=0.050000
2017/08/30 08:46:30 step 6: mse=1.155964 step=0.050000
2017/08/30 08:46:33 step 7: mse=1.155549 step=0.050000
2017/08/30 08:46:33 Saving...
2017/08/30 08:46:33 Gathering batch of experience...
2017/08/30 08:47:11 batch 498: mean=5.646894 stddev=1.462104 entropy=1.114810 frames=100140 count=5007
2017/08/30 08:47:11 Training policy...
2017/08/30 08:47:36 step 0: objective=0.270650 reg=0.011148
2017/08/30 08:47:53 step 1: objective=0.271169 reg=0.011148
2017/08/30 08:48:10 step 2: objective=0.271833 reg=0.011147
2017/08/30 08:48:27 step 3: objective=0.272383 reg=0.011147
2017/08/30 08:48:44 step 4: objective=0.272862 reg=0.011147
2017/08/30 08:49:01 step 5: objective=0.273372 reg=0.011149
2017/08/30 08:49:18 step 6: objective=0.273820 reg=0.011145
2017/08/30 08:49:35 step 7: objective=0.274240 reg=0.011142
2017/08/30 08:49:35 Training value function...
2017/08/30 08:49:41 step 0: mse=1.194990 step=0.050000
2017/08/30 08:49:44 step 1: mse=1.193669 step=0.050000
2017/08/30 08:49:48 step 2: mse=1.192436 step=0.050000
2017/08/30 08:49:51 step 3: mse=1.191287 step=0.050000
2017/08/30 08:49:55 step 4: mse=1.190211 step=0.050000
2017/08/30 08:49:58 step 5: mse=1.189205 step=0.050000
2017/08/30 08:50:02 step 6: mse=1.188234 step=0.050000
2017/08/30 08:50:05 step 7: mse=1.187323 step=0.050000
2017/08/30 08:50:05 Saving...
2017/08/30 08:50:05 Gathering batch of experience...
2017/08/30 08:50:43 batch 499: mean=5.613541 stddev=1.468068 entropy=1.117584 frames=100140 count=5007
2017/08/30 08:50:43 Training policy...
2017/08/30 08:51:08 step 0: objective=0.258362 reg=0.011176
2017/08/30 08:51:25 step 1: objective=0.258987 reg=0.011174
2017/08/30 08:51:42 step 2: objective=0.259598 reg=0.011176
2017/08/30 08:51:59 step 3: objective=0.260137 reg=0.011177
2017/08/30 08:52:16 step 4: objective=0.260755 reg=0.011180
2017/08/30 08:52:33 step 5: objective=0.261174 reg=0.011177
2017/08/30 08:52:50 step 6: objective=0.261633 reg=0.011174
2017/08/30 08:53:07 step 7: objective=0.262079 reg=0.011172
2017/08/30 08:53:07 Training value function...
2017/08/30 08:53:13 step 0: mse=1.215442 step=0.050000
2017/08/30 08:53:16 step 1: mse=1.215227 step=0.050000
2017/08/30 08:53:20 step 2: mse=1.214986 step=0.050000
2017/08/30 08:53:23 step 3: mse=1.214818 step=0.050000
2017/08/30 08:53:27 step 4: mse=1.214627 step=0.050000
2017/08/30 08:53:30 step 5: mse=1.214498 step=0.050000
2017/08/30 08:53:34 step 6: mse=1.214372 step=0.050000
2017/08/30 08:53:37 step 7: mse=1.214274 step=0.050000
2017/08/30 08:53:37 Saving...
2017/08/30 08:53:37 Gathering batch of experience...
2017/08/30 08:54:16 batch 500: mean=5.592171 stddev=1.475532 entropy=1.120425 frames=100140 count=5007
2017/08/30 08:54:16 Training policy...
2017/08/30 08:54:40 step 0: objective=0.243741 reg=0.011204
2017/08/30 08:54:57 step 1: objective=0.244317 reg=0.011207
2017/08/30 08:55:14 step 2: objective=0.244947 reg=0.011206
2017/08/30 08:55:31 step 3: objective=0.245516 reg=0.011202
2017/08/30 08:55:48 step 4: objective=0.246055 reg=0.011200
2017/08/30 08:56:05 step 5: objective=0.246452 reg=0.011200
2017/08/30 08:56:22 step 6: objective=0.246877 reg=0.011200
2017/08/30 08:56:40 step 7: objective=0.247240 reg=0.011200
2017/08/30 08:56:40 Training value function...
2017/08/30 08:56:46 step 0: mse=1.164058 step=0.050000
2017/08/30 08:56:49 step 1: mse=1.164085 step=0.050000
2017/08/30 08:56:52 step 2: mse=1.164088 step=0.050000
2017/08/30 08:56:56 step 3: mse=1.164124 step=0.050000
2017/08/30 08:56:59 step 4: mse=1.164129 step=0.050000
2017/08/30 08:57:03 step 5: mse=1.164149 step=0.050000
2017/08/30 08:57:06 step 6: mse=1.164156 step=0.050000
2017/08/30 08:57:10 step 7: mse=1.164176 step=0.050000
2017/08/30 08:57:10 Saving...
2017/08/30 08:57:10 Gathering batch of experience...
2017/08/30 08:57:48 batch 501: mean=5.603954 stddev=1.485543 entropy=1.118351 frames=100140 count=5007
2017/08/30 08:57:48 Training policy...
2017/08/30 08:58:12 step 0: objective=0.265680 reg=0.011183
2017/08/30 08:58:29 step 1: objective=0.266344 reg=0.011186
2017/08/30 08:58:46 step 2: objective=0.266997 reg=0.011184
2017/08/30 08:59:03 step 3: objective=0.267463 reg=0.011182
2017/08/30 08:59:21 step 4: objective=0.267971 reg=0.011184
2017/08/30 08:59:37 step 5: objective=0.268448 reg=0.011185
2017/08/30 08:59:54 step 6: objective=0.268789 reg=0.011185
2017/08/30 09:00:12 step 7: objective=0.269147 reg=0.011178
2017/08/30 09:00:12 Training value function...
2017/08/30 09:00:18 step 0: mse=1.209032 step=0.050000
2017/08/30 09:00:21 step 1: mse=1.207929 step=0.050000
2017/08/30 09:00:25 step 2: mse=1.206906 step=0.050000
2017/08/30 09:00:28 step 3: mse=1.205950 step=0.050000
2017/08/30 09:00:31 step 4: mse=1.205016 step=0.050000
2017/08/30 09:00:35 step 5: mse=1.204147 step=0.050000
2017/08/30 09:00:38 step 6: mse=1.203335 step=0.050000
2017/08/30 09:00:42 step 7: mse=1.202577 step=0.050000
2017/08/30 09:00:42 Saving...
2017/08/30 09:00:42 Gathering batch of experience...
2017/08/30 09:01:20 batch 502: mean=5.616936 stddev=1.500368 entropy=1.115150 frames=100140 count=5007
2017/08/30 09:01:20 Training policy...
2017/08/30 09:01:45 step 0: objective=0.257624 reg=0.011152
2017/08/30 09:02:02 step 1: objective=0.258237 reg=0.011152
2017/08/30 09:02:19 step 2: objective=0.258808 reg=0.011156
2017/08/30 09:02:36 step 3: objective=0.259492 reg=0.011152
2017/08/30 09:02:53 step 4: objective=0.260030 reg=0.011152
2017/08/30 09:03:10 step 5: objective=0.260434 reg=0.011145
2017/08/30 09:03:27 step 6: objective=0.260728 reg=0.011151
2017/08/30 09:03:45 step 7: objective=0.261233 reg=0.011152
2017/08/30 09:03:45 Training value function...
2017/08/30 09:03:51 step 0: mse=1.220937 step=0.050000
2017/08/30 09:03:54 step 1: mse=1.220585 step=0.050000
2017/08/30 09:03:57 step 2: mse=1.220273 step=0.050000
2017/08/30 09:04:01 step 3: mse=1.219993 step=0.050000
2017/08/30 09:04:04 step 4: mse=1.219729 step=0.050000
2017/08/30 09:04:08 step 5: mse=1.219487 step=0.050000
2017/08/30 09:04:11 step 6: mse=1.219267 step=0.050000
2017/08/30 09:04:15 step 7: mse=1.219064 step=0.050000
2017/08/30 09:04:15 Saving...
2017/08/30 09:04:15 Gathering batch of experience...
2017/08/30 09:04:53 batch 503: mean=5.634112 stddev=1.466332 entropy=1.114649 frames=100140 count=5007
2017/08/30 09:04:53 Training policy...
2017/08/30 09:05:18 step 0: objective=0.249563 reg=0.011147
2017/08/30 09:05:35 step 1: objective=0.250253 reg=0.011146
2017/08/30 09:05:52 step 2: objective=0.250718 reg=0.011141
2017/08/30 09:06:09 step 3: objective=0.251335 reg=0.011144
2017/08/30 09:06:26 step 4: objective=0.251873 reg=0.011146
2017/08/30 09:06:44 step 5: objective=0.252376 reg=0.011146
2017/08/30 09:07:01 step 6: objective=0.252766 reg=0.011145
2017/08/30 09:07:18 step 7: objective=0.253318 reg=0.011146
2017/08/30 09:07:18 Training value function...
2017/08/30 09:07:24 step 0: mse=1.162756 step=0.050000
2017/08/30 09:07:28 step 1: mse=1.162648 step=0.050000
2017/08/30 09:07:31 step 2: mse=1.162554 step=0.050000
2017/08/30 09:07:34 step 3: mse=1.162471 step=0.050000
2017/08/30 09:07:38 step 4: mse=1.162406 step=0.050000
2017/08/30 09:07:41 step 5: mse=1.162346 step=0.050000
2017/08/30 09:07:45 step 6: mse=1.162279 step=0.050000
2017/08/30 09:07:48 step 7: mse=1.162220 step=0.050000
2017/08/30 09:07:48 Saving...
2017/08/30 09:07:48 Gathering batch of experience...
2017/08/30 09:08:27 batch 504: mean=5.586179 stddev=1.479543 entropy=1.115240 frames=100140 count=5007
2017/08/30 09:08:27 Training policy...
2017/08/30 09:08:51 step 0: objective=0.241286 reg=0.011152
2017/08/30 09:09:08 step 1: objective=0.241908 reg=0.011153
2017/08/30 09:09:26 step 2: objective=0.242502 reg=0.011154
2017/08/30 09:09:43 step 3: objective=0.243103 reg=0.011154
2017/08/30 09:10:00 step 4: objective=0.243651 reg=0.011155
2017/08/30 09:10:17 step 5: objective=0.244091 reg=0.011153
2017/08/30 09:10:35 step 6: objective=0.244485 reg=0.011153
2017/08/30 09:10:52 step 7: objective=0.244855 reg=0.011148
2017/08/30 09:10:52 Training value function...
2017/08/30 09:10:58 step 0: mse=1.166957 step=0.050000
2017/08/30 09:11:01 step 1: mse=1.167214 step=0.050000
2017/08/30 09:11:05 step 2: mse=1.167469 step=0.050000
2017/08/30 09:11:08 step 3: mse=1.167708 step=0.050000
2017/08/30 09:11:12 step 4: mse=1.167942 step=0.050000
2017/08/30 09:11:15 step 5: mse=1.168157 step=0.050000
2017/08/30 09:11:18 step 6: mse=1.168355 step=0.050000
2017/08/30 09:11:22 step 7: mse=1.168545 step=0.050000
2017/08/30 09:11:22 Saving...
2017/08/30 09:11:22 Gathering batch of experience...
2017/08/30 09:12:01 batch 505: mean=5.616737 stddev=1.488624 entropy=1.112779 frames=100140 count=5007
2017/08/30 09:12:01 Training policy...
2017/08/30 09:12:26 step 0: objective=0.263122 reg=0.011128
2017/08/30 09:12:43 step 1: objective=0.263629 reg=0.011127
2017/08/30 09:13:01 step 2: objective=0.264137 reg=0.011131
2017/08/30 09:13:19 step 3: objective=0.264661 reg=0.011129
2017/08/30 09:13:36 step 4: objective=0.265127 reg=0.011124
2017/08/30 09:13:53 step 5: objective=0.265575 reg=0.011124
2017/08/30 09:14:10 step 6: objective=0.266017 reg=0.011123
2017/08/30 09:14:28 step 7: objective=0.266478 reg=0.011121
2017/08/30 09:14:28 Training value function...
2017/08/30 09:14:34 step 0: mse=1.189192 step=0.050000
2017/08/30 09:14:37 step 1: mse=1.188068 step=0.050000
2017/08/30 09:14:41 step 2: mse=1.187025 step=0.050000
2017/08/30 09:14:44 step 3: mse=1.186065 step=0.050000
2017/08/30 09:14:48 step 4: mse=1.185159 step=0.050000
2017/08/30 09:14:51 step 5: mse=1.184312 step=0.050000
2017/08/30 09:14:55 step 6: mse=1.183515 step=0.050000
2017/08/30 09:14:58 step 7: mse=1.182764 step=0.050000
2017/08/30 09:14:58 Saving...
2017/08/30 09:14:58 Gathering batch of experience...
2017/08/30 09:15:37 batch 506: mean=5.586779 stddev=1.447990 entropy=1.119638 frames=100140 count=5007
2017/08/30 09:15:37 Training policy...
2017/08/30 09:16:01 step 0: objective=0.240286 reg=0.011196
2017/08/30 09:16:18 step 1: objective=0.240873 reg=0.011196
2017/08/30 09:16:36 step 2: objective=0.241407 reg=0.011198
2017/08/30 09:16:53 step 3: objective=0.241925 reg=0.011196
2017/08/30 09:17:10 step 4: objective=0.242426 reg=0.011194
2017/08/30 09:17:28 step 5: objective=0.242905 reg=0.011193
2017/08/30 09:17:45 step 6: objective=0.243286 reg=0.011193
2017/08/30 09:18:02 step 7: objective=0.243689 reg=0.011190
2017/08/30 09:18:02 Training value function...
2017/08/30 09:18:08 step 0: mse=1.131567 step=0.050000
2017/08/30 09:18:12 step 1: mse=1.131969 step=0.050000
2017/08/30 09:18:15 step 2: mse=1.132361 step=0.050000
2017/08/30 09:18:19 step 3: mse=1.132739 step=0.050000
2017/08/30 09:18:22 step 4: mse=1.133106 step=0.050000
2017/08/30 09:18:26 step 5: mse=1.133459 step=0.050000
2017/08/30 09:18:29 step 6: mse=1.133794 step=0.050000
2017/08/30 09:18:33 step 7: mse=1.134114 step=0.050000
2017/08/30 09:18:33 Saving...
2017/08/30 09:18:33 Gathering batch of experience...
2017/08/30 09:19:11 batch 507: mean=5.580987 stddev=1.473480 entropy=1.112755 frames=100140 count=5007
2017/08/30 09:19:11 Training policy...
2017/08/30 09:19:37 step 0: objective=0.251290 reg=0.011127
2017/08/30 09:19:54 step 1: objective=0.251897 reg=0.011132
2017/08/30 09:20:11 step 2: objective=0.252439 reg=0.011135
2017/08/30 09:20:28 step 3: objective=0.252916 reg=0.011135
2017/08/30 09:20:46 step 4: objective=0.253415 reg=0.011131
2017/08/30 09:21:03 step 5: objective=0.253863 reg=0.011131
2017/08/30 09:21:20 step 6: objective=0.254246 reg=0.011130
2017/08/30 09:21:38 step 7: objective=0.254588 reg=0.011132
2017/08/30 09:21:38 Training value function...
2017/08/30 09:21:44 step 0: mse=1.153292 step=0.050000
2017/08/30 09:21:47 step 1: mse=1.153192 step=0.050000
2017/08/30 09:21:51 step 2: mse=1.153111 step=0.050000
2017/08/30 09:21:54 step 3: mse=1.153039 step=0.050000
2017/08/30 09:21:58 step 4: mse=1.152977 step=0.050000
2017/08/30 09:22:01 step 5: mse=1.152923 step=0.050000
2017/08/30 09:22:05 step 6: mse=1.152873 step=0.050000
2017/08/30 09:22:08 step 7: mse=1.152825 step=0.050000
2017/08/30 09:22:08 Saving...
2017/08/30 09:22:08 Gathering batch of experience...
2017/08/30 09:22:47 batch 508: mean=5.599960 stddev=1.453749 entropy=1.115837 frames=100140 count=5007
2017/08/30 09:22:47 Training policy...
2017/08/30 09:23:11 step 0: objective=0.244367 reg=0.011158
2017/08/30 09:23:29 step 1: objective=0.245044 reg=0.011161
2017/08/30 09:23:46 step 2: objective=0.245607 reg=0.011158
2017/08/30 09:24:04 step 3: objective=0.246097 reg=0.011155
2017/08/30 09:24:21 step 4: objective=0.246633 reg=0.011156
2017/08/30 09:24:39 step 5: objective=0.247084 reg=0.011155
2017/08/30 09:24:56 step 6: objective=0.247521 reg=0.011154
2017/08/30 09:25:14 step 7: objective=0.247917 reg=0.011152
2017/08/30 09:25:14 Training value function...
2017/08/30 09:25:20 step 0: mse=1.143556 step=0.050000
2017/08/30 09:25:23 step 1: mse=1.143509 step=0.050000
2017/08/30 09:25:27 step 2: mse=1.143519 step=0.050000
2017/08/30 09:25:30 step 3: mse=1.143536 step=0.050000
2017/08/30 09:25:34 step 4: mse=1.143515 step=0.050000
2017/08/30 09:25:37 step 5: mse=1.143528 step=0.050000
2017/08/30 09:25:40 step 6: mse=1.143512 step=0.050000
2017/08/30 09:25:44 step 7: mse=1.143489 step=0.050000
2017/08/30 09:25:44 Saving...
2017/08/30 09:25:44 Gathering batch of experience...
2017/08/30 09:26:23 batch 509: mean=5.622129 stddev=1.456997 entropy=1.112917 frames=100140 count=5007
2017/08/30 09:26:23 Training policy...
2017/08/30 09:26:47 step 0: objective=0.262304 reg=0.011129
2017/08/30 09:27:05 step 1: objective=0.262929 reg=0.011127
2017/08/30 09:27:22 step 2: objective=0.263564 reg=0.011127
2017/08/30 09:27:40 step 3: objective=0.264084 reg=0.011130
2017/08/30 09:27:57 step 4: objective=0.264519 reg=0.011128
2017/08/30 09:28:15 step 5: objective=0.265005 reg=0.011127
2017/08/30 09:28:32 step 6: objective=0.265350 reg=0.011129
2017/08/30 09:28:50 step 7: objective=0.265728 reg=0.011125
2017/08/30 09:28:50 Training value function...
2017/08/30 09:28:56 step 0: mse=1.189166 step=0.050000
2017/08/30 09:28:59 step 1: mse=1.188297 step=0.050000
2017/08/30 09:29:03 step 2: mse=1.187492 step=0.050000
2017/08/30 09:29:06 step 3: mse=1.186730 step=0.050000
2017/08/30 09:29:10 step 4: mse=1.186022 step=0.050000
2017/08/30 09:29:13 step 5: mse=1.185348 step=0.050000
2017/08/30 09:29:17 step 6: mse=1.184720 step=0.050000
2017/08/30 09:29:20 step 7: mse=1.184129 step=0.050000
2017/08/30 09:29:20 Saving...
2017/08/30 09:29:20 Gathering batch of experience...
2017/08/30 09:29:59 batch 510: mean=5.612942 stddev=1.471918 entropy=1.109311 frames=100140 count=5007
2017/08/30 09:29:59 Training policy...
2017/08/30 09:30:24 step 0: objective=0.262042 reg=0.011093
2017/08/30 09:30:41 step 1: objective=0.262551 reg=0.011095
2017/08/30 09:30:59 step 2: objective=0.263187 reg=0.011094
2017/08/30 09:31:17 step 3: objective=0.263604 reg=0.011097
2017/08/30 09:31:34 step 4: objective=0.264023 reg=0.011095
2017/08/30 09:31:52 step 5: objective=0.264365 reg=0.011097
2017/08/30 09:32:09 step 6: objective=0.264763 reg=0.011097
2017/08/30 09:32:27 step 7: objective=0.265281 reg=0.011090
2017/08/30 09:32:27 Training value function...
2017/08/30 09:32:33 step 0: mse=1.203228 step=0.050000
2017/08/30 09:32:36 step 1: mse=1.202721 step=0.050000
2017/08/30 09:32:40 step 2: mse=1.202277 step=0.050000
2017/08/30 09:32:43 step 3: mse=1.201867 step=0.050000
2017/08/30 09:32:47 step 4: mse=1.201488 step=0.050000
2017/08/30 09:32:50 step 5: mse=1.201137 step=0.050000
2017/08/30 09:32:54 step 6: mse=1.200812 step=0.050000
2017/08/30 09:32:57 step 7: mse=1.200468 step=0.050000
2017/08/30 09:32:57 Saving...
2017/08/30 09:32:57 Gathering batch of experience...
2017/08/30 09:33:36 batch 511: mean=5.617935 stddev=1.486515 entropy=1.109073 frames=100140 count=5007
2017/08/30 09:33:36 Training policy...
2017/08/30 09:34:01 step 0: objective=0.244760 reg=0.011091
2017/08/30 09:34:19 step 1: objective=0.245419 reg=0.011091
2017/08/30 09:34:36 step 2: objective=0.245824 reg=0.011092
2017/08/30 09:34:54 step 3: objective=0.246340 reg=0.011093
2017/08/30 09:35:11 step 4: objective=0.246808 reg=0.011090
2017/08/30 09:35:29 step 5: objective=0.247302 reg=0.011088
2017/08/30 09:35:47 step 6: objective=0.247763 reg=0.011089
2017/08/30 09:36:04 step 7: objective=0.248208 reg=0.011085
2017/08/30 09:36:04 Training value function...
2017/08/30 09:36:10 step 0: mse=1.160533 step=0.050000
2017/08/30 09:36:14 step 1: mse=1.160750 step=0.050000
2017/08/30 09:36:17 step 2: mse=1.160967 step=0.050000
2017/08/30 09:36:21 step 3: mse=1.161181 step=0.050000
2017/08/30 09:36:24 step 4: mse=1.161352 step=0.050000
2017/08/30 09:36:28 step 5: mse=1.161530 step=0.050000
2017/08/30 09:36:31 step 6: mse=1.161687 step=0.050000
2017/08/30 09:36:34 step 7: mse=1.161850 step=0.050000
2017/08/30 09:36:34 Saving...
2017/08/30 09:36:35 Gathering batch of experience...
2017/08/30 09:37:13 batch 512: mean=5.612942 stddev=1.491999 entropy=1.107373 frames=100140 count=5007
2017/08/30 09:37:13 Training policy...
2017/08/30 09:37:38 step 0: objective=0.258666 reg=0.011074
2017/08/30 09:37:56 step 1: objective=0.259280 reg=0.011072
2017/08/30 09:38:14 step 2: objective=0.259904 reg=0.011069
2017/08/30 09:38:32 step 3: objective=0.260332 reg=0.011076
2017/08/30 09:38:50 step 4: objective=0.260960 reg=0.011075
2017/08/30 09:39:08 step 5: objective=0.261473 reg=0.011071
2017/08/30 09:39:25 step 6: objective=0.261865 reg=0.011069
2017/08/30 09:39:43 step 7: objective=0.262289 reg=0.011071
2017/08/30 09:39:43 Training value function...
2017/08/30 09:39:49 step 0: mse=1.189134 step=0.050000
2017/08/30 09:39:53 step 1: mse=1.188481 step=0.050000
2017/08/30 09:39:56 step 2: mse=1.187852 step=0.050000
2017/08/30 09:39:59 step 3: mse=1.187291 step=0.050000
2017/08/30 09:40:03 step 4: mse=1.186727 step=0.050000
2017/08/30 09:40:06 step 5: mse=1.186222 step=0.050000
2017/08/30 09:40:10 step 6: mse=1.185720 step=0.050000
2017/08/30 09:40:13 step 7: mse=1.185216 step=0.050000
2017/08/30 09:40:13 Saving...
2017/08/30 09:40:14 Gathering batch of experience...
2017/08/30 09:40:52 batch 513: mean=5.570801 stddev=1.482651 entropy=1.111072 frames=100140 count=5007
2017/08/30 09:40:52 Training policy...
2017/08/30 09:41:17 step 0: objective=0.251510 reg=0.011111
2017/08/30 09:41:35 step 1: objective=0.252136 reg=0.011110
2017/08/30 09:41:53 step 2: objective=0.252789 reg=0.011113
2017/08/30 09:42:11 step 3: objective=0.253276 reg=0.011112
2017/08/30 09:42:28 step 4: objective=0.253657 reg=0.011110
2017/08/30 09:42:46 step 5: objective=0.254060 reg=0.011108
2017/08/30 09:43:04 step 6: objective=0.254519 reg=0.011104
2017/08/30 09:43:21 step 7: objective=0.254881 reg=0.011103
2017/08/30 09:43:21 Training value function...
2017/08/30 09:43:27 step 0: mse=1.158744 step=0.050000
2017/08/30 09:43:31 step 1: mse=1.158503 step=0.050000
2017/08/30 09:43:34 step 2: mse=1.158253 step=0.050000
2017/08/30 09:43:38 step 3: mse=1.158027 step=0.050000
2017/08/30 09:43:41 step 4: mse=1.157822 step=0.050000
2017/08/30 09:43:45 step 5: mse=1.157629 step=0.050000
2017/08/30 09:43:48 step 6: mse=1.157441 step=0.050000
2017/08/30 09:43:52 step 7: mse=1.157255 step=0.050000
2017/08/30 09:43:52 Saving...
2017/08/30 09:43:52 Gathering batch of experience...
2017/08/30 09:44:30 batch 514: mean=5.628520 stddev=1.465743 entropy=1.104810 frames=100140 count=5007
2017/08/30 09:44:30 Training policy...
2017/08/30 09:44:56 step 0: objective=0.258583 reg=0.011048
2017/08/30 09:45:13 step 1: objective=0.259420 reg=0.011051
2017/08/30 09:45:31 step 2: objective=0.260020 reg=0.011051
2017/08/30 09:45:49 step 3: objective=0.260566 reg=0.011051
2017/08/30 09:46:07 step 4: objective=0.261078 reg=0.011056
2017/08/30 09:46:25 step 5: objective=0.261554 reg=0.011058
2017/08/30 09:46:42 step 6: objective=0.261969 reg=0.011057
2017/08/30 09:47:00 step 7: objective=0.262282 reg=0.011055
2017/08/30 09:47:00 Training value function...
2017/08/30 09:47:06 step 0: mse=1.206337 step=0.050000
2017/08/30 09:47:10 step 1: mse=1.206025 step=0.050000
2017/08/30 09:47:13 step 2: mse=1.205738 step=0.050000
2017/08/30 09:47:16 step 3: mse=1.205473 step=0.050000
2017/08/30 09:47:20 step 4: mse=1.205221 step=0.050000
2017/08/30 09:47:23 step 5: mse=1.204982 step=0.050000
2017/08/30 09:47:27 step 6: mse=1.204758 step=0.050000
2017/08/30 09:47:30 step 7: mse=1.204551 step=0.050000
2017/08/30 09:47:30 Saving...
2017/08/30 09:47:31 Gathering batch of experience...
2017/08/30 09:48:09 batch 515: mean=5.608348 stddev=1.485498 entropy=1.109297 frames=100140 count=5007
2017/08/30 09:48:09 Training policy...
2017/08/30 09:48:35 step 0: objective=0.244143 reg=0.011093
2017/08/30 09:48:53 step 1: objective=0.244896 reg=0.011093
2017/08/30 09:49:11 step 2: objective=0.245463 reg=0.011089
2017/08/30 09:49:28 step 3: objective=0.245952 reg=0.011090
2017/08/30 09:49:46 step 4: objective=0.246360 reg=0.011089
2017/08/30 09:50:04 step 5: objective=0.246793 reg=0.011090
2017/08/30 09:50:22 step 6: objective=0.247255 reg=0.011090
2017/08/30 09:50:40 step 7: objective=0.247628 reg=0.011093
2017/08/30 09:50:40 Training value function...
2017/08/30 09:50:46 step 0: mse=1.177156 step=0.050000
2017/08/30 09:50:49 step 1: mse=1.177478 step=0.050000
2017/08/30 09:50:53 step 2: mse=1.177793 step=0.050000
2017/08/30 09:50:56 step 3: mse=1.178095 step=0.050000
2017/08/30 09:51:00 step 4: mse=1.178393 step=0.050000
2017/08/30 09:51:03 step 5: mse=1.178672 step=0.050000
2017/08/30 09:51:07 step 6: mse=1.178937 step=0.050000
2017/08/30 09:51:10 step 7: mse=1.179189 step=0.050000
2017/08/30 09:51:10 Saving...
2017/08/30 09:51:10 Gathering batch of experience...
2017/08/30 09:51:49 batch 516: mean=5.599161 stddev=1.468837 entropy=1.109944 frames=100140 count=5007
2017/08/30 09:51:49 Training policy...
2017/08/30 09:52:15 step 0: objective=0.243896 reg=0.011099
2017/08/30 09:52:33 step 1: objective=0.244416 reg=0.011101
2017/08/30 09:52:51 step 2: objective=0.244873 reg=0.011103
2017/08/30 09:53:09 step 3: objective=0.245402 reg=0.011104
2017/08/30 09:53:27 step 4: objective=0.245858 reg=0.011097
2017/08/30 09:53:45 step 5: objective=0.246175 reg=0.011101
2017/08/30 09:54:03 step 6: objective=0.246625 reg=0.011098
2017/08/30 09:54:21 step 7: objective=0.247005 reg=0.011095
2017/08/30 09:54:21 Training value function...
2017/08/30 09:54:27 step 0: mse=1.153832 step=0.050000
2017/08/30 09:54:30 step 1: mse=1.154252 step=0.050000
2017/08/30 09:54:34 step 2: mse=1.154652 step=0.050000
2017/08/30 09:54:37 step 3: mse=1.155025 step=0.050000
2017/08/30 09:54:41 step 4: mse=1.155363 step=0.050000
2017/08/30 09:54:44 step 5: mse=1.155690 step=0.050000
2017/08/30 09:54:47 step 6: mse=1.155987 step=0.050000
2017/08/30 09:54:51 step 7: mse=1.156264 step=0.050000
2017/08/30 09:54:51 Saving...
2017/08/30 09:54:51 Gathering batch of experience...
2017/08/30 09:55:30 batch 517: mean=5.657679 stddev=1.459750 entropy=1.106574 frames=100140 count=5007
2017/08/30 09:55:30 Training policy...
2017/08/30 09:55:55 step 0: objective=0.271103 reg=0.011066
2017/08/30 09:56:13 step 1: objective=0.271848 reg=0.011064
2017/08/30 09:56:31 step 2: objective=0.272403 reg=0.011066
2017/08/30 09:56:49 step 3: objective=0.272909 reg=0.011069
2017/08/30 09:57:07 step 4: objective=0.273315 reg=0.011069
2017/08/30 09:57:25 step 5: objective=0.273761 reg=0.011068
2017/08/30 09:57:44 step 6: objective=0.274232 reg=0.011067
2017/08/30 09:58:02 step 7: objective=0.274530 reg=0.011066
2017/08/30 09:58:02 Training value function...
2017/08/30 09:58:08 step 0: mse=1.151429 step=0.050000
2017/08/30 09:58:12 step 1: mse=1.149171 step=0.050000
2017/08/30 09:58:15 step 2: mse=1.147070 step=0.050000
2017/08/30 09:58:19 step 3: mse=1.145111 step=0.050000
2017/08/30 09:58:22 step 4: mse=1.143285 step=0.050000
2017/08/30 09:58:25 step 5: mse=1.141572 step=0.050000
2017/08/30 09:58:29 step 6: mse=1.139967 step=0.050000
2017/08/30 09:58:32 step 7: mse=1.138462 step=0.050000
2017/08/30 09:58:32 Saving...
2017/08/30 09:58:33 Gathering batch of experience...
2017/08/30 09:59:11 batch 518: mean=5.587378 stddev=1.471758 entropy=1.107731 frames=100140 count=5007
2017/08/30 09:59:11 Training policy...
2017/08/30 09:59:37 step 0: objective=0.239797 reg=0.011077
2017/08/30 09:59:55 step 1: objective=0.240414 reg=0.011079
2017/08/30 10:00:13 step 2: objective=0.240957 reg=0.011079
2017/08/30 10:00:31 step 3: objective=0.241467 reg=0.011079
2017/08/30 10:00:49 step 4: objective=0.241945 reg=0.011081
2017/08/30 10:01:07 step 5: objective=0.242344 reg=0.011078
2017/08/30 10:01:25 step 6: objective=0.242709 reg=0.011078
2017/08/30 10:01:43 step 7: objective=0.243173 reg=0.011079
2017/08/30 10:01:43 Training value function...
2017/08/30 10:01:49 step 0: mse=1.129827 step=0.050000
2017/08/30 10:01:52 step 1: mse=1.130153 step=0.050000
2017/08/30 10:01:56 step 2: mse=1.130479 step=0.050000
2017/08/30 10:01:59 step 3: mse=1.130794 step=0.050000
2017/08/30 10:02:03 step 4: mse=1.131119 step=0.050000
2017/08/30 10:02:06 step 5: mse=1.131402 step=0.050000
2017/08/30 10:02:10 step 6: mse=1.131698 step=0.050000
2017/08/30 10:02:13 step 7: mse=1.131942 step=0.050000
2017/08/30 10:02:13 Saving...
2017/08/30 10:02:13 Gathering batch of experience...
2017/08/30 10:02:52 batch 519: mean=5.609347 stddev=1.468794 entropy=1.102745 frames=100140 count=5007
2017/08/30 10:02:52 Training policy...
2017/08/30 10:03:17 step 0: objective=0.258182 reg=0.011027
2017/08/30 10:03:35 step 1: objective=0.258861 reg=0.011031
2017/08/30 10:03:53 step 2: objective=0.259329 reg=0.011033
2017/08/30 10:04:11 step 3: objective=0.259850 reg=0.011032
2017/08/30 10:04:30 step 4: objective=0.260369 reg=0.011030
2017/08/30 10:04:48 step 5: objective=0.260855 reg=0.011030
2017/08/30 10:05:06 step 6: objective=0.261188 reg=0.011027
2017/08/30 10:05:24 step 7: objective=0.261525 reg=0.011029
2017/08/30 10:05:24 Training value function...
2017/08/30 10:05:30 step 0: mse=1.133527 step=0.050000
2017/08/30 10:05:33 step 1: mse=1.132518 step=0.050000
2017/08/30 10:05:37 step 2: mse=1.131586 step=0.050000
2017/08/30 10:05:40 step 3: mse=1.130725 step=0.050000
2017/08/30 10:05:43 step 4: mse=1.129923 step=0.050000
2017/08/30 10:05:47 step 5: mse=1.129167 step=0.050000
2017/08/30 10:05:50 step 6: mse=1.128458 step=0.050000
2017/08/30 10:05:54 step 7: mse=1.127795 step=0.050000
2017/08/30 10:05:54 Saving...
2017/08/30 10:05:54 Gathering batch of experience...
2017/08/30 10:06:33 batch 520: mean=5.572598 stddev=1.514945 entropy=1.105193 frames=100140 count=5007
2017/08/30 10:06:33 Training policy...
2017/08/30 10:06:58 step 0: objective=0.249441 reg=0.011052
2017/08/30 10:07:16 step 1: objective=0.249987 reg=0.011048
2017/08/30 10:07:35 step 2: objective=0.250495 reg=0.011054
2017/08/30 10:07:53 step 3: objective=0.250963 reg=0.011051
2017/08/30 10:08:11 step 4: objective=0.251294 reg=0.011056
2017/08/30 10:08:29 step 5: objective=0.251728 reg=0.011051
2017/08/30 10:08:47 step 6: objective=0.252215 reg=0.011051
2017/08/30 10:09:05 step 7: objective=0.252635 reg=0.011051
2017/08/30 10:09:05 Training value function...
2017/08/30 10:09:11 step 0: mse=1.157085 step=0.050000
2017/08/30 10:09:15 step 1: mse=1.156912 step=0.050000
2017/08/30 10:09:18 step 2: mse=1.156760 step=0.050000
2017/08/30 10:09:22 step 3: mse=1.156607 step=0.050000
2017/08/30 10:09:25 step 4: mse=1.156492 step=0.050000
2017/08/30 10:09:29 step 5: mse=1.156380 step=0.050000
2017/08/30 10:09:32 step 6: mse=1.156279 step=0.050000
2017/08/30 10:09:36 step 7: mse=1.156170 step=0.050000
2017/08/30 10:09:36 Saving...
2017/08/30 10:09:36 Gathering batch of experience...
2017/08/30 10:10:15 batch 521: mean=5.583184 stddev=1.459465 entropy=1.110977 frames=100140 count=5007
2017/08/30 10:10:15 Training policy...
2017/08/30 10:10:40 step 0: objective=0.244891 reg=0.011110
2017/08/30 10:10:58 step 1: objective=0.245536 reg=0.011109
2017/08/30 10:11:16 step 2: objective=0.246063 reg=0.011109
2017/08/30 10:11:35 step 3: objective=0.246601 reg=0.011110
2017/08/30 10:11:54 step 4: objective=0.247104 reg=0.011109
2017/08/30 10:12:12 step 5: objective=0.247523 reg=0.011109
2017/08/30 10:12:30 step 6: objective=0.247951 reg=0.011106
2017/08/30 10:12:48 step 7: objective=0.248395 reg=0.011106
2017/08/30 10:12:48 Training value function...
2017/08/30 10:12:54 step 0: mse=1.162617 step=0.050000
2017/08/30 10:12:58 step 1: mse=1.162908 step=0.050000
2017/08/30 10:13:01 step 2: mse=1.163185 step=0.050000
2017/08/30 10:13:05 step 3: mse=1.163461 step=0.050000
2017/08/30 10:13:08 step 4: mse=1.163736 step=0.050000
2017/08/30 10:13:12 step 5: mse=1.164007 step=0.050000
2017/08/30 10:13:15 step 6: mse=1.164258 step=0.050000
2017/08/30 10:13:19 step 7: mse=1.164502 step=0.050000
2017/08/30 10:13:19 Saving...
2017/08/30 10:13:19 Gathering batch of experience...
2017/08/30 10:13:58 batch 522: mean=5.584582 stddev=1.476392 entropy=1.107139 frames=100140 count=5007
2017/08/30 10:13:58 Training policy...
2017/08/30 10:14:23 step 0: objective=0.240901 reg=0.011071
2017/08/30 10:14:41 step 1: objective=0.241472 reg=0.011078
2017/08/30 10:15:00 step 2: objective=0.241964 reg=0.011081
2017/08/30 10:15:18 step 3: objective=0.242446 reg=0.011082
2017/08/30 10:15:36 step 4: objective=0.242901 reg=0.011076
2017/08/30 10:15:55 step 5: objective=0.243362 reg=0.011079
2017/08/30 10:16:13 step 6: objective=0.243782 reg=0.011077
2017/08/30 10:16:31 step 7: objective=0.244191 reg=0.011077
2017/08/30 10:16:31 Training value function...
2017/08/30 10:16:37 step 0: mse=1.139038 step=0.050000
2017/08/30 10:16:41 step 1: mse=1.139192 step=0.050000
2017/08/30 10:16:44 step 2: mse=1.139351 step=0.050000
2017/08/30 10:16:48 step 3: mse=1.139510 step=0.050000
2017/08/30 10:16:51 step 4: mse=1.139663 step=0.050000
2017/08/30 10:16:55 step 5: mse=1.139815 step=0.050000
2017/08/30 10:16:58 step 6: mse=1.139965 step=0.050000
2017/08/30 10:17:01 step 7: mse=1.140108 step=0.050000
2017/08/30 10:17:01 Saving...
2017/08/30 10:17:02 Gathering batch of experience...
2017/08/30 10:17:41 batch 523: mean=5.592970 stddev=1.436804 entropy=1.104810 frames=100140 count=5007
2017/08/30 10:17:41 Training policy...
2017/08/30 10:18:06 step 0: objective=0.246257 reg=0.011048
2017/08/30 10:18:24 step 1: objective=0.246839 reg=0.011051
2017/08/30 10:18:43 step 2: objective=0.247343 reg=0.011052
2017/08/30 10:19:01 step 3: objective=0.247890 reg=0.011050
2017/08/30 10:19:20 step 4: objective=0.248497 reg=0.011049
2017/08/30 10:19:38 step 5: objective=0.248931 reg=0.011051
2017/08/30 10:19:56 step 6: objective=0.249310 reg=0.011052
2017/08/30 10:20:15 step 7: objective=0.249713 reg=0.011051
2017/08/30 10:20:15 Training value function...
2017/08/30 10:20:21 step 0: mse=1.121477 step=0.050000
2017/08/30 10:20:24 step 1: mse=1.121366 step=0.050000
2017/08/30 10:20:28 step 2: mse=1.121283 step=0.050000
2017/08/30 10:20:31 step 3: mse=1.121224 step=0.050000
2017/08/30 10:20:34 step 4: mse=1.121182 step=0.050000
2017/08/30 10:20:38 step 5: mse=1.121154 step=0.050000
2017/08/30 10:20:41 step 6: mse=1.121167 step=0.050000
2017/08/30 10:20:45 step 7: mse=1.121187 step=0.050000
2017/08/30 10:20:45 Saving...
2017/08/30 10:20:45 Gathering batch of experience...
2017/08/30 10:21:24 batch 524: mean=5.611744 stddev=1.440743 entropy=1.109633 frames=100140 count=5007
2017/08/30 10:21:24 Training policy...
2017/08/30 10:21:50 step 0: objective=0.256504 reg=0.011096
2017/08/30 10:22:09 step 1: objective=0.257017 reg=0.011101
2017/08/30 10:22:28 step 2: objective=0.257432 reg=0.011102
2017/08/30 10:22:46 step 3: objective=0.258086 reg=0.011101
2017/08/30 10:23:05 step 4: objective=0.258597 reg=0.011101
2017/08/30 10:23:23 step 5: objective=0.259114 reg=0.011095
2017/08/30 10:23:42 step 6: objective=0.259554 reg=0.011098
2017/08/30 10:24:01 step 7: objective=0.260005 reg=0.011097
2017/08/30 10:24:01 Training value function...
2017/08/30 10:24:07 step 0: mse=1.125360 step=0.050000
2017/08/30 10:24:10 step 1: mse=1.124895 step=0.050000
2017/08/30 10:24:14 step 2: mse=1.124469 step=0.050000
2017/08/30 10:24:17 step 3: mse=1.124072 step=0.050000
2017/08/30 10:24:20 step 4: mse=1.123710 step=0.050000
2017/08/30 10:24:24 step 5: mse=1.123369 step=0.050000
2017/08/30 10:24:27 step 6: mse=1.123047 step=0.050000
2017/08/30 10:24:31 step 7: mse=1.122745 step=0.050000
2017/08/30 10:24:31 Saving...
2017/08/30 10:24:31 Gathering batch of experience...
2017/08/30 10:25:10 batch 525: mean=5.643699 stddev=1.459277 entropy=1.101040 frames=100140 count=5007
2017/08/30 10:25:10 Training policy...
2017/08/30 10:25:36 step 0: objective=0.273533 reg=0.011010
2017/08/30 10:25:54 step 1: objective=0.274360 reg=0.011013
2017/08/30 10:26:14 step 2: objective=0.274919 reg=0.011014
2017/08/30 10:26:32 step 3: objective=0.275293 reg=0.011017
2017/08/30 10:26:50 step 4: objective=0.275808 reg=0.011017
2017/08/30 10:27:09 step 5: objective=0.276255 reg=0.011015
2017/08/30 10:27:27 step 6: objective=0.276650 reg=0.011013
2017/08/30 10:27:46 step 7: objective=0.277048 reg=0.011014
2017/08/30 10:27:46 Training value function...
2017/08/30 10:27:52 step 0: mse=1.177269 step=0.050000
2017/08/30 10:27:55 step 1: mse=1.175731 step=0.050000
2017/08/30 10:27:59 step 2: mse=1.174296 step=0.050000
2017/08/30 10:28:02 step 3: mse=1.172895 step=0.050000
2017/08/30 10:28:05 step 4: mse=1.171626 step=0.050000
2017/08/30 10:28:09 step 5: mse=1.170410 step=0.050000
2017/08/30 10:28:12 step 6: mse=1.169240 step=0.050000
