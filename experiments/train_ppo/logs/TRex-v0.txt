2017/08/26 22:22:37 Run with arguments: [-algo mse -env TRex-v0 -step 1 -valstep 0.1 -iters 8 -valiters 8 -discount 0.99 -critic TRex-v0/critic.json -actor TRex-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1]
2017/08/26 22:22:37 Creating environments...
2017/08/26 22:22:43 Creating new forest for: TRex-v0/actor.json
2017/08/26 22:22:43 Creating new forest for: TRex-v0/critic.json
2017/08/26 22:22:43 Running. Press Ctrl+C to stop.
2017/08/26 22:22:43 Gathering batch of experience...
2017/08/26 22:22:59 Run with arguments: [-algo mse -env TRex-v0 -step 1 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic TRex-v0/critic.json -actor TRex-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1]
2017/08/26 22:22:59 Creating environments...
2017/08/26 22:23:06 Creating new forest for: TRex-v0/actor.json
2017/08/26 22:23:06 Creating new forest for: TRex-v0/critic.json
2017/08/26 22:23:06 Running. Press Ctrl+C to stop.
2017/08/26 22:23:06 Gathering batch of experience...
2017/08/26 22:24:32 batch 0: mean=49.730769 stddev=11.380002 entropy=1.386294 frames=4269 count=78
2017/08/26 22:24:32 Training policy...
2017/08/26 22:24:36 step 0: objective=9.107977
2017/08/26 22:24:38 step 1: objective=8.913901
2017/08/26 22:24:39 step 2: objective=7.3001885
2017/08/26 22:24:41 step 3: objective=6.998669
2017/08/26 22:24:43 step 4: objective=6.7687273
2017/08/26 22:24:44 step 5: objective=7.4481497
2017/08/26 22:24:46 step 6: objective=7.5880585
2017/08/26 22:24:48 step 7: objective=7.477685
2017/08/26 22:24:48 Training value function...
2017/08/26 22:24:51 step 0: mse=305.419209 step=0.100000
2017/08/26 22:24:52 step 1: mse=254.132169 step=0.100000
2017/08/26 22:24:54 step 2: mse=212.821835 step=0.100000
2017/08/26 22:24:55 step 3: mse=179.025806 step=0.100000
2017/08/26 22:24:57 step 4: mse=152.402872 step=0.100000
2017/08/26 22:24:58 step 5: mse=130.202995 step=0.100000
2017/08/26 22:25:00 step 6: mse=112.277121 step=0.100000
2017/08/26 22:25:01 step 7: mse=96.546720 step=0.100000
2017/08/26 22:25:01 Saving...
2017/08/26 22:25:01 Gathering batch of experience...
2017/08/26 22:26:25 batch 1: mean=54.027778 stddev=15.286134 entropy=1.193448 frames=4273 count=72
2017/08/26 22:26:25 Training policy...
2017/08/26 22:26:29 step 0: objective=4.574105
2017/08/26 22:26:31 step 1: objective=4.540075
2017/08/26 22:26:33 step 2: objective=4.454481
2017/08/26 22:26:34 step 3: objective=4.43265
2017/08/26 22:26:36 step 4: objective=4.2533584
2017/08/26 22:26:38 step 5: objective=4.233249
2017/08/26 22:26:40 step 6: objective=4.183234
2017/08/26 22:26:41 step 7: objective=4.1782513
2017/08/26 22:26:41 Training value function...
2017/08/26 22:26:45 step 0: mse=105.326488 step=0.100000
2017/08/26 22:26:46 step 1: mse=92.401287 step=0.100000
2017/08/26 22:26:48 step 2: mse=82.118640 step=0.100000
2017/08/26 22:26:49 step 3: mse=73.851699 step=0.100000
2017/08/26 22:26:51 step 4: mse=66.853298 step=0.100000
2017/08/26 22:26:52 step 5: mse=60.893661 step=0.100000
2017/08/26 22:26:54 step 6: mse=56.136448 step=0.100000
2017/08/26 22:26:55 step 7: mse=52.111709 step=0.100000
2017/08/26 22:26:55 Saving...
2017/08/26 22:26:55 Gathering batch of experience...
2017/08/26 22:28:21 batch 2: mean=51.842105 stddev=11.657449 entropy=1.161242 frames=4334 count=76
2017/08/26 22:28:21 Training policy...
2017/08/26 22:28:26 step 0: objective=2.140811
2017/08/26 22:28:27 step 1: objective=2.1335583
2017/08/26 22:28:29 step 2: objective=2.1354747
2017/08/26 22:28:31 step 3: objective=2.1229708
2017/08/26 22:28:32 step 4: objective=2.1188104
2017/08/26 22:28:34 step 5: objective=2.111468
2017/08/26 22:28:36 step 6: objective=2.1056435
2017/08/26 22:28:38 step 7: objective=2.0900183
2017/08/26 22:28:38 Training value function...
2017/08/26 22:28:41 step 0: mse=41.682145 step=0.100000
2017/08/26 22:28:42 step 1: mse=39.716587 step=0.100000
2017/08/26 22:28:44 step 2: mse=37.763258 step=0.100000
2017/08/26 22:28:45 step 3: mse=35.732997 step=0.100000
2017/08/26 22:28:47 step 4: mse=34.306675 step=0.100000
2017/08/26 22:28:48 step 5: mse=33.120908 step=0.100000
2017/08/26 22:28:50 step 6: mse=31.974502 step=0.100000
2017/08/26 22:28:51 step 7: mse=31.076095 step=0.100000
2017/08/26 22:28:51 Saving...
2017/08/26 22:28:51 Gathering batch of experience...
2017/08/26 22:30:16 batch 3: mean=57.142857 stddev=19.591752 entropy=1.124935 frames=4382 count=70
2017/08/26 22:30:16 Training policy...
2017/08/26 22:30:21 step 0: objective=1.9867482
2017/08/26 22:30:23 step 1: objective=1.9734372
2017/08/26 22:30:24 step 2: objective=1.9603752
2017/08/26 22:30:26 step 3: objective=1.9419043
2017/08/26 22:30:28 step 4: objective=1.9383901
2017/08/26 22:30:30 step 5: objective=1.9305587
2017/08/26 22:30:31 step 6: objective=1.9237094
2017/08/26 22:30:33 step 7: objective=1.9201548
2017/08/26 22:30:33 Training value function...
2017/08/26 22:30:36 step 0: mse=54.807729 step=0.100000
2017/08/26 22:30:38 step 1: mse=52.807013 step=0.100000
2017/08/26 22:30:39 step 2: mse=50.946937 step=0.100000
2017/08/26 22:30:41 step 3: mse=49.380536 step=0.100000
2017/08/26 22:30:42 step 4: mse=47.933851 step=0.100000
2017/08/26 22:30:44 step 5: mse=46.869762 step=0.100000
2017/08/26 22:30:46 step 6: mse=45.855625 step=0.100000
2017/08/26 22:30:47 step 7: mse=44.953241 step=0.100000
2017/08/26 22:30:47 Saving...
2017/08/26 22:30:47 Gathering batch of experience...
2017/08/26 22:32:13 batch 4: mean=57.957143 stddev=16.195622 entropy=1.098286 frames=4449 count=70
2017/08/26 22:32:13 Training policy...
2017/08/26 22:32:18 step 0: objective=1.4310447
2017/08/26 22:32:20 step 1: objective=1.4187
2017/08/26 22:32:22 step 2: objective=1.413744
2017/08/26 22:32:23 step 3: objective=1.4214077
2017/08/26 22:32:25 step 4: objective=1.4221905
2017/08/26 22:32:27 step 5: objective=1.420491
2017/08/26 22:32:29 step 6: objective=1.407558
2017/08/26 22:32:30 step 7: objective=1.4088284
2017/08/26 22:32:30 Training value function...
2017/08/26 22:32:34 step 0: mse=42.751817 step=0.100000
2017/08/26 22:32:35 step 1: mse=41.889785 step=0.100000
2017/08/26 22:32:37 step 2: mse=41.118480 step=0.100000
2017/08/26 22:32:38 step 3: mse=40.488310 step=0.100000
2017/08/26 22:32:40 step 4: mse=39.897649 step=0.100000
2017/08/26 22:32:41 step 5: mse=39.141643 step=0.100000
2017/08/26 22:32:43 step 6: mse=38.634647 step=0.100000
2017/08/26 22:32:45 step 7: mse=38.319407 step=0.100000
2017/08/26 22:32:45 Saving...
2017/08/26 22:32:45 Gathering batch of experience...
2017/08/26 22:34:06 batch 5: mean=65.866667 stddev=26.360619 entropy=1.077115 frames=4314 count=60
2017/08/26 22:34:06 Training policy...
2017/08/26 22:34:11 step 0: objective=1.9162939
2017/08/26 22:34:13 step 1: objective=1.883091
2017/08/26 22:34:14 step 2: objective=1.8428864
2017/08/26 22:34:16 step 3: objective=1.8526198
2017/08/26 22:34:18 step 4: objective=1.8645604
2017/08/26 22:34:19 step 5: objective=1.8652103
2017/08/26 22:34:21 step 6: objective=1.8780631
2017/08/26 22:34:23 step 7: objective=1.8824092
2017/08/26 22:34:23 Training value function...
2017/08/26 22:34:26 step 0: mse=63.174402 step=0.100000
2017/08/26 22:34:27 step 1: mse=61.111941 step=0.100000
2017/08/26 22:34:29 step 2: mse=59.361247 step=0.100000
2017/08/26 22:34:30 step 3: mse=57.838179 step=0.100000
2017/08/26 22:34:32 step 4: mse=56.634966 step=0.100000
2017/08/26 22:34:33 step 5: mse=55.563218 step=0.100000
2017/08/26 22:34:35 step 6: mse=54.627774 step=0.100000
2017/08/26 22:34:37 step 7: mse=53.681449 step=0.100000
2017/08/26 22:34:37 Saving...
2017/08/26 22:34:37 Gathering batch of experience...
2017/08/26 22:36:03 batch 6: mean=62.230769 stddev=21.107614 entropy=1.072895 frames=4424 count=65
2017/08/26 22:36:03 Training policy...
2017/08/26 22:36:08 step 0: objective=1.0036132
2017/08/26 22:36:10 step 1: objective=0.99694085
2017/08/26 22:36:11 step 2: objective=0.99351966
2017/08/26 22:36:13 step 3: objective=0.9929143
2017/08/26 22:36:15 step 4: objective=0.99016297
2017/08/26 22:36:16 step 5: objective=0.9834746
2017/08/26 22:36:18 step 6: objective=0.9888022
2017/08/26 22:36:20 step 7: objective=0.9874589
2017/08/26 22:36:20 Training value function...
2017/08/26 22:36:23 step 0: mse=46.378286 step=0.100000
2017/08/26 22:36:25 step 1: mse=45.895663 step=0.100000
2017/08/26 22:36:26 step 2: mse=45.510441 step=0.100000
2017/08/26 22:36:28 step 3: mse=45.167061 step=0.100000
2017/08/26 22:36:29 step 4: mse=44.863758 step=0.100000
2017/08/26 22:36:31 step 5: mse=44.525176 step=0.100000
2017/08/26 22:36:32 step 6: mse=44.265764 step=0.100000
2017/08/26 22:36:34 step 7: mse=44.094094 step=0.100000
2017/08/26 22:36:34 Saving...
2017/08/26 22:36:34 Gathering batch of experience...
2017/08/26 22:38:00 batch 7: mean=66.266667 stddev=30.188224 entropy=1.041448 frames=4334 count=60
2017/08/26 22:38:00 Training policy...
2017/08/26 22:38:05 step 0: objective=1.4012532
2017/08/26 22:38:07 step 1: objective=1.3942217
2017/08/26 22:38:08 step 2: objective=1.3925052
2017/08/26 22:38:10 step 3: objective=1.3869634
2017/08/26 22:38:12 step 4: objective=1.3771126
2017/08/26 22:38:13 step 5: objective=1.3822122
2017/08/26 22:38:15 step 6: objective=1.3775963
2017/08/26 22:38:17 step 7: objective=1.3731446
2017/08/26 22:38:17 Training value function...
2017/08/26 22:38:20 step 0: mse=63.400362 step=0.100000
2017/08/26 22:38:21 step 1: mse=61.933565 step=0.100000
2017/08/26 22:38:23 step 2: mse=60.715163 step=0.100000
2017/08/26 22:38:24 step 3: mse=59.590100 step=0.100000
2017/08/26 22:38:26 step 4: mse=58.588131 step=0.100000
2017/08/26 22:38:27 step 5: mse=57.726809 step=0.100000
2017/08/26 22:38:29 step 6: mse=57.012485 step=0.100000
2017/08/26 22:38:31 step 7: mse=56.328906 step=0.100000
2017/08/26 22:38:31 Saving...
2017/08/26 22:38:31 Gathering batch of experience...
2017/08/26 22:39:54 batch 8: mean=72.472727 stddev=20.600842 entropy=1.000208 frames=4350 count=55
2017/08/26 22:39:54 Training policy...
2017/08/26 22:39:59 step 0: objective=1.4826242
2017/08/26 22:40:00 step 1: objective=1.4814734
2017/08/26 22:40:02 step 2: objective=1.481129
2017/08/26 22:40:04 step 3: objective=1.4783199
2017/08/26 22:40:05 step 4: objective=1.4686176
2017/08/26 22:40:07 step 5: objective=1.4681644
2017/08/26 22:40:09 step 6: objective=1.4648738
2017/08/26 22:40:11 step 7: objective=1.4655693
2017/08/26 22:40:11 Training value function...
2017/08/26 22:40:14 step 0: mse=53.644114 step=0.100000
2017/08/26 22:40:15 step 1: mse=52.469768 step=0.100000
2017/08/26 22:40:17 step 2: mse=51.368254 step=0.100000
2017/08/26 22:40:18 step 3: mse=50.133289 step=0.100000
2017/08/26 22:40:20 step 4: mse=49.022666 step=0.100000
2017/08/26 22:40:21 step 5: mse=47.701067 step=0.100000
2017/08/26 22:40:23 step 6: mse=46.857987 step=0.100000
2017/08/26 22:40:25 step 7: mse=46.189467 step=0.100000
2017/08/26 22:40:25 Saving...
2017/08/26 22:40:25 Gathering batch of experience...
2017/08/26 22:41:24 Run with arguments: [-algo mse -env TRex-v0 -step 0.2 -valstep 0.1 -iters 8 -valiters 8 -discount 0.97 -critic TRex-v0/critic.json -actor TRex-v0/actor.json -depth 4 -minleaf 128 -batch 4096 -reg 0.01 -decay 0.99 -maxtrees 500 -frametime 100ms -history -featurefrac 0.1]
2017/08/26 22:41:24 Creating environments...
2017/08/26 22:41:30 Loaded forest from: TRex-v0/actor.json
2017/08/26 22:41:30 Loaded forest from: TRex-v0/critic.json
2017/08/26 22:41:30 Running. Press Ctrl+C to stop.
2017/08/26 22:41:30 Gathering batch of experience...
2017/08/26 22:42:59 batch 0: mean=82.716981 stddev=45.744730 entropy=0.970861 frames=4744 count=53
2017/08/26 22:42:59 Training policy...
2017/08/26 22:43:05 step 0: objective=2.128896
2017/08/26 22:43:07 step 1: objective=2.1422458
2017/08/26 22:43:08 step 2: objective=2.1515203
2017/08/26 22:43:10 step 3: objective=2.1596422
2017/08/26 22:43:12 step 4: objective=2.169335
2017/08/26 22:43:14 step 5: objective=2.1757731
2017/08/26 22:43:16 step 6: objective=2.1815457
2017/08/26 22:43:18 step 7: objective=2.1859922
2017/08/26 22:43:18 Training value function...
2017/08/26 22:43:21 step 0: mse=92.886982 step=0.100000
2017/08/26 22:43:23 step 1: mse=87.536839 step=0.100000
2017/08/26 22:43:25 step 2: mse=83.206489 step=0.100000
2017/08/26 22:43:26 step 3: mse=79.315703 step=0.100000
2017/08/26 22:43:28 step 4: mse=76.033294 step=0.100000
2017/08/26 22:43:30 step 5: mse=73.347412 step=0.100000
2017/08/26 22:43:32 step 6: mse=71.027511 step=0.100000
2017/08/26 22:43:33 step 7: mse=69.051562 step=0.100000
2017/08/26 22:43:33 Saving...
2017/08/26 22:43:33 Gathering batch of experience...
2017/08/26 22:44:57 batch 1: mean=82.520000 stddev=32.426680 entropy=0.969450 frames=4477 count=50
2017/08/26 22:44:57 Training policy...
2017/08/26 22:45:03 step 0: objective=1.3866166
2017/08/26 22:45:04 step 1: objective=1.3968005
2017/08/26 22:45:06 step 2: objective=1.404527
2017/08/26 22:45:08 step 3: objective=1.4108707
2017/08/26 22:45:09 step 4: objective=1.4168237
2017/08/26 22:45:11 step 5: objective=1.4219116
2017/08/26 22:45:13 step 6: objective=1.4257201
2017/08/26 22:45:15 step 7: objective=1.429501
2017/08/26 22:45:15 Training value function...
2017/08/26 22:45:18 step 0: mse=61.016895 step=0.100000
2017/08/26 22:45:20 step 1: mse=60.024080 step=0.100000
2017/08/26 22:45:21 step 2: mse=59.158271 step=0.100000
2017/08/26 22:45:23 step 3: mse=58.427935 step=0.100000
2017/08/26 22:45:24 step 4: mse=57.724568 step=0.100000
2017/08/26 22:45:26 step 5: mse=57.090303 step=0.100000
2017/08/26 22:45:28 step 6: mse=56.514091 step=0.100000
2017/08/26 22:45:29 step 7: mse=56.005389 step=0.100000
2017/08/26 22:45:29 Saving...
2017/08/26 22:45:29 Gathering batch of experience...
2017/08/26 22:46:57 batch 2: mean=85.102041 stddev=33.968320 entropy=0.955005 frames=4525 count=49
2017/08/26 22:46:57 Training policy...
2017/08/26 22:47:02 step 0: objective=1.267595
2017/08/26 22:47:04 step 1: objective=1.2799906
2017/08/26 22:47:06 step 2: objective=1.288351
2017/08/26 22:47:07 step 3: objective=1.2959658
2017/08/26 22:47:09 step 4: objective=1.3039018
2017/08/26 22:47:11 step 5: objective=1.3104442
2017/08/26 22:47:13 step 6: objective=1.3162898
2017/08/26 22:47:14 step 7: objective=1.3206867
2017/08/26 22:47:14 Training value function...
2017/08/26 22:47:18 step 0: mse=61.915510 step=0.100000
2017/08/26 22:47:19 step 1: mse=61.034519 step=0.100000
2017/08/26 22:47:21 step 2: mse=60.273494 step=0.100000
2017/08/26 22:47:23 step 3: mse=59.634126 step=0.100000
2017/08/26 22:47:24 step 4: mse=59.043494 step=0.100000
2017/08/26 22:47:26 step 5: mse=58.443623 step=0.100000
2017/08/26 22:47:28 step 6: mse=57.918226 step=0.100000
2017/08/26 22:47:29 step 7: mse=57.445506 step=0.100000
2017/08/26 22:47:29 Saving...
2017/08/26 22:47:29 Gathering batch of experience...
2017/08/26 22:48:58 batch 3: mean=86.500000 stddev=36.714711 entropy=0.966173 frames=4690 count=50
2017/08/26 22:48:58 Training policy...
2017/08/26 22:49:04 step 0: objective=1.2145954
2017/08/26 22:49:06 step 1: objective=1.2254038
2017/08/26 22:49:07 step 2: objective=1.2346654
2017/08/26 22:49:09 step 3: objective=1.24222
2017/08/26 22:49:11 step 4: objective=1.2479439
2017/08/26 22:49:13 step 5: objective=1.2535332
2017/08/26 22:49:15 step 6: objective=1.2579378
2017/08/26 22:49:17 step 7: objective=1.2626641
2017/08/26 22:49:17 Training value function...
2017/08/26 22:49:20 step 0: mse=62.869214 step=0.100000
2017/08/26 22:49:22 step 1: mse=62.162683 step=0.100000
2017/08/26 22:49:23 step 2: mse=61.490398 step=0.100000
2017/08/26 22:49:25 step 3: mse=60.889367 step=0.100000
2017/08/26 22:49:27 step 4: mse=60.330828 step=0.100000
2017/08/26 22:49:28 step 5: mse=59.852291 step=0.100000
2017/08/26 22:49:30 step 6: mse=59.446820 step=0.100000
2017/08/26 22:49:32 step 7: mse=59.029173 step=0.100000
2017/08/26 22:49:32 Saving...
2017/08/26 22:49:32 Gathering batch of experience...
2017/08/26 22:50:54 batch 4: mean=94.651163 stddev=43.616662 entropy=0.946372 frames=4395 count=43
2017/08/26 22:50:54 Training policy...
2017/08/26 22:50:59 step 0: objective=1.3961469
2017/08/26 22:51:01 step 1: objective=1.4081577
2017/08/26 22:51:03 step 2: objective=1.4178598
2017/08/26 22:51:04 step 3: objective=1.4258206
2017/08/26 22:51:06 step 4: objective=1.4322715
2017/08/26 22:51:08 step 5: objective=1.4388906
2017/08/26 22:51:10 step 6: objective=1.4446727
2017/08/26 22:51:11 step 7: objective=1.4482038
2017/08/26 22:51:11 Training value function...
2017/08/26 22:51:15 step 0: mse=72.465253 step=0.100000
2017/08/26 22:51:16 step 1: mse=71.188982 step=0.100000
2017/08/26 22:51:18 step 2: mse=70.069787 step=0.100000
2017/08/26 22:51:19 step 3: mse=69.086480 step=0.100000
2017/08/26 22:51:21 step 4: mse=68.176662 step=0.100000
2017/08/26 22:51:23 step 5: mse=67.376868 step=0.100000
2017/08/26 22:51:24 step 6: mse=66.568262 step=0.100000
2017/08/26 22:51:26 step 7: mse=65.887631 step=0.100000
2017/08/26 22:51:26 Saving...
2017/08/26 22:51:26 Gathering batch of experience...
2017/08/26 22:52:51 batch 5: mean=88.804348 stddev=39.048253 entropy=0.958602 frames=4424 count=46
2017/08/26 22:52:51 Training policy...
2017/08/26 22:52:56 step 0: objective=0.90917176
2017/08/26 22:52:57 step 1: objective=0.92315704
2017/08/26 22:52:59 step 2: objective=0.93137157
2017/08/26 22:53:01 step 3: objective=0.9420485
2017/08/26 22:53:03 step 4: objective=0.9493831
2017/08/26 22:53:04 step 5: objective=0.95415014
2017/08/26 22:53:06 step 6: objective=0.959471
2017/08/26 22:53:08 step 7: objective=0.96605694
2017/08/26 22:53:08 Training value function...
2017/08/26 22:53:11 step 0: mse=62.366518 step=0.100000
2017/08/26 22:53:13 step 1: mse=61.917016 step=0.100000
2017/08/26 22:53:14 step 2: mse=61.618264 step=0.100000
2017/08/26 22:53:16 step 3: mse=61.293878 step=0.100000
2017/08/26 22:53:17 step 4: mse=61.049775 step=0.100000
2017/08/26 22:53:19 step 5: mse=60.774146 step=0.100000
2017/08/26 22:53:21 step 6: mse=60.566883 step=0.100000
2017/08/26 22:53:22 step 7: mse=60.178918 step=0.100000
2017/08/26 22:53:22 Saving...
2017/08/26 22:53:22 Gathering batch of experience...
2017/08/26 22:54:50 batch 6: mean=108.615385 stddev=55.065283 entropy=0.929820 frames=4553 count=39
2017/08/26 22:54:50 Training policy...
2017/08/26 22:54:55 step 0: objective=1.87116
2017/08/26 22:54:57 step 1: objective=1.8839917
2017/08/26 22:54:59 step 2: objective=1.892466
2017/08/26 22:55:01 step 3: objective=1.9002074
2017/08/26 22:55:02 step 4: objective=1.9057938
2017/08/26 22:55:04 step 5: objective=1.9113789
2017/08/26 22:55:06 step 6: objective=1.9172611
2017/08/26 22:55:08 step 7: objective=1.922266
2017/08/26 22:55:08 Training value function...
2017/08/26 22:55:11 step 0: mse=83.593610 step=0.100000
2017/08/26 22:55:13 step 1: mse=80.772733 step=0.100000
2017/08/26 22:55:15 step 2: mse=78.195558 step=0.100000
2017/08/26 22:55:16 step 3: mse=76.020713 step=0.100000
2017/08/26 22:55:18 step 4: mse=74.095540 step=0.100000
2017/08/26 22:55:20 step 5: mse=72.498409 step=0.100000
2017/08/26 22:55:21 step 6: mse=70.972883 step=0.100000
2017/08/26 22:55:23 step 7: mse=69.615472 step=0.100000
2017/08/26 22:55:23 Saving...
2017/08/26 22:55:23 Gathering batch of experience...
2017/08/26 22:56:52 batch 7: mean=110.950000 stddev=49.460060 entropy=0.922837 frames=4772 count=40
2017/08/26 22:56:52 Training policy...
2017/08/26 22:56:57 step 0: objective=1.3977627
2017/08/26 22:56:59 step 1: objective=1.4086744
2017/08/26 22:57:01 step 2: objective=1.4163669
2017/08/26 22:57:03 step 3: objective=1.4235562
2017/08/26 22:57:05 step 4: objective=1.4304156
2017/08/26 22:57:07 step 5: objective=1.4351425
2017/08/26 22:57:08 step 6: objective=1.4402531
2017/08/26 22:57:10 step 7: objective=1.4451557
2017/08/26 22:57:10 Training value function...
2017/08/26 22:57:14 step 0: mse=70.038066 step=0.100000
2017/08/26 22:57:16 step 1: mse=68.753171 step=0.100000
2017/08/26 22:57:17 step 2: mse=67.575698 step=0.100000
2017/08/26 22:57:19 step 3: mse=66.614601 step=0.100000
2017/08/26 22:57:21 step 4: mse=65.655774 step=0.100000
2017/08/26 22:57:23 step 5: mse=64.910970 step=0.100000
2017/08/26 22:57:24 step 6: mse=64.114994 step=0.100000
2017/08/26 22:57:26 step 7: mse=63.437227 step=0.100000
2017/08/26 22:57:26 Saving...
2017/08/26 22:57:26 Gathering batch of experience...
2017/08/26 22:58:52 batch 8: mean=90.130435 stddev=38.022081 entropy=0.943547 frames=4489 count=46
2017/08/26 22:58:52 Training policy...
2017/08/26 22:58:57 step 0: objective=0.19420215
2017/08/26 22:58:59 step 1: objective=0.20821765
2017/08/26 22:59:01 step 2: objective=0.2177005
2017/08/26 22:59:03 step 3: objective=0.22391504
2017/08/26 22:59:04 step 4: objective=0.23227347
2017/08/26 22:59:06 step 5: objective=0.2378969
2017/08/26 22:59:08 step 6: objective=0.24281381
2017/08/26 22:59:10 step 7: objective=0.24787687
2017/08/26 22:59:10 Training value function...
2017/08/26 22:59:13 step 0: mse=58.143604 step=0.100000
2017/08/26 22:59:15 step 1: mse=57.702275 step=0.100000
2017/08/26 22:59:16 step 2: mse=57.072677 step=0.100000
2017/08/26 22:59:18 step 3: mse=56.763481 step=0.100000
2017/08/26 22:59:20 step 4: mse=56.451376 step=0.100000
2017/08/26 22:59:21 step 5: mse=56.242788 step=0.100000
2017/08/26 22:59:23 step 6: mse=56.076312 step=0.100000
2017/08/26 22:59:25 step 7: mse=55.944179 step=0.100000
2017/08/26 22:59:25 Saving...
2017/08/26 22:59:25 Gathering batch of experience...
2017/08/26 23:00:46 batch 9: mean=97.023810 stddev=46.132567 entropy=0.939598 frames=4393 count=42
2017/08/26 23:00:46 Training policy...
2017/08/26 23:00:51 step 0: objective=1.106796
2017/08/26 23:00:53 step 1: objective=1.1195694
2017/08/26 23:00:55 step 2: objective=1.1288007
2017/08/26 23:00:57 step 3: objective=1.1341501
2017/08/26 23:00:58 step 4: objective=1.1402944
2017/08/26 23:01:00 step 5: objective=1.1453679
2017/08/26 23:01:02 step 6: objective=1.1493278
2017/08/26 23:01:04 step 7: objective=1.1558323
2017/08/26 23:01:04 Training value function...
2017/08/26 23:01:07 step 0: mse=66.978843 step=0.100000
2017/08/26 23:01:09 step 1: mse=66.211900 step=0.100000
2017/08/26 23:01:10 step 2: mse=65.520397 step=0.100000
2017/08/26 23:01:12 step 3: mse=64.892870 step=0.100000
2017/08/26 23:01:14 step 4: mse=64.230166 step=0.100000
2017/08/26 23:01:15 step 5: mse=63.757386 step=0.100000
2017/08/26 23:01:17 step 6: mse=63.293272 step=0.100000
2017/08/26 23:01:18 step 7: mse=62.880251 step=0.100000
2017/08/26 23:01:18 Saving...
2017/08/26 23:01:18 Gathering batch of experience...
2017/08/26 23:02:47 batch 10: mean=103.214286 stddev=54.483084 entropy=0.934945 frames=4663 count=42
2017/08/26 23:02:47 Training policy...
2017/08/26 23:02:53 step 0: objective=1.29491
2017/08/26 23:02:54 step 1: objective=1.3061217
2017/08/26 23:02:56 step 2: objective=1.3167331
2017/08/26 23:02:58 step 3: objective=1.3223628
2017/08/26 23:03:00 step 4: objective=1.3308569
2017/08/26 23:03:02 step 5: objective=1.3368727
2017/08/26 23:03:04 step 6: objective=1.3427658
2017/08/26 23:03:06 step 7: objective=1.347884
2017/08/26 23:03:06 Training value function...
2017/08/26 23:03:09 step 0: mse=76.004762 step=0.100000
2017/08/26 23:03:11 step 1: mse=74.437358 step=0.100000
2017/08/26 23:03:13 step 2: mse=73.196480 step=0.100000
2017/08/26 23:03:14 step 3: mse=71.803645 step=0.100000
2017/08/26 23:03:16 step 4: mse=70.799200 step=0.100000
2017/08/26 23:03:18 step 5: mse=70.118524 step=0.100000
2017/08/26 23:03:20 step 6: mse=69.285448 step=0.100000
2017/08/26 23:03:21 step 7: mse=68.573352 step=0.100000
2017/08/26 23:03:21 Saving...
2017/08/26 23:03:21 Gathering batch of experience...
2017/08/26 23:04:53 batch 11: mean=98.600000 stddev=57.880490 entropy=0.926731 frames=4774 count=45
2017/08/26 23:04:53 Training policy...
2017/08/26 23:04:59 step 0: objective=0.95063585
2017/08/26 23:05:01 step 1: objective=0.96648717
2017/08/26 23:05:03 step 2: objective=0.9767555
2017/08/26 23:05:05 step 3: objective=0.98371303
2017/08/26 23:05:07 step 4: objective=0.9910108
2017/08/26 23:05:09 step 5: objective=0.99500793
2017/08/26 23:05:10 step 6: objective=1.0012023
2017/08/26 23:05:12 step 7: objective=1.0067304
2017/08/26 23:05:12 Training value function...
2017/08/26 23:05:16 step 0: mse=75.541911 step=0.100000
2017/08/26 23:05:18 step 1: mse=74.145120 step=0.100000
2017/08/26 23:05:19 step 2: mse=72.838074 step=0.100000
2017/08/26 23:05:21 step 3: mse=71.665614 step=0.100000
2017/08/26 23:05:23 step 4: mse=70.838213 step=0.100000
2017/08/26 23:05:25 step 5: mse=70.193843 step=0.100000
2017/08/26 23:05:26 step 6: mse=69.570882 step=0.100000
2017/08/26 23:05:28 step 7: mse=68.805194 step=0.100000
2017/08/26 23:05:28 Saving...
2017/08/26 23:05:28 Gathering batch of experience...
2017/08/26 23:07:10 batch 12: mean=102.177778 stddev=52.366779 entropy=0.933375 frames=4948 count=45
2017/08/26 23:07:10 Training policy...
2017/08/26 23:07:16 step 0: objective=1.1054127
2017/08/26 23:07:18 step 1: objective=1.1177313
2017/08/26 23:07:20 step 2: objective=1.1273122
2017/08/26 23:07:22 step 3: objective=1.1342717
2017/08/26 23:07:24 step 4: objective=1.1413116
2017/08/26 23:07:26 step 5: objective=1.1470239
2017/08/26 23:07:27 step 6: objective=1.1526488
2017/08/26 23:07:29 step 7: objective=1.1576678
2017/08/26 23:07:29 Training value function...
2017/08/26 23:07:33 step 0: mse=70.986291 step=0.100000
2017/08/26 23:07:35 step 1: mse=70.483560 step=0.100000
2017/08/26 23:07:37 step 2: mse=69.926854 step=0.100000
2017/08/26 23:07:39 step 3: mse=69.378074 step=0.100000
2017/08/26 23:07:40 step 4: mse=68.863234 step=0.100000
2017/08/26 23:07:42 step 5: mse=68.451027 step=0.100000
2017/08/26 23:07:44 step 6: mse=68.011452 step=0.100000
2017/08/26 23:07:46 step 7: mse=67.603556 step=0.100000
2017/08/26 23:07:46 Saving...
2017/08/26 23:07:46 Gathering batch of experience...
2017/08/26 23:09:12 batch 13: mean=124.235294 stddev=66.011612 entropy=0.906925 frames=4510 count=34
2017/08/26 23:09:12 Training policy...
2017/08/26 23:09:18 step 0: objective=1.7619754
2017/08/26 23:09:20 step 1: objective=1.7750341
2017/08/26 23:09:21 step 2: objective=1.7842244
2017/08/26 23:09:23 step 3: objective=1.7900798
2017/08/26 23:09:25 step 4: objective=1.7956169
2017/08/26 23:09:27 step 5: objective=1.8000499
2017/08/26 23:09:28 step 6: objective=1.8047575
2017/08/26 23:09:30 step 7: objective=1.8084165
2017/08/26 23:09:30 Training value function...
2017/08/26 23:09:34 step 0: mse=82.628506 step=0.100000
2017/08/26 23:09:35 step 1: mse=80.241117 step=0.100000
2017/08/26 23:09:37 step 2: mse=78.031663 step=0.100000
2017/08/26 23:09:39 step 3: mse=76.215541 step=0.100000
2017/08/26 23:09:40 step 4: mse=74.598307 step=0.100000
2017/08/26 23:09:42 step 5: mse=73.221240 step=0.100000
2017/08/26 23:09:44 step 6: mse=71.996755 step=0.100000
2017/08/26 23:09:45 step 7: mse=70.745001 step=0.100000
2017/08/26 23:09:45 Saving...
2017/08/26 23:09:45 Gathering batch of experience...
2017/08/26 23:11:11 batch 14: mean=109.868421 stddev=68.861100 entropy=0.918198 frames=4465 count=38
2017/08/26 23:11:11 Training policy...
2017/08/26 23:11:16 step 0: objective=0.8903483
2017/08/26 23:11:18 step 1: objective=0.90260595
2017/08/26 23:11:20 step 2: objective=0.911914
2017/08/26 23:11:22 step 3: objective=0.9195498
2017/08/26 23:11:24 step 4: objective=0.9263027
2017/08/26 23:11:25 step 5: objective=0.9310723
2017/08/26 23:11:27 step 6: objective=0.9365851
2017/08/26 23:11:29 step 7: objective=0.9412996
2017/08/26 23:11:29 Training value function...
2017/08/26 23:11:32 step 0: mse=79.772224 step=0.100000
2017/08/26 23:11:34 step 1: mse=78.730831 step=0.100000
2017/08/26 23:11:36 step 2: mse=77.894833 step=0.100000
2017/08/26 23:11:37 step 3: mse=76.752017 step=0.100000
2017/08/26 23:11:39 step 4: mse=75.680226 step=0.100000
2017/08/26 23:11:41 step 5: mse=74.874230 step=0.100000
2017/08/26 23:11:42 step 6: mse=74.136650 step=0.100000
2017/08/26 23:11:44 step 7: mse=73.544499 step=0.100000
2017/08/26 23:11:44 Saving...
2017/08/26 23:11:44 Gathering batch of experience...
2017/08/26 23:13:14 batch 15: mean=118.783784 stddev=58.619771 entropy=0.902064 frames=4707 count=37
2017/08/26 23:13:14 Training policy...
2017/08/26 23:13:19 step 0: objective=1.0821149
2017/08/26 23:13:21 step 1: objective=1.0977355
2017/08/26 23:13:23 step 2: objective=1.1078849
2017/08/26 23:13:25 step 3: objective=1.1149573
2017/08/26 23:13:27 step 4: objective=1.1208895
2017/08/26 23:13:29 step 5: objective=1.1262383
2017/08/26 23:13:31 step 6: objective=1.1299257
2017/08/26 23:13:33 step 7: objective=1.1339958
2017/08/26 23:13:33 Training value function...
2017/08/26 23:13:36 step 0: mse=71.296281 step=0.100000
2017/08/26 23:13:38 step 1: mse=70.030775 step=0.100000
2017/08/26 23:13:40 step 2: mse=68.849921 step=0.100000
2017/08/26 23:13:42 step 3: mse=67.807726 step=0.100000
2017/08/26 23:13:43 step 4: mse=67.212507 step=0.100000
2017/08/26 23:13:45 step 5: mse=66.440864 step=0.100000
2017/08/26 23:13:47 step 6: mse=65.619341 step=0.100000
2017/08/26 23:13:49 step 7: mse=65.143802 step=0.100000
2017/08/26 23:13:49 Saving...
2017/08/26 23:13:49 Gathering batch of experience...
2017/08/26 23:15:16 batch 16: mean=118.277778 stddev=73.037514 entropy=0.892954 frames=4543 count=36
2017/08/26 23:15:16 Training policy...
2017/08/26 23:15:21 step 0: objective=1.1168258
2017/08/26 23:15:23 step 1: objective=1.1295999
2017/08/26 23:15:25 step 2: objective=1.1374975
2017/08/26 23:15:27 step 3: objective=1.1451763
2017/08/26 23:15:29 step 4: objective=1.1511834
2017/08/26 23:15:30 step 5: objective=1.1579429
2017/08/26 23:15:32 step 6: objective=1.1652344
2017/08/26 23:15:34 step 7: objective=1.1695904
2017/08/26 23:15:34 Training value function...
2017/08/26 23:15:38 step 0: mse=77.429602 step=0.100000
2017/08/26 23:15:39 step 1: mse=75.578269 step=0.100000
2017/08/26 23:15:41 step 2: mse=74.786243 step=0.100000
2017/08/26 23:15:43 step 3: mse=73.434316 step=0.100000
2017/08/26 23:15:44 step 4: mse=72.252571 step=0.100000
2017/08/26 23:15:46 step 5: mse=71.288020 step=0.100000
2017/08/26 23:15:48 step 6: mse=70.548105 step=0.100000
2017/08/26 23:15:49 step 7: mse=70.095146 step=0.100000
2017/08/26 23:15:49 Saving...
2017/08/26 23:15:49 Gathering batch of experience...
2017/08/26 23:17:16 batch 17: mean=134.272727 stddev=87.828784 entropy=0.878640 frames=4700 count=33
2017/08/26 23:17:16 Training policy...
2017/08/26 23:17:21 step 0: objective=1.4580684
2017/08/26 23:17:23 step 1: objective=1.4689815
2017/08/26 23:17:25 step 2: objective=1.4795278
2017/08/26 23:17:27 step 3: objective=1.4867431
2017/08/26 23:17:29 step 4: objective=1.4932396
2017/08/26 23:17:31 step 5: objective=1.4982238
2017/08/26 23:17:32 step 6: objective=1.5021752
2017/08/26 23:17:34 step 7: objective=1.5068002
2017/08/26 23:17:34 Training value function...
2017/08/26 23:17:38 step 0: mse=79.285562 step=0.100000
2017/08/26 23:17:40 step 1: mse=77.606896 step=0.100000
2017/08/26 23:17:41 step 2: mse=76.011074 step=0.100000
2017/08/26 23:17:43 step 3: mse=74.193436 step=0.100000
2017/08/26 23:17:45 step 4: mse=72.973297 step=0.100000
2017/08/26 23:17:47 step 5: mse=71.795879 step=0.100000
2017/08/26 23:17:48 step 6: mse=70.997335 step=0.100000
2017/08/26 23:17:50 step 7: mse=70.213586 step=0.100000
2017/08/26 23:17:50 Saving...
2017/08/26 23:17:50 Gathering batch of experience...
2017/08/26 23:19:29 batch 18: mean=159.551724 stddev=85.717896 entropy=0.872155 frames=4887 count=29
2017/08/26 23:19:29 Training policy...
2017/08/26 23:19:35 step 0: objective=1.574882
2017/08/26 23:19:37 step 1: objective=1.5849767
2017/08/26 23:19:39 step 2: objective=1.5931145
2017/08/26 23:19:41 step 3: objective=1.5985706
2017/08/26 23:19:43 step 4: objective=1.6036962
2017/08/26 23:19:44 step 5: objective=1.6085619
2017/08/26 23:19:46 step 6: objective=1.613545
2017/08/26 23:19:48 step 7: objective=1.6177595
2017/08/26 23:19:48 Training value function...
2017/08/26 23:19:52 step 0: mse=74.413853 step=0.100000
2017/08/26 23:19:54 step 1: mse=72.611668 step=0.100000
2017/08/26 23:19:56 step 2: mse=71.021265 step=0.100000
2017/08/26 23:19:58 step 3: mse=69.623471 step=0.100000
2017/08/26 23:19:59 step 4: mse=68.395388 step=0.100000
2017/08/26 23:20:01 step 5: mse=67.232813 step=0.100000
2017/08/26 23:20:03 step 6: mse=66.260909 step=0.100000
2017/08/26 23:20:05 step 7: mse=65.380694 step=0.100000
2017/08/26 23:20:05 Saving...
2017/08/26 23:20:05 Gathering batch of experience...
2017/08/26 23:21:35 batch 19: mean=123.805556 stddev=70.826399 entropy=0.890918 frames=4750 count=36
2017/08/26 23:21:35 Training policy...
2017/08/26 23:21:40 step 0: objective=0.43153027
2017/08/26 23:21:42 step 1: objective=0.44341725
2017/08/26 23:21:44 step 2: objective=0.4530204
2017/08/26 23:21:46 step 3: objective=0.45900163
2017/08/26 23:21:48 step 4: objective=0.4654486
2017/08/26 23:21:50 step 5: objective=0.4708239
2017/08/26 23:21:52 step 6: objective=0.47585028
2017/08/26 23:21:54 step 7: objective=0.4800624
2017/08/26 23:21:54 Training value function...
2017/08/26 23:21:57 step 0: mse=66.926006 step=0.100000
2017/08/26 23:21:59 step 1: mse=66.309310 step=0.100000
2017/08/26 23:22:01 step 2: mse=65.839709 step=0.100000
2017/08/26 23:22:03 step 3: mse=65.425041 step=0.100000
2017/08/26 23:22:04 step 4: mse=65.083040 step=0.100000
2017/08/26 23:22:06 step 5: mse=64.845316 step=0.100000
2017/08/26 23:22:08 step 6: mse=64.470819 step=0.100000
2017/08/26 23:22:10 step 7: mse=64.223077 step=0.100000
2017/08/26 23:22:10 Saving...
2017/08/26 23:22:10 Gathering batch of experience...
2017/08/26 23:23:39 batch 20: mean=142.290323 stddev=84.750181 entropy=0.870918 frames=4673 count=31
2017/08/26 23:23:39 Training policy...
2017/08/26 23:23:45 step 0: objective=1.2142785
2017/08/26 23:23:47 step 1: objective=1.2238473
2017/08/26 23:23:49 step 2: objective=1.2317029
2017/08/26 23:23:50 step 3: objective=1.2399281
2017/08/26 23:23:52 step 4: objective=1.2464929
2017/08/26 23:23:54 step 5: objective=1.2520851
2017/08/26 23:23:56 step 6: objective=1.259504
2017/08/26 23:23:58 step 7: objective=1.2619077
2017/08/26 23:23:58 Training value function...
2017/08/26 23:24:02 step 0: mse=73.139817 step=0.100000
2017/08/26 23:24:03 step 1: mse=72.010910 step=0.100000
2017/08/26 23:24:05 step 2: mse=70.831871 step=0.100000
2017/08/26 23:24:07 step 3: mse=69.525259 step=0.100000
2017/08/26 23:24:09 step 4: mse=68.361699 step=0.100000
2017/08/26 23:24:10 step 5: mse=67.575631 step=0.100000
2017/08/26 23:24:12 step 6: mse=66.883459 step=0.100000
2017/08/26 23:24:14 step 7: mse=66.057849 step=0.100000
2017/08/26 23:24:14 Saving...
2017/08/26 23:24:14 Gathering batch of experience...
2017/08/26 23:25:54 batch 21: mean=138.970588 stddev=73.876879 entropy=0.866979 frames=5022 count=34
2017/08/26 23:25:54 Training policy...
2017/08/26 23:26:00 step 0: objective=1.0461984
2017/08/26 23:26:02 step 1: objective=1.0604349
2017/08/26 23:26:04 step 2: objective=1.0669062
2017/08/26 23:26:06 step 3: objective=1.0723989
2017/08/26 23:26:08 step 4: objective=1.0770338
2017/08/26 23:26:11 step 5: objective=1.0826273
2017/08/26 23:26:13 step 6: objective=1.0873767
2017/08/26 23:26:15 step 7: objective=1.091455
2017/08/26 23:26:15 Training value function...
2017/08/26 23:26:18 step 0: mse=71.445218 step=0.100000
2017/08/26 23:26:20 step 1: mse=70.077901 step=0.100000
2017/08/26 23:26:22 step 2: mse=68.894266 step=0.100000
2017/08/26 23:26:24 step 3: mse=68.124613 step=0.100000
2017/08/26 23:26:26 step 4: mse=67.161848 step=0.100000
2017/08/26 23:26:28 step 5: mse=66.367375 step=0.100000
2017/08/26 23:26:30 step 6: mse=65.781318 step=0.100000
2017/08/26 23:26:32 step 7: mse=65.314953 step=0.100000
2017/08/26 23:26:32 Saving...
2017/08/26 23:26:32 Gathering batch of experience...
2017/08/26 23:28:02 batch 22: mean=137.575758 stddev=68.136241 entropy=0.866475 frames=4836 count=33
2017/08/26 23:28:02 Training policy...
2017/08/26 23:28:08 step 0: objective=0.8389178
2017/08/26 23:28:10 step 1: objective=0.8503895
2017/08/26 23:28:12 step 2: objective=0.8612088
2017/08/26 23:28:14 step 3: objective=0.8719095
2017/08/26 23:28:16 step 4: objective=0.87820596
2017/08/26 23:28:18 step 5: objective=0.8824505
2017/08/26 23:28:20 step 6: objective=0.88625056
2017/08/26 23:28:22 step 7: objective=0.8912821
2017/08/26 23:28:22 Training value function...
2017/08/26 23:28:25 step 0: mse=67.265602 step=0.100000
2017/08/26 23:28:27 step 1: mse=66.712388 step=0.100000
2017/08/26 23:28:29 step 2: mse=66.043874 step=0.100000
2017/08/26 23:28:31 step 3: mse=65.584587 step=0.100000
2017/08/26 23:28:33 step 4: mse=65.107946 step=0.100000
2017/08/26 23:28:34 step 5: mse=64.522630 step=0.100000
2017/08/26 23:28:36 step 6: mse=63.970685 step=0.100000
2017/08/26 23:28:38 step 7: mse=63.659293 step=0.100000
2017/08/26 23:28:38 Saving...
2017/08/26 23:28:38 Gathering batch of experience...
2017/08/26 23:30:10 batch 23: mean=156.107143 stddev=80.798842 entropy=0.866589 frames=4622 count=28
2017/08/26 23:30:10 Training policy...
2017/08/26 23:30:16 step 0: objective=1.4216176
2017/08/26 23:30:18 step 1: objective=1.4327974
2017/08/26 23:30:20 step 2: objective=1.4411451
2017/08/26 23:30:21 step 3: objective=1.4491551
2017/08/26 23:30:23 step 4: objective=1.4543543
2017/08/26 23:30:25 step 5: objective=1.4598508
2017/08/26 23:30:27 step 6: objective=1.4644479
2017/08/26 23:30:29 step 7: objective=1.4692531
2017/08/26 23:30:29 Training value function...
2017/08/26 23:30:33 step 0: mse=73.457189 step=0.100000
2017/08/26 23:30:34 step 1: mse=72.018834 step=0.100000
2017/08/26 23:30:36 step 2: mse=70.682394 step=0.100000
2017/08/26 23:30:38 step 3: mse=69.525611 step=0.100000
2017/08/26 23:30:40 step 4: mse=68.588060 step=0.100000
2017/08/26 23:30:41 step 5: mse=67.662128 step=0.100000
2017/08/26 23:30:43 step 6: mse=66.763993 step=0.100000
2017/08/26 23:30:45 step 7: mse=65.948727 step=0.100000
2017/08/26 23:30:45 Saving...
2017/08/26 23:30:45 Gathering batch of experience...
2017/08/26 23:32:18 batch 24: mean=169.481481 stddev=95.656163 entropy=0.853001 frames=4814 count=27
2017/08/26 23:32:18 Training policy...
2017/08/26 23:32:24 step 0: objective=1.4131407
2017/08/26 23:32:26 step 1: objective=1.4238142
2017/08/26 23:32:27 step 2: objective=1.4318459
2017/08/26 23:32:29 step 3: objective=1.4387443
2017/08/26 23:32:31 step 4: objective=1.4439723
2017/08/26 23:32:33 step 5: objective=1.4488088
2017/08/26 23:32:35 step 6: objective=1.4538211
2017/08/26 23:32:37 step 7: objective=1.459052
2017/08/26 23:32:37 Training value function...
2017/08/26 23:32:41 step 0: mse=74.166025 step=0.100000
2017/08/26 23:32:43 step 1: mse=72.825537 step=0.100000
2017/08/26 23:32:45 step 2: mse=71.453793 step=0.100000
2017/08/26 23:32:47 step 3: mse=70.257976 step=0.100000
2017/08/26 23:32:48 step 4: mse=69.167449 step=0.100000
2017/08/26 23:32:50 step 5: mse=68.253196 step=0.100000
2017/08/26 23:32:52 step 6: mse=67.401236 step=0.100000
2017/08/26 23:32:54 step 7: mse=66.569296 step=0.100000
2017/08/26 23:32:54 Saving...
2017/08/26 23:32:54 Gathering batch of experience...
2017/08/26 23:34:28 batch 25: mean=151.161290 stddev=80.631818 entropy=0.853585 frames=4958 count=31
2017/08/26 23:34:28 Training policy...
2017/08/26 23:34:34 step 0: objective=0.6986841
2017/08/26 23:34:36 step 1: objective=0.7080516
2017/08/26 23:34:38 step 2: objective=0.714864
2017/08/26 23:34:40 step 3: objective=0.72132033
2017/08/26 23:34:42 step 4: objective=0.72989595
2017/08/26 23:34:44 step 5: objective=0.7352379
2017/08/26 23:34:46 step 6: objective=0.74019885
2017/08/26 23:34:48 step 7: objective=0.74393815
2017/08/26 23:34:48 Training value function...
2017/08/26 23:34:51 step 0: mse=64.661012 step=0.100000
2017/08/26 23:34:53 step 1: mse=64.249489 step=0.100000
2017/08/26 23:34:55 step 2: mse=63.862674 step=0.100000
2017/08/26 23:34:57 step 3: mse=63.602270 step=0.100000
2017/08/26 23:34:59 step 4: mse=63.373473 step=0.100000
2017/08/26 23:35:01 step 5: mse=63.187167 step=0.100000
2017/08/26 23:35:03 step 6: mse=63.031514 step=0.100000
2017/08/26 23:35:05 step 7: mse=62.893632 step=0.100000
2017/08/26 23:35:05 Saving...
2017/08/26 23:35:05 Gathering batch of experience...
2017/08/26 23:36:37 batch 26: mean=143.419355 stddev=69.881824 entropy=0.863111 frames=4726 count=31
2017/08/26 23:36:37 Training policy...
2017/08/26 23:36:42 step 0: objective=0.7337284
2017/08/26 23:36:44 step 1: objective=0.745399
2017/08/26 23:36:46 step 2: objective=0.7530876
2017/08/26 23:36:48 step 3: objective=0.7594805
2017/08/26 23:36:50 step 4: objective=0.7641136
2017/08/26 23:36:52 step 5: objective=0.7697358
2017/08/26 23:36:54 step 6: objective=0.7740057
2017/08/26 23:36:56 step 7: objective=0.7778837
2017/08/26 23:36:56 Training value function...
2017/08/26 23:36:59 step 0: mse=62.325932 step=0.100000
2017/08/26 23:37:01 step 1: mse=61.672704 step=0.100000
2017/08/26 23:37:03 step 2: mse=60.872716 step=0.100000
2017/08/26 23:37:05 step 3: mse=60.261257 step=0.100000
2017/08/26 23:37:07 step 4: mse=59.597483 step=0.100000
2017/08/26 23:37:08 step 5: mse=59.012950 step=0.100000
2017/08/26 23:37:10 step 6: mse=58.709556 step=0.100000
2017/08/26 23:37:12 step 7: mse=58.068860 step=0.100000
2017/08/26 23:37:12 Saving...
2017/08/26 23:37:12 Gathering batch of experience...
2017/08/26 23:38:40 batch 27: mean=148.066667 stddev=89.004469 entropy=0.860420 frames=4697 count=30
2017/08/26 23:38:40 Training policy...
2017/08/26 23:38:46 step 0: objective=1.0433375
2017/08/26 23:38:48 step 1: objective=1.0562087
2017/08/26 23:38:50 step 2: objective=1.0672318
2017/08/26 23:38:51 step 3: objective=1.075086
2017/08/26 23:38:53 step 4: objective=1.0799413
2017/08/26 23:38:55 step 5: objective=1.085231
2017/08/26 23:38:57 step 6: objective=1.0899888
2017/08/26 23:38:59 step 7: objective=1.0937483
2017/08/26 23:38:59 Training value function...
2017/08/26 23:39:03 step 0: mse=76.228268 step=0.100000
2017/08/26 23:39:05 step 1: mse=74.825481 step=0.100000
2017/08/26 23:39:06 step 2: mse=73.851062 step=0.100000
2017/08/26 23:39:08 step 3: mse=72.992770 step=0.100000
2017/08/26 23:39:10 step 4: mse=72.055026 step=0.100000
2017/08/26 23:39:12 step 5: mse=71.525173 step=0.100000
2017/08/26 23:39:14 step 6: mse=70.777876 step=0.100000
2017/08/26 23:39:16 step 7: mse=70.090537 step=0.100000
2017/08/26 23:39:16 Saving...
2017/08/26 23:39:16 Gathering batch of experience...
2017/08/26 23:40:44 batch 28: mean=135.718750 stddev=63.279753 entropy=0.859647 frames=4628 count=32
2017/08/26 23:40:44 Training policy...
2017/08/26 23:40:49 step 0: objective=0.6762075
2017/08/26 23:40:51 step 1: objective=0.6868504
2017/08/26 23:40:53 step 2: objective=0.6968891
2017/08/26 23:40:55 step 3: objective=0.70305157
2017/08/26 23:40:57 step 4: objective=0.7087084
2017/08/26 23:40:58 step 5: objective=0.71371174
2017/08/26 23:41:00 step 6: objective=0.71902126
2017/08/26 23:41:02 step 7: objective=0.7245604
2017/08/26 23:41:02 Training value function...
2017/08/26 23:41:06 step 0: mse=65.403855 step=0.100000
2017/08/26 23:41:08 step 1: mse=63.769393 step=0.100000
2017/08/26 23:41:09 step 2: mse=62.374167 step=0.100000
2017/08/26 23:41:11 step 3: mse=61.214418 step=0.100000
2017/08/26 23:41:13 step 4: mse=60.253291 step=0.100000
2017/08/26 23:41:15 step 5: mse=59.330383 step=0.100000
2017/08/26 23:41:17 step 6: mse=58.578745 step=0.100000
2017/08/26 23:41:18 step 7: mse=57.960861 step=0.100000
2017/08/26 23:41:18 Saving...
2017/08/26 23:41:18 Gathering batch of experience...
2017/08/26 23:42:53 batch 29: mean=164.642857 stddev=91.946496 entropy=0.842255 frames=4857 count=28
2017/08/26 23:42:53 Training policy...
2017/08/26 23:42:58 step 0: objective=1.5736575
2017/08/26 23:43:00 step 1: objective=1.5833017
2017/08/26 23:43:02 step 2: objective=1.5910394
2017/08/26 23:43:04 step 3: objective=1.5988263
2017/08/26 23:43:06 step 4: objective=1.6032298
2017/08/26 23:43:08 step 5: objective=1.6078678
2017/08/26 23:43:10 step 6: objective=1.6116669
2017/08/26 23:43:12 step 7: objective=1.6158799
2017/08/26 23:43:12 Training value function...
2017/08/26 23:43:16 step 0: mse=77.009251 step=0.100000
2017/08/26 23:43:18 step 1: mse=74.760232 step=0.100000
2017/08/26 23:43:20 step 2: mse=72.636167 step=0.100000
2017/08/26 23:43:22 step 3: mse=70.866892 step=0.100000
2017/08/26 23:43:24 step 4: mse=69.428034 step=0.100000
2017/08/26 23:43:26 step 5: mse=68.156691 step=0.100000
2017/08/26 23:43:27 step 6: mse=67.070881 step=0.100000
2017/08/26 23:43:29 step 7: mse=66.129393 step=0.100000
2017/08/26 23:43:29 Saving...
2017/08/26 23:43:29 Gathering batch of experience...
2017/08/26 23:45:18 batch 30: mean=183.629630 stddev=107.603920 entropy=0.836045 frames=5187 count=27
2017/08/26 23:45:18 Training policy...
2017/08/26 23:45:24 step 0: objective=1.5772033
2017/08/26 23:45:27 step 1: objective=1.5864822
2017/08/26 23:45:29 step 2: objective=1.5936455
2017/08/26 23:45:31 step 3: objective=1.6015725
2017/08/26 23:45:33 step 4: objective=1.6064657
2017/08/26 23:45:35 step 5: objective=1.6108176
2017/08/26 23:45:37 step 6: objective=1.6152854
2017/08/26 23:45:39 step 7: objective=1.619025
2017/08/26 23:45:39 Training value function...
2017/08/26 23:45:43 step 0: mse=74.458422 step=0.100000
2017/08/26 23:45:45 step 1: mse=72.431575 step=0.100000
2017/08/26 23:45:47 step 2: mse=70.596055 step=0.100000
2017/08/26 23:45:49 step 3: mse=69.157883 step=0.100000
2017/08/26 23:45:51 step 4: mse=67.503331 step=0.100000
2017/08/26 23:45:53 step 5: mse=66.033114 step=0.100000
2017/08/26 23:45:56 step 6: mse=65.007728 step=0.100000
2017/08/26 23:45:58 step 7: mse=63.726106 step=0.100000
2017/08/26 23:45:58 Saving...
2017/08/26 23:45:58 Gathering batch of experience...
2017/08/26 23:47:29 batch 31: mean=138.393939 stddev=71.781630 entropy=0.855263 frames=4858 count=33
2017/08/26 23:47:29 Training policy...
2017/08/26 23:47:35 step 0: objective=0.2984999
2017/08/26 23:47:37 step 1: objective=0.31027976
2017/08/26 23:47:39 step 2: objective=0.32408524
2017/08/26 23:47:41 step 3: objective=0.33056232
2017/08/26 23:47:43 step 4: objective=0.33568916
2017/08/26 23:47:45 step 5: objective=0.34122488
2017/08/26 23:47:47 step 6: objective=0.34565875
2017/08/26 23:47:49 step 7: objective=0.35008243
2017/08/26 23:47:49 Training value function...
2017/08/26 23:47:53 step 0: mse=70.543271 step=0.100000
2017/08/26 23:47:55 step 1: mse=68.810512 step=0.100000
2017/08/26 23:47:57 step 2: mse=67.467842 step=0.100000
2017/08/26 23:47:58 step 3: mse=66.458004 step=0.100000
2017/08/26 23:48:00 step 4: mse=65.559174 step=0.100000
2017/08/26 23:48:02 step 5: mse=64.706982 step=0.100000
2017/08/26 23:48:04 step 6: mse=63.982656 step=0.100000
2017/08/26 23:48:06 step 7: mse=63.513674 step=0.100000
2017/08/26 23:48:06 Saving...
2017/08/26 23:48:06 Gathering batch of experience...
2017/08/26 23:49:37 batch 32: mean=141.242424 stddev=74.055684 entropy=0.851580 frames=4952 count=33
2017/08/26 23:49:37 Training policy...
2017/08/26 23:49:44 step 0: objective=0.75428593
2017/08/26 23:49:46 step 1: objective=0.7657318
2017/08/26 23:49:48 step 2: objective=0.77323264
2017/08/26 23:49:50 step 3: objective=0.7811309
2017/08/26 23:49:52 step 4: objective=0.7870611
2017/08/26 23:49:54 step 5: objective=0.791631
2017/08/26 23:49:56 step 6: objective=0.7963054
2017/08/26 23:49:58 step 7: objective=0.79938984
2017/08/26 23:49:58 Training value function...
2017/08/26 23:50:02 step 0: mse=65.021867 step=0.100000
2017/08/26 23:50:04 step 1: mse=64.614293 step=0.100000
2017/08/26 23:50:05 step 2: mse=64.262742 step=0.100000
2017/08/26 23:50:07 step 3: mse=63.947602 step=0.100000
2017/08/26 23:50:09 step 4: mse=63.499905 step=0.100000
2017/08/26 23:50:11 step 5: mse=63.245005 step=0.100000
2017/08/26 23:50:13 step 6: mse=63.007940 step=0.100000
2017/08/26 23:50:15 step 7: mse=62.816248 step=0.100000
2017/08/26 23:50:15 Saving...
2017/08/26 23:50:15 Gathering batch of experience...
2017/08/26 23:51:50 batch 33: mean=146.129032 stddev=87.545285 entropy=0.853738 frames=4789 count=31
2017/08/26 23:51:50 Training policy...
2017/08/26 23:51:56 step 0: objective=1.2084564
2017/08/26 23:51:58 step 1: objective=1.2190933
2017/08/26 23:52:00 step 2: objective=1.2271411
2017/08/26 23:52:02 step 3: objective=1.2343671
2017/08/26 23:52:04 step 4: objective=1.2389373
2017/08/26 23:52:06 step 5: objective=1.2443159
2017/08/26 23:52:08 step 6: objective=1.249436
2017/08/26 23:52:10 step 7: objective=1.2546968
2017/08/26 23:52:10 Training value function...
2017/08/26 23:52:14 step 0: mse=73.562250 step=0.100000
2017/08/26 23:52:16 step 1: mse=72.460174 step=0.100000
2017/08/26 23:52:17 step 2: mse=71.429681 step=0.100000
2017/08/26 23:52:19 step 3: mse=70.478648 step=0.100000
2017/08/26 23:52:21 step 4: mse=69.598429 step=0.100000
2017/08/26 23:52:23 step 5: mse=68.825245 step=0.100000
2017/08/26 23:52:25 step 6: mse=68.149160 step=0.100000
2017/08/26 23:52:27 step 7: mse=67.512330 step=0.100000
2017/08/26 23:52:27 Saving...
2017/08/26 23:52:27 Gathering batch of experience...
2017/08/26 23:53:56 batch 34: mean=174.500000 stddev=80.493311 entropy=0.839362 frames=4787 count=26
2017/08/26 23:53:56 Training policy...
2017/08/26 23:54:02 step 0: objective=1.451858
2017/08/26 23:54:04 step 1: objective=1.462855
2017/08/26 23:54:06 step 2: objective=1.4710737
2017/08/26 23:54:08 step 3: objective=1.4777656
2017/08/26 23:54:10 step 4: objective=1.4844841
2017/08/26 23:54:12 step 5: objective=1.4886287
2017/08/26 23:54:14 step 6: objective=1.4915648
2017/08/26 23:54:16 step 7: objective=1.4961083
2017/08/26 23:54:16 Training value function...
2017/08/26 23:54:19 step 0: mse=67.610451 step=0.100000
2017/08/26 23:54:21 step 1: mse=66.161477 step=0.100000
2017/08/26 23:54:23 step 2: mse=64.904724 step=0.100000
2017/08/26 23:54:25 step 3: mse=63.702197 step=0.100000
2017/08/26 23:54:27 step 4: mse=62.582923 step=0.100000
2017/08/26 23:54:29 step 5: mse=61.563144 step=0.100000
2017/08/26 23:54:30 step 6: mse=60.556748 step=0.100000
2017/08/26 23:54:32 step 7: mse=59.811955 step=0.100000
2017/08/26 23:54:32 Saving...
2017/08/26 23:54:32 Gathering batch of experience...
2017/08/26 23:56:12 batch 35: mean=185.692308 stddev=95.530410 entropy=0.840124 frames=5063 count=26
2017/08/26 23:56:12 Training policy...
2017/08/26 23:56:19 step 0: objective=1.4190267
2017/08/26 23:56:21 step 1: objective=1.4277806
2017/08/26 23:56:23 step 2: objective=1.4357853
2017/08/26 23:56:25 step 3: objective=1.442228
2017/08/26 23:56:27 step 4: objective=1.4470265
2017/08/26 23:56:29 step 5: objective=1.4513311
2017/08/26 23:56:31 step 6: objective=1.4550532
2017/08/26 23:56:33 step 7: objective=1.4617966
2017/08/26 23:56:33 Training value function...
2017/08/26 23:56:37 step 0: mse=67.038355 step=0.100000
2017/08/26 23:56:40 step 1: mse=64.785622 step=0.100000
2017/08/26 23:56:42 step 2: mse=63.080329 step=0.100000
2017/08/26 23:56:44 step 3: mse=61.525663 step=0.100000
2017/08/26 23:56:46 step 4: mse=60.123046 step=0.100000
2017/08/26 23:56:48 step 5: mse=58.896058 step=0.100000
2017/08/26 23:56:50 step 6: mse=57.845767 step=0.100000
2017/08/26 23:56:52 step 7: mse=56.917797 step=0.100000
2017/08/26 23:56:52 Saving...
2017/08/26 23:56:52 Gathering batch of experience...
2017/08/26 23:58:27 batch 36: mean=189.080000 stddev=101.453800 entropy=0.823213 frames=4948 count=25
2017/08/26 23:58:27 Training policy...
2017/08/26 23:58:33 step 0: objective=1.2007368
2017/08/26 23:58:35 step 1: objective=1.2073914
2017/08/26 23:58:37 step 2: objective=1.2134628
2017/08/26 23:58:39 step 3: objective=1.2194675
2017/08/26 23:58:41 step 4: objective=1.2241796
2017/08/26 23:58:43 step 5: objective=1.2281908
2017/08/26 23:58:45 step 6: objective=1.2316943
2017/08/26 23:58:47 step 7: objective=1.2360045
2017/08/26 23:58:47 Training value function...
2017/08/26 23:58:51 step 0: mse=65.633389 step=0.100000
2017/08/26 23:58:53 step 1: mse=64.121474 step=0.100000
2017/08/26 23:58:55 step 2: mse=62.899131 step=0.100000
2017/08/26 23:58:57 step 3: mse=61.756714 step=0.100000
2017/08/26 23:58:59 step 4: mse=61.046630 step=0.100000
2017/08/26 23:59:01 step 5: mse=59.906154 step=0.100000
2017/08/26 23:59:03 step 6: mse=59.088089 step=0.100000
2017/08/26 23:59:05 step 7: mse=58.450374 step=0.100000
2017/08/26 23:59:05 Saving...
2017/08/26 23:59:05 Gathering batch of experience...
2017/08/27 00:00:35 batch 37: mean=187.520000 stddev=120.731146 entropy=0.818218 frames=4887 count=25
2017/08/27 00:00:35 Training policy...
2017/08/27 00:00:41 step 0: objective=1.2220874
2017/08/27 00:00:43 step 1: objective=1.2321452
2017/08/27 00:00:45 step 2: objective=1.2403716
2017/08/27 00:00:47 step 3: objective=1.2473506
2017/08/27 00:00:49 step 4: objective=1.2520086
2017/08/27 00:00:51 step 5: objective=1.2578145
2017/08/27 00:00:53 step 6: objective=1.2623802
2017/08/27 00:00:55 step 7: objective=1.2660811
2017/08/27 00:00:55 Training value function...
2017/08/27 00:00:59 step 0: mse=75.863917 step=0.100000
2017/08/27 00:01:01 step 1: mse=73.694997 step=0.100000
2017/08/27 00:01:03 step 2: mse=72.016959 step=0.100000
2017/08/27 00:01:05 step 3: mse=70.783064 step=0.100000
2017/08/27 00:01:07 step 4: mse=69.330827 step=0.100000
2017/08/27 00:01:09 step 5: mse=68.469091 step=0.100000
2017/08/27 00:01:11 step 6: mse=67.376055 step=0.100000
2017/08/27 00:01:13 step 7: mse=66.278493 step=0.100000
2017/08/27 00:01:13 Saving...
2017/08/27 00:01:13 Gathering batch of experience...
2017/08/27 00:02:40 batch 38: mean=224.142857 stddev=120.334963 entropy=0.810193 frames=4877 count=21
2017/08/27 00:02:40 Training policy...
2017/08/27 00:02:46 step 0: objective=1.4679054
2017/08/27 00:02:48 step 1: objective=1.4770658
2017/08/27 00:02:50 step 2: objective=1.4874276
2017/08/27 00:02:52 step 3: objective=1.4926623
2017/08/27 00:02:54 step 4: objective=1.497125
2017/08/27 00:02:56 step 5: objective=1.5017998
2017/08/27 00:02:58 step 6: objective=1.505912
2017/08/27 00:03:00 step 7: objective=1.5093845
2017/08/27 00:03:00 Training value function...
2017/08/27 00:03:04 step 0: mse=67.451639 step=0.100000
2017/08/27 00:03:06 step 1: mse=65.622467 step=0.100000
2017/08/27 00:03:08 step 2: mse=64.080567 step=0.100000
2017/08/27 00:03:10 step 3: mse=62.793556 step=0.100000
2017/08/27 00:03:12 step 4: mse=61.616837 step=0.100000
2017/08/27 00:03:14 step 5: mse=60.546818 step=0.100000
2017/08/27 00:03:16 step 6: mse=59.612910 step=0.100000
2017/08/27 00:03:18 step 7: mse=58.772564 step=0.100000
2017/08/27 00:03:18 Saving...
2017/08/27 00:03:18 Gathering batch of experience...
2017/08/27 00:05:05 batch 39: mean=209.833333 stddev=122.459404 entropy=0.802502 frames=5229 count=24
2017/08/27 00:05:05 Training policy...
2017/08/27 00:05:11 step 0: objective=1.0420953
2017/08/27 00:05:14 step 1: objective=1.0526334
2017/08/27 00:05:16 step 2: objective=1.058984
2017/08/27 00:05:18 step 3: objective=1.0651276
2017/08/27 00:05:20 step 4: objective=1.0701113
2017/08/27 00:05:22 step 5: objective=1.0741241
2017/08/27 00:05:24 step 6: objective=1.0773581
2017/08/27 00:05:27 step 7: objective=1.0806555
2017/08/27 00:05:27 Training value function...
2017/08/27 00:05:31 step 0: mse=66.842440 step=0.100000
2017/08/27 00:05:33 step 1: mse=65.968157 step=0.100000
2017/08/27 00:05:35 step 2: mse=64.664263 step=0.100000
2017/08/27 00:05:37 step 3: mse=63.624957 step=0.100000
2017/08/27 00:05:39 step 4: mse=62.586262 step=0.100000
2017/08/27 00:05:41 step 5: mse=61.690670 step=0.100000
2017/08/27 00:05:43 step 6: mse=60.873984 step=0.100000
2017/08/27 00:05:45 step 7: mse=60.342126 step=0.100000
2017/08/27 00:05:45 Saving...
2017/08/27 00:05:46 Gathering batch of experience...
2017/08/27 00:07:26 batch 40: mean=184.259259 stddev=109.735909 entropy=0.820450 frames=5205 count=27
2017/08/27 00:07:26 Training policy...
2017/08/27 00:07:33 step 0: objective=0.72233546
2017/08/27 00:07:35 step 1: objective=0.73233414
2017/08/27 00:07:37 step 2: objective=0.74109745
2017/08/27 00:07:39 step 3: objective=0.7467156
2017/08/27 00:07:42 step 4: objective=0.75219935
2017/08/27 00:07:44 step 5: objective=0.7568866
2017/08/27 00:07:46 step 6: objective=0.76082116
2017/08/27 00:07:48 step 7: objective=0.76464045
2017/08/27 00:07:48 Training value function...
2017/08/27 00:07:52 step 0: mse=63.224869 step=0.100000
2017/08/27 00:07:54 step 1: mse=62.567540 step=0.100000
2017/08/27 00:07:56 step 2: mse=62.006415 step=0.100000
2017/08/27 00:07:59 step 3: mse=61.650687 step=0.100000
2017/08/27 00:08:01 step 4: mse=61.306949 step=0.100000
2017/08/27 00:08:03 step 5: mse=60.984632 step=0.100000
2017/08/27 00:08:05 step 6: mse=60.603160 step=0.100000
2017/08/27 00:08:07 step 7: mse=60.306323 step=0.100000
2017/08/27 00:08:07 Saving...
2017/08/27 00:08:07 Gathering batch of experience...
2017/08/27 00:09:41 batch 41: mean=183.423077 stddev=107.976199 entropy=0.819575 frames=4984 count=26
2017/08/27 00:09:41 Training policy...
2017/08/27 00:09:48 step 0: objective=0.7834521
2017/08/27 00:09:50 step 1: objective=0.7932914
2017/08/27 00:09:52 step 2: objective=0.8021714
2017/08/27 00:09:54 step 3: objective=0.8089743
2017/08/27 00:09:56 step 4: objective=0.8146934
2017/08/27 00:09:58 step 5: objective=0.81906223
2017/08/27 00:10:00 step 6: objective=0.82340354
2017/08/27 00:10:02 step 7: objective=0.82612336
2017/08/27 00:10:02 Training value function...
2017/08/27 00:10:06 step 0: mse=61.118198 step=0.100000
2017/08/27 00:10:08 step 1: mse=60.581207 step=0.100000
2017/08/27 00:10:10 step 2: mse=60.031416 step=0.100000
2017/08/27 00:10:12 step 3: mse=59.587089 step=0.100000
2017/08/27 00:10:14 step 4: mse=59.181972 step=0.100000
2017/08/27 00:10:16 step 5: mse=58.753738 step=0.100000
2017/08/27 00:10:18 step 6: mse=58.389986 step=0.100000
2017/08/27 00:10:20 step 7: mse=58.101487 step=0.100000
2017/08/27 00:10:20 Saving...
2017/08/27 00:10:20 Gathering batch of experience...
2017/08/27 00:11:58 batch 42: mean=166.777778 stddev=110.907814 entropy=0.817944 frames=4718 count=27
2017/08/27 00:11:58 Training policy...
2017/08/27 00:12:04 step 0: objective=0.740197
2017/08/27 00:12:06 step 1: objective=0.7508205
2017/08/27 00:12:08 step 2: objective=0.7591708
2017/08/27 00:12:10 step 3: objective=0.76678824
2017/08/27 00:12:12 step 4: objective=0.7723609
2017/08/27 00:12:14 step 5: objective=0.77710193
2017/08/27 00:12:16 step 6: objective=0.78121406
2017/08/27 00:12:18 step 7: objective=0.7853943
2017/08/27 00:12:18 Training value function...
2017/08/27 00:12:22 step 0: mse=72.250813 step=0.100000
2017/08/27 00:12:24 step 1: mse=71.377032 step=0.100000
2017/08/27 00:12:26 step 2: mse=70.515874 step=0.100000
2017/08/27 00:12:28 step 3: mse=69.755754 step=0.100000
2017/08/27 00:12:30 step 4: mse=69.252068 step=0.100000
2017/08/27 00:12:31 step 5: mse=68.925994 step=0.100000
2017/08/27 00:12:33 step 6: mse=68.641410 step=0.100000
2017/08/27 00:12:35 step 7: mse=68.167653 step=0.100000
2017/08/27 00:12:35 Saving...
2017/08/27 00:12:35 Gathering batch of experience...
2017/08/27 00:14:20 batch 43: mean=167.107143 stddev=97.504337 entropy=0.815964 frames=4920 count=28
2017/08/27 00:14:20 Training policy...
2017/08/27 00:14:27 step 0: objective=0.83139527
2017/08/27 00:14:29 step 1: objective=0.84492934
2017/08/27 00:14:31 step 2: objective=0.85605806
2017/08/27 00:14:33 step 3: objective=0.86212546
2017/08/27 00:14:35 step 4: objective=0.8662191
2017/08/27 00:14:37 step 5: objective=0.8702243
2017/08/27 00:14:39 step 6: objective=0.8731188
2017/08/27 00:14:41 step 7: objective=0.87603116
2017/08/27 00:14:41 Training value function...
2017/08/27 00:14:45 step 0: mse=66.272102 step=0.100000
2017/08/27 00:14:47 step 1: mse=65.537742 step=0.100000
2017/08/27 00:14:49 step 2: mse=65.193278 step=0.100000
2017/08/27 00:14:51 step 3: mse=64.712929 step=0.100000
2017/08/27 00:14:53 step 4: mse=64.198384 step=0.100000
2017/08/27 00:14:55 step 5: mse=63.678022 step=0.100000
2017/08/27 00:14:57 step 6: mse=63.313823 step=0.100000
2017/08/27 00:14:59 step 7: mse=63.098818 step=0.100000
2017/08/27 00:14:59 Saving...
2017/08/27 00:14:59 Gathering batch of experience...
2017/08/27 00:16:45 batch 44: mean=184.296296 stddev=111.587473 entropy=0.801803 frames=5201 count=27
2017/08/27 00:16:45 Training policy...
2017/08/27 00:16:52 step 0: objective=1.199352
2017/08/27 00:16:54 step 1: objective=1.2089108
2017/08/27 00:16:56 step 2: objective=1.2162902
2017/08/27 00:16:58 step 3: objective=1.2224786
2017/08/27 00:17:00 step 4: objective=1.2273124
2017/08/27 00:17:03 step 5: objective=1.2323991
2017/08/27 00:17:05 step 6: objective=1.236846
2017/08/27 00:17:07 step 7: objective=1.2408957
2017/08/27 00:17:07 Training value function...
2017/08/27 00:17:11 step 0: mse=68.480058 step=0.100000
2017/08/27 00:17:13 step 1: mse=67.253195 step=0.100000
2017/08/27 00:17:15 step 2: mse=66.284739 step=0.100000
2017/08/27 00:17:17 step 3: mse=65.387884 step=0.100000
2017/08/27 00:17:19 step 4: mse=64.596722 step=0.100000
2017/08/27 00:17:22 step 5: mse=63.752659 step=0.100000
2017/08/27 00:17:24 step 6: mse=63.034082 step=0.100000
2017/08/27 00:17:26 step 7: mse=61.840058 step=0.100000
2017/08/27 00:17:26 Saving...
2017/08/27 00:17:26 Gathering batch of experience...
2017/08/27 00:19:03 batch 45: mean=161.607143 stddev=79.062967 entropy=0.806778 frames=4782 count=28
2017/08/27 00:19:03 Training policy...
2017/08/27 00:19:09 step 0: objective=0.5968449
2017/08/27 00:19:11 step 1: objective=0.6058157
2017/08/27 00:19:13 step 2: objective=0.6138328
2017/08/27 00:19:15 step 3: objective=0.61840165
2017/08/27 00:19:17 step 4: objective=0.62626857
2017/08/27 00:19:19 step 5: objective=0.63141197
2017/08/27 00:19:21 step 6: objective=0.6365965
2017/08/27 00:19:23 step 7: objective=0.64241153
2017/08/27 00:19:23 Training value function...
2017/08/27 00:19:27 step 0: mse=60.684916 step=0.100000
2017/08/27 00:19:29 step 1: mse=60.123546 step=0.100000
2017/08/27 00:19:31 step 2: mse=59.342577 step=0.100000
2017/08/27 00:19:33 step 3: mse=58.709538 step=0.100000
2017/08/27 00:19:35 step 4: mse=58.281289 step=0.100000
2017/08/27 00:19:37 step 5: mse=57.914774 step=0.100000
2017/08/27 00:19:39 step 6: mse=57.455691 step=0.100000
2017/08/27 00:19:41 step 7: mse=57.277553 step=0.100000
2017/08/27 00:19:41 Saving...
2017/08/27 00:19:41 Gathering batch of experience...
2017/08/27 00:21:13 batch 46: mean=221.857143 stddev=103.349746 entropy=0.796850 frames=4842 count=21
2017/08/27 00:21:13 Training policy...
2017/08/27 00:21:19 step 0: objective=1.6183745
2017/08/27 00:21:21 step 1: objective=1.6273758
2017/08/27 00:21:23 step 2: objective=1.6355059
2017/08/27 00:21:25 step 3: objective=1.6409959
2017/08/27 00:21:27 step 4: objective=1.6494222
2017/08/27 00:21:29 step 5: objective=1.6533511
2017/08/27 00:21:31 step 6: objective=1.6565083
2017/08/27 00:21:33 step 7: objective=1.660206
2017/08/27 00:21:33 Training value function...
2017/08/27 00:21:37 step 0: mse=67.216774 step=0.100000
2017/08/27 00:21:39 step 1: mse=64.984215 step=0.100000
2017/08/27 00:21:41 step 2: mse=63.060135 step=0.100000
2017/08/27 00:21:43 step 3: mse=61.347538 step=0.100000
2017/08/27 00:21:45 step 4: mse=59.810128 step=0.100000
2017/08/27 00:21:47 step 5: mse=58.265787 step=0.100000
2017/08/27 00:21:48 step 6: mse=57.009379 step=0.100000
2017/08/27 00:21:50 step 7: mse=55.976268 step=0.100000
2017/08/27 00:21:50 Saving...
2017/08/27 00:21:50 Gathering batch of experience...
2017/08/27 00:23:28 batch 47: mean=197.333333 stddev=74.607119 entropy=0.794398 frames=4981 count=24
2017/08/27 00:23:28 Training policy...
2017/08/27 00:23:34 step 0: objective=1.0752829
2017/08/27 00:23:37 step 1: objective=1.0839076
2017/08/27 00:23:39 step 2: objective=1.0920111
2017/08/27 00:23:41 step 3: objective=1.098484
2017/08/27 00:23:43 step 4: objective=1.1044508
2017/08/27 00:23:45 step 5: objective=1.109041
2017/08/27 00:23:47 step 6: objective=1.1131182
2017/08/27 00:23:49 step 7: objective=1.1167817
2017/08/27 00:23:49 Training value function...
2017/08/27 00:23:53 step 0: mse=57.991666 step=0.100000
2017/08/27 00:23:55 step 1: mse=56.525940 step=0.100000
2017/08/27 00:23:57 step 2: mse=54.993847 step=0.100000
2017/08/27 00:23:59 step 3: mse=53.640486 step=0.100000
2017/08/27 00:24:01 step 4: mse=52.478598 step=0.100000
2017/08/27 00:24:03 step 5: mse=51.391572 step=0.100000
2017/08/27 00:24:05 step 6: mse=50.663483 step=0.100000
2017/08/27 00:24:07 step 7: mse=49.866354 step=0.100000
2017/08/27 00:24:07 Saving...
2017/08/27 00:24:07 Gathering batch of experience...
2017/08/27 00:25:42 batch 48: mean=211.681818 stddev=80.000220 entropy=0.798982 frames=4877 count=22
2017/08/27 00:25:42 Training policy...
2017/08/27 00:25:48 step 0: objective=1.0661352
2017/08/27 00:25:50 step 1: objective=1.0754308
2017/08/27 00:25:52 step 2: objective=1.0831158
2017/08/27 00:25:55 step 3: objective=1.087527
2017/08/27 00:25:57 step 4: objective=1.0916039
2017/08/27 00:25:59 step 5: objective=1.0951985
2017/08/27 00:26:01 step 6: objective=1.0993383
2017/08/27 00:26:03 step 7: objective=1.1024626
2017/08/27 00:26:03 Training value function...
2017/08/27 00:26:07 step 0: mse=53.785244 step=0.100000
2017/08/27 00:26:09 step 1: mse=52.870990 step=0.100000
2017/08/27 00:26:11 step 2: mse=51.515085 step=0.100000
2017/08/27 00:26:13 step 3: mse=50.572491 step=0.100000
2017/08/27 00:26:14 step 4: mse=49.814358 step=0.100000
2017/08/27 00:26:16 step 5: mse=49.002188 step=0.100000
2017/08/27 00:26:18 step 6: mse=48.180958 step=0.100000
2017/08/27 00:26:20 step 7: mse=47.727910 step=0.100000
2017/08/27 00:26:20 Saving...
2017/08/27 00:26:20 Gathering batch of experience...
2017/08/27 00:27:54 batch 49: mean=214.681818 stddev=95.151261 entropy=0.790846 frames=4924 count=22
2017/08/27 00:27:54 Training policy...
2017/08/27 00:28:01 step 0: objective=1.1009398
2017/08/27 00:28:03 step 1: objective=1.1086831
2017/08/27 00:28:05 step 2: objective=1.1144848
2017/08/27 00:28:07 step 3: objective=1.1191136
2017/08/27 00:28:09 step 4: objective=1.1240554
2017/08/27 00:28:11 step 5: objective=1.1293541
2017/08/27 00:28:13 step 6: objective=1.1320028
2017/08/27 00:28:16 step 7: objective=1.1356505
2017/08/27 00:28:16 Training value function...
2017/08/27 00:28:20 step 0: mse=56.765245 step=0.100000
2017/08/27 00:28:22 step 1: mse=55.799504 step=0.100000
2017/08/27 00:28:24 step 2: mse=54.947384 step=0.100000
2017/08/27 00:28:26 step 3: mse=54.162100 step=0.100000
2017/08/27 00:28:28 step 4: mse=53.605708 step=0.100000
2017/08/27 00:28:30 step 5: mse=52.997028 step=0.100000
2017/08/27 00:28:32 step 6: mse=52.425543 step=0.100000
2017/08/27 00:28:34 step 7: mse=51.756046 step=0.100000
2017/08/27 00:28:34 Saving...
2017/08/27 00:28:34 Gathering batch of experience...
2017/08/27 00:30:13 batch 50: mean=219.142857 stddev=126.679305 entropy=0.789765 frames=4767 count=21
2017/08/27 00:30:13 Training policy...
2017/08/27 00:30:19 step 0: objective=1.3607967
2017/08/27 00:30:21 step 1: objective=1.3686509
2017/08/27 00:30:23 step 2: objective=1.373542
2017/08/27 00:30:25 step 3: objective=1.3787147
2017/08/27 00:30:27 step 4: objective=1.3833499
2017/08/27 00:30:29 step 5: objective=1.3871906
2017/08/27 00:30:31 step 6: objective=1.3901623
2017/08/27 00:30:33 step 7: objective=1.3935121
2017/08/27 00:30:33 Training value function...
2017/08/27 00:30:37 step 0: mse=69.214826 step=0.100000
2017/08/27 00:30:39 step 1: mse=66.574154 step=0.100000
2017/08/27 00:30:41 step 2: mse=64.079307 step=0.100000
2017/08/27 00:30:42 step 3: mse=61.857002 step=0.100000
2017/08/27 00:30:44 step 4: mse=60.281794 step=0.100000
2017/08/27 00:30:46 step 5: mse=59.140532 step=0.100000
2017/08/27 00:30:48 step 6: mse=57.919094 step=0.100000
2017/08/27 00:30:50 step 7: mse=56.382319 step=0.100000
2017/08/27 00:30:50 Saving...
2017/08/27 00:30:50 Gathering batch of experience...
2017/08/27 00:32:36 batch 51: mean=196.576923 stddev=118.560005 entropy=0.796190 frames=5320 count=26
2017/08/27 00:32:36 Training policy...
2017/08/27 00:32:43 step 0: objective=0.7984735
2017/08/27 00:32:45 step 1: objective=0.80955803
2017/08/27 00:32:47 step 2: objective=0.81822336
2017/08/27 00:32:50 step 3: objective=0.82427335
2017/08/27 00:32:52 step 4: objective=0.8289371
2017/08/27 00:32:54 step 5: objective=0.8374343
2017/08/27 00:32:57 step 6: objective=0.841474
2017/08/27 00:32:59 step 7: objective=0.8443865
2017/08/27 00:32:59 Training value function...
2017/08/27 00:33:03 step 0: mse=63.595816 step=0.100000
2017/08/27 00:33:05 step 1: mse=62.596220 step=0.100000
2017/08/27 00:33:08 step 2: mse=61.516647 step=0.100000
2017/08/27 00:33:10 step 3: mse=60.591371 step=0.100000
2017/08/27 00:33:12 step 4: mse=59.801434 step=0.100000
2017/08/27 00:33:14 step 5: mse=59.164459 step=0.100000
2017/08/27 00:33:16 step 6: mse=58.805015 step=0.100000
2017/08/27 00:33:19 step 7: mse=58.411819 step=0.100000
2017/08/27 00:33:19 Saving...
2017/08/27 00:33:19 Gathering batch of experience...
2017/08/27 00:35:00 batch 52: mean=202.280000 stddev=110.604347 entropy=0.793497 frames=5268 count=25
2017/08/27 00:35:00 Training policy...
2017/08/27 00:35:07 step 0: objective=0.8625148
2017/08/27 00:35:09 step 1: objective=0.8737788
2017/08/27 00:35:12 step 2: objective=0.87992394
2017/08/27 00:35:14 step 3: objective=0.8857697
2017/08/27 00:35:16 step 4: objective=0.889854
2017/08/27 00:35:18 step 5: objective=0.8940318
2017/08/27 00:35:21 step 6: objective=0.8975553
2017/08/27 00:35:23 step 7: objective=0.90029866
2017/08/27 00:35:23 Training value function...
2017/08/27 00:35:27 step 0: mse=58.548125 step=0.100000
2017/08/27 00:35:29 step 1: mse=57.993893 step=0.100000
2017/08/27 00:35:31 step 2: mse=57.573727 step=0.100000
2017/08/27 00:35:34 step 3: mse=57.140878 step=0.100000
2017/08/27 00:35:36 step 4: mse=56.769962 step=0.100000
2017/08/27 00:35:38 step 5: mse=56.455208 step=0.100000
2017/08/27 00:35:40 step 6: mse=55.950476 step=0.100000
2017/08/27 00:35:42 step 7: mse=55.169991 step=0.100000
2017/08/27 00:35:42 Saving...
2017/08/27 00:35:42 Gathering batch of experience...
2017/08/27 00:37:22 batch 53: mean=203.520000 stddev=127.524467 entropy=0.795723 frames=5279 count=25
2017/08/27 00:37:22 Training policy...
2017/08/27 00:37:28 step 0: objective=1.042421
2017/08/27 00:37:31 step 1: objective=1.0510451
2017/08/27 00:37:33 step 2: objective=1.0584837
2017/08/27 00:37:35 step 3: objective=1.0649502
2017/08/27 00:37:38 step 4: objective=1.0712208
2017/08/27 00:37:40 step 5: objective=1.0753932
2017/08/27 00:37:42 step 6: objective=1.0797386
2017/08/27 00:37:44 step 7: objective=1.0830015
2017/08/27 00:37:44 Training value function...
2017/08/27 00:37:49 step 0: mse=64.710635 step=0.100000
2017/08/27 00:37:51 step 1: mse=63.714121 step=0.100000
2017/08/27 00:37:53 step 2: mse=62.893655 step=0.100000
2017/08/27 00:37:55 step 3: mse=62.140438 step=0.100000
2017/08/27 00:37:57 step 4: mse=61.420552 step=0.100000
2017/08/27 00:38:00 step 5: mse=60.869191 step=0.100000
2017/08/27 00:38:02 step 6: mse=60.254157 step=0.100000
2017/08/27 00:38:04 step 7: mse=59.725460 step=0.100000
2017/08/27 00:38:04 Saving...
2017/08/27 00:38:04 Gathering batch of experience...
2017/08/27 00:39:41 batch 54: mean=218.318182 stddev=109.250915 entropy=0.783644 frames=4995 count=22
2017/08/27 00:39:41 Training policy...
2017/08/27 00:39:48 step 0: objective=1.2456464
2017/08/27 00:39:50 step 1: objective=1.2538617
2017/08/27 00:39:52 step 2: objective=1.260919
2017/08/27 00:39:54 step 3: objective=1.2680453
2017/08/27 00:39:56 step 4: objective=1.2731105
2017/08/27 00:39:58 step 5: objective=1.2780215
2017/08/27 00:40:00 step 6: objective=1.2818635
2017/08/27 00:40:02 step 7: objective=1.284808
2017/08/27 00:40:02 Training value function...
2017/08/27 00:40:06 step 0: mse=69.590703 step=0.100000
2017/08/27 00:40:09 step 1: mse=67.290620 step=0.100000
2017/08/27 00:40:11 step 2: mse=65.304484 step=0.100000
2017/08/27 00:40:13 step 3: mse=63.660923 step=0.100000
2017/08/27 00:40:15 step 4: mse=62.288942 step=0.100000
2017/08/27 00:40:17 step 5: mse=61.402354 step=0.100000
2017/08/27 00:40:19 step 6: mse=60.310918 step=0.100000
2017/08/27 00:40:21 step 7: mse=59.352787 step=0.100000
2017/08/27 00:40:21 Saving...
2017/08/27 00:40:21 Gathering batch of experience...
2017/08/27 00:41:53 batch 55: mean=205.590909 stddev=118.378691 entropy=0.792270 frames=4704 count=22
2017/08/27 00:41:53 Training policy...
2017/08/27 00:41:59 step 0: objective=0.97900724
2017/08/27 00:42:01 step 1: objective=0.9871553
2017/08/27 00:42:03 step 2: objective=0.9948602
2017/08/27 00:42:05 step 3: objective=1.0004609
2017/08/27 00:42:07 step 4: objective=1.0050993
2017/08/27 00:42:09 step 5: objective=1.0099125
2017/08/27 00:42:10 step 6: objective=1.0136747
2017/08/27 00:42:13 step 7: objective=1.018122
2017/08/27 00:42:13 Training value function...
2017/08/27 00:42:16 step 0: mse=64.675945 step=0.100000
2017/08/27 00:42:18 step 1: mse=63.878154 step=0.100000
2017/08/27 00:42:20 step 2: mse=63.232588 step=0.100000
2017/08/27 00:42:22 step 3: mse=62.590604 step=0.100000
2017/08/27 00:42:24 step 4: mse=62.032539 step=0.100000
2017/08/27 00:42:26 step 5: mse=61.423653 step=0.100000
2017/08/27 00:42:28 step 6: mse=60.918106 step=0.100000
2017/08/27 00:42:30 step 7: mse=60.511643 step=0.100000
2017/08/27 00:42:30 Saving...
2017/08/27 00:42:30 Gathering batch of experience...
2017/08/27 00:44:09 batch 56: mean=205.478261 stddev=105.186323 entropy=0.785294 frames=4930 count=23
2017/08/27 00:44:09 Training policy...
2017/08/27 00:44:16 step 0: objective=0.74415237
2017/08/27 00:44:18 step 1: objective=0.7514759
2017/08/27 00:44:20 step 2: objective=0.75768125
2017/08/27 00:44:22 step 3: objective=0.7629703
2017/08/27 00:44:24 step 4: objective=0.7669673
2017/08/27 00:44:26 step 5: objective=0.7714857
2017/08/27 00:44:28 step 6: objective=0.77481514
2017/08/27 00:44:30 step 7: objective=0.77767795
2017/08/27 00:44:30 Training value function...
2017/08/27 00:44:34 step 0: mse=56.710578 step=0.100000
2017/08/27 00:44:36 step 1: mse=55.983743 step=0.100000
2017/08/27 00:44:38 step 2: mse=55.436161 step=0.100000
2017/08/27 00:44:40 step 3: mse=54.988168 step=0.100000
2017/08/27 00:44:42 step 4: mse=54.546394 step=0.100000
2017/08/27 00:44:45 step 5: mse=54.238634 step=0.100000
2017/08/27 00:44:47 step 6: mse=53.983607 step=0.100000
2017/08/27 00:44:49 step 7: mse=53.781171 step=0.100000
2017/08/27 00:44:49 Saving...
2017/08/27 00:44:49 Gathering batch of experience...
2017/08/27 00:46:29 batch 57: mean=232.500000 stddev=127.629346 entropy=0.777532 frames=5284 count=22
2017/08/27 00:46:29 Training policy...
2017/08/27 00:46:36 step 0: objective=1.3549737
2017/08/27 00:46:38 step 1: objective=1.3625456
2017/08/27 00:46:40 step 2: objective=1.3697119
2017/08/27 00:46:43 step 3: objective=1.3754503
2017/08/27 00:46:45 step 4: objective=1.3798475
2017/08/27 00:46:47 step 5: objective=1.3846459
2017/08/27 00:46:49 step 6: objective=1.3880947
2017/08/27 00:46:52 step 7: objective=1.3914135
2017/08/27 00:46:52 Training value function...
2017/08/27 00:46:56 step 0: mse=68.013663 step=0.100000
2017/08/27 00:46:58 step 1: mse=66.413945 step=0.100000
2017/08/27 00:47:01 step 2: mse=65.018459 step=0.100000
2017/08/27 00:47:03 step 3: mse=63.686692 step=0.100000
2017/08/27 00:47:05 step 4: mse=62.568882 step=0.100000
2017/08/27 00:47:07 step 5: mse=61.144351 step=0.100000
2017/08/27 00:47:09 step 6: mse=60.145647 step=0.100000
2017/08/27 00:47:12 step 7: mse=59.074977 step=0.100000
2017/08/27 00:47:12 Saving...
2017/08/27 00:47:12 Gathering batch of experience...
2017/08/27 00:48:57 batch 58: mean=179.678571 stddev=123.996271 entropy=0.788907 frames=5241 count=28
2017/08/27 00:48:57 Training policy...
2017/08/27 00:49:04 step 0: objective=0.60122275
2017/08/27 00:49:06 step 1: objective=0.6112626
2017/08/27 00:49:09 step 2: objective=0.6204749
2017/08/27 00:49:11 step 3: objective=0.6270667
2017/08/27 00:49:13 step 4: objective=0.6312373
2017/08/27 00:49:15 step 5: objective=0.63666564
2017/08/27 00:49:18 step 6: objective=0.64078456
2017/08/27 00:49:20 step 7: objective=0.6447239
2017/08/27 00:49:20 Training value function...
2017/08/27 00:49:24 step 0: mse=71.683281 step=0.100000
2017/08/27 00:49:26 step 1: mse=70.481957 step=0.100000
2017/08/27 00:49:29 step 2: mse=69.878735 step=0.100000
2017/08/27 00:49:31 step 3: mse=68.838656 step=0.100000
2017/08/27 00:49:33 step 4: mse=67.994643 step=0.100000
2017/08/27 00:49:35 step 5: mse=67.700302 step=0.100000
2017/08/27 00:49:37 step 6: mse=67.396812 step=0.100000
2017/08/27 00:49:39 step 7: mse=67.152666 step=0.100000
2017/08/27 00:49:39 Saving...
2017/08/27 00:49:39 Gathering batch of experience...
2017/08/27 00:51:20 batch 59: mean=239.250000 stddev=149.540588 entropy=0.766096 frames=4916 count=20
2017/08/27 00:51:20 Training policy...
2017/08/27 00:51:26 step 0: objective=1.7090511
2017/08/27 00:51:29 step 1: objective=1.7192881
2017/08/27 00:51:31 step 2: objective=1.7248517
2017/08/27 00:51:33 step 3: objective=1.7308315
2017/08/27 00:51:35 step 4: objective=1.7354066
2017/08/27 00:51:37 step 5: objective=1.7395169
2017/08/27 00:51:39 step 6: objective=1.7435215
2017/08/27 00:51:41 step 7: objective=1.7491612
2017/08/27 00:51:41 Training value function...
2017/08/27 00:51:45 step 0: mse=76.922799 step=0.100000
2017/08/27 00:51:47 step 1: mse=74.308749 step=0.100000
2017/08/27 00:51:49 step 2: mse=71.876380 step=0.100000
2017/08/27 00:51:52 step 3: mse=69.665060 step=0.100000
2017/08/27 00:51:54 step 4: mse=67.973010 step=0.100000
2017/08/27 00:51:56 step 5: mse=66.312467 step=0.100000
2017/08/27 00:51:58 step 6: mse=64.776731 step=0.100000
2017/08/27 00:52:00 step 7: mse=63.484526 step=0.100000
2017/08/27 00:52:00 Saving...
2017/08/27 00:52:00 Gathering batch of experience...
2017/08/27 00:53:38 batch 60: mean=216.608696 stddev=132.646880 entropy=0.782487 frames=5153 count=23
2017/08/27 00:53:38 Training policy...
2017/08/27 00:53:45 step 0: objective=0.785944
2017/08/27 00:53:47 step 1: objective=0.7962607
2017/08/27 00:53:50 step 2: objective=0.8024003
2017/08/27 00:53:52 step 3: objective=0.8083581
2017/08/27 00:53:54 step 4: objective=0.8128311
2017/08/27 00:53:56 step 5: objective=0.81680536
2017/08/27 00:53:58 step 6: objective=0.81964314
2017/08/27 00:54:01 step 7: objective=0.82230836
2017/08/27 00:54:01 Training value function...
2017/08/27 00:54:05 step 0: mse=60.231891 step=0.100000
2017/08/27 00:54:07 step 1: mse=59.224477 step=0.100000
2017/08/27 00:54:09 step 2: mse=58.350906 step=0.100000
2017/08/27 00:54:11 step 3: mse=57.932074 step=0.100000
2017/08/27 00:54:13 step 4: mse=57.768386 step=0.100000
2017/08/27 00:54:15 step 5: mse=56.664352 step=0.100000
2017/08/27 00:54:18 step 6: mse=55.476705 step=0.100000
2017/08/27 00:54:20 step 7: mse=54.675722 step=0.100000
2017/08/27 00:54:20 Saving...
2017/08/27 00:54:20 Gathering batch of experience...
2017/08/27 00:55:55 batch 61: mean=248.421053 stddev=144.792162 entropy=0.768701 frames=4846 count=19
2017/08/27 00:55:55 Training policy...
2017/08/27 00:56:01 step 0: objective=1.2628936
2017/08/27 00:56:03 step 1: objective=1.2705954
2017/08/27 00:56:06 step 2: objective=1.2790505
2017/08/27 00:56:08 step 3: objective=1.2836968
2017/08/27 00:56:10 step 4: objective=1.2880667
2017/08/27 00:56:12 step 5: objective=1.2938464
2017/08/27 00:56:14 step 6: objective=1.2975779
2017/08/27 00:56:16 step 7: objective=1.3015535
2017/08/27 00:56:16 Training value function...
2017/08/27 00:56:20 step 0: mse=64.878778 step=0.100000
2017/08/27 00:56:22 step 1: mse=62.843235 step=0.100000
2017/08/27 00:56:24 step 2: mse=61.272216 step=0.100000
2017/08/27 00:56:26 step 3: mse=59.953169 step=0.100000
2017/08/27 00:56:28 step 4: mse=58.599323 step=0.100000
2017/08/27 00:56:30 step 5: mse=57.439199 step=0.100000
2017/08/27 00:56:32 step 6: mse=56.371839 step=0.100000
2017/08/27 00:56:34 step 7: mse=55.727037 step=0.100000
2017/08/27 00:56:34 Saving...
2017/08/27 00:56:34 Gathering batch of experience...
2017/08/27 00:58:20 batch 62: mean=218.608696 stddev=136.299778 entropy=0.782502 frames=5198 count=23
2017/08/27 00:58:20 Training policy...
2017/08/27 00:58:27 step 0: objective=0.7233234
2017/08/27 00:58:29 step 1: objective=0.7313041
2017/08/27 00:58:31 step 2: objective=0.7361018
2017/08/27 00:58:33 step 3: objective=0.74153155
2017/08/27 00:58:36 step 4: objective=0.7454034
2017/08/27 00:58:38 step 5: objective=0.7521504
2017/08/27 00:58:40 step 6: objective=0.7564198
2017/08/27 00:58:42 step 7: objective=0.75888324
2017/08/27 00:58:42 Training value function...
2017/08/27 00:58:47 step 0: mse=62.031469 step=0.100000
2017/08/27 00:58:49 step 1: mse=61.628609 step=0.100000
2017/08/27 00:58:51 step 2: mse=61.197262 step=0.100000
2017/08/27 00:58:53 step 3: mse=60.806939 step=0.100000
2017/08/27 00:58:55 step 4: mse=60.494023 step=0.100000
2017/08/27 00:58:57 step 5: mse=60.163628 step=0.100000
2017/08/27 00:59:00 step 6: mse=59.701982 step=0.100000
2017/08/27 00:59:02 step 7: mse=59.419600 step=0.100000
2017/08/27 00:59:02 Saving...
2017/08/27 00:59:02 Gathering batch of experience...
2017/08/27 01:00:43 batch 63: mean=234.272727 stddev=131.861216 entropy=0.774477 frames=5320 count=22
2017/08/27 01:00:43 Training policy...
2017/08/27 01:00:50 step 0: objective=1.0408398
2017/08/27 01:00:52 step 1: objective=1.0497745
2017/08/27 01:00:55 step 2: objective=1.0548205
2017/08/27 01:00:57 step 3: objective=1.0616521
2017/08/27 01:00:59 step 4: objective=1.065762
2017/08/27 01:01:02 step 5: objective=1.069425
2017/08/27 01:01:04 step 6: objective=1.0742627
2017/08/27 01:01:06 step 7: objective=1.0775324
2017/08/27 01:01:06 Training value function...
2017/08/27 01:01:11 step 0: mse=60.525632 step=0.100000
2017/08/27 01:01:13 step 1: mse=59.672860 step=0.100000
2017/08/27 01:01:15 step 2: mse=58.863312 step=0.100000
2017/08/27 01:01:18 step 3: mse=58.270306 step=0.100000
2017/08/27 01:01:20 step 4: mse=57.648141 step=0.100000
2017/08/27 01:01:22 step 5: mse=56.804505 step=0.100000
2017/08/27 01:01:24 step 6: mse=56.022310 step=0.100000
2017/08/27 01:01:27 step 7: mse=55.551472 step=0.100000
2017/08/27 01:01:27 Saving...
2017/08/27 01:01:27 Gathering batch of experience...
2017/08/27 01:02:54 batch 64: mean=212.380952 stddev=109.270950 entropy=0.773378 frames=4642 count=21
2017/08/27 01:02:54 Training policy...
2017/08/27 01:03:00 step 0: objective=0.809251
2017/08/27 01:03:02 step 1: objective=0.8202592
2017/08/27 01:03:04 step 2: objective=0.82691187
2017/08/27 01:03:06 step 3: objective=0.8331662
2017/08/27 01:03:08 step 4: objective=0.83758444
2017/08/27 01:03:10 step 5: objective=0.84200084
2017/08/27 01:03:12 step 6: objective=0.8464776
2017/08/27 01:03:14 step 7: objective=0.8514987
2017/08/27 01:03:14 Training value function...
2017/08/27 01:03:18 step 0: mse=60.970277 step=0.100000
2017/08/27 01:03:20 step 1: mse=59.564064 step=0.100000
2017/08/27 01:03:22 step 2: mse=58.340067 step=0.100000
2017/08/27 01:03:23 step 3: mse=57.471695 step=0.100000
2017/08/27 01:03:25 step 4: mse=56.622849 step=0.100000
2017/08/27 01:03:27 step 5: mse=55.838788 step=0.100000
2017/08/27 01:03:29 step 6: mse=55.294080 step=0.100000
2017/08/27 01:03:31 step 7: mse=54.723913 step=0.100000
2017/08/27 01:03:31 Saving...
2017/08/27 01:03:31 Gathering batch of experience...
2017/08/27 01:05:11 batch 65: mean=279.888889 stddev=128.113183 entropy=0.757026 frames=5162 count=18
2017/08/27 01:05:11 Training policy...
2017/08/27 01:05:17 step 0: objective=1.4145772
2017/08/27 01:05:19 step 1: objective=1.4218817
2017/08/27 01:05:21 step 2: objective=1.4270017
2017/08/27 01:05:24 step 3: objective=1.4324566
2017/08/27 01:05:26 step 4: objective=1.4367129
2017/08/27 01:05:28 step 5: objective=1.4402912
2017/08/27 01:05:30 step 6: objective=1.4438117
2017/08/27 01:05:32 step 7: objective=1.4478513
2017/08/27 01:05:32 Training value function...
2017/08/27 01:05:37 step 0: mse=62.135989 step=0.100000
2017/08/27 01:05:39 step 1: mse=60.288220 step=0.100000
2017/08/27 01:05:41 step 2: mse=58.225291 step=0.100000
2017/08/27 01:05:43 step 3: mse=56.618037 step=0.100000
2017/08/27 01:05:45 step 4: mse=54.901929 step=0.100000
2017/08/27 01:05:47 step 5: mse=53.796383 step=0.100000
2017/08/27 01:05:50 step 6: mse=52.694384 step=0.100000
2017/08/27 01:05:52 step 7: mse=51.562961 step=0.100000
2017/08/27 01:05:52 Saving...
2017/08/27 01:05:52 Gathering batch of experience...
2017/08/27 01:07:43 batch 66: mean=231.434783 stddev=139.829656 entropy=0.762845 frames=5482 count=23
2017/08/27 01:07:43 Training policy...
2017/08/27 01:07:50 step 0: objective=0.9492899
2017/08/27 01:07:52 step 1: objective=0.95719105
2017/08/27 01:07:55 step 2: objective=0.9638141
2017/08/27 01:07:57 step 3: objective=0.96908927
2017/08/27 01:08:00 step 4: objective=0.9732777
2017/08/27 01:08:02 step 5: objective=0.978509
2017/08/27 01:08:04 step 6: objective=0.9829033
2017/08/27 01:08:07 step 7: objective=0.9899504
2017/08/27 01:08:07 Training value function...
2017/08/27 01:08:11 step 0: mse=64.986712 step=0.100000
2017/08/27 01:08:14 step 1: mse=63.768816 step=0.100000
2017/08/27 01:08:16 step 2: mse=63.042130 step=0.100000
2017/08/27 01:08:18 step 3: mse=61.624764 step=0.100000
2017/08/27 01:08:20 step 4: mse=60.991200 step=0.100000
2017/08/27 01:08:23 step 5: mse=60.413962 step=0.100000
2017/08/27 01:08:25 step 6: mse=59.910099 step=0.100000
2017/08/27 01:08:27 step 7: mse=59.319845 step=0.100000
2017/08/27 01:08:27 Saving...
2017/08/27 01:08:27 Gathering batch of experience...
2017/08/27 01:10:14 batch 67: mean=267.578947 stddev=124.098567 entropy=0.754729 frames=5223 count=19
2017/08/27 01:10:14 Training policy...
2017/08/27 01:10:21 step 0: objective=1.1828564
2017/08/27 01:10:23 step 1: objective=1.1901946
2017/08/27 01:10:25 step 2: objective=1.1968234
2017/08/27 01:10:27 step 3: objective=1.2024604
2017/08/27 01:10:30 step 4: objective=1.2070941
2017/08/27 01:10:32 step 5: objective=1.2116649
2017/08/27 01:10:34 step 6: objective=1.2146604
2017/08/27 01:10:36 step 7: objective=1.2171718
2017/08/27 01:10:36 Training value function...
2017/08/27 01:10:41 step 0: mse=57.102245 step=0.100000
2017/08/27 01:10:43 step 1: mse=55.789865 step=0.100000
2017/08/27 01:10:45 step 2: mse=54.057731 step=0.100000
2017/08/27 01:10:47 step 3: mse=52.774672 step=0.100000
2017/08/27 01:10:50 step 4: mse=51.344677 step=0.100000
2017/08/27 01:10:52 step 5: mse=50.679403 step=0.100000
2017/08/27 01:10:54 step 6: mse=49.742743 step=0.100000
2017/08/27 01:10:56 step 7: mse=48.491245 step=0.100000
2017/08/27 01:10:56 Saving...
2017/08/27 01:10:56 Gathering batch of experience...
2017/08/27 01:12:48 batch 68: mean=231.045455 stddev=145.861852 entropy=0.766475 frames=5227 count=22
2017/08/27 01:12:48 Training policy...
2017/08/27 01:12:54 step 0: objective=0.7854109
2017/08/27 01:12:57 step 1: objective=0.79360783
2017/08/27 01:12:59 step 2: objective=0.80192864
2017/08/27 01:13:01 step 3: objective=0.81010276
2017/08/27 01:13:04 step 4: objective=0.8134917
2017/08/27 01:13:06 step 5: objective=0.8200446
2017/08/27 01:13:08 step 6: objective=0.82383984
2017/08/27 01:13:10 step 7: objective=0.827658
2017/08/27 01:13:10 Training value function...
2017/08/27 01:13:15 step 0: mse=56.524402 step=0.100000
2017/08/27 01:13:17 step 1: mse=55.792258 step=0.100000
2017/08/27 01:13:19 step 2: mse=55.268761 step=0.100000
2017/08/27 01:13:21 step 3: mse=54.588756 step=0.100000
2017/08/27 01:13:23 step 4: mse=53.991271 step=0.100000
2017/08/27 01:13:26 step 5: mse=53.496074 step=0.100000
2017/08/27 01:13:28 step 6: mse=52.738051 step=0.100000
2017/08/27 01:13:30 step 7: mse=52.086780 step=0.100000
2017/08/27 01:13:30 Saving...
2017/08/27 01:13:30 Gathering batch of experience...
2017/08/27 01:15:10 batch 69: mean=205.347826 stddev=126.042646 entropy=0.765871 frames=4901 count=23
2017/08/27 01:15:10 Training policy...
2017/08/27 01:15:17 step 0: objective=0.52295774
2017/08/27 01:15:19 step 1: objective=0.5324524
2017/08/27 01:15:21 step 2: objective=0.53900826
2017/08/27 01:15:23 step 3: objective=0.5450085
2017/08/27 01:15:25 step 4: objective=0.55074114
2017/08/27 01:15:27 step 5: objective=0.5535391
2017/08/27 01:15:29 step 6: objective=0.55788076
2017/08/27 01:15:31 step 7: objective=0.5613599
2017/08/27 01:15:31 Training value function...
2017/08/27 01:15:35 step 0: mse=64.495577 step=0.100000
2017/08/27 01:15:37 step 1: mse=64.183164 step=0.100000
2017/08/27 01:15:39 step 2: mse=63.859193 step=0.100000
2017/08/27 01:15:41 step 3: mse=63.481853 step=0.100000
2017/08/27 01:15:43 step 4: mse=63.306607 step=0.100000
2017/08/27 01:15:45 step 5: mse=62.733622 step=0.100000
2017/08/27 01:15:47 step 6: mse=62.655531 step=0.100000
2017/08/27 01:15:49 step 7: mse=62.495366 step=0.100000
2017/08/27 01:15:49 Saving...
2017/08/27 01:15:49 Gathering batch of experience...
2017/08/27 01:17:29 batch 70: mean=214.875000 stddev=134.753884 entropy=0.764824 frames=5335 count=24
2017/08/27 01:17:29 Training policy...
2017/08/27 01:17:36 step 0: objective=0.9771045
2017/08/27 01:17:38 step 1: objective=0.98409647
2017/08/27 01:17:41 step 2: objective=0.9897541
2017/08/27 01:17:43 step 3: objective=0.9943902
2017/08/27 01:17:45 step 4: objective=1.0015099
2017/08/27 01:17:48 step 5: objective=1.0053821
2017/08/27 01:17:50 step 6: objective=1.0094949
2017/08/27 01:17:52 step 7: objective=1.0128913
2017/08/27 01:17:52 Training value function...
2017/08/27 01:17:57 step 0: mse=63.646378 step=0.100000
2017/08/27 01:17:59 step 1: mse=62.904930 step=0.100000
2017/08/27 01:18:01 step 2: mse=62.194878 step=0.100000
2017/08/27 01:18:03 step 3: mse=61.449776 step=0.100000
2017/08/27 01:18:06 step 4: mse=60.846368 step=0.100000
2017/08/27 01:18:08 step 5: mse=60.334248 step=0.100000
2017/08/27 01:18:10 step 6: mse=59.811094 step=0.100000
2017/08/27 01:18:12 step 7: mse=59.366576 step=0.100000
2017/08/27 01:18:12 Saving...
2017/08/27 01:18:12 Gathering batch of experience...
2017/08/27 01:19:44 batch 71: mean=202.217391 stddev=96.915901 entropy=0.764189 frames=4861 count=23
2017/08/27 01:19:44 Training policy...
2017/08/27 01:19:50 step 0: objective=0.6588431
2017/08/27 01:19:52 step 1: objective=0.6683937
2017/08/27 01:19:55 step 2: objective=0.67517775
2017/08/27 01:19:57 step 3: objective=0.68117315
2017/08/27 01:19:59 step 4: objective=0.6860905
2017/08/27 01:20:01 step 5: objective=0.69053465
2017/08/27 01:20:03 step 6: objective=0.69678974
2017/08/27 01:20:05 step 7: objective=0.70002306
2017/08/27 01:20:05 Training value function...
2017/08/27 01:20:09 step 0: mse=59.417382 step=0.100000
2017/08/27 01:20:11 step 1: mse=58.894598 step=0.100000
2017/08/27 01:20:13 step 2: mse=57.955990 step=0.100000
2017/08/27 01:20:15 step 3: mse=57.346087 step=0.100000
2017/08/27 01:20:17 step 4: mse=57.023180 step=0.100000
2017/08/27 01:20:19 step 5: mse=56.334885 step=0.100000
2017/08/27 01:20:21 step 6: mse=56.049620 step=0.100000
2017/08/27 01:20:23 step 7: mse=55.807850 step=0.100000
2017/08/27 01:20:23 Saving...
2017/08/27 01:20:23 Gathering batch of experience...
2017/08/27 01:22:12 batch 72: mean=240.454545 stddev=131.522458 entropy=0.750884 frames=5451 count=22
2017/08/27 01:22:12 Training policy...
2017/08/27 01:22:19 step 0: objective=1.3483864
2017/08/27 01:22:21 step 1: objective=1.3581457
2017/08/27 01:22:24 step 2: objective=1.3634137
2017/08/27 01:22:27 step 3: objective=1.3702855
2017/08/27 01:22:30 step 4: objective=1.3740838
2017/08/27 01:22:33 step 5: objective=1.378285
2017/08/27 01:22:36 step 6: objective=1.3806653
2017/08/27 01:22:40 step 7: objective=1.3833622
2017/08/27 01:22:40 Training value function...
2017/08/27 01:22:45 step 0: mse=64.075699 step=0.100000
2017/08/27 01:22:47 step 1: mse=62.613445 step=0.100000
2017/08/27 01:22:50 step 2: mse=61.148386 step=0.100000
2017/08/27 01:22:52 step 3: mse=59.993737 step=0.100000
2017/08/27 01:22:54 step 4: mse=58.921171 step=0.100000
2017/08/27 01:22:57 step 5: mse=57.887479 step=0.100000
2017/08/27 01:22:59 step 6: mse=57.012993 step=0.100000
2017/08/27 01:23:01 step 7: mse=56.204570 step=0.100000
2017/08/27 01:23:01 Saving...
2017/08/27 01:23:01 Gathering batch of experience...
2017/08/27 01:24:45 batch 73: mean=222.217391 stddev=133.316543 entropy=0.754290 frames=5279 count=23
2017/08/27 01:24:45 Training policy...
2017/08/27 01:24:52 step 0: objective=1.1331306
2017/08/27 01:24:54 step 1: objective=1.141066
2017/08/27 01:24:57 step 2: objective=1.1472633
2017/08/27 01:24:59 step 3: objective=1.152261
2017/08/27 01:25:01 step 4: objective=1.1556247
2017/08/27 01:25:03 step 5: objective=1.1589996
2017/08/27 01:25:06 step 6: objective=1.16167
2017/08/27 01:25:08 step 7: objective=1.164658
2017/08/27 01:25:08 Training value function...
2017/08/27 01:25:12 step 0: mse=68.227177 step=0.100000
2017/08/27 01:25:15 step 1: mse=67.065820 step=0.100000
2017/08/27 01:25:17 step 2: mse=66.216392 step=0.100000
2017/08/27 01:25:19 step 3: mse=64.989378 step=0.100000
2017/08/27 01:25:21 step 4: mse=63.572977 step=0.100000
2017/08/27 01:25:24 step 5: mse=62.767779 step=0.100000
2017/08/27 01:25:26 step 6: mse=62.271016 step=0.100000
2017/08/27 01:25:28 step 7: mse=61.129005 step=0.100000
2017/08/27 01:25:28 Saving...
2017/08/27 01:25:28 Gathering batch of experience...
2017/08/27 01:27:15 batch 74: mean=331.750000 stddev=102.320880 entropy=0.734309 frames=5408 count=16
2017/08/27 01:27:15 Training policy...
2017/08/27 01:27:22 step 0: objective=1.6961617
2017/08/27 01:27:24 step 1: objective=1.7023474
2017/08/27 01:27:26 step 2: objective=1.70637
2017/08/27 01:27:29 step 3: objective=1.7091345
2017/08/27 01:27:31 step 4: objective=1.7124394
2017/08/27 01:27:33 step 5: objective=1.715725
2017/08/27 01:27:36 step 6: objective=1.718064
2017/08/27 01:27:38 step 7: objective=1.7202454
2017/08/27 01:27:38 Training value function...
2017/08/27 01:27:43 step 0: mse=56.112906 step=0.100000
2017/08/27 01:27:45 step 1: mse=53.773152 step=0.100000
2017/08/27 01:27:47 step 2: mse=51.714114 step=0.100000
2017/08/27 01:27:49 step 3: mse=49.962790 step=0.100000
2017/08/27 01:27:51 step 4: mse=48.092351 step=0.100000
2017/08/27 01:27:54 step 5: mse=46.692656 step=0.100000
2017/08/27 01:27:56 step 6: mse=45.430625 step=0.100000
2017/08/27 01:27:58 step 7: mse=44.306898 step=0.100000
2017/08/27 01:27:58 Saving...
2017/08/27 01:27:58 Gathering batch of experience...
2017/08/27 01:29:45 batch 75: mean=281.444444 stddev=132.149840 entropy=0.737580 frames=5186 count=18
2017/08/27 01:29:45 Training policy...
2017/08/27 01:29:52 step 0: objective=0.99115247
2017/08/27 01:29:54 step 1: objective=0.9985545
2017/08/27 01:29:56 step 2: objective=1.0043952
2017/08/27 01:29:58 step 3: objective=1.0088886
2017/08/27 01:30:01 step 4: objective=1.0144651
2017/08/27 01:30:03 step 5: objective=1.0181061
2017/08/27 01:30:05 step 6: objective=1.0205154
2017/08/27 01:30:07 step 7: objective=1.023672
2017/08/27 01:30:07 Training value function...
2017/08/27 01:30:12 step 0: mse=51.504789 step=0.100000
2017/08/27 01:30:14 step 1: mse=50.755844 step=0.100000
2017/08/27 01:30:16 step 2: mse=50.049636 step=0.100000
2017/08/27 01:30:18 step 3: mse=49.492308 step=0.100000
2017/08/27 01:30:20 step 4: mse=48.969069 step=0.100000
2017/08/27 01:30:22 step 5: mse=48.611755 step=0.100000
2017/08/27 01:30:24 step 6: mse=47.981338 step=0.100000
2017/08/27 01:30:27 step 7: mse=47.466290 step=0.100000
2017/08/27 01:30:27 Saving...
2017/08/27 01:30:27 Gathering batch of experience...
2017/08/27 01:32:23 batch 76: mean=253.476190 stddev=127.446579 entropy=0.744100 frames=5483 count=21
2017/08/27 01:32:23 Training policy...
2017/08/27 01:32:31 step 0: objective=0.6536781
2017/08/27 01:32:33 step 1: objective=0.65957636
2017/08/27 01:32:35 step 2: objective=0.6656533
2017/08/27 01:32:38 step 3: objective=0.67072135
2017/08/27 01:32:40 step 4: objective=0.67433536
2017/08/27 01:32:42 step 5: objective=0.6785899
2017/08/27 01:32:45 step 6: objective=0.6809018
2017/08/27 01:32:47 step 7: objective=0.68350536
2017/08/27 01:32:47 Training value function...
2017/08/27 01:32:52 step 0: mse=53.664695 step=0.100000
2017/08/27 01:32:54 step 1: mse=53.052888 step=0.100000
2017/08/27 01:32:57 step 2: mse=52.097811 step=0.100000
2017/08/27 01:32:59 step 3: mse=51.480522 step=0.100000
2017/08/27 01:33:01 step 4: mse=50.999650 step=0.100000
2017/08/27 01:33:03 step 5: mse=50.519281 step=0.100000
2017/08/27 01:33:06 step 6: mse=50.240994 step=0.100000
2017/08/27 01:33:08 step 7: mse=49.927991 step=0.100000
2017/08/27 01:33:08 Saving...
2017/08/27 01:33:08 Gathering batch of experience...
2017/08/27 01:34:51 batch 77: mean=268.052632 stddev=126.028599 entropy=0.739872 frames=5231 count=19
2017/08/27 01:34:51 Training policy...
2017/08/27 01:34:57 step 0: objective=0.9980022
2017/08/27 01:34:59 step 1: objective=1.0078003
2017/08/27 01:35:02 step 2: objective=1.0139626
2017/08/27 01:35:04 step 3: objective=1.0191525
2017/08/27 01:35:06 step 4: objective=1.0220442
2017/08/27 01:35:09 step 5: objective=1.0249144
2017/08/27 01:35:11 step 6: objective=1.0283633
2017/08/27 01:35:13 step 7: objective=1.0315943
2017/08/27 01:35:13 Training value function...
2017/08/27 01:35:18 step 0: mse=50.412631 step=0.100000
2017/08/27 01:35:20 step 1: mse=49.590879 step=0.100000
2017/08/27 01:35:22 step 2: mse=48.892979 step=0.100000
2017/08/27 01:35:24 step 3: mse=48.233160 step=0.100000
2017/08/27 01:35:26 step 4: mse=47.645856 step=0.100000
2017/08/27 01:35:28 step 5: mse=47.102248 step=0.100000
2017/08/27 01:35:31 step 6: mse=46.538440 step=0.100000
2017/08/27 01:35:33 step 7: mse=46.099079 step=0.100000
2017/08/27 01:35:33 Saving...
2017/08/27 01:35:33 Gathering batch of experience...
2017/08/27 01:37:14 batch 78: mean=257.105263 stddev=123.599904 entropy=0.747506 frames=5029 count=19
2017/08/27 01:37:14 Training policy...
2017/08/27 01:37:20 step 0: objective=0.9467419
2017/08/27 01:37:22 step 1: objective=0.95643955
2017/08/27 01:37:24 step 2: objective=0.9634922
2017/08/27 01:37:27 step 3: objective=0.96946925
2017/08/27 01:37:29 step 4: objective=0.9728174
2017/08/27 01:37:31 step 5: objective=0.9753
2017/08/27 01:37:33 step 6: objective=0.97852933
2017/08/27 01:37:35 step 7: objective=0.982027
2017/08/27 01:37:35 Training value function...
2017/08/27 01:37:39 step 0: mse=55.203885 step=0.100000
2017/08/27 01:37:41 step 1: mse=54.578197 step=0.100000
2017/08/27 01:37:44 step 2: mse=54.002981 step=0.100000
2017/08/27 01:37:46 step 3: mse=53.559383 step=0.100000
2017/08/27 01:37:48 step 4: mse=53.063584 step=0.100000
2017/08/27 01:37:50 step 5: mse=52.591981 step=0.100000
2017/08/27 01:37:52 step 6: mse=52.221524 step=0.100000
2017/08/27 01:37:54 step 7: mse=51.808777 step=0.100000
2017/08/27 01:37:54 Saving...
2017/08/27 01:37:54 Gathering batch of experience...
2017/08/27 01:39:40 batch 79: mean=289.000000 stddev=114.520255 entropy=0.739297 frames=5334 count=18
2017/08/27 01:39:40 Training policy...
2017/08/27 01:39:46 step 0: objective=1.1844549
2017/08/27 01:39:49 step 1: objective=1.192049
2017/08/27 01:39:51 step 2: objective=1.1987587
2017/08/27 01:39:53 step 3: objective=1.2045323
2017/08/27 01:39:56 step 4: objective=1.2089291
2017/08/27 01:39:58 step 5: objective=1.2122538
2017/08/27 01:40:00 step 6: objective=1.2159303
2017/08/27 01:40:03 step 7: objective=1.2184663
2017/08/27 01:40:03 Training value function...
2017/08/27 01:40:07 step 0: mse=55.212256 step=0.100000
2017/08/27 01:40:09 step 1: mse=54.140759 step=0.100000
2017/08/27 01:40:12 step 2: mse=52.996309 step=0.100000
2017/08/27 01:40:14 step 3: mse=51.585600 step=0.100000
2017/08/27 01:40:16 step 4: mse=50.633479 step=0.100000
2017/08/27 01:40:18 step 5: mse=49.843640 step=0.100000
2017/08/27 01:40:20 step 6: mse=49.149978 step=0.100000
2017/08/27 01:40:23 step 7: mse=48.393951 step=0.100000
2017/08/27 01:40:23 Saving...
2017/08/27 01:40:23 Gathering batch of experience...
2017/08/27 01:42:06 batch 80: mean=258.150000 stddev=134.547863 entropy=0.749922 frames=5307 count=20
2017/08/27 01:42:06 Training policy...
2017/08/27 01:42:12 step 0: objective=0.9515774
2017/08/27 01:42:15 step 1: objective=0.9584888
2017/08/27 01:42:17 step 2: objective=0.9650252
2017/08/27 01:42:19 step 3: objective=0.9695895
2017/08/27 01:42:22 step 4: objective=0.9739947
2017/08/27 01:42:24 step 5: objective=0.9777515
2017/08/27 01:42:26 step 6: objective=0.98039204
2017/08/27 01:42:29 step 7: objective=0.98329777
2017/08/27 01:42:29 Training value function...
2017/08/27 01:42:33 step 0: mse=61.994700 step=0.100000
2017/08/27 01:42:35 step 1: mse=61.386732 step=0.100000
2017/08/27 01:42:37 step 2: mse=60.723558 step=0.100000
2017/08/27 01:42:40 step 3: mse=60.162184 step=0.100000
2017/08/27 01:42:42 step 4: mse=59.525450 step=0.100000
2017/08/27 01:42:44 step 5: mse=59.117319 step=0.100000
2017/08/27 01:42:46 step 6: mse=58.692815 step=0.100000
2017/08/27 01:42:49 step 7: mse=58.267500 step=0.100000
2017/08/27 01:42:49 Saving...
2017/08/27 01:42:49 Gathering batch of experience...
2017/08/27 01:44:24 batch 81: mean=270.611111 stddev=122.037398 entropy=0.738788 frames=5004 count=18
2017/08/27 01:44:24 Training policy...
2017/08/27 01:44:31 step 0: objective=0.957306
2017/08/27 01:44:33 step 1: objective=0.966132
2017/08/27 01:44:35 step 2: objective=0.9726739
2017/08/27 01:44:37 step 3: objective=0.9781744
2017/08/27 01:44:39 step 4: objective=0.98139125
2017/08/27 01:44:41 step 5: objective=0.9853133
2017/08/27 01:44:44 step 6: objective=0.98787075
2017/08/27 01:44:46 step 7: objective=0.9900916
2017/08/27 01:44:46 Training value function...
2017/08/27 01:44:50 step 0: mse=49.795266 step=0.100000
2017/08/27 01:44:52 step 1: mse=49.405877 step=0.100000
2017/08/27 01:44:54 step 2: mse=48.852627 step=0.100000
2017/08/27 01:44:56 step 3: mse=48.350303 step=0.100000
2017/08/27 01:44:58 step 4: mse=48.052799 step=0.100000
2017/08/27 01:45:00 step 5: mse=47.682151 step=0.100000
2017/08/27 01:45:02 step 6: mse=47.332292 step=0.100000
2017/08/27 01:45:04 step 7: mse=46.995290 step=0.100000
2017/08/27 01:45:04 Saving...
2017/08/27 01:45:04 Gathering batch of experience...
2017/08/27 01:46:32 batch 82: mean=321.333333 stddev=139.882173 entropy=0.728850 frames=4894 count=15
2017/08/27 01:46:32 Training policy...
2017/08/27 01:46:38 step 0: objective=1.2269212
2017/08/27 01:46:40 step 1: objective=1.2335826
2017/08/27 01:46:43 step 2: objective=1.2370664
2017/08/27 01:46:45 step 3: objective=1.2409359
2017/08/27 01:46:47 step 4: objective=1.244308
2017/08/27 01:46:49 step 5: objective=1.2478113
2017/08/27 01:46:51 step 6: objective=1.2504631
2017/08/27 01:46:53 step 7: objective=1.2532488
2017/08/27 01:46:53 Training value function...
2017/08/27 01:46:57 step 0: mse=49.309579 step=0.100000
2017/08/27 01:47:00 step 1: mse=48.325809 step=0.100000
2017/08/27 01:47:02 step 2: mse=46.227221 step=0.100000
2017/08/27 01:47:04 step 3: mse=44.753698 step=0.100000
2017/08/27 01:47:06 step 4: mse=44.081607 step=0.100000
2017/08/27 01:47:08 step 5: mse=42.863363 step=0.100000
2017/08/27 01:47:10 step 6: mse=42.274281 step=0.100000
2017/08/27 01:47:12 step 7: mse=41.070712 step=0.100000
2017/08/27 01:47:12 Saving...
2017/08/27 01:47:12 Gathering batch of experience...
2017/08/27 01:48:55 batch 83: mean=288.944444 stddev=154.223673 entropy=0.731729 frames=5297 count=18
2017/08/27 01:48:55 Training policy...
2017/08/27 01:49:02 step 0: objective=1.1588264
2017/08/27 01:49:05 step 1: objective=1.1675414
2017/08/27 01:49:07 step 2: objective=1.1726253
2017/08/27 01:49:09 step 3: objective=1.1770643
2017/08/27 01:49:12 step 4: objective=1.183442
2017/08/27 01:49:14 step 5: objective=1.1863102
2017/08/27 01:49:16 step 6: objective=1.1893957
2017/08/27 01:49:19 step 7: objective=1.1916174
2017/08/27 01:49:19 Training value function...
2017/08/27 01:49:23 step 0: mse=59.356440 step=0.100000
2017/08/27 01:49:25 step 1: mse=57.952167 step=0.100000
2017/08/27 01:49:27 step 2: mse=56.576128 step=0.100000
2017/08/27 01:49:30 step 3: mse=55.514822 step=0.100000
2017/08/27 01:49:32 step 4: mse=54.535770 step=0.100000
2017/08/27 01:49:34 step 5: mse=53.490666 step=0.100000
2017/08/27 01:49:36 step 6: mse=52.744319 step=0.100000
2017/08/27 01:49:39 step 7: mse=52.190525 step=0.100000
2017/08/27 01:49:39 Saving...
2017/08/27 01:49:39 Gathering batch of experience...
2017/08/27 01:51:22 batch 84: mean=299.500000 stddev=129.219129 entropy=0.723574 frames=5506 count=18
2017/08/27 01:51:22 Training policy...
2017/08/27 01:51:29 step 0: objective=1.0271354
2017/08/27 01:51:31 step 1: objective=1.0344746
2017/08/27 01:51:34 step 2: objective=1.0386244
2017/08/27 01:51:36 step 3: objective=1.0434952
2017/08/27 01:51:38 step 4: objective=1.0472286
2017/08/27 01:51:41 step 5: objective=1.0510333
2017/08/27 01:51:43 step 6: objective=1.0545312
2017/08/27 01:51:46 step 7: objective=1.0564133
2017/08/27 01:51:46 Training value function...
2017/08/27 01:51:50 step 0: mse=55.762977 step=0.100000
2017/08/27 01:51:52 step 1: mse=54.903301 step=0.100000
2017/08/27 01:51:55 step 2: mse=54.107817 step=0.100000
2017/08/27 01:51:57 step 3: mse=53.568602 step=0.100000
2017/08/27 01:51:59 step 4: mse=52.902585 step=0.100000
2017/08/27 01:52:02 step 5: mse=52.264428 step=0.100000
2017/08/27 01:52:04 step 6: mse=51.732446 step=0.100000
2017/08/27 01:52:06 step 7: mse=51.323221 step=0.100000
2017/08/27 01:52:06 Saving...
2017/08/27 01:52:06 Gathering batch of experience...
2017/08/27 01:53:50 batch 85: mean=266.631579 stddev=117.708029 entropy=0.744912 frames=5212 count=19
2017/08/27 01:53:50 Training policy...
2017/08/27 01:53:57 step 0: objective=0.65605783
2017/08/27 01:53:59 step 1: objective=0.6639964
2017/08/27 01:54:01 step 2: objective=0.66854
2017/08/27 01:54:03 step 3: objective=0.672946
2017/08/27 01:54:06 step 4: objective=0.67755234
2017/08/27 01:54:08 step 5: objective=0.6812857
2017/08/27 01:54:10 step 6: objective=0.6840438
2017/08/27 01:54:13 step 7: objective=0.6865218
2017/08/27 01:54:13 Training value function...
2017/08/27 01:54:17 step 0: mse=49.578805 step=0.100000
2017/08/27 01:54:19 step 1: mse=48.868543 step=0.100000
2017/08/27 01:54:21 step 2: mse=48.555497 step=0.100000
2017/08/27 01:54:23 step 3: mse=47.974110 step=0.100000
2017/08/27 01:54:26 step 4: mse=47.793041 step=0.100000
2017/08/27 01:54:28 step 5: mse=47.703802 step=0.100000
2017/08/27 01:54:30 step 6: mse=47.593779 step=0.100000
2017/08/27 01:54:32 step 7: mse=47.431659 step=0.100000
2017/08/27 01:54:32 Saving...
2017/08/27 01:54:32 Gathering batch of experience...
2017/08/27 01:56:26 batch 86: mean=314.529412 stddev=143.352760 entropy=0.739673 frames=5429 count=17
2017/08/27 01:56:26 Training policy...
2017/08/27 01:56:33 step 0: objective=1.4061223
2017/08/27 01:56:35 step 1: objective=1.4120715
2017/08/27 01:56:38 step 2: objective=1.4176987
2017/08/27 01:56:40 step 3: objective=1.4214945
2017/08/27 01:56:42 step 4: objective=1.4258883
2017/08/27 01:56:45 step 5: objective=1.4287778
2017/08/27 01:56:47 step 6: objective=1.4319261
2017/08/27 01:56:50 step 7: objective=1.4346509
2017/08/27 01:56:50 Training value function...
2017/08/27 01:56:54 step 0: mse=56.412389 step=0.100000
2017/08/27 01:56:56 step 1: mse=54.940701 step=0.100000
2017/08/27 01:56:59 step 2: mse=53.356371 step=0.100000
2017/08/27 01:57:01 step 3: mse=51.983773 step=0.100000
2017/08/27 01:57:03 step 4: mse=50.559440 step=0.100000
2017/08/27 01:57:05 step 5: mse=49.674918 step=0.100000
2017/08/27 01:57:08 step 6: mse=48.504736 step=0.100000
2017/08/27 01:57:10 step 7: mse=47.849262 step=0.100000
2017/08/27 01:57:10 Saving...
2017/08/27 01:57:10 Gathering batch of experience...
2017/08/27 01:58:59 batch 87: mean=267.142857 stddev=141.130566 entropy=0.740729 frames=5744 count=21
2017/08/27 01:58:59 Training policy...
2017/08/27 01:59:06 step 0: objective=0.70276296
2017/08/27 01:59:09 step 1: objective=0.71000147
2017/08/27 01:59:12 step 2: objective=0.7167682
2017/08/27 01:59:14 step 3: objective=0.7203903
2017/08/27 01:59:17 step 4: objective=0.72441393
2017/08/27 01:59:19 step 5: objective=0.72754806
2017/08/27 01:59:22 step 6: objective=0.73025054
2017/08/27 01:59:24 step 7: objective=0.7325593
2017/08/27 01:59:24 Training value function...
2017/08/27 01:59:29 step 0: mse=49.381356 step=0.100000
2017/08/27 01:59:31 step 1: mse=49.218397 step=0.100000
2017/08/27 01:59:34 step 2: mse=49.068097 step=0.100000
2017/08/27 01:59:36 step 3: mse=48.573991 step=0.100000
2017/08/27 01:59:39 step 4: mse=48.441423 step=0.100000
2017/08/27 01:59:41 step 5: mse=48.064196 step=0.100000
2017/08/27 01:59:44 step 6: mse=48.007435 step=0.100000
2017/08/27 01:59:46 step 7: mse=47.881003 step=0.100000
2017/08/27 01:59:46 Saving...
2017/08/27 01:59:46 Gathering batch of experience...
2017/08/27 02:01:27 batch 88: mean=321.687500 stddev=145.968626 entropy=0.737328 frames=5221 count=16
2017/08/27 02:01:27 Training policy...
2017/08/27 02:01:34 step 0: objective=1.407198
2017/08/27 02:01:36 step 1: objective=1.4138609
2017/08/27 02:01:39 step 2: objective=1.418319
2017/08/27 02:01:41 step 3: objective=1.4225794
2017/08/27 02:01:43 step 4: objective=1.4258945
2017/08/27 02:01:46 step 5: objective=1.4291164
2017/08/27 02:01:48 step 6: objective=1.4313356
2017/08/27 02:01:50 step 7: objective=1.4337553
2017/08/27 02:01:50 Training value function...
2017/08/27 02:01:55 step 0: mse=56.468753 step=0.100000
2017/08/27 02:01:57 step 1: mse=55.012301 step=0.100000
2017/08/27 02:01:59 step 2: mse=53.603381 step=0.100000
2017/08/27 02:02:01 step 3: mse=52.537774 step=0.100000
2017/08/27 02:02:03 step 4: mse=51.586998 step=0.100000
2017/08/27 02:02:05 step 5: mse=50.749063 step=0.100000
2017/08/27 02:02:07 step 6: mse=49.920780 step=0.100000
2017/08/27 02:02:10 step 7: mse=48.865329 step=0.100000
2017/08/27 02:02:10 Saving...
2017/08/27 02:02:10 Gathering batch of experience...
2017/08/27 02:03:46 batch 89: mean=258.684211 stddev=151.699860 entropy=0.743635 frames=5033 count=19
2017/08/27 02:03:46 Training policy...
2017/08/27 02:03:53 step 0: objective=0.7554783
2017/08/27 02:03:55 step 1: objective=0.76321536
2017/08/27 02:03:57 step 2: objective=0.7695129
2017/08/27 02:03:59 step 3: objective=0.7740481
2017/08/27 02:04:02 step 4: objective=0.77813476
2017/08/27 02:04:04 step 5: objective=0.7813455
2017/08/27 02:04:06 step 6: objective=0.7850753
2017/08/27 02:04:08 step 7: objective=0.78812283
2017/08/27 02:04:08 Training value function...
2017/08/27 02:04:12 step 0: mse=62.000438 step=0.100000
2017/08/27 02:04:14 step 1: mse=61.387276 step=0.100000
2017/08/27 02:04:16 step 2: mse=60.888904 step=0.100000
2017/08/27 02:04:19 step 3: mse=60.387123 step=0.100000
2017/08/27 02:04:21 step 4: mse=59.987132 step=0.100000
2017/08/27 02:04:23 step 5: mse=59.670224 step=0.100000
2017/08/27 02:04:25 step 6: mse=59.276022 step=0.100000
2017/08/27 02:04:27 step 7: mse=58.940625 step=0.100000
2017/08/27 02:04:27 Saving...
2017/08/27 02:04:27 Gathering batch of experience...
2017/08/27 02:06:12 batch 90: mean=293.055556 stddev=124.737712 entropy=0.725421 frames=5397 count=18
2017/08/27 02:06:12 Training policy...
2017/08/27 02:06:19 step 0: objective=0.99460006
2017/08/27 02:06:22 step 1: objective=1.0004941
2017/08/27 02:06:24 step 2: objective=1.0052438
2017/08/27 02:06:27 step 3: objective=1.0098144
2017/08/27 02:06:29 step 4: objective=1.0139197
2017/08/27 02:06:31 step 5: objective=1.0166051
2017/08/27 02:06:34 step 6: objective=1.0189451
2017/08/27 02:06:36 step 7: objective=1.0215298
2017/08/27 02:06:36 Training value function...
2017/08/27 02:06:40 step 0: mse=52.617151 step=0.100000
2017/08/27 02:06:43 step 1: mse=52.094652 step=0.100000
2017/08/27 02:06:45 step 2: mse=51.519967 step=0.100000
2017/08/27 02:06:47 step 3: mse=50.965739 step=0.100000
2017/08/27 02:06:49 step 4: mse=50.575719 step=0.100000
2017/08/27 02:06:52 step 5: mse=50.070727 step=0.100000
2017/08/27 02:06:54 step 6: mse=49.605649 step=0.100000
2017/08/27 02:06:56 step 7: mse=49.160904 step=0.100000
2017/08/27 02:06:56 Saving...
2017/08/27 02:06:56 Gathering batch of experience...
2017/08/27 02:08:43 batch 91: mean=326.411765 stddev=156.699059 entropy=0.722293 frames=5613 count=17
2017/08/27 02:08:43 Training policy...
2017/08/27 02:08:51 step 0: objective=1.4342204
2017/08/27 02:08:53 step 1: objective=1.4424461
2017/08/27 02:08:56 step 2: objective=1.4472601
2017/08/27 02:08:58 step 3: objective=1.4522284
2017/08/27 02:09:01 step 4: objective=1.4554682
2017/08/27 02:09:03 step 5: objective=1.4589438
2017/08/27 02:09:06 step 6: objective=1.4638557
2017/08/27 02:09:08 step 7: objective=1.4673289
2017/08/27 02:09:08 Training value function...
2017/08/27 02:09:13 step 0: mse=61.475583 step=0.100000
2017/08/27 02:09:15 step 1: mse=59.671883 step=0.100000
2017/08/27 02:09:17 step 2: mse=57.984117 step=0.100000
2017/08/27 02:09:20 step 3: mse=56.442050 step=0.100000
2017/08/27 02:09:22 step 4: mse=54.949166 step=0.100000
2017/08/27 02:09:24 step 5: mse=53.848620 step=0.100000
2017/08/27 02:09:27 step 6: mse=52.908424 step=0.100000
2017/08/27 02:09:29 step 7: mse=52.028542 step=0.100000
2017/08/27 02:09:29 Saving...
2017/08/27 02:09:29 Gathering batch of experience...
2017/08/27 02:11:08 batch 92: mean=248.285714 stddev=154.659732 entropy=0.740475 frames=5338 count=21
2017/08/27 02:11:08 Training policy...
2017/08/27 02:11:15 step 0: objective=0.7264273
2017/08/27 02:11:17 step 1: objective=0.7344474
2017/08/27 02:11:20 step 2: objective=0.7422845
2017/08/27 02:11:22 step 3: objective=0.74713075
2017/08/27 02:11:24 step 4: objective=0.75049573
2017/08/27 02:11:27 step 5: objective=0.7540748
2017/08/27 02:11:29 step 6: objective=0.75714904
2017/08/27 02:11:31 step 7: objective=0.76045483
2017/08/27 02:11:31 Training value function...
2017/08/27 02:11:36 step 0: mse=54.797799 step=0.100000
2017/08/27 02:11:38 step 1: mse=54.377622 step=0.100000
2017/08/27 02:11:40 step 2: mse=54.048087 step=0.100000
2017/08/27 02:11:43 step 3: mse=53.594650 step=0.100000
2017/08/27 02:11:45 step 4: mse=53.247772 step=0.100000
2017/08/27 02:11:47 step 5: mse=52.861057 step=0.100000
2017/08/27 02:11:49 step 6: mse=52.536934 step=0.100000
2017/08/27 02:11:52 step 7: mse=52.198976 step=0.100000
2017/08/27 02:11:52 Saving...
2017/08/27 02:11:52 Gathering batch of experience...
2017/08/27 02:13:27 batch 93: mean=290.529412 stddev=136.669252 entropy=0.732233 frames=5047 count=17
2017/08/27 02:13:27 Training policy...
2017/08/27 02:13:33 step 0: objective=1.1001884
2017/08/27 02:13:35 step 1: objective=1.1064163
2017/08/27 02:13:38 step 2: objective=1.1105071
2017/08/27 02:13:40 step 3: objective=1.1148382
2017/08/27 02:13:42 step 4: objective=1.1185831
2017/08/27 02:13:44 step 5: objective=1.1219116
2017/08/27 02:13:47 step 6: objective=1.1243931
2017/08/27 02:13:49 step 7: objective=1.1286803
2017/08/27 02:13:49 Training value function...
2017/08/27 02:13:53 step 0: mse=55.271667 step=0.100000
2017/08/27 02:13:55 step 1: mse=54.414519 step=0.100000
2017/08/27 02:13:57 step 2: mse=53.678053 step=0.100000
2017/08/27 02:13:59 step 3: mse=52.953146 step=0.100000
2017/08/27 02:14:02 step 4: mse=52.178281 step=0.100000
2017/08/27 02:14:04 step 5: mse=51.560288 step=0.100000
2017/08/27 02:14:06 step 6: mse=51.075927 step=0.100000
2017/08/27 02:14:08 step 7: mse=50.577705 step=0.100000
2017/08/27 02:14:08 Saving...
2017/08/27 02:14:08 Gathering batch of experience...
2017/08/27 02:15:56 batch 94: mean=272.619048 stddev=149.028114 entropy=0.734262 frames=5855 count=21
2017/08/27 02:15:56 Training policy...
2017/08/27 02:16:03 step 0: objective=0.79836506
2017/08/27 02:16:06 step 1: objective=0.8054268
2017/08/27 02:16:08 step 2: objective=0.81017137
2017/08/27 02:16:11 step 3: objective=0.8136623
2017/08/27 02:16:14 step 4: objective=0.818734
2017/08/27 02:16:16 step 5: objective=0.82245034
2017/08/27 02:16:19 step 6: objective=0.82645136
2017/08/27 02:16:21 step 7: objective=0.82913464
2017/08/27 02:16:21 Training value function...
2017/08/27 02:16:26 step 0: mse=54.233646 step=0.100000
2017/08/27 02:16:29 step 1: mse=53.898512 step=0.100000
2017/08/27 02:16:31 step 2: mse=53.461649 step=0.100000
2017/08/27 02:16:33 step 3: mse=53.081163 step=0.100000
2017/08/27 02:16:36 step 4: mse=52.629690 step=0.100000
2017/08/27 02:16:38 step 5: mse=52.172498 step=0.100000
2017/08/27 02:16:41 step 6: mse=51.852701 step=0.100000
2017/08/27 02:16:43 step 7: mse=51.542025 step=0.100000
2017/08/27 02:16:43 Saving...
2017/08/27 02:16:43 Gathering batch of experience...
2017/08/27 02:18:35 batch 95: mean=266.300000 stddev=154.398867 entropy=0.742499 frames=5442 count=20
2017/08/27 02:18:35 Training policy...
2017/08/27 02:18:43 step 0: objective=1.0067242
2017/08/27 02:18:45 step 1: objective=1.0166222
2017/08/27 02:18:47 step 2: objective=1.02393
2017/08/27 02:18:50 step 3: objective=1.0277523
2017/08/27 02:18:52 step 4: objective=1.0301484
2017/08/27 02:18:55 step 5: objective=1.033822
2017/08/27 02:18:57 step 6: objective=1.0374881
2017/08/27 02:19:00 step 7: objective=1.0406746
2017/08/27 02:19:00 Training value function...
2017/08/27 02:19:04 step 0: mse=58.637720 step=0.100000
2017/08/27 02:19:06 step 1: mse=57.779358 step=0.100000
2017/08/27 02:19:09 step 2: mse=56.985750 step=0.100000
2017/08/27 02:19:11 step 3: mse=56.265036 step=0.100000
2017/08/27 02:19:13 step 4: mse=55.654752 step=0.100000
2017/08/27 02:19:15 step 5: mse=55.167945 step=0.100000
2017/08/27 02:19:18 step 6: mse=54.710371 step=0.100000
2017/08/27 02:19:20 step 7: mse=54.239375 step=0.100000
2017/08/27 02:19:20 Saving...
2017/08/27 02:19:20 Gathering batch of experience...
2017/08/27 02:20:52 batch 96: mean=254.421053 stddev=108.604214 entropy=0.747950 frames=4994 count=19
2017/08/27 02:20:52 Training policy...
2017/08/27 02:20:59 step 0: objective=0.65933937
2017/08/27 02:21:01 step 1: objective=0.6671893
2017/08/27 02:21:03 step 2: objective=0.6738003
2017/08/27 02:21:05 step 3: objective=0.67736197
2017/08/27 02:21:08 step 4: objective=0.68136394
2017/08/27 02:21:10 step 5: objective=0.6851675
2017/08/27 02:21:12 step 6: objective=0.68782115
2017/08/27 02:21:14 step 7: objective=0.69096076
2017/08/27 02:21:14 Training value function...
2017/08/27 02:21:18 step 0: mse=53.607886 step=0.100000
2017/08/27 02:21:20 step 1: mse=53.025706 step=0.100000
2017/08/27 02:21:22 step 2: mse=52.710772 step=0.100000
2017/08/27 02:21:24 step 3: mse=51.782088 step=0.100000
2017/08/27 02:21:26 step 4: mse=51.028987 step=0.100000
2017/08/27 02:21:29 step 5: mse=50.577403 step=0.100000
2017/08/27 02:21:31 step 6: mse=50.339948 step=0.100000
2017/08/27 02:21:33 step 7: mse=50.047688 step=0.100000
2017/08/27 02:21:33 Saving...
2017/08/27 02:21:33 Gathering batch of experience...
2017/08/27 02:23:24 batch 97: mean=332.823529 stddev=135.914435 entropy=0.722019 frames=5736 count=17
2017/08/27 02:23:24 Training policy...
2017/08/27 02:23:31 step 0: objective=1.5833808
2017/08/27 02:23:34 step 1: objective=1.5914545
2017/08/27 02:23:36 step 2: objective=1.5971229
2017/08/27 02:23:39 step 3: objective=1.6001744
2017/08/27 02:23:41 step 4: objective=1.6037177
2017/08/27 02:23:44 step 5: objective=1.6066198
2017/08/27 02:23:46 step 6: objective=1.6088704
2017/08/27 02:23:49 step 7: objective=1.6118044
2017/08/27 02:23:49 Training value function...
2017/08/27 02:23:54 step 0: mse=58.055664 step=0.100000
2017/08/27 02:23:56 step 1: mse=55.960111 step=0.100000
2017/08/27 02:23:59 step 2: mse=54.101005 step=0.100000
2017/08/27 02:24:01 step 3: mse=52.485809 step=0.100000
2017/08/27 02:24:03 step 4: mse=51.147948 step=0.100000
2017/08/27 02:24:06 step 5: mse=49.791871 step=0.100000
2017/08/27 02:24:08 step 6: mse=48.611388 step=0.100000
2017/08/27 02:24:11 step 7: mse=47.523368 step=0.100000
2017/08/27 02:24:11 Saving...
2017/08/27 02:24:11 Gathering batch of experience...
2017/08/27 02:25:53 batch 98: mean=234.863636 stddev=162.087601 entropy=0.734409 frames=5289 count=22
2017/08/27 02:25:53 Training policy...
2017/08/27 02:26:00 step 0: objective=0.73729944
2017/08/27 02:26:03 step 1: objective=0.7449565
2017/08/27 02:26:05 step 2: objective=0.75232947
2017/08/27 02:26:07 step 3: objective=0.75668335
2017/08/27 02:26:10 step 4: objective=0.7607799
2017/08/27 02:26:12 step 5: objective=0.7636325
2017/08/27 02:26:14 step 6: objective=0.7658089
2017/08/27 02:26:17 step 7: objective=0.7685316
2017/08/27 02:26:17 Training value function...
2017/08/27 02:26:21 step 0: mse=63.430653 step=0.100000
2017/08/27 02:26:23 step 1: mse=62.913447 step=0.100000
2017/08/27 02:26:25 step 2: mse=62.265354 step=0.100000
2017/08/27 02:26:28 step 3: mse=61.905767 step=0.100000
2017/08/27 02:26:30 step 4: mse=61.196622 step=0.100000
2017/08/27 02:26:32 step 5: mse=60.492763 step=0.100000
2017/08/27 02:26:34 step 6: mse=60.046828 step=0.100000
2017/08/27 02:26:36 step 7: mse=59.395575 step=0.100000
2017/08/27 02:26:36 Saving...
2017/08/27 02:26:36 Gathering batch of experience...
2017/08/27 02:28:22 batch 99: mean=234.363636 stddev=137.579909 entropy=0.739942 frames=5315 count=22
2017/08/27 02:28:22 Training policy...
2017/08/27 02:28:29 step 0: objective=0.80159944
2017/08/27 02:28:31 step 1: objective=0.8090563
2017/08/27 02:28:34 step 2: objective=0.8153939
2017/08/27 02:28:36 step 3: objective=0.8209418
2017/08/27 02:28:38 step 4: objective=0.825008
2017/08/27 02:28:41 step 5: objective=0.82917875
2017/08/27 02:28:43 step 6: objective=0.8341723
2017/08/27 02:28:45 step 7: objective=0.8374195
2017/08/27 02:28:45 Training value function...
2017/08/27 02:28:50 step 0: mse=58.480004 step=0.100000
2017/08/27 02:28:52 step 1: mse=57.983849 step=0.100000
2017/08/27 02:28:54 step 2: mse=57.591084 step=0.100000
2017/08/27 02:28:56 step 3: mse=56.906117 step=0.100000
2017/08/27 02:28:59 step 4: mse=56.342549 step=0.100000
2017/08/27 02:29:01 step 5: mse=56.043692 step=0.100000
2017/08/27 02:29:03 step 6: mse=55.688849 step=0.100000
2017/08/27 02:29:05 step 7: mse=55.449058 step=0.100000
2017/08/27 02:29:05 Saving...
2017/08/27 02:29:05 Gathering batch of experience...
2017/08/27 02:30:50 batch 100: mean=283.722222 stddev=125.708572 entropy=0.723313 frames=5232 count=18
2017/08/27 02:30:50 Training policy...
2017/08/27 02:30:57 step 0: objective=1.1670264
2017/08/27 02:30:59 step 1: objective=1.1738164
2017/08/27 02:31:02 step 2: objective=1.1785423
2017/08/27 02:31:04 step 3: objective=1.1826992
2017/08/27 02:31:07 step 4: objective=1.1859279
2017/08/27 02:31:09 step 5: objective=1.1907895
2017/08/27 02:31:11 step 6: objective=1.1940364
2017/08/27 02:31:14 step 7: objective=1.1971364
2017/08/27 02:31:14 Training value function...
2017/08/27 02:31:18 step 0: mse=53.129047 step=0.100000
2017/08/27 02:31:20 step 1: mse=52.161401 step=0.100000
2017/08/27 02:31:22 step 2: mse=51.108344 step=0.100000
2017/08/27 02:31:25 step 3: mse=50.089048 step=0.100000
2017/08/27 02:31:27 step 4: mse=49.207596 step=0.100000
2017/08/27 02:31:29 step 5: mse=48.528224 step=0.100000
2017/08/27 02:31:31 step 6: mse=47.959716 step=0.100000
2017/08/27 02:31:33 step 7: mse=47.548654 step=0.100000
2017/08/27 02:31:33 Saving...
2017/08/27 02:31:33 Gathering batch of experience...
2017/08/27 02:33:13 batch 101: mean=256.526316 stddev=135.029965 entropy=0.724735 frames=5006 count=19
2017/08/27 02:33:13 Training policy...
2017/08/27 02:33:19 step 0: objective=0.9164182
2017/08/27 02:33:22 step 1: objective=0.9243487
2017/08/27 02:33:24 step 2: objective=0.9299523
2017/08/27 02:33:26 step 3: objective=0.9331269
2017/08/27 02:33:28 step 4: objective=0.93679994
2017/08/27 02:33:31 step 5: objective=0.9407759
2017/08/27 02:33:33 step 6: objective=0.9447379
2017/08/27 02:33:35 step 7: objective=0.9472123
2017/08/27 02:33:35 Training value function...
2017/08/27 02:33:39 step 0: mse=53.360830 step=0.100000
2017/08/27 02:33:41 step 1: mse=52.566488 step=0.100000
2017/08/27 02:33:43 step 2: mse=52.127808 step=0.100000
2017/08/27 02:33:45 step 3: mse=51.729133 step=0.100000
2017/08/27 02:33:47 step 4: mse=51.308477 step=0.100000
2017/08/27 02:33:50 step 5: mse=50.781996 step=0.100000
2017/08/27 02:33:52 step 6: mse=50.464642 step=0.100000
2017/08/27 02:33:54 step 7: mse=50.169678 step=0.100000
2017/08/27 02:33:54 Saving...
2017/08/27 02:33:54 Gathering batch of experience...
2017/08/27 02:35:44 batch 102: mean=301.777778 stddev=179.629729 entropy=0.722309 frames=5494 count=18
2017/08/27 02:35:44 Training policy...
2017/08/27 02:35:51 step 0: objective=1.4424806
2017/08/27 02:35:54 step 1: objective=1.4517509
2017/08/27 02:35:56 step 2: objective=1.4578725
2017/08/27 02:35:59 step 3: objective=1.461323
2017/08/27 02:36:01 step 4: objective=1.4664307
2017/08/27 02:36:04 step 5: objective=1.4723034
2017/08/27 02:36:06 step 6: objective=1.4758872
2017/08/27 02:36:09 step 7: objective=1.4793471
2017/08/27 02:36:09 Training value function...
2017/08/27 02:36:13 step 0: mse=70.752331 step=0.100000
2017/08/27 02:36:16 step 1: mse=68.367846 step=0.100000
2017/08/27 02:36:18 step 2: mse=66.223987 step=0.100000
2017/08/27 02:36:20 step 3: mse=64.191608 step=0.100000
2017/08/27 02:36:22 step 4: mse=62.727652 step=0.100000
2017/08/27 02:36:25 step 5: mse=61.493061 step=0.100000
2017/08/27 02:36:27 step 6: mse=60.554218 step=0.100000
2017/08/27 02:36:29 step 7: mse=59.316978 step=0.100000
2017/08/27 02:36:29 Saving...
2017/08/27 02:36:29 Gathering batch of experience...
2017/08/27 02:38:05 batch 103: mean=290.411765 stddev=129.588516 entropy=0.721219 frames=5049 count=17
2017/08/27 02:38:05 Training policy...
2017/08/27 02:38:12 step 0: objective=0.91879404
2017/08/27 02:38:14 step 1: objective=0.92727
2017/08/27 02:38:16 step 2: objective=0.9325294
2017/08/27 02:38:18 step 3: objective=0.9377989
2017/08/27 02:38:21 step 4: objective=0.9417807
2017/08/27 02:38:23 step 5: objective=0.94679207
2017/08/27 02:38:25 step 6: objective=0.9495112
2017/08/27 02:38:27 step 7: objective=0.95156676
2017/08/27 02:38:27 Training value function...
2017/08/27 02:38:31 step 0: mse=54.914307 step=0.100000
2017/08/27 02:38:34 step 1: mse=54.362279 step=0.100000
2017/08/27 02:38:36 step 2: mse=53.718161 step=0.100000
2017/08/27 02:38:38 step 3: mse=53.012931 step=0.100000
2017/08/27 02:38:40 step 4: mse=52.404871 step=0.100000
2017/08/27 02:38:42 step 5: mse=51.732461 step=0.100000
2017/08/27 02:38:44 step 6: mse=51.305982 step=0.100000
2017/08/27 02:38:46 step 7: mse=50.907350 step=0.100000
2017/08/27 02:38:46 Saving...
2017/08/27 02:38:46 Gathering batch of experience...
2017/08/27 02:40:38 batch 104: mean=323.470588 stddev=128.872996 entropy=0.719783 frames=5592 count=17
2017/08/27 02:40:38 Training policy...
2017/08/27 02:40:45 step 0: objective=1.2457885
2017/08/27 02:40:47 step 1: objective=1.2528414
2017/08/27 02:40:50 step 2: objective=1.2590925
2017/08/27 02:40:52 step 3: objective=1.2634344
2017/08/27 02:40:55 step 4: objective=1.2678872
2017/08/27 02:40:57 step 5: objective=1.2726151
2017/08/27 02:41:00 step 6: objective=1.2755668
2017/08/27 02:41:02 step 7: objective=1.2794925
2017/08/27 02:41:02 Training value function...
2017/08/27 02:41:07 step 0: mse=56.177393 step=0.100000
2017/08/27 02:41:09 step 1: mse=55.061528 step=0.100000
2017/08/27 02:41:12 step 2: mse=54.130211 step=0.100000
2017/08/27 02:41:14 step 3: mse=53.347616 step=0.100000
2017/08/27 02:41:16 step 4: mse=52.265175 step=0.100000
2017/08/27 02:41:19 step 5: mse=51.488863 step=0.100000
2017/08/27 02:41:21 step 6: mse=50.735771 step=0.100000
2017/08/27 02:41:23 step 7: mse=49.939780 step=0.100000
2017/08/27 02:41:23 Saving...
2017/08/27 02:41:23 Gathering batch of experience...
2017/08/27 02:43:09 batch 105: mean=319.647059 stddev=130.353791 entropy=0.714629 frames=5527 count=17
2017/08/27 02:43:09 Training policy...
2017/08/27 02:43:16 step 0: objective=0.99687386
2017/08/27 02:43:19 step 1: objective=1.0032728
2017/08/27 02:43:21 step 2: objective=1.0070102
2017/08/27 02:43:23 step 3: objective=1.009929
2017/08/27 02:43:26 step 4: objective=1.0124352
2017/08/27 02:43:28 step 5: objective=1.0160172
2017/08/27 02:43:31 step 6: objective=1.0176744
2017/08/27 02:43:33 step 7: objective=1.0201157
2017/08/27 02:43:33 Training value function...
2017/08/27 02:43:38 step 0: mse=49.077230 step=0.100000
2017/08/27 02:43:40 step 1: mse=48.482968 step=0.100000
2017/08/27 02:43:43 step 2: mse=47.856190 step=0.100000
2017/08/27 02:43:45 step 3: mse=47.451270 step=0.100000
2017/08/27 02:43:47 step 4: mse=46.998279 step=0.100000
2017/08/27 02:43:49 step 5: mse=46.544236 step=0.100000
2017/08/27 02:43:52 step 6: mse=46.059963 step=0.100000
2017/08/27 02:43:54 step 7: mse=45.558871 step=0.100000
2017/08/27 02:43:54 Saving...
2017/08/27 02:43:54 Gathering batch of experience...
2017/08/27 02:45:49 batch 106: mean=306.823529 stddev=143.783839 entropy=0.716177 frames=5305 count=17
2017/08/27 02:45:49 Training policy...
2017/08/27 02:45:56 step 0: objective=0.9448973
2017/08/27 02:45:59 step 1: objective=0.95184857
2017/08/27 02:46:01 step 2: objective=0.9566221
2017/08/27 02:46:03 step 3: objective=0.9606637
2017/08/27 02:46:06 step 4: objective=0.9639007
2017/08/27 02:46:08 step 5: objective=0.9666616
2017/08/27 02:46:11 step 6: objective=0.9685961
2017/08/27 02:46:13 step 7: objective=0.9727652
2017/08/27 02:46:13 Training value function...
2017/08/27 02:46:17 step 0: mse=51.477849 step=0.100000
2017/08/27 02:46:20 step 1: mse=50.851662 step=0.100000
2017/08/27 02:46:22 step 2: mse=50.188382 step=0.100000
2017/08/27 02:46:24 step 3: mse=49.688010 step=0.100000
2017/08/27 02:46:26 step 4: mse=49.251288 step=0.100000
2017/08/27 02:46:28 step 5: mse=48.748031 step=0.100000
2017/08/27 02:46:31 step 6: mse=48.257784 step=0.100000
2017/08/27 02:46:33 step 7: mse=47.849687 step=0.100000
2017/08/27 02:46:33 Saving...
2017/08/27 02:46:33 Gathering batch of experience...
2017/08/27 02:48:22 batch 107: mean=344.687500 stddev=115.889882 entropy=0.711212 frames=5594 count=16
2017/08/27 02:48:22 Training policy...
2017/08/27 02:48:30 step 0: objective=1.223098
2017/08/27 02:48:32 step 1: objective=1.229055
2017/08/27 02:48:35 step 2: objective=1.234845
2017/08/27 02:48:37 step 3: objective=1.2386698
2017/08/27 02:48:40 step 4: objective=1.2412555
2017/08/27 02:48:42 step 5: objective=1.2451317
2017/08/27 02:48:45 step 6: objective=1.247838
2017/08/27 02:48:48 step 7: objective=1.2505449
2017/08/27 02:48:48 Training value function...
2017/08/27 02:48:52 step 0: mse=50.880762 step=0.100000
2017/08/27 02:48:54 step 1: mse=49.892421 step=0.100000
2017/08/27 02:48:57 step 2: mse=48.822958 step=0.100000
2017/08/27 02:48:59 step 3: mse=47.967178 step=0.100000
2017/08/27 02:49:01 step 4: mse=47.207594 step=0.100000
2017/08/27 02:49:04 step 5: mse=46.327481 step=0.100000
2017/08/27 02:49:06 step 6: mse=45.832847 step=0.100000
2017/08/27 02:49:08 step 7: mse=45.208986 step=0.100000
2017/08/27 02:49:08 Saving...
2017/08/27 02:49:08 Gathering batch of experience...
2017/08/27 02:50:54 batch 108: mean=267.150000 stddev=131.564917 entropy=0.718665 frames=5487 count=20
2017/08/27 02:50:54 Training policy...
2017/08/27 02:51:01 step 0: objective=0.4799368
2017/08/27 02:51:03 step 1: objective=0.48964873
2017/08/27 02:51:06 step 2: objective=0.4940799
2017/08/27 02:51:08 step 3: objective=0.49879354
2017/08/27 02:51:11 step 4: objective=0.50180817
2017/08/27 02:51:13 step 5: objective=0.5047018
2017/08/27 02:51:16 step 6: objective=0.5076639
2017/08/27 02:51:18 step 7: objective=0.50945675
2017/08/27 02:51:18 Training value function...
2017/08/27 02:51:23 step 0: mse=50.256266 step=0.100000
2017/08/27 02:51:25 step 1: mse=49.727785 step=0.100000
2017/08/27 02:51:27 step 2: mse=49.380247 step=0.100000
2017/08/27 02:51:29 step 3: mse=49.072350 step=0.100000
2017/08/27 02:51:32 step 4: mse=48.841709 step=0.100000
2017/08/27 02:51:34 step 5: mse=48.660350 step=0.100000
2017/08/27 02:51:36 step 6: mse=48.482574 step=0.100000
2017/08/27 02:51:39 step 7: mse=48.329709 step=0.100000
2017/08/27 02:51:39 Saving...
2017/08/27 02:51:39 Gathering batch of experience...
2017/08/27 02:53:16 batch 109: mean=268.052632 stddev=158.049784 entropy=0.719836 frames=5197 count=19
2017/08/27 02:53:16 Training policy...
2017/08/27 02:53:23 step 0: objective=1.0381285
2017/08/27 02:53:25 step 1: objective=1.0450525
2017/08/27 02:53:28 step 2: objective=1.0503899
2017/08/27 02:53:30 step 3: objective=1.0547268
2017/08/27 02:53:32 step 4: objective=1.0591727
2017/08/27 02:53:35 step 5: objective=1.0625774
2017/08/27 02:53:37 step 6: objective=1.0643437
2017/08/27 02:53:39 step 7: objective=1.0668372
2017/08/27 02:53:39 Training value function...
2017/08/27 02:53:44 step 0: mse=57.089925 step=0.100000
2017/08/27 02:53:46 step 1: mse=56.209875 step=0.100000
2017/08/27 02:53:48 step 2: mse=55.498757 step=0.100000
2017/08/27 02:53:50 step 3: mse=54.843655 step=0.100000
2017/08/27 02:53:52 step 4: mse=54.148074 step=0.100000
2017/08/27 02:53:54 step 5: mse=53.607836 step=0.100000
2017/08/27 02:53:57 step 6: mse=53.124655 step=0.100000
2017/08/27 02:53:59 step 7: mse=52.694558 step=0.100000
2017/08/27 02:53:59 Saving...
2017/08/27 02:53:59 Gathering batch of experience...
2017/08/27 02:55:49 batch 110: mean=341.533333 stddev=131.956491 entropy=0.707923 frames=5188 count=15
2017/08/27 02:55:49 Training policy...
2017/08/27 02:55:55 step 0: objective=1.4146035
2017/08/27 02:55:58 step 1: objective=1.4223629
2017/08/27 02:56:00 step 2: objective=1.4281051
2017/08/27 02:56:02 step 3: objective=1.4315262
2017/08/27 02:56:05 step 4: objective=1.4351914
2017/08/27 02:56:07 step 5: objective=1.4396106
2017/08/27 02:56:10 step 6: objective=1.4435536
2017/08/27 02:56:12 step 7: objective=1.4459682
2017/08/27 02:56:12 Training value function...
2017/08/27 02:56:16 step 0: mse=55.850340 step=0.100000
2017/08/27 02:56:18 step 1: mse=54.568026 step=0.100000
2017/08/27 02:56:20 step 2: mse=53.362033 step=0.100000
2017/08/27 02:56:23 step 3: mse=52.345484 step=0.100000
2017/08/27 02:56:25 step 4: mse=51.463856 step=0.100000
2017/08/27 02:56:27 step 5: mse=50.317711 step=0.100000
2017/08/27 02:56:29 step 6: mse=48.367476 step=0.100000
2017/08/27 02:56:31 step 7: mse=47.757805 step=0.100000
2017/08/27 02:56:31 Saving...
2017/08/27 02:56:31 Gathering batch of experience...
2017/08/27 02:58:24 batch 111: mean=338.125000 stddev=161.501500 entropy=0.702829 frames=5459 count=16
2017/08/27 02:58:24 Training policy...
2017/08/27 02:58:31 step 0: objective=1.1395074
2017/08/27 02:58:33 step 1: objective=1.1458724
2017/08/27 02:58:36 step 2: objective=1.1510414
2017/08/27 02:58:38 step 3: objective=1.154452
2017/08/27 02:58:41 step 4: objective=1.1570705
2017/08/27 02:58:43 step 5: objective=1.1598554
2017/08/27 02:58:46 step 6: objective=1.162234
2017/08/27 02:58:48 step 7: objective=1.1640298
2017/08/27 02:58:48 Training value function...
2017/08/27 02:58:53 step 0: mse=52.188113 step=0.100000
2017/08/27 02:58:55 step 1: mse=51.382391 step=0.100000
2017/08/27 02:58:57 step 2: mse=50.674513 step=0.100000
2017/08/27 02:59:00 step 3: mse=50.054383 step=0.100000
2017/08/27 02:59:02 step 4: mse=49.517712 step=0.100000
2017/08/27 02:59:04 step 5: mse=48.993128 step=0.100000
2017/08/27 02:59:06 step 6: mse=48.213326 step=0.100000
2017/08/27 02:59:09 step 7: mse=47.797757 step=0.100000
2017/08/27 02:59:09 Saving...
2017/08/27 02:59:09 Gathering batch of experience...
2017/08/27 03:01:05 batch 112: mean=310.578947 stddev=163.484529 entropy=0.709162 frames=5979 count=19
2017/08/27 03:01:05 Training policy...
2017/08/27 03:01:13 step 0: objective=0.9668979
2017/08/27 03:01:16 step 1: objective=0.9718838
2017/08/27 03:01:19 step 2: objective=0.9756759
2017/08/27 03:01:21 step 3: objective=0.9799955
2017/08/27 03:01:24 step 4: objective=0.98367375
2017/08/27 03:01:27 step 5: objective=0.98658735
2017/08/27 03:01:30 step 6: objective=0.9903069
2017/08/27 03:01:32 step 7: objective=0.9930202
2017/08/27 03:01:32 Training value function...
2017/08/27 03:01:37 step 0: mse=56.790840 step=0.100000
2017/08/27 03:01:40 step 1: mse=56.102293 step=0.100000
2017/08/27 03:01:42 step 2: mse=55.165500 step=0.100000
2017/08/27 03:01:45 step 3: mse=54.460974 step=0.100000
2017/08/27 03:01:47 step 4: mse=53.983966 step=0.100000
2017/08/27 03:01:50 step 5: mse=53.535737 step=0.100000
2017/08/27 03:01:52 step 6: mse=53.100739 step=0.100000
2017/08/27 03:01:55 step 7: mse=52.583219 step=0.100000
2017/08/27 03:01:55 Saving...
2017/08/27 03:01:55 Gathering batch of experience...
2017/08/27 03:03:33 batch 113: mean=289.777778 stddev=146.690360 entropy=0.714328 frames=5316 count=18
2017/08/27 03:03:33 Training policy...
2017/08/27 03:03:40 step 0: objective=1.0140705
2017/08/27 03:03:42 step 1: objective=1.0216507
2017/08/27 03:03:44 step 2: objective=1.0294548
2017/08/27 03:03:47 step 3: objective=1.0340171
2017/08/27 03:03:49 step 4: objective=1.0373327
2017/08/27 03:03:52 step 5: objective=1.0407825
2017/08/27 03:03:54 step 6: objective=1.044529
2017/08/27 03:03:57 step 7: objective=1.0471305
2017/08/27 03:03:57 Training value function...
2017/08/27 03:04:01 step 0: mse=57.113045 step=0.100000
2017/08/27 03:04:03 step 1: mse=56.344298 step=0.100000
2017/08/27 03:04:05 step 2: mse=55.447042 step=0.100000
2017/08/27 03:04:08 step 3: mse=54.828926 step=0.100000
2017/08/27 03:04:10 step 4: mse=54.186457 step=0.100000
2017/08/27 03:04:12 step 5: mse=53.509617 step=0.100000
2017/08/27 03:04:14 step 6: mse=52.945746 step=0.100000
2017/08/27 03:04:17 step 7: mse=52.213620 step=0.100000
2017/08/27 03:04:17 Saving...
2017/08/27 03:04:17 Gathering batch of experience...
2017/08/27 03:06:15 batch 114: mean=354.875000 stddev=129.849853 entropy=0.703737 frames=5739 count=16
2017/08/27 03:06:15 Training policy...
2017/08/27 03:06:23 step 0: objective=1.3336626
2017/08/27 03:06:25 step 1: objective=1.3385295
2017/08/27 03:06:28 step 2: objective=1.3431947
2017/08/27 03:06:31 step 3: objective=1.3480837
2017/08/27 03:06:33 step 4: objective=1.3512318
2017/08/27 03:06:36 step 5: objective=1.3540292
2017/08/27 03:06:38 step 6: objective=1.3566347
2017/08/27 03:06:41 step 7: objective=1.3590724
2017/08/27 03:06:41 Training value function...
2017/08/27 03:06:46 step 0: mse=53.318413 step=0.100000
2017/08/27 03:06:48 step 1: mse=51.995118 step=0.100000
2017/08/27 03:06:51 step 2: mse=50.679144 step=0.100000
2017/08/27 03:06:53 step 3: mse=49.644188 step=0.100000
2017/08/27 03:06:55 step 4: mse=48.728783 step=0.100000
2017/08/27 03:06:58 step 5: mse=47.990543 step=0.100000
2017/08/27 03:07:00 step 6: mse=47.243302 step=0.100000
2017/08/27 03:07:03 step 7: mse=46.646689 step=0.100000
2017/08/27 03:07:03 Saving...
2017/08/27 03:07:03 Gathering batch of experience...
2017/08/27 03:08:44 batch 115: mean=279.555556 stddev=157.908279 entropy=0.724094 frames=5122 count=18
2017/08/27 03:08:44 Training policy...
2017/08/27 03:08:50 step 0: objective=0.7625298
2017/08/27 03:08:53 step 1: objective=0.76994705
2017/08/27 03:08:55 step 2: objective=0.7763167
2017/08/27 03:08:57 step 3: objective=0.7806788
2017/08/27 03:09:00 step 4: objective=0.78444064
2017/08/27 03:09:02 step 5: objective=0.78644204
2017/08/27 03:09:04 step 6: objective=0.7898148
2017/08/27 03:09:07 step 7: objective=0.7927908
2017/08/27 03:09:07 Training value function...
2017/08/27 03:09:11 step 0: mse=56.088977 step=0.100000
2017/08/27 03:09:13 step 1: mse=55.469234 step=0.100000
2017/08/27 03:09:15 step 2: mse=54.970334 step=0.100000
2017/08/27 03:09:17 step 3: mse=54.455968 step=0.100000
2017/08/27 03:09:19 step 4: mse=54.041343 step=0.100000
2017/08/27 03:09:21 step 5: mse=53.635449 step=0.100000
2017/08/27 03:09:24 step 6: mse=53.235689 step=0.100000
2017/08/27 03:09:26 step 7: mse=52.887095 step=0.100000
2017/08/27 03:09:26 Saving...
2017/08/27 03:09:26 Gathering batch of experience...
2017/08/27 03:11:02 batch 116: mean=316.000000 stddev=106.328500 entropy=0.714103 frames=5162 count=16
2017/08/27 03:11:02 Training policy...
2017/08/27 03:11:09 step 0: objective=0.7617564
2017/08/27 03:11:11 step 1: objective=0.76894116
2017/08/27 03:11:13 step 2: objective=0.7736648
2017/08/27 03:11:16 step 3: objective=0.7789052
2017/08/27 03:11:18 step 4: objective=0.7816468
2017/08/27 03:11:20 step 5: objective=0.7849815
2017/08/27 03:11:23 step 6: objective=0.7880341
2017/08/27 03:11:25 step 7: objective=0.78982466
2017/08/27 03:11:25 Training value function...
2017/08/27 03:11:29 step 0: mse=43.570306 step=0.100000
2017/08/27 03:11:31 step 1: mse=42.816745 step=0.100000
2017/08/27 03:11:33 step 2: mse=42.208320 step=0.100000
2017/08/27 03:11:36 step 3: mse=41.243725 step=0.100000
2017/08/27 03:11:38 step 4: mse=40.601378 step=0.100000
2017/08/27 03:11:40 step 5: mse=39.999040 step=0.100000
2017/08/27 03:11:42 step 6: mse=39.609867 step=0.100000
2017/08/27 03:11:44 step 7: mse=39.179659 step=0.100000
2017/08/27 03:11:44 Saving...
2017/08/27 03:11:44 Gathering batch of experience...
2017/08/27 03:13:35 batch 117: mean=275.500000 stddev=149.510368 entropy=0.724876 frames=5630 count=20
2017/08/27 03:13:35 Training policy...
2017/08/27 03:13:43 step 0: objective=0.8464744
2017/08/27 03:13:45 step 1: objective=0.85495764
2017/08/27 03:13:48 step 2: objective=0.86035824
2017/08/27 03:13:50 step 3: objective=0.8652155
2017/08/27 03:13:53 step 4: objective=0.8691847
2017/08/27 03:13:55 step 5: objective=0.8726056
2017/08/27 03:13:58 step 6: objective=0.87674046
2017/08/27 03:14:01 step 7: objective=0.8793425
2017/08/27 03:14:01 Training value function...
2017/08/27 03:14:05 step 0: mse=55.031977 step=0.100000
2017/08/27 03:14:08 step 1: mse=54.302104 step=0.100000
2017/08/27 03:14:10 step 2: mse=53.513877 step=0.100000
2017/08/27 03:14:12 step 3: mse=53.047863 step=0.100000
2017/08/27 03:14:15 step 4: mse=52.666993 step=0.100000
2017/08/27 03:14:17 step 5: mse=52.369614 step=0.100000
2017/08/27 03:14:19 step 6: mse=51.944473 step=0.100000
2017/08/27 03:14:22 step 7: mse=51.689905 step=0.100000
2017/08/27 03:14:22 Saving...
2017/08/27 03:14:22 Gathering batch of experience...
2017/08/27 03:15:58 batch 118: mean=319.187500 stddev=152.820245 entropy=0.712200 frames=5175 count=16
2017/08/27 03:15:58 Training policy...
2017/08/27 03:16:05 step 0: objective=1.2747949
2017/08/27 03:16:07 step 1: objective=1.2809029
2017/08/27 03:16:09 step 2: objective=1.2852008
2017/08/27 03:16:12 step 3: objective=1.2897011
2017/08/27 03:16:14 step 4: objective=1.2939837
2017/08/27 03:16:17 step 5: objective=1.2975421
2017/08/27 03:16:19 step 6: objective=1.300695
2017/08/27 03:16:21 step 7: objective=1.3034333
2017/08/27 03:16:21 Training value function...
2017/08/27 03:16:26 step 0: mse=55.951128 step=0.100000
2017/08/27 03:16:28 step 1: mse=54.498279 step=0.100000
2017/08/27 03:16:30 step 2: mse=53.279932 step=0.100000
2017/08/27 03:16:32 step 3: mse=52.191618 step=0.100000
2017/08/27 03:16:34 step 4: mse=51.339737 step=0.100000
2017/08/27 03:16:36 step 5: mse=50.550135 step=0.100000
2017/08/27 03:16:39 step 6: mse=49.768399 step=0.100000
2017/08/27 03:16:41 step 7: mse=48.807447 step=0.100000
2017/08/27 03:16:41 Saving...
2017/08/27 03:16:41 Gathering batch of experience...
2017/08/27 03:18:26 batch 119: mean=289.055556 stddev=163.889350 entropy=0.709480 frames=5287 count=18
2017/08/27 03:18:26 Training policy...
2017/08/27 03:18:33 step 0: objective=0.9733357
2017/08/27 03:18:35 step 1: objective=0.9817981
2017/08/27 03:18:38 step 2: objective=0.9878476
2017/08/27 03:18:40 step 3: objective=0.99238616
2017/08/27 03:18:42 step 4: objective=0.9969185
2017/08/27 03:18:45 step 5: objective=1.0003844
2017/08/27 03:18:47 step 6: objective=1.0034058
2017/08/27 03:18:50 step 7: objective=1.0058664
2017/08/27 03:18:50 Training value function...
2017/08/27 03:18:54 step 0: mse=57.244599 step=0.100000
2017/08/27 03:18:56 step 1: mse=56.430049 step=0.100000
2017/08/27 03:18:58 step 2: mse=55.898360 step=0.100000
2017/08/27 03:19:01 step 3: mse=55.282280 step=0.100000
2017/08/27 03:19:03 step 4: mse=54.814449 step=0.100000
2017/08/27 03:19:05 step 5: mse=54.438195 step=0.100000
2017/08/27 03:19:07 step 6: mse=54.087522 step=0.100000
2017/08/27 03:19:09 step 7: mse=53.767905 step=0.100000
2017/08/27 03:19:09 Saving...
2017/08/27 03:19:09 Gathering batch of experience...
2017/08/27 03:21:00 batch 120: mean=287.000000 stddev=134.099880 entropy=0.716284 frames=5281 count=18
2017/08/27 03:21:00 Training policy...
2017/08/27 03:21:07 step 0: objective=0.9390397
2017/08/27 03:21:09 step 1: objective=0.946431
2017/08/27 03:21:12 step 2: objective=0.9517063
2017/08/27 03:21:14 step 3: objective=0.9558179
2017/08/27 03:21:17 step 4: objective=0.9605256
2017/08/27 03:21:19 step 5: objective=0.9638652
2017/08/27 03:21:21 step 6: objective=0.96676254
2017/08/27 03:21:24 step 7: objective=0.96939206
2017/08/27 03:21:24 Training value function...
2017/08/27 03:21:28 step 0: mse=52.914102 step=0.100000
2017/08/27 03:21:30 step 1: mse=52.449551 step=0.100000
2017/08/27 03:21:33 step 2: mse=51.895999 step=0.100000
2017/08/27 03:21:35 step 3: mse=51.451873 step=0.100000
2017/08/27 03:21:37 step 4: mse=51.082749 step=0.100000
2017/08/27 03:21:39 step 5: mse=50.713302 step=0.100000
2017/08/27 03:21:41 step 6: mse=50.351087 step=0.100000
2017/08/27 03:21:44 step 7: mse=50.078156 step=0.100000
2017/08/27 03:21:44 Saving...
2017/08/27 03:21:44 Gathering batch of experience...
2017/08/27 03:23:36 batch 121: mean=306.000000 stddev=143.590080 entropy=0.707718 frames=5607 count=18
2017/08/27 03:23:36 Training policy...
2017/08/27 03:23:43 step 0: objective=1.1148531
2017/08/27 03:23:46 step 1: objective=1.1218491
2017/08/27 03:23:48 step 2: objective=1.1267432
2017/08/27 03:23:51 step 3: objective=1.1320299
2017/08/27 03:23:53 step 4: objective=1.1352271
2017/08/27 03:23:56 step 5: objective=1.1379753
2017/08/27 03:23:58 step 6: objective=1.1404661
2017/08/27 03:24:01 step 7: objective=1.1442482
2017/08/27 03:24:01 Training value function...
2017/08/27 03:24:06 step 0: mse=51.933707 step=0.100000
2017/08/27 03:24:08 step 1: mse=50.629230 step=0.100000
2017/08/27 03:24:11 step 2: mse=49.732280 step=0.100000
2017/08/27 03:24:13 step 3: mse=48.762603 step=0.100000
2017/08/27 03:24:15 step 4: mse=48.168149 step=0.100000
2017/08/27 03:24:18 step 5: mse=47.264799 step=0.100000
2017/08/27 03:24:20 step 6: mse=46.855262 step=0.100000
2017/08/27 03:24:22 step 7: mse=46.173330 step=0.100000
2017/08/27 03:24:22 Saving...
2017/08/27 03:24:22 Gathering batch of experience...
2017/08/27 03:26:17 batch 122: mean=303.789474 stddev=158.207917 entropy=0.706667 frames=5860 count=19
2017/08/27 03:26:17 Training policy...
2017/08/27 03:26:24 step 0: objective=0.9848109
2017/08/27 03:26:27 step 1: objective=0.9913131
2017/08/27 03:26:30 step 2: objective=0.99773526
2017/08/27 03:26:32 step 3: objective=1.0020082
2017/08/27 03:26:35 step 4: objective=1.0058879
2017/08/27 03:26:38 step 5: objective=1.0089682
2017/08/27 03:26:41 step 6: objective=1.012711
2017/08/27 03:26:43 step 7: objective=1.0152584
2017/08/27 03:26:43 Training value function...
2017/08/27 03:26:48 step 0: mse=53.870012 step=0.100000
2017/08/27 03:26:51 step 1: mse=53.145880 step=0.100000
2017/08/27 03:26:53 step 2: mse=52.549713 step=0.100000
2017/08/27 03:26:55 step 3: mse=51.946370 step=0.100000
2017/08/27 03:26:58 step 4: mse=51.421912 step=0.100000
2017/08/27 03:27:00 step 5: mse=50.930478 step=0.100000
2017/08/27 03:27:03 step 6: mse=50.439966 step=0.100000
2017/08/27 03:27:05 step 7: mse=50.082715 step=0.100000
2017/08/27 03:27:05 Saving...
2017/08/27 03:27:05 Gathering batch of experience...
2017/08/27 03:28:58 batch 123: mean=329.000000 stddev=129.026160 entropy=0.701392 frames=5348 count=16
2017/08/27 03:28:58 Training policy...
2017/08/27 03:29:05 step 0: objective=1.0493296
2017/08/27 03:29:07 step 1: objective=1.0575074
2017/08/27 03:29:10 step 2: objective=1.060687
2017/08/27 03:29:12 step 3: objective=1.0641391
2017/08/27 03:29:15 step 4: objective=1.0672015
2017/08/27 03:29:17 step 5: objective=1.0689467
2017/08/27 03:29:20 step 6: objective=1.0707351
2017/08/27 03:29:22 step 7: objective=1.072669
2017/08/27 03:29:22 Training value function...
2017/08/27 03:29:26 step 0: mse=48.090834 step=0.100000
2017/08/27 03:29:29 step 1: mse=47.474468 step=0.100000
2017/08/27 03:29:31 step 2: mse=46.787379 step=0.100000
2017/08/27 03:29:33 step 3: mse=46.172938 step=0.100000
2017/08/27 03:29:35 step 4: mse=45.662016 step=0.100000
2017/08/27 03:29:37 step 5: mse=45.029247 step=0.100000
2017/08/27 03:29:40 step 6: mse=44.762831 step=0.100000
2017/08/27 03:29:42 step 7: mse=44.375046 step=0.100000
2017/08/27 03:29:42 Saving...
2017/08/27 03:29:42 Gathering batch of experience...
2017/08/27 03:31:29 batch 124: mean=277.850000 stddev=151.643092 entropy=0.702771 frames=5673 count=20
2017/08/27 03:31:29 Training policy...
2017/08/27 03:31:36 step 0: objective=0.7203782
2017/08/27 03:31:39 step 1: objective=0.72693855
2017/08/27 03:31:41 step 2: objective=0.73056775
2017/08/27 03:31:44 step 3: objective=0.735042
2017/08/27 03:31:46 step 4: objective=0.7394937
2017/08/27 03:31:49 step 5: objective=0.7429717
2017/08/27 03:31:52 step 6: objective=0.74542594
2017/08/27 03:31:54 step 7: objective=0.7478761
2017/08/27 03:31:54 Training value function...
2017/08/27 03:31:59 step 0: mse=52.146951 step=0.100000
2017/08/27 03:32:01 step 1: mse=51.907103 step=0.100000
2017/08/27 03:32:04 step 2: mse=51.466130 step=0.100000
2017/08/27 03:32:06 step 3: mse=51.161202 step=0.100000
2017/08/27 03:32:08 step 4: mse=50.955075 step=0.100000
2017/08/27 03:32:11 step 5: mse=50.716790 step=0.100000
2017/08/27 03:32:13 step 6: mse=50.503980 step=0.100000
2017/08/27 03:32:15 step 7: mse=50.194504 step=0.100000
2017/08/27 03:32:15 Saving...
2017/08/27 03:32:16 Gathering batch of experience...
2017/08/27 03:34:02 batch 125: mean=328.588235 stddev=169.016553 entropy=0.704036 frames=5635 count=17
2017/08/27 03:34:02 Training policy...
2017/08/27 03:34:09 step 0: objective=1.3941616
2017/08/27 03:34:12 step 1: objective=1.4019704
2017/08/27 03:34:15 step 2: objective=1.4058748
2017/08/27 03:34:17 step 3: objective=1.410086
2017/08/27 03:34:20 step 4: objective=1.4136258
2017/08/27 03:34:22 step 5: objective=1.4177015
2017/08/27 03:34:25 step 6: objective=1.4206014
2017/08/27 03:34:28 step 7: objective=1.4246753
2017/08/27 03:34:28 Training value function...
2017/08/27 03:34:32 step 0: mse=58.607278 step=0.100000
2017/08/27 03:34:35 step 1: mse=57.073548 step=0.100000
2017/08/27 03:34:37 step 2: mse=55.800437 step=0.100000
2017/08/27 03:34:39 step 3: mse=54.613413 step=0.100000
2017/08/27 03:34:42 step 4: mse=53.399001 step=0.100000
2017/08/27 03:34:44 step 5: mse=52.502252 step=0.100000
2017/08/27 03:34:46 step 6: mse=51.640391 step=0.100000
2017/08/27 03:34:49 step 7: mse=50.908029 step=0.100000
2017/08/27 03:34:49 Saving...
2017/08/27 03:34:49 Gathering batch of experience...
2017/08/27 03:36:34 batch 126: mean=328.000000 stddev=149.446036 entropy=0.701287 frames=5649 count=17
2017/08/27 03:36:34 Training policy...
2017/08/27 03:36:41 step 0: objective=1.0583006
2017/08/27 03:36:44 step 1: objective=1.0644847
2017/08/27 03:36:46 step 2: objective=1.0693893
2017/08/27 03:36:49 step 3: objective=1.0742346
2017/08/27 03:36:52 step 4: objective=1.078007
2017/08/27 03:36:54 step 5: objective=1.0804763
2017/08/27 03:36:57 step 6: objective=1.0843703
2017/08/27 03:37:00 step 7: objective=1.0866354
2017/08/27 03:37:00 Training value function...
2017/08/27 03:37:04 step 0: mse=49.930900 step=0.100000
2017/08/27 03:37:06 step 1: mse=49.173432 step=0.100000
2017/08/27 03:37:09 step 2: mse=48.519306 step=0.100000
2017/08/27 03:37:11 step 3: mse=47.730064 step=0.100000
2017/08/27 03:37:14 step 4: mse=47.284775 step=0.100000
2017/08/27 03:37:16 step 5: mse=46.679833 step=0.100000
2017/08/27 03:37:18 step 6: mse=46.149520 step=0.100000
2017/08/27 03:37:21 step 7: mse=45.766404 step=0.100000
2017/08/27 03:37:21 Saving...
2017/08/27 03:37:21 Gathering batch of experience...
2017/08/27 03:39:05 batch 127: mean=360.400000 stddev=147.480078 entropy=0.689820 frames=5446 count=15
2017/08/27 03:39:05 Training policy...
2017/08/27 03:39:12 step 0: objective=1.2316011
2017/08/27 03:39:14 step 1: objective=1.2390045
2017/08/27 03:39:17 step 2: objective=1.2446713
2017/08/27 03:39:20 step 3: objective=1.2476965
2017/08/27 03:39:22 step 4: objective=1.2530749
2017/08/27 03:39:25 step 5: objective=1.2565134
2017/08/27 03:39:27 step 6: objective=1.2602485
2017/08/27 03:39:30 step 7: objective=1.2624667
2017/08/27 03:39:30 Training value function...
2017/08/27 03:39:34 step 0: mse=53.709290 step=0.100000
2017/08/27 03:39:36 step 1: mse=52.217973 step=0.100000
2017/08/27 03:39:39 step 2: mse=51.171289 step=0.100000
2017/08/27 03:39:41 step 3: mse=49.987206 step=0.100000
2017/08/27 03:39:43 step 4: mse=48.950941 step=0.100000
2017/08/27 03:39:46 step 5: mse=47.978301 step=0.100000
2017/08/27 03:39:48 step 6: mse=47.309253 step=0.100000
2017/08/27 03:39:50 step 7: mse=46.416747 step=0.100000
2017/08/27 03:39:50 Saving...
2017/08/27 03:39:50 Gathering batch of experience...
2017/08/27 03:41:34 batch 128: mean=325.058824 stddev=162.174732 entropy=0.696229 frames=5580 count=17
2017/08/27 03:41:34 Training policy...
2017/08/27 03:41:41 step 0: objective=0.9977023
2017/08/27 03:41:44 step 1: objective=1.0042353
2017/08/27 03:41:46 step 2: objective=1.0099566
2017/08/27 03:41:49 step 3: objective=1.0144274
2017/08/27 03:41:51 step 4: objective=1.0177574
2017/08/27 03:41:54 step 5: objective=1.0198265
2017/08/27 03:41:57 step 6: objective=1.022736
2017/08/27 03:41:59 step 7: objective=1.0259967
2017/08/27 03:41:59 Training value function...
2017/08/27 03:42:04 step 0: mse=50.047877 step=0.100000
2017/08/27 03:42:06 step 1: mse=49.289660 step=0.100000
2017/08/27 03:42:09 step 2: mse=48.029771 step=0.100000
2017/08/27 03:42:11 step 3: mse=47.454709 step=0.100000
2017/08/27 03:42:13 step 4: mse=46.569697 step=0.100000
2017/08/27 03:42:16 step 5: mse=46.220089 step=0.100000
2017/08/27 03:42:18 step 6: mse=45.783312 step=0.100000
2017/08/27 03:42:20 step 7: mse=44.829415 step=0.100000
2017/08/27 03:42:20 Saving...
2017/08/27 03:42:21 Gathering batch of experience...
2017/08/27 03:44:09 batch 129: mean=301.833333 stddev=136.789071 entropy=0.703051 frames=5539 count=18
2017/08/27 03:44:09 Training policy...
2017/08/27 03:44:16 step 0: objective=0.6404136
2017/08/27 03:44:19 step 1: objective=0.648197
2017/08/27 03:44:21 step 2: objective=0.6530126
2017/08/27 03:44:24 step 3: objective=0.656179
2017/08/27 03:44:26 step 4: objective=0.6602968
2017/08/27 03:44:29 step 5: objective=0.66341513
2017/08/27 03:44:32 step 6: objective=0.66899556
2017/08/27 03:44:34 step 7: objective=0.67153007
2017/08/27 03:44:34 Training value function...
2017/08/27 03:44:39 step 0: mse=47.354017 step=0.100000
2017/08/27 03:44:41 step 1: mse=46.999595 step=0.100000
2017/08/27 03:44:43 step 2: mse=46.716294 step=0.100000
2017/08/27 03:44:46 step 3: mse=46.138569 step=0.100000
2017/08/27 03:44:48 step 4: mse=45.887474 step=0.100000
2017/08/27 03:44:50 step 5: mse=45.172243 step=0.100000
2017/08/27 03:44:53 step 6: mse=44.920783 step=0.100000
2017/08/27 03:44:55 step 7: mse=44.653196 step=0.100000
2017/08/27 03:44:55 Saving...
2017/08/27 03:44:55 Gathering batch of experience...
2017/08/27 03:46:41 batch 130: mean=287.111111 stddev=166.184265 entropy=0.695337 frames=5251 count=18
2017/08/27 03:46:41 Training policy...
2017/08/27 03:46:48 step 0: objective=0.93225056
2017/08/27 03:46:51 step 1: objective=0.941162
2017/08/27 03:46:53 step 2: objective=0.9466117
2017/08/27 03:46:55 step 3: objective=0.95034456
2017/08/27 03:46:58 step 4: objective=0.9546103
2017/08/27 03:47:00 step 5: objective=0.9582255
2017/08/27 03:47:03 step 6: objective=0.96070445
2017/08/27 03:47:05 step 7: objective=0.9627791
2017/08/27 03:47:05 Training value function...
2017/08/27 03:47:09 step 0: mse=54.764646 step=0.100000
2017/08/27 03:47:12 step 1: mse=54.203109 step=0.100000
2017/08/27 03:47:14 step 2: mse=53.615004 step=0.100000
2017/08/27 03:47:16 step 3: mse=53.119597 step=0.100000
2017/08/27 03:47:18 step 4: mse=52.684008 step=0.100000
2017/08/27 03:47:20 step 5: mse=51.891970 step=0.100000
2017/08/27 03:47:23 step 6: mse=51.175730 step=0.100000
2017/08/27 03:47:25 step 7: mse=50.572868 step=0.100000
2017/08/27 03:47:25 Saving...
2017/08/27 03:47:25 Gathering batch of experience...
2017/08/27 03:49:04 batch 131: mean=368.357143 stddev=183.339111 entropy=0.682960 frames=5158 count=14
2017/08/27 03:49:04 Training policy...
2017/08/27 03:49:11 step 0: objective=1.5340382
2017/08/27 03:49:14 step 1: objective=1.5398825
2017/08/27 03:49:16 step 2: objective=1.5440199
2017/08/27 03:49:18 step 3: objective=1.5484171
2017/08/27 03:49:21 step 4: objective=1.5517751
2017/08/27 03:49:23 step 5: objective=1.5564101
2017/08/27 03:49:26 step 6: objective=1.5600283
2017/08/27 03:49:28 step 7: objective=1.562731
2017/08/27 03:49:28 Training value function...
2017/08/27 03:49:32 step 0: mse=60.975805 step=0.100000
2017/08/27 03:49:34 step 1: mse=58.759070 step=0.100000
2017/08/27 03:49:37 step 2: mse=57.115110 step=0.100000
2017/08/27 03:49:39 step 3: mse=55.665260 step=0.100000
2017/08/27 03:49:41 step 4: mse=54.414035 step=0.100000
2017/08/27 03:49:43 step 5: mse=53.128032 step=0.100000
2017/08/27 03:49:45 step 6: mse=52.101875 step=0.100000
2017/08/27 03:49:47 step 7: mse=50.807964 step=0.100000
2017/08/27 03:49:47 Saving...
2017/08/27 03:49:47 Gathering batch of experience...
2017/08/27 03:51:34 batch 132: mean=337.812500 stddev=134.889871 entropy=0.695419 frames=5472 count=16
2017/08/27 03:51:34 Training policy...
2017/08/27 03:51:41 step 0: objective=0.78717744
2017/08/27 03:51:44 step 1: objective=0.7927172
2017/08/27 03:51:47 step 2: objective=0.7993496
2017/08/27 03:51:49 step 3: objective=0.804106
2017/08/27 03:51:52 step 4: objective=0.80708236
2017/08/27 03:51:54 step 5: objective=0.8104621
2017/08/27 03:51:57 step 6: objective=0.81293374
2017/08/27 03:51:59 step 7: objective=0.8156051
2017/08/27 03:51:59 Training value function...
2017/08/27 03:52:04 step 0: mse=44.432722 step=0.100000
2017/08/27 03:52:06 step 1: mse=44.055643 step=0.100000
2017/08/27 03:52:08 step 2: mse=43.223261 step=0.100000
2017/08/27 03:52:11 step 3: mse=42.257699 step=0.100000
2017/08/27 03:52:13 step 4: mse=42.036147 step=0.100000
2017/08/27 03:52:15 step 5: mse=41.773422 step=0.100000
2017/08/27 03:52:17 step 6: mse=41.544838 step=0.100000
2017/08/27 03:52:20 step 7: mse=41.370246 step=0.100000
2017/08/27 03:52:20 Saving...
2017/08/27 03:52:20 Gathering batch of experience...
2017/08/27 03:54:05 batch 133: mean=334.437500 stddev=144.760133 entropy=0.686679 frames=5416 count=16
2017/08/27 03:54:05 Training policy...
2017/08/27 03:54:12 step 0: objective=0.9287233
2017/08/27 03:54:14 step 1: objective=0.93415904
2017/08/27 03:54:17 step 2: objective=0.9388006
2017/08/27 03:54:19 step 3: objective=0.9415278
2017/08/27 03:54:22 step 4: objective=0.9448522
2017/08/27 03:54:25 step 5: objective=0.9477441
2017/08/27 03:54:27 step 6: objective=0.94969124
2017/08/27 03:54:30 step 7: objective=0.9521927
2017/08/27 03:54:30 Training value function...
2017/08/27 03:54:34 step 0: mse=46.721249 step=0.100000
2017/08/27 03:54:36 step 1: mse=46.230322 step=0.100000
2017/08/27 03:54:39 step 2: mse=45.800477 step=0.100000
2017/08/27 03:54:41 step 3: mse=45.424832 step=0.100000
2017/08/27 03:54:43 step 4: mse=45.118958 step=0.100000
2017/08/27 03:54:45 step 5: mse=44.886559 step=0.100000
2017/08/27 03:54:48 step 6: mse=44.658331 step=0.100000
2017/08/27 03:54:50 step 7: mse=44.298837 step=0.100000
2017/08/27 03:54:50 Saving...
2017/08/27 03:54:50 Gathering batch of experience...
2017/08/27 03:56:38 batch 134: mean=342.882353 stddev=172.975647 entropy=0.683941 frames=5865 count=17
2017/08/27 03:56:38 Training policy...
2017/08/27 03:56:46 step 0: objective=1.3397682
2017/08/27 03:56:48 step 1: objective=1.3454264
2017/08/27 03:56:51 step 2: objective=1.3506153
2017/08/27 03:56:54 step 3: objective=1.3542732
2017/08/27 03:56:57 step 4: objective=1.3577347
2017/08/27 03:56:59 step 5: objective=1.3604654
2017/08/27 03:57:02 step 6: objective=1.3635873
2017/08/27 03:57:05 step 7: objective=1.3656789
2017/08/27 03:57:05 Training value function...
2017/08/27 03:57:10 step 0: mse=61.758177 step=0.100000
2017/08/27 03:57:12 step 1: mse=60.335840 step=0.100000
2017/08/27 03:57:15 step 2: mse=59.004165 step=0.100000
2017/08/27 03:57:17 step 3: mse=57.709307 step=0.100000
2017/08/27 03:57:20 step 4: mse=56.598995 step=0.100000
2017/08/27 03:57:22 step 5: mse=55.776783 step=0.100000
2017/08/27 03:57:24 step 6: mse=54.845474 step=0.100000
2017/08/27 03:57:27 step 7: mse=54.125800 step=0.100000
2017/08/27 03:57:27 Saving...
2017/08/27 03:57:27 Gathering batch of experience...
2017/08/27 03:59:13 batch 135: mean=310.500000 stddev=172.773857 entropy=0.684556 frames=5653 count=18
2017/08/27 03:59:13 Training policy...
2017/08/27 03:59:21 step 0: objective=0.8236785
2017/08/27 03:59:23 step 1: objective=0.8318325
2017/08/27 03:59:26 step 2: objective=0.83882815
2017/08/27 03:59:28 step 3: objective=0.8430205
2017/08/27 03:59:31 step 4: objective=0.84667206
2017/08/27 03:59:34 step 5: objective=0.8495786
2017/08/27 03:59:36 step 6: objective=0.8530577
2017/08/27 03:59:39 step 7: objective=0.85518295
2017/08/27 03:59:39 Training value function...
2017/08/27 03:59:44 step 0: mse=56.246874 step=0.100000
2017/08/27 03:59:46 step 1: mse=55.919650 step=0.100000
2017/08/27 03:59:48 step 2: mse=55.733978 step=0.100000
2017/08/27 03:59:51 step 3: mse=55.516701 step=0.100000
2017/08/27 03:59:53 step 4: mse=55.310040 step=0.100000
2017/08/27 03:59:56 step 5: mse=54.695838 step=0.100000
2017/08/27 03:59:58 step 6: mse=54.345178 step=0.100000
2017/08/27 04:00:00 step 7: mse=54.265606 step=0.100000
2017/08/27 04:00:00 Saving...
2017/08/27 04:00:00 Gathering batch of experience...
2017/08/27 04:01:47 batch 136: mean=321.125000 stddev=141.024765 entropy=0.688511 frames=5219 count=16
2017/08/27 04:01:47 Training policy...
2017/08/27 04:01:54 step 0: objective=0.8723667
2017/08/27 04:01:56 step 1: objective=0.87841177
2017/08/27 04:01:58 step 2: objective=0.88570553
2017/08/27 04:02:01 step 3: objective=0.8899127
2017/08/27 04:02:03 step 4: objective=0.8934162
2017/08/27 04:02:06 step 5: objective=0.89606357
2017/08/27 04:02:08 step 6: objective=0.89831585
2017/08/27 04:02:11 step 7: objective=0.90095466
2017/08/27 04:02:11 Training value function...
2017/08/27 04:02:15 step 0: mse=51.004683 step=0.100000
2017/08/27 04:02:17 step 1: mse=50.284970 step=0.100000
2017/08/27 04:02:19 step 2: mse=49.608426 step=0.100000
2017/08/27 04:02:21 step 3: mse=49.062597 step=0.100000
2017/08/27 04:02:23 step 4: mse=48.475480 step=0.100000
2017/08/27 04:02:26 step 5: mse=48.002181 step=0.100000
2017/08/27 04:02:28 step 6: mse=47.386732 step=0.100000
2017/08/27 04:02:30 step 7: mse=46.906914 step=0.100000
2017/08/27 04:02:30 Saving...
2017/08/27 04:02:30 Gathering batch of experience...
2017/08/27 04:04:20 batch 137: mean=291.052632 stddev=159.557438 entropy=0.693605 frames=5618 count=19
2017/08/27 04:04:20 Training policy...
2017/08/27 04:04:27 step 0: objective=0.90118283
2017/08/27 04:04:30 step 1: objective=0.9091681
2017/08/27 04:04:33 step 2: objective=0.91355485
2017/08/27 04:04:35 step 3: objective=0.9175042
2017/08/27 04:04:38 step 4: objective=0.92116475
2017/08/27 04:04:41 step 5: objective=0.924246
2017/08/27 04:04:43 step 6: objective=0.9269934
2017/08/27 04:04:46 step 7: objective=0.9299148
2017/08/27 04:04:46 Training value function...
2017/08/27 04:04:51 step 0: mse=54.185000 step=0.100000
2017/08/27 04:04:53 step 1: mse=53.323466 step=0.100000
2017/08/27 04:04:55 step 2: mse=52.914507 step=0.100000
2017/08/27 04:04:58 step 3: mse=52.516684 step=0.100000
2017/08/27 04:05:00 step 4: mse=52.061920 step=0.100000
2017/08/27 04:05:02 step 5: mse=51.646098 step=0.100000
2017/08/27 04:05:05 step 6: mse=50.840289 step=0.100000
2017/08/27 04:05:07 step 7: mse=50.443572 step=0.100000
2017/08/27 04:05:07 Saving...
2017/08/27 04:05:07 Gathering batch of experience...
2017/08/27 04:07:00 batch 138: mean=422.785714 stddev=169.345454 entropy=0.668970 frames=5878 count=14
2017/08/27 04:07:00 Training policy...
2017/08/27 04:07:08 step 0: objective=1.6577059
2017/08/27 04:07:11 step 1: objective=1.6622318
2017/08/27 04:07:13 step 2: objective=1.6660541
2017/08/27 04:07:16 step 3: objective=1.6682974
2017/08/27 04:07:19 step 4: objective=1.6709803
2017/08/27 04:07:22 step 5: objective=1.6727546
2017/08/27 04:07:24 step 6: objective=1.6750507
2017/08/27 04:07:27 step 7: objective=1.6766872
2017/08/27 04:07:27 Training value function...
2017/08/27 04:07:32 step 0: mse=58.775964 step=0.100000
2017/08/27 04:07:35 step 1: mse=56.726351 step=0.100000
2017/08/27 04:07:37 step 2: mse=54.947385 step=0.100000
2017/08/27 04:07:40 step 3: mse=53.252932 step=0.100000
2017/08/27 04:07:42 step 4: mse=51.956657 step=0.100000
2017/08/27 04:07:44 step 5: mse=50.583219 step=0.100000
2017/08/27 04:07:47 step 6: mse=49.539228 step=0.100000
2017/08/27 04:07:49 step 7: mse=48.646721 step=0.100000
2017/08/27 04:07:49 Saving...
2017/08/27 04:07:49 Gathering batch of experience...
2017/08/27 04:09:38 batch 139: mean=296.235294 stddev=147.783040 entropy=0.691975 frames=5128 count=17
2017/08/27 04:09:38 Training policy...
2017/08/27 04:09:45 step 0: objective=0.5013312
2017/08/27 04:09:47 step 1: objective=0.50815266
2017/08/27 04:09:49 step 2: objective=0.51434857
2017/08/27 04:09:52 step 3: objective=0.5173439
2017/08/27 04:09:54 step 4: objective=0.52063525
2017/08/27 04:09:57 step 5: objective=0.5242888
2017/08/27 04:09:59 step 6: objective=0.52626073
2017/08/27 04:10:01 step 7: objective=0.5295717
2017/08/27 04:10:01 Training value function...
2017/08/27 04:10:06 step 0: mse=47.942008 step=0.100000
2017/08/27 04:10:08 step 1: mse=47.573120 step=0.100000
2017/08/27 04:10:10 step 2: mse=47.238385 step=0.100000
2017/08/27 04:10:12 step 3: mse=47.072051 step=0.100000
2017/08/27 04:10:14 step 4: mse=46.932570 step=0.100000
2017/08/27 04:10:16 step 5: mse=46.688269 step=0.100000
2017/08/27 04:10:19 step 6: mse=46.528314 step=0.100000
2017/08/27 04:10:21 step 7: mse=46.360575 step=0.100000
2017/08/27 04:10:21 Saving...
2017/08/27 04:10:21 Gathering batch of experience...
2017/08/27 04:12:13 batch 140: mean=346.066667 stddev=189.122347 entropy=0.681443 frames=5208 count=15
2017/08/27 04:12:13 Training policy...
2017/08/27 04:12:20 step 0: objective=1.185901
2017/08/27 04:12:22 step 1: objective=1.1928995
2017/08/27 04:12:25 step 2: objective=1.2001561
2017/08/27 04:12:27 step 3: objective=1.2045028
2017/08/27 04:12:29 step 4: objective=1.2073457
2017/08/27 04:12:32 step 5: objective=1.2098268
2017/08/27 04:12:34 step 6: objective=1.2125231
2017/08/27 04:12:37 step 7: objective=1.214289
2017/08/27 04:12:37 Training value function...
2017/08/27 04:12:41 step 0: mse=56.152271 step=0.100000
2017/08/27 04:12:43 step 1: mse=54.761656 step=0.100000
2017/08/27 04:12:46 step 2: mse=53.516269 step=0.100000
2017/08/27 04:12:48 step 3: mse=52.486753 step=0.100000
2017/08/27 04:12:50 step 4: mse=51.511240 step=0.100000
2017/08/27 04:12:52 step 5: mse=50.535779 step=0.100000
2017/08/27 04:12:54 step 6: mse=49.807349 step=0.100000
2017/08/27 04:12:56 step 7: mse=49.185583 step=0.100000
2017/08/27 04:12:56 Saving...
2017/08/27 04:12:57 Gathering batch of experience...
2017/08/27 04:14:47 batch 141: mean=352.250000 stddev=153.759349 entropy=0.676637 frames=5679 count=16
2017/08/27 04:14:47 Training policy...
2017/08/27 04:14:55 step 0: objective=1.0350242
2017/08/27 04:14:57 step 1: objective=1.0413332
2017/08/27 04:15:00 step 2: objective=1.0450512
2017/08/27 04:15:03 step 3: objective=1.047622
2017/08/27 04:15:06 step 4: objective=1.0507866
2017/08/27 04:15:08 step 5: objective=1.0542164
2017/08/27 04:15:11 step 6: objective=1.0570107
2017/08/27 04:15:14 step 7: objective=1.058827
2017/08/27 04:15:14 Training value function...
2017/08/27 04:15:18 step 0: mse=49.581373 step=0.100000
2017/08/27 04:15:21 step 1: mse=48.845957 step=0.100000
2017/08/27 04:15:23 step 2: mse=48.233526 step=0.100000
2017/08/27 04:15:25 step 3: mse=47.664890 step=0.100000
2017/08/27 04:15:28 step 4: mse=47.122000 step=0.100000
2017/08/27 04:15:30 step 5: mse=46.649286 step=0.100000
2017/08/27 04:15:33 step 6: mse=46.154872 step=0.100000
2017/08/27 04:15:35 step 7: mse=45.651656 step=0.100000
2017/08/27 04:15:35 Saving...
2017/08/27 04:15:35 Gathering batch of experience...
2017/08/27 04:17:15 batch 142: mean=324.437500 stddev=118.110631 entropy=0.684867 frames=5287 count=16
2017/08/27 04:17:15 Training policy...
2017/08/27 04:17:22 step 0: objective=0.7625532
2017/08/27 04:17:24 step 1: objective=0.7704245
2017/08/27 04:17:27 step 2: objective=0.7747393
2017/08/27 04:17:29 step 3: objective=0.7782368
2017/08/27 04:17:32 step 4: objective=0.781641
2017/08/27 04:17:35 step 5: objective=0.78444403
2017/08/27 04:17:37 step 6: objective=0.7864382
2017/08/27 04:17:39 step 7: objective=0.78880495
2017/08/27 04:17:39 Training value function...
2017/08/27 04:17:44 step 0: mse=47.917903 step=0.100000
2017/08/27 04:17:46 step 1: mse=47.618288 step=0.100000
2017/08/27 04:17:48 step 2: mse=47.065582 step=0.100000
2017/08/27 04:17:51 step 3: mse=46.236940 step=0.100000
2017/08/27 04:17:53 step 4: mse=45.652949 step=0.100000
2017/08/27 04:17:55 step 5: mse=45.348619 step=0.100000
2017/08/27 04:17:57 step 6: mse=45.084400 step=0.100000
2017/08/27 04:17:59 step 7: mse=44.741054 step=0.100000
2017/08/27 04:17:59 Saving...
2017/08/27 04:18:00 Gathering batch of experience...
2017/08/27 04:19:59 batch 143: mean=319.722222 stddev=141.261698 entropy=0.678484 frames=5842 count=18
2017/08/27 04:19:59 Training policy...
2017/08/27 04:20:07 step 0: objective=1.012327
2017/08/27 04:20:09 step 1: objective=1.019702
2017/08/27 04:20:12 step 2: objective=1.0233266
2017/08/27 04:20:15 step 3: objective=1.028238
2017/08/27 04:20:18 step 4: objective=1.0309907
2017/08/27 04:20:20 step 5: objective=1.0340414
2017/08/27 04:20:23 step 6: objective=1.0365205
2017/08/27 04:20:26 step 7: objective=1.0387806
2017/08/27 04:20:26 Training value function...
2017/08/27 04:20:31 step 0: mse=51.088814 step=0.100000
2017/08/27 04:20:33 step 1: mse=50.060294 step=0.100000
2017/08/27 04:20:36 step 2: mse=49.503807 step=0.100000
2017/08/27 04:20:38 step 3: mse=48.927034 step=0.100000
2017/08/27 04:20:41 step 4: mse=48.568199 step=0.100000
2017/08/27 04:20:43 step 5: mse=48.225909 step=0.100000
2017/08/27 04:20:46 step 6: mse=47.771832 step=0.100000
2017/08/27 04:20:48 step 7: mse=47.057021 step=0.100000
2017/08/27 04:20:48 Saving...
2017/08/27 04:20:48 Gathering batch of experience...
2017/08/27 04:22:39 batch 144: mean=360.937500 stddev=118.804708 entropy=0.679343 frames=5841 count=16
2017/08/27 04:22:39 Training policy...
2017/08/27 04:22:47 step 0: objective=1.1471816
2017/08/27 04:22:50 step 1: objective=1.1516864
2017/08/27 04:22:52 step 2: objective=1.156541
2017/08/27 04:22:55 step 3: objective=1.1600865
2017/08/27 04:22:58 step 4: objective=1.1635629
2017/08/27 04:23:01 step 5: objective=1.1657177
2017/08/27 04:23:04 step 6: objective=1.1686287
2017/08/27 04:23:06 step 7: objective=1.1707343
2017/08/27 04:23:06 Training value function...
2017/08/27 04:23:11 step 0: mse=50.300171 step=0.100000
2017/08/27 04:23:14 step 1: mse=49.619191 step=0.100000
2017/08/27 04:23:16 step 2: mse=48.886550 step=0.100000
2017/08/27 04:23:18 step 3: mse=48.429448 step=0.100000
2017/08/27 04:23:21 step 4: mse=47.877309 step=0.100000
2017/08/27 04:23:23 step 5: mse=47.452508 step=0.100000
2017/08/27 04:23:26 step 6: mse=46.911896 step=0.100000
2017/08/27 04:23:28 step 7: mse=46.469627 step=0.100000
2017/08/27 04:23:28 Saving...
2017/08/27 04:23:28 Gathering batch of experience...
2017/08/27 04:25:14 batch 145: mean=404.000000 stddev=112.257994 entropy=0.675185 frames=5676 count=14
2017/08/27 04:25:14 Training policy...
2017/08/27 04:25:21 step 0: objective=1.2664567
2017/08/27 04:25:24 step 1: objective=1.2706176
2017/08/27 04:25:27 step 2: objective=1.2755525
2017/08/27 04:25:29 step 3: objective=1.2787362
2017/08/27 04:25:32 step 4: objective=1.2805072
2017/08/27 04:25:35 step 5: objective=1.2825449
2017/08/27 04:25:37 step 6: objective=1.2844892
2017/08/27 04:25:40 step 7: objective=1.2866819
2017/08/27 04:25:40 Training value function...
2017/08/27 04:25:45 step 0: mse=43.923916 step=0.100000
2017/08/27 04:25:47 step 1: mse=42.829337 step=0.100000
2017/08/27 04:25:50 step 2: mse=41.761144 step=0.100000
2017/08/27 04:25:52 step 3: mse=40.796529 step=0.100000
2017/08/27 04:25:54 step 4: mse=39.929001 step=0.100000
2017/08/27 04:25:57 step 5: mse=39.216246 step=0.100000
2017/08/27 04:25:59 step 6: mse=38.309182 step=0.100000
2017/08/27 04:26:01 step 7: mse=37.663981 step=0.100000
2017/08/27 04:26:01 Saving...
2017/08/27 04:26:02 Gathering batch of experience...
2017/08/27 04:28:01 batch 146: mean=353.294118 stddev=178.704411 entropy=0.680456 frames=6021 count=17
2017/08/27 04:28:01 Training policy...
2017/08/27 04:28:09 step 0: objective=1.0901297
2017/08/27 04:28:12 step 1: objective=1.096915
2017/08/27 04:28:15 step 2: objective=1.1005646
2017/08/27 04:28:18 step 3: objective=1.1039462
2017/08/27 04:28:20 step 4: objective=1.1076753
2017/08/27 04:28:23 step 5: objective=1.1101841
2017/08/27 04:28:26 step 6: objective=1.1120532
2017/08/27 04:28:29 step 7: objective=1.1141101
2017/08/27 04:28:29 Training value function...
2017/08/27 04:28:34 step 0: mse=50.161212 step=0.100000
2017/08/27 04:28:37 step 1: mse=48.809903 step=0.100000
2017/08/27 04:28:39 step 2: mse=48.089177 step=0.100000
2017/08/27 04:28:42 step 3: mse=46.802341 step=0.100000
2017/08/27 04:28:45 step 4: mse=45.969313 step=0.100000
2017/08/27 04:28:47 step 5: mse=45.232412 step=0.100000
2017/08/27 04:28:50 step 6: mse=44.330085 step=0.100000
2017/08/27 04:28:52 step 7: mse=43.673769 step=0.100000
2017/08/27 04:28:52 Saving...
2017/08/27 04:28:53 Gathering batch of experience...
2017/08/27 04:30:36 batch 147: mean=329.500000 stddev=167.619360 entropy=0.679669 frames=5318 count=16
2017/08/27 04:30:36 Training policy...
2017/08/27 04:30:43 step 0: objective=0.8709101
2017/08/27 04:30:45 step 1: objective=0.8779251
2017/08/27 04:30:48 step 2: objective=0.882622
2017/08/27 04:30:50 step 3: objective=0.8864823
2017/08/27 04:30:53 step 4: objective=0.88919395
2017/08/27 04:30:55 step 5: objective=0.8913577
2017/08/27 04:30:58 step 6: objective=0.89358664
2017/08/27 04:31:00 step 7: objective=0.8955843
2017/08/27 04:31:00 Training value function...
2017/08/27 04:31:05 step 0: mse=49.606908 step=0.100000
2017/08/27 04:31:07 step 1: mse=49.047498 step=0.100000
2017/08/27 04:31:09 step 2: mse=48.217160 step=0.100000
2017/08/27 04:31:11 step 3: mse=47.766077 step=0.100000
2017/08/27 04:31:14 step 4: mse=47.142511 step=0.100000
2017/08/27 04:31:16 step 5: mse=46.799241 step=0.100000
2017/08/27 04:31:18 step 6: mse=45.838375 step=0.100000
2017/08/27 04:31:20 step 7: mse=45.154874 step=0.100000
2017/08/27 04:31:20 Saving...
2017/08/27 04:31:20 Gathering batch of experience...
2017/08/27 04:33:09 batch 148: mean=388.066667 stddev=180.897196 entropy=0.674733 frames=5805 count=15
2017/08/27 04:33:09 Training policy...
2017/08/27 04:33:17 step 0: objective=1.3488227
2017/08/27 04:33:20 step 1: objective=1.3541992
2017/08/27 04:33:22 step 2: objective=1.3579779
2017/08/27 04:33:25 step 3: objective=1.3605034
2017/08/27 04:33:28 step 4: objective=1.3638855
2017/08/27 04:33:31 step 5: objective=1.3663087
2017/08/27 04:33:33 step 6: objective=1.3688798
2017/08/27 04:33:36 step 7: objective=1.3709444
2017/08/27 04:33:36 Training value function...
2017/08/27 04:33:41 step 0: mse=58.429511 step=0.100000
2017/08/27 04:33:43 step 1: mse=57.125211 step=0.100000
2017/08/27 04:33:46 step 2: mse=55.816914 step=0.100000
2017/08/27 04:33:48 step 3: mse=54.444554 step=0.100000
2017/08/27 04:33:51 step 4: mse=53.346838 step=0.100000
2017/08/27 04:33:53 step 5: mse=52.464035 step=0.100000
2017/08/27 04:33:56 step 6: mse=51.629198 step=0.100000
2017/08/27 04:33:58 step 7: mse=50.910552 step=0.100000
2017/08/27 04:33:58 Saving...
2017/08/27 04:33:58 Gathering batch of experience...
2017/08/27 04:35:51 batch 149: mean=395.400000 stddev=213.762735 entropy=0.674559 frames=5876 count=15
2017/08/27 04:35:51 Training policy...
2017/08/27 04:35:59 step 0: objective=1.1044809
2017/08/27 04:36:01 step 1: objective=1.1090826
2017/08/27 04:36:04 step 2: objective=1.1132915
2017/08/27 04:36:07 step 3: objective=1.1183771
2017/08/27 04:36:10 step 4: objective=1.1207395
2017/08/27 04:36:13 step 5: objective=1.1231996
2017/08/27 04:36:15 step 6: objective=1.1253449
2017/08/27 04:36:18 step 7: objective=1.127345
2017/08/27 04:36:18 Training value function...
2017/08/27 04:36:23 step 0: mse=48.731578 step=0.100000
2017/08/27 04:36:25 step 1: mse=47.891069 step=0.100000
2017/08/27 04:36:28 step 2: mse=47.186566 step=0.100000
2017/08/27 04:36:30 step 3: mse=46.457401 step=0.100000
2017/08/27 04:36:33 step 4: mse=45.855338 step=0.100000
2017/08/27 04:36:35 step 5: mse=44.873032 step=0.100000
2017/08/27 04:36:38 step 6: mse=44.448700 step=0.100000
2017/08/27 04:36:40 step 7: mse=43.917709 step=0.100000
2017/08/27 04:36:40 Saving...
2017/08/27 04:36:40 Gathering batch of experience...
2017/08/27 04:38:29 batch 150: mean=302.888889 stddev=149.557826 entropy=0.689340 frames=5541 count=18
2017/08/27 04:38:29 Training policy...
2017/08/27 04:38:37 step 0: objective=0.44421098
2017/08/27 04:38:39 step 1: objective=0.45206833
2017/08/27 04:38:42 step 2: objective=0.45701227
2017/08/27 04:38:44 step 3: objective=0.4601374
2017/08/27 04:38:47 step 4: objective=0.46339834
2017/08/27 04:38:50 step 5: objective=0.46602386
2017/08/27 04:38:52 step 6: objective=0.46915174
2017/08/27 04:38:55 step 7: objective=0.47130963
2017/08/27 04:38:55 Training value function...
2017/08/27 04:38:59 step 0: mse=47.676546 step=0.100000
2017/08/27 04:39:02 step 1: mse=47.289574 step=0.100000
2017/08/27 04:39:04 step 2: mse=46.858455 step=0.100000
2017/08/27 04:39:06 step 3: mse=46.456319 step=0.100000
2017/08/27 04:39:09 step 4: mse=46.198616 step=0.100000
2017/08/27 04:39:11 step 5: mse=45.987126 step=0.100000
2017/08/27 04:39:13 step 6: mse=45.654090 step=0.100000
2017/08/27 04:39:16 step 7: mse=45.417863 step=0.100000
2017/08/27 04:39:16 Saving...
2017/08/27 04:39:16 Gathering batch of experience...
2017/08/27 04:41:02 batch 151: mean=355.625000 stddev=174.641731 entropy=0.676310 frames=5708 count=16
2017/08/27 04:41:02 Training policy...
2017/08/27 04:41:10 step 0: objective=1.2116665
2017/08/27 04:41:13 step 1: objective=1.2187562
2017/08/27 04:41:15 step 2: objective=1.2242169
2017/08/27 04:41:18 step 3: objective=1.2274896
2017/08/27 04:41:21 step 4: objective=1.2297397
2017/08/27 04:41:24 step 5: objective=1.2324836
2017/08/27 04:41:26 step 6: objective=1.2346542
2017/08/27 04:41:29 step 7: objective=1.2368014
2017/08/27 04:41:29 Training value function...
2017/08/27 04:41:34 step 0: mse=52.647830 step=0.100000
2017/08/27 04:41:36 step 1: mse=51.692408 step=0.100000
2017/08/27 04:41:38 step 2: mse=50.600549 step=0.100000
2017/08/27 04:41:41 step 3: mse=49.541617 step=0.100000
2017/08/27 04:41:43 step 4: mse=48.773608 step=0.100000
2017/08/27 04:41:45 step 5: mse=48.060074 step=0.100000
2017/08/27 04:41:48 step 6: mse=47.404307 step=0.100000
2017/08/27 04:41:50 step 7: mse=46.866495 step=0.100000
2017/08/27 04:41:50 Saving...
2017/08/27 04:41:50 Gathering batch of experience...
2017/08/27 04:43:45 batch 152: mean=366.866667 stddev=163.672383 entropy=0.674702 frames=5525 count=15
2017/08/27 04:43:45 Training policy...
2017/08/27 04:43:53 step 0: objective=1.2895479
2017/08/27 04:43:55 step 1: objective=1.2954278
2017/08/27 04:43:58 step 2: objective=1.2996016
2017/08/27 04:44:01 step 3: objective=1.3043381
2017/08/27 04:44:03 step 4: objective=1.3073207
2017/08/27 04:44:06 step 5: objective=1.3098031
2017/08/27 04:44:08 step 6: objective=1.312417
2017/08/27 04:44:11 step 7: objective=1.31473
2017/08/27 04:44:11 Training value function...
2017/08/27 04:44:16 step 0: mse=58.716919 step=0.100000
2017/08/27 04:44:18 step 1: mse=57.600313 step=0.100000
2017/08/27 04:44:20 step 2: mse=56.510278 step=0.100000
2017/08/27 04:44:23 step 3: mse=55.522642 step=0.100000
2017/08/27 04:44:25 step 4: mse=54.707561 step=0.100000
2017/08/27 04:44:27 step 5: mse=53.925527 step=0.100000
2017/08/27 04:44:30 step 6: mse=53.177120 step=0.100000
2017/08/27 04:44:32 step 7: mse=52.337401 step=0.100000
2017/08/27 04:44:32 Saving...
2017/08/27 04:44:32 Gathering batch of experience...
2017/08/27 04:46:15 batch 153: mean=330.125000 stddev=163.763501 entropy=0.673333 frames=5333 count=16
2017/08/27 04:46:15 Training policy...
2017/08/27 04:46:22 step 0: objective=0.81864923
2017/08/27 04:46:25 step 1: objective=0.82410073
2017/08/27 04:46:27 step 2: objective=0.82851624
2017/08/27 04:46:30 step 3: objective=0.83149964
2017/08/27 04:46:32 step 4: objective=0.83597034
2017/08/27 04:46:35 step 5: objective=0.83885366
2017/08/27 04:46:37 step 6: objective=0.84087956
2017/08/27 04:46:40 step 7: objective=0.8433975
2017/08/27 04:46:40 Training value function...
2017/08/27 04:46:44 step 0: mse=50.029305 step=0.100000
2017/08/27 04:46:46 step 1: mse=49.460083 step=0.100000
2017/08/27 04:46:49 step 2: mse=49.074709 step=0.100000
2017/08/27 04:46:51 step 3: mse=48.623974 step=0.100000
2017/08/27 04:46:53 step 4: mse=48.304151 step=0.100000
2017/08/27 04:46:56 step 5: mse=47.923912 step=0.100000
2017/08/27 04:46:58 step 6: mse=47.489903 step=0.100000
2017/08/27 04:47:00 step 7: mse=47.257349 step=0.100000
2017/08/27 04:47:00 Saving...
2017/08/27 04:47:00 Gathering batch of experience...
2017/08/27 04:48:47 batch 154: mean=394.500000 stddev=138.839964 entropy=0.675432 frames=5536 count=14
2017/08/27 04:48:47 Training policy...
2017/08/27 04:48:55 step 0: objective=1.0756071
2017/08/27 04:48:57 step 1: objective=1.0800846
2017/08/27 04:49:00 step 2: objective=1.0836406
2017/08/27 04:49:03 step 3: objective=1.0866094
2017/08/27 04:49:05 step 4: objective=1.089851
2017/08/27 04:49:08 step 5: objective=1.0926293
2017/08/27 04:49:11 step 6: objective=1.0952137
2017/08/27 04:49:13 step 7: objective=1.0971583
2017/08/27 04:49:13 Training value function...
2017/08/27 04:49:18 step 0: mse=44.065230 step=0.100000
2017/08/27 04:49:20 step 1: mse=43.345271 step=0.100000
2017/08/27 04:49:22 step 2: mse=42.489428 step=0.100000
2017/08/27 04:49:25 step 3: mse=41.686964 step=0.100000
2017/08/27 04:49:27 step 4: mse=41.032998 step=0.100000
2017/08/27 04:49:29 step 5: mse=40.519429 step=0.100000
2017/08/27 04:49:32 step 6: mse=39.944120 step=0.100000
2017/08/27 04:49:34 step 7: mse=39.197507 step=0.100000
2017/08/27 04:49:34 Saving...
2017/08/27 04:49:34 Gathering batch of experience...
2017/08/27 04:51:07 batch 155: mean=262.157895 stddev=197.525551 entropy=0.697185 frames=5039 count=19
2017/08/27 04:51:07 Training policy...
2017/08/27 04:51:14 step 0: objective=0.57643247
2017/08/27 04:51:16 step 1: objective=0.58414704
2017/08/27 04:51:19 step 2: objective=0.5885667
2017/08/27 04:51:21 step 3: objective=0.59348464
2017/08/27 04:51:23 step 4: objective=0.59803617
2017/08/27 04:51:26 step 5: objective=0.60124767
2017/08/27 04:51:28 step 6: objective=0.6041477
2017/08/27 04:51:31 step 7: objective=0.60762095
2017/08/27 04:51:31 Training value function...
2017/08/27 04:51:35 step 0: mse=59.195523 step=0.100000
2017/08/27 04:51:37 step 1: mse=58.013357 step=0.100000
2017/08/27 04:51:39 step 2: mse=56.787703 step=0.100000
2017/08/27 04:51:41 step 3: mse=55.815039 step=0.100000
2017/08/27 04:51:43 step 4: mse=55.190697 step=0.100000
2017/08/27 04:51:45 step 5: mse=54.598105 step=0.100000
2017/08/27 04:51:47 step 6: mse=53.672056 step=0.100000
2017/08/27 04:51:50 step 7: mse=53.245557 step=0.100000
2017/08/27 04:51:50 Saving...
2017/08/27 04:51:50 Gathering batch of experience...
2017/08/27 04:53:36 batch 156: mean=358.466667 stddev=165.883842 entropy=0.680922 frames=5402 count=15
2017/08/27 04:53:36 Training policy...
2017/08/27 04:53:43 step 0: objective=1.3648704
2017/08/27 04:53:46 step 1: objective=1.3714198
2017/08/27 04:53:49 step 2: objective=1.3774363
2017/08/27 04:53:51 step 3: objective=1.3807847
2017/08/27 04:53:54 step 4: objective=1.3840052
2017/08/27 04:53:56 step 5: objective=1.3868186
2017/08/27 04:53:59 step 6: objective=1.3892392
2017/08/27 04:54:01 step 7: objective=1.3916612
2017/08/27 04:54:01 Training value function...
2017/08/27 04:54:06 step 0: mse=57.916608 step=0.100000
2017/08/27 04:54:08 step 1: mse=56.319025 step=0.100000
2017/08/27 04:54:10 step 2: mse=54.302523 step=0.100000
2017/08/27 04:54:13 step 3: mse=52.763433 step=0.100000
2017/08/27 04:54:15 step 4: mse=51.296033 step=0.100000
2017/08/27 04:54:17 step 5: mse=50.286751 step=0.100000
2017/08/27 04:54:19 step 6: mse=49.275901 step=0.100000
2017/08/27 04:54:22 step 7: mse=48.439516 step=0.100000
2017/08/27 04:54:22 Saving...
2017/08/27 04:54:22 Gathering batch of experience...
2017/08/27 04:56:16 batch 157: mean=350.529412 stddev=216.219964 entropy=0.681287 frames=5935 count=17
2017/08/27 04:56:16 Training policy...
2017/08/27 04:56:24 step 0: objective=1.0679818
2017/08/27 04:56:27 step 1: objective=1.0746936
2017/08/27 04:56:30 step 2: objective=1.0797727
2017/08/27 04:56:33 step 3: objective=1.0830865
2017/08/27 04:56:35 step 4: objective=1.0864854
2017/08/27 04:56:38 step 5: objective=1.0889366
2017/08/27 04:56:41 step 6: objective=1.0911901
2017/08/27 04:56:44 step 7: objective=1.093987
2017/08/27 04:56:44 Training value function...
2017/08/27 04:56:49 step 0: mse=55.885852 step=0.100000
2017/08/27 04:56:51 step 1: mse=55.118935 step=0.100000
2017/08/27 04:56:54 step 2: mse=54.297304 step=0.100000
2017/08/27 04:56:57 step 3: mse=53.611068 step=0.100000
2017/08/27 04:56:59 step 4: mse=52.805179 step=0.100000
2017/08/27 04:57:02 step 5: mse=52.230449 step=0.100000
2017/08/27 04:57:04 step 6: mse=51.764028 step=0.100000
2017/08/27 04:57:07 step 7: mse=51.335430 step=0.100000
2017/08/27 04:57:07 Saving...
2017/08/27 04:57:07 Gathering batch of experience...
2017/08/27 04:58:46 batch 158: mean=409.000000 stddev=132.749040 entropy=0.662219 frames=5320 count=13
2017/08/27 04:58:46 Training policy...
2017/08/27 04:58:53 step 0: objective=1.1038374
2017/08/27 04:58:55 step 1: objective=1.1091852
2017/08/27 04:58:58 step 2: objective=1.1132051
2017/08/27 04:59:01 step 3: objective=1.1168011
2017/08/27 04:59:03 step 4: objective=1.1202308
2017/08/27 04:59:06 step 5: objective=1.1227654
2017/08/27 04:59:08 step 6: objective=1.1254181
2017/08/27 04:59:11 step 7: objective=1.1275051
2017/08/27 04:59:11 Training value function...
2017/08/27 04:59:15 step 0: mse=47.215915 step=0.100000
2017/08/27 04:59:17 step 1: mse=46.154723 step=0.100000
2017/08/27 04:59:19 step 2: mse=45.384978 step=0.100000
2017/08/27 04:59:22 step 3: mse=44.624200 step=0.100000
2017/08/27 04:59:24 step 4: mse=43.888258 step=0.100000
2017/08/27 04:59:26 step 5: mse=43.294029 step=0.100000
2017/08/27 04:59:28 step 6: mse=42.683175 step=0.100000
2017/08/27 04:59:31 step 7: mse=42.142344 step=0.100000
2017/08/27 04:59:31 Saving...
2017/08/27 04:59:31 Gathering batch of experience...
2017/08/27 05:01:30 batch 159: mean=366.882353 stddev=211.812037 entropy=0.679851 frames=6201 count=17
2017/08/27 05:01:30 Training policy...
2017/08/27 05:01:38 step 0: objective=1.121359
2017/08/27 05:01:41 step 1: objective=1.1272683
2017/08/27 05:01:44 step 2: objective=1.1300906
2017/08/27 05:01:47 step 3: objective=1.1334239
2017/08/27 05:01:50 step 4: objective=1.1366903
2017/08/27 05:01:53 step 5: objective=1.1393378
2017/08/27 05:01:56 step 6: objective=1.1422696
2017/08/27 05:01:59 step 7: objective=1.1448002
2017/08/27 05:01:59 Training value function...
2017/08/27 05:02:04 step 0: mse=54.375873 step=0.100000
2017/08/27 05:02:07 step 1: mse=53.579245 step=0.100000
2017/08/27 05:02:10 step 2: mse=52.909351 step=0.100000
2017/08/27 05:02:12 step 3: mse=52.195837 step=0.100000
2017/08/27 05:02:15 step 4: mse=51.551904 step=0.100000
2017/08/27 05:02:17 step 5: mse=51.053602 step=0.100000
2017/08/27 05:02:20 step 6: mse=50.542984 step=0.100000
2017/08/27 05:02:23 step 7: mse=50.012190 step=0.100000
2017/08/27 05:02:23 Saving...
2017/08/27 05:02:23 Gathering batch of experience...
2017/08/27 05:04:03 batch 160: mean=355.266667 stddev=153.528919 entropy=0.674580 frames=5366 count=15
2017/08/27 05:04:03 Training policy...
2017/08/27 05:04:10 step 0: objective=1.0557128
2017/08/27 05:04:12 step 1: objective=1.0635704
2017/08/27 05:04:15 step 2: objective=1.0681854
2017/08/27 05:04:18 step 3: objective=1.071087
2017/08/27 05:04:20 step 4: objective=1.0756577
2017/08/27 05:04:23 step 5: objective=1.0777622
2017/08/27 05:04:25 step 6: objective=1.081066
2017/08/27 05:04:28 step 7: objective=1.0832206
2017/08/27 05:04:28 Training value function...
2017/08/27 05:04:32 step 0: mse=53.314759 step=0.100000
2017/08/27 05:04:35 step 1: mse=52.512211 step=0.100000
2017/08/27 05:04:37 step 2: mse=51.506265 step=0.100000
2017/08/27 05:04:39 step 3: mse=50.794064 step=0.100000
2017/08/27 05:04:41 step 4: mse=49.725154 step=0.100000
2017/08/27 05:04:44 step 5: mse=48.584089 step=0.100000
2017/08/27 05:04:46 step 6: mse=47.852123 step=0.100000
2017/08/27 05:04:48 step 7: mse=47.374323 step=0.100000
2017/08/27 05:04:48 Saving...
2017/08/27 05:04:48 Gathering batch of experience...
2017/08/27 05:06:38 batch 161: mean=346.000000 stddev=146.630914 entropy=0.680436 frames=5588 count=16
2017/08/27 05:06:38 Training policy...
2017/08/27 05:06:45 step 0: objective=0.77414125
2017/08/27 05:06:48 step 1: objective=0.77938926
2017/08/27 05:06:51 step 2: objective=0.7821259
2017/08/27 05:06:53 step 3: objective=0.7849894
2017/08/27 05:06:56 step 4: objective=0.7882755
2017/08/27 05:06:59 step 5: objective=0.7911204
2017/08/27 05:07:01 step 6: objective=0.79294795
2017/08/27 05:07:04 step 7: objective=0.7952341
2017/08/27 05:07:04 Training value function...
2017/08/27 05:07:09 step 0: mse=43.136640 step=0.100000
2017/08/27 05:07:11 step 1: mse=42.464651 step=0.100000
2017/08/27 05:07:13 step 2: mse=41.972900 step=0.100000
2017/08/27 05:07:16 step 3: mse=41.340992 step=0.100000
2017/08/27 05:07:18 step 4: mse=40.835325 step=0.100000
2017/08/27 05:07:20 step 5: mse=40.191772 step=0.100000
2017/08/27 05:07:23 step 6: mse=40.052697 step=0.100000
2017/08/27 05:07:25 step 7: mse=39.698148 step=0.100000
2017/08/27 05:07:25 Saving...
2017/08/27 05:07:25 Gathering batch of experience...
2017/08/27 05:09:19 batch 162: mean=404.785714 stddev=170.021502 entropy=0.667319 frames=5644 count=14
2017/08/27 05:09:19 Training policy...
2017/08/27 05:09:27 step 0: objective=1.2795142
2017/08/27 05:09:29 step 1: objective=1.2869263
2017/08/27 05:09:32 step 2: objective=1.2901613
2017/08/27 05:09:35 step 3: objective=1.2931421
2017/08/27 05:09:38 step 4: objective=1.2967652
2017/08/27 05:09:40 step 5: objective=1.2988241
2017/08/27 05:09:43 step 6: objective=1.301523
2017/08/27 05:09:46 step 7: objective=1.3034116
2017/08/27 05:09:46 Training value function...
2017/08/27 05:09:50 step 0: mse=51.797297 step=0.100000
2017/08/27 05:09:53 step 1: mse=50.556817 step=0.100000
2017/08/27 05:09:55 step 2: mse=49.485977 step=0.100000
2017/08/27 05:09:57 step 3: mse=48.535433 step=0.100000
2017/08/27 05:10:00 step 4: mse=47.709789 step=0.100000
2017/08/27 05:10:02 step 5: mse=46.832394 step=0.100000
2017/08/27 05:10:05 step 6: mse=46.254241 step=0.100000
2017/08/27 05:10:07 step 7: mse=45.589193 step=0.100000
2017/08/27 05:10:07 Saving...
2017/08/27 05:10:07 Gathering batch of experience...
2017/08/27 05:11:56 batch 163: mean=433.538462 stddev=157.382736 entropy=0.672092 frames=5595 count=13
2017/08/27 05:11:56 Training policy...
2017/08/27 05:12:04 step 0: objective=1.2014748
2017/08/27 05:12:06 step 1: objective=1.2054898
2017/08/27 05:12:09 step 2: objective=1.2089745
2017/08/27 05:12:12 step 3: objective=1.2113774
2017/08/27 05:12:14 step 4: objective=1.2141507
2017/08/27 05:12:17 step 5: objective=1.2163312
2017/08/27 05:12:20 step 6: objective=1.2191671
2017/08/27 05:12:22 step 7: objective=1.2210886
2017/08/27 05:12:22 Training value function...
2017/08/27 05:12:27 step 0: mse=43.765826 step=0.100000
2017/08/27 05:12:29 step 1: mse=42.728195 step=0.100000
2017/08/27 05:12:32 step 2: mse=41.861432 step=0.100000
2017/08/27 05:12:34 step 3: mse=41.085064 step=0.100000
2017/08/27 05:12:36 step 4: mse=40.419058 step=0.100000
2017/08/27 05:12:39 step 5: mse=39.776997 step=0.100000
2017/08/27 05:12:41 step 6: mse=39.214795 step=0.100000
2017/08/27 05:12:43 step 7: mse=38.725503 step=0.100000
2017/08/27 05:12:43 Saving...
2017/08/27 05:12:43 Gathering batch of experience...
2017/08/27 05:14:31 batch 164: mean=349.125000 stddev=176.519077 entropy=0.671894 frames=5613 count=16
2017/08/27 05:14:31 Training policy...
2017/08/27 05:14:39 step 0: objective=0.7855238
2017/08/27 05:14:42 step 1: objective=0.7922783
2017/08/27 05:14:44 step 2: objective=0.7950875
2017/08/27 05:14:47 step 3: objective=0.79917043
2017/08/27 05:14:50 step 4: objective=0.8027528
2017/08/27 05:14:52 step 5: objective=0.8064027
2017/08/27 05:14:55 step 6: objective=0.80844223
2017/08/27 05:14:58 step 7: objective=0.811024
2017/08/27 05:14:58 Training value function...
2017/08/27 05:15:03 step 0: mse=47.561065 step=0.100000
2017/08/27 05:15:05 step 1: mse=47.099489 step=0.100000
2017/08/27 05:15:07 step 2: mse=46.665201 step=0.100000
2017/08/27 05:15:10 step 3: mse=46.453768 step=0.100000
2017/08/27 05:15:12 step 4: mse=46.109130 step=0.100000
2017/08/27 05:15:14 step 5: mse=45.562631 step=0.100000
2017/08/27 05:15:17 step 6: mse=45.478731 step=0.100000
2017/08/27 05:15:19 step 7: mse=45.101835 step=0.100000
2017/08/27 05:15:19 Saving...
2017/08/27 05:15:19 Gathering batch of experience...
2017/08/27 05:17:20 batch 165: mean=379.533333 stddev=138.458594 entropy=0.667857 frames=5727 count=15
2017/08/27 05:17:20 Training policy...
2017/08/27 05:17:28 step 0: objective=0.99926114
2017/08/27 05:17:31 step 1: objective=1.0070925
2017/08/27 05:17:33 step 2: objective=1.0105447
2017/08/27 05:17:36 step 3: objective=1.0132773
2017/08/27 05:17:39 step 4: objective=1.0161179
2017/08/27 05:17:42 step 5: objective=1.0176152
2017/08/27 05:17:44 step 6: objective=1.0200933
2017/08/27 05:17:47 step 7: objective=1.0224371
2017/08/27 05:17:47 Training value function...
2017/08/27 05:17:52 step 0: mse=46.550587 step=0.100000
2017/08/27 05:17:54 step 1: mse=45.968971 step=0.100000
2017/08/27 05:17:57 step 2: mse=45.394260 step=0.100000
2017/08/27 05:17:59 step 3: mse=44.853699 step=0.100000
2017/08/27 05:18:01 step 4: mse=44.483851 step=0.100000
2017/08/27 05:18:04 step 5: mse=44.096573 step=0.100000
2017/08/27 05:18:06 step 6: mse=43.830672 step=0.100000
2017/08/27 05:18:09 step 7: mse=43.606390 step=0.100000
2017/08/27 05:18:09 Saving...
2017/08/27 05:18:09 Gathering batch of experience...
2017/08/27 05:20:09 batch 166: mean=384.000000 stddev=224.153646 entropy=0.671882 frames=5319 count=14
2017/08/27 05:20:09 Training policy...
2017/08/27 05:20:17 step 0: objective=1.1419665
2017/08/27 05:20:19 step 1: objective=1.1485888
2017/08/27 05:20:22 step 2: objective=1.1531448
2017/08/27 05:20:24 step 3: objective=1.1554036
2017/08/27 05:20:27 step 4: objective=1.158516
2017/08/27 05:20:29 step 5: objective=1.162115
2017/08/27 05:20:32 step 6: objective=1.1644496
2017/08/27 05:20:34 step 7: objective=1.1666322
2017/08/27 05:20:34 Training value function...
2017/08/27 05:20:39 step 0: mse=53.489801 step=0.100000
2017/08/27 05:20:41 step 1: mse=52.046582 step=0.100000
2017/08/27 05:20:43 step 2: mse=50.901919 step=0.100000
2017/08/27 05:20:46 step 3: mse=50.121328 step=0.100000
2017/08/27 05:20:48 step 4: mse=49.265437 step=0.100000
2017/08/27 05:20:50 step 5: mse=48.326607 step=0.100000
2017/08/27 05:20:52 step 6: mse=47.552370 step=0.100000
2017/08/27 05:20:54 step 7: mse=47.000614 step=0.100000
2017/08/27 05:20:54 Saving...
2017/08/27 05:20:55 Gathering batch of experience...
2017/08/27 05:22:40 batch 167: mean=390.357143 stddev=177.916356 entropy=0.670204 frames=5451 count=14
2017/08/27 05:22:40 Training policy...
2017/08/27 05:22:47 step 0: objective=1.2181112
2017/08/27 05:22:50 step 1: objective=1.2245014
2017/08/27 05:22:53 step 2: objective=1.228122
2017/08/27 05:22:55 step 3: objective=1.2321643
2017/08/27 05:22:58 step 4: objective=1.2360826
2017/08/27 05:23:01 step 5: objective=1.2392132
2017/08/27 05:23:03 step 6: objective=1.2415116
2017/08/27 05:23:06 step 7: objective=1.2434016
2017/08/27 05:23:06 Training value function...
2017/08/27 05:23:10 step 0: mse=52.980803 step=0.100000
2017/08/27 05:23:13 step 1: mse=51.563151 step=0.100000
2017/08/27 05:23:15 step 2: mse=50.275086 step=0.100000
2017/08/27 05:23:17 step 3: mse=49.181483 step=0.100000
2017/08/27 05:23:20 step 4: mse=48.207870 step=0.100000
2017/08/27 05:23:22 step 5: mse=47.252834 step=0.100000
2017/08/27 05:23:24 step 6: mse=46.428532 step=0.100000
2017/08/27 05:23:27 step 7: mse=45.770133 step=0.100000
2017/08/27 05:23:27 Saving...
2017/08/27 05:23:27 Gathering batch of experience...
2017/08/27 05:25:23 batch 168: mean=439.076923 stddev=120.495427 entropy=0.658848 frames=5690 count=13
2017/08/27 05:25:23 Training policy...
2017/08/27 05:25:30 step 0: objective=1.220915
2017/08/27 05:25:33 step 1: objective=1.2256478
2017/08/27 05:25:36 step 2: objective=1.2291229
2017/08/27 05:25:39 step 3: objective=1.2319444
2017/08/27 05:25:41 step 4: objective=1.2353451
2017/08/27 05:25:44 step 5: objective=1.2383214
2017/08/27 05:25:47 step 6: objective=1.2404461
2017/08/27 05:25:50 step 7: objective=1.2420312
2017/08/27 05:25:50 Training value function...
2017/08/27 05:25:54 step 0: mse=45.634026 step=0.100000
2017/08/27 05:25:57 step 1: mse=44.356322 step=0.100000
2017/08/27 05:25:59 step 2: mse=43.144383 step=0.100000
2017/08/27 05:26:01 step 3: mse=42.045459 step=0.100000
2017/08/27 05:26:04 step 4: mse=40.777533 step=0.100000
2017/08/27 05:26:06 step 5: mse=40.040800 step=0.100000
2017/08/27 05:26:09 step 6: mse=39.320947 step=0.100000
2017/08/27 05:26:11 step 7: mse=38.041182 step=0.100000
2017/08/27 05:26:11 Saving...
2017/08/27 05:26:11 Gathering batch of experience...
2017/08/27 05:28:06 batch 169: mean=304.421053 stddev=206.093570 entropy=0.677780 frames=5807 count=19
2017/08/27 05:28:06 Training policy...
2017/08/27 05:28:14 step 0: objective=0.52510995
2017/08/27 05:28:17 step 1: objective=0.53191555
2017/08/27 05:28:20 step 2: objective=0.53670776
2017/08/27 05:28:23 step 3: objective=0.5405941
2017/08/27 05:28:25 step 4: objective=0.54409987
2017/08/27 05:28:28 step 5: objective=0.54715204
2017/08/27 05:28:31 step 6: objective=0.54879594
2017/08/27 05:28:34 step 7: objective=0.5513078
2017/08/27 05:28:34 Training value function...
2017/08/27 05:28:39 step 0: mse=50.964151 step=0.100000
2017/08/27 05:28:41 step 1: mse=50.615386 step=0.100000
2017/08/27 05:28:43 step 2: mse=50.550653 step=0.100000
2017/08/27 05:28:46 step 3: mse=50.292042 step=0.100000
2017/08/27 05:28:48 step 4: mse=50.027630 step=0.100000
2017/08/27 05:28:51 step 5: mse=49.952736 step=0.100000
2017/08/27 05:28:53 step 6: mse=49.873276 step=0.100000
2017/08/27 05:28:56 step 7: mse=49.719352 step=0.100000
2017/08/27 05:28:56 Saving...
2017/08/27 05:28:56 Gathering batch of experience...
2017/08/27 05:30:53 batch 170: mean=326.500000 stddev=187.134013 entropy=0.677531 frames=5907 count=18
2017/08/27 05:30:53 Training policy...
2017/08/27 05:31:01 step 0: objective=0.8534801
2017/08/27 05:31:03 step 1: objective=0.8606598
2017/08/27 05:31:06 step 2: objective=0.86439604
2017/08/27 05:31:09 step 3: objective=0.8673792
2017/08/27 05:31:12 step 4: objective=0.8699142
2017/08/27 05:31:15 step 5: objective=0.8732399
2017/08/27 05:31:18 step 6: objective=0.8752659
2017/08/27 05:31:21 step 7: objective=0.8773555
2017/08/27 05:31:21 Training value function...
2017/08/27 05:31:26 step 0: mse=50.853426 step=0.100000
2017/08/27 05:31:28 step 1: mse=50.041386 step=0.100000
2017/08/27 05:31:31 step 2: mse=49.848128 step=0.100000
2017/08/27 05:31:33 step 3: mse=49.228478 step=0.100000
2017/08/27 05:31:36 step 4: mse=48.579237 step=0.100000
2017/08/27 05:31:38 step 5: mse=48.124416 step=0.100000
2017/08/27 05:31:41 step 6: mse=47.654557 step=0.100000
2017/08/27 05:31:43 step 7: mse=47.276399 step=0.100000
2017/08/27 05:31:43 Saving...
2017/08/27 05:31:43 Gathering batch of experience...
2017/08/27 05:33:49 batch 171: mean=363.882353 stddev=186.090074 entropy=0.659711 frames=6188 count=17
2017/08/27 05:33:49 Training policy...
2017/08/27 05:33:58 step 0: objective=1.1589401
2017/08/27 05:34:00 step 1: objective=1.1662802
2017/08/27 05:34:03 step 2: objective=1.171217
2017/08/27 05:34:07 step 3: objective=1.1751819
2017/08/27 05:34:09 step 4: objective=1.1789383
2017/08/27 05:34:13 step 5: objective=1.1827627
2017/08/27 05:34:16 step 6: objective=1.1849225
2017/08/27 05:34:19 step 7: objective=1.1866734
2017/08/27 05:34:19 Training value function...
2017/08/27 05:34:24 step 0: mse=55.456854 step=0.100000
2017/08/27 05:34:26 step 1: mse=54.510212 step=0.100000
2017/08/27 05:34:29 step 2: mse=53.656910 step=0.100000
2017/08/27 05:34:31 step 3: mse=52.906979 step=0.100000
2017/08/27 05:34:34 step 4: mse=52.276819 step=0.100000
2017/08/27 05:34:37 step 5: mse=51.594753 step=0.100000
2017/08/27 05:34:39 step 6: mse=50.985524 step=0.100000
2017/08/27 05:34:42 step 7: mse=50.652193 step=0.100000
2017/08/27 05:34:42 Saving...
2017/08/27 05:34:42 Gathering batch of experience...
2017/08/27 05:36:34 batch 172: mean=334.937500 stddev=200.725082 entropy=0.674143 frames=5363 count=16
2017/08/27 05:36:34 Training policy...
2017/08/27 05:36:41 step 0: objective=0.95500237
2017/08/27 05:36:44 step 1: objective=0.9594749
2017/08/27 05:36:46 step 2: objective=0.9630594
2017/08/27 05:36:49 step 3: objective=0.966169
2017/08/27 05:36:51 step 4: objective=0.9698199
2017/08/27 05:36:54 step 5: objective=0.9728143
2017/08/27 05:36:57 step 6: objective=0.97645396
2017/08/27 05:36:59 step 7: objective=0.98063457
2017/08/27 05:36:59 Training value function...
2017/08/27 05:37:04 step 0: mse=48.970877 step=0.100000
2017/08/27 05:37:06 step 1: mse=48.402314 step=0.100000
2017/08/27 05:37:08 step 2: mse=47.847390 step=0.100000
2017/08/27 05:37:10 step 3: mse=47.447551 step=0.100000
2017/08/27 05:37:13 step 4: mse=47.010889 step=0.100000
2017/08/27 05:37:15 step 5: mse=46.606189 step=0.100000
2017/08/27 05:37:17 step 6: mse=46.196984 step=0.100000
2017/08/27 05:37:19 step 7: mse=45.920138 step=0.100000
2017/08/27 05:37:19 Saving...
2017/08/27 05:37:19 Gathering batch of experience...
2017/08/27 05:39:09 batch 173: mean=360.625000 stddev=149.320492 entropy=0.665810 frames=5808 count=16
2017/08/27 05:39:09 Training policy...
2017/08/27 05:39:16 step 0: objective=0.93653506
2017/08/27 05:39:19 step 1: objective=0.9413637
2017/08/27 05:39:22 step 2: objective=0.94437283
2017/08/27 05:39:25 step 3: objective=0.9474321
2017/08/27 05:39:28 step 4: objective=0.9496132
2017/08/27 05:39:31 step 5: objective=0.95267624
2017/08/27 05:39:34 step 6: objective=0.95570487
2017/08/27 05:39:36 step 7: objective=0.9579113
2017/08/27 05:39:36 Training value function...
2017/08/27 05:39:41 step 0: mse=46.479659 step=0.100000
2017/08/27 05:39:44 step 1: mse=46.041590 step=0.100000
2017/08/27 05:39:46 step 2: mse=45.653130 step=0.100000
2017/08/27 05:39:49 step 3: mse=45.015679 step=0.100000
2017/08/27 05:39:51 step 4: mse=44.627288 step=0.100000
2017/08/27 05:39:53 step 5: mse=44.022103 step=0.100000
2017/08/27 05:39:56 step 6: mse=43.805140 step=0.100000
2017/08/27 05:39:58 step 7: mse=43.429515 step=0.100000
2017/08/27 05:39:58 Saving...
2017/08/27 05:39:58 Gathering batch of experience...
2017/08/27 05:41:50 batch 174: mean=406.142857 stddev=161.621187 entropy=0.664474 frames=5672 count=14
2017/08/27 05:41:50 Training policy...
2017/08/27 05:41:57 step 0: objective=1.1773942
2017/08/27 05:42:00 step 1: objective=1.1829705
2017/08/27 05:42:03 step 2: objective=1.186184
2017/08/27 05:42:06 step 3: objective=1.1886063
2017/08/27 05:42:08 step 4: objective=1.1905591
2017/08/27 05:42:11 step 5: objective=1.1928606
2017/08/27 05:42:14 step 6: objective=1.1956042
2017/08/27 05:42:17 step 7: objective=1.19813
2017/08/27 05:42:17 Training value function...
2017/08/27 05:42:21 step 0: mse=46.072630 step=0.100000
2017/08/27 05:42:24 step 1: mse=45.217010 step=0.100000
2017/08/27 05:42:26 step 2: mse=44.480330 step=0.100000
2017/08/27 05:42:29 step 3: mse=43.753179 step=0.100000
2017/08/27 05:42:31 step 4: mse=43.171041 step=0.100000
2017/08/27 05:42:33 step 5: mse=42.696347 step=0.100000
2017/08/27 05:42:36 step 6: mse=42.190440 step=0.100000
2017/08/27 05:42:38 step 7: mse=41.757816 step=0.100000
2017/08/27 05:42:38 Saving...
2017/08/27 05:42:38 Gathering batch of experience...
2017/08/27 05:44:29 batch 175: mean=365.333333 stddev=192.965167 entropy=0.663354 frames=5473 count=15
2017/08/27 05:44:29 Training policy...
2017/08/27 05:44:37 step 0: objective=1.0090239
2017/08/27 05:44:39 step 1: objective=1.0138607
2017/08/27 05:44:42 step 2: objective=1.0176271
2017/08/27 05:44:45 step 3: objective=1.0221153
2017/08/27 05:44:48 step 4: objective=1.025808
2017/08/27 05:44:50 step 5: objective=1.0292896
2017/08/27 05:44:53 step 6: objective=1.0313402
2017/08/27 05:44:55 step 7: objective=1.033631
2017/08/27 05:44:55 Training value function...
2017/08/27 05:45:00 step 0: mse=50.149131 step=0.100000
2017/08/27 05:45:02 step 1: mse=49.541005 step=0.100000
2017/08/27 05:45:05 step 2: mse=48.934794 step=0.100000
2017/08/27 05:45:07 step 3: mse=48.531104 step=0.100000
2017/08/27 05:45:09 step 4: mse=48.101588 step=0.100000
2017/08/27 05:45:12 step 5: mse=47.765958 step=0.100000
2017/08/27 05:45:14 step 6: mse=47.387368 step=0.100000
2017/08/27 05:45:16 step 7: mse=47.068004 step=0.100000
2017/08/27 05:45:16 Saving...
2017/08/27 05:45:16 Gathering batch of experience...
2017/08/27 05:47:17 batch 176: mean=377.125000 stddev=163.760448 entropy=0.668016 frames=6042 count=16
2017/08/27 05:47:17 Training policy...
2017/08/27 05:47:25 step 0: objective=1.1657984
2017/08/27 05:47:27 step 1: objective=1.1717664
2017/08/27 05:47:30 step 2: objective=1.1762369
2017/08/27 05:47:33 step 3: objective=1.1804233
2017/08/27 05:47:36 step 4: objective=1.1836127
2017/08/27 05:47:39 step 5: objective=1.1869938
2017/08/27 05:47:42 step 6: objective=1.1894429
2017/08/27 05:47:45 step 7: objective=1.1917961
2017/08/27 05:47:45 Training value function...
2017/08/27 05:47:50 step 0: mse=52.414624 step=0.100000
2017/08/27 05:47:53 step 1: mse=51.418751 step=0.100000
2017/08/27 05:47:55 step 2: mse=50.440945 step=0.100000
2017/08/27 05:47:58 step 3: mse=49.788616 step=0.100000
2017/08/27 05:48:00 step 4: mse=48.919111 step=0.100000
2017/08/27 05:48:03 step 5: mse=48.346528 step=0.100000
2017/08/27 05:48:06 step 6: mse=47.722586 step=0.100000
2017/08/27 05:48:08 step 7: mse=47.097422 step=0.100000
2017/08/27 05:48:08 Saving...
2017/08/27 05:48:08 Gathering batch of experience...
2017/08/27 05:49:55 batch 177: mean=381.333333 stddev=166.757975 entropy=0.666341 frames=5723 count=15
2017/08/27 05:49:55 Training policy...
2017/08/27 05:50:03 step 0: objective=1.0861685
2017/08/27 05:50:05 step 1: objective=1.0919974
2017/08/27 05:50:08 step 2: objective=1.0958644
2017/08/27 05:50:11 step 3: objective=1.0991895
2017/08/27 05:50:14 step 4: objective=1.1034873
2017/08/27 05:50:17 step 5: objective=1.1065379
2017/08/27 05:50:19 step 6: objective=1.1091663
2017/08/27 05:50:22 step 7: objective=1.1120977
2017/08/27 05:50:22 Training value function...
2017/08/27 05:50:27 step 0: mse=49.418281 step=0.100000
2017/08/27 05:50:29 step 1: mse=48.763472 step=0.100000
2017/08/27 05:50:32 step 2: mse=48.211722 step=0.100000
2017/08/27 05:50:34 step 3: mse=47.350875 step=0.100000
2017/08/27 05:50:37 step 4: mse=46.586031 step=0.100000
2017/08/27 05:50:39 step 5: mse=46.051799 step=0.100000
2017/08/27 05:50:41 step 6: mse=45.422940 step=0.100000
2017/08/27 05:50:44 step 7: mse=44.837207 step=0.100000
2017/08/27 05:50:44 Saving...
2017/08/27 05:50:44 Gathering batch of experience...
2017/08/27 05:52:33 batch 178: mean=302.842105 stddev=172.677449 entropy=0.667835 frames=5822 count=19
2017/08/27 05:52:33 Training policy...
2017/08/27 05:52:40 step 0: objective=0.66986775
2017/08/27 05:52:43 step 1: objective=0.6765001
2017/08/27 05:52:46 step 2: objective=0.68046254
2017/08/27 05:52:49 step 3: objective=0.6849341
2017/08/27 05:52:52 step 4: objective=0.6887568
2017/08/27 05:52:55 step 5: objective=0.6912947
2017/08/27 05:52:58 step 6: objective=0.69354194
2017/08/27 05:53:00 step 7: objective=0.6952643
2017/08/27 05:53:00 Training value function...
2017/08/27 05:53:05 step 0: mse=50.661140 step=0.100000
2017/08/27 05:53:08 step 1: mse=50.721033 step=0.100000
2017/08/27 05:53:10 step 2: mse=50.541960 step=0.100000
2017/08/27 05:53:13 step 3: mse=50.357019 step=0.100000
2017/08/27 05:53:15 step 4: mse=50.413372 step=0.100000
2017/08/27 05:53:18 step 5: mse=50.480181 step=0.100000
2017/08/27 05:53:20 step 6: mse=50.514664 step=0.100000
2017/08/27 05:53:23 step 7: mse=50.347004 step=0.100000
2017/08/27 05:53:23 Saving...
2017/08/27 05:53:23 Gathering batch of experience...
2017/08/27 05:55:25 batch 179: mean=363.250000 stddev=222.946042 entropy=0.658107 frames=5776 count=16
2017/08/27 05:55:25 Training policy...
2017/08/27 05:55:33 step 0: objective=1.2986118
2017/08/27 05:55:36 step 1: objective=1.3037156
2017/08/27 05:55:38 step 2: objective=1.3074822
2017/08/27 05:55:41 step 3: objective=1.3117288
2017/08/27 05:55:44 step 4: objective=1.3154298
2017/08/27 05:55:47 step 5: objective=1.3182853
2017/08/27 05:55:50 step 6: objective=1.3207053
2017/08/27 05:55:53 step 7: objective=1.3231833
2017/08/27 05:55:53 Training value function...
2017/08/27 05:55:57 step 0: mse=58.027274 step=0.100000
2017/08/27 05:56:00 step 1: mse=56.634736 step=0.100000
2017/08/27 05:56:02 step 2: mse=55.640620 step=0.100000
2017/08/27 05:56:05 step 3: mse=54.441349 step=0.100000
2017/08/27 05:56:07 step 4: mse=53.414959 step=0.100000
2017/08/27 05:56:10 step 5: mse=52.288702 step=0.100000
2017/08/27 05:56:12 step 6: mse=51.615242 step=0.100000
2017/08/27 05:56:15 step 7: mse=50.542407 step=0.100000
2017/08/27 05:56:15 Saving...
2017/08/27 05:56:15 Gathering batch of experience...
2017/08/27 05:58:06 batch 180: mean=405.428571 stddev=160.544927 entropy=0.659007 frames=5668 count=14
2017/08/27 05:58:06 Training policy...
2017/08/27 05:58:13 step 0: objective=1.1367259
2017/08/27 05:58:16 step 1: objective=1.1416904
2017/08/27 05:58:19 step 2: objective=1.1461312
2017/08/27 05:58:22 step 3: objective=1.1491499
2017/08/27 05:58:24 step 4: objective=1.1518012
2017/08/27 05:58:27 step 5: objective=1.1541985
2017/08/27 05:58:30 step 6: objective=1.15665
2017/08/27 05:58:33 step 7: objective=1.1584922
2017/08/27 05:58:33 Training value function...
2017/08/27 05:58:37 step 0: mse=48.048399 step=0.100000
2017/08/27 05:58:40 step 1: mse=46.512315 step=0.100000
2017/08/27 05:58:42 step 2: mse=45.465291 step=0.100000
2017/08/27 05:58:45 step 3: mse=44.329493 step=0.100000
2017/08/27 05:58:47 step 4: mse=43.527608 step=0.100000
2017/08/27 05:58:49 step 5: mse=42.403741 step=0.100000
2017/08/27 05:58:52 step 6: mse=41.728579 step=0.100000
2017/08/27 05:58:54 step 7: mse=40.871850 step=0.100000
2017/08/27 05:58:54 Saving...
2017/08/27 05:58:54 Gathering batch of experience...
2017/08/27 06:00:50 batch 181: mean=384.928571 stddev=125.660236 entropy=0.654239 frames=5423 count=14
2017/08/27 06:00:50 Training policy...
2017/08/27 06:00:57 step 0: objective=0.88915205
2017/08/27 06:01:00 step 1: objective=0.8942477
2017/08/27 06:01:03 step 2: objective=0.89922345
2017/08/27 06:01:05 step 3: objective=0.9019401
2017/08/27 06:01:08 step 4: objective=0.90460247
2017/08/27 06:01:11 step 5: objective=0.9081194
2017/08/27 06:01:13 step 6: objective=0.9105832
2017/08/27 06:01:16 step 7: objective=0.9125557
2017/08/27 06:01:16 Training value function...
2017/08/27 06:01:20 step 0: mse=47.291372 step=0.100000
2017/08/27 06:01:23 step 1: mse=45.903656 step=0.100000
2017/08/27 06:01:25 step 2: mse=45.329999 step=0.100000
2017/08/27 06:01:27 step 3: mse=44.260757 step=0.100000
2017/08/27 06:01:30 step 4: mse=43.590908 step=0.100000
2017/08/27 06:01:32 step 5: mse=43.015437 step=0.100000
2017/08/27 06:01:34 step 6: mse=42.372360 step=0.100000
2017/08/27 06:01:36 step 7: mse=42.073576 step=0.100000
2017/08/27 06:01:36 Saving...
2017/08/27 06:01:36 Gathering batch of experience...
2017/08/27 06:03:30 batch 182: mean=403.214286 stddev=131.957341 entropy=0.652185 frames=5654 count=14
2017/08/27 06:03:30 Training policy...
2017/08/27 06:03:37 step 0: objective=1.0280153
2017/08/27 06:03:40 step 1: objective=1.0341113
2017/08/27 06:03:43 step 2: objective=1.0385537
2017/08/27 06:03:46 step 3: objective=1.0420609
2017/08/27 06:03:48 step 4: objective=1.0442934
2017/08/27 06:03:51 step 5: objective=1.0460773
2017/08/27 06:03:54 step 6: objective=1.0475945
2017/08/27 06:03:57 step 7: objective=1.0493987
2017/08/27 06:03:57 Training value function...
2017/08/27 06:04:01 step 0: mse=43.735266 step=0.100000
2017/08/27 06:04:04 step 1: mse=42.943055 step=0.100000
2017/08/27 06:04:06 step 2: mse=42.270070 step=0.100000
2017/08/27 06:04:09 step 3: mse=41.634072 step=0.100000
2017/08/27 06:04:11 step 4: mse=41.044718 step=0.100000
2017/08/27 06:04:13 step 5: mse=40.636108 step=0.100000
2017/08/27 06:04:16 step 6: mse=40.128842 step=0.100000
2017/08/27 06:04:18 step 7: mse=39.726102 step=0.100000
2017/08/27 06:04:18 Saving...
2017/08/27 06:04:18 Gathering batch of experience...
2017/08/27 06:06:04 batch 183: mean=385.357143 stddev=118.934920 entropy=0.656990 frames=5432 count=14
2017/08/27 06:06:04 Training policy...
2017/08/27 06:06:11 step 0: objective=0.98459786
2017/08/27 06:06:14 step 1: objective=0.9902857
2017/08/27 06:06:16 step 2: objective=0.9941391
2017/08/27 06:06:19 step 3: objective=0.9970028
2017/08/27 06:06:22 step 4: objective=0.99992555
2017/08/27 06:06:24 step 5: objective=1.0024004
2017/08/27 06:06:27 step 6: objective=1.0051644
2017/08/27 06:06:30 step 7: objective=1.0066973
2017/08/27 06:06:30 Training value function...
2017/08/27 06:06:34 step 0: mse=43.999395 step=0.100000
2017/08/27 06:06:36 step 1: mse=43.116832 step=0.100000
2017/08/27 06:06:39 step 2: mse=42.273600 step=0.100000
2017/08/27 06:06:41 step 3: mse=41.611607 step=0.100000
2017/08/27 06:06:43 step 4: mse=41.160461 step=0.100000
2017/08/27 06:06:46 step 5: mse=40.841970 step=0.100000
2017/08/27 06:06:48 step 6: mse=40.144378 step=0.100000
2017/08/27 06:06:50 step 7: mse=39.645500 step=0.100000
2017/08/27 06:06:50 Saving...
2017/08/27 06:06:50 Gathering batch of experience...
2017/08/27 06:08:34 batch 184: mean=343.437500 stddev=180.984450 entropy=0.658570 frames=5519 count=16
2017/08/27 06:08:34 Training policy...
2017/08/27 06:08:41 step 0: objective=0.9610035
2017/08/27 06:08:44 step 1: objective=0.9665852
2017/08/27 06:08:47 step 2: objective=0.97043645
2017/08/27 06:08:49 step 3: objective=0.9738069
2017/08/27 06:08:52 step 4: objective=0.9761982
2017/08/27 06:08:55 step 5: objective=0.9790028
2017/08/27 06:08:57 step 6: objective=0.9806485
2017/08/27 06:09:00 step 7: objective=0.98251325
2017/08/27 06:09:00 Training value function...
2017/08/27 06:09:05 step 0: mse=56.402167 step=0.100000
2017/08/27 06:09:07 step 1: mse=55.560050 step=0.100000
2017/08/27 06:09:09 step 2: mse=54.769516 step=0.100000
2017/08/27 06:09:12 step 3: mse=54.168825 step=0.100000
2017/08/27 06:09:14 step 4: mse=53.582418 step=0.100000
2017/08/27 06:09:16 step 5: mse=53.145158 step=0.100000
2017/08/27 06:09:19 step 6: mse=52.081405 step=0.100000
2017/08/27 06:09:21 step 7: mse=51.573727 step=0.100000
2017/08/27 06:09:21 Saving...
2017/08/27 06:09:21 Gathering batch of experience...
2017/08/27 06:11:21 batch 185: mean=382.066667 stddev=147.513374 entropy=0.655275 frames=5749 count=15
2017/08/27 06:11:21 Training policy...
2017/08/27 06:11:29 step 0: objective=1.1654028
2017/08/27 06:11:31 step 1: objective=1.1699347
2017/08/27 06:11:34 step 2: objective=1.1744914
2017/08/27 06:11:37 step 3: objective=1.1784056
2017/08/27 06:11:40 step 4: objective=1.18146
2017/08/27 06:11:43 step 5: objective=1.1843247
2017/08/27 06:11:46 step 6: objective=1.1869435
2017/08/27 06:11:48 step 7: objective=1.1891254
2017/08/27 06:11:48 Training value function...
2017/08/27 06:11:53 step 0: mse=46.302051 step=0.100000
2017/08/27 06:11:56 step 1: mse=45.459353 step=0.100000
2017/08/27 06:11:58 step 2: mse=44.814888 step=0.100000
2017/08/27 06:12:00 step 3: mse=44.168988 step=0.100000
2017/08/27 06:12:03 step 4: mse=43.675407 step=0.100000
2017/08/27 06:12:05 step 5: mse=42.618678 step=0.100000
2017/08/27 06:12:08 step 6: mse=42.151324 step=0.100000
2017/08/27 06:12:10 step 7: mse=41.679641 step=0.100000
2017/08/27 06:12:10 Saving...
2017/08/27 06:12:10 Gathering batch of experience...
2017/08/27 06:14:13 batch 186: mean=488.230769 stddev=154.587866 entropy=0.646196 frames=6250 count=13
2017/08/27 06:14:13 Training policy...
2017/08/27 06:14:22 step 0: objective=1.5913916
2017/08/27 06:14:25 step 1: objective=1.5944932
2017/08/27 06:14:28 step 2: objective=1.5984296
2017/08/27 06:14:31 step 3: objective=1.6005561
2017/08/27 06:14:34 step 4: objective=1.6026889
2017/08/27 06:14:37 step 5: objective=1.6058676
2017/08/27 06:14:40 step 6: objective=1.6086792
2017/08/27 06:14:43 step 7: objective=1.6102537
2017/08/27 06:14:43 Training value function...
2017/08/27 06:14:49 step 0: mse=53.860408 step=0.100000
2017/08/27 06:14:51 step 1: mse=52.039902 step=0.100000
2017/08/27 06:14:54 step 2: mse=50.429566 step=0.100000
2017/08/27 06:14:57 step 3: mse=49.033697 step=0.100000
2017/08/27 06:14:59 step 4: mse=47.716863 step=0.100000
2017/08/27 06:15:02 step 5: mse=46.499194 step=0.100000
2017/08/27 06:15:05 step 6: mse=45.580923 step=0.100000
2017/08/27 06:15:07 step 7: mse=44.550666 step=0.100000
2017/08/27 06:15:07 Saving...
2017/08/27 06:15:07 Gathering batch of experience...
2017/08/27 06:16:53 batch 187: mean=360.187500 stddev=176.167966 entropy=0.659448 frames=5777 count=16
2017/08/27 06:16:53 Training policy...
2017/08/27 06:17:00 step 0: objective=0.7935828
2017/08/27 06:17:03 step 1: objective=0.7994147
2017/08/27 06:17:06 step 2: objective=0.80423576
2017/08/27 06:17:09 step 3: objective=0.8078104
2017/08/27 06:17:12 step 4: objective=0.81065166
2017/08/27 06:17:14 step 5: objective=0.8125676
2017/08/27 06:17:17 step 6: objective=0.81500506
2017/08/27 06:17:20 step 7: objective=0.8174238
2017/08/27 06:17:20 Training value function...
2017/08/27 06:17:25 step 0: mse=46.072924 step=0.100000
2017/08/27 06:17:27 step 1: mse=45.558933 step=0.100000
2017/08/27 06:17:30 step 2: mse=45.042258 step=0.100000
2017/08/27 06:17:32 step 3: mse=44.657954 step=0.100000
2017/08/27 06:17:35 step 4: mse=44.052036 step=0.100000
2017/08/27 06:17:37 step 5: mse=43.709921 step=0.100000
2017/08/27 06:17:40 step 6: mse=43.309671 step=0.100000
2017/08/27 06:17:42 step 7: mse=43.094202 step=0.100000
2017/08/27 06:17:42 Saving...
2017/08/27 06:17:42 Gathering batch of experience...
2017/08/27 06:19:46 batch 188: mean=353.411765 stddev=199.100938 entropy=0.662439 frames=6007 count=17
2017/08/27 06:19:46 Training policy...
2017/08/27 06:19:54 step 0: objective=0.8595631
2017/08/27 06:19:57 step 1: objective=0.86507744
2017/08/27 06:20:00 step 2: objective=0.86946696
2017/08/27 06:20:03 step 3: objective=0.87404245
2017/08/27 06:20:06 step 4: objective=0.8775266
2017/08/27 06:20:09 step 5: objective=0.8814907
2017/08/27 06:20:12 step 6: objective=0.88381904
2017/08/27 06:20:15 step 7: objective=0.8877041
2017/08/27 06:20:15 Training value function...
2017/08/27 06:20:20 step 0: mse=52.579547 step=0.100000
2017/08/27 06:20:23 step 1: mse=51.837675 step=0.100000
2017/08/27 06:20:26 step 2: mse=51.217204 step=0.100000
2017/08/27 06:20:28 step 3: mse=50.816698 step=0.100000
2017/08/27 06:20:31 step 4: mse=50.621471 step=0.100000
2017/08/27 06:20:33 step 5: mse=50.264770 step=0.100000
2017/08/27 06:20:36 step 6: mse=50.049838 step=0.100000
2017/08/27 06:20:38 step 7: mse=49.728546 step=0.100000
2017/08/27 06:20:38 Saving...
2017/08/27 06:20:39 Gathering batch of experience...
2017/08/27 06:22:36 batch 189: mean=416.714286 stddev=189.364889 entropy=0.647436 frames=5785 count=14
2017/08/27 06:22:36 Training policy...
2017/08/27 06:22:44 step 0: objective=1.1607822
2017/08/27 06:22:47 step 1: objective=1.1653988
2017/08/27 06:22:49 step 2: objective=1.1686517
2017/08/27 06:22:52 step 3: objective=1.1718512
2017/08/27 06:22:55 step 4: objective=1.1740854
2017/08/27 06:22:58 step 5: objective=1.1761492
2017/08/27 06:23:01 step 6: objective=1.1782013
2017/08/27 06:23:04 step 7: objective=1.1797107
2017/08/27 06:23:04 Training value function...
2017/08/27 06:23:08 step 0: mse=48.638399 step=0.100000
2017/08/27 06:23:11 step 1: mse=47.740744 step=0.100000
2017/08/27 06:23:13 step 2: mse=46.955183 step=0.100000
2017/08/27 06:23:16 step 3: mse=46.209352 step=0.100000
2017/08/27 06:23:18 step 4: mse=45.566415 step=0.100000
2017/08/27 06:23:21 step 5: mse=45.026050 step=0.100000
2017/08/27 06:23:23 step 6: mse=44.595995 step=0.100000
2017/08/27 06:23:26 step 7: mse=44.024415 step=0.100000
2017/08/27 06:23:26 Saving...
2017/08/27 06:23:26 Gathering batch of experience...
2017/08/27 06:25:12 batch 190: mean=388.923077 stddev=157.895029 entropy=0.643526 frames=5060 count=13
2017/08/27 06:25:12 Training policy...
2017/08/27 06:25:19 step 0: objective=0.87299013
2017/08/27 06:25:21 step 1: objective=0.8777807
2017/08/27 06:25:24 step 2: objective=0.8828122
2017/08/27 06:25:26 step 3: objective=0.8863814
2017/08/27 06:25:29 step 4: objective=0.8892864
2017/08/27 06:25:31 step 5: objective=0.89208543
2017/08/27 06:25:34 step 6: objective=0.8942385
2017/08/27 06:25:36 step 7: objective=0.89677936
2017/08/27 06:25:36 Training value function...
2017/08/27 06:25:40 step 0: mse=45.435329 step=0.100000
2017/08/27 06:25:43 step 1: mse=44.870812 step=0.100000
2017/08/27 06:25:45 step 2: mse=44.373816 step=0.100000
2017/08/27 06:25:47 step 3: mse=43.805843 step=0.100000
2017/08/27 06:25:49 step 4: mse=43.508798 step=0.100000
2017/08/27 06:25:51 step 5: mse=43.144411 step=0.100000
2017/08/27 06:25:53 step 6: mse=42.650807 step=0.100000
2017/08/27 06:25:55 step 7: mse=42.190186 step=0.100000
2017/08/27 06:25:55 Saving...
2017/08/27 06:25:56 Gathering batch of experience...
2017/08/27 06:27:54 batch 191: mean=436.000000 stddev=164.302856 entropy=0.646783 frames=6054 count=14
2017/08/27 06:27:54 Training policy...
2017/08/27 06:28:02 step 0: objective=1.1842793
2017/08/27 06:28:05 step 1: objective=1.18891
2017/08/27 06:28:08 step 2: objective=1.1925178
2017/08/27 06:28:11 step 3: objective=1.1961826
2017/08/27 06:28:14 step 4: objective=1.1993922
2017/08/27 06:28:18 step 5: objective=1.2024846
2017/08/27 06:28:21 step 6: objective=1.2050095
2017/08/27 06:28:24 step 7: objective=1.2071103
2017/08/27 06:28:24 Training value function...
2017/08/27 06:28:28 step 0: mse=48.782855 step=0.100000
2017/08/27 06:28:31 step 1: mse=47.837120 step=0.100000
2017/08/27 06:28:34 step 2: mse=46.761922 step=0.100000
2017/08/27 06:28:36 step 3: mse=45.854120 step=0.100000
2017/08/27 06:28:39 step 4: mse=45.219371 step=0.100000
2017/08/27 06:28:41 step 5: mse=44.388310 step=0.100000
2017/08/27 06:28:44 step 6: mse=43.672683 step=0.100000
2017/08/27 06:28:46 step 7: mse=43.049365 step=0.100000
2017/08/27 06:28:46 Saving...
2017/08/27 06:28:46 Gathering batch of experience...
2017/08/27 06:30:27 batch 192: mean=324.750000 stddev=146.758944 entropy=0.658131 frames=5265 count=16
2017/08/27 06:30:27 Training policy...
2017/08/27 06:30:34 step 0: objective=0.6473602
2017/08/27 06:30:37 step 1: objective=0.65387326
2017/08/27 06:30:40 step 2: objective=0.6591043
2017/08/27 06:30:42 step 3: objective=0.6628976
2017/08/27 06:30:45 step 4: objective=0.6675018
2017/08/27 06:30:48 step 5: objective=0.67095375
2017/08/27 06:30:50 step 6: objective=0.6735169
2017/08/27 06:30:53 step 7: objective=0.6762452
2017/08/27 06:30:53 Training value function...
2017/08/27 06:30:57 step 0: mse=46.888825 step=0.100000
2017/08/27 06:30:59 step 1: mse=46.514858 step=0.100000
2017/08/27 06:31:01 step 2: mse=45.835299 step=0.100000
2017/08/27 06:31:04 step 3: mse=45.411620 step=0.100000
2017/08/27 06:31:06 step 4: mse=44.911916 step=0.100000
2017/08/27 06:31:08 step 5: mse=44.650570 step=0.100000
2017/08/27 06:31:10 step 6: mse=44.280675 step=0.100000
2017/08/27 06:31:12 step 7: mse=43.868069 step=0.100000
2017/08/27 06:31:12 Saving...
2017/08/27 06:31:12 Gathering batch of experience...
2017/08/27 06:33:03 batch 193: mean=375.733333 stddev=188.084898 entropy=0.651582 frames=5623 count=15
2017/08/27 06:33:03 Training policy...
2017/08/27 06:33:10 step 0: objective=1.1954942
2017/08/27 06:33:13 step 1: objective=1.2011653
2017/08/27 06:33:16 step 2: objective=1.2055893
2017/08/27 06:33:18 step 3: objective=1.2084652
2017/08/27 06:33:21 step 4: objective=1.2126058
2017/08/27 06:33:24 step 5: objective=1.2149227
2017/08/27 06:33:27 step 6: objective=1.2177804
2017/08/27 06:33:30 step 7: objective=1.2211903
2017/08/27 06:33:30 Training value function...
2017/08/27 06:33:34 step 0: mse=54.218729 step=0.100000
2017/08/27 06:33:37 step 1: mse=52.972760 step=0.100000
2017/08/27 06:33:39 step 2: mse=52.090776 step=0.100000
2017/08/27 06:33:42 step 3: mse=51.184520 step=0.100000
2017/08/27 06:33:44 step 4: mse=50.409953 step=0.100000
2017/08/27 06:33:46 step 5: mse=49.677250 step=0.100000
2017/08/27 06:33:49 step 6: mse=49.091992 step=0.100000
2017/08/27 06:33:51 step 7: mse=48.529018 step=0.100000
2017/08/27 06:33:51 Saving...
2017/08/27 06:33:51 Gathering batch of experience...
2017/08/27 06:35:32 batch 194: mean=360.000000 stddev=166.577710 entropy=0.653161 frames=5418 count=15
2017/08/27 06:35:32 Training policy...
2017/08/27 06:35:39 step 0: objective=0.93430007
2017/08/27 06:35:42 step 1: objective=0.93901694
2017/08/27 06:35:44 step 2: objective=0.94355655
2017/08/27 06:35:47 step 3: objective=0.94657946
2017/08/27 06:35:50 step 4: objective=0.9500865
2017/08/27 06:35:52 step 5: objective=0.9525758
2017/08/27 06:35:55 step 6: objective=0.95554173
2017/08/27 06:35:58 step 7: objective=0.95803946
2017/08/27 06:35:58 Training value function...
2017/08/27 06:36:02 step 0: mse=47.412359 step=0.100000
2017/08/27 06:36:05 step 1: mse=46.376178 step=0.100000
2017/08/27 06:36:07 step 2: mse=45.647414 step=0.100000
2017/08/27 06:36:09 step 3: mse=45.334289 step=0.100000
2017/08/27 06:36:11 step 4: mse=44.692141 step=0.100000
2017/08/27 06:36:14 step 5: mse=43.766030 step=0.100000
2017/08/27 06:36:16 step 6: mse=43.228624 step=0.100000
2017/08/27 06:36:18 step 7: mse=42.680258 step=0.100000
2017/08/27 06:36:18 Saving...
2017/08/27 06:36:18 Gathering batch of experience...
2017/08/27 06:38:09 batch 195: mean=438.615385 stddev=147.135489 entropy=0.644527 frames=5667 count=13
2017/08/27 06:38:09 Training policy...
2017/08/27 06:38:16 step 0: objective=1.2681706
2017/08/27 06:38:19 step 1: objective=1.2739016
2017/08/27 06:38:22 step 2: objective=1.2775578
2017/08/27 06:38:25 step 3: objective=1.2801194
2017/08/27 06:38:28 step 4: objective=1.2827849
2017/08/27 06:38:31 step 5: objective=1.2861071
2017/08/27 06:38:33 step 6: objective=1.288433
2017/08/27 06:38:36 step 7: objective=1.2901973
2017/08/27 06:38:36 Training value function...
2017/08/27 06:38:41 step 0: mse=48.705217 step=0.100000
2017/08/27 06:38:43 step 1: mse=47.674791 step=0.100000
2017/08/27 06:38:46 step 2: mse=46.854109 step=0.100000
2017/08/27 06:38:48 step 3: mse=46.031908 step=0.100000
2017/08/27 06:38:51 step 4: mse=45.269179 step=0.100000
2017/08/27 06:38:53 step 5: mse=44.191191 step=0.100000
2017/08/27 06:38:55 step 6: mse=43.554526 step=0.100000
2017/08/27 06:38:58 step 7: mse=42.835117 step=0.100000
2017/08/27 06:38:58 Saving...
2017/08/27 06:38:58 Gathering batch of experience...
2017/08/27 06:40:49 batch 196: mean=331.764706 stddev=178.091691 entropy=0.663023 frames=5681 count=17
2017/08/27 06:40:49 Training policy...
2017/08/27 06:40:57 step 0: objective=0.8662463
2017/08/27 06:41:00 step 1: objective=0.8747836
2017/08/27 06:41:03 step 2: objective=0.87939376
2017/08/27 06:41:05 step 3: objective=0.88354445
2017/08/27 06:41:08 step 4: objective=0.88767976
2017/08/27 06:41:11 step 5: objective=0.8904716
2017/08/27 06:41:14 step 6: objective=0.893335
2017/08/27 06:41:17 step 7: objective=0.89715403
2017/08/27 06:41:17 Training value function...
2017/08/27 06:41:22 step 0: mse=56.636507 step=0.100000
2017/08/27 06:41:24 step 1: mse=55.814996 step=0.100000
2017/08/27 06:41:26 step 2: mse=54.706512 step=0.100000
2017/08/27 06:41:29 step 3: mse=54.165374 step=0.100000
2017/08/27 06:41:31 step 4: mse=53.154336 step=0.100000
2017/08/27 06:41:34 step 5: mse=52.410819 step=0.100000
2017/08/27 06:41:36 step 6: mse=51.726980 step=0.100000
2017/08/27 06:41:39 step 7: mse=51.242916 step=0.100000
2017/08/27 06:41:39 Saving...
2017/08/27 06:41:39 Gathering batch of experience...
2017/08/27 06:43:26 batch 197: mean=361.600000 stddev=152.939552 entropy=0.652014 frames=5456 count=15
2017/08/27 06:43:26 Training policy...
2017/08/27 06:43:33 step 0: objective=0.8988316
2017/08/27 06:43:36 step 1: objective=0.9047887
2017/08/27 06:43:38 step 2: objective=0.9082322
2017/08/27 06:43:41 step 3: objective=0.9120504
2017/08/27 06:43:44 step 4: objective=0.9155702
2017/08/27 06:43:47 step 5: objective=0.9184045
2017/08/27 06:43:49 step 6: objective=0.9221666
2017/08/27 06:43:52 step 7: objective=0.9237464
2017/08/27 06:43:52 Training value function...
2017/08/27 06:43:57 step 0: mse=45.122470 step=0.100000
2017/08/27 06:43:59 step 1: mse=44.304320 step=0.100000
2017/08/27 06:44:01 step 2: mse=43.800722 step=0.100000
2017/08/27 06:44:04 step 3: mse=42.695680 step=0.100000
2017/08/27 06:44:06 step 4: mse=42.280035 step=0.100000
2017/08/27 06:44:08 step 5: mse=41.698815 step=0.100000
2017/08/27 06:44:11 step 6: mse=41.443743 step=0.100000
2017/08/27 06:44:13 step 7: mse=40.514599 step=0.100000
2017/08/27 06:44:13 Saving...
2017/08/27 06:44:13 Gathering batch of experience...
2017/08/27 06:46:07 batch 198: mean=391.857143 stddev=158.355774 entropy=0.650527 frames=5490 count=14
2017/08/27 06:46:07 Training policy...
2017/08/27 06:46:15 step 0: objective=1.1550333
2017/08/27 06:46:17 step 1: objective=1.1619551
2017/08/27 06:46:20 step 2: objective=1.1652571
2017/08/27 06:46:23 step 3: objective=1.1692615
2017/08/27 06:46:26 step 4: objective=1.1722468
2017/08/27 06:46:28 step 5: objective=1.1744393
2017/08/27 06:46:31 step 6: objective=1.1771994
2017/08/27 06:46:34 step 7: objective=1.1793227
2017/08/27 06:46:34 Training value function...
2017/08/27 06:46:38 step 0: mse=52.536975 step=0.100000
2017/08/27 06:46:41 step 1: mse=51.524743 step=0.100000
2017/08/27 06:46:43 step 2: mse=50.599609 step=0.100000
2017/08/27 06:46:45 step 3: mse=49.827363 step=0.100000
2017/08/27 06:46:48 step 4: mse=49.007843 step=0.100000
2017/08/27 06:46:50 step 5: mse=48.238503 step=0.100000
2017/08/27 06:46:52 step 6: mse=47.637332 step=0.100000
2017/08/27 06:46:55 step 7: mse=47.006364 step=0.100000
2017/08/27 06:46:55 Saving...
2017/08/27 06:46:55 Gathering batch of experience...
2017/08/27 06:49:00 batch 199: mean=374.800000 stddev=194.033056 entropy=0.644889 frames=5606 count=15
2017/08/27 06:49:00 Training policy...
2017/08/27 06:49:07 step 0: objective=1.0555421
2017/08/27 06:49:10 step 1: objective=1.0601658
2017/08/27 06:49:13 step 2: objective=1.0646528
2017/08/27 06:49:16 step 3: objective=1.067533
2017/08/27 06:49:18 step 4: objective=1.070941
2017/08/27 06:49:21 step 5: objective=1.0735945
2017/08/27 06:49:24 step 6: objective=1.0752503
2017/08/27 06:49:27 step 7: objective=1.0779068
2017/08/27 06:49:27 Training value function...
2017/08/27 06:49:31 step 0: mse=50.071928 step=0.100000
2017/08/27 06:49:34 step 1: mse=49.296690 step=0.100000
2017/08/27 06:49:36 step 2: mse=48.518011 step=0.100000
2017/08/27 06:49:39 step 3: mse=47.802830 step=0.100000
2017/08/27 06:49:41 step 4: mse=47.228708 step=0.100000
2017/08/27 06:49:43 step 5: mse=46.570759 step=0.100000
2017/08/27 06:49:46 step 6: mse=46.068789 step=0.100000
2017/08/27 06:49:48 step 7: mse=45.556719 step=0.100000
2017/08/27 06:49:48 Saving...
2017/08/27 06:49:48 Gathering batch of experience...
2017/08/27 06:51:47 batch 200: mean=500.416667 stddev=152.362757 entropy=0.651993 frames=5902 count=12
2017/08/27 06:51:47 Training policy...
2017/08/27 06:51:55 step 0: objective=1.3902963
2017/08/27 06:51:58 step 1: objective=1.3960694
2017/08/27 06:52:01 step 2: objective=1.3990085
2017/08/27 06:52:04 step 3: objective=1.4014914
2017/08/27 06:52:07 step 4: objective=1.4035984
2017/08/27 06:52:10 step 5: objective=1.405444
2017/08/27 06:52:12 step 6: objective=1.4082462
2017/08/27 06:52:16 step 7: objective=1.4099352
2017/08/27 06:52:16 Training value function...
2017/08/27 06:52:20 step 0: mse=49.390078 step=0.100000
2017/08/27 06:52:23 step 1: mse=48.277233 step=0.100000
2017/08/27 06:52:25 step 2: mse=47.317441 step=0.100000
2017/08/27 06:52:28 step 3: mse=46.441459 step=0.100000
2017/08/27 06:52:30 step 4: mse=45.652496 step=0.100000
2017/08/27 06:52:33 step 5: mse=44.897385 step=0.100000
2017/08/27 06:52:35 step 6: mse=44.199997 step=0.100000
2017/08/27 06:52:38 step 7: mse=43.673873 step=0.100000
2017/08/27 06:52:38 Saving...
2017/08/27 06:52:38 Gathering batch of experience...
2017/08/27 06:54:42 batch 201: mean=440.071429 stddev=183.307105 entropy=0.641938 frames=6094 count=14
2017/08/27 06:54:42 Training policy...
2017/08/27 06:54:50 step 0: objective=1.0775703
2017/08/27 06:54:53 step 1: objective=1.0818828
2017/08/27 06:54:56 step 2: objective=1.0843049
2017/08/27 06:54:59 step 3: objective=1.0879261
2017/08/27 06:55:02 step 4: objective=1.0901899
2017/08/27 06:55:05 step 5: objective=1.0939662
2017/08/27 06:55:08 step 6: objective=1.0965343
2017/08/27 06:55:12 step 7: objective=1.0978317
2017/08/27 06:55:12 Training value function...
2017/08/27 06:55:17 step 0: mse=45.795404 step=0.100000
2017/08/27 06:55:19 step 1: mse=44.882985 step=0.100000
2017/08/27 06:55:22 step 2: mse=44.151001 step=0.100000
2017/08/27 06:55:24 step 3: mse=43.457533 step=0.100000
2017/08/27 06:55:27 step 4: mse=42.879894 step=0.100000
2017/08/27 06:55:30 step 5: mse=42.308438 step=0.100000
2017/08/27 06:55:32 step 6: mse=41.628880 step=0.100000
2017/08/27 06:55:35 step 7: mse=41.183770 step=0.100000
2017/08/27 06:55:35 Saving...
2017/08/27 06:55:35 Gathering batch of experience...
2017/08/27 06:57:32 batch 202: mean=533.909091 stddev=146.511219 entropy=0.643981 frames=5741 count=11
2017/08/27 06:57:32 Training policy...
2017/08/27 06:57:39 step 0: objective=1.5066124
2017/08/27 06:57:42 step 1: objective=1.511273
2017/08/27 06:57:45 step 2: objective=1.5148504
2017/08/27 06:57:48 step 3: objective=1.5176237
2017/08/27 06:57:51 step 4: objective=1.5201843
2017/08/27 06:57:54 step 5: objective=1.5223724
2017/08/27 06:57:57 step 6: objective=1.5248066
2017/08/27 06:58:00 step 7: objective=1.5263225
2017/08/27 06:58:00 Training value function...
2017/08/27 06:58:04 step 0: mse=51.932734 step=0.100000
2017/08/27 06:58:07 step 1: mse=49.833089 step=0.100000
2017/08/27 06:58:09 step 2: mse=48.063434 step=0.100000
2017/08/27 06:58:12 step 3: mse=46.582793 step=0.100000
2017/08/27 06:58:14 step 4: mse=44.730151 step=0.100000
2017/08/27 06:58:16 step 5: mse=43.408655 step=0.100000
2017/08/27 06:58:19 step 6: mse=42.251510 step=0.100000
2017/08/27 06:58:21 step 7: mse=41.293726 step=0.100000
2017/08/27 06:58:21 Saving...
2017/08/27 06:58:21 Gathering batch of experience...
2017/08/27 07:00:11 batch 203: mean=461.846154 stddev=138.251636 entropy=0.635289 frames=5948 count=13
2017/08/27 07:00:11 Training policy...
2017/08/27 07:00:19 step 0: objective=0.8496646
2017/08/27 07:00:22 step 1: objective=0.85509187
2017/08/27 07:00:25 step 2: objective=0.85908717
2017/08/27 07:00:28 step 3: objective=0.86251974
2017/08/27 07:00:31 step 4: objective=0.86503273
2017/08/27 07:00:34 step 5: objective=0.86746734
2017/08/27 07:00:37 step 6: objective=0.8693438
2017/08/27 07:00:40 step 7: objective=0.87121606
2017/08/27 07:00:40 Training value function...
2017/08/27 07:00:45 step 0: mse=41.129014 step=0.100000
2017/08/27 07:00:48 step 1: mse=40.677716 step=0.100000
2017/08/27 07:00:50 step 2: mse=40.280508 step=0.100000
2017/08/27 07:00:53 step 3: mse=40.162080 step=0.100000
2017/08/27 07:00:55 step 4: mse=39.720885 step=0.100000
2017/08/27 07:00:58 step 5: mse=39.434586 step=0.100000
2017/08/27 07:01:00 step 6: mse=39.215363 step=0.100000
2017/08/27 07:01:02 step 7: mse=38.893538 step=0.100000
2017/08/27 07:01:02 Saving...
2017/08/27 07:01:03 Gathering batch of experience...
2017/08/27 07:02:53 batch 204: mean=436.846154 stddev=129.623031 entropy=0.641025 frames=5657 count=13
2017/08/27 07:02:53 Training policy...
2017/08/27 07:03:01 step 0: objective=0.7697957
2017/08/27 07:03:03 step 1: objective=0.7738805
2017/08/27 07:03:06 step 2: objective=0.77721524
2017/08/27 07:03:09 step 3: objective=0.779887
2017/08/27 07:03:12 step 4: objective=0.7828549
2017/08/27 07:03:15 step 5: objective=0.7853646
2017/08/27 07:03:18 step 6: objective=0.7874856
2017/08/27 07:03:21 step 7: objective=0.7896115
2017/08/27 07:03:21 Training value function...
2017/08/27 07:03:25 step 0: mse=41.247173 step=0.100000
2017/08/27 07:03:28 step 1: mse=40.618749 step=0.100000
2017/08/27 07:03:30 step 2: mse=40.036401 step=0.100000
2017/08/27 07:03:32 step 3: mse=39.665052 step=0.100000
2017/08/27 07:03:35 step 4: mse=39.284129 step=0.100000
2017/08/27 07:03:37 step 5: mse=38.874682 step=0.100000
2017/08/27 07:03:39 step 6: mse=38.570183 step=0.100000
2017/08/27 07:03:42 step 7: mse=38.279122 step=0.100000
2017/08/27 07:03:42 Saving...
2017/08/27 07:03:42 Gathering batch of experience...
2017/08/27 07:05:38 batch 205: mean=496.500000 stddev=116.706541 entropy=0.638864 frames=5876 count=12
2017/08/27 07:05:38 Training policy...
2017/08/27 07:05:46 step 0: objective=1.1706164
2017/08/27 07:05:49 step 1: objective=1.1750225
2017/08/27 07:05:52 step 2: objective=1.1786652
2017/08/27 07:05:55 step 3: objective=1.1828967
2017/08/27 07:05:58 step 4: objective=1.1853496
2017/08/27 07:06:01 step 5: objective=1.1879016
2017/08/27 07:06:04 step 6: objective=1.1900721
2017/08/27 07:06:07 step 7: objective=1.1921419
2017/08/27 07:06:07 Training value function...
2017/08/27 07:06:11 step 0: mse=41.689199 step=0.100000
2017/08/27 07:06:14 step 1: mse=40.882616 step=0.100000
2017/08/27 07:06:16 step 2: mse=40.310059 step=0.100000
2017/08/27 07:06:19 step 3: mse=39.422025 step=0.100000
2017/08/27 07:06:21 step 4: mse=38.839322 step=0.100000
2017/08/27 07:06:24 step 5: mse=38.356874 step=0.100000
2017/08/27 07:06:26 step 6: mse=37.641266 step=0.100000
2017/08/27 07:06:29 step 7: mse=37.130910 step=0.100000
2017/08/27 07:06:29 Saving...
2017/08/27 07:06:29 Gathering batch of experience...
2017/08/27 07:08:23 batch 206: mean=462.833333 stddev=174.489175 entropy=0.644842 frames=5477 count=12
2017/08/27 07:08:23 Training policy...
2017/08/27 07:08:30 step 0: objective=1.0259223
2017/08/27 07:08:33 step 1: objective=1.029293
2017/08/27 07:08:36 step 2: objective=1.0323936
2017/08/27 07:08:38 step 3: objective=1.0353287
2017/08/27 07:08:41 step 4: objective=1.037543
2017/08/27 07:08:44 step 5: objective=1.039678
2017/08/27 07:08:47 step 6: objective=1.0416286
2017/08/27 07:08:49 step 7: objective=1.0432278
2017/08/27 07:08:49 Training value function...
2017/08/27 07:08:54 step 0: mse=44.694605 step=0.100000
2017/08/27 07:08:56 step 1: mse=43.985686 step=0.100000
2017/08/27 07:08:59 step 2: mse=43.339919 step=0.100000
2017/08/27 07:09:01 step 3: mse=42.843650 step=0.100000
2017/08/27 07:09:03 step 4: mse=42.382445 step=0.100000
2017/08/27 07:09:06 step 5: mse=41.956491 step=0.100000
2017/08/27 07:09:08 step 6: mse=41.509457 step=0.100000
2017/08/27 07:09:10 step 7: mse=41.137976 step=0.100000
2017/08/27 07:09:10 Saving...
2017/08/27 07:09:10 Gathering batch of experience...
2017/08/27 07:11:03 batch 207: mean=393.769231 stddev=208.259141 entropy=0.651291 frames=5076 count=13
2017/08/27 07:11:03 Training policy...
2017/08/27 07:11:10 step 0: objective=0.85996324
2017/08/27 07:11:12 step 1: objective=0.8670999
2017/08/27 07:11:15 step 2: objective=0.87069935
2017/08/27 07:11:17 step 3: objective=0.87357837
2017/08/27 07:11:20 step 4: objective=0.87735635
2017/08/27 07:11:23 step 5: objective=0.8811433
2017/08/27 07:11:25 step 6: objective=0.88290745
2017/08/27 07:11:28 step 7: objective=0.8848891
2017/08/27 07:11:28 Training value function...
2017/08/27 07:11:32 step 0: mse=47.617277 step=0.100000
2017/08/27 07:11:34 step 1: mse=47.061033 step=0.100000
2017/08/27 07:11:36 step 2: mse=46.611160 step=0.100000
2017/08/27 07:11:38 step 3: mse=46.197461 step=0.100000
2017/08/27 07:11:40 step 4: mse=45.676643 step=0.100000
2017/08/27 07:11:43 step 5: mse=45.363201 step=0.100000
2017/08/27 07:11:45 step 6: mse=44.717244 step=0.100000
2017/08/27 07:11:47 step 7: mse=44.170787 step=0.100000
2017/08/27 07:11:47 Saving...
2017/08/27 07:11:47 Gathering batch of experience...
2017/08/27 07:13:38 batch 208: mean=412.928571 stddev=183.461738 entropy=0.649592 frames=5742 count=14
2017/08/27 07:13:38 Training policy...
2017/08/27 07:13:46 step 0: objective=1.0072953
2017/08/27 07:13:49 step 1: objective=1.012312
2017/08/27 07:13:52 step 2: objective=1.0166098
2017/08/27 07:13:55 step 3: objective=1.0200571
2017/08/27 07:13:58 step 4: objective=1.0231683
2017/08/27 07:14:01 step 5: objective=1.0250026
2017/08/27 07:14:04 step 6: objective=1.0278959
2017/08/27 07:14:06 step 7: objective=1.0300491
2017/08/27 07:14:06 Training value function...
2017/08/27 07:14:11 step 0: mse=50.048365 step=0.100000
2017/08/27 07:14:14 step 1: mse=49.579666 step=0.100000
2017/08/27 07:14:16 step 2: mse=49.170436 step=0.100000
2017/08/27 07:14:18 step 3: mse=48.818450 step=0.100000
2017/08/27 07:14:21 step 4: mse=48.463735 step=0.100000
2017/08/27 07:14:23 step 5: mse=48.201908 step=0.100000
2017/08/27 07:14:26 step 6: mse=47.908661 step=0.100000
2017/08/27 07:14:28 step 7: mse=47.686331 step=0.100000
2017/08/27 07:14:28 Saving...
2017/08/27 07:14:28 Gathering batch of experience...
2017/08/27 07:16:22 batch 209: mean=382.875000 stddev=214.077052 entropy=0.649332 frames=6079 count=16
2017/08/27 07:16:22 Training policy...
2017/08/27 07:16:30 step 0: objective=0.96674556
2017/08/27 07:16:33 step 1: objective=0.97211945
2017/08/27 07:16:36 step 2: objective=0.9757638
2017/08/27 07:16:39 step 3: objective=0.97972745
2017/08/27 07:16:43 step 4: objective=0.98336124
2017/08/27 07:16:46 step 5: objective=0.98546845
2017/08/27 07:16:49 step 6: objective=0.9876761
2017/08/27 07:16:52 step 7: objective=0.99013436
2017/08/27 07:16:52 Training value function...
2017/08/27 07:16:57 step 0: mse=50.449394 step=0.100000
2017/08/27 07:16:59 step 1: mse=49.493232 step=0.100000
2017/08/27 07:17:02 step 2: mse=48.642087 step=0.100000
2017/08/27 07:17:05 step 3: mse=48.055348 step=0.100000
2017/08/27 07:17:07 step 4: mse=47.573280 step=0.100000
2017/08/27 07:17:10 step 5: mse=47.048813 step=0.100000
2017/08/27 07:17:12 step 6: mse=46.672850 step=0.100000
2017/08/27 07:17:15 step 7: mse=46.279191 step=0.100000
2017/08/27 07:17:15 Saving...
2017/08/27 07:17:15 Gathering batch of experience...
2017/08/27 07:19:28 batch 210: mean=426.466667 stddev=223.868970 entropy=0.652872 frames=6290 count=15
2017/08/27 07:19:28 Training policy...
2017/08/27 07:19:37 step 0: objective=1.070621
2017/08/27 07:19:40 step 1: objective=1.0746405
2017/08/27 07:19:43 step 2: objective=1.0785692
2017/08/27 07:19:46 step 3: objective=1.0814931
2017/08/27 07:19:50 step 4: objective=1.0845947
2017/08/27 07:19:53 step 5: objective=1.087406
2017/08/27 07:19:56 step 6: objective=1.0897022
2017/08/27 07:20:00 step 7: objective=1.0935967
2017/08/27 07:20:00 Training value function...
2017/08/27 07:20:05 step 0: mse=46.576402 step=0.100000
2017/08/27 07:20:07 step 1: mse=45.938279 step=0.100000
2017/08/27 07:20:10 step 2: mse=45.287405 step=0.100000
2017/08/27 07:20:13 step 3: mse=44.628737 step=0.100000
2017/08/27 07:20:16 step 4: mse=44.154221 step=0.100000
2017/08/27 07:20:18 step 5: mse=43.740255 step=0.100000
2017/08/27 07:20:21 step 6: mse=43.270352 step=0.100000
2017/08/27 07:20:23 step 7: mse=42.930159 step=0.100000
2017/08/27 07:20:23 Saving...
2017/08/27 07:20:24 Gathering batch of experience...
2017/08/27 07:22:34 batch 211: mean=418.357143 stddev=230.491589 entropy=0.648959 frames=5764 count=14
2017/08/27 07:22:34 Training policy...
2017/08/27 07:22:42 step 0: objective=1.1045306
2017/08/27 07:22:45 step 1: objective=1.1106501
2017/08/27 07:22:48 step 2: objective=1.1152327
2017/08/27 07:22:51 step 3: objective=1.1181532
2017/08/27 07:22:54 step 4: objective=1.1216117
2017/08/27 07:22:57 step 5: objective=1.1247629
2017/08/27 07:23:00 step 6: objective=1.1271018
2017/08/27 07:23:03 step 7: objective=1.1294155
2017/08/27 07:23:03 Training value function...
2017/08/27 07:23:08 step 0: mse=51.851697 step=0.100000
2017/08/27 07:23:10 step 1: mse=50.938752 step=0.100000
2017/08/27 07:23:13 step 2: mse=50.047867 step=0.100000
2017/08/27 07:23:15 step 3: mse=49.475268 step=0.100000
2017/08/27 07:23:17 step 4: mse=48.808477 step=0.100000
2017/08/27 07:23:20 step 5: mse=48.247659 step=0.100000
2017/08/27 07:23:22 step 6: mse=47.374542 step=0.100000
2017/08/27 07:23:25 step 7: mse=46.958458 step=0.100000
2017/08/27 07:23:25 Saving...
2017/08/27 07:23:25 Gathering batch of experience...
2017/08/27 07:25:34 batch 212: mean=375.933333 stddev=197.192450 entropy=0.651294 frames=5621 count=15
2017/08/27 07:25:34 Training policy...
2017/08/27 07:25:42 step 0: objective=0.77276105
2017/08/27 07:25:45 step 1: objective=0.77839684
2017/08/27 07:25:47 step 2: objective=0.78196555
2017/08/27 07:25:50 step 3: objective=0.78614724
2017/08/27 07:25:53 step 4: objective=0.7882922
2017/08/27 07:25:56 step 5: objective=0.7902189
2017/08/27 07:25:59 step 6: objective=0.79247534
2017/08/27 07:26:02 step 7: objective=0.7942665
2017/08/27 07:26:02 Training value function...
2017/08/27 07:26:06 step 0: mse=44.065488 step=0.100000
2017/08/27 07:26:09 step 1: mse=43.669719 step=0.100000
2017/08/27 07:26:11 step 2: mse=43.414725 step=0.100000
2017/08/27 07:26:13 step 3: mse=43.187250 step=0.100000
2017/08/27 07:26:16 step 4: mse=42.932779 step=0.100000
2017/08/27 07:26:18 step 5: mse=42.728601 step=0.100000
2017/08/27 07:26:21 step 6: mse=42.646545 step=0.100000
2017/08/27 07:26:23 step 7: mse=42.543402 step=0.100000
2017/08/27 07:26:23 Saving...
2017/08/27 07:26:23 Gathering batch of experience...
2017/08/27 07:28:15 batch 213: mean=341.764706 stddev=211.664143 entropy=0.655332 frames=5796 count=17
2017/08/27 07:28:15 Training policy...
2017/08/27 07:28:23 step 0: objective=0.92277896
2017/08/27 07:28:26 step 1: objective=0.92917734
2017/08/27 07:28:29 step 2: objective=0.93413424
2017/08/27 07:28:32 step 3: objective=0.9383384
2017/08/27 07:28:35 step 4: objective=0.94154197
2017/08/27 07:28:38 step 5: objective=0.94450915
2017/08/27 07:28:41 step 6: objective=0.9473661
2017/08/27 07:28:44 step 7: objective=0.9494547
2017/08/27 07:28:44 Training value function...
2017/08/27 07:28:48 step 0: mse=54.464002 step=0.100000
2017/08/27 07:28:51 step 1: mse=54.099022 step=0.100000
2017/08/27 07:28:53 step 2: mse=53.121629 step=0.100000
2017/08/27 07:28:56 step 3: mse=52.336533 step=0.100000
2017/08/27 07:28:58 step 4: mse=52.040772 step=0.100000
2017/08/27 07:29:01 step 5: mse=51.755135 step=0.100000
2017/08/27 07:29:03 step 6: mse=51.064800 step=0.100000
2017/08/27 07:29:06 step 7: mse=50.917883 step=0.100000
2017/08/27 07:29:06 Saving...
2017/08/27 07:29:06 Gathering batch of experience...
2017/08/27 07:31:05 batch 214: mean=411.500000 stddev=151.405204 entropy=0.643829 frames=5747 count=14
2017/08/27 07:31:05 Training policy...
2017/08/27 07:31:13 step 0: objective=1.2089719
2017/08/27 07:31:16 step 1: objective=1.2148275
2017/08/27 07:31:19 step 2: objective=1.2199134
2017/08/27 07:31:22 step 3: objective=1.222741
2017/08/27 07:31:25 step 4: objective=1.2266395
2017/08/27 07:31:28 step 5: objective=1.2290804
2017/08/27 07:31:31 step 6: objective=1.2315773
2017/08/27 07:31:34 step 7: objective=1.2342552
2017/08/27 07:31:34 Training value function...
2017/08/27 07:31:39 step 0: mse=49.788294 step=0.100000
2017/08/27 07:31:41 step 1: mse=48.619532 step=0.100000
2017/08/27 07:31:43 step 2: mse=47.326522 step=0.100000
2017/08/27 07:31:46 step 3: mse=46.419354 step=0.100000
2017/08/27 07:31:48 step 4: mse=45.638060 step=0.100000
2017/08/27 07:31:51 step 5: mse=44.518094 step=0.100000
2017/08/27 07:31:53 step 6: mse=43.703215 step=0.100000
2017/08/27 07:31:56 step 7: mse=42.895490 step=0.100000
2017/08/27 07:31:56 Saving...
2017/08/27 07:31:56 Gathering batch of experience...
2017/08/27 07:33:41 batch 215: mean=417.076923 stddev=147.958654 entropy=0.643617 frames=5404 count=13
2017/08/27 07:33:41 Training policy...
2017/08/27 07:33:49 step 0: objective=0.9179453
2017/08/27 07:33:51 step 1: objective=0.9226726
2017/08/27 07:33:54 step 2: objective=0.9254632
2017/08/27 07:33:57 step 3: objective=0.9295131
2017/08/27 07:34:00 step 4: objective=0.9315678
2017/08/27 07:34:03 step 5: objective=0.93422323
2017/08/27 07:34:05 step 6: objective=0.9361237
2017/08/27 07:34:08 step 7: objective=0.9386862
2017/08/27 07:34:08 Training value function...
2017/08/27 07:34:13 step 0: mse=41.812562 step=0.100000
2017/08/27 07:34:15 step 1: mse=41.206195 step=0.100000
2017/08/27 07:34:17 step 2: mse=40.770101 step=0.100000
2017/08/27 07:34:19 step 3: mse=40.484661 step=0.100000
2017/08/27 07:34:22 step 4: mse=40.050919 step=0.100000
2017/08/27 07:34:24 step 5: mse=39.677244 step=0.100000
2017/08/27 07:34:26 step 6: mse=39.342107 step=0.100000
2017/08/27 07:34:29 step 7: mse=38.939577 step=0.100000
2017/08/27 07:34:29 Saving...
2017/08/27 07:34:29 Gathering batch of experience...
2017/08/27 07:36:26 batch 216: mean=368.666667 stddev=206.402735 entropy=0.652326 frames=5505 count=15
2017/08/27 07:36:26 Training policy...
2017/08/27 07:36:34 step 0: objective=1.0503036
2017/08/27 07:36:36 step 1: objective=1.0559179
2017/08/27 07:36:39 step 2: objective=1.0598704
2017/08/27 07:36:42 step 3: objective=1.0637623
2017/08/27 07:36:45 step 4: objective=1.0664907
2017/08/27 07:36:48 step 5: objective=1.069038
2017/08/27 07:36:50 step 6: objective=1.0710329
2017/08/27 07:36:53 step 7: objective=1.0731003
2017/08/27 07:36:53 Training value function...
2017/08/27 07:36:58 step 0: mse=50.729651 step=0.100000
2017/08/27 07:37:00 step 1: mse=49.898144 step=0.100000
2017/08/27 07:37:02 step 2: mse=49.041687 step=0.100000
2017/08/27 07:37:05 step 3: mse=48.489341 step=0.100000
2017/08/27 07:37:07 step 4: mse=47.726450 step=0.100000
2017/08/27 07:37:09 step 5: mse=47.065055 step=0.100000
2017/08/27 07:37:12 step 6: mse=46.384159 step=0.100000
2017/08/27 07:37:14 step 7: mse=45.857841 step=0.100000
2017/08/27 07:37:14 Saving...
2017/08/27 07:37:14 Gathering batch of experience...
2017/08/27 07:39:22 batch 217: mean=563.333333 stddev=170.922172 entropy=0.642129 frames=6559 count=12
2017/08/27 07:39:22 Training policy...
2017/08/27 07:39:31 step 0: objective=1.8444568
2017/08/27 07:39:35 step 1: objective=1.8501767
2017/08/27 07:39:38 step 2: objective=1.8543924
2017/08/27 07:39:42 step 3: objective=1.8572136
2017/08/27 07:39:45 step 4: objective=1.8612653
2017/08/27 07:39:49 step 5: objective=1.8635302
2017/08/27 07:39:52 step 6: objective=1.8668957
2017/08/27 07:39:55 step 7: objective=1.8685205
2017/08/27 07:39:55 Training value function...
2017/08/27 07:40:01 step 0: mse=60.053592 step=0.100000
2017/08/27 07:40:04 step 1: mse=57.227272 step=0.100000
2017/08/27 07:40:07 step 2: mse=54.785453 step=0.100000
2017/08/27 07:40:09 step 3: mse=52.580473 step=0.100000
2017/08/27 07:40:12 step 4: mse=50.595126 step=0.100000
2017/08/27 07:40:15 step 5: mse=48.840467 step=0.100000
2017/08/27 07:40:18 step 6: mse=47.521602 step=0.100000
2017/08/27 07:40:21 step 7: mse=46.274269 step=0.100000
2017/08/27 07:40:21 Saving...
2017/08/27 07:40:21 Gathering batch of experience...
2017/08/27 07:42:12 batch 218: mean=446.769231 stddev=182.632525 entropy=0.644293 frames=5744 count=13
2017/08/27 07:42:12 Training policy...
2017/08/27 07:42:20 step 0: objective=0.78917205
2017/08/27 07:42:23 step 1: objective=0.7964186
2017/08/27 07:42:25 step 2: objective=0.8003129
2017/08/27 07:42:28 step 3: objective=0.80388105
2017/08/27 07:42:31 step 4: objective=0.80716664
2017/08/27 07:42:34 step 5: objective=0.80954313
2017/08/27 07:42:37 step 6: objective=0.81132513
2017/08/27 07:42:40 step 7: objective=0.8127463
2017/08/27 07:42:40 Training value function...
2017/08/27 07:42:45 step 0: mse=47.039140 step=0.100000
2017/08/27 07:42:47 step 1: mse=46.350618 step=0.100000
2017/08/27 07:42:50 step 2: mse=45.881253 step=0.100000
2017/08/27 07:42:52 step 3: mse=45.407810 step=0.100000
2017/08/27 07:42:55 step 4: mse=45.073505 step=0.100000
2017/08/27 07:42:57 step 5: mse=44.451558 step=0.100000
2017/08/27 07:43:00 step 6: mse=44.156185 step=0.100000
2017/08/27 07:43:02 step 7: mse=43.599026 step=0.100000
2017/08/27 07:43:02 Saving...
2017/08/27 07:43:02 Gathering batch of experience...
2017/08/27 07:44:58 batch 219: mean=442.692308 stddev=107.514138 entropy=0.638532 frames=5739 count=13
2017/08/27 07:44:58 Training policy...
2017/08/27 07:45:05 step 0: objective=0.8248932
2017/08/27 07:45:08 step 1: objective=0.829723
2017/08/27 07:45:11 step 2: objective=0.8331871
2017/08/27 07:45:14 step 3: objective=0.8356924
2017/08/27 07:45:17 step 4: objective=0.83750767
2017/08/27 07:45:20 step 5: objective=0.83904433
2017/08/27 07:45:23 step 6: objective=0.8423124
2017/08/27 07:45:26 step 7: objective=0.84405994
2017/08/27 07:45:26 Training value function...
2017/08/27 07:45:31 step 0: mse=40.211570 step=0.100000
2017/08/27 07:45:33 step 1: mse=39.732663 step=0.100000
2017/08/27 07:45:36 step 2: mse=38.920607 step=0.100000
2017/08/27 07:45:38 step 3: mse=38.529177 step=0.100000
2017/08/27 07:45:40 step 4: mse=38.266918 step=0.100000
2017/08/27 07:45:43 step 5: mse=38.037347 step=0.100000
2017/08/27 07:45:45 step 6: mse=37.149037 step=0.100000
2017/08/27 07:45:48 step 7: mse=36.424608 step=0.100000
2017/08/27 07:45:48 Saving...
2017/08/27 07:45:48 Gathering batch of experience...
2017/08/27 07:47:48 batch 220: mean=384.733333 stddev=191.793454 entropy=0.640797 frames=5747 count=15
2017/08/27 07:47:48 Training policy...
2017/08/27 07:47:55 step 0: objective=0.9435633
2017/08/27 07:47:58 step 1: objective=0.94909674
2017/08/27 07:48:01 step 2: objective=0.95286155
2017/08/27 07:48:04 step 3: objective=0.9560246
2017/08/27 07:48:07 step 4: objective=0.9597269
2017/08/27 07:48:10 step 5: objective=0.9628972
2017/08/27 07:48:13 step 6: objective=0.9658315
2017/08/27 07:48:16 step 7: objective=0.96768
2017/08/27 07:48:16 Training value function...
2017/08/27 07:48:21 step 0: mse=48.417539 step=0.100000
2017/08/27 07:48:23 step 1: mse=47.738041 step=0.100000
2017/08/27 07:48:26 step 2: mse=46.999985 step=0.100000
2017/08/27 07:48:28 step 3: mse=46.285204 step=0.100000
2017/08/27 07:48:31 step 4: mse=45.696698 step=0.100000
2017/08/27 07:48:33 step 5: mse=45.123117 step=0.100000
2017/08/27 07:48:35 step 6: mse=44.698230 step=0.100000
2017/08/27 07:48:38 step 7: mse=44.230154 step=0.100000
2017/08/27 07:48:38 Saving...
2017/08/27 07:48:38 Gathering batch of experience...
2017/08/27 07:50:35 batch 221: mean=334.611111 stddev=188.909778 entropy=0.650161 frames=6051 count=18
2017/08/27 07:50:35 Training policy...
2017/08/27 07:50:43 step 0: objective=0.7428867
2017/08/27 07:50:46 step 1: objective=0.7480133
2017/08/27 07:50:49 step 2: objective=0.75293565
2017/08/27 07:50:52 step 3: objective=0.75747466
2017/08/27 07:50:55 step 4: objective=0.7609114
2017/08/27 07:50:58 step 5: objective=0.7638405
2017/08/27 07:51:02 step 6: objective=0.7658562
2017/08/27 07:51:05 step 7: objective=0.76826376
2017/08/27 07:51:05 Training value function...
2017/08/27 07:51:10 step 0: mse=53.576082 step=0.100000
2017/08/27 07:51:12 step 1: mse=53.434624 step=0.100000
2017/08/27 07:51:15 step 2: mse=53.279903 step=0.100000
2017/08/27 07:51:17 step 3: mse=53.177383 step=0.100000
2017/08/27 07:51:20 step 4: mse=52.801948 step=0.100000
2017/08/27 07:51:22 step 5: mse=52.694425 step=0.100000
2017/08/27 07:51:25 step 6: mse=52.570425 step=0.100000
2017/08/27 07:51:27 step 7: mse=52.458200 step=0.100000
2017/08/27 07:51:27 Saving...
2017/08/27 07:51:28 Gathering batch of experience...
2017/08/27 07:53:12 batch 222: mean=343.750000 stddev=208.792511 entropy=0.644089 frames=5491 count=16
2017/08/27 07:53:12 Training policy...
2017/08/27 07:53:19 step 0: objective=1.0915803
2017/08/27 07:53:22 step 1: objective=1.0995508
2017/08/27 07:53:25 step 2: objective=1.1044972
2017/08/27 07:53:28 step 3: objective=1.1083273
2017/08/27 07:53:31 step 4: objective=1.1112944
2017/08/27 07:53:33 step 5: objective=1.1132944
2017/08/27 07:53:36 step 6: objective=1.1148069
2017/08/27 07:53:39 step 7: objective=1.1176581
2017/08/27 07:53:39 Training value function...
2017/08/27 07:53:44 step 0: mse=55.018842 step=0.100000
2017/08/27 07:53:46 step 1: mse=54.259511 step=0.100000
2017/08/27 07:53:48 step 2: mse=53.514732 step=0.100000
2017/08/27 07:53:51 step 3: mse=52.863004 step=0.100000
2017/08/27 07:53:53 step 4: mse=52.252238 step=0.100000
2017/08/27 07:53:55 step 5: mse=51.615654 step=0.100000
2017/08/27 07:53:58 step 6: mse=51.001224 step=0.100000
2017/08/27 07:54:00 step 7: mse=50.162700 step=0.100000
2017/08/27 07:54:00 Saving...
2017/08/27 07:54:00 Gathering batch of experience...
2017/08/27 07:56:07 batch 223: mean=534.909091 stddev=108.750302 entropy=0.631705 frames=5768 count=11
2017/08/27 07:56:07 Training policy...
2017/08/27 07:56:15 step 0: objective=1.4182055
2017/08/27 07:56:18 step 1: objective=1.4216112
2017/08/27 07:56:21 step 2: objective=1.4244932
2017/08/27 07:56:24 step 3: objective=1.4280982
2017/08/27 07:56:27 step 4: objective=1.4303169
2017/08/27 07:56:30 step 5: objective=1.4320704
2017/08/27 07:56:33 step 6: objective=1.4342682
2017/08/27 07:56:36 step 7: objective=1.435905
2017/08/27 07:56:36 Training value function...
2017/08/27 07:56:41 step 0: mse=46.999865 step=0.100000
2017/08/27 07:56:43 step 1: mse=45.439880 step=0.100000
2017/08/27 07:56:45 step 2: mse=44.206077 step=0.100000
2017/08/27 07:56:48 step 3: mse=43.049686 step=0.100000
2017/08/27 07:56:50 step 4: mse=42.014492 step=0.100000
2017/08/27 07:56:53 step 5: mse=41.135417 step=0.100000
2017/08/27 07:56:55 step 6: mse=40.310847 step=0.100000
2017/08/27 07:56:57 step 7: mse=39.618760 step=0.100000
2017/08/27 07:56:57 Saving...
2017/08/27 07:56:58 Gathering batch of experience...
2017/08/27 07:58:49 batch 224: mean=392.857143 stddev=222.809290 entropy=0.633112 frames=5440 count=14
2017/08/27 07:58:49 Training policy...
2017/08/27 07:58:57 step 0: objective=0.9912102
2017/08/27 07:59:00 step 1: objective=0.99745464
2017/08/27 07:59:02 step 2: objective=1.0028334
2017/08/27 07:59:05 step 3: objective=1.0079224
2017/08/27 07:59:08 step 4: objective=1.0123831
2017/08/27 07:59:11 step 5: objective=1.0147386
2017/08/27 07:59:14 step 6: objective=1.0170938
2017/08/27 07:59:16 step 7: objective=1.0194921
2017/08/27 07:59:16 Training value function...
2017/08/27 07:59:21 step 0: mse=51.522844 step=0.100000
2017/08/27 07:59:23 step 1: mse=50.843690 step=0.100000
2017/08/27 07:59:26 step 2: mse=50.218495 step=0.100000
2017/08/27 07:59:28 step 3: mse=49.867943 step=0.100000
2017/08/27 07:59:30 step 4: mse=49.013758 step=0.100000
2017/08/27 07:59:33 step 5: mse=48.269575 step=0.100000
2017/08/27 07:59:35 step 6: mse=47.235661 step=0.100000
2017/08/27 07:59:37 step 7: mse=46.213143 step=0.100000
2017/08/27 07:59:37 Saving...
2017/08/27 07:59:37 Gathering batch of experience...
2017/08/27 08:01:41 batch 225: mean=397.812500 stddev=208.763089 entropy=0.641607 frames=6308 count=16
2017/08/27 08:01:41 Training policy...
2017/08/27 08:01:50 step 0: objective=0.9850615
2017/08/27 08:01:53 step 1: objective=0.9914657
2017/08/27 08:01:57 step 2: objective=0.99543595
2017/08/27 08:02:00 step 3: objective=0.99751085
2017/08/27 08:02:03 step 4: objective=1.0007707
2017/08/27 08:02:07 step 5: objective=1.0023319
2017/08/27 08:02:10 step 6: objective=1.0043701
2017/08/27 08:02:13 step 7: objective=1.0062537
2017/08/27 08:02:13 Training value function...
2017/08/27 08:02:18 step 0: mse=47.752957 step=0.100000
2017/08/27 08:02:21 step 1: mse=47.235827 step=0.100000
2017/08/27 08:02:24 step 2: mse=46.711730 step=0.100000
2017/08/27 08:02:27 step 3: mse=45.968071 step=0.100000
2017/08/27 08:02:29 step 4: mse=45.374590 step=0.100000
2017/08/27 08:02:32 step 5: mse=44.916002 step=0.100000
2017/08/27 08:02:35 step 6: mse=44.448107 step=0.100000
2017/08/27 08:02:37 step 7: mse=43.885767 step=0.100000
2017/08/27 08:02:37 Saving...
2017/08/27 08:02:38 Gathering batch of experience...
2017/08/27 08:04:33 batch 226: mean=423.714286 stddev=176.749794 entropy=0.643976 frames=5889 count=14
2017/08/27 08:04:33 Training policy...
2017/08/27 08:04:41 step 0: objective=0.963719
2017/08/27 08:04:44 step 1: objective=0.9670697
2017/08/27 08:04:47 step 2: objective=0.97045225
2017/08/27 08:04:50 step 3: objective=0.9728384
2017/08/27 08:04:53 step 4: objective=0.975216
2017/08/27 08:04:56 step 5: objective=0.9773744
2017/08/27 08:04:59 step 6: objective=0.97947794
2017/08/27 08:05:02 step 7: objective=0.9812089
2017/08/27 08:05:02 Training value function...
2017/08/27 08:05:07 step 0: mse=44.922725 step=0.100000
2017/08/27 08:05:09 step 1: mse=44.345772 step=0.100000
2017/08/27 08:05:12 step 2: mse=43.840915 step=0.100000
2017/08/27 08:05:14 step 3: mse=43.458679 step=0.100000
2017/08/27 08:05:17 step 4: mse=43.037998 step=0.100000
2017/08/27 08:05:19 step 5: mse=42.713583 step=0.100000
2017/08/27 08:05:22 step 6: mse=42.362085 step=0.100000
2017/08/27 08:05:24 step 7: mse=42.092216 step=0.100000
2017/08/27 08:05:24 Saving...
2017/08/27 08:05:24 Gathering batch of experience...
2017/08/27 08:07:25 batch 227: mean=459.615385 stddev=182.763209 entropy=0.632774 frames=5890 count=13
2017/08/27 08:07:25 Training policy...
2017/08/27 08:07:33 step 0: objective=1.3856374
2017/08/27 08:07:36 step 1: objective=1.3911426
2017/08/27 08:07:39 step 2: objective=1.3960918
2017/08/27 08:07:42 step 3: objective=1.3997476
2017/08/27 08:07:46 step 4: objective=1.4030612
2017/08/27 08:07:49 step 5: objective=1.4057841
2017/08/27 08:07:52 step 6: objective=1.4077501
2017/08/27 08:07:55 step 7: objective=1.4095411
2017/08/27 08:07:55 Training value function...
2017/08/27 08:08:00 step 0: mse=55.058284 step=0.100000
2017/08/27 08:08:02 step 1: mse=52.964683 step=0.100000
2017/08/27 08:08:05 step 2: mse=51.659912 step=0.100000
2017/08/27 08:08:07 step 3: mse=50.584797 step=0.100000
2017/08/27 08:08:10 step 4: mse=49.065586 step=0.100000
2017/08/27 08:08:13 step 5: mse=48.047247 step=0.100000
2017/08/27 08:08:15 step 6: mse=47.295240 step=0.100000
2017/08/27 08:08:18 step 7: mse=46.458803 step=0.100000
2017/08/27 08:08:18 Saving...
2017/08/27 08:08:18 Gathering batch of experience...
2017/08/27 08:10:32 batch 228: mean=486.307692 stddev=166.940056 entropy=0.630514 frames=6222 count=13
2017/08/27 08:10:32 Training policy...
2017/08/27 08:10:41 step 0: objective=1.062177
2017/08/27 08:10:44 step 1: objective=1.0674677
2017/08/27 08:10:47 step 2: objective=1.071376
2017/08/27 08:10:50 step 3: objective=1.0751461
2017/08/27 08:10:54 step 4: objective=1.0779582
2017/08/27 08:10:57 step 5: objective=1.0796267
2017/08/27 08:11:00 step 6: objective=1.0815907
2017/08/27 08:11:03 step 7: objective=1.0846123
2017/08/27 08:11:03 Training value function...
2017/08/27 08:11:08 step 0: mse=47.005174 step=0.100000
2017/08/27 08:11:11 step 1: mse=46.561424 step=0.100000
2017/08/27 08:11:14 step 2: mse=46.201110 step=0.100000
2017/08/27 08:11:16 step 3: mse=45.623283 step=0.100000
2017/08/27 08:11:19 step 4: mse=45.038021 step=0.100000
2017/08/27 08:11:22 step 5: mse=44.596637 step=0.100000
2017/08/27 08:11:24 step 6: mse=44.332085 step=0.100000
2017/08/27 08:11:27 step 7: mse=44.020286 step=0.100000
2017/08/27 08:11:27 Saving...
2017/08/27 08:11:27 Gathering batch of experience...
2017/08/27 08:13:31 batch 229: mean=460.230769 stddev=146.579542 entropy=0.633933 frames=5925 count=13
2017/08/27 08:13:31 Training policy...
2017/08/27 08:13:39 step 0: objective=0.86341953
2017/08/27 08:13:42 step 1: objective=0.869407
2017/08/27 08:13:45 step 2: objective=0.8727415
2017/08/27 08:13:48 step 3: objective=0.87615204
2017/08/27 08:13:51 step 4: objective=0.8784037
2017/08/27 08:13:54 step 5: objective=0.8803808
2017/08/27 08:13:57 step 6: objective=0.8826735
2017/08/27 08:14:00 step 7: objective=0.88448906
2017/08/27 08:14:00 Training value function...
2017/08/27 08:14:05 step 0: mse=41.756863 step=0.100000
2017/08/27 08:14:08 step 1: mse=41.593433 step=0.100000
2017/08/27 08:14:10 step 2: mse=41.328234 step=0.100000
2017/08/27 08:14:13 step 3: mse=41.174669 step=0.100000
2017/08/27 08:14:15 step 4: mse=40.952234 step=0.100000
2017/08/27 08:14:18 step 5: mse=40.850747 step=0.100000
2017/08/27 08:14:20 step 6: mse=40.667321 step=0.100000
2017/08/27 08:14:23 step 7: mse=40.511177 step=0.100000
2017/08/27 08:14:23 Saving...
2017/08/27 08:14:23 Gathering batch of experience...
2017/08/27 08:16:13 batch 230: mean=451.769231 stddev=193.303330 entropy=0.630542 frames=5787 count=13
2017/08/27 08:16:13 Training policy...
2017/08/27 08:16:21 step 0: objective=1.0644848
2017/08/27 08:16:24 step 1: objective=1.0685018
2017/08/27 08:16:27 step 2: objective=1.0721048
2017/08/27 08:16:30 step 3: objective=1.0740459
2017/08/27 08:16:34 step 4: objective=1.0771664
2017/08/27 08:16:37 step 5: objective=1.0793468
2017/08/27 08:16:40 step 6: objective=1.0822928
2017/08/27 08:16:43 step 7: objective=1.084004
2017/08/27 08:16:43 Training value function...
2017/08/27 08:16:48 step 0: mse=45.184891 step=0.100000
2017/08/27 08:16:50 step 1: mse=44.262910 step=0.100000
2017/08/27 08:16:53 step 2: mse=43.560407 step=0.100000
2017/08/27 08:16:55 step 3: mse=42.931166 step=0.100000
2017/08/27 08:16:57 step 4: mse=42.441764 step=0.100000
2017/08/27 08:17:00 step 5: mse=41.897833 step=0.100000
2017/08/27 08:17:02 step 6: mse=41.507713 step=0.100000
2017/08/27 08:17:05 step 7: mse=41.107240 step=0.100000
2017/08/27 08:17:05 Saving...
2017/08/27 08:17:05 Gathering batch of experience...
2017/08/27 08:19:07 batch 231: mean=480.583333 stddev=173.219253 entropy=0.633916 frames=5670 count=12
2017/08/27 08:19:07 Training policy...
2017/08/27 08:19:15 step 0: objective=1.2091427
2017/08/27 08:19:18 step 1: objective=1.2137408
2017/08/27 08:19:21 step 2: objective=1.2168576
2017/08/27 08:19:24 step 3: objective=1.2204378
2017/08/27 08:19:27 step 4: objective=1.2233067
2017/08/27 08:19:30 step 5: objective=1.2263058
2017/08/27 08:19:33 step 6: objective=1.2286851
2017/08/27 08:19:36 step 7: objective=1.2300617
2017/08/27 08:19:36 Training value function...
2017/08/27 08:19:40 step 0: mse=48.106827 step=0.100000
2017/08/27 08:19:43 step 1: mse=46.951690 step=0.100000
2017/08/27 08:19:45 step 2: mse=45.909012 step=0.100000
2017/08/27 08:19:48 step 3: mse=45.051170 step=0.100000
2017/08/27 08:19:50 step 4: mse=44.272794 step=0.100000
2017/08/27 08:19:52 step 5: mse=43.466776 step=0.100000
2017/08/27 08:19:55 step 6: mse=42.767424 step=0.100000
2017/08/27 08:19:57 step 7: mse=42.178512 step=0.100000
2017/08/27 08:19:57 Saving...
2017/08/27 08:19:57 Gathering batch of experience...
2017/08/27 08:21:54 batch 232: mean=429.400000 stddev=200.894931 entropy=0.640597 frames=6358 count=15
2017/08/27 08:21:54 Training policy...
2017/08/27 08:22:03 step 0: objective=0.8247408
2017/08/27 08:22:06 step 1: objective=0.83051264
2017/08/27 08:22:10 step 2: objective=0.8340709
2017/08/27 08:22:13 step 3: objective=0.83633
2017/08/27 08:22:16 step 4: objective=0.84011525
2017/08/27 08:22:20 step 5: objective=0.8435451
2017/08/27 08:22:23 step 6: objective=0.8454779
2017/08/27 08:22:27 step 7: objective=0.8469236
2017/08/27 08:22:27 Training value function...
2017/08/27 08:22:32 step 0: mse=43.453996 step=0.100000
2017/08/27 08:22:34 step 1: mse=43.054413 step=0.100000
2017/08/27 08:22:37 step 2: mse=42.770928 step=0.100000
2017/08/27 08:22:40 step 3: mse=42.425972 step=0.100000
2017/08/27 08:22:43 step 4: mse=42.139281 step=0.100000
2017/08/27 08:22:45 step 5: mse=41.676035 step=0.100000
2017/08/27 08:22:48 step 6: mse=41.385965 step=0.100000
2017/08/27 08:22:51 step 7: mse=41.154333 step=0.100000
2017/08/27 08:22:51 Saving...
2017/08/27 08:22:51 Gathering batch of experience...
2017/08/27 08:24:55 batch 233: mean=451.923077 stddev=213.945522 entropy=0.631064 frames=5767 count=13
2017/08/27 08:24:55 Training policy...
2017/08/27 08:25:03 step 0: objective=1.2054228
2017/08/27 08:25:06 step 1: objective=1.2097843
2017/08/27 08:25:09 step 2: objective=1.2145411
2017/08/27 08:25:12 step 3: objective=1.2170283
2017/08/27 08:25:15 step 4: objective=1.2200906
2017/08/27 08:25:18 step 5: objective=1.2230088
2017/08/27 08:25:21 step 6: objective=1.2253009
2017/08/27 08:25:24 step 7: objective=1.2280364
2017/08/27 08:25:24 Training value function...
2017/08/27 08:25:29 step 0: mse=52.801461 step=0.100000
2017/08/27 08:25:32 step 1: mse=51.675175 step=0.100000
2017/08/27 08:25:34 step 2: mse=50.982861 step=0.100000
2017/08/27 08:25:36 step 3: mse=49.762252 step=0.100000
2017/08/27 08:25:39 step 4: mse=49.185184 step=0.100000
2017/08/27 08:25:41 step 5: mse=48.563402 step=0.100000
2017/08/27 08:25:44 step 6: mse=47.163978 step=0.100000
2017/08/27 08:25:46 step 7: mse=46.589530 step=0.100000
2017/08/27 08:25:46 Saving...
2017/08/27 08:25:46 Gathering batch of experience...
2017/08/27 08:27:52 batch 234: mean=484.500000 stddev=151.060418 entropy=0.639155 frames=5729 count=12
2017/08/27 08:27:52 Training policy...
2017/08/27 08:28:00 step 0: objective=1.075787
2017/08/27 08:28:03 step 1: objective=1.0805464
2017/08/27 08:28:06 step 2: objective=1.0835166
2017/08/27 08:28:09 step 3: objective=1.0860698
2017/08/27 08:28:12 step 4: objective=1.0881114
2017/08/27 08:28:15 step 5: objective=1.0907749
2017/08/27 08:28:18 step 6: objective=1.0933886
2017/08/27 08:28:21 step 7: objective=1.0948724
2017/08/27 08:28:21 Training value function...
2017/08/27 08:28:26 step 0: mse=43.198355 step=0.100000
2017/08/27 08:28:28 step 1: mse=42.463397 step=0.100000
2017/08/27 08:28:31 step 2: mse=41.763725 step=0.100000
2017/08/27 08:28:33 step 3: mse=41.029879 step=0.100000
2017/08/27 08:28:36 step 4: mse=40.457786 step=0.100000
2017/08/27 08:28:38 step 5: mse=40.012012 step=0.100000
2017/08/27 08:28:41 step 6: mse=39.459688 step=0.100000
2017/08/27 08:28:43 step 7: mse=39.021941 step=0.100000
2017/08/27 08:28:43 Saving...
2017/08/27 08:28:43 Gathering batch of experience...
2017/08/27 08:30:39 batch 235: mean=537.090909 stddev=134.697948 entropy=0.630267 frames=5778 count=11
2017/08/27 08:30:39 Training policy...
2017/08/27 08:30:47 step 0: objective=1.2058198
2017/08/27 08:30:50 step 1: objective=1.2103537
2017/08/27 08:30:53 step 2: objective=1.2132874
2017/08/27 08:30:56 step 3: objective=1.2164007
2017/08/27 08:30:59 step 4: objective=1.220093
2017/08/27 08:31:02 step 5: objective=1.2232832
2017/08/27 08:31:05 step 6: objective=1.2248929
2017/08/27 08:31:08 step 7: objective=1.2266474
2017/08/27 08:31:08 Training value function...
2017/08/27 08:31:13 step 0: mse=43.275097 step=0.100000
2017/08/27 08:31:15 step 1: mse=42.317304 step=0.100000
2017/08/27 08:31:18 step 2: mse=41.590765 step=0.100000
2017/08/27 08:31:20 step 3: mse=40.879858 step=0.100000
2017/08/27 08:31:23 step 4: mse=40.143442 step=0.100000
2017/08/27 08:31:25 step 5: mse=39.511485 step=0.100000
2017/08/27 08:31:28 step 6: mse=38.964542 step=0.100000
2017/08/27 08:31:30 step 7: mse=38.393919 step=0.100000
2017/08/27 08:31:30 Saving...
2017/08/27 08:31:30 Gathering batch of experience...
2017/08/27 08:33:29 batch 236: mean=399.466667 stddev=243.991493 entropy=0.640310 frames=5900 count=15
2017/08/27 08:33:29 Training policy...
2017/08/27 08:33:37 step 0: objective=0.76097506
2017/08/27 08:33:40 step 1: objective=0.76701576
2017/08/27 08:33:43 step 2: objective=0.77110875
2017/08/27 08:33:46 step 3: objective=0.7741935
2017/08/27 08:33:49 step 4: objective=0.7768604
2017/08/27 08:33:52 step 5: objective=0.77993304
2017/08/27 08:33:55 step 6: objective=0.78229403
2017/08/27 08:33:58 step 7: objective=0.7839617
2017/08/27 08:33:58 Training value function...
2017/08/27 08:34:03 step 0: mse=49.853001 step=0.100000
2017/08/27 08:34:06 step 1: mse=48.937236 step=0.100000
2017/08/27 08:34:08 step 2: mse=48.064170 step=0.100000
2017/08/27 08:34:11 step 3: mse=47.979118 step=0.100000
2017/08/27 08:34:13 step 4: mse=47.345014 step=0.100000
2017/08/27 08:34:16 step 5: mse=46.746067 step=0.100000
2017/08/27 08:34:18 step 6: mse=45.878431 step=0.100000
2017/08/27 08:34:21 step 7: mse=45.517551 step=0.100000
2017/08/27 08:34:21 Saving...
2017/08/27 08:34:21 Gathering batch of experience...
2017/08/27 08:35:59 batch 237: mean=346.933333 stddev=203.616786 entropy=0.650087 frames=5200 count=15
2017/08/27 08:35:59 Training policy...
2017/08/27 08:36:06 step 0: objective=0.66225076
2017/08/27 08:36:09 step 1: objective=0.6697025
2017/08/27 08:36:12 step 2: objective=0.6766578
2017/08/27 08:36:14 step 3: objective=0.6819186
2017/08/27 08:36:17 step 4: objective=0.68495536
2017/08/27 08:36:20 step 5: objective=0.6873066
2017/08/27 08:36:22 step 6: objective=0.6904278
2017/08/27 08:36:25 step 7: objective=0.6929853
2017/08/27 08:36:25 Training value function...
2017/08/27 08:36:29 step 0: mse=51.199690 step=0.100000
2017/08/27 08:36:32 step 1: mse=50.819503 step=0.100000
2017/08/27 08:36:34 step 2: mse=50.378157 step=0.100000
2017/08/27 08:36:36 step 3: mse=49.998942 step=0.100000
2017/08/27 08:36:38 step 4: mse=49.522001 step=0.100000
2017/08/27 08:36:41 step 5: mse=49.149931 step=0.100000
2017/08/27 08:36:43 step 6: mse=48.835995 step=0.100000
2017/08/27 08:36:45 step 7: mse=48.389571 step=0.100000
2017/08/27 08:36:45 Saving...
2017/08/27 08:36:45 Gathering batch of experience...
2017/08/27 08:38:34 batch 238: mean=430.384615 stddev=160.748030 entropy=0.640845 frames=5559 count=13
2017/08/27 08:38:34 Training policy...
2017/08/27 08:38:42 step 0: objective=1.1314726
2017/08/27 08:38:45 step 1: objective=1.136486
2017/08/27 08:38:48 step 2: objective=1.140533
2017/08/27 08:38:51 step 3: objective=1.1446029
2017/08/27 08:38:54 step 4: objective=1.147467
2017/08/27 08:38:57 step 5: objective=1.1513606
2017/08/27 08:38:59 step 6: objective=1.1542226
2017/08/27 08:39:02 step 7: objective=1.1560118
2017/08/27 08:39:02 Training value function...
2017/08/27 08:39:07 step 0: mse=48.140940 step=0.100000
2017/08/27 08:39:09 step 1: mse=47.258690 step=0.100000
2017/08/27 08:39:12 step 2: mse=45.986411 step=0.100000
2017/08/27 08:39:14 step 3: mse=45.328214 step=0.100000
2017/08/27 08:39:16 step 4: mse=44.690838 step=0.100000
2017/08/27 08:39:19 step 5: mse=44.062180 step=0.100000
2017/08/27 08:39:21 step 6: mse=43.463853 step=0.100000
2017/08/27 08:39:23 step 7: mse=42.887367 step=0.100000
2017/08/27 08:39:23 Saving...
2017/08/27 08:39:23 Gathering batch of experience...
2017/08/27 08:41:17 batch 239: mean=440.916667 stddev=204.599796 entropy=0.629090 frames=5215 count=12
2017/08/27 08:41:17 Training policy...
2017/08/27 08:41:24 step 0: objective=1.1662401
2017/08/27 08:41:27 step 1: objective=1.1721703
2017/08/27 08:41:29 step 2: objective=1.1780317
2017/08/27 08:41:32 step 3: objective=1.1810864
2017/08/27 08:41:35 step 4: objective=1.1846142
2017/08/27 08:41:38 step 5: objective=1.1874353
2017/08/27 08:41:40 step 6: objective=1.1899178
2017/08/27 08:41:43 step 7: objective=1.1917615
2017/08/27 08:41:43 Training value function...
2017/08/27 08:41:47 step 0: mse=46.647053 step=0.100000
2017/08/27 08:41:50 step 1: mse=45.585968 step=0.100000
2017/08/27 08:41:52 step 2: mse=44.621149 step=0.100000
2017/08/27 08:41:54 step 3: mse=43.554362 step=0.100000
2017/08/27 08:41:56 step 4: mse=42.719859 step=0.100000
2017/08/27 08:41:58 step 5: mse=41.904564 step=0.100000
2017/08/27 08:42:00 step 6: mse=41.342322 step=0.100000
2017/08/27 08:42:03 step 7: mse=40.608136 step=0.100000
2017/08/27 08:42:03 Saving...
2017/08/27 08:42:03 Gathering batch of experience...
2017/08/27 08:44:11 batch 240: mean=394.187500 stddev=204.046937 entropy=0.644202 frames=6260 count=16
2017/08/27 08:44:11 Training policy...
2017/08/27 08:44:19 step 0: objective=0.8766046
2017/08/27 08:44:23 step 1: objective=0.8841444
2017/08/27 08:44:26 step 2: objective=0.8887155
2017/08/27 08:44:29 step 3: objective=0.89160377
2017/08/27 08:44:33 step 4: objective=0.8938459
2017/08/27 08:44:36 step 5: objective=0.89745694
2017/08/27 08:44:39 step 6: objective=0.8996747
2017/08/27 08:44:43 step 7: objective=0.9027261
2017/08/27 08:44:43 Training value function...
2017/08/27 08:44:48 step 0: mse=48.504883 step=0.100000
2017/08/27 08:44:51 step 1: mse=47.802250 step=0.100000
2017/08/27 08:44:53 step 2: mse=47.204457 step=0.100000
2017/08/27 08:44:56 step 3: mse=46.765885 step=0.100000
2017/08/27 08:44:59 step 4: mse=46.340855 step=0.100000
2017/08/27 08:45:01 step 5: mse=45.919606 step=0.100000
2017/08/27 08:45:04 step 6: mse=45.622936 step=0.100000
2017/08/27 08:45:07 step 7: mse=45.268853 step=0.100000
2017/08/27 08:45:07 Saving...
2017/08/27 08:45:07 Gathering batch of experience...
2017/08/27 08:47:11 batch 241: mean=411.071429 stddev=192.042579 entropy=0.639215 frames=5711 count=14
2017/08/27 08:47:11 Training policy...
2017/08/27 08:47:19 step 0: objective=0.8980742
2017/08/27 08:47:22 step 1: objective=0.90513325
2017/08/27 08:47:25 step 2: objective=0.90960306
2017/08/27 08:47:28 step 3: objective=0.915574
2017/08/27 08:47:31 step 4: objective=0.9184535
2017/08/27 08:47:34 step 5: objective=0.92083645
2017/08/27 08:47:37 step 6: objective=0.92231154
2017/08/27 08:47:40 step 7: objective=0.9239923
2017/08/27 08:47:40 Training value function...
2017/08/27 08:47:45 step 0: mse=45.829480 step=0.100000
2017/08/27 08:47:47 step 1: mse=45.286645 step=0.100000
2017/08/27 08:47:50 step 2: mse=44.931231 step=0.100000
2017/08/27 08:47:52 step 3: mse=44.749864 step=0.100000
2017/08/27 08:47:54 step 4: mse=44.428818 step=0.100000
2017/08/27 08:47:57 step 5: mse=44.209848 step=0.100000
2017/08/27 08:47:59 step 6: mse=43.926174 step=0.100000
2017/08/27 08:48:02 step 7: mse=43.733933 step=0.100000
2017/08/27 08:48:02 Saving...
2017/08/27 08:48:02 Gathering batch of experience...
2017/08/27 08:49:48 batch 242: mean=400.571429 stddev=192.024074 entropy=0.645357 frames=5573 count=14
2017/08/27 08:49:48 Training policy...
2017/08/27 08:49:56 step 0: objective=1.0589995
2017/08/27 08:49:58 step 1: objective=1.064758
2017/08/27 08:50:01 step 2: objective=1.068143
2017/08/27 08:50:04 step 3: objective=1.0718443
2017/08/27 08:50:07 step 4: objective=1.0748291
2017/08/27 08:50:10 step 5: objective=1.0785708
2017/08/27 08:50:13 step 6: objective=1.0806955
2017/08/27 08:50:16 step 7: objective=1.0830675
2017/08/27 08:50:16 Training value function...
2017/08/27 08:50:21 step 0: mse=51.735458 step=0.100000
2017/08/27 08:50:23 step 1: mse=51.118804 step=0.100000
2017/08/27 08:50:25 step 2: mse=50.580648 step=0.100000
2017/08/27 08:50:28 step 3: mse=50.120556 step=0.100000
2017/08/27 08:50:30 step 4: mse=49.577380 step=0.100000
2017/08/27 08:50:32 step 5: mse=49.100710 step=0.100000
2017/08/27 08:50:35 step 6: mse=48.719355 step=0.100000
2017/08/27 08:50:37 step 7: mse=48.223195 step=0.100000
2017/08/27 08:50:37 Saving...
2017/08/27 08:50:37 Gathering batch of experience...
